From @tp @end|ng |rom p|@kor@k|@com  Fri Oct  1 11:01:39 2021
From: @tp @end|ng |rom p|@kor@k|@com (Andrew Piskorski)
Date: Fri, 1 Oct 2021 05:01:39 -0400
Subject: [Rd] R 4.1.x make check fails, stats-Ex.R,
 step factor reduced below minFactor
Message-ID: <YVbOc7TQQuUN8tYO@piskorski.com>

I recently built R 4.1.1 (Patched) from source, as I have many older
versions over the years.  This version, on Ubuntu 18.04.4 LTS:

  R 4.1.1 (Patched), 2021-09-21, svn.rev 80946, x86_64-pc-linux-gnu

Surprisingly, "make check" fails, which I don't recall seeing before.
The error is in from stats-Ex.R, which unfortunately terminates all
further testing!  This particular error, "step factor ... reduced
below 'minFactor'" does not seem very serious, but I can't figure out
why it's happening.

I installed with "make install install-tests" as usual, which seemed
to work fine.  Running the same tests after install, I'm able to get
more coverage by using errorsAreFatal=FALSE.  However, it seems the
rest of the 'stats' tests after the bad one still do not run.

I'm confused about the intent of this particular test.  The comment
above it seems to says that it's SUPPOSED to throw this error, yet
getting the error still terminates further testing, which seems
strange.  What's supposed to happen here?

Any ideas on why this error might be occurring, and how I should debug
it?  What's the right way for me to disable this one failing test, so
the ones after it can run?

Thanks for your help!


## "make check" output:
make[1]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
make[2]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
make[3]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
Testing examples for package 'base'
Testing examples for package 'tools'
  comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ... OK
Testing examples for package 'utils'
Testing examples for package 'grDevices'
  comparing 'grDevices-Ex.Rout' to 'grDevices-Ex.Rout.save' ... OK
Testing examples for package 'graphics'
  comparing 'graphics-Ex.Rout' to 'graphics-Ex.Rout.save' ... OK
Testing examples for package 'stats'
Error: testing 'stats' failed
Execution halted
Makefile:37: recipe for target 'test-Examples-Base' failed
make[3]: *** [test-Examples-Base] Error 1
make[3]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
../../tests/Makefile.common:198: recipe for target 'test-Examples' failed
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
../../tests/Makefile.common:184: recipe for target 'test-all-basics' failed
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
Makefile:305: recipe for target 'check-all' failed
make: *** [check-all] Error 2


## From file:  tests/Examples/stats-Ex.Rout.fail

> ## Here, requiring close convergence, you need to use more accurate numerical
> ##  differentiation; this gives Error: "step factor .. reduced below 'minFactor' .."
> options(digits = 10) # more accuracy for 'trace'
> ## IGNORE_RDIFF_BEGIN
> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model
>    (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model
1017460.306    (4.15e+02): par = (1 1 1)
758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
269506.3538    (3.23e+02): par = (51.75719816 -13.09155957 0.8428607709)
68969.21893    (1.03e+02): par = (76.0006985 -1.935226745 1.0190858)
633.3672230    (1.29e+00): par = (100.3761515 8.624648402 5.104490259)
151.4400218    (9.39e+00): par = (100.6344391 4.913490985 0.2849209569)
53.08739850    (7.24e+00): par = (100.6830407 6.899303317 0.4637755074)
1.344478640    (5.97e-01): par = (100.0368306 9.897714142 0.5169294939)
0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
0.9906046054   (9.95e-08): par = (100.028875 9.916228366 0.50252165)
0.9906046054   (9.93e-08): par = (100.028875 9.916228366 0.50252165)
Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  : 
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562
Calls: update -> update.default -> eval -> eval -> nls
Execution halted


## After install, start R with --vanilla and run tests like this:
## https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Testing-a-Unix_002dalike-Installation
Sys.setenv(LC_COLLATE = "C", LC_TIME = "C", LANGUAGE = "en")
pdf("tests.pdf")
tools::testInstalledPackages(scope="base", errorsAreFatal=FALSE)

-- 
Andrew Piskorski <atp at piskorski.com>


From @eb@meyer @end|ng |rom |@u@de  Fri Oct  1 12:03:25 2021
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Fri, 1 Oct 2021 12:03:25 +0200
Subject: [Rd] R 4.1.x make check fails, stats-Ex.R,
 step factor reduced below minFactor
In-Reply-To: <YVbOc7TQQuUN8tYO@piskorski.com>
References: <YVbOc7TQQuUN8tYO@piskorski.com>
Message-ID: <339c9b7c-baad-8ef5-82db-8b3a2cba945f@fau.de>

For what it's worth, make check runs OK for me with sessionInfo()

R version 4.1.1 Patched (2021-09-30 r80997)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.6 LTS

Matrix products: default
BLAS:   /home/smeyer/R/base/release/build/lib/libRblas.so
LAPACK: /home/smeyer/R/base/release/build/lib/libRlapack.so

The output of these examples is:

>> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>   No starting values specified for some parameters.
> Initializing ?Const?, ?A?, ?B? to '1.'.
> Consider specifying 'start' or using a selfStart model
> Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  : 
>   step factor 0.000488281 reduced below 'minFactor' of 0.000976562
>>    (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>   No starting values specified for some parameters.
> Initializing ?Const?, ?A?, ?B? to '1.'.
> Consider specifying 'start' or using a selfStart model
> 1017460.306    (4.15e+02): par = (1 1 1)
> 758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
> 269506.3537    (3.23e+02): par = (51.75719817 -13.09155958 0.8428607712)
> 68969.21891    (1.03e+02): par = (76.0006985 -1.93522675 1.0190858)
> 633.3672224    (1.29e+00): par = (100.3761515 8.624648408 5.104490252)
> 151.4400170    (9.39e+00): par = (100.6344391 4.913490999 0.2849209664)
> 53.08739445    (7.24e+00): par = (100.6830407 6.899303393 0.4637755095)
> 1.344478582    (5.97e-01): par = (100.0368306 9.897714144 0.5169294926)
> 0.9908415908   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
> 0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
> 0.9906046054   (9.94e-08): par = (100.028875 9.916228366 0.50252165)
> 0.9906046054   (5.00e-08): par = (100.028875 9.916228377 0.5025216525)
> Nonlinear regression model
>   model: y ~ Const + A * exp(B * x)
>    data: parent.frame()
>       Const           A           B 
> 100.0288750   9.9162284   0.5025217 
>  residual sum-of-squares: 0.9906046

Running with example(nls) in an interactive session gives the extra output

> Number of iterations to convergence: 11 
> Achieved convergence tolerance: 4.996813e-08

(when the "show.nls.convergence" option is not set to FALSE. It is set 
to FALSE in SSasymp.Rd but not reset at the end.)

Best regards,

	Sebastian


Am 01.10.21 um 11:01 schrieb Andrew Piskorski:
> I recently built R 4.1.1 (Patched) from source, as I have many older
> versions over the years.  This version, on Ubuntu 18.04.4 LTS:
> 
>    R 4.1.1 (Patched), 2021-09-21, svn.rev 80946, x86_64-pc-linux-gnu
> 
> Surprisingly, "make check" fails, which I don't recall seeing before.
> The error is in from stats-Ex.R, which unfortunately terminates all
> further testing!  This particular error, "step factor ... reduced
> below 'minFactor'" does not seem very serious, but I can't figure out
> why it's happening.
> 
> I installed with "make install install-tests" as usual, which seemed
> to work fine.  Running the same tests after install, I'm able to get
> more coverage by using errorsAreFatal=FALSE.  However, it seems the
> rest of the 'stats' tests after the bad one still do not run.
> 
> I'm confused about the intent of this particular test.  The comment
> above it seems to says that it's SUPPOSED to throw this error, yet
> getting the error still terminates further testing, which seems
> strange.  What's supposed to happen here?
> 
> Any ideas on why this error might be occurring, and how I should debug
> it?  What's the right way for me to disable this one failing test, so
> the ones after it can run?
> 
> Thanks for your help!
> 
> 
> ## "make check" output:
> make[1]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
> make[2]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
> make[3]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
> Testing examples for package 'base'
> Testing examples for package 'tools'
>    comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ... OK
> Testing examples for package 'utils'
> Testing examples for package 'grDevices'
>    comparing 'grDevices-Ex.Rout' to 'grDevices-Ex.Rout.save' ... OK
> Testing examples for package 'graphics'
>    comparing 'graphics-Ex.Rout' to 'graphics-Ex.Rout.save' ... OK
> Testing examples for package 'stats'
> Error: testing 'stats' failed
> Execution halted
> Makefile:37: recipe for target 'test-Examples-Base' failed
> make[3]: *** [test-Examples-Base] Error 1
> make[3]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
> ../../tests/Makefile.common:198: recipe for target 'test-Examples' failed
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
> ../../tests/Makefile.common:184: recipe for target 'test-all-basics' failed
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
> Makefile:305: recipe for target 'check-all' failed
> make: *** [check-all] Error 2
> 
> 
> ## From file:  tests/Examples/stats-Ex.Rout.fail
> 
>> ## Here, requiring close convergence, you need to use more accurate numerical
>> ##  differentiation; this gives Error: "step factor .. reduced below 'minFactor' .."
>> options(digits = 10) # more accuracy for 'trace'
>> ## IGNORE_RDIFF_BEGIN
>> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>    No starting values specified for some parameters.
> Initializing 'Const', 'A', 'B' to '1.'.
> Consider specifying 'start' or using a selfStart model
>>     (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>    No starting values specified for some parameters.
> Initializing 'Const', 'A', 'B' to '1.'.
> Consider specifying 'start' or using a selfStart model
> 1017460.306    (4.15e+02): par = (1 1 1)
> 758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
> 269506.3538    (3.23e+02): par = (51.75719816 -13.09155957 0.8428607709)
> 68969.21893    (1.03e+02): par = (76.0006985 -1.935226745 1.0190858)
> 633.3672230    (1.29e+00): par = (100.3761515 8.624648402 5.104490259)
> 151.4400218    (9.39e+00): par = (100.6344391 4.913490985 0.2849209569)
> 53.08739850    (7.24e+00): par = (100.6830407 6.899303317 0.4637755074)
> 1.344478640    (5.97e-01): par = (100.0368306 9.897714142 0.5169294939)
> 0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
> 0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
> 0.9906046054   (9.95e-08): par = (100.028875 9.916228366 0.50252165)
> 0.9906046054   (9.93e-08): par = (100.028875 9.916228366 0.50252165)
> Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>    step factor 0.000488281 reduced below 'minFactor' of 0.000976562
> Calls: update -> update.default -> eval -> eval -> nls
> Execution halted
> 
> 
> ## After install, start R with --vanilla and run tests like this:
> ## https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Testing-a-Unix_002dalike-Installation
> Sys.setenv(LC_COLLATE = "C", LC_TIME = "C", LANGUAGE = "en")
> pdf("tests.pdf")
> tools::testInstalledPackages(scope="base", errorsAreFatal=FALSE)
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Oct  1 12:48:28 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 1 Oct 2021 12:48:28 +0200
Subject: [Rd] 
 translation domain is not inferred correctly from a package's
 print methods -- intended behavior?
In-Reply-To: <CAPRVBcx4PXAAOSs6jqw4cio0E7GxnOft1McUma6TBh_hcaBWLg@mail.gmail.com>
References: <CAPRVBcx4PXAAOSs6jqw4cio0E7GxnOft1McUma6TBh_hcaBWLg@mail.gmail.com>
Message-ID: <24918.59260.330726.837476@stat.math.ethz.ch>

>>>>> Michael Chirico 
>>>>>     on Mon, 12 Jul 2021 14:21:14 -0700 writes:

    > Here is a reprex:


    > # initialize reprex package
    > cd /tmp
    > mkdir myPkg && cd myPkg
    > echo "Package: myPkg" > DESCRIPTION
    > echo "Version: 0.0.1" >> DESCRIPTION
    > mkdir R
    > echo "print.my_class = function(x, ...) { cat(gettext(\"'%s' is
    > deprecated.\"), '\n', gettext(\"'%s' is deprecated.\",
    > domain='R-myPkg'), '\n') }" > R/foo.R
    > echo "S3method(print, my_class)" > NAMESPACE
    > # extract string for translation
    > Rscript -e "tools::update_pkg_po('.')"
    > # add dummy translation
    > msginit -i po/R-myPkg.pot -o po/R-ja.po -l ja --no-translator
    > head -n -1 po/R-ja.po > tmp && mv tmp po/R-ja.po
    > echo 'msgstr "%s successfully translated"' >> po/R-ja.po
    > # install .mo translations
    > Rscript -e "tools::update_pkg_po('.')"
    > # install package & test
    > R CMD INSTALL .
    > LANGUAGE=ja Rscript -e "library(myPkg); print(structure(1, class = 'my_class'))"
    > #  '%s' ???????
    > #  %s successfully translated

Trying to see if the current "R-devel trunk" would still suffer
from this, and prompted by Suharto Anggono's suggestion on R's
bugzilla,   https://bugs.r-project.org/show_bug.cgi?id=17998#c24


I've finally started looking at this ..
(Not having a Japanese locale installed though).

    > Note that the first gettext() call, which doesn't supply domain=,
    > returns the corresponding translation from base R (i.e., the output is
    > the same as gettext("'%s' is deprecated.", domain="R-base")).

I don't see this (not having a Japanase locale?  should I try
with a locale I have installed?)

    > The second gettext() call, where domain= is supplied, returns our
    > dummy translation, which is what I would have expected from the first
    > execution.

I can get the following which seems to say that everything is
fine and fixed now, right?

MM at lynne:myPkg$ LANGUAGE=ja R-devel -s --vanilla -e 'library(myPkg,lib.loc="~/R/library/64-linux-MM-only");structure(1,class="my_class");R.version.string'
%s successfully translated 
 %s successfully translated 
[1] "R Under development (unstable) (2021-09-30 r80997)"


MM at lynne:myPkg$ LANGUAGE=ja `R-devel RHOME`/bin/Rscript --vanilla -e 'library(myPkg,lib.loc="~/R/library/64-linux-MM-only");structure(1,class="my_class");R.version.string'
%s successfully translated 
 %s successfully translated 
[1] "R Under development (unstable) (2021-09-30 r80997)"


Note: During my experiments, I also do observe things confusing to me, when
using Rscript and R from the command line... in some cases
getting errors (in Japanese) ... but that may be just in those
cases I have left any space in the string
((in the case of 'R' which in my case suffers from quoting hell
  because I use wrapper  sh-scripts to call my versions of R ... ))


    > Here is what's in ?gettext:

    >> If domain is NULL or "", and gettext or ngettext is called from a function in the namespace of package pkg the domain is set to "R-pkg". Otherwise there is no default domain.


    > Does that mean the S3 print method is not "in the namespace of myPkg"?

no.

    > Or is there a bug here?

Yes, rather;  or there *was* one.

Thanks a lot, Michael!

Best,
Martin


From pd@|gd @end|ng |rom gm@||@com  Fri Oct  1 13:14:19 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 1 Oct 2021 13:14:19 +0200
Subject: [Rd] R 4.1.x make check fails, stats-Ex.R,
 step factor reduced below minFactor
In-Reply-To: <339c9b7c-baad-8ef5-82db-8b3a2cba945f@fau.de>
References: <YVbOc7TQQuUN8tYO@piskorski.com>
 <339c9b7c-baad-8ef5-82db-8b3a2cba945f@fau.de>
Message-ID: <6B302244-A695-46E5-876F-2B291FFC82E2@gmail.com>

On Mac, I also don't get the error, but I think this is a different issue.

If I remember correctly, the error is known to occur on some platforms, but not all, which is the reason for the ## IGNORE_RDIFF_BEGIN ... END.

However _when_ it occurs, R should just print the error and continue. If it doesn't, something is up. One possible reason is that something has been playing with options(error=), e.g. in a start-up file. 

-pd


> On 1 Oct 2021, at 12:03 , Sebastian Meyer <seb.meyer at fau.de> wrote:
> 
> For what it's worth, make check runs OK for me with sessionInfo()
> 
> R version 4.1.1 Patched (2021-09-30 r80997)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 18.04.6 LTS
> 
> Matrix products: default
> BLAS:   /home/smeyer/R/base/release/build/lib/libRblas.so
> LAPACK: /home/smeyer/R/base/release/build/lib/libRlapack.so
> 
> The output of these examples is:
> 
>>> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
>> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>>  No starting values specified for some parameters.
>> Initializing ?Const?, ?A?, ?B? to '1.'.
>> Consider specifying 'start' or using a selfStart model
>> Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :   step factor 0.000488281 reduced below 'minFactor' of 0.000976562
>>>   (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
>> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>>  No starting values specified for some parameters.
>> Initializing ?Const?, ?A?, ?B? to '1.'.
>> Consider specifying 'start' or using a selfStart model
>> 1017460.306    (4.15e+02): par = (1 1 1)
>> 758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
>> 269506.3537    (3.23e+02): par = (51.75719817 -13.09155958 0.8428607712)
>> 68969.21891    (1.03e+02): par = (76.0006985 -1.93522675 1.0190858)
>> 633.3672224    (1.29e+00): par = (100.3761515 8.624648408 5.104490252)
>> 151.4400170    (9.39e+00): par = (100.6344391 4.913490999 0.2849209664)
>> 53.08739445    (7.24e+00): par = (100.6830407 6.899303393 0.4637755095)
>> 1.344478582    (5.97e-01): par = (100.0368306 9.897714144 0.5169294926)
>> 0.9908415908   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
>> 0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
>> 0.9906046054   (9.94e-08): par = (100.028875 9.916228366 0.50252165)
>> 0.9906046054   (5.00e-08): par = (100.028875 9.916228377 0.5025216525)
>> Nonlinear regression model
>>  model: y ~ Const + A * exp(B * x)
>>   data: parent.frame()
>>      Const           A           B 100.0288750   9.9162284   0.5025217  residual sum-of-squares: 0.9906046
> 
> Running with example(nls) in an interactive session gives the extra output
> 
>> Number of iterations to convergence: 11 Achieved convergence tolerance: 4.996813e-08
> 
> (when the "show.nls.convergence" option is not set to FALSE. It is set to FALSE in SSasymp.Rd but not reset at the end.)
> 
> Best regards,
> 
> 	Sebastian
> 
> 
> Am 01.10.21 um 11:01 schrieb Andrew Piskorski:
>> I recently built R 4.1.1 (Patched) from source, as I have many older
>> versions over the years.  This version, on Ubuntu 18.04.4 LTS:
>>   R 4.1.1 (Patched), 2021-09-21, svn.rev 80946, x86_64-pc-linux-gnu
>> Surprisingly, "make check" fails, which I don't recall seeing before.
>> The error is in from stats-Ex.R, which unfortunately terminates all
>> further testing!  This particular error, "step factor ... reduced
>> below 'minFactor'" does not seem very serious, but I can't figure out
>> why it's happening.
>> I installed with "make install install-tests" as usual, which seemed
>> to work fine.  Running the same tests after install, I'm able to get
>> more coverage by using errorsAreFatal=FALSE.  However, it seems the
>> rest of the 'stats' tests after the bad one still do not run.
>> I'm confused about the intent of this particular test.  The comment
>> above it seems to says that it's SUPPOSED to throw this error, yet
>> getting the error still terminates further testing, which seems
>> strange.  What's supposed to happen here?
>> Any ideas on why this error might be occurring, and how I should debug
>> it?  What's the right way for me to disable this one failing test, so
>> the ones after it can run?
>> Thanks for your help!
>> ## "make check" output:
>> make[1]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
>> make[2]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
>> make[3]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
>> Testing examples for package 'base'
>> Testing examples for package 'tools'
>>   comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ... OK
>> Testing examples for package 'utils'
>> Testing examples for package 'grDevices'
>>   comparing 'grDevices-Ex.Rout' to 'grDevices-Ex.Rout.save' ... OK
>> Testing examples for package 'graphics'
>>   comparing 'graphics-Ex.Rout' to 'graphics-Ex.Rout.save' ... OK
>> Testing examples for package 'stats'
>> Error: testing 'stats' failed
>> Execution halted
>> Makefile:37: recipe for target 'test-Examples-Base' failed
>> make[3]: *** [test-Examples-Base] Error 1
>> make[3]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
>> ../../tests/Makefile.common:198: recipe for target 'test-Examples' failed
>> make[2]: *** [test-Examples] Error 2
>> make[2]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
>> ../../tests/Makefile.common:184: recipe for target 'test-all-basics' failed
>> make[1]: *** [test-all-basics] Error 1
>> make[1]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
>> Makefile:305: recipe for target 'check-all' failed
>> make: *** [check-all] Error 2
>> ## From file:  tests/Examples/stats-Ex.Rout.fail
>>> ## Here, requiring close convergence, you need to use more accurate numerical
>>> ##  differentiation; this gives Error: "step factor .. reduced below 'minFactor' .."
>>> options(digits = 10) # more accuracy for 'trace'
>>> ## IGNORE_RDIFF_BEGIN
>>> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
>> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>>   No starting values specified for some parameters.
>> Initializing 'Const', 'A', 'B' to '1.'.
>> Consider specifying 'start' or using a selfStart model
>>>    (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
>> Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>>   No starting values specified for some parameters.
>> Initializing 'Const', 'A', 'B' to '1.'.
>> Consider specifying 'start' or using a selfStart model
>> 1017460.306    (4.15e+02): par = (1 1 1)
>> 758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
>> 269506.3538    (3.23e+02): par = (51.75719816 -13.09155957 0.8428607709)
>> 68969.21893    (1.03e+02): par = (76.0006985 -1.935226745 1.0190858)
>> 633.3672230    (1.29e+00): par = (100.3761515 8.624648402 5.104490259)
>> 151.4400218    (9.39e+00): par = (100.6344391 4.913490985 0.2849209569)
>> 53.08739850    (7.24e+00): par = (100.6830407 6.899303317 0.4637755074)
>> 1.344478640    (5.97e-01): par = (100.0368306 9.897714142 0.5169294939)
>> 0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
>> 0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
>> 0.9906046054   (9.95e-08): par = (100.028875 9.916228366 0.50252165)
>> 0.9906046054   (9.93e-08): par = (100.028875 9.916228366 0.50252165)
>> Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
>>   step factor 0.000488281 reduced below 'minFactor' of 0.000976562
>> Calls: update -> update.default -> eval -> eval -> nls
>> Execution halted
>> ## After install, start R with --vanilla and run tests like this:
>> ## https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Testing-a-Unix_002dalike-Installation
>> Sys.setenv(LC_COLLATE = "C", LC_TIME = "C", LANGUAGE = "en")
>> pdf("tests.pdf")
>> tools::testInstalledPackages(scope="base", errorsAreFatal=FALSE)
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Oct  1 15:45:48 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 1 Oct 2021 15:45:48 +0200
Subject: [Rd] R 4.1.x make check fails, stats-Ex.R,
 step factor reduced below minFactor
In-Reply-To: <YVbOc7TQQuUN8tYO@piskorski.com>
References: <YVbOc7TQQuUN8tYO@piskorski.com>
Message-ID: <24919.4364.817651.951991@stat.math.ethz.ch>

>>>>> Andrew Piskorski 
>>>>>     on Fri, 1 Oct 2021 05:01:39 -0400 writes:

    > I recently built R 4.1.1 (Patched) from source, as I have many older
    > versions over the years.  This version, on Ubuntu 18.04.4 LTS:

    > R 4.1.1 (Patched), 2021-09-21, svn.rev 80946, x86_64-pc-linux-gnu

    > Surprisingly, "make check" fails, which I don't recall seeing before.
    > The error is in from stats-Ex.R, which unfortunately terminates all
    > further testing!  This particular error, "step factor ... reduced
    > below 'minFactor'" does not seem very serious, but I can't figure out
    > why it's happening.

    > I installed with "make install install-tests" as usual, which seemed
    > to work fine.  Running the same tests after install, I'm able to get
    > more coverage by using errorsAreFatal=FALSE.  However, it seems the
    > rest of the 'stats' tests after the bad one still do not run.

    > I'm confused about the intent of this particular test.  The comment
    > above it seems to says that it's SUPPOSED to throw this error, yet
    > getting the error still terminates further testing, which seems
    > strange.  What's supposed to happen here?

    > Any ideas on why this error might be occurring, and how I should debug
    > it?  What's the right way for me to disable this one failing test, so
    > the ones after it can run?

    > Thanks for your help!


    > ## "make check" output:
    > make[1]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
    > make[2]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
    > make[3]: Entering directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
    > Testing examples for package 'base'
    > Testing examples for package 'tools'
    > comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ... OK
    > Testing examples for package 'utils'
    > Testing examples for package 'grDevices'
    > comparing 'grDevices-Ex.Rout' to 'grDevices-Ex.Rout.save' ... OK
    > Testing examples for package 'graphics'
    > comparing 'graphics-Ex.Rout' to 'graphics-Ex.Rout.save' ... OK
    > Testing examples for package 'stats'
    > Error: testing 'stats' failed
    > Execution halted
    > Makefile:37: recipe for target 'test-Examples-Base' failed
    > make[3]: *** [test-Examples-Base] Error 1
    > make[3]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests/Examples'
    > ../../tests/Makefile.common:198: recipe for target 'test-Examples' failed
    > make[2]: *** [test-Examples] Error 2
    > make[2]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
    > ../../tests/Makefile.common:184: recipe for target 'test-all-basics' failed
    > make[1]: *** [test-all-basics] Error 1
    > make[1]: Leaving directory '/home/nobackup/co/R/R-4-1-branch/Build-x86_64/tests'
    > Makefile:305: recipe for target 'check-all' failed
    > make: *** [check-all] Error 2


    > ## From file:  tests/Examples/stats-Ex.Rout.fail

    >> ## Here, requiring close convergence, you need to use more accurate numerical
    >> ##  differentiation; this gives Error: "step factor .. reduced below 'minFactor' .."
    >> options(digits = 10) # more accuracy for 'trace'
    >> ## IGNORE_RDIFF_BEGIN
    >> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
    > Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
    > No starting values specified for some parameters.
    > Initializing 'Const', 'A', 'B' to '1.'.
    > Consider specifying 'start' or using a selfStart model

So this did give an error we expected (on some platforms only),
hence used try().

However, the next one "should work" (*)
and failing there, *does* fail the tests :

    >> (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
    > Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
    > No starting values specified for some parameters.
    > Initializing 'Const', 'A', 'B' to '1.'.
    > Consider specifying 'start' or using a selfStart model
    > 1017460.306    (4.15e+02): par = (1 1 1)
    > 758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
    > 269506.3538    (3.23e+02): par = (51.75719816 -13.09155957 0.8428607709)
    > 68969.21893    (1.03e+02): par = (76.0006985 -1.935226745 1.0190858)
    > 633.3672230    (1.29e+00): par = (100.3761515 8.624648402 5.104490259)
    > 151.4400218    (9.39e+00): par = (100.6344391 4.913490985 0.2849209569)
    > 53.08739850    (7.24e+00): par = (100.6830407 6.899303317 0.4637755074)
    > 1.344478640    (5.97e-01): par = (100.0368306 9.897714142 0.5169294939)
    > 0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
    > 0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
    > 0.9906046054   (9.95e-08): par = (100.028875 9.916228366 0.50252165)
    > 0.9906046054   (9.93e-08): par = (100.028875 9.916228366 0.50252165)
    > Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  : 
    > step factor 0.000488281 reduced below 'minFactor' of 0.000976562
    > Calls: update -> update.default -> eval -> eval -> nls
    > Execution halted

On our versions of Linux (and hardware in case it should matter: Intel x64), 
the above has always worked:
e.g.,

> (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
Warning in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing ?Const?, ?A?, ?B? to '1.'.
Consider specifying 'start' or using a selfStart model
1017460.306    (4.15e+02): par = (1 1 1)
758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543746)
269506.3540    (3.23e+02): par = (51.75719814 -13.09155954 0.8428607699)
68969.21900    (1.03e+02): par = (76.00069849 -1.93522673 1.019085799)
633.3672239    (1.29e+00): par = (100.3761515 8.62464841 5.104490279)
151.4400266    (9.39e+00): par = (100.6344391 4.913490966 0.284920948)
53.08740235    (7.24e+00): par = (100.6830408 6.899303242 0.4637755057)
1.344478691    (5.97e-01): par = (100.0368306 9.89771414 0.5169294949)
0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516842)
0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207337)
0.9906046054   (9.94e-08): par = (100.028875 9.916228366 0.50252165)
0.9906046054   (5.06e-10): par = (100.028875 9.916228388 0.5025216549)
Nonlinear regression model
  model: y ~ Const + A * exp(B * x)
   data: parent.frame()
      Const           A           B 
100.0288750   9.9162284   0.5025217 
 residual sum-of-squares: 0.9906046

However, we had heard of "strange platforms" where it failed,
--> R's bugzilla PR#18165
and for that reason, in the R-devel version of that source file
 <Rsrc>/src/library/stats/man/nls.Rd

have the code amended to not stop on error on those platforms
only:

o2 <- options(digits = 10) # more accuracy for 'trace'
## central differencing works here typically (PR#18165: not converging on *some*):
ctr2 <- nls.control(nDcentral=TRUE, tol = 8e-8, # <- even smaller than above
   warnOnly = (grepl("^aarch64.*linux", R.version$platform) && grepl("^NixOS", osVersion)
              ))
(nlm2 <- update(nlmod, control = ctr2, trace = TRUE)); options(o2)

... now would that run w/o error on your Ubuntu-installed R ?

First guess: no

Is there anything special (system libraries, compilers, ..)
on your platform?

If not, I do wonder because indeed the

   example(nls)

R code (indeed the full help page) is identical as in R 4.1.1,
and I think we can assume for sure that these examples have run
satisfactorily on most Ubuntu 18.04 LTS, no?



    > ## After install, start R with --vanilla and run tests like this:
    > ## https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Testing-a-Unix_002dalike-Installation
    > Sys.setenv(LC_COLLATE = "C", LC_TIME = "C", LANGUAGE = "en")
    > pdf("tests.pdf")
    > tools::testInstalledPackages(scope="base", errorsAreFatal=FALSE)

    > -- 
    > Andrew Piskorski <atp at piskorski.com>

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From @tp @end|ng |rom p|@kor@k|@com  Fri Oct  1 18:05:44 2021
From: @tp @end|ng |rom p|@kor@k|@com (Andrew Piskorski)
Date: Fri, 1 Oct 2021 12:05:44 -0400
Subject: [Rd] R 4.1.x make check fails, stats-Ex.R,
 step factor reduced below minFactor
In-Reply-To: <24919.4364.817651.951991@stat.math.ethz.ch>
References: <YVbOc7TQQuUN8tYO@piskorski.com>
 <24919.4364.817651.951991@stat.math.ethz.ch>
Message-ID: <YVcx2BvQIJZBd0oF@piskorski.com>

On Fri, Oct 01, 2021 at 03:45:48PM +0200, Martin Maechler wrote:

> Is there anything special (system libraries, compilers, ..)
> on your platform?

No.  As far as I know this is an ordinary SuperMicro x86-64 server,
nothing strange or unusual.  /proc/cpuinfo says "Intel(R) Xeon(R) CPU
E5-2670 0 @ 2.60GHz".

> o2 <- options(digits = 10) # more accuracy for 'trace'
> ## central differencing works here typically (PR#18165: not converging on *some*):
> ctr2 <- nls.control(nDcentral=TRUE, tol = 8e-8, # <- even smaller than above
>    warnOnly = (grepl("^aarch64.*linux", R.version$platform) && grepl("^NixOS", osVersion)
>               ))
> (nlm2 <- update(nlmod, control = ctr2, trace = TRUE)); options(o2)
> 
> ... now would that run w/o error on your Ubuntu-installed R ?

Interactively, the code above runs fine.  In fact, the original code
ALSO seems to run fine, no errors at all!  See output below.  I get
the error when running the tests via either "make check" or
tools::testInstalledPackages(scope="base"), but outside of that
testing framework it runs fine.

Ah, interactively, if I ALSO run the code for the immediately prior
test in stats-Ex.R, THEN the nlm2 code fails the same way as with
"make check".  That prior test does set.seed(27), which seems to
trigger the downstream failures.  Simply skipping the set.seed(27)
(interactively) makes the failure go away for me.  But if the
set.seed(27) is necessary, maybe the second test should be doing its
own set.seed() of some sort?

I don't know how/where to comment out that set.seed(27) to try running
tests without it.  Editing "src/library/stats/man/nls.Rd" and re-running
"make check" still does the set.seed(27).


Just run code from the single failing test, it works fine:
------------------------------------------------------------
## R --vanilla
R version 4.1.1 Patched (2021-09-21 r80946) -- "Kick Things"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu/x86_64 (64-bit)

> Sys.setenv(LC_COLLATE = "C", LC_TIME = "C", LANGUAGE = "en")
> options(digits = 10)
> x <- -(1:100)/10
> y <- 100 + 10 * exp(x / 2) + rnorm(x)/10
> nlmod <- nls(y ~  Const + A * exp(B * x))
Warning message:
In nls(y ~ Const + A * exp(B * x)) :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model

> nlm1 <- update(nlmod, control = list(tol = 1e-7))
Warning message:
In nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model

> nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE)
1017400.445    (4.11e+02): par = (1 1 1)
752239.9094    (1.96e+02): par = (13.41553998 1.959746504 0.01471383253)
668978.9926    (1.65e+02): par = (189.3774772 -162.3882591 1.397507535)
375910.4745    (1.20e+02): par = (167.1787529 -119.9960435 1.42386803)
93230.26788    (5.49e+01): par = (133.8879258 -56.45697809 1.498055399)
382.9221937    (2.42e+00): par = (100.6364489 6.806405333 1.84811172)
138.7915397    (9.68e+00): par = (100.6763251 6.489793899 0.7564107501)
24.47843640    (5.42e+00): par = (100.4024547 8.003646622 0.4918079622)
0.8056918383   (4.49e-03): par = (99.9629562 10.01549373 0.4913706525)
0.8056755692   (4.09e-06): par = (99.96295295 10.01549135 0.4914577719)
0.8056755692   (7.83e-09): par = (99.96295344 10.01549217 0.4914579487)
Warning message:
In nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model

> nlm1
Nonlinear regression model
  model: y ~ Const + A * exp(B * x)
   data: parent.frame()
     Const          A          B 
99.9629534 10.0154922  0.4914579 
 residual sum-of-squares: 0.8056756

Number of iterations to convergence: 10 
Achieved convergence tolerance: 1.586349e-08

> nlm2
Nonlinear regression model
  model: y ~ Const + A * exp(B * x)
   data: parent.frame()
     Const          A          B 
99.9629534 10.0154922  0.4914579 
 residual sum-of-squares: 0.8056756

Number of iterations to convergence: 10 
Achieved convergence tolerance: 7.832984e-09


Instead run BOTH these tests, now the last one fails:
------------------------------------------------------------
## R --vanilla
R version 4.1.1 Patched (2021-09-21 r80946) -- "Kick Things"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu/x86_64 (64-bit)

## The two examples below show that you can fit a model to
## artificial data with noise but not to artificial data
## without noise.
> x <- 1:10
> y <- 2*x + 3                            # perfect fit
## terminates in an error, because convergence cannot be confirmed:
> try(nls(y ~ a + b*x, start = list(a = 0.12345, b = 0.54321)))
> Error in nls(y ~ a + b * x, start = list(a = 0.12345, b = 0.54321)) : 
  number of iterations exceeded maximum of 50
## adjusting the convergence test by adding 'scaleOffset' to its denominator RSS:
> nls(y ~ a + b*x, start = list(a = 0.12345, b = 0.54321),
    control = list(scaleOffset = 1, printEval=TRUE))
> +   It.   1, fac=           1, eval (no.,total): ( 1,  1): new dev = 1.05935e-12
Nonlinear regression model
  model: y ~ a + b * x
   data: parent.frame()
a b 
3 2 
 residual sum-of-squares: 1.059e-12

Number of iterations to convergence: 1 
Achieved convergence tolerance: 3.639e-07
> ## Alternatively jittering the "too exact" values, slightly:
set.seed(27)
> yeps <- y + rnorm(length(y), sd = 0.01) # added noise
> nls(yeps ~ a + b*x, start = list(a = 0.12345, b = 0.54321))
Nonlinear regression model
  model: yeps ~ a + b * x
   data: parent.frame()
    a     b 
3.001 2.000 
 residual sum-of-squares: 0.001346

Number of iterations to convergence: 2 
Achieved convergence tolerance: 8.658e-09
> 
> ## the nls() internal cheap guess for starting values can be sufficient:
> x <- -(1:100)/10
> y <- 100 + 10 * exp(x / 2) + rnorm(x)/10
> nlmod <- nls(y ~  Const + A * exp(B * x))
Warning message:
In nls(y ~ Const + A * exp(B * x)) :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model
> options(digits = 10) # more accuracy for 'trace'
> try(nlm1 <- update(nlmod, control = list(tol = 1e-7))) # where central diff. work here:
Warning message:
In nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model
>    (nlm2 <- update(nlmod, control = list(tol = 8e-8, nDcentral=TRUE), trace=TRUE))
1017460.306    (4.15e+02): par = (1 1 1)
758164.7503    (2.34e+02): par = (13.42031396 1.961485 0.05947543745)
269506.3538    (3.23e+02): par = (51.75719816 -13.09155957 0.8428607709)
68969.21893    (1.03e+02): par = (76.0006985 -1.935226745 1.0190858)
633.3672230    (1.29e+00): par = (100.3761515 8.624648402 5.104490259)
151.4400218    (9.39e+00): par = (100.6344391 4.913490985 0.2849209569)
53.08739850    (7.24e+00): par = (100.6830407 6.899303317 0.4637755074)
1.344478640    (5.97e-01): par = (100.0368306 9.897714142 0.5169294939)
0.9908415909   (1.55e-02): par = (100.0300625 9.9144191 0.5023516843)
0.9906046057   (1.84e-05): par = (100.0288724 9.916224018 0.5025207336)
0.9906046054   (9.95e-08): par = (100.028875 9.916228366 0.50252165)
0.9906046054   (9.93e-08): par = (100.028875 9.916228366 0.50252165)
Error in nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  : 
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562
In addition: Warning message:
In nls(formula = y ~ Const + A * exp(B * x), algorithm = "default",  :
  No starting values specified for some parameters.
Initializing 'Const', 'A', 'B' to '1.'.
Consider specifying 'start' or using a selfStart model
------------------------------------------------------------

-- 
Andrew Piskorski <atp at piskorski.com>


From brod|e@g@@|@m @end|ng |rom y@hoo@com  Fri Oct  1 18:07:17 2021
From: brod|e@g@@|@m @end|ng |rom y@hoo@com (Brodie Gaslam)
Date: Fri, 1 Oct 2021 16:07:17 +0000 (UTC)
Subject: [Rd] 
 [External] Re: Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
 <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
Message-ID: <19068044.1033359.1633104437752@mail.yahoo.com>

> On Thursday, September 30, 2021, 01:25:02 PM EDT, <luke-tierney at uiowa.edu> wrote:
>
>> On Thu, 30 Sep 2021, brodie gaslam via R-devel wrote:
>>
>> Andr?,
>>
>> I'm not an R core member, but happen to have looked a little bit at this
>> issue myself.? I've seen similar things on Skylake and Coffee Lake 2
>> (9700, one generation past your latest) too.? I think it would make sense
>> to have some handling of this, although I would want to show the trade-off
>> with performance impacts on CPUs that are not affected by this, and on
>> vectors that don't actually have NAs and similar.? I think the performance
>> impact is likely to be small so long as branch prediction is active, but
>> since branch prediction is involved you might need to check with different
>> ratios of NAs (not for your NA bailout branch, but for e.g. interaction
>> of what you add and the existing `na.rm=TRUE` logic).
>
> I would want to see realistic examples where this matters, not
> microbenchmarks, before thinking about complicating the code. Not all
> but most cases where sum(x) returns NaN/NA would eventually result in
> an error; getting to the error faster is not likely to be useful.

That's a very good point, and I'll admit I did not consider it
sufficiently.? There are examples such as `rowSums`/`colSums` where some
rows/columns evaluate to NA thus the result is still contains meaningful
data.? By extension, any loop that applies `sum` to list elements where
some might contain NAs, and others not.? `tapply` or any other group based
aggregation come to mind.

> My understanding is that arm64 does not support proper long doubles
> (they are the same as regular doubles).

Mine is the same.

> So code using long doubles isn't getting the hoped-for improved
> precision. Since that architecture is becoming more common we should
> probably be looking at replacing uses of long doubles with better
> algorithms that can work with regular doubles, e.g Kahan summation or
> variants for sum.

This is probably the bigger issue.? If the future is ARM/AMD, the value of
Intel x87-only optimizations becomes questionable.

More generally is the question of whether to completely replace long
double with algorithmic precision methods, at a cost of performance on
systems that do support hardware long doubles (Intel or otherwise), or
whether both code pathways are kept and selected at compile time.? Or
maybe the aggregation functions gain a low-precision flag for simple
double precision accumulation.

I'm curious to look at the performance and precision implications of e.g.
Kahan summation if no one has done that yet.? Some quick poking around
shows people using processor specific intrinsics to take advantage of
advanced multi-element instructions, but I imagine R would not want to do
that.? Assuming others have not done this already, I will have a look and
report back.

>> Since we're on the topic I want to point out that the default NA in R
>> starts off as a signaling NA:
>>
>>???? example(numToBits)?? # for `bitC`
>>???? bitC(NA_real_)
>>???? ## [1] 0 11111111111 | 0000000000000000000000000000000000000000011110100010
>>???? bitC(NA_real_ + 0)
>>???? ## [1] 0 11111111111 | 1000000000000000000000000000000000000000011110100010
>>
>> Notice the leading bit of the significant starts off as zero, which marks
>> it as a signaling NA, but becomes 1, i.e. non-signaling, after any
>> operation[2].
>>
>> This is meaningful because the mere act of loading a signaling NA into the
>> x87 FPU is sufficient to trigger the slowdowns, even if the NA is not
>> actually used in arithmetic operations.? This happens sometimes under some
>> optimization levels.? I don't now of any benefit of starting off with a
>> signaling NA, especially since the encoding is lost pretty much as soon as
>> it is used.? If folks are interested I can provide patch to turn the NA
>> quiet by default.
>
> In principle this might be a good idea, but the current bit pattern is
> unfortunately baked into a number of packages and documents on
> internals, as well as serialized objects. The work needed to sort that
> out is probably not worth the effort.

One reason why we might not need to sort this out is precisely the
instability shown above.? Anything that relies on the signaling bit set to
a particular value will behave differently with `NA_real_` vs
`NA_real_ + x`.? `R_IsNA` only checks the lower word, so it doesn't care
about the signaling bit or the 19 subsequent ones.? Anything that does
likely has unpredictable behavior **currently**.

Similarly, the documentation[1] only specifies the low word:

> On such platforms NA is represented by the NaN value with low-word 0x7a2
> (1954 in decimal).

This is consistent with the semantics of `R_IsNA`.

> It also doesn't seem to affect the performance issue here since
> setting b[1] <- NA_real_ + 0 produces the same slowdown (at least on
> my current Intel machine).

The subtlety here is that the slowdown happens by merely loading the
signaling NaN onto the X87 FPU.? Consider the following:

??? x <- t(1:1e7+1L)
??? system.time(rowSums(x))
??? ##??? user? system elapsed
??? ##?? 1.685?? 0.007?? 1.693

If we apply the following patch to make NA_REAL quiet:

Index: src/main/arithmetic.c
===================================================================
--- src/main/arithmetic.c?? ?(revision 80996)
+++ src/main/arithmetic.c?? ?(working copy)
@@ -117,7 +117,7 @@
???? /* The gcc shipping with Fedora 9 gets this wrong without
????? * the volatile declaration. Thanks to Marc Schwartz. */
???? volatile ieee_double x;
-??? x.word[hw] = 0x7ff00000;
+??? x.word[hw] = 0x7ff80000;
???? x.word[lw] = 1954;
???? return x.value;
?}

We get a ~25x speedup:

??? x <- t(1:1e7+1L)
??? system.time(rowSums(x))
??? ##??? user? system elapsed
??? ##?? 0.068?? 0.000?? 0.068

This despite no NAs anywhere in sight.? I observe the slow behavior on
both Skylake, Coffee Lake 2 and others, across different OSes, so long as
the -O2 compilation flag is used.

This likely happens because the compiler tries to prepare for the `keepNA`
branch in[1]:

?? ???? case INTSXP:
?? ???? {
?? ??? ?int *ix = INTEGER(x) + (R_xlen_t)n*j;
?? ??? ?for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
?? ??? ???? if (*ix != NA_INTEGER) {cnt++; sum += *ix;}
?? ??? ???? else if (keepNA) {sum = NA_REAL; break;}
?? ??? ?break;
?? ???? }

by loading an NA_REAL into the FPU.? At least that was my interpretation
of the following machine code (dumped from src/main/array.o).? I barely
understand ASM, but it looks like 9bd4 loads R_NaReal, and this happens
before the test for NA at 9be8:

??????????? case LGLSXP:?? # looks like INTSXP/LGLSXP branches collapsed
??????????? {
??????????????? int *ix = LOGICAL(x) + (R_xlen_t)n * j;
??? 9bc8:?????? 4d 01 e3??????????????? add??? r11,r12
??????????????? for (R_xlen_t i = 0; i < n; i++, ra++, ix++)
??? 9bcb:?????? 48 85 db??????????????? test?? rbx,rbx
??? 9bce:?????? 0f 8e fc fe ff ff?????? jle??? 9ad0 <do_colsum+0x260>
??????????????????? if (keepNA) {
??????????????????????? if (*ix != NA_LOGICAL) *ra += *ix;
??????????????????????? else *ra = NA_REAL;
??? 9bd4:?????? dd 05 00 00 00 00?????? fld??? QWORD PTR [rip+0x0]??????? # 9bda <do_colsum+0x36a>
??????????????????????? 9bd6: R_X86_64_PC32???? R_NaReal-0x4
??? 9bda:?????? 48 8b 95 60 ff ff ff??? mov??? rdx,QWORD PTR [rbp-0xa0]
??????????????? for (R_xlen_t i = 0; i < n; i++, ra++, ix++)
??? 9be1:?????? 31 c0?????????????????? xor??? eax,eax
??? 9be3:?????? eb 2c?????????????????? jmp??? 9c11 <do_colsum+0x3a1>
??? 9be5:?????? 0f 1f 00??????????????? nop??? DWORD PTR [rax]
??????????????????????? if (*ix != NA_LOGICAL) *ra += *ix;
??? 9be8:?????? 45 39 d0??????????????? cmp??? r8d,r10d
??? 9beb:?????? 74 5b?????????????????? je???? 9c48 <do_colsum+0x3d8>
??? 9bed:?????? 44 89 85 78 ff ff ff??? mov??? DWORD PTR [rbp-0x88],r8d
??? 9bf4:?????? db 85 78 ff ff ff?????? fild?? DWORD PTR [rbp-0x88]
??? 9bfa:?????? db 2a?????????????????? fld??? TBYTE PTR [rdx]
??? 9bfc:?????? de c1?????????????????? faddp? st(1),st
??? 9bfe:?????? db 3a?????????????????? fstp?? TBYTE PTR [rdx]

... SNIP

??? 9c48:?????? db 3a?????????????????? fstp?? TBYTE PTR [rdx]
??? 9c4a:?????? db 2a?????????????????? fld??? TBYTE PTR [rdx]
??? 9c4c:?????? eb b2?????????????????? jmp??? 9c00 <do_colsum+0x390>

If no NA_LOGICAL (NA_INTEGER) are encountered, the NaN is not used.
However, it is always loaded, and for signaling NaNs this alone appears
to switch the FPU to turtle mode.

But more important than whether I can interpret ASM correctly (dubious),
simply changing the NA_REAL value to be of the quiet variety dramatically
improves performance of `rowSums` with integers.

Ironically, this doesn't happen with the REALSXP branch because that one
relies on NaN propagation in the FPU so doesn't load the NA_REAL for the
early-break case when it encounters one.? Of course if it does encounter a
NaN, quiet or not, we get a slowdown.

Compiling with -O3 also fixes this.

Bad performance of `rowSums` on integers alone is not really that big a
deal given the output is numeric, and that's why I never reported this
despite having known about it for a while.? But Andr?'s e-mail pushed me
into saying something about it.? There is a risk that code relies on the
full bit pattern of NA_REAL, but I think those are probably broken
currently since the signaling bit is even more unstable than the general
payload bits.

Best,

B.

[1]: https://github.com/r-devel/r-svn/blob/6891db49680629427e3d5927053531b8fa5d8ee3/src/main/array.c#L1939
[2]: https://cran.r-project.org/doc/manuals/r-release/R-data.html#Special-values

> Best,
>
> luke
>
>
>>
>> Best,
>>
>> B.
>>
>> [1]: https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/
>> [2]: https://en.wikipedia.org/wiki/NaN#Encoding
>>
>>
>>
>>
>>
>>> On Thursday, September 30, 2021, 06:52:59 AM EDT, GILLIBERT, Andre <andre.gillibert at chu-rouen.fr> wrote:
>>>
>>> Dear R developers,
>>>
>>> By default, R uses the "long double" data type to get extra precision for intermediate computations, with a small performance tradeoff.
>>>
>>> Unfortunately, on all Intel x86 computers I have ever seen, long doubles (implemented in the x87 FPU) are extremely slow whenever a special representation (NA, NaN or infinities) is used; probably because it triggers poorly optimized microcode in the CPU firmware. A function such as sum() becomes more than hundred times slower!
>>> Test code:
>>> a=runif(1e7);system.time(for(i in 1:100)sum(a))
>>> b=a;b[1]=NA;system.time(sum(b))
>>>
>>> The slowdown factors are as follows on a few intel CPU:
>>>
>>> 1)????? Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits : 140 times slower with NA
>>>
>>> 2)????? Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150 times slower with NA
>>>
>>> 3)????? Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130 times slower with NA
>>>
>>> 4)????? Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times slower with NA
>>>
>>> I do not have access to more recent Intel CPUs, but I doubt that it has improved much.
>>>
>>> Recent AMD CPUs have no significant slowdown.
>>> There is no significant slowdown on Intel CPUs (more recent than Sandy Bridge) for 64 bits floating point calculations based on SSE2. Therefore, operators using doubles, such as '+' are unaffected.
>>>
>>> I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe somebody can test.
>>>
>>> Since NAs are not rare in real-life, I think that it would worth an extra check in functions based on long doubles, such as sum(). The check for special representations do not necessarily have to be done at each iteration for cumulative functions.
>>> If you are interested, I can write a bunch of patches to fix the main functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums, matrix multiplication (matprod="internal").
>>>
>>> What do you think of that?
>>>
>>> --
>>> Sincerely
>>> Andr? GILLIBERT
>>>
>>>????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa????????????????? Phone:??????????? 319-335-3386
> Department of Statistics and??????? Fax:????????????? 319-335-3017
>???? Actuarial Science
> 241 Schaeffer Hall????????????????? email:? luke-tierney at uiowa.edu
> Iowa City, IA 52242??????????????? WWW:? http://www.stat.uiowa.edu
>
>


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Fri Oct  1 18:14:57 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Fri, 1 Oct 2021 16:14:57 +0000
Subject: [Rd] 
 [External] Re: Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <CAD4oTHE7MeOYG3MRbHbwHS76HpHj783__ku0GoNQN9iqOvvxUg@mail.gmail.com>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
 <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
 <CAD4oTHE7MeOYG3MRbHbwHS76HpHj783__ku0GoNQN9iqOvvxUg@mail.gmail.com>
Message-ID: <ac7871d0bf6249fa9946e9be5e084679@chu-rouen.fr>


> Mildly related (?) to this discussion, if you happen to be in a situation
> where you know something is a C NAN, but need to check if its a proper R
> NA, the R_IsNA function is surprisingly (to me, at least) expensive to do
> in a tight loop because it calls the (again, surprisingly expensive to me)
> isnan function.  

What is your platform? CPU, OS, compiler?
How much expensive? 5-10 times slower than the improved code you wrote, or 100-200 times slower?

I analyzed the C and assembly source code of R_IsNA on a x86_64 GNU/Linux computer (Celeron J1900) with GCC 5.4 and found that it was somewhat expensive, but the main problems did not seem to come from isnan.

isnan was only responsible of a ucomisd xmm0, xmm0 instruction followed by a conditional jump on x86_64. This instruction is slower on NAN than on normal FP, but it seems to have an acceptable speed.
On x86_32, the isnan is  responsible of a fld mem64, fst mem64, fucomip and conditional jump : it is suboptimal, but things could be worse.

On x86_64, the first problem I noticed is that R_IsNA is not inlined, and the registry-based x86_64 Linux calling convention is not necessarily good for that problem, with added loads/unloads from memory to registry.
Second problem (the worst part) : the write of a 64-bits double followed by the read of a 32-bits integer in the ieee_double union confuses the compiler, that generates very poor code, with unnecessary load/stores.

The second problem can be solved by using a union with a uint64_t and a double fields, and using &0xFFFFFFFF to extract the low part of the uint64_t. This works well for x86_64, but also for x86_32, where GCC avoids useless emulation of 64-bits integers, directly reading the 32-bits integer.

-- 
Sincerely
Andr? GILLIBERT

From pd@|gd @end|ng |rom gm@||@com  Sun Oct  3 18:40:48 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 3 Oct 2021 18:40:48 +0200
Subject: [Rd] R 4.1.2 scheduled for November 1
Message-ID: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>

(Just a quick heads-up for developers.)
 
Full schedule to be made available soon.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Sun Oct  3 18:58:08 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 3 Oct 2021 18:58:08 +0200
Subject: [Rd] R 4.1.2 scheduled for November 1
In-Reply-To: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
References: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
Message-ID: <EE1D7D21-430D-4FF8-BEF8-3B46DBD29B7A@gmail.com>

Schedule should appear on developer.r-project.org when it gets updated from SVN.

> On 3 Oct 2021, at 18:40 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> (Just a quick heads-up for developers.)
> 
> Full schedule to be made available soon.
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk  Wed Oct  6 10:25:37 2021
From: t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk (Tim Taylor)
Date: Wed, 6 Oct 2021 08:25:37 +0000
Subject: [Rd] Request for stopifnot
Message-ID: <LO0P265MB260254C21367AC632873C463DDB09@LO0P265MB2602.GBRP265.PROD.OUTLOOK.COM>

Would R-core be receptive to adding an additional parameter to stopifnot so we can hide the call in the output as in stop?

i.e. The signature would become:
stopifnot2 <- function (..., exprs, exprObject, local = TRUE, .call = TRUE)

It looks like this would be a one-line change to the the underlying stop call to:
stop(simpleError(msg, call = if((p <- sys.parent(1L)) && isTRUE(.call)) sys.call(p)))

Best

Tim

From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Oct  6 11:07:47 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 6 Oct 2021 11:07:47 +0200
Subject: [Rd] 
 [External] Re: Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <19068044.1033359.1633104437752@mail.yahoo.com>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
 <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
 <19068044.1033359.1633104437752@mail.yahoo.com>
Message-ID: <25ce3992-23d2-9cc4-e989-b83ef2732efc@gmail.com>


On 10/1/21 6:07 PM, Brodie Gaslam via R-devel wrote:
>> On Thursday, September 30, 2021, 01:25:02 PM EDT, <luke-tierney at uiowa.edu> wrote:
>>
>>> On Thu, 30 Sep 2021, brodie gaslam via R-devel wrote:
>>>
>>> Andr?,
>>>
>>> I'm not an R core member, but happen to have looked a little bit at this
>>> issue myself.? I've seen similar things on Skylake and Coffee Lake 2
>>> (9700, one generation past your latest) too.? I think it would make sense
>>> to have some handling of this, although I would want to show the trade-off
>>> with performance impacts on CPUs that are not affected by this, and on
>>> vectors that don't actually have NAs and similar.? I think the performance
>>> impact is likely to be small so long as branch prediction is active, but
>>> since branch prediction is involved you might need to check with different
>>> ratios of NAs (not for your NA bailout branch, but for e.g. interaction
>>> of what you add and the existing `na.rm=TRUE` logic).
>> I would want to see realistic examples where this matters, not
>> microbenchmarks, before thinking about complicating the code. Not all
>> but most cases where sum(x) returns NaN/NA would eventually result in
>> an error; getting to the error faster is not likely to be useful.
> That's a very good point, and I'll admit I did not consider it
> sufficiently.? There are examples such as `rowSums`/`colSums` where some
> rows/columns evaluate to NA thus the result is still contains meaningful
> data.? By extension, any loop that applies `sum` to list elements where
> some might contain NAs, and others not.? `tapply` or any other group based
> aggregation come to mind.
>
>> My understanding is that arm64 does not support proper long doubles
>> (they are the same as regular doubles).
> Mine is the same.

Then there are issues with that "long double" (where not equivalent to 
"double") is implemented differently on different platforms, providing 
different properties. We have ran into that on Power, where "long 
double" it is implemented using a sum of doubles ("double-double"). If 
we could rely just on "double", we would not have to worry about such 
things.

>> So code using long doubles isn't getting the hoped-for improved
>> precision. Since that architecture is becoming more common we should
>> probably be looking at replacing uses of long doubles with better
>> algorithms that can work with regular doubles, e.g Kahan summation or
>> variants for sum.
> This is probably the bigger issue.? If the future is ARM/AMD, the value of
> Intel x87-only optimizations becomes questionable.
>
> More generally is the question of whether to completely replace long
> double with algorithmic precision methods, at a cost of performance on
> systems that do support hardware long doubles (Intel or otherwise), or
> whether both code pathways are kept and selected at compile time.? Or
> maybe the aggregation functions gain a low-precision flag for simple
> double precision accumulation.
>
> I'm curious to look at the performance and precision implications of e.g.
> Kahan summation if no one has done that yet.? Some quick poking around
> shows people using processor specific intrinsics to take advantage of
> advanced multi-element instructions, but I imagine R would not want to do
> that.? Assuming others have not done this already, I will have a look and
> report back.

Processor-specific (or even compiler-specific) code is better avoided, 
but sometimes it is possible to write portable code that is tailored to 
run fast on common platforms, while still working correctly with 
acceptable performance on other.

Sometimes one can give hints to the compiler via OpenMP pragmas to 
vectorize code and/or use vectorized instructions, e.g. when it is ok to 
ignore some specific corner cases (R uses this in mayHaveNaNOrInf to 
tell the compiler it is ok to assume associativity of addition in a 
specific loop/variable, hence allowing it to vectorize better).

>>> Since we're on the topic I want to point out that the default NA in R
>>> starts off as a signaling NA:
>>>
>>>  ???? example(numToBits)?? # for `bitC`
>>>  ???? bitC(NA_real_)
>>>  ???? ## [1] 0 11111111111 | 0000000000000000000000000000000000000000011110100010
>>>  ???? bitC(NA_real_ + 0)
>>>  ???? ## [1] 0 11111111111 | 1000000000000000000000000000000000000000011110100010
>>>
>>> Notice the leading bit of the significant starts off as zero, which marks
>>> it as a signaling NA, but becomes 1, i.e. non-signaling, after any
>>> operation[2].
>>>
>>> This is meaningful because the mere act of loading a signaling NA into the
>>> x87 FPU is sufficient to trigger the slowdowns, even if the NA is not
>>> actually used in arithmetic operations.? This happens sometimes under some
>>> optimization levels.? I don't now of any benefit of starting off with a
>>> signaling NA, especially since the encoding is lost pretty much as soon as
>>> it is used.? If folks are interested I can provide patch to turn the NA
>>> quiet by default.
>> In principle this might be a good idea, but the current bit pattern is
>> unfortunately baked into a number of packages and documents on
>> internals, as well as serialized objects. The work needed to sort that
>> out is probably not worth the effort.
> One reason why we might not need to sort this out is precisely the
> instability shown above.? Anything that relies on the signaling bit set to
> a particular value will behave differently with `NA_real_` vs
> `NA_real_ + x`.? `R_IsNA` only checks the lower word, so it doesn't care
> about the signaling bit or the 19 subsequent ones.? Anything that does
> likely has unpredictable behavior **currently**.
>
> Similarly, the documentation[1] only specifies the low word:
>
>> On such platforms NA is represented by the NaN value with low-word 0x7a2
>> (1954 in decimal).
> This is consistent with the semantics of `R_IsNA`.

The signalling vs non-signalling bit may also impact propagation of the 
NaN payload on some platforms. Some non-portable code could be looking 
at all the bits. Changing the representation based on performance issues 
in a specific processor may not be the right thing to do in principle. 
There would have to be a strong benefit of the change to outweigh these 
risks.

>> It also doesn't seem to affect the performance issue here since
>> setting b[1] <- NA_real_ + 0 produces the same slowdown (at least on
>> my current Intel machine).
> The subtlety here is that the slowdown happens by merely loading the
> signaling NaN onto the X87 FPU.? Consider the following:
>
>  ??? x <- t(1:1e7+1L)
>  ??? system.time(rowSums(x))
>  ??? ##??? user? system elapsed
>  ??? ##?? 1.685?? 0.007?? 1.693
>
> If we apply the following patch to make NA_REAL quiet:
>
> Index: src/main/arithmetic.c
> ===================================================================
> --- src/main/arithmetic.c?? ?(revision 80996)
> +++ src/main/arithmetic.c?? ?(working copy)
> @@ -117,7 +117,7 @@
>  ???? /* The gcc shipping with Fedora 9 gets this wrong without
>  ????? * the volatile declaration. Thanks to Marc Schwartz. */
>  ???? volatile ieee_double x;
> -??? x.word[hw] = 0x7ff00000;
> +??? x.word[hw] = 0x7ff80000;
>  ???? x.word[lw] = 1954;
>  ???? return x.value;
>  ?}
>
> We get a ~25x speedup:
>
>  ??? x <- t(1:1e7+1L)
>  ??? system.time(rowSums(x))
>  ??? ##??? user? system elapsed
>  ??? ##?? 0.068?? 0.000?? 0.068
>
> This despite no NAs anywhere in sight.? I observe the slow behavior on
> both Skylake, Coffee Lake 2 and others, across different OSes, so long as
> the -O2 compilation flag is used.
>
> This likely happens because the compiler tries to prepare for the `keepNA`
> branch in[1]:
>
>  ?? ???? case INTSXP:
>  ?? ???? {
>  ?? ??? ?int *ix = INTEGER(x) + (R_xlen_t)n*j;
>  ?? ??? ?for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
>  ?? ??? ???? if (*ix != NA_INTEGER) {cnt++; sum += *ix;}
>  ?? ??? ???? else if (keepNA) {sum = NA_REAL; break;}
>  ?? ??? ?break;
>  ?? ???? }
>
> by loading an NA_REAL into the FPU.? At least that was my interpretation
> of the following machine code (dumped from src/main/array.o).? I barely
> understand ASM, but it looks like 9bd4 loads R_NaReal, and this happens
> before the test for NA at 9be8:
>
>  ??????????? case LGLSXP:?? # looks like INTSXP/LGLSXP branches collapsed
>  ??????????? {
>  ??????????????? int *ix = LOGICAL(x) + (R_xlen_t)n * j;
>  ??? 9bc8:?????? 4d 01 e3??????????????? add??? r11,r12
>  ??????????????? for (R_xlen_t i = 0; i < n; i++, ra++, ix++)
>  ??? 9bcb:?????? 48 85 db??????????????? test?? rbx,rbx
>  ??? 9bce:?????? 0f 8e fc fe ff ff?????? jle??? 9ad0 <do_colsum+0x260>
>  ??????????????????? if (keepNA) {
>  ??????????????????????? if (*ix != NA_LOGICAL) *ra += *ix;
>  ??????????????????????? else *ra = NA_REAL;
>  ??? 9bd4:?????? dd 05 00 00 00 00?????? fld??? QWORD PTR [rip+0x0]??????? # 9bda <do_colsum+0x36a>
>  ??????????????????????? 9bd6: R_X86_64_PC32???? R_NaReal-0x4
>  ??? 9bda:?????? 48 8b 95 60 ff ff ff??? mov??? rdx,QWORD PTR [rbp-0xa0]
>  ??????????????? for (R_xlen_t i = 0; i < n; i++, ra++, ix++)
>  ??? 9be1:?????? 31 c0?????????????????? xor??? eax,eax
>  ??? 9be3:?????? eb 2c?????????????????? jmp??? 9c11 <do_colsum+0x3a1>
>  ??? 9be5:?????? 0f 1f 00??????????????? nop??? DWORD PTR [rax]
>  ??????????????????????? if (*ix != NA_LOGICAL) *ra += *ix;
>  ??? 9be8:?????? 45 39 d0??????????????? cmp??? r8d,r10d
>  ??? 9beb:?????? 74 5b?????????????????? je???? 9c48 <do_colsum+0x3d8>
>  ??? 9bed:?????? 44 89 85 78 ff ff ff??? mov??? DWORD PTR [rbp-0x88],r8d
>  ??? 9bf4:?????? db 85 78 ff ff ff?????? fild?? DWORD PTR [rbp-0x88]
>  ??? 9bfa:?????? db 2a?????????????????? fld??? TBYTE PTR [rdx]
>  ??? 9bfc:?????? de c1?????????????????? faddp? st(1),st
>  ??? 9bfe:?????? db 3a?????????????????? fstp?? TBYTE PTR [rdx]
>
> ... SNIP
>
>  ??? 9c48:?????? db 3a?????????????????? fstp?? TBYTE PTR [rdx]
>  ??? 9c4a:?????? db 2a?????????????????? fld??? TBYTE PTR [rdx]
>  ??? 9c4c:?????? eb b2?????????????????? jmp??? 9c00 <do_colsum+0x390>
>
> If no NA_LOGICAL (NA_INTEGER) are encountered, the NaN is not used.
> However, it is always loaded, and for signaling NaNs this alone appears
> to switch the FPU to turtle mode.
>
> But more important than whether I can interpret ASM correctly (dubious),
> simply changing the NA_REAL value to be of the quiet variety dramatically
> improves performance of `rowSums` with integers.
>
> Ironically, this doesn't happen with the REALSXP branch because that one
> relies on NaN propagation in the FPU so doesn't load the NA_REAL for the
> early-break case when it encounters one.? Of course if it does encounter a
> NaN, quiet or not, we get a slowdown.
>
> Compiling with -O3 also fixes this.

In general it is very difficult to tell performance from the assembly, 
because a lot of optimizations happen at the hardware level, but except 
from compiler experts who understand concrete processors in details, one 
can make guesses and based on them come up with performance 
improvements. If your guess is right about the reason for the slowdown, 
there should be a way to suggest a small change to the C code, along the 
lines of what -O3 does, so that the compiler (recent version of GCC) 
would produce code which doesn't load the value eagerly and runs faster.

> Bad performance of `rowSums` on integers alone is not really that big a
> deal given the output is numeric, and that's why I never reported this
> despite having known about it for a while.? But Andr?'s e-mail pushed me
> into saying something about it.? There is a risk that code relies on the
> full bit pattern of NA_REAL, but I think those are probably broken
> currently since the signaling bit is even more unstable than the general
> payload bits.

Yes, the signalling bit is often lost sooner than the payload.

Best
Tomas

>
> Best,
>
> B.
>
> [1]: https://github.com/r-devel/r-svn/blob/6891db49680629427e3d5927053531b8fa5d8ee3/src/main/array.c#L1939
> [2]: https://cran.r-project.org/doc/manuals/r-release/R-data.html#Special-values
>
>> Best,
>>
>> luke
>>
>>
>>> Best,
>>>
>>> B.
>>>
>>> [1]: https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/
>>> [2]: https://en.wikipedia.org/wiki/NaN#Encoding
>>>
>>>
>>>
>>>
>>>
>>>> On Thursday, September 30, 2021, 06:52:59 AM EDT, GILLIBERT, Andre <andre.gillibert at chu-rouen.fr> wrote:
>>>>
>>>> Dear R developers,
>>>>
>>>> By default, R uses the "long double" data type to get extra precision for intermediate computations, with a small performance tradeoff.
>>>>
>>>> Unfortunately, on all Intel x86 computers I have ever seen, long doubles (implemented in the x87 FPU) are extremely slow whenever a special representation (NA, NaN or infinities) is used; probably because it triggers poorly optimized microcode in the CPU firmware. A function such as sum() becomes more than hundred times slower!
>>>> Test code:
>>>> a=runif(1e7);system.time(for(i in 1:100)sum(a))
>>>> b=a;b[1]=NA;system.time(sum(b))
>>>>
>>>> The slowdown factors are as follows on a few intel CPU:
>>>>
>>>> 1)????? Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits : 140 times slower with NA
>>>>
>>>> 2)????? Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150 times slower with NA
>>>>
>>>> 3)????? Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130 times slower with NA
>>>>
>>>> 4)????? Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times slower with NA
>>>>
>>>> I do not have access to more recent Intel CPUs, but I doubt that it has improved much.
>>>>
>>>> Recent AMD CPUs have no significant slowdown.
>>>> There is no significant slowdown on Intel CPUs (more recent than Sandy Bridge) for 64 bits floating point calculations based on SSE2. Therefore, operators using doubles, such as '+' are unaffected.
>>>>
>>>> I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe somebody can test.
>>>>
>>>> Since NAs are not rare in real-life, I think that it would worth an extra check in functions based on long doubles, such as sum(). The check for special representations do not necessarily have to be done at each iteration for cumulative functions.
>>>> If you are interested, I can write a bunch of patches to fix the main functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums, matrix multiplication (matprod="internal").
>>>>
>>>> What do you think of that?
>>>>
>>>> --
>>>> Sincerely
>>>> Andr? GILLIBERT
>>>>
>>>>  ????? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa????????????????? Phone:??????????? 319-335-3386
>> Department of Statistics and??????? Fax:????????????? 319-335-3017
>>  ???? Actuarial Science
>> 241 Schaeffer Hall????????????????? email:? luke-tierney at uiowa.edu
>> Iowa City, IA 52242??????????????? WWW:? http://www.stat.uiowa.edu
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From r-deve| @end|ng |rom @ker@t|ng@de  Thu Oct  7 09:26:08 2021
From: r-deve| @end|ng |rom @ker@t|ng@de (Andreas Kersting)
Date: Thu, 07 Oct 2021 09:26:08 +0200 (CEST)
Subject: [Rd] GC: parallelizing the CHARSXP cache maintenance
Message-ID: <E1mYNn6-0000cv-1M@rmmprod05.runbox>

Hi all,

As part of RunGenCollect() (in src/main/memory.c), some maintenance on the CHARSXP cache is done, namely unmarked nodes/CHARSXPs are removed from the hash chains. This requires always touching all CHARSXP in the cache, irrespective of the number of generations which were just garbage collected. In a session with a big CHARSXP cache, this will significantly slow down gc also when just collecting the youngest generation.

However, this part of RunGenCollect() seems to be one of the few which can easily be parallelized without the need for thread synchronization. And it seems to be the one most profiting from parallelization.

Attached patch (?parallel_CHARSXP_cache.diff) implements parallelization over the elements of R_StringHash and gives the following performance improvements on my system when using 4 threads compared to R devel (revision 81008):

Elapsed time for 200 non-full gc in a session after

x <- as.character(runif(1e6))[]
gc(full = TRUE)

8sec -> 2.5sec.

AND

Elapsed time for five non-full gc in a session after

x <- as.character(runif(5e7))[]
gc(full = TRUE)

21sec -> 6sec.

In the patch, I dropped the two lines 

FORWARD_NODE(s);
FORWARD_NODE(CXHEAD(s));

because they are currently both no-ops (and would require synchronization if they were not). They are no-ops because we have

?# define CXHEAD(x) (x)  // in Defn.h

and hence FORWARD_NODE(s)/FORWARD_NODE(CXHEAD(s)) is only called when s is already marked, in which case FORWARD_NODE() does nothing.

I used OpenMP despite the known issues of some of its implementations with hanging after a fork, mostly because it was the easiest thing to do for a PoC. I worked around this similar to e.g. data.table by using only one thread in forked children.

It might be worth considering making the parallelization conditional on the size of the CHARSXP cache and use only the main thread if the cache is (still) small.

In the second attached patch (parallel_CHARSXP_cache_no_forward.diff) I additionally no longer call FORWARD_NODE(R_StringHash) because this will make the following call to PROCESS_NODES() iterate through all elements of R_StringHash again which is unnecessary since all elements are either R_NilValue or an already marked CHARSXP. I rather directly mark & snap R_StringHash. In contrast to the parallelization, this only affects full gcs since R_StringHash will quickly belong to the oldest generation.

Attached gc_test.R is the script I used to get the previously mentioned and more gc timings.

To me this looks like a significant performance improvement, especially given the little changeset. What do you think?

Best regards,
Andreas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: parallel_CHARSXP_cache.diff
Type: text/x-patch
Size: 2424 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20211007/34bed55c/attachment.bin>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: parallel_CHARSXP_cache_no_forward.diff
Type: text/x-patch
Size: 3185 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20211007/34bed55c/attachment-0001.bin>

From r-deve| @end|ng |rom @ker@t|ng@de  Thu Oct  7 09:33:42 2021
From: r-deve| @end|ng |rom @ker@t|ng@de (Andreas Kersting)
Date: Thu, 07 Oct 2021 09:33:42 +0200 (CEST)
Subject: [Rd] GC: improving the marking performance for STRSXPs
Message-ID: <E1mYNuQ-0001Al-8B@rmmprod05.runbox>

Hi all,

in GC (in src/main/memory.c), FORWARD_CHILDREN() (called by PROCESS_NODES()) treats STRSXPs just like VECSXPs, i.e. it calls FORWARD_NODE() for all its children. I claim that this is unnecessarily inefficient since the children of a STRSXP can legitimately only be (atomic) CHARSXPs and could hence be marked directly in the call of FORWARD_CHILDREN() on the STRSXP.

Attached patch (?atomic_CHARSXP.diff) implements this and gives the following performance improvements on my system compared to R devel (revision 81008):

Elapsed time for two full gc in a session after

x <- as.character(runif(5e7))[]

19sec -> 15sec.

This is the best-case scenario for the patch: very many unique/unmarked CHARSXP in the STRSXP. For already marked CHARSXP there is no performance gain since FORWARD_NODE() is a no-op for them.

The relative performance gain is even bigger if iterating through the STRSXP produces many cache misses, as e.g. after

x <- as.character(runif(5e7))[]
x <- sample(x, length(x))

Elapsed time for two full gc here: 83sec -> 52sec. This is because we have less cache misses per CHARSXP.

This patch additionally also assumes that the ATTRIBs of a CHARSXP are not to be traced because they are just used for maintaining the CHARSXP hash chains.

The second attached patch (?atomic_CHARSXP_safe_unlikely.diff) checks both assumptions and calls gc_error() if they are violated and is still noticeably faster than R devel: 19sec -> 17sec and 83sec -> 54sec, respectively.

Attached gc_test.R is the script I used to get the previously mentioned and more gc timings.

Do you think that this is a reasonable change? It does make the code more complex and I am not sure if there might be situations in which the assumptions are violated, even though ?SET_STRING_ELT() and ?installAttrib() do enforce them.

Best regards,
Andreas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: atomic_CHARSXP.diff
Type: text/x-patch
Size: 1948 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20211007/f018a189/attachment.bin>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: atomic_CHARSXP_safe_unlikely.diff
Type: text/x-patch
Size: 2427 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20211007/f018a189/attachment-0001.bin>

From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sat Oct  9 04:40:10 2021
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sat, 9 Oct 2021 02:40:10 +0000 (UTC)
Subject: [Rd] formatC(<zero-length>) doesn't keep attributes
References: <1932751023.1279015.1633747210908.ref@mail.yahoo.com>
Message-ID: <1932751023.1279015.1633747210908@mail.yahoo.com>

By r80949, 'formatC' code in R devel has
? ? if (!(n <- length(x))) return(character())

If 'x' has length zero, the return value of 'formatC' doesn't have attributes. It doesn't follow the documented "Value": "A character object of the same size and attributes as x".

Based on my observation, the early return could be removed.
    n <- length(x)


From georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk  Sat Oct  9 10:33:16 2021
From: georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk (Georgi Boshnakov)
Date: Sat, 9 Oct 2021 08:33:16 +0000
Subject: [Rd] =?utf-8?q?Bug_18208_-_tools=3A=3A=3AlatexToUtf8=28tools=3A?=
 =?utf-8?b?OnBhcnNlTGF0ZXgoIlxcJ2kiKSkgc2hvdWxkIGdlbmVyYXRlIMOt?=
In-Reply-To: <CAOsPdQKA=JTEYBrZv9m_AmJ5o+MrrvJ=13j8hETU+M_FMyYhxw@mail.gmail.com>
References: <CAOsPdQKA=JTEYBrZv9m_AmJ5o+MrrvJ=13j8hETU+M_FMyYhxw@mail.gmail.com>
Message-ID: <LOYP265MB2015180ED8689A4175D97255AEB39@LOYP265MB2015.GBRP265.PROD.OUTLOOK.COM>

tools:::latexToUtf8() doesn't convert the LaTeX accented character "\\'i<file://'i>" to  ? (see Bug #18208 https://bugs.r-project.org/show_bug.cgi?id=18208,  reported by Manuel L?pez-Ib??ez for details and justification). For example:

> tools:::latexToUtf8(tools::parseLatex("\\'i<file://'i>"))
\'i

It does the conversion if i is replaced by '\i':

> tools:::latexToUtf8(tools::parseLatex("\\'\\i<file://'//i>"))
?

Both are acceptable in LaTeX.

I think that this can be fixed by adding a line to the definition of makeLatexTable() in R/src/library/tools/R/parseLatex.R, just before it returns:

makeLatexTable <- function(utf8table)
{
    ...

    table[["\\textemdash<file://textemdash>"]] <- "\u2014"
    latexArgCount[["\\textemdash<file://textemdash>"]] <<- 0

    table$"\\'"$"i"  <- table$"\\'"$"\\i<file://i>"    # Georgi

    table
}

I can submit a patch if I get access  to bugzilla.

After building R-devel svn 81022 from 2021-10-08 with the above change, we get what we want:

> tools:::latexToUtf8(tools::parseLatex("\\'i<file://'i>"))
?
> tools:::latexToUtf8(tools::parseLatex("\\'\\i<file://'//i>"))
?
Georgi Boshnakov





	[[alternative HTML version deleted]]


From georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk  Sat Oct  9 12:43:39 2021
From: georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk (Georgi Boshnakov)
Date: Sat, 9 Oct 2021 10:43:39 +0000
Subject: [Rd] 
 =?utf-8?q?Bug_18208_-_tools=3A=3A=3AlatexToUtf8=28tools=3A?=
 =?utf-8?b?OnBhcnNlTGF0ZXgoIlxcJ2kiKSkgc2hvdWxkIGdlbmVyYXRlIMOt?=
In-Reply-To: <CAOsPdQKA=JTEYBrZv9m_AmJ5o+MrrvJ=13j8hETU+M_FMyYhxw@mail.gmail.com>
References: <CAOsPdQKA=JTEYBrZv9m_AmJ5o+MrrvJ=13j8hETU+M_FMyYhxw@mail.gmail.com>
Message-ID: <LOYP265MB2015D0C2F691C9197A530688AEB39@LOYP265MB2015.GBRP265.PROD.OUTLOOK.COM>

Resending this as the original message went out as html and the special characters got garbled.

tools:::latexToUtf8() doesn't convert the LaTeX accented character "\\'i" to? ? (see Bug #18208 https://bugs.r-project.org/show_bug.cgi?id=18208,? reported by Manuel L?pez-Ib??ez for details and justification). For example:

> tools:::latexToUtf8(tools::parseLatex("\\'i"))
\'i 

It does the conversion if i is replaced by '\i':

> tools:::latexToUtf8(tools::parseLatex("file:\\'\\i"))
? 


I think that this can be fixed by adding a line to the definition of makeLatexTable() in R/src/library/tools/R/parseLatex.R, just before it returns: 

makeLatexTable <- function(utf8table)
{
??? ...

? ? table[["file://textemdash"]] <- "\u2014"
? ? latexArgCount[["file://textemdash"]] <<- 0

? ? table$"\\'"$"i" ?<- table$"\\'"$"\\i" ?? # Georgi

? ? table
}

I can submit a patch if I get access? to bugzilla.

After building R-devel svn 81022 from 2021-10-08 with the above change, we get what we want:

> tools:::latexToUtf8(tools::parseLatex("\\'i"))
? 
> tools:::latexToUtf8(tools::parseLatex("\\'\\i"))
? 

Georgi Boshnakov

From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Sun Oct 10 13:56:00 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Sun, 10 Oct 2021 11:56:00 +0000
Subject: [Rd] Potential bugs in table dnn
Message-ID: <1633866959731.85310@ap-hm.fr>

Dear list,

table does not set dnn for dataframes of length 1:

table(warpbreaks[2:3]) # has dnn
#     tension
# wool L M H
#    A 9 9 9
#    B 9 9 9

table(warpbreaks[2]) # has no dnn
# 
#  A  B 
# 27 27 

This is because of if (length(dnn) != length(args)) (line 53 in https://github.com/wch/r-source/blob/trunk/src/library/base/R/table.R). When commenting this line or modifying it to if (length(dnn) != length(args) || dnn == ""), dnn are set as expected:

table2(warpbreaks[2:3]) # has dnn
#     tension
# wool L M H
#    A 9 9 9
#    B 9 9 9

table2(warpbreaks[2]) # has dnn
# wool
#  A  B 
# 27 27 

However, I do not get the logic for the initial if (length(dnn) != length(args)), so the change may break something else...

In addition, table documentation says "If the argument dnn is not supplied, the internal function list.names is called to compute the ?dimname names?. If the arguments in ... are named, those names are used." Some cases seem inconsistent or may return a warning:

table(warpbreaks[2], dnn = letters) # no warning/not as documented
# wool
#  A  B 
# 27 27 

table(warpbreaks[2], dnn = letters[1]) # as documented
# a
#  A  B 
# 27 27 

table(zzz = warpbreaks[2], dnn = letters[1]) # as documented
# a
#  A  B 
# 27 27 

table(zzz = warpbreaks$wool, dnn = letters[1]) # as documented
# a
#  A  B 
# 27 27 

table(warpbreaks$wool, dnn = letters) # as expected
# Error in names(dn) <- dnn : 
#   attribut 'names' [26] doit ?tre de m?me longueur que le vecteur [1]

Best regards,

Thomas

From tr@ver@c @end|ng |rom gm@||@com  Mon Oct 11 07:05:49 2021
From: tr@ver@c @end|ng |rom gm@||@com (Travers Ching)
Date: Sun, 10 Oct 2021 22:05:49 -0700
Subject: [Rd] Crash/bug when calling match on latin1 strings
Message-ID: <CAPLMX9FKNS2Hf9BNcArWL_GrEkggxOd04-b+rfHtEAceCpH9dA@mail.gmail.com>

Here's a brief example:

# A bunch of words in UTF8; replace *'s
words <- readLines("h****://pastebin.c**/raw/MFCQfhpY", encoding = "UTF-8")
words2 <- iconv(words, "utf-8", "latin1")
gctorture(TRUE)
y <- match(words2, words2)
<The program crashes / segfaults ~90% of the time>

I searched bugzilla but didn't see anything. Apologies if this is already
reported.

The bug appears in both R-devel and the release, but doesn't seem to affect
R 4.0.5.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 11 08:41:51 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 11 Oct 2021 07:41:51 +0100
Subject: [Rd] Crash/bug when calling match on latin1 strings
In-Reply-To: <CAPLMX9FKNS2Hf9BNcArWL_GrEkggxOd04-b+rfHtEAceCpH9dA@mail.gmail.com>
References: <CAPLMX9FKNS2Hf9BNcArWL_GrEkggxOd04-b+rfHtEAceCpH9dA@mail.gmail.com>
Message-ID: <7bdc35a6-b3c1-88b7-8e82-61d4b5f4ae7a@sapo.pt>

Hello,

R 4.1.1 on Ubuntu 20.04.

I can reproduce this error but not ~90% of the time, only the 1st time I 
run the script.
If I run other (terminal) commands before rerunning the R script it 
sometimes segfaults again but once again very far from 90% of the time.


rui at rui:~/tmp$ R -q -f rhelp.R
 > sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.1.1
 >
 > # A bunch of words in UTF8; replace *'s
 > words <- readLines("h****://pastebin.c**/raw/MFCQfhpY", encoding = 
"UTF-8")
 > words2 <- iconv(words, "utf-8", "latin1")
 > gctorture(TRUE)
 > y <- match(words2, words2)

  *** caught segfault ***
address 0x10, cause 'memory not mapped'
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation
*** recursive gc invocation

Traceback:
  1: match(words2, words2)
An irrecoverable exception occurred. R is aborting now ...
Falta de segmenta??o (n?cleo despejado)



This last line is Portuguese for

Segmentation fault (core dumped)

Hope this helps,

Rui Barradas


?s 06:05 de 11/10/21, Travers Ching escreveu:
> Here's a brief example:
> 
> # A bunch of words in UTF8; replace *'s
> words <- readLines("h****://pastebin.c**/raw/MFCQfhpY", encoding = "UTF-8")
> words2 <- iconv(words, "utf-8", "latin1")
> gctorture(TRUE)
> y <- match(words2, words2)
> <The program crashes / segfaults ~90% of the time>
> 
> I searched bugzilla but didn't see anything. Apologies if this is already
> reported.
> 
> The bug appears in both R-devel and the release, but doesn't seem to affect
> R 4.0.5.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Oct 11 11:31:53 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 11 Oct 2021 11:31:53 +0200
Subject: [Rd] Crash/bug when calling match on latin1 strings
In-Reply-To: <7bdc35a6-b3c1-88b7-8e82-61d4b5f4ae7a@sapo.pt>
References: <CAPLMX9FKNS2Hf9BNcArWL_GrEkggxOd04-b+rfHtEAceCpH9dA@mail.gmail.com>
 <7bdc35a6-b3c1-88b7-8e82-61d4b5f4ae7a@sapo.pt>
Message-ID: <24932.1161.878644.458922@stat.math.ethz.ch>

>>>>> Rui Barradas 
>>>>>     on Mon, 11 Oct 2021 07:41:51 +0100 writes:

    > Hello,

    > R 4.1.1 on Ubuntu 20.04.

    > I can reproduce this error but not ~90% of the time, only the 1st time I 
    > run the script.
    > If I run other (terminal) commands before rerunning the R script it 
    > sometimes segfaults again but once again very far from 90% of the time.


    > rui at rui:~/tmp$ R -q -f rhelp.R
    >> sessionInfo()
    > R version 4.1.1 (2021-08-10)
    > Platform: x86_64-pc-linux-gnu (64-bit)
    > Running under: Ubuntu 20.04.3 LTS

    > Matrix products: default
    > BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
    > LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

    > locale:
    > [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
    > [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
    > [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
    > [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
    > [9] LC_ADDRESS=C               LC_TELEPHONE=C
    > [11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > loaded via a namespace (and not attached):
    > [1] compiler_4.1.1
    >> 
    >> # A bunch of words in UTF8; replace *'s
    >> words <- readLines("h****://pastebin.c**/raw/MFCQfhpY", encoding = 
    > "UTF-8")
    >> words2 <- iconv(words, "utf-8", "latin1")
    >> gctorture(TRUE)
    >> y <- match(words2, words2)

    > *** caught segfault ***
    > address 0x10, cause 'memory not mapped'
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation
    > *** recursive gc invocation

    > Traceback:
    > 1: match(words2, words2)
    > An irrecoverable exception occurred. R is aborting now ...
    > Falta de segmenta??o (n?cleo despejado)



    > This last line is Portuguese for

    > Segmentation fault (core dumped)

    > Hope this helps,

Yes, it does, thank you!

I can confirm the problem:  Only in R 4.1.0 and newer, and
including current "R-patched" and "R-devel" versions.

I've now turned this into a formal R bug report on R's bugzilla,
and (slightly) extended your (Travers') example into self
contained (no internet access) R script.

Bugzilla PR#18211 :    " match(<latin1>) memory corruption "

  https://bugs.r-project.org/show_bug.cgi?id=18211

  with attachment 2929
  --> https://bugs.r-project.org/attachment.cgi?id=2929&action=edit

==> please if possible follow up on bugzilla

Thanks again to you both!
Martin Maechler


    > Rui Barradas

    > ?s 06:05 de 11/10/21, Travers Ching escreveu:
    >> Here's a brief example:
    >> 
    >> # A bunch of words in UTF8; replace *'s
    >> words <- readLines("h****://pastebin.c**/raw/MFCQfhpY", encoding = "UTF-8")
    >> words2 <- iconv(words, "utf-8", "latin1")
    >> gctorture(TRUE)
    >> y <- match(words2, words2)
    >> <The program crashes / segfaults ~90% of the time>
    >> 
    >> I searched bugzilla but didn't see anything. Apologies if this is already
    >> reported.
    >> 
    >> The bug appears in both R-devel and the release, but doesn't seem to affect
    >> R 4.0.5.


From z@|er@b@rutcuog|u @end|ng |rom gm@||@com  Tue Oct 12 08:04:40 2021
From: z@|er@b@rutcuog|u @end|ng |rom gm@||@com (Zafer Barutcuoglu)
Date: Tue, 12 Oct 2021 02:04:40 -0400
Subject: [Rd] int overflow writing long vectors to socketConnection
Message-ID: <0E317F6A-E81C-47E5-9388-F14A8F392B87@gmail.com>

Hi,

Writing >=2GB to a socketConnection (e.g. via writeBin) does not work correctly, because of this int typecast in modules/internet/sockconn.c:
> static size_t sock_write(const void *ptr, size_t size, size_t nitems,
> 			 Rconnection con)
> {
>     Rsockconn this = (Rsockconn)con->private;
>     ssize_t n = R_SockWrite(this->fd, ptr, (int)(size * nitems),
> 			    this->timeout)/((ssize_t)size);
>     return n > 0 ? n : 0;
> }
which seems uncalled for, given:
> ssize_t R_SockWrite(int sockp, const void *buf, size_t len, int timeout)


Is there a rationale for it, or should it be fixed?

Best,
--
Zafer


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 12 11:34:59 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 12 Oct 2021 11:34:59 +0200
Subject: [Rd] int overflow writing long vectors to socketConnection
In-Reply-To: <0E317F6A-E81C-47E5-9388-F14A8F392B87@gmail.com>
References: <0E317F6A-E81C-47E5-9388-F14A8F392B87@gmail.com>
Message-ID: <24933.22211.780123.250926@stat.math.ethz.ch>

>>>>> Zafer Barutcuoglu 
>>>>>     on Tue, 12 Oct 2021 02:04:40 -0400 writes:

    > Hi,

    > Writing >=2GB to a socketConnection (e.g. via writeBin) does not work correctly, because of this int typecast in modules/internet/sockconn.c:
    >> static size_t sock_write(const void *ptr, size_t size, size_t nitems,
    >> Rconnection con)
    >> {
    >> Rsockconn this = (Rsockconn)con->private;
    >> ssize_t n = R_SockWrite(this->fd, ptr, (int)(size * nitems),
    this-> timeout)/((ssize_t)size);
    >> return n > 0 ? n : 0;
    >> }
    > which seems uncalled for, given:
    >> ssize_t R_SockWrite(int sockp, const void *buf, size_t len, int timeout)


    > Is there a rationale for it, or should it be fixed?

I've fixed it; it's clearly been a  "typo" introduced at the
same when the type of 'len' in the R_SockWrite() header was
changed from int to size_t .. and the intent must have been to
do the same inside sock_write().

    > Best,
    > --
    > Zafer

Thank you for the report!

Martin Maechler
ETH Zurich  and  R Core


From @osp@m m@iii@g oii @itieid-im@de  Tue Oct 12 12:11:10 2021
From: @osp@m m@iii@g oii @itieid-im@de (@osp@m m@iii@g oii @itieid-im@de)
Date: Tue, 12 Oct 2021 12:11:10 +0200
Subject: [Rd] Slow try in combination with do.call
In-Reply-To: <24899.27400.17297.779309@stat.math.ethz.ch>
References: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>
 <24899.26457.944004.373721@stat.math.ethz.ch>
 <24899.27400.17297.779309@stat.math.ethz.ch>
Message-ID: <61367f47abb6b2f4374c676dba2d8e4915d9cd31.camel@altfeld-im.de>

In fact an attentive user reported the same type of (slow due to deparse) problem in may tryCatchLog package recently when using a large sparse matrix

    https://github.com/aryoda/tryCatchLog/issues/68

and I have fixed it by explicitly using the nlines arg of deparse() instead of using as.character()
which implicitly calls deparse() for a call stack.

Looking for a fix I think I may have found inconsistent deparse default arguments in base R between as.character() and deparse():

    A direct deparse call in R uses
        control = c("keepNA", "keepInteger", "niceNames", "showAttributes")
    as default (see ?.deparseOpts for details).

    The as.character() implementation in the C code of base R calls the internal deparse C function
    with another default for .deparseOpts:
        The SIMPLEDEPARSE C constant which corresponds to control = NULL.
        https://github.com/wch/r-source/blob/54f94f0433c487fe55553b0df9bae477c9babdd1/src/main/deparse.c#L345

This is clearly no bug but maybe the as.character() implementation should use the default args of deparse() for consistency (just a proposal!)...

BTW: You can find my analysis result with the call path and links to the R source code in the github issue:
     https://github.com/aryoda/tryCatchLog/issues/68#issuecomment-930593002



On Thu, 2021-09-16 at 18:04 +0200, Martin Maechler wrote:
> > > > > > Martin Maechler 
> > > > > >     on Thu, 16 Sep 2021 17:48:41 +0200 writes:
> > > > > > Alexander Kaever 
> > > > > >     on Thu, 16 Sep 2021 14:00:03 +0000 writes:
> 
>     >> Hi,
>     >> It seems like a try(do.call(f, args)) can be very slow on error depending on the args size. This is related to a complete deparse of the call
> using deparse(call)[1L] within the try function. How about replacing deparse(call)[1L] by deparse(call, nlines = 1)?
> 
>     >> Best,
>     >> Alex
> 
>     > an *excellent* idea!
> 
>     > I have checked that the resulting try() object continues to contain the
>     > long large call; indeed that is not the problem, but the
>     > deparse()ing  *is* as you say above.
> 
>     > {The experts typically use  tryCatch() directly, instead of  try() ,
>     > which may be the reason other experienced R developers have not
>     > stumbled over this ...}
> 
>     > Thanks a lot, notably also for the clear  repr.ex. below.
> 
>     > Best regards,
>     > Martin
> 
> OTOH, I find so many cases  of   deparse(*)[1]  (or similar) in
> R's own sources, I'm wondering
> if I'm forgetting something ... and using nlines=* is not always
> faster & equivalent and hence better ??
> 
> Martin
> 
> 
> 
> 
>     >> Example:
> 
>     >> fun <- function(x) {
>     >> stop("testing")
>     >> }
>     >> d <- rep(list(mtcars), 10000)
>     >> object.size(d)
>     >> # 72MB
> 
>     >> system.time({
>     >> try(do.call(fun, args = list(x = d)))
>     >> })
>     >> # 8s
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 12 12:43:04 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 12 Oct 2021 12:43:04 +0200
Subject: [Rd] Slow try in combination with do.call
In-Reply-To: <61367f47abb6b2f4374c676dba2d8e4915d9cd31.camel@altfeld-im.de>
References: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>
 <24899.26457.944004.373721@stat.math.ethz.ch>
 <24899.27400.17297.779309@stat.math.ethz.ch>
 <61367f47abb6b2f4374c676dba2d8e4915d9cd31.camel@altfeld-im.de>
Message-ID: <24933.26296.13729.20557@stat.math.ethz.ch>

Just in case, you hadn't noticed:

Since Sep.17, we have had the faster  try()  now in both R-devel
and "R 4.1.1 patched" which will be released as R 4.1.2  by the
end of this month, with NEWS entry

    ? try() is considerably faster in case of an error and long call,
      as e.g., from some do.call().  Thanks to Alexander Kaever's
      suggestion posted to R-devel.

Martin


>>>>> nospam at altfeld-im de 
>>>>>     on Tue, 12 Oct 2021 12:11:10 +0200 writes:

    > In fact an attentive user reported the same type of (slow due to deparse) problem in may tryCatchLog package recently when using a large sparse matrix
    > https://github.com/aryoda/tryCatchLog/issues/68

    > and I have fixed it by explicitly using the nlines arg of deparse() instead of using as.character()
    > which implicitly calls deparse() for a call stack.

    > Looking for a fix I think I may have found inconsistent deparse default arguments in base R between as.character() and deparse():

    > A direct deparse call in R uses
    > control = c("keepNA", "keepInteger", "niceNames", "showAttributes")
    > as default (see ?.deparseOpts for details).

    > The as.character() implementation in the C code of base R calls the internal deparse C function
    > with another default for .deparseOpts:
    > The SIMPLEDEPARSE C constant which corresponds to control = NULL.
    > https://github.com/wch/r-source/blob/54f94f0433c487fe55553b0df9bae477c9babdd1/src/main/deparse.c#L345

    > This is clearly no bug but maybe the as.character() implementation should use the default args of deparse() for consistency (just a proposal!)...

    > BTW: You can find my analysis result with the call path and links to the R source code in the github issue:
    > https://github.com/aryoda/tryCatchLog/issues/68#issuecomment-930593002



    > On Thu, 2021-09-16 at 18:04 +0200, Martin Maechler wrote:
    >> > > > > > Martin Maechler 
    >> > > > > >     on Thu, 16 Sep 2021 17:48:41 +0200 writes:
    >> > > > > > Alexander Kaever 
    >> > > > > >     on Thu, 16 Sep 2021 14:00:03 +0000 writes:
    >> 
    >> >> Hi,
    >> >> It seems like a try(do.call(f, args)) can be very slow on error depending on the args size. This is related to a complete deparse of the call
    >> using deparse(call)[1L] within the try function. How about replacing deparse(call)[1L] by deparse(call, nlines = 1)?
    >> 
    >> >> Best,
    >> >> Alex
    >> 
    >> > an *excellent* idea!
    >> 
    >> > I have checked that the resulting try() object continues to contain the
    >> > long large call; indeed that is not the problem, but the
    >> > deparse()ing  *is* as you say above.
    >> 
    >> > {The experts typically use  tryCatch() directly, instead of  try() ,
    >> > which may be the reason other experienced R developers have not
    >> > stumbled over this ...}
    >> 
    >> > Thanks a lot, notably also for the clear  repr.ex. below.
    >> 
    >> > Best regards,
    >> > Martin
    >> 
    >> OTOH, I find so many cases  of   deparse(*)[1]  (or similar) in
    >> R's own sources, I'm wondering
    >> if I'm forgetting something ... and using nlines=* is not always
    >> faster & equivalent and hence better ??
    >> 
    >> Martin
    >> 
    >> 
    >> 
    >> 
    >> >> Example:
    >> 
    >> >> fun <- function(x) {
    >> >> stop("testing")
    >> >> }
    >> >> d <- rep(list(mtcars), 10000)
    >> >> object.size(d)
    >> >> # 72MB
    >> 
    >> >> system.time({
    >> >> try(do.call(fun, args = list(x = d)))
    >> >> })
    >> >> # 8s
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Wed Oct 13 13:12:09 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Wed, 13 Oct 2021 11:12:09 +0000
Subject: [Rd] Potential bugs in table dnn
In-Reply-To: <1633866959731.85310@ap-hm.fr>
References: <1633866959731.85310@ap-hm.fr>
Message-ID: <8d7fe93b9ad64d4ab56edc2f28f2336b@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Inline comments below in the previous message

I'm not 100% sure if the current behavior is intended or not. If not, here is a patch (which I can submit on R Bugzilla if appropriate):


diff -u orig/table.R mod/table.R
--- orig/table.R	2021-10-13 10:04:28.560912800 +0200
+++ mod/table.R	2021-10-13 10:43:43.815915100 +0200
@@ -1,7 +1,7 @@
 #  File src/library/base/R/table.R
 #  Part of the R package, https://www.R-project.org
 #
-#  Copyright (C) 1995-2020 The R Core Team
+#  Copyright (C) 1995-2021 The R Core Team
 #
 #  This program is free software; you can redistribute it and/or modify
 #  it under the terms of the GNU General Public License as published by
@@ -50,9 +50,8 @@
     args <- list(...)
     if (length(args) == 1L && is.list(args[[1L]])) { ## e.g. a data.frame
 	args <- args[[1L]]
-	if (length(dnn) != length(args))
-	    dnn <- if (!is.null(argn <- names(args))) argn
-		   else paste(dnn[1L], seq_along(args), sep = ".")
+	dnn <- if (!is.null(argn <- names(args))) argn
+	       else paste(dnn[1L], seq_along(args), sep = ".")
     }
     if (!length(args))
 	stop("nothing to tabulate")
diff -u orig/table.Rd mod/table.Rd
--- orig/table.Rd	2021-10-13 11:39:45.839097000 +0200
+++ mod/table.Rd	2021-10-13 11:56:25.620660900 +0200
@@ -1,6 +1,6 @@
 % File src/library/base/man/table.Rd
 % Part of the R package, https://www.R-project.org
-% Copyright 1995-2021 R Core Team
+% Copyright 1995-2016 R Core Team
 % Distributed under GPL 2 or later
 
 \name{table}
@@ -48,7 +48,7 @@
   \item{useNA}{whether to include \code{NA} values in the table.
     See \sQuote{Details}.  Can be abbreviated.}
   \item{dnn}{the names to be given to the dimensions in the result (the
-    \emph{dimnames names}).}
+    \emph{dimnames names}).  See \sQuote{Details}.}
   \item{deparse.level}{controls how the default \code{dnn} is
     constructed.  See \sQuote{Details}.}
   \item{x}{an arbitrary \R object, or an object inheriting from class
@@ -64,12 +64,15 @@
   \item{sep, base}{passed to \code{\link{provideDimnames}}.}
 }
 \details{
-  If the argument \code{dnn} is not supplied, the internal function
+  If ... is one or more objects which can be interpreted as factors
+  and the argument \code{dnn} is not supplied, the internal function
   \code{list.names} is called to compute the \sQuote{dimname names}.  If the
   arguments in \code{\dots} are named, those names are used.  For the
   remaining arguments, \code{deparse.level = 0} gives an empty name,
   \code{deparse.level = 1} uses the supplied argument if it is a symbol,
-  and \code{deparse.level = 2} will deparse the argument.
+  and \code{deparse.level = 2} will deparse the argument.  Otherwise,
+  if ... is a list (or data frame), its names are used as the
+  \sQuote{dimname names} and the argument \code{dnn} is not used.
 
   Only when \code{exclude} is specified (i.e., not by default) and
   non-empty, will \code{table} potentially drop levels of factor



> Dear list,
> 
> table does not set dnn for dataframes of length 1:
> 
> table(warpbreaks[2:3]) # has dnn
> #     tension
> # wool L M H
> #    A 9 9 9
> #    B 9 9 9
> 
> table(warpbreaks[2]) # has no dnn
> # 
> #  A  B 
> # 27 27 
> 
> This is because of if (length(dnn) != length(args)) (line 53 in https://github.com/wch/r-source/blob/trunk/src/library/base/R/table.R). When commenting this line or modifying it to if (length(dnn) != length(args) || dnn == ""), dnn are set as expected:
> 
> table2(warpbreaks[2:3]) # has dnn
> #     tension
> # wool L M H
> #    A 9 9 9
> #    B 9 9 9
> 
> table2(warpbreaks[2]) # has dnn
> # wool
> #  A  B 
> # 27 27 
> 
> However, I do not get the logic for the initial if (length(dnn) != length(args)), so the change may break something else...

I guess the purpose of this line is to have the possibility to set the dimname names through the dnn argument for lists (or data frames) of length 1, e.g.:

table(warpbreaks[2], dnn = "xxx")
# xxx
#  A  B 
# 27 27

However, this seems inconsistent with the behavior for lists (or data frames) of length >1. Removing the exception introduced by the if clause restore the consistency in dimname names for lists (or data frames) whatever their length.


> In addition, table documentation says "If the argument dnn is not supplied, the internal function list.names is called to compute the 'dimname names'. If the arguments in ... are named, those names are used." Some cases seem inconsistent or may return a warning:

The documentation seems not very clear on how dimname names are computed for lists (or data frames). If removing the if clause [i.e., consistent behavior for lists (or data frames), see above], I think it only requires to document the "precedence" of list (or data frame) names over dnn when ... is a list (or data frame), e.g.: "if ... is a list (or data frame), its names are used as the \sQuote{dimname names} and the argument \code{dnn} is not used." (see the patch above)


> table(warpbreaks[2], dnn = letters) # no warning/not as documented
> # wool
> #  A  B 
> # 27 27 
> 
> table(warpbreaks[2], dnn = letters[1]) # as documented
> # a
> #  A  B 
> # 27 27 
> 
> table(zzz = warpbreaks[2], dnn = letters[1]) # as documented
> # a
> #  A  B 
> # 27 27 
> 
> table(zzz = warpbreaks$wool, dnn = letters[1]) # as documented
> # a
> #  A  B 
> # 27 27 
> 
> table(warpbreaks$wool, dnn = letters) # as expected
> # Error in names(dn) <- dnn : 
> #   attribut 'names' [26] doit ?tre de m?me longueur que le vecteur [1]
> 
> Best regards,
> 
> Thomas


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 14 10:47:53 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 14 Oct 2021 10:47:53 +0200
Subject: [Rd] Potential bugs in table dnn
In-Reply-To: <8d7fe93b9ad64d4ab56edc2f28f2336b@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
References: <1633866959731.85310@ap-hm.fr>
 <8d7fe93b9ad64d4ab56edc2f28f2336b@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
Message-ID: <24935.61113.197265.919449@stat.math.ethz.ch>

>>>>> SOEIRO Thomas 
>>>>>     on Wed, 13 Oct 2021 11:12:09 +0000 writes:

    > Inline comments below in the previous message I'm not 100%
    > sure if the current behavior is intended or not. If not,
    > here is a patch (which I can submit on R Bugzilla if
    > appropriate):

Excuse us for not replying earlier, Thomas, but yes, there is a
buglet in generating dimnames when creating table() objects,
but I think *not* in the behaviour you want to change
because that *is* partly purposeful and not a bug (in code).

Rather it's incomplete documentation which currently does not
cover that case ... and I see your proposed patch also tries to
address the issue of "too terse" documentation.

The only bug I see is that here,

  R> table(warpbreaks[3])

   L  M  H 
  18 18 18 
  R> 

the automatic dnn's (= [d]im[n]ames' [n]ames) are not taken as
in the (>= 2)-dim case,

  R> table(warpbreaks[-1])
      tension
  wool L M H
     A 9 9 9
     B 9 9 9
  R>

However, I definitely would not want to see anything different
than what we see now for

  R> table(FOOBAR = warpbreaks[-1])
      tension
  wool L M H
     A 9 9 9
     B 9 9 9
  R>

where indeed, the FOOBAR should be *kept* disregarded
(as it should in  table(FOOBAR = warpbreaks[3])  once we fix the
 1D --- {1-argument with own dimnames} case)

and of course, this should also stay as is, undisputedly:

  R> table(POISSON_7 = rpois(100, 7))
  POISSON_7
   2  3  4  5  6  7  8  9 10 11 12 13 14 
   4  5 14 16 20  8  8 13  1  5  3  2  1 
  R>

I'm fine if you move this to R bugzilla  {where it remains more
easily findable in say 1 year's time}.

Thank you for the report and diagnosis so far!
Martin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 14 11:43:51 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 14 Oct 2021 11:43:51 +0200
Subject: [Rd] Potential bugs in table dnn
In-Reply-To: <24935.61113.197265.919449@stat.math.ethz.ch>
References: <1633866959731.85310@ap-hm.fr>
 <8d7fe93b9ad64d4ab56edc2f28f2336b@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
 <24935.61113.197265.919449@stat.math.ethz.ch>
Message-ID: <24935.64471.128323.9537@stat.math.ethz.ch>

Dear Thomas,

actually, I have in the mean time already applied the changes I
think are needed,
both in the code and in the documentation.

So, in this case, it may be a waste of time to still open a
bugzilla issue, I think.

Here are my current changes (not yet committed; of course I would also add
a NEWS entry, mentioning you):


Index: src/library/base/R/table.R
===================================================================
53c53
< 	if (length(dnn) != length(args))
---
> 	if(length(args) == 1L || length(dnn) != length(args))
Index: src/library/base/man/table.Rd
===================================================================
23c23
<   \code{table} uses the cross-classifying factors to build a contingency
---
>   \code{table} uses cross-classifying factors to build a contingency
41c41,42
<     (including character strings), or a list (or data frame) whose
---
>     (including numbers or character strings), or a \code{\link{list}} (such
>     as a data frame) whose
67c68,69
<   If the argument \code{dnn} is not supplied, the internal function
---
>   If the argument \code{dnn} is not supplied \emph{and} if \code{\dots} is
>   not one \code{list} with its own \code{\link{names}()}, the internal function



With regards,
Martin


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Thu Oct 14 12:08:48 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Thu, 14 Oct 2021 10:08:48 +0000
Subject: [Rd] Potential bugs in table dnn
In-Reply-To: <24935.64471.128323.9537@stat.math.ethz.ch>
References: <1633866959731.85310@ap-hm.fr>
 <8d7fe93b9ad64d4ab56edc2f28f2336b@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
 <24935.61113.197265.919449@stat.math.ethz.ch>
 <24935.64471.128323.9537@stat.math.ethz.ch>
Message-ID: <f543d651f76541f1b11d7703644f1a28@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear Martin,

Thank you for the perfect fix. It fixes both issues in the 1-dim case (i.e. automatic dnn *and* disregard dnn/names in ...), as well as the documentation.



While working on table, may be this should be an error?

table(warpbreaks[2], warpbreaks[3]) 
#      
#       1:3
#   1:2   0
# Warning messages:
# 1: In xtfrm.data.frame(x) : cannot xtfrm data frames
# 2: In xtfrm.data.frame(x) : cannot xtfrm data frames

Best regards,

Thomas

> -----Message d'origine-----
> De?: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Envoy??: jeudi 14 octobre 2021 11:44
> ??: SOEIRO Thomas
> Cc?: R Development List
> Objet?: Re: [Rd] Potential bugs in table dnn
> 
> EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS
> 
> Dear Thomas,
> 
> actually, I have in the mean time already applied the changes I think are
> needed, both in the code and in the documentation.
> 
> So, in this case, it may be a waste of time to still open a bugzilla issue, I think.
> 
> Here are my current changes (not yet committed; of course I would also add
> a NEWS entry, mentioning you):
> 
> 
> Index: src/library/base/R/table.R
> ==========================================================
> =========
> 53c53
> <       if (length(dnn) != length(args))
> ---
> >       if(length(args) == 1L || length(dnn) != length(args))
> Index: src/library/base/man/table.Rd
> ==========================================================
> =========
> 23c23
> <   \code{table} uses the cross-classifying factors to build a contingency
> ---
> >   \code{table} uses cross-classifying factors to build a contingency
> 41c41,42
> <     (including character strings), or a list (or data frame) whose
> ---
> >     (including numbers or character strings), or a \code{\link{list}} (such
> >     as a data frame) whose
> 67c68,69
> <   If the argument \code{dnn} is not supplied, the internal function
> ---
> >   If the argument \code{dnn} is not supplied \emph{and} if \code{\dots} is
> >   not one \code{list} with its own \code{\link{names}()}, the internal
> > function
> 
> 
> 
> With regards,
> Martin

From m|ch@|2992 @end|ng |rom gm@||@com  Fri Oct 15 16:44:28 2021
From: m|ch@|2992 @end|ng |rom gm@||@com (=?UTF-8?Q?Micha=C5=82_Bojanowski?=)
Date: Fri, 15 Oct 2021 16:44:28 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
Message-ID: <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>

Dear colleagues,

I would be grateful if somebody could explain and perhaps help work
around the following.

I have .Renviron with, say:

AVAR=${APPDATA}/foo/bar

Which is a documented way of referring to existing environment
variables. Now, with that in R I'm getting:

Sys.getenv("APPDATA")    # That works OK
[1] "C:\\Users\\mbojanowski\\AppData\\Roaming"

so OK, but:

Sys.getenv("AVAR")
[1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"

So all the (back)slashes are gone from APPDATA.

Does processing ${} removes the backslashes? I could not find anything
on that in R Windows FAQ nor on the web.
Thanks in advance!

Michal


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Oct 15 18:19:20 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 15 Oct 2021 12:19:20 -0400
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
Message-ID: <809d9306-ad58-2827-d18d-37f4bca5ca52@gmail.com>

On 15/10/2021 10:44 a.m., Micha? Bojanowski wrote:
> Dear colleagues,
> 
> I would be grateful if somebody could explain and perhaps help work
> around the following.
> 
> I have .Renviron with, say:
> 
> AVAR=${APPDATA}/foo/bar
> 
> Which is a documented way of referring to existing environment
> variables. Now, with that in R I'm getting:

I think in your example, AVAR would be set using

AVAR=C:\Users\mbojanowski\AppData\Roaming/foo/bar

When I export that value in a bash shell (on a Mac, not Windows), I get 
the same thing as you saw:

$ printenv AVAR
C:UsersmbojanowskiAppDataRoaming/foo/bar

Here R was not involved at all, this is the shell eating the backslashes.

So I suppose R is following the same rules as bash (or maybe getting 
bash or sh to handle .Renviron).  Those rules are that the single 
backslashes are treated as escapes, and so they are dropped and the 
following character is preserved: 
https://www.gnu.org/software/bash/manual/html_node/Escape-Character.html .

I think you don't have a lot of choice here:  if you don't have control 
over how an environment variable is being set, then don't try to use it 
in an expansion in .Renviron.  If you do have control, then avoid using 
backslashes.

So this would be fine:

APPDATA=C:/Users/mbojanowski/AppData/Roaming
AVAR=${APPDATA}/foo/bar

but your APPDATA setting needs to be handled in some other way, e.g. in 
.Rprofile instead of .Renviron.

Duncan Murdoch

> 
> Sys.getenv("APPDATA")    # That works OK
> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> 
> so OK, but:
> 
> Sys.getenv("AVAR")
> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> 
> So all the (back)slashes are gone from APPDATA.
> 
> Does processing ${} removes the backslashes? I could not find anything
> on that in R Windows FAQ nor on the web.
> Thanks in advance!
> 
> Michal
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Oct 15 18:37:44 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 15 Oct 2021 19:37:44 +0300
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
Message-ID: <20211015193744.1776bb29@Tarkus>

On Fri, 15 Oct 2021 16:44:28 +0200
Micha? Bojanowski <michal2992 at gmail.com> wrote:

> AVAR=${APPDATA}/foo/bar
> 
> Which is a documented way of referring to existing environment
> variables. Now, with that in R I'm getting:
> 
> Sys.getenv("APPDATA")    # That works OK
> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> 
> so OK, but:
> 
> Sys.getenv("AVAR")
> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"

Hmm, that

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Oct 15 18:40:37 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 15 Oct 2021 19:40:37 +0300
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
Message-ID: <20211015194037.595b389f@Tarkus>

Sorry for the noise! I wasn't supposed to send my previous message.

On Fri, 15 Oct 2021 16:44:28 +0200
Micha? Bojanowski <michal2992 at gmail.com> wrote:

> AVAR=${APPDATA}/foo/bar
> 
> Which is a documented way of referring to existing environment
> variables. Now, with that in R I'm getting:
> 
> Sys.getenv("APPDATA")    # That works OK
> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> 
> so OK, but:
> 
> Sys.getenv("AVAR")
> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"

Hmm, a function called by readRenviron does seem to remove backslashes,
but not if they are encountered inside quotes:

https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149

Would AVAR="${APPDATA}"/foo/bar work?

-- 
Best regards,
Ivan


From m|ch@|2992 @end|ng |rom gm@||@com  Fri Oct 15 18:43:05 2021
From: m|ch@|2992 @end|ng |rom gm@||@com (=?UTF-8?Q?Micha=C5=82_Bojanowski?=)
Date: Fri, 15 Oct 2021 18:43:05 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <20211015194037.595b389f@Tarkus>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
Message-ID: <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>

Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
Thank you all!
Michal

On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> Sorry for the noise! I wasn't supposed to send my previous message.
>
> On Fri, 15 Oct 2021 16:44:28 +0200
> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>
> > AVAR=${APPDATA}/foo/bar
> >
> > Which is a documented way of referring to existing environment
> > variables. Now, with that in R I'm getting:
> >
> > Sys.getenv("APPDATA")    # That works OK
> > [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> >
> > so OK, but:
> >
> > Sys.getenv("AVAR")
> > [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>
> Hmm, a function called by readRenviron does seem to remove backslashes,
> but not if they are encountered inside quotes:
>
> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>
> Would AVAR="${APPDATA}"/foo/bar work?
>
> --
> Best regards,
> Ivan


From m|ch@|2992 @end|ng |rom gm@||@com  Fri Oct 15 18:44:21 2021
From: m|ch@|2992 @end|ng |rom gm@||@com (=?UTF-8?Q?Micha=C5=82_Bojanowski?=)
Date: Fri, 15 Oct 2021 18:44:21 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
Message-ID: <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>

Perhaps a small update to ?.Renviron would be in order to mention that...

On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>
> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
> Thank you all!
> Michal
>
> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >
> > Sorry for the noise! I wasn't supposed to send my previous message.
> >
> > On Fri, 15 Oct 2021 16:44:28 +0200
> > Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >
> > > AVAR=${APPDATA}/foo/bar
> > >
> > > Which is a documented way of referring to existing environment
> > > variables. Now, with that in R I'm getting:
> > >
> > > Sys.getenv("APPDATA")    # That works OK
> > > [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> > >
> > > so OK, but:
> > >
> > > Sys.getenv("AVAR")
> > > [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> >
> > Hmm, a function called by readRenviron does seem to remove backslashes,
> > but not if they are encountered inside quotes:
> >
> > https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
> >
> > Would AVAR="${APPDATA}"/foo/bar work?
> >
> > --
> > Best regards,
> > Ivan


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Fri Oct 15 22:26:51 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Fri, 15 Oct 2021 20:26:51 +0000
Subject: [Rd] Potential bugs in table dnn
Message-ID: <1634329611558.69539@ap-hm.fr>

> Dear Martin,
> 
> Thank you for the perfect fix. It fixes both issues in the 1-dim case (i.e. automatic dnn *and* disregard dnn/names in ...), as well as the documentation.


Finally, there is still a corner case that the patch did not fix in the 1D-case. We cannot override the data frame's names with the dnn argument:

tab(warpbreaks[2], dnn = letters[1]) # dnn ignored
# wool
#  A  B 
# 27 27 

tab(warpbreaks[2:3], dnn = letters[1:2]) # works
#    b
# a   L M H
#   A 9 9 9
#   B 9 9 9

But I did not manage to fix it...


> While working on table, may be this should be an error?
> 
> table(warpbreaks[2], warpbreaks[3]) 
> #      
> #       1:3
> #   1:2   0
> # Warning messages:
> # 1: In xtfrm.data.frame(x) : cannot xtfrm data frames
> # 2: In xtfrm.data.frame(x) : cannot xtfrm data frames
> 
> Best regards,
> 
> Thomas
> 
> > -----Message d'origine-----
> > De : Martin Maechler [mailto:maechler using stat.math.ethz.ch]
> > Envoy? : jeudi 14 octobre 2021 11:44
> > ? : SOEIRO Thomas
> > Cc : R Development List
> > Objet : Re: [Rd] Potential bugs in table dnn
> > 
> > EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS
> > 
> > Dear Thomas,
> > 
> > actually, I have in the mean time already applied the changes I think are
> > needed, both in the code and in the documentation.
> > 
> > So, in this case, it may be a waste of time to still open a bugzilla issue, I think.
> > 
> > Here are my current changes (not yet committed; of course I would also add
> > a NEWS entry, mentioning you):
> > 
> > 
> > Index: src/library/base/R/table.R
> > ==========================================================
> > =========
> > 53c53
> > <       if (length(dnn) != length(args))
> > ---
> > >       if(length(args) == 1L || length(dnn) != length(args))
> > Index: src/library/base/man/table.Rd
> > ==========================================================
> > =========
> > 23c23
> > <   \code{table} uses the cross-classifying factors to build a contingency
> > ---
> > >   \code{table} uses cross-classifying factors to build a contingency
> > 41c41,42
> > <     (including character strings), or a list (or data frame) whose
> > ---
> > >     (including numbers or character strings), or a \code{\link{list}} (such
> > >     as a data frame) whose
> > 67c68,69
> > <   If the argument \code{dnn} is not supplied, the internal function
> > ---
> > >   If the argument \code{dnn} is not supplied \emph{and} if \code{\dots} is
> > >   not one \code{list} with its own \code{\link{names}()}, the internal
> > > function
> > 
> > 
> > 
> > With regards,
> > Martin

From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Oct 18 17:02:05 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 18 Oct 2021 17:02:05 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
Message-ID: <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>


On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
> Perhaps a small update to ?.Renviron would be in order to mention that...

Would you have a more specific suggestion how to update the 
documentation? Please note that it already says

"?value? is then processed in a similar way to a Unix shell: in 
particular the outermost level of (single or double) quotes is stripped, 
and backslashes are removed except inside quotes."

Thanks,
Tomas

> On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
>> Thank you all!
>> Michal
>>
>> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>> Sorry for the noise! I wasn't supposed to send my previous message.
>>>
>>> On Fri, 15 Oct 2021 16:44:28 +0200
>>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>
>>>> AVAR=${APPDATA}/foo/bar
>>>>
>>>> Which is a documented way of referring to existing environment
>>>> variables. Now, with that in R I'm getting:
>>>>
>>>> Sys.getenv("APPDATA")    # That works OK
>>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
>>>>
>>>> so OK, but:
>>>>
>>>> Sys.getenv("AVAR")
>>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>>> Hmm, a function called by readRenviron does seem to remove backslashes,
>>> but not if they are encountered inside quotes:
>>>
>>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>>>
>>> Would AVAR="${APPDATA}"/foo/bar work?
>>>
>>> --
>>> Best regards,
>>> Ivan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Oct 19 01:45:23 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Mon, 18 Oct 2021 18:45:23 -0500 (CDT)
Subject: [Rd] 
 [External]  GC: improving the marking performance for STRSXPs
In-Reply-To: <E1mYNuQ-0001Al-8B@rmmprod05.runbox>
References: <E1mYNuQ-0001Al-8B@rmmprod05.runbox>
Message-ID: <alpine.DEB.2.22.394.2110181839570.117406@luke-Latitude-7480>

Thanks. I have committed a modified version, also incorporating the
handling of R_StringHash from your other post, in r81073. I prefer to
be more conservative in the GC. for example not assume without
checking that STRSXP elements are CHARSXP. This does add some
overhead, but the change is still beneficial.

I don't think we would want to add the complexity of threading at this
point, though it might be worth considering at a later time. There are
a few other possible modifications that I'll explore that might
provide comparable improvements to the ones seen with your patch
without adding the complexity of threads.

Best,

luke

On Thu, 7 Oct 2021, Andreas Kersting wrote:

> Hi all,
>
> in GC (in src/main/memory.c), FORWARD_CHILDREN() (called by PROCESS_NODES()) treats STRSXPs just like VECSXPs, i.e. it calls FORWARD_NODE() for all its children. I claim that this is unnecessarily inefficient since the children of a STRSXP can legitimately only be (atomic) CHARSXPs and could hence be marked directly in the call of FORWARD_CHILDREN() on the STRSXP.
>
> Attached patch (?atomic_CHARSXP.diff) implements this and gives the following performance improvements on my system compared to R devel (revision 81008):
>
> Elapsed time for two full gc in a session after
>
> x <- as.character(runif(5e7))[]
>
> 19sec -> 15sec.
>
> This is the best-case scenario for the patch: very many unique/unmarked CHARSXP in the STRSXP. For already marked CHARSXP there is no performance gain since FORWARD_NODE() is a no-op for them.
>
> The relative performance gain is even bigger if iterating through the STRSXP produces many cache misses, as e.g. after
>
> x <- as.character(runif(5e7))[]
> x <- sample(x, length(x))
>
> Elapsed time for two full gc here: 83sec -> 52sec. This is because we have less cache misses per CHARSXP.
>
> This patch additionally also assumes that the ATTRIBs of a CHARSXP are not to be traced because they are just used for maintaining the CHARSXP hash chains.
>
> The second attached patch (?atomic_CHARSXP_safe_unlikely.diff) checks both assumptions and calls gc_error() if they are violated and is still noticeably faster than R devel: 19sec -> 17sec and 83sec -> 54sec, respectively.
>
> Attached gc_test.R is the script I used to get the previously mentioned and more gc timings.
>
> Do you think that this is a reasonable change? It does make the code more complex and I am not sure if there might be situations in which the assumptions are violated, even though ?SET_STRING_ELT() and ?installAttrib() do enforce them.
>
> Best regards,
> Andreas

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Wed Oct 20 00:17:16 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Tue, 19 Oct 2021 22:17:16 +0000
Subject: [Rd] Environment setting _R_CHECK_DEPENDS_ONLY_='true'
Message-ID: <7C83324B-EB19-46AB-BC08-6E8A8FCB65E5@anu.edu.au>

Setting  
Sys,setenv('_R_CHECK_DEPENDS_ONLY_'=?true?)
or Sys,setenv('_R_CHECK_DEPENDS_ONLY_?=TRUE)

(either appear to be acceptable) appears to have no effect when I do, e.g.

$R CMD check qra_0.2.4.tar.gz
* using log directory ?/Users/johnm1/pkgs/qra.Rcheck?
* using R version 4.1.1 (2021-08-10)
* using platform: x86_64-apple-darwin17.0 (64-bit)
* using session charset: UTF-8
. . .

(This should have failed.)

I?d have expected that the "On most systems . . .? mentioned in the Writing R extensions 
manual (1.1.3.1 Suggested packages) would include my setup.

Any insight on what I am missing will be welcome.

John Maindonald             email: john.maindonald at anu.edu.au





From d|pter|x@w@ng @end|ng |rom gm@||@com  Wed Oct 20 01:06:04 2021
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Tue, 19 Oct 2021 19:06:04 -0400
Subject: [Rd] stats::fft produces inconsistent results
Message-ID: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>

Dear R-devel Team,

I'm developing a neuroscience signal pipeline package in R (https://github.com/dipterix/ravetools) and I noticed a weird issue that failed my unit test.

Basically I was trying to use `fftw3` library to implement fast multivariate fft function in C++. When I tried to compare my results with stats::fft, the test result showed the first element of **expected** (which was produced by stats::fft) was zero, which, I am pretty sure, is wrong, and I can confirm that my function produces correct results.

However, somehow I couldn?t reproduce this issue on my personal computer (osx, M1, R4.1.1), the error simply went away. 

The catch is my function produced consistent and correct results but stats::fft was not. This does not mean `stats::fft` has bugs. Instead, I suspect there could be some weird interactions between my code and stats::fft at C/C++ level, but I couldn?t figure it out why.

+++ Details:

Here?s the code I used for the test:

https://github.com/dipterix/ravetools/blob/4dc35d64763304aff869d92dddad38a7f2b30637/tests/testthat/test-fftw.R#L33-L41

????????Test code????????
set.seed(1)
x <- rnorm(1000)
dim(x) <- c(100,10)
a <- ravetools:::mvfftw_r2c(x, 0)
c <- apply(x, 2, stats::fft)[1:51,]
expect_equal(a, c)
????????????????????????

Here are the tests that gave me the errors:

The test logs on win-builder
https://win-builder.r-project.org/07586ios8AbL/00check.log

Test logs on GitHub
https://github.com/dipterix/ravetools/runs/3944874310?check_suite_focus=true


?????????????? Failed tests ??????????????
 -- Failure (test-fftw.R:41:3): mvfftw_r2c --------------------------------------
 `a` (`actual`) not equal to `c` (`expected`).

 actual vs expected
                                     [,1]                    [,2]                  [,3]                  [,4]                    ...
 - actual[1, ]     10.8887367+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i ...
 + expected[1, ]    0.0000000+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i...

????????????????????????

The first columns are different, `actual` is the results I produced via `ravetools:::mvfftw_r2c`, and `expected` was produced by `stats::fft`


Any help or attention is very much appreciated.
Thanks,
- Zhengjia

From bbo|ker @end|ng |rom gm@||@com  Wed Oct 20 03:27:29 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 19 Oct 2021 21:27:29 -0400
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
Message-ID: <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>

   This is a long shot, but here's a plausible scenario:

   as part of its pipeline, ravetools::mvfftw computes the mean of the 
input vector **and then centers it to a mean of zero** (intentionally or 
accidentally?)

   because variables are passed to compiled code by reference (someone 
can feel free to correct my terminology), this means that the original 
vector in R now has a mean of zero

   the first element of fft() is mean(x)*length(x), so if mean(x) has 
been forced to zero, that would explain your issue.

   I don't know about the non-reproducibility part.

On 10/19/21 7:06 PM, Dipterix Wang wrote:
> Dear R-devel Team,
> 
> I'm developing a neuroscience signal pipeline package in R (https://github.com/dipterix/ravetools) and I noticed a weird issue that failed my unit test.
> 
> Basically I was trying to use `fftw3` library to implement fast multivariate fft function in C++. When I tried to compare my results with stats::fft, the test result showed the first element of **expected** (which was produced by stats::fft) was zero, which, I am pretty sure, is wrong, and I can confirm that my function produces correct results.
> 
> However, somehow I couldn?t reproduce this issue on my personal computer (osx, M1, R4.1.1), the error simply went away.
> 
> The catch is my function produced consistent and correct results but stats::fft was not. This does not mean `stats::fft` has bugs. Instead, I suspect there could be some weird interactions between my code and stats::fft at C/C++ level, but I couldn?t figure it out why.
> 
> +++ Details:
> 
> Here?s the code I used for the test:
> 
> https://github.com/dipterix/ravetools/blob/4dc35d64763304aff869d92dddad38a7f2b30637/tests/testthat/test-fftw.R#L33-L41
> 
> ????????Test code????????
> set.seed(1)
> x <- rnorm(1000)
> dim(x) <- c(100,10)
> a <- ravetools:::mvfftw_r2c(x, 0)
> c <- apply(x, 2, stats::fft)[1:51,]
> expect_equal(a, c)
> ????????????????????????
> 
> Here are the tests that gave me the errors:
> 
> The test logs on win-builder
> https://win-builder.r-project.org/07586ios8AbL/00check.log
> 
> Test logs on GitHub
> https://github.com/dipterix/ravetools/runs/3944874310?check_suite_focus=true
> 
> 
> ?????????????? Failed tests ??????????????
>   -- Failure (test-fftw.R:41:3): mvfftw_r2c --------------------------------------
>   `a` (`actual`) not equal to `c` (`expected`).
> 
>   actual vs expected
>                                       [,1]                    [,2]                  [,3]                  [,4]                    ...
>   - actual[1, ]     10.8887367+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i ...
>   + expected[1, ]    0.0000000+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i...
> 
> ????????????????????????
> 
> The first columns are different, `actual` is the results I produced via `ravetools:::mvfftw_r2c`, and `expected` was produced by `stats::fft`
> 
> 
> Any help or attention is very much appreciated.
> Thanks,
> - Zhengjia
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @eb@meyer @end|ng |rom |@u@de  Wed Oct 20 09:31:33 2021
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Wed, 20 Oct 2021 09:31:33 +0200
Subject: [Rd] Environment setting _R_CHECK_DEPENDS_ONLY_='true'
In-Reply-To: <7C83324B-EB19-46AB-BC08-6E8A8FCB65E5@anu.edu.au>
References: <7C83324B-EB19-46AB-BC08-6E8A8FCB65E5@anu.edu.au>
Message-ID: <d3a5e0b2-3687-31ec-814f-ca301b818e26@fau.de>

(this should have been posted to R-package-devel, not R-devel)

Am 20.10.21 um 00:17 schrieb John Maindonald via R-devel:
> Setting
> Sys,setenv('_R_CHECK_DEPENDS_ONLY_'=?true?)
> or Sys,setenv('_R_CHECK_DEPENDS_ONLY_?=TRUE)
> 
> (either appear to be acceptable) appears to have no effect when I do, e.g.

If you set the environment variable inside a running R process, it will 
only affect that process and child processes, but not an independent R 
process launched from a shell like you seem to be doing here:

> 
> $R CMD check qra_0.2.4.tar.gz
> * using log directory ?/Users/johnm1/pkgs/qra.Rcheck?
> * using R version 4.1.1 (2021-08-10)
> * using platform: x86_64-apple-darwin17.0 (64-bit)
> * using session charset: UTF-8
> . . .
> 
> (This should have failed.)

How to set environment variables is system-specific. On a Unix-like 
system, you could use the command

_R_CHECK_DEPENDS_ONLY_=true  R CMD check qra_0.2.4.tar.gz

to set the environment variable for this R process.
See, e.g., https://en.wikipedia.org/wiki/Environment_variable.

Best regards,

	Sebastian Meyer


> 
> I?d have expected that the "On most systems . . .? mentioned in the Writing R extensions
> manual (1.1.3.1 Suggested packages) would include my setup.
> 
> Any insight on what I am missing will be welcome.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> 
> 
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Wed Oct 20 10:10:00 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Wed, 20 Oct 2021 08:10:00 +0000
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
Message-ID: <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>

Hello,

That sounds like a good diagnosis!
Indeed, R vectors are passed "by reference" to C code, but the semantic must be "by value", i.e. the C function must NOT change the contents of the vector, except in very specific cases.

A good program that has to work on a vector, must first duplicate the vector, unless the only reference to the vector is the reference inside the C function.
This can be tested by the MAYBE_REFERENCED() macro in Rinternals.h.

A good example can be found in the fft() function in src/library/stats/src/fourier.c in R source code:
    switch (TYPEOF(z)) {
    case INTSXP:
    case LGLSXP:
    case REALSXP:
        z = coerceVector(z, CPLXSXP);
        break;
    case CPLXSXP:
        if (MAYBE_REFERENCED(z)) z = duplicate(z);
        break;
    default:
        error(_("non-numeric argument"));
    }
    PROTECT(z);

This code coerces non-complex vectors to complex. Since this makes a copy, there is no need to duplicate.
Complex vectors are duplicated, unless they are not referenced by anything but the fft() function.

Now, the z vector can be modified "in place" without inconsistency.

Properly using R vectors in C code is tricky. You have to understand.
1) When you are allowed or not to modify vectors
2) When to PROTECT()vectors
3) How the garbage collector works and when it can trigger (answer : basically, when you call any internal R function)

Chapter 5 of "Writing R Extensions" documentation is quite extensive:
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C

-- 
Sincerely
Andr? GILLIBERT

-----Message d'origine-----
De?: R-devel <r-devel-bounces at r-project.org> De la part de Ben Bolker
Envoy??: mercredi 20 octobre 2021 03:27
??: r-devel at r-project.org
Objet?: Re: [Rd] stats::fft produces inconsistent results


   This is a long shot, but here's a plausible scenario:

   as part of its pipeline, ravetools::mvfftw computes the mean of the
input vector **and then centers it to a mean of zero** (intentionally or
accidentally?)

   because variables are passed to compiled code by reference (someone
can feel free to correct my terminology), this means that the original
vector in R now has a mean of zero

   the first element of fft() is mean(x)*length(x), so if mean(x) has
been forced to zero, that would explain your issue.

   I don't know about the non-reproducibility part.

On 10/19/21 7:06 PM, Dipterix Wang wrote:
> Dear R-devel Team,
>
> I'm developing a neuroscience signal pipeline package in R (https://github.com/dipterix/ravetools) and I noticed a weird issue that failed my unit test.
>
> Basically I was trying to use `fftw3` library to implement fast multivariate fft function in C++. When I tried to compare my results with stats::fft, the test result showed the first element of **expected** (which was produced by stats::fft) was zero, which, I am pretty sure, is wrong, and I can confirm that my function produces correct results.
>
> However, somehow I couldn?t reproduce this issue on my personal computer (osx, M1, R4.1.1), the error simply went away.
>
> The catch is my function produced consistent and correct results but stats::fft was not. This does not mean `stats::fft` has bugs. Instead, I suspect there could be some weird interactions between my code and stats::fft at C/C++ level, but I couldn?t figure it out why.
>
> +++ Details:
>
> Here?s the code I used for the test:
>
> https://github.com/dipterix/ravetools/blob/4dc35d64763304aff869d92dddad38a7f2b30637/tests/testthat/test-fftw.R#L33-L41
>
> ????????Test code????????
> set.seed(1)
> x <- rnorm(1000)
> dim(x) <- c(100,10)
> a <- ravetools:::mvfftw_r2c(x, 0)
> c <- apply(x, 2, stats::fft)[1:51,]
> expect_equal(a, c)
> ????????????????????????
>
> Here are the tests that gave me the errors:
>
> The test logs on win-builder
> https://win-builder.r-project.org/07586ios8AbL/00check.log
>
> Test logs on GitHub
> https://github.com/dipterix/ravetools/runs/3944874310?check_suite_focus=true
>
>
> ?????????????? Failed tests ??????????????
>   -- Failure (test-fftw.R:41:3): mvfftw_r2c --------------------------------------
>   `a` (`actual`) not equal to `c` (`expected`).
>
>   actual vs expected
>                                       [,1]                    [,2]                  [,3]                  [,4]                    ...
>   - actual[1, ]     10.8887367+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i ...
>   + expected[1, ]    0.0000000+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i...
>
> ????????????????????????
>
> The first columns are different, `actual` is the results I produced via `ravetools:::mvfftw_r2c`, and `expected` was produced by `stats::fft`
>
>
> Any help or attention is very much appreciated.
> Thanks,
> - Zhengjia
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Oct 20 11:26:21 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 20 Oct 2021 11:26:21 +0200
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
Message-ID: <24943.57533.175029.414837@stat.math.ethz.ch>

>>>>> GILLIBERT, Andre 
>>>>>     on Wed, 20 Oct 2021 08:10:00 +0000 writes:

    > Hello,
    > That sounds like a good diagnosis!
    > Indeed, R vectors are passed "by reference" to C code, but the semantic must be "by value", i.e. the C function must NOT change the contents of the vector, except in very specific cases.

    > A good program that has to work on a vector, must first duplicate the vector, unless the only reference to the vector is the reference inside the C function.
    > This can be tested by the MAYBE_REFERENCED() macro in Rinternals.h.

    > A good example can be found in the fft() function in src/library/stats/src/fourier.c in R source code:
    > switch (TYPEOF(z)) {
    > case INTSXP:
    > case LGLSXP:
    > case REALSXP:
    > z = coerceVector(z, CPLXSXP);
    > break;
    > case CPLXSXP:
    > if (MAYBE_REFERENCED(z)) z = duplicate(z);
    > break;
    > default:
    > error(_("non-numeric argument"));
    > }
    > PROTECT(z);

    > This code coerces non-complex vectors to complex. Since this makes a copy, there is no need to duplicate.
    > Complex vectors are duplicated, unless they are not referenced by anything but the fft() function.

    > Now, the z vector can be modified "in place" without inconsistency.

    > Properly using R vectors in C code is tricky. You have to understand.
    > 1) When you are allowed or not to modify vectors
    > 2) When to PROTECT()vectors
    > 3) How the garbage collector works and when it can trigger (answer : basically, when you call any internal R function)

    > Chapter 5 of "Writing R Extensions" documentation is quite extensive:
    > https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C

    > -- 
    > Sincerely
    > Andr? GILLIBERT

Thank you, Andr? , that's very good.

Just to state the obvious conclusion:

If Ben's suggestion is correct (and Andr? has explained *how*
that could happen) this would mean  a
SEVERE BUG in package ravetools's  mvfftw() function.

and it would have been (yet another) case of gaining speed by
killing correctness...

... but then ravetools  is not even a CRAN package, so why
should you dare to use it for anything serious ?

... yes, being grouchy ..

    > -----Message d'origine-----
    > De?: R-devel <r-devel-bounces at r-project.org> De la part de Ben Bolker
    > Envoy??: mercredi 20 octobre 2021 03:27
    > ??: r-devel at r-project.org
    > Objet?: Re: [Rd] stats::fft produces inconsistent results


    > This is a long shot, but here's a plausible scenario:

    > as part of its pipeline, ravetools::mvfftw computes the mean of the
    > input vector **and then centers it to a mean of zero** (intentionally or
    > accidentally?)

    > because variables are passed to compiled code by reference (someone
    > can feel free to correct my terminology), this means that the original
    > vector in R now has a mean of zero

    > the first element of fft() is mean(x)*length(x), so if mean(x) has
    > been forced to zero, that would explain your issue.

    > I don't know about the non-reproducibility part.

    > On 10/19/21 7:06 PM, Dipterix Wang wrote:
    >> Dear R-devel Team,
    >> 
    >> I'm developing a neuroscience signal pipeline package in R (https://github.com/dipterix/ravetools) and I noticed a weird issue that failed my unit test.
    >> 
    >> Basically I was trying to use `fftw3` library to implement fast multivariate fft function in C++. When I tried to compare my results with stats::fft, the test result showed the first element of **expected** (which was produced by stats::fft) was zero, which, I am pretty sure, is wrong, and I can confirm that my function produces correct results.
    >> 
    >> However, somehow I couldn?t reproduce this issue on my personal computer (osx, M1, R4.1.1), the error simply went away.
    >> 
    >> The catch is my function produced consistent and correct results but stats::fft was not. This does not mean `stats::fft` has bugs. Instead, I suspect there could be some weird interactions between my code and stats::fft at C/C++ level, but I couldn?t figure it out why.
    >> 
    >> +++ Details:
    >> 
    >> Here?s the code I used for the test:
    >> 
    >> https://github.com/dipterix/ravetools/blob/4dc35d64763304aff869d92dddad38a7f2b30637/tests/testthat/test-fftw.R#L33-L41
    >> 
    >> ????????Test code????????
    >> set.seed(1)
    >> x <- rnorm(1000)
    >> dim(x) <- c(100,10)
    >> a <- ravetools:::mvfftw_r2c(x, 0)
    >> c <- apply(x, 2, stats::fft)[1:51,]
    >> expect_equal(a, c)
    >> ????????????????????????
    >> 
    >> Here are the tests that gave me the errors:
    >> 
    >> The test logs on win-builder
    >> https://win-builder.r-project.org/07586ios8AbL/00check.log
    >> 
    >> Test logs on GitHub
    >> https://github.com/dipterix/ravetools/runs/3944874310?check_suite_focus=true
    >> 
    >> 
    >> ?????????????? Failed tests ??????????????
    >> -- Failure (test-fftw.R:41:3): mvfftw_r2c --------------------------------------
    >> `a` (`actual`) not equal to `c` (`expected`).
    >> 
    >> actual vs expected
    >> [,1]                    [,2]                  [,3]                  [,4]                    ...
    >> - actual[1, ]     10.8887367+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i ...
    >> + expected[1, ]    0.0000000+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i...
    >> 
    >> ????????????????????????
    >> 
    >> The first columns are different, `actual` is the results I produced via `ravetools:::mvfftw_r2c`, and `expected` was produced by `stats::fft`
    >> 
    >> 
    >> Any help or attention is very much appreciated.
    >> Thanks,
    >> - Zhengjia


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Oct 20 11:32:07 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 20 Oct 2021 11:32:07 +0200
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <24943.57533.175029.414837@stat.math.ethz.ch>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
 <24943.57533.175029.414837@stat.math.ethz.ch>
Message-ID: <24943.57879.154680.523491@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Wed, 20 Oct 2021 11:26:21 +0200 writes:

[............]

    > Thank you, Andr? , that's very good.

    > Just to state the obvious conclusion:

    > If Ben's suggestion is correct (and Andr? has explained *how*
    > that could happen) this would mean  a
    > SEVERE BUG in package ravetools's  mvfftw() function.

    > and it would have been (yet another) case of gaining speed by
    > killing correctness...

    > ... but then ravetools  is not even a CRAN package, so why
    > should you dare to use it for anything serious ?

    > ... yes, being grouchy ..

which I should rather not be.

Dipterix Wang *did* say initially that he is currently
developing ravetools so it's very reasonabl this is not yet a
CRAN package..

Best,
Martin

    >> -----Message d'origine-----
    >> De?: R-devel <r-devel-bounces at r-project.org> De la part de Ben Bolker
    >> Envoy??: mercredi 20 octobre 2021 03:27
    >> ??: r-devel at r-project.org
    >> Objet?: Re: [Rd] stats::fft produces inconsistent results


    >> This is a long shot, but here's a plausible scenario:

    >> as part of its pipeline, ravetools::mvfftw computes the mean of the
    >> input vector **and then centers it to a mean of zero** (intentionally or
    >> accidentally?)

    >> because variables are passed to compiled code by reference (someone
    >> can feel free to correct my terminology), this means that the original
    >> vector in R now has a mean of zero

    >> the first element of fft() is mean(x)*length(x), so if mean(x) has
    >> been forced to zero, that would explain your issue.

    >> I don't know about the non-reproducibility part.

    >> On 10/19/21 7:06 PM, Dipterix Wang wrote:
    >>> Dear R-devel Team,
    >>> 
    >>> I'm developing a neuroscience signal pipeline package in R (https://github.com/dipterix/ravetools) and I noticed a weird issue that failed my unit test.
    >>> 
    >>> Basically I was trying to use `fftw3` library to implement fast multivariate fft function in C++. When I tried to compare my results with stats::fft, the test result showed the first element of **expected** (which was produced by stats::fft) was zero, which, I am pretty sure, is wrong, and I can confirm that my function produces correct results.
    >>> 
    >>> However, somehow I couldn?t reproduce this issue on my personal computer (osx, M1, R4.1.1), the error simply went away.
    >>> 
    >>> The catch is my function produced consistent and correct results but stats::fft was not. This does not mean `stats::fft` has bugs. Instead, I suspect there could be some weird interactions between my code and stats::fft at C/C++ level, but I couldn?t figure it out why.
    >>> 
    >>> +++ Details:
    >>> 
    >>> Here?s the code I used for the test:
    >>> 
    >>> https://github.com/dipterix/ravetools/blob/4dc35d64763304aff869d92dddad38a7f2b30637/tests/testthat/test-fftw.R#L33-L41
    >>> 
    >>> ????????Test code????????
    >>> set.seed(1)
    >>> x <- rnorm(1000)
    >>> dim(x) <- c(100,10)
    >>> a <- ravetools:::mvfftw_r2c(x, 0)
    >>> c <- apply(x, 2, stats::fft)[1:51,]
    >>> expect_equal(a, c)
    >>> ????????????????????????
    >>> 
    >>> Here are the tests that gave me the errors:
    >>> 
    >>> The test logs on win-builder
    >>> https://win-builder.r-project.org/07586ios8AbL/00check.log
    >>> 
    >>> Test logs on GitHub
    >>> https://github.com/dipterix/ravetools/runs/3944874310?check_suite_focus=true
    >>> 
    >>> 
    >>> ?????????????? Failed tests ??????????????
    >>> -- Failure (test-fftw.R:41:3): mvfftw_r2c --------------------------------------
    >>> `a` (`actual`) not equal to `c` (`expected`).
    >>> 
    >>> actual vs expected
    >>> [,1]                    [,2]                  [,3]                  [,4]                    ...
    >>> - actual[1, ]     10.8887367+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i ...
    >>> + expected[1, ]    0.0000000+ 0.0000000i  -3.7808077+ 0.0000000i   2.967354+ 0.000000i   5.160186+ 0.000000i...
    >>> 
    >>> ????????????????????????
    >>> 
    >>> The first columns are different, `actual` is the results I produced via `ravetools:::mvfftw_r2c`, and `expected` was produced by `stats::fft`
    >>> 
    >>> 
    >>> Any help or attention is very much appreciated.
    >>> Thanks,
    >>> - Zhengjia

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From edd @end|ng |rom deb|@n@org  Wed Oct 20 15:31:19 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Wed, 20 Oct 2021 08:31:19 -0500
Subject: [Rd] Environment setting _R_CHECK_DEPENDS_ONLY_='true'
In-Reply-To: <d3a5e0b2-3687-31ec-814f-ca301b818e26@fau.de>
References: <7C83324B-EB19-46AB-BC08-6E8A8FCB65E5@anu.edu.au>
 <d3a5e0b2-3687-31ec-814f-ca301b818e26@fau.de>
Message-ID: <24944.6695.39047.303485@rob.eddelbuettel.com>


On 20 October 2021 at 09:31, Sebastian Meyer wrote:
| If you set the environment variable inside a running R process, it will 
| only affect that process and child processes, but not an independent R 
| process launched from a shell like you seem to be doing here:

Yes. That is somewhat common, if obscure, knowledge by those bitten before.

Maybe a line or two could be / should be added to the docs to that effect?

| How to set environment variables is system-specific. On a Unix-like 
| system, you could use the command
| 
| _R_CHECK_DEPENDS_ONLY_=true  R CMD check qra_0.2.4.tar.gz
| 
| to set the environment variable for this R process.
| See, e.g., https://en.wikipedia.org/wiki/Environment_variable.

R does have hooks for this, I had these for a few years now:

  ~/.R/check.Renviron
  ~/.R/check.Renviron-Rdevel

Again, might be worthwhile documenting it in the Inst+Admin manual (if it
isn' already, I don't recall right now).

Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From m|ch@|2992 @end|ng |rom gm@||@com  Wed Oct 20 16:31:08 2021
From: m|ch@|2992 @end|ng |rom gm@||@com (=?UTF-8?Q?Micha=C5=82_Bojanowski?=)
Date: Wed, 20 Oct 2021 16:31:08 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
Message-ID: <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>

Hello Tomas,

Yes, that's accurate although rather terse, which is perhaps the
reason why I did not realize it applies to my case.

How about adding something in the direction of:

1. Continuing the cited paragraph with:
In particular, on Windows it may be necessary to quote references to
existing environment variables, especially those containing file paths
(which include backslashes). For example: `"${WINVAR}"`.

2. Add an example (not run):

# On Windows do quote references to variables containing paths, e.g.:
# If APPDATA=C:\Users\foobar\AppData\Roaming
# to point to a library tree inside APPDATA in .Renviron use
R_LIBS_USER="${APPDATA}"/R-library

Incidentally the last example is on backslashes too.

What do you think?

On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
>
> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
> > Perhaps a small update to ?.Renviron would be in order to mention that...
>
> Would you have a more specific suggestion how to update the
> documentation? Please note that it already says
>
> "?value? is then processed in a similar way to a Unix shell: in
> particular the outermost level of (single or double) quotes is stripped,
> and backslashes are removed except inside quotes."
>
> Thanks,
> Tomas
>
> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
> >> Thank you all!
> >> Michal
> >>
> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >>> Sorry for the noise! I wasn't supposed to send my previous message.
> >>>
> >>> On Fri, 15 Oct 2021 16:44:28 +0200
> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >>>
> >>>> AVAR=${APPDATA}/foo/bar
> >>>>
> >>>> Which is a documented way of referring to existing environment
> >>>> variables. Now, with that in R I'm getting:
> >>>>
> >>>> Sys.getenv("APPDATA")    # That works OK
> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> >>>>
> >>>> so OK, but:
> >>>>
> >>>> Sys.getenv("AVAR")
> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
> >>> but not if they are encountered inside quotes:
> >>>
> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
> >>>
> >>> Would AVAR="${APPDATA}"/foo/bar work?
> >>>
> >>> --
> >>> Best regards,
> >>> Ivan
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From ht @end|ng |rom he@therturner@net  Wed Oct 20 17:08:49 2021
From: ht @end|ng |rom he@therturner@net (Heather Turner)
Date: Wed, 20 Oct 2021 16:08:49 +0100
Subject: [Rd] R Contribution Working Group
Message-ID: <58228a08-8aa9-418c-9096-984eb810c1ae@www.fastmail.com>

Dear All,

The R Contribution Working Group was set up last year with the purpose of encouraging new contributors to R core, especially from currently under-represented groups. More detail here: https://forwards.github.io/rcontribution/working-group.

The group has been meeting approximately once a month with representatives from R Core, Forwards, R-Ladies, MiR and the general R contributor community (from aspiring to experienced contributors).  We currently alternate between a Americas-friendly time and a Europe/Middle East/Africa-friendly time. Anyone supporting the aims of the group is welcome to attend when they can.

The next meeting will be will be Tuesday, October 26, 2021, 20:00-21:00 UTC.

The agenda is here: https://hackmd.io/GzIGWM4ZTdmM3B3q6C24RA?edit - feel free to add items for us to discuss (time allowing!).

Join Zoom Meeting
https://us02web.zoom.us/j/88955759010?pwd=VW9IR2p1eVRicHc5czJSZ1VkUDB6QT09 (ID: 88955759010, passcode: KOI9wWzh).

Best wishes,

Heather


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Oct 20 17:55:15 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 20 Oct 2021 08:55:15 -0700
Subject: [Rd] BUG?: R CMD check with --as-cran *disables* checks for unused
 imports otherwise performed
Message-ID: <CAFDcVCQtwySG8HpbOABqoKJ=B7kiQpj57SaU_hzQ=hSWDDa_GA@mail.gmail.com>

ISSUE:

Using 'R CMD check' with --as-cran,
set_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_=TRUE, whereas the
default is FALSE, which you get if you don't add --as-cran.
I would expect --as-cran to check more things and more be conservative
than without.  So, is this behavior a mistake?  Could it be a thinko
around the negating "IGNORE", and the behavior is meant to be vice
verse?

Example:

$ R CMD check QDNAseq_1.29.4.tar.gz
...
* using R version 4.1.1 (2021-08-10)
* using platform: x86_64-pc-linux-gnu (64-bit)
...
* checking dependencies in R code ... NOTE
Namespace in Imports field not imported from: ?future?
  All declared Imports should be used.

whereas, if I run with --as-cran, I don't get that NOTE;

$ R CMD check --as-cran QDNAseq_1.29.4.tar.gz
...
* checking dependencies in R code ... OK


TROUBLESHOOTING:

In src/library/tools/R/check.R [1], the following is set if --as-cran is used:

  Sys.setenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_" = "TRUE")

whereas, if not set, the default is:

ignore_unused_imports <-
config_val_to_logical(Sys.getenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_",
"FALSE"))

[1] https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/check.R#L6335
[2] https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/QC.R#L5954-L5956

/Henrik


From d@v|@ @end|ng |rom r@tud|o@com  Wed Oct 20 18:30:41 2021
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Wed, 20 Oct 2021 12:30:41 -0400
Subject: [Rd] as.list.factor() should shift input names onto the resulting
 list
Message-ID: <CABzLhzxentZR2EDyML_o4Pv9D1WOtaxYEWYRpDk=1FMVKytGug@mail.gmail.com>

Hi all,

The current implementation of as.list.factor() looks like:

as.list.factor
#> function (x, ...)
#> {
#>     res <- vector("list", length(x))
#>     for (i in seq_along(x)) res[[i]] <- x[i]
#>     res
#> }
#> <bytecode: 0x7fa11d146cc0>
#> <environment: namespace:base>

I believe this is incorrect, as names of `x` are not shifted onto `res`.
This results in the behavior shown below, which I am fairly certain is
incorrect (compared to Date methods and other classes). It also affects the
output of lapply().

I believe that as.list.factor() could be rewritten to be more like either
as.list.Date() or as.list.POSIXct(), which would fix the issue.

x <- factor(c("f1", "f2"))
names(x) <- c("a", "b")

y <- as.Date("2019-01-01") + 0:1
names(y) <- c("a", "b")

# Incorrect behavior:
# - Names are kept on inner elements
# - Names are not propagated onto resulting list
as.list(x)
#> [[1]]
#>  a
#> f1
#> Levels: f1 f2
#>
#> [[2]]
#>  b
#> f2
#> Levels: f1 f2

# Correct behavior:
# - Names are stripped from inner elements
# - Names are propagated onto resulting list
as.list(y)
#> $a
#> [1] "2019-01-01"
#>
#> $b
#> [1] "2019-01-02"

# The factor behavior breaks the lapply() invariant that names
# of `X` will be propagated onto the result
lapply(x, identity)
#> [[1]]
#>  a
#> f1
#> Levels: f1 f2
#>
#> [[2]]
#>  b
#> f2
#> Levels: f1 f2

# This works correctly
lapply(y, identity)
#> $a
#> [1] "2019-01-01"
#>
#> $b
#> [1] "2019-01-02"

Thanks,
Davis Vaughan

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Oct 20 20:22:17 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 20 Oct 2021 11:22:17 -0700
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
Message-ID: <CAFDcVCQ-4Sbyhu__=T-a=cx+FHMD5Poszyx7C-+zY=S+ZqTbkw@mail.gmail.com>

Two comments/suggestions:

1. What about recommending to always quote the value in Renviron
files, e.g. ABC="Hello world" and DEF="${APPDATA}/R-library"?  This
should a practice that works on all platforms.

2. What about having readRenviron() escapes strings it imports via
environment variables?  See example below.  Is there ever a use case
where someone wants/needs, or even rely on, the current behavior? (I
would even like to argue the current behavior is a design bug that
should be fixed.)  As an analogue from the shell world, Bash escapes
its input.

To illustrate the latter, with:

A=C:\\ABC
B=${A}
C="${A}"

or equivalently:

A="C:\ABC"
B=${A}
C="${A}"

we currently get:

$ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
        A         B         C
"C:\\ABC"   "C:ABC" "C:\\ABC"

If base::readRenviron() would escape "input" environment variables, we
would get identical values for both 'B' and 'C', which I think is what
most people would expect.

To be clear, this is a problem that occur on all platforms, but it's
more likely to be revealed on MS Windows since paths uses backslashes,
but you could image a Linux user using something like
A="Hello\nworld\n" and would also be surprised about the above
behavior, when they end up with B="Hellonworldn".

/Henrik

On Wed, Oct 20, 2021 at 7:31 AM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>
> Hello Tomas,
>
> Yes, that's accurate although rather terse, which is perhaps the
> reason why I did not realize it applies to my case.
>
> How about adding something in the direction of:
>
> 1. Continuing the cited paragraph with:
> In particular, on Windows it may be necessary to quote references to
> existing environment variables, especially those containing file paths
> (which include backslashes). For example: `"${WINVAR}"`.
>
> 2. Add an example (not run):
>
> # On Windows do quote references to variables containing paths, e.g.:
> # If APPDATA=C:\Users\foobar\AppData\Roaming
> # to point to a library tree inside APPDATA in .Renviron use
> R_LIBS_USER="${APPDATA}"/R-library
>
> Incidentally the last example is on backslashes too.
>
> What do you think?
>
> On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >
> >
> > On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
> > > Perhaps a small update to ?.Renviron would be in order to mention that...
> >
> > Would you have a more specific suggestion how to update the
> > documentation? Please note that it already says
> >
> > "?value? is then processed in a similar way to a Unix shell: in
> > particular the outermost level of (single or double) quotes is stripped,
> > and backslashes are removed except inside quotes."
> >
> > Thanks,
> > Tomas
> >
> > > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
> > >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
> > >> Thank you all!
> > >> Michal
> > >>
> > >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> > >>> Sorry for the noise! I wasn't supposed to send my previous message.
> > >>>
> > >>> On Fri, 15 Oct 2021 16:44:28 +0200
> > >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
> > >>>
> > >>>> AVAR=${APPDATA}/foo/bar
> > >>>>
> > >>>> Which is a documented way of referring to existing environment
> > >>>> variables. Now, with that in R I'm getting:
> > >>>>
> > >>>> Sys.getenv("APPDATA")    # That works OK
> > >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> > >>>>
> > >>>> so OK, but:
> > >>>>
> > >>>> Sys.getenv("AVAR")
> > >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> > >>> Hmm, a function called by readRenviron does seem to remove backslashes,
> > >>> but not if they are encountered inside quotes:
> > >>>
> > >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
> > >>>
> > >>> Would AVAR="${APPDATA}"/foo/bar work?
> > >>>
> > >>> --
> > >>> Best regards,
> > >>> Ivan
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From d|pter|x@w@ng @end|ng |rom gm@||@com  Wed Oct 20 22:00:49 2021
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Wed, 20 Oct 2021 16:00:49 -0400
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <24943.57879.154680.523491@stat.math.ethz.ch>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
 <24943.57533.175029.414837@stat.math.ethz.ch>
 <24943.57879.154680.523491@stat.math.ethz.ch>
Message-ID: <DD97681A-82B8-45A0-8294-6A2FB0099952@gmail.com>

Wow, you guys are amazing!

>>> as part of its pipeline, ravetools::mvfftw computes the mean of the
>>> input vector **and then centers it to a mean of zero** (intentionally or
>>> accidentally?)
> 
>>> because variables are passed to compiled code by reference (someone
>>> can feel free to correct my terminology), this means that the original
>>> vector in R now has a mean of zero


I didn?t center the input vector in my code. The data was fed ?as-is? into FFTW3. My guess is FFTW3 internally center the data. It could be that FFTW3 library behave differently on different platforms, which could explain the reproducibility issue. 

>>> "Indeed, R vectors are passed "by reference" to C code, but the semantic must be "by value", i.e. the C function must NOT change the contents of the vector, except in very specific cases.?


CRAN has already had fftw and fftwtools, the issue is the data I?m targeting at are at GB-level, copying the vectors can be memory inefficient or even use up memories. The strategy of ravetools is to import signals from local files, fft, then directly write to disk. So only one reference will be used and modifying in-place is on purpose. In fact, and the fft functions I created are not intended to be used directly by users.

However, I should've been very cautious when using these functions. This is my fault. I?ll check the whole package to make sure only one reference is used or otherwise the vectors will be copied.

>>> This can be tested by the MAYBE_REFERENCED() macro in Rinternals.h.


Nice to learn! I?ll add it to my code.

>>> Properly using R vectors in C code is tricky. You have to understand.
>>> 1) When you are allowed or not to modify vectors
>>> 2) When to PROTECT()vectors
>>> 3) How the garbage collector works and when it can trigger (answer : basically, when you call any internal R function)
>>> Chapter 5 of "Writing R Extensions" documentation is quite extensive:
>>>  https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C <https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C>

Indeed, I found myself often confused about when to PROTECT and when not. 

>>>> ... but then ravetools  is not even a CRAN package, so why should you dare to use it for anything serious ?

Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.
But it?s good to be rigorous. Sooner or later I'll have to face these problems. It?s better to make mistakes before having made many.

Thanks y?all!

Best,
- Dipterix Wang


> On Oct 20, 2021, at 5:32 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Martin Maechler 
>>>>>>    on Wed, 20 Oct 2021 11:26:21 +0200 writes:
> 
> [............]
> 
>> Thank you, Andr? , that's very good.
> 
>> Just to state the obvious conclusion:
> 
>> If Ben's suggestion is correct (and Andr? has explained *how*
>> that could happen) this would mean  a
>> SEVERE BUG in package ravetools's  mvfftw() function.
> 
>> and it would have been (yet another) case of gaining speed by
>> killing correctness...
> 
>> ... but then ravetools  is not even a CRAN package, so why
>> should you dare to use it for anything serious ?
> 
>> ... yes, being grouchy ..
> 
> which I should rather not be.
> 
> Dipterix Wang *did* say initially that he is currently
> developing ravetools so it's very reasonabl this is not yet a
> CRAN package..
> 
> Best,
> Martin
> 


	[[alternative HTML version deleted]]


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Thu Oct 21 12:32:34 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Thu, 21 Oct 2021 10:32:34 +0000
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <DD97681A-82B8-45A0-8294-6A2FB0099952@gmail.com>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
 <24943.57533.175029.414837@stat.math.ethz.ch>
 <24943.57879.154680.523491@stat.math.ethz.ch>
 <DD97681A-82B8-45A0-8294-6A2FB0099952@gmail.com>
Message-ID: <79f67ba361fd4c51a1df243797319b0b@chu-rouen.fr>

> Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.


Fortunately, you did not get offensed. :)


This is nice to have a large community of developers for R packages, even if, sometimes, buggy packages are annoying R developers because any small change in R may "break" them even though they were actually broken from the begining.


> Indeed, I found myself often confused about when to PROTECT and when not.



A (relatively) quick explanation.

There are several ?pools? of data objects that have different rules. The most common ?pool? is the pool of garbage collectable R objects, that can be allocated with allocVector and is passed from R to C code and vice versa. Another pool is the malloc/free pool, that works with explicit allocation/deallocation. R does not modify the malloc/free implementation in any way, and memory leaks may happen. Operating systems may have other pools of memory (e.g. mmap'ed memory) that are not handled by R either. There is also a transient storage (R_alloc/vmaxset/vmaxget) that is automatically freed when returning from C to R, and should be used for temporary storage but not for objects returned to R code.



The PROTECT system is needed for garbage collectable objects.

The garbage collector may trigger whenever a R internal function is called. Typically, when some memory is internally allocated.

The garbage collector frees objects that are neither referenced directly nor indirectly from R code and from the PROTECT stack.

The PROTECT stack is used by C code to make sure objects that are not yet (or will never be) referenced by R code, are not destroyed when the garbage collector runs.



The functions allocating new R objects, such as allocVector(), but also coerceVector(), duplicate(),return unprotected objects, that may be destroyed the next time an internal R function is called, unless it is explicitly PROTECT'ed before. Indeed, such objects would have no reference from R code and so, would be deleted.


The PROTECT stack must be balanced on a call from R to a C function. There must be as many UNPROTECT'ions than PROTECT'ions.

The typical C code PROTECTs any object allocated as soon as it is allocated (e.g. call to allocVector or coerceVector). It UNPROTECTs temporary objects to "free" them (the actual memory release may be delayed to the next garbage collection). It UNPROTECTs the object it returns to R code. Indeed, in pure C code, there will be no garbage collection between the time the object is UNPROTECTed and the time R grabs the object. You must be very careful if you are using C++, because destructors must not call any R internal function that may trigger a garbage collection.
The arguments to the C code, do not have to be PROTECT'ed, unless they are re-allocated. For instance, it is frequent to call coerceVector or arguments and re-assign them to the C variable that represents the argument. The new object must be PROTECT'ed.


Actually, you do not need to *directly* PROTECT all objects that are allocated in the C function, but you must make sure that all objects are *indirectly* PROTECT'ed. For instance, you may allocate a VECSXP (a "list" in R) and fill the slots with newly allocated objects. You only need to PROTECT the VECSXP, since its slots are indirectly protected.


If you have any doubt, it is not a bug to over-PROTECT objects. It may slightly slow down garbage collection and use space on the PROTECTion stack, but that is rarely a big deal. You should only avoid that when that would lead to thousands or millions of protections.


As I said, the PROTECT stack must be balanced between the entry and exit of the C code. This is not a problem for 99% of functions that free all the memory they use internally except the object that is returned. Sometimes, some "background" memory, hidden to R code, may have to be allocated for more time. A call to R_PreserveObject protects the object, even after the C code returns to R, until R_ReleaseObject is called. Without an explicit call to R_ReleaseObject, memory is leaked!


There is another mechanism in R that must be known. If you call any R function from C code, or any internal R function that may fail with an error, or any internal R function that can be stopped by the user (see R_CheckUserInterrupt), then, R may call a longjmp to exit all the C code. This is very much incompatible with C++ exceptions or constructors/destructors. Rcpp can avoid, to some extent, that problem.


With C code, this means that some malloc'ed memory or allocated resources (file descriptors, sockets, etc.) may be leaked unless something is done to prevent that. All PROTECT'ed objects are automatically unprotected, so there is no problem with memory leak of garbage collectable objects. There is a R_UnwindProtect() mechanism to free temporary resources (e.g. a socket you allocated) when a longjmp is triggered. Non-memory resources (e.g. a socket) returned to R should use the R_MakeExternalPtr() mechanism to make sure that, when the memory is freed by the garbage collector, the resource is also freed.


"Writing R extensions" contains more extensive documentation, but I hope that my quick description of the system will make it easier to understand the extensive documentation.


 --

Sinc?rement

Andr? GILLIBERT



De : Dipterix Wang <dipterix.wang at gmail.com>
Envoy? : mercredi 20 octobre 2021 22:01
? : Martin Maechler <maechler at stat.math.ethz.ch>; GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr>; bbolker at gmail.com
Cc : r-devel at r-project.org
Objet : Re: [Rd] stats::fft produces inconsistent results



ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. Merci de votre vigilance



Wow, you guys are amazing!



as part of its pipeline, ravetools::mvfftw computes the mean of the
input vector **and then centers it to a mean of zero** (intentionally or
accidentally?)



because variables are passed to compiled code by reference (someone
can feel free to correct my terminology), this means that the original
vector in R now has a mean of zero



I didn?t center the input vector in my code. The data was fed ?as-is? into FFTW3. My guess is FFTW3 internally center the data. It could be that FFTW3 library behave differently on different platforms, which could explain the reproducibility issue.



"Indeed, R vectors are passed "by reference" to C code, but the semantic must be "by value", i.e. the C function must NOT change the contents of the vector, except in very specific cases.?



CRAN has already had fftw and fftwtools, the issue is the data I?m targeting at are at GB-level, copying the vectors can be memory inefficient or even use up memories. The strategy of ravetools is to import signals from local files, fft, then directly write to disk. So only one reference will be used and modifying in-place is on purpose. In fact, and the fft functions I created are not intended to be used directly by users.



However, I should've been very cautious when using these functions. This is my fault. I?ll check the whole package to make sure only one reference is used or otherwise the vectors will be copied.



This can be tested by the MAYBE_REFERENCED() macro in Rinternals.h.



Nice to learn! I?ll add it to my code.



Properly using R vectors in C code is tricky. You have to understand.

1) When you are allowed or not to modify vectors

2) When to PROTECT()vectors

3) How the garbage collector works and when it can trigger (answer : basically, when you call any internal R function)

Chapter 5 of "Writing R Extensions" documentation is quite extensive:

 https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C



Indeed, I found myself often confused about when to PROTECT and when not.



... but then ravetools  is not even a CRAN package, so why should you dare to use it for anything serious ?



Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.

But it?s good to be rigorous. Sooner or later I'll have to face these problems. It?s better to make mistakes before having made many.



Thanks y?all!



Best,

- Dipterix Wang





On Oct 20, 2021, at 5:32 AM, Martin Maechler <maechler at stat.math.ethz.ch<mailto:maechler at stat.math.ethz.ch>> wrote:



Martin Maechler
   on Wed, 20 Oct 2021 11:26:21 +0200 writes:

[............]



Thank you, Andr? , that's very good.



Just to state the obvious conclusion:



If Ben's suggestion is correct (and Andr? has explained *how*
that could happen) this would mean  a
SEVERE BUG in package ravetools's  mvfftw() function.



and it would have been (yet another) case of gaining speed by
killing correctness...



... but then ravetools  is not even a CRAN package, so why
should you dare to use it for anything serious ?



... yes, being grouchy ..

which I should rather not be.

Dipterix Wang *did* say initially that he is currently
developing ravetools so it's very reasonabl this is not yet a
CRAN package..

Best,
Martin



	[[alternative HTML version deleted]]


From j3||d|ck @end|ng |rom gm@||@com  Thu Oct 21 05:08:44 2021
From: j3||d|ck @end|ng |rom gm@||@com (Jeffrey Dick)
Date: Thu, 21 Oct 2021 11:08:44 +0800
Subject: [Rd] 
 BUG?: R CMD check with --as-cran *disables* checks for unused
 imports otherwise performed
In-Reply-To: <CAFDcVCQtwySG8HpbOABqoKJ=B7kiQpj57SaU_hzQ=hSWDDa_GA@mail.gmail.com>
References: <CAFDcVCQtwySG8HpbOABqoKJ=B7kiQpj57SaU_hzQ=hSWDDa_GA@mail.gmail.com>
Message-ID: <CANBtttbbDsSkgvDseywE3vi7jxcPG6V4Es_JfP7tWZQm4LTyoA@mail.gmail.com>

FWIW, I also encountered this issue and posted on R-pkg-devel about it,
with no resolution at the time (May 2020). See "Dependencies NOTE lost with
--as-cran" (
https://stat.ethz.ch/pipermail/r-package-devel/2020q2/005467.html)

On Wed, Oct 20, 2021 at 11:55 PM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> ISSUE:
>
> Using 'R CMD check' with --as-cran,
> set_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_=TRUE, whereas the
> default is FALSE, which you get if you don't add --as-cran.
> I would expect --as-cran to check more things and more be conservative
> than without.  So, is this behavior a mistake?  Could it be a thinko
> around the negating "IGNORE", and the behavior is meant to be vice
> verse?
>
> Example:
>
> $ R CMD check QDNAseq_1.29.4.tar.gz
> ...
> * using R version 4.1.1 (2021-08-10)
> * using platform: x86_64-pc-linux-gnu (64-bit)
> ...
> * checking dependencies in R code ... NOTE
> Namespace in Imports field not imported from: ?future?
>   All declared Imports should be used.
>
> whereas, if I run with --as-cran, I don't get that NOTE;
>
> $ R CMD check --as-cran QDNAseq_1.29.4.tar.gz
> ...
> * checking dependencies in R code ... OK
>
>
> TROUBLESHOOTING:
>
> In src/library/tools/R/check.R [1], the following is set if --as-cran is
> used:
>
>   Sys.setenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_" = "TRUE")
>
> whereas, if not set, the default is:
>
> ignore_unused_imports <-
>
> config_val_to_logical(Sys.getenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_",
> "FALSE"))
>
> [1]
> https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/check.R#L6335
> [2]
> https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/QC.R#L5954-L5956
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 21 17:18:30 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 21 Oct 2021 17:18:30 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
Message-ID: <24945.33990.369010.718929@stat.math.ethz.ch>

>>>>> Micha? Bojanowski 
>>>>>     on Wed, 20 Oct 2021 16:31:08 +0200 writes:

    > Hello Tomas,
    > Yes, that's accurate although rather terse, which is perhaps the
    > reason why I did not realize it applies to my case.

    > How about adding something in the direction of:

    > 1. Continuing the cited paragraph with:
    > In particular, on Windows it may be necessary to quote references to
    > existing environment variables, especially those containing file paths
    > (which include backslashes). For example: `"${WINVAR}"`.

    > 2. Add an example (not run):

    > # On Windows do quote references to variables containing paths, e.g.:
    > # If APPDATA=C:\Users\foobar\AppData\Roaming
    > # to point to a library tree inside APPDATA in .Renviron use
    > R_LIBS_USER="${APPDATA}"/R-library

    > Incidentally the last example is on backslashes too.


    > What do you think?

I agree that adding an example really helps a lot in such cases,
in my experience, notably if it's precise enough to be used +/- directly.



    > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
    >> 
    >> 
    >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
    >> > Perhaps a small update to ?.Renviron would be in order to mention that...
    >> 
    >> Would you have a more specific suggestion how to update the
    >> documentation? Please note that it already says
    >> 
    >> "?value? is then processed in a similar way to a Unix shell: in
    >> particular the outermost level of (single or double) quotes is stripped,
    >> and backslashes are removed except inside quotes."
    >> 
    >> Thanks,
    >> Tomas
    >> 
    >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
    >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
    >> >> Thank you all!
    >> >> Michal
    >> >>
    >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
    >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
    >> >>>
    >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
    >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
    >> >>>
    >> >>>> AVAR=${APPDATA}/foo/bar
    >> >>>>
    >> >>>> Which is a documented way of referring to existing environment
    >> >>>> variables. Now, with that in R I'm getting:
    >> >>>>
    >> >>>> Sys.getenv("APPDATA")    # That works OK
    >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
    >> >>>>
    >> >>>> so OK, but:
    >> >>>>
    >> >>>> Sys.getenv("AVAR")
    >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
    >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
    >> >>> but not if they are encountered inside quotes:
    >> >>>
    >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
    >> >>>
    >> >>> Would AVAR="${APPDATA}"/foo/bar work?
    >> >>>
    >> >>> --
    >> >>> Best regards,
    >> >>> Ivan
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From d|pter|x@w@ng @end|ng |rom gm@||@com  Thu Oct 21 22:26:14 2021
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Thu, 21 Oct 2021 16:26:14 -0400
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <79f67ba361fd4c51a1df243797319b0b@chu-rouen.fr>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
 <24943.57533.175029.414837@stat.math.ethz.ch>
 <24943.57879.154680.523491@stat.math.ethz.ch>
 <DD97681A-82B8-45A0-8294-6A2FB0099952@gmail.com>
 <79f67ba361fd4c51a1df243797319b0b@chu-rouen.fr>
Message-ID: <A69E1CFD-B231-4509-B906-257E171886CF@gmail.com>

Thank you for such detailed and plain explanation. It is much clearer to me now w.r.t. the R internal memory management and how PROTECT should be used. 

Also after diving into the documentation of FFTW3 library, I think I found why the data was centered.

https://www.fftw.org/fftw3_doc/Planner-Flags.html

Basically 
1. FFTW3 modifies the input data by default 
2. one has to initialize the data after planning fft (except for some special situations). This ?subtle? detail is buried in their documentation and is very hard to debug once a mistake is made. 

The second one actually causes CRAN package fftwtools to produce inconsistent results on osx (https://github.com/krahim/fftwtools/issues/15)

Best,
Dipterix

> On Oct 21, 2021, at 6:32 AM, GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr> wrote:
> 
> > Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.
> 
> Fortunately, you did not get offensed. :)
> 
> This is nice to have a large community of developers for R packages, even if, sometimes, buggy packages are annoying R developers because any small change in R may "break" them even though they were actually broken from the begining.
> 
> > Indeed, I found myself often confused about when to PROTECT and when not. 
>  
> A (relatively) quick explanation.
> There are several ?pools? of data objects that have different rules. The most common ?pool? is the pool of garbage collectable R objects, that can be allocated with allocVector and is passed from R to C code and vice versa. Another pool is the malloc/free pool, that works with explicit allocation/deallocation. R does not modify the malloc/free implementation in any way, and memory leaks may happen. Operating systems may have other pools of memory (e.g. mmap'ed memory) that are not handled by R either. There is also a transient storage (R_alloc/vmaxset/vmaxget) that is automatically freed when returning from C to R, and should be used for temporary storage but not for objects returned to R code.
>  
> The PROTECT system is needed for garbage collectable objects.
> The garbage collector may trigger whenever a R internal function is called. Typically, when some memory is internally allocated.
> The garbage collector frees objects that are neither referenced directly nor indirectly from R code and from the PROTECT stack.
> The PROTECT stack is used by C code to make sure objects that are not yet (or will never be) referenced by R code, are not destroyed when the garbage collector runs.
>  
> The functions allocating new R objects, such as allocVector(), but also coerceVector(), duplicate(),return unprotected objects, that may be destroyed the next time an internal R function is called, unless it is explicitly PROTECT'ed before. Indeed, such objects would have no reference from R code and so, would be deleted.
>   
> The PROTECT stack must be balanced on a call from R to a C function. There must be as many UNPROTECT'ions than PROTECT'ions.
> 
> The typical C code PROTECTs any object allocated as soon as it is allocated (e.g. call to allocVector or coerceVector). It UNPROTECTs temporary objects to "free" them (the actual memory release may be delayed to the next garbage collection). It UNPROTECTs the object it returns to R code. Indeed, in pure C code, there will be no garbage collection between the time the object is UNPROTECTed and the time R grabs the object. You must be very careful if you are using C++, because destructors must not call any R internal function that may trigger a garbage collection.
> The arguments to the C code, do not have to be PROTECT'ed, unless they are re-allocated. For instance, it is frequent to call coerceVector or arguments and re-assign them to the C variable that represents the argument. The new object must be PROTECT'ed.
> 
> Actually, you do not need to *directly* PROTECT all objects that are allocated in the C function, but you must make sure that all objects are *indirectly* PROTECT'ed. For instance, you may allocate a VECSXP (a "list" in R) and fill the slots with newly allocated objects. You only need to PROTECT the VECSXP, since its slots are indirectly protected.
> 
> If you have any doubt, it is not a bug to over-PROTECT objects. It may slightly slow down garbage collection and use space on the PROTECTion stack, but that is rarely a big deal. You should only avoid that when that would lead to thousands or millions of protections.
> 
> As I said, the PROTECT stack must be balanced between the entry and exit of the C code. This is not a problem for 99% of functions that free all the memory they use internally except the object that is returned. Sometimes, some "background" memory, hidden to R code, may have to be allocated for more time. A call to R_PreserveObject protects the object, even after the C code returns to R, until R_ReleaseObject is called. Without an explicit call to R_ReleaseObject, memory is leaked!
> 
> There is another mechanism in R that must be known. If you call any R function from C code, or any internal R function that may fail with an error, or any internal R function that can be stopped by the user (see R_CheckUserInterrupt), then, R may call a longjmp to exit all the C code. This is very much incompatible with C++ exceptions or constructors/destructors. Rcpp can avoid, to some extent, that problem.
> 
> With C code, this means that some malloc'ed memory or allocated resources (file descriptors, sockets, etc.) may be leaked unless something is done to prevent that. All PROTECT'ed objects are automatically unprotected, so there is no problem with memory leak of garbage collectable objects. There is a R_UnwindProtect() mechanism to free temporary resources (e.g. a socket you allocated) when a longjmp is triggered. Non-memory resources (e.g. a socket) returned to R should use the R_MakeExternalPtr() mechanism to make sure that, when the memory is freed by the garbage collector, the resource is also freed.
> 
> "Writing R extensions" contains more extensive documentation, but I hope that my quick description of the system will make it easier to understand the extensive documentation.
> 
>  -- <>
> Sinc?rement
> Andr? GILLIBERT
>  
> De?: <> Dipterix Wang <dipterix.wang at gmail.com <mailto:dipterix.wang at gmail.com>> 
> Envoy? : mercredi 20 octobre 2021 22:01
> ? : Martin Maechler <maechler at stat.math.ethz.ch <mailto:maechler at stat.math.ethz.ch>>; GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr <mailto:Andre.Gillibert at chu-rouen.fr>>; bbolker at gmail.com <mailto:bbolker at gmail.com>
> Cc : r-devel at r-project.org <mailto:r-devel at r-project.org>
> Objet : Re: [Rd] stats::fft produces inconsistent results
>  
> ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. Merci de votre vigilance
>  
> Wow, you guys are amazing! 
>  
> as part of its pipeline, ravetools::mvfftw computes the mean of the
> input vector **and then centers it to a mean of zero** (intentionally or
> accidentally?)
> 
> 
> because variables are passed to compiled code by reference (someone
> can feel free to correct my terminology), this means that the original
> vector in R now has a mean of zero
>  
> I didn?t center the input vector in my code. The data was fed ?as-is? into FFTW3. My guess is FFTW3 internally center the data. It could be that FFTW3 library behave differently on different platforms, which could explain the reproducibility issue. 
>  
> "Indeed, R vectors are passed "by reference" to C code, but the semantic must be "by value", i.e. the C function must NOT change the contents of the vector, except in very specific cases.?
>  
> CRAN has already had fftw and fftwtools, the issue is the data I?m targeting at are at GB-level, copying the vectors can be memory inefficient or even use up memories. The strategy of ravetools is to import signals from local files, fft, then directly write to disk. So only one reference will be used and modifying in-place is on purpose. In fact, and the fft functions I created are not intended to be used directly by users.
>  
> However, I should've been very cautious when using these functions. This is my fault. I?ll check the whole package to make sure only one reference is used or otherwise the vectors will be copied.
>  
> This can be tested by the MAYBE_REFERENCED() macro in Rinternals.h.
>  
> Nice to learn! I?ll add it to my code.
>  
> Properly using R vectors in C code is tricky. You have to understand.
> 1) When you are allowed or not to modify vectors
> 2) When to PROTECT()vectors
> 3) How the garbage collector works and when it can trigger (answer : basically, when you call any internal R function)
> Chapter 5 of "Writing R Extensions" documentation is quite extensive:
>  https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C <https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C>
>  
> Indeed, I found myself often confused about when to PROTECT and when not. 
>  
> ... but then ravetools  is not even a CRAN package, so why should you dare to use it for anything serious ?
>  
> Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.
> But it?s good to be rigorous. Sooner or later I'll have to face these problems. It?s better to make mistakes before having made many.
>  
> Thanks y?all!
>  
> Best,
> - Dipterix Wang
>  
> 
> 
> On Oct 20, 2021, at 5:32 AM, Martin Maechler <maechler at stat.math.ethz.ch <mailto:maechler at stat.math.ethz.ch>> wrote:
>  
> Martin Maechler 
>    on Wed, 20 Oct 2021 11:26:21 +0200 writes:
> 
> [............]
> 
> 
> Thank you, Andr? , that's very good.
> 
> 
> Just to state the obvious conclusion:
> 
> 
> If Ben's suggestion is correct (and Andr? has explained *how*
> that could happen) this would mean  a
> SEVERE BUG in package ravetools's  mvfftw() function.
> 
> 
> and it would have been (yet another) case of gaining speed by
> killing correctness...
> 
> 
> ... but then ravetools  is not even a CRAN package, so why
> should you dare to use it for anything serious ?
> 
> 
> ... yes, being grouchy ..
> 
> which I should rather not be.
> 
> Dipterix Wang *did* say initially that he is currently
> developing ravetools so it's very reasonabl this is not yet a
> CRAN package..
> 
> Best,
> Martin


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 21 22:46:29 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 21 Oct 2021 16:46:29 -0400
Subject: [Rd] stats::fft produces inconsistent results
In-Reply-To: <A69E1CFD-B231-4509-B906-257E171886CF@gmail.com>
References: <B4AFA0CC-E150-4821-A84A-4A4F987EE636@gmail.com>
 <f44377c7-673c-b2e9-2ab0-00e4711cb310@gmail.com>
 <3b2419e95bc740ae98a47ba1a962b7d1@chu-rouen.fr>
 <24943.57533.175029.414837@stat.math.ethz.ch>
 <24943.57879.154680.523491@stat.math.ethz.ch>
 <DD97681A-82B8-45A0-8294-6A2FB0099952@gmail.com>
 <79f67ba361fd4c51a1df243797319b0b@chu-rouen.fr>
 <A69E1CFD-B231-4509-B906-257E171886CF@gmail.com>
Message-ID: <6ec8ec9d-4c83-ebb2-3932-952a406c5c02@gmail.com>

   Nice!

On 10/21/21 4:26 PM, Dipterix Wang wrote:
> Thank you for such detailed and plain explanation. It is much clearer to 
> me now w.r.t. the R internal memory management and how PROTECT should be 
> used.
> 
> Also after diving into the documentation of FFTW3 library, I think I 
> found why the data was centered.
> 
> https://www.fftw.org/fftw3_doc/Planner-Flags.html 
> <https://www.fftw.org/fftw3_doc/Planner-Flags.html>
> 
> Basically
> 1. FFTW3 modifies the input data by default
> 2. one has to initialize the data after planning fft (except for some 
> special situations). This ?subtle? detail is buried in their 
> documentation and is very hard to debug once a mistake is made.
> 
> The second one actually causes CRAN package fftwtools to produce 
> inconsistent results on osx 
> (https://github.com/krahim/fftwtools/issues/15 
> <https://github.com/krahim/fftwtools/issues/15>)
> 
> Best,
> Dipterix
> 
>> On Oct 21, 2021, at 6:32 AM, GILLIBERT, Andre 
>> <Andre.Gillibert at chu-rouen.fr <mailto:Andre.Gillibert at chu-rouen.fr>> 
>> wrote:
>>
>> > Haha, thanks : ) I guess I will probably be grouchy too if seeing so many people making the same mistakes again and again. It just happened to be me.
>>
>> Fortunately, you did not get offensed. :)
>>
>> This is nice to have a large community of developers for R packages, 
>> even if, sometimes, buggy packages are annoying R developers because 
>> any small change in R may "break" them even though they were actually 
>> broken from the begining.
>>
>> >Indeed, I found myself often confused about when to PROTECT and when not.
>>
>> A (relatively) quick explanation.
>> There are several ?pools? of data objects that have different rules. 
>> The most common ?pool? is the pool of garbage collectable R objects, 
>> that can be allocated with allocVector and is passed from R to C code 
>> and vice versa. Another pool is the malloc/free pool, that works with 
>> explicit allocation/deallocation. R does not modify the malloc/free 
>> implementation in any way, and memory leaks may happen. Operating 
>> systems may have other pools of memory (e.g. mmap'ed memory) that are 
>> not handled by R either. There is also a transient storage 
>> (R_alloc/vmaxset/vmaxget) that is automatically freed when returning 
>> from C to R, and should be used for temporary storage but not for 
>> objects returned to R code.
>>
>> The PROTECT system is needed for garbage collectable objects.
>> The garbage collector may trigger whenever a R internal function is 
>> called. Typically, when some memory is internally allocated.
>> The garbage collector frees objects that are neither referenced 
>> directly nor indirectly from R code and from the PROTECT stack.
>> The PROTECT stack is used by C code to make sure objects that are not 
>> yet (or will never be) referenced by R code, are not destroyed when 
>> the garbage collector runs.
>>
>> The functions allocating new R objects, such as allocVector(), but 
>> also coerceVector(), duplicate(),return unprotected objects, that may 
>> be destroyed the next time an internal R function is called, unless it 
>> is explicitly PROTECT'ed before. Indeed, such objects would have no 
>> reference from R code and so, would be deleted.
>>
>> The PROTECT stack must be balanced on a call from R to a C function. 
>> There must be as many UNPROTECT'ions than PROTECT'ions.
>>
>> The typical C code PROTECTs any object allocated as soon as it is 
>> allocated (e.g. call to allocVector or coerceVector). It UNPROTECTs 
>> temporary objects to "free" them (the actual memory release may be 
>> delayed to the next garbage collection). It UNPROTECTs the object it 
>> returns to R code. Indeed, in pure C code, there will be no garbage 
>> collection between the time the object is UNPROTECTed and the time R 
>> grabs the object. You must be very careful if you are using C++, 
>> because destructors must not call any R internal function that may 
>> trigger a garbage collection.
>> The arguments to the C code, do not have to be PROTECT'ed, unless they 
>> are re-allocated. For instance, it is frequent to call coerceVector or 
>> arguments and re-assign them to the C variable that represents the 
>> argument. The new object must be PROTECT'ed.
>>
>> Actually, you do not need to *directly* PROTECT all objects that are 
>> allocated in the C function, but you must make sure that all objects 
>> are *indirectly* PROTECT'ed. For instance, you may allocate a VECSXP 
>> (a "list" in R) and fill the slots with newly allocated objects. You 
>> only need to PROTECT the VECSXP, since its slots are indirectly protected.
>>
>> If you have any doubt, it is not a bug to over-PROTECT objects. It may 
>> slightly slow down garbage collection and use space on the PROTECTion 
>> stack, but that is rarely a big deal. You should only avoid that when 
>> that would lead to thousands or millions of protections.
>>
>> As I said, the PROTECT stack must be balanced between the entry and 
>> exit of the C code. This is not a problem for 99% of functions that 
>> free all the memory they use internally except the object that is 
>> returned. Sometimes, some "background" memory, hidden to R code, may 
>> have to be allocated for more time. A call to R_PreserveObject 
>> protects the object, even after the C code returns to R, until 
>> R_ReleaseObject is called. Without an explicit call to 
>> R_ReleaseObject,?memory is leaked!
>>
>> There is another mechanism in R that must be known. If you call any R 
>> function from C code, or any internal R function that may fail with an 
>> error, or any internal R function that can be stopped by the user (see 
>> R_CheckUserInterrupt), then, R may call a longjmp to exit all the C 
>> code. This is very much incompatible with C++ exceptions or 
>> constructors/destructors. Rcpp can avoid, to some extent, that problem.
>>
>> With C code, this means that some malloc'ed memory or allocated 
>> resources (file descriptors, sockets, etc.) may be leaked unless 
>> something is done to prevent that. All PROTECT'ed objects are 
>> automatically unprotected, so there is no problem with memory leak of 
>> garbage collectable objects. There is a R_UnwindProtect() mechanism to 
>> free temporary resources (e.g. a socket you allocated) when a longjmp 
>> is triggered. Non-memory resources (e.g. a socket) returned to R 
>> should use theR_MakeExternalPtr() mechanism to make sure that, when 
>> the memory is freed by the garbage collector, the resource is also freed.
>>
>> "Writing R extensions" contains more extensive documentation, but I 
>> hope that my quick description of the system will make it easier to 
>> understand the extensive documentation.
>>
>> --
>> Sinc?rement
>> Andr? GILLIBERT
>>
>> *De?:*Dipterix Wang <dipterix.wang at gmail.com 
>> <mailto:dipterix.wang at gmail.com>>
>> *Envoy??:*mercredi 20 octobre 2021 22:01
>> *??:*Martin Maechler <maechler at stat.math.ethz.ch 
>> <mailto:maechler at stat.math.ethz.ch>>; GILLIBERT, Andre 
>> <Andre.Gillibert at chu-rouen.fr 
>> <mailto:Andre.Gillibert at chu-rouen.fr>>;bbolker at gmail.com 
>> <mailto:bbolker at gmail.com>
>> *Cc?:*r-devel at r-project.org <mailto:r-devel at r-project.org>
>> *Objet?:*Re: [Rd] stats::fft produces inconsistent results
>>
>> ATTENTION:Cet e-mail provient d?une adresse mail ext?rieure au CHU de 
>> Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes 
>> ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. 
>> En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. 
>> Merci de votre vigilance
>>
>> Wow, you guys are amazing!
>>
>>             as part of its pipeline, ravetools::mvfftw computes the
>>             mean of the
>>             input vector **and then centers it to a mean of zero**
>>             (intentionally or
>>             accidentally?)
>>
>>
>>
>>             because variables are passed to compiled code by reference
>>             (someone
>>             can feel free to correct my terminology), this means that
>>             the original
>>             vector in R now has a mean of zero
>>
>> I didn?t center the input vector in my code. The data was fed ?as-is? 
>> into FFTW3. My guess is FFTW3 internally center the data. It could be 
>> that FFTW3 library behave differently on different platforms, which 
>> could explain the reproducibility issue.
>>
>>             /"Indeed, R vectors are passed "by reference" to C code,
>>             but the semantic must be "by value", i.e. the C function
>>             must NOT change the contents of the vector, except in very
>>             specific cases.?/
>>
>> CRAN has already had fftw and fftwtools, the issue is the data I?m 
>> targeting at are at GB-level, copying the vectors can be memory 
>> inefficient or even use up memories. The strategy of ravetools is to 
>> import signals from local files, fft, then directly write to disk. So 
>> only one reference will be used and modifying in-place is on purpose. 
>> In fact, and the fft functions I created are not intended to be used 
>> directly by users.
>>
>> However, I should've been very cautious when using these functions. 
>> This is my fault. I?ll check the whole package to make sure only one 
>> reference is used or otherwise the vectors will be copied.
>>
>>             /This can be tested by the MAYBE_REFERENCED() macro in
>>             Rinternals.h./
>>
>> Nice to learn! I?ll add it to my code.
>>
>>             Properly using R vectors in C code is tricky. You have to
>>             understand.
>>
>>             1) When you are allowed or not to modify vectors
>>
>>             2) When to PROTECT()vectors
>>
>>             3) How the garbage collector works and when it can trigger
>>             (answer : basically, when you call any internal R function)
>>
>>             Chapter 5 of "Writing R Extensions" documentation is quite
>>             extensive:
>>
>>             https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C<https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Handling-R-objects-in-C>
>>
>> Indeed, I found myself often confused about when to PROTECT and when not.
>>
>>                 ... but then ravetools ?is not even a CRAN package, so
>>                 why should you dare to use it for anything serious ?
>>
>> Haha, thanks : ) I guess I will probably be grouchy too if seeing so 
>> many people making the same mistakes again and again. It just happened 
>> to be me.
>> But it?s good to be rigorous. Sooner or later I'll have to face these 
>> problems. It?s better to make mistakes before having made many.
>>
>> Thanks y?all!
>>
>> Best,
>> - Dipterix Wang
>>
>>
>>
>>     On Oct 20, 2021, at 5:32 AM, Martin Maechler
>>     <maechler at stat.math.ethz.ch<mailto:maechler at stat.math.ethz.ch>> wrote:
>>
>>                         Martin Maechler
>>                         ???on Wed, 20 Oct 2021 11:26:21 +0200 writes:
>>
>>
>>     [............]
>>
>>
>>         Thank you, Andr? , that's very good.
>>
>>
>>
>>         Just to state the obvious conclusion:
>>
>>
>>
>>         If Ben's suggestion is correct (and Andr? has explained *how*
>>         that could happen) this would mean ?a
>>         SEVERE BUG in package ravetools's ?mvfftw() function.
>>
>>
>>
>>         and it would have been (yet another) case of gaining speed by
>>         killing correctness...
>>
>>
>>
>>         ... but then ravetools ?is not even a CRAN package, so why
>>         should you dare to use it for anything serious ?
>>
>>
>>
>>         ... yes, being grouchy ..
>>
>>
>>     which I should rather not be.
>>
>>     Dipterix Wang *did* say initially that he is currently
>>     developing ravetools so it's very reasonabl this is not yet a
>>     CRAN package..
>>
>>     Best,
>>     Martin
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat Oct 23 22:14:31 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 23 Oct 2021 20:14:31 +0000
Subject: [Rd] Environment setting _R_CHECK_DEPENDS_ONLY_='true'
In-Reply-To: <24944.6695.39047.303485@rob.eddelbuettel.com>
References: <7C83324B-EB19-46AB-BC08-6E8A8FCB65E5@anu.edu.au>
 <d3a5e0b2-3687-31ec-814f-ca301b818e26@fau.de>
 <24944.6695.39047.303485@rob.eddelbuettel.com>
Message-ID: <B1F93CC9-0D7C-4D11-9324-120F6D22B753@anu.edu.au>

A footnote, following an off-list exchange with Prof Ripley, is that I needed
needed to have Suggested or other additional packages installed somewhere
other than .Library .

"The following variables control checks for undeclared/unconditional use of other packages. They work by setting up a temporary library directory and setting .libPaths() to just that and .Library, so are only effective if additional packages are installed somewhere other than .Library.?
[I am not sure of the source of this quote.]

If vignettes make extensive use of Suggested packages,
then exiting early from vignettes when access would otherwise be required to
Suggested package [under knitr, one can use knitr::knit_exit()]  can be an
alternative to leaving out checking of vignettes in order to speed up initial
testing.

On MacOS Mojave with a bash shell
  env _R_CHECK_DEPENDS_ONLY_=true  R CMD check qra_0.2.4.tar.gz
works like a charm.  Some other Unix systems will omit the ?='


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 21/10/2021, at 02:31, Dirk Eddelbuettel <edd at debian.org<mailto:edd at debian.org>> wrote:


On 20 October 2021 at 09:31, Sebastian Meyer wrote:
| If you set the environment variable inside a running R process, it will
| only affect that process and child processes, but not an independent R
| process launched from a shell like you seem to be doing here:

Yes. That is somewhat common, if obscure, knowledge by those bitten before.

Maybe a line or two could be / should be added to the docs to that effect?

| How to set environment variables is system-specific. On a Unix-like
| system, you could use the command
|
| _R_CHECK_DEPENDS_ONLY_=true  R CMD check qra_0.2.4.tar.gz
|
| to set the environment variable for this R process.
| See, e.g., https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEnvironment_variable&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7Cb519af02f1df454df49208d993cdea27%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637703335008269211%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=aCCVvvnWQaRxtzxuUJ5lDKcPfMU2BzCJnDRC%2BTa4TnI%3D&amp;reserved=0.

R does have hooks for this, I had these for a few years now:

 ~/.R/check.Renviron
 ~/.R/check.Renviron-Rdevel

Again, might be worthwhile documenting it in the Inst+Admin manual (if it
isn' already, I don't recall right now).

Dirk

--
https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdirk.eddelbuettel.com%2F&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7Cb519af02f1df454df49208d993cdea27%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637703335008269211%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=5MTPe0%2Ftqou%2B0DI8%2F7C4NYtM3tJCb4Vpwbe4klWiTco%3D&amp;reserved=0 | @eddelbuettel | edd at debian.org<mailto:edd at debian.org>


	[[alternative HTML version deleted]]


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Sun Oct 24 22:51:30 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Sun, 24 Oct 2021 20:51:30 +0000
Subject: [Rd] Potential improvements of ave?
Message-ID: <1635108690195.23049@ap-hm.fr>

Since the original report raised several proposals, I submitted a bug report on R Bugzilla trying to summarize the discussion: https://bugs.r-project.org/show_bug.cgi?id=18223

(Maybe I should have ask before if it is really appropriate to do so. Please let me no if not.)

> Hi Abby,
> 
> I actually have a patch submitted that does this for unique/duplicated
> (only numeric cases I think) but it is, as patches from external
> contributors go, quite sizable which means it requires a correspondingly
> large amount of an R-core member's time and energy to vet and consider. It
> is in the queue, and so, I expect (/hope, provided I didn't make a mistake)
> it will be incorporated at some point. (
> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17993)
> 
> You are correct that the speedups are quite significant for calling
> unique/duplicated on large vectors that know they are sorted: Speedup on my
> machine for a fairly sizable vector (length 1e7) ranges from about ~10x in
> the densely duplicated case up to ~60-70x in the sparsely duplicated case
> for duplicated(). For unique() it seems to range from ~10x in the densely
> duplicated case to ~15 in the spare case.
> 
> I had thought that min and max already did this, but looking now, they
> don't seem to by default, thought ALTREP classes themselves do have an
> option of setting a min/max method, which would be hit. That does seem like
> low-hanging fruit, I agree, though in many cases the slow down from a
> single pass over the data to get a min probably isn't earthshattering.
> 
> The others do seem like they could benefit as well.
> 
> Best,
> ~G
> 
> On Tue, Mar 16, 2021 at 2:54 PM Abby Spurdle <spurdle.a using gmail.com> wrote:
> 
> > There are some relatively obvious examples:
> > unique, which.min/which.max/etc, range/min/max, quantile, aggregate/split
> >
> > Also, many timeseries, graphics and spline functions are dependent on the
> > order.
> >
> > In the case of data.frame(s), a boolean flag would probably need to be
> > extended to allow for multiple column sorting, and
> > ascending/descending options.
> >
> > On Tue, Mar 16, 2021 at 11:08 AM Gabriel Becker <gabembecker using gmail.com>
> > wrote:
> > >
> > > Abby,
> > >
> > > Vectors do have an internal mechanism for knowing that they are sorted
> > via ALTREP (it was one of 2 core motivating features for 'smart vectors'
> > the other being knowledge about presence of NAs).
> > >
> > > Currently I don't think we expose it at the R level, though it is part
> > of the official C API. I don't know of any plans for this to change, but I
> > suppose it could. Plus for functions in R itself, we could even use it
> > without exposing it more widely. A number of functions, including sort
> > itself, already do this in fact, but more could. I'd be interested in
> > hearing which functions you think would particularly benefit from this.
> > >
> > > ~G
> > >
> > > On Mon, Mar 15, 2021 at 12:01 PM SOEIRO Thomas <Thomas.SOEIRO using ap-hm.fr>
> > wrote:
> > > >
> > > > Hi Abby,
> > > >
> > > > Thank you for your positive feedback.
> > > >
> > > > I agree for your general comment about sorting.
> > > >
> > > > For ave specifically, ordering may not help because the output must
> > maintain the order of the input (as ave returns only x and not the entiere
> > data.frame).
> > > >
> > > > Thanks,
> > > >
> > > > Thomas
> > > > ________________________________________
> > > > De : Abby Spurdle <spurdle.a using gmail.com>
> > > > Envoy? : lundi 15 mars 2021 10:22
> > > > ? : SOEIRO Thomas
> > > > Cc : r-devel using r-project.org
> > > > Objet : Re: [Rd] Potential improvements of ave?
> > > >
> > > > EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS
> > > >
> > > > Hi Thomas,
> > > >
> > > > These are some great suggestions.
> > > > But I can't help but feel there's a much bigger problem here.
> > > >
> > > > Intuitively, the ave function could (or should) sort the data.
> > > > Then the indexing step becomes almost trivial, in terms of both time
> > > > and space complexity.
> > > > And the ave function is not the only example of where a problem
> > > > becomes much simpler, if the data is sorted.
> > > >
> > > > Historically, I've never found base R functions user-friendly for
> > > > aggregation purposes, or for sorting.
> > > > (At least, not by comparison to SQL).
> > > >
> > > > But that's not the main problem.
> > > > It would seem preferable to sort the data, only once.
> > > > (Rather than sorting it repeatedly, or not at all).
> > > >
> > > > Perhaps, objects such as vectors and data.frame(s) could have a
> > > > boolean attribute, to indicate if they're sorted.
> > > > Or functions such as ave could have a sorted argument.
> > > > In either case, if true, the function assumes the data is sorted and
> > > > applies a more efficient algorithm.
> > > >
> > > >
> > > > B.
> > > >
> > > >
> > > > On Sat, Mar 13, 2021 at 1:07 PM SOEIRO Thomas <Thomas.SOEIRO using ap-hm.fr>
> > wrote:
> > > > >
> > > > > Dear all,
> > > > >
> > > > > I have two questions/suggestions about ave, but I am not sure if it's
> > relevant for bug reports.
> > > > >
> > > > >
> > > > >
> > > > > 1) I have performance issues with ave in a case where I didn't expect
> > it. The following code runs as expected:
> > > > >
> > > > > set.seed(1)
> > > > >
> > > > > df1 <- data.frame(id1 = sample(1:1e2, 5e2, TRUE),
> > > > >                   id2 = sample(1:3, 5e2, TRUE),
> > > > >                   id3 = sample(1:5, 5e2, TRUE),
> > > > >                   val = sample(1:300, 5e2, TRUE))
> > > > >
> > > > > df1$diff <- ave(df1$val,
> > > > >                 df1$id1,
> > > > >                 df1$id2,
> > > > >                 df1$id3,
> > > > >                 FUN = function(i) c(diff(i), 0))
> > > > >
> > > > > head(df1[order(df1$id1,
> > > > >                df1$id2,
> > > > >                df1$id3), ])
> > > > >
> > > > > But when expanding the data.frame (* 1e4), ave fails (Error: cannot
> > allocate vector of size 1110.0 Gb):
> > > > >
> > > > > df2 <- data.frame(id1 = sample(1:(1e2 * 1e4), 5e2 * 1e4, TRUE),
> > > > >                   id2 = sample(1:3, 5e2 * 1e4, TRUE),
> > > > >                   id3 = sample(1:(5 * 1e4), 5e2 * 1e4, TRUE),
> > > > >                   val = sample(1:300, 5e2 * 1e4, TRUE))
> > > > >
> > > > > df2$diff <- ave(df2$val,
> > > > >                 df2$id1,
> > > > >                 df2$id2,
> > > > >                 df2$id3,
> > > > >                 FUN = function(i) c(diff(i), 0))
> > > > >
> > > > > This use case does not seem extreme to me (e.g. aggregate et al work
> > perfectly on this data.frame).
> > > > > So my question is: Is this expected/intended/reasonable? i.e. Does
> > ave need to be optimized?
> > > > >
> > > > >
> > > > >
> > > > > 2) Gabor Grothendieck pointed out in 2011 that drop = TRUE is needed
> > to avoid warnings in case of unused levels (https://stat.ethz.ch/pipermail/r-devel/2011-February/059947.html).
> > > > > Is it relevant/possible to expose the drop argument explicitly?
> > > > >
> > > > >
> > > > >
> > > > > Thanks,
> > > > >
> > > > > Thomas

From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Sun Oct 24 23:08:53 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Sun, 24 Oct 2021 21:08:53 +0000
Subject: [Rd] Potential bugs in table dnn
Message-ID: <d6c90ac83c894dac80e3851a533c467a@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear Martin,

Should I finally report a bug for this (these?) remaining issue as initially agreed?

Best regards,

Thomas

> > Dear Martin,
> >
> > Thank you for the perfect fix. It fixes both issues in the 1-dim case (i.e. automatic dnn *and* disregard dnn/names in ...), as well as the documentation.
>
>
> Finally, there is still a corner case that the patch did not fix in the 1D-case. We cannot override the data frame's names with the dnn argument:
>
> tab(warpbreaks[2], dnn = letters[1]) # dnn ignored
> # wool
> #  A  B
> # 27 27
>
> tab(warpbreaks[2:3], dnn = letters[1:2]) # works
> #    b
> # a   L M H
> #   A 9 9 9
> #   B 9 9 9
>
> But I did not manage to fix it...
>
>
> > While working on table, may be this should be an error?
> >
> > table(warpbreaks[2], warpbreaks[3])
> > #
> > #       1:3
> > #   1:2   0
> > # Warning messages:
> > # 1: In xtfrm.data.frame(x) : cannot xtfrm data frames
> > # 2: In xtfrm.data.frame(x) : cannot xtfrm data frames
> >
> > Best regards,
> >
> > Thomas
> >
> > > -----Message d'origine-----
> > > De : Martin Maechler [mailto:maechler using stat.math.ethz.ch]
> > > Envoy? : jeudi 14 octobre 2021 11:44
> > > ? : SOEIRO Thomas
> > > Cc : R Development List
> > > Objet : Re: [Rd] Potential bugs in table dnn
> > >
> > > EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS
> > >
> > > Dear Thomas,
> > >
> > > actually, I have in the mean time already applied the changes I think are
> > > needed, both in the code and in the documentation.
> > >
> > > So, in this case, it may be a waste of time to still open a bugzilla issue, I think.
> > >
> > > Here are my current changes (not yet committed; of course I would also add
> > > a NEWS entry, mentioning you):
> > >
> > >
> > > Index: src/library/base/R/table.R
> > > ==========================================================
> > > =========
> > > 53c53
> > > <       if (length(dnn) != length(args))
> > > ---
> > > >       if(length(args) == 1L || length(dnn) != length(args))
> > > Index: src/library/base/man/table.Rd
> > > ==========================================================
> > > =========
> > > 23c23
> > > <   \code{table} uses the cross-classifying factors to build a contingency
> > > ---
> > > >   \code{table} uses cross-classifying factors to build a contingency
> > > 41c41,42
> > > <     (including character strings), or a list (or data frame) whose
> > > ---
> > > >     (including numbers or character strings), or a \code{\link{list}} (such
> > > >     as a data frame) whose
> > > 67c68,69
> > > <   If the argument \code{dnn} is not supplied, the internal function
> > > ---
> > > >   If the argument \code{dnn} is not supplied \emph{and} if \code{\dots} is
> > > >   not one \code{list} with its own \code{\link{names}()}, the internal
> > > > function
> > >
> > >
> > >
> > > With regards,
> > > Martin


From bjorn@@ue@t@d @end|ng |rom u|@@no  Sun Oct 24 23:32:54 2021
From: bjorn@@ue@t@d @end|ng |rom u|@@no (=?iso-8859-1?Q?Bj=F8rn_Henrik_Auestad?=)
Date: Sun, 24 Oct 2021 21:32:54 +0000
Subject: [Rd] Problems with packages fda and splines (PR#13263)
Message-ID: <SV0P279MB00432384FB7D9B36AB28C6AA9C829@SV0P279MB0043.NORP279.PROD.OUTLOOK.COM>

Dear Spencer,

I'm struggling with the same problem as was mentioned in Re: [Rd] Problems with packages fda and splines (PR#13263).

(See also copy below.) I.e. handling NA's with smooth.basis or Data2fd. Would you kindly let me know if it is possible

to handle NA's with Data2fd?

Best regards,
Bj?rn H. Auestad

Head, Department of Mathematics and Physics
University of Stavanger
phone: 51 83 18 74 / 91 31 65 34


Spencer Graves spencer.graves at pdf.com<mailto:r-devel%40r-project.org?Subject=Re%3A%20%5BRd%5D%20Problems%20with%20packages%20fda%20and%20splines%20%28PR%2313263%29&In-Reply-To=%3C4914A1F9.8050106%40pdf.com%3E>
Fri Nov 7 21:15:53 CET 2008

  *   Previous message: [Rd] Problems with packages fda and splines (PR#13263)<https://stat.ethz.ch/pipermail/r-devel/2008-November/051216.html>
  *   Next message: [Rd] barplot can put legend in wrong place, request option to override that (PR#13265)<https://stat.ethz.ch/pipermail/r-devel/2008-November/051218.html>
  *   Messages sorted by: [ date ]<https://stat.ethz.ch/pipermail/r-devel/2008-November/date.html#51217> [ thread ]<https://stat.ethz.ch/pipermail/r-devel/2008-November/thread.html#51217> [ subject ]<https://stat.ethz.ch/pipermail/r-devel/2008-November/subject.html#51217> [ author ]<https://stat.ethz.ch/pipermail/r-devel/2008-November/author.html#51217>

________________________________

Hello, David:



      Thanks for the comments about NA problems in 'fda'.  I'll look

into this and get back with you.



      Spencer



degras at uchicago.edu<https://stat.ethz.ch/mailman/listinfo/r-devel> wrote:

> Full_Name: David D Degras

> Version: 2.8.0

> OS: Mac OS X

> Submission from: (NULL) (128.135.239.11)

>

>

> I have recently installed the version 2.8.0 of R along with package fda (v

> 2.0.2)

> and its dependencies (including package splines v. 2.8.0).

>

> Here are my problems:

>

> 1) The package splines should feature functions such a predict.bs,

> predict.bSpline and such and it does not! I can make calls to bs, ns, and

> interpSpline but not to any predicting function.

> Example:

>

>> library(splines)

>> predict.bs

>>

> Erreur : objet "predict.bs" non trouv? # in english: object "predict.bs" not

> found

>

> Also, I cannot track the package splines on the CRAN website. Why is that?

>

> 2) Package fda: it does not handle at all NAs although promising to.

> I have met this problem using Data2fd and project.basis as well.

> An example script is enclosed at the end of this email.

>

> Can you help on this ?

>

> Thanks,

>

> David

>

> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

> R SCRIPT for Data2fd with NAs

> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

>

>

>> library(fda)

>> y=runif(10)

>> x=Data2fd(1:10,y) # creates functional object in B-spline basis

>>

> Warning message:

> In smooth.basis(argvals, y, fdP, wtvec = w, fdnames = fdnames) :

>   The number of basis functions = 12 exceeds 10 = the number of points to be

> smoothed.  With no smoothing (lambda = 0), this will produce a perfect fit to

> data that typically has wild excursions between data points.

>

>> x$coefs # here it works because no NAs

>>

>             [,1]

>  [1,]  0.9193563

>  [2,]  0.1590327

>  [3,]  0.6441482

>  [4,]  1.1257380

>  [5,]  0.1234022

>  [6,]  0.7228168

>  [7,]  0.8709656

>  [8,] -0.3634714

>  [9,]  0.9097221

> [10,]  1.1726878

> [11,]  0.4130424

> [12,]  0.3122870

>

>> y[3]=NA # create a NA

>> x=Data2fd(1:10,y)

>>

> Warning message:

> In smooth.basis(argvals, y, fdP, wtvec = w, fdnames = fdnames) :

>   The number of basis functions = 12 exceeds 10 = the number of points to be

> smoothed.  With no smoothing (lambda = 0), this will produce a perfect fit to

> data that typically has wild excursions between data points.

>

>> x$coefs # vector of NAs because y[3]=NA

>>

>       [,1]

>  [1,]   NA

>  [2,]   NA

>  [3,]   NA

>  [4,]   NA

>  [5,]   NA

>  [6,]   NA

>  [7,]   NA

>  [8,]   NA

>  [9,]   NA

> [10,]   NA

> [11,]   NA

> [12,]   NA

>

> ______________________________________________

> R-devel at r-project.org<https://stat.ethz.ch/mailman/listinfo/r-devel> mailing list

> https://stat.ethz.ch/mailman/listinfo/r-devel

>




	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Oct 27 20:45:08 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 27 Oct 2021 20:45:08 +0200
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <24945.33990.369010.718929@stat.math.ethz.ch>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
Message-ID: <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>


On 10/21/21 5:18 PM, Martin Maechler wrote:
>>>>>> Micha? Bojanowski
>>>>>>      on Wed, 20 Oct 2021 16:31:08 +0200 writes:
>      > Hello Tomas,
>      > Yes, that's accurate although rather terse, which is perhaps the
>      > reason why I did not realize it applies to my case.
>
>      > How about adding something in the direction of:
>
>      > 1. Continuing the cited paragraph with:
>      > In particular, on Windows it may be necessary to quote references to
>      > existing environment variables, especially those containing file paths
>      > (which include backslashes). For example: `"${WINVAR}"`.
>
>      > 2. Add an example (not run):
>
>      > # On Windows do quote references to variables containing paths, e.g.:
>      > # If APPDATA=C:\Users\foobar\AppData\Roaming
>      > # to point to a library tree inside APPDATA in .Renviron use
>      > R_LIBS_USER="${APPDATA}"/R-library
>
>      > Incidentally the last example is on backslashes too.
>
>
>      > What do you think?
>
> I agree that adding an example really helps a lot in such cases,
> in my experience, notably if it's precise enough to be used +/- directly.

Yes, I agree as well. I think the Renviron files should be written in a 
way so that they would work the same in a POSIX shell, so e.g. 
VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to 
preserve backslashes in VAR0. It is better to use forward slashes in 
string literals, e.g. VAR="c:/users". If one still needed backslashes, 
they could then be entered in single quotes, e.g. VAR='c:\users'.

The currently implemented parsing of Renviron files differs in a number 
of details from POSIX shells, some are documented and some are not. 
Relying only on the documented behavior that is the same as in POSIX 
shells is the best choice for future compatibility.

Tomas

>
>
>      > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>      >>
>      >>
>      >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
>      >> > Perhaps a small update to ?.Renviron would be in order to mention that...
>      >>
>      >> Would you have a more specific suggestion how to update the
>      >> documentation? Please note that it already says
>      >>
>      >> "?value? is then processed in a similar way to a Unix shell: in
>      >> particular the outermost level of (single or double) quotes is stripped,
>      >> and backslashes are removed except inside quotes."
>      >>
>      >> Thanks,
>      >> Tomas
>      >>
>      >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>      >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
>      >> >> Thank you all!
>      >> >> Michal
>      >> >>
>      >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>      >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
>      >> >>>
>      >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
>      >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>      >> >>>
>      >> >>>> AVAR=${APPDATA}/foo/bar
>      >> >>>>
>      >> >>>> Which is a documented way of referring to existing environment
>      >> >>>> variables. Now, with that in R I'm getting:
>      >> >>>>
>      >> >>>> Sys.getenv("APPDATA")    # That works OK
>      >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
>      >> >>>>
>      >> >>>> so OK, but:
>      >> >>>>
>      >> >>>> Sys.getenv("AVAR")
>      >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>      >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
>      >> >>> but not if they are encountered inside quotes:
>      >> >>>
>      >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>      >> >>>
>      >> >>> Would AVAR="${APPDATA}"/foo/bar work?
>      >> >>>
>      >> >>> --
>      >> >>> Best regards,
>      >> >>> Ivan
>      >> > ______________________________________________
>      >> > R-devel at r-project.org mailing list
>      >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Oct 28 19:18:54 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 28 Oct 2021 13:18:54 -0400
Subject: [Rd] Bug (?) in vignette handling
Message-ID: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>

This StackOverflow post:  https://stackoverflow.com/q/69756236/2554330 
points out that objects created in one vignette are available in a later 
vignette.  I don't think this should be happening:  vignettes should be 
self-contained.

The current answer there, https://stackoverflow.com/a/69758025/2554330, 
suggests that "R CMD check" will detect this.  However, sometimes one 
vignette can replace a standard function with a custom version, and then 
both will work without generating an error, but the second vignette 
won't do the same thing if run independently.

For example, try these pure Sweave vignettes:

-------------------------
aaa3.Rnw:
-------------------------
\documentclass{article}
%\VignetteIndexEntry{Sweave aaa3}
\begin{document}

<<>>=
mean <- function(x) "I am the Sweave mean"
@

\end{document}

------------------------
aaa4.Rnw:
------------------------

\documentclass{article}
%\VignetteIndexEntry{Sweave aaa4}
\begin{document}

<<>>=
mean(1:5)
@

\end{document}

Put these in a package, build and install the package, and you'll see 
that the mean() function in aaa4.Rnw prints the result from the 
redefined mean in aaa3.Rnw.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Oct 29 11:52:18 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 29 Oct 2021 11:52:18 +0200
Subject: [Rd] Bug (?) in vignette handling
In-Reply-To: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>
References: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>
Message-ID: <24955.50258.23812.695610@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Thu, 28 Oct 2021 13:18:54 -0400 writes:

    > This StackOverflow post:  https://stackoverflow.com/q/69756236/2554330 
    > points out that objects created in one vignette are available in a later 
    > vignette.  I don't think this should be happening:  vignettes should be 
    > self-contained.

I strongly agree.

    > The current answer there, https://stackoverflow.com/a/69758025/2554330, 
    > suggests that "R CMD check" will detect this.  However, sometimes one 
    > vignette can replace a standard function with a custom version, and then 
    > both will work without generating an error, but the second vignette 
    > won't do the same thing if run independently.

    > For example, try these pure Sweave vignettes:

    > -------------------------
    > aaa3.Rnw:
    > -------------------------
    > \documentclass{article}
    > %\VignetteIndexEntry{Sweave aaa3}
    > \begin{document}

    > <<>>=
    > mean <- function(x) "I am the Sweave mean"
    > @

    > \end{document}

    > ------------------------
    > aaa4.Rnw:
    > ------------------------

    > \documentclass{article}
    > %\VignetteIndexEntry{Sweave aaa4}
    > \begin{document}

    > <<>>=
    > mean(1:5)
    > @

    > \end{document}

    > Put these in a package, build and install the package, and you'll see 
    > that the mean() function in aaa4.Rnw prints the result from the 
    > redefined mean in aaa3.Rnw.

Is it because R is *not* run with  --no-save --no-restore
accidentally?
Without looking, I would not expect that the vignettes are run
inside the same running R (even though that may speedup things)


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Oct 30 20:28:13 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 30 Oct 2021 14:28:13 -0400
Subject: [Rd] Bug (?) in vignette handling
In-Reply-To: <24955.50258.23812.695610@stat.math.ethz.ch>
References: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>
 <24955.50258.23812.695610@stat.math.ethz.ch>
Message-ID: <6771c4de-99e6-ff37-305e-236c6895853d@gmail.com>

On 29/10/2021 5:52 a.m., Martin Maechler wrote:
>>>>>> Duncan Murdoch
>>>>>>      on Thu, 28 Oct 2021 13:18:54 -0400 writes:
> 
>      > This StackOverflow post:  https://stackoverflow.com/q/69756236/2554330
>      > points out that objects created in one vignette are available in a later
>      > vignette.  I don't think this should be happening:  vignettes should be
>      > self-contained.
> 
> I strongly agree.
> 
>      > The current answer there, https://stackoverflow.com/a/69758025/2554330,
>      > suggests that "R CMD check" will detect this.  However, sometimes one
>      > vignette can replace a standard function with a custom version, and then
>      > both will work without generating an error, but the second vignette
>      > won't do the same thing if run independently.
> 
>      > For example, try these pure Sweave vignettes:
> 
>      > -------------------------
>      > aaa3.Rnw:
>      > -------------------------
>      > \documentclass{article}
>      > %\VignetteIndexEntry{Sweave aaa3}
>      > \begin{document}
> 
>      > <<>>=
>      > mean <- function(x) "I am the Sweave mean"
>      > @
> 
>      > \end{document}
> 
>      > ------------------------
>      > aaa4.Rnw:
>      > ------------------------
> 
>      > \documentclass{article}
>      > %\VignetteIndexEntry{Sweave aaa4}
>      > \begin{document}
> 
>      > <<>>=
>      > mean(1:5)
>      > @
> 
>      > \end{document}
> 
>      > Put these in a package, build and install the package, and you'll see
>      > that the mean() function in aaa4.Rnw prints the result from the
>      > redefined mean in aaa3.Rnw.
> 
> Is it because R is *not* run with  --no-save --no-restore
> accidentally?
> Without looking, I would not expect that the vignettes are run
> inside the same running R (even though that may speedup things)
> 

I think for R CMD build they are run in one process, while for R CMD 
check they are in separate processes.  R CMD build runs 
tools::buildVignettes(), which runs code that's part of the vignette 
build engine.

The Sweave engine evaluates things in .GlobalEnv, so any leftover 
objects will be visible there for the next vignette.  I think it's up to 
the writer of each vignette engine whether there's any cleanup, but it 
appears that neither Sweave nor knitr does any.

One possible fix would be for buildVignettes() to make a snapshot of 
what's in .GlobalEnv before processing any vignettes, and restoring it 
after each one.  I've tried a weaker version of this:  it records the 
names in .GlobalEnv at the start, and deletes anything new before 
processing each vignette.  So vignettes could modify or delete what's 
there, but not add anything.

I think you don't want to completely clear out .GlobalEnv, because 
people might choose to run buildVignettes() in an R session and expect 
the vignettes to see the contents there.

"make check" in R-devel doesn't complain about this change, but I'll let 
R Core decide whether it's a good idea or not.  A patch is below.

Duncan Murdoch

Index: src/library/tools/R/Vignettes.R
===================================================================
--- src/library/tools/R/Vignettes.R	(revision 81110)
+++ src/library/tools/R/Vignettes.R	(working copy)
@@ -560,7 +560,11 @@
      sourceList <- list()
      startdir <- getwd()
      fails <- character()
+    # People may build vignettes from a session and expect
+    # to see some variables, so we won't delete these
+    existingVars <- ls(.GlobalEnv, all = TRUE)
      for(i in seq_along(vigns$docs)) {
+    	rm(list = setdiff(ls(.GlobalEnv, all = TRUE), existingVars), envir 
= .GlobalEnv)
          thisOK <- TRUE
          file <- basename(vigns$docs[i])
          enc <- vigns$encodings[i]


From @eb@meyer @end|ng |rom |@u@de  Sun Oct 31 00:11:46 2021
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Sun, 31 Oct 2021 00:11:46 +0200
Subject: [Rd] Bug (?) in vignette handling
In-Reply-To: <6771c4de-99e6-ff37-305e-236c6895853d@gmail.com>
References: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>
 <24955.50258.23812.695610@stat.math.ethz.ch>
 <6771c4de-99e6-ff37-305e-236c6895853d@gmail.com>
Message-ID: <bbffe723-60fe-550f-0de3-837136ca3c64@fau.de>

Am 30.10.21 um 20:28 schrieb Duncan Murdoch:
> On 29/10/2021 5:52 a.m., Martin Maechler wrote:
>>>>>>> Duncan Murdoch
>>>>>>> ???? on Thu, 28 Oct 2021 13:18:54 -0400 writes:
>>
>> ???? > This StackOverflow post:  
>> https://stackoverflow.com/q/69756236/2554330
>> ???? > points out that objects created in one vignette are available 
>> in a later
>> ???? > vignette.? I don't think this should be happening:? vignettes 
>> should be
>> ???? > self-contained.
>>
>> I strongly agree.
>>
>> ???? > The current answer there, 
>> https://stackoverflow.com/a/69758025/2554330,
>> ???? > suggests that "R CMD check" will detect this.? However, 
>> sometimes one
>> ???? > vignette can replace a standard function with a custom version, 
>> and then
>> ???? > both will work without generating an error, but the second 
>> vignette
>> ???? > won't do the same thing if run independently.
>>
>> ???? > For example, try these pure Sweave vignettes:
>>
>> ???? > -------------------------
>> ???? > aaa3.Rnw:
>> ???? > -------------------------
>> ???? > \documentclass{article}
>> ???? > %\VignetteIndexEntry{Sweave aaa3}
>> ???? > \begin{document}
>>
>> ???? > <<>>=
>> ???? > mean <- function(x) "I am the Sweave mean"
>> ???? > @
>>
>> ???? > \end{document}
>>
>> ???? > ------------------------
>> ???? > aaa4.Rnw:
>> ???? > ------------------------
>>
>> ???? > \documentclass{article}
>> ???? > %\VignetteIndexEntry{Sweave aaa4}
>> ???? > \begin{document}
>>
>> ???? > <<>>=
>> ???? > mean(1:5)
>> ???? > @
>>
>> ???? > \end{document}
>>
>> ???? > Put these in a package, build and install the package, and 
>> you'll see
>> ???? > that the mean() function in aaa4.Rnw prints the result from the
>> ???? > redefined mean in aaa3.Rnw.
>>
>> Is it because R is *not* run with? --no-save --no-restore
>> accidentally?
>> Without looking, I would not expect that the vignettes are run
>> inside the same running R (even though that may speedup things)
>>
> 
> I think for R CMD build they are run in one process, while for R CMD 
> check they are in separate processes.? R CMD build runs 
> tools::buildVignettes(), which runs code that's part of the vignette 
> build engine.

Thankfully R CMD check has been building the vignettes in separate R 
processes already since R 3.6.0, so has hopefully identified most 
problems until now. The corresponding env var is 
_R_CHECK_BUILD_VIGNETTES_SEPARATELY_.

The standard (and exported!) buildVignettes() has been weaving all 
vignettes in the same session ever since it was added back in 2002. This 
approach is probably more efficient (avoiding repetitive package 
loading), but carry-over effects seem both likely and undesirable 
(thinking of vignettes as separate and independently reproducible 
manuscripts about different aspects of a package). AFAICS, it is not 
explicitly documented that buildVignettes() runs all vignettes in the 
same R session, so at least this is no advertised feature.

> The Sweave engine evaluates things in .GlobalEnv, so any leftover 
> objects will be visible there for the next vignette.? I think it's up to 
> the writer of each vignette engine whether there's any cleanup, but it 
> appears that neither Sweave nor knitr does any.

I think this is by design and also useful in interactive sessions to 
investigate the environment after weaving.

> One possible fix would be for buildVignettes() to make a snapshot of 
> what's in .GlobalEnv before processing any vignettes, and restoring it 
> after each one.? I've tried a weaker version of this:? it records the 
> names in .GlobalEnv at the start, and deletes anything new before 
> processing each vignette.? So vignettes could modify or delete what's 
> there, but not add anything.
> 
> I think you don't want to completely clear out .GlobalEnv, because 
> people might choose to run buildVignettes() in an R session and expect 
> the vignettes to see the contents there.
> 
> "make check" in R-devel doesn't complain about this change, but I'll let 
> R Core decide whether it's a good idea or not.? A patch is below.

Clearing the workspace would be an improvement, but I think it would be 
even better for R CMD build to produce each vignette in a clean R 
session, especially with regard to loaded packages. Changing 
buildVignettes() to use clean R processes by default (I'd say even if 
there is only one vignette) should be considered. I'd appreciate seeing 
this report in Bugzilla to investigate further (and not forget).

Best regards,

    Sebastian Meyer


> 
> Duncan Murdoch
> 
> Index: src/library/tools/R/Vignettes.R
> ===================================================================
> --- src/library/tools/R/Vignettes.R??? (revision 81110)
> +++ src/library/tools/R/Vignettes.R??? (working copy)
> @@ -560,7 +560,11 @@
>  ???? sourceList <- list()
>  ???? startdir <- getwd()
>  ???? fails <- character()
> +??? # People may build vignettes from a session and expect
> +??? # to see some variables, so we won't delete these
> +??? existingVars <- ls(.GlobalEnv, all = TRUE)
>  ???? for(i in seq_along(vigns$docs)) {
> +??????? rm(list = setdiff(ls(.GlobalEnv, all = TRUE), existingVars), 
> envir = .GlobalEnv)
>  ???????? thisOK <- TRUE
>  ???????? file <- basename(vigns$docs[i])
>  ???????? enc <- vigns$encodings[i]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sun Oct 31 02:55:15 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sat, 30 Oct 2021 17:55:15 -0700
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
 <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
Message-ID: <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>

> ... If one still needed backslashes,
> they could then be entered in single quotes, e.g. VAR='c:\users'.

I don't think it matters whether you use single or double quotes -
both will work.  Here's a proof of concept on Linux with R 4.1.1:

$ cat ./.Renviron
A=C:\users
B='C:\users'
C="C:\users"

$ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
          A           B           C
  "C:users" "C:\\users" "C:\\users"

/Henrik

On Wed, Oct 27, 2021 at 11:45 AM Tomas Kalibera
<tomas.kalibera at gmail.com> wrote:
>
>
> On 10/21/21 5:18 PM, Martin Maechler wrote:
> >>>>>> Micha? Bojanowski
> >>>>>>      on Wed, 20 Oct 2021 16:31:08 +0200 writes:
> >      > Hello Tomas,
> >      > Yes, that's accurate although rather terse, which is perhaps the
> >      > reason why I did not realize it applies to my case.
> >
> >      > How about adding something in the direction of:
> >
> >      > 1. Continuing the cited paragraph with:
> >      > In particular, on Windows it may be necessary to quote references to
> >      > existing environment variables, especially those containing file paths
> >      > (which include backslashes). For example: `"${WINVAR}"`.
> >
> >      > 2. Add an example (not run):
> >
> >      > # On Windows do quote references to variables containing paths, e.g.:
> >      > # If APPDATA=C:\Users\foobar\AppData\Roaming
> >      > # to point to a library tree inside APPDATA in .Renviron use
> >      > R_LIBS_USER="${APPDATA}"/R-library
> >
> >      > Incidentally the last example is on backslashes too.
> >
> >
> >      > What do you think?
> >
> > I agree that adding an example really helps a lot in such cases,
> > in my experience, notably if it's precise enough to be used +/- directly.
>
> Yes, I agree as well. I think the Renviron files should be written in a
> way so that they would work the same in a POSIX shell, so e.g.
> VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to
> preserve backslashes in VAR0. It is better to use forward slashes in
> string literals, e.g. VAR="c:/users". If one still needed backslashes,
> they could then be entered in single quotes, e.g. VAR='c:\users'.
>
> The currently implemented parsing of Renviron files differs in a number
> of details from POSIX shells, some are documented and some are not.
> Relying only on the documented behavior that is the same as in POSIX
> shells is the best choice for future compatibility.
>
> Tomas
>
> >
> >
> >      > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >      >>
> >      >>
> >      >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
> >      >> > Perhaps a small update to ?.Renviron would be in order to mention that...
> >      >>
> >      >> Would you have a more specific suggestion how to update the
> >      >> documentation? Please note that it already says
> >      >>
> >      >> "?value? is then processed in a similar way to a Unix shell: in
> >      >> particular the outermost level of (single or double) quotes is stripped,
> >      >> and backslashes are removed except inside quotes."
> >      >>
> >      >> Thanks,
> >      >> Tomas
> >      >>
> >      >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >      >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
> >      >> >> Thank you all!
> >      >> >> Michal
> >      >> >>
> >      >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >      >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
> >      >> >>>
> >      >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
> >      >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >      >> >>>
> >      >> >>>> AVAR=${APPDATA}/foo/bar
> >      >> >>>>
> >      >> >>>> Which is a documented way of referring to existing environment
> >      >> >>>> variables. Now, with that in R I'm getting:
> >      >> >>>>
> >      >> >>>> Sys.getenv("APPDATA")    # That works OK
> >      >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> >      >> >>>>
> >      >> >>>> so OK, but:
> >      >> >>>>
> >      >> >>>> Sys.getenv("AVAR")
> >      >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> >      >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
> >      >> >>> but not if they are encountered inside quotes:
> >      >> >>>
> >      >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
> >      >> >>>
> >      >> >>> Would AVAR="${APPDATA}"/foo/bar work?
> >      >> >>>
> >      >> >>> --
> >      >> >>> Best regards,
> >      >> >>> Ivan
> >      >> > ______________________________________________
> >      >> > R-devel at r-project.org mailing list
> >      >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >      > ______________________________________________
> >      > R-devel at r-project.org mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Oct 31 10:31:15 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 31 Oct 2021 05:31:15 -0400
Subject: [Rd] Bug (?) in vignette handling
In-Reply-To: <bbffe723-60fe-550f-0de3-837136ca3c64@fau.de>
References: <289044bd-51c5-f0fe-75c7-3497491bcdd9@gmail.com>
 <24955.50258.23812.695610@stat.math.ethz.ch>
 <6771c4de-99e6-ff37-305e-236c6895853d@gmail.com>
 <bbffe723-60fe-550f-0de3-837136ca3c64@fau.de>
Message-ID: <e1fb3e76-936d-416b-0571-adcfbe534355@gmail.com>

On 30/10/2021 6:11 p.m., Sebastian Meyer wrote:
> Am 30.10.21 um 20:28 schrieb Duncan Murdoch:
>> On 29/10/2021 5:52 a.m., Martin Maechler wrote:
>>>>>>>> Duncan Murdoch
>>>>>>>>  ???? on Thu, 28 Oct 2021 13:18:54 -0400 writes:
>>>
>>>  ???? > This StackOverflow post:
>>> https://stackoverflow.com/q/69756236/2554330
>>>  ???? > points out that objects created in one vignette are available
>>> in a later
>>>  ???? > vignette.? I don't think this should be happening:? vignettes
>>> should be
>>>  ???? > self-contained.
>>>
>>> I strongly agree.
>>>
>>>  ???? > The current answer there,
>>> https://stackoverflow.com/a/69758025/2554330,
>>>  ???? > suggests that "R CMD check" will detect this.? However,
>>> sometimes one
>>>  ???? > vignette can replace a standard function with a custom version,
>>> and then
>>>  ???? > both will work without generating an error, but the second
>>> vignette
>>>  ???? > won't do the same thing if run independently.
>>>
>>>  ???? > For example, try these pure Sweave vignettes:
>>>
>>>  ???? > -------------------------
>>>  ???? > aaa3.Rnw:
>>>  ???? > -------------------------
>>>  ???? > \documentclass{article}
>>>  ???? > %\VignetteIndexEntry{Sweave aaa3}
>>>  ???? > \begin{document}
>>>
>>>  ???? > <<>>=
>>>  ???? > mean <- function(x) "I am the Sweave mean"
>>>  ???? > @
>>>
>>>  ???? > \end{document}
>>>
>>>  ???? > ------------------------
>>>  ???? > aaa4.Rnw:
>>>  ???? > ------------------------
>>>
>>>  ???? > \documentclass{article}
>>>  ???? > %\VignetteIndexEntry{Sweave aaa4}
>>>  ???? > \begin{document}
>>>
>>>  ???? > <<>>=
>>>  ???? > mean(1:5)
>>>  ???? > @
>>>
>>>  ???? > \end{document}
>>>
>>>  ???? > Put these in a package, build and install the package, and
>>> you'll see
>>>  ???? > that the mean() function in aaa4.Rnw prints the result from the
>>>  ???? > redefined mean in aaa3.Rnw.
>>>
>>> Is it because R is *not* run with? --no-save --no-restore
>>> accidentally?
>>> Without looking, I would not expect that the vignettes are run
>>> inside the same running R (even though that may speedup things)
>>>
>>
>> I think for R CMD build they are run in one process, while for R CMD
>> check they are in separate processes.? R CMD build runs
>> tools::buildVignettes(), which runs code that's part of the vignette
>> build engine.
> 
> Thankfully R CMD check has been building the vignettes in separate R
> processes already since R 3.6.0, so has hopefully identified most
> problems until now. The corresponding env var is
> _R_CHECK_BUILD_VIGNETTES_SEPARATELY_.
> 
> The standard (and exported!) buildVignettes() has been weaving all
> vignettes in the same session ever since it was added back in 2002. This
> approach is probably more efficient (avoiding repetitive package
> loading), but carry-over effects seem both likely and undesirable
> (thinking of vignettes as separate and independently reproducible
> manuscripts about different aspects of a package). AFAICS, it is not
> explicitly documented that buildVignettes() runs all vignettes in the
> same R session, so at least this is no advertised feature.
> 
>> The Sweave engine evaluates things in .GlobalEnv, so any leftover
>> objects will be visible there for the next vignette.? I think it's up to
>> the writer of each vignette engine whether there's any cleanup, but it
>> appears that neither Sweave nor knitr does any.
> 
> I think this is by design and also useful in interactive sessions to
> investigate the environment after weaving.
> 
>> One possible fix would be for buildVignettes() to make a snapshot of
>> what's in .GlobalEnv before processing any vignettes, and restoring it
>> after each one.? I've tried a weaker version of this:? it records the
>> names in .GlobalEnv at the start, and deletes anything new before
>> processing each vignette.? So vignettes could modify or delete what's
>> there, but not add anything.
>>
>> I think you don't want to completely clear out .GlobalEnv, because
>> people might choose to run buildVignettes() in an R session and expect
>> the vignettes to see the contents there.
>>
>> "make check" in R-devel doesn't complain about this change, but I'll let
>> R Core decide whether it's a good idea or not.? A patch is below.
> 
> Clearing the workspace would be an improvement, but I think it would be
> even better for R CMD build to produce each vignette in a clean R
> session, especially with regard to loaded packages. Changing
> buildVignettes() to use clean R processes by default (I'd say even if
> there is only one vignette) should be considered. I'd appreciate seeing
> this report in Bugzilla to investigate further (and not forget).

Yes, that makes sense:  currently R CMD build starts a new clean session 
and runs buildVignettes() there; it would make more sense for 
buildVignettes to be starting a session for each vignette.  Users who 
don't want to run their vignettes in a clean session or who want to see 
the leftovers can still do so, calling Sweave or knit or whatever directly.

I'll post some of this to Bugzilla.

Duncan Murdoch


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Sun Oct 31 10:59:21 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Sun, 31 Oct 2021 10:59:21 +0100
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
 <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
 <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>
Message-ID: <87e89990-ebc4-6879-a34e-4301c3b83563@gmail.com>


On 10/31/21 2:55 AM, Henrik Bengtsson wrote:
>> ... If one still needed backslashes,
>> they could then be entered in single quotes, e.g. VAR='c:\users'.
> I don't think it matters whether you use single or double quotes -
> both will work.  Here's a proof of concept on Linux with R 4.1.1:
>
> $ cat ./.Renviron
> A=C:\users
> B='C:\users'
> C="C:\users"
>
> $ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
>            A           B           C
>    "C:users" "C:\\users" "C:\\users"

Yes, but as I wrote "I think the Renviron files should be written in a 
way so that they would work the same in a POSIX shell". This is why 
single quotes. With double quotes, backslashes are interpreted 
differently from a POSIX shell.

Tomas


>
> /Henrik
>
> On Wed, Oct 27, 2021 at 11:45 AM Tomas Kalibera
> <tomas.kalibera at gmail.com> wrote:
>>
>> On 10/21/21 5:18 PM, Martin Maechler wrote:
>>>>>>>> Micha? Bojanowski
>>>>>>>>       on Wed, 20 Oct 2021 16:31:08 +0200 writes:
>>>       > Hello Tomas,
>>>       > Yes, that's accurate although rather terse, which is perhaps the
>>>       > reason why I did not realize it applies to my case.
>>>
>>>       > How about adding something in the direction of:
>>>
>>>       > 1. Continuing the cited paragraph with:
>>>       > In particular, on Windows it may be necessary to quote references to
>>>       > existing environment variables, especially those containing file paths
>>>       > (which include backslashes). For example: `"${WINVAR}"`.
>>>
>>>       > 2. Add an example (not run):
>>>
>>>       > # On Windows do quote references to variables containing paths, e.g.:
>>>       > # If APPDATA=C:\Users\foobar\AppData\Roaming
>>>       > # to point to a library tree inside APPDATA in .Renviron use
>>>       > R_LIBS_USER="${APPDATA}"/R-library
>>>
>>>       > Incidentally the last example is on backslashes too.
>>>
>>>
>>>       > What do you think?
>>>
>>> I agree that adding an example really helps a lot in such cases,
>>> in my experience, notably if it's precise enough to be used +/- directly.
>> Yes, I agree as well. I think the Renviron files should be written in a
>> way so that they would work the same in a POSIX shell, so e.g.
>> VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to
>> preserve backslashes in VAR0. It is better to use forward slashes in
>> string literals, e.g. VAR="c:/users". If one still needed backslashes,
>> they could then be entered in single quotes, e.g. VAR='c:\users'.
>>
>> The currently implemented parsing of Renviron files differs in a number
>> of details from POSIX shells, some are documented and some are not.
>> Relying only on the documented behavior that is the same as in POSIX
>> shells is the best choice for future compatibility.
>>
>> Tomas
>>
>>>
>>>       > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>>       >>
>>>       >>
>>>       >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
>>>       >> > Perhaps a small update to ?.Renviron would be in order to mention that...
>>>       >>
>>>       >> Would you have a more specific suggestion how to update the
>>>       >> documentation? Please note that it already says
>>>       >>
>>>       >> "?value? is then processed in a similar way to a Unix shell: in
>>>       >> particular the outermost level of (single or double) quotes is stripped,
>>>       >> and backslashes are removed except inside quotes."
>>>       >>
>>>       >> Thanks,
>>>       >> Tomas
>>>       >>
>>>       >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>       >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
>>>       >> >> Thank you all!
>>>       >> >> Michal
>>>       >> >>
>>>       >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>>       >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
>>>       >> >>>
>>>       >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
>>>       >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>       >> >>>
>>>       >> >>>> AVAR=${APPDATA}/foo/bar
>>>       >> >>>>
>>>       >> >>>> Which is a documented way of referring to existing environment
>>>       >> >>>> variables. Now, with that in R I'm getting:
>>>       >> >>>>
>>>       >> >>>> Sys.getenv("APPDATA")    # That works OK
>>>       >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
>>>       >> >>>>
>>>       >> >>>> so OK, but:
>>>       >> >>>>
>>>       >> >>>> Sys.getenv("AVAR")
>>>       >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>>>       >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
>>>       >> >>> but not if they are encountered inside quotes:
>>>       >> >>>
>>>       >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>>>       >> >>>
>>>       >> >>> Would AVAR="${APPDATA}"/foo/bar work?
>>>       >> >>>
>>>       >> >>> --
>>>       >> >>> Best regards,
>>>       >> >>> Ivan
>>>       >> > ______________________________________________
>>>       >> > R-devel at r-project.org mailing list
>>>       >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>       > ______________________________________________
>>>       > R-devel at r-project.org mailing list
>>>       > https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


