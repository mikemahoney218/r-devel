From pgilbert902 at gmail.com  Thu Aug  1 01:14:42 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 31 Jul 2013 19:14:42 -0400
Subject: [Rd] Depends vs Imports
Message-ID: <51F99A62.6040205@gmail.com>

I am being asked to modernize the Depends line in the DESCRIPTION file 
of some packages. Writing R Extensions says:

   The general rules are

      Packages whose namespace only is needed to load the package using
    library(pkgname) must be listed in the ?Imports? field and not in
    the ?Depends? field. Packages listed in imports or importFrom
    directives in the NAMESPACE file should almost always be in
    ?Imports? and not ?Depends?.

      Packages that need to be attached to successfully load the
     package using library(pkgname) must be listed in the
     ?Depends? field, only.

Could someone please explain a few points I thought I understood but 
obviously do not, or point to where these are explained:

    -What does it mean for the namespace only to be needed? I thought 
the namespace was needed if the package or some of its functions were 
mentioned in the NAMESPACE file, and that only the namespace was needed 
if only the generics were called, and not other functions. The above 
suggests that I may be wrong about this. If so, that is, Imports will 
usually suffice, then when would Depends ever be needed when a package 
is mentioned in the NAMESPACE file?

   -Should the package DESCRIPTION make any accommodation for the 
situation where users will probably need to directly call functions in 
the imported package, even though the package itself does not?

    -What does "need to be attached" mean? Is there a distinction 
between a package being attached and a namespace being attached.

    -Does "successfully load" mean something different from actually 
using the package? That is, can we assume that if the package loads then 
all the functions to run things will actually be found?

    -If pkg1 uses a function foo in pkg3 indirectly, by a call to a 
function in  pkg2 which then uses foo, how should pkg1 indicate the 
relationship with foo's pkg3, or is there no need to indicate any 
relationship with pkg3 because that is all looked after by pkg2?

Thanks,
Paul


From simon.urbanek at r-project.org  Thu Aug  1 02:35:19 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 31 Jul 2013 20:35:19 -0400
Subject: [Rd] Depends vs Imports
In-Reply-To: <51F99A62.6040205@gmail.com>
References: <51F99A62.6040205@gmail.com>
Message-ID: <C627D03C-9632-4C9E-850F-AEF71872277D@r-project.org>


On Jul 31, 2013, at 7:14 PM, Paul Gilbert wrote:

> I am being asked to modernize the Depends line in the DESCRIPTION file of some packages. Writing R Extensions says:
> 
>  The general rules are
> 
>     Packages whose namespace only is needed to load the package using
>   library(pkgname) must be listed in the ?Imports? field and not in
>   the ?Depends? field. Packages listed in imports or importFrom
>   directives in the NAMESPACE file should almost always be in
>   ?Imports? and not ?Depends?.
> 
>     Packages that need to be attached to successfully load the
>    package using library(pkgname) must be listed in the
>    ?Depends? field, only.
> 
> Could someone please explain a few points I thought I understood but obviously do not, or point to where these are explained:
> 
>   -What does it mean for the namespace only to be needed? I thought the namespace was needed if the package or some of its functions were mentioned in the NAMESPACE file, and that only the namespace was needed if only the generics were called, and not other functions. The above suggests that I may be wrong about this. If so, that is, Imports will usually suffice, then when would Depends ever be needed when a package is mentioned in the NAMESPACE file?
> 

In the namespace era Depends is never really needed. All modern packages have no technical need for Depends anymore. Loosely speaking the only purpose of Depends today is to expose other package's functions to the user without re-exporting them.


>  -Should the package DESCRIPTION make any accommodation for the situation where users will probably need to directly call functions in the imported package, even though the package itself does not?
> 
>   -What does "need to be attached" mean? Is there a distinction between a package being attached and a namespace being attached.
> 

No, the distinction is between loaded and attached (namespace/package is synonymous here).


>   -Does "successfully load" mean something different from actually using the package? That is, can we assume that if the package loads then all the functions to run things will actually be found?
> 

Define "found" - they will not be attached to the search path, so they will be found if you address them fully via myPackage::myFn but not just via myFn (except for another package that imports myPackage).


>   -If pkg1 uses a function foo in pkg3 indirectly, by a call to a function in  pkg2 which then uses foo, how should pkg1 indicate the relationship with foo's pkg3, or is there no need to indicate any relationship with pkg3 because that is all looked after by pkg2?
> 

There is no need - how would you imagine being responsible for code that you did not write? pkg2 will import function from pkg1, but you're not importing them in pkg3, you don't even care about them so you have no direct relationship with pkg1 (imagine pkg2 switched to use pkg4 instead of pkg1).


IMHO it's all really simple:

load = functions exported in myPkg are available to interested parties as myPkg::foo or via direct imports - essentially this means the package can now be used

attach = the namespace (and thus all exported functions) is attached to the search path - the only effect is that you have now added the exported functions to the global pool of functions - sort of like dumping them in the workspace (for all practical purposes, not technically)

import a function into a package = make sure that this function works in my package regardless of the search path (so I can write fn1 instead of pkg1::fn1 and still know it will come from pkg1 and not someone's workspace or other package that chose the same name)

Cheers,
Simon


From michael.weylandt at gmail.com  Thu Aug  1 04:41:51 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 31 Jul 2013 21:41:51 -0500
Subject: [Rd] Depends vs Imports
In-Reply-To: <C627D03C-9632-4C9E-850F-AEF71872277D@r-project.org>
References: <51F99A62.6040205@gmail.com>
	<C627D03C-9632-4C9E-850F-AEF71872277D@r-project.org>
Message-ID: <CAAmySGNr_dYq3_=cDGoOtFius_h5GJC=3sZqRuYJFqC0DhvgWw@mail.gmail.com>

On Wed, Jul 31, 2013 at 7:35 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Jul 31, 2013, at 7:14 PM, Paul Gilbert wrote:
>
>> I am being asked to modernize the Depends line in the DESCRIPTION file of some packages. Writing R Extensions says:
>>
>>  The general rules are
>>
>>     Packages whose namespace only is needed to load the package using
>>   library(pkgname) must be listed in the ?Imports? field and not in
>>   the ?Depends? field. Packages listed in imports or importFrom
>>   directives in the NAMESPACE file should almost always be in
>>   ?Imports? and not ?Depends?.
>>
>>     Packages that need to be attached to successfully load the
>>    package using library(pkgname) must be listed in the
>>    ?Depends? field, only.
>>
>> Could someone please explain a few points I thought I understood but obviously do not, or point to where these are explained:
>>
>>   -What does it mean for the namespace only to be needed? I thought the namespace was needed if the package or some of its functions were mentioned in the NAMESPACE file, and that only the namespace was needed if only the generics were called, and not other functions. The above suggests that I may be wrong about this. If so, that is, Imports will usually suffice, then when would Depends ever be needed when a package is mentioned in the NAMESPACE file?
>>
>
> In the namespace era Depends is never really needed. All modern packages have no technical need for Depends anymore. Loosely speaking the only purpose of Depends today is to expose other package's functions to the user without re-exporting them.
>

Just to make sure I understand this: an example would be if A provides
an S3 generic and B provides a (registered but unexported) method for
that generic -- this would be a great time for B to list A as
"Depends" instead of "Imports" to make sure the generic is available
to the user?

Thanks,
Michael


From pgilbert902 at gmail.com  Thu Aug  1 05:12:27 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 31 Jul 2013 23:12:27 -0400
Subject: [Rd] Depends vs Imports
In-Reply-To: <C627D03C-9632-4C9E-850F-AEF71872277D@r-project.org>
References: <51F99A62.6040205@gmail.com>
	<C627D03C-9632-4C9E-850F-AEF71872277D@r-project.org>
Message-ID: <51F9D21B.3060000@gmail.com>

Simon

Thanks, that helps a lot, but see below ..

On 13-07-31 08:35 PM, Simon Urbanek wrote:
>
> On Jul 31, 2013, at 7:14 PM, Paul Gilbert wrote:
>
>> I am being asked to modernize the Depends line in the DESCRIPTION
>> file of some packages. Writing R Extensions says:
>>
>> The general rules are
>>
>> Packages whose namespace only is needed to load the package using
>> library(pkgname) must be listed in the ?Imports? field and not in
>> the ?Depends? field. Packages listed in imports or importFrom
>> directives in the NAMESPACE file should almost always be in
>> ?Imports? and not ?Depends?.
>>
>> Packages that need to be attached to successfully load the package
>> using library(pkgname) must be listed in the ?Depends? field,
>> only.
>>
>> Could someone please explain a few points I thought I understood
>> but obviously do not, or point to where these are explained:
>>
>> -What does it mean for the namespace only to be needed? I thought
>> the namespace was needed if the package or some of its functions
>> were mentioned in the NAMESPACE file, and that only the namespace
>> was needed if only the generics were called, and not other
>> functions. The above suggests that I may be wrong about this. If
>> so, that is, Imports will usually suffice, then when would Depends
>> ever be needed when a package is mentioned in the NAMESPACE file?
>>
>
> In the namespace era Depends is never really needed. All modern
> packages have no technical need for Depends anymore. Loosely speaking
> the only purpose of Depends today is to expose other package's
> functions to the user without re-exporting them.

This seems to mostly work, except in the situation where a package is 
used that enhances an imported package. For example, I Import DBI but 
the call dbDriver("MySQL") fails looking for MySQL in package RMySQL if 
I only import that and do not list it in Depends. Am I missing something?

Similarly, I have a package tframePlus that provides extra methods (for 
zoo and xts) for my package tframe. Since tframe does not depend or 
import tframePlus (in fact, the reverse), I seem to need tframePlus in 
Depends not Imports of another package that Imports tframe. Does this 
sound right or am I missing something else?

Also, I have a package TSMySQL which enhances my package TSdbi. When a 
user uses TSMySQL they will want to use many functions in TSdbi. Here 
again, I seem to need TSMySQL to Depend on TSdbi, for the reason you 
mention, exposing all the functions to the user.

(I'm glad this is simple, I have trouble when things are difficult.)

Thanks again,
Paul
>
>
>> -Should the package DESCRIPTION make any accommodation for the
>> situation where users will probably need to directly call functions
>> in the imported package, even though the package itself does not?
>>
>> -What does "need to be attached" mean? Is there a distinction
>> between a package being attached and a namespace being attached.
>>
>
> No, the distinction is between loaded and attached (namespace/package
> is synonymous here).
>
>
>> -Does "successfully load" mean something different from actually
>> using the package? That is, can we assume that if the package loads
>> then all the functions to run things will actually be found?
>>
>
> Define "found" - they will not be attached to the search path, so
> they will be found if you address them fully via myPackage::myFn but
> not just via myFn (except for another package that imports
> myPackage).
>
>
>> -If pkg1 uses a function foo in pkg3 indirectly, by a call to a
>> function in  pkg2 which then uses foo, how should pkg1 indicate the
>> relationship with foo's pkg3, or is there no need to indicate any
>> relationship with pkg3 because that is all looked after by pkg2?
>>
>
> There is no need - how would you imagine being responsible for code
> that you did not write? pkg2 will import function from pkg1, but
> you're not importing them in pkg3, you don't even care about them so
> you have no direct relationship with pkg1 (imagine pkg2 switched to
> use pkg4 instead of pkg1).
>
>
> IMHO it's all really simple:
>
> load = functions exported in myPkg are available to interested
> parties as myPkg::foo or via direct imports - essentially this means
> the package can now be used
>
> attach = the namespace (and thus all exported functions) is attached
> to the search path - the only effect is that you have now added the
> exported functions to the global pool of functions - sort of like
> dumping them in the workspace (for all practical purposes, not
> technically)
>
> import a function into a package = make sure that this function works
> in my package regardless of the search path (so I can write fn1
> instead of pkg1::fn1 and still know it will come from pkg1 and not
> someone's workspace or other package that chose the same name)
>
> Cheers, Simon
>
>


From Thierry.ONKELINX at inbo.be  Thu Aug  1 11:18:57 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 1 Aug 2013 09:18:57 +0000
Subject: [Rd] Error from R CMD check
In-Reply-To: <51F7A0EC.4070502@gmail.com>
References: <AA818EAD2576BC488B4F623941DA7427CD31C519@inbomail.inbo.be>
	<51F7A0EC.4070502@gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD31EC63@inbomail.inbo.be>

Dear Duncan,

Thank you for your suggestion. R CMD check is no longer failing to install the package.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Verzonden: dinsdag 30 juli 2013 13:18
Aan: ONKELINX, Thierry
CC: r-devel at r-project.org
Onderwerp: Re: [Rd] Error from R CMD check

On 13-07-30 6:34 AM, ONKELINX, Thierry wrote:
> Dear all,
>
> I'm puzzled by the error I get from R CMD check one of my packages. I'm running R CMD check with the --as-cran flag and it get the error both from running it from the command line as from within Rstudio. On the same machine R CMD check on my GRTS package (https://r-forge.r-project.org/R/?group_id=1027) works fine.
>
> Any suggestions on how to fix this? I can send the source code in a private email if required.
>
> Best regards,
>
> Thierry
>
> Output from Rcmd.exe check --as-cran watervogels_0.3-27.tar.gz
>
>
> * using log directory 'U:/svn2/watervogels/watervogels.Rcheck'
> * using R version 3.0.1 Patched (2013-07-14 r63298)
> * using platform: i386-w64-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'watervogels/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'watervogels' version '0.3-27'
> * package encoding: UTF-8
> * checking CRAN incoming feasibility ... NOTE
> Maintainer: 'Thierry Onkelinx <Thierry.Onkelinx at inbo.be>'
> New submission
> Non-FOSS package license (Private package of the Research Institute
> for Nature and
> Forest)
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking whether package 'watervogels' can be installed ... ERROR
> Installation failed.
> See 'U:/svn2/watervogels/watervogels.Rcheck/00install.out' for details.
>
> Exited with status 1.
>
>
>
> Output from 00install.out
>
> * installing *source* package 'watervogels' ...
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded Warning in
> Sys.junction(from, to) :
>    cannot set reparse point 'C:\DOCUME~1\THIERR~2\LOCALS~1\Temp\RtmpMZUCyo\RLIBS_15585fa46d84/watervogels', reason 'De in de reparsepuntbuffer aanwezige gegevens zijn ongeldig'
> Error in flink(normalizePath(pkgdir), tmplib) :
>    cannot link from
> U:\svn2\watervogels\watervogels.Rcheck\00_pkg_src\watervogels
> * removing 'U:/svn2/watervogels/watervogels.Rcheck/watervogels'
>
> A translation of the error message: The data in the reparse point buffer are invalid.

It's hard to diagnose the cause of the error, but you can avoid the use of junctions by setting the environment variable R_WIN_NO_JUNCTIONS to some non-empty content, and that might avoid it.

Duncan Murdoch

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From hb at biostat.ucsf.edu  Thu Aug  1 19:26:56 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 1 Aug 2013 10:26:56 -0700
Subject: [Rd] Adding text comments to graphics device output files?
In-Reply-To: <D25A53EE-AAC2-42DA-8264-FD5E602DBB33@r-project.org>
References: <CAFDcVCTHb65JCh+uREyczADbgRfMNYHNUJx+PuitpPb1ahASPA@mail.gmail.com>
	<51F87EBE.3070803@ucdavis.edu>
	<CAFDcVCQ1WeqcX-GShEoZ8-OSwaaRY6EdvxUsH_A=sh7h94z7UA@mail.gmail.com>
	<D25A53EE-AAC2-42DA-8264-FD5E602DBB33@r-project.org>
Message-ID: <CAFDcVCQP_L=HBcK7_WZVD5iWsWDsqZgjGc=6S3=q5N4qRuX2CA@mail.gmail.com>

Thank you both. It works like a charm (tried it on Windows).

/Henrik

On Wed, Jul 31, 2013 at 7:17 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Jul 31, 2013, at 12:12 AM, Henrik Bengtsson wrote:
>
>> Hi Duncan,
>>
>> this is perfect timing.  Your
>> https://github.com/duncantl/png/blob/master/testMeta.R example
>> illustrates what I'm looking for.
>>
>> Yes, it would be great if this would be incorporated into the 'png' package.
>>
>
> Ok, I have added support for both text chunks and arbitrary R metadata to the PNG package.
> http://rforge.net/png
> The it is based on Duncan's idea, but the implementation and API is different -- Duncan's approach was implemented before png has support for the PNG info, so it is now simply extending that concept. You can store native text key/values pairs. In addition, R-native matadata can be attached -- it is stored as a special key "R.metadata" holding the serialization of the R object. See the last example in
> http://rforge.net/doc/packages/png/writePNG.html
> Feedback is welcome.
>
> Cheers,
> Simon
>
>
>
>> Thanks,
>>
>> Henrik
>>
>> On Tue, Jul 30, 2013 at 8:04 PM, Duncan Temple Lang
>> <dtemplelang at ucdavis.edu> wrote:
>>>
>>> Hi Henrik
>>>
>>> I have some extensions of Simon U's png package
>>> to read and write metadata elements for PNG.
>>> They are at
>>>   https://github.com/duncantl/png.git
>>>
>>> When I have time to completely test them, maybe Simon
>>> may incorporate them.
>>>
>>>  D.
>>>
>>> On 7/30/13 7:59 PM, Henrik Bengtsson wrote:
>>>> Hi,
>>>>
>>>> several image file format supports textual/meta data comments in one
>>>> way or the other.  For me an obvious usage would be to add
>>>> sessionInfo() information to PNG and PDF image files, ideally from
>>>> within R although external tools would work as well(*).  Has anyone
>>>> looked into this or have any suggestions or comments?
>>>>
>>>> /Henrik
>>>>
>>>> (*) One could even imagine including self-contained R
>>>> scripts/vignettes within such comments.
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From skostysh at princeton.edu  Sat Aug  3 11:56:23 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 3 Aug 2013 05:56:23 -0400
Subject: [Rd] tk + browser() can leave R unresponsive
Message-ID: <CAE3=dmcTJt-HMSj4gBSjuitt_LfmhLZihm--qPp3tUGTzJO0aw@mail.gmail.com>

I don't know if this is a bug. I can reproduce the following on Ubuntu
12.04.2 and 13.04 64-bit with R version 3.0.1 and with r63479. There
is no difference if R is patched with the fix for PR#15407 or not,
although without the fix there are more ways to trigger this.

I can reproduce with the following:

1. Open R in gnome-terminal or xterm

2. Run 'library(tcltk)'

3. Run 'trace(tk_select.list, edit = TRUE)'
and put "browser()" at the beginning of the onOK body (e.g. in Vim run
<<:g/onOK/put ='browser()'>>). That is, transform

    onOK <- function() {
        res <- 1L + as.integer(tkcurselection(box))
        cat("res is: ", res)
        ans.select_list <<- choices[res]
        tkgrab.release(dlg)
        tkdestroy(dlg)
    }

to:

    onOK <- function() {
        browser()
        res <- 1L + as.integer(tkcurselection(box))
        cat("res is: ", res)
        ans.select_list <<- choices[res]
        tkgrab.release(dlg)
        tkdestroy(dlg)
    }

4. Run 'install.packages()'

5. Double-click on a package

R becomes unresponsive and I have to kill it.

> sessionInfo()
R Under development (unstable) (2013-08-02 r63479)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From skostysh at princeton.edu  Sat Aug  3 12:06:39 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 3 Aug 2013 06:06:39 -0400
Subject: [Rd] tk + browser() can leave R unresponsive
In-Reply-To: <CAE3=dmcTJt-HMSj4gBSjuitt_LfmhLZihm--qPp3tUGTzJO0aw@mail.gmail.com>
References: <CAE3=dmcTJt-HMSj4gBSjuitt_LfmhLZihm--qPp3tUGTzJO0aw@mail.gmail.com>
Message-ID: <CAE3=dmebOXxzdq2iBkeZJSRwwW-=yfUfnjcJihpLKCK24NsFvw@mail.gmail.com>

On Sat, Aug 3, 2013 at 5:56 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> I don't know if this is a bug. I can reproduce the following on Ubuntu
> 12.04.2 and 13.04 64-bit with R version 3.0.1 and with r63479. There
> is no difference if R is patched with the fix for PR#15407 or not,
> although without the fix there are more ways to trigger this.
>
> I can reproduce with the following:
>
> 1. Open R in gnome-terminal or xterm
>
> 2. Run 'library(tcltk)'
>
> 3. Run 'trace(tk_select.list, edit = TRUE)'
> and put "browser()" at the beginning of the onOK body (e.g. in Vim run
> <<:g/onOK/put ='browser()'>>). That is, transform
>
>     onOK <- function() {
>         res <- 1L + as.integer(tkcurselection(box))
>         cat("res is: ", res)
>         ans.select_list <<- choices[res]
>         tkgrab.release(dlg)
>         tkdestroy(dlg)
>     }
>
> to:
>
>     onOK <- function() {
>         browser()
>         res <- 1L + as.integer(tkcurselection(box))
>         cat("res is: ", res)
>         ans.select_list <<- choices[res]
>         tkgrab.release(dlg)
>         tkdestroy(dlg)
>     }
>
> 4. Run 'install.packages()'
>
> 5. Double-click on a package
>
> R becomes unresponsive and I have to kill it.
>
>> sessionInfo()
> R Under development (unstable) (2013-08-02 r63479)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University

This might be related to PR#14730. I will add this info there unless
someone suggests otherwise.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From ripley at stats.ox.ac.uk  Sat Aug  3 19:06:08 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 03 Aug 2013 18:06:08 +0100
Subject: [Rd] [R] Internalization of help pages
In-Reply-To: <CAGKU+8CMoDkZgkd1dvXa2QMWJVXkvJVfH7n9pZePtNEYkAu3ww@mail.gmail.com>
References: <CAGKU+8B57gJWPCxbDR9-SGZd2W8Ukhn=u40VgzwTJACUqb7f=w@mail.gmail.com>
	<CACk-te30KOYkr6QjCyAQXRjG3hUMnRraXJeLwuKercxgoXun3w@mail.gmail.com>
	<CAGKU+8CMoDkZgkd1dvXa2QMWJVXkvJVfH7n9pZePtNEYkAu3ww@mail.gmail.com>
Message-ID: <51FD3880.6070506@stats.ox.ac.uk>

This was an R-devel topic, and I have moved it where it belongs.  See 
the posting guide.

On 03/08/2013 08:34, Tom?? Greif wrote:
> Bert,
>
> thank you for your response.
>
> I understand this would be huge task. My idea is:
>
> 1. Translation of help files is optional, driven by demand. This way (as I
> believe) core packages will get translated first, followed by some other
> CRAN packages. I don't expect that every page is translated.

It is not just a question of translating, but keeping translations up to 
date.  Even for messages, the latter is an issue.

>
> 2. Use collaborative open-source tools for translation. For example crowdin
> is online translation tool free for open-source projects. Alternatively,
> wiki can be used for translation (it would be however necessary to program
> link to upload original translation and download translations back)
>
> 3. When browsing help, file based on user's locale will be displayed (if
> exists) with failover to default (English).

You had better check the version that was translated, and that is not 
currently recorded in the file.

> I agree with you that translation has to be exact. However, I believe that
> users can benefit more from slightly inexact documentation written in their
> first language than from exact documentation in language they do not
> understand well.

That is a matter of opinion: many people have the opposite opinion.

> Any idea how to create proof of concept for this? I guess this would
> require attention from someone from r-core team.

Not so.  R is Open Source: just go ahead and do it.  You can contribute 
patches via bugs.r-project.org.   But note that this would not get 
released under R 3.1.0 ca Mar 2014, so there is plenty of time to iron 
this out and submit a fully working solution.

Another small issue is size.  For R itself the 'English' (mostly 
American) help pages are about 10MB installed.  Adding help pages for, 
say, the 15 languages for which we have translated messages would 
increase the size of R about 2.5x.

>
> Regards,
>
> Tomas
>
>
> On 3 August 2013 01:39, Bert Gunter <gunter.berton at gene.com> wrote:
>
>> Tom????
>>
>> 1.  Your concern is valid, especially now that R has become so widely
>> used throughout the world. But language translation is hard.
>>
>> 2. Warning and error messages are short, and relatively trivial to
>> translate.
>>
>> 3. There are tens of thousands of Help pages in thousands of packages,
>> most separately maintained.
>>
>> I would guess that the best option would be to try to run the files
>> through a mature, open source translator, if such exists. However, I'm
>> ignorant of such matters. And my understanding is that at present,
>> even the best may not be adequate (Help files have to accurate in
>> exact detail).
>>
>>
>>
>> Best,
>> Bert
>>
>> On Fri, Aug 2, 2013 at 2:54 PM, Tom???? Greif
>> <tomas.greif at collectionspro.eu> wrote:
>>> Is it possible to translate help files? I see there are some localization
>>> options for GUI, but not for help. I think this would be really helpful
>> for
>>> users who don't have English as their primary language.
>>>
>>> Because all the online help is created from text files, it should be not
>>> that difficult to maintain different language versions (e.g. to mark them
>>> as not valid when primary documentation in English changes).
>>>
>>> Regards,
>>>
>>> Tomas Greif
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>>
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tal.galili at gmail.com  Sun Aug  4 09:02:59 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Sun, 4 Aug 2013 10:02:59 +0300
Subject: [Rd] R crashes when using cutree after as.hclust on a subset of a
	dendrogram
Message-ID: <CANdJ3dUVweNi1nEN4GCRMLGpxBz2avHmhymbmKNOooxy21N+6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130804/0d990008/attachment.pl>

From bhh at xs4all.nl  Sun Aug  4 21:33:35 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 4 Aug 2013 21:33:35 +0200
Subject: [Rd] Redundant text in help page for eigen
Message-ID: <B2DC9A53-D697-4A16-8E89-E99569D6B927@xs4all.nl>



I noticed that there is some redundant text in eigen.Rd (both the patched and the devel version).

"whereas" appears to be a leftover of previous versions.

\source{
  By default \code{eigen} uses the LAPACK routines \code{DSYEVR},
  \code{DGEEV}, \code{ZHEEV} and \code{ZGEEV} whereas

  LAPACK is from \url{http://www.netlib.org/lapack} and its guide is listed
  in the references.
}



Berend

From b.rowlingson at lancaster.ac.uk  Mon Aug  5 00:22:23 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 4 Aug 2013 23:22:23 +0100
Subject: [Rd] [R] Internalization of help pages
In-Reply-To: <84705d8af5c14f2a886fe96afb4bcd56@EX-0-HT0.lancs.local>
References: <cagku+8b57gjwpcxbdr9-sgzd2w8ukhn=u40vgzwtjacuqb7f=w@mail.gmail.com>
	<51fd9e3c.4080202@bitwrit.com.au>
	<cack-te30koykr6qjcyaqxrjg3humnrraxjelwukercxgoxun3w@mail.gmail.com>
	<cagku+8cmodkzgkd1dvxa2qmwjvxkvjvfh7n9pzeptneykau3ww@mail.gmail.com>
	<51FDA03A.5020304@bitwrit.com.au>
	<84705d8af5c14f2a886fe96afb4bcd56@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMX1g0bLwRbQ-F_-mX9Sk0HbvxWjfxXQLc7F--sVZU_wQ@mail.gmail.com>

[I've tried to move this back to R-devel, which I think is what Brian
Ripley tried and nobody followed...]

On Sun, Aug 4, 2013 at 4:15 PM, John Kane <jrkrideau at inbox.com> wrote:
> I tried it in French and there a few hiccups but it's not too bad.
>
> Personally I'd like to see the help tranlated into English too.l
>
> John Kane
> Kingston ON Canada

 The problems of getting translations for help pages are many-fold:

1. Giving translators access to current .Rd files, which is tricky
when people are developing with roxygen2.
2. Finding translators to do the work. There are a lot of tools for
helping translate message files, but whole .Rd docs might be too much
for the casual translator.
3. Having a standard way to display help in language X if it exists,
considering the complexity of R's help (plain text, web, PDF
versions). Put it all in help/XX and html/XX and doc/XX for XX in
languages?
4. As (3) but with vignettes. Wouldn't vignette("foo",language="fr")
be nice if "foo" was available in French? Or vignette(language="de")
to get all German vignettes?
5. Language bloat. Best solved by making language documentation 'add
on' packs. Easier for a package developer to do for one package, hard
for core R with several packages and core documentation.
6. How do you integrate that with CRAN?
7. Does CRAN have to build all the built languages documentation from
the language .Rd files? A standard repository structure on github and
some github_ wrapper functions might help kick this off since there
wouldn't be a need to bother the busy CRAN people with things.

Of all of that I reckon foreign-language vignette support might be the
easiest to implement. It would seem to require a way for an author to
specify the language of a vignette, a standard place for languaged
vignettes (source and built), and a mod to the vignette function to
look in those places.

The comparable translation project I know of is the translation of
documents for the OSGeo Live DVD - this consists of translations of
short project introductions and walkthroughs (with screenshots) for
about 50 pieces of software, which is probably of the order of
difficulty of translating an R package with about 100 well-documented
functions. It works well but it does have a lot of commitment from
everyone every six months at the release points.

However, getting all the R documentation translated is probably easier
than getting everyone to speak english - we started trying to do that
in the 18th century and look how that turned out...

Barry


From bbolker at gmail.com  Mon Aug  5 15:31:21 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 5 Aug 2013 09:31:21 -0400
Subject: [Rd] proposal for new FAQ entry?
Message-ID: <CABghstQXootK=zEH=QcSNur1JzAYF1dY_+AxBWvBSWp3gBZbXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130805/20f9d8af/attachment.pl>

From pdalgd at gmail.com  Mon Aug  5 15:53:58 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 5 Aug 2013 15:53:58 +0200
Subject: [Rd] proposal for new FAQ entry?
In-Reply-To: <CABghstQXootK=zEH=QcSNur1JzAYF1dY_+AxBWvBSWp3gBZbXQ@mail.gmail.com>
References: <CABghstQXootK=zEH=QcSNur1JzAYF1dY_+AxBWvBSWp3gBZbXQ@mail.gmail.com>
Message-ID: <8127FBD3-1294-491F-95DD-75E738995AD6@gmail.com>


On Aug 5, 2013, at 15:31 , Ben Bolker wrote:

> "Why did read.table stop reading my file" is a pretty FAQ, e.g.
> 
> http://thread.gmane.org/gmane.comp.lang.r.general/297406/focus=297409
> 
> (I could come up with a lot more examples if someone wanted).
> 
> The answer is typically "check for spurious comment characters and
> unmatched quotation marks"

Or, diddle comment.char=/quote=  argument settings in cases where the commenting/quoting features themselves were unexpected.

> 
> Does this seem FAQ-worthy? Should I e-mail the FAQ maintainer and suggest
> it?

Sure, as long as we never change the numbering of FAQ 7.31...

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From b.rowlingson at lancaster.ac.uk  Mon Aug  5 16:11:04 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 5 Aug 2013 15:11:04 +0100
Subject: [Rd] proposal for new FAQ entry?
In-Reply-To: <c0d0ad20487142e7a6b39183218c2a0a@EX-1-HT0.lancs.local>
References: <CABghstQXootK=zEH=QcSNur1JzAYF1dY_+AxBWvBSWp3gBZbXQ@mail.gmail.com>
	<c0d0ad20487142e7a6b39183218c2a0a@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPySuX=U7kvRrnTyQadXmeq8gZzXutzxXZNV28cRgjCTQ@mail.gmail.com>

On Mon, Aug 5, 2013 at 2:53 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>> Does this seem FAQ-worthy? Should I e-mail the FAQ maintainer and suggest
>> it?
>
> Sure, as long as we never change the numbering of FAQ 7.31...
>

 Not even to FAQ 7.31+1e-15 ?

Barry


From pdalgd at gmail.com  Mon Aug  5 17:37:30 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 5 Aug 2013 17:37:30 +0200
Subject: [Rd] proposal for new FAQ entry?
In-Reply-To: <CANVKczPySuX=U7kvRrnTyQadXmeq8gZzXutzxXZNV28cRgjCTQ@mail.gmail.com>
References: <CABghstQXootK=zEH=QcSNur1JzAYF1dY_+AxBWvBSWp3gBZbXQ@mail.gmail.com>
	<c0d0ad20487142e7a6b39183218c2a0a@EX-1-HT0.lancs.local>
	<CANVKczPySuX=U7kvRrnTyQadXmeq8gZzXutzxXZNV28cRgjCTQ@mail.gmail.com>
Message-ID: <A96CB45A-8D10-4E98-BA55-0304F1D24C8E@gmail.com>


On Aug 5, 2013, at 16:11 , Barry Rowlingson wrote:

> On Mon, Aug 5, 2013 at 2:53 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>>> Does this seem FAQ-worthy? Should I e-mail the FAQ maintainer and suggest
>>> it?
>> 
>> Sure, as long as we never change the numbering of FAQ 7.31...
>> 
> 
> Not even to FAQ 7.31+1e-15 ?
> 

Why would R think those numbers are equal?

(Yes, Virginia, there _is_ an answer!)

-pd



> Barry

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From greif.tomas at gmail.com  Mon Aug  5 21:31:49 2013
From: greif.tomas at gmail.com (=?UTF-8?B?VG9tw6HFoSBHcmVpZg==?=)
Date: Mon, 5 Aug 2013 21:31:49 +0200
Subject: [Rd] [R] Internalization of help pages
In-Reply-To: <CANVKczMX1g0bLwRbQ-F_-mX9Sk0HbvxWjfxXQLc7F--sVZU_wQ@mail.gmail.com>
References: <cagku+8b57gjwpcxbdr9-sgzd2w8ukhn=u40vgzwtjacuqb7f=w@mail.gmail.com>
	<51fd9e3c.4080202@bitwrit.com.au>
	<cack-te30koykr6qjcyaqxrjg3humnrraxjelwukercxgoxun3w@mail.gmail.com>
	<cagku+8cmodkzgkd1dvxa2qmwjvxkvjvfh7n9pzeptneykau3ww@mail.gmail.com>
	<51FDA03A.5020304@bitwrit.com.au>
	<84705d8af5c14f2a886fe96afb4bcd56@EX-0-HT0.lancs.local>
	<CANVKczMX1g0bLwRbQ-F_-mX9Sk0HbvxWjfxXQLc7F--sVZU_wQ@mail.gmail.com>
Message-ID: <CAGKU+8A1qSkgZeiLd9cTW9TVEmS2VARLyOF8eH_=K=CDEGg4Ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130805/1e7824eb/attachment.pl>

From jim at bitwrit.com.au  Tue Aug  6 06:03:44 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 06 Aug 2013 14:03:44 +1000
Subject: [Rd] [R] Internalization of help pages
In-Reply-To: <CAGKU+8BZFjCytebgmSKVrx-6W4XtjBZ5yu2OYdskPahtxoY7-w@mail.gmail.com>
References: <cagku+8b57gjwpcxbdr9-sgzd2w8ukhn=u40vgzwtjacuqb7f=w@mail.gmail.com>
	<51fd9e3c.4080202@bitwrit.com.au>
	<cack-te30koykr6qjcyaqxrjg3humnrraxjelwukercxgoxun3w@mail.gmail.com>
	<cagku+8cmodkzgkd1dvxa2qmwjvxkvjvfh7n9pzeptneykau3ww@mail.gmail.com>
	<51FDA03A.5020304@bitwrit.com.au>
	<84705d8af5c14f2a886fe96afb4bcd56@EX-0-HT0.lancs.local>
	<CANVKczMX1g0bLwRbQ-F_-mX9Sk0HbvxWjfxXQLc7F--sVZU_wQ@mail.gmail.com>
	<CAGKU+8BZFjCytebgmSKVrx-6W4XtjBZ5yu2OYdskPahtxoY7-w@mail.gmail.com>
Message-ID: <520075A0.4040508@bitwrit.com.au>

On 08/06/2013 12:12 AM, Tom?? Greif wrote:
> My original idea was to start translating Rd files directly. It looks
> easy to just skip all the tags and translate rest (but maybe I'm wrong
> on this). I'm sure we can figure out better ways to do this later.
> ...
That was essentially the way I did the translation. I was thinking more 
of a distributed solution, with either package maintainers or foreign 
language R groups (or both) creating packages with non-English help 
files that could be downloaded from non-CRAN sites. The Babel problem 
has flung many an open source project into a tar pit of ever-expanding 
dimensions.

I liked the following:

>     However, getting all the R documentation translated is probably easier
>     than getting everyone to speak english - we started trying to do that
>     in the 18th century and look how that turned out...
>
>     Barry
>
but maybe getting most of the people to speak English all of the time 
(pace Abraham Lincoln) remains the optimal solution.

Jim


From un_tonio at yahoo.com  Tue Aug  6 13:58:51 2013
From: un_tonio at yahoo.com (Tonio)
Date: Tue, 6 Aug 2013 04:58:51 -0700 (PDT)
Subject: [Rd] Error in building pdf manual with Rtools
Message-ID: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130806/fddca1e4/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Aug  7 13:42:34 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 07 Aug 2013 12:42:34 +0100
Subject: [Rd] Error in building pdf manual with Rtools
In-Reply-To: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>
References: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>
Message-ID: <520232AA.4070306@stats.ox.ac.uk>

On 06/08/2013 12:58, Tonio wrote:
> Dear list,
>
> I am trying to produce a pdf manual using Rtools (version 3.1.0.1936) on Windows 8 (64-bit). I am also aware of the inconsolata issue posted in the forum (https://stat.ethz.ch/pipermail/r-devel/2013-June/066850.html), and then I have installed the patched version of R-3.0.1. However I still have some errors with the following message:
>
> R CMD Rd2pdf mypack
> Hmm ... looks like a package
> Converting Rd files to LaTeX ....
> Creating pdf output from LaTeX ...
> Warning: running command '"C:\PROGRA~1\MIKTEX~1.9\miktex\bin\x64\texi2dvi.exe"
> --pdf "Rd2.tex"  -I "C:/PROGRA~1/R/R-30~1.1PA/share/texmf/tex/latex" -I "C:/PROG
> RA~1/R/R-30~1.1PA/share/texmf/bibtex/bst"' had status 1
> Error : running 'texi2dvi' on 'Rd2.tex' failed
>
> LaTeX errors:
> !pdfTeX error: pdflatex.EXE (file ts1-zi4r): Font ts1-zi4r at 540 not found
>   ==> Fatal error occurred, no output PDF file produced!
>
> Error in running tools::texi2pdf()
>
>
>
>
> The MiKTeX I use is 2.9 and apparently it has no problem in building files with the inconsolata-zi4 packages, since there is the ts1-zi4r.tfm file.

Evidently there is such a problem.  My guess is that your MiKTeX is 
missing an entry for the inconsolata map: zi4.map contains

ts1-zi4r Inconsolata-zi4r " zi4TS1Encoding ReEncodeFont " <i4-ts1.enc 
<Inconsolata-zi4r.pfb

This is neither an Rtools nor an R-devel issue, but a TeX one.

> Any help with this issue will be much appreciated.
>
>
> Best,
> Antonio



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From un_tonio at yahoo.com  Wed Aug  7 20:29:28 2013
From: un_tonio at yahoo.com (Tonio)
Date: Wed, 7 Aug 2013 11:29:28 -0700 (PDT)
Subject: [Rd] Error in building pdf manual with Rtools
In-Reply-To: <520232AA.4070306@stats.ox.ac.uk>
References: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>
	<520232AA.4070306@stats.ox.ac.uk>
Message-ID: <1375900168.25455.YahooMailNeo@web124504.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130807/402ba4f0/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Aug  8 17:30:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 08 Aug 2013 16:30:43 +0100
Subject: [Rd] Error in building pdf manual with Rtools
In-Reply-To: <1375900168.25455.YahooMailNeo@web124504.mail.ne1.yahoo.com>
References: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>
	<520232AA.4070306@stats.ox.ac.uk>
	<1375900168.25455.YahooMailNeo@web124504.mail.ne1.yahoo.com>
Message-ID: <5203B9A3.1050202@stats.ox.ac.uk>

On 07/08/2013 19:29, Tonio wrote:
> Many thanks for your reply.
>
> Actually such entry --the one for ts1-zi4r, and the other one for ts1-zi4b as well-- are both included in the zi4.map
>
> I agree that this is an issue for the TeX community, and in particular for MiKTeX users. However it seems that there is not a clear answer yet on this issue, and this brings some consequences in transforming the Rd files.

Not for users with properly configured systems ....

> Best regards,
> Tonio
>
>
>
>
>
> ________________________________
>   Fra: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Til: r-devel at r-project.org
> Sendt: 13:42 onsdag den 7. august 2013
> Emne: Re: [Rd] Error in building pdf manual with Rtools
>
>
> On 06/08/2013 12:58, Tonio wrote:
>> Dear list,
>>
>> I am trying to produce a pdf manual using Rtools (version 3.1.0.1936) on Windows 8 (64-bit). I am also aware of the inconsolata issue posted in the forum (https://stat.ethz.ch/pipermail/r-devel/2013-June/066850.html), and then I have installed the patched version of R-3.0.1. However I still have some errors with the following message:
>>
>> R CMD Rd2pdfmypack
>> Hmm ... looks like a package
>> Converting Rd files to LaTeX ....
>> Creating pdf output from LaTeX ...
>> Warning: running command '"C:\PROGRA~1\MIKTEX~1.9\miktex\bin\x64\texi2dvi.exe"
>> --pdf "Rd2.tex"  -I "C:/PROGRA~1/R/R-30~1.1PA/share/texmf/tex/latex" -I "C:/PROG
>> RA~1/R/R-30~1.1PA/share/texmf/bibtex/bst"' had status 1
>> Error : running 'texi2dvi' on 'Rd2.tex' failed
>>
>> LaTeX errors:
>> !pdfTeX error: pdflatex.EXE (file ts1-zi4r): Font ts1-zi4r at 540 not found
> [[elided Yahoo spam]]
>>
>> Error in running tools::texi2pdf()
>>
>>
>>
>>
>> The MiKTeX I use is 2.9 and apparently it has no problem in building files with the inconsolata-zi4 packages, since there is the ts1-zi4r.tfm file.
>
> Evidently there is such a problem.  My guess is that your MiKTeX is
> missing an entry for the inconsolata map: zi4.map contains
>
> ts1-zi4r Inconsolata-zi4r " zi4TS1Encoding ReEncodeFont " <i4-ts1.enc
> <Inconsolata-zi4r.pfb
>
> This is neither an Rtools nor an R-devel issue, but a TeX one.
>
>> Any help with this issue will be much appreciated.
>>
>>
>> Best,
>> Antonio
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From un_tonio at yahoo.com  Thu Aug  8 17:42:12 2013
From: un_tonio at yahoo.com (Tonio)
Date: Thu, 8 Aug 2013 08:42:12 -0700 (PDT)
Subject: [Rd] Error in building pdf manual with Rtools
In-Reply-To: <5203B9A3.1050202@stats.ox.ac.uk>
References: <1375790331.3973.YahooMailNeo@web124506.mail.ne1.yahoo.com>	<520232AA.4070306@stats.ox.ac.uk>	<1375900168.25455.YahooMailNeo@web124504.mail.ne1.yahoo.com>
	<5203B9A3.1050202@stats.ox.ac.uk>
Message-ID: <1375976532.19899.YahooMailNeo@web124505.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130808/fc2cabb7/attachment.pl>

From bbolker at gmail.com  Thu Aug  8 17:59:40 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Aug 2013 11:59:40 -0400
Subject: [Rd] trivial typo in "writing r extensions"
Message-ID: <5203C06C.2020109@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


 "followed" on line 423 of R-exts.texi should probably be "followed
by" (or you could say "'followed' on line 423 should probably followed
by 'by'" :-) )

  cheers
    Ben Bolker

===================================================================
- --- R-exts.texi	(revision 63524)
+++ R-exts.texi	(working copy)
@@ -420,7 +420,7 @@

 @c DESCRIPTION field Maintainer
 The mandatory @samp{Maintainer} field should give a @emph{single} name
- -followed a @emph{valid} (RFC 2822) email address in angle brackets.  It
+followed by a @emph{valid} (RFC 2822) email address in angle
brackets.  It
 should not end in a period or comma.  This field is what is reported by
 the @code{maintainer} function and used by @code{bug.report}.  For a
 @acronym{CRAN} package it should be a @emph{person}, not a mailing list
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with undefined - http://www.enigmail.net/

iQEcBAEBAgAGBQJSA8BsAAoJEOCV5YRblxUH8z8H/2bPJvZOoQGkUC9WAFLljfGb
4CTnegcngCc8Jw/fcLo0X6I4D58sAC/QnXehBYZPdCOTyktcVAtW6m33fPZ6WpZr
3h1TM0KXHfMncQVLJWZWmrhv4FVk9SrBmF+4V/FmzGqxdAE3Fx/tYmifvadjdTAa
GiOWpYDYyQlB/vhh7rFyjIC+0tq11BflRzY+qKq3X46q5MehAI+EYk3A7Sd34HQw
Foz2fOy07UHFEUhogp6qMq9Nay2JE2WBACcJLr/KmODIWTfvW4g8opqwA52uNBAo
QrPtMovSrTv0jLdzi0s9eEoN5J1NV6xoy7dUsSumZD3oHfpwEeyKx71MkFonmfw=
=BgbJ
-----END PGP SIGNATURE-----


From hpages at fhcrc.org  Fri Aug  9 10:19:42 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 09 Aug 2013 01:19:42 -0700
Subject: [Rd] a fast table() for the 1D case
Message-ID: <5204A61E.9090209@fhcrc.org>

Hi,

table1D() below can be up to 60x faster than base::table() for the 1D
case. Here are the detailed speedups compared to base::table().

   o With a logical vector of length 5M:     11x faster
                                     (or more if 'useNA="always"')

   o With factor/integer/numeric/character of length 1M and 9 levels
     (or 9 distinct values for non-factors):
      - factor:                              60x faster
      - integer/numeric vector:              12x faster
      - character vector:                   2.4x faster

   o With factor/integer/numeric/character of length 1M and no
     duplicates:
       - factor:                              5x faster
       - integer vector:                      2x faster
       - numeric vector:                    1.7x faster
       - character vector:       no significant speedup

Would be great if this improvement could make it into base::table().

Thanks,
H.

   ## A fast table() implementation for the 1D case (replacing the '...'
   ## arg with 'x' and omitting the 'dnn' and 'deparse.level' arguments
   ## which are unrelated to performance).

   table1D <- function(x, exclude = if (useNA == "no") c(NA, NaN),
                       useNA = c("no", "ifany", "always"))
   {
     if (!missing(exclude) && is.null(exclude)) {
         useNA <- "always"
     } else {
         useNA <- match.arg(useNA)
     }
     if (useNA == "always" && !missing(exclude))
         exclude <- setdiff(exclude, NA)
     if (is.factor(x)) {
         x2 <- levels(x)
         append_NA <- (useNA == "always" ||
                       useNA == "ifany" && any(is.na(x))) &&
                      !any(is.na(x2))
         if (append_NA) {
             x2 <- c(x2, NA)
             x <- factor(x, levels=x2, exclude=NULL)
         }
         t2 <- tabulate(x, nbins=length(x2))
         if (!is.null(exclude)) {
             keep_idx <- which(!(x2 %in% exclude))
             x2 <- x2[keep_idx]
             t2 <- t2[keep_idx]
         }
     } else {
         xx <- match(x, x)
         t <- tabulate(xx, nbins=length(xx))
         keep_idx <- which(t != 0L)
         x2 <- x[keep_idx]
         t2 <- t[keep_idx]
         if (!is.null(exclude)) {
             exclude <- as.vector(exclude, typeof(x))
             keep_idx <- which(!(x2 %in% exclude))
             x2 <- x2[keep_idx]
             t2 <- t2[keep_idx]
         }
         oo <- order(x2)
         x2 <- x2[oo]
         t2 <- t2[oo]
         append_NA <- useNA == "always" && !any(is.na(x2))
         if (append_NA) {
             x2 <- c(x2, NA)
             t2 <- c(t2, 0L)
         }
     }
     ans <- array(t2)
     dimnames(ans) <- list(as.character(x2))
     names(dimnames(ans)) <- "x"  # always set to 'x'
     class(ans) <- "table"
     ans
   }

table1D() also fixes some issues with base::table() that can be exposed
by running the tests below.

   test_table <- function(FUN_NAME)
   {
     FUN <- match.fun(FUN_NAME)

     .make_target <- function(target_names, target_data)
     {
         ans <- array(target_data)
         dimnames(ans) <- list(as.character(target_names))
         names(dimnames(ans)) <- "x"
         class(ans) <- "table"
         ans
     }

     .check_identical <- function(target, current, varname, extra_args)
     {
         if (identical(target, current))
             return()
         if (extra_args != "")
             extra_args <- paste0(", ", extra_args)
         cat("unexpected result for '", FUN_NAME,
             "(x=", varname, extra_args, ")'\n", sep="")
     }

     .test_exclude <- function(x, varname, target_names0, target_data0, 
exclude)
     {
         extra_args <- paste0("exclude=", deparse(exclude))
         current <- FUN(x=x, exclude=exclude)
         target_names <- target_names0
         target_data <- target_data0
         if (is.null(exclude)) {
             if (!any(is.na(target_names))) {
                 target_names <- c(target_names, NA)
                 target_data <- c(target_data, 0L)
             }
         } else {
             if (!is.factor(x)) {
                 exclude <- as.vector(exclude, typeof(x))
             } else if (!any(is.na(levels(x)))) {
                 exclude <- union(exclude, NA)
             }
             exclude_idx <- match(exclude, target_names, nomatch=0L)
             if (any(exclude_idx != 0L)) {
                 target_names <- target_names[-exclude_idx]
                 target_data <- target_data[-exclude_idx]
             }
         }
         target <- .make_target(target_names, target_data)
         .check_identical(target, current, varname, extra_args)
     }

     .do_exclude_tests <- function(x, varname, target_names0, target_data0,
                                   more_excludes=NULL)
     {
         .BASIC_EXCLUDES <- list(c(NA, NaN), NULL, numeric(0), NA, NaN)
         excludes <- c(.BASIC_EXCLUDES, more_excludes)
         for (exclude in excludes)
             .test_exclude(x, varname, target_names0, target_data0, exclude)
     }

     ## Test on a numeric vector.
     x0 <- numeric(0)
     .do_exclude_tests(x0, "x0", character(0), integer(0), list(5.3))

     x1_target_names0 <- c(-9, 4, 5.3, NaN, NA)
     x1_target_data0 <- c(1L, 2L, 1L, 2L, 3L)
     x1 <- c(5.3, 4, NaN, 4, NA, NA, NaN, -9, NA)
     excludes <- list(c(5.3, -9),
                      c(5.3, NA, -9),
                      c(5.3, NaN, -9),
                      c(5.3, 80, -9),
                      x1_target_names0)
     .do_exclude_tests(x1, "x1", x1_target_names0, x1_target_data0, 
excludes)

     x2_target_names0 <- c(-9, 4, 5.3, NA, NaN)
     x2_target_data0 <- c(1L, 2L, 1L, 3L, 2L)
     x2 <- rev(x1)
     .do_exclude_tests(x2, "x2", x2_target_names0, x2_target_data0, 
excludes)

     x3_target_names0 <- c(-9, 4, 5.3)
     x3_target_data0 <- c(1L, 2L, 1L)
     x3 <- c(5.3, 4, 4, -9)
     .do_exclude_tests(x3, "x3", x3_target_names0, x3_target_data0, 
excludes)

     ## Test on a factor.
     f0 <- factor()
     .do_exclude_tests(f0, "f0", character(0), integer(0), list(5.3))

     f1 <- factor(x1)
     .do_exclude_tests(f1, "f1", x1_target_names0, x1_target_data0, 
excludes)

     f2 <- factor(x1, exclude=NULL)
     .do_exclude_tests(f2, "f2", x1_target_names0, x1_target_data0, 
excludes)

     f3_target_names0 <- c(6.82, x1_target_names0, -7.66)
     f3_target_data0 <- c(0L, 1L, 2L, 1L, 0L, 0L, 0L)
     f3 <- factor(x3, levels=f3_target_names0, exclude=NULL)
     .do_exclude_tests(f3, "f3", f3_target_names0, f3_target_data0, 
excludes)

     x4_target_names0 <- c(6.82, -9, 5.3, 4, -7.66)
     x4_target_data0 <- c(0L, 1L, 1L, 2L, 0L)
     f4 <- factor(x3, levels=x4_target_names0, exclude=NULL)
     .do_exclude_tests(f4, "f4", x4_target_names0, x4_target_data0, 
excludes)

     ## Test on a character vector.
     c0 <- character(0)
     .do_exclude_tests(c0, "c0", character(0), integer(0), list("Aa"))

     c1 <- c("b", "AA", "", "a", "ab", "NaN", "4", "Aa", NA, "NaN", 
"ab", NA)
     c1_target_names0 <- sort(unique(c1), na.last=TRUE)
     c1_target_data0 <- c(1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L)
     excludes <- list(c("Aa", 4, ""),
                      c("Aa", NA, 4, "", "Z"),
                      c("Aa", NaN, 4, "", "Z"),
                      c("Aa", 4, "", "Z"))
     .do_exclude_tests(c1, "c1", c1_target_names0, c1_target_data0, 
excludes)

     c2 <- c("b", "AA", "", "a", "ab", "", "", "4", "Aa", "ab")
     c2_target_names0 <- sort(unique(c2), na.last=TRUE)
     c2_target_data0 <- c(3L, 1L, 1L, 1L, 1L, 2L, 1L)
     .do_exclude_tests(c2, "c2", c2_target_names0, c2_target_data0, 
excludes)

     ## Test on a logical vector.
     l0 <- logical(0)
     .do_exclude_tests(l0, "l0", character(0), integer(0), list(c("Aa", 
TRUE)))

     l1 <- c(FALSE, FALSE, NA, TRUE, FALSE, FALSE, NA, NA, TRUE)
     l1_target_names0 <- c(FALSE, TRUE, NA)
     l1_target_data0 <- c(4L, 2L, 3L)
     excludes <- list(c(TRUE, FALSE),
                      c("Aa", NA, TRUE),
                      c("Aa", NaN, TRUE),
                      l1_target_names0)
     .do_exclude_tests(l1, "l1", l1_target_names0, l1_target_data0, 
excludes)

     l2 <- c(FALSE, FALSE, TRUE, FALSE, FALSE, TRUE)
     l2_target_names0 <- c(FALSE, TRUE)
     l2_target_data0 <- c(4L, 2L)
     .do_exclude_tests(l2, "l2", l2_target_names0, l2_target_data0, 
excludes)
   }

   test_table("table")    # will display some issues
   test_table("table1D")  # should not display anything


> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.1

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From baronshtam at lightminersystems.com  Fri Aug  9 23:48:07 2013
From: baronshtam at lightminersystems.com (Boris Aronshtam)
Date: Fri, 9 Aug 2013 21:48:07 +0000
Subject: [Rd] Creating data.frame from c-language
Message-ID: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130809/78ca4827/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Aug 10 15:17:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 10 Aug 2013 14:17:50 +0100
Subject: [Rd] Creating data.frame from c-language
In-Reply-To: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>
References: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>
Message-ID: <52063D7E.7000009@stats.ox.ac.uk>

On 09/08/2013 22:48, Boris Aronshtam wrote:
> I need to create a data.frame from C-language and populate it. I Know how to create lists from C, but I cannot figure out how to create a data.frame. Does anyone have a sample code for creating a data.frame, setting column names, and populating it with data?

Use data.frame() via an eval() call from C.

Or see the code is stats/src/model.c, as part of model.frame.default 
(but I would only do that if speed were essential).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From seanpor at acm.org  Sat Aug 10 15:48:43 2013
From: seanpor at acm.org (Sean O'Riordain)
Date: Sat, 10 Aug 2013 14:48:43 +0100
Subject: [Rd] broken link in docs for Binormial functions
Message-ID: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130810/43a9f80e/attachment.pl>

From edd at debian.org  Sat Aug 10 18:41:39 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 10 Aug 2013 11:41:39 -0500
Subject: [Rd] Creating data.frame from c-language
In-Reply-To: <52063D7E.7000009@stats.ox.ac.uk>
References: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>
	<52063D7E.7000009@stats.ox.ac.uk>
Message-ID: <20998.27971.266792.578650@max.nulle.part>


On 10 August 2013 at 14:17, Prof Brian Ripley wrote:
| On 09/08/2013 22:48, Boris Aronshtam wrote:
| > I need to create a data.frame from C-language and populate it. I Know how to create lists from C, but I cannot figure out how to create a data.frame. Does anyone have a sample code for creating a data.frame, setting column names, and populating it with data?
| 
| Use data.frame() via an eval() call from C.
|
| Or see the code is stats/src/model.c, as part of model.frame.default 
| (but I would only do that if speed were essential).

Or if C++ is an option for you, below if a six-line Rcpp source example:

R> sourceCpp("/tmp/dataframe.cpp")   ## see the file below
R> set.seed(42);  getDataFrame(5)    ## set RNG seed, request a dataframe
          a        b
1  1.370958 0.457742
2 -0.564698 0.719112
3  0.363128 0.934672
4  0.632863 0.255429
5  0.404268 0.462293
R> 
 
The source file used above follows below.

Dirk


#include <Rcpp.h>

using namespace Rcpp;

// [[Rcpp::export]]
DataFrame getDataFrame(int n) {
  NumericVector a = rnorm(n);
  NumericVector b = runif(n);
  return DataFrame::create(Named("a") = a,
			   Named("b") = b);
}
    



-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ripley at stats.ox.ac.uk  Sat Aug 10 20:11:03 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 10 Aug 2013 19:11:03 +0100
Subject: [Rd] broken link in docs for Binormial functions
In-Reply-To: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>
References: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>
Message-ID: <52068237.9060103@stats.ox.ac.uk>

On 10/08/2013 14:48, Sean O'Riordain wrote:
> On the local documentation page for Binomial, i.e.
> http://127.0.0.1:xxxx/library/stats/html/Binomial.html
>
> The link to Catherine Loader's paper
> "Catherine Loader (2000). *Fast and Accurate Computation of Binomial
> Probabilities*; available from
> http://www.herine.net/stat/software/dbinom.html."
>
> appears to be broken.

And what should it be replaced by?  (We've fixed this up at least once 
before.)

As Berners-Lee says, URIs should be permanent ....

>
> Kind regards,
> Se?n
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Sat Aug 10 20:34:04 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 10 Aug 2013 20:34:04 +0200
Subject: [Rd] broken link in docs for Binormial functions
In-Reply-To: <52068237.9060103@stats.ox.ac.uk>
References: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>
	<52068237.9060103@stats.ox.ac.uk>
Message-ID: <A418E98B-80C3-4544-913F-9740EEF2DE5A@gmail.com>


On Aug 10, 2013, at 20:11 , Prof Brian Ripley wrote:

> On 10/08/2013 14:48, Sean O'Riordain wrote:
>> On the local documentation page for Binomial, i.e.
>> http://127.0.0.1:xxxx/library/stats/html/Binomial.html
>> 
>> The link to Catherine Loader's paper
>> "Catherine Loader (2000). *Fast and Accurate Computation of Binomial
>> Probabilities*; available from
>> http://www.herine.net/stat/software/dbinom.html."
>> 
>> appears to be broken.
> 
> And what should it be replaced by?  (We've fixed this up at least once before.)
> 
> As Berners-Lee says, URIs should be permanent ....

It can be dug up via Google Scholar fairly easily, but the link goes to an attachment to an Octave enhancement request!

Perhaps we should ask permission to nail the thing down somewhere on r-project.org?

-pd

(Berners-Lee et al. never foresaw the chaos created by the commercialization of the web, or indeed of other academic infrastructures. Try locating Catherine herself or even the stats department at CWRU to see what I mean.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Sat Aug 10 20:43:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 10 Aug 2013 11:43:57 -0700
Subject: [Rd] broken link in docs for Binormial functions
In-Reply-To: <52068237.9060103@stats.ox.ac.uk>
References: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>
	<52068237.9060103@stats.ox.ac.uk>
Message-ID: <759F46A7-DC9B-4E80-992D-0766BBB19B89@comcast.net>


On Aug 10, 2013, at 11:11 AM, Prof Brian Ripley wrote:

> On 10/08/2013 14:48, Sean O'Riordain wrote:
>> On the local documentation page for Binomial, i.e.
>> http://127.0.0.1:xxxx/library/stats/html/Binomial.html
>> 
>> The link to Catherine Loader's paper
>> "Catherine Loader (2000). *Fast and Accurate Computation of Binomial
>> Probabilities*; available from
>> http://www.herine.net/stat/software/dbinom.html."
>> 
>> appears to be broken.
> 
> And what should it be replaced by?  (We've fixed this up at least once before.)

A copy can be had at:

http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CC0QFjAA&url=http%3A%2F%2Fprojects.scipy.org%2Fscipy%2Fraw-attachment%2Fticket%2F620%2Floader2000Fast.pdf&ei=Q4cGUpuGA8qWyAHN6ICgAQ&usg=AFQjCNG2mDFe3iE0Xahyl0d6f2cazTKgFQ&sig2=Ghc7H91rILXLrBLlJjQTJA

Ugggh. Does anyone else hate the Google encoding that was adopted a couple of years ago?

http://projects.scipy.org/scipy/raw-attachment/ticket/620/loader2000Fast.pdf?


> 
> As Berners-Lee says, URIs should be permanent ....
> 
>> 
>> Kind regards,
>> Se?n
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 

-- 
David Winsemius
Alameda, CA, USA


From groemping at beuth-hochschule.de  Mon Aug 12 10:26:54 2013
From: groemping at beuth-hochschule.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Mon, 12 Aug 2013 10:26:54 +0200
Subject: [Rd] Reason for difference in singular value decomposition produced
 by function La.svd (via prcomp)?
In-Reply-To: <5203A9FD.5070607@beuth-hochschule.de>
References: <5203A9FD.5070607@beuth-hochschule.de>
Message-ID: <52089C4E.2050600@beuth-hochschule.de>

Dear expeRts,

I previously posted this message to R-help and did not get a response, 
therefore I now try here, with a few additional system details added.

I have run some simulations under R 2.15.1 on a Mac (OS X, 10.6.8), and 
I have rerun a sample of them under R 3.0.1 on Windows 7 (and also for 
comparison under R2.14.1 on Windows XP). For most cases, I get exactly 
the same results in all three runs. However, for those cases that depend 
on principal components computed with prcomp, where the particular 
choice of the orthogonalization is arbitrary because of several 
identical singular values, I get different results between the two 
Windows versions on the one hand and the Mac version on the other hand. 
I did not find anything documented about the difference; maybe I didn't 
know where to look. Can someone help me understand the reason?

Best, Ulrike


From pdalgd at gmail.com  Mon Aug 12 14:57:10 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 12 Aug 2013 14:57:10 +0200
Subject: [Rd] Reason for difference in singular value decomposition
	produced by function La.svd (via prcomp)?
In-Reply-To: <52089C4E.2050600@beuth-hochschule.de>
References: <5203A9FD.5070607@beuth-hochschule.de>
	<52089C4E.2050600@beuth-hochschule.de>
Message-ID: <A0F6A54A-CA9F-4EE7-B2D5-496B878E43A9@gmail.com>


On Aug 12, 2013, at 10:26 , Ulrike Gr?mping wrote:

> Dear expeRts,
> 
> I previously posted this message to R-help and did not get a response, therefore I now try here, with a few additional system details added.
> 
> I have run some simulations under R 2.15.1 on a Mac (OS X, 10.6.8), and I have rerun a sample of them under R 3.0.1 on Windows 7 (and also for comparison under R2.14.1 on Windows XP). For most cases, I get exactly the same results in all three runs. However, for those cases that depend on principal components computed with prcomp, where the particular choice of the orthogonalization is arbitrary because of several identical singular values, I get different results between the two Windows versions on the one hand and the Mac version on the other hand. I did not find anything documented about the difference; maybe I didn't know where to look. Can someone help me understand the reason?

What did you expect? There is nothing in the SVD algorithm to select a solution which satisfies some auxiliary criterion that makes it unique.

When the orthogonalization is arbitrary, the particular solution that you get may depend on rounding error and other low-level details of the algorithm. A change of machine/os/compiler/etc. may give you a different result. 

> 
> Best, Ulrike
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From baronshtam at lightminersystems.com  Mon Aug 12 18:24:36 2013
From: baronshtam at lightminersystems.com (Boris Aronshtam)
Date: Mon, 12 Aug 2013 16:24:36 +0000
Subject: [Rd] Creating data.frame from c-language
In-Reply-To: <52063D7E.7000009@stats.ox.ac.uk>
References: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>
	<52063D7E.7000009@stats.ox.ac.uk>
Message-ID: <9D80368C6A00834189C1982FB64EFA3007ED8721@ORD2MBX07C.mex05.mlsrvr.com>

Dear Professor Brian D. Ripley,

Thank you for your reply. Yes, the speed is essential and data is large (gigabytes). I would like to learn from stats/src/model.c. Where can I find it?

Thanks,
Boris

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Saturday, August 10, 2013 6:18 AM
To: Boris Aronshtam
Cc: r-devel at r-project.org
Subject: Re: [Rd] Creating data.frame from c-language

On 09/08/2013 22:48, Boris Aronshtam wrote:
> I need to create a data.frame from C-language and populate it. I Know how to create lists from C, but I cannot figure out how to create a data.frame. Does anyone have a sample code for creating a data.frame, setting column names, and populating it with data?

Use data.frame() via an eval() call from C.

Or see the code is stats/src/model.c, as part of model.frame.default (but I would only do that if speed were essential).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Aug 12 18:25:47 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Aug 2013 17:25:47 +0100
Subject: [Rd] Creating data.frame from c-language
In-Reply-To: <9D80368C6A00834189C1982FB64EFA3007ED8721@ORD2MBX07C.mex05.mlsrvr.com>
References: <9D80368C6A00834189C1982FB64EFA3007ED8670@ORD2MBX07C.mex05.mlsrvr.com>
	<52063D7E.7000009@stats.ox.ac.uk>
	<9D80368C6A00834189C1982FB64EFA3007ED8721@ORD2MBX07C.mex05.mlsrvr.com>
Message-ID: <52090C8B.2030603@stats.ox.ac.uk>

On 12/08/2013 17:24, Boris Aronshtam wrote:
> Dear Professor Brian D. Ripley,
>
> Thank you for your reply. Yes, the speed is essential and data is large (gigabytes). I would like to learn from stats/src/model.c. Where can I find it?

In the R sources ....

> Thanks,
> Boris
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Saturday, August 10, 2013 6:18 AM
> To: Boris Aronshtam
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Creating data.frame from c-language
>
> On 09/08/2013 22:48, Boris Aronshtam wrote:
>> I need to create a data.frame from C-language and populate it. I Know how to create lists from C, but I cannot figure out how to create a data.frame. Does anyone have a sample code for creating a data.frame, setting column names, and populating it with data?
>
> Use data.frame() via an eval() call from C.
>
> Or see the code is stats/src/model.c, as part of model.frame.default (but I would only do that if speed were essential).
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From justintalbot at gmail.com  Mon Aug 12 19:06:43 2013
From: justintalbot at gmail.com (Justin Talbot)
Date: Mon, 12 Aug 2013 10:06:43 -0700
Subject: [Rd] Multiple return values / bug in rpart?
Message-ID: <CALLn38OLtHRRmZTmOWvnDrqna+WN9wNmhGjQA29FoVhxOA+ghA@mail.gmail.com>

In the recommended package rpart (version 4.1-1), the file rpartpl.R
contains the following line:

return(x = x[!erase], y = y[!erase])

AFAIK, returning multiple values like this is not valid R. Is that
correct? I can't seem to make it work in my own code.

It doesn't appear that rpartpl.R is used anywhere, so this may have
never caused an issue. But it's tripping up my R compiler.

Thanks,
Justin Talbot


From b.rowlingson at lancaster.ac.uk  Tue Aug 13 11:27:57 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 13 Aug 2013 10:27:57 +0100
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <cff453a96347419fa1d1333cbf2c6090@EX-0-HT0.lancs.local>
References: <cff453a96347419fa1d1333cbf2c6090@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMLpt4hj=oGpxE1KVov3ftUkg2F7nJNCXr31ogby-XChA@mail.gmail.com>

On Mon, Aug 12, 2013 at 6:06 PM, Justin Talbot <justintalbot at gmail.com> wrote:
> In the recommended package rpart (version 4.1-1), the file rpartpl.R
> contains the following line:
>
> return(x = x[!erase], y = y[!erase])
>
> AFAIK, returning multiple values like this is not valid R. Is that
> correct? I can't seem to make it work in my own code.

 Works for me, returning a list:

 > foo
function(x){return(x,x*2)}
 > foo(99)
[[1]]
[1] 99

[[2]]
[1] 198

But hey, that might just be because I redefined 'return' earlier:

 > return
function(...){list(...)}

It is unlikely this is the case in rpart though...


From simon.urbanek at r-project.org  Tue Aug 13 14:35:49 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 13 Aug 2013 08:35:49 -0400
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <CANVKczMLpt4hj=oGpxE1KVov3ftUkg2F7nJNCXr31ogby-XChA@mail.gmail.com>
References: <cff453a96347419fa1d1333cbf2c6090@EX-0-HT0.lancs.local>
	<CANVKczMLpt4hj=oGpxE1KVov3ftUkg2F7nJNCXr31ogby-XChA@mail.gmail.com>
Message-ID: <35F51954-9AB9-44F0-81FC-E473D398377A@r-project.org>


On Aug 13, 2013, at 5:27 AM, Barry Rowlingson wrote:

> On Mon, Aug 12, 2013 at 6:06 PM, Justin Talbot <justintalbot at gmail.com> wrote:
>> In the recommended package rpart (version 4.1-1), the file rpartpl.R
>> contains the following line:
>> 
>> return(x = x[!erase], y = y[!erase])
>> 
>> AFAIK, returning multiple values like this is not valid R. Is that
>> correct? I can't seem to make it work in my own code.
> 
> Works for me, returning a list:
> 
>> foo
> function(x){return(x,x*2)}
>> foo(99)
> [[1]]
> [1] 99
> 
> [[2]]
> [1] 198
> 
> But hey, that might just be because I redefined 'return' earlier:
> 
>> return
> function(...){list(...)}
> 

eek.. this is bad:

> (function() { if(TRUE) return("OK"); "BAD!" })()
[1] "BAD!"

Trying to modify the behavior of return() is rather tricky since you have to return from the function that's calling you ...


From spinuvit at gmail.com  Tue Aug 13 14:44:51 2013
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Tue, 13 Aug 2013 14:44:51 +0200
Subject: [Rd] Source location of currently evaluated code?
Message-ID: <87ppthzrng.fsf@gmail.com>


Hi, 

Is there a way to retrieve the parsed location of currently executed
function?

In other words, how to define a function "foo" such that when sourced
from a file "file_with_foo.R" containing foo() at line 1, it should
print:

    foo called in file_with_foo.R at line 1


Thanks, 

  Vitalie


From therneau at mayo.edu  Tue Aug 13 14:54:35 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 13 Aug 2013 07:54:35 -0500
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <mailman.15.1376388008.32611.r-devel@r-project.org>
References: <mailman.15.1376388008.32611.r-devel@r-project.org>
Message-ID: <520A2C8B.4080901@mayo.edu>

I don't remember what rpartpl once did myself; as you point out it is a routine that is no 
longer used and should be removed.  I've cc'd Brian since he maintains the rpart code.

Long ago return() with multiple arguments was a legal shorthand for returning a list.  
This feature was depricated in Splus, I think even before R rose to prominence.  I vaguely 
remember a time when it's usage generated a warning.

The fact that I've never noticed this unused routine is somewhat embarrassing.  Perhaps I 
need a "not documented, never called" addition to R CMD check to help me along.

Terry Therneau

> In the recommended package rpart (version 4.1-1), the file rpartpl.R
> contains the following line:
>
> return(x = x[!erase], y = y[!erase])
>
> AFAIK, returning multiple values like this is not valid R. Is that
> correct? I can't seem to make it work in my own code.
>
> It doesn't appear that rpartpl.R is used anywhere, so this may have
> never caused an issue. But it's tripping up my R compiler.
>
> Thanks,
> Justin Talbot


From ripley at stats.ox.ac.uk  Tue Aug 13 14:59:16 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Aug 2013 13:59:16 +0100
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <520A2C8B.4080901@mayo.edu>
References: <mailman.15.1376388008.32611.r-devel@r-project.org>
	<520A2C8B.4080901@mayo.edu>
Message-ID: <520A2DA4.9070600@stats.ox.ac.uk>

On 13/08/2013 13:54, Terry Therneau wrote:
> I don't remember what rpartpl once did myself; as you point out it is a
> routine that is no longer used and should be removed.  I've cc'd Brian
> since he maintains the rpart code.
>
> Long ago return() with multiple arguments was a legal shorthand for
> returning a list. This feature was depricated in Splus, I think even
> before R rose to prominence.  I vaguely remember a time when it's usage
> generated a warning.

Yes, usage generated a warning then an error, but not parsing.

 > foo <- function() return(a=1, b=2)
 > foo()
Error in return(a = 1, b = 2) : multi-argument returns are not permitted

> The fact that I've never noticed this unused routine is somewhat
> embarrassing.  Perhaps I need a "not documented, never called" addition
> to R CMD check to help me along.

But you cannot know 'never called'.  This is callable by 
rpart:::rpartpl() : it is also possible that functions in your namespace 
are called via eval()ing expressions at R or C level.  (There are 
examples around for which that is the only usage.)

>
> Terry Therneau
>
>> In the recommended package rpart (version 4.1-1), the file rpartpl.R
>> contains the following line:
>>
>> return(x = x[!erase], y = y[!erase])
>>
>> AFAIK, returning multiple values like this is not valid R. Is that
>> correct? I can't seem to make it work in my own code.
>>
>> It doesn't appear that rpartpl.R is used anywhere, so this may have
>> never caused an issue. But it's tripping up my R compiler.
>>
>> Thanks,
>> Justin Talbot


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Tue Aug 13 17:25:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 13 Aug 2013 11:25:13 -0400
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <520A2DA4.9070600@stats.ox.ac.uk>
References: <mailman.15.1376388008.32611.r-devel@r-project.org>
	<520A2C8B.4080901@mayo.edu> <520A2DA4.9070600@stats.ox.ac.uk>
Message-ID: <520A4FD9.2010701@gmail.com>

On 13-08-13 8:59 AM, Prof Brian Ripley wrote:
> On 13/08/2013 13:54, Terry Therneau wrote:
>> I don't remember what rpartpl once did myself; as you point out it is a
>> routine that is no longer used and should be removed.  I've cc'd Brian
>> since he maintains the rpart code.
>>
>> Long ago return() with multiple arguments was a legal shorthand for
>> returning a list. This feature was depricated in Splus, I think even
>> before R rose to prominence.  I vaguely remember a time when it's usage
>> generated a warning.
>
> Yes, usage generated a warning then an error, but not parsing.
>
>   > foo <- function() return(a=1, b=2)
>   > foo()
> Error in return(a = 1, b = 2) : multi-argument returns are not permitted
>
>> The fact that I've never noticed this unused routine is somewhat
>> embarrassing.  Perhaps I need a "not documented, never called" addition
>> to R CMD check to help me along.
>
> But you cannot know 'never called'.  This is callable by
> rpart:::rpartpl() : it is also possible that functions in your namespace
> are called via eval()ing expressions at R or C level.  (There are
> examples around for which that is the only usage.)

An approximation to "never called" is to run Rprof on your test code, 
and see which functions are not mentioned.  I have a package under 
construction with some students that can use this approach to identify 
which lines are never seen while profiling the test code.

Duncan Murdoch


From luke-tierney at uiowa.edu  Tue Aug 13 20:42:36 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 13 Aug 2013 13:42:36 -0500
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <520A4FD9.2010701@gmail.com>
References: <mailman.15.1376388008.32611.r-devel@r-project.org>
	<520A2C8B.4080901@mayo.edu> <520A2DA4.9070600@stats.ox.ac.uk>
	<520A4FD9.2010701@gmail.com>
Message-ID: <alpine.DEB.2.02.1308131341320.28684@luke-Latitude>

Both codetools and the compiler should be checking for use of multiple
args in return -- I'll look into adding that.

Best,

luke

On Tue, 13 Aug 2013, Duncan Murdoch wrote:

> On 13-08-13 8:59 AM, Prof Brian Ripley wrote:
>> On 13/08/2013 13:54, Terry Therneau wrote:
>>> I don't remember what rpartpl once did myself; as you point out it is a
>>> routine that is no longer used and should be removed.  I've cc'd Brian
>>> since he maintains the rpart code.
>>> 
>>> Long ago return() with multiple arguments was a legal shorthand for
>>> returning a list. This feature was depricated in Splus, I think even
>>> before R rose to prominence.  I vaguely remember a time when it's usage
>>> generated a warning.
>> 
>> Yes, usage generated a warning then an error, but not parsing.
>>
>>   > foo <- function() return(a=1, b=2)
>>   > foo()
>> Error in return(a = 1, b = 2) : multi-argument returns are not permitted
>> 
>>> The fact that I've never noticed this unused routine is somewhat
>>> embarrassing.  Perhaps I need a "not documented, never called" addition
>>> to R CMD check to help me along.
>> 
>> But you cannot know 'never called'.  This is callable by
>> rpart:::rpartpl() : it is also possible that functions in your namespace
>> are called via eval()ing expressions at R or C level.  (There are
>> examples around for which that is the only usage.)
>
> An approximation to "never called" is to run Rprof on your test code, and see 
> which functions are not mentioned.  I have a package under construction with 
> some students that can use this approach to identify which lines are never 
> seen while profiling the test code.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jmc at r-project.org  Tue Aug 13 22:34:56 2013
From: jmc at r-project.org (John Chambers)
Date: Tue, 13 Aug 2013 13:34:56 -0700
Subject: [Rd] Multiple return values / bug in rpart?
In-Reply-To: <alpine.DEB.2.02.1308131341320.28684@luke-Latitude>
References: <mailman.15.1376388008.32611.r-devel@r-project.org>
	<520A2C8B.4080901@mayo.edu> <520A2DA4.9070600@stats.ox.ac.uk>
	<520A4FD9.2010701@gmail.com>
	<alpine.DEB.2.02.1308131341320.28684@luke-Latitude>
Message-ID: <520A9870.8090907@r-project.org>

And just in case anyone is curious about the history, return() with 
multiple arguments was legal in S2 but the syntax in the blue book had 
only return(expr), whether enforced or not in the code.

   John


On 8/13/13 11:42 AM, luke-tierney at uiowa.edu wrote:
> Both codetools and the compiler should be checking for use of multiple
> args in return -- I'll look into adding that.
>
> Best,
>
> luke
>
> On Tue, 13 Aug 2013, Duncan Murdoch wrote:
>
>> On 13-08-13 8:59 AM, Prof Brian Ripley wrote:
>>> On 13/08/2013 13:54, Terry Therneau wrote:
>>>> I don't remember what rpartpl once did myself; as you point out it is a
>>>> routine that is no longer used and should be removed.  I've cc'd Brian
>>>> since he maintains the rpart code.
>>>>
>>>> Long ago return() with multiple arguments was a legal shorthand for
>>>> returning a list. This feature was depricated in Splus, I think even
>>>> before R rose to prominence.  I vaguely remember a time when it's usage
>>>> generated a warning.
>>>
>>> Yes, usage generated a warning then an error, but not parsing.
>>>
>>>   > foo <- function() return(a=1, b=2)
>>>   > foo()
>>> Error in return(a = 1, b = 2) : multi-argument returns are not permitted
>>>
>>>> The fact that I've never noticed this unused routine is somewhat
>>>> embarrassing.  Perhaps I need a "not documented, never called" addition
>>>> to R CMD check to help me along.
>>>
>>> But you cannot know 'never called'.  This is callable by
>>> rpart:::rpartpl() : it is also possible that functions in your namespace
>>> are called via eval()ing expressions at R or C level.  (There are
>>> examples around for which that is the only usage.)
>>
>> An approximation to "never called" is to run Rprof on your test code,
>> and see which functions are not mentioned.  I have a package under
>> construction with some students that can use this approach to identify
>> which lines are never seen while profiling the test code.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From ronglli at cn.ibm.com  Wed Aug 14 12:30:28 2013
From: ronglli at cn.ibm.com (Rong lI Li)
Date: Wed, 14 Aug 2013 18:30:28 +0800
Subject: [Rd] 2 questions about signal & broken connection in R
Message-ID: <OF26FEB442.E4CCE09D-ON48257BC7.003847CF-48257BC7.0039D50D@cn.ibm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130814/79bdd106/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Aug 14 18:38:57 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Aug 2013 17:38:57 +0100
Subject: [Rd] 2 questions about signal & broken connection in R
In-Reply-To: <OF26FEB442.E4CCE09D-ON48257BC7.003847CF-48257BC7.0039D50D@cn.ibm.com>
References: <OF26FEB442.E4CCE09D-ON48257BC7.003847CF-48257BC7.0039D50D@cn.ibm.com>
Message-ID: <520BB2A1.10308@stats.ox.ac.uk>

You seem to be assuming that Ctrl-C is the way to interrupt an R session 
and that it sends a signal.  Neither are true, in general, nor is there 
a general way to turn off interruptibility from the R console.

You have not followed the posting guide and it may be that you are only 
interested in some particular R setup -- which you did not tell us about.

If you want to run code so that it is not interruptible from a console, 
do not run it from a console ....

On 14/08/2013 11:30, Rong lI Li wrote:
>
>
> Hi, all,
>
> I have 2 questions about signal handling in R. Would you pls help give me
> some suggestions? Many thanks!
>
> [How to block the signal in one R function]:
> If one R function hopes to be running without interrupting, how can we
> avoid this?
> To be more specific, for one R function "func1", it will do a loop to send
> messages to another R process, and receive responses from peers. How can we
> avoid users interrupt this function by pressing "Ctrl+C", so that it can
> finish normally, without messing up the message protocol? Are there any way
> to block signal handling within the function?
>
> [why writing to one broken connection for the 3rd time will hang, instead
> of getting exceptions]:
> Such as, there is one broken socket connection (in blocking mode), which is
> closed by peer by calling "close(conn)".
> The 1st write will return. The 2nd write will get an exception. The 3rd
> write will hang there forever.
> How can users always get an exception or other error messages when writing
> to a broken connection, instead of possibly hanging there?
>
>> writeBin(as.integer(1), con, endian="big");
>> writeBin(as.integer(1), con, endian="big");
> Error in writeBin(as.integer(1), con, endian = "big") :
>    ignoring SIGPIPE signal
>> writeBin(as.integer(1), con, endian="big");  ----- hanging
>
>
> =====================
>
> Rong "Jessica", Li
> Platform Symphony TET, CSTL, IBM Systems &Technology Group, Development
> Tel:86-10-82451010  Email:ronglli at cn.ibm.com
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at uw.edu  Wed Aug 14 23:25:59 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 15 Aug 2013 09:25:59 +1200
Subject: [Rd] readChar and blocking connections
Message-ID: <CAJ55+d+c=WVKU37Q+rcAqoECz1tfo2CrSqFaM5MpCLoPUV1vwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130815/50d222c1/attachment.pl>

From gmbecker at ucdavis.edu  Thu Aug 15 01:46:31 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 14 Aug 2013 16:46:31 -0700
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
Message-ID: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>

R-team,

The $value element of the return value of *withVisible* does not agree with
the return value of *eval* when *withVisible* is passed a variable (symbol)
containing an expression object or anonymous code/expressions which
generates an expression object when evaluated (such as calls to *parse* or *
expression*).

I have attached a patch against the svn trunk which addresses this.

Example (under devel r63577):

> withVisible(parse(text="5+pi"))
$value
*expression(5+pi)*

$visible
[1] TRUE

> eval(parse(text="5+pi"))
*[1] 8.141593*



With the attached patch this is no longer the case:


> withVisible(parse(text="5+pi"))
$value
*[1] 8.141593*

$visible
[1] TRUE

The patch changes only the withVisible function in eval.c. I'm happy to
work with / at the direction of an R-core member to get the patch into an
different form/coding style/fix strategy/etc if its current form is not
acceptable.

Thanks,
~G

> sessionInfo()
R Under development (unstable) (2013-08-14 r63577)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

From mmuurr at gmail.com  Thu Aug 15 01:47:43 2013
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 14 Aug 2013 19:47:43 -0400
Subject: [Rd] local variable assignment: first copies from higher frame?
Message-ID: <CA+YV+HzN5NEPyytEKkSBoj-Ca-wd5Sw=NRM1=g2oukZki53G0g@mail.gmail.com>

hi all -- this might not be the correct list for this
question/discussion, though R-help didn't seem like the correct venue,
either, so...

i'm looking for just some extra clarification of how local variables
are defined/bound, beyond the simple cases given in the Language
document.

the particular instance is when there is variable assignment inside a function.
normally, this creates a local variable, but there appears to be an
additional preceding step that does a bit more: the local variable is
initialized to the value of any same-named variable bound in a
containing frame.
in a sense, the lexical scoping rule is first applied to acquire a
value, and this value is then applied to the new local variable, and
is then immediately changed by the assignment operation.

i only noticed this when assigning variables to entries within a
'list' structure, like so:

tempf <- function(x, local = TRUE)
  {
    executing_environment <- environment()
    closure_environment <- parent.env(executing_environment)

    print(executing_environment)
    cat(str(mget("my_list", envir = executing_environment, inherits =
FALSE, ifnotfound = NA)[[1]]))
    print(closure_environment)
    cat(str(mget("my_list", envir = closure_environment, inherits =
FALSE, ifnotfound = NA)[[1]]))

    if(local) {
      my_list$x <- x
    } else {
      my_list$x <<- x
    }

    print(executing_environment)
    cat(str(mget("my_list", envir = executing_environment, inherits =
FALSE, ifnotfound = NA)[[1]]))
    print(closure_environment)
    cat(str(mget("my_list", envir = closure_environment, inherits =
FALSE, ifnotfound = NA)[[1]]))
  }

> my_list <- list(x = 1, y = 2)
> tempf(0, local = TRUE)
<environment: 0xcb47cb8>
 logi NA
<environment: R_GlobalEnv>
List of 2
 $ x: num 1
 $ y: num 2
<environment: 0xcb47cb8>
List of 2
 $ x: num 0
 $ y: num 2
<environment: R_GlobalEnv>
List of 2
 $ x: num 1
 $ y: num 2
> tempf(0, local = FALSE)
<environment: 0xbf4df50>
 logi NA
<environment: R_GlobalEnv>
List of 2
 $ x: num 1
 $ y: num 2
<environment: 0xbf4df50>
 logi NA
<environment: R_GlobalEnv>
List of 2
 $ x: num 0
 $ y: num 2

what surprised me in the first "local = TRUE" case is that 'y' is
still 2 in the executing environment.
so, i think my question comes down to this: when a new local variable
is created in an assignment operation, is the full value of any
matching variable in a containing frame first copied to the new local
variable?
and if so, was this chosen as a strategy specifically to allow for
these sorts of "indexed" assignment operations? (where i'm assigning
to only a single location within the vector object)?
and finally, are the other entries in the vector fully copied over, or
are they treated as "promises" similar to formal parameters, albeit
now as single entries within a containing vector?

thanks for any help on digging down a bit on the implementation here!

-murat


From peter.meilstrup at gmail.com  Thu Aug 15 04:19:06 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Wed, 14 Aug 2013 19:19:06 -0700
Subject: [Rd] local variable assignment: first copies from higher frame?
In-Reply-To: <CA+YV+HzN5NEPyytEKkSBoj-Ca-wd5Sw=NRM1=g2oukZki53G0g@mail.gmail.com>
References: <CA+YV+HzN5NEPyytEKkSBoj-Ca-wd5Sw=NRM1=g2oukZki53G0g@mail.gmail.com>
Message-ID: <CAJoaRhYuKyqxpHdqki0hHuDhZbXA32Xidy9myuLs6y5-gviJ2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130814/09fba89a/attachment.pl>

From pdalgd at gmail.com  Thu Aug 15 08:04:43 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 15 Aug 2013 08:04:43 +0200
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
In-Reply-To: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
References: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
Message-ID: <780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>


On Aug 15, 2013, at 01:46 , Gabriel Becker wrote:

> R-team,
> 
> The $value element of the return value of *withVisible* does not agree with
> the return value of *eval* when *withVisible* is passed a variable (symbol)
> containing an expression object or anonymous code/expressions which
> generates an expression object when evaluated (such as calls to *parse* or *
> expression*).
> 
> I have attached a patch against the svn trunk which addresses this.
> 
> Example (under devel r63577):
> 
>> withVisible(parse(text="5+pi"))
> $value
> *expression(5+pi)*
> 
> $visible
> [1] TRUE
> 
>> eval(parse(text="5+pi"))
> *[1] 8.141593*
> 

I don't think that is a bug, it is by design. The comparison should be to what happens if you just type the expression at the prompt:

> parse(text="5+pi")
expression(5+pi)


> With the attached patch this is no longer the case:

...so the patch introduces a bug since you can no longer withVisible() something that returns a language object.

> 
>> withVisible(parse(text="5+pi"))
> $value
> *[1] 8.141593*
> 
> $visible
> [1] TRUE
> 
> The patch changes only the withVisible function in eval.c. I'm happy to
> work with / at the direction of an R-core member to get the patch into an
> different form/coding style/fix strategy/etc if its current form is not
> acceptable.
> 
> Thanks,
> ~G
> 
>> sessionInfo()
> R Under development (unstable) (2013-08-14 r63577)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.meilstrup at gmail.com  Thu Aug 15 08:14:37 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Wed, 14 Aug 2013 23:14:37 -0700
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
In-Reply-To: <780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>
References: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
	<780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>
Message-ID: <CAJoaRhaBLU4jXufDDFNfrtXB2pfrqqns9CgUQbfB=gvuW_iGxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130814/061698c3/attachment.pl>

From gmbecker at ucdavis.edu  Thu Aug 15 09:06:07 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 15 Aug 2013 00:06:07 -0700
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
In-Reply-To: <CAJoaRhaBLU4jXufDDFNfrtXB2pfrqqns9CgUQbfB=gvuW_iGxA@mail.gmail.com>
References: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
	<780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>
	<CAJoaRhaBLU4jXufDDFNfrtXB2pfrqqns9CgUQbfB=gvuW_iGxA@mail.gmail.com>
Message-ID: <CADwqtCO2drN5wN7MurSXs2j75+3gm0Q1y4yK6MaWkuHHtc3nzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130815/798b23c9/attachment.pl>

From simon.urbanek at r-project.org  Thu Aug 15 14:59:35 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Aug 2013 08:59:35 -0400
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
In-Reply-To: <CADwqtCO2drN5wN7MurSXs2j75+3gm0Q1y4yK6MaWkuHHtc3nzg@mail.gmail.com>
References: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
	<780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>
	<CAJoaRhaBLU4jXufDDFNfrtXB2pfrqqns9CgUQbfB=gvuW_iGxA@mail.gmail.com>
	<CADwqtCO2drN5wN7MurSXs2j75+3gm0Q1y4yK6MaWkuHHtc3nzg@mail.gmail.com>
Message-ID: <9D1C0CBD-245C-417E-B7D6-9623609C3E99@r-project.org>


On Aug 15, 2013, at 3:06 AM, Gabriel Becker wrote:

> On Wed, Aug 14, 2013 at 11:14 PM, Peter Meilstrup <peter.meilstrup at gmail.com
>> wrote:
> 
>> I agree that the present behavior of withVisible is the Right Thing, but
>> the documentation is confusing. The documentation claims that withVisible
>> "evaluates an expression."
>> 
>> This may capture an inside view of how the .Internal function is
>> implemented, but is nonsense from the R user's standpoint, where
>> "expression" is a particular type of R object and "evaluate an expression"
>> means to do something like eval().
>> 
> 
> And particularly, if you pass withVisible a variable containing an
> expression, said expression is not evaluated. The expression/symbol
> pointing to the object where it is stored is, I know, but the expression
> itself is not.
> 
> Furthermore, the exact same language ("evaluate an expression") appears in
> the eval documentation, and that function DOES evaluate the actual
> expression. Thus my (apparently incorrect) assumption that they should have
> the same behavior.
> 

I think the confusion comes from the misunderstanding of what gets evaluated when. The simplest way to explain is that withVisible() is equivalent to evalq(), but you're thinking of eval() which does two evaluations (the argument is evaluated and then the value of the argument is evaluated). Note that this is documented very explicitly:

"eval? evaluates its first argument in the current scope before passing it to the evaluator"

whereas withVisible only does the first part:

"The argument is evaluated in the caller's context."

Cheers,
Simon



> ~G
> 
> 
>> 
>> Peter
>> 
>> 
>> On Wed, Aug 14, 2013 at 11:04 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> 
>>> On Aug 15, 2013, at 01:46 , Gabriel Becker wrote:
>>> 
>>>> R-team,
>>>> 
>>>> The $value element of the return value of *withVisible* does not agree
>>> with
>>>> the return value of *eval* when *withVisible* is passed a variable
>>> (symbol)
>>>> containing an expression object or anonymous code/expressions which
>>>> generates an expression object when evaluated (such as calls to *parse*
>>> or *
>>>> expression*).
>>>> 
>>>> I have attached a patch against the svn trunk which addresses this.
>>>> 
>>>> Example (under devel r63577):
>>>> 
>>>>> withVisible(parse(text="5+pi"))
>>>> $value
>>>> *expression(5+pi)*
>>>> 
>>>> $visible
>>>> [1] TRUE
>>>> 
>>>>> eval(parse(text="5+pi"))
>>>> *[1] 8.141593*
>>>> 
>>> 
>>> I don't think that is a bug, it is by design. The comparison should be to
>>> what happens if you just type the expression at the prompt:
>>> 
>>>> parse(text="5+pi")
>>> expression(5+pi)
>>> 
>>> 
>>>> With the attached patch this is no longer the case:
>>> 
>>> ...so the patch introduces a bug since you can no longer withVisible()
>>> something that returns a language object.
>>> 
>>>> 
>>>>> withVisible(parse(text="5+pi"))
>>>> $value
>>>> *[1] 8.141593*
>>>> 
>>>> $visible
>>>> [1] TRUE
>>>> 
>>>> The patch changes only the withVisible function in eval.c. I'm happy to
>>>> work with / at the direction of an R-core member to get the patch into
>>> an
>>>> different form/coding style/fix strategy/etc if its current form is not
>>>> acceptable.
>>>> 
>>>> Thanks,
>>>> ~G
>>>> 
>>>>> sessionInfo()
>>>> R Under development (unstable) (2013-08-14 r63577)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>> 
>>>> locale:
>>>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Gabriel Becker
>>>> Graduate Student
>>>> Statistics Department
>>>> University of California, Davis
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From peter.meilstrup at gmail.com  Thu Aug 15 15:44:34 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 15 Aug 2013 06:44:34 -0700
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
In-Reply-To: <9D1C0CBD-245C-417E-B7D6-9623609C3E99@r-project.org>
References: <CADwqtCNGqOmfYeOd4bEob7+zu4D=xwiyoAkU9P1KhHnF7FYMJw@mail.gmail.com>
	<780A6D7E-AFA3-4C07-AF61-C2ED06580526@gmail.com>
	<CAJoaRhaBLU4jXufDDFNfrtXB2pfrqqns9CgUQbfB=gvuW_iGxA@mail.gmail.com>
	<CADwqtCO2drN5wN7MurSXs2j75+3gm0Q1y4yK6MaWkuHHtc3nzg@mail.gmail.com>
	<9D1C0CBD-245C-417E-B7D6-9623609C3E99@r-project.org>
Message-ID: <CAJoaRhYrv20jJF0EjMXu0D97wQ2zWmjPmsOURiczLMX=YcR6yA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130815/d3fbe747/attachment.pl>

From peter.meilstrup at gmail.com  Thu Aug 15 17:11:30 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 15 Aug 2013 08:11:30 -0700
Subject: [Rd] Inconsistency between eval and withVisible (with patch)
Message-ID: <CAJoaRhaJtjyEeds543yBPSQh2phLMDNqN=sn2xqS6XixpJ+FMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130815/09b31db2/attachment.pl>

From mmuurr at gmail.com  Thu Aug 15 17:33:07 2013
From: mmuurr at gmail.com (Murat Tasan)
Date: Thu, 15 Aug 2013 11:33:07 -0400
Subject: [Rd] local variable assignment: first copies from higher frame?
In-Reply-To: <CAJoaRhYuKyqxpHdqki0hHuDhZbXA32Xidy9myuLs6y5-gviJ2Q@mail.gmail.com>
References: <CA+YV+HzN5NEPyytEKkSBoj-Ca-wd5Sw=NRM1=g2oukZki53G0g@mail.gmail.com>
	<CAJoaRhYuKyqxpHdqki0hHuDhZbXA32Xidy9myuLs6y5-gviJ2Q@mail.gmail.com>
Message-ID: <CA+YV+HzpqUw7Ur94JxTtvnPWqLxVvCpO-wGwmEyY2dA4POb_FA@mail.gmail.com>

ah, that makes perfect sense in the functional programming sense of things.
thanks!

On Wed, Aug 14, 2013 at 10:19 PM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
> Not anything that complicated -- your answer is in the R language definition
> under 'Subset assignment' and the part in "Function calls" that describes
> assignment functions.
>
> Whenever a call is found on the left side of a `<-`, it is munged by
> sticking a "<-" on the function name and pulling out the first argument. So
>
> my_list$x <- x
>
> which is syntactically equivalent to
>
> `$`(my_list, x) <- x
>
> is effectively transformed into something like:
>
> my_list <- `$<-`(my_list, x, x)
>
> The function `$<-` gets its argument from wherever it is found, and returns
> a modified version.
>
> Peter


From voronaam at gmail.com  Fri Aug 16 00:07:05 2013
From: voronaam at gmail.com (Aleksey Vorona)
Date: Thu, 15 Aug 2013 15:07:05 -0700
Subject: [Rd] format bug and patch
Message-ID: <CAL_Jc-FGbMfh1BP6N5FT7qrm1F4h0WWe8YDzY8mgrAQGLXBEsw@mail.gmail.com>

Dear R-team,

I've been using R for a while and decided to contribute some bug
fixes. The first bug I tried to solve was
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15411

I have attached a patch with the fix to the bug and would love to hear
comments about its quality.

Also, while testing this bug I found another related issue:
> format(complex(real=10, imaginary=4), digits = 1);
[1] "10+0i"

I think this should've been "10+4i". I have entered this as a bug
#15427. But a patch for formatComplex() would be a bigger change, than
the patch for formatReal() I made. So, before I start, I would like to
gauge your opinion.

Do you agree it is a bug?


From murdoch.duncan at gmail.com  Fri Aug 16 19:46:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Aug 2013 13:46:30 -0400
Subject: [Rd] format bug and patch
In-Reply-To: <CAL_Jc-FGbMfh1BP6N5FT7qrm1F4h0WWe8YDzY8mgrAQGLXBEsw@mail.gmail.com>
References: <CAL_Jc-FGbMfh1BP6N5FT7qrm1F4h0WWe8YDzY8mgrAQGLXBEsw@mail.gmail.com>
Message-ID: <520E6576.9020607@gmail.com>

On 13-08-15 6:07 PM, Aleksey Vorona wrote:
> Dear R-team,
>
> I've been using R for a while and decided to contribute some bug
> fixes. The first bug I tried to solve was
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15411
>
> I have attached a patch with the fix to the bug and would love to hear
> comments about its quality.
>
> Also, while testing this bug I found another related issue:
>> format(complex(real=10, imaginary=4), digits = 1);
> [1] "10+0i"
>
> I think this should've been "10+4i". I have entered this as a bug
> #15427. But a patch for formatComplex() would be a bigger change, than
> the patch for formatReal() I made. So, before I start, I would like to
> gauge your opinion.
>
> Do you agree it is a bug?

No, it is a somewhat questionable design, but not a bug.  You asked for 
1 significant digit.  format() will give both the real and imaginary 
parts accurate to 1 significant digit.  Since the real part has two 
digits, it handles the imaginary part as 04, which is rendered as 0.

The questionable part of the design is that 11+4i would be rendered as 
11+0i, i.e. two digits accuracy are given in the real part even though 
you only asked for one.  I think it would be better to be consistent 
here.  I think it makes more sense to give 11+4i (or 10+4i in your 
example) than to give 10+0i for both, but I think that is a matter of 
taste, rather than a bug fix.

I have also prepared a patch for the 15411 bug; I'll compare mine to 
yours and commit something, but not for a week or so:  I am mostly 
offline until then.

Duncan Murdoch


From Robert.McGehee at geodecapital.com  Fri Aug 16 19:54:16 2013
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Fri, 16 Aug 2013 13:54:16 -0400
Subject: [Rd] as.Date.character speed improvement suggestion
Message-ID: <17B09E7789D3104E8F5EEB0582A8D66F0104D7514DD3@MSGRTPCCRF2WIN.DMN1.FMR.COM>

R-Devel,
I store and retrieve a large amount of financial data (millions of rows) in a PostgreSQL database keyed by date (and represented in R by class Date). Unfortunately, I frequently find that a great deal of processing time is spent converting dates from character representations to Date class representations in R, presumably because strptime is not fast for large vectors (>10,000 elements). I'd like to suggest a patch that speeds up the date conversion considerably for most every large date vectors (up to 400x in some real life cases).

I suspect most everyone with large vectors of class Date will find that most of their values are duplicated (repeatedly). (There are, after all, only 36,524 days in a century.) Given this, as.Date.character can be sped up substantially for large vectors by only calling strptime on unique dates and then filling in the calculated values for the entire vector. Since the time savings can be several minutes in real-life cases, I think this enhancement should certainly be considered. Also, in a worst case scenario of a long vector with only one duplicated value, the suggested change does not slow down the calculation.

Here's a proof of concept:
as.Date.character2 <- function(x, ...) {
    if (anyDuplicated(x)) {
        ux <- unique(x)
        idx <- match(x, ux)
        y <- as.Date.character(ux, ...)
        return(y[idx])
    }
    as.Date.character(x, ...)
}

## Example1: Construct a 1-million length character vector of 1000 unique dates
## By considering only unique values, speed is >250x faster

> dtch <- format(sample(Sys.Date()-1:1000, 1e6, replace=TRUE))
> system.time(dt1 <- as.Date.character(dtch))
   user  system elapsed 
 12.630  23.628  36.262
> system.time(dt2 <- as.Date.character2(dtch))
   user  system elapsed 
  0.117   0.019   0.136 
> identical(dt1, dt2)
[1] TRUE


## Example2: In a "worst case" scenario of a 1,000,002 length character of 1,000,001 unique dates
## the new function is not any slower (within error).
> dtch <- format(c(Sys.Date(), Sys.Date()+-5e5:5e5))
> system.time(dt1 <- as.Date.character(dtch))
   user  system elapsed 
 20.264  25.584  45.855
> system.time(dt2 <- as.Date.character2(dtch))
   user  system elapsed 
 20.525  24.809  45.335 
> identical(dt1, dt2)
[1] TRUE

Alternatively, this logic should be built in to strptime itself.

Robert


From simon.urbanek at r-project.org  Fri Aug 16 22:02:37 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Aug 2013 16:02:37 -0400
Subject: [Rd] as.Date.character speed improvement suggestion
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66F0104D7514DD3@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <17B09E7789D3104E8F5EEB0582A8D66F0104D7514DD3@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <28B6425F-3871-425F-A88C-03163971081E@r-project.org>


On Aug 16, 2013, at 1:54 PM, McGehee, Robert wrote:

> R-Devel,
> I store and retrieve a large amount of financial data (millions of rows) in a PostgreSQL database keyed by date (and represented in R by class Date). Unfortunately, I frequently find that a great deal of processing time is spent converting dates from character representations to Date class representations in R, presumably because strptime is not fast for large vectors (>10,000 elements). I'd like to suggest a patch that speeds up the date conversion considerably for most every large date vectors (up to 400x in some real life cases).
> 

This is more of a comment: if you want speed and have a standard date format, you can use fastPOSIXct from fasttime. The real bottleneck are system calls that do the conversion and fasttime is avoiding them by doing fast string parsing instead:

> system.time(dt1 <- as.Date.character(dtch))
   user  system elapsed 
 31.513   0.046  31.559 
> system.time(dt1 <- as.Date(fasttime::fastPOSIXct(dtch)))
   user  system elapsed 
  0.055   0.018   0.074 

Cutting back to unique dates may works for some applications (not for any of ours because we are always dealing with timestamps - but that's why we use POSIXct and not Date), but I'd argue that you may as well do it right away in your specialized application instead.

Cheers,
Simon



> I suspect most everyone with large vectors of class Date will find that most of their values are duplicated (repeatedly). (There are, after all, only 36,524 days in a century.) Given this, as.Date.character can be sped up substantially for large vectors by only calling strptime on unique dates and then filling in the calculated values for the entire vector. Since the time savings can be several minutes in real-life cases, I think this enhancement should certainly be considered. Also, in a worst case scenario of a long vector with only one duplicated value, the suggested change does not slow down the calculation.
> 
> Here's a proof of concept:
> as.Date.character2 <- function(x, ...) {
>    if (anyDuplicated(x)) {
>        ux <- unique(x)
>        idx <- match(x, ux)
>        y <- as.Date.character(ux, ...)
>        return(y[idx])
>    }
>    as.Date.character(x, ...)
> }
> 
> ## Example1: Construct a 1-million length character vector of 1000 unique dates
> ## By considering only unique values, speed is >250x faster
> 
>> dtch <- format(sample(Sys.Date()-1:1000, 1e6, replace=TRUE))
>> system.time(dt1 <- as.Date.character(dtch))
>   user  system elapsed 
> 12.630  23.628  36.262
>> system.time(dt2 <- as.Date.character2(dtch))
>   user  system elapsed 
>  0.117   0.019   0.136 
>> identical(dt1, dt2)
> [1] TRUE
> 
> 
> ## Example2: In a "worst case" scenario of a 1,000,002 length character of 1,000,001 unique dates
> ## the new function is not any slower (within error).
>> dtch <- format(c(Sys.Date(), Sys.Date()+-5e5:5e5))
>> system.time(dt1 <- as.Date.character(dtch))
>   user  system elapsed 
> 20.264  25.584  45.855
>> system.time(dt2 <- as.Date.character2(dtch))
>   user  system elapsed 
> 20.525  24.809  45.335 
>> identical(dt1, dt2)
> [1] TRUE
> 
> Alternatively, this logic should be built in to strptime itself.
> 
> Robert
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From voronaam at gmail.com  Fri Aug 16 21:47:01 2013
From: voronaam at gmail.com (Aleksey Vorona)
Date: Fri, 16 Aug 2013 12:47:01 -0700
Subject: [Rd] format bug and patch
In-Reply-To: <520E6576.9020607@gmail.com>
References: <CAL_Jc-FGbMfh1BP6N5FT7qrm1F4h0WWe8YDzY8mgrAQGLXBEsw@mail.gmail.com>
	<520E6576.9020607@gmail.com>
Message-ID: <CAL_Jc-EvwHTpuHZp2UnHuBzu-RA12pzd+9Bk5umNE5kFQHUqFA@mail.gmail.com>

On 8/16/13, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-08-15 6:07 PM, Aleksey Vorona wrote:
>> Dear R-team,
>>
>> I've been using R for a while and decided to contribute some bug
>> fixes. The first bug I tried to solve was
>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15411
>>
>> I have attached a patch with the fix to the bug and would love to hear
>> comments about its quality.
>>
>> Also, while testing this bug I found another related issue:
>>> format(complex(real=10, imaginary=4), digits = 1);
>> [1] "10+0i"
>>
>> I think this should've been "10+4i". I have entered this as a bug
>> #15427. But a patch for formatComplex() would be a bigger change, than
>> the patch for formatReal() I made. So, before I start, I would like to
>> gauge your opinion.
>>
>> Do you agree it is a bug?
>
> No, it is a somewhat questionable design, but not a bug.  You asked for
> 1 significant digit.  format() will give both the real and imaginary
> parts accurate to 1 significant digit.  Since the real part has two
> digits, it handles the imaginary part as 04, which is rendered as 0.
>
> The questionable part of the design is that 11+4i would be rendered as
> 11+0i, i.e. two digits accuracy are given in the real part even though
> you only asked for one.  I think it would be better to be consistent
> here.  I think it makes more sense to give 11+4i (or 10+4i in your
> example) than to give 10+0i for both, but I think that is a matter of
> taste, rather than a bug fix.
>
> I have also prepared a patch for the 15411 bug; I'll compare mine to
> yours and commit something, but not for a week or so:  I am mostly
> offline until then.
>
> Duncan Murdoch
>
>

Thank you for the reply. I sent this message to Duncan only.
Re-sending this again to the list. Sorry...

My interpretation of digits=1 was that I want both real and imaginary
parts to have 1 significant digits.

Consider this command, no digits parameter this time:

> format(complex(real=5.6e+8, imaginary=2.1e+16));
[1] "0e+00+2.1e+16i"

I do not see a reason not to output the number as it was entered.

If it is not a bug, it should be documented. I'll check if I can help with that.

-- Aleksey


From ripley at stats.ox.ac.uk  Sat Aug 17 07:32:35 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Aug 2013 06:32:35 +0100
Subject: [Rd] format bug and patch
In-Reply-To: <CAL_Jc-EvwHTpuHZp2UnHuBzu-RA12pzd+9Bk5umNE5kFQHUqFA@mail.gmail.com>
References: <CAL_Jc-FGbMfh1BP6N5FT7qrm1F4h0WWe8YDzY8mgrAQGLXBEsw@mail.gmail.com>
	<520E6576.9020607@gmail.com>
	<CAL_Jc-EvwHTpuHZp2UnHuBzu-RA12pzd+9Bk5umNE5kFQHUqFA@mail.gmail.com>
Message-ID: <520F0AF3.7080508@stats.ox.ac.uk>

On 16/08/2013 20:47, Aleksey Vorona wrote:
> On 8/16/13, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-08-15 6:07 PM, Aleksey Vorona wrote:
>>> Dear R-team,
>>>
>>> I've been using R for a while and decided to contribute some bug
>>> fixes. The first bug I tried to solve was
>>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15411
>>>
>>> I have attached a patch with the fix to the bug and would love to hear
>>> comments about its quality.
>>>
>>> Also, while testing this bug I found another related issue:
>>>> format(complex(real=10, imaginary=4), digits = 1);
>>> [1] "10+0i"
>>>
>>> I think this should've been "10+4i". I have entered this as a bug
>>> #15427. But a patch for formatComplex() would be a bigger change, than
>>> the patch for formatReal() I made. So, before I start, I would like to
>>> gauge your opinion.
>>>
>>> Do you agree it is a bug?
>>
>> No, it is a somewhat questionable design, but not a bug.  You asked for
>> 1 significant digit.  format() will give both the real and imaginary
>> parts accurate to 1 significant digit.  Since the real part has two
>> digits, it handles the imaginary part as 04, which is rendered as 0.
>>
>> The questionable part of the design is that 11+4i would be rendered as
>> 11+0i, i.e. two digits accuracy are given in the real part even though
>> you only asked for one.  I think it would be better to be consistent
>> here.  I think it makes more sense to give 11+4i (or 10+4i in your
>> example) than to give 10+0i for both, but I think that is a matter of
>> taste, rather than a bug fix.
>>
>> I have also prepared a patch for the 15411 bug; I'll compare mine to
>> yours and commit something, but not for a week or so:  I am mostly
>> offline until then.
>>
>> Duncan Murdoch
>>
>>
>
> Thank you for the reply. I sent this message to Duncan only.
> Re-sending this again to the list. Sorry...
>
> My interpretation of digits=1 was that I want both real and imaginary
> parts to have 1 significant digits.
>
> Consider this command, no digits parameter this time:
>
>> format(complex(real=5.6e+8, imaginary=2.1e+16));
> [1] "0e+00+2.1e+16i"
>
> I do not see a reason not to output the number as it was entered.
>
> If it is not a bug, it should be documented. I'll check if I can help with that.

It is documented.  You can help by reading the documentation for yourself!

   digits: how many significant digits are to be used for numeric and
           complex ?x?.  The default, ?NULL?, uses
           ?getOption("digits")?.  This is a suggestion: enough decimal
           places will be used so that the smallest (in magnitude)
           number has this many significant digits, and also to satisfy
           ?nsmall?.  (For the interpretation for complex numbers see
           ?signif?.)
            ^^^^^^

      For ?signif? the recognized values of ?digits? are ?1...22?, and
      non-missing values are rounded to the nearest integer in that
      range.  Complex numbers are rounded to retain the specified number
      of digits in the larger of the components.



>
> -- Aleksey
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bbolker at gmail.com  Sat Aug 17 18:19:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Aug 2013 12:19:58 -0400
Subject: [Rd] model.frame(), model.matrix(), and derived predictor variables
Message-ID: <520FA2AE.7030109@gmail.com>


  Dear r-developers:

  I am struggling with some fundamental aspects of model.frame().

  Conceptually, I think of a flow from data -> model.frame() ->
model.matrix; the data contain _input variables_, while model.matrix
contains _predictor variables_: data have been transformed, splines and
polynomials have been expanded into their corresponding
multi-dimensional bases, and factors have been expanded into appropriate
sets of dummy variables depending on their contrasts.
  I originally thought of model.frame() as containing input variables as
well (but with only the variables needed by the model, and with cases
containing NAs handled according to the relevant na.action setting), but
that's not quite true.  While factors are retained as-is, splines and
polynomials and parameter transformations are evaluated. For example

d <- data.frame(x=1:10,y=1:10)
model.frame(y~log(x),d)

produces a model frame with columns 'y', 'log(x)' (not 'y', 'x').

This makes it hard (impossible?) to use the model frame to re-evaluate
the existing formula in a model, e.g.

m <- lm(y~log(x),d)
update(m,data=model.frame(m))
## Error in eval(expr, envir, enclos) : object 'x' not found

It seems to me that this is a reasonable thing to want to do
(i.e. use the model frame as a stored copy of the data that
 can be used for additional model operations); otherwise, I
either need to carry along an additional copy of the data in
a slot, or hope that the model is still living in an environment
where it can find a copy of the original data.

Does anyone have any insights into the original design choices,
or suggestions about how they have handled this within their own
code? Do you just add an additional data slot to the model?  I've
considered trying to write some kind of 'augmented' model frame, that
would contain the equivalent of
setdiff(all.vars(formula),model.frame(m)) [i.e.  all input variables
that appeared in the formula but not in the model frame ...].

  thanks
   Ben Bolker


From peter.meilstrup at gmail.com  Sun Aug 18 15:12:50 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Sun, 18 Aug 2013 06:12:50 -0700
Subject: [Rd] How does R_UnboundValue and removing variables work?
Message-ID: <CAJoaRhbyWdd_bGXzFxxFyLr_qFofNsU4b+=QwV9QbRT1GCnniQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130818/0b01857a/attachment.pl>

From gmbecker at ucdavis.edu  Mon Aug 19 02:04:27 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 18 Aug 2013 17:04:27 -0700
Subject: [Rd] Correct procedure when working on bugs tracked in bugzilla?
Message-ID: <CADwqtCP0FrNCHRbkb2Vx8Fz0nPHhA36GUG3RKLSfiSJiTwHd2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130818/fa93626c/attachment.pl>

From simon.urbanek at r-project.org  Mon Aug 19 06:38:56 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 19 Aug 2013 00:38:56 -0400
Subject: [Rd] How does R_UnboundValue and removing variables work?
In-Reply-To: <CAJoaRhbyWdd_bGXzFxxFyLr_qFofNsU4b+=QwV9QbRT1GCnniQ@mail.gmail.com>
References: <CAJoaRhbyWdd_bGXzFxxFyLr_qFofNsU4b+=QwV9QbRT1GCnniQ@mail.gmail.com>
Message-ID: <B864DA3A-7A7E-4F2A-95B0-1861EF70569F@r-project.org>

Peter,

On Aug 18, 2013, at 9:12 AM, Peter Meilstrup wrote:

> Reading "R Internals" made me believe that R_UnboundValue was a placeholder
> that would be skipped over in variable lookup. viz. the section of R
> Internals "Hash tables" says "items are not actually deleted but have their
> value set to R_UnboundValue.", which seems to align with what I read in
> envir.c.
> 

Not quite. The CAR of the LISTSXP corresponding to the symbol entry is set to R_UnboundValue in case it is cached, but the entry is actually removed from the chain (see RemoveFromList).


> So, I reasoned, if I have a function that returns R_UnboundValue,
> like so:
> 
> unbound_value <- function() .Call("unbound_value")
> 
> SEXP unbound_value() {
>  return R_UnboundValue;
> }
> 
> then calling
> 
> x <- unbound_value()
> 
> ought to make "x" unbound. [spare me from saying this is a bad idea--I'm
> just trying to understand what's going on.]
> 
> But it seems to only work partially --  If a name "x" is bound to
> R_UnboundValue, exists("x") returns TRUE, though sometimes name lookup
> proceeds as you'd expect:
> 
>> x <- 5; local({x <- 6; rm("x"); exists("x", inherits=FALSE)})
> [1] FALSE
>> x <-5;  local({x <- 6; x <- unbound_value(); exists("x", inherits=FALSE)})
> [1] TRUE
>> x <-5;  local({x <- 6; x <- vadr:::unbound_value(); x})
> [1] 5
> 
> but assigning unbound on the global namespace blocks name lookup from going
> up the search path:
> 
>> find("HairEyeColor")
> [1] "package:datasets"
>> HairEyeColor <- unbound_value()
>> class(HairEyeColor)
> Error: object 'HairEyeColor' not found
>> rm("HairEyeColor")
>> class(HairEyeColor)
> [1] "table"
> 
> I've been looking through the source in envir.c but I haven't found what
> would make rm("x") have a different effect from x <- unbound_value(). Any
> hints?
> 

See above - rm() actually removes the entry whereas you are setting it to R_UnboundValue which is really bad (R_UnboundValue should really never leave the internals). Note that exists() is a special case - it only looks if the entry exists in the list, not what its value is, therefore it will find you entry with R_UnboundValue and say, ok, it exists.

You can easily see that when you look at the contents of the environment:

> e=new.env(FALSE)
> e$x=1L
> .Internal(inspect(e))
@100c6ab18 04 ENVSXP g0c0 [NAM(1)] <0x100c6ab18>
FRAME:
  @100b6f2b0 02 LISTSXP g0c0 [] 
    TAG: @1008a4b10 01 SYMSXP g1c0 [MARK,NAM(2)] "x"
    @100b6ab38 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
ENCLOS:
  @1008745f8 04 ENVSXP g1c0 [MARK,NAM(2),GL,gp=0x8000] <R_GlobalEnv>
> e$x=unbound_value()
> .Internal(inspect(e))
@100c6ab18 04 ENVSXP g0c0 [MARK,NAM(1)] <0x100c6ab18>
FRAME:
  @100b6f2b0 02 LISTSXP g0c0 [MARK] 
    TAG: @1008a4b10 01 SYMSXP g1c0 [MARK,NAM(2)] "x"
    @100843140 01 SYMSXP g1c0 [MARK,NAM(2)] "x1?"
ENCLOS:
  @1008745f8 04 ENVSXP g1c0 [MARK,NAM(2),GL,gp=0x8000] <R_GlobalEnv>
> exists("x",,e)
[1] TRUE
> rm(x,envir=e)
> exists("x",,e)
[1] FALSE
> .Internal(inspect(e))
@100c6ab18 04 ENVSXP g0c0 [MARK,NAM(2)] <0x100c6ab18>
ENCLOS:
  @1008745f8 04 ENVSXP g1c0 [MARK,NAM(2),GL,gp=0x8000] <R_GlobalEnv>

You can repeat the same trick with hashed envs - the only difference is that there are then multiple lists and only one is involved.

Cheers,
S


From arraintxikiak at gmail.com  Mon Aug 19 12:34:30 2013
From: arraintxikiak at gmail.com (Arrain Txikiak)
Date: Mon, 19 Aug 2013 12:34:30 +0200
Subject: [Rd] Issues in installing R-devel
Message-ID: <CADKrCQGp6neJ2wmpJakfCdk-rCuGRzfF6amxxH8JStEW_z05Nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130819/1808b56e/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Aug 19 15:08:33 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Aug 2013 14:08:33 +0100
Subject: [Rd] Issues in installing R-devel
In-Reply-To: <CADKrCQGp6neJ2wmpJakfCdk-rCuGRzfF6amxxH8JStEW_z05Nw@mail.gmail.com>
References: <CADKrCQGp6neJ2wmpJakfCdk-rCuGRzfF6amxxH8JStEW_z05Nw@mail.gmail.com>
Message-ID: <521218D1.1050502@stats.ox.ac.uk>

Please try again: this has already been reported and fixed.

BTW, you did not follow the posting guide and report your platform. 
This issue was only for 32-bit builds.

On 19/08/2013 11:34, Arrain Txikiak wrote:
> Dear list,
>
> I have tried to compile and install the development version of R, but
> met some problems I'm not quite sure how to resolve.
>
> I have downloaded the code from your repository, configured, and tried
> to compile using the makefile, as follows:
>
> [atxi at aquario R]$ svn co http://svn.r-project.org/R/trunk
> [atxi at aquario R]$ cd trunk
> [atxi at aquario R]$ ./tools/rsync-recommended
> [atxi at aquario R]$ ./configure --enable-R-shlib
> [atxi at aquario R]$ make
>
> I'm getting the following error:
>
> gcc -std=gnu99 -Wl,--export-dynamic -fopenmp  -L/usr/local/lib -o R.bin
> Rmain.o  -L../../lib -lR -lRblas
> ../../lib/libR.so: undefined reference to `SHORT_VEC_LENGTH'
> collect2: ld returned 1 exit status
>
> This does not seem to be a missing dependency, as the complaint is about
> something included in the R code.  I had previously successfully
> installed R-devel using the exact same commands on the same machine.
>
> What am I doing wrong?
>
> In advance thank you for support.
>
> -- Txikiak
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Mon Aug 19 17:25:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Aug 2013 11:25:35 -0400
Subject: [Rd] Correct procedure when working on bugs tracked in bugzilla?
In-Reply-To: <CADwqtCP0FrNCHRbkb2Vx8Fz0nPHhA36GUG3RKLSfiSJiTwHd2Q@mail.gmail.com>
References: <CADwqtCP0FrNCHRbkb2Vx8Fz0nPHhA36GUG3RKLSfiSJiTwHd2Q@mail.gmail.com>
Message-ID: <521238EF.3050201@gmail.com>

On 13-08-18 8:04 PM, Gabriel Becker wrote:
> Hi R-core,
>
> I have been working on squashing a few bugs in the past couple of days
> (specifically I have submitted patches for
> 15425<https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15425>and
> 15253 <https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15253>) , but I
> haven't been assigning the bugs to myself in bugzilla as I was not sure if
> that is something only R-core members should be doing.
>
> Is there a correct/desired way that I as a non-R-core member should
> indicate that I'm working on a fix for a particular bug or am interested
> in/willing to do so?

As far as I am aware there is no official policy on this, so I'll give 
an opinion:

Assigning it to yourself would probably be bad: I wouldn't even look at 
it any more.  I don't know policies of other Core members.

The best approach is to add a note on the bug saying you're working on 
it (which will push it to the top of the list in the default ordering), 
along with a note saying when you expect to be done.  That would stop me 
from spending time on it until you submitted a patch, or your stated 
deadline was long past.

Duncan Murdoch


From SheltonS at stemcell.ucsf.edu  Mon Aug 19 20:53:38 2013
From: SheltonS at stemcell.ucsf.edu (Shelton, Samuel)
Date: Mon, 19 Aug 2013 18:53:38 +0000
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <<C74505CF-FE4E-45D4-99D0-41EA2A9F4BF1@gmail.com>>
Message-ID: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130819/bb3aa434/attachment.pl>

From pdalgd at gmail.com  Tue Aug 20 18:23:51 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 20 Aug 2013 18:23:51 +0200
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>
References: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>
Message-ID: <3C4E3712-EA69-441D-859B-B3C85BE628E2@gmail.com>


On Aug 19, 2013, at 20:53 , Shelton, Samuel wrote:

> Dear R developer,
> 
> I am an R user and am currently having a problem with versions of R >3.0.0. We build larger correlation matrices of >30000 with pairwise correlations made. We have been using a line of code
> 
> simMat=bicor(datExpr1,use="p")

What is bicor()? From the WGCNA package? Perhaps the package is doing something incompatible with the long vector support in R 3.0.0. You need to report such queries to the maintainer. So far we have no evidence that the bug is in R itself, and you're not giving us anything reproducible to investigate.

> 
> To build the similarity matrix with datExpr1 being a matrix with genes as columns (>30000) and rows being samples. This code works fine on an iMac running OSX 10.8.5 and using R 2.15.2 and the Rblas library. When I try to run the same code with R version 3.0.0 and 3.0.1 it only partially builds the matrix. It will return correlations for samples 1:11262 but from 11262:30000 the matrix is full of 0's.
> 
> We would like to be able to use R 3.0.0 to allow us to build larger correlation matrices on our cluster but we can't use it at the moment due to this problem. My colleague has previously had a similar issue when using snow leopard and this was to do with a compatibility issue between snow leopard and the veclib. Has something changed in version 3.0.0 to give an incompatibility with the veclib?
> 

This seems entirely speculative. Please stick to the facts.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.langfelder at gmail.com  Tue Aug 20 18:43:48 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 20 Aug 2013 09:43:48 -0700
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>
References: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>
Message-ID: <CA+hbrhUsbQOA-qa3x27VfmbKTt19JCuDuzUMR8icxbxbB7OZ3Q@mail.gmail.com>

Hi Sam,

I assume you mean that correlation for _genes_ (not samples)
11262:30000 is 0? I am the maintainer of the WGCNA package but
unfortunately I don't have access to a Mac big enough to try
30000x30000 correlation matrix, but I would be thankful if you could
try reproducing the problem with smaller matrices (e.g. 20000x20000)
and try to produce a small reproducible example by
generating the data using say rnorm, say like this:

nGenes = 20000 # as small as possible that still produces the error
nSamples = 100
datExpr1 = matrix(rnorm(nSamples * nGenes), nSamples, nGenes)

simMat = bicor(datExpr1, use = 'p')

Best,

Peter

On Mon, Aug 19, 2013 at 11:53 AM, Shelton, Samuel
<SheltonS at stemcell.ucsf.edu> wrote:
> Dear R developer,
>
> I am an R user and am currently having a problem with versions of R >3.0.0. We build larger correlation matrices of >30000 with pairwise correlations made. We have been using a line of code
>
> simMat=bicor(datExpr1,use="p")
>
> To build the similarity matrix with datExpr1 being a matrix with genes as columns (>30000) and rows being samples. This code works fine on an iMac running OSX 10.8.5 and using R 2.15.2 and the Rblas library. When I try to run the same code with R version 3.0.0 and 3.0.1 it only partially builds the matrix. It will return correlations for samples 1:11262 but from 11262:30000 the matrix is full of 0's.
>
> We would like to be able to use R 3.0.0 to allow us to build larger correlation matrices on our cluster but we can't use it at the moment due to this problem. My colleague has previously had a similar issue when using snow leopard and this was to do with a compatibility issue between snow leopard and the veclib. Has something changed in version 3.0.0 to give an incompatibility with the veclib?
>
> Many thanks
>
> Sam
>
> Samuel Shelton, Ph.D.
> Postdoctoral Researcher,
> The Oldham Lab,
> The institute of Regeneration Medicine,
> University of California San Francisco,
> San Francisco, CA 94143
>
> email: sheltons at stemcell.ucsf.edu
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From peter.langfelder at gmail.com  Tue Aug 20 19:31:36 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 20 Aug 2013 10:31:36 -0700
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <3C4E3712-EA69-441D-859B-B3C85BE628E2@gmail.com>
References: <CE37B7C1.17CFF%sheltons@stemcell.ucsf.edu>
	<3C4E3712-EA69-441D-859B-B3C85BE628E2@gmail.com>
Message-ID: <CA+hbrhUx47OyHnQ4V=JW6+KroyhwoCnziEvLwGQW54aYC8JH7Q@mail.gmail.com>

On Tue, Aug 20, 2013 at 9:23 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> What is bicor()? From the WGCNA package? Perhaps the package is doing something incompatible with the long vector support in R 3.0.0. You need to report such queries to the maintainer.

The maintainer is reporting for duty :)

The version of WGCNA currently on CRAN uses .C to call compiled code.
If I read the manuals right, long vectors are not allowed in .C calls.
In my .C calls I use explicit type casts (as.integer, as.double etc)
for all arguments.

Once we see a reproducible example, we can figure out the problem.

Peter


From peter.langfelder at gmail.com  Tue Aug 20 19:53:02 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 20 Aug 2013 10:53:02 -0700
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
References: <CA+hbrhUsbQOA-qa3x27VfmbKTt19JCuDuzUMR8icxbxbB7OZ3Q@mail.gmail.com>
	<CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
Message-ID: <CA+hbrhVzUye1C3ZLpTWnPB21gaZYhiWeffHsf+sDCe0oeV0=RA@mail.gmail.com>

Hi Samuel,

WGCNA currently does not support calculations with matrices larger
than the old R limit, and it will take some time to update it to
support the large matrices. Furthermore, WGCNA relies on other
functions (most notably hclust) that would have to be updated as well
to support long vectors.

In the meantime I suggest using the "blockwise" functions to handle
large data sets, or, if possible, reducing the number of genes to less
than the old limit of 46340 or so.

Sorry I can't be of more help.

Best,

Peter

On Tue, Aug 20, 2013 at 10:42 AM, Shelton, Samuel
<SheltonS at stemcell.ucsf.edu> wrote:
> Hi all,
>
> Thanks for getting back to me. We would like to move over to v3.0.0 on our
> cluster so that we can build matrices larger than 46300*46300 (limit in R
> <3.0.0)
> but so far we can't get things to work with R v3.0.0 and higher. I am
> trying to trouble shoot at the moment and I am now thinking that the
> problem is actually with the diag function that has been rewritten in
> version 3.0.0.
>
>
> The problem is definitely with the diag function and it does not occur on
> smaller matrices (20000*20000) and I think it maybe a bug.
> This illustrates the problem:
>
> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
> I do see the same for 3.0.0). This does not occur when I run it with R
> 2.15.2.
>
>
> mat1=matrix(rexp(20000^2), 20000)
>
> mat1[1:10,1:10]
>            [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
>  [,7]       [,8]       [,9]      [,10]
>  [1,] 0.1829090 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
> 0.469843567 2.57767543 0.17449595 0.01949358
>  [2,] 0.5731522 0.15835939 0.29165029 0.6781249 0.64553728 2.4438404
> 2.140374938 0.40091195 0.51201369 0.98904490
>  [3,] 0.3250310 0.09934147 0.79962549 0.4933385 0.30473422 0.4556765
> 0.002640034 0.90606861 2.58772944 0.89884208
>  [4,] 1.4195017 0.16082660 0.01377838 0.2115803 1.43992672 0.3883675
> 0.040903805 0.51011305 0.41998024 0.44209926
>  [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.17333324 0.3388678
> 3.206179119 0.52170966 1.03084845 0.05843232
>  [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 1.0237664
> 2.547528816 1.35629450 0.87983354 0.25236343
>  [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
> 1.137348735 0.08371053 0.23144290 0.18915132
>  [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
> 0.144371435 3.03299285 0.09728111 0.39890260
>  [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
> 2.437192399 0.34689557 0.02039205 0.54898488
> [10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
> 0.571159401 0.63375850 0.63221987 1.32840290
>> mat1[19990:20000,19990:20000]
>            [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
>   [,7]      [,8]       [,9]     [,10]     [,11]
>  [1,] 1.7910910 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
> 0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
>  [2,] 0.2862914 1.5267870 0.98214645 0.0004617244 0.6395319 0.075217874
> 0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
>  [3,] 2.0492301 0.7216115 0.16951284 0.2726676762 2.1893806 1.202518385
> 0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
>  [4,] 0.6538994 0.2437594 2.08848881 0.3917212249 0.4441824 0.433749415
> 1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
>  [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.8914097 0.497023176
> 0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
>  [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 1.296227000
> 0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
>  [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
> 1.5474078 2.5899490 5.19298969 1.4680934 1.0537164
>  [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
> 1.8699504 1.9187339 5.13248671 0.4621520 0.4753582
>  [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
> 0.7391137 0.1574844 0.65985494 0.4066742 0.8072494
> [10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
> 0.4642319 0.1582297 1.71676326 0.3662139 0.7864957
> [11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
> 0.8430396 0.5132811 0.30547431 1.6088725 0.4001791
>
> diag(mat1)=0
>
> mat1[1:10,1:10]
>            [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
>  [,7]       [,8]       [,9]      [,10]
>  [1,] 0.0000000 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
> 0.469843567 2.57767543 0.17449595 0.01949358
>  [2,] 0.5731522 0.00000000 0.29165029 0.6781249 0.64553728 2.4438404
> 2.140374938 0.40091195 0.51201369 0.98904490
>  [3,] 0.3250310 0.09934147 0.00000000 0.4933385 0.30473422 0.4556765
> 0.002640034 0.90606861 2.58772944 0.89884208
>  [4,] 1.4195017 0.16082660 0.01377838 0.0000000 1.43992672 0.3883675
> 0.040903805 0.51011305 0.41998024 0.44209926
>  [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.00000000 0.3388678
> 3.206179119 0.52170966 1.03084845 0.05843232
>  [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 0.0000000
> 2.547528816 1.35629450 0.87983354 0.25236343
>  [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
> 0.000000000 0.08371053 0.23144290 0.18915132
>  [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
> 0.144371435 0.00000000 0.09728111 0.39890260
>  [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
> 2.437192399 0.34689557 0.00000000 0.54898488
> [10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
> 0.571159401 0.63375850 0.63221987 0.00000000
>
> mat1[19990:20000,19990:20000]
>            [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
>   [,7]      [,8]       [,9]     [,10]     [,11]
>  [1,] 0.0000000 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
> 0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
>  [2,] 0.2862914 0.0000000 0.98214645 0.0004617244 0.6395319 0.075217874
> 0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
>  [3,] 2.0492301 0.7216115 0.00000000 0.2726676762 2.1893806 1.202518385
> 0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
>  [4,] 0.6538994 0.2437594 2.08848881 0.0000000000 0.4441824 0.433749415
> 1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
>  [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.0000000 0.497023176
> 0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
>  [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 0.000000000
> 0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
>  [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
> 0.0000000 2.5899490 5.19298969 1.4680934 1.0537164
>  [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
> 1.8699504 0.0000000 5.13248671 0.4621520 0.4753582
>  [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
> 0.7391137 0.1574844 0.00000000 0.4066742 0.8072494
> [10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
> 0.4642319 0.1582297 1.71676326 0.0000000 0.7864957
> [11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
> 0.8430396 0.5132811 0.30547431 1.6088725 0.0000000
>
> mat1=matrix(rexp(38000^2), 38000)
> dim(mat1)
> [1] 38000 38000
> mat1[1:10,1:10]
>            [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
> [,7]      [,8]       [,9]      [,10]
>  [1,] 3.8622815 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
> 0.45672475 0.2891504 1.57087882 1.27375802
>  [2,] 3.8229940 0.1540735 0.30189392 1.2100152 0.003323061 0.7195875
> 0.60251052 1.9820380 0.18637086 0.05154236
>  [3,] 2.0411498 0.8371707 0.02714550 1.3032572 0.330472063 0.3502267
> 0.11908140 0.4155857 3.46471729 0.31890778
>  [4,] 1.5503390 0.7377494 2.01433675 0.6109255 1.844484309 1.2492693
> 0.09365743 0.4006219 2.37769616 0.38643521
>  [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.526454982 0.1207842
> 0.93567987 1.7369767 4.47922786 0.20033928
>  [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.1362716
> 1.72807083 0.2570055 0.02127689 0.80225716
>  [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
> 0.01432572 0.6064162 0.69264596 0.50871566
>  [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
> 1.12583466 0.3391067 0.18707165 3.71877247
>  [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
> 0.18612994 1.0498866 1.89162156 1.56643880
> [10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
> 0.25436398 1.1275389 0.20960212 0.63957112
>
>
>
>
> mat1[37990:38000,37990:38000]
>            [,1]       [,2]       [,3]       [,4]      [,5]       [,6]
> [,7]       [,8]       [,9]     [,10]     [,11]
>  [1,] 0.8349326 1.32098263 2.68879316 0.52361090 1.4066094 0.00754308
> 2.4489865 1.76284621 0.09097126 2.1598758 0.8805701
>  [2,] 2.5754994 1.15753606 1.76895066 3.06645700 0.8767225 0.33247639
> 1.5726808 0.12698495 0.75271682 6.4336476 0.1330457
>  [3,] 2.5737957 0.58234929 0.40403205 0.34882433 0.4074048 1.54867135
> 2.5971068 0.27276140 0.56926494 0.2129180 1.3027215
>  [4,] 0.9352113 0.46839288 0.41284388 1.40216119 0.8936151 2.98304058
> 0.4350446 1.14864094 0.26756970 2.6662998 0.1802141
>  [5,] 1.6430435 1.22137017 0.06943644 0.03251737 0.2142083 0.16964865
> 1.6099314 0.95709429 0.22884734 0.5087986 0.9048555
>  [6,] 2.5340159 1.28618183 3.86698388 1.05946189 3.5006776 0.39320471
> 0.4927357 0.66159842 0.18235678 0.5172896 2.2221550
>  [7,] 0.1961937 0.17305031 0.62327325 3.14622730 3.4905449 3.08823676
> 0.5282165 0.48879156 0.11807913 0.7372706 0.9975103
>  [8,] 0.8392414 0.17107463 1.08732839 0.28981611 0.4722655 0.17587788
> 1.7426814 0.13985161 1.86885446 1.9031580 1.1088431
>  [9,] 3.4648342 0.33834943 0.07891645 0.07206860 1.1792628 0.54092203
> 0.8141844 2.82687085 0.78395229 0.5313417 3.2164664
> [10,] 0.1524299 0.02045616 0.67881610 1.51491647 2.4390115 0.89033581
> 0.9026651 0.46858464 1.47711638 2.1821178 2.2149071
> [11,] 0.9397162 0.42376104 0.20034405 1.47672836 1.0461904 0.97296202
> 2.1658717 0.04487329 0.30611082 1.1680312 0.9952517
>
> diag(mat1)=0
>
> mat1[1:10,1:10]
>            [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
> [,7]      [,8]       [,9]      [,10]
>  [1,] 0.0000000 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
> 0.45672475 0.2891504 1.57087882 1.27375802
>  [2,] 3.8229940 0.0000000 0.30189392 1.2100152 0.003323061 0.7195875
> 0.60251052 1.9820380 0.18637086 0.05154236
>  [3,] 2.0411498 0.8371707 0.00000000 1.3032572 0.330472063 0.3502267
> 0.11908140 0.4155857 3.46471729 0.31890778
>  [4,] 1.5503390 0.7377494 2.01433675 0.0000000 1.844484309 1.2492693
> 0.09365743 0.4006219 2.37769616 0.38643521
>  [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.000000000 0.1207842
> 0.93567987 1.7369767 4.47922786 0.20033928
>  [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.0000000
> 1.72807083 0.2570055 0.02127689 0.80225716
>  [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
> 0.00000000 0.6064162 0.69264596 0.50871566
>  [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
> 1.12583466 0.0000000 0.18707165 3.71877247
>  [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
> 0.18612994 1.0498866 0.00000000 1.56643880
> [10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
> 0.25436398 1.1275389 0.20960212 0.00000000
>
>
> ## After calling the diag function the bottom of the matrix is all set to
> 0.
>
>
> mat1[37990:38000,37990:38000]
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
>  [1,]    0    0    0    0    0    0    0    0    0     0     0
>  [2,]    0    0    0    0    0    0    0    0    0     0     0
>  [3,]    0    0    0    0    0    0    0    0    0     0     0
>  [4,]    0    0    0    0    0    0    0    0    0     0     0
>  [5,]    0    0    0    0    0    0    0    0    0     0     0
>  [6,]    0    0    0    0    0    0    0    0    0     0     0
>  [7,]    0    0    0    0    0    0    0    0    0     0     0
>  [8,]    0    0    0    0    0    0    0    0    0     0     0
>  [9,]    0    0    0    0    0    0    0    0    0     0     0
> [10,]    0    0    0    0    0    0    0    0    0     0     0
> [11,]    0    0    0    0    0    0    0    0    0     0     0
>
> It looks like there is an issue with larger matrices when calling diag
> function and it has nothing to do with WGCNA.
>
>
>
>
>
>
> On 8/20/13 9:43 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:
>
>>Hi Sam,
>>
>>I assume you mean that correlation for _genes_ (not samples)
>>11262:30000 is 0? I am the maintainer of the WGCNA package but
>>unfortunately I don't have access to a Mac big enough to try
>>30000x30000 correlation matrix, but I would be thankful if you could
>>try reproducing the problem with smaller matrices (e.g. 20000x20000)
>>and try to produce a small reproducible example by
>>generating the data using say rnorm, say like this:
>>
>>nGenes = 20000 # as small as possible that still produces the error
>>nSamples = 100
>>datExpr1 = matrix(rnorm(nSamples * nGenes), nSamples, nGenes)
>>
>>simMat = bicor(datExpr1, use = 'p')
>>
>>Best,
>>
>>Peter
>>
>>On Mon, Aug 19, 2013 at 11:53 AM, Shelton, Samuel
>><SheltonS at stemcell.ucsf.edu> wrote:
>>> Dear R developer,
>>>
>>> I am an R user and am currently having a problem with versions of R
>>>>3.0.0. We build larger correlation matrices of >30000 with pairwise
>>>>correlations made. We have been using a line of code
>>>
>>> simMat=bicor(datExpr1,use="p")
>>>
>>> To build the similarity matrix with datExpr1 being a matrix with genes
>>>as columns (>30000) and rows being samples. This code works fine on an
>>>iMac running OSX 10.8.5 and using R 2.15.2 and the Rblas library. When I
>>>try to run the same code with R version 3.0.0 and 3.0.1 it only
>>>partially builds the matrix. It will return correlations for samples
>>>1:11262 but from 11262:30000 the matrix is full of 0's.
>>>
>>> We would like to be able to use R 3.0.0 to allow us to build larger
>>>correlation matrices on our cluster but we can't use it at the moment
>>>due to this problem. My colleague has previously had a similar issue
>>>when using snow leopard and this was to do with a compatibility issue
>>>between snow leopard and the veclib. Has something changed in version
>>>3.0.0 to give an incompatibility with the veclib?
>>>
>>> Many thanks
>>>
>>> Sam
>>>
>>> Samuel Shelton, Ph.D.
>>> Postdoctoral Researcher,
>>> The Oldham Lab,
>>> The institute of Regeneration Medicine,
>>> University of California San Francisco,
>>> San Francisco, CA 94143
>>>
>>> email: sheltons at stemcell.ucsf.edu
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ivo.welch at anderson.ucla.edu  Tue Aug 20 20:41:56 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Tue, 20 Aug 2013 11:41:56 -0700
Subject: [Rd] Extending suggestion for stopifnot
Message-ID: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>

I am using a variant of stopifnot a lot.  can I suggest that base R
extends its functionality?  I know how to do this for myself.  this is
a suggestion for beginners and students.  I don't think it would break
anything.

first, I think it would be more useful if it had an optional character
string, so users could write

  stopifnot( is.matrix(m), "m is not a matrix" )

this would mean that stopifnot would have to detect whether the last
argument is a string.  (I think stopifnot should have had only one
condition, and one should have used all() to test multiple conditions,
but this is a bridge that was already crossed.)  upon failure,
stopifnot should print the character string.  that's it.


A second enhancement would be a "smart string", which knows that
everything inside {{...}} should be evaluated.

  stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )


my own programming variant looks even nicer,

   is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"

but requesting base R to add the %and% and %or% (or, better yet, 'and'
and 'or') operators by default would be pushing my luck.

/iaw


----
Ivo Welch (ivo.welch at gmail.com)


From deepayan.sarkar at gmail.com  Tue Aug 20 21:30:38 2013
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 21 Aug 2013 01:00:38 +0530
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <CADfFDC6PcZ-5rmjgJbvzo+XuZ8kD_5gX=-L59dy8ESkKn6DTiQ@mail.gmail.com>

On Wed, Aug 21, 2013 at 12:11 AM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:

> I am using a variant of stopifnot a lot.  can I suggest that base R
> extends its functionality?  I know how to do this for myself.  this is
> a suggestion for beginners and students.  I don't think it would break
> anything.
>
> first, I think it would be more useful if it had an optional character
> string, so users could write
>
>   stopifnot( is.matrix(m), "m is not a matrix" )

How is this better/nicer/more preferable than, say,

if (!is.matrix(m)) stop("m is not a matrix")

?

I think stopifnot() is mostly meant for regression tests and sanity
checks, and should not be used instead of stop() if you want nicely
formatted error messages.

-Deepayan


> this would mean that stopifnot would have to detect whether the last
> argument is a string.  (I think stopifnot should have had only one
> condition, and one should have used all() to test multiple conditions,
> but this is a bridge that was already crossed.)  upon failure,
> stopifnot should print the character string.  that's it.
>
>
> A second enhancement would be a "smart string", which knows that
> everything inside {{...}} should be evaluated.
>
>   stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )
>
>
> my own programming variant looks even nicer,
>
>    is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"
>
> but requesting base R to add the %and% and %or% (or, better yet, 'and'
> and 'or') operators by default would be pushing my luck.
>
> /iaw
>
>
> ----
> Ivo Welch (ivo.welch at gmail.com)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From arraintxikiak at gmail.com  Tue Aug 20 22:05:11 2013
From: arraintxikiak at gmail.com (Arrain Txikiak)
Date: Tue, 20 Aug 2013 22:05:11 +0200
Subject: [Rd] R-devel Digest, Vol 126, Issue 18
In-Reply-To: <mailman.19.1376992808.1493.r-devel@r-project.org>
References: <mailman.19.1376992808.1493.r-devel@r-project.org>
Message-ID: <5213CBF7.2010602@gmail.com>

Thank you, it does work now indeed.  My platform is 32 bit.

-- Txikiak

On 08/20/2013 12:00 PM, r-devel-request at r-project.org wrote:
> Date: Mon, 19 Aug 2013 14:08:33 +0100
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: r-devel at r-project.org
> Subject: Re: [Rd] Issues in installing R-devel
> Message-ID: <521218D1.1050502 at stats.ox.ac.uk>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Please try again: this has already been reported and fixed.
>
> BTW, you did not follow the posting guide and report your platform.
> This issue was only for 32-bit builds.
>
> On 19/08/2013 11:34, Arrain Txikiak wrote:
>> Dear list,
>>
>> I have tried to compile and install the development version of R, but
>> met some problems I'm not quite sure how to resolve.
>>
>> I have downloaded the code from your repository, configured, and tried
>> to compile using the makefile, as follows:
>>
>> [atxi at aquario R]$ svn co http://svn.r-project.org/R/trunk
>> [atxi at aquario R]$ cd trunk
>> [atxi at aquario R]$ ./tools/rsync-recommended
>> [atxi at aquario R]$ ./configure --enable-R-shlib
>> [atxi at aquario R]$ make
>>
>> I'm getting the following error:
>>
>> gcc -std=gnu99 -Wl,--export-dynamic -fopenmp  -L/usr/local/lib -o R.bin
>> Rmain.o  -L../../lib -lR -lRblas
>> ../../lib/libR.so: undefined reference to `SHORT_VEC_LENGTH'
>> collect2: ld returned 1 exit status
>>
>> This does not seem to be a missing dependency, as the complaint is about
>> something included in the R code.  I had previously successfully
>> installed R-devel using the exact same commands on the same machine.
>>
>> What am I doing wrong?
>>
>> In advance thank you for support.
>>
>> -- Txikiak
>>


From michael.weylandt at gmail.com  Tue Aug 20 22:06:14 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Tue, 20 Aug 2013 16:06:14 -0400
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <1E984682-1DA5-4793-9301-11EF1E999B84@gmail.com>



On Aug 20, 2013, at 14:41, ivo welch <ivo.welch at anderson.ucla.edu> wrote:

> A second enhancement would be a "smart string", which knows that
> everything inside {{...}} should be evaluated. 

I think one the HTML templating libraries (whisker or mustache or some such) provides something not unlike this. Perhaps take a look. 

> 
>  stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )
> 
> 
> my own programming variant looks even nicer,
> 
>   is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"
> 
> but requesting base R to add the %and% and %or% (or, better yet, 'and'
> and 'or') operators by default would be pushing my luck.

Does %or% throw an error or is this wrapped in something else?

The former seems rather perl-ish, but the latter might suggest you look into the || and && operators if you only know their single counterparts. 

Michael

> 
> /iaw
> 
> 
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From peter.langfelder at gmail.com  Tue Aug 20 22:36:24 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 20 Aug 2013 13:36:24 -0700
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>

On Tue, Aug 20, 2013 at 11:41 AM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
> I am using a variant of stopifnot a lot.  can I suggest that base R
> extends its functionality?  I know how to do this for myself.  this is
> a suggestion for beginners and students.  I don't think it would break
> anything.
>
> first, I think it would be more useful if it had an optional character
> string, so users could write
>
>   stopifnot( is.matrix(m), "m is not a matrix" )
>
> this would mean that stopifnot would have to detect whether the last
> argument is a string.  (I think stopifnot should have had only one
> condition, and one should have used all() to test multiple conditions,
> but this is a bridge that was already crossed.)  upon failure,
> stopifnot should print the character string.  that's it.
>
>
> A second enhancement would be a "smart string", which knows that
> everything inside {{...}} should be evaluated.
>
>   stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )

I think using a function (in this case paste) is cleaner:

paste("m is not a matrix, but a", class(m))

It avoids adding a new convention ("evaluate everything between {{
}}") and has additional arguments.

>
>
> my own programming variant looks even nicer,
>
>    is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"

In R you can write it as

is.matrix(m) || stop("m is not a matrix but a ", class(m))

Examples:

m = 1
> is.matrix(m) || stop("m is not a matrix but a ", class(m))
Error: m is not a matrix but a numeric

> m = matrix(0,2,2)
> is.matrix(m) || stop("m is not a matrix but a ", class(m))
[1] TRUE

But the construct

if (!is.matrix(m)) stop("m is not a matrix but a ", class(m))

is more readable for people not used to Pearl.


From wdunlap at tibco.com  Tue Aug 20 23:00:49 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 20 Aug 2013 21:00:49 +0000
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3303EB@PA-MBX01.na.tibco.com>

> my own programming variant looks even nicer,
>    is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"

But it does not act nicely.  All %anything% constructs have the
same precedence, that of %*%.   Hence
   x==3 %or% "x is not three"
is parsed as
  x == ( 3 %or% "x is not three" )
which is not what I think you want.

Use standard functional notation, e.g., ensureThat(condition, message), and
you don't get into parsing trouble.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of ivo welch
> Sent: Tuesday, August 20, 2013 11:42 AM
> To: r-devel at r-project.org List
> Subject: [Rd] Extending suggestion for stopifnot
> 
> I am using a variant of stopifnot a lot.  can I suggest that base R
> extends its functionality?  I know how to do this for myself.  this is
> a suggestion for beginners and students.  I don't think it would break
> anything.
> 
> first, I think it would be more useful if it had an optional character
> string, so users could write
> 
>   stopifnot( is.matrix(m), "m is not a matrix" )
> 
> this would mean that stopifnot would have to detect whether the last
> argument is a string.  (I think stopifnot should have had only one
> condition, and one should have used all() to test multiple conditions,
> but this is a bridge that was already crossed.)  upon failure,
> stopifnot should print the character string.  that's it.
> 
> 
> A second enhancement would be a "smart string", which knows that
> everything inside {{...}} should be evaluated.
> 
>   stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )
> 
> 
> my own programming variant looks even nicer,
> 
>    is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"
> 
> but requesting base R to add the %and% and %or% (or, better yet, 'and'
> and 'or') operators by default would be pushing my luck.
> 
> /iaw
> 
> 
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rowe at muxspace.com  Tue Aug 20 23:14:26 2013
From: rowe at muxspace.com (Brian Rowe)
Date: Tue, 20 Aug 2013 17:14:26 -0400
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
Message-ID: <13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>

If all you care about is emulating static type checking, then you can also accomplish the same thing with lambda.r using type constraints on function definitions.

e.g.
> f(m) %::% matrix : matrix
> f(m) %as% { m }

> f(as.data.frame(matrix(rnorm(12),nrow=3)))
Error in UseFunction("f", ...) : No valid function for 'f(data.frame)'

> f(1)
Error in UseFunction("f", ...) : No valid function for 'f(1)'

> f
<function>
[[1]]
f(m) %::% matrix:matrix
f(m) %as% ?



On Aug 20, 2013, at 4:36 PM, Peter Langfelder <peter.langfelder at gmail.com> wrote:

> On Tue, Aug 20, 2013 at 11:41 AM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
>> I am using a variant of stopifnot a lot.  can I suggest that base R
>> extends its functionality?  I know how to do this for myself.  this is
>> a suggestion for beginners and students.  I don't think it would break
>> anything.
>> 
>> first, I think it would be more useful if it had an optional character
>> string, so users could write
>> 
>>  stopifnot( is.matrix(m), "m is not a matrix" )
>> 
>> this would mean that stopifnot would have to detect whether the last
>> argument is a string.  (I think stopifnot should have had only one
>> condition, and one should have used all() to test multiple conditions,
>> but this is a bridge that was already crossed.)  upon failure,
>> stopifnot should print the character string.  that's it.
>> 
>> 
>> A second enhancement would be a "smart string", which knows that
>> everything inside {{...}} should be evaluated.
>> 
>>  stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )
> 
> I think using a function (in this case paste) is cleaner:
> 
> paste("m is not a matrix, but a", class(m))
> 
> It avoids adding a new convention ("evaluate everything between {{
> }}") and has additional arguments.
> 
>> 
>> 
>> my own programming variant looks even nicer,
>> 
>>   is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"
> 
> In R you can write it as
> 
> is.matrix(m) || stop("m is not a matrix but a ", class(m))
> 
> Examples:
> 
> m = 1
>> is.matrix(m) || stop("m is not a matrix but a ", class(m))
> Error: m is not a matrix but a numeric
> 
>> m = matrix(0,2,2)
>> is.matrix(m) || stop("m is not a matrix but a ", class(m))
> [1] TRUE
> 
> But the construct
> 
> if (!is.matrix(m)) stop("m is not a matrix but a ", class(m))
> 
> is more readable for people not used to Pearl.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ivo.welch at gmail.com  Wed Aug 21 00:00:18 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Tue, 20 Aug 2013 15:00:18 -0700
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
	<13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>
Message-ID: <CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>

thx, deepayan:  how is stopifnot better than
    if (!all(...)) stop()
given that we have stopifnot() and I have seen it used often, I think
my two suggestions would make it better.

thx, michael:  the %and% and %or% constructs are indeed relics of my
perl background.  my own definition is

`%and%` <- function(e1, e2) {  if (e1) { if (is.character(e2))
abort.estring(e2) else eval(e2) } }

it's syntactic sugar.  my abort.estring() function prints the
character as n estring() [extended string, see below] and exits.  it
can probably be written a lot better.  remember, I am not an expert.

thx, peter: the estring has the advantage of having it all in one
string, which allows me to say, e.g.,
   (x) %or% "x is not true but {{x}}"
the comma here does not work.  it basically becomes an interpolated
string, just like the construct "x is $x" in perl.

thx, bill: ensureThat() is not a base R function.  uggh---I think you
are right on precedence.  I always use parens around my conditions.
old C habit from decades ago, so I never ran into this problem.  if()
is good enough.  my main suggestion was adding an optional message at
the end of stopifnot(), and possibly extended (interpolated) strings.

thx, brian:  I think of lambda.r as being more "heavyweight" and
requiring a modestly steeper learning curve.  if it was standard in
base R, I would definitely switch to it.  I think we want a system
that my students are taught to use from day 1.


in sum, I agree that one accomplish the functionality in base R.  my
initial suggestion was very simple and small: (1) adding an optional
character string at the end of an existing function, stopifnot().  (2)
I think "estrings" (that behave like characters but are interpolated
before printout) are useful in the same way perl interpolated strings
are useful.  this would be a bigger change.  some people would like
it.  others don't see the advantage.  I think the benefits would
outweigh the costs.  (3) I just mentioned %and% and %or% as an
"aside".  it this is definitely a bigger change, where we can all
agree to disagree whether we like this in code or not.  just ignore
#3.

best,

/iaw


estring <- function(e2, N.UP =2) {

  rx <- "(?<=\\{\\{).*?(?=\\}\\})"

  match <- gregexpr(rx, e2, perl=TRUE)

  syntax <- regmatches(e2, match)[[1]]
  syntax <- lapply(syntax, parse, file="", n=NULL)
##  syntax<-lapply(syntax, eval.parent, n=N.UP)
  r <- tryCatch( syntax<-lapply(syntax, eval.parent, n=N.UP), error=
function(e) NULL )
  if (is.null(r)) r <- tryCatch( syntax<-lapply(syntax, eval.parent,
n=N.UP+1), error= function(e) NULL )
  if (is.null(r)) r <- tryCatch( syntax<-lapply(syntax, eval.parent,
n=N.UP-1), error= function(e) NULL )
  if (is.null(r)) r <- tryCatch( syntax<-lapply(syntax, eval.parent,
n=N.UP-2), error= function(e) "unknown variable" )
  ## the return is now ignored.  if we cannot recognize the syntax, we
just leave it.

  s<- unlist(sys.calls())
  if (length(s)>1) cat("Function '",
as.character(s[[length(s)-N.UP+1]]), "':\n\t", sep="") else
cat("[GlobalEnv]:\t")
  regmatches(e2, match) <- "%s"

  do.call(sprintf, c(fmt=e2, '...'=syntax) )
}
----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/
J. Fred Weston Professor of Finance
Anderson School at UCLA, C519
Director, UCLA Anderson Fink Center for Finance and Investments
Free Finance Textbook, http://book.ivo-welch.info/
Editor, Critical Finance Review, http://www.critical-finance-review.org/



On Tue, Aug 20, 2013 at 2:14 PM, Brian Rowe <rowe at muxspace.com> wrote:
> If all you care about is emulating static type checking, then you can also accomplish the same thing with lambda.r using type constraints on function definitions.
>
> e.g.
>> f(m) %::% matrix : matrix
>> f(m) %as% { m }
>
>> f(as.data.frame(matrix(rnorm(12),nrow=3)))
> Error in UseFunction("f", ...) : No valid function for 'f(data.frame)'
>
>> f(1)
> Error in UseFunction("f", ...) : No valid function for 'f(1)'
>
>> f
> <function>
> [[1]]
> f(m) %::% matrix:matrix
> f(m) %as% ?
>
>
>
> On Aug 20, 2013, at 4:36 PM, Peter Langfelder <peter.langfelder at gmail.com> wrote:
>
>> On Tue, Aug 20, 2013 at 11:41 AM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
>>> I am using a variant of stopifnot a lot.  can I suggest that base R
>>> extends its functionality?  I know how to do this for myself.  this is
>>> a suggestion for beginners and students.  I don't think it would break
>>> anything.
>>>
>>> first, I think it would be more useful if it had an optional character
>>> string, so users could write
>>>
>>>  stopifnot( is.matrix(m), "m is not a matrix" )
>>>
>>> this would mean that stopifnot would have to detect whether the last
>>> argument is a string.  (I think stopifnot should have had only one
>>> condition, and one should have used all() to test multiple conditions,
>>> but this is a bridge that was already crossed.)  upon failure,
>>> stopifnot should print the character string.  that's it.
>>>
>>>
>>> A second enhancement would be a "smart string", which knows that
>>> everything inside {{...}} should be evaluated.
>>>
>>>  stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )
>>
>> I think using a function (in this case paste) is cleaner:
>>
>> paste("m is not a matrix, but a", class(m))
>>
>> It avoids adding a new convention ("evaluate everything between {{
>> }}") and has additional arguments.
>>
>>>
>>>
>>> my own programming variant looks even nicer,
>>>
>>>   is.matrix(m) %or% "m is not a matrix but a {{class(m)}}"
>>
>> In R you can write it as
>>
>> is.matrix(m) || stop("m is not a matrix but a ", class(m))
>>
>> Examples:
>>
>> m = 1
>>> is.matrix(m) || stop("m is not a matrix but a ", class(m))
>> Error: m is not a matrix but a numeric
>>
>>> m = matrix(0,2,2)
>>> is.matrix(m) || stop("m is not a matrix but a ", class(m))
>> [1] TRUE
>>
>> But the construct
>>
>> if (!is.matrix(m)) stop("m is not a matrix but a ", class(m))
>>
>> is more readable for people not used to Pearl.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Wed Aug 21 00:28:43 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Aug 2013 18:28:43 -0400
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
	<13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>
	<CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>
Message-ID: <CAP01uR=DjMtUHE7QZmHuY5hwRADg66dADRX1AxoFmbTJWBwFMw@mail.gmail.com>

On Tue, Aug 20, 2013 at 6:00 PM, ivo welch <ivo.welch at gmail.com> wrote:
> character string at the end of an existing function, stopifnot().  (2)
> I think "estrings" (that behave like characters but are interpolated
> before printout) are useful in the same way perl interpolated strings
> are useful.

The gsubfn package has string interpolation somewhat like perl.
Preface a function call with fn$ and then back ticks and $ are
interpolated.

library(gsubfn)
fn$identity("pi is $pi")

library(sqldf)
fn$sqldf("select * from BOD where Time > $pi")

fn$stop("class is `class(pi)`")


From ivo.welch at gmail.com  Wed Aug 21 00:39:10 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Tue, 20 Aug 2013 15:39:10 -0700
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAP01uR=DjMtUHE7QZmHuY5hwRADg66dADRX1AxoFmbTJWBwFMw@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
	<13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>
	<CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>
	<CAP01uR=DjMtUHE7QZmHuY5hwRADg66dADRX1AxoFmbTJWBwFMw@mail.gmail.com>
Message-ID: <CAPr7RtUhENdMa8zgT8-ys9GccjFr+R=fA6XMep5mqkoLfv7SjQ@mail.gmail.com>

functionality is nice.  syntax is weird.  I think I would have
preferred an "interpolate" function call.
    stop( i("class is `class(pi)` and $pi") )
three typing letters, too, and more logical.  most importantly, I wish
we had some form of this in base R from the outset--whatever it is--so
that my students get used to using the standard from the outset.

[the {{...}} had the advantage of being unlikely to break anything.
perl has it nicely done--- " is interpolated, ' is not.  but this is a
bridge that we crossed long ago in R.  it would break too much.]

best,

/iaw
----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/
J. Fred Weston Professor of Finance
Anderson School at UCLA, C519
Director, UCLA Anderson Fink Center for Finance and Investments
Free Finance Textbook, http://book.ivo-welch.info/
Editor, Critical Finance Review, http://www.critical-finance-review.org/



On Tue, Aug 20, 2013 at 3:28 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Tue, Aug 20, 2013 at 6:00 PM, ivo welch <ivo.welch at gmail.com> wrote:
>> character string at the end of an existing function, stopifnot().  (2)
>> I think "estrings" (that behave like characters but are interpolated
>> before printout) are useful in the same way perl interpolated strings
>> are useful.
>
> The gsubfn package has string interpolation somewhat like perl.
> Preface a function call with fn$ and then back ticks and $ are
> interpolated.
>
> library(gsubfn)
> fn$identity("pi is $pi")
>
> library(sqldf)
> fn$sqldf("select * from BOD where Time > $pi")
>
> fn$stop("class is `class(pi)`")


From h.wickham at gmail.com  Wed Aug 21 00:43:03 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 20 Aug 2013 17:43:03 -0500
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <CABdHhvFTih=NGm=_PxJfTSO3g29HR=wPJWOYOxk5UmKFk2H52w@mail.gmail.com>

> first, I think it would be more useful if it had an optional character
> string, so users could write
>
>   stopifnot( is.matrix(m), "m is not a matrix" )
>

Another option is to just generate better error messages automatically, e.g.:

> library(assertthat)
> x <- 1:10
> assert_that(is.matrix(x))
Error: x is not a matrix

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From mtmorgan at fhcrc.org  Wed Aug 21 02:36:33 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 20 Aug 2013 17:36:33 -0700
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <52140B91.4010300@fhcrc.org>

On 08/20/2013 11:41 AM, ivo welch wrote:
> A second enhancement would be a "smart string", which knows that
> everything inside {{...}} should be evaluated.
>
>    stopifnot( is.matrix(m), "m is not a matrix, but a {{class(m)}}" )

a variant with more traditional syntax might be

   if (!is.matrix(m))
       stopf("m is not a matrix, but a '%s'", class(m))
or

   stopifnotf(is.matrix(m), "m is not a matrix, but a '%s'", class(m))

where stopf is analogous to sprintf but signalling the corresponding condition 
(perhaps taking the opportunity to strwrap to getOption("width")). This would 
work well with gettextf to allow for translation. An imperfect implementation 
(call. is incorrect, for example) is

.msg <-
     function(fmt, ..., domain=NULL, width=getOption("width"))
     ## Use this helper to format all error / warning / message text
{
     txt <- strwrap(gettextf(fmt, ..., domain=domain), width=width,
                    exdent=2)
     paste(txt, collapse="\n")
}

stopf <-
     function(..., call.=FALSE)
{
     stop(.msg(...), call.=call.)
}

stopifnotf <-
     function(test, fmt, ...)
{
     if (!test)
         stopf(fmt, ...)
}

One might also wish to expose the condition class system, along the lines of

.textf <- ## a variant of .makeMessage
     function(fmt, ..., width = getOption("width"), domain = NULL,
              appendLF = FALSE)
{
     txt <- gettextf(fmt, ..., domain = domain)
     msg <- paste(strwrap(txt, width = width, indent = 2, exdent = 2),
                  collapse="\n")
     if (appendLF)
         paste0(msg, "\n")
     else msg
}

.condition <-
     function(fmt, ..., class, call = NULL)
{
     msg <- .textf(fmt, ...)
     if (is.null(call))
         msg <- paste0("\n", msg)
     class <- c(class, "condition")
     structure(list(message=msg, call = call), class=class)
}

stopf <-
     function(fmt, ..., class. = "simpleError", call. = TRUE, domain = NULL)
{
     call. <- if (is.logical(call.) && 1L == length(call.) && call.)
         sys.call(-1)
     else NULL
     cond <- .condition(fmt, ..., domain = domain,
                        class = c(class., "error"), call = call.)
     stop(cond)
}

warnf <-
     function(fmt, ..., class. = "simpleWarning", call. = TRUE, domain = NULL)
{
     ## does not support immediate., but options(warn=1) supported
     call. <- if (is.logical(call.) && 1L == length(call.) && call.)
         sys.call(-1)
     else NULL
     cond <- .condition(fmt, ..., domain = domain,
                        class = c(class., "warning" ), call = call.)
     warning(cond)
}

messagef <-
     function(fmt, ..., class. = "simpleMessage", domain = NULL,
              appendLF = TRUE)
{
     cond <- .condition(fmt, ..., domain = domain, appendLF = appendLF,
                        class = c(class., "message"))
     message(cond)
}


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From deepayan.sarkar at gmail.com  Wed Aug 21 10:26:20 2013
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 21 Aug 2013 13:56:20 +0530
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<CA+hbrhVcih5+u1hV5c2c_+HC6UJ6BzpdwmP4VWuuU=gdNmkz1Q@mail.gmail.com>
	<13664C4E-7ACE-410E-A0EE-6D07D5E590BD@muxspace.com>
	<CAPr7RtWxF=Vh3OSpZEonKpLKnbDNnHT2X3dvAXVzeqdcnB2_CA@mail.gmail.com>
Message-ID: <CADfFDC6EMTY4oxjLN9oH3JvCMSGY0Tp5sX1mqjJU1zDGrj_euA@mail.gmail.com>

On Wed, Aug 21, 2013 at 3:30 AM, ivo welch <ivo.welch at gmail.com> wrote:
> thx, deepayan:  how is stopifnot better than
>     if (!all(...)) stop()

But I am not claiming that it is!

If you think it is not useful, then don't use stopifnot(), use stop()
instead, and tell your students to do so as well.

> given that we have stopifnot() and I have seen it used often, I think
> my two suggestions would make it better.

Maybe it will (in some specific use cases). But looking at your
suggestion purely from the point of view of "is it worth incorporating
into base R?", I don't see enough justification. The disadvantage is
that it will complicate a simple function. The supposed advantage is
only an advantage when you use stopifnot() in a way that was not
intended, whereas there is already an alternative that does almost
exactly what you want (at least you haven't yet explained why you are
not happy with stop()). Interpolated strings may be cool, but I don't
see a big readability advantage of

if (!is.matrix(m)) stop("m is not a matrix, but a {{class(m)}}")

over

if (!is.matrix(m)) stop("m is not a matrix, but a ", class(m))

Note that I'm not saying that stop() is perfect or anything, or that
there is no need for alternatives. Just that I'm not convinced that
the base R changes you want are justified.

-Deepayan


From SheltonS at stemcell.ucsf.edu  Tue Aug 20 19:42:42 2013
From: SheltonS at stemcell.ucsf.edu (Shelton, Samuel)
Date: Tue, 20 Aug 2013 17:42:42 +0000
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CA+hbrhUsbQOA-qa3x27VfmbKTt19JCuDuzUMR8icxbxbB7OZ3Q@mail.gmail.com>
Message-ID: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>

Hi all,

Thanks for getting back to me. We would like to move over to v3.0.0 on our
cluster so that we can build matrices larger than 46300*46300 (limit in R
<3.0.0)
but so far we can't get things to work with R v3.0.0 and higher. I am
trying to trouble shoot at the moment and I am now thinking that the
problem is actually with the diag function that has been rewritten in
version 3.0.0. 


The problem is definitely with the diag function and it does not occur on
smaller matrices (20000*20000) and I think it maybe a bug.
This illustrates the problem:

This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
I do see the same for 3.0.0). This does not occur when I run it with R
2.15.2. 


mat1=matrix(rexp(20000^2), 20000)

mat1[1:10,1:10]
           [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
 [,7]       [,8]       [,9]      [,10]
 [1,] 0.1829090 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
0.469843567 2.57767543 0.17449595 0.01949358
 [2,] 0.5731522 0.15835939 0.29165029 0.6781249 0.64553728 2.4438404
2.140374938 0.40091195 0.51201369 0.98904490
 [3,] 0.3250310 0.09934147 0.79962549 0.4933385 0.30473422 0.4556765
0.002640034 0.90606861 2.58772944 0.89884208
 [4,] 1.4195017 0.16082660 0.01377838 0.2115803 1.43992672 0.3883675
0.040903805 0.51011305 0.41998024 0.44209926
 [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.17333324 0.3388678
3.206179119 0.52170966 1.03084845 0.05843232
 [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 1.0237664
2.547528816 1.35629450 0.87983354 0.25236343
 [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
1.137348735 0.08371053 0.23144290 0.18915132
 [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
0.144371435 3.03299285 0.09728111 0.39890260
 [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
2.437192399 0.34689557 0.02039205 0.54898488
[10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
0.571159401 0.63375850 0.63221987 1.32840290
> mat1[19990:20000,19990:20000]
           [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
  [,7]      [,8]       [,9]     [,10]     [,11]
 [1,] 1.7910910 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
 [2,] 0.2862914 1.5267870 0.98214645 0.0004617244 0.6395319 0.075217874
0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
 [3,] 2.0492301 0.7216115 0.16951284 0.2726676762 2.1893806 1.202518385
0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
 [4,] 0.6538994 0.2437594 2.08848881 0.3917212249 0.4441824 0.433749415
1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
 [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.8914097 0.497023176
0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
 [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 1.296227000
0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
 [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
1.5474078 2.5899490 5.19298969 1.4680934 1.0537164
 [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
1.8699504 1.9187339 5.13248671 0.4621520 0.4753582
 [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
0.7391137 0.1574844 0.65985494 0.4066742 0.8072494
[10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
0.4642319 0.1582297 1.71676326 0.3662139 0.7864957
[11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
0.8430396 0.5132811 0.30547431 1.6088725 0.4001791

diag(mat1)=0

mat1[1:10,1:10]
           [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
 [,7]       [,8]       [,9]      [,10]
 [1,] 0.0000000 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
0.469843567 2.57767543 0.17449595 0.01949358
 [2,] 0.5731522 0.00000000 0.29165029 0.6781249 0.64553728 2.4438404
2.140374938 0.40091195 0.51201369 0.98904490
 [3,] 0.3250310 0.09934147 0.00000000 0.4933385 0.30473422 0.4556765
0.002640034 0.90606861 2.58772944 0.89884208
 [4,] 1.4195017 0.16082660 0.01377838 0.0000000 1.43992672 0.3883675
0.040903805 0.51011305 0.41998024 0.44209926
 [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.00000000 0.3388678
3.206179119 0.52170966 1.03084845 0.05843232
 [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 0.0000000
2.547528816 1.35629450 0.87983354 0.25236343
 [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
0.000000000 0.08371053 0.23144290 0.18915132
 [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
0.144371435 0.00000000 0.09728111 0.39890260
 [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
2.437192399 0.34689557 0.00000000 0.54898488
[10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
0.571159401 0.63375850 0.63221987 0.00000000

mat1[19990:20000,19990:20000]
           [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
  [,7]      [,8]       [,9]     [,10]     [,11]
 [1,] 0.0000000 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
 [2,] 0.2862914 0.0000000 0.98214645 0.0004617244 0.6395319 0.075217874
0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
 [3,] 2.0492301 0.7216115 0.00000000 0.2726676762 2.1893806 1.202518385
0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
 [4,] 0.6538994 0.2437594 2.08848881 0.0000000000 0.4441824 0.433749415
1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
 [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.0000000 0.497023176
0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
 [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 0.000000000
0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
 [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
0.0000000 2.5899490 5.19298969 1.4680934 1.0537164
 [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
1.8699504 0.0000000 5.13248671 0.4621520 0.4753582
 [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
0.7391137 0.1574844 0.00000000 0.4066742 0.8072494
[10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
0.4642319 0.1582297 1.71676326 0.0000000 0.7864957
[11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
0.8430396 0.5132811 0.30547431 1.6088725 0.0000000

mat1=matrix(rexp(38000^2), 38000)
dim(mat1)
[1] 38000 38000
mat1[1:10,1:10]
           [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
[,7]      [,8]       [,9]      [,10]
 [1,] 3.8622815 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
0.45672475 0.2891504 1.57087882 1.27375802
 [2,] 3.8229940 0.1540735 0.30189392 1.2100152 0.003323061 0.7195875
0.60251052 1.9820380 0.18637086 0.05154236
 [3,] 2.0411498 0.8371707 0.02714550 1.3032572 0.330472063 0.3502267
0.11908140 0.4155857 3.46471729 0.31890778
 [4,] 1.5503390 0.7377494 2.01433675 0.6109255 1.844484309 1.2492693
0.09365743 0.4006219 2.37769616 0.38643521
 [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.526454982 0.1207842
0.93567987 1.7369767 4.47922786 0.20033928
 [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.1362716
1.72807083 0.2570055 0.02127689 0.80225716
 [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
0.01432572 0.6064162 0.69264596 0.50871566
 [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
1.12583466 0.3391067 0.18707165 3.71877247
 [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
0.18612994 1.0498866 1.89162156 1.56643880
[10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
0.25436398 1.1275389 0.20960212 0.63957112




mat1[37990:38000,37990:38000]
           [,1]       [,2]       [,3]       [,4]      [,5]       [,6]
[,7]       [,8]       [,9]     [,10]     [,11]
 [1,] 0.8349326 1.32098263 2.68879316 0.52361090 1.4066094 0.00754308
2.4489865 1.76284621 0.09097126 2.1598758 0.8805701
 [2,] 2.5754994 1.15753606 1.76895066 3.06645700 0.8767225 0.33247639
1.5726808 0.12698495 0.75271682 6.4336476 0.1330457
 [3,] 2.5737957 0.58234929 0.40403205 0.34882433 0.4074048 1.54867135
2.5971068 0.27276140 0.56926494 0.2129180 1.3027215
 [4,] 0.9352113 0.46839288 0.41284388 1.40216119 0.8936151 2.98304058
0.4350446 1.14864094 0.26756970 2.6662998 0.1802141
 [5,] 1.6430435 1.22137017 0.06943644 0.03251737 0.2142083 0.16964865
1.6099314 0.95709429 0.22884734 0.5087986 0.9048555
 [6,] 2.5340159 1.28618183 3.86698388 1.05946189 3.5006776 0.39320471
0.4927357 0.66159842 0.18235678 0.5172896 2.2221550
 [7,] 0.1961937 0.17305031 0.62327325 3.14622730 3.4905449 3.08823676
0.5282165 0.48879156 0.11807913 0.7372706 0.9975103
 [8,] 0.8392414 0.17107463 1.08732839 0.28981611 0.4722655 0.17587788
1.7426814 0.13985161 1.86885446 1.9031580 1.1088431
 [9,] 3.4648342 0.33834943 0.07891645 0.07206860 1.1792628 0.54092203
0.8141844 2.82687085 0.78395229 0.5313417 3.2164664
[10,] 0.1524299 0.02045616 0.67881610 1.51491647 2.4390115 0.89033581
0.9026651 0.46858464 1.47711638 2.1821178 2.2149071
[11,] 0.9397162 0.42376104 0.20034405 1.47672836 1.0461904 0.97296202
2.1658717 0.04487329 0.30611082 1.1680312 0.9952517

diag(mat1)=0

mat1[1:10,1:10]
           [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
[,7]      [,8]       [,9]      [,10]
 [1,] 0.0000000 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
0.45672475 0.2891504 1.57087882 1.27375802
 [2,] 3.8229940 0.0000000 0.30189392 1.2100152 0.003323061 0.7195875
0.60251052 1.9820380 0.18637086 0.05154236
 [3,] 2.0411498 0.8371707 0.00000000 1.3032572 0.330472063 0.3502267
0.11908140 0.4155857 3.46471729 0.31890778
 [4,] 1.5503390 0.7377494 2.01433675 0.0000000 1.844484309 1.2492693
0.09365743 0.4006219 2.37769616 0.38643521
 [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.000000000 0.1207842
0.93567987 1.7369767 4.47922786 0.20033928
 [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.0000000
1.72807083 0.2570055 0.02127689 0.80225716
 [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
0.00000000 0.6064162 0.69264596 0.50871566
 [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
1.12583466 0.0000000 0.18707165 3.71877247
 [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
0.18612994 1.0498866 0.00000000 1.56643880
[10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
0.25436398 1.1275389 0.20960212 0.00000000


## After calling the diag function the bottom of the matrix is all set to
0.


mat1[37990:38000,37990:38000]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
 [1,]    0    0    0    0    0    0    0    0    0     0     0
 [2,]    0    0    0    0    0    0    0    0    0     0     0
 [3,]    0    0    0    0    0    0    0    0    0     0     0
 [4,]    0    0    0    0    0    0    0    0    0     0     0
 [5,]    0    0    0    0    0    0    0    0    0     0     0
 [6,]    0    0    0    0    0    0    0    0    0     0     0
 [7,]    0    0    0    0    0    0    0    0    0     0     0
 [8,]    0    0    0    0    0    0    0    0    0     0     0
 [9,]    0    0    0    0    0    0    0    0    0     0     0
[10,]    0    0    0    0    0    0    0    0    0     0     0
[11,]    0    0    0    0    0    0    0    0    0     0     0

It looks like there is an issue with larger matrices when calling diag
function and it has nothing to do with WGCNA.






On 8/20/13 9:43 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:

>Hi Sam,
>
>I assume you mean that correlation for _genes_ (not samples)
>11262:30000 is 0? I am the maintainer of the WGCNA package but
>unfortunately I don't have access to a Mac big enough to try
>30000x30000 correlation matrix, but I would be thankful if you could
>try reproducing the problem with smaller matrices (e.g. 20000x20000)
>and try to produce a small reproducible example by
>generating the data using say rnorm, say like this:
>
>nGenes = 20000 # as small as possible that still produces the error
>nSamples = 100
>datExpr1 = matrix(rnorm(nSamples * nGenes), nSamples, nGenes)
>
>simMat = bicor(datExpr1, use = 'p')
>
>Best,
>
>Peter
>
>On Mon, Aug 19, 2013 at 11:53 AM, Shelton, Samuel
><SheltonS at stemcell.ucsf.edu> wrote:
>> Dear R developer,
>>
>> I am an R user and am currently having a problem with versions of R
>>>3.0.0. We build larger correlation matrices of >30000 with pairwise
>>>correlations made. We have been using a line of code
>>
>> simMat=bicor(datExpr1,use="p")
>>
>> To build the similarity matrix with datExpr1 being a matrix with genes
>>as columns (>30000) and rows being samples. This code works fine on an
>>iMac running OSX 10.8.5 and using R 2.15.2 and the Rblas library. When I
>>try to run the same code with R version 3.0.0 and 3.0.1 it only
>>partially builds the matrix. It will return correlations for samples
>>1:11262 but from 11262:30000 the matrix is full of 0's.
>>
>> We would like to be able to use R 3.0.0 to allow us to build larger
>>correlation matrices on our cluster but we can't use it at the moment
>>due to this problem. My colleague has previously had a similar issue
>>when using snow leopard and this was to do with a compatibility issue
>>between snow leopard and the veclib. Has something changed in version
>>3.0.0 to give an incompatibility with the veclib?
>>
>> Many thanks
>>
>> Sam
>>
>> Samuel Shelton, Ph.D.
>> Postdoctoral Researcher,
>> The Oldham Lab,
>> The institute of Regeneration Medicine,
>> University of California San Francisco,
>> San Francisco, CA 94143
>>
>> email: sheltons at stemcell.ucsf.edu
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From SheltonS at stemcell.ucsf.edu  Tue Aug 20 20:04:30 2013
From: SheltonS at stemcell.ucsf.edu (Shelton, Samuel)
Date: Tue, 20 Aug 2013 18:04:30 +0000
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CA+hbrhVzUye1C3ZLpTWnPB21gaZYhiWeffHsf+sDCe0oeV0=RA@mail.gmail.com>
Message-ID: <CE38FC69.1882B%sheltons@stemcell.ucsf.edu>

Hi Peter,


But this is still an issue bellow the old R limit. I just tried the same
with a matrix of 30000*30000 and I see the same problem. This never used
to happen with R v2.15.2 and we could regularly build similarity matrices
of 45000*45000. This behavior of filling up the bottom of the matrix with
0's after calling diag is only happening with v3.0.0 and v3.0.1.

As I said I don't think that this is an issue with WGCNA but it has
implications for WGCNA because it limits the number of genes to be
included in network construction.

Thanks

Sam






On 8/20/13 10:53 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:

>Hi Samuel,
>
>WGCNA currently does not support calculations with matrices larger
>than the old R limit, and it will take some time to update it to
>support the large matrices. Furthermore, WGCNA relies on other
>functions (most notably hclust) that would have to be updated as well
>to support long vectors.
>
>In the meantime I suggest using the "blockwise" functions to handle
>large data sets, or, if possible, reducing the number of genes to less
>than the old limit of 46340 or so.
>
>Sorry I can't be of more help.
>
>Best,
>
>Peter
>
>On Tue, Aug 20, 2013 at 10:42 AM, Shelton, Samuel
><SheltonS at stemcell.ucsf.edu> wrote:
>> Hi all,
>>
>> Thanks for getting back to me. We would like to move over to v3.0.0 on
>>our
>> cluster so that we can build matrices larger than 46300*46300 (limit in
>>R
>> <3.0.0)
>> but so far we can't get things to work with R v3.0.0 and higher. I am
>> trying to trouble shoot at the moment and I am now thinking that the
>> problem is actually with the diag function that has been rewritten in
>> version 3.0.0.
>>
>>
>> The problem is definitely with the diag function and it does not occur
>>on
>> smaller matrices (20000*20000) and I think it maybe a bug.
>> This illustrates the problem:
>>
>> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1
>>(but
>> I do see the same for 3.0.0). This does not occur when I run it with R
>> 2.15.2.
>>
>>
>> mat1=matrix(rexp(20000^2), 20000)
>>
>> mat1[1:10,1:10]
>>            [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
>>  [,7]       [,8]       [,9]      [,10]
>>  [1,] 0.1829090 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
>> 0.469843567 2.57767543 0.17449595 0.01949358
>>  [2,] 0.5731522 0.15835939 0.29165029 0.6781249 0.64553728 2.4438404
>> 2.140374938 0.40091195 0.51201369 0.98904490
>>  [3,] 0.3250310 0.09934147 0.79962549 0.4933385 0.30473422 0.4556765
>> 0.002640034 0.90606861 2.58772944 0.89884208
>>  [4,] 1.4195017 0.16082660 0.01377838 0.2115803 1.43992672 0.3883675
>> 0.040903805 0.51011305 0.41998024 0.44209926
>>  [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.17333324 0.3388678
>> 3.206179119 0.52170966 1.03084845 0.05843232
>>  [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 1.0237664
>> 2.547528816 1.35629450 0.87983354 0.25236343
>>  [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
>> 1.137348735 0.08371053 0.23144290 0.18915132
>>  [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
>> 0.144371435 3.03299285 0.09728111 0.39890260
>>  [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
>> 2.437192399 0.34689557 0.02039205 0.54898488
>> [10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
>> 0.571159401 0.63375850 0.63221987 1.32840290
>>> mat1[19990:20000,19990:20000]
>>            [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
>>   [,7]      [,8]       [,9]     [,10]     [,11]
>>  [1,] 1.7910910 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
>> 0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
>>  [2,] 0.2862914 1.5267870 0.98214645 0.0004617244 0.6395319 0.075217874
>> 0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
>>  [3,] 2.0492301 0.7216115 0.16951284 0.2726676762 2.1893806 1.202518385
>> 0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
>>  [4,] 0.6538994 0.2437594 2.08848881 0.3917212249 0.4441824 0.433749415
>> 1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
>>  [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.8914097 0.497023176
>> 0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
>>  [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 1.296227000
>> 0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
>>  [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
>> 1.5474078 2.5899490 5.19298969 1.4680934 1.0537164
>>  [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
>> 1.8699504 1.9187339 5.13248671 0.4621520 0.4753582
>>  [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
>> 0.7391137 0.1574844 0.65985494 0.4066742 0.8072494
>> [10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
>> 0.4642319 0.1582297 1.71676326 0.3662139 0.7864957
>> [11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
>> 0.8430396 0.5132811 0.30547431 1.6088725 0.4001791
>>
>> diag(mat1)=0
>>
>> mat1[1:10,1:10]
>>            [,1]       [,2]       [,3]      [,4]       [,5]      [,6]
>>  [,7]       [,8]       [,9]      [,10]
>>  [1,] 0.0000000 0.39867734 0.80499126 4.1746377 0.20717066 1.1477365
>> 0.469843567 2.57767543 0.17449595 0.01949358
>>  [2,] 0.5731522 0.00000000 0.29165029 0.6781249 0.64553728 2.4438404
>> 2.140374938 0.40091195 0.51201369 0.98904490
>>  [3,] 0.3250310 0.09934147 0.00000000 0.4933385 0.30473422 0.4556765
>> 0.002640034 0.90606861 2.58772944 0.89884208
>>  [4,] 1.4195017 0.16082660 0.01377838 0.0000000 1.43992672 0.3883675
>> 0.040903805 0.51011305 0.41998024 0.44209926
>>  [5,] 0.8328441 1.10335604 0.11875332 0.1600287 0.00000000 0.3388678
>> 3.206179119 0.52170966 1.03084845 0.05843232
>>  [6,] 1.3179906 0.76376188 1.24231798 0.9424030 0.04440514 0.0000000
>> 2.547528816 1.35629450 0.87983354 0.25236343
>>  [7,] 0.6990544 1.17003075 0.66063936 0.8632534 0.28965611 0.6718020
>> 0.000000000 0.08371053 0.23144290 0.18915132
>>  [8,] 0.9908026 1.20471979 0.08816010 0.2652131 0.03537790 0.3295816
>> 0.144371435 0.00000000 0.09728111 0.39890260
>>  [9,] 0.9557305 0.29196500 0.43955758 0.7332643 2.03457020 0.5858431
>> 2.437192399 0.34689557 0.00000000 0.54898488
>> [10,] 3.7220703 0.13572389 0.18888673 0.5683698 1.79209016 1.3495723
>> 0.571159401 0.63375850 0.63221987 0.00000000
>>
>> mat1[19990:20000,19990:20000]
>>            [,1]      [,2]       [,3]         [,4]      [,5]        [,6]
>>   [,7]      [,8]       [,9]     [,10]     [,11]
>>  [1,] 0.0000000 0.5719982 0.38689588 1.2157545685 0.8530179 1.464105574
>> 0.5986705 1.1623393 0.55244563 0.1770146 0.4326310
>>  [2,] 0.2862914 0.0000000 0.98214645 0.0004617244 0.6395319 0.075217874
>> 0.6725620 0.2403549 0.08436217 0.1435451 0.7487862
>>  [3,] 2.0492301 0.7216115 0.00000000 0.2726676762 2.1893806 1.202518385
>> 0.9897710 1.4813026 2.42517705 0.3398811 0.7285074
>>  [4,] 0.6538994 0.2437594 2.08848881 0.0000000000 0.4441824 0.433749415
>> 1.3022991 1.3695241 0.07057642 0.4296937 2.9307556
>>  [5,] 2.3688094 2.3970048 0.03545232 0.5986997508 0.0000000 0.497023176
>> 0.4210650 1.5337767 0.01141066 1.1562830 1.0572076
>>  [6,] 2.0626934 0.6186995 0.99197835 1.4794321654 0.1549314 0.000000000
>> 0.2790942 0.9327613 0.84131377 0.8782590 0.3279970
>>  [7,] 1.2423823 0.2385994 0.11390071 2.0745023842 1.9152523 0.754186281
>> 0.0000000 2.5899490 5.19298969 1.4680934 1.0537164
>>  [8,] 1.3657070 1.9502828 1.07681438 0.9339731540 1.7532474 0.186193421
>> 1.8699504 0.0000000 5.13248671 0.4621520 0.4753582
>>  [9,] 0.6512000 0.5104660 0.17820166 0.3965162944 0.0919119 0.187808660
>> 0.7391137 0.1574844 0.00000000 0.4066742 0.8072494
>> [10,] 0.7435028 1.1395666 2.46096009 0.7060164691 1.7965986 0.008278685
>> 0.4642319 0.1582297 1.71676326 0.0000000 0.7864957
>> [11,] 0.3537041 0.6622001 2.01642141 1.8225423060 0.3295436 1.260737179
>> 0.8430396 0.5132811 0.30547431 1.6088725 0.0000000
>>
>> mat1=matrix(rexp(38000^2), 38000)
>> dim(mat1)
>> [1] 38000 38000
>> mat1[1:10,1:10]
>>            [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
>> [,7]      [,8]       [,9]      [,10]
>>  [1,] 3.8622815 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
>> 0.45672475 0.2891504 1.57087882 1.27375802
>>  [2,] 3.8229940 0.1540735 0.30189392 1.2100152 0.003323061 0.7195875
>> 0.60251052 1.9820380 0.18637086 0.05154236
>>  [3,] 2.0411498 0.8371707 0.02714550 1.3032572 0.330472063 0.3502267
>> 0.11908140 0.4155857 3.46471729 0.31890778
>>  [4,] 1.5503390 0.7377494 2.01433675 0.6109255 1.844484309 1.2492693
>> 0.09365743 0.4006219 2.37769616 0.38643521
>>  [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.526454982 0.1207842
>> 0.93567987 1.7369767 4.47922786 0.20033928
>>  [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.1362716
>> 1.72807083 0.2570055 0.02127689 0.80225716
>>  [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
>> 0.01432572 0.6064162 0.69264596 0.50871566
>>  [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
>> 1.12583466 0.3391067 0.18707165 3.71877247
>>  [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
>> 0.18612994 1.0498866 1.89162156 1.56643880
>> [10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
>> 0.25436398 1.1275389 0.20960212 0.63957112
>>
>>
>>
>>
>> mat1[37990:38000,37990:38000]
>>            [,1]       [,2]       [,3]       [,4]      [,5]       [,6]
>> [,7]       [,8]       [,9]     [,10]     [,11]
>>  [1,] 0.8349326 1.32098263 2.68879316 0.52361090 1.4066094 0.00754308
>> 2.4489865 1.76284621 0.09097126 2.1598758 0.8805701
>>  [2,] 2.5754994 1.15753606 1.76895066 3.06645700 0.8767225 0.33247639
>> 1.5726808 0.12698495 0.75271682 6.4336476 0.1330457
>>  [3,] 2.5737957 0.58234929 0.40403205 0.34882433 0.4074048 1.54867135
>> 2.5971068 0.27276140 0.56926494 0.2129180 1.3027215
>>  [4,] 0.9352113 0.46839288 0.41284388 1.40216119 0.8936151 2.98304058
>> 0.4350446 1.14864094 0.26756970 2.6662998 0.1802141
>>  [5,] 1.6430435 1.22137017 0.06943644 0.03251737 0.2142083 0.16964865
>> 1.6099314 0.95709429 0.22884734 0.5087986 0.9048555
>>  [6,] 2.5340159 1.28618183 3.86698388 1.05946189 3.5006776 0.39320471
>> 0.4927357 0.66159842 0.18235678 0.5172896 2.2221550
>>  [7,] 0.1961937 0.17305031 0.62327325 3.14622730 3.4905449 3.08823676
>> 0.5282165 0.48879156 0.11807913 0.7372706 0.9975103
>>  [8,] 0.8392414 0.17107463 1.08732839 0.28981611 0.4722655 0.17587788
>> 1.7426814 0.13985161 1.86885446 1.9031580 1.1088431
>>  [9,] 3.4648342 0.33834943 0.07891645 0.07206860 1.1792628 0.54092203
>> 0.8141844 2.82687085 0.78395229 0.5313417 3.2164664
>> [10,] 0.1524299 0.02045616 0.67881610 1.51491647 2.4390115 0.89033581
>> 0.9026651 0.46858464 1.47711638 2.1821178 2.2149071
>> [11,] 0.9397162 0.42376104 0.20034405 1.47672836 1.0461904 0.97296202
>> 2.1658717 0.04487329 0.30611082 1.1680312 0.9952517
>>
>> diag(mat1)=0
>>
>> mat1[1:10,1:10]
>>            [,1]      [,2]       [,3]      [,4]        [,5]      [,6]
>> [,7]      [,8]       [,9]      [,10]
>>  [1,] 0.0000000 0.1357886 1.64090976 0.4494637 0.812315613 0.5328906
>> 0.45672475 0.2891504 1.57087882 1.27375802
>>  [2,] 3.8229940 0.0000000 0.30189392 1.2100152 0.003323061 0.7195875
>> 0.60251052 1.9820380 0.18637086 0.05154236
>>  [3,] 2.0411498 0.8371707 0.00000000 1.3032572 0.330472063 0.3502267
>> 0.11908140 0.4155857 3.46471729 0.31890778
>>  [4,] 1.5503390 0.7377494 2.01433675 0.0000000 1.844484309 1.2492693
>> 0.09365743 0.4006219 2.37769616 0.38643521
>>  [5,] 0.4815804 0.5824312 0.61003728 0.4782871 0.000000000 0.1207842
>> 0.93567987 1.7369767 4.47922786 0.20033928
>>  [6,] 0.3791645 0.1015489 1.96832962 1.5417178 1.030250434 0.0000000
>> 1.72807083 0.2570055 0.02127689 0.80225716
>>  [7,] 1.5212795 2.8133952 0.15990367 0.4337506 0.526532536 2.9926685
>> 0.00000000 0.6064162 0.69264596 0.50871566
>>  [8,] 1.2600365 0.1901277 2.34806048 1.1472887 0.141571521 2.0355007
>> 1.12583466 0.0000000 0.18707165 3.71877247
>>  [9,] 3.0197258 2.3693633 0.94571337 0.2756933 0.938999190 1.5892456
>> 0.18612994 1.0498866 0.00000000 1.56643880
>> [10,] 0.3573243 0.3047595 0.01894034 2.4666841 0.660994174 0.2248711
>> 0.25436398 1.1275389 0.20960212 0.00000000
>>
>>
>> ## After calling the diag function the bottom of the matrix is all set
>>to
>> 0.
>>
>>
>> mat1[37990:38000,37990:38000]
>>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
>>  [1,]    0    0    0    0    0    0    0    0    0     0     0
>>  [2,]    0    0    0    0    0    0    0    0    0     0     0
>>  [3,]    0    0    0    0    0    0    0    0    0     0     0
>>  [4,]    0    0    0    0    0    0    0    0    0     0     0
>>  [5,]    0    0    0    0    0    0    0    0    0     0     0
>>  [6,]    0    0    0    0    0    0    0    0    0     0     0
>>  [7,]    0    0    0    0    0    0    0    0    0     0     0
>>  [8,]    0    0    0    0    0    0    0    0    0     0     0
>>  [9,]    0    0    0    0    0    0    0    0    0     0     0
>> [10,]    0    0    0    0    0    0    0    0    0     0     0
>> [11,]    0    0    0    0    0    0    0    0    0     0     0
>>
>> It looks like there is an issue with larger matrices when calling diag
>> function and it has nothing to do with WGCNA.
>>
>>
>>
>>
>>
>>
>> On 8/20/13 9:43 AM, "Peter Langfelder" <peter.langfelder at gmail.com>
>>wrote:
>>
>>>Hi Sam,
>>>
>>>I assume you mean that correlation for _genes_ (not samples)
>>>11262:30000 is 0? I am the maintainer of the WGCNA package but
>>>unfortunately I don't have access to a Mac big enough to try
>>>30000x30000 correlation matrix, but I would be thankful if you could
>>>try reproducing the problem with smaller matrices (e.g. 20000x20000)
>>>and try to produce a small reproducible example by
>>>generating the data using say rnorm, say like this:
>>>
>>>nGenes = 20000 # as small as possible that still produces the error
>>>nSamples = 100
>>>datExpr1 = matrix(rnorm(nSamples * nGenes), nSamples, nGenes)
>>>
>>>simMat = bicor(datExpr1, use = 'p')
>>>
>>>Best,
>>>
>>>Peter
>>>
>>>On Mon, Aug 19, 2013 at 11:53 AM, Shelton, Samuel
>>><SheltonS at stemcell.ucsf.edu> wrote:
>>>> Dear R developer,
>>>>
>>>> I am an R user and am currently having a problem with versions of R
>>>>>3.0.0. We build larger correlation matrices of >30000 with pairwise
>>>>>correlations made. We have been using a line of code
>>>>
>>>> simMat=bicor(datExpr1,use="p")
>>>>
>>>> To build the similarity matrix with datExpr1 being a matrix with genes
>>>>as columns (>30000) and rows being samples. This code works fine on an
>>>>iMac running OSX 10.8.5 and using R 2.15.2 and the Rblas library. When
>>>>I
>>>>try to run the same code with R version 3.0.0 and 3.0.1 it only
>>>>partially builds the matrix. It will return correlations for samples
>>>>1:11262 but from 11262:30000 the matrix is full of 0's.
>>>>
>>>> We would like to be able to use R 3.0.0 to allow us to build larger
>>>>correlation matrices on our cluster but we can't use it at the moment
>>>>due to this problem. My colleague has previously had a similar issue
>>>>when using snow leopard and this was to do with a compatibility issue
>>>>between snow leopard and the veclib. Has something changed in version
>>>>3.0.0 to give an incompatibility with the veclib?
>>>>
>>>> Many thanks
>>>>
>>>> Sam
>>>>
>>>> Samuel Shelton, Ph.D.
>>>> Postdoctoral Researcher,
>>>> The Oldham Lab,
>>>> The institute of Regeneration Medicine,
>>>> University of California San Francisco,
>>>> San Francisco, CA 94143
>>>>
>>>> email: sheltons at stemcell.ucsf.edu
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From pdalgd at gmail.com  Wed Aug 21 14:45:39 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Aug 2013 14:45:39 +0200
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
Message-ID: <E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>


On Aug 20, 2013, at 19:42 , Shelton, Samuel wrote:

> Hi all,
> 
> Thanks for getting back to me. We would like to move over to v3.0.0 on our
> cluster so that we can build matrices larger than 46300*46300 (limit in R
> <3.0.0)
> but so far we can't get things to work with R v3.0.0 and higher. I am
> trying to trouble shoot at the moment and I am now thinking that the
> problem is actually with the diag function that has been rewritten in
> version 3.0.0. 
> 
> 
> The problem is definitely with the diag function and it does not occur on
> smaller matrices (20000*20000) and I think it maybe a bug.
> This illustrates the problem:
> 
> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
> I do see the same for 3.0.0). This does not occur when I run it with R
> 2.15.2. 
> 


Thanks. I can condense this to 

> M <- matrix(1,23170,23170) ; diag(M) <- 0 ; range(colSums(M))
[1] 23169 23169
> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
[1]     0 23170

and the fact that 2^14.5 is 23170.48 is not likely to be a coincidence...

It is only happening with some of my builds, though. In particular, my MacPorts build of 3.0.1 does not have the problem on Snow Leopard, nor does the CRAN build of 3.0.0, still on Snow Leopard. It takes forever to check on a 4GB machine....

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From geoffjentry at hexdump.org  Wed Aug 21 15:56:20 2013
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Wed, 21 Aug 2013 06:56:20 -0700 (PDT)
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1308210656030.3904@cardinals.dreamhost.com>

> first, I think it would be more useful if it had an optional character
> string, so users could write
>  stopifnot( is.matrix(m), "m is not a matrix" )

stop() allows for arbitrary strings ....


From ripley at stats.ox.ac.uk  Wed Aug 21 16:00:04 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Aug 2013 15:00:04 +0100
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
Message-ID: <5214C7E4.7000901@stats.ox.ac.uk>

On 21/08/2013 13:45, peter dalgaard wrote:
>
> On Aug 20, 2013, at 19:42 , Shelton, Samuel wrote:
>
>> Hi all,
>>
>> Thanks for getting back to me. We would like to move over to v3.0.0 on our
>> cluster so that we can build matrices larger than 46300*46300 (limit in R
>> <3.0.0)
>> but so far we can't get things to work with R v3.0.0 and higher. I am
>> trying to trouble shoot at the moment and I am now thinking that the
>> problem is actually with the diag function that has been rewritten in
>> version 3.0.0.
>>
>>
>> The problem is definitely with the diag function and it does not occur on
>> smaller matrices (20000*20000) and I think it maybe a bug.
>> This illustrates the problem:
>>
>> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
>> I do see the same for 3.0.0). This does not occur when I run it with R
>> 2.15.2.
>>
>
>
> Thanks. I can condense this to
>
>> M <- matrix(1,23170,23170) ; diag(M) <- 0 ; range(colSums(M))
> [1] 23169 23169
>> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
> [1]     0 23170

A much faster check is to look at M[1:3, 1:3]

> and the fact that 2^14.5 is 23170.48 is not likely to be a coincidence...
>
> It is only happening with some of my builds, though. In particular, my MacPorts build of 3.0.1 does not have the problem on Snow Leopard, nor does the CRAN build of 3.0.0, still on Snow Leopard. It takes forever to check on a 4GB machine....

Note that does not use the diag() function but diag<-(), which is 
essentially unchanged since 2.15.x (the error detection was moved above 
an expensive calculation).

It works correctly on x86_64 Linux and Solaris.  I suspect a 
platform-specific issue in

         x[cbind(i, i)] <- value


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Aug 21 16:39:13 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Aug 2013 16:39:13 +0200
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <5214C7E4.7000901@stats.ox.ac.uk>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
	<5214C7E4.7000901@stats.ox.ac.uk>
Message-ID: <C7B04BCF-0772-42B3-8CA1-50C98A5E3C4A@gmail.com>


On Aug 21, 2013, at 16:00 , Prof Brian Ripley wrote:

> On 21/08/2013 13:45, peter dalgaard wrote:
>> 
>> On Aug 20, 2013, at 19:42 , Shelton, Samuel wrote:
>> 
>>> Hi all,
>>> 
>>> Thanks for getting back to me. We would like to move over to v3.0.0 on our
>>> cluster so that we can build matrices larger than 46300*46300 (limit in R
>>> <3.0.0)
>>> but so far we can't get things to work with R v3.0.0 and higher. I am
>>> trying to trouble shoot at the moment and I am now thinking that the
>>> problem is actually with the diag function that has been rewritten in
>>> version 3.0.0.
>>> 
>>> 
>>> The problem is definitely with the diag function and it does not occur on
>>> smaller matrices (20000*20000) and I think it maybe a bug.
>>> This illustrates the problem:
>>> 
>>> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
>>> I do see the same for 3.0.0). This does not occur when I run it with R
>>> 2.15.2.
>>> 
>> 
>> 
>> Thanks. I can condense this to
>> 
>>> M <- matrix(1,23170,23170) ; diag(M) <- 0 ; range(colSums(M))
>> [1] 23169 23169
>>> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
>> [1]     0 23170
> 
> A much faster check is to look at M[1:3, 1:3]

That doesn't show the issue for larger values of 23171, though.


> 
>> and the fact that 2^14.5 is 23170.48 is not likely to be a coincidence...
>> 
>> It is only happening with some of my builds, though. In particular, my MacPorts build of 3.0.1 does not have the problem on Snow Leopard, nor does the CRAN build of 3.0.0, still on Snow Leopard. It takes forever to check on a 4GB machine....
> 
> Note that does not use the diag() function but diag<-(), which is essentially unchanged since 2.15.x (the error detection was moved above an expensive calculation).
> 
> It works correctly on x86_64 Linux and Solaris.  I suspect a platform-specific issue in
> 
>        x[cbind(i, i)] <- value

Likely. I'm not seeing it on the iMac/SnowLeopard, only on the MacPro/Lion. I'm upgrading the MacPorts R on the MacPro now to see whether it has issues too, but of course that reinstalls everything but the kitchen sink...

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Wed Aug 21 18:51:46 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Aug 2013 18:51:46 +0200
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <C7B04BCF-0772-42B3-8CA1-50C98A5E3C4A@gmail.com>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
	<5214C7E4.7000901@stats.ox.ac.uk>
	<C7B04BCF-0772-42B3-8CA1-50C98A5E3C4A@gmail.com>
Message-ID: <113B3522-724C-4427-A8EF-3321595F43F4@gmail.com>


On Aug 21, 2013, at 16:39 , peter dalgaard wrote:

> 
> Likely. I'm not seeing it on the iMac/SnowLeopard, only on the MacPro/Lion. I'm upgrading the MacPorts R on the MacPro now to see whether it has issues too, but of course that reinstalls everything but the kitchen sink...

Whoops. I don't know what I was thinking there. I seem to have suppressed all memory of the hard disk replacement on the iMac, and its aftereffects. Both machines are in fact running Lion! That makes things even odder...


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From istazahn at gmail.com  Wed Aug 21 20:47:07 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 21 Aug 2013 14:47:07 -0400
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <113B3522-724C-4427-A8EF-3321595F43F4@gmail.com>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
	<5214C7E4.7000901@stats.ox.ac.uk>
	<C7B04BCF-0772-42B3-8CA1-50C98A5E3C4A@gmail.com>
	<113B3522-724C-4427-A8EF-3321595F43F4@gmail.com>
Message-ID: <CA+vqiLFwzHgXWWqwYpPgWc-5etRdg8NiM_Oivz4Pe6gEDH8JTw@mail.gmail.com>

In case this is helpful, I don't see this issue on my Mac Pro with OSX
version 10.7.5. Details below.


> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
[1] 23170 23170

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> .Platform
$OS.type
[1] "unix"

$file.sep
[1] "/"

$dynlib.ext
[1] ".so"

$GUI
[1] "X11"

$endian
[1] "little"

$pkgType
[1] "mac.binary"

$path.sep
[1] ":"

$r_arch
[1] ""

> R.Version()
$platform
[1] "x86_64-apple-darwin10.8.0"

$arch
[1] "x86_64"

$os
[1] "darwin10.8.0"

$system
[1] "x86_64, darwin10.8.0"

$status
[1] ""

$major
[1] "3"

$minor
[1] "0.1"

$year
[1] "2013"

$month
[1] "05"

$day
[1] "16"

$`svn rev`
[1] "62743"

$language
[1] "R"

$version.string
[1] "R version 3.0.1 (2013-05-16)"

$nickname
[1] "Good Sport"

On Wed, Aug 21, 2013 at 12:51 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Aug 21, 2013, at 16:39 , peter dalgaard wrote:
>
>>
>> Likely. I'm not seeing it on the iMac/SnowLeopard, only on the MacPro/Lion. I'm upgrading the MacPorts R on the MacPro now to see whether it has issues too, but of course that reinstalls everything but the kitchen sink...
>
> Whoops. I don't know what I was thinking there. I seem to have suppressed all memory of the hard disk replacement on the iMac, and its aftereffects. Both machines are in fact running Lion! That makes things even odder...
>
>
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Aug 21 21:26:00 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Aug 2013 20:26:00 +0100
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <5214C7E4.7000901@stats.ox.ac.uk>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
	<5214C7E4.7000901@stats.ox.ac.uk>
Message-ID: <52151448.8040708@stats.ox.ac.uk>

On 21/08/2013 15:00, Prof Brian Ripley wrote:
> On 21/08/2013 13:45, peter dalgaard wrote:
>>
>> On Aug 20, 2013, at 19:42 , Shelton, Samuel wrote:
>>
>>> Hi all,
>>>
>>> Thanks for getting back to me. We would like to move over to v3.0.0
>>> on our
>>> cluster so that we can build matrices larger than 46300*46300 (limit
>>> in R
>>> <3.0.0)
>>> but so far we can't get things to work with R v3.0.0 and higher. I am
>>> trying to trouble shoot at the moment and I am now thinking that the
>>> problem is actually with the diag function that has been rewritten in
>>> version 3.0.0.
>>>
>>>
>>> The problem is definitely with the diag function and it does not
>>> occur on
>>> smaller matrices (20000*20000) and I think it maybe a bug.
>>> This illustrates the problem:
>>>
>>> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1
>>> (but
>>> I do see the same for 3.0.0). This does not occur when I run it with R
>>> 2.15.2.
>>>
>>
>>
>> Thanks. I can condense this to
>>
>>> M <- matrix(1,23170,23170) ; diag(M) <- 0 ; range(colSums(M))
>> [1] 23169 23169
>>> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
>> [1]     0 23170
>
> A much faster check is to look at M[1:3, 1:3]
>
>> and the fact that 2^14.5 is 23170.48 is not likely to be a coincidence...
>>
>> It is only happening with some of my builds, though. In particular, my
>> MacPorts build of 3.0.1 does not have the problem on Snow Leopard, nor
>> does the CRAN build of 3.0.0, still on Snow Leopard. It takes forever
>> to check on a 4GB machine....
>
> Note that does not use the diag() function but diag<-(), which is
> essentially unchanged since 2.15.x (the error detection was moved above
> an expensive calculation).
>
> It works correctly on x86_64 Linux and Solaris.  I suspect a
> platform-specific issue in
>
>          x[cbind(i, i)] <- value
>
>

I have tracked this down to an issue with memcpy on vectors of 2^32 or 
more bytes.  That very likely explains why it appears in some OS X 
builds and not others (depending on the compiler and libc used), and not 
on other platforms.

I am looking into a workaround that only uses smaller sections for 
memcpy without losing all the performance gains.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ivo.welch at gmail.com  Thu Aug 22 01:49:18 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Wed, 21 Aug 2013 16:49:18 -0700
Subject: [Rd] Extending suggestion for stopifnot
In-Reply-To: <alpine.DEB.2.00.1308210656030.3904@cardinals.dreamhost.com>
References: <CAPr7RtX3b5XBzgn1XT3nPcvX71G=W1CpK=tK1T3zz4zWW=pQNQ@mail.gmail.com>
	<alpine.DEB.2.00.1308210656030.3904@cardinals.dreamhost.com>
Message-ID: <CAPr7RtUkSx61+3oG-eoMGAKZ_g1d=T12HAOwS-G+EEeMyPHcsg@mail.gmail.com>

thx to everyone for having listened to my suggestion and reasoning
through it, even though it won't fly.

maybe, as a last word, let me add a short appeal that is more generic:
 R is a tough programming language for beginners.  anything that
allows a user to request additional error-checking, and/or that makes
it easier and encourages users to write programs that check inputs
would probably get widely used and be welcome by many.  R libraries
are useful, but it's not the same as having these sort of features in
the base language.

regards,

/iaw
----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/
J. Fred Weston Professor of Finance
Anderson School at UCLA, C519
Director, UCLA Anderson Fink Center for Finance and Investments
Free Finance Textbook, http://book.ivo-welch.info/
Editor, Critical Finance Review, http://www.critical-finance-review.org/



On Wed, Aug 21, 2013 at 6:56 AM, Geoff Jentry <geoffjentry at hexdump.org> wrote:
>> first, I think it would be more useful if it had an optional character
>> string, so users could write
>>  stopifnot( is.matrix(m), "m is not a matrix" )
>
>
> stop() allows for arbitrary strings ....


From xie at yihui.name  Thu Aug 22 07:45:08 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 22 Aug 2013 00:45:08 -0500
Subject: [Rd] legitimate use of :::
Message-ID: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>

Hi,

So now R CMD check starts to warn against :::, but I believe sometimes
it is legitimate to use it when developing R packages. For example, I
have some utils functions that are not exported but I want to share
them across the packages that I maintain. I do not need to coordinate
with other authors about these internal functions since I'm the only
author and I know clearly what I'm doing, and I want to avoid copying
and pasting the code across packages just to avoid the NOTE in R CMD
check. What should I do in this case?

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
102 Snedecor Hall, Ames, IA


From ligges at statistik.tu-dortmund.de  Thu Aug 22 13:45:01 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 22 Aug 2013 13:45:01 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
Message-ID: <5215F9BD.5030009@statistik.tu-dortmund.de>



On 22.08.2013 07:45, Yihui Xie wrote:
> Hi,
>
> So now R CMD check starts to warn against :::, but I believe sometimes
> it is legitimate to use it when developing R packages. For example, I
> have some utils functions that are not exported but I want to share
> them across the packages that I maintain. I do not need to coordinate
> with other authors about these internal functions since I'm the only
> author and I know clearly what I'm doing, and I want to avoid copying
> and pasting the code across packages just to avoid the NOTE in R CMD
> check. What should I do in this case?

Nothing. The way you describe above seems to be a reasonable usage, iff 
you are the same maintainer who knows what is going on. Other 
maintainers should not use one of your not exported (hence non API) 
functions, of course.

Uwe Ligges


>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 102 Snedecor Hall, Ames, IA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From friendly at yorku.ca  Thu Aug 22 15:09:40 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 22 Aug 2013 09:09:40 -0400
Subject: [Rd] Confusion about Depends:, Imports:, Enhances:, import(),
	inportFrom()
Message-ID: <52160D94.4010605@yorku.ca>

In checking my vcdExtra package, the following NOTE newly appeared 
(R-Forge, using R version 3.0.1 Patched (2013-08-20 r63635))

Package in Depends field not imported from: ?gnm?
   These packages needs to imported from for the case when
   this namespace is loaded but not attached.

In the DESCRIPTION file, I have

Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)

In NAMESPACE:

# we are a vcd extension
import(vcd)

I've read 1.1.1 of R-Exts, but it is not clear to me whether I should 
also import gnm or change
the DESCRIPTION file to use

Imports: vcd, gnm (>= 1.0.3)

R-Exts says: The ?Imports? field lists packages whose namespaces are 
imported from (as specified in the
NAMESPACE file) but which do not need to be attached, but how can I tell 
if gnm needs to be attached?

Also, what is the difference between Imports: in DESCRIPTION and 
imports() in NAMESPACE?

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From michael.weylandt at gmail.com  Thu Aug 22 19:05:18 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Thu, 22 Aug 2013 13:05:18 -0400
Subject: [Rd] Confusion about Depends:, Imports:, Enhances:, import(),
	inportFrom()
In-Reply-To: <52160D94.4010605@yorku.ca>
References: <52160D94.4010605@yorku.ca>
Message-ID: <32CA103E-3F41-4051-B54E-A8EDD90BC694@gmail.com>



On Aug 22, 2013, at 9:09, Michael Friendly <friendly at yorku.ca> wrote:

> In checking my vcdExtra package, the following NOTE newly appeared (R-Forge, using R version 3.0.1 Patched (2013-08-20 r63635))
> 
> Package in Depends field not imported from: ?gnm?
>  These packages needs to imported from for the case when
>  this namespace is loaded but not attached.
> 
> In the DESCRIPTION file, I have
> 
> Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)
> 
> In NAMESPACE:
> 
> # we are a vcd extension
> import(vcd)
> 
> I've read 1.1.1 of R-Exts, but it is not clear to me whether I should also import gnm or change
> the DESCRIPTION file to use
> 
> Imports: vcd, gnm (>= 1.0.3)
> 
> R-Exts says: The ?Imports? field lists packages whose namespaces are imported from (as specified in the
> NAMESPACE file) but which do not need to be attached, but how can I tell if gnm needs to be attached?

I think the current best practice is to use Imports unless gnm provides functions the end user needs in order to use your package. 

Practically, I think this usually comes down to asking whether gnm provides relevant generics -- if you provide methods only, the end user would only be able to call them directly (ick!) unless gnm is both loaded and attached (Depends)

If gnm is tools for your code, but not the user to call directly, Imports is cleaner. 

Does that help?

Michael

> 
> Also, what is the difference between Imports: in DESCRIPTION and imports() in NAMESPACE?
> 

One enables the other: Imports in DESCRIPTION allows for both imports() and importsFrom(). It could probably be automatic, but the DESC file is much older than the NAMESPACE file. 


> -Michael
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From friendly at yorku.ca  Thu Aug 22 20:57:25 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 22 Aug 2013 14:57:25 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <5215F9BD.5030009@statistik.tu-dortmund.de>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
Message-ID: <52165F15.1090500@yorku.ca>

On 8/22/2013 7:45 AM, Uwe Ligges wrote:
>
>
> On 22.08.2013 07:45, Yihui Xie wrote:
>> Hi,
>>
>> So now R CMD check starts to warn against :::, but I believe sometimes
>> it is legitimate to use it when developing R packages. For example, I
>> have some utils functions that are not exported but I want to share
>> them across the packages that I maintain. I do not need to coordinate
>> with other authors about these internal functions since I'm the only
>> author and I know clearly what I'm doing, and I want to avoid copying
>> and pasting the code across packages just to avoid the NOTE in R CMD
>> check. What should I do in this case?
>
> Nothing. The way you describe above seems to be a reasonable usage, iff
> you are the same maintainer who knows what is going on. Other
> maintainers should not use one of your not exported (hence non API)
> functions, of course.
>
> Uwe Ligges
>
>

Related to this is the use of other-package unexported utility functions 
that don't pass Uwe's iff test, but I, as maintainer,
want to use in my package.

Cases in point:  in heplots, I had used stats:::Pillai, stats:::Wilks,
stats:::Roy and stats:::LH for calculation in one of my functions.
Similarly, I had a need to use car:::df.terms, also unexported, but
don't want to ask John Fox to export it just for my use.  Uwe's
reply suggests that I should not be using car:::df.terms, however.

To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
CRAN), I simply copied/pasted these functions to my package, but this 
seems wasteful.

-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From hb at biostat.ucsf.edu  Thu Aug 22 21:33:36 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 22 Aug 2013 12:33:36 -0700
Subject: [Rd] Confusion about Depends:, Imports:, Enhances:, import(),
	inportFrom()
In-Reply-To: <32CA103E-3F41-4051-B54E-A8EDD90BC694@gmail.com>
References: <52160D94.4010605@yorku.ca>
	<32CA103E-3F41-4051-B54E-A8EDD90BC694@gmail.com>
Message-ID: <CAFDcVCTY7Y4gTYz1u-U+OdrahFcsdD6WHU+0HR_szz73OxyWMQ@mail.gmail.com>

On Thu, Aug 22, 2013 at 10:05 AM, R. Michael Weylandt
<michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>
>
> On Aug 22, 2013, at 9:09, Michael Friendly <friendly at yorku.ca> wrote:
>
>> In checking my vcdExtra package, the following NOTE newly appeared (R-Forge, using R version 3.0.1 Patched (2013-08-20 r63635))
>>
>> Package in Depends field not imported from: ?gnm?
>>  These packages needs to imported from for the case when
>>  this namespace is loaded but not attached.
>>
>> In the DESCRIPTION file, I have
>>
>> Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)
>>
>> In NAMESPACE:
>>
>> # we are a vcd extension
>> import(vcd)
>>
>> I've read 1.1.1 of R-Exts, but it is not clear to me whether I should also import gnm or change
>> the DESCRIPTION file to use
>>
>> Imports: vcd, gnm (>= 1.0.3)
>>
>> R-Exts says: The ?Imports? field lists packages whose namespaces are imported from (as specified in the
>> NAMESPACE file) but which do not need to be attached, but how can I tell if gnm needs to be attached?
>
> I think the current best practice is to use Imports unless gnm provides functions the end user needs in order to use your package.
>
> Practically, I think this usually comes down to asking whether gnm provides relevant generics -- if you provide methods only, the end user would only be able to call them directly (ick!) unless gnm is both loaded and attached (Depends)
>
> If gnm is tools for your code, but not the user to call directly, Imports is cleaner.
>
> Does that help?
>
> Michael
>
>>
>> Also, what is the difference between Imports: in DESCRIPTION and imports() in NAMESPACE?
>>
>
> One enables the other: Imports in DESCRIPTION allows for both imports() and importsFrom(). It could probably be automatic, but the DESC file is much older than the NAMESPACE file.

I pretty sure you can also use import()/importFrom() in NAMESPACE for
packages listed under Depends in DESCRIPTION.

/Henrik

>
>
>> -Michael
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.weylandt at gmail.com  Thu Aug 22 22:28:05 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Thu, 22 Aug 2013 16:28:05 -0400
Subject: [Rd] Confusion about Depends:, Imports:, Enhances:, import(),
	inportFrom()
In-Reply-To: <CAFDcVCTY7Y4gTYz1u-U+OdrahFcsdD6WHU+0HR_szz73OxyWMQ@mail.gmail.com>
References: <52160D94.4010605@yorku.ca>
	<32CA103E-3F41-4051-B54E-A8EDD90BC694@gmail.com>
	<CAFDcVCTY7Y4gTYz1u-U+OdrahFcsdD6WHU+0HR_szz73OxyWMQ@mail.gmail.com>
Message-ID: <196580BF-4351-46B2-A912-FE3C8B024B53@gmail.com>



On Aug 22, 2013, at 15:33, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

> On Thu, Aug 22, 2013 at 10:05 AM, R. Michael Weylandt
> <michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>> 
>> 
>> On Aug 22, 2013, at 9:09, Michael Friendly <friendly at yorku.ca> wrote:
>> 
>>> In checking my vcdExtra package, the following NOTE newly appeared (R-Forge, using R version 3.0.1 Patched (2013-08-20 r63635))
>>> 
>>> Package in Depends field not imported from: ?gnm?
>>> These packages needs to imported from for the case when
>>> this namespace is loaded but not attached.
>>> 
>>> In the DESCRIPTION file, I have
>>> 
>>> Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)
>>> 
>>> In NAMESPACE:
>>> 
>>> # we are a vcd extension
>>> import(vcd)
>>> 
>>> I've read 1.1.1 of R-Exts, but it is not clear to me whether I should also import gnm or change
>>> the DESCRIPTION file to use
>>> 
>>> Imports: vcd, gnm (>= 1.0.3)
>>> 
>>> R-Exts says: The ?Imports? field lists packages whose namespaces are imported from (as specified in the
>>> NAMESPACE file) but which do not need to be attached, but how can I tell if gnm needs to be attached?
>> 
>> I think the current best practice is to use Imports unless gnm provides functions the end user needs in order to use your package.
>> 
>> Practically, I think this usually comes down to asking whether gnm provides relevant generics -- if you provide methods only, the end user would only be able to call them directly (ick!) unless gnm is both loaded and attached (Depends)
>> 
>> If gnm is tools for your code, but not the user to call directly, Imports is cleaner.
>> 
>> Does that help?
>> 
>> Michael
>> 
>>> 
>>> Also, what is the difference between Imports: in DESCRIPTION and imports() in NAMESPACE?
>> 
>> One enables the other: Imports in DESCRIPTION allows for both imports() and importsFrom(). It could probably be automatic, but the DESC file is much older than the NAMESPACE file.
> 
> I pretty sure you can also use import()/importFrom() in NAMESPACE for
> packages listed under Depends in DESCRIPTION.
> 

Agreed, but you couldn't auto-generate Depends from the namespace file. I suppose if (per my above) Depends was only used for generics...

Not sure if the devtools world does anything like this, though it seems logical enough. 

Michael

> /Henrik
> 
>> 
>> 
>>> -Michael
>>> 
>>> --
>>> Michael Friendly     Email: friendly AT yorku DOT ca
>>> Professor, Psychology Dept. & Chair, Quantitative Methods
>>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>>> 4700 Keele Street    Web:   http://www.datavis.ca
>>> Toronto, ONT  M3J 1P3 CANADA
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Thu Aug 22 22:44:32 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 22 Aug 2013 22:44:32 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <52165F15.1090500@yorku.ca>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
Message-ID: <250BF44E-7313-4EAB-8140-BA8D6D7B953A@gmail.com>


On Aug 22, 2013, at 20:57 , Michael Friendly wrote:

> Cases in point:  in heplots, I had used stats:::Pillai, stats:::Wilks,
> stats:::Roy and stats:::LH for calculation in one of my functions.

That particular case has been on what remains of my conscience for some time....

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Thu Aug 22 22:42:01 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 22 Aug 2013 16:42:01 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <52165F15.1090500@yorku.ca>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
Message-ID: <001301ce9f78$0e5e0e20$2b1a2a60$@mcmaster.ca>

Dear Michael and Uwe,

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Michael Friendly
> Sent: Thursday, August 22, 2013 2:57 PM
> To: Uwe Ligges
> Cc: R-devel
> Subject: Re: [Rd] legitimate use of :::
> 
> On 8/22/2013 7:45 AM, Uwe Ligges wrote:
> >
> >
> > On 22.08.2013 07:45, Yihui Xie wrote:
> >> Hi,
> >>
> >> So now R CMD check starts to warn against :::, but I believe
> sometimes
> >> it is legitimate to use it when developing R packages. For example,
> I
> >> have some utils functions that are not exported but I want to share
> >> them across the packages that I maintain. I do not need to
> coordinate
> >> with other authors about these internal functions since I'm the only
> >> author and I know clearly what I'm doing, and I want to avoid
> copying
> >> and pasting the code across packages just to avoid the NOTE in R CMD
> >> check. What should I do in this case?
> >
> > Nothing. The way you describe above seems to be a reasonable usage,
> iff
> > you are the same maintainer who knows what is going on. Other
> > maintainers should not use one of your not exported (hence non API)
> > functions, of course.
> >
> > Uwe Ligges
> >
> >
> 
> Related to this is the use of other-package unexported utility
> functions
> that don't pass Uwe's iff test, but I, as maintainer,
> want to use in my package.
> 
> Cases in point:  in heplots, I had used stats:::Pillai, stats:::Wilks,
> stats:::Roy and stats:::LH for calculation in one of my functions.
> Similarly, I had a need to use car:::df.terms, also unexported, but
> don't want to ask John Fox to export it just for my use.  Uwe's
> reply suggests that I should not be using car:::df.terms, however.
> 
> To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
> CRAN), I simply copied/pasted these functions to my package, but this
> seems wasteful.

I think that the ideal solution is for everyone to export functions that
somewhat else might want, but it's hard to anticipate what these are, and it
would be useful then to differentiate functions that are meant for "end"
users from those meant for developers. Maybe packages could document the
latter in something like a Utilities.Rd file. Probably there's a better,
more formal, solution.

The stats:::Pillai, Wilks, HL, and Roy functions seem reasonable candidates
for export -- I too use these functions, in the car package, and have
resorted to the fix that Michael adopted. I'd be happy to export df.terms,
but would rather segregate it from end-user functions.

It's also clear to me that enforcing namespace conventions more
consistently, which is certainly desirable in the abstract, opens a can of
worms, especially for the CRAN administrators. One hopes that we'll all
survive the process and will have better packages in the end.

My two cents.

John

> 
> -Michael
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu Aug 22 23:03:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 22 Aug 2013 16:03:53 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <52165F15.1090500@yorku.ca>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
Message-ID: <CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>

> To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
> CRAN), I simply copied/pasted these functions to my package, but this seems
> wasteful.

Wasteful of disk space, but disk space is cheap. It's less wasteful of
your time, if the referenced code breaks in an unexpected time.  Your
time is much more valuable than disk space.

A gigabyte of disk space costs about $0.10, so even if you value your
time at a very conservative rate of $100 / hour, you should only spend
an hour of your time reducing package size if it saves at least 1 TB
of disk space. That's a lot of copies of a function!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From xie at yihui.name  Thu Aug 22 23:22:50 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 22 Aug 2013 16:22:50 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <5215F9BD.5030009@statistik.tu-dortmund.de>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
Message-ID: <CANROs4f67ZzpOHPE90J9vCOD5z8jENauWatX++4Mv3f=oWYd=g@mail.gmail.com>

r63654 has fixed this particular issue, and R-devel will no longer
warn against the use of ::: on packages of the same maintainer.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
102 Snedecor Hall, Ames, IA


On Thu, Aug 22, 2013 at 6:45 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 22.08.2013 07:45, Yihui Xie wrote:
>>
>> Hi,
>>
>> So now R CMD check starts to warn against :::, but I believe sometimes
>> it is legitimate to use it when developing R packages. For example, I
>> have some utils functions that are not exported but I want to share
>> them across the packages that I maintain. I do not need to coordinate
>> with other authors about these internal functions since I'm the only
>> author and I know clearly what I'm doing, and I want to avoid copying
>> and pasting the code across packages just to avoid the NOTE in R CMD
>> check. What should I do in this case?
>
>
> Nothing. The way you describe above seems to be a reasonable usage, iff you
> are the same maintainer who knows what is going on. Other maintainers should
> not use one of your not exported (hence non API) functions, of course.
>
> Uwe Ligges


From hb at biostat.ucsf.edu  Thu Aug 22 23:23:01 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 22 Aug 2013 14:23:01 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
Message-ID: <CAFDcVCRnhpzbC+vkZEwWXYo1UhQex=DMB7ExkxaxVaYwBgPrFA@mail.gmail.com>

On Thu, Aug 22, 2013 at 2:03 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>> To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
>> CRAN), I simply copied/pasted these functions to my package, but this seems
>> wasteful.
>
> Wasteful of disk space, but disk space is cheap. It's less wasteful of
> your time, if the referenced code breaks in an unexpected time.  Your
> time is much more valuable than disk space.
>
> A gigabyte of disk space costs about $0.10, so even if you value your
> time at a very conservative rate of $100 / hour, you should only spend
> an hour of your time reducing package size if it saves at least 1 TB
> of disk space. That's a lot of copies of a function!

A bigger issue is source-code license conflicts; you may cut'n'paste
GPL code into a distribution that is under another license.

/Henrik


>
> Hadley
>
> --
> Chief Scientist, RStudio
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gmbecker at ucdavis.edu  Thu Aug 22 23:26:08 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 22 Aug 2013 14:26:08 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
Message-ID: <CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/7d42ff2c/attachment.pl>

From h.wickham at gmail.com  Thu Aug 22 23:36:41 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 22 Aug 2013 16:36:41 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
Message-ID: <CABdHhvHsTCgkOxsXSTMWf2PX6apoXHN4jDoqi6s=S3c9BwcfLg@mail.gmail.com>

>>Wasteful of disk space, but disk space is cheap. It's less wasteful of
>>your time, if the referenced code breaks in an unexpected time.  Your
>>time is much more valuable than disk space.
>
> On the other hand, it's quite dangerous software design. What if the
> original author finds a bug and implements a fix, but you don't hear about
> it?
>
> Furthermore, what happens when I come along and need the same functionality?
> Sure I could make a copy, but maybe I only know about your copy and don't
> know it is a copy of something else, so now we have a copy of a copy, which
> is even more problematic. Using ::: prevents this issue.

There are costs and benefits to both approaches. Copy-and-paste also
minimises external dependencies which can be important in some cases.
I'm not arguing for unmitigated duplication, but there are definitely
good reasons to do it.

I have quite a few v. simple functions that live in multiple packages.
Often I want to keep the dependencies of packages as lightweight as
possible (learning from past experiences) and avoid tightly coupling
packages together.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From jfox at mcmaster.ca  Thu Aug 22 23:43:35 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 22 Aug 2013 17:43:35 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <250BF44E-7313-4EAB-8140-BA8D6D7B953A@gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>	<5215F9BD.5030009@statistik.tu-dortmund.de>	<52165F15.1090500@yorku.ca>
	<250BF44E-7313-4EAB-8140-BA8D6D7B953A@gmail.com>
Message-ID: <002001ce9f80$a7f562b0$f7e02810$@mcmaster.ca>

Dear Peter,

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of peter dalgaard
> Sent: Thursday, August 22, 2013 4:45 PM
> To: Michael Friendly
> Cc: R-devel; Uwe Ligges
> Subject: Re: [Rd] legitimate use of :::
> 
> 
> On Aug 22, 2013, at 20:57 , Michael Friendly wrote:
> 
> > Cases in point:  in heplots, I had used stats:::Pillai,
> stats:::Wilks,
> > stats:::Roy and stats:::LH for calculation in one of my functions.
> 
> That particular case has been on what remains of my conscience for some
> time....
> 

Happily, it would be easy to relieve your conscience in this matter.

Best,
 John

> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rowe at muxspace.com  Thu Aug 22 23:52:09 2013
From: rowe at muxspace.com (Brian Rowe)
Date: Thu, 22 Aug 2013 17:52:09 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
Message-ID: <BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>

Another point to consider is that copying someone else's code forces you to become a maintainer of the copied code. If there are any bug fixes/enhancements/what-have-you in the original you won't get those updates. So now you own the copied code and need to consider the cost of the codebase diverging (from the original).

On Aug 22, 2013, at 5:03 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

>> To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
>> CRAN), I simply copied/pasted these functions to my package, but this seems
>> wasteful.
> 
> Wasteful of disk space, but disk space is cheap. It's less wasteful of
> your time, if the referenced code breaks in an unexpected time.  Your
> time is much more valuable than disk space.
> 
> A gigabyte of disk space costs about $0.10, so even if you value your
> time at a very conservative rate of $100 / hour, you should only spend
> an hour of your time reducing package size if it saves at least 1 TB
> of disk space. That's a lot of copies of a function!
> 
> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Fri Aug 23 00:00:54 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 22 Aug 2013 17:00:54 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
Message-ID: <CABdHhvGvYtzT92GaYLi8wUh1if04_-hKJ6MEmE6jGdpYw1j9uw@mail.gmail.com>

On Thu, Aug 22, 2013 at 4:52 PM, Brian Rowe <rowe at muxspace.com> wrote:
> Another point to consider is that copying someone else's code forces you to become a maintainer of the copied code. If there are any bug fixes/enhancements/what-have-you in the original you won't get those updates. So now you own the copied code and need to consider the cost of the codebase diverging (from the original).

Sometimes that's a good thing - you're equally insulated from the
original maintainer changing the function to work in a way that you
don't like.  Again, I'm not arguing that copy-and-paste is necessarily
the right solution, but it's not necessarily the wrong solution either
- it depends on the context.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From ggrothendieck at gmail.com  Fri Aug 23 00:27:20 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Aug 2013 18:27:20 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
Message-ID: <CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>

If ::: is disallowed then its likely that package developers will need
to export more functions to satisfy the consumers of those otherwise
hidden functions but if more functions are exported then there
will be a greater likelihood of conflicts among packages.

The problem seems to be that there are potentially three sorts of
functions here:

1. a function is hidden
2. a function is accessible via ::: but is not on the search path
3. a function is on the search path

The problem arises in attempting to force fit these three concepts
into only two
categories either by removing the first category (as was done previously)
or by removing the second category (which seems to be the new approach).


From rowe at muxspace.com  Fri Aug 23 00:36:52 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Thu, 22 Aug 2013 18:36:52 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
Message-ID: <ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>

You raise an interesting point that I've mulled over a bit: namespace collisions. How many of these issues would go away if there were a better mechanism for managing namespaces? eg in other languages you can control which objects/modules you wish to import from a library. Under this regime I think package developers would be less concerned about exposing functions that otherwise would be private. 

On Aug 22, 2013, at 6:27 PM, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> If ::: is disallowed then its likely that package developers will need
> to export more functions to satisfy the consumers of those otherwise
> hidden functions but if more functions are exported then there
> will be a greater likelihood of conflicts among packages.
> 
> The problem seems to be that there are potentially three sorts of
> functions here:
> 
> 1. a function is hidden
> 2. a function is accessible via ::: but is not on the search path
> 3. a function is on the search path
> 
> The problem arises in attempting to force fit these three concepts
> into only two
> categories either by removing the first category (as was done previously)
> or by removing the second category (which seems to be the new approach).


From ligges at statistik.tu-dortmund.de  Fri Aug 23 00:41:42 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 23 Aug 2013 00:41:42 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
Message-ID: <521693A6.5030407@statistik.tu-dortmund.de>



On 23.08.2013 00:36, Brian Lee Yung Rowe wrote:
> You raise an interesting point that I've mulled over a bit: namespace collisions. How many of these issues would go away if there were a better mechanism for managing namespaces? eg in other languages you can control which objects/modules you wish to import from a library. Under this regime I think package developers would be less concerned about exposing functions that otherwise would be private.


Exactly, the corresponding NAMESPACE directive is

importFrom()

and it should be used.


> On Aug 22, 2013, at 6:27 PM, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>
>> If ::: is disallowed then its likely that package developers will need
>> to export more functions to satisfy the consumers of those otherwise
>> hidden functions but if more functions are exported then there
>> will be a greater likelihood of conflicts among packages.
>>
>> The problem seems to be that there are potentially three sorts of
>> functions here:
>>
>> 1. a function is hidden
>> 2. a function is accessible via ::: but is not on the search path
>> 3. a function is on the search path
>

Not entirely right:

If the package or only parts of it are imported via importFrom by 
another package, the package is not loaded, hence not on the search path.

Best,
Uwe Ligges


>> The problem arises in attempting to force fit these three concepts
>> into only two
>> categories either by removing the first category (as was done previously)
>> or by removing the second category (which seems to be the new approach).


From ggrothendieck at gmail.com  Fri Aug 23 01:45:42 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Aug 2013 19:45:42 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <521693A6.5030407@statistik.tu-dortmund.de>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
Message-ID: <CAP01uR=OnxFTMDtzLdWbWF=kRtSaZ_Rt5FQDDtbBrEv518BocA@mail.gmail.com>

On Thu, Aug 22, 2013 at 6:41 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 23.08.2013 00:36, Brian Lee Yung Rowe wrote:
>>
>> You raise an interesting point that I've mulled over a bit: namespace
>> collisions. How many of these issues would go away if there were a better
>> mechanism for managing namespaces? eg in other languages you can control
>> which objects/modules you wish to import from a library. Under this regime I
>> think package developers would be less concerned about exposing functions
>> that otherwise would be private.
>
>
>
> Exactly, the corresponding NAMESPACE directive is
>
> importFrom()
>
> and it should be used.
>
>
>
>> On Aug 22, 2013, at 6:27 PM, Gabor Grothendieck <ggrothendieck at gmail.com>
>> wrote:
>>
>>> If ::: is disallowed then its likely that package developers will need
>>> to export more functions to satisfy the consumers of those otherwise
>>> hidden functions but if more functions are exported then there
>>> will be a greater likelihood of conflicts among packages.
>>>
>>> The problem seems to be that there are potentially three sorts of
>>> functions here:
>>>
>>> 1. a function is hidden
>>> 2. a function is accessible via ::: but is not on the search path
>>> 3. a function is on the search path
>>
>>
>
> Not entirely right:
>
> If the package or only parts of it are imported via importFrom by another
> package, the package is not loaded, hence not on the search path.

OK but it is still true that under the new rules to use importFrom(B,
f) in package A
that f must be exported by B.  That implies that f could cause a
conflict when B is
placed on the search path via library(B) by some other package
(package C) or by the user.

f is either exported by B or not.  If f is exported by B then f will
be placed on
the search path whenever B is placed on the search path and if f is
not exported then A can't import it.  That is there is no way for B to
declare a function to be importable by another package without having that
function also placed on the search path whenever B is loaded by a library(B)l or
a Depends: B from another package.




on the search path


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From gmbecker at ucdavis.edu  Fri Aug 23 01:57:09 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 22 Aug 2013 16:57:09 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAP01uR=OnxFTMDtzLdWbWF=kRtSaZ_Rt5FQDDtbBrEv518BocA@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAP01uR=OnxFTMDtzLdWbWF=kRtSaZ_Rt5FQDDtbBrEv518BocA@mail.gmail.com>
Message-ID: <CADwqtCMODUev9SktUmZx_h49XUVFxRJmmdpkDXJThgyEP=gscQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/43ec0ca6/attachment.pl>

From peter.meilstrup at gmail.com  Fri Aug 23 02:01:38 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 22 Aug 2013 17:01:38 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <521693A6.5030407@statistik.tu-dortmund.de>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
Message-ID: <CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/b9628bc4/attachment.pl>

From ggrothendieck at gmail.com  Fri Aug 23 02:19:45 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Aug 2013 20:19:45 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CADwqtCMODUev9SktUmZx_h49XUVFxRJmmdpkDXJThgyEP=gscQ@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAP01uR=OnxFTMDtzLdWbWF=kRtSaZ_Rt5FQDDtbBrEv518BocA@mail.gmail.com>
	<CADwqtCMODUev9SktUmZx_h49XUVFxRJmmdpkDXJThgyEP=gscQ@mail.gmail.com>
Message-ID: <CAP01uRm_KpvVqLEBQVzNYWKhQSzHWv76HPM4Y=CwT13wgGuuZw@mail.gmail.com>

On Thu, Aug 22, 2013 at 7:57 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> My understanding is that lookup happens in the imports before moving on to
> the search path,  so if I understand you correctly I don't think that is an
> issue. If A also *exported* f, that would be a problem...
>

A can only import f from B if f has been exported from B so while its
not a problem for A, whenever anyone issues a library(B) f will be
visible on the
search path -- the problem of potential conflicts with f remains.

B really only exported f so that A could import it but a side effect
of that is that
anyone who puts B on the search path makes f visible.


From gmbecker at ucdavis.edu  Fri Aug 23 02:23:11 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 22 Aug 2013 17:23:11 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAP01uRm_KpvVqLEBQVzNYWKhQSzHWv76HPM4Y=CwT13wgGuuZw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAP01uR=OnxFTMDtzLdWbWF=kRtSaZ_Rt5FQDDtbBrEv518BocA@mail.gmail.com>
	<CADwqtCMODUev9SktUmZx_h49XUVFxRJmmdpkDXJThgyEP=gscQ@mail.gmail.com>
	<CAP01uRm_KpvVqLEBQVzNYWKhQSzHWv76HPM4Y=CwT13wgGuuZw@mail.gmail.com>
Message-ID: <CADwqtCNj2pnPuDEYiKLONUdfYuQsKJQiNHtwDPrTDANneFwGDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/629ed8f8/attachment.pl>

From peter.meilstrup at gmail.com  Fri Aug 23 02:27:27 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 22 Aug 2013 17:27:27 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
Message-ID: <CAJoaRhamc8VRm2DYAKCzQUJA7DO4ypwvP6w_XkDWmCFOAwMDgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/81fa43bf/attachment.pl>

From rowe at muxspace.com  Fri Aug 23 02:37:23 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Thu, 22 Aug 2013 20:37:23 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
Message-ID: <6BEDBBD2-D3A3-4271-8376-2A20199D73EA@muxspace.com>

This is what I was getting at as well. It would be great to have a call like

require(package, c('funtion.1','function.2')) 

or similar that gives users granular control over what gets imported in the shell. I would be drunk with joy if the same mechanism could be used to automatically populate the package directives.


On Aug 22, 2013, at 8:01 PM, Peter Meilstrup <peter.meilstrup at gmail.com> wrote:

> It would be nice if the functionality of importFrom() and import() were
> available to user level code, rather than just to people building packages
> for distribution. One most often encounters namespace conflicts at the user
> level, when loading two packages that have no logical connection other than
> both bearing on your problem of the moment.
> 
> R conflates "having namespaces" with "having a library distribution
> mechanism" and while its library distribution mechanism is top notch, most
> modern languages do not require you to learn the distribution procedure in
> order to just have namespaces.
> 
> For instance, in Python you merely put code in a file called foo.py and
> then in any other file in the same directory you type "import functionName
> from foo". I.E. using namespaces does not require you to build/install
> packages. Python namespaces are also hierarchical so that the question of
> this thread would easily be resolved by putting functions into
> foo._internal and in other packages typing import * from "foo._internal"
> 
> Peter
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gray at clhn.co  Fri Aug 23 02:41:58 2013
From: gray at clhn.co (Gray)
Date: Thu, 22 Aug 2013 19:41:58 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
Message-ID: <20130823004158.GA14224@gray-ThinkPad-X200-Tablet>

Peter Meilstrup: (05:01PM on Thu, Aug 22)
>One most often encounters namespace conflicts at the user level, when
>loading two packages that have no logical connection other than both
>bearing on your problem of the moment.

Unless I'm mistaken, you can reassign the hidden functions, ie

fna <- joespackage:::usefulfunction

fnb <- janespackage:::usefulfunction

which is a little bit of a pain, but makes the user's code
unambiguous.  This also works with two colons for explicitly exported
functions.

-- 
Gray Calhoun, Assistant Professor of Economics at Iowa State 
http://gray.clhn.co (web)


From jfox at mcmaster.ca  Fri Aug 23 03:54:26 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 22 Aug 2013 21:54:26 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
Message-ID: <web-470792921@cgpsrv2.cis.mcmaster.ca>

Dear Gray,

On Thu, 22 Aug 2013 19:41:58 -0500
 Gray <gray at clhn.co> wrote:
> Peter Meilstrup: (05:01PM on Thu, Aug 22)
> >One most often encounters namespace conflicts at the user level, when
> >loading two packages that have no logical connection other than both
> >bearing on your problem of the moment.
> 
> Unless I'm mistaken, you can reassign the hidden functions, ie
> 
> fna <- joespackage:::usefulfunction
> 
> fnb <- janespackage:::usefulfunction
> 

This will now generate a note from R CMD check and an objection from the CRAN administrators.

Best,
 John

> which is a little bit of a pain, but makes the user's code
> unambiguous.  This also works with two colons for explicitly exported
> functions.
> 
> -- 
> Gray Calhoun, Assistant Professor of Economics at Iowa State http://gray.clhn.co (web)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gmbecker at ucdavis.edu  Fri Aug 23 04:02:55 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 22 Aug 2013 19:02:55 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
Message-ID: <CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130822/a10129e8/attachment.pl>

From xie at yihui.name  Fri Aug 23 05:54:47 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 22 Aug 2013 22:54:47 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
	<CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>
Message-ID: <CANROs4eF6TqTpzTyP0nXPWXjR_1O4SG_Vev+yD5oTcYpyc_5CA@mail.gmail.com>

Maybe it is not a good idea for R CMD check to check ::: at all, and a
warning in R-exts and ?':::' may well be enough. On the other hand, it
is just so easy to get around :::, because everybody can see its
source code:

> `:::`
function (pkg, name)
{
    pkg <- as.character(substitute(pkg))
    name <- as.character(substitute(name))
    get(name, envir = asNamespace(pkg), inherits = FALSE)
}

Then the package authors who really want to take the risk may start
another "hide and seek" game, e.g.

`%:::%` = function(pkg, fun) get(fun, envir = asNamespace(pkg),
inherits = FALSE)
'stats' %:::% 'Pillai'

Non-exported functions do not necessarily imply instability. Maybe it
is just because the author is too lazy to document them, or he/she did
not realize these functions happen to be useful for another author.

Although R-devel does not warn against ::: on the packages of the same
maintainer now, these maintainers may change in the future, or one
maintainer can be an author but not maintainer of another package,
from which he/she imports an unexported function, or package authors
have coordinated well with each other about the unexported functions.
I believe there are other legitimate reasons for :::, which might make
it difficult for R to cover all these cases, and also bring additional
communications between package authors and CRAN.

In conclusion, R CMD check cannot really stop :::, and ::: can be
there for good reasons, so how about just let it go?

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
102 Snedecor Hall, Ames, IA


On Thu, Aug 22, 2013 at 9:02 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Hey guys,
>
> Because I was curious and had nothing else that I should have been doing
> (that second part is a lie), I looked into the namespace code.
>
> I have a working patch that implements importHiddenFrom. It doesn't
> currently check whether you then export that symbol (which should not be
> allowed) but that would be easy to implement.
>
> Is there any desire from R-core to have add the importHiddenFrom
> functionality? If so I can add the export check and submit the patch either
> here or on bugzilla. I figure its a long shot but hey, at least I now know
> how the namespace stuff works.
>
> I do agree with Peter Meilstrup that poking around at the internals of
> someone else's code is often not a good idea, but as others have pointed
> out it is done in practice in some fairly high-profile packages, and if its
> going to happen it seems like it would be nice to indicate as much in the
> NAMESPACE file.
>
> ~G
>
>
> On Thu, Aug 22, 2013 at 5:41 PM, Gray <gray at clhn.co> wrote:
>
>> Peter Meilstrup: (05:01PM on Thu, Aug 22)
>>
>>  One most often encounters namespace conflicts at the user level, when
>>> loading two packages that have no logical connection other than both
>>> bearing on your problem of the moment.
>>>
>>
>> Unless I'm mistaken, you can reassign the hidden functions, ie
>>
>> fna <- joespackage:::usefulfunction
>>
>> fnb <- janespackage:::usefulfunction
>>
>> which is a little bit of a pain, but makes the user's code
>> unambiguous.  This also works with two colons for explicitly exported
>> functions.
>>
>> --
>> Gray Calhoun, Assistant Professor of Economics at Iowa State
>> http://gray.clhn.co (web)


From milbo at sonic.net  Fri Aug 23 12:32:47 2013
From: milbo at sonic.net (Stephen Milborrow)
Date: Fri, 23 Aug 2013 11:32:47 +0100
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com><5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
Message-ID: <9CC287024D6F4C628EDB5E6CA39EA565@Studio17>

>> To avoid the NOTEs (which often triggers a 'pls fix' upon submission to
>> CRAN), I simply copied/pasted these functions to my package, but this
>> seems wasteful.

An issue is how one acknowledges the author of the cut and pasted code.

Assume that for one reason or another the original function can't easily be
made available via NAMESPACEs and so to avoid CRAN submission complaints you
are forced into cut and copying.  If the copied code is somewhat substantial
a short acknowledgment on a man page is insufficient.  As far as I know the
only alternative to list the author of the copied code in the Author field
of your DESCRIPTION file.  This makes the Author field ungainly (especially
if the copied-from package has itself a lengthy Author field) and gives
disproportionate credit to the author of the copied code over those in
Depends.

It would be good if there was a better mechanism in the DESCRIPTION file for
acknowledging authors you copied code from.  Tricky,  lots of grey areas.
On balance I think I'm in the camp of those who say ::: should allowed.


From ucfagls at gmail.com  Fri Aug 23 17:15:09 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 23 Aug 2013 09:15:09 -0600
Subject: [Rd] Accessing the formals() of a non-exported method without :::?
Message-ID: <CAAHES9yLLQ3F_K5ws4x3d-gq-eSWL=mQfcbOqgQKkqTpH_vNgw@mail.gmail.com>

Dear List,

I'm in the process of making tweaks to my various R packages following
changes in r-devel for package checks. I'm wondering about the one use
of ::: in one of my packages. I am arranging for a call to a
non-exported S3 method via do.call. For this I need the arguments of
the function and hence I was doing

    Args <- head(formals(analogue:::wa.default), -1)

Following the recent thread on legitimate uses of ::: I think the
above is both acceptable and won't generate a Note now with R CMD
check following a recent change to that code. But is there a better
way to get the formal arguments of a non-exported S3 method?

Thanks.

G

-- 
Gavin Simpson


From michael.weylandt at gmail.com  Fri Aug 23 17:27:16 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Fri, 23 Aug 2013 11:27:16 -0400
Subject: [Rd] Accessing the formals() of a non-exported method without
	:::?
In-Reply-To: <CAAHES9yLLQ3F_K5ws4x3d-gq-eSWL=mQfcbOqgQKkqTpH_vNgw@mail.gmail.com>
References: <CAAHES9yLLQ3F_K5ws4x3d-gq-eSWL=mQfcbOqgQKkqTpH_vNgw@mail.gmail.com>
Message-ID: <CE3B5F3F-0589-4A35-A9D3-6F424695661E@gmail.com>



On Aug 23, 2013, at 11:15, Gavin Simpson <ucfagls at gmail.com> wrote:

> Dear List,
> 
> I'm in the process of making tweaks to my various R packages following
> changes in r-devel for package checks. I'm wondering about the one use
> of ::: in one of my packages. I am arranging for a call to a
> non-exported S3 method via do.call. For this I need the arguments of
> the function and hence I was doing
> 
>    Args <- head(formals(analogue:::wa.default), -1)
> 
> Following the recent thread on legitimate uses of ::: I think the
> above is both acceptable and won't generate a Note now with R CMD
> check following a recent change to that code. But is there a better
> way to get the formal arguments of a non-exported S3 method?
> 

Something like (untested)

formalsS3 <- function(...) formals(getS3method(...))

might work. I haven't checked to see how R CMD check feels about getS3method() though. 

Michael


> Thanks.
> 
> G
> 
> -- 
> Gavin Simpson
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From friendly at yorku.ca  Fri Aug 23 22:24:40 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 23 Aug 2013 16:24:40 -0400
Subject: [Rd] packages with Sweave and knitr vignettes?
Message-ID: <5217C508.8050004@yorku.ca>

Now that R 3.0.0+ supports non-Sweave vignettes, R-exts \S 1.4.2 seems 
to imply that
it is possible to include both Sweave and knitr vignettes in a single 
package.

I'm wondering
if anyone has tried this and/or if there are some hidden gotchas putting 
this into practice,
and concerned about creating problems with CRAN checks if I try this.

Consider two vignettes:

pkg/vignettes/vign1.Rnw, containing:
% !Rnw weave = Sweave
%\VignetteEngine{Sweave}
...

pkg/vignettes/vign2.Rnw, containing:
% !Rnw weave = knitr
%\VignetteEngine{knitr::knitr}
...

both are .Rnw files, distinguished only by \VignetteEngine. vign1.Rnw is 
currently in my
package, and vign2.Rnw compiles OK outside it, using knitr in an R 
console or RStudio.

R-exts implies that the DESCRIPTION file must include (minimally):

VignetteBuilder: Sweave, knitr
Suggests: knitr

Is anything more/different required?  Does a package exist that does this?

TIA
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From dtenenba at fhcrc.org  Fri Aug 23 22:40:19 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 23 Aug 2013 13:40:19 -0700
Subject: [Rd] packages with Sweave and knitr vignettes?
In-Reply-To: <5217C508.8050004@yorku.ca>
References: <5217C508.8050004@yorku.ca>
Message-ID: <CAF42j22OZftA+A3xKrvV8exnYeTsTVUCuz0Yn3d+kwET_2z-SQ@mail.gmail.com>

On Fri, Aug 23, 2013 at 1:24 PM, Michael Friendly <friendly at yorku.ca> wrote:
> Now that R 3.0.0+ supports non-Sweave vignettes, R-exts \S 1.4.2 seems to
> imply that
> it is possible to include both Sweave and knitr vignettes in a single
> package.
>
> I'm wondering
> if anyone has tried this and/or if there are some hidden gotchas putting
> this into practice,
> and concerned about creating problems with CRAN checks if I try this.
>

You could easily find out. Add vign2.Rnw to your package, build it, then run
R CMD check --as-cran mypkg_.0.0.1.tar.gz

Dam


> Consider two vignettes:
>
> pkg/vignettes/vign1.Rnw, containing:
> % !Rnw weave = Sweave
> %\VignetteEngine{Sweave}
> ...
>
> pkg/vignettes/vign2.Rnw, containing:
> % !Rnw weave = knitr
> %\VignetteEngine{knitr::knitr}
> ...
>
> both are .Rnw files, distinguished only by \VignetteEngine. vign1.Rnw is
> currently in my
> package, and vign2.Rnw compiles OK outside it, using knitr in an R console
> or RStudio.
>
> R-exts implies that the DESCRIPTION file must include (minimally):
>
> VignetteBuilder: Sweave, knitr
> Suggests: knitr
>
> Is anything more/different required?  Does a package exist that does this?
>
> TIA
> -Michael
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Aug 23 23:49:17 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 23 Aug 2013 14:49:17 -0700
Subject: [Rd] packages with Sweave and knitr vignettes?
In-Reply-To: <5217C508.8050004@yorku.ca>
References: <5217C508.8050004@yorku.ca>
Message-ID: <CAFDcVCTdyhe9dZ+LL5kHJ+5V-ZhKBJM171APoEEvDM08hC13bg@mail.gmail.com>

On Fri, Aug 23, 2013 at 1:24 PM, Michael Friendly <friendly at yorku.ca> wrote:
> Now that R 3.0.0+ supports non-Sweave vignettes, R-exts \S 1.4.2 seems to
> imply that
> it is possible to include both Sweave and knitr vignettes in a single
> package.
>
> I'm wondering
> if anyone has tried this and/or if there are some hidden gotchas putting
> this into practice,
> and concerned about creating problems with CRAN checks if I try this.
>
> Consider two vignettes:
>
> pkg/vignettes/vign1.Rnw, containing:
> % !Rnw weave = Sweave
> %\VignetteEngine{Sweave}
> ...
>
> pkg/vignettes/vign2.Rnw, containing:
> % !Rnw weave = knitr
> %\VignetteEngine{knitr::knitr}
> ...
>
> both are .Rnw files, distinguished only by \VignetteEngine. vign1.Rnw is
> currently in my
> package, and vign2.Rnw compiles OK outside it, using knitr in an R console
> or RStudio.
>
> R-exts implies that the DESCRIPTION file must include (minimally):
>
> VignetteBuilder: Sweave, knitr
> Suggests: knitr

The vignette-builder package for Sweave is 'utils' (not Sweave), so you want:

VignetteBuilder: utils, knitr

However, as said in 'Writing R Extensions', "The utils package is
always implicitly appended to the list of builder packages.", so you
don't really need to add it, but personally I'd say it's a nice
gesture to make it explicit which vignette-builder package you are
using.

Also, the full formal engine name for Sweave is utils::Sweave, so for
complete parallelism with knitr::knitr, you could be explicit and
write \VignetteEngine{utils::Sweave}.

/Henrik

>
> Is anything more/different required?  Does a package exist that does this?
>
> TIA
> -Michael
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ross at biostat.ucsf.edu  Sat Aug 24 01:53:35 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 23 Aug 2013 16:53:35 -0700
Subject: [Rd] Makevars and Makeconf sequencing
Message-ID: <1377302015.1062.38.camel@localhost>

http://cran.r-project.org/doc/manuals/R-exts.html#Configure-and-cleanup
near the start of 1.2.1 Using Makevars says

> There are some macros which are set whilst configuring the building of
> R itself and are stored in R_HOME/etcR_ARCH/Makeconf. That makefile is
> included as a Makefile after Makevars[.win], and the macros it defines
> can be used in macro assignments and make command lines in the latter.
> 
I'm confused.  If Makeconf is included after Makevars, then how can
Makevars use macros defined in Makeconf?

Or is the meaning only that a variable definition in Makeconf can be
overridden in Makevars?

Ross Boylan


From simon.urbanek at r-project.org  Sat Aug 24 02:22:53 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 23 Aug 2013 20:22:53 -0400
Subject: [Rd] Makevars and Makeconf sequencing
In-Reply-To: <1377302015.1062.38.camel@localhost>
References: <1377302015.1062.38.camel@localhost>
Message-ID: <3095AF57-EC53-4F58-BEF6-E2EAB87741F6@r-project.org>


On Aug 23, 2013, at 7:53 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:

> http://cran.r-project.org/doc/manuals/R-exts.html#Configure-and-cleanup
> near the start of 1.2.1 Using Makevars says
> 
>> There are some macros which are set whilst configuring the building of
>> R itself and are stored in R_HOME/etcR_ARCH/Makeconf. That makefile is
>> included as a Makefile after Makevars[.win], and the macros it defines
>> can be used in macro assignments and make command lines in the latter.
>> 
> I'm confused.  If Makeconf is included after Makevars, then how can
> Makevars use macros defined in Makeconf?
> 

Because regular (recursively expanded) variables in makefiles are evaluated lazily (i.e., when substituted).


> Or is the meaning only that a variable definition in Makeconf can be
> overridden in Makevars?
> 
> Ross Boylan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From xie at yihui.name  Sat Aug 24 05:20:59 2013
From: xie at yihui.name (Yihui Xie)
Date: Fri, 23 Aug 2013 22:20:59 -0500
Subject: [Rd] packages with Sweave and knitr vignettes?
In-Reply-To: <CAFDcVCTdyhe9dZ+LL5kHJ+5V-ZhKBJM171APoEEvDM08hC13bg@mail.gmail.com>
References: <5217C508.8050004@yorku.ca>
	<CAFDcVCTdyhe9dZ+LL5kHJ+5V-ZhKBJM171APoEEvDM08hC13bg@mail.gmail.com>
Message-ID: <CANROs4cvyt+wQn6CWmx=8+focY5M0RCup4d27sGiMD_Z2yxi6g@mail.gmail.com>

Note there is a bug in R-release, and its consequence is that you
cannot use two different weave engines on two documents of the same
file extension.  In your case, you cannot use both knitr and Sweave on
two .Rnw documents. I just checked R-devel, and it has not been fixed
yet. If you do not have a good reason to use both engines, you can
just choose one of them.

Other than that, I think the non-Sweave vignettes are in a pretty good
state now.

You can check the Reverse Suggests on CRAN:
http://cran.r-project.org/package=knitr Most of them suggested knitr
for vignette building purposes, and knitr itself also uses knitr to
build LaTeX, HTML, and Markdown vignettes.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
102 Snedecor Hall, Ames, IA


On Fri, Aug 23, 2013 at 4:49 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Fri, Aug 23, 2013 at 1:24 PM, Michael Friendly <friendly at yorku.ca> wrote:
>> Now that R 3.0.0+ supports non-Sweave vignettes, R-exts \S 1.4.2 seems to
>> imply that
>> it is possible to include both Sweave and knitr vignettes in a single
>> package.
>>
>> I'm wondering
>> if anyone has tried this and/or if there are some hidden gotchas putting
>> this into practice,
>> and concerned about creating problems with CRAN checks if I try this.
>>
>> Consider two vignettes:
>>
>> pkg/vignettes/vign1.Rnw, containing:
>> % !Rnw weave = Sweave
>> %\VignetteEngine{Sweave}
>> ...
>>
>> pkg/vignettes/vign2.Rnw, containing:
>> % !Rnw weave = knitr
>> %\VignetteEngine{knitr::knitr}
>> ...
>>
>> both are .Rnw files, distinguished only by \VignetteEngine. vign1.Rnw is
>> currently in my
>> package, and vign2.Rnw compiles OK outside it, using knitr in an R console
>> or RStudio.
>>
>> R-exts implies that the DESCRIPTION file must include (minimally):
>>
>> VignetteBuilder: Sweave, knitr
>> Suggests: knitr
>
> The vignette-builder package for Sweave is 'utils' (not Sweave), so you want:
>
> VignetteBuilder: utils, knitr
>
> However, as said in 'Writing R Extensions', "The utils package is
> always implicitly appended to the list of builder packages.", so you
> don't really need to add it, but personally I'd say it's a nice
> gesture to make it explicit which vignette-builder package you are
> using.
>
> Also, the full formal engine name for Sweave is utils::Sweave, so for
> complete parallelism with knitr::knitr, you could be explicit and
> write \VignetteEngine{utils::Sweave}.
>
> /Henrik
>
>>
>> Is anything more/different required?  Does a package exist that does this?
>>
>> TIA
>> -Michael
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA


From ucfagls at gmail.com  Sat Aug 24 05:49:49 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 23 Aug 2013 21:49:49 -0600
Subject: [Rd] Accessing the formals() of a non-exported method without
	:::?
In-Reply-To: <CE3B5F3F-0589-4A35-A9D3-6F424695661E@gmail.com>
References: <CAAHES9yLLQ3F_K5ws4x3d-gq-eSWL=mQfcbOqgQKkqTpH_vNgw@mail.gmail.com>
	<CE3B5F3F-0589-4A35-A9D3-6F424695661E@gmail.com>
Message-ID: <CAAHES9xZCRozYV-n0Fg8n2wbE4QfWUzGkLycsbBnyAGARZC2Gw@mail.gmail.com>

Thanks Michael, somewhat embarrassingly, I had forgotten that a
package can refer to any of *its own packages*. So I don't need
analogue:::foo.bar as that is being called from a function in the
analogue namespace.

Cheers,

G

On 23 August 2013 09:27, R. Michael Weylandt
<michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>
>
> On Aug 23, 2013, at 11:15, Gavin Simpson <ucfagls at gmail.com> wrote:
>
>> Dear List,
>>
>> I'm in the process of making tweaks to my various R packages following
>> changes in r-devel for package checks. I'm wondering about the one use
>> of ::: in one of my packages. I am arranging for a call to a
>> non-exported S3 method via do.call. For this I need the arguments of
>> the function and hence I was doing
>>
>>    Args <- head(formals(analogue:::wa.default), -1)
>>
>> Following the recent thread on legitimate uses of ::: I think the
>> above is both acceptable and won't generate a Note now with R CMD
>> check following a recent change to that code. But is there a better
>> way to get the formal arguments of a non-exported S3 method?
>>
>
> Something like (untested)
>
> formalsS3 <- function(...) formals(getS3method(...))
>
> might work. I haven't checked to see how R CMD check feels about getS3method() though.
>
> Michael
>
>
>> Thanks.
>>
>> G
>>
>> --
>> Gavin Simpson
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Gavin Simpson, PhD


From ucfagls at gmail.com  Sat Aug 24 06:01:16 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 23 Aug 2013 22:01:16 -0600
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
Message-ID: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>

Dear List,

In one of my packages I have an S3 method for the plot3d generic
function from package rgl. I am trying to streamline my Depends
entries but don't know how to have

plot3d(foo)

in the examples section for the plot3d method in my package, without
rgl being in Depends.

Note that I importFrom(rgl, plotd3d) and register my S3 method via
S3Method() in the NAMESPACE.

If rgl is not in Depends but in Imports, I see this when checking the package

> ## 3D plot of data with curve superimposed
> plot3d(aber.pc, abernethy2)
Error: could not find function "plot3d"

I presume this is because rgl's namespace is only loaded but the
package is not attached to the search path.

Writing R extensions indicates that one can export from a namespace
something that was imported from another package namespace. I thought
that might help the situation, and now the code doesn't raise an
error, I get

* checking for missing documentation entries ... WARNING
Undocumented code objects:
  ?plot3d?
All user-level objects in a package should have documentation entries.
See the chapter ?Writing R documentation files? in the ?Writing R
Extensions? manual.

as I don't document plot3d() itself.

What is the recommended combination of Depends and Imports plus
NAMESPACE directives etc that one should use in this situation? Or am
I missing something else?

I have a similar issue with my package including an S3 method for a
generic in the lattice package, so if possible I could get rid of both
of these from Depends if I can solve the above issue.

Thanks in advance.

Gavin

-- 
Gavin Simpson


From ucfagls at gmail.com  Sat Aug 24 06:05:51 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 23 Aug 2013 22:05:51 -0600
Subject: [Rd] Accessing the formals() of a non-exported method without
	:::?
In-Reply-To: <CAAHES9xZCRozYV-n0Fg8n2wbE4QfWUzGkLycsbBnyAGARZC2Gw@mail.gmail.com>
References: <CAAHES9yLLQ3F_K5ws4x3d-gq-eSWL=mQfcbOqgQKkqTpH_vNgw@mail.gmail.com>
	<CE3B5F3F-0589-4A35-A9D3-6F424695661E@gmail.com>
	<CAAHES9xZCRozYV-n0Fg8n2wbE4QfWUzGkLycsbBnyAGARZC2Gw@mail.gmail.com>
Message-ID: <CAAHES9xD2f7bSYiXppAceAJYXAm+nd1ito6QQWYeADtFW+EHFA@mail.gmail.com>

By

"...I had forgotten that a package can refer to any of *its own packages*"

I of course meant

"...I had forgotten that a package can refer to any of *its own functions*"

Guess I should call it a night...

G

On 23 August 2013 21:49, Gavin Simpson <ucfagls at gmail.com> wrote:
> Thanks Michael, somewhat embarrassingly, I had forgotten that a
> package can refer to any of *its own packages*. So I don't need
> analogue:::foo.bar as that is being called from a function in the
> analogue namespace.
>
> Cheers,
>
> G
>
> On 23 August 2013 09:27, R. Michael Weylandt
> <michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>>
>>
>> On Aug 23, 2013, at 11:15, Gavin Simpson <ucfagls at gmail.com> wrote:
>>
>>> Dear List,
>>>
>>> I'm in the process of making tweaks to my various R packages following
>>> changes in r-devel for package checks. I'm wondering about the one use
>>> of ::: in one of my packages. I am arranging for a call to a
>>> non-exported S3 method via do.call. For this I need the arguments of
>>> the function and hence I was doing
>>>
>>>    Args <- head(formals(analogue:::wa.default), -1)
>>>
>>> Following the recent thread on legitimate uses of ::: I think the
>>> above is both acceptable and won't generate a Note now with R CMD
>>> check following a recent change to that code. But is there a better
>>> way to get the formal arguments of a non-exported S3 method?
>>>
>>
>> Something like (untested)
>>
>> formalsS3 <- function(...) formals(getS3method(...))
>>
>> might work. I haven't checked to see how R CMD check feels about getS3method() though.
>>
>> Michael
>>
>>
>>> Thanks.
>>>
>>> G
>>>
>>> --
>>> Gavin Simpson
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Gavin Simpson, PhD



-- 
Gavin Simpson, PhD


From kasperdanielhansen at gmail.com  Sat Aug 24 18:46:37 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Sat, 24 Aug 2013 12:46:37 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAJoaRhamc8VRm2DYAKCzQUJA7DO4ypwvP6w_XkDWmCFOAwMDgg@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
	<CAJoaRhamc8VRm2DYAKCzQUJA7DO4ypwvP6w_XkDWmCFOAwMDgg@mail.gmail.com>
Message-ID: <CAC2h7us=Duy3L8N5H--hfyOx__-Yp+uiYxV7YY6eK==Tisw1Gg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130824/d51fe8c2/attachment.pl>

From bbolker at gmail.com  Sun Aug 25 04:40:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 24 Aug 2013 22:40:41 -0400
Subject: [Rd] model.frame(), model.matrix(),
	and derived predictor variables
In-Reply-To: <520FA2AE.7030109@gmail.com>
References: <520FA2AE.7030109@gmail.com>
Message-ID: <52196EA9.3070302@gmail.com>


  Bump: just trying one more time to see if anyone had thoughts on this
(so far it's just <crickets> ...)


-------- Original Message --------
Subject: model.frame(), model.matrix(), and derived predictor variables
Date: Sat, 17 Aug 2013 12:19:58 -0400
From: Ben Bolker <bbolker at gmail.com>
To: R-devel at stat.math.ethz.ch <R-devel at stat.math.ethz.ch>


  Dear r-developers:

  I am struggling with some fundamental aspects of model.frame().

  Conceptually, I think of a flow from data -> model.frame() ->
model.matrix; the data contain _input variables_, while model.matrix
contains _predictor variables_: data have been transformed, splines and
polynomials have been expanded into their corresponding
multi-dimensional bases, and factors have been expanded into appropriate
sets of dummy variables depending on their contrasts.
  I originally thought of model.frame() as containing input variables as
well (but with only the variables needed by the model, and with cases
containing NAs handled according to the relevant na.action setting), but
that's not quite true.  While factors are retained as-is, splines and
polynomials and parameter transformations are evaluated. For example

d <- data.frame(x=1:10,y=1:10)
model.frame(y~log(x),d)

produces a model frame with columns 'y', 'log(x)' (not 'y', 'x').

This makes it hard (impossible?) to use the model frame to re-evaluate
the existing formula in a model, e.g.

m <- lm(y~log(x),d)
update(m,data=model.frame(m))
## Error in eval(expr, envir, enclos) : object 'x' not found

It seems to me that this is a reasonable thing to want to do
(i.e. use the model frame as a stored copy of the data that
 can be used for additional model operations); otherwise, I
either need to carry along an additional copy of the data in
a slot, or hope that the model is still living in an environment
where it can find a copy of the original data.

Does anyone have any insights into the original design choices,
or suggestions about how they have handled this within their own
code? Do you just add an additional data slot to the model?  I've
considered trying to write some kind of 'augmented' model frame, that
would contain the equivalent of
setdiff(all.vars(formula),model.frame(m)) [i.e.  all input variables
that appeared in the formula but not in the model frame ...].

  thanks
   Ben Bolker


From bt_jannis at yahoo.de  Wed Aug 21 16:34:22 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Wed, 21 Aug 2013 16:34:22 +0200
Subject: [Rd] cyclic namespace dependency detected when loading ...
Message-ID: <5214CFEE.2000809@yahoo.de>

Hi R users,


I am developing two packages. Each package uses some functions from the 
other package. Now when I define these dependencies in the NAMESPACE 
file (via importFrom(XXXX,function1,....)), i get this error (when 
building one package):

cyclic namespace dependency detected when loading 'XXXXXX', already 
loading ?YYYYYYY?, ?XXXXXXXXX?

Is there any way to prevent this error? Shouldn't this case be allowed 
in some way? Or can package dependencies only be in one direction?


Thanks
Jannis


From SheltonS at stemcell.ucsf.edu  Wed Aug 21 17:17:55 2013
From: SheltonS at stemcell.ucsf.edu (Shelton, Samuel)
Date: Wed, 21 Aug 2013 15:17:55 +0000
Subject: [Rd] Problem with R >3.0.0
In-Reply-To: <E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
References: <CE38EC7A.1872F%sheltons@stemcell.ucsf.edu>,
	<E7CFD001-DE7D-4534-B1A2-8C5E1F5613BB@gmail.com>
Message-ID: <8A011F8D-BFB0-45A5-85DC-8B6DB1A0BF6B@stemcell.ucsf.edu>

Thanks for looking into this for me.

I made a mistake with the version of Osx I was using it is actually 10.8.4 mountain lion. Interestingly it was doing the same on this particular iMac with snow leopard and that was the reason that I upgraded it to mountain lion. I found the same problem with v3.0.0 and with 3.0.1 both with snow leopard and mountain lion.  2.15.2 which is the same verion that we use on our cluster did not give this behaviour on either snow leopard or mountain lion.

Please let me know if you want me to do any more testing as I have access to machines with lots of ram.

Sam

Sent from my iPad

On Aug 21, 2013, at 5:46 AM, "peter dalgaard" <pdalgd at gmail.com> wrote:

> 
> On Aug 20, 2013, at 19:42 , Shelton, Samuel wrote:
> 
>> Hi all,
>> 
>> Thanks for getting back to me. We would like to move over to v3.0.0 on our
>> cluster so that we can build matrices larger than 46300*46300 (limit in R
>> <3.0.0)
>> but so far we can't get things to work with R v3.0.0 and higher. I am
>> trying to trouble shoot at the moment and I am now thinking that the
>> problem is actually with the diag function that has been rewritten in
>> version 3.0.0. 
>> 
>> 
>> The problem is definitely with the diag function and it does not occur on
>> smaller matrices (20000*20000) and I think it maybe a bug.
>> This illustrates the problem:
>> 
>> This was done on an iMac i5 with OSX 10.8.5 16GB Ram and with R 3.0.1 (but
>> I do see the same for 3.0.0). This does not occur when I run it with R
>> 2.15.2. 
>> 
> 
> 
> Thanks. I can condense this to 
> 
>> M <- matrix(1,23170,23170) ; diag(M) <- 0 ; range(colSums(M))
> [1] 23169 23169
>> M <- matrix(1,23171,23171) ; diag(M) <- 0 ; range(colSums(M))
> [1]     0 23170
> 
> and the fact that 2^14.5 is 23170.48 is not likely to be a coincidence...
> 
> It is only happening with some of my builds, though. In particular, my MacPorts build of 3.0.1 does not have the problem on Snow Leopard, nor does the CRAN build of 3.0.0, still on Snow Leopard. It takes forever to check on a 4GB machine....
> 
> -- 
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 


From ligges at statistik.tu-dortmund.de  Sun Aug 25 16:18:05 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 25 Aug 2013 16:18:05 +0200
Subject: [Rd] cyclic namespace dependency detected when loading ...
In-Reply-To: <5214CFEE.2000809@yahoo.de>
References: <5214CFEE.2000809@yahoo.de>
Message-ID: <521A121D.2050209@statistik.tu-dortmund.de>



On 21.08.2013 16:34, Jannis wrote:
> Hi R users,
>
>
> I am developing two packages. Each package uses some functions from the
> other package. Now when I define these dependencies in the NAMESPACE
> file (via importFrom(XXXX,function1,....)), i get this error (when
> building one package):
>
> cyclic namespace dependency detected when loading 'XXXXXX', already
> loading ?YYYYYYY?, ?XXXXXXXXX?
>
> Is there any way to prevent this error? Shouldn't this case be allowed
> in some way? Or can package dependencies only be in one direction?

Imports only in one direction: Package A has to be installed before 
package B and package B before package A now. The hen and the egg...

Best,
Uwe Ligges


>
>
> Thanks
> Jannis
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Sun Aug 25 16:29:29 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 25 Aug 2013 09:29:29 -0500
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
Message-ID: <CABdHhvG4tWCg1n86mOY5Qd3s_xcmzJ+KsH0npRGoWDnQ4OrEHA@mail.gmail.com>

What I do, which is probably wrong, but at least it works, is export
the s3 method as a function. i.e. instead of

S3method(genericfunction, myclass)

I do

export(genericfunction.myclass)

Hadley

On Fri, Aug 23, 2013 at 11:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
> Dear List,
>
> In one of my packages I have an S3 method for the plot3d generic
> function from package rgl. I am trying to streamline my Depends
> entries but don't know how to have
>
> plot3d(foo)
>
> in the examples section for the plot3d method in my package, without
> rgl being in Depends.
>
> Note that I importFrom(rgl, plotd3d) and register my S3 method via
> S3Method() in the NAMESPACE.
>
> If rgl is not in Depends but in Imports, I see this when checking the package
>
>> ## 3D plot of data with curve superimposed
>> plot3d(aber.pc, abernethy2)
> Error: could not find function "plot3d"
>
> I presume this is because rgl's namespace is only loaded but the
> package is not attached to the search path.
>
> Writing R extensions indicates that one can export from a namespace
> something that was imported from another package namespace. I thought
> that might help the situation, and now the code doesn't raise an
> error, I get
>
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>   ?plot3d?
> All user-level objects in a package should have documentation entries.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
>
> as I don't document plot3d() itself.
>
> What is the recommended combination of Depends and Imports plus
> NAMESPACE directives etc that one should use in this situation? Or am
> I missing something else?
>
> I have a similar issue with my package including an S3 method for a
> generic in the lattice package, so if possible I could get rid of both
> of these from Depends if I can solve the above issue.
>
> Thanks in advance.
>
> Gavin
>
> --
> Gavin Simpson
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From gmbecker at ucdavis.edu  Mon Aug 26 00:47:25 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 25 Aug 2013 15:47:25 -0700
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CABdHhvG4tWCg1n86mOY5Qd3s_xcmzJ+KsH0npRGoWDnQ4OrEHA@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<CABdHhvG4tWCg1n86mOY5Qd3s_xcmzJ+KsH0npRGoWDnQ4OrEHA@mail.gmail.com>
Message-ID: <CADwqtCOad3qV8ikHaWWnr+Q6gz4E6ht4J9FxxgAcM_fBYoA8bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130825/84483eb6/attachment.pl>

From murdoch.duncan at gmail.com  Fri Aug 23 18:05:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Aug 2013 12:05:43 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CANROs4eF6TqTpzTyP0nXPWXjR_1O4SG_Vev+yD5oTcYpyc_5CA@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
	<CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>
	<CANROs4eF6TqTpzTyP0nXPWXjR_1O4SG_Vev+yD5oTcYpyc_5CA@mail.gmail.com>
Message-ID: <52178857.5040005@gmail.com>

On 13-08-22 11:54 PM, Yihui Xie wrote:
> Maybe it is not a good idea for R CMD check to check ::: at all, and a
> warning in R-exts and ?':::' may well be enough. On the other hand, it
> is just so easy to get around :::, because everybody can see its
> source code:

It's a really bad idea to write tricky code to subvert the tests.  If 
the tests are wrong, you can argue for changes (and in this case you 
did, and changes were made), but if you can't give a convincing 
argument, you should follow the good practices that the repository 
policies enforce.

Duncan Murdoch

>
>> `:::`
> function (pkg, name)
> {
>      pkg <- as.character(substitute(pkg))
>      name <- as.character(substitute(name))
>      get(name, envir = asNamespace(pkg), inherits = FALSE)
> }
>
> Then the package authors who really want to take the risk may start
> another "hide and seek" game, e.g.
>
> `%:::%` = function(pkg, fun) get(fun, envir = asNamespace(pkg),
> inherits = FALSE)
> 'stats' %:::% 'Pillai'
>
> Non-exported functions do not necessarily imply instability. Maybe it
> is just because the author is too lazy to document them, or he/she did
> not realize these functions happen to be useful for another author.
>
> Although R-devel does not warn against ::: on the packages of the same
> maintainer now, these maintainers may change in the future, or one
> maintainer can be an author but not maintainer of another package,
> from which he/she imports an unexported function, or package authors
> have coordinated well with each other about the unexported functions.
> I believe there are other legitimate reasons for :::, which might make
> it difficult for R to cover all these cases, and also bring additional
> communications between package authors and CRAN.
>
> In conclusion, R CMD check cannot really stop :::, and ::: can be
> there for good reasons, so how about just let it go?
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 102 Snedecor Hall, Ames, IA
>
>
> On Thu, Aug 22, 2013 at 9:02 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>> Hey guys,
>>
>> Because I was curious and had nothing else that I should have been doing
>> (that second part is a lie), I looked into the namespace code.
>>
>> I have a working patch that implements importHiddenFrom. It doesn't
>> currently check whether you then export that symbol (which should not be
>> allowed) but that would be easy to implement.
>>
>> Is there any desire from R-core to have add the importHiddenFrom
>> functionality? If so I can add the export check and submit the patch either
>> here or on bugzilla. I figure its a long shot but hey, at least I now know
>> how the namespace stuff works.
>>
>> I do agree with Peter Meilstrup that poking around at the internals of
>> someone else's code is often not a good idea, but as others have pointed
>> out it is done in practice in some fairly high-profile packages, and if its
>> going to happen it seems like it would be nice to indicate as much in the
>> NAMESPACE file.
>>
>> ~G
>>
>>
>> On Thu, Aug 22, 2013 at 5:41 PM, Gray <gray at clhn.co> wrote:
>>
>>> Peter Meilstrup: (05:01PM on Thu, Aug 22)
>>>
>>>   One most often encounters namespace conflicts at the user level, when
>>>> loading two packages that have no logical connection other than both
>>>> bearing on your problem of the moment.
>>>>
>>>
>>> Unless I'm mistaken, you can reassign the hidden functions, ie
>>>
>>> fna <- joespackage:::usefulfunction
>>>
>>> fnb <- janespackage:::usefulfunction
>>>
>>> which is a little bit of a pain, but makes the user's code
>>> unambiguous.  This also works with two colons for explicitly exported
>>> functions.
>>>
>>> --
>>> Gray Calhoun, Assistant Professor of Economics at Iowa State
>>> http://gray.clhn.co (web)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Aug 26 03:28:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 25 Aug 2013 21:28:17 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAC2h7us=Duy3L8N5H--hfyOx__-Yp+uiYxV7YY6eK==Tisw1Gg@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
	<CAJoaRhamc8VRm2DYAKCzQUJA7DO4ypwvP6w_XkDWmCFOAwMDgg@mail.gmail.com>
	<CAC2h7us=Duy3L8N5H--hfyOx__-Yp+uiYxV7YY6eK==Tisw1Gg@mail.gmail.com>
Message-ID: <521AAF31.5070008@gmail.com>

On 13-08-24 12:46 PM, Kasper Daniel Hansen wrote:
> On Thu, Aug 22, 2013 at 8:27 PM, Peter Meilstrup Using ::: on a package you
> don't control can be more dangerous. For a
>>
>> package author to choose to export a function to the public interface
>> represents at least some assurance that that interface will be stable or
>> slow-moving. But there are no implied assurances about how code in the
>> private namespace might change behind the scenes. I might completely
>> refactor the code and change the behavior of any private function between
>> 0.0.1 releases, but I would not do that for exported functions.
>
>
> This is true (that it could be dangerous), but sometimes, as a package
> author, I am willing to take this risk.  Personally, I don't do this
> lightly, but sometimes there is no way around it, particular if the hidden
> function does some magic in its own NAMESPACE.  It is not all functions
> that one can just easily copy over into you own package.
>
> It is fine to say that the use of ::: should be discouraged, it is another
> thing if it prevents you from submitting to CRAN (which I don't know for
> sure; I thought that Notes were ok?).

CRAN is a good place to send your packages because it does some quality 
control on the packages it accepts.  As I said in my message to Yihui, 
if you think the test is wrong, you can argue about that and it might be 
changed, but if you can't convince the CRAN maintainers of the validity 
of your point, you shouldn't send your package there.  There are plenty 
of other places (github, R-forge, etc.) where you can distribute it.

Duncan Murdoch


From xie at yihui.name  Mon Aug 26 04:53:53 2013
From: xie at yihui.name (Yihui Xie)
Date: Sun, 25 Aug 2013 21:53:53 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <52178857.5040005@gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
	<CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>
	<CANROs4eF6TqTpzTyP0nXPWXjR_1O4SG_Vev+yD5oTcYpyc_5CA@mail.gmail.com>
	<52178857.5040005@gmail.com>
Message-ID: <CANROs4fLzMGGzMEDGckNkHSZPGDNi40rJet8FNxhwZXsTuJNFw@mail.gmail.com>

I know it is really bad, but the so-called good approach can be more
expensive than that, primarily because a package with a NOTE in R CMD
check is likely to be rejected by CRAN, or authors have to justify the
NOTE in the email.

For this particular case, I can imagine at least one case which can be
endless trouble to CRAN: if the package author A has talked to B to
use a hidden function in B's package, and B thinks that function is
relatively stable but does not want to export it; A may go ahead and
use it via :::. Both A and B understand that unexported function well,
then what should A do when submitting the package to CRAN? Should CRAN
continue adding rules for such exceptions?

In other words, "bad" practices almost always have exceptions and edge
cases. Of course, the decision is always in CRAN's hands, and I will
try to respect and follow it as a package author.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
102 Snedecor Hall, Ames, IA


On Fri, Aug 23, 2013 at 11:05 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-08-22 11:54 PM, Yihui Xie wrote:
>>
>> Maybe it is not a good idea for R CMD check to check ::: at all, and a
>> warning in R-exts and ?':::' may well be enough. On the other hand, it
>> is just so easy to get around :::, because everybody can see its
>> source code:
>
>
> It's a really bad idea to write tricky code to subvert the tests.  If the
> tests are wrong, you can argue for changes (and in this case you did, and
> changes were made), but if you can't give a convincing argument, you should
> follow the good practices that the repository policies enforce.
>
> Duncan Murdoch
>
>>
>>> `:::`
>>
>> function (pkg, name)
>> {
>>      pkg <- as.character(substitute(pkg))
>>      name <- as.character(substitute(name))
>>      get(name, envir = asNamespace(pkg), inherits = FALSE)
>> }
>>
>> Then the package authors who really want to take the risk may start
>> another "hide and seek" game, e.g.
>>
>> `%:::%` = function(pkg, fun) get(fun, envir = asNamespace(pkg),
>> inherits = FALSE)
>> 'stats' %:::% 'Pillai'


From gmbecker at ucdavis.edu  Mon Aug 26 08:36:32 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 25 Aug 2013 23:36:32 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CANROs4fLzMGGzMEDGckNkHSZPGDNi40rJet8FNxhwZXsTuJNFw@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de>
	<52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<BA069179-9E70-4CCE-BD8E-CCB01988B68E@muxspace.com>
	<CAP01uRnuo9kFwbDpmZrQhkF5Mo5EW5LZt623o6b7N7F804Rp0Q@mail.gmail.com>
	<ABEAF14C-9D05-4878-9A15-3FC9728C7951@muxspace.com>
	<521693A6.5030407@statistik.tu-dortmund.de>
	<CAJoaRhZ_fRG2vuUk-dkXa6JwG4zYK2eDDTzw4BXQJFmWxwV92Q@mail.gmail.com>
	<20130823004158.GA14224@gray-ThinkPad-X200-Tablet>
	<CADwqtCMDBcXpziz-_WfMdCtodfeczHySpm7VYyw-zifX8+1ahw@mail.gmail.com>
	<CANROs4eF6TqTpzTyP0nXPWXjR_1O4SG_Vev+yD5oTcYpyc_5CA@mail.gmail.com>
	<52178857.5040005@gmail.com>
	<CANROs4fLzMGGzMEDGckNkHSZPGDNi40rJet8FNxhwZXsTuJNFw@mail.gmail.com>
Message-ID: <CADwqtCMM4PwE2593Q2hHE2y+7SX6ANHSW=XnH+tFpr1PSEVBfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130825/816465f7/attachment.pl>

From plummerm at iarc.fr  Mon Aug 26 10:28:46 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Mon, 26 Aug 2013 08:28:46 +0000
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
Message-ID: <1377505726.5290.20.camel@braque.iarc.fr>

I think rgl should be in Depends.  You are providing a method for a
generic function from another package. In order to use your method, you
want the user to be able to call the generic function without scoping
(i.e. without calling rgl::plot3d), so the generic should be on the
search path, so the package that provides it should be listed in Depends
in the NAMESPACE file.

Martyn

On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
> Dear List,
> 
> In one of my packages I have an S3 method for the plot3d generic
> function from package rgl. I am trying to streamline my Depends
> entries but don't know how to have
> 
> plot3d(foo)
> 
> in the examples section for the plot3d method in my package, without
> rgl being in Depends.
> 
> Note that I importFrom(rgl, plotd3d) and register my S3 method via
> S3Method() in the NAMESPACE.
> 
> If rgl is not in Depends but in Imports, I see this when checking the package
> 
> > ## 3D plot of data with curve superimposed
> > plot3d(aber.pc, abernethy2)
> Error: could not find function "plot3d"
> 
> I presume this is because rgl's namespace is only loaded but the
> package is not attached to the search path.
> 
> Writing R extensions indicates that one can export from a namespace
> something that was imported from another package namespace. I thought
> that might help the situation, and now the code doesn't raise an
> error, I get
> 
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>   ?plot3d?
> All user-level objects in a package should have documentation entries.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
> 
> as I don't document plot3d() itself.
> 
> What is the recommended combination of Depends and Imports plus
> NAMESPACE directives etc that one should use in this situation? Or am
> I missing something else?
> 
> I have a similar issue with my package including an S3 method for a
> generic in the lattice package, so if possible I could get rid of both
> of these from Depends if I can solve the above issue.
> 
> Thanks in advance.
> 
> Gavin
> 


From benjamin.hofner at imbe.med.uni-erlangen.de  Mon Aug 26 14:51:56 2013
From: benjamin.hofner at imbe.med.uni-erlangen.de (Benjamin Hofner)
Date: Mon, 26 Aug 2013 14:51:56 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <mailman.25.1377252007.21998.r-devel@r-project.org>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
Message-ID: <521B4F6C.3090101@imbe.med.uni-erlangen.de>

Hi,

related to this important discussion I have several questions:

What can I do to explicitly state that I want to use a certain, 
*non-exported* generic function? The function I am currently talking of 
is predict.smooth.spline from package stats. As I want to make shure 
that *this* function is used I currently call 
stats:::predict.smooth.spline() in my code, which now triggers a NOTE on 
CRAN. Strange enough predict.smooth.spline even has a manual page but is 
not exported (as is true for many other generic functions as well).

Is it advisable to specify (S3) methods without exporting them? How can 
I access exactly this function without using :::? And/or shouldn't we (R 
Core in this instance but others - including myself) export all methods 
(especially if a manual exists anyway)?

A related question concerns the function stats:::n.knots. I want to use 
this function to compute the number of knots for a spline (not 
necessarily a smoothing spline as defined by smooth.spline were it is 
originally used). The source of the function even states as a comment: 
"## Namespace-hidden but at least available to programmeRs:" So I guess 
this function can be considered to be stable and usable. Would it then 
be possible for R Core to export this function?

Finally, if one needs to copy a function (perhaps with minor 
modifications), how does one properly state the authorship of the code 
that one copies? Are there any guidelines, rules, ...? Is it sufficient 
for small functions to state the original authorship as a comment in the 
source? Is it necessary to state the authorship in the manual? Or is it 
even required to state the quthorship in the DESCRITPION? I already did 
an extensive search of the R-devel mailing list but couldn't find an 
appropriate answer. And after all I do not want to spend hours and hours 
thinking about licenses, authorship etc. but I want to produce nice and 
usable code (but also want to mention the original authors appropriately)!

Happy to learn more and read your thoughts and ideas about these issues.

All the best,
Benjamin


From murdoch.duncan at gmail.com  Mon Aug 26 16:47:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Aug 2013 10:47:38 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B4F6C.3090101@imbe.med.uni-erlangen.de>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
Message-ID: <521B6A8A.7040307@gmail.com>

On 26/08/2013 8:51 AM, Benjamin Hofner wrote:
> Hi,
>
> related to this important discussion I have several questions:
>
> What can I do to explicitly state that I want to use a certain,
> *non-exported* generic function? The function I am currently talking of
> is predict.smooth.spline from package stats. As I want to make shure
> that *this* function is used I currently call
> stats:::predict.smooth.spline() in my code, which now triggers a NOTE on
> CRAN. Strange enough predict.smooth.spline even has a manual page but is
> not exported (as is true for many other generic functions as well).

Actually the standard name is that predict() is a generic function, 
predict.smooth.spline() is a method, but it's a good question.  Can you 
describe why you want to call that method on something that isn't a 
smooth.spline object?
>
> Is it advisable to specify (S3) methods without exporting them? How can
> I access exactly this function without using :::? And/or shouldn't we (R
> Core in this instance but others - including myself) export all methods
> (especially if a manual exists anyway)?

The general reason for hiding methods is that it allows the author of the package to change the internal implementation of the class without worrying that it will break code that uses the method, i.e. it will stop usages such as yours.  So you need to explain why you are doing what you are doing.


> A related question concerns the function stats:::n.knots. I want to use
> this function to compute the number of knots for a spline (not
> necessarily a smoothing spline as defined by smooth.spline were it is
> originally used). The source of the function even states as a comment:
> "## Namespace-hidden but at least available to programmeRs:" So I guess
> this function can be considered to be stable and usable. Would it then
> be possible for R Core to export this function?
>
> Finally, if one needs to copy a function (perhaps with minor
> modifications), how does one properly state the authorship of the code
> that one copies? Are there any guidelines, rules, ...? Is it sufficient
> for small functions to state the original authorship as a comment in the
> source? Is it necessary to state the authorship in the manual? Or is it
> even required to state the quthorship in the DESCRITPION? I already did
> an extensive search of the R-devel mailing list but couldn't find an
> appropriate answer. And after all I do not want to spend hours and hours
> thinking about licenses, authorship etc. but I want to produce nice and
> usable code (but also want to mention the original authors appropriately)!

I would say that you should certainly state it in the man page, and have 
something in the DESCRIPTION file as well.  It might be something like

Author:  Duncan Murdoch, with code from others (see the man pages)

However, I just looked at rgl (a package I maintain), and I see we 
didn't do that.  We have a separate README file listing other credits.

Duncan Murdoch

>
> Happy to learn more and read your thoughts and ideas about these issues.
>
> All the best,
> Benjamin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From benjamin.hofner at fau.de  Mon Aug 26 17:20:10 2013
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Mon, 26 Aug 2013 17:20:10 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B6A8A.7040307@gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com>
Message-ID: <521B722A.5050702@fau.de>

Dear Duncan,

thank you for the quick reply.

Am 26.08.2013 16:47, schrieb Duncan Murdoch:
> On 26/08/2013 8:51 AM, Benjamin Hofner wrote:
>> Hi,
>>
>> related to this important discussion I have several questions:
>>
>> What can I do to explicitly state that I want to use a certain,
>> *non-exported* generic function? The function I am currently talking of
>> is predict.smooth.spline from package stats. As I want to make shure
>> that *this* function is used I currently call
>> stats:::predict.smooth.spline() in my code, which now triggers a NOTE on
>> CRAN. Strange enough predict.smooth.spline even has a manual page but is
>> not exported (as is true for many other generic functions as well).
>
> Actually the standard name is that predict() is a generic function,
> predict.smooth.spline() is a method, but it's a good question.  Can you
> describe why you want to call that method on something that isn't a
> smooth.spline object?

Actually the object is a smooth.spline object but with additional 
attributes and more classes, i.e.,

class(mod)
[1] "opm_model"           "smooth.spline_model" "smooth.spline"

Now I have a specialized predict function predict.smooth.spline_model 
which in turn calls predict.smooth.spline.

I just tried to use NextMethod(generic = "predict", object, ...) and it 
seems to work. So this seems to be the desired solution. I tried this 
earlier and got error messages, perhaps because I omitted the argument 
generic. I guess the function then was confused what the generic is 
(predict or predict.smooth).

>>
>> Is it advisable to specify (S3) methods without exporting them? How can
>> I access exactly this function without using :::? And/or shouldn't we (R
>> Core in this instance but others - including myself) export all methods
>> (especially if a manual exists anyway)?
>
> The general reason for hiding methods is that it allows the author of
> the package to change the internal implementation of the class without
> worrying that it will break code that uses the method, i.e. it will stop
> usages such as yours.  So you need to explain why you are doing what you
> are doing.

I see no difference in these two ways to call the next generic function: 
In both cases I can (and do) specify further arguments, namely x for new 
data and deriv = 0. Thus in both cases I rely on the interface in the 
same way. I do not see any bonus for the package maintainer (both of the 
depending and dependent package). The interface stays the same and the 
class could change in both situations. Isn't a method always relying on 
the current implementation of a class? And isn't anything else more than 
unwanted? So again? Why hiding a method? The only reason I see is that 
one doesn't want to document the function properly.

>
>
>> A related question concerns the function stats:::n.knots. I want to use
>> this function to compute the number of knots for a spline (not
>> necessarily a smoothing spline as defined by smooth.spline were it is
>> originally used). The source of the function even states as a comment:
>> "## Namespace-hidden but at least available to programmeRs:" So I guess
>> this function can be considered to be stable and usable. Would it then
>> be possible for R Core to export this function?

Do I need to file a formal request for this issue?

>>
>> Finally, if one needs to copy a function (perhaps with minor
>> modifications), how does one properly state the authorship of the code
>> that one copies? Are there any guidelines, rules, ...? Is it sufficient
>> for small functions to state the original authorship as a comment in the
>> source? Is it necessary to state the authorship in the manual? Or is it
>> even required to state the quthorship in the DESCRITPION? I already did
>> an extensive search of the R-devel mailing list but couldn't find an
>> appropriate answer. And after all I do not want to spend hours and hours
>> thinking about licenses, authorship etc. but I want to produce nice and
>> usable code (but also want to mention the original authors
>> appropriately)!
>
> I would say that you should certainly state it in the man page, and have
> something in the DESCRIPTION file as well.  It might be something like
>
> Author:  Duncan Murdoch, with code from others (see the man pages)
>
> However, I just looked at rgl (a package I maintain), and I see we
> didn't do that.  We have a separate README file listing other credits.

This is a good solution. Do I need to specify the original License etc? 
And what about a helper function such as stats:::n.knots? This will not 
appear in the manual of my package. Is it sufficient in this case to 
document the authorship in the source (and perhaps a README as you 
suggested)?

>
> Duncan Murdoch
>
>>
>> Happy to learn more and read your thoughts and ideas about these issues.
>>
>> All the best,
>> Benjamin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Benjamin


From h.wickham at gmail.com  Mon Aug 26 17:38:54 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 26 Aug 2013 10:38:54 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B6A8A.7040307@gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com>
Message-ID: <CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>

> I would say that you should certainly state it in the man page, and have
> something in the DESCRIPTION file as well.  It might be something like
>
> Author:  Duncan Murdoch, with code from others (see the man pages)
>
> However, I just looked at rgl (a package I maintain), and I see we didn't do
> that.  We have a separate README file listing other credits.

The feedback that I've been getting from CRAN maintainers lately is
that you have to include all source code contributors in the authors
field.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From hb at biostat.ucsf.edu  Mon Aug 26 17:42:11 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 26 Aug 2013 08:42:11 -0700
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <1377505726.5290.20.camel@braque.iarc.fr>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<1377505726.5290.20.camel@braque.iarc.fr>
Message-ID: <CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>

On Mon, Aug 26, 2013 at 1:28 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
> I think rgl should be in Depends.  You are providing a method for a
> generic function from another package. In order to use your method, you
> want the user to be able to call the generic function without scoping
> (i.e. without calling rgl::plot3d), so the generic should be on the
> search path, so the package that provides it should be listed in Depends
> in the NAMESPACE file.

You can re-export an imported object, but it has to be done via an
explicit export(), cf. "It is possible to export variables from a
namespace which it has imported from other namespaces: this has to be
done explicitly and not via exportPattern" [Writing R Extensions].

/H

>
> Martyn
>
> On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
>> Dear List,
>>
>> In one of my packages I have an S3 method for the plot3d generic
>> function from package rgl. I am trying to streamline my Depends
>> entries but don't know how to have
>>
>> plot3d(foo)
>>
>> in the examples section for the plot3d method in my package, without
>> rgl being in Depends.
>>
>> Note that I importFrom(rgl, plotd3d) and register my S3 method via
>> S3Method() in the NAMESPACE.
>>
>> If rgl is not in Depends but in Imports, I see this when checking the package
>>
>> > ## 3D plot of data with curve superimposed
>> > plot3d(aber.pc, abernethy2)
>> Error: could not find function "plot3d"
>>
>> I presume this is because rgl's namespace is only loaded but the
>> package is not attached to the search path.
>>
>> Writing R extensions indicates that one can export from a namespace
>> something that was imported from another package namespace. I thought
>> that might help the situation, and now the code doesn't raise an
>> error, I get
>>
>> * checking for missing documentation entries ... WARNING
>> Undocumented code objects:
>>   ?plot3d?
>> All user-level objects in a package should have documentation entries.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> Extensions? manual.
>>
>> as I don't document plot3d() itself.
>>
>> What is the recommended combination of Depends and Imports plus
>> NAMESPACE directives etc that one should use in this situation? Or am
>> I missing something else?
>>
>> I have a similar issue with my package including an S3 method for a
>> generic in the lattice package, so if possible I could get rid of both
>> of these from Depends if I can solve the above issue.
>>
>> Thanks in advance.
>>
>> Gavin
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ucfagls at gmail.com  Mon Aug 26 18:04:44 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Mon, 26 Aug 2013 10:04:44 -0600
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<1377505726.5290.20.camel@braque.iarc.fr>
	<CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>
Message-ID: <CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>

Right Henrik, but then you have to document it or R CMD check raises a
Warning, which is less likely to pass muster when submitting to CRAN.
So you document that method on your existing method's Rd page (just
via an \alias{}), which is fine until the user does end up attaching
the original source of the method, and then you get the annoying
warnings about masking and `?plot3d` will bring up a dialogue asking
which version of the help you want to read.

Part of me thinks it would be better if there was a mechanism whereby
a generic will just work if package foo imports that generic and
exports a method for it.

Cheers,

G

On 26 August 2013 09:42, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Mon, Aug 26, 2013 at 1:28 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
>> I think rgl should be in Depends.  You are providing a method for a
>> generic function from another package. In order to use your method, you
>> want the user to be able to call the generic function without scoping
>> (i.e. without calling rgl::plot3d), so the generic should be on the
>> search path, so the package that provides it should be listed in Depends
>> in the NAMESPACE file.
>
> You can re-export an imported object, but it has to be done via an
> explicit export(), cf. "It is possible to export variables from a
> namespace which it has imported from other namespaces: this has to be
> done explicitly and not via exportPattern" [Writing R Extensions].
>
> /H
>
>>
>> Martyn
>>
>> On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
>>> Dear List,
>>>
>>> In one of my packages I have an S3 method for the plot3d generic
>>> function from package rgl. I am trying to streamline my Depends
>>> entries but don't know how to have
>>>
>>> plot3d(foo)
>>>
>>> in the examples section for the plot3d method in my package, without
>>> rgl being in Depends.
>>>
>>> Note that I importFrom(rgl, plotd3d) and register my S3 method via
>>> S3Method() in the NAMESPACE.
>>>
>>> If rgl is not in Depends but in Imports, I see this when checking the package
>>>
>>> > ## 3D plot of data with curve superimposed
>>> > plot3d(aber.pc, abernethy2)
>>> Error: could not find function "plot3d"
>>>
>>> I presume this is because rgl's namespace is only loaded but the
>>> package is not attached to the search path.
>>>
>>> Writing R extensions indicates that one can export from a namespace
>>> something that was imported from another package namespace. I thought
>>> that might help the situation, and now the code doesn't raise an
>>> error, I get
>>>
>>> * checking for missing documentation entries ... WARNING
>>> Undocumented code objects:
>>>   ?plot3d?
>>> All user-level objects in a package should have documentation entries.
>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>> Extensions? manual.
>>>
>>> as I don't document plot3d() itself.
>>>
>>> What is the recommended combination of Depends and Imports plus
>>> NAMESPACE directives etc that one should use in this situation? Or am
>>> I missing something else?
>>>
>>> I have a similar issue with my package including an S3 method for a
>>> generic in the lattice package, so if possible I could get rid of both
>>> of these from Depends if I can solve the above issue.
>>>
>>> Thanks in advance.
>>>
>>> Gavin
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Gavin Simpson, PhD


From h.wickham at gmail.com  Mon Aug 26 18:39:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 26 Aug 2013 11:39:53 -0500
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<1377505726.5290.20.camel@braque.iarc.fr>
	<CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>
	<CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>
Message-ID: <CABdHhvEqD8r0GhOq62+E3=f12ZsN=WsCsiUWgfEaRQVoEZOd1A@mail.gmail.com>

Or you could import the generic, but not export it, and then use
require("rgl") in examples.  That seems reasonable if the majority of
functions don't need other rgl functions.

If most of the time you do need rgl loaded, then Martyn's suggestion
to require rgl seems reasonable.

Hadley

On Mon, Aug 26, 2013 at 11:04 AM, Gavin Simpson <ucfagls at gmail.com> wrote:
> Right Henrik, but then you have to document it or R CMD check raises a
> Warning, which is less likely to pass muster when submitting to CRAN.
> So you document that method on your existing method's Rd page (just
> via an \alias{}), which is fine until the user does end up attaching
> the original source of the method, and then you get the annoying
> warnings about masking and `?plot3d` will bring up a dialogue asking
> which version of the help you want to read.
>
> Part of me thinks it would be better if there was a mechanism whereby
> a generic will just work if package foo imports that generic and
> exports a method for it.
>
> Cheers,
>
> G
>
> On 26 August 2013 09:42, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> On Mon, Aug 26, 2013 at 1:28 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
>>> I think rgl should be in Depends.  You are providing a method for a
>>> generic function from another package. In order to use your method, you
>>> want the user to be able to call the generic function without scoping
>>> (i.e. without calling rgl::plot3d), so the generic should be on the
>>> search path, so the package that provides it should be listed in Depends
>>> in the NAMESPACE file.
>>
>> You can re-export an imported object, but it has to be done via an
>> explicit export(), cf. "It is possible to export variables from a
>> namespace which it has imported from other namespaces: this has to be
>> done explicitly and not via exportPattern" [Writing R Extensions].
>>
>> /H
>>
>>>
>>> Martyn
>>>
>>> On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
>>>> Dear List,
>>>>
>>>> In one of my packages I have an S3 method for the plot3d generic
>>>> function from package rgl. I am trying to streamline my Depends
>>>> entries but don't know how to have
>>>>
>>>> plot3d(foo)
>>>>
>>>> in the examples section for the plot3d method in my package, without
>>>> rgl being in Depends.
>>>>
>>>> Note that I importFrom(rgl, plotd3d) and register my S3 method via
>>>> S3Method() in the NAMESPACE.
>>>>
>>>> If rgl is not in Depends but in Imports, I see this when checking the package
>>>>
>>>> > ## 3D plot of data with curve superimposed
>>>> > plot3d(aber.pc, abernethy2)
>>>> Error: could not find function "plot3d"
>>>>
>>>> I presume this is because rgl's namespace is only loaded but the
>>>> package is not attached to the search path.
>>>>
>>>> Writing R extensions indicates that one can export from a namespace
>>>> something that was imported from another package namespace. I thought
>>>> that might help the situation, and now the code doesn't raise an
>>>> error, I get
>>>>
>>>> * checking for missing documentation entries ... WARNING
>>>> Undocumented code objects:
>>>>   ?plot3d?
>>>> All user-level objects in a package should have documentation entries.
>>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>>> Extensions? manual.
>>>>
>>>> as I don't document plot3d() itself.
>>>>
>>>> What is the recommended combination of Depends and Imports plus
>>>> NAMESPACE directives etc that one should use in this situation? Or am
>>>> I missing something else?
>>>>
>>>> I have a similar issue with my package including an S3 method for a
>>>> generic in the lattice package, so if possible I could get rid of both
>>>> of these from Depends if I can solve the above issue.
>>>>
>>>> Thanks in advance.
>>>>
>>>> Gavin
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Gavin Simpson, PhD
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From kasperdanielhansen at gmail.com  Mon Aug 26 19:57:00 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 26 Aug 2013 13:57:00 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com>
	<CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>
Message-ID: <CAC2h7uvhCzbUR_YyOQrHTqsmpa=L6_nGJzKFDZb2w9gj=VJ7cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130826/28cb6e4f/attachment.pl>

From trevor.l.davis at gmail.com  Mon Aug 26 20:06:15 2013
From: trevor.l.davis at gmail.com (Trevor Davis)
Date: Mon, 26 Aug 2013 11:06:15 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B722A.5050702@fau.de>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com> <521B722A.5050702@fau.de>
Message-ID: <CAMigB8Gf4tdrpeOBU88T=UE-hVySJgh3etgELKs2C1GmWzyxyA@mail.gmail.com>

> This is a good solution. Do I need to specify the original License etc? And
> what about a helper function such as stats:::n.knots? This will not appear
> in the manual of my package. Is it sufficient in this case to document the
> authorship in the source (and perhaps a README as you suggested)?

If the license is the same as your projects you just need the proper
copyright notice.
As Hadley suggests it is a good idea to also document the appropriate authorship
in the Authors field in the DESCRIPTION as well.

If the license is different but permissive than then it typically doesn't need
go into DESCRIPTION or a separate LICENSE file but the permissive
license text does usually need to either go
into inst/COPYRIGHT or at the top of the relevant code file:

  https://www.softwarefreedom.org/resources/2007/gpl-non-gpl-collaboration.html
  https://www.softwarefreedom.org/resources/2012/ManagingCopyrightInformation.html

If the license is more restrictive
you must either convert your project or not use the code at all
although for very small code snippets you might have fair use rights
(at least in the United States).

- Trevor


From h.wickham at gmail.com  Mon Aug 26 20:12:55 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 26 Aug 2013 13:12:55 -0500
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAMigB8Gf4tdrpeOBU88T=UE-hVySJgh3etgELKs2C1GmWzyxyA@mail.gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com> <521B722A.5050702@fau.de>
	<CAMigB8Gf4tdrpeOBU88T=UE-hVySJgh3etgELKs2C1GmWzyxyA@mail.gmail.com>
Message-ID: <CABdHhvELKs7V=eOVD4P3jD6KxMqDYwXR6BWLVemi+RicobaWcQ@mail.gmail.com>

On Mon, Aug 26, 2013 at 1:06 PM, Trevor Davis <trevor.l.davis at gmail.com> wrote:
>> This is a good solution. Do I need to specify the original License etc? And
>> what about a helper function such as stats:::n.knots? This will not appear
>> in the manual of my package. Is it sufficient in this case to document the
>> authorship in the source (and perhaps a README as you suggested)?
>
> If the license is the same as your projects you just need the proper
> copyright notice.
> As Hadley suggests it is a good idea to also document the appropriate authorship
> in the Authors field in the DESCRIPTION as well.
>
> If the license is different but permissive than then it typically doesn't need
> go into DESCRIPTION or a separate LICENSE file but the permissive
> license text does usually need to either go
> into inst/COPYRIGHT or at the top of the relevant code file:
>
>   https://www.softwarefreedom.org/resources/2007/gpl-non-gpl-collaboration.html
>   https://www.softwarefreedom.org/resources/2012/ManagingCopyrightInformation.html

That may be true for other open source projects, but that is not the
interpretation that cran maintainers have used in the past.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From murdoch.duncan at gmail.com  Mon Aug 26 20:14:56 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Aug 2013 14:14:56 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAC2h7uvhCzbUR_YyOQrHTqsmpa=L6_nGJzKFDZb2w9gj=VJ7cA@mail.gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com>
	<CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>
	<CAC2h7uvhCzbUR_YyOQrHTqsmpa=L6_nGJzKFDZb2w9gj=VJ7cA@mail.gmail.com>
Message-ID: <521B9B20.7010106@gmail.com>

On 26/08/2013 1:57 PM, Kasper Daniel Hansen wrote:
> It seems that several people in this thread assumes that it is easy or 
> even possible to convince an author of a package to export a given 
> function.  This is clearly not always true, partly because as an 
> author you gain additional work by doing this.  The downsides to using 
> ::: is really about the possibility of the package breaking or 
> misfunctioning, and I don't really see why this is anyone else's problem.

As long as you keep the package to yourself, it's nobody's problem but 
yours.  If you want CRAN to distribute it, then it harms their 
reputation if it doesn't meet their standards.

Duncan Murdoch
>
> Best,
> Kasper
>
>
> On Mon, Aug 26, 2013 at 11:38 AM, Hadley Wickham <h.wickham at gmail.com 
> <mailto:h.wickham at gmail.com>> wrote:
>
>     > I would say that you should certainly state it in the man page,
>     and have
>     > something in the DESCRIPTION file as well.  It might be
>     something like
>     >
>     > Author:  Duncan Murdoch, with code from others (see the man pages)
>     >
>     > However, I just looked at rgl (a package I maintain), and I see
>     we didn't do
>     > that.  We have a separate README file listing other credits.
>
>     The feedback that I've been getting from CRAN maintainers lately is
>     that you have to include all source code contributors in the authors
>     field.
>
>     Hadley
>
>     --
>     Chief Scientist, RStudio
>     http://had.co.nz/
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Mon Aug 26 20:24:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Aug 2013 14:24:15 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B722A.5050702@fau.de>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com> <521B722A.5050702@fau.de>
Message-ID: <521B9D4F.3030009@gmail.com>

On 26/08/2013 11:20 AM, Benjamin Hofner wrote:
> Dear Duncan,
>
> thank you for the quick reply.
>
> Am 26.08.2013 16:47, schrieb Duncan Murdoch:
> > On 26/08/2013 8:51 AM, Benjamin Hofner wrote:
> >> Hi,
> >>
> >> related to this important discussion I have several questions:
> >>
> >> What can I do to explicitly state that I want to use a certain,
> >> *non-exported* generic function? The function I am currently talking of
> >> is predict.smooth.spline from package stats. As I want to make shure
> >> that *this* function is used I currently call
> >> stats:::predict.smooth.spline() in my code, which now triggers a NOTE on
> >> CRAN. Strange enough predict.smooth.spline even has a manual page but is
> >> not exported (as is true for many other generic functions as well).
> >
> > Actually the standard name is that predict() is a generic function,
> > predict.smooth.spline() is a method, but it's a good question.  Can you
> > describe why you want to call that method on something that isn't a
> > smooth.spline object?
>
> Actually the object is a smooth.spline object but with additional
> attributes and more classes, i.e.,
>
> class(mod)
> [1] "opm_model"           "smooth.spline_model" "smooth.spline"
>
> Now I have a specialized predict function predict.smooth.spline_model
> which in turn calls predict.smooth.spline.
>
> I just tried to use NextMethod(generic = "predict", object, ...) and it
> seems to work. So this seems to be the desired solution. I tried this
> earlier and got error messages, perhaps because I omitted the argument
> generic. I guess the function then was confused what the generic is
> (predict or predict.smooth).
>
> >>
> >> Is it advisable to specify (S3) methods without exporting them? How can
> >> I access exactly this function without using :::? And/or shouldn't we (R
> >> Core in this instance but others - including myself) export all methods
> >> (especially if a manual exists anyway)?
> >
> > The general reason for hiding methods is that it allows the author of
> > the package to change the internal implementation of the class without
> > worrying that it will break code that uses the method, i.e. it will stop
> > usages such as yours.  So you need to explain why you are doing what you
> > are doing.
>
> I see no difference in these two ways to call the next generic function:
> In both cases I can (and do) specify further arguments, namely x for new
> data and deriv = 0. Thus in both cases I rely on the interface in the
> same way. I do not see any bonus for the package maintainer (both of the
> depending and dependent package). The interface stays the same and the
> class could change in both situations. Isn't a method always relying on
> the current implementation of a class? And isn't anything else more than
> unwanted? So again? Why hiding a method? The only reason I see is that
> one doesn't want to document the function properly.

But as you've discovered, you don't need ::: access, you can use 
NextMethod.  You would need ::: access if the object wasn't a 
smooth.spline object, because then the generic and NextMethod wouldn't 
dispatch to the method.  If you were calling a smooth.spline method on 
something that is not a smooth.spline object, your code could break if 
something about the  smooth.spline class was changed, and the predict 
method for it was adjusted to compensate.
>
> >
> >
> >> A related question concerns the function stats:::n.knots. I want to use
> >> this function to compute the number of knots for a spline (not
> >> necessarily a smoothing spline as defined by smooth.spline were it is
> >> originally used). The source of the function even states as a comment:
> >> "## Namespace-hidden but at least available to programmeRs:" So I guess
> >> this function can be considered to be stable and usable. Would it then
> >> be possible for R Core to export this function?
>
> Do I need to file a formal request for this issue?

It might be better to write to the author of that comment.  You can find 
out who that is using "svn blame" (or as some of us prefer, "svn 
praise") on the file.

> >> Finally, if one needs to copy a function (perhaps with minor
> >> modifications), how does one properly state the authorship of the code
> >> that one copies? Are there any guidelines, rules, ...? Is it sufficient
> >> for small functions to state the original authorship as a comment in the
> >> source? Is it necessary to state the authorship in the manual? Or is it
> >> even required to state the quthorship in the DESCRITPION? I already did
> >> an extensive search of the R-devel mailing list but couldn't find an
> >> appropriate answer. And after all I do not want to spend hours and hours
> >> thinking about licenses, authorship etc. but I want to produce nice and
> >> usable code (but also want to mention the original authors
> >> appropriately)!
> >
> > I would say that you should certainly state it in the man page, and have
> > something in the DESCRIPTION file as well.  It might be something like
> >
> > Author:  Duncan Murdoch, with code from others (see the man pages)
> >
> > However, I just looked at rgl (a package I maintain), and I see we
> > didn't do that.  We have a separate README file listing other credits.
>
> This is a good solution. Do I need to specify the original License etc?
> And what about a helper function such as stats:::n.knots? This will not
> appear in the manual of my package. Is it sufficient in this case to
> document the authorship in the source (and perhaps a README as you
> suggested)?
I think you want to give credit in a place where users will see it, not 
just in the source.  Our README solution isn't good for that, because 
most people will never know they have that file.

Duncan Murdoch


From benjamin.hofner at imbe.med.uni-erlangen.de  Mon Aug 26 17:52:57 2013
From: benjamin.hofner at imbe.med.uni-erlangen.de (Benjamin Hofner)
Date: Mon, 26 Aug 2013 17:52:57 +0200
Subject: [Rd] legitimate use of :::
In-Reply-To: <CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>
	<521B4F6C.3090101@imbe.med.uni-erlangen.de>
	<521B6A8A.7040307@gmail.com>
	<CABdHhvE7cym=D9nWSynW6U-c6YddDm7Q0sVbZp+5vY-LuBt3NQ@mail.gmail.com>
Message-ID: <521B79D9.8040803@imbe.med.uni-erlangen.de>

Am 26.08.2013 17:38, schrieb Hadley Wickham:
>> I would say that you should certainly state it in the man page, and have
>> something in the DESCRIPTION file as well.  It might be something like
>>
>> Author:  Duncan Murdoch, with code from others (see the man pages)
>>
>> However, I just looked at rgl (a package I maintain), and I see we didn't do
>> that.  We have a separate README file listing other credits.
>
> The feedback that I've been getting from CRAN maintainers lately is
> that you have to include all source code contributors in the authors
> field.
>
> Hadley

I read these mails as well when I was looking for a good way to document 
code contributions. However, it seems to be nonsense to me, especially 
if you really just duplicate a simple function such as the n.knots. Next 
time I just "rewrite" the function (which doesn't seem to be good 
practice as well).

Well, on the other hand it reads nice to have R Core as contributing 
authors in my package(s)...

Perhaps a new field in DESCRIPTION and a standardized way how to name 
authors of functions one has duplicated would save a lot of the hassle? 
I could imagine a field that requires the structure:

Contributions:
   function (pkg): Authors

e.g.

   n.knots (stats): R Core

(perhaps with an added LICENSE "field")

Benjamin
-- 
******************************************************************************
Dr. rer. nat. Benjamin Hofner

Institut f?r Medizininformatik, Biometrie und Epidemiologie
Friedrich-Alexander-Universit?t Erlangen-N?rnberg
Waldstr. 6 - 91054 Erlangen - Germany

Tel: +49-9131-85-22707
Fax: +49-9131-85-25740

Office:
   Room 3.036
   Universit?tsstra?e 22
   (Entrance at the left side of the building)

benjamin.hofner at fau.de

http://www.imbe.med.uni-erlangen.de/cms/benjamin_hofner.html
http://www.benjaminhofner.de


From pgilbert902 at gmail.com  Mon Aug 26 21:12:49 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 26 Aug 2013 15:12:49 -0400
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<1377505726.5290.20.camel@braque.iarc.fr>
	<CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>
	<CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>
Message-ID: <521BA8B1.4080509@gmail.com>



On 13-08-26 12:04 PM, Gavin Simpson wrote:
> Right Henrik, but then you have to document it or R CMD check raises a
> Warning, which is less likely to pass muster when submitting to CRAN.
> So you document that method on your existing method's Rd page (just
> via an \alias{}), which is fine until the user does end up attaching
> the original source of the method, and then you get the annoying
> warnings about masking and `?plot3d` will bring up a dialogue asking
> which version of the help you want to read.
>
> Part of me thinks it would be better if there was a mechanism whereby
> a generic will just work if package foo imports that generic and
> exports a method for it.

Either I am messing up something again (reasonably likely) or it does 
just work with S4 methods. I can import the namespace that has the 
generic and the methods work, I do not seem to need to export the 
generic.  Is S3 working differently? I do have the documentation problem 
when I try to export other imported functions that I would like 
available to users.

Paul
>
> Cheers,
>
> G
>
> On 26 August 2013 09:42, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> On Mon, Aug 26, 2013 at 1:28 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
>>> I think rgl should be in Depends.  You are providing a method for a
>>> generic function from another package. In order to use your method, you
>>> want the user to be able to call the generic function without scoping
>>> (i.e. without calling rgl::plot3d), so the generic should be on the
>>> search path, so the package that provides it should be listed in Depends
>>> in the NAMESPACE file.
>>
>> You can re-export an imported object, but it has to be done via an
>> explicit export(), cf. "It is possible to export variables from a
>> namespace which it has imported from other namespaces: this has to be
>> done explicitly and not via exportPattern" [Writing R Extensions].
>>
>> /H
>>
>>>
>>> Martyn
>>>
>>> On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
>>>> Dear List,
>>>>
>>>> In one of my packages I have an S3 method for the plot3d generic
>>>> function from package rgl. I am trying to streamline my Depends
>>>> entries but don't know how to have
>>>>
>>>> plot3d(foo)
>>>>
>>>> in the examples section for the plot3d method in my package, without
>>>> rgl being in Depends.
>>>>
>>>> Note that I importFrom(rgl, plotd3d) and register my S3 method via
>>>> S3Method() in the NAMESPACE.
>>>>
>>>> If rgl is not in Depends but in Imports, I see this when checking the package
>>>>
>>>>> ## 3D plot of data with curve superimposed
>>>>> plot3d(aber.pc, abernethy2)
>>>> Error: could not find function "plot3d"
>>>>
>>>> I presume this is because rgl's namespace is only loaded but the
>>>> package is not attached to the search path.
>>>>
>>>> Writing R extensions indicates that one can export from a namespace
>>>> something that was imported from another package namespace. I thought
>>>> that might help the situation, and now the code doesn't raise an
>>>> error, I get
>>>>
>>>> * checking for missing documentation entries ... WARNING
>>>> Undocumented code objects:
>>>>    ?plot3d?
>>>> All user-level objects in a package should have documentation entries.
>>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>>> Extensions? manual.
>>>>
>>>> as I don't document plot3d() itself.
>>>>
>>>> What is the recommended combination of Depends and Imports plus
>>>> NAMESPACE directives etc that one should use in this situation? Or am
>>>> I missing something else?
>>>>
>>>> I have a similar issue with my package including an S3 method for a
>>>> generic in the lattice package, so if possible I could get rid of both
>>>> of these from Depends if I can solve the above issue.
>>>>
>>>> Thanks in advance.
>>>>
>>>> Gavin
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From jfox at mcmaster.ca  Mon Aug 26 20:49:22 2013
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 Aug 2013 14:49:22 -0400
Subject: [Rd] legitimate use of :::
In-Reply-To: <521B9D4F.3030009@gmail.com>
References: <mailman.25.1377252007.21998.r-devel@r-project.org>	<521B4F6C.3090101@imbe.med.uni-erlangen.de>	<521B6A8A.7040307@gmail.com>
	<521B722A.5050702@fau.de> <521B9D4F.3030009@gmail.com>
Message-ID: <004f01cea28c$fb675f20$f2361d60$@mcmaster.ca>

Dear Duncan,

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Duncan Murdoch
> Sent: Monday, August 26, 2013 2:24 PM
> To: Benjamin Hofner
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] legitimate use of :::
> 
> On 26/08/2013 11:20 AM, Benjamin Hofner wrote:
> > Dear Duncan,
> >
> > thank you for the quick reply.
> >
> > Am 26.08.2013 16:47, schrieb Duncan Murdoch:
> > > On 26/08/2013 8:51 AM, Benjamin Hofner wrote:
> > >> Hi,
> > >>

. . .

> > This is a good solution. Do I need to specify the original License
> etc?
> > And what about a helper function such as stats:::n.knots? This will
> not
> > appear in the manual of my package. Is it sufficient in this case to
> > document the authorship in the source (and perhaps a README as you
> > suggested)?
> I think you want to give credit in a place where users will see it, not
> just in the source.  Our README solution isn't good for that, because
> most people will never know they have that file.
> 
> Duncan Murdoch

I've been giving credit in the Authors at R: field of the DESCRIPTION file and
via comments in the source code, but this isn't a good solution since the
first is non-specific and the second won't be read by users. 

Now that this practice will be much more frequent as a consequence of
eliminating ::: references, it would be nice to have a standard solution.
Maybe using the comment argument to person() in the Authors at R field makes
sense; I haven't tried this.

Best,
 John


From ucfagls at gmail.com  Mon Aug 26 21:18:23 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Mon, 26 Aug 2013 13:18:23 -0600
Subject: [Rd] Correct NAMESPACE approach when writing an S3 method for a
 generic in another package
In-Reply-To: <521BA8B1.4080509@gmail.com>
References: <CAAHES9yT-YM=huPWJ+Wgv7y8RQV3n=hX8cHOMYXrCLNc7A4e4g@mail.gmail.com>
	<1377505726.5290.20.camel@braque.iarc.fr>
	<CAFDcVCS0+qtPH3qBMOgouYhEg0-vzuh7xK7Y11GoMT+_C_1LxA@mail.gmail.com>
	<CAAHES9zPndYwgDuH2bVyFmMmUj2rnfhBYTddRpAoiASRhoUnsw@mail.gmail.com>
	<521BA8B1.4080509@gmail.com>
Message-ID: <CAAHES9xVCZRho7sNArmrYZrYjth3jRO+mXFoXHUhVeg=DC7B=A@mail.gmail.com>

I'm not familiar enough with S4 to know what is going on there. With
S3 methods, the package that defines the generic needs to be loaded
and attached, otherwise you can't do

foo(bar)

when

foo.myclass(bar)

is what you want to be called and you export that method from your
package. Calling `foo()` will result in an error. As long as the
package containing the definition of the generic is not attached,
there is no function `foo()` and hence the user gets an error.

G

On 26 August 2013 13:12, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>
> On 13-08-26 12:04 PM, Gavin Simpson wrote:
>>
>> Right Henrik, but then you have to document it or R CMD check raises a
>> Warning, which is less likely to pass muster when submitting to CRAN.
>> So you document that method on your existing method's Rd page (just
>> via an \alias{}), which is fine until the user does end up attaching
>> the original source of the method, and then you get the annoying
>> warnings about masking and `?plot3d` will bring up a dialogue asking
>> which version of the help you want to read.
>>
>> Part of me thinks it would be better if there was a mechanism whereby
>> a generic will just work if package foo imports that generic and
>> exports a method for it.
>
>
> Either I am messing up something again (reasonably likely) or it does just
> work with S4 methods. I can import the namespace that has the generic and
> the methods work, I do not seem to need to export the generic.  Is S3
> working differently? I do have the documentation problem when I try to
> export other imported functions that I would like available to users.
>
> Paul
>
>>
>> Cheers,
>>
>> G
>>
>> On 26 August 2013 09:42, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>
>>> On Mon, Aug 26, 2013 at 1:28 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
>>>>
>>>> I think rgl should be in Depends.  You are providing a method for a
>>>> generic function from another package. In order to use your method, you
>>>> want the user to be able to call the generic function without scoping
>>>> (i.e. without calling rgl::plot3d), so the generic should be on the
>>>> search path, so the package that provides it should be listed in Depends
>>>> in the NAMESPACE file.
>>>
>>>
>>> You can re-export an imported object, but it has to be done via an
>>> explicit export(), cf. "It is possible to export variables from a
>>> namespace which it has imported from other namespaces: this has to be
>>> done explicitly and not via exportPattern" [Writing R Extensions].
>>>
>>> /H
>>>
>>>>
>>>> Martyn
>>>>
>>>> On Fri, 2013-08-23 at 22:01 -0600, Gavin Simpson wrote:
>>>>>
>>>>> Dear List,
>>>>>
>>>>> In one of my packages I have an S3 method for the plot3d generic
>>>>> function from package rgl. I am trying to streamline my Depends
>>>>> entries but don't know how to have
>>>>>
>>>>> plot3d(foo)
>>>>>
>>>>> in the examples section for the plot3d method in my package, without
>>>>> rgl being in Depends.
>>>>>
>>>>> Note that I importFrom(rgl, plotd3d) and register my S3 method via
>>>>> S3Method() in the NAMESPACE.
>>>>>
>>>>> If rgl is not in Depends but in Imports, I see this when checking the
>>>>> package
>>>>>
>>>>>> ## 3D plot of data with curve superimposed
>>>>>> plot3d(aber.pc, abernethy2)
>>>>>
>>>>> Error: could not find function "plot3d"
>>>>>
>>>>> I presume this is because rgl's namespace is only loaded but the
>>>>> package is not attached to the search path.
>>>>>
>>>>> Writing R extensions indicates that one can export from a namespace
>>>>> something that was imported from another package namespace. I thought
>>>>> that might help the situation, and now the code doesn't raise an
>>>>> error, I get
>>>>>
>>>>> * checking for missing documentation entries ... WARNING
>>>>> Undocumented code objects:
>>>>>    ?plot3d?
>>>>> All user-level objects in a package should have documentation entries.
>>>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>>>> Extensions? manual.
>>>>>
>>>>> as I don't document plot3d() itself.
>>>>>
>>>>> What is the recommended combination of Depends and Imports plus
>>>>> NAMESPACE directives etc that one should use in this situation? Or am
>>>>> I missing something else?
>>>>>
>>>>> I have a similar issue with my package including an S3 method for a
>>>>> generic in the lattice package, so if possible I could get rid of both
>>>>> of these from Depends if I can solve the above issue.
>>>>>
>>>>> Thanks in advance.
>>>>>
>>>>> Gavin
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>



-- 
Gavin Simpson, PhD


From hb at biostat.ucsf.edu  Mon Aug 26 21:55:50 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 26 Aug 2013 12:55:50 -0700
Subject: [Rd] legitimate use of :::
In-Reply-To: <CAC2h7us=Duy3L8N5H--hfyOx__-Yp+uiYxV7YY6eK==Tisw1Gg@mail.gmail.com>
References: <CANROs4dyoRyjoVHZLs7wDrFrjVX-1zvTTv2i4tBzF3f6Rx-XTA@mail.gmail.com>
	<5215F9BD.5030009@statistik.tu-dortmund.de> <52165F15.1090500@yorku.ca>
	<CABdHhvENvyTD6dPtbQzNaGqgwHNtV86juZh=5F7oBQSPJhO1Rw@mail.gmail.com>
	<CADwqtCNSE=-S9r97WcGL=bKosMnTx6KddPc08Tj_kLNPTN3i+Q@mail.gmail.com>
	<CAJoaRhamc8VRm2DYAKCzQUJA7DO4ypwvP6w_XkDWmCFOAwMDgg@mail.gmail.com>
	<CAC2h7us=Duy3L8N5H--hfyOx__-Yp+uiYxV7YY6eK==Tisw1Gg@mail.gmail.com>
Message-ID: <CAFDcVCQ5iB32tzYjvz6USJsBRWxpVO=L8gp01pN79sfLLFhdmQ@mail.gmail.com>

On Sat, Aug 24, 2013 at 9:46 AM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
> On Thu, Aug 22, 2013 at 8:27 PM, Peter Meilstrup Using ::: on a package you
> don't control can be more dangerous. For a
>>
>> package author to choose to export a function to the public interface
>> represents at least some assurance that that interface will be stable or
>> slow-moving. But there are no implied assurances about how code in the
>> private namespace might change behind the scenes. I might completely
>> refactor the code and change the behavior of any private function between
>> 0.0.1 releases, but I would not do that for exported functions.
>
>
> This is true (that it could be dangerous), but sometimes, as a package
> author, I am willing to take this risk.  Personally, I don't do this
> lightly, but sometimes there is no way around it, particular if the hidden
> function does some magic in its own NAMESPACE.  It is not all functions
> that one can just easily copy over into you own package.
>
> It is fine to say that the use of ::: should be discouraged, it is another
> thing if it prevents you from submitting to CRAN (which I don't know for
> sure; I thought that Notes were ok?).

Closely related and particularly on which NOTEs are CRAN show stoppers
and which are not:

I find 'R CMD check' extremely useful and I believe it has greatly
improved the quality of R and contributed packages including mine.
The more checks/tests the better.  No doubt about that.   Keeping in
mind the famous statement that "R is not CRAN" (or is it "CRAN is not
R"), and knowing there is great overlap between R core and CRAN team
members, it is still not easy to distinguish between what is R and
what is CRAN and where they're heading.  The CRAN Repository Policy
[http://cran.r-project.org/web/packages/policies.html ; very useful
addition] is very clear on 'R CMD check --as-cran' WARNINGs and
ERRORs, but for NOTEs it leaves room for interpretation.  For
instance, it mentions that package with "significant notes" needs to
be updated, but from experience I'd say it's up to the package
developer to guess what CRAN means by "significant notes".  It also
gives sends the message that there is some leeway for the developer to
publish a package with ("regular"?) NOTEs as long as s/he has
considered their implications [cf. "If there are warnings or notes you
cannot eliminate (for example because you believe them to be spurious)
send an explanatory note as part of your covering email, or as a
comment on the submission form."].   Unfortunately you won't find out
until submission, which seems a waste of time for both the developer
and CRAN.

If CRAN accept certain 'R CMD check --as-cran' NOTEs but not others,
may I propose some kind of mechanism to '--as-cran' that
grep()/grep(invert=TRUE) which NOTEs are significant/non-significant
for CRAN submissions/updates?  That may be too much work to be
exhaustive, but at least the ones that, to CRAN, are obviously
rejected/accepted would be helpful.  With 4700+ packages of CRAN with
lots of daily submissions/updates, the CRAN team has a much better
idea what's accepted or not, than each individual developer.

If it is the case that CRAN consider the majority of the NOTEs to be
"significant", I propose to clarify/be explicit about that in the CRAN
Repository Policy document.

...and finally, thanks to the CRAN team [if they read this] for the
work they put in daily.

/Henrik

PS. I am aware that proposals to CRAN should be sent to CRAN, but it's
useful to have this discussion among R developers before going
one-on-one with CRAN.  If there is an agreement on the above, I'll
send it off to the CRAN team.

>
> Best,
> Kasper
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gianluca.mastrantonio at yahoo.it  Tue Aug 27 14:14:47 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Tue, 27 Aug 2013 14:14:47 +0200
Subject: [Rd] Error in simulation. NAN
Message-ID: <521C9837.9000701@yahoo.it>

Hi all,

im triyng to implement a bayesian model with R and c++.
I have a strange problem. I can't reproduce the error with a small 
script and then i post the original one.
The problem is after the line

       for(MCMC_iter2=0;MCMC_iter2<thin;MCMC_iter2++)

For the first 34 iterations all work fine, after,  all the simulations 
of mu_acc_P return an "nan". If i delete the line

alpha_acc_P[0] = rnorm(app1_3,sqrt(app1_4)  );

the simulations of mu_acc_P  work fine. For me it is really strange,

Thanks!.


#include <iostream>
#include <string>
using namespace std;

#include <R.h>
#include <Rinternals.h>
#include <R_ext/Linpack.h>
#include <R_ext/Lapack.h>
#include <R_ext/BLAS.h>
#include "funzioni.h"
#define _USE_MATH_DEFINES
extern "C" {
     SEXP Model1_imp11Cpp(
   SEXP ad_start_r, SEXP ad_end_r, SEXP ad_esp_r,
   SEXP burnin_r, SEXP thin_r,SEXP iter_1_r,SEXP iter_2_r,
   SEXP n_j_r,SEXP J_r,
   SEXP prior_alpha_r,SEXP prior_rho_r,SEXP prior_sigma2_r,SEXP 
prior_phi_r,SEXP prior_zeta2_r,
   SEXP sdprop_rho_r,SEXP sdprop_sigma2_r,
   SEXP start_alpha_r,SEXP start_mu_r,SEXP start_rho_r,SEXP 
start_sigma2_r,SEXP start_k_r,SEXP start_phi_r, SEXP start_zeta2_r,
   SEXP x_r,SEXP H_r, SEXP acceptratio_r
   // SEXP Sigma_adapt_sp_r, SEXP mean_adapt_sp_r, SEXP sim_acc_sp_r, 
SEXP ep_sp_r, SEXP acc_index_sp_r,
   // SEXP Sigma_adapt_k_r, SEXP mean_adapt_k_r, SEXP sim_acc_k_r, SEXP 
ep_k_r, SEXP acc_index_k_r
   //
   ){

     /*****************************************
                 Varie ed eventuali
     *****************************************/
     // indici
     int i,j,k,l,h,t,f,info,MCMC_iter,MCMC_iter2;
     int nProtect= 0;
     int indice_adapt=0;
     double duepi = (2*M_PI);
     // costanti
     char const *lower = "L";
     char const *upper = "U";
     char const *ntran = "N";
     char const *ytran = "T";
     char const *rside = "R";
     char const *lside = "L";
     const double one = 1.0;
     const double negOne = -1.0;
     const double zero = 0.0;
     const int incOne = 1;


     /*****************************************
                      Set-up
     *****************************************/

     double *x_P      = REAL(x_r);
     int n_j          = INTEGER(n_j_r)[0];
     int J            = INTEGER(J_r)[0];
     int N             = n_j*J;
     int iter_1       = INTEGER(iter_1_r)[0];
     int iter_2       = INTEGER(iter_2_r)[0];
     int burnin       = INTEGER(burnin_r)[0];
     int thin         = INTEGER(thin_r)[0];
     int ad_start     = INTEGER(ad_start_r)[0];
     int ad_end       = INTEGER(ad_end_r)[0];
     double *ad_esp_P = REAL(ad_esp_r);
     double *acceptratio_P = REAL(acceptratio_r);
     double *H_P      = REAL(H_r);
     // int nSamples_save = INTEGER(nSamples_save_r)[0];
     // PRIOR
     double *prior_alpha   = REAL(prior_alpha_r);
     double M_alpha = prior_alpha[0];  double sigma2_alpha = 
prior_alpha[1];
     double *prior_rho     = REAL(prior_rho_r);
     double a_rho = prior_rho[0];    double b_rho = prior_rho[1];
     double *prior_sigma2  = REAL(prior_sigma2_r);
     double a_sigma2 = prior_sigma2[0];  double b_sigma2 = prior_sigma2[1];
     double *prior_zeta2   = REAL(prior_zeta2_r);
     double a_zeta2 = prior_zeta2[0];  double b_zeta2 = prior_zeta2[1];
     double *prior_phi   = REAL(prior_phi_r);
     double M_phi= prior_phi[0];  double sigma2_phi = prior_phi[1];
     double lim_down= prior_phi[2];  double lim_up = prior_phi[3];

     // PROPOSAL
     double *sdprop_rho  = REAL(sdprop_rho_r);
     double sd_rho  = sdprop_rho[0];
     double *sdprop_sigma2  = REAL(sdprop_sigma2_r);
     double sd_sigma2  = sdprop_sigma2[0];

     // STARTING
     double *start_alpha_P  = REAL(start_alpha_r);
     double start_alpha     = start_alpha_P[0];
     double *start_mu_P     = REAL(start_mu_r);

     // for(j=0;j<J;j++)
     // {
     //     start_mu[j] =  start_mu_P+j) ;
     // }
     double *start_phi_P    = REAL(start_phi_r);
     double start_phi       = start_phi_P[0];
     double *start_rho_P    = REAL(start_rho_r);
     double start_rho       = start_rho_P[0];
     double *start_sigma2_P = REAL(start_sigma2_r);
     double start_sigma2    = start_sigma2_P[0];
     double *start_zeta2_P  = REAL(start_zeta2_r);
     double start_zeta2     = start_zeta2_P[0];
     double *start_k_P       = REAL(start_k_r);
     double start_k[N-1];
     for(j=0;j<N;j++)
     {
         start_k[j] =  *(start_k_P+j) ;
     }

     /*****************************************
                 Varie ed eventuali II
     *****************************************/
     const int incJ    = J;
     const int incN    = N;
     const int nn_j    = n_j*n_j;
     const int inc4    = 4;
     const int inc2    = 2;

     double app1_1, app1_2, app1_3, app1_4;
     double appn_j_1[n_j];
     double app_uno_n_j[n_j];
     for(i=0;i<n_j;i++)
     {
       app_uno_n_j[i] = 1;
     }

     int nSamples_save = iter_2;
     // generatore random
     GetRNGstate();

     // /*****************************************
     // //  UPDATE PARAMETRI
     // *****************************************/

     // alpha
     double *alpha_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_alpha_P, &incOne, alpha_acc_P, &incOne);
     // mu_acc
     double *mu_acc_P = (double *) R_alloc(J, sizeof(double));
     F77_NAME(dcopy)(&incJ, start_mu_P, &incOne, mu_acc_P, &incOne);
     // phi
     double *phi_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_phi_P, &incOne, phi_acc_P, &incOne);
     // zeta2
     double *zeta2_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_zeta2_P, &incOne, zeta2_acc_P, &incOne);
     // sigma2
     double *sigma2_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_sigma2_P, &incOne, sigma2_acc_P, 
&incOne);
     // rho
     double *rho_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_rho_P, &incOne, rho_acc_P, &incOne);
     // k
     double *k_acc_P = (double *) R_alloc(n_j*J, sizeof(double));
     F77_NAME(dcopy)(&incN, start_k_P, &incOne, k_acc_P, &incOne);

     // variabili di appoggio per i parametri
     double *mu_app_P = (double *) R_alloc(J, sizeof(double));
     F77_NAME(dcopy)(&incJ, start_mu_P, &incOne, mu_app_P, &incOne);

     /*****************************************
     //  OUTPUT di R
     *****************************************/

     SEXP mu_out_r,alpha_out_r;

     PROTECT(mu_out_r   = allocMatrix(REALSXP, J, nSamples_save)); 
nProtect++;
     double *mu_out_P = REAL(mu_out_r);
     PROTECT(alpha_out_r   = allocMatrix(REALSXP, 1, nSamples_save)); 
nProtect++;
     double *alpha_out_P = REAL(alpha_out_r);
     //
    // PROTECT(accept_r = allocMatrix(REALSXP, 1, 1)); nProtect++;

     /*****************************************
                 Varie ed eventuali III
     *****************************************/

     // MATRICI COVARIANZA E AFFINI
     double *C_P          = (double *) R_alloc(nn_j, sizeof(double));
     double *C_cand_P     = (double *) R_alloc(nn_j, sizeof(double));
     double Sum_Sigma_inv;
     double Sigma_inv_one[n_j-1];
     double logdet;

     //


     // /*****************************************
     // //  PARAMETRI PARTE ADATTIVA
     // *****************************************/

     // /*****************************************
     // //  STARTING MCMC
     // *****************************************/

     // MATRICE DI COVARIANZA
     covexp(rho_acc_P[0], C_P, H_P, nn_j);
     F77_NAME(dscal)(&nn_j, &sigma2_acc_P[0], C_P, &incOne);

     //invert C and log det cov
     F77_NAME(dpotrf)(upper, &n_j, C_P, &n_j, &info); if(info != 0)
     {
       error("c++ error:    Cholesky failed in sp.lm (N1)\n");
     }
     // adesso C contiene la parte superiore dellafattorizzazione di 
cholesky
     logdet = 0.0;
     for(i = 0; i < n_j; i++) logdet += 2*log(C_P[i*n_j+i]);
     F77_NAME(dpotri)(upper, &n_j, C_P, &n_j, &info);
     if(info != 0)
     {
         error("c++ error: Cholesky inverse failed in sp.lm (N2)\n");
     }
     for(j=0;j<n_j-1;j++)
     {
       for(h=j+1;h<n_j;h++)
       {
         Sum_Sigma_inv +=  C_P[j*n_j+h] ;
       }
     }
     Sum_Sigma_inv = Sum_Sigma_inv*2;
     for(j=0;j<n_j;j++){Sum_Sigma_inv += C_P[j*n_j+j];}

     for(j=0;j<n_j;j++)
     {
       Sigma_inv_one[j] = 0;
       for(h=0;h<n_j;h++)
       {
         Sigma_inv_one[j]  +=  C_P[j*n_j+h];
       }
     }

     // /*****************************************
     // // MCMC
     // *****************************************/

     for(MCMC_iter=0;MCMC_iter<iter_1;MCMC_iter++)
     {

     }

     for(MCMC_iter=0;MCMC_iter<iter_2;MCMC_iter++)
     {
       for(MCMC_iter2=0;MCMC_iter2<thin;MCMC_iter2++)
       {
           indice_adapt += 1;

           /************  SIMULAZIONE MU **********/
           F77_NAME(dcopy)(&incJ, mu_acc_P, &incOne, mu_app_P, &incOne);

           // mu_1
           app1_2 = 
1/((1+pow(phi_acc_P[0],2))/zeta2_acc_P[0]+Sum_Sigma_inv);
           app1_1 = phi_acc_P[0]*mu_app_P[1]/zeta2_acc_P[0];

           for(t=0; t<n_j;t++)
           {
             app1_1 += 
Sigma_inv_one[t]*(x_P[t]+2*M_PI*k_acc_P[t]-alpha_acc_P[0]);
           }

           app1_1 = app1_1*app1_2;

           mu_acc_P[0] = rnorm(app1_1,sqrt(app1_2));
           for(j=1;j<J-1; j++)
           {
               // mu_j
               app1_1 = 
(phi_acc_P[0]*mu_app_P[j-1]+phi_acc_P[0]*mu_app_P[j+1])/zeta2_acc_P[0];
               for(t=0; t<n_j;t++)
               {
                 app1_1 += 
Sigma_inv_one[t]*(x_P[t+n_j*j]+2*M_PI*k_acc_P[t+n_j*j]-alpha_acc_P[0]);
               }
               app1_1 = app1_1*app1_2;
               mu_acc_P[j] = rnorm(app1_1,sqrt(app1_2));
           }
           // // mu_J
           app1_2 = 1/(1/zeta2_acc_P[0]+Sum_Sigma_inv);
           app1_1 = phi_acc_P[0]*mu_app_P[J-2]/zeta2_acc_P[0];
           for(t=0; t<n_j;t++)
           {
             app1_1 += 
Sigma_inv_one[t]*(x_P[t+n_j*(J-1)]+2*M_PI*k_acc_P[t+n_j*(J-1)]-alpha_acc_P[0]);
           }
           app1_1 = app1_1*app1_2;
           mu_acc_P[J-1] = rnorm(app1_1,sqrt(app1_2));

            /************  SIMULAZIONE alpha **********/
           app1_3    = 1/(J*Sum_Sigma_inv+sigma2_alpha);
           app1_4    = M_alpha;
           for(t=0;t<n_j;t++)
           {
             for(j=0;j<J;j++)
             {
               app1_4 += 
Sigma_inv_one[t]*(x_P[t+n_j*j]+2*M_PI*k_acc_P[t+n_j*j]-mu_app_P[j]);
             }
           }
           app1_4 = app1_4*app1_3;

          alpha_acc_P[0] = rnorm(app1_3,sqrt(app1_4)  );


       }






       /************  SALVO LE VARIABILI **********/
       F77_NAME(dcopy)(&incJ, mu_acc_P, &incOne, &mu_out_P[MCMC_iter*J], 
&incOne);
       F77_NAME(dcopy)(&incOne, alpha_acc_P, &incOne, 
&alpha_out_P[MCMC_iter], &incOne);
     }

    //make return object
     SEXP result,resultNames;

     // oggetti della lista
     int nResultListObjs = 2;

     PROTECT(result = allocVector(VECSXP, nResultListObjs)); nProtect++;
     PROTECT(resultNames = allocVector(VECSXP, nResultListObjs)); 
nProtect++;



     //samples
     SET_VECTOR_ELT(result, 0, mu_out_r);
     SET_VECTOR_ELT(resultNames, 0, mkChar("mu"));
     SET_VECTOR_ELT(result, 1, alpha_out_r);
     SET_VECTOR_ELT(resultNames, 1, mkChar("alpha"));
     namesgets(result, resultNames);

     //unprotect
     UNPROTECT(nProtect);

     return(result);

   //return(R_NilValue);

     }
}


From Martyn.Byng at nag.co.uk  Tue Aug 27 15:14:12 2013
From: Martyn.Byng at nag.co.uk (Martyn Byng)
Date: Tue, 27 Aug 2013 14:14:12 +0100
Subject: [Rd] Error in simulation. NAN
References: <521C9837.9000701@yahoo.it>
Message-ID: <49E76DF37649DC48A4CE882BC8CE51C9031AFB91@nagmail2.nag.co.uk>

Hi,

You are going to have to track down exactly where the NaN is being
produced. These usually occur due to performing invalid numerical
operations, like trying to take the square-root of a negative number,
trying to calculate 0/0 etc.

Try adding a series of if / then blocks prior to performing any
operation that could result in a NaN, so something like: 

if (app1_4 <= 0.0) {
  error("app1_4 is -ve");
} else {
          alpha_acc_P[0] = rnorm(app1_3,sqrt(app1_4)  );
}

this should then give you a better idea of what is going wrong.

Martyn

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of
gianluca.mastrantonio at yahoo.it
Sent: 27 August 2013 13:15
To: r-devel at r-project.org
Subject: [Rd] Error in simulation. NAN

Hi all,

im triyng to implement a bayesian model with R and c++.
I have a strange problem. I can't reproduce the error with a small
script and then i post the original one.
The problem is after the line

       for(MCMC_iter2=0;MCMC_iter2<thin;MCMC_iter2++)

For the first 34 iterations all work fine, after,  all the simulations
of mu_acc_P return an "nan". If i delete the line

alpha_acc_P[0] = rnorm(app1_3,sqrt(app1_4)  );

the simulations of mu_acc_P  work fine. For me it is really strange,

Thanks!.


#include <iostream>
#include <string>
using namespace std;

#include <R.h>
#include <Rinternals.h>
#include <R_ext/Linpack.h>
#include <R_ext/Lapack.h>
#include <R_ext/BLAS.h>
#include "funzioni.h"
#define _USE_MATH_DEFINES
extern "C" {
     SEXP Model1_imp11Cpp(
   SEXP ad_start_r, SEXP ad_end_r, SEXP ad_esp_r,
   SEXP burnin_r, SEXP thin_r,SEXP iter_1_r,SEXP iter_2_r,
   SEXP n_j_r,SEXP J_r,
   SEXP prior_alpha_r,SEXP prior_rho_r,SEXP prior_sigma2_r,SEXP
prior_phi_r,SEXP prior_zeta2_r,
   SEXP sdprop_rho_r,SEXP sdprop_sigma2_r,
   SEXP start_alpha_r,SEXP start_mu_r,SEXP start_rho_r,SEXP
start_sigma2_r,SEXP start_k_r,SEXP start_phi_r, SEXP start_zeta2_r,
   SEXP x_r,SEXP H_r, SEXP acceptratio_r
   // SEXP Sigma_adapt_sp_r, SEXP mean_adapt_sp_r, SEXP sim_acc_sp_r,
SEXP ep_sp_r, SEXP acc_index_sp_r,
   // SEXP Sigma_adapt_k_r, SEXP mean_adapt_k_r, SEXP sim_acc_k_r, SEXP
ep_k_r, SEXP acc_index_k_r
   //
   ){

     /*****************************************
                 Varie ed eventuali
     *****************************************/
     // indici
     int i,j,k,l,h,t,f,info,MCMC_iter,MCMC_iter2;
     int nProtect= 0;
     int indice_adapt=0;
     double duepi = (2*M_PI);
     // costanti
     char const *lower = "L";
     char const *upper = "U";
     char const *ntran = "N";
     char const *ytran = "T";
     char const *rside = "R";
     char const *lside = "L";
     const double one = 1.0;
     const double negOne = -1.0;
     const double zero = 0.0;
     const int incOne = 1;


     /*****************************************
                      Set-up
     *****************************************/

     double *x_P      = REAL(x_r);
     int n_j          = INTEGER(n_j_r)[0];
     int J            = INTEGER(J_r)[0];
     int N             = n_j*J;
     int iter_1       = INTEGER(iter_1_r)[0];
     int iter_2       = INTEGER(iter_2_r)[0];
     int burnin       = INTEGER(burnin_r)[0];
     int thin         = INTEGER(thin_r)[0];
     int ad_start     = INTEGER(ad_start_r)[0];
     int ad_end       = INTEGER(ad_end_r)[0];
     double *ad_esp_P = REAL(ad_esp_r);
     double *acceptratio_P = REAL(acceptratio_r);
     double *H_P      = REAL(H_r);
     // int nSamples_save = INTEGER(nSamples_save_r)[0];
     // PRIOR
     double *prior_alpha   = REAL(prior_alpha_r);
     double M_alpha = prior_alpha[0];  double sigma2_alpha =
prior_alpha[1];
     double *prior_rho     = REAL(prior_rho_r);
     double a_rho = prior_rho[0];    double b_rho = prior_rho[1];
     double *prior_sigma2  = REAL(prior_sigma2_r);
     double a_sigma2 = prior_sigma2[0];  double b_sigma2 =
prior_sigma2[1];
     double *prior_zeta2   = REAL(prior_zeta2_r);
     double a_zeta2 = prior_zeta2[0];  double b_zeta2 = prior_zeta2[1];
     double *prior_phi   = REAL(prior_phi_r);
     double M_phi= prior_phi[0];  double sigma2_phi = prior_phi[1];
     double lim_down= prior_phi[2];  double lim_up = prior_phi[3];

     // PROPOSAL
     double *sdprop_rho  = REAL(sdprop_rho_r);
     double sd_rho  = sdprop_rho[0];
     double *sdprop_sigma2  = REAL(sdprop_sigma2_r);
     double sd_sigma2  = sdprop_sigma2[0];

     // STARTING
     double *start_alpha_P  = REAL(start_alpha_r);
     double start_alpha     = start_alpha_P[0];
     double *start_mu_P     = REAL(start_mu_r);

     // for(j=0;j<J;j++)
     // {
     //     start_mu[j] =  start_mu_P+j) ;
     // }
     double *start_phi_P    = REAL(start_phi_r);
     double start_phi       = start_phi_P[0];
     double *start_rho_P    = REAL(start_rho_r);
     double start_rho       = start_rho_P[0];
     double *start_sigma2_P = REAL(start_sigma2_r);
     double start_sigma2    = start_sigma2_P[0];
     double *start_zeta2_P  = REAL(start_zeta2_r);
     double start_zeta2     = start_zeta2_P[0];
     double *start_k_P       = REAL(start_k_r);
     double start_k[N-1];
     for(j=0;j<N;j++)
     {
         start_k[j] =  *(start_k_P+j) ;
     }

     /*****************************************
                 Varie ed eventuali II
     *****************************************/
     const int incJ    = J;
     const int incN    = N;
     const int nn_j    = n_j*n_j;
     const int inc4    = 4;
     const int inc2    = 2;

     double app1_1, app1_2, app1_3, app1_4;
     double appn_j_1[n_j];
     double app_uno_n_j[n_j];
     for(i=0;i<n_j;i++)
     {
       app_uno_n_j[i] = 1;
     }

     int nSamples_save = iter_2;
     // generatore random
     GetRNGstate();

     // /*****************************************
     // //  UPDATE PARAMETRI
     // *****************************************/

     // alpha
     double *alpha_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_alpha_P, &incOne, alpha_acc_P,
&incOne);
     // mu_acc
     double *mu_acc_P = (double *) R_alloc(J, sizeof(double));
     F77_NAME(dcopy)(&incJ, start_mu_P, &incOne, mu_acc_P, &incOne);
     // phi
     double *phi_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_phi_P, &incOne, phi_acc_P, &incOne);
     // zeta2
     double *zeta2_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_zeta2_P, &incOne, zeta2_acc_P,
&incOne);
     // sigma2
     double *sigma2_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_sigma2_P, &incOne, sigma2_acc_P,
&incOne);
     // rho
     double *rho_acc_P = (double *) R_alloc(1, sizeof(double));
     F77_NAME(dcopy)(&incOne, start_rho_P, &incOne, rho_acc_P, &incOne);
     // k
     double *k_acc_P = (double *) R_alloc(n_j*J, sizeof(double));
     F77_NAME(dcopy)(&incN, start_k_P, &incOne, k_acc_P, &incOne);

     // variabili di appoggio per i parametri
     double *mu_app_P = (double *) R_alloc(J, sizeof(double));
     F77_NAME(dcopy)(&incJ, start_mu_P, &incOne, mu_app_P, &incOne);

     /*****************************************
     //  OUTPUT di R
     *****************************************/

     SEXP mu_out_r,alpha_out_r;

     PROTECT(mu_out_r   = allocMatrix(REALSXP, J, nSamples_save)); 
nProtect++;
     double *mu_out_P = REAL(mu_out_r);
     PROTECT(alpha_out_r   = allocMatrix(REALSXP, 1, nSamples_save)); 
nProtect++;
     double *alpha_out_P = REAL(alpha_out_r);
     //
    // PROTECT(accept_r = allocMatrix(REALSXP, 1, 1)); nProtect++;

     /*****************************************
                 Varie ed eventuali III
     *****************************************/

     // MATRICI COVARIANZA E AFFINI
     double *C_P          = (double *) R_alloc(nn_j, sizeof(double));
     double *C_cand_P     = (double *) R_alloc(nn_j, sizeof(double));
     double Sum_Sigma_inv;
     double Sigma_inv_one[n_j-1];
     double logdet;

     //


     // /*****************************************
     // //  PARAMETRI PARTE ADATTIVA
     // *****************************************/

     // /*****************************************
     // //  STARTING MCMC
     // *****************************************/

     // MATRICE DI COVARIANZA
     covexp(rho_acc_P[0], C_P, H_P, nn_j);
     F77_NAME(dscal)(&nn_j, &sigma2_acc_P[0], C_P, &incOne);

     //invert C and log det cov
     F77_NAME(dpotrf)(upper, &n_j, C_P, &n_j, &info); if(info != 0)
     {
       error("c++ error:    Cholesky failed in sp.lm (N1)\n");
     }
     // adesso C contiene la parte superiore dellafattorizzazione di
cholesky
     logdet = 0.0;
     for(i = 0; i < n_j; i++) logdet += 2*log(C_P[i*n_j+i]);
     F77_NAME(dpotri)(upper, &n_j, C_P, &n_j, &info);
     if(info != 0)
     {
         error("c++ error: Cholesky inverse failed in sp.lm (N2)\n");
     }
     for(j=0;j<n_j-1;j++)
     {
       for(h=j+1;h<n_j;h++)
       {
         Sum_Sigma_inv +=  C_P[j*n_j+h] ;
       }
     }
     Sum_Sigma_inv = Sum_Sigma_inv*2;
     for(j=0;j<n_j;j++){Sum_Sigma_inv += C_P[j*n_j+j];}

     for(j=0;j<n_j;j++)
     {
       Sigma_inv_one[j] = 0;
       for(h=0;h<n_j;h++)
       {
         Sigma_inv_one[j]  +=  C_P[j*n_j+h];
       }
     }

     // /*****************************************
     // // MCMC
     // *****************************************/

     for(MCMC_iter=0;MCMC_iter<iter_1;MCMC_iter++)
     {

     }

     for(MCMC_iter=0;MCMC_iter<iter_2;MCMC_iter++)
     {
       for(MCMC_iter2=0;MCMC_iter2<thin;MCMC_iter2++)
       {
           indice_adapt += 1;

           /************  SIMULAZIONE MU **********/
           F77_NAME(dcopy)(&incJ, mu_acc_P, &incOne, mu_app_P, &incOne);

           // mu_1
           app1_2 =
1/((1+pow(phi_acc_P[0],2))/zeta2_acc_P[0]+Sum_Sigma_inv);
           app1_1 = phi_acc_P[0]*mu_app_P[1]/zeta2_acc_P[0];

           for(t=0; t<n_j;t++)
           {
             app1_1 +=
Sigma_inv_one[t]*(x_P[t]+2*M_PI*k_acc_P[t]-alpha_acc_P[0]);
           }

           app1_1 = app1_1*app1_2;

           mu_acc_P[0] = rnorm(app1_1,sqrt(app1_2));
           for(j=1;j<J-1; j++)
           {
               // mu_j
               app1_1 =
(phi_acc_P[0]*mu_app_P[j-1]+phi_acc_P[0]*mu_app_P[j+1])/zeta2_acc_P[0];
               for(t=0; t<n_j;t++)
               {
                 app1_1 +=
Sigma_inv_one[t]*(x_P[t+n_j*j]+2*M_PI*k_acc_P[t+n_j*j]-alpha_acc_P[0]);
               }
               app1_1 = app1_1*app1_2;
               mu_acc_P[j] = rnorm(app1_1,sqrt(app1_2));
           }
           // // mu_J
           app1_2 = 1/(1/zeta2_acc_P[0]+Sum_Sigma_inv);
           app1_1 = phi_acc_P[0]*mu_app_P[J-2]/zeta2_acc_P[0];
           for(t=0; t<n_j;t++)
           {
             app1_1 +=
Sigma_inv_one[t]*(x_P[t+n_j*(J-1)]+2*M_PI*k_acc_P[t+n_j*(J-1)]-alpha_acc
_P[0]);
           }
           app1_1 = app1_1*app1_2;
           mu_acc_P[J-1] = rnorm(app1_1,sqrt(app1_2));

            /************  SIMULAZIONE alpha **********/
           app1_3    = 1/(J*Sum_Sigma_inv+sigma2_alpha);
           app1_4    = M_alpha;
           for(t=0;t<n_j;t++)
           {
             for(j=0;j<J;j++)
             {
               app1_4 +=
Sigma_inv_one[t]*(x_P[t+n_j*j]+2*M_PI*k_acc_P[t+n_j*j]-mu_app_P[j]);
             }
           }
           app1_4 = app1_4*app1_3;

          alpha_acc_P[0] = rnorm(app1_3,sqrt(app1_4)  );


       }






       /************  SALVO LE VARIABILI **********/
       F77_NAME(dcopy)(&incJ, mu_acc_P, &incOne, &mu_out_P[MCMC_iter*J],
&incOne);
       F77_NAME(dcopy)(&incOne, alpha_acc_P, &incOne,
&alpha_out_P[MCMC_iter], &incOne);
     }

    //make return object
     SEXP result,resultNames;

     // oggetti della lista
     int nResultListObjs = 2;

     PROTECT(result = allocVector(VECSXP, nResultListObjs)); nProtect++;
     PROTECT(resultNames = allocVector(VECSXP, nResultListObjs)); 
nProtect++;



     //samples
     SET_VECTOR_ELT(result, 0, mu_out_r);
     SET_VECTOR_ELT(resultNames, 0, mkChar("mu"));
     SET_VECTOR_ELT(result, 1, alpha_out_r);
     SET_VECTOR_ELT(resultNames, 1, mkChar("alpha"));
     namesgets(result, resultNames);

     //unprotect
     UNPROTECT(nProtect);

     return(result);

   //return(R_NilValue);

     }
}

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:12}}


From bbolker at gmail.com  Tue Aug 27 19:32:12 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Aug 2013 13:32:12 -0400
Subject: [Rd] possible tweaking of family()$simulate?
Message-ID: <521CE29C.6010503@gmail.com>


   This should probably be submitted eventually as a wishlist to R-core,
as it requires (minor) changes to base R, but I thought I would float it
here first ...

  In a package, I construct glm()-like model objects that have 'family'
components based on the GLM family objects (binomial(), poisson(),
Gamma(), etc.).  I have written a 'simulate' method for these objects
that has basically had to re-code much of what's already contained in
the family()$simulate methods, because they are just a little bit too
hardcoded.  I can't just add list elements to my object, because it's
represented by an S4 class .......

  For example, poisson()$simulate contains references to

* object$prior.weights  -- could be replaced by weights(object) ?
* fitted(object) -- I would like to be able to substitute my own "mu"
value here, but I can hack around it (in a perfect world I would add a
third optional argument:

 $simulate <- function(object,nsim,ftd=fitted(object)) {
    ...
 }

  binomial()$simulate contains references to the above two components,
as well as a reference to object$model (which could be replaced by
model.frame(object)).

  inverse.gaussian()$simulate has a reference to
summary(object)$dispersion (this wouldn't be too hard)

  The required changes would be fairly minor, and as far as I can tell
completely backward compatible.  Of course I don't know if there's much
demand for it ... it would certainly be helpful for me, I don't know if
there is latent demand out there ...

  thoughts?
    Ben Bolker


From comaths at hotmail.com  Tue Aug 27 18:38:34 2013
From: comaths at hotmail.com (comaths)
Date: Tue, 27 Aug 2013 09:38:34 -0700 (PDT)
Subject: [Rd] Rename the package published on CRAN
Message-ID: <1377621514333-4674670.post@n4.nabble.com>

Hello Folks,

I have an R package published on CRAN and I want to rename it for the next
version, something like from "rName" to "rNAME". I have read the CRAN
policy, but did not find any topic regarding to this.  So does anybody know
whether there is any CRAN policy for this? Thanks!

Best,

C 



--
View this message in context: http://r.789695.n4.nabble.com/Rename-the-package-published-on-CRAN-tp4674670.html
Sent from the R devel mailing list archive at Nabble.com.


From sat3lite at gmail.com  Tue Aug 27 20:50:06 2013
From: sat3lite at gmail.com (Sana Wajid)
Date: Tue, 27 Aug 2013 14:50:06 -0400
Subject: [Rd] Minimum requirements for package submission
Message-ID: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130827/a6dd7e3a/attachment.pl>

From h.wickham at gmail.com  Wed Aug 28 15:37:32 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 08:37:32 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
Message-ID: <CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>

> 1. My functions are very basic. For example, getRoot gets the root of the
> current tree (APE phylo object) and getAncestor gets the ancestor to the
> current node:
>
> getRoot <- function(cur_Tree){
>     return(length(cur_Tree$tip.label)+1)
> }
>
> getAncestor <- function(cur_Node, cur_Tree){
> ...
> return(ancestor)
> }
>
> Is this okay or do I have to do anything else to submit the package? Later
> on (within the next few months) I would have time to convert these
> functions to S3/4 but at the moment the most important thing it to get it
> out there on CRAN.

As long as your package passes R CMD check --as-cran on the
development version of R, CRAN will be happy.  They do not generally
read your source code, and CRAN does not certify that your package is
useful or even correct - so you don't need to worry about what your
package does.

> 2. Does the vignette need to be written in latex or can I get away with
> writing all of the requirements in word? (I believe I've seen a vignette
> written in word -> pdf)

I don't think you can use word, but you can use Rmarkdown, which is
much simpler than latex.

> 3. Any other suggestions/links?

Make sure you read http://cran.r-project.org/web/packages/policies.html

Good luck!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Wed Aug 28 15:50:51 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 08:50:51 -0500
Subject: [Rd] RProf + memory profiling
Message-ID: <CABdHhvGbwcsg4uGnVftge+-jeJg-2-Qx4NXX2a5hu1pemMmYdg@mail.gmail.com>

Hi all,

RProf with memory profiling = TRUE provides a useful breakdown of R's
memory usage into small vectors, big vectors and nodes.  Is there a
way to get this information from the command line? gc() aggregates
small and big vectors into one number and (obviously) also does a gc.
Are there any other options?

Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From kw.stat at gmail.com  Wed Aug 28 16:01:41 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 28 Aug 2013 09:01:41 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
Message-ID: <CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130828/8b5c3457/attachment.pl>

From edd at debian.org  Wed Aug 28 16:26:57 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 28 Aug 2013 09:26:57 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
Message-ID: <21022.2225.867873.997588@max.nulle.part>


On 28 August 2013 at 09:01, Kevin Wright wrote:
|  Before knitr became an accepted engine for vignettes, I had a
| knitr-generated vignette that I included in a package.  It could just as
| easily have been a Word file saved as a pdf.  There was some trick to doing
| this (which I have forgotten).  Something like creating an extremely
| minimal .rnw file and then including the vignette with the same name and a
| .pdf extension.  Search the R-help mail archives and you can find other
| people who have included non-.rnw vignettes.

Sort of. Kinda. Maybe not quite. I think you may be assuming "constant
requirements" at the CRAN side.  They are anything but -- and to be plain,
that is a Good Thing (TM) in the long run.

The change to preferring vignettes/ over inst/doc/ is just one of many; there
is also an ongoing preference for vignettes that fully reproducible from
source. Which may eventually put an end to non-Rnw / non-(la)tex vignettes.

Related rant: I really wish we had "CHANGES" file, or a section in the
manuals. It is virtually impossible to look at a current "Writing R
Extensions" manual, and a previous one, in order to get a succinct view of
what changed.  Having to diff the NEWS files, or glancing at commit logs via
the RCS is a very poor proxy.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Wed Aug 28 16:41:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 28 Aug 2013 10:41:29 -0400
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <21022.2225.867873.997588@max.nulle.part>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
Message-ID: <521E0C19.8030306@gmail.com>

On 28/08/2013 10:26 AM, Dirk Eddelbuettel wrote:
> On 28 August 2013 at 09:01, Kevin Wright wrote:
> |  Before knitr became an accepted engine for vignettes, I had a
> | knitr-generated vignette that I included in a package.  It could just as
> | easily have been a Word file saved as a pdf.  There was some trick to doing
> | this (which I have forgotten).  Something like creating an extremely
> | minimal .rnw file and then including the vignette with the same name and a
> | .pdf extension.  Search the R-help mail archives and you can find other
> | people who have included non-.rnw vignettes.
>
> Sort of. Kinda. Maybe not quite. I think you may be assuming "constant
> requirements" at the CRAN side.  They are anything but -- and to be plain,
> that is a Good Thing (TM) in the long run.
>
> The change to preferring vignettes/ over inst/doc/ is just one of many; there
> is also an ongoing preference for vignettes that fully reproducible from
> source. Which may eventually put an end to non-Rnw / non-(la)tex vignettes.
>
> Related rant: I really wish we had "CHANGES" file, or a section in the
> manuals. It is virtually impossible to look at a current "Writing R
> Extensions" manual, and a previous one, in order to get a succinct view of
> what changed.  Having to diff the NEWS files, or glancing at commit logs via
> the RCS is a very poor proxy.

I don't understand the difference between the CHANGES file you are 
asking for and the NEWS file.  Do you want something in purely 
chronological order, rather than categorized as NEWS is?

Duncan Murdoch


From h.wickham at gmail.com  Wed Aug 28 16:44:49 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 09:44:49 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <521E0C19.8030306@gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part> <521E0C19.8030306@gmail.com>
Message-ID: <CABdHhvGaTkowxazL3i-HfsrPuWP_8rq4TOR=bWPKj8-vzdB8PA@mail.gmail.com>

>> Related rant: I really wish we had "CHANGES" file, or a section in the
>> manuals. It is virtually impossible to look at a current "Writing R
>> Extensions" manual, and a previous one, in order to get a succinct view of
>> what changed.  Having to diff the NEWS files, or glancing at commit logs
>> via
>> the RCS is a very poor proxy.
>
> I don't understand the difference between the CHANGES file you are asking
> for and the NEWS file.  Do you want something in purely chronological order,
> rather than categorized as NEWS is?

I think Dirk was talking about a CHANGES/NEWS file for "Writing R extensions"

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From edd at debian.org  Wed Aug 28 16:59:38 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 28 Aug 2013 09:59:38 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CABdHhvGaTkowxazL3i-HfsrPuWP_8rq4TOR=bWPKj8-vzdB8PA@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<521E0C19.8030306@gmail.com>
	<CABdHhvGaTkowxazL3i-HfsrPuWP_8rq4TOR=bWPKj8-vzdB8PA@mail.gmail.com>
Message-ID: <21022.4186.756519.269862@max.nulle.part>


On 28 August 2013 at 09:44, Hadley Wickham wrote:
| >> Related rant: I really wish we had "CHANGES" file, or a section in the
| >> manuals. It is virtually impossible to look at a current "Writing R
| >> Extensions" manual, and a previous one, in order to get a succinct view of
| >> what changed.  Having to diff the NEWS files, or glancing at commit logs
| >> via
| >> the RCS is a very poor proxy.
| >
| > I don't understand the difference between the CHANGES file you are asking
| > for and the NEWS file.  Do you want something in purely chronological order,
| > rather than categorized as NEWS is?
| 
| I think Dirk was talking about a CHANGES/NEWS file for "Writing R extensions"

Yup. In the sense of "something to look at to see what one may need to change".

Eg for Debian, the "Policy" document has a version number making discussion /
comparison and reference more tangible.  Also, if/when an update is made, an
'upgrade checklist' is provided -- see eg [1] for the most recent annoucement
[2] for the policy manual web presence, and [3] for the complete checklist
with a roll-back history.

I am not suggesting this exact format. I am merely pointing that it
(currently) takes a couple of extra steps to stay on top of required changes,
which in turn leads to everybody just uploading to CRAN as a trial, which in
turn overburdens the CRAN maintainers.  Seems suboptimal to me.

Dirk

[1] http://lists.debian.org/debian-devel-announce/2012/09/msg00006.html
[2] http://www.debian.org/doc/devel-manuals#policy    
[3] http://www.debian.org/doc/packaging-manuals/upgrading-checklist.txt

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ligges at statistik.tu-dortmund.de  Wed Aug 28 17:07:37 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Aug 2013 17:07:37 +0200
Subject: [Rd] Rename the package published on CRAN
In-Reply-To: <1377621514333-4674670.post@n4.nabble.com>
References: <1377621514333-4674670.post@n4.nabble.com>
Message-ID: <521E1239.3000801@statistik.tu-dortmund.de>

On 27.08.2013 18:38, comaths wrote:
> Hello Folks,
>
> I have an R package published on CRAN and I want to rename it for the next
> version, something like from "rName" to "rNAME". I have read the CRAN
> policy, but did not find any topic regarding to this.  So does anybody know
> whether there is any CRAN policy for this? Thanks!

Actually you cannot: CRAN had to archive rName at first, but then no 
other package with the name but different capitalization can be added to 
CRAN, since that name is taken and packages work on file level where 
some operating systems cannot distinguish capitalization appropriately 
enough, hence the name rNAME is not available after archival of rName 
... The is a simple technical restriction.

Even with a really different name, renaming packages should be reduced 
to an absolute minimum and would probably only accepted for legal 
concerns related to inappropriate package names.

Best,
Uwe Ligges





>
> Best,
>
> C
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Rename-the-package-published-on-CRAN-tp4674670.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Wed Aug 28 17:18:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 28 Aug 2013 11:18:47 -0400
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <21022.4186.756519.269862@max.nulle.part>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<521E0C19.8030306@gmail.com>
	<CABdHhvGaTkowxazL3i-HfsrPuWP_8rq4TOR=bWPKj8-vzdB8PA@mail.gmail.com>
	<21022.4186.756519.269862@max.nulle.part>
Message-ID: <521E14D7.8080809@gmail.com>

On 28/08/2013 10:59 AM, Dirk Eddelbuettel wrote:
> On 28 August 2013 at 09:44, Hadley Wickham wrote:
> | >> Related rant: I really wish we had "CHANGES" file, or a section in the
> | >> manuals. It is virtually impossible to look at a current "Writing R
> | >> Extensions" manual, and a previous one, in order to get a succinct view of
> | >> what changed.  Having to diff the NEWS files, or glancing at commit logs
> | >> via
> | >> the RCS is a very poor proxy.
> | >
> | > I don't understand the difference between the CHANGES file you are asking
> | > for and the NEWS file.  Do you want something in purely chronological order,
> | > rather than categorized as NEWS is?
> |
> | I think Dirk was talking about a CHANGES/NEWS file for "Writing R extensions"
>
> Yup. In the sense of "something to look at to see what one may need to change".
>
> Eg for Debian, the "Policy" document has a version number making discussion /
> comparison and reference more tangible.  Also, if/when an update is made, an
> 'upgrade checklist' is provided -- see eg [1] for the most recent annoucement
> [2] for the policy manual web presence, and [3] for the complete checklist
> with a roll-back history.
>
> I am not suggesting this exact format. I am merely pointing that it
> (currently) takes a couple of extra steps to stay on top of required changes,
> which in turn leads to everybody just uploading to CRAN as a trial, which in
> turn overburdens the CRAN maintainers.  Seems suboptimal to me.

There is the "--as-cran" option to R CMD check, so it's not quite as bad 
as you suggest, but as others have mentioned there is some ambiguity 
about how NOTEs in those checks are treated.  But isn't any "overburden" 
mainly a CRAN problem, so not something to be discussed on this list?

To be clear:  I am not a CRAN member.  I only know CRAN policy as an 
outsider, same as you.  And before an argument starts about where CRAN 
policy discussions should take place:  this is certainly not the 
place.   You can ask CRAN where such discussions should happen, but I 
suspect the answer will be "nowhere public", because most public 
discussions of CRAN policy devolve very quickly into ridiculous demands 
on the volunteers who run it.

Duncan Murdoch
>
> Dirk
>
> [1] http://lists.debian.org/debian-devel-announce/2012/09/msg00006.html
> [2] http://www.debian.org/doc/devel-manuals#policy
> [3] http://www.debian.org/doc/packaging-manuals/upgrading-checklist.txt
>


From edd at debian.org  Wed Aug 28 17:47:52 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 28 Aug 2013 10:47:52 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <521E14D7.8080809@gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<521E0C19.8030306@gmail.com>
	<CABdHhvGaTkowxazL3i-HfsrPuWP_8rq4TOR=bWPKj8-vzdB8PA@mail.gmail.com>
	<21022.4186.756519.269862@max.nulle.part>
	<521E14D7.8080809@gmail.com>
Message-ID: <21022.7080.870364.663805@max.nulle.part>


On 28 August 2013 at 11:18, Duncan Murdoch wrote:
| On 28/08/2013 10:59 AM, Dirk Eddelbuettel wrote:
| > On 28 August 2013 at 09:44, Hadley Wickham wrote:
| > | >> Related rant: I really wish we had "CHANGES" file, or a section in the
| > | >> manuals. It is virtually impossible to look at a current "Writing R
| > | >> Extensions" manual, and a previous one, in order to get a succinct view of
| > | >> what changed.  Having to diff the NEWS files, or glancing at commit logs
| > | >> via
| > | >> the RCS is a very poor proxy.
| > | >
| > | > I don't understand the difference between the CHANGES file you are asking
| > | > for and the NEWS file.  Do you want something in purely chronological order,
| > | > rather than categorized as NEWS is?
| > |
| > | I think Dirk was talking about a CHANGES/NEWS file for "Writing R extensions"
| >
| > Yup. In the sense of "something to look at to see what one may need to change".
| >
| > Eg for Debian, the "Policy" document has a version number making discussion /
| > comparison and reference more tangible.  Also, if/when an update is made, an
| > 'upgrade checklist' is provided -- see eg [1] for the most recent annoucement
| > [2] for the policy manual web presence, and [3] for the complete checklist
| > with a roll-back history.
| >
| > I am not suggesting this exact format. I am merely pointing that it
| > (currently) takes a couple of extra steps to stay on top of required changes,
| > which in turn leads to everybody just uploading to CRAN as a trial, which in
| > turn overburdens the CRAN maintainers.  Seems suboptimal to me.
| 
| There is the "--as-cran" option to R CMD check, so it's not quite as bad 

Sure. I use that all the time, and it is the sole reason I keep an r-devel
build around. 

But it is _reactive_. I suggest something proactive.

| as you suggest, but as others have mentioned there is some ambiguity 
| about how NOTEs in those checks are treated.  But isn't any "overburden" 
| mainly a CRAN problem, so not something to be discussed on this list?
| 
| To be clear:  I am not a CRAN member.  I only know CRAN policy as an 
| outsider, same as you.  And before an argument starts about where CRAN 
| policy discussions should take place:  this is certainly not the 

This is the R development list. I have been subscribed for fourteen years,
and to the best of my recollection there never was any discussion of
this. Here.  At the place created to discuss R development issues. Ie work
meant for CRAN. 

In my book, that's a bug and not a feature.

| place.   You can ask CRAN where such discussions should happen, but I 
| suspect the answer will be "nowhere public", because most public 
| discussions of CRAN policy devolve very quickly into ridiculous demands 
| on the volunteers who run it.

By never engaging in the discussions the CRAN maintainers do not exactly help
their case, or for that matter their users (eg those submitting packages).

Dirk

ObDisclaimer: I remain a really huge fanboy of CRAN, and almost always defend
it in dicussions with other R users (not all of which are all that kindly
disposed to CRAN these days).  But even I am at a loss for explanations for
some of these things, and am tired of the current back-and-forth on submissions.
The fact that _overnight changes_ to r-devel are reasons for reject are just
silly. 

ObDisclaimer 2: I am not complaining to you. You just happent to be just
about the only R Core member engaging here.  I am grateful that you do, and I
do understand that your ability to affect change is also limited. I merely
assume it is larger than mine.


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From pgilbert902 at gmail.com  Wed Aug 28 18:15:26 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 28 Aug 2013 12:15:26 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
Message-ID: <521E221E.3020107@gmail.com>

I have a package (TSdbi) which provides end user functions that I 
export, and several utilities for plugin packages (e.g. TSMySQL) that I 
do not export because I do not intend them to be exposed to end users. I 
call these from the plugin packages using TSdbi:::  but that now 
produces a note in the checks:

* checking dependencies in R code ... NOTE
Namespace imported from by a ?:::? call: ?TSdbi?
   See the note in ?`:::` about the use of this operator. :: should be
   used rather than ::: if the function is exported, and a package
   almost never needs to use ::: for its own functions.

Is there a preferred method to accomplish this in a way that does not 
produce a note?

Thanks,
Paul


From h.wickham at gmail.com  Wed Aug 28 18:17:46 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 11:17:46 -0500
Subject: [Rd] Memory allocation in read.table
Message-ID: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>

Hi all,

I've been trying to learn more about memory profiling in R and I've
been trying memory profiling out on read.table. I'm getting a bit of a
strange result, and I hope that someone might be able to explain why.

After running

Rprof("read-table.prof", memory.profiling = TRUE, line.profiling = TRUE,
  gc.profiling = TRUE, interval = interval)
diamonds <- read.table("diamonds.csv", sep = ",", header = TRUE)
Rprof(NULL)

and doing an lot of data manipulation, I end up with a table that
displays the total memory (in megabytes) allocated and released (by
gc) from each line of (a local copy of) read.table:

          file line  alloc release
1 read-table.r  122 1.9797  1.1435
2 read-table.r  165 1.1148  0.6511
3 read-table.r  221 0.0763  0.0321
4 read-table.r  222 0.4922  1.5057

Lines 122 and 165 are where I expect to see big allocations and
releases - they're calling scan and convert.type respectively. Lines
221 and 222 are more of a mystery:

    class(data) <- "data.frame"
    attr(data, "row.names") <- row.names

Why do those lines need any allocations? I thought class<- and attr<-
were primitives, and hence would modify in place.

Re-running with gctorture(TRUE) yields roughly similar numbers,
although there is no memory release because gc is called earlier, and
the assignment of allocations to line is probably more accurate given
that gctorture runs the code about 20x slower:

           file line    alloc  release
25 read-table.r  221 0.387299 0.00e+00
26 read-table.r  222 0.362964 0.00e+00

The whole object, when loaded, is ~4 meg, so those allocations
represent fairly sizeable chunks of the total.

Any suggestions would be greatly appreciated.  Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From marc_schwartz at me.com  Wed Aug 28 18:29:28 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 28 Aug 2013 11:29:28 -0500
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E221E.3020107@gmail.com>
References: <521E221E.3020107@gmail.com>
Message-ID: <E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>


On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:

> I have a package (TSdbi) which provides end user functions that I export, and several utilities for plugin packages (e.g. TSMySQL) that I do not export because I do not intend them to be exposed to end users. I call these from the plugin packages using TSdbi:::  but that now produces a note in the checks:
> 
> * checking dependencies in R code ... NOTE
> Namespace imported from by a ?:::? call: ?TSdbi?
>  See the note in ?`:::` about the use of this operator. :: should be
>  used rather than ::: if the function is exported, and a package
>  almost never needs to use ::: for its own functions.
> 
> Is there a preferred method to accomplish this in a way that does not produce a note?
> 
> Thanks,
> Paul



Paul,

See this rather lengthy discussion that occurred within the past week:

  https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html

Regards,

Marc Schwartz


From ucfagls at gmail.com  Wed Aug 28 18:29:44 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 28 Aug 2013 10:29:44 -0600
Subject: [Rd] =?utf-8?b?4oCYOjo64oCZIGNhbGw=?=
In-Reply-To: <521E221E.3020107@gmail.com>
References: <521E221E.3020107@gmail.com>
Message-ID: <CAAHES9wtYSFMDj_2vK0WNaAaHnT=EmaF5=B9nq28KWbe-mLCCg@mail.gmail.com>

Paul, this was discussed at length only a couple of days ago. See this thread:

http://comments.gmane.org/gmane.comp.lang.r.devel/34100

If I follow you, I think a change has been made that doesn't NOTE if
the use of `:::` is to packages for which you are also the maintainer.
But read the thread as the change is mentioned in there somewhere.

HTH

G

On 28 August 2013 10:15, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> I have a package (TSdbi) which provides end user functions that I export,
> and several utilities for plugin packages (e.g. TSMySQL) that I do not
> export because I do not intend them to be exposed to end users. I call these
> from the plugin packages using TSdbi:::  but that now produces a note in the
> checks:
>
> * checking dependencies in R code ... NOTE
> Namespace imported from by a ?:::? call: ?TSdbi?
>   See the note in ?`:::` about the use of this operator. :: should be
>   used rather than ::: if the function is exported, and a package
>   almost never needs to use ::: for its own functions.
>
> Is there a preferred method to accomplish this in a way that does not
> produce a note?
>
> Thanks,
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Gavin Simpson, PhD


From simon.urbanek at r-project.org  Wed Aug 28 19:44:57 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 28 Aug 2013 13:44:57 -0400
Subject: [Rd] Memory allocation in read.table
In-Reply-To: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
References: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
Message-ID: <6603B703-48C9-417E-9495-F68B4015F381@r-project.org>

On Aug 28, 2013, at 12:17 PM, Hadley Wickham wrote:

> Hi all,
> 
> I've been trying to learn more about memory profiling in R and I've
> been trying memory profiling out on read.table. I'm getting a bit of a
> strange result, and I hope that someone might be able to explain why.
> 
> After running
> 
> Rprof("read-table.prof", memory.profiling = TRUE, line.profiling = TRUE,
>  gc.profiling = TRUE, interval = interval)
> diamonds <- read.table("diamonds.csv", sep = ",", header = TRUE)
> Rprof(NULL)
> 
> and doing an lot of data manipulation, I end up with a table that
> displays the total memory (in megabytes) allocated and released (by
> gc) from each line of (a local copy of) read.table:
> 
>          file line  alloc release
> 1 read-table.r  122 1.9797  1.1435
> 2 read-table.r  165 1.1148  0.6511
> 3 read-table.r  221 0.0763  0.0321
> 4 read-table.r  222 0.4922  1.5057
> 
> Lines 122 and 165 are where I expect to see big allocations and
> releases - they're calling scan and convert.type respectively. Lines
> 221 and 222 are more of a mystery:
> 
>    class(data) <- "data.frame"
>    attr(data, "row.names") <- row.names
> 
> Why do those lines need any allocations? I thought class<- and attr<-
> were primitives, and hence would modify in place.
> 

.. but only if there is no other reference to the data (i.e. NAMED < 2). If there are two references, they have to copy, because it would change the other copy.
Here, however, it already has NAMED=2 because of 

data <- data[keep]

If you remove that line and inverse the order of class() and attr()<- then you get 0 copies.

Cheers,
Simon

PS: if you are loading any sizable data, the one thing you don't want to do is to use read.table() ;)


> Re-running with gctorture(TRUE) yields roughly similar numbers,
> although there is no memory release because gc is called earlier, and
> the assignment of allocations to line is probably more accurate given
> that gctorture runs the code about 20x slower:
> 
>           file line    alloc  release
> 25 read-table.r  221 0.387299 0.00e+00
> 26 read-table.r  222 0.362964 0.00e+00
> 
> The whole object, when loaded, is ~4 meg, so those allocations
> represent fairly sizeable chunks of the total.
> 
> Any suggestions would be greatly appreciated.  Thanks!
> 
> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From h.wickham at gmail.com  Wed Aug 28 19:59:07 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 12:59:07 -0500
Subject: [Rd] Memory allocation in read.table
In-Reply-To: <6603B703-48C9-417E-9495-F68B4015F381@r-project.org>
References: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
	<6603B703-48C9-417E-9495-F68B4015F381@r-project.org>
Message-ID: <CABdHhvE9LrcseP93KTG4AtkrgffDF9FgkQH-kBnP_fgJRt+i8w@mail.gmail.com>

>> Why do those lines need any allocations? I thought class<- and attr<-
>> were primitives, and hence would modify in place.
>>
>
> .. but only if there is no other reference to the data (i.e. NAMED < 2). If there are two references, they have to copy, because it would change the other copy.
> Here, however, it already has NAMED=2 because of
>
> data <- data[keep]

Ah, got it - thanks!

> PS: if you are loading any sizable data, the one thing you don't want to do is to use read.table() ;)

Yes ;)  Romain and I (mostly Romain) are working on some faster
alternatives at https://github.com/romainfrancois/fastread.

One surprising finding so far (to me at least), is that when loading a
file full of doubles, you pretty quickly get to the point where strtod
is the bottleneck.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From simon.urbanek at r-project.org  Wed Aug 28 20:10:17 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 28 Aug 2013 14:10:17 -0400
Subject: [Rd] Memory allocation in read.table
In-Reply-To: <CABdHhvE9LrcseP93KTG4AtkrgffDF9FgkQH-kBnP_fgJRt+i8w@mail.gmail.com>
References: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
	<6603B703-48C9-417E-9495-F68B4015F381@r-project.org>
	<CABdHhvE9LrcseP93KTG4AtkrgffDF9FgkQH-kBnP_fgJRt+i8w@mail.gmail.com>
Message-ID: <0CA3536B-D70E-4B6E-A888-A6992B17DEC3@r-project.org>


On Aug 28, 2013, at 1:59 PM, Hadley Wickham wrote:

>>> Why do those lines need any allocations? I thought class<- and attr<-
>>> were primitives, and hence would modify in place.
>>> 
>> 
>> .. but only if there is no other reference to the data (i.e. NAMED < 2). If there are two references, they have to copy, because it would change the other copy.
>> Here, however, it already has NAMED=2 because of
>> 
>> data <- data[keep]
> 
> Ah, got it - thanks!
> 
>> PS: if you are loading any sizable data, the one thing you don't want to do is to use read.table() ;)
> 
> Yes ;)  Romain and I (mostly Romain) are working on some faster
> alternatives at https://github.com/romainfrancois/fastread.
> 
> One surprising finding so far (to me at least), is that when loading a
> file full of doubles, you pretty quickly get to the point where strtod
> is the bottleneck.
> 

Yup - parsing is the most expensive part. That's why for high-throughput data you don't want to use ASCII representation. It's amazing that the disk speeds are now so high that CPUs are the bottlenecks now, not vice versa.

Re fast loading - yes, that's something I was also working around in iotools https://github.com/s-u/iotools 

Cheers,
Simon


From geoffjentry at hexdump.org  Wed Aug 28 20:19:39 2013
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Wed, 28 Aug 2013 11:19:39 -0700 (PDT)
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <21022.2225.867873.997588@max.nulle.part>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
Message-ID: <alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>

On Wed, 28 Aug 2013, Dirk Eddelbuettel wrote:
> The change to preferring vignettes/ over inst/doc/ is just one of many; there
> is also an ongoing preference for vignettes that fully reproducible from
> source. Which may eventually put an end to non-Rnw / non-(la)tex vignettes.

I'm currently stymied by this. I was one who did the stub-Rnw trick 
previously - it would be unwise for the vignette for twitteR to be run 
truly dynamically as it requires someone's real credentials to process.

Not a problem, I run it by hand before submitting and then use the stub 
.Rnw for the vignette metadata to get picked up by CRAN.

With the move to vignettes/ over inst/doc, that hasn't worked. doh!

Aside: If someone knows of a way to get a non-autogenerated documentation 
file linked on a package's CRAN page (other than URL, which is a 
possibility) I'd love to hear ideas.

-J


From h.wickham at gmail.com  Wed Aug 28 20:24:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 13:24:53 -0500
Subject: [Rd] Memory allocation in read.table
In-Reply-To: <0CA3536B-D70E-4B6E-A888-A6992B17DEC3@r-project.org>
References: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
	<6603B703-48C9-417E-9495-F68B4015F381@r-project.org>
	<CABdHhvE9LrcseP93KTG4AtkrgffDF9FgkQH-kBnP_fgJRt+i8w@mail.gmail.com>
	<0CA3536B-D70E-4B6E-A888-A6992B17DEC3@r-project.org>
Message-ID: <CABdHhvFWjUT+9W9nGxp-JcV-w03J69rffiZi3JdWsgoNXASNgg@mail.gmail.com>

> Yup - parsing is the most expensive part. That's why for high-throughput data you don't want to use ASCII representation. It's amazing that the disk speeds are now so high that CPUs are the bottlenecks now, not vice versa.

Do you have any recommendations for binary formats? For R, is there
anything obviously better than Rdata?

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From pgilbert902 at gmail.com  Wed Aug 28 20:50:14 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 28 Aug 2013 14:50:14 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
Message-ID: <521E4666.8080603@gmail.com>

On 13-08-28 12:29 PM, Marc Schwartz wrote:
>
> On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>> I have a package (TSdbi) which provides end user functions that I export, and several utilities for plugin packages (e.g. TSMySQL) that I do not export because I do not intend them to be exposed to end users. I call these from the plugin packages using TSdbi:::  but that now produces a note in the checks:
>>
>> * checking dependencies in R code ... NOTE
>> Namespace imported from by a ?:::? call: ?TSdbi?
>>   See the note in ?`:::` about the use of this operator. :: should be
>>   used rather than ::: if the function is exported, and a package
>>   almost never needs to use ::: for its own functions.
>>
>> Is there a preferred method to accomplish this in a way that does not produce a note?
>>
>> Thanks,
>> Paul
>
>
>
> Paul,
>
> See this rather lengthy discussion that occurred within the past week:
>
>    https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html
>
> Regards,
>
> Marc Schwartz

I did follow the recent discussion, but no one answered the question "Is 
there a preferred method to accomplish this?" (I suppose the answer is 
that there is no other way, given that no one actually suggested 
anything else.) Most of the on topic discussion in that thread was about 
how to subvert the CRAN checks, which is not what I am trying to do and 
was also pointed out as a bad idea by Duncan. The substantive response was

 >r63654 has fixed this particular issue, and R-devel will no longer
 >warn against the use of ::: on packages of the same maintainer.
 >
 >Regards,
 >Yihui

but that strikes me as a temporary work around rather than a real 
solution: suppose plugins are provided by a package from another maintainer.

Since CRAN notes have a habit of becoming warnings and then errors, it 
seems useful to identify the preferred legitimate approach while this is 
still a note. That would save work for both package developers and CRAN 
maintainers.

My thinking is that there is a need for a NAMESPACE directive something 
like limitedExport() that allows ::: for identified functions without 
provoking a CRAN complaint when packages use those functions. But there 
may already be a better way I don't know about. Or perhaps the solution 
is to split the end user functions and the utilities for plugin packages 
into two separate packages?

Paul


From simon.urbanek at r-project.org  Wed Aug 28 20:52:45 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 28 Aug 2013 14:52:45 -0400
Subject: [Rd] Memory allocation in read.table
In-Reply-To: <CABdHhvFWjUT+9W9nGxp-JcV-w03J69rffiZi3JdWsgoNXASNgg@mail.gmail.com>
References: <CABdHhvEtVhBQS7x+S86my3ec26-iCQx+NpVdzM4nh5ca=pGfqg@mail.gmail.com>
	<6603B703-48C9-417E-9495-F68B4015F381@r-project.org>
	<CABdHhvE9LrcseP93KTG4AtkrgffDF9FgkQH-kBnP_fgJRt+i8w@mail.gmail.com>
	<0CA3536B-D70E-4B6E-A888-A6992B17DEC3@r-project.org>
	<CABdHhvFWjUT+9W9nGxp-JcV-w03J69rffiZi3JdWsgoNXASNgg@mail.gmail.com>
Message-ID: <08647436-E8B7-4579-BF51-80DADD441190@r-project.org>

On Aug 28, 2013, at 2:24 PM, Hadley Wickham wrote:

>> Yup - parsing is the most expensive part. That's why for high-throughput data you don't want to use ASCII representation. It's amazing that the disk speeds are now so high that CPUs are the bottlenecks now, not vice versa.
> 
> Do you have any recommendations for binary formats? For R, is there anything obviously better than Rdata?
> 

native formats are the fastest (and versatile), so
readBin/writeBin or mmap
I tend to avoid strings (I use dates as POSIXct which are doubles and for anything else factors - which are integers) so the above works for me just fine.
I am working on a way to do direct mmap serialization of SEXPs but it's not ready yet (basic vectors are supported but complex objects not yet).

Cheers,
Simon


From kasperdanielhansen at gmail.com  Wed Aug 28 21:06:45 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 28 Aug 2013 15:06:45 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E4666.8080603@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
Message-ID: <CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130828/40fee02f/attachment.pl>

From murdoch.duncan at gmail.com  Wed Aug 28 21:18:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 28 Aug 2013 15:18:47 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E4666.8080603@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
Message-ID: <521E4D17.8060401@gmail.com>

On 28/08/2013 2:50 PM, Paul Gilbert wrote:
> On 13-08-28 12:29 PM, Marc Schwartz wrote:
> >
> > On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> >
> >> I have a package (TSdbi) which provides end user functions that I export, and several utilities for plugin packages (e.g. TSMySQL) that I do not export because I do not intend them to be exposed to end users. I call these from the plugin packages using TSdbi:::  but that now produces a note in the checks:
> >>
> >> * checking dependencies in R code ... NOTE
> >> Namespace imported from by a ?:::? call: ?TSdbi?
> >>   See the note in ?`:::` about the use of this operator. :: should be
> >>   used rather than ::: if the function is exported, and a package
> >>   almost never needs to use ::: for its own functions.
> >>
> >> Is there a preferred method to accomplish this in a way that does not produce a note?
> >>
> >> Thanks,
> >> Paul
> >
> >
> >
> > Paul,
> >
> > See this rather lengthy discussion that occurred within the past week:
> >
> >    https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html
> >
> > Regards,
> >
> > Marc Schwartz
>
> I did follow the recent discussion, but no one answered the question "Is
> there a preferred method to accomplish this?" (I suppose the answer is
> that there is no other way, given that no one actually suggested
> anything else.) Most of the on topic discussion in that thread was about
> how to subvert the CRAN checks, which is not what I am trying to do and
> was also pointed out as a bad idea by Duncan. The substantive response was
>
>   >r63654 has fixed this particular issue, and R-devel will no longer
>   >warn against the use of ::: on packages of the same maintainer.
>   >
>   >Regards,
>   >Yihui
>
> but that strikes me as a temporary work around rather than a real
> solution: suppose plugins are provided by a package from another maintainer.
>
> Since CRAN notes have a habit of becoming warnings and then errors, it
> seems useful to identify the preferred legitimate approach while this is
> still a note. That would save work for both package developers and CRAN
> maintainers.
>
> My thinking is that there is a need for a NAMESPACE directive something
> like limitedExport() that allows ::: for identified functions without
> provoking a CRAN complaint when packages use those functions. But there
> may already be a better way I don't know about. Or perhaps the solution
> is to split the end user functions and the utilities for plugin packages
> into two separate packages?

I don't see a need for that.  The reason ::: is bad is because 
non-exported functions may change without notice, breaking the package 
that uses them, and possibly giving the users of that package bad 
results.  If you're the maintainer of both the donor and user of the 
non-exported function, then you can be expected to keep them in sync, 
hence r63654.  If those are different people, then the donor had better 
indicate that the function is safe to use.  That's what export() does.

If you are worried about a cluttered listing of functions and help 
pages, you can use an initial "." in the name of the object, or use 
\keyword{internal} in the .Rd file.  I forget the full list of effects 
of each of these, but using both should make your function nearly 
invisible, while still exported if it is listed as such in the NAMESPACE 
file.

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Aug 28 21:22:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 28 Aug 2013 15:22:06 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>
Message-ID: <521E4DDE.8010404@gmail.com>

On 28/08/2013 3:06 PM, Kasper Daniel Hansen wrote:
> My point of view is that if you have a core package where you need access
> to "hidden" functions for making a plugin, you should probably export these
> hidden functions in the first place.  Chances are that if you need access
> to these hidden functions (for expert use), other (expert) users might want
> access as well, so take the time to export and document it.
>
> I want to use ::: specifically for the case where I have no control over
> the other package.

And as a potential user of your package, I don't want you to use ::: if 
you don't have control over the other package, because its author might 
unwittingly change it in a way that causes me to get incorrect results.

If you want to use :::, go ahead, just don't put your package on CRAN, 
where I get most of my packages.  Then we'll both be happy.

Duncan Murdoch
>
> Best,
> Kasper
>
>
>
>
> On Wed, Aug 28, 2013 at 2:50 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
> > On 13-08-28 12:29 PM, Marc Schwartz wrote:
> >
> >>
> >> On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> >>
> >>  I have a package (TSdbi) which provides end user functions that I
> >>> export, and several utilities for plugin packages (e.g. TSMySQL) that I do
> >>> not export because I do not intend them to be exposed to end users. I call
> >>> these from the plugin packages using TSdbi:::  but that now produces a note
> >>> in the checks:
> >>>
> >>> * checking dependencies in R code ... NOTE
> >>> Namespace imported from by a ?:::? call: ?TSdbi?
> >>>   See the note in ?`:::` about the use of this operator. :: should be
> >>>   used rather than ::: if the function is exported, and a package
> >>>   almost never needs to use ::: for its own functions.
> >>>
> >>> Is there a preferred method to accomplish this in a way that does not
> >>> produce a note?
> >>>
> >>> Thanks,
> >>> Paul
> >>>
> >>
> >>
> >>
> >> Paul,
> >>
> >> See this rather lengthy discussion that occurred within the past week:
> >>
> >>    https://stat.ethz.ch/**pipermail/r-devel/2013-August/**067180.html<https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html>
> >>
> >> Regards,
> >>
> >> Marc Schwartz
> >>
> >
> > I did follow the recent discussion, but no one answered the question "Is
> > there a preferred method to accomplish this?" (I suppose the answer is that
> > there is no other way, given that no one actually suggested anything else.)
> > Most of the on topic discussion in that thread was about how to subvert the
> > CRAN checks, which is not what I am trying to do and was also pointed out
> > as a bad idea by Duncan. The substantive response was
> >
> > >r63654 has fixed this particular issue, and R-devel will no longer
> > >warn against the use of ::: on packages of the same maintainer.
> > >
> > >Regards,
> > >Yihui
> >
> > but that strikes me as a temporary work around rather than a real
> > solution: suppose plugins are provided by a package from another maintainer.
> >
> > Since CRAN notes have a habit of becoming warnings and then errors, it
> > seems useful to identify the preferred legitimate approach while this is
> > still a note. That would save work for both package developers and CRAN
> > maintainers.
> >
> > My thinking is that there is a need for a NAMESPACE directive something
> > like limitedExport() that allows ::: for identified functions without
> > provoking a CRAN complaint when packages use those functions. But there may
> > already be a better way I don't know about. Or perhaps the solution is to
> > split the end user functions and the utilities for plugin packages into two
> > separate packages?
> >
> > Paul
> >
> >
> > ______________________________**________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
> >
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Wed Aug 28 21:33:10 2013
From: cstrato at aon.at (cstrato)
Date: Wed, 28 Aug 2013 21:33:10 +0200
Subject: [Rd] Error when using buildVignettes()
Message-ID: <521E5076.9020106@aon.at>

Dear all,

When running function 'testQAReport()', which uses function 
'buildVignettes()' to create a pdf-file I get the following error:

 > source("testQAReport.R")
 > testQAReport()
Error in .get_package_metadata(pkgdir) :
   Files 'DESCRIPTION' and 'DESCRIPTION.in' are missing.

Since I did not get this error in earlier versions of R, could you 
please tell me what may be the reason for this error?


Here is the code for "testQAReport.R":

#------------------------------------------------------------------------------#
# testQAReport.R: test quality control report
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
- - - -
testQAReport <-
function(dataset     = "My Dataset",
          title       = "Quality Report",
          date        = "October, 2011",
          author      = "Christian Stratowa",
          outdir      = file.path(getwd(), "TestQA"),
          ...)
{
    ## directory containing parts of QAReport.Rnw
    indir <- file.path(path.package("xps"), "QC");

    ## create directory containing final QAReport.Rnw
    if (!dir.create(outdir))
       stop("could not create report directory");
    if (!dir.create(file.path(outdir, "inst")))
       stop("could not create report subdirectory 'inst'");
    if (!dir.create(file.path(outdir, "inst", "doc")))
       stop("could not create report subdirectory 'doc'");
    docdir <- file.path(outdir, "inst", "doc");

    QCb <- readLines(file.path(indir, "QC.begin.Rnw"));

    ## replace title, date, author
    QCb <- sub("@TITLE@",  title,  QCb);
    QCb <- sub("@DATE@",   date,   QCb);
    QCb <- sub("@AUTHOR@", author, QCb);

    ## dataset info
    numtrees <- 6; chipname <- "Test3"; chiptype <- "GeneChip";
    QCb <- sub("@DATASET@",  dataset,  QCb);
    QCb <- sub("@NUMTREES@", numtrees, QCb);
    QCb <- sub("@CHIPNAME@", chipname, QCb);
    QCb <- sub("@CHIPTYPE@", chiptype, QCb);

    write(QCb, file.path(docdir, "QAReport.Rnw"));

    QCe <- readLines(file.path(indir, "QC.end.Rnw"));
    QCe <- sub("@DATASET@",  dataset,  QCe);
    QCe <- gsub("_","\\\\_", QCe);

    write(QCe, file.path(docdir, "QAReport.Rnw"), append=TRUE);

    ## build vignette QC.pdf
    if (require(tools)) {
       buildVignettes(dir=outdir, lib.loc=NULL, quiet=FALSE, clean=FALSE);
    }#if
}#xpsQAReport

#------------------------------------------------------------------------------#

The file "QC.begin.Rnw" is as follows:

\documentclass{article}


\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Cclass}[1]{{\textit{#1}}}
\newcommand{\Rexten}[1]{{\textit{#1}}}
\newcommand{\xps}{\Rpackage{xps}}
\newcommand{\ROOT}{\Robject{ROOT}}

\begin{document}

\title{@TITLE@}
\date{@DATE@}
\author{@AUTHOR@}
\maketitle

\tableofcontents


\section{Introduction}

  This is the quality assessment report for the dataset '@DATASET@'. The 
dataset consists of
  @NUMTREES@ Affymetrix @CHIPTYPE@ arrays of type '@CHIPNAME@'. \\

  This report was generated using function \Rfunction{xpsQAReport} of 
package \xps. \\


The file "QC.end.Rnw" is as follows:

\section{Summary}

  The current quality report for dataset '@DATASET@' displays the most 
important quality plots, using the
  default settings for most plots. Package \xps\ contains additional 
plots which can be used for further
  quality assessments. \\


\section*{Session Information:}

<<echo=FALSE>>=
sessionInfo()
@

\end{document}


Finally, the output which is located in TestQA/inst/doc/QAReport.Rnw is 
as follows:

\documentclass{article}


\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Cclass}[1]{{\textit{#1}}}
\newcommand{\Rexten}[1]{{\textit{#1}}}
\newcommand{\xps}{\Rpackage{xps}}
\newcommand{\ROOT}{\Robject{ROOT}}

\begin{document}

\title{Quality Report}
\date{October, 2011}
\author{Christian Stratowa}
\maketitle

\tableofcontents


\section{Introduction}

  This is the quality assessment report for the dataset 'My Dataset'. 
The dataset consists of
  6 Affymetrix GeneChip arrays of type 'Test3'. \\

  This report was generated using function \Rfunction{xpsQAReport} of 
package \xps. \\

\section{Summary}

  The current quality report for dataset 'My Dataset' displays the most 
important quality plots, using the
  default settings for most plots. Package \xps\ contains additional 
plots which can be used for further
  quality assessments. \\


\section*{Session Information:}

<<echo=FALSE>>=
sessionInfo()
@

\end{document}


Can you please tell me why function buildVignettes() of the tools 
package is no longer able to convert this file into a pdf-file?
Thank you in advance.


 > sessionInfo()
R version 3.0.0 Patched (2013-04-11 r62551)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] xps_1.21.4

Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From xie at yihui.name  Wed Aug 28 21:44:49 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 28 Aug 2013 14:44:49 -0500
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E4666.8080603@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
Message-ID: <CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>

If this issue is going to be solved at all, it might end up as yet
another "hack" like utils::globalVariables just to "fix" R CMD check
which was trying to fix things that were not necessarily broken.

To be clear, I was not suggesting subvert this check. What I was
hoping is a way to tell CRAN that "Yes, I have read the documentation;
I understand the risk, and I want to take it like a moth flying into
the flames".

Many people have been talking about this "risk", and how about some
evidence? Who was bitten by :::? How many real cases in which a
package was broken by :::?

Yes, unexported functions may change, so are exported functions (they
may change API, be deprecated, add new arguments, change defaults, and
so on). Almost everything in a package is constantly evolving, and I
believe the correct way (and the only way) to stop things from being
broken is to write enough test cases. When something is broken, we
will be able to know that. Yes, we may not have control over other
people's packages, but we always have control over our own test cases.
IMHO, testing is the justification of CRAN's reputation and quality,
and that is a part of what CRAN does.

In God we trust, and everyone else should bring tests.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Aug 28, 2013 at 1:50 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> On 13-08-28 12:29 PM, Marc Schwartz wrote:
>>
>>
>> On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>
>>> I have a package (TSdbi) which provides end user functions that I export,
>>> and several utilities for plugin packages (e.g. TSMySQL) that I do not
>>> export because I do not intend them to be exposed to end users. I call these
>>> from the plugin packages using TSdbi:::  but that now produces a note in the
>>> checks:
>>>
>>> * checking dependencies in R code ... NOTE
>>> Namespace imported from by a ?:::? call: ?TSdbi?
>>>   See the note in ?`:::` about the use of this operator. :: should be
>>>   used rather than ::: if the function is exported, and a package
>>>   almost never needs to use ::: for its own functions.
>>>
>>> Is there a preferred method to accomplish this in a way that does not
>>> produce a note?
>>>
>>> Thanks,
>>> Paul
>>
>>
>>
>>
>> Paul,
>>
>> See this rather lengthy discussion that occurred within the past week:
>>
>>    https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html
>>
>> Regards,
>>
>> Marc Schwartz
>
>
> I did follow the recent discussion, but no one answered the question "Is
> there a preferred method to accomplish this?" (I suppose the answer is that
> there is no other way, given that no one actually suggested anything else.)
> Most of the on topic discussion in that thread was about how to subvert the
> CRAN checks, which is not what I am trying to do and was also pointed out as
> a bad idea by Duncan. The substantive response was
>
>>r63654 has fixed this particular issue, and R-devel will no longer
>>warn against the use of ::: on packages of the same maintainer.
>>
>>Regards,
>>Yihui
>
> but that strikes me as a temporary work around rather than a real solution:
> suppose plugins are provided by a package from another maintainer.
>
> Since CRAN notes have a habit of becoming warnings and then errors, it seems
> useful to identify the preferred legitimate approach while this is still a
> note. That would save work for both package developers and CRAN maintainers.
>
> My thinking is that there is a need for a NAMESPACE directive something like
> limitedExport() that allows ::: for identified functions without provoking a
> CRAN complaint when packages use those functions. But there may already be a
> better way I don't know about. Or perhaps the solution is to split the end
> user functions and the utilities for plugin packages into two separate
> packages?
>
> Paul


From pgilbert902 at gmail.com  Wed Aug 28 22:17:20 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 28 Aug 2013 16:17:20 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>
Message-ID: <521E5AD0.7070409@gmail.com>

I may have confused things by referring to ':::' which everyone reads as 
not exported, not documented, not part of the API, constantly changing, ...

In my mind, the real question is about two levels of exporting, one to 
other package developers, and another to end users. In both cases they 
are part of the "API", relatively constant, and documented. (I try to 
document even internal functions, otherwise I can't remember what they do.)

So far, I see three possible solutions:

   1/ R adds another namespace directive allowing certain functions to 
be "exported" differently, possibly just by causing the checks to be 
silent about ::: when those functions are used in that way by other 
packages.

  2/ The package gets split in two, one for use by other packages and 
one for use by end users.

  3/ Some functions are exported normally but hidden by using "." in the 
beginning of their names. Other package maintainers would know they 
exist, but end users would not so easily find them. (Duncan's other 
suggestion of using \keyword{internal} in the .Rd file strikes me as 
problematic. I'm surprised CRAN checks do not already object to 
functions exported and documented with \keyword{internal}.)

Paul

On 13-08-28 03:44 PM, Yihui Xie wrote:
> If this issue is going to be solved at all, it might end up as yet
> another "hack" like utils::globalVariables just to "fix" R CMD check
> which was trying to fix things that were not necessarily broken.
>
> To be clear, I was not suggesting subvert this check. What I was
> hoping is a way to tell CRAN that "Yes, I have read the documentation;
> I understand the risk, and I want to take it like a moth flying into
> the flames".
>
> Many people have been talking about this "risk", and how about some
> evidence? Who was bitten by :::? How many real cases in which a
> package was broken by :::?
>
> Yes, unexported functions may change, so are exported functions (they
> may change API, be deprecated, add new arguments, change defaults, and
> so on). Almost everything in a package is constantly evolving, and I
> believe the correct way (and the only way) to stop things from being
> broken is to write enough test cases. When something is broken, we
> will be able to know that. Yes, we may not have control over other
> people's packages, but we always have control over our own test cases.
> IMHO, testing is the justification of CRAN's reputation and quality,
> and that is a part of what CRAN does.
>
> In God we trust, and everyone else should bring tests.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Wed, Aug 28, 2013 at 1:50 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>> On 13-08-28 12:29 PM, Marc Schwartz wrote:
>>>
>>>
>>> On Aug 28, 2013, at 11:15 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>>
>>>> I have a package (TSdbi) which provides end user functions that I export,
>>>> and several utilities for plugin packages (e.g. TSMySQL) that I do not
>>>> export because I do not intend them to be exposed to end users. I call these
>>>> from the plugin packages using TSdbi:::  but that now produces a note in the
>>>> checks:
>>>>
>>>> * checking dependencies in R code ... NOTE
>>>> Namespace imported from by a ?:::? call: ?TSdbi?
>>>>    See the note in ?`:::` about the use of this operator. :: should be
>>>>    used rather than ::: if the function is exported, and a package
>>>>    almost never needs to use ::: for its own functions.
>>>>
>>>> Is there a preferred method to accomplish this in a way that does not
>>>> produce a note?
>>>>
>>>> Thanks,
>>>> Paul
>>>
>>>
>>>
>>>
>>> Paul,
>>>
>>> See this rather lengthy discussion that occurred within the past week:
>>>
>>>     https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html
>>>
>>> Regards,
>>>
>>> Marc Schwartz
>>
>>
>> I did follow the recent discussion, but no one answered the question "Is
>> there a preferred method to accomplish this?" (I suppose the answer is that
>> there is no other way, given that no one actually suggested anything else.)
>> Most of the on topic discussion in that thread was about how to subvert the
>> CRAN checks, which is not what I am trying to do and was also pointed out as
>> a bad idea by Duncan. The substantive response was
>>
>>> r63654 has fixed this particular issue, and R-devel will no longer
>>> warn against the use of ::: on packages of the same maintainer.
>>>
>>> Regards,
>>> Yihui
>>
>> but that strikes me as a temporary work around rather than a real solution:
>> suppose plugins are provided by a package from another maintainer.
>>
>> Since CRAN notes have a habit of becoming warnings and then errors, it seems
>> useful to identify the preferred legitimate approach while this is still a
>> note. That would save work for both package developers and CRAN maintainers.
>>
>> My thinking is that there is a need for a NAMESPACE directive something like
>> limitedExport() that allows ::: for identified functions without provoking a
>> CRAN complaint when packages use those functions. But there may already be a
>> better way I don't know about. Or perhaps the solution is to split the end
>> user functions and the utilities for plugin packages into two separate
>> packages?
>>
>> Paul


From bbolker at gmail.com  Wed Aug 28 22:58:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 28 Aug 2013 20:58:36 +0000
Subject: [Rd] Minimum requirements for package submission
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
Message-ID: <loom.20130828T225613-593@post.gmane.org>

Geoff Jentry <geoffjentry <at> hexdump.org> writes:

> 
> On Wed, 28 Aug 2013, Dirk Eddelbuettel wrote:
> > The change to preferring vignettes/ over inst/doc/ is just one of many; 
> there
> > is also an ongoing preference for vignettes that fully reproducible from
> > source. Which may eventually put an end to non-Rnw / non-(la)tex vignettes.
> 
> I'm currently stymied by this. I was one who did the stub-Rnw trick 
> previously - it would be unwise for the vignette for twitteR to be run 
> truly dynamically as it requires someone's real credentials to process.
> 
> Not a problem, I run it by hand before submitting and then use the stub 
> .Rnw for the vignette metadata to get picked up by CRAN.
> 
> With the move to vignettes/ over inst/doc, that hasn't worked. doh!
> 
> Aside: If someone knows of a way to get a non-autogenerated documentation 
> file linked on a package's CRAN page (other than URL, which is a 
> possibility) I'd love to hear ideas.


  It may be suboptimal/there may be better ways, but what I would do
in your situation would be to save the real twitteR results to a
.Rdata file (e.g. put it in inst/vignetteData) and then 'fake' the
twitter call: add a non-eval'd but echo'd chunk that appears to run
the command, and an eval'd but non-echo'd chunk that loads the results
of having run the command.

   Ben Bolker


From h.wickham at gmail.com  Wed Aug 28 23:13:57 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 28 Aug 2013 16:13:57 -0500
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E5AD0.7070409@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>
	<521E5AD0.7070409@gmail.com>
Message-ID: <CABdHhvEiR-nWOBA36gTgpexqy3ASzHw9QtXKqqd+KB6gX=pMuw@mail.gmail.com>

>  3/ Some functions are exported normally but hidden by using "." in the
> beginning of their names. Other package maintainers would know they exist,
> but end users would not so easily find them. (Duncan's other suggestion of
> using \keyword{internal} in the .Rd file strikes me as problematic. I'm
> surprised CRAN checks do not already object to functions exported and
> documented with \keyword{internal}.)

Why? I think this is exactly the use case of \keyword{internal}.

-- 
Chief Scientist, RStudio
http://had.co.nz/


From geoffjentry at hexdump.org  Wed Aug 28 23:19:43 2013
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Wed, 28 Aug 2013 14:19:43 -0700
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <loom.20130828T225613-593@post.gmane.org>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
Message-ID: <alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>

On Wed, 28 Aug 2013, Ben Bolker wrote:
>  It may be suboptimal/there may be better ways, but what I would do in 
> your situation would be to save the real twitteR results to a .Rdata 
> file (e.g. put it in inst/vignetteData) and then 'fake' the twitter 
> call: add a non-eval'd but echo'd chunk that appears to run the command, 
> and an eval'd but non-echo'd chunk that loads the results of having run 
> the command.

Interesting, I'll look into doing that.

Thanks
-J


From gmbecker at ucdavis.edu  Wed Aug 28 23:43:58 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 28 Aug 2013 14:43:58 -0700
Subject: [Rd] model.frame(), model.matrix(),
	and derived predictor variables
In-Reply-To: <52196EA9.3070302@gmail.com>
References: <520FA2AE.7030109@gmail.com>
	<52196EA9.3070302@gmail.com>
Message-ID: <CADwqtCNvOOna0th5wDch133Q_3WGWYGKxSnnj_J8S5HXO6EqSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130828/2c8f67f6/attachment.pl>

From hb at biostat.ucsf.edu  Wed Aug 28 23:49:25 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 28 Aug 2013 14:49:25 -0700
Subject: [Rd] Error when using buildVignettes()
In-Reply-To: <521E5076.9020106@aon.at>
References: <521E5076.9020106@aon.at>
Message-ID: <CAFDcVCSGCkxqYMC9MJAyLY6ybby6qX3mg+P97dX1yKA4ap7qFg@mail.gmail.com>

> > sessionInfo()
> R version 3.0.0 Patched (2013-04-11 r62551)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)

I would check with R 3.0.1 patched and R devel before anything else,
especially when troubleshooting vignette-related issues.

/Henrik


On Wed, Aug 28, 2013 at 12:33 PM, cstrato <cstrato at aon.at> wrote:
> Dear all,
>
> When running function 'testQAReport()', which uses function
> 'buildVignettes()' to create a pdf-file I get the following error:
>
>> source("testQAReport.R")
>> testQAReport()
> Error in .get_package_metadata(pkgdir) :
>   Files 'DESCRIPTION' and 'DESCRIPTION.in' are missing.
>
> Since I did not get this error in earlier versions of R, could you please
> tell me what may be the reason for this error?
>
>
> Here is the code for "testQAReport.R":
>
> #------------------------------------------------------------------------------#
> # testQAReport.R: test quality control report
> # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
> - -
> testQAReport <-
> function(dataset     = "My Dataset",
>          title       = "Quality Report",
>          date        = "October, 2011",
>          author      = "Christian Stratowa",
>          outdir      = file.path(getwd(), "TestQA"),
>          ...)
> {
>    ## directory containing parts of QAReport.Rnw
>    indir <- file.path(path.package("xps"), "QC");
>
>    ## create directory containing final QAReport.Rnw
>    if (!dir.create(outdir))
>       stop("could not create report directory");
>    if (!dir.create(file.path(outdir, "inst")))
>       stop("could not create report subdirectory 'inst'");
>    if (!dir.create(file.path(outdir, "inst", "doc")))
>       stop("could not create report subdirectory 'doc'");
>    docdir <- file.path(outdir, "inst", "doc");
>
>    QCb <- readLines(file.path(indir, "QC.begin.Rnw"));
>
>    ## replace title, date, author
>    QCb <- sub("@TITLE@",  title,  QCb);
>    QCb <- sub("@DATE@",   date,   QCb);
>    QCb <- sub("@AUTHOR@", author, QCb);
>
>    ## dataset info
>    numtrees <- 6; chipname <- "Test3"; chiptype <- "GeneChip";
>    QCb <- sub("@DATASET@",  dataset,  QCb);
>    QCb <- sub("@NUMTREES@", numtrees, QCb);
>    QCb <- sub("@CHIPNAME@", chipname, QCb);
>    QCb <- sub("@CHIPTYPE@", chiptype, QCb);
>
>    write(QCb, file.path(docdir, "QAReport.Rnw"));
>
>    QCe <- readLines(file.path(indir, "QC.end.Rnw"));
>    QCe <- sub("@DATASET@",  dataset,  QCe);
>    QCe <- gsub("_","\\\\_", QCe);
>
>    write(QCe, file.path(docdir, "QAReport.Rnw"), append=TRUE);
>
>    ## build vignette QC.pdf
>    if (require(tools)) {
>       buildVignettes(dir=outdir, lib.loc=NULL, quiet=FALSE, clean=FALSE);
>    }#if
> }#xpsQAReport
>
> #------------------------------------------------------------------------------#
>
> The file "QC.begin.Rnw" is as follows:
>
> \documentclass{article}
>
>
> \textwidth=6.2in
> \textheight=8.5in
> %\parskip=.3cm
> \oddsidemargin=.1in
> \evensidemargin=.1in
> \headheight=-.3in
>
> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
> \newcommand{\Rcode}[1]{{\texttt{#1}}}
> \newcommand{\Robject}[1]{{\texttt{#1}}}
> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
> \newcommand{\Rclass}[1]{{\textit{#1}}}
> \newcommand{\Cclass}[1]{{\textit{#1}}}
> \newcommand{\Rexten}[1]{{\textit{#1}}}
> \newcommand{\xps}{\Rpackage{xps}}
> \newcommand{\ROOT}{\Robject{ROOT}}
>
> \begin{document}
>
> \title{@TITLE@}
> \date{@DATE@}
> \author{@AUTHOR@}
> \maketitle
>
> \tableofcontents
>
>
> \section{Introduction}
>
>  This is the quality assessment report for the dataset '@DATASET@'. The
> dataset consists of
>  @NUMTREES@ Affymetrix @CHIPTYPE@ arrays of type '@CHIPNAME@'. \\
>
>  This report was generated using function \Rfunction{xpsQAReport} of package
> \xps. \\
>
>
> The file "QC.end.Rnw" is as follows:
>
> \section{Summary}
>
>  The current quality report for dataset '@DATASET@' displays the most
> important quality plots, using the
>  default settings for most plots. Package \xps\ contains additional plots
> which can be used for further
>  quality assessments. \\
>
>
> \section*{Session Information:}
>
> <<echo=FALSE>>=
> sessionInfo()
> @
>
> \end{document}
>
>
> Finally, the output which is located in TestQA/inst/doc/QAReport.Rnw is as
> follows:
>
> \documentclass{article}
>
>
> \textwidth=6.2in
> \textheight=8.5in
> %\parskip=.3cm
> \oddsidemargin=.1in
> \evensidemargin=.1in
> \headheight=-.3in
>
> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
> \newcommand{\Rcode}[1]{{\texttt{#1}}}
> \newcommand{\Robject}[1]{{\texttt{#1}}}
> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
> \newcommand{\Rclass}[1]{{\textit{#1}}}
> \newcommand{\Cclass}[1]{{\textit{#1}}}
> \newcommand{\Rexten}[1]{{\textit{#1}}}
> \newcommand{\xps}{\Rpackage{xps}}
> \newcommand{\ROOT}{\Robject{ROOT}}
>
> \begin{document}
>
> \title{Quality Report}
> \date{October, 2011}
> \author{Christian Stratowa}
> \maketitle
>
> \tableofcontents
>
>
> \section{Introduction}
>
>  This is the quality assessment report for the dataset 'My Dataset'. The
> dataset consists of
>  6 Affymetrix GeneChip arrays of type 'Test3'. \\
>
>  This report was generated using function \Rfunction{xpsQAReport} of package
> \xps. \\
>
> \section{Summary}
>
>  The current quality report for dataset 'My Dataset' displays the most
> important quality plots, using the
>  default settings for most plots. Package \xps\ contains additional plots
> which can be used for further
>  quality assessments. \\
>
>
> \section*{Session Information:}
>
> <<echo=FALSE>>=
> sessionInfo()
> @
>
> \end{document}
>
>
> Can you please tell me why function buildVignettes() of the tools package is
> no longer able to convert this file into a pdf-file?
> Thank you in advance.
>
>
>> sessionInfo()
> R version 3.0.0 Patched (2013-04-11 r62551)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] xps_1.21.4
>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
> V.i.e.n.n.a           A.u.s.t.r.i.a
> e.m.a.i.l:        cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Thu Aug 29 00:10:07 2013
From: cstrato at aon.at (cstrato)
Date: Thu, 29 Aug 2013 00:10:07 +0200
Subject: [Rd] Error when using buildVignettes()
In-Reply-To: <CAFDcVCSGCkxqYMC9MJAyLY6ybby6qX3mg+P97dX1yKA4ap7qFg@mail.gmail.com>
References: <521E5076.9020106@aon.at>
	<CAFDcVCSGCkxqYMC9MJAyLY6ybby6qX3mg+P97dX1yKA4ap7qFg@mail.gmail.com>
Message-ID: <521E753F.5030708@aon.at>

Dear Henrik,

Thank you for your suggestion, however the error was detected by a user 
who is already using R 3.0.1, see:
https://www.stat.math.ethz.ch/pipermail/bioconductor/2013-August/054633.html

Best regards,
Christian


On 8/28/13 11:49 PM, Henrik Bengtsson wrote:
>>> sessionInfo()
>> R version 3.0.0 Patched (2013-04-11 r62551)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> I would check with R 3.0.1 patched and R devel before anything else,
> especially when troubleshooting vignette-related issues.
>
> /Henrik
>
>
> On Wed, Aug 28, 2013 at 12:33 PM, cstrato <cstrato at aon.at> wrote:
>> Dear all,
>>
>> When running function 'testQAReport()', which uses function
>> 'buildVignettes()' to create a pdf-file I get the following error:
>>
>>> source("testQAReport.R")
>>> testQAReport()
>> Error in .get_package_metadata(pkgdir) :
>>    Files 'DESCRIPTION' and 'DESCRIPTION.in' are missing.
>>
>> Since I did not get this error in earlier versions of R, could you please
>> tell me what may be the reason for this error?
>>
>>
>> Here is the code for "testQAReport.R":
>>
>> #------------------------------------------------------------------------------#
>> # testQAReport.R: test quality control report
>> # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
>> - -
>> testQAReport <-
>> function(dataset     = "My Dataset",
>>           title       = "Quality Report",
>>           date        = "October, 2011",
>>           author      = "Christian Stratowa",
>>           outdir      = file.path(getwd(), "TestQA"),
>>           ...)
>> {
>>     ## directory containing parts of QAReport.Rnw
>>     indir <- file.path(path.package("xps"), "QC");
>>
>>     ## create directory containing final QAReport.Rnw
>>     if (!dir.create(outdir))
>>        stop("could not create report directory");
>>     if (!dir.create(file.path(outdir, "inst")))
>>        stop("could not create report subdirectory 'inst'");
>>     if (!dir.create(file.path(outdir, "inst", "doc")))
>>        stop("could not create report subdirectory 'doc'");
>>     docdir <- file.path(outdir, "inst", "doc");
>>
>>     QCb <- readLines(file.path(indir, "QC.begin.Rnw"));
>>
>>     ## replace title, date, author
>>     QCb <- sub("@TITLE@",  title,  QCb);
>>     QCb <- sub("@DATE@",   date,   QCb);
>>     QCb <- sub("@AUTHOR@", author, QCb);
>>
>>     ## dataset info
>>     numtrees <- 6; chipname <- "Test3"; chiptype <- "GeneChip";
>>     QCb <- sub("@DATASET@",  dataset,  QCb);
>>     QCb <- sub("@NUMTREES@", numtrees, QCb);
>>     QCb <- sub("@CHIPNAME@", chipname, QCb);
>>     QCb <- sub("@CHIPTYPE@", chiptype, QCb);
>>
>>     write(QCb, file.path(docdir, "QAReport.Rnw"));
>>
>>     QCe <- readLines(file.path(indir, "QC.end.Rnw"));
>>     QCe <- sub("@DATASET@",  dataset,  QCe);
>>     QCe <- gsub("_","\\\\_", QCe);
>>
>>     write(QCe, file.path(docdir, "QAReport.Rnw"), append=TRUE);
>>
>>     ## build vignette QC.pdf
>>     if (require(tools)) {
>>        buildVignettes(dir=outdir, lib.loc=NULL, quiet=FALSE, clean=FALSE);
>>     }#if
>> }#xpsQAReport
>>
>> #------------------------------------------------------------------------------#
>>
>> The file "QC.begin.Rnw" is as follows:
>>
>> \documentclass{article}
>>
>>
>> \textwidth=6.2in
>> \textheight=8.5in
>> %\parskip=.3cm
>> \oddsidemargin=.1in
>> \evensidemargin=.1in
>> \headheight=-.3in
>>
>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>> \newcommand{\xps}{\Rpackage{xps}}
>> \newcommand{\ROOT}{\Robject{ROOT}}
>>
>> \begin{document}
>>
>> \title{@TITLE@}
>> \date{@DATE@}
>> \author{@AUTHOR@}
>> \maketitle
>>
>> \tableofcontents
>>
>>
>> \section{Introduction}
>>
>>   This is the quality assessment report for the dataset '@DATASET@'. The
>> dataset consists of
>>   @NUMTREES@ Affymetrix @CHIPTYPE@ arrays of type '@CHIPNAME@'. \\
>>
>>   This report was generated using function \Rfunction{xpsQAReport} of package
>> \xps. \\
>>
>>
>> The file "QC.end.Rnw" is as follows:
>>
>> \section{Summary}
>>
>>   The current quality report for dataset '@DATASET@' displays the most
>> important quality plots, using the
>>   default settings for most plots. Package \xps\ contains additional plots
>> which can be used for further
>>   quality assessments. \\
>>
>>
>> \section*{Session Information:}
>>
>> <<echo=FALSE>>=
>> sessionInfo()
>> @
>>
>> \end{document}
>>
>>
>> Finally, the output which is located in TestQA/inst/doc/QAReport.Rnw is as
>> follows:
>>
>> \documentclass{article}
>>
>>
>> \textwidth=6.2in
>> \textheight=8.5in
>> %\parskip=.3cm
>> \oddsidemargin=.1in
>> \evensidemargin=.1in
>> \headheight=-.3in
>>
>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>> \newcommand{\xps}{\Rpackage{xps}}
>> \newcommand{\ROOT}{\Robject{ROOT}}
>>
>> \begin{document}
>>
>> \title{Quality Report}
>> \date{October, 2011}
>> \author{Christian Stratowa}
>> \maketitle
>>
>> \tableofcontents
>>
>>
>> \section{Introduction}
>>
>>   This is the quality assessment report for the dataset 'My Dataset'. The
>> dataset consists of
>>   6 Affymetrix GeneChip arrays of type 'Test3'. \\
>>
>>   This report was generated using function \Rfunction{xpsQAReport} of package
>> \xps. \\
>>
>> \section{Summary}
>>
>>   The current quality report for dataset 'My Dataset' displays the most
>> important quality plots, using the
>>   default settings for most plots. Package \xps\ contains additional plots
>> which can be used for further
>>   quality assessments. \\
>>
>>
>> \section*{Session Information:}
>>
>> <<echo=FALSE>>=
>> sessionInfo()
>> @
>>
>> \end{document}
>>
>>
>> Can you please tell me why function buildVignettes() of the tools package is
>> no longer able to convert this file into a pdf-file?
>> Thank you in advance.
>>
>>
>>> sessionInfo()
>> R version 3.0.0 Patched (2013-04-11 r62551)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] tools     stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> other attached packages:
>> [1] xps_1.21.4
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>> V.i.e.n.n.a           A.u.s.t.r.i.a
>> e.m.a.i.l:        cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Thu Aug 29 00:58:38 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 28 Aug 2013 15:58:38 -0700
Subject: [Rd] Error when using buildVignettes()
In-Reply-To: <521E753F.5030708@aon.at>
References: <521E5076.9020106@aon.at>
	<CAFDcVCSGCkxqYMC9MJAyLY6ybby6qX3mg+P97dX1yKA4ap7qFg@mail.gmail.com>
	<521E753F.5030708@aon.at>
Message-ID: <CAFDcVCQbhehTVOn0tvjokdkf2Q83DvLDBTnsRfdzdKYZ=1N+iw@mail.gmail.com>

Ok.  ...I've now read your original thread more carefully, and I'd say
that tools::buildVignettes() is intended for building vignettes within
packages, not for compiling vignette files in general.  This is most
likely why it complains - it simply looks for files that it expect to
see in a package source tree.  FYI, lots of changes were made to these
tools in R 3.0.0, which may explain why you didn't see them before
(not saying it was correct usage before either).

I'd say, use Sweave/Stangle "manually" and then pass it on to tools::texi2pdf().

<sales pitch>
1. For *.Rnw -> *.tex -> *.pdf, you can use R.rsp::compileRnw() that
does all this in one go with more sanity checks.

2. Instead of using all those sub("@TITLE@",  title, ...) coding to
generate the report Rnw from a main Rnw template, add a layer of RSP
markup and run it through the RSP compiler.  For instance, with a
template.Rnw.rsp containing:

 This is the quality assessment report for the dataset '<%=dataset%>'.
The dataset consists of
 <%=numtrees%> Affymetrix <%=chiptype%> arrays of type '<%=chipname%>'.

you can compile it all in one go into a final PDF by pdf <-
R.rsp::rfile("template.Rnw.rsp").  RSP supports <%@include
file="..."%> statements and more if you wish to bring multiple Rnw
templates into a final one.  See help("R.rsp") for vignettes etc.
</sales pitch>

On Wed, Aug 28, 2013 at 3:10 PM, cstrato <cstrato at aon.at> wrote:
> Dear Henrik,
>
> Thank you for your suggestion, however the error was detected by a user who
> is already using R 3.0.1, see:
> https://www.stat.math.ethz.ch/pipermail/bioconductor/2013-August/054633.html
>
> Best regards,
> Christian
>
>
>
> On 8/28/13 11:49 PM, Henrik Bengtsson wrote:
>>>>
>>>> sessionInfo()
>>>
>>> R version 3.0.0 Patched (2013-04-11 r62551)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>>
>> I would check with R 3.0.1 patched and R devel before anything else,
>> especially when troubleshooting vignette-related issues.
>>
>> /Henrik
>>
>>
>> On Wed, Aug 28, 2013 at 12:33 PM, cstrato <cstrato at aon.at> wrote:
>>>
>>> Dear all,
>>>
>>> When running function 'testQAReport()', which uses function
>>> 'buildVignettes()' to create a pdf-file I get the following error:
>>>
>>>> source("testQAReport.R")
>>>> testQAReport()
>>>
>>> Error in .get_package_metadata(pkgdir) :
>>>    Files 'DESCRIPTION' and 'DESCRIPTION.in' are missing.
>>>
>>> Since I did not get this error in earlier versions of R, could you please
>>> tell me what may be the reason for this error?
>>>
>>>
>>> Here is the code for "testQAReport.R":
>>>
>>>
>>> #------------------------------------------------------------------------------#
>>> # testQAReport.R: test quality control report
>>> # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
>>> -
>>> - -
>>> testQAReport <-
>>> function(dataset     = "My Dataset",
>>>           title       = "Quality Report",
>>>           date        = "October, 2011",
>>>           author      = "Christian Stratowa",
>>>           outdir      = file.path(getwd(), "TestQA"),
>>>           ...)
>>> {
>>>     ## directory containing parts of QAReport.Rnw
>>>     indir <- file.path(path.package("xps"), "QC");
>>>
>>>     ## create directory containing final QAReport.Rnw
>>>     if (!dir.create(outdir))
>>>        stop("could not create report directory");
>>>     if (!dir.create(file.path(outdir, "inst")))
>>>        stop("could not create report subdirectory 'inst'");
>>>     if (!dir.create(file.path(outdir, "inst", "doc")))
>>>        stop("could not create report subdirectory 'doc'");
>>>     docdir <- file.path(outdir, "inst", "doc");
>>>
>>>     QCb <- readLines(file.path(indir, "QC.begin.Rnw"));
>>>
>>>     ## replace title, date, author
>>>     QCb <- sub("@TITLE@",  title,  QCb);
>>>     QCb <- sub("@DATE@",   date,   QCb);
>>>     QCb <- sub("@AUTHOR@", author, QCb);
>>>
>>>     ## dataset info
>>>     numtrees <- 6; chipname <- "Test3"; chiptype <- "GeneChip";
>>>     QCb <- sub("@DATASET@",  dataset,  QCb);
>>>     QCb <- sub("@NUMTREES@", numtrees, QCb);
>>>     QCb <- sub("@CHIPNAME@", chipname, QCb);
>>>     QCb <- sub("@CHIPTYPE@", chiptype, QCb);
>>>
>>>     write(QCb, file.path(docdir, "QAReport.Rnw"));
>>>
>>>     QCe <- readLines(file.path(indir, "QC.end.Rnw"));
>>>     QCe <- sub("@DATASET@",  dataset,  QCe);
>>>     QCe <- gsub("_","\\\\_", QCe);
>>>
>>>     write(QCe, file.path(docdir, "QAReport.Rnw"), append=TRUE);
>>>
>>>     ## build vignette QC.pdf
>>>     if (require(tools)) {
>>>        buildVignettes(dir=outdir, lib.loc=NULL, quiet=FALSE,
>>> clean=FALSE);
>>>     }#if
>>> }#xpsQAReport
>>>
>>>
>>> #------------------------------------------------------------------------------#
>>>
>>> The file "QC.begin.Rnw" is as follows:
>>>
>>> \documentclass{article}
>>>
>>>
>>> \textwidth=6.2in
>>> \textheight=8.5in
>>> %\parskip=.3cm
>>> \oddsidemargin=.1in
>>> \evensidemargin=.1in
>>> \headheight=-.3in
>>>
>>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>>> \newcommand{\xps}{\Rpackage{xps}}
>>> \newcommand{\ROOT}{\Robject{ROOT}}
>>>
>>> \begin{document}
>>>
>>> \title{@TITLE@}
>>> \date{@DATE@}
>>> \author{@AUTHOR@}
>>> \maketitle
>>>
>>> \tableofcontents
>>>
>>>
>>> \section{Introduction}
>>>
>>>   This is the quality assessment report for the dataset '@DATASET@'. The
>>> dataset consists of
>>>   @NUMTREES@ Affymetrix @CHIPTYPE@ arrays of type '@CHIPNAME@'. \\
>>>
>>>   This report was generated using function \Rfunction{xpsQAReport} of
>>> package
>>> \xps. \\
>>>
>>>
>>> The file "QC.end.Rnw" is as follows:
>>>
>>> \section{Summary}
>>>
>>>   The current quality report for dataset '@DATASET@' displays the most
>>> important quality plots, using the
>>>   default settings for most plots. Package \xps\ contains additional
>>> plots
>>> which can be used for further
>>>   quality assessments. \\
>>>
>>>
>>> \section*{Session Information:}
>>>
>>> <<echo=FALSE>>=
>>> sessionInfo()
>>> @
>>>
>>> \end{document}
>>>
>>>
>>> Finally, the output which is located in TestQA/inst/doc/QAReport.Rnw is
>>> as
>>> follows:
>>>
>>> \documentclass{article}
>>>
>>>
>>> \textwidth=6.2in
>>> \textheight=8.5in
>>> %\parskip=.3cm
>>> \oddsidemargin=.1in
>>> \evensidemargin=.1in
>>> \headheight=-.3in
>>>
>>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>>> \newcommand{\xps}{\Rpackage{xps}}
>>> \newcommand{\ROOT}{\Robject{ROOT}}
>>>
>>> \begin{document}
>>>
>>> \title{Quality Report}
>>> \date{October, 2011}
>>> \author{Christian Stratowa}
>>> \maketitle
>>>
>>> \tableofcontents
>>>
>>>
>>> \section{Introduction}
>>>
>>>   This is the quality assessment report for the dataset 'My Dataset'. The
>>> dataset consists of
>>>   6 Affymetrix GeneChip arrays of type 'Test3'. \\
>>>
>>>   This report was generated using function \Rfunction{xpsQAReport} of
>>> package
>>> \xps. \\
>>>
>>> \section{Summary}
>>>
>>>   The current quality report for dataset 'My Dataset' displays the most
>>> important quality plots, using the
>>>   default settings for most plots. Package \xps\ contains additional
>>> plots
>>> which can be used for further
>>>   quality assessments. \\
>>>
>>>
>>> \section*{Session Information:}
>>>
>>> <<echo=FALSE>>=
>>> sessionInfo()
>>> @
>>>
>>> \end{document}
>>>
>>>
>>> Can you please tell me why function buildVignettes() of the tools package
>>> is
>>> no longer able to convert this file into a pdf-file?
>>> Thank you in advance.
>>>
>>>
>>>> sessionInfo()
>>>
>>> R version 3.0.0 Patched (2013-04-11 r62551)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>> [1] C
>>>
>>> attached base packages:
>>> [1] tools     stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>> [1] xps_1.21.4
>>>
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._._._
>>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a           A.u.s.t.r.i.a
>>> e.m.a.i.l:        cstrato at aon.at
>>> _._._._._._._._._._._._._._._._._._
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From Mark.Bravington at csiro.au  Thu Aug 29 01:14:27 2013
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 28 Aug 2013 23:14:27 +0000
Subject: [Rd] ':::' call
In-Reply-To: <521E4DDE.8010404@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>	<521E4666.8080603@gmail.com>
	<CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>
	<521E4DDE.8010404@gmail.com>
Message-ID: <1D2694C7C3A6C04AA75E11C592A882E44F83FFFD@exmbx05-cdc.nexus.csiro.au>

<< Extracted from email trail below >>

> And as a potential user of your package, I don't want you to 
> use ::: if you don't have control over the other package, 
> because its author might unwittingly change it in a way that 
> causes me to get incorrect results.
> 
> If you want to use :::, go ahead, just don't put your package 
> on CRAN, where I get most of my packages.  Then we'll both be happy.
> 

Fine. BTW, when will CRAN be removing the C(omprehensive) from its name?

CRAN can never offer any guarantee that code works properly. Lots of code on CRAN doesn't, that's why packages have bug-fix releases all the time. And packages sometimes change the functionality even of functions that they *do* export. I certainly don't blindly trust stuff I download from CRAN; code aside, lots of it has excruciating documentation which hardly inspires faith. Nor do I blame CRAN for hosting bad code. CRAN is just a library; libraries are not responsible for the content of the books they hold.

With respect specifically to ::: : to guard against functionality changes of the type mentioned, B just needs to use a strict version check on A's package in the NAMESPACE. When A updates on CRAN, B will realize that the new version needs to be checked (because B's package will refuse to load on systems using the new version of A), and B can check functionality and amend their version check.

Adding yet more options about limited exports etc is not a good idea, I think. R's structure is REALLY complicated, particularly when it comes to packages. There is already too much stuff, too many different ways to do things. That is probably one reason why there is so much confusion and indeed so many bad choices from maintainers. Adding yet more techno-fixes is liable to be counterproductive.

Still in the case of :::, I agree with Yihui Xie that CRAN should not bother worrying about it. A Note would be OK if it weren't that Notes have a nasty habit of somehow turning into Warnings. In that respect: why not just have a separate package that has all sort of checks that anyone might ever want (I find most of them useless, but I know others like them), but that is independent of CRAN checks?

More generally, while the principles that CRAN espouses seemed OK to me last time I checked (eg  packages shouldn't mess each other up), the same is not true for the approach CRAN takes to them. The plethora of checks makes the whole thing legalistic: the criterion becomes not "is this package any good?" but "does it pass checks AA-ZZ?" So, for a maintainer with very limited time for arguments and who knows their own code and is well aware that the CRAN checks produce lots of False Positives and also False Negatives (there is lots of bad code out there...), it's hardly surprising if there is every temptation to just pop in a workaround.

If there was a much tighter, and well-explained, set of checks, then I reckon there would be fewer workarounds overall (because of a cultural shift, not just in terms of superfluous checks that have been removed) and there wouldn't be the need for lengthy dialogs between maintainers and CRAN. Notwithstanding the enormous efforts that the CRAN people put in (whoever they may be...): CRAN might be better off working with human nature(s), not against it.

bye
Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Thursday, 29 August 2013 5:22 AM
> To: Kasper Daniel Hansen
> Cc: Marc Schwartz; R-devel at r-project.org; Paul Gilbert
> Subject: Re: [Rd] ':::' call
> 
> On 28/08/2013 3:06 PM, Kasper Daniel Hansen wrote:
> > My point of view is that if you have a core package where you need 
> > access to "hidden" functions for making a plugin, you 
> should probably 
> > export these hidden functions in the first place.  Chances 
> are that if 
> > you need access to these hidden functions (for expert use), other 
> > (expert) users might want access as well, so take the time 
> to export and document it.
> >
> > I want to use ::: specifically for the case where I have no control 
> > over the other package.
> 
> And as a potential user of your package, I don't want you to 
> use ::: if you don't have control over the other package, 
> because its author might unwittingly change it in a way that 
> causes me to get incorrect results.
> 
> If you want to use :::, go ahead, just don't put your package 
> on CRAN, where I get most of my packages.  Then we'll both be happy.
> 
> Duncan Murdoch
> >
> > Best,
> > Kasper
> >
> >
> >
> >
> > On Wed, Aug 28, 2013 at 2:50 PM, Paul Gilbert 
> <pgilbert902 at gmail.com> wrote:
> >
> > > On 13-08-28 12:29 PM, Marc Schwartz wrote:
> > >
> > >>
> > >> On Aug 28, 2013, at 11:15 AM, Paul Gilbert 
> <pgilbert902 at gmail.com> wrote:
> > >>
> > >>  I have a package (TSdbi) which provides end user 
> functions that I
> > >>> export, and several utilities for plugin packages (e.g. 
> TSMySQL) 
> > >>> that I do not export because I do not intend them to be 
> exposed to 
> > >>> end users. I call these from the plugin packages using 
> TSdbi:::  
> > >>> but that now produces a note in the checks:
> > >>>
> > >>> * checking dependencies in R code ... NOTE Namespace 
> imported from 
> > >>> by a ':::' call: 'TSdbi'
> > >>>   See the note in ?`:::` about the use of this 
> operator. :: should be
> > >>>   used rather than ::: if the function is exported, and 
> a package
> > >>>   almost never needs to use ::: for its own functions.
> > >>>
> > >>> Is there a preferred method to accomplish this in a way 
> that does 
> > >>> not produce a note?
> > >>>
> > >>> Thanks,
> > >>> Paul
> > >>>
> > >>
> > >>
> > >>
> > >> Paul,
> > >>
> > >> See this rather lengthy discussion that occurred within 
> the past week:
> > >>
> > >>    
> > >> 
> https://stat.ethz.ch/**pipermail/r-devel/2013-August/**067180.html<
> > >> https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html>
> > >>
> > >> Regards,
> > >>
> > >> Marc Schwartz
> > >>
> > >
> > > I did follow the recent discussion, but no one answered 
> the question 
> > > "Is there a preferred method to accomplish this?" (I suppose the 
> > > answer is that there is no other way, given that no one actually 
> > > suggested anything else.) Most of the on topic discussion in that 
> > > thread was about how to subvert the CRAN checks, which is 
> not what I 
> > > am trying to do and was also pointed out as a bad idea by Duncan. 
> > > The substantive response was
> > >
> > > >r63654 has fixed this particular issue, and R-devel will 
> no longer 
> > > >warn against the use of ::: on packages of the same maintainer.
> > > >
> > > >Regards,
> > > >Yihui
> > >
> > > but that strikes me as a temporary work around rather than a real
> > > solution: suppose plugins are provided by a package from 
> another maintainer.
> > >
> > > Since CRAN notes have a habit of becoming warnings and 
> then errors, 
> > > it seems useful to identify the preferred legitimate 
> approach while 
> > > this is still a note. That would save work for both package 
> > > developers and CRAN maintainers.
> > >
> > > My thinking is that there is a need for a NAMESPACE directive 
> > > something like limitedExport() that allows ::: for identified 
> > > functions without provoking a CRAN complaint when 
> packages use those 
> > > functions. But there may already be a better way I don't 
> know about. 
> > > Or perhaps the solution is to split the end user 
> functions and the 
> > > utilities for plugin packages into two separate packages?
> > >
> > > Paul
> > >
> > >
> > > ______________________________**________________
> > > R-devel at r-project.org mailing list
> > > 
> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch
> > > /mailman/listinfo/r-devel>
> > >
> >
> > 	[[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

From pgilbert902 at gmail.com  Thu Aug 29 01:50:00 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 28 Aug 2013 19:50:00 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <CABdHhvEiR-nWOBA36gTgpexqy3ASzHw9QtXKqqd+KB6gX=pMuw@mail.gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>
	<521E5AD0.7070409@gmail.com>
	<CABdHhvEiR-nWOBA36gTgpexqy3ASzHw9QtXKqqd+KB6gX=pMuw@mail.gmail.com>
Message-ID: <521E8CA8.30205@gmail.com>



On 13-08-28 05:13 PM, Hadley Wickham wrote:
>>   3/ Some functions are exported normally but hidden by using "." in the
>> beginning of their names. Other package maintainers would know they exist,
>> but end users would not so easily find them. (Duncan's other suggestion of
>> using \keyword{internal} in the .Rd file strikes me as problematic. I'm
>> surprised CRAN checks do not already object to functions exported and
>> documented with \keyword{internal}.)
>
> Why? I think this is exactly the use case of \keyword{internal}.
>

 From Writing R extensions "The special keyword ?internal? marks a page 
of internal objects that are not part of the package?s API" which 
suggests to me that a function with \keyword{internal} should not be 
exported, since that makes it part of the API. And, if it is really for 
internal use in a package, why would you export it? I think you are 
interpreting "internal" to mean internal to a group of packages, not 
internal to a package. But that is just the complement of what I am 
saying: there may be a need for two levels of export.

(Also, if you export it then you should document it, but for many 
maintainers \keyword{internal} is shorthand for I don't need to document 
this properly because no one is suppose to use it outside the package.)

Paul


From gmbecker at ucdavis.edu  Thu Aug 29 02:13:47 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 28 Aug 2013 17:13:47 -0700
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E8CA8.30205@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CANROs4dNke+TBd2OVrY9q_cvLCVh9JkWsy+XaT66s_Ns3gcRpw@mail.gmail.com>
	<521E5AD0.7070409@gmail.com>
	<CABdHhvEiR-nWOBA36gTgpexqy3ASzHw9QtXKqqd+KB6gX=pMuw@mail.gmail.com>
	<521E8CA8.30205@gmail.com>
Message-ID: <CADwqtCN-NTG1UK6nBaobp7h-XHgzHfUehNe41fSGAzqctqXEfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130828/54509e27/attachment.pl>

From kasperdanielhansen at gmail.com  Thu Aug 29 03:00:33 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 28 Aug 2013 21:00:33 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <521E4DDE.8010404@gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>
	<521E4DDE.8010404@gmail.com>
Message-ID: <CAC2h7uuau6A7YQ=GaghBACqjRdv_Mh3WgOC-=6az9avLxkUExA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130828/459f302e/attachment.pl>

From comaths at hotmail.com  Wed Aug 28 18:09:57 2013
From: comaths at hotmail.com (comaths)
Date: Wed, 28 Aug 2013 09:09:57 -0700 (PDT)
Subject: [Rd] Rename the package published on CRAN
In-Reply-To: <521E1239.3000801@statistik.tu-dortmund.de>
References: <1377621514333-4674670.post@n4.nabble.com>
	<521E1239.3000801@statistik.tu-dortmund.de>
Message-ID: <1377706197687-4674768.post@n4.nabble.com>

Dear Uwe,

Thanks for your reply. Then I will keep the original name.

Best,

Comaths


Uwe Ligges-3 wrote
> On 27.08.2013 18:38, comaths wrote:
>> Hello Folks,
>>
>> I have an R package published on CRAN and I want to rename it for the
>> next
>> version, something like from "rName" to "rNAME". I have read the CRAN
>> policy, but did not find any topic regarding to this.  So does anybody
>> know
>> whether there is any CRAN policy for this? Thanks!
> 
> Actually you cannot: CRAN had to archive rName at first, but then no 
> other package with the name but different capitalization can be added to 
> CRAN, since that name is taken and packages work on file level where 
> some operating systems cannot distinguish capitalization appropriately 
> enough, hence the name rNAME is not available after archival of rName 
> ... The is a simple technical restriction.
> 
> Even with a really different name, renaming packages should be reduced 
> to an absolute minimum and would probably only accepted for legal 
> concerns related to inappropriate package names.
> 
> Best,
> Uwe Ligges
> 
> 
> 
> 
> 
>>
>> Best,
>>
>> C
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Rename-the-package-published-on-CRAN-tp4674670.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> 

> R-devel@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________

> R-devel@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel





--
View this message in context: http://r.789695.n4.nabble.com/Rename-the-package-published-on-CRAN-tp4674670p4674768.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Thu Aug 29 13:19:42 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Aug 2013 07:19:42 -0400
Subject: [Rd] =?windows-1252?q?=91=3A=3A=3A=92_call?=
In-Reply-To: <CAC2h7uuau6A7YQ=GaghBACqjRdv_Mh3WgOC-=6az9avLxkUExA@mail.gmail.com>
References: <521E221E.3020107@gmail.com>
	<E340A230-94C4-4ED3-BD42-0C72F8CAC340@me.com>
	<521E4666.8080603@gmail.com>
	<CAC2h7utx9=Guxidk3Bt1f42=yobbqRSk3ZE0eRC89np+r1JUrA@mail.gmail.com>
	<521E4DDE.8010404@gmail.com>
	<CAC2h7uuau6A7YQ=GaghBACqjRdv_Mh3WgOC-=6az9avLxkUExA@mail.gmail.com>
Message-ID: <521F2E4E.7080909@gmail.com>

On 13-08-28 9:00 PM, Kasper Daniel Hansen wrote:
>
>
>
> On Wed, Aug 28, 2013 at 3:22 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 28/08/2013 3:06 PM, Kasper Daniel Hansen wrote:
>
>         My point of view is that if you have a core package where you
>         need access
>         to "hidden" functions for making a plugin, you should probably
>         export these
>         hidden functions in the first place.  Chances are that if you
>         need access
>         to these hidden functions (for expert use), other (expert) users
>         might want
>         access as well, so take the time to export and document it.
>
>         I want to use ::: specifically for the case where I have no
>         control over
>         the other package.
>
>
>     And as a potential user of your package, I don't want you to use :::
>     if you don't have control over the other package, because its author
>     might unwittingly change it in a way that causes me to get incorrect
>     results.
>
>
> Perhaps you have heard of the concept of "testing".  R actually has good
> testing facilities (if you include add-on packages) and these facilities
> are very helpful in checking whether the answers provided by a package
> are correct. /sarcasm off

How does this argument not apply to *all* tests done by CRAN? Should it 
stop doing any tests at all, because users can do them if they care?

Duncan Murdoch

>
> And btw. nothing guarantees that the output of an exported function does
> not change when the package version change.  Only testing can help you here.
>
> I don't know if CRAN re-checks a package if dependencies change, but
> obviously it ought to, from a software validity point of view.
>
> Best,
> Kasper
>
>     If you want to use :::, go ahead, just don't put your package on
>     CRAN, where I get most of my packages.  Then we'll both be happy.
>
>     Duncan Murdoch
>
>
>         Best,
>         Kasper
>
>
>
>
>         On Wed, Aug 28, 2013 at 2:50 PM, Paul Gilbert
>         <pgilbert902 at gmail.com <mailto:pgilbert902 at gmail.com>> wrote:
>
>          > On 13-08-28 12:29 PM, Marc Schwartz wrote:
>          >
>          >>
>          >> On Aug 28, 2013, at 11:15 AM, Paul Gilbert
>         <pgilbert902 at gmail.com <mailto:pgilbert902 at gmail.com>> wrote:
>          >>
>          >>  I have a package (TSdbi) which provides end user functions
>         that I
>          >>> export, and several utilities for plugin packages (e.g.
>         TSMySQL) that I do
>          >>> not export because I do not intend them to be exposed to
>         end users. I call
>          >>> these from the plugin packages using TSdbi:::  but that now
>         produces a note
>          >>> in the checks:
>          >>>
>          >>> * checking dependencies in R code ... NOTE
>          >>> Namespace imported from by a ?:::? call: ?TSdbi?
>          >>>   See the note in ?`:::` about the use of this operator. ::
>         should be
>          >>>   used rather than ::: if the function is exported, and a
>         package
>          >>>   almost never needs to use ::: for its own functions.
>          >>>
>          >>> Is there a preferred method to accomplish this in a way
>         that does not
>          >>> produce a note?
>          >>>
>          >>> Thanks,
>          >>> Paul
>          >>>
>          >>
>          >>
>          >>
>          >> Paul,
>          >>
>          >> See this rather lengthy discussion that occurred within the
>         past week:
>          >>
>          >>
>         https://stat.ethz.ch/**__pipermail/r-devel/2013-August/__**067180.html
>         <https://stat.ethz.ch/**pipermail/r-devel/2013-August/**067180.html><https://stat.__ethz.ch/pipermail/r-devel/__2013-August/067180.html
>         <https://stat.ethz.ch/pipermail/r-devel/2013-August/067180.html>>
>
>          >>
>          >> Regards,
>          >>
>          >> Marc Schwartz
>          >>
>          >
>          > I did follow the recent discussion, but no one answered the
>         question "Is
>          > there a preferred method to accomplish this?" (I suppose the
>         answer is that
>          > there is no other way, given that no one actually suggested
>         anything else.)
>          > Most of the on topic discussion in that thread was about how
>         to subvert the
>          > CRAN checks, which is not what I am trying to do and was also
>         pointed out
>          > as a bad idea by Duncan. The substantive response was
>          >
>          > >r63654 has fixed this particular issue, and R-devel will no
>         longer
>          > >warn against the use of ::: on packages of the same maintainer.
>          > >
>          > >Regards,
>          > >Yihui
>          >
>          > but that strikes me as a temporary work around rather than a real
>          > solution: suppose plugins are provided by a package from
>         another maintainer.
>          >
>          > Since CRAN notes have a habit of becoming warnings and then
>         errors, it
>          > seems useful to identify the preferred legitimate approach
>         while this is
>          > still a note. That would save work for both package
>         developers and CRAN
>          > maintainers.
>          >
>          > My thinking is that there is a need for a NAMESPACE directive
>         something
>          > like limitedExport() that allows ::: for identified functions
>         without
>          > provoking a CRAN complaint when packages use those functions.
>         But there may
>          > already be a better way I don't know about. Or perhaps the
>         solution is to
>          > split the end user functions and the utilities for plugin
>         packages into two
>          > separate packages?
>          >
>          > Paul
>          >
>          >
>          > ________________________________**________________
>          > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>          > https://stat.ethz.ch/mailman/*__*listinfo/r-devel
>         <https://stat.ethz.ch/mailman/**listinfo/r-devel><https://__stat.ethz.ch/mailman/listinfo/__r-devel
>         <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>          >
>
>                  [[alternative HTML version deleted]]
>
>
>
>
>         ________________________________________________
>         R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-devel
>         <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>
>


From cstrato at aon.at  Thu Aug 29 14:08:19 2013
From: cstrato at aon.at (cstrato)
Date: Thu, 29 Aug 2013 14:08:19 +0200
Subject: [Rd] Packages not found
Message-ID: <521F39B3.9090204@aon.at>

Dear all,

On the CRAN website http://cran.r-project.org/ it is currently not 
possible to get to the packages. Clicking on "Packages" or on 
"Contributed extension packages" results in Error 404: Object not 
found!, see: http://cran.r-project.org/web/packages/

Best regards,
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From ligges at statistik.tu-dortmund.de  Thu Aug 29 14:47:21 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 29 Aug 2013 14:47:21 +0200
Subject: [Rd] Packages not found
In-Reply-To: <521F39B3.9090204@aon.at>
References: <521F39B3.9090204@aon.at>
Message-ID: <521F42D9.7010606@statistik.tu-dortmund.de>

Thanks, we know, this is work in progress.

Uwe Ligges




On 29.08.2013 14:08, cstrato wrote:
> Dear all,
>
> On the CRAN website http://cran.r-project.org/ it is currently not
> possible to get to the packages. Clicking on "Packages" or on
> "Contributed extension packages" results in Error 404: Object not
> found!, see: http://cran.r-project.org/web/packages/
>
> Best regards,
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
> V.i.e.n.n.a           A.u.s.t.r.i.a
> e.m.a.i.l:        cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Aug 29 14:56:53 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Aug 2013 14:56:53 +0200
Subject: [Rd] Packages not found
In-Reply-To: <521F42D9.7010606@statistik.tu-dortmund.de>
References: <521F39B3.9090204@aon.at>
	<521F42D9.7010606@statistik.tu-dortmund.de>
Message-ID: <21023.17685.765190.525989@stat.math.ethz.ch>

>>>>> Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>     on Thu, 29 Aug 2013 14:47:21 +0200 writes:

    > Thanks, we know, this is work in progress.  Uwe Ligges

and mirrors still work, e.g.,

http://cran.CH.r-project.org/web/packages/
	    ---

Martin

    > On 29.08.2013 14:08, cstrato wrote:
    >> Dear all,
    >> 
    >> On the CRAN website http://cran.r-project.org/ it is
    >> currently not possible to get to the packages. Clicking
    >> on "Packages" or on "Contributed extension packages"
    >> results in Error 404: Object not found!, see:
    >> http://cran.r-project.org/web/packages/
    >> 
    >> Best regards, Christian


From cstrato at aon.at  Thu Aug 29 15:06:02 2013
From: cstrato at aon.at (cstrato)
Date: Thu, 29 Aug 2013 15:06:02 +0200
Subject: [Rd] Packages not found
In-Reply-To: <21023.17685.765190.525989@stat.math.ethz.ch>
References: <521F39B3.9090204@aon.at>
	<521F42D9.7010606@statistik.tu-dortmund.de>
	<21023.17685.765190.525989@stat.math.ethz.ch>
Message-ID: <521F473A.6060308@aon.at>

Dear Uwe and Martin,

Thank you for your reply and workaround.

Best regards,
Christian


On 8/29/13 2:56 PM, Martin Maechler wrote:
>>>>>> Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>      on Thu, 29 Aug 2013 14:47:21 +0200 writes:
>
>      > Thanks, we know, this is work in progress.  Uwe Ligges
>
> and mirrors still work, e.g.,
>
> http://cran.CH.r-project.org/web/packages/
> 	    ---
>
> Martin
>
>      > On 29.08.2013 14:08, cstrato wrote:
>      >> Dear all,
>      >>
>      >> On the CRAN website http://cran.r-project.org/ it is
>      >> currently not possible to get to the packages. Clicking
>      >> on "Packages" or on "Contributed extension packages"
>      >> results in Error 404: Object not found!, see:
>      >> http://cran.r-project.org/web/packages/
>      >>
>      >> Best regards, Christian
>


From bbolker at gmail.com  Thu Aug 29 15:21:52 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Aug 2013 09:21:52 -0400
Subject: [Rd] model.frame(), model.matrix(),
	and derived predictor variables
In-Reply-To: <CADwqtCNvOOna0th5wDch133Q_3WGWYGKxSnnj_J8S5HXO6EqSw@mail.gmail.com>
References: <520FA2AE.7030109@gmail.com> <52196EA9.3070302@gmail.com>
	<CADwqtCNvOOna0th5wDch133Q_3WGWYGKxSnnj_J8S5HXO6EqSw@mail.gmail.com>
Message-ID: <521F4AF0.9060908@gmail.com>

On 13-08-28 05:43 PM, Gabriel Becker wrote:
> Ben,
> 
> It works for me ...
>> x = rpois(100, 5) + 1
>> y = rnorm(100, x)
>> d = data.frame(x,y)
>> m <- lm(y~log(x),d)
>> update(m,data=model.frame(m))
> 
> Call:
> lm(formula = y ~ log(x), data = model.frame(m))
> 
> Coefficients:
> (Intercept)       log(x) 
>      -4.010        5.817 
> 
> 

    That's because x and y are still lying around in your global
environment.  If you rm(x); rm(y) then it won't work any more.  And it
wouldn't have worked if you had constructed your model frame directly as

 d = data.frame(x=rpois(100,5)+1)
 d = transform(d,y=rnorm(100,x))

> 
> You can also re-fit using the model.matrix directly. In your example,
> the model frame can be passed directly to lm.fit /lm.wfit.

    Yes, if I want to refit the same model.  But if I want to do
something else with the model (e.g. try fitting vs. x instead of log(x),
or some other function of x) then it doesn't work.

  cheers
    Ben
> 
> 
> ~G
> 
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8  
>  [7] LC_PAPER=C                 LC_NAME=C                
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C           
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base    
> 
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
> 
> 
> 
> 
> On Sat, Aug 24, 2013 at 7:40 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>       Bump: just trying one more time to see if anyone had thoughts on this
>     (so far it's just <crickets> ...)
> 
> 
>     -------- Original Message --------
>     Subject: model.frame(), model.matrix(), and derived predictor variables
>     Date: Sat, 17 Aug 2013 12:19:58 -0400
>     From: Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>
>     To: R-devel at stat.math.ethz.ch <mailto:R-devel at stat.math.ethz.ch>
>     <R-devel at stat.math.ethz.ch <mailto:R-devel at stat.math.ethz.ch>>
> 
> 
>       Dear r-developers:
> 
>       I am struggling with some fundamental aspects of model.frame().
> 
>       Conceptually, I think of a flow from data -> model.frame() ->
>     model.matrix; the data contain _input variables_, while model.matrix
>     contains _predictor variables_: data have been transformed, splines and
>     polynomials have been expanded into their corresponding
>     multi-dimensional bases, and factors have been expanded into appropriate
>     sets of dummy variables depending on their contrasts.
>       I originally thought of model.frame() as containing input variables as
>     well (but with only the variables needed by the model, and with cases
>     containing NAs handled according to the relevant na.action setting), but
>     that's not quite true.  While factors are retained as-is, splines and
>     polynomials and parameter transformations are evaluated. For example
> 
>     d <- data.frame(x=1:10,y=1:10)
>     model.frame(y~log(x),d)
> 
>     produces a model frame with columns 'y', 'log(x)' (not 'y', 'x').
> 
>     This makes it hard (impossible?) to use the model frame to re-evaluate
>     the existing formula in a model, e.g.
> 
>     m <- lm(y~log(x),d)
>     update(m,data=model.frame(m))
>     ## Error in eval(expr, envir, enclos) : object 'x' not found
> 
>     It seems to me that this is a reasonable thing to want to do
>     (i.e. use the model frame as a stored copy of the data that
>      can be used for additional model operations); otherwise, I
>     either need to carry along an additional copy of the data in
>     a slot, or hope that the model is still living in an environment
>     where it can find a copy of the original data.
> 
>     Does anyone have any insights into the original design choices,
>     or suggestions about how they have handled this within their own
>     code? Do you just add an additional data slot to the model?  I've
>     considered trying to write some kind of 'augmented' model frame, that
>     would contain the equivalent of
>     that appeared in the formula but not in the model frame ...].
>     setdiff(all.vars(formula),model.frame(m)) [i.e.  all input variables
>     that appeared in the formula but not in the model frame ...].
> 
>       thanks
>        Ben Bolker
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From h.wickham at gmail.com  Thu Aug 29 15:39:46 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 08:39:46 -0500
Subject: [Rd] Why does an empty vector occupy 40 bytes?
Message-ID: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>

Hi all,

Why is the object size of an empty vector 40 bytes? (At least in 64-bit R.)

object.size(integer(0))
# 40 bytes

Reading R internals, it looks like it should be:

* 4 bytes: sxpinfo header (= 32 bits)
* 8 bytes: pointer to attributes
* 8 bytes: pointer to next node
* 8 bytes: pointer to previous node
* 4 bytes: length
* 4 bytes: true length

= 36 bytes

Where are the extra 4 bytes coming from? What have I missed?

I thought it might be for memory alignment, but if it was padded by an
additional 4 bytes, then an integer vector of length 1 should be the
same size, assuming I've interpreted the comment about "aligned as
required" correctly.

Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From simon.urbanek at r-project.org  Thu Aug 29 16:59:09 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Aug 2013 10:59:09 -0400
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
Message-ID: <90CCA572-7E85-49FD-8013-EC936C5CBA7C@r-project.org>


On Aug 29, 2013, at 9:39 AM, Hadley Wickham wrote:

> Hi all,
> 
> Why is the object size of an empty vector 40 bytes? (At least in 64-bit R.)
> 
> object.size(integer(0))
> # 40 bytes
> 
> Reading R internals, it looks like it should be:
> 
> * 4 bytes: sxpinfo header (= 32 bits)
> * 8 bytes: pointer to attributes
> * 8 bytes: pointer to next node
> * 8 bytes: pointer to previous node
> * 4 bytes: length
> * 4 bytes: true length
> 
> = 36 bytes
> 
> Where are the extra 4 bytes coming from? What have I missed?
> 

Alignment of pointers -- there are 4 bytes of padding on 64-bit machines after sxpinfo


> I thought it might be for memory alignment, but if it was padded by an
> additional 4 bytes, then an integer vector of length 1 should be the
> same size, assuming I've interpreted the comment about "aligned as
> required" correctly.
> 
> Thanks!
> 
> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Thu Aug 29 17:10:44 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Aug 2013 16:10:44 +0100
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
Message-ID: <521F6474.40307@stats.ox.ac.uk>

On 29/08/2013 14:39, Hadley Wickham wrote:
> Hi all,
>
> Why is the object size of an empty vector 40 bytes? (At least in 64-bit R.)
>
> object.size(integer(0))
> # 40 bytes
>
> Reading R internals, it looks like it should be:
>
> * 4 bytes: sxpinfo header (= 32 bits)
> * 8 bytes: pointer to attributes
> * 8 bytes: pointer to next node
> * 8 bytes: pointer to previous node
> * 4 bytes: length
> * 4 bytes: true length
>
> = 36 bytes
>
> Where are the extra 4 bytes coming from? What have I missed?
>
> I thought it might be for memory alignment, but if it was padded by an
> additional 4 bytes, then an integer vector of length 1 should be the
> same size, assuming I've interpreted the comment about "aligned as
> required" correctly.

You have not: the start of the vector area also needs to be aligned 
(since it might hold doubles or CHARSXPs).

See memory.c, which says, inter alia

/* All vector objects must be a multiple of sizeof(SEXPREC_ALIGN)
    bytes so that alignment is preserved for all objects */

/* Node Classes.  Non-vector nodes are of class zero. Small vector
    nodes are in classes 1, ..., NUM_SMALL_NODE_CLASSES, and large
    vector nodes are in class LARGE_NODE_CLASS.  For vector nodes the
    node header is followed in memory by the vector data, offset from
    the header by SEXPREC_ALIGN. */

And also, object.size() is only approximate, and documented to be so. In 
fact many short vectors are using larger blocks of memory incompletely, 
and of course the OS is supplying memory in pages.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Thu Aug 29 18:08:35 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 11:08:35 -0500
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <521F6474.40307@stats.ox.ac.uk>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
Message-ID: <CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>

> You have not: the start of the vector area also needs to be aligned (since
> it might hold doubles or CHARSXPs).

Thanks, that was the key point I was missing. (Also mentioned to me
off list by Luke Tierney).

> See memory.c, which says, inter alia
>
> /* All vector objects must be a multiple of sizeof(SEXPREC_ALIGN)
>    bytes so that alignment is preserved for all objects */
>
> /* Node Classes.  Non-vector nodes are of class zero. Small vector
>    nodes are in classes 1, ..., NUM_SMALL_NODE_CLASSES, and large
>    vector nodes are in class LARGE_NODE_CLASS.  For vector nodes the
>    node header is followed in memory by the vector data, offset from
>    the header by SEXPREC_ALIGN. */
>
> And also, object.size() is only approximate, and documented to be so. In
> fact many short vectors are using larger blocks of memory incompletely, and
> of course the OS is supplying memory in pages.

Yes, the size of an object is a nebulous concept. Do you want the
marginal size or the average size? Do you want to know how big the
object is, or the impact of the object on memory allocation?

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From sat3lite at gmail.com  Thu Aug 29 20:11:10 2013
From: sat3lite at gmail.com (Sana Wajid)
Date: Thu, 29 Aug 2013 14:11:10 -0400
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
Message-ID: <CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130829/a4648a8b/attachment.pl>

From simon.urbanek at r-project.org  Thu Aug 29 20:12:10 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Aug 2013 14:12:10 -0400
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
Message-ID: <7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>

On Aug 29, 2013, at 12:08 PM, Hadley Wickham wrote:

>> You have not: the start of the vector area also needs to be aligned (since
>> it might hold doubles or CHARSXPs).
> 
> Thanks, that was the key point I was missing. (Also mentioned to me off list by Luke Tierney).
> 

Not to be picky, but that is not the point. The alignment is due to the attrib pointer which is at offset 8 despite the fact that there is only a 4-byte element in front of it. Maybe for better illustration, this is the layout on 64-bit machines:

* 4 bytes: sxpinfo header (= 32 bits)
* 4 bytes: --- padding so next ptr is aligned ---
* 8 bytes: pointer to attributes
* 8 bytes: pointer to next node
* 8 bytes: pointer to previous node
* 4 bytes: length
* 4 bytes: true length

= 40 bytes

This is already aligned so the payload alignment doesn't any extra padding so that has no effect at all.



>> See memory.c, which says, inter alia
>> 
>> /* All vector objects must be a multiple of sizeof(SEXPREC_ALIGN)
>>   bytes so that alignment is preserved for all objects */
>> 
>> /* Node Classes.  Non-vector nodes are of class zero. Small vector
>>   nodes are in classes 1, ..., NUM_SMALL_NODE_CLASSES, and large
>>   vector nodes are in class LARGE_NODE_CLASS.  For vector nodes the
>>   node header is followed in memory by the vector data, offset from
>>   the header by SEXPREC_ALIGN. */
>> 
>> And also, object.size() is only approximate, and documented to be so. In
>> fact many short vectors are using larger blocks of memory incompletely, and
>> of course the OS is supplying memory in pages.
> 
> Yes, the size of an object is a nebulous concept. Do you want the
> marginal size or the average size? Do you want to know how big the
> object is, or the impact of the object on memory allocation?
> 
> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From h.wickham at gmail.com  Thu Aug 29 20:37:06 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 13:37:06 -0500
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
Message-ID: <CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>

> Not to be picky, but that is not the point. The alignment is due to the attrib pointer which is at offset 8 despite the fact that there is only a 4-byte element in front of it. Maybe for better illustration, this is the layout on 64-bit machines:

Ok, thanks for the clarification.

>
> * 4 bytes: sxpinfo header (= 32 bits)
> * 4 bytes: --- padding so next ptr is aligned ---
> * 8 bytes: pointer to attributes
> * 8 bytes: pointer to next node
> * 8 bytes: pointer to previous node
> * 4 bytes: length
> * 4 bytes: true length
>
> = 40 bytes
>
> This is already aligned so the payload alignment doesn't any extra padding so that has no effect at all.

Do pointers always have to be aligned?

Hadley


-- 
Chief Scientist, RStudio
http://had.co.nz/


From simon.urbanek at r-project.org  Thu Aug 29 21:09:59 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Aug 2013 15:09:59 -0400
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
Message-ID: <B6D87831-7F8A-4474-B4A9-0021FC71B486@r-project.org>


On Aug 29, 2013, at 2:37 PM, Hadley Wickham wrote:

>> Not to be picky, but that is not the point. The alignment is due to the attrib pointer which is at offset 8 despite the fact that there is only a 4-byte element in front of it. Maybe for better illustration, this is the layout on 64-bit machines:
> 
> Ok, thanks for the clarification.
> 
>> 
>> * 4 bytes: sxpinfo header (= 32 bits)
>> * 4 bytes: --- padding so next ptr is aligned ---
>> * 8 bytes: pointer to attributes
>> * 8 bytes: pointer to next node
>> * 8 bytes: pointer to previous node
>> * 4 bytes: length
>> * 4 bytes: true length
>> 
>> = 40 bytes
>> 
>> This is already aligned so the payload alignment doesn't any extra padding so that has no effect at all.
> 
> Do pointers always have to be aligned?
> 

Depends on the architecture, e.g., Sparc doesn't allow non-aligned pointers at all (results in a segfault), SV x86_64 ABI specifies pointers to be aligned at 8 bytes, but the x86_64 CPUs will allow misaligned pointers with a performance penalty (the same was true for x86 - i.e. misaligned pointers are tolerated with a penalty).


From pdalgd at gmail.com  Thu Aug 29 21:11:02 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 29 Aug 2013 21:11:02 +0200
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
Message-ID: <309C5D98-6D0E-4A34-B399-6623960F1A2F@gmail.com>


On Aug 29, 2013, at 20:37 , Hadley Wickham wrote:

>> Not to be picky, but that is not the point. The alignment is due to the attrib pointer which is at offset 8 despite the fact that there is only a 4-byte element in front of it. Maybe for better illustration, this is the layout on 64-bit machines:
> 
> Ok, thanks for the clarification.
> 
>> 
>> * 4 bytes: sxpinfo header (= 32 bits)
>> * 4 bytes: --- padding so next ptr is aligned ---
>> * 8 bytes: pointer to attributes
>> * 8 bytes: pointer to next node
>> * 8 bytes: pointer to previous node
>> * 4 bytes: length
>> * 4 bytes: true length
>> 
>> = 40 bytes
>> 
>> This is already aligned so the payload alignment doesn't any extra padding so that has no effect at all.
> 
> Do pointers always have to be aligned?

I think that is architecture/compiler specific, but usually aligned pointers are loaded into memory in one clock cycle whereas unaligned ones take two, insofar as the architecture allows it at all. 

Back in the days when Sun machines went 64 bit (1993 or so?), there was an issue with dyn.loading into Splus, where it was passing unaligned pointers and gcc was expecting them to be aligned. Basically, it became a toss-up whether dyn.load calls would work or not... 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jgrn at illinois.edu  Thu Aug 29 21:15:09 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 29 Aug 2013 14:15:09 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
	<CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
Message-ID: <CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>

I had a similar question awhile ago.  Basically, my understanding is
if it is a function, it needs to be documented UNLESS you are calling
it via :::

--j

On Thu, Aug 29, 2013 at 1:11 PM, Sana Wajid <sat3lite at gmail.com> wrote:
> Thank you all, I appreciate your responses. Just a quick follow up
> question: couple of my functions are "background" or "behind the scenes"
> functions. Do these have to be documented in the manual as well?
>
>
> On Wed, Aug 28, 2013 at 5:19 PM, Geoff Jentry <geoffjentry at hexdump.org>wrote:
>
>> On Wed, 28 Aug 2013, Ben Bolker wrote:
>>
>>>  It may be suboptimal/there may be better ways, but what I would do in
>>> your situation would be to save the real twitteR results to a .Rdata file
>>> (e.g. put it in inst/vignetteData) and then 'fake' the twitter call: add a
>>> non-eval'd but echo'd chunk that appears to run the command, and an eval'd
>>> but non-echo'd chunk that loads the results of having run the command.
>>>
>>
>> Interesting, I'll look into doing that.
>>
>> Thanks
>> -J
>>
>>
>> ______________________________**________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From h.wickham at gmail.com  Thu Aug 29 21:26:29 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 14:26:29 -0500
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <B6D87831-7F8A-4474-B4A9-0021FC71B486@r-project.org>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
	<B6D87831-7F8A-4474-B4A9-0021FC71B486@r-project.org>
Message-ID: <CABdHhvGoM-bHcH0Q-zcWGwRZsRQzb4gU3yNvL6kNb2PHdF2Z0w@mail.gmail.com>

>> Do pointers always have to be aligned?
>
> Depends on the architecture, e.g., Sparc doesn't allow non-aligned pointers at all (results in a segfault), SV x86_64 ABI specifies pointers to be aligned at 8 bytes, but the x86_64 CPUs will allow misaligned pointers with a performance penalty (the same was true for x86 - i.e. misaligned pointers are tolerated with a penalty).

Ok, so you might not have to align pointers a particular architecture,
but if you're writing code that you want to work across multiple
architectures you must.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Thu Aug 29 21:33:57 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 14:33:57 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
	<CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
	<CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>
Message-ID: <CABdHhvEB=CwtDLYJZippO3Baf=yFK1UOdOGDvwDkBD76H6JFUA@mail.gmail.com>

You only need ::: if you're calling it from another package (and see
the lengthly recent discussion on that issue).  The key distinction is
whether the function is exported or not: You must document any
function that you export. You don't have to document any function you
don't export.

Hadley

On Thu, Aug 29, 2013 at 2:15 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> I had a similar question awhile ago.  Basically, my understanding is
> if it is a function, it needs to be documented UNLESS you are calling
> it via :::
>
> --j
>
> On Thu, Aug 29, 2013 at 1:11 PM, Sana Wajid <sat3lite at gmail.com> wrote:
>> Thank you all, I appreciate your responses. Just a quick follow up
>> question: couple of my functions are "background" or "behind the scenes"
>> functions. Do these have to be documented in the manual as well?
>>
>>
>> On Wed, Aug 28, 2013 at 5:19 PM, Geoff Jentry <geoffjentry at hexdump.org>wrote:
>>
>>> On Wed, 28 Aug 2013, Ben Bolker wrote:
>>>
>>>>  It may be suboptimal/there may be better ways, but what I would do in
>>>> your situation would be to save the real twitteR results to a .Rdata file
>>>> (e.g. put it in inst/vignetteData) and then 'fake' the twitter call: add a
>>>> non-eval'd but echo'd chunk that appears to run the command, and an eval'd
>>>> but non-echo'd chunk that loads the results of having run the command.
>>>>
>>>
>>> Interesting, I'll look into doing that.
>>>
>>> Thanks
>>> -J
>>>
>>>
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From simon.urbanek at r-project.org  Thu Aug 29 21:35:33 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Aug 2013 15:35:33 -0400
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvGoM-bHcH0Q-zcWGwRZsRQzb4gU3yNvL6kNb2PHdF2Z0w@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
	<B6D87831-7F8A-4474-B4A9-0021FC71B486@r-project.org>
	<CABdHhvGoM-bHcH0Q-zcWGwRZsRQzb4gU3yNvL6kNb2PHdF2Z0w@mail.gmail.com>
Message-ID: <0D4AE14D-4C68-4AD3-93C1-F01BCB66C82A@r-project.org>

On Aug 29, 2013, at 3:26 PM, Hadley Wickham wrote:

>>> Do pointers always have to be aligned?
>> 
>> Depends on the architecture, e.g., Sparc doesn't allow non-aligned pointers at all (results in a segfault), SV x86_64 ABI specifies pointers to be aligned at 8 bytes, but the x86_64 CPUs will allow misaligned pointers with a performance penalty (the same was true for x86 - i.e. misaligned pointers are tolerated with a penalty).
> 
> Ok, so you might not have to align pointers a particular architecture,
> but if you're writing code that you want to work across multiple
> architectures you must.
> 

Yes. In many cases the compiler does that for you (e.g. inside structs), but if you are constructing binary objects that will be loaded into memory directly and then accessed then, yes, you have to take that into account. Note that the alignment requirements are not just for pointers but for all types, e.g., Sparc also segfaults if you don't align doubles on 8-byte boundary.

It is also a good idea to have alignment in mind when designing structs, e.g.:

struct a {
    char flag;
    char *name;
    char active;
    char *description;
    int  len;
};

takes 40 bytes on 64-bit machine, while just re-ordering the members to

struct b {
    char *name;
    char *description;
    char flag;
    char active;
    int  len;
};

takes 24 bytes.

Cheers,
Simon


> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> 


From jgrn at illinois.edu  Thu Aug 29 21:37:02 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 29 Aug 2013 14:37:02 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CABdHhvEB=CwtDLYJZippO3Baf=yFK1UOdOGDvwDkBD76H6JFUA@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
	<CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
	<CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>
	<CABdHhvEB=CwtDLYJZippO3Baf=yFK1UOdOGDvwDkBD76H6JFUA@mail.gmail.com>
Message-ID: <CABG0rfso0hwq0RPccap=nORBY1nnP9S7yhpT_ygRJa+Ax9abhg@mail.gmail.com>

Ah, sorry -- I thought if I try to call a "hidden" function that has
not be exported (and, I thought, if it is exported, it needs to be
documented?), I have to call it via ::: ?

--j

On Thu, Aug 29, 2013 at 2:33 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> You only need ::: if you're calling it from another package (and see
> the lengthly recent discussion on that issue).  The key distinction is
> whether the function is exported or not: You must document any
> function that you export. You don't have to document any function you
> don't export.
>
> Hadley
>
> On Thu, Aug 29, 2013 at 2:15 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>> I had a similar question awhile ago.  Basically, my understanding is
>> if it is a function, it needs to be documented UNLESS you are calling
>> it via :::
>>
>> --j
>>
>> On Thu, Aug 29, 2013 at 1:11 PM, Sana Wajid <sat3lite at gmail.com> wrote:
>>> Thank you all, I appreciate your responses. Just a quick follow up
>>> question: couple of my functions are "background" or "behind the scenes"
>>> functions. Do these have to be documented in the manual as well?
>>>
>>>
>>> On Wed, Aug 28, 2013 at 5:19 PM, Geoff Jentry <geoffjentry at hexdump.org>wrote:
>>>
>>>> On Wed, 28 Aug 2013, Ben Bolker wrote:
>>>>
>>>>>  It may be suboptimal/there may be better ways, but what I would do in
>>>>> your situation would be to save the real twitteR results to a .Rdata file
>>>>> (e.g. put it in inst/vignetteData) and then 'fake' the twitter call: add a
>>>>> non-eval'd but echo'd chunk that appears to run the command, and an eval'd
>>>>> but non-echo'd chunk that loads the results of having run the command.
>>>>>
>>>>
>>>> Interesting, I'll look into doing that.
>>>>
>>>> Thanks
>>>> -J
>>>>
>>>>
>>>> ______________________________**________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 607 South Mathews Avenue, MC 150
>> Urbana, IL 61801
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Chief Scientist, RStudio
> http://had.co.nz/



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From h.wickham at gmail.com  Thu Aug 29 21:51:02 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Aug 2013 14:51:02 -0500
Subject: [Rd] Minimum requirements for package submission
In-Reply-To: <CABG0rfso0hwq0RPccap=nORBY1nnP9S7yhpT_ygRJa+Ax9abhg@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
	<CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
	<CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>
	<CABdHhvEB=CwtDLYJZippO3Baf=yFK1UOdOGDvwDkBD76H6JFUA@mail.gmail.com>
	<CABG0rfso0hwq0RPccap=nORBY1nnP9S7yhpT_ygRJa+Ax9abhg@mail.gmail.com>
Message-ID: <CABdHhvH8T5VZ2pU3p8+2Pq4Tv+jiw_bwF7v55=2mSEdX+PPvAg@mail.gmail.com>

You only need ::: from outside the package.
Hadley

On Thu, Aug 29, 2013 at 2:37 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Ah, sorry -- I thought if I try to call a "hidden" function that has
> not be exported (and, I thought, if it is exported, it needs to be
> documented?), I have to call it via ::: ?
>
> --j
>
> On Thu, Aug 29, 2013 at 2:33 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>> You only need ::: if you're calling it from another package (and see
>> the lengthly recent discussion on that issue).  The key distinction is
>> whether the function is exported or not: You must document any
>> function that you export. You don't have to document any function you
>> don't export.
>>
>> Hadley
>>
>> On Thu, Aug 29, 2013 at 2:15 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>>> I had a similar question awhile ago.  Basically, my understanding is
>>> if it is a function, it needs to be documented UNLESS you are calling
>>> it via :::
>>>
>>> --j
>>>
>>> On Thu, Aug 29, 2013 at 1:11 PM, Sana Wajid <sat3lite at gmail.com> wrote:
>>>> Thank you all, I appreciate your responses. Just a quick follow up
>>>> question: couple of my functions are "background" or "behind the scenes"
>>>> functions. Do these have to be documented in the manual as well?
>>>>
>>>>
>>>> On Wed, Aug 28, 2013 at 5:19 PM, Geoff Jentry <geoffjentry at hexdump.org>wrote:
>>>>
>>>>> On Wed, 28 Aug 2013, Ben Bolker wrote:
>>>>>
>>>>>>  It may be suboptimal/there may be better ways, but what I would do in
>>>>>> your situation would be to save the real twitteR results to a .Rdata file
>>>>>> (e.g. put it in inst/vignetteData) and then 'fake' the twitter call: add a
>>>>>> non-eval'd but echo'd chunk that appears to run the command, and an eval'd
>>>>>> but non-echo'd chunk that loads the results of having run the command.
>>>>>>
>>>>>
>>>>> Interesting, I'll look into doing that.
>>>>>
>>>>> Thanks
>>>>> -J
>>>>>
>>>>>
>>>>> ______________________________**________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>> --
>>> Jonathan A. Greenberg, PhD
>>> Assistant Professor
>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>> Department of Geography and Geographic Information Science
>>> University of Illinois at Urbana-Champaign
>>> 607 South Mathews Avenue, MC 150
>>> Urbana, IL 61801
>>> Phone: 217-300-1924
>>> http://www.geog.illinois.edu/~jgrn/
>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> Chief Scientist, RStudio
>> http://had.co.nz/
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007



-- 
Chief Scientist, RStudio
http://had.co.nz/


From ripley at stats.ox.ac.uk  Thu Aug 29 22:17:07 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Aug 2013 21:17:07 +0100
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <CABdHhvGoM-bHcH0Q-zcWGwRZsRQzb4gU3yNvL6kNb2PHdF2Z0w@mail.gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
	<B6D87831-7F8A-4474-B4A9-0021FC71B486@r-project.org>
	<CABdHhvGoM-bHcH0Q-zcWGwRZsRQzb4gU3yNvL6kNb2PHdF2Z0w@mail.gmail.com>
Message-ID: <521FAC43.8080209@stats.ox.ac.uk>

On 29/08/2013 20:26, Hadley Wickham wrote:
>>> Do pointers always have to be aligned?
>>
>> Depends on the architecture, e.g., Sparc doesn't allow non-aligned pointers at all (results in a segfault), SV x86_64 ABI specifies pointers to be aligned at 8 bytes, but the x86_64 CPUs will allow misaligned pointers with a performance penalty (the same was true for x86 - i.e. misaligned pointers are tolerated with a penalty).
>
> Ok, so you might not have to align pointers a particular architecture,
> but if you're writing code that you want to work across multiple
> architectures you must.

Yes, and note too that you may or may not need to align doubles, 
independently of pointers (and it may even be a compiler setting: it is 
on Solaris).

>
> Hadley
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cstrato at aon.at  Thu Aug 29 22:52:09 2013
From: cstrato at aon.at (cstrato)
Date: Thu, 29 Aug 2013 22:52:09 +0200
Subject: [Rd] Error when using buildVignettes()
In-Reply-To: <CAFDcVCQbhehTVOn0tvjokdkf2Q83DvLDBTnsRfdzdKYZ=1N+iw@mail.gmail.com>
References: <521E5076.9020106@aon.at>
	<CAFDcVCSGCkxqYMC9MJAyLY6ybby6qX3mg+P97dX1yKA4ap7qFg@mail.gmail.com>
	<521E753F.5030708@aon.at>
	<CAFDcVCQbhehTVOn0tvjokdkf2Q83DvLDBTnsRfdzdKYZ=1N+iw@mail.gmail.com>
Message-ID: <521FB479.4010908@aon.at>

Dear Henrik,

Thank you for your extensive reply, using:

Sweave("QAReport.Rnw")
tools::texi2pdf("QAReport.tex", clean = TRUE)

did solve my problem.

Nevertheless, I do not understand why function buildVignettes() was 
modified in a way that it can no longer be used to create vignettes for 
testing purposes w/o a DESCRIPTION file. This is also nowhere mentioned 
in the R News file. The only comment is: "If there is a field 
BuildVignettes in the package ?DESCRIPTION? file with a false value, 
re-building the vignettes is skipped." It would be easy to simply use 
true as default if there is no DESCRIPTION file is present.

Best regards,
Christian


On 8/29/13 12:58 AM, Henrik Bengtsson wrote:
> Ok.  ...I've now read your original thread more carefully, and I'd say
> that tools::buildVignettes() is intended for building vignettes within
> packages, not for compiling vignette files in general.  This is most
> likely why it complains - it simply looks for files that it expect to
> see in a package source tree.  FYI, lots of changes were made to these
> tools in R 3.0.0, which may explain why you didn't see them before
> (not saying it was correct usage before either).
>
> I'd say, use Sweave/Stangle "manually" and then pass it on to tools::texi2pdf().
>
> <sales pitch>
> 1. For *.Rnw -> *.tex -> *.pdf, you can use R.rsp::compileRnw() that
> does all this in one go with more sanity checks.
>
> 2. Instead of using all those sub("@TITLE@",  title, ...) coding to
> generate the report Rnw from a main Rnw template, add a layer of RSP
> markup and run it through the RSP compiler.  For instance, with a
> template.Rnw.rsp containing:
>
>   This is the quality assessment report for the dataset '<%=dataset%>'.
> The dataset consists of
>   <%=numtrees%> Affymetrix <%=chiptype%> arrays of type '<%=chipname%>'.
>
> you can compile it all in one go into a final PDF by pdf <-
> R.rsp::rfile("template.Rnw.rsp").  RSP supports <%@include
> file="..."%> statements and more if you wish to bring multiple Rnw
> templates into a final one.  See help("R.rsp") for vignettes etc.
> </sales pitch>
>
> On Wed, Aug 28, 2013 at 3:10 PM, cstrato <cstrato at aon.at> wrote:
>> Dear Henrik,
>>
>> Thank you for your suggestion, however the error was detected by a user who
>> is already using R 3.0.1, see:
>> https://www.stat.math.ethz.ch/pipermail/bioconductor/2013-August/054633.html
>>
>> Best regards,
>> Christian
>>
>>
>>
>> On 8/28/13 11:49 PM, Henrik Bengtsson wrote:
>>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.0.0 Patched (2013-04-11 r62551)
>>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>>
>>> I would check with R 3.0.1 patched and R devel before anything else,
>>> especially when troubleshooting vignette-related issues.
>>>
>>> /Henrik
>>>
>>>
>>> On Wed, Aug 28, 2013 at 12:33 PM, cstrato <cstrato at aon.at> wrote:
>>>>
>>>> Dear all,
>>>>
>>>> When running function 'testQAReport()', which uses function
>>>> 'buildVignettes()' to create a pdf-file I get the following error:
>>>>
>>>>> source("testQAReport.R")
>>>>> testQAReport()
>>>>
>>>> Error in .get_package_metadata(pkgdir) :
>>>>     Files 'DESCRIPTION' and 'DESCRIPTION.in' are missing.
>>>>
>>>> Since I did not get this error in earlier versions of R, could you please
>>>> tell me what may be the reason for this error?
>>>>
>>>>
>>>> Here is the code for "testQAReport.R":
>>>>
>>>>
>>>> #------------------------------------------------------------------------------#
>>>> # testQAReport.R: test quality control report
>>>> # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
>>>> -
>>>> - -
>>>> testQAReport <-
>>>> function(dataset     = "My Dataset",
>>>>            title       = "Quality Report",
>>>>            date        = "October, 2011",
>>>>            author      = "Christian Stratowa",
>>>>            outdir      = file.path(getwd(), "TestQA"),
>>>>            ...)
>>>> {
>>>>      ## directory containing parts of QAReport.Rnw
>>>>      indir <- file.path(path.package("xps"), "QC");
>>>>
>>>>      ## create directory containing final QAReport.Rnw
>>>>      if (!dir.create(outdir))
>>>>         stop("could not create report directory");
>>>>      if (!dir.create(file.path(outdir, "inst")))
>>>>         stop("could not create report subdirectory 'inst'");
>>>>      if (!dir.create(file.path(outdir, "inst", "doc")))
>>>>         stop("could not create report subdirectory 'doc'");
>>>>      docdir <- file.path(outdir, "inst", "doc");
>>>>
>>>>      QCb <- readLines(file.path(indir, "QC.begin.Rnw"));
>>>>
>>>>      ## replace title, date, author
>>>>      QCb <- sub("@TITLE@",  title,  QCb);
>>>>      QCb <- sub("@DATE@",   date,   QCb);
>>>>      QCb <- sub("@AUTHOR@", author, QCb);
>>>>
>>>>      ## dataset info
>>>>      numtrees <- 6; chipname <- "Test3"; chiptype <- "GeneChip";
>>>>      QCb <- sub("@DATASET@",  dataset,  QCb);
>>>>      QCb <- sub("@NUMTREES@", numtrees, QCb);
>>>>      QCb <- sub("@CHIPNAME@", chipname, QCb);
>>>>      QCb <- sub("@CHIPTYPE@", chiptype, QCb);
>>>>
>>>>      write(QCb, file.path(docdir, "QAReport.Rnw"));
>>>>
>>>>      QCe <- readLines(file.path(indir, "QC.end.Rnw"));
>>>>      QCe <- sub("@DATASET@",  dataset,  QCe);
>>>>      QCe <- gsub("_","\\\\_", QCe);
>>>>
>>>>      write(QCe, file.path(docdir, "QAReport.Rnw"), append=TRUE);
>>>>
>>>>      ## build vignette QC.pdf
>>>>      if (require(tools)) {
>>>>         buildVignettes(dir=outdir, lib.loc=NULL, quiet=FALSE,
>>>> clean=FALSE);
>>>>      }#if
>>>> }#xpsQAReport
>>>>
>>>>
>>>> #------------------------------------------------------------------------------#
>>>>
>>>> The file "QC.begin.Rnw" is as follows:
>>>>
>>>> \documentclass{article}
>>>>
>>>>
>>>> \textwidth=6.2in
>>>> \textheight=8.5in
>>>> %\parskip=.3cm
>>>> \oddsidemargin=.1in
>>>> \evensidemargin=.1in
>>>> \headheight=-.3in
>>>>
>>>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>>>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>>>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>>>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>>>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>>>> \newcommand{\xps}{\Rpackage{xps}}
>>>> \newcommand{\ROOT}{\Robject{ROOT}}
>>>>
>>>> \begin{document}
>>>>
>>>> \title{@TITLE@}
>>>> \date{@DATE@}
>>>> \author{@AUTHOR@}
>>>> \maketitle
>>>>
>>>> \tableofcontents
>>>>
>>>>
>>>> \section{Introduction}
>>>>
>>>>    This is the quality assessment report for the dataset '@DATASET@'. The
>>>> dataset consists of
>>>>    @NUMTREES@ Affymetrix @CHIPTYPE@ arrays of type '@CHIPNAME@'. \\
>>>>
>>>>    This report was generated using function \Rfunction{xpsQAReport} of
>>>> package
>>>> \xps. \\
>>>>
>>>>
>>>> The file "QC.end.Rnw" is as follows:
>>>>
>>>> \section{Summary}
>>>>
>>>>    The current quality report for dataset '@DATASET@' displays the most
>>>> important quality plots, using the
>>>>    default settings for most plots. Package \xps\ contains additional
>>>> plots
>>>> which can be used for further
>>>>    quality assessments. \\
>>>>
>>>>
>>>> \section*{Session Information:}
>>>>
>>>> <<echo=FALSE>>=
>>>> sessionInfo()
>>>> @
>>>>
>>>> \end{document}
>>>>
>>>>
>>>> Finally, the output which is located in TestQA/inst/doc/QAReport.Rnw is
>>>> as
>>>> follows:
>>>>
>>>> \documentclass{article}
>>>>
>>>>
>>>> \textwidth=6.2in
>>>> \textheight=8.5in
>>>> %\parskip=.3cm
>>>> \oddsidemargin=.1in
>>>> \evensidemargin=.1in
>>>> \headheight=-.3in
>>>>
>>>> \newcommand{\Rfunction}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rmethod}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rcode}[1]{{\texttt{#1}}}
>>>> \newcommand{\Robject}[1]{{\texttt{#1}}}
>>>> \newcommand{\Rpackage}[1]{{\textsf{#1}}}
>>>> \newcommand{\Rclass}[1]{{\textit{#1}}}
>>>> \newcommand{\Cclass}[1]{{\textit{#1}}}
>>>> \newcommand{\Rexten}[1]{{\textit{#1}}}
>>>> \newcommand{\xps}{\Rpackage{xps}}
>>>> \newcommand{\ROOT}{\Robject{ROOT}}
>>>>
>>>> \begin{document}
>>>>
>>>> \title{Quality Report}
>>>> \date{October, 2011}
>>>> \author{Christian Stratowa}
>>>> \maketitle
>>>>
>>>> \tableofcontents
>>>>
>>>>
>>>> \section{Introduction}
>>>>
>>>>    This is the quality assessment report for the dataset 'My Dataset'. The
>>>> dataset consists of
>>>>    6 Affymetrix GeneChip arrays of type 'Test3'. \\
>>>>
>>>>    This report was generated using function \Rfunction{xpsQAReport} of
>>>> package
>>>> \xps. \\
>>>>
>>>> \section{Summary}
>>>>
>>>>    The current quality report for dataset 'My Dataset' displays the most
>>>> important quality plots, using the
>>>>    default settings for most plots. Package \xps\ contains additional
>>>> plots
>>>> which can be used for further
>>>>    quality assessments. \\
>>>>
>>>>
>>>> \section*{Session Information:}
>>>>
>>>> <<echo=FALSE>>=
>>>> sessionInfo()
>>>> @
>>>>
>>>> \end{document}
>>>>
>>>>
>>>> Can you please tell me why function buildVignettes() of the tools package
>>>> is
>>>> no longer able to convert this file into a pdf-file?
>>>> Thank you in advance.
>>>>
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.0.0 Patched (2013-04-11 r62551)
>>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>>
>>>> locale:
>>>> [1] C
>>>>
>>>> attached base packages:
>>>> [1] tools     stats     graphics  grDevices utils     datasets  methods
>>>> [8] base
>>>>
>>>> other attached packages:
>>>> [1] xps_1.21.4
>>>>
>>>> Best regards
>>>> Christian
>>>> _._._._._._._._._._._._._._._._._._
>>>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>>>> V.i.e.n.n.a           A.u.s.t.r.i.a
>>>> e.m.a.i.l:        cstrato at aon.at
>>>> _._._._._._._._._._._._._._._._._._
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>


From pdalgd at gmail.com  Thu Aug 29 23:23:39 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 29 Aug 2013 23:23:39 +0200
Subject: [Rd] Why does an empty vector occupy 40 bytes?
In-Reply-To: <309C5D98-6D0E-4A34-B399-6623960F1A2F@gmail.com>
References: <CABdHhvFchkfQagqO1xJbEn9MbePFLO6VR4kaNhUYgzyB6Jp8tg@mail.gmail.com>
	<521F6474.40307@stats.ox.ac.uk>
	<CABdHhvHZ2RYd_TGrehUSUt5xw6y-pgNbxQ8Tpu0jiAj145Z5KQ@mail.gmail.com>
	<7447F5AA-A29E-412B-8DEF-25D6F796FF16@r-project.org>
	<CABdHhvGayo-GatxtrMW6oCR9a3fBbw_1gJ2Y0hvv63QMT7dDFQ@mail.gmail.com>
	<309C5D98-6D0E-4A34-B399-6623960F1A2F@gmail.com>
Message-ID: <958C7E21-C4EC-4C2F-BB43-1AE9BF3692AF@gmail.com>

Whoops, yes. As Brian reminded me, it was probably double alignment, not pointers, that was the issue on the old Suns.

-pd

On Aug 29, 2013, at 21:11 , peter dalgaard wrote:

> 
> On Aug 29, 2013, at 20:37 , Hadley Wickham wrote:
> 
>>> Not to be picky, but that is not the point. The alignment is due to the attrib pointer which is at offset 8 despite the fact that there is only a 4-byte element in front of it. Maybe for better illustration, this is the layout on 64-bit machines:
>> 
>> Ok, thanks for the clarification.
>> 
>>> 
>>> * 4 bytes: sxpinfo header (= 32 bits)
>>> * 4 bytes: --- padding so next ptr is aligned ---
>>> * 8 bytes: pointer to attributes
>>> * 8 bytes: pointer to next node
>>> * 8 bytes: pointer to previous node
>>> * 4 bytes: length
>>> * 4 bytes: true length
>>> 
>>> = 40 bytes
>>> 
>>> This is already aligned so the payload alignment doesn't any extra padding so that has no effect at all.
>> 
>> Do pointers always have to be aligned?
> 
> I think that is architecture/compiler specific, but usually aligned pointers are loaded into memory in one clock cycle whereas unaligned ones take two, insofar as the architecture allows it at all. 
> 
> Back in the days when Sun machines went 64 bit (1993 or so?), there was an issue with dyn.loading into Splus, where it was passing unaligned pointers and gcc was expecting them to be aligned. Basically, it became a toss-up whether dyn.load calls would work or not... 
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gmbecker at ucdavis.edu  Thu Aug 29 23:51:54 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 29 Aug 2013 14:51:54 -0700
Subject: [Rd] model.frame(), model.matrix(),
	and derived predictor variables
In-Reply-To: <521F4AF0.9060908@gmail.com>
References: <520FA2AE.7030109@gmail.com> <52196EA9.3070302@gmail.com>
	<CADwqtCNvOOna0th5wDch133Q_3WGWYGKxSnnj_J8S5HXO6EqSw@mail.gmail.com>
	<521F4AF0.9060908@gmail.com>
Message-ID: <CADwqtCML-rzoRyP=V3OXqeWz2zWz061MUF5pH8wp0JiWUNdw+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130829/dbb01303/attachment.pl>

From hb at biostat.ucsf.edu  Fri Aug 30 05:38:24 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 29 Aug 2013 20:38:24 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
Message-ID: <CAFDcVCQVWKxBr_07rZWqz=x8E296b6DNzNm4x8dVT4LQd3RDOg@mail.gmail.com>

Hi,

SETUP:
Consider three packages PkgA, PkgB and PkgC.

PkgA defines a generic function foo() and exports it;

export(foo)

PkgB imports PkgA::foo() and re-exports it;

importFrom(PkgA, foo)
export(foo)

PkgC imports everything from PkgA and PkgB:

imports(PkgA, PkgB)


PROBLEM:
Loading or attaching the namespace of PkgC will generate a warning:

  replacing previous import by 'PkgA::foo' when loading 'PkgC'

This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):

* checking whether package 'PkgC' can be installed ... WARNING
Found the following significant warnings:
  Warning: replacing previous import by 'PkgA::foo' when loading
'CellularAutomaton'


FALSE?
Isn't it valid to argue that this is a "false" warning, because
identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?


/Henrik

PS. The above can be avoided by using explicit importFrom() on PkgA
and PkgB, but that's really tedious.  In my case this is out of my
reach, because I'm the author of PkgA and PkgB but not many of the
PkgC packages.


From rpruim at calvin.edu  Thu Aug 29 16:10:53 2013
From: rpruim at calvin.edu (rpruim)
Date: Thu, 29 Aug 2013 07:10:53 -0700 (PDT)
Subject: [Rd] Packages not found
In-Reply-To: <521F39B3.9090204@aon.at>
References: <521F39B3.9090204@aon.at>
Message-ID: <1377785453351-4674884.post@n4.nabble.com>

> On the CRAN website http://cran.r-project.org/ it is currently not 
> possible to get to the packages. Clicking on "Packages" or on 
> "Contributed extension packages" results in Error 404: Object not 
> found!, see: http://cran.r-project.org/web/packages/

This is also blocking R CMD check --as-cran

$ R CMD check --as-cran fastR_0.7-1.tar.gz 
* using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
* using R Under development (unstable) (2013-08-19 r63623)
* using platform: x86_64-apple-darwin11.4.2 (64-bit)
* using session charset: UTF-8
* checking for file ?fastR/DESCRIPTION? ... OK
* checking extension type ... Package
* this is package ?fastR? version ?0.7-1?
* checking CRAN incoming feasibility ...Warning in
url(sprintf("%s/web/packages/packages.rds", CRAN), "rb") :
  cannot open: HTTP status was '404 Not Found'
Error in url(sprintf("%s/web/packages/packages.rds", CRAN), "rb") : 
  cannot open the connection
Execution halted




--
View this message in context: http://r.789695.n4.nabble.com/Packages-not-found-tp4674862p4674884.html
Sent from the R devel mailing list archive at Nabble.com.


From rpruim at calvin.edu  Thu Aug 29 16:32:42 2013
From: rpruim at calvin.edu (rpruim)
Date: Thu, 29 Aug 2013 07:32:42 -0700 (PDT)
Subject: [Rd] Packages not found
In-Reply-To: <21023.17685.765190.525989@stat.math.ethz.ch>
References: <521F39B3.9090204@aon.at>
	<521F42D9.7010606@statistik.tu-dortmund.de>
	<21023.17685.765190.525989@stat.math.ethz.ch>
Message-ID: <1377786762659-4674888.post@n4.nabble.com>

Is it possible to set the CRAN mirror at the command line when doing R CMD
check --as-cran (which also breaks currently)?

$ R CMD check --as-cran fastR_0.7-1.tar.gz 
* using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
* using R Under development (unstable) (2013-08-19 r63623)
* using platform: x86_64-apple-darwin11.4.2 (64-bit)
* using session charset: UTF-8
* checking for file ?fastR/DESCRIPTION? ... OK
* checking extension type ... Package
* this is package ?fastR? version ?0.7-1?
* checking CRAN incoming feasibility ...Warning in
url(sprintf("%s/web/packages/packages.rds", CRAN), "rb") :
  cannot open: HTTP status was '404 Not Found'
Error in url(sprintf("%s/web/packages/packages.rds", CRAN), "rb") : 
  cannot open the connection
Execution halted



--
View this message in context: http://r.789695.n4.nabble.com/Packages-not-found-tp4674862p4674888.html
Sent from the R devel mailing list archive at Nabble.com.


From trannon.mosher at clearcapital.com  Thu Aug 29 22:01:43 2013
From: trannon.mosher at clearcapital.com (Trannon Mosher)
Date: Thu, 29 Aug 2013 13:01:43 -0700
Subject: [Rd] Big Integer Support in JSON-to-R Conversion
Message-ID: <CAH+WQuA9BMc+BMvdg4CqRGYX6e54msGyQG4EcL-O67dBijT6uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130829/52e27841/attachment.pl>

From reijo.sund at helsinki.fi  Fri Aug 30 00:33:30 2013
From: reijo.sund at helsinki.fi (Reijo Sund)
Date: Thu, 29 Aug 2013 18:33:30 -0400
Subject: [Rd]  ::: inside the package
In-Reply-To: <CABdHhvH8T5VZ2pU3p8+2Pq4Tv+jiw_bwF7v55=2mSEdX+PPvAg@mail.gmail.com>
References: <CAPrRzuyMDh64qTw=DSEAunVfjG5AFY=aMHr5NrE9L+f5RmZNkw@mail.gmail.com>
	<CABdHhvGt184JfHZAw1k_GpGmiGgaK-XnCLqRofOvU9=WUgUuGw@mail.gmail.com>
	<CAKFxdiRjTE6avW9An2_X6HDV63f+Sv8LsO6FESrY0MzGKdHOLg@mail.gmail.com>
	<21022.2225.867873.997588@max.nulle.part>
	<alpine.DEB.2.00.1308281115520.22063@cardinals.dreamhost.com>
	<loom.20130828T225613-593@post.gmane.org>
	<alpine.DEB.2.00.1308281418290.8964@cardinals.dreamhost.com>
	<CAPrRzuzLJ5hWvfUquJeQ_iw8R+WAHvzZ1nGeiZHauyLf_3yrXg@mail.gmail.com>
	<CABG0rfuzXOfws6-yJxEQr=m8qLUrduY=MKo47Np8ZM=c2wwSgg@mail.gmail.com>
	<CABdHhvEB=CwtDLYJZippO3Baf=yFK1UOdOGDvwDkBD76H6JFUA@mail.gmail.com>
	<CABG0rfso0hwq0RPccap=nORBY1nnP9S7yhpT_ygRJa+Ax9abhg@mail.gmail.com>
	<CABdHhvH8T5VZ2pU3p8+2Pq4Tv+jiw_bwF7v55=2mSEdX+PPvAg@mail.gmail.com>
Message-ID: <9855BE02-6A2F-4748-844C-C631E6FC8E9A@helsinki.fi>

> You only need ::: from outside the package.

In some cases I have had difficulties to evaluate non-exported/hidden R functions from C code without ::: (inside the package). But that's a different story and not any serious problem at all. Probably there is also some easy workaround, but I haven't even tried to search for any other solutions as ::: works fine.

From oboturov at gmail.com  Fri Aug 30 11:19:53 2013
From: oboturov at gmail.com (=?UTF-8?B?0J7QsdC+0YLRg9GA0L7QsiDQkNGA0YLQtdC8?=)
Date: Fri, 30 Aug 2013 11:19:53 +0200
Subject: [Rd] Type annotations for R function parameters.
Message-ID: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130830/e461b502/attachment.pl>

From murdoch.duncan at gmail.com  Fri Aug 30 12:54:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 30 Aug 2013 06:54:33 -0400
Subject: [Rd] Type annotations for R function parameters.
In-Reply-To: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
References: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
Message-ID: <522079E9.8080702@gmail.com>

On 13-08-30 5:19 AM, ???????? ????? wrote:
> Hello.
>
> One of my clients asked if it would be possible to have an IDE which could
> use type discovery for R functions to make flow-like construction of an R
> program. Something like a LabView graphical composition of processing
> elements.
>
> They called this type of program composition a "workflow".
>
> I looked at some of this programs, like:
> * Orange http://orange.biolab.si/
> * RedR http://www.red-r.org/
> * Rattle http://rattle.togaware.com/
> * Rpad https://code.google.com/p/rpad/
>
> and all of them did type introspection (they made mapping between R
> functions and their IDE's visual framework) by hand for each function of
> supported packages which is time and resource consuming.
>
> So, to reduce an amount of code to be written for adapters between R and
> IDE some kind of annotations could be introduced over parameters and return
> values. Those could be optional and will help to discover type information
> for support of dynamic composition of programs.
>
> Do you have any suggestions on the topic?

It's very common for R functions to accept many different types for the 
same argument on input, and somewhat common for the type of output to 
depend on the inputs, so this looks hard:  that's why those front ends 
need work by hand.

Duncan Murdoch


From deepayan.sarkar at gmail.com  Fri Aug 30 13:15:46 2013
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 30 Aug 2013 16:45:46 +0530
Subject: [Rd] Type annotations for R function parameters.
In-Reply-To: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
References: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
Message-ID: <CADfFDC5YNaJF-N1zfXOYCpYvWFg4_y=AqBG1TVO9ThtOZi7naA@mail.gmail.com>

On Fri, Aug 30, 2013 at 2:49 PM, ???????? ????? <oboturov at gmail.com> wrote:
> Hello.
>
> One of my clients asked if it would be possible to have an IDE which could
> use type discovery for R functions to make flow-like construction of an R
> program. Something like a LabView graphical composition of processing
> elements.
>
> They called this type of program composition a "workflow".
>
> I looked at some of this programs, like:
> * Orange http://orange.biolab.si/
> * RedR http://www.red-r.org/
> * Rattle http://rattle.togaware.com/
> * Rpad https://code.google.com/p/rpad/
>
> and all of them did type introspection (they made mapping between R
> functions and their IDE's visual framework) by hand for each function of
> supported packages which is time and resource consuming.
>
> So, to reduce an amount of code to be written for adapters between R and
> IDE some kind of annotations could be introduced over parameters and return
> values. Those could be optional and will help to discover type information
> for support of dynamic composition of programs.
>
> Do you have any suggestions on the topic?

See

http://bioconductor.org/packages/2.12/bioc/html/TypeInfo.html

-Deepayan


From murdoch.duncan at gmail.com  Fri Aug 30 14:08:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 30 Aug 2013 08:08:11 -0400
Subject: [Rd] Type annotations for R function parameters.
In-Reply-To: <CAKFcK8iua93o+ve7=GyGwLzx6NUBrPgf2UGx8jNFSTi9MkxhQg@mail.gmail.com>
References: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
	<522079E9.8080702@gmail.com>
	<CAKFcK8iua93o+ve7=GyGwLzx6NUBrPgf2UGx8jNFSTi9MkxhQg@mail.gmail.com>
Message-ID: <52208B2B.5040803@gmail.com>

On 13-08-30 7:22 AM, ???????? ????? wrote:
> This essentially locks up the version of each package at the time of
> writing an adapter. This makes you to make review of changes before
> introducing an updated version of those packages into the system.

Yes, that's why I said this is hard.
>
> Also there could a register of converters written by package developers
> to cope with diversity of types.

Converters aren't sufficient.  For example, many functions that take 
input from files accept a filename as a character string or a connection 
object for the input parameter.  The character string is converted to a 
connection using file() (sometimes "" is converted to stdin() or 
stdout()), but often other things are done as well, e.g. code to close 
the connection at the end of the function call.

For example, here is the code that examines the "con" argument to the 
readLines() function:

     if (is.character(con)) {
         con <- file(con, "r")
         on.exit(close(con))
     }

The cat() function is a little more complicated, and the parse() 
function has much more extensive calculations involving its "file" 
argument, because it needs to set debugging information and produce 
diagnostic messages.

Duncan Murdoch


>
> On Friday, August 30, 2013, Duncan Murdoch wrote:
>
>     On 13-08-30 5:19 AM, ???????? ????? wrote:
>
>         Hello.
>
>         One of my clients asked if it would be possible to have an IDE
>         which could
>         use type discovery for R functions to make flow-like
>         construction of an R
>         program. Something like a LabView graphical composition of
>         processing
>         elements.
>
>         They called this type of program composition a "workflow".
>
>         I looked at some of this programs, like:
>         * Orange http://orange.biolab.si/
>         * RedR http://www.red-r.org/
>         * Rattle http://rattle.togaware.com/
>         * Rpad https://code.google.com/p/__rpad/
>         <https://code.google.com/p/rpad/>
>
>         and all of them did type introspection (they made mapping between R
>         functions and their IDE's visual framework) by hand for each
>         function of
>         supported packages which is time and resource consuming.
>
>         So, to reduce an amount of code to be written for adapters
>         between R and
>         IDE some kind of annotations could be introduced over parameters
>         and return
>         values. Those could be optional and will help to discover type
>         information
>         for support of dynamic composition of programs.
>
>         Do you have any suggestions on the topic?
>
>
>     It's very common for R functions to accept many different types for
>     the same argument on input, and somewhat common for the type of
>     output to depend on the inputs, so this looks hard:  that's why
>     those front ends need work by hand.
>
>     Duncan Murdoch
>


From pgilbert902 at gmail.com  Fri Aug 30 15:58:24 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 30 Aug 2013 09:58:24 -0400
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
Message-ID: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>

This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)
Paul

Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

>Hi,
>
>SETUP:
>Consider three packages PkgA, PkgB and PkgC.
>
>PkgA defines a generic function foo() and exports it;
>
>export(foo)
>
>PkgB imports PkgA::foo() and re-exports it;
>
>importFrom(PkgA, foo)
>export(foo)
>
>PkgC imports everything from PkgA and PkgB:
>
>imports(PkgA, PkgB)
>
>
>PROBLEM:
>Loading or attaching the namespace of PkgC will generate a warning:
>
>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>
>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>
>* checking whether package 'PkgC' can be installed ... WARNING
>Found the following significant warnings:
>  Warning: replacing previous import by 'PkgA::foo' when loading
>'CellularAutomaton'
>
>
>FALSE?
>Isn't it valid to argue that this is a "false" warning, because
>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>
>
>/Henrik
>
>PS. The above can be avoided by using explicit importFrom() on PkgA
>and PkgB, but that's really tedious.  In my case this is out of my
>reach, because I'm the author of PkgA and PkgB but not many of the
>PkgC packages.
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

From rowe at muxspace.com  Fri Aug 30 17:39:26 2013
From: rowe at muxspace.com (Brian Rowe)
Date: Fri, 30 Aug 2013 11:39:26 -0400
Subject: [Rd] Type annotations for R function parameters.
In-Reply-To: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
References: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
Message-ID: <6AC4EC88-4EF5-46EE-9501-6A73EF6D2302@muxspace.com>

The type constraints in lambda.r make this relatively easy. The idea is to add a declaration before a function that provides static typing on the function arguments. The type constraint also specifies the return type, so it would be straightforward to construct a graph. Where a type variable is used, then there would need to be a run-time determination for the actual types as happens in Haskell. Obviously to have a complete graph of a program would require the whole program to be written using lambda.r.

For example you can decorate two separate function clauses each with their own type constraint.

slice(x, pivot, inclusive) %::% a : numeric : logical : list
slice(x, pivot, inclusive=FALSE) %as% {
  left <- x[1:pivot]
  right <- x[(pivot+as.numeric(!inclusive)):length(x)]
  list(left, right)
}

slice(x, expression) %::% a : logical : list
slice(x, expression) %as% {
  left <- x[expression]
  right <- x[!expression]
  list(left, right)
}

This calls the first clause since the second argument is numeric.
> x <- rnorm(10)
> slice(x, 4)
[[1]]
[1]  1.2468112 -0.2795106  0.5775026  1.0521653

[[2]]
[1] -1.0493246 -2.0634126  0.0368455 -1.8431248 -0.3630197  0.1015901


This calls the second clause since x < 0 is logical.
> slice(x, x < 0)
[[1]]
[1] -0.2795106 -1.0493246 -2.0634126 -1.8431248 -0.3630197

[[2]]
[1] 1.2468112 0.5775026 1.0521653 0.0368455 0.1015901


This fails since no clause of the function accepts a character as the second argument.
> slice(x, 'a')
Error in UseFunction(slice, "slice", ...) :
  No valid function for 'slice(c(1.24681120969809,-0.279510617209735,0.577502630574721,1.05216534148533, ...),a)'


Warm Regards,
Brian



On Aug 30, 2013, at 5:19 AM, ???????? ????? <oboturov at gmail.com> wrote:

> Hello.
> 
> One of my clients asked if it would be possible to have an IDE which could
> use type discovery for R functions to make flow-like construction of an R
> program. Something like a LabView graphical composition of processing
> elements.
> 
> They called this type of program composition a "workflow".
> 
> I looked at some of this programs, like:
> * Orange http://orange.biolab.si/
> * RedR http://www.red-r.org/
> * Rattle http://rattle.togaware.com/
> * Rpad https://code.google.com/p/rpad/
> 
> and all of them did type introspection (they made mapping between R
> functions and their IDE's visual framework) by hand for each function of
> supported packages which is time and resource consuming.
> 
> So, to reduce an amount of code to be written for adapters between R and
> IDE some kind of annotations could be introduced over parameters and return
> values. Those could be optional and will help to discover type information
> for support of dynamic composition of programs.
> 
> Do you have any suggestions on the topic?
> 
> Best regards,
> 
> Artem Oboturov
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Aug 30 20:51:29 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 11:51:29 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
In-Reply-To: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
Message-ID: <CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>

Hi.

On Fri, Aug 30, 2013 at 6:58 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)

For the record, you're referring to R-devel thread 'Correct NAMESPACE
approach when writing an S3 method for a generic in another package'
started on Aug 24, 2013
[https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
Yes, it's closely related or possibly the same issue.  However, I do
not find it odd that the S3 generic function needs to be exported
from/available via the namespace.  Hence it needs to be export():ed by
at least one package/namespace.

The real issue is when two package needs to export a generic function
with the same name, e.g. foo().   If the two generic functions are
defined differently (e.g. different arguments/signatures), they will
be in conflict with each other.  If they are identical, this should
not be a problem, but here I might be wrong.  However, there is also
the special case where one package reexports the generic function from
another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
the object 'foo' does actually not existing in the name space of
package PkgB - instead it provides a "redirect" to it, e.g.

> PkgA::foo
function (...)
UseMethod("foo")
<environment: namespace:PkgA>

> PkgB::foo
function (...)
UseMethod("foo")
<environment: namespace:PkgA>

> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
[1] FALSE

> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
[1] TRUE

> identical(PkgB::foo, PkgA::foo)
[1] TRUE


The warning on "replacing previous import by 'PkgA::foo' when loading
'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
base::namespaceImportFrom()
[http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R],
simply because it detects that "foo" (=n) has already been imported to
PkgC' namespace (=impenv):

if (exists(n, envir = impenv, inherits = FALSE)) {
    if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
        ## warn only if generic overwrites a function which
        ## it was not derived from
        ...
    }
    warning(sprintf(msg, sQuote(paste(nsname, n, sep = "::")),
sQuote(from)), call. = FALSE, domain = NA)
}

Note how there is already code for avoiding "false" warnings on S4
generic function.  This is what we'd like to have also for S3 generic
functions, but it's much harder to test for such since they're not
formally defined.  However, I'd argue that it is safe to skip the
warning *when the variable to be imported does not actually exist in
the package being imported* (e.g. when just rexported), i.e.

>svn diff namespace.R
Index: namespace.R
===================================================================
--- namespace.R (revision 63776)
+++ namespace.R (working copy)
@@ -871,6 +871,10 @@
     }
     for (n in impnames)
        if (exists(n, envir = impenv, inherits = FALSE)) {
+            ## warn only if imported variable actually exists in the
+            ## namespace imported from, which is not the case if
+            ## the variable is rexported from another namespace
+            if (!exists(n, envir = ns, inherits = FALSE)) next
            if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
                ## warn only if generic overwrites a function which
                ## it was not derived from

I'm planning to propose ("wishlist / enhancement"; it may even be a
bug) this over at https://bugs.r-project.org/.

Comments, anyone?

/Henrik


> Paul
>
> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>
>>Hi,
>>
>>SETUP:
>>Consider three packages PkgA, PkgB and PkgC.
>>
>>PkgA defines a generic function foo() and exports it;
>>
>>export(foo)
>>
>>PkgB imports PkgA::foo() and re-exports it;
>>
>>importFrom(PkgA, foo)
>>export(foo)
>>
>>PkgC imports everything from PkgA and PkgB:
>>
>>imports(PkgA, PkgB)
>>
>>
>>PROBLEM:
>>Loading or attaching the namespace of PkgC will generate a warning:
>>
>>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>>
>>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>>
>>* checking whether package 'PkgC' can be installed ... WARNING
>>Found the following significant warnings:
>>  Warning: replacing previous import by 'PkgA::foo' when loading
>>'CellularAutomaton'
>>
>>
>>FALSE?
>>Isn't it valid to argue that this is a "false" warning, because
>>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>>
>>
>>/Henrik
>>
>>PS. The above can be avoided by using explicit importFrom() on PkgA
>>and PkgB, but that's really tedious.  In my case this is out of my
>>reach, because I'm the author of PkgA and PkgB but not many of the
>>PkgC packages.
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Fri Aug 30 21:00:14 2013
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Aug 2013 21:00:14 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
Message-ID: <5220EBBE.8080504@aon.at>

Dear all,

To create a *.pdf file from a *.Rnw file I do:

       olddir <- getwd();
       setwd(outdir);

       tryCatch({Sweave("QAReport.Rnw");
                 tools::texi2pdf("QAReport.tex", clean=TRUE)
                },
                finally = setwd(olddir)
               );

This works fine, however 'clean=TRUE' does only work when:
      outdir <- "Test/inst/doc/"
but does not remove the files *.aux, *.log, *.toc when:
      outdir <- "Test/"

Why does function texi2pdf() require the directory structure for 
vignettes for the deletion of interim files?

(The help file?texi2pdf does not mention that this structure is necessary.)

Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From marc_schwartz at me.com  Fri Aug 30 21:09:40 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 30 Aug 2013 14:09:40 -0500
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220EBBE.8080504@aon.at>
References: <5220EBBE.8080504@aon.at>
Message-ID: <D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>


On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:

> Dear all,
> 
> To create a *.pdf file from a *.Rnw file I do:
> 
>      olddir <- getwd();
>      setwd(outdir);
> 
>      tryCatch({Sweave("QAReport.Rnw");
>                tools::texi2pdf("QAReport.tex", clean=TRUE)
>               },
>               finally = setwd(olddir)
>              );
> 
> This works fine, however 'clean=TRUE' does only work when:
>     outdir <- "Test/inst/doc/"
> but does not remove the files *.aux, *.log, *.toc when:
>     outdir <- "Test/"
> 
> Why does function texi2pdf() require the directory structure for vignettes for the deletion of interim files?
> 
> (The help file?texi2pdf does not mention that this structure is necessary.)
> 
> Best regards
> Christian


In the Details section of ?texi2pdf, there is:

"Despite the name, this is used in R to compile LaTeX files, specifically those generated from vignettes."


Since it is intended specifically for package vignettes, the path requirement should not be a surprise. :-)

Regards,

Marc Schwartz


From murdoch.duncan at gmail.com  Fri Aug 30 21:14:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 30 Aug 2013 15:14:43 -0400
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
Message-ID: <5220EF23.5040400@gmail.com>

On 30/08/2013 3:09 PM, Marc Schwartz wrote:
> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>
> > Dear all,
> >
> > To create a *.pdf file from a *.Rnw file I do:
> >
> >      olddir <- getwd();
> >      setwd(outdir);
> >
> >      tryCatch({Sweave("QAReport.Rnw");
> >                tools::texi2pdf("QAReport.tex", clean=TRUE)
> >               },
> >               finally = setwd(olddir)
> >              );
> >
> > This works fine, however 'clean=TRUE' does only work when:
> >     outdir <- "Test/inst/doc/"
> > but does not remove the files *.aux, *.log, *.toc when:
> >     outdir <- "Test/"
> >
> > Why does function texi2pdf() require the directory structure for vignettes for the deletion of interim files?
> >
> > (The help file?texi2pdf does not mention that this structure is necessary.)
> >
> > Best regards
> > Christian
>
>
> In the Details section of ?texi2pdf, there is:
>
> "Despite the name, this is used in R to compile LaTeX files, specifically those generated from vignettes."
>
>
> Since it is intended specifically for package vignettes, the path requirement should not be a surprise. :-)
>

There is no path requirement.  Christian was incorrect in his diagnosis.

texi2pdf won't delete files that existed before it was run, whether or 
not they were changed during the run.  That's likely what Christian was 
seeing.

Duncan Murdoch


From hb at biostat.ucsf.edu  Fri Aug 30 21:20:27 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 12:20:27 -0700
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220EF23.5040400@gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com>
Message-ID: <CAFDcVCQhjXKMd4q+eYYY0OFiPDz56L1fya6ND1iSttUxp3rNdw@mail.gmail.com>

On Fri, Aug 30, 2013 at 12:14 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>
>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>
>> > Dear all,
>> >
>> > To create a *.pdf file from a *.Rnw file I do:
>> >
>> >      olddir <- getwd();
>> >      setwd(outdir);
>> >
>> >      tryCatch({Sweave("QAReport.Rnw");
>> >                tools::texi2pdf("QAReport.tex", clean=TRUE)
>> >               },
>> >               finally = setwd(olddir)
>> >              );
>> >
>> > This works fine, however 'clean=TRUE' does only work when:
>> >     outdir <- "Test/inst/doc/"
>> > but does not remove the files *.aux, *.log, *.toc when:
>> >     outdir <- "Test/"
>> >
>> > Why does function texi2pdf() require the directory structure for
>> > vignettes for the deletion of interim files?
>> >
>> > (The help file?texi2pdf does not mention that this structure is
>> > necessary.)
>> >
>> > Best regards
>> > Christian
>>
>>
>> In the Details section of ?texi2pdf, there is:
>>
>> "Despite the name, this is used in R to compile LaTeX files, specifically
>> those generated from vignettes."
>>
>>
>> Since it is intended specifically for package vignettes, the path
>> requirement should not be a surprise. :-)
>>
>
> There is no path requirement.  Christian was incorrect in his diagnosis.
>
> texi2pdf won't delete files that existed before it was run, whether or not
> they were changed during the run.  That's likely what Christian was seeing.

Or, that the cleanup fails if the compilation is too quick, cf.
PR#15394 'texi2dvi(..., clean=TRUE) sometimes too quick for "clean"
(with PATCH)' submitted on July 17, 2013:

  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15394

/Henrik

>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Fri Aug 30 21:21:27 2013
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Aug 2013 21:21:27 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220EF23.5040400@gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com>
Message-ID: <5220F0B7.2000107@aon.at>

Dear Duncan, dear Marc,

Thank you for your fast reply.

Can you please tell me:
If texi2pdf() won't delete files how are the files deleted when the 
directory structure is Test/inst/doc/?
Is this done by Sweave()?

Best regards,
Christian


On 8/30/13 9:14 PM, Duncan Murdoch wrote:
> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>
>> > Dear all,
>> >
>> > To create a *.pdf file from a *.Rnw file I do:
>> >
>> >      olddir <- getwd();
>> >      setwd(outdir);
>> >
>> >      tryCatch({Sweave("QAReport.Rnw");
>> >                tools::texi2pdf("QAReport.tex", clean=TRUE)
>> >               },
>> >               finally = setwd(olddir)
>> >              );
>> >
>> > This works fine, however 'clean=TRUE' does only work when:
>> >     outdir <- "Test/inst/doc/"
>> > but does not remove the files *.aux, *.log, *.toc when:
>> >     outdir <- "Test/"
>> >
>> > Why does function texi2pdf() require the directory structure for
>> vignettes for the deletion of interim files?
>> >
>> > (The help file?texi2pdf does not mention that this structure is
>> necessary.)
>> >
>> > Best regards
>> > Christian
>>
>>
>> In the Details section of ?texi2pdf, there is:
>>
>> "Despite the name, this is used in R to compile LaTeX files,
>> specifically those generated from vignettes."
>>
>>
>> Since it is intended specifically for package vignettes, the path
>> requirement should not be a surprise. :-)
>>
>
> There is no path requirement.  Christian was incorrect in his diagnosis.
>
> texi2pdf won't delete files that existed before it was run, whether or
> not they were changed during the run.  That's likely what Christian was
> seeing.
>
> Duncan Murdoch
>


From murdoch.duncan at gmail.com  Fri Aug 30 21:30:45 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 30 Aug 2013 15:30:45 -0400
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220F0B7.2000107@aon.at>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
Message-ID: <5220F2E5.6070709@gmail.com>

On 30/08/2013 3:21 PM, cstrato wrote:
> Dear Duncan, dear Marc,
>
> Thank you for your fast reply.
>
> Can you please tell me:
> If texi2pdf() won't delete files how are the files deleted when the
> directory structure is Test/inst/doc/?
> Is this done by Sweave()?

No.

Duncan Murdoch
>
> Best regards,
> Christian
>
>
> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
> > On 30/08/2013 3:09 PM, Marc Schwartz wrote:
> >> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
> >>
> >> > Dear all,
> >> >
> >> > To create a *.pdf file from a *.Rnw file I do:
> >> >
> >> >      olddir <- getwd();
> >> >      setwd(outdir);
> >> >
> >> >      tryCatch({Sweave("QAReport.Rnw");
> >> >                tools::texi2pdf("QAReport.tex", clean=TRUE)
> >> >               },
> >> >               finally = setwd(olddir)
> >> >              );
> >> >
> >> > This works fine, however 'clean=TRUE' does only work when:
> >> >     outdir <- "Test/inst/doc/"
> >> > but does not remove the files *.aux, *.log, *.toc when:
> >> >     outdir <- "Test/"
> >> >
> >> > Why does function texi2pdf() require the directory structure for
> >> vignettes for the deletion of interim files?
> >> >
> >> > (The help file?texi2pdf does not mention that this structure is
> >> necessary.)
> >> >
> >> > Best regards
> >> > Christian
> >>
> >>
> >> In the Details section of ?texi2pdf, there is:
> >>
> >> "Despite the name, this is used in R to compile LaTeX files,
> >> specifically those generated from vignettes."
> >>
> >>
> >> Since it is intended specifically for package vignettes, the path
> >> requirement should not be a surprise. :-)
> >>
> >
> > There is no path requirement.  Christian was incorrect in his diagnosis.
> >
> > texi2pdf won't delete files that existed before it was run, whether or
> > not they were changed during the run.  That's likely what Christian was
> > seeing.
> >
> > Duncan Murdoch
> >


From hb at biostat.ucsf.edu  Fri Aug 30 21:36:28 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 12:36:28 -0700
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220F0B7.2000107@aon.at>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
Message-ID: <CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>

On Fri, Aug 30, 2013 at 12:21 PM, cstrato <cstrato at aon.at> wrote:
> Dear Duncan, dear Marc,
>
> Thank you for your fast reply.
>
> Can you please tell me:
> If texi2pdf() won't delete files how are the files deleted when the
> directory structure is Test/inst/doc/?

Check if what you're observing is reproducible when you run it *many*
times.  If not, see my previous reply.

/Henrik

> Is this done by Sweave()?
>
> Best regards,
> Christian
>
>
>
> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
>>
>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>
>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>
>>> > Dear all,
>>> >
>>> > To create a *.pdf file from a *.Rnw file I do:
>>> >
>>> >      olddir <- getwd();
>>> >      setwd(outdir);
>>> >
>>> >      tryCatch({Sweave("QAReport.Rnw");
>>> >                tools::texi2pdf("QAReport.tex", clean=TRUE)
>>> >               },
>>> >               finally = setwd(olddir)
>>> >              );
>>> >
>>> > This works fine, however 'clean=TRUE' does only work when:
>>> >     outdir <- "Test/inst/doc/"
>>> > but does not remove the files *.aux, *.log, *.toc when:
>>> >     outdir <- "Test/"
>>> >
>>> > Why does function texi2pdf() require the directory structure for
>>> vignettes for the deletion of interim files?
>>> >
>>> > (The help file?texi2pdf does not mention that this structure is
>>> necessary.)
>>> >
>>> > Best regards
>>> > Christian
>>>
>>>
>>> In the Details section of ?texi2pdf, there is:
>>>
>>> "Despite the name, this is used in R to compile LaTeX files,
>>> specifically those generated from vignettes."
>>>
>>>
>>> Since it is intended specifically for package vignettes, the path
>>> requirement should not be a surprise. :-)
>>>
>>
>> There is no path requirement.  Christian was incorrect in his diagnosis.
>>
>> texi2pdf won't delete files that existed before it was run, whether or
>> not they were changed during the run.  That's likely what Christian was
>> seeing.
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at me.com  Fri Aug 30 21:40:30 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 30 Aug 2013 14:40:30 -0500
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <CAFDcVCQhjXKMd4q+eYYY0OFiPDz56L1fya6ND1iSttUxp3rNdw@mail.gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com>
	<CAFDcVCQhjXKMd4q+eYYY0OFiPDz56L1fya6ND1iSttUxp3rNdw@mail.gmail.com>
Message-ID: <6B9AC052-B374-46E6-A12A-08E8CE706547@me.com>


On Aug 30, 2013, at 2:20 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

> On Fri, Aug 30, 2013 at 12:14 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>> 
>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>> 
>>>> Dear all,
>>>> 
>>>> To create a *.pdf file from a *.Rnw file I do:
>>>> 
>>>>     olddir <- getwd();
>>>>     setwd(outdir);
>>>> 
>>>>     tryCatch({Sweave("QAReport.Rnw");
>>>>               tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>              },
>>>>              finally = setwd(olddir)
>>>>             );
>>>> 
>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>    outdir <- "Test/inst/doc/"
>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>    outdir <- "Test/"
>>>> 
>>>> Why does function texi2pdf() require the directory structure for
>>>> vignettes for the deletion of interim files?
>>>> 
>>>> (The help file?texi2pdf does not mention that this structure is
>>>> necessary.)
>>>> 
>>>> Best regards
>>>> Christian
>>> 
>>> 
>>> In the Details section of ?texi2pdf, there is:
>>> 
>>> "Despite the name, this is used in R to compile LaTeX files, specifically
>>> those generated from vignettes."
>>> 
>>> 
>>> Since it is intended specifically for package vignettes, the path
>>> requirement should not be a surprise. :-)
>>> 
>> 
>> There is no path requirement.  Christian was incorrect in his diagnosis.
>> 
>> texi2pdf won't delete files that existed before it was run, whether or not
>> they were changed during the run.  That's likely what Christian was seeing.
> 
> Or, that the cleanup fails if the compilation is too quick, cf.
> PR#15394 'texi2dvi(..., clean=TRUE) sometimes too quick for "clean"
> (with PATCH)' submitted on July 17, 2013:
> 
>  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15394
> 
> /Henrik


Interesting.

It is late on a Friday, so perhaps I am short on functioning neurons.

If the intent of 'clean = TRUE' is to remove the byproducts of compiling the .PDF file from the source .TEX file, why not just delete the resultant aux|log|tex|dvi files that match the basename of the source .TEX file rather than being dependent upon the time stamp? 

Is there a reason that I am failing to consider for a need to retain these files if older than the current time stamp? Perhaps if the compilation requires multiple cycles of latex processing (eg. the use of longtables, etc.), in which case, one could run texi2pdf(..., clean = FALSE) some number of times, then a final texi2pdf(..., clean = TRUE) when done. I actually have my own shell script that does this when creating Sweave files.

Of course, the help file does have the following for the 'clean' argument: ...May not work on some platforms.

Thanks,

Marc


From hb at biostat.ucsf.edu  Fri Aug 30 21:46:02 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 12:46:02 -0700
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <6B9AC052-B374-46E6-A12A-08E8CE706547@me.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com>
	<CAFDcVCQhjXKMd4q+eYYY0OFiPDz56L1fya6ND1iSttUxp3rNdw@mail.gmail.com>
	<6B9AC052-B374-46E6-A12A-08E8CE706547@me.com>
Message-ID: <CAFDcVCRVz4nanmXu8hQ2Qo_pj9e-fE-w2ENz4vCsYY74HGNpaQ@mail.gmail.com>

On Fri, Aug 30, 2013 at 12:40 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
> On Aug 30, 2013, at 2:20 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>
>> On Fri, Aug 30, 2013 at 12:14 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>
>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>
>>>>>     olddir <- getwd();
>>>>>     setwd(outdir);
>>>>>
>>>>>     tryCatch({Sweave("QAReport.Rnw");
>>>>>               tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>              },
>>>>>              finally = setwd(olddir)
>>>>>             );
>>>>>
>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>    outdir <- "Test/inst/doc/"
>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>    outdir <- "Test/"
>>>>>
>>>>> Why does function texi2pdf() require the directory structure for
>>>>> vignettes for the deletion of interim files?
>>>>>
>>>>> (The help file?texi2pdf does not mention that this structure is
>>>>> necessary.)
>>>>>
>>>>> Best regards
>>>>> Christian
>>>>
>>>>
>>>> In the Details section of ?texi2pdf, there is:
>>>>
>>>> "Despite the name, this is used in R to compile LaTeX files, specifically
>>>> those generated from vignettes."
>>>>
>>>>
>>>> Since it is intended specifically for package vignettes, the path
>>>> requirement should not be a surprise. :-)
>>>>
>>>
>>> There is no path requirement.  Christian was incorrect in his diagnosis.
>>>
>>> texi2pdf won't delete files that existed before it was run, whether or not
>>> they were changed during the run.  That's likely what Christian was seeing.
>>
>> Or, that the cleanup fails if the compilation is too quick, cf.
>> PR#15394 'texi2dvi(..., clean=TRUE) sometimes too quick for "clean"
>> (with PATCH)' submitted on July 17, 2013:
>>
>>  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15394
>>
>> /Henrik
>
>
> Interesting.
>
> It is late on a Friday, so perhaps I am short on functioning neurons.
>
> If the intent of 'clean = TRUE' is to remove the byproducts of compiling the .PDF file from the source .TEX file, why not just delete the resultant aux|log|tex|dvi files that match the basename of the source .TEX file rather than being dependent upon the time stamp?

I'm quite sure because it is not easy/impossible to predict which the
byproducts are.  To catch everything, you'd have to do something
<basename>.* and that is certainly not safe.

/Henrik

>
> Is there a reason that I am failing to consider for a need to retain these files if older than the current time stamp? Perhaps if the compilation requires multiple cycles of latex processing (eg. the use of longtables, etc.), in which case, one could run texi2pdf(..., clean = FALSE) some number of times, then a final texi2pdf(..., clean = TRUE) when done. I actually have my own shell script that does this when creating Sweave files.
>
> Of course, the help file does have the following for the 'clean' argument: ...May not work on some platforms.
>
> Thanks,
>
> Marc
>


From hb at biostat.ucsf.edu  Fri Aug 30 21:47:27 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 12:47:27 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
In-Reply-To: <CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
Message-ID: <CAFDcVCSsd0KcZCCRv0f-MzUU__PJE9ZkrGF4jxy7dZS9Ci1Wyg@mail.gmail.com>

On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi.
>
> On Fri, Aug 30, 2013 at 6:58 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>> This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)
>
> For the record, you're referring to R-devel thread 'Correct NAMESPACE
> approach when writing an S3 method for a generic in another package'
> started on Aug 24, 2013
> [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
> Yes, it's closely related or possibly the same issue.  However, I do
> not find it odd that the S3 generic function needs to be exported
> from/available via the namespace.  Hence it needs to be export():ed by
> at least one package/namespace.
>
> The real issue is when two package needs to export a generic function
> with the same name, e.g. foo().   If the two generic functions are
> defined differently (e.g. different arguments/signatures), they will
> be in conflict with each other.  If they are identical, this should
> not be a problem, but here I might be wrong.  However, there is also
> the special case where one package reexports the generic function from
> another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
> the object 'foo' does actually not existing in the name space of
> package PkgB - instead it provides a "redirect" to it, e.g.
>
>> PkgA::foo
> function (...)
> UseMethod("foo")
> <environment: namespace:PkgA>
>
>> PkgB::foo
> function (...)
> UseMethod("foo")
> <environment: namespace:PkgA>
>
>> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
> [1] FALSE
>
>> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
> [1] TRUE
>
>> identical(PkgB::foo, PkgA::foo)
> [1] TRUE
>
>
> The warning on "replacing previous import by 'PkgA::foo' when loading
> 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
> base::namespaceImportFrom()
> [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R],
> simply because it detects that "foo" (=n) has already been imported to
> PkgC' namespace (=impenv):
>
> if (exists(n, envir = impenv, inherits = FALSE)) {
>     if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>         ## warn only if generic overwrites a function which
>         ## it was not derived from
>         ...
>     }
>     warning(sprintf(msg, sQuote(paste(nsname, n, sep = "::")),
> sQuote(from)), call. = FALSE, domain = NA)
> }
>
> Note how there is already code for avoiding "false" warnings on S4
> generic function.  This is what we'd like to have also for S3 generic
> functions, but it's much harder to test for such since they're not
> formally defined.  However, I'd argue that it is safe to skip the
> warning *when the variable to be imported does not actually exist in
> the package being imported* (e.g. when just rexported), i.e.
>
>>svn diff namespace.R
> Index: namespace.R
> ===================================================================
> --- namespace.R (revision 63776)
> +++ namespace.R (working copy)
> @@ -871,6 +871,10 @@
>      }
>      for (n in impnames)
>         if (exists(n, envir = impenv, inherits = FALSE)) {
> +            ## warn only if imported variable actually exists in the
> +            ## namespace imported from, which is not the case if
> +            ## the variable is rexported from another namespace
> +            if (!exists(n, envir = ns, inherits = FALSE)) next
>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>                 ## warn only if generic overwrites a function which
>                 ## it was not derived from

Ok, if import(PkgA, PkgB) and PkgB reexports a *different* foo() than
PkgA::foo(), say PkgZ::foo so identical(PkgB::foo, PkgA::foo) is
FALSE, then there is indeed a conflict.  An alternative patch:

>svn diff namespace.R
Index: namespace.R
===================================================================
--- namespace.R (revision 63776)
+++ namespace.R (working copy)
@@ -871,6 +871,11 @@
     }
     for (n in impnames)
        if (exists(n, envir = impenv, inherits = FALSE)) {
+            ## warn only if imported variable is non-identical to
+            ## the one already imported
+            getImp <- get(n, envir = impenv)
+            obj <- get(n, envir = ns)
+            if (identical(obj, getImp)) next
            if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
                ## warn only if generic overwrites a function which
                ## it was not derived from

/Henrik

>
> I'm planning to propose ("wishlist / enhancement"; it may even be a
> bug) this over at https://bugs.r-project.org/.
>
> Comments, anyone?
>
> /Henrik
>
>
>> Paul
>>
>> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>
>>>Hi,
>>>
>>>SETUP:
>>>Consider three packages PkgA, PkgB and PkgC.
>>>
>>>PkgA defines a generic function foo() and exports it;
>>>
>>>export(foo)
>>>
>>>PkgB imports PkgA::foo() and re-exports it;
>>>
>>>importFrom(PkgA, foo)
>>>export(foo)
>>>
>>>PkgC imports everything from PkgA and PkgB:
>>>
>>>imports(PkgA, PkgB)
>>>
>>>
>>>PROBLEM:
>>>Loading or attaching the namespace of PkgC will generate a warning:
>>>
>>>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>>>
>>>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>>>
>>>* checking whether package 'PkgC' can be installed ... WARNING
>>>Found the following significant warnings:
>>>  Warning: replacing previous import by 'PkgA::foo' when loading
>>>'CellularAutomaton'
>>>
>>>
>>>FALSE?
>>>Isn't it valid to argue that this is a "false" warning, because
>>>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>>>
>>>
>>>/Henrik
>>>
>>>PS. The above can be avoided by using explicit importFrom() on PkgA
>>>and PkgB, but that's really tedious.  In my case this is out of my
>>>reach, because I'm the author of PkgA and PkgB but not many of the
>>>PkgC packages.
>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Fri Aug 30 21:50:24 2013
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Aug 2013 21:50:24 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
	<CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>
Message-ID: <5220F780.8080507@aon.at>

Dear Henrik,

Thank you for your explanation.

Yes, this behavior is reproducible many times.

When I copy both lines together into R, i.e.
    Sweave("QAReport.Rnw")
    tools::texi2pdf("QAReport.tex", clean = TRUE)

then the auxiliary files are deleted. However, when I keep the *.tex 
file only and run:
    tools::texi2pdf("QAReport.tex", clean = TRUE)

then these files are not deleted. I can delete them manually many times 
and run texi2pdf() again, they will never be deleted.

I really hope that your patch will be applied, so that it works as 
expected with the next Bioconductor release on October.

Best regards,
Christian


On 8/30/13 9:36 PM, Henrik Bengtsson wrote:
> On Fri, Aug 30, 2013 at 12:21 PM, cstrato <cstrato at aon.at> wrote:
>> Dear Duncan, dear Marc,
>>
>> Thank you for your fast reply.
>>
>> Can you please tell me:
>> If texi2pdf() won't delete files how are the files deleted when the
>> directory structure is Test/inst/doc/?
>
> Check if what you're observing is reproducible when you run it *many*
> times.  If not, see my previous reply.
>
> /Henrik
>
>> Is this done by Sweave()?
>>
>> Best regards,
>> Christian
>>
>>
>>
>> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
>>>
>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>
>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>
>>>>>       olddir <- getwd();
>>>>>       setwd(outdir);
>>>>>
>>>>>       tryCatch({Sweave("QAReport.Rnw");
>>>>>                 tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>                },
>>>>>                finally = setwd(olddir)
>>>>>               );
>>>>>
>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>      outdir <- "Test/inst/doc/"
>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>      outdir <- "Test/"
>>>>>
>>>>> Why does function texi2pdf() require the directory structure for
>>>> vignettes for the deletion of interim files?
>>>>>
>>>>> (The help file?texi2pdf does not mention that this structure is
>>>> necessary.)
>>>>>
>>>>> Best regards
>>>>> Christian
>>>>
>>>>
>>>> In the Details section of ?texi2pdf, there is:
>>>>
>>>> "Despite the name, this is used in R to compile LaTeX files,
>>>> specifically those generated from vignettes."
>>>>
>>>>
>>>> Since it is intended specifically for package vignettes, the path
>>>> requirement should not be a surprise. :-)
>>>>
>>>
>>> There is no path requirement.  Christian was incorrect in his diagnosis.
>>>
>>> texi2pdf won't delete files that existed before it was run, whether or
>>> not they were changed during the run.  That's likely what Christian was
>>> seeing.
>>>
>>> Duncan Murdoch
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cstrato at aon.at  Fri Aug 30 21:55:14 2013
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Aug 2013 21:55:14 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <CAFDcVCRVz4nanmXu8hQ2Qo_pj9e-fE-w2ENz4vCsYY74HGNpaQ@mail.gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com>
	<CAFDcVCQhjXKMd4q+eYYY0OFiPDz56L1fya6ND1iSttUxp3rNdw@mail.gmail.com>
	<6B9AC052-B374-46E6-A12A-08E8CE706547@me.com>
	<CAFDcVCRVz4nanmXu8hQ2Qo_pj9e-fE-w2ENz4vCsYY74HGNpaQ@mail.gmail.com>
Message-ID: <5220F8A2.8000608@aon.at>

Dear Henrik,

Below is the 'QAReport.Rnw' file which I use on my Mac to reproduce your 
problem. Maybe this will help others to reproduce this problem, too.

Best regards,
Christian

---- begin QAReport.Rnw ----
\documentclass{article}


\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Cclass}[1]{{\textit{#1}}}
\newcommand{\Rexten}[1]{{\textit{#1}}}
\newcommand{\xps}{\Rpackage{xps}}
\newcommand{\ROOT}{\Robject{ROOT}}

\begin{document}

\title{Quality Report}
\date{October, 2011}
\author{Christian Stratowa}
\maketitle

\tableofcontents


\section{Introduction}

  This is the quality assessment report for the dataset 'My Dataset'. 
The dataset consists of
  6 Affymetrix GeneChip arrays of type 'Test3'. \\

  This report was generated using function \Rfunction{xpsQAReport} of 
package \xps. \\

\section{Summary}

  The current quality report for dataset 'My Dataset' displays the most 
important quality plots, using the
  default settings for most plots. Package \xps\ contains additional 
plots which can be used for further
  quality assessments. \\


\section*{Session Information:}

<<echo=FALSE>>=
sessionInfo()
@

\end{document}

---- end QAReport.Rnw ----



On 8/30/13 9:46 PM, Henrik Bengtsson wrote:
> On Fri, Aug 30, 2013 at 12:40 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>
>> On Aug 30, 2013, at 2:20 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>
>>> On Fri, Aug 30, 2013 at 12:14 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>>
>>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>>
>>>>>>      olddir <- getwd();
>>>>>>      setwd(outdir);
>>>>>>
>>>>>>      tryCatch({Sweave("QAReport.Rnw");
>>>>>>                tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>>               },
>>>>>>               finally = setwd(olddir)
>>>>>>              );
>>>>>>
>>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>>     outdir <- "Test/inst/doc/"
>>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>>     outdir <- "Test/"
>>>>>>
>>>>>> Why does function texi2pdf() require the directory structure for
>>>>>> vignettes for the deletion of interim files?
>>>>>>
>>>>>> (The help file?texi2pdf does not mention that this structure is
>>>>>> necessary.)
>>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>
>>>>>
>>>>> In the Details section of ?texi2pdf, there is:
>>>>>
>>>>> "Despite the name, this is used in R to compile LaTeX files, specifically
>>>>> those generated from vignettes."
>>>>>
>>>>>
>>>>> Since it is intended specifically for package vignettes, the path
>>>>> requirement should not be a surprise. :-)
>>>>>
>>>>
>>>> There is no path requirement.  Christian was incorrect in his diagnosis.
>>>>
>>>> texi2pdf won't delete files that existed before it was run, whether or not
>>>> they were changed during the run.  That's likely what Christian was seeing.
>>>
>>> Or, that the cleanup fails if the compilation is too quick, cf.
>>> PR#15394 'texi2dvi(..., clean=TRUE) sometimes too quick for "clean"
>>> (with PATCH)' submitted on July 17, 2013:
>>>
>>>   https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15394
>>>
>>> /Henrik
>>
>>
>> Interesting.
>>
>> It is late on a Friday, so perhaps I am short on functioning neurons.
>>
>> If the intent of 'clean = TRUE' is to remove the byproducts of compiling the .PDF file from the source .TEX file, why not just delete the resultant aux|log|tex|dvi files that match the basename of the source .TEX file rather than being dependent upon the time stamp?
>
> I'm quite sure because it is not easy/impossible to predict which the
> byproducts are.  To catch everything, you'd have to do something
> <basename>.* and that is certainly not safe.
>
> /Henrik
>
>>
>> Is there a reason that I am failing to consider for a need to retain these files if older than the current time stamp? Perhaps if the compilation requires multiple cycles of latex processing (eg. the use of longtables, etc.), in which case, one could run texi2pdf(..., clean = FALSE) some number of times, then a final texi2pdf(..., clean = TRUE) when done. I actually have my own shell script that does this when creating Sweave files.
>>
>> Of course, the help file does have the following for the 'clean' argument: ...May not work on some platforms.
>>
>> Thanks,
>>
>> Marc
>>
>


From cstrato at aon.at  Fri Aug 30 22:05:11 2013
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Aug 2013 22:05:11 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220F780.8080507@aon.at>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
	<CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>
	<5220F780.8080507@aon.at>
Message-ID: <5220FAF7.5080603@aon.at>

Dear Henrik,

I am trying to attach the 'QAReport.Rnw' file which I am using on my Mac 
to reproduce your problem.

Best regards,
Christian


On 8/30/13 9:50 PM, cstrato wrote:
> Dear Henrik,
>
> Thank you for your explanation.
>
> Yes, this behavior is reproducible many times.
>
> When I copy both lines together into R, i.e.
>     Sweave("QAReport.Rnw")
>     tools::texi2pdf("QAReport.tex", clean = TRUE)
>
> then the auxiliary files are deleted. However, when I keep the *.tex
> file only and run:
>     tools::texi2pdf("QAReport.tex", clean = TRUE)
>
> then these files are not deleted. I can delete them manually many times
> and run texi2pdf() again, they will never be deleted.
>
> I really hope that your patch will be applied, so that it works as
> expected with the next Bioconductor release on October.
>
> Best regards,
> Christian
>
>
> On 8/30/13 9:36 PM, Henrik Bengtsson wrote:
>> On Fri, Aug 30, 2013 at 12:21 PM, cstrato <cstrato at aon.at> wrote:
>>> Dear Duncan, dear Marc,
>>>
>>> Thank you for your fast reply.
>>>
>>> Can you please tell me:
>>> If texi2pdf() won't delete files how are the files deleted when the
>>> directory structure is Test/inst/doc/?
>>
>> Check if what you're observing is reproducible when you run it *many*
>> times.  If not, see my previous reply.
>>
>> /Henrik
>>
>>> Is this done by Sweave()?
>>>
>>> Best regards,
>>> Christian
>>>
>>>
>>>
>>> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
>>>>
>>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>>
>>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>>
>>>>>>       olddir <- getwd();
>>>>>>       setwd(outdir);
>>>>>>
>>>>>>       tryCatch({Sweave("QAReport.Rnw");
>>>>>>                 tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>>                },
>>>>>>                finally = setwd(olddir)
>>>>>>               );
>>>>>>
>>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>>      outdir <- "Test/inst/doc/"
>>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>>      outdir <- "Test/"
>>>>>>
>>>>>> Why does function texi2pdf() require the directory structure for
>>>>> vignettes for the deletion of interim files?
>>>>>>
>>>>>> (The help file?texi2pdf does not mention that this structure is
>>>>> necessary.)
>>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>
>>>>>
>>>>> In the Details section of ?texi2pdf, there is:
>>>>>
>>>>> "Despite the name, this is used in R to compile LaTeX files,
>>>>> specifically those generated from vignettes."
>>>>>
>>>>>
>>>>> Since it is intended specifically for package vignettes, the path
>>>>> requirement should not be a surprise. :-)
>>>>>
>>>>
>>>> There is no path requirement.  Christian was incorrect in his
>>>> diagnosis.
>>>>
>>>> texi2pdf won't delete files that existed before it was run, whether or
>>>> not they were changed during the run.  That's likely what Christian was
>>>> seeing.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
-------------- next part --------------
\documentclass{article}


\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Cclass}[1]{{\textit{#1}}}
\newcommand{\Rexten}[1]{{\textit{#1}}}
\newcommand{\xps}{\Rpackage{xps}}
\newcommand{\ROOT}{\Robject{ROOT}}

\begin{document}

\title{Quality Report}
\date{October, 2011}
\author{Christian Stratowa}
\maketitle

\tableofcontents


\section{Introduction}

 This is the quality assessment report for the dataset 'My Dataset'. The dataset consists of
 6 Affymetrix GeneChip arrays of type 'Test3'. \\

 This report was generated using function \Rfunction{xpsQAReport} of package \xps. \\

\section{Summary}

 The current quality report for dataset 'My Dataset' displays the most important quality plots, using the
 default settings for most plots. Package \xps\ contains additional plots which can be used for further
 quality assessments. \\


\section*{Session Information:}

<<echo=FALSE>>=
sessionInfo()
@ 

\end{document}

From hb at biostat.ucsf.edu  Fri Aug 30 22:23:49 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 30 Aug 2013 13:23:49 -0700
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <5220FAF7.5080603@aon.at>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
	<CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>
	<5220F780.8080507@aon.at> <5220FAF7.5080603@aon.at>
Message-ID: <CAFDcVCQVQA6R2M5URVZONpQZWk7eW64z0utU0tvsqmHKTAK2XQ@mail.gmail.com>

Just checked the SVN logs and the comparison towards file timestamps
have been dropped in R devel and R 3.0.1 SVN r63690 (Aug 25, 2013) and
newer.  It is now simply comparing the set of files before and after.
Try with one of those and I'll bet you that clean=TRUE does what it
supposed to.

/Henrik


On Fri, Aug 30, 2013 at 1:05 PM, cstrato <cstrato at aon.at> wrote:
> Dear Henrik,
>
> I am trying to attach the 'QAReport.Rnw' file which I am using on my Mac to
> reproduce your problem.
>
> Best regards,
> Christian
>
>
>
> On 8/30/13 9:50 PM, cstrato wrote:
>>
>> Dear Henrik,
>>
>> Thank you for your explanation.
>>
>> Yes, this behavior is reproducible many times.
>>
>> When I copy both lines together into R, i.e.
>>     Sweave("QAReport.Rnw")
>>     tools::texi2pdf("QAReport.tex", clean = TRUE)
>>
>> then the auxiliary files are deleted. However, when I keep the *.tex
>> file only and run:
>>     tools::texi2pdf("QAReport.tex", clean = TRUE)
>>
>> then these files are not deleted. I can delete them manually many times
>> and run texi2pdf() again, they will never be deleted.
>>
>> I really hope that your patch will be applied, so that it works as
>> expected with the next Bioconductor release on October.
>>
>> Best regards,
>> Christian
>>
>>
>> On 8/30/13 9:36 PM, Henrik Bengtsson wrote:
>>>
>>> On Fri, Aug 30, 2013 at 12:21 PM, cstrato <cstrato at aon.at> wrote:
>>>>
>>>> Dear Duncan, dear Marc,
>>>>
>>>> Thank you for your fast reply.
>>>>
>>>> Can you please tell me:
>>>> If texi2pdf() won't delete files how are the files deleted when the
>>>> directory structure is Test/inst/doc/?
>>>
>>>
>>> Check if what you're observing is reproducible when you run it *many*
>>> times.  If not, see my previous reply.
>>>
>>> /Henrik
>>>
>>>> Is this done by Sweave()?
>>>>
>>>> Best regards,
>>>> Christian
>>>>
>>>>
>>>>
>>>> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
>>>>>
>>>>>
>>>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>>>
>>>>>>
>>>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>>>
>>>>>>> Dear all,
>>>>>>>
>>>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>>>
>>>>>>>       olddir <- getwd();
>>>>>>>       setwd(outdir);
>>>>>>>
>>>>>>>       tryCatch({Sweave("QAReport.Rnw");
>>>>>>>                 tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>>>                },
>>>>>>>                finally = setwd(olddir)
>>>>>>>               );
>>>>>>>
>>>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>>>      outdir <- "Test/inst/doc/"
>>>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>>>      outdir <- "Test/"
>>>>>>>
>>>>>>> Why does function texi2pdf() require the directory structure for
>>>>>>
>>>>>> vignettes for the deletion of interim files?
>>>>>>>
>>>>>>>
>>>>>>> (The help file?texi2pdf does not mention that this structure is
>>>>>>
>>>>>> necessary.)
>>>>>>>
>>>>>>>
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>
>>>>>>
>>>>>>
>>>>>> In the Details section of ?texi2pdf, there is:
>>>>>>
>>>>>> "Despite the name, this is used in R to compile LaTeX files,
>>>>>> specifically those generated from vignettes."
>>>>>>
>>>>>>
>>>>>> Since it is intended specifically for package vignettes, the path
>>>>>> requirement should not be a surprise. :-)
>>>>>>
>>>>>
>>>>> There is no path requirement.  Christian was incorrect in his
>>>>> diagnosis.
>>>>>
>>>>> texi2pdf won't delete files that existed before it was run, whether or
>>>>> not they were changed during the run.  That's likely what Christian was
>>>>> seeing.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>


From cstrato at aon.at  Sat Aug 31 00:12:23 2013
From: cstrato at aon.at (cstrato)
Date: Sat, 31 Aug 2013 00:12:23 +0200
Subject: [Rd] Problem with texi2pdf(..,clean=TRUE)
In-Reply-To: <CAFDcVCQVQA6R2M5URVZONpQZWk7eW64z0utU0tvsqmHKTAK2XQ@mail.gmail.com>
References: <5220EBBE.8080504@aon.at>
	<D9E36BC9-3F08-4735-A61C-C183486D59C3@me.com>
	<5220EF23.5040400@gmail.com> <5220F0B7.2000107@aon.at>
	<CAFDcVCSRbFwDAee0sUtkQHwEK-488b=5uhq142n_eKgwCjV1RA@mail.gmail.com>
	<5220F780.8080507@aon.at> <5220FAF7.5080603@aon.at>
	<CAFDcVCQVQA6R2M5URVZONpQZWk7eW64z0utU0tvsqmHKTAK2XQ@mail.gmail.com>
Message-ID: <522118C7.4070305@aon.at>

Dear Henrik,

Thank you for this information, I will try to install the patched version.

Best regards,
Christian


On 8/30/13 10:23 PM, Henrik Bengtsson wrote:
> Just checked the SVN logs and the comparison towards file timestamps
> have been dropped in R devel and R 3.0.1 SVN r63690 (Aug 25, 2013) and
> newer.  It is now simply comparing the set of files before and after.
> Try with one of those and I'll bet you that clean=TRUE does what it
> supposed to.
>
> /Henrik
>
>
> On Fri, Aug 30, 2013 at 1:05 PM, cstrato <cstrato at aon.at> wrote:
>> Dear Henrik,
>>
>> I am trying to attach the 'QAReport.Rnw' file which I am using on my Mac to
>> reproduce your problem.
>>
>> Best regards,
>> Christian
>>
>>
>>
>> On 8/30/13 9:50 PM, cstrato wrote:
>>>
>>> Dear Henrik,
>>>
>>> Thank you for your explanation.
>>>
>>> Yes, this behavior is reproducible many times.
>>>
>>> When I copy both lines together into R, i.e.
>>>      Sweave("QAReport.Rnw")
>>>      tools::texi2pdf("QAReport.tex", clean = TRUE)
>>>
>>> then the auxiliary files are deleted. However, when I keep the *.tex
>>> file only and run:
>>>      tools::texi2pdf("QAReport.tex", clean = TRUE)
>>>
>>> then these files are not deleted. I can delete them manually many times
>>> and run texi2pdf() again, they will never be deleted.
>>>
>>> I really hope that your patch will be applied, so that it works as
>>> expected with the next Bioconductor release on October.
>>>
>>> Best regards,
>>> Christian
>>>
>>>
>>> On 8/30/13 9:36 PM, Henrik Bengtsson wrote:
>>>>
>>>> On Fri, Aug 30, 2013 at 12:21 PM, cstrato <cstrato at aon.at> wrote:
>>>>>
>>>>> Dear Duncan, dear Marc,
>>>>>
>>>>> Thank you for your fast reply.
>>>>>
>>>>> Can you please tell me:
>>>>> If texi2pdf() won't delete files how are the files deleted when the
>>>>> directory structure is Test/inst/doc/?
>>>>
>>>>
>>>> Check if what you're observing is reproducible when you run it *many*
>>>> times.  If not, see my previous reply.
>>>>
>>>> /Henrik
>>>>
>>>>> Is this done by Sweave()?
>>>>>
>>>>> Best regards,
>>>>> Christian
>>>>>
>>>>>
>>>>>
>>>>> On 8/30/13 9:14 PM, Duncan Murdoch wrote:
>>>>>>
>>>>>>
>>>>>> On 30/08/2013 3:09 PM, Marc Schwartz wrote:
>>>>>>>
>>>>>>>
>>>>>>> On Aug 30, 2013, at 2:00 PM, cstrato <cstrato at aon.at> wrote:
>>>>>>>
>>>>>>>> Dear all,
>>>>>>>>
>>>>>>>> To create a *.pdf file from a *.Rnw file I do:
>>>>>>>>
>>>>>>>>        olddir <- getwd();
>>>>>>>>        setwd(outdir);
>>>>>>>>
>>>>>>>>        tryCatch({Sweave("QAReport.Rnw");
>>>>>>>>                  tools::texi2pdf("QAReport.tex", clean=TRUE)
>>>>>>>>                 },
>>>>>>>>                 finally = setwd(olddir)
>>>>>>>>                );
>>>>>>>>
>>>>>>>> This works fine, however 'clean=TRUE' does only work when:
>>>>>>>>       outdir <- "Test/inst/doc/"
>>>>>>>> but does not remove the files *.aux, *.log, *.toc when:
>>>>>>>>       outdir <- "Test/"
>>>>>>>>
>>>>>>>> Why does function texi2pdf() require the directory structure for
>>>>>>>
>>>>>>> vignettes for the deletion of interim files?
>>>>>>>>
>>>>>>>>
>>>>>>>> (The help file?texi2pdf does not mention that this structure is
>>>>>>>
>>>>>>> necessary.)
>>>>>>>>
>>>>>>>>
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> In the Details section of ?texi2pdf, there is:
>>>>>>>
>>>>>>> "Despite the name, this is used in R to compile LaTeX files,
>>>>>>> specifically those generated from vignettes."
>>>>>>>
>>>>>>>
>>>>>>> Since it is intended specifically for package vignettes, the path
>>>>>>> requirement should not be a surprise. :-)
>>>>>>>
>>>>>>
>>>>>> There is no path requirement.  Christian was incorrect in his
>>>>>> diagnosis.
>>>>>>
>>>>>> texi2pdf won't delete files that existed before it was run, whether or
>>>>>> not they were changed during the run.  That's likely what Christian was
>>>>>> seeing.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>
>


From oboturov at gmail.com  Fri Aug 30 13:22:47 2013
From: oboturov at gmail.com (=?UTF-8?B?0J7QsdC+0YLRg9GA0L7QsiDQkNGA0YLQtdC8?=)
Date: Fri, 30 Aug 2013 13:22:47 +0200
Subject: [Rd] Type annotations for R function parameters.
In-Reply-To: <522079E9.8080702@gmail.com>
References: <CAKFcK8j8OsVGC4LaL4P7ec+2683SypGjOJEsFqV6pfHhFJHMUQ@mail.gmail.com>
	<522079E9.8080702@gmail.com>
Message-ID: <CAKFcK8iua93o+ve7=GyGwLzx6NUBrPgf2UGx8jNFSTi9MkxhQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130830/82685997/attachment.pl>

