From sannandi at umail.iu.edu  Tue Apr  1 01:40:57 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Mon, 31 Mar 2014 16:40:57 -0700
Subject: [Rd] C API to get numrow of data frame
Message-ID: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140331/061615b0/attachment.pl>

From murray at stokely.org  Tue Apr  1 02:04:28 2014
From: murray at stokely.org (Murray Stokely)
Date: Mon, 31 Mar 2014 17:04:28 -0700
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
Message-ID: <CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>

The simplest case would be:

   int num_rows = Rf_length(VECTOR_ELT(dataframe, 0));
   int num_columns = Rf_length(dataframe);

There may be edge cases for which this doesn't work; would need to
look into how the dim primitive is implemented to be sure.

               - Murray


On Mon, Mar 31, 2014 at 4:40 PM, Sandip Nandi <sannandi at umail.iu.edu> wrote:
> Hi ,
>
> Is there any C API to the R API  nrow of dataframe ?
>
> x<- data.frame()
> n<- nrow(x)
> print(n)
> 0
>
>
> Example :
> My C function which deals with data frame looks like and I don't to send
> the  number of rows of data frame .I want to detect it from the function
> itself, my function take data frame as argument and do some on it. I want
> API equivalent to nrow. I tried Rf_nrows,Rf_ncols . No much help.
>
> SEXP  writeRR(SEXP dataframe) {
>
> }
>
>
> Any help is very appreciated.
>
> Thanks,
> Sandip
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sannandi at umail.iu.edu  Tue Apr  1 02:54:41 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Mon, 31 Mar 2014 17:54:41 -0700
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
	<CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
Message-ID: <CAGSjAUA4gPaeViQPZ2ACxXWcUxFf443+i9Z8Vhp7JRORQnGBpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140331/17da637b/attachment.pl>

From csardi.gabor at gmail.com  Tue Apr  1 03:12:05 2014
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Mon, 31 Mar 2014 21:12:05 -0400
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
	<CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
Message-ID: <CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140331/82d29c59/attachment.pl>

From sannandi at umail.iu.edu  Tue Apr  1 03:14:30 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Mon, 31 Mar 2014 18:14:30 -0700
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
	<CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
	<CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>
Message-ID: <CAGSjAUDVaxFjBPLNLxXPbkeDyyzN9Qc59-sxBZr6V0QEsx=OmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140331/3caeeb3d/attachment.pl>

From murray at stokely.org  Tue Apr  1 03:27:53 2014
From: murray at stokely.org (Murray Stokely)
Date: Mon, 31 Mar 2014 18:27:53 -0700
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
	<CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
	<CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>
Message-ID: <CAECWziKRWv_y_SUdivEpnHBiSS4p3GQLKeZobFTfeQFeEGsQ+A@mail.gmail.com>

I didn't look at the names because I believe that would be incorrect
if the row names were stored internally in the compact form.

See ?.set_row_names (hat tip, Tim Hesterberg who showed me this years ago) :

     'row.names' can be stored internally in compact form.
     '.set_row_names(n)' generates that form for automatic row names of
     length 'n', to be assigned to 'attr(<a data frame>, "row.names")'.
     '.row_names_info' gives information on the internal form of the
     row names for a data frame: for details of what information see
     the argument 'type'.

The function I wrote obviously doesn't work for 0 row or 0 column
data.frames, you need to check for that.

On Mon, Mar 31, 2014 at 6:12 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> I think it is actually better to check the length of the row names. In case
> the data frame has zero columns. (FIXME, of course.)
>
> Gabor
>
>
> On Mon, Mar 31, 2014 at 8:04 PM, Murray Stokely <murray at stokely.org> wrote:
>>
>> The simplest case would be:
>>
>>    int num_rows = Rf_length(VECTOR_ELT(dataframe, 0));
>>    int num_columns = Rf_length(dataframe);
>>
>> There may be edge cases for which this doesn't work; would need to
>> look into how the dim primitive is implemented to be sure.
>>
>>                - Murray
>>
>>
>> On Mon, Mar 31, 2014 at 4:40 PM, Sandip Nandi <sannandi at umail.iu.edu>
>> wrote:
>> > Hi ,
>> >
>> > Is there any C API to the R API  nrow of dataframe ?
>> >
>> > x<- data.frame()
>> > n<- nrow(x)
>> > print(n)
>> > 0
>> >
>> >
>> > Example :
>> > My C function which deals with data frame looks like and I don't to send
>> > the  number of rows of data frame .I want to detect it from the function
>> > itself, my function take data frame as argument and do some on it. I
>> > want
>> > API equivalent to nrow. I tried Rf_nrows,Rf_ncols . No much help.
>> >
>> > SEXP  writeRR(SEXP dataframe) {
>> >
>> > }
>> >
>> >
>> > Any help is very appreciated.
>> >
>> > Thanks,
>> > Sandip
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From kevinushey at gmail.com  Tue Apr  1 04:51:37 2014
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 31 Mar 2014 19:51:37 -0700
Subject: [Rd] C API to get numrow of data frame
In-Reply-To: <CAECWziKRWv_y_SUdivEpnHBiSS4p3GQLKeZobFTfeQFeEGsQ+A@mail.gmail.com>
References: <CAGSjAUBKaMh0gipxCvGCftDLPX8EfnVhp3vGY1D=mQ=i-P=YdA@mail.gmail.com>
	<CAECWziL0EeJqHLSrr9fYzRT5bgPeGLzWX-4Kmwx+8jQL978ycQ@mail.gmail.com>
	<CABtg=K=btOH=m3e6sLE+JNyqFcs5Y2OPWr_Ayg6HYVjuZMfKFw@mail.gmail.com>
	<CAECWziKRWv_y_SUdivEpnHBiSS4p3GQLKeZobFTfeQFeEGsQ+A@mail.gmail.com>
Message-ID: <CAJXgQP39W+LScJU0=kTh_rXZSv27rOn8q0oy-uajPFZKsHThCA@mail.gmail.com>

The safest way is to check the length of the row.names attribute, e.g.

    length(getAttrib(df, R_RowNamesSymbol)).

This protects you from both data.frames with zero columns, as well as
corrupted data.frames containing columns with different lengths, since
by definition the number of rows in a data.frame is defined by its
row.names attribute. However, R will internally un-collapse a
collapsed row.names on this getAttrib call, which is probably
undesired for very large data.frames.

One way of getting around this is calling .row_names_info from R, e.g.
(modulo my errors):

int df_nrows(SEXP s) {
    if (!Rf_inherits(s, "data.frame")) Rf_error("expecting a data.frame");
    SEXP two = PROTECT(Rf_ScalarInteger(2));
    SEXP call = PROTECT( Rf_lang3(
      Rf_install(".row_names_info"),
      s,
      two
    ) );
    SEXP result = PROTECT(Rf_eval(call, R_BaseEnv));
    int output = INTEGER(result)[0];
    UNPROTECT(3);
    return output;
}

More ideally (?), such a function could be added to util.c and
exported by R, e.g. (again, modulo my errors):

int df_nrows(SEXP s) {
    if (!inherits(s, "data.frame")) error("expecting a data.frame");
    SEXP t = getAttrib0(s, R_RowNamesSymbol);
    if (isInteger(t) && INTEGER(t)[0] == NA_INTEGER && LENGTH(t) == 2)
      return abs(INTEGER(t)[1]);
    else
      return LENGTH(t);
}

or even incorporated into the already available 'nrows' function.
Although there is probably someone out there depending on 'nrows'
returning the number of columns for their data.frame...

Cheers,
Kevin

On Mon, Mar 31, 2014 at 6:27 PM, Murray Stokely <murray at stokely.org> wrote:
> I didn't look at the names because I believe that would be incorrect
> if the row names were stored internally in the compact form.
>
> See ?.set_row_names (hat tip, Tim Hesterberg who showed me this years ago) :
>
>      'row.names' can be stored internally in compact form.
>      '.set_row_names(n)' generates that form for automatic row names of
>      length 'n', to be assigned to 'attr(<a data frame>, "row.names")'.
>      '.row_names_info' gives information on the internal form of the
>      row names for a data frame: for details of what information see
>      the argument 'type'.
>
> The function I wrote obviously doesn't work for 0 row or 0 column
> data.frames, you need to check for that.
>
> On Mon, Mar 31, 2014 at 6:12 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> I think it is actually better to check the length of the row names. In case
>> the data frame has zero columns. (FIXME, of course.)
>>
>> Gabor
>>
>>
>> On Mon, Mar 31, 2014 at 8:04 PM, Murray Stokely <murray at stokely.org> wrote:
>>>
>>> The simplest case would be:
>>>
>>>    int num_rows = Rf_length(VECTOR_ELT(dataframe, 0));
>>>    int num_columns = Rf_length(dataframe);
>>>
>>> There may be edge cases for which this doesn't work; would need to
>>> look into how the dim primitive is implemented to be sure.
>>>
>>>                - Murray
>>>
>>>
>>> On Mon, Mar 31, 2014 at 4:40 PM, Sandip Nandi <sannandi at umail.iu.edu>
>>> wrote:
>>> > Hi ,
>>> >
>>> > Is there any C API to the R API  nrow of dataframe ?
>>> >
>>> > x<- data.frame()
>>> > n<- nrow(x)
>>> > print(n)
>>> > 0
>>> >
>>> >
>>> > Example :
>>> > My C function which deals with data frame looks like and I don't to send
>>> > the  number of rows of data frame .I want to detect it from the function
>>> > itself, my function take data frame as argument and do some on it. I
>>> > want
>>> > API equivalent to nrow. I tried Rf_nrows,Rf_ncols . No much help.
>>> >
>>> > SEXP  writeRR(SEXP dataframe) {
>>> >
>>> > }
>>> >
>>> >
>>> > Any help is very appreciated.
>>> >
>>> > Thanks,
>>> > Sandip
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sannandi at umail.iu.edu  Wed Apr  2 02:46:03 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Tue, 1 Apr 2014 17:46:03 -0700
Subject: [Rd] Typeof for character vector in dataframe returns integer
Message-ID: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/f100fc29/attachment.pl>

From sannandi at umail.iu.edu  Wed Apr  2 02:55:52 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Tue, 1 Apr 2014 17:55:52 -0700
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <D4D4BDC9-394C-489B-83C1-E158E93D0EB3@gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<D4D4BDC9-394C-489B-83C1-E158E93D0EB3@gmail.com>
Message-ID: <CAGSjAUACYg5eGQqPY6+vzaDB_hFfjzUZgm9B1mqzbOeh0NLodA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/6cecd721/attachment.pl>

From josh.m.ulrich at gmail.com  Wed Apr  2 02:56:10 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 1 Apr 2014 19:56:10 -0500
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
Message-ID: <CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/9c3c97d1/attachment.pl>

From sannandi at umail.iu.edu  Wed Apr  2 03:04:30 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Tue, 1 Apr 2014 18:04:30 -0700
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
Message-ID: <CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/1490ffba/attachment.pl>

From josh.m.ulrich at gmail.com  Wed Apr  2 03:18:02 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 1 Apr 2014 20:18:02 -0500
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
	<CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>
Message-ID: <CAPPM_gQfD=dvC-6ez=VORgZ_nNsJKCPuuyH0nrQBYMB7R=KgYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/df9aaff2/attachment.pl>

From sannandi at umail.iu.edu  Wed Apr  2 06:13:29 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Tue, 1 Apr 2014 21:13:29 -0700
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAPPM_gQfD=dvC-6ez=VORgZ_nNsJKCPuuyH0nrQBYMB7R=KgYA@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
	<CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>
	<CAPPM_gQfD=dvC-6ez=VORgZ_nNsJKCPuuyH0nrQBYMB7R=KgYA@mail.gmail.com>
Message-ID: <CAGSjAUD3nJj_1zq3J3=7ERNtXRPF0QqMU2Ut52H5wzRnzF1XCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140401/dd91d29d/attachment.pl>

From gregor.kastner at wu.ac.at  Wed Apr  2 08:43:10 2014
From: gregor.kastner at wu.ac.at (Gregor Kastner)
Date: Wed, 2 Apr 2014 08:43:10 +0200
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUD3nJj_1zq3J3=7ERNtXRPF0QqMU2Ut52H5wzRnzF1XCw@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
	<CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>
	<CAPPM_gQfD=dvC-6ez=VORgZ_nNsJKCPuuyH0nrQBYMB7R=KgYA@mail.gmail.com>
	<CAGSjAUD3nJj_1zq3J3=7ERNtXRPF0QqMU2Ut52H5wzRnzF1XCw@mail.gmail.com>
Message-ID: <20140402084310.7b148d77@mine>

Hi Sandip,

> Sorry for the wrong interpretation. So how to avoid that ? I mean how to
> forcefully make it character vector ?

As indicated by Joshua, ?data.frame will show you the way:

df <- data.frame(gender, age, stringsAsFactors = FALSE)
 
Best,
/g


From romain at r-enthusiasts.com  Wed Apr  2 08:52:22 2014
From: romain at r-enthusiasts.com (=?iso-8859-1?Q?Romain_Fran=E7ois?=)
Date: Wed, 2 Apr 2014 08:52:22 +0200
Subject: [Rd] special handling of row.names
Message-ID: <2A6423DA-C7AE-479C-A594-E15DECD5328F@r-enthusiasts.com>

Hello, 

I think there is an inconsistency in the handling of the compact form of the row.names attributes. 

When n is the number of rows of a data.frame, the compact form is c(NA_integer_,-n), as in: 

> d <- data.frame(x=1:10)
> .Internal(inspect(d))
@104f174a8 19 VECSXP g0c1 [OBJ,NAM(2),ATT] (len=1, tl=0)
  @103a7dc60 13 INTSXP g0c4 [] (len=10, tl=0) 1,2,3,4,5,...
ATTRIB:
  @104959380 02 LISTSXP g0c0 []
    TAG: @100823078 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "names" (has value)
    @104f17748 16 STRSXP g0c1 [NAM(2)] (len=1, tl=0)
      @10085c678 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "x"
    TAG: @10082d060 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "row.names" (has value)
    @104f0e898 13 INTSXP g0c1 [] (len=2, tl=0) -2147483648,-10
    TAG: @100823548 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "class" (has value)
    @104f0e8c8 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @1008a7e60 09 CHARSXP g1c2 [MARK,gp=0x61,ATT] [ASCII] [cached] "data.frame"

But then, -10 becomes 10: 

> d2 <- structure( d, class = "data.frame" )
> .Internal(inspect(d2))
@104f08898 19 VECSXP g0c1 [OBJ,NAM(2),ATT] (len=1, tl=0)
  @103a7dc60 13 INTSXP g0c4 [NAM(2)] (len=10, tl=0) 1,2,3,4,5,...
ATTRIB:
  @104956150 02 LISTSXP g0c0 []
    TAG: @100823078 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "names" (has value)
    @104f087a8 16 STRSXP g0c1 [] (len=1, tl=0)
      @10085c678 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "x"
    TAG: @10082d060 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "row.names" (has value)
    @104f088c8 13 INTSXP g0c1 [] (len=2, tl=0) -2147483648,10
    TAG: @100823548 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "class" (has value)
    @104f08838 16 STRSXP g0c1 [] (len=1, tl=0)
      @1008a7e60 09 CHARSXP g1c2 [MARK,gp=0x61,ATT] [ASCII] [cached] "data.frame"

This happens in row_names_gets (attrib.c), here: 

	if(OK_compact) {
	    /* we hide the length in an impossible integer vector */
	    PROTECT(val = allocVector(INTSXP, 2));
	    INTEGER(val)[0] = NA_INTEGER;
	    INTEGER(val)[1] = n;
	    ans =  installAttrib(vec, R_RowNamesSymbol, val);
	    UNPROTECT(1);
	    return ans;
	}

I believe it should be INTEGER(val)[1] = -n; for consistency. 



BTW, perhaps structure should be internalized to prevent special handling of row.names when it does not make sense. Here is structure: 

structure
function (.Data, ...)
{
    attrib <- list(...)
    if (length(attrib)) {
        specials <- c(".Dim", ".Dimnames", ".Names", ".Tsp",
            ".Label")
        replace <- c("dim", "dimnames", "names", "tsp", "levels")
        m <- match(names(attrib), specials)
        ok <- (!is.na(m) & m)
        names(attrib)[ok] <- replace[m[ok]]
        if ("factor" %in% attrib[["class", exact = TRUE]] &&
            typeof(.Data) == "double")
            storage.mode(.Data) <- "integer"
        attributes(.Data) <- c(attributes(.Data), attrib)
    }
    return(.Data)
}

When I do structure( d, class = "data.frame" ), eventually this line is executed: 

attributes(.Data) <- c(attributes(.Data), attrib)

So, first attributes are retrieved, and because of R special handling of row.names, it gets promoted to 1:n in getAttrib. 

Then, we want to set the row.names attribute, special handling again in setAttrib, leading to row_names_gets, R actually loops over the attribute to check if it is of the form 1:n, and if it is it brings back the compact form (making a mistake along the way). 

This looks like a waste of resources. 

Romain

From maechler at stat.math.ethz.ch  Wed Apr  2 11:26:42 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Apr 2014 11:26:42 +0200
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUD3nJj_1zq3J3=7ERNtXRPF0QqMU2Ut52H5wzRnzF1XCw@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<CAPPM_gRmK3Xh0SLPAc5avbWzgjRdOrYSZApQLqaxqBeOTiXiiw@mail.gmail.com>
	<CAGSjAUCrBD7_qcoieJMZSeKD_CfFs+euE5PFQEW7iKoSViUrrw@mail.gmail.com>
	<CAPPM_gQfD=dvC-6ez=VORgZ_nNsJKCPuuyH0nrQBYMB7R=KgYA@mail.gmail.com>
	<CAGSjAUD3nJj_1zq3J3=7ERNtXRPF0QqMU2Ut52H5wzRnzF1XCw@mail.gmail.com>
Message-ID: <21307.55250.843515.553561@stat.math.ethz.ch>

PLEASE! 
All this does *not* belong to the R-devel mailing list.

It is entirely apt for R-help (or "similar", including stackoverflow).

Please do *not* misuse R-devel for basic R questions.

Martin Maechler,
ETH Zurich


From mrjefftoyou at gmail.com  Wed Apr  2 02:51:28 2014
From: mrjefftoyou at gmail.com (Jeff Johnson)
Date: Tue, 1 Apr 2014 17:51:28 -0700
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
Message-ID: <D4D4BDC9-394C-489B-83C1-E158E93D0EB3@gmail.com>

Perhaps because indexes start at 0?

Sent from my iPhone

> On Apr 1, 2014, at 5:46 PM, Sandip Nandi <sannandi at umail.iu.edu> wrote:
> 
> Hi ,
> 
> I want to know is this behavior expected and why is that ? Need some help
> 
> gender <- c("F", "M", "M", "F", "F", "M", "F", "F")
>> age    <- c(23, 25, 27, 29, 31, 33, 35, 37)
>> df<- data.frame(gender,age)
>> typeof(df[[1]])
> [1] "integer"   >>>>>>>>>>>>>  Why is this integer . *Should not it be
> character ?*
>> typeof(df[[2]])
> [1] "double"
> 
>> typeof(gender)
> [1] "character"
>> typeof(age)
> [1] "double"
> 
> In my code i am trying to do some thing based on typeof and the type for
> character column is strange.
> 
> Thanks,
> Sandip
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Wed Apr  2 11:34:42 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 2 Apr 2014 11:34:42 +0200
Subject: [Rd] Typeof for character vector in dataframe returns integer
In-Reply-To: <CAGSjAUACYg5eGQqPY6+vzaDB_hFfjzUZgm9B1mqzbOeh0NLodA@mail.gmail.com>
References: <CAGSjAUCx7B3_vavmXQrQTtgAF1BO03YZXuutE3hdb7rJcjfS3Q@mail.gmail.com>
	<D4D4BDC9-394C-489B-83C1-E158E93D0EB3@gmail.com>
	<CAGSjAUACYg5eGQqPY6+vzaDB_hFfjzUZgm9B1mqzbOeh0NLodA@mail.gmail.com>
Message-ID: <CAO1zAVa+7RufuRfYEn5LXewtorkqi0wO2doeA_=pHsythQ7TEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140402/03a7a16e/attachment.pl>

From adamwelc at yahoo.com  Thu Apr  3 00:11:28 2014
From: adamwelc at yahoo.com (Adam Welc)
Date: Wed, 2 Apr 2014 15:11:28 -0700
Subject: [Rd] inconsistent error messages on Mac OS X
Message-ID: <CABzWa1dqJKxUf_vYt-pwzvxDH_iYpecBy_R-JegJ7jk3iqstFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140402/0105768d/attachment.pl>

From dtenenba at fhcrc.org  Thu Apr  3 00:32:22 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 2 Apr 2014 15:32:22 -0700 (PDT)
Subject: [Rd] inconsistent error messages on Mac OS X
In-Reply-To: <CABzWa1dqJKxUf_vYt-pwzvxDH_iYpecBy_R-JegJ7jk3iqstFg@mail.gmail.com>
Message-ID: <1280702641.1261952.1396477942331.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "Adam Welc" <adamwelc at yahoo.com>
> To: r-devel at r-project.org
> Sent: Wednesday, April 2, 2014 3:11:28 PM
> Subject: [Rd] inconsistent error messages on Mac OS X
> 
> Hi All,
> 
> I am one of the contributors to the FastR project (
> https://bitbucket.org/allr <https://bitbucket.org/allr.>) and I have
> encountered an interesting issue when trying to implement vector
> accesses
> within FastR. I am trying to understand what kind of error message
> should
> be generated for the following expression:
> 
> x<-1:4; x[[1]]<-NULL; x
> 
> In order to determine the error message, I ran the shell of standard
> GNU R
> (installed via MacPorts - R version 2.15.3) on Mac OS X 10.8.5 as
> follows,
> with R metadata (that is .RData or .Rhistory files) removed from the
> current directory 

Instead you should probably start R as follows:

R --vanilla

?Startup explains why removing .RData etc from the current directory is not enough, in the absence of --vanilla.

>(I have edited portions of the R header printed
> when the
> shell starts for the sake for readability):
> 
> Adams-MacBook-Air:work adam$ R
> 
> R version 2.15.3 (2013-03-01) -- "Security Blanket"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-apple-darwin12.3.0/x86_64 (64-bit)
> ...
> ...
> Type 'q()' to quit R.
> 
> > x<-1:4; x[[1]]<-NULL; x
> Error in x[[1]] <- NULL :
>   incompatible types (from NULL to integer) in [[ assignment
> > q()
> Save workspace image? [y/n/c]: n
> 
> 
> Adams-MacBook-Air:work adam$ R
> 
> R version 2.15.3 (2013-03-01) -- "Security Blanket"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-apple-darwin12.3.0/x86_64 (64-bit)
> ...
> ...
> Type 'q()' to quit R.
> 
> > x<-1:4; x[[1]]<-NULL; x
> Error in x[[1]] <- NULL :
>   more elements supplied than there are to replace
> >
> 
> 
> As you can see, the error message for the same expression is
> different on
> two subsequent executions of the GNU R shell (with no workspace image
> saving - but it does not matter, as I observe the same behavior if
> the
> workspace is saved).
> 
> I tried the same thing on Linux, but there the behavior seems
> consistent
> (the second message is displayed in each execution).
> 
> This issue is not specific to this single expression - it happens in
> other
> (though not all) cases when the NULL value is assigned to an element
> of a
> vector.
> 
> I was wondering if someone has observed the same behavior and perhaps
> knows
> what may be causing it...
> 

I can't reproduce this on 
R Under development (unstable) (2013-10-12 r64048)

with or without --vanilla, it consistently gives the second error message.

Dan


> Thank you
> 
> Adam
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sannandi at umail.iu.edu  Thu Apr  3 07:40:39 2014
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Wed, 2 Apr 2014 22:40:39 -0700
Subject: [Rd] question regarding lang2 command in C
Message-ID: <CAGSjAUDyGryZ1VCWug1Vj51D6x8rpeQAurw-j2XprUN+O7vEQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140402/11bd2404/attachment.pl>

From romain at r-enthusiasts.com  Thu Apr  3 08:25:26 2014
From: romain at r-enthusiasts.com (=?iso-8859-1?Q?Romain_Fran=E7ois?=)
Date: Thu, 3 Apr 2014 08:25:26 +0200
Subject: [Rd] question regarding lang2 command in C
In-Reply-To: <CAGSjAUDyGryZ1VCWug1Vj51D6x8rpeQAurw-j2XprUN+O7vEQg@mail.gmail.com>
References: <CAGSjAUDyGryZ1VCWug1Vj51D6x8rpeQAurw-j2XprUN+O7vEQg@mail.gmail.com>
Message-ID: <511A0950-AA68-4557-9C70-07D51E5A1732@r-enthusiasts.com>

Hi, 

This is easy if the gender and age are already vectors of some sort of the same size. 

SEXP df = PROTECT(allocVector(VECSXP, 2)); 
SET_VECTOR_ELT(df,0,gender) ;
SET_VECTOR_ELT(df,1,age) ;
SEXP names = PROTECT(allocVector(STRSXP,2));
SET_STRING_ELT(names,0,mkChar("age"))
SET_STRING_ELT(names,0,mkChar("gender"))
setAttrib(df, R_NamesSymbol, names );
setAttrib(df, R_ClassSymbol, mkString("data.frame"));
SEXP rn = PROTECT(allocVector(INTSXP,2)); 
INTEGER(rn)[0] = NA_INTEGER ;
INTEGER(rn)[1] = -length(gender);
setAttrib(df, R_RowNamesSymbol, rn) ;
UNPROTECT(3) ;
return df ;

If you really want to call back to R and make a call as you did before, you can do something like this: 

  SEXP call = PROTECT(lang4(install("data.frame"), age, gender, ScalarLogical(FALSE))) ;
  SET_TAG(CDR(call), install("age")) ;
  SET_TAG(CDDR(call), install("gender")) ;
  SET_TAG(CDR(CDDR(call)), install("stringsAsFactors")) ;
  SEXP df = PROTECT(eval(call, R_GlobalEnv)) ;
  UNPROTECT(2) ;
  return df ;

Or you can use Rcpp: 

  DataFrame df = DataFrame::create(
    _["age"] = age, _["gender"] = gender, _["stringsAsFactors"] = FALSE
  ) ;

Romain

Le 3 avr. 2014 ? 07:40, Sandip Nandi <sannandi at umail.iu.edu> a ?crit :

> Hi ,
> 
> I am asking too many questions , sorry for that .  I am creating a data
> frame in C itself , reading a table .
> 
> The data frame calling code looks like this
> ======================================
> 
> *PROTECT(dfm=lang2(install("data.frame"),df));*
> *SEXP res = PROTECT(eval(dfm,R_GlobalEnv));*
> 
> UNPROTECT(2);
> return res;
> ==================================
> 
> It works fine , now the problem is I want to do the below one  from C
> itself  ( adding the *stringsAsFactors = FALSE* parameter)
> 
> df <- data.frame(gender, age, *stringsAsFactors = FALSE*);
> 
> How can I do it from C , adding extra parameters. Anyone has pointer or any
> example . It will be great help. I find the arguments will always be in
> pair , i don't find any example.
> 
> 
> I try to see the source code ,not able to make it
> 
> Thanks


From Thierry.ONKELINX at inbo.be  Thu Apr  3 12:09:16 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 3 Apr 2014 10:09:16 +0000
Subject: [Rd] summary of lme4.0 model in package
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>

Dear all,

My package has Depends: lme4.0 in the DESCRIPTION. I need to extract the fixed effect of a model and their standard errors. I use coef(summary(model)) inside a function to do that. Model is the output of a call to glmer() from the lme4.0 package.

coef(summary(model)) throws an error: $ operator is invalid for atomic vectors

I have tracked it down to a problem with summary(model) because str(summary(model)) gives this

Classes 'summaryDefault', 'table'  Named chr [1:3] "1" "mer" "S4"
  ..- attr(*, "names")= chr [1:3] "Length" "Class" "Mode"

But it should return

Formal class 'summary.mer' [package "lme4.0"] with 42 slots
  ..@ methTitle: chr "Generalized linear mixed model fit by the Laplace approximation"
  ..@ logLik   :Class 'logLik' : -2265 (df=12)
--- output snipped ---

What puzzles me is that the function gives the error when called from the package, but works fine when I source the code of the function manually.

#this fails
MyPackage:MyFunction(model)
#this works
source("MyPackage/R/MyFunction.R")
MyFunction(model)

Any idea on what is going wrong and how to fix this?

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sendmailR_1.1-2   base64enc_0.1-1   ABV_0.2-21        lme4.0_0.999999-4 lattice_0.20-28   Matrix_1.1-3

loaded via a namespace (and not attached):
 [1] AFLP_0.4.0-66       colorspace_1.2-4    dichromat_2.0-0     digest_0.6.4        Epi_1.1.63
 [6] fortunes_1.5-2      ggplot2_0.9.3.1.99  grid_3.0.2          gridExtra_0.9.1     gtable_0.1.2
[11] labeling_0.2        lme4_1.1-5          lubridate_1.3.3     MASS_7.3-30         memoise_0.1
[16] mgcv_1.7-28         minqa_1.2.3         multcomp_1.3-2      munsell_0.4.2       mvtnorm_0.9-9997
[21] nlme_3.1-115        permute_0.8-3       plyr_1.8.1          proto_0.3-10        RColorBrewer_1.0-5
[26] Rcpp_0.11.1         RcppEigen_0.3.2.1.1 reshape_0.8.4       reshape2_1.2.2      RODBC_1.3-10
[31] sandwich_2.3-0      scales_0.2.3        seqinr_3.0-9        signal_0.7-3        splines_3.0.2
[36] stats4_3.0.2        stringr_0.6.2       survival_2.37-7     TH.data_1.0-3       tools_3.0.2
[41] vegan_2.1-41        watervogels_0.5-51  xtable_1.7-3        zoo_1.7-11


Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From jwiley.psych at gmail.com  Thu Apr  3 12:35:45 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 Apr 2014 03:35:45 -0700
Subject: [Rd] summary of lme4.0 model in package
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
Message-ID: <CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/1c2134d4/attachment.pl>

From jon.clayden at gmail.com  Thu Apr  3 13:24:30 2014
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 3 Apr 2014 12:24:30 +0100
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
Message-ID: <CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/f194c5b6/attachment.pl>

From bodenhofer at bioinf.jku.at  Thu Apr  3 13:33:23 2014
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Thu, 03 Apr 2014 13:33:23 +0200
Subject: [Rd] [Bioc-devel] Conflicting definitions for function
 redefined as S4 generics
In-Reply-To: <5334605D.5080809@fhcrc.org>
References: <5332B958.5020703@bioinf.jku.at>	<CAOQ5NyfQ8eFc2mLODPR-FB=71UuUjVZjz4srfmRSj-TOJBNmOQ@mail.gmail.com>	<CADwqtCOPEtXcj_06=PGnrEBMOkyag+KonAM9WKiunL2M8WYp5w@mail.gmail.com>	<CAOQ5Nye=K4ekaJ=yYXX69MdddHMNLXtg5yxtrsmfSO_gkZrzvA@mail.gmail.com>
	<5333EBBB.80007@bioinf.jku.at> <5334605D.5080809@fhcrc.org>
Message-ID: <533D4703.8070705@bioinf.jku.at>

On 03/27/2014 06:31 PM, Herv? Pag?s wrote:
> On 03/27/2014 02:13 AM, Ulrich Bodenhofer wrote:
>> [...]
>>
>> For the time being, it seems I have three options:
>>
>> 1) not supplying the sort() function yet (it is not yet in the release,
>> but only in my internal devel version)
>> 2) including a dependency to BiocGenerics
>> 3) leaving the problem open, mentioning in the documentation that users
>> who want to use apcluster in conjunction with Bioconductor should load
>> BiocGenerics first
>
> 4) define an S3 method, as mentioned in my previous post
>
> H.
>
After a while, I came back to this suggestion. Thanks, Herv?! I now 
tried it and it indeed works smoothly: all problems I mentioned - as you 
expected correctly - are resolved. It seems that BiocGenerics screws up 
my previously defined S4 generic, but leaves my S3 function untouched. 
Hmm ...

The question is whether it is good style to use S3 and S4 together. 
Actually I am reluctant to think so, but if it helps and creates no 
other problems whatsoever, why not?

Cheers,
Ulrich


From Thierry.ONKELINX at inbo.be  Thu Apr  3 13:44:12 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 3 Apr 2014 11:44:12 +0000
Subject: [Rd] summary of lme4.0 model in package
In-Reply-To: <CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
	<CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A21E24@inbomail.inbo.be>

Dear Joshua,

Thank you for quick reply.

Note that my package has Depends: lme4.0 in DESCRIPTION. It imports and suggests other packages but not lme4. lme4_1.1-5 is attached because my package imports (via Imports: in DESCRIPTION) functions from package A, which imports (via Imports: in DESCRIPTION) functions from package B, which imports (via Imports: in DESCRIPTION) functions from lme4. Neither packages A nor B import lme4 related functions.

Should try to import lme4.0 instead of depending on it?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Joshua Wiley [mailto:jwiley.psych at gmail.com]
Verzonden: donderdag 3 april 2014 12:36
Aan: ONKELINX, Thierry
CC: r-devel at r-project.org
Onderwerp: Re: [Rd] summary of lme4.0 model in package

Dear Thierry,

You have lme4.0_0.999999-4 attached and  lme4_1.1-5 loaded via a namespace.  I wonder if changes between the versions and which was getting called when are making the difference.  In particular, when you source it, I would assume methods from the attached package are used.  When you use the function from the package, the methods from the dependencies for the package would be used.

Cheers,

Josh



On Thu, Apr 3, 2014 at 3:09 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
Dear all,

My package has Depends: lme4.0 in the DESCRIPTION. I need to extract the fixed effect of a model and their standard errors. I use coef(summary(model)) inside a function to do that. Model is the output of a call to glmer() from the lme4.0 package.

coef(summary(model)) throws an error: $ operator is invalid for atomic vectors

I have tracked it down to a problem with summary(model) because str(summary(model)) gives this

Classes 'summaryDefault', 'table'  Named chr [1:3] "1" "mer" "S4"
  ..- attr(*, "names")= chr [1:3] "Length" "Class" "Mode"

But it should return

Formal class 'summary.mer' [package "lme4.0"] with 42 slots
  ..@ methTitle: chr "Generalized linear mixed model fit by the Laplace approximation"
  ..@ logLik   :Class 'logLik' : -2265 (df=12)
--- output snipped ---

What puzzles me is that the function gives the error when called from the package, but works fine when I source the code of the function manually.

#this fails
MyPackage:MyFunction(model)
#this works
source("MyPackage/R/MyFunction.R")
MyFunction(model)

Any idea on what is going wrong and how to fix this?

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sendmailR_1.1-2   base64enc_0.1-1   ABV_0.2-21        lme4.0_0.999999-4 lattice_0.20-28   Matrix_1.1-3

loaded via a namespace (and not attached):
 [1] AFLP_0.4.0-66       colorspace_1.2-4    dichromat_2.0-0     digest_0.6.4        Epi_1.1.63
 [6] fortunes_1.5-2      ggplot2_0.9.3.1.99  grid_3.0.2          gridExtra_0.9.1     gtable_0.1.2
[11] labeling_0.2        lme4_1.1-5          lubridate_1.3.3     MASS_7.3-30         memoise_0.1
[16] mgcv_1.7-28         minqa_1.2.3         multcomp_1.3-2      munsell_0.4.2       mvtnorm_0.9-9997
[21] nlme_3.1-115        permute_0.8-3       plyr_1.8.1          proto_0.3-10        RColorBrewer_1.0-5
[26] Rcpp_0.11.1         RcppEigen_0.3.2.1.1 reshape_0.8.4       reshape2_1.2.2      RODBC_1.3-10
[31] sandwich_2.3-0      scales_0.2.3        seqinr_3.0-9        signal_0.7-3        splines_3.0.2
[36] stats4_3.0.2        stringr_0.6.2       survival_2.37-7     TH.data_1.0-3       tools_3.0.2
[41] vegan_2.1-41        watervogels_0.5-51  xtable_1.7-3        zoo_1.7-11


Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel




--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com
260.673.5518
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From lawrence.michael at gene.com  Thu Apr  3 14:19:19 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 3 Apr 2014 05:19:19 -0700
Subject: [Rd] [Bioc-devel] Conflicting definitions for function
 redefined as S4 generics
In-Reply-To: <533D4703.8070705@bioinf.jku.at>
References: <5332B958.5020703@bioinf.jku.at>
	<CAOQ5NyfQ8eFc2mLODPR-FB=71UuUjVZjz4srfmRSj-TOJBNmOQ@mail.gmail.com>
	<CADwqtCOPEtXcj_06=PGnrEBMOkyag+KonAM9WKiunL2M8WYp5w@mail.gmail.com>
	<CAOQ5Nye=K4ekaJ=yYXX69MdddHMNLXtg5yxtrsmfSO_gkZrzvA@mail.gmail.com>
	<5333EBBB.80007@bioinf.jku.at> <5334605D.5080809@fhcrc.org>
	<533D4703.8070705@bioinf.jku.at>
Message-ID: <CAOQ5NydFZ4RiuXerRLwGL+3mWWN51oHsK6GNZuZ=GoMMLnUUvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/73be787c/attachment.pl>

From pdalgd at gmail.com  Thu Apr  3 14:27:55 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 3 Apr 2014 14:27:55 +0200
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
Message-ID: <391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>

I'm seeing nothing of the sort with the nightly build of 3.1.0RC, also on 10.9.2. This is a plain-vanilla Xcode+ancillaries build as per Simon's instructions (I think):

pd$ more config.site 
r_arch=${r_arch:=x86_64}
CC="gcc -arch $r_arch"
CXX="g++ -arch $r_arch"
F77="gfortran -arch $r_arch"
FC="gfortran -arch $r_arch"
OBJC="gcc -arch $r_arch"
with_blas="-framework vecLib"
with_lapack=yes

so either something is up specifically with gcc-4.8, or you managed to hose your time zone data base somehow (/usr/share/zoneinfo, I suppose).

- Peter D.

On 03 Apr 2014, at 13:24 , Jon Clayden <jon.clayden at gmail.com> wrote:

> For what it's worth, this issue persists in R-rc_2014-04-02_r65358.
> 
> Regards,
> Jon
> 
> 
> On 24 March 2014 10:40, Jon Clayden <jon.clayden at gmail.com> wrote:
> 
>> Dear all,
>> 
>> As of the current R alpha release, I'm seeing timezone-related warnings on
>> installing any package (including the recommended ones), which I haven't
>> seen before. For example,
>> 
>> [~/Documents/Source/R-alpha]$ bin/R CMD INSTALL ~/git/tractor/lib/reportr
>> * installing to library '/Users/jon/Documents/Source/R-alpha/library'
>> * installing *source* package 'reportr' ...
>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>> Warning in as.POSIXlt.POSIXct(x, tz) :
>>  unknown timezone 'America/New_York'
>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>> Warning in as.POSIXlt.POSIXct(x, tz) :
>>  unknown timezone 'America/New_York'
>> ** R
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (reportr)
>> 
>> This is R-alpha r65266, built from source on OS X 10.9.2 using gcc 4.8.2.
>> I ran configure with
>> 
>> ./configure --with-blas="-framework Accelerate" --with-lapack
>> --with-system-zlib --enable-memory-profiling
>> --with-tcl-config=/System/Library/Frameworks/Tcl.framework/tclConfig.sh
>> --with-tk-config=/System/Library/Frameworks/Tk.framework/tkConfig.sh
>> CC=gcc-4.8 CXX=g++-4.8 OBJC=clang F77=gfortran-4.8 FC=gfortran-4.8
>> CPPFLAGS="-D__ACCELERATE__" CFLAGS="-mtune=native -g -O2"
>> CXXFLAGS="-mtune=native -g -O2" FFLAGS="-mtune=native -g -O2"
>> FCFLAGS="-mtune=native -g -O2"
>> 
>> Session info is
>> 
>> R version 3.1.0 alpha (2014-03-23 r65266)
>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>> 
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> I see some related material in the NEWS, but no indication that these
>> warnings are expected. I hope this report is helpful.
>> 
>> All the best,
>> Jon
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From edd at debian.org  Thu Apr  3 14:32:38 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 3 Apr 2014 07:32:38 -0500
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
Message-ID: <21309.21734.211169.441@max.nulle.part>


On 3 April 2014 at 12:24, Jon Clayden wrote:
| For what it's worth, this issue persists in R-rc_2014-04-02_r65358.

I'm running a beta version on Ubuntu and do not see this, neither on INSTALL
or check during package development nor during normal use:

R> R.version
               _                                       
platform       x86_64-pc-linux-gnu                     
arch           x86_64                                  
os             linux-gnu                               
system         x86_64, linux-gnu                       
status         beta                                    
major          3                                       
minor          1.0                                     
year           2014                                    
month          03                                      
day            28                                      
svn rev        65330                                   
language       R                                       
version.string R version 3.1.0 beta (2014-03-28 r65330)
nickname       Spring Dance                            
R> format(Sys.time())
[1] "2014-04-03 07:30:17.171488"
R> format(Sys.time(), tz="America/New_York")
[1] "2014-04-03 08:30:28.771662"
R> format(Sys.time(), tz="Europe/Berlin")
[1] "2014-04-03 14:30:41.211835"
R> Sys.getenv("TZ")
[1] ""
R> 

As you can see, I do not set a TZ variable and things work here.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ripley at stats.ox.ac.uk  Thu Apr  3 14:38:23 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 03 Apr 2014 13:38:23 +0100
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
	<391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
Message-ID: <533D563F.6030305@stats.ox.ac.uk>

On 03/04/2014 13:27, peter dalgaard wrote:
> I'm seeing nothing of the sort with the nightly build of 3.1.0RC, also on 10.9.2. This is a plain-vanilla Xcode+ancillaries build as per Simon's instructions (I think):
>
> pd$ more config.site
> r_arch=${r_arch:=x86_64}
> CC="gcc -arch $r_arch"
> CXX="g++ -arch $r_arch"
> F77="gfortran -arch $r_arch"
> FC="gfortran -arch $r_arch"
> OBJC="gcc -arch $r_arch"
> with_blas="-framework vecLib"
> with_lapack=yes
>
> so either something is up specifically with gcc-4.8, or you managed to hose your time zone data base somehow (/usr/share/zoneinfo, I suppose).

More likely the one shipping with R, since --with-internal-tzcode is the 
default on OS X [*].  Setting TZDIR incorrectly would do this:

 > Sys.time()
[1] "2014-04-03 12:37:01 GMT"
Warning messages:
1: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
2: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'America/New_York'

when I do that.

You could try --without-internal-tzcode.

[*] Although x86_64 OS X has a 64-bit time_t it seems to have a 32-bit 
time-zone database and so wraps around.


> - Peter D.
>
> On 03 Apr 2014, at 13:24 , Jon Clayden <jon.clayden at gmail.com> wrote:
>
>> For what it's worth, this issue persists in R-rc_2014-04-02_r65358.
>>
>> Regards,
>> Jon
>>
>>
>> On 24 March 2014 10:40, Jon Clayden <jon.clayden at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> As of the current R alpha release, I'm seeing timezone-related warnings on
>>> installing any package (including the recommended ones), which I haven't
>>> seen before. For example,
>>>
>>> [~/Documents/Source/R-alpha]$ bin/R CMD INSTALL ~/git/tractor/lib/reportr
>>> * installing to library '/Users/jon/Documents/Source/R-alpha/library'
>>> * installing *source* package 'reportr' ...
>>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
>>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>>> Warning in as.POSIXlt.POSIXct(x, tz) :
>>>   unknown timezone 'America/New_York'
>>> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>>> Warning in as.POSIXlt.POSIXct(x, tz) :
>>>   unknown timezone 'America/New_York'
>>> ** R
>>> ** preparing package for lazy loading
>>> ** help
>>> *** installing help indices
>>> ** building package indices
>>> ** testing if installed package can be loaded
>>> * DONE (reportr)
>>>
>>> This is R-alpha r65266, built from source on OS X 10.9.2 using gcc 4.8.2.
>>> I ran configure with
>>>
>>> ./configure --with-blas="-framework Accelerate" --with-lapack
>>> --with-system-zlib --enable-memory-profiling
>>> --with-tcl-config=/System/Library/Frameworks/Tcl.framework/tclConfig.sh
>>> --with-tk-config=/System/Library/Frameworks/Tk.framework/tkConfig.sh
>>> CC=gcc-4.8 CXX=g++-4.8 OBJC=clang F77=gfortran-4.8 FC=gfortran-4.8
>>> CPPFLAGS="-D__ACCELERATE__" CFLAGS="-mtune=native -g -O2"
>>> CXXFLAGS="-mtune=native -g -O2" FFLAGS="-mtune=native -g -O2"
>>> FCFLAGS="-mtune=native -g -O2"
>>>
>>> Session info is
>>>
>>> R version 3.1.0 alpha (2014-03-23 r65266)
>>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>>>
>>> locale:
>>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> I see some related material in the NEWS, but no indication that these
>>> warnings are expected. I hope this report is helpful.
>>>
>>> All the best,
>>> Jon
>>>
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jon.clayden at gmail.com  Thu Apr  3 14:47:40 2014
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 3 Apr 2014 13:47:40 +0100
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <533D563F.6030305@stats.ox.ac.uk>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
	<391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
	<533D563F.6030305@stats.ox.ac.uk>
Message-ID: <CAM9CR=2FJmy9p1b8RdfXLQTnJ67eyqei_Y40jUgN-bGpfEDBQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/f0303fa2/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Apr  3 14:55:07 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 3 Apr 2014 12:55:07 +0000
Subject: [Rd] summary of lme4.0 model in package
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
	<CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com> 
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A22175@inbomail.inbo.be>

An update: I copied the functions from package A into MyPackage instead of importing them. This avoids lme4_1.1-5 to be loaded via namespace (see sessionInfo). However, the error remains. Nlme is loaded via namespace by lme4.0

R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sendmailR_1.1-2   base64enc_0.1-1   ABV_0.2-21        lme4.0_0.999999-4 lattice_0.20-28   Matrix_1.1-3

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.4       fortunes_1.5-2     ggplot2_0.9.3.1.99 grid_3.0.2
 [7] gridExtra_0.9.1    gtable_0.1.2       labeling_0.2       lubridate_1.3.3    MASS_7.3-30        memoise_0.1
[13] multcomp_1.3-2     munsell_0.4.2      mvtnorm_0.9-9997   nlme_3.1-115       plyr_1.8.1         proto_0.3-10
[19] RColorBrewer_1.0-5 Rcpp_0.11.1        reshape2_1.2.2     RODBC_1.3-10       sandwich_2.3-0     scales_0.2.3
[25] splines_3.0.2      stats4_3.0.2       stringr_0.6.2      survival_2.37-7    TH.data_1.0-3      tools_3.0.2
[31] zoo_1.7-11

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: ONKELINX, Thierry
Verzonden: donderdag 3 april 2014 13:44
Aan: 'Joshua Wiley'
CC: r-devel at r-project.org
Onderwerp: RE: [Rd] summary of lme4.0 model in package

Dear Joshua,

Thank you for quick reply.

Note that my package has Depends: lme4.0 in DESCRIPTION. It imports and suggests other packages but not lme4. lme4_1.1-5 is attached because my package imports (via Imports: in DESCRIPTION) functions from package A, which imports (via Imports: in DESCRIPTION) functions from package B, which imports (via Imports: in DESCRIPTION) functions from lme4. Neither packages A nor B import lme4 related functions.

Should try to import lme4.0 instead of depending on it?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: Joshua Wiley [mailto:jwiley.psych at gmail.com]
Verzonden: donderdag 3 april 2014 12:36
Aan: ONKELINX, Thierry
CC: r-devel at r-project.org
Onderwerp: Re: [Rd] summary of lme4.0 model in package

Dear Thierry,

You have lme4.0_0.999999-4 attached and  lme4_1.1-5 loaded via a namespace.  I wonder if changes between the versions and which was getting called when are making the difference.  In particular, when you source it, I would assume methods from the attached package are used.  When you use the function from the package, the methods from the dependencies for the package would be used.

Cheers,

Josh



On Thu, Apr 3, 2014 at 3:09 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
Dear all,

My package has Depends: lme4.0 in the DESCRIPTION. I need to extract the fixed effect of a model and their standard errors. I use coef(summary(model)) inside a function to do that. Model is the output of a call to glmer() from the lme4.0 package.

coef(summary(model)) throws an error: $ operator is invalid for atomic vectors

I have tracked it down to a problem with summary(model) because str(summary(model)) gives this

Classes 'summaryDefault', 'table'  Named chr [1:3] "1" "mer" "S4"
  ..- attr(*, "names")= chr [1:3] "Length" "Class" "Mode"

But it should return

Formal class 'summary.mer' [package "lme4.0"] with 42 slots
  ..@ methTitle: chr "Generalized linear mixed model fit by the Laplace approximation"
  ..@ logLik   :Class 'logLik' : -2265 (df=12)
--- output snipped ---

What puzzles me is that the function gives the error when called from the package, but works fine when I source the code of the function manually.

#this fails
MyPackage:MyFunction(model)
#this works
source("MyPackage/R/MyFunction.R")
MyFunction(model)

Any idea on what is going wrong and how to fix this?

sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252    LC_MONETARY=Dutch_Belgium.1252 [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sendmailR_1.1-2   base64enc_0.1-1   ABV_0.2-21        lme4.0_0.999999-4 lattice_0.20-28   Matrix_1.1-3

loaded via a namespace (and not attached):
 [1] AFLP_0.4.0-66       colorspace_1.2-4    dichromat_2.0-0     digest_0.6.4        Epi_1.1.63
 [6] fortunes_1.5-2      ggplot2_0.9.3.1.99  grid_3.0.2          gridExtra_0.9.1     gtable_0.1.2 [11] labeling_0.2        lme4_1.1-5          lubridate_1.3.3     MASS_7.3-30         memoise_0.1 [16] mgcv_1.7-28         minqa_1.2.3         multcomp_1.3-2      munsell_0.4.2       mvtnorm_0.9-9997 [21] nlme_3.1-115        permute_0.8-3       plyr_1.8.1          proto_0.3-10        RColorBrewer_1.0-5 [26] Rcpp_0.11.1         RcppEigen_0.3.2.1.1 reshape_0.8.4       reshape2_1.2.2      RODBC_1.3-10 [31] sandwich_2.3-0      scales_0.2.3        seqinr_3.0-9        signal_0.7-3        splines_3.0.2 [36] stats4_3.0.2        stringr_0.6.2       survival_2.37-7     TH.data_1.0-3       tools_3.0.2 [41] vegan_2.1-41        watervogels_0.5-51  xtable_1.7-3        zoo_1.7-11


Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel




--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com
260.673.5518
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From jorismeys at gmail.com  Thu Apr  3 15:17:51 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 3 Apr 2014 15:17:51 +0200
Subject: [Rd] summary of lme4.0 model in package
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3A22175@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
	<CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3A22175@inbomail.inbo.be>
Message-ID: <CAO1zAVb_7GmzVTgfV4aVew5YZdBJtKUCDPfnvtmPtnj80gcScw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/9f063b3c/attachment.pl>

From pdalgd at gmail.com  Thu Apr  3 15:39:00 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 3 Apr 2014 15:39:00 +0200
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <CAM9CR=2FJmy9p1b8RdfXLQTnJ67eyqei_Y40jUgN-bGpfEDBQg@mail.gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
	<391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
	<533D563F.6030305@stats.ox.ac.uk>
	<CAM9CR=2FJmy9p1b8RdfXLQTnJ67eyqei_Y40jUgN-bGpfEDBQg@mail.gmail.com>
Message-ID: <3C356D7A-2E5D-4AE4-8E16-598AF43F9064@gmail.com>

Thanks to Brian. Yet another thing that zoomed by without me really noticing.

However, I'd like to be sure that it isn't a "make dist" issue. We do seem to ship the correct files in src/extra/tzone, but could you please check Brian's suggestion about TZDIR possibly being set incorrectly?

-pd

On 03 Apr 2014, at 14:47 , Jon Clayden <jon.clayden at gmail.com> wrote:

> Many thanks, Prof Ripley. The "--without-internal-tzcode" option does indeed resolve the problem.
> 
> Regards,
> Jon
> 
> 
> On 3 April 2014 13:38, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 03/04/2014 13:27, peter dalgaard wrote:
> I'm seeing nothing of the sort with the nightly build of 3.1.0RC, also on 10.9.2. This is a plain-vanilla Xcode+ancillaries build as per Simon's instructions (I think):
> 
> pd$ more config.site
> r_arch=${r_arch:=x86_64}
> CC="gcc -arch $r_arch"
> CXX="g++ -arch $r_arch"
> F77="gfortran -arch $r_arch"
> FC="gfortran -arch $r_arch"
> OBJC="gcc -arch $r_arch"
> with_blas="-framework vecLib"
> with_lapack=yes
> 
> so either something is up specifically with gcc-4.8, or you managed to hose your time zone data base somehow (/usr/share/zoneinfo, I suppose).
> 
> More likely the one shipping with R, since --with-internal-tzcode is the default on OS X [*].  Setting TZDIR incorrectly would do this:
> 
> > Sys.time()
> [1] "2014-04-03 12:37:01 GMT"
> Warning messages:
> 1: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
> 2: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
> 3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'America/New_York'
> 
> when I do that.
> 
> You could try --without-internal-tzcode.
> 
> [*] Although x86_64 OS X has a 64-bit time_t it seems to have a 32-bit time-zone database and so wraps around.
> 
> 
> 
> - Peter D.
> 
> On 03 Apr 2014, at 13:24 , Jon Clayden <jon.clayden at gmail.com> wrote:
> 
> For what it's worth, this issue persists in R-rc_2014-04-02_r65358.
> 
> Regards,
> Jon
> 
> 
> On 24 March 2014 10:40, Jon Clayden <jon.clayden at gmail.com> wrote:
> 
> Dear all,
> 
> As of the current R alpha release, I'm seeing timezone-related warnings on
> installing any package (including the recommended ones), which I haven't
> seen before. For example,
> 
> [~/Documents/Source/R-alpha]$ bin/R CMD INSTALL ~/git/tractor/lib/reportr
> * installing to library '/Users/jon/Documents/Source/R-alpha/library'
> * installing *source* package 'reportr' ...
> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
> Warning in as.POSIXlt.POSIXct(x, tz) :
>   unknown timezone 'America/New_York'
> Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
> Warning in as.POSIXlt.POSIXct(x, tz) :
>   unknown timezone 'America/New_York'
> ** R
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (reportr)
> 
> This is R-alpha r65266, built from source on OS X 10.9.2 using gcc 4.8.2.
> I ran configure with
> 
> ./configure --with-blas="-framework Accelerate" --with-lapack
> --with-system-zlib --enable-memory-profiling
> --with-tcl-config=/System/Library/Frameworks/Tcl.framework/tclConfig.sh
> --with-tk-config=/System/Library/Frameworks/Tk.framework/tkConfig.sh
> CC=gcc-4.8 CXX=g++-4.8 OBJC=clang F77=gfortran-4.8 FC=gfortran-4.8
> CPPFLAGS="-D__ACCELERATE__" CFLAGS="-mtune=native -g -O2"
> CXXFLAGS="-mtune=native -g -O2" FFLAGS="-mtune=native -g -O2"
> FCFLAGS="-mtune=native -g -O2"
> 
> Session info is
> 
> R version 3.1.0 alpha (2014-03-23 r65266)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> I see some related material in the NEWS, but no indication that these
> warnings are expected. I hope this report is helpful.
> 
> All the best,
> Jon
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jon.clayden at gmail.com  Thu Apr  3 16:08:49 2014
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 3 Apr 2014 15:08:49 +0100
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <3C356D7A-2E5D-4AE4-8E16-598AF43F9064@gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
	<391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
	<533D563F.6030305@stats.ox.ac.uk>
	<CAM9CR=2FJmy9p1b8RdfXLQTnJ67eyqei_Y40jUgN-bGpfEDBQg@mail.gmail.com>
	<3C356D7A-2E5D-4AE4-8E16-598AF43F9064@gmail.com>
Message-ID: <CAM9CR=29RE0fiDA3Y9ifKirsnUNg=c9aDyuhTnQqO5e1ds3drQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140403/e5f303bf/attachment.pl>

From benjamin.hofner at fau.de  Fri Apr  4 12:34:58 2014
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Fri, 4 Apr 2014 03:34:58 -0700 (PDT)
Subject: [Rd] summary of lme4.0 model in package
In-Reply-To: <CAO1zAVb_7GmzVTgfV4aVew5YZdBJtKUCDPfnvtmPtnj80gcScw@mail.gmail.com>
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
	<CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3A22175@inbomail.inbo.be>
	<CAO1zAVb_7GmzVTgfV4aVew5YZdBJtKUCDPfnvtmPtnj80gcScw@mail.gmail.com>
Message-ID: <1396607682862-4688170.post@n4.nabble.com>

Dear Thierry,

I had the same problem in my package papeR, where I was depending on lme4 in
my DESCRIPTION file. The problem vanished after I also added 
  import(lme4) 
to my NAMESPACE (which is advised nowadays by R CMD check anyway). You can
of course also use importFrom() to import the summary function only.

All the best,
Benjamin



--
View this message in context: http://r.789695.n4.nabble.com/summary-of-lme4-0-model-in-package-tp4688082p4688170.html
Sent from the R devel mailing list archive at Nabble.com.


From mtmorgan at fhcrc.org  Sat Apr  5 20:24:47 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 05 Apr 2014 11:24:47 -0700
Subject: [Rd] Package vignettes share the same environment?
Message-ID: <53404A6F.70302@fhcrc.org>

In a package 'vig' R CMD build vig (or tools::buildVignettes(dir="vig") with

$ cat vig/vignettes/vig1.Rnw
\documentclass{article}
\begin{document}
<<>>=
x <- 1
@
\end{document}

$ cat vig/vignettes/vig2.Rnw
\documentclass{article}
\begin{document}
<<>>=
x
@
\end{document}

produces vig2.pdf where x is defined with value 1 -- the vignettes share a build 
environment. This seems undesirable in terms of reproducibility (a reader of 
vig2.pdf will not understand where x is assigned; similarly for the results of 
require()  or data() in vig1 referenced in vig2), and is not (?) documented. A 
more elaborate context is

     https://stat.ethz.ch/pipermail/bioc-devel/2014-April/005501.html

Would it be better to build each vignette in its own environment?

$ R --version|head -n 3
R version 3.1.0 RC (2014-04-05 r65379) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

Martin
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From greg at warnes.net  Sat Apr  5 19:39:20 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Sat, 5 Apr 2014 13:39:20 -0400
Subject: [Rd] Internet error on Mac OS X 10.9 with 3.1.0 RC
Message-ID: <CA48EF59-5A49-4443-A6FE-E08BF52DBBAC@warnes.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140405/2063ae00/attachment.pl>

From murdoch.duncan at gmail.com  Sat Apr  5 22:04:53 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 05 Apr 2014 16:04:53 -0400
Subject: [Rd] Package vignettes share the same environment?
In-Reply-To: <53404A6F.70302@fhcrc.org>
References: <53404A6F.70302@fhcrc.org>
Message-ID: <534061E5.9010201@gmail.com>

On 05/04/2014, 2:24 PM, Martin Morgan wrote:
> In a package 'vig' R CMD build vig (or tools::buildVignettes(dir="vig") with
>
> $ cat vig/vignettes/vig1.Rnw
> \documentclass{article}
> \begin{document}
> <<>>=
> x <- 1
> @
> \end{document}
>
> $ cat vig/vignettes/vig2.Rnw
> \documentclass{article}
> \begin{document}
> <<>>=
> x
> @
> \end{document}
>
> produces vig2.pdf where x is defined with value 1 -- the vignettes share a build
> environment. This seems undesirable in terms of reproducibility (a reader of
> vig2.pdf will not understand where x is assigned; similarly for the results of
> require()  or data() in vig1 referenced in vig2), and is not (?) documented. A
> more elaborate context is
>
>       https://stat.ethz.ch/pipermail/bioc-devel/2014-April/005501.html
>
> Would it be better to build each vignette in its own environment?

It's not just the environment that gets shared:  if you run 
buildVignette or buildVignettes in an R session, other aspects of the 
session (e.g. options() settings) will also be inherited by the 
vignette.  The way "R CMD build" handles this is to start a new R 
process to build the vignettes.

Currently it builds all vignettes in one process, rather than starting a 
separate process for each, which is why you see the x variable carry 
from one vignette to another.  I think it has been like this for quite a 
while, because on some platforms (e.g. Windows), starting a new process 
is quite slow.

I don't know if any other packages than gage currently depend on this 
behaviour.  It does sound confusing for the reader, but I don't think it 
breaks reproducibility:  after all, if a user has the package, they have 
all the vignettes, not just one.  If they just have the vignette, then 
they might not have the functions in the package that it needs, so 
they've already lost reproducibility.

Duncan Murdoch

>
> $ R --version|head -n 3
> R version 3.1.0 RC (2014-04-05 r65379) -- "Spring Dance"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> Martin
>


From xie at yihui.name  Sun Apr  6 04:37:03 2014
From: xie at yihui.name (Yihui Xie)
Date: Sat, 5 Apr 2014 21:37:03 -0500
Subject: [Rd] Package vignettes share the same environment?
In-Reply-To: <534061E5.9010201@gmail.com>
References: <53404A6F.70302@fhcrc.org> <534061E5.9010201@gmail.com>
Message-ID: <CANROs4e45f2eZF+mn2kmJLZ7XJ28srxZ81YeC3i9DgfkpM+ccg@mail.gmail.com>

By "quite slow" start-up time on Windows, you mean on the order of 1
or 2 seconds? That is probably not too bad, when we weigh it against
the confusion from compiling all vignettes in the same R session.

knitr::knit() has an 'envir' argument that specifies the environment
in which the code chunks are executed, but at the moment it is not
easy to pass additional arguments to the vignette engine. Of course,
one way is to define a new vignette engine, and that is not too hard:
it is basically something like knitr::knit(file, envir = new.env()).

But as mentioned below, there are other things shared in the same
session such as options(). I guess the cleanest way is still to start
new R sessions.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Sat, Apr 5, 2014 at 3:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 05/04/2014, 2:24 PM, Martin Morgan wrote:
>>
>> In a package 'vig' R CMD build vig (or tools::buildVignettes(dir="vig")
>> with
>>
>> $ cat vig/vignettes/vig1.Rnw
>> \documentclass{article}
>> \begin{document}
>> <<>>=
>> x <- 1
>> @
>> \end{document}
>>
>> $ cat vig/vignettes/vig2.Rnw
>> \documentclass{article}
>> \begin{document}
>> <<>>=
>> x
>> @
>> \end{document}
>>
>> produces vig2.pdf where x is defined with value 1 -- the vignettes share a
>> build
>> environment. This seems undesirable in terms of reproducibility (a reader
>> of
>> vig2.pdf will not understand where x is assigned; similarly for the
>> results of
>> require()  or data() in vig1 referenced in vig2), and is not (?)
>> documented. A
>> more elaborate context is
>>
>>       https://stat.ethz.ch/pipermail/bioc-devel/2014-April/005501.html
>>
>> Would it be better to build each vignette in its own environment?
>
>
> It's not just the environment that gets shared:  if you run buildVignette or
> buildVignettes in an R session, other aspects of the session (e.g. options()
> settings) will also be inherited by the vignette.  The way "R CMD build"
> handles this is to start a new R process to build the vignettes.
>
> Currently it builds all vignettes in one process, rather than starting a
> separate process for each, which is why you see the x variable carry from
> one vignette to another.  I think it has been like this for quite a while,
> because on some platforms (e.g. Windows), starting a new process is quite
> slow.
>
> I don't know if any other packages than gage currently depend on this
> behaviour.  It does sound confusing for the reader, but I don't think it
> breaks reproducibility:  after all, if a user has the package, they have all
> the vignettes, not just one.  If they just have the vignette, then they
> might not have the functions in the package that it needs, so they've
> already lost reproducibility.
>
> Duncan Murdoch


From djsamperi at gmail.com  Sun Apr  6 07:02:23 2014
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sun, 6 Apr 2014 01:02:23 -0400
Subject: [Rd] Timezone warnings on package install in R-alpha
In-Reply-To: <CAM9CR=29RE0fiDA3Y9ifKirsnUNg=c9aDyuhTnQqO5e1ds3drQ@mail.gmail.com>
References: <CAM9CR=3cWvm1cmJNOrm3C_VckK6f=TV9tzyGJNo+OQHaut=0yQ@mail.gmail.com>
	<CAM9CR=3uZrUCpJ-MunxNeZAs+ZdFk0ng5ENN4Hiyw-KB+Ry2Lw@mail.gmail.com>
	<391E016C-9F61-46E6-9D3D-1EBFE7A2A6E4@gmail.com>
	<533D563F.6030305@stats.ox.ac.uk>
	<CAM9CR=2FJmy9p1b8RdfXLQTnJ67eyqei_Y40jUgN-bGpfEDBQg@mail.gmail.com>
	<3C356D7A-2E5D-4AE4-8E16-598AF43F9064@gmail.com>
	<CAM9CR=29RE0fiDA3Y9ifKirsnUNg=c9aDyuhTnQqO5e1ds3drQ@mail.gmail.com>
Message-ID: <CADUbQ5ic=NC_eOr6caUrKm6VWVYOWHgtP_vYmUkc4FtP1YRFPA@mail.gmail.com>

Hi,

I just discovered a small issue that fits into this thread.

Consider:
z <- as.POSIXlt(Sys.time())
z$gmtoff

Under both Fedora and Windows (using R 3.1.0) I get the
value -14400, which is the number of SECONDS offset
from GMT (for New York), not the number of minutes
offset as specified in the man page for POSIXlt.

I assume that gmtoff is the offset that results when
the adjustment due to z$isdst has already been applied,
so it changes with the seasons, unlike the fixed geographic
zone (-5 for New York City). Please correct me if I am wrong.

Finally, I seem to recall that I was able to read a zoneinfo
file to fetch information like longitude and latitude for the
city that is returned by Sys.timezone(), but either I forgot
how to do this, or the procedure no longer applies. Is this
kind of thing supported?

Thanks,
Dominick


On Thu, Apr 3, 2014 at 10:08 AM, Jon Clayden <jon.clayden at gmail.com> wrote:
> That doesn't seem to be the case. After rebuilding using the old configure
> options, I see
>
>> Sys.getenv("TZDIR")
> [1] ""
>
> Jon
>
>
> On 3 April 2014 14:39, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> Thanks to Brian. Yet another thing that zoomed by without me really
>> noticing.
>>
>> However, I'd like to be sure that it isn't a "make dist" issue. We do seem
>> to ship the correct files in src/extra/tzone, but could you please check
>> Brian's suggestion about TZDIR possibly being set incorrectly?
>>
>> -pd
>>
>> On 03 Apr 2014, at 14:47 , Jon Clayden <jon.clayden at gmail.com> wrote:
>>
>> > Many thanks, Prof Ripley. The "--without-internal-tzcode" option does
>> indeed resolve the problem.
>> >
>> > Regards,
>> > Jon
>> >
>> >
>> > On 3 April 2014 13:38, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> > On 03/04/2014 13:27, peter dalgaard wrote:
>> > I'm seeing nothing of the sort with the nightly build of 3.1.0RC, also
>> on 10.9.2. This is a plain-vanilla Xcode+ancillaries build as per Simon's
>> instructions (I think):
>> >
>> > pd$ more config.site
>> > r_arch=${r_arch:=x86_64}
>> > CC="gcc -arch $r_arch"
>> > CXX="g++ -arch $r_arch"
>> > F77="gfortran -arch $r_arch"
>> > FC="gfortran -arch $r_arch"
>> > OBJC="gcc -arch $r_arch"
>> > with_blas="-framework vecLib"
>> > with_lapack=yes
>> >
>> > so either something is up specifically with gcc-4.8, or you managed to
>> hose your time zone data base somehow (/usr/share/zoneinfo, I suppose).
>> >
>> > More likely the one shipping with R, since --with-internal-tzcode is the
>> default on OS X [*].  Setting TZDIR incorrectly would do this:
>> >
>> > > Sys.time()
>> > [1] "2014-04-03 12:37:01 GMT"
>> > Warning messages:
>> > 1: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
>> > 2: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>> > 3: In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'America/New_York'
>> >
>> > when I do that.
>> >
>> > You could try --without-internal-tzcode.
>> >
>> > [*] Although x86_64 OS X has a 64-bit time_t it seems to have a 32-bit
>> time-zone database and so wraps around.
>> >
>> >
>> >
>> > - Peter D.
>> >
>> > On 03 Apr 2014, at 13:24 , Jon Clayden <jon.clayden at gmail.com> wrote:
>> >
>> > For what it's worth, this issue persists in R-rc_2014-04-02_r65358.
>> >
>> > Regards,
>> > Jon
>> >
>> >
>> > On 24 March 2014 10:40, Jon Clayden <jon.clayden at gmail.com> wrote:
>> >
>> > Dear all,
>> >
>> > As of the current R alpha release, I'm seeing timezone-related warnings
>> on
>> > installing any package (including the recommended ones), which I haven't
>> > seen before. For example,
>> >
>> > [~/Documents/Source/R-alpha]$ bin/R CMD INSTALL ~/git/tractor/lib/reportr
>> > * installing to library '/Users/jon/Documents/Source/R-alpha/library'
>> > * installing *source* package 'reportr' ...
>> > Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'Europe/London'
>> > Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>> > Warning in as.POSIXlt.POSIXct(x, tz) :
>> >   unknown timezone 'America/New_York'
>> > Warning in as.POSIXlt.POSIXct(x, tz) : unknown timezone 'GMT'
>> > Warning in as.POSIXlt.POSIXct(x, tz) :
>> >   unknown timezone 'America/New_York'
>> > ** R
>> > ** preparing package for lazy loading
>> > ** help
>> > *** installing help indices
>> > ** building package indices
>> > ** testing if installed package can be loaded
>> > * DONE (reportr)
>> >
>> > This is R-alpha r65266, built from source on OS X 10.9.2 using gcc 4.8.2.
>> > I ran configure with
>> >
>> > ./configure --with-blas="-framework Accelerate" --with-lapack
>> > --with-system-zlib --enable-memory-profiling
>> > --with-tcl-config=/System/Library/Frameworks/Tcl.framework/tclConfig.sh
>> > --with-tk-config=/System/Library/Frameworks/Tk.framework/tkConfig.sh
>> > CC=gcc-4.8 CXX=g++-4.8 OBJC=clang F77=gfortran-4.8 FC=gfortran-4.8
>> > CPPFLAGS="-D__ACCELERATE__" CFLAGS="-mtune=native -g -O2"
>> > CXXFLAGS="-mtune=native -g -O2" FFLAGS="-mtune=native -g -O2"
>> > FCFLAGS="-mtune=native -g -O2"
>> >
>> > Session info is
>> >
>> > R version 3.1.0 alpha (2014-03-23 r65266)
>> > Platform: x86_64-apple-darwin13.1.0 (64-bit)
>> >
>> > locale:
>> > [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> > I see some related material in the NEWS, but no indication that these
>> > warnings are expected. I hope this report is helpful.
>> >
>> > All the best,
>> > Jon
>> >
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>> >
>> > --
>> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> > University of Oxford,             Tel:  +44 1865 272861 (self)
>> > 1 South Parks Road,                     +44 1865 272866 (PA)
>> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> >
>>
>> --
>> Peter Dalgaard, Professor
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From greg at warnes.net  Sun Apr  6 14:52:07 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Sun, 6 Apr 2014 08:52:07 -0400
Subject: [Rd] Internet error on Mac OS X 10.9 with 3.1.0 RC
In-Reply-To: <3BA2F5AC-25EC-413E-9FD8-A15D5D4239D3@r-project.org>
References: <CA48EF59-5A49-4443-A6FE-E08BF52DBBAC@warnes.net>
	<3BA2F5AC-25EC-413E-9FD8-A15D5D4239D3@r-project.org>
Message-ID: <CDF7A11A-F454-4DB9-8BDA-AD35371775F0@warnes.net>

Hi Simon,

> sessionInfo()
R version 3.1.0 RC (2014-04-04 r65373)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


I just reinstalled, and can?t duplicate the error now.  The only difference, AFAIC, is that this time I left R 3.0.3 installed by running "sudo pkgutil --forget org.r-project.R.x86_64.fw.pkg? first.

-Greg



On Apr 5, 2014, at 7:00 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> Greg,
> 
> since we have more than one build now, could you, please, include sessionInfo()?
> 
> Thanks
> Simon
> 
> 
> 
> On Apr 5, 2014, at 1:39 PM, Gregory R. Warnes <greg at warnes.net> wrote:
> 
>> 
>> OS X 10.9.2
>> 
>> R 3.1.0 RC (2014-04-04 r65373) installer from http://r.research.att.com
>> 
>> Attempting to install packages yields the following:
>> 
>>> install.packages( c('gregmisc','RUnit') )
>> --- Please select a CRAN mirror for use in this session ---
>> Error in url("http://cran.r-project.org/CRAN_mirrors.csv") : 
>> internet routines cannot be accessed in module
>> 
>> -Greg
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 


From greg at warnes.net  Sun Apr  6 14:54:58 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Sun, 6 Apr 2014 08:54:58 -0400
Subject: [Rd] Internet error on Mac OS X 10.9 with 3.1.0 RC
In-Reply-To: <3BA2F5AC-25EC-413E-9FD8-A15D5D4239D3@r-project.org>
References: <CA48EF59-5A49-4443-A6FE-E08BF52DBBAC@warnes.net>
	<3BA2F5AC-25EC-413E-9FD8-A15D5D4239D3@r-project.org>
Message-ID: <2A6BECF9-E4E3-4095-9E5F-BAAB65A1B62D@warnes.net>

Hi Simon,

> sessionInfo()
R version 3.1.0 RC (2014-04-04 r65373)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


I just reinstalled, and can?t duplicate the error now.  The only difference, AFAIC, is that this time I left R 3.0.3 installed by running "sudo pkgutil --forget org.r-project.R.x86_64.fw.pkg? first.

-Greg



On Apr 5, 2014, at 7:00 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> Greg,
> 
> since we have more than one build now, could you, please, include sessionInfo()?
> 
> Thanks
> Simon
> 
> 
> 
> On Apr 5, 2014, at 1:39 PM, Gregory R. Warnes <greg at warnes.net> wrote:
> 
>> 
>> OS X 10.9.2
>> 
>> R 3.1.0 RC (2014-04-04 r65373) installer from http://r.research.att.com
>> 
>> Attempting to install packages yields the following:
>> 
>>> install.packages( c('gregmisc','RUnit') )
>> --- Please select a CRAN mirror for use in this session ---
>> Error in url("http://cran.r-project.org/CRAN_mirrors.csv") : 
>> internet routines cannot be accessed in module
>> 
>> -Greg
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 


From dtenenba at fhcrc.org  Mon Apr  7 05:52:07 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Sun, 6 Apr 2014 20:52:07 -0700 (PDT)
Subject: [Rd] minor issue with R CMD INSTALL --build
In-Reply-To: <1867252237.1388059.1396842585514.JavaMail.root@fhcrc.org>
Message-ID: <1444172336.1388061.1396842727876.JavaMail.root@fhcrc.org>

Hello,

I created a trivial package like this:

R --vanilla
a = 1
package.skeleton("apkg")

Then at the command prompt I removed apkg/man/* to avoid installation errors since those man pages are incomplete.

Then:

R CMD build apkg
R CMD INSTALL --build apkg_1.0.tar.gz 

says:
[...]
packaged installation of 'apkg' as 'apkg_1.0.tgz.gz'

I would have expected it to say:
packaged installation of 'apkg' as 'apkg_1.0.tgz'

Because indeed it did create apkg_1.0.tgz, not apkg_1.0.tgz.gz.

> sessionInfo()
R version 3.1.0 RC (2014-04-05 r65382)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

Thanks,
Dan


From hb at biostat.ucsf.edu  Mon Apr  7 06:33:15 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Apr 2014 21:33:15 -0700
Subject: [Rd] attach() outputs messages to stdout - should it be stderr?
Message-ID: <CAFDcVCTOCzGZYoZjGPxbkv+h_CJyLQ=4zNGwrfV351RkETw07g@mail.gmail.com>

Contrary to other functions in 'base', attach() output messages to
stdout instead of stdout, e.g.

> a <- 1
> capture.output(attach(list(a=1)))
[1] "The following object is masked _by_ .GlobalEnv:"
[2] ""
[3] "    a"

Shouldn't this message go to stderr?

Here's a patch for the local function checkConflicts() of
base::attach(), cf. ditto for base::library() that outputs to stderr:

Index: library/base/R/attach.R
===================================================================
--- library/base/R/attach.R	(revision 65344)
+++ library/base/R/attach.R	(working copy)
@@ -73,7 +73,7 @@
                                             "The following objects
are masked %s %s:\n\n%s\n"),
                                    if (i < db.pos) "_by_" else "from",
                                    pkg, paste(objs, collapse="\n"))
-                    cat(msg)
+                    cat(msg, file = stderr())
                 }
             }
         }

/Henrik


From adamwelc at yahoo.com  Mon Apr  7 07:31:45 2014
From: adamwelc at yahoo.com (Adam Welc)
Date: Sun, 6 Apr 2014 22:31:45 -0700
Subject: [Rd] inconsistent error messages on Mac OS X
Message-ID: <CABzWa1cDNjZdsN=V2yXxKa6So8pXV9Zxnq9ZrSXKs2Y84WciEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140406/9230ae99/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Apr  7 09:40:15 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 7 Apr 2014 07:40:15 +0000
Subject: [Rd] summary of lme4.0 model in package
In-Reply-To: <CAO1zAVb_7GmzVTgfV4aVew5YZdBJtKUCDPfnvtmPtnj80gcScw@mail.gmail.com>
References: <AA818EAD2576BC488B4F623941DA7427F3A21CF9@inbomail.inbo.be>
	<CANz9Z_L=hnu+Ly-fDonTMpC5XvHF-eSzvsE2sx+93j0pZ3WMng@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3A22175@inbomail.inbo.be>
	<CAO1zAVb_7GmzVTgfV4aVew5YZdBJtKUCDPfnvtmPtnj80gcScw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3A24051@inbomail.inbo.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140407/9d28f22a/attachment.pl>

From maechler at stat.math.ethz.ch  Mon Apr  7 10:40:11 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Apr 2014 10:40:11 +0200
Subject: [Rd] attach() outputs messages to stdout - should it be stderr?
In-Reply-To: <CAFDcVCTOCzGZYoZjGPxbkv+h_CJyLQ=4zNGwrfV351RkETw07g@mail.gmail.com>
References: <CAFDcVCTOCzGZYoZjGPxbkv+h_CJyLQ=4zNGwrfV351RkETw07g@mail.gmail.com>
Message-ID: <21314.25707.909655.571485@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>     on Sun, 6 Apr 2014 21:33:15 -0700 writes:

    > Contrary to other functions in 'base', attach() output
    > messages to stdout instead of stdout, e.g.

    >> a <- 1 capture.output(attach(list(a=1)))
    > [1] "The following object is masked _by_ .GlobalEnv:"
    > [2] ""
    > [3] " a"

    > Shouldn't this message go to stderr?

well, it this is changed... it should be changed to use 
message() really -- as library() does.

Then, it will not only go to stderr, but also be something you can
e.g. use  suppressMessages( . )  with.

I tend to agree to change this from cat() to  message(),
and will do so after a bit of waiting..

Martin

    > Here's a patch for the local function checkConflicts() of
    > base::attach(), cf. ditto for base::library() that outputs
    > to stderr:

> Index: library/base/R/attach.R
> ===================================================================
> --- library/base/R/attach.R	(revision 65344)
> +++ library/base/R/attach.R	(working copy)
> @@ -73,7 +73,7 @@
>                                              "The following objects
> are masked %s %s:\n\n%s\n"),
>                                     if (i < db.pos) "_by_" else "from",
>                                     pkg, paste(objs, collapse="\n"))
> -                    cat(msg)
> +                    cat(msg, file = stderr())
>                  }
>              }
>          }

> /Henrik


From hb at biostat.ucsf.edu  Mon Apr  7 17:20:27 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 7 Apr 2014 08:20:27 -0700
Subject: [Rd] attach() outputs messages to stdout - should it be stderr?
In-Reply-To: <21314.25707.909655.571485@stat.math.ethz.ch>
References: <CAFDcVCTOCzGZYoZjGPxbkv+h_CJyLQ=4zNGwrfV351RkETw07g@mail.gmail.com>
	<21314.25707.909655.571485@stat.math.ethz.ch>
Message-ID: <CAFDcVCSP+cZR0XHErX_5GEq4AEbgrw209PwM0ae7MFMNaVidzw@mail.gmail.com>

On Mon, Apr 7, 2014 at 1:40 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>>     on Sun, 6 Apr 2014 21:33:15 -0700 writes:
>
>     > Contrary to other functions in 'base', attach() output
>     > messages to stdout instead of stdout, e.g.
>
>     >> a <- 1 capture.output(attach(list(a=1)))
>     > [1] "The following object is masked _by_ .GlobalEnv:"
>     > [2] ""
>     > [3] " a"
>
>     > Shouldn't this message go to stderr?
>
> well, it this is changed... it should be changed to use
> message() really -- as library() does.
>
> Then, it will not only go to stderr, but also be something you can
> e.g. use  suppressMessages( . )  with.
>
> I tend to agree to change this from cat() to  message(),
> and will do so after a bit of waiting..

Thanks - sounds good.

I proposed cat(..., file=stderr()) rather that message(), because I
saw it was used in several other place in 'base' - left overs from a
earlier era?

/Henrik

>
> Martin
>
>     > Here's a patch for the local function checkConflicts() of
>     > base::attach(), cf. ditto for base::library() that outputs
>     > to stderr:
>
>> Index: library/base/R/attach.R
>> ===================================================================
>> --- library/base/R/attach.R   (revision 65344)
>> +++ library/base/R/attach.R   (working copy)
>> @@ -73,7 +73,7 @@
>>                                              "The following objects
>> are masked %s %s:\n\n%s\n"),
>>                                     if (i < db.pos) "_by_" else "from",
>>                                     pkg, paste(objs, collapse="\n"))
>> -                    cat(msg)
>> +                    cat(msg, file = stderr())
>>                  }
>>              }
>>          }
>
>> /Henrik


From maechler at stat.math.ethz.ch  Wed Apr  9 08:58:50 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 9 Apr 2014 08:58:50 +0200
Subject: [Rd] attach() outputs messages to stdout - should it be stderr?
In-Reply-To: <CAFDcVCSP+cZR0XHErX_5GEq4AEbgrw209PwM0ae7MFMNaVidzw@mail.gmail.com>
References: <CAFDcVCTOCzGZYoZjGPxbkv+h_CJyLQ=4zNGwrfV351RkETw07g@mail.gmail.com>
	<21314.25707.909655.571485@stat.math.ethz.ch>
	<CAFDcVCSP+cZR0XHErX_5GEq4AEbgrw209PwM0ae7MFMNaVidzw@mail.gmail.com>
Message-ID: <21316.61354.200139.724425@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>     on Mon, 7 Apr 2014 08:20:27 -0700 writes:

    > On Mon, Apr 7, 2014 at 1:40 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu> on Sun, 6 Apr
    >>>>>>> 2014 21:33:15 -0700 writes:
    >> 
    >> > Contrary to other functions in 'base', attach() output
    >> > messages to stdout instead of stdout, e.g.
    >> 
    >> >> a <- 1 capture.output(attach(list(a=1))) > [1] "The
    >> following object is masked _by_ .GlobalEnv:" > [2] "" >
    >> [3] " a"
    >> 
    >> > Shouldn't this message go to stderr?
    >> 
    >> well, it this is changed... it should be changed to use
    >> message() really -- as library() does.
    >> 
    >> Then, it will not only go to stderr, but also be
    >> something you can e.g. use suppressMessages( . )  with.
    >> 
    >> I tend to agree to change this from cat() to message(),
    >> and will do so after a bit of waiting..

    > Thanks - sounds good.

    > I proposed cat(..., file=stderr()) rather that message(),
    > because I saw it was used in several other place in 'base'
    > - left overs from a earlier era?

partly, probably.  In principle you / we should not only look in
'base' but all "base packages", i.e. all in

       installed.packages(priority = "base")

Yesterday, I have committed the change -- to use  message() --
to R-devel, i.e., of course too late to make it into 
R 3.1.0, released tomorrow.

Martin


From jon at thon.cc  Wed Apr  9 14:25:06 2014
From: jon at thon.cc (Jonathon Love)
Date: Wed, 09 Apr 2014 14:25:06 +0200
Subject: [Rd] building R under windows - comm: file 1 is not in sorted order
Message-ID: <53453C22.9000502@thon.cc>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hi,

I'm just trying to build R under windows, and receive the following error:

windres -i dllversion.rc -o dllversion.o
comm: file 1 is not in sorted order
make[4]: *** [Rgraphapp.def] Error 1
make[3]: *** [rlibs] Error 1
make[2]: *** [../../bin/i386/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2


I have been working through this document:

http://cran.rstudio.com/doc/manuals/r-release/R-admin.html#Building-the-core-files

and this error follows the issuing of the command

`make all recommended`

i am using

Rtools 3.1.0.1942, and am using the official 3.0.3 source tarball. I
have not customised the mkrules files at all (so building 32-bit).
Everything is as vanilla as I can make it.

Any tips on how I can solve this?

with thanks

Jonathon

- -- 

don't use google, use duckduckgo instead:

https://duckduckgo.com/supportus.html





-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
Comment: GPGTools - https://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBCgAGBQJTRTwiAAoJEH277gjmPGDYIBIQALGtOVL8/8qOsW3K6PrY+BB2
1i0UB7eOA/Tr1O/Y6b82+BxeDE6kyaOA72b5J85WdYolst2Pj8o+zxYtc5X1mfVu
irQCkmMn0oXSSNqaXNdS4Wd7OSIrDuTP5dUlzoTPJuoqm8M/xZsyDfAFhdu6ORiG
9MwBb02Pgs7Cq3tTHN957vW/KfcMwJm874goJomYYm9D4vfM/pg2TEzoOxNmAt87
OD0dry0w5DcZtqnQ5Tp2IYIu8yHEX3T04diISHPNprLO7A8dxtBFpR8pIV0bxS1P
6LosQzzGXu2hUCyfHJlsZpw+JbVCe4Eyzn1cbEj7bbLwvtJ9zzp2FIiV0PexSOQP
yIL96YihM4Llkz7aGsv2K2wZdpi8Nkbg8RbFrtn+ppTCNyXia4oP3UK3wu9vna4I
Yy17+dVDBUAoO89xkuM4/t52SyBDoEignWIkHEtgB1gDFSoqeJpqwKzQwCD7nFos
mzvEM1Vo9g9b3fYzEoy+k+ZkEpvrGmraH8SB2ypO+5v18SLhxbDLsx6numlBVkaN
r2zd36HOpO82/MtcEtn/UDmMEBBf2KhsTAno7Q5M818U+UBVgYbr0r2Uvq1rEHOd
ZES0+JMsvNBKVIoOSLtJ4qlX4lrgb7Qge7gZJIwojEBWRwUJwd2FyKv/Vcnh0jx8
l7F+BTjGoJXkam2lt8bp
=X+8m
-----END PGP SIGNATURE-----


From kirill.mueller at ivt.baug.ethz.ch  Thu Apr 10 10:34:51 2014
From: kirill.mueller at ivt.baug.ethz.ch (=?ISO-8859-1?Q?Kirill_M=FCller?=)
Date: Thu, 10 Apr 2014 10:34:51 +0200
Subject: [Rd] NOTE when detecting mismatch in output, and codes for NOTEs,
 WARNINGs and ERRORs
In-Reply-To: <53331290.9020800@gmail.com>
References: <533296B5.4000307@ivt.baug.ethz.ch> <53331290.9020800@gmail.com>
Message-ID: <534657AB.9010000@ivt.baug.ethz.ch>


On 03/26/2014 06:46 PM, Paul Gilbert wrote:
>
>
> On 03/26/2014 04:58 AM, Kirill M?ller wrote:
>> Dear list
>>
>>
>> It is possible to store expected output for tests and examples. From the
>> manual: "If tests has a subdirectory Examples containing a file
>> pkg-Ex.Rout.save, this is compared to the output file for running the
>> examples when the latter are checked." And, earlier (written in the
>> context of test output, but apparently applies here as well): "...,
>> these two are compared, with differences being reported but not causing
>> an error."
>>
>> I think a NOTE would be appropriate here, in order to be able to detect
>> this by only looking at the summary. Is there a reason for not flagging
>> differences here?
>
> The problem is that differences occur too often because this is a 
> comparison of characters in the output files (a diff). Any output that 
> is affected by locale, node name or Internet downloads, time, host, or 
> OS, is likely to cause a difference. Also, if you print results to a 
> high precision you will get differences on different systems, 
> depending on OS, 32 vs 64 bit, numerical libraries, etc. A better test 
> strategy when it is numerical results that you want to compare is to 
> do a numerical comparison and throw an error if the result is not 
> good, something like
>
>   r <- result from your function
>   rGood <- known good value
>   fuzz <- 1e-12  #tolerance
>
>   if (fuzz < max(abs(r - rGood))) stop('Test xxx failed.')
>
> It is more work to set up, but the maintenance will be less, 
> especially when you consider that your tests need to run on different 
> OSes on CRAN.
>
> You can also use try() and catch error codes if you want to check those.
>

Thanks for your input.

To me, this is a different kind of test, for which I'd rather use the 
facilities provided by the testthat package. Imagine a function that 
operates on, say, strings, vectors, or data frames, and that is expected 
to produce completely identical results on all platforms -- here, a 
character-by-character comparison of the output is appropriate, and I'd 
rather see a WARNING or ERROR if something fails.

Perhaps this functionality can be provided by external packages like 
roxygen and testthat: roxygen could create the "good" output (if asked 
for) and set up a testthat test that compares the example run with the 
"good" output. This would duplicate part of the work already done by 
base R; the duplication could be avoided if there was a way to specify 
the severity of a character-level difference between output and expected 
output, perhaps by means of an .Rout.cfg file in DCF format:

OnDifference: mute|note|warning|error
Normalize: [R expression]
Fuzziness: [number of different lines that are tolerated]

On that note: Is there a convenient way to create the .Rout.save files 
in base R? By "convenient" I mean a single function call, not checking 
and manually copying as suggested here: 
https://stat.ethz.ch/pipermail/r-help/2004-November/060310.html .


Cheers

Kirill


From wewolski at gmail.com  Thu Apr 10 10:16:00 2014
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 10 Apr 2014 10:16:00 +0200
Subject: [Rd] ! LaTeX Error: File `zi4.sty' not found.
Message-ID: <CAAjnpdj4BdnWUvka74Dua-33+1=GavaGFywZowTyGxct7AhveA@mail.gmail.com>

R version 3.1.0 beta (2014-03-28 r65330) -- "Spring Dance"

When running R CMD check mypackage.

the check fails with :

! LaTeX Error: File `zi4.sty' not found.


a search for this error forwards to similar errors but with an
inconsolata.sty file.



-- 
Witold Eryk Wolski


From edd at debian.org  Thu Apr 10 14:04:00 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Apr 2014 07:04:00 -0500
Subject: [Rd] ! LaTeX Error: File `zi4.sty' not found.
In-Reply-To: <CAAjnpdj4BdnWUvka74Dua-33+1=GavaGFywZowTyGxct7AhveA@mail.gmail.com>
References: <CAAjnpdj4BdnWUvka74Dua-33+1=GavaGFywZowTyGxct7AhveA@mail.gmail.com>
Message-ID: <21318.34992.835898.380329@max.nulle.part>


On 10 April 2014 at 10:16, Witold E Wolski wrote:
| R version 3.1.0 beta (2014-03-28 r65330) -- "Spring Dance"
| 
| When running R CMD check mypackage.
| 
| the check fails with :
| 
| ! LaTeX Error: File `zi4.sty' not found.

You failed to state which OS you're on, so barring contradictory information
I'll just assume it is similar to mine:

  edd at max:~$ locate zi4.sty
  /usr/share/texlive/texmf-dist/tex/latex/inconsolata/zi4.sty
  edd at max:~$ 

and

  edd at max:~$ dpkg -S `locate zi4.sty`
  texlive-fonts-extra: /usr/share/texlive/texmf-dist/tex/latex/inconsolata/zi4.sty
  edd at max:~$ 

As most (La)TeX installations these derive from TeXLive, you probably want to
make sure you have current enough and complete enough installation of it.  On
the Linux distros and releases I use, I never had an issue. (But then I also
do not use the very old and stable "Debian stable" or "Ubuntu LTS" variants.)

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Thu Apr 10 14:22:27 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Apr 2014 07:22:27 -0500
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <21148.34116.611590.24751@max.nulle.part>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<21148.34116.611590.24751@max.nulle.part>
Message-ID: <21318.36099.233395.938198@max.nulle.part>


On 2 December 2013 at 07:04, Dirk Eddelbuettel wrote:
| 
| Following up on the thread spawned a while back, I just wanted to say that I
| appreciate today's RSS serving of R-devel NEWS:
| 
|    CHANGES IN R-devel PACKAGE INSTALLATION
| 
|    There is _experimental_ support for compiling C++11 code in packages. The
|    file ?src/Makevars? or ?src/Makevars.win? should define the macro
|    ?USE_CXX11 = true?. Where needed, an alternative C++11 compiler can be
|    specified by setting macros ?CXX11?, ?CXX11FLAGS? and so on, either when R
|    is configured or in a personal ?Makevars? file. (The default is to use
|    ?$(CXX) -std=c++11?.) 
| 
| Thanks for initial and incremental changes. They are appreciated.

And now a big thanks to Martyn and anybody else in R Core who pushed this
through to the R 3.1.0 release this morning.

Having Makevars to let us say CXX_STD = CXX11 (plus the other variants) is a
real step forward, and relying on the information gleaned at configuration
time for R is sensible too.   

It's really good to have this, so thanks again.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From plummerm at iarc.fr  Thu Apr 10 15:02:50 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 10 Apr 2014 13:02:50 +0000
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <21318.36099.233395.938198@max.nulle.part>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<21148.34116.611590.24751@max.nulle.part>
	<21318.36099.233395.938198@max.nulle.part>
Message-ID: <1397134969.11062.0.camel@braque.iarc.fr>

On Thu, 2014-04-10 at 07:22 -0500, Dirk Eddelbuettel wrote:
> On 2 December 2013 at 07:04, Dirk Eddelbuettel wrote:
> | 
> | Following up on the thread spawned a while back, I just wanted to say that I
> | appreciate today's RSS serving of R-devel NEWS:
> | 
> |    CHANGES IN R-devel PACKAGE INSTALLATION
> | 
> |    There is _experimental_ support for compiling C++11 code in packages. The
> |    file ?src/Makevars? or ?src/Makevars.win? should define the macro
> |    ?USE_CXX11 = true?. Where needed, an alternative C++11 compiler can be
> |    specified by setting macros ?CXX11?, ?CXX11FLAGS? and so on, either when R
> |    is configured or in a personal ?Makevars? file. (The default is to use
> |    ?$(CXX) -std=c++11?.) 
> | 
> | Thanks for initial and incremental changes. They are appreciated.
> 
> And now a big thanks to Martyn and anybody else in R Core who pushed this
> through to the R 3.1.0 release this morning.

Credit it due to Brian here.
Martyn

> Having Makevars to let us say CXX_STD = CXX11 (plus the other variants) is a
> real step forward, and relying on the information gleaned at configuration
> time for R is sensible too.   
> 
> It's really good to have this, so thanks again.
> 
> Dirk
> 


From ggrothendieck at gmail.com  Thu Apr 10 17:14:56 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 10 Apr 2014 11:14:56 -0400
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
	<478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>
Message-ID: <CAP01uRnkS7YM3i5sJOAhfF3V4t-ZsMuXGFB2ViFQc_FTYwhegw@mail.gmail.com>

On Tue, Oct 29, 2013 at 1:58 AM,  <romain at r-enthusiasts.com> wrote:
> Le 2013-10-29 03:01, Whit Armstrong a ?crit :
>
>> I would love to see optional c++0x support added for R.
>
>
> c++0x was the name given for when this was in development. Now c++11 is a
> published standard backed by implementations by major compilers.
> people need to stop calling it c++0x
>
>
>> If there is anything I can do to help, please let me know.
>
>
> Come here https://github.com/romainfrancois/cpp11_article where I'm writing
> an article on C++11 and what would be the benefits.
>

Unless you are willing to do it yourself currently Rtools on Windows uses
g++ 4.6.3 and that requires that one specify -std=c++0x or -std=gnu++0x .

Ubuntu 12.04 LTS also provides g++ 4.6.3.

g++ 4.7 is the first version of g++ that accepts -std=c++11 or -std=gnu++11

More info at:
http://gcc.gnu.org/projects/cxx0x.html


From plummerm at iarc.fr  Thu Apr 10 17:58:47 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 10 Apr 2014 15:58:47 +0000
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <CAP01uRnkS7YM3i5sJOAhfF3V4t-ZsMuXGFB2ViFQc_FTYwhegw@mail.gmail.com>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
	<478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>
	<CAP01uRnkS7YM3i5sJOAhfF3V4t-ZsMuXGFB2ViFQc_FTYwhegw@mail.gmail.com>
Message-ID: <1397145527.11062.8.camel@braque.iarc.fr>

On Thu, 2014-04-10 at 11:14 -0400, Gabor Grothendieck wrote:
> On Tue, Oct 29, 2013 at 1:58 AM,  <romain at r-enthusiasts.com> wrote:
> > Le 2013-10-29 03:01, Whit Armstrong a ?crit :
> >
> >> I would love to see optional c++0x support added for R.
> >
> >
> > c++0x was the name given for when this was in development. Now c++11 is a
> > published standard backed by implementations by major compilers.
> > people need to stop calling it c++0x
> >
> >
> >> If there is anything I can do to help, please let me know.
> >
> >
> > Come here https://github.com/romainfrancois/cpp11_article where I'm writing
> > an article on C++11 and what would be the benefits.
> >
> 
> Unless you are willing to do it yourself currently Rtools on Windows uses
> g++ 4.6.3 and that requires that one specify -std=c++0x or -std=gnu++0x .
> 
> Ubuntu 12.04 LTS also provides g++ 4.6.3.
> 
> g++ 4.7 is the first version of g++ that accepts -std=c++11 or -std=gnu++11
> 
> More info at:
> http://gcc.gnu.org/projects/cxx0x.html

The R configure script is permissive and will enable "C++11" support if
your compiler accepts -std=c++0x. Obviously you will only get partial
support for the C++11 standard (But this is also true of some compilers
that accept -std=c++11). You may be OK if you just want C99 features,
which were missing from the C++98 standard, and features previously
introduced in the TR1 extension. But there are no guarantees.

Cross-platform support for C++11 is going to remain poor for some time
to come, I'm afraid.

Martyn
-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From romain at r-enthusiasts.com  Thu Apr 10 18:04:39 2014
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Thu, 10 Apr 2014 18:04:39 +0200
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <1397145527.11062.8.camel@braque.iarc.fr>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
	<478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>
	<CAP01uRnkS7YM3i5sJOAhfF3V4t-ZsMuXGFB2ViFQc_FTYwhegw@mail.gmail.com>
	<1397145527.11062.8.camel@braque.iarc.fr>
Message-ID: <F23D3CEA-13C3-48ED-BAB7-34CCEF09BDC2@r-enthusiasts.com>


Le 10 avr. 2014 ? 17:58, Martyn Plummer <plummerM at iarc.fr> a ?crit :

> On Thu, 2014-04-10 at 11:14 -0400, Gabor Grothendieck wrote:
>> On Tue, Oct 29, 2013 at 1:58 AM,  <romain at r-enthusiasts.com> wrote:
>>> Le 2013-10-29 03:01, Whit Armstrong a ?crit :
>>> 
>>>> I would love to see optional c++0x support added for R.
>>> 
>>> 
>>> c++0x was the name given for when this was in development. Now c++11 is a
>>> published standard backed by implementations by major compilers.
>>> people need to stop calling it c++0x
>>> 
>>> 
>>>> If there is anything I can do to help, please let me know.
>>> 
>>> 
>>> Come here https://github.com/romainfrancois/cpp11_article where I'm writing
>>> an article on C++11 and what would be the benefits.
>>> 
>> 
>> Unless you are willing to do it yourself currently Rtools on Windows uses
>> g++ 4.6.3 and that requires that one specify -std=c++0x or -std=gnu++0x .
>> 
>> Ubuntu 12.04 LTS also provides g++ 4.6.3.
>> 
>> g++ 4.7 is the first version of g++ that accepts -std=c++11 or -std=gnu++11
>> 
>> More info at:
>> http://gcc.gnu.org/projects/cxx0x.html
> 
> The R configure script is permissive and will enable "C++11" support if
> your compiler accepts -std=c++0x. Obviously you will only get partial
> support for the C++11 standard (But this is also true of some compilers
> that accept -std=c++11). You may be OK if you just want C99 features,
> which were missing from the C++98 standard, and features previously
> introduced in the TR1 extension. But there are no guarantees.
> 
> Cross-platform support for C++11 is going to remain poor for some time
> to come, I'm afraid.
> 
> Martyn

What would be a good enough motivation for distributing a version of Rtools based on a more recent gcc, e.g. in the 4.8 series, which has much better coverage of the standard. 

I don?t have the skills to build an Rtools distribution, but if I can help one way or another, please let me know. I could, perhaps with other interested parties sponsor someone?s time for example. 

Romain

From edd at debian.org  Thu Apr 10 18:26:11 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Apr 2014 11:26:11 -0500
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <1397145527.11062.8.camel@braque.iarc.fr>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
	<478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>
	<CAP01uRnkS7YM3i5sJOAhfF3V4t-ZsMuXGFB2ViFQc_FTYwhegw@mail.gmail.com>
	<1397145527.11062.8.camel@braque.iarc.fr>
Message-ID: <21318.50723.582070.694792@max.nulle.part>


On 10 April 2014 at 15:58, Martyn Plummer wrote:
| The R configure script is permissive and will enable "C++11" support if
| your compiler accepts -std=c++0x. Obviously you will only get partial
| support for the C++11 standard (But this is also true of some compilers
| that accept -std=c++11). You may be OK if you just want C99 features,
| which were missing from the C++98 standard, and features previously
| introduced in the TR1 extension. But there are no guarantees.

Indeed. I am using that feature (of asking for C++11 and being guaranteed a
set of changes relative to C99) in the RcppCNPy upload that went onto CRAN
this morning --- as we now have consistent 'long long' support.  Which also
works with Rtools and g++ 4.6.*.

| Cross-platform support for C++11 is going to remain poor for some time
| to come, I'm afraid.

Precisely.  

One does have the option of using what R / CRAN now "C++11" incrementally by
taking what is provided where it is provided.

My simple example finally getting 'long long' via the cstdint header works
that way (on my machine, cstdint goes back to the oldest compiler I still
have, g++-4.4).  But it needs one of the extensions: -std=c++11 where
available, -std=c++0x on older systems.

And eg Martin Morgan's recent question of how to use 'unordered_map' should
work the same way: just turn on C++11 and depend on R 3.1.0. That header is
also provided at least as far back as 4.4.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From kevinushey at gmail.com  Thu Apr 10 22:57:30 2014
From: kevinushey at gmail.com (Kevin Ushey)
Date: Thu, 10 Apr 2014 13:57:30 -0700
Subject: [Rd] Is it possible to shrink an R object in place?
Message-ID: <CAJXgQP0H0cR-sWdmzhUHKU0MgSyCO9u3td=p6SpQ9RR_sHZaPQ@mail.gmail.com>

Suppose I generate an integer vector with e.g.

    SEXP iv = PROTECT(allocVector(INTSXP, 100));

and later want to shrink the object, e.g.

    shrink(iv, 50);

would simply re-set the length to 50, and allow R to reclaim the
memory that was previously used.

Is it possible to do this while respecting how R manages memory?

The motivation: there are many operations where the length of the
output is not known ahead of time, and in such cases one typically
uses a data structure that can grow efficiently. Unfortunately, IIUC
SEXPRECs cannot do this; however, an alternative possibility would
involve reserving extra memory, and then shrinking to fit after the
operation is complete.

There have been some discussions previously that defaulted to answers
of the form "you should probably just copy", e.g.
https://stat.ethz.ch/pipermail/r-devel/2008-March/048593.html, but I
wanted to ping and see if others had ideas, or if perhaps there was
code in the R sources that might be relevant.

Another reason why this is interesting is due to C++11 and
multi-threading: if I can pre-allocate SEXPs that will contain results
in the main thread, and then fill these SEXPs asynchronously (without
touching R, and hence not getting in the way of the GC or otherwise),
I can then fill these SEXPs in place and shrink-to-fit after the
computations have been completed. With C++11 support coming with R
3.1.0, functionality like this is very attractive.

The obvious alternatives are to 1) determine the length of the output
first and hence generate SEXPs of appropriate size right off the bat
(potentially expensive), and 2) fill thread-safe containers and copy
to an R object (definitely expensive).

I am probably missing something subtle (or obvious) as to why this may
not work, or be recommended, so I appreciate any comments.

Thanks,
Kevin


From simon.urbanek at r-project.org  Fri Apr 11 17:08:32 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Apr 2014 11:08:32 -0400
Subject: [Rd] Is it possible to shrink an R object in place?
In-Reply-To: <CAJXgQP0H0cR-sWdmzhUHKU0MgSyCO9u3td=p6SpQ9RR_sHZaPQ@mail.gmail.com>
References: <CAJXgQP0H0cR-sWdmzhUHKU0MgSyCO9u3td=p6SpQ9RR_sHZaPQ@mail.gmail.com>
Message-ID: <75B0D51E-7974-4B03-A6E2-542A9DD96DCC@r-project.org>

Kevin,
Kevin,

On Apr 10, 2014, at 4:57 PM, Kevin Ushey <kevinushey at gmail.com> wrote:

> Suppose I generate an integer vector with e.g.
> 
>    SEXP iv = PROTECT(allocVector(INTSXP, 100));
> 
> and later want to shrink the object, e.g.
> 
>    shrink(iv, 50);
> 
> would simply re-set the length to 50, and allow R to reclaim the
> memory that was previously used.
> 
> Is it possible to do this while respecting how R manages memory?
> 

The short answer is, no.

There are several problems with this, one of the main ones being that there is simply no way to release the "excess" memory, so the vector still has the full length in memory. There is the SETLENGTH() function, but it's not part of the API and it has been proposed for elimination because of the inherent issues it causes (discrepancy in allocated and reported length).


> The motivation: there are many operations where the length of the
> output is not known ahead of time, and in such cases one typically
> uses a data structure that can grow efficiently. Unfortunately, IIUC
> SEXPRECs cannot do this; however, an alternative possibility would
> involve reserving extra memory, and then shrinking to fit after the
> operation is complete.
> 
> There have been some discussions previously that defaulted to answers
> of the form "you should probably just copy", e.g.
> https://stat.ethz.ch/pipermail/r-devel/2008-March/048593.html, but I
> wanted to ping and see if others had ideas, or if perhaps there was
> code in the R sources that might be relevant.
> 
> Another reason why this is interesting is due to C++11 and
> multi-threading: if I can pre-allocate SEXPs that will contain results
> in the main thread, and then fill these SEXPs asynchronously (without
> touching R, and hence not getting in the way of the GC or otherwise),
> I can then fill these SEXPs in place and shrink-to-fit after the
> computations have been completed. With C++11 support coming with R
> 3.1.0, functionality like this is very attractive.
> 

I don't see how this is related to the question - it was always possible to fill SEXPs from parallel threads and has been routinely used even in R itself (most commonly via OpenMP).


> The obvious alternatives are to 1) determine the length of the output
> first and hence generate SEXPs of appropriate size right off the bat
> (potentially expensive), and 2) fill thread-safe containers and copy
> to an R object (definitely expensive).
> 

In most current OSes, it is impossible to shrink allocated memory in-place, so if you really don't know the size of the object, it will be copied anyway. As mentioned above, the only case where shrinking may work is if you only need to strip a few elements of a large vector so that keeping the same allocation has no significant effect.

Cheers,
Simon




> I am probably missing something subtle (or obvious) as to why this may
> not work, or be recommended, so I appreciate any comments.
> 
> Thanks,
> Kevin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From greg at warnes.net  Fri Apr 11 17:50:01 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Fri, 11 Apr 2014 11:50:01 -0400
Subject: [Rd] type.convert and doubles
Message-ID: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140411/9691324e/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 11 19:43:48 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Apr 2014 13:43:48 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
Message-ID: <326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>

Greg,

On Apr 11, 2014, at 11:50 AM, Gregory R. Warnes <greg at warnes.net> wrote:

> Hi All,
> 
> I see this in the NEWS for R 3.1.0: 
> 
> type.convert() (and hence by default read.table()) returns a character vector or factor when representing a numeric input as a double would lose accuracy. Similarly for complex inputs.
> 
> This behavior seems likely to surprise users.

Can you elaborate why that would be surprising? It is consistent with the intention of type.convert() to determine the correct type to represent the value - it has always used character/factor as a fallback where native type doesn't match. It has never issued any warning in that case historically, so IMHO it would be rather surprising if it did now?

Cheers,
Simon


>  Would it be possible to issue a warning when this occurs?
> 
> Aside: I?m very happy to see the new ?s? and ?f? browser (debugger) commands!
> 
> -Greg
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From romain at r-enthusiasts.com  Fri Apr 11 21:47:40 2014
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 11 Apr 2014 21:47:40 +0200
Subject: [Rd] Is it possible to shrink an R object in place?
In-Reply-To: <75B0D51E-7974-4B03-A6E2-542A9DD96DCC@r-project.org>
References: <CAJXgQP0H0cR-sWdmzhUHKU0MgSyCO9u3td=p6SpQ9RR_sHZaPQ@mail.gmail.com>
	<75B0D51E-7974-4B03-A6E2-542A9DD96DCC@r-project.org>
Message-ID: <087F83F3-07FC-4AEC-B5F8-C5FAA5D28D4C@r-enthusiasts.com>

Hello, 

I?ve been using shrinking in https://github.com/hadley/dplyr/blob/master/inst/include/tools/ShrinkableVector.h

This defines a ShrinkableVector of some R type (INTSXP, ...) given the maximum number of elements it will hold. Then, I reset with SETLENGTH when needed. The constructor protects the SEXP, and the destructor restores the original length before removing the protection. With this I only have to allocate the data once, and I can make R believe a vector is of a different size. As long as I restore the correct size eventually. 

Kevin, when you start using parallelism, you have to change the way you approach the sequence of things that go on. Particularly it is less of a problem to do a double pass, i.e. one to figure out the appropriate size and one to handle part of the data. And guess what, there is lots of that to come in next versions of Rcpp11. 

Romain

Le 11 avr. 2014 ? 17:08, Simon Urbanek <simon.urbanek at r-project.org> a ?crit :

> Kevin,
> Kevin,
> 
> On Apr 10, 2014, at 4:57 PM, Kevin Ushey <kevinushey at gmail.com> wrote:
> 
>> Suppose I generate an integer vector with e.g.
>> 
>>   SEXP iv = PROTECT(allocVector(INTSXP, 100));
>> 
>> and later want to shrink the object, e.g.
>> 
>>   shrink(iv, 50);
>> 
>> would simply re-set the length to 50, and allow R to reclaim the
>> memory that was previously used.
>> 
>> Is it possible to do this while respecting how R manages memory?
>> 
> 
> The short answer is, no.
> 
> There are several problems with this, one of the main ones being that there is simply no way to release the "excess" memory, so the vector still has the full length in memory. There is the SETLENGTH() function, but it's not part of the API and it has been proposed for elimination because of the inherent issues it causes (discrepancy in allocated and reported length).
> 
> 
>> The motivation: there are many operations where the length of the
>> output is not known ahead of time, and in such cases one typically
>> uses a data structure that can grow efficiently. Unfortunately, IIUC
>> SEXPRECs cannot do this; however, an alternative possibility would
>> involve reserving extra memory, and then shrinking to fit after the
>> operation is complete.
>> 
>> There have been some discussions previously that defaulted to answers
>> of the form "you should probably just copy", e.g.
>> https://stat.ethz.ch/pipermail/r-devel/2008-March/048593.html, but I
>> wanted to ping and see if others had ideas, or if perhaps there was
>> code in the R sources that might be relevant.
>> 
>> Another reason why this is interesting is due to C++11 and
>> multi-threading: if I can pre-allocate SEXPs that will contain results
>> in the main thread, and then fill these SEXPs asynchronously (without
>> touching R, and hence not getting in the way of the GC or otherwise),
>> I can then fill these SEXPs in place and shrink-to-fit after the
>> computations have been completed. With C++11 support coming with R
>> 3.1.0, functionality like this is very attractive.
>> 
> 
> I don't see how this is related to the question - it was always possible to fill SEXPs from parallel threads and has been routinely used even in R itself (most commonly via OpenMP).
> 
> 
>> The obvious alternatives are to 1) determine the length of the output
>> first and hence generate SEXPs of appropriate size right off the bat
>> (potentially expensive), and 2) fill thread-safe containers and copy
>> to an R object (definitely expensive).
>> 
> 
> In most current OSes, it is impossible to shrink allocated memory in-place, so if you really don't know the size of the object, it will be copied anyway. As mentioned above, the only case where shrinking may work is if you only need to strip a few elements of a large vector so that keeping the same allocation has no significant effect.
> 
> Cheers,
> Simon
> 
> 
> 
> 
>> I am probably missing something subtle (or obvious) as to why this may
>> not work, or be recommended, so I appreciate any comments.
>> 
>> Thanks,
>> Kevin
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Apr 11 22:34:20 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Apr 2014 16:34:20 -0400
Subject: [Rd] Is it possible to shrink an R object in place?
In-Reply-To: <087F83F3-07FC-4AEC-B5F8-C5FAA5D28D4C@r-enthusiasts.com>
References: <CAJXgQP0H0cR-sWdmzhUHKU0MgSyCO9u3td=p6SpQ9RR_sHZaPQ@mail.gmail.com>
	<75B0D51E-7974-4B03-A6E2-542A9DD96DCC@r-project.org>
	<087F83F3-07FC-4AEC-B5F8-C5FAA5D28D4C@r-enthusiasts.com>
Message-ID: <32672E6B-ED25-40D5-9E8D-A967C679ED06@r-project.org>


On Apr 11, 2014, at 3:47 PM, Romain Francois <romain at r-enthusiasts.com> wrote:

> Hello, 
> 
> I?ve been using shrinking in https://github.com/hadley/dplyr/blob/master/inst/include/tools/ShrinkableVector.h
> 
> This defines a ShrinkableVector of some R type (INTSXP, ...) given the maximum number of elements it will hold. Then, I reset with SETLENGTH when needed. The constructor protects the SEXP, and the destructor restores the original length before removing the protection. With this I only have to allocate the data once, and I can make R believe a vector is of a different size. As long as I restore the correct size eventually. 
> 

I like the destructor touch of restoring the size :) - that is neat.

But as I said, this is only useful in cases where you strip off a few elements, otherwise you're better off creating a copy because of the memory implications.

Cheers,
Simon


> Kevin, when you start using parallelism, you have to change the way you approach the sequence of things that go on. Particularly it is less of a problem to do a double pass, i.e. one to figure out the appropriate size and one to handle part of the data. And guess what, there is lots of that to come in next versions of Rcpp11. 
> 
> Romain
> 
> Le 11 avr. 2014 ? 17:08, Simon Urbanek <simon.urbanek at r-project.org> a ?crit :
> 
>> Kevin,
>> Kevin,
>> 
>> On Apr 10, 2014, at 4:57 PM, Kevin Ushey <kevinushey at gmail.com> wrote:
>> 
>>> Suppose I generate an integer vector with e.g.
>>> 
>>>  SEXP iv = PROTECT(allocVector(INTSXP, 100));
>>> 
>>> and later want to shrink the object, e.g.
>>> 
>>>  shrink(iv, 50);
>>> 
>>> would simply re-set the length to 50, and allow R to reclaim the
>>> memory that was previously used.
>>> 
>>> Is it possible to do this while respecting how R manages memory?
>>> 
>> 
>> The short answer is, no.
>> 
>> There are several problems with this, one of the main ones being that there is simply no way to release the "excess" memory, so the vector still has the full length in memory. There is the SETLENGTH() function, but it's not part of the API and it has been proposed for elimination because of the inherent issues it causes (discrepancy in allocated and reported length).
>> 
>> 
>>> The motivation: there are many operations where the length of the
>>> output is not known ahead of time, and in such cases one typically
>>> uses a data structure that can grow efficiently. Unfortunately, IIUC
>>> SEXPRECs cannot do this; however, an alternative possibility would
>>> involve reserving extra memory, and then shrinking to fit after the
>>> operation is complete.
>>> 
>>> There have been some discussions previously that defaulted to answers
>>> of the form "you should probably just copy", e.g.
>>> https://stat.ethz.ch/pipermail/r-devel/2008-March/048593.html, but I
>>> wanted to ping and see if others had ideas, or if perhaps there was
>>> code in the R sources that might be relevant.
>>> 
>>> Another reason why this is interesting is due to C++11 and
>>> multi-threading: if I can pre-allocate SEXPs that will contain results
>>> in the main thread, and then fill these SEXPs asynchronously (without
>>> touching R, and hence not getting in the way of the GC or otherwise),
>>> I can then fill these SEXPs in place and shrink-to-fit after the
>>> computations have been completed. With C++11 support coming with R
>>> 3.1.0, functionality like this is very attractive.
>>> 
>> 
>> I don't see how this is related to the question - it was always possible to fill SEXPs from parallel threads and has been routinely used even in R itself (most commonly via OpenMP).
>> 
>> 
>>> The obvious alternatives are to 1) determine the length of the output
>>> first and hence generate SEXPs of appropriate size right off the bat
>>> (potentially expensive), and 2) fill thread-safe containers and copy
>>> to an R object (definitely expensive).
>>> 
>> 
>> In most current OSes, it is impossible to shrink allocated memory in-place, so if you really don't know the size of the object, it will be copied anyway. As mentioned above, the only case where shrinking may work is if you only need to strip a few elements of a large vector so that keeping the same allocation has no significant effect.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> 
>>> I am probably missing something subtle (or obvious) as to why this may
>>> not work, or be recommended, so I appreciate any comments.
>>> 
>>> Thanks,
>>> Kevin
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From pgilbert902 at gmail.com  Fri Apr 11 23:38:20 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 11 Apr 2014 17:38:20 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
Message-ID: <534860CC.2090206@gmail.com>



On 04/11/2014 01:43 PM, Simon Urbanek wrote:
> Greg,
>
> On Apr 11, 2014, at 11:50 AM, Gregory R. Warnes <greg at warnes.net>
> wrote:
>
>> Hi All,
>>
>> I see this in the NEWS for R 3.1.0:
>>
>> type.convert() (and hence by default read.table()) returns a
>> character vector or factor when representing a numeric input as a
>> double would lose accuracy. Similarly for complex inputs.
>>
>> This behavior seems likely to surprise users.
>
> Can you elaborate why that would be surprising? It is consistent with
> the intention of type.convert() to determine the correct type to
> represent the value - it has always used character/factor as a
> fallback where native type doesn't match.

Strictly speaking, I don't think this is true. If it were, it would not 
have been necessary to make the change so that it does now fallback to 
using character/factor. It may, however, have always been the intent.

I don't really think a warning is necessary, but there are some surprises:

 > str(type.convert(format(1/3, digits=17))) # R-3.0.3
  num 0.333

 > str(type.convert(format(1/3, digits=17))) # R-3.1.0
  Factor w/ 1 level "0.33333333333333331": 1

Now you could say that one should never do that, and the change is just 
flushing out a bug that was always there. But the point is that in 
serialization situations there can be some surprises. So, for example, 
RODBC talking to PostgresSQL databases is now returning factors rather 
than numerics for double precision fields, whereas with RPostgresSQL the 
behaviour has not changed.

Paul

It has never issued any
> warning in that case historically, so IMHO it would be rather
> surprising if it did now?
>
> Cheers, Simon
>
>
>> Would it be possible to issue a warning when this occurs?
>>
>> Aside: I?m very happy to see the new ?s? and ?f? browser (debugger)
>> commands!
>>
>> -Greg [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>


From djsamperi at gmail.com  Sat Apr 12 06:39:10 2014
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 12 Apr 2014 00:39:10 -0400
Subject: [Rd] vapply confusion
Message-ID: <CADUbQ5gKwR+gMpjALkizH77zNj6ds4NbxX_-Kq5OjO+gqJo4=g@mail.gmail.com>

The following code seems to contain an inconsistency in
the behavior of vapply(). Am I missing something here?

## This function assumes v is a 3d vector, beta a scalar.
f3d <- function(v,beta) { v+beta }

## This expression applies f3d to a vector of scalars, and
## specifies the template 'array(10,3)' for the return value.
dat <- vapply(seq(0,1,length=10), function(beta) {
  f3d(c(0,0,0), beta) }, array(10,3))

dim(dat) # 3 10 (the dimensions are the reverse of the template?)

Of course, a transpose will patch the result to match the
specified template.


From ccberry at ucsd.edu  Sat Apr 12 18:10:10 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Sat, 12 Apr 2014 16:10:10 +0000
Subject: [Rd] vapply confusion
References: <CADUbQ5gKwR+gMpjALkizH77zNj6ds4NbxX_-Kq5OjO+gqJo4=g@mail.gmail.com>
Message-ID: <loom.20140412T180140-839@post.gmane.org>

Dominick Samperi <djsamperi <at> gmail.com> writes:

> 
> The following code seems to contain an inconsistency in
> the behavior of vapply(). Am I missing something here?
> 
> ## This function assumes v is a 3d vector, beta a scalar.
> f3d <- function(v,beta) { v+beta }
> 
> ## This expression applies f3d to a vector of scalars, and
> ## specifies the template 'array(10,3)' for the return value.
> dat <- vapply(seq(0,1,length=10), function(beta) {
>   f3d(c(0,0,0), beta) }, array(10,3))
> 

Same result as that of sapply(...

> dim(dat) # 3 10 (the dimensions are the reverse of the template?)
> 

No the template has dimension '3'

> dim(array(10,3))
[1] 3
> 

and X has length 10.

Editting the help page:

"If FUN.VALUE is [an array, the result is] an array a with dim(a) ==
c(dim(FUN.VALUE), length(X))."

which is what you got.

HTH,

Chuck


From pgilbert902 at gmail.com  Sun Apr 13 17:25:49 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 13 Apr 2014 11:25:49 -0400
Subject: [Rd] NOTE when detecting mismatch in output, and codes for NOTEs,
 WARNINGs and ERRORs
In-Reply-To: <534657AB.9010000@ivt.baug.ethz.ch>
References: <533296B5.4000307@ivt.baug.ethz.ch> <53331290.9020800@gmail.com>
	<534657AB.9010000@ivt.baug.ethz.ch>
Message-ID: <534AAC7D.2090705@gmail.com>



On 04/10/2014 04:34 AM, Kirill M?ller wrote:
>
> On 03/26/2014 06:46 PM, Paul Gilbert wrote:
>>
>>
>> On 03/26/2014 04:58 AM, Kirill M?ller wrote:
>>> Dear list
>>>
>>>
>>> It is possible to store expected output for tests and examples. From the
>>> manual: "If tests has a subdirectory Examples containing a file
>>> pkg-Ex.Rout.save, this is compared to the output file for running the
>>> examples when the latter are checked." And, earlier (written in the
>>> context of test output, but apparently applies here as well): "...,
>>> these two are compared, with differences being reported but not causing
>>> an error."
>>>
>>> I think a NOTE would be appropriate here, in order to be able to detect
>>> this by only looking at the summary. Is there a reason for not flagging
>>> differences here?
>>
>> The problem is that differences occur too often because this is a
>> comparison of characters in the output files (a diff). Any output that
>> is affected by locale, node name or Internet downloads, time, host, or
>> OS, is likely to cause a difference. Also, if you print results to a
>> high precision you will get differences on different systems,
>> depending on OS, 32 vs 64 bit, numerical libraries, etc. A better test
>> strategy when it is numerical results that you want to compare is to
>> do a numerical comparison and throw an error if the result is not
>> good, something like
>>
>>   r <- result from your function
>>   rGood <- known good value
>>   fuzz <- 1e-12  #tolerance
>>
>>   if (fuzz < max(abs(r - rGood))) stop('Test xxx failed.')
>>
>> It is more work to set up, but the maintenance will be less,
>> especially when you consider that your tests need to run on different
>> OSes on CRAN.
>>
>> You can also use try() and catch error codes if you want to check those.
>>
>
> Thanks for your input.
>
> To me, this is a different kind of test,

Yes, if you meant that you intended to compare character output, it is a 
different kind of test. With a file in the tests/ directory of a package 
you can construct a test of character differences in individual commands 
with something like

   z1 <- as.character(rnorm(5))
   z2 <- as.character(type.convert(z1))
   if(any(z1 != z2)) stop("character differences exist.")

for which no one would be required to make any changes to the existing 
package checking system. One caveat is output that is done as a side 
effect. For longer output streams from multiple commands you might 
construct your own testing with R CMD Rdiff.

As you point out, adding something to flag different levels of severity 
for differences from a .Rout.save file would require some work by someone.

HTH,
Paul

for which I'd rather use the
> facilities provided by the testthat package. Imagine a function that
> operates on, say, strings, vectors, or data frames, and that is expected
> to produce completely identical results on all platforms -- here, a
> character-by-character comparison of the output is appropriate, and I'd
> rather see a WARNING or ERROR if something fails.
>
> Perhaps this functionality can be provided by external packages like
> roxygen and testthat: roxygen could create the "good" output (if asked
> for) and set up a testthat test that compares the example run with the
> "good" output. This would duplicate part of the work already done by
> base R; the duplication could be avoided if there was a way to specify
> the severity of a character-level difference between output and expected
> output, perhaps by means of an .Rout.cfg file in DCF format:
>
> OnDifference: mute|note|warning|error
> Normalize: [R expression]
> Fuzziness: [number of different lines that are tolerated]
>
> On that note: Is there a convenient way to create the .Rout.save files
> in base R? By "convenient" I mean a single function call, not checking
> and manually copying as suggested here:
> https://stat.ethz.ch/pipermail/r-help/2004-November/060310.html .
>
>
> Cheers
>
> Kirill


From skostysh at princeton.edu  Mon Apr 14 13:12:55 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Mon, 14 Apr 2014 07:12:55 -0400
Subject: [Rd] duplication regression (?)
Message-ID: <CAE3=dmcfuEOXjoEGcj4+MrWp-Waur4Nb+saPH2OnSkdANc+skA@mail.gmail.com>

Below is an example of output that changed as a result of r64970. I
did not see any NEWS item suggesting this change is expected.

Note that the example is contrived and I don't have a use case for it.
I stumbled across it when playing with recent changes in R relating to
duplication. Does the example use undefined syntax?

-----
fn1 <- function(mylist) {
    fn1a <- function() mylist[[c(1,1)]][[1]] <<- 9
    fn1a()
    return(NULL)
}

fn2 <- function(myarg) fn1(myarg)

test_list <- list(list(list(1)))
print(test_list[[c(1,1,1)]])
fn2(test_list)
print(test_list[[c(1,1,1)]])
-----

Before r64970 the output is
[1] 1
[1] 1

After r64970 the output is
[1] 1
[1] 9

> sessionInfo()
R Under development (unstable) (2014-04-10 r65396)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From maechler at stat.math.ethz.ch  Mon Apr 14 14:28:12 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Apr 2014 14:28:12 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
	batch mode exit
In-Reply-To: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
Message-ID: <21323.54364.87334.81949@stat.math.ethz.ch>

>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>     on Sun, 13 Apr 2014 10:22:55 -0500 writes:

[on the R-SIG-Mac  mailing list] :	  

    > Hi all,
    > With R version 3.1.0 on OSX, using either the Snow Leopard or the Mavericks binary installation on a Mac with fully updated Mavericks, there has been a change in behavior since 3.0.3.

I've just written to R-core about this:

    R CMD Sweave

has *serious* problems also in the very simple case when it
should produce figures: They are not available after the
completion of R CMD Sweave,
confirming your  'deletes non tex files created upon batch mode exit'

So this is not related to OSX only, but also a big problem 
at least on other *nix descendent platforms, such as Linux.

In short, failure (no graphic produce in the example below) by

   R CMD Sweave foo.Rnw

but all is fine with using Sweave(), as you Marc, noted, and hence with  

   Rscript -e 'Sweave("foo.Rnw")'

... and to answer your question:  
No this was not intended and is probably one of the bigger / 
most embarrassing bugs in a newly released version of R
in my view: 

Basically  'R CMD Sweave' is partly broken in R 3.1.0.
Yes, this should never have happened.

I had to partially revert the R 3.1.0 installation here (our
statistics dept), by making R 3.0.3 the default 'R'
for now, as we are relying on 'R CMD Sweave ..' in many places.

Personally I've never noticed the problem, as I seem to always
Sweave from ESS (Emacs speaks statistics) which calls  Sweave()
in R, and that works fine, also in  R 3.1.0, as you've already
noted 

Martin Maechler, ETH Zurich

%------------------------------------------------------------
\documentclass[12pt]{article}
\usepackage{Sweave}
\begin{document}  Just a simple graphic 

<<qqnorm, fig=TRUE>>= 
qqnorm(rnorm(20))
@ 

and that's all, folks!
\end{document}
%------------------------------------------------------------

    > I have a master .Rnw file which runs a series of outputs from multiple R code files, each called in BATCH mode using system() from within the master .Rnw file. The output of the R code files go to separate text files in order to catch some of the function call output that would not otherwise be included in the resultant .tex file due to output redirection.

    > Those text files are then included in the resultant .tex file using, for example:

    > \lstinputlisting[caption={}]{test.out}

    > directives which are included in the .Rnw source file.

    > A simple example to replicate the observed behaviors.

    > The test.Rnw file content:

    > %% R CMD Sweave test.Rnw
    > <<results=tex,echo=false>>=
    > system("R CMD BATCH test.R test.out")
    > @ 


    > The test.R file content:

    > options(echo = FALSE)
    > options(useFancyQuotes = FALSE)
    > installed.packages()


    > On version 3.0.3, the file test.out is created, along with test.tex. test.out contains the output of installed.packages(). I did not include the aforementioned listing directive in test.Rnw here for simplicity.

    > On version 3.1.0, the file test.out is created, but when the R CMD Sweave command exits and returns to the CLI in the console, test.out is deleted, presumably as part of a post R batch session clean up process. The file test.tex is retained.

    > I uninstalled 3.1.0 and reinstalled 3.0.3 and observed the prior behavior. I then tried clean installs of both the Snow Leopard and Mavericks 3.1.0 binaries, with the new behavior observed in both cases.

    > In reading the NEWS file for 3.1.0, there are multiple references to Sweave, but there is nothing explicit about this new behavior. 

    > I should note that when the .Rnw file is run from within an R 3.1.0 interactive session using:

    > Sweave("test.Rnw")

    > the test.out file is created and not deleted upon the function exit, or when exiting the R session back to the console. 

    > Thus, this new behavior seems to be limited to running Sweave from the CLI using R CMD. It is not clear to me if this new behavior is by design or perhaps an unintended consequence of changes elsewhere in Sweave processing or in the handling of R in BATCH mode.

    > When watching the folder where the file output activity takes place, I note that a file .build.timestamp is created and then deleted, which leads me to believe that the new functions fileSnapshot() and changedFiles() are being used in the course of processing R in BATCH mode. If that is correct and there is a clean up step that is occurring upon BATCH mode exit, which deletes all files and folders other than .tex files, is it possible that this process is being overly aggressive? Or if not, is there a way to not have these files deleted or have a protected folder where these files can be retained?

    > Thanks for any insights.

    > Regards,

    > Marc Schwartz


From marc_schwartz at me.com  Mon Apr 14 16:23:06 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 14 Apr 2014 09:23:06 -0500
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <21323.54364.87334.81949@stat.math.ethz.ch>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
Message-ID: <CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>

Hi Martin,

Thanks for your confirmation on this.

I normally do not use R CMD Sweave, as I too run under ESS in normal day to day operations. This finding was a quirk of having a particular Rnw document that I occasionally run using R CMD Sweave and I had done so over the weekend, realizing this behavior.

Thanks again.

Regards,

Marc


On Apr 14, 2014, at 7:28 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>>    on Sun, 13 Apr 2014 10:22:55 -0500 writes:
> 
> [on the R-SIG-Mac  mailing list] :	  
> 
>> Hi all,
>> With R version 3.1.0 on OSX, using either the Snow Leopard or the Mavericks binary installation on a Mac with fully updated Mavericks, there has been a change in behavior since 3.0.3.
> 
> I've just written to R-core about this:
> 
>    R CMD Sweave
> 
> has *serious* problems also in the very simple case when it
> should produce figures: They are not available after the
> completion of R CMD Sweave,
> confirming your  'deletes non tex files created upon batch mode exit'
> 
> So this is not related to OSX only, but also a big problem 
> at least on other *nix descendent platforms, such as Linux.
> 
> In short, failure (no graphic produce in the example below) by
> 
>   R CMD Sweave foo.Rnw
> 
> but all is fine with using Sweave(), as you Marc, noted, and hence with  
> 
>   Rscript -e 'Sweave("foo.Rnw")'
> 
> ... and to answer your question:  
> No this was not intended and is probably one of the bigger / 
> most embarrassing bugs in a newly released version of R
> in my view: 
> 
> Basically  'R CMD Sweave' is partly broken in R 3.1.0.
> Yes, this should never have happened.
> 
> I had to partially revert the R 3.1.0 installation here (our
> statistics dept), by making R 3.0.3 the default 'R'
> for now, as we are relying on 'R CMD Sweave ..' in many places.
> 
> Personally I've never noticed the problem, as I seem to always
> Sweave from ESS (Emacs speaks statistics) which calls  Sweave()
> in R, and that works fine, also in  R 3.1.0, as you've already
> noted 
> 
> Martin Maechler, ETH Zurich
> 
> %------------------------------------------------------------
> \documentclass[12pt]{article}
> \usepackage{Sweave}
> \begin{document}  Just a simple graphic 
> 
> <<qqnorm, fig=TRUE>>= 
> qqnorm(rnorm(20))
> @ 
> 
> and that's all, folks!
> \end{document}
> %------------------------------------------------------------
> 
>> I have a master .Rnw file which runs a series of outputs from multiple R code files, each called in BATCH mode using system() from within the master .Rnw file. The output of the R code files go to separate text files in order to catch some of the function call output that would not otherwise be included in the resultant .tex file due to output redirection.
> 
>> Those text files are then included in the resultant .tex file using, for example:
> 
>> \lstinputlisting[caption={}]{test.out}
> 
>> directives which are included in the .Rnw source file.
> 
>> A simple example to replicate the observed behaviors.
> 
>> The test.Rnw file content:
> 
>> %% R CMD Sweave test.Rnw
>> <<results=tex,echo=false>>=
>> system("R CMD BATCH test.R test.out")
>> @ 
> 
> 
>> The test.R file content:
> 
>> options(echo = FALSE)
>> options(useFancyQuotes = FALSE)
>> installed.packages()
> 
> 
>> On version 3.0.3, the file test.out is created, along with test.tex. test.out contains the output of installed.packages(). I did not include the aforementioned listing directive in test.Rnw here for simplicity.
> 
>> On version 3.1.0, the file test.out is created, but when the R CMD Sweave command exits and returns to the CLI in the console, test.out is deleted, presumably as part of a post R batch session clean up process. The file test.tex is retained.
> 
>> I uninstalled 3.1.0 and reinstalled 3.0.3 and observed the prior behavior. I then tried clean installs of both the Snow Leopard and Mavericks 3.1.0 binaries, with the new behavior observed in both cases.
> 
>> In reading the NEWS file for 3.1.0, there are multiple references to Sweave, but there is nothing explicit about this new behavior. 
> 
>> I should note that when the .Rnw file is run from within an R 3.1.0 interactive session using:
> 
>> Sweave("test.Rnw")
> 
>> the test.out file is created and not deleted upon the function exit, or when exiting the R session back to the console. 
> 
>> Thus, this new behavior seems to be limited to running Sweave from the CLI using R CMD. It is not clear to me if this new behavior is by design or perhaps an unintended consequence of changes elsewhere in Sweave processing or in the handling of R in BATCH mode.
> 
>> When watching the folder where the file output activity takes place, I note that a file .build.timestamp is created and then deleted, which leads me to believe that the new functions fileSnapshot() and changedFiles() are being used in the course of processing R in BATCH mode. If that is correct and there is a clean up step that is occurring upon BATCH mode exit, which deletes all files and folders other than .tex files, is it possible that this process is being overly aggressive? Or if not, is there a way to not have these files deleted or have a protected folder where these files can be retained?
> 
>> Thanks for any insights.
> 
>> Regards,
> 
>> Marc Schwartz


From hb at biostat.ucsf.edu  Mon Apr 14 19:00:45 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 14 Apr 2014 10:00:45 -0700
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <21323.54364.87334.81949@stat.math.ethz.ch>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
Message-ID: <CAFDcVCTQdfrN=r5QqYCagfQ4iR+LigwonVOe=417BqLBvagEGg@mail.gmail.com>

Until fixed, one way to fool R here without changing the vignette or
anything else seems to be (verified on Windows):

mkdir figures
set SWEAVE_OPTIONS=prefix.string=figures/fig
R CMD Sweave foo.Rnw

That obviously has some limitations.

/Henrik


On Mon, Apr 14, 2014 at 5:28 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>>     on Sun, 13 Apr 2014 10:22:55 -0500 writes:
>
> [on the R-SIG-Mac  mailing list] :
>
>     > Hi all,
>     > With R version 3.1.0 on OSX, using either the Snow Leopard or the Mavericks binary installation on a Mac with fully updated Mavericks, there has been a change in behavior since 3.0.3.
>
> I've just written to R-core about this:
>
>     R CMD Sweave
>
> has *serious* problems also in the very simple case when it
> should produce figures: They are not available after the
> completion of R CMD Sweave,
> confirming your  'deletes non tex files created upon batch mode exit'
>
> So this is not related to OSX only, but also a big problem
> at least on other *nix descendent platforms, such as Linux.
>
> In short, failure (no graphic produce in the example below) by
>
>    R CMD Sweave foo.Rnw
>
> but all is fine with using Sweave(), as you Marc, noted, and hence with
>
>    Rscript -e 'Sweave("foo.Rnw")'
>
> ... and to answer your question:
> No this was not intended and is probably one of the bigger /
> most embarrassing bugs in a newly released version of R
> in my view:
>
> Basically  'R CMD Sweave' is partly broken in R 3.1.0.
> Yes, this should never have happened.
>
> I had to partially revert the R 3.1.0 installation here (our
> statistics dept), by making R 3.0.3 the default 'R'
> for now, as we are relying on 'R CMD Sweave ..' in many places.
>
> Personally I've never noticed the problem, as I seem to always
> Sweave from ESS (Emacs speaks statistics) which calls  Sweave()
> in R, and that works fine, also in  R 3.1.0, as you've already
> noted
>
> Martin Maechler, ETH Zurich
>
> %------------------------------------------------------------
> \documentclass[12pt]{article}
> \usepackage{Sweave}
> \begin{document}  Just a simple graphic
>
> <<qqnorm, fig=TRUE>>=
> qqnorm(rnorm(20))
> @
>
> and that's all, folks!
> \end{document}
> %------------------------------------------------------------
>
>     > I have a master .Rnw file which runs a series of outputs from multiple R code files, each called in BATCH mode using system() from within the master .Rnw file. The output of the R code files go to separate text files in order to catch some of the function call output that would not otherwise be included in the resultant .tex file due to output redirection.
>
>     > Those text files are then included in the resultant .tex file using, for example:
>
>     > \lstinputlisting[caption={}]{test.out}
>
>     > directives which are included in the .Rnw source file.
>
>     > A simple example to replicate the observed behaviors.
>
>     > The test.Rnw file content:
>
>     > %% R CMD Sweave test.Rnw
>     > <<results=tex,echo=false>>=
>     > system("R CMD BATCH test.R test.out")
>     > @
>
>
>     > The test.R file content:
>
>     > options(echo = FALSE)
>     > options(useFancyQuotes = FALSE)
>     > installed.packages()
>
>
>     > On version 3.0.3, the file test.out is created, along with test.tex. test.out contains the output of installed.packages(). I did not include the aforementioned listing directive in test.Rnw here for simplicity.
>
>     > On version 3.1.0, the file test.out is created, but when the R CMD Sweave command exits and returns to the CLI in the console, test.out is deleted, presumably as part of a post R batch session clean up process. The file test.tex is retained.
>
>     > I uninstalled 3.1.0 and reinstalled 3.0.3 and observed the prior behavior. I then tried clean installs of both the Snow Leopard and Mavericks 3.1.0 binaries, with the new behavior observed in both cases.
>
>     > In reading the NEWS file for 3.1.0, there are multiple references to Sweave, but there is nothing explicit about this new behavior.
>
>     > I should note that when the .Rnw file is run from within an R 3.1.0 interactive session using:
>
>     > Sweave("test.Rnw")
>
>     > the test.out file is created and not deleted upon the function exit, or when exiting the R session back to the console.
>
>     > Thus, this new behavior seems to be limited to running Sweave from the CLI using R CMD. It is not clear to me if this new behavior is by design or perhaps an unintended consequence of changes elsewhere in Sweave processing or in the handling of R in BATCH mode.
>
>     > When watching the folder where the file output activity takes place, I note that a file .build.timestamp is created and then deleted, which leads me to believe that the new functions fileSnapshot() and changedFiles() are being used in the course of processing R in BATCH mode. If that is correct and there is a clean up step that is occurring upon BATCH mode exit, which deletes all files and folders other than .tex files, is it possible that this process is being overly aggressive? Or if not, is there a way to not have these files deleted or have a protected folder where these files can be retained?
>
>     > Thanks for any insights.
>
>     > Regards,
>
>     > Marc Schwartz
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From melikamp at melikamp.com  Mon Apr 14 18:45:53 2014
From: melikamp at melikamp.com (Ivan Zaigralin)
Date: Mon, 14 Apr 2014 12:45:53 -0400
Subject: [Rd] question about code signing
Message-ID: <534C10C1.6060807@melikamp.com>

Greetings!

I maintain R SlackBuild for Slackware and derivatives, and it would make me
sleep easier if I could verify gpg signatures of the sources I refer to.
Is there any way to get the source signed with gpg, by any chance, preferably
in tarball form?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 901 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140414/89658104/attachment.bin>

From skyebend at skyeome.net  Mon Apr 14 23:36:51 2014
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Mon, 14 Apr 2014 14:36:51 -0700
Subject: [Rd] best way to write tests when sort() evaluates differently in R
 CMD check due to LC_COLLATE locale setting?
Message-ID: <534C54F3.7020101@skyeome.net>

Dear R devel,

What is the correct way to write package tests that could possibly fail 
due to locale collation behavior?  Is it safe/proper for me to call 
Sys.setlocale("LC_COLLATE", "en_US.UTF-8")  in each test file? Or should 
I explicitly force collation to C before writing tests?  Or do I need to 
always call sort() on my comparison objects to ensure they are sorted in 
the same locale-specific way?

I'd had a strange situation where a package test I'm writing fails R CMD 
check, but runs fine in the R terminal.  I eventually got to the point 
where I can see that in R CMD check, the vector I'm comparing to 
evaluate the test result did not seem to be sorted as requested. Further 
digging revealed that the locale's LC_COLLATE value is set to 'C' in R 
CMD check while it is "en_US.UTF-8" in my R terminal.

Now that I know what to look for in the documentation, I realize that 
this is a feature. p.36 of "Writing R Extensions" states:

"All these tests are run with collation set to the C
locale, and for the examples and tests with environment variable
LANGUAGE=en: this is to minimize differences between platforms. "

It appears that this impacts the sort order of capital letters

 > Sys.setlocale("LC_COLLATE", "C")
[1] "C"
 > sort(c("a",'A','b','c'))
[1] "A" "a" "b" "c"
 > Sys.setlocale("LC_COLLATE", "en_US.UTF-8")
[1] "en_US.UTF-8"
 > sort(c("a",'A','b','c'))
[1] "a" "A" "b" "c"

best,
  -skye


From murdoch.duncan at gmail.com  Tue Apr 15 13:14:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Apr 2014 07:14:55 -0400
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
Message-ID: <534D14AF.8020500@gmail.com>

On 14/04/2014, 10:23 AM, Marc Schwartz wrote:
> Hi Martin,
>
> Thanks for your confirmation on this.
>
> I normally do not use R CMD Sweave, as I too run under ESS in normal day to day operations. This finding was a quirk of having a particular Rnw document that I occasionally run using R CMD Sweave and I had done so over the weekend, realizing this behavior.

This sounds like an argument for dropping R CMD Sweave, rather than 
fixing it.  The bug was introduced in July, 2013, and nobody noticed it 
because so few people use that feature, and apparently nobody who does 
use it bothers to test pre-release versions.

Duncan Murdoch

> Thanks again.
>
> Regards,
>
> Marc
>
>
> On Apr 14, 2014, at 7:28 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>
>>>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>>>     on Sun, 13 Apr 2014 10:22:55 -0500 writes:
>>
>> [on the R-SIG-Mac  mailing list] :	
>>
>>> Hi all,
>>> With R version 3.1.0 on OSX, using either the Snow Leopard or the Mavericks binary installation on a Mac with fully updated Mavericks, there has been a change in behavior since 3.0.3.
>>
>> I've just written to R-core about this:
>>
>>     R CMD Sweave
>>
>> has *serious* problems also in the very simple case when it
>> should produce figures: They are not available after the
>> completion of R CMD Sweave,
>> confirming your  'deletes non tex files created upon batch mode exit'
>>
>> So this is not related to OSX only, but also a big problem
>> at least on other *nix descendent platforms, such as Linux.
>>
>> In short, failure (no graphic produce in the example below) by
>>
>>    R CMD Sweave foo.Rnw
>>
>> but all is fine with using Sweave(), as you Marc, noted, and hence with
>>
>>    Rscript -e 'Sweave("foo.Rnw")'
>>
>> ... and to answer your question:
>> No this was not intended and is probably one of the bigger /
>> most embarrassing bugs in a newly released version of R
>> in my view:
>>
>> Basically  'R CMD Sweave' is partly broken in R 3.1.0.
>> Yes, this should never have happened.
>>
>> I had to partially revert the R 3.1.0 installation here (our
>> statistics dept), by making R 3.0.3 the default 'R'
>> for now, as we are relying on 'R CMD Sweave ..' in many places.
>>
>> Personally I've never noticed the problem, as I seem to always
>> Sweave from ESS (Emacs speaks statistics) which calls  Sweave()
>> in R, and that works fine, also in  R 3.1.0, as you've already
>> noted
>>
>> Martin Maechler, ETH Zurich
>>
>> %------------------------------------------------------------
>> \documentclass[12pt]{article}
>> \usepackage{Sweave}
>> \begin{document}  Just a simple graphic
>>
>> <<qqnorm, fig=TRUE>>=
>> qqnorm(rnorm(20))
>> @
>>
>> and that's all, folks!
>> \end{document}
>> %------------------------------------------------------------
>>
>>> I have a master .Rnw file which runs a series of outputs from multiple R code files, each called in BATCH mode using system() from within the master .Rnw file. The output of the R code files go to separate text files in order to catch some of the function call output that would not otherwise be included in the resultant .tex file due to output redirection.
>>
>>> Those text files are then included in the resultant .tex file using, for example:
>>
>>> \lstinputlisting[caption={}]{test.out}
>>
>>> directives which are included in the .Rnw source file.
>>
>>> A simple example to replicate the observed behaviors.
>>
>>> The test.Rnw file content:
>>
>>> %% R CMD Sweave test.Rnw
>>> <<results=tex,echo=false>>=
>>> system("R CMD BATCH test.R test.out")
>>> @
>>
>>
>>> The test.R file content:
>>
>>> options(echo = FALSE)
>>> options(useFancyQuotes = FALSE)
>>> installed.packages()
>>
>>
>>> On version 3.0.3, the file test.out is created, along with test.tex. test.out contains the output of installed.packages(). I did not include the aforementioned listing directive in test.Rnw here for simplicity.
>>
>>> On version 3.1.0, the file test.out is created, but when the R CMD Sweave command exits and returns to the CLI in the console, test.out is deleted, presumably as part of a post R batch session clean up process. The file test.tex is retained.
>>
>>> I uninstalled 3.1.0 and reinstalled 3.0.3 and observed the prior behavior. I then tried clean installs of both the Snow Leopard and Mavericks 3.1.0 binaries, with the new behavior observed in both cases.
>>
>>> In reading the NEWS file for 3.1.0, there are multiple references to Sweave, but there is nothing explicit about this new behavior.
>>
>>> I should note that when the .Rnw file is run from within an R 3.1.0 interactive session using:
>>
>>> Sweave("test.Rnw")
>>
>>> the test.out file is created and not deleted upon the function exit, or when exiting the R session back to the console.
>>
>>> Thus, this new behavior seems to be limited to running Sweave from the CLI using R CMD. It is not clear to me if this new behavior is by design or perhaps an unintended consequence of changes elsewhere in Sweave processing or in the handling of R in BATCH mode.
>>
>>> When watching the folder where the file output activity takes place, I note that a file .build.timestamp is created and then deleted, which leads me to believe that the new functions fileSnapshot() and changedFiles() are being used in the course of processing R in BATCH mode. If that is correct and there is a clean up step that is occurring upon BATCH mode exit, which deletes all files and folders other than .tex files, is it possible that this process is being overly aggressive? Or if not, is there a way to not have these files deleted or have a protected folder where these files can be retained?
>>
>>> Thanks for any insights.
>>
>>> Regards,
>>
>>> Marc Schwartz
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pdalgd at gmail.com  Tue Apr 15 14:12:31 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 15 Apr 2014 14:12:31 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
	batch mode exit
In-Reply-To: <534D14AF.8020500@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
Message-ID: <2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>


On 15 Apr 2014, at 13:14 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 14/04/2014, 10:23 AM, Marc Schwartz wrote:
>> Hi Martin,
>> 
>> Thanks for your confirmation on this.
>> 
>> I normally do not use R CMD Sweave, as I too run under ESS in normal day to day operations. This finding was a quirk of having a particular Rnw document that I occasionally run using R CMD Sweave and I had done so over the weekend, realizing this behavior.
> 
> This sounds like an argument for dropping R CMD Sweave, rather than fixing it.  The bug was introduced in July, 2013, and nobody noticed it because so few people use that feature, and apparently nobody who does use it bothers to test pre-release versions.
> 

I'd say that that cat is out of the bag. There are probably umpteen documents around suggesting "R CMD Sweave". As people use Sweave only sporadically, it could take years before the old usage got stamped out. And anyways, the command format is the obvious way to generate documents in scripts and makefiles, isn't it?

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From csardi.gabor at gmail.com  Tue Apr 15 14:24:22 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 15 Apr 2014 08:24:22 -0400
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <534D14AF.8020500@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
Message-ID: <CABtg=KmhEf6c+3J47tfAW32rZE+hNiaS3Cwx89n0Ypn+eSN_Ug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140415/9016db80/attachment.pl>

From murdoch.duncan at gmail.com  Tue Apr 15 14:54:34 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Apr 2014 08:54:34 -0400
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
Message-ID: <534D2C0A.3090502@gmail.com>

On 15/04/2014 8:12 AM, peter dalgaard wrote:
> On 15 Apr 2014, at 13:14 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> > On 14/04/2014, 10:23 AM, Marc Schwartz wrote:
> >> Hi Martin,
> >>
> >> Thanks for your confirmation on this.
> >>
> >> I normally do not use R CMD Sweave, as I too run under ESS in normal day to day operations. This finding was a quirk of having a particular Rnw document that I occasionally run using R CMD Sweave and I had done so over the weekend, realizing this behavior.
> >
> > This sounds like an argument for dropping R CMD Sweave, rather than fixing it.  The bug was introduced in July, 2013, and nobody noticed it because so few people use that feature, and apparently nobody who does use it bothers to test pre-release versions.
> >
>
> I'd say that that cat is out of the bag. There are probably umpteen documents around suggesting "R CMD Sweave". As people use Sweave only sporadically, it could take years before the old usage got stamped out. And anyways, the command format is the obvious way to generate documents in scripts and makefiles, isn't it?
>

I use Rscript, and I expect most others do too, but I was wrong about 
how long this went unreported.  Martin Morgan reported it in February in 
R-devel and I didn't notice.  He even gave a link to it in a message in 
March on another topic; I replied to the March message, but didn't 
follow the link.

We discourage people from using bugs.r-project.org for pre-release 
issues; perhaps we shouldn't do that.

Duncan Murdoch


From h.wickham at gmail.com  Tue Apr 15 16:11:11 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 15 Apr 2014 09:11:11 -0500
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <534D2C0A.3090502@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
Message-ID: <CABdHhvFVZRv2w3v9ByzRw9NmXZw7TNqxWOTLJvQteH2udv+cPw@mail.gmail.com>

> I use Rscript, and I expect most others do too, but I was wrong about how
> long this went unreported.  Martin Morgan reported it in February in R-devel
> and I didn't notice.  He even gave a link to it in a message in March on
> another topic; I replied to the March message, but didn't follow the link.
>
> We discourage people from using bugs.r-project.org for pre-release issues;
> perhaps we shouldn't do that.

Regardless of the venue, the cost for submitting an issue that doesn't
turn out to be a bug is quite high - you're likely to get a nasty
message. If you want more people to submit bug reports, I think you
have to be prepared to receive reports about things that users think
are bugs, but developers do not. If you want to encourage people to
submit bugs, then you have to make it a pleasant (or at least not
unpleasant) experience.

Hadley

-- 
http://had.co.nz/


From benjamin.hofner at imbe.med.uni-erlangen.de  Tue Apr 15 15:12:16 2014
From: benjamin.hofner at imbe.med.uni-erlangen.de (Benjamin Hofner)
Date: Tue, 15 Apr 2014 15:12:16 +0200
Subject: [Rd] Problem: Importing two packages which export a function with
 the same name
Message-ID: <534D3030.40303@imbe.med.uni-erlangen.de>

Hi all,

I am currently updating our package gamboostLSS which depends on package 
mboost *and* on package gamlss.dist. From mboost we use a lot of the 
fitting infrastructure and from gamlss.dist we obtain the relevant loss 
functions (aka families) used for fitting and corresponding quantile 
functions. Furthermore, we use the Family() function from package mboost.

However, if I depend on both packages, mboost::Family is always masked 
by a function of the same name from package gamlss.dist.

I tried to change the order of mboost and gamlss.dist in both my 
NAMESPACE and my DESCRIPTION file but couldn't see any difference in the 
result: gamlss.dist is always loaded after mboost and thus it breaks my 
code.

Actually, I would love to use something similar to importFrom() with a 
pattern that excludes Family, i.e.,

importFrom(gamlss.dist, exclude_pattern = "Family")

or the same with an include pattern designed to exclude Family in my 
NAMESPACE. Is this possible anyhow?

As gamlss.dist keeps evolving over time with more families to be added, 
I cannot manually importFrom(...) all the relevant families. I would 
have to change the list of functions all the time.

Thanks and all the best,
Benjamin


From arnima at hafro.is  Tue Apr 15 19:48:33 2014
From: arnima at hafro.is (Arni Magnusson)
Date: Tue, 15 Apr 2014 17:48:33 +0000 (UTC)
Subject: [Rd] ASCIIfy() - a proposal for package:tools
Message-ID: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>

Hi all,

I would like to propose the attached function ASCIIfy() to be added to the 
'tools' package.

Non-ASCII characters in character vectors can be problematic for R 
packages, but sometimes they cannot be avoided. To make packages portable 
and build without 'R CMD check' warnings, my solution has been to convert 
problematic characters in functions and datasets to escaped ASCII, so 
plot(1,main="S?o Paulo") becomes plot(1,main="S\u00e3o Paulo").

The showNonASCII() function in package:tools is helpful to identify R 
source files where characters should be converted to ASCII one way or 
another, but I could not find a function to actually perform the 
conversion to ASCII.

I have written the function ASCIIfy() to convert character vectors to 
ASCII. I imagine other R package developers might be looking for a similar 
tool, and it seems to me that package:tools is the first place they would 
look, where the R Core Team has provided a variety of tools for handling 
non-ASCII characters in package development.

I hope the R Core Team will adopt ASCIIfy() into the 'tools' package, to 
make life easier for package developers outside the English-speaking 
world. I have of course no problem with them renaming or rewriting the 
function in any way.

See the attached examples - all in flat ASCII that was prepared using the 
function itself! The main objective, though, is to ASCIIfy functions and 
datasets, not help pages.

Arni
-------------- next part --------------
ASCIIfy <- function(string, bytes=2, fallback="?")
{
  bytes <- match.arg(as.character(bytes), 1:2)
  convert <- function(char)  # convert to ASCII, e.g. "z", "\xfe", or "\u00fe"
  {
    raw <- charToRaw(char)
    if(length(raw)==1 && raw<=127)  # 7-bit
      ascii <- char
    else if(length(raw)==1 && bytes==1)  # 8-bit to \x00
      ascii <- paste0("\\x", raw)
    else if(length(raw)==1 && bytes==2)  # 8-bit to \u0000
      ascii <- paste0("\\u", chartr(" ","0",formatC(as.character(raw),width=4)))
    else if(length(raw)==2 && bytes==1)  # 16-bit to \x00, if possible
      if(utf8ToInt(char) <= 255)
        ascii <- paste0("\\x", format.hexmode(utf8ToInt(char)))
      else {
        ascii <- fallback; warning(char, " could not be converted to 1 byte")}
    else if(length(raw)==2 && bytes==2)  # UTF-8 to \u0000
      ascii <- paste0("\\u", format.hexmode(utf8ToInt(char),width=4))
    else {
      ascii <- fallback
      warning(char, " could not be converted to ", bytes, " byte")}
    return(ascii)
  }

  if(length(string) > 1)
  {
    sapply(string, ASCIIfy, bytes=bytes, fallback=fallback, USE.NAMES=FALSE)
  }
  else
  {
    input <- unlist(strsplit(string,""))  # "c"  "a"  "f"  "<\'e>"
    output <- character(length(input))    # ""   ""   ""   ""
    for(i in seq_along(input))
      output[i] <- convert(input[i])      # "c"  "a"  "f"  "\\u00e9"
    output <- paste(output, collapse="")  # "caf\\u00e9"
    return(output)
  }
}
-------------- next part --------------
\name{ASCIIfy}
\alias{ASCIIfy}
\title{Convert Characters to ASCII}
\description{
  Convert character vector to ASCII, replacing non-ASCII characters with
  single-byte (\samp{\x00}) or two-byte (\samp{\u0000}) codes.
}
\usage{
ASCIIfy(x, bytes = 2, fallback = "?")
}
\arguments{
  \item{x}{a character vector, possibly containing non-ASCII
    characters.}
  \item{bytes}{either \code{1} or \code{2}, for single-byte
    (\samp{\x00}) or two-byte (\samp{\u0000}) codes.}
  \item{fallback}{an output character to use, when input characters
    cannot be converted.}
}
\value{
  A character vector like \code{x}, except non-ASCII characters have
  been replaced with \samp{\x00} or \samp{\u0000} codes.
}
\author{Arni Magnusson.}
\note{
  To render single backslashes, use these or similar techniques:
  \verb{
    write(ASCIIfy(x), "file.txt")
    cat(paste(ASCIIfy(x), collapse="\n"), "\n", sep="")}

  The resulting strings are plain ASCII and can be used in R functions
  and datasets to improve package portability.
}
\seealso{
  \code{\link[tools]{showNonASCII}} identifies non-ASCII characters in
  a character vector.
}
\examples{
cities <- c("S\u00e3o Paulo", "Reykjav\u00edk")
print(cities)
ASCIIfy(cities, 1)
ASCIIfy(cities, 2)

athens <- "\u0391\u03b8\u03ae\u03bd\u03b1"
print(athens)
ASCIIfy(athens)
}
\keyword{}

From greg at warnes.net  Tue Apr 15 21:17:38 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Tue, 15 Apr 2014 15:17:38 -0400
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
	batch mode exit
In-Reply-To: <CABdHhvFVZRv2w3v9ByzRw9NmXZw7TNqxWOTLJvQteH2udv+cPw@mail.gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
	<CABdHhvFVZRv2w3v9ByzRw9NmXZw7TNqxWOTLJvQteH2udv+cPw@mail.gmail.com>
Message-ID: <A42039D4-EAB9-413A-9796-E612BD2C45D5@warnes.net>

I have, at times, been a heavy user of R CMD Sweave and would prefer to see it fixed!   

I encountered this error while preparing notes for a guest lecture last fall, and was too busy to identify the source of the error, so worked around it (thank goodness for version control, making file restores easy) rather than reporting the bug?.

-Greg

On Apr 15, 2014, at 10:11 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

>> I use Rscript, and I expect most others do too, but I was wrong about how
>> long this went unreported.  Martin Morgan reported it in February in R-devel
>> and I didn't notice.  He even gave a link to it in a message in March on
>> another topic; I replied to the March message, but didn't follow the link.
>> 
>> We discourage people from using bugs.r-project.org for pre-release issues;
>> perhaps we shouldn't do that.
> 
> Regardless of the venue, the cost for submitting an issue that doesn't
> turn out to be a bug is quite high - you're likely to get a nasty
> message. If you want more people to submit bug reports, I think you
> have to be prepared to receive reports about things that users think
> are bugs, but developers do not. If you want to encourage people to
> submit bugs, then you have to make it a pleasant (or at least not
> unpleasant) experience.
> 
> Hadley
> 
> -- 
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Wed Apr 16 05:27:59 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 15 Apr 2014 20:27:59 -0700
Subject: [Rd] duplication regression (?)
In-Reply-To: <CAE3=dmcfuEOXjoEGcj4+MrWp-Waur4Nb+saPH2OnSkdANc+skA@mail.gmail.com>
References: <CAE3=dmcfuEOXjoEGcj4+MrWp-Waur4Nb+saPH2OnSkdANc+skA@mail.gmail.com>
Message-ID: <CAOQ5NyfQOnKMj32gxOdLA36zLbMBuYdxSyAf3X1epPxcUZkktg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140415/1e634e7e/attachment.pl>

From geoffjentry at hexdump.org  Wed Apr 16 16:23:13 2014
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Wed, 16 Apr 2014 07:23:13 -0700 (PDT)
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
Message-ID: <alpine.DEB.2.00.1404160722070.10135@cardinals.dreamhost.com>

On Tue, 15 Apr 2014, peter dalgaard wrote:
> I'd say that that cat is out of the bag. There are probably umpteen 
> documents around suggesting "R CMD Sweave". As people use Sweave only 
> sporadically, it could take years before the old usage got stamped out. 
> And anyways, the command format is the obvious way to generate documents 
> in scripts and makefiles, isn't it?

A majority of my Sweave building is done by R CMD Sweave, I just 
infrequently build Sweave documents. I've started transitioning to RStudio 
for this but only in certain situations.


From csardi.gabor at gmail.com  Wed Apr 16 19:55:47 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 16 Apr 2014 13:55:47 -0400
Subject: [Rd] R 3.0.3 for OSX
Message-ID: <CABtg=KkcFARVkAjHT=jEisbsxmwUxNqxqYKW4HDFGD80aq_VtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140416/d83500e2/attachment.pl>

From simon.urbanek at r-project.org  Wed Apr 16 20:39:59 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 16 Apr 2014 14:39:59 -0400
Subject: [Rd] R 3.0.3 for OSX
In-Reply-To: <CABtg=KkcFARVkAjHT=jEisbsxmwUxNqxqYKW4HDFGD80aq_VtA@mail.gmail.com>
References: <CABtg=KkcFARVkAjHT=jEisbsxmwUxNqxqYKW4HDFGD80aq_VtA@mail.gmail.com>
Message-ID: <7C5B2CFC-802A-4032-A0B9-B25AF7201FB9@r-project.org>

On Apr 16, 2014, at 1:55 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> The R-3.0.3 pkg is missing from here:
> http://cran.r-project.org/bin/macosx/old/
> 
> Is this intended?

No - now fixed.

> Anyone knows where to get it?
> 

http://cran.r-project.org/bin/macosx/R-3.0.3.pkg

Cheers,
Simon


> Thanks,
> Gabor
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From csardi.gabor at gmail.com  Wed Apr 16 21:00:11 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 16 Apr 2014 15:00:11 -0400
Subject: [Rd] R 3.0.3 for OSX
In-Reply-To: <7C5B2CFC-802A-4032-A0B9-B25AF7201FB9@r-project.org>
References: <CABtg=KkcFARVkAjHT=jEisbsxmwUxNqxqYKW4HDFGD80aq_VtA@mail.gmail.com>
	<7C5B2CFC-802A-4032-A0B9-B25AF7201FB9@r-project.org>
Message-ID: <CABtg=KmQNne7DG645kX7TavjzreVd02TvThH6qO5gPZ2fVK-GA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140416/9ba4e0e6/attachment.pl>

From simon.urbanek at r-project.org  Wed Apr 16 21:06:32 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 16 Apr 2014 15:06:32 -0400
Subject: [Rd] R 3.0.3 for OSX
In-Reply-To: <CABtg=KmQNne7DG645kX7TavjzreVd02TvThH6qO5gPZ2fVK-GA@mail.gmail.com>
References: <CABtg=KkcFARVkAjHT=jEisbsxmwUxNqxqYKW4HDFGD80aq_VtA@mail.gmail.com>
	<7C5B2CFC-802A-4032-A0B9-B25AF7201FB9@r-project.org>
	<CABtg=KmQNne7DG645kX7TavjzreVd02TvThH6qO5gPZ2fVK-GA@mail.gmail.com>
Message-ID: <23275410-6E85-47ED-8459-8032F5BC6C72@r-project.org>


On Apr 16, 2014, at 3:00 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Wed, Apr 16, 2014 at 2:39 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> On Apr 16, 2014, at 1:55 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> > The R-3.0.3 pkg is missing from here:
> > http://cran.r-project.org/bin/macosx/old/
> >
> > Is this intended?
> 
> No - now fixed.
> 
> I must be missing something, but can't see it there.....
>  
> 
> > Anyone knows where to get it?
> >
> 
> http://cran.r-project.org/bin/macosx/R-3.0.3.pkg
> 
> Thanks. Maybe it is worth to put a link on it from the web pages, or put it in the old/ directory, so that people can find it easier.
> 

Yes, it's there now:

http://r.research.att.com/bin/macosx/old/

The mirrors will pick it up on the next sync.

Cheers,
Simon


> Gabor
>  
> 
> 
> Cheers,
> Simon
> 
> 
> > Thanks,
> > Gabor
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 


From maechler at stat.math.ethz.ch  Thu Apr 17 11:22:04 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Apr 2014 11:22:04 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <534D2C0A.3090502@gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
Message-ID: <21327.40252.449500.713638@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Tue, 15 Apr 2014 08:54:34 -0400 writes:

    > On 15/04/2014 8:12 AM, peter dalgaard wrote:
    >> On 15 Apr 2014, at 13:14 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
    >> 
    >> > On 14/04/2014, 10:23 AM, Marc Schwartz wrote:
    >> >> Hi Martin,
    >> >>
    >> >> Thanks for your confirmation on this.
    >> >>
    >> >> I normally do not use R CMD Sweave, as I too run under ESS in normal day to day operations. This finding was a quirk of having a particular Rnw document that I occasionally run using R CMD Sweave and I had done so over the weekend, realizing this behavior.
    >> >
    >> > This sounds like an argument for dropping R CMD Sweave, rather than fixing it.  The bug was introduced in July, 2013, and nobody noticed it because so few people use that feature, and apparently nobody who does use it bothers to test pre-release versions.
    >> >
    >> 
    >> I'd say that that cat is out of the bag. There are probably umpteen documents around suggesting "R CMD Sweave". As people use Sweave only sporadically, it could take years before the old usage got stamped out. And anyways, the command format is the obvious way to generate documents in scripts and makefiles, isn't it?
    >> 

    > I use Rscript, and I expect most others do too, but I was wrong about 
    > how long this went unreported.  Martin Morgan reported it in February in 
    > R-devel and I didn't notice.  He even gave a link to it in a message in 
    > March on another topic; I replied to the March message, but didn't 
    > follow the link.

    > We discourage people from using bugs.r-project.org for pre-release 
    > issues; perhaps we shouldn't do that.

    > Duncan Murdoch

I agree:  Rather we should encourage such volunteer testers reporting
such problems.

The 'R version' is already part of the bug report form;
I'm not sure we can easily *list* all the "R version == R-devel"
bugs easily via web interface, but even w/o that,
we should rather be glad for such reports.

PS: I'm currently testing a patch where 'R CMD Sweave' will
    revert to not deleting anything after running the R code by default.

Martin Maechler


From csardi.gabor at gmail.com  Thu Apr 17 15:30:23 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 09:30:23 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
Message-ID: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/335f1929/attachment.pl>

From Robert.McGehee at geodecapital.com  Thu Apr 17 15:42:20 2014
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 17 Apr 2014 09:42:20 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <534860CC.2090206@gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
Message-ID: <17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>

Hi,
As Greg suggested, this new feature in type.convert certainly did surprise one user (me), enough so that I had to downgrade back to 3.0.3 until our code was modified to handle the new behavior.

Here's my use case: I have a function that pulls arbitrary financial data from a web service call such as a stock's industry, price, volume, etc. by reading the web output as a text table. The data may be either character (industry, stock name, etc.) or numeric (price, volume, etc.), and the function generally doesn't know the class in advance. The problem is that we frequently get numeric values represented with more precision than actually exists, for instance a price of "2.6999999999999999" rather than "2.70". The numeric representation is exactly one digit too much for type.convert which (in R 3.10.0) converts it to character instead of numeric (not what I want). This caused a bunch of "non-numeric argument to binary operator" errors to appear today as numeric data was now being represented as characters.

I have no doubt that this probably will cause some unwanted RODBC side effects for us as well. IMO, getting the class right is more important than infinite precision. What use is a character representation of a number anyway if you can't perform arithmetic on it? I would favor at least making the new behavior optional, but I think many packages (like RODBC) potentially need to be patched to code around the new feature if it's left in.

(This aside, thanks for all the nice features and bug fixes in the new version!)
Cheers, Robert

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Paul Gilbert
Sent: Friday, April 11, 2014 5:38 PM
To: Simon Urbanek; Gregory R. Warnes
Cc: R-devel
Subject: Re: [Rd] type.convert and doubles



On 04/11/2014 01:43 PM, Simon Urbanek wrote:
> Greg,
>
> On Apr 11, 2014, at 11:50 AM, Gregory R. Warnes <greg at warnes.net>
> wrote:
>
>> Hi All,
>>
>> I see this in the NEWS for R 3.1.0:
>>
>> type.convert() (and hence by default read.table()) returns a
>> character vector or factor when representing a numeric input as a
>> double would lose accuracy. Similarly for complex inputs.
>>
>> This behavior seems likely to surprise users.
>
> Can you elaborate why that would be surprising? It is consistent with
> the intention of type.convert() to determine the correct type to
> represent the value - it has always used character/factor as a
> fallback where native type doesn't match.

Strictly speaking, I don't think this is true. If it were, it would not 
have been necessary to make the change so that it does now fallback to 
using character/factor. It may, however, have always been the intent.

I don't really think a warning is necessary, but there are some surprises:

 > str(type.convert(format(1/3, digits=17))) # R-3.0.3
  num 0.333

 > str(type.convert(format(1/3, digits=17))) # R-3.1.0
  Factor w/ 1 level "0.33333333333333331": 1

Now you could say that one should never do that, and the change is just 
flushing out a bug that was always there. But the point is that in 
serialization situations there can be some surprises. So, for example, 
RODBC talking to PostgresSQL databases is now returning factors rather 
than numerics for double precision fields, whereas with RPostgresSQL the 
behaviour has not changed.

Paul

It has never issued any
> warning in that case historically, so IMHO it would be rather
> surprising if it did now...
>
> Cheers, Simon
>
>
>> Would it be possible to issue a warning when this occurs?
>>
>> Aside: I'm very happy to see the new 's' and 'f' browser (debugger)
>> commands!
>>
>> -Greg [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Apr 17 15:46:33 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Apr 2014 09:46:33 -0400
Subject: [Rd] ASCIIfy() - a proposal for package:tools
In-Reply-To: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>
References: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>
Message-ID: <534FDB39.9010506@gmail.com>

Nobody else has replied to this, so I will.  It's very unlikely that we 
would incorporate this function into base R.  For one thing, the tools 
package is intended to be tools used by R, not by users.  R doesn't need 
this function, so it doesn't belong in tools.  (Some other functions in 
tools like showNonASCII have come to be used by users, but their primary 
purpose is for R.)

Utility functions that are maintained by R Core and are useful to users 
belong in the utils package.  But I wouldn't add ASCIIfy to that package 
either, because I don't want to impose its maintenance on R Core.

Utility functions that are maintained by others belong in contributed 
packages.  So I'd suggest that you add this function to some package 
that you maintain (perhaps a new one, containing a collection of related 
utility functions), or search CRAN for an appropriate package with a 
maintainer who is willing to take this on.

Duncan Murdoch

On 15/04/2014 1:48 PM, Arni Magnusson wrote:
> Hi all,
>
> I would like to propose the attached function ASCIIfy() to be added to the
> 'tools' package.
>
> Non-ASCII characters in character vectors can be problematic for R
> packages, but sometimes they cannot be avoided. To make packages portable
> and build without 'R CMD check' warnings, my solution has been to convert
> problematic characters in functions and datasets to escaped ASCII, so
> plot(1,main="S?o Paulo") becomes plot(1,main="S\u00e3o Paulo").
>
> The showNonASCII() function in package:tools is helpful to identify R
> source files where characters should be converted to ASCII one way or
> another, but I could not find a function to actually perform the
> conversion to ASCII.
>
> I have written the function ASCIIfy() to convert character vectors to
> ASCII. I imagine other R package developers might be looking for a similar
> tool, and it seems to me that package:tools is the first place they would
> look, where the R Core Team has provided a variety of tools for handling
> non-ASCII characters in package development.
>
> I hope the R Core Team will adopt ASCIIfy() into the 'tools' package, to
> make life easier for package developers outside the English-speaking
> world. I have of course no problem with them renaming or rewriting the
> function in any way.
>
> See the attached examples - all in flat ASCII that was prepared using the
> function itself! The main objective, though, is to ASCIIfy functions and
> datasets, not help pages.
>
> Arni
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu Apr 17 15:49:08 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 17 Apr 2014 08:49:08 -0500
Subject: [Rd] type.convert and doubles
In-Reply-To: <534860CC.2090206@gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
Message-ID: <CABdHhvHNhps=YKK712Y+5iMeo8TyBY+60KT7tc3fSX-kSotn7A@mail.gmail.com>

> Strictly speaking, I don't think this is true. If it were, it would not have
> been necessary to make the change so that it does now fallback to using
> character/factor. It may, however, have always been the intent.
>
> I don't really think a warning is necessary, but there are some surprises:
>
>> str(type.convert(format(1/3, digits=17))) # R-3.0.3
>  num 0.333
>
>> str(type.convert(format(1/3, digits=17))) # R-3.1.0
>  Factor w/ 1 level "0.33333333333333331": 1

It is bizarre that it makes a factor rather than a string.
0.333333333333 is pretty obviously not a categorical value.

Hadley

-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Thu Apr 17 15:59:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Apr 2014 09:59:16 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <534FDE34.3090602@gmail.com>

On 17/04/2014 9:42 AM, McGehee, Robert wrote:
> Hi,
> As Greg suggested, this new feature in type.convert certainly did surprise one user (me), enough so that I had to downgrade back to 3.0.3 until our code was modified to handle the new behavior.

I don't have an opinion on this particular change, but one way to avoid 
surprises like this is to test releases when they become available.  For 
3.1.0, the alpha became available on March 13.

If you are especially eager, you can follow the news feed at 
http://developer.r-project.org/blosxom.cgi/R-devel/NEWS.  This 
particular change was announced there more than a year ago 
(http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2013/03/19), 
and has shown up several times since as minor edits have been made to 
the announcement.

Duncan Murdoch
>
> Here's my use case: I have a function that pulls arbitrary financial data from a web service call such as a stock's industry, price, volume, etc. by reading the web output as a text table. The data may be either character (industry, stock name, etc.) or numeric (price, volume, etc.), and the function generally doesn't know the class in advance. The problem is that we frequently get numeric values represented with more precision than actually exists, for instance a price of "2.6999999999999999" rather than "2.70". The numeric representation is exactly one digit too much for type.convert which (in R 3.10.0) converts it to character instead of numeric (not what I want). This caused a bunch of "non-numeric argument to binary operator" errors to appear today as numeric data was now being represented as characters.
>
> I have no doubt that this probably will cause some unwanted RODBC side effects for us as well. IMO, getting the class right is more important than infinite precision. What use is a character representation of a number anyway if you can't perform arithmetic on it? I would favor at least making the new behavior optional, but I think many packages (like RODBC) potentially need to be patched to code around the new feature if it's left in.
>
> (This aside, thanks for all the nice features and bug fixes in the new version!)
> Cheers, Robert
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Paul Gilbert
> Sent: Friday, April 11, 2014 5:38 PM
> To: Simon Urbanek; Gregory R. Warnes
> Cc: R-devel
> Subject: Re: [Rd] type.convert and doubles
>
>
>
> On 04/11/2014 01:43 PM, Simon Urbanek wrote:
> > Greg,
> >
> > On Apr 11, 2014, at 11:50 AM, Gregory R. Warnes <greg at warnes.net>
> > wrote:
> >
> >> Hi All,
> >>
> >> I see this in the NEWS for R 3.1.0:
> >>
> >> type.convert() (and hence by default read.table()) returns a
> >> character vector or factor when representing a numeric input as a
> >> double would lose accuracy. Similarly for complex inputs.
> >>
> >> This behavior seems likely to surprise users.
> >
> > Can you elaborate why that would be surprising? It is consistent with
> > the intention of type.convert() to determine the correct type to
> > represent the value - it has always used character/factor as a
> > fallback where native type doesn't match.
>
> Strictly speaking, I don't think this is true. If it were, it would not
> have been necessary to make the change so that it does now fallback to
> using character/factor. It may, however, have always been the intent.
>
> I don't really think a warning is necessary, but there are some surprises:
>
>   > str(type.convert(format(1/3, digits=17))) # R-3.0.3
>    num 0.333
>
>   > str(type.convert(format(1/3, digits=17))) # R-3.1.0
>    Factor w/ 1 level "0.33333333333333331": 1
>
> Now you could say that one should never do that, and the change is just
> flushing out a bug that was always there. But the point is that in
> serialization situations there can be some surprises. So, for example,
> RODBC talking to PostgresSQL databases is now returning factors rather
> than numerics for double precision fields, whereas with RPostgresSQL the
> behaviour has not changed.
>
> Paul
>
> It has never issued any
> > warning in that case historically, so IMHO it would be rather
> > surprising if it did now...
> >
> > Cheers, Simon
> >
> >
> >> Would it be possible to issue a warning when this occurs?
> >>
> >> Aside: I'm very happy to see the new 's' and 'f' browser (debugger)
> >> commands!
> >>
> >> -Greg [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________ R-devel at r-project.org
> > mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From greg at warnes.net  Thu Apr 17 18:47:04 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Thu, 17 Apr 2014 12:47:04 -0400
Subject: [Rd] ASCIIfy() - a proposal for package:tools
In-Reply-To: <534FDB39.9010506@gmail.com>
References: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>
	<534FDB39.9010506@gmail.com>
Message-ID: <415DFB5A-BE24-4CFC-BF9D-77EE50C6EDEA@warnes.net>

Hi Arni,

I?ll be glad to drop ASCIIfy into gtools.  Let me know if this OK.

-Greg

On Apr 17, 2014, at 9:46 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> Nobody else has replied to this, so I will.  It's very unlikely that we would incorporate this function into base R.  For one thing, the tools package is intended to be tools used by R, not by users.  R doesn't need this function, so it doesn't belong in tools.  (Some other functions in tools like showNonASCII have come to be used by users, but their primary purpose is for R.)
> 
> Utility functions that are maintained by R Core and are useful to users belong in the utils package.  But I wouldn't add ASCIIfy to that package either, because I don't want to impose its maintenance on R Core.
> 
> Utility functions that are maintained by others belong in contributed packages.  So I'd suggest that you add this function to some package that you maintain (perhaps a new one, containing a collection of related utility functions), or search CRAN for an appropriate package with a maintainer who is willing to take this on.
> 
> Duncan Murdoch
> 
> On 15/04/2014 1:48 PM, Arni Magnusson wrote:
>> Hi all,
>> 
>> I would like to propose the attached function ASCIIfy() to be added to the
>> 'tools' package.
>> 
>> Non-ASCII characters in character vectors can be problematic for R
>> packages, but sometimes they cannot be avoided. To make packages portable
>> and build without 'R CMD check' warnings, my solution has been to convert
>> problematic characters in functions and datasets to escaped ASCII, so
>> plot(1,main="S?o Paulo") becomes plot(1,main="S\u00e3o Paulo").
>> 
>> The showNonASCII() function in package:tools is helpful to identify R
>> source files where characters should be converted to ASCII one way or
>> another, but I could not find a function to actually perform the
>> conversion to ASCII.
>> 
>> I have written the function ASCIIfy() to convert character vectors to
>> ASCII. I imagine other R package developers might be looking for a similar
>> tool, and it seems to me that package:tools is the first place they would
>> look, where the R Core Team has provided a variety of tools for handling
>> non-ASCII characters in package development.
>> 
>> I hope the R Core Team will adopt ASCIIfy() into the 'tools' package, to
>> make life easier for package developers outside the English-speaking
>> world. I have of course no problem with them renaming or rewriting the
>> function in any way.
>> 
>> See the attached examples - all in flat ASCII that was prepared using the
>> function itself! The main objective, though, is to ASCIIfy functions and
>> datasets, not help pages.
>> 
>> Arni
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Apr 17 18:52:47 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Apr 2014 12:52:47 -0400
Subject: [Rd] ASCIIfy() - a proposal for package:tools
In-Reply-To: <415DFB5A-BE24-4CFC-BF9D-77EE50C6EDEA@warnes.net>
References: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>
	<534FDB39.9010506@gmail.com>
	<415DFB5A-BE24-4CFC-BF9D-77EE50C6EDEA@warnes.net>
Message-ID: <535006DF.3000803@gmail.com>

On 17/04/2014 12:47 PM, Gregory R. Warnes wrote:
> Hi Arni,
>
> I?ll be glad to drop ASCIIfy into gtools.  Let me know if this OK.

Thanks, that sounds like a great solution if Arni doesn't want his own 
package.

Duncan Murdoch

>
> -Greg
>
> On Apr 17, 2014, at 9:46 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> > Nobody else has replied to this, so I will.  It's very unlikely that we would incorporate this function into base R.  For one thing, the tools package is intended to be tools used by R, not by users.  R doesn't need this function, so it doesn't belong in tools.  (Some other functions in tools like showNonASCII have come to be used by users, but their primary purpose is for R.)
> >
> > Utility functions that are maintained by R Core and are useful to users belong in the utils package.  But I wouldn't add ASCIIfy to that package either, because I don't want to impose its maintenance on R Core.
> >
> > Utility functions that are maintained by others belong in contributed packages.  So I'd suggest that you add this function to some package that you maintain (perhaps a new one, containing a collection of related utility functions), or search CRAN for an appropriate package with a maintainer who is willing to take this on.
> >
> > Duncan Murdoch
> >
> > On 15/04/2014 1:48 PM, Arni Magnusson wrote:
> >> Hi all,
> >>
> >> I would like to propose the attached function ASCIIfy() to be added to the
> >> 'tools' package.
> >>
> >> Non-ASCII characters in character vectors can be problematic for R
> >> packages, but sometimes they cannot be avoided. To make packages portable
> >> and build without 'R CMD check' warnings, my solution has been to convert
> >> problematic characters in functions and datasets to escaped ASCII, so
> >> plot(1,main="S?o Paulo") becomes plot(1,main="S\u00e3o Paulo").
> >>
> >> The showNonASCII() function in package:tools is helpful to identify R
> >> source files where characters should be converted to ASCII one way or
> >> another, but I could not find a function to actually perform the
> >> conversion to ASCII.
> >>
> >> I have written the function ASCIIfy() to convert character vectors to
> >> ASCII. I imagine other R package developers might be looking for a similar
> >> tool, and it seems to me that package:tools is the first place they would
> >> look, where the R Core Team has provided a variety of tools for handling
> >> non-ASCII characters in package development.
> >>
> >> I hope the R Core Team will adopt ASCIIfy() into the 'tools' package, to
> >> make life easier for package developers outside the English-speaking
> >> world. I have of course no problem with them renaming or rewriting the
> >> function in any way.
> >>
> >> See the attached examples - all in flat ASCII that was prepared using the
> >> function itself! The main objective, though, is to ASCIIfy functions and
> >> datasets, not help pages.
> >>
> >> Arni
> >>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From arnima at hafro.is  Thu Apr 17 19:15:46 2014
From: arnima at hafro.is (Arni Magnusson)
Date: Thu, 17 Apr 2014 17:15:46 +0000 (GMT)
Subject: [Rd] ASCIIfy() - a proposal for package:tools
In-Reply-To: <535006DF.3000803@gmail.com>
References: <alpine.LFD.2.11.1404151701350.2876@hafstokkur.hafro.is>
	<534FDB39.9010506@gmail.com>
	<415DFB5A-BE24-4CFC-BF9D-77EE50C6EDEA@warnes.net>
	<535006DF.3000803@gmail.com>
Message-ID: <alpine.LFD.2.11.1404171709250.36335@hafstokkur.hafro.is>

Thanks Duncan, for considering ASCIIfy. I understand your reasoning.

This is a recurring pattern - I propose functions for core R, and Greg 
catches them from freefall :)

I'm delighted with ASCIIfy being hosted in gtools. The R and Rd should be 
ready as is.

Cheers,

Arni


From djsamperi at gmail.com  Thu Apr 17 19:56:22 2014
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 17 Apr 2014 13:56:22 -0400
Subject: [Rd] rgl rotations
Message-ID: <CADUbQ5jzOxftsVGLw-C-V4NSuk1uKM9p2PuQDigK3Xpm2L5gTA@mail.gmail.com>

Is there a way to change the viewpoint using view3d (or rgl.viewpoint)
with respect to
the image that currently appears rather than the perspective that rgl
thinks is the
default? For example, if I create an image and then perform what
should be a no-op:

rgl.viewpoint(userMatrix=rotationMatrix(0,1,0,0))

the image is rotated. Then I can perform rotations on the result
without surprises.
But I want to specify rotation with respect to the image as it
originally appeared,
or with respect to the viewpoint that is currently in effect.

Experimentation has revealed that when using rotationMatrix the z-axis
points out
of the canvas instead of pointing up as it often is in mathematics,
especially when
using the spherical coordinates (theta,phi).

I guess the question is: can we query rgl for the current viewpoint and then
apply changes to that? Another way of putting it is: can we do programmatically
what we can easily do using the mouse in interactive mode?

Thanks,
Dominick


From murray at stokely.org  Thu Apr 17 20:21:46 2014
From: murray at stokely.org (Murray Stokely)
Date: Thu, 17 Apr 2014 14:21:46 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>

On Thu, Apr 17, 2014 at 6:42 AM, McGehee, Robert
<Robert.McGehee at geodecapital.com> wrote:
> Here's my use case: I have a function that pulls arbitrary financial data from a web service call such as a stock's industry, price, volume, etc. by reading the web output as a text table. The data may be either character (industry, stock name, etc.) or numeric (price, volume, etc.), and the function generally doesn't know the class in advance. The problem is that we frequently get numeric values represented with more precision than actually exists, for instance a price of "2.6999999999999999" rather than "2.70". The numeric representation is exactly one digit too much for type.convert which (in R 3.10.0) converts it to character instead of numeric (not what I want). This caused a bunch of "non-numeric argument to binary operator" errors to appear today as numeric data was now being represented as characters.
>
> I have no doubt that this probably will cause some unwanted RODBC side effects for us as well. IMO, getting the class right is more important than infinite precision. What use is a character representation of a number anyway if you can't perform arithmetic on it? I would favor at least making the new behavior optional, but I think many packages (like RODBC) potentially need to be patched to code around the new feature if it's left in.

The uses of character representation of a number are many: unique
identifiers/user ids, hash codes, timestamps, or other values where
rounding results to the nearest value that can be represented as a
numeric type would completely change the results of any data analysis
performed on that data.

Database join operations are certainly an area where R's previous
behavior of silently dropping precision of numbers with type.convert
can get you into trouble.  For example, things like join operations or
group by operations performed in R code would produce erroneous
results if you are joining/grouping by a key without the full
precision of your underlying data.  Records can get joined up
incorrectly or aggregated with the wrong groups.

If you later want to do arithmetic on them, you can choose to lose
precision by using as.numeric() or use one of the large number
packages on CRAN (GMP, int64, bit64, etc.).  But once you've dropped
the precision with as.numeric you can never get it back, which is why
the previous behavior was clearly dangerous.

I think I had some additional examples in the original bug/patch I
filed about this issue a few years ago, but I'm unable to find it on
bugs.r-project.org and its not referenced in the cl descriptions or
news file.

     - Murray


From murdoch.duncan at gmail.com  Thu Apr 17 20:31:47 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Apr 2014 14:31:47 -0400
Subject: [Rd] rgl rotations
In-Reply-To: <CADUbQ5jzOxftsVGLw-C-V4NSuk1uKM9p2PuQDigK3Xpm2L5gTA@mail.gmail.com>
References: <CADUbQ5jzOxftsVGLw-C-V4NSuk1uKM9p2PuQDigK3Xpm2L5gTA@mail.gmail.com>
Message-ID: <53501E13.5020601@gmail.com>

On 17/04/2014 1:56 PM, Dominick Samperi wrote:
> Is there a way to change the viewpoint using view3d (or rgl.viewpoint)
> with respect to
> the image that currently appears rather than the perspective that rgl
> thinks is the
> default? For example, if I create an image and then perform what
> should be a no-op:
>
> rgl.viewpoint(userMatrix=rotationMatrix(0,1,0,0))
>
> the image is rotated. Then I can perform rotations on the result
> without surprises.
> But I want to specify rotation with respect to the image as it
> originally appeared,
> or with respect to the viewpoint that is currently in effect.
>
> Experimentation has revealed that when using rotationMatrix the z-axis
> points out
> of the canvas instead of pointing up as it often is in mathematics,
> especially when
> using the spherical coordinates (theta,phi).
>
> I guess the question is: can we query rgl for the current viewpoint and then
> apply changes to that? Another way of putting it is: can we do programmatically
> what we can easily do using the mouse in interactive mode?

There are two matrices involved in rgl rendering, and they are computed 
in a relatively complicated way that is described in ?par3d.  I'm not 
sure I understand all of what you want to do, but I think the following 
achieves it; if not, take a look at that help page:

example(plot3d)  # just get a sample plot on screen.  Rotate it by mouse 
if you like.
U <- par3d("userMatrix")
for (theta in seq(0, pi, len=100)) {
   par3d(userMatrix = rotate3d(U, theta, 0,0,1)) # Rotate about model's 
z axis
   Sys.sleep(0.1)
}

for (theta in seq(0, pi, len=100)) {
   par3d(userMatrix = rotationMatrix(theta, 0,0,1) %*%U ) # Rotate about 
viewer's z axis
   Sys.sleep(0.1)
}

In this case, the "viewer's z-axis" is perpendicular to the screen; the 
"model's z-axis" is parallel to the z axis in the box around the plot.

Duncan Murdoch


From ggrothendieck at gmail.com  Thu Apr 17 20:35:48 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 17 Apr 2014 14:35:48 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
Message-ID: <CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>

On Thu, Apr 17, 2014 at 2:21 PM, Murray Stokely <murray at stokely.org> wrote:
> If you later want to do arithmetic on them, you can choose to lose
> precision by using as.numeric() or use one of the large number
> packages on CRAN (GMP, int64, bit64, etc.).  But once you've dropped
> the precision with as.numeric you can never get it back, which is why
> the previous behavior was clearly dangerous.

Only if you knew that that column was supposed to be numeric. There is
nothing in type.convert or read.table to allow you to override how it
works (colClasses only works if you knew which columns are which in
the first place) nor is there anything to allow you to know which
columns were affected so that you know which columns to look at to fix
it yourself afterwards.


From murray at stokely.org  Thu Apr 17 22:31:46 2014
From: murray at stokely.org (Murray Stokely)
Date: Thu, 17 Apr 2014 16:31:46 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
Message-ID: <CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>

On Thu, Apr 17, 2014 at 2:35 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Only if you knew that that column was supposed to be numeric. There is

The columns that are "supposed" to be numeric are those that can fit
into a numeric data type.  Previously that was not always the case
with columns that could not be represented as a numeric erroneously
coerced into a truncated/rounded numeric.

> nothing in type.convert or read.table to allow you to override how it
> works (colClasses only works if you knew which columns are which in
> the first place) nor is there anything to allow you to know which
> columns were affected so that you know which columns to look at to fix
> it yourself afterwards.

You want a casting operation in your SQL query or similar if you want
a rounded type that will always fit in a double.  Cast or Convert
operators in SQL, or similar for however you are getting the data you
want to use with type.convert().  This is all application specific and
sort of beyond the scope of type.convert(), which now behaves as it
has been documented to behave.

In my code for this kind of thing I have however typically introduced
an option() to let the user control casting behavior for e.g. 64-bit
ints in C++.  Should they be returned as truncated precision numeric
types or the full precision data in a character string representation?
 In the RProtoBuf package we let the user specify an option() to
specify which behavior they need for their application as a shortcut
to just always returning the safer character representation and making
them coerce to numeric often.

            - Murray


From simon.urbanek at r-project.org  Thu Apr 17 23:18:43 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 17:18:43 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
Message-ID: <C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>


On Apr 17, 2014, at 9:30 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> Hi All, I am not sure why this happens, but apparently an old binary is
> installed by default. Downloading and installing the new binary by hand
> works fine.
> 

I think you may be misinterpreting - the is no binary for igraph 0.7 because it fails make check, so I don't see how "Downloading and installing the new binary by hand works fine." can be true.
The *source* is available so you can compile it from sources, but that's different that what you asked for which was to install the *binary*.

Cheers,
Simon


> Is this the intended behavior? If yes, may I ask what is the reason for it?
> Thanks, Gabor
> 
>> install.packages("igraph")
> 
>  There is a binary version available (and will be installed) but the
>  source version is later:
>        binary source
> igraph 0.6.5-2  0.7.0
> 
> trying URL '
> http://cran.rstudio.com/bin/macosx/contrib/3.1/igraph_0.6.5-2.tgz'
> Content type 'application/x-gzip' length 4466270 bytes (4.3 Mb)
> opened URL
> ==================================================
> downloaded 4.3 Mb
> 
> 
> The downloaded binary packages are in
> /var/folders/ws/7rmdm_cn2pd8l1c3lqyycv0c0000gn/T//RtmpJiLDYF/downloaded_packages
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From csardi.gabor at gmail.com  Fri Apr 18 00:31:07 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 18:31:07 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
Message-ID: <CABtg=K=gr6CXzUJXyEv04_HhnU1Xosu-uNLhvf9bZxqmmLhzaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/88b81faa/attachment.pl>

From pgilbert902 at gmail.com  Fri Apr 18 00:51:53 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 17 Apr 2014 18:51:53 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>	<534860CC.2090206@gmail.com>	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
Message-ID: <53505B09.4000808@gmail.com>



On 04/17/2014 02:21 PM, Murray Stokely wrote:
> On Thu, Apr 17, 2014 at 6:42 AM, McGehee, Robert
> <Robert.McGehee at geodecapital.com> wrote:
>> Here's my use case: I have a function that pulls arbitrary
>> financial data from a web service call such as a stock's industry,
>> price, volume, etc. by reading the web output as a text table. The
>> data may be either character (industry, stock name, etc.) or
>> numeric (price, volume, etc.), and the function generally doesn't
>> know the class in advance. The problem is that we frequently get
>> numeric values represented with more precision than actually
>> exists, for instance a price of "2.6999999999999999" rather than
>> "2.70". The numeric representation is exactly one digit too much
>> for type.convert which (in R 3.10.0) converts it to character
>> instead of numeric (not what I want). This caused a bunch of
>> "non-numeric argument to binary operator" errors to appear today as
>> numeric data was now being represented as characters.
>>
>> I have no doubt that this probably will cause some unwanted RODBC
>> side effects for us as well. IMO, getting the class right is more
>> important than infinite precision. What use is a character
>> representation of a number anyway if you can't perform arithmetic
>> on it? I would favor at least making the new behavior optional, but
>> I think many packages (like RODBC) potentially need to be patched
>> to code around the new feature if it's left in.
>
> The uses of character representation of a number are many: unique
> identifiers/user ids, hash codes, timestamps, or other values where
> rounding results to the nearest value that can be represented as a
> numeric type would completely change the results of any data
> analysis performed on that data.
>
> Database join operations are certainly an area where R's previous
> behavior of silently dropping precision of numbers with type.convert
> can get you into trouble.  For example, things like join operations
> or group by operations performed in R code would produce erroneous
> results if you are joining/grouping by a key without the full
> precision of your underlying data.  Records can get joined up
> incorrectly or aggregated with the wrong groups.

I don't understand this. Assuming you are sending the SQL statement to 
the database engine, none of this erroneous matching is happening in R. 
The calculations all happens on the database.

But, for the case where the database does know that numbers are double 
precision, it would be nice if they got transmitted by ODBC to R as 
numerics (the usual translation) just as they are by the native 
interfaces like RPostgreSQL. Do you get the erroneous results when you 
use a native interface?

( from second response:)
> You want a casting operation in your SQL query or similar if you want
> a rounded type that will always fit in a double.  Cast or Convert
> operators in SQL, or similar for however you are getting the data you
> want to use with type.convert().  This is all application specific and
> sort of beyond the scope of type.convert(), which now behaves as it
> has been documented to behave.

This seems to suggests I need to use different SQL statements depending 
on which interface I use to talk to the database.

If you do 1/3 in a database calculation and that ends up being 
represented as something more accurate than double precision on the 
database, then it needs to be transmitted as something with higher 
precision (character/factor?). If the result is double precision it 
should be sent as double precision, not as something pretending to be 
more accurate.

I suspect the difficulty with ODBC may be that type.convert() really 
should not be called when both ends of the communication know that a 
double precision number is being exchanged.

Paul

> If you later want to do arithmetic on them, you can choose to lose
> precision by using as.numeric() or use one of the large number
> packages on CRAN (GMP, int64, bit64, etc.).  But once you've dropped
> the precision with as.numeric you can never get it back, which is
> why the previous behavior was clearly dangerous.
>
> I think I had some additional examples in the original bug/patch I
> filed about this issue a few years ago, but I'm unable to find it on
> bugs.r-project.org and its not referenced in the cl descriptions or
> news file.
>
> - Murray
>


From Robert.McGehee at geodecapital.com  Fri Apr 18 01:15:47 2014
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 17 Apr 2014 19:15:47 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
Message-ID: <17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>

> This is all application specific and
> sort of beyond the scope of type.convert(), which now behaves as it
> has been documented to behave.

That's only a true statement because the documentation was changed to reflect the new behavior! The new feature in type.convert certainly does not behave according to the documentation as of R 3.0.3. Here's a snippit:
 
     The first type that can accept all the
     non-missing values is chosen (numeric and complex return values
     will represented approximately, of course).

The key phrase is in parentheses, which reminds the user to expect a possible loss of precision. That important parenthetical was removed from the documentation in R 3.1.0 (among other changes).

Putting aside the fact that this introduces a large amount of unnecessary work rewriting SQL / data import code, SQL packages, my biggest conceptual problem is that I can no longer rely on a particular function call returning a particular class. In my example querying stock prices, about 5% of prices came back as factors and the remaining 95% as numeric, so we had random errors popping in throughout the morning.

Here's a short example showing us how the new behavior can be unreliable. I pass a character representation of a uniformly distributed random variable to type.convert. 90% of the time it is converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in which type.convert converts to a factor the leading non-zero digit is always a 9. So if you were expecting a numeric value, then 1 in 10 times you may have a bug in your code that didn't exist before.

> options(digits=16)
> cl <- NULL; for (i in 1:10000) cl[i] <- class(type.convert(format(runif(1))))
> table(cl)
cl
factor numeric
   990    9010

Cheers, Robert


From csardi.gabor at gmail.com  Fri Apr 18 01:42:50 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 19:42:50 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
Message-ID: <CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/ea581591/attachment.pl>

From dtenenba at fhcrc.org  Fri Apr 18 01:52:36 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 17 Apr 2014 16:52:36 -0700 (PDT)
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
Message-ID: <436951764.1641811.1397778756489.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "G?bor Cs?rdi" <csardi.gabor at gmail.com>
> To: "Simon Urbanek" <simon.urbanek at r-project.org>
> Cc: r-devel at r-project.org
> Sent: Thursday, April 17, 2014 4:42:50 PM
> Subject: Re: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
> 
> On Thu, Apr 17, 2014 at 5:18 PM, Simon Urbanek
> <simon.urbanek at r-project.org>wrote:
> 
> >
> > On Apr 17, 2014, at 9:30 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> > wrote:
> >
> > > Hi All, I am not sure why this happens, but apparently an old
> > > binary is
> > > installed by default. Downloading and installing the new binary
> > > by hand
> > > works fine.
> > >
> >
> > I think you may be misinterpreting - the is no binary for igraph
> > 0.7
> > because it fails make check,
> 
> 
> Btw. it fails R CMD check (there is no make check afaik) because it
> suggests a BioC package (graph), that is not available. 



The graph package is available:

http://www.bioconductor.org/packages/release/bioc/html/graph.html


...but maybe not installed on the CRAN build machine.

All of this would make more sense if the OP was using the Mavericks build of R because we don't yet have BioC binary packages for that, but his original sessionInfo() showed that he was using the Snow Leopard build.


> Can CRAN
> packages
> not depend on BioC packages any more?
> 

I think they can. graph is in igraph's Suggests. If CRAN packages could not depend on BioC packages, I would imagine that igraph would be removed from CRAN until it got rid of that dependency.

Dan

> Thanks, Gabor
> 
> [...]
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mengsteab.aregay at gmail.com  Fri Apr 18 02:50:14 2014
From: mengsteab.aregay at gmail.com (Mengsteab Aregay)
Date: Thu, 17 Apr 2014 20:50:14 -0400
Subject: [Rd] Unsubscribe me please
Message-ID: <CAC09cvSHbDxGrnfc7fC4XMHmAQcC=9DrpYnWOUcgp=5Mty7v2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/46e89534/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 18 03:05:39 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 21:05:39 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=K=gr6CXzUJXyEv04_HhnU1Xosu-uNLhvf9bZxqmmLhzaw@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=gr6CXzUJXyEv04_HhnU1Xosu-uNLhvf9bZxqmmLhzaw@mail.gmail.com>
Message-ID: <4F729DD8-1F03-48CE-91C6-1A699B5EAFF2@r-project.org>

On Apr 17, 2014, at 6:31 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Apr 17, 2014 at 5:18 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On Apr 17, 2014, at 9:30 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> > Hi All, I am not sure why this happens, but apparently an old binary is
> > installed by default. Downloading and installing the new binary by hand
> > works fine.
> >
> 
> I think you may be misinterpreting - the is no binary for igraph 0.7 because it fails make check, so I don't see how "Downloading and installing the new binary by hand works fine." can be true.
> 
> What is the tgz linked from here, then?
> http://cran.r-project.org/web/packages/igraph/index.html
> 

That is the 3.0 package. Sorry, my bad, the symlinks have not been switched from prerelease to release - my bad, now fixed.

Cheers,
Simon



> Gabor
>  
> The *source* is available so you can compile it from sources, but that's different that what you asked for which was to install the *binary*.
> 
> Cheers,
> Simon
> 
> 
> > Is this the intended behavior? If yes, may I ask what is the reason for it?
> > Thanks, Gabor
> >
> >> install.packages("igraph")
> >
> >  There is a binary version available (and will be installed) but the
> >  source version is later:
> >        binary source
> > igraph 0.6.5-2  0.7.0
> >
> > trying URL '
> > http://cran.rstudio.com/bin/macosx/contrib/3.1/igraph_0.6.5-2.tgz'
> > Content type 'application/x-gzip' length 4466270 bytes (4.3 Mb)
> > opened URL
> > ==================================================
> > downloaded 4.3 Mb
> >
> >
> > The downloaded binary packages are in
> > /var/folders/ws/7rmdm_cn2pd8l1c3lqyycv0c0000gn/T//RtmpJiLDYF/downloaded_packages
> >> sessionInfo()
> > R version 3.1.0 (2014-04-10)
> > Platform: x86_64-apple-darwin10.8.0 (64-bit)
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.1.0
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 


From simon.urbanek at r-project.org  Fri Apr 18 03:07:48 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 21:07:48 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
Message-ID: <15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>


On Apr 17, 2014, at 7:42 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Apr 17, 2014 at 5:18 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On Apr 17, 2014, at 9:30 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> > Hi All, I am not sure why this happens, but apparently an old binary is
> > installed by default. Downloading and installing the new binary by hand
> > works fine.
> >
> 
> I think you may be misinterpreting - the is no binary for igraph 0.7 because it fails make check,
> 
> Btw. it fails R CMD check (there is no make check afaik) because it suggests a BioC package (graph), that is not available. Can CRAN packages not depend on BioC packages any more?
> 

No, the issue is that igraph suggests graph yet fails when it's not present. It should guard against failure is case it's not available. I didn't look at this particular case, but sometimes that is necessary to break infinite dependency loops.

Cheers,
Simon


From csardi.gabor at gmail.com  Fri Apr 18 03:24:11 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 21:24:11 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
Message-ID: <CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/f46aa0f7/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 18 03:43:03 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 21:43:03 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
Message-ID: <EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>

On Apr 17, 2014, at 9:24 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Apr 17, 2014 at 9:07 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> [...]
> 
> No, the issue is that igraph suggests graph yet fails when it's not present. It should guard against failure is case it's not available. I didn't look at this particular case, but sometimes that is necessary to break infinite dependency loops.
> 
> So if I make 'graph' a dependency via Imports, then everything will be OK? 
> 
> We can rely on Imports and Depends from BioC being available, but not on Suggests?
> 

The Suggests failure has nothing to do with BioC. Only packages listed in Depends/Imports are required for a package to work so there is no guarantee for any packages in Suggests to be available - hence the package should not break if they are not available - that's the whole point of Suggests. If you list it in Depends/Imports then it won't even get to the check if those packages are not available - it won't build at all. I didn't look at the dependencies in this particular case, but one reason to use Suggests is to break dependency loops: if A depends on B and B on A, then there is no way to install them, so typically A suggests B and B depends on A so that A can be installed and checked first without B and then B checked with A and finally A with B. If A breaks without B then it makes such bootstrapping impossible - we found some packages with this issue, that's why mentioned this - I don't know if that's the case with igraph or not.

As for BioC, the builds for BioC are independent of CRAN, so CRAN doesn't build BioC packages and thus their availability is subject to manual intervention - on the OS X build machine there is currently no automated way to track BioC packages, but we're working on it.

Cheers,
Simon


From michael.weylandt at gmail.com  Fri Apr 18 03:45:16 2014
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Thu, 17 Apr 2014 21:45:16 -0400
Subject: [Rd] Unsubscribe me please
In-Reply-To: <CAC09cvSHbDxGrnfc7fC4XMHmAQcC=9DrpYnWOUcgp=5Mty7v2w@mail.gmail.com>
References: <CAC09cvSHbDxGrnfc7fC4XMHmAQcC=9DrpYnWOUcgp=5Mty7v2w@mail.gmail.com>
Message-ID: <351E0DEB-93FE-40E8-B660-FEC250E54B1F@gmail.com>



On Apr 17, 2014, at 20:50, Mengsteab Aregay <mengsteab.aregay at gmail.com> wrote:

> I don't want to accept anymore emails from
> https://stat.ethz.ch/mailman/listinfo/r-devel. can u please unsubscribed me.

Read your own link. It has un-subscription instructions. 

> 
> Thanks you
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Fri Apr 18 03:52:33 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 21:52:33 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
Message-ID: <CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/0713d3c3/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 18 04:08:49 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 22:08:49 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
	<CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
Message-ID: <39455DD7-E184-47F9-9324-9918547981EC@r-project.org>

On Apr 17, 2014, at 9:52 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Apr 17, 2014 at 9:43 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> [...]
> The Suggests failure has nothing to do with BioC. Only packages listed in Depends/Imports are required for a package to work so there is no guarantee for any packages in Suggests to be available - hence the package should not break if they are not available - that's the whole point of Suggests. If you list it in Depends/Imports then it won't even get to the check if those packages are not available - it won't build at all. I didn't look at the dependencies in this particular case, but one reason to use Suggests is to break dependency loops: if A depends on B and B on A, then there is no way to install them, so typically A suggests B and B depends on A so that A can be installed and checked first without B and then B checked with A and finally A with B.
> 
> I would naively think that if you install A and B _together_, then they should be fine. At least this is how dependencies work on various Linux distributions, AFAIK.

They cannot be installed together, R doesn't have a concept of "together" since it doesn't separate copying and parse/eval stages so you cannot "pre-install" the packages and then run them through R to create the binary. Therefore dependencies are always sequential.


>  If A breaks without B then it makes such bootstrapping impossible - we found some packages with this issue, that's why mentioned this - I don't know if that's the case with igraph or not.
> 
> As for BioC, the builds for BioC are independent of CRAN, so CRAN doesn't build BioC packages and thus their availability is subject to manual intervention - on the OS X build machine there is currently no automated way to track BioC packages, but we're working on it.
> 
> So this effectively means that if I Import/Depend/Suggest etc. a BioC package in igraph, then igraph will likely not be available for OSX. Right? 
> 

No.

Cheers,
Simon


From csardi.gabor at gmail.com  Fri Apr 18 04:14:35 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 22:14:35 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <39455DD7-E184-47F9-9324-9918547981EC@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
	<CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
	<39455DD7-E184-47F9-9324-9918547981EC@r-project.org>
Message-ID: <CABtg=KmWrnKS6f5N2Ebj-i2kMyRukBYChVPMYoxOqh5yq9JFSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/fc15e162/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 18 04:24:08 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 22:24:08 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=KmWrnKS6f5N2Ebj-i2kMyRukBYChVPMYoxOqh5yq9JFSw@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
	<CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
	<39455DD7-E184-47F9-9324-9918547981EC@r-project.org>
	<CABtg=KmWrnKS6f5N2Ebj-i2kMyRukBYChVPMYoxOqh5yq9JFSw@mail.gmail.com>
Message-ID: <CF6F6B5C-86CC-49E2-99D6-7D8FED89A7F5@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/2ae0b036/attachment.pl>

From csardi.gabor at gmail.com  Fri Apr 18 04:37:51 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 17 Apr 2014 22:37:51 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CF6F6B5C-86CC-49E2-99D6-7D8FED89A7F5@r-project.org>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
	<CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
	<39455DD7-E184-47F9-9324-9918547981EC@r-project.org>
	<CABtg=KmWrnKS6f5N2Ebj-i2kMyRukBYChVPMYoxOqh5yq9JFSw@mail.gmail.com>
	<CF6F6B5C-86CC-49E2-99D6-7D8FED89A7F5@r-project.org>
Message-ID: <CABtg=K=+JH=6mFqaQM6_Gf4OY9dY9WCY-sUgWWNbQWMsfEUqeQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140417/228421c0/attachment.pl>

From simon.urbanek at r-project.org  Fri Apr 18 04:52:31 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Apr 2014 22:52:31 -0400
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=K=+JH=6mFqaQM6_Gf4OY9dY9WCY-sUgWWNbQWMsfEUqeQ@mail.gmail.com>
References: <CABtg=KmwERwaJ+JwEG6G6NeZLmHoPc+PJNk+0CjMqWs=BwXD0g@mail.gmail.com>
	<C2E40931-DA04-496B-82EF-58179FCDD8C7@r-project.org>
	<CABtg=K=m2+jvc+8nJgANeXFMZnbK=nrZY73=9N+cATzdC6HfQQ@mail.gmail.com>
	<15EDAF28-8C7F-49D9-8E36-BF705E6EE1C3@r-project.org>
	<CABtg=Kmy_g9WieTot8i261rVEX2+Fmd-rpPBVG4devfybXrhFg@mail.gmail.com>
	<EC946039-7029-431B-88D8-B8DF0A512E0C@r-project.org>
	<CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
	<39455DD7-E184-47F9-9324-9918547981EC@r-project.org>
	<CABtg=KmWrnKS6f5N2Ebj-i2kMyRukBYChVPMYoxOqh5yq9JFSw@mail.gmail.com>
	<CF6F6B5C-86CC-49E2-99D6-7D8FED89A7F5@r-project.org>
	<CABtg=K=+JH=6mFqaQM6_Gf4OY9dY9WCY-sUgWWNbQWMsfEUqeQ@mail.gmail.com>
Message-ID: <20E0E156-56E6-49A0-9E59-25C9A7A0F888@r-project.org>

On Apr 17, 2014, at 10:37 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Apr 17, 2014 at 10:24 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> [...]
>> :) Let's try to make this simple. What can I do to make igraph available for OSX users? I guess this is clear, I can make all examples that load suggested packages optional.
>> 
> 
> Yes, I think that would be a good idea if you really want to support Suggests.
> 
> Well, I could not care less about the 1-2 functions that use 'graph', but I want the package to be eventually available on CRAN for OSX. I'll update the examples whenever I can find a free day to check the reverse dependencies....
> 

Thanks. I have verified that graph is now available and igraph seems to pass check with it so it should be available tomorrow.

Cheers,
Simon


From atp at piskorski.com  Fri Apr 18 15:55:05 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Fri, 18 Apr 2014 09:55:05 -0400
Subject: [Rd] Why did R 3.0's resolveNativeRoutine remove full-search
	ability?
Message-ID: <20140418135505.GA55039@piskorski.com>

In versions of R prior to 3.0, by default .C and .Call would find the
requested C function regardless of which shared library it was located
in.  You could use the PACKAGE argument to restrict the search to a
specific library, but doing so was not necessary for it to work.

R 3.0 introduced a significant change to that behavior; from the NEWS
file:

  CHANGES IN R 3.0.0: 
  PERFORMANCE IMPROVEMENTS: 
    * A foreign function call (.C() etc) in a package without a PACKAGE 
      argument will only look in the first DLL specified in the 
      NAMESPACE file of the package rather than searching all loaded 
      DLLs.  A few packages needed PACKAGE arguments added. 

That is not merely a performance improvement, it is a significant
change in functionality.  Now, when R code in my package foo tries to
call C code located in bar.so, it fails with a "not resolved from
current namespace (foo)" error.  It works if I change all my uses of
.C and .Call to pass a PACKAGE="bar" argument.  Ok, I can make that
change in my code, no big deal.

What surprises me though, is that there appears to be no way to invoke
the old (and very conventional Unix-style), "I don't want to specify
where the function is located, just keep searching until you find it"
behavior.  Is there really no way to do that, and if so, why not?

Comparing the R sources on the 3.1 vs. 2.15 branches, it looks as if
this is due to some simple changes to resolveNativeRoutine in
"src/main/dotcode.c".  Specifically, the newer code adds this:

   errorcall(call, "\"%s\" not resolved from current namespace (%s)",
             buf, ns);

And removes these lines:

   /* need to continue if the namespace search failed */
   *fun = R_FindSymbol(buf, dll.DLLname, symbol);
   if (*fun) return args;

Is that extra call to R_FindSymbol really all that's necessary to
invoke the old "keep searching" behavior?  Would it be a good idea to
provide an optional way of finding a native routine regardless of
where it's located, perhaps via an optional PACKAGE=NA argument to .C,
.Call, etc.?

And now I see that help(".Call") says:

   'PACKAGE = ""' used to be accepted (but was undocumented): it is 
    now an error. 

I assume passing PACKAGE="" used to invoke the same "keep searching"
behavior as not passing any PACKAGE argument at all.  So apparently
the removal of functionality was intentional.  I'd like to better
understand why.  Why should that be an error?  Or said another way,
why has traditional Unix-style symbol resolution been banned from use
with .C and .Call ?

-- 
Andrew Piskorski <atp at piskorski.com>


From dtenenba at fhcrc.org  Fri Apr 18 16:25:49 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 18 Apr 2014 07:25:49 -0700 (PDT)
Subject: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
In-Reply-To: <CABtg=KnH79bok4s0KYjiVvxfr+W4k=7DVkg3TQT24eLM0CfAgQ@mail.gmail.com>
Message-ID: <1582448003.1649542.1397831149923.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "G?bor Cs?rdi" <csardi.gabor at gmail.com>
> To: "Simon Urbanek" <simon.urbanek at r-project.org>
> Cc: r-devel at r-project.org
> Sent: Thursday, April 17, 2014 6:52:33 PM
> Subject: Re: [Rd] R-3.1.0 OSX Snow Leopard installs old binary
> 
> On Thu, Apr 17, 2014 at 9:43 PM, Simon Urbanek
> <simon.urbanek at r-project.org>wrote:
> [...]
> 
> > The Suggests failure has nothing to do with BioC. Only packages
> > listed in
> > Depends/Imports are required for a package to work so there is no
> > guarantee
> > for any packages in Suggests to be available - hence the package
> > should not
> > break if they are not available - that's the whole point of
> > Suggests. If
> > you list it in Depends/Imports then it won't even get to the check
> > if those
> > packages are not available - it won't build at all. I didn't look
> > at the
> > dependencies in this particular case, but one reason to use
> > Suggests is to
> > break dependency loops: if A depends on B and B on A, then there is
> > no way
> > to install them, so typically A suggests B and B depends on A so
> > that A can
> > be installed and checked first without B and then B checked with A
> > and
> > finally A with B.
> >
> 
> I would naively think that if you install A and B _together_, then
> they
> should be fine. At least this is how dependencies work on various
> Linux
> distributions, AFAIK.
> 
> 
> > If A breaks without B then it makes such bootstrapping impossible -
> > we
> > found some packages with this issue, that's why mentioned this - I
> > don't
> > know if that's the case with igraph or not.
> >
> > As for BioC, the builds for BioC are independent of CRAN, so CRAN
> > doesn't
> > build BioC packages and thus their availability is subject to
> > manual
> > intervention - on the OS X build machine there is currently no
> > automated
> > way to track BioC packages, but we're working on it.
> >
> 
> So this effectively means that if I Import/Depend/Suggest etc. a BioC
> package in igraph, then igraph will likely not be available for OSX.
> Right?

Wrong. It's just the Mavericks binaries that are not yet available. Snow Leopard binaries are available.

Dan


> 
> Gabor
> 
> 
> 
> >
> > Cheers,
> > Simon
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From simon.urbanek at r-project.org  Fri Apr 18 16:29:15 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Apr 2014 10:29:15 -0400
Subject: [Rd] Why did R 3.0's resolveNativeRoutine remove full-search
	ability?
In-Reply-To: <20140418135505.GA55039@piskorski.com>
References: <20140418135505.GA55039@piskorski.com>
Message-ID: <BFE389FD-2402-4E89-BCD0-918714D274C1@r-project.org>

Andrew,

On Apr 18, 2014, at 9:55 AM, Andrew Piskorski <atp at piskorski.com> wrote:

> In versions of R prior to 3.0, by default .C and .Call would find the
> requested C function regardless of which shared library it was located
> in.  You could use the PACKAGE argument to restrict the search to a
> specific library, but doing so was not necessary for it to work.
> 
> R 3.0 introduced a significant change to that behavior; from the NEWS
> file:
> 
>  CHANGES IN R 3.0.0: 
>  PERFORMANCE IMPROVEMENTS: 
>    * A foreign function call (.C() etc) in a package without a PACKAGE 
>      argument will only look in the first DLL specified in the 
>      NAMESPACE file of the package rather than searching all loaded 
>      DLLs.  A few packages needed PACKAGE arguments added. 
> 
> That is not merely a performance improvement, it is a significant
> change in functionality.  Now, when R code in my package foo tries to
> call C code located in bar.so, it fails with a "not resolved from
> current namespace (foo)" error.  It works if I change all my uses of
> .C and .Call to pass a PACKAGE="bar" argument.  Ok, I can make that
> change in my code, no big deal.
> 
> What surprises me though, is that there appears to be no way to invoke
> the old (and very conventional Unix-style), "I don't want to specify
> where the function is located, just keep searching until you find it"
> behavior.  Is there really no way to do that, and if so, why not?
> 
> Comparing the R sources on the 3.1 vs. 2.15 branches, it looks as if
> this is due to some simple changes to resolveNativeRoutine in
> "src/main/dotcode.c".  Specifically, the newer code adds this:
> 
>   errorcall(call, "\"%s\" not resolved from current namespace (%s)",
>             buf, ns);
> 
> And removes these lines:
> 
>   /* need to continue if the namespace search failed */
>   *fun = R_FindSymbol(buf, dll.DLLname, symbol);
>   if (*fun) return args;
> 
> Is that extra call to R_FindSymbol really all that's necessary to
> invoke the old "keep searching" behavior?  Would it be a good idea to
> provide an optional way of finding a native routine regardless of
> where it's located, perhaps via an optional PACKAGE=NA argument to .C,
> .Call, etc.?
> 
> And now I see that help(".Call") says:
> 
>   'PACKAGE = ""' used to be accepted (but was undocumented): it is 
>    now an error. 
> 
> I assume passing PACKAGE="" used to invoke the same "keep searching"
> behavior as not passing any PACKAGE argument at all.  So apparently
> the removal of functionality was intentional.  I'd like to better
> understand why.  Why should that be an error?  Or said another way,
> why has traditional Unix-style symbol resolution been banned from use
> with .C and .Call ?
> 

I cannot speak for the author, but a very strong argument is to prevent (symbol) namespace issues. If you cannot even say where the symbol comes from, you have absolutely no way of knowing that the symbol you get has anything to do with the symbol you intended to get, because you could get any random symbol in any shared object that may or may not have anything to do with your code. Note that even you as the author of the code have no control over the namespace so although you intended this to work, loading some other package can break your code - and in a fatal manner since this will typically lead to a segfault. Do you have any strong use case for allowing this given how dangerous it is? Ever since symbol registration has been made easy, it's much more efficient and safe to use symbols directly instead.

Cheers,
Simon


From JHZhang at mdanderson.org  Fri Apr 18 18:38:29 2014
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 18 Apr 2014 16:38:29 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
Message-ID: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140418/c2420ef4/attachment.pl>

From wdunlap at tibco.com  Fri Apr 18 18:50:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Apr 2014 16:50:22 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>

> Within an R session, type Sys.getenv() will list all the environment variables, but each one
> of them occupies about a page, so scrolling to find one is difficult. Is this because I don't
> know how to use it or something could be improved? 

Attaching the class "simple.list" to the output of Sys.getenv() gives it
a nicer print method:

   > structure(Sys.getenv(), class="simple.list")
                           _                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
   ALCKPath                C:\\Program Files\\Lenovo\\AutoLock                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
   ALLUSERSPROFILE         C:\\ProgramData                                                       
   ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
   windir                  C:\\Windows                                    

(I don't know why print.simple.list adds the line with a hyphen above the 2nd
column at the top.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Jun Zhang
> Sent: Friday, April 18, 2014 9:38 AM
> To: r-devel at r-project.org
> Subject: [Rd] Can the output of Sys.getenv() be improved?
> 
> Within an R session, type Sys.getenv() will list all the environment variables, but each one
> of them occupies about a page, so scrolling to find one is difficult. Is this because I don't
> know how to use it or something could be improved? Usually I'm not sure the exact
> name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's
> lib, include, modules information provided during compilation. When I load rjags, I was
> told that it linked to JAGS 3.3.0 (a package also available in my environment). This made
> me think there must be a variable to make that to happen. What can I do to make rjags
> to link to JAGS 3.4.0?
> 
> Jun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From xie at yihui.name  Fri Apr 18 18:51:48 2014
From: xie at yihui.name (Yihui Xie)
Date: Fri, 18 Apr 2014 11:51:48 -0500
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
Message-ID: <CANROs4cF-4xRZAq7uGoERdRMdV41qg4kVDDEo-OVuudu49_sWw@mail.gmail.com>

For your first question, try str(as.list(Sys.getenv())). I do not know
the answer for the JAGS question, and I'll leave it to someone else to
tell you which mailing list to use for such questions...

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Fri, Apr 18, 2014 at 11:38 AM, Zhang,Jun <JHZhang at mdanderson.org> wrote:
> Within an R session, type Sys.getenv() will list all the environment variables, but each one of them occupies about a page, so scrolling to find one is difficult. Is this because I don't know how to use it or something could be improved? Usually I'm not sure the exact name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's lib, include, modules information provided during compilation. When I load rjags, I was told that it linked to JAGS 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
>
> Jun


From JHZhang at mdanderson.org  Fri Apr 18 19:03:16 2014
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 18 Apr 2014 17:03:16 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <CANROs4cF-4xRZAq7uGoERdRMdV41qg4kVDDEo-OVuudu49_sWw@mail.gmail.com>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<CANROs4cF-4xRZAq7uGoERdRMdV41qg4kVDDEo-OVuudu49_sWw@mail.gmail.com>
Message-ID: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B5A@DCPWPEXMBX03.mdanderson.edu>

That is a great command to have. Once the better formatted envvars with value is listed, I noticed that JAGS-3.3.0/bin is in the PATH, so that problem is also solved for my user. 

Thanks,
Jun

-----Original Message-----
From: xieyihui at gmail.com [mailto:xieyihui at gmail.com] On Behalf Of Yihui Xie
Sent: Friday, April 18, 2014 11:52 AM
To: Zhang,Jun
Cc: r-devel at r-project.org
Subject: Re: [Rd] Can the output of Sys.getenv() be improved?

For your first question, try str(as.list(Sys.getenv())). I do not know the answer for the JAGS question, and I'll leave it to someone else to tell you which mailing list to use for such questions...

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Fri, Apr 18, 2014 at 11:38 AM, Zhang,Jun <JHZhang at mdanderson.org> wrote:
> Within an R session, type Sys.getenv() will list all the environment variables, but each one of them occupies about a page, so scrolling to find one is difficult. Is this because I don't know how to use it or something could be improved? Usually I'm not sure the exact name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's lib, include, modules information provided during compilation. When I load rjags, I was told that it linked to JAGS 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
>
> Jun


From JHZhang at mdanderson.org  Fri Apr 18 19:24:10 2014
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 18 Apr 2014 17:24:10 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B5A@DCPWPEXMBX03.mdanderson.edu>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<CANROs4cF-4xRZAq7uGoERdRMdV41qg4kVDDEo-OVuudu49_sWw@mail.gmail.com>
	<8EE4E2C595735A4EAEC2A3311537FE4D15B84B5A@DCPWPEXMBX03.mdanderson.edu>
Message-ID: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B80@DCPWPEXMBX03.mdanderson.edu>

I take the latter part back. I could not possibly load rjags with JAGS-3.4.0 linked. 

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Zhang,Jun
Sent: Friday, April 18, 2014 12:03 PM
To: 'Yihui Xie'
Cc: r-devel at r-project.org
Subject: Re: [Rd] Can the output of Sys.getenv() be improved?

That is a great command to have. Once the better formatted envvars with value is listed, I noticed that JAGS-3.3.0/bin is in the PATH, so that problem is also solved for my user. 

Thanks,
Jun

-----Original Message-----
From: xieyihui at gmail.com [mailto:xieyihui at gmail.com] On Behalf Of Yihui Xie
Sent: Friday, April 18, 2014 11:52 AM
To: Zhang,Jun
Cc: r-devel at r-project.org
Subject: Re: [Rd] Can the output of Sys.getenv() be improved?

For your first question, try str(as.list(Sys.getenv())). I do not know the answer for the JAGS question, and I'll leave it to someone else to tell you which mailing list to use for such questions...

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Fri, Apr 18, 2014 at 11:38 AM, Zhang,Jun <JHZhang at mdanderson.org> wrote:
> Within an R session, type Sys.getenv() will list all the environment variables, but each one of them occupies about a page, so scrolling to find one is difficult. Is this because I don't know how to use it or something could be improved? Usually I'm not sure the exact name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's lib, include, modules information provided during compilation. When I load rjags, I was told that it linked to JAGS 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
>
> Jun

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From JHZhang at mdanderson.org  Fri Apr 18 19:58:43 2014
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 18 Apr 2014 17:58:43 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
Message-ID: <8EE4E2C595735A4EAEC2A3311537FE4D15B84BC4@DCPWPEXMBX03.mdanderson.edu>

Thank you very much for your reply. 
This seems better used for Windows.

Best regards,
Jun

-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com] 
Sent: Friday, April 18, 2014 11:50 AM
To: Zhang,Jun; r-devel at r-project.org
Subject: RE: Can the output of Sys.getenv() be improved?

> Within an R session, type Sys.getenv() will list all the environment 
> variables, but each one of them occupies about a page, so scrolling to 
> find one is difficult. Is this because I don't know how to use it or something could be improved?

Attaching the class "simple.list" to the output of Sys.getenv() gives it a nicer print method:

   > structure(Sys.getenv(), class="simple.list")
                           _                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
   ALCKPath                C:\\Program Files\\Lenovo\\AutoLock                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
   ALLUSERSPROFILE         C:\\ProgramData                                                       
   ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
   windir                  C:\\Windows                                    

(I don't know why print.simple.list adds the line with a hyphen above the 2nd column at the top.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Jun Zhang
> Sent: Friday, April 18, 2014 9:38 AM
> To: r-devel at r-project.org
> Subject: [Rd] Can the output of Sys.getenv() be improved?
> 
> Within an R session, type Sys.getenv() will list all the environment 
> variables, but each one of them occupies about a page, so scrolling to 
> find one is difficult. Is this because I don't know how to use it or 
> something could be improved? Usually I'm not sure the exact name of a 
> variable but want to look it up. Recently I installed rjags, with the 
> JAGS-3.4.0's lib, include, modules information provided during 
> compilation. When I load rjags, I was told that it linked to JAGS 
> 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
> 
> Jun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Fri Apr 18 22:54:15 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 18 Apr 2014 16:54:15 -0400
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
Message-ID: <CAP01uRkTUFEEGTYW9yg5OgE-K9AVSEoOeisGrR669hswa-9_KQ@mail.gmail.com>

On Fri, Apr 18, 2014 at 12:38 PM, Zhang,Jun <JHZhang at mdanderson.org> wrote:
> Within an R session, type Sys.getenv() will list all the environment variables, but each one of them occupies about a page, so scrolling to find one is difficult. Is this because I don't know how to use it or something could be improved? Usually I'm not sure the exact name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's lib, include, modules information provided during compilation. When I load rjags, I was told that it linked to JAGS 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
>

Try this:

str(as.list(Sys.getenv()))

or this:

View(as.matrix(Sys.getenv()))


From JHZhang at mdanderson.org  Fri Apr 18 23:01:02 2014
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 18 Apr 2014 21:01:02 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <CAP01uRkTUFEEGTYW9yg5OgE-K9AVSEoOeisGrR669hswa-9_KQ@mail.gmail.com>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<CAP01uRkTUFEEGTYW9yg5OgE-K9AVSEoOeisGrR669hswa-9_KQ@mail.gmail.com>
Message-ID: <8EE4E2C595735A4EAEC2A3311537FE4D15B84D7D@DCPWPEXMBX03.mdanderson.edu>

Thanks Gabor, really appreciate your help.

-Jun

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Friday, April 18, 2014 3:54 PM
To: Zhang,Jun
Cc: r-devel at r-project.org
Subject: Re: [Rd] Can the output of Sys.getenv() be improved?

On Fri, Apr 18, 2014 at 12:38 PM, Zhang,Jun <JHZhang at mdanderson.org> wrote:
> Within an R session, type Sys.getenv() will list all the environment variables, but each one of them occupies about a page, so scrolling to find one is difficult. Is this because I don't know how to use it or something could be improved? Usually I'm not sure the exact name of a variable but want to look it up. Recently I installed rjags, with the JAGS-3.4.0's lib, include, modules information provided during compilation. When I load rjags, I was told that it linked to JAGS 3.3.0 (a package also available in my environment). This made me think there must be a variable to make that to happen. What can I do to make rjags to link to JAGS 3.4.0?
>

Try this:

str(as.list(Sys.getenv()))

or this:

View(as.matrix(Sys.getenv()))

From jorismeys at gmail.com  Sat Apr 19 11:42:09 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 19 Apr 2014 11:42:09 +0200
Subject: [Rd] lag() not returning a time series object
Message-ID: <CAO1zAVaQfta=HjfwZGPs6D=LVS4xG7RxWDP2Au-J=dUgUPsvEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140419/a3b1af49/attachment.pl>

From maechler at stat.math.ethz.ch  Sat Apr 19 14:57:04 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 19 Apr 2014 14:57:04 +0200
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
Message-ID: <21330.29344.628971.904268@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Fri, 18 Apr 2014 16:50:22 +0000 writes:

    >> Within an R session, type Sys.getenv() will list all the
    >> environment variables, but each one of them occupies
    >> about a page, so scrolling to find one is difficult. Is
    >> this because I don't know how to use it or something
    >> could be improved?

    > Attaching the class "simple.list" to the output of
    > Sys.getenv() gives it a nicer print method:

    >> structure(Sys.getenv(), class="simple.list")
    >                            _ !

Good idea; this is something we could do unconditionally, i.e.,
return from Sys.getenv().
It would hardly break code, 
as simple.list only has a print and a `[` method.

It would help people like Jun and could hardly harm, AFAICS.

Opinions?


From maechler at stat.math.ethz.ch  Sat Apr 19 15:00:10 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 19 Apr 2014 15:00:10 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <21330.29530.72292.435730@stat.math.ethz.ch>

>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>     on Thu, 17 Apr 2014 19:15:47 -0400 writes:

    >> This is all application specific and
    >> sort of beyond the scope of type.convert(), which now behaves as it
    >> has been documented to behave.

    > That's only a true statement because the documentation was changed to reflect the new behavior! The new feature in type.convert certainly does not behave according to the documentation as of R 3.0.3. Here's a snippit:
 
    > The first type that can accept all the
    > non-missing values is chosen (numeric and complex return values
    > will represented approximately, of course).

    > The key phrase is in parentheses, which reminds the user to expect a possible loss of precision. That important parenthetical was removed from the documentation in R 3.1.0 (among other changes).

    > Putting aside the fact that this introduces a large amount of unnecessary work rewriting SQL / data import code, SQL packages, my biggest conceptual problem is that I can no longer rely on a particular function call returning a particular class. In my example querying stock prices, about 5% of prices came back as factors and the remaining 95% as numeric, so we had random errors popping in throughout the morning.

    > Here's a short example showing us how the new behavior can be unreliable. I pass a character representation of a uniformly distributed random variable to type.convert. 90% of the time it is converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in which type.convert converts to a factor the leading non-zero digit is always a 9. So if you were expecting a numeric value, then 1 in 10 times you may have a bug in your code that didn't exist before.

    >> options(digits=16)
    >> cl <- NULL; for (i in 1:10000) cl[i] <- class(type.convert(format(runif(1))))
    >> table(cl)
    > cl
    > factor numeric
    > 990    9010

Yes.  

Murray's point is valid, too.

But in my view, with the reasoning we have seen here,
*and* with the well known software design principle of
 "least surprise" in mind,
I also do think that the default for type.convert() should be what
it has been for > 10 years now.

Martin


From maechler at stat.math.ethz.ch  Sat Apr 19 15:05:35 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 19 Apr 2014 15:05:35 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <21327.40252.449500.713638@stat.math.ethz.ch>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
	<21327.40252.449500.713638@stat.math.ethz.ch>
Message-ID: <21330.29855.529905.505417@stat.math.ethz.ch>


>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 17 Apr 2014 11:22:04 +0200 writes:

 [................]

    > PS: I'm currently testing a patch where 'R CMD Sweave' will
    > revert to not deleting anything after running the R code by default.

    > Martin Maechler

Some may have noted that R-devel, since svn revsion 65401 (= 2014-04-17 12:19:44 +0200)
now is patched, with log message

> R CMD Sweave must not delete files by default; buildVignette(*, keep);
>  update (and fix/clarify) documentation; 
> cosmetic (& speedup in buildVignettes())

The daily (source!) snapshots of R devel now also contain it.

We plan to port the patch to 'R 3.1.0 patched' (to become 3.1.1
in the future) after the Easter holidays...
and would be glad if some volunteers could support development
of R by testing this (or newer) version of R-devel.

Martin Maechler, ETH Zurich


From marc_schwartz at me.com  Sat Apr 19 16:37:30 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 19 Apr 2014 09:37:30 -0500
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <21330.29855.529905.505417@stat.math.ethz.ch>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
	<21327.40252.449500.713638@stat.math.ethz.ch>
	<21330.29855.529905.505417@stat.math.ethz.ch>
Message-ID: <F996C27F-6E02-4FFB-9982-88E7FDA70257@me.com>


On Apr 19, 2014, at 8:05 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> 
>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>    on Thu, 17 Apr 2014 11:22:04 +0200 writes:
> 
> [................]
> 
>> PS: I'm currently testing a patch where 'R CMD Sweave' will
>> revert to not deleting anything after running the R code by default.
> 
>> Martin Maechler
> 
> Some may have noted that R-devel, since svn revsion 65401 (= 2014-04-17 12:19:44 +0200)
> now is patched, with log message
> 
>> R CMD Sweave must not delete files by default; buildVignette(*, keep);
>> update (and fix/clarify) documentation; 
>> cosmetic (& speedup in buildVignettes())
> 
> The daily (source!) snapshots of R devel now also contain it.
> 
> We plan to port the patch to 'R 3.1.0 patched' (to become 3.1.1
> in the future) after the Easter holidays...
> and would be glad if some volunteers could support development
> of R by testing this (or newer) version of R-devel.
> 
> Martin Maechler, ETH Zurich


Hi Martin,

Thanks for this.

I removed 3.1.0 release on my Mac and cleanly installed:

  R Under development (unstable) (2014-04-17 r65403) -- "Unsuffered Consequences"

from Simon's binary site. This is using the Mavericks binary, albeit on Simon's site, it indicates r65407.

I ran the prior .Rnw file that started this thread and it now works fine, as the created 'non-tex' files are retained upon completion of the R CMD Sweave run.

Thanks for the efforts in fixing this issue.

Regards,

Marc Schwartz


From simon.urbanek at r-project.org  Sat Apr 19 19:06:15 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 19 Apr 2014 13:06:15 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <21330.29530.72292.435730@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
Message-ID: <A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>

On Apr 19, 2014, at 9:00 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>>    on Thu, 17 Apr 2014 19:15:47 -0400 writes:
> 
>>> This is all application specific and
>>> sort of beyond the scope of type.convert(), which now behaves as it
>>> has been documented to behave.
> 
>> That's only a true statement because the documentation was changed to reflect the new behavior! The new feature in type.convert certainly does not behave according to the documentation as of R 3.0.3. Here's a snippit:
> 
>> The first type that can accept all the
>> non-missing values is chosen (numeric and complex return values
>> will represented approximately, of course).
> 
>> The key phrase is in parentheses, which reminds the user to expect a possible loss of precision. That important parenthetical was removed from the documentation in R 3.1.0 (among other changes).
> 
>> Putting aside the fact that this introduces a large amount of unnecessary work rewriting SQL / data import code, SQL packages, my biggest conceptual problem is that I can no longer rely on a particular function call returning a particular class. In my example querying stock prices, about 5% of prices came back as factors and the remaining 95% as numeric, so we had random errors popping in throughout the morning.
> 
>> Here's a short example showing us how the new behavior can be unreliable. I pass a character representation of a uniformly distributed random variable to type.convert. 90% of the time it is converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in which type.convert converts to a factor the leading non-zero digit is always a 9. So if you were expecting a numeric value, then 1 in 10 times you may have a bug in your code that didn't exist before.
> 
>>> options(digits=16)
>>> cl <- NULL; for (i in 1:10000) cl[i] <- class(type.convert(format(runif(1))))
>>> table(cl)
>> cl
>> factor numeric
>> 990    9010
> 
> Yes.  
> 
> Murray's point is valid, too.
> 
> But in my view, with the reasoning we have seen here,
> *and* with the well known software design principle of
> "least surprise" in mind,
> I also do think that the default for type.convert() should be what
> it has been for > 10 years now.
> 

I think there should be two separate discussions:

a) have an option (argument to type.convert and possibly read.table) to enable/disable this behavior. I'm strongly in favor of this.

b) decide what the default for a) will be. I have no strong opinion, I can see arguments in both directions

But most importantly I think a) is better than the status quo - even if the discussion about b) drags out.

Cheers,
Simon


From ggrothendieck at gmail.com  Sat Apr 19 20:48:34 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 19 Apr 2014 14:48:34 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
Message-ID: <CAP01uRmvpGwQm31Lh8nVAysP-c1og+cHSFYROEGibNt1JejDPg@mail.gmail.com>

On Sat, Apr 19, 2014 at 1:06 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Apr 19, 2014, at 9:00 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>
> I think there should be two separate discussions:
>
> a) have an option (argument to type.convert and possibly read.table) to enable/disable this behavior. I'm strongly in favor of this.
>
> b) decide what the default for a) will be. I have no strong opinion, I can see arguments in both directions
>
> But most importantly I think a) is better than the status quo - even if the discussion about b) drags out.
>
> Cheers,
> Simon

Another possibility is:

(c) Return the column as factor/character but with a distinguishing
class so that the user can reset its class later. e.g.

DF <- read.table(...)
DF[] <- lapply(DF, function(x) if (inherits(x, "special.class"))
as.numeric(x) else x)

Personally I would go with (a) in both type.convert and read.table
with a default that reflects the historical behavior rather than the
current 3.1 behavior.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murray at stokely.org  Sun Apr 20 09:24:12 2014
From: murray at stokely.org (Murray Stokely)
Date: Sun, 20 Apr 2014 00:24:12 -0700
Subject: [Rd] type.convert and doubles
In-Reply-To: <A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
Message-ID: <CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>

Yes, I'm also strongly in favor of having an option for this.  If
there was an option in base R for controlling this we would just use
that and get rid of the separate RProtoBuf.int64AsString option we use
in the RProtoBuf package on CRAN to control whether 64-bit int types
from C++ are returned to R as numerics or character vectors.

I agree that reasonable people can disagree about the default, but I
found my original bug report about this, so I will counter Robert's
example with my favorite example of what was wrong with the previous
behavior :

tmp<-data.frame(n=c("72057594037927936", "72057594037927937"),
name=c("foo", "bar"))
length(unique(tmp$n))
# 2
write.csv(tmp, "/tmp/foo.csv", quote=FALSE, row.names=FALSE)
data <- read.csv("/tmp/foo.csv")
length(unique(data$n))
# 1

          - Murray


On Sat, Apr 19, 2014 at 10:06 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Apr 19, 2014, at 9:00 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>
>>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>>>    on Thu, 17 Apr 2014 19:15:47 -0400 writes:
>>
>>>> This is all application specific and
>>>> sort of beyond the scope of type.convert(), which now behaves as it
>>>> has been documented to behave.
>>
>>> That's only a true statement because the documentation was changed to reflect the new behavior! The new feature in type.convert certainly does not behave according to the documentation as of R 3.0.3. Here's a snippit:
>>
>>> The first type that can accept all the
>>> non-missing values is chosen (numeric and complex return values
>>> will represented approximately, of course).
>>
>>> The key phrase is in parentheses, which reminds the user to expect a possible loss of precision. That important parenthetical was removed from the documentation in R 3.1.0 (among other changes).
>>
>>> Putting aside the fact that this introduces a large amount of unnecessary work rewriting SQL / data import code, SQL packages, my biggest conceptual problem is that I can no longer rely on a particular function call returning a particular class. In my example querying stock prices, about 5% of prices came back as factors and the remaining 95% as numeric, so we had random errors popping in throughout the morning.
>>
>>> Here's a short example showing us how the new behavior can be unreliable. I pass a character representation of a uniformly distributed random variable to type.convert. 90% of the time it is converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in which type.convert converts to a factor the leading non-zero digit is always a 9. So if you were expecting a numeric value, then 1 in 10 times you may have a bug in your code that didn't exist before.
>>
>>>> options(digits=16)
>>>> cl <- NULL; for (i in 1:10000) cl[i] <- class(type.convert(format(runif(1))))
>>>> table(cl)
>>> cl
>>> factor numeric
>>> 990    9010
>>
>> Yes.
>>
>> Murray's point is valid, too.
>>
>> But in my view, with the reasoning we have seen here,
>> *and* with the well known software design principle of
>> "least surprise" in mind,
>> I also do think that the default for type.convert() should be what
>> it has been for > 10 years now.
>>
>
> I think there should be two separate discussions:
>
> a) have an option (argument to type.convert and possibly read.table) to enable/disable this behavior. I'm strongly in favor of this.
>
> b) decide what the default for a) will be. I have no strong opinion, I can see arguments in both directions
>
> But most importantly I think a) is better than the status quo - even if the discussion about b) drags out.
>
> Cheers,
> Simon
>
>
>


From maechler at stat.math.ethz.ch  Sun Apr 20 20:19:40 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sun, 20 Apr 2014 20:19:40 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <F996C27F-6E02-4FFB-9982-88E7FDA70257@me.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
	<21327.40252.449500.713638@stat.math.ethz.ch>
	<21330.29855.529905.505417@stat.math.ethz.ch>
	<F996C27F-6E02-4FFB-9982-88E7FDA70257@me.com>
Message-ID: <21332.4028.705122.456144@stat.math.ethz.ch>

>>>>> Marc Schwartz <marc_schwartz at me.com>
>>>>>     on Sat, 19 Apr 2014 09:37:30 -0500 writes:

    > On Apr 19, 2014, at 8:05 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:

    >> 
    >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch> on Thu,
    >>>>>>> 17 Apr 2014 11:22:04 +0200 writes:
    >> 
    >> [................]
    >> 
    >>> PS: I'm currently testing a patch where 'R CMD Sweave'
    >>> will revert to not deleting anything after running the R
    >>> code by default.
    >> 
    >>> Martin Maechler
    >> 
    >> Some may have noted that R-devel, since svn revsion 65401
    >> (= 2014-04-17 12:19:44 +0200) now is patched, with log
    >> message
    >> 
    >>> R CMD Sweave must not delete files by default;
    >>> buildVignette(*, keep); update (and fix/clarify)
    >>> documentation; cosmetic (& speedup in buildVignettes())
    >> 
    >> The daily (source!) snapshots of R devel now also contain
    >> it.
    >> 
    >> We plan to port the patch to 'R 3.1.0 patched' (to become
    >> 3.1.1 in the future) after the Easter holidays...  and
    >> would be glad if some volunteers could support
    >> development of R by testing this (or newer) version of
    >> R-devel.
    >> 
    >> Martin Maechler, ETH Zurich


    > Hi Martin,

    > Thanks for this.

    > I removed 3.1.0 release on my Mac and cleanly installed:

    >   R Under development (unstable) (2014-04-17 r65403) --
    > "Unsuffered Consequences"

    > from Simon's binary site. This is using the Mavericks
    > binary, albeit on Simon's site, it indicates r65407.

    > I ran the prior .Rnw file that started this thread and it
    > now works fine, as the created 'non-tex' files are
    > retained upon completion of the R CMD Sweave run.

Thank you, Marc, for the confirmation.

    > Thanks for the efforts in fixing this issue.

you are welcome, and thanked again together with everyone who
spends the little extra time for checking / using "the next
version of R" -- in general, i.e., on a regular basis.

Martin

    > Regards,
    > Marc Schwartz


From csardi.gabor at gmail.com  Sun Apr 20 20:22:57 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 20 Apr 2014 14:22:57 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
Message-ID: <CABtg=KnPivHj2dpQ1A=GhnimsxTbi9_c7umK29eLhSrEGd+oMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140420/04fe5f37/attachment.pl>

From jorismeys at gmail.com  Sun Apr 20 20:45:51 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Sun, 20 Apr 2014 20:45:51 +0200
Subject: [Rd] lag() not returning a time series object
In-Reply-To: <CAO1zAVaQfta=HjfwZGPs6D=LVS4xG7RxWDP2Au-J=dUgUPsvEg@mail.gmail.com>
References: <CAO1zAVaQfta=HjfwZGPs6D=LVS4xG7RxWDP2Au-J=dUgUPsvEg@mail.gmail.com>
Message-ID: <CAO1zAVa6dbNPg_b44b9_wuVUv--PZmz7aU-_U6gf6+C_VEx8Ow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140420/e546e254/attachment.pl>

From murdoch.duncan at gmail.com  Sun Apr 20 21:28:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Apr 2014 15:28:59 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CABtg=KnPivHj2dpQ1A=GhnimsxTbi9_c7umK29eLhSrEGd+oMQ@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>	<534860CC.2090206@gmail.com>	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>	<21330.29530.72292.435730@stat.math.ethz.ch>	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>	<CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
	<CABtg=KnPivHj2dpQ1A=GhnimsxTbi9_c7umK29eLhSrEGd+oMQ@mail.gmail.com>
Message-ID: <53541FFB.4040404@gmail.com>

On 20/04/2014, 2:22 PM, G?bor Cs?rdi wrote:
> How about using the quoting to decide what should be character, and what
> not? You do not need to quote numbers, logical values, only characters, so
> this would make sense imo.

That explicitly violates some of the CSV "standards".  The quotes must 
have no effect on the interpretation.

Duncan Murdoch

>
> How about something like this:
> - if it is quoted (and not specified otherwise in colClasses), then it is a
> character/factor
> - if it is not quoted (and not specified otherwise in colClasses), then the
> type is automatically detected, according to the pre-3.1.x method, and a
> (suppressible) warning or error is given if information is lost, when
> coercing to numbers.
>
> Just an idea.
>
> Gabor
>
> On Sun, Apr 20, 2014 at 3:24 AM, Murray Stokely <murray at stokely.org> wrote:
>
>> Yes, I'm also strongly in favor of having an option for this.  If
>> there was an option in base R for controlling this we would just use
>> that and get rid of the separate RProtoBuf.int64AsString option we use
>> in the RProtoBuf package on CRAN to control whether 64-bit int types
>> from C++ are returned to R as numerics or character vectors.
>>
>> I agree that reasonable people can disagree about the default, but I
>> found my original bug report about this, so I will counter Robert's
>> example with my favorite example of what was wrong with the previous
>> behavior :
>>
>> tmp<-data.frame(n=c("72057594037927936", "72057594037927937"),
>> name=c("foo", "bar"))
>> length(unique(tmp$n))
>> # 2
>> write.csv(tmp, "/tmp/foo.csv", quote=FALSE, row.names=FALSE)
>> data <- read.csv("/tmp/foo.csv")
>> length(unique(data$n))
>> # 1
>>
>>            - Murray
>>
>>
>> On Sat, Apr 19, 2014 at 10:06 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> On Apr 19, 2014, at 9:00 AM, Martin Maechler <maechler at stat.math.ethz.ch>
>> wrote:
>>>
>>>>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>>>>>     on Thu, 17 Apr 2014 19:15:47 -0400 writes:
>>>>
>>>>>> This is all application specific and
>>>>>> sort of beyond the scope of type.convert(), which now behaves as it
>>>>>> has been documented to behave.
>>>>
>>>>> That's only a true statement because the documentation was changed to
>> reflect the new behavior! The new feature in type.convert certainly does
>> not behave according to the documentation as of R 3.0.3. Here's a snippit:
>>>>
>>>>> The first type that can accept all the
>>>>> non-missing values is chosen (numeric and complex return values
>>>>> will represented approximately, of course).
>>>>
>>>>> The key phrase is in parentheses, which reminds the user to expect a
>> possible loss of precision. That important parenthetical was removed from
>> the documentation in R 3.1.0 (among other changes).
>>>>
>>>>> Putting aside the fact that this introduces a large amount of
>> unnecessary work rewriting SQL / data import code, SQL packages, my biggest
>> conceptual problem is that I can no longer rely on a particular function
>> call returning a particular class. In my example querying stock prices,
>> about 5% of prices came back as factors and the remaining 95% as numeric,
>> so we had random errors popping in throughout the morning.
>>>>
>>>>> Here's a short example showing us how the new behavior can be
>> unreliable. I pass a character representation of a uniformly distributed
>> random variable to type.convert. 90% of the time it is converted to
>> "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in
>> which type.convert converts to a factor the leading non-zero digit is
>> always a 9. So if you were expecting a numeric value, then 1 in 10 times
>> you may have a bug in your code that didn't exist before.
>>>>
>>>>>> options(digits=16)
>>>>>> cl <- NULL; for (i in 1:10000) cl[i] <-
>> class(type.convert(format(runif(1))))
>>>>>> table(cl)
>>>>> cl
>>>>> factor numeric
>>>>> 990    9010
>>>>
>>>> Yes.
>>>>
>>>> Murray's point is valid, too.
>>>>
>>>> But in my view, with the reasoning we have seen here,
>>>> *and* with the well known software design principle of
>>>> "least surprise" in mind,
>>>> I also do think that the default for type.convert() should be what
>>>> it has been for > 10 years now.
>>>>
>>>
>>> I think there should be two separate discussions:
>>>
>>> a) have an option (argument to type.convert and possibly read.table) to
>> enable/disable this behavior. I'm strongly in favor of this.
>>>
>>> b) decide what the default for a) will be. I have no strong opinion, I
>> can see arguments in both directions
>>>
>>> But most importantly I think a) is better than the status quo - even if
>> the discussion about b) drags out.
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeroen.ooms at stat.ucla.edu  Mon Apr 21 00:43:31 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 20 Apr 2014 15:43:31 -0700
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <21332.4028.705122.456144@stat.math.ethz.ch>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>
	<21323.54364.87334.81949@stat.math.ethz.ch>
	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>
	<534D14AF.8020500@gmail.com>
	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>
	<534D2C0A.3090502@gmail.com>
	<21327.40252.449500.713638@stat.math.ethz.ch>
	<21330.29855.529905.505417@stat.math.ethz.ch>
	<F996C27F-6E02-4FFB-9982-88E7FDA70257@me.com>
	<21332.4028.705122.456144@stat.math.ethz.ch>
Message-ID: <CABFfbXsrzW_ka2XgONfXd3r2p56vD49acrwmHOm1E-xhbtDnvg@mail.gmail.com>

On Sun, Apr 20, 2014 at 11:19 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> you are welcome, and thanked again together with everyone who
> spends the little extra time for checking / using "the next
> version of R" -- in general, i.e., on a regular basis.

With the risk of starting another flamewar I would like to point out
that a natural way to encourage use of r-patched/r-dev would be
extending the R release cycle to CRAN packages as was proposed on this
mailing list a couple of weeks ago.

If install.packages would default to downloading frozen/stable CRAN
packages in r-release, and download the very latest CRAN packages in
r-patched/r-dev, then most developers would probably switch to r-dev.
Thereby they would automatically be using the latest ("devel")
versions of base packages in the same way as they currently test their
script/project/package to work with the latest ("current") versions of
CRAN packages.


From murdoch.duncan at gmail.com  Mon Apr 21 13:43:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Apr 2014 07:43:55 -0400
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
In-Reply-To: <CABFfbXsrzW_ka2XgONfXd3r2p56vD49acrwmHOm1E-xhbtDnvg@mail.gmail.com>
References: <4E473ADD-6080-496D-AF34-15AEDEE52CDB@me.com>	<21323.54364.87334.81949@stat.math.ethz.ch>	<CAD32310-9E37-43A0-8CA6-9FF4A01C5324@me.com>	<534D14AF.8020500@gmail.com>	<2C3A5ADD-8560-448F-8042-74D68EBF922D@gmail.com>	<534D2C0A.3090502@gmail.com>	<21327.40252.449500.713638@stat.math.ethz.ch>	<21330.29855.529905.505417@stat.math.ethz.ch>	<F996C27F-6E02-4FFB-9982-88E7FDA70257@me.com>	<21332.4028.705122.456144@stat.math.ethz.ch>
	<CABFfbXsrzW_ka2XgONfXd3r2p56vD49acrwmHOm1E-xhbtDnvg@mail.gmail.com>
Message-ID: <5355047B.5060406@gmail.com>

On 20/04/2014, 6:43 PM, Jeroen Ooms wrote:
> On Sun, Apr 20, 2014 at 11:19 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>> you are welcome, and thanked again together with everyone who
>> spends the little extra time for checking / using "the next
>> version of R" -- in general, i.e., on a regular basis.
>
> With the risk of starting another flamewar I would like to point out
> that a natural way to encourage use of r-patched/r-dev would be
> extending the R release cycle to CRAN packages as was proposed on this
> mailing list a couple of weeks ago.
>
> If install.packages would default to downloading frozen/stable CRAN
> packages in r-release, and download the very latest CRAN packages in
> r-patched/r-dev, then most developers would probably switch to r-dev.

I doubt if that would be true.  I'd guess most everybody would use 
r-patched.  This would have the effect that nobody would have 
reproducible research (since r-patched builds aren't archived), and few 
would test r-devel.

Duncan Murdoch

> Thereby they would automatically be using the latest ("devel")
> versions of base packages in the same way as they currently test their
> script/project/package to work with the latest ("current") versions of
> CRAN packages.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Robert.McGehee at geodecapital.com  Mon Apr 21 15:24:13 2014
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon, 21 Apr 2014 09:24:13 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
Message-ID: <CF7A8B8B.42D8%Robert.McGehee@geodecapital.com>

Agreed. Perhaps even a global option would make sense. We already have an
option with a similar spirit: 'options(?stringsAsFactors"=T/F)'. Perhaps
'options(?exactNumericAsString?=T/F)' [or something else] would be
desirable, with the option being the default value to the type.convert
argument. 

I also like Gabor?s idea of a ?distinguishing class?. R doesn?t natively
support arbitrary precision numbers (AFAIK), but I think that?s what
Murray wants. I could imagine some kind of new class emerging here that
initially looks just like a character/factor, but may evolve over time to
accept arithmetic methods and act more like a number (e.g. knowing that
?0.1?, ?.10? and "1e-1" are the same number, or that ?-9?<?-0.2"). A class
?bignum? perhaps? 

Cheers, Robert


On 4/20/14, 3:24 AM, "Murray Stokely" <murray at stokely.org> wrote:

>Yes, I'm also strongly in favor of having an option for this.  If
>there was an option in base R for controlling this we would just use
>that and get rid of the separate RProtoBuf.int64AsString option we use
>in the RProtoBuf package on CRAN to control whether 64-bit int types
>from C++ are returned to R as numerics or character vectors.
>
>I agree that reasonable people can disagree about the default, but I
>found my original bug report about this, so I will counter Robert's
>example with my favorite example of what was wrong with the previous
>behavior :
>
>tmp<-data.frame(n=c("72057594037927936", "72057594037927937"),
>name=c("foo", "bar"))
>length(unique(tmp$n))
># 2
>write.csv(tmp, "/tmp/foo.csv", quote=FALSE, row.names=FALSE)
>data <- read.csv("/tmp/foo.csv")
>length(unique(data$n))
># 1
>
>          - Murray
>
>
>On Sat, Apr 19, 2014 at 10:06 AM, Simon Urbanek
><simon.urbanek at r-project.org> wrote:
>> On Apr 19, 2014, at 9:00 AM, Martin Maechler
>><maechler at stat.math.ethz.ch> wrote:
>>
>>>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>>>>    on Thu, 17 Apr 2014 19:15:47 -0400 writes:
>>>
>>>>> This is all application specific and
>>>>> sort of beyond the scope of type.convert(), which now behaves as it
>>>>> has been documented to behave.
>>>
>>>> That's only a true statement because the documentation was changed to
>>>>reflect the new behavior! The new feature in type.convert certainly
>>>>does not behave according to the documentation as of R 3.0.3. Here's a
>>>>snippit:
>>>
>>>> The first type that can accept all the
>>>> non-missing values is chosen (numeric and complex return values
>>>> will represented approximately, of course).
>>>
>>>> The key phrase is in parentheses, which reminds the user to expect a
>>>>possible loss of precision. That important parenthetical was removed
>>>>from the documentation in R 3.1.0 (among other changes).
>>>
>>>> Putting aside the fact that this introduces a large amount of
>>>>unnecessary work rewriting SQL / data import code, SQL packages, my
>>>>biggest conceptual problem is that I can no longer rely on a
>>>>particular function call returning a particular class. In my example
>>>>querying stock prices, about 5% of prices came back as factors and the
>>>>remaining 95% as numeric, so we had random errors popping in
>>>>throughout the morning.
>>>
>>>> Here's a short example showing us how the new behavior can be
>>>>unreliable. I pass a character representation of a uniformly
>>>>distributed random variable to type.convert. 90% of the time it is
>>>>converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the
>>>>10% of cases in which type.convert converts to a factor the leading
>>>>non-zero digit is always a 9. So if you were expecting a numeric
>>>>value, then 1 in 10 times you may have a bug in your code that didn't
>>>>exist before.
>>>
>>>>> options(digits=16)
>>>>> cl <- NULL; for (i in 1:10000) cl[i] <-
>>>>>class(type.convert(format(runif(1))))
>>>>> table(cl)
>>>> cl
>>>> factor numeric
>>>> 990    9010
>>>
>>> Yes.
>>>
>>> Murray's point is valid, too.
>>>
>>> But in my view, with the reasoning we have seen here,
>>> *and* with the well known software design principle of
>>> "least surprise" in mind,
>>> I also do think that the default for type.convert() should be what
>>> it has been for > 10 years now.
>>>
>>
>> I think there should be two separate discussions:
>>
>> a) have an option (argument to type.convert and possibly read.table) to
>>enable/disable this behavior. I'm strongly in favor of this.
>>
>> b) decide what the default for a) will be. I have no strong opinion, I
>>can see arguments in both directions
>>
>> But most importantly I think a) is better than the status quo - even if
>>the discussion about b) drags out.
>>
>> Cheers,
>> Simon
>>
>>
>>


From atp at piskorski.com  Mon Apr 21 17:53:17 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 21 Apr 2014 11:53:17 -0400
Subject: [Rd] read.table() code fails outside of the utils package
Message-ID: <20140421155317.GA11783@piskorski.com>

One of the great things about R is how readable and re-usable much of
its own implementation is.  If an R function doesn't do quite what you
want but is close, it is usually very easy to read its code and start
adapting that as the base for a modified version.

In the 2.x versions of R, that was the case with read.table().  It was
easy to experiment with its source code, as it all worked just fine
when run at the top level or from inside any other package.

In R 3.1.0, that is no longer true.  The read.table() source ONLY works
when run from inside the "utils" package.  The (only) culprit is this:

  .External(C_readtablehead, file, 1L, comment.char, blank.lines.skip, quote, sep, skipNul)

Older versions of read.table() instead did this, which ran fine from
any package; this entry point no longer exists:

  .Internal(readTableHead(file, nlines, comment.char, blank.lines.skip, quote, sep)) 

The C implementation of readTableHead is in utils.so, but the symbol
is marked as local.  I tried adding "attribute_visible" to its
function definition in "src/library/utils/src/io.c" and recompiling,
which DID make the symbol globally visible.  With that change, my own
C code works just fine when calling readTableHead.  But interestingly,
R code using .External() like this still fails:

   .External("readtablehead", ..., PACKAGE="utils") 
   Error: "readtablehead" not available for .External() for package "utils" 

Why is that?  Apparently the C symbol being visible isn't enough, but
what else is needed for .External() to work?
(Clearly there's something here about how R C programming works that I
don't understand.)

Finally, since it is generally useful to be able to experiment with
and re-use parts of the stock read.table() implementation, I suggest:

1. R add "attribute_visible" or otherwise make readtablehead callable
   from user C code.
2. R make readtablehead callable from user R code via .External().

What do you think?  Note that I'm not asking that the current
interface or behavior of readtablehead necessarily be SUPPORTED in any
way, just that it be callable for experimental purposes, much as the
old .Internal(readTableHead()) was in earlier versions of R.

-- 
Andrew Piskorski <atp at piskorski.com>


From simon.urbanek at r-project.org  Mon Apr 21 18:43:55 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 21 Apr 2014 12:43:55 -0400
Subject: [Rd] read.table() code fails outside of the utils package
In-Reply-To: <20140421155317.GA11783@piskorski.com>
References: <20140421155317.GA11783@piskorski.com>
Message-ID: <27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>

Andrew,

On Apr 21, 2014, at 11:53 AM, Andrew Piskorski <atp at piskorski.com> wrote:

> One of the great things about R is how readable and re-usable much of
> its own implementation is.  If an R function doesn't do quite what you
> want but is close, it is usually very easy to read its code and start
> adapting that as the base for a modified version.
> 
> In the 2.x versions of R, that was the case with read.table().  It was
> easy to experiment with its source code, as it all worked just fine
> when run at the top level or from inside any other package.
> 
> In R 3.1.0, that is no longer true.  The read.table() source ONLY works
> when run from inside the "utils" package.  The (only) culprit is this:
> 
>  .External(C_readtablehead, file, 1L, comment.char, blank.lines.skip, quote, sep, skipNul)
> 
> Older versions of read.table() instead did this, which ran fine from
> any package; this entry point no longer exists:
> 
>  .Internal(readTableHead(file, nlines, comment.char, blank.lines.skip, quote, sep)) 
> 
> The C implementation of readTableHead is in utils.so, but the symbol
> is marked as local.

And that's how it should be - there is not reason why any other code should link to it. Why don't you just use

.External(utils:::C_readtablehead, ...)

if you need to call it?

Cheers,
Simon


>  .External(C_readtablehead, file, 1L, comment.char, blank.lines.skip, quote, sep, skipNul)
>  I tried adding "attribute_visible" to its
> function definition in "src/library/utils/src/io.c" and recompiling,
> which DID make the symbol globally visible.  With that change, my own
> C code works just fine when calling readTableHead.  But interestingly,
> R code using .External() like this still fails:
> 
>   .External("readtablehead", ..., PACKAGE="utils") 
>   Error: "readtablehead" not available for .External() for package "utils" 
> 
> Why is that?  Apparently the C symbol being visible isn't enough, but
> what else is needed for .External() to work?
> (Clearly there's something here about how R C programming works that I
> don't understand.)
> 
> Finally, since it is generally useful to be able to experiment with
> and re-use parts of the stock read.table() implementation, I suggest:
> 
> 1. R add "attribute_visible" or otherwise make readtablehead callable
>   from user C code.
> 2. R make readtablehead callable from user R code via .External().
> 
> What do you think?  Note that I'm not asking that the current
> interface or behavior of readtablehead necessarily be SUPPORTED in any
> way, just that it be callable for experimental purposes, much as the
> old .Internal(readTableHead()) was in earlier versions of R.
> 
> -- 
> Andrew Piskorski <atp at piskorski.com>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From atp at piskorski.com  Mon Apr 21 19:08:51 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 21 Apr 2014 13:08:51 -0400
Subject: [Rd] read.table() code fails outside of the utils package
In-Reply-To: <27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>
References: <20140421155317.GA11783@piskorski.com>
	<27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>
Message-ID: <20140421170851.GA28440@piskorski.com>

On Mon, Apr 21, 2014 at 12:43:55PM -0400, Simon Urbanek wrote:

> And that's how it should be - there is not reason why any other code should link to it. Why don't you just use
> 
> .External(utils:::C_readtablehead, ...)

Ah, that works fine, and is nice and simple.  So problem solved, thank
you!

I do still wonder though, with the C symbol made visible in utils.so,
how come this still failed?:

   .External("readtablehead", ..., PACKAGE="utils") 
   Error: "readtablehead" not available for .External() for package "utils" 

-- 
Andrew Piskorski <atp at piskorski.com>


From gmbecker at ucdavis.edu  Mon Apr 21 19:14:02 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 21 Apr 2014 10:14:02 -0700
Subject: [Rd] read.table() code fails outside of the utils package
In-Reply-To: <20140421170851.GA28440@piskorski.com>
References: <20140421155317.GA11783@piskorski.com>
	<27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>
	<20140421170851.GA28440@piskorski.com>
Message-ID: <CADwqtCNNp+FJoeQK2T_w9mj3mrb0rOyTNaGzRB9CpBqFSkyfSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140421/f3b0b0bd/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Apr 21 19:44:05 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Apr 2014 18:44:05 +0100
Subject: [Rd] read.table() code fails outside of the utils package
In-Reply-To: <20140421170851.GA28440@piskorski.com>
References: <20140421155317.GA11783@piskorski.com>	<27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>
	<20140421170851.GA28440@piskorski.com>
Message-ID: <535558E5.3030105@stats.ox.ac.uk>

On 21/04/2014 18:08, Andrew Piskorski wrote:
> On Mon, Apr 21, 2014 at 12:43:55PM -0400, Simon Urbanek wrote:
>
>> And that's how it should be - there is not reason why any other code should link to it. Why don't you just use
>>
>> .External(utils:::C_readtablehead, ...)
>
> Ah, that works fine, and is nice and simple.  So problem solved, thank
> you!
>
> I do still wonder though, with the C symbol made visible in utils.so,

That isn't true on platforms which support hiding entry points.  Try

% nm -g library/utils/libs/utils.so | grep readtablehead

on Linux.

> how come this still failed?:
>
>     .External("readtablehead", ..., PACKAGE="utils")
>     Error: "readtablehead" not available for .External() for package "utils"

Rather, you need to tell us why that should have worked ....  Maybe you 
failed to read in the code

R_init_utils(DllInfo *dll)
{
     R_registerRoutines(dll, NULL, CallEntries, NULL, ExtEntries);
     R_useDynamicSymbols(dll, FALSE);
     R_forceSymbols(dll, TRUE);
}

See 'Writing R Extensions'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From atp at piskorski.com  Mon Apr 21 21:28:21 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 21 Apr 2014 15:28:21 -0400
Subject: [Rd] how to get old type.convert() numeric behavior?
Message-ID: <20140421192821.GA48319@piskorski.com>

Regarding this change:

> CHANGES IN R 3.1.0: 
>   NEW FEATURES: 
>     * type.convert() (and hence by default read.table()) returns a 
>       character vector or factor when representing a numeric input as a 
>       double would lose accuracy.  Similarly for complex inputs. 
>  
>       If a file contains numeric data with unrepresentable numbers of 
>       decimal places that are intended to be read as numeric, specify 
>       colClasses in read.table() to be "numeric". 

How do I get the old behavior where type.convert() automatically
converts to numeric if suitable, regardless of whether or not the
string has more than 17 digits of accuracy?

Sure, I could first pass every single column of data through a kludgy
checking function like my.can.be.numeric() below, and then set
colClasses to "numeric" or not based on that, but is there a better
way?


my.can.be.numeric <- function(xx) { 
   old.warn <- options(warn = -1) 
   on.exit(options(old.warn)) 
   (!is.na(as.numeric(xx))) 
} 

Example of the changed behavior in R 3.1.0 vs. earlier versions, both
with options("digits"=10) set:
  
# R version 3.1.0 Patched (2014-04-15 r65398) -- "Spring Dance" 
# Platform: x86_64-unknown-linux-gnu/x86_64 (64-bit) 
> type.convert(paste("0.", paste(rep(0:9,3)[seq_len(17)],collapse=""), sep=""), as.is=TRUE) 
[1] 0.01234568 
> type.convert(paste("0.", paste(rep(0:9,3)[seq_len(18)],collapse=""), sep=""), as.is=TRUE) 
[1] "0.012345678901234567" 

# R version 3.0.2 Patched (2013-10-23 r64103) -- "Frisbee Sailing" 
# Platform: x86_64-unknown-linux-gnu/x86_64 (64-bit) 
> type.convert(paste("0.", paste(rep(0:9,3)[seq_len(17)],collapse=""), sep=""), as.is=TRUE) 
[1] 0.01234568 
> type.convert(paste("0.", paste(rep(0:9,3)[seq_len(18)],collapse=""), sep=""), as.is=TRUE) 
[1] 0.01234568 

-- 
Andrew Piskorski <atp at piskorski.com>


From wdunlap at tibco.com  Mon Apr 21 22:04:44 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Apr 2014 20:04:44 +0000
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <21330.29344.628971.904268@stat.math.ethz.ch>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
	<21330.29344.628971.904268@stat.math.ethz.ch>
Message-ID: <E66794E69CFDE04D9A70842786030B933FACA474@PA-MBX01.na.tibco.com>

>     >> structure(Sys.getenv(), class="simple.list")
>     >                            _ !
> 
> Good idea; this is something we could do unconditionally, i.e.,
> return from Sys.getenv().

As the OP noted, the print method for simple.list will pad all
lines to have the same length, so if, say, PATH, is very long,
all other printed lines will be padded with blanks to match its
length.  With the Windows GUI you don't notice this much
because the lines do not wrap around, but when viewing results
on Linux with a terminal emulator like putty this looks bad.  A print method like
   p <- function(x, ...)
   {
      cat(formatDL(x), sep="\n")
      invisible(x)
   }
would look better.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Saturday, April 19, 2014 5:57 AM
> To: William Dunlap
> Cc: Jun Zhang; r-devel at r-project.org
> Subject: Re: [Rd] Can the output of Sys.getenv() be improved?
> 
> >>>>> William Dunlap <wdunlap at tibco.com>
> >>>>>     on Fri, 18 Apr 2014 16:50:22 +0000 writes:
> 
>     >> Within an R session, type Sys.getenv() will list all the
>     >> environment variables, but each one of them occupies
>     >> about a page, so scrolling to find one is difficult. Is
>     >> this because I don't know how to use it or something
>     >> could be improved?
> 
>     > Attaching the class "simple.list" to the output of
>     > Sys.getenv() gives it a nicer print method:
> 
>     >> structure(Sys.getenv(), class="simple.list")
>     >                            _ !
> 
> Good idea; this is something we could do unconditionally, i.e.,
> return from Sys.getenv().
> It would hardly break code,
> as simple.list only has a print and a `[` method.
> 
> It would help people like Jun and could hardly harm, AFAICS.
> 
> Opinions?


From atp at piskorski.com  Mon Apr 21 22:13:16 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 21 Apr 2014 16:13:16 -0400
Subject: [Rd] read.table() code fails outside of the utils package
In-Reply-To: <535558E5.3030105@stats.ox.ac.uk>
References: <20140421155317.GA11783@piskorski.com>
	<27A253DD-2564-4F6E-AD37-24737BCF4FFE@r-project.org>
	<20140421170851.GA28440@piskorski.com>
	<535558E5.3030105@stats.ox.ac.uk>
Message-ID: <20140421201316.GA54548@piskorski.com>

On Mon, Apr 21, 2014 at 06:44:05PM +0100, Prof Brian Ripley wrote:
> On 21/04/2014 18:08, Andrew Piskorski wrote:

> >> .External(utils:::C_readtablehead, ...)
> >
> > Ah, that works fine, and is nice and simple.  So problem solved, thank
> > you!
> >
> > I do still wonder though, with the C symbol made visible in utils.so,
> 
> That isn't true on platforms which support hiding entry points.  Try
> 
> % nm -g library/utils/libs/utils.so | grep readtablehead
> 
> on Linux.

What isn't true?  That .External(utils:::C_readtablehead, ...)
should work for me under stock R 3.0.1?  My Linux (Ubuntu 12.04.3 LTS)
definitely does seem to support hiding entry points.

I have two separate installs, both built from source.  The first one
is stock, and the lower-case "t" here indicates that the readtablehead
symbol is local:

  andy at odo:~$ nm /usr/local/pkg/R-3.1-branch-20140416/lib/R/library/utils/libs/x86_64/utils.so | grep readtablehead
  00000000000059a0 t readtablehead

This second install is where I added "attribute_visible" to
readtablehead and recompiled, the upper-case "T" means it is a global
symbol:

  andy at odo:~$ nm /usr/local/pkg/R-3.1-branch-20140418/lib/R/library/utils/libs/x86_64/utils.so | grep readtablehead
  00000000000059c0 T readtablehead

Fortunately, calling .External(utils:::C_readtablehead, ...) works
with either of those installs.  But writing my won C code that calls
readtablehead only works in the second one where the symbol is global.

> > how come this still failed?:
> >
> >     .External("readtablehead", ..., PACKAGE="utils")
> >     Error: "readtablehead" not available for .External() for package "utils"
> 
> Rather, you need to tell us why that should have worked ....

That exact style of call DOES work for every cross-package use of .C
and .Call I've tried in my own code.  But I have never "registered"
any of my C code with R.  Obviously there is something different about
readtablehead and/or the utils package (probably the latter), and I am
trying to understand what it is.

> Maybe you failed to read in the code
> 
> R_init_utils(DllInfo *dll)
> {
>      R_registerRoutines(dll, NULL, CallEntries, NULL, ExtEntries);
>      R_useDynamicSymbols(dll, FALSE);
>      R_forceSymbols(dll, TRUE);
> }

I believe you are implying that using R_registerRoutines in a package
changes the behavior of .Call() and .External() such that ONLY
registered functions will be found, even if I invoke .External() with
a string function name like "readtablehead" rather than the registered
value C_readtablehead.  While if I do not register any C functions at
all in a package, then using a string name like "readtablehead" will
work as long as that C function symbol is visible.

> >     .External("readtablehead", ..., PACKAGE="utils")
> >     Error: "readtablehead" not available for .External() for package "utils"

> See 'Writing R Extensions'.

I already had, many times.  If this question is answered there, it was
not apparent to me.

-- 
Andrew Piskorski <atp at piskorski.com>


From maechler at stat.math.ethz.ch  Tue Apr 22 09:42:11 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Apr 2014 09:42:11 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <CF7A8B8B.42D8%Robert.McGehee@geodecapital.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<CAECWziLUnzDzrT6gt8aAEmwTTzxigOF5DsPvr=KKVet6DBHYiQ@mail.gmail.com>
	<CF7A8B8B.42D8%Robert.McGehee@geodecapital.com>
Message-ID: <21334.7507.964128.304846@stat.math.ethz.ch>

>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
>>>>>     on Mon, 21 Apr 2014 09:24:13 -0400 writes:

    > Agreed. Perhaps even a global option would make sense. We
    > already have an option with a similar spirit:
    > 'options(?stringsAsFactors"=T/F)'. Perhaps
    > 'options(?exactNumericAsString?=T/F)' [or something else]
    > would be desirable, with the option being the default
    > value to the type.convert argument.

No, please, no, not a global option here!

Global options that influence default behavior of basic
functions is too much against the principle of functional
programming, and my personal opinion has always been that
'stringsAsFactors' has been a mistake (as a global option, not
as an argument).

Note that with such global options, the output of sessionInfo()
would in principle have to contain all (such) global options in
addtion to R and package versions in order to diagnose behavior
of R functions.

I think we have more or less agreed that we'd like to have
a new function *argument* to type.convert(); 
passed "upstream" to read.table() and via ... the other
read.<foo>() that call read.table.


    > I also like Gabor?s idea of a ?distinguishing class?. R
    > doesn?t natively support arbitrary precision numbers
    > (AFAIK), but I think that?s what Murray wants. I could
    > imagine some kind of new class emerging here that
    > initially looks just like a character/factor, but may
    > evolve over time to accept arithmetic methods and act more
    > like a number (e.g. knowing that ?0.1?, ?.10? and "1e-1"
    > are the same number, or that ?-9?<?-0.2"). A class
    > ?bignum? perhaps?

That's another interesting idea. As maintainer of CRAN package
'Rmpfr' and co-maintainer of 'gmp', I'm even biased about this
issue.

Martin

    > Cheers, Robert


    > On 4/20/14, 3:24 AM, "Murray Stokely" <murray at stokely.org>
    > wrote:

    >> Yes, I'm also strongly in favor of having an option for
    >> this.  If there was an option in base R for controlling
    >> this we would just use that and get rid of the separate
    >> RProtoBuf.int64AsString option we use in the RProtoBuf
    >> package on CRAN to control whether 64-bit int types from
    >> C++ are returned to R as numerics or character vectors.
    >> 
    >> I agree that reasonable people can disagree about the
    >> default, but I found my original bug report about this,
    >> so I will counter Robert's example with my favorite
    >> example of what was wrong with the previous behavior :
    >> 
    >> tmp<-data.frame(n=c("72057594037927936",
    >> "72057594037927937"), name=c("foo", "bar"))
    >> length(unique(tmp$n)) # 2 write.csv(tmp, "/tmp/foo.csv",
    >> quote=FALSE, row.names=FALSE) data <-
    >> read.csv("/tmp/foo.csv") length(unique(data$n)) # 1
    >> 
    >> - Murray
    >> 
    >> 
    >> On Sat, Apr 19, 2014 at 10:06 AM, Simon Urbanek
    >> <simon.urbanek at r-project.org> wrote:
    >>> On Apr 19, 2014, at 9:00 AM, Martin Maechler
    >>> <maechler at stat.math.ethz.ch> wrote:
    >>> 
    >>>>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
    >>>>>>>>> on Thu, 17 Apr 2014 19:15:47 -0400 writes:
    >>>> 
>>>>> This is all application specific and
>>>>> sort of beyond the scope of type.convert(), which now
    >>>> behaves as it
>>>>> has been documented to behave.
    >>>> 
    >>>>> That's only a true statement because the documentation
    >>>>> was changed to reflect the new behavior! The new
    >>>>> feature in type.convert certainly does not behave
    >>>>> according to the documentation as of R 3.0.3. Here's a
    >>>>> snippit:
    >>>> 
    >>>>> The first type that can accept all the non-missing
    >>>>> values is chosen (numeric and complex return values
    >>>>> will represented approximately, of course).
    >>>> 
    >>>>> The key phrase is in parentheses, which reminds the
    >>>>> user to expect a possible loss of precision. That
    >>>>> important parenthetical was removed from the
    >>>>> documentation in R 3.1.0 (among other changes).
    >>>> 
    >>>>> Putting aside the fact that this introduces a large
    >>>>> amount of unnecessary work rewriting SQL / data import
    >>>>> code, SQL packages, my biggest conceptual problem is
    >>>>> that I can no longer rely on a particular function
    >>>>> call returning a particular class. In my example
    >>>>> querying stock prices, about 5% of prices came back as
    >>>>> factors and the remaining 95% as numeric, so we had
    >>>>> random errors popping in throughout the morning.
    >>>> 
    >>>>> Here's a short example showing us how the new behavior
    >>>>> can be unreliable. I pass a character representation
    >>>>> of a uniformly distributed random variable to
    >>>>> type.convert. 90% of the time it is converted to
    >>>>> "numeric" and 10% it is a "factor" (in R 3.1.0). In
    >>>>> the 10% of cases in which type.convert converts to a
    >>>>> factor the leading non-zero digit is always a 9. So if
    >>>>> you were expecting a numeric value, then 1 in 10 times
    >>>>> you may have a bug in your code that didn't exist
    >>>>> before.
    >>>> 
>>>>> options(digits=16)
>>>>> cl <- NULL; for (i in 1:10000) cl[i] <-
    >>>>>> class(type.convert(format(runif(1))))
>>>>> table(cl)
    >>>>> cl factor numeric 990 9010
    >>>> 
    >>>> Yes.
    >>>> 
    >>>> Murray's point is valid, too.
    >>>> 
    >>>> But in my view, with the reasoning we have seen here,
    >>>> *and* with the well known software design principle of
    >>>> "least surprise" in mind, I also do think that the
    >>>> default for type.convert() should be what it has been
    >>>> for > 10 years now.
    >>>> 
    >>> 
    >>> I think there should be two separate discussions:
    >>> 
    >>> a) have an option (argument to type.convert and possibly
    >>> read.table) to enable/disable this behavior. I'm
    >>> strongly in favor of this.
    >>> 
    >>> b) decide what the default for a) will be. I have no
    >>> strong opinion, I can see arguments in both directions
    >>> 
    >>> But most importantly I think a) is better than the
    >>> status quo - even if the discussion about b) drags out.
    >>> 
    >>> Cheers, Simon
    >>> 
    >>> 
    >>>


From thomas.rusch at wu.ac.at  Tue Apr 22 17:52:47 2014
From: thomas.rusch at wu.ac.at (Thomas Rusch)
Date: Tue, 22 Apr 2014 17:52:47 +0200
Subject: [Rd] R 3.1.0: 'R CMD Sweave' deletes non tex files created upon
 batch mode exit
Message-ID: <5356904F.5070200@wu.ac.at>

Hi Martin,

I use R CMD Sweave often as well, so thanks for looking into this. I 
have now tested some of my scripts with R-devel revision 65449 
(2014-04-22) on 64-Bit Linux Mint 14.

I can confirm Marc's report that running R CMD Sweave no longer deletes 
graphic files and retains created non-tex files (eps and/or pdf).

What does not behave as before is the output printed to stdout, which 
before listed the number and name of each  code chunk it processed and 
also the options. It now outputs only any Sweave errors or messages from 
within R, and finishes with Output file: foo.tex

In case all works fine and no messages are printed, all that is written 
to stdout is Output file: foo.tex after R CMD Sweave processed the .Rnw.

In an R version prior to 3.1.0 output was e.g.,

Writing to file foo.tex
Processing code chunks with options ...
  1 : keep.source (label = setup, foo.Rnw:22)
  2 : keep.source term verbatim (label = packages, foo.Rnw:90)
  3 : keep.source term verbatim (label = data, foo:148)
...

It still outputs this information when running Sweave from within R if I 
say e.g.,

R> Sweave("foo.Rnw")

I'm not sure whether the new behavior of not printing information to 
stdout for R CMD Sweave is intended or not, but I thought I'll report it 
along with confirming R CMD Sweave no works again for me.

Best wishes
Thomas



 > sessionInfo()
R Under development (unstable) (2014-04-22 r65449)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> >>>>> Martin Maechler <[hidden email] 
> <http://r.789695.n4.nabble.com/user/SendEmail.jtp?type=node&node=4689102&i=0>> 
>
> >>>>>     on Thu, 17 Apr 2014 11:22:04 +0200 writes:
>
>  [................]
>
>     > PS: I'm currently testing a patch where 'R CMD Sweave' will
>     > revert to not deleting anything after running the R code by 
> default.
>
>     > Martin Maechler
>
> Some may have noted that R-devel, since svn revsion 65401 (= 
> 2014-04-17 12:19:44 +0200)
> now is patched, with log message
>
> > R CMD Sweave must not delete files by default; buildVignette(*, keep);
> >  update (and fix/clarify) documentation;
> > cosmetic (& speedup in buildVignettes())
>
> The daily (source!) snapshots of R devel now also contain it.
>
> We plan to port the patch to 'R 3.1.0 patched' (to become 3.1.1
> in the future) after the Easter holidays...
> and would be glad if some volunteers could support development
> of R by testing this (or newer) version of R-devel.
>
> Martin Maechler, ETH Zurich


From therneau at mayo.edu  Tue Apr 22 19:18:55 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 22 Apr 2014 12:18:55 -0500
Subject: [Rd] type.convert and doubles
In-Reply-To: <mailman.21.1398160807.8453.r-devel@r-project.org>
References: <mailman.21.1398160807.8453.r-devel@r-project.org>
Message-ID: <6e55ab$8m17fm@ironport10.mayo.edu>

"No global options"
I don't have an opinion about type.convert, but I must object to Martin's sweeping 
statement about global options, and stringsAsFactors in particular.  There have been only 
a few decisions in Splus/R that were so bad that our biostat group modified the core 
routines in order to return to sane behavior: automatic conversion of strings to factors 
was one of them --- not just when reading a data set but every bloody time you modified a 
data frame.  Addition of the global option was a blessing.

I work in a large biostatistics group whose mission is the advancement of medicine. 
Nothing frightens me more about the long term viability of R as a tool than sweeping 
announcements about "principles" which brush pragmatic considerations aside as irrelevant. 
  Some of us need to get work done.  (S4 zealots can be particularly annoying in this 
regard.)

How many of you remember the orignal S decision to have all modeling functions fail upon 
seeing a missing value?  The na.action argument was only available within lm() etc calls, 
with no global override, because "missing values are serious artifacts and should not be 
removed without thought".   Martin- should this be removed from the global options as well?

Terry T.




On 04/22/2014 05:00 AM, r-devel-request at r-project.org wrote:
>>>>>> >>>>>McGehee, Robert<Robert.McGehee at geodecapital.com>
>>>>>> >>>>>     on Mon, 21 Apr 2014 09:24:13 -0400 writes:
>      > Agreed. Perhaps even a global option would make sense. We
>      > already have an option with a similar spirit:
>      > 'options(?stringsAsFactors"=T/F)'. Perhaps
>      > 'options(?exactNumericAsString?=T/F)' [or something else]
>      > would be desirable, with the option being the default
>      > value to the type.convert argument.
>
> No, please, no, not a global option here!
>
> Global options that influence default behavior of basic
> functions is too much against the principle of functional
> programming, and my personal opinion has always been that
> 'stringsAsFactors' has been a mistake (as a global option, not
> as an argument).
>
> Note that with such global options, the output of sessionInfo()
> would in principle have to contain all (such) global options in
> addtion to R and package versions in order to diagnose behavior
> of R functions.
>
> I think we have more or less agreed that we'd like to have
> a new function*argument*  to type.convert();
> passed "upstream" to read.table() and via ... the other
> read.<foo>() that call read.table.
>
>
>      > I also like Gabor?s idea of a ?distinguishing class?. R
>      > doesn?t natively support arbitrary precision numbers
>      > (AFAIK), but I think that?s what Murray wants. I could
>      > imagine some kind of new class emerging here that
>      > initially looks just like a character/factor, but may
>      > evolve over time to accept arithmetic methods and act more
>      > like a number (e.g. knowing that ?0.1?, ?.10? and "1e-1"
>      > are the same number, or that ?-9?<?-0.2"). A class
>      > ?bignum? perhaps?
>
> That's another interesting idea. As maintainer of CRAN package
> 'Rmpfr' and co-maintainer of 'gmp', I'm even biased about this
> issue.
>
> Martin
>


From nalimilan at club.fr  Tue Apr 22 22:47:34 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Tue, 22 Apr 2014 22:47:34 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <6e55ab$8m17fm@ironport10.mayo.edu>
References: <mailman.21.1398160807.8453.r-devel@r-project.org>
	<6e55ab$8m17fm@ironport10.mayo.edu>
Message-ID: <1398199654.32176.12.camel@milan>

Le mardi 22 avril 2014 ? 12:18 -0500, Therneau, Terry M., Ph.D. a
?crit :
> "No global options"
> I don't have an opinion about type.convert, but I must object to Martin's sweeping 
> statement about global options, and stringsAsFactors in particular.  There have been only 
> a few decisions in Splus/R that were so bad that our biostat group modified the core 
> routines in order to return to sane behavior: automatic conversion of strings to factors 
> was one of them --- not just when reading a data set but every bloody time you modified a 
> data frame.  Addition of the global option was a blessing.
> 
> I work in a large biostatistics group whose mission is the advancement of medicine. 
> Nothing frightens me more about the long term viability of R as a tool than sweeping 
> announcements about "principles" which brush pragmatic considerations aside as irrelevant. 
>   Some of us need to get work done.  (S4 zealots can be particularly annoying in this 
> regard.)
> 
> How many of you remember the orignal S decision to have all modeling functions fail upon 
> seeing a missing value?  The na.action argument was only available within lm() etc calls, 
> with no global override, because "missing values are serious artifacts and should not be 
> removed without thought".   Martin- should this be removed from the global options as well?
Very interesting. Do you have any written references about this
behavior, and how it was eventually changed?

Thanks

> Terry T.
> 
> 
> 
> 
> On 04/22/2014 05:00 AM, r-devel-request at r-project.org wrote:
> >>>>>> >>>>>McGehee, Robert<Robert.McGehee at geodecapital.com>
> >>>>>> >>>>>     on Mon, 21 Apr 2014 09:24:13 -0400 writes:
> >      > Agreed. Perhaps even a global option would make sense. We
> >      > already have an option with a similar spirit:
> >      > 'options(?stringsAsFactors"=T/F)'. Perhaps
> >      > 'options(?exactNumericAsString?=T/F)' [or something else]
> >      > would be desirable, with the option being the default
> >      > value to the type.convert argument.
> >
> > No, please, no, not a global option here!
> >
> > Global options that influence default behavior of basic
> > functions is too much against the principle of functional
> > programming, and my personal opinion has always been that
> > 'stringsAsFactors' has been a mistake (as a global option, not
> > as an argument).
> >
> > Note that with such global options, the output of sessionInfo()
> > would in principle have to contain all (such) global options in
> > addtion to R and package versions in order to diagnose behavior
> > of R functions.
> >
> > I think we have more or less agreed that we'd like to have
> > a new function*argument*  to type.convert();
> > passed "upstream" to read.table() and via ... the other
> > read.<foo>() that call read.table.
> >
> >
> >      > I also like Gabor?s idea of a ?distinguishing class?. R
> >      > doesn?t natively support arbitrary precision numbers
> >      > (AFAIK), but I think that?s what Murray wants. I could
> >      > imagine some kind of new class emerging here that
> >      > initially looks just like a character/factor, but may
> >      > evolve over time to accept arithmetic methods and act more
> >      > like a number (e.g. knowing that ?0.1?, ?.10? and "1e-1"
> >      > are the same number, or that ?-9?<?-0.2"). A class
> >      > ?bignum? perhaps?
> >
> > That's another interesting idea. As maintainer of CRAN package
> > 'Rmpfr' and co-maintainer of 'gmp', I'm even biased about this
> > issue.
> >
> > Martin
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed Apr 23 08:43:25 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Apr 2014 08:43:25 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <6e55ab$8m17fn@ironport10.mayo.edu>
References: <mailman.21.1398160807.8453.r-devel@r-project.org>
	<6e55ab$8m17fn@ironport10.mayo.edu>
Message-ID: <21335.24845.872125.240937@stat.math.ethz.ch>

>>>>> Therneau, Terry M , Ph D <therneau at mayo.edu>
>>>>>     on Tue, 22 Apr 2014 12:18:55 -0500 writes:

    > "No global options"
    > I don't have an opinion about type.convert, but I must object to Martin's sweeping 
    > statement about global options, and stringsAsFactors in particular.  There have been only 
    > a few decisions in Splus/R that were so bad that our biostat group modified the core 
    > routines in order to return to sane behavior: automatic conversion of strings to factors 
    > was one of them --- not just when reading a data set but every bloody time you modified a 
    > data frame.  Addition of the global option was a blessing.

    > I work in a large biostatistics group whose mission is the advancement of medicine. 
    > Nothing frightens me more about the long term viability of R as a tool than sweeping 
    > announcements about "principles" which brush pragmatic considerations aside as irrelevant. 
    > Some of us need to get work done.  (S4 zealots can be particularly annoying in this 
    > regard.)

    > How many of you remember the orignal S decision to have all modeling functions fail upon 
    > seeing a missing value?  The na.action argument was only available within lm() etc calls, 
    > with no global override, because "missing values are serious artifacts and should not be 
    > removed without thought".   Martin- should this be removed from the global options as well?

Terry,  you are right that sweeping statements in general are
not something scientists should use often.

First note that I would not advocate abolishing existing global
options,  because at the same time I do advocate back
compatibility often more than colleagues.

But I do continue the argument that global options are something
tempting but never necessary.  Almost all agree that their
convenience, e.g. for output printing, e.g. number of digits, or
plotting -- adapting  to "current state" is something we just do
want for convenience.
But I'm still arguing that using an explicit 'stringsAsfactor'
*argument* -- or your own wrapper for  read.table() with 
different defaults, would be much cleaner.  There are not so
many cases where you'd have to pass such an argument, and - I
think also pass a 'na.action' argument to modelling functions, 
rather than getting these from a global option.

Said all that, yes, I'd try to fight hard introducing 
*more* global options that influence basic R functionality
apart from *output* configuration.

Martin







    > On 04/22/2014 05:00 AM, r-devel-request at r-project.org wrote:
    >>>>>>> >>>>>McGehee, Robert<Robert.McGehee at geodecapital.com>
    >>>>>>> >>>>>     on Mon, 21 Apr 2014 09:24:13 -0400 writes:
    >> > Agreed. Perhaps even a global option would make sense. We
    >> > already have an option with a similar spirit:
    >> > 'options(?stringsAsFactors"=T/F)'. Perhaps
    >> > 'options(?exactNumericAsString?=T/F)' [or something else]
    >> > would be desirable, with the option being the default
    >> > value to the type.convert argument.
    >> 
    >> No, please, no, not a global option here!
    >> 
    >> Global options that influence default behavior of basic
    >> functions is too much against the principle of functional
    >> programming, and my personal opinion has always been that
    >> 'stringsAsFactors' has been a mistake (as a global option, not
    >> as an argument).
    >> 
    >> Note that with such global options, the output of sessionInfo()
    >> would in principle have to contain all (such) global options in
    >> addtion to R and package versions in order to diagnose behavior
    >> of R functions.
    >> 
    >> I think we have more or less agreed that we'd like to have
    >> a new function*argument*  to type.convert();
    >> passed "upstream" to read.table() and via ... the other
    >> read.<foo>() that call read.table.
    >> 
    >> 
    >> > I also like Gabor?s idea of a ?distinguishing class?. R
    >> > doesn?t natively support arbitrary precision numbers
    >> > (AFAIK), but I think that?s what Murray wants. I could
    >> > imagine some kind of new class emerging here that
    >> > initially looks just like a character/factor, but may
    >> > evolve over time to accept arithmetic methods and act more
    >> > like a number (e.g. knowing that ?0.1?, ?.10? and "1e-1"
    >> > are the same number, or that ?-9?<?-0.2"). A class
    >> > ?bignum? perhaps?
    >> 
    >> That's another interesting idea. As maintainer of CRAN package
    >> 'Rmpfr' and co-maintainer of 'gmp', I'm even biased about this
    >> issue.
    >> 
    >> Martin
    >>


From therneau at mayo.edu  Wed Apr 23 15:32:02 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 23 Apr 2014 08:32:02 -0500
Subject: [Rd] type.convert and doubles
In-Reply-To: <21335.24845.872125.240937@stat.math.ethz.ch>
References: <mailman.21.1398160807.8453.r-devel@r-project.org>
	<6e55ab$8m17fn@ironport10.mayo.edu>
	<21335.24845.872125.240937@stat.math.ethz.ch>
Message-ID: <6e55ab$8m400t@ironport10.mayo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140423/8894f270/attachment.pl>

From tlumley at uw.edu  Wed Apr 23 23:09:18 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 24 Apr 2014 09:09:18 +1200
Subject: [Rd] Why did R 3.0's resolveNativeRoutine remove full-search
	ability?
In-Reply-To: <BFE389FD-2402-4E89-BCD0-918714D274C1@r-project.org>
References: <20140418135505.GA55039@piskorski.com>
	<BFE389FD-2402-4E89-BCD0-918714D274C1@r-project.org>
Message-ID: <CAJ55+dJVeF8zc-im9sJFvN37h-1PYVnV46N7V4QYUcHcOz0dCA@mail.gmail.com>

On Sat, Apr 19, 2014 at 2:29 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Andrew,
>
> On Apr 18, 2014, at 9:55 AM, Andrew Piskorski <atp at piskorski.com> wrote:
>
>> In versions of R prior to 3.0, by default .C and .Call would find the
>> requested C function regardless of which shared library it was located
>> in.  You could use the PACKAGE argument to restrict the search to a
>> specific library, but doing so was not necessary for it to work.
>>
>> R 3.0 introduced a significant change to that behavior; from the NEWS
>> file:
>>
>>  CHANGES IN R 3.0.0:
>>  PERFORMANCE IMPROVEMENTS:
>>    * A foreign function call (.C() etc) in a package without a PACKAGE
>>      argument will only look in the first DLL specified in the
>>      NAMESPACE file of the package rather than searching all loaded
>>      DLLs.  A few packages needed PACKAGE arguments added.
>>
>> That is not merely a performance improvement, it is a significant
>> change in functionality.  Now, when R code in my package foo tries to
>> call C code located in bar.so, it fails with a "not resolved from
>> current namespace (foo)" error.  It works if I change all my uses of
>> .C and .Call to pass a PACKAGE="bar" argument.  Ok, I can make that
>> change in my code, no big deal.
>>
>> What surprises me though, is that there appears to be no way to invoke
>> the old (and very conventional Unix-style), "I don't want to specify
>> where the function is located, just keep searching until you find it"
>> behavior.  Is there really no way to do that, and if so, why not?
>>
>> Comparing the R sources on the 3.1 vs. 2.15 branches, it looks as if
>> this is due to some simple changes to resolveNativeRoutine in
>> "src/main/dotcode.c".  Specifically, the newer code adds this:
>>
>>   errorcall(call, "\"%s\" not resolved from current namespace (%s)",
>>             buf, ns);
>>
>> And removes these lines:
>>
>>   /* need to continue if the namespace search failed */
>>   *fun = R_FindSymbol(buf, dll.DLLname, symbol);
>>   if (*fun) return args;
>>
>> Is that extra call to R_FindSymbol really all that's necessary to
>> invoke the old "keep searching" behavior?  Would it be a good idea to
>> provide an optional way of finding a native routine regardless of
>> where it's located, perhaps via an optional PACKAGE=NA argument to .C,
>> .Call, etc.?
>>
>> And now I see that help(".Call") says:
>>
>>   'PACKAGE = ""' used to be accepted (but was undocumented): it is
>>    now an error.
>>
>> I assume passing PACKAGE="" used to invoke the same "keep searching"
>> behavior as not passing any PACKAGE argument at all.  So apparently
>> the removal of functionality was intentional.  I'd like to better
>> understand why.  Why should that be an error?  Or said another way,
>> why has traditional Unix-style symbol resolution been banned from use
>> with .C and .Call ?
>>
>
> I cannot speak for the author, but a very strong argument is to prevent (symbol) namespace issues. If you cannot even say where the symbol comes from, you have absolutely no way of knowing that the symbol you get has anything to do with the symbol you intended to get, because you could get any random symbol in any shared object that may or may not have anything to do with your code. Note that even you as the author of the code have no control over the namespace so although you intended this to work, loading some other package can break your code - and in a fatal manner since this will typically lead to a segfault. Do you have any strong use case for allowing this given how dangerous it is? Ever since symbol registration has been made easy, it's much more efficient and safe to use symbols directly instead.
>


As a follow-up to this, note that with traditional Unix symbol
resolution it was forbidden to have two different routines with the
same name linked into an object. That just isn't an option for R
because of the package system.  This isn't theoretical: the PACKAGE=
argument was introduced when finding the wrong symbol resolution
became a real problem late last century
(http://marc.info/?l=r-devel&m=107151103308418&w=2), but there wasn't
a good cross-package calling mechanism for quite a while. Now there is
a cross-package mechanism that works, where the Unix-style approach
cannot be made to work safely with packages from multiple authors.

   -thomas


-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From fongchunchan at gmail.com  Thu Apr 24 01:00:33 2014
From: fongchunchan at gmail.com (Fong Chun Chan)
Date: Wed, 23 Apr 2014 16:00:33 -0700
Subject: [Rd] Error when Installing R-3.1.0
Message-ID: <CAB-BZ9LvtLJZ8eV8+bybukpGsreGR9dE7WA_H21XvqKsF+ZGUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140423/98a377c5/attachment.pl>

From xie at yihui.name  Thu Apr 24 19:11:53 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 24 Apr 2014 12:11:53 -0500
Subject: [Rd] The regular expressions in compareVersion()
Message-ID: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>

Hi,

I guess the backslash should not be used as the separator for
strsplit() in compareVersion(), because the period in [.] is no longer
a metacharacter (no need to "escape" it using a backslash):
https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867

> compareVersion
function (a, b)
{
....
    a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
    b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
....
<environment: namespace:utils>

A similar regular expression problem also exists in the Sweave syntax
(for \Sexpr{}), and I have reported it once. It was fixed but the fix
was immediately reverted for some reason:
https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


From atp at piskorski.com  Thu Apr 24 22:13:09 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Thu, 24 Apr 2014 16:13:09 -0400
Subject: [Rd] palette() can hang and fail due to X11
Message-ID: <20140424201308.GA22592@piskorski.com>

For many years, when my R process starts up I've been automatically
setting my preferred default plot colors, basically like so:

  my.colors <-
     c("black" ,"red" ,"gold" ,"sky blue" ,"green" ,"blue" ,"orange"
       ,"grey" ,"hot pink" ,"brown" ,"sea green" ,"cyan" ,"purple" ,"tomato1")
  require("grDevices")
  palette(my.colors)

That seemed to work reliably in all 2.x versions of R, regardless of
whether my R was interactive or not, or if my Linux, ssh, and screen
environment had X-Windows properly set up or not.  It Just Worked.

However, now in R 3.1.0 Patched (2014-04-15 r65398, on Linux),
depending on whether I have a good X-Windows connection or not it can
fail like so:

  Error in .External2(C_X11, d$display, d$width, d$height, d$pointsize,  :  
    unable to start device X11 

Simply wrapping the palette() call in try() of course helps keep that
error from breaking the rest of my R start up.  However, occasionally
the call to palette() will hang for perhaps a minute, unexpectedly
locking up my R process until it finishes whatever it was doing.

But, all I want to do here is set my default colors to the length 14
vector above, which seems like something that SHOULD be simple...  Is
there some way for me to reliably do that WITHOUT invoking all this
extra X11 device machinery?

The relevant C code appears to be "palette" in
"src/library/grDevices/src/colors.c" and "do_dotcallgr" for
.Call.graphics in "src/main/dotcode.c", but I don't understand what
part is triggering the additional complex behavior, nor how I should
avoid it.

Any advice on how I should handle this robustly?  (Thanks!)

-- 
Andrew Piskorski <atp at piskorski.com>


From murdoch.duncan at gmail.com  Thu Apr 24 22:42:06 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 16:42:06 -0400
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
Message-ID: <5359771E.8040507@gmail.com>

On 24/04/2014, 1:11 PM, Yihui Xie wrote:
> Hi,
>
> I guess the backslash should not be used as the separator for
> strsplit() in compareVersion(), because the period in [.] is no longer
> a metacharacter (no need to "escape" it using a backslash):
> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>
>> compareVersion
> function (a, b)
> {
> ....
>      a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>      b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
> ....
> <environment: namespace:utils>

Could you post an example where this causes trouble, or are you just 
suggesting this as a way to make the source a little cleaner?

>
> A similar regular expression problem also exists in the Sweave syntax
> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
> was immediately reverted for some reason:
> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0

A link to your report would be more useful, if it included an example 
where the bad regexp causes trouble.

Duncan Murdoch


From hb at biostat.ucsf.edu  Thu Apr 24 23:26:53 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 24 Apr 2014 14:26:53 -0700
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <5359771E.8040507@gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
Message-ID: <CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>

On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>
>> Hi,
>>
>> I guess the backslash should not be used as the separator for
>> strsplit() in compareVersion(), because the period in [.] is no longer
>> a metacharacter (no need to "escape" it using a backslash):
>>
>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>
>>> compareVersion
>>
>> function (a, b)
>> {
>> ....
>>      a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>      b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>> ....
>> <environment: namespace:utils>
>
>
> Could you post an example where this causes trouble, or are you just
> suggesting this as a way to make the source a little cleaner?

Maybe it's already clear, but [\\.] is the set for the two symbols '\'
and '.', not '.' alone.  For example, I would expect an error below:

> compareVersion("3.14-59.26", "3.14-59\\26")
[1] 0

/Henrik

>
>
>>
>> A similar regular expression problem also exists in the Sweave syntax
>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>> was immediately reverted for some reason:
>>
>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>
>
> A link to your report would be more useful, if it included an example where
> the bad regexp causes trouble.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Apr 25 01:20:02 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Apr 2014 19:20:02 -0400
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
Message-ID: <53599C22.8040202@gmail.com>

On 24/04/2014, 5:26 PM, Henrik Bengtsson wrote:
> On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>>
>>> Hi,
>>>
>>> I guess the backslash should not be used as the separator for
>>> strsplit() in compareVersion(), because the period in [.] is no longer
>>> a metacharacter (no need to "escape" it using a backslash):
>>>
>>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>>
>>>> compareVersion
>>>
>>> function (a, b)
>>> {
>>> ....
>>>       a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>>       b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>>> ....
>>> <environment: namespace:utils>
>>
>>
>> Could you post an example where this causes trouble, or are you just
>> suggesting this as a way to make the source a little cleaner?
>
> Maybe it's already clear, but [\\.] is the set for the two symbols '\'
> and '.', not '.' alone.  For example, I would expect an error below:
>
>> compareVersion("3.14-59.26", "3.14-59\\26")
> [1] 0
>

How does that cause problems?

Duncan Murdoch

> /Henrik
>
>>
>>
>>>
>>> A similar regular expression problem also exists in the Sweave syntax
>>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>>> was immediately reverted for some reason:
>>>
>>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>>
>>
>> A link to your report would be more useful, if it included an example where
>> the bad regexp causes trouble.
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From atp at piskorski.com  Fri Apr 25 01:54:29 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Thu, 24 Apr 2014 19:54:29 -0400
Subject: [Rd] palette() can hang and fail due to X11
In-Reply-To: <20140424201308.GA22592@piskorski.com>
References: <20140424201308.GA22592@piskorski.com>
Message-ID: <20140424235429.GA58193@piskorski.com>

The fundamental problem here seems to be a change (probably a bug) in
the behavior of palette().  In R 3.1.0, calling palette() opens a new
X window (on Linux)!  That seems like a bug, as I can't think of any
good reason for it to open a window, and it never did in any of the
2.x versions of R I've ever used.

I am using:

  R 3.1.0 (Patched), 2014-04-15, svn.rev 65398, x86_64-unknown-linux-gnu  
  Ubuntu 12.04.3 LTS

Is there something else I should check to help track down the bug?

-- 
Andrew Piskorski <atp at piskorski.com>


From simon.urbanek at r-project.org  Fri Apr 25 03:22:40 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Apr 2014 21:22:40 -0400
Subject: [Rd] palette() can hang and fail due to X11
In-Reply-To: <20140424201308.GA22592@piskorski.com>
References: <20140424201308.GA22592@piskorski.com>
Message-ID: <9D39ED59-7E29-4C11-B99D-2A0FDD85B8D5@r-project.org>

Andrew,

palette is a property recorded in the graphics device* and therefore R will create a new device (see dev.new()) if only the null device is open. Which device is really up to your settings, so you could adjust your preferred device depending on what you want it to be.

The bottom line is that you probably don't want to set the palette if you don't have a device that could be used. The delay you see is probably due to your local settings that seem to choose X11 as the default device which may or may not work depending on the different way you start R and/or the availability of the server you DISPLAY is pointing to.

* - this has changed in R 3.0.0, quote:

 Palette changes get recorded on the display list, so
 replaying plots (including when resizing screen devices and using
 dev.copy()) will work better when the palette is changed
 during a plot.

Cheers,
Simon


On Apr 24, 2014, at 4:13 PM, Andrew Piskorski <atp at piskorski.com> wrote:

> For many years, when my R process starts up I've been automatically
> setting my preferred default plot colors, basically like so:
> 
>  my.colors <-
>     c("black" ,"red" ,"gold" ,"sky blue" ,"green" ,"blue" ,"orange"
>       ,"grey" ,"hot pink" ,"brown" ,"sea green" ,"cyan" ,"purple" ,"tomato1")
>  require("grDevices")
>  palette(my.colors)
> 
> That seemed to work reliably in all 2.x versions of R, regardless of
> whether my R was interactive or not, or if my Linux, ssh, and screen
> environment had X-Windows properly set up or not.  It Just Worked.
> 
> However, now in R 3.1.0 Patched (2014-04-15 r65398, on Linux),
> depending on whether I have a good X-Windows connection or not it can
> fail like so:
> 
>  Error in .External2(C_X11, d$display, d$width, d$height, d$pointsize,  :  
>    unable to start device X11 
> 
> Simply wrapping the palette() call in try() of course helps keep that
> error from breaking the rest of my R start up.  However, occasionally
> the call to palette() will hang for perhaps a minute, unexpectedly
> locking up my R process until it finishes whatever it was doing.
> 
> But, all I want to do here is set my default colors to the length 14
> vector above, which seems like something that SHOULD be simple...  Is
> there some way for me to reliably do that WITHOUT invoking all this
> extra X11 device machinery?
> 
> The relevant C code appears to be "palette" in
> "src/library/grDevices/src/colors.c" and "do_dotcallgr" for
> .Call.graphics in "src/main/dotcode.c", but I don't understand what
> part is triggering the additional complex behavior, nor how I should
> avoid it.
> 
> Any advice on how I should handle this robustly?  (Thanks!)
> 
> -- 
> Andrew Piskorski <atp at piskorski.com>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From xie at yihui.name  Fri Apr 25 04:15:25 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 24 Apr 2014 21:15:25 -0500
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <53599C22.8040202@gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
Message-ID: <CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>

You are right that this is unlikely to cause problems, because users
are unlikely to put backslashes in version numbers. Henrik has pointed
out the problem. It is not about "making the source code a little
cleaner", but "making it correct". Either someone in R core corrects
the wrong regular expressions in a few seconds (unless you think \ can
be a legal character in a version number), or I just give up the
report. It seems the latter is easier. It is not worth additional
Q&A's back and forth.

Regarding the regular expression problem for \Sexpr{} in Sweave,
please see here for a record:
http://r.789695.n4.nabble.com/Sweave-printing-an-underscore-in-the-output-from-an-R-command-td4675177.html
As I said, it is a similar problem: someone tried to escape a
character that did not need to be escaped in [].

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Apr 24, 2014 at 6:20 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/04/2014, 5:26 PM, Henrik Bengtsson wrote:
>>
>> On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>
>>> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>>>
>>>>
>>>> Hi,
>>>>
>>>> I guess the backslash should not be used as the separator for
>>>> strsplit() in compareVersion(), because the period in [.] is no longer
>>>> a metacharacter (no need to "escape" it using a backslash):
>>>>
>>>>
>>>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>>>
>>>>> compareVersion
>>>>
>>>>
>>>> function (a, b)
>>>> {
>>>> ....
>>>>       a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>>>       b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>>>> ....
>>>> <environment: namespace:utils>
>>>
>>>
>>>
>>> Could you post an example where this causes trouble, or are you just
>>> suggesting this as a way to make the source a little cleaner?
>>
>>
>> Maybe it's already clear, but [\\.] is the set for the two symbols '\'
>> and '.', not '.' alone.  For example, I would expect an error below:
>>
>>> compareVersion("3.14-59.26", "3.14-59\\26")
>>
>> [1] 0
>>
>
> How does that cause problems?
>
> Duncan Murdoch
>
>
>> /Henrik
>>
>>>
>>>
>>>>
>>>> A similar regular expression problem also exists in the Sweave syntax
>>>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>>>> was immediately reverted for some reason:
>>>>
>>>>
>>>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>>>
>>>
>>>
>>> A link to your report would be more useful, if it included an example
>>> where
>>> the bad regexp causes trouble.
>>>
>>> Duncan Murdoch


From simon.urbanek at r-project.org  Fri Apr 25 04:27:27 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Apr 2014 22:27:27 -0400
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
	<CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
Message-ID: <CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>

FWIW the link has a long thread that is 90% irrelevant - AFAICS the relevant part is

From: Yihui Xie-2
Sep 02, 2013; 4:11pm
Re: Sweave: printing an underscore in the output from an R command
[...]
Now you are good at the regular expression level, but Sweave comes and 
bites you, and that is due to this bug in the regular expression in 
Sweave Noweb syntax: 

> SweaveSyntaxNoweb$docexpr 
[1] "\\\\Sexpr\\{([^\\}]*)\\}" 

It should have been "\\\\Sexpr\\{([^}]*)\\}", i.e. } does not need to 
be escaped inside [], and \\ will be interpreted literally inside []. 
In your case, Sweave sees \ in \Sexpr{}, and the regular expression 
stops matching there, and is unable to see } after \, so it believes 
there is no inline R expressions in your document. 


On Apr 24, 2014, at 10:15 PM, Yihui Xie <xie at yihui.name> wrote:

> You are right that this is unlikely to cause problems, because users
> are unlikely to put backslashes in version numbers. Henrik has pointed
> out the problem. It is not about "making the source code a little
> cleaner", but "making it correct". Either someone in R core corrects
> the wrong regular expressions in a few seconds (unless you think \ can
> be a legal character in a version number), or I just give up the
> report. It seems the latter is easier. It is not worth additional
> Q&A's back and forth.
> 
> Regarding the regular expression problem for \Sexpr{} in Sweave,
> please see here for a record:
> http://r.789695.n4.nabble.com/Sweave-printing-an-underscore-in-the-output-from-an-R-command-td4675177.html
> As I said, it is a similar problem: someone tried to escape a
> character that did not need to be escaped in [].
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> 
> 
> On Thu, Apr 24, 2014 at 6:20 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 24/04/2014, 5:26 PM, Henrik Bengtsson wrote:
>>> 
>>> On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> 
>>>> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>>>> 
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> I guess the backslash should not be used as the separator for
>>>>> strsplit() in compareVersion(), because the period in [.] is no longer
>>>>> a metacharacter (no need to "escape" it using a backslash):
>>>>> 
>>>>> 
>>>>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>>>> 
>>>>>> compareVersion
>>>>> 
>>>>> 
>>>>> function (a, b)
>>>>> {
>>>>> ....
>>>>>      a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>>>>      b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>>>>> ....
>>>>> <environment: namespace:utils>
>>>> 
>>>> 
>>>> 
>>>> Could you post an example where this causes trouble, or are you just
>>>> suggesting this as a way to make the source a little cleaner?
>>> 
>>> 
>>> Maybe it's already clear, but [\\.] is the set for the two symbols '\'
>>> and '.', not '.' alone.  For example, I would expect an error below:
>>> 
>>>> compareVersion("3.14-59.26", "3.14-59\\26")
>>> 
>>> [1] 0
>>> 
>> 
>> How does that cause problems?
>> 
>> Duncan Murdoch
>> 
>> 
>>> /Henrik
>>> 
>>>> 
>>>> 
>>>>> 
>>>>> A similar regular expression problem also exists in the Sweave syntax
>>>>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>>>>> was immediately reverted for some reason:
>>>>> 
>>>>> 
>>>>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>>>> 
>>>> 
>>>> 
>>>> A link to your report would be more useful, if it included an example
>>>> where
>>>> the bad regexp causes trouble.
>>>> 
>>>> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Fri Apr 25 14:04:34 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Apr 2014 08:04:34 -0400
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
	<CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
	<CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>
Message-ID: <535A4F52.4020300@gmail.com>

On 24/04/2014, 10:27 PM, Simon Urbanek wrote:
> FWIW the link has a long thread that is 90% irrelevant - AFAICS the relevant part is
>
> From: Yihui Xie-2
> Sep 02, 2013; 4:11pm
> Re: Sweave: printing an underscore in the output from an R command
> [...]
> Now you are good at the regular expression level, but Sweave comes and
> bites you, and that is due to this bug in the regular expression in
> Sweave Noweb syntax:
>
>> SweaveSyntaxNoweb$docexpr
> [1] "\\\\Sexpr\\{([^\\}]*)\\}"
>
> It should have been "\\\\Sexpr\\{([^}]*)\\}", i.e. } does not need to
> be escaped inside [], and \\ will be interpreted literally inside [].
> In your case, Sweave sees \ in \Sexpr{}, and the regular expression
> stops matching there, and is unable to see } after \, so it believes
> there is no inline R expressions in your document.
>

Thanks.  I've put in a bug report on this one now, so it shouldn't get 
missed again.  If nobody else gets to it first I'll deal with it.

I don't see any value in fixing the compareVersion example, but if 
someone submits a bug report about it, someone else might fix it.

Duncan Murdoch

>
> On Apr 24, 2014, at 10:15 PM, Yihui Xie <xie at yihui.name> wrote:
>
>> You are right that this is unlikely to cause problems, because users
>> are unlikely to put backslashes in version numbers. Henrik has pointed
>> out the problem. It is not about "making the source code a little
>> cleaner", but "making it correct". Either someone in R core corrects
>> the wrong regular expressions in a few seconds (unless you think \ can
>> be a legal character in a version number), or I just give up the
>> report. It seems the latter is easier. It is not worth additional
>> Q&A's back and forth.
>>
>> Regarding the regular expression problem for \Sexpr{} in Sweave,
>> please see here for a record:
>> http://r.789695.n4.nabble.com/Sweave-printing-an-underscore-in-the-output-from-an-R-command-td4675177.html
>> As I said, it is a similar problem: someone tried to escape a
>> character that did not need to be escaped in [].
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>>
>>
>> On Thu, Apr 24, 2014 at 6:20 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 24/04/2014, 5:26 PM, Henrik Bengtsson wrote:
>>>>
>>>> On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> wrote:
>>>>>
>>>>> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>>>>>
>>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I guess the backslash should not be used as the separator for
>>>>>> strsplit() in compareVersion(), because the period in [.] is no longer
>>>>>> a metacharacter (no need to "escape" it using a backslash):
>>>>>>
>>>>>>
>>>>>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>>>>>
>>>>>>> compareVersion
>>>>>>
>>>>>>
>>>>>> function (a, b)
>>>>>> {
>>>>>> ....
>>>>>>       a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>>>>>       b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>>>>>> ....
>>>>>> <environment: namespace:utils>
>>>>>
>>>>>
>>>>>
>>>>> Could you post an example where this causes trouble, or are you just
>>>>> suggesting this as a way to make the source a little cleaner?
>>>>
>>>>
>>>> Maybe it's already clear, but [\\.] is the set for the two symbols '\'
>>>> and '.', not '.' alone.  For example, I would expect an error below:
>>>>
>>>>> compareVersion("3.14-59.26", "3.14-59\\26")
>>>>
>>>> [1] 0
>>>>
>>>
>>> How does that cause problems?
>>>
>>> Duncan Murdoch
>>>
>>>
>>>> /Henrik
>>>>
>>>>>
>>>>>
>>>>>>
>>>>>> A similar regular expression problem also exists in the Sweave syntax
>>>>>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>>>>>> was immediately reverted for some reason:
>>>>>>
>>>>>>
>>>>>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>>>>>
>>>>>
>>>>>
>>>>> A link to your report would be more useful, if it included an example
>>>>> where
>>>>> the bad regexp causes trouble.
>>>>>
>>>>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From pdalgd at gmail.com  Fri Apr 25 14:50:53 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 25 Apr 2014 14:50:53 +0200
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <535A4F52.4020300@gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
	<CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
	<CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>
	<535A4F52.4020300@gmail.com>
Message-ID: <177237DA-1B70-4340-AB22-C550F2495851@gmail.com>


On 25 Apr 2014, at 14:04 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 24/04/2014, 10:27 PM, Simon Urbanek wrote:
>> FWIW the link has a long thread that is 90% irrelevant - AFAICS the relevant part is
>> 
>> From: Yihui Xie-2
>> Sep 02, 2013; 4:11pm
>> Re: Sweave: printing an underscore in the output from an R command
>> [...]
>> Now you are good at the regular expression level, but Sweave comes and
>> bites you, and that is due to this bug in the regular expression in
>> Sweave Noweb syntax:
>> 
>>> SweaveSyntaxNoweb$docexpr
>> [1] "\\\\Sexpr\\{([^\\}]*)\\}"
>> 
>> It should have been "\\\\Sexpr\\{([^}]*)\\}", i.e. } does not need to
>> be escaped inside [], and \\ will be interpreted literally inside [].
>> In your case, Sweave sees \ in \Sexpr{}, and the regular expression
>> stops matching there, and is unable to see } after \, so it believes
>> there is no inline R expressions in your document.
>> 
> 
> Thanks.  I've put in a bug report on this one now, so it shouldn't get missed again.  If nobody else gets to it first I'll deal with it.
> 
> I don't see any value in fixing the compareVersion example, but if someone submits a bug report about it, someone else might fix it.

No point in clinging to obviously incorrect code either. Fixed in R-devel.

Peter

> 
> Duncan Murdoch
> 
>> 
>> On Apr 24, 2014, at 10:15 PM, Yihui Xie <xie at yihui.name> wrote:
>> 
>>> You are right that this is unlikely to cause problems, because users
>>> are unlikely to put backslashes in version numbers. Henrik has pointed
>>> out the problem. It is not about "making the source code a little
>>> cleaner", but "making it correct". Either someone in R core corrects
>>> the wrong regular expressions in a few seconds (unless you think \ can
>>> be a legal character in a version number), or I just give up the
>>> report. It seems the latter is easier. It is not worth additional
>>> Q&A's back and forth.
>>> 
>>> Regarding the regular expression problem for \Sexpr{} in Sweave,
>>> please see here for a record:
>>> http://r.789695.n4.nabble.com/Sweave-printing-an-underscore-in-the-output-from-an-R-command-td4675177.html
>>> As I said, it is a similar problem: someone tried to escape a
>>> character that did not need to be escaped in [].
>>> 
>>> Regards,
>>> Yihui
>>> --
>>> Yihui Xie <xieyihui at gmail.com>
>>> Web: http://yihui.name
>>> 
>>> 
>>> On Thu, Apr 24, 2014 at 6:20 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 24/04/2014, 5:26 PM, Henrik Bengtsson wrote:
>>>>> 
>>>>> On Thu, Apr 24, 2014 at 1:42 PM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com> wrote:
>>>>>> 
>>>>>> On 24/04/2014, 1:11 PM, Yihui Xie wrote:
>>>>>>> 
>>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I guess the backslash should not be used as the separator for
>>>>>>> strsplit() in compareVersion(), because the period in [.] is no longer
>>>>>>> a metacharacter (no need to "escape" it using a backslash):
>>>>>>> 
>>>>>>> 
>>>>>>> https://github.com/wch/r-source/blob/trunk/src/library/utils/R/packages.R#L866-L867
>>>>>>> 
>>>>>>>> compareVersion
>>>>>>> 
>>>>>>> 
>>>>>>> function (a, b)
>>>>>>> {
>>>>>>> ....
>>>>>>>      a <- as.integer(strsplit(a, "[\\.-]")[[1L]])
>>>>>>>      b <- as.integer(strsplit(b, "[\\.-]")[[1L]])
>>>>>>> ....
>>>>>>> <environment: namespace:utils>
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Could you post an example where this causes trouble, or are you just
>>>>>> suggesting this as a way to make the source a little cleaner?
>>>>> 
>>>>> 
>>>>> Maybe it's already clear, but [\\.] is the set for the two symbols '\'
>>>>> and '.', not '.' alone.  For example, I would expect an error below:
>>>>> 
>>>>>> compareVersion("3.14-59.26", "3.14-59\\26")
>>>>> 
>>>>> [1] 0
>>>>> 
>>>> 
>>>> How does that cause problems?
>>>> 
>>>> Duncan Murdoch
>>>> 
>>>> 
>>>>> /Henrik
>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> 
>>>>>>> A similar regular expression problem also exists in the Sweave syntax
>>>>>>> (for \Sexpr{}), and I have reported it once. It was fixed but the fix
>>>>>>> was immediately reverted for some reason:
>>>>>>> 
>>>>>>> 
>>>>>>> https://github.com/wch/r-source/commit/52b0a46e15136a7f9e4777e9960fdda6d84880c0
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> A link to your report would be more useful, if it included an example
>>>>>> where
>>>>>> the bad regexp causes trouble.
>>>>>> 
>>>>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hb at biostat.ucsf.edu  Fri Apr 25 20:49:23 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 25 Apr 2014 11:49:23 -0700
Subject: [Rd] Preventing $R_HOME/site-library/ via R_LIBS_SITE=":" (no other
	way?)
Message-ID: <CAFDcVCSxCTE4xtFywAUGSvaBMDEvUwqErzL=CNFg6H-UhnJ9aQ@mail.gmail.com>

(As a non-root/non-admin), I've just tried to figure out how to
prevent a default $R_HOME/site-library/ to be added to the library
path.  The solution I found was to environment variable R_LIBS_SITE to
":" (preferably in ~/.Renviron).  Note that setting R_LIBS_SITE to en
empty string will cause it to fall back to using
$R_HOME/site-library/.  This "hack" is based on the following in
help(".Library.site"):

.Library.site is a (possibly empty) character vector giving the
locations of the site libraries, by default the ?site-library?
subdirectory of R_HOME (which may not exist).
[...]
.Library.site can be set via the environment variable R_LIBS_SITE (as
a non-empty colon-separated list of library trees).

It turns out that any dummy string would work (e.g.
R_LIBS_SITE=non-existing-directory), but using the OS's path separator
is at least according to the docs.



TROUBLESHOOTING/PATCHING:
I don't see an obvious elegant fix to this in R, but I believe the
issue is that the system/global Rprofile
(src\library\profile\Common.R) does:

 Sys.setenv(R_LIBS_SITE =
            .expand_R_libs_env_var(Sys.getenv("R_LIBS_SITE")))

Here this information on whether R_LIBS_SITE is unset or empty is
lost.  Sys.getenv("R_LIBS_SITE", NA_character_) would distinguish the
two cases.  However, NA_character_ is coerced to "NA" in
Sys.setenv(R_LIBS_SITE = ...), which means a site library cannot be
"NA". I assume my above "hack" could be done as:

local({
 libs <- Sys.getenv("R_LIBS_SITE", NA_character_)
 libs <- if (is.na(libs)) "" else if (libs == "") .Platform$path.sep else libs
 Sys.setenv(R_LIBS_SITE = .expand_R_libs_env_var(libs))
})

Not elegant, but it should work.  If not added, may I propose the
following patch to the docs:

>svn diff src\library\base\man\libPaths.Rd
Index: src/library/base/man/libPaths.Rd
===================================================================
--- src/library/base/man/libPaths.Rd    (revision 65492)
+++ src/library/base/man/libPaths.Rd    (working copy)
@@ -63,6 +63,8 @@

   \code{.Library.site} can be set via the environment variable
   \env{R_LIBS_SITE} (as a non-empty colon-separated list of library trees).
+  To prevent the default \file{site-library} subdirectory of
+  \env{R_HOME} to be used, one can set \env{R_LIBS_SITE} to \code{":"}.
 #endif
 #ifdef windows
   The library search path is initialized at startup from the environment
@@ -77,6 +79,8 @@

   \code{.Library.site} can be set via the environment variable
   \env{R_LIBS_SITE} (as a non-empty semicolon-separated list of library trees).

+  To prevent the default \file{site-library} subdirectory of
+  \env{R_HOME} to be used, one can set \env{R_LIBS_SITE} to \code{";"}.
 #endif

   Both \env{R_LIBS_USER} and \env{R_LIBS_SITE} feature possible


My $.02 - may save someone else 30 mins.


From atp at piskorski.com  Fri Apr 25 20:55:22 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Fri, 25 Apr 2014 14:55:22 -0400
Subject: [Rd] palette() can hang and fail due to X11
In-Reply-To: <9D39ED59-7E29-4C11-B99D-2A0FDD85B8D5@r-project.org>
References: <20140424201308.GA22592@piskorski.com>
	<9D39ED59-7E29-4C11-B99D-2A0FDD85B8D5@r-project.org>
Message-ID: <20140425185522.GA89495@piskorski.com>

On Thu, Apr 24, 2014 at 09:22:40PM -0400, Simon Urbanek wrote:

> The bottom line is that you probably don't want to set the palette
> if you don't have a device that could be used.

Ok.  In my testing so far, it seems all I need is a simple little
function that does:

  pdf(); nn <- dev.cur(); rr <- palette(my.colors); dev.off(nn); rr 

I could have it check dev.list() and skip creating the sacrificial pdf
device if there already is a real graphics device up and running, but
in my testing so far that doesn't seem to be necessary, creating the
new pdf device gives the right behavior no matter what.

So if anybody else runs into this, that seems to be the practical
solution, it's pretty easy.  Pedantically though, ideally this hack
wouldn't be necessary.  You said:

> palette is a property recorded in the graphics device*

Perhaps its implementation currently is, I don't know.  (But what
about the special "null" graphics device that is always open,
shouldn't that be a good place to record the session-wide palette?)
But logically, the color palette is not and cannot be solely a
property of a graphics device.  Note that help("palette") says:

   There is only one palette setting for all devices in a R session. 
   If the palette is changed, the new palette applies to all 
   subsequent plotting. 

So the current color choices are logically a property of the R
session, independent of any specific graphics devices.

Clearly, palette() was always intended to do two things.  One, it
changes the user's session-wide default colors.  Two, it tells the
currently open graphics device (if any), to use those new colors.

A new (and no doubt useful) feature in R 3.0 is that each graphics
device remembers its history of palette changes.  Apparently as a side
effect of that change, palette() now INSISTS that a real non-null
graphics device be open, and opens one if there isn't.  This is a new
third thing palette() does that it never did before.

Glomming together all three of these essentially independent jobs into
the single palette() command seems a bit unfortunate.  Is there was
some way for me to do ONLY the first of palette()'s jobs, set my
session-wide default colors and that's it?  It looks like there is no
such entry point in the code, but the little hack with the sacrificial
pdf device above is a way to approximate one.

-- 
Andrew Piskorski <atp at piskorski.com>


From hb at biostat.ucsf.edu  Fri Apr 25 23:16:02 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 25 Apr 2014 14:16:02 -0700
Subject: [Rd] Odd behavior on Windows: Rgui responds to user interrupts
 (Ctrl-C) at the Windows command prompt (iff launched from one)
Message-ID: <CAFDcVCQUXziJSWPbEY=ukK4Zb3Emi8eu5bvFKyg=Dm0Yf-VJRQ@mail.gmail.com>

On Windows,

1. Open the Windows Command interpreter (cmd.exe).

2. Launch rgui.exe --vanilla.

2. In RGui, (disable Misc -> Buffered output) and run the following
endless loop:

> i <- 0; repeat { print(i <- i + 1); Sys.sleep(0.1) }
[1] 1
[1] 2
[1] 3
...

3a. Back at the Windows command line, press Ctrl-C (user interrupt).
This will interrupt Rgui!

3b. Alternatively, start Rterm.exe and press Ctrl-C. It will also
interrupt Rgui.

Additional observations:
* The user interrupt in the Windows command interpreter, interrupts
*all* running Rgui:s.
* A user interrupt in *any* Windows command interpreter, will interrupt Rgui.
* This only occurs if Rgui is started via the Windows command line
(cmd.exe).  It does not occur if launched directly.

Can anyone else reproduce this?  Is this an R or an OS feature?

/Henrik

Session info:

C:\tmp>path
PATH="C:\Program Files\R\R-3.1.0\bin\i386"

C:\tmp>R --quiet --vanilla -e "sessionInfo()"
> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From pdalgd at gmail.com  Sat Apr 26 09:36:47 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 26 Apr 2014 09:36:47 +0200
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <177237DA-1B70-4340-AB22-C550F2495851@gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
	<CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
	<CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>
	<535A4F52.4020300@gmail.com>
	<177237DA-1B70-4340-AB22-C550F2495851@gmail.com>
Message-ID: <B4D7D0B5-D1C8-4244-BF0E-E40B132DB4D7@gmail.com>


On 25 Apr 2014, at 14:50 , peter dalgaard <pdalgd at gmail.com> wrote:

>> Thanks.  I've put in a bug report on this one now, so it shouldn't get missed again.  If nobody else gets to it first I'll deal with it.
>> 
>> I don't see any value in fixing the compareVersion example, but if someone submits a bug report about it, someone else might fix it.
> 
> No point in clinging to obviously incorrect code either. Fixed in R-devel.
> 
> Peter

Notice that I haven't touched Sweave, just compareVersion. The RE's may well be incorrect for Sweave, but the obvious fix was tried in r64087 and broke "make" when building vignettes, hence the reversion in r64100.  (See R-devel mails from Oct 23, 2013 if you care.)

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tomk at 0xdata.com  Sat Apr 26 06:23:23 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Fri, 25 Apr 2014 21:23:23 -0700
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior available
Message-ID: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>


Hi,

We at 0xdata use Java and R together, and the new behavior for read.csv has
made R unable to read the output of Java?s Double.toString().

This, needless to say, is disruptive for us.  (Actually, it was downright shocking.)

+1 for restoring old behavior.

Thanks,
Tom


From murdoch.duncan at gmail.com  Sat Apr 26 13:28:40 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 07:28:40 -0400
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
Message-ID: <535B9868.8040700@gmail.com>

On 26/04/2014, 12:23 AM, Tom Kraljevic wrote:
>
> Hi,
>
> We at 0xdata use Java and R together, and the new behavior for read.csv has
> made R unable to read the output of Java?s Double.toString().

It may be less convenient, but it's certainly not "unable".  Use colClasses.


>
> This, needless to say, is disruptive for us.  (Actually, it was downright shocking.)

It wouldn't have been a shock if you had tested pre-release versions. 
Commercial users of R should be contributing to its development, and 
that's a really easy way to do so.

Duncan Murdoch

>
> +1 for restoring old behavior.


From edd at debian.org  Sat Apr 26 14:26:45 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 26 Apr 2014 07:26:45 -0500
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert)
	behavior	available
In-Reply-To: <535B9868.8040700@gmail.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
Message-ID: <21339.42501.466132.822224@max.nulle.part>


On 26 April 2014 at 07:28, Duncan Murdoch wrote:
| On 26/04/2014, 12:23 AM, Tom Kraljevic wrote:
| >
| > Hi,
| >
| > We at 0xdata use Java and R together, and the new behavior for read.csv has
| > made R unable to read the output of Java?s Double.toString().
| 
| It may be less convenient, but it's certainly not "unable".  Use colClasses.
| 
| 
| >
| > This, needless to say, is disruptive for us.  (Actually, it was downright shocking.)
| 
| It wouldn't have been a shock if you had tested pre-release versions. 
| Commercial users of R should be contributing to its development, and 
| that's a really easy way to do so.

Seconded. For what it is worth, I made five pre-release available within
Debian. Testing thses each was just an apt-get away.

In any event, you can also farm out the old behaviour to a (local or even
CRAN) package that provides the old behaviour if your life depends upon it.

Or you could real serialization rather than relying on the crutch that is csv.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Sat Apr 26 14:35:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 08:35:08 -0400
Subject: [Rd] The regular expressions in compareVersion()
In-Reply-To: <B4D7D0B5-D1C8-4244-BF0E-E40B132DB4D7@gmail.com>
References: <CANROs4dE+EM92_EoD9E1aeS-1B1wmYiV2vyWsSOwx3Xn6ydV1A@mail.gmail.com>
	<5359771E.8040507@gmail.com>
	<CAFDcVCR2JN9EoXwMFpE9RbXYiRN=UyJH_-RgFAKO6_a78uf1CA@mail.gmail.com>
	<53599C22.8040202@gmail.com>
	<CANROs4eZQHOkiocU-31KHVtEbmdzJ9S78N7dKF4n+wTd5ir7=A@mail.gmail.com>
	<CB6F5EE2-E221-4A34-8802-50EF8BFD35E0@r-project.org>
	<535A4F52.4020300@gmail.com>
	<177237DA-1B70-4340-AB22-C550F2495851@gmail.com>
	<B4D7D0B5-D1C8-4244-BF0E-E40B132DB4D7@gmail.com>
Message-ID: <535BA7FC.1060004@gmail.com>

On 26/04/2014, 3:36 AM, peter dalgaard wrote:
>
> On 25 Apr 2014, at 14:50 , peter dalgaard <pdalgd at gmail.com> wrote:
>
>>> Thanks.  I've put in a bug report on this one now, so it shouldn't get missed again.  If nobody else gets to it first I'll deal with it.
>>>
>>> I don't see any value in fixing the compareVersion example, but if someone submits a bug report about it, someone else might fix it.
>>
>> No point in clinging to obviously incorrect code either. Fixed in R-devel.
>>
>> Peter
>
> Notice that I haven't touched Sweave, just compareVersion. The RE's may well be incorrect for Sweave, but the obvious fix was tried in r64087 and broke "make" when building vignettes,
hence the reversion in r64100.  (See R-devel mails from Oct 23, 2013 if 
you care.)


The issue in this case was that the Sweave.Rnw vignette gave a verbatim 
illustration of \Sexpr{}, relying on the bug to prevent it from being 
expanded.  After a bit more testing, I'll re-commit the fixes.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Apr 26 18:50:15 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 12:50:15 -0400
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <06756CB6-19CD-4FA6-8A82-779787FF64FB@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<06756CB6-19CD-4FA6-8A82-779787FF64FB@0xdata.com>
Message-ID: <535BE3C7.8010101@gmail.com>

On 26/04/2014, 12:28 PM, Tom Kraljevic wrote:
>
> Hi Duncan,
>
>
> Please allow me to add a bit more context, which I probably should have
> added to my original message.
>
> We actually did see this in an R 3.1 beta which was pulled by an apt-get
> and thought it had been released
> accidentally.  From my user perspective, the parsing of a string like
> ?1.2345678901234567890? into a
> factor was so surprising, I actually assumed it was just a really bad
> bug that would be fixed before the
> ?real" release.  I didn?t bother reporting it since I assumed beta users
> would be heavily impacted and
> there is no way it wouldn?t be fixed.  Apologies for that mistake on my
> part.

The beta stage is quite late.  There's a non-zero risk that a bug 
detected during the beta stage will make it through to release, 
especially if the report doesn't arrive until after we've switched to 
release candidates.

This change was made very early in the development cycle of 3.1.0, back 
in March 2013.  If you are making serious use of R, I'd really recommend 
that you try out some of the R-devel versions early, when design 
decisions are being made.  I suspect this feature would have been 
changed if we'd heard your complaints then.  It'll likely still be 
changed, but it is harder now, because some users already depend on the 
new behaviour.

>
> After discovering this new behavior really got released GA, I went
> searching to see what was going on.
> I found this bug, which states ?If you wish to express your opinion
> about the new behavior, please do so
> on the R-devel mailing list."
>
> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=15751

Actually it isn't the bug that said that, it was Simon :-).  if you look 
up some of his other posts on this topic here in the R-devel list, 
you'll see a couple of proposals for changes.

Duncan Murdoch

>
> So I?m sharing my opinion, as suggested.  Thanks to all for the time
> spent reading my opinion.
>
>
> Let me also say, we are huge fans of R; many of our customers use R, and
> we greatly appreciate the
> efforts of the R core team.  We are in the process of contributing an
> H2O package back to the R
> community and thanks to the CRAN moderators, as well, for their
> assistance in this process.
> CRAN is a fantastic resource.
>
>
> I would like to share a little more insight on how this behavior affects
> us, in particular.  These merits
> have probably already been debated, but let me state them here again to
> provide the appropriate
> context.
>
> 1.  When dealing with larger and larger data, things become cumbersome.
>   Your comment that
> specifying column types would work is true.  But when there are
> thousands+ of columns, specifying
> them one by one becomes more and more of a burden, and it becomes easier
> to make a mistake.
> And when you do make a mistake, you can imagine a tool writer choosing
> to just ?do what it?s told?
> and swallowing the mistake.  (Trying not to be smarter than the user.)
>
> 2.  When working with datasets that have more and more rows, sometimes
> there is a bad row.
> Big data is messy.  Having one bad value in one bad row contaminate the
> entire dataset can be
> undesirable for some.  When you have millions of rows or more, each row
> becomes less precious.
> Many people would rather just ignore the effects of the bad row than try
> to fix it.  Especially in this
> case, when ?bad? means a bit of extra precision that likely won?t have a
> negative impact on the result.
> (In our case, this extra precision was the output of Java?s
> Double.toString().)
>
> Our users want to use R as a driver language and a reference tool.
>   Being able to interchange
> data easily (even just snippets) between tools is very valuable.
>
>
> Thanks,
> Tom
>
>
> Below is an example of how you can create a million row dataset which
> works fine (parses as a
> numeric), but then adding just one bad row (which still *looks*
> numeric!) flips the entire column to
> a factor.  Finding that one row out of a million+ can be quite a challenge.
>
>
> # Script to generate dataset.
> $ cat genDataset.py
> #!/usr/bin/env python
>
> for x in range(0, 1000000):
>      print (str(x) + ".1")
>
> # Generate the dataset.
> $ ./genDataset.py > million.csv
>
> # R 3.1 thinks it?s a numeric.
> $ R
>  > df = read.csv("million.csv")
>  > str(df)
> 'data.frame':999999 obs. of  1 variable:
>   $ X0.1: num  1.1 2.1 3.1 4.1 5.1 6.1 7.1 8.1 9.1 10.1 ...
>
> # Add one more over-precision row.
> $ echo "1.2345678901234567890" >> million.csv
>
> # Now R 3.1 thinks it?s a factor.
> $ R
>  > df2 = read.csv("million.csv")
>  > str(df2)
> 'data.frame':1000000 obs. of  1 variable:
>   $ X0.1: Factor w/ 1000000 levels "1.1","1.2345678901234567890",..: 1
> 111113 222224 333335 444446 555557 666668 777779 888890 3 ...
>
>
>
>
>
> On Apr 26, 2014, at 4:28 AM, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
>
>> On 26/04/2014, 12:23 AM, Tom Kraljevic wrote:
>>>
>>> Hi,
>>>
>>> We at 0xdata use Java and R together, and the new behavior for
>>> read.csv has
>>> made R unable to read the output of Java?s Double.toString().
>>
>> It may be less convenient, but it's certainly not "unable".  Use
>> colClasses.
>>
>>
>>>
>>> This, needless to say, is disruptive for us.  (Actually, it was
>>> downright shocking.)
>>
>> It wouldn't have been a shock if you had tested pre-release versions.
>> Commercial users of R should be contributing to its development, and
>> that's a really easy way to do so.
>>
>> Duncan Murdoch
>>
>>>
>>> +1 for restoring old behavior.
>>
>>
>>
>


From ash.moran at patchspace.co.uk  Sat Apr 26 18:01:37 2014
From: ash.moran at patchspace.co.uk (ashmoran)
Date: Sat, 26 Apr 2014 09:01:37 -0700 (PDT)
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380544403.10008.15.camel@milan>
References: <1380544403.10008.15.camel@milan>
Message-ID: <1398528097256-4689530.post@n4.nabble.com>

Milan Bouchet-Valat wrote
> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> quoted integers as an acceptable value for columns for which
> colClasses="integer". But when colClasses is omitted, these columns are
> read as integer anyway.
> 
> For example, let's consider a file named file.dat, containing:
> "1"
> "2"
> 
>> read.table("file.dat", colClasses="integer")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
> : 
>   scan() expected 'an integer' and got '"1"'

Hi 

I just ran into a variation of this. I'm teaching myself agent based
modelling from a book that uses NetLogo as the implementation language[1].
NetLogo has a feature called BehaviourSpaces that runs models over a varying
range of parameter values and make arbitrary observations at each time step,
which it then outputs to a CSV. One of the exercises involves plotting some
graphs of a model run, but the output needs some processing before it can be
graphed. Rather than hack away at the data by hand each time I run it, I
decided to find a stats package to help, and I chose R. I'm a complete
beginner to R, and I've been using the R in Action early access PDF as a
guide[2]. I'm using R 3.1.0 GUI 1.64 Mavericks build (6734).

The NetLogo CSV writer quotes all values, and mixes integers and floats. So
a column of data might contain say (with the quotes actually in the file)
"0", "1.25", "1", "2", "3.175". I tried importing the data like this:

    profit <- read.csv("BusinessInvestor1 Profit-table.csv", sep=",",
header=TRUE, skip=6)

But then some of the data is read in as factors:

    str(profit)
    'data.frame':	1560 obs. of  9 variables:
     $ X.run.number.                                                 : int 
8 6 2 7 5 1 3 4 6 8 ...
     $ restrict.sensing.radius                                       :
Factor w/ 1 level "false": 1 1 1 1 1 1 1 1 1 1 ...
     $ risk.multiplier                                               : int 
1 1 1 1 1 1 1 1 1 1 ...
     $ sensing.radius                                                : int 
1 1 1 1 1 1 1 1 1 1 ...
     $ profit.multiplier                                             : num 
0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...
     $ X.step.                                                       : int 
0 0 0 0 0 0 0 0 1 1 ...
     $ mean..wealth..of.turtles                                      :
Factor w/ 1501 levels "0","100038.136",..: 1 1 1 1 1 1 1 1 623 550 ...
     $ mean..profit..of.patches.with..any..turtles.here.             :
Factor w/ 1547 levels "2503.675","2582.275",..: 1 8 7 6 5 4 3 10 278 230 ...
     $ mean..failure.probability..of.patches.with..any..turtles.here.:
Factor w/ 1558 levels "0.026069451281579437",..: 1504 1528 1508 1518 1516
1514 1512 1536 1321 1471 ...

(For reasons I don't understand, the profit.multiplier parameter ? which
runs "0.5", "0.6", ?, "1" ? is imported as a numeric, whereas the
observation values get turned into factors.)

I read about colClasses but this trips over the "quoted integers aren't
integers" bug:

    profit <- read.csv("BusinessInvestor1 Profit-table.csv", sep=",",
header=TRUE, skip=6, colClasses=c("integer", "logical", "numeric",
"numeric", "numeric", "integer", "numeric", "numeric", "numeric"))
    Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
na.strings,  : 
      scan() expected 'an integer', got '"8"'

I created a little script to import the data, and use some casts to clean it
up. At first I thought it was working, until I realised this line (to
process CSV data in the range 0...1):

    profit$mean_failure_probability_of_inhabited <-
as.numeric(profit$mean_failure_probability_of_inhabited)

Was producing crazy values:

    str(profit)
    'data.frame':   1560 obs. of  9 variables:
    ...
     $ mean_failure_probability_of_inhabited: num  1504 1528 1508 1518 1516
...

Eventually I figured out to do this (although I haven't yet figured out
why):

    profit$mean_failure_probability_of_inhabited <-
as.numeric(as.character(profit$mean_failure_probability_of_inhabited))

Anyway, for a beginner coming to R, this is all REALLY confusing, and it's
taken me several hours to get my head round it. Although after reading about
it a bit I can see the implementation issues causing this behaviour, as a
noob it just feels like "R can't import CSV data". The most baffling thing
is how telling R what format the data in each column is in actually
*reduces* its ability to read the file! (For a while I thought it was
complaining because "8" is an integer, not a real, but now I see it's
because it's seeing it as a string.) My understanding of the CSV was the
same as Peter Meilstrup describes it later in the thread ? that quotes in a
CSV are to allow the delimiter character in a value, and don't imply
anything about the type of the data (because CSVs are untyped).

Googling the scan() error led to this mailing list thread so I thought I'd
describe my experience. If there's a more intuitive way for read.csv /
read.table to work it might save beginners like me a lot of head-scratching!

Best regards
Ash

[1] http://www.amazon.com/dp/0691136742/
[2] http://www.manning.com/kabacoff2/



--
View this message in context: http://r.789695.n4.nabble.com/read-table-with-quoted-integers-tp4677249p4689530.html
Sent from the R devel mailing list archive at Nabble.com.


From tomk at 0xdata.com  Sat Apr 26 18:28:48 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Sat, 26 Apr 2014 09:28:48 -0700
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <535B9868.8040700@gmail.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
Message-ID: <06756CB6-19CD-4FA6-8A82-779787FF64FB@0xdata.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140426/74551927/attachment.pl>

From tomk at 0xdata.com  Sat Apr 26 18:43:37 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Sat, 26 Apr 2014 09:43:37 -0700
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <21339.42501.466132.822224@max.nulle.part>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
Message-ID: <CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>


Hi Dirk,


Thanks for taking the time to respond (both here and in other forums).

Most of what I wanted to share I put in a followup response to Duncan (please read
that thread if you?re interested).

I would like to comment on the last point you brought up, though, in case anyone else
finds it beneficial.

For data which is exchanged programmatically machine-to-machine, I was able to
use Java?s Double.toHexString() as a direct replacement for toString().  R is able
to read this lossless (but still text) format.  So this addresses some of the challenges
we have with this change.


Thanks,
Tom


On Apr 26, 2014, at 5:26 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

> 
> On 26 April 2014 at 07:28, Duncan Murdoch wrote:
> | On 26/04/2014, 12:23 AM, Tom Kraljevic wrote:
> | >
> | > Hi,
> | >
> | > We at 0xdata use Java and R together, and the new behavior for read.csv has
> | > made R unable to read the output of Java?s Double.toString().
> | 
> | It may be less convenient, but it's certainly not "unable".  Use colClasses.
> | 
> | 
> | >
> | > This, needless to say, is disruptive for us.  (Actually, it was downright shocking.)
> | 
> | It wouldn't have been a shock if you had tested pre-release versions. 
> | Commercial users of R should be contributing to its development, and 
> | that's a really easy way to do so.
> 
> Seconded. For what it is worth, I made five pre-release available within
> Debian. Testing thses each was just an apt-get away.
> 
> In any event, you can also farm out the old behaviour to a (local or even
> CRAN) package that provides the old behaviour if your life depends upon it.
> 
> Or you could real serialization rather than relying on the crutch that is csv.
> 
> Dirk
> 
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From tomk at 0xdata.com  Sat Apr 26 22:12:09 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Sat, 26 Apr 2014 13:12:09 -0700
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
	<CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
Message-ID: <2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>


Hi,


One additional follow-up here.

Unfortunately, I hit what looks like an R parsing bug that makes the Java Double.toHexString() output
unreliable for reading by R.  (This is really unfortunate, because the format is intended to be lossless
and it looks like it?s so close to fully working.)

You can see the spec for the conversion here:
    http://docs.oracle.com/javase/7/docs/api/java/lang/Double.html#toHexString(double)

The last value in the list below is not parsed by R in the way I expected, and causes the column to flip 
from numeric to factor.


-0x1.8ff831c7ffffdp-1
-0x1.aff831c7ffffdp-1
-0x1.bff831c7ffffdp-1
-0x1.cff831c7ffffdp-1
-0x1.dff831c7ffffdp-1
-0x1.eff831c7ffffdp-1
-0x1.fff831c7ffffdp-1           <<<<< this value is not parsed as a number and flips the column from numeric to factor.


Below is the R output from adding one row at a time to ?bad.csv?.
The last attempt results in a factor rather than a numeric column.

What?s really odd about it is that the .a through .e case work fine but the .f case doesn?t.


Thanks,
Tom


> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	1 obs. of  1 variable:
 $ V1: num -0.781
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	2 obs. of  1 variable:
 $ V1: num  -0.781 -0.844
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	3 obs. of  1 variable:
 $ V1: num  -0.781 -0.844 -0.875
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	4 obs. of  1 variable:
 $ V1: num  -0.781 -0.844 -0.875 -0.906
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	5 obs. of  1 variable:
 $ V1: num  -0.781 -0.844 -0.875 -0.906 -0.937
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	6 obs. of  1 variable:
 $ V1: num  -0.781 -0.844 -0.875 -0.906 -0.937 ...
> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
> str(bad.df)
'data.frame':	7 obs. of  1 variable:
 $ V1: Factor w/ 7 levels "-0x1.8ff831c7ffffdp-1",..: 1 2 3 4 5 6 7


From maechler at stat.math.ethz.ch  Sat Apr 26 22:28:42 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Apr 2014 22:28:42 +0200
Subject: [Rd] Can the output of Sys.getenv() be improved?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FACA474@PA-MBX01.na.tibco.com>
References: <8EE4E2C595735A4EAEC2A3311537FE4D15B84B24@DCPWPEXMBX03.mdanderson.edu>
	<E66794E69CFDE04D9A70842786030B933FAC7207@PA-MBX01.na.tibco.com>
	<21330.29344.628971.904268@stat.math.ethz.ch>
	<E66794E69CFDE04D9A70842786030B933FACA474@PA-MBX01.na.tibco.com>
Message-ID: <21340.5882.843346.677435@stat.math.ethz.ch>

> >     >> structure(Sys.getenv(), class="simple.list")
> >     >                            _ !
> > 
> > Good idea; this is something we could do unconditionally, i.e.,
> > return from Sys.getenv().

> As the OP noted, the print method for simple.list will pad all
> lines to have the same length, so if, say, PATH, is very long,
> all other printed lines will be padded with blanks to match its
> length.  With the Windows GUI you don't notice this much
> because the lines do not wrap around, but when viewing results
> on Linux with a terminal emulator like putty this looks bad.  A print method like
>    p <- function(x, ...)
>    {
>       cat(formatDL(x), sep="\n")
>       invisible(x)
>    }
> would look better.

You are right, thank you, Bill, for the suggestion.
Indeed, as we have got the nice formatDL() formatting
functionality, why not providing yet another simple listlike
class, where I've use  "DList" (Description List) as indirectly
suggested by the DL of formatDL().

Committed as rev 65504 (R-devel only).

If there is a compelling argument for a better S3 class name, we
can still change that (longer names are not compelling to me,
much shorter ones neither ...)

Martin


> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com


> > -----Original Message-----
> > From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> > Sent: Saturday, April 19, 2014 5:57 AM
> > To: William Dunlap
> > Cc: Jun Zhang; r-devel at r-project.org
> > Subject: Re: [Rd] Can the output of Sys.getenv() be improved?
> > 
> > >>>>> William Dunlap <wdunlap at tibco.com>
> > >>>>>     on Fri, 18 Apr 2014 16:50:22 +0000 writes:
> > 
> >     >> Within an R session, type Sys.getenv() will list all the
> >     >> environment variables, but each one of them occupies
> >     >> about a page, so scrolling to find one is difficult. Is
> >     >> this because I don't know how to use it or something
> >     >> could be improved?
> > 
> >     > Attaching the class "simple.list" to the output of
> >     > Sys.getenv() gives it a nicer print method:
> > 
> >     >> structure(Sys.getenv(), class="simple.list")
> >     >                            _ !
> > 
> > Good idea; this is something we could do unconditionally, i.e.,
> > return from Sys.getenv().
> > It would hardly break code,
> > as simple.list only has a print and a `[` method.
> > 
> > It would help people like Jun and could hardly harm, AFAICS.
> > 
> > Opinions?


From maechler at stat.math.ethz.ch  Sat Apr 26 22:59:17 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Apr 2014 22:59:17 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
Message-ID: <21340.7717.170377.354029@stat.math.ethz.ch>

>>>>> Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Sat, 19 Apr 2014 13:06:15 -0400 writes:

    > On Apr 19, 2014, at 9:00 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
    >>>>>>> on Thu, 17 Apr 2014 19:15:47 -0400 writes:
    >> 
    >>>> This is all application specific and
    >>>> sort of beyond the scope of type.convert(), which now behaves as it
    >>>> has been documented to behave.
    >> 
    >>> That's only a true statement because the documentation was changed to reflect the new behavior! The new feature in type.convert certainly does not behave according to the documentation as of R 3.0.3. Here's a snippit:
    >> 
    >>> The first type that can accept all the
    >>> non-missing values is chosen (numeric and complex return values
    >>> will represented approximately, of course).
    >> 
    >>> The key phrase is in parentheses, which reminds the user to expect a possible loss of precision. That important parenthetical was removed from the documentation in R 3.1.0 (among other changes).
    >> 
    >>> Putting aside the fact that this introduces a large amount of unnecessary work rewriting SQL / data import code, SQL packages, my biggest conceptual problem is that I can no longer rely on a particular function call returning a particular class. In my example querying stock prices, about 5% of prices came back as factors and the remaining 95% as numeric, so we had random errors popping in throughout the morning.
    >> 
    >>> Here's a short example showing us how the new behavior can be unreliable. I pass a character representation of a uniformly distributed random variable to type.convert. 90% of the time it is converted to "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in which type.convert converts to a factor the leading non-zero digit is always a 9. So if you were expecting a numeric value, then 1 in 10 times you may have a bug in your code that didn't exist before.
    >> 
    >>>> options(digits=16)
    >>>> cl <- NULL; for (i in 1:10000) cl[i] <- class(type.convert(format(runif(1))))
    >>>> table(cl)
    >>> cl
    >>> factor numeric
    >>> 990    9010
    >> 
    >> Yes.  
    >> 
    >> Murray's point is valid, too.
    >> 
    >> But in my view, with the reasoning we have seen here,
    >> *and* with the well known software design principle of
    >> "least surprise" in mind,
    >> I also do think that the default for type.convert() should be what
    >> it has been for > 10 years now.
    >> 

    > I think there should be two separate discussions:

    > a) have an option (argument to type.convert and possibly read.table) to enable/disable this behavior. I'm strongly in favor of this.

In my (not committed) version of R-devel, I now have

 > str(type.convert(format(1/3, digits=17), exact=TRUE)) 
  Factor w/ 1 level "0.33333333333333331": 1
 > str(type.convert(format(1/3, digits=17), exact=FALSE))
  num 0.333

where the 'exact' argument name has been ``imported'' from the
underlying C code.

[ As we CRAN package writers know by now, arguments nowadays can
  hardly be abbreviated anymore, and so I am not open to longer
  alternative argument names, as someone liking blind typing, I'm
  not fond of camel case or other keyboard gymnastics (;-) but if someone has a great idea for
  a better argument name.... ]

Instead of only  TRUE/FALSE, we could consider NA with 
semantics "FALSE + warning" or also "TRUE + warning".


    > b) decide what the default for a) will be. I have no strong opinion, I can see arguments in both directions

I think many have seen the good arguments in both directions.
I'm still strongly advocating that we value long term stability
higher here, and revert to more compatibility with the many
years of previous versions.

If we'd use a default of 'exact=NA', I'd like it to mean
FALSE + warning, but would not oppose much to  TRUE + warning.

I agree that for the TRUE case, it may make more sense to return
string-like object of a new (simple) class such as  "bignum"
that was mentioned in this thread.

OTOH, this functionality should make it into an R 3.1.1 in the
not so distant future, and thinking through consequences and
implementing the new class approach may just take a tad too much
time...

Martin

    > But most importantly I think a) is better than the status quo - even if the discussion about b) drags out.

    > Cheers,
    > Simon


From murdoch.duncan at gmail.com  Sat Apr 26 23:18:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 17:18:59 -0400
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
	<CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
	<2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>
Message-ID: <535C22C3.1080108@gmail.com>

On 26/04/2014, 4:12 PM, Tom Kraljevic wrote:
>
> Hi,
>
>
> One additional follow-up here.
>
> Unfortunately, I hit what looks like an R parsing bug that makes the Java Double.toHexString() output
> unreliable for reading by R.  (This is really unfortunate, because the format is intended to be lossless
> and it looks like it?s so close to fully working.)
>
> You can see the spec for the conversion here:
>      http://docs.oracle.com/javase/7/docs/api/java/lang/Double.html#toHexString(double)
>
> The last value in the list below is not parsed by R in the way I expected, and causes the column to flip
> from numeric to factor.
>
>
> -0x1.8ff831c7ffffdp-1
> -0x1.aff831c7ffffdp-1
> -0x1.bff831c7ffffdp-1
> -0x1.cff831c7ffffdp-1
> -0x1.dff831c7ffffdp-1
> -0x1.eff831c7ffffdp-1
> -0x1.fff831c7ffffdp-1           <<<<< this value is not parsed as a number and flips the column from numeric to factor.

That looks like a bug in the conversion code.  It uses the same test for 
lack of accuracy for hex doubles as it uses for decimal ones, but hex 
doubles can be larger before they lose precision.  I believe the largest 
integer that can be represented exactly is 2^53 - 1, i.e.

0x1.fffffffffffffp52

in this notation; can you confirm that your Java code reads it and 
writes the same string?  This is about 1% bigger than the limit at which 
type.convert switches to strings or factors.

Duncan Murdoch
>
>
> Below is the R output from adding one row at a time to ?bad.csv?.
> The last attempt results in a factor rather than a numeric column.
>
> What?s really odd about it is that the .a through .e case work fine but the .f case doesn?t.
>
>
> Thanks,
> Tom
>
>
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	1 obs. of  1 variable:
>   $ V1: num -0.781
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	2 obs. of  1 variable:
>   $ V1: num  -0.781 -0.844
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	3 obs. of  1 variable:
>   $ V1: num  -0.781 -0.844 -0.875
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	4 obs. of  1 variable:
>   $ V1: num  -0.781 -0.844 -0.875 -0.906
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	5 obs. of  1 variable:
>   $ V1: num  -0.781 -0.844 -0.875 -0.906 -0.937
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	6 obs. of  1 variable:
>   $ V1: num  -0.781 -0.844 -0.875 -0.906 -0.937 ...
>> bad.df = read.csv(file="/Users/tomk/bad.csv", header=F)
>> str(bad.df)
> 'data.frame':	7 obs. of  1 variable:
>   $ V1: Factor w/ 7 levels "-0x1.8ff831c7ffffdp-1",..: 1 2 3 4 5 6 7
>
>


From greg at warnes.net  Sat Apr 26 23:27:30 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Sat, 26 Apr 2014 17:27:30 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <21340.7717.170377.354029@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
Message-ID: <390CD06C-3936-456D-88BE-BBA872B771B5@warnes.net>


On Apr 26, 2014, at 4:59 PM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> 
>> I think there should be two separate discussions:
> 
>> a) have an option (argument to type.convert and possibly read.table) to enable/disable this behavior. I'm strongly in favor of this.
> 
> In my (not committed) version of R-devel, I now have
> 
>> str(type.convert(format(1/3, digits=17), exact=TRUE)) 
>  Factor w/ 1 level "0.33333333333333331": 1
>> str(type.convert(format(1/3, digits=17), exact=FALSE))
>  num 0.333
> 
> where the 'exact' argument name has been ``imported'' from the
> underlying C code.
> 

Looks good to me!

> <snip>
> 
> Instead of only  TRUE/FALSE, we could consider NA with 
> semantics "FALSE + warning" or also "TRUE + warning?.
> 
> 
>> b) decide what the default for a) will be. I have no strong opinion, I can see arguments in both directions
> 
> I think many have seen the good arguments in both directions.
> I'm still strongly advocating that we value long term stability
> higher here, and revert to more compatibility with the many
> years of previous versions.
> 
> If we'd use a default of 'exact=NA', I'd like it to mean
> FALSE + warning, but would not oppose much to  TRUE + warning.
> 

I vote for the default to be ?exact=NA? meaning ?FALSE + warning" 

-Greg

From murdoch.duncan at gmail.com  Sun Apr 27 00:59:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 26 Apr 2014 18:59:54 -0400
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <69603DCB-A117-41F1-BBA1-609E7B61B9F1@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
	<CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
	<2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>
	<535C22C3.1080108@gmail.com>
	<69603DCB-A117-41F1-BBA1-609E7B61B9F1@0xdata.com>
Message-ID: <535C3A6A.50101@gmail.com>

On 26/04/2014, 6:40 PM, Tom Kraljevic wrote:
>
> Hi Duncan,
>
>
> This program and output should answer your question regarding java behavior.
>
> Basically the character toHexString() representation is shown to be
> lossless for this
> example (in Java).
>
> Please let me know if there is any way I can help further.  I?d love for
> this to work!
> I would be happy to put all this into an R bug report if that is
> convenient for you.

This one has enough attention already that I don't think it will get 
lost, so no more bug reports are necessary.  Martin Maechler (on another 
thread) is describing some changes that should address this.  It would 
be really helpful if you tested it on your examples after he commits his 
changes.

Duncan Murdoch

>
>
> Thanks,
> Tom
>
>
>
>
> $ cat example.java
> class example {
>      public static void main(String[] args) {
>          String value_as_string = "-0x1.fff831c7ffffdp-1";
>          double value = Double.parseDouble(value_as_string);
>          System.out.println("Starting string    : " + value_as_string);
>          System.out.println("value toString()   : " +
> Double.toString(value));
>          System.out.println("value toHexString(): " +
> Double.toHexString(value));
>
>          long bits = Double.doubleToRawLongBits(value);
>          boolean isNegative = (bits & 0x8000000000000000L) != 0;
>          long biased_exponent      = (bits & 0x7ff0000000000000L) >> 52;
>          long exponent = biased_exponent - 1023;
>          long mantissa =  bits & 0x000fffffffffffffL;
>          System.out.println("isNegative         : " + isNegative);
>          System.out.println("biased exponent    : " + biased_exponent);
>          System.out.println("exponent           : " + exponent);
>          System.out.println("mantissa           : " + mantissa);
>          System.out.println("mantissa as hex    : " +
> Long.toHexString(mantissa));
>      }
> }
>
>
> $ javac example.java
> $ java example
> Starting string    : -0x1.fff831c7ffffdp-1
> value toString()   : -0.999940448440611
> value toHexString(): -0x1.fff831c7ffffdp-1
> isNegative         : true
> biased exponent    : 1022
> exponent           : -1
> mantissa           : 4503063234609149
> mantissa as hex    : fff831c7ffffd
>
>
> $ java -version
> java version "1.7.0_51"
> Java(TM) SE Runtime Environment (build 1.7.0_51-b13)
> Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)
>
>
>
> On Apr 26, 2014, at 2:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
>
>> On 26/04/2014, 4:12 PM, Tom Kraljevic wrote:
>>>
>>> Hi,
>>>
>>>
>>> One additional follow-up here.
>>>
>>> Unfortunately, I hit what looks like an R parsing bug that makes the
>>> Java Double.toHexString() output
>>> unreliable for reading by R.  (This is really unfortunate, because
>>> the format is intended to be lossless
>>> and it looks like it?s so close to fully working.)
>>>
>>> You can see the spec for the conversion here:
>>> http://docs.oracle.com/javase/7/docs/api/java/lang/Double.html#toHexString(double)
>>> <http://docs.oracle.com/javase/7/docs/api/java/lang/Double.html#toHexString%28double%29>
>>>
>>> The last value in the list below is not parsed by R in the way I
>>> expected, and causes the column to flip
>>> from numeric to factor.
>>>
>>>
>>> -0x1.8ff831c7ffffdp-1
>>> -0x1.aff831c7ffffdp-1
>>> -0x1.bff831c7ffffdp-1
>>> -0x1.cff831c7ffffdp-1
>>> -0x1.dff831c7ffffdp-1
>>> -0x1.eff831c7ffffdp-1
>>> -0x1.fff831c7ffffdp-1           <<<<< this value is not parsed as a
>>> number and flips the column from numeric to factor.
>>
>> That looks like a bug in the conversion code.  It uses the same test
>> for lack of accuracy for hex doubles as it uses for decimal ones, but
>> hex doubles can be larger before they lose precision.  I believe the
>> largest integer that can be represented exactly is 2^53 - 1, i.e.
>>
>> 0x1.fffffffffffffp52
>>
>> in this notation; can you confirm that your Java code reads it and
>> writes the same string?  This is about 1% bigger than the limit at
>> which type.convert switches to strings or factors.
>>
>> Duncan Murdoch
>


From tomk at 0xdata.com  Sun Apr 27 00:40:14 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Sat, 26 Apr 2014 15:40:14 -0700
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <535C22C3.1080108@gmail.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
	<CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
	<2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>
	<535C22C3.1080108@gmail.com>
Message-ID: <69603DCB-A117-41F1-BBA1-609E7B61B9F1@0xdata.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140426/eba4abd6/attachment.pl>

From kevin at 0xdata.com  Sun Apr 27 01:03:36 2014
From: kevin at 0xdata.com (knormoyle)
Date: Sat, 26 Apr 2014 16:03:36 -0700 (PDT)
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
	available
In-Reply-To: <535C22C3.1080108@gmail.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
	<535B9868.8040700@gmail.com>
	<21339.42501.466132.822224@max.nulle.part>
	<CD8BE0B1-B423-4A78-999D-150B9543E4B4@0xdata.com>
	<2E36E30E-424B-4CC4-BA9C-6AEC2AAFB340@0xdata.com>
	<535C22C3.1080108@gmail.com>
Message-ID: <1398553416700-4689553.post@n4.nabble.com>

Hi Duncan,
I'm with Tom, don't want to be redundant but here's some extra info.
This made me think that the problem is not a 'theshold'. Any thoughts.
Also, if the "bad" number strings are entered at the R command prompt, they
are parsed correctly as the expected number. (not factors)

thanks,
-kevin


this works

0x1.ffadp-1

> df = read.csv("bad1.csv", header=F)
> str(df)
'data.frame':    1 obs. of  1 variable:
 $ V1: num 0.999


but this doesn't

0x1.ffa000000000dp-1

> df = read.csv("bad1.csv", header=F)
> str(df)
'data.frame':    1 obs. of  1 variable:
 $ V1: Factor w/ 1 level "0x1.ffa000000000dp-1 ": 1


this also works, which is one less trailing zero.

0x1.ffa00000000dp-1

>  df = read.csv("bad1.csv", header=F)
> str(df)
'data.frame':    1 obs. of  1 variable:
 $ V1: num 0.999 



--
View this message in context: http://r.789695.n4.nabble.com/Please-make-Pre-3-1-read-csv-type-convert-behavior-available-tp4689507p4689553.html
Sent from the R devel mailing list archive at Nabble.com.


From hwborchers at gmail.com  Sun Apr 27 13:38:59 2014
From: hwborchers at gmail.com (Hans W Borchers)
Date: Sun, 27 Apr 2014 13:38:59 +0200
Subject: [Rd] Strange behaviour of the ':' operator
Message-ID: <CAML4n3M3Jzmm6aCaYCjF5XGd=Swg9YgxTUU5YykXNOop2JKi6Q@mail.gmail.com>

Is the following really intended behaviour of the ':' operator,

    > s <- pi - 3.0 + 1e-07
    > x <- s:pi
    > x
    [1] 0.1415928 1.1415928 2.1415928 3.1415928

though the last entry in the range vector is greater than pi?

    > x[4] > pi; x[4] - pi
    [1] TRUE
    [1] 1e-07

and the same, of course, for the seq() function.
I would understand this behaviour for 1e-14 or so, but it seems
unexpected for such a distinct difference as 1e-07.


From 538280 at gmail.com  Sun Apr 27 15:58:20 2014
From: 538280 at gmail.com (Greg Snow)
Date: Sun, 27 Apr 2014 07:58:20 -0600
Subject: [Rd] Strange behaviour of the ':' operator
In-Reply-To: <CAML4n3M3Jzmm6aCaYCjF5XGd=Swg9YgxTUU5YykXNOop2JKi6Q@mail.gmail.com>
References: <CAML4n3M3Jzmm6aCaYCjF5XGd=Swg9YgxTUU5YykXNOop2JKi6Q@mail.gmail.com>
Message-ID: <CAFEqCdwT69fBiy8J-3biqOSUaFf4GE7E9VbhEc_uguvZs=wWog@mail.gmail.com>

>From the help page ?':' we can read:

"Value ?to? will be included if it differs from ?from? by an
     integer up to a numeric fuzz of about ?1e-7?."

So it looks like it is the intended behavior.



On Sun, Apr 27, 2014 at 5:38 AM, Hans W Borchers <hwborchers at gmail.com> wrote:
> Is the following really intended behaviour of the ':' operator,
>
>     > s <- pi - 3.0 + 1e-07
>     > x <- s:pi
>     > x
>     [1] 0.1415928 1.1415928 2.1415928 3.1415928
>
> though the last entry in the range vector is greater than pi?
>
>     > x[4] > pi; x[4] - pi
>     [1] TRUE
>     [1] 1e-07
>
> and the same, of course, for the seq() function.
> I would understand this behaviour for 1e-14 or so, but it seems
> unexpected for such a distinct difference as 1e-07.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From h.wickham at gmail.com  Sun Apr 27 16:16:41 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 27 Apr 2014 09:16:41 -0500
Subject: [Rd] type.convert and doubles
In-Reply-To: <21340.7717.170377.354029@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
Message-ID: <CABdHhvH5mi7B4QsF8a2KOaxk7L_AwRvq0Y2qLvbVVAphfGQe-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140427/50815a5c/attachment.pl>

From atp at piskorski.com  Sun Apr 27 17:31:25 2014
From: atp at piskorski.com (Andrew Piskorski)
Date: Sun, 27 Apr 2014 11:31:25 -0400
Subject: [Rd] Please make Pre-3.1 read.csv (type.convert) behavior
 available
In-Reply-To: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
References: <D56A602D-9044-400D-B12A-196A5EAEC05D@0xdata.com>
Message-ID: <20140427153125.GA20280@piskorski.com>

On Fri, Apr 25, 2014 at 09:23:23PM -0700, Tom Kraljevic wrote:

> This, needless to say, is disruptive for us.  (Actually, it was downright shocking.)

It WAS somewhat shocking.  I trust the R core team to get things
right, and (AFAICT) they nearly always do.  This was an exception, and
shocking mostly in that it was so obviously wrong to completely
discard all possibility of backwards compatibility.

The old type.convert() functionality worked fine and was very useful,
so the *obviously* right thing to do would be to at least retain the
old behavior as a (non-default) option.

Reproducing the old behavior in user R code is not simple.  For
anybody else stuck with this, you can do it (probably inefficiently)
with the two functions below.  Create your own version of read.table()
that calls the dtk.type.convert() below instead of the stock
type.convert().  It's not pretty, but that will do it.


dtk.type.convert <- function(xx ,... ,ignore.signif.p=TRUE) { 
   # Add backwards compatibility to R 3.1's "new feature": 
   if(ignore.signif.p && all(dtk.can.be.numeric(xx ,ignore.na.p=TRUE))) { 
      if(all(is.na(xx))) type.convert(xx ,...) 
      else methods::as(xx ,"numeric")  
   } else type.convert(xx ,...) 
} 

dtk.can.be.numeric <- function(xx ,ignore.na.p=TRUE) { 
   # Test whether a value can be converted to numeric without becoming NA. 
   # AKA, can this value be usefully represented as numeric? 
   # Optionally ignore NAs already present in the incoming data. 

   old.warn <- options(warn = -1) ; on.exit(options(old.warn)) 
   aa <- !is.na(as.numeric(xx)) 
   if(ignore.na.p) (is.na(xx) | aa) else aa 
}

-- 
Andrew Piskorski <atp at piskorski.com>


From murdoch.duncan at gmail.com  Sun Apr 27 18:26:31 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Apr 2014 12:26:31 -0400
Subject: [Rd] type.convert and doubles
In-Reply-To: <CABdHhvH5mi7B4QsF8a2KOaxk7L_AwRvq0Y2qLvbVVAphfGQe-g@mail.gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>	<534860CC.2090206@gmail.com>	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>	<21330.29530.72292.435730@stat.math.ethz.ch>	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>	<21340.7717.170377.354029@stat.math.ethz.ch>
	<CABdHhvH5mi7B4QsF8a2KOaxk7L_AwRvq0Y2qLvbVVAphfGQe-g@mail.gmail.com>
Message-ID: <535D2FB7.9080304@gmail.com>

On 27/04/2014, 10:16 AM, Hadley Wickham wrote:
> Is there a reason it's a factor and not a string? A string would seem to be
> more appropriate to me (given that we know it's a number that can't be
> represented exactly by R)

The user asked that anything which can't be converted to a number should 
be converted to a factor.

Yes, that's a bad default, but some people rely on it.

Duncan Murdoch

>
> Hadley
>
> On Saturday, April 26, 2014, Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
>>>>>>> Simon Urbanek <simon.urbanek at r-project.org <javascript:;>>
>>>>>>>      on Sat, 19 Apr 2014 13:06:15 -0400 writes:
>>
>>      > On Apr 19, 2014, at 9:00 AM, Martin Maechler <
>> maechler at stat.math.ethz.ch <javascript:;>> wrote:
>>      >>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com<javascript:;>
>>>
>>      >>>>>>> on Thu, 17 Apr 2014 19:15:47 -0400 writes:
>>      >>
>>      >>>> This is all application specific and
>>      >>>> sort of beyond the scope of type.convert(), which now behaves as
>> it
>>      >>>> has been documented to behave.
>>      >>
>>      >>> That's only a true statement because the documentation was changed
>> to reflect the new behavior! The new feature in type.convert certainly does
>> not behave according to the documentation as of R 3.0.3. Here's a snippit:
>>      >>
>>      >>> The first type that can accept all the
>>      >>> non-missing values is chosen (numeric and complex return values
>>      >>> will represented approximately, of course).
>>      >>
>>      >>> The key phrase is in parentheses, which reminds the user to expect
>> a possible loss of precision. That important parenthetical was removed from
>> the documentation in R 3.1.0 (among other changes).
>>      >>
>>      >>> Putting aside the fact that this introduces a large amount of
>> unnecessary work rewriting SQL / data import code, SQL packages, my biggest
>> conceptual problem is that I can no longer rely on a particular function
>> call returning a particular class. In my example querying stock prices,
>> about 5% of prices came back as factors and the remaining 95% as numeric,
>> so we had random errors popping in throughout the morning.
>>      >>
>>      >>> Here's a short example showing us how the new behavior can be
>> unreliable. I pass a character representation of a uniformly distributed
>> random variable to type.convert. 90% of the time it is converted to
>> "numeric" and 10% it is a "factor" (in R 3.1.0). In the 10% of cases in
>> which type.convert converts to a factor the leading non-zero digit is
>> always a 9. So if you were expecting a numeric value, then 1 in 10 times
>> you may have a bug in your code that didn't exist before.
>>      >>
>>      >>>> options(digits=16)
>>      >>>> cl <- NULL; for (i in 1:10000) cl[i] <-
>> class(type.convert(format(runif(1))))
>>      >>>> table(cl)
>>      >>> cl
>>      >>> factor numeric
>>      >>> 990    9010
>>      >>
>>      >> Yes.
>>      >>
>>      >> Murray's point is valid, too.
>>      >>
>>      >> But in my view, with the reasoning we have seen here,
>>      >> *and* with the well known software design principle of
>>      >> "least surprise" in mind,
>>      >> I also do think that the default for type.convert() should be what
>>      >> it has been for > 10 years now.
>>      >>
>>
>>      > I think there should be two separate discussions:
>>
>>      > a) have an option (argument to type.convert and possibly read.table)
>> to enable/disable this behavior. I'm strongly in favor of this.
>>
>> In my (not committed) version of R-devel, I now have
>>
>>   > str(type.convert(format(1/3, digits=17), exact=TRUE))
>>    Factor w/ 1 level "0.33333333333333331": 1
>>   > str(type.convert(format(1/3, digits=17), exact=FALSE))
>>    num 0.333
>>
>> where the 'exact' argument name has been ``imported'' from the
>> underlying C code.
>>
>> [ As we CRAN package writers know by now, arguments nowadays can
>>    hardly be abbreviated anymore, and so I am not open to longer
>>    alternative argument names, as someone liking blind typing, I'm
>>    not fond of camel case or other keyboard gymnastics (;-) but if someone
>> has a great idea for
>>    a better argument name.... ]
>>
>> Instead of only  TRUE/FALSE, we could consider NA with
>> semantics "FALSE + warning" or also "TRUE + warning".
>>
>>
>>      > b) decide what the default for a) will be. I have no strong opinion,
>> I can see arguments in both directions
>>
>> I think many have seen the good arguments in both directions.
>> I'm still strongly advocating that we value long term stability
>> higher here, and revert to more compatibility with the many
>> years of previous versions.
>>
>> If we'd use a default of 'exact=NA', I'd like it to mean
>> FALSE + warning, but would not oppose much to  TRUE + warning.
>>
>> I agree that for the TRUE case, it may make more sense to return
>> string-like object of a new (simple) class such as  "bignum"
>> that was mentioned in this thread.
>>
>> OTOH, this functionality should make it into an R 3.1.1 in the
>> not so distant future, and thinking through consequences and
>> implementing the new class approach may just take a tad too much
>> time...
>>
>> Martin
>>
>>      > But most importantly I think a) is better than the status quo - even
>> if the discussion about b) drags out.
>>
>>      > Cheers,
>>      > Simon
>>
>> ______________________________________________
>> R-devel at r-project.org <javascript:;> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


From konrad.rudolph+r-devel at gmail.com  Mon Apr 28 15:55:26 2014
From: konrad.rudolph+r-devel at gmail.com (Konrad Rudolph)
Date: Mon, 28 Apr 2014 14:55:26 +0100
Subject: [Rd] RFC: API design of package "modules"
Message-ID: <CAM2gKPaQnMCtdS8AuaRxe-eq=d6s2s-CTnuMXxKumpfrW6rDNA@mail.gmail.com>

Some time ago I?ve published the first draft of the package ?modules?
[1] which aims to provide a module system as an alternative to
packages for R. Very briefly, this is aimed to complement the existing
package system for very small code units which do not require the
(small, but existing) overhead associated with writing a package. I?ve
noticed that people around me put off writing packages (and thus,
reusable code) due to that, and use `source` instead. Modules would
work (in many cases) as a drop-in replacement for `source`, and could
thus encourage code reuse.

However, now I?m stuck on a particular aspect of the API and would
like to solicit feedback from r-devel.

`import('foo')` imports a given module, `foo`. In addition to other
differences detailed in [2], modules allow/impose a hierarchical
organisation. That way, `import('foo')` might load code from a file
called `foo.r` or from a file called `foo/__init__.r` (reminiscent of
Python?s module mechanism) and `import('foo/bar')` would load a file
`foo/bar.r` or `foo/bar/__init__r.` [3].

`import` also allows selectively importing only some functions, so
that a user might write `import('foo', c('f', 'g'))` to only import
the functions `f` and `g`.

However, at the moment modules don?t allow the equivalent of Python?s
`from foo import bar` for nested modules. That is, if I have two
nested modules `bar` and `baz`, I cannot import both of them in one
`import` statement, I need two (`import('foo/bar');
import('foo/baz')`).

I would like feedback on what people think is the best way of solving
this. Here are some suggestions I?ve gathered; in the following,
`foo`, `bar`, `qux` are (sub)modules. `f1`, `b1`, `b2`, `q1` ? are
functions within the modules whose name starts with the same letter:

(1) Use of Bash-like wildcards to specify which modules to import:

```
foo = import('foo')
# Exposes `foo$f1`, `foo$f2` ?, but no submodules

bar = import('foo/bar')
# Exposes `bar$b1`, `bar$b2`

foo = import('foo/{bar,qux}')
# Exposes `foo$f1`, `foo$bar$b1`, `foo$bar$b2`, `foo$qux$q1` etc.

foo = import('foo/*')
# Exposes everything

# Specifying which functions to import:
foo = import('foo/{bar,baz}', c('bar$b1', qux$q1'))
# Exposes `foo$bar$b1`, `foo$qux$q1` but NOT `foo$f1`, `foo$bar$b2` etc.
```

This is straightforward, but I feel vaguely that it?s too stringly
typed [4]. A colleague dislikes this proposal because it treats nested
modules and functions unequal: as mentioned above, `import('foo',
'f')` will import only `f` from `foo`. His argument is that there
should be a uniform way of specifying which nested modules or
functions to import ? somewhat analogously to Python?s mechanism,
where `from a import b` might import a submodule *or* an object `b`.

(2) Treat submodules and functions uniformly, one per argument:

```
foo = import('foo')
# Exposes `foo$f1`, `foo$f2` ?, but no submodules

bar = import('foo/bar')
# Exposes `bar$b1`, `bar$b2`

foo = import('foo/f1', 'foo/bar', 'foo/qux/q1')
# Exposes `foo$f1`, `foo$bar$b1`, `foo$bar$b2`, `foo$qux$q1`.
```

However, this has the disadvantage of cramming even more functionality
into the first argument and using stringly typing for everything
instead of using ?proper? function arguments.

(3) Drop the whole thing, force people to use a separate `import`
statement for every submodule (.NET does this for namespace imports,
but then, .NET?s namespaces don?t implement a module system):

```
foo = import('foo')
# Exposes `foo$f1`, `foo$f2` ?, but no submodules

bar = import('foo/bar')
# Exposes `bar$b1`, `bar$b2`

foo = import('foo', 'f1')
# Exposes `foo$f1`

bar = import('foo/bar')
# Exposes `bar$b1`, `bar$b2` ?
```

(4) Something else?

So this is my question: what do other people think? Which is the most
useful and least confusing alternative from the users? perspective?

[1]: https://github.com/klmr/modules
[2]: https://github.com/klmr/modules/blob/master/README.md#feature-comparison
[3] The original syntax for this was `import(foo)` and
`import(foo.bar)`, respectively, but Hadley convinced me to drop
non-standard argument evaluation. I?m still not convinced that NSE is
actually harmful here, but I?m likewise not convinced that it?s
beneficial (although I personally like it in this case).
[4]: http://c2.com/cgi/wiki?StringlyTyped

Kind regards,
Konrad


From maechler at stat.math.ethz.ch  Mon Apr 28 19:17:03 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Apr 2014 19:17:03 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <21340.7717.170377.354029@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
Message-ID: <21342.36111.527401.91467@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Sat, 26 Apr 2014 22:59:17 +0200 writes:

>>>>> Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Sat, 19 Apr 2014 13:06:15 -0400 writes:

    >> On Apr 19, 2014, at 9:00 AM, Martin Maechler
    >> <maechler at stat.math.ethz.ch> wrote:
    >>>>>>>> McGehee, Robert <Robert.McGehee at geodecapital.com>
    >>>>>>>> on Thu, 17 Apr 2014 19:15:47 -0400 writes:
    >>> 
    >>>>> This is all application specific and sort of beyond
    >>>>> the scope of type.convert(), which now behaves as it
    >>>>> has been documented to behave.
    >>> 
    >>>> That's only a true statement because the documentation
    >>>> was changed to reflect the new behavior! The new
    >>>> feature in type.convert certainly does not behave
    >>>> according to the documentation as of R 3.0.3. Here's a
    >>>> snippit:
    >>> 
    >>>> The first type that can accept all the non-missing
    >>>> values is chosen (numeric and complex return values
    >>>> will represented approximately, of course).
    >>> 
    >>>> The key phrase is in parentheses, which reminds the
    >>>> user to expect a possible loss of precision. That
    >>>> important parenthetical was removed from the
    >>>> documentation in R 3.1.0 (among other changes).
    >>> 
    >>>> Putting aside the fact that this introduces a large
    >>>> amount of unnecessary work rewriting SQL / data import
    >>>> code, SQL packages, my biggest conceptual problem is
    >>>> that I can no longer rely on a particular function call
    >>>> returning a particular class. In my example querying
    >>>> stock prices, about 5% of prices came back as factors
    >>>> and the remaining 95% as numeric, so we had random
    >>>> errors popping in throughout the morning.
    >>> 
    >>>> Here's a short example showing us how the new behavior
    >>>> can be unreliable. I pass a character representation of
    >>>> a uniformly distributed random variable to
    >>>> type.convert. 90% of the time it is converted to
    >>>> "numeric" and 10% it is a "factor" (in R 3.1.0). In the
    >>>> 10% of cases in which type.convert converts to a factor
    >>>> the leading non-zero digit is always a 9. So if you
    >>>> were expecting a numeric value, then 1 in 10 times you
    >>>> may have a bug in your code that didn't exist before.
    >>> 
    >>>>> options(digits=16) cl <- NULL; for (i in 1:10000)
    >>>>> cl[i] <- class(type.convert(format(runif(1))))
    >>>>> table(cl)
    >>>> cl factor numeric 990 9010
    >>> 
    >>> Yes.
    >>> 
    >>> Murray's point is valid, too.
    >>> 
    >>> But in my view, with the reasoning we have seen here,
    >>> *and* with the well known software design principle of
    >>> "least surprise" in mind, I also do think that the
    >>> default for type.convert() should be what it has been
    >>> for > 10 years now.
    >>> 

    >> I think there should be two separate discussions:

    >> a) have an option (argument to type.convert and possibly
    >> read.table) to enable/disable this behavior. I'm strongly
    >> in favor of this.

    > In my (not committed) version of R-devel, I now have

    >> str(type.convert(format(1/3, digits=17), exact=TRUE))
    >   Factor w/ 1 level "0.33333333333333331": 1
    >> str(type.convert(format(1/3, digits=17), exact=FALSE))
    >   num 0.333

    > where the 'exact' argument name has been ``imported'' from
    > the underlying C code.

    > [ As we CRAN package writers know by now, arguments
    > nowadays can hardly be abbreviated anymore, and so I am
    > not open to longer alternative argument names, as someone
    > liking blind typing, I'm not fond of camel case or other
    > keyboard gymnastics (;-) but if someone has a great idea
    > for a better argument name.... ]

    > Instead of only TRUE/FALSE, we could consider NA with
    > semantics "FALSE + warning" or also "TRUE + warning".


    >> b) decide what the default for a) will be. I have no
    >> strong opinion, I can see arguments in both directions

    > I think many have seen the good arguments in both
    > directions.  I'm still strongly advocating that we value
    > long term stability higher here, and revert to more
    > compatibility with the many years of previous versions.

    > If we'd use a default of 'exact=NA', I'd like it to mean
    > FALSE + warning, but would not oppose much to TRUE +
    > warning.

I have now committed svn rev 65507  --- to R-devel only for now ---
the above:   exact = NA  is the default
and it means  "warning + FALSE".

Interestingly, I currently get 5 identical warnings for one
simple call, so there seems clearly room for optimization, and
that is one main reason for this reason to not yet be migrated
to 'R 3.1.0 patched'.

Martin


    > I agree that for the TRUE case, it may make more sense to
    > return string-like object of a new (simple) class such as
    > "bignum" that was mentioned in this thread.

    > OTOH, this functionality should make it into an R 3.1.1 in
    > the not so distant future, and thinking through
    > consequences and implementing the new class approach may
    > just take a tad too much time...

    > Martin

    >> But most importantly I think a) is better than the status
    >> quo - even if the discussion about b) drags out.

    >> Cheers, Simon

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Tue Apr 29 09:32:21 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 29 Apr 2014 09:32:21 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <21342.36111.527401.91467@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>
Message-ID: <37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>


On 28 Apr 2014, at 19:17 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
[...snip...]

>>> I think there should be two separate discussions:
> 
>>> a) have an option (argument to type.convert and possibly
>>> read.table) to enable/disable this behavior. I'm strongly
>>> in favor of this.
> 
>> In my (not committed) version of R-devel, I now have
> 
>>> str(type.convert(format(1/3, digits=17), exact=TRUE))
>>  Factor w/ 1 level "0.33333333333333331": 1
>>> str(type.convert(format(1/3, digits=17), exact=FALSE))
>>  num 0.333
> 
>> where the 'exact' argument name has been ``imported'' from
>> the underlying C code.
> 
>> [ As we CRAN package writers know by now, arguments
>> nowadays can hardly be abbreviated anymore, and so I am
>> not open to longer alternative argument names, as someone
>> liking blind typing, I'm not fond of camel case or other
>> keyboard gymnastics (;-) but if someone has a great idea
>> for a better argument name.... ]
> 
>> Instead of only TRUE/FALSE, we could consider NA with
>> semantics "FALSE + warning" or also "TRUE + warning".
> 
> 
>>> b) decide what the default for a) will be. I have no
>>> strong opinion, I can see arguments in both directions
> 
>> I think many have seen the good arguments in both
>> directions.  I'm still strongly advocating that we value
>> long term stability higher here, and revert to more
>> compatibility with the many years of previous versions.
> 
>> If we'd use a default of 'exact=NA', I'd like it to mean
>> FALSE + warning, but would not oppose much to TRUE +
>> warning.
> 
> I have now committed svn rev 65507  --- to R-devel only for now ---
> the above:   exact = NA  is the default
> and it means  "warning + FALSE".
> 
> Interestingly, I currently get 5 identical warnings for one
> simple call, so there seems clearly room for optimization, and
> that is one main reason for this reason to not yet be migrated
> to 'R 3.1.0 patched'.

I actually think that the default should be the old behaviour. No warning, just potentially lose digits. If this gets a user in trouble, _then_ turn on the check for lost digits. 

After all, I think we had about one single use case, where lost digits caused trouble (I cannot even dig up what the case was - someone had, like, 20-digit ID labels, I reckon). In contrast, we have seen umpteen cases where people have exported floating point data to slightly beyond machine precision, "just in case", and relied on read.table() to do the sensible thing.

It's also an open question whether we really want to apply the same logic to doubles and integer inputs. The whole change went in as (r62327)

"force type.convert to read e.g. 64-bit integers as strings/factors"

I, for one, did not expect that "e.g." would include 0.12345678901234567. My eyes were on the upcoming 3.0.0 release at that point, so I might not have noticed it anyway, but apparently noone lifted an eyebrow. It seems that this was deliberately postponed for 3.1.0, but for more than a year, noone actually exercised the code. 

-pd

BTW, "exact" is a horrible name for an option, how about digitloss=c("allow", "warn", "forbid")?


> 
> Martin
> 
> 
>> I agree that for the TRUE case, it may make more sense to
>> return string-like object of a new (simple) class such as
>> "bignum" that was mentioned in this thread.
> 
>> OTOH, this functionality should make it into an R 3.1.1 in
>> the not so distant future, and thinking through
>> consequences and implementing the new class approach may
>> just take a tad too much time...
> 
>> Martin
> 
>>> But most importantly I think a) is better than the status
>>> quo - even if the discussion about b) drags out.
> 
>>> Cheers, Simon
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bt_jannis at yahoo.de  Tue Apr 29 09:34:31 2014
From: bt_jannis at yahoo.de (Jannis)
Date: Tue, 29 Apr 2014 09:34:31 +0200
Subject: [Rd] access environment in which an error occurred
Message-ID: <535F5607.1000601@yahoo.de>

Dear R developers,


i have already send the question below to r-help but got no responses. 
Perhaps it is more suitable for r-devel due to its rather technical 
level. It would really help me to find a solution (or to find out that 
there is none).


Is there any way to access/print/save the content of an environment in
which an error occoured?

Imagine the following testcase:


test =  function() {
    b =  3
    plot(notavailable)
}


dump.frames.mod = function() {
     save(list=ls(parent.frame(1)), file='dummy.RData')
}
options(error = quote({dump.frames.mod()}))

test()

The call to plot() inside test() here would create an error in which 
case I would like
to save the whole environment in which it occurred (in this case only
the object b) to some file for later debugging. In the way I tried to
implement it above, only the content of the global environment is saved
(probably because dump.frames.mod is called from this environment). Is
there any way to save the content of the environment down in the stack
where the error actually occurred?

I know about the dump.frames()
function which somehow does not work this case. I have implemented 
something like:

   dump.frames.mod = function(file.name, file.results)
     {
       file.name.error = 'dummy'
       cat(paste('\nSaving  workspace to file: \n', file.name.error, 
'.rda\n', sep=''))
       dump.frames(dumpto = file.name.error, to.file = TRUE)
       quit(save = 'no', status = 10)
     }
   options(error = quote({dump.frames.mod()}))

This, however, seems to hang my R session in case of an error. I do the 
whole thing to debug Code run remotely and non interactively on a 
cluster. In the logfiles produced I get the message that an error 
occurred (the result of cat(paste('\nSaving  workspace to file: \n', 
file.name.error, '.rda\n', sep=''))) but neither a file is created nor 
the R process is stopped. The cluster process just keeps on running with 
no indication that something actually happens. My impression is that 
this may be due to the huge size of the current R workspace as the 
dump.frames method above usually works smoothly when I run my code with 
much smaller test files.

So the first solution is basically a hack to avoid the dump.frames 
thing. A solution to any of the issues would be great.


Thanks
Jannis


From Mark.Bravington at csiro.au  Tue Apr 29 10:25:41 2014
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Tue, 29 Apr 2014 08:25:41 +0000
Subject: [Rd] type.convert and doubles
In-Reply-To: <37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>,
	<37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
Message-ID: <1D2694C7C3A6C04AA75E11C592A882E44F886CCC@exmbx05-cdc.nexus.csiro.au>

[...snip...]
Martin Maecher wrote:

> > I have now committed svn rev 65507  --- to R-devel only for now ---
> > the above:   exact = NA  is the default
> > and it means  "warning + FALSE".
> >
> > Interestingly, I currently get 5 identical warnings for one
> > simple call, so there seems clearly room for optimization, and
> > that is one main reason for this reason to not yet be migrated
> > to 'R 3.1.0 patched'.

Peter Dalgaard wrote:
> I actually think that the default should be the old behaviour. No warning, just potentially lose digits. If this gets a user in trouble, _then_ turn on the check for lost digits.

+1

IMO "read.table" and friends are convenience functions with somewhat of a "do what I mean" flavour, and as such their default should be to work conveniently for most cases. We typically ignore loss of precision in all sorts of numeric operations without warning. Those who do really care about that 21st digit in 'read.table' could always use 'colClasses'. With a 'digitloss' argument (but shouldn't it be column-specific? if not, is it really needed?) they can get what they need more easily, but the evidence seems to be that this is a rare case.

Mark Bravington
CSIRO
Hobart
Australia

From maechler at stat.math.ethz.ch  Tue Apr 29 10:41:19 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2014 10:41:19 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <1D2694C7C3A6C04AA75E11C592A882E44F886CCC@exmbx05-cdc.nexus.csiro.au>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>
	<37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
	<1D2694C7C3A6C04AA75E11C592A882E44F886CCC@exmbx05-cdc.nexus.csiro.au>
Message-ID: <21343.26031.613623.397191@stat.math.ethz.ch>

>>>>>   <Mark.Bravington at csiro.au>
>>>>>     on Tue, 29 Apr 2014 08:25:41 +0000 writes:

    > [...snip...]
    > Martin Maecher wrote:

    >> > I have now committed svn rev 65507  --- to R-devel only for now ---
    >> > the above:   exact = NA  is the default
    >> > and it means  "warning + FALSE".
    >> >
    >> > Interestingly, I currently get 5 identical warnings for one
    >> > simple call, so there seems clearly room for optimization,

BTW, the above was an implicit RFC and for code proposals by
really good C programmers...


    >> >  and that is one main reason for this reason to not yet be migrated
    >> > to 'R 3.1.0 patched'.

    > Peter Dalgaard wrote:
    >> I actually think that the default should be the old behaviour. No warning, just potentially lose digits. If this gets a user in trouble, _then_ turn on the check for lost digits.

    > +1

(yes please, people chime in ... once, you can also give "-1")

    > IMO "read.table" and friends are convenience functions with somewhat of a "do what I mean" flavour, and as such their default should be to work conveniently for most cases. We typically ignore loss of precision in all sorts of numeric operations without warning. Those who do really care about that 21st digit in 'read.table' could always use 'colClasses'. With a 'digitloss' argument (but shouldn't it be column-specific? if not, is it really needed?) 

Note that the current implementation of read.table() and friends
only use type.convert() at all when there are *no* colClasses at
all,  and I think we really should not change that principled
behavior !

>  they can get what they need more easily, but the evidence seems to be that this is a rare case.

    > Mark Bravington
    > CSIRO
    > Hobart
    > Australia


From maechler at stat.math.ethz.ch  Tue Apr 29 10:58:14 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2014 10:58:14 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>
	<37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
Message-ID: <21343.27046.363801.987001@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Tue, 29 Apr 2014 09:32:21 +0200 writes:

    > On 28 Apr 2014, at 19:17 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >> 
    > [...snip...]

    >>>> I think there should be two separate discussions:
    >> 
    >>>> a) have an option (argument to type.convert and possibly
    >>>> read.table) to enable/disable this behavior. I'm strongly
    >>>> in favor of this.
    >> 
    >>> In my (not committed) version of R-devel, I now have
    >> 
    >>>> str(type.convert(format(1/3, digits=17), exact=TRUE))
    >>> Factor w/ 1 level "0.33333333333333331": 1
    >>>> str(type.convert(format(1/3, digits=17), exact=FALSE))
    >>> num 0.333
    >> 
    >>> where the 'exact' argument name has been ``imported'' from
    >>> the underlying C code.
    >> 
    >>> [ As we CRAN package writers know by now, arguments
    >>> nowadays can hardly be abbreviated anymore, and so I am
    >>> not open to longer alternative argument names, as someone
    >>> liking blind typing, I'm not fond of camel case or other
    >>> keyboard gymnastics (;-) but if someone has a great idea
    >>> for a better argument name.... ]
    >> 
    >>> Instead of only TRUE/FALSE, we could consider NA with
    >>> semantics "FALSE + warning" or also "TRUE + warning".
    >> 
    >> 
    >>>> b) decide what the default for a) will be. I have no
    >>>> strong opinion, I can see arguments in both directions
    >> 
    >>> I think many have seen the good arguments in both
    >>> directions.  I'm still strongly advocating that we value
    >>> long term stability higher here, and revert to more
    >>> compatibility with the many years of previous versions.
    >> 
    >>> If we'd use a default of 'exact=NA', I'd like it to mean
    >>> FALSE + warning, but would not oppose much to TRUE +
    >>> warning.
    >> 
    >> I have now committed svn rev 65507  --- to R-devel only for now ---
    >> the above:   exact = NA  is the default
    >> and it means  "warning + FALSE".
    >> 
    >> Interestingly, I currently get 5 identical warnings for one
    >> simple call, so there seems clearly room for optimization, and
    >> that is one main reason for this reason to not yet be migrated
    >> to 'R 3.1.0 patched'.

    > I actually think that the default should be the old behaviour. No warning, just potentially lose digits. If this gets a user in trouble, _then_ turn on the check for lost digits. 

    > After all, I think we had about one single use case, where lost digits caused trouble (I cannot even dig up what the case was - someone had, like, 20-digit ID labels, I reckon). In contrast, we have seen umpteen cases where people have exported floating point data to slightly beyond machine precision, "just in case", and relied on read.table() to do the sensible thing.

    > It's also an open question whether we really want to apply the same logic to doubles and integer inputs. 

a really good point.  From my cursory code reading it would not
look so obvious where to make the distinction without quite a
bit of more coding, but I may just have overlooked a good idea.


    > The whole change went in as (r62327)

    > "force type.convert to read e.g. 64-bit integers as strings/factors"

    > I, for one, did not expect that "e.g." would include 0.12345678901234567. My eyes were on the upcoming 3.0.0 release at that point, so I might not have noticed it anyway, but apparently noone lifted an eyebrow. It seems that this was deliberately postponed for 3.1.0, but for more than a year, noone actually exercised the code. 

    > -pd

    > BTW, "exact" is a horrible name for an option, how about digitloss=c("allow", "warn", "forbid")?

I've also thought quickly about switching to an "enumeration
type" with string options.

If we would distinguish integer and non-integer input (and
hexadecimal vs decimal which are already different code branches),
we would need more than three options anyway ...
and when I start thinking about the possibilities, I start to
see too many "desirable" possibilities, e.g.,

 digitloss="allow for non-integers, don't warn"
 digitloss="allow for non-integers, do warn"
 digitloss="forbid, don't warn"
 digitloss="forbid, do  warn"

etc... which would speak for a different approach, maybe with
yet another argument for dealing with "long integer" only.

OTOH, I don't feel like spending even considerably more time on
this, now,  unless others are willing to also help (coding + testing).

Martin


From jttkim at googlemail.com  Tue Apr 29 12:45:46 2014
From: jttkim at googlemail.com (Jan Kim)
Date: Tue, 29 Apr 2014 11:45:46 +0100
Subject: [Rd] type.convert and doubles
In-Reply-To: <21343.26031.613623.397191@stat.math.ethz.ch>
References: <CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>
	<37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
	<1D2694C7C3A6C04AA75E11C592A882E44F886CCC@exmbx05-cdc.nexus.csiro.au>
	<21343.26031.613623.397191@stat.math.ethz.ch>
Message-ID: <20140429104545.GA24367@localhost>

On Tue, Apr 29, 2014 at 10:41:19AM +0200, Martin Maechler wrote:
> >>>>>   <Mark.Bravington at csiro.au>
> >>>>>     on Tue, 29 Apr 2014 08:25:41 +0000 writes:
> 
>     > [...snip...]
>     > Martin Maecher wrote:
> 
>     >> > I have now committed svn rev 65507  --- to R-devel only for now ---
>     >> > the above:   exact = NA  is the default
>     >> > and it means  "warning + FALSE".
>     >> >
>     >> > Interestingly, I currently get 5 identical warnings for one
>     >> > simple call, so there seems clearly room for optimization,
> 
> BTW, the above was an implicit RFC and for code proposals by
> really good C programmers...
> 
> 
>     >> >  and that is one main reason for this reason to not yet be migrated
>     >> > to 'R 3.1.0 patched'.
> 
>     > Peter Dalgaard wrote:
>     >> I actually think that the default should be the old behaviour. No warning, just potentially lose digits. If this gets a user in trouble, _then_ turn on the check for lost digits.
> 
>     > +1
> 
> (yes please, people chime in ... once, you can also give "-1")

+1 from me as well. Warning about loss of precision seems ok to me
as well, perhaps that could be phased in in the future.

Generally, I'd also suggest that conditions for implicit conversion
to the factor class should be progressively restricted, rather than
extended. This is because I've seen too many budding / not overly
type-aware R programmers running into trouble due to some variable
ending up containing a factor where they didn't anticipate that.
You can only hope they don't "figure out" to "fix this" by using
as.numeric in this case...

Best regards, Jan

>     > IMO "read.table" and friends are convenience functions with somewhat of a "do what I mean" flavour, and as such their default should be to work conveniently for most cases. We typically ignore loss of precision in all sorts of numeric operations without warning. Those who do really care about that 21st digit in 'read.table' could always use 'colClasses'. With a 'digitloss' argument (but shouldn't it be column-specific? if not, is it really needed?) 
> 
> Note that the current implementation of read.table() and friends
> only use type.convert() at all when there are *no* colClasses at
> all,  and I think we really should not change that principled
> behavior !
> 
> >  they can get what they need more easily, but the evidence seems to be that this is a rare case.
> 
>     > Mark Bravington
>     > CSIRO
>     > Hobart
>     > Australia
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From maechler at stat.math.ethz.ch  Tue Apr 29 12:01:06 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2014 12:01:06 +0200
Subject: [Rd] type.convert and doubles
In-Reply-To: <21343.26031.613623.397191@stat.math.ethz.ch>
References: <3736EC2D-7360-4AF6-BF96-5A2DF3D3EF14@warnes.net>
	<326FE12B-D6FE-471B-9E0C-10BEC0584DB7@r-project.org>
	<534860CC.2090206@gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CED9FD8C@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAECWziJq92keAD2sHHE7ky6CHhqatrBOONq_Vf18AHJ8GActZw@mail.gmail.com>
	<CAP01uRmdnTUgDH=sNryx9=w5Rtmw3b+8KiZOWPg48r6rc86ssQ@mail.gmail.com>
	<CAECWziKLBRjRNpneVJ2hNbTG3jF2ec6GeF9m+1S092WoufCdiQ@mail.gmail.com>
	<17B09E7789D3104E8F5EEB0582A8D66F0129CEDA0169@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<21330.29530.72292.435730@stat.math.ethz.ch>
	<A9466CB2-2B20-413D-986C-7EEC93CEC190@r-project.org>
	<21340.7717.170377.354029@stat.math.ethz.ch>
	<21342.36111.527401.91467@stat.math.ethz.ch>
	<37CEF3E8-01CA-474E-B794-4B6BCCAD0CBE@gmail.com>
	<1D2694C7C3A6C04AA75E11C592A882E44F886CCC@exmbx05-cdc.nexus.csiro.au>
	<21343.26031.613623.397191@stat.math.ethz.ch>
Message-ID: <21343.30818.729611.102016@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 29 Apr 2014 10:41:19 +0200 writes:

>>>>>   <Mark.Bravington at csiro.au>
>>>>>     on Tue, 29 Apr 2014 08:25:41 +0000 writes:

    >> [...snip...]
    >> Martin Maecher wrote:

    >>> > I have now committed svn rev 65507  --- to R-devel only for now ---
    >>> > the above:   exact = NA  is the default
    >>> > and it means  "warning + FALSE".
    >>> >
    >>> > Interestingly, I currently get 5 identical warnings for one
    >>> > simple call, so there seems clearly room for optimization,

    > BTW, the above was an implicit RFC and for code proposals by
    > really good C programmers...

Hmm... it actually was pretty simple --> back to *one* warning
after svn rev 65513

    >>> >  and that is one main reason for this reason to not yet be migrated
    >>> > to 'R 3.1.0 patched'.

[..........]


From avula.jayakrishna at gmail.com  Tue Apr 29 12:39:41 2014
From: avula.jayakrishna at gmail.com (JaiReddy)
Date: Tue, 29 Apr 2014 03:39:41 -0700 (PDT)
Subject: [Rd] C API for parse error
Message-ID: <1398767981512-4689662.post@n4.nabble.com>

May I know if we have any C api(or any other way) in retrieving the parse
error message after calling R_ParseVector?



--
View this message in context: http://r.789695.n4.nabble.com/C-API-for-parse-error-tp4689662.html
Sent from the R devel mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Tue Apr 29 15:11:20 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 29 Apr 2014 14:11:20 +0100
Subject: [Rd] RFC: API design of package "modules"
In-Reply-To: <e2a52d9c8e4d463daff108836143a191@EX-1-HT0.lancs.local>
References: <e2a52d9c8e4d463daff108836143a191@EX-1-HT0.lancs.local>
Message-ID: <CANVKczP-RgABZXSZPipSmS+cHwfefL7eVXnpJs_10E7Yp_Uxxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140429/73a74d40/attachment.pl>

From gmbecker at ucdavis.edu  Tue Apr 29 15:37:49 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 29 Apr 2014 06:37:49 -0700
Subject: [Rd] RFC: API design of package "modules"
In-Reply-To: <CANVKczP-RgABZXSZPipSmS+cHwfefL7eVXnpJs_10E7Yp_Uxxg@mail.gmail.com>
References: <e2a52d9c8e4d463daff108836143a191@EX-1-HT0.lancs.local>
	<CANVKczP-RgABZXSZPipSmS+cHwfefL7eVXnpJs_10E7Yp_Uxxg@mail.gmail.com>
Message-ID: <CADwqtCM8GybtWpBJDmHt3revk28Rgf83mMne5BbzYnT+QSTLdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140429/61d1ae56/attachment.pl>

From simon.urbanek at r-project.org  Tue Apr 29 17:09:23 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 29 Apr 2014 11:09:23 -0400
Subject: [Rd] C API for parse error
In-Reply-To: <1398767981512-4689662.post@n4.nabble.com>
References: <1398767981512-4689662.post@n4.nabble.com>
Message-ID: <7E779079-3D9D-4B04-BE0E-E8065F7C8656@r-project.org>

On Apr 29, 2014, at 6:39 AM, JaiReddy <avula.jayakrishna at gmail.com> wrote:

> May I know if we have any C api(or any other way) in retrieving the parse error message after calling R_ParseVector?
> 

R_ParseErrorMsg

But AFAICS it's not part of the API, so beware (although it's not hidden). By now I think it's safer to use try(parse(text=), silent=TRUE) which gives you the full error with details (the Msg is only one part). It could be worthwhile to think about exposing a C-level API to all the R_ParseError* pieces, though - but I'll leave that to the parser experts since only they know if this is now stable enough.

Cheers,
Simon


> 
> --
> View this message in context: http://r.789695.n4.nabble.com/C-API-for-parse-error-tp4689662.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From jeroenooms at gmail.com  Tue Apr 29 21:51:20 2014
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 29 Apr 2014 12:51:20 -0700
Subject: [Rd] RFC: API design of package "modules"
In-Reply-To: <CADwqtCM8GybtWpBJDmHt3revk28Rgf83mMne5BbzYnT+QSTLdQ@mail.gmail.com>
References: <e2a52d9c8e4d463daff108836143a191@EX-1-HT0.lancs.local>
	<CANVKczP-RgABZXSZPipSmS+cHwfefL7eVXnpJs_10E7Yp_Uxxg@mail.gmail.com>
	<CADwqtCM8GybtWpBJDmHt3revk28Rgf83mMne5BbzYnT+QSTLdQ@mail.gmail.com>
Message-ID: <CABFfbXuQ0En6pXPi9MBCnUDDEayc30OJnb-gRjkbkJfYJhCy7w@mail.gmail.com>

On Tue, Apr 29, 2014 at 6:37 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>
> pkg::fun() will call function fun from the namespace of package pkg
> *without loading it onto the search path*

It is important to use conventional terminology here. The package (and
its dependencies) gets loaded but not *attached*. The `library` and
`require` functions load and attach a package in a single step. You
can also manually attach and detach environments to/from the search
path using the `attach` and `detach` functions.


From gmbecker at ucdavis.edu  Tue Apr 29 22:07:27 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 29 Apr 2014 13:07:27 -0700
Subject: [Rd] RFC: API design of package "modules"
In-Reply-To: <CABFfbXuQ0En6pXPi9MBCnUDDEayc30OJnb-gRjkbkJfYJhCy7w@mail.gmail.com>
References: <e2a52d9c8e4d463daff108836143a191@EX-1-HT0.lancs.local>
	<CANVKczP-RgABZXSZPipSmS+cHwfefL7eVXnpJs_10E7Yp_Uxxg@mail.gmail.com>
	<CADwqtCM8GybtWpBJDmHt3revk28Rgf83mMne5BbzYnT+QSTLdQ@mail.gmail.com>
	<CABFfbXuQ0En6pXPi9MBCnUDDEayc30OJnb-gRjkbkJfYJhCy7w@mail.gmail.com>
Message-ID: <CADwqtCOAe3RDigqFTh48VSVvun9DXb0_iUYm_3wfq-HPD6zQDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140429/564044a3/attachment.pl>

From hb at biostat.ucsf.edu  Wed Apr 30 01:46:26 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 29 Apr 2014 16:46:26 -0700
Subject: [Rd] SUGGESTION: Option to have menu() and select.list() to use
 stderr (or even "prompt" output)
Message-ID: <CAFDcVCQ5vpVNdXhe4o7SKS1C9EBvHF4JhSwGi-B8PFUXXcF3zA@mail.gmail.com>

SEND TO STDERR:
Currently utils::menu() and utils::select.list() with graphics=FALSE
queries the user via the standard output (stdout).  I'd like to
suggest to do this via standard error (stderr) instead, or at least
have an option to choose which output stream.

If they would send to stderr, they could also be used in various
report generators that capture stdout and redirect to the generated
report.  As it is now, trying to use menu() and select.list() in such
frameworks will cause the menu options to appear in the report and not
be visible to the user in an interactive run.  This behavior affects
other querying functions such as setRepositories(graphics=FALSE) and
chooseCRANmirror(graphics=FALSE) so those cannot be used in report
generators either.  Before anyone argues that one shouldn't use
reports that prompts the user, there are several flavors of "report
generators/vignettes" that are natural to use also interactively.


SEND TO CONSOLE "PROMPT" OUTPUT:
Next, I've noticed that both the prompt of readline() and the
"Selection: " prompt of menu() are always displayed to the user, i.e.
they cannot be captured.  This is useful, because at least the
querying prompt can never be hidden from the user, which will always
see/understand that an input is needed.  Here is an example showing
this:

> zz <- file("all.Rout", open="wt"); sink(zz); sink(zz, type="message"); readline("Always here for you: "); sink(type="message"); sink()
Always here for you: ok
> cat(readLines("all.Rout"), sep="\n")
[1] "ok"
>

> zz <- file("all.Rout", open="wt"); sink(zz); sink(zz, type="message"); menu(letters[1:3], graphics=FALSE); sink(type="message"); sink()
Selection: 3
> cat(readLines("all.Rout"), sep="\n")

1: a
2: b
3: c

[1] 3
>

To me it looks like it would be even better if menu() and
select.list() would use this console "prompt" output for all its
output rather than stdout.  Second best is to use stderr.  I'm trying
to see when this is not wanted.  First, since readline(), menu() and
select.list() can only be used in interactive modes, I only assume
that the console prompt is always available so that should not be an
issue, or?  Second, it could be there are packages/software that rely
on being able to capture their output, but that would be solved by
having an argument output=c("stdout", "stderr", "prompt"), say.

Comments?

Henrik

PS. I've verified the above behavior with R 3.1.0 on Windows, OSX and Linux.


From aborgabor at gmail.com  Wed Apr 30 15:13:05 2014
From: aborgabor at gmail.com (Gabor Bakos)
Date: Wed, 30 Apr 2014 15:13:05 +0200
Subject: [Rd] arima.c bug?
Message-ID: <5360F6E1.5030508@gmail.com>

Hello,

   Reading the code I have found that in the line 653 (Pnew[i + r * j] =
tmp;) of http://svn.r-project.org/R/trunk/src/library/stats/src/arima.c
(latest as of now) the multiplier for j is r instead of rd (which is the
dimension of the matrix). Was it intentional? That seems at least worth
a comment why it is the case instead of Pnew[i + rd * j] = tmp;
Thanks and Kind Regards, gabor


From aborgabor at gmail.com  Wed Apr 30 16:09:03 2014
From: aborgabor at gmail.com (Gabor Bakos)
Date: Wed, 30 Apr 2014 16:09:03 +0200
Subject: [Rd] arima.c bug?
In-Reply-To: <5360F6E1.5030508@gmail.com>
References: <5360F6E1.5030508@gmail.com>
Message-ID: <536103FF.4020904@gmail.com>

On 2014. April 30. 15:13:05, Gabor Bakos wrote:
> Hello,
>
>    Reading the code I have found that in the line 653 (Pnew[i + r * j] =
> tmp;) of http://svn.r-project.org/R/trunk/src/library/stats/src/arima.c
> (latest as of now) the multiplier for j is r instead of rd (which is the
> dimension of the matrix). Was it intentional? That seems at least worth
> a comment why it is the case instead of Pnew[i + rd * j] = tmp;
> Thanks and Kind Regards, gabor
Sorry, I missed the if (d == 0) condition for that block. In that case 
rd == d, so this do not cause bugs, just a bit confusion for a short 
time. :)
Thanks, gabor



From mike1947 at gmail.com  Wed Apr 30 15:44:10 2014
From: mike1947 at gmail.com (Michael Cohen)
Date: Wed, 30 Apr 2014 09:44:10 -0400
Subject: [Rd] ReplayPlot, limited to single session for RecordPlot()
Message-ID: <CAD8yWB9JjHBYS2OWC4yaStNr=O6FRFh65X0wFuHjf28FZ1SoQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140430/b202523d/attachment.pl>

From kamal.fartiyal84 at gmail.com  Wed Apr 30 18:11:53 2014
From: kamal.fartiyal84 at gmail.com (Kamal)
Date: Wed, 30 Apr 2014 18:11:53 +0200
Subject: [Rd] Problem with Renaming R object
Message-ID: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140430/c6d1de1c/attachment.pl>

From therneau at mayo.edu  Wed Apr 30 19:00:33 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 30 Apr 2014 12:00:33 -0500
Subject: [Rd] Quantile issue
Message-ID: <3dfcdc$gjrdrk@ironport9.mayo.edu>

This is likely yet another instance of round off error, but it caught me by surprise.

tmt% R --vanilla
  (headers skipped, version 3.0.2 on Linux)

> load('qtest.rda')
> length(temp)
[1] 3622
> max(temp) >= quantile(temp, .98)
   98%
FALSE

I can send the file to anyone who would like to understand this more deeply.
The top 3% of the vector is a single repeated value.

Terry Therneau


From h.wickham at gmail.com  Wed Apr 30 19:23:30 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 30 Apr 2014 12:23:30 -0500
Subject: [Rd] Problem with Renaming R object
In-Reply-To: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>
References: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>
Message-ID: <CABdHhvGd+fE=KVEPw94_mmg=xXENyhzs4qSBnK6qZ4uFj5m1Gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140430/68f18342/attachment.pl>

From kasperdanielhansen at gmail.com  Wed Apr 30 19:26:03 2014
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 30 Apr 2014 13:26:03 -0400
Subject: [Rd] Problem with Renaming R object
In-Reply-To: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>
References: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>
Message-ID: <CAC2h7ut4GCYkMGumbKVT+kwnj3xR0jCszDp+RnZD5seYjwBtcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140430/13089060/attachment.pl>

From kamal.fartiyal84 at gmail.com  Wed Apr 30 19:29:29 2014
From: kamal.fartiyal84 at gmail.com (Kamal)
Date: Wed, 30 Apr 2014 19:29:29 +0200
Subject: [Rd] Problem with Renaming R object
In-Reply-To: <CAC2h7ut4GCYkMGumbKVT+kwnj3xR0jCszDp+RnZD5seYjwBtcg@mail.gmail.com>
References: <CACof4rqe62Ym04Bfgx8g0acrBU3-j0YpNxrLEi=Lmb1ZT551Lg@mail.gmail.com>
	<CAC2h7ut4GCYkMGumbKVT+kwnj3xR0jCszDp+RnZD5seYjwBtcg@mail.gmail.com>
Message-ID: <CACof4rrc8v8GBRMuJmqxC6+hQ6HftPd1QcPdMPgGReG1H8Zsew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140430/83d63461/attachment.pl>

From fisher at plessthan.com  Wed Apr 30 21:03:34 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Wed, 30 Apr 2014 12:03:34 -0700
Subject: [Rd] "Name partially matched in data frame"
Message-ID: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>

R 3.1.0
OS X

Colleagues,

I recently updated to 3.1.0 and I have encountered 
	Warning messages: ...  Name partially matched in data frame
when I do something like:
	DATAFRAME$colname
where colname is actually something longer than that (but unambiguous).  

I have much appreciated the partial matching capabilities because it fits with my workflow.  I often receive updated data months after the initial code is written.  In order to keep track of what I did in the past, I provide lengthy (unambiguous) names for columns, then abbreviate the names as I call them.  This behavior has been termed ?lazy? in various correspondence on this mailing list but it works for me and probably works for others.

I realize that the new message is only a warning but it is a minor nuisance.  Would it be possible to add an
	option(partialMatch=TRUE)	## default is FALSE
or something similar to suppress that behavior?  That should keep both camps happy.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From murdoch.duncan at gmail.com  Wed Apr 30 21:32:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 30 Apr 2014 15:32:16 -0400
Subject: [Rd] "Name partially matched in data frame"
In-Reply-To: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>
References: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>
Message-ID: <53614FC0.30408@gmail.com>

On 30/04/2014 3:03 PM, Fisher Dennis wrote:
> R 3.1.0
> OS X
>
> Colleagues,
>
> I recently updated to 3.1.0 and I have encountered
> 	Warning messages: ...  Name partially matched in data frame
> when I do something like:
> 	DATAFRAME$colname
> where colname is actually something longer than that (but unambiguous).
>
> I have much appreciated the partial matching capabilities because it fits with my workflow.  I often receive updated data months after the initial code is written.  In order to keep track of what I did in the past, I provide lengthy (unambiguous) names for columns, then abbreviate the names as I call them.  This behavior has been termed ?lazy? in various correspondence on this mailing list but it works for me and probably works for others.
>
> I realize that the new message is only a warning but it is a minor nuisance.  Would it be possible to add an
> 	option(partialMatch=TRUE)	## default is FALSE
> or something similar to suppress that behavior?  That should keep both camps happy.

I'd be much happier with a general mechanism to suppress particular 
warnings.  Then you could choose to suppress this one.

We might be able to do that with options("warning.expression"), but I 
don't see how...

Duncan Murdohc


From skostysh at princeton.edu  Wed Apr 30 21:33:54 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 30 Apr 2014 15:33:54 -0400
Subject: [Rd] "Name partially matched in data frame"
In-Reply-To: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>
References: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>
Message-ID: <CAE3=dmcbsbKMa87GVzZ3Gykdo-Cf_f4wHb=SOdmyqr0tL8uxcg@mail.gmail.com>

Hi Dennis,

On Wed, Apr 30, 2014 at 3:03 PM, Fisher Dennis <fisher at plessthan.com> wrote:
> R 3.1.0
> OS X
>
> Colleagues,
>
> I recently updated to 3.1.0 and I have encountered
>         Warning messages: ...  Name partially matched in data frame
> when I do something like:
>         DATAFRAME$colname
> where colname is actually something longer than that (but unambiguous).
>
> I have much appreciated the partial matching capabilities because it fits with my workflow.  I often receive updated data months after the initial code is written.  In order to keep track of what I did in the past, I provide lengthy (unambiguous) names for columns, then abbreviate the names as I call them.  This behavior has been termed ?lazy? in various correspondence on this mailing list but it works for me and probably works for others.

Why not store that information elsewhere? e.g. in an attribute?

> I realize that the new message is only a warning but it is a minor nuisance.  Would it be possible to add an
>         option(partialMatch=TRUE)       ## default is FALSE
> or something similar to suppress that behavior?  That should keep both camps happy.

There is currently no option to control that behavior and (although I
do understand your use case) I personally hope one is not implemented.
The reason is that you might put that option in your .Rprofile and
when you share your code with me I get errors that columns aren't
found.

You can of course redefine the `$`:

> dataf <- data.frame(longColumn = 5)
> dataf$long
[1] 5
Warning message:
In `$.data.frame`(dataf, long) : Name partially matched in data frame
>
> `$.data.frame` <-
+ function (x, name)
+ {
+     a <- x[[name]]
+     if (!is.null(a))
+         return(a)
+     a <- x[[name, exact = FALSE]]
+     return(a)
+ }
>
> dataf$long
[1] 5
>

I hope you don't do that though.

Another option is to use the more verbose dataf[["long", exact = FALSE]].

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From skostysh at princeton.edu  Wed Apr 30 21:36:02 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 30 Apr 2014 15:36:02 -0400
Subject: [Rd] "Name partially matched in data frame"
In-Reply-To: <CAE3=dmcbsbKMa87GVzZ3Gykdo-Cf_f4wHb=SOdmyqr0tL8uxcg@mail.gmail.com>
References: <3781BDEC-E7D2-482A-A7A7-63B61B021754@plessthan.com>
	<CAE3=dmcbsbKMa87GVzZ3Gykdo-Cf_f4wHb=SOdmyqr0tL8uxcg@mail.gmail.com>
Message-ID: <CAE3=dmfrtEKmbiM0DSZ2zx2oVRHRYeAHZt8F1YLHjp5oF73U8w@mail.gmail.com>

On Wed, Apr 30, 2014 at 3:33 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> Hi Dennis,
>
> On Wed, Apr 30, 2014 at 3:03 PM, Fisher Dennis <fisher at plessthan.com> wrote:
>> R 3.1.0
>> OS X
>>
>> Colleagues,
>>
>> I recently updated to 3.1.0 and I have encountered
>>         Warning messages: ...  Name partially matched in data frame
>> when I do something like:
>>         DATAFRAME$colname
>> where colname is actually something longer than that (but unambiguous).
>>
>> I have much appreciated the partial matching capabilities because it fits with my workflow.  I often receive updated data months after the initial code is written.  In order to keep track of what I did in the past, I provide lengthy (unambiguous) names for columns, then abbreviate the names as I call them.  This behavior has been termed ?lazy? in various correspondence on this mailing list but it works for me and probably works for others.
>
> Why not store that information elsewhere? e.g. in an attribute?
>
>> I realize that the new message is only a warning but it is a minor nuisance.  Would it be possible to add an
>>         option(partialMatch=TRUE)       ## default is FALSE
>> or something similar to suppress that behavior?  That should keep both camps happy.
>
> There is currently no option to control that behavior and (although I
> do understand your use case) I personally hope one is not implemented.
> The reason is that you might put that option in your .Rprofile and
> when you share your code with me I get errors that columns aren't
> found.

Let me change this to "I would get warnings, which would make me worried."

> You can of course redefine the `$`:
>
>> dataf <- data.frame(longColumn = 5)
>> dataf$long
> [1] 5
> Warning message:
> In `$.data.frame`(dataf, long) : Name partially matched in data frame
>>
>> `$.data.frame` <-
> + function (x, name)
> + {
> +     a <- x[[name]]
> +     if (!is.null(a))
> +         return(a)
> +     a <- x[[name, exact = FALSE]]
> +     return(a)
> + }
>>
>> dataf$long
> [1] 5
>>
>
> I hope you don't do that though.
>
> Another option is to use the more verbose dataf[["long", exact = FALSE]].
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


