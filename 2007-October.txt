From googel.vs.privacy at googlemail.com  Mon Oct  1 14:11:24 2007
From: googel.vs.privacy at googlemail.com (idontwant googeltospyafterme)
Date: Mon, 1 Oct 2007 14:11:24 +0200
Subject: [Rd] R-Server remotecontrolled via browser-GUI
Message-ID: <e0a4be450710010511q6ecde96aic3af0111a32395ce@mail.gmail.com>

hi jeff,
i have read your paper from 2005 and your rapache solution sounds
good. i was wondering if u did sth about the state problem... you
should put a changelog on your website. what changes will come with
1.0?
and what is brew exactly for? it is like a tuned "cat", mixing
r-output and text, right?
so if i build a gui, brew could generate the html. but i dont'have to
use brew, do i? what are the advantages of using brew with rapache?

what do you think of openstatserver btw?

i think there are lots of interesting and promising approaches around
in R-community.
but as with all OSS, same here. many people working on slightly
different solutions for the same problem. and none of the solutions is
feature complete, some are not even actively developed and only a few
are to be seen as stable or beyond beta stadium.
well, i work almost only with OSS, so i got used to it :-)
it's just difficult to navigate thru the possibilities without
spending too much time on recherche.

have a nice day,

Josuah


From elff at sowi.uni-mannheim.de  Mon Oct  1 17:24:18 2007
From: elff at sowi.uni-mannheim.de (Martin Elff)
Date: Mon, 1 Oct 2007 17:24:18 +0200
Subject: [Rd] Aggregate factor names
In-Reply-To: <375E8B77-0436-472C-9F85-C56B46DFFEE9@DAL.CA>
References: <375E8B77-0436-472C-9F85-C56B46DFFEE9@DAL.CA>
Message-ID: <200710011724.18691.elff@sowi.uni-mannheim.de>

On Thursday 27 September 2007 (17:57:55), Mike Lawrence wrote:
> ex. it is annoying to type
>
> with(
> ????????my.data
> ????????,aggregate(
> ????????????????my.dv
> ????????????????,list(
> ????????????????????????one.iv = one.iv
> ????????????????????????,another.iv = another.iv
> ????????????????????????,yet.another.iv = yet.another.iv
> ????????????????)
> ????????????????,some.function
> ????????)
> )

If you use my package 'memisc' you can write

aggregate(some.function(my.dv)~one.iv+another.iv+yet.another.iv,
		data=my.data)

Best,
Martin

-- 
"Dealing with failure is easy: work hard to improve.  Success is also
easy to handle: you've solved the wrong problem.  Work hard to
improve."
  fortune 1.0

-------------------------------------------------
Dr. Martin Elff
Dept. of Social Sciences
University of Mannheim
Block A5, Room A 328 (NEW)
68131 Mannheim
Germany

Phone: +49-621-181-2093
Fax: +49-621-181-2099
E-Mail: elff at sowi.uni-mannheim.de
Web: http://webrum.uni-mannheim.de/sowi/elff/
     http://www.sowi.uni-mannheim.de/lspwivs/
-------------------------------------------------


From hin-tak.leung at cimr.cam.ac.uk  Mon Oct  1 20:30:26 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 01 Oct 2007 19:30:26 +0100
Subject: [Rd] R "capabilities" on a cluster node
In-Reply-To: <fdh1od$sor$1@sea.gmane.org>
References: <fdh1od$sor$1@sea.gmane.org>
Message-ID: <47013CC2.4090904@cimr.cam.ac.uk>

The double '//' is harmless. What you are failing at is that your 
R-build-host has the system X11 runtime libraries (libSM.so.6 and
friends) while your execution hosts don't have them, and R_X11.so 
depends on the system X11 libraries which R cannot find on the execution 
hosts.

So - ask your grid engine administrator to install the X11 runtime
libraries on the grid nodes, or ask him/her to build a special version 
of R which doesn't depend on X11. (the former is the recommended 
approach, but your admins may think the latter suit their policies).

Yes, pdf/ps are always available. (they are just save-to-file devices 
using R's own pdf/ps writing code).

The png/jpeg situation are similar to but separate from X11. On the R
build host, you need both the development headers (libpng-devel,
libjpeg-devel, libX11-devel & other libX*-devel packages for redhat
systems) as well as the runtime libraries (libpng, libjpeg, libX*) to 
build R with each of the support for these 3. On the execution hosts,
you need just the runtime libraries.

The reason why you are missing jpeg/png is probably because your build 
host doesn't have the headers. (it is relatively rare not to have
jpeg/png runtime, but the headers are normally not installed).

We (used to?) have a similiar situation on our sun grid - my desktop R 
can do png but our cluster grid R cannot. (ghostscript and a few other 
software can convert ps/pdf to png so it is not a big loss, just a minor
inconvenience).

Earl F. Glynn wrote:
> R version 2.5.1 (2007-06-27)
> 
> I' running some simple R jobs via the  Sun Grid Engine on our Linux cluster 
> in preparation for some bigger ones.
> 
> I checked R's capabilities on the cluster nodes (after failing to create a 
> png file) and am getting the following warning message:
> [Run on a cluster node using qrsh:]
> 
> 
> 
>> capabilities()
> 
>     jpeg      png    tcltk      X11 http/ftp  sockets   libxml     fifo
> 
>    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE     TRUE
> 
>   cledit    iconv      NLS  profmem
> 
>     TRUE     TRUE     TRUE    FALSE
> 
> Warning message:
> 
> unable to load shared library 
> '/n/site/inst/Linux-i686/bioinfo/R/2.5.1/lib/R/modules//R_X11.so':
> 
>   libSM.so.6: cannot open shared object file: No such file or directory in: 
> capabilities()
> 
> 
> 
> 
> 
> Is the double slash (//) in the path above a bug in how we've configured R 
> here (the /n/site/inst/ directory is shared but is platform specific), or a 
> bug in how the capabilities command works?  The file does exist if the 
> double slash in the path had not caused the warning above.
> 
> 
> 
> 
> 
> 
> How can one programmatically get the info from ?Devices, which appears to be 
> dynamic based on one's system?  Is it safe to assume that pdf's or 
> postscript files are always available in R since they're not listed in 
> capabilities and seem to be shown everywhere under ?Devices ?
> 
> 
> 
> 
> 
> Part of the ?Devices output on a cluster node says this:
> 
> 
> 
>    The following devices will be available if R was compiled to use
> 
>      them:
> 
> 
> 
>         *  'X11' The graphics driver for the X11 Window system
> 
> 
> 
>         *  'png' PNG bitmap device
> 
> 
> 
>         *  'jpeg' JPEG bitmap device
> 
> 
> 
> We can just recompile to get png or jpeg support?  Are X11 libraries used on 
> cluster nodes while running "headless"?  Can I create pngs or jpegs without 
> X11?
> 
> 
> 
> Thanks for any advice about this.
> 
> 
> 
> efg
> 
> 
> 
> Earl F. Glynn
> 
> Scientific Programmer
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Tue Oct  2 04:28:29 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Mon,  1 Oct 2007 19:28:29 -0700
Subject: [Rd] pairlist objects
Message-ID: <1191292109.4701accd24217@webmail.fhcrc.org>

Hi,

?pairlist gives no explanation about what exactly is the difference
between a pairlist and a list (except that a pairlist of length 0
is 'NULL'). So, what's a pairlist?

class(.Options)
[1] "pairlist"

Some strange things about the "pairlist" type:

  > showClass("pairlist")
  Error in getClass(Class) : "pairlist" is not a defined class

Why the above doesn't work? It works for "list":

  > showClass("list")

  No Slots, prototype of class "list"

  Extends: "vector"

  > is.list(.Options)
  [1] TRUE

  > is.vector(.Options)
  [1] FALSE

This doesn't make sense! If 'x' is a list, then it should be considered
a vector too.

Subsetting a pairlist with [] doesn't produce a pairlist: 

  > class(.Options[1:3])
  [1] "list"

Yes, this one is documented, but still...


Cheers,
H.


From bolker at ufl.edu  Mon Oct  1 17:28:51 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 1 Oct 2007 08:28:51 -0700 (PDT)
Subject: [Rd] to overcome error while computing sd for each subset of
 data (PR#9931)
In-Reply-To: <20070927112241.7F054667F6@slim.kubism.ku.dk>
References: <20070927112241.7F054667F6@slim.kubism.ku.dk>
Message-ID: <12981381.post@talk.nabble.com>




anjalishitole wrote:
> 
> Full_Name: Anjali Shitole
> Version: R 2.5.1
> OS: 
> Submission from: (NULL) (202.141.157.91)
> 
>   [snip]
> 
> Please help me to overcome this error.
> 
> 

  Dear Mr. Shitole,

 * this problem is not a bug, please don't post it as such
 * this problem is inappropriate for the r-devel list, which is for
technical questions
and discussion about the workings of R, not for questions about specific
analyses
 * please read the posting guide (URL listed in every message posted),
provide
a reproducible example, and resubmit your question to r-help
 * hint: the third argument to aggregate needs to be a function, further
optional
arguments can be specified.  sd(x) is not a function.  sd is.

 sincerely
    Ben Bolker

-- 
View this message in context: http://www.nabble.com/to-overcome-error-while-computing-sd-for-each-subset-of-data-%28PR-9931%29-tf4532694.html#a12981381
Sent from the R devel mailing list archive at Nabble.com.


From lawremi at iastate.edu  Tue Oct  2 16:34:07 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Tue, 2 Oct 2007 09:34:07 -0500
Subject: [Rd] patch: allow R CMD build exclude patterns to match symlinks
Message-ID: <509e0620710020734h5125e19cud6cebfa97fcaecdc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071002/49b08694/attachment.pl 

From hin-tak.leung at cimr.cam.ac.uk  Tue Oct  2 18:32:18 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 02 Oct 2007 17:32:18 +0100
Subject: [Rd] pairlist objects
In-Reply-To: <1191292109.4701accd24217@webmail.fhcrc.org>
References: <1191292109.4701accd24217@webmail.fhcrc.org>
Message-ID: <47027292.6010808@cimr.cam.ac.uk>

?list has a little bit of information. As far as I know, historically,
the more inefficient one (pairlist()) came first, where R inherits its
structure and implementation from LISP ; list() came later as a new 
implementation of a list-like object which is more efficient and faster
in various manner (e.g. addressing the (n)th elements in the middle,
and overall storage size). So these days most list-like stuff within R
is done as list()'s rather than pairlist()'s.

Internally, a pairlist() in R is implemented as a recursive binary
tree (LISTSXP), where one branch of the first node consists of the
first elements, its
attributes, and the other branch consists of a daughter node which
consists of the 2nd element as its one branch, etc. Walking such a tree
is slow and its storage requirement is a bit larger than list().

Internally, a list() in R is a VECSXP, which is a one-dimensional 
structure, plus some attributes storing the names of the elements, etc.
It is a bit more efficient in terms of storage (a 1-D structure vs a 
recursive binary tree), and also in random addressing of its elements -
e.g. you can jump to the (n)th element without walking the 1st to the 
(n-1)th elements.

This is my understanding, no doubt the R core team has more and better 
way to say about this.

a list() is not of class vector (despite the implementation in C being a 
VECSXP) - a vector in R is a 1-D structure where all the elements are of 
the same type/mode, which a list() is not.

hpages at fhcrc.org wrote:
> Hi,
> 
> ?pairlist gives no explanation about what exactly is the difference
> between a pairlist and a list (except that a pairlist of length 0
> is 'NULL'). So, what's a pairlist?
> 
> class(.Options)
> [1] "pairlist"
> 
> Some strange things about the "pairlist" type:
> 
>   > showClass("pairlist")
>   Error in getClass(Class) : "pairlist" is not a defined class
> 
> Why the above doesn't work? It works for "list":
> 
>   > showClass("list")
> 
>   No Slots, prototype of class "list"
> 
>   Extends: "vector"
> 
>   > is.list(.Options)
>   [1] TRUE
> 
>   > is.vector(.Options)
>   [1] FALSE
> 
> This doesn't make sense! If 'x' is a list, then it should be considered
> a vector too.
> 
> Subsetting a pairlist with [] doesn't produce a pairlist: 
> 
>   > class(.Options[1:3])
>   [1] "list"
> 
> Yes, this one is documented, but still...
> 
> 
> Cheers,
> H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Tue Oct  2 19:55:00 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 2 Oct 2007 13:55:00 -0400
Subject: [Rd] pairlist objects
In-Reply-To: <1191292109.4701accd24217@webmail.fhcrc.org>
References: <1191292109.4701accd24217@webmail.fhcrc.org>
Message-ID: <AAFE4514-2403-4B51-8E49-782DCA6FF77B@r-project.org>


On Oct 1, 2007, at 10:28 PM, hpages at fhcrc.org wrote:

> ?pairlist gives no explanation about what exactly is the difference  
> between a pairlist and a list (except that a pairlist of length 0  
> is 'NULL'). So, what's a pairlist?
>

I read "traditional _dotted pair_ lists (as in LISP)" there - c.f. also
http://cran.r-project.org/doc/manuals/R-lang.html#Pairlist-objects



> class(.Options)
> [1] "pairlist"
>
> Some strange things about the "pairlist" type:
>
>> showClass("pairlist")
>   Error in getClass(Class) : "pairlist" is not a defined class
>
> Why the above doesn't work?

Because "pairlist" is not a formal class. Why should it?


> It works for "list":
>
>> showClass("list")
>
>   No Slots, prototype of class "list"
>
>   Extends: "vector"
>
>> is.list(.Options)
>   [1] TRUE
>
>> is.vector(.Options)
>   [1] FALSE
>
> This doesn't make sense! If 'x' is a list, then it should be  
> considered a vector too.
>

Why? They are completely different objects. lists are generic  
vectors, pairlists are not vectors (c.f. the docs above).


> Subsetting a pairlist with [] doesn't produce a pairlist:
>
>> class(.Options[1:3])
>   [1] "list"
>
> Yes, this one is documented, but still...
>

As the docs say, on R level pairlists are usually converted to  
vectors as the use of pairlists is deprecated.

Cheers,
Simon


From steve.kembel at gmail.com  Wed Oct  3 23:29:53 2007
From: steve.kembel at gmail.com (Steve Kembel)
Date: Wed, 3 Oct 2007 14:29:53 -0700
Subject: [Rd] Call for participation: Comparative Methods in R Hackathon
Message-ID: <EC843DB3-9CBF-4001-B336-DB8BAA7B3D98@gmail.com>

             NESCent Hackathon on Comparative Methods in R

                   Call for Participation and Input

The R statistical analysis package has emerged as a popular platform
for implementation of powerful comparative phylogenetic methods to
understand the evolution of organismal traits. The National
Evolutionary Synthesis Center (NESCent) is organizing a hackathon
focused on the integration of comparative phylogenetic methods within
R. The event will take place on Dec 10-14, 2007, at NESCent in Durham,
North Carolina.  We are broadly soliciting applications for
participation as well as comments and suggestions from the
community. More information about the event is available at
http://hackathon.nescent.org/R_Hackathon_1.

A hackathon is an event at which a group of programmers who otherwise
do not have the opportunity to interact on a routine basis meet to
collaboratively develop working code that is of utility to the
community as a whole. This event will bring together different groups
of developers and users of comparative methods to work towards a
common set of objectives centering on common challenges of data
exchange, interoperability, and usability.

CALL FOR INPUT
We are soliciting input from the community at large regarding the
priorities and objectives of the hackathon.  If you are a user of
comparative phylogenetic software and have any ideas that you would
like the community of developers to be aware of, please submit your
input directly through the hackathon wiki
(http://hackathon.nescent.org; click on 'Forum') or by email to
hackathon2 at nescent.org.

CALL FOR PARTICIPATION
We invite all individuals interested in attending to respond by email
to the questions below. We are specifically encouraging applications
from:
* Members of underrepresented groups, specifically women and members
   of minorities.
* Those with skills and interests in documentation or visualization,
   as both are currently underrepresented among the initial set of
   attendees
* Biologists familiar with comparative phylogenetic methods who are
   interested in working face-to-face with developers to help
   prioritize needs, document and test the code being developed,
   provide feedback regarding usability, and ensure the community value
   of the code being written at the event.
* Graduate students and postdocs.

Please read the detailed description on the website
(http://hackathon.nescent.org/R_Hackathon_1) prior to applying. Email
your responses and, if possible, a CV to hackathon2 at nescent.org by
October 14.

1. Please indicate if you would be available for all or only for part
    of the Dec 10-14 time period.

2. All code produced at the event is to be made available immediately
    under an OSI-approved open-source license (specifically, the GPL
    for any code in R). Please indicate whether this would pose any
    difficulty for your participation.

3. Briefly describe your qualifications (e.g. your familiarity with
    comparative phylogenetic methods and/or R programming).

4. Please state what you would most like to accomplish at the
    hackathon.  If you would not be writing software at the event,
    please state how you would like to contribute and how you would
    expect to benefit.

5. Please indicate if you are a member of an underrepresented group
    (including women, persons with disabilities, and any of the
    following minorities: African American, Hispanic, American Indian,
    Alaska Native, Native Hawaiian, and Pacific Islander).

Please be aware that the funds, as well as the space, for this event
are limited, and the organizers need to balance the skills of the
attendees, so not all qualified applicants can be guaranteed
acceptance.

The Organizing Committee
 From NESCent: Hilmar Lapp, Brian O'Meara, Samantha Price, Todd  
Vision, Amy Zanne
 From UC Berkeley: Steven Kembel


From edd at debian.org  Thu Oct  4 03:55:54 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 3 Oct 2007 20:55:54 -0500
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
Message-ID: <18180.18474.131705.985610@ron.nulle.part>


Many thanks to Dr Yu for updating Rmpi for R 2.6.0, and for starting to make
the changes to support Open MPI.

I have just built the updated Debian package of Rmpi (i.e. r-cran-rmpi) under
R 2.6.0 but I cannot convince myself yet whether it works or not.  Simple
tests work.  E.g. on my Debian testing box, with Rmpi installed directly
using Open Mpi 1.2.3-2 (from Debian) and using 'r' from littler:

edd at ron:~> orterun -np 3 r -e 'library(Rmpi); print(mpi.comm.rank(0))'
[1] 0
[1] 1
[1] 2
edd at ron:~>  

but I basically cannot get anything more complicated to work yet.  R / Rmpi
just seem to hang, in particular snow and and getMPIcluster() just sit there:

> cl <- makeSOCKcluster(c("localhost", "localhost"))
> stopCluster(cl)
> library(Rmpi)
> cl <- makeMPIcluster(n=3)
Error in makeMPIcluster(n = 3) : no nodes available.
>                                                            

I may be overlooking something simple here, in particular the launching of
apps appears to be different for Open MPI than it was with LAM/MPI (or maybe
I am just confused because I also look at LLNL's slurm for use with Open MPI ?)

Has anybody gotten Open MPI and Rmpi to work on simple demos?  Similarly, is
anybody using snow with Rmpi and Open MPI yet?

Also, the Open MPI FAQ is pretty clear on their preference for using mpicc
for compiling/linking to keep control of the compiler and linker options and
switches.  Note that e.g. on my Debian system

edd at ron:~> mpicc --showme:link
-pthread -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl -lutil -lm -ldl

whereas Rmpi built with just the default from R CMD:

gcc-4.2 -std=gnu99 -shared  -o Rmpi.so RegQuery.o Rmpi.o conversion.o internal.o -L/usr/lib -lmpi -lpthread -fPIC   -L/usr/lib/R/lib -lR

Don't we need libopen-rte and libopen-pal as the MPI FAQ suggests?

Many thanks, Dirk

-- 
Three out of two people have difficulties with fractions.


From ecjbosu at aol.com  Thu Oct  4 04:25:41 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Wed, 03 Oct 2007 21:25:41 -0500
Subject: [Rd] Rexcelpoi
Message-ID: <fe1ivr$m9a$1@sea.gmane.org>

I was experimenting with Rexcelpoi from Armstrong Whit.  I was able to 
compile the package in my Redhat linux machine with a few warnings but 
no errors.  I was not able to get the package built on my windows xp 
computer, but that is for another post.

I load R on the linux computer and type in the library call to Rexcelpoi 
the receive the following error.

library(Rexcelpoi)

  *** caught segfault ***
address (nil), cause 'memory not mapped'

Traceback:
  1: dyn.load(file, ...)
  2: library.dynam(lib, package, package.lib)
  3: loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = 
keep.source)
  4: doTryCatch(return(expr), name, parentenv, handler)
  5: tryCatchOne(expr, names, parentenv, handlers[[1]])
  6: tryCatchList(expr, classes, parentenv, handlers)
  7: tryCatch(expr, error = function(e) {    call <- conditionCall(e) 
  if (!is.null(call)) {        if (identical(ca       ll[[1]], 
quote(doTryCatch)))             call <- sys.call(-4)        dcall <- 
deparse(call)[1]        prefix <- paste       ("Error in", dcall, ": ") 
        LONGCALL <- 30        if (nchar(dcall) > LONGCALL) 
prefix <- paste(prefi       x, "\n\t", sep = "")    }    else prefix <- 
"Error : "    msg <- paste(prefix, conditionMessage(e), "\n", sep = "") 
           .Internal(seterrmessage(msg[1]))    if (!silent && 
identical(getOption("show.error.messages"),         TRUE)) { 
    cat(msg, file = stderr())        .Internal(printDeferredWarnings()) 
    }    invisible(structure(msg, class = "try       -error"))})
  8: try({    ns <- loadNamespace(package, c(which.lib.loc, lib.loc), 
keep.source = keep.source)    dataPath <- file.p 
ath(which.lib.loc, package, "data")    env <- attachNamespace(ns, pos = 
pos, dataPath = dataPath)})
  9: library(Rexcelpoi)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:


Some things I can figure out, but this one is beyond my capabilities. 
Any thoughts or suggestions are greatly appreciated.  If you think the 
build warnings are important, I can rebuild the package and post those.

Everyone have a wonderful day.

Thank you
Joe


From hyu at stats.uwo.ca  Thu Oct  4 07:11:23 2007
From: hyu at stats.uwo.ca (Hao Yu)
Date: Thu, 4 Oct 2007 01:11:23 -0400 (EDT)
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
In-Reply-To: <18180.18474.131705.985610@ron.nulle.part>
References: <18180.18474.131705.985610@ron.nulle.part>
Message-ID: <1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>

Hi Dirk,

Thank for pointing out additional flags needed in order to compile Rmpi
correctly. Those flags can be added in configure.ac once openmpi dir is
detected. BTW -DMPI2 flag was missed in your Rmpi since the detection of
openmpi was not good. It should be
####
        if test -d  ${MPI_ROOT}/lib/openmpi; then
                echo "Found openmpi dir in ${MPI_ROOT}/lib"
                MPI_DEPS="-DMPI2"
        fi
####

I tried to run Rmpi under snow and got the same error messenger. But after
checking makeMPIcluster, I found that n=3 was a wrong argument. After
makeMPIcluster finds that count is missing,
count=mpi.comm.size(0)-1 is used. If you start R alone, this will return
count=0 since there is only one member (master). I do not know why snow
did not use count=mpi.universe.size()-1 to find total nodes available.
Anyway after using
cl=makeMPIcluster(count=3),
I was able to run parApply function.

I tried
R -> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)

Also
mpirun -host hostfile -np 1 R --no-save
library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)

Hao

PS: hostfile contains all nodes info so in R mpi.universe.size() returns
right number and will spawn to remote nodes.

Rmp under Debian 3.1 and openmpi 1.2.4 seems OK. I did find some missing
lib under Debian 4.0.


Dirk Eddelbuettel wrote:
>
> Many thanks to Dr Yu for updating Rmpi for R 2.6.0, and for starting to
> make
> the changes to support Open MPI.
>
> I have just built the updated Debian package of Rmpi (i.e. r-cran-rmpi)
> under
> R 2.6.0 but I cannot convince myself yet whether it works or not.  Simple
> tests work.  E.g. on my Debian testing box, with Rmpi installed directly
> using Open Mpi 1.2.3-2 (from Debian) and using 'r' from littler:
>
> edd at ron:~> orterun -np 3 r -e 'library(Rmpi); print(mpi.comm.rank(0))'
> [1] 0
> [1] 1
> [1] 2
> edd at ron:~>
>
> but I basically cannot get anything more complicated to work yet.  R /
> Rmpi
> just seem to hang, in particular snow and and getMPIcluster() just sit
> there:
>
>> cl <- makeSOCKcluster(c("localhost", "localhost"))
>> stopCluster(cl)
>> library(Rmpi)
>> cl <- makeMPIcluster(n=3)
> Error in makeMPIcluster(n = 3) : no nodes available.
>>
>
> I may be overlooking something simple here, in particular the launching of
> apps appears to be different for Open MPI than it was with LAM/MPI (or
> maybe
> I am just confused because I also look at LLNL's slurm for use with Open
> MPI ?)
>
> Has anybody gotten Open MPI and Rmpi to work on simple demos?  Similarly,
> is
> anybody using snow with Rmpi and Open MPI yet?
>
> Also, the Open MPI FAQ is pretty clear on their preference for using mpicc
> for compiling/linking to keep control of the compiler and linker options
> and
> switches.  Note that e.g. on my Debian system
>
> edd at ron:~> mpicc --showme:link
> -pthread -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl
> -lutil -lm -ldl
>
> whereas Rmpi built with just the default from R CMD:
>
> gcc-4.2 -std=gnu99 -shared  -o Rmpi.so RegQuery.o Rmpi.o conversion.o
> internal.o -L/usr/lib -lmpi -lpthread -fPIC   -L/usr/lib/R/lib -lR
>
> Don't we need libopen-rte and libopen-pal as the MPI FAQ suggests?
>
> Many thanks, Dirk
>
> --
> Three out of two people have difficulties with fractions.
>


-- 
Department of Statistics & Actuarial Sciences
Fax Phone#:(519)-661-3813
The University of Western Ontario
Office Phone#:(519)-661-3622
London, Ontario N6A 5B7
http://www.stats.uwo.ca/faculty/yu


From edd at debian.org  Thu Oct  4 12:31:55 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 4 Oct 2007 05:31:55 -0500
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
In-Reply-To: <1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
References: <18180.18474.131705.985610@ron.nulle.part>
	<1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
Message-ID: <18180.49435.543290.484122@ron.nulle.part>


On 4 October 2007 at 01:11, Hao Yu wrote:
| Hi Dirk,
| 
| Thank for pointing out additional flags needed in order to compile Rmpi
| correctly. Those flags can be added in configure.ac once openmpi dir is
| detected. BTW -DMPI2 flag was missed in your Rmpi since the detection of
| openmpi was not good. It should be
| ####
|         if test -d  ${MPI_ROOT}/lib/openmpi; then
|                 echo "Found openmpi dir in ${MPI_ROOT}/lib"
|                 MPI_DEPS="-DMPI2"
|         fi
| ####

I don't follow. From my build log:

* Installing *source* package 'Rmpi' ...
[...]
checking for gcc option to accept ISO C89... none needed
I am here /usr
Try to find mpi.h ...
Found in /usr/include
Try to find libmpi or libmpich ...
Found libmpi in /usr/lib
Found openmpi dir in /usr/lib       <---------- found openmpi
[...]
** libs
make[1]: Entering directory `/tmp/buildd/rmpi-0.5-4/src'
gcc-4.2 -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include -DPACKAGE_NAME=\"\" -DPACKAGE_TARNAME=\"\" -DPACKAGE_VERSION=\"\" -DPACKAGE_STRING=\"\" -DPACKAGE_BUGREPORT=\"\" -I/usr/include -DMPI2 -fPIC     -fpic  -g -O2 -c RegQuery.c -o RegQuery.o
[...]

so -DMPI2 is used.

Because I build this in a chroot / pbuilder envinronment, neither LAM nor
MPICH2 are installed and Open MPI is detected. 

| I tried to run Rmpi under snow and got the same error messenger. But after
| checking makeMPIcluster, I found that n=3 was a wrong argument. After
| makeMPIcluster finds that count is missing,

Yes, my bad. But it also hangs with argument count=3 (which I had tried, but
my mail was wrong.)

| count=mpi.comm.size(0)-1 is used. If you start R alone, this will return
| count=0 since there is only one member (master). I do not know why snow
| did not use count=mpi.universe.size()-1 to find total nodes available.

How would it know total nodes ?  See below re hostfile.

| Anyway after using
| cl=makeMPIcluster(count=3),
| I was able to run parApply function.
| 
| I tried
| R -> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
| 
| Also
| mpirun -host hostfile -np 1 R --no-save
| library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
| 
| Hao
| 
| PS: hostfile contains all nodes info so in R mpi.universe.size() returns
| right number and will spawn to remote nodes.

So we depend on a correct hostfile ?   As I understand the Open MPI this is
deprecated:

# This is the default hostfile for Open MPI.  Notice that it does not
# contain any hosts (not even localhost).  This file should only
# contain hosts if a system administrator wants users to always have
# the same set of default hosts, and is not using a batch scheduler
# (such as SLURM, PBS, etc.).

I am _very_ interested in running Open MPI and Rmpi under slurm (which we
added to Debian as source package slurm-llnl) so it would be nice if this
could rewritten to not require a hostfile as this seems to be how upstream is
going. 

| Rmp under Debian 3.1 and openmpi 1.2.4 seems OK. I did find some missing
| lib under Debian 4.0.

Can you be more specifi? I'd be glad to help.

Thanks!

Dirk


| 
| 
| Dirk Eddelbuettel wrote:
| >
| > Many thanks to Dr Yu for updating Rmpi for R 2.6.0, and for starting to
| > make
| > the changes to support Open MPI.
| >
| > I have just built the updated Debian package of Rmpi (i.e. r-cran-rmpi)
| > under
| > R 2.6.0 but I cannot convince myself yet whether it works or not.  Simple
| > tests work.  E.g. on my Debian testing box, with Rmpi installed directly
| > using Open Mpi 1.2.3-2 (from Debian) and using 'r' from littler:
| >
| > edd at ron:~> orterun -np 3 r -e 'library(Rmpi); print(mpi.comm.rank(0))'
| > [1] 0
| > [1] 1
| > [1] 2
| > edd at ron:~>
| >
| > but I basically cannot get anything more complicated to work yet.  R /
| > Rmpi
| > just seem to hang, in particular snow and and getMPIcluster() just sit
| > there:
| >
| >> cl <- makeSOCKcluster(c("localhost", "localhost"))
| >> stopCluster(cl)
| >> library(Rmpi)
| >> cl <- makeMPIcluster(n=3)
| > Error in makeMPIcluster(n = 3) : no nodes available.
| >>
| >
| > I may be overlooking something simple here, in particular the launching of
| > apps appears to be different for Open MPI than it was with LAM/MPI (or
| > maybe
| > I am just confused because I also look at LLNL's slurm for use with Open
| > MPI ?)
| >
| > Has anybody gotten Open MPI and Rmpi to work on simple demos?  Similarly,
| > is
| > anybody using snow with Rmpi and Open MPI yet?
| >
| > Also, the Open MPI FAQ is pretty clear on their preference for using mpicc
| > for compiling/linking to keep control of the compiler and linker options
| > and
| > switches.  Note that e.g. on my Debian system
| >
| > edd at ron:~> mpicc --showme:link
| > -pthread -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl
| > -lutil -lm -ldl
| >
| > whereas Rmpi built with just the default from R CMD:
| >
| > gcc-4.2 -std=gnu99 -shared  -o Rmpi.so RegQuery.o Rmpi.o conversion.o
| > internal.o -L/usr/lib -lmpi -lpthread -fPIC   -L/usr/lib/R/lib -lR
| >
| > Don't we need libopen-rte and libopen-pal as the MPI FAQ suggests?
| >
| > Many thanks, Dirk
| >
| > --
| > Three out of two people have difficulties with fractions.
| >
| 
| 
| -- 
| Department of Statistics & Actuarial Sciences
| Fax Phone#:(519)-661-3813
| The University of Western Ontario
| Office Phone#:(519)-661-3622
| London, Ontario N6A 5B7
| http://www.stats.uwo.ca/faculty/yu

-- 
Three out of two people have difficulties with fractions.


From luke at stat.uiowa.edu  Thu Oct  4 13:37:24 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 4 Oct 2007 06:37:24 -0500 (CDT)
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
In-Reply-To: <18180.49435.543290.484122@ron.nulle.part>
References: <18180.18474.131705.985610@ron.nulle.part>
	<1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
	<18180.49435.543290.484122@ron.nulle.part>
Message-ID: <Pine.LNX.4.64.0710040622360.765@itasca2.wildberry.org>

On Thu, 4 Oct 2007, Dirk Eddelbuettel wrote:

>
> On 4 October 2007 at 01:11, Hao Yu wrote:
> | Hi Dirk,
> |
> | Thank for pointing out additional flags needed in order to compile Rmpi
> | correctly. Those flags can be added in configure.ac once openmpi dir is
> | detected. BTW -DMPI2 flag was missed in your Rmpi since the detection of
> | openmpi was not good. It should be
> | ####
> |         if test -d  ${MPI_ROOT}/lib/openmpi; then
> |                 echo "Found openmpi dir in ${MPI_ROOT}/lib"
> |                 MPI_DEPS="-DMPI2"
> |         fi
> | ####
>
> I don't follow. From my build log:
>
> * Installing *source* package 'Rmpi' ...
> [...]
> checking for gcc option to accept ISO C89... none needed
> I am here /usr
> Try to find mpi.h ...
> Found in /usr/include
> Try to find libmpi or libmpich ...
> Found libmpi in /usr/lib
> Found openmpi dir in /usr/lib       <---------- found openmpi
> [...]
> ** libs
> make[1]: Entering directory `/tmp/buildd/rmpi-0.5-4/src'
> gcc-4.2 -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include -DPACKAGE_NAME=\"\" -DPACKAGE_TARNAME=\"\" -DPACKAGE_VERSION=\"\" -DPACKAGE_STRING=\"\" -DPACKAGE_BUGREPORT=\"\" -I/usr/include -DMPI2 -fPIC     -fpic  -g -O2 -c RegQuery.c -o RegQuery.o
> [...]
>
> so -DMPI2 is used.
>
> Because I build this in a chroot / pbuilder envinronment, neither LAM nor
> MPICH2 are installed and Open MPI is detected.
>
> | I tried to run Rmpi under snow and got the same error messenger. But after
> | checking makeMPIcluster, I found that n=3 was a wrong argument. After
> | makeMPIcluster finds that count is missing,
>
> Yes, my bad. But it also hangs with argument count=3 (which I had tried, but
> my mail was wrong.)

Any chance the snow workers are picking up another version of Rmpi, eg
a LAM one?  Might happen if you have R_SNOW_LIB set and a Rmpi
installed there.  Otherwise starting with outfile=something may help.
Let me know what you find out -- I'd like to make the snow
configuration process more bullet-proof.

>
> | count=mpi.comm.size(0)-1 is used. If you start R alone, this will return
> | count=0 since there is only one member (master). I do not know why snow
> | did not use count=mpi.universe.size()-1 to find total nodes available.
>
> How would it know total nodes ?  See below re hostfile.
>
> | Anyway after using
> | cl=makeMPIcluster(count=3),
> | I was able to run parApply function.
> |
> | I tried
> | R -> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
> |
> | Also
> | mpirun -host hostfile -np 1 R --no-save
> | library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
> |
> | Hao
> |
> | PS: hostfile contains all nodes info so in R mpi.universe.size() returns
> | right number and will spawn to remote nodes.
>
> So we depend on a correct hostfile ?   As I understand the Open MPI this is
> deprecated:
>
> # This is the default hostfile for Open MPI.  Notice that it does not
> # contain any hosts (not even localhost).  This file should only
> # contain hosts if a system administrator wants users to always have
> # the same set of default hosts, and is not using a batch scheduler
> # (such as SLURM, PBS, etc.).
>
> I am _very_ interested in running Open MPI and Rmpi under slurm (which we
> added to Debian as source package slurm-llnl) so it would be nice if this
> could rewritten to not require a hostfile as this seems to be how upstream is
> going.

To work better with batch scheduling environments where spawning might
be techncally or politically problematic I have been trying to improve
the RMPISNOW script that can be used with LAM as

     mpirun -np 3 RMPISNOW

and then either

     cl <- makeCluster()  # no argument

or

     cl <- makeCluster(2) # mpi rank - 1 (or less I believe)

(the default type for makeCluster becomes MPI in this case).  This
seems to work reasonably well in LAM and I think I can get it to work
similarly in OpenMPI -- will try in the next day or so.  Both LAM and
OpenMPI provide environment variables so shell scripts can determine
the mpirank, which is useful for getting --slave and output redirect
to the workers.  I haven't figured out anything analogous for
MPIC/MPICH2 yet.

Best,

luke


>
> | Rmp under Debian 3.1 and openmpi 1.2.4 seems OK. I did find some missing
> | lib under Debian 4.0.
>
> Can you be more specifi? I'd be glad to help.
>
> Thanks!
>
> Dirk
>
>
> |
> |
> | Dirk Eddelbuettel wrote:
> | >
> | > Many thanks to Dr Yu for updating Rmpi for R 2.6.0, and for starting to
> | > make
> | > the changes to support Open MPI.
> | >
> | > I have just built the updated Debian package of Rmpi (i.e. r-cran-rmpi)
> | > under
> | > R 2.6.0 but I cannot convince myself yet whether it works or not.  Simple
> | > tests work.  E.g. on my Debian testing box, with Rmpi installed directly
> | > using Open Mpi 1.2.3-2 (from Debian) and using 'r' from littler:
> | >
> | > edd at ron:~> orterun -np 3 r -e 'library(Rmpi); print(mpi.comm.rank(0))'
> | > [1] 0
> | > [1] 1
> | > [1] 2
> | > edd at ron:~>
> | >
> | > but I basically cannot get anything more complicated to work yet.  R /
> | > Rmpi
> | > just seem to hang, in particular snow and and getMPIcluster() just sit
> | > there:
> | >
> | >> cl <- makeSOCKcluster(c("localhost", "localhost"))
> | >> stopCluster(cl)
> | >> library(Rmpi)
> | >> cl <- makeMPIcluster(n=3)
> | > Error in makeMPIcluster(n = 3) : no nodes available.
> | >>
> | >
> | > I may be overlooking something simple here, in particular the launching of
> | > apps appears to be different for Open MPI than it was with LAM/MPI (or
> | > maybe
> | > I am just confused because I also look at LLNL's slurm for use with Open
> | > MPI ?)
> | >
> | > Has anybody gotten Open MPI and Rmpi to work on simple demos?  Similarly,
> | > is
> | > anybody using snow with Rmpi and Open MPI yet?
> | >
> | > Also, the Open MPI FAQ is pretty clear on their preference for using mpicc
> | > for compiling/linking to keep control of the compiler and linker options
> | > and
> | > switches.  Note that e.g. on my Debian system
> | >
> | > edd at ron:~> mpicc --showme:link
> | > -pthread -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl
> | > -lutil -lm -ldl
> | >
> | > whereas Rmpi built with just the default from R CMD:
> | >
> | > gcc-4.2 -std=gnu99 -shared  -o Rmpi.so RegQuery.o Rmpi.o conversion.o
> | > internal.o -L/usr/lib -lmpi -lpthread -fPIC   -L/usr/lib/R/lib -lR
> | >
> | > Don't we need libopen-rte and libopen-pal as the MPI FAQ suggests?
> | >
> | > Many thanks, Dirk
> | >
> | > --
> | > Three out of two people have difficulties with fractions.
> | >
> |
> |
> | --
> | Department of Statistics & Actuarial Sciences
> | Fax Phone#:(519)-661-3813
> | The University of Western Ontario
> | Office Phone#:(519)-661-3622
> | London, Ontario N6A 5B7
> | http://www.stats.uwo.ca/faculty/yu
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From edd at debian.org  Thu Oct  4 13:49:47 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 4 Oct 2007 06:49:47 -0500
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
In-Reply-To: <Pine.LNX.4.64.0710040622360.765@itasca2.wildberry.org>
References: <18180.18474.131705.985610@ron.nulle.part>
	<1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
	<18180.49435.543290.484122@ron.nulle.part>
	<Pine.LNX.4.64.0710040622360.765@itasca2.wildberry.org>
Message-ID: <18180.54107.70814.696133@ron.nulle.part>


On 4 October 2007 at 06:37, Luke Tierney wrote:
| > Yes, my bad. But it also hangs with argument count=3 (which I had tried, but
| > my mail was wrong.)
| 
| Any chance the snow workers are picking up another version of Rmpi, eg
| a LAM one?  Might happen if you have R_SNOW_LIB set and a Rmpi
| installed there.  Otherwise starting with outfile=something may help.
| Let me know what you find out -- I'd like to make the snow
| configuration process more bullet-proof.

I generally don;t have any environment variables, so not sure. I'll try to
see what I can find.

| > | count=mpi.comm.size(0)-1 is used. If you start R alone, this will return
| > | count=0 since there is only one member (master). I do not know why snow
| > | did not use count=mpi.universe.size()-1 to find total nodes available.
| >
| > How would it know total nodes ?  See below re hostfile.
| >
| > | Anyway after using
| > | cl=makeMPIcluster(count=3),
| > | I was able to run parApply function.
| > |
| > | I tried
| > | R -> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
| > |
| > | Also
| > | mpirun -host hostfile -np 1 R --no-save
| > | library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
| > |
| > | Hao
| > |
| > | PS: hostfile contains all nodes info so in R mpi.universe.size() returns
| > | right number and will spawn to remote nodes.
| >
| > So we depend on a correct hostfile ?   As I understand the Open MPI this is
| > deprecated:
| >
| > # This is the default hostfile for Open MPI.  Notice that it does not
| > # contain any hosts (not even localhost).  This file should only
| > # contain hosts if a system administrator wants users to always have
| > # the same set of default hosts, and is not using a batch scheduler
| > # (such as SLURM, PBS, etc.).
| >
| > I am _very_ interested in running Open MPI and Rmpi under slurm (which we
| > added to Debian as source package slurm-llnl) so it would be nice if this
| > could rewritten to not require a hostfile as this seems to be how upstream is
| > going.
| 
| To work better with batch scheduling environments where spawning might
| be techncally or politically problematic I have been trying to improve
| the RMPISNOW script that can be used with LAM as
| 
|      mpirun -np 3 RMPISNOW
| 
| and then either
| 
|      cl <- makeCluster()  # no argument
| 
| or
| 
|      cl <- makeCluster(2) # mpi rank - 1 (or less I believe)
| 
| (the default type for makeCluster becomes MPI in this case).  This
| seems to work reasonably well in LAM and I think I can get it to work
| similarly in OpenMPI -- will try in the next day or so.  Both LAM and
| OpenMPI provide environment variables so shell scripts can determine
| the mpirank, which is useful for getting --slave and output redirect
| to the workers.  I haven't figured out anything analogous for
| MPIC/MPICH2 yet.

Yes, out of a run I also realized that I can't just ask Rmpi to work without
a hostfile -- the info must come from somewhere.  

That said, it still fails with a minimal slurm example using the srun. Ie

edd at ron:~> cat /tmp/rmpi.r
#!/usr/bin/env r
library(Rmpi)
library(snow)
cl <- makeMPIcluster(count=1)
print("Hello\n")

does not make it through makeMPIcluster either and just hangs if I do:

edd at ron:~> srun -N 1 /tmp/rmpi.r
                                

Dirk


-- 
Three out of two people have difficulties with fractions.


From luke at stat.uiowa.edu  Thu Oct  4 18:02:03 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 4 Oct 2007 11:02:03 -0500 (CDT)
Subject: [Rd] Rmpi_0.5-4 and OpenMPI questions
In-Reply-To: <1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
References: <18180.18474.131705.985610@ron.nulle.part>
	<1325.129.100.76.161.1191474683.squirrel@www.stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0710041044120.16003@nokomis.stat.uiowa.edu>

On Thu, 4 Oct 2007, Hao Yu wrote:

> Hi Dirk,
>
> Thank for pointing out additional flags needed in order to compile Rmpi
> correctly. Those flags can be added in configure.ac once openmpi dir is
> detected. BTW -DMPI2 flag was missed in your Rmpi since the detection of
> openmpi was not good. It should be
> ####
>        if test -d  ${MPI_ROOT}/lib/openmpi; then
>                echo "Found openmpi dir in ${MPI_ROOT}/lib"
>                MPI_DEPS="-DMPI2"
>        fi
> ####
>
> I tried to run Rmpi under snow and got the same error messenger. But after
> checking makeMPIcluster, I found that n=3 was a wrong argument. After
> makeMPIcluster finds that count is missing,
> count=mpi.comm.size(0)-1 is used. If you start R alone, this will return
> count=0 since there is only one member (master). I do not know why snow
> did not use count=mpi.universe.size()-1 to find total nodes available.

The bit of code you are looking at, for handling calls with no count
argument, is for the case where workers have been started by mpirun
with the RMPISNOW script rather than spawing.  Using
mpi.universe.size() to guess a reasonable default choice for the
spawning case might be useful -- will look into that.

I have OpenMPI installed on Fedora 7 x84_64.  Rmpi 0.5-4 configure
fails for me -- it does not find mpi.h.  I can get Rmpi to build if I
manually set these in Makevars:

     PKG_CFLAGS   = $(ARCHCFLAGS) -I/usr/include/openmpi
     PKG_LIBS     = -L/usr/lib64/openmpi -L/lib -lmpi -lpthread -fPIC $(ARCHLIB)

When I try to use R -> library(Rmpi) -> library(snow) cl <- makeMPIcluster(2)
or mpirun -np3 R -> library(Rmpi) -> ... I get

     Signal:11 info.si_errno:0(Success) si_code:1(SEGV_MAPERR)
     Failing at addr:0x1d26ab7
     [0] func:/usr/lib64/openmpi/libopal.so.0 [0x2aaaafee3263]
     [1] func:/lib64/libc.so.6 [0x367f030630]
     [2] func:/usr/lib64/openmpi/libmpi.so.0(ompi_fortran_string_f2c+0x8c) [0x2aaaaf813bcc]
     [3] func:/usr/lib64/openmpi/libmpi.so.0(mpi_comm_spawn_f+0x75) [0x2aaaaf816405]
     ...
     *** End of error message ***
     Segmentation fault
     luke at nokomis ~%

But mpirun -np 3 RMPISNOW does seem to work, more or less.  A modified
version of RMPISNOW, hopefully attached, does a better job of getting
sensible arguments to the workers and master, but the master R still
thinks it is non-interactive.  I have not figured out a work-around
for that yet -- suggestions welcome.

Best,

luke

> Anyway after using
> cl=makeMPIcluster(count=3),
> I was able to run parApply function.
>
> I tried
> R -> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
>
> Also
> mpirun -host hostfile -np 1 R --no-save
> library(Rmpi) -> library(snow) -> c1=makeMPIcluster(3)
>
> Hao
>
> PS: hostfile contains all nodes info so in R mpi.universe.size() returns
> right number and will spawn to remote nodes.
>
> Rmp under Debian 3.1 and openmpi 1.2.4 seems OK. I did find some missing
> lib under Debian 4.0.
>
>
> Dirk Eddelbuettel wrote:
>>
>> Many thanks to Dr Yu for updating Rmpi for R 2.6.0, and for starting to
>> make
>> the changes to support Open MPI.
>>
>> I have just built the updated Debian package of Rmpi (i.e. r-cran-rmpi)
>> under
>> R 2.6.0 but I cannot convince myself yet whether it works or not.  Simple
>> tests work.  E.g. on my Debian testing box, with Rmpi installed directly
>> using Open Mpi 1.2.3-2 (from Debian) and using 'r' from littler:
>>
>> edd at ron:~> orterun -np 3 r -e 'library(Rmpi); print(mpi.comm.rank(0))'
>> [1] 0
>> [1] 1
>> [1] 2
>> edd at ron:~>
>>
>> but I basically cannot get anything more complicated to work yet.  R /
>> Rmpi
>> just seem to hang, in particular snow and and getMPIcluster() just sit
>> there:
>>
>>> cl <- makeSOCKcluster(c("localhost", "localhost"))
>>> stopCluster(cl)
>>> library(Rmpi)
>>> cl <- makeMPIcluster(n=3)
>> Error in makeMPIcluster(n = 3) : no nodes available.
>>>
>>
>> I may be overlooking something simple here, in particular the launching of
>> apps appears to be different for Open MPI than it was with LAM/MPI (or
>> maybe
>> I am just confused because I also look at LLNL's slurm for use with Open
>> MPI ?)
>>
>> Has anybody gotten Open MPI and Rmpi to work on simple demos?  Similarly,
>> is
>> anybody using snow with Rmpi and Open MPI yet?
>>
>> Also, the Open MPI FAQ is pretty clear on their preference for using mpicc
>> for compiling/linking to keep control of the compiler and linker options
>> and
>> switches.  Note that e.g. on my Debian system
>>
>> edd at ron:~> mpicc --showme:link
>> -pthread -lmpi -lopen-rte -lopen-pal -ldl -Wl,--export-dynamic -lnsl
>> -lutil -lm -ldl
>>
>> whereas Rmpi built with just the default from R CMD:
>>
>> gcc-4.2 -std=gnu99 -shared  -o Rmpi.so RegQuery.o Rmpi.o conversion.o
>> internal.o -L/usr/lib -lmpi -lpthread -fPIC   -L/usr/lib/R/lib -lR
>>
>> Don't we need libopen-rte and libopen-pal as the MPI FAQ suggests?
>>
>> Many thanks, Dirk
>>
>> --
>> Three out of two people have difficulties with fractions.
>>
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
-------------- next part --------------
#! /bin/sh

# if defined, prepend R_SNOW_LIB to $_LIBS
if test ! -z "${R_SNOW_LIB}" ; then
    R_LIBS=${R_SNOW_LIB}:${R_LIBS}; export R_LIBS
fi

# find the library containing the snow package; should eventually use Rscript
snowdir=`echo 'invisible(cat(tryCatch(dirname(.find.package("snow")), error = function(e) ""),"\n",sep=""))' | R --slave`

# for now this hijacks the R_PROFILE mechanism to start up the R
# sessions and load snow and Rmpi into them
R_PROFILE=${snowdir}/snow/RMPISNOWprofile; export R_PROFILE

if test ! -z "${LAMRANK}" ; then
    # use the LAMRANK environment variable set by LAM-MPI's mpirun to
    # run R with appropriate arguments for master and workers.
    if test "${LAMRANK}" == "0" ; then
	exec R $*
    else
	exec R --slave > /dev/null 2>&1
    fi
elif test ! -z "${OMPI_MCA_ns_nds_vpid}" ; then
    # Similar approach for OpenMPI using the OMPI_MCA_ns_nds_vpid
    # variable.  Don't know if it might be better to use
    # OMPI_MCA_ns_nds_vpid_start instead.  The master R process thinks
    # it is non-interactive so for now --no-save or something like
    # that is needed.
    if test "${OMPI_MCA_ns_nds_vpid}" == "0" ; then
	exec R --no-save $*
    else
	exec R --slave > /dev/null 2>&1
    fi
else 
    # The fallback is to use the same arguments on master and workers,
    # with --no-save for cases where workers don't have a terminal.
    # This means that things like CMD batch won't work. It seems to be
    # important NOT to use exec here, at least when this code runs under LAM.
    R --no-save $*
fi

From marco.scutari at gmail.com  Thu Oct  4 20:05:36 2007
From: marco.scutari at gmail.com (Marco Scutari)
Date: Thu, 4 Oct 2007 20:05:36 +0200
Subject: [Rd] bnlearn package compilation failure on MacOSX
Message-ID: <20071004180536.GA2993@elhalyn>


Hi all.

I've recently uploaded a package (bnlearn) to CRAN. It builds fine 
on both Linux (32 and 64 bit) and Windows, but fails on MacOSX ix86
because of C90 vs C99 issues:

http://www.r-project.org/nosvn/R.check/r-patched-macosx-ix86/bnlearn-00install.html

Since I've no MacOSX machine at hand, I would like to ask you:
why is C99 not the default for gcc on MacOSX ix86? Is it safe to 
force gcc to use C99 with either -std=c99 o -std=gnu99?

Thanks in advance.


-- 
Marco Scutari                               
Linux Registered User #341807                  http://counter.li.org
powered by : 
Debian Sid GNU/Linux (SGI-XFS)                       Kernel 2.6.21.3


From ripley at stats.ox.ac.uk  Thu Oct  4 20:51:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Oct 2007 19:51:26 +0100 (BST)
Subject: [Rd] bnlearn package compilation failure on MacOSX
In-Reply-To: <20071004180536.GA2993@elhalyn>
References: <20071004180536.GA2993@elhalyn>
Message-ID: <Pine.LNX.4.64.0710041945010.5059@gannet.stats.ox.ac.uk>

You've got more serious problems than that: you cannot assume gcc.
For example on the SunPro compiler I got

cc -I/home/ripley/R/R-devel-SunPro/include 
-I/home/ripley/R/R-devel-SunPro/inclu
de  -I/usr/local/include    -Kpic  -xO5 -xc99 -xlibmil -nofstore -c 
mutual.infor
mation.c -o mutual.information.o
"mutual.information.c", line 34: member can not have variably modified 
type: n
"mutual.information.c", line 35: member can not have variably modified 
type: m
"mutual.information.c", line 41: cannot dereference non-pointer type
"mutual.information.c", line 52: cannot dereference non-pointer type
"mutual.information.c", line 52: cannot dereference non-pointer type
"mutual.information.c", line 53: cannot dereference non-pointer type
"mutual.information.c", line 53: cannot dereference non-pointer type
"mutual.information.c", line 54: cannot dereference non-pointer type
"mutual.information.c", line 54: cannot dereference non-pointer type
"mutual.information.c", line 60: warning: improper pointer/integer 
combination:
arg #5
"mutual.information.c", line 62: cannot recover from previous errors

Note that is in C99 mode, and under Linux.


On Thu, 4 Oct 2007, Marco Scutari wrote:

>
> Hi all.
>
> I've recently uploaded a package (bnlearn) to CRAN. It builds fine
> on both Linux (32 and 64 bit) and Windows, but fails on MacOSX ix86
> because of C90 vs C99 issues:
>
> http://www.r-project.org/nosvn/R.check/r-patched-macosx-ix86/bnlearn-00install.html
>
> Since I've no MacOSX machine at hand, I would like to ask you:
> why is C99 not the default for gcc on MacOSX ix86? Is it safe to
> force gcc to use C99 with either -std=c99 o -std=gnu99?
>
> Thanks in advance.
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marco.scutari at gmail.com  Thu Oct  4 21:47:26 2007
From: marco.scutari at gmail.com (Marco Scutari)
Date: Thu, 4 Oct 2007 21:47:26 +0200
Subject: [Rd] bnlearn package compilation failure on MacOSX
In-Reply-To: <Pine.LNX.4.64.0710041945010.5059@gannet.stats.ox.ac.uk>
References: <20071004180536.GA2993@elhalyn>
	<Pine.LNX.4.64.0710041945010.5059@gannet.stats.ox.ac.uk>
Message-ID: <20071004194726.GB2993@elhalyn>


On Thu 04/10/07, Prof Brian Ripley wrote:
> You've got more serious problems than that: you cannot assume gcc.
> For example on the SunPro compiler I got
>
[snip]
>
> Note that is in C99 mode, and under Linux.

Hmm. I'm able to reproduce at least some of these errors using
gcc in ansi mode:

[fizban@~/bnlearn/src]:gcc-4.2 -std=gnu99 -I/usr/share/R/include 
-I/usr/share/R/include -ansi -Wall -pedantic -std=c99 -fpic -g 
-O2 -c mutual.information.c -o mutual.information.o
mutual.information.c: In function 'mi': 
mutual.information.c:34: warning: a member of a structure or union
  cannot have a variably modified type
mutual.information.c:35: warning: a member of a structure or union
  cannot have a variably modified type

I'll work on that. On the other hand I'm still curious: why
r-patched-macosx-ix86 uses -std=gnu99 for the ppc arch but not 
for i386 one?

-- 
Marco Scutari                               
Linux Registered User #341807                  http://counter.li.org
powered by : 
Debian Sid GNU/Linux (SGI-XFS)                       Kernel 2.6.21.3


From kw.statr at gmail.com  Thu Oct  4 22:14:18 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Thu, 4 Oct 2007 15:14:18 -0500
Subject: [Rd] Building package with R 2.6.0 on Windows/Cygwin gives error
	with tar
Message-ID: <c968588d0710041314l6971662bv6dfcf1e5004e8395@mail.gmail.com>

My setup:
Windows XP, R-2.6.0, Cygwin (not the Rtools version)

When I tried to build a package, I was given this message:
tar: c\:/X/Rpkgs/Drydown_1.41.tar: Cannot open: Input/Output error

Even manually typing the following caused the same error:
tar chf 'c:/X/Rpkgs/Drydown_1.41.tar' Drydown

I looked at the 2.5.1 and 2.6.0 build scripts.  After restoring this
section to the 2.6.0 build script:
  ## workaround for paths in Cygwin tar
  $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
  }
then $filepath evaluates to
  /cygdrive/c/X/Rpkgs/Drydown_1.41.tar
and I was able to build packages again.

(Posted in case someone else has the same problem and/or finds this useful.)

Kevin Wright


From simon.urbanek at r-project.org  Thu Oct  4 23:32:48 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 4 Oct 2007 17:32:48 -0400
Subject: [Rd] bnlearn package compilation failure on MacOSX
In-Reply-To: <20071004180536.GA2993@elhalyn>
References: <20071004180536.GA2993@elhalyn>
Message-ID: <97FF5D29-C3E0-408E-9613-A0ADE9E00288@r-project.org>

Marco,

On Oct 4, 2007, at 2:05 PM, Marco Scutari wrote:

> I've recently uploaded a package (bnlearn) to CRAN. It builds fine  
> on both Linux (32 and 64 bit) and Windows, but fails on MacOSX ix86  
> because of C90 vs C99 issues:
>
> http://www.r-project.org/nosvn/R.check/r-patched-macosx-ix86/ 
> bnlearn-00install.html
>
> Since I've no MacOSX machine at hand, I would like to ask you: why  
> is C99 not the default for gcc on MacOSX ix86?


It was not deliberate. The current R build (R 2.6.0) was modified to  
use -std=gnu99 in the CC section for both architectures instead of  
using CFLAGS, that should solve the problem. A work around for older  
R is to set PKG_CFLAGS=-std=gnu99 when installing bnlearn.

However, note that C99 compiler is not required for R so it may not  
be available. Since you don't really need any advanced functionality  
of C99, it may be a good idea to change it to a more portable C code.


> Is it safe to force gcc to use C99 with either -std=c99 o -std=gnu99?
>

Not in your package as cannot assume gcc in general, but temporarily  
for R 2.5.1 on OS X, yes.

Thanks,
Simon


From marco.scutari at gmail.com  Thu Oct  4 23:44:11 2007
From: marco.scutari at gmail.com (Marco Scutari)
Date: Thu, 4 Oct 2007 23:44:11 +0200
Subject: [Rd] bnlearn package compilation failure on MacOSX
In-Reply-To: <97FF5D29-C3E0-408E-9613-A0ADE9E00288@r-project.org>
References: <20071004180536.GA2993@elhalyn>
	<97FF5D29-C3E0-408E-9613-A0ADE9E00288@r-project.org>
Message-ID: <20071004214411.GC2993@elhalyn>


On Thu 04/10/07, Simon Urbanek wrote:
> It was not deliberate. The current  R build (R 2.6.0) was modified
> to use -std=gnu99 in the CC section for both architectures instead
> of using CFLAGS, that should solve  the problem. A work around for
> older R is to set PKG_CFLAGS=-std=gnu99 when installing bnlearn.

Ok.

> However, note  that C99 compiler is  not required for R  so it may
> not  be  available.  Since  you don't  really  need  any  advanced
> functionality of C99, it may be a good idea to change it to a more
> portable C code.

That's what I'm going to do; it's now on the top of my TODO list. 

>> Is  it safe  to  force gcc  to  use C99  with  either -std=c99  o
>> -std=gnu99?
>>
>
> Not  in  your  package  as  cannot  assume  gcc  in  general,  but
> temporarily for R 2.5.1 on OS X, yes.

Thanks for the clarification.

-- 
Marco Scutari                               
Linux Registered User #341807                  http://counter.li.org
powered by : 
Debian Sid GNU/Linux (SGI-XFS)                       Kernel 2.6.21.3


From gesteves at uepb.edu.br  Thu Oct  4 19:12:25 2007
From: gesteves at uepb.edu.br (Gustavo H. Esteves)
Date: Thu, 4 Oct 2007 14:12:25 -0300
Subject: [Rd] Problem with rgl into MAC OS X
In-Reply-To: <a79825cf0710031902j76a9e0cbx3ae9842ebf8456e2@mail.gmail.com>
References: <a79825cf0710031902j76a9e0cbx3ae9842ebf8456e2@mail.gmail.com>
Message-ID: <a79825cf0710041012k6932efecha8a56af8ac64c040@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071004/d3adde80/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Oct  5 14:19:01 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Oct 2007 13:19:01 +0100 (BST)
Subject: [Rd] Building package with R 2.6.0 on Windows/Cygwin gives
 error with tar
In-Reply-To: <c968588d0710041314l6971662bv6dfcf1e5004e8395@mail.gmail.com>
References: <c968588d0710041314l6971662bv6dfcf1e5004e8395@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710051311440.30430@gannet.stats.ox.ac.uk>

Try setting TAR to 'tar --force-local'.

This should be the default under Windows, but a typo was introduced in R 
2.6.0 after it was tested.

On Thu, 4 Oct 2007, Kevin Wright wrote:

> My setup:
> Windows XP, R-2.6.0, Cygwin (not the Rtools version)
>
> When I tried to build a package, I was given this message:
> tar: c\:/X/Rpkgs/Drydown_1.41.tar: Cannot open: Input/Output error
>
> Even manually typing the following caused the same error:
> tar chf 'c:/X/Rpkgs/Drydown_1.41.tar' Drydown
>
> I looked at the 2.5.1 and 2.6.0 build scripts.  After restoring this
> section to the 2.6.0 build script:
>  ## workaround for paths in Cygwin tar
>  $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
>  }
> then $filepath evaluates to
>  /cygdrive/c/X/Rpkgs/Drydown_1.41.tar
> and I was able to build packages again.
>
> (Posted in case someone else has the same problem and/or finds this useful.)

It WOULD have been useful if you had tested in the alpha/beta/RC period 
and not immediately after release.  (I believe this has been asked of you 
before.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.hankin at noc.soton.ac.uk  Fri Oct  5 16:47:55 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 5 Oct 2007 15:47:55 +0100
Subject: [Rd] R-2.6.0 package check problems
Message-ID: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>

Hello


One of my packages, untb_1.3-2, passes R CMD check under
MacOSX (and apparently the systems used in the package check
summary page on CRAN) but fails with the following message on
R-2.6.0.tgz compiled last night on my (home) linux box.  I hasten
to add that I have never seen this error before on home-compiled
pre-releases of R-2.6.0.

Can anyone help me understand what is going on?


localhost:~/scratch%R CMD check untb_1.3-2.tgz

[snip]

creating untb-Ex.R ... OK
* checking examples ... ERROR
Running examples in 'untb-Ex.R' failed.
The error most likely occurred in:

 > ### * butterflies
 >
 > flush(stderr()); flush(stdout())
 >
 > ### Name: butterflies
 > ### Title: abundance data for butterflies
 > ### Aliases: butterflies butterfly
 > ### Keywords: datasets
 >
 > ### ** Examples
 >
 > data(butterflies)
 > plot(butterflies, uncertainty=TRUE)
Error in log(theta) :
   could not find symbol "base" in environment of the generic function
Calls: plot ... optimal.theta -> optimize -> <Anonymous> -> f -> log
Execution halted







localhost:~/scratch%R
 > sessionInfo()
R version 2.6.0 (2007-10-03)
i686-pc-linux-gnu

locale:
LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=e 
n_US;LC_
MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_M 
EASUREME
NT=en_US;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] rcompgen_0.1-15
 > R.version
                _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status
major          2
minor          6.0
year           2007
month          10
day            03
svn rev        43063
language       R
version.string R version 2.6.0 (2007-10-03)
 >
 >







--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ligges at statistik.uni-dortmund.de  Fri Oct  5 17:11:09 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Oct 2007 17:11:09 +0200
Subject: [Rd] R-2.6.0 package check problems
In-Reply-To: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
References: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
Message-ID: <4706540D.9030509@statistik.uni-dortmund.de>



Robin Hankin wrote:
> Hello
> 
> 
> One of my packages, untb_1.3-2, passes R CMD check under
> MacOSX (and apparently the systems used in the package check
> summary page on CRAN) but fails with the following message on
> R-2.6.0.tgz compiled last night on my (home) linux box.  I hasten
> to add that I have never seen this error before on home-compiled
> pre-releases of R-2.6.0.
> 
> Can anyone help me understand what is going on?


- I only see version 1.3-0 of your package passing the checks on CRAN.
- Do you have set R_LIBS inappropriate for your new R version or are you 
using some other binary packages compiled with a former version of R?

Uwe





> 
> localhost:~/scratch%R CMD check untb_1.3-2.tgz
> 
> [snip]
> 
> creating untb-Ex.R ... OK
> * checking examples ... ERROR
> Running examples in 'untb-Ex.R' failed.
> The error most likely occurred in:
> 
>  > ### * butterflies
>  >
>  > flush(stderr()); flush(stdout())
>  >
>  > ### Name: butterflies
>  > ### Title: abundance data for butterflies
>  > ### Aliases: butterflies butterfly
>  > ### Keywords: datasets
>  >
>  > ### ** Examples
>  >
>  > data(butterflies)
>  > plot(butterflies, uncertainty=TRUE)
> Error in log(theta) :
>    could not find symbol "base" in environment of the generic function
> Calls: plot ... optimal.theta -> optimize -> <Anonymous> -> f -> log
> Execution halted
> 
> 
> 
> 
> 
> 
> 
> localhost:~/scratch%R
>  > sessionInfo()
> R version 2.6.0 (2007-10-03)
> i686-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=e 
> n_US;LC_
> MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_M 
> EASUREME
> NT=en_US;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] rcompgen_0.1-15
>  > R.version
>                 _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status
> major          2
> minor          6.0
> year           2007
> month          10
> day            03
> svn rev        43063
> language       R
> version.string R version 2.6.0 (2007-10-03)
>  >
>  >
> 
> 
> 
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thomas.Petzoldt at tu-dresden.de  Fri Oct  5 17:49:26 2007
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 05 Oct 2007 17:49:26 +0200
Subject: [Rd] R-2.6.0 package check problems
In-Reply-To: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
References: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
Message-ID: <47065D06.5080107@tu-dresden.de>

Robin Hankin wrote:
 > Hello
 >
 >
 > One of my packages, untb_1.3-2, passes R CMD check under
 > MacOSX (and apparently the systems used in the package check
 > summary page on CRAN) but fails with the following message on
 > R-2.6.0.tgz compiled last night on my (home) linux box.  I hasten
 > to add that I have never seen this error before on home-compiled
 > pre-releases of R-2.6.0.
 >
 > Can anyone help me understand what is going on?

Hi Robin,

congratulations to your published article about untb ;-)

One possible explanation is that your examples use random numbers which 
may be different ones during the CRAN check. I had this problem with 
another package where a "rare random number event" lead to 
non-convergence of optim during the package check. You may use 
set.seed() as a first aid and then try to stabilize your algorithms.

BTW: untb_1.3-2.tar.gz passed the check just now on my system: R 2.7.0 
Under development (unstable), svn rev 43092 (5. Oct), i386-pc-mingw32


Thomas P.


-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From kw.statr at gmail.com  Fri Oct  5 18:44:31 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Fri, 5 Oct 2007 11:44:31 -0500
Subject: [Rd] Building package with R 2.6.0 on Windows/Cygwin gives
	error with tar
In-Reply-To: <Pine.LNX.4.64.0710051311440.30430@gannet.stats.ox.ac.uk>
References: <c968588d0710041314l6971662bv6dfcf1e5004e8395@mail.gmail.com>
	<Pine.LNX.4.64.0710051311440.30430@gannet.stats.ox.ac.uk>
Message-ID: <c968588d0710050944m23ac9446m5a4e35ca4aa648f9@mail.gmail.com>

I tried setenv TAR="tar --force-local" and also tried changing the
build script directly to
    R_system(join(" ",
		  ("tar --force-local -chf",
		   &shell_quote_file_path($filepath),
		   "$pkgname")));
but still had this error:
tar: Cannot execute remote shell: No such file or directory
tar: c\:/x/rpkgs/Drydown_1.41.tar: Cannot open: Input/Output error

Replacing R_system with print confirms that $filepath does not have
the backslash.

Curiously, at the bash prompt, this does work:
tar --force-local -chf "c:/X/Rpkgs/Drydown_1.41.tar" Drydown

Maybe a confusion between R_system and bash ???

I'm happy to help test this further, but with the hack reported at the
start of this thread I'm also content to let this drop (or go off
list).

Kevin Wright



On 10/5/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> Try setting TAR to 'tar --force-local'.
>
> This should be the default under Windows, but a typo was introduced in R
> 2.6.0 after it was tested.
>
> On Thu, 4 Oct 2007, Kevin Wright wrote:
>
> > My setup:
> > Windows XP, R-2.6.0, Cygwin (not the Rtools version)
> >
> > When I tried to build a package, I was given this message:
> > tar: c\:/X/Rpkgs/Drydown_1.41.tar: Cannot open: Input/Output error
> >
> > Even manually typing the following caused the same error:
> > tar chf 'c:/X/Rpkgs/Drydown_1.41.tar' Drydown
> >
> > I looked at the 2.5.1 and 2.6.0 build scripts.  After restoring this
> > section to the 2.6.0 build script:
> >  ## workaround for paths in Cygwin tar
> >  $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
> >  }
> > then $filepath evaluates to
> >  /cygdrive/c/X/Rpkgs/Drydown_1.41.tar
> > and I was able to build packages again.
> >
> > (Posted in case someone else has the same problem and/or finds this useful.)
>
> It WOULD have been useful if you had tested in the alpha/beta/RC period
> and not immediately after release.  (I believe this has been asked of you
> before.)
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From G.J.A.Fox at gw.utwente.nl  Fri Oct  5 17:41:23 2007
From: G.J.A.Fox at gw.utwente.nl (G.J.A.Fox at gw.utwente.nl)
Date: Fri, 5 Oct 2007 17:41:23 +0200
Subject: [Rd] problem with building package in R 2.6.0
Message-ID: <4B2C66ED32F9334798B092FEC883229C01CBB3DC@gwex1.dynamic.gw.utwente.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071005/8e74a312/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Oct  5 20:50:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Oct 2007 19:50:30 +0100 (BST)
Subject: [Rd] problem with building package in R 2.6.0
In-Reply-To: <4B2C66ED32F9334798B092FEC883229C01CBB3DC@gwex1.dynamic.gw.utwente.nl>
References: <4B2C66ED32F9334798B092FEC883229C01CBB3DC@gwex1.dynamic.gw.utwente.nl>
Message-ID: <Pine.LNX.4.64.0710051949360.25941@gannet.stats.ox.ac.uk>

On Fri, 5 Oct 2007, G.J.A.Fox at gw.utwente.nl wrote:

> Hello,
>
>
>
> I can nolonger build R packages in R 2.6.0 (win xp). I get the error
> message 'sh' is not recognized as an internal
>
> or external command. In earlier versions of R I had no problems. Maybe
> that someone can help me with this.

You can: read the R-admin manual and make sure you have the correct tools 
installed _and in your path_.



>
>
>
> Jean-Paul Fox.
>
>
>
>
>
> C:\PROGRA~1\R\R-2.6.0\bin>Rcmd build --force --binary C:\Temp\R260\mlirt
>
> * checking for file 'C:\Temp\R260\mlirt/DESCRIPTION' ... OK
>
> * preparing 'C:\Temp\R260\mlirt':
>
> * checking DESCRIPTION meta-information ...'sh' is not recognized as an
> internal
>
> or external command,
>
> operable program or batch file.
>
> 'sh' is not recognized as an internal or external command,
>
> operable program or batch file.
>
> OK
>
> * removing junk files
>
> 'sh' is not recognized as an internal or external command,
>
> operable program or batch file.
>
> 'sh' is not recognized as an internal or external command,
>
> operable program or batch file.
>
> 'sh' is not recognized as an internal or external command,
>
> operable program or batch file.
>
> Error: cannot open file 'mlirt/DESCRIPTION' for reading
>
>
>
>
>
>
>
> ______________________________________________________
>
>
>
> dr.ir. G.J.A. Fox
>
> Twente University
> Faculty of Behavioural Sciences
>
> Department of Research Methodology, Measurement and Data Analysis
>
> PO. Box 217, 7500 AE Enschede
> The Netherlands
>
>
>
> E-Mail Fox at edte.utwente.nl
>
> HomePage http://users.edte.utwente.nl/Fox
>
> Voice +31 (0)53 4893326
> ______________________________________________________
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hpages at fhcrc.org  Fri Oct  5 22:58:42 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 05 Oct 2007 13:58:42 -0700
Subject: [Rd] 'R CMD build' and file permissions
Message-ID: <4706A582.4060406@fhcrc.org>

Hi,

When building a source package on Linux with 'R CMD build',
the files in the resulting tarball don't have the original
permissions.
The problem is that the packages I want to build include an SQLite
data base (an .sqlite file) and, before I run 'R CMD build', I've
made this file read-only (chmod 444) because I want this DB to be
read-only. Then if I install by running 'R CMD INSTALL' directly on
the source directory, everything works as expected (the permissions
of the installed .sqlite file are conserved). But if I run 'R CMD build'
in order to produce the tarballs (I need to distribute those packages),
then, when the user will install them, the SQLite DBs will not be
read-only anymore.

Is there a way to prevent 'R CMD build' from changing the permissions
of the source files?
Thanks in advance!

Cheers,
H


From hin-tak.leung at cimr.cam.ac.uk  Sun Oct  7 05:56:32 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Sun, 07 Oct 2007 04:56:32 +0100
Subject: [Rd] R 2.6.0 S4 data breakage, R _data_class(), class<-, etc.
Message-ID: <470858F0.1090902@cimr.cam.ac.uk>

Hi,

(somebody would probably yell at me for not checking 2.6.0rc,
for which I can only apologize...)

Our R package (snpMatrix in 
http://www-gene.cimr.cam.ac.uk/clayton/software/) is broken rather badly
in 2.6.0 ; I have fixed most of it now so a new release is imminent;
but I'd like to mention a few things, mostly to summarize my experience
and hopefully the 'writing R extensions' document can be updated to
reflect some of this...

1) We created and bundled some data in the past in the 2.2 to 2.5
time frame (well, 18 months in reality);
most of them triggers a warning 'pre-2.4.0 S4 objects detected...
consider recreating...'
   a) I could fix all of them with just 'a <- asS4(a)' and save()
        (they are relatively simple objects just missing the S4 object
         bit flag)
   b) I am surprised one of them were actually saved from 2.5 - our buggy
      code no doubt, see below.

We never noticed we didn't do SET_S4_OBJECT() in our C code nor
asS4() in our R code until this week. Obviously we were mistakenly
relying on the S4 method dispatch on S3 objects, which were withdrawn in 
2.6.0...

2) I am surprised that 'class(a)' can read S4 class names, but 
'class(a)<-' does not set the S4 object bit. I suppose the correct way 
would be to do new(...)? This needs to be written down somewhere...
The asymmetry is somewhat surprising though.

3) We have some C code which branches depending on the S4 class.
The R extension doc didn't explain that one needs to do R_data_class()
rather than classgets() (or 'getAttrib(x, RClassSymbol)') to retrieve
S4 classes; further more,
R_data_class() is not part of the public API, and I only found it by
looking at the C code of 'class()' (do_class()). But R_data_class()
is part of exposed binary interface and the methods package certainly
uses it; isn't it time to make it part of the public API? In any case, I 
think a way of retrieving the S4 class in C is needed.

  4) The documentation is missing a fair part - specifically,
I need to be able to read and write the S4 class attribute...
so R_data_class() needs to be documented and exposed as part of the 
public API (and included in the Rinternals.h include),
and the recommended way of making an S4 object in C? I found
classgets() + SET_S4_OBJECT() seem to work, but I'd like an 
authoritative answer...

5) I am finding 'class()<-' + asS4() in R and classgets()+ 
SET_S4_OBJECT() in C combo's a bit awkward. Is there any reasons why
class<- or classgets() (or if there is a more 'correct' API to use for
S4) cannot automatically set the S4 bit if the name is a known S4 class?

Thanks for reading so far...

Hin-Tak


From jmc at r-project.org  Sun Oct  7 16:44:31 2007
From: jmc at r-project.org (John Chambers)
Date: Sun, 07 Oct 2007 10:44:31 -0400
Subject: [Rd] R 2.6.0 S4 data breakage, R _data_class(), class<-, etc.
In-Reply-To: <470858F0.1090902@cimr.cam.ac.uk>
References: <470858F0.1090902@cimr.cam.ac.uk>
Message-ID: <4708F0CF.4000308@r-project.org>

Most of your problems seem related to assigning an S4 class to an 
arbitrary object--a really bad idea, since it can produce invalid objects.

Objects from S4 classes are created by calling the function new(), and 
in principal _only_ by calling that function.  Objects from one class 
are coerced to another by calling the function as().

Assigning a class to any old object is a very S3 idea (and not a good 
idea except in low-level code there, either).

At the C level there are  macros for new() (R recommends NEW_OBJECT()), 
although the safest approach when feasible is to allocate the object in 
R.  The general as() computation really needs to be done in R because of 
its special use of method dispatch; there are macros for the equivalent 
of the as.<type>() functions.

Perhaps some improvements to the documentation would make this clearer, 
although Chapter 7 and Appendix A of Programming with Data seem 
reasonably definite.

Thanks for sharing your notes.

John


Hin-Tak Leung wrote:
> Hi,
>
> (somebody would probably yell at me for not checking 2.6.0rc,
> for which I can only apologize...)
>
> Our R package (snpMatrix in 
> http://www-gene.cimr.cam.ac.uk/clayton/software/) is broken rather badly
> in 2.6.0 ; I have fixed most of it now so a new release is imminent;
> but I'd like to mention a few things, mostly to summarize my experience
> and hopefully the 'writing R extensions' document can be updated to
> reflect some of this...
>
> 1) We created and bundled some data in the past in the 2.2 to 2.5
> time frame (well, 18 months in reality);
> most of them triggers a warning 'pre-2.4.0 S4 objects detected...
> consider recreating...'
>    a) I could fix all of them with just 'a <- asS4(a)' and save()
>         (they are relatively simple objects just missing the S4 object
>          bit flag)
>    b) I am surprised one of them were actually saved from 2.5 - our buggy
>       code no doubt, see below.
>
> We never noticed we didn't do SET_S4_OBJECT() in our C code nor
> asS4() in our R code until this week. Obviously we were mistakenly
> relying on the S4 method dispatch on S3 objects, which were withdrawn in 
> 2.6.0...
>
> 2) I am surprised that 'class(a)' can read S4 class names, but 
> 'class(a)<-' does not set the S4 object bit. I suppose the correct way 
> would be to do new(...)? This needs to be written down somewhere...
> The asymmetry is somewhat surprising though.
>
> 3) We have some C code which branches depending on the S4 class.
> The R extension doc didn't explain that one needs to do R_data_class()
> rather than classgets() (or 'getAttrib(x, RClassSymbol)') to retrieve
> S4 classes; further more,
> R_data_class() is not part of the public API, and I only found it by
> looking at the C code of 'class()' (do_class()). But R_data_class()
> is part of exposed binary interface and the methods package certainly
> uses it; isn't it time to make it part of the public API? In any case, I 
> think a way of retrieving the S4 class in C is needed.
>   
Yes, or at the least instructions to handle the case of a NULL class 
attribute, but a macro would be good.
>   4) The documentation is missing a fair part - specifically,
> I need to be able to read and write the S4 class attribute...
> so R_data_class() needs to be documented and exposed as part of the 
> public API (and included in the Rinternals.h include),
> and the recommended way of making an S4 object in C? I found
> classgets() + SET_S4_OBJECT() seem to work, but I'd like an 
> authoritative answer...
>
> 5) I am finding 'class()<-' + asS4() in R and classgets()+ 
> SET_S4_OBJECT() in C combo's a bit awkward. Is there any reasons why
> class<- or classgets() (or if there is a more 'correct' API to use for
> S4) cannot automatically set the S4 bit if the name is a known S4 class?
>
> Thanks for reading so far...
>
> Hin-Tak
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From mtmorgan at fhcrc.org  Sun Oct  7 21:18:41 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 07 Oct 2007 12:18:41 -0700
Subject: [Rd] R 2.6.0 S4 data breakage, R _data_class(), class<-, etc.
In-Reply-To: <4708F0CF.4000308@r-project.org> (John Chambers's message of
	"Sun, 07 Oct 2007 10:44:31 -0400")
References: <470858F0.1090902@cimr.cam.ac.uk> <4708F0CF.4000308@r-project.org>
Message-ID: <6phy7eeka26.fsf@gopher4.fhcrc.org>

John Chambers <jmc at r-project.org> writes:

> Most of your problems seem related to assigning an S4 class to an 
> arbitrary object--a really bad idea, since it can produce invalid objects.
>
> Objects from S4 classes are created by calling the function new(), and 
> in principal _only_ by calling that function.  Objects from one class 
> are coerced to another by calling the function as().

But both 'new' and 'as' appear to produce invalid (in a different
sense, I guess) objects:

> setClass("snp", contains="raw",
+          validity=function(object) {
+              if (length(object) < 1) "too short"
+              else TRUE
+          })
[1] "snp"
> new("snp")
An object of class "snp"
raw(0)
> as(raw(), "snp")
An object of class "snp"
raw(0)
> new("snp", raw())
Error in validObject(.Object) : invalid class "snp" object: too short

Conversely, I think the S4 implementation implicitly requires that
'new' with a single argument (i.e., class name) return a valid object
-- see

https://stat.ethz.ch/pipermail/bioc-devel/2007-September/001323.html

Also, coercing a genome's worth of 'raw' SNPs to 'snp' appears to be
more memory efficient than creating a new 'snp' (even with an explicit
validity check):

> x <- raw(1)
> tracemem(x)
[1] "<0x1034e28>"
> y <- as(x, "snp")
tracemem[0x1034e28 -> 0x7b67e8]: .mergeAttrs setDataPart .Call slot<- @<- asMethod as<- asMethod as 
> y <- new("snp", x)
tracemem[0x1034e28 -> 0x7bed28]: initialize initialize new 
tracemem[0x7bed28 -> 0x8fd968]: .mergeAttrs setDataPart .Call slot<- @<- asMethod as<- initialize initialize new 
tracemem[0x8fd968 -> 0x906518]: switch getDataPart .Call slot validObject initialize initialize new 
> validObject(y <- as(x, "snp"))
tracemem[0x1034e28 -> 0xa1bfc8]: .mergeAttrs setDataPart .Call slot<- @<- asMethod as<- asMethod as validObject 
tracemem[0xa1bfc8 -> 0x9e6dd8]: switch getDataPart .Call slot validObject 
TRUE

Martin

> Assigning a class to any old object is a very S3 idea (and not a good 
> idea except in low-level code there, either).
>
> At the C level there are  macros for new() (R recommends NEW_OBJECT()), 
> although the safest approach when feasible is to allocate the object in 
> R.  The general as() computation really needs to be done in R because of 
> its special use of method dispatch; there are macros for the equivalent 
> of the as.<type>() functions.
>
> Perhaps some improvements to the documentation would make this clearer, 
> although Chapter 7 and Appendix A of Programming with Data seem 
> reasonably definite.
>
> Thanks for sharing your notes.
>
> John
>
>
> Hin-Tak Leung wrote:
>> Hi,
>>
>> (somebody would probably yell at me for not checking 2.6.0rc,
>> for which I can only apologize...)
>>
>> Our R package (snpMatrix in 
>> http://www-gene.cimr.cam.ac.uk/clayton/software/) is broken rather badly
>> in 2.6.0 ; I have fixed most of it now so a new release is imminent;
>> but I'd like to mention a few things, mostly to summarize my experience
>> and hopefully the 'writing R extensions' document can be updated to
>> reflect some of this...
>>
>> 1) We created and bundled some data in the past in the 2.2 to 2.5
>> time frame (well, 18 months in reality);
>> most of them triggers a warning 'pre-2.4.0 S4 objects detected...
>> consider recreating...'
>>    a) I could fix all of them with just 'a <- asS4(a)' and save()
>>         (they are relatively simple objects just missing the S4 object
>>          bit flag)
>>    b) I am surprised one of them were actually saved from 2.5 - our buggy
>>       code no doubt, see below.
>>
>> We never noticed we didn't do SET_S4_OBJECT() in our C code nor
>> asS4() in our R code until this week. Obviously we were mistakenly
>> relying on the S4 method dispatch on S3 objects, which were withdrawn in 
>> 2.6.0...
>>
>> 2) I am surprised that 'class(a)' can read S4 class names, but 
>> 'class(a)<-' does not set the S4 object bit. I suppose the correct way 
>> would be to do new(...)? This needs to be written down somewhere...
>> The asymmetry is somewhat surprising though.
>>
>> 3) We have some C code which branches depending on the S4 class.
>> The R extension doc didn't explain that one needs to do R_data_class()
>> rather than classgets() (or 'getAttrib(x, RClassSymbol)') to retrieve
>> S4 classes; further more,
>> R_data_class() is not part of the public API, and I only found it by
>> looking at the C code of 'class()' (do_class()). But R_data_class()
>> is part of exposed binary interface and the methods package certainly
>> uses it; isn't it time to make it part of the public API? In any case, I 
>> think a way of retrieving the S4 class in C is needed.
>>   
> Yes, or at the least instructions to handle the case of a NULL class 
> attribute, but a macro would be good.
>>   4) The documentation is missing a fair part - specifically,
>> I need to be able to read and write the S4 class attribute...
>> so R_data_class() needs to be documented and exposed as part of the 
>> public API (and included in the Rinternals.h include),
>> and the recommended way of making an S4 object in C? I found
>> classgets() + SET_S4_OBJECT() seem to work, but I'd like an 
>> authoritative answer...
>>
>> 5) I am finding 'class()<-' + asS4() in R and classgets()+ 
>> SET_S4_OBJECT() in C combo's a bit awkward. Is there any reasons why
>> class<- or classgets() (or if there is a more 'correct' API to use for
>> S4) cannot automatically set the S4 bit if the name is a known S4 class?
>>
>> Thanks for reading so far...
>>
>> Hin-Tak
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology Shared Resource Director
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (208) 667-2793


From bhs2 at mevik.net  Mon Oct  8 11:07:16 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 08 Oct 2007 11:07:16 +0200
Subject: [Rd] R 2.6.0 S4 data breakage, R _data_class(), class<-, etc.
In-Reply-To: <6phy7eeka26.fsf@gopher4.fhcrc.org> (Martin Morgan's message of
	"Sun, 07 Oct 2007 12:18:41 -0700")
References: <470858F0.1090902@cimr.cam.ac.uk> <4708F0CF.4000308@r-project.org>
	<6phy7eeka26.fsf@gopher4.fhcrc.org>
Message-ID: <m0hcl27z5n.fsf@bar.nemo-project.org>

Martin Morgan wrote:

> But both 'new' and 'as' appear to produce invalid (in a different
> sense, I guess) objects:
>
>> setClass("snp", contains="raw",
> +          validity=function(object) {
> +              if (length(object) < 1) "too short"
> +              else TRUE
> +          })

Well, you _have_ designed a class with an invalid prototype (as
determined by your own validity function). :-)

-- 
Bj?rn-Helge Mevik


From schmidb at ibe.med.uni-muenchen.de  Mon Oct  8 15:16:14 2007
From: schmidb at ibe.med.uni-muenchen.de (Markus Schmidberger)
Date: Mon, 08 Oct 2007 15:16:14 +0200
Subject: [Rd] Rmpi_0.5-4 and MPICH2 does not work
Message-ID: <470A2D9E.2000802@ibe.med.uni-muenchen.de>

Hello,

Rmpi_0.5-4 is not working with MPICH2.
I have mpich2-1.0.6 on a windows cluster. R-2.5.1 and Rmpi_0.5-3 is 
working well.
Running R-2.6.0 and Rmpi_0.5-4 on one PC is working! Using more PCs 
mpi.spawn.Rslaves(nslaves=4) hangs without any error. There is also no 
message in the mpi.log

Any ideas for debugging?

I build Rmpi by my self with Rtools: Rcmd build --binary Rmpi_0.5-4\Rmpi
It is working well, but there is a warning: "this package has a 
configure script. It probably needs manual configuration"
Are there any problems by this warning?

Best
Markus

-- 
Dipl.-Tech. Math. Markus Schmidberger

Ludwig-Maximilians-Universit?t M?nchen
IBE - Institut f?r medizinische Informationsverarbeitung,
Biometrie und Epidemiologie
Marchioninistr. 15, D-81377 Muenchen
URL: http://ibe.web.med.uni-muenchen.de 
Mail: Markus.Schmidberger [at] ibe.med.uni-muenchen.de


From mtmorgan at fhcrc.org  Mon Oct  8 15:59:17 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 08 Oct 2007 06:59:17 -0700
Subject: [Rd] R 2.6.0 S4 data breakage, R _data_class(), class<-, etc.
In-Reply-To: <m0hcl27z5n.fsf@bar.nemo-project.org> 
	=?iso-8859-1?q?=28Bj=F8rn-Helge?= Mevik's message of "Mon,
	08 Oct 2007 11:07:16 +0200")
References: <470858F0.1090902@cimr.cam.ac.uk> <4708F0CF.4000308@r-project.org>
	<6phy7eeka26.fsf@gopher4.fhcrc.org>
	<m0hcl27z5n.fsf@bar.nemo-project.org>
Message-ID: <6phk5pxlnbe.fsf@gopher4.fhcrc.org>

bhs2 at mevik.net (Bj?rn-Helge Mevik) writes:

> Martin Morgan wrote:
>
>> But both 'new' and 'as' appear to produce invalid (in a different
>> sense, I guess) objects:
>>
>>> setClass("snp", contains="raw",
>> +          validity=function(object) {
>> +              if (length(object) < 1) "too short"
>> +              else TRUE
>> +          })
>
> Well, you _have_ designed a class with an invalid prototype (as
> determined by your own validity function). :-)

Yeah, its true I did, but the software let me get away with it. Even
with a valid protoytpe I can as(raw(), "snp").

Martin

> -- 
> Bj?rn-Helge Mevik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From iago.mosqueira at gmail.com  Tue Oct  9 09:43:42 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Tue, 9 Oct 2007 09:43:42 +0200
Subject: [Rd] Package compile under Windows on 2.6.0
Message-ID: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>

Dear all,

We are experiencing some trouble when compiling R packages using R
2.6.0 and the new Rtools installer under Windows XP.

(1) First, compiling any package using the new setup stops with an
errorrelated to some "/" issue on the inst folder. This folder only
contains a CITATION file

---------- Making package FLCore ------------
 adding build stamp to DESCRIPTION
 installing NAMESPACE file and metadata
 making DLL ...
making FLCoreClasses.d from FLCoreClasses.cpp
g++-sjlj   -Ic:/progra~1/r/r-2.6.0/include    -Wall -O2  -c
FLCoreClasses.cpp -o FLCoreClasses.o
windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED" -I
c:/progra~1/r/r-2.6.0/include  -i FLCore_res.rc -o FLCore_res.o
g++-sjlj   -shared -s  -o FLCore.dll FLCore.def FLCoreClasses.o
FLCore_res.o  -Lc:/progra~1/r/r-2.6.0/bin    -lR
 ... DLL made
 installing DLL
 installing R files
 installing inst files
rm: failed to get attributes of `/': No such file or directory
rm: failed to get attributes of `/': No such file or directory
 installing data files
rm: failed to get attributes of `/': No such file or directory
make[2]: *** [C:/Sandbox/R260built/FLCore.Rcheck/FLCore/data] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-FLCore] Error 2
*** Installation of FLCore failed ***

(2) Testing with the previous Rtoolset with updated MinGW and Perl, a
package from CRAN can be compiled (VR), but our package now fails with

---------- Making package FLCore ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  installing R files
  installing inst files
  installing data files
  installing man source files
  installing indices
Error in eval(expr, envir, enclos) : could not find function "setClass"
Error: unable to load R code in package 'FLCore'
Execution halted
make[2]: *** [indices] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-FLCore] Error 2
*** Installation of FLCore failed ***

methods is loaded trhough a require(methods) inside an .onLoad call.

(3) The package compiles on a Linux machine with R 2.6.0

Is there any issue with MinGW or the Rtools he should consider?

Many thanks,


Iago


From r.hankin at noc.soton.ac.uk  Tue Oct  9 10:16:37 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 9 Oct 2007 09:16:37 +0100
Subject: [Rd] R-2.6.0 package check problems
In-Reply-To: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
References: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
Message-ID: <4346292B-C733-4710-ADAD-5D13822E3869@noc.soton.ac.uk>


On 5 Oct 2007, at 15:47, Robin Hankin wrote:

> Hello
>
>
> One of my packages, untb_1.3-2, passes R CMD check under
> MacOSX (and apparently the systems used in the package check
> summary page on CRAN) but fails with the following message on
> R-2.6.0.tgz compiled last night on my (home) linux box.  I hasten
> to add that I have never seen this error before on home-compiled
> pre-releases of R-2.6.0.
>
> Can anyone help me understand what is going on?
>
>


thanks everyone.   My problems were solved by following Peter D's
(offline) suggestion to update all the dependencies: he noted that
log() became generic in R-2.6.0; untb depends on Brobdingnag,
the newest version of which tests for log() being generic [using
isGeneric("log")] and executes different code
depending on the answer.

crisis over!







--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From P.Dalgaard at biostat.ku.dk  Tue Oct  9 10:45:28 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 09 Oct 2007 10:45:28 +0200
Subject: [Rd] R-2.6.0 package check problems
In-Reply-To: <4346292B-C733-4710-ADAD-5D13822E3869@noc.soton.ac.uk>
References: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
	<4346292B-C733-4710-ADAD-5D13822E3869@noc.soton.ac.uk>
Message-ID: <470B3FA8.4050900@biostat.ku.dk>

Robin Hankin wrote:
>
> thanks everyone.   My problems were solved by following Peter D's
> (offline) suggestion...
That (offline) must have been unintentional. I usually try to keep
discussions on the list, unless there is very good reason not to.

In this particular case I was clearly speculating (the reply starts with
"Hmm"!) and thus expecting that someone would know more than me and
might chime In.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue Oct  9 10:53:02 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Oct 2007 09:53:02 +0100 (BST)
Subject: [Rd] R-2.6.0 package check problems
In-Reply-To: <470B3FA8.4050900@biostat.ku.dk>
References: <B5BB0B9B-FF8F-4A4B-9ADB-20ACF8E9F0EA@noc.soton.ac.uk>
	<4346292B-C733-4710-ADAD-5D13822E3869@noc.soton.ac.uk>
	<470B3FA8.4050900@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0710090951370.26753@gannet.stats.ox.ac.uk>

On Tue, 9 Oct 2007, Peter Dalgaard wrote:

> Robin Hankin wrote:
>>
>> thanks everyone.   My problems were solved by following Peter D's
>> (offline) suggestion...
> That (offline) must have been unintentional. I usually try to keep
> discussions on the list, unless there is very good reason not to.
>
> In this particular case I was clearly speculating (the reply starts with
> "Hmm"!) and thus expecting that someone would know more than me and
> might chime In.

Given the number of times I have said it, I did assume that packages would 
have been re-installed for 2.6.0.  So let me say it once again ...

      **** Several packages do not work if installed under R < 2.6.0. ****

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From d.firth at warwick.ac.uk  Tue Oct  9 13:48:11 2007
From: d.firth at warwick.ac.uk (David Firth)
Date: Tue, 9 Oct 2007 12:48:11 +0100
Subject: [Rd] misbehaviour of some tk windows, R 2.6.0 on SUSE 10.1?
Message-ID: <200710091248.12073.d.firth@warwick.ac.uk>

I don't know whether this is specific to (my installation 
of) SUSE 10.1, or is more general.  

With R 2.6.0, I am finding that some widgets made through 
the tcltk package are having problems which become evident 
through scrollbar activity.  An example is demo(tkfaq) -- 
see below.  To reproduce the problem, I do the following: 
after the tk window appears, hold down the "scroll-down" 
tab at the foot of the window for a few seconds, then 
release.  If scrolling stops (as it should, if all is 
working correctly), do the same thing again.  Repeating 
this 2 or 3 times usually results in uncontrolled 
(unstoppable) scrolling activity; and closing the window 
when that happens delivers the errors that appear in the 
transcript below.

My R 2.6.0 was built on my own system,

OS:  SUSE linux 10.1
tcl: 8.4.12-14
tk:  8.4.12-14
gcc: 4.1.0-25

Since I had not seen this behaviour with previous versions 
of R, I did a check with R 2.5.1: a fresh build today of R 
2.5.1 on the same system does not appear to have the same 
problem.

Any ideas?  Is anyone else seeing this behaviour?

David


----------------------------------------
david at blackbox2:~> R --vanilla

R version 2.6.0 (2007-10-03)
Copyright (C) 2007 The R Foundation for Statistical 
Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> sessionInfo()
R version 2.6.0 (2007-10-03) 
i686-pc-linux-gnu 

locale:
LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  
methods   base     

loaded via a namespace (and not attached):
[1] rcompgen_0.1-15
> library(tcltk)
Loading Tcl/Tk interface ... done
> demo(tkfaq)


	demo(tkfaq)
	---- ~~~~~

Type  <Return>	 to start : 

> require(tcltk) || stop("tcltk support is absent")
[1] TRUE

> local({
+ 
+     tt <- tktoplevel()
+     tkwm.title(tt, "R FAQ")
+ #    Gave tiny font on some systems
+ #    txt <- tktext(tt, bg="white", font="courier")
+     txt <- tktext(tt, bg="white")
+     scr <- tkscrollbar(tt, repeatinterval=5,
+        .... [TRUNCATED] 
******************************************************
 The source for this demo can be found in the file:
 /home/david/lib/R/library/tcltk/demo/tkfaq.R 
******************************************************
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.1".

Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.2".

Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.2".

Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.2".

Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.2".

Error in structure(.External("dotTclObjv", objv, PACKAGE 
= "tcltk"), class = "tclObj") : 
  [tcl] invalid command name ".1.2".

>


From ligges at statistik.uni-dortmund.de  Tue Oct  9 15:10:16 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Oct 2007 15:10:16 +0200
Subject: [Rd] Package compile under Windows on 2.6.0
In-Reply-To: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>
References: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>
Message-ID: <470B7DB8.3080204@statistik.uni-dortmund.de>

It works for me up to that point, but I do not have the real Rtools 
setup running. So you have the

I'd propose to start with a package that already passes checks on 
Windows. And then go the harder way to a package that shows problems ...


Iago Mosqueira wrote:
> Dear all,
> 
> We are experiencing some trouble when compiling R packages using R
> 2.6.0 and the new Rtools installer under Windows XP.
> 
> (1) First, compiling any package using the new setup stops with an
> errorrelated to some "/" issue on the inst folder. This folder only
> contains a CITATION file
> 
> ---------- Making package FLCore ------------
>  adding build stamp to DESCRIPTION
>  installing NAMESPACE file and metadata
>  making DLL ...
> making FLCoreClasses.d from FLCoreClasses.cpp
> g++-sjlj   -Ic:/progra~1/r/r-2.6.0/include    -Wall -O2  -c
> FLCoreClasses.cpp -o FLCoreClasses.o
> windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED" -I
> c:/progra~1/r/r-2.6.0/include  -i FLCore_res.rc -o FLCore_res.o
> g++-sjlj   -shared -s  -o FLCore.dll FLCore.def FLCoreClasses.o
> FLCore_res.o  -Lc:/progra~1/r/r-2.6.0/bin    -lR
>  ... DLL made
>  installing DLL
>  installing R files
>  installing inst files
> rm: failed to get attributes of `/': No such file or directory

Are the permissions alright?


> rm: failed to get attributes of `/': No such file or directory
>  installing data files
> rm: failed to get attributes of `/': No such file or directory
> make[2]: *** [C:/Sandbox/R260built/FLCore.Rcheck/FLCore/data] Error 1
> make[1]: *** [all] Error 2
> make: *** [pkg-FLCore] Error 2
> *** Installation of FLCore failed ***
> 
> (2) Testing with the previous Rtoolset with updated MinGW and Perl, a
> package from CRAN can be compiled (VR), but our package now fails with
> 
> ---------- Making package FLCore ------------
>   adding build stamp to DESCRIPTION
>   installing NAMESPACE file and metadata
>   installing R files
>   installing inst files
>   installing data files
>   installing man source files
>   installing indices
> Error in eval(expr, envir, enclos) : could not find function "setClass"


Have you imported the Namespace? Whcih version of your package are you 
talking about?


Best,
uwe

> Error: unable to load R code in package 'FLCore'
> Execution halted
> make[2]: *** [indices] Error 1
> make[1]: *** [all] Error 2
> make: *** [pkg-FLCore] Error 2
> *** Installation of FLCore failed ***
> 
> methods is loaded trhough a require(methods) inside an .onLoad call.
> 
> (3) The package compiles on a Linux machine with R 2.6.0
> 
> Is there any issue with MinGW or the Rtools he should consider?
> 
> Many thanks,
> 
> 
> Iago
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From iago.mosqueira at gmail.com  Tue Oct  9 15:15:39 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Tue, 9 Oct 2007 15:15:39 +0200
Subject: [Rd] Package compile under Windows on 2.6.0
In-Reply-To: <470B7DB8.3080204@statistik.uni-dortmund.de>
References: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>
	<470B7DB8.3080204@statistik.uni-dortmund.de>
Message-ID: <dba1e14b0710090615r3bf5ad42o99fcc746103a4952@mail.gmail.com>

On 09/10/2007, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> It works for me up to that point, but I do not have the real Rtools
> setup running. So you have the
>
> I'd propose to start with a package that already passes checks on
> Windows. And then go the harder way to a package that shows problems ...

This is the basic package of our library, so we need this one before
others can be tested.

>
> Iago Mosqueira wrote:
> > Dear all,
> >
> > We are experiencing some trouble when compiling R packages using R
> > 2.6.0 and the new Rtools installer under Windows XP.
> >
> > (1) First, compiling any package using the new setup stops with an
> > errorrelated to some "/" issue on the inst folder. This folder only
> > contains a CITATION file
> >
> > ---------- Making package FLCore ------------
> >  adding build stamp to DESCRIPTION
> >  installing NAMESPACE file and metadata
> >  making DLL ...
> > making FLCoreClasses.d from FLCoreClasses.cpp
> > g++-sjlj   -Ic:/progra~1/r/r-2.6.0/include    -Wall -O2  -c
> > FLCoreClasses.cpp -o FLCoreClasses.o
> > windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED" -I
> > c:/progra~1/r/r-2.6.0/include  -i FLCore_res.rc -o FLCore_res.o
> > g++-sjlj   -shared -s  -o FLCore.dll FLCore.def FLCoreClasses.o
> > FLCore_res.o  -Lc:/progra~1/r/r-2.6.0/bin    -lR
> >  ... DLL made
> >  installing DLL
> >  installing R files
> >  installing inst files
> > rm: failed to get attributes of `/': No such file or directory
>
> Are the permissions alright?

Should be, works in Linux and never had problems before, but I'll check.

> > rm: failed to get attributes of `/': No such file or directory
> >  installing data files
> > rm: failed to get attributes of `/': No such file or directory
> > make[2]: *** [C:/Sandbox/R260built/FLCore.Rcheck/FLCore/data] Error 1
> > make[1]: *** [all] Error 2
> > make: *** [pkg-FLCore] Error 2
> > *** Installation of FLCore failed ***
> >
> > (2) Testing with the previous Rtoolset with updated MinGW and Perl, a
> > package from CRAN can be compiled (VR), but our package now fails with
> >
> > ---------- Making package FLCore ------------
> >   adding build stamp to DESCRIPTION
> >   installing NAMESPACE file and metadata
> >   installing R files
> >   installing inst files
> >   installing data files
> >   installing man source files
> >   installing indices
> > Error in eval(expr, envir, enclos) : could not find function "setClass"
>
>
> Have you imported the Namespace? Whcih version of your package are you
> talking about?

Until now the only reference to methods was on the onLoad call, but I
did try explicitely importing the methods namespace. It made no
difference

Thanks,


Iago

>
> Best,
> uwe
>
> > Error: unable to load R code in package 'FLCore'
> > Execution halted
> > make[2]: *** [indices] Error 1
> > make[1]: *** [all] Error 2
> > make: *** [pkg-FLCore] Error 2
> > *** Installation of FLCore failed ***
> >
> > methods is loaded trhough a require(methods) inside an .onLoad call.
> >
> > (3) The package compiles on a Linux machine with R 2.6.0
> >
> > Is there any issue with MinGW or the Rtools he should consider?
> >
> > Many thanks,
> >
> >
> > Iago
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From P.Dalgaard at biostat.ku.dk  Tue Oct  9 20:52:53 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 09 Oct 2007 20:52:53 +0200
Subject: [Rd] misbehaviour of some tk windows, R 2.6.0 on SUSE 10.1?
In-Reply-To: <200710091248.12073.d.firth@warwick.ac.uk>
References: <200710091248.12073.d.firth@warwick.ac.uk>
Message-ID: <470BCE05.9070109@biostat.ku.dk>

David Firth wrote:
> I don't know whether this is specific to (my installation 
> of) SUSE 10.1, or is more general.  
>
> With R 2.6.0, I am finding that some widgets made through 
> the tcltk package are having problems which become evident 
> through scrollbar activity.  An example is demo(tkfaq) -- 
> see below.  To reproduce the problem, I do the following: 
> after the tk window appears, hold down the "scroll-down" 
> tab at the foot of the window for a few seconds, then 
> release.  If scrolling stops (as it should, if all is 
> working correctly), do the same thing again.  Repeating 
> this 2 or 3 times usually results in uncontrolled 
> (unstoppable) scrolling activity; and closing the window 
> when that happens delivers the errors that appear in the 
> transcript below.
>
> My R 2.6.0 was built on my own system,
>
> OS:  SUSE linux 10.1
> tcl: 8.4.12-14
> tk:  8.4.12-14
> gcc: 4.1.0-25
>
> Since I had not seen this behaviour with previous versions 
> of R, I did a check with R 2.5.1: a fresh build today of R 
> 2.5.1 on the same system does not appear to have the same 
> problem.
>
> Any ideas?  Is anyone else seeing this behaviour?
>
> David
>   

Looks a bit nasty. I see it on SUSE 10.2 as well. Increasing the
repeatinterval setting for the scrollbar helps, but even at a setting of
50, I still see the effect. It is usually stoppable with the middle
button over the trough.
The error message is what you'd expect from killing a window while
something is trying to talk to widgets inside of it. The details of the
popup dialog is a little more informative:

    while executing
"$w cget -repeatinterval"
    (procedure "tk::ScrollSelect" line 12)
    invoked from within
"tk::ScrollSelect .3.2 arrow2 again"
    ("after" script)

I think there's a clue in there. It has the hallmarks of a race
condition: As I understand it the autorepeat feature runs an "after"
script which effectively presses the arrow again 5 ms later, invoking
another "after" script, etc. A button release is supposed to kill the
after script, but it might not do so in time, in which case it may try
to kill something that already died, etc.

Can't offhand see that we did anything to the event loop that could
cause this, though.
>
> ----------------------------------------
> david at blackbox2:~> R --vanilla
>
> R version 2.6.0 (2007-10-03)
> Copyright (C) 2007 The R Foundation for Statistical 
> Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>   
>> sessionInfo()
>>     
> R version 2.6.0 (2007-10-03) 
> i686-pc-linux-gnu 
>
> locale:
> LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  
> methods   base     
>
> loaded via a namespace (and not attached):
> [1] rcompgen_0.1-15
>   
>> library(tcltk)
>>     
> Loading Tcl/Tk interface ... done
>   
>> demo(tkfaq)
>>     
>
>
> 	demo(tkfaq)
> 	---- ~~~~~
>
> Type  <Return>	 to start : 
>
>   
>> require(tcltk) || stop("tcltk support is absent")
>>     
> [1] TRUE
>
>   
>> local({
>>     
> + 
> +     tt <- tktoplevel()
> +     tkwm.title(tt, "R FAQ")
> + #    Gave tiny font on some systems
> + #    txt <- tktext(tt, bg="white", font="courier")
> +     txt <- tktext(tt, bg="white")
> +     scr <- tkscrollbar(tt, repeatinterval=5,
> +        .... [TRUNCATED] 
> ******************************************************
>  The source for this demo can be found in the file:
>  /home/david/lib/R/library/tcltk/demo/tkfaq.R 
> ******************************************************
>   
>> Error in structure(.External("dotTclObjv", objv, PACKAGE 
>>     
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.1".
>
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.2".
>
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.2".
>
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.2".
>
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.2".
>
> Error in structure(.External("dotTclObjv", objv, PACKAGE 
> = "tcltk"), class = "tclObj") : 
>   [tcl] invalid command name ".1.2".
>
>   
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Tue Oct  9 22:31:45 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 09 Oct 2007 22:31:45 +0200
Subject: [Rd] misbehaviour of some tk windows, R 2.6.0 on SUSE 10.1?
In-Reply-To: <470BCE05.9070109@biostat.ku.dk>
References: <200710091248.12073.d.firth@warwick.ac.uk>
	<470BCE05.9070109@biostat.ku.dk>
Message-ID: <470BE531.3090701@biostat.ku.dk>

Peter Dalgaard wrote:
> David Firth wrote:
>   
>> I don't know whether this is specific to (my installation 
>> of) SUSE 10.1, or is more general.  
>>
>> With R 2.6.0, I am finding that some widgets made through 
>> the tcltk package are having problems which become evident 
>> through scrollbar activity.  An example is demo(tkfaq) -- 
>> see below.  To reproduce the problem, I do the following: 
>> after the tk window appears, hold down the "scroll-down" 
>> tab at the foot of the window for a few seconds, then 
>> release.  If scrolling stops (as it should, if all is 
>> working correctly), do the same thing again.  Repeating 
>> this 2 or 3 times usually results in uncontrolled 
>> (unstoppable) scrolling activity; and closing the window 
>> when that happens delivers the errors that appear in the 
>> transcript below.
>>
>> My R 2.6.0 was built on my own system,
>>
>> OS:  SUSE linux 10.1
>> tcl: 8.4.12-14
>> tk:  8.4.12-14
>> gcc: 4.1.0-25
>>
>> Since I had not seen this behaviour with previous versions 
>> of R, I did a check with R 2.5.1: a fresh build today of R 
>> 2.5.1 on the same system does not appear to have the same 
>> problem.
>>
>> Any ideas?  Is anyone else seeing this behaviour?
>>
>> David
>>   
>>     
>
> Looks a bit nasty. I see it on SUSE 10.2 as well. Increasing the
> repeatinterval setting for the scrollbar helps, but even at a setting of
> 50, I still see the effect. It is usually stoppable with the middle
> button over the trough.
> The error message is what you'd expect from killing a window while
> something is trying to talk to widgets inside of it. The details of the
> popup dialog is a little more informative:
>
>     while executing
> "$w cget -repeatinterval"
>     (procedure "tk::ScrollSelect" line 12)
>     invoked from within
> "tk::ScrollSelect .3.2 arrow2 again"
>     ("after" script)
>
> I think there's a clue in there. It has the hallmarks of a race
> condition: As I understand it the autorepeat feature runs an "after"
> script which effectively presses the arrow again 5 ms later, invoking
> another "after" script, etc. A button release is supposed to kill the
> after script, but it might not do so in time, in which case it may try
> to kill something that already died, etc.
>
> Can't offhand see that we did anything to the event loop that could
> cause this, though.
>   
Exactly the same behaviour on Fedora 7. Looping scrolling with 2.6.0+, 
no probs with 2.5.1.

Can probably eliminate OS issues and hardware then (2x3.2GHz, 64 bit 
SUSE vs. 600MHz, 32bit Fedora).  Argh....

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jfox at mcmaster.ca  Wed Oct 10 04:07:06 2007
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 9 Oct 2007 22:07:06 -0400
Subject: [Rd] misbehaviour of some tk windows, R 2.6.0 on SUSE 10.1?
In-Reply-To: <470BE531.3090701@biostat.ku.dk>
Message-ID: <20071010020709.MPBJ1617.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter and David,

For what it's worth, I observe this behaviour after upgrading to R 2.6.0
under Ubuntu 7.04. When David previously reported the problem to me, I
tested on R 2.5.1 (again with Ubuntu 7.04) and did not observe the problem.

Regards,
 John

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Tuesday, October 09, 2007 4:32 PM
> To: David Firth
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] misbehaviour of some tk windows, R 2.6.0 on 
> SUSE 10.1?
> 
> Peter Dalgaard wrote:
> > David Firth wrote:
> >   
> >> I don't know whether this is specific to (my installation
> >> of) SUSE 10.1, or is more general.  
> >>
> >> With R 2.6.0, I am finding that some widgets made through 
> the tcltk 
> >> package are having problems which become evident through scrollbar 
> >> activity.  An example is demo(tkfaq) -- see below.  To 
> reproduce the 
> >> problem, I do the following:
> >> after the tk window appears, hold down the "scroll-down" 
> >> tab at the foot of the window for a few seconds, then release.  If 
> >> scrolling stops (as it should, if all is working 
> correctly), do the 
> >> same thing again.  Repeating this 2 or 3 times usually results in 
> >> uncontrolled
> >> (unstoppable) scrolling activity; and closing the window when that 
> >> happens delivers the errors that appear in the transcript below.
> >>
> >> My R 2.6.0 was built on my own system,
> >>
> >> OS:  SUSE linux 10.1
> >> tcl: 8.4.12-14
> >> tk:  8.4.12-14
> >> gcc: 4.1.0-25
> >>
> >> Since I had not seen this behaviour with previous versions of R, I 
> >> did a check with R 2.5.1: a fresh build today of R
> >> 2.5.1 on the same system does not appear to have the same problem.
> >>
> >> Any ideas?  Is anyone else seeing this behaviour?
> >>
> >> David
> >>   
> >>     
> >
> > Looks a bit nasty. I see it on SUSE 10.2 as well. Increasing the 
> > repeatinterval setting for the scrollbar helps, but even at 
> a setting 
> > of 50, I still see the effect. It is usually stoppable with 
> the middle 
> > button over the trough.
> > The error message is what you'd expect from killing a window while 
> > something is trying to talk to widgets inside of it. The details of 
> > the popup dialog is a little more informative:
> >
> >     while executing
> > "$w cget -repeatinterval"
> >     (procedure "tk::ScrollSelect" line 12)
> >     invoked from within
> > "tk::ScrollSelect .3.2 arrow2 again"
> >     ("after" script)
> >
> > I think there's a clue in there. It has the hallmarks of a race
> > condition: As I understand it the autorepeat feature runs an "after"
> > script which effectively presses the arrow again 5 ms 
> later, invoking 
> > another "after" script, etc. A button release is supposed 
> to kill the 
> > after script, but it might not do so in time, in which case 
> it may try 
> > to kill something that already died, etc.
> >
> > Can't offhand see that we did anything to the event loop that could 
> > cause this, though.
> >   
> Exactly the same behaviour on Fedora 7. Looping scrolling 
> with 2.6.0+, no probs with 2.5.1.
> 
> Can probably eliminate OS issues and hardware then (2x3.2GHz, 
> 64 bit SUSE vs. 600MHz, 32bit Fedora).  Argh....
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ripley at stats.ox.ac.uk  Wed Oct 10 14:57:59 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Oct 2007 13:57:59 +0100 (BST)
Subject: [Rd] Package compile under Windows on 2.6.0
In-Reply-To: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>
References: <dba1e14b0710090043u726b36bbt3af4117c71bf7110@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710101354060.19645@gannet.stats.ox.ac.uk>

An on-list followup after some off-list rounds of correspondence.

The problem 2) was that packages defining S4 classes/methods need to be 
installed to use lazy loading (or SaveImage, but that is deprecated, and 
removed in R-devel).  This package had not specified lazy loading, and the 
automated guesser was choosing lazyloading on Linux and not on Windows.

On Tue, 9 Oct 2007, Iago Mosqueira wrote:

> Dear all,
>
> We are experiencing some trouble when compiling R packages using R
> 2.6.0 and the new Rtools installer under Windows XP.
>
> (1) First, compiling any package using the new setup stops with an
> errorrelated to some "/" issue on the inst folder. This folder only
> contains a CITATION file
>
> ---------- Making package FLCore ------------
> adding build stamp to DESCRIPTION
> installing NAMESPACE file and metadata
> making DLL ...
> making FLCoreClasses.d from FLCoreClasses.cpp
> g++-sjlj   -Ic:/progra~1/r/r-2.6.0/include    -Wall -O2  -c
> FLCoreClasses.cpp -o FLCoreClasses.o
> windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED" -I
> c:/progra~1/r/r-2.6.0/include  -i FLCore_res.rc -o FLCore_res.o
> g++-sjlj   -shared -s  -o FLCore.dll FLCore.def FLCoreClasses.o
> FLCore_res.o  -Lc:/progra~1/r/r-2.6.0/bin    -lR
> ... DLL made
> installing DLL
> installing R files
> installing inst files
> rm: failed to get attributes of `/': No such file or directory
> rm: failed to get attributes of `/': No such file or directory
> installing data files
> rm: failed to get attributes of `/': No such file or directory
> make[2]: *** [C:/Sandbox/R260built/FLCore.Rcheck/FLCore/data] Error 1
> make[1]: *** [all] Error 2
> make: *** [pkg-FLCore] Error 2
> *** Installation of FLCore failed ***
>
> (2) Testing with the previous Rtoolset with updated MinGW and Perl, a
> package from CRAN can be compiled (VR), but our package now fails with
>
> ---------- Making package FLCore ------------
>  adding build stamp to DESCRIPTION
>  installing NAMESPACE file and metadata
>  installing R files
>  installing inst files
>  installing data files
>  installing man source files
>  installing indices
> Error in eval(expr, envir, enclos) : could not find function "setClass"
> Error: unable to load R code in package 'FLCore'
> Execution halted
> make[2]: *** [indices] Error 1
> make[1]: *** [all] Error 2
> make: *** [pkg-FLCore] Error 2
> *** Installation of FLCore failed ***
>
> methods is loaded trhough a require(methods) inside an .onLoad call.
>
> (3) The package compiles on a Linux machine with R 2.6.0
>
> Is there any issue with MinGW or the Rtools he should consider?
>
> Many thanks,
>
>
> Iago
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Wed Oct 10 16:14:23 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 10 Oct 2007 16:14:23 +0200
Subject: [Rd] Bug repository temporarily stalled
Message-ID: <470CDE3F.1000300@biostat.ku.dk>

As part of a system upgrade just before Oct 1, the Dept. of Public
Health no longer uses sendmail for incoming mail.

This, unfortunately, also killed all user-level procmail filtering and
hence also the r-bugs mail interface, so reports are being received but
not processed. Now that they have realized it, the IT guys are working
on a fix, so please have a little patience....

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From btyner at gmail.com  Wed Oct 10 16:35:24 2007
From: btyner at gmail.com (btyner at gmail.com)
Date: Wed, 10 Oct 2007 16:35:24 +0200 (CEST)
Subject: [Rd] corMatrix crashes with corARMA structure (PR#9952)
Message-ID: <20071010143524.E4A3F288008C@mail.pubhealth.ku.dk>

Full_Name: Benjamin Tyner
Version: 2.6.0 RC 2007-10-01 r43043
OS: WinXP
Submission from: (NULL) (171.161.224.10)


platform       i386-pc-mingw32                       
arch           i386                                  
os             mingw32                               
system         i386, mingw32                         
status         RC                                    
major          2                                     
minor          6.0                                   
year           2007                                  
month          10                                    
day            01                                    
svn rev        43043                                 
language       R                                     
version.string R version 2.6.0 RC (2007-10-01 r43043)

I have seen this in other versions/platforms as well. Brian Ripley informs me
the segfault is in corStruct.c

Code to reproduce:

n <- 100

# example from Box and Jenkins p. 83
arcoefs <- c(0.8)
macoefs <- c(-0.6)
p <- length(arcoefs)
q <- length(macoefs)

require(nlme)
tmp <- corARMA(value=c(arcoefs,macoefs), form=~1, p=p, q=q)
Sigma <- corMatrix(tmp, covariate = 1:n) # segfault


From btyner at gmail.com  Wed Oct 10 17:04:16 2007
From: btyner at gmail.com (btyner at gmail.com)
Date: Wed, 10 Oct 2007 17:04:16 +0200 (CEST)
Subject: [Rd] corMatrix crashes with corARMA structure (PR#9982)
Message-ID: <20071010150416.ECE2C2834612@mail.pubhealth.ku.dk>

Full_Name: Benjamin Tyner
Version: 2.6.0 RC 2007-10-01 r43043
OS: WinXP
Submission from: (NULL) (171.161.224.10)


platform       i386-pc-mingw32                       
arch           i386                                  
os             mingw32                               
system         i386, mingw32                         
status         RC                                    
major          2                                     
minor          6.0                                   
year           2007                                  
month          10                                    
day            01                                    
svn rev        43043                                 
language       R                                     
version.string R version 2.6.0 RC (2007-10-01 r43043)

I have seen this in other versions/platforms as well. Brian Ripley informs me
the segfault is in corStruct.c

Code to reproduce:

n <- 100

# example from Box and Jenkins p. 83
arcoefs <- c(0.8)
macoefs <- c(-0.6)
p <- length(arcoefs)
q <- length(macoefs)

require(nlme)
tmp <- corARMA(value=c(arcoefs,macoefs), form=~1, p=p, q=q)
Sigma <- corMatrix(tmp, covariate = 1:n) # segfault


From chris.bainbridge at gmail.com  Wed Oct 10 16:35:25 2007
From: chris.bainbridge at gmail.com (chris.bainbridge at gmail.com)
Date: Wed, 10 Oct 2007 16:35:25 +0200 (CEST)
Subject: [Rd] rendering dashed steps produces solid horizontal lines
	(PR#9953)
Message-ID: <20071010143525.A33A1288008C@mail.pubhealth.ku.dk>

Full_Name: Chris Bainbridge
Version: 2.2.1
OS: Linux
Submission from: (NULL) (86.157.4.96)


The following python script will render two pdf files, one with lines and one
with steps. The pdf with steps (s.pdf) renders the horizontal line as a solid
when it should be dotted as in lpdf. It seems as though R tries to render every
data point individually when using steps, but manages to join them all together
as a straight line when using lines.

#!/usr/bin/python                                                               
                  
import os                                                                       
                  
                                                                                
                  
f=open('x.txt','w')                                                             
                  
i=0                                                                             
                  
f.write('x y\n')                                                                
                  
while i<100:                                                                    
                  
    f.write('%f %f\n'%(i,0.5))                                                  
                  
    i+=1                                                                        
                  
f.close()                                                                       
                  
rscr="""pdf('%s.pdf')                                                           
                  
d <- read.table('x.txt', header=T)                                              
                  
attach(d)                                                                       
                  
plot(x,y, bty='n', las=1, lty=2,type='%s')                                      
                  
"""                                                                             
                  
f=open('l.r','w')                                                               
                  
f.write(rscr%('l','l'))                                                         
                  
f.close()                                                                       
                  
os.system('R -q --no-save < l.r')                                               
                  
f=open('s.r','w')                                                               
                  
f.write(rscr%('s','s'))                                                         
                  
f.close()                                                                       
                  
os.system('R -q --no-save < s.r')


From dolanp at science.oregonstate.edu  Wed Oct 10 16:35:44 2007
From: dolanp at science.oregonstate.edu (dolanp at science.oregonstate.edu)
Date: Wed, 10 Oct 2007 16:35:44 +0200 (CEST)
Subject: [Rd] gregexpr (PR#9965)
Message-ID: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>

Full_Name: Peter Dolan
Version: 2.5.1
OS: Windows
Submission from: (NULL) (128.193.227.43)


gregexpr does not find all matching substrings if the substrings overlap:

> gregexpr("abab","ababab")
[[1]]
[1] 1
attr(,"match.length")
[1] 4

It does work correctly in Version 2.3.1 under linux.


From dominique.couturier at mac.com  Wed Oct 10 16:35:30 2007
From: dominique.couturier at mac.com (dominique.couturier at mac.com)
Date: Wed, 10 Oct 2007 16:35:30 +0200 (CEST)
Subject: [Rd] R-2.6.0> problem to load library(stats) (PR#9956)
Message-ID: <20071010143530.53864288008C@mail.pubhealth.ku.dk>

Hello,

I just installed R-2.6.0 on my computer (OSX 10.4.10, ppc) and get  
the following message when I try to load the library stats:

 > library(stats)
Error in dyn.load(file, ...) :
   kann shared library '/Library/Frameworks/R.framework/Resources/ 
library/stats/libs/ppc/stats.so' nicht laden:
  dlopen(/Library/Frameworks/R.framework/Resources/library/stats/libs/ 
ppc/stats.so, 6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
   Referenced from: /Library/Frameworks/R.framework/Resources/library/ 
stats/libs/ppc/stats.so
   Reason: image not found
Fehler: Laden von Paket/Namensraum f"ur 'stats' fehlgeschlagen


This warning also appears at the startup of R.


Kind Regards,
DlC


From guillot at agroparistech.fr  Wed Oct 10 16:35:41 2007
From: guillot at agroparistech.fr (guillot at agroparistech.fr)
Date: Wed, 10 Oct 2007 16:35:41 +0200 (CEST)
Subject: [Rd] package Geneland / Rgui under windows (PR#9964)
Message-ID: <20071010143541.CF35F28800A8@mail.pubhealth.ku.dk>

Full_Name: Gilles Guillot
Version: 2.6.0
OS: windows XP professional
Submission from: (NULL) (129.240.88.50)


This sequence of command does not work in the R gui 2.6.0:

library(Geneland)

set.seed(1)

data <- simdata(nindiv=200,
                coord.lim=c(0,1,0,1) ,
                number.nuclei=5 ,
                allele.numbers=rep(10,20),
                IBD=FALSE,
                npop=2,
                give.tess.grid=FALSE)

geno <- data$genotypes
coord <- t(data$coord.indiv)

path.mcmc <- paste(tempdir(),"/",sep="") 

set.seed(1)
mcmcFmodel(coordinates=coord,
           genotypes=geno,
           path.mcmc=path.mcmc,
           rate.max=10,
           delta.coord=0,
           npopmin=1,
           npopinit=5,
           npopmax=5,
           nb.nuclei.max=50,
           nit=500,
           thinning=1,
           freq.model="Dirichlet",
           varnpop=FALSE,
           spatial=TRUE)


the call to mcmcFmodel freezes R

The same sequence of command works in the R command line of R 2.6.0 
and also in the R GUI of 2.5.1


From schlather at math.uni-goettingen.de  Wed Oct 10 16:35:18 2007
From: schlather at math.uni-goettingen.de (schlather at math.uni-goettingen.de)
Date: Wed, 10 Oct 2007 16:35:18 +0200 (CEST)
Subject: [Rd] documentation of .C (PR#9948)
Message-ID: <20071010143518.573DC288008C@mail.pubhealth.ku.dk>

Full_Name: Martin Schlather
Version: R version 2.7.0 Under development (unstable) (2007-10-01 r43043)
OS: Linux
Submission from: (NULL) (91.3.209.203)


Hi,

There are 2 dangers with using 'DUP=FALSE' mentioned:
  * formal arguments
  * lists

Would you also mention a third one, namely
that values in R are now only referenced  whenever 
possible and not always copied; hence .C(..., DUP=FALSE) 
may change the values of other local variables.

E.g., with C code 
   void addone(double *x) {  *x = *x + 1; }

you get 
  
  x <- as.double(1)
  y <- x
  .C("addone", x, PACKAGE="test", DUP=FALSE)
  print(c(x,y))
#[1] 2 2

  
  x <- as.double(1)
  y <- as.double(x)
 .C("addone", x, PACKAGE="test", DUP=FALSE)
  print(c(x,y))
#[1] 2 2 

  x <- as.double(1)
  y <- as.integer(x)
 .C("addone", x, PACKAGE="test", DUP=FALSE)
  print(c(x,y))
#[1] 2 1

Many thanks and kind regards,
Martin


From skylab.gupta at gmail.com  Wed Oct 10 16:35:13 2007
From: skylab.gupta at gmail.com (skylab.gupta at gmail.com)
Date: Wed, 10 Oct 2007 16:35:13 +0200 (CEST)
Subject: [Rd] pt inaccurate when x is close to 0 (PR#9945)
Message-ID: <20071010143513.11DD128800A8@mail.pubhealth.ku.dk>

Full_Name: Skylab Gupta
Version: R version 2.5.1 (2007-06-27)
OS: Windows XP
Submission from: (NULL) (216.82.144.137)


Hello,

I have been playing around with the statistical distributions in R. I think the
computations for the cumulative distribution function of the students t
distribution in R are not very accurate.

For instance, the cdf of a students t distribution with 13 degrees of freedom at
1e-4 is reported in R as "0.5000391350986764"; from Mathematica, it seems the
correct value is "0.50003913510150055", only about 9 accurate digits reported in
R.

I also did the following from within R:

-------------
df<-seq(1,100,by=1)
y<-pt(1e-4,df)
z<-c(0.50003183098839799,0.50003535533895194,0.50003675525997071,0.50003749999985481,0.50003796066840744,0.50003827327749706,0.50003849914427922,0.50003866990364754,0.50003880349244212,0.50003891083995444,0.50003899897813187,0.50003907263208447,0.50003913510150055,0.50003918874627440,0.50003923531785055,0.50003927612461441,0.50003931217478748,0.50003934425324170,0.50003937297989520,0.50003939886014204,0.50003942229165621,0.50003944360703978,0.50003946308016112,0.50003948094039441,0.50003949738053710,0.50003951256485324,0.50003952663295181,0.50003953969680248,0.50003955185925653,0.50003956322006460,0.50003957385523301,0.50003958382054481,0.50003959318443636,0.50003960200394315,0.50003961032679112,0.50003961818144815,0.50003962562026172,0.50003963266089213,0.50003963934773465,0.50003964569404735,0.50003965173577758,0.50003965749688895,0.50003966298323521,0.50003966823056478,0.50003967322766096,0.50003967801868676,0.50003968260005904,0.50003968700228751,0.50003969121916547,0.500
 03969526955183,0.50003969915340063,0.50003970290428668,0.50003970650705731,0.50003970997149927,0.50003971332909936,0.50003971654204993,0.50003971964040972,0.50003972264367180,0.50003972553808163,0.50003972835715427,0.50003973106835642,0.50003973370765664,0.50003973624942966,0.50003973868896101,0.50003974107556448,0.50003974338818691,0.50003974563557085,0.50003974781567961,0.50003974993203681,0.50003975199594708,0.50003975399737965,0.50003975593675354,0.50003975782715593,0.50003975966389691,0.50003976145762119,0.50003976321975063,0.50003976489560775,0.50003976655049909,0.50003976818673812,0.50003976975798736,0.50003977127434285,0.50003977277055756,0.50003977423495483,0.50003977566285773,0.50003977705769798,0.50003977841313474,0.50003977975147973,0.50003978102874791,0.50003978230822732,0.50003978356836509,0.50003978477872879,0.50003978596096421,0.50003978713049724,0.50003978827577344,0.50003978935715154,0.50003979045422919,0.50003979153680134,0.50003979256756137,0.500039793589
 57851,0.50003979462027492)

plot(df,(y-z)/z, type="s")
-------------

In the above R code, df contains the 100 integers between 1-100, y contains the
cdf of the students t distribution computed at 1e-4 from R, for all the df
degrees of freedom; and z contains the correct values (to 17 decimal digits) of
the students t distribution cdf at 1e-4 computed from Mathematica; when I plot
the relative errors between the computed values from Mathematica and R, it seems
the relative errors are large; we get only about 10-12 digits of accuracy from R
rather than about 15 digits (all this assuming that the Mathematica computed
values are correct). This happens for all values close to 0 where the cdf is
evaluated.

I am working on Windows XP, and I installed a precompiled binary version of R.
The following information might also be useful:

---------------
> sessionInfo()
R version 2.5.1 (2007-06-27) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
"base"     

> version
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.1                         
year           2007                        
month          06                          
day            27                          
svn rev        42083                       
language       R                           
version.string R version 2.5.1 (2007-06-27)
---------------

Is there a reason for this loss of accuracy, or am I missing something here?
Thanks.


From Greg.Snow at intermountainmail.org  Wed Oct 10 17:48:30 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 10 Oct 2007 09:48:30 -0600
Subject: [Rd] gregexpr (PR#9965)
In-Reply-To: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>
References: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC80D22@LP-EXCHVS07.CO.IHC.COM>

If you want all the matches (including overlaps) then you could try one
of these:

> gregexpr("(?=abab)","ababab",perl=TRUE)
[[1]]
[1] 1 3
attr(,"match.length")
[1] 0 0

> gregexpr("ab(?=ab)","ababab",perl=TRUE)
[[1]]
[1] 1 3
attr(,"match.length")
[1] 2 2

The book "Mastering Regular Expressions" by Jeffrey Friedl has a lot of
detail on the hows and whys of regular expression matching.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> dolanp at science.oregonstate.edu
> Sent: Wednesday, October 10, 2007 8:36 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] gregexpr (PR#9965)
> 
> Full_Name: Peter Dolan
> Version: 2.5.1
> OS: Windows
> Submission from: (NULL) (128.193.227.43)
> 
> 
> gregexpr does not find all matching substrings if the 
> substrings overlap:
> 
> > gregexpr("abab","ababab")
> [[1]]
> [1] 1
> attr(,"match.length")
> [1] 4
> 
> It does work correctly in Version 2.3.1 under linux.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From sgiannerini at gmail.com  Wed Oct 10 17:55:43 2007
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 10 Oct 2007 17:55:43 +0200
Subject: [Rd] corMatrix crashes with corARMA structure (PR#9952)
In-Reply-To: <20071010143524.E4A3F288008C@mail.pubhealth.ku.dk>
References: <20071010143524.E4A3F288008C@mail.pubhealth.ku.dk>
Message-ID: <3c12769c0710100855u328d5ccexcff234ca0b174b5a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071010/7665d86c/attachment.pl 

From murdoch at stats.uwo.ca  Wed Oct 10 19:10:32 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 10 Oct 2007 13:10:32 -0400
Subject: [Rd] pt inaccurate when x is close to 0 (PR#9945)
In-Reply-To: <20071010143513.11DD128800A8@mail.pubhealth.ku.dk>
References: <20071010143513.11DD128800A8@mail.pubhealth.ku.dk>
Message-ID: <470D0788.4080307@stats.uwo.ca>

On 10/10/2007 10:35 AM, skylab.gupta at gmail.com wrote:
> Full_Name: Skylab Gupta
> Version: R version 2.5.1 (2007-06-27)
> OS: Windows XP
> Submission from: (NULL) (216.82.144.137)
> 
> 
> Hello,
> 
> I have been playing around with the statistical distributions in R. I think the
> computations for the cumulative distribution function of the students t
> distribution in R are not very accurate.
> 
> For instance, the cdf of a students t distribution with 13 degrees of freedom at
> 1e-4 is reported in R as "0.5000391350986764"; from Mathematica, it seems the
> correct value is "0.50003913510150055", only about 9 accurate digits reported in
> R.

As Charles Berry told you when this was posted to R-help, it looks as 
though it is Mathematica that is inaccurate.  For example, I would 
expect this plot to be smooth, and it is not in either R or Mathematica, 
but R is at least monotone:

# the Mathematica values
plot(diff(z[80:100]), type='l')

The R values
plot(diff(pt(1e-4, df=80:100)), type='l')

> 
> I also did the following from within R:
> 
> -------------
> df<-seq(1,100,by=1)
> y<-pt(1e-4,df)
> z<-c(0.50003183098839799,0.50003535533895194,0.50003675525997071,0.50003749999985481,0.50003796066840744,0.50003827327749706,0.50003849914427922,0.50003866990364754,0.50003880349244212,0.50003891083995444,0.50003899897813187,0.50003907263208447,0.50003913510150055,0.50003918874627440,0.50003923531785055,0.50003927612461441,0.50003931217478748,0.50003934425324170,0.50003937297989520,0.50003939886014204,0.50003942229165621,0.50003944360703978,0.50003946308016112,0.50003948094039441,0.50003949738053710,0.50003951256485324,0.50003952663295181,0.50003953969680248,0.50003955185925653,0.50003956322006460,0.50003957385523301,0.50003958382054481,0.50003959318443636,0.50003960200394315,0.50003961032679112,0.50003961818144815,0.50003962562026172,0.50003963266089213,0.50003963934773465,0.50003964569404735,0.50003965173577758,0.50003965749688895,0.50003966298323521,0.50003966823056478,0.50003967322766096,0.50003967801868676,0.50003968260005904,0.50003968700228751,0.50003969121916547,0.
500
>  03969526955183,0.50003969915340063,0.50003970290428668,0.50003970650705731,0.50003970997149927,0.50003971332909936,0.50003971654204993,0.50003971964040972,0.50003972264367180,0.50003972553808163,0.50003972835715427,0.50003973106835642,0.50003973370765664,0.50003973624942966,0.50003973868896101,0.50003974107556448,0.50003974338818691,0.50003974563557085,0.50003974781567961,0.50003974993203681,0.50003975199594708,0.50003975399737965,0.50003975593675354,0.50003975782715593,0.50003975966389691,0.50003976145762119,0.50003976321975063,0.50003976489560775,0.50003976655049909,0.50003976818673812,0.50003976975798736,0.50003977127434285,0.50003977277055756,0.50003977423495483,0.50003977566285773,0.50003977705769798,0.50003977841313474,0.50003977975147973,0.50003978102874791,0.50003978230822732,0.50003978356836509,0.50003978477872879,0.50003978596096421,0.50003978713049724,0.50003978827577344,0.50003978935715154,0.50003979045422919,0.50003979153680134,0.50003979256756137,0.500039793
589
>  57851,0.50003979462027492)
> 
> plot(df,(y-z)/z, type="s")
> -------------
> 
> In the above R code, df contains the 100 integers between 1-100, y contains the
> cdf of the students t distribution computed at 1e-4 from R, for all the df
> degrees of freedom; and z contains the correct values (to 17 decimal digits) of
> the students t distribution cdf at 1e-4 computed from Mathematica; when I plot
> the relative errors between the computed values from Mathematica and R, it seems
> the relative errors are large; we get only about 10-12 digits of accuracy from R
> rather than about 15 digits (all this assuming that the Mathematica computed
> values are correct).

It seems you are making a bad assumption.

Duncan Murdoch



  This happens for all values close to 0 where the cdf is
> evaluated.
> 
> I am working on Windows XP, and I installed a precompiled binary version of R.
> The following information might also be useful:
> 
> ---------------
>> sessionInfo()
> R version 2.5.1 (2007-06-27) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
> "base"     
> 
>> version
> platform       i386-pc-mingw32             
> arch           i386                        
> os             mingw32                     
> system         i386, mingw32               
> status                                     
> major          2                           
> minor          5.1                         
> year           2007                        
> month          06                          
> day            27                          
> svn rev        42083                       
> language       R                           
> version.string R version 2.5.1 (2007-06-27)
> ---------------
> 
> Is there a reason for this loss of accuracy, or am I missing something here?
> Thanks.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cberry at tajo.ucsd.edu  Wed Oct 10 20:03:22 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 10 Oct 2007 11:03:22 -0700
Subject: [Rd] pt inaccurate when x is close to 0 (PR#9945)
In-Reply-To: <470D0788.4080307@stats.uwo.ca>
References: <20071010143513.11DD128800A8@mail.pubhealth.ku.dk>
	<470D0788.4080307@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0710101036020.10430@tajo.ucsd.edu>

On Wed, 10 Oct 2007, Duncan Murdoch wrote:

> On 10/10/2007 10:35 AM, skylab.gupta at gmail.com wrote:
>> Full_Name: Skylab Gupta
>> Version: R version 2.5.1 (2007-06-27)
>> OS: Windows XP
>> Submission from: (NULL) (216.82.144.137)
>>
>>
>> Hello,
>>
>> I have been playing around with the statistical distributions in R. I think the
>> computations for the cumulative distribution function of the students t
>> distribution in R are not very accurate.
>>
>> For instance, the cdf of a students t distribution with 13 degrees of freedom at
>> 1e-4 is reported in R as "0.5000391350986764"; from Mathematica, it seems the
>> correct value is "0.50003913510150055", only about 9 accurate digits reported in
>> R.
>
> As Charles Berry told you when this was posted to R-help, it looks as
> though it is Mathematica that is inaccurate.  For example, I would
> expect this plot to be smooth, and it is not in either R or Mathematica,
> but R is at least monotone:
>
> # the Mathematica values
> plot(diff(z[80:100]), type='l')
>
> The R values
> plot(diff(pt(1e-4, df=80:100)), type='l')
>

Further, if one truly needs to get highly accurate values for

 	pt( near.zero, df )

recognize that dt(x, df ) is nearly quadratic around x==0 and dominated by 
a linear component for x > 0.

So, simple quadrature gets the area under the density for (0, near.zero] 
quite accurately. One knows that pt(0, df) is exactly 0.5, so this can be 
added to get the result.

This one point quadrature rule is accurate to better than 3e-14 for every 
df %in% 1:100 :

really.simple.values <- 0.5 +
 	sapply( 1:100, function(y) dt( 0.5e-04, y ) * 1e-04 )

Three point Gaussian quadrature (is overkill and) seems accurate up to 
machine precision.

Chuck

>>
>> I also did the following from within R:
>>
>> -------------
>> df<-seq(1,100,by=1)
>> y<-pt(1e-4,df)
>> z<-c(0.50003183098839799,0.50003535533895194,0.50003675525997071,0.50003749999985481,0.50003796066840744,0.50003827327749706,0.50003849914427922,0.50003866990364754,0.50003880349244212,0.50003891083995444,0.50003899897813187,0.50003907263208447,0.50003913510150055,0.50003918874627440,0.50003923531785055,0.50003927612461441,0.50003931217478748,0.50003934425324170,0.50003937297989520,0.50003939886014204,0.50003942229165621,0.50003944360703978,0.50003946308016112,0.50003948094039441,0.50003949738053710,0.50003951256485324,0.50003952663295181,0.50003953969680248,0.50003955185925653,0.50003956322006460,0.50003957385523301,0.50003958382054481,0.50003959318443636,0.50003960200394315,0.50003961032679112,0.50003961818144815,0.50003962562026172,0.50003963266089213,0.50003963934773465,0.50003964569404735,0.50003965173577758,0.50003965749688895,0.50003966298323521,0.50003966823056478,0.50003967322766096,0.50003967801868676,0.50003968260005904,0.50003968700228751,0.50003969121916547,0.
> 500
>>  03969526955183,0.50003969915340063,0.50003970290428668,0.50003970650705731,0.50003970997149927,0.50003971332909936,0.50003971654204993,0.50003971964040972,0.50003972264367180,0.50003972553808163,0.50003972835715427,0.50003973106835642,0.50003973370765664,0.50003973624942966,0.50003973868896101,0.50003974107556448,0.50003974338818691,0.50003974563557085,0.50003974781567961,0.50003974993203681,0.50003975199594708,0.50003975399737965,0.50003975593675354,0.50003975782715593,0.50003975966389691,0.50003976145762119,0.50003976321975063,0.50003976489560775,0.50003976655049909,0.50003976818673812,0.50003976975798736,0.50003977127434285,0.50003977277055756,0.50003977423495483,0.50003977566285773,0.50003977705769798,0.50003977841313474,0.50003977975147973,0.50003978102874791,0.50003978230822732,0.50003978356836509,0.50003978477872879,0.50003978596096421,0.50003978713049724,0.50003978827577344,0.50003978935715154,0.50003979045422919,0.50003979153680134,0.50003979256756137,0.500039793
> 589
>>  57851,0.50003979462027492)
>>
>> plot(df,(y-z)/z, type="s")
>> -------------
>>
>> In the above R code, df contains the 100 integers between 1-100, y contains the
>> cdf of the students t distribution computed at 1e-4 from R, for all the df
>> degrees of freedom; and z contains the correct values (to 17 decimal digits) of
>> the students t distribution cdf at 1e-4 computed from Mathematica; when I plot
>> the relative errors between the computed values from Mathematica and R, it seems
>> the relative errors are large; we get only about 10-12 digits of accuracy from R
>> rather than about 15 digits (all this assuming that the Mathematica computed
>> values are correct).
>
> It seems you are making a bad assumption.
>
> Duncan Murdoch
>
>
>
>  This happens for all values close to 0 where the cdf is
>> evaluated.
>>
>> I am working on Windows XP, and I installed a precompiled binary version of R.
>> The following information might also be useful:
>>
>> ---------------
>>> sessionInfo()
>> R version 2.5.1 (2007-06-27)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> States.1252;LC_MONETARY=English_United
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> "base"
>>
>>> version
>> platform       i386-pc-mingw32
>> arch           i386
>> os             mingw32
>> system         i386, mingw32
>> status
>> major          2
>> minor          5.1
>> year           2007
>> month          06
>> day            27
>> svn rev        42083
>> language       R
>> version.string R version 2.5.1 (2007-06-27)
>> ---------------
>>
>> Is there a reason for this loss of accuracy, or am I missing something here?
>> Thanks.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From tlumley at u.washington.edu  Wed Oct 10 20:10:50 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Oct 2007 11:10:50 -0700 (PDT)
Subject: [Rd] documentation of .C (PR#9948)
In-Reply-To: <20071010143518.573DC288008C@mail.pubhealth.ku.dk>
References: <20071010143518.573DC288008C@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710101109540.26217@homer24.u.washington.edu>

On Wed, 10 Oct 2007, schlather at math.uni-goettingen.de wrote:

> Full_Name: Martin Schlather
> Version: R version 2.7.0 Under development (unstable) (2007-10-01 r43043)
> OS: Linux
> Submission from: (NULL) (91.3.209.203)
>
>
> Hi,
>
> There are 2 dangers with using 'DUP=FALSE' mentioned:
>  * formal arguments
>  * lists
>
> Would you also mention a third one, namely
> that values in R are now only referenced  whenever
> possible and not always copied; hence .C(..., DUP=FALSE)
> may change the values of other local variables.
>

How about a warning like

"if you pass a local variable to .C/.Fortran with 
DUP=FALSE, your compiled code can alter the local variable and not just 
the copy in the return list. "

 	-thomas

(copied from ?.C, of course)


From simon.urbanek at r-project.org  Wed Oct 10 20:23:45 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 10 Oct 2007 14:23:45 -0400
Subject: [Rd] R-2.6.0> problem to load library(stats) (PR#9956)
In-Reply-To: <20071010143530.53864288008C@mail.pubhealth.ku.dk>
References: <20071010143530.53864288008C@mail.pubhealth.ku.dk>
Message-ID: <4263B2B0-4A8A-4429-A983-B9F71062DB5F@r-project.org>

Dominique,

please make sure you have the correct, current R binary from CRAN. It  
should have the MD5 hash of ff218b4e5687077c0078ca4948be1205 (for the  
full R). If it doesn't, please make sure you fetch it from another  
mirror. For a very brief period of time (less than 24h) there was a  
binary featuring the problem you list, but it was fixed immediately.

Cheers,
Simon


On Oct 10, 2007, at 10:35 AM, dominique.couturier at mac.com wrote:

> Hello,
>
> I just installed R-2.6.0 on my computer (OSX 10.4.10, ppc) and get
> the following message when I try to load the library stats:
>
>> library(stats)
> Error in dyn.load(file, ...) :
>    kann shared library '/Library/Frameworks/R.framework/Resources/
> library/stats/libs/ppc/stats.so' nicht laden:
>   dlopen(/Library/Frameworks/R.framework/Resources/library/stats/libs/
> ppc/stats.so, 6): Library not loaded: /usr/local/lib/libgfortran. 
> 2.dylib
>    Referenced from: /Library/Frameworks/R.framework/Resources/library/
> stats/libs/ppc/stats.so
>    Reason: image not found
> Fehler: Laden von Paket/Namensraum f"ur 'stats' fehlgeschlagen
>
>
> This warning also appears at the startup of R.
>
>
> Kind Regards,
> DlC
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Wed Oct 10 20:28:21 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Oct 2007 19:28:21 +0100 (BST)
Subject: [Rd] documentation of .C (PR#9948)
In-Reply-To: <20071010143518.573DC288008C@mail.pubhealth.ku.dk>
References: <20071010143518.573DC288008C@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710101737130.12592@gannet.stats.ox.ac.uk>

On Wed, 10 Oct 2007, schlather at math.uni-goettingen.de wrote:

> Full_Name: Martin Schlather
> Version: R version 2.7.0 Under development (unstable) (2007-10-01 r43043)
> OS: Linux
> Submission from: (NULL) (91.3.209.203)
>
>
> Hi,
>
> There are 2 dangers with using 'DUP=FALSE' mentioned:
>  * formal arguments
>  * lists
>
> Would you also mention a third one, namely
> that values in R are now only referenced  whenever
> possible and not always copied; hence .C(..., DUP=FALSE)
> may change the values of other local variables.

That has always been the case (depending on the meaning of 'possible'), 
and is part of the first point made.  It *does* give a circumstance in 
which other variables can be changed.  Spelling out all of those (and 
'local' is not really relevant) would be a mammoth task.

> E.g., with C code
>   void addone(double *x) {  *x = *x + 1; }
>
> you get
>
>  x <- as.double(1)
>  y <- x
>  .C("addone", x, PACKAGE="test", DUP=FALSE)
>  print(c(x,y))
> #[1] 2 2
>
>
>  x <- as.double(1)
>  y <- as.double(x)
> .C("addone", x, PACKAGE="test", DUP=FALSE)
>  print(c(x,y))
> #[1] 2 2
>
>  x <- as.double(1)
>  y <- as.integer(x)
> .C("addone", x, PACKAGE="test", DUP=FALSE)
>  print(c(x,y))
> #[1] 2 1

These are the result of changing an actual argument.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Bravington at csiro.au  Thu Oct 11 01:04:54 2007
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 11 Oct 2007 10:04:54 +1100
Subject: [Rd] slow load() in R2.6.0
Message-ID: <D79013E40FEF254AAF0D72DFC94F2748675EA3@extas4-hba.tas.csiro.au>

I'm encountering excruciatingly slow load times for character vectors in
R 2.6.0-- up to 30sec for a 15K file that contains a no-attributes
character vector of length ~1e4 and object size ~0.5MB. In R 2.5.1,
repeated loads of the same set of files are near-instantaneous.

The problem is proving tricky to reproduce consistently from scratch, so
I have attached the 3 files used in the examples below. If I create a
similar-looking object from scratch, then save it and re-load it a few
times, the problem doesn't always occur... at least not in that session.


FWIW I have noticed that the time taken to load seems to be roughly a
power of 2 of the "base slow load time"-- could be a red herring.

The problem seems specific to character vectors-- I noticed it with
entire workspaces and have whittled it down to char vecs only.

The example below is from a brand-new session with only the basic
packages loaded; delays in my real sessions are much longer.


Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623



Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> system.time( load( 'd:/r2.0/t1.rda'))
   user  system elapsed 
    0.5     0.0     0.5 
> system.time( load( 'd:/r2.0/t1.rda')) # same file; slower
   user  system elapsed 
    3.5     0.0     3.5 
> system.time( load( 'd:/r2.0/t1.rda'))
   user  system elapsed 
   4.13    0.00    4.13 
> system.time( load( 'd:/r2.0/t1.rda'))
   user  system elapsed 
   3.51    0.00    3.52 

> system.time( load( 'd:/r2.0/t2.rda'))  # different bigger file
   user  system elapsed 
   4.42    0.00    4.42 
> system.time( load( 'd:/r2.0/t2.rda')) # same file; slower
   user  system elapsed 
  10.44    0.00   10.44 
> system.time( load( 'd:/r2.0/t2.rda'))
   user  system elapsed 
  10.79    0.00   10.80 
> system.time( load( 'd:/r2.0/t2.rda'))
   user  system elapsed 
  10.39    0.00   10.41 
> system.time( load( 'd:/r2.0/t1.rda')) # the smaller file again; slower
   user  system elapsed 
  10.67    0.00   10.69 
> system.time( load( 'd:/r2.0/t3.rda')) # different smaller file
   user  system elapsed 
  10.51    0.00   10.52 
> system.time( load( 'd:/r2.0/t2.rda')) # now bigger file again: slower
   user  system elapsed 
  14.61    0.00   14.61 



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 6.0
 year = 2007
 month = 10
 day = 03
 svn rev = 43063
 language = R
 version.string = R version 2.6.0 (2007-10-03)

Windows XP (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MON
ETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

Search Path:
Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:utils, package:datasets, package:methods, Autoloads,
package:base

From ripley at stats.ox.ac.uk  Thu Oct 11 06:27:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Oct 2007 05:27:22 +0100 (BST)
Subject: [Rd] slow load() in R2.6.0
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F2748675EA3@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F2748675EA3@extas4-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.64.0710110443260.7258@gannet.stats.ox.ac.uk>

On Thu, 11 Oct 2007, Mark.Bravington at csiro.au wrote:

> I'm encountering excruciatingly slow load times for character vectors in
> R 2.6.0-- up to 30sec for a 15K file that contains a no-attributes
> character vector of length ~1e4 and object size ~0.5MB. In R 2.5.1,
> repeated loads of the same set of files are near-instantaneous.
>
> The problem is proving tricky to reproduce consistently from scratch, so
> I have attached the 3 files used in the examples below.

There was no attachment: since these are (I presume) binary files, can you 
not put them on a website (as suggested by the posting guide)?

> If I create a similar-looking object from scratch, then save it and 
> re-load it a few times, the problem doesn't always occur... at least not 
> in that session.
>
>
> FWIW I have noticed that the time taken to load seems to be roughly a
> power of 2 of the "base slow load time"-- could be a red herring.
>
> The problem seems specific to character vectors-- I noticed it with
> entire workspaces and have whittled it down to char vecs only.
>
> The example below is from a brand-new session with only the basic
> packages loaded; delays in my real sessions are much longer.

Can you please try R-patched or R-devel.  We've found and solved a couple 
of performance issues with creating STRSXPs, but with character vectors of 
the millions of elements.

I tried several examples of around 10000 elements and got times of at most 
0.05 secs in 2.6.0.  These included parts of those examples on which we 
had seen performance issues.

A few clues:

- even your base time is much slower than I would expect.

- you say  'a 15K file ... object size ~0.5MB'.  That's pretty phenomenal
   compression, and I am seeing file sizes more like 100Kb for objects that
   size.  Since object.size does take into account duplication, one way to
   get that would be to have all unique elements.  At ca 50bytes per
   element you would need an average string length of about 15 chars.  Such
   an object takes about 200Kb as a .rda file.


>
>
> Mark Bravington
> CSIRO Mathematical & Information Sciences
> Marine Laboratory
> Castray Esplanade
> Hobart 7001
> TAS
>
> ph (+61) 3 6232 5118
> fax (+61) 3 6232 5012
> mob (+61) 438 315 623
>
>
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> system.time( load( 'd:/r2.0/t1.rda'))
>   user  system elapsed
>    0.5     0.0     0.5
>> system.time( load( 'd:/r2.0/t1.rda')) # same file; slower
>   user  system elapsed
>    3.5     0.0     3.5
>> system.time( load( 'd:/r2.0/t1.rda'))
>   user  system elapsed
>   4.13    0.00    4.13
>> system.time( load( 'd:/r2.0/t1.rda'))
>   user  system elapsed
>   3.51    0.00    3.52
>
>> system.time( load( 'd:/r2.0/t2.rda'))  # different bigger file
>   user  system elapsed
>   4.42    0.00    4.42
>> system.time( load( 'd:/r2.0/t2.rda')) # same file; slower
>   user  system elapsed
>  10.44    0.00   10.44
>> system.time( load( 'd:/r2.0/t2.rda'))
>   user  system elapsed
>  10.79    0.00   10.80
>> system.time( load( 'd:/r2.0/t2.rda'))
>   user  system elapsed
>  10.39    0.00   10.41
>> system.time( load( 'd:/r2.0/t1.rda')) # the smaller file again; slower
>   user  system elapsed
>  10.67    0.00   10.69
>> system.time( load( 'd:/r2.0/t3.rda')) # different smaller file
>   user  system elapsed
>  10.51    0.00   10.52
>> system.time( load( 'd:/r2.0/t2.rda')) # now bigger file again: slower
>   user  system elapsed
>  14.61    0.00   14.61
>
>
>
> --please do not edit the information below--
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 6.0
> year = 2007
> month = 10
> day = 03
> svn rev = 43063
> language = R
> version.string = R version 2.6.0 (2007-10-03)
>
> Windows XP (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MON
> ETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>
> Search Path:
> Search Path:
> .GlobalEnv, package:stats, package:graphics, package:grDevices,
> package:utils, package:datasets, package:methods, Autoloads,
> package:base
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Bravington at csiro.au  Thu Oct 11 09:36:18 2007
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 11 Oct 2007 18:36:18 +1100
Subject: [Rd] slow load() in R2.6.0
Message-ID: <D79013E40FEF254AAF0D72DFC94F2748545C84@extas4-hba.tas.csiro.au>

Problem fixed by R-patched, thanks; see comments below.

>On Thu, 11 Oct 2007, Mark.Bravington at csiro.au wrote:
>
>> I'm encountering excruciatingly slow load times for character vectors

>> in R 2.6.0-- up to 30sec for a 15K file that contains a no-attributes

>> character vector of length ~1e4 and object size ~0.5MB. In R 2.5.1, 
>> repeated loads of the same set of files are near-instantaneous.
>>
>> The problem is proving tricky to reproduce consistently from scratch,

>> so I have attached the 3 files used in the examples below.
>
>There was no attachment: since these are (I presume) binary files, can
you 
>not put them on a website (as suggested by the posting guide)?

Sorry, I would have if I could, but can't at present. The attachments
got through OK to me at least, though. If anyone does have an interest
in the files, let me know off-list and I'll re-send as a zip or
somesuch.

>
>> If I create a similar-looking object from scratch, then save it and
>> re-load it a few times, the problem doesn't always occur... at least
not 
>> in that session.
>>
>>
>> FWIW I have noticed that the time taken to load seems to be roughly a

>> power of 2 of the "base slow load time"-- could be a red herring.
>>
>> The problem seems specific to character vectors-- I noticed it with 
>> entire workspaces and have whittled it down to char vecs only.
>>
>> The example below is from a brand-new session with only the basic 
>> packages loaded; delays in my real sessions are much longer.
>
>Can you please try R-patched or R-devel.  We've found and solved a
couple 
>of performance issues with creating STRSXPs, but with character vectors
of 
>the millions of elements.

Thanks; R-patched fixed it. I did look in R-devel NEWS before posting,
but that doesn't mention the bug fix on CHARSXP which is in the
R-patched NEWS, so I didn't persist.

FWIW in case work is still being done on new CHARSXP: my problems were
with much shorter vectors (~1e4) than the millions mentioned in
patched-NEWS, and the strings were short too: 90% were '' and the other
10% were 'a'. Also, when the previously offending objects are loaded
into 2.6.0patched, they are 3-10X smaller (according to object.size)
than in unpatched-- I was also amazed by the compression! Looks like
unpatched R was allocating at least a 32-byte memory entry per
individual zero-character string. It is down to about 4 bytes per
(zero-character) string in R-patched.


Mark Bravington

>
>I tried several examples of around 10000 elements and got times of at
most 
>0.05 secs in 2.6.0.  These included parts of those examples on which we

>had seen performance issues.
>
>A few clues:
>
>- even your base time is much slower than I would expect.
>
>- you say  'a 15K file ... object size ~0.5MB'.  That's pretty
phenomenal
>   compression, and I am seeing file sizes more like 100Kb for objects
that
>   size.  Since object.size does take into account duplication, one way
to
>   get that would be to have all unique elements.  At ca 50bytes per
>   element you would need an average string length of about 15 chars.
Such
>   an object takes about 200Kb as a .rda file.
>
>
>>
>>
>> Mark Bravington
>> CSIRO Mathematical & Information Sciences
>> Marine Laboratory
>> Castray Esplanade
>> Hobart 7001
>> TAS
>>
>> ph (+61) 3 6232 5118
>> fax (+61) 3 6232 5012
>> mob (+61) 438 315 623
>>
>>
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or 
>> 'help.start()' for an HTML browser interface to help. Type 'q()' to 
>> quit R.
>>
>>> system.time( load( 'd:/r2.0/t1.rda'))
>>   user  system elapsed
>>    0.5     0.0     0.5
>>> system.time( load( 'd:/r2.0/t1.rda')) # same file; slower
>>   user  system elapsed
>>    3.5     0.0     3.5
>>> system.time( load( 'd:/r2.0/t1.rda'))
>>   user  system elapsed
>>   4.13    0.00    4.13
>>> system.time( load( 'd:/r2.0/t1.rda'))
>>   user  system elapsed
>>   3.51    0.00    3.52
>>
>>> system.time( load( 'd:/r2.0/t2.rda'))  # different bigger file
>>   user  system elapsed
>>   4.42    0.00    4.42
>>> system.time( load( 'd:/r2.0/t2.rda')) # same file; slower
>>   user  system elapsed
>>  10.44    0.00   10.44
>>> system.time( load( 'd:/r2.0/t2.rda'))
>>   user  system elapsed
>>  10.79    0.00   10.80
>>> system.time( load( 'd:/r2.0/t2.rda'))
>>   user  system elapsed
>>  10.39    0.00   10.41
>>> system.time( load( 'd:/r2.0/t1.rda')) # the smaller file again; 
>>> slower
>>   user  system elapsed
>>  10.67    0.00   10.69
>>> system.time( load( 'd:/r2.0/t3.rda')) # different smaller file
>>   user  system elapsed
>>  10.51    0.00   10.52
>>> system.time( load( 'd:/r2.0/t2.rda')) # now bigger file again:
slower
>>   user  system elapsed
>>  14.61    0.00   14.61
>>
>>
>>
>> --please do not edit the information below--
>>
>> Version:
>> platform = i386-pc-mingw32
>> arch = i386
>> os = mingw32
>> system = i386, mingw32
>> status =
>> major = 2
>> minor = 6.0
>> year = 2007
>> month = 10
>> day = 03
>> svn rev = 43063
>> language = R
>> version.string = R version 2.6.0 (2007-10-03)
>>
>> Windows XP (build 2600) Service Pack 2.0
>>
>> Locale: 
>>
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_M
>> ON
>>
ETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>>
>> Search Path:
>> Search Path:
>> .GlobalEnv, package:stats, package:graphics, package:grDevices, 
>> package:utils, package:datasets, package:methods, Autoloads, 
>> package:base
>>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From ripley at stats.ox.ac.uk  Thu Oct 11 10:11:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Oct 2007 09:11:54 +0100 (BST)
Subject: [Rd] slow load() in R2.6.0
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F2748545C84@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F2748545C84@extas4-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.64.0710110853090.13328@gannet.stats.ox.ac.uk>

I still can't reproduce this with lots of empty strings, but the way they 
are handled was changed in R-patched -- but not with the intention of 
avoiding a performance bottleneck, just to simplify the code.

I don't get object sizes as large as 500Kb, but it will be the case that 
"" is shared in the patched version, and each copy could need 28 bytes in 
2.6.0 or 2.5.1.  So (depending how it was created), a vector of 10000 "" 
could reduce from 320Kb to about 40Kb.  (All assuming a 32-bit system, but 
yours looked like Windows.)

This is work-in-progress in that R-devel is faster than R-patched, 
appreciably so on some problems, and that change will be ported to 
R-patched shortly.

On Thu, 11 Oct 2007, Mark.Bravington at csiro.au wrote:

> Problem fixed by R-patched, thanks; see comments below.
>
>> On Thu, 11 Oct 2007, Mark.Bravington at csiro.au wrote:
>>
>>> I'm encountering excruciatingly slow load times for character vectors
>
>>> in R 2.6.0-- up to 30sec for a 15K file that contains a no-attributes
>
>>> character vector of length ~1e4 and object size ~0.5MB. In R 2.5.1,
>>> repeated loads of the same set of files are near-instantaneous.
>>>
>>> The problem is proving tricky to reproduce consistently from scratch,
>
>>> so I have attached the 3 files used in the examples below.
>>
>> There was no attachment: since these are (I presume) binary files, can
> you
>> not put them on a website (as suggested by the posting guide)?
>
> Sorry, I would have if I could, but can't at present. The attachments
> got through OK to me at least, though. If anyone does have an interest
> in the files, let me know off-list and I'll re-send as a zip or
> somesuch.
>
>>
>>> If I create a similar-looking object from scratch, then save it and
>>> re-load it a few times, the problem doesn't always occur... at least
> not
>>> in that session.
>>>
>>>
>>> FWIW I have noticed that the time taken to load seems to be roughly a
>
>>> power of 2 of the "base slow load time"-- could be a red herring.
>>>
>>> The problem seems specific to character vectors-- I noticed it with
>>> entire workspaces and have whittled it down to char vecs only.
>>>
>>> The example below is from a brand-new session with only the basic
>>> packages loaded; delays in my real sessions are much longer.
>>
>> Can you please try R-patched or R-devel.  We've found and solved a
> couple
>> of performance issues with creating STRSXPs, but with character vectors
> of
>> the millions of elements.
>
> Thanks; R-patched fixed it. I did look in R-devel NEWS before posting,
> but that doesn't mention the bug fix on CHARSXP which is in the
> R-patched NEWS, so I didn't persist.
>
> FWIW in case work is still being done on new CHARSXP: my problems were
> with much shorter vectors (~1e4) than the millions mentioned in
> patched-NEWS, and the strings were short too: 90% were '' and the other
> 10% were 'a'. Also, when the previously offending objects are loaded
> into 2.6.0patched, they are 3-10X smaller (according to object.size)
> than in unpatched-- I was also amazed by the compression! Looks like
> unpatched R was allocating at least a 32-byte memory entry per
> individual zero-character string. It is down to about 4 bytes per
> (zero-character) string in R-patched.
>
>
> Mark Bravington
>
>>
>> I tried several examples of around 10000 elements and got times of at
> most
>> 0.05 secs in 2.6.0.  These included parts of those examples on which we
>
>> had seen performance issues.
>>
>> A few clues:
>>
>> - even your base time is much slower than I would expect.
>>
>> - you say  'a 15K file ... object size ~0.5MB'.  That's pretty
> phenomenal
>>   compression, and I am seeing file sizes more like 100Kb for objects
> that
>>   size.  Since object.size does take into account duplication, one way
> to
>>   get that would be to have all unique elements.  At ca 50bytes per
>>   element you would need an average string length of about 15 chars.
> Such
>>   an object takes about 200Kb as a .rda file.
>>
>>
>>>
>>>
>>> Mark Bravington
>>> CSIRO Mathematical & Information Sciences
>>> Marine Laboratory
>>> Castray Esplanade
>>> Hobart 7001
>>> TAS
>>>
>>> ph (+61) 3 6232 5118
>>> fax (+61) 3 6232 5012
>>> mob (+61) 438 315 623
>>>
>>>
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help. Type 'q()' to
>>> quit R.
>>>
>>>> system.time( load( 'd:/r2.0/t1.rda'))
>>>   user  system elapsed
>>>    0.5     0.0     0.5
>>>> system.time( load( 'd:/r2.0/t1.rda')) # same file; slower
>>>   user  system elapsed
>>>    3.5     0.0     3.5
>>>> system.time( load( 'd:/r2.0/t1.rda'))
>>>   user  system elapsed
>>>   4.13    0.00    4.13
>>>> system.time( load( 'd:/r2.0/t1.rda'))
>>>   user  system elapsed
>>>   3.51    0.00    3.52
>>>
>>>> system.time( load( 'd:/r2.0/t2.rda'))  # different bigger file
>>>   user  system elapsed
>>>   4.42    0.00    4.42
>>>> system.time( load( 'd:/r2.0/t2.rda')) # same file; slower
>>>   user  system elapsed
>>>  10.44    0.00   10.44
>>>> system.time( load( 'd:/r2.0/t2.rda'))
>>>   user  system elapsed
>>>  10.79    0.00   10.80
>>>> system.time( load( 'd:/r2.0/t2.rda'))
>>>   user  system elapsed
>>>  10.39    0.00   10.41
>>>> system.time( load( 'd:/r2.0/t1.rda')) # the smaller file again;
>>>> slower
>>>   user  system elapsed
>>>  10.67    0.00   10.69
>>>> system.time( load( 'd:/r2.0/t3.rda')) # different smaller file
>>>   user  system elapsed
>>>  10.51    0.00   10.52
>>>> system.time( load( 'd:/r2.0/t2.rda')) # now bigger file again:
> slower
>>>   user  system elapsed
>>>  14.61    0.00   14.61
>>>
>>>
>>>
>>> --please do not edit the information below--
>>>
>>> Version:
>>> platform = i386-pc-mingw32
>>> arch = i386
>>> os = mingw32
>>> system = i386, mingw32
>>> status =
>>> major = 2
>>> minor = 6.0
>>> year = 2007
>>> month = 10
>>> day = 03
>>> svn rev = 43063
>>> language = R
>>> version.string = R version 2.6.0 (2007-10-03)
>>>
>>> Windows XP (build 2600) Service Pack 2.0
>>>
>>> Locale:
>>>
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_M
>>> ON
>>>
> ETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>>>
>>> Search Path:
>>> Search Path:
>>> .GlobalEnv, package:stats, package:graphics, package:grDevices,
>>> package:utils, package:datasets, package:methods, Autoloads,
>>> package:base
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Oct 11 10:13:24 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 11 Oct 2007 10:13:24 +0200
Subject: [Rd] attachments for R-devel e-mails
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F2748545C84@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F2748545C84@extas4-hba.tas.csiro.au>
Message-ID: <18189.56100.191309.92357@stat.math.ethz.ch>


      >> There was no attachment: since these are (I presume)
      >> binary files, can ou
      >> not put them on a website (as suggested by the posting
      >> guide)?

    > Sorry, I would have if I could, but can't at present. The
    > attachments got through OK to me at least, though. If
    > anyone does have an interest in the files, let me know
    > off-list and I'll re-send as a zip or somesuch.

Currently, the following attachment MIME types are accepted for
R-devel {R-help has less}:

 text/plain
 text/x-diff
 text/x-patch
 application/pgp-signature
 application/postscript
 application/pdf
 application/x-tar
 application/x-compressed-tar
 application/x-gzip
 image/png
 message/rfc822

However, many mailers just send

 application/octet-stream

which means ``unspecified binary'' and which has often been used for
sending viruses etc.  Further note, that I've not allowed the
common jpg and gif image types on purpose, since they are the
ones spammers have been using for a while now.

Regards,
Martin Maechler, ETH Zurich,
R-{help|devel|...} list and mailman site maintainer.


From ripley at stats.ox.ac.uk  Thu Oct 11 10:47:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Oct 2007 09:47:10 +0100 (BST)
Subject: [Rd] gregexpr (PR#9965)
In-Reply-To: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>
References: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710110942210.14648@gannet.stats.ox.ac.uk>

This was a deliberate change for R 2.4.0 with SVN log:

r38145 | rgentlem | 2006-05-20 23:58:14 +0100 (Sat, 20 May 2006) | 2 lines
fixing gregexpr infelicity

So it seems the author of gregexpr believed that the bug was in 2.3.1, not 
2.5.1.

On Wed, 10 Oct 2007, dolanp at science.oregonstate.edu wrote:

> Full_Name: Peter Dolan
> Version: 2.5.1
> OS: Windows
> Submission from: (NULL) (128.193.227.43)
>
>
> gregexpr does not find all matching substrings if the substrings overlap:
>
>> gregexpr("abab","ababab")
> [[1]]
> [1] 1
> attr(,"match.length")
> [1] 4
>
> It does work correctly in Version 2.3.1 under linux.

'correctly' is a matter of definition, I believe: this could be considered 
to be vaguely worded in the help.

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Oct 11 11:10:27 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 11 Oct 2007 11:10:27 +0200 (CEST)
Subject: [Rd] corMatrix crashes with corARMA structure (PR#9952)
Message-ID: <20071011091027.44259282EFF7@mail.pubhealth.ku.dk>

This is already fixed in nlme_3.1-86!

> Sigma <- corMatrix(tmp, covariate = 1:n) # segfault
Error in corMatrix.corARMA(tmp, covariate = 1:n) :
   'object' has not been Initialize()d

Please do check that things you report are not already fixed.


On Wed, 10 Oct 2007, btyner at gmail.com wrote:

> Full_Name: Benjamin Tyner
> Version: 2.6.0 RC 2007-10-01 r43043
> OS: WinXP
> Submission from: (NULL) (171.161.224.10)
>
>
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status         RC
> major          2
> minor          6.0
> year           2007
> month          10
> day            01
> svn rev        43043
> language       R
> version.string R version 2.6.0 RC (2007-10-01 r43043)
>
> I have seen this in other versions/platforms as well. Brian Ripley informs me
> the segfault is in corStruct.c
>
> Code to reproduce:
>
> n <- 100
>
> # example from Box and Jenkins p. 83
> arcoefs <- c(0.8)
> macoefs <- c(-0.6)
> p <- length(arcoefs)
> q <- length(macoefs)
>
> require(nlme)
> tmp <- corARMA(value=c(arcoefs,macoefs), form=~1, p=p, q=q)
> Sigma <- corMatrix(tmp, covariate = 1:n) # segfault
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Greg.Snow at intermountainmail.org  Thu Oct 11 11:10:35 2007
From: Greg.Snow at intermountainmail.org (Greg.Snow at intermountainmail.org)
Date: Thu, 11 Oct 2007 11:10:35 +0200 (CEST)
Subject: [Rd] gregexpr (PR#9965)
Message-ID: <20071011091035.A0399283416A@mail.pubhealth.ku.dk>

If you want all the matches (including overlaps) then you could try one
of these:

> gregexpr("(?=3Dabab)","ababab",perl=3DTRUE)
[[1]]
[1] 1 3
attr(,"match.length")
[1] 0 0

> gregexpr("ab(?=3Dab)","ababab",perl=3DTRUE)
[[1]]
[1] 1 3
attr(,"match.length")
[1] 2 2

The book "Mastering Regular Expressions" by Jeffrey Friedl has a lot of
detail on the hows and whys of regular expression matching.

--=20
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
=20
=20

> -----Original Message-----
> From: r-devel-bounces at r-project.org=20
> [mailto:r-devel-bounces at r-project.org] On Behalf Of=20
> dolanp at science.oregonstate.edu
> Sent: Wednesday, October 10, 2007 8:36 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] gregexpr (PR#9965)
>=20
> Full_Name: Peter Dolan
> Version: 2.5.1
> OS: Windows
> Submission from: (NULL) (128.193.227.43)
>=20
>=20
> gregexpr does not find all matching substrings if the=20
> substrings overlap:
>=20
> > gregexpr("abab","ababab")
> [[1]]
> [1] 1
> attr(,"match.length")
> [1] 4
>=20
> It does work correctly in Version 2.3.1 under linux.
>=20
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>=20


From ernesto at ipimar.pt  Thu Oct 11 12:15:08 2007
From: ernesto at ipimar.pt (ernesto)
Date: Thu, 11 Oct 2007 11:15:08 +0100
Subject: [Rd] R260 cross-compilation
Message-ID: <470DF7AC.1070704@ipimar.pt>

Hi,

I'm trying to cross compile R260 in a ubuntu 6.06 linux. I downloaded 
the Makefile for 251 and simply replaced the R version by 260. However 
I'm getting an error about mingw.

ernesto at gandalf:~/ipimar/devel/R/ccompile260$ make R
export 
PATH=/home/ernesto/ipimar/devel/R/ccompile260/cross-tools/bin:/home/ernesto/ipimar/devel/R/ccompile260/cross-tools/i586-mingw32/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games; 
\
        cd 
/home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32/; \
        make; \
        cd /home/ernesto/ipimar/devel/R/ccompile260/WinR; \
        tar zcf Win-R-2.6.0.tgz R-2.6.0
make[1]: Entering directory 
`/home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32'
make --no-print-directory -C front-ends Rpwd
make -C ../../include -f Makefile.win version
make Rpwd.exe
i586-mingw32-gcc-sjlj  -std=gnu99 -I../../include  -O3 -Wall -pedantic  
-c rpwd.c -o rpwd.o
make[4]: i586-mingw32-gcc-sjlj: Command not found
make[4]: *** [rpwd.o] Error 127
make[3]: *** [Rpwd] Error 2
make[2]: *** [front-ends/Rpwd.exe] Error 2
make[1]: *** [all] Error 2
make[1]: Leaving directory 
`/home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32'

How can I fix this ? Is there a new Makefile for R260 ?

Thanks

EJ


From ripley at stats.ox.ac.uk  Thu Oct 11 12:35:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Oct 2007 11:35:58 +0100 (BST)
Subject: [Rd] R260 cross-compilation
In-Reply-To: <470DF7AC.1070704@ipimar.pt>
References: <470DF7AC.1070704@ipimar.pt>
Message-ID: <Pine.LNX.4.64.0710111119021.16965@gannet.stats.ox.ac.uk>

I don't know what you mean about 'the Makefile': the R sources contain 
all the makefiles needed.

Things are different for 2.6.0 but the procedure is (still) described in 
the R-admin manual (section 3.1.9 in the version I am looking at), and it 
has been tested.  Looks like you have the settings in MkRules incorrectly 
configured, and probably have not built your own cross-compiler for the 
current gcc-4.2.x.


On Thu, 11 Oct 2007, ernesto wrote:

> Hi,
>
> I'm trying to cross compile R260 in a ubuntu 6.06 linux. I downloaded
> the Makefile for 251 and simply replaced the R version by 260. However
> I'm getting an error about mingw.
>
> ernesto at gandalf:~/ipimar/devel/R/ccompile260$ make R
> export
> PATH=/home/ernesto/ipimar/devel/R/ccompile260/cross-tools/bin:/home/ernesto/ipimar/devel/R/ccompile260/cross-tools/i586-mingw32/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games;
> \
>        cd
> /home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32/; \
>        make; \
>        cd /home/ernesto/ipimar/devel/R/ccompile260/WinR; \
>        tar zcf Win-R-2.6.0.tgz R-2.6.0
> make[1]: Entering directory
> `/home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32'
> make --no-print-directory -C front-ends Rpwd
> make -C ../../include -f Makefile.win version
> make Rpwd.exe
> i586-mingw32-gcc-sjlj  -std=gnu99 -I../../include  -O3 -Wall -pedantic
> -c rpwd.c -o rpwd.o
> make[4]: i586-mingw32-gcc-sjlj: Command not found
> make[4]: *** [rpwd.o] Error 127
> make[3]: *** [Rpwd] Error 2
> make[2]: *** [front-ends/Rpwd.exe] Error 2
> make[1]: *** [all] Error 2
> make[1]: Leaving directory
> `/home/ernesto/ipimar/devel/R/ccompile260/WinR/R-2.6.0/src/gnuwin32'
>
> How can I fix this ? Is there a new Makefile for R260 ?
>
> Thanks
>
> EJ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Thu Oct 11 16:21:32 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Oct 2007 07:21:32 -0700 (PDT)
Subject: [Rd] pt inaccurate when x is close to 0 (PR#9945)
In-Reply-To: <470D0788.4080307@stats.uwo.ca>
References: <20071010143513.11DD128800A8@mail.pubhealth.ku.dk>
	<470D0788.4080307@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0710110709380.24673@homer21.u.washington.edu>

On Wed, 10 Oct 2007, Duncan Murdoch wrote:>
> As Charles Berry told you when this was posted to R-help, it looks as
> though it is Mathematica that is inaccurate.  For example, I would
> expect this plot to be smooth, and it is not in either R or Mathematica,
> but R is at least monotone:

I did check this on Maple by integrating the density function and got 
about 11-12 digits accuracy at df=88.  I also tried replacing 1e-4 with an 
exactly-representable number (3/32768), with a similar accuracy level.

pbeta() claims 14-digit accuracy and is called by pt() with 1/(1+x^2/n) as 
its argument.  I would have thought that the 1/(1+x^2/n) could easily be 
responsible for this sort of accuracy loss when x=1e-4.  If so, it may not 
be easy to improve.

 	-thomas


From rgentlem at fhcrc.org  Thu Oct 11 17:03:50 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Thu, 11 Oct 2007 08:03:50 -0700
Subject: [Rd] gregexpr (PR#9965)
In-Reply-To: <Pine.LNX.4.64.0710110942210.14648@gannet.stats.ox.ac.uk>
References: <20071010143544.1B484288008C@mail.pubhealth.ku.dk>
	<Pine.LNX.4.64.0710110942210.14648@gannet.stats.ox.ac.uk>
Message-ID: <470E3B56.9030000@fhcrc.org>

Yes, we had originally wanted it to find all matches, but user 
complaints that it did not perform as Perl does were taken to prevail. 
There are different ways to do this, but it seems the notion that one 
not start looking for the next match until after the previous one is 
more common.  I did consciously decide not to have a switch, and instead 
we wrote something that does what we wanted it to do and put it in the 
Biostrings package (from Bioconductor) as geregexpr2 (sorry but only 
fixed = TRUE is supported, since that is all we needed).

best wishes
   Robert


Prof Brian Ripley wrote:
> This was a deliberate change for R 2.4.0 with SVN log:
> 
> r38145 | rgentlem | 2006-05-20 23:58:14 +0100 (Sat, 20 May 2006) | 2 lines
> fixing gregexpr infelicity
> 
> So it seems the author of gregexpr believed that the bug was in 2.3.1, not 
> 2.5.1.
> 
> On Wed, 10 Oct 2007, dolanp at science.oregonstate.edu wrote:
> 
>> Full_Name: Peter Dolan
>> Version: 2.5.1
>> OS: Windows
>> Submission from: (NULL) (128.193.227.43)
>>
>>
>> gregexpr does not find all matching substrings if the substrings overlap:
>>
>>> gregexpr("abab","ababab")
>> [[1]]
>> [1] 1
>> attr(,"match.length")
>> [1] 4
>>
>> It does work correctly in Version 2.3.1 under linux.
> 
> 'correctly' is a matter of definition, I believe: this could be considered 
> to be vaguely worded in the help.
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From rgentlem at fhcrc.org  Thu Oct 11 17:07:06 2007
From: rgentlem at fhcrc.org (rgentlem at fhcrc.org)
Date: Thu, 11 Oct 2007 17:07:06 +0200 (CEST)
Subject: [Rd] gregexpr (PR#9965)
Message-ID: <20071011150706.EDC4C2834611@mail.pubhealth.ku.dk>

Yes, we had originally wanted it to find all matches, but user 
complaints that it did not perform as Perl does were taken to prevail. 
There are different ways to do this, but it seems the notion that one 
not start looking for the next match until after the previous one is 
more common.  I did consciously decide not to have a switch, and instead 
we wrote something that does what we wanted it to do and put it in the 
Biostrings package (from Bioconductor) as geregexpr2 (sorry but only 
fixed = TRUE is supported, since that is all we needed).

best wishes
   Robert


Prof Brian Ripley wrote:
> This was a deliberate change for R 2.4.0 with SVN log:
> 
> r38145 | rgentlem | 2006-05-20 23:58:14 +0100 (Sat, 20 May 2006) | 2 lines
> fixing gregexpr infelicity
> 
> So it seems the author of gregexpr believed that the bug was in 2.3.1, not 
> 2.5.1.
> 
> On Wed, 10 Oct 2007, dolanp at science.oregonstate.edu wrote:
> 
>> Full_Name: Peter Dolan
>> Version: 2.5.1
>> OS: Windows
>> Submission from: (NULL) (128.193.227.43)
>>
>>
>> gregexpr does not find all matching substrings if the substrings overlap:
>>
>>> gregexpr("abab","ababab")
>> [[1]]
>> [1] 1
>> attr(,"match.length")
>> [1] 4
>>
>> It does work correctly in Version 2.3.1 under linux.
> 
> 'correctly' is a matter of definition, I believe: this could be considered 
> to be vaguely worded in the help.
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From murdoch at stats.uwo.ca  Thu Oct 11 17:10:49 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 11 Oct 2007 11:10:49 -0400
Subject: [Rd] [Fwd: Re:  pt inaccurate when x is close to 0 (PR#9945)]
Message-ID: <470E3CF9.2050009@stats.uwo.ca>

Here's a contribution from Ian Smith that got bounced from the list.

-------- Original Message --------
Subject: Re: [Rd] pt inaccurate when x is close to 0 (PR#9945)
Date: Thu, 11 Oct 2007 06:02:43 -0400
From: iandjmsmith at aol.com
To: murdoch at stats.uwo.ca


Duncan,

I tried sending the rest of this to R-devel but it was rejected as spam, 
hence the personal e-mail.


R calculates the pt value from


nx = 1 + (x/n)*x;
val = pbeta(1./nx, n / 2., 0.5, /*lower_tail*/1, log_p);


whereas Gnumeric calculates the value as


val =? (n > x * x)
? pbeta (x * x / (n + x * x), 0.5, n / 2, /*lower_tail*/0, log_p)
: pbeta (n / (n + x * x), n / 2.0, 0.5, /*lower_tail*/1, log_p);


thus avoiding the loss of accuracy in the pbeta routine when 1-1./nx
is calculated.


It also makes the


if (n > 4e5) { /*-- Fixme(?): test should depend on `n' AND `x' ! */
??? /* Approx. from? Abramowitz & Stegun 26.7.8 (p.949) */
??? val = 1./(4.*n);
??? return pnorm(x*(1. - val)/sqrt(1. + x*x*2.*val), 0.0, 1.0,
???????? lower_tail, log_p);
}


code unneccessary.


Ian Smith


Personally, I think the code should also guard against the possible
overflow of the x * x expressions.


________________________________________________________________________
Get a FREE AOL Email account with unlimited storage.  Plus, share and 
store photos and experience exclusively recorded live music Sessions 
from your favourite artists. Find out more at 
http://info.aol.co.uk/joinnow/?ncid=548.


From chris.knight at manchester.ac.uk  Thu Oct 11 11:11:31 2007
From: chris.knight at manchester.ac.uk (chris.knight at manchester.ac.uk)
Date: Thu, 11 Oct 2007 11:11:31 +0200 (CEST)
Subject: [Rd] failure to find lapply (PR#9999)
Message-ID: <20071011091131.3DA042834169@mail.pubhealth.ku.dk>

I have been unable to reproduce this problem but the warning I got told 
me to send a bug report, so here it is.

After a fairly lengthy session, using the ape and ade4 packages, 
conducted via a terminal in kate under kubuntu 6.06 linux , I found 
errors claiming not to find lapply- see first  section below.

...
 > if(nas>0){
+ tree<-drop.tip(tree,tip=which(is.na(scorei)))
+ scorei<-scorei[which(!is.na(scorei))]
+ }
Error in paste("as.", value, sep = "") : could not find function "lapply"
 > tree2<-newick2phylog(write.tree(tree, multi.line=FALSE))
Error in paste("%.", digits, "g", sep = "") :
  could not find function "lapply"
 > n<-length(tree$tip.label)-1
 > e<-rep(NA,n)
 > k<-1/(1:n)
 > for(j in 1:n){
+ Error in sapply(c("(", ")"), function(s) gregexpr(s, substr(line, 1, 
cursor),  :
  could not find function "lapply"
 > e[j]<-sum(k[j:n])
Error: object "j" not found
 > Error in sapply(c("(", ")"), function(s) gregexpr(s, substr(line, 1, 
cursor),  :
  could not find function "lapply"
 > }

...

This continued in a similar vein as I had pasted in quite a few lines 
until the warning suggesting a bug report (below).
As can be seen below, this error prevented directly calling either 
bug.report() or sessionInfo(), however the R.version output was possible 
and the output from bug.report() and sessionInfo() from another session 
started just after on the same machine are given below:

...
 > tree<-drop.tip(tree,tip=which(is.na(scorei)))
Error in paste("as.", value, sep = "") : could not find function "lapply"
 > Error in sapply(c("(", ")"), function(s) gregexpr(s, substr(line, 1, 
cursor),  :
  could not find function "lapply"
 > scorei<-scorei[which(!is.na(scorei))]
Warning message:
An unusual circumstance has arisen in the nesting of readline input. 
Please report using bug.report()
 > bug.report()
Error in paste(names(R.version), R.version, sep = " = ", collapse = "\\n 
") :
  could not find function "lapply"
 > lapply
[[1]]
Error in paste("Error in", dcall, ": ") :
  could not find function "lapply"
 >                                  
 > sessionInfo()
Error in sapply(package, function(x) x == "package:base" || 
!is.null(attr(as.environment(x),  :
  could not find function "lapply"
 > R.version
               _
platform       i486-pc-linux-gnu
arch           i486
os             linux-gnu
system         i486, linux-gnu
status
major          2
minor          6.0
year           2007
month          10
day            03
svn rev        43063
language       R
version.string R version 2.6.0 (2007-10-03)

...

sessionInfo() from another, similar session:

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ade4_1.4-4     lattice_0.16-5 nlme_3.1-85    gee_4.13-13    ape_2.0-1

loaded via a namespace (and not attached):
[1] grid_2.6.0      rcompgen_0.1-15

 From bug.report() in another session

--please do not edit the information below--

Version:
platform = i486-pc-linux-gnu
arch = i486
os = linux-gnu
system = i486, linux-gnu
status =
major = 2
minor = 6.0
year = 2007
month = 10
day = 03
svn rev = 43063
language = R
version.string = R version 2.6.0 (2007-10-03)

Locale:
LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C

Search Path:
.GlobalEnv, package:ade4, package:lattice, package:nlme, package:gee, 
package:ape, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:methods, Autoloads, package:base
~
~
~
~
~
~
~
~
~
~
"R.bug.report" 27L, 783C 4,0-1 All

-- 
------------------------------------------------------------------------
Dr Christopher Knight             Manchester Interdisciplinary Biocentre
room 2.001                                  The University of Manchester
Tel:  +44 (0)161 3065138                             131 Princess Street
Fax:  +44 (0)161 3064556                               Manchester M1 7DN
chris.knight at manchester.ac.uk                                         UK 
www.dbkgroup.org/MCISB/people/knight/                   ` ? . ,,><(((?>


From ggrothendieck at gmail.com  Fri Oct 12 09:04:30 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 12 Oct 2007 03:04:30 -0400
Subject: [Rd] LazyLoad changes the class of objects
Message-ID: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>

Consider a package that this DESCRIPTION file:

---
Package: tester
Version: 0.1-0
Date: 2007-10-12
Title: Prototype object-based programming
Author: Gabor Grothendieck
Maintainer: Gabor Grothendieck <ggrothendieck at gmail.com>
Description: test
LazyLoad: true
Depends: R (>= 2.6.0)
License: GPL2
---

and a single subdirectory R containing tester.R which contains two lines:

---
e <- new.env()
class(e) <- c("x", "environment")
---

Now issue these commands:

> library(tester)
> class(tester::e)
[1] "environment"

> R.version.string # Windows Vista
[1] "R version 2.6.0 Patched (2007-10-08 r43124)"


Note that the class of e was changed from what we set it to !!!

On the other handn, if we omit LazyLoad: true from the DESCRIPTION file
then it retains its original class.

> # removed LazyLoad: true line from DESCRIPTION and reinstall pkg
> # now its ok
> library(tester)
> class(tester::e)
[1] "x"           "environment"


From savicky at cs.cas.cz  Fri Oct 12 09:19:07 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 12 Oct 2007 09:19:07 +0200
Subject: [Rd] as.integer(x) versus as.integer(trunc(x))
Message-ID: <20071012071907.GA16113@cs.cas.cz>

as.integer(x) rounds floating point numbers towards zero,
so it behaves approximately as as.integer(trunc(x)).

If x > INT_MAX, then as.integer(x) is NA. This is nothing
bad, but it is slightly more restrictive than necessary. An
alternative approach could be that
  as.integer(x) is NA, if trunc(x) > INT_MAX and
  as.integer(x) == INT_MAX for all x in [INT_MAX,INT_MAX+1).

Let me suggest the following patch to IntegerFromReal for consideration:

--- R-devel_2007-10-11-orig/src/main/coerce.c	2007-07-25 17:54:17.000000000 +0200
+++ R-devel_2007-10-11-asinteger/src/main/coerce.c	2007-10-12 07:10:06.000000000 +0200
@@ -173,7 +173,8 @@
 {
     if (ISNAN(x))
 	return NA_INTEGER;
-    else if (x > INT_MAX || x <= INT_MIN ) {
+    x = trunc(x);
+    if (x > INT_MAX || x <= INT_MIN ) {
 	*warn |= WARN_NA;
 	return NA_INTEGER;
     }

This patch changes the behavior as suggested above. Its effect may be seen
using the script
  options(digits=12)
  x <- seq(2^31 - 3, 2^31, length=7)
  cbind(x,as.integer(trunc(x)),as.integer(x))

Original behavior:
  [1,] 2147483645.0 2147483645 2147483645
  [2,] 2147483645.5 2147483645 2147483645
  [3,] 2147483646.0 2147483646 2147483646
  [4,] 2147483646.5 2147483646 2147483646
  [5,] 2147483647.0 2147483647 2147483647
  [6,] 2147483647.5 2147483647         NA
  [7,] 2147483648.0         NA         NA

Using the patch:
  [1,] 2147483645.0 2147483645 2147483645
  [2,] 2147483645.5 2147483645 2147483645
  [3,] 2147483646.0 2147483646 2147483646
  [4,] 2147483646.5 2147483646 2147483646
  [5,] 2147483647.0 2147483647 2147483647
  [6,] 2147483647.5 2147483647 2147483647
  [7,] 2147483648.0         NA         NA

Petr Savicky.


From maechler at stat.math.ethz.ch  Fri Oct 12 15:09:21 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 12 Oct 2007 15:09:21 +0200
Subject: [Rd] pt inaccurate when x is close to 0 (PR#9945)
In-Reply-To: <470E3CF9.2050009@stats.uwo.ca>
References: <470E3CF9.2050009@stats.uwo.ca>
Message-ID: <18191.29185.486743.8495@stat.math.ethz.ch>

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Thu, 11 Oct 2007 11:10:49 -0400 writes:

    DM> Here's a contribution from Ian Smith that got bounced
    DM> from the list. 

 [well, given the obvious Spam that AOL appended at the end... ]

    DM> -------- Original Message --------
    DM> Subject: Re: [Rd] pt inaccurate when x is close to 0 (PR#9945)
    DM> Date: Thu, 11 Oct 2007 06:02:43 -0400
    DM> From: iandjmsmith at aol.com
    DM> To: murdoch at stats.uwo.ca


    DM> Duncan,

    DM> I tried sending the rest of this to R-devel but it was rejected as spam, 
    DM> hence the personal e-mail.


    DM> R calculates the pt value from


    DM> nx = 1 + (x/n)*x;
    DM> val = pbeta(1./nx, n / 2., 0.5, /*lower_tail*/1, log_p);


    DM> whereas Gnumeric calculates the value as


    DM> val =? (n > x * x)
    DM> ? pbeta (x * x / (n + x * x), 0.5, n / 2, /*lower_tail*/0, log_p)
    DM> : pbeta (n / (n + x * x), n / 2.0, 0.5, /*lower_tail*/1, log_p);

seems a good idea
        {{however I doubt the  "?"  in  "val =?" above }}

    DM> thus avoiding the loss of accuracy in the pbeta routine when 1-1./nx
    DM> is calculated.

    DM> It also makes the

    DM> if (n > 4e5) { /*-- Fixme(?): test should depend on `n' AND `x' ! */
    DM> ??? /* Approx. from? Abramowitz & Stegun 26.7.8 (p.949) */
    DM> ??? val = 1./(4.*n);
    DM> ??? return pnorm(x*(1. - val)/sqrt(1. + x*x*2.*val), 0.0, 1.0,
    DM> ???????? lower_tail, log_p);
    DM> }

    DM> code unneccessary.

probably, will have to see.

    DM> Ian Smith

    DM> Personally, I think the code should also guard against the possible
    DM> overflow of the x * x expressions.

The current code actually *does* guard 
since the overflow happens to "+Inf" and that does fulfill '> 1e100'
and the current code has

    nx = 1 + (x/n)*x;
    ....
    if(fabs(nx) > 1e100) {
    		....
    }

... 

I'll try to use the Gnumeric switch and see and think some more
about the other extreme cases.

Martin


From johannes.schauer at tugraz.at  Wed Oct 10 16:35:37 2007
From: johannes.schauer at tugraz.at (johannes.schauer at tugraz.at)
Date: Wed, 10 Oct 2007 16:35:37 +0200 (CEST)
Subject: [Rd] Error on saving graphics as ps-files with R 2.6.0 (PR#9960)
Message-ID: <20071010143537.9CDBB288008C@mail.pubhealth.ku.dk>

Full_Name: Johannes Schauer
Version: 2.6.0
OS: Windows XP Professional
Submission from: (NULL) (129.27.154.7)


When I want to save graphics (hist, boxplot, plot, ...) as ps-files in R 2.6.0 I
get an error message stating "Invalid font type" with "font family not found in
PostScript font database". I used to work with R 2.5.1 and R 2.5.0 and it seems
to be a new problem.


From rkoenker at uiuc.edu  Fri Oct 12 17:16:05 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Fri, 12 Oct 2007 10:16:05 -0500
Subject: [Rd] no visible binding
Message-ID: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>

Could someone advise me about how to react to the message:

* checking R code for possible problems ... NOTE
slm: no visible binding for global variable 'response'

from R CMD check SparseM    with
* using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)

The offending code looks like this:

"slm" <-
function (formula,  data, weights, na.action, method = "csr",
     contrasts = NULL, ...)
{
     call <- match.call()
     m <- match.call(expand.dots = FALSE)
     m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
     m[[1]] <- as.name("model.frame")
     m <- eval(m, sys.frame(sys.parent()))
     if (method == "model.frame")
         return(m)
     Terms <- attr(m, "terms")
     weights <- model.extract(m, weights)
     Y <- model.extract(m, response)
     X <- as.matrix.csr(model.matrix(Terms, m, contrasts))
     fit <- {
         if (length(weights))
             slm.wfit(X, Y,  weights, method, ...)
         else slm.fit(X, Y,  method, ...)
     }
     fit$terms <- Terms
     fit$call <- call
     attr(fit, "na.message") <- attr(m, "na.message")
     class(fit) <- c(if (is.matrix(Y)) "mslm", "slm")
     fit
}


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


From santos at supagro.inra.fr  Fri Oct 12 14:24:44 2007
From: santos at supagro.inra.fr (Filipe Santos)
Date: Fri, 12 Oct 2007 14:24:44 +0200
Subject: [Rd] Error in Windows Vista, saving workspace...
Message-ID: <200710121424.44622.santos@supagro.inra.fr>

Dear all...

I'm using R 2.6.0 in windows Vista. And I got the following error:

> quit()
Save workspace image? [y/n/c]: y
Error in gzfile(file,"wb"): unable to open connection
In addiction: Warning message:
In gzfile(file, "wb") : cannot open compressed file '.RDataTmp'

This happens in both in RGui and Rterm

Thanks,
Filipe Santos


From roberto.passera at tin.it  Wed Oct 10 16:35:35 2007
From: roberto.passera at tin.it (roberto.passera at tin.it)
Date: Wed, 10 Oct 2007 16:35:35 +0200 (CEST)
Subject: [Rd] File-Choose directory-Choose a folder (PR#9959)
Message-ID: <20071010143535.F2A19288008C@mail.pubhealth.ku.dk>

Full_Name: Roberto Passera
Version: 2.6.0 and 2.6.0 patched
OS: Windows Vista Premium
Submission from: (NULL) (151.48.70.219)


Using R 2.6.0 and 2.6.0 patched Italian version on Windows Vista systems, when
selecting File-Choose directory, the sub-command Choose a folder doesn't go,
being stopped to Desktop option.


From ligges at statistik.uni-dortmund.de  Fri Oct 12 18:57:42 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Oct 2007 18:57:42 +0200
Subject: [Rd] no visible binding
In-Reply-To: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
References: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
Message-ID: <470FA786.4090104@statistik.uni-dortmund.de>

Dear Roger,

simply use quotes as in:

model.extract(m, "response")

Best,
Uwe



roger koenker wrote:
> Could someone advise me about how to react to the message:
> 
> * checking R code for possible problems ... NOTE
> slm: no visible binding for global variable 'response'
> 
> from R CMD check SparseM    with
> * using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)
> 
> The offending code looks like this:
> 
> "slm" <-
> function (formula,  data, weights, na.action, method = "csr",
>      contrasts = NULL, ...)
> {
>      call <- match.call()
>      m <- match.call(expand.dots = FALSE)
>      m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
>      m[[1]] <- as.name("model.frame")
>      m <- eval(m, sys.frame(sys.parent()))
>      if (method == "model.frame")
>          return(m)
>      Terms <- attr(m, "terms")
>      weights <- model.extract(m, weights)
>      Y <- model.extract(m, response)
>      X <- as.matrix.csr(model.matrix(Terms, m, contrasts))
>      fit <- {
>          if (length(weights))
>              slm.wfit(X, Y,  weights, method, ...)
>          else slm.fit(X, Y,  method, ...)
>      }
>      fit$terms <- Terms
>      fit$call <- call
>      attr(fit, "na.message") <- attr(m, "na.message")
>      class(fit) <- c(if (is.matrix(Y)) "mslm", "slm")
>      fit
> }
> 
> 
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Roger.Bivand at nhh.no  Fri Oct 12 18:59:37 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Oct 2007 18:59:37 +0200 (CEST)
Subject: [Rd] no visible binding
In-Reply-To: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
References: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
Message-ID: <Pine.LNX.4.64.0710121855510.17956@reclus.nhh.no>

On Fri, 12 Oct 2007, roger koenker wrote:

> Could someone advise me about how to react to the message:
>
> * checking R code for possible problems ... NOTE
> slm: no visible binding for global variable 'response'
>
> from R CMD check SparseM    with
> * using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)
>
> The offending code looks like this:
>
> "slm" <-
> function (formula,  data, weights, na.action, method = "csr",
>     contrasts = NULL, ...)
> {
>     call <- match.call()
>     m <- match.call(expand.dots = FALSE)
>     m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
>     m[[1]] <- as.name("model.frame")
>     m <- eval(m, sys.frame(sys.parent()))
>     if (method == "model.frame")
>         return(m)
>     Terms <- attr(m, "terms")
>     weights <- model.extract(m, weights)
>     Y <- model.extract(m, response)
                             ^^^^^^^^

which becomes:

> as.character(substitute(response))
[1] "response"

inside model.extract. I'm not sure why codetools doesn't pick up weights 
in the same context one line earlier, probably because weights is also 
assigned to.

Hope this helps,

Roger

>     X <- as.matrix.csr(model.matrix(Terms, m, contrasts))
>     fit <- {
>         if (length(weights))
>             slm.wfit(X, Y,  weights, method, ...)
>         else slm.fit(X, Y,  method, ...)
>     }
>     fit$terms <- Terms
>     fit$call <- call
>     attr(fit, "na.message") <- attr(m, "na.message")
>     class(fit) <- c(if (is.matrix(Y)) "mslm", "slm")
>     fit
> }
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From P.Dalgaard at biostat.ku.dk  Fri Oct 12 18:59:50 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 12 Oct 2007 18:59:50 +0200
Subject: [Rd] no visible binding
In-Reply-To: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
References: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
Message-ID: <470FA806.8010203@biostat.ku.dk>

roger koenker wrote:
> Could someone advise me about how to react to the message:
>   
I'd try putting quotes in

model.extract(m, "response")

(and also in

model.extract(m, "weights")

even though you're not seeing the complaint on that one).


> * checking R code for possible problems ... NOTE
> slm: no visible binding for global variable 'response'
>
> from R CMD check SparseM    with
> * using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)
>
> The offending code looks like this:
>
> "slm" <-
> function (formula,  data, weights, na.action, method = "csr",
>      contrasts = NULL, ...)
> {
>      call <- match.call()
>      m <- match.call(expand.dots = FALSE)
>      m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
>      m[[1]] <- as.name("model.frame")
>      m <- eval(m, sys.frame(sys.parent()))
>      if (method == "model.frame")
>          return(m)
>      Terms <- attr(m, "terms")
>      weights <- model.extract(m, weights)
>      Y <- model.extract(m, response)
>      X <- as.matrix.csr(model.matrix(Terms, m, contrasts))
>      fit <- {
>          if (length(weights))
>              slm.wfit(X, Y,  weights, method, ...)
>          else slm.fit(X, Y,  method, ...)
>      }
>      fit$terms <- Terms
>      fit$call <- call
>      attr(fit, "na.message") <- attr(m, "na.message")
>      class(fit) <- c(if (is.matrix(Y)) "mslm", "slm")
>      fit
> }
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Fri Oct 12 19:01:20 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Oct 2007 19:01:20 +0200
Subject: [Rd] Error on saving graphics as ps-files with R 2.6.0 (PR#9960)
In-Reply-To: <20071010143537.9CDBB288008C@mail.pubhealth.ku.dk>
References: <20071010143537.9CDBB288008C@mail.pubhealth.ku.dk>
Message-ID: <470FA860.5070006@statistik.uni-dortmund.de>



johannes.schauer at tugraz.at wrote:
> Full_Name: Johannes Schauer
> Version: 2.6.0
> OS: Windows XP Professional
> Submission from: (NULL) (129.27.154.7)
> 
> 
> When I want to save graphics (hist, boxplot, plot, ...) as ps-files in R 2.6.0 I
> get an error message stating "Invalid font type" with "font family not found in
> PostScript font database". I used to work with R 2.5.1 and R 2.5.0 and it seems
> to be a new problem.

This has already been fixed in r-patched an reported several times. 
Please read the NEWS files and the mailing list archives.

I am really surprised that so many people are using the menu (and hence 
copying devices) rather than starting from a clean postscript device 
(which is always preferable). No developer does so I guess and nobody 
else seems to have looked into the alpha/beta versions or release 
candidates of R-2.6.0...

Uwe Ligges



> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Fri Oct 12 19:03:18 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Oct 2007 19:03:18 +0200
Subject: [Rd] Error in Windows Vista, saving workspace...
In-Reply-To: <200710121424.44622.santos@supagro.inra.fr>
References: <200710121424.44622.santos@supagro.inra.fr>
Message-ID: <470FA8D6.3070107@statistik.uni-dortmund.de>

Do you have write permissions in the current working directory? I guess not.

Uwe Ligges


Filipe Santos wrote:
> Dear all...
> 
> I'm using R 2.6.0 in windows Vista. And I got the following error:
> 
>> quit()
> Save workspace image? [y/n/c]: y
> Error in gzfile(file,"wb"): unable to open connection
> In addiction: Warning message:
> In gzfile(file, "wb") : cannot open compressed file '.RDataTmp'
> 
> This happens in both in RGui and Rterm
> 
> Thanks,
> Filipe Santos
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Fri Oct 12 19:04:15 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Oct 2007 19:04:15 +0200
Subject: [Rd] no visible binding
In-Reply-To: <Pine.LNX.4.64.0710121855510.17956@reclus.nhh.no>
References: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
	<Pine.LNX.4.64.0710121855510.17956@reclus.nhh.no>
Message-ID: <470FA90F.8000503@statistik.uni-dortmund.de>



Roger Bivand wrote:
> On Fri, 12 Oct 2007, roger koenker wrote:
> 
>> Could someone advise me about how to react to the message:
>>
>> * checking R code for possible problems ... NOTE
>> slm: no visible binding for global variable 'response'
>>
>> from R CMD check SparseM    with
>> * using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)
>>
>> The offending code looks like this:
>>
>> "slm" <-
>> function (formula,  data, weights, na.action, method = "csr",
>>     contrasts = NULL, ...)
>> {
>>     call <- match.call()
>>     m <- match.call(expand.dots = FALSE)
>>     m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
>>     m[[1]] <- as.name("model.frame")
>>     m <- eval(m, sys.frame(sys.parent()))
>>     if (method == "model.frame")
>>         return(m)
>>     Terms <- attr(m, "terms")
>>     weights <- model.extract(m, weights)
>>     Y <- model.extract(m, response)
>                              ^^^^^^^^
> 
> which becomes:
> 
>> as.character(substitute(response))
> [1] "response"
> 
> inside model.extract. I'm not sure why codetools doesn't pick up weights 
> in the same context one line earlier, probably because weights is also 
> assigned to.

Yes. That object exists, but response does not.

Uwe




> Hope this helps,
> 
> Roger
> 
>>     X <- as.matrix.csr(model.matrix(Terms, m, contrasts))
>>     fit <- {
>>         if (length(weights))
>>             slm.wfit(X, Y,  weights, method, ...)
>>         else slm.fit(X, Y,  method, ...)
>>     }
>>     fit$terms <- Terms
>>     fit$call <- call
>>     attr(fit, "na.message") <- attr(m, "na.message")
>>     class(fit) <- c(if (is.matrix(Y)) "mslm", "slm")
>>     fit
>> }
>>
>>
>> url:    www.econ.uiuc.edu/~roger            Roger Koenker
>> email    rkoenker at uiuc.edu            Department of Economics
>> vox:     217-333-4558                University of Illinois
>> fax:       217-244-6678                Champaign, IL 61820
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From ripley at stats.ox.ac.uk  Fri Oct 12 20:10:53 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri, 12 Oct 2007 20:10:53 +0200 (CEST)
Subject: [Rd] File-Choose directory-Choose a folder (PR#9959)
Message-ID: <20071012181053.1199F283460B@mail.pubhealth.ku.dk>

As I've noted on the website, this appears to be a Vista bug as the 
Microsoft example code also fails.

Note: choose.dir() works in Rterm but not in Rgui.

On Wed, 10 Oct 2007, roberto.passera at tin.it wrote:

> Full_Name: Roberto Passera
> Version: 2.6.0 and 2.6.0 patched
> OS: Windows Vista Premium
> Submission from: (NULL) (151.48.70.219)
>
>
> Using R 2.6.0 and 2.6.0 patched Italian version on Windows Vista systems, when
> selecting File-Choose directory, the sub-command Choose a folder doesn't go,
> being stopped to Desktop option.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Oct 12 20:13:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Oct 2007 19:13:26 +0100 (BST)
Subject: [Rd] no visible binding
In-Reply-To: <470FA90F.8000503@statistik.uni-dortmund.de>
References: <050851DE-BDC9-4F82-8EA9-B05B9DC60AA7@uiuc.edu>
	<Pine.LNX.4.64.0710121855510.17956@reclus.nhh.no>
	<470FA90F.8000503@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0710121908150.21896@gannet.stats.ox.ac.uk>

Just to pick on this: 'how to react?'.

Codetools does have false positives, and non-standard evaluation often 
triggers them.  I've seen this one several times and pretty clearly a 
chararcter string is better style.

But some are just false positives, including those in MASS.


On Fri, 12 Oct 2007, Uwe Ligges wrote:

>
>
> Roger Bivand wrote:
>> On Fri, 12 Oct 2007, roger koenker wrote:
>>
>>> Could someone advise me about how to react to the message:
>>>
>>> * checking R code for possible problems ... NOTE
>>> slm: no visible binding for global variable 'response'
>>>
>>> from R CMD check SparseM    with
>>> * using R version 2.6.0 Under development (unstable) (2007-09-03 r42749)
>>>
>>> The offending code looks like this:
>>>
>>> "slm" <-
>>> function (formula,  data, weights, na.action, method = "csr",
>>>     contrasts = NULL, ...)
>>> {
>>>     call <- match.call()
>>>     m <- match.call(expand.dots = FALSE)
>>>     m$method <- m$model <- m$x <- m$y <- m$contrasts <-  m$... <- NULL
>>>     m[[1]] <- as.name("model.frame")
>>>     m <- eval(m, sys.frame(sys.parent()))
>>>     if (method == "model.frame")
>>>         return(m)
>>>     Terms <- attr(m, "terms")
>>>     weights <- model.extract(m, weights)
>>>     Y <- model.extract(m, response)
>>                              ^^^^^^^^
>>
>> which becomes:
>>
>>> as.character(substitute(response))
>> [1] "response"
>>
>> inside model.extract. I'm not sure why codetools doesn't pick up weights
>> in the same context one line earlier, probably because weights is also
>> assigned to.
>
> Yes. That object exists, but response does not.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lgautier at gmail.com  Sat Oct 13 14:50:05 2007
From: lgautier at gmail.com (lgautier at gmail.com)
Date: Sat, 13 Oct 2007 14:50:05 +0200 (CEST)
Subject: [Rd] website: Current version of R announced on the home page
	(PR#10339)
Message-ID: <20071013125005.DC6C2283460B@mail.pubhealth.ku.dk>

Full_Name: Laurent Gautier
Version: NA
OS: NA
Submission from: (NULL) (89.84.245.71)


When only reading the "news" entries on the home page
(http://www.r-project.org/), one could think that the latest R released is
R-2.5.1.


From jinghuazhao at hotmail.com  Sat Oct 13 21:12:13 2007
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Sat, 13 Oct 2007 19:12:13 +0000
Subject: [Rd] R260 cross-compilation
In-Reply-To: <470DF7AC.1070704@ipimar.pt>
References: <470DF7AC.1070704@ipimar.pt>
Message-ID: <BAY127-W394A62A53259B387873D36A5A10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071013/c5327f84/attachment.pl 

From maechler at stat.math.ethz.ch  Sat Oct 13 23:48:37 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 13 Oct 2007 23:48:37 +0200
Subject: [Rd] website: Current version of R announced on the home page
	(PR#10339)
In-Reply-To: <20071013125005.DC6C2283460B@mail.pubhealth.ku.dk>
References: <20071013125005.DC6C2283460B@mail.pubhealth.ku.dk>
Message-ID: <18193.15669.667486.477623@stat.math.ethz.ch>

>>>>> "LG" == Laurent Gautier <lgautier at gmail.com>
>>>>>     on Sat, 13 Oct 2007 14:50:05 +0200 (CEST) writes:

    LG> Full_Name: Laurent Gautier Version: NA OS: NA Submission
    LG> from: (NULL) (89.84.245.71)

Thank you for the heads up.

[ An e-mail to R-devel (or R-core) would have been slightly more
  appropriate than a formal bug report.
  But we *are* grateful.
]
    LG> When only reading the "news" entries on the home page
    LG> (http://www.r-project.org/), one could think that the
    LG> latest R released is R-2.5.1.

I've fixed it now; it will show on the web page within 24 hours
Thanks again,
Martin


From cstrato at aon.at  Sun Oct 14 16:44:34 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 14 Oct 2007 16:44:34 +0200
Subject: [Rd] Inconsistent behavior of sQuote and dQuote
Message-ID: <47122B52.80401@aon.at>

Dear all

When comparing sQuote("text") and dQuote("text") on MacOS X and Linux FC4
I get an inconsistent behavior (using the new release version R-2.6.0):

sQuote: On Mac I get the correct result "'text'", but on FC4 the 
incorrect result "`text?".
dQuote: On Mac I get the correct result "\"text\"", but on FC4 the 
incorrect result ""text"".

For this reason I cannot use these functions in my package.

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From ligges at statistik.uni-dortmund.de  Sun Oct 14 17:36:06 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 14 Oct 2007 17:36:06 +0200
Subject: [Rd] bug (?) in [.data.frame with matrix-like indexing
Message-ID: <47123766.2060308@statistik.uni-dortmund.de>

Consider in R-2.6.0 (also R-patched from yesterday):

iris[1, c(TRUE, FALSE, FALSE, FALSE, FALSE)]
##  Error in .subset2(xx, j) : recursive indexing failed at level 2

iris[1, c(FALSE, FALSE, FALSE, FALSE, TRUE)]
## Error in .subset2(xx, j) : attempt to select less than one element

i.e. matrix-like indexing on data.frames, one logically-indexed 
dimension with only one value TRUE in it.

It is not documented to work, but it did so in former versions of R.
Is it a bug or withdrawn support?


Uwe Ligges


From murdoch at stats.uwo.ca  Sun Oct 14 17:56:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 14 Oct 2007 11:56:39 -0400
Subject: [Rd] Inconsistent behavior of sQuote and dQuote
In-Reply-To: <47122B52.80401@aon.at>
References: <47122B52.80401@aon.at>
Message-ID: <47123C37.3070706@stats.uwo.ca>

On 14/10/2007 10:44 AM, cstrato wrote:
> Dear all
> 
> When comparing sQuote("text") and dQuote("text") on MacOS X and Linux FC4
> I get an inconsistent behavior (using the new release version R-2.6.0):
> 
> sQuote: On Mac I get the correct result "'text'", but on FC4 the 
> incorrect result "`text?".

Those both look correct to me (but not the same).  What do you see?

> dQuote: On Mac I get the correct result "\"text\"", but on FC4 the 
> incorrect result ""text"".

The second one looks wrong here (no escapes shown), but I suspect those 
inner quotes aren't really the same as the outer quotes, and that's why 
they're not escaped.

If you don't want the fancyquotes at all, you can use 
options(useFancyQuotes=FALSE).  In a package, it would be polite to do 
this only locally, i.e. have something like

save <- options(useFancyQuotes=FALSE)
on.exit(options(save))

in functions that call sQuote or dQuote, because options() belong to the 
user, not to you.

Duncan Murdoch

> 
> For this reason I cannot use these functions in my package.
> 
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at comcast.net  Sun Oct 14 18:18:14 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sun, 14 Oct 2007 11:18:14 -0500
Subject: [Rd] Inconsistent behavior of sQuote and dQuote
In-Reply-To: <47123C37.3070706@stats.uwo.ca>
References: <47122B52.80401@aon.at>  <47123C37.3070706@stats.uwo.ca>
Message-ID: <1192378694.3559.45.camel@Bellerophon.localdomain>

On Sun, 2007-10-14 at 11:56 -0400, Duncan Murdoch wrote:
> On 14/10/2007 10:44 AM, cstrato wrote:
> > Dear all
> > 
> > When comparing sQuote("text") and dQuote("text") on MacOS X and Linux FC4
> > I get an inconsistent behavior (using the new release version R-2.6.0):
> > 
> > sQuote: On Mac I get the correct result "'text'", but on FC4 the 
> > incorrect result "`text?".
> 
> Those both look correct to me (but not the same).  What do you see?
> 
> > dQuote: On Mac I get the correct result "\"text\"", but on FC4 the 
> > incorrect result ""text"".
> 
> The second one looks wrong here (no escapes shown), but I suspect those 
> inner quotes aren't really the same as the outer quotes, and that's why 
> they're not escaped.
> 
> If you don't want the fancyquotes at all, you can use 
> options(useFancyQuotes=FALSE).  In a package, it would be polite to do 
> this only locally, i.e. have something like
> 
> save <- options(useFancyQuotes=FALSE)
> on.exit(options(save))
> 
> in functions that call sQuote or dQuote, because options() belong to the 
> user, not to you.

FWIW, on F7 I get:

> sQuote("text")
[1] "?text?"

> dQuote("text")
[1] "?text?"


options(useFancyQuotes = FALSE)

> sQuote("text")
[1] "'text'"

> dQuote("text")
[1] "\"text\""


The differing behavior between OS X and FC4 is perhaps due to the
available character sets and the locales, presuming that they may not be
the same. See the Details section of ?sQuote.

I might also point out that FC4 has been EOL for some time. It would be
prudent to consider updating to a more recent version. FC6 and F7 are
the currently maintained releases, with F8 due to be released on
November 8.

HTH,

Marc Schwartz


From cstrato at aon.at  Sun Oct 14 18:45:57 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 14 Oct 2007 18:45:57 +0200
Subject: [Rd] Inconsistent behavior of sQuote and dQuote
In-Reply-To: <1192378694.3559.45.camel@Bellerophon.localdomain>
References: <47122B52.80401@aon.at> <47123C37.3070706@stats.uwo.ca>
	<1192378694.3559.45.camel@Bellerophon.localdomain>
Message-ID: <471247C5.8040701@aon.at>

Dear Duncan and Marc

Thank you for your comments, and please allow me to express my personal 
opinion:

I have read the comments of Markus Kuhn mentioned in the help file to 
sQuote:
http://www.cl.cam.ac.uk/~mgk25/ucs/quotes.html

Since R is a programming language, the behavior should in my opinion be 
consistent
for all platforms, and as default it should only rely on ASCII 
characters, in this
case 0x22 and 0x27, so it is possible to pass these characters to other 
programming
languages, in my case C++.

Since shQuote(string,type) has already a type option, I would suggest to 
add
options to sQuote() and dQuote(), too, with default being ASCII behavior.

However, this is only my personal opinion.

Best regards
Christian

Marc Schwartz wrote:
> On Sun, 2007-10-14 at 11:56 -0400, Duncan Murdoch wrote:
>   
>> On 14/10/2007 10:44 AM, cstrato wrote:
>>     
>>> Dear all
>>>
>>> When comparing sQuote("text") and dQuote("text") on MacOS X and Linux FC4
>>> I get an inconsistent behavior (using the new release version R-2.6.0):
>>>
>>> sQuote: On Mac I get the correct result "'text'", but on FC4 the 
>>> incorrect result "`text?".
>>>       
>> Those both look correct to me (but not the same).  What do you see?
>>
>>     
>>> dQuote: On Mac I get the correct result "\"text\"", but on FC4 the 
>>> incorrect result ""text"".
>>>       
>> The second one looks wrong here (no escapes shown), but I suspect those 
>> inner quotes aren't really the same as the outer quotes, and that's why 
>> they're not escaped.
>>
>> If you don't want the fancyquotes at all, you can use 
>> options(useFancyQuotes=FALSE).  In a package, it would be polite to do 
>> this only locally, i.e. have something like
>>
>> save <- options(useFancyQuotes=FALSE)
>> on.exit(options(save))
>>
>> in functions that call sQuote or dQuote, because options() belong to the 
>> user, not to you.
>>     
>
> FWIW, on F7 I get:
>
>   
>> sQuote("text")
>>     
> [1] "?text?"
>
>   
>> dQuote("text")
>>     
> [1] "?text?"
>
>
> options(useFancyQuotes = FALSE)
>
>   
>> sQuote("text")
>>     
> [1] "'text'"
>
>   
>> dQuote("text")
>>     
> [1] "\"text\""
>
>
> The differing behavior between OS X and FC4 is perhaps due to the
> available character sets and the locales, presuming that they may not be
> the same. See the Details section of ?sQuote.
>
> I might also point out that FC4 has been EOL for some time. It would be
> prudent to consider updating to a more recent version. FC6 and F7 are
> the currently maintained releases, with F8 due to be released on
> November 8.
>
> HTH,
>
> Marc Schwartz
>
>
>
>
>


From p.dalgaard at biostat.ku.dk  Sun Oct 14 19:01:55 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 14 Oct 2007 19:01:55 +0200
Subject: [Rd] bug (?) in [.data.frame with matrix-like indexing
In-Reply-To: <47123766.2060308@statistik.uni-dortmund.de>
References: <47123766.2060308@statistik.uni-dortmund.de>
Message-ID: <47124B83.5040004@biostat.ku.dk>

Uwe Ligges wrote:
> Consider in R-2.6.0 (also R-patched from yesterday):
>
> iris[1, c(TRUE, FALSE, FALSE, FALSE, FALSE)]
> ##  Error in .subset2(xx, j) : recursive indexing failed at level 2
>
> iris[1, c(FALSE, FALSE, FALSE, FALSE, TRUE)]
> ## Error in .subset2(xx, j) : attempt to select less than one element
>
> i.e. matrix-like indexing on data.frames, one logically-indexed 
> dimension with only one value TRUE in it.
>
> It is not documented to work, but it did so in former versions of R.
> Is it a bug or withdrawn support?
>
>
>   
It's been reported before. Looks unintentional.

As I also said last time, the log for the relevant revision has

"make DF[, 1] and DF[1:m, 1] consistent"

(and it doesn't...)


> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mtmorgan at fhcrc.org  Sun Oct 14 20:40:25 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 14 Oct 2007 11:40:25 -0700
Subject: [Rd] data.frame row.names=NULL with named vector
Message-ID: <6phmyulk09y.fsf@gopher4.fhcrc.org>

A minor issue with data.frame is a change introduced leading to R
2.5.0, where row.names=NULL (i.e., do not name rows) is not honored
with a named vector

> x <- letters[1:3]
> names(x) <- x
> data.frame(x, row.names=NULL)
  x
a a
b b
c c

and a slightly more subtle example

> data.frame(y=1:3, x, row.names=NULL)
  y x
a 1 a
b 2 b
c 3 c

A 2.5.0 news entry says

    o	data.frame() ignored 'row.names' for 0-column data frames, and
	no longer treats an explicit row.names=NULL differently from
	the default value.

The relevant section of ?data.frame however says

     If 'row.names' was supplied as 'NULL' or no suitable component
     was found the row names are the integer sequence starting at one

This is not consistent with the current behavior, and is unchanged
from the pre 2.5.0 version. The workaround is distinctly hackish

> df <- data.frame(x)
> row.names(df) <- NULL

> sessionInfo()
R version 2.7.0 Under development (unstable) (2007-10-13 r43163) 
x86_64-unknown-linux-gnu 

Martin


From t.yee at auckland.ac.nz  Sun Oct 14 23:23:42 2007
From: t.yee at auckland.ac.nz (Thomas Yee)
Date: Mon, 15 Oct 2007 10:23:42 +1300
Subject: [Rd] Extending deriv3()
Message-ID: <471288DE.2090500@auckland.ac.nz>

Hello,

I was wondering if the functions deriv3(), deriv() etc. could be extended
to handle psigamma() and its special cases (digamma(), trigamma()
etc.). From the error message it seems that 'psigamma' needs to be
added to the derivatives table.
This might be easy since psigamma() has a deriv argument.

Additionally, this error message is also obtained when requesting for
the Hessian of the gamma and lgamma functions:

d3 = deriv(~  gamma(y), namev="y", hessian= TRUE)
d3 = deriv(~ lgamma(y), namev="y", hessian= TRUE)

Another class of special functions worth adding are the Bessel functions.

Thanks

Thomas


From ripley at stats.ox.ac.uk  Mon Oct 15 11:13:11 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Oct 2007 10:13:11 +0100 (BST)
Subject: [Rd] Extending deriv3()
In-Reply-To: <471288DE.2090500@auckland.ac.nz>
References: <471288DE.2090500@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0710150953250.11139@gannet.stats.ox.ac.uk>

On Mon, 15 Oct 2007, Thomas Yee wrote:

> Hello,
>
> I was wondering if the functions deriv3(), deriv() etc. could be extended
> to handle psigamma() and its special cases (digamma(), trigamma()
> etc.). From the error message it seems that 'psigamma' needs to be
> added to the derivatives table.
> This might be easy since psigamma() has a deriv argument.

If you look at ?deriv you will see that it only knows about functions *of 
one argument* and operators.  So it would be easy to add digamma(x) and 
psigamma(x) (and I will do so shortly), it would not be so easy to add 
psigamma(x, deriv).

> Additionally, this error message is also obtained when requesting for
> the Hessian of the gamma and lgamma functions:
>
> d3 = deriv(~  gamma(y), namev="y", hessian= TRUE)
> d3 = deriv(~ lgamma(y), namev="y", hessian= TRUE)
>
> Another class of special functions worth adding are the Bessel functions.

Well, you can always submit a patch ....

Note that deriv() in R differs from that in S in being done in C and hence 
not being user-extensible.  A long time ago that had an advantage: S's 
deriv could be very slow and take a lot of memory by the standards of the 
early 1990's.  Rather than work on adding yet more special cases it would 
seem better to work on making it user-extensible.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From savicky at cs.cas.cz  Mon Oct 15 12:49:22 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 15 Oct 2007 12:49:22 +0200
Subject: [Rd] all zeroes in Mersenne Twister state may remain undetected
Message-ID: <20071015104922.GA3412@cs.cas.cz>

The function runif(n) contains a protection against a corrupted .Random.seed.
Besides other things, it tests whether at least one of the numbers 
.Random.seed[3:626] is not zero. If all(.Random.seed[3:626]==0), then
the internal Mersenne Twister state is regenerated using current time,
since a zero state is a fixed point of the recurrence and, hence, produces
a constant sequence.

However, the condition any(.Random.seed[3:626]!=0) does not imply that
the internal Mersenne Twister state is indeed not zero, since only the
most significant bit of .Random.seed[3] belongs to the internal state.
Hence, the number of bits in the state of Mersenne Twister
is 624*32 - 31 = 19937, which explains the period 2^19937-1.

For example, if .Random.seed[3] == 1, we always have the condition
  any(.Random.seed[3:626]!=0)
satisfied, but the internal state may still be effectively zero. An 
example of such a situation is
  RNGkind("default")
  .Random.seed[3:626] <- as.integer(0)
  .Random.seed[3] <- as.integer(1)
  x <- runif(10000)
  all(x==x[1]) # TRUE
  length(unique(x)) # 1
  all(.Random.seed[3:626]==0) # TRUE
Here, the internal state was effectively zero, but this fact was not
detected, since some (unimportant) bits of .Random.seed[3] were not zero.

On the contrary, if also .Random.seed[3]==0, then the internal state
is regenerated and the output of runif() becomes non constant:
  RNGkind("default")
  .Random.seed[3:626] <- as.integer(0)
  x <- runif(10000)
  all(x==x[1]) # FALSE
  length(unique(x)) # 10000
  all(.Random.seed[3:626]==0) # FALSE

The following patch to FixupSeeds corrects the detection of zero state:

--- R-devel_2007-10-14-orig/src/main/RNG.c	2007-09-02 07:49:35.000000000 +0200
+++ R-devel_2007-10-14-FixupSeeds/src/main/RNG.c	2007-10-15 04:33:52.988060624 +0200
@@ -181,7 +181,9 @@
 	 /* No action unless user has corrupted .Random.seed */
 	if(I1 <= 0) I1 = 624; 
 	/* check for all zeroes */
-	for (j = 1; j <= 624; j++)
+	notallzero = ((RNG_Table[RNG_kind].i_seed[1] & 0x80000000) != 0);
+	if(!notallzero)
+	for (j = 2; j <= 624; j++)
 	    if(RNG_Table[RNG_kind].i_seed[j] != 0) {
 		notallzero = 1;
 		break;

Petr Savicky.


From bob.ohara at helsinki.fi  Mon Oct 15 10:30:05 2007
From: bob.ohara at helsinki.fi (bob.ohara at helsinki.fi)
Date: Mon, 15 Oct 2007 10:30:05 +0200 (CEST)
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
Message-ID: <20071015083005.DE2E42834169@mail.pubhealth.ku.dk>

Full_Name: Bob O'Hara
Version: 2.6.0
OS: Windows XP
Submission from: (NULL) (88.112.20.250)


Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
work as expected, I haven't looked at anything else.

Some code to see if you can reproduce the bug (or discover it's in my head...):

boxplot(count ~ spray, data = InsectSprays)

# Try to change x-axis:
boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))

# Plot horizontally:
boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)

# Now try to change x-axis:
boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
# Changes y-axis!

# Now try to change y-axis:
boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
# Changes x-axis!

# Plot x-axis on log scale:
boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
# Does indeed change x-axis

# Don't add ticks on x-axis:
boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
# Works as expected.


From santos at supagro.inra.fr  Mon Oct 15 10:43:18 2007
From: santos at supagro.inra.fr (Filipe Santos)
Date: Mon, 15 Oct 2007 10:43:18 +0200
Subject: [Rd] Error in Windows Vista, saving workspace...
In-Reply-To: <470FA8D6.3070107@statistik.uni-dortmund.de>
References: <200710121424.44622.santos@supagro.inra.fr>
	<470FA8D6.3070107@statistik.uni-dortmund.de>
Message-ID: <200710151043.19743.santos@supagro.inra.fr>

I just did a standard installation of R in my computer.

What I was trying here is to call attention that Windows Vista doesn't allow 
normal users to write on the R default installation directory. Instead, the 
information about configuration files ( and in this case .RDataTmp ) 
shouldn't they be stored in Username/AppData/Local ?

Filipe Santos

On Friday 12 October 2007 19:03:18 you wrote:
> Do you have write permissions in the current working directory? I guess
> not.
>
> Uwe Ligges
>
> Filipe Santos wrote:
> > Dear all...
> >
> > I'm using R 2.6.0 in windows Vista. And I got the following error:
> >> quit()
> >
> > Save workspace image? [y/n/c]: y
> > Error in gzfile(file,"wb"): unable to open connection
> > In addiction: Warning message:
> > In gzfile(file, "wb") : cannot open compressed file '.RDataTmp'
> >
> > This happens in both in RGui and Rterm
> >
> > Thanks,
> > Filipe Santos
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Mon Oct 15 14:20:02 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Oct 2007 08:20:02 -0400
Subject: [Rd] Extending deriv3()
In-Reply-To: <Pine.LNX.4.64.0710150953250.11139@gannet.stats.ox.ac.uk>
References: <471288DE.2090500@auckland.ac.nz>
	<Pine.LNX.4.64.0710150953250.11139@gannet.stats.ox.ac.uk>
Message-ID: <971536df0710150520s30f2ab0cn4723e1b027a0351a@mail.gmail.com>

If you are modifying it it would also be nice to add
{ to the derivative table so one can write this:

    f <- function(x) x*x
    deriv(body(f), "x", func = TRUE)

Currently, one must do:

    deriv(body(f)[[2]], "x", func = TRUE)


On 10/15/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Mon, 15 Oct 2007, Thomas Yee wrote:
>
> > Hello,
> >
> > I was wondering if the functions deriv3(), deriv() etc. could be extended
> > to handle psigamma() and its special cases (digamma(), trigamma()
> > etc.). From the error message it seems that 'psigamma' needs to be
> > added to the derivatives table.
> > This might be easy since psigamma() has a deriv argument.
>
> If you look at ?deriv you will see that it only knows about functions *of
> one argument* and operators.  So it would be easy to add digamma(x) and
> psigamma(x) (and I will do so shortly), it would not be so easy to add
> psigamma(x, deriv).
>
> > Additionally, this error message is also obtained when requesting for
> > the Hessian of the gamma and lgamma functions:
> >
> > d3 = deriv(~  gamma(y), namev="y", hessian= TRUE)
> > d3 = deriv(~ lgamma(y), namev="y", hessian= TRUE)
> >
> > Another class of special functions worth adding are the Bessel functions.
>
> Well, you can always submit a patch ....
>
> Note that deriv() in R differs from that in S in being done in C and hence
> not being user-extensible.  A long time ago that had an advantage: S's
> deriv could be very slow and take a lot of memory by the standards of the
> early 1990's.  Rather than work on adding yet more special cases it would
> seem better to work on making it user-extensible.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From marc_schwartz at comcast.net  Mon Oct 15 14:20:16 2007
From: marc_schwartz at comcast.net (marc_schwartz at comcast.net)
Date: Mon, 15 Oct 2007 14:20:16 +0200 (CEST)
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
Message-ID: <20071015122016.CB1E12834613@mail.pubhealth.ku.dk>

On Mon, 2007-10-15 at 10:30 +0200, bob.ohara at helsinki.fi wrote:
> Full_Name: Bob O'Hara
> Version: 2.6.0
> OS: Windows XP
> Submission from: (NULL) (88.112.20.250)
> 
> 
> Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
> At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
> work as expected, I haven't looked at anything else.
> 
> Some code to see if you can reproduce the bug (or discover it's in my head...):
> 
> boxplot(count ~ spray, data = InsectSprays)
> 
> # Try to change x-axis:
> boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))
> 
> # Plot horizontally:
> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)
> 
> # Now try to change x-axis:
> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
> # Changes y-axis!
> 
> # Now try to change y-axis:
> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
> # Changes x-axis!
> 
> # Plot x-axis on log scale:
> boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
> # Does indeed change x-axis
> 
> # Don't add ticks on x-axis:
> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
> # Works as expected.

Hi Bob,

No, it's not in your head. This is documented in ?bxp, which is the
function that actually does the plotting for boxplot(). See the
description of 'pars' in ?bxp:

"Currently, yaxs and ylim are used ???along the boxplot???, i.e.,
vertically, when horizontal is false, and xlim horizontally."

So essentially, the named 'x' and 'y' axes are rotated 90 degrees when
you use 'horizontal = TRUE', rather than the vertical axis always being
'y' and the horizontal axis always being 'x'. This has been discussed on
the lists previously.

Regards,

Marc Schwartz


From cipollin at ds.unifi.it  Mon Oct 15 15:00:55 2007
From: cipollin at ds.unifi.it (Fabrizio Cipollini)
Date: Mon, 15 Oct 2007 15:00:55 +0200
Subject: [Rd] Constants
Message-ID: <200710151259.l9FCxBxE014098@ds.unifi.it>

Dear R developers

I wrote a package whose computational 'engine' is programmed in Fortran 77.
However, I used also C code, mainly for exploiting the Mathlib Standalone
set of functions.

I successfully compiled and used my package for months, under R-2.4.1 
(and MINGW - GCC 3.4.2).

Now, I switched to R-2.6.0 (and the 'Rtool.exe' set of Murdoch, 
installed EXACTLY
as in its prescriptions) and I encountered problems during compilation.
In a C function I use the DOUBLE_EPS constant (of course, I loaded 
the <R_ext/Constants.h> header).
but the the 'R CMD check' say that
"
CFunctions1.c:333: error: `DBL_EPSILON' undeclared (first use in this function)
...
"

I suspect that the difference between my two compilation experiences 
lies in the different structure
of the <float.h> header between GCC 3.4.2 and GCC 3.4.5.
I'm not a C expertise and hence the question: There is a clean way 
for using this
kind of constants (DOUBLE_EPS and other similar) as my previous experience?

Thanks a lot in advance
Fabrizio

P.S. I have a Pentium Centrino and Windows XP.


From ripley at stats.ox.ac.uk  Mon Oct 15 15:05:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Oct 2007 14:05:46 +0100 (BST)
Subject: [Rd] Error in Windows Vista, saving workspace...
In-Reply-To: <200710151043.19743.santos@supagro.inra.fr>
References: <200710121424.44622.santos@supagro.inra.fr>
	<470FA8D6.3070107@statistik.uni-dortmund.de>
	<200710151043.19743.santos@supagro.inra.fr>
Message-ID: <Pine.LNX.4.64.0710151403450.8052@gannet.stats.ox.ac.uk>

On Mon, 15 Oct 2007, Filipe Santos wrote:

> I just did a standard installation of R in my computer.
>
> What I was trying here is to call attention that Windows Vista doesn't allow
> normal users to write on the R default installation directory. Instead, the
> information about configuration files ( and in this case .RDataTmp )
> shouldn't they be stored in Username/AppData/Local ?

It does if the user installs R.  Note the advice in the rw-FAQ to set up 
a shortcut with an appropriate working directory, which it seems you did 
not do.

There is nothing new about Vista here: all NT-based versions of Windows 
did the same thing.


>
> Filipe Santos
>
> On Friday 12 October 2007 19:03:18 you wrote:
>> Do you have write permissions in the current working directory? I guess
>> not.
>>
>> Uwe Ligges
>>
>> Filipe Santos wrote:
>>> Dear all...
>>>
>>> I'm using R 2.6.0 in windows Vista. And I got the following error:
>>>> quit()
>>>
>>> Save workspace image? [y/n/c]: y
>>> Error in gzfile(file,"wb"): unable to open connection
>>> In addiction: Warning message:
>>> In gzfile(file, "wb") : cannot open compressed file '.RDataTmp'
>>>
>>> This happens in both in RGui and Rterm
>>>
>>> Thanks,
>>> Filipe Santos
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Oct 15 15:25:16 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon, 15 Oct 2007 15:25:16 +0200 (CEST)
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
Message-ID: <20071015132516.0E44A2834615@mail.pubhealth.ku.dk>

>>>>> "ms" == marc schwartz <marc_schwartz at comcast.net>
>>>>>     on Mon, 15 Oct 2007 14:20:16 +0200 (CEST) writes:

    ms> On Mon, 2007-10-15 at 10:30 +0200, bob.ohara at helsinki.fi wrote:
    >> Full_Name: Bob O'Hara
    >> Version: 2.6.0
    >> OS: Windows XP
    >> Submission from: (NULL) (88.112.20.250)
    >> 
    >> 
    >> Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
    >> At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
    >> work as expected, I haven't looked at anything else.
    >> 
    >> Some code to see if you can reproduce the bug (or discover it's in my head...):
    >> 
    >> boxplot(count ~ spray, data = InsectSprays)
    >> 
    >> # Try to change x-axis:
    >> boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))
    >> 
    >> # Plot horizontally:
    >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)
    >> 
    >> # Now try to change x-axis:
    >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
    >> # Changes y-axis!
    >> 
    >> # Now try to change y-axis:
    >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
    >> # Changes x-axis!
    >> 
    >> # Plot x-axis on log scale:
    >> boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
    >> # Does indeed change x-axis
    >> 
    >> # Don't add ticks on x-axis:
    >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
    >> # Works as expected.

    ms> Hi Bob,

    ms> No, it's not in your head. This is documented in ?bxp, which is the
    ms> function that actually does the plotting for boxplot(). See the
    ms> description of 'pars' in ?bxp:

    ms> "Currently, yaxs and ylim are used ???along the boxplot???, i.e.,
    ms> vertically, when horizontal is false, and xlim horizontally."

    ms> So essentially, the named 'x' and 'y' axes are rotated 90 degrees when
    ms> you use 'horizontal = TRUE', rather than the vertical axis always being
    ms> 'y' and the horizontal axis always being 'x'. This has been discussed on
    ms> the lists previously.

Yes; thank you, Marc.

And the reason for this is very sensible I think:

If you have a longish  boxplot()  or  bxp() command,
and you just want to go from vertical to horizontal or vice
versa, it makes most sense just to have to change the
'horizontal' flag and not having to see if there are other 'x*'
and or 'y*' arguments that all need to be changed as well.

Regards,
Martin Maechler


From guillot at math.chalmers.se  Mon Oct 15 15:29:09 2007
From: guillot at math.chalmers.se (Gilles GUILLOT)
Date: Mon, 15 Oct 2007 15:29:09 +0200 (CEST)
Subject: [Rd] package Geneland / Rgui under windows
Message-ID: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>

Hi,
I experienced a problem with the package Geneland under R 2.6.0
with  windows XP professional.

The commands below should simulate a dataset,
then make an MCMC simulation stored in tempdir().

It works with R 2.5.1 (both GUI and command line)
It works with the command line of R 2.6.0
but not with the R GUI of 2.6.0: no output file is created in tempdir()
and R remains frozen.
I reported it as a bug
(PR#9964)  but did not get any feed back.

Thanks in advance for any help.

Gilles

set.seed(1)
data <- simdata(nindiv=200,
                coord.lim=c(0,1,0,1) ,
                number.nuclei=5 ,
                allele.numbers=rep(10,20),
                IBD=FALSE,
                npop=2,
                give.tess.grid=FALSE)


path.mcmc <- paste(tempdir(),"/",sep="")

mcmcFmodel(coordinates= t(data$coord.indiv),
           genotypes=data$genotypes,
           path.mcmc=path.mcmc,
           rate.max=10,
           delta.coord=0,
           npopmin=1,
           npopinit=5,
           npopmax=5,
           nb.nuclei.max=50,
           nit=500,
           thinning=1,
           freq.model="Dirichlet",
           varnpop=FALSE,
           spatial=TRUE)


From jarioksa at sun3.oulu.fi  Mon Oct 15 15:42:24 2007
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon, 15 Oct 2007 16:42:24 +0300
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
In-Reply-To: <20071015132516.0E44A2834615@mail.pubhealth.ku.dk>
References: <20071015132516.0E44A2834615@mail.pubhealth.ku.dk>
Message-ID: <1192455744.6005.14.camel@biol102145.oulu.fi>

On Mon, 2007-10-15 at 15:25 +0200, maechler at stat.math.ethz.ch wrote:
> >>>>> "ms" == marc schwartz <marc_schwartz at comcast.net>
> >>>>>     on Mon, 15 Oct 2007 14:20:16 +0200 (CEST) writes:
> 
>     ms> On Mon, 2007-10-15 at 10:30 +0200, bob.ohara at helsinki.fi wrote:
>     >> Full_Name: Bob O'Hara
>     >> Version: 2.6.0
>     >> OS: Windows XP
>     >> Submission from: (NULL) (88.112.20.250)
>     >> 
>     >> 
>     >> Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
>     >> At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
>     >> work as expected, I haven't looked at anything else.
>     >> 
>     >> Some code to see if you can reproduce the bug (or discover it's in my head...):
>     >> 
>     >> boxplot(count ~ spray, data = InsectSprays)
>     >> 
>     >> # Try to change x-axis:
>     >> boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))
>     >> 
>     >> # Plot horizontally:
>     >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)
>     >> 
>     >> # Now try to change x-axis:
>     >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
>     >> # Changes y-axis!
>     >> 
>     >> # Now try to change y-axis:
>     >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
>     >> # Changes x-axis!
>     >> 
>     >> # Plot x-axis on log scale:
>     >> boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
>     >> # Does indeed change x-axis
>     >> 
>     >> # Don't add ticks on x-axis:
>     >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
>     >> # Works as expected.
> 
>     ms> Hi Bob,
> 
>     ms> No, it's not in your head. This is documented in ?bxp, which is the
>     ms> function that actually does the plotting for boxplot(). See the
>     ms> description of 'pars' in ?bxp:
> 
>     ms> "Currently, yaxs and ylim are used ???along the boxplot???, i.e.,
>     ms> vertically, when horizontal is false, and xlim horizontally."
> 
>     ms> So essentially, the named 'x' and 'y' axes are rotated 90 degrees when
>     ms> you use 'horizontal = TRUE', rather than the vertical axis always being
>     ms> 'y' and the horizontal axis always being 'x'. This has been discussed on
>     ms> the lists previously.
> 
> Yes; thank you, Marc.
> 
> And the reason for this is very sensible I think:
> 
> If you have a longish  boxplot()  or  bxp() command,
> and you just want to go from vertical to horizontal or vice
> versa, it makes most sense just to have to change the
> 'horizontal' flag and not having to see if there are other 'x*'
> and or 'y*' arguments that all need to be changed as well.
> 
Except that you must change xaxt/yaxt and log="x"/log="y" which do not
follow the "along the box" logic, and behave differently than
xlim/ylim. 

Nothing of this is fatal, but this probably needs more than one
iteration to find which way each of the x* and y* arguments works.

cheers, jari oksanen


From sdavis2 at mail.nih.gov  Mon Oct 15 16:06:33 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 15 Oct 2007 10:06:33 -0400
Subject: [Rd] package Geneland / Rgui under windows
In-Reply-To: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>
References: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>
Message-ID: <471373E9.90004@mail.nih.gov>

Gilles GUILLOT wrote:
> Hi,
> I experienced a problem with the package Geneland under R 2.6.0
> with  windows XP professional.
> 
> The commands below should simulate a dataset,
> then make an MCMC simulation stored in tempdir().
> 
> It works with R 2.5.1 (both GUI and command line)
> It works with the command line of R 2.6.0
> but not with the R GUI of 2.6.0: no output file is created in tempdir()
> and R remains frozen.
> I reported it as a bug
> (PR#9964)  but did not get any feed back.

I think the general rule-of-thumb is to contact the package author for
problems with individual packages.  Many package authors read this list,
but there are probably some that do not.  Sometimes problems with
individual packages are actually bugs in R, but I would say that this is
not usually the case.  However, the package author is probably the best
person to make this judgment.

Sean


From guillot at math.chalmers.se  Mon Oct 15 16:29:44 2007
From: guillot at math.chalmers.se (Gilles GUILLOT)
Date: Mon, 15 Oct 2007 16:29:44 +0200 (CEST)
Subject: [Rd] package Geneland / Rgui under windows
In-Reply-To: <471373E9.90004@mail.nih.gov>
References: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>
	<471373E9.90004@mail.nih.gov>
Message-ID: <37924.129.240.88.50.1192458584.squirrel@webmail.chalmers.se>

I forgot to say that I was the package author.
I suspected a bug of R as Geneland worked fine for two
years and the problem popped up
with the release of R 2.6.0
And I can't see any explanation.
So, any clue would help.

gilles


> Gilles GUILLOT wrote:
>> Hi,
>> I experienced a problem with the package Geneland under R 2.6.0
>> with  windows XP professional.
>>
>> The commands below should simulate a dataset,
>> then make an MCMC simulation stored in tempdir().
>>
>> It works with R 2.5.1 (both GUI and command line)
>> It works with the command line of R 2.6.0
>> but not with the R GUI of 2.6.0: no output file is created in tempdir()
>> and R remains frozen.
>> I reported it as a bug
>> (PR#9964)  but did not get any feed back.
>
> I think the general rule-of-thumb is to contact the package author for
> problems with individual packages.  Many package authors read this list,
> but there are probably some that do not.  Sometimes problems with
> individual packages are actually bugs in R, but I would say that this is
> not usually the case.  However, the package author is probably the best
> person to make this judgment.
>
> Sean
>


_________________________________________________________________
Gilles GUILLOT
INRA MIA Paris - FRANCE

Now working from Matematisk Statistik
Chalmers University of Technology,
S-412 96 G?teborg, SWEDEN
Rum: 3079
tel: +46 31 772 5338,
Email: guillot at math.chalmers.se
http://www.inapg.inra.fr/ens_rech/mathinfo/personnel/guillot/welcome.html


From ripley at stats.ox.ac.uk  Mon Oct 15 17:40:08 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Oct 2007 16:40:08 +0100 (BST)
Subject: [Rd] Extending deriv3()
In-Reply-To: <Pine.LNX.4.64.0710150953250.11139@gannet.stats.ox.ac.uk>
References: <471288DE.2090500@auckland.ac.nz>
	<Pine.LNX.4.64.0710150953250.11139@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0710151636590.29487@gannet.stats.ox.ac.uk>

BTW, this has come up several times before, e.g.

http://tolstoy.newcastle.edu.au/R/e2/help/07/08/22447.html

is a call for patches.

On Mon, 15 Oct 2007, Prof Brian Ripley wrote:

> On Mon, 15 Oct 2007, Thomas Yee wrote:
>
>> Hello,
>>
>> I was wondering if the functions deriv3(), deriv() etc. could be extended
>> to handle psigamma() and its special cases (digamma(), trigamma()
>> etc.). From the error message it seems that 'psigamma' needs to be
>> added to the derivatives table.
>> This might be easy since psigamma() has a deriv argument.
>
> If you look at ?deriv you will see that it only knows about functions *of
> one argument* and operators.  So it would be easy to add digamma(x) and
> psigamma(x) (and I will do so shortly), it would not be so easy to add
> psigamma(x, deriv).

I've now implemented that in R-devel, including the 'not so easy' case.

>> Additionally, this error message is also obtained when requesting for
>> the Hessian of the gamma and lgamma functions:
>>
>> d3 = deriv(~  gamma(y), namev="y", hessian= TRUE)
>> d3 = deriv(~ lgamma(y), namev="y", hessian= TRUE)
>>
>> Another class of special functions worth adding are the Bessel functions.
>
> Well, you can always submit a patch ....
>
> Note that deriv() in R differs from that in S in being done in C and hence
> not being user-extensible.  A long time ago that had an advantage: S's
> deriv could be very slow and take a lot of memory by the standards of the
> early 1990's.  Rather than work on adding yet more special cases it would
> seem better to work on making it user-extensible.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Oct 15 18:25:41 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon, 15 Oct 2007 18:25:41 +0200 (CEST)
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
Message-ID: <20071015162541.31B0F283416A@mail.pubhealth.ku.dk>

>>>>> "JO" == Jari Oksanen <jarioksa at sun3.oulu.fi>
>>>>>     on Mon, 15 Oct 2007 16:42:24 +0300 writes:

    JO> On Mon, 2007-10-15 at 15:25 +0200, maechler at stat.math.ethz.ch wrote:
    >> >>>>> "ms" == marc schwartz <marc_schwartz at comcast.net>
    >> >>>>>     on Mon, 15 Oct 2007 14:20:16 +0200 (CEST) writes:
    >> 
    ms> On Mon, 2007-10-15 at 10:30 +0200, bob.ohara at helsinki.fi wrote:
    >> >> Full_Name: Bob O'Hara
    >> >> Version: 2.6.0
    >> >> OS: Windows XP
    >> >> Submission from: (NULL) (88.112.20.250)
    >> >> 
    >> >> 
    >> >> Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
    >> >> At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
    >> >> work as expected, I haven't looked at anything else.
    >> >> 
    >> >> Some code to see if you can reproduce the bug (or discover it's in my head...):
    >> >> 
    >> >> boxplot(count ~ spray, data = InsectSprays)
    >> >> 
    >> >> # Try to change x-axis:
    >> >> boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))
    >> >> 
    >> >> # Plot horizontally:
    >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)
    >> >> 
    >> >> # Now try to change x-axis:
    >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
    >> >> # Changes y-axis!
    >> >> 
    >> >> # Now try to change y-axis:
    >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
    >> >> # Changes x-axis!
    >> >> 
    >> >> # Plot x-axis on log scale:
    >> >> boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
    >> >> # Does indeed change x-axis
    >> >> 
    >> >> # Don't add ticks on x-axis:
    >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
    >> >> # Works as expected.
    >> 
    ms> Hi Bob,
    >> 
    ms> No, it's not in your head. This is documented in ?bxp, which is the
    ms> function that actually does the plotting for boxplot(). See the
    ms> description of 'pars' in ?bxp:
    >> 
    ms> "Currently, yaxs and ylim are used ???????along the boxplot???????, i.e.,
    ms> vertically, when horizontal is false, and xlim horizontally."
    >> 
    ms> So essentially, the named 'x' and 'y' axes are rotated 90 degrees when
    ms> you use 'horizontal = TRUE', rather than the vertical axis always being
    ms> 'y' and the horizontal axis always being 'x'. This has been discussed on
    ms> the lists previously.
    >> 
    >> Yes; thank you, Marc.
    >> 
    >> And the reason for this is very sensible I think:
    >> 
    >> If you have a longish  boxplot()  or  bxp() command,
    >> and you just want to go from vertical to horizontal or vice
    >> versa, it makes most sense just to have to change the
    >> 'horizontal' flag and not having to see if there are other 'x*'
    >> and or 'y*' arguments that all need to be changed as well.
    >> 
    JO> Except that you must change xaxt/yaxt and log="x"/log="y" which do not
    JO> follow the "along the box" logic, and behave differently than
    JO> xlim/ylim. 

    JO> Nothing of this is fatal, but this probably needs more than one
    JO> iteration to find which way each of the x* and y* arguments works.

Oops!!    Thank you Jari, for the note.

What you describe is then very unfortunate, and I hadn't been
aware of that.

``of course'', making any change to consistency
would break existing code that consciously works with the
current mis-"designed" behavior.  

But now I understand why we have the word  "currently" 
in the description mentioned above.

So given the help file, we should consider dropping the whole
``along the boxplot'' idea?

{{well, yes, we should drop "traditional graphics" and work with
  grid-based graphical objects ("grob"s) that can be drawn
  vertically or horizontally,
  e.g., in lattice or (most probably) ggplot2
}}

Martin


From hin-tak.leung at cimr.cam.ac.uk  Mon Oct 15 20:13:14 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 15 Oct 2007 19:13:14 +0100
Subject: [Rd] package Geneland / Rgui under windows
In-Reply-To: <37924.129.240.88.50.1192458584.squirrel@webmail.chalmers.se>
References: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>	<471373E9.90004@mail.nih.gov>
	<37924.129.240.88.50.1192458584.squirrel@webmail.chalmers.se>
Message-ID: <4713ADBA.6090706@cimr.cam.ac.uk>

I don't have 'genuine' windows, but I have been running win32 R
under wine from time to time for a couple of years (among other
reasons, for testing cross-compilation of our R package - snpMatrix in 
http://www-gene.cimr.cam.ac.uk/clayton/software/), and your package
(fields_3.5.zip  Geneland_2.0.8.zip  RandomFields_1.3.30.zip)
works fine with win32 R 2.6.0 Rgui under wine.

However, I notice an anomaly - You are using printf() instead of 
Rprintf() - and these messages:

            *****************************
            ***    MCMC inference     ***
            *****************************
   0.200 %
...
  99.800 %
100.000 %
            ************************************
            ***    End of MCMC inference     ***
            ************************************

get sent to the parent terminal controlling wine, rather than going
into Rgui's console. (we made a similiar mistake in an early version of 
snpMatrix).

Consider replacing printf() with Rprintf() . This is an FAQ in the 
R-windows FAQ web page. That might be why Rgui hangs in XP but Rterm works.

Gilles GUILLOT wrote:
> I forgot to say that I was the package author.
> I suspected a bug of R as Geneland worked fine for two
> years and the problem popped up
> with the release of R 2.6.0
> And I can't see any explanation.
> So, any clue would help.
> 
> gilles
> 
> 
>> Gilles GUILLOT wrote:
>>> Hi,
>>> I experienced a problem with the package Geneland under R 2.6.0
>>> with  windows XP professional.
>>>
>>> The commands below should simulate a dataset,
>>> then make an MCMC simulation stored in tempdir().
>>>
>>> It works with R 2.5.1 (both GUI and command line)
>>> It works with the command line of R 2.6.0
>>> but not with the R GUI of 2.6.0: no output file is created in tempdir()
>>> and R remains frozen.
>>> I reported it as a bug
>>> (PR#9964)  but did not get any feed back.
>> I think the general rule-of-thumb is to contact the package author for
>> problems with individual packages.  Many package authors read this list,
>> but there are probably some that do not.  Sometimes problems with
>> individual packages are actually bugs in R, but I would say that this is
>> not usually the case.  However, the package author is probably the best
>> person to make this judgment.
>>
>> Sean
>>
> 
> 
> _________________________________________________________________
> Gilles GUILLOT
> INRA MIA Paris - FRANCE
> 
> Now working from Matematisk Statistik
> Chalmers University of Technology,
> S-412 96 G?teborg, SWEDEN
> Rum: 3079
> tel: +46 31 772 5338,
> Email: guillot at math.chalmers.se
> http://www.inapg.inra.fr/ens_rech/mathinfo/personnel/guillot/welcome.html
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From khansen at stat.Berkeley.EDU  Mon Oct 15 20:43:23 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 15 Oct 2007 11:43:23 -0700
Subject: [Rd] namespace, S4 and import
Message-ID: <4DB4D00D-E77E-476B-9CB8-776BECAE1489@stat.berkeley.edu>

Hi

I have been using a bit of namespaces in the past, but the following  
alludes me.

I am dealing with the Bioconductor packages Biobase and affy. Biobase  
has a namespace and affy does not. affy contains the S4 class  
"AffyBatch" which extends the "eSet" class in Biobase.

I am extending the AffyBatch class myself. My code works fine as long  
as I do not have any NAMESPACE file.

Now I am trying to add one. I am importing Biobase, but I cannot  
import affy since it does not have a NAMESPACE. However, when I try R  
CMD INSTALL it complains that it cannot find AffyBatch :

Error in setIs(Class, class2, classDef = classDef, where = where) :
   Unable to find package environment for class "AffyBatch" to revise  
subclass information

So how do I make the classes in affy available for my package when  
affy does not have a NAMESPACE?

The relevant lines from my DESCRIPTION file is
   Depends: R (>= 2.6), affy (>= 1.16), affxparser (>= 1.10),  
Biobase, methods
   LazyLoad: yes

and from my NAMESPACE file I have
   exportPattern("^[^\\.]")
   import(Biobase)

I have also tried (in desperation) to add a "require(affy)" in  
both .onLoad and .onAttach, but to no help.

While I am at this: as I remember it, in the old days we needed  
"require(methods)" in .onLoad to work with S4, is that still necessary?

I am using R-2.6.0 on OS X (PPC)

Thanks, Kasper


From marc_schwartz at comcast.net  Mon Oct 15 21:05:18 2007
From: marc_schwartz at comcast.net (marc_schwartz at comcast.net)
Date: Mon, 15 Oct 2007 21:05:18 +0200 (CEST)
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
Message-ID: <20071015190518.1DF4B283416A@mail.pubhealth.ku.dk>


--=-ZyOtZFb05MaZLi4/Ovwu
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

On Mon, 2007-10-15 at 18:25 +0200, maechler at stat.math.ethz.ch wrote: 
> >>>>> "JO" == Jari Oksanen <jarioksa at sun3.oulu.fi>
> >>>>>     on Mon, 15 Oct 2007 16:42:24 +0300 writes:
> 
>     JO> On Mon, 2007-10-15 at 15:25 +0200, maechler at stat.math.ethz.ch wrote:
>     >> >>>>> "ms" == marc schwartz <marc_schwartz at comcast.net>
>     >> >>>>>     on Mon, 15 Oct 2007 14:20:16 +0200 (CEST) writes:
>     >> 
>     ms> On Mon, 2007-10-15 at 10:30 +0200, bob.ohara at helsinki.fi wrote:
>     >> >> Full_Name: Bob O'Hara
>     >> >> Version: 2.6.0
>     >> >> OS: Windows XP
>     >> >> Submission from: (NULL) (88.112.20.250)
>     >> >> 
>     >> >> 
>     >> >> Using horizontal=TRUE with boxplot() confuses it as to what is an x- or y-axis. 
>     >> >> At least, xlim= and ylim= are the wrong way round, log="x" (or "y") and xaxt=
>     >> >> work as expected, I haven't looked at anything else.
>     >> >> 
>     >> >> Some code to see if you can reproduce the bug (or discover it's in my head...):
>     >> >> 
>     >> >> boxplot(count ~ spray, data = InsectSprays)
>     >> >> 
>     >> >> # Try to change x-axis:
>     >> >> boxplot(count ~ spray, data = InsectSprays, xlim=c(0,50))
>     >> >> 
>     >> >> # Plot horizontally:
>     >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE)
>     >> >> 
>     >> >> # Now try to change x-axis:
>     >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xlim=c(0,50))
>     >> >> # Changes y-axis!
>     >> >> 
>     >> >> # Now try to change y-axis:
>     >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, ylim=c(0,50))
>     >> >> # Changes x-axis!
>     >> >> 
>     >> >> # Plot x-axis on log scale:
>     >> >> boxplot(count+1 ~ spray, data = InsectSprays, horizontal=TRUE, log="x")
>     >> >> # Does indeed change x-axis
>     >> >> 
>     >> >> # Don't add ticks on x-axis:
>     >> >> boxplot(count ~ spray, data = InsectSprays, horizontal=TRUE, xaxt="n")
>     >> >> # Works as expected.
>     >> 
>     ms> Hi Bob,
>     >> 
>     ms> No, it's not in your head. This is documented in ?bxp, which is the
>     ms> function that actually does the plotting for boxplot(). See the
>     ms> description of 'pars' in ?bxp:
>     >> 
>     ms> "Currently, yaxs and ylim are used ???????????????along the boxplot????????????????, i.e.,
>     ms> vertically, when horizontal is false, and xlim horizontally."
>     >> 
>     ms> So essentially, the named 'x' and 'y' axes are rotated 90 degrees when
>     ms> you use 'horizontal = TRUE', rather than the vertical axis always being
>     ms> 'y' and the horizontal axis always being 'x'. This has been discussed on
>     ms> the lists previously.
>     >> 
>     >> Yes; thank you, Marc.
>     >> 
>     >> And the reason for this is very sensible I think:
>     >> 
>     >> If you have a longish  boxplot()  or  bxp() command,
>     >> and you just want to go from vertical to horizontal or vice
>     >> versa, it makes most sense just to have to change the
>     >> 'horizontal' flag and not having to see if there are other 'x*'
>     >> and or 'y*' arguments that all need to be changed as well.
>     >> 
>     JO> Except that you must change xaxt/yaxt and log="x"/log="y" which do not
>     JO> follow the "along the box" logic, and behave differently than
>     JO> xlim/ylim. 
> 
>     JO> Nothing of this is fatal, but this probably needs more than one
>     JO> iteration to find which way each of the x* and y* arguments works.
> 
> Oops!!    Thank you Jari, for the note.
> 
> What you describe is then very unfortunate, and I hadn't been
> aware of that.
> 
> ``of course'', making any change to consistency
> would break existing code that consciously works with the
> current mis-"designed" behavior.  
> 
> But now I understand why we have the word  "currently" 
> in the description mentioned above.
> 
> So given the help file, we should consider dropping the whole
> ``along the boxplot'' idea?
> 
> {{well, yes, we should drop "traditional graphics" and work with
>   grid-based graphical objects ("grob"s) that can be drawn
>   vertically or horizontally,
>   e.g., in lattice or (most probably) ggplot2
> }}
> 
> Martin

The key code in question, from boxplot.R, seems to be:

    if (!add) {
	plot.new()
	## shall we switch log for horizontal with
	## switch(log, x="y", y="x", log) ??
	if (horizontal)
	    plot.window(ylim = xlim, xlim = ylim, log = log, xaxs = pars$yaxs)
	else
	    plot.window(xlim = xlim, ylim = ylim, log = log, yaxs = pars$yaxs)
    }
    xlog <- (par("ylog") && horizontal) || (par("xlog") && !horizontal)


So it would appear that ylim/xlim and xaxs/yaxs are interchanged when
horizontal = TRUE.  All? other axis specific pars remain as per normal.

I have attached a proposed patch against bxp.Rd (against the current svn
copy) for consideration. Hopefully this makes ?bxp a bit more clear.

If any changes are to be made to current behavior, it would be good to
do this incrementally, with a note/warning added to 2.7.1 and then
changed in 2.8.0.  If that is too soon, then increment by one version.

Thanks all,

Marc


--=-ZyOtZFb05MaZLi4/Ovwu
Content-Disposition: attachment; filename=diff.patch
Content-Type: text/x-patch; name=diff.patch; charset=ISO-8859-15
Content-Transfer-Encoding: 7bit

--- bxp.Rd	2007-10-15 13:27:21.000000000 -0500
+++ bxp.Rd.patch	2007-10-15 13:55:42.000000000 -0500
@@ -43,8 +43,8 @@
   \item{frame.plot}{logical, indicating if a \sQuote{frame}
     (\code{\link{box}}) should be drawn; defaults to \code{TRUE}, unless
     \code{axes = FALSE} is specified.}
-  \item{horizontal}{logical indicating if the  boxplots should be
-    horizontal; default \code{FALSE} means vertical boxes.}
+  \item{horizontal}{logical indicating if the boxplots should be
+    horizontal; default \code{FALSE} means vertical boxes. See note.}
   \item{add}{logical, if true \emph{add} boxplot to current plot.}
   \item{at}{numeric vector giving the locations where the boxplots
     should be drawn, particularly when \code{add = TRUE}; defaults to
@@ -56,9 +56,6 @@
     normally(\code{\dots}), see the following.  (Those in \code{\dots}
     take precedence over those in \code{pars}.)
 
-    Currently, \code{yaxs} and \code{ylim} are used \sQuote{along the
-      boxplot}, i.e., vertically, when \code{horizontal} is
-    false, and \code{xlim} horizontally.
     \code{xaxt}, \code{yaxt}, \code{las}, \code{cex.axis}, and
     \code{col.axis} are passed to \code{\link{axis}}, and \code{main},
     \code{cex.main}, \code{col.main}, \code{sub}, \code{cex.sub},
@@ -101,10 +98,15 @@
   }%.../pars
 }
 \note{
-  if \code{add = FALSE}, the default is \code{xlim = c(0.5, n +0.5)}.
+  If \code{add = FALSE}, the default is \code{xlim = c(0.5, n +0.5)}.
   It will usually be a good idea to specify the latter if the "x" axis
   has a log scale or \code{at} is specified or \code{width} is far from
   uniform.
+
+  If \code{horizontal = TRUE}, the "y" axis is the horizontal axis and the "x"
+  axis is the vertical axis. Graphical pars \code{xlim/ylim} and 
+  \code{xaxs/yaxs} are reversed in this case. Other axis related pars treat
+  the vertical axis as "y" and the horizontal axis as "x".
 }
 \value{
   An invisible vector, actually identical to the \code{at} argument,

--=-ZyOtZFb05MaZLi4/Ovwu--


From h.wickham at gmail.com  Mon Oct 15 21:34:41 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 15 Oct 2007 14:34:41 -0500
Subject: [Rd] boxplot() confuses x- and y-axes (PR#10345)
In-Reply-To: <20071015162541.31B0F283416A@mail.pubhealth.ku.dk>
References: <20071015162541.31B0F283416A@mail.pubhealth.ku.dk>
Message-ID: <f8e6ff050710151234i2e6e4e7cgd2abad97451f1e72@mail.gmail.com>

> So given the help file, we should consider dropping the whole
> ``along the boxplot'' idea?
>
> {{well, yes, we should drop "traditional graphics" and work with
>   grid-based graphical objects ("grob"s) that can be drawn
>   vertically or horizontally,
>   e.g., in lattice or (most probably) ggplot2
> }}

ggplot2 does this in a completely general way (i.e. for all types of
graphics) with the coord_flip coordinate system, which flips the
interpretation of the x and y scales.  This includes producing
smoothers of x conditional on y, and so forth.

Hadley

-- 
http://had.co.nz/


From h.wickham at gmail.com  Mon Oct 15 22:48:43 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 15 Oct 2007 15:48:43 -0500
Subject: [Rd] Digest package - make digest generic?
In-Reply-To: <59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
Message-ID: <f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>

On 10/15/07, Henrik Bengtsson <hb at maths.lth.se> wrote:
> [As agreed, CC:ing r-devel since others might be interested in this as well.]
>
> Hi.
>
> On 10/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> > Hi Hadley,
> >
> > On 15 October 2007 at 09:51, hadley wickham wrote:
> > | Would you consider making digest a generic function?  That way I could
> > | (e.g.) make a generic method for ggplot objects which didn't depend
> > | (so much) on their internal representation.
> >
> > Well, generally speaking, I always take patches :)
>
> I see know problems in doing this.  The patch would be:
>
> digest <- function(...) UseMethod("digest");
> digest.default <- <current digest function>.
>
> I think that should do, and I don't think it has any surprising side
> effects so it could be added in the next release.  Dirk, can you do
> that?
>
> >
> > I have to admit that I am fairly weak on these aspects of the S language.
> > One question is:  how to the current users of digest (i.e. Henrik's and
> > Seth's caching mechanism, for example) use it on arbitrary objects _without_
> > it being generic?
>
> I basically put everything I want into a list() and pass that to
> digest::digest().

Yes, that's what I'm doing too.

> >
> > | The reason I ask is that I'm using digest as a way of coming up with a
> > | unique file name for each example graphic.  I want to be able to
> > | easily compare the appearance of examples between versions, but
> > | currently the digest depends on internal details, so it's hard to
> > | match up graphics between versions.
>
> See loadCache(key) and saveCache(object, key) in R.cache, which
> basically loads and saves results from and to a file cache based on a
> key object - no need to specify paths or filenames.  You can specify
> paths etc if you want to, but by default it is just transparent.

The problem is I need to refer to the image from the documentation, so
I do need to know it's path.  I also want to be able to look at the
image, so if the digests are different I can see what the difference
is (I'm planning to automate this with the imagemagick compare command
line tool).

> However, I think Hadley is referring to a different problem.
> Basically, he got an object containing a lot of fields, but for his
> purposes it is only a subset of the fields that he wants to use to
> generate a consistent the hashcode.  If he pass any other field, that

Yes, exactly.

> will break the consistency.  In that case, the designer of the class
> has to identify the fields that makes uniquely identify the state of
> the object.  I do that for many of my object and pass them down in a
> list() structure to digest().  I agree, by making digest() generic,
> one can make the code nicer.  [If there is a need to dispatch on
> multiple arguments, we have to go for S4, but otherwise S3 gives the
> minimal modification].
>
> Side comment: This basically comes down to how for instance Java deals
> with hashCode() and equals() etc.  By default the object as is used to
> generate the hashcode (and can be used by equals() compare objects).

Yes, that's the model I was thinking of too.

Hadley

-- 
http://had.co.nz/


From hb at stat.berkeley.edu  Mon Oct 15 23:05:38 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 15 Oct 2007 14:05:38 -0700
Subject: [Rd] Digest package - make digest generic?
In-Reply-To: <f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
Message-ID: <59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>

On 10/15/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 10/15/07, Henrik Bengtsson <hb at maths.lth.se> wrote:
> > [As agreed, CC:ing r-devel since others might be interested in this as well.]
> >
> > Hi.
> >
> > On 10/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
> > >
> > > Hi Hadley,
> > >
> > > On 15 October 2007 at 09:51, hadley wickham wrote:
> > > | Would you consider making digest a generic function?  That way I could
> > > | (e.g.) make a generic method for ggplot objects which didn't depend
> > > | (so much) on their internal representation.
> > >
> > > Well, generally speaking, I always take patches :)
> >
> > I see know problems in doing this.  The patch would be:
> >
> > digest <- function(...) UseMethod("digest");
> > digest.default <- <current digest function>.
> >
> > I think that should do, and I don't think it has any surprising side
> > effects so it could be added in the next release.  Dirk, can you do
> > that?
> >
> > >
> > > I have to admit that I am fairly weak on these aspects of the S language.
> > > One question is:  how to the current users of digest (i.e. Henrik's and
> > > Seth's caching mechanism, for example) use it on arbitrary objects _without_
> > > it being generic?
> >
> > I basically put everything I want into a list() and pass that to
> > digest::digest().
>
> Yes, that's what I'm doing too.
>
> > >
> > > | The reason I ask is that I'm using digest as a way of coming up with a
> > > | unique file name for each example graphic.  I want to be able to
> > > | easily compare the appearance of examples between versions, but
> > > | currently the digest depends on internal details, so it's hard to
> > > | match up graphics between versions.
> >
> > See loadCache(key) and saveCache(object, key) in R.cache, which
> > basically loads and saves results from and to a file cache based on a
> > key object - no need to specify paths or filenames.  You can specify
> > paths etc if you want to, but by default it is just transparent.
>
> The problem is I need to refer to the image from the documentation, so
> I do need to know it's path.  I also want to be able to look at the
> image, so if the digests are different I can see what the difference
> is (I'm planning to automate this with the imagemagick compare command
> line tool).

See ?findCache.  That will give you the pathname given a key.  It is
on purpose that I do not list this function in the HTML help index - I
want to keep the "public" API to a minimum.

/Henrik

>
> > However, I think Hadley is referring to a different problem.
> > Basically, he got an object containing a lot of fields, but for his
> > purposes it is only a subset of the fields that he wants to use to
> > generate a consistent the hashcode.  If he pass any other field, that
>
> Yes, exactly.
>
> > will break the consistency.  In that case, the designer of the class
> > has to identify the fields that makes uniquely identify the state of
> > the object.  I do that for many of my object and pass them down in a
> > list() structure to digest().  I agree, by making digest() generic,
> > one can make the code nicer.  [If there is a need to dispatch on
> > multiple arguments, we have to go for S4, but otherwise S3 gives the
> > minimal modification].
> >
> > Side comment: This basically comes down to how for instance Java deals
> > with hashCode() and equals() etc.  By default the object as is used to
> > generate the hashcode (and can be used by equals() compare objects).
>
> Yes, that's the model I was thinking of too.
>
> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Oct 16 09:33:52 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Oct 2007 08:33:52 +0100 (BST)
Subject: [Rd] package Geneland / Rgui under windows
In-Reply-To: <471373E9.90004@mail.nih.gov>
References: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>
	<471373E9.90004@mail.nih.gov>
Message-ID: <Pine.LNX.4.64.0710160813060.19726@gannet.stats.ox.ac.uk>

On Mon, 15 Oct 2007, Sean Davis wrote:

> Gilles GUILLOT wrote:
>> Hi,
>> I experienced a problem with the package Geneland under R 2.6.0
>> with  windows XP professional.
>>
>> The commands below should simulate a dataset,
>> then make an MCMC simulation stored in tempdir().
>>
>> It works with R 2.5.1 (both GUI and command line)
>> It works with the command line of R 2.6.0
>> but not with the R GUI of 2.6.0: no output file is created in tempdir()
>> and R remains frozen.
>> I reported it as a bug
>> (PR#9964)  but did not get any feed back.
>
> I think the general rule-of-thumb is to contact the package author for
> problems with individual packages.  Many package authors read this list,
> but there are probably some that do not.  Sometimes problems with
> individual packages are actually bugs in R, but I would say that this is
> not usually the case.

Overwhelmingly so: I don't believe we know of any in the transition to 
2.6.0 that were not bugs in the packages concerned.

> However, the package author is probably the best person to make this 
> judgment.

In this case 'Gilles GUILLOT' completely failed to say that he is the 
maintainer, including in his bug report (and he is using a different email 
address from the one in the package: I only know this is the same person 
from a private reply).

I think he needs to run R under a debugger and find out what 'freezes' 
means.  If as I suspect this is in the compiled code of the package, it 
is not a bug in R.

Windows binaries for R 2.6.0 are built with a different compiler than 
3.4.5, and this has triggered a few package problems (note, not problems 
in R but in the packages concerned):

- a couple of packages infinite loop because the calculations are done in 
extended precision registers and so do not terminate, something we have 
had to work around for LAPACK, for example.

- I think three packages infinite-loop because they write outside array 
bounds.  In one case it always did, but used to get away with it.

None of these explain a Rgui/Rterm difference, if that is what is meant 
here (R has a 'command line' in both, and Rterm is a 'console application' 
in Windows-speak).  The main possible difference relates to I/O, and I see 
that Geneland uses Fortran I/O.  Fortran I/O to '*' (or units 5/6) is 
incompatible with a GUI application, and in gcc 4.2.1 Fortran I/O is 
pretty much incompatible with C I/O (initializing has been known to break 
C I/O).  So I suggest that Fortran I/O is removed and replaced by calls to 
realpr etc.

Filing a bug report on issues in your own package is not at all good form: 
R-bugs is not for 'feed back', but there *was* a comment filed on PR#9964.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdpeng at gmail.com  Tue Oct 16 14:25:24 2007
From: rdpeng at gmail.com (Roger Peng)
Date: Tue, 16 Oct 2007 08:25:24 -0400
Subject: [Rd] Fwd:  Digest package - make digest generic?
In-Reply-To: <66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
Message-ID: <66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>

Sorry, I forgot the 'reply-all'.

-roger

---------- Forwarded message ----------
From: Roger Peng <rdpeng at gmail.com>
Date: Oct 16, 2007 8:24 AM
Subject: Re: [Rd] Digest package - make digest generic?
To: Henrik Bengtsson <hb at stat.berkeley.edu>


Would it be possible to instead create a function with a name like
'digest0' which is the current function, and then create a generic
function with the name 'digest'?  In this case 'digest0' always
returns the digest of the "raw" object.

My one concern is that my current expectation is that 'digest' takes
an object and hashes the entire object, regardless of class.  So if
two objects are different (even in their internal representation),
they should return different digests.  I would be a little worried if
'digest' had a different (and perhaps unpredictable) behavior
depending on the class of the object where two objects that were in
fact different could lead to the same digest.

I can see why one might want class-specific behavior, but what a class
author wants from 'digest' may not be different from what other users
of 'digest' on that object want.

A simple approach might be

digest0 <- function(x, ...) digest(unclass(x), ...)

although this doesn't work for S4 objects I don't think.

-roger

On 10/15/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> On 10/15/07, hadley wickham <h.wickham at gmail.com> wrote:
> > On 10/15/07, Henrik Bengtsson <hb at maths.lth.se> wrote:
> > > [As agreed, CC:ing r-devel since others might be interested in this as well.]
> > >
> > > Hi.
> > >
> > > On 10/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
> > > >
> > > > Hi Hadley,
> > > >
> > > > On 15 October 2007 at 09:51, hadley wickham wrote:
> > > > | Would you consider making digest a generic function?  That way I could
> > > > | (e.g.) make a generic method for ggplot objects which didn't depend
> > > > | (so much) on their internal representation.
> > > >
> > > > Well, generally speaking, I always take patches :)
> > >
> > > I see know problems in doing this.  The patch would be:
> > >
> > > digest <- function(...) UseMethod("digest");
> > > digest.default <- <current digest function>.
> > >
> > > I think that should do, and I don't think it has any surprising side
> > > effects so it could be added in the next release.  Dirk, can you do
> > > that?
> > >
> > > >
> > > > I have to admit that I am fairly weak on these aspects of the S language.
> > > > One question is:  how to the current users of digest (i.e. Henrik's and
> > > > Seth's caching mechanism, for example) use it on arbitrary objects _without_
> > > > it being generic?
> > >
> > > I basically put everything I want into a list() and pass that to
> > > digest::digest().
> >
> > Yes, that's what I'm doing too.
> >
> > > >
> > > > | The reason I ask is that I'm using digest as a way of coming up with a
> > > > | unique file name for each example graphic.  I want to be able to
> > > > | easily compare the appearance of examples between versions, but
> > > > | currently the digest depends on internal details, so it's hard to
> > > > | match up graphics between versions.
> > >
> > > See loadCache(key) and saveCache(object, key) in R.cache, which
> > > basically loads and saves results from and to a file cache based on a
> > > key object - no need to specify paths or filenames.  You can specify
> > > paths etc if you want to, but by default it is just transparent.
> >
> > The problem is I need to refer to the image from the documentation, so
> > I do need to know it's path.  I also want to be able to look at the
> > image, so if the digests are different I can see what the difference
> > is (I'm planning to automate this with the imagemagick compare command
> > line tool).
>
> See ?findCache.  That will give you the pathname given a key.  It is
> on purpose that I do not list this function in the HTML help index - I
> want to keep the "public" API to a minimum.
>
> /Henrik
>
> >
> > > However, I think Hadley is referring to a different problem.
> > > Basically, he got an object containing a lot of fields, but for his
> > > purposes it is only a subset of the fields that he wants to use to
> > > generate a consistent the hashcode.  If he pass any other field, that
> >
> > Yes, exactly.
> >
> > > will break the consistency.  In that case, the designer of the class
> > > has to identify the fields that makes uniquely identify the state of
> > > the object.  I do that for many of my object and pass them down in a
> > > list() structure to digest().  I agree, by making digest() generic,
> > > one can make the code nicer.  [If there is a need to dispatch on
> > > multiple arguments, we have to go for S4, but otherwise S3 gives the
> > > minimal modification].
> > >
> > > Side comment: This basically comes down to how for instance Java deals
> > > with hashCode() and equals() etc.  By default the object as is used to
> > > generate the hashcode (and can be used by equals() compare objects).
> >
> > Yes, that's the model I was thinking of too.
> >
> > Hadley
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


--
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From jonathan at swintons.net  Tue Oct 16 11:00:43 2007
From: jonathan at swintons.net (Jonathan Swinton)
Date: Tue, 16 Oct 2007 10:00:43 +0100
Subject: [Rd] Additional file filter for Windows text editor Open/Save
	dialogues.
Message-ID: <47147DBB.4060101@swintons.net>


I propose the following very simple patch to src\gnuwin32\editor.c. Its purpose is to allow vignette files, specifically .Snw and .Rnw suffixes, to be an available filter in the Open and Save dialogues of the R GUI text editor.

I have successfully built and tested this against R 2.5.0, and found it useful.

Although the patch is against the current r-devel, I cannot currently build that (because of a failure to build Rblas.dll, FWIW, and no doubt all my fault for not reading the right bit of the manual).
However it seems to me unlikely that this patch would be the victim of such version differences, and I think it better to offer it now; I am unlikely to be able to troubleshoot my r-devel build for a long time if at all.




Index: editor.c
===================================================================
--- editor.c	(revision 43174)
+++ editor.c	(working copy)
@@ -52,6 +52,9 @@
  static int neditors  = 0;
  static Rboolean fix_editor_up = FALSE;

+/* Definition of available filters for Open and Save dialogues */
+#define EDITORFILEFILTER "R files (*.R)\0*.R\0S files (*.q, *.ssc, *.S)\0*.q;*.ssc;*.S\0Vignette files (*.Rnw,*.Snw)\0*.Rnw;*.Snw\0All files (*.*)\0*.*\0\0"
+
  static EditorData neweditordata (int file, char *filename)
  {
      EditorData p;
@@ -149,7 +152,7 @@
      EditorData p = getdata(t);
      char *current_name = (p->file ? p->filename : "");
      char *name;
-    setuserfilter("R files (*.R)\0*.R\0S files (*.q, *.ssc, *.S)\0*.q;*.ssc;*.S\0All files (*.*)\0*.*\0\0");
+    setuserfilter( EDITORFILEFILTER);
      name = askfilesave(G_("Save script as"), current_name);
      if (name == NULL)
  	return;
@@ -337,7 +340,7 @@
  {
      char *name;
      int i; textbox t; EditorData p;
-    setuserfilter("R files (*.R)\0*.R\0S files (*.q, *.ssc, *.S)\0*.q;*.ssc;*.S\0All files (*.*)\0*.*\0\0");
+    setuserfilter(EDITORFILEFILTER);
      name = askfilename("Open script", default_name); /* returns NULL if open dialog cancelled */
      if (name) {
  	/* check if file is already open in an editor. If so, close and open again */


From bates at stat.wisc.edu  Tue Oct 16 17:47:09 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 16 Oct 2007 10:47:09 -0500
Subject: [Rd] Sweave/ESS-like tools for HTML
Message-ID: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>

My university provides me with a powerful course management system for
the courses that I teach.  Among other things I can create a wiki for
the course, which is very convenient for cross-linking different bits
of the course.

Naturally I use R extensively in my teaching and I want to incorporate
R code, output and graphics in such a wiki.  If I were producing LaTeX
sources instead of HTML sources I create .Rnw files for Sweave and I
would edit them using ESS in emacs.

What options do I have for producing HTML with embedded R content and
what is a good, preferably emacs-based, way of editing the source
code?

One basic problem is trying to present mathematical expressions in HTML (see
http://www.cs.tut.fi/~jkorpela/math/) but, aside from that, there are
questions of presenting input R expressions and the corresponding
output and of incorporating graphics files produced by R.  I could try
to use latex2html or texi2html but the output from latex2html at least
would be quite inconvenient to use because it generates so many linked
files.  Once they are uploaded it would be horrible trying to get all
the links straightened out.

In a sense there are already tools for this type of output from .Rd
files.  Would it be best to use those tools or to use texinfo tools or
...?


From sdavis2 at mail.nih.gov  Tue Oct 16 18:05:42 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 16 Oct 2007 12:05:42 -0400
Subject: [Rd] Sweave/ESS-like tools for HTML
In-Reply-To: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
Message-ID: <4714E156.9040500@mail.nih.gov>

Douglas Bates wrote:
> My university provides me with a powerful course management system for
> the courses that I teach.  Among other things I can create a wiki for
> the course, which is very convenient for cross-linking different bits
> of the course.
> 
> Naturally I use R extensively in my teaching and I want to incorporate
> R code, output and graphics in such a wiki.  If I were producing LaTeX
> sources instead of HTML sources I create .Rnw files for Sweave and I
> would edit them using ESS in emacs.
> 
> What options do I have for producing HTML with embedded R content and
> what is a good, preferably emacs-based, way of editing the source
> code?
> 
> One basic problem is trying to present mathematical expressions in HTML (see
> http://www.cs.tut.fi/~jkorpela/math/) but, aside from that, there are
> questions of presenting input R expressions and the corresponding
> output and of incorporating graphics files produced by R.  I could try
> to use latex2html or texi2html but the output from latex2html at least
> would be quite inconvenient to use because it generates so many linked
> files.  Once they are uploaded it would be horrible trying to get all
> the links straightened out.
> 
> In a sense there are already tools for this type of output from .Rd
> files.  Would it be best to use those tools or to use texinfo tools or
> ...?

I have never tried it, but have you looked into using the RweaveHTML
driver in the RHTML package for processing .Rnw files?

Sean


From edd at debian.org  Tue Oct 16 20:29:33 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 16 Oct 2007 13:29:33 -0500
Subject: [Rd] Fwd:  Digest package - make digest generic?
In-Reply-To: <66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
Message-ID: <18197.781.298239.228245@ron.nulle.part>


Hi Roger,

On 16 October 2007 at 08:25, Roger Peng wrote:
| Sorry, I forgot the 'reply-all'.
| 
| -roger
| 
| ---------- Forwarded message ----------
| From: Roger Peng <rdpeng at gmail.com>
| Date: Oct 16, 2007 8:24 AM
| Subject: Re: [Rd] Digest package - make digest generic?
| To: Henrik Bengtsson <hb at stat.berkeley.edu>
| 
| 
| Would it be possible to instead create a function with a name like
| 'digest0' which is the current function, and then create a generic
| function with the name 'digest'?  In this case 'digest0' always
| returns the digest of the "raw" object.
| 
| My one concern is that my current expectation is that 'digest' takes
| an object and hashes the entire object, regardless of class.  So if
| two objects are different (even in their internal representation),
| they should return different digests.  I would be a little worried if
| 'digest' had a different (and perhaps unpredictable) behavior
| depending on the class of the object where two objects that were in
| fact different could lead to the same digest.

But haven't the cryptographers taken care of that argument?  

To my layman's understanding, the consensus is that hash collissions are
possible but very very unlikely. And we already have that problem with digest
as it stands as -- if collission are possible, identical hashes could result
from two different input whether or not digest is generic or not. 

Or am I missing what you were trying to get at?
 
| I can see why one might want class-specific behavior, but what a class
| author wants from 'digest' may not be different from what other users
| of 'digest' on that object want.
| 
| A simple approach might be
| 
| digest0 <- function(x, ...) digest(unclass(x), ...)

Or, just for argument's sake, we go full circle, digest stays as it is and
Hadley implements his own generic, say, 'Digest()', aroumd digest ?  Naa....

I think I like the idea of making it generic, but I really would like to
know more about possible downsides.

Dirk
 
| although this doesn't work for S4 objects I don't think.
| 
| -roger
| 
| On 10/15/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
| > On 10/15/07, hadley wickham <h.wickham at gmail.com> wrote:
| > > On 10/15/07, Henrik Bengtsson <hb at maths.lth.se> wrote:
| > > > [As agreed, CC:ing r-devel since others might be interested in this as well.]
| > > >
| > > > Hi.
| > > >
| > > > On 10/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
| > > > >
| > > > > Hi Hadley,
| > > > >
| > > > > On 15 October 2007 at 09:51, hadley wickham wrote:
| > > > > | Would you consider making digest a generic function?  That way I could
| > > > > | (e.g.) make a generic method for ggplot objects which didn't depend
| > > > > | (so much) on their internal representation.
| > > > >
| > > > > Well, generally speaking, I always take patches :)
| > > >
| > > > I see know problems in doing this.  The patch would be:
| > > >
| > > > digest <- function(...) UseMethod("digest");
| > > > digest.default <- <current digest function>.
| > > >
| > > > I think that should do, and I don't think it has any surprising side
| > > > effects so it could be added in the next release.  Dirk, can you do
| > > > that?
| > > >
| > > > >
| > > > > I have to admit that I am fairly weak on these aspects of the S language.
| > > > > One question is:  how to the current users of digest (i.e. Henrik's and
| > > > > Seth's caching mechanism, for example) use it on arbitrary objects _without_
| > > > > it being generic?
| > > >
| > > > I basically put everything I want into a list() and pass that to
| > > > digest::digest().
| > >
| > > Yes, that's what I'm doing too.
| > >
| > > > >
| > > > > | The reason I ask is that I'm using digest as a way of coming up with a
| > > > > | unique file name for each example graphic.  I want to be able to
| > > > > | easily compare the appearance of examples between versions, but
| > > > > | currently the digest depends on internal details, so it's hard to
| > > > > | match up graphics between versions.
| > > >
| > > > See loadCache(key) and saveCache(object, key) in R.cache, which
| > > > basically loads and saves results from and to a file cache based on a
| > > > key object - no need to specify paths or filenames.  You can specify
| > > > paths etc if you want to, but by default it is just transparent.
| > >
| > > The problem is I need to refer to the image from the documentation, so
| > > I do need to know it's path.  I also want to be able to look at the
| > > image, so if the digests are different I can see what the difference
| > > is (I'm planning to automate this with the imagemagick compare command
| > > line tool).
| >
| > See ?findCache.  That will give you the pathname given a key.  It is
| > on purpose that I do not list this function in the HTML help index - I
| > want to keep the "public" API to a minimum.
| >
| > /Henrik
| >
| > >
| > > > However, I think Hadley is referring to a different problem.
| > > > Basically, he got an object containing a lot of fields, but for his
| > > > purposes it is only a subset of the fields that he wants to use to
| > > > generate a consistent the hashcode.  If he pass any other field, that
| > >
| > > Yes, exactly.
| > >
| > > > will break the consistency.  In that case, the designer of the class
| > > > has to identify the fields that makes uniquely identify the state of
| > > > the object.  I do that for many of my object and pass them down in a
| > > > list() structure to digest().  I agree, by making digest() generic,
| > > > one can make the code nicer.  [If there is a need to dispatch on
| > > > multiple arguments, we have to go for S4, but otherwise S3 gives the
| > > > minimal modification].
| > > >
| > > > Side comment: This basically comes down to how for instance Java deals
| > > > with hashCode() and equals() etc.  By default the object as is used to
| > > > generate the hashcode (and can be used by equals() compare objects).
| > >
| > > Yes, that's the model I was thinking of too.
| > >
| > > Hadley
| > >
| > > --
| > > http://had.co.nz/
| > >
| > > ______________________________________________
| > > R-devel at r-project.org mailing list
| > > https://stat.ethz.ch/mailman/listinfo/r-devel
| > >
| >
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| >
| 
| 
| --
| Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
| 
| 
| -- 
| Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Three out of two people have difficulties with fractions.


From ripley at stats.ox.ac.uk  Tue Oct 16 20:34:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Oct 2007 19:34:58 +0100 (BST)
Subject: [Rd] (PR#9964) package Geneland / Rgui under windows
In-Reply-To: <Pine.LNX.4.64.0710160813060.19726@gannet.stats.ox.ac.uk>
References: <37036.129.240.88.50.1192454949.squirrel@webmail.chalmers.se>
	<471373E9.90004@mail.nih.gov>
	<Pine.LNX.4.64.0710160813060.19726@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0710161925430.21882@gannet.stats.ox.ac.uk>

I can confirm that if the Geneland is built under gcc 3.4.5 it works in R 
2.6.0 in Rgui (modulo the output which is sent nowhere).  So the issue is 
the Fortran code of the package, and very likely its use of Fortran I/O.

Since this confirms there is not a bug in R 2.6.0, I am filing this on 
R-bugs and closing the bug report.  There is a bug in the package, but 
that is not a subject for R-bugs.

I've put my build up on the CRANextras repository: Uwe might like to 
remove his so that users get that one until such a time as the I/O issues 
are resolved.

On Tue, 16 Oct 2007, Prof Brian Ripley wrote:

> On Mon, 15 Oct 2007, Sean Davis wrote:
>
>> Gilles GUILLOT wrote:
>>> Hi,
>>> I experienced a problem with the package Geneland under R 2.6.0
>>> with  windows XP professional.
>>>
>>> The commands below should simulate a dataset,
>>> then make an MCMC simulation stored in tempdir().
>>>
>>> It works with R 2.5.1 (both GUI and command line)
>>> It works with the command line of R 2.6.0
>>> but not with the R GUI of 2.6.0: no output file is created in tempdir()
>>> and R remains frozen.
>>> I reported it as a bug
>>> (PR#9964)  but did not get any feed back.
>>
>> I think the general rule-of-thumb is to contact the package author for
>> problems with individual packages.  Many package authors read this list,
>> but there are probably some that do not.  Sometimes problems with
>> individual packages are actually bugs in R, but I would say that this is
>> not usually the case.
>
> Overwhelmingly so: I don't believe we know of any in the transition to
> 2.6.0 that were not bugs in the packages concerned.
>
>> However, the package author is probably the best person to make this
>> judgment.
>
> In this case 'Gilles GUILLOT' completely failed to say that he is the
> maintainer, including in his bug report (and he is using a different email
> address from the one in the package: I only know this is the same person
> from a private reply).
>
> I think he needs to run R under a debugger and find out what 'freezes'
> means.  If as I suspect this is in the compiled code of the package, it
> is not a bug in R.
>
> Windows binaries for R 2.6.0 are built with a different compiler than
> 3.4.5, and this has triggered a few package problems (note, not problems
> in R but in the packages concerned):
>
> - a couple of packages infinite loop because the calculations are done in
> extended precision registers and so do not terminate, something we have
> had to work around for LAPACK, for example.
>
> - I think three packages infinite-loop because they write outside array
> bounds.  In one case it always did, but used to get away with it.
>
> None of these explain a Rgui/Rterm difference, if that is what is meant
> here (R has a 'command line' in both, and Rterm is a 'console application'
> in Windows-speak).  The main possible difference relates to I/O, and I see
> that Geneland uses Fortran I/O.  Fortran I/O to '*' (or units 5/6) is
> incompatible with a GUI application, and in gcc 4.2.1 Fortran I/O is
> pretty much incompatible with C I/O (initializing has been known to break
> C I/O).  So I suggest that Fortran I/O is removed and replaced by calls to
> realpr etc.
>
> Filing a bug report on issues in your own package is not at all good form:
> R-bugs is not for 'feed back', but there *was* a comment filed on PR#9964.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tshort at epri.com  Tue Oct 16 18:33:02 2007
From: tshort at epri.com (Tom Short)
Date: Tue, 16 Oct 2007 16:33:02 +0000 (UTC)
Subject: [Rd] Sweave/ESS-like tools for HTML
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
	<4714E156.9040500@mail.nih.gov>
Message-ID: <loom.20071016T162929-540@post.gmane.org>

See this link for more on creating/converting to HTML:

http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/SweaveConvert

For using ESS with mixed HTML/R files, see this:

https://stat.ethz.ch/pipermail/ess-help/2006-December/003826.html

- Tom

Tom Short
Electric Power Research Institute


From duncan at wald.ucdavis.edu  Tue Oct 16 21:59:13 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 17 Oct 2007 08:59:13 +1300
Subject: [Rd] Sweave/ESS-like tools for HTML
In-Reply-To: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
Message-ID: <47151811.5040500@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Doug.

  This is probably more than you want - either to know or to use
for your specific task, but I'll throw it out there for general
information.

 I write documents using XML, specifically an extended version
of Docbook with elements for describing R concepts (e.g.
code, plot, output, function name, argument, ...).  Then,
I use XSL to transform this to either HTML, FO and on to PDF,
or to LaTeX (via db2latex).  As for processing
the R code and inserting the output into the resulting view/document,
I use the Sxslt package from within R which allows me to combine XSL
rules with those that also call R functions.
I author the documents using the nxml mode in emacs
and have some basic "gestures" for sending code from the document
to R.


Deb Nolan and I use this for creating dynamic and interactive
documents which can be transformed to HTML with embedded
controls for the reader to control the R computations
interactively.

Rather than thinking of the document as being one whose
primary purpose is to be displayed to readers,
the approach allows us to put arbitrary things into the
document as part of our work but render only the bits
we want for a particular audience, e.g. mix code,
pedagogical material, R documentation, data, code
from other languages.

The XML/Docbook-XSL-R approach is very general and flexible
with possibly "too" many degrees of freedom.  If the document is
destined only for HTML, then writing in HTML directly may be
best. The generality is useful when there are multiple targets
and one wants to extract information programmatically, e.g.
extract subsets of the code within the document such as
that in section 2, or only Matlab code.

I will be packaging up all the material we have on this soon,
so if anyone wants a copy, let me know.


  D.

Douglas Bates wrote:
> My university provides me with a powerful course management system for
> the courses that I teach.  Among other things I can create a wiki for
> the course, which is very convenient for cross-linking different bits
> of the course.
> 
> Naturally I use R extensively in my teaching and I want to incorporate
> R code, output and graphics in such a wiki.  If I were producing LaTeX
> sources instead of HTML sources I create .Rnw files for Sweave and I
> would edit them using ESS in emacs.
> 
> What options do I have for producing HTML with embedded R content and
> what is a good, preferably emacs-based, way of editing the source
> code?
> 
> One basic problem is trying to present mathematical expressions in HTML (see
> http://www.cs.tut.fi/~jkorpela/math/) but, aside from that, there are
> questions of presenting input R expressions and the corresponding
> output and of incorporating graphics files produced by R.  I could try
> to use latex2html or texi2html but the output from latex2html at least
> would be quite inconvenient to use because it generates so many linked
> files.  Once they are uploaded it would be horrible trying to get all
> the links straightened out.
> 
> In a sense there are already tools for this type of output from .Rd
> files.  Would it be best to use those tools or to use texinfo tools or
> ...?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.7 (Darwin)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHFRgR9p/Jzwa2QP4RAi2vAJ0S+Mnbjvt6z9pe1kPoIxHeaaZQkACggHOL
GflkuedfvPVQfm6fayigGK0=
=4fKz
-----END PGP SIGNATURE-----


From rdpeng at gmail.com  Tue Oct 16 22:00:16 2007
From: rdpeng at gmail.com (Roger Peng)
Date: Tue, 16 Oct 2007 16:00:16 -0400
Subject: [Rd] Fwd: Digest package - make digest generic?
In-Reply-To: <18197.781.298239.228245@ron.nulle.part>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
	<18197.781.298239.228245@ron.nulle.part>
Message-ID: <66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>

My understanding was that Hadley wanted 'digest' to operate on part of
an object rather than on the entire, which might contain uninteresting
or irrelevant details.  For example, if we had

a <- structure(list(x = 1, y = 2), class = "foo")
b <- structure(list(x = 2342342, y = 2), class = "foo")

digest.foo <- function(object, ...) digest(object$y)

Then 'digest(a)' and 'digest(b)' would return the same value in this
case, even though 'a' and 'b' are different objects.  I can see why
someone *might* want digest to return the same hash for 'a' and 'b'
but I would personally find this behavior a little surprising.

-roger

On 10/16/07, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> Hi Roger,
>
> On 16 October 2007 at 08:25, Roger Peng wrote:
> | Sorry, I forgot the 'reply-all'.
> |
> | -roger
> |
> | ---------- Forwarded message ----------
> | From: Roger Peng <rdpeng at gmail.com>
> | Date: Oct 16, 2007 8:24 AM
> | Subject: Re: [Rd] Digest package - make digest generic?
> | To: Henrik Bengtsson <hb at stat.berkeley.edu>
> |
> |
> | Would it be possible to instead create a function with a name like
> | 'digest0' which is the current function, and then create a generic
> | function with the name 'digest'?  In this case 'digest0' always
> | returns the digest of the "raw" object.
> |
> | My one concern is that my current expectation is that 'digest' takes
> | an object and hashes the entire object, regardless of class.  So if
> | two objects are different (even in their internal representation),
> | they should return different digests.  I would be a little worried if
> | 'digest' had a different (and perhaps unpredictable) behavior
> | depending on the class of the object where two objects that were in
> | fact different could lead to the same digest.
>
> But haven't the cryptographers taken care of that argument?
>
> To my layman's understanding, the consensus is that hash collissions are
> possible but very very unlikely. And we already have that problem with digest
> as it stands as -- if collission are possible, identical hashes could result
> from two different input whether or not digest is generic or not.
>
> Or am I missing what you were trying to get at?
>
> | I can see why one might want class-specific behavior, but what a class
> | author wants from 'digest' may not be different from what other users
> | of 'digest' on that object want.
> |
> | A simple approach might be
> |
> | digest0 <- function(x, ...) digest(unclass(x), ...)
>
> Or, just for argument's sake, we go full circle, digest stays as it is and
> Hadley implements his own generic, say, 'Digest()', aroumd digest ?  Naa....
>
> I think I like the idea of making it generic, but I really would like to
> know more about possible downsides.
>
> Dirk
>
> | although this doesn't work for S4 objects I don't think.
> |
> | -roger
> |
> | On 10/15/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> | > On 10/15/07, hadley wickham <h.wickham at gmail.com> wrote:
> | > > On 10/15/07, Henrik Bengtsson <hb at maths.lth.se> wrote:
> | > > > [As agreed, CC:ing r-devel since others might be interested in this as well.]
> | > > >
> | > > > Hi.
> | > > >
> | > > > On 10/15/07, Dirk Eddelbuettel <edd at debian.org> wrote:
> | > > > >
> | > > > > Hi Hadley,
> | > > > >
> | > > > > On 15 October 2007 at 09:51, hadley wickham wrote:
> | > > > > | Would you consider making digest a generic function?  That way I could
> | > > > > | (e.g.) make a generic method for ggplot objects which didn't depend
> | > > > > | (so much) on their internal representation.
> | > > > >
> | > > > > Well, generally speaking, I always take patches :)
> | > > >
> | > > > I see know problems in doing this.  The patch would be:
> | > > >
> | > > > digest <- function(...) UseMethod("digest");
> | > > > digest.default <- <current digest function>.
> | > > >
> | > > > I think that should do, and I don't think it has any surprising side
> | > > > effects so it could be added in the next release.  Dirk, can you do
> | > > > that?
> | > > >
> | > > > >
> | > > > > I have to admit that I am fairly weak on these aspects of the S language.
> | > > > > One question is:  how to the current users of digest (i.e. Henrik's and
> | > > > > Seth's caching mechanism, for example) use it on arbitrary objects _without_
> | > > > > it being generic?
> | > > >
> | > > > I basically put everything I want into a list() and pass that to
> | > > > digest::digest().
> | > >
> | > > Yes, that's what I'm doing too.
> | > >
> | > > > >
> | > > > > | The reason I ask is that I'm using digest as a way of coming up with a
> | > > > > | unique file name for each example graphic.  I want to be able to
> | > > > > | easily compare the appearance of examples between versions, but
> | > > > > | currently the digest depends on internal details, so it's hard to
> | > > > > | match up graphics between versions.
> | > > >
> | > > > See loadCache(key) and saveCache(object, key) in R.cache, which
> | > > > basically loads and saves results from and to a file cache based on a
> | > > > key object - no need to specify paths or filenames.  You can specify
> | > > > paths etc if you want to, but by default it is just transparent.
> | > >
> | > > The problem is I need to refer to the image from the documentation, so
> | > > I do need to know it's path.  I also want to be able to look at the
> | > > image, so if the digests are different I can see what the difference
> | > > is (I'm planning to automate this with the imagemagick compare command
> | > > line tool).
> | >
> | > See ?findCache.  That will give you the pathname given a key.  It is
> | > on purpose that I do not list this function in the HTML help index - I
> | > want to keep the "public" API to a minimum.
> | >
> | > /Henrik
> | >
> | > >
> | > > > However, I think Hadley is referring to a different problem.
> | > > > Basically, he got an object containing a lot of fields, but for his
> | > > > purposes it is only a subset of the fields that he wants to use to
> | > > > generate a consistent the hashcode.  If he pass any other field, that
> | > >
> | > > Yes, exactly.
> | > >
> | > > > will break the consistency.  In that case, the designer of the class
> | > > > has to identify the fields that makes uniquely identify the state of
> | > > > the object.  I do that for many of my object and pass them down in a
> | > > > list() structure to digest().  I agree, by making digest() generic,
> | > > > one can make the code nicer.  [If there is a need to dispatch on
> | > > > multiple arguments, we have to go for S4, but otherwise S3 gives the
> | > > > minimal modification].
> | > > >
> | > > > Side comment: This basically comes down to how for instance Java deals
> | > > > with hashCode() and equals() etc.  By default the object as is used to
> | > > > generate the hashcode (and can be used by equals() compare objects).
> | > >
> | > > Yes, that's the model I was thinking of too.
> | > >
> | > > Hadley
> | > >
> | > > --
> | > > http://had.co.nz/
> | > >
> | > > ______________________________________________
> | > > R-devel at r-project.org mailing list
> | > > https://stat.ethz.ch/mailman/listinfo/r-devel
> | > >
> | >
> | > ______________________________________________
> | > R-devel at r-project.org mailing list
> | > https://stat.ethz.ch/mailman/listinfo/r-devel
> | >
> |
> |
> | --
> | Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> |
> |
> | --
> | Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Three out of two people have difficulties with fractions.
>


-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From h.wickham at gmail.com  Tue Oct 16 22:22:31 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 16 Oct 2007 15:22:31 -0500
Subject: [Rd] Fwd: Digest package - make digest generic?
In-Reply-To: <66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
	<18197.781.298239.228245@ron.nulle.part>
	<66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>
Message-ID: <f8e6ff050710161322g69214d7dv9fa4672280404e9c@mail.gmail.com>

On 10/16/07, Roger Peng <rdpeng at gmail.com> wrote:
> My understanding was that Hadley wanted 'digest' to operate on part of
> an object rather than on the entire, which might contain uninteresting
> or irrelevant details.  For example, if we had
>
> a <- structure(list(x = 1, y = 2), class = "foo")
> b <- structure(list(x = 2342342, y = 2), class = "foo")
>
> digest.foo <- function(object, ...) digest(object$y)

Yes, that's exactly what I want, except in my case my objects contain
about 20 or 30 bits of information that are irrelevant (I'm my case
documentation about the class and other functions), so it would be
surprising if p1 and p2 which produced identical plots gave different
digests.

If you want the default behaviour, you could always call
digest.default to digest the entire object.

Hadley


From rdpeng at gmail.com  Tue Oct 16 22:59:59 2007
From: rdpeng at gmail.com (Roger Peng)
Date: Tue, 16 Oct 2007 16:59:59 -0400
Subject: [Rd] Fwd: Digest package - make digest generic?
In-Reply-To: <f8e6ff050710161322g69214d7dv9fa4672280404e9c@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<18195.34181.782782.49558@ron.nulle.part>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
	<18197.781.298239.228245@ron.nulle.part>
	<66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>
	<f8e6ff050710161322g69214d7dv9fa4672280404e9c@mail.gmail.com>
Message-ID: <66f3bd910710161359t4a1580ecl9bc2ec1191560cd7@mail.gmail.com>

Calling 'digest.default' directly would not be possible if the method
were hidden in a namespace (without resorting to some maneuvering).
To force the default method I think you'd need to 'unclass' the
object.

I'm not against making 'digest' generic, but I'd prefer it if there
were a guaranteed way to compute the digest of the "raw"/full object
without having to wonder about class-specific behavior.  Something
like:

digest0 <- [[the current 'digest' function]]
digest <- function(object, ...) UseMethod("digest")
digest.default <- function(object, ...) digest0(object, ...)

As I think we've seen in this discussion already, what is surprising
to one person may not be surprising to another (and vice versa) so
having something like 'digest0' which is consistent across all R
objects would be useful.

-roger

On 10/16/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 10/16/07, Roger Peng <rdpeng at gmail.com> wrote:
> > My understanding was that Hadley wanted 'digest' to operate on part of
> > an object rather than on the entire, which might contain uninteresting
> > or irrelevant details.  For example, if we had
> >
> > a <- structure(list(x = 1, y = 2), class = "foo")
> > b <- structure(list(x = 2342342, y = 2), class = "foo")
> >
> > digest.foo <- function(object, ...) digest(object$y)
>
> Yes, that's exactly what I want, except in my case my objects contain
> about 20 or 30 bits of information that are irrelevant (I'm my case
> documentation about the class and other functions), so it would be
> surprising if p1 and p2 which produced identical plots gave different
> digests.
>
> If you want the default behaviour, you could always call
> digest.default to digest the entire object.
>
> Hadley
>


-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From hb at stat.berkeley.edu  Wed Oct 17 03:10:41 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 16 Oct 2007 18:10:41 -0700
Subject: [Rd] Fwd: Digest package - make digest generic?
In-Reply-To: <66f3bd910710161359t4a1580ecl9bc2ec1191560cd7@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
	<18197.781.298239.228245@ron.nulle.part>
	<66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>
	<f8e6ff050710161322g69214d7dv9fa4672280404e9c@mail.gmail.com>
	<66f3bd910710161359t4a1580ecl9bc2ec1191560cd7@mail.gmail.com>
Message-ID: <59d7961d0710161810r5e3c8f10o2155dffa47ee20ac@mail.gmail.com>

Hi,

if there is a need for a digest0(), which there seems to be, we should
have one, but we should find a better name.

A better approach may be to keep digest() as is and introduce
hashCode() for the feature Hadley requested, e.g.

hashCode <- function(...) UseMethod("hashCode");
hashCode.default <- function(...) digest(...);

Personally, I think hashCode() is a more descriptive term of the
value/outcome whereas digest() describes the action.  Of course, some
of the arguments of digest() should be excluded from hashCode(), but
the above gives you the idea.

That would make the distinction clear, and it is very much in line how
Java is doing it (sorry Dylan folks).  I think the Java got a useful
setup with its hashCode() & equals() methods.  If you want the
details, here is one reference:

  http://www.geocities.com/technofundo/tech/java/equalhash.html

but the short story is that <quote>two objects that are "equal" must
produce the same hash code as long as they are equal, however unequal
objects need not produce distinct hash codes.</quote>.  The equals()
relationship should be reflexive, symmetric, transitive, consistent.
For details, see above URL.  These rules are very useful, but requires
quite a bit of effort from the developer/maintainer in order to keep
it up to date and valid.

Cheers

Henrik






On 10/16/07, Roger Peng <rdpeng at gmail.com> wrote:
> Calling 'digest.default' directly would not be possible if the method
> were hidden in a namespace (without resorting to some maneuvering).
> To force the default method I think you'd need to 'unclass' the
> object.
>
> I'm not against making 'digest' generic, but I'd prefer it if there
> were a guaranteed way to compute the digest of the "raw"/full object
> without having to wonder about class-specific behavior.  Something
> like:
>
> digest0 <- [[the current 'digest' function]]
> digest <- function(object, ...) UseMethod("digest")
> digest.default <- function(object, ...) digest0(object, ...)
>
> As I think we've seen in this discussion already, what is surprising
> to one person may not be surprising to another (and vice versa) so
> having something like 'digest0' which is consistent across all R
> objects would be useful.
>
> -roger
>
> On 10/16/07, hadley wickham <h.wickham at gmail.com> wrote:
> > On 10/16/07, Roger Peng <rdpeng at gmail.com> wrote:
> > > My understanding was that Hadley wanted 'digest' to operate on part of
> > > an object rather than on the entire, which might contain uninteresting
> > > or irrelevant details.  For example, if we had
> > >
> > > a <- structure(list(x = 1, y = 2), class = "foo")
> > > b <- structure(list(x = 2342342, y = 2), class = "foo")
> > >
> > > digest.foo <- function(object, ...) digest(object$y)
> >
> > Yes, that's exactly what I want, except in my case my objects contain
> > about 20 or 30 bits of information that are irrelevant (I'm my case
> > documentation about the class and other functions), so it would be
> > surprising if p1 and p2 which produced identical plots gave different
> > digests.
> >
> > If you want the default behaviour, you could always call
> > digest.default to digest the entire object.
> >
> > Hadley
> >
>
>
> --
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Wed Oct 17 04:36:21 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 16 Oct 2007 21:36:21 -0500
Subject: [Rd] Fwd: Digest package - make digest generic?
In-Reply-To: <59d7961d0710161810r5e3c8f10o2155dffa47ee20ac@mail.gmail.com>
References: <f8e6ff050710150751r5d9add21sdb3ebccdb93ed085@mail.gmail.com>
	<59d7961d0710151300i1aed80adx448642f6161b3d29@mail.gmail.com>
	<f8e6ff050710151348x8888784lc6e5c5b5cf7e2bd@mail.gmail.com>
	<59d7961d0710151405w1b78c2bl81f08da87e62207e@mail.gmail.com>
	<66f3bd910710160524g3ef0f207h30f5f6bdf2880110@mail.gmail.com>
	<66f3bd910710160525o697104a8y90e9c8bf4c3255d1@mail.gmail.com>
	<18197.781.298239.228245@ron.nulle.part>
	<66f3bd910710161300w1857acd9gfdd038c389077dec@mail.gmail.com>
	<f8e6ff050710161322g69214d7dv9fa4672280404e9c@mail.gmail.com>
	<66f3bd910710161359t4a1580ecl9bc2ec1191560cd7@mail.gmail.com>
	<59d7961d0710161810r5e3c8f10o2155dffa47ee20ac@mail.gmail.com>
Message-ID: <18197.29989.476315.453783@ron.nulle.part>


On 16 October 2007 at 18:10, Henrik Bengtsson wrote:
| if there is a need for a digest0(), which there seems to be, we should
| have one, but we should find a better name.
|
| A better approach may be to keep digest() as is and introduce

Agreed.  It's better to keep the existing name and functionality.

| hashCode() for the feature Hadley requested, e.g.
| 
| hashCode <- function(...) UseMethod("hashCode");
| hashCode.default <- function(...) digest(...);
| 
| Personally, I think hashCode() is a more descriptive term of the
| value/outcome whereas digest() describes the action.  Of course, some
| of the arguments of digest() should be excluded from hashCode(), but
| the above gives you the idea.

Not sure I like the 'hashCode' name all that much.  How about some verbNoun
combination like 'createHash' ?
 
| That would make the distinction clear, and it is very much in line how
| Java is doing it (sorry Dylan folks).  I think the Java got a useful
| setup with its hashCode() & equals() methods.  If you want the
| details, here is one reference:
| 
|   http://www.geocities.com/technofundo/tech/java/equalhash.html
| 
| but the short story is that <quote>two objects that are "equal" must
| produce the same hash code as long as they are equal, however unequal
| objects need not produce distinct hash codes.</quote>.  The equals()
| relationship should be reflexive, symmetric, transitive, consistent.
| For details, see above URL.  These rules are very useful, but requires
| quite a bit of effort from the developer/maintainer in order to keep
| it up to date and valid.

Yes, I am not sure I can guarantee that.  We can always try, though.

Thanks for the follow-up!

Dirk

-- 
Three out of two people have difficulties with fractions.


From detlef.steuer at hsu-hamburg.de  Wed Oct 17 08:37:02 2007
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Wed, 17 Oct 2007 08:37:02 +0200
Subject: [Rd] Sweave/ESS-like tools for HTML
In-Reply-To: <47151811.5040500@wald.ucdavis.edu>
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
	<47151811.5040500@wald.ucdavis.edu>
Message-ID: <20071017083702.62ecf849@gaia.unibw-hamburg.de>

Hi Duncan,

your approach looks _quite_ useful to me!
I'm a bit afraid it will be a very hard jump to get on that tool,
but riding it must be fun.

Yes, I'm interested!

Detlef

On Wed, 17 Oct 2007 08:59:13 +1300
Duncan Temple Lang <duncan at wald.ucdavis.edu> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Hi Doug.
> 
>   This is probably more than you want - either to know or to use
> for your specific task, but I'll throw it out there for general
> information.
> 
>  I write documents using XML, specifically an extended version
> of Docbook with elements for describing R concepts (e.g.
> code, plot, output, function name, argument, ...).  Then,
> I use XSL to transform this to either HTML, FO and on to PDF,
> or to LaTeX (via db2latex).  As for processing
> the R code and inserting the output into the resulting view/document,
> I use the Sxslt package from within R which allows me to combine XSL
> rules with those that also call R functions.
> I author the documents using the nxml mode in emacs
> and have some basic "gestures" for sending code from the document
> to R.
> 
> 
> Deb Nolan and I use this for creating dynamic and interactive
> documents which can be transformed to HTML with embedded
> controls for the reader to control the R computations
> interactively.
> 
> Rather than thinking of the document as being one whose
> primary purpose is to be displayed to readers,
> the approach allows us to put arbitrary things into the
> document as part of our work but render only the bits
> we want for a particular audience, e.g. mix code,
> pedagogical material, R documentation, data, code
> from other languages.
> 
> The XML/Docbook-XSL-R approach is very general and flexible
> with possibly "too" many degrees of freedom.  If the document is
> destined only for HTML, then writing in HTML directly may be
> best. The generality is useful when there are multiple targets
> and one wants to extract information programmatically, e.g.
> extract subsets of the code within the document such as
> that in section 2, or only Matlab code.
> 
> I will be packaging up all the material we have on this soon,
> so if anyone wants a copy, let me know.
> 
> 
>   D.
> 
> Douglas Bates wrote:
> > My university provides me with a powerful course management system for
> > the courses that I teach.  Among other things I can create a wiki for
> > the course, which is very convenient for cross-linking different bits
> > of the course.
> > 
> > Naturally I use R extensively in my teaching and I want to incorporate
> > R code, output and graphics in such a wiki.  If I were producing LaTeX
> > sources instead of HTML sources I create .Rnw files for Sweave and I
> > would edit them using ESS in emacs.
> > 
> > What options do I have for producing HTML with embedded R content and
> > what is a good, preferably emacs-based, way of editing the source
> > code?
> > 
> > One basic problem is trying to present mathematical expressions in HTML (see
> > http://www.cs.tut.fi/~jkorpela/math/) but, aside from that, there are
> > questions of presenting input R expressions and the corresponding
> > output and of incorporating graphics files produced by R.  I could try
> > to use latex2html or texi2html but the output from latex2html at least
> > would be quite inconvenient to use because it generates so many linked
> > files.  Once they are uploaded it would be horrible trying to get all
> > the links straightened out.
> > 
> > In a sense there are already tools for this type of output from .Rd
> > files.  Would it be best to use those tools or to use texinfo tools or
> > ...?
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.7 (Darwin)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFHFRgR9p/Jzwa2QP4RAi2vAJ0S+Mnbjvt6z9pe1kPoIxHeaaZQkACggHOL
> GflkuedfvPVQfm6fayigGK0=
> =4fKz
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Somebody once said, "If you lend someone $10 and never see that person 
again, it was probably worth it".
--- found in a mailing list


From dstates at umich.edu  Wed Oct 17 05:05:07 2007
From: dstates at umich.edu (dstates at umich.edu)
Date: Wed, 17 Oct 2007 05:05:07 +0200 (CEST)
Subject: [Rd] dget not restoring dput in R 2.6.0 (PR#10350)
Message-ID: <20071017030507.EC9FC282EFF4@mail.pubhealth.ku.dk>

Full_Name: David States
Version: 2.6.0
OS: Windows XP64
Submission from: (NULL) (141.211.38.9)


# The pair of commands
#
# dput(object, "file.dput")
# object = dget("file.dput")
#
# should be a no op, but this is not working correctly for all objects.
#
# Simple example:
#
# make a simple object of class "hclust"
cl = hclust(dist(matrix(nrow=4,ncol=4, c(1:16))))
# save it to a file using dput
dput(cl, "cl.dput")
# the following two commands should give identical results, but they dont
str(cl)
str(dget("cl.dput"))
# plot also fails to interpret the labels on the restore object correctly
par(mfrow=c(2,1))
plot(cl)
plot(dget("cl.dput"))


From otoomet at ut.ee  Wed Oct 17 06:10:05 2007
From: otoomet at ut.ee (otoomet at ut.ee)
Date: Wed, 17 Oct 2007 06:10:05 +0200 (CEST)
Subject: [Rd] R CMD build and et_EE.UTF-8 locale -> invalid files (PR#10351)
Message-ID: <20071017041005.D2340282EFF4@mail.pubhealth.ku.dk>

Full_Name: Ott Toomet
Version: 2.6.0, 2.5.x
OS: debian etch, lenny
Submission from: (NULL) (80.235.63.243)


When building a package with 'R CMD build name_of_directory" using "et_EE.UTF-8"
locale, I get the following:

siim at tancredi:~/tyyq/econ/micEcon$ R CMD build trunk 
* checking for file 'trunk/DESCRIPTION' ... OK
* preparing 'trunk':
* checking DESCRIPTION meta-information ... OK
* checking whether 'INDEX' is up-to-date ... NO
* use '--force' to overwrite the existing 'INDEX'
* removing junk files
* excluding invalid files from 'micEcon'
Subdirectory 'R' contains invalid file names:
  testConsist.R tobit2fit.R tobit2.R tobit5fit.R translogCalc.R
  translogDeriv.R translogEst.R translogHessian.R translogMonoRestr.R
  utils.R vcov-methods.R vcov.selection.R writeFront41in.R
Subdirectory 'man' contains invalid file names:
  testConsist.Rd tobit2fit.Rd translogCalc.Rd translogDeriv.Rd
  translogEst.Rd translogHessian.Rd triang.Rd vcov-methods.Rd
  vcov.selection.Rd vecli2m.Rd veclipos.Rd vecli.Rd writeFront41in.Rd
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'micEcon_0.3-8.tar.gz'

Of course, the package does not work because of removal of these files.  It is
hard for me to see anything illegal in the listed file names.  Even more,
everything works perfectly, if I run the command from "C" locale:

siim at tancredi:~/tyyq/econ/micEcon$ LC_ALL="C" R CMD build trunk 
* checking for file 'trunk/DESCRIPTION' ... OK
* preparing 'trunk':
* checking DESCRIPTION meta-information ... OK
* checking whether 'INDEX' is up-to-date ... NO
* use '--force' to overwrite the existing 'INDEX'
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'micEcon_0.3-8.tar.gz'

I can still can directly install from the subdirectory: 'R CMD INSTALL trunk'
works well regardless of locale.

The micEcon package is available at CRAN.

Best,
Ott


From P.Dalgaard at biostat.ku.dk  Wed Oct 17 09:58:04 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 17 Oct 2007 09:58:04 +0200
Subject: [Rd] R CMD build and et_EE.UTF-8 locale -> invalid files
	(PR#10351)
In-Reply-To: <20071017041005.D2340282EFF4@mail.pubhealth.ku.dk>
References: <20071017041005.D2340282EFF4@mail.pubhealth.ku.dk>
Message-ID: <4715C08C.6080705@biostat.ku.dk>

otoomet at ut.ee wrote:
> Full_Name: Ott Toomet
> Version: 2.6.0, 2.5.x
> OS: debian etch, lenny
> Submission from: (NULL) (80.235.63.243)
>
>
> When building a package with 'R CMD build name_of_directory" using "et_EE.UTF-8"
> locale, I get the following:
>
> siim at tancredi:~/tyyq/econ/micEcon$ R CMD build trunk 
> * checking for file 'trunk/DESCRIPTION' ... OK
> * preparing 'trunk':
> * checking DESCRIPTION meta-information ... OK
> * checking whether 'INDEX' is up-to-date ... NO
> * use '--force' to overwrite the existing 'INDEX'
> * removing junk files
> * excluding invalid files from 'micEcon'
> Subdirectory 'R' contains invalid file names:
>   testConsist.R tobit2fit.R tobit2.R tobit5fit.R translogCalc.R
>   translogDeriv.R translogEst.R translogHessian.R translogMonoRestr.R
>   utils.R vcov-methods.R vcov.selection.R writeFront41in.R
> Subdirectory 'man' contains invalid file names:
>   testConsist.Rd tobit2fit.Rd translogCalc.Rd translogDeriv.Rd
>   translogEst.Rd translogHessian.Rd triang.Rd vcov-methods.Rd
>   vcov.selection.Rd vecli2m.Rd veclipos.Rd vecli.Rd writeFront41in.Rd
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'micEcon_0.3-8.tar.gz'
>
> Of course, the package does not work because of removal of these files.  It is
> hard for me to see anything illegal in the listed file names.  Even more,
> everything works perfectly, if I run the command from "C" locale:
>
> siim at tancredi:~/tyyq/econ/micEcon$ LC_ALL="C" R CMD build trunk 
> * checking for file 'trunk/DESCRIPTION' ... OK
> * preparing 'trunk':
> * checking DESCRIPTION meta-information ... OK
> * checking whether 'INDEX' is up-to-date ... NO
> * use '--force' to overwrite the existing 'INDEX'
> * removing junk files
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'micEcon_0.3-8.tar.gz'
>
> I can still can directly install from the subdirectory: 'R CMD INSTALL trunk'
> works well regardless of locale.
>
> The micEcon package is available at CRAN.
>
>   
I'm not sure what to do about it, but I'm 99% sure that what is biting
you is that Estonian sorts z before t, and something somewhere is using
a regexp containing a-zA-Z.

Presumably, R CMD build should just standardize the locale to "C"
internally (it is a right pain to change all instances of a-zA-Z to
[[:alpha:]],  most likely not even possible to do it portably, and at
any rate, packages should not come out different depending on the locale
in which it was built.)


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Wed Oct 17 10:35:15 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 17 Oct 2007 10:35:15 +0200 (CEST)
Subject: [Rd] dget not restoring dput in R 2.6.0 (PR#10350)
Message-ID: <20071017083515.93656283416B@mail.pubhealth.ku.dk>

On Wed, 17 Oct 2007, dstates at umich.edu wrote:

> Full_Name: David States
> Version: 2.6.0
> OS: Windows XP64
> Submission from: (NULL) (141.211.38.9)
>
>
> # The pair of commands
> #
> # dput(object, "file.dput")
> # object = dget("file.dput")
> #
> # should be a no op, but this is not working correctly for all objects.

Not so, and it says so on the help page:

      Deparsing an object is difficult, and not always possible.  With
      the default 'control', 'dput()' attempts to deparse in a way that
      is readable, but for more complex or unusual objects, not likely
      to be parsed as identical to the original.  Use 'control = "all"'
      for the most complete deparsing; use 'control = NULL' for the
      simplest deparsing, not even including attributes.

Had you followed the advice, your example would have worked.

dump() is more accurate than dput(), and save() more so than either.

> #
> # Simple example:
> #
> # make a simple object of class "hclust"
> cl = hclust(dist(matrix(nrow=4,ncol=4, c(1:16))))
> # save it to a file using dput
> dput(cl, "cl.dput")
> # the following two commands should give identical results, but they dont
> str(cl)
> str(dget("cl.dput"))
> # plot also fails to interpret the labels on the restore object correctly
> par(mfrow=c(2,1))
> plot(cl)
> plot(dget("cl.dput"))
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at stat.uiowa.edu  Wed Oct 17 14:59:39 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 17 Oct 2007 07:59:39 -0500 (CDT)
Subject: [Rd] LazyLoad changes the class of objects
In-Reply-To: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>
References: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>

Yes, attributes are not preserved, though why that should matter
given the frequent strong recommendations in this list against
using attributes on environments or other reference objects is
beyond me. More importantly, locking and active bindings are not
preserved either.  Will look into fixing this this 2.7.

luke

On Fri, 12 Oct 2007, Gabor Grothendieck wrote:

> Consider a package that this DESCRIPTION file:
>
> ---
> Package: tester
> Version: 0.1-0
> Date: 2007-10-12
> Title: Prototype object-based programming
> Author: Gabor Grothendieck
> Maintainer: Gabor Grothendieck <ggrothendieck at gmail.com>
> Description: test
> LazyLoad: true
> Depends: R (>= 2.6.0)
> License: GPL2
> ---
>
> and a single subdirectory R containing tester.R which contains two lines:
>
> ---
> e <- new.env()
> class(e) <- c("x", "environment")
> ---
>
> Now issue these commands:
>
>> library(tester)
>> class(tester::e)
> [1] "environment"
>
>> R.version.string # Windows Vista
> [1] "R version 2.6.0 Patched (2007-10-08 r43124)"
>
>
> Note that the class of e was changed from what we set it to !!!
>
> On the other handn, if we omit LazyLoad: true from the DESCRIPTION file
> then it retains its original class.
>
>> # removed LazyLoad: true line from DESCRIPTION and reinstall pkg
>> # now its ok
>> library(tester)
>> class(tester::e)
> [1] "x"           "environment"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From hb at stat.berkeley.edu  Wed Oct 17 16:41:27 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 17 Oct 2007 07:41:27 -0700
Subject: [Rd] LazyLoad changes the class of objects
In-Reply-To: <Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>
References: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>
	<Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>
Message-ID: <59d7961d0710170741k4b25359cjdbdfcb77f772b87f@mail.gmail.com>

Yes (on the yes), to second Luke.  Here is John Chambers' comment when
I was bitten by the same "bug" a while ago:

  http://tolstoy.newcastle.edu.au/R/devel/02b/0524.html

See also Peter Dalgaard's follow up suggesting to wrap up the
environment in a list, which will typically be enough.  I've been
using this "trick" successfully in the Object class (R.oo package) for
several years, where I'm putting the environment in the attributes
list of an object, i.e.  obj <- NA; attr(NA, "..env") <- new.env();
It turned out at the time that this was slightly faster to access than
using a list element.

Cheers

Henrik

On 10/17/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
> Yes, attributes are not preserved, though why that should matter
> given the frequent strong recommendations in this list against
> using attributes on environments or other reference objects is
> beyond me. More importantly, locking and active bindings are not
> preserved either.  Will look into fixing this this 2.7.
>
> luke
>
> On Fri, 12 Oct 2007, Gabor Grothendieck wrote:
>
> > Consider a package that this DESCRIPTION file:
> >
> > ---
> > Package: tester
> > Version: 0.1-0
> > Date: 2007-10-12
> > Title: Prototype object-based programming
> > Author: Gabor Grothendieck
> > Maintainer: Gabor Grothendieck <ggrothendieck at gmail.com>
> > Description: test
> > LazyLoad: true
> > Depends: R (>= 2.6.0)
> > License: GPL2
> > ---
> >
> > and a single subdirectory R containing tester.R which contains two lines:
> >
> > ---
> > e <- new.env()
> > class(e) <- c("x", "environment")
> > ---
> >
> > Now issue these commands:
> >
> >> library(tester)
> >> class(tester::e)
> > [1] "environment"
> >
> >> R.version.string # Windows Vista
> > [1] "R version 2.6.0 Patched (2007-10-08 r43124)"
> >
> >
> > Note that the class of e was changed from what we set it to !!!
> >
> > On the other handn, if we omit LazyLoad: true from the DESCRIPTION file
> > then it retains its original class.
> >
> >> # removed LazyLoad: true line from DESCRIPTION and reinstall pkg
> >> # now its ok
> >> library(tester)
> >> class(tester::e)
> > [1] "x"           "environment"
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Wed Oct 17 17:07:14 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 17 Oct 2007 11:07:14 -0400
Subject: [Rd] LazyLoad changes the class of objects
In-Reply-To: <59d7961d0710170741k4b25359cjdbdfcb77f772b87f@mail.gmail.com>
References: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>
	<Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>
	<59d7961d0710170741k4b25359cjdbdfcb77f772b87f@mail.gmail.com>
Message-ID: <971536df0710170807x1f896c0bo98ad91e7a8a0164c@mail.gmail.com>

On 10/17/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Yes (on the yes), to second Luke.  Here is John Chambers' comment when
> I was bitten by the same "bug" a while ago:
>
>  http://tolstoy.newcastle.edu.au/R/devel/02b/0524.html
>
> See also Peter Dalgaard's follow up suggesting to wrap up the
> environment in a list, which will typically be enough.  I've been
> using this "trick" successfully in the Object class (R.oo package) for
> several years, where I'm putting the environment in the attributes
> list of an object, i.e.  obj <- NA; attr(NA, "..env") <- new.env();
> It turned out at the time that this was slightly faster to access than
> using a list element.

This has all been discussed before but this "trick" is not sufficient
for defining an environment subclass because it does not respect
inheritance.  The subclass writer must replicate all methods that
act on environments in a subclass for an environment subclass to
have them.  Inheritance is completely broken.

If there were N environment methods the writer of an environment subclass
would have to write N methods to support them all.  On the other hand,
if it worked in a true OO way the subclass writer would not have to write
anything.

Also suppose a new environment method comes along.  In true OO
the subclass automatically inherits it but with the "trick" the subclass
writer needs to write a new method always mimicing the parent.

This is not how OO is supposed to work.


From savicky at cs.cas.cz  Wed Oct 17 18:11:16 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 17 Oct 2007 18:11:16 +0200
Subject: [Rd] predictable bit patterns in runif(n) shortly after set.seed
Message-ID: <20071017161116.GE10239@cs.cas.cz>

Mersenne Twister generator is known to be sensitive to the
algorithm used to generate its initial state. The initialization
used in R generates the initial state in a way, which leaves
linear dependencies mod 2 among the bits in the initial state.
Since Mersenne Twister performs only operations, which are
linear mod 2, these dependencies propagate to the output sequence.

An easy to see consequence of this may be demonstrated by
the following script:

  pattern <- function(m=1400)
  {
      x <- runif(m)
      y <- matrix(nrow=m,ncol=32)
      for (j in 1:32) {
          y[,j] <- floor(2*x)
          x <- 2*x - y[,j]
      }
      u <- rep(0,times=32)
      u[c(3,7,10,14,21,25,32)] <- 1
      c(y %*% u) %% 2
  }
  RNGkind("default") # or set.seed() with any seed
  z <- pattern()
  abs(diff(z,lag=2)) # sequence with long constant subsequences

It should be pointed out that it is indeed a consequence of the
initialization. If e.g. runif(10000) is run after RNGkind/set.seed,
then the effect disappears.

Note that each row in matrix y used in function pattern() contains
the bit representation of one of the numbers from runif(m).
Different elements of z are derived from different rows in y and,
hence, from different elements of runif(m). Consequently, they should
mimic an i.i.d. sequence. However, abs(diff(z,lag=2)) allows to
reject such an assumption easily.

The pattern is even better visible graphically, for example using
  for (i in 1:20) {
      set.seed(i)
      z <- pattern()
      z <- abs(diff(z,lag=2))
      if (i == 1) {
          plot(cumsum(2*z-1),type="l")
      } else {
          lines(cumsum(2*z-1))
      }
  }
The resulting curve is almost the same for all the seeds.

I have a working patch, which solves this problem by adding
a new generator called Mersenne-Twister-52, which is the
standard Mersenne Twister with the following modifications:
 - It uses MRG32k5a by P.L'Ecuyer for generating the initial state
   (This generator works modulo odd primes and so does not generate
   dependencies of the kind to which Mersenne Twister is sensitive.)
 - Combines 26 bits of two consequtive numbers into a single number
   with 52 random bits (this explains its name) and adds a constant
   shift 2^-53 to guarantee that the result is always in (0,1).

Combining the two changes together allows to keep the current Mersenne
Twister implementation intact for backward compatibility and provides
more reasons to add a new name than just a different seeding.

In my opinion, there may be applications, which can benefit from
more then 32 random bits in the numbers from runif(n).

I would be pleased to send the patch to R-devel, if the proposed
solution is of the sort, which could be considered.

Petr Savicky.


From nikko at hailmail.net  Wed Oct 17 20:49:52 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 17 Oct 2007 14:49:52 -0400
Subject: [Rd] nmle: gnls  freezes on difficult case
In-Reply-To: <mailman.15.1192615203.10808.r-devel@r-project.org>
References: <mailman.15.1192615203.10808.r-devel@r-project.org>
Message-ID: <1192646992.32030.1216419667@webmail.messagingengine.com>

Hi,
I am not sure this is a bug but I can repeat it, The functions and data
are below.
I know this is nasty data, and it is very questionable whether a 4pl
model
is appropriate, but it is data fed to an automated tool and I would
have hoped for an error. Does this repeat for anyone else?
My details:
> version
               _                           
platform       i686-pc-linux-gnu           
arch           i686                        
os             linux-gnu                   
system         i686, linux-gnu             
status                                     
major          2                           
minor          6.0                         
year           2007                        
month          10                          
day            03                          
svn rev        43063                       
language       R                           
version.string R version 2.6.0 (2007-10-03)



start=c(-1.5, 9.5,  0.09, 10.25)
names(start)<-c("A","B","xmid","scal")

gnls(response~SSllogis(conc,A,B,xmid,scal),tdat,start=start,weights=varPower(),verbose=TRUE)

**Iteration 1
GLS step: Objective: NULLvarStruct  parameters:
    power 
0.3373199 

NLS step: RSS =  0 
 model parameters:-0.799941  8.99983  -0.522623  212.314  
 iterations: 2 

Convergence:
   params varStruct 
 1.172208  1.000000 
### After about 10 min hit cntrl C

Warning messages:
1: In log(xmid) : NaNs produced
2: In log(xmid) : NaNs produced
3: In log(xmid) : NaNs produced




#####################################################################
#### Data
tdat<-data.frame(conc=c(0.00203,0.0061,0.0183,0.0549,0.165,0.494,1.48,4.44,13.3,40),
                 response=c(12,-4,19,11,-5,-3,1,6,0,-8))
#### Self start function
SSllogis <- selfStart(~ A + (B-A)/(1 + exp(scal*(log(x)-log(xmid)))),
  function(mCall, data, LHS)
  {
    #browser()
    xy <- sortedXyData(mCall[["x"]], LHS, data)
    if (nrow(xy) < 5) {
        stop("too few distinct input values to fit a four-parameter
        logistic")
      }
    rng <- range(xy$y)
    drng <- diff(rng)
    B <- rng[2] + 0.001
    A <- rng[1] - 0.001
    xy$prop <- log((B-xy$y)/(xy$y-A+0.001))
    #(xy$y - rng[1] + 0.05 * drng)/(1.1 * drng)
    ir <- as.vector(coef(lm(prop ~ log(x), data = xy)))
    scal <- ir[2]
    xmid <- exp(-ir[1]/ir[2])
    #pars <- as.vector(coef(nls(y ~ cbind(1, 1/(1 + exp((xmid - 
    #    x)/exp(lscal)))), data = xy, start = list(xmid = ir[1], 
    #    lscal = log(abs(ir[2]))), algorithm = "plinear")))
    value <- c(A, B, xmid, scal)
    names(value) <- mCall[c("A", "B", "xmid", "scal")]
    value

  }, c("A", "B", "xmid", "scal"))


From ggrothendieck at gmail.com  Thu Oct 18 03:45:43 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 17 Oct 2007 21:45:43 -0400
Subject: [Rd] Withdrawing SaveImage
Message-ID: <971536df0710171845u4007229h17ae2185ee5eb39d@mail.gmail.com>

I noticed this under R 2.7.0 NEWS:

    o	In package installation, SaveImage: yes is defunct and
	lazyloading is attempted instead.

I think its premature to make SaveImage defunct especially when:

1. there is a bug that would be triggered in some packages
by automatically using LazyLoad instead of SaveImage:

https://stat.ethz.ch/pipermail/r-devel/2007-October/047118.html

2. only last year it was stated on R-devel that there was "no intention to
withdraw SaveImage: yes"

http://tolstoy.newcastle.edu.au/R/devel/06/02/4025.html

Having "SaveImage: yes" automatically invoke LazyLoad is really
tantamount to withdrawing it.

At the very least making SaveImage defunct should be postponed until the
bug in #1 is fixed and a period of time has elapsed during which both
SaveImage and LazyLoad are available without that bug so that packages
affected can gradually move over and have the ability to move back to
SaveImage if the move uncovers more R bugs related to this.


From btyner at gmail.com  Thu Oct 18 15:15:06 2007
From: btyner at gmail.com (btyner at gmail.com)
Date: Thu, 18 Oct 2007 15:15:06 +0200 (CEST)
Subject: [Rd] documentation bug for isoreg example (PR#10352)
Message-ID: <20071018131506.909B7283461C@mail.pubhealth.ku.dk>

Full_Name: Benjamin Tyner
Version: 2.6.0 (43063)
OS: WinXP
Submission from: (NULL) (171.161.224.10)


At the end of the examples for isoreg, there is

   cat("R^2 =", formatC(sum(residuals(ir4)^2) / (9*var(y4)), digits=2),"\n")

I think this should be

   cat("R^2 =", formatC(1 - sum(residuals(ir4)^2) / (9*var(y4)), digits=2),"\n"

Thanks
Ben

platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          6.0                         
year           2007                        
month          10                          
day            03                          
svn rev        43063                       
language       R                           
version.string R version 2.6.0 (2007-10-03)


From nikko at hailmail.net  Thu Oct 18 16:17:50 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 18 Oct 2007 10:17:50 -0400
Subject: [Rd] nmle: gnls freezes on difficult case
Message-ID: <1192717070.9380.1216571837@webmail.messagingengine.com>

Hi,
Following up on my own post, if in gnlsControl I specify
opt='optim' gnls exits quite nicely, with an error, which
is what I would expect. Is this a bug in nlminb?

Nicholas


tt<-gnls(response~SSllogis(conc,A,B,xmid,scal),tdat,start=start,weights=varPower(),verbose=TRUE,control=gnlsControl(opt='optim'))
**Iteration 1
GLS step: Objective: 29.04254varStruct  parameters:
    power 
0.3373206 

NLS step: RSS =  0 
 model parameters:-0.799941  8.99983  -0.522623  212.314  
 iterations: 2 

Convergence:
   params varStruct 
 1.172208  1.000000 
Error in optim(c(coef(gnlsSt)), function(gnlsPars) -logLik(gnlsSt,
gnlsPars),  : 
  initial value in 'vmmin' is not finite
In addition: Warning messages:
1: In log(xmid) : NaNs produced
2: In log(xmid) : NaNs produced
3: In log(xmid) : NaNs produced


From nikko at hailmail.net  Thu Oct 18 16:40:14 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 18 Oct 2007 10:40:14 -0400
Subject: [Rd] nmle: gnls freezes on difficult case
Message-ID: <1192718414.13467.1216579365@webmail.messagingengine.com>

Hi,
I was just able to try this on a windows xp machine
using R-2.5.1. gnls exits gracefully with an error 
so maybe this is a problem with my R installation. If 
so sorry to bother everyone. Does anyone have an idea
which installation parameters to tweek that might cure
this?

Thanks
Nicholas


From ripley at stats.ox.ac.uk  Thu Oct 18 16:46:01 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Oct 2007 15:46:01 +0100 (BST)
Subject: [Rd] nmle: gnls freezes on difficult case
In-Reply-To: <1192717070.9380.1216571837@webmail.messagingengine.com>
References: <1192717070.9380.1216571837@webmail.messagingengine.com>
Message-ID: <Pine.LNX.4.64.0710181543370.17479@gannet.stats.ox.ac.uk>

On Thu, 18 Oct 2007, Nicholas Lewin-Koh wrote:

> Hi,
> Following up on my own post, if in gnlsControl I specify
> opt='optim' gnls exits quite nicely, with an error, which
> is what I would expect. Is this a bug in nlminb?

Possibly, but complex algorithms can loop for non-bug reasons.  I don't 
feel motivated to explore it in detail, but if you want/are able to, 
please let us know what you find.

I have always found optim to work better in package nlme than nlminb (and 
I know others who have the same experience).

>
> Nicholas
>
>
> tt<-gnls(response~SSllogis(conc,A,B,xmid,scal),tdat,start=start,weights=varPower(),verbose=TRUE,control=gnlsControl(opt='optim'))
> **Iteration 1
> GLS step: Objective: 29.04254varStruct  parameters:
>    power
> 0.3373206
>
> NLS step: RSS =  0
> model parameters:-0.799941  8.99983  -0.522623  212.314
> iterations: 2
>
> Convergence:
>   params varStruct
> 1.172208  1.000000
> Error in optim(c(coef(gnlsSt)), function(gnlsPars) -logLik(gnlsSt,
> gnlsPars),  :
>  initial value in 'vmmin' is not finite
> In addition: Warning messages:
> 1: In log(xmid) : NaNs produced
> 2: In log(xmid) : NaNs produced
> 3: In log(xmid) : NaNs produced
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nikko at hailmail.net  Thu Oct 18 17:04:12 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 18 Oct 2007 11:04:12 -0400
Subject: [Rd] nmle: gnls freezes on difficult case
In-Reply-To: <Pine.LNX.4.64.0710181543370.17479@gannet.stats.ox.ac.uk>
References: <1192717070.9380.1216571837@webmail.messagingengine.com>
	<Pine.LNX.4.64.0710181543370.17479@gannet.stats.ox.ac.uk>
Message-ID: <1192719852.19068.1216582441@webmail.messagingengine.com>

Hi,
Thank you for the pointer, I will make the default in my code optim.
As I specified in my last post it may be my installation. In this
case the problem is that the third parameter (xmid) goes negative and 
the log(xmid) fails in the parameterization I am using. For some
reason nlminb is not exiting gracefully. I can look more into this
later if I get time.

Ideally I should constrain xmid to be strictly positive, how would
I use L-BFGS-B in gnls? gnls does not accept a ... argument. In the 
gnlsControl documentation it says

optimMethod: character - the optimization method to be used with the
          'optim' optimizer. The default is '"BFGS"'.  An alternative
          is '"L-BFGS-B"'.

but there is no obvious way to specify lower and upper. Either an
example if there is some scoping trick to do it would be nice,
or change that sentence to "optim method 'L-BFGS-B' will not work
since there is way to specify the upper and lower constraints"

Thanks

Nicholas


Nicholas

On Thu, 18 Oct 2007 15:46:01 +0100 (BST), "Prof Brian Ripley"
<ripley at stats.ox.ac.uk> said:
> On Thu, 18 Oct 2007, Nicholas Lewin-Koh wrote:
> 
> > Hi,
> > Following up on my own post, if in gnlsControl I specify
> > opt='optim' gnls exits quite nicely, with an error, which
> > is what I would expect. Is this a bug in nlminb?
> 
> Possibly, but complex algorithms can loop for non-bug reasons.  I don't 
> feel motivated to explore it in detail, but if you want/are able to, 
> please let us know what you find.
> 
> I have always found optim to work better in package nlme than nlminb (and 
> I know others who have the same experience).
> 
> >
> > Nicholas
> >
> >
> > tt<-gnls(response~SSllogis(conc,A,B,xmid,scal),tdat,start=start,weights=varPower(),verbose=TRUE,control=gnlsControl(opt='optim'))
> > **Iteration 1
> > GLS step: Objective: 29.04254varStruct  parameters:
> >    power
> > 0.3373206
> >
> > NLS step: RSS =  0
> > model parameters:-0.799941  8.99983  -0.522623  212.314
> > iterations: 2
> >
> > Convergence:
> >   params varStruct
> > 1.172208  1.000000
> > Error in optim(c(coef(gnlsSt)), function(gnlsPars) -logLik(gnlsSt,
> > gnlsPars),  :
> >  initial value in 'vmmin' is not finite
> > In addition: Warning messages:
> > 1: In log(xmid) : NaNs produced
> > 2: In log(xmid) : NaNs produced
> > 3: In log(xmid) : NaNs produced
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Thu Oct 18 17:04:36 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 18 Oct 2007 11:04:36 -0400
Subject: [Rd] Sweave wish items
Message-ID: <971536df0710180804k34ef4e43jd02f0ce64a889732@mail.gmail.com>

A scanario I have is spawning a Sweave job from another program (not
necessarily written in R).  That program needs to pass some information
to the Sweave program including what the file name is of the report to
produce.

Currently it calls a shell script which calls R CMD Sweave but it would
be nice if R CMD Sweave were powerful enough to do that itself.  These
are the features that would be desirable:

- support --args or some other method of passing arguments from
  R CMD Sweave line to the Sweave script

- have a facility whereby R CMD Sweave can directly generate the
.pdf file and an argument which allows the caller to define the name
of the resulting pdf file. e.g. --pdf

- -o or some way to define the name of the output file.  I need to
have many different outputs from the same Rnw file so its
important to name them differently.

- an -x argument similar to Perl/Python/Ruby such that if one calls
R CMD Sweave -x abc myfile.Rnw then all lines up to the first one
matching the indicated regexp are skipped.  This facilitates combining
the script with a shell or batch file if the previous is not enough.

Thus one could spawn this from their program:

R CMD Sweave --pdf myfile.Rnw -o myfile-123.pdf --args 23

and it would generate a pdf file from myfile.Rnw of the indicated
ame passing 23 as arg1 to the R code embedded in the Sweave file.

Also it would be possible to place Windows batch commands and
the Sweave file in the same file and the batch commands would
look like this:

-----------------------------
... various Windows batch commands ...
R CMD Sweave -x "^.EOF" --pdf -o %1 %0 --args %2
.... maybe more commands ....
exit
% EOF
... Sweave code goes here ...


From h.wickham at gmail.com  Thu Oct 18 19:16:00 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 18 Oct 2007 12:16:00 -0500
Subject: [Rd] Underlying representation for rownames
Message-ID: <f8e6ff050710181016v79c866acwca29a16ad2d5fae2@mail.gmail.com>

Is it possible to get at the underlying representation of row names -
ie. what you see in the output from dput:

> df <- data.frame(1:4)
> dput(df)
structure(list(X1.4 = 1:4), .Names = "X1.4", row.names = c(NA,
-4L), class = "data.frame")

I would like to be able to tell if a data frame has the default row
names, or if they have been changed by the user.  I need this for
rggobi because in GGobi row names should be unique across all data
frames, unless explicitly set by the user.

Thanks,

Hadley


-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Thu Oct 18 19:36:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Oct 2007 18:36:33 +0100 (BST)
Subject: [Rd] Underlying representation for rownames
In-Reply-To: <f8e6ff050710181016v79c866acwca29a16ad2d5fae2@mail.gmail.com>
References: <f8e6ff050710181016v79c866acwca29a16ad2d5fae2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710181832450.3360@gannet.stats.ox.ac.uk>

I think ?.row_names_info is what you are looking for (although data frames 
have row.names and matrices have rownames, pace the subject line).

On Thu, 18 Oct 2007, hadley wickham wrote:

> Is it possible to get at the underlying representation of row names -
> ie. what you see in the output from dput:
>
>> df <- data.frame(1:4)
>> dput(df)
> structure(list(X1.4 = 1:4), .Names = "X1.4", row.names = c(NA,
> -4L), class = "data.frame")
>
> I would like to be able to tell if a data frame has the default row
> names, or if they have been changed by the user.  I need this for
> rggobi because in GGobi row names should be unique across all data
> frames, unless explicitly set by the user.
>
> Thanks,
>
> Hadley
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From robert.castelo at upf.edu  Thu Oct 18 19:41:39 2007
From: robert.castelo at upf.edu (Robert Castelo)
Date: Thu, 18 Oct 2007 19:41:39 +0200
Subject: [Rd] append/concatenate an element to a list in C-language
Message-ID: <1192729299.17964.27.camel@llull.imim.es>

dear people,

i need to code a function in C working in R and receives two R SEXP
objects as parameters, where one is a list and another is a vector of
integers:

void f(SEXP list, SEXP vector) {

  ...

  return list;
}


and it should return the given list with the integer vector concatenated
at the end (as the last element of the list). the list can be really big
so i would not like to create a new list from scratch and copy all the
elements, including the additional one. i'm also interested in knowing
how should i properly handle protections of the SEXP objects when doing
this.

i've been looking at the R source code for everything that has to do
with CAR, CDR, CONS, and even found functions with promising names like
listAppend or GrowList but i have not been able to figure this out nor i
haven't been able to find any reference on how to do this by googling
all around, so any help will be very much appreciated.


thanks a lot!!!

robert.


From osklyar at ebi.ac.uk  Fri Oct 19 00:17:23 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 18 Oct 2007 23:17:23 +0100
Subject: [Rd] append/concatenate an element to a list in C-language
In-Reply-To: <1192729299.17964.27.camel@llull.imim.es>
References: <1192729299.17964.27.camel@llull.imim.es>
Message-ID: <1192745843.5857.53.camel@carbon>

Hi.

I believe it is virtually impossible, maybe even not virtually: if you
manage to do so somehow, please report it as a bug because such things
must be impossible as they break the integrity of R and data.

Forget about changing size in place: it is C and 'realloc' would be
about the only way to do it, which would not be smart even if you can
find a pointer to what you want to change. However, consider you want to
copy (after all it is a list, which is an array of pointers and you
might think you only need to copy pointers, which is cheap even for a
huge list). Consider a simple example:
you allocVector(VECSXP,n+1); then either memcpy n elements (if you
manage to get a pointer say with DATAPTR, and R-API is smart not to
allow you to get it that simple) or you simply SET_VECTOR_ELT(new, i,
VECTOR_ELT(old, i)) and then add the last one. You know what would be
wrong about this idea? You cannot be sure that pointers to elements of
the old list are not modified/deleted elsewhere, thus affecting your new
list! Even if you overwrite the list in place, providing such software
to users is error prone as users do not know about your ideas of keeping
everything tidy.

The only right way to replicate (if you want to do it in C) is copy and
copy duplicating each element of the list, i.e.:

SEXP f(SEXP old, SEXP v) {
SEXP new; int i,nprotect=0;
PROTECT(new=allocVector(VECSXP,n+1)); nprotect++;
for(i=0;i<n;i++)
  SET_VECTOR_ELT(new, i, Rf_duplicate(VECTOR_ELT(old, i)));
SET_VECTOR_ELT(new, n, v);
/* set names here if you need */
UNPROTECT(1);
return new;

What you could do, if you really need such functionality. Provide R with
external pointer to a data structure that you maintain in your C (I
would suggest C++) code and use C++ STL for dynamic updates (either
lists or vectors, whatever suits better). But the overhead of writing
the interface will take more than copying a list of any size!

Finally: void f(SEXP list, SEXP vector); is a malformed definition which
will lead to Segmentation Fault. Please read "Writing R extensions"
first.

Best,
Oleg

-  
Dr Oleg Sklyar * EMBL-EBI, Cambridge CB10 1SD, UK * +441223494466


On Thu, 2007-10-18 at 19:41 +0200, Robert Castelo wrote:
> dear people,
> 
> i need to code a function in C working in R and receives two R SEXP
> objects as parameters, where one is a list and another is a vector of
> integers:
> 
> void f(SEXP list, SEXP vector) {
> 
>   ...
> 
>   return list;
> }
> 
> 
> and it should return the given list with the integer vector concatenated
> at the end (as the last element of the list). the list can be really big
> so i would not like to create a new list from scratch and copy all the
> elements, including the additional one. i'm also interested in knowing
> how should i properly handle protections of the SEXP objects when doing
> this.
> 
> i've been looking at the R source code for everything that has to do
> with CAR, CDR, CONS, and even found functions with promising names like
> listAppend or GrowList but i have not been able to figure this out nor i
> haven't been able to find any reference on how to do this by googling
> all around, so any help will be very much appreciated.
> 
> 
> thanks a lot!!!
> 
> robert.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tplate at acm.org  Fri Oct 19 04:07:05 2007
From: tplate at acm.org (Tony Plate)
Date: Thu, 18 Oct 2007 20:07:05 -0600
Subject: [Rd] append/concatenate an element to a list in C-language
In-Reply-To: <1192729299.17964.27.camel@llull.imim.es>
References: <1192729299.17964.27.camel@llull.imim.es>
Message-ID: <47181149.60309@acm.org>

This sounds like it could be dangerous, but if you're sure it's 
necessary and you know what you are doing, you could investigate whether 
the "pairlist" internal structure might enable you to do this (AFAIK, a 
"pairlist" is a traditional linked-list data structure).  In general, 
pairlists seem to be used very little, and I've never seen their use 
encouraged, so I would be very cautious.  You can read more about 
"pairlists" under ?pairlist, in the R-internals manual, and in the 
source starting at src/include/Rinternals.h (look for "LISTSXP").

-- Tony Plate

Robert Castelo wrote:
> dear people,
>
> i need to code a function in C working in R and receives two R SEXP
> objects as parameters, where one is a list and another is a vector of
> integers:
>
> void f(SEXP list, SEXP vector) {
>
>   ...
>
>   return list;
> }
>
>
> and it should return the given list with the integer vector concatenated
> at the end (as the last element of the list). the list can be really big
> so i would not like to create a new list from scratch and copy all the
> elements, including the additional one. i'm also interested in knowing
> how should i properly handle protections of the SEXP objects when doing
> this.
>
> i've been looking at the R source code for everything that has to do
> with CAR, CDR, CONS, and even found functions with promising names like
> listAppend or GrowList but i have not been able to figure this out nor i
> haven't been able to find any reference on how to do this by googling
> all around, so any help will be very much appreciated.
>
>
> thanks a lot!!!
>
> robert.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From bolker at ufl.edu  Thu Oct 18 13:45:10 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 18 Oct 2007 04:45:10 -0700 (PDT)
Subject: [Rd] Sweave/ESS-like tools for HTML
In-Reply-To: <loom.20071016T162929-540@post.gmane.org>
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
	<4714E156.9040500@mail.nih.gov>
	<loom.20071016T162929-540@post.gmane.org>
Message-ID: <13272187.post@talk.nabble.com>




Tom Short-2 wrote:
> 
> See this link for more on creating/converting to HTML:
> 
> http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/SweaveConvert
> 
> For using ESS with mixed HTML/R files, see this:
> 
> https://stat.ethz.ch/pipermail/ess-help/2006-December/003826.html
> 
> - Tom
> 
> Tom Short
> Electric Power Research Institute
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

 A couple of other bits of information:
(1) I started writing a LaTeX-to-Rwiki translator,
anyone who wants to try it should contact me.
(It sounds, though, as though the wiki that Doug
Bates is going to use accepts HTML rather than
the Rwiki format?

(2) I have trouble getting through to Ian Hutchinson's
web site to get tth.  If you do get there, check out
ttm (TeX-to-MathML) as well.

  The SGML approach does seem like the wave of
the future, but in the meanwhile TeX/tth works well
for me.

  Ben Bolker
-- 
View this message in context: http://www.nabble.com/Sweave-ESS-like-tools-for-HTML-tf4635106.html#a13272187
Sent from the R devel mailing list archive at Nabble.com.


From mdalphin at amgen.com  Thu Oct 18 23:01:40 2007
From: mdalphin at amgen.com (Dalphin, Mark)
Date: Thu, 18 Oct 2007 14:01:40 -0700
Subject: [Rd] Regression test failed when building on an "older" Linux
	cluster
Message-ID: <567ACB2E39C83543B746F1AD7F5E5E040C939D68@wa-mb2-sea.amgen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071018/a11f817c/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Oct 19 09:46:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Oct 2007 08:46:39 +0100 (BST)
Subject: [Rd] append/concatenate an element to a list in C-language
In-Reply-To: <1192729299.17964.27.camel@llull.imim.es>
References: <1192729299.17964.27.camel@llull.imim.es>
Message-ID: <Pine.LNX.4.64.0710181848020.3360@gannet.stats.ox.ac.uk>

On Thu, 18 Oct 2007, Robert Castelo wrote:

> dear people,
>
> i need to code a function in C working in R and receives two R SEXP
> objects as parameters, where one is a list and another is a vector of
> integers:
>
> void f(SEXP list, SEXP vector) {
>
>  ...
>
>  return list;
> }

You are returning an result in a function that returns void: the compiler 
will complain at you.

> and it should return the given list with the integer vector concatenated
> at the end (as the last element of the list). the list can be really big
> so i would not like to create a new list from scratch and copy all the
> elements, including the additional one. i'm also interested in knowing
> how should i properly handle protections of the SEXP objects when doing
> this.

If you study the R Internals manual you will see that there is no space on 
the original VECSXP for another element, so you do *need* to create a new 
VECSXP.  Note that creating a new list does not mean necessarily copying 
the elements, but you do need to think about the NAMED bits.

If you are doing this repeatedly you could think about exploiting the 
TRUELENGTH field to create a list with spare space that you could exploit 
in future calls.

It is often possible to avoid copying, but considerable care is needed to 
ensure that you do not end up with an object that does not effectively 
share elements with another user-visible one.

> i've been looking at the R source code for everything that has to do
> with CAR, CDR, CONS, and even found functions with promising names like
> listAppend or GrowList but i have not been able to figure this out nor i
> haven't been able to find any reference on how to do this by googling
> all around, so any help will be very much appreciated.

Those are for pairlists, not (vector) lists.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Oct 19 09:50:49 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri, 19 Oct 2007 09:50:49 +0200 (CEST)
Subject: [Rd] documentation bug for isoreg example (PR#10352)
Message-ID: <20071019075049.7E3AD2834618@mail.pubhealth.ku.dk>

>>>>> "BT" == Benjamin Tyner <btyner at gmail.com>
>>>>>     on Thu, 18 Oct 2007 15:15:06 +0200 (CEST) writes:

    BT> Full_Name: Benjamin Tyner
    BT> Version: 2.6.0 (43063)
    BT> OS: WinXP
    BT> Submission from: (NULL) (171.161.224.10)


    BT> At the end of the examples for isoreg, there is

    BT> cat("R^2 =", formatC(sum(residuals(ir4)^2) / (9*var(y4)), digits=2),"\n")

    BT> I think this should be

    BT> cat("R^2 =", formatC(1 - sum(residuals(ir4)^2) / (9*var(y4)), digits=2),"\n"

I think so too, and I'm infinitely embarrassed because I think I
had put that example there {maybe cut & paste from somewhere,
but still...}

Martin Maechler, ETH Zurich.


From robert.castelo at upf.edu  Fri Oct 19 11:08:47 2007
From: robert.castelo at upf.edu (Robert Castelo)
Date: Fri, 19 Oct 2007 11:08:47 +0200
Subject: [Rd] append/concatenate an element to a list in C-language
In-Reply-To: <Pine.LNX.4.64.0710181848020.3360@gannet.stats.ox.ac.uk>
References: <1192729299.17964.27.camel@llull.imim.es> 
	<Pine.LNX.4.64.0710181848020.3360@gannet.stats.ox.ac.uk>
Message-ID: <1192784927.8051.33.camel@llull.imim.es>

hi,

thanks to all the replies, i think the discussion can be followed
throughout this message.

> You are returning an result in a function that returns void: the compiler 
> will complain at you.

apologies, indeed it should have been

SEXP f(SEXP list, SEXP element);

> If you study the R Internals manual you will see that there is no space on 
> the original VECSXP for another element, so you do *need* to create a new 
> VECSXP.  Note that creating a new list does not mean necessarily copying 
> the elements, but you do need to think about the NAMED bits.

in this list i need not names associated to each element, i guess that
should release me from thinking about the NAMED bits you refer to (?).

what you say about "creating a new list does not mean necessarily
copying the elements" interests me. i'd like to avoid going through the
old list and copy the elements. i'd like to add one at the end as fast
as possible.

if, in a situation like:

l <- list(1,2)
l <- c(l,3)

R, internally, concatenates 3 to the list l avoiding to copy all 3
elements again, then i'd just like to know how R does that to do it
myself as well.

> If you are doing this repeatedly you could think about exploiting the 
> TRUELENGTH field to create a list with spare space that you could exploit 
> in future calls.

i cannot anticipate what will be the maximum length of my list. i'm
working with clique lists in undirected graphs and given a list of
cliques and an edge to be removed this function will modify the clique
list according to this edge removal. since i'd like R to handle graphs
as big as possible with the available hardware, this list can be
arbitrarily large and that's why i want to avoid going through the
elements of the list.

> It is often possible to avoid copying, but considerable care is needed to 
> ensure that you do not end up with an object that does not effectively 
> share elements with another user-visible one.

so, would it be possible to create a new VECSXP vector with one extra
element, then somehow "memcpy" the old vector of SEXP pointers into this
new one, and add a brand new element with SET_VECTOR_ELT?

> > i've been looking at the R source code for everything that has to do
> > with CAR, CDR, CONS, and even found functions with promising names like
> > listAppend or GrowList but i have not been able to figure this out nor i
> > haven't been able to find any reference on how to do this by googling
> > all around, so any help will be very much appreciated.
> 
> Those are for pairlists, not (vector) lists.

ok.


thanks!
robert.


From P.Dalgaard at biostat.ku.dk  Fri Oct 19 12:19:20 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 19 Oct 2007 12:19:20 +0200
Subject: [Rd] append/concatenate an element to a list in C-language
In-Reply-To: <1192784927.8051.33.camel@llull.imim.es>
References: <1192729299.17964.27.camel@llull.imim.es>
	<Pine.LNX.4.64.0710181848020.3360@gannet.stats.ox.ac.uk>
	<1192784927.8051.33.camel@llull.imim.es>
Message-ID: <471884A8.7070105@biostat.ku.dk>

Robert Castelo wrote:
> hi,
>
> thanks to all the replies, i think the discussion can be followed
> throughout this message.
>
>   
>> You are returning an result in a function that returns void: the compiler 
>> will complain at you.
>>     
>
> apologies, indeed it should have been
>
> SEXP f(SEXP list, SEXP element);
>
>   
>> If you study the R Internals manual you will see that there is no space on 
>> the original VECSXP for another element, so you do *need* to create a new 
>> VECSXP.  Note that creating a new list does not mean necessarily copying 
>> the elements, but you do need to think about the NAMED bits.
>>     
>
> in this list i need not names associated to each element, i guess that
> should release me from thinking about the NAMED bits you refer to (?).
>
>   
No! This is very important: The same R object may be known under
multiple names and this is what NAMED records (well, it tries).  When
this is the case, it is not safe to modify it destructively.  E.g.

x <- rnorm(100)
y <- x     # at this point y and x refer to the SAME object
y[1] <- 0  # NOW we have to duplicate y or the subassignment will change x

Notice that this appears in disguised forms:

g <- function(y) {
   y[1] <- 0  # MAY require duplication
   mean(y)
}
x <- rnorm(100)
g(x) # duplication needed
g(rnorm(100)) # duplication not needed

Don't try anything involving destructive modification of objects before
you have understood this!

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From bates at stat.wisc.edu  Fri Oct 19 16:35:14 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 19 Oct 2007 09:35:14 -0500
Subject: [Rd] Sweave/ESS-like tools for HTML
In-Reply-To: <13272187.post@talk.nabble.com>
References: <40e66e0b0710160847r427a12a1xfded42b812fe2006@mail.gmail.com>
	<4714E156.9040500@mail.nih.gov>
	<loom.20071016T162929-540@post.gmane.org>
	<13272187.post@talk.nabble.com>
Message-ID: <40e66e0b0710190735n7552c3e4m917e12e6fed46ada@mail.gmail.com>

On 10/18/07, Ben Bolker <bolker at ufl.edu> wrote:

> Tom Short-2 wrote:

> > See this link for more on creating/converting to HTML:

> > http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/SweaveConvert

> > For using ESS with mixed HTML/R files, see this:

> > https://stat.ethz.ch/pipermail/ess-help/2006-December/003826.html

>  A couple of other bits of information:
> (1) I started writing a LaTeX-to-Rwiki translator,
> anyone who wants to try it should contact me.
> (It sounds, though, as though the wiki that Doug
> Bates is going to use accepts HTML rather than
> the Rwiki format?

> (2) I have trouble getting through to Ian Hutchinson's
> web site to get tth.  If you do get there, check out
> ttm (TeX-to-MathML) as well.

I found the links that Tom sent to be very helpful and did install
both the tth and  tex4ht Debian packages.

Both approaches are interesting but there are some inherent
limitations to HTML and the course management system that are
difficult to overcome.  I haven't found a way to include an expression
like $\bar{x}$ without resorting to images and the course management
system goes to great lengths to hide the file hierarchy so including
an image in part of the wiki is difficult.

Perhaps it is better if I create stand-alone PDF documents but then
linking becomes difficult.


>   The SGML approach does seem like the wave of
> the future, but in the meanwhile TeX/tth works well
> for me.
>
>   Ben Bolker
> --
> View this message in context: http://www.nabble.com/Sweave-ESS-like-tools-for-HTML-tf4635106.html#a13272187
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rohan7799 at gmail.com  Fri Oct 19 09:36:57 2007
From: rohan7799 at gmail.com (Rohan7)
Date: Fri, 19 Oct 2007 00:36:57 -0700 (PDT)
Subject: [Rd]  How to create Web service in R?
Message-ID: <13289735.post@talk.nabble.com>


Hello all,

   Is it possible to create web service in R? 
   Any links or book i can refer!
   
  My second question is i'm trying to call a web service using RCurl
package. The pdf from google doesnt have entire code in it.[ R as web client
- RCurl package]. It's not written how to send parameter for a function or
i'm missing something. I want to pass parameter to a function of a
webservice.

   Please help me for the same.
   
Regards,
Rohan7

 
-- 
View this message in context: http://www.nabble.com/How-to-create-Web-service-in-R--tf4651580.html#a13289735
Sent from the R devel mailing list archive at Nabble.com.


From deiwiks at icr.gess.ethz.ch  Fri Oct 19 18:05:09 2007
From: deiwiks at icr.gess.ethz.ch (deiwiks at icr.gess.ethz.ch)
Date: Fri, 19 Oct 2007 18:05:09 +0200 (CEST)
Subject: [Rd] Name length of function argument? (PR#10357)
Message-ID: <20071019160510.0B602283416A@mail.pubhealth.ku.dk>

Hi,
I've just been programming a function to calculate the likelihood in a 
probit model.
The function looks like this

likelihood <- function(Y,X,p) {
Z <- p[1] +p[2]*X
P <- Y*pnorm(Z) + (1-Y)*(1-pnorm(Z))
-prod(P)
}

out <- optim(likelihood,p=c(0,0),Y=wells$switch,X=wells$dist, hessian=TRUE)

X and Y are vectors containing column data.
This works fine, however, if I rename p to pp or anything that is longer 
than one character, I get the following error message:

Error in optim(f, pp = c(0, 0), Y=wells$switch, X=wells$dist, 
hessian=TRUE) :
  cannot coerce type closure to double vector

This seems like a bug... Or can you help me find the mistake I made?

Thanks,
 Christa

-- 
Christa Deiwiks
International Conflict Research
ETH Zurich

Seilergraben 49 (SEI E.3)
8092 Zurich
Ph: +41 44 632 67 60

http://www.icr.ethz.ch/people/deiwiks


From mtmorgan at fhcrc.org  Fri Oct 19 20:47:25 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 19 Oct 2007 11:47:25 -0700
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
Message-ID: <6phprzbq6v6.fsf@gopher4.fhcrc.org>

R developers,

On windows, it seems like R_HOME/etc/Makeconf has

SHELL = /bin/sh

instead of the location of Rtools' sh. I think this is because
R_HOME/src/gnuwin32/fixed/etc/Makeconf needs to define SHELL as just
sh (since Rtools/bin  has to be on the PATH).

This is of consequence with R CMD config.

R version 2.7.0 Under development (unstable) (2007-10-19 r43218)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

Martin
-- 
Martin Morgan
Bioconductor / Computational Biology


From hpages at fhcrc.org  Fri Oct 19 21:12:07 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 19 Oct 2007 12:12:07 -0700
Subject: [Rd] install.packages() and configure.args
Message-ID: <47190187.50507@fhcrc.org>

Hi,

In the case where install.packages("packageA") also needs to install
required package "packageB", then what is passed thru the 'configure.args'
argument seems to be lost when it's the turn of packageA to be installed
(the last package to get installed).

This is not easy to reproduce but let's say you have the graphviz libraries
installed on your system, but you don't have the graph package installed yet.
Then this

  install.packages("Rgraphviz",
                   rep="http://bioconductor.org/packages/2.1/bioc",
                   configure.args="--with-graphviz=/some/non/standard/place")

will fail because --with-graphviz=/some/non/standard/place doesn't seem to be
passed to Rgraphviz's configure script. But if you already have the graph package,
then it will work.

Cheers,
H.


From richard.pearson at postgrad.manchester.ac.uk  Sat Oct 20 11:21:39 2007
From: richard.pearson at postgrad.manchester.ac.uk (Richard Pearson)
Date: Sat, 20 Oct 2007 10:21:39 +0100
Subject: [Rd] How to create Web service in R?
In-Reply-To: <13289735.post@talk.nabble.com>
References: <13289735.post@talk.nabble.com>
Message-ID: <4719C8A3.70600@postgrad.manchester.ac.uk>

Rohan

There's a bioconductor package called RWebServices - does this help?

http://bioconductor.org/packages/2.1/bioc/html/RWebServices.html

Regards

Richard.


Rohan7 wrote:
> Hello all,
>
>    Is it possible to create web service in R? 
>    Any links or book i can refer!
>    
>   My second question is i'm trying to call a web service using RCurl
> package. The pdf from google doesnt have entire code in it.[ R as web client
> - RCurl package]. It's not written how to send parameter for a function or
> i'm missing something. I want to pass parameter to a function of a
> webservice.
>
>    Please help me for the same.
>    
> Regards,
> Rohan7
>
>  
>


From murdoch at stats.uwo.ca  Sat Oct 20 12:02:55 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 20 Oct 2007 06:02:55 -0400
Subject: [Rd] Name length of function argument? (PR#10357)
In-Reply-To: <20071019160510.0B602283416A@mail.pubhealth.ku.dk>
References: <20071019160510.0B602283416A@mail.pubhealth.ku.dk>
Message-ID: <4719D24F.3020800@stats.uwo.ca>

deiwiks at icr.gess.ethz.ch wrote:
> Hi,
> I've just been programming a function to calculate the likelihood in a 
> probit model.
> The function looks like this
>
> likelihood <- function(Y,X,p) {
> Z <- p[1] +p[2]*X
> P <- Y*pnorm(Z) + (1-Y)*(1-pnorm(Z))
> -prod(P)
> }
>
> out <- optim(likelihood,p=c(0,0),Y=wells$switch,X=wells$dist, hessian=TRUE)
>
> X and Y are vectors containing column data.
> This works fine, however, if I rename p to pp or anything that is longer 
> than one character, I get the following error message:
>
> Error in optim(f, pp = c(0, 0), Y=wells$switch, X=wells$dist, 
> hessian=TRUE) :
>   cannot coerce type closure to double vector
>
> This seems like a bug... Or can you help me find the mistake I made?
>   
See ?optim.  The first argument should be par, not fn.

Duncan Murdoch


From murdoch at stats.uwo.ca  Sat Oct 20 12:37:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 20 Oct 2007 06:37:12 -0400
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
In-Reply-To: <6phprzbq6v6.fsf@gopher4.fhcrc.org>
References: <6phprzbq6v6.fsf@gopher4.fhcrc.org>
Message-ID: <4719DA58.1020500@stats.uwo.ca>

Martin Morgan wrote:
> R developers,
>
> On windows, it seems like R_HOME/etc/Makeconf has
>
> SHELL = /bin/sh
>
> instead of the location of Rtools' sh. I think this is because
> R_HOME/src/gnuwin32/fixed/etc/Makeconf needs to define SHELL as just
> sh (since Rtools/bin  has to be on the PATH).
>
> This is of consequence with R CMD config.
>   
Could you show what goes wrong?  I don't don't see any problems.

Duncan Murdoch
> R version 2.7.0 Under development (unstable) (2007-10-19 r43218)
> Copyright (C) 2007 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> Martin
>


From ripley at stats.ox.ac.uk  Sat Oct 20 12:44:52 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Oct 2007 11:44:52 +0100 (BST)
Subject: [Rd] Name length of function argument? (PR#10357)
In-Reply-To: <20071019160510.0B602283416A@mail.pubhealth.ku.dk>
References: <20071019160510.0B602283416A@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710201129580.523@gannet.stats.ox.ac.uk>

Please study the help page before posting.  In the example code given 'p' 
is partially matching the second argument 'par' of optim(), so the unnamed 
first argument matches to the second argument 'fn'.

In the second case, 'f' matches 'par' and 'pp' matches '...', and 'f' is 
of 'type closure'.

On Fri, 19 Oct 2007, deiwiks at icr.gess.ethz.ch wrote:

> Hi,
> I've just been programming a function to calculate the likelihood in a
> probit model.
> The function looks like this
>
> likelihood <- function(Y,X,p) {
> Z <- p[1] +p[2]*X
> P <- Y*pnorm(Z) + (1-Y)*(1-pnorm(Z))
> -prod(P)
> }
>
> out <- optim(likelihood,p=c(0,0),Y=wells$switch,X=wells$dist, hessian=TRUE)
>
> X and Y are vectors containing column data.
> This works fine, however, if I rename p to pp or anything that is longer
> than one character, I get the following error message:
>
> Error in optim(f, pp = c(0, 0), Y=wells$switch, X=wells$dist,
> hessian=TRUE) :
>  cannot coerce type closure to double vector
>
> This seems like a bug... Or can you help me find the mistake I made?

Yes, it is a bug in your code.  From the R FAQ:

    If a command you are familiar with causes an R error message in a case
    where its usual definition ought to be reasonable, it is probably a
    bug.   If a command does the wrong thing, that is a bug.  But be sure
    you know for certain in what it ought to have done.  If you aren't
    familiar with the command, or don't know for certain how the command is
    supposed to work, then it might actually be working right.

Asking a question on R-bugs is an indication that you do not 'know for 
certain'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Sat Oct 20 14:49:53 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 20 Oct 2007 05:49:53 -0700
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
In-Reply-To: <4719DA58.1020500@stats.uwo.ca> (Duncan Murdoch's message of
	"Sat, 20 Oct 2007 06:37:12 -0400")
References: <6phprzbq6v6.fsf@gopher4.fhcrc.org> <4719DA58.1020500@stats.uwo.ca>
Message-ID: <6phmyueeyry.fsf@gopher4.fhcrc.org>

D:\mtmorgan\src\R-devel>bin\R CMD config CC
make: /bin/sh: Command not found
make: ** [print] Error 127
make: /bin/sh: Command not found
make: ** [print] Error 127

D:\mtmorgan\src\R-devel>bin\R CMD config CC

This is on a system where cygwin and Rtools (from your installer) are
under c:/usr (rather than the more usual location for cygwin directly
under c:/). The system has seen many cooks over the years, and there
could well be a misconfiguration somewhere else. PATH (e.g., to make,
sh, ar) seem to point to the right location, versions seem to be
correct, and changing SHELL to sh remedies the situation.

Thanks,

Martin

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> Martin Morgan wrote:
>> R developers,
>>
>> On windows, it seems like R_HOME/etc/Makeconf has
>>
>> SHELL = /bin/sh
>>
>> instead of the location of Rtools' sh. I think this is because
>> R_HOME/src/gnuwin32/fixed/etc/Makeconf needs to define SHELL as just
>> sh (since Rtools/bin  has to be on the PATH).
>>
>> This is of consequence with R CMD config.
>>
> Could you show what goes wrong?  I don't don't see any problems.
>
> Duncan Murdoch
>> R version 2.7.0 Under development (unstable) (2007-10-19 r43218)
>> Copyright (C) 2007 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>>
>> Martin
>>
>


From ripley at stats.ox.ac.uk  Sat Oct 20 15:31:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Oct 2007 14:31:17 +0100 (BST)
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
In-Reply-To: <6phmyueeyry.fsf@gopher4.fhcrc.org>
References: <6phprzbq6v6.fsf@gopher4.fhcrc.org> <4719DA58.1020500@stats.uwo.ca>
	<6phmyueeyry.fsf@gopher4.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0710201428110.2507@gannet.stats.ox.ac.uk>

On Sat, 20 Oct 2007, Martin Morgan wrote:

> D:\mtmorgan\src\R-devel>bin\R CMD config CC
> make: /bin/sh: Command not found
> make: ** [print] Error 127
> make: /bin/sh: Command not found
> make: ** [print] Error 127
>
> D:\mtmorgan\src\R-devel>bin\R CMD config CC
>
> This is on a system where cygwin and Rtools (from your installer) are
> under c:/usr (rather than the more usual location for cygwin directly
> under c:/). The system has seen many cooks over the years, and there
> could well be a misconfiguration somewhere else. PATH (e.g., to make,
> sh, ar) seem to point to the right location, versions seem to be
> correct, and changing SHELL to sh remedies the situation.

I am pretty sure that has the wrong make.exe.  Works for me without having 
/bin/sh on the system, and I worked hard to build a make.exe that was not 
looking for /bin/sh.

Does it work for you if SHELL is commented out in etc/Makeconf?

>
> Thanks,
>
> Martin
>
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>
>> Martin Morgan wrote:
>>> R developers,
>>>
>>> On windows, it seems like R_HOME/etc/Makeconf has
>>>
>>> SHELL = /bin/sh
>>>
>>> instead of the location of Rtools' sh. I think this is because
>>> R_HOME/src/gnuwin32/fixed/etc/Makeconf needs to define SHELL as just
>>> sh (since Rtools/bin  has to be on the PATH).
>>>
>>> This is of consequence with R CMD config.
>>>
>> Could you show what goes wrong?  I don't don't see any problems.
>>
>> Duncan Murdoch
>>> R version 2.7.0 Under development (unstable) (2007-10-19 r43218)
>>> Copyright (C) 2007 The R Foundation for Statistical Computing
>>> ISBN 3-900051-07-0
>>>
>>> Martin
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sat Oct 20 15:39:41 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 20 Oct 2007 09:39:41 -0400
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
In-Reply-To: <6phmyueeyry.fsf@gopher4.fhcrc.org>
References: <6phprzbq6v6.fsf@gopher4.fhcrc.org>	<4719DA58.1020500@stats.uwo.ca>
	<6phmyueeyry.fsf@gopher4.fhcrc.org>
Message-ID: <471A051D.8080903@stats.uwo.ca>

Martin Morgan wrote:
> D:\mtmorgan\src\R-devel>bin\R CMD config CC
> make: /bin/sh: Command not found
> make: ** [print] Error 127
> make: /bin/sh: Command not found
> make: ** [print] Error 127
>
> D:\mtmorgan\src\R-devel>bin\R CMD config CC
>
> This is on a system where cygwin and Rtools (from your installer) are
> under c:/usr (rather than the more usual location for cygwin directly
> under c:/). The system has seen many cooks over the years, and there
> could well be a misconfiguration somewhere else. PATH (e.g., to make,
> sh, ar) seem to point to the right location, versions seem to be
> correct, and changing SHELL to sh remedies the situation.
>   
I suspect you have path problems.  Cygwin should generally follow all of 
the R tools in the path, because we have some modified versions of 
Cygwin utilities.  For example, when running in CMD.EXE, this path works 
for me:

C:\Documents and Settings\murdoch>path
PATH=c:\Rtools\bin;c:\Rtools\perl\bin;c:\Rtools\MinGW\bin;C:\texmf\miktex\bin;f:\texmf\miktex\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\
Wbem;f:\Program Files\Subversion\bin:f:\R\svn\R-devel\R\bin

In a Cygwin bash shell I use this path:

$ printenv PATH
$ printenv PATH
/cygdrive/c/Rtools/bin:/cygdrive/c/Rtools/perl/bin:/cygdrive/c/Rtools/minGW/bin:/usr/local/bin:/usr/bin:/bin:/usr/X11R6/bin:/cygdrive/c/util/misc:/cygdrive/c/windows/system32:/cygdrive/f/R/svn/r-devel/R/bin:/cygdrive/f/texmf/miktex/bin:/cygdrive/c/progra~1/htmlhe~1:/cygdrive/f/program 
files/subversion/bin


From mtmorgan at fhcrc.org  Sat Oct 20 16:20:19 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 20 Oct 2007 07:20:19 -0700
Subject: [Rd] Windows fixed/etc/Makeconf SHELL incorrect?
In-Reply-To: <471A051D.8080903@stats.uwo.ca> (Duncan Murdoch's message of
	"Sat, 20 Oct 2007 09:39:41 -0400")
References: <6phprzbq6v6.fsf@gopher4.fhcrc.org>
	<4719DA58.1020500@stats.uwo.ca> <6phmyueeyry.fsf@gopher4.fhcrc.org>
	<471A051D.8080903@stats.uwo.ca>
Message-ID: <6phbqatrhp8.fsf@gopher4.fhcrc.org>

Thanks to both for your time.

I edited bin/config:124 to display info before one of the problematic
make commands, adding

echo "MAKE --version: `${MAKE} --version`"
echo "which MAKE: `which ${MAKE}`"
echo "R_HOME: ${R_HOME}"
echo "R_SHARE_DIR: ${R_SHARE_DIR}"
echo "query: $query"

here is the output:

D:\mtmorgan\src\R-devel\bin>R CMD config CC
MAKE --version: GNU Make version 3.79.1, by Richard Stallman and Roland McGrath.

Built for i686-pc-cygwin
Copyright (C) 1988, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2000
        Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.

Report bugs to <bug-make at gnu.org>.

which MAKE: /cygdrive/c/usr/Rtools/bin/make
R_HOME: D:/mtmorgan/src/R-devel
R_SHARE_DIR: D:/mtmorgan/src/R-devel/share
query: make -s -f D:/mtmorgan/src/R-devel/etc/Makeconf -f D:/mtmorgan/src
/R-devel/share/make/config.mk print R_HOME=D:/mtmorgan/src/R-devel
make: /bin/sh: Command not found

which looks correct?

The PATH is hopeless, but starts

PATH: /cygdrive/d/mtmorgan/src/R-devel/bin:/cygdrive/c/GTK/bin:/cygdrive/c/progr
am files/imagemagick-6.3.2-q16:.:/cygdrive/c/usr/Rtools/bin:/cygdrive/c/usr/Rtoo
ls/MinGW/bin:/cygdrive/c/usr/Perl/bin/:

A much abbreviated PATH does not have any better success

D:\mtmorgan\src\R-devel\bin>set PATH=c:\usr\Rtools\bin;C:\usr\Rtools\MingGW\bin

D:\mtmorgan\src\R-devel\bin>R CMD config CC
MAKE --version: GNU Make version 3.79.1, by Richard Stallman and Roland McGrath.

Built for i686-pc-cygwin
Copyright (C) 1988, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2000
        Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.

Report bugs to <bug-make at gnu.org>.

which: not found
which MAKE:
R_HOME: D:/mtmorgan/src/R-devel
R_SHARE_DIR: D:/mtmorgan/src/R-devel/share
query: make -s -f D:/mtmorgan/src/R-devel/etc/Makeconf -f D:/mtmorgan/src
/R-devel/share/make/config.mk print R_HOME=D:/mtmorgan/src/R-devel
make: /bin/sh: Command not found
make: *** [print] Error 127

I guess the take-home message is that the problem is likely a system
configuration issue on our end, so I'll try to clean things up. Thanks
for your time.

Martin

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> Martin Morgan wrote:
>> D:\mtmorgan\src\R-devel>bin\R CMD config CC
>> make: /bin/sh: Command not found
>> make: ** [print] Error 127
>> make: /bin/sh: Command not found
>> make: ** [print] Error 127
>>
>> D:\mtmorgan\src\R-devel>bin\R CMD config CC
>>
>> This is on a system where cygwin and Rtools (from your installer) are
>> under c:/usr (rather than the more usual location for cygwin directly
>> under c:/). The system has seen many cooks over the years, and there
>> could well be a misconfiguration somewhere else. PATH (e.g., to make,
>> sh, ar) seem to point to the right location, versions seem to be
>> correct, and changing SHELL to sh remedies the situation.
>>
> I suspect you have path problems.  Cygwin should generally follow all
> of the R tools in the path, because we have some modified versions of
> Cygwin utilities.  For example, when running in CMD.EXE, this path
> works for me:
>
> C:\Documents and Settings\murdoch>path
> PATH=c:\Rtools\bin;c:\Rtools\perl\bin;c:\Rtools\MinGW\bin;C:\texmf\miktex\bin;f:\texmf\miktex\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\
> Wbem;f:\Program Files\Subversion\bin:f:\R\svn\R-devel\R\bin
>
> In a Cygwin bash shell I use this path:
>
> $ printenv PATH
> $ printenv PATH
> /cygdrive/c/Rtools/bin:/cygdrive/c/Rtools/perl/bin:/cygdrive/c/Rtools/minGW/bin:/usr/local/bin:/usr/bin:/bin:/usr/X11R6/bin:/cygdrive/c/util/misc:/cygdrive/c/windows/system32:/cygdrive/f/R/svn/r-devel/R/bin:/cygdrive/f/texmf/miktex/bin:/cygdrive/c/progra~1/htmlhe~1:/cygdrive/f/program
> files/subversion/bin


From duncan at wald.ucdavis.edu  Sat Oct 20 22:41:43 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sun, 21 Oct 2007 09:41:43 +1300
Subject: [Rd] How to create Web service in R?
In-Reply-To: <13289735.post@talk.nabble.com>
References: <13289735.post@talk.nabble.com>
Message-ID: <471A6807.5000605@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



Rohan7 wrote:
> Hello all,
> 
>    Is it possible to create web service in R? 
>    Any links or book i can refer!
>    
>   My second question is i'm trying to call a web service using RCurl
> package. The pdf from google doesnt have entire code in it.[ R as web client
> - RCurl package]. It's not written how to send parameter for a function or
> i'm missing something. I want to pass parameter to a function of a
> webservice.

By Web Service do you mean specifically SOAP? There are other Web
Services and each one will involve a different way of invoking
a Web Service method. However, SOAP is the most common and
while RCurl is used to communicate the request and result,
there are many more steps in generating the contents of the
request.  See the SSOAP package from www.omegahat.org for
a mechanism for making SOAP requests from R. It even has
basic support for reading WSDL files and generating R
functions that make the Web Service method "appear" as a local
R function.

  D.

> 
>    Please help me for the same.
>    
> Regards,
> Rohan7
> 
>  
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.7 (Darwin)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHGmgH9p/Jzwa2QP4RAn/VAJ4+dn3y8JRlW4o+iAa6IhYHdLT44QCfbREl
Ysn8Z5zgWHns89jpaf7uuc8=
=53Ns
-----END PGP SIGNATURE-----


From duncan at wald.ucdavis.edu  Sat Oct 20 23:17:20 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sun, 21 Oct 2007 10:17:20 +1300
Subject: [Rd] install.packages() and configure.args
In-Reply-To: <47190187.50507@fhcrc.org>
References: <47190187.50507@fhcrc.org>
Message-ID: <471A7060.2000709@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi Herve

 The "best" way to specify configure.args when there are multiple
packages (either directly or via dependencies) is to use names on
the character vector, i.e.

   install.packages("Rgraphviz",
                    rep="http://bioconductor.org/packages/2.1/bioc",

configure.args=c(Rgraphviz="--with-graphviz=/some/non/standard/place"))


This allows one to specify command line arguments for many packages
simultaneously and unambiguously.

install.packages() only uses configure.args when there are no names
if there is only one package being installed.  It could be made
smarter to apply this to the first of the pkgs only, or
to identify the packages as direct and dependent.  But it is not
obvious it is worth the effort as using names on configure.args
provides a complete solution and is more informative.

Thanks for pointing this out.

 D.

Herve Pages wrote:
> Hi,
> 
> In the case where install.packages("packageA") also needs to install
> required package "packageB", then what is passed thru the 'configure.args'
> argument seems to be lost when it's the turn of packageA to be installed
> (the last package to get installed).
> 
> This is not easy to reproduce but let's say you have the graphviz libraries
> installed on your system, but you don't have the graph package installed yet.
> Then this
> 
>   install.packages("Rgraphviz",
>                    rep="http://bioconductor.org/packages/2.1/bioc",
>                    configure.args="--with-graphviz=/some/non/standard/place")
> 
> will fail because --with-graphviz=/some/non/standard/place doesn't seem to be
> passed to Rgraphviz's configure script. But if you already have the graph package,
> then it will work.
> 
> Cheers,
> H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.7 (Darwin)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHGnBg9p/Jzwa2QP4RAp0NAJ9Qe/thxdrX8CpFVcRP2UoHk1txFACeL9uM
twmID5hsclilHhIfPsuFt7A=
=vCz1
-----END PGP SIGNATURE-----


From savicky at cs.cas.cz  Mon Oct 22 14:50:26 2007
From: savicky at cs.cas.cz (savicky at cs.cas.cz)
Date: Mon, 22 Oct 2007 14:50:26 +0200 (CEST)
Subject: [Rd] bug in detection of zero state for Mersenne Twister (PR#10362)
Message-ID: <20071022125026.D577D283416B@mail.pubhealth.ku.dk>

Full_Name: Petr Savicky
Version: all versions starting from 1.7.0
OS: observed on Linux, but is platform independent
Submission from: (NULL) (62.24.91.47)


The function runif(n) contains a protection against the zero state of
Mersenne Twister stored in .Random.seed. If the state is zero, it is
regenerated using current time, since a zero state is a fixed point of the
recurrence and, hence, produces a constant sequence.

The detection of zero state contains a bug, due to which a zero state may
not be recognized. This happens if there are nonzero bits in .Random.seed[3]
at positions, which are not used by Mersenne Twister (only the most
significant bit of .Random.seed[3] is used and the remaining 31 are
discarded).

An example of such a situation is
  RNGkind("default")
  .Random.seed[3] <- as.integer(1)
  .Random.seed[4:626] <- as.integer(0)
  x <- runif(10000)
  all(x==x[1]) # TRUE
  all(.Random.seed[3:626]==0) # TRUE
The output shows that the initial state was indeed effectively zero,
since the final state is all zeros.

The following patch to FixupSeeds corrects the detection of zero state:

--- R-devel_2007-10-21-orig/src/main/RNG.c  2007-09-02 07:49:35.000000000 +0200
+++ R-devel_2007-10-21-FixupSeeds/src/main/RNG.c    2007-10-21
21:47:02.455450224 +0200
@@ -181,7 +181,9 @@
     /* No action unless user has corrupted .Random.seed */
    if(I1 <= 0) I1 = 624;
    /* check for all zeroes */
-   for (j = 1; j <= 624; j++)
+   notallzero = ((RNG_Table[RNG_kind].i_seed[1] & 0x80000000) != 0);
+   if(!notallzero)
+   for (j = 2; j <= 624; j++)
        if(RNG_Table[RNG_kind].i_seed[j] != 0) {
        notallzero = 1;
        break;


From jenny at stat.ubc.ca  Mon Oct 22 20:00:15 2007
From: jenny at stat.ubc.ca (jenny at stat.ubc.ca)
Date: Mon, 22 Oct 2007 20:00:15 +0200 (CEST)
Subject: [Rd] predict.gnls seems to break when 'newdata' specified (PR#10364)
Message-ID: <20071022180015.F36F4283416C@mail.pubhealth.ku.dk>

Full_Name: Jennifer Bryan
Version: 2.5.1
OS: Mac OS 10.4.10
Submission from: (NULL) (142.103.104.81)


The predict method for gnls seems to break when I provide 'newdata'.  It seems
to be the code that checks that the factors in newdata have the same contrasts
as the data provided for the original fit.  I illustrate below with an example
from Pinheiro and Bates.  I can't even use predict on the original data.frame
when I provide the original data as newdata.

## copied verbatim from Pinheiro & Bates 8.3.3
fm1Dial.gnls <-
  gnls(rate ~ SSasympOff(pressure, Asym, lrc, c0),
       data = Dialyzer, params = list(Asym + lrc ~ QB, c0 ~ 1),
       start = c(53.6, 8.6, 0.51, -0.26, 0.225))
## differs from P & B only due to different default contrasts
Dialyzer$QBcontr <- ifelse(Dialyzer$QB == 200, 0, 1)
fm1Dial.nls <-
  nls(rate ~ SSasympOff(pressure, Asym.Int + Asym.QB * QBcontr,
                        lrc.Int + lrc.QB * QBcontr, c0), data =
      Dialyzer, start = c(Asym.Int = 53.6, Asym.QB = 17,
                  lrc.Int = 0.51, lrc.QB = -0.5, c0 = 0.225))
## I get the same results from the above fits, they differ from those
## in the book due to different contrasts
predict(fm1Dial.gnls)                     # works
predict(fm1Dial.gnls, newdata = Dialyzer) # fails, factor levels complaint
predict(fm1Dial.nls, newdata = Dialyzer)  # works


From rgentlem at fhcrc.org  Mon Oct 22 21:04:35 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Mon, 22 Oct 2007 12:04:35 -0700
Subject: [Rd] install.packages() and configure.args
In-Reply-To: <471A7060.2000709@wald.ucdavis.edu>
References: <47190187.50507@fhcrc.org> <471A7060.2000709@wald.ucdavis.edu>
Message-ID: <471CF443.3000807@fhcrc.org>

since, in Herve's example only one package was named, it would be nice 
to either, make sure configure args are associated with it, or to force 
only named configure.args parameters, and possibly check the names?


Duncan Temple Lang wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Hi Herve
> 
>  The "best" way to specify configure.args when there are multiple
> packages (either directly or via dependencies) is to use names on
> the character vector, i.e.
> 
>    install.packages("Rgraphviz",
>                     rep="http://bioconductor.org/packages/2.1/bioc",
> 
> configure.args=c(Rgraphviz="--with-graphviz=/some/non/standard/place"))
> 
> 
> This allows one to specify command line arguments for many packages
> simultaneously and unambiguously.
> 
> install.packages() only uses configure.args when there are no names
> if there is only one package being installed.  It could be made
> smarter to apply this to the first of the pkgs only, or
> to identify the packages as direct and dependent.  But it is not
> obvious it is worth the effort as using names on configure.args
> provides a complete solution and is more informative.
> 
> Thanks for pointing this out.
> 
>  D.
> 
> Herve Pages wrote:
>> Hi,
>>
>> In the case where install.packages("packageA") also needs to install
>> required package "packageB", then what is passed thru the 'configure.args'
>> argument seems to be lost when it's the turn of packageA to be installed
>> (the last package to get installed).
>>
>> This is not easy to reproduce but let's say you have the graphviz libraries
>> installed on your system, but you don't have the graph package installed yet.
>> Then this
>>
>>   install.packages("Rgraphviz",
>>                    rep="http://bioconductor.org/packages/2.1/bioc",
>>                    configure.args="--with-graphviz=/some/non/standard/place")
>>
>> will fail because --with-graphviz=/some/non/standard/place doesn't seem to be
>> passed to Rgraphviz's configure script. But if you already have the graph package,
>> then it will work.
>>
>> Cheers,
>> H.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.7 (Darwin)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFHGnBg9p/Jzwa2QP4RAp0NAJ9Qe/thxdrX8CpFVcRP2UoHk1txFACeL9uM
> twmID5hsclilHhIfPsuFt7A=
> =vCz1
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From tlumley at u.washington.edu  Mon Oct 22 23:54:39 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Oct 2007 14:54:39 -0700 (PDT)
Subject: [Rd] RSQLite indexing
Message-ID: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>


I am trying to use RSQLite for storing data and  I need to create indexes on 
two variables in the table. It appears from searching the web that the CREATE 
INDEX operation in SQLite is relatively slow for large files, and this has been 
my experience as well.

The two index variables are crossed. One has about 350,000 levels [yes, it's 
genetic association data]. The other will have about 4000 levels eventually, 
but is up to about 100 now.   When the data were entered they were already ordered by this second index variable.

Creating the index took about an hour on the 100-level, presorted variable and about 12 hours on the 350,000-level unsorted variable.  I'm looking for advice on how to reduce this. Specifically
1/ would it be faster if the variable with more levels was the presorted one?
2/ would it be faster or slower if the index were created before adding all the data?
3/ are there any options that can be set to speed up the indexing?

The SQLite database will not be the primary archive for the data, so optimizations that are risky in the case of power loss or hardware failure are still acceptable.  Since Bioconductor seems to use SQLite a lot I'm hoping there is some simple solution.


     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From h.wickham at gmail.com  Tue Oct 23 00:37:57 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 22 Oct 2007 17:37:57 -0500
Subject: [Rd] RSQLite indexing
In-Reply-To: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
Message-ID: <f8e6ff050710221537k50de547ci9b11d91fe090941e@mail.gmail.com>

On 10/22/07, Thomas Lumley <tlumley at u.washington.edu> wrote:
>
> I am trying to use RSQLite for storing data and  I need to create indexes on
> two variables in the table. It appears from searching the web that the CREATE
> INDEX operation in SQLite is relatively slow for large files, and this has been
> my experience as well.
>
> The two index variables are crossed. One has about 350,000 levels [yes, it's
> genetic association data]. The other will have about 4000 levels eventually,
> but is up to about 100 now.   When the data were entered they were already ordered by this second index variable.
>
> Creating the index took about an hour on the 100-level, presorted variable and about 12 hours on the 350,000-level unsorted variable.  I'm looking for advice on how to reduce this. Specifically

How big is your dataset?  SQLite can be slow, but I didn't think it
was that slow.

> 1/ would it be faster if the variable with more levels was the presorted one?

I didn't think this would matter (and can imagine situations where it
would be worse).  Is there a particular reason you think this might
help?

> 2/ would it be faster or slower if the index were created before adding all the data?

It's generally much faster to create the index after loading all the data.

> 3/ are there any options that can be set to speed up the indexing?

Have you tried 'vacuum'ing your database prior to indexing?

Will you be indexing on both columns simultaneously?  If so, you might
try creating a single index.


Hadley

-- 
http://had.co.nz/


From tlumley at u.washington.edu  Tue Oct 23 00:57:14 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 22 Oct 2007 15:57:14 -0700 (PDT)
Subject: [Rd] RSQLite indexing
In-Reply-To: <f8e6ff050710221537k50de547ci9b11d91fe090941e@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0710221557140.27183@hymn12.u.washington.edu>

On Mon, 22 Oct 2007, hadley wickham wrote:

> On 10/22/07, Thomas Lumley <tlumley at u.washington.edu> wrote:
>>
>> I am trying to use RSQLite for storing data and  I need to create indexes on
>> two variables in the table. It appears from searching the web that the CREATE
>> INDEX operation in SQLite is relatively slow for large files, and this has been
>> my experience as well.
>>
>> The two index variables are crossed. One has about 350,000 levels [yes, it's
>> genetic association data]. The other will have about 4000 levels eventually,
>> but is up to about 100 now.   When the data were entered they were already ordered by this second index variable.
>>
>> Creating the index took about an hour on the 100-level, presorted variable and about 12 hours on the 350,000-level unsorted variable.  I'm looking for advice on how to reduce this. Specifically
>
> How big is your dataset?  SQLite can be slow, but I didn't think it
> was that slow.

350000x100 entries on 12 variables

>> 1/ would it be faster if the variable with more levels was the presorted one?
>
> I didn't think this would matter (and can imagine situations where it
> would be worse).  Is there a particular reason you think this might
> help?

Mainly that it would be nice if it did.  Preordering might help more for the larger number of levels because the smaller number of levels gives more valid places to insert a record into the index.  I could just experiment, but since it takes so long I thought it was worth asking if anyone had actual knowledge.


>> 2/ would it be faster or slower if the index were created before adding all the data?
>
> It's generally much faster to create the index after loading all the data.

Yes. The reason I thought it might not be in this case is that the indexing operation uses remarkably little CPU (and doesn't use anywhere near the disk bandwidth) so I hoped there might be some saving in doing both at once.



>> 3/ are there any options that can be set to speed up the indexing?
>
> Have you tried 'vacuum'ing your database prior to indexing?

Yes. But it has never had anything deleted from it, so it's not surprising that it didn't help.

> Will you be indexing on both columns simultaneously?  If so, you might
> try creating a single index.

No, indexing will be on one or the other column, not on both at once.

      -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From jeff.horner at vanderbilt.edu  Tue Oct 23 01:03:54 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Mon, 22 Oct 2007 18:03:54 -0500
Subject: [Rd] RSQLite indexing
In-Reply-To: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
Message-ID: <471D2C5A.5000608@vanderbilt.edu>

Thomas Lumley wrote on 10/22/2007 04:54 PM:
> I am trying to use RSQLite for storing data and  I need to create indexes on 
> two variables in the table. It appears from searching the web that the CREATE 
> INDEX operation in SQLite is relatively slow for large files, and this has been 
> my experience as well.
> 
> The two index variables are crossed. One has about 350,000 levels [yes, it's 
> genetic association data]. The other will have about 4000 levels eventually, 
> but is up to about 100 now.   When the data were entered they were already ordered by this second index variable.
> 
> Creating the index took about an hour on the 100-level, presorted variable and about 12 hours on the 350,000-level unsorted variable.  I'm looking for advice on how to reduce this. Specifically
> 1/ would it be faster if the variable with more levels was the presorted one?
> 2/ would it be faster or slower if the index were created before adding all the data?
> 3/ are there any options that can be set to speed up the indexing?
> 
> The SQLite database will not be the primary archive for the data, so optimizations that are risky in the case of power loss or hardware failure are still acceptable.  Since Bioconductor seems to use SQLite a lot I'm hoping there is some simple solution.

Well then, while some may think it overkill to run a mysql database 
server for 1 to a handfull of clients, the benefits of using typed 
columns (rather than strings, which might have something to do with slow 
indexing) plus all the other goodies could save you the extra day or two 
speeding up SQLite indexing.

A project here at vanderbilt stores (mostly read-only) data in mysql 5.0 
tables in myisam format. The tables have 3 to 5 million records each. 
Index creation speed for a varchar(9) column with 1,559,100 levels takes 
roughly 1.5 minutes, for example.

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From mgd at santafe.edu  Tue Oct 23 01:05:10 2007
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Mon, 22 Oct 2007 17:05:10 -0600
Subject: [Rd] RSQLite indexing
In-Reply-To: <Pine.LNX.4.43.0710221557140.27183@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0710221557140.27183@hymn12.u.washington.edu>
Message-ID: <471D2CA6.2030908@santafe.edu>

Thomas Lumley wrote:
>> How big is your dataset?  SQLite can be slow, but I didn't think it
>> was that slow.
>>     
>
> 350000x100 entries on 12 variables
>   
I had a similar problem a while back and took the opportunity to test 
various RDBMS.   I found that a product called TimesTen from Oracle was 
the fastest, followed by Microsoft SQL server, followed by Oracle 10 
Enterprise with bitmap indicies, followed by Postgres.  RSQLite had 
relatively poor performance and I had trouble persuading MySQL to 
optimize the query at all.   I did not try any column oriented database 
systems like Sybase IQ or Vertica, which should do better for the 
read-oriented workload.


From khansen at stat.Berkeley.EDU  Tue Oct 23 03:07:18 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 22 Oct 2007 18:07:18 -0700
Subject: [Rd] RSQLite indexing
In-Reply-To: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
Message-ID: <E366C868-54C6-4591-90B9-D034393F298A@stat.berkeley.edu>

On Oct 22, 2007, at 2:54 PM, Thomas Lumley wrote:

>
> I am trying to use RSQLite for storing data and  I need to create  
> indexes on
> two variables in the table. It appears from searching the web that  
> the CREATE
> INDEX operation in SQLite is relatively slow for large files, and  
> this has been
> my experience as well.
>
> The two index variables are crossed. One has about 350,000 levels  
> [yes, it's
> genetic association data]. The other will have about 4000 levels  
> eventually,
> but is up to about 100 now.   When the data were entered they were  
> already ordered by this second index variable.
>
> Creating the index took about an hour on the 100-level, presorted  
> variable and about 12 hours on the 350,000-level unsorted  
> variable.  I'm looking for advice on how to reduce this. Specifically
> 1/ would it be faster if the variable with more levels was the  
> presorted one?
> 2/ would it be faster or slower if the index were created before  
> adding all the data?
> 3/ are there any options that can be set to speed up the indexing?
>
> The SQLite database will not be the primary archive for the data,  
> so optimizations that are risky in the case of power loss or  
> hardware failure are still acceptable.  Since Bioconductor seems to  
> use SQLite a lot I'm hoping there is some simple solution.

I have not used RSQLite, but have some experience doing this thing  
for big sqlite databases using the command line client. Every  
database in sqlite has a number of parameters associated with it. You  
want to make sure that cache_size is at _most_ 2000 (yes, I know this  
is totally counterintuitive as it tells sqlite to use as little  
memory as possible). You also tell it to be non-synchronous. In  
sqlite the commands are
sqlite> pragma default_cache_size = 2000
sqlite> pragma_synchronous = off
You can test the setting of these parameters by just doing a
sqlite> pragma default_cache_size
As far as I remember, cache size can only be set when you create the  
database. I have no idea how RSQlite handles it.

When I asked about this problem on the sqlite mailing list, the  
sqlite-creator said that this was a "locality of reference problem"  
and that it was being "worked on". And that I could search the  
archives for more info (which did not help me back then).

I don't know whether or not sorting helps.

Another thing to do is to check in what amount sqlite sits idle while  
doing I/O. It is probably impossible to avoid some idleness with such  
a thing, but it should of course be kept to a minimum.

It is true that some of the other databases are probably much faster  
at creating indices. But in the post-index analysis, sqlite is a  
really fast database, probably amongst the fastest there is. It does  
not do a good job a converting your queries into smart queries, but  
if you are doing something simple, it is blazingly fast with the  
right user options.

Kasper


From seth at userprimary.net  Tue Oct 23 06:33:07 2007
From: seth at userprimary.net (Seth Falcon)
Date: Mon, 22 Oct 2007 21:33:07 -0700
Subject: [Rd] RSQLite indexing
In-Reply-To: <471D2C5A.5000608@vanderbilt.edu> (Jeffrey Horner's message of
	"Mon\, 22 Oct 2007 18\:03\:54 -0500")
References: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
	<471D2C5A.5000608@vanderbilt.edu>
Message-ID: <m2lk9uo3gc.fsf@userprimary.net>

Jeffrey Horner <jeff.horner at vanderbilt.edu> writes:

> Thomas Lumley wrote on 10/22/2007 04:54 PM:
>> I am trying to use RSQLite for storing data and  I need to create indexes on 
>> two variables in the table. It appears from searching the web that the CREATE 
>> INDEX operation in SQLite is relatively slow for large files, and this has been 
>> my experience as well.

What is your schema?  In particular, are things that are integers or
floats being stored that way in SQLite?

I believe the annotation data packages via AnnotationDbi are using
cache_size=64000 and synchronous=0 and that this was determined by a
handful of experiments on typical annotation dbs.

Columns with few levels may not benefit from an index.  See this
thread:

http://thread.gmane.org/gmane.comp.db.sqlite.general/23683/focus=23693

But your column with many levels should suffer this problem :-)

+ seth

-- 
Seth Falcon | seth at userprimary.net | blog: http://userprimary.net/user/


From lbraglia at gmail.com  Tue Oct 23 21:05:11 2007
From: lbraglia at gmail.com (lbraglia at gmail.com)
Date: Tue, 23 Oct 2007 21:05:11 +0200 (CEST)
Subject: [Rd] typo in italian translation (PR#10367)
Message-ID: <20071023190511.2C70D282EFF1@mail.pubhealth.ku.dk>

Hi

read.table in a table with numb of read elements not
multiple of columns


Avviso in scan(file, what, nmax, sep, dec, quote, skip, nlines,
na.strings,  : 
	 il numero di elemtni letti non ?? un multiplo del numero di
colonne


--> change "elemtni" to "elementi"


Regards

	Luca


From khansen at stat.Berkeley.EDU  Tue Oct 23 22:09:03 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 23 Oct 2007 13:09:03 -0700
Subject: [Rd] RSQLite indexing
In-Reply-To: <E366C868-54C6-4591-90B9-D034393F298A@stat.berkeley.edu>
References: <Pine.LNX.4.43.0710221454390.27183@hymn12.u.washington.edu>
	<E366C868-54C6-4591-90B9-D034393F298A@stat.berkeley.edu>
Message-ID: <208C0998-F4B0-446B-979A-492ABC9B6B08@stat.berkeley.edu>


On Oct 22, 2007, at 6:07 PM, Kasper Daniel Hansen wrote:

> On Oct 22, 2007, at 2:54 PM, Thomas Lumley wrote:
>
>>
>> I am trying to use RSQLite for storing data and  I need to create
>> indexes on
>> two variables in the table. It appears from searching the web that
>> the CREATE
>> INDEX operation in SQLite is relatively slow for large files, and
>> this has been
>> my experience as well.
>>
>> The two index variables are crossed. One has about 350,000 levels
>> [yes, it's
>> genetic association data]. The other will have about 4000 levels
>> eventually,
>> but is up to about 100 now.   When the data were entered they were
>> already ordered by this second index variable.
>>
>> Creating the index took about an hour on the 100-level, presorted
>> variable and about 12 hours on the 350,000-level unsorted
>> variable.  I'm looking for advice on how to reduce this. Specifically
>> 1/ would it be faster if the variable with more levels was the
>> presorted one?
>> 2/ would it be faster or slower if the index were created before
>> adding all the data?
>> 3/ are there any options that can be set to speed up the indexing?
>>
>> The SQLite database will not be the primary archive for the data,
>> so optimizations that are risky in the case of power loss or
>> hardware failure are still acceptable.  Since Bioconductor seems to
>> use SQLite a lot I'm hoping there is some simple solution.
>
> I have not used RSQLite, but have some experience doing this thing
> for big sqlite databases using the command line client. Every
> database in sqlite has a number of parameters associated with it. You
> want to make sure that cache_size is at _most_ 2000 (yes, I know this
> is totally counterintuitive as it tells sqlite to use as little
> memory as possible). You also tell it to be non-synchronous. In
> sqlite the commands are
> sqlite> pragma default_cache_size = 2000
> sqlite> pragma_synchronous = off
> You can test the setting of these parameters by just doing a
> sqlite> pragma default_cache_size
> As far as I remember, cache size can only be set when you create the
> database. I have no idea how RSQlite handles it.
>
> When I asked about this problem on the sqlite mailing list, the
> sqlite-creator said that this was a "locality of reference problem"
> and that it was being "worked on". And that I could search the
> archives for more info (which did not help me back then).
>
> I don't know whether or not sorting helps.
>
> Another thing to do is to check in what amount sqlite sits idle while
> doing I/O. It is probably impossible to avoid some idleness with such
> a thing, but it should of course be kept to a minimum.
>
> It is true that some of the other databases are probably much faster
> at creating indices. But in the post-index analysis, sqlite is a
> really fast database, probably amongst the fastest there is. It does
> not do a good job a converting your queries into smart queries, but
> if you are doing something simple, it is blazingly fast with the
> right user options.

Let me just emphasize (based on Seth's email) that the  
default_cache_size settings only is for an indexing command. For  
actual operations on the database using the index, like a select  
statement, you would want to increase the cache_size to something  
bigger.

My comments are based on experience with a database with 315 *10^6  
rows, and the importance of this is quite dependent on database size.

Kasper


From dvorak at cs.cas.cz  Tue Oct 23 23:56:29 2007
From: dvorak at cs.cas.cz (Jakub Dvorak)
Date: Tue, 23 Oct 2007 23:56:29 +0200 (CEST)
Subject: [Rd] API for optimization with Simulated annealing
Message-ID: <64011.84.42.183.124.1193176589.squirrel@uivti.cs.cas.cz>

Dear list,

I was trying to use the R API for optimization method "Simulated annealing"
    void samin(int n, double *x, double *Fmin, optimfn fn, int maxit,
               int tmax, double temp, int trace, void *ex);
but I encountered the following problem:

The implementation of the function samin (as seen in src/main/optim.c)
passes its void * argument "ex" into the function genptry (implemented
in the same source file) and the function genptry expects that the void *
argument "ex" points to a struct opt_struct, from which genptry takes a
function generating a new candidate point (if it is present). The struct
opt_struct seems to be intended only for internal use in implementation
of optim called from R. Using opt_struct in my C code calling samin
encounters the following problems:
1. The definition of opt_struct is present inside the file optim.c, thus
my source has no access to it.
2. The function genptry uses opt_struct attribute R_gcall of type SEXP which
doesn't allow to specify a function writen in C for generating a new
candidate point. This should be either an R function or NULL, meaning
that the default generating function is used.

Hence, a C user has to copy the definition of opt_struct to his
code and fill NULL to its R_gcall component.

This may cause problems, when opt_struct changes in future. Also,
it does not allow to use a user defined C function for generating
a new candidate point.

In order to solve the problems above, I would like to suggest that
samin does not pass the argument "ex" to genptry, which is fixed.
Instead, the function generating a new candidate point should be given
as an new pointer-to-function argument, say new_candidate, of function
samin. NULL value would mean "use the default". When called from R,
a (pointer to) function similar to genptry would be given as new_candidate
argument. Then, samin would call the function *new_candidate and pass
"ex" to it. Since "new_candidate" and "ex" are created in the same
environment, they may share the definition of an appropriate opt_struct.

Please, find a suggestion for a corresponding patch below.

The code modified according to my patch satifies the following general
requirement: The only thing that an implementation of the function
samin as an API should do with its argument void * ex is to pass it to
functions given by other arguments of samin. Then the user has full control
on usage of argument "ex" and is completely free to carry any data in it
because only he/she is responsible on right interpretation and use of the data.

Any change of API makes current users of the API unhappy. Still, I would
like to suggest the patch below for consideration, since, in my opinion, the
current samin API is not used frequently due to the problems described above.

        Jakub Dvorak

And here is the patch:

--- R-devel_2007-10-22/src/include/R_ext/Applic.h	2007-08-31 17:53:41.000000000 +0200
+++ R-devel_my_source/src/include/R_ext/Applic.h	2007-10-23 23:02:43.397529120 +0200
@@ -65,6 +65,7 @@
 /* main/optim.c */
 typedef double optimfn(int, double *, void *);
 typedef void optimgr(int, double *, double *, void *);
+typedef void sagenptry(int, double *, double *, double, void *);

 void vmmin(int n, double *b, double *Fmin,
 	   optimfn fn, optimgr gr, int maxit, int trace,
@@ -82,8 +83,8 @@
 	    double *Fmin, optimfn fn, optimgr gr, int *fail, void *ex,
 	    double factr, double pgtol, int *fncount, int *grcount,
 	    int maxit, char *msg, int trace, int nREPORT);
-void samin(int n, double *pb, double *yb, optimfn fn, int maxit,
-	   int tmax, double ti, int trace, void *ex);
+void samin(int n, double *pb, double *yb, optimfn fn, sagenptry *new_candidate,
+       int maxit, int tmax, double ti, int trace, void *ex);



--- R-devel_2007-10-22/src/main/optim.c	2007-08-15 17:50:12.000000000 +0200
+++ R-devel_my_source/src/main/optim.c	2007-10-23 23:02:43.397529120 +0200
@@ -171,6 +171,13 @@
     }
 }

+static void genptry_default(int n, double *p, double *ptry, double scale, void *ex)
+{  /* default Gaussian Markov kernel */
+    int i;
+    for (i = 0; i < n; i++)
+        ptry[i] = p[i] + scale * norm_rand();  /* new candidate point */
+}
+
 static void genptry(int n, double *p, double *ptry, double scale, void *ex)
 {
     SEXP s, x;
@@ -196,10 +203,8 @@
 	    ptry[i] = REAL(s)[i] / (OS->parscale[i]);
 	UNPROTECT(2);
     }
-    else {  /* default Gaussian Markov kernel */
-        for (i = 0; i < n; i++)
-            ptry[i] = p[i] + scale * norm_rand();  /* new candidate point */
-    }
+    else
+        genptry_default(n, p, ptry, scale, ex);
 }

 /* par fn gr method options */
@@ -275,7 +280,7 @@
         } else {
 	    PROTECT(OS->R_gcall = R_NilValue); /* for balance */
         }
-        samin (npar, dpar, &val, fminfn, maxit, tmax, temp, trace, (void *)OS);
+        samin (npar, dpar, &val, fminfn, &genptry, maxit, tmax, temp, trace, (void *)OS);
         for (i = 0; i < npar; i++)
             REAL(par)[i] = dpar[i] * (OS->parscale[i]);
         fncount = npar > 0 ? maxit : 1;
@@ -1084,8 +1089,8 @@
 #define E1 1.7182818  /* exp(1.0)-1.0 */
 #define STEPS 100

-void samin(int n, double *pb, double *yb, optimfn fminfn, int maxit,
-	   int tmax, double ti, int trace, void *ex)
+void samin(int n, double *pb, double *yb, optimfn fminfn, sagenptry *new_candidate,
+       int maxit, int tmax, double ti, int trace, void *ex)

 /* Given a starting point pb[0..n-1], simulated annealing minimization
    is performed on the function fminfn. The starting temperature
@@ -1121,9 +1126,11 @@
     while (its < maxit) {  /* cool down system */
 	t = ti/log((double)its + E1);  /* temperature annealing schedule */
 	k = 1;
+    if (new_candidate == NULL)
+        new_candidate = &genptry_default;
 	while ((k <= tmax) && (its < maxit))  /* iterate at constant temperature */
 	{
-            genptry(n, p, ptry, scale * t, ex);  /* generate new candidate point */
+        new_candidate(n, p, ptry, scale * t, ex);  /* generate new candidate point */
 	    ytry = fminfn (n, ptry, ex);
 	    if (!R_FINITE(ytry)) ytry = big;
 	    dy = ytry - y;


From markus.breitenbach at gmail.com  Tue Oct 23 18:25:53 2007
From: markus.breitenbach at gmail.com (markus.breitenbach at gmail.com)
Date: Tue, 23 Oct 2007 18:25:53 +0200 (CEST)
Subject: [Rd] R crashes while printing variable read from read.delim()
	(PR#10366)
Message-ID: <20071023162553.754B7282EFF1@mail.pubhealth.ku.dk>

Full_Name: Markus Breitenbach
Version: 2.5.1
OS: Windows
Submission from: (NULL) (70.58.24.243)


> cdcr <- read.delim("cdcr_flat_survival.dat")
> dim(cdcr)
[1] 7162  387
> cdcr
# results in stack overflow

# bug reproduced in 2.4.1/linux and 2.5.1/windows...


From tlumley at u.washington.edu  Wed Oct 24 01:09:23 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 23 Oct 2007 16:09:23 -0700 (PDT)
Subject: [Rd] RSQLite indexing: summary
Message-ID: <Pine.LNX.4.43.0710231609230.4220@hymn14.u.washington.edu>


I asked about slow indexing in RSQLite for a genetic database.  Seth Falcon's suggestion of making sure that the identifiers were stored as integer rather than string made a big difference.  SNPs come from the factory as "rs100092" and stripping the "rs" off the front is easy.

Other advice about larger or smaller SQLite cache size didn't seem to have much impact in my setting, and I didn't try the advice about getting a different database.

Despite it's many other virtues, SQLite is still slow at indexing.

Thanks to all.

     -thomas=

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ripley at stats.ox.ac.uk  Wed Oct 24 09:37:00 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Oct 2007 08:37:00 +0100 (BST)
Subject: [Rd] Regression test failed when building on an "older" Linux
 cluster
In-Reply-To: <567ACB2E39C83543B746F1AD7F5E5E040C939D68@wa-mb2-sea.amgen.com>
References: <567ACB2E39C83543B746F1AD7F5E5E040C939D68@wa-mb2-sea.amgen.com>
Message-ID: <Pine.LNX.4.64.0710221144570.16638@gannet.stats.ox.ac.uk>

We don't offer the option of building R without documentation, so I 
presume you do not have Perl installed.

Without the examples, there is no check of large swathes of code, so 'make 
check' should not succeed (it would give a false sense of security to pass 
most tests by omitting them).  I've altered it so it will always fail 
without Perl.

I don't buy the disc space argument: you don't have to _install_ the 
documentation on each node, and 'make check' runs on the build and not the 
installed copy.  We don't offer the possibility of installing a cut-down 
version, but surely someone with such a specialized need will be able to 
script that?  And if disc space is tight, why have a copy on each node? 
(We don't on our clusters, where space is not tight: it makes maintenance 
of packages so much easier to have a single shared copy.)

On Thu, 18 Oct 2007, Dalphin, Mark wrote:

> We have an aging Linux Cluster here, running Red Hat 7.3. We have some
> business reasons for not upgrading the OS version. I don't recall the exact
> hardware (dual Pentium III, 4 Gbyte RAM, 1 GHz clock?), but it was pretty
> good in 2001 or so.
>
> We recently tried to build and install R, ver 2.6.0, for this cluster.
> It built and apparently ran correctly, but it failed "make check".
> Earlier versions of R failed "make check" as well, not always for the same
> reason.
>
> I just located the failure in the tests.
> It is in the file: R-2.6.0/tests/reg-tests-1.R and fails in the code:
>
> ## related checks on eff.aovlist
> example(eff.aovlist) # helmert contrasts
> eff1 <- eff.aovlist(fit)
> fit <- aov(Yield ~ A * B * C + Error(Block), data = aovdat)
> eff2 <- eff.aovlist(fit)
> stopifnot(all.equal(eff1, eff2)) # will have rounding-error differences
> options(contrasts = old)
> ## Were different in earlier versions
>
> The failure occurred in the 'stopifnot()' call, but was preceded by a
> warning about a lack of documentation in "example(eff.aovlist)". I looked at
> "example" and found that it relies on available documentation to work,
> returning this warning when no documentation is found:
>
>    file <- index.search(topic, INDICES, "AnIndex", "R-ex")
>    if (file == "") {
>        warning(gettextf("no help file found for '%s'", topic),
>            domain = NA)
>        return(invisible())
>
> Well, our old Linux cluster doesn't support building R documentation; why
> would it when we are very limited on disk space for each node? No one can
> log in there; it is all run via LSF. The lack of documentation makes
> "example()" fail to return anything and the "reg-tests-1.R" requires that a
> value for 'fit' be returned in the global environment for comparison. In
> short, in the absence of documentation, this regression test must fail. (I
> am assuming that my interpretation of the failure is correct; please feel
> free to let me know that I am mis-interpreting the cause of failure!).
>
> If I comment out the above code, all the other tests run correctly. Of
> course, normally we would build on another, better equipped host, and then
> copy R to each host. That is not possible in this case as the glibc is so
> old that it is not compatible with the calls generated on newer hosts.
>
> I am surprised that this problem with "example()" doesn't cause other
> failures in the "make check". It makes me think that the use of "example()"
> here is unusual (or that I am misinterpreting the failure). If that is the
> case, then I suggest removing the call to "example" and replacing it with
> the code from within that example. I believe that running R on a compute
> cluster without documentation building tools is not an unreasonable use
> case. (If that is so, why haven't others stumbled onto this problem before
> me? I don't know.) Making the regression tests work in the absence of
> documentation, along with the rest of R seems reasonable.
>
> We are now using R on the compute cluster. This email's purpose is to
> suggest that R may at times be built in an environment without documentation
> tools and it would be nice if the regression tests still worked there. I
> hope the developers will consider this use case.
>
> Regards,
> Mark Dalphin
>
> PS Having written this email, I am consumed by guilt; I haven't properly and
> recently checked the "R admin manual" that I should be able to build R
> without documentation. Checking for "essential programs for building and
> running R" doesn't seem to show that building documentation is required. I
> am relieved to report that building documentation, despite being under
> "Essential Programs" section is described in a manner suggesting that
> documentation is optional.
> http://cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-othe
> r-programs-under-Unix
>
> ----------------------
> Mark Dalphin
> Dept Comp Biol, M/S AW2/D3262
> Amgen, Inc.
> 1201 Amgen Court W
> Seattle, WA 98119
> Phone: +1-206-265-7951
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Oct 24 09:52:07 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Oct 2007 09:52:07 +0200
Subject: [Rd] R crashes while printing variable read from read.delim()
 (PR#10366)
In-Reply-To: <20071023162553.754B7282EFF1@mail.pubhealth.ku.dk>
References: <20071023162553.754B7282EFF1@mail.pubhealth.ku.dk>
Message-ID: <471EF9A7.5010101@statistik.uni-dortmund.de>

markus.breitenbach at gmail.com wrote:
> Full_Name: Markus Breitenbach
> Version: 2.5.1
> OS: Windows
> Submission from: (NULL) (70.58.24.243)
> 
> 
>> cdcr <- read.delim("cdcr_flat_survival.dat")
>> dim(cdcr)
> [1] 7162  387
>> cdcr



Please test and report on a recent version of R such as R-2.6.0 (even 
better R-patched or R-devel).

We do not have "cdcr_flat_survival.dat". Hence we cannot reproduce.

Thank you,
Uwe Ligges



> # results in stack overflow
> 
> # bug reproduced in 2.4.1/linux and 2.5.1/windows...
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Wed Oct 24 09:55:07 2007
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Wed, 24 Oct 2007 09:55:07 +0200 (CEST)
Subject: [Rd] R crashes while printing variable read from read.delim()
	(PR#10370)
Message-ID: <20071024075507.E5F34283416D@mail.pubhealth.ku.dk>

markus.breitenbach at gmail.com wrote:
> Full_Name: Markus Breitenbach
> Version: 2.5.1
> OS: Windows
> Submission from: (NULL) (70.58.24.243)
> 
> 
>> cdcr <- read.delim("cdcr_flat_survival.dat")
>> dim(cdcr)
> [1] 7162  387
>> cdcr



Please test and report on a recent version of R such as R-2.6.0 (even 
better R-patched or R-devel).

We do not have "cdcr_flat_survival.dat". Hence we cannot reproduce.

Thank you,
Uwe Ligges



> # results in stack overflow
> 
> # bug reproduced in 2.4.1/linux and 2.5.1/windows...
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at u.washington.edu  Wed Oct 24 17:07:28 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 24 Oct 2007 08:07:28 -0700 (PDT)
Subject: [Rd] typo in italian translation (PR#10367)
In-Reply-To: <20071023190511.2C70D282EFF1@mail.pubhealth.ku.dk>
References: <20071023190511.2C70D282EFF1@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710240802560.16703@homer24.u.washington.edu>


Thanks for reporting this, but please report it to the Italian translation 
team.  R-core doesn't try to manage translation bugs because most of us 
don't know most of the languages.

Contact addressses for the translation teams are listed at
   http://developer.r-project.org/TranslationTeams.html

 	-thomas

On Tue, 23 Oct 2007, lbraglia at gmail.com wrote:

> Hi
>
> read.table in a table with numb of read elements not
> multiple of columns
>
>
> Avviso in scan(file, what, nmax, sep, dec, quote, skip, nlines,
> na.strings,  :
> 	 il numero di elemtni letti non ?? un multiplo del numero di
> colonne
>
>
> --> change "elemtni" to "elementi"
>
>
> Regards
>
> 	Luca
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From lbraglia at gmail.com  Wed Oct 24 17:27:35 2007
From: lbraglia at gmail.com (Luca Braglia)
Date: Wed, 24 Oct 2007 17:27:35 +0200
Subject: [Rd] typo in italian translation (PR#10367)
In-Reply-To: <Pine.LNX.4.64.0710240802560.16703@homer24.u.washington.edu>
References: <20071023190511.2C70D282EFF1@mail.pubhealth.ku.dk>
	<Pine.LNX.4.64.0710240802560.16703@homer24.u.washington.edu>
Message-ID: <20071024152735.GA7696@debian>

On 24/10/07 -  08:07, Thomas Lumley wrote:
>
> Thanks for reporting this, but please report it to the Italian translation 
> team.  R-core doesn't try to manage translation bugs because most of us 
> don't know most of the languages.
>
> Contact addressses for the translation teams are listed at
>   http://developer.r-project.org/TranslationTeams.html


ok, next time I'll send it directly to prof. Stefano Iacus


thanks for the advice


	Luca Braglia


From clyde at stat.duke.edu  Wed Oct 24 18:30:15 2007
From: clyde at stat.duke.edu (clyde at stat.duke.edu)
Date: Wed, 24 Oct 2007 18:30:15 +0200 (CEST)
Subject: [Rd] TukeyHSD (PR#10371)
Message-ID: <20071024163015.BB4092834166@mail.pubhealth.ku.dk>

Full_Name: Merlise  Clyde
Version: 2.6.0
OS: MAC OS X 10.4.1
Submission from: (NULL) (24.199.155.62)


the print method for function TukeyHSD returns "height" .  This occurs with the
example in the documentation:

>   summary(fm1 <- aov(breaks ~ wool + tension, data = warpbreaks))
            Df Sum Sq Mean Sq F value   Pr(>F)   
wool         1  450.7   450.7  3.3393 0.073614 . 
tension      2 2034.3  1017.1  7.5367 0.001378 **
Residuals   50 6747.9   135.0                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
>      TukeyHSD(fm1, "tension", ordered = TRUE)
      height
>      plot(TukeyHSD(fm1, "tension"))
Error in UseMethod("vcov") : no applicable method for "vcov"


From mdalphin at amgen.com  Wed Oct 24 19:42:09 2007
From: mdalphin at amgen.com (Dalphin, Mark)
Date: Wed, 24 Oct 2007 10:42:09 -0700
Subject: [Rd] Regression test failed when building on an "older" Linux
 cluster
In-Reply-To: <Pine.LNX.4.64.0710221144570.16638@gannet.stats.ox.ac.uk>
Message-ID: <B666A61E25AD0241B6F6E17AE3C17B8F0502FF8F0E@uswa-pmsg-mbs01.am.corp.amgen.com>

Thank you, Prof. Ripley.

In fact, I tend to agree somewhat with your arguments; our system administrators don't, however.

We do have Perl, though looking now I see its version is too old, 5.6.1, not the required > 5.8.0.

Your argument that the examples are essential for testing sways me. If that is how these tests are constructed, then we have failed the tests and can't trust the use of R on that old cluster. I intended my question to imply that we had failed on only one call to example(), hence I concluded (without evidence) that the test functions called example() only once where I had noted the failure. I probably should have grepped for "example(" before concluding that.

I'll see if we can install an upgraded Perl on a shared location and build R against that. I that solves the problem, I'll report back.

Thank you for your time.

Regards,
Mark Dalphin

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, October 24, 2007 12:37 AM
To: Dalphin, Mark
Cc: R-Devel at stat.math.ethz.ch
Subject: Re: [Rd] Regression test failed when building on an "older" Linux cluster

We don't offer the option of building R without documentation, so I presume you do not have Perl installed.

Without the examples, there is no check of large swathes of code, so 'make check' should not succeed (it would give a false sense of security to pass most tests by omitting them).  I've altered it so it will always fail without Perl.

I don't buy the disc space argument: you don't have to _install_ the documentation on each node, and 'make check' runs on the build and not the installed copy.  We don't offer the possibility of installing a cut-down version, but surely someone with such a specialized need will be able to script that?  And if disc space is tight, why have a copy on each node?
(We don't on our clusters, where space is not tight: it makes maintenance of packages so much easier to have a single shared copy.)

On Thu, 18 Oct 2007, Dalphin, Mark wrote:

> We have an aging Linux Cluster here, running Red Hat 7.3. We have some
> business reasons for not upgrading the OS version. I don't recall the
> exact hardware (dual Pentium III, 4 Gbyte RAM, 1 GHz clock?), but it
> was pretty good in 2001 or so.
>
> We recently tried to build and install R, ver 2.6.0, for this cluster.
> It built and apparently ran correctly, but it failed "make check".
> Earlier versions of R failed "make check" as well, not always for the
> same reason.
>
> I just located the failure in the tests.
> It is in the file: R-2.6.0/tests/reg-tests-1.R and fails in the code:
>
> ## related checks on eff.aovlist
> example(eff.aovlist) # helmert contrasts
> eff1 <- eff.aovlist(fit)
> fit <- aov(Yield ~ A * B * C + Error(Block), data = aovdat)
> eff2 <- eff.aovlist(fit)
> stopifnot(all.equal(eff1, eff2)) # will have rounding-error
> differences options(contrasts = old) ## Were different in earlier
> versions
>
> The failure occurred in the 'stopifnot()' call, but was preceded by a
> warning about a lack of documentation in "example(eff.aovlist)". I
> looked at "example" and found that it relies on available
> documentation to work, returning this warning when no documentation is found:
>
>    file <- index.search(topic, INDICES, "AnIndex", "R-ex")
>    if (file == "") {
>        warning(gettextf("no help file found for '%s'", topic),
>            domain = NA)
>        return(invisible())
>
> Well, our old Linux cluster doesn't support building R documentation;
> why would it when we are very limited on disk space for each node? No
> one can log in there; it is all run via LSF. The lack of documentation
> makes "example()" fail to return anything and the "reg-tests-1.R"
> requires that a value for 'fit' be returned in the global environment
> for comparison. In short, in the absence of documentation, this
> regression test must fail. (I am assuming that my interpretation of
> the failure is correct; please feel free to let me know that I am mis-interpreting the cause of failure!).
>
> If I comment out the above code, all the other tests run correctly. Of
> course, normally we would build on another, better equipped host, and
> then copy R to each host. That is not possible in this case as the
> glibc is so old that it is not compatible with the calls generated on newer hosts.
>
> I am surprised that this problem with "example()" doesn't cause other
> failures in the "make check". It makes me think that the use of "example()"
> here is unusual (or that I am misinterpreting the failure). If that is
> the case, then I suggest removing the call to "example" and replacing
> it with the code from within that example. I believe that running R on
> a compute cluster without documentation building tools is not an
> unreasonable use case. (If that is so, why haven't others stumbled
> onto this problem before me? I don't know.) Making the regression
> tests work in the absence of documentation, along with the rest of R seems reasonable.
>
> We are now using R on the compute cluster. This email's purpose is to
> suggest that R may at times be built in an environment without
> documentation tools and it would be nice if the regression tests still
> worked there. I hope the developers will consider this use case.
>
> Regards,
> Mark Dalphin
>
> PS Having written this email, I am consumed by guilt; I haven't
> properly and recently checked the "R admin manual" that I should be
> able to build R without documentation. Checking for "essential
> programs for building and running R" doesn't seem to show that
> building documentation is required. I am relieved to report that
> building documentation, despite being under "Essential Programs"
> section is described in a manner suggesting that documentation is optional.
> http://cran.r-project.org/doc/manuals/R-admin.html#Essential-and-usefu
> l-othe
> r-programs-under-Unix
>
> ----------------------
> Mark Dalphin
> Dept Comp Biol, M/S AW2/D3262
> Amgen, Inc.
> 1201 Amgen Court W
> Seattle, WA 98119
> Phone: +1-206-265-7951
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From atp at piskorski.com  Wed Oct 24 21:00:25 2007
From: atp at piskorski.com (atp at piskorski.com)
Date: Wed, 24 Oct 2007 21:00:25 +0200 (CEST)
Subject: [Rd] R trunk (2.7) build fails with -fpic, needs -fPIC (PR#10372)
Message-ID: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>

On Linux x86-64 (Ubuntu 6.06), the latest R sources from the
Subversion trunk fail to build with the following "recompile with
-fPIC" error:

  $ ./configure --with-x=yes --prefix=$inst_dir --enable-R-shlib --with-tcltk=/usr/lib/tcl8.4 --with-tcl-config=/usr/lib/tcl8.4/tclConfig.sh
  $ make

  /usr/bin/ld: ../appl/approx.o: relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
  ../appl/approx.o: could not read symbols: Bad value

This is easy to fix by changing 4 lines in the configure script from
"-fpic" to -fPIC", as shown in the patch below.

I saw this failure on an Intel x86-64 server, running Ubuntu 6.06:

  $ uname -srvm
  Linux 2.6.20.4 #1 SMP PREEMPT Sat Mar 31 07:46:01 EDT 2007 x86_64

  $ cat /etc/lsb-release
  DISTRIB_ID=Ubuntu
  DISTRIB_RELEASE=6.06
  DISTRIB_CODENAME=dapper
  DISTRIB_DESCRIPTION="Ubuntu 6.06.1 LTS"

  $ grep name /proc/cpuinfo
  model name      :                   Intel(R) Xeon(TM) CPU 3.80GHz
  model name      :                   Intel(R) Xeon(TM) CPU 3.80GHz

  $ dpkg -l libc6
  ||/ Name     Version              Description
  +++-========-====================-=================================================
  ii  libc6    2.3.6-0ubuntu20.4    GNU C Library: Shared libraries and Timezone data

  $ apt-cache show libc6 | grep Architecture | uniq
  Architecture: amd64

Here's a patch which fixes the problem:


$ svn diff configure
Index: configure
===================================================================
--- configure	(revision 43265)
+++ configure	(working copy)
@@ -32806,7 +32806,7 @@
       cpicflags="-fPIC"
       ;;
     *)
-      cpicflags="-fpic"
+      cpicflags="-fPIC"
       ;;
   esac
   shlib_ldflags="-shared"
@@ -32817,7 +32817,7 @@
       fpicflags="-fPIC"
       ;;
     *)
-      fpicflags="-fpic"
+      fpicflags="-fPIC"
       ;;
   esac
 fi
@@ -32827,7 +32827,7 @@
       cxxpicflags="-fPIC"
       ;;
     *)
-      cxxpicflags="-fpic"
+      cxxpicflags="-fPIC"
       ;;
   esac
   shlib_cxxldflags="-shared"
@@ -47768,7 +47768,7 @@
       fcpicflags="-fPIC"
       ;;
     *)
-      fcpicflags="-fpic"
+      fcpicflags="-fPIC"
       ;;
   esac
 fi

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From p.dalgaard at biostat.ku.dk  Thu Oct 25 00:19:13 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 25 Oct 2007 00:19:13 +0200
Subject: [Rd] R trunk (2.7) build fails with -fpic,
	needs -fPIC (PR#10372)
In-Reply-To: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>
References: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>
Message-ID: <471FC4E1.6080102@biostat.ku.dk>

atp at piskorski.com wrote:
> On Linux x86-64 (Ubuntu 6.06), the latest R sources from the
> Subversion trunk fail to build with the following "recompile with
> -fPIC" error:
>
>   $ ./configure --with-x=yes --prefix=$inst_dir --enable-R-shlib --with-tcltk=/usr/lib/tcl8.4 --with-tcl-config=/usr/lib/tcl8.4/tclConfig.sh
>   $ make
>
>   /usr/bin/ld: ../appl/approx.o: relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
>   ../appl/approx.o: could not read symbols: Bad value
>
> This is easy to fix by changing 4 lines in the configure script from
> "-fpic" to -fPIC", as shown in the patch below.
>
> I saw this failure on an Intel x86-64 server, running Ubuntu 6.06:
>
>   $ uname -srvm
>   Linux 2.6.20.4 #1 SMP PREEMPT Sat Mar 31 07:46:01 EDT 2007 x86_64
>
>   $ cat /etc/lsb-release
>   DISTRIB_ID=Ubuntu
>   DISTRIB_RELEASE=6.06
>   DISTRIB_CODENAME=dapper
>   DISTRIB_DESCRIPTION="Ubuntu 6.06.1 LTS"
>
>   $ grep name /proc/cpuinfo
>   model name      :                   Intel(R) Xeon(TM) CPU 3.80GHz
>   model name      :                   Intel(R) Xeon(TM) CPU 3.80GHz
>
>   $ dpkg -l libc6
>   ||/ Name     Version              Description
>   +++-========-====================-=================================================
>   ii  libc6    2.3.6-0ubuntu20.4    GNU C Library: Shared libraries and Timezone data
>
>   $ apt-cache show libc6 | grep Architecture | uniq
>   Architecture: amd64
>
> Here's a patch which fixes the problem:
>
>
> $ svn diff configure
> Index: configure
> ===================================================================
> --- configure	(revision 43265)
> +++ configure	(working copy)
> @@ -32806,7 +32806,7 @@
>        cpicflags="-fPIC"
>        ;;
>      *)
> -      cpicflags="-fpic"
> +      cpicflags="-fPIC"
>        ;;
>    esac
>    shlib_ldflags="-shared"
> @@ -32817,7 +32817,7 @@
>        fpicflags="-fPIC"
>        ;;
>      *)
> -      fpicflags="-fpic"
> +      fpicflags="-fPIC"
>        ;;
>    esac
>  fi
> @@ -32827,7 +32827,7 @@
>        cxxpicflags="-fPIC"
>        ;;
>      *)
> -      cxxpicflags="-fpic"
> +      cxxpicflags="-fPIC"
>        ;;
>    esac
>    shlib_cxxldflags="-shared"
> @@ -47768,7 +47768,7 @@
>        fcpicflags="-fPIC"
>        ;;
>      *)
> -      fcpicflags="-fpic"
> +      fcpicflags="-fPIC"
>        ;;
>    esac
>  fi
>
>   
Fedora 7 seems perfectly happy with -fpic, and that patch looks 
unhealthy (for one thing, you shouldn't mess with that script directly, 
but use autoconf and aclocal on oter source files, for another, you are 
prescribing that -fPIC is to be used for all architectures.

Whic compiler/linker is this?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From atp at piskorski.com  Thu Oct 25 01:13:58 2007
From: atp at piskorski.com (Andrew Piskorski)
Date: Wed, 24 Oct 2007 19:13:58 -0400
Subject: [Rd] R trunk (2.7) build fails with -fpic,
	needs -fPIC (PR#10372)
In-Reply-To: <471FC4E1.6080102@biostat.ku.dk>
References: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>
	<471FC4E1.6080102@biostat.ku.dk>
Message-ID: <20071024231358.GA58065@tehun.pair.com>

On Thu, Oct 25, 2007 at 12:19:13AM +0200, Peter Dalgaard wrote:

> Fedora 7 seems perfectly happy with -fpic,

Well, Ubuntu 6.06 x86-64 sure seems to hate it, but all I know about
-fpic vs. -fPIC is what I read here:

  http://gcc.gnu.org/onlinedocs/gcc-4.0.3/gcc/Code-Gen-Options.html#index-fpic-1556
  http://gcc.gnu.org/onlinedocs/gcc-4.2.2/gcc/Code-Gen-Options.html#index-fpic-1667

> Whic compiler/linker is this?

$ gcc --version | grep gcc
gcc (GCC) 4.0.3 (Ubuntu 4.0.3-1ubuntu5)
$ ld --version | grep ld
GNU ld version 2.16.91 20060118 Debian GNU/Linux

$ COLUMNS=140 dpkg -l binutils gcc-4.0
+++-==========-=============================-==============================================
ii  binutils   2.16.1cvs20060117-1ubuntu2.1  The GNU assembler, linker and binary utilities
ii  gcc-4.0    4.0.3-1ubuntu5                The GNU C compiler

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From stefano.iacus at unimi.it  Thu Oct 25 01:49:31 2007
From: stefano.iacus at unimi.it (stefano iacus)
Date: Thu, 25 Oct 2007 01:49:31 +0200
Subject: [Rd] typo in italian translation (PR#10367)
In-Reply-To: <20071024152735.GA7696@debian>
References: <20071023190511.2C70D282EFF1@mail.pubhealth.ku.dk>
	<Pine.LNX.4.64.0710240802560.16703@homer24.u.washington.edu>
	<20071024152735.GA7696@debian>
Message-ID: <016B241B-5699-46D2-B2D0-1AACD1BD2750@unimi.it>

I'll need to update lots of translations. Will do this as well.
thanks
stefano

On 24/ott/07, at 17:27, Luca Braglia wrote:

> On 24/10/07 -  08:07, Thomas Lumley wrote:
>>
>> Thanks for reporting this, but please report it to the Italian  
>> translation
>> team.  R-core doesn't try to manage translation bugs because most  
>> of us
>> don't know most of the languages.
>>
>> Contact addressses for the translation teams are listed at
>>   http://developer.r-project.org/TranslationTeams.html
>
>
> ok, next time I'll send it directly to prof. Stefano Iacus
>
>
> thanks for the advice
>
>
> 	Luca Braglia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From stefano.iacus at unimi.it  Thu Oct 25 01:50:10 2007
From: stefano.iacus at unimi.it (stefano.iacus at unimi.it)
Date: Thu, 25 Oct 2007 01:50:10 +0200 (CEST)
Subject: [Rd] typo in italian translation (PR#10367)
Message-ID: <20071024235010.16A62282EFF1@mail.pubhealth.ku.dk>

I'll need to update lots of translations. Will do this as well.
thanks
stefano

On 24/ott/07, at 17:27, Luca Braglia wrote:

> On 24/10/07 -  08:07, Thomas Lumley wrote:
>>
>> Thanks for reporting this, but please report it to the Italian  
>> translation
>> team.  R-core doesn't try to manage translation bugs because most  
>> of us
>> don't know most of the languages.
>>
>> Contact addressses for the translation teams are listed at
>>   http://developer.r-project.org/TranslationTeams.html
>
>
> ok, next time I'll send it directly to prof. Stefano Iacus
>
>
> thanks for the advice
>
>
> 	Luca Braglia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Thu Oct 25 08:47:53 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 25 Oct 2007 08:47:53 +0200
Subject: [Rd] R trunk (2.7) build fails with -fpic,
	needs -fPIC (PR#10372)
In-Reply-To: <20071024231358.GA58065@tehun.pair.com>
References: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>
	<471FC4E1.6080102@biostat.ku.dk>
	<20071024231358.GA58065@tehun.pair.com>
Message-ID: <47203C19.90005@biostat.ku.dk>

Andrew Piskorski wrote:
> On Thu, Oct 25, 2007 at 12:19:13AM +0200, Peter Dalgaard wrote:
>
>   
>> Fedora 7 seems perfectly happy with -fpic,
>>     
>
> Well, Ubuntu 6.06 x86-64 sure seems to hate it, but all I know about
> -fpic vs. -fPIC is what I read here:
>
>   http://gcc.gnu.org/onlinedocs/gcc-4.0.3/gcc/Code-Gen-Options.html#index-fpic-1556
>   http://gcc.gnu.org/onlinedocs/gcc-4.2.2/gcc/Code-Gen-Options.html#index-fpic-1667
>
>   
>> Whic compiler/linker is this?
>>     
>
> $ gcc --version | grep gcc
> gcc (GCC) 4.0.3 (Ubuntu 4.0.3-1ubuntu5)
> $ ld --version | grep ld
> GNU ld version 2.16.91 20060118 Debian GNU/Linux
>
> $ COLUMNS=140 dpkg -l binutils gcc-4.0
> +++-==========-=============================-==============================================
> ii  binutils   2.16.1cvs20060117-1ubuntu2.1  The GNU assembler, linker and binary utilities
> ii  gcc-4.0    4.0.3-1ubuntu5                The GNU C compiler
>
>   
Fedora is at 4.1.2 and 2.17.50. You might try an upgrade. Also, make 
sure that your sources are clean (as in make distclean or fresh svn 
checkout) so that you are not mixing modules built with different 
compiler options.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ezehosita at yahoo.com  Thu Oct 25 12:22:29 2007
From: ezehosita at yahoo.com (ezeh osita)
Date: Thu, 25 Oct 2007 03:22:29 -0700 (PDT)
Subject: [Rd] help
Message-ID: <210507.69136.qm@web32208.mail.mud.yahoo.com>

hello,

please can anyone help me out. Am a new user of R program. Am having problem
with this code below, not getting the expected results.

1. Each m, the cumulative sum should be 1.000 but the 2nd and 3rd m returned 2.000 and 3.000
instead of 1.000.

2.  to get the LCL(m) and UCL(m) for each m base on these instructions
         if out.cum > 0.025 then LCL(m)= y-1
         if out.cum >0.975 then ucl(m)= y-1
   how do I code these instructions into this code.

thanks
Aruike
                               

pp=function(x,n,M){z=1.0;a=2.3071430;b=7.266064;H=3


     out.h=c()   


     out.y=c()


     out.m=c()


     out.prob=c()


     


       for(h in 1:H){


       for(m in 1:M){


       for(y in
0:m){  


 


    
g=lgamma(m+z)+lgamma(n[h]+a+b)+lgamma(x[h]+y+a)+lgamma(n[h]+m+b-x[h]-y) 


     
g=g-lgamma(y+z)-lgamma(m-y+z)-lgamma(x[h]+a)-lgamma(n[h]+b-x[h])-
lgamma(n[h]+m+a+b)


  


     out.h=c(out.h,h)


     out.y=c(out.y,y)


     out.m=c(out.m,m)


    
out.prob=c(out.prob, exp(g))   


  
out.cum=c(cumsum(out.prob))


    


 Result=data.frame(out.h,out.y,out.m,out.prob,out.cum)


 }}}}
Kings=pp(x=c(19,20,30), n=c(52,60,80),3)
 Kings



out.h out.y out.m  
out.prob   out.cum


1      1     0    
1 0.65395431 0.6539543


2      1     1     1
0.34604569 1.0000000


3      1     0    
2 0.43127277 1.4312728


4      1     1    
2 0.44536308 1.8766358


5      1     2    
2 0.12336415 2.0000000


6      1     0    
3 0.28672775 2.2867277


7      1     1    
3 0.43363507 2.7203628


8      1     2     3 0.23440955 2.9547724


9      1     3    
3 0.04522764 3.0000000










Send instant messages to your online friends http://uk.messenger.yahoo.com


From atp at piskorski.com  Thu Oct 25 14:01:21 2007
From: atp at piskorski.com (Andrew Piskorski)
Date: Thu, 25 Oct 2007 08:01:21 -0400
Subject: [Rd] R trunk (2.7) build fails with -fpic,
	needs -fPIC (PR#10372)
In-Reply-To: <47203C19.90005@biostat.ku.dk>
References: <20071024190025.794E6282EFF1@mail.pubhealth.ku.dk>
	<471FC4E1.6080102@biostat.ku.dk>
	<20071024231358.GA58065@tehun.pair.com>
	<47203C19.90005@biostat.ku.dk>
Message-ID: <20071025120120.GA67590@tehun.pair.com>

On Thu, Oct 25, 2007 at 08:47:53AM +0200, Peter Dalgaard wrote:

> Also, make sure that your sources are clean (as in make distclean or
> fresh svn checkout) so that you are not mixing modules built with
> different compiler options.

I did a 'make clean distclean', 'svn up', removed my changes to
configure, and...  It worked!  It now builds successfully with -fpic
(not -fPIC).  So, problem solved, thank you!  And I apologize for
wasting your time with this.

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From andy_liaw at merck.com  Thu Oct 25 15:04:53 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 25 Oct 2007 09:04:53 -0400
Subject: [Rd] meaning of "trim" in mean()
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>

(I see this in both R-patched r43124 and R-devel r43233.)
In the Argument section of ?mean:

trim     the fraction (0 to 0.5) of observations to be trimmed from each
end of x before the mean is computed. Values outside that range are
taken as the nearest endpoint.  

Then in the Value section:

If trim is non-zero, a symmetrically trimmed mean is computed with a
fraction of trim observations deleted from each end before the mean is
computed.

The description in "trim" to me sounds like Windsorizing, rather than
trimming.  Should that be edited?

Best,
Andy


Andy Liaw, PhD
Biometrics Research    PO Box 2000 RY33-300
Merck Research Labs        Rahway, NJ 07065
andy_liaw(a)merck.com          732-594-0820



------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachme...{{dropped:15}}


From P.Dalgaard at biostat.ku.dk  Thu Oct 25 15:25:16 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 25 Oct 2007 15:25:16 +0200
Subject: [Rd] meaning of "trim" in mean()
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>
Message-ID: <4720993C.5030105@biostat.ku.dk>

Liaw, Andy wrote:
> (I see this in both R-patched r43124 and R-devel r43233.)
> In the Argument section of ?mean:
>
> trim     the fraction (0 to 0.5) of observations to be trimmed from each
> end of x before the mean is computed. Values outside that range are
> taken as the nearest endpoint.  
>
> Then in the Value section:
>
> If trim is non-zero, a symmetrically trimmed mean is computed with a
> fraction of trim observations deleted from each end before the mean is
> computed.
>
> The description in "trim" to me sounds like Windsorizing, rather than
> trimming.  Should that be edited?
>
>   
I think so:

> x <- sort(rnorm(10))
> mean(x,trim=.1)
[1] -0.6387413
> mean(x[2:9])
[1] -0.6387413
> mean(x[c(2,2:9,9)]) # Winsorizing
[1] -0.6204222

So yes, it is trimming, not Winsorizing, and the last sentence in the
description of "trim" is misleading and should be, well..., trimmed.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Thu Oct 25 17:04:36 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 25 Oct 2007 17:04:36 +0200
Subject: [Rd] help
In-Reply-To: <210507.69136.qm@web32208.mail.mud.yahoo.com>
References: <210507.69136.qm@web32208.mail.mud.yahoo.com>
Message-ID: <18208.45188.211515.468914@stat.math.ethz.ch>

>>>>> "eo" == ezeh osita <ezehosita at yahoo.com>
>>>>>     on Thu, 25 Oct 2007 03:22:29 -0700 (PDT) writes:

    eo> hello, please can anyone help me out. Am a new user of R
    eo> program. Am having problem with this code below, not
    eo> getting the expected results.

Welcome to the masses (of R users)!

As a new user of R, there's only one mailing list for you : 

R-help;  definitely not R-devel.

Can you please re-post there?

Regards
Martin Maechler, ETH Zurich


From ahenningsen at email.uni-kiel.de  Thu Oct 25 19:52:20 2007
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Thu, 25 Oct 2007 19:52:20 +0200
Subject: [Rd] Splitting up the micEcon package?
Message-ID: <200710251952.20587.ahenningsen@email.uni-kiel.de>

Dear R Developers:

The functions of our micEcon package can be subdivided into 3 categories:
- microeconomic demand and firm models
- sample selection models (mainly selection())
- routines for (likelihood) maximization (e.g. maxLik(), maxNR(), maxBHHH())
   (mainly used for ML estimation of sample selection models)

Although sample selection models are often used in microeconomic analyses, 
they are also used in several other disciplines. Therefore, we are unsure 
whether it is better to keep these different functionalities in the micEcon 
package or to move the sample selection models and the routines for 
(likelihood) maximization into one or two new package(s) (increasing the long 
list of R packages even further).
What is your recommendation?

Thank you,
Ott & Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20071025/b24db8d1/attachment.bin 

From miguez at uiuc.edu  Fri Oct 26 00:48:08 2007
From: miguez at uiuc.edu (miguez at uiuc.edu)
Date: Thu, 25 Oct 2007 17:48:08 -0500 (CDT)
Subject: [Rd] Invalid permissions
Message-ID: <20071025174808.AXT92400@expms5.cites.uiuc.edu>

Hi,

I'm new to using complied code in R. I'm having a problem that might require further details but I think all I need is for someone to point me in the right direction. 

I wrote a C function which works fine if I load the shared object in the usual way using dyn.load("myfun.so"). However, if I source an R file which contains this function with others, when I try to use it, R aborts with an 'invalid permission' message. I'm not sure if this is clear but when I load the function by itself it works, but when I load it together with others it doesn't. 

Any help would be appreciated.

Thanks!

Fernando


From ripley at stats.ox.ac.uk  Fri Oct 26 09:16:03 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Oct 2007 08:16:03 +0100 (BST)
Subject: [Rd] Use of all/any
Message-ID: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>

all/any coerce their arguments to logical (if possible).  I've added a 
warning in R-devel if coercion is from something other than integer.

This arose because it is easy to make a slip and write all(X) > 0 rather 
than all(X > 0): thanks to Bill Dunlap for bringing that to my attention.
However, it has been useful in detecting quite a few other things:

- indices which had been made double where integer was intended. One 
example from predict.lm was

                 iipiv[ii == 0] <- 0

which was intended to be

                 iipiv[ii == 0L] <- 0L

- uses of lapply where sapply was intended.  Examples are of the form

 	all(lapply(z, is.numeric))

which is applying all() to a list.  One might worry that

 	sapply(z, is.numeric)

will return a list if length(z) == 0 (which it does) and so all() would 
warn, but that is covered by another change, to ignore all length-zero 
arguments (and so avoid the cost of coercion to logical(0)).


I decided not to warn on integer as it is so common.  But at least some of 
these are thinkos.  For example, constructions like

 	all(grep(pattern, x))

occurred scores of times in the R sources.  Since the value of grep() is 
an integer vector of positive indices, this is equivalent to

 	length(grep(pattern, x)) > 0

and when used in a if() condition the '> 0' is not needed.


Some warnings are common from other packages: one is

Warning in any(textLocations) :
   coercing argument of type 'double' to logical

from lattice (and Deepayan Sarkar will fix that shortly).  Quite a few 
others looked familiar but are the result of package authors copying code 
from base R or other packages: if you do that you do need to copy the 
bugfixes too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From clyde at stat.duke.edu  Thu Oct 25 22:00:13 2007
From: clyde at stat.duke.edu (clyde at stat.duke.edu)
Date: Thu, 25 Oct 2007 22:00:13 +0200 (CEST)
Subject: [Rd] PR#10371
Message-ID: <20071025200013.BBC0C2834169@mail.pubhealth.ku.dk>

Oops -- I should have tested it without libraries loaded :-)

The conflict must be with the HH package.  I tested the example again 
using all the packages required by HH and do get the correct results, but 
once the HH package is loaded, the TukeyHSD function returns "height" and 
the plot command gives the error described previously.

Should I report this bug directly to the authors of the HH package or 
file a new bug report under HH?

Thanks!
Merlise

-- 
__________________________________________________
|                                                |
| Merlise Clyde,  Associate Professor            |
| Department of Statistical Science              |
| 223E  Old Chemistry, BOX 90251                 | 
| Duke University                                |
| Durham, NC  27708-0251                         | 
|                                                |
| Office Phone: (919) 681-8440                   |
| Fax:          (919) 684-8594                   |
| email:        clyde at stat.duke.edu              |
| web:          http://www.stat.duke.edu/~clyde  |
|________________________________________________|


From P.Dalgaard at biostat.ku.dk  Fri Oct 26 10:11:41 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 26 Oct 2007 10:11:41 +0200
Subject: [Rd] PR#10371
In-Reply-To: <20071025200013.BBC0C2834169@mail.pubhealth.ku.dk>
References: <20071025200013.BBC0C2834169@mail.pubhealth.ku.dk>
Message-ID: <4721A13D.3010505@biostat.ku.dk>

clyde at stat.duke.edu wrote:
> Oops -- I should have tested it without libraries loaded :-)
>
> The conflict must be with the HH package.  I tested the example again 
> using all the packages required by HH and do get the correct results, but 
> once the HH package is loaded, the TukeyHSD function returns "height" and 
> the plot command gives the error described previously.
>
> Should I report this bug directly to the authors of the HH package or 
> file a new bug report under HH?
>
>   
The former. (The current bug report system doesn't have a mechanism
whereby package maintainers can refile reports as they get fixed, and
r-core cannot track the issues.)

> Thanks!
> Merlise
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Fri Oct 26 18:18:08 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Oct 2007 18:18:08 +0200
Subject: [Rd] Use of all/any
In-Reply-To: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>
Message-ID: <18210.4928.146934.283358@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Fri, 26 Oct 2007 08:16:03 +0100 (BST) writes:

    BDR> all/any coerce their arguments to logical (if
    BDR> possible).  I've added a warning in R-devel if coercion
    BDR> is from something other than integer.

    BDR> This arose because it is easy to make a slip and write
    BDR> all(X) > 0 rather than all(X > 0): thanks to Bill
    BDR> Dunlap for bringing that to my attention.  


    BDR> However, it has been useful in detecting quite a few other things:

    BDR> - indices which had been made double where integer was
    BDR> intended. One example from predict.lm was

    BDR>                  iipiv[ii == 0] <- 0

    BDR> which was intended to be

    BDR>                  iipiv[ii == 0L] <- 0L

Hmm....  Do we really want to generate warnings for such small
inefficiencies?
I'm very happy that we've introduced   <n>L integer notation, and
as a subtle programmer, I'm making use of it gladly --- but
still not always, just for code beauty reasons ("0" reads better).

On the other hand, I don't think the casual R / S programmer
should get warnings; after all, S and R  are not C on purpose.

Apropos Bill Dunlap's note:  Do newer versions of S-plus warn?
At least up to 6.2.2, I'm pretty sure no S version has warned
about
	X <- c(0.1, pi)
	all(X) > 0.5

In spite, of the buglets of you have revealed, mentioned below,
currently, I'd still tend to only warn for coercion from
non-numeric, but not from double.

In this context, I have thought again of using *levels* of
warnings, configurable via options(), and we could activate more
stringent warnings when "R CMD check"ing than per default.

Actually, we already have a simple form of that (with I think message()),
and also with the way the 'codetools' ``warnings'' are treated
by 'R CMD check'.
For my taste and "S language feeling", such a	
    'double -> logical coercion warning'
is somewhat similar in sprit to some of the codetools warnings.

Martin



    BDR> - uses of lapply where sapply was intended.  Examples
    BDR> are of the form

    BDR>  	all(lapply(z, is.numeric))

    BDR> which is applying all() to a list.  One might worry
    BDR> that

    BDR>  	sapply(z, is.numeric)

    BDR> will return a list if length(z) == 0 (which it does)
    BDR> and so all() would warn, but that is covered by another
    BDR> change, to ignore all length-zero arguments (and so
    BDR> avoid the cost of coercion to logical(0)).


    BDR> I decided not to warn on integer as it is so common.
    BDR> But at least some of these are thinkos.  For example,
    BDR> constructions like

    BDR>  	all(grep(pattern, x))

    BDR> occurred scores of times in the R sources.  Since the
    BDR> value of grep() is an integer vector of positive
    BDR> indices, this is equivalent to

    BDR>  	length(grep(pattern, x)) > 0

    BDR> and when used in a if() condition the '> 0' is not
    BDR> needed.


    BDR> Some warnings are common from other packages: one is

    BDR> Warning in any(textLocations) : coercing argument of
    BDR> type 'double' to logical

    BDR> from lattice (and Deepayan Sarkar will fix that
    BDR> shortly).  Quite a few others looked familiar but are
    BDR> the result of package authors copying code from base R
    BDR> or other packages: if you do that you do need to copy
    BDR> the bugfixes too.


From murdoch at stats.uwo.ca  Fri Oct 26 18:33:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 26 Oct 2007 12:33:12 -0400
Subject: [Rd] Use of all/any
In-Reply-To: <18210.4928.146934.283358@stat.math.ethz.ch>
References: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>
	<18210.4928.146934.283358@stat.math.ethz.ch>
Message-ID: <472216C8.4080701@stats.uwo.ca>

On 10/26/2007 12:18 PM, Martin Maechler wrote:
>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Fri, 26 Oct 2007 08:16:03 +0100 (BST) writes:
> 
>     BDR> all/any coerce their arguments to logical (if
>     BDR> possible).  I've added a warning in R-devel if coercion
>     BDR> is from something other than integer.
> 
>     BDR> This arose because it is easy to make a slip and write
>     BDR> all(X) > 0 rather than all(X > 0): thanks to Bill
>     BDR> Dunlap for bringing that to my attention.  
> 
> 
>     BDR> However, it has been useful in detecting quite a few other things:
> 
>     BDR> - indices which had been made double where integer was
>     BDR> intended. One example from predict.lm was
> 
>     BDR>                  iipiv[ii == 0] <- 0
> 
>     BDR> which was intended to be
> 
>     BDR>                  iipiv[ii == 0L] <- 0L
> 
> Hmm....  Do we really want to generate warnings for such small
> inefficiencies?
> I'm very happy that we've introduced   <n>L integer notation, and
> as a subtle programmer, I'm making use of it gladly --- but
> still not always, just for code beauty reasons ("0" reads better).
> 
> On the other hand, I don't think the casual R / S programmer
> should get warnings; after all, S and R  are not C on purpose.
> 
> Apropos Bill Dunlap's note:  Do newer versions of S-plus warn?
> At least up to 6.2.2, I'm pretty sure no S version has warned
> about
> 	X <- c(0.1, pi)
> 	all(X) > 0.5

I don't know whether S warns about that, but isn't it clear that it 
should generate a warning?  That's almost certainly a typo for

  all(X > 0.5)

If someone really wanted to do what all(X) > 0.5 says, then they should 
code it clearly as

  all(X != 0)

and not try to win an obfuscated code contest by coding it in the 
original way.

Duncan Murdoch

> 
> In spite, of the buglets of you have revealed, mentioned below,
> currently, I'd still tend to only warn for coercion from
> non-numeric, but not from double.
> 
> In this context, I have thought again of using *levels* of
> warnings, configurable via options(), and we could activate more
> stringent warnings when "R CMD check"ing than per default.
> 
> Actually, we already have a simple form of that (with I think message()),
> and also with the way the 'codetools' ``warnings'' are treated
> by 'R CMD check'.
> For my taste and "S language feeling", such a	
>     'double -> logical coercion warning'
> is somewhat similar in sprit to some of the codetools warnings.
> 
> Martin
> 
> 
> 
>     BDR> - uses of lapply where sapply was intended.  Examples
>     BDR> are of the form
> 
>     BDR>  	all(lapply(z, is.numeric))
> 
>     BDR> which is applying all() to a list.  One might worry
>     BDR> that
> 
>     BDR>  	sapply(z, is.numeric)
> 
>     BDR> will return a list if length(z) == 0 (which it does)
>     BDR> and so all() would warn, but that is covered by another
>     BDR> change, to ignore all length-zero arguments (and so
>     BDR> avoid the cost of coercion to logical(0)).
> 
> 
>     BDR> I decided not to warn on integer as it is so common.
>     BDR> But at least some of these are thinkos.  For example,
>     BDR> constructions like
> 
>     BDR>  	all(grep(pattern, x))
> 
>     BDR> occurred scores of times in the R sources.  Since the
>     BDR> value of grep() is an integer vector of positive
>     BDR> indices, this is equivalent to
> 
>     BDR>  	length(grep(pattern, x)) > 0
> 
>     BDR> and when used in a if() condition the '> 0' is not
>     BDR> needed.
> 
> 
>     BDR> Some warnings are common from other packages: one is
> 
>     BDR> Warning in any(textLocations) : coercing argument of
>     BDR> type 'double' to logical
> 
>     BDR> from lattice (and Deepayan Sarkar will fix that
>     BDR> shortly).  Quite a few others looked familiar but are
>     BDR> the result of package authors copying code from base R
>     BDR> or other packages: if you do that you do need to copy
>     BDR> the bugfixes too.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bill at insightful.com  Fri Oct 26 21:46:25 2007
From: bill at insightful.com (Bill Dunlap)
Date: Fri, 26 Oct 2007 12:46:25 -0700 (PDT)
Subject: [Rd] Use of all/any
In-Reply-To: <18210.4928.146934.283358@stat.math.ethz.ch>
References: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>
	<18210.4928.146934.283358@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0710261145460.10088@durian.statsci.com>

On Fri, 26 Oct 2007, Martin Maechler wrote:

> Apropos Bill Dunlap's note:  Do newer versions of S-plus warn?
> At least up to 6.2.2, I'm pretty sure no S version has warned
> about
> 	X <- c(0.1, pi)
> 	all(X) > 0.5

Hi Martin,

No, it doesn't warn.  We had a user who ran into a bug
in another function that came from this sort of thing
so I wrote some code that examined parse trees for
expresions of the form
    <comparison operator>
        <call to any or all>
        <anything>
or
    <comparison operator>
        <anything>
        <call to any or all>
and ran it over all our source code.  Out of curiousity
I also ran it over the current R source and an out-of-date
copy of the package source code from CRAN and that is
where I ran across the problem in polr() (and lots of instances
in packages, although they seemed to be clustered).

Now I have a question/complaint about doing this.  In Splus
I looked for this pattern with the following code
   isComparisonOfAnyOrAll <- function(expr)
      isCallTo(expr, c("<", ">", "<=", ">=", "==")) &&
        (isCallTo(expr[[2]], c("any", "all")) ||
         isCallTo(expr[[3]], c("any", "all")))
where isCallTo is
   isCallTo <- function(expr, functionName, numberArgs = NULL)
   {
        # return TRUE if expr is a call to with one of the functions
	# listed in functionName.  If numberArgs is non-NULL, it should
	# be a nonnegative integer giving the required number of arguments
	# in the call
        if(class(expr) == "call with ...") {
                # e.g., Quote(foo(x, ..., value = TRUE))
                # This class is only in Splus
                if(!is.null(numberArgs)) {
                        warning("call has ... in argument list, numberArgs will count all ... arguments as 1 argument"
                                )
                }
                expr <- expr[[1]]
        }
        if(length(functionName) == 1) {
                retval <- class(expr) == "call" && identical(expr[[1]], as.name(
                        functionName)) && (is.null(numberArgs) || numberArgs ==
                        length(expr) - 1)
        }
        else {
                retval <- class(expr) == "call" && is.name(expr[[1]]) &&
                        is.element(as.character(expr[[1]]), functionName) &&
                        (is.null(numberArgs) || numberArgs == length(expr) -
                        1)
        }
        retval
   }
This code works in Splus and R.  E.g.,
   > isComparisonOfAnyOrAll(Quote(any(x)<0))
   [1] TRUE
   > isComparisonOfAnyOrAll(Quote(any(x<0)))
   [1] FALSE

In Splus I use
   rapply(expr, classes="call",
     f=function(x)if(isComparisonOfAnyOrAll(x))deparseText(x))
to rattle down an an expression tree looking for this pattern.
However's R's rapply won't let me do that because
it insists its input be a function instead of being of
recursive type.  Its help file says it evaluates the arguments
to f() even if they are expressions, and that may contribute
to problems.  The Splus rapply accepts any recursive type and it does not
evaluate the subtrees that it hands to f().

E.g., running the same input into R and Splus and labelling
the output lines 'Splus:' and 'R   :', we get
  RS> rapply(function(x)log(x+1), f = function(expr) if (is.name(expr)) as.character(expr)) # all.names()
  Splus: [1] "log" "+"   "x"
  R    : Error in rapply(function(x) log(x + 1), f = function(expr) if (is.name(expr)) as.character(expr)) :
  R    :  'object' must be a list
If I get around the "'object' must be a list' problem by wrapping
the input in a list then I run into the evalution problem

Does R have an rapply-like function that works like Splus's?

Are the R parse tree classes sufficiently different from lists
that we cannot expect the above to work?

In Splus I've used rapply quite productively to find patterns
in parse trees and then change the code.  E.g., to change all
calls of the form
    log(x, base)
to
    logb(x, base)
but not change calls of the form log(x) you can do
    > changeLogCalls<-function(func) {
        rapply(func, classes="call", how="replace",
            function(expr){
                if(isCallTo(expr,"log",2)) expr[[1]] <- as.name("logb")
                expr
            })
    }
    }
    > changeLogCalls(function(x)log(x,2)/log(x))
    function(x)
    logb(x, 2)/log(x)

I suspect I should be looking in codetools for this sort of
thing.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From bill at insightful.com  Fri Oct 26 21:53:46 2007
From: bill at insightful.com (Bill Dunlap)
Date: Fri, 26 Oct 2007 12:53:46 -0700 (PDT)
Subject: [Rd] Use of all/any
In-Reply-To: <Pine.GSO.4.56.0710261145460.10088@durian.statsci.com>
References: <Pine.LNX.4.64.0710260751480.4295@gannet.stats.ox.ac.uk>
	<18210.4928.146934.283358@stat.math.ethz.ch>
	<Pine.GSO.4.56.0710261145460.10088@durian.statsci.com>
Message-ID: <Pine.GSO.4.56.0710261253070.10088@durian.statsci.com>

On Fri, 26 Oct 2007, Bill Dunlap wrote:

> In Splus I use
>    rapply(expr, classes="call",
>      f=function(x)if(isComparisonOfAnyOrAll(x))deparseText(x))
> to rattle down an an expression tree looking for this pattern.
> However's R's rapply won't let me do that because
> it insists its input be a function instead of being of
                         oops, "a list", not "function"
> recursive type.  Its help file says it evaluates the arguments
> to f() even if they are expressions, and that may contribute
> to problems.  The Splus rapply accepts any recursive type and it does not
> evaluate the subtrees that it hands to f().

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From brechbuehler at gmail.com  Sat Oct 27 00:30:05 2007
From: brechbuehler at gmail.com (brechbuehler at gmail.com)
Date: Sat, 27 Oct 2007 00:30:05 +0200 (CEST)
Subject: [Rd] x11(....) kills R without DISPLAY (PR#10379)
Message-ID: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>

Full_Name: Christian Brechbuehler
Version: 2.4.1, 2.5.1, 
OS: Ubuntu GNU/Linux
Submission from: (NULL) (24.61.47.236)


Context:
'X11' starts a graphics device driver on the display given by argument
'display'.

Problem:
If the environment variable DISPLAY is not set, the R process dies with exit
status 1.

Example (start R without DISPLAY from bash):
  % DISPLAY= R
  > x11("localhost:11.0")                        # this is my valid DISPLAY
  Error: Couldn't find per display information
  %

History:
This was reported before (e.g.,
https://stat.ethz.ch/pipermail/ess-help/2006-April/003464.html), but search
turns up no R Bug Report.

Reportedly this problem was introduced between R 2.2.1 and R 2.3.0.  The
following versions are affected:
  R 2.4.1 (Patched), 2007-03-25, svn.rev 40917, x86_64-unknown-linux-gnu
  R 2.5.1 (Patched), 2007-09-16, svn.rev 43071, x86_64-unknown-linux-gnu 
  R 2.6.0 (Patched), 2007-10-16, svn.rev 43176, x86_64-unknown-linux-gnu 
  R 2.6.0 (Patched), 2007-10-25, svn.rev 43271, x86_64-unknown-linux-gnu 
  R 2.7.0 (Under development (unstable)), 2007-10-25, svn.rev 43273,
x86_64-unknown-linux-gnu


Further Observations:

(A) If DISPLAY is set but not a valid X11 server, R dies equally.

(B) If DISPLAY is set to an X11 server on which I don't have access, the x11
call fails as follows:
| Error in x11("localhost:11.0") : 
|    X11 fatal IO error: please save work and shut down R
|
| Enter a frame number, or 0 to exit   
| 
| 1: x11("localhost:11.0")
|
| Selection:
I.e., the R session survives.  But it is not possible to start an X11 graphics
device driver.

(C) If DISPLAY is set to an X11 server on which I have access, the x11 call
succeeds, and it opens a window on the server named in the 'display' argument. 
Nothing happens on DISPLAY, which is appropriate.

My conjecture: R seems to first connect to the server given by the DISPLAY
environment variable, performing no visible operations, before heeding the
'display' argument.

(D) It is possible to swich between X11 servers (a.k.a. displays) on the fly by
using graphics.off() followed by x11(my.new.display).

When Googling, I found the error string "Couldn't find per display information"
sometimes associated with the Xt library.

I'd be happy to answer any questions that may help clarify the issue.


From p.dalgaard at biostat.ku.dk  Sat Oct 27 01:27:17 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 27 Oct 2007 01:27:17 +0200
Subject: [Rd] x11(....) kills R without DISPLAY (PR#10379)
In-Reply-To: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
References: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
Message-ID: <472277D5.9080202@biostat.ku.dk>

brechbuehler at gmail.com wrote:
> Full_Name: Christian Brechbuehler
> Version: 2.4.1, 2.5.1, 
> OS: Ubuntu GNU/Linux
> Submission from: (NULL) (24.61.47.236)
>
>
> Context:
> 'X11' starts a graphics device driver on the display given by argument
> 'display'.
>
> Problem:
> If the environment variable DISPLAY is not set, the R process dies with exit
> status 1.
>
> Example (start R without DISPLAY from bash):
>   % DISPLAY= R
>   > x11("localhost:11.0")                        # this is my valid DISPLAY
>   Error: Couldn't find per display information
>   %
>
> History:
> This was reported before (e.g.,
> https://stat.ethz.ch/pipermail/ess-help/2006-April/003464.html), but search
> turns up no R Bug Report.
>
> Reportedly this problem was introduced between R 2.2.1 and R 2.3.0.  The
> following versions are affected:
>   R 2.4.1 (Patched), 2007-03-25, svn.rev 40917, x86_64-unknown-linux-gnu
>   R 2.5.1 (Patched), 2007-09-16, svn.rev 43071, x86_64-unknown-linux-gnu 
>   R 2.6.0 (Patched), 2007-10-16, svn.rev 43176, x86_64-unknown-linux-gnu 
>   R 2.6.0 (Patched), 2007-10-25, svn.rev 43271, x86_64-unknown-linux-gnu 
>   R 2.7.0 (Under development (unstable)), 2007-10-25, svn.rev 43273,
> x86_64-unknown-linux-gnu
>
>   
I see this on Fedora 7 too. I suspect that the earlier report was 
thought to be Mac specific.

> Further Observations:
>
> (A) If DISPLAY is set but not a valid X11 server, R dies equally.
>
> (B) If DISPLAY is set to an X11 server on which I don't have access, the x11
> call fails as follows:
> | Error in x11("localhost:11.0") : 
> |    X11 fatal IO error: please save work and shut down R
> |
> | Enter a frame number, or 0 to exit   
> | 
> | 1: x11("localhost:11.0")
> |
> | Selection:
> I.e., the R session survives.  But it is not possible to start an X11 graphics
> device driver.
>
> (C) If DISPLAY is set to an X11 server on which I have access, the x11 call
> succeeds, and it opens a window on the server named in the 'display' argument. 
> Nothing happens on DISPLAY, which is appropriate.
>
> My conjecture: R seems to first connect to the server given by the DISPLAY
> environment variable, performing no visible operations, before heeding the
> 'display' argument.
>
> (D) It is possible to swich between X11 servers (a.k.a. displays) on the fly by
> using graphics.off() followed by x11(my.new.display).
>
> When Googling, I found the error string "Couldn't find per display information"
> sometimes associated with the Xt library.
>
> I'd be happy to answer any questions that may help clarify the issue.
>
>   
(E) It appears that you have to use a valid display in the x11() call

 > x11(":1")
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
  unable to start device X11
In addition: Warning message:
In x11(":1") : unable to open connection to X11 display ':1'
 > x11(":0")
Error: Couldn't find per display information

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From hin-tak.leung at cimr.cam.ac.uk  Sat Oct 27 02:35:30 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Sat, 27 Oct 2007 01:35:30 +0100
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
In-Reply-To: <472277D5.9080202@biostat.ku.dk>
References: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
	<472277D5.9080202@biostat.ku.dk>
Message-ID: <472287D2.1020603@cimr.cam.ac.uk>

Peter Dalgaard wrote:
> brechbuehler at gmail.com wrote:
>> Full_Name: Christian Brechbuehler
>> Version: 2.4.1, 2.5.1, 
>> OS: Ubuntu GNU/Linux
>> Submission from: (NULL) (24.61.47.236)
>>
>>
<snipped>
>> Example (start R without DISPLAY from bash):
>>   % DISPLAY= R
>>   > x11("localhost:11.0")                        # this is my valid DISPLAY
>>   Error: Couldn't find per display information
>>   %
<snipped>
>>   
> I see this on Fedora 7 too. I suspect that the earlier report was 
> thought to be Mac specific.
<snipped>

I was experimenting with xvfb last week and didn't see the catatrophic 
problem like that, so I tried again. Is it possible that this has 
already been fixed in R 2.6.0 ? (I am on fedora 7, x86_64 as well).

------------------------------------------
$ export -n DISPLAY

$ R
R version 2.6.0 (2007-10-03)
...
 > x11()
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
   unable to start device X11
In addition: Warning message:
In x11() : unable to open connection to X11 display ''
 > q()
Save workspace image? [y/n/c]: n
$ export DISPLAY=
$ R
R version 2.6.0 (2007-10-03)
...
 > x11()
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
   unable to start device X11
In addition: Warning message:
In x11() : unable to open connection to X11 display ''
 > q()
Save workspace image? [y/n/c]: n


From hin-tak.leung at cimr.cam.ac.uk  Sat Oct 27 02:40:18 2007
From: hin-tak.leung at cimr.cam.ac.uk (hin-tak.leung at cimr.cam.ac.uk)
Date: Sat, 27 Oct 2007 02:40:18 +0200 (CEST)
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
Message-ID: <20071027004018.A81172834619@mail.pubhealth.ku.dk>

Peter Dalgaard wrote:
> brechbuehler at gmail.com wrote:
>> Full_Name: Christian Brechbuehler
>> Version: 2.4.1, 2.5.1, 
>> OS: Ubuntu GNU/Linux
>> Submission from: (NULL) (24.61.47.236)
>>
>>
<snipped>
>> Example (start R without DISPLAY from bash):
>>   % DISPLAY= R
>>   > x11("localhost:11.0")                        # this is my valid DISPLAY
>>   Error: Couldn't find per display information
>>   %
<snipped>
>>   
> I see this on Fedora 7 too. I suspect that the earlier report was 
> thought to be Mac specific.
<snipped>

I was experimenting with xvfb last week and didn't see the catatrophic 
problem like that, so I tried again. Is it possible that this has 
already been fixed in R 2.6.0 ? (I am on fedora 7, x86_64 as well).

------------------------------------------
$ export -n DISPLAY

$ R
R version 2.6.0 (2007-10-03)
...
 > x11()
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
   unable to start device X11
In addition: Warning message:
In x11() : unable to open connection to X11 display ''
 > q()
Save workspace image? [y/n/c]: n
$ export DISPLAY=
$ R
R version 2.6.0 (2007-10-03)
...
 > x11()
Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
else gamma,  :
   unable to start device X11
In addition: Warning message:
In x11() : unable to open connection to X11 display ''
 > q()
Save workspace image? [y/n/c]: n


From p.dalgaard at biostat.ku.dk  Sat Oct 27 02:45:53 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 27 Oct 2007 02:45:53 +0200
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
In-Reply-To: <472287D2.1020603@cimr.cam.ac.uk>
References: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
	<472277D5.9080202@biostat.ku.dk> <472287D2.1020603@cimr.cam.ac.uk>
Message-ID: <47228A41.5050901@biostat.ku.dk>

Hin-Tak Leung wrote:
> Peter Dalgaard wrote:
>> brechbuehler at gmail.com wrote:
>>> Full_Name: Christian Brechbuehler
>>> Version: 2.4.1, 2.5.1, OS: Ubuntu GNU/Linux
>>> Submission from: (NULL) (24.61.47.236)
>>>
>>>
> <snipped>
>>> Example (start R without DISPLAY from bash):
>>>   % DISPLAY= R
>>>   > x11("localhost:11.0")                        # this is my valid 
>>> DISPLAY
>>>   Error: Couldn't find per display information
>>>   %
> <snipped>
>>>   
>> I see this on Fedora 7 too. I suspect that the earlier report was 
>> thought to be Mac specific.
> <snipped>
>
> I was experimenting with xvfb last week and didn't see the catatrophic 
> problem like that, so I tried again. Is it possible that this has 
> already been fixed in R 2.6.0 ? (I am on fedora 7, x86_64 as well).
>
> ------------------------------------------
> $ export -n DISPLAY
>
> $ R
> R version 2.6.0 (2007-10-03)
> ...
> > x11()
> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
> else gamma,  :
>   unable to start device X11
> In addition: Warning message:
> In x11() : unable to open connection to X11 display ''
> > q()
> Save workspace image? [y/n/c]: n
> $ export DISPLAY=
> $ R
> R version 2.6.0 (2007-10-03)
> ...
> > x11()
> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1 
> else gamma,  :
>   unable to start device X11
> In addition: Warning message:
> In x11() : unable to open connection to X11 display ''
> > q()
> Save workspace image? [y/n/c]: n
> --------------------------------------------------
>
You need x11() with a valid display to trigger the bug:

[pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
pd at 192.168.1.10's password:
Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
[pd at janus ~]$ echo $DISPLAY
localhost:10.0
[pd at janus ~]$ DISPLAY= R -q
 > x11("localhost:10.0")
Error: Couldn't find per display information
[pd at janus ~]$ uname -a
Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007 x86_64 
x86_64 x86_64 GNU/Linux
[pd at janus ~]$ cat /etc/issue
Fedora release 7 (Moonshine)
Kernel \r on an \m


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Sat Oct 27 02:50:17 2007
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Sat, 27 Oct 2007 02:50:17 +0200 (CEST)
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
Message-ID: <20071027005017.3493A2834619@mail.pubhealth.ku.dk>

Hin-Tak Leung wrote:
> Peter Dalgaard wrote:
>> brechbuehler at gmail.com wrote:
>>> Full_Name: Christian Brechbuehler
>>> Version: 2.4.1, 2.5.1, OS: Ubuntu GNU/Linux
>>> Submission from: (NULL) (24.61.47.236)
>>>
>>>
> <snipped>
>>> Example (start R without DISPLAY from bash):
>>>   % DISPLAY=3D R
>>>   > x11("localhost:11.0")                        # this is my valid=20
>>> DISPLAY
>>>   Error: Couldn't find per display information
>>>   %
> <snipped>
>>>  =20
>> I see this on Fedora 7 too. I suspect that the earlier report was=20
>> thought to be Mac specific.
> <snipped>
>
> I was experimenting with xvfb last week and didn't see the catatrophic =

> problem like that, so I tried again. Is it possible that this has=20
> already been fixed in R 2.6.0 ? (I am on fedora 7, x86_64 as well).
>
> ------------------------------------------
> $ export -n DISPLAY
>
> $ R
> R version 2.6.0 (2007-10-03)
> ...
> > x11()
> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1=20
> else gamma,  :
>   unable to start device X11
> In addition: Warning message:
> In x11() : unable to open connection to X11 display ''
> > q()
> Save workspace image? [y/n/c]: n
> $ export DISPLAY=3D
> $ R
> R version 2.6.0 (2007-10-03)
> ...
> > x11()
> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1=20
> else gamma,  :
>   unable to start device X11
> In addition: Warning message:
> In x11() : unable to open connection to X11 display ''
> > q()
> Save workspace image? [y/n/c]: n
> --------------------------------------------------
>
You need x11() with a valid display to trigger the bug:

[pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
pd at 192.168.1.10's password:
Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
[pd at janus ~]$ echo $DISPLAY
localhost:10.0
[pd at janus ~]$ DISPLAY=3D R -q
 > x11("localhost:10.0")
Error: Couldn't find per display information
[pd at janus ~]$ uname -a
Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007 x86_64=20
x86_64 x86_64 GNU/Linux
[pd at janus ~]$ cat /etc/issue
Fedora release 7 (Moonshine)
Kernel \r on an \m


--=20
   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907


From John.Maindonald at anu.edu.au  Sat Oct 27 09:10:22 2007
From: John.Maindonald at anu.edu.au (John.Maindonald at anu.edu.au)
Date: Sat, 27 Oct 2007 09:10:22 +0200 (CEST)
Subject: [Rd] Unwanted axis labels when rug() has POSIXlt argument (PR#10380)
Message-ID: <20071027071022.79EF72834619@mail.pubhealth.ku.dk>

rug() may add integer axis labels when called with a POSIXlt object
as argument.

dtimes <- c("09/29/2007  12:54", "09/30/2007  00:14", "10/01/2007   
00:14",
               "10/02/2007  00:14", "10/03/2007  00:14", "10/04/2007   
00:14",
               "10/05/2007  00:14", "10/06/2007  00:14", "10/07/2007   
00:14",
               "10/08/2007  00:14")
z <- strptime(dtimes, "%m/%d/%Y %H:%M", tz="EST5EDT")
plot(z, rnorm(10))
rug(z)

This happens also undo Windows, both with 2.6.0 and 2.7.0 (2007-10-26  
r43284)

--please do not edit the information below--

Version:
platform = i386-apple-darwin8.10.1
arch = i386
os = darwin8.10.1
system = i386, darwin8.10.1
status =
major = 2
minor = 6.0
year = 2007
month = 10
day = 03
svn rev = 43063
language = R
version.string = R version 2.6.0 (2007-10-03)

Locale:
C

Search Path:
.GlobalEnv, package:stats, package:graphics, package:grDevices,  
package:utils, package:datasets, package:methods, Autoloads,  
package:base

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From murdoch at stats.uwo.ca  Sat Oct 27 09:48:06 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 27 Oct 2007 03:48:06 -0400
Subject: [Rd] Unwanted axis labels when rug() has POSIXlt argument
	(PR#10380)
In-Reply-To: <20071027071022.79EF72834619@mail.pubhealth.ku.dk>
References: <20071027071022.79EF72834619@mail.pubhealth.ku.dk>
Message-ID: <4722ED36.3080400@stats.uwo.ca>

On 27/10/2007 3:10 AM, John.Maindonald at anu.edu.au wrote:
> rug() may add integer axis labels when called with a POSIXlt object
> as argument.
> 
> dtimes <- c("09/29/2007  12:54", "09/30/2007  00:14", "10/01/2007   
> 00:14",
>                "10/02/2007  00:14", "10/03/2007  00:14", "10/04/2007   
> 00:14",
>                "10/05/2007  00:14", "10/06/2007  00:14", "10/07/2007   
> 00:14",
>                "10/08/2007  00:14")
> z <- strptime(dtimes, "%m/%d/%Y %H:%M", tz="EST5EDT")
> plot(z, rnorm(10))
> rug(z)
> 
> This happens also undo Windows, both with 2.6.0 and 2.7.0 (2007-10-26  
> r43284)

rug() is documented to require a numeric vector as input, and z isn't 
one of those, so there's an argument that this is user error.  Still, 
its behaviour is a little surprising.

The workaround is to use rug(as.numeric(z)).

Duncan Murdoch

> 
> --please do not edit the information below--
> 
> Version:
> platform = i386-apple-darwin8.10.1
> arch = i386
> os = darwin8.10.1
> system = i386, darwin8.10.1
> status =
> major = 2
> minor = 6.0
> year = 2007
> month = 10
> day = 03
> svn rev = 43063
> language = R
> version.string = R version 2.6.0 (2007-10-03)
> 
> Locale:
> C
> 
> Search Path:
> .GlobalEnv, package:stats, package:graphics, package:grDevices,  
> package:utils, package:datasets, package:methods, Autoloads,  
> package:base
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From John.Maindonald at anu.edu.au  Sat Oct 27 10:09:59 2007
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Sat, 27 Oct 2007 18:09:59 +1000
Subject: [Rd] Unwanted axis labels when rug() has POSIXlt argument
	(PR#10380)
In-Reply-To: <4722ED36.3080400@stats.uwo.ca>
References: <20071027071022.79EF72834619@mail.pubhealth.ku.dk>
	<4722ED36.3080400@stats.uwo.ca>
Message-ID: <2B208DEF-AC57-4BC0-84A2-0BC2C4A371C2@anu.edu.au>

Yes, I noticed after I had sent it that x was said to be numeric.

Incidentally, this does not happen, in my experience, with Date objects.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 27 Oct 2007, at 5:48 PM, Duncan Murdoch wrote:

> On 27/10/2007 3:10 AM, John.Maindonald at anu.edu.au wrote:
>> rug() may add integer axis labels when called with a POSIXlt object
>> as argument.
>> dtimes <- c("09/29/2007  12:54", "09/30/2007  00:14",  
>> "10/01/2007   00:14",
>>                "10/02/2007  00:14", "10/03/2007  00:14",  
>> "10/04/2007   00:14",
>>                "10/05/2007  00:14", "10/06/2007  00:14",  
>> "10/07/2007   00:14",
>>                "10/08/2007  00:14")
>> z <- strptime(dtimes, "%m/%d/%Y %H:%M", tz="EST5EDT")
>> plot(z, rnorm(10))
>> rug(z)
>> This happens also undo Windows, both with 2.6.0 and 2.7.0  
>> (2007-10-26  r43284)
>
> rug() is documented to require a numeric vector as input, and z  
> isn't one of those, so there's an argument that this is user  
> error.  Still, its behaviour is a little surprising.
>
> The workaround is to use rug(as.numeric(z)).
>
> Duncan Murdoch
>
>> --please do not edit the information below--
>> Version:
>> platform = i386-apple-darwin8.10.1
>> arch = i386
>> os = darwin8.10.1
>> system = i386, darwin8.10.1
>> status =
>> major = 2
>> minor = 6.0
>> year = 2007
>> month = 10
>> day = 03
>> svn rev = 43063
>> language = R
>> version.string = R version 2.6.0 (2007-10-03)
>> Locale:
>> C
>> Search Path:
>> .GlobalEnv, package:stats, package:graphics, package:grDevices,   
>> package:utils, package:datasets, package:methods, Autoloads,   
>> package:base
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ed at sixfoursystems.com  Sat Oct 27 17:35:29 2007
From: ed at sixfoursystems.com (Ed Knutson)
Date: Sat, 27 Oct 2007 10:35:29 -0500
Subject: [Rd] Cell or PS3 Port
Message-ID: <47235AC1.9040302@sixfoursystems.com>

Hello,

I am interested in optimizing some of R's vector math functions to 
utilize the SPE units of the Cell processor (commonly found in the 
Playstation 3) and I am wondering if anyone has already done any work in 
that area.  I can't find anything using the search page or Google. 
(Admittedly it is difficult to search for information on a 
one-letter-named programming language whose contributed documentation 
intrinsically refers to "cells" frequently. :)  I'm assuming it will be 
possible to compile R under a PS3 version of Linux, since it has a ppc64 
architecture and R already runs on OS X.  Are there any known caveats to 
compiling R for a distro like Ubuntu with X11 support?

I'm just going through the Cell SDK documentation at this point so it 
will be a few days before I really get into the guts of it.  Any 
information would be greatly appreciated.

-Ed


From edd at debian.org  Sat Oct 27 19:36:15 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 27 Oct 2007 12:36:15 -0500
Subject: [Rd] Cell or PS3 Port
In-Reply-To: <47235AC1.9040302@sixfoursystems.com>
References: <47235AC1.9040302@sixfoursystems.com>
Message-ID: <18211.30479.866042.710923@ron.nulle.part>


On 27 October 2007 at 10:35, Ed Knutson wrote:
| I am interested in optimizing some of R's vector math functions to 
| utilize the SPE units of the Cell processor (commonly found in the 
| Playstation 3) and I am wondering if anyone has already done any work in 
| that area.  I can't find anything using the search page or Google. 
| (Admittedly it is difficult to search for information on a 
| one-letter-named programming language whose contributed documentation 
| intrinsically refers to "cells" frequently. :)  I'm assuming it will be 

See the r-devel archives for August where Doug Bates started a thread 
	[Rd] Compiling R for the Sony Playstation 3
with many posts.  

The upshot,as I recall, is the he 'simply' installed Ubuntu on his PS3 in
order to real software (read: Emacs, R) running on his 'dvd player' as he
calls it.

There is a lot of interest in making R work on things like the Cell as well
as in GPGPU frameworks, at least for subroutines and libraries (and I
understand that some work is ongoing in that area).  The main R thread will
probably remain single-threaded 'forever'.  Others may have more pertinent
comments.

Hope this helps, Dirk

-- 
Three out of two people have difficulties with fractions.


From ripley at stats.ox.ac.uk  Sun Oct 28 07:54:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 28 Oct 2007 06:54:58 +0000 (GMT)
Subject: [Rd] meaning of "trim" in mean()
In-Reply-To: <4720993C.5030105@biostat.ku.dk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>
	<4720993C.5030105@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0710271814060.15370@gannet.stats.ox.ac.uk>

There is only one _range_ mentioned, (0, 0.5).  I don't see how you can 
construe 'that range' to be a reference to anything other than (0, 0.5).

And why do you suppose the description for argument 'trim' is referring to 
'values' of a different argument?

It is telling you what happens for values of trim < 0 or > 0.5: that is 
not information that it is appropriate to excise.


On Thu, 25 Oct 2007, Peter Dalgaard wrote:

> Liaw, Andy wrote:
>> (I see this in both R-patched r43124 and R-devel r43233.)
>> In the Argument section of ?mean:
>>
>> trim     the fraction (0 to 0.5) of observations to be trimmed from each
>> end of x before the mean is computed. Values outside that range are
>> taken as the nearest endpoint.
>>
>> Then in the Value section:
>>
>> If trim is non-zero, a symmetrically trimmed mean is computed with a
>> fraction of trim observations deleted from each end before the mean is
>> computed.
>>
>> The description in "trim" to me sounds like Windsorizing, rather than
>> trimming.  Should that be edited?
>>
>>
> I think so:
>
>> x <- sort(rnorm(10))
>> mean(x,trim=.1)
> [1] -0.6387413
>> mean(x[2:9])
> [1] -0.6387413
>> mean(x[c(2,2:9,9)]) # Winsorizing
> [1] -0.6204222
>
> So yes, it is trimming, not Winsorizing, and the last sentence in the
> description of "trim" is misleading and should be, well..., trimmed.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pburns at pburns.seanet.com  Sun Oct 28 09:43:06 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 28 Oct 2007 08:43:06 +0000
Subject: [Rd] meaning of "trim" in mean()
In-Reply-To: <Pine.LNX.4.64.0710271814060.15370@gannet.stats.ox.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>	<4720993C.5030105@biostat.ku.dk>
	<Pine.LNX.4.64.0710271814060.15370@gannet.stats.ox.ac.uk>
Message-ID: <47244B9A.8090108@pburns.seanet.com>

If the sentence in question were amended to:

Values of trim outside that range ...

then I think it would rule out the misinterpretation of
the sentence.

Pat


Prof Brian Ripley wrote:

>There is only one _range_ mentioned, (0, 0.5).  I don't see how you can 
>construe 'that range' to be a reference to anything other than (0, 0.5).
>
>And why do you suppose the description for argument 'trim' is referring to 
>'values' of a different argument?
>
>It is telling you what happens for values of trim < 0 or > 0.5: that is 
>not information that it is appropriate to excise.
>
>
>On Thu, 25 Oct 2007, Peter Dalgaard wrote:
>
>  
>
>>Liaw, Andy wrote:
>>    
>>
>>>(I see this in both R-patched r43124 and R-devel r43233.)
>>>In the Argument section of ?mean:
>>>
>>>trim     the fraction (0 to 0.5) of observations to be trimmed from each
>>>end of x before the mean is computed. Values outside that range are
>>>taken as the nearest endpoint.
>>>
>>>Then in the Value section:
>>>
>>>If trim is non-zero, a symmetrically trimmed mean is computed with a
>>>fraction of trim observations deleted from each end before the mean is
>>>computed.
>>>
>>>The description in "trim" to me sounds like Windsorizing, rather than
>>>trimming.  Should that be edited?
>>>
>>>
>>>      
>>>
>>I think so:
>>
>>    
>>
>>>x <- sort(rnorm(10))
>>>mean(x,trim=.1)
>>>      
>>>
>>[1] -0.6387413
>>    
>>
>>>mean(x[2:9])
>>>      
>>>
>>[1] -0.6387413
>>    
>>
>>>mean(x[c(2,2:9,9)]) # Winsorizing
>>>      
>>>
>>[1] -0.6204222
>>
>>So yes, it is trimming, not Winsorizing, and the last sentence in the
>>description of "trim" is misleading and should be, well..., trimmed.
>>
>>
>>    
>>
>
>  
>


From sunshineboy55558888 at gmail.com  Sun Oct 28 13:33:57 2007
From: sunshineboy55558888 at gmail.com (=?GB2312?B?zfW7og==?=)
Date: Sun, 28 Oct 2007 20:33:57 +0800
Subject: [Rd] R-devel Digest, Vol 56, Issue 27
In-Reply-To: <mailman.15.1193569202.21167.r-devel@r-project.org>
References: <mailman.15.1193569202.21167.r-devel@r-project.org>
Message-ID: <d1bf3ebe0710280533m33d9c099jaa101fa0cc386421@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071028/42b05284/attachment.pl 

From ripley at stats.ox.ac.uk  Sun Oct 28 13:44:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 28 Oct 2007 12:44:05 +0000 (GMT)
Subject: [Rd] Using SJava? (was  R-devel Digest, Vol 56, Issue 27)
In-Reply-To: <d1bf3ebe0710280533m33d9c099jaa101fa0cc386421@mail.gmail.com>
References: <mailman.15.1193569202.21167.r-devel@r-project.org>
	<d1bf3ebe0710280533m33d9c099jaa101fa0cc386421@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710281238140.16703@gannet.stats.ox.ac.uk>

The error is:

> Exception in thread "main" java.lang.UnsatisfiedLinkError: no SJava in
> java.library.path

so this is most likely an error in the package you are using (SJava?), not 
in R.

Please do read and follow the R posting guide at 
http://www.r-project.org/posting-guide.html (including using a reasonable 
subject line).

On Sun, 28 Oct 2007, ???? wrote:

> Dear R expert:
>
> I have the problems with calling R from Java on Windows
> XP_SP2/Eclipse3.1/JDK1.5
>
> problems:
>
> Loading RInterpreter library
> Exception in thread "main" java.lang.UnsatisfiedLinkError: no RInterpreter
> in java.library.path
> at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1682)
> at java.lang.Runtime.loadLibrary0(Runtime.java:822)
> at java.lang.System.loadLibrary(System.java:992)
> at org.omegahat.R.Java.ROmegahatInterpreter.(ROmegahatInterpreter.java:28)
> at org.omegahat.R.Java.Examples.lmTest.main(lmTest.java:8)
> and
>
> Exception in thread "main" java.lang.UnsatisfiedLinkError: no SJava in
> java.library.path
> at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1682)
> at java.lang.Runtime.loadLibrary0(Runtime.java:822)
> at java.lang.System.loadLibrary(System.java:992)
> at org.omegahat.R.Java.RForeignReference.(RForeignReference.java:22)
> at ne.Test.main(Test.java:11)
>
> help me!Thanks!
> name:wanghu(from china)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Sun Oct 28 14:42:49 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 28 Oct 2007 14:42:49 +0100
Subject: [Rd] meaning of "trim" in mean()
In-Reply-To: <47244B9A.8090108@pburns.seanet.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>	<4720993C.5030105@biostat.ku.dk>
	<Pine.LNX.4.64.0710271814060.15370@gannet.stats.ox.ac.uk>
	<47244B9A.8090108@pburns.seanet.com>
Message-ID: <472491D9.20502@biostat.ku.dk>

Patrick Burns wrote:
> If the sentence in question were amended to:
>
> Values of trim outside that range ...
>
> then I think it would rule out the misinterpretation of
> the sentence.

Yup. And I maintain that although the wording may not be technically 
ambiguous,  the whole operation is about restricting the range of x, and 
therefore is easy to interpolate "the range of x after trimming from 
each end".

>
> Pat
>
>
> Prof Brian Ripley wrote:
>
>> There is only one _range_ mentioned, (0, 0.5).  I don't see how you 
>> can construe 'that range' to be a reference to anything other than 
>> (0, 0.5).
>>
>> And why do you suppose the description for argument 'trim' is 
>> referring to 'values' of a different argument?
>>
>> It is telling you what happens for values of trim < 0 or > 0.5: that 
>> is not information that it is appropriate to excise.
>>
>>
>> On Thu, 25 Oct 2007, Peter Dalgaard wrote:
>>
>>  
>>
>>> Liaw, Andy wrote:
>>>   
>>>> (I see this in both R-patched r43124 and R-devel r43233.)
>>>> In the Argument section of ?mean:
>>>>
>>>> trim     the fraction (0 to 0.5) of observations to be trimmed from 
>>>> each
>>>> end of x before the mean is computed. Values outside that range are
>>>> taken as the nearest endpoint.
>>>>
>>>> Then in the Value section:
>>>>
>>>> If trim is non-zero, a symmetrically trimmed mean is computed with a
>>>> fraction of trim observations deleted from each end before the mean is
>>>> computed.
>>>>
>>>> The description in "trim" to me sounds like Windsorizing, rather than
>>>> trimming.  Should that be edited?
>>>>
>>>>
>>>>     
>>> I think so:
>>>
>>>   
>>>> x <- sort(rnorm(10))
>>>> mean(x,trim=.1)
>>>>     
>>> [1] -0.6387413
>>>   
>>>> mean(x[2:9])
>>>>     
>>> [1] -0.6387413
>>>   
>>>> mean(x[c(2,2:9,9)]) # Winsorizing
>>>>     
>>> [1] -0.6204222
>>>
>>> So yes, it is trimming, not Winsorizing, and the last sentence in the
>>> description of "trim" is misleading and should be, well..., trimmed.
>>>
>>>
>>>   
>>
>>  
>>


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Sun Oct 28 15:01:55 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 28 Oct 2007 10:01:55 -0400
Subject: [Rd] meaning of "trim" in mean()
In-Reply-To: <47244B9A.8090108@pburns.seanet.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04D88433@usctmx1106.merck.com>	<4720993C.5030105@biostat.ku.dk>	<Pine.LNX.4.64.0710271814060.15370@gannet.stats.ox.ac.uk>
	<47244B9A.8090108@pburns.seanet.com>
Message-ID: <47249653.6000008@stats.uwo.ca>

On 28/10/2007 4:43 AM, Patrick Burns wrote:
> If the sentence in question were amended to:
> 
> Values of trim outside that range ...
> 
> then I think it would rule out the misinterpretation of
> the sentence.

Good suggestion.  I've changed it.

Duncan Murdoch

> 
> Pat
> 
> 
> Prof Brian Ripley wrote:
> 
>> There is only one _range_ mentioned, (0, 0.5).  I don't see how you can 
>> construe 'that range' to be a reference to anything other than (0, 0.5).
>>
>> And why do you suppose the description for argument 'trim' is referring to 
>> 'values' of a different argument?
>>
>> It is telling you what happens for values of trim < 0 or > 0.5: that is 
>> not information that it is appropriate to excise.
>>
>>
>> On Thu, 25 Oct 2007, Peter Dalgaard wrote:
>>
>>  
>>
>>> Liaw, Andy wrote:
>>>    
>>>
>>>> (I see this in both R-patched r43124 and R-devel r43233.)
>>>> In the Argument section of ?mean:
>>>>
>>>> trim     the fraction (0 to 0.5) of observations to be trimmed from each
>>>> end of x before the mean is computed. Values outside that range are
>>>> taken as the nearest endpoint.
>>>>
>>>> Then in the Value section:
>>>>
>>>> If trim is non-zero, a symmetrically trimmed mean is computed with a
>>>> fraction of trim observations deleted from each end before the mean is
>>>> computed.
>>>>
>>>> The description in "trim" to me sounds like Windsorizing, rather than
>>>> trimming.  Should that be edited?
>>>>
>>>>
>>>>      
>>>>
>>> I think so:
>>>
>>>    
>>>
>>>> x <- sort(rnorm(10))
>>>> mean(x,trim=.1)
>>>>      
>>>>
>>> [1] -0.6387413
>>>    
>>>
>>>> mean(x[2:9])
>>>>      
>>>>
>>> [1] -0.6387413
>>>    
>>>
>>>> mean(x[c(2,2:9,9)]) # Winsorizing
>>>>      
>>>>
>>> [1] -0.6204222
>>>
>>> So yes, it is trimming, not Winsorizing, and the last sentence in the
>>> description of "trim" is misleading and should be, well..., trimmed.
>>>
>>>
>>>    
>>>
>>  
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Oct 29 15:10:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Oct 2007 14:10:34 +0000 (GMT)
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
In-Reply-To: <20071027005017.3493A2834619@mail.pubhealth.ku.dk>
References: <20071027005017.3493A2834619@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0710291406400.930@auk.stats>

The problem is that the XtOpenDisplay call did not specify the display.
Easily fixed ....

On Sat, 27 Oct 2007, p.dalgaard at biostat.ku.dk wrote:

> Hin-Tak Leung wrote:
>> Peter Dalgaard wrote:
>>> brechbuehler at gmail.com wrote:
>>>> Full_Name: Christian Brechbuehler
>>>> Version: 2.4.1, 2.5.1, OS: Ubuntu GNU/Linux
>>>> Submission from: (NULL) (24.61.47.236)
>>>>
>>>>
>> <snipped>
>>>> Example (start R without DISPLAY from bash):
>>>>   % DISPLAY=3D R
>>>>  > x11("localhost:11.0")                        # this is my valid=20
>>>> DISPLAY
>>>>   Error: Couldn't find per display information
>>>>   %
>> <snipped>
>>>>  =20
>>> I see this on Fedora 7 too. I suspect that the earlier report was=20
>>> thought to be Mac specific.
>> <snipped>
>>
>> I was experimenting with xvfb last week and didn't see the catatrophic =
>
>> problem like that, so I tried again. Is it possible that this has=20
>> already been fixed in R 2.6.0 ? (I am on fedora 7, x86_64 as well).
>>
>> ------------------------------------------
>> $ export -n DISPLAY
>>
>> $ R
>> R version 2.6.0 (2007-10-03)
>> ...
>>> x11()
>> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1=20
>> else gamma,  :
>>   unable to start device X11
>> In addition: Warning message:
>> In x11() : unable to open connection to X11 display ''
>>> q()
>> Save workspace image? [y/n/c]: n
>> $ export DISPLAY=3D
>> $ R
>> R version 2.6.0 (2007-10-03)
>> ...
>>> x11()
>> Error in X11(display, width, height, pointsize, if (is.null(gamma)) 1=20
>> else gamma,  :
>>   unable to start device X11
>> In addition: Warning message:
>> In x11() : unable to open connection to X11 display ''
>>> q()
>> Save workspace image? [y/n/c]: n
>> --------------------------------------------------
>>
> You need x11() with a valid display to trigger the bug:
>
> [pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
> pd at 192.168.1.10's password:
> Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
> [pd at janus ~]$ echo $DISPLAY
> localhost:10.0
> [pd at janus ~]$ DISPLAY=3D R -q
> > x11("localhost:10.0")
> Error: Couldn't find per display information
> [pd at janus ~]$ uname -a
> Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007 x86_64=20
> x86_64 x86_64 GNU/Linux
> [pd at janus ~]$ cat /etc/issue
> Fedora release 7 (Moonshine)
> Kernel \r on an \m
>
>
> --=20
>   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
> 918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
> 907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Oct 29 16:27:43 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Oct 2007 15:27:43 +0000 (GMT)
Subject: [Rd] Bug with Cor(..., method='spearman") and by() (PR#9921)
In-Reply-To: <20070920212218.C2F27668EE@slim.kubism.ku.dk>
References: <20070920212218.C2F27668EE@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0710291453200.31865@gannet.stats.ox.ac.uk>

This is nothing whatsoever to do with by(), and it is cor, not Cor.
Try

X <- cbind(NA, 1:3)
cor(X, use = "complete")
cor(X, use = "complete", method="spearman")

In short, cor() behaves differently when given a vector of NAs.  That's 
perfectly reasonable, as the ranks are undefined.

Since

> cor(na.omit(X))
Error in cor(na.omit(X)) : 'x' is empty

I would say that consistency requires that both examples give an error.

On Thu, 20 Sep 2007, HDoran at air.org wrote:

> I posted this on R help, and a few others responded indicating they too
> were able to replicate the error as a function of missing data. I
> believe this should not be the case and hence and reporting it here.

But you have failed to explain to us why such an example must work: your 
'belief' is not relevant here.  As the FAQ says, do not report as a bug 
something you do not 'know for certain'.

> ### Code provided on R-Help by Ivar Herfindal
> # Simulate data
> testdata <- cbind.data.frame(gr=3Drep(letters[1:4], each=3D5), =
> aa=3Drnorm(20),
> bb=3Drnorm(20))
> # Introduce some missingness
> testdata[1:5, 2] <- NA
>
> # This works fine
> by(testdata[,c("aa", "bb")], testdata$gr, cor, use=3D"complete",
> method=3D"pearson")
>
> # This induces error
> by(testdata[,c("aa", "bb")], testdata$gr, cor, use=3D"complete",
> method=3D"spearman")
>
> Error in FUN(data[x, ], ...) : 'x' is empty
>
> ## Alternatively, we can try this
>
> # This works fine
> by(testdata[,c('aa', 'bb')], testdata$gr, cor, use=3D'complete',
> method=3D'pearson')
>
> ## This induces the same error
> by(testdata[,c('aa', 'bb')], testdata$gr, cor, use=3D'complete',
> method=3D'spearman')
>
> Error in FUN(data[x, ], ...) : 'x' is empty
>
> I am using Windows XP with session info below
>
> Harold Doran
>
>
>> sessionInfo()
> R version 2.5.0 (2007-04-23)=20
> i386-pc-mingw32=20
>
> locale:
> LC_COLLATE=3DEnglish_United States.1252;LC_CTYPE=3DEnglish_United
> States.1252;LC_MONETARY=3DEnglish_United
> States.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_United States.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"    =20
>
> other attached packages:
>     mlmRev        lme4      Matrix     lattice=20
>  "0.995-1" "0.99875-2" "0.99875-3"    "0.15-4"=20
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From osoong at bren.ucsb.edu  Mon Oct 29 16:55:02 2007
From: osoong at bren.ucsb.edu (Oliver Soong)
Date: Mon, 29 Oct 2007 08:55:02 -0700
Subject: [Rd] pairs, par
Message-ID: <7559d52e0710290855wdc0908eh64cbbac96cabc07d@mail.gmail.com>

Hi,

I posted over at R-help, and didn't get a response, but perhaps that
was the wrong forum for this question.  I'm having some confusion over
the coordinate system after using pairs.  I'm not interested in the
content of the actual pairs plot, although the number of pairs seems
to matter a bit.  I'm purely interested in knowing where subsequent
points will be plotted on the device.  However, after using pairs, the
par information (omd, fig, plt, and usr) don't reflect what points
does.  For example:

pairs(iris[1:5])
par(xpd = NA)
points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)
par(c("omd", "fig", "plt", "usr"))

The resulting plot shows that the corners of the are approximately
0.05 user coordinate units from the boundaries of the plot region.
According to par, though, there is a margin around the plotting region
that is clearly not symmetric and does not correspond to around 0.05
units.

If we use pairs(iris[1:2]) and repeat the rest, the corners are now
0.02 user coordinate units.  par provides the same information as
before.

So:
1. How do I figure out where coordinates I give to points will display
on the figure?
2. More generally (for my own understanding), why does the par
information not do what I expect?  Do I have some fundamental
misunderstanding of the arrangement of plotting, figure, display, and
margin regions within the device?  Is there a bug in pairs and/or par?

I'm using R 2.5.1, and this behavior occurs on a fresh R console.

Thanks!

Oliver


-- 
Oliver Soong
Donald Bren School of Environmental Science & Management
University of California, Santa Barbara
Santa Barbara, CA 93106-5131
805-893-7044 (office)
610-291-9706 (cell)


From tplate at acm.org  Mon Oct 29 17:56:49 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 29 Oct 2007 10:56:49 -0600
Subject: [Rd] pairs, par
In-Reply-To: <7559d52e0710290855wdc0908eh64cbbac96cabc07d@mail.gmail.com>
References: <7559d52e0710290855wdc0908eh64cbbac96cabc07d@mail.gmail.com>
Message-ID: <472610D1.4060900@acm.org>

I would look into the code for pairs().  Among other things, it sets and 
restores par(mfrow=...).  I suspect this is the relevant issue, not the 
use of pairs().  I would try to figure out what state a graphics device 
is in after resetting par("mfrow").  When I try the following (R 2.6.0 
patched, under Windows), I see a line on the plot, but not in a place 
that corresponds to the axis that were drawn by the 'plot()' command:

 > par(mfrow=c(2,2))
 > plot(1:2)
 > par(mfrow=c(1,1))
 > lines(1:2,1:2)
 >

(and if you want to be able to set up a new coordinate system on the 
plotting device to draw on top of the plot left by pairs(), look at 
par("new") & something like plot(0:1, type='n', axes=F, xlab=""))

hope this helps,

Tony Plate

Oliver Soong wrote:
> Hi,
>
> I posted over at R-help, and didn't get a response, but perhaps that
> was the wrong forum for this question.  I'm having some confusion over
> the coordinate system after using pairs.  I'm not interested in the
> content of the actual pairs plot, although the number of pairs seems
> to matter a bit.  I'm purely interested in knowing where subsequent
> points will be plotted on the device.  However, after using pairs, the
> par information (omd, fig, plt, and usr) don't reflect what points
> does.  For example:
>
> pairs(iris[1:5])
> par(xpd = NA)
> points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
> points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
> points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
> points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)
> par(c("omd", "fig", "plt", "usr"))
>
> The resulting plot shows that the corners of the are approximately
> 0.05 user coordinate units from the boundaries of the plot region.
> According to par, though, there is a margin around the plotting region
> that is clearly not symmetric and does not correspond to around 0.05
> units.
>
> If we use pairs(iris[1:2]) and repeat the rest, the corners are now
> 0.02 user coordinate units.  par provides the same information as
> before.
>
> So:
> 1. How do I figure out where coordinates I give to points will display
> on the figure?
> 2. More generally (for my own understanding), why does the par
> information not do what I expect?  Do I have some fundamental
> misunderstanding of the arrangement of plotting, figure, display, and
> margin regions within the device?  Is there a bug in pairs and/or par?
>
> I'm using R 2.5.1, and this behavior occurs on a fresh R console.
>
> Thanks!
>
> Oliver
>
>
>


From hin-tak.leung at cimr.cam.ac.uk  Mon Oct 29 18:29:06 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 29 Oct 2007 17:29:06 +0000
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
In-Reply-To: <47228A41.5050901@biostat.ku.dk>
References: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
	<472277D5.9080202@biostat.ku.dk> <472287D2.1020603@cimr.cam.ac.uk>
	<47228A41.5050901@biostat.ku.dk>
Message-ID: <47261862.2030903@cimr.cam.ac.uk>

Peter Dalgaard wrote:
<snipped>
> You need x11() with a valid display to trigger the bug:
> 
> [pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
> pd at 192.168.1.10's password:
> Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
> [pd at janus ~]$ echo $DISPLAY
> localhost:10.0
> [pd at janus ~]$ DISPLAY= R -q
>  > x11("localhost:10.0")
> Error: Couldn't find per display information
> [pd at janus ~]$ uname -a
> Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007 x86_64 
> x86_64 x86_64 GNU/Linux
> [pd at janus ~]$ cat /etc/issue
> Fedora release 7 (Moonshine)
> Kernel \r on an \m

Agh, sorry. Yes, x11() (with or without $DISPLAY set) doesn't
die catatrophically, x11("validinfo") does.

HTL


From osoong at bren.ucsb.edu  Mon Oct 29 18:54:18 2007
From: osoong at bren.ucsb.edu (Oliver Soong)
Date: Mon, 29 Oct 2007 10:54:18 -0700
Subject: [Rd] pairs, par
In-Reply-To: <472610D1.4060900@acm.org>
References: <7559d52e0710290855wdc0908eh64cbbac96cabc07d@mail.gmail.com>
	<472610D1.4060900@acm.org>
Message-ID: <7559d52e0710291054k4beadea6w7c4e8c957cc46dab@mail.gmail.com>

I dug around in pairs, and I think it has something to do with the
on.exit(par(opar)) bit:

f <- function() {
	opar <- par(mfrow = c(2, 2), mar = rep(0.5, 4), oma = rep(4, 4))
	on.exit(par(opar))
	for(i in 1:4) plot(0:1, 0:1)
	par(c("mfg", "omd", "fig", "plt", "usr"))
	print(opar)
}
f()
par(xpd = NA)
par(c("omd", "fig", "plt", "usr"))
points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)

My guess is that there are 2 sets of graphical parameters, the ones
stored in par and the ones used by the plotting functions.  Before
par(opar) gets called, the two are synchronized.  When par(opar) gets
called, we somehow set new values for par without changing the ones
used by the plotting functions, and the data used by points becomes
out of sync with the par information.

This is reflected in this much simpler example:

x11()
par(c("omd", "fig", "plt", "usr"))
points(0, 0)

Again, par is defined, but this time the data used by the plotting
functions has not been set, and an error occurs.

Thanks for the workaround suggestion.  I guess I can always define a
new plotting region to force par and the plotting data to
re-synchronize.  It might be nice if those two didn't go out of sync,
as I had assumed par would always be reliable.

Oliver


On 10/29/07, Tony Plate <tplate at acm.org> wrote:
> I would look into the code for pairs().  Among other things, it sets and
> restores par(mfrow=...).  I suspect this is the relevant issue, not the
> use of pairs().  I would try to figure out what state a graphics device
> is in after resetting par("mfrow").  When I try the following (R 2.6.0
> patched, under Windows), I see a line on the plot, but not in a place
> that corresponds to the axis that were drawn by the 'plot()' command:
>
>  > par(mfrow=c(2,2))
>  > plot(1:2)
>  > par(mfrow=c(1,1))
>  > lines(1:2,1:2)
>  >
>
> (and if you want to be able to set up a new coordinate system on the
> plotting device to draw on top of the plot left by pairs(), look at
> par("new") & something like plot(0:1, type='n', axes=F, xlab=""))
>
> hope this helps,
>
> Tony Plate
>
> Oliver Soong wrote:
> > Hi,
> >
> > I posted over at R-help, and didn't get a response, but perhaps that
> > was the wrong forum for this question.  I'm having some confusion over
> > the coordinate system after using pairs.  I'm not interested in the
> > content of the actual pairs plot, although the number of pairs seems
> > to matter a bit.  I'm purely interested in knowing where subsequent
> > points will be plotted on the device.  However, after using pairs, the
> > par information (omd, fig, plt, and usr) don't reflect what points
> > does.  For example:
> >
> > pairs(iris[1:5])
> > par(xpd = NA)
> > points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
> > points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
> > points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
> > points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)
> > par(c("omd", "fig", "plt", "usr"))
> >
> > The resulting plot shows that the corners of the are approximately
> > 0.05 user coordinate units from the boundaries of the plot region.
> > According to par, though, there is a margin around the plotting region
> > that is clearly not symmetric and does not correspond to around 0.05
> > units.
> >
> > If we use pairs(iris[1:2]) and repeat the rest, the corners are now
> > 0.02 user coordinate units.  par provides the same information as
> > before.
> >
> > So:
> > 1. How do I figure out where coordinates I give to points will display
> > on the figure?
> > 2. More generally (for my own understanding), why does the par
> > information not do what I expect?  Do I have some fundamental
> > misunderstanding of the arrangement of plotting, figure, display, and
> > margin regions within the device?  Is there a bug in pairs and/or par?
> >
> > I'm using R 2.5.1, and this behavior occurs on a fresh R console.
> >
> > Thanks!
> >
> > Oliver
> >
> >
> >
>
>


-- 
Oliver Soong
Donald Bren School of Environmental Science & Management
University of California, Santa Barbara
Santa Barbara, CA 93106-5131
805-893-7044 (office)
610-291-9706 (cell)


From p.dalgaard at biostat.ku.dk  Mon Oct 29 20:12:44 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 29 Oct 2007 20:12:44 +0100
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
In-Reply-To: <47261862.2030903@cimr.cam.ac.uk>
References: <20071026223005.3CF422834619@mail.pubhealth.ku.dk>
	<472277D5.9080202@biostat.ku.dk> <472287D2.1020603@cimr.cam.ac.uk>
	<47228A41.5050901@biostat.ku.dk> <47261862.2030903@cimr.cam.ac.uk>
Message-ID: <472630AC.30501@biostat.ku.dk>

Hin-Tak Leung wrote:
> Peter Dalgaard wrote:
> <snipped>
>> You need x11() with a valid display to trigger the bug:
>>
>> [pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
>> pd at 192.168.1.10's password:
>> Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
>> [pd at janus ~]$ echo $DISPLAY
>> localhost:10.0
>> [pd at janus ~]$ DISPLAY= R -q
>>  > x11("localhost:10.0")
>> Error: Couldn't find per display information
>> [pd at janus ~]$ uname -a
>> Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007 
>> x86_64 x86_64 x86_64 GNU/Linux
>> [pd at janus ~]$ cat /etc/issue
>> Fedora release 7 (Moonshine)
>> Kernel \r on an \m
>
> Agh, sorry. Yes, x11() (with or without $DISPLAY set) doesn't
> die catatrophically, x11("validinfo") does.
>
> HTL
The culprit would seem to be this bit of devX11.c

1302                    xtdpy = XtOpenDisplay(app_con, NULL, "r_x11", 
"R_x11",
1303                                          NULL, 0, &zero, NULL);
1304                    toplevel = XtAppCreateShell(NULL, "R_x11",

The 2nd arg to XtOpenDisplay is listed as display_string, so passing a 
NULL here seems like trouble when the default ways of finding the 
display do not work.

Looks like a fix is to insert p instead of NULL. (Tested rudimentarily.)



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Mon Oct 29 20:15:46 2007
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Mon, 29 Oct 2007 20:15:46 +0100 (CET)
Subject: [Rd] (PR#10379) Re:  x11(....) kills R without DISPLAY
Message-ID: <20071029191546.289EA282EFF6@mail.pubhealth.ku.dk>

Hin-Tak Leung wrote:
> Peter Dalgaard wrote:
> <snipped>
>> You need x11() with a valid display to trigger the bug:
>>
>> [pd at titmouse2 BUILD]$ ssh -Y 192.168.1.10
>> pd at 192.168.1.10's password:
>> Last login: Sat Oct 27 02:40:16 2007 from 192.168.1.11
>> [pd at janus ~]$ echo $DISPLAY
>> localhost:10.0
>> [pd at janus ~]$ DISPLAY=3D R -q
>>  > x11("localhost:10.0")
>> Error: Couldn't find per display information
>> [pd at janus ~]$ uname -a
>> Linux janus 2.6.22.9-91.fc7 #1 SMP Thu Sep 27 20:47:39 EDT 2007=20
>> x86_64 x86_64 x86_64 GNU/Linux
>> [pd at janus ~]$ cat /etc/issue
>> Fedora release 7 (Moonshine)
>> Kernel \r on an \m
>
> Agh, sorry. Yes, x11() (with or without $DISPLAY set) doesn't
> die catatrophically, x11("validinfo") does.
>
> HTL
The culprit would seem to be this bit of devX11.c

1302                    xtdpy =3D XtOpenDisplay(app_con, NULL, "r_x11",=20
"R_x11",
1303                                          NULL, 0, &zero, NULL);
1304                    toplevel =3D XtAppCreateShell(NULL, "R_x11",

The 2nd arg to XtOpenDisplay is listed as display_string, so passing a=20
NULL here seems like trouble when the default ways of finding the=20
display do not work.

Looks like a fix is to insert p instead of NULL. (Tested rudimentarily.)



--=20
   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907


From elagin at wias-berlin.de  Mon Oct 29 23:45:36 2007
From: elagin at wias-berlin.de (Mstislav Elagin)
Date: Mon, 29 Oct 2007 23:45:36 +0100
Subject: [Rd] a package depending on other packages does not pass checking
	on windows
Message-ID: <47266290.8050401@wias-berlin.de>

Dear developers,

I am writing a package that depends on some other packages. The
dependencies are stated in the `description' file under "Depends". They
are installed in my private library, which is pointed to by setting
R_LIBS in .Renviron, and are available if R is started normally.
However, when I try to `R CMD check' my package, R complains about the
dependencies being not available. I believe the reason is the option
--vanilla set in $R_HOME/bin/check that prevents R from reading my
.Renviron.
This problem manifests itself with R 2.5.1 under Windows XP but not with
the same version under Linux. (Yes, I know this is not the latest
version, sorry about that :) )

How do I convince `R CMD check' to find the packages installed in the
private library?

Thanks in advance for your help!

WBR

Mstislav Elagin


From ggrothendieck at gmail.com  Mon Oct 29 23:51:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 29 Oct 2007 18:51:45 -0400
Subject: [Rd] pairs, par
In-Reply-To: <7559d52e0710291054k4beadea6w7c4e8c957cc46dab@mail.gmail.com>
References: <7559d52e0710290855wdc0908eh64cbbac96cabc07d@mail.gmail.com>
	<472610D1.4060900@acm.org>
	<7559d52e0710291054k4beadea6w7c4e8c957cc46dab@mail.gmail.com>
Message-ID: <971536df0710291551k3bd56829j43048d8a104e69e5@mail.gmail.com>

This hack will disable the on.exit temporarily:

pairs.data.frame <- function(x, ...) {
	on.exit <- function(...) {}
	environment(pairs.default) <- environment()
	pairs.default(x, ...)
}
pairs(iris)
par("usr")
# add points to lower right square
points(1:10/10, 1:10/10, col = "red")


On 10/29/07, Oliver Soong <osoong at bren.ucsb.edu> wrote:
> I dug around in pairs, and I think it has something to do with the
> on.exit(par(opar)) bit:
>
> f <- function() {
>        opar <- par(mfrow = c(2, 2), mar = rep(0.5, 4), oma = rep(4, 4))
>        on.exit(par(opar))
>        for(i in 1:4) plot(0:1, 0:1)
>        par(c("mfg", "omd", "fig", "plt", "usr"))
>        print(opar)
> }
> f()
> par(xpd = NA)
> par(c("omd", "fig", "plt", "usr"))
> points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
> points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
> points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
> points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)
>
> My guess is that there are 2 sets of graphical parameters, the ones
> stored in par and the ones used by the plotting functions.  Before
> par(opar) gets called, the two are synchronized.  When par(opar) gets
> called, we somehow set new values for par without changing the ones
> used by the plotting functions, and the data used by points becomes
> out of sync with the par information.
>
> This is reflected in this much simpler example:
>
> x11()
> par(c("omd", "fig", "plt", "usr"))
> points(0, 0)
>
> Again, par is defined, but this time the data used by the plotting
> functions has not been set, and an error occurs.
>
> Thanks for the workaround suggestion.  I guess I can always define a
> new plotting region to force par and the plotting data to
> re-synchronize.  It might be nice if those two didn't go out of sync,
> as I had assumed par would always be reliable.
>
> Oliver
>
>
> On 10/29/07, Tony Plate <tplate at acm.org> wrote:
> > I would look into the code for pairs().  Among other things, it sets and
> > restores par(mfrow=...).  I suspect this is the relevant issue, not the
> > use of pairs().  I would try to figure out what state a graphics device
> > is in after resetting par("mfrow").  When I try the following (R 2.6.0
> > patched, under Windows), I see a line on the plot, but not in a place
> > that corresponds to the axis that were drawn by the 'plot()' command:
> >
> >  > par(mfrow=c(2,2))
> >  > plot(1:2)
> >  > par(mfrow=c(1,1))
> >  > lines(1:2,1:2)
> >  >
> >
> > (and if you want to be able to set up a new coordinate system on the
> > plotting device to draw on top of the plot left by pairs(), look at
> > par("new") & something like plot(0:1, type='n', axes=F, xlab=""))
> >
> > hope this helps,
> >
> > Tony Plate
> >
> > Oliver Soong wrote:
> > > Hi,
> > >
> > > I posted over at R-help, and didn't get a response, but perhaps that
> > > was the wrong forum for this question.  I'm having some confusion over
> > > the coordinate system after using pairs.  I'm not interested in the
> > > content of the actual pairs plot, although the number of pairs seems
> > > to matter a bit.  I'm purely interested in knowing where subsequent
> > > points will be plotted on the device.  However, after using pairs, the
> > > par information (omd, fig, plt, and usr) don't reflect what points
> > > does.  For example:
> > >
> > > pairs(iris[1:5])
> > > par(xpd = NA)
> > > points(0 - 0.01 * 1:100, 0 - 0.01 * 1:100)
> > > points(0 - 0.01 * 1:100, 1 + 0.01 * 1:100)
> > > points(1 + 0.01 * 1:100, 0 - 0.01 * 1:100)
> > > points(1 + 0.01 * 1:100, 1 + 0.01 * 1:100)
> > > par(c("omd", "fig", "plt", "usr"))
> > >
> > > The resulting plot shows that the corners of the are approximately
> > > 0.05 user coordinate units from the boundaries of the plot region.
> > > According to par, though, there is a margin around the plotting region
> > > that is clearly not symmetric and does not correspond to around 0.05
> > > units.
> > >
> > > If we use pairs(iris[1:2]) and repeat the rest, the corners are now
> > > 0.02 user coordinate units.  par provides the same information as
> > > before.
> > >
> > > So:
> > > 1. How do I figure out where coordinates I give to points will display
> > > on the figure?
> > > 2. More generally (for my own understanding), why does the par
> > > information not do what I expect?  Do I have some fundamental
> > > misunderstanding of the arrangement of plotting, figure, display, and
> > > margin regions within the device?  Is there a bug in pairs and/or par?
> > >
> > > I'm using R 2.5.1, and this behavior occurs on a fresh R console.
> > >
> > > Thanks!
> > >
> > > Oliver
> > >
> > >
> > >
> >
> >
>
>
> --
> Oliver Soong
> Donald Bren School of Environmental Science & Management
> University of California, Santa Barbara
> Santa Barbara, CA 93106-5131
> 805-893-7044 (office)
> 610-291-9706 (cell)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From khansen at stat.Berkeley.EDU  Tue Oct 30 00:17:55 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 29 Oct 2007 16:17:55 -0700
Subject: [Rd] a package depending on other packages does not pass
	checking on windows
In-Reply-To: <47266290.8050401@wias-berlin.de>
References: <47266290.8050401@wias-berlin.de>
Message-ID: <7CE883A8-7A3C-42EB-BFB0-ED6A454F5C83@stat.berkeley.edu>

I have been bitten by this myself. For that reason I have stopped  
using .Renviron.

I believe the behavior is the same under Linux and Windows, so I  
think you might have a different setup on the two machines.

You can fix it by explicitly setting
   R_LIBS
as an environment variable or by putting the following in your .Rprofile
   .libPaths(SOMEDIR)
But of these are accessed by R CMD ...

Kasper

On Oct 29, 2007, at 3:45 PM, Mstislav Elagin wrote:

> Dear developers,
>
> I am writing a package that depends on some other packages. The
> dependencies are stated in the `description' file under "Depends".  
> They
> are installed in my private library, which is pointed to by setting
> R_LIBS in .Renviron, and are available if R is started normally.
> However, when I try to `R CMD check' my package, R complains about the
> dependencies being not available. I believe the reason is the option
> --vanilla set in $R_HOME/bin/check that prevents R from reading my
> .Renviron.
> This problem manifests itself with R 2.5.1 under Windows XP but not  
> with
> the same version under Linux. (Yes, I know this is not the latest
> version, sorry about that :) )
>
> How do I convince `R CMD check' to find the packages installed in the
> private library?
>
> Thanks in advance for your help!
>
> WBR
>
> Mstislav Elagin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawremi at iastate.edu  Tue Oct 30 01:41:43 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Mon, 29 Oct 2007 19:41:43 -0500
Subject: [Rd] Using SJava? (was R-devel Digest, Vol 56, Issue 27)
In-Reply-To: <Pine.LNX.4.64.0710281238140.16703@gannet.stats.ox.ac.uk>
References: <mailman.15.1193569202.21167.r-devel@r-project.org>
	<d1bf3ebe0710280533m33d9c099jaa101fa0cc386421@mail.gmail.com>
	<Pine.LNX.4.64.0710281238140.16703@gannet.stats.ox.ac.uk>
Message-ID: <509e0620710291741g36a57ba6l1e3123833e15a224@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071029/3df40fb8/attachment.pl 

From martin.kober at gmail.com  Tue Oct 30 02:00:07 2007
From: martin.kober at gmail.com (martin.kober at gmail.com)
Date: Tue, 30 Oct 2007 02:00:07 +0100 (CET)
Subject: [Rd] R can't source() long lines (PR#10383)
Message-ID: <20071030010007.19D8F282EFF1@mail.pubhealth.ku.dk>

Full_Name: Martin Kober
Version: 2.6.0
OS: Vista & Linux
Submission from: (NULL) (137.208.185.169)


Hi!

I just stumbled upon a problem with file source()ing:

R will fail to source a file if it contains lines longer than about 8192 bytes
("input buffer overflow").

While it's save to say that human-written code won't contain lines that long,
dump()ed data structures may reasonably contain strings longer than that (as in
my case).

What's more, R will happily help you to create such files:

x = paste(rep("12345678", 1024), collapse="")
dump("x")
source("dumpdata.R") ## this fails (on Linux & Vista)

I'm now using save/load, which is probably better in that case anyway. Still, I
would be nice if source() worked or at least dump() would break lines to avoid
this issue.

Best regards,
Martin Kober


From brechbuehler at gmail.com  Tue Oct 30 03:22:17 2007
From: brechbuehler at gmail.com (=?ISO-8859-1?Q?Christian_Brechb=FChler?=)
Date: Mon, 29 Oct 2007 22:22:17 -0400
Subject: [Rd] (PR#10379) Re: x11(....) kills R without DISPLAY
In-Reply-To: <20071029191546.289EA282EFF6@mail.pubhealth.ku.dk>
References: <20071029191546.289EA282EFF6@mail.pubhealth.ku.dk>
Message-ID: <c0177e5a0710291922n1e853077pfc7ea4348473e06e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071029/625a6c46/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Oct 30 08:02:19 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Oct 2007 07:02:19 +0000 (GMT)
Subject: [Rd] a package depending on other packages does not pass
 checking on windows
In-Reply-To: <47266290.8050401@wias-berlin.de>
References: <47266290.8050401@wias-berlin.de>
Message-ID: <Pine.LNX.4.64.0710300658560.600@gannet.stats.ox.ac.uk>

>From the 'Writing R Extensions' manual:

   R CMD check and R CMD build run R with
   --vanilla, so none of the user's startup files are read.  If
   you need R_LIBS set (to find packages in a non-standard library)
   you will need to set it in the environment.

so 'the problem' is your not reading the documentation.

On Mon, 29 Oct 2007, Mstislav Elagin wrote:

> Dear developers,
>
> I am writing a package that depends on some other packages. The
> dependencies are stated in the `description' file under "Depends". They
> are installed in my private library, which is pointed to by setting
> R_LIBS in .Renviron, and are available if R is started normally.
> However, when I try to `R CMD check' my package, R complains about the
> dependencies being not available. I believe the reason is the option
> --vanilla set in $R_HOME/bin/check that prevents R from reading my
> .Renviron.
> This problem manifests itself with R 2.5.1 under Windows XP but not with
> the same version under Linux. (Yes, I know this is not the latest
> version, sorry about that :) )
>
> How do I convince `R CMD check' to find the packages installed in the
> private library?
>
> Thanks in advance for your help!
>
> WBR
>
> Mstislav Elagin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Oct 30 08:10:16 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 30 Oct 2007 08:10:16 +0100 (CET)
Subject: [Rd] R can't source() long lines (PR#10383)
Message-ID: <20071030071016.54991282EFF1@mail.pubhealth.ku.dk>

This is as documented in ?source, and so is not a bug.

On Tue, 30 Oct 2007, martin.kober at gmail.com wrote:

> Full_Name: Martin Kober
> Version: 2.6.0
> OS: Vista & Linux
> Submission from: (NULL) (137.208.185.169)
>
>
> Hi!
>
> I just stumbled upon a problem with file source()ing:
>
> R will fail to source a file if it contains lines longer than about 8192 bytes
> ("input buffer overflow").
>
> While it's save to say that human-written code won't contain lines that long,
> dump()ed data structures may reasonably contain strings longer than that (as in
> my case).
>
> What's more, R will happily help you to create such files:
>
> x = paste(rep("12345678", 1024), collapse="")
> dump("x")
> source("dumpdata.R") ## this fails (on Linux & Vista)
>
> I'm now using save/load, which is probably better in that case anyway. 
> Still, I would be nice if source() worked or at least dump() would break 
> lines to avoid this issue.

It would be even nicer if users read the documentation rather than 
expected the developers to do so for them.

> Best regards,
> Martin Kober
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From martin.kober at gmail.com  Tue Oct 30 11:20:13 2007
From: martin.kober at gmail.com (martin.kober at gmail.com)
Date: Tue, 30 Oct 2007 11:20:13 +0100 (CET)
Subject: [Rd] R can't source() long lines (PR#10383)
Message-ID: <20071030102013.6EED92834611@mail.pubhealth.ku.dk>

On 10/30/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> This is as documented in ?source, and so is not a bug.
Indeed. You are of course correct, sorry I missed that.

What still remains is that dump() creates a file that won't source,
without warning or stopping (since the output is basically useless).
Note that ?dump states that "A warning is issued if it is likely that
problems will arise" (in different context, but still).

Best Regards

> On Tue, 30 Oct 2007, martin.kober at gmail.com wrote:
>
> > Full_Name: Martin Kober
> > Version: 2.6.0
> > OS: Vista & Linux
> > Submission from: (NULL) (137.208.185.169)
> >
> >
> > Hi!
> >
> > I just stumbled upon a problem with file source()ing:
> >
> > R will fail to source a file if it contains lines longer than about 8192 bytes
> > ("input buffer overflow").
> >
> > While it's save to say that human-written code won't contain lines that long,
> > dump()ed data structures may reasonably contain strings longer than that (as in
> > my case).
> >
> > What's more, R will happily help you to create such files:
> >
> > x = paste(rep("12345678", 1024), collapse="")
> > dump("x")
> > source("dumpdata.R") ## this fails (on Linux & Vista)
> >
> > I'm now using save/load, which is probably better in that case anyway.
> > Still, I would be nice if source() worked or at least dump() would break
> > lines to avoid this issue.
>
> It would be even nicer if users read the documentation rather than
> expected the developers to do so for them.
>
> > Best regards,
> > Martin Kober
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From jarioksa at sun3.oulu.fi  Tue Oct 30 12:09:06 2007
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 30 Oct 2007 13:09:06 +0200
Subject: [Rd] R can't source() long lines (PR#10383)
In-Reply-To: <20071030071016.54991282EFF1@mail.pubhealth.ku.dk>
References: <20071030071016.54991282EFF1@mail.pubhealth.ku.dk>
Message-ID: <1193742546.22591.19.camel@biol102145.oulu.fi>


On Tue, 2007-10-30 at 08:10 +0100, ripley at stats.ox.ac.uk wrote:
> This is as documented in ?source, and so is not a bug.
> 
This gives us a FAQ answer:

Q: What is the difference between a feature and a bug?

A: Features are documented, bugs are undocumented. If it is a bug, it is
either a bug in a function or a bug in the documentation (usually the
latter).

cheers, jari oksanen


From smitropa at tgen.org  Tue Oct 30 19:19:39 2007
From: smitropa at tgen.org (sotiris)
Date: Tue, 30 Oct 2007 11:19:39 -0700 (PDT)
Subject: [Rd] Library file for the R engine in Windows?
In-Reply-To: <000801c71882$0b6e46a0$0e010a0a@headquarters.silicoinsights>
References: <004601c717ed$24e90f10$0e010a0a@headquarters.silicoinsights>
	<Pine.LNX.4.64.0612050638370.7721@gannet.stats.ox.ac.uk>
	<000801c71882$0b6e46a0$0e010a0a@headquarters.silicoinsights>
Message-ID: <13492792.post@talk.nabble.com>


Hello,  I was able to create the Rdll.lib file.  However, I get the following
linking error message when I try to build my VC++ project.

The line that the linker is complaining about is calling the pnorm function.

GenePoolAnalysis.obj : error LNK2019: unresolved external symbol _pnorm5
referenced in function...

The offending line of code is
PValue = 2*pnorm(-1.0*TestStatistic, 0.0, 1.0, 1, 0);

Where you able to use R functions?

Euxaristo :)



Christos Hatzis wrote:
> 
> Thank you.
> 
> I am using the **free** Microsoft Visual C++ Toolkit 2003.  The Rdll.lib
> library builds successfully following the instructions in README.packages.
> One potential caveat is that lib.exe that is needed to build the library
> from R.exp is not part of the free toolkit.  However, a workaround is
> possible as 'lib' is equivalent to 'link /lib':
> 
> pexports R.dll > R.exp
> link /lib /def:R.exp /machine:x86 /out:Rdll.lib
> 
> -Christos
> 
> Christos Hatzis, Ph.D.
> Nuvera Biosciences, Inc.
> 400 West Cummings Park
> Suite 5350
> Woburn, MA 01801
> Tel: 781-938-3830
> www.nuverabio.com
>  
> 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Tuesday, December 05, 2006 1:42 AM
> To: Christos Hatzis
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Library file for the R engine in Windows?
> 
> This is discussed in README.packages: yes you do need to build an import
> library for VC++6 (don't know for sure about later versions).  The
> recommended route is to build it from the sources, but pexports.exe from
> mingw-utils can usually be used.
> 
> On Mon, 4 Dec 2006, Christos Hatzis wrote:
> 
>> Hi,
>>
>> I am trying to use dynamic memory allocation in the C code to be 
>> called by R through the .C interface.
>> I have used R_alloc as explained in the Writing R Extensions and 
>> included the R.h header.
>> The program compiles fine but fails when linking.  Obviously it needs 
>> a library file where R_alloc is found.
>> I have tried to link by adding R.dll to list of files at the end of 
>> the link command but that did not work either.
>>
>> The S Programming book mentions that a library Rdll.lib needs to be 
>> built from source, but I am not sure if this is still the recommended 
>> route.
>>
>> I am using Microsoft Visual C++ Toolkit in Windows XP Pro.
>> Thank you for any advice.
>>
>> Christos Hatzis, Ph.D.
>> Nuvera Biosciences, Inc.
>> 400 West Cummings Park
>> Suite 5350
>> Woburn, MA 01801
>> Tel: 781-938-3830
>> www.nuverabio.com <http://www.nuverabio.com/>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Library-file-for-the-R-engine-in-Windows--tf2757219.html#a13492792
Sent from the R devel mailing list archive at Nabble.com.


From dusa.adrian at gmail.com  Wed Oct 31 00:31:17 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Wed, 31 Oct 2007 01:31:17 +0200
Subject: [Rd] slow tcl/tk
Message-ID: <200710310131.17238.dusa.adrian@gmail.com>


Dear list,

Building my QCAGUI package using Rcmdr 1.3.0, under R 2.6.0 (using Kubuntu 
Gutsy) I noticed the library starts visibly slower than... somewhere in the 
past.

I used the same version of Rcmdr under previous versions of R and the tcl/tk 
window used to open instantly. Under the current version though, the window 
take seconds to open: first it builds the base window, then the menus and 
finally the complete window.

The whole process takes about five seconds.
I don't think it has anything to do with the Linux version, because I noticed 
the same behavior under the previous one as well.

Is there something changed about tcl/tk in R 2.6.0?

Thanks in advance,
Adrian

-- 
Adrian Dusa
University of Bucharest
Faculty of Sociology and Social Work
9, Schitu Magureanu Bd.
Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101


From schmidb at ibe.med.uni-muenchen.de  Wed Oct 31 13:52:08 2007
From: schmidb at ibe.med.uni-muenchen.de (Markus Schmidberger)
Date: Wed, 31 Oct 2007 13:52:08 +0100
Subject: [Rd] Rmpi, mpi.irecv.Robj
Message-ID: <47287A78.4000206@ibe.med.uni-muenchen.de>

Hello,

in the package "Rmpi" (Version 0.5-5) I am missing the nonblocking 
function "mpi.irecv.Robj".
Is there any reason for not having this function?

Best
Markus

-- 
Dipl.-Tech. Math. Markus Schmidberger

Ludwig-Maximilians-Universit?t M?nchen
IBE - Institut f?r medizinische Informationsverarbeitung,
Biometrie und Epidemiologie
Marchioninistr. 15, D-81377 Muenchen
URL: http://ibe.web.med.uni-muenchen.de 
Mail: Markus.Schmidberger [at] ibe.med.uni-muenchen.de


From jfox at mcmaster.ca  Wed Oct 31 14:36:42 2007
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 31 Oct 2007 09:36:42 -0400
Subject: [Rd] slow tcl/tk
In-Reply-To: <200710310131.17238.dusa.adrian@gmail.com>
Message-ID: <6bpls7$4qv0le@toip6.srvr.bell.ca>

Dear r-devel list members,

As Adrian is aware, I've observed the same behaviour in R 2.6.0, in my case
under Ubuntu Gutsy. It's my impression that the slowness of dialogs to
display is true more generally of tcltk windows, but is particularly
apparent for the main Rcmdr window because, I suspect, of its complexity.

Since I'd like to insure that the Rcmdr works reasonably well under Linux
systems, it would help to know the source of the problem.

Thanks,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Adrian Dusa
> Sent: Tuesday, October 30, 2007 7:31 PM
> To: r-devel at r-project.org
> Subject: [Rd] slow tcl/tk
> 
> 
> Dear list,
> 
> Building my QCAGUI package using Rcmdr 1.3.0, under R 2.6.0 
> (using Kubuntu
> Gutsy) I noticed the library starts visibly slower than... 
> somewhere in the past.
> 
> I used the same version of Rcmdr under previous versions of R 
> and the tcl/tk window used to open instantly. Under the 
> current version though, the window take seconds to open: 
> first it builds the base window, then the menus and finally 
> the complete window.
> 
> The whole process takes about five seconds.
> I don't think it has anything to do with the Linux version, 
> because I noticed the same behavior under the previous one as well.
> 
> Is there something changed about tcl/tk in R 2.6.0?
> 
> Thanks in advance,
> Adrian
> 
> --
> Adrian Dusa
> University of Bucharest
> Faculty of Sociology and Social Work
> 9, Schitu Magureanu Bd.
> Bucharest sector 5
> Romania
> Tel./Fax: +40 21 3126618 \
>           +40 21 3120210 / int.101
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From P.Dalgaard at biostat.ku.dk  Wed Oct 31 14:53:36 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 31 Oct 2007 14:53:36 +0100
Subject: [Rd] slow tcl/tk
In-Reply-To: <200710310131.17238.dusa.adrian@gmail.com>
References: <200710310131.17238.dusa.adrian@gmail.com>
Message-ID: <472888E0.1000003@biostat.ku.dk>

Adrian Dusa wrote:
> Dear list,
>
> Building my QCAGUI package using Rcmdr 1.3.0, under R 2.6.0 (using Kubuntu 
> Gutsy) I noticed the library starts visibly slower than... somewhere in the 
> past.
>
> I used the same version of Rcmdr under previous versions of R and the tcl/tk 
> window used to open instantly. Under the current version though, the window 
> take seconds to open: first it builds the base window, then the menus and 
> finally the complete window.
>
> The whole process takes about five seconds.
> I don't think it has anything to do with the Linux version, because I noticed 
> the same behavior under the previous one as well.
>
> Is there something changed about tcl/tk in R 2.6.0?
>
>   
Hmm, there's an event loop messup which was fixed in R-patched. The main
effect of that one was that scrollbars could go crazy. Not sure whether
it might cause your kind of symptoms, but you might check out the fixed
version.

It doesn't seem to make much of a difference here. Rather, I suspect
that Rcmdr itself got changed and a number of things that used to be
fixed are now generated programmatically. There's certainly a lot of
eval(parse(...)) stuff going on. (This sort of code always makes me a
little suspicious, but I haven't by far studied it well enough to say
whether there might be a more efficient way.)

> Thanks in advance,
> Adrian
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Wed Oct 31 14:55:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Oct 2007 13:55:22 +0000 (GMT)
Subject: [Rd] slow tcl/tk
In-Reply-To: <6bpls7$4qv0le@toip6.srvr.bell.ca>
References: <6bpls7$4qv0le@toip6.srvr.bell.ca>
Message-ID: <Pine.LNX.4.64.0710311354540.7824@gannet.stats.ox.ac.uk>

On Wed, 31 Oct 2007, John Fox wrote:

> Dear r-devel list members,
>
> As Adrian is aware, I've observed the same behaviour in R 2.6.0, in my case
> under Ubuntu Gutsy. It's my impression that the slowness of dialogs to
> display is true more generally of tcltk windows, but is particularly
> apparent for the main Rcmdr window because, I suspect, of its complexity.
>
> Since I'd like to insure that the Rcmdr works reasonably well under Linux
> systems, it would help to know the source of the problem.

We think it is solved in R-patched: can you try that?

>
> Thanks,
> John
>
> --------------------------------
> John Fox, Professor
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> --------------------------------
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Adrian Dusa
>> Sent: Tuesday, October 30, 2007 7:31 PM
>> To: r-devel at r-project.org
>> Subject: [Rd] slow tcl/tk
>>
>>
>> Dear list,
>>
>> Building my QCAGUI package using Rcmdr 1.3.0, under R 2.6.0
>> (using Kubuntu
>> Gutsy) I noticed the library starts visibly slower than...
>> somewhere in the past.
>>
>> I used the same version of Rcmdr under previous versions of R
>> and the tcl/tk window used to open instantly. Under the
>> current version though, the window take seconds to open:
>> first it builds the base window, then the menus and finally
>> the complete window.
>>
>> The whole process takes about five seconds.
>> I don't think it has anything to do with the Linux version,
>> because I noticed the same behavior under the previous one as well.
>>
>> Is there something changed about tcl/tk in R 2.6.0?
>>
>> Thanks in advance,
>> Adrian
>>
>> --
>> Adrian Dusa
>> University of Bucharest
>> Faculty of Sociology and Social Work
>> 9, Schitu Magureanu Bd.
>> Bucharest sector 5
>> Romania
>> Tel./Fax: +40 21 3126618 \
>>           +40 21 3120210 / int.101
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From schmidb at ibe.med.uni-muenchen.de  Wed Oct 31 15:50:14 2007
From: schmidb at ibe.med.uni-muenchen.de (Markus Schmidberger)
Date: Wed, 31 Oct 2007 15:50:14 +0100
Subject: [Rd] snow, mpi.isend
Message-ID: <47289626.1000402@ibe.med.uni-muenchen.de>

Hello,

in the package "snow" there will be used mpi.send in the function 
sendData.MPInode. Why you do not use the nonblocking function mpi.isend? 
This will be much faster.

The same is for recvData. But in rmpi the function "mpi.irecv.Robj" is 
still missing (see Mail "Rmpi, mpi.irecv.Robj")

(I have some problems with the mailinglist. I all the time got back the 
message: "Message rejected by filter rule match")

Best
Markus Schmidberger

-- 
Dipl.-Tech. Math. Markus Schmidberger

Ludwig-Maximilians-Universit?t M?nchen
IBE - Institut f?r medizinische Informationsverarbeitung,
Biometrie und Epidemiologie
Marchioninistr. 15, D-81377 Muenchen
URL: http://ibe.web.med.uni-muenchen.de 
Mail: Markus.Schmidberger [at] ibe.med.uni-muenchen.de


From jfox at mcmaster.ca  Wed Oct 31 16:12:57 2007
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 31 Oct 2007 11:12:57 -0400
Subject: [Rd] slow tcl/tk
In-Reply-To: <472888E0.1000003@biostat.ku.dk>
Message-ID: <6bpki0$7cf23r@toip3.srvr.bell.ca>

Dear Peter,

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Wednesday, October 31, 2007 9:54 AM
> To: Adrian Dusa
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] slow tcl/tk
> 
> Adrian Dusa wrote:
> > Dear list,
> >
> > Building my QCAGUI package using Rcmdr 1.3.0, under R 2.6.0 (using 
> > Kubuntu
> > Gutsy) I noticed the library starts visibly slower than... 
> somewhere 
> > in the past.
> >
> > I used the same version of Rcmdr under previous versions of 
> R and the 
> > tcl/tk window used to open instantly. Under the current version 
> > though, the window take seconds to open: first it builds the base 
> > window, then the menus and finally the complete window.
> >
> > The whole process takes about five seconds.
> > I don't think it has anything to do with the Linux version, 
> because I 
> > noticed the same behavior under the previous one as well.
> >
> > Is there something changed about tcl/tk in R 2.6.0?
> >
> >   
> Hmm, there's an event loop messup which was fixed in 
> R-patched. The main effect of that one was that scrollbars 
> could go crazy. Not sure whether it might cause your kind of 
> symptoms, but you might check out the fixed version.
> 
> It doesn't seem to make much of a difference here. Rather, I 
> suspect that Rcmdr itself got changed and a number of things 
> that used to be fixed are now generated programmatically. 

It's possible that I'm missing something, but I don't think that there have
been recent changes to the Rcmdr that would account for this difference (and
note that I don't see it under Windows). In particular, I think that the
change coincided with R-2.6.0 (which seems to be Adrian's experience too).

> There's certainly a lot of
> eval(parse(...)) stuff going on. (This sort of code always 
> makes me a little suspicious, but I haven't by far studied it 
> well enough to say whether there might be a more efficient way.)

The awkward eval-parses have always been there. There's probably a better
way to do at least some of this, but I haven't been able to think of it.

Regards,
 John

> 
> > Thanks in advance,
> > Adrian
> >
> >   
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From hyu at stats.uwo.ca  Wed Oct 31 14:55:47 2007
From: hyu at stats.uwo.ca (Hao Yu)
Date: Wed, 31 Oct 2007 09:55:47 -0400 (EDT)
Subject: [Rd] Rmpi, mpi.irecv.Robj
In-Reply-To: <47287A78.4000206@ibe.med.uni-muenchen.de>
References: <47287A78.4000206@ibe.med.uni-muenchen.de>
Message-ID: <Pine.LNX.4.62.0710310950570.22229@fisher.stats.uwo.ca>

mpi.recv or mpi.irecv needs a buffer to store an incoming messenger and 
must know in advance the size of the buffer. For mpi.irecv.Robj to work, 
one needs to probe the incoming messenger size which is a block call. So 
there is no point to implment mpi.irecv.Robj unless there is an another 
nonblocking call to find the buffer size.

Hao

*************************************************************************
Department of Statistics & Actuarial Sciences 	Fax Phone#:(519)-661-3813
The University of Western Ontario            Office Phone#:(519)-661-3622
London, Ontario N6A 5B7 
Email: hyu at fisher.stats.uwo.ca	      http://www.stats.uwo.ca/faculty/yu

On Wed, 31 Oct 2007, Markus Schmidberger wrote:

> Hello,
>
> in the package "Rmpi" (Version 0.5-5) I am missing the nonblocking function 
> "mpi.irecv.Robj".
> Is there any reason for not having this function?
>
> Best
> Markus
>
> -- 
> Dipl.-Tech. Math. Markus Schmidberger
>
> Ludwig-Maximilians-Universit?t M?nchen
> IBE - Institut f?r medizinische Informationsverarbeitung,
> Biometrie und Epidemiologie
> Marchioninistr. 15, D-81377 Muenchen
> URL: http://ibe.web.med.uni-muenchen.de Mail: Markus.Schmidberger [at] 
> ibe.med.uni-muenchen.de
>

From pgilbert at bank-banque-canada.ca  Wed Oct 31 16:47:07 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 31 Oct 2007 11:47:07 -0400
Subject: [Rd] vignette optional sections.
Message-ID: <4728A37B.3030704@bank-banque-canada.ca>

I am writing a vignette that can run certain things on some systems but 
needs to skip them on other systems. (Some sections need databases that 
will not always be available.) Wrapping things in an if(){} partly 
works. It gives fairly ugly examples and all printing gets delayed until 
the end of the if.  However, if the block produces a graphic, and I have 
{fig=TRUE} so in the case where the database is available the graphic is 
included in the vignette pdf, then the pdf generation fails in the case 
where the graphic is not produced.

Does anyone have suggestions for a nice solution to this?

Thanks,
Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential in...{{dropped:26}}


From P.Dalgaard at biostat.ku.dk  Wed Oct 31 17:00:45 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 31 Oct 2007 17:00:45 +0100
Subject: [Rd] slow tcl/tk
In-Reply-To: <6bpki0$7cf23r@toip3.srvr.bell.ca>
References: <6bpki0$7cf23r@toip3.srvr.bell.ca>
Message-ID: <4728A6AD.2090700@biostat.ku.dk>


> It's possible that I'm missing something, but I don't think that there have
> been recent changes to the Rcmdr that would account for this difference (and
> note that I don't see it under Windows). In particular, I think that the
> change coincided with R-2.6.0 (which seems to be Adrian's experience too).
>
>   
Yes, I realized that there could be other consequences of the change in
2.6.0. Moved to R-core for internal discussions.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jfox at mcmaster.ca  Wed Oct 31 17:16:21 2007
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 31 Oct 2007 12:16:21 -0400
Subject: [Rd] slow tcl/tk
In-Reply-To: <4728A6AD.2090700@biostat.ku.dk>
Message-ID: <6bpki0$7cfer4@toip3.srvr.bell.ca>

Dear Peter,

Thank you for pursuing this.

Regards,
 John


> -----Original Message-----
> From: Peter Dalgaard [mailto:P.Dalgaard at biostat.ku.dk] 
> Sent: Wednesday, October 31, 2007 12:01 PM
> To: John Fox
> Cc: r-devel at r-project.org; 'Adrian Dusa'
> Subject: Re: [Rd] slow tcl/tk
> 
> 
> > It's possible that I'm missing something, but I don't think 
> that there 
> > have been recent changes to the Rcmdr that would account for this 
> > difference (and note that I don't see it under Windows). In 
> > particular, I think that the change coincided with R-2.6.0 
> (which seems to be Adrian's experience too).
> >
> >   
> Yes, I realized that there could be other consequences of the 
> change in 2.6.0. Moved to R-core for internal discussions.
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: 
> (+45) 35327907
> 
> 
> 


