From bhh at xs4all.nl  Mon Dec  3 15:25:21 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 3 Dec 2012 15:25:21 +0100
Subject: [Rd] qr.qy and qr.qty give an error message when y is integer and
	LAPACK=TRUE
Message-ID: <7FEC69A9-D90B-4C33-B91B-F388BCCF5AAF@xs4all.nl>


With this example

set.seed(123)
A <- matrix(runif(40), nrow = 8)
y <- 1:nrow(A)

A.laqr <- qr(A, LAPACK=TRUE)

both  qr.qy(A.laqr,y)  and  qr.qty(A.laqr,y)  give the respective error messages

Error in qr.qy(A.laqr, y) : 'b' must be a numeric matrix
Error in qr.qty(A.laqr, y) : 'b' must be a numeric matrix

However when Lapack is not used as in 

A.liqr <- qr(A, LAPACK=FALSE)

qr.qy(A.liqr,y) and qr.qty(A.liqr,y) don't issue error messages.

Looking at the source of qr.qy and qr.qty in https://svn.r-project.org/R/trunk/src/library/base/R/qr.R
I see that in the case of Lapack the storage.mode of y is not set to "double" (in contrast to when Linpack QR has been used).

I assume that the error issued when LAPACK=TRUE is not intended.

Berend

Suggested code change  in qr.qy
Replace 

    if(!is.null(a) && is.logical(a) && a)
        return(.Call("qr_qy_real", qr, as.matrix(y), 0, PACKAGE = "base"))

with

    if(!is.null(a) && is.logical(a) && a) {
        storage.mode(y) <- "double"
        return(.Call("qr_qy_real", qr, as.matrix(y), 0, PACKAGE = "base"))
    }

and a similar change in qr.qty

From maechler at stat.math.ethz.ch  Mon Dec  3 16:17:35 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Dec 2012 16:17:35 +0100
Subject: [Rd] qr.qy and qr.qty give an error message when y is integer
	and	LAPACK=TRUE
In-Reply-To: <7FEC69A9-D90B-4C33-B91B-F388BCCF5AAF@xs4all.nl>
References: <7FEC69A9-D90B-4C33-B91B-F388BCCF5AAF@xs4all.nl>
Message-ID: <20668.49807.685927.321902@stat.math.ethz.ch>

>>>>> Berend Hasselman <bhh at xs4all.nl>
>>>>>     on Mon, 3 Dec 2012 15:25:21 +0100 writes:

    > With this example

    > set.seed(123) A <- matrix(runif(40), nrow = 8) y <-
    > 1:nrow(A)

    > A.laqr <- qr(A, LAPACK=TRUE)

    > both qr.qy(A.laqr,y) and qr.qty(A.laqr,y) give the
    > respective error messages

    > Error in qr.qy(A.laqr, y) : 'b' must be a numeric matrix
    > Error in qr.qty(A.laqr, y) : 'b' must be a numeric matrix

    > However when Lapack is not used as in

    > A.liqr <- qr(A, LAPACK=FALSE)

    > qr.qy(A.liqr,y) and qr.qty(A.liqr,y) don't issue error
    > messages.

You are right... if you look at R 2.15.2 (or even it's patched
version).


    > Looking at the source of qr.qy and qr.qty in
    > https://svn.r-project.org/R/trunk/src/library/base/R/qr.R

Hmm, no: If  you really looked at that code (during the last several weeks),
you would have noted that the code has *changed* from what you
give below...

and the current R development version uses  
.Internal(.) instead of .Call()  and the C code behind the
.Internal() nicely deals with integer 'y' as well.

In short, this is already fixed in R, since ~ September,
but it won't probably be fixed in "R 2.15.2 patched" ...


Thank you for the report, anyway!
Martin



    > I see that in the case of Lapack the storage.mode of y is
    > not set to "double" (in contrast to when Linpack QR has
    > been used).



    > I assume that the error issued when LAPACK=TRUE is not
    > intended.

    > Berend

    > Suggested code change in qr.qy Replace

    >     if(!is.null(a) && is.logical(a) && a)
    > return(.Call("qr_qy_real", qr, as.matrix(y), 0, PACKAGE =
    > "base"))

    > with

    >     if(!is.null(a) && is.logical(a) && a) {
    > storage.mode(y) <- "double" return(.Call("qr_qy_real", qr,
    > as.matrix(y), 0, PACKAGE = "base")) }

    > and a similar change in qr.qty
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bhh at xs4all.nl  Mon Dec  3 16:42:13 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 3 Dec 2012 16:42:13 +0100
Subject: [Rd] qr.qy and qr.qty give an error message when y is integer
	and LAPACK=TRUE
In-Reply-To: <20668.49807.685927.321902@stat.math.ethz.ch>
References: <7FEC69A9-D90B-4C33-B91B-F388BCCF5AAF@xs4all.nl>
	<20668.49807.685927.321902@stat.math.ethz.ch>
Message-ID: <703EA8C7-3985-43AE-AD16-35B0988BEC34@xs4all.nl>


On 03-12-2012, at 16:17, Martin Maechler wrote:

>>>>>> Berend Hasselman <bhh at xs4all.nl>
>>>>>>    on Mon, 3 Dec 2012 15:25:21 +0100 writes:
> 
>> With this example
> 
>> set.seed(123) A <- matrix(runif(40), nrow = 8) y <-
>> 1:nrow(A)
> 
>> A.laqr <- qr(A, LAPACK=TRUE)
> 
>> both qr.qy(A.laqr,y) and qr.qty(A.laqr,y) give the
>> respective error messages
> 
>> Error in qr.qy(A.laqr, y) : 'b' must be a numeric matrix
>> Error in qr.qty(A.laqr, y) : 'b' must be a numeric matrix
> 
>> However when Lapack is not used as in
> 
>> A.liqr <- qr(A, LAPACK=FALSE)
> 
>> qr.qy(A.liqr,y) and qr.qty(A.liqr,y) don't issue error
>> messages.
> 
> You are right... if you look at R 2.15.2 (or even it's patched
> version).
> 

Which I did. And copied from R 2.15.2.

>> Looking at the source of qr.qy and qr.qty in
>> https://svn.r-project.org/R/trunk/src/library/base/R/qr.R
> 
> Hmm, no: If  you really looked at that code (during the last several weeks),
> you would have noted that the code has *changed* from what you
> give below...
> 

> and the current R development version uses  
> .Internal(.) instead of .Call()  and the C code behind the
> .Internal() nicely deals with integer 'y' as well.
> 

I did look at that code but did not drill down. Stupid.

> In short, this is already fixed in R, since ~ September,
> but it won't probably be fixed in "R 2.15.2 patched" ...
> 

Apologies for the noise.

Berend


From jon.clayden at gmail.com  Mon Dec  3 18:28:32 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Mon, 3 Dec 2012 17:28:32 +0000
Subject: [Rd] Compilation failure on Solaris: any advice?
Message-ID: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121203/3efe9f93/attachment.pl>

From spencer.graves at structuremonitoring.com  Mon Dec  3 22:03:34 2012
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 03 Dec 2012 13:03:34 -0800
Subject: [Rd] Documentation on making R code faster?
In-Reply-To: <50BCF760.1000909@structuremonitoring.com>
References: <50BCF760.1000909@structuremonitoring.com>
Message-ID: <50BD13A6.4070407@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121203/54cfb11c/attachment.pl>

From nashjc at uottawa.ca  Tue Dec  4 14:57:42 2012
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 04 Dec 2012 08:57:42 -0500
Subject: [Rd] Speeding up R (was Using multicores in R)
In-Reply-To: <mailman.27.1354618808.3098.r-devel@r-project.org>
References: <mailman.27.1354618808.3098.r-devel@r-project.org>
Message-ID: <50BE0156.5070403@uottawa.ca>

For info, I put a little study I did about the byte code compiler and 
other speedup approaches (but not multicore) on the Rwiki at

http://rwiki.sciviews.org/doku.php?id=tips:rqcasestudy

which looks at a specific problem, so may not be relevant to everyone.
However, one of my reasons for doing it was to document the "how to" a 
little.

JN

>
>        2.  Have you tried the "compiler" package?  If I understand
> correctly, R is a two-stage interpreter, first translating what we know
> as R into byte code, which is then interpreted by a byte code
> interpreter.  If my memory is correct, this approach can cut the compute
> time by a factor of 100.
>
>
>


From hb at biostat.ucsf.edu  Tue Dec  4 21:24:15 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 4 Dec 2012 12:24:15 -0800
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command line
	option --max-cores)
Message-ID: <CAFDcVCQMsFDL3NVcrVsnXPhB0vJ4gaQDOxQKN7esBSzktuTCEQ@mail.gmail.com>

In the 'parallel' package there is detectCores(), which tries its best
to infer the number of cores on the current machine.  This is useful
if you wish to utilize the *maximum* number of cores on the machine.
Several are using this to set the number of cores when parallelizing,
sometimes also hardcoded within 3rd-party scripts/package code, but
there are several settings where you wish to use fewer, e.g. in a
compute cluster where you R session is given only a portion of the
cores available.  Because of this, I'd like to propose to add
getCores(), which by default returns what detectCores() gives, but can
also be set to return what is assigned via setCores().  The idea is
this getCores() could replace most common usage of detectCores() and
provide more control.  An additional feature would be that 'parallel'
when loaded would check for command line argument --max-cores=<int>,
which will update the number of cores via setCores().  This would make
it possible for, say, a Torque/PBS compute cluster to launch an R
batch script as

  Rscript --max-cores=$PBS_NP script.R

and the only thing the script.R needs to know about is parallel::getCores().

I understand that I can do all this already in my own scripts, but I'd
like to propose a standard for R.

Comments?

/Henrik


From hpages at fhcrc.org  Tue Dec  4 23:31:48 2012
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 04 Dec 2012 14:31:48 -0800
Subject: [Rd] inconsistencies between ?class and ?UseMethod
Message-ID: <50BE79D4.5060205@fhcrc.org>

Hi,

The 2 man pages give inconsistent description of class():

Found in ?class:

      If the object does not have a class attribute, it has an implicit
      class, ?"matrix"?, ?"array"? or the result of ?mode(x)? (except
      that integer vectors have implicit class ?"integer"?).

Found in ?UseMethod:

      Matrices and arrays have class ?"matrix"? or?"array"? followed
      by the class of the underlying vector.
      Most vectors have class the result of ?mode(x)?, except that
      integer vectors have class ?c("integer", "numeric")? and real
      vectors have class ?c("double", "numeric")?.

So according to ?UseMethod, class(matrix(1:4)) should be
c("matrix", "integer", "numeric"), which is of course not the case:

   > class(matrix(1:4))
   [1] "matrix"

I wonder if this was ever true, and, if so, when and why it has changed.

Anyway, an update to ?UseMethod would be welcome. Or, documenting
class() in only 1 place seems even better (more DRY principle).

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Wed Dec  5 02:25:14 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 4 Dec 2012 20:25:14 -0500
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command
	line option --max-cores)
In-Reply-To: <CAFDcVCQMsFDL3NVcrVsnXPhB0vJ4gaQDOxQKN7esBSzktuTCEQ@mail.gmail.com>
References: <CAFDcVCQMsFDL3NVcrVsnXPhB0vJ4gaQDOxQKN7esBSzktuTCEQ@mail.gmail.com>
Message-ID: <46368C13-0F72-4FAD-9412-1FE321CE3F06@r-project.org>

A somewhat simplistic answer is that we already have that with the "mc.cores" option. In multicore the default was to use all cores (without the need to use detectCores) and yet you could reduce the number as you want with mc.cores. This is similar to what you are talking about but it's not a sufficient solution.

There are some plans for somewhat more general approach. You may have noticed that mcaffinity() was added to query/control/limit the mapping of cores to tasks. It allows much more file-grained control and better decisions whether to recursively split jobs or not as the state is global for the entire R. The (vague) plan is to generalize this for all platforms - if not binding to a particular core then at least to monitor the assigned number of cores.

Cheers,
Simon


On Dec 4, 2012, at 3:24 PM, Henrik Bengtsson wrote:

> In the 'parallel' package there is detectCores(), which tries its best
> to infer the number of cores on the current machine.  This is useful
> if you wish to utilize the *maximum* number of cores on the machine.
> Several are using this to set the number of cores when parallelizing,
> sometimes also hardcoded within 3rd-party scripts/package code, but
> there are several settings where you wish to use fewer, e.g. in a
> compute cluster where you R session is given only a portion of the
> cores available.  Because of this, I'd like to propose to add
> getCores(), which by default returns what detectCores() gives, but can
> also be set to return what is assigned via setCores().  The idea is
> this getCores() could replace most common usage of detectCores() and
> provide more control.  An additional feature would be that 'parallel'
> when loaded would check for command line argument --max-cores=<int>,
> which will update the number of cores via setCores().  This would make
> it possible for, say, a Torque/PBS compute cluster to launch an R
> batch script as
> 
>  Rscript --max-cores=$PBS_NP script.R
> 
> and the only thing the script.R needs to know about is parallel::getCores().
> 
> I understand that I can do all this already in my own scripts, but I'd
> like to propose a standard for R.
> 
> Comments?
> 
> /Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jeff__goode at hotmail.com  Wed Dec  5 04:00:56 2012
From: jeff__goode at hotmail.com (Jeff Goode)
Date: Wed, 5 Dec 2012 03:00:56 +0000
Subject: [Rd] RInside, rcpp   compilation problem
Message-ID: <BAY173-W1722F51AFF63B3074FBE9A6460@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121205/2c6b6351/attachment.pl>

From hb at biostat.ucsf.edu  Wed Dec  5 04:22:30 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 4 Dec 2012 19:22:30 -0800
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command
 line option --max-cores)
In-Reply-To: <46368C13-0F72-4FAD-9412-1FE321CE3F06@r-project.org>
References: <CAFDcVCQMsFDL3NVcrVsnXPhB0vJ4gaQDOxQKN7esBSzktuTCEQ@mail.gmail.com>
	<46368C13-0F72-4FAD-9412-1FE321CE3F06@r-project.org>
Message-ID: <CAFDcVCSmb3GpUBmkXAuYud468Bt2FxAicGt-SHFAvrtzPNehPw@mail.gmail.com>

On Tue, Dec 4, 2012 at 5:25 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> A somewhat simplistic answer is that we already have that with the "mc.cores" option. In multicore the default was to use all cores (without the need to use detectCores) and yet you could reduce the number as you want with mc.cores. This is similar to what you are talking about but it's not a sufficient solution.
>
> There are some plans for somewhat more general approach. You may have noticed that mcaffinity() was added to query/control/limit the mapping of cores to tasks. It allows much more file-grained control and better decisions whether to recursively split jobs or not as the state is global for the entire R. The (vague) plan is to generalize this for all platforms - if not binding to a particular core then at least to monitor the assigned number of cores.

I did not now about the concept of 'CPU affinity masks', but I can
quickly guess what the idea is, and it certainly provides a richer
control of CPU/core resources.  Yes, it would be very helpful if it
would work cross platform.

Thanks for the heads up.

/Henrik

>
> Cheers,
> Simon
>
>
> On Dec 4, 2012, at 3:24 PM, Henrik Bengtsson wrote:
>
>> In the 'parallel' package there is detectCores(), which tries its best
>> to infer the number of cores on the current machine.  This is useful
>> if you wish to utilize the *maximum* number of cores on the machine.
>> Several are using this to set the number of cores when parallelizing,
>> sometimes also hardcoded within 3rd-party scripts/package code, but
>> there are several settings where you wish to use fewer, e.g. in a
>> compute cluster where you R session is given only a portion of the
>> cores available.  Because of this, I'd like to propose to add
>> getCores(), which by default returns what detectCores() gives, but can
>> also be set to return what is assigned via setCores().  The idea is
>> this getCores() could replace most common usage of detectCores() and
>> provide more control.  An additional feature would be that 'parallel'
>> when loaded would check for command line argument --max-cores=<int>,
>> which will update the number of cores via setCores().  This would make
>> it possible for, say, a Torque/PBS compute cluster to launch an R
>> batch script as
>>
>>  Rscript --max-cores=$PBS_NP script.R
>>
>> and the only thing the script.R needs to know about is parallel::getCores().
>>
>> I understand that I can do all this already in my own scripts, but I'd
>> like to propose a standard for R.
>>
>> Comments?
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From simon.urbanek at r-project.org  Wed Dec  5 04:47:36 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 4 Dec 2012 22:47:36 -0500
Subject: [Rd] RInside, rcpp   compilation problem
In-Reply-To: <BAY173-W1722F51AFF63B3074FBE9A6460@phx.gbl>
References: <BAY173-W1722F51AFF63B3074FBE9A6460@phx.gbl>
Message-ID: <8A587F96-3B47-4C3A-AEE5-9CBBB52C915C@r-project.org>


On Dec 4, 2012, at 10:00 PM, Jeff Goode wrote:

> I have spent some hours browsing the RInside and rcpp documentation, lots of it; but ... as a programmer of C++ since 1990, on both Windows and Unix ... ( Solaris and Ubuntu, and Mandrake/Mandrivo Linux); I see a minor problem ......  Where is the rcpp.h header file??  

In the Rcpp package which RInside links to. Please use rcpp-devel mailing list for such questions (as per request of the authors).

Cheers,
Simon


> The below code fails to compile as the RInside.h header file references the rcpp.h header file, which is not included with RInclude download. This is the sample code provided in one of the RInside manuals: 
> #include <iostream> 
> 
> #include <RInside.h>                            // for the embedded R via RInside
> rcpp::NumericMatrix createMatrix(const int n) {
>    Rcpp::NumericMatrix M(n,n);
>    for (int i=0; i<n; i++) {
>        for (int j=0; j<n; j++) {
>            M(i,j) = i*10 + j; 
>        }
>    }
>    return(M);
> } 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Wed Dec  5 05:41:56 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Dec 2012 22:41:56 -0600
Subject: [Rd] RInside, rcpp   compilation problem
In-Reply-To: <8A587F96-3B47-4C3A-AEE5-9CBBB52C915C@r-project.org>
References: <BAY173-W1722F51AFF63B3074FBE9A6460@phx.gbl>
	<8A587F96-3B47-4C3A-AEE5-9CBBB52C915C@r-project.org>
Message-ID: <20670.53396.784398.15075@max.nulle.part>


On 4 December 2012 at 22:47, Simon Urbanek wrote:
| 
| On Dec 4, 2012, at 10:00 PM, Jeff Goode wrote:
| 
| > I have spent some hours browsing the RInside and rcpp documentation, lots of it; but ... as a programmer of C++ since 1990, on both Windows and Unix ... ( Solaris and Ubuntu, and Mandrake/Mandrivo Linux); I see a minor problem ......  Where is the rcpp.h header file??  
| 
| In the Rcpp package which RInside links to. 

Correct. And Depends: upon.

| Please use rcpp-devel mailing list for such questions (as per request of the authors).

Mostly as a courtesy to readers of r-devel.  And several different folks may
respond via rcpp-devel, not all of whom read here as well.

So redirecting via CC:, please feel free to keep follow-up there (but you
need to be subscribed to post).

| > The below code fails to compile as the RInside.h header file references the rcpp.h header file, which is not included with RInclude download. This is the sample code provided in one of the RInside manuals: 
| > #include <iostream> 
| > 
| > #include <RInside.h>                            // for the embedded R via RInside
| > rcpp::NumericMatrix createMatrix(const int n) {
| >    Rcpp::NumericMatrix M(n,n);
| >    for (int i=0; i<n; i++) {
| >        for (int j=0; j<n; j++) {
| >            M(i,j) = i*10 + j; 
| >        }
| >    }
| >    return(M);
| > } 		 	   		  

You appear to have clipped this from examples/standard/rinside_sample1.cpp

That very directory examples/standard, and its neighbouring directories, each
have

    i)   a Makefile for Linux, OS X, ... and 

    ii)  a Makefile.win for Win*, and

    iii) contributed cmake/ files

all of which do the build.  RInside needs itself, Rcpp and R so a few -I and
-L switches need to set --- which those three alternatives do for you.  

So if you, say, do 'cp rinside_sample1.cpp jeff1.cpp' you can just say 
'make jeff1' and the executable will be built.  That is a feature.  The
Makefile should work for your projects, and the other makefiles in the
neighbouring directories show how to do this with MPI, Qt, Wt, and (in SVN)
Boost. 

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spencer.graves at prodsyse.com  Wed Dec  5 07:24:14 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 04 Dec 2012 22:24:14 -0800
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be loaded
Message-ID: <50BEE88E.9080701@prodsyse.com>

Hello:


       I'm having problems creating a real NAMESPACE to replace the pro 
forma one in the fda package on R-Forge.  "R CMD check" complains, 
"Error: package 'zoo' could not be loaded ... there is no package called 
'zoo'";  see below.  I get this both with and without "import(zoo)" in 
NAMESPACE.


       Suggestions?
       Thanks,
       Spencer


p.s.  The current code including this problem can be obtained through 
anonymous access via "svn checkout 
svn://svn.r-forge.r-project.org/svnroot/fda/".


C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
* using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
* using R version 2.15.2 (2012-10-26)
* using platform: i386-w64-mingw32 (32-bit)

<snip>

* checking loading without being on the library search path ... WARNING
Loading required package: splines
Loading required package: zoo
Error: package 'zoo' could not be loaded
In addition: Warning message:
In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc)
  :
   there is no package called 'zoo'
Execution halted

It looks like this package has a loading problem when not on .libPaths:
see the messages for details.




 > sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] zoo_1.7-9

loaded via a namespace (and not attached):
[1] grid_2.15.2     lattice_0.20-10


From cberry at tajo.ucsd.edu  Wed Dec  5 06:40:07 2012
From: cberry at tajo.ucsd.edu (cberry at tajo.ucsd.edu)
Date: Tue, 4 Dec 2012 21:40:07 -0800
Subject: [Rd] inconsistencies between ?class and ?UseMethod
References: <50BE79D4.5060205@fhcrc.org>
Message-ID: <87y5hdukeg.fsf@tajo.ucsd.edu>

Herv? Pag?s <hpages at fhcrc.org> writes:

> Hi,
>
> The 2 man pages give inconsistent description of class():
>
> Found in ?class:
>
>      If the object does not have a class attribute, it has an implicit
>      class, ?"matrix"?, ?"array"? or the result of ?mode(x)? (except
>      that integer vectors have implicit class ?"integer"?).
>
> Found in ?UseMethod:
>
>      Matrices and arrays have class ?"matrix"? or?"array"? followed
>      by the class of the underlying vector.
>      Most vectors have class the result of ?mode(x)?, except that
>      integer vectors have class ?c("integer", "numeric")? and real
>      vectors have class ?c("double", "numeric")?.
>
> So according to ?UseMethod, class(matrix(1:4)) should be
> c("matrix", "integer", "numeric"), which is of course not the case:
>
>   > class(matrix(1:4))
>   [1] "matrix"
>
> I wonder if this was ever true, and, if so, when and why it has changed.


It still is in the sense that UseMethod and NextMethod dispatch in that
manner on implicit classes. It is bit confusing to me that class()
doesn't report all the implicit classes (like the first error message
below) and inherits() only admits what class() has told.

Note what the first error message below says and how the succesive calls
for afun() work as methods are added to the generic.

If you set a class attribute then the picture changes. I do not see where
this is documented, but it looks like once a class attribute is set, the
implicit classes go away - per the last error message.

> afun <- function(x) UseMethod("afun",x)
> afun(matrix(1L,nc=1))
Error in UseMethod("afun", x) : 
  no applicable method for 'afun' applied to an object of class
  "c('matrix', 'integer', 'numeric')"
> afun.numeric <- function(x) cat("numeric",x,"\n")
> afun(matrix(1L,nc=1))
numeric 1 
> afun.integer <- function(x) cat("integer",x,"\n")
> afun(matrix(1L,nc=1))
integer 1 
> afun.matrix <- function(x) cat("matrix",x,"\n")
> afun(matrix(1L,nc=1))
matrix 1 
> afun.matrix <- function(x) NextMethod()
> afun(matrix(1L,nc=1))
integer 1 
> afun.fooey <- function(x) NextMethod()
> my.mat <- matrix(1L,nc=1)
> afun(my.mat)
matrix 1 
> class(my.mat) <- "fooey"
> afun(my.mat)
Error in NextMethod() : no method to invoke
> 

> Anyway, an update to ?UseMethod would be welcome. 

I wonder if "except with implicit" would improve over "with some
interpolated" in ?class here:

"...in R UseMethod dispatches on the class as returned by class (with
some interpolated classes: see the link)"

HTH,

Chuck

> Or, documenting
> class() in only 1 place seems even better (more DRY principle).
>
> Thanks,
> H.

-- 
Charles C. Berry                            Dept of Family/Preventive Medicine
cberry at ucsd edu			    UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, CA 92093-0901


From manoj.g at isim.net.in  Wed Dec  5 07:33:28 2012
From: manoj.g at isim.net.in (Manoj G)
Date: Tue, 4 Dec 2012 22:33:28 -0800 (PST)
Subject: [Rd] Stand alone application using R
Message-ID: <1354689208848-4652158.post@n4.nabble.com>

Hello everyone.......

I am curious to develop a stand-alone application using R and I am exploring
how to do it. Shiny can be used if it is a web application!

But which programming is more suitable and can be easily bundled with R? 

Java? or python? or something else? What do u prefer?

Thanks in advance for your help... Good day... :)

-Manoj G



-----
Manoj G
--
View this message in context: http://r.789695.n4.nabble.com/Stand-alone-application-using-R-tp4652158.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Dec  5 15:31:22 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 5 Dec 2012 09:31:22 -0500
Subject: [Rd] Stand alone application using R
In-Reply-To: <1354689208848-4652158.post@n4.nabble.com>
References: <1354689208848-4652158.post@n4.nabble.com>
Message-ID: <F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>


On Dec 5, 2012, at 1:33 AM, Manoj G wrote:

> Hello everyone.......
> 
> I am curious to develop a stand-alone application using R and I am exploring how to do it.

There are many examples - the GUIs bundled with R (R.app for Mac, Rgui, rterm for Windows) or packages like Rserve (C), RInside (C++), JGR (Java), ...


> Shiny can be used if it is a web application!
> 
> But which programming is more suitable and can be easily bundled with R? 
> 
> Java? or python? or something else? What do u prefer?
> 

The native language for embedding R is C, but there are embedding interfaces for other languages, so it really depends on your taste and the complexity you are willing to  tolerate.

Cheers,
S


> Thanks in advance for your help... Good day... :)
> 
> -Manoj G
> 
> 
> 
> -----
> Manoj G
> --
> View this message in context: http://r.789695.n4.nabble.com/Stand-alone-application-using-R-tp4652158.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From manoj.g at isim.net.in  Wed Dec  5 17:09:57 2012
From: manoj.g at isim.net.in (Manoj G)
Date: Wed, 5 Dec 2012 08:09:57 -0800 (PST)
Subject: [Rd] Stand alone application using R
In-Reply-To: <F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>
References: <1354689208848-4652158.post@n4.nabble.com>
	<F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>
Message-ID: <1354723797215-4652207.post@n4.nabble.com>

Thanks Simon,

I will go ahead with JGR now. 

There are java packages like rJava and RCaller. And i found they are not
useful after a certain extent. How different is JGR from these two?

I am willing to tolerate more complexity but, i am curious to develop a more
sophisticated application where i want to see R outputs in some some other
environment without using R console.

Thank,
Manoj G



-----
Manoj G
--
View this message in context: http://r.789695.n4.nabble.com/Stand-alone-application-using-R-tp4652158p4652207.html
Sent from the R devel mailing list archive at Nabble.com.


From wdunlap at tibco.com  Wed Dec  5 17:40:51 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 5 Dec 2012 16:40:51 +0000
Subject: [Rd] Stand alone application using R
In-Reply-To: <1354723797215-4652207.post@n4.nabble.com>
References: <1354689208848-4652158.post@n4.nabble.com>
	<F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>
	<1354723797215-4652207.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931B8C1319@PA-MBX01.na.tibco.com>

Would you mind elaborating on how rJava and RCaller
"are not useful after a certain extent"?  I.e., are there
bugs, memory leaks, too limited an API, or other problems
with them?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Manoj G
> Sent: Wednesday, December 05, 2012 8:10 AM
> To: r-devel at r-project.org
> Subject: Re: [Rd] Stand alone application using R
> 
> Thanks Simon,
> 
> I will go ahead with JGR now.
> 
> There are java packages like rJava and RCaller. And i found they are not
> useful after a certain extent. How different is JGR from these two?
> 
> I am willing to tolerate more complexity but, i am curious to develop a more
> sophisticated application where i want to see R outputs in some some other
> environment without using R console.
> 
> Thank,
> Manoj G
> 
> 
> 
> -----
> Manoj G
> --
> View this message in context: http://r.789695.n4.nabble.com/Stand-alone-application-
> using-R-tp4652158p4652207.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From brian at braverock.com  Wed Dec  5 17:47:54 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 05 Dec 2012 10:47:54 -0600
Subject: [Rd] Stand alone application using R
In-Reply-To: <1354723797215-4652207.post@n4.nabble.com>
References: <1354689208848-4652158.post@n4.nabble.com>
	<F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>
	<1354723797215-4652207.post@n4.nabble.com>
Message-ID: <50BF7ABA.80200@braverock.com>

On 12/05/2012 10:09 AM, Manoj G wrote:
> I am willing to tolerate more complexity but, i am curious to develop a more
> sophisticated application where i want to see R outputs in some some other
> environment without using R console.

Doesn't this conversation belong on R-SIG-GUI?

-- 
Brian


From simon.urbanek at r-project.org  Wed Dec  5 19:27:11 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 5 Dec 2012 13:27:11 -0500
Subject: [Rd] Stand alone application using R
In-Reply-To: <1354723797215-4652207.post@n4.nabble.com>
References: <1354689208848-4652158.post@n4.nabble.com>
	<F7F69D00-186C-417E-98D6-D66794F3A2E1@r-project.org>
	<1354723797215-4652207.post@n4.nabble.com>
Message-ID: <730FA894-A2CB-472A-ACA6-4247A275E24D@r-project.org>


On Dec 5, 2012, at 11:09 AM, Manoj G <manoj.g at isim.net.in> wrote:

> Thanks Simon,
> 
> I will go ahead with JGR now. 
> 
> There are java packages like rJava and RCaller. And i found they are not
> useful after a certain extent. How different is JGR from these two?
> 

JGR is using JRI from rJava for the R/Java interface.

Cheers,
Simon


> I am willing to tolerate more complexity but, i am curious to develop a more
> sophisticated application where i want to see R outputs in some some other
> environment without using R console.
> 
> Thank,
> Manoj G
> 
> 
> 
> -----
> Manoj G
> --
> View this message in context: http://r.789695.n4.nabble.com/Stand-alone-application-using-R-tp4652158p4652207.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Wed Dec  5 20:10:58 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Dec 2012 14:10:58 -0500
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BEE88E.9080701@prodsyse.com>
References: <50BEE88E.9080701@prodsyse.com>
Message-ID: <50BF9C42.8090506@gmail.com>

On 12-12-05 1:24 AM, Spencer Graves wrote:
> Hello:
>
>
>         I'm having problems creating a real NAMESPACE to replace the pro
> forma one in the fda package on R-Forge.  "R CMD check" complains,
> "Error: package 'zoo' could not be loaded ... there is no package called
> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
> NAMESPACE.
>
>
>         Suggestions?
>         Thanks,
>         Spencer
>
>
> p.s.  The current code including this problem can be obtained through
> anonymous access via "svn checkout
> svn://svn.r-forge.r-project.org/svnroot/fda/".
>
>
> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
> * using R version 2.15.2 (2012-10-26)
> * using platform: i386-w64-mingw32 (32-bit)
>
> <snip>
>
> * checking loading without being on the library search path ... WARNING
> Loading required package: splines
> Loading required package: zoo
> Error: package 'zoo' could not be loaded
> In addition: Warning message:
> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
> lib.loc)
>    :
>     there is no package called 'zoo'
> Execution halted
>
> It looks like this package has a loading problem when not on .libPaths:
> see the messages for details.

This message is printed by tools when there's an error when it tries to 
load a package (not sure if it's yours or zoo) that is not in the 
.libPaths.  There might be more details in the check log.

What does it say there?

Duncan Murdoch
>
>
>
>
>   > sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] zoo_1.7-9
>
> loaded via a namespace (and not attached):
> [1] grid_2.15.2     lattice_0.20-10
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at prodsyse.com  Wed Dec  5 20:19:12 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 05 Dec 2012 11:19:12 -0800
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BF9C42.8090506@gmail.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
Message-ID: <50BF9E30.1050402@prodsyse.com>

On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
> On 12-12-05 1:24 AM, Spencer Graves wrote:
>> Hello:
>>
>>
>>         I'm having problems creating a real NAMESPACE to replace the pro
>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>> "Error: package 'zoo' could not be loaded ... there is no package called
>> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
>> NAMESPACE.
>>
>>
>>         Suggestions?
>>         Thanks,
>>         Spencer
>>
>>
>> p.s.  The current code including this problem can be obtained through
>> anonymous access via "svn checkout
>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>
>>
>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>> * using R version 2.15.2 (2012-10-26)
>> * using platform: i386-w64-mingw32 (32-bit)
>>
>> <snip>
>>
>> * checking loading without being on the library search path ... WARNING
>> Loading required package: splines
>> Loading required package: zoo
>> Error: package 'zoo' could not be loaded
>> In addition: Warning message:
>> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
>> lib.loc)
>>    :
>>     there is no package called 'zoo'
>> Execution halted
>>
>> It looks like this package has a loading problem when not on .libPaths:
>> see the messages for details.
>
> This message is printed by tools when there's an error when it tries 
> to load a package (not sure if it's yours or zoo) that is not in the 
> .libPaths.  There might be more details in the check log.
>
> What does it say there?


       I didn't see any more than the portion copied here.  Below please 
find the entire 00check.log.  Thanks, Spencer


* using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
* using R version 2.15.2 (2012-10-26)
* using platform: i386-w64-mingw32 (32-bit)
* using session charset: ISO8859-1
* checking for file 'fda/DESCRIPTION' ... OK
* this is package 'fda' version '2.3.3'
* checking package namespace information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for executable files ... OK
* checking whether package 'fda' can be installed ... OK
* checking installed package size ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies 
... OK
* checking whether the namespace can be unloaded cleanly ... OK
* checking loading without being on the library search path ... WARNING
Loading required package: splines
Loading required package: zoo
Error: package 'zoo' could not be loaded
In addition: Warning message:
In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc) :
   there is no package called 'zoo'
Execution halted

It looks like this package has a loading problem when not on .libPaths:
see the messages for details.
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... WARNING
Missing link(s) in documentation object 
'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd':
   'use.proper.basis' 'is.eqbasis'

Missing link(s) in documentation object 
'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd':
   'plot.cca.fd'

Missing link(s) in documentation object 
'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd':
   'polynom'

Missing link(s) in documentation object 
'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd':
   'polynompen'

Missing link(s) in documentation object 
'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd':
   'getURL'

See the information in section 'Cross-references' of the 'Writing R
Extensions' manual.

* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking contents of 'data' directory ... OK
* checking data for non-ASCII characters ... OK
* checking data for ASCII and uncompressed saves ... OK
* checking installed files from 'inst/doc' ... OK
* checking examples ... ERROR
Running examples in 'fda-Ex.R' failed
The error most likely occurred in:

 > ### Name: CanadianWeather
 > ### Title: Canadian average annual weather cycle
 > ### Aliases: CanadianWeather daily
 > ### Keywords: datasets
 >
 > ### ** Examples
 >
 > ##
 > ## 1.  Plot (latitude & longitude) of stations by region
 > ##
 > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1], type='n',
+                            xlab="West Longitude", ylab="North Latitude",
+                            axes=FALSE) )
 > Wlon <- pretty(CanadianWeather$coordinates[, 2])
 > axis(1, -Wlon, Wlon)
 > axis(2)
 >
 > rgns <- 1:4
 > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
 > Rgns <- rgns[CanadianWeather$region]
 > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
+                              col=Rgns, pch=Rgns) )
 > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
 >
 > ##
 > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
 > ##
 > data(CanadianWeather)
 > # Expand the left margin to allow space for place names
 > op <- par(mar=c(5, 4, 4, 5)+.1)
 > # Plot
 > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
 > matplot(day.5, CanadianWeather$dailyAv[, stations, "Temperature.C"],
+         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg C)")
Error in UseMethod("matplot") :
   no applicable method for 'matplot' applied to an object of class 
"c('double', 'numeric')"
Calls: matplot
Execution halted

>
> Duncan Murdoch
>>
>>
>>
>>
>>   > sessionInfo()
>> R version 2.15.2 (2012-10-26)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] zoo_1.7-9
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.15.2     lattice_0.20-10
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From murdoch.duncan at gmail.com  Wed Dec  5 20:27:25 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Dec 2012 14:27:25 -0500
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BF9E30.1050402@prodsyse.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
	<50BF9E30.1050402@prodsyse.com>
Message-ID: <50BFA01D.3080708@gmail.com>

On 12-12-05 2:19 PM, Spencer Graves wrote:
> On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
>> On 12-12-05 1:24 AM, Spencer Graves wrote:
>>> Hello:
>>>
>>>
>>>          I'm having problems creating a real NAMESPACE to replace the pro
>>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>>> "Error: package 'zoo' could not be loaded ... there is no package called
>>> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
>>> NAMESPACE.
>>>
>>>
>>>          Suggestions?
>>>          Thanks,
>>>          Spencer
>>>
>>>
>>> p.s.  The current code including this problem can be obtained through
>>> anonymous access via "svn checkout
>>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>>
>>>
>>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>> * using R version 2.15.2 (2012-10-26)
>>> * using platform: i386-w64-mingw32 (32-bit)
>>>
>>> <snip>
>>>
>>> * checking loading without being on the library search path ... WARNING
>>> Loading required package: splines
>>> Loading required package: zoo
>>> Error: package 'zoo' could not be loaded
>>> In addition: Warning message:
>>> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
>>> lib.loc)
>>>     :
>>>      there is no package called 'zoo'
>>> Execution halted
>>>
>>> It looks like this package has a loading problem when not on .libPaths:
>>> see the messages for details.
>>
>> This message is printed by tools when there's an error when it tries
>> to load a package (not sure if it's yours or zoo) that is not in the
>> .libPaths.  There might be more details in the check log.
>>
>> What does it say there?
>
>
>         I didn't see any more than the portion copied here.  Below please
> find the entire 00check.log.  Thanks, Spencer
>

Do you have more than one library, or do you use the default 
.libPaths()?  I'm on a slightly old install of R on this Mac, and I see 
this (starting R from the same place I ran the check):

 > .libPaths()
[1] "/Library/Frameworks/R.framework/Versions/2.15/Resources/library"

What do you see?

Duncan Murdoch


>
> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
> * using R version 2.15.2 (2012-10-26)
> * using platform: i386-w64-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'fda/DESCRIPTION' ... OK
> * this is package 'fda' version '2.3.3'
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking whether package 'fda' can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies
> ... OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking loading without being on the library search path ... WARNING
> Loading required package: splines
> Loading required package: zoo
> Error: package 'zoo' could not be loaded
> In addition: Warning message:
> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
> lib.loc) :
>     there is no package called 'zoo'
> Execution halted
>
> It looks like this package has a loading problem when not on .libPaths:
> see the messages for details.
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... WARNING
> Missing link(s) in documentation object
> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd':
>     'use.proper.basis' 'is.eqbasis'
>
> Missing link(s) in documentation object
> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd':
>     'plot.cca.fd'
>
> Missing link(s) in documentation object
> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd':
>     'polynom'
>
> Missing link(s) in documentation object
> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd':
>     'polynompen'
>
> Missing link(s) in documentation object
> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd':
>     'getURL'
>
> See the information in section 'Cross-references' of the 'Writing R
> Extensions' manual.
>
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking contents of 'data' directory ... OK
> * checking data for non-ASCII characters ... OK
> * checking data for ASCII and uncompressed saves ... OK
> * checking installed files from 'inst/doc' ... OK
> * checking examples ... ERROR
> Running examples in 'fda-Ex.R' failed
> The error most likely occurred in:
>
>   > ### Name: CanadianWeather
>   > ### Title: Canadian average annual weather cycle
>   > ### Aliases: CanadianWeather daily
>   > ### Keywords: datasets
>   >
>   > ### ** Examples
>   >
>   > ##
>   > ## 1.  Plot (latitude & longitude) of stations by region
>   > ##
>   > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1], type='n',
> +                            xlab="West Longitude", ylab="North Latitude",
> +                            axes=FALSE) )
>   > Wlon <- pretty(CanadianWeather$coordinates[, 2])
>   > axis(1, -Wlon, Wlon)
>   > axis(2)
>   >
>   > rgns <- 1:4
>   > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
>   > Rgns <- rgns[CanadianWeather$region]
>   > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
> +                              col=Rgns, pch=Rgns) )
>   > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
>   >
>   > ##
>   > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
>   > ##
>   > data(CanadianWeather)
>   > # Expand the left margin to allow space for place names
>   > op <- par(mar=c(5, 4, 4, 5)+.1)
>   > # Plot
>   > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
>   > matplot(day.5, CanadianWeather$dailyAv[, stations, "Temperature.C"],
> +         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg C)")
> Error in UseMethod("matplot") :
>     no applicable method for 'matplot' applied to an object of class
> "c('double', 'numeric')"
> Calls: matplot
> Execution halted
>
>>
>> Duncan Murdoch
>>>
>>>
>>>
>>>
>>>    > sessionInfo()
>>> R version 2.15.2 (2012-10-26)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>
>>> other attached packages:
>>> [1] zoo_1.7-9
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.15.2     lattice_0.20-10
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>


From spencer.graves at prodsyse.com  Wed Dec  5 21:26:32 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 05 Dec 2012 12:26:32 -0800
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BFA01D.3080708@gmail.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
	<50BF9E30.1050402@prodsyse.com> <50BFA01D.3080708@gmail.com>
Message-ID: <50BFADF8.6010203@prodsyse.com>

On 12/5/2012 11:27 AM, Duncan Murdoch wrote:
> On 12-12-05 2:19 PM, Spencer Graves wrote:
>> On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
>>> On 12-12-05 1:24 AM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>          I'm having problems creating a real NAMESPACE to replace 
>>>> the pro
>>>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>>>> "Error: package 'zoo' could not be loaded ... there is no package 
>>>> called
>>>> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
>>>> NAMESPACE.
>>>>
>>>>
>>>>          Suggestions?
>>>>          Thanks,
>>>>          Spencer
>>>>
>>>>
>>>> p.s.  The current code including this problem can be obtained through
>>>> anonymous access via "svn checkout
>>>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>>>
>>>>
>>>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>>> * using R version 2.15.2 (2012-10-26)
>>>> * using platform: i386-w64-mingw32 (32-bit)
>>>>
>>>> <snip>
>>>>
>>>> * checking loading without being on the library search path ... 
>>>> WARNING
>>>> Loading required package: splines
>>>> Loading required package: zoo
>>>> Error: package 'zoo' could not be loaded
>>>> In addition: Warning message:
>>>> In library(pkg, character.only = TRUE, logical.return = TRUE, 
>>>> lib.loc =
>>>> lib.loc)
>>>>     :
>>>>      there is no package called 'zoo'
>>>> Execution halted
>>>>
>>>> It looks like this package has a loading problem when not on 
>>>> .libPaths:
>>>> see the messages for details.
>>>
>>> This message is printed by tools when there's an error when it tries
>>> to load a package (not sure if it's yours or zoo) that is not in the
>>> .libPaths.  There might be more details in the check log.
>>>
>>> What does it say there?
>>
>>
>>         I didn't see any more than the portion copied here. Below please
>> find the entire 00check.log.  Thanks, Spencer
>>
>
> Do you have more than one library, or do you use the default 
> .libPaths()?  I'm on a slightly old install of R on this Mac, and I 
> see this (starting R from the same place I ran the check):
>
> > .libPaths()
> [1] "/Library/Frameworks/R.framework/Versions/2.15/Resources/library"
>
> What do you see?


 > .libPaths()
[1] "C:/Users/sgraves/pgms/R/R-2.15.2/library"
[2] "C:/Users/sgraves/R/win-library/2.15"
 >

       Thanks.  Spencer

>
> Duncan Murdoch
>
>
>>
>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>> * using R version 2.15.2 (2012-10-26)
>> * using platform: i386-w64-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'fda/DESCRIPTION' ... OK
>> * this is package 'fda' version '2.3.3'
>> * checking package namespace information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking if there is a namespace ... OK
>> * checking for executable files ... OK
>> * checking whether package 'fda' can be installed ... OK
>> * checking installed package size ... OK
>> * checking package directory ... OK
>> * checking for portable file names ... OK
>> * checking DESCRIPTION meta-information ... OK
>> * checking top-level files ... OK
>> * checking for left-over files ... OK
>> * checking index information ... OK
>> * checking package subdirectories ... OK
>> * checking R files for non-ASCII characters ... OK
>> * checking R files for syntax errors ... OK
>> * checking whether the package can be loaded ... OK
>> * checking whether the package can be loaded with stated dependencies 
>> ... OK
>> * checking whether the package can be unloaded cleanly ... OK
>> * checking whether the namespace can be loaded with stated dependencies
>> ... OK
>> * checking whether the namespace can be unloaded cleanly ... OK
>> * checking loading without being on the library search path ... WARNING
>> Loading required package: splines
>> Loading required package: zoo
>> Error: package 'zoo' could not be loaded
>> In addition: Warning message:
>> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
>> lib.loc) :
>>     there is no package called 'zoo'
>> Execution halted
>>
>> It looks like this package has a loading problem when not on .libPaths:
>> see the messages for details.
>> * checking for unstated dependencies in R code ... OK
>> * checking S3 generic/method consistency ... OK
>> * checking replacement functions ... OK
>> * checking foreign function calls ... OK
>> * checking R code for possible problems ... OK
>> * checking Rd files ... OK
>> * checking Rd metadata ... OK
>> * checking Rd cross-references ... WARNING
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd': 
>>
>>     'use.proper.basis' 'is.eqbasis'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd': 
>>
>>     'plot.cca.fd'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd': 
>>
>>     'polynom'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd': 
>>
>>     'polynompen'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd': 
>>
>>     'getURL'
>>
>> See the information in section 'Cross-references' of the 'Writing R
>> Extensions' manual.
>>
>> * checking for missing documentation entries ... OK
>> * checking for code/documentation mismatches ... OK
>> * checking Rd \usage sections ... OK
>> * checking Rd contents ... OK
>> * checking for unstated dependencies in examples ... OK
>> * checking contents of 'data' directory ... OK
>> * checking data for non-ASCII characters ... OK
>> * checking data for ASCII and uncompressed saves ... OK
>> * checking installed files from 'inst/doc' ... OK
>> * checking examples ... ERROR
>> Running examples in 'fda-Ex.R' failed
>> The error most likely occurred in:
>>
>>   > ### Name: CanadianWeather
>>   > ### Title: Canadian average annual weather cycle
>>   > ### Aliases: CanadianWeather daily
>>   > ### Keywords: datasets
>>   >
>>   > ### ** Examples
>>   >
>>   > ##
>>   > ## 1.  Plot (latitude & longitude) of stations by region
>>   > ##
>>   > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1], 
>> type='n',
>> +                            xlab="West Longitude", ylab="North 
>> Latitude",
>> +                            axes=FALSE) )
>>   > Wlon <- pretty(CanadianWeather$coordinates[, 2])
>>   > axis(1, -Wlon, Wlon)
>>   > axis(2)
>>   >
>>   > rgns <- 1:4
>>   > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
>>   > Rgns <- rgns[CanadianWeather$region]
>>   > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
>> +                              col=Rgns, pch=Rgns) )
>>   > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
>>   >
>>   > ##
>>   > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
>>   > ##
>>   > data(CanadianWeather)
>>   > # Expand the left margin to allow space for place names
>>   > op <- par(mar=c(5, 4, 4, 5)+.1)
>>   > # Plot
>>   > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
>>   > matplot(day.5, CanadianWeather$dailyAv[, stations, "Temperature.C"],
>> +         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg 
>> C)")
>> Error in UseMethod("matplot") :
>>     no applicable method for 'matplot' applied to an object of class
>> "c('double', 'numeric')"
>> Calls: matplot
>> Execution halted
>>
>>>
>>> Duncan Murdoch
>>>>
>>>>
>>>>
>>>>
>>>>    > sessionInfo()
>>>> R version 2.15.2 (2012-10-26)
>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>
>>>> other attached packages:
>>>> [1] zoo_1.7-9
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.15.2     lattice_0.20-10
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From elw at stderr.org  Wed Dec  5 21:23:51 2012
From: elw at stderr.org (elijah wright)
Date: Wed, 5 Dec 2012 14:23:51 -0600
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
Message-ID: <CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121205/bb9d215d/attachment.pl>

From spencer.graves at prodsyse.com  Wed Dec  5 21:54:56 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 05 Dec 2012 12:54:56 -0800
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BFA01D.3080708@gmail.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
	<50BF9E30.1050402@prodsyse.com> <50BFA01D.3080708@gmail.com>
Message-ID: <50BFB4A0.2060609@prodsyse.com>

On 12/5/2012 11:27 AM, Duncan Murdoch wrote:
> On 12-12-05 2:19 PM, Spencer Graves wrote:
>> On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
>>> On 12-12-05 1:24 AM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>          I'm having problems creating a real NAMESPACE to replace
>>>> the pro
>>>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>>>> "Error: package 'zoo' could not be loaded ... there is no package
>>>> called
>>>> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
>>>> NAMESPACE.
>>>>
>>>>
>>>>          Suggestions?
>>>>          Thanks,
>>>>          Spencer
>>>>
>>>>
>>>> p.s.  The current code including this problem can be obtained through
>>>> anonymous access via "svn checkout
>>>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>>>
>>>>
>>>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>>> * using R version 2.15.2 (2012-10-26)
>>>> * using platform: i386-w64-mingw32 (32-bit)
>>>>
>>>> <snip>
>>>>
>>>> * checking loading without being on the library search path ...
>>>> WARNING
>>>> Loading required package: splines
>>>> Loading required package: zoo
>>>> Error: package 'zoo' could not be loaded
>>>> In addition: Warning message:
>>>> In library(pkg, character.only = TRUE, logical.return = TRUE,
>>>> lib.loc =
>>>> lib.loc)
>>>>     :
>>>>      there is no package called 'zoo'
>>>> Execution halted
>>>>
>>>> It looks like this package has a loading problem when not on
>>>> .libPaths:
>>>> see the messages for details.
>>>
>>> This message is printed by tools when there's an error when it tries
>>> to load a package (not sure if it's yours or zoo) that is not in the
>>> .libPaths.  There might be more details in the check log.
>>>
>>> What does it say there?
>>
>>
>>         I didn't see any more than the portion copied here. Below please
>> find the entire 00check.log.  Thanks, Spencer
>>
>
> Do you have more than one library, or do you use the default
> .libPaths()?  I'm on a slightly old install of R on this Mac, and I
> see this (starting R from the same place I ran the check):
>
> > .libPaths()
> [1] "/Library/Frameworks/R.framework/Versions/2.15/Resources/library"
>
> What do you see?


> .libPaths()
[1] "C:/Users/sgraves/pgms/R/R-2.15.2/library"
[2] "C:/Users/sgraves/R/win-library/2.15"
>

*** FIXED:


	  I deleted the directory "C:/Users/sgraves/R/win-library/2.15", 
reinstalled zoo, and now I don't get that error any more.  (I still have 
others ;-)


	  I don't know where .libPaths() got 
"C:/Users/sgraves/R/win-library/2.15":  It's not in R_HOME or R_LIBS. 
Fortunately, I don't have to solve that problem.


       Thanks.  Spencer

>
> Duncan Murdoch
>
>
>>
>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>> * using R version 2.15.2 (2012-10-26)
>> * using platform: i386-w64-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'fda/DESCRIPTION' ... OK
>> * this is package 'fda' version '2.3.3'
>> * checking package namespace information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking if there is a namespace ... OK
>> * checking for executable files ... OK
>> * checking whether package 'fda' can be installed ... OK
>> * checking installed package size ... OK
>> * checking package directory ... OK
>> * checking for portable file names ... OK
>> * checking DESCRIPTION meta-information ... OK
>> * checking top-level files ... OK
>> * checking for left-over files ... OK
>> * checking index information ... OK
>> * checking package subdirectories ... OK
>> * checking R files for non-ASCII characters ... OK
>> * checking R files for syntax errors ... OK
>> * checking whether the package can be loaded ... OK
>> * checking whether the package can be loaded with stated dependencies
>> ... OK
>> * checking whether the package can be unloaded cleanly ... OK
>> * checking whether the namespace can be loaded with stated dependencies
>> ... OK
>> * checking whether the namespace can be unloaded cleanly ... OK
>> * checking loading without being on the library search path ... WARNING
>> Loading required package: splines
>> Loading required package: zoo
>> Error: package 'zoo' could not be loaded
>> In addition: Warning message:
>> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
>> lib.loc) :
>>     there is no package called 'zoo'
>> Execution halted
>>
>> It looks like this package has a loading problem when not on .libPaths:
>> see the messages for details.
>> * checking for unstated dependencies in R code ... OK
>> * checking S3 generic/method consistency ... OK
>> * checking replacement functions ... OK
>> * checking foreign function calls ... OK
>> * checking R code for possible problems ... OK
>> * checking Rd files ... OK
>> * checking Rd metadata ... OK
>> * checking Rd cross-references ... WARNING
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd':
>>
>>     'use.proper.basis' 'is.eqbasis'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd':
>>
>>     'plot.cca.fd'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd':
>>
>>     'polynom'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd':
>>
>>     'polynompen'
>>
>> Missing link(s) in documentation object
>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd':
>>
>>     'getURL'
>>
>> See the information in section 'Cross-references' of the 'Writing R
>> Extensions' manual.
>>
>> * checking for missing documentation entries ... OK
>> * checking for code/documentation mismatches ... OK
>> * checking Rd \usage sections ... OK
>> * checking Rd contents ... OK
>> * checking for unstated dependencies in examples ... OK
>> * checking contents of 'data' directory ... OK
>> * checking data for non-ASCII characters ... OK
>> * checking data for ASCII and uncompressed saves ... OK
>> * checking installed files from 'inst/doc' ... OK
>> * checking examples ... ERROR
>> Running examples in 'fda-Ex.R' failed
>> The error most likely occurred in:
>>
>>   > ### Name: CanadianWeather
>>   > ### Title: Canadian average annual weather cycle
>>   > ### Aliases: CanadianWeather daily
>>   > ### Keywords: datasets
>>   >
>>   > ### ** Examples
>>   >
>>   > ##
>>   > ## 1.  Plot (latitude & longitude) of stations by region
>>   > ##
>>   > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1],
>> type='n',
>> +                            xlab="West Longitude", ylab="North
>> Latitude",
>> +                            axes=FALSE) )
>>   > Wlon <- pretty(CanadianWeather$coordinates[, 2])
>>   > axis(1, -Wlon, Wlon)
>>   > axis(2)
>>   >
>>   > rgns <- 1:4
>>   > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
>>   > Rgns <- rgns[CanadianWeather$region]
>>   > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
>> +                              col=Rgns, pch=Rgns) )
>>   > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
>>   >
>>   > ##
>>   > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
>>   > ##
>>   > data(CanadianWeather)
>>   > # Expand the left margin to allow space for place names
>>   > op <- par(mar=c(5, 4, 4, 5)+.1)
>>   > # Plot
>>   > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
>>   > matplot(day.5, CanadianWeather$dailyAv[, stations, "Temperature.C"],
>> +         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg
>> C)")
>> Error in UseMethod("matplot") :
>>     no applicable method for 'matplot' applied to an object of class
>> "c('double', 'numeric')"
>> Calls: matplot
>> Execution halted
>>
>>>
>>> Duncan Murdoch
>>>>
>>>>
>>>>
>>>>
>>>>    > sessionInfo()
>>>> R version 2.15.2 (2012-10-26)
>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>
>>>> other attached packages:
>>>> [1] zoo_1.7-9
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.15.2     lattice_0.20-10
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From murdoch.duncan at gmail.com  Wed Dec  5 22:12:35 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Dec 2012 16:12:35 -0500
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BFADF8.6010203@prodsyse.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
	<50BF9E30.1050402@prodsyse.com> <50BFA01D.3080708@gmail.com>
	<50BFADF8.6010203@prodsyse.com>
Message-ID: <50BFB8C3.3020208@gmail.com>

On 12-12-05 3:26 PM, Spencer Graves wrote:
> On 12/5/2012 11:27 AM, Duncan Murdoch wrote:
>> On 12-12-05 2:19 PM, Spencer Graves wrote:
>>> On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
>>>> On 12-12-05 1:24 AM, Spencer Graves wrote:
>>>>> Hello:
>>>>>
>>>>>
>>>>>           I'm having problems creating a real NAMESPACE to replace
>>>>> the pro
>>>>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>>>>> "Error: package 'zoo' could not be loaded ... there is no package
>>>>> called
>>>>> 'zoo'";  see below.  I get this both with and without "import(zoo)" in
>>>>> NAMESPACE.
>>>>>
>>>>>
>>>>>           Suggestions?
>>>>>           Thanks,
>>>>>           Spencer
>>>>>
>>>>>
>>>>> p.s.  The current code including this problem can be obtained through
>>>>> anonymous access via "svn checkout
>>>>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>>>>
>>>>>
>>>>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>>>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>>>> * using R version 2.15.2 (2012-10-26)
>>>>> * using platform: i386-w64-mingw32 (32-bit)
>>>>>
>>>>> <snip>
>>>>>
>>>>> * checking loading without being on the library search path ...
>>>>> WARNING
>>>>> Loading required package: splines
>>>>> Loading required package: zoo
>>>>> Error: package 'zoo' could not be loaded
>>>>> In addition: Warning message:
>>>>> In library(pkg, character.only = TRUE, logical.return = TRUE,
>>>>> lib.loc =
>>>>> lib.loc)
>>>>>      :
>>>>>       there is no package called 'zoo'
>>>>> Execution halted
>>>>>
>>>>> It looks like this package has a loading problem when not on
>>>>> .libPaths:
>>>>> see the messages for details.
>>>>
>>>> This message is printed by tools when there's an error when it tries
>>>> to load a package (not sure if it's yours or zoo) that is not in the
>>>> .libPaths.  There might be more details in the check log.
>>>>
>>>> What does it say there?
>>>
>>>
>>>          I didn't see any more than the portion copied here. Below please
>>> find the entire 00check.log.  Thanks, Spencer
>>>
>>
>> Do you have more than one library, or do you use the default
>> .libPaths()?  I'm on a slightly old install of R on this Mac, and I
>> see this (starting R from the same place I ran the check):
>>
>>> .libPaths()
>> [1] "/Library/Frameworks/R.framework/Versions/2.15/Resources/library"
>>
>> What do you see?
>
>
>   > .libPaths()
> [1] "C:/Users/sgraves/pgms/R/R-2.15.2/library"
> [2] "C:/Users/sgraves/R/win-library/2.15"

I would guess the problem is that it is using a different .libPaths 
setting for that test, and zoo is in the wrong place.  I don't know 
whether this is something you did or a bug in the check code.

In any case, that's a funny ordering you're using:  normally I'd expect 
the user-specific library to come first (because it would be searched 
first), and that would be followed by the system library installed with 
R.  How are you setting it?

Duncan Murdoch

>   >
>
>         Thanks.  Spencer
>
>>
>> Duncan Murdoch
>>
>>
>>>
>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>> * using R version 2.15.2 (2012-10-26)
>>> * using platform: i386-w64-mingw32 (32-bit)
>>> * using session charset: ISO8859-1
>>> * checking for file 'fda/DESCRIPTION' ... OK
>>> * this is package 'fda' version '2.3.3'
>>> * checking package namespace information ... OK
>>> * checking package dependencies ... OK
>>> * checking if this is a source package ... OK
>>> * checking if there is a namespace ... OK
>>> * checking for executable files ... OK
>>> * checking whether package 'fda' can be installed ... OK
>>> * checking installed package size ... OK
>>> * checking package directory ... OK
>>> * checking for portable file names ... OK
>>> * checking DESCRIPTION meta-information ... OK
>>> * checking top-level files ... OK
>>> * checking for left-over files ... OK
>>> * checking index information ... OK
>>> * checking package subdirectories ... OK
>>> * checking R files for non-ASCII characters ... OK
>>> * checking R files for syntax errors ... OK
>>> * checking whether the package can be loaded ... OK
>>> * checking whether the package can be loaded with stated dependencies
>>> ... OK
>>> * checking whether the package can be unloaded cleanly ... OK
>>> * checking whether the namespace can be loaded with stated dependencies
>>> ... OK
>>> * checking whether the namespace can be unloaded cleanly ... OK
>>> * checking loading without being on the library search path ... WARNING
>>> Loading required package: splines
>>> Loading required package: zoo
>>> Error: package 'zoo' could not be loaded
>>> In addition: Warning message:
>>> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
>>> lib.loc) :
>>>      there is no package called 'zoo'
>>> Execution halted
>>>
>>> It looks like this package has a loading problem when not on .libPaths:
>>> see the messages for details.
>>> * checking for unstated dependencies in R code ... OK
>>> * checking S3 generic/method consistency ... OK
>>> * checking replacement functions ... OK
>>> * checking foreign function calls ... OK
>>> * checking R code for possible problems ... OK
>>> * checking Rd files ... OK
>>> * checking Rd metadata ... OK
>>> * checking Rd cross-references ... WARNING
>>> Missing link(s) in documentation object
>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd':
>>>
>>>      'use.proper.basis' 'is.eqbasis'
>>>
>>> Missing link(s) in documentation object
>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd':
>>>
>>>      'plot.cca.fd'
>>>
>>> Missing link(s) in documentation object
>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd':
>>>
>>>      'polynom'
>>>
>>> Missing link(s) in documentation object
>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd':
>>>
>>>      'polynompen'
>>>
>>> Missing link(s) in documentation object
>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd':
>>>
>>>      'getURL'
>>>
>>> See the information in section 'Cross-references' of the 'Writing R
>>> Extensions' manual.
>>>
>>> * checking for missing documentation entries ... OK
>>> * checking for code/documentation mismatches ... OK
>>> * checking Rd \usage sections ... OK
>>> * checking Rd contents ... OK
>>> * checking for unstated dependencies in examples ... OK
>>> * checking contents of 'data' directory ... OK
>>> * checking data for non-ASCII characters ... OK
>>> * checking data for ASCII and uncompressed saves ... OK
>>> * checking installed files from 'inst/doc' ... OK
>>> * checking examples ... ERROR
>>> Running examples in 'fda-Ex.R' failed
>>> The error most likely occurred in:
>>>
>>>    > ### Name: CanadianWeather
>>>    > ### Title: Canadian average annual weather cycle
>>>    > ### Aliases: CanadianWeather daily
>>>    > ### Keywords: datasets
>>>    >
>>>    > ### ** Examples
>>>    >
>>>    > ##
>>>    > ## 1.  Plot (latitude & longitude) of stations by region
>>>    > ##
>>>    > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1],
>>> type='n',
>>> +                            xlab="West Longitude", ylab="North
>>> Latitude",
>>> +                            axes=FALSE) )
>>>    > Wlon <- pretty(CanadianWeather$coordinates[, 2])
>>>    > axis(1, -Wlon, Wlon)
>>>    > axis(2)
>>>    >
>>>    > rgns <- 1:4
>>>    > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
>>>    > Rgns <- rgns[CanadianWeather$region]
>>>    > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
>>> +                              col=Rgns, pch=Rgns) )
>>>    > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
>>>    >
>>>    > ##
>>>    > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
>>>    > ##
>>>    > data(CanadianWeather)
>>>    > # Expand the left margin to allow space for place names
>>>    > op <- par(mar=c(5, 4, 4, 5)+.1)
>>>    > # Plot
>>>    > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
>>>    > matplot(day.5, CanadianWeather$dailyAv[, stations, "Temperature.C"],
>>> +         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg
>>> C)")
>>> Error in UseMethod("matplot") :
>>>      no applicable method for 'matplot' applied to an object of class
>>> "c('double', 'numeric')"
>>> Calls: matplot
>>> Execution halted
>>>
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>     > sessionInfo()
>>>>> R version 2.15.2 (2012-10-26)
>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=English_United States.1252
>>>>> [2] LC_CTYPE=English_United States.1252
>>>>> [3] LC_MONETARY=English_United States.1252
>>>>> [4] LC_NUMERIC=C
>>>>> [5] LC_TIME=English_United States.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>
>>>>> other attached packages:
>>>>> [1] zoo_1.7-9
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] grid_2.15.2     lattice_0.20-10
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From pauljohn32 at gmail.com  Thu Dec  6 00:58:42 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 5 Dec 2012 17:58:42 -0600
Subject: [Rd] Understanding svd usage and its necessity in generalized
	inverse calculation
Message-ID: <CAErODj9LyK3aZSJjxLPEeTTB3QN9rzEsdHYXnMa26xU98REQgg@mail.gmail.com>

Dear R-devel:

I could use some advice about matrix calculations and steps that might
make for faster computation of generalized inverses. It appears in
some projects there is a bottleneck at the use of svd in calculation
of generalized inverses.

Here's some Rprof output I need to understand.

>   summaryRprof("Amelia.out")
$by.self
                             self.time self.pct total.time total.pct
"La.svd"                        150.34    27.66     164.82     30.32
"emfred"                         40.90     7.52     535.62     98.53
"<Anonymous>"                    32.92     6.06     122.16     22.47
"amsweep"                        26.70     4.91     475.94     87.55
"%*%"                            26.06     4.79      26.06      4.79
"as.matrix"                      23.32     4.29      37.34      6.87
"structure"                      22.30     4.10      30.68      5.64
"t"                              18.64     3.43      25.34      4.66
"matrix"                         14.66     2.70      15.02      2.76
"deparse"                        14.52     2.67      33.58      6.18
"strsplit"                        9.90     1.82       9.90      1.82
"match"                           9.80     1.80      22.94      4.22
"conditionMessage"                8.92     1.64      14.50      2.67
"svd"                             8.70     1.60     185.88     34.19
"mpinv"                           8.40     1.55     221.56     40.76
"c"                               8.16     1.50       8.16      1.50
".deparseOpts"                    7.92     1.46      12.42      2.28
"$"                               6.94     1.28       6.94      1.28
"t.default"                       6.70     1.23       6.70      1.23
"diag"                            5.66     1.04       8.96      1.65
"cbind"                           5.48     1.01       5.48      1.01
"rbind"                           5.36     0.99      10.84      1.99
"am.inv"                          4.88     0.90      10.76      1.98
".Call"                           4.70     0.86       4.70      0.86
[snip]

$by.total
                             total.time total.pct self.time self.pct
"amelia.default"                 543.58     99.99      0.04     0.01
"amelia"                         543.58     99.99      0.00     0.00
"emarch"                         536.94     98.77      0.18     0.03
"emfred"                         535.62     98.53     40.90     7.52
"amsweep"                        475.94     87.55     26.70     4.91
"mpinv"                          221.56     40.76      8.40     1.55
"svd"                            185.88     34.19      8.70     1.60
"La.svd"                         164.82     30.32    150.34    27.66
"try"                            161.52     29.71      0.50     0.09
"tryCatch"                       161.04     29.62      3.38     0.62
"tryCatchList"                   157.06     28.89      1.06     0.19
"tryCatchOne"                    156.00     28.70      3.20     0.59
"<Anonymous>"                    122.16     22.47     32.92     6.06
"as.matrix"                       37.34      6.87     23.32     4.29
"deparse"                         33.58      6.18     14.52     2.67
"structure"                       30.68      5.64     22.30     4.10
"%*%"                             26.06      4.79     26.06     4.79
"t"                               25.34      4.66     18.64     3.43
"match"                           22.94      4.22      9.80     1.80
"%in%"                            21.74      4.00      2.44     0.45
"simpleError"                     16.72      3.08      0.62     0.11
"matrix"                          15.02      2.76     14.66     2.70
"conditionMessage"                14.50      2.67      8.92     1.64
"mode"                            14.44      2.66      1.76     0.32
"doTryCatch"                      13.94      2.56      2.72     0.50
".deparseOpts"                    12.42      2.28      7.92     1.46

I *Think* this means that a bottlleneck here is svd, which is being
called by this function that calculates generalized inverses:

## Moore-Penrose Inverse function (aka Generalized Inverse)
##   X:    symmetric matrix
##   tol:  convergence requirement
mpinv <- function(X, tol = sqrt(.Machine$double.eps)) {
  s <- svd(X)
  e <- s$d
  e[e > tol] <- 1/e[e > tol]
  s$v %*% diag(e,nrow=length(e)) %*% t(s$u)
}

That is from the Amerlia package, which we like to use very much.

Basically, I wonder if I should use a customized generalized inverse
or svd calculator to make this faster.

Why bother, you ask?  We have many people who do multiple imputation
for missing data and the psychologists are persuaded that they now
ought to collect 50 or 100 imputations (gulp).  The users want to
include many many variables in these models, and so we see iterations
in the 100s for each imputation.  That makes for some super long
running jobs, and I've been profiling the multiple imputation
algorithms in various packages to see what I can do to make them
faster.

Question: Is the usage of svd really necessary for generalized
inverse? Can I employ some alternative to get faster?  The literature
on this is pretty specialized.  I mean to say, "will one of you math
professors please tell me what is safe or unsafe".

The cholesky decomposition is fastest for the well conditioned matrix,
but not suitable to all matrices.  svd is the gold standard for
accuracy, but it is slowest. In the past, I've chased speedups like
this and sometimes find a happy answer, but just as often I wish I had
asked an expert before wandering off on a fool's errand.

There's plenty of literature about it. See, for example, this article:

Smoktunowicz, A., & Wr?bel, I. (2012). Numerical aspects of computing
the Moore-Penrose inverse of full column rank matrices. BIT Numerical
Mathematics, 52(2), 503?524. doi:10.1007/s10543-011-0362-0

Which seems to say that a method proposed by Byers and Xu (2008) is as
about as good as, but faster than, svd.

It appears to me work on this traces back to a speedup obtained by
Courrieu, whose method takes about one-half as much time as the svd.

P. Courrieu. Fast Computation of Moore-Penrose Inverse matrices.
Neural Information
Processing-Letters and Reviews, 8:25?29, 2005.

Katsikis, Casilos N. and Dimitrios Pappas. 2008. Fast computing of the
Moore-Penrose Inverse Matrix. Electronic Journal of Linear Algebra 17:
637-650.
http://celc.cii.fc.ul.pt/iic/ela/ela-articles/articles/vol17_pp337-350.pdf

Toutounian, F., & Ataei, A. (2009). A new method for computing
Moore-Penrose inverse matrices. J. Comput. Appl. Math., 228(1),
412?417. doi:10.1016/j.cam.2008.10.008

I see in the MASS package there is a ginv function, it uses the svd,
just as the mpinv in Amelia does.

Maybe I should ignore this, or leave it up to some BLAS implementation?

pj

-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From spencer.graves at prodsyse.com  Thu Dec  6 00:59:50 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 05 Dec 2012 15:59:50 -0800
Subject: [Rd] NAMESPACE problem: import(zoo) but 'zoo' could not be
	loaded
In-Reply-To: <50BFB8C3.3020208@gmail.com>
References: <50BEE88E.9080701@prodsyse.com> <50BF9C42.8090506@gmail.com>
	<50BF9E30.1050402@prodsyse.com> <50BFA01D.3080708@gmail.com>
	<50BFADF8.6010203@prodsyse.com> <50BFB8C3.3020208@gmail.com>
Message-ID: <50BFDFF6.9000006@prodsyse.com>

On 12/5/2012 1:12 PM, Duncan Murdoch wrote:
> On 12-12-05 3:26 PM, Spencer Graves wrote:
>> On 12/5/2012 11:27 AM, Duncan Murdoch wrote:
>>> On 12-12-05 2:19 PM, Spencer Graves wrote:
>>>> On 12/5/2012 11:10 AM, Duncan Murdoch wrote:
>>>>> On 12-12-05 1:24 AM, Spencer Graves wrote:
>>>>>> Hello:
>>>>>>
>>>>>>
>>>>>>           I'm having problems creating a real NAMESPACE to replace
>>>>>> the pro
>>>>>> forma one in the fda package on R-Forge.  "R CMD check" complains,
>>>>>> "Error: package 'zoo' could not be loaded ... there is no package
>>>>>> called
>>>>>> 'zoo'";  see below.  I get this both with and without 
>>>>>> "import(zoo)" in
>>>>>> NAMESPACE.
>>>>>>
>>>>>>
>>>>>>           Suggestions?
>>>>>>           Thanks,
>>>>>>           Spencer
>>>>>>
>>>>>>
>>>>>> p.s.  The current code including this problem can be obtained 
>>>>>> through
>>>>>> anonymous access via "svn checkout
>>>>>> svn://svn.r-forge.r-project.org/svnroot/fda/".
>>>>>>
>>>>>>
>>>>>> C:\Users\sgraves\2012\R_pkgs\fda>R CMD check fda_2.3.3.tar.gz
>>>>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>>>>> * using R version 2.15.2 (2012-10-26)
>>>>>> * using platform: i386-w64-mingw32 (32-bit)
>>>>>>
>>>>>> <snip>
>>>>>>
>>>>>> * checking loading without being on the library search path ...
>>>>>> WARNING
>>>>>> Loading required package: splines
>>>>>> Loading required package: zoo
>>>>>> Error: package 'zoo' could not be loaded
>>>>>> In addition: Warning message:
>>>>>> In library(pkg, character.only = TRUE, logical.return = TRUE,
>>>>>> lib.loc =
>>>>>> lib.loc)
>>>>>>      :
>>>>>>       there is no package called 'zoo'
>>>>>> Execution halted
>>>>>>
>>>>>> It looks like this package has a loading problem when not on
>>>>>> .libPaths:
>>>>>> see the messages for details.
>>>>>
>>>>> This message is printed by tools when there's an error when it tries
>>>>> to load a package (not sure if it's yours or zoo) that is not in the
>>>>> .libPaths.  There might be more details in the check log.
>>>>>
>>>>> What does it say there?
>>>>
>>>>
>>>>          I didn't see any more than the portion copied here. Below 
>>>> please
>>>> find the entire 00check.log.  Thanks, Spencer
>>>>
>>>
>>> Do you have more than one library, or do you use the default
>>> .libPaths()?  I'm on a slightly old install of R on this Mac, and I
>>> see this (starting R from the same place I ran the check):
>>>
>>>> .libPaths()
>>> [1] "/Library/Frameworks/R.framework/Versions/2.15/Resources/library"
>>>
>>> What do you see?
>>
>>
>>   > .libPaths()
>> [1] "C:/Users/sgraves/pgms/R/R-2.15.2/library"
>> [2] "C:/Users/sgraves/R/win-library/2.15"
>
> I would guess the problem is that it is using a different .libPaths 
> setting for that test, and zoo is in the wrong place.  I don't know 
> whether this is something you did or a bug in the check code.
>
> In any case, that's a funny ordering you're using:  normally I'd 
> expect the user-specific library to come first (because it would be 
> searched first), and that would be followed by the system library 
> installed with R.  How are you setting it?


       I don't know how it was being set.  I couldn't find the second 
path in environment variables or Rprofile.site.  However, when I 
physically deleted it, restarted R, Emacs, and the Windows Command 
Prompt, it went away.  Now .libPaths() contains only the first path.  
After I installed zoo in that, this error went away.


       Thanks again for your help.
       Spencer

>
> Duncan Murdoch
>
>>   >
>>
>>         Thanks.  Spencer
>>
>>>
>>> Duncan Murdoch
>>>
>>>
>>>>
>>>> * using log directory 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck'
>>>> * using R version 2.15.2 (2012-10-26)
>>>> * using platform: i386-w64-mingw32 (32-bit)
>>>> * using session charset: ISO8859-1
>>>> * checking for file 'fda/DESCRIPTION' ... OK
>>>> * this is package 'fda' version '2.3.3'
>>>> * checking package namespace information ... OK
>>>> * checking package dependencies ... OK
>>>> * checking if this is a source package ... OK
>>>> * checking if there is a namespace ... OK
>>>> * checking for executable files ... OK
>>>> * checking whether package 'fda' can be installed ... OK
>>>> * checking installed package size ... OK
>>>> * checking package directory ... OK
>>>> * checking for portable file names ... OK
>>>> * checking DESCRIPTION meta-information ... OK
>>>> * checking top-level files ... OK
>>>> * checking for left-over files ... OK
>>>> * checking index information ... OK
>>>> * checking package subdirectories ... OK
>>>> * checking R files for non-ASCII characters ... OK
>>>> * checking R files for syntax errors ... OK
>>>> * checking whether the package can be loaded ... OK
>>>> * checking whether the package can be loaded with stated dependencies
>>>> ... OK
>>>> * checking whether the package can be unloaded cleanly ... OK
>>>> * checking whether the namespace can be loaded with stated 
>>>> dependencies
>>>> ... OK
>>>> * checking whether the namespace can be unloaded cleanly ... OK
>>>> * checking loading without being on the library search path ... 
>>>> WARNING
>>>> Loading required package: splines
>>>> Loading required package: zoo
>>>> Error: package 'zoo' could not be loaded
>>>> In addition: Warning message:
>>>> In library(pkg, character.only = TRUE, logical.return = TRUE, 
>>>> lib.loc =
>>>> lib.loc) :
>>>>      there is no package called 'zoo'
>>>> Execution halted
>>>>
>>>> It looks like this package has a loading problem when not on 
>>>> .libPaths:
>>>> see the messages for details.
>>>> * checking for unstated dependencies in R code ... OK
>>>> * checking S3 generic/method consistency ... OK
>>>> * checking replacement functions ... OK
>>>> * checking foreign function calls ... OK
>>>> * checking R code for possible problems ... OK
>>>> * checking Rd files ... OK
>>>> * checking Rd metadata ... OK
>>>> * checking Rd cross-references ... WARNING
>>>> Missing link(s) in documentation object
>>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/basisfd.Rd': 
>>>>
>>>>
>>>>      'use.proper.basis' 'is.eqbasis'
>>>>
>>>> Missing link(s) in documentation object
>>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/cca.fd.Rd': 
>>>>
>>>>
>>>>      'plot.cca.fd'
>>>>
>>>> Missing link(s) in documentation object
>>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomial.Rd': 
>>>>
>>>>
>>>>      'polynom'
>>>>
>>>> Missing link(s) in documentation object
>>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/monomialpen.Rd': 
>>>>
>>>>
>>>>      'polynompen'
>>>>
>>>> Missing link(s) in documentation object
>>>> 'C:/Users/sgraves/2012/R_pkgs/fda/fda.Rcheck/00_pkg_src/fda/man/readHMD.Rd': 
>>>>
>>>>
>>>>      'getURL'
>>>>
>>>> See the information in section 'Cross-references' of the 'Writing R
>>>> Extensions' manual.
>>>>
>>>> * checking for missing documentation entries ... OK
>>>> * checking for code/documentation mismatches ... OK
>>>> * checking Rd \usage sections ... OK
>>>> * checking Rd contents ... OK
>>>> * checking for unstated dependencies in examples ... OK
>>>> * checking contents of 'data' directory ... OK
>>>> * checking data for non-ASCII characters ... OK
>>>> * checking data for ASCII and uncompressed saves ... OK
>>>> * checking installed files from 'inst/doc' ... OK
>>>> * checking examples ... ERROR
>>>> Running examples in 'fda-Ex.R' failed
>>>> The error most likely occurred in:
>>>>
>>>>    > ### Name: CanadianWeather
>>>>    > ### Title: Canadian average annual weather cycle
>>>>    > ### Aliases: CanadianWeather daily
>>>>    > ### Keywords: datasets
>>>>    >
>>>>    > ### ** Examples
>>>>    >
>>>>    > ##
>>>>    > ## 1.  Plot (latitude & longitude) of stations by region
>>>>    > ##
>>>>    > with(CanadianWeather, plot(-coordinates[, 2], coordinates[, 1],
>>>> type='n',
>>>> +                            xlab="West Longitude", ylab="North
>>>> Latitude",
>>>> +                            axes=FALSE) )
>>>>    > Wlon <- pretty(CanadianWeather$coordinates[, 2])
>>>>    > axis(1, -Wlon, Wlon)
>>>>    > axis(2)
>>>>    >
>>>>    > rgns <- 1:4
>>>>    > names(rgns) <- c('Arctic', 'Atlantic', 'Continental', 'Pacific')
>>>>    > Rgns <- rgns[CanadianWeather$region]
>>>>    > with(CanadianWeather, points(-coordinates[, 2], coordinates[, 1],
>>>> +                              col=Rgns, pch=Rgns) )
>>>>    > legend('topright', legend=names(rgns), col=rgns, pch=rgns)
>>>>    >
>>>>    > ##
>>>>    > ## 2.  Plot dailyAv[, 'Temperature.C'] for 4 stations
>>>>    > ##
>>>>    > data(CanadianWeather)
>>>>    > # Expand the left margin to allow space for place names
>>>>    > op <- par(mar=c(5, 4, 4, 5)+.1)
>>>>    > # Plot
>>>>    > stations <- c("Pr. Rupert", "Montreal", "Edmonton", "Resolute")
>>>>    > matplot(day.5, CanadianWeather$dailyAv[, stations, 
>>>> "Temperature.C"],
>>>> +         type="l", axes=FALSE, xlab="", ylab="Mean Temperature (deg
>>>> C)")
>>>> Error in UseMethod("matplot") :
>>>>      no applicable method for 'matplot' applied to an object of class
>>>> "c('double', 'numeric')"
>>>> Calls: matplot
>>>> Execution halted
>>>>
>>>>>
>>>>> Duncan Murdoch
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>     > sessionInfo()
>>>>>> R version 2.15.2 (2012-10-26)
>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_United States.1252
>>>>>> [2] LC_CTYPE=English_United States.1252
>>>>>> [3] LC_MONETARY=English_United States.1252
>>>>>> [4] LC_NUMERIC=C
>>>>>> [5] LC_TIME=English_United States.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] zoo_1.7-9
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] grid_2.15.2     lattice_0.20-10
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From suharto_anggono at yahoo.com  Thu Dec  6 06:39:36 2012
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 5 Dec 2012 21:39:36 -0800 (PST)
Subject: [Rd] factor(x, exclude=y) if x is a factor
Message-ID: <1354772376.18523.YahooMailClassic@web125102.mail.ne1.yahoo.com>

I found this part in the documentation of 'factor'.

     'factor(x, exclude=NULL)' applied to a factor is a no-operation
     unless there are unused levels: in that case, a factor with the
     reduced level set is returned.  If 'exclude' is used it should
     also be a factor with the same level set as 'x' or a set of codes
     for the levels to be excluded.


Regarding the last sentence, this is the actual behavior.

> x <- factor(c("a","b"), levels=c("a","b"))
> x
[1] a b
Levels: a b
> factor(x, exclude=factor("a", levels=c("a","b")))
[1] a b
Levels: a b
> factor(x, exclude=1L)
[1] a b
Levels: a b

I expect "a" to be removed from levels.


> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.2


The results are the same in R 2.5.1.


In R 2.5.1, if function 'match' did not apply 'as.character' to factor (and used internal code of factor instead), it would work to set 'exclude' as in the above quotation of the documentation. In the example above, "a" would be removed from levels.


One cause of the trouble is this code in the definition of function 'factor', in R 2.15.2 or in R 2.5.1.

    exclude <- as.vector(exclude, typeof(x))

What is the intent actually?


From hpages at fhcrc.org  Thu Dec  6 09:15:38 2012
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 6 Dec 2012 00:15:38 -0800
Subject: [Rd] inconsistencies between ?class and ?UseMethod
In-Reply-To: <87y5hdukeg.fsf@tajo.ucsd.edu>
References: <50BE79D4.5060205@fhcrc.org> <87y5hdukeg.fsf@tajo.ucsd.edu>
Message-ID: <50C0542A.4010709@fhcrc.org>



On 12/04/2012 09:40 PM, cberry at tajo.ucsd.edu wrote:
> Herv? Pag?s <hpages at fhcrc.org> writes:
>
>> Hi,
>>
>> The 2 man pages give inconsistent description of class():
>>
>> Found in ?class:
>>
>>       If the object does not have a class attribute, it has an implicit
>>       class, ?"matrix"?, ?"array"? or the result of ?mode(x)? (except
>>       that integer vectors have implicit class ?"integer"?).
>>
>> Found in ?UseMethod:
>>
>>       Matrices and arrays have class ?"matrix"? or?"array"? followed
>>       by the class of the underlying vector.
>>       Most vectors have class the result of ?mode(x)?, except that
>>       integer vectors have class ?c("integer", "numeric")? and real
>>       vectors have class ?c("double", "numeric")?.
>>
>> So according to ?UseMethod, class(matrix(1:4)) should be
>> c("matrix", "integer", "numeric"), which is of course not the case:
>>
>>    > class(matrix(1:4))
>>    [1] "matrix"
>>
>> I wonder if this was ever true, and, if so, when and why it has changed.
>
>
> It still is in the sense that UseMethod and NextMethod dispatch in that
> manner on implicit classes.

Yes I understand that:

 > is.matrix(matrix(1:4))
[1] TRUE
 > is.integer(matrix(1:4))
[1] TRUE
 > is.numeric(matrix(1:4))
[1] TRUE

but then:

 > is(matrix(1:4), "matrix")
[1] TRUE
 > is(matrix(1:4), "integer")
[1] FALSE
 > is(matrix(1:4), "numeric")
[1] FALSE

and also:

 > inherits(matrix(1:4), "matrix")
[1] TRUE
 > inherits(matrix(1:4), "integer")
[1] FALSE
 > inherits(matrix(1:4), "numeric")
[1] FALSE

despite the use of the term _inherits_ in ?UseMethod (underlined, yes!)

See, the biggest challenge we are facing is to stay focused on 1 issue
at a time, and the issue I'm reporting here is that ?class is saying
something and ?UseMethod is saying something else. I'm not that
interested in discussing which one is telling the truth, and even less
how what they say is connected to other tools, that would take us way
too far ;-)

Thanks,
H.

> It is bit confusing to me that class()
> doesn't report all the implicit classes (like the first error message
> below) and inherits() only admits what class() has told.
>
> Note what the first error message below says and how the succesive calls
> for afun() work as methods are added to the generic.
>
> If you set a class attribute then the picture changes. I do not see where
> this is documented, but it looks like once a class attribute is set, the
> implicit classes go away - per the last error message.
>
>> afun <- function(x) UseMethod("afun",x)
>> afun(matrix(1L,nc=1))
> Error in UseMethod("afun", x) :
>    no applicable method for 'afun' applied to an object of class
>    "c('matrix', 'integer', 'numeric')"
>> afun.numeric <- function(x) cat("numeric",x,"\n")
>> afun(matrix(1L,nc=1))
> numeric 1
>> afun.integer <- function(x) cat("integer",x,"\n")
>> afun(matrix(1L,nc=1))
> integer 1
>> afun.matrix <- function(x) cat("matrix",x,"\n")
>> afun(matrix(1L,nc=1))
> matrix 1
>> afun.matrix <- function(x) NextMethod()
>> afun(matrix(1L,nc=1))
> integer 1
>> afun.fooey <- function(x) NextMethod()
>> my.mat <- matrix(1L,nc=1)
>> afun(my.mat)
> matrix 1
>> class(my.mat) <- "fooey"
>> afun(my.mat)
> Error in NextMethod() : no method to invoke
>>
>
>> Anyway, an update to ?UseMethod would be welcome.
>
> I wonder if "except with implicit" would improve over "with some
> interpolated" in ?class here:
>
> "...in R UseMethod dispatches on the class as returned by class (with
> some interpolated classes: see the link)"
>
> HTH,
>
> Chuck
>
>> Or, documenting
>> class() in only 1 place seems even better (more DRY principle).
>>
>> Thanks,
>> H.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jon.clayden at gmail.com  Thu Dec  6 11:59:29 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 6 Dec 2012 10:59:29 +0000
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
	<CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
Message-ID: <CAM9CR=3e3L+XYU+JTCy_SOzYupu7-zVAhj7sN+LsDEsC0LP+LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121206/cb1fa21e/attachment.pl>

From therneau at mayo.edu  Thu Dec  6 15:48:13 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 06 Dec 2012 08:48:13 -0600
Subject: [Rd] as.matrix.Surv -- R core question/opinions
Message-ID: <50C0B02D.4070803@mayo.edu>

1. A Surv object is a matrix with some extra attributes.  The as.matrix.Surv function 
removes the extras but otherwise leaves it as is.

2. The last several versions of the survival library were accidentally missing the 
S3method('as.matrix', 'Surv') line from their NAMESPACE file.  (Instead it's position is 
held by a duplicate of the line just above it in the NAMESPACE file, suggesting a 
copy/paste error).  As a consequence the as.matrix.Surv function was effectively ignored, 
and the default method was being used.
    The as.matrix.default function leaves anything with a "dim" attribute alone.

3. In my current about-to-submit-to-CRAN  version of survival the missing NAMESPACE line 
was restored.  This breaks one function in one package (rms) which calls "as.matrix(y)" on 
a Surv object but then later looks at the "type" attribute of y.

  So now to the design question: should the as.matrix.Surv function "sanitize" the result 
by removing the extra attributes, or should it leave them alone?  The first seems cleaner; 
my accidental multi-year test of leaving them in, however, clearly shows that it does no 
harm.

Terry T.


From maechler at stat.math.ethz.ch  Thu Dec  6 16:12:49 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 6 Dec 2012 16:12:49 +0100
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
	<CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
Message-ID: <20672.46577.43959.564387@stat.math.ethz.ch>

>>>>> elijah wright <elw at stderr.org>
>>>>>     on Wed, 5 Dec 2012 14:23:51 -0600 writes:

    > Is that a build with "good old" Studio or a build with a recent GCC?
    > I don't have any direct comments that would be helpful to you - but let me
    > know if you need a place to do some test builds and try to figure it out.
    > I can certainly help you with that.

    > [Are more Solaris-esque build slaves needed?  Someone give a shout if so...
    > we can sponsor some infrastructure there.]

`` shout! ''

as long we (R community at large "in principle", de facto,
   	    AFAIK, Prof Brian Ripley) 
can have a Solaris testbed for CRAN which is reflected in the
CRAN package check, it would be really great if someone provided
a "Solaris-builder" server similar to the
win-builder.r-project.org one that Uwe (and his Depaertment/
University) provides. 

Martin

    > --elijah
    > (@Joyent)



    > On Mon, Dec 3, 2012 at 11:28 AM, Jon Clayden <jon.clayden at gmail.com> wrote:

    >> Dear all,
    >> 
    >> The current version of my RNiftyReg package is failing to compile on CRAN's
    >> Solaris testbed, but I don't have access to a Solaris system to debug on,
    >> and Googling the error hasn't been very helpful. The error is
    >> 
    >> CC -library=stlport4 -I/home/ripley/R/cc/include -DNDEBUG -DNDEBUG
    >> -DRNIFTYREG -I/usr/local/include    -KPIC  -O -xlibmil -xtarget=native
    >> -nofstore  -c niftyreg.cpp -o niftyreg.o
    >> "_reg_f3d_sym.cpp", line 25: Error: reg_f3d may not have a type qualifier.
    >> "niftyreg.cpp", line 527:     Where: While instantiating
    >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
    >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
    >> "_reg_f3d_sym.cpp", line 26: Error: reg_f3d<T> cannot be initialized
    >> in a constructor.
    >> "niftyreg.cpp", line 527:     Where: While instantiating
    >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
    >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
    >> "_reg_f3d_sym.cpp", line 26: Error: Could not find
    >> reg_f3d<double>::reg_f3d() to initialize base class.
    >> "niftyreg.cpp", line 527:     Where: While instantiating
    >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
    >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
    >> 3 Error(s) detected.
    >> *** Error code 2
    >> make: Fatal error: Command failed for target `niftyreg.o'
    >> 
    >> 
    >> (Full log at [1].) The relevant part of the source is a C++ class
    >> constructor, part of the library that my package interfaces to:
    >> 
    >> template <class T>
    >> reg_f3d_sym<T>::reg_f3d_sym(int refTimePoint,int floTimePoint)
    >> :reg_f3d<T>::reg_f3d(refTimePoint,floTimePoint)
    >> {
    this-> executableName=(char *)"NiftyReg F3D SYM";
    >> 
    this-> backwardControlPointGrid=NULL;
    this-> backwardWarped=NULL;
    this-> backwardWarpedGradientImage=NULL;
    this-> backwardDeformationFieldImage=NULL;
    this-> backwardVoxelBasedMeasureGradientImage=NULL;
    this-> backwardNodeBasedGradientImage=NULL;
    >> 
    this-> backwardBestControlPointPosition=NULL;
    this-> backwardConjugateG=NULL;
    this-> backwardConjugateH=NULL;
    >> 
    this-> backwardProbaJointHistogram=NULL;
    this-> backwardLogJointHistogram=NULL;
    >> 
    this-> floatingMaskImage=NULL;
    this-> currentFloatingMask=NULL;
    this-> floatingMaskPyramid=NULL;
    this-> backwardActiveVoxelNumber=NULL;
    >> 
    this-> inverseConsistencyWeight=0.1;
    >> 
    >> #ifndef NDEBUG
    >> printf("[NiftyReg DEBUG] reg_f3d_sym constructor called\n");
    >> #endif
    >> }
    >> 
    >> The error does not occur on any Windows, Linux or OS X system which I have
    >> access to, so this would seem to be an issue relating to the Solaris
    >> compiler toolchain in particular. Can anyone shed any light on it, please?
    >> 
    >> Thanks in advance,
    >> Jon
    >> 
    >> --
    >> [1]
    >> 
    >> http://www.r-project.org/nosvn/R.check/r-patched-solaris-x86/RNiftyReg-00install.html
    >>


From lorenz at usgs.gov  Thu Dec  6 16:12:24 2012
From: lorenz at usgs.gov (Lorenz, David)
Date: Thu, 6 Dec 2012 09:12:24 -0600
Subject: [Rd] factor(x, exclude=y) if x is a factor
In-Reply-To: <1354772376.18523.YahooMailClassic@web125102.mail.ne1.yahoo.com>
References: <1354772376.18523.YahooMailClassic@web125102.mail.ne1.yahoo.com>
Message-ID: <CALxY2Lcgd0cJAHi1w5r4Npzp9-a6w5B7OOLEip-Ax8LP8+PTxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121206/c67fd956/attachment.pl>

From wdunlap at tibco.com  Thu Dec  6 16:32:33 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Dec 2012 15:32:33 +0000
Subject: [Rd] svd(X, LINPACK=TRUE) alters its input
Message-ID: <E66794E69CFDE04D9A70842786030B931B8C8C24@PA-MBX04.na.tibco.com>

Ordinary functions should not alter their inputs but in R-2.15.2
svd(LINPACK=TRUE,X) does.  (It worked in 2.15.0 but not in 2.15.1
or 2.15.2 and became deprecated in 2.15.2.)

> X <- matrix(c(1,2,3, 5,7,11, 13,17,19), 3, 3)
> X
     [,1] [,2] [,3]
[1,]    1    5   13
[2,]    2    7   17
[3,]    3   11   19
> svd(X, LINPACK=TRUE)$d
[1] 31.9718214  2.3882717  0.3143114
Warning message:
In svd(X, LINPACK = TRUE) : LINPACK = TRUE is deprecated
> X
          [,1]        [,2]        [,3]
[1,] 1.2672612 -13.8975846 -27.7951692
[2,] 0.5345225   1.0945920   2.1072825
[3,] 0.8017837   0.9955161  -0.9794695
> version
               _                            
platform       x86_64-w64-mingw32           
arch           x86_64                       
os             mingw32                      
system         x86_64, mingw32              
status                                      
major          2                            
minor          15.2                         
year           2012                         
month          10                           
day            26                           
svn rev        61015                        
language       R                            
version.string R version 2.15.2 (2012-10-26)
nickname       Trick or Treat  
> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base                  

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From edd at debian.org  Thu Dec  6 16:34:48 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 6 Dec 2012 09:34:48 -0600
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <20672.46577.43959.564387@stat.math.ethz.ch>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
	<CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
	<20672.46577.43959.564387@stat.math.ethz.ch>
Message-ID: <20672.47896.772981.226424@max.nulle.part>


On 6 December 2012 at 16:12, Martin Maechler wrote:
| >>>>> elijah wright <elw at stderr.org>
| >>>>>     on Wed, 5 Dec 2012 14:23:51 -0600 writes:
| 
|     > Is that a build with "good old" Studio or a build with a recent GCC?
|     > I don't have any direct comments that would be helpful to you - but let me
|     > know if you need a place to do some test builds and try to figure it out.
|     > I can certainly help you with that.
| 
|     > [Are more Solaris-esque build slaves needed?  Someone give a shout if so...
|     > we can sponsor some infrastructure there.]
| 
| `` shout! ''

:)

| as long we (R community at large "in principle", de facto,
|    	    AFAIK, Prof Brian Ripley) 
| can have a Solaris testbed for CRAN which is reflected in the
| CRAN package check, it would be really great if someone provided
| a "Solaris-builder" server similar to the
| win-builder.r-project.org one that Uwe (and his Depaertment/
| University) provides. 

In a world with finite resources in terms of coding time and attention span,
should we not provide such resources first for OS X and Linux?  But maybe we
need some empirics first so that we can rank-order compilers by relevance.

I for one get more error emails from Intel icc users (say, two a year) than
from Solaris users (probably about one or two, over all these years; and yes
I excluded the CRAN maintainers here).

That said, we do have a concrete offer for help from Elijah which should a)
be commended ("nice job!") and used but b) we should maybe try to think about
what other resources would help.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From kasperdanielhansen at gmail.com  Thu Dec  6 16:38:01 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 6 Dec 2012 10:38:01 -0500
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <20672.46577.43959.564387@stat.math.ethz.ch>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
	<CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
	<20672.46577.43959.564387@stat.math.ethz.ch>
Message-ID: <CAC2h7usePq1EKKuZVHCYotQf21qodOOoO8vZQpyU9qnUXQCHHg@mail.gmail.com>

On Thu, Dec 6, 2012 at 10:12 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> elijah wright <elw at stderr.org>
>>>>>>     on Wed, 5 Dec 2012 14:23:51 -0600 writes:
>
>     > Is that a build with "good old" Studio or a build with a recent GCC?
>     > I don't have any direct comments that would be helpful to you - but let me
>     > know if you need a place to do some test builds and try to figure it out.
>     > I can certainly help you with that.
>
>     > [Are more Solaris-esque build slaves needed?  Someone give a shout if so...
>     > we can sponsor some infrastructure there.]
>
> `` shout! ''
>
> as long we (R community at large "in principle", de facto,
>             AFAIK, Prof Brian Ripley)
> can have a Solaris testbed for CRAN which is reflected in the
> CRAN package check, it would be really great if someone provided
> a "Solaris-builder" server similar to the
> win-builder.r-project.org one that Uwe (and his Depaertment/
> University) provides.

Getting a solaris-builder would be awesome.  My understanding is that
people both use a Solaris supplied compiler as well as GCC regularly
on this platform (ok, I don't fully know what I am talking about here,
since I don't have access to Solaris), and having one builder for each
compiler would be awesome.  (As would a linux machine with an intel
compiler, now that I am dreaming).

Additionally, right now I personally have a need for a login to a
Solaris machine. Some build problems with Rgraphviz has been reported
on Solaris and there is no way I can fix them without command line
access.

Best,
Kasper Daniel Hansen
Assistant Professor
McKusick-Nathans Institute of Genetic Medicine
Department of Biostatistics
Johns Hopkins University
Website: http://www.biostat.jhsph.edu/~khansen




> Martin
>
>     > --elijah
>     > (@Joyent)
>
>
>
>     > On Mon, Dec 3, 2012 at 11:28 AM, Jon Clayden <jon.clayden at gmail.com> wrote:
>
>     >> Dear all,
>     >>
>     >> The current version of my RNiftyReg package is failing to compile on CRAN's
>     >> Solaris testbed, but I don't have access to a Solaris system to debug on,
>     >> and Googling the error hasn't been very helpful. The error is
>     >>
>     >> CC -library=stlport4 -I/home/ripley/R/cc/include -DNDEBUG -DNDEBUG
>     >> -DRNIFTYREG -I/usr/local/include    -KPIC  -O -xlibmil -xtarget=native
>     >> -nofstore  -c niftyreg.cpp -o niftyreg.o
>     >> "_reg_f3d_sym.cpp", line 25: Error: reg_f3d may not have a type qualifier.
>     >> "niftyreg.cpp", line 527:     Where: While instantiating
>     >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
>     >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
>     >> "_reg_f3d_sym.cpp", line 26: Error: reg_f3d<T> cannot be initialized
>     >> in a constructor.
>     >> "niftyreg.cpp", line 527:     Where: While instantiating
>     >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
>     >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
>     >> "_reg_f3d_sym.cpp", line 26: Error: Could not find
>     >> reg_f3d<double>::reg_f3d() to initialize base class.
>     >> "niftyreg.cpp", line 527:     Where: While instantiating
>     >> "reg_f3d_sym<double>::reg_f3d_sym(int, int)".
>     >> "niftyreg.cpp", line 527:     Where: Instantiated from non-template code.
>     >> 3 Error(s) detected.
>     >> *** Error code 2
>     >> make: Fatal error: Command failed for target `niftyreg.o'
>     >>
>     >>
>     >> (Full log at [1].) The relevant part of the source is a C++ class
>     >> constructor, part of the library that my package interfaces to:
>     >>
>     >> template <class T>
>     >> reg_f3d_sym<T>::reg_f3d_sym(int refTimePoint,int floTimePoint)
>     >> :reg_f3d<T>::reg_f3d(refTimePoint,floTimePoint)
>     >> {
>     this-> executableName=(char *)"NiftyReg F3D SYM";
>     >>
>     this-> backwardControlPointGrid=NULL;
>     this-> backwardWarped=NULL;
>     this-> backwardWarpedGradientImage=NULL;
>     this-> backwardDeformationFieldImage=NULL;
>     this-> backwardVoxelBasedMeasureGradientImage=NULL;
>     this-> backwardNodeBasedGradientImage=NULL;
>     >>
>     this-> backwardBestControlPointPosition=NULL;
>     this-> backwardConjugateG=NULL;
>     this-> backwardConjugateH=NULL;
>     >>
>     this-> backwardProbaJointHistogram=NULL;
>     this-> backwardLogJointHistogram=NULL;
>     >>
>     this-> floatingMaskImage=NULL;
>     this-> currentFloatingMask=NULL;
>     this-> floatingMaskPyramid=NULL;
>     this-> backwardActiveVoxelNumber=NULL;
>     >>
>     this-> inverseConsistencyWeight=0.1;
>     >>
>     >> #ifndef NDEBUG
>     >> printf("[NiftyReg DEBUG] reg_f3d_sym constructor called\n");
>     >> #endif
>     >> }
>     >>
>     >> The error does not occur on any Windows, Linux or OS X system which I have
>     >> access to, so this would seem to be an issue relating to the Solaris
>     >> compiler toolchain in particular. Can anyone shed any light on it, please?
>     >>
>     >> Thanks in advance,
>     >> Jon
>     >>
>     >> --
>     >> [1]
>     >>
>     >> http://www.r-project.org/nosvn/R.check/r-patched-solaris-x86/RNiftyReg-00install.html
>     >>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu Dec  6 18:15:10 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 06 Dec 2012 17:15:10 +0000
Subject: [Rd] svd(X, LINPACK=TRUE) alters its input
In-Reply-To: <E66794E69CFDE04D9A70842786030B931B8C8C24@PA-MBX04.na.tibco.com>
References: <E66794E69CFDE04D9A70842786030B931B8C8C24@PA-MBX04.na.tibco.com>
Message-ID: <50C0D29E.1080008@stats.ox.ac.uk>

On 06/12/2012 15:32, William Dunlap wrote:
> Ordinary functions should not alter their inputs but in R-2.15.2
> svd(LINPACK=TRUE,X) does.  (It worked in 2.15.0 but not in 2.15.1
> or 2.15.2 and became deprecated in 2.15.2.)

But not in R-devel.  I'll backport the difference.

>
>> X <- matrix(c(1,2,3, 5,7,11, 13,17,19), 3, 3)
>> X
>       [,1] [,2] [,3]
> [1,]    1    5   13
> [2,]    2    7   17
> [3,]    3   11   19
>> svd(X, LINPACK=TRUE)$d
> [1] 31.9718214  2.3882717  0.3143114
> Warning message:
> In svd(X, LINPACK = TRUE) : LINPACK = TRUE is deprecated
>> X
>            [,1]        [,2]        [,3]
> [1,] 1.2672612 -13.8975846 -27.7951692
> [2,] 0.5345225   1.0945920   2.1072825
> [3,] 0.8017837   0.9955161  -0.9794695
>> version
>                 _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          2
> minor          15.2
> year           2012
> month          10
> day            26
> svn rev        61015
> language       R
> version.string R version 2.15.2 (2012-10-26)
> nickname       Trick or Treat
>> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mauricio.zambrano at jrc.ec.europa.eu  Thu Dec  6 18:22:47 2012
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Thu, 06 Dec 2012 18:22:47 +0100
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <509A3175.7010100@stats>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<509A3175.7010100@stats>
Message-ID: <50C0D467.4060908@jrc.ec.europa.eu>

On 07/11/12 11:01, Prof Brian Ripley wrote:
> On 07/11/12 09:53, Duncan Murdoch wrote:
>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>> Hi all,
>>>
>>> Is it possible to add comments in the DESCRIPTION file?
>>
>>
>> The read.dcf function is used to read the DESCRIPTION file, and it
>> doesn't support comments. (The current Debian control format
>> description does appear to support comments with leading # markers, but
>> R's read.dcf function doesn't support these.)
>>
>> You could probably get away with something like
>>
>> #: this is a comment
>>
>> since unrecognized fields are ignored, but I think this fact is
>> undocumented so I would say it's safer to assume that comments are not
>> supported.
>
> In that form, but lots of people have fields like
>
> Note: this is a comment
>
> and CRAN uses
>
> X-CRAN-Comment:
>
Dear Prof. Ripley,

Last week I used the 'X-CRAN-Comment' field in the DESCRIPTION file of a 
package that now is on CRAN. However, the comment I added is not shown 
on the web page of the package on CRAN 
(http://cran.r-project.org/web/packages/hydroPSO).

Does it mean that the 'X-CRAN-Comment' field is not actually used by 
CRAN or it is used but not shown on the CRAN web page of the package ?

Thanks in advance,

Mauricio Zambrano-Bigiarini

-- 
=================================================
Water Resources Unit
Institute for Environment and Sustainability (IES)
Joint Research Centre (JRC), European Commission
TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
webinfo    : http://floods.jrc.ec.europa.eu/
=================================================
DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:14}}


From elw at stderr.org  Thu Dec  6 18:40:37 2012
From: elw at stderr.org (elijah wright)
Date: Thu, 6 Dec 2012 11:40:37 -0600
Subject: [Rd] Compilation failure on Solaris: any advice?
In-Reply-To: <20672.47896.772981.226424@max.nulle.part>
References: <CAM9CR=0DPTdi2eh1ZSnpzQi3vPpbJKzrQg+WADby7+S40pNd4w@mail.gmail.com>
	<CANQ3A2OymxgrJvr3M0pOAgsxp4+LPE5j58u+fitsCG_M3wxR9Q@mail.gmail.com>
	<20672.46577.43959.564387@stat.math.ethz.ch>
	<20672.47896.772981.226424@max.nulle.part>
Message-ID: <CANQ3A2PPQq=drZus6yy89mX6wRswqTcVc=aXAP6QmvjHDcJt=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121206/1422873c/attachment.pl>

From ligges at statistik.tu-dortmund.de  Thu Dec  6 19:14:06 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 06 Dec 2012 19:14:06 +0100
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <50C0D467.4060908@jrc.ec.europa.eu>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<509A3175.7010100@stats> <50C0D467.4060908@jrc.ec.europa.eu>
Message-ID: <50C0E06E.70105@statistik.tu-dortmund.de>



On 06.12.2012 18:22, Mauricio Zambrano-Bigiarini wrote:
> On 07/11/12 11:01, Prof Brian Ripley wrote:
>> On 07/11/12 09:53, Duncan Murdoch wrote:
>>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>>> Hi all,
>>>>
>>>> Is it possible to add comments in the DESCRIPTION file?
>>>
>>>
>>> The read.dcf function is used to read the DESCRIPTION file, and it
>>> doesn't support comments. (The current Debian control format
>>> description does appear to support comments with leading # markers, but
>>> R's read.dcf function doesn't support these.)
>>>
>>> You could probably get away with something like
>>>
>>> #: this is a comment
>>>
>>> since unrecognized fields are ignored, but I think this fact is
>>> undocumented so I would say it's safer to assume that comments are not
>>> supported.
>>
>> In that form, but lots of people have fields like
>>
>> Note: this is a comment
>>
>> and CRAN uses
>>
>> X-CRAN-Comment:
>>
> Dear Prof. Ripley,
>
> Last week I used the 'X-CRAN-Comment' field in the DESCRIPTION file of a
> package that now is on CRAN. However, the comment I added is not shown
> on the web page of the package on CRAN
> (http://cran.r-project.org/web/packages/hydroPSO).


Err, please do not use it yourself.
This is intended for CRAN internal purposes only, hence we call it 
X-CRAN-.... so we are assuming nobody else uses it.

Thanks,
Uwe Ligges

> Does it mean that the 'X-CRAN-Comment' field is not actually used by
> CRAN or it is used but not shown on the CRAN web page of the package ?
>
> Thanks in advance,
>
> Mauricio Zambrano-Bigiarini
>


From hpages at fhcrc.org  Fri Dec  7 00:41:41 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 06 Dec 2012 15:41:41 -0800
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <509A2FAA.1030404@gmail.com>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
Message-ID: <50C12D35.9000706@fhcrc.org>

Hi,

Wouldn't be hard to patch read.dcf() though.

FWIW here's the "comment aware" version of read.dcf() I've been using
for years:

   .removeCommentLines <- function(infile=stdin(), outfile=stdout())
   {
     if (is.character(infile)) {
         infile <- file(infile, "r")
         on.exit(close(infile))
     }
     if (is.character(outfile)) {
         outfile <- file(outfile, "w")
         on.exit({close(infile); close(outfile)})
     }
     while (TRUE) {
         lines <- readLines(infile, n=25000L)
         if (length(lines) == 0L)
             return()
         keep_it <- substr(lines, 1L, 1L) != "#"
         writeLines(lines[keep_it], outfile)
     }
   }

   read.dcf2 <- function(file, ...)
   {
     clean_file <- file.path(tempdir(), "clean.dcf")
     .removeCommentLines(file, clean_file)
     on.exit(file.remove(clean_file))
     read.dcf(clean_file, ...)
   }

Cheers,
H.

On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>> Hi all,
>>
>> Is it possible to add comments in the DESCRIPTION file?
>
>
> The read.dcf function is used to read the DESCRIPTION file, and it
> doesn't support comments.  (The current Debian control format
> description does appear to support comments with leading # markers, but
> R's read.dcf function doesn't support these.)
>
> You could probably get away with something like
>
> #: this is a comment
>
> since unrecognized fields are ignored, but I think this fact is
> undocumented so I would say it's safer to assume that comments are not
> supported.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Fri Dec  7 00:47:03 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 06 Dec 2012 15:47:03 -0800
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <50C12D35.9000706@fhcrc.org>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<50C12D35.9000706@fhcrc.org>
Message-ID: <50C12E77.3020705@fhcrc.org>



On 12/06/2012 03:41 PM, Herv? Pag?s wrote:
> Hi,
>
> Wouldn't be hard to patch read.dcf() though.
>
> FWIW here's the "comment aware" version of read.dcf() I've been using
> for years:
>
>    .removeCommentLines <- function(infile=stdin(), outfile=stdout())
>    {
>      if (is.character(infile)) {
>          infile <- file(infile, "r")
>          on.exit(close(infile))
>      }
>      if (is.character(outfile)) {
>          outfile <- file(outfile, "w")
>          on.exit({close(infile); close(outfile)})
>      }
>      while (TRUE) {
>          lines <- readLines(infile, n=25000L)
>          if (length(lines) == 0L)
>              return()
>          keep_it <- substr(lines, 1L, 1L) != "#"
>          writeLines(lines[keep_it], outfile)
>      }
>    }
>
>    read.dcf2 <- function(file, ...)
>    {
>      clean_file <- file.path(tempdir(), "clean.dcf")

mmh, would certainly be better to just use tempfile() here.

H.

>      .removeCommentLines(file, clean_file)
>      on.exit(file.remove(clean_file))
>      read.dcf(clean_file, ...)
>    }
>
> Cheers,
> H.
>
> On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>> Hi all,
>>>
>>> Is it possible to add comments in the DESCRIPTION file?
>>
>>
>> The read.dcf function is used to read the DESCRIPTION file, and it
>> doesn't support comments.  (The current Debian control format
>> description does appear to support comments with leading # markers, but
>> R's read.dcf function doesn't support these.)
>>
>> You could probably get away with something like
>>
>> #: this is a comment
>>
>> since unrecognized fields are ignored, but I think this fact is
>> undocumented so I would say it's safer to assume that comments are not
>> supported.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From wdunlap at tibco.com  Fri Dec  7 01:53:03 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Dec 2012 00:53:03 +0000
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <50C12E77.3020705@fhcrc.org>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<50C12D35.9000706@fhcrc.org> <50C12E77.3020705@fhcrc.org>
Message-ID: <E66794E69CFDE04D9A70842786030B931B8CB010@PA-MBX04.na.tibco.com>

Why not just use some tag that R doesn't already use, say "Comment:", instead
of a #?  If you allow # in position one of a line to mean a comment then people
may expect # to be used as a comment anywhere on a line.

(It may also mess up some dcf parsing code that I've written - it checks that lines
after tagged lines are either empty, the start of a new description, or start with a space,
a continuation of the previous line.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Herv? Pag?s
> Sent: Thursday, December 06, 2012 3:47 PM
> To: Duncan Murdoch
> Cc: christophe.genolini at u-paris10.fr; r-devel at r-project.org; Christophe Genolini
> Subject: Re: [Rd] Comments in the DESCRIPTION file
> 
> 
> 
> On 12/06/2012 03:41 PM, Herv? Pag?s wrote:
> > Hi,
> >
> > Wouldn't be hard to patch read.dcf() though.
> >
> > FWIW here's the "comment aware" version of read.dcf() I've been using
> > for years:
> >
> >    .removeCommentLines <- function(infile=stdin(), outfile=stdout())
> >    {
> >      if (is.character(infile)) {
> >          infile <- file(infile, "r")
> >          on.exit(close(infile))
> >      }
> >      if (is.character(outfile)) {
> >          outfile <- file(outfile, "w")
> >          on.exit({close(infile); close(outfile)})
> >      }
> >      while (TRUE) {
> >          lines <- readLines(infile, n=25000L)
> >          if (length(lines) == 0L)
> >              return()
> >          keep_it <- substr(lines, 1L, 1L) != "#"
> >          writeLines(lines[keep_it], outfile)
> >      }
> >    }
> >
> >    read.dcf2 <- function(file, ...)
> >    {
> >      clean_file <- file.path(tempdir(), "clean.dcf")
> 
> mmh, would certainly be better to just use tempfile() here.
> 
> H.
> 
> >      .removeCommentLines(file, clean_file)
> >      on.exit(file.remove(clean_file))
> >      read.dcf(clean_file, ...)
> >    }
> >
> > Cheers,
> > H.
> >
> > On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
> >> On 12-11-07 4:26 AM, Christophe Genolini wrote:
> >>> Hi all,
> >>>
> >>> Is it possible to add comments in the DESCRIPTION file?
> >>
> >>
> >> The read.dcf function is used to read the DESCRIPTION file, and it
> >> doesn't support comments.  (The current Debian control format
> >> description does appear to support comments with leading # markers, but
> >> R's read.dcf function doesn't support these.)
> >>
> >> You could probably get away with something like
> >>
> >> #: this is a comment
> >>
> >> since unrecognized fields are ignored, but I think this fact is
> >> undocumented so I would say it's safer to assume that comments are not
> >> supported.
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> --
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Fri Dec  7 02:36:31 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 06 Dec 2012 17:36:31 -0800
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <E66794E69CFDE04D9A70842786030B931B8CB010@PA-MBX04.na.tibco.com>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<50C12D35.9000706@fhcrc.org> <50C12E77.3020705@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B931B8CB010@PA-MBX04.na.tibco.com>
Message-ID: <50C1481F.9020206@fhcrc.org>

On 12/06/2012 04:53 PM, William Dunlap wrote:
> Why not just use some tag that R doesn't already use, say "Comment:", instead
> of a #?  If you allow # in position one of a line to mean a comment then people
> may expect # to be used as a comment anywhere on a line.

I would stick to whatever the DCF spec say, if there is such thing.
If the spec says # on position 1 means a comment then I think read.dcf()
should do that. Then the function can be used to read any DCF file,
not just DESCRIPTION files.

Cheers,
H.

>
> (It may also mess up some dcf parsing code that I've written - it checks that lines
> after tagged lines are either empty, the start of a new description, or start with a space,
> a continuation of the previous line.)
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Herv? Pag?s
>> Sent: Thursday, December 06, 2012 3:47 PM
>> To: Duncan Murdoch
>> Cc: christophe.genolini at u-paris10.fr; r-devel at r-project.org; Christophe Genolini
>> Subject: Re: [Rd] Comments in the DESCRIPTION file
>>
>>
>>
>> On 12/06/2012 03:41 PM, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> Wouldn't be hard to patch read.dcf() though.
>>>
>>> FWIW here's the "comment aware" version of read.dcf() I've been using
>>> for years:
>>>
>>>     .removeCommentLines <- function(infile=stdin(), outfile=stdout())
>>>     {
>>>       if (is.character(infile)) {
>>>           infile <- file(infile, "r")
>>>           on.exit(close(infile))
>>>       }
>>>       if (is.character(outfile)) {
>>>           outfile <- file(outfile, "w")
>>>           on.exit({close(infile); close(outfile)})
>>>       }
>>>       while (TRUE) {
>>>           lines <- readLines(infile, n=25000L)
>>>           if (length(lines) == 0L)
>>>               return()
>>>           keep_it <- substr(lines, 1L, 1L) != "#"
>>>           writeLines(lines[keep_it], outfile)
>>>       }
>>>     }
>>>
>>>     read.dcf2 <- function(file, ...)
>>>     {
>>>       clean_file <- file.path(tempdir(), "clean.dcf")
>>
>> mmh, would certainly be better to just use tempfile() here.
>>
>> H.
>>
>>>       .removeCommentLines(file, clean_file)
>>>       on.exit(file.remove(clean_file))
>>>       read.dcf(clean_file, ...)
>>>     }
>>>
>>> Cheers,
>>> H.
>>>
>>> On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
>>>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>>>> Hi all,
>>>>>
>>>>> Is it possible to add comments in the DESCRIPTION file?
>>>>
>>>>
>>>> The read.dcf function is used to read the DESCRIPTION file, and it
>>>> doesn't support comments.  (The current Debian control format
>>>> description does appear to support comments with leading # markers, but
>>>> R's read.dcf function doesn't support these.)
>>>>
>>>> You could probably get away with something like
>>>>
>>>> #: this is a comment
>>>>
>>>> since unrecognized fields are ignored, but I think this fact is
>>>> undocumented so I would say it's safer to assume that comments are not
>>>> supported.
>>>>
>>>> Duncan Murdoch
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Fri Dec  7 02:59:35 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 6 Dec 2012 20:59:35 -0500
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <50C1481F.9020206@fhcrc.org>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<50C12D35.9000706@fhcrc.org> <50C12E77.3020705@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B931B8CB010@PA-MBX04.na.tibco.com>
	<50C1481F.9020206@fhcrc.org>
Message-ID: <1D903134-9B2F-40AB-959E-48615C2BD4CE@r-project.org>

On Dec 6, 2012, at 8:36 PM, Herv? Pag?s wrote:

> On 12/06/2012 04:53 PM, William Dunlap wrote:
>> Why not just use some tag that R doesn't already use, say "Comment:", instead
>> of a #?  If you allow # in position one of a line to mean a comment then people
>> may expect # to be used as a comment anywhere on a line.
> 
> I would stick to whatever the DCF spec say, if there is such thing.
> If the spec says # on position 1 means a comment then I think read.dcf()
> should do that. Then the function can be used to read any DCF file,
> not just DESCRIPTION files.
> 

DCF itself doesn't define the meaning of # -- it only defines that no field name is allowed to start with #. In fact the same document says that lines starting with # are not permitted in general DCF files -- they are only permitted in Debian's source package control files. That leaves the status of # as comments somewhat confusing. My interpretation would be that generic DCF doesn't allow # but specific formats derived from DCF may choose to interpret it that way. In either case the current behavior of read.dcf() definitely satisfies the DCF definition. As both Brian and Bill pointed out, the proper way to do that is to define a data field with data/value as the comment.

Cheers,
Simon



> Cheers,
> H.
> 
>> 
>> (It may also mess up some dcf parsing code that I've written - it checks that lines
>> after tagged lines are either empty, the start of a new description, or start with a space,
>> a continuation of the previous line.)
>> 
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>>> Of Herv? Pag?s
>>> Sent: Thursday, December 06, 2012 3:47 PM
>>> To: Duncan Murdoch
>>> Cc: christophe.genolini at u-paris10.fr; r-devel at r-project.org; Christophe Genolini
>>> Subject: Re: [Rd] Comments in the DESCRIPTION file
>>> 
>>> 
>>> 
>>> On 12/06/2012 03:41 PM, Herv? Pag?s wrote:
>>>> Hi,
>>>> 
>>>> Wouldn't be hard to patch read.dcf() though.
>>>> 
>>>> FWIW here's the "comment aware" version of read.dcf() I've been using
>>>> for years:
>>>> 
>>>>    .removeCommentLines <- function(infile=stdin(), outfile=stdout())
>>>>    {
>>>>      if (is.character(infile)) {
>>>>          infile <- file(infile, "r")
>>>>          on.exit(close(infile))
>>>>      }
>>>>      if (is.character(outfile)) {
>>>>          outfile <- file(outfile, "w")
>>>>          on.exit({close(infile); close(outfile)})
>>>>      }
>>>>      while (TRUE) {
>>>>          lines <- readLines(infile, n=25000L)
>>>>          if (length(lines) == 0L)
>>>>              return()
>>>>          keep_it <- substr(lines, 1L, 1L) != "#"
>>>>          writeLines(lines[keep_it], outfile)
>>>>      }
>>>>    }
>>>> 
>>>>    read.dcf2 <- function(file, ...)
>>>>    {
>>>>      clean_file <- file.path(tempdir(), "clean.dcf")
>>> 
>>> mmh, would certainly be better to just use tempfile() here.
>>> 
>>> H.
>>> 
>>>>      .removeCommentLines(file, clean_file)
>>>>      on.exit(file.remove(clean_file))
>>>>      read.dcf(clean_file, ...)
>>>>    }
>>>> 
>>>> Cheers,
>>>> H.
>>>> 
>>>> On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
>>>>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>>>>> Hi all,
>>>>>> 
>>>>>> Is it possible to add comments in the DESCRIPTION file?
>>>>> 
>>>>> 
>>>>> The read.dcf function is used to read the DESCRIPTION file, and it
>>>>> doesn't support comments.  (The current Debian control format
>>>>> description does appear to support comments with leading # markers, but
>>>>> R's read.dcf function doesn't support these.)
>>>>> 
>>>>> You could probably get away with something like
>>>>> 
>>>>> #: this is a comment
>>>>> 
>>>>> since unrecognized fields are ignored, but I think this fact is
>>>>> undocumented so I would say it's safer to assume that comments are not
>>>>> supported.
>>>>> 
>>>>> Duncan Murdoch
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> --
>>> Herv? Pag?s
>>> 
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>> 
>>> E-mail: hpages at fhcrc.org
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From mauricio.zambrano at jrc.ec.europa.eu  Fri Dec  7 08:33:58 2012
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Fri, 07 Dec 2012 08:33:58 +0100
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <50C0E06E.70105@statistik.tu-dortmund.de>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<509A3175.7010100@stats> <50C0D467.4060908@jrc.ec.europa.eu>
	<50C0E06E.70105@statistik.tu-dortmund.de>
Message-ID: <50C19BE6.2030901@jrc.ec.europa.eu>

On 06/12/12 19:14, Uwe Ligges wrote:
>
>
> On 06.12.2012 18:22, Mauricio Zambrano-Bigiarini wrote:
>> On 07/11/12 11:01, Prof Brian Ripley wrote:
>>> On 07/11/12 09:53, Duncan Murdoch wrote:
>>>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>>>> Hi all,
>>>>>
>>>>> Is it possible to add comments in the DESCRIPTION file?
>>>>
>>>>
>>>> The read.dcf function is used to read the DESCRIPTION file, and it
>>>> doesn't support comments. (The current Debian control format
>>>> description does appear to support comments with leading # markers, but
>>>> R's read.dcf function doesn't support these.)
>>>>
>>>> You could probably get away with something like
>>>>
>>>> #: this is a comment
>>>>
>>>> since unrecognized fields are ignored, but I think this fact is
>>>> undocumented so I would say it's safer to assume that comments are not
>>>> supported.
>>>
>>> In that form, but lots of people have fields like
>>>
>>> Note: this is a comment
>>>
>>> and CRAN uses
>>>
>>> X-CRAN-Comment:
>>>
>> Dear Prof. Ripley,
>>
>> Last week I used the 'X-CRAN-Comment' field in the DESCRIPTION file of a
>> package that now is on CRAN. However, the comment I added is not shown
>> on the web page of the package on CRAN
>> (http://cran.r-project.org/web/packages/hydroPSO).
>
>
> Err, please do not use it yourself.
> This is intended for CRAN internal purposes only, hence we call it
> X-CRAN-.... so we are assuming nobody else uses it.

Thanks Uwe for making this point clear.

All the best,

Mauricio

>
> Thanks,
> Uwe Ligges
>
>> Does it mean that the 'X-CRAN-Comment' field is not actually used by
>> CRAN or it is used but not shown on the CRAN web page of the package ?
>>
>> Thanks in advance,
>>
>> Mauricio Zambrano-Bigiarini
>>
>


From jalvesaq at gmail.com  Fri Dec  7 00:19:04 2012
From: jalvesaq at gmail.com (Jakson Alves de Aquino)
Date: Thu, 6 Dec 2012 20:19:04 -0300
Subject: [Rd] base package: extra new line at source() function
Message-ID: <CAGBu4CMkYGAKDhNXgWsKeJE4zJU0RiKYsBCVGKYFXdkM4ivvvA@mail.gmail.com>

Hi,

When we do source("file.R", echo = TRUE) the output on R Console
includes an extra new line between each line of code. The extra "\n"
is added on line 201 of src/library/base/R/source.R (please, see
attached patch). I tested the function without this "\n" on an
terminal emulator in Linux and on R Console in Windows RGui. I don't
know if the "\n" is useful in other circumstances.

Thanks!

-- 
Jakson Alves de Aquino
Federal University of Cear?
Social Sciences Department
www.lepem.ufc.br/aquino.php

From lgautier at gmail.com  Fri Dec  7 09:25:11 2012
From: lgautier at gmail.com (Laurent Gautier)
Date: Fri, 07 Dec 2012 09:25:11 +0100
Subject: [Rd] documentation for legend(): possible missing info for pch.
Message-ID: <50C1A7E7.1010709@gmail.com>

In the documentation for graphics::legend(), the entry for "pch" is:

 >      pch: the plotting symbols appearing in the legend, either as
           vector of 1-character strings, or one (multi character)
           string.  _Must_ be specified for symbol drawing.


If I did not misread them, examples in the same documentation page 
suggest that it is also possible to pass integers.


Best,


Laurent


From janko.thyson.rstuff at googlemail.com  Fri Dec  7 15:05:22 2012
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Fri, 07 Dec 2012 15:05:22 +0100
Subject: [Rd] Workarounds/solutions to Rd file name conflict when extending
 a S4 method of some other package
Message-ID: <50C1F7A2.3020104@googlemail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121207/37733bed/attachment.pl>

From vineethmohan at algotree.com  Fri Dec  7 13:40:27 2012
From: vineethmohan at algotree.com (Vineeth Mohan)
Date: Fri, 7 Dec 2012 18:10:27 +0530
Subject: [Rd] memory management in C code
Message-ID: <CADdZhHbSN3u49xDYGK7a5oawX0LaM7=h6BL9AC0Mw35f25xhRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121207/c3328d69/attachment.pl>

From ruipbarradas at sapo.pt  Fri Dec  7 19:45:57 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 07 Dec 2012 18:45:57 +0000
Subject: [Rd] memory management in C code
In-Reply-To: <CADdZhHbSN3u49xDYGK7a5oawX0LaM7=h6BL9AC0Mw35f25xhRQ@mail.gmail.com>
References: <CADdZhHbSN3u49xDYGK7a5oawX0LaM7=h6BL9AC0Mw35f25xhRQ@mail.gmail.com>
Message-ID: <50C23965.5080205@sapo.pt>

Hello,

This is explained in Writing R Extensions, Section 6.1 file R-exts.pdf 
in your distribution of R, folder doc.
There are two types of functions to allocate memory in C functions 
called from R code.

1. R_alloc() - the memory is automatically reclaimed at the end of the 
function call.
2. Calloc/Realloc - you must call Free() [ uppercase, not free() ] at 
the end of the function call.

Hope this helps,

Rui Barradas
Em 07-12-2012 12:40, Vineeth Mohan escreveu:
> Hi ,
>
> I am a newbie to R and i am trying to create a R package which is pretty
> main memory intensive.
> I would like to know what happens to the variables allocated in the C code
> while writing R extensions based on C.
> Are they preserved until someone de-allocate them or are they taken out by
> R's garbage collection ?
>
> Thanks
>             Vineeth
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Dec  7 23:51:02 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 7 Dec 2012 14:51:02 -0800
Subject: [Rd] Make scripts during package installation?
Message-ID: <CAFDcVCRM0bDHfqtUV4gLpyRuDrRzujRtRajUaDYN0fdeH-Vvkg@mail.gmail.com>

During installation of a package, Makevars/Makefile in src/ is
processed.  I've always considered the purpose of this for compiling
native code.  Is that it's solely purpose, or is it alright to use it
also for non-code compilation purposes, e.g. building inst/
subdirectories on the fly?  If not, are there other means to create
non-static inst/ subdirectories during installation?

The immediate need I have right now is that untar an archive to
inst/testScripts/.  The reason why I need this is that a package can
only contain pathnames of length <= 100 characters (restriction in the
tar file format), and mine are longer than that, e.g.
aroma.affymetrix/inst/testScripts/system/chipTypes/Mapping50K_Hind240,Xba240/test20080730,100K,BPN,alleleSpecific.R
[115 chars].  See also
http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora/aroma.affymetrix-00check.html
. One strategy is to create a local tar file referring to files
system/chipTypes/Mapping50K_Hind240,Xba240/test20080730,100K,BPN,alleleSpecific.R
and then untar it to aroma.affymetrix/inst/testScripts/ during
installation.  I want to this under the assumption that after the
package installation is completed, the package directory is read-only
so nothing can be updated after that step.  Note that this cannot be
done during package built, only installation.

/Henrik


From hpages at fhcrc.org  Sat Dec  8 02:10:09 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 07 Dec 2012 17:10:09 -0800
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <1D903134-9B2F-40AB-959E-48615C2BD4CE@r-project.org>
References: <509A2942.3050004@u-paris10.fr> <509A2FAA.1030404@gmail.com>
	<50C12D35.9000706@fhcrc.org> <50C12E77.3020705@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B931B8CB010@PA-MBX04.na.tibco.com>
	<50C1481F.9020206@fhcrc.org>
	<1D903134-9B2F-40AB-959E-48615C2BD4CE@r-project.org>
Message-ID: <50C29371.30603@fhcrc.org>

Hi Simon,

On 12/06/2012 05:59 PM, Simon Urbanek wrote:
> On Dec 6, 2012, at 8:36 PM, Herv? Pag?s wrote:
>
>> On 12/06/2012 04:53 PM, William Dunlap wrote:
>>> Why not just use some tag that R doesn't already use, say "Comment:", instead
>>> of a #?  If you allow # in position one of a line to mean a comment then people
>>> may expect # to be used as a comment anywhere on a line.
>>
>> I would stick to whatever the DCF spec say, if there is such thing.
>> If the spec says # on position 1 means a comment then I think read.dcf()
>> should do that. Then the function can be used to read any DCF file,
>> not just DESCRIPTION files.
>>
>
> DCF itself doesn't define the meaning of # -- it only defines that no field name is allowed to start with #. In fact the same document says that lines starting with # are not permitted in general DCF files -- they are only permitted in Debian's source package control files. That leaves the status of # as comments somewhat confusing. My interpretation would be that generic DCF doesn't allow # but specific formats derived from DCF may choose to interpret it that way. In either case the current behavior of read.dcf() definitely satisfies the DCF definition.

Not if the definition says that no field name is allowed to start
with #:

   > read.dcf("toto.dcf")
        #Package Version
   [1,] "toto"   "0.0.0"

> As both Brian and Bill pointed out, the proper way to do that is to define a data field with data/value as the comment.

which maybe works OK for inserting comments in DESCRIPTION files,
but not so well for inserting inter-record comments in DCF files with
multiple records.

In Bioconductor we maintain a big DCF file that we use to automatically
re-generate a collection of annotation packages at each release. The
file looks like:

# Annotation packages for Human

Package: hcg110.db
Version: 2.8.0
PkgTemplate: NCBICHIP.DB

Package: hgfocus.db
Version: 2.8.0
PkgTemplate: NCBICHIP.DB

# Annotation packages for Mouse

Package: mgu74a.db
Version: 2.8.0
PkgTemplate: NCBICHIP.DB

Package: mgu74av2.db
Version: 2.8.0
PkgTemplate: NCBICHIP.DB

The problem if you put those comments in key/value pairs is that
it contaminates the output of read.dcf() with fake records:

 > read.dcf("toto.dcf")
      Note                            Package       Version PkgTemplate
[1,] "Annotation packages for Human" NA            NA      NA
[2,] NA                              "hcg110.db"   "2.8.0" "NCBICHIP.DB"
[3,] NA                              "hgfocus.db"  "2.8.0" "NCBICHIP.DB"
[4,] "Annotation packages for Mouse" NA            NA      NA
[5,] NA                              "mgu74a.db"   "2.8.0" "NCBICHIP.DB"
[6,] NA                              "mgu74av2.db" "2.8.0" "NCBICHIP.DB"

The file really has 4 records of data and it'd be good to be able to add
inter-record comments without altering the number of records.

This is the reason why we use a "comment aware" version of read.dcf().

I can see why maybe you wouldn't like having people start using # to
insert comment lines in their DESCRIPTION file and I agree that it
should probably be discouraged. So maybe support for # comments could
be made optional in read.dcf() thru an extra arg, and would be disabled
by default?

Thanks,
H.

>
> Cheers,
> Simon
>
>
>
>> Cheers,
>> H.
>>
>>>
>>> (It may also mess up some dcf parsing code that I've written - it checks that lines
>>> after tagged lines are either empty, the start of a new description, or start with a space,
>>> a continuation of the previous line.)
>>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>>>> Of Herv? Pag?s
>>>> Sent: Thursday, December 06, 2012 3:47 PM
>>>> To: Duncan Murdoch
>>>> Cc: christophe.genolini at u-paris10.fr; r-devel at r-project.org; Christophe Genolini
>>>> Subject: Re: [Rd] Comments in the DESCRIPTION file
>>>>
>>>>
>>>>
>>>> On 12/06/2012 03:41 PM, Herv? Pag?s wrote:
>>>>> Hi,
>>>>>
>>>>> Wouldn't be hard to patch read.dcf() though.
>>>>>
>>>>> FWIW here's the "comment aware" version of read.dcf() I've been using
>>>>> for years:
>>>>>
>>>>>     .removeCommentLines <- function(infile=stdin(), outfile=stdout())
>>>>>     {
>>>>>       if (is.character(infile)) {
>>>>>           infile <- file(infile, "r")
>>>>>           on.exit(close(infile))
>>>>>       }
>>>>>       if (is.character(outfile)) {
>>>>>           outfile <- file(outfile, "w")
>>>>>           on.exit({close(infile); close(outfile)})
>>>>>       }
>>>>>       while (TRUE) {
>>>>>           lines <- readLines(infile, n=25000L)
>>>>>           if (length(lines) == 0L)
>>>>>               return()
>>>>>           keep_it <- substr(lines, 1L, 1L) != "#"
>>>>>           writeLines(lines[keep_it], outfile)
>>>>>       }
>>>>>     }
>>>>>
>>>>>     read.dcf2 <- function(file, ...)
>>>>>     {
>>>>>       clean_file <- file.path(tempdir(), "clean.dcf")
>>>>
>>>> mmh, would certainly be better to just use tempfile() here.
>>>>
>>>> H.
>>>>
>>>>>       .removeCommentLines(file, clean_file)
>>>>>       on.exit(file.remove(clean_file))
>>>>>       read.dcf(clean_file, ...)
>>>>>     }
>>>>>
>>>>> Cheers,
>>>>> H.
>>>>>
>>>>> On 11/07/2012 01:53 AM, Duncan Murdoch wrote:
>>>>>> On 12-11-07 4:26 AM, Christophe Genolini wrote:
>>>>>>> Hi all,
>>>>>>>
>>>>>>> Is it possible to add comments in the DESCRIPTION file?
>>>>>>
>>>>>>
>>>>>> The read.dcf function is used to read the DESCRIPTION file, and it
>>>>>> doesn't support comments.  (The current Debian control format
>>>>>> description does appear to support comments with leading # markers, but
>>>>>> R's read.dcf function doesn't support these.)
>>>>>>
>>>>>> You could probably get away with something like
>>>>>>
>>>>>> #: this is a comment
>>>>>>
>>>>>> since unrecognized fields are ignored, but I think this fact is
>>>>>> undocumented so I would say it's safer to assume that comments are not
>>>>>> supported.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> --
>>>> Herv? Pag?s
>>>>
>>>> Program in Computational Biology
>>>> Division of Public Health Sciences
>>>> Fred Hutchinson Cancer Research Center
>>>> 1100 Fairview Ave. N, M1-B514
>>>> P.O. Box 19024
>>>> Seattle, WA 98109-1024
>>>>
>>>> E-mail: hpages at fhcrc.org
>>>> Phone:  (206) 667-5791
>>>> Fax:    (206) 667-1319
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ripley at stats.ox.ac.uk  Sat Dec  8 06:03:36 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 08 Dec 2012 05:03:36 +0000
Subject: [Rd] Make scripts during package installation?
In-Reply-To: <CAFDcVCRM0bDHfqtUV4gLpyRuDrRzujRtRajUaDYN0fdeH-Vvkg@mail.gmail.com>
References: <CAFDcVCRM0bDHfqtUV4gLpyRuDrRzujRtRajUaDYN0fdeH-Vvkg@mail.gmail.com>
Message-ID: <50C2CA28.80509@stats.ox.ac.uk>

Your subject makes no sense: there is no such thing as a 'make script'.

On 07/12/2012 22:51, Henrik Bengtsson wrote:
> During installation of a package, Makevars/Makefile in src/ is
> processed.  I've always considered the purpose of this for compiling
> native code.  Is that it's solely purpose, or is it alright to use it
> also for non-code compilation purposes, e.g. building inst/
> subdirectories on the fly?  If not, are there other means to create
> non-static inst/ subdirectories during installation?

This is what the configure[.win] script is for.  See package nloptr for 
one such use in Makevars, though (in connection with compiled code).

>
> The immediate need I have right now is that untar an archive to
> inst/testScripts/.  The reason why I need this is that a package can
> only contain pathnames of length <= 100 characters (restriction in the
> tar file format), and mine are longer than that, e.g.
> aroma.affymetrix/inst/testScripts/system/chipTypes/Mapping50K_Hind240,Xba240/test20080730,100K,BPN,alleleSpecific.R
> [115 chars].  See also
> http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora/aroma.affymetrix-00check.html
> . One strategy is to create a local tar file referring to files
> system/chipTypes/Mapping50K_Hind240,Xba240/test20080730,100K,BPN,alleleSpecific.R
> and then untar it to aroma.affymetrix/inst/testScripts/ during
> installation.  I want to this under the assumption that after the
> package installation is completed, the package directory is read-only
> so nothing can be updated after that step.  Note that this cannot be
> done during package built, only installation.
>
> /Henrik


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ruipbarradas at sapo.pt  Sat Dec  8 12:38:48 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 08 Dec 2012 11:38:48 +0000
Subject: [Rd] file.link on Windows 7
Message-ID: <50C326C8.7080304@sapo.pt>

Hello,

A post to R-Help by Oliver Soong reports what seems to be a bug specific 
to Windows (I'm on Windows 7).
The original post is as follows:

----------------------------------------------------------------
from: Oliver Soong <osoong+r at gmail.com>
to: r-help <r-help at r-project.org>
date: Fri, 7 Dec 2012 22:07:49 -0800
subject: [R] file.link fails on NTFS

Windows 7 64-bit, R 2.15.2 i386.  Working directory is on an NTFS drive.

> writeLines("", "file.txt")
> file.link("file.txt", "link.txt")

Warning in file.link("file.txt", "link.txt") :
   cannot link 'link.txt' to 'link.txt', reason 'The system cannot find
the file specified'

No link is created.  The 'link.txt' to 'link.txt' is suspicious.  Does
this happen to anybody else?  I didn't find anything in my searches.

Oliver

----------------------------------------------------------------
The above code runs with no problems on Ubuntu 12.04/ R 2.15.2, 
file.link returns TRUE.
I've checked the sources and .Internal calls "file.link", executing 
do_filelink(). The segment in file src/main/platform.c seems right, not 
mistaking argument 'from' for 'to':

#ifdef Win32
         wchar_t *from, *to;

         from = filenameToWchar(STRING_ELT(f1, i%n1), TRUE);
         to = filenameToWchar(STRING_ELT(f2, i%n2), TRUE);
         LOGICAL(ans)[i] = CreateHardLinkW(to, from, NULL) != 0;
         if(!LOGICAL(ans)[i]) {
         warning(_("cannot link '%ls' to '%ls', reason '%s'"),
             from, to, formatError(GetLastError()));
         }
#else


But there's something going on. The link is not created and the warning 
message is wrong.

Bug report? (Why CreateHardLinkW, and not CreateHardLink?)

Rui Barradas


From ruipbarradas at sapo.pt  Sat Dec  8 12:46:21 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 08 Dec 2012 11:46:21 +0000
Subject: [Rd] file.link on Windows 7
In-Reply-To: <50C326C8.7080304@sapo.pt>
References: <50C326C8.7080304@sapo.pt>
Message-ID: <50C3288D.10507@sapo.pt>

Sorry, forgot the session info.

 > sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Rui Barradas
Em 08-12-2012 11:38, Rui Barradas escreveu:
> Hello,
>
> A post to R-Help by Oliver Soong reports what seems to be a bug 
> specific to Windows (I'm on Windows 7).
> The original post is as follows:
>
> ----------------------------------------------------------------
> from: Oliver Soong <osoong+r at gmail.com>
> to: r-help <r-help at r-project.org>
> date: Fri, 7 Dec 2012 22:07:49 -0800
> subject: [R] file.link fails on NTFS
>
> Windows 7 64-bit, R 2.15.2 i386.  Working directory is on an NTFS drive.
>
>> writeLines("", "file.txt")
>> file.link("file.txt", "link.txt")
>
> Warning in file.link("file.txt", "link.txt") :
>   cannot link 'link.txt' to 'link.txt', reason 'The system cannot find
> the file specified'
>
> No link is created.  The 'link.txt' to 'link.txt' is suspicious. Does
> this happen to anybody else?  I didn't find anything in my searches.
>
> Oliver
>
> ----------------------------------------------------------------
> The above code runs with no problems on Ubuntu 12.04/ R 2.15.2, 
> file.link returns TRUE.
> I've checked the sources and .Internal calls "file.link", executing 
> do_filelink(). The segment in file src/main/platform.c seems right, 
> not mistaking argument 'from' for 'to':
>
> #ifdef Win32
>         wchar_t *from, *to;
>
>         from = filenameToWchar(STRING_ELT(f1, i%n1), TRUE);
>         to = filenameToWchar(STRING_ELT(f2, i%n2), TRUE);
>         LOGICAL(ans)[i] = CreateHardLinkW(to, from, NULL) != 0;
>         if(!LOGICAL(ans)[i]) {
>         warning(_("cannot link '%ls' to '%ls', reason '%s'"),
>             from, to, formatError(GetLastError()));
>         }
> #else
>
>
> But there's something going on. The link is not created and the 
> warning message is wrong.
>
> Bug report? (Why CreateHardLinkW, and not CreateHardLink?)
>
> Rui Barradas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat Dec  8 13:36:43 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Dec 2012 07:36:43 -0500
Subject: [Rd] file.link on Windows 7
In-Reply-To: <50C326C8.7080304@sapo.pt>
References: <50C326C8.7080304@sapo.pt>
Message-ID: <50C3345B.3090206@gmail.com>

On 12-12-08 6:38 AM, Rui Barradas wrote:
> Hello,
>
> A post to R-Help by Oliver Soong reports what seems to be a bug specific
> to Windows (I'm on Windows 7).
> The original post is as follows:

I see the bug, and will fix it.

Duncan Murdoch

>
> ----------------------------------------------------------------
> from: Oliver Soong <osoong+r at gmail.com>
> to: r-help <r-help at r-project.org>
> date: Fri, 7 Dec 2012 22:07:49 -0800
> subject: [R] file.link fails on NTFS
>
> Windows 7 64-bit, R 2.15.2 i386.  Working directory is on an NTFS drive.
>
>> writeLines("", "file.txt")
>> file.link("file.txt", "link.txt")
>
> Warning in file.link("file.txt", "link.txt") :
>     cannot link 'link.txt' to 'link.txt', reason 'The system cannot find
> the file specified'
>
> No link is created.  The 'link.txt' to 'link.txt' is suspicious.  Does
> this happen to anybody else?  I didn't find anything in my searches.
>
> Oliver
>
> ----------------------------------------------------------------
> The above code runs with no problems on Ubuntu 12.04/ R 2.15.2,
> file.link returns TRUE.
> I've checked the sources and .Internal calls "file.link", executing
> do_filelink(). The segment in file src/main/platform.c seems right, not
> mistaking argument 'from' for 'to':
>
> #ifdef Win32
>           wchar_t *from, *to;
>
>           from = filenameToWchar(STRING_ELT(f1, i%n1), TRUE);
>           to = filenameToWchar(STRING_ELT(f2, i%n2), TRUE);
>           LOGICAL(ans)[i] = CreateHardLinkW(to, from, NULL) != 0;
>           if(!LOGICAL(ans)[i]) {
>           warning(_("cannot link '%ls' to '%ls', reason '%s'"),
>               from, to, formatError(GetLastError()));
>           }
> #else
>
>
> But there's something going on. The link is not created and the warning
> message is wrong.
>
> Bug report? (Why CreateHardLinkW, and not CreateHardLink?)
>
> Rui Barradas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mpietro at outlook.com  Sat Dec  8 03:26:26 2012
From: mpietro at outlook.com (mpietro)
Date: Fri, 7 Dec 2012 18:26:26 -0800 (PST)
Subject: [Rd] C function, double problem
Message-ID: <1354933586648-4652537.post@n4.nabble.com>

Hi everybody,

here's my problem:

i call a C function which calculates a large number of double values and
puts them into an array which is passed from R as a parameter in the
function (like  .C("function", other parameters, result =  as.double( c ( 1
: quantity ) ). 
When the values come back to R in the result array, they are all truncated
to their integer value (i.e. I lose the decimal parts). 
I think that the problem is that this calculated double numbers are actually
too long, with many decimals, because i changed in code  the calculated
values with arbitrary double values with a few decimals and it works.

Has anybody any idea of where the problem is?

Thanks in advance!



--
View this message in context: http://r.789695.n4.nabble.com/C-function-double-problem-tp4652537.html
Sent from the R devel mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Sat Dec  8 16:47:27 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 08 Dec 2012 15:47:27 +0000
Subject: [Rd] C function, double problem
In-Reply-To: <1354933586648-4652537.post@n4.nabble.com>
References: <1354933586648-4652537.post@n4.nabble.com>
Message-ID: <50C3610F.9090902@sapo.pt>

Hello,

The double in R and the double in C are the same type, with the same 
number of decimals (64 bits), so it's not because the numbers are too long.
Try calling .C("function", other parameters, result = double(quantity)).
Or maybe the error is in the C code, of which we know nothing about.

Rui Barradas
Em 08-12-2012 02:26, mpietro escreveu:
> Hi everybody,
>
> here's my problem:
>
> i call a C function which calculates a large number of double values and
> puts them into an array which is passed from R as a parameter in the
> function (like  .C("function", other parameters, result =  as.double( c ( 1
> : quantity ) ).
> When the values come back to R in the result array, they are all truncated
> to their integer value (i.e. I lose the decimal parts).
> I think that the problem is that this calculated double numbers are actually
> too long, with many decimals, because i changed in code  the calculated
> values with arbitrary double values with a few decimals and it works.
>
> Has anybody any idea of where the problem is?
>
> Thanks in advance!
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/C-function-double-problem-tp4652537.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Sat Dec  8 16:58:35 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 8 Dec 2012 09:58:35 -0600
Subject: [Rd] C function, double problem
In-Reply-To: <1354933586648-4652537.post@n4.nabble.com>
References: <1354933586648-4652537.post@n4.nabble.com>
Message-ID: <20675.25515.678337.884430@max.nulle.part>


That is great example of why folks should NOT use the .C() interface.

Rcpp can help here, __even if you do not use any Rcpp language features__.
Below is a showcase for the recent sourceCpp() function which takes a C++
file (shown below), converts it and optionally runs the embedded R
code. Think of as something like Sweave for mixing C++ and R rather than
Latex and R.

Source file is shown via cat on the cmdline:

edd at max:/tmp$ cat dblvec.cpp 

#include <Rcpp.h>

#include <vector>

// [[Rcpp::export]]
std::vector<double> dbl(std::vector<double> x) {
  std::vector<double> y(x.size());
  for (unsigned int i=0; i<y.size(); i++)
    y[i] = 2.0*x[i];
  return y;
}


/*** R
     myx <- seq(1.1, 5.5, by=1.1)
     print(dbl(myx))
***/

edd at max:/tmp$
edd at max:/tmp$

We then simply source it to show off how it transform a C++ vector of doubles:

edd at max:/tmp$ R --quiet -e 'library(Rcpp); sourceCpp("dblvec.cpp")'
R> library(Rcpp); sourceCpp("dblvec.cpp")

R> myx <- seq(1.1, 5.5, by = 1.1)

R> print(dbl(myx))
[1]  2.2  4.4  6.6  8.8 11.0
R> 
R> 
edd at max:/tmp$ 

No make, compiler invocation, linking, ... which all happen behind the
scenes.  We just enjoy the C++ function to double the content of a double
vector. 


Hope this helps,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mtmorgan at fhcrc.org  Sun Dec  9 00:05:37 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 08 Dec 2012 15:05:37 -0800
Subject: [Rd] namespace S3 and S4 generic imports cannot both be satisfied:
Message-ID: <50C3C7C1.5050508@fhcrc.org>

PkgA wishes to write a method for 'unique' on S4 class 'A'. ?Methods indicates 
that one should

   setGeneric("unique")

   setClass("A")
   unique.A <- function(x, incomparables=FALSE, ...) {}
   setMethod(unique, "A", unique.A)

Both S3 and S4 methods need to be exported in the NAMESPACE

   import(methods)
   S3method(unique, A)
   exportMethods(unique)

PkgB introduces a new class and method

   setClass("B")
   unique.B <- function(x, incomparables=FALSE, ...) {}
   setMethod(unique, "B", unique.B)

and in the NAMESPACE has

   import(methods)
   importFrom(PkgA, unique)
   S3method(unique, B)
   exportMethods(unique)

Unfortuantely, R CMD check says that

* checking whether package 'PkgB' can be installed ... WARNING
Found the following significant warnings:
   Warning: found an S4 version of 'unique' so it has not been imported correctly
See '/home/mtmorgan/tmp/PkgB.Rcheck/00install.out' for details.

This is from (svn r61253) R-devel/src/library/base/R/namespace.R:1339, where the 
code finds the S4 generic, but not the S3 generic. Obviously the namespace 
cannot have both the S3 and S4 symbols defined, but this seems to be required? A 
workaround might extend the check to include getGeneric(genname)@default.

This scenario is reproducible in the attached tarball

   tar xzf PkgAB.tar.gz
   R CMD INSTALL PkgA
   R CMD check PkgB

Martin Morgan
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793
-------------- next part --------------
A non-text attachment was scrubbed...
Name: PkgAB.tar.gz
Type: application/x-gzip
Size: 973 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121208/df47c96a/attachment.gz>

From ripley at stats.ox.ac.uk  Sun Dec  9 13:51:58 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Dec 2012 12:51:58 +0000
Subject: [Rd] documentation for legend(): possible missing info for pch.
In-Reply-To: <50C1A7E7.1010709@gmail.com>
References: <50C1A7E7.1010709@gmail.com>
Message-ID: <50C4896E.1070102@stats.ox.ac.uk>

On 07/12/2012 08:25, Laurent Gautier wrote:
> In the documentation for graphics::legend(), the entry for "pch" is:
>
>  >      pch: the plotting symbols appearing in the legend, either as
>            vector of 1-character strings, or one (multi character)
>            string.  _Must_ be specified for symbol drawing.
>
>
> If I did not misread them, examples in the same documentation page
> suggest that it is also possible to pass integers.

The authors of legend() have not responded AFAICS.

It is possible to pass some integers, but 'pch = c(-1, 3, 4)' is not 
explained.   Strangely although ?points documents the interpretation of 
both positive and non-negative integers, legend() excludes negative ones.

I'll correct the docs, at least.

Thank you for the report.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From htl10 at users.sourceforge.net  Sun Dec  9 19:17:13 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Sun, 9 Dec 2012 18:17:13 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
Message-ID: <1355077033.97773.YahooMailClassic@web172303.mail.ir2.yahoo.com>

Noticed a problem for a while - tests/testit.Rd, tests/ver20.Rd are removed on "make clean" unintentionally.

This seems to come from a change in tests/Makefile.in, which adds the line:
   - at rm -f *.tar.gz *.Rd back in May 2012.

-----------
commit c4d70254e7b7f9d7ed17faecfb3097195d852ddc
Author: ripley <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
Date:   Sun May 27 09:04:41 2012 +0000

    fix some issues seen by examining no-segfaults.Rout
    
    git-svn-id: https://svn.r-project.org/R/trunk at 59451 00db46b3-68df-0310-9c12-caf00c1e9a41
----------

svn users probably don't notice files are unintentionally removed; git-svn does complain about version-controlled files being missing during rebase (i.e. re-applying local private patches to an updated upstream).

TIA.



From edd at debian.org  Sun Dec  9 19:39:04 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 9 Dec 2012 12:39:04 -0600
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <1355077033.97773.YahooMailClassic@web172303.mail.ir2.yahoo.com>
References: <1355077033.97773.YahooMailClassic@web172303.mail.ir2.yahoo.com>
Message-ID: <20676.56008.881879.85729@max.nulle.part>


On 9 December 2012 at 18:17, Hin-Tak Leung wrote:
| Noticed a problem for a while - tests/testit.Rd, tests/ver20.Rd are removed on "make clean" unintentionally.
| 
| This seems to come from a change in tests/Makefile.in, which adds the line:
|    - at rm -f *.tar.gz *.Rd back in May 2012.
| 
| -----------
| commit c4d70254e7b7f9d7ed17faecfb3097195d852ddc
| Author: ripley <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
| Date:   Sun May 27 09:04:41 2012 +0000
| 
|     fix some issues seen by examining no-segfaults.Rout
|     
|     git-svn-id: https://svn.r-project.org/R/trunk at 59451 00db46b3-68df-0310-9c12-caf00c1e9a41
| ----------
| 
| svn users probably don't notice files are unintentionally removed; git-svn does complain about version-controlled files being missing during rebase (i.e. re-applying local private patches to an updated upstream).

svn marks missing files via a '!' (and unknown/unexpected files with a '?'):

edd at max:~/svn/r-devel/tests$ svn st
?       Makefile
!       ver20.Rd
?       Native/Makefile
?       Examples/utils-Ex.Rout.fail
?       Examples/Makefile
!       testit.Rd
?       Embedding/Makefile
edd at max:~/svn/r-devel/tests$ 

Do you REALLY think svn would not know about missing files?  There does not
seem to be a limit on the disdain for svn among git users. Fascinating.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jmc at r-project.org  Sun Dec  9 20:27:55 2012
From: jmc at r-project.org (John Chambers)
Date: Sun, 09 Dec 2012 11:27:55 -0800
Subject: [Rd] namespace S3 and S4 generic imports cannot both be
	satisfied:
In-Reply-To: <50C3C7C1.5050508@fhcrc.org>
References: <50C3C7C1.5050508@fhcrc.org>
Message-ID: <50C4E63B.1060207@r-project.org>

Yes, you are right.

Mixing S3 and S4 methods for a generic is fine, although in subtle cases 
one is safer promoting the S3 method to an S4 method, as you did in your 
example.

Usually, the default method for the S4 generic is the S3 generic.  But, 
in general, it's not possible to check algorithmically whether the S3 
methods will be dispatched.  For example, an S4 method on "vector" could 
dispatch S3 methods on subclasses "numeric", etc. (don't ask why ...), 
for a generic that had no default method.

That the trouble with this check isn't found right away is likely 
because one is typically working with a primitive where no generic 
function is created.

Should be fixed in rev. 61263.  Please check on your real example; it 
seems fine on the test you submitted.

Thanks for the catch.

John

On 12/8/12 3:05 PM, Martin Morgan wrote:
> PkgA wishes to write a method for 'unique' on S4 class 'A'. ?Methods
> indicates that one should
>
>    setGeneric("unique")
>
>    setClass("A")
>    unique.A <- function(x, incomparables=FALSE, ...) {}
>    setMethod(unique, "A", unique.A)
>
> Both S3 and S4 methods need to be exported in the NAMESPACE
>
>    import(methods)
>    S3method(unique, A)
>    exportMethods(unique)
>
> PkgB introduces a new class and method
>
>    setClass("B")
>    unique.B <- function(x, incomparables=FALSE, ...) {}
>    setMethod(unique, "B", unique.B)
>
> and in the NAMESPACE has
>
>    import(methods)
>    importFrom(PkgA, unique)
>    S3method(unique, B)
>    exportMethods(unique)
>
> Unfortuantely, R CMD check says that
>
> * checking whether package 'PkgB' can be installed ... WARNING
> Found the following significant warnings:
>    Warning: found an S4 version of 'unique' so it has not been imported
> correctly
> See '/home/mtmorgan/tmp/PkgB.Rcheck/00install.out' for details.
>
> This is from (svn r61253) R-devel/src/library/base/R/namespace.R:1339,
> where the code finds the S4 generic, but not the S3 generic. Obviously
> the namespace cannot have both the S3 and S4 symbols defined, but this
> seems to be required? A workaround might extend the check to include
> getGeneric(genname)@default.
>
> This scenario is reproducible in the attached tarball
>
>    tar xzf PkgAB.tar.gz
>    R CMD INSTALL PkgA
>    R CMD check PkgB
>
> Martin Morgan
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From htl10 at users.sourceforge.net  Sun Dec  9 22:13:22 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Sun, 9 Dec 2012 21:13:22 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <20676.56008.881879.85729@max.nulle.part>
Message-ID: <1355087602.12550.YahooMailClassic@web172306.mail.ir2.yahoo.com>

--- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org> wrote:

> On 9 December 2012 at 18:17, Hin-Tak Leung wrote:
> | Noticed a problem for a while - tests/testit.Rd,
> tests/ver20.Rd are removed on "make clean" unintentionally.
> | 
> | This seems to come from a change in tests/Makefile.in,
> which adds the line:
> |? ? - at rm -f *.tar.gz *.Rd back in May 2012.
> | 
> | -----------
> | commit c4d70254e7b7f9d7ed17faecfb3097195d852ddc
> | Author: ripley
> <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
> | Date:???Sun May 27 09:04:41 2012 +0000
> | 
> |? ???fix some issues seen by examining
> no-segfaults.Rout
> |? ???
> |? ???git-svn-id: https://svn.r-project.org/R/trunk at 59451
> 00db46b3-68df-0310-9c12-caf00c1e9a41
> | ----------
> | 
> | svn users probably don't notice files are unintentionally
> removed; git-svn does complain about version-controlled
> files being missing during rebase (i.e. re-applying local
> private patches to an updated upstream).
> 
> svn marks missing files via a '!' (and unknown/unexpected
> files with a '?'):
> 
> edd at max:~/svn/r-devel/tests$ svn st
> ?? ? ???Makefile
> !? ? ???ver20.Rd
> ?? ? ???Native/Makefile
> ?? ?
> ???Examples/utils-Ex.Rout.fail
> ?? ? ???Examples/Makefile
> !? ? ???testit.Rd
> ?? ? ???Embedding/Makefile
> edd at max:~/svn/r-devel/tests$ 
> 
> Do you REALLY think svn would not know about missing
> files?? There does not
> seem to be a limit on the disdain for svn among git users.
> Fascinating.
> 
> Dirk

Sorry about the over-sight on subversion - to be honest I have not been using subversion itself at all, since I am happier with git-svn (entirely my own opinion). That said, please do not distract the issue - a small bug was introduced back in May which you seem to corroborate.

Thanks for confirming the issue being also seen with subversion, nonetheless.

I know a few number of people who are happier with bzr, darcs, mercurial. That doesn't really say much about anything.

Hin-Tak



From pauljohn32 at gmail.com  Mon Dec 10 07:51:10 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 10 Dec 2012 00:51:10 -0600
Subject: [Rd] Changing arguments inside .Call. Wise to encourage "const" on
	all arguments?
Message-ID: <CAErODj-=z9J_kY6hbgS+MrDLg9K=-3M4bJH9aeAbhL8g=csp7g@mail.gmail.com>

I'm continuing my work on finding speedups in generalized inverse
calculations in some simulations.  It leads me back to .C and .Call,
and some questions I've never been able to answer for myself.  It may
be I can push some calculations to LAPACK in or C BLAS, that's why I
realized again I don't understand the call by reference or value
semantics of .Call

Why aren't users of .Call encouraged to "const" their arguments, and
why doesn't .Call do this for them (if we really believe in return by
value)?

R Gentleman's R Programming for Bioinformatics is the most
understandable treatment I've found on .Call. It appears to me .Call
leaves "wiggle room" where there should be none.  Here's Gentleman on
p. 185. "For .Call and .External, the return value is an R object (the
C functions must return a SEXP), and for these functions the values
that were passed are typically not modified.  If they must be
modified, then making a copy in R, prior to invoking the C code, is
necessary."

I *think* that means:

.Call allows return by reference, BUT we really wish users would not
use it. Users can damage R data structures that are pointed to unless
they really truly know what they are doing on the C side. ??

This seems dangerous. Why allow return  by reference at all?

On p. 197, there's a similar comment  "Any function that has been
invoked by either .External or .Call will have all of its arguments
protected already. You do not need to protect them. .... [T]hey were
not duplicated and should be treated as read-only values."

"should be ... read-only" concerns me. They are "protected" in the
garbage collector sense, but they are not protected from "return by
reference" damage. Right?

Why doesn't the documentation recommend function writers to mark
arguments to C functions as const?  Isn't that what the return by
value policy would suggest?

Here's a troublesome example in  R src/main/array.c:

/* DropDims strips away redundant dimensioning information. */
/* If there is an appropriate dimnames attribute the correct */
/* element is extracted and attached to the vector as a names */
/* attribute.  Note that this function mutates x. */
/* Duplication should occur before this is called. */

SEXP DropDims(SEXP x)
{
    SEXP dims, dimnames, newnames = R_NilValue;
    int i, n, ndims;

   PROTECT(x);
   dims = getAttrib(x, R_DimSymbol);
[... SNIP ....]
    setAttrib(x, R_DimNamesSymbol, R_NilValue);
    setAttrib(x, R_DimSymbol, R_NilValue);
    setAttrib(x, R_NamesSymbol, newnames);
[... SNIP ....]

return x;
}

Well, at least there's a warning comment with that one.  But it does
show .Call allows call by reference.

Why allow it, though? DropDims could copy x, modify the copy, and return it.

I wondered why DropDims bothers to return x at all. We seem to be
using modify and return by reference there.

I also wondered why x is PROTECTED, actually. Its an argument, wasn't
it automatically protected? Is it no longer  protected after the
function starts modifying it?

Here's an  example with similar usage in Writing R Extensions, section
5.10.1 "Calling .Call".  It protects the arguments a and b (needed
??), then changes them.

#include <R.h>
#include <Rdefines.h>

     SEXP convolve2(SEXP a, SEXP b)
     {
         R_len_t i, j, na, nb, nab;
         double *xa, *xb, *xab;
         SEXP ab;

         PROTECT(a = AS_NUMERIC(a)); /* PJ wonders, doesn't this alter
"a"  in calling code*/
         PROTECT(b = AS_NUMERIC(b));
         na = LENGTH(a); nb = LENGTH(b); nab = na + nb - 1;
         PROTECT(ab = NEW_NUMERIC(nab));
         xa = NUMERIC_POINTER(a); xb = NUMERIC_POINTER(b);
         xab = NUMERIC_POINTER(ab);
         for(i = 0; i < nab; i++) xab[i] = 0.0;
         for(i = 0; i < na; i++)
              for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
         UNPROTECT(3);
         return(ab);
     }


Doesn't

        PROTECT(a = AS_NUMERIC(a));

have the alter the data structure "a" both inside the C function and
in the calling R code as well? And, if a was PROTECTED automatically,
could we do without that PROTECT()?

pj

-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From ronggui.huang at gmail.com  Mon Dec 10 08:15:34 2012
From: ronggui.huang at gmail.com (Wincent)
Date: Mon, 10 Dec 2012 15:15:34 +0800
Subject: [Rd] How to locate a file quickly
Message-ID: <CANQBBMuZF-dLNWYZMu5oPwRUHHALrRhdipoMhWL3LEARnVuFvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121210/7ccdc3e9/attachment.pl>

From suharto_anggono at yahoo.com  Mon Dec 10 08:46:13 2012
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 9 Dec 2012 23:46:13 -0800 (PST)
Subject: [Rd] factor(x, exclude=y) if x is a factor
Message-ID: <1355125573.27046.YahooMailClassic@web125103.mail.ne1.yahoo.com>

After searching, I see that https://stat.ethz.ch/pipermail/r-help/2011-April/276274.html has mentioned this issue, perhaps more clearly.

Thanks for pointing out "Arguments" section about 'exclude'. That documents the code
    exclude <- as.vector(exclude, typeof(x))

A note: if x is a factor, factor(x, exclude=y) doesn't always do nothing other than dropping unused levels.

> x <- 2:3
> x
[1] 2 3
> xf <- factor(x, levels=x)
> xf
[1] 2 3
Levels: 2 3
> factor(xf, exclude=2)
[1] <NA> 3
Levels: 3

> x <- c(2:3, "a")
> x
[1] "2" "3" "a"
> xf <- factor(x, levels=x)
> xf
[1] 2 3 a
Levels: 2 3 a
> factor(xf, exclude=2)
[1] <NA> 3    a
Levels: 3 a

> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

--- On Thu, 6/12/12, Lorenz, David <lorenz at usgs.gov> wrote:

From: Lorenz, David <lorenz at usgs.gov>
Subject: Re: [Rd] factor(x, exclude=y) if x is a factor
To: "Suharto Anggono Suharto Anggono" <suharto_anggono at yahoo.com>
Cc: R-devel at r-project.org
Date: Thursday, 6 December, 2012, 10:12 PM

Suharto,? I think that the key is to read the definition of exclude in the Arguments section:a vector of values to be excluded when forming the set of levels. This should 
be of the same type as x, and will be coerced if necessary.? Because?the levels already exist for x as a factor, they are not formed or revised, except to drop unused levels in the case where exclude=NULL (or the default value). To drop level a from x use:

factor(as.character(x), exclude="a")? or, on creation:
x <- factor(c("a", "b"), exclude="a")
Dave


On Wed, Dec 5, 2012 at 11:39 PM, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:


factor(x, exclude=factor("a", levels=c("a","b")))






From maechler at stat.math.ethz.ch  Mon Dec 10 09:42:29 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Dec 2012 09:42:29 +0100
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <1355087602.12550.YahooMailClassic@web172306.mail.ir2.yahoo.com>
References: <20676.56008.881879.85729@max.nulle.part>
	<1355087602.12550.YahooMailClassic@web172306.mail.ir2.yahoo.com>
Message-ID: <20677.41077.877503.721651@stat.math.ethz.ch>

> --- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org> wrote:

> On 9 December 2012 at 18:17, Hin-Tak Leung wrote:
> | Noticed a problem for a while - tests/testit.Rd,
> tests/ver20.Rd are removed on "make clean" unintentionally.
> | 
> | This seems to come from a change in tests/Makefile.in, which adds the line:
> |? ? - at rm -f *.tar.gz *.Rd back in May 2012.
> | 
> | -----------
> | commit c4d70254e7b7f9d7ed17faecfb3097195d852ddc
> | Author: ripley <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
> | Date:???Sun May 27 09:04:41 2012 +0000
> | 
> |? ???fix some issues seen by examining no-segfaults.Rout
> |? ???

[..... dropped
 ..... embarrassing / amusing distraction on svn/git ..... 
 ..... started by the OP, not by Dirk !
]

> That said ..a small bug was introduced back in May  .....

Yes, you are right.
BTW: The reason that nobody (from R core, probably not many
people otherwise) has found/mentioned this bug before is not the
use of svn, but the fact that it is much more convenient (and
hence somewhat recommended) to build R outside of its source
directory, and in that case the two *.Rd files that belong to
./tests/ are not removed (from the *build* directory's ./tests/)

Martin


From htl10 at users.sourceforge.net  Mon Dec 10 10:23:14 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Mon, 10 Dec 2012 09:23:14 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <20677.41077.877503.721651@stat.math.ethz.ch>
Message-ID: <1355131394.64582.YahooMailClassic@web172305.mail.ir2.yahoo.com>

--- On Mon, 10/12/12, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> > --- On Sun, 9/12/12, Dirk
> Eddelbuettel <edd at debian.org>
> wrote:
> 
> > On 9 December 2012 at 18:17, Hin-Tak Leung wrote:
> > | Noticed a problem for a while - tests/testit.Rd,
> > tests/ver20.Rd are removed on "make clean"
> unintentionally.
> > | 
> > | This seems to come from a change in
> tests/Makefile.in, which adds the line:
> > |? ? - at rm -f *.tar.gz *.Rd back in May 2012.
> > | 
> > | -----------
> > | commit c4d70254e7b7f9d7ed17faecfb3097195d852ddc
> > | Author: ripley
> <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
> > | Date:???Sun May 27 09:04:41 2012 +0000
> > | 
> > |? ???fix some issues seen by examining
> no-segfaults.Rout
> > |? ???
> 
> [..... dropped
>  ..... embarrassing / amusing distraction on svn/git ..... 
>  ..... started by the OP, not by Dirk !
> ]

That comment is a bit childish, don't you think?

> > That said ..a small bug was introduced back in
> May? .....
> 
> Yes, you are right.
> BTW: The reason that nobody (from R core, probably not many
> people otherwise) has found/mentioned this bug before is not
> the
> use of svn, but the fact that it is much more convenient
> (and
> hence somewhat recommended) to build R outside of its
> source
> directory, and in that case the two *.Rd files that belong
> to
> ./tests/ are not removed (from the *build* directory's
> ./tests/)

"more convenient" is a subjective matter.

As I mentioned in my original post, I have a few local modifications which are continually re-applied ("rebase"d, but I shall not be drawn into arguing about matters of personal preference again) - therefore it is more convenient to build on top.

Since we are on the topic of locally-continually applied modifications, I reported another issue about 40 days ago, that reccent R trunk now treat revision as numeric, so 'unknown' in the topic level Makefile.in should be changed accordingly to 0 or some number. Here is the diff - one of the "locally-continually applied modifications" I am talking about:

--- a/Makefile.in
+++ b/Makefile.in
@@ -94,7 +94,7 @@ svnonly:
        @if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
          (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
          touch non-tarball ; \
-         (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: unknown") 2> /dev/null \
+         (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: 0") 2> /dev/null \
            | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
            | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
          $(SHELL) $(top_srcdir)/tools/move-if-change SVN-REVISION-tmp SVN-REVISION ; \




From maechler at stat.math.ethz.ch  Mon Dec 10 17:46:50 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Dec 2012 17:46:50 +0100
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <1355131394.64582.YahooMailClassic@web172305.mail.ir2.yahoo.com>
References: <20677.41077.877503.721651@stat.math.ethz.ch>
	<1355131394.64582.YahooMailClassic@web172305.mail.ir2.yahoo.com>
Message-ID: <20678.4602.644283.169005@stat.math.ethz.ch>

>>>>> Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>     on Mon, 10 Dec 2012 09:23:14 +0000 writes:

    > --- On Mon, 10/12/12, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
 [.....]

    >> > That said ..a small bug was introduced back in
    >> May? .....
    >> 
    >> Yes, you are right.
    >> BTW: The reason that nobody (from R core, probably not many
    >> people otherwise) has found/mentioned this bug before is not
    >> the
    >> use of svn, but the fact that it is much more convenient
    >> (and
    >> hence somewhat recommended) to build R outside of its
    >> source
    >> directory, and in that case the two *.Rd files that belong
    >> to
    >> ./tests/ are not removed (from the *build* directory's
    >> ./tests/)

    > "more convenient" is a subjective matter.

    > As I mentioned in my original post, I have a few local modifications which are continually re-applied ("rebase"d, but I shall not be drawn into arguing about matters of personal preference again) - therefore it is more convenient to build on top.

    > Since we are on the topic of locally-continually applied modifications, I reported another issue about 40 days ago, that reccent R trunk now treat revision as numeric, so 'unknown' in the topic level Makefile.in should be changed accordingly to 0 or some number. Here is the diff - one of the "locally-continually applied modifications" I am talking about:

    > --- a/Makefile.in
    > +++ b/Makefile.in
    > @@ -94,7 +94,7 @@ svnonly:
    > @if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
    > (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
    > touch non-tarball ; \
    > -         (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: unknown") 2> /dev/null \
    > +         (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: 0") 2> /dev/null \
    > | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
    > | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
    > $(SHELL) $(top_srcdir)/tools/move-if-change SVN-REVISION-tmp SVN-REVISION ; \

That change needs another important change in src/main/version.c
where the string "unknown" has been explicitly looked for.

I have now committed a patch to both ---
using '-99' : something clearly "artificial", rather than '0'
which looks too innocuous.

Martin


From maechler at stat.math.ethz.ch  Mon Dec 10 17:49:33 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Dec 2012 17:49:33 +0100
Subject: [Rd] How to locate a file quickly
In-Reply-To: <CANQBBMuZF-dLNWYZMu5oPwRUHHALrRhdipoMhWL3LEARnVuFvw@mail.gmail.com>
References: <CANQBBMuZF-dLNWYZMu5oPwRUHHALrRhdipoMhWL3LEARnVuFvw@mail.gmail.com>
Message-ID: <20678.4765.512748.465665@stat.math.ethz.ch>

>>>>> Wincent  <ronggui.huang at gmail.com>
>>>>>     on Mon, 10 Dec 2012 15:15:34 +0800 writes:

    > Dear all,
    > During the development of R packages, more and more functions are written
    > and some of them are placed in a file. After a while, I want to revised a
    > function, but forget which file the function is in. Is there a recommended
    > way of locate a function quickly?

why do you think this belongs to R-devel ?

Please use  R-help  for such questions.

Best regards,
Martin


From therneau at mayo.edu  Mon Dec 10 18:12:19 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 10 Dec 2012 11:12:19 -0600
Subject: [Rd] CMD check and .Rbuildignore
Message-ID: <50C617F3.4010707@mayo.edu>

I often run R CMD check on my package source.  I've noted of late that this process gives 
warning messages about
files listed in my .Rbuildignore file, where is once ignored these.

Terry T.


From htl10 at users.sourceforge.net  Mon Dec 10 19:55:52 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Mon, 10 Dec 2012 18:55:52 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <20678.4602.644283.169005@stat.math.ethz.ch>
Message-ID: <1355165752.80715.YahooMailClassic@web172301.mail.ir2.yahoo.com>

--- On Mon, 10/12/12, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> >>>>> Hin-Tak Leung
> <htl10 at users.sourceforge.net>
> >>>>>? ???on Mon, 10 Dec
> 2012 09:23:14 +0000 writes:
> 
> ? ? > --- On Mon, 10/12/12, Martin Maechler
> <maechler at stat.math.ethz.ch>
> wrote:
>  [.....]
> 
> ? ? >> > That said ..a small bug was
> introduced back in
> ? ? >> May? .....
> ? ? >> 
> ? ? >> Yes, you are right.
> ? ? >> BTW: The reason that nobody (from R
> core, probably not many
> ? ? >> people otherwise) has found/mentioned
> this bug before is not
> ? ? >> the
> ? ? >> use of svn, but the fact that it is
> much more convenient
> ? ? >> (and
> ? ? >> hence somewhat recommended) to build
> R outside of its
> ? ? >> source
> ? ? >> directory, and in that case the two
> *.Rd files that belong
> ? ? >> to
> ? ? >> ./tests/ are not removed (from the
> *build* directory's
> ? ? >> ./tests/)
> 
> ? ? > "more convenient" is a subjective
> matter.
> 
> ? ? > As I mentioned in my original post, I
> have a few local modifications which are continually
> re-applied ("rebase"d, but I shall not be drawn into arguing
> about matters of personal preference again) - therefore it
> is more convenient to build on top.
> 
> ? ? > Since we are on the topic of
> locally-continually applied modifications, I reported
> another issue about 40 days ago, that reccent R trunk now
> treat revision as numeric, so 'unknown' in the topic level
> Makefile.in should be changed accordingly to 0 or some
> number. Here is the diff - one of the "locally-continually
> applied modifications" I am talking about:
> 
> ? ? > --- a/Makefile.in
> ? ? > +++ b/Makefile.in
> ? ? > @@ -94,7 +94,7 @@ svnonly:
> ? ? > @if test ! -f "$(srcdir)/doc/FAQ" || test
> -f non-tarball ; then \
> ? ? > (cd doc/manual && $(MAKE)
> front-matter html-non-svn) ; \
> ? ? > touch non-tarball ; \
> ? ? > -? ? ?
> ???(cd $(srcdir); LC_ALL=C TZ=GMT svn info ||
> $(ECHO) "Revision: unknown") 2> /dev/null \
> ? ? > +? ? ?
> ???(cd $(srcdir); LC_ALL=C TZ=GMT svn info ||
> $(ECHO) "Revision: 0") 2> /dev/null \
> ? ? > | sed -n -e '/^Revision/p' -e '/^Last
> Changed Date/'p \
> ? ? > | cut -d' ' -f1,2,3,4 >
> SVN-REVISION-tmp ; \
> ? ? > $(SHELL)
> $(top_srcdir)/tools/move-if-change SVN-REVISION-tmp
> SVN-REVISION ; \
> 
> That change needs another important change in
> src/main/version.c
> where the string "unknown" has been explicitly looked for.
> 
> I have now committed a patch to both ---
> using '-99' : something clearly "artificial", rather than
> '0'
> which looks too innocuous.

Thanks.

Genuine revision number starts from 1, so 0 does the minimal job of indicating it is not genuine. I can't remember what was the precise problem/symptom, possibly R showing a very ugly error message when it starts, trying to display some basic version info.

I have 7 such "continually locally applied modifications" at the moment - the oldest two dated back 14 months ago. The other 6 are something which are temporarily useful, or at least harmless, but not obviously correct way (or "one of the obviously correct alternatives") of doing things.

I certainly find that being able to carry "continually locally applied modifications", somewhat indefinitely and privately, from 40 days old to 14 months old, while tracking and incorporating upstream changes, and continue to make and track local changes, a useful feature of distributed version control systems in general, versus centralized version control systems. The 7th mod would have been either automatically dropped (if the up-stream applies the exact same change, which is 40 days later), or *offered* to be dropped/modified in this case when upstream applies a different change to the same code area. 

BTW, the current version of the recommended library Matrix has not been able to build since early September. (over 3 months ago). I assume that it will be fixed eventually, or before R 16, in the next few months.


From simon.urbanek at r-project.org  Mon Dec 10 20:05:23 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 10 Dec 2012 14:05:23 -0500
Subject: [Rd] Changing arguments inside .Call. Wise to encourage "const"
	on all arguments?
In-Reply-To: <CAErODj-=z9J_kY6hbgS+MrDLg9K=-3M4bJH9aeAbhL8g=csp7g@mail.gmail.com>
References: <CAErODj-=z9J_kY6hbgS+MrDLg9K=-3M4bJH9aeAbhL8g=csp7g@mail.gmail.com>
Message-ID: <E1BEA37D-B8A8-4AC3-B23B-8664D5B5E537@r-project.org>


On Dec 10, 2012, at 1:51 AM, Paul Johnson wrote:

> I'm continuing my work on finding speedups in generalized inverse
> calculations in some simulations.  It leads me back to .C and .Call,
> and some questions I've never been able to answer for myself.  It may
> be I can push some calculations to LAPACK in or C BLAS, that's why I
> realized again I don't understand the call by reference or value
> semantics of .Call
> 
> Why aren't users of .Call encouraged to "const" their arguments, and
> why doesn't .Call do this for them (if we really believe in return by
> value)?
> 

Because there is a difference between the *data* part of the SEXP and the object itself. Internal structure of the object may need to be modified (e.g. the NAMED ref counting increased when you assign it) in a call to R API. You can't flag the data part as const separately, so you have to use non-const SEXP.


> R Gentleman's R Programming for Bioinformatics is the most
> understandable treatment I've found on .Call. It appears to me .Call
> leaves "wiggle room" where there should be none.  Here's Gentleman on
> p. 185. "For .Call and .External, the return value is an R object (the
> C functions must return a SEXP), and for these functions the values
> that were passed are typically not modified.  If they must be
> modified, then making a copy in R, prior to invoking the C code, is
> necessary."
> 
> I *think* that means:
> 
> .Call allows return by reference, BUT we really wish users would not
> use it. Users can damage R data structures that are pointed to unless
> they really truly know what they are doing on the C side. ??
> 
> This seems dangerous. Why allow return  by reference at all?
> 

Because it is completely legal to do things like

SEXP last(SEXP bar) {
   if (TYPEOF(bar) = VECSXP && LENGTH(bar) > 0)
     return VECTOR_ELT(bar, LENGTH(bar) - 1);
  Rf_error("sorry, I only work on lists");
 }

There is no point in duplicating the element.



> On p. 197, there's a similar comment  "Any function that has been
> invoked by either .External or .Call will have all of its arguments
> protected already. You do not need to protect them. .... [T]hey were
> not duplicated and should be treated as read-only values."
> 
> "should be ... read-only" concerns me. They are "protected" in the
> garbage collector sense,

Yes


> but they are not protected from "return by
> reference" damage. Right?
> 

There is no "return by reference damage".

The only problem is if you modify input arguments while someone else holds a reference, but there is no way in C to prevent that while still allowing them to be useful. Note that it is legal to modify input arguments if there are no references to it.

Cheers,
Simon


> Why doesn't the documentation recommend function writers to mark
> arguments to C functions as const?  Isn't that what the return by
> value policy would suggest?
> 
> Here's a troublesome example in  R src/main/array.c:
> 
> /* DropDims strips away redundant dimensioning information. */
> /* If there is an appropriate dimnames attribute the correct */
> /* element is extracted and attached to the vector as a names */
> /* attribute.  Note that this function mutates x. */
> /* Duplication should occur before this is called. */
> 
> SEXP DropDims(SEXP x)
> {
>    SEXP dims, dimnames, newnames = R_NilValue;
>    int i, n, ndims;
> 
>   PROTECT(x);
>   dims = getAttrib(x, R_DimSymbol);
> [... SNIP ....]
>    setAttrib(x, R_DimNamesSymbol, R_NilValue);
>    setAttrib(x, R_DimSymbol, R_NilValue);
>    setAttrib(x, R_NamesSymbol, newnames);
> [... SNIP ....]
> 
> return x;
> }
> 
> Well, at least there's a warning comment with that one.  But it does
> show .Call allows call by reference.
> 
> Why allow it, though? DropDims could copy x, modify the copy, and return it.
> 
> I wondered why DropDims bothers to return x at all. We seem to be
> using modify and return by reference there.
> 
> I also wondered why x is PROTECTED, actually. Its an argument, wasn't
> it automatically protected? Is it no longer  protected after the
> function starts modifying it?
> 
> Here's an  example with similar usage in Writing R Extensions, section
> 5.10.1 "Calling .Call".  It protects the arguments a and b (needed
> ??), then changes them.
> 
> #include <R.h>
> #include <Rdefines.h>
> 
>     SEXP convolve2(SEXP a, SEXP b)
>     {
>         R_len_t i, j, na, nb, nab;
>         double *xa, *xb, *xab;
>         SEXP ab;
> 
>         PROTECT(a = AS_NUMERIC(a)); /* PJ wonders, doesn't this alter
> "a"  in calling code*/
>         PROTECT(b = AS_NUMERIC(b));
>         na = LENGTH(a); nb = LENGTH(b); nab = na + nb - 1;
>         PROTECT(ab = NEW_NUMERIC(nab));
>         xa = NUMERIC_POINTER(a); xb = NUMERIC_POINTER(b);
>         xab = NUMERIC_POINTER(ab);
>         for(i = 0; i < nab; i++) xab[i] = 0.0;
>         for(i = 0; i < na; i++)
>              for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
>         UNPROTECT(3);
>         return(ab);
>     }
> 
> 
> Doesn't
> 
>        PROTECT(a = AS_NUMERIC(a));
> 
> have the alter the data structure "a" both inside the C function and
> in the calling R code as well? And, if a was PROTECTED automatically,
> could we do without that PROTECT()?
> 
> pj
> 
> -- 
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Mon Dec 10 22:48:40 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 10 Dec 2012 16:48:40 -0500
Subject: [Rd] Changing arguments inside .Call. Wise to encourage "const"
	on all arguments?
In-Reply-To: <E1BEA37D-B8A8-4AC3-B23B-8664D5B5E537@r-project.org>
References: <CAErODj-=z9J_kY6hbgS+MrDLg9K=-3M4bJH9aeAbhL8g=csp7g@mail.gmail.com>
	<E1BEA37D-B8A8-4AC3-B23B-8664D5B5E537@r-project.org>
Message-ID: <D01288E6-4EDF-48CF-BE74-6D83AA7D48F7@r-project.org>

On Dec 10, 2012, at 2:05 PM, Simon Urbanek wrote:

> 
> On Dec 10, 2012, at 1:51 AM, Paul Johnson wrote:
> 
>> I'm continuing my work on finding speedups in generalized inverse
>> calculations in some simulations.  It leads me back to .C and .Call,
>> and some questions I've never been able to answer for myself.  It may
>> be I can push some calculations to LAPACK in or C BLAS, that's why I
>> realized again I don't understand the call by reference or value
>> semantics of .Call
>> 
>> Why aren't users of .Call encouraged to "const" their arguments, and
>> why doesn't .Call do this for them (if we really believe in return by
>> value)?
>> 
> 
> Because there is a difference between the *data* part of the SEXP and the object itself. Internal structure of the object may need to be modified (e.g. the NAMED ref counting increased when you assign it) in a call to R API. You can't flag the data part as const separately, so you have to use non-const SEXP.
> 
> 
>> R Gentleman's R Programming for Bioinformatics is the most
>> understandable treatment I've found on .Call. It appears to me .Call
>> leaves "wiggle room" where there should be none.  Here's Gentleman on
>> p. 185. "For .Call and .External, the return value is an R object (the
>> C functions must return a SEXP), and for these functions the values
>> that were passed are typically not modified.  If they must be
>> modified, then making a copy in R, prior to invoking the C code, is
>> necessary."
>> 
>> I *think* that means:
>> 
>> .Call allows return by reference, BUT we really wish users would not
>> use it. Users can damage R data structures that are pointed to unless
>> they really truly know what they are doing on the C side. ??
>> 
>> This seems dangerous. Why allow return  by reference at all?
>> 
> 
> Because it is completely legal to do things like
> 
> SEXP last(SEXP bar) {
>   if (TYPEOF(bar) = VECSXP && LENGTH(bar) > 0)
>     return VECTOR_ELT(bar, LENGTH(bar) - 1);
>  Rf_error("sorry, I only work on lists");
> }
> 

Martin Morgan pointed out that this example is a bad one -- which is true. The common idiom that is safe is

SEXP foo(SEXP bar) {
...
return bar;
}

However, the last() example above is bad, because returning the element directly is a bad idea -- the conservative approach would be to use duplicate(), the more efficient one would be to bump up NAMED. Sorry, my bad. I guess I was rather strengthening Paul's point to duplicate() when in doubt even if it's less efficient :).

Cheers,
Simon


> There is no point in duplicating the element.
> 
> 
> 
>> On p. 197, there's a similar comment  "Any function that has been
>> invoked by either .External or .Call will have all of its arguments
>> protected already. You do not need to protect them. .... [T]hey were
>> not duplicated and should be treated as read-only values."
>> 
>> "should be ... read-only" concerns me. They are "protected" in the
>> garbage collector sense,
> 
> Yes
> 
> 
>> but they are not protected from "return by
>> reference" damage. Right?
>> 
> 
> There is no "return by reference damage".
> 
> The only problem is if you modify input arguments while someone else holds a reference, but there is no way in C to prevent that while still allowing them to be useful. Note that it is legal to modify input arguments if there are no references to it.
> 
> Cheers,
> Simon
> 
> 
>> Why doesn't the documentation recommend function writers to mark
>> arguments to C functions as const?  Isn't that what the return by
>> value policy would suggest?
>> 
>> Here's a troublesome example in  R src/main/array.c:
>> 
>> /* DropDims strips away redundant dimensioning information. */
>> /* If there is an appropriate dimnames attribute the correct */
>> /* element is extracted and attached to the vector as a names */
>> /* attribute.  Note that this function mutates x. */
>> /* Duplication should occur before this is called. */
>> 
>> SEXP DropDims(SEXP x)
>> {
>>   SEXP dims, dimnames, newnames = R_NilValue;
>>   int i, n, ndims;
>> 
>>  PROTECT(x);
>>  dims = getAttrib(x, R_DimSymbol);
>> [... SNIP ....]
>>   setAttrib(x, R_DimNamesSymbol, R_NilValue);
>>   setAttrib(x, R_DimSymbol, R_NilValue);
>>   setAttrib(x, R_NamesSymbol, newnames);
>> [... SNIP ....]
>> 
>> return x;
>> }
>> 
>> Well, at least there's a warning comment with that one.  But it does
>> show .Call allows call by reference.
>> 
>> Why allow it, though? DropDims could copy x, modify the copy, and return it.
>> 
>> I wondered why DropDims bothers to return x at all. We seem to be
>> using modify and return by reference there.
>> 
>> I also wondered why x is PROTECTED, actually. Its an argument, wasn't
>> it automatically protected? Is it no longer  protected after the
>> function starts modifying it?
>> 
>> Here's an  example with similar usage in Writing R Extensions, section
>> 5.10.1 "Calling .Call".  It protects the arguments a and b (needed
>> ??), then changes them.
>> 
>> #include <R.h>
>> #include <Rdefines.h>
>> 
>>    SEXP convolve2(SEXP a, SEXP b)
>>    {
>>        R_len_t i, j, na, nb, nab;
>>        double *xa, *xb, *xab;
>>        SEXP ab;
>> 
>>        PROTECT(a = AS_NUMERIC(a)); /* PJ wonders, doesn't this alter
>> "a"  in calling code*/
>>        PROTECT(b = AS_NUMERIC(b));
>>        na = LENGTH(a); nb = LENGTH(b); nab = na + nb - 1;
>>        PROTECT(ab = NEW_NUMERIC(nab));
>>        xa = NUMERIC_POINTER(a); xb = NUMERIC_POINTER(b);
>>        xab = NUMERIC_POINTER(ab);
>>        for(i = 0; i < nab; i++) xab[i] = 0.0;
>>        for(i = 0; i < na; i++)
>>             for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
>>        UNPROTECT(3);
>>        return(ab);
>>    }
>> 
>> 
>> Doesn't
>> 
>>       PROTECT(a = AS_NUMERIC(a));
>> 
>> have the alter the data structure "a" both inside the C function and
>> in the calling R code as well? And, if a was PROTECTED automatically,
>> could we do without that PROTECT()?
>> 
>> pj
>> 
>> -- 
>> Paul E. Johnson
>> Professor, Political Science      Assoc. Director
>> 1541 Lilac Lane, Room 504      Center for Research Methods
>> University of Kansas                 University of Kansas
>> http://pj.freefaculty.org               http://quant.ku.edu
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From winstonchang1 at gmail.com  Tue Dec 11 05:30:19 2012
From: winstonchang1 at gmail.com (Winston Chang)
Date: Mon, 10 Dec 2012 22:30:19 -0600
Subject: [Rd] Bug in mclapply?
Message-ID: <CAFOpNVEg6SNre+=0E4BM=3BoxnjLuGBLqmAxj-STu2RHUWPkmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121210/b9a76d53/attachment.pl>

From benjamin.hofner at fau.de  Mon Dec 10 17:45:52 2012
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Mon, 10 Dec 2012 17:45:52 +0100
Subject: [Rd] Generate .Rout.save files for vignettes
Message-ID: <50C611C0.9040700@fau.de>

I am looking for a way to generate .Rout.save files for vignettes.
The manual "Writing R Extensions" states here [1] in item number 20:

"If there is a target output file .Rout.save in the vignette source 
directory, the output from running the code in that vignette is compared 
with the target output file."

Yet, there is no pointer on how to get the correct .Rout.save files for 
vignettes. (For the files in directory "test" there is a footnote on how 
to get the .Rout.save files. [2])

As a temporary solution, we currently use a script that calls 
tools:::.run_one_vignette() on each vignette and dumps the output:

echo 'tools:::.run_one_vignette("vignette.Rnw", docDir = ".");' | R 
--vanilla > vignette.Rout.save

However, this doesn't result in the same code as produced by R CMD 
check. E.g., we get the R startup header and furthermore get the output 
in German where localization is available (thus having differences when 
running R CMD check).

Does anyone have any hints on how to automatically get the correct 
results (i.e., without the header)? And is it possible to include these 
hints in the "Writing R extensions" manual for other users?

Any help is highly appreciated.
Best,
    Benjamin

--------------------
[1] http://cran.r-project.org/doc/manuals/R-exts.html#Checking-packages
[2] http://cran.r-project.org/doc/manuals/R-exts.html#fn-15


From murdoch.duncan at gmail.com  Tue Dec 11 14:52:53 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Dec 2012 08:52:53 -0500
Subject: [Rd] Generate .Rout.save files for vignettes
In-Reply-To: <50C611C0.9040700@fau.de>
References: <50C611C0.9040700@fau.de>
Message-ID: <50C73AB5.8050103@gmail.com>

On 12-12-10 11:45 AM, Benjamin Hofner wrote:
> I am looking for a way to generate .Rout.save files for vignettes.
> The manual "Writing R Extensions" states here [1] in item number 20:
>
> "If there is a target output file .Rout.save in the vignette source
> directory, the output from running the code in that vignette is compared
> with the target output file."
>
> Yet, there is no pointer on how to get the correct .Rout.save files for
> vignettes. (For the files in directory "test" there is a footnote on how
> to get the .Rout.save files. [2])

I agree, this should be documented.  But it is rather easy:

Just create an empty file and call it vignette.Rout.save.  Run the 
checks, and you'll get lots of errors because it won't compare to the 
real output.

When you get a compare failure, the file vignette.Rnw.log will be left 
in the *.Rcheck directory.  You can just copy that into the 
vignette.Rout.save file.

Duncan Murdoch

>
> As a temporary solution, we currently use a script that calls
> tools:::.run_one_vignette() on each vignette and dumps the output:
>
> echo 'tools:::.run_one_vignette("vignette.Rnw", docDir = ".");' | R
> --vanilla > vignette.Rout.save
>
> However, this doesn't result in the same code as produced by R CMD
> check. E.g., we get the R startup header and furthermore get the output
> in German where localization is available (thus having differences when
> running R CMD check).
>
> Does anyone have any hints on how to automatically get the correct
> results (i.e., without the header)? And is it possible to include these
> hints in the "Writing R extensions" manual for other users?
>
> Any help is highly appreciated.
> Best,
>      Benjamin
>
> --------------------
> [1] http://cran.r-project.org/doc/manuals/R-exts.html#Checking-packages
> [2] http://cran.r-project.org/doc/manuals/R-exts.html#fn-15
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Dec 11 15:41:18 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2012 14:41:18 +0000
Subject: [Rd] Generate .Rout.save files for vignettes
In-Reply-To: <50C73AB5.8050103@gmail.com>
References: <50C611C0.9040700@fau.de> <50C73AB5.8050103@gmail.com>
Message-ID: <50C7460E.3020104@stats.ox.ac.uk>

But note that this was added at the request of one package author.  We 
don't generally recommended it, not least as people do not take 
sufficient care about platform differences and keeping such output up to 
date.  So people (including authors) tend to simply ignore a mass of 
differences.

It is better to craft tests with controlled output (and chosen number of 
significant digits) if you want to check package printed output.


On 11/12/2012 13:52, Duncan Murdoch wrote:
> On 12-12-10 11:45 AM, Benjamin Hofner wrote:
>> I am looking for a way to generate .Rout.save files for vignettes.
>> The manual "Writing R Extensions" states here [1] in item number 20:
>>
>> "If there is a target output file .Rout.save in the vignette source
>> directory, the output from running the code in that vignette is compared
>> with the target output file."
>>
>> Yet, there is no pointer on how to get the correct .Rout.save files for
>> vignettes. (For the files in directory "test" there is a footnote on how
>> to get the .Rout.save files. [2])
>
> I agree, this should be documented.  But it is rather easy:
>
> Just create an empty file and call it vignette.Rout.save.  Run the
> checks, and you'll get lots of errors because it won't compare to the
> real output.
>
> When you get a compare failure, the file vignette.Rnw.log will be left
> in the *.Rcheck directory.  You can just copy that into the
> vignette.Rout.save file.

You need to watch out for locale differences: make sure you do this in 
an English locale for portability (everyone has one of those, the 'C' 
locale).

>
> Duncan Murdoch
>
>>
>> As a temporary solution, we currently use a script that calls
>> tools:::.run_one_vignette() on each vignette and dumps the output:
>>
>> echo 'tools:::.run_one_vignette("vignette.Rnw", docDir = ".");' | R
>> --vanilla > vignette.Rout.save
>>
>> However, this doesn't result in the same code as produced by R CMD
>> check. E.g., we get the R startup header and furthermore get the output
>> in German where localization is available (thus having differences when
>> running R CMD check).
>>
>> Does anyone have any hints on how to automatically get the correct
>> results (i.e., without the header)? And is it possible to include these
>> hints in the "Writing R extensions" manual for other users?
>>
>> Any help is highly appreciated.
>> Best,
>>      Benjamin
>>
>> --------------------
>> [1] http://cran.r-project.org/doc/manuals/R-exts.html#Checking-packages
>> [2] http://cran.r-project.org/doc/manuals/R-exts.html#fn-15
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From david.c.sterratt at ed.ac.uk  Tue Dec 11 16:13:35 2012
From: david.c.sterratt at ed.ac.uk (David Sterratt)
Date: Tue, 11 Dec 2012 15:13:35 +0000
Subject: [Rd] Catching errors from solve() with near-singular matrices
Message-ID: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>

Dear all,

The background is that I'm trying to fix this bug in the geometry
package:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1993&group_id=1149&atid=4552

Boiled down, the problem is that there exists at least one matrix X for
which det(X) != 0 and for which solve(X) fails giving the error "system
is computationally singular: reciprocal condition number = ..." (see
appended code & attached file). I don't want my function that calls
solve(X) to return an error.

I can think of two strategies for dealing with this problem:

Strategy 1: Some code like this:
   if (det(X) < epsilon) {
      warning("Near singular matrix") 
      return(NULL) 
   }
   return(solve(X))

The problem is then to find what epsilon should be.

Strategy 2: Catch the error thrown by solve(X) like this:

        f <- function(X) {
          invX <- tryCatch(solve(X), error=function(e) {
            warning(e)
            error.flag <<- TRUE})
          if (error.flag) return(NULL)
          return(invX)
        }
        
This works OK if called without a surrounding try() 
        
        ret  <- f(matrix(0, 2, 2))      ## Gives warning
        
However, if I encase the call to f() in a try statement, I get an error: 

        ret1 <- try(f(matrix(0, 2, 2))) ## Gives error "Lapack routine dgesv: system is exactly singular"

This is undesirable.

Advice on how to solve the problem with either strategy would be much
appreciated - as indeed would be a completely different solution.

All the best,

David.

* * *

Code to throw an error in solve():

> X = as.matrix(read.csv("X.csv"))
> det(X)
[1] 2.32721e-21
> solve(X)
Error in solve.default(X) : 
  system is computationally singular: reciprocal condition number = 1.79977e-16


-- 
David C Sterratt, Research Fellow http://homepages.inf.ed.ac.uk/sterratt
Institute for Adaptive and Neural Computation     tel: +44 131 651 1739
School of Informatics, University of Edinburgh    fax: +44 131 650 6899
Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB, Scotland  
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
NEW BOOK: Principles of Computational Modelling in Neuroscience
Sterratt, Graham, Gillies & Willshaw (CUP, 2011).
http://www.compneuroprinciples.org  

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jon.clayden at gmail.com  Tue Dec 11 16:43:27 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Tue, 11 Dec 2012 15:43:27 +0000
Subject: [Rd] Catching errors from solve() with near-singular matrices
In-Reply-To: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>
References: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>
Message-ID: <CAM9CR=2gUVsOJN77DFgsRctOEpnCdH3PwiNFR1QCiTY1uhhpjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121211/c315f1d7/attachment.pl>

From winstonchang1 at gmail.com  Tue Dec 11 18:22:37 2012
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 11 Dec 2012 11:22:37 -0600
Subject: [Rd] Bug in mclapply?
In-Reply-To: <CAFOpNVEg6SNre+=0E4BM=3BoxnjLuGBLqmAxj-STu2RHUWPkmg@mail.gmail.com>
References: <CAFOpNVEg6SNre+=0E4BM=3BoxnjLuGBLqmAxj-STu2RHUWPkmg@mail.gmail.com>
Message-ID: <CAFOpNVHOsxuc4ehzq3DQEJqKBpjQ64qRqi0FzsXJiBHT2eUgJw@mail.gmail.com>

(Sorry for the repeat message; I forgot to send the previous message
in plain text.)

I've been using mclapply and have encountered situations where it
gives errors or returns incorrect results. Here's a minimal example,
which gives the error on R 2.15.2 on Mac and Linux:

library(parallel)
f <- function(x) NULL
mclapply(1, f, mc.preschedule = FALSE, mc.cores = 1)
# Error in sum(sapply(res, inherits, "try-error")) :
#  invalid 'type' (list) of argument


I believe it happens when the following are true:
- The function returns NULL
- mc.preschedule = FALSE
- mc.cores >= length of the input data


Here are some examples I used to trace down the problem.

library(parallel)
f <- function(x) NULL

# Error when mc.preschedule=FALSE and mc.cores >= length(x)
mclapply(1, f, mc.preschedule = FALSE, mc.cores = 1)    # Error
mclapply(1, f, mc.preschedule = FALSE, mc.cores = 2)    # Error
mclapply(1:2, f, mc.preschedule = FALSE, mc.cores = 1)  # OK

# In the following 2 cases, I get an error about 10-20% of the time.
# The other times, the result is worse: it returns a list with only one
# element, not two!
mclapply(1:2, f, mc.preschedule = FALSE, mc.cores = 2)  # Error
mclapply(1:2, f, mc.preschedule = FALSE, mc.cores = 3)  # Error


# When mc.preschedule=TRUE, always works
mclapply(1, f, mc.preschedule = TRUE, mc.cores = 1)    # OK
mclapply(1:2, f, mc.preschedule = TRUE, mc.cores = 1)  # OK
mclapply(1:2, f, mc.preschedule = TRUE, mc.cores = 2)  # OK

# lapply() always works
lapply(1, f)    # OK
lapply(1:2, f)  # OK
lapply(1:2, f)  # OK


# If function returns non-null, it works
g <- function(x) 0
mclapply(1, g, mc.preschedule = FALSE, mc.cores = 1)    # OK
mclapply(1:2, g, mc.preschedule = FALSE, mc.cores = 1)  # OK
mclapply(1:2, g, mc.preschedule = FALSE, mc.cores = 2)  # OK



Digging around in mclapply(), I think it happens because
mccollect(jobs) is returning an empty list. But when I use
options(error=recover) and debug the function, I find that when I call
mccollect(jobs) again, it returns a list with values -- it's as though
mccollect() is returning too early. This will illustrate:

> mclapply(1, f, mc.preschedule = FALSE, mc.cores = 1)
Error in sum(sapply(res, inherits, "try-error")) :
  invalid 'type' (list) of argument

Enter a frame number, or 0 to exit

1: mclapply(1, f, mc.preschedule = FALSE, mc.cores = 1)

Selection: 1
Called from: top level
Browse[1]> res
named list()
Browse[1]> res <- mccollect(jobs)
Browse[1]> res
$`12348`
NULL

The error happens on line 63 of mclapply.r, which is after `res <-
mccollect(jobs)` is called, on line 61. At this point, res should be a
named list with values filled in, but it's empty. When I run `res <-
mccollect(jobs)` again, it gives the correct values.

Is there a good way to work around this issue for now?

-Winston


From murdoch.duncan at gmail.com  Tue Dec 11 18:27:42 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Dec 2012 12:27:42 -0500
Subject: [Rd] Generate .Rout.save files for vignettes
In-Reply-To: <50C7460E.3020104@stats.ox.ac.uk>
References: <50C611C0.9040700@fau.de> <50C73AB5.8050103@gmail.com>
	<50C7460E.3020104@stats.ox.ac.uk>
Message-ID: <50C76D0E.7000609@gmail.com>

On 12-12-11 9:41 AM, Prof Brian Ripley wrote:
> But note that this was added at the request of one package author.  We
> don't generally recommended it, not least as people do not take
> sufficient care about platform differences and keeping such output up to
> date.  So people (including authors) tend to simply ignore a mass of
> differences.
>
> It is better to craft tests with controlled output (and chosen number of
> significant digits) if you want to check package printed output.

This seems like a useful test for a package developer, but maybe not for 
package users (or for CRAN, if the developer wants to work in a 
non-standard locale).

I wonder if there's a way to make it easy to use locally, without 
inconveniencing everyone else?  Perhaps it should simply default to not 
being done, with an environment variable flag set to enable it.

Duncan Murdoch


>
>
> On 11/12/2012 13:52, Duncan Murdoch wrote:
>> On 12-12-10 11:45 AM, Benjamin Hofner wrote:
>>> I am looking for a way to generate .Rout.save files for vignettes.
>>> The manual "Writing R Extensions" states here [1] in item number 20:
>>>
>>> "If there is a target output file .Rout.save in the vignette source
>>> directory, the output from running the code in that vignette is compared
>>> with the target output file."
>>>
>>> Yet, there is no pointer on how to get the correct .Rout.save files for
>>> vignettes. (For the files in directory "test" there is a footnote on how
>>> to get the .Rout.save files. [2])
>>
>> I agree, this should be documented.  But it is rather easy:
>>
>> Just create an empty file and call it vignette.Rout.save.  Run the
>> checks, and you'll get lots of errors because it won't compare to the
>> real output.
>>
>> When you get a compare failure, the file vignette.Rnw.log will be left
>> in the *.Rcheck directory.  You can just copy that into the
>> vignette.Rout.save file.
>
> You need to watch out for locale differences: make sure you do this in
> an English locale for portability (everyone has one of those, the 'C'
> locale).
>
>>
>> Duncan Murdoch
>>
>>>
>>> As a temporary solution, we currently use a script that calls
>>> tools:::.run_one_vignette() on each vignette and dumps the output:
>>>
>>> echo 'tools:::.run_one_vignette("vignette.Rnw", docDir = ".");' | R
>>> --vanilla > vignette.Rout.save
>>>
>>> However, this doesn't result in the same code as produced by R CMD
>>> check. E.g., we get the R startup header and furthermore get the output
>>> in German where localization is available (thus having differences when
>>> running R CMD check).
>>>
>>> Does anyone have any hints on how to automatically get the correct
>>> results (i.e., without the header)? And is it possible to include these
>>> hints in the "Writing R extensions" manual for other users?
>>>
>>> Any help is highly appreciated.
>>> Best,
>>>       Benjamin
>>>
>>> --------------------
>>> [1] http://cran.r-project.org/doc/manuals/R-exts.html#Checking-packages
>>> [2] http://cran.r-project.org/doc/manuals/R-exts.html#fn-15
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Tue Dec 11 19:23:52 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2012 18:23:52 +0000
Subject: [Rd] Generate .Rout.save files for vignettes
In-Reply-To: <50C76D0E.7000609@gmail.com>
References: <50C611C0.9040700@fau.de> <50C73AB5.8050103@gmail.com>
	<50C7460E.3020104@stats.ox.ac.uk> <50C76D0E.7000609@gmail.com>
Message-ID: <50C77A38.7000604@stats.ox.ac.uk>

On 11/12/2012 17:27, Duncan Murdoch wrote:
> On 12-12-11 9:41 AM, Prof Brian Ripley wrote:
>> But note that this was added at the request of one package author.  We
>> don't generally recommended it, not least as people do not take
>> sufficient care about platform differences and keeping such output up to
>> date.  So people (including authors) tend to simply ignore a mass of
>> differences.
>>
>> It is better to craft tests with controlled output (and chosen number of
>> significant digits) if you want to check package printed output.
>
> This seems like a useful test for a package developer, but maybe not for
> package users (or for CRAN, if the developer wants to work in a
> non-standard locale).
>
> I wonder if there's a way to make it easy to use locally, without
> inconveniencing everyone else?  Perhaps it should simply default to not
> being done, with an environment variable flag set to enable it.

What I do (and CRAN recommends for author-mode tests) is to have such a 
.save file excluded by .Rbuildignore.

>
> Duncan Murdoch
>
>
>>
>>
>> On 11/12/2012 13:52, Duncan Murdoch wrote:
>>> On 12-12-10 11:45 AM, Benjamin Hofner wrote:
>>>> I am looking for a way to generate .Rout.save files for vignettes.
>>>> The manual "Writing R Extensions" states here [1] in item number 20:
>>>>
>>>> "If there is a target output file .Rout.save in the vignette source
>>>> directory, the output from running the code in that vignette is
>>>> compared
>>>> with the target output file."
>>>>
>>>> Yet, there is no pointer on how to get the correct .Rout.save files for
>>>> vignettes. (For the files in directory "test" there is a footnote on
>>>> how
>>>> to get the .Rout.save files. [2])
>>>
>>> I agree, this should be documented.  But it is rather easy:
>>>
>>> Just create an empty file and call it vignette.Rout.save.  Run the
>>> checks, and you'll get lots of errors because it won't compare to the
>>> real output.
>>>
>>> When you get a compare failure, the file vignette.Rnw.log will be left
>>> in the *.Rcheck directory.  You can just copy that into the
>>> vignette.Rout.save file.
>>
>> You need to watch out for locale differences: make sure you do this in
>> an English locale for portability (everyone has one of those, the 'C'
>> locale).
>>
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> As a temporary solution, we currently use a script that calls
>>>> tools:::.run_one_vignette() on each vignette and dumps the output:
>>>>
>>>> echo 'tools:::.run_one_vignette("vignette.Rnw", docDir = ".");' | R
>>>> --vanilla > vignette.Rout.save
>>>>
>>>> However, this doesn't result in the same code as produced by R CMD
>>>> check. E.g., we get the R startup header and furthermore get the output
>>>> in German where localization is available (thus having differences when
>>>> running R CMD check).
>>>>
>>>> Does anyone have any hints on how to automatically get the correct
>>>> results (i.e., without the header)? And is it possible to include these
>>>> hints in the "Writing R extensions" manual for other users?
>>>>
>>>> Any help is highly appreciated.
>>>> Best,
>>>>       Benjamin
>>>>
>>>> --------------------
>>>> [1] http://cran.r-project.org/doc/manuals/R-exts.html#Checking-packages
>>>> [2] http://cran.r-project.org/doc/manuals/R-exts.html#fn-15
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From MEC at stowers.org  Tue Dec 11 21:14:44 2012
From: MEC at stowers.org (Cook, Malcolm)
Date: Tue, 11 Dec 2012 14:14:44 -0600
Subject: [Rd] library(tcltk) v. SIGPIPE BUG (?!?)
Message-ID: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>

Hi R-devel, tcltk devel, and sqldf devel,

The transcript below shows how loading the tcl/tk library in under R causes subprocesses to ignore SIGPIPE.

I am including the developer of the (wonderful) sqldf package since it requires tcltk and you might like to make this dependence optional to the user (at least until this is fixed in tcltk).

Am I mistaken in calling this a 'bug'?

Any insights appreciated!

Thanks,

Malcolm Cook
Computational Biology - Stowers Institute for Medical Research


> system(intern=TRUE,'yes | head ')
 [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
> library(tcltk)
Loading Tcl/Tk interface ... done
> system(intern=TRUE,'yes | head ')

### this now does not return to the prompt and Looking at 'top' shows that 'yes' is running until I hit ctrl-c, after which it returns.
C-c C-c
  [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"


> sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base     
>


From ggrothendieck at gmail.com  Tue Dec 11 21:39:41 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Dec 2012 15:39:41 -0500
Subject: [Rd] library(tcltk) v. SIGPIPE BUG (?!?)
In-Reply-To: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>
References: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>
Message-ID: <CAP01uRn4fwmxpMwNEJ+E9AgkyQjBVPZxhx-=2BVH-+_BgYfYXA@mail.gmail.com>

On Tue, Dec 11, 2012 at 3:14 PM, Cook, Malcolm <MEC at stowers.org> wrote:
> Hi R-devel, tcltk devel, and sqldf devel,
>
> The transcript below shows how loading the tcl/tk library in under R causes subprocesses to ignore SIGPIPE.
>
> I am including the developer of the (wonderful) sqldf package since it requires tcltk and you might like to make this dependence optional to the user (at least until this is fixed in tcltk).
>
> Am I mistaken in calling this a 'bug'?
>
> Any insights appreciated!
>
> Thanks,
>
> Malcolm Cook
> Computational Biology - Stowers Institute for Medical Research
>
>
>> system(intern=TRUE,'yes | head ')
>  [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
>> library(tcltk)
> Loading Tcl/Tk interface ... done
>> system(intern=TRUE,'yes | head ')
>
> ### this now does not return to the prompt and Looking at 'top' shows that 'yes' is running until I hit ctrl-c, after which it returns.
> C-c C-c
>   [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
>
>
>> sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base
>>
>
>

As a workaround specify the "R" engine instead of the "tcl" engine in
wihch case gsubfn (which is called by sqldf) won't try to use the
tcltk package:

options(gsubfn.engine = "R")
library(sqldf)



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From MEC at stowers.org  Tue Dec 11 23:50:58 2012
From: MEC at stowers.org (Cook, Malcolm)
Date: Tue, 11 Dec 2012 16:50:58 -0600
Subject: [Rd] library(tcltk) v. SIGPIPE BUG (?!?)
In-Reply-To: <CAP01uRn4fwmxpMwNEJ+E9AgkyQjBVPZxhx-=2BVH-+_BgYfYXA@mail.gmail.com>
References: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>
	<CAP01uRn4fwmxpMwNEJ+E9AgkyQjBVPZxhx-=2BVH-+_BgYfYXA@mail.gmail.com>
Message-ID: <2C40E43D1F7A56408C4463FD245DDDF90790E16BFE@EXCHMB-02.stowers-institute.org>

Excellent, thanks for the workaround, that gets _me_ by, for now.....

~Malcolm


> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Tuesday, December 11, 2012 2:40 PM
> To: Cook, Malcolm
> Cc: r-discussion at listserv.stowers.org; r-devel at r-project.org; phgrosjean at sciviews.org; Blanchette, Marco
> Subject: Re: library(tcltk) v. SIGPIPE BUG (?!?)
> 
> On Tue, Dec 11, 2012 at 3:14 PM, Cook, Malcolm <MEC at stowers.org> wrote:
> > Hi R-devel, tcltk devel, and sqldf devel,
> >
> > The transcript below shows how loading the tcl/tk library in under R causes subprocesses to ignore SIGPIPE.
> >
> > I am including the developer of the (wonderful) sqldf package since it requires tcltk and you might like to make this dependence
> optional to the user (at least until this is fixed in tcltk).
> >
> > Am I mistaken in calling this a 'bug'?
> >
> > Any insights appreciated!
> >
> > Thanks,
> >
> > Malcolm Cook
> > Computational Biology - Stowers Institute for Medical Research
> >
> >
> >> system(intern=TRUE,'yes | head ')
> >  [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
> >> library(tcltk)
> > Loading Tcl/Tk interface ... done
> >> system(intern=TRUE,'yes | head ')
> >
> > ### this now does not return to the prompt and Looking at 'top' shows that 'yes' is running until I hit ctrl-c, after which it returns.
> > C-c C-c
> >   [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
> >
> >
> >> sessionInfo()
> > R version 2.15.1 (2012-06-22)
> > Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> >
> > locale:
> > [1] C
> >
> > attached base packages:
> > [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base
> >>
> >
> >
> 
> As a workaround specify the "R" engine instead of the "tcl" engine in
> wihch case gsubfn (which is called by sqldf) won't try to use the
> tcltk package:
> 
> options(gsubfn.engine = "R")
> library(sqldf)
> 
> 
> 
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From pdalgd at gmail.com  Wed Dec 12 08:45:35 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 12 Dec 2012 08:45:35 +0100
Subject: [Rd] library(tcltk) v. SIGPIPE BUG (?!?)
In-Reply-To: <2C40E43D1F7A56408C4463FD245DDDF90790E16BFE@EXCHMB-02.stowers-institute.org>
References: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>
	<CAP01uRn4fwmxpMwNEJ+E9AgkyQjBVPZxhx-=2BVH-+_BgYfYXA@mail.gmail.com>
	<2C40E43D1F7A56408C4463FD245DDDF90790E16BFE@EXCHMB-02.stowers-institute.org>
Message-ID: <B43D742C-90BC-41E7-BDD7-9FD29AE06028@gmail.com>


On Dec 11, 2012, at 23:50 , Cook, Malcolm wrote:

> Excellent, thanks for the workaround, that gets _me_ by, for now.....

The real issue is probably yet another symptom of something that can be described as insufficient separation between the R engine and its GUI components. Or: One process trying to serve two masters. It is not fixable overnight, but some of us (me, at least) try to find time to get a handle on it. My take is that it is necessary to set things up as separate threads or processes and define the interface via some sort of message-passing protocol.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Wed Dec 12 09:02:57 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Dec 2012 09:02:57 +0100
Subject: [Rd] library(tcltk) v. SIGPIPE BUG (?!?)
In-Reply-To: <2C40E43D1F7A56408C4463FD245DDDF90790E16BFE@EXCHMB-02.stowers-institute.org>
References: <2C40E43D1F7A56408C4463FD245DDDF90790E16BC1@EXCHMB-02.stowers-institute.org>
	<CAP01uRn4fwmxpMwNEJ+E9AgkyQjBVPZxhx-=2BVH-+_BgYfYXA@mail.gmail.com>
	<2C40E43D1F7A56408C4463FD245DDDF90790E16BFE@EXCHMB-02.stowers-institute.org>
Message-ID: <20680.14897.269920.627534@stat.math.ethz.ch>

>>>>> "CM" == Cook, Malcolm <MEC at stowers.org>
>>>>>     on Tue, 11 Dec 2012 16:50:58 -0600 writes:

    CM> Excellent, thanks for the workaround, that gets _me_ by, for now.....
    CM> ~Malcolm


    >> -----Original Message-----
    >> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
    >> Sent: Tuesday, December 11, 2012 2:40 PM
    >> To: Cook, Malcolm
    >> Cc: r-discussion at listserv.stowers.org; r-devel at r-project.org; phgrosjean at sciviews.org; Blanchette, Marco
    >> Subject: Re: library(tcltk) v. SIGPIPE BUG (?!?)
    >> 
    >> On Tue, Dec 11, 2012 at 3:14 PM, Cook, Malcolm <MEC at stowers.org> wrote:
    >> > Hi R-devel, tcltk devel, and sqldf devel,
    >> >
    >> > The transcript below shows how loading the tcl/tk library in under R causes subprocesses to ignore SIGPIPE.
    >> >
    >> > I am including the developer of the (wonderful) sqldf package since it requires tcltk and you might like to make this dependence
    >> optional to the user (at least until this is fixed in tcltk).
    >> >
    >> > Am I mistaken in calling this a 'bug'?

well, at least an unfortunate feature ;-)

    >> > Any insights appreciated!

Could it be that the problem in the severity you've reported it,
is  Mac specific ?

For me, on Linux (R 2.15.2 patched):

    > system(intern=TRUE,'yes | head ')
     [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"

    > require(tcltk)
    Loading required package: tcltk
    Loading Tcl/Tk interface ... done
    > system(intern=TRUE,'yes | head ')
    yes: standard output: Broken pipe
    yes: write error
     [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
    > system(intern=TRUE,'yes | head ')
    yes: standard output: Broken pipe
    yes: write error
     [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
    > system(intern=TRUE,'yes | head -6 ')
    yes: standard output: Broken pipe
    yes: write error
    [1] "y" "y" "y" "y" "y" "y"

So things continue to  ``work'' there, 
although with the extra "warning" messages.


    >> >
    >> > Thanks,
    >> >
    >> > Malcolm Cook
    >> > Computational Biology - Stowers Institute for Medical Research
    >> >
    >> >
    >> >> system(intern=TRUE,'yes | head ')
    >> >  [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
    >> >> library(tcltk)
    >> > Loading Tcl/Tk interface ... done
    >> >> system(intern=TRUE,'yes | head ')
    >> >
    >> > ### this now does not return to the prompt and Looking at 'top' shows that 'yes' is running until I hit ctrl-c, after which it returns.
    >> > C-c C-c
    >> >   [1] "y" "y" "y" "y" "y" "y" "y" "y" "y" "y"
    >> >
    >> >
    >> >> sessionInfo()
    >> > R version 2.15.1 (2012-06-22)
    >> > Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
    >> >
    >> > locale:
    >> > [1] C
    >> >
    >> > attached base packages:
    >> > [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base
    >> >>
    >> >
    >> >
    >> 
    >> As a workaround specify the "R" engine instead of the "tcl" engine in
    >> wihch case gsubfn (which is called by sqldf) won't try to use the
    >> tcltk package:
    >> 
    >> options(gsubfn.engine = "R")
    >> library(sqldf)
    >> 
    >> 
    >> 
    >> --
    >> Statistics & Software Consulting
    >> GKX Group, GKX Associates Inc.
    >> tel: 1-877-GKX-GROUP
    >> email: ggrothendieck at gmail.com

    CM> ______________________________________________
    CM> R-devel at r-project.org mailing list
    CM> https://stat.ethz.ch/mailman/listinfo/r-devel


From bodenhofer at bioinf.jku.at  Tue Dec 11 15:39:45 2012
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Tue, 11 Dec 2012 15:39:45 +0100
Subject: [Rd] Strange, most probably unjustified,
 codoc mismatch for S4 method with one argument plus '...'
Message-ID: <50C745B1.4030606@bioinf.jku.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121211/c80d3706/attachment.pl>

From thibaut.lamadon at gmail.com  Tue Dec 11 20:24:02 2012
From: thibaut.lamadon at gmail.com (Thibaut Lamadon)
Date: Tue, 11 Dec 2012 19:24:02 +0000
Subject: [Rd] Error when overloading + operator in R S4 class and using
	Matrix package
Message-ID: <CAEPk4KeCfKe45T0NHzA5=kqcvnT+afnroP4s-A0iHT4=GkLd4g@mail.gmail.com>

Dear all,

I get a weird effect when trying to overload the + operator and using
the Matrix package with sparse matrices. I first define a very simple
class that does not use the Matrix package but has a + operator. I
then sum two sparse matrices. The first M+M addition delivers the
expected result but the second throws an error. Here is a very simple
code that generates the error:

require(Matrix)
setClass("TestM",representation(M='numeric'))
setMethod("initialize", "TestM", function(.Object,x) {
  .Object at M = x
  .Object
})
setMethod("+", c("TestM","TestM"), function(e1,e2) {
  e1 at M + e2 at M
})

M = Matrix(diag(1:10),sparse=T)
M+M  # > FINE
M+M  # > ERROR

M = Matrix(diag(1:10),sparse=F)
M+M  # > FINE
M+M  # > FINE

The second addition throws the following error:

Error in forceSymmetric(callGeneric(as(e1, "dgCMatrix"), as(e2, "dgCMatrix"))) :
  error in evaluating the argument 'x' in selecting a method for function
'forceSymmetric': Error in .Arith.Csparse(e1, e2, .Generic, class. =
"dgCMatrix") :
  object '.Generic' not found

And the error does not happen if the matrices are not sparse. Is there
some interference between the+ I define and the + for sparseMatrix ?
Do I not define the + operator correctly?

I posted this on stackoverflow and was advised to ask here if this
might be an S4 bug.

Thank you very much,

t.


From ravi.varadhan at jhu.edu  Tue Dec 11 16:46:09 2012
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 11 Dec 2012 15:46:09 +0000
Subject: [Rd] Catching errors from solve() with near-singular matrices
In-Reply-To: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>
References: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3317B34@DOM-EB-MAIL1.win.ad.jhu.edu>

I am not sure that this query is appropriate for r-devel, it seems to be more appropriate for r-help.

In any case,  you might want to try MASS::ginv instead of solve(), if you expect ill-conditioning.  Here is one possible solution:

        f <- function(X) {
          invX <- tryCatch(ginv(X, tol=.Machine$double.eps), error=function(e) {
            warning(e)
            error.flag <- TRUE})  # you should avoid the global assignment `<<-' 
          if (error.flag) return(NULL)
          return(invX)
        }

      n <- 14
        A <- matrix(NA, n, n)
for (i in 1:n) for (j in 1:n) A[i,j] <- 1/(i+j-1)

ret  <- f(A)               
ret1 <- try(f(A)) 

Hope this helps,
Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of David Sterratt
Sent: Tuesday, December 11, 2012 10:14 AM
To: r-devel at r-project.org
Subject: [Rd] Catching errors from solve() with near-singular matrices

Dear all,

The background is that I'm trying to fix this bug in the geometry
package:
https://r-forge.r-project.org/tracker/index.php?func=detail&aid=1993&group_id=1149&atid=4552

Boiled down, the problem is that there exists at least one matrix X for which det(X) != 0 and for which solve(X) fails giving the error "system is computationally singular: reciprocal condition number = ..." (see appended code & attached file). I don't want my function that calls
solve(X) to return an error.

I can think of two strategies for dealing with this problem:

Strategy 1: Some code like this:
   if (det(X) < epsilon) {
      warning("Near singular matrix") 
      return(NULL) 
   }
   return(solve(X))

The problem is then to find what epsilon should be.

Strategy 2: Catch the error thrown by solve(X) like this:

        f <- function(X) {
          invX <- tryCatch(solve(X), error=function(e) {
            warning(e)
            error.flag <<- TRUE})
          if (error.flag) return(NULL)
          return(invX)
        }
        
This works OK if called without a surrounding try() 
        
        ret  <- f(matrix(0, 2, 2))      ## Gives warning
        
However, if I encase the call to f() in a try statement, I get an error: 

        ret1 <- try(f(matrix(0, 2, 2))) ## Gives error "Lapack routine dgesv: system is exactly singular"

This is undesirable.

Advice on how to solve the problem with either strategy would be much appreciated - as indeed would be a completely different solution.

All the best,

David.

* * *

Code to throw an error in solve():

> X = as.matrix(read.csv("X.csv"))
> det(X)
[1] 2.32721e-21
> solve(X)
Error in solve.default(X) : 
  system is computationally singular: reciprocal condition number = 1.79977e-16


--
David C Sterratt, Research Fellow http://homepages.inf.ed.ac.uk/sterratt
Institute for Adaptive and Neural Computation     tel: +44 131 651 1739
School of Informatics, University of Edinburgh    fax: +44 131 650 6899
Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB, Scotland
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * NEW BOOK: Principles of Computational Modelling in Neuroscience Sterratt, Graham, Gillies & Willshaw (CUP, 2011).
http://www.compneuroprinciples.org  

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336.


From david.c.sterratt at ed.ac.uk  Wed Dec 12 12:14:30 2012
From: david.c.sterratt at ed.ac.uk (David Sterratt)
Date: Wed, 12 Dec 2012 11:14:30 +0000
Subject: [Rd] Catching errors from solve() with near-singular matrices
In-Reply-To: <CAM9CR=2gUVsOJN77DFgsRctOEpnCdH3PwiNFR1QCiTY1uhhpjg@mail.gmail.com>
References: <1355238815.25539.5588.camel@bonnington.inf.ed.ac.uk>
	<CAM9CR=2gUVsOJN77DFgsRctOEpnCdH3PwiNFR1QCiTY1uhhpjg@mail.gmail.com>
Message-ID: <1355310870.25539.6382.camel@bonnington.inf.ed.ac.uk>

Dear all,

many thanks to Jon & Ravi for their help on this, and apologies if
r-help would have been a more appropriate forum.

On Tue, 2012-12-11 at 15:43 +0000, Jon Clayden wrote:

>       Strategy 1: Some code like this:
>            if (det(X) < epsilon) {
>               warning("Near singular matrix")
>               return(NULL)
>            }
>            return(solve(X))
>
> This solution is probably the easiest one to take, but to match
> solve.default, the test should be
>
>   if (rcond(X) < .Machine$double.eps)
>
> Catching that case should avoid the error. I hope this helps.

Yes, that works well.

On Tue, 2012-12-11 at 15:46 +0000, Ravi Varadhan wrote:
> In any case,  you might want to try MASS::ginv instead of solve(), if
> you expect ill-conditioning.  Here is one possible solution:
> 
>         f <- function(X) {
>           invX <- tryCatch(ginv(X, tol=.Machine$double.eps),
> error=function(e) {
>             warning(e)
>             error.flag <- TRUE})  # you should avoid the global
> assignment `<<-' 
>           if (error.flag) return(NULL)
>           return(invX)
>         }

I'll try this if any problems do emerge with the above solution. One
small point: I used <<- because there seemed to be no other way of
returning from the function f if an error had been thrown by ginv() (or
solve()):

> flag <- FALSE
> tryCatch(stop(), error=function(e) {flag <- TRUE})
> flag
[1] FALSE
> tryCatch(stop(), error=function(e) {flag <<- TRUE})
> flag
[1] TRUE

I feel sure that there must be a more elegant way of doing this!

David.

-- 
David C Sterratt, Research Fellow http://homepages.inf.ed.ac.uk/sterratt
Institute for Adaptive and Neural Computation     tel: +44 131 651 1739
School of Informatics, University of Edinburgh    fax: +44 131 650 6899
Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB, Scotland  
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
NEW BOOK: Principles of Computational Modelling in Neuroscience
Sterratt, Graham, Gillies & Willshaw (CUP, 2011).
http://www.compneuroprinciples.org  


The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pauljohn32 at gmail.com  Wed Dec 12 19:14:54 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 12 Dec 2012 12:14:54 -0600
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
Message-ID: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>

Speaking of optimization and speeding up R calculations...

I mentioned last week I want to speed up calculation of generalized
inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
souped up generalized inverse algorithm published by

V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
matrix, Electronic Journal of Linear Algebra,
17(2008), 637-650.

I was so delighted to see the computation time drop on my Debian
system that I boasted to the WIndows users and gave them a test case.
They answered back "there's no benefits, plus Windows is faster than
Linux".

That sent me off on a bit of a goose chase, but I think I'm beginning
to understand the situation.  I believe R-2.15.2 introduced a tighter
requirement for precision, thus triggering longer-lasting calculations
in many example scripts. Better algorithms can avoid some of that
slowdown, as you see in this test case.

Here is the test code you can run to see:

http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R

It downloads a data file from that same directory and then runs some
multiple imputations with the Amelia package.

Here's the output from my computer

http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout

That includes the profile of the calculations that depend on the
ordinary generalized inverse algorithm based on svd and the new one.

See? The KP algorithm is faster.  And just as accurate as
Amelia:::mpinv or MASS::ginv (for details on that, please review my
notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).

So I asked WIndows users for more detailed feedback, including
sessionInfo(), and I noticed that my proposed algorithm is not faster
on Windows--WITH OLD R!

Here's the script output with R-2.15.0, shows no speedup from the
KPginv algorithm

http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout

On the same machine, I updated to R-2.15.2, and we see the same
speedup from the KPginv algorithm

http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout

After that, I realized it is an R version change, not an OS
difference, I was a bit relieved.

What causes the difference in this case?  In the Amelia code, they try
to avoid doing the generalized inverse by using the ordinary solve(),
and if that fails, then they do the generalized inverse. In R 2.15.0,
the near singularity of the matrix is ignored, but not in R 2.15.2.
The ordinary solve is failing almost all the time, thus triggering the
use of the svd based generalized inverse.  Which is slower.

The Katsikis and Pappas 2008 algorithm is the fastest one I've found
after translating from Matlab to R.  It is not so universally
applicable as svd based methods, it will fail if there are linearly
dependent columns. However, it does tolerate columns of all zeros,
which seems to be the problem case in the particular application I am
testing.

I tried very hard to get the newer algorithm described here to go as
fast, but it is way way slower, at least in the implementations I
tried:
##  KPP
## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
improved method for
## the computation of the Moore Penrose inverse matrix," Applied
## Mathematics and Computation, 2011

The notes on that are in the qrginv.R file linked above.

The fact that I can't make that newer KPP algorithm go faster,
although the authors show it can go faster in Matlab, leads me to a
bunch of other questions and possibly the need to implement all of
this in C with LAPACK or EIGEN or something like that, but at this
point, I've got to return to my normal job.  If somebody is good at
R's .Call interface and can make a pure C implementation of KPP.

I think the key thing is that with R-2.15.2, there is an svd-related
bottleneck in the multiple imputation algorithms in Amelia. The
replacement version of the function Amelia:::mpinv does reclaim a 30%
time saving, while generating imputations that are identical, so far
as i can tell.

pj



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From pgilbert902 at gmail.com  Wed Dec 12 19:33:25 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 12 Dec 2012 13:33:25 -0500
Subject: [Rd] =?windows-1252?q?SystemRequirements=92_field?=
Message-ID: <50C8CDF5.3020401@gmail.com>

Am I correct in thinking that the ?SystemRequirements? field in a 
package DESCRIPTION file is purely descriptive, there are no standard 
elements that can be extracted by parsing it and used automatically?

This field does not seem to be widely used, even for some obvious cases 
like backend database driver requirements, perl, perl modules, etc.
It might help to have a list of possibilities. Some I think about 
immediately are SQLLite, MySQL, PostgreSQL, ODBC, Perl, Perl_CSVXS,
MPI, rpcgen, Oracle-license,  Bloomberg-license and Fame-license.
Maybe there could be a generic OTHER_* for things not in a standard list?

Paul


From ripley at stats.ox.ac.uk  Wed Dec 12 20:19:06 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2012 19:19:06 +0000
Subject: [Rd] =?windows-1252?q?SystemRequirements=92_field?=
In-Reply-To: <50C8CDF5.3020401@gmail.com>
References: <50C8CDF5.3020401@gmail.com>
Message-ID: <50C8D8AA.7010701@stats.ox.ac.uk>

On 12/12/2012 18:33, Paul Gilbert wrote:
> Am I correct in thinking that the ?SystemRequirements? field in a
> package DESCRIPTION file is purely descriptive, there are no standard
> elements that can be extracted by parsing it and used automatically?

No.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert902 at gmail.com  Wed Dec 12 20:55:07 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 12 Dec 2012 14:55:07 -0500
Subject: [Rd] =?windows-1252?q?SystemRequirements=92_field?=
In-Reply-To: <50C8D8AA.7010701@stats.ox.ac.uk>
References: <50C8CDF5.3020401@gmail.com> <50C8D8AA.7010701@stats.ox.ac.uk>
Message-ID: <50C8E11B.6030106@gmail.com>



On 12-12-12 02:19 PM, Prof Brian Ripley wrote:
> On 12/12/2012 18:33, Paul Gilbert wrote:
>> Am I correct in thinking that the ?SystemRequirements? field in a
>> package DESCRIPTION file is purely descriptive, there are no standard
>> elements that can be extracted by parsing it and used automatically?
>
> No.
>

Where can I find more details?  The section "The DESCRIPTION file" in 
"Writing R Extensions" says only:

    Other dependencies (external to the R system) should be listed in
    the ?SystemRequirements? field, possibly amplified in a separate
    README file.

Thanks,
Paul


From b.rowlingson at lancaster.ac.uk  Thu Dec 13 00:05:20 2012
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 12 Dec 2012 23:05:20 +0000
Subject: [Rd] =?windows-1252?q?SystemRequirements=92_field?=
In-Reply-To: <47ce74456609465db2defc7d092c681f@EX-0-HT0.lancs.local>
References: <50C8CDF5.3020401@gmail.com> <50C8D8AA.7010701@stats.ox.ac.uk>
	<47ce74456609465db2defc7d092c681f@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPo_Es28rN9JH+4EHqgnnrDyHfkkC0_JYbgqcLAr1Zx_Q@mail.gmail.com>

I see three references to systemRequirements in Writing R Extensions.
The one you list in your last email, this one:

"If your package requires one of these interpreters or an extension
then this should be declared in the ?SystemRequirements? field of its
DESCRIPTION file." [for listing interpreters to run scripts]

and

"If you really must assume GNU make, declare it in the DESCRIPTON file by

          SystemRequirements: GNU make"

A grep of a complete R 2.15-2 source tree doesn't show it being used
either. It's mentioned in the OONEWS file for R 1.7.0

"It is now recommended to use the 'SystemRequirements:' field in the
DESCRIPTION file for specifying dependencies external to the R
system."

Grepping all the DESCRIPTION files on my work box shows such values
for that field as:

"GRASS (>=6.3)"
"An ODBC3 driver manager and drivers"
"libxml2 (>=2.6.3)"
"OpenGL, GLU Library, zlib (optional), libpng)
"for building from source: GDAL >= 1.6.0 library"

some of which look pretty free-form descriptive to me.

Hope that's a bit more useful than 'No'.

On Wed, Dec 12, 2012 at 7:55 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>
> On 12-12-12 02:19 PM, Prof Brian Ripley wrote:
>> On 12/12/2012 18:33, Paul Gilbert wrote:
>>> Am I correct in thinking that the ?SystemRequirements? field in a
>>> package DESCRIPTION file is purely descriptive, there are no standard
>>> elements that can be extracted by parsing it and used automatically?
>>
>> No.
>>
>
> Where can I find more details?  The section "The DESCRIPTION file" in
> "Writing R Extensions" says only:
>
>     Other dependencies (external to the R system) should be listed in
>     the ?SystemRequirements? field, possibly amplified in a separate
>     README file.
>
> Thanks,
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Thu Dec 13 01:32:10 2012
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 12 Dec 2012 16:32:10 -0800
Subject: [Rd] bug in sort.list(method="radix)
Message-ID: <50C9220A.1090007@fhcrc.org>

Hi,

The man page for sort.list says:

   Method ?"radix"? is only implemented for integer ?x? with a range
   of less than 100,000.

but actually:

   > sort.list(c(4L, -5L), method="radix")
   Error in sort.list(c(4L, -5L), method = "radix") : negative value
   in 'x'

Implementation bug or documentation bug?

Here is an old post more or less related to this:

   https://stat.ethz.ch/pipermail/r-devel/2011-February/060000.html

Thanks,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From suharto_anggono at yahoo.com  Thu Dec 13 08:24:51 2012
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 12 Dec 2012 23:24:51 -0800 (PST)
Subject: [Rd] Suggestion of change to reduce overhead of 'table'
Message-ID: <1355383491.88939.YahooMailClassic@web125105.mail.ne1.yahoo.com>

In R 2.7.2, if argument 'exclude' is not specified and input is already a factor, function 'table' uses the input as is. In R 2.15.2, in the same case, function 'table' always applies function 'factor' to the input. The time spent by 'factor' is not long, but is not negligible.


I suggest to change 'table' so that 'factor' is not called for input that is already a factor when it is known that the resulting levels is as in the input. This is diff against https://svn.r-project.org/R/trunk/src/library/base/R/table.R.

85c85,88
<? ? ? ? ? ? ? ? ? ? ? ???a <- factor(a, levels = ll[!(ll %in% exclude)],
---
>? ? ? ? ? ? ? ? ? ? ? ???llexcl <- ll %in% exclude
>? ? ? ? ? ? ? ? ? ? ? ???if (any(llexcl) ||
>? ? ? ? ? ? ? ? ? ? ? ???(useNA == "no" && any(is.na(ll))))
>? ? ? ? ? ? ? ? ? ? ? ? ? ???factor(a, levels = ll[!llexcl],
86a90,91
>? ? ? ? ? ? ? ? ? ? ? ???else
>? ? ? ? ? ? ? ? ? ? ? ? ? ???a


Function 'table' calls function 'addNA' in some cases. I suggest to change 'addNA', too. This is diff against https://svn.r-project.org/R/trunk/src/library/base/R/factor.R.

336d335
<? ???if (ifany & !any(is.na(x))) return(x)
338c337,339
<? ???if (!any(is.na(ll))) ll <- c(ll, NA)
---
>? ???hasNAlev <- any(is.na(ll))
>? ???if ((ifany || hasNAlev) && !any(is.na(x))) return(x)
>? ???if (!hasNAlev) ll <- c(ll, NA)


Instead of calling 'factor', 'addNA' can also change "levels" attribute and accordingly fill missing value in internal code of the factor.


From ligges at statistik.tu-dortmund.de  Thu Dec 13 10:33:46 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 13 Dec 2012 10:33:46 +0100
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
Message-ID: <50C9A0FA.9090501@statistik.tu-dortmund.de>

Long message, but as far as I can see, this is not about base R but the 
contributed package Amelia: Please discuss possible improvements with 
its maintainer.

Best,
Uwe Ligges


On 12.12.2012 19:14, Paul Johnson wrote:
> Speaking of optimization and speeding up R calculations...
>
> I mentioned last week I want to speed up calculation of generalized
> inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
> souped up generalized inverse algorithm published by
>
> V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
> matrix, Electronic Journal of Linear Algebra,
> 17(2008), 637-650.
>
> I was so delighted to see the computation time drop on my Debian
> system that I boasted to the WIndows users and gave them a test case.
> They answered back "there's no benefits, plus Windows is faster than
> Linux".
>
> That sent me off on a bit of a goose chase, but I think I'm beginning
> to understand the situation.  I believe R-2.15.2 introduced a tighter
> requirement for precision, thus triggering longer-lasting calculations
> in many example scripts. Better algorithms can avoid some of that
> slowdown, as you see in this test case.
>
> Here is the test code you can run to see:
>
> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R
>
> It downloads a data file from that same directory and then runs some
> multiple imputations with the Amelia package.
>
> Here's the output from my computer
>
> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout
>
> That includes the profile of the calculations that depend on the
> ordinary generalized inverse algorithm based on svd and the new one.
>
> See? The KP algorithm is faster.  And just as accurate as
> Amelia:::mpinv or MASS::ginv (for details on that, please review my
> notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).
>
> So I asked WIndows users for more detailed feedback, including
> sessionInfo(), and I noticed that my proposed algorithm is not faster
> on Windows--WITH OLD R!
>
> Here's the script output with R-2.15.0, shows no speedup from the
> KPginv algorithm
>
> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout
>
> On the same machine, I updated to R-2.15.2, and we see the same
> speedup from the KPginv algorithm
>
> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout
>
> After that, I realized it is an R version change, not an OS
> difference, I was a bit relieved.
>
> What causes the difference in this case?  In the Amelia code, they try
> to avoid doing the generalized inverse by using the ordinary solve(),
> and if that fails, then they do the generalized inverse. In R 2.15.0,
> the near singularity of the matrix is ignored, but not in R 2.15.2.
> The ordinary solve is failing almost all the time, thus triggering the
> use of the svd based generalized inverse.  Which is slower.
>
> The Katsikis and Pappas 2008 algorithm is the fastest one I've found
> after translating from Matlab to R.  It is not so universally
> applicable as svd based methods, it will fail if there are linearly
> dependent columns. However, it does tolerate columns of all zeros,
> which seems to be the problem case in the particular application I am
> testing.
>
> I tried very hard to get the newer algorithm described here to go as
> fast, but it is way way slower, at least in the implementations I
> tried:
> ##  KPP
> ## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
> improved method for
> ## the computation of the Moore Penrose inverse matrix," Applied
> ## Mathematics and Computation, 2011
>
> The notes on that are in the qrginv.R file linked above.
>
> The fact that I can't make that newer KPP algorithm go faster,
> although the authors show it can go faster in Matlab, leads me to a
> bunch of other questions and possibly the need to implement all of
> this in C with LAPACK or EIGEN or something like that, but at this
> point, I've got to return to my normal job.  If somebody is good at
> R's .Call interface and can make a pure C implementation of KPP.
>
> I think the key thing is that with R-2.15.2, there is an svd-related
> bottleneck in the multiple imputation algorithms in Amelia. The
> replacement version of the function Amelia:::mpinv does reclaim a 30%
> time saving, while generating imputations that are identical, so far
> as i can tell.
>
> pj
>
>
>


From davide.rambaldi at ieo.eu  Wed Dec 12 14:51:33 2012
From: davide.rambaldi at ieo.eu (Davide Rambaldi)
Date: Wed, 12 Dec 2012 14:51:33 +0100
Subject: [Rd] Lost in S4 and S3 classes
Message-ID: <D5F5DD5E-9BA1-4C15-B943-E6AC21300D4F@ieo.eu>

Hi all, this is my first post in R devel? sorry if I lost some of the guidelines. 

Anyway this is my problem:

Version:

R version 2.15.2 (2012-10-26)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

I want to make an S4 class that use the output object of the function of nls.lm as a slot:

setOldClass("nls.lm")

setClass (
  Class="TestClass",
  representation=representation(
      lmOutput = "nls.lm",
      anumeric = "numeric"
    )
  )


Now, if I want to call this class in a "constructor function" I can do something like this (correct?):

myConstructor <- function()
{
  return(new("TestClass"))
}

pippo <- myConstructor()

> pippo
An object of class "TestClass"
Slot "lmOutput":
<S4 Type Object>
attr(,".S3Class")
[1] "nls.lm"

Slot "anumeric":
numeric(0)


And the object "pippo" seems correctly initialized.


If I use this code instead I got an error:

myConstructor2 <- function()
{
  pippo <- new("TestClass", anumeric=1000)
  return(pippo)
}

> pippo <- myConstructor2()
Error in validObject(.Object) : 
  invalid class ?TestClass? object: invalid object for slot "lmOutput" in class "TestClass": got class "S4", should be or extend class "nls.lm"


Seems that if I want to INIT in new some slots, this create problem with a S3 Class slot?

Any clue on how to avoid this problem?

Thanks





-----------------------------------------------------------
PLEASE NOTE MY NEW EMAIL ADDRESS
-----------------------------------------------------------

-----------------------------------------------------
Davide Rambaldi, Bioinformatics PhD.
-----------------------------------------------------
IEO ~ MolMed
[e] davide.rambaldi at ieo.eu
[e] davide.rambaldi at gmail.com


From davide.rambaldi at ieo.eu  Thu Dec 13 12:48:37 2012
From: davide.rambaldi at ieo.eu (Davide Rambaldi)
Date: Thu, 13 Dec 2012 12:48:37 +0100
Subject: [Rd] Lost in S4 and S3 classes
In-Reply-To: <D5F5DD5E-9BA1-4C15-B943-E6AC21300D4F@ieo.eu>
References: <D5F5DD5E-9BA1-4C15-B943-E6AC21300D4F@ieo.eu>
Message-ID: <6424B597-0E06-4FD0-83B7-D498C48176EC@ieo.eu>

Hi, for the r-devel archives, I report here the answer of Martin Morgan on stackoverflow (http://goo.gl/CF5I9):

Actually, the no-argument constructor returns an invalid object, too, it's just not tested

> validObject(new("TestClass"))
Error in validObject(new("TestClass")) :
 
  invalid 
class "TestClass" object: invalid object for slot "lmOutput"

  
in class "TestClass": got class "S4", should be or extend class "nls.lm"
The solution is to provide an appropriate prototype, maybe

setClass (
  
Class="TestClass",

  representation=representation(
      lmOutput = "nls.lm",
      anumeric = "numeric"
),

  prototype=prototype(
      lmOutput=structure(list(), class="nls.lm")
)
)

Answered by Martin Morgan


All the best

Davide R.



On Dec 12, 2012, at 2:51 PM, Davide Rambaldi wrote:

> Hi all, this is my first post in R devel? sorry if I lost some of the guidelines. 
> 
> Anyway this is my problem:
> 
> Version:
> 
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> I want to make an S4 class that use the output object of the function of nls.lm as a slot:
> 
> setOldClass("nls.lm")
> 
> setClass (
>  Class="TestClass",
>  representation=representation(
>      lmOutput = "nls.lm",
>      anumeric = "numeric"
>    )
>  )
> 
> 
> Now, if I want to call this class in a "constructor function" I can do something like this (correct?):
> 
> myConstructor <- function()
> {
>  return(new("TestClass"))
> }
> 
> pippo <- myConstructor()
> 
>> pippo
> An object of class "TestClass"
> Slot "lmOutput":
> <S4 Type Object>
> attr(,".S3Class")
> [1] "nls.lm"
> 
> Slot "anumeric":
> numeric(0)
> 
> 
> And the object "pippo" seems correctly initialized.
> 
> 
> If I use this code instead I got an error:
> 
> myConstructor2 <- function()
> {
>  pippo <- new("TestClass", anumeric=1000)
>  return(pippo)
> }
> 
>> pippo <- myConstructor2()
> Error in validObject(.Object) : 
>  invalid class ?TestClass? object: invalid object for slot "lmOutput" in class "TestClass": got class "S4", should be or extend class "nls.lm"
> 
> 
> Seems that if I want to INIT in new some slots, this create problem with a S3 Class slot?
> 
> Any clue on how to avoid this problem?
> 
> Thanks
> 
> 
> 
> 
> 
> -----------------------------------------------------------
> PLEASE NOTE MY NEW EMAIL ADDRESS
> -----------------------------------------------------------
> 
> -----------------------------------------------------
> Davide Rambaldi, Bioinformatics PhD.
> -----------------------------------------------------
> IEO ~ MolMed
> [e] davide.rambaldi at ieo.eu
> [e] davide.rambaldi at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From vitaliy.feoktistov at gmail.com  Thu Dec 13 15:18:09 2012
From: vitaliy.feoktistov at gmail.com (Vitaliy FEOKTISTOV)
Date: Thu, 13 Dec 2012 15:18:09 +0100
Subject: [Rd] error memory allocation
Message-ID: <CAGHrqz9m_SGV=QDMh832jwHFPGrx=bc=XLYaxk_xLV=m24pqDA@mail.gmail.com>

Hello,

I've compiled R-2.15.2 for windows x64 and try to do a simple test :

-------------------------------------------------------------------------------------------------------------------------------
A <- matrix(rnorm(3e8), 3e4, 3e4)
B <- solve(A)
Erreur dans solve.default(A) : impossible d'allouer un bloc de m?moire
de taille 6.7 Go
-------------------------------------------------------------------------------------------------------------------------------

to solve this problem in R-2.13.2 (windows version) the following
modifications were needed :

in "R_HOME/src/main/memory.c" to modify the definition of the function
"char *R_alloc(...)"

-------------------------------------------------------------------------------------------------------------------------------
#ifdef WIN64
#define SIZEOF_SIZE_T 8
#endif
-------------------------------------------------------------------------------------------------------------------------------

what I have to change in R-2.15.2 to avoid this problem of memory allocation ?

Thanks!


From edd at debian.org  Thu Dec 13 17:42:20 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 13 Dec 2012 10:42:20 -0600
Subject: [Rd] R NEWS change related to .C/.Call/.External/.Fortran
Message-ID: <20682.1388.474360.732594@max.nulle.part>


The much-appreciated feed of changes to NEWS.Rd list this today [1]:

  2.15.2 UTILITIES

  ?R CMD check? now checks for ?.C()?, ?.Call()?, ?.External()? and
  ?.Fortran()? calls in other packages, and gives a warning on those found from
  R itself (which are not part of the API and change without notice: many will
  changed for R 3.0.0).

Could this be clarified/rewritten? I honestly cannot make out what it is
supposed to say, apart from inferring that use of the API via these functions
will be patrolled more strongly. 

Dirk


[1] http://developer.r-project.org/blosxom.cgi/R-devel/2012/12/13#n2012-12-13

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  


From yi.wang at unsw.edu.au  Fri Dec 14 04:01:09 2012
From: yi.wang at unsw.edu.au (Yi (Alice) Wang)
Date: Fri, 14 Dec 2012 11:01:09 +0800
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <50C9A0FA.9090501@statistik.tu-dortmund.de>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
Message-ID: <CAFKx_ziPeyQtWsHHm7RkMQZhqPYx3teYwbSySBjz3NFRTrwXtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121214/a6550718/attachment.pl>

From htl10 at users.sourceforge.net  Fri Dec 14 04:15:47 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 14 Dec 2012 03:15:47 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <20676.56008.881879.85729@max.nulle.part>
Message-ID: <1355454947.80816.YahooMailClassic@web172305.mail.ir2.yahoo.com>

--- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org> wrote:

<snipped>
> Do you REALLY think svn would not know about missing
> files?? There does not
> seem to be a limit on the disdain for svn among git users.
> Fascinating.

FWIW, as one of the linux kernel maintainers, I don't apologize for being familiar with git. I did not decide git as the official tool for maintaining the linux kernel. Linus did.

There does not seem to be a limit on the disdain for the linux kernel among debian users.
Fascinating.


From pauljohn32 at gmail.com  Fri Dec 14 07:55:53 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 14 Dec 2012 00:55:53 -0600
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <50C9A0FA.9090501@statistik.tu-dortmund.de>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
Message-ID: <CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>

On Thu, Dec 13, 2012 at 3:33 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
> Long message, but as far as I can see, this is not about base R but the
> contributed package Amelia: Please discuss possible improvements with its
> maintainer.
>
Thanks for answering, but I'm really surprised by your answer. The
package is a constant, but R got much slower  between R-2.15.1 and
R-2.15.2. The profile of functions called radically changed, svd gets
called much more because solve() fails much more often.

No change in R could account for it?  I'm not saying R is wrong, it
may be more accurate and better. After chasing the slowdown for a
week, I need some comfort. Does the LINPACK -> LAPACK change play a
role. The change I'm looking for is something that would substantially
tune up mathematical precision so that matrices that did not seem
singular before are now, in the eyes of functions like chol() and
solve().  Whereas in R-2.15.1, a matrix can be inverted by solve(),
for example, now R-2.15.2 rejects the matrix as singular.

I will take the problem up with applications, of course. But you see
how package writers might think its ridiculous.   They argue, "I had a
perfectly fine calculation against R-2.15.0 and R-2.15.1, and now with
R-2.15.2 it takes three times as long?  And you want me to revise my
package?"

Would you be persuaded there's an R base question if I showed you a
particular matrix that can be decomposed or solved in R-2.15.1 but
cannot be in R-2.15.2? I should have thought of that before, I suppose
:)

pj
> Best,
> Uwe Ligges
>
>
>
> On 12.12.2012 19:14, Paul Johnson wrote:
>>
>> Speaking of optimization and speeding up R calculations...
>>
>> I mentioned last week I want to speed up calculation of generalized
>> inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
>> souped up generalized inverse algorithm published by
>>
>> V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
>> matrix, Electronic Journal of Linear Algebra,
>> 17(2008), 637-650.
>>
>> I was so delighted to see the computation time drop on my Debian
>> system that I boasted to the WIndows users and gave them a test case.
>> They answered back "there's no benefits, plus Windows is faster than
>> Linux".
>>
>> That sent me off on a bit of a goose chase, but I think I'm beginning
>> to understand the situation.  I believe R-2.15.2 introduced a tighter
>> requirement for precision, thus triggering longer-lasting calculations
>> in many example scripts. Better algorithms can avoid some of that
>> slowdown, as you see in this test case.
>>
>> Here is the test code you can run to see:
>>
>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R
>>
>> It downloads a data file from that same directory and then runs some
>> multiple imputations with the Amelia package.
>>
>> Here's the output from my computer
>>
>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout
>>
>> That includes the profile of the calculations that depend on the
>> ordinary generalized inverse algorithm based on svd and the new one.
>>
>> See? The KP algorithm is faster.  And just as accurate as
>> Amelia:::mpinv or MASS::ginv (for details on that, please review my
>> notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).
>>
>> So I asked WIndows users for more detailed feedback, including
>> sessionInfo(), and I noticed that my proposed algorithm is not faster
>> on Windows--WITH OLD R!
>>
>> Here's the script output with R-2.15.0, shows no speedup from the
>> KPginv algorithm
>>
>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout
>>
>> On the same machine, I updated to R-2.15.2, and we see the same
>> speedup from the KPginv algorithm
>>
>>
>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout
>>
>> After that, I realized it is an R version change, not an OS
>> difference, I was a bit relieved.
>>
>> What causes the difference in this case?  In the Amelia code, they try
>> to avoid doing the generalized inverse by using the ordinary solve(),
>> and if that fails, then they do the generalized inverse. In R 2.15.0,
>> the near singularity of the matrix is ignored, but not in R 2.15.2.
>> The ordinary solve is failing almost all the time, thus triggering the
>> use of the svd based generalized inverse.  Which is slower.
>>
>> The Katsikis and Pappas 2008 algorithm is the fastest one I've found
>> after translating from Matlab to R.  It is not so universally
>> applicable as svd based methods, it will fail if there are linearly
>> dependent columns. However, it does tolerate columns of all zeros,
>> which seems to be the problem case in the particular application I am
>> testing.
>>
>> I tried very hard to get the newer algorithm described here to go as
>> fast, but it is way way slower, at least in the implementations I
>> tried:
>> ##  KPP
>> ## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
>> improved method for
>> ## the computation of the Moore Penrose inverse matrix," Applied
>> ## Mathematics and Computation, 2011
>>
>> The notes on that are in the qrginv.R file linked above.
>>
>> The fact that I can't make that newer KPP algorithm go faster,
>> although the authors show it can go faster in Matlab, leads me to a
>> bunch of other questions and possibly the need to implement all of
>> this in C with LAPACK or EIGEN or something like that, but at this
>> point, I've got to return to my normal job.  If somebody is good at
>> R's .Call interface and can make a pure C implementation of KPP.
>>
>> I think the key thing is that with R-2.15.2, there is an svd-related
>> bottleneck in the multiple imputation algorithms in Amelia. The
>> replacement version of the function Amelia:::mpinv does reclaim a 30%
>> time saving, while generating imputations that are identical, so far
>> as i can tell.
>>
>> pj
>>
>>
>>
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From pauljohn32 at gmail.com  Fri Dec 14 08:01:19 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 14 Dec 2012 01:01:19 -0600
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <CAFKx_ziPeyQtWsHHm7RkMQZhqPYx3teYwbSySBjz3NFRTrwXtg@mail.gmail.com>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAFKx_ziPeyQtWsHHm7RkMQZhqPYx3teYwbSySBjz3NFRTrwXtg@mail.gmail.com>
Message-ID: <CAErODj9APDF=Lx3EBtv=VjdXas9CxnvGFOLqvPhbYpRNuqwLQA@mail.gmail.com>

On Thu, Dec 13, 2012 at 9:01 PM, Yi (Alice) Wang <yi.wang at unsw.edu.au> wrote:
> I have also encountered a similar problem. My mvabund package runs much
> faster on linux/OSX than on windows with both R/2.15.1 and R/2.15.2. For
> example, with mvabund_3.6.3 and R/2.15.2,
> system.time(example(anova.manyglm))
>

Hi, Alice

You have a different problem than I do.

The change from R-2.15.1 to R-2.15.2 makes the program slower on all
platforms.  The slowdown that emerges in R-2.15.2 on all types of
hardware concerns me.

It only seemed like a "Windows is better" issue when all the Windows
users who tested my program were using R-2.15.0 or R-2.15.1. As soon
as they update R, then they have the slowdown as well.

pj


> on OSX returns
>
>    user  system elapsed
>   3.351   0.006   3.381
>
> but on windows 7 it returns
>
>    user  system elapsed
>   13.13   0.00   13.14
>
> I also used svd frequently in my c code though by calling the gsl functions
> only. In my memory, I think the comp time difference is not that significant
> with earlier R versions. So maybe it is worth an investigation?
>
> Many thanks,
> Yi Wang
>
>
> On Thu, Dec 13, 2012 at 5:33 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>>
>> Long message, but as far as I can see, this is not about base R but the
>> contributed package Amelia: Please discuss possible improvements with its
>> maintainer.
>>
>> Best,
>> Uwe Ligges
>>
>>
>> On 12.12.2012 19:14, Paul Johnson wrote:
>>>
>>> Speaking of optimization and speeding up R calculations...
>>>
>>> I mentioned last week I want to speed up calculation of generalized
>>> inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
>>> souped up generalized inverse algorithm published by
>>>
>>> V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
>>> matrix, Electronic Journal of Linear Algebra,
>>> 17(2008), 637-650.
>>>
>>> I was so delighted to see the computation time drop on my Debian
>>> system that I boasted to the WIndows users and gave them a test case.
>>> They answered back "there's no benefits, plus Windows is faster than
>>> Linux".
>>>
>>> That sent me off on a bit of a goose chase, but I think I'm beginning
>>> to understand the situation.  I believe R-2.15.2 introduced a tighter
>>> requirement for precision, thus triggering longer-lasting calculations
>>> in many example scripts. Better algorithms can avoid some of that
>>> slowdown, as you see in this test case.
>>>
>>> Here is the test code you can run to see:
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R
>>>
>>> It downloads a data file from that same directory and then runs some
>>> multiple imputations with the Amelia package.
>>>
>>> Here's the output from my computer
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout
>>>
>>> That includes the profile of the calculations that depend on the
>>> ordinary generalized inverse algorithm based on svd and the new one.
>>>
>>> See? The KP algorithm is faster.  And just as accurate as
>>> Amelia:::mpinv or MASS::ginv (for details on that, please review my
>>> notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).
>>>
>>> So I asked WIndows users for more detailed feedback, including
>>> sessionInfo(), and I noticed that my proposed algorithm is not faster
>>> on Windows--WITH OLD R!
>>>
>>> Here's the script output with R-2.15.0, shows no speedup from the
>>> KPginv algorithm
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout
>>>
>>> On the same machine, I updated to R-2.15.2, and we see the same
>>> speedup from the KPginv algorithm
>>>
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout
>>>
>>> After that, I realized it is an R version change, not an OS
>>> difference, I was a bit relieved.
>>>
>>> What causes the difference in this case?  In the Amelia code, they try
>>> to avoid doing the generalized inverse by using the ordinary solve(),
>>> and if that fails, then they do the generalized inverse. In R 2.15.0,
>>> the near singularity of the matrix is ignored, but not in R 2.15.2.
>>> The ordinary solve is failing almost all the time, thus triggering the
>>> use of the svd based generalized inverse.  Which is slower.
>>>
>>> The Katsikis and Pappas 2008 algorithm is the fastest one I've found
>>> after translating from Matlab to R.  It is not so universally
>>> applicable as svd based methods, it will fail if there are linearly
>>> dependent columns. However, it does tolerate columns of all zeros,
>>> which seems to be the problem case in the particular application I am
>>> testing.
>>>
>>> I tried very hard to get the newer algorithm described here to go as
>>> fast, but it is way way slower, at least in the implementations I
>>> tried:
>>> ##  KPP
>>> ## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
>>> improved method for
>>> ## the computation of the Moore Penrose inverse matrix," Applied
>>> ## Mathematics and Computation, 2011
>>>
>>> The notes on that are in the qrginv.R file linked above.
>>>
>>> The fact that I can't make that newer KPP algorithm go faster,
>>> although the authors show it can go faster in Matlab, leads me to a
>>> bunch of other questions and possibly the need to implement all of
>>> this in C with LAPACK or EIGEN or something like that, but at this
>>> point, I've got to return to my normal job.  If somebody is good at
>>> R's .Call interface and can make a pure C implementation of KPP.
>>>
>>> I think the key thing is that with R-2.15.2, there is an svd-related
>>> bottleneck in the multiple imputation algorithms in Amelia. The
>>> replacement version of the function Amelia:::mpinv does reclaim a 30%
>>> time saving, while generating imputations that are identical, so far
>>> as i can tell.
>>>
>>> pj
>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
>
>
> --
> Dr. Wang, Yi (Alice)
> Research Assistant Professor
> Institute of Computational and Theoretical Studies
> Department of Computer Science
> Faculty of Science
> Hong Kong Baptist University
> Kowloon Tong, Hong Kong
> Email: yiwang at comp.hkbu.edu.hk
> Tel: +852-3411-2789
> Web: http://www.icts.hkbu.edu.hk/yiwang/public/
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From mtmorgan at fhcrc.org  Fri Dec 14 08:58:54 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 14 Dec 2012 08:58:54 +0100
Subject: [Rd] namespace S3 and S4 generic imports cannot both be
	satisfied:
In-Reply-To: <50C4E63B.1060207@r-project.org>
References: <50C3C7C1.5050508@fhcrc.org> <50C4E63B.1060207@r-project.org>
Message-ID: <50CADC3E.4000309@fhcrc.org>

On 12/09/2012 08:27 PM, John Chambers wrote:
> Yes, you are right.
>
> Mixing S3 and S4 methods for a generic is fine, although in subtle cases one is
> safer promoting the S3 method to an S4 method, as you did in your example.
>
> Usually, the default method for the S4 generic is the S3 generic.  But, in
> general, it's not possible to check algorithmically whether the S3 methods will
> be dispatched.  For example, an S4 method on "vector" could dispatch S3 methods
> on subclasses "numeric", etc. (don't ask why ...), for a generic that had no
> default method.
>
> That the trouble with this check isn't found right away is likely because one is
> typically working with a primitive where no generic function is created.
>
> Should be fixed in rev. 61263.  Please check on your real example; it seems fine
> on the test you submitted.

Thanks, this addresses the problem for our real example. Martin

>
> Thanks for the catch.
>
> John
>
> On 12/8/12 3:05 PM, Martin Morgan wrote:
>> PkgA wishes to write a method for 'unique' on S4 class 'A'. ?Methods
>> indicates that one should
>>
>>    setGeneric("unique")
>>
>>    setClass("A")
>>    unique.A <- function(x, incomparables=FALSE, ...) {}
>>    setMethod(unique, "A", unique.A)
>>
>> Both S3 and S4 methods need to be exported in the NAMESPACE
>>
>>    import(methods)
>>    S3method(unique, A)
>>    exportMethods(unique)
>>
>> PkgB introduces a new class and method
>>
>>    setClass("B")
>>    unique.B <- function(x, incomparables=FALSE, ...) {}
>>    setMethod(unique, "B", unique.B)
>>
>> and in the NAMESPACE has
>>
>>    import(methods)
>>    importFrom(PkgA, unique)
>>    S3method(unique, B)
>>    exportMethods(unique)
>>
>> Unfortuantely, R CMD check says that
>>
>> * checking whether package 'PkgB' can be installed ... WARNING
>> Found the following significant warnings:
>>    Warning: found an S4 version of 'unique' so it has not been imported
>> correctly
>> See '/home/mtmorgan/tmp/PkgB.Rcheck/00install.out' for details.
>>
>> This is from (svn r61253) R-devel/src/library/base/R/namespace.R:1339,
>> where the code finds the S4 generic, but not the S3 generic. Obviously
>> the namespace cannot have both the S3 and S4 symbols defined, but this
>> seems to be required? A workaround might extend the check to include
>> getGeneric(genname)@default.
>>
>> This scenario is reproducible in the attached tarball
>>
>>    tar xzf PkgAB.tar.gz
>>    R CMD INSTALL PkgA
>>    R CMD check PkgB
>>
>> Martin Morgan
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From bodenhofer at bioinf.jku.at  Fri Dec 14 09:46:43 2012
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Fri, 14 Dec 2012 09:46:43 +0100
Subject: [Rd] Strange, most probably unjustified,
 codoc mismatch for S4 method with one argument plus '...' (re-try)
Message-ID: <50CAE773.8070004@bioinf.jku.at>

Hi,

I just figured out that I accidentally posted my message in HTML, so I 
am retrying in plain text only. Sorry.

I am currently extending one of our CRAN packages and ran into an 
unexpected problem when checking the source package. I got some warnings 
in the step "* checking for code/documentation mismatches". I double 
checked everything and did not see anything that would actually justify 
this warning. After testing around for quite a while, I think I can now 
pinpoint the problem. In order to make myself clear, I need to explain 
the situation in more detail:

The default method (passed as def argument of setGeneric()) has the 
formal argument list (x, y, ...). Suppose I want to register a method 
with a signature without y, say signature(x="matrix", y="missing"). If I 
pass a function to setMethod() that only has the argument x,i.e. 
function(x) {...}, everything works well. It also works well if I 
register a function with additional arguments, e.g. function(x, 
dummy=NULL, ...){...} (note: y is missing in the definition). However, 
if I try to register a function with two formal arguments, x and '...', 
i.e.function(x, ...){...}, I get the warning that argument y is present 
in the code but missing in the documentation , although it is actually 
NOT in the code. In order to make this reproducible for everybody, I put 
together a little dummy package in which one of the methods leads to 
exactly this warning:

    http://www.bioinf.jku.at/people/bodenhofer/codocMismatchTest_0.0.1.tar.gz

Just run 'R CMD check' on this archive and you'll see. You will also see 
from the code and the corresponding documentation that the warning seems 
unjustified. I tried the following R versions: 2.12.1, 2.13.0, 2.13.1, 
2.14.0, 2.14.1, 2.15.0, 2.15.1, 2.15.2, 2.16.0 (devel), and all 
consistently gave the same warning.

Is this a bug or is there a special reason for this behavior? Any help 
is gratefully appreciated!

Thanks in advance and best regards,
Ulrich


------------------------------------------------------------------------
*Dr. Ulrich Bodenhofer*
Associate Professor
Institute of Bioinformatics

*Johannes Kepler University*
Altenberger Str. 69
4040 Linz, Austria

Tel. +43 732 2468 4526
Fax +43 732 2468 4539
bodenhofer at bioinf.jku.at <mailto:bodenhofer at bioinf.jku.at>
http://www.bioinf.jku.at/ <http://www.bioinf.jku.at>


From maechler at stat.math.ethz.ch  Fri Dec 14 10:59:42 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Dec 2012 10:59:42 +0100
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <CAErODj9APDF=Lx3EBtv=VjdXas9CxnvGFOLqvPhbYpRNuqwLQA@mail.gmail.com>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAFKx_ziPeyQtWsHHm7RkMQZhqPYx3teYwbSySBjz3NFRTrwXtg@mail.gmail.com>
	<CAErODj9APDF=Lx3EBtv=VjdXas9CxnvGFOLqvPhbYpRNuqwLQA@mail.gmail.com>
Message-ID: <20682.63630.236645.304026@stat.math.ethz.ch>

>>>>> "PJ" == Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Fri, 14 Dec 2012 01:01:19 -0600 writes:

    PJ> On Thu, Dec 13, 2012 at 9:01 PM, Yi (Alice) Wang <yi.wang at unsw.edu.au> wrote:
    >> I have also encountered a similar problem. My mvabund package runs much
    >> faster on linux/OSX than on windows with both R/2.15.1 and R/2.15.2. For
    >> example, with mvabund_3.6.3 and R/2.15.2,
    >> system.time(example(anova.manyglm))
    >> 

    PJ> Hi, Alice

    PJ> You have a different problem than I do.

    PJ> The change from R-2.15.1 to R-2.15.2 makes the program slower on all
    PJ> platforms.  The slowdown that emerges in R-2.15.2 on all types of
    PJ> hardware concerns me.

    PJ> It only seemed like a "Windows is better" issue when all the Windows
    PJ> users who tested my program were using R-2.15.0 or R-2.15.1. As soon
    PJ> as they update R, then they have the slowdown as well.

Paul, I'm pretty sure you are right that it is not just your package.
Rather, the NEWS for R 2.15.2  contain 

    ? The included LAPACK has been updated to 3.4.1, with some patches
      from the current SVN sources.  (_Inter alia_, this resolves
      PR#14692.)

and as I got from your e-mails --- yes, a reproducible example
(without package Amelia) would have been (and would still be)
 really enlightening ---
indeed,  "the default tolerance" (in a vague sense) of detecting
(near)singularity may well have been tightened in the newer LAPACK.

Martin


    >> on OSX returns
    >> 
    >> user  system elapsed
    >> 3.351   0.006   3.381
    >> 
    >> but on windows 7 it returns
    >> 
    >> user  system elapsed
    >> 13.13   0.00   13.14
    >> 
    >> I also used svd frequently in my c code though by calling the gsl functions
    >> only. In my memory, I think the comp time difference is not that significant
    >> with earlier R versions. So maybe it is worth an investigation?
    >> 
    >> Many thanks,
    >> Yi Wang
    >> 
    >> 
    >> On Thu, Dec 13, 2012 at 5:33 PM, Uwe Ligges
    >> <ligges at statistik.tu-dortmund.de> wrote:
    >>> 
    >>> Long message, but as far as I can see, this is not about base R but the
    >>> contributed package Amelia: Please discuss possible improvements with its
    >>> maintainer.
    >>> 
    >>> Best,
    >>> Uwe Ligges
    >>> 
    >>> 
    >>> On 12.12.2012 19:14, Paul Johnson wrote:
    >>>> 
    >>>> Speaking of optimization and speeding up R calculations...
    >>>> 
    >>>> I mentioned last week I want to speed up calculation of generalized
    >>>> inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
    >>>> souped up generalized inverse algorithm published by
    >>>> 
    >>>> V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
    >>>> matrix, Electronic Journal of Linear Algebra,
    >>>> 17(2008), 637-650.
    >>>> 
    >>>> I was so delighted to see the computation time drop on my Debian
    >>>> system that I boasted to the WIndows users and gave them a test case.
    >>>> They answered back "there's no benefits, plus Windows is faster than
    >>>> Linux".
    >>>> 
    >>>> That sent me off on a bit of a goose chase, but I think I'm beginning
    >>>> to understand the situation.  I believe R-2.15.2 introduced a tighter
    >>>> requirement for precision, thus triggering longer-lasting calculations
    >>>> in many example scripts. Better algorithms can avoid some of that
    >>>> slowdown, as you see in this test case.
    >>>> 
    >>>> Here is the test code you can run to see:
    >>>> 
    >>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R
    >>>> 
    >>>> It downloads a data file from that same directory and then runs some
    >>>> multiple imputations with the Amelia package.
    >>>> 
    >>>> Here's the output from my computer
    >>>> 
    >>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout
    >>>> 
    >>>> That includes the profile of the calculations that depend on the
    >>>> ordinary generalized inverse algorithm based on svd and the new one.
    >>>> 
    >>>> See? The KP algorithm is faster.  And just as accurate as
    >>>> Amelia:::mpinv or MASS::ginv (for details on that, please review my
    >>>> notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).
    >>>> 
    >>>> So I asked WIndows users for more detailed feedback, including
    >>>> sessionInfo(), and I noticed that my proposed algorithm is not faster
    >>>> on Windows--WITH OLD R!
    >>>> 
    >>>> Here's the script output with R-2.15.0, shows no speedup from the
    >>>> KPginv algorithm
    >>>> 
    >>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout
    >>>> 
    >>>> On the same machine, I updated to R-2.15.2, and we see the same
    >>>> speedup from the KPginv algorithm
    >>>> 
    >>>> 
    >>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout
    >>>> 
    >>>> After that, I realized it is an R version change, not an OS
    >>>> difference, I was a bit relieved.
    >>>> 
    >>>> What causes the difference in this case?  In the Amelia code, they try
    >>>> to avoid doing the generalized inverse by using the ordinary solve(),
    >>>> and if that fails, then they do the generalized inverse. In R 2.15.0,
    >>>> the near singularity of the matrix is ignored, but not in R 2.15.2.
    >>>> The ordinary solve is failing almost all the time, thus triggering the
    >>>> use of the svd based generalized inverse.  Which is slower.
    >>>> 
    >>>> The Katsikis and Pappas 2008 algorithm is the fastest one I've found
    >>>> after translating from Matlab to R.  It is not so universally
    >>>> applicable as svd based methods, it will fail if there are linearly
    >>>> dependent columns. However, it does tolerate columns of all zeros,
    >>>> which seems to be the problem case in the particular application I am
    >>>> testing.
    >>>> 
    >>>> I tried very hard to get the newer algorithm described here to go as
    >>>> fast, but it is way way slower, at least in the implementations I
    >>>> tried:
    >>>> ##  KPP
    >>>> ## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
    >>>> improved method for
    >>>> ## the computation of the Moore Penrose inverse matrix," Applied
    >>>> ## Mathematics and Computation, 2011
    >>>> 
    >>>> The notes on that are in the qrginv.R file linked above.
    >>>> 
    >>>> The fact that I can't make that newer KPP algorithm go faster,
    >>>> although the authors show it can go faster in Matlab, leads me to a
    >>>> bunch of other questions and possibly the need to implement all of
    >>>> this in C with LAPACK or EIGEN or something like that, but at this
    >>>> point, I've got to return to my normal job.  If somebody is good at
    >>>> R's .Call interface and can make a pure C implementation of KPP.
    >>>> 
    >>>> I think the key thing is that with R-2.15.2, there is an svd-related
    >>>> bottleneck in the multiple imputation algorithms in Amelia. The
    >>>> replacement version of the function Amelia:::mpinv does reclaim a 30%
    >>>> time saving, while generating imputations that are identical, so far
    >>>> as i can tell.
    >>>> 
    >>>> pj
    >>>> 
    >>>> 
    >>>> 
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 
    >> 
    >> 
    >> --
    >> 
    >> 
    >> --
    >> Dr. Wang, Yi (Alice)
    >> Research Assistant Professor
    >> Institute of Computational and Theoretical Studies
    >> Department of Computer Science
    >> Faculty of Science
    >> Hong Kong Baptist University
    >> Kowloon Tong, Hong Kong
    >> Email: yiwang at comp.hkbu.edu.hk
    >> Tel: +852-3411-2789
    >> Web: http://www.icts.hkbu.edu.hk/yiwang/public/
    >> 



    PJ> -- 
    PJ> Paul E. Johnson
    PJ> Professor, Political Science      Assoc. Director
    PJ> 1541 Lilac Lane, Room 504      Center for Research Methods
    PJ> University of Kansas                 University of Kansas
    PJ> http://pj.freefaculty.org               http://quant.ku.edu

    PJ> ______________________________________________
    PJ> R-devel at r-project.org mailing list
    PJ> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Fri Dec 14 18:07:09 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 14 Dec 2012 18:07:09 +0100
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
Message-ID: <50CB5CBD.1040104@statistik.tu-dortmund.de>



On 14.12.2012 07:55, Paul Johnson wrote:
> On Thu, Dec 13, 2012 at 3:33 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>> Long message, but as far as I can see, this is not about base R but the
>> contributed package Amelia: Please discuss possible improvements with its
>> maintainer.
>>
> Thanks for answering, but I'm really surprised by your answer. The
> package is a constant, but R got much slower  between R-2.15.1 and
> R-2.15.2. The profile of functions called radically changed, svd gets
> called much more because solve() fails much more often.


I have screened your mail and I have seen statements and code re. 
Amelia. If you are talking about R, please provide reproducible examples 
without overhead of packages. The CRAN check times of > 4000 packages 
are typically a good indicator, and they are a bit slower for R-2.15.2 
but not that it is generally worrying (since we also run more checks).




> No change in R could account for it?  I'm not saying R is wrong, it
> may be more accurate and better. After chasing the slowdown for a
> week, I need some comfort. Does the LINPACK -> LAPACK change play a
> role. The change I'm looking for is something that would substantially
> tune up mathematical precision so that matrices that did not seem
> singular before are now, in the eyes of functions like chol() and
> solve().  Whereas in R-2.15.1, a matrix can be inverted by solve(),
> for example, now R-2.15.2 rejects the matrix as singular.

Then a LAPACK upgrade for bugfix reasons, I believe.

> I will take the problem up with applications, of course. But you see
> how package writers might think its ridiculous.   They argue, "I had a
> perfectly fine calculation against R-2.15.0 and R-2.15.1, and now with
> R-2.15.2 it takes three times as long?  And you want me to revise my
> package?"
>
> Would you be persuaded there's an R base question if I showed you a
> particular matrix that can be decomposed or solved in R-2.15.1 but
> cannot be in R-2.15.2? I should have thought of that before, I suppose
> :)

Yes, a minimal reproducible example would be good, but then it is 
probably a LAPACK issue and we have to convince the LAPACK people to 
improve code.

Best,
uwe



>
> pj
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 12.12.2012 19:14, Paul Johnson wrote:
>>>
>>> Speaking of optimization and speeding up R calculations...
>>>
>>> I mentioned last week I want to speed up calculation of generalized
>>> inverses. On Debian Wheezy with R-2.15.2, I see a huge speedup using a
>>> souped up generalized inverse algorithm published by
>>>
>>> V. N. Katsikis, D. Pappas, Fast computing of theMoore-Penrose inverse
>>> matrix, Electronic Journal of Linear Algebra,
>>> 17(2008), 637-650.
>>>
>>> I was so delighted to see the computation time drop on my Debian
>>> system that I boasted to the WIndows users and gave them a test case.
>>> They answered back "there's no benefits, plus Windows is faster than
>>> Linux".
>>>
>>> That sent me off on a bit of a goose chase, but I think I'm beginning
>>> to understand the situation.  I believe R-2.15.2 introduced a tighter
>>> requirement for precision, thus triggering longer-lasting calculations
>>> in many example scripts. Better algorithms can avoid some of that
>>> slowdown, as you see in this test case.
>>>
>>> Here is the test code you can run to see:
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.R
>>>
>>> It downloads a data file from that same directory and then runs some
>>> multiple imputations with the Amelia package.
>>>
>>> Here's the output from my computer
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1.Rout
>>>
>>> That includes the profile of the calculations that depend on the
>>> ordinary generalized inverse algorithm based on svd and the new one.
>>>
>>> See? The KP algorithm is faster.  And just as accurate as
>>> Amelia:::mpinv or MASS::ginv (for details on that, please review my
>>> notes in http://pj.freefaculty.org/scraps/profile/qrginv.R).
>>>
>>> So I asked WIndows users for more detailed feedback, including
>>> sessionInfo(), and I noticed that my proposed algorithm is not faster
>>> on Windows--WITH OLD R!
>>>
>>> Here's the script output with R-2.15.0, shows no speedup from the
>>> KPginv algorithm
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-Windows.Rout
>>>
>>> On the same machine, I updated to R-2.15.2, and we see the same
>>> speedup from the KPginv algorithm
>>>
>>>
>>> http://pj.freefaculty.org/scraps/profile/prof-puzzle-1-CRMDA02-WinR2.15.2.Rout
>>>
>>> After that, I realized it is an R version change, not an OS
>>> difference, I was a bit relieved.
>>>
>>> What causes the difference in this case?  In the Amelia code, they try
>>> to avoid doing the generalized inverse by using the ordinary solve(),
>>> and if that fails, then they do the generalized inverse. In R 2.15.0,
>>> the near singularity of the matrix is ignored, but not in R 2.15.2.
>>> The ordinary solve is failing almost all the time, thus triggering the
>>> use of the svd based generalized inverse.  Which is slower.
>>>
>>> The Katsikis and Pappas 2008 algorithm is the fastest one I've found
>>> after translating from Matlab to R.  It is not so universally
>>> applicable as svd based methods, it will fail if there are linearly
>>> dependent columns. However, it does tolerate columns of all zeros,
>>> which seems to be the problem case in the particular application I am
>>> testing.
>>>
>>> I tried very hard to get the newer algorithm described here to go as
>>> fast, but it is way way slower, at least in the implementations I
>>> tried:
>>> ##  KPP
>>> ## Vasilios N. Katsikis, Dimitrios Pappas, Athanassios Petralias.  "An
>>> improved method for
>>> ## the computation of the Moore Penrose inverse matrix," Applied
>>> ## Mathematics and Computation, 2011
>>>
>>> The notes on that are in the qrginv.R file linked above.
>>>
>>> The fact that I can't make that newer KPP algorithm go faster,
>>> although the authors show it can go faster in Matlab, leads me to a
>>> bunch of other questions and possibly the need to implement all of
>>> this in C with LAPACK or EIGEN or something like that, but at this
>>> point, I've got to return to my normal job.  If somebody is good at
>>> R's .Call interface and can make a pure C implementation of KPP.
>>>
>>> I think the key thing is that with R-2.15.2, there is an svd-related
>>> bottleneck in the multiple imputation algorithms in Amelia. The
>>> replacement version of the function Amelia:::mpinv does reclaim a 30%
>>> time saving, while generating imputations that are identical, so far
>>> as i can tell.
>>>
>>> pj
>>>
>>>
>>>
>>
>
>
>


From edd at debian.org  Fri Dec 14 18:11:49 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 14 Dec 2012 11:11:49 -0600
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <50CB5CBD.1040104@statistik.tu-dortmund.de>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
	<50CB5CBD.1040104@statistik.tu-dortmund.de>
Message-ID: <20683.24021.243724.727014@max.nulle.part>


On 14 December 2012 at 18:07, Uwe Ligges wrote:
| without overhead of packages. The CRAN check times of > 4000 packages 
| are typically a good indicator, and they are a bit slower for R-2.15.2 

And sadly less so when you force us to turn tests off.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ligges at statistik.tu-dortmund.de  Fri Dec 14 18:13:55 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 14 Dec 2012 18:13:55 +0100
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <1355454947.80816.YahooMailClassic@web172305.mail.ir2.yahoo.com>
References: <1355454947.80816.YahooMailClassic@web172305.mail.ir2.yahoo.com>
Message-ID: <50CB5E53.5020507@statistik.tu-dortmund.de>



On 14.12.2012 04:15, Hin-Tak Leung wrote:
> --- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> <snipped>
>> Do you REALLY think svn would not know about missing
>> files?  There does not
>> seem to be a limit on the disdain for svn among git users.
>> Fascinating.
>
> FWIW, as one of the linux kernel maintainers, I don't apologize for being familiar with git. I did not decide git as the official tool for maintaining the linux kernel. Linus did.
>
> There does not seem to be a limit on the disdain for the linux kernel among debian users.
> Fascinating.


There *is* no limit on the disdain for people discussing off-topic 
svn/git/linux disdains on the *R*-devel list among R developers.

Uwe Ligges




>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Fri Dec 14 18:19:02 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 14 Dec 2012 18:19:02 +0100
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <20683.24021.243724.727014@max.nulle.part>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
	<50CB5CBD.1040104@statistik.tu-dortmund.de>
	<20683.24021.243724.727014@max.nulle.part>
Message-ID: <50CB5F86.9030703@statistik.tu-dortmund.de>



On 14.12.2012 18:11, Dirk Eddelbuettel wrote:
>
> On 14 December 2012 at 18:07, Uwe Ligges wrote:
> | without overhead of packages. The CRAN check times of > 4000 packages
> | are typically a good indicator, and they are a bit slower for R-2.15.2

Please do not quote only parts of my sentences, that one was continued:

"but not that it is generally worrying (since we also run more checks)."

Thanks,
Uwe

> And sadly less so when you force us to turn tests off.
> Dirk
>


From edd at debian.org  Fri Dec 14 18:32:26 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 14 Dec 2012 11:32:26 -0600
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <50CB5F86.9030703@statistik.tu-dortmund.de>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
	<50CB5CBD.1040104@statistik.tu-dortmund.de>
	<20683.24021.243724.727014@max.nulle.part>
	<50CB5F86.9030703@statistik.tu-dortmund.de>
Message-ID: <20683.25258.504484.936275@max.nulle.part>


On 14 December 2012 at 18:19, Uwe Ligges wrote:
| 
| 
| On 14.12.2012 18:11, Dirk Eddelbuettel wrote:
| >
| > On 14 December 2012 at 18:07, Uwe Ligges wrote:
| > | without overhead of packages. The CRAN check times of > 4000 packages
| > | are typically a good indicator, and they are a bit slower for R-2.15.2
| 
| Please do not quote only parts of my sentences, that one was continued:
| 
| "but not that it is generally worrying (since we also run more checks)."

I understand the resource constraint, but the fact remains that on the CRAN
side most-visible package I am involved with now runs _way fewer_ tests than
it used to, making these very comparisons across time a little tricky.

Rock, meet hard place. In an ideal world we had way more tests, and
comparisons among them. But time is, alas, finite...

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spencer.graves at structuremonitoring.com  Fri Dec 14 19:42:52 2012
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 14 Dec 2012 10:42:52 -0800
Subject: [Rd] R-2.15.2 changes in computation speed. Numerical precision?
In-Reply-To: <20683.25258.504484.936275@max.nulle.part>
References: <CAErODj-96eWJ-geM_3eCt1RMZxA7zCOo6ev1-WibvZtFAMYoDQ@mail.gmail.com>
	<50C9A0FA.9090501@statistik.tu-dortmund.de>
	<CAErODj-1J-rXJBTLDNd6Y7sKP-8aKrvYz3zPQG5v__F8BFNeoQ@mail.gmail.com>
	<50CB5CBD.1040104@statistik.tu-dortmund.de>
	<20683.24021.243724.727014@max.nulle.part>
	<50CB5F86.9030703@statistik.tu-dortmund.de>
	<20683.25258.504484.936275@max.nulle.part>
Message-ID: <50CB732C.7080006@structuremonitoring.com>

On 12/14/2012 9:32 AM, Dirk Eddelbuettel wrote:
> On 14 December 2012 at 18:19, Uwe Ligges wrote:
> |
> |
> | On 14.12.2012 18:11, Dirk Eddelbuettel wrote:
> | >
> | > On 14 December 2012 at 18:07, Uwe Ligges wrote:
> | > | without overhead of packages. The CRAN check times of > 4000 packages
> | > | are typically a good indicator, and they are a bit slower for R-2.15.2
> |
> | Please do not quote only parts of my sentences, that one was continued:
> |
> | "but not that it is generally worrying (since we also run more checks)."
>
> I understand the resource constraint, but the fact remains that on the CRAN
> side most-visible package I am involved with now runs _way fewer_ tests than
> it used to, making these very comparisons across time a little tricky.
>
> Rock, meet hard place. In an ideal world we had way more tests, and
> comparisons among them. But time is, alas, finite...


       This raises again the question of why the CRAN resources are so 
constrained?


       I don't know the answer to that, but I assume it's because the 
current CRAN maintainers would rather force package maintainers to turn 
off tests than recruit help to fix the resource constraints in other 
ways.  I just fit a log-logistic model using drm{drc} to the number of 
CRAN packages using data from John Fox (2009) "Aspects of the Social 
Organization and Trajectory of the R Project", R Journal 
(http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf), 
with some points I added with more recent data.


       From this model fit, I estimate the doubling time for the number 
of CRAN packages at roughly 4.5 years.  This is triple the historic 18 
month speed improvements achieved since 1971 and is still 1.5 times the 
3 year doubling time for number of transistors per chip forecasted by 
the 2010 update to the International Technology Roadmap for 
Semiconductors (Wikipedia, "Moore's Law"). From this, I infer that a 
reasonable replacement schedule for hardware in the current CRAN server 
farm should be able to solve this problem and release this constraint on 
CRAN test time.


      Jim Ramsay suggested that if money is a constraint, he has grant 
money that could pay some nominal fee for CRAN usage provided he could 
get an invoice.  CRAN could still be free for anyone without the ability 
to easily pay such, like page charges in many journal.  However, his 
grant money can NOT be used to make contributions.


       A "CRAN" function has been added to the "fda" package to test to 
see if it was running "--as-cran";  we use this to skip tests if TRUE.  
Ramsay and I are with Dirk:  We wish there were a way to release this 
compute time constraint on CRAN.  However, we have so far been unable to 
get information on the source of that constraint.  (R-Forge is similarly 
a very valuable service with other known problems, also with unknown 
causes.)


       Best Wishes,
       Spencer

> Dirk
>


From htl10 at users.sourceforge.net  Fri Dec 14 20:48:14 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 14 Dec 2012 19:48:14 +0000 (GMT)
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <50CB5E53.5020507@statistik.tu-dortmund.de>
Message-ID: <1355514494.11587.YahooMailClassic@web172304.mail.ir2.yahoo.com>

--- On Fri, 14/12/12, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> On 14.12.2012 04:15, Hin-Tak Leung wrote:
> > --- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org>
> wrote:
> >
> > <snipped>
> >> Do you REALLY think svn would not know about
> missing
> >> files?? There does not
> >> seem to be a limit on the disdain for svn among git
> users.
> >> Fascinating.
> >
> > FWIW, as one of the linux kernel maintainers, I don't
> apologize for being familiar with git. I did not decide git
> as the official tool for maintaining the linux kernel. Linus
> did.
> >
> > There does not seem to be a limit on the disdain for
> the linux kernel among debian users.
> > Fascinating.
> 
> 
> There *is* no limit on the disdain for people discussing
> off-topic 
> svn/git/linux disdains on the *R*-devel list among R
> developers.

That needs a "Fascinating" exclamation at the end to be genuine and authentic for the typical R developers/debian users.




From marc_schwartz at me.com  Fri Dec 14 21:01:05 2012
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 14 Dec 2012 14:01:05 -0600
Subject: [Rd] small issue with over-zealous clean.
In-Reply-To: <1355514494.11587.YahooMailClassic@web172304.mail.ir2.yahoo.com>
References: <1355514494.11587.YahooMailClassic@web172304.mail.ir2.yahoo.com>
Message-ID: <A9D3ACF6-11ED-484D-A0C8-E71728307588@me.com>


On Dec 14, 2012, at 1:48 PM, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:

> --- On Fri, 14/12/12, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
>> On 14.12.2012 04:15, Hin-Tak Leung wrote:
>>> --- On Sun, 9/12/12, Dirk Eddelbuettel <edd at debian.org>
>> wrote:
>>> 
>>> <snipped>
>>>> Do you REALLY think svn would not know about
>> missing
>>>> files?  There does not
>>>> seem to be a limit on the disdain for svn among git
>> users.
>>>> Fascinating.
>>> 
>>> FWIW, as one of the linux kernel maintainers, I don't
>> apologize for being familiar with git. I did not decide git
>> as the official tool for maintaining the linux kernel. Linus
>> did.
>>> 
>>> There does not seem to be a limit on the disdain for
>> the linux kernel among debian users.
>>> Fascinating.
>> 
>> 
>> There *is* no limit on the disdain for people discussing
>> off-topic 
>> svn/git/linux disdains on the *R*-devel list among R
>> developers.
> 
> That needs a "Fascinating" exclamation at the end to be genuine and authentic for the typical R developers/debian users.



That's enough of this off-topic subject matter. Take it off list if you wish to continue this dialog.

Any further posts to R-Devel in this vain will not be tolerated.

Marc Schwartz
R-Devel Co-Admin


From pauljohn32 at gmail.com  Fri Dec 14 23:31:43 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 14 Dec 2012 16:31:43 -0600
Subject: [Rd] Found explanation for R-2.15.2 slowdown in one case;
 caution for any users of La_chol
Message-ID: <CAErODj_5cvD78nmC1RBAWGgjKSvPpVwpVsNZMjcQgyjqSraQ3w@mail.gmail.com>

2 days ago, I posted my long message about the observed slowdown in a
package between R-2.15.0 and R-2.15.2.

Uwe Ligges urged me to make a self-contained R example. That was the
encouragement I needed. I tracked the problem down to a failing use of
a LAPACK routine.

R's LAPACK C interface changed one variable in one function. But it
turned out to be an important change.  In case others have code that
is behaving in unexpected says, I'd urge package writers to
double-check their usage of the Cholesky inverse. Here are details:

In R 2.15.0, src/main/lapack.c, we have the prototype:

SEXP La_chol (SEXP A)

BUT in R 2.15.2, the prototype changed:

SEXP La_chol (SEXP A, SEXP pivot)

In the problem case I was studying, the effort to use La_chol was
wrapped in a "try" catch framework, and when Cholesky failed, it fell
back to a singular value decomposition. That's much slower, of course.

Hence the program seemed slower under R-2.15.2, but it was really
failing in a way that I had not noticed.

pj

-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From mtmorgan at fhcrc.org  Sat Dec 15 06:26:55 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 15 Dec 2012 06:26:55 +0100
Subject: [Rd] Strange, most probably unjustified,
 codoc mismatch for S4 method with one argument plus '...' (re-try)
In-Reply-To: <50CAE773.8070004@bioinf.jku.at>
References: <50CAE773.8070004@bioinf.jku.at>
Message-ID: <50CC0A1F.6060504@fhcrc.org>

On 12/14/2012 09:46 AM, Ulrich Bodenhofer wrote:
> Hi,
>
> I just figured out that I accidentally posted my message in HTML, so I am
> retrying in plain text only. Sorry.
>
> I am currently extending one of our CRAN packages and ran into an unexpected
> problem when checking the source package. I got some warnings in the step "*
> checking for code/documentation mismatches". I double checked everything and did
> not see anything that would actually justify this warning. After testing around
> for quite a while, I think I can now pinpoint the problem. In order to make
> myself clear, I need to explain the situation in more detail:
>
> The default method (passed as def argument of setGeneric()) has the formal
> argument list (x, y, ...). Suppose I want to register a method with a signature
> without y, say signature(x="matrix", y="missing"). If I pass a function to
> setMethod() that only has the argument x,i.e. function(x) {...}, everything
> works well. It also works well if I register a function with additional
> arguments, e.g. function(x, dummy=NULL, ...){...} (note: y is missing in the
> definition). However, if I try to register a function with two formal arguments,
> x and '...', i.e.function(x, ...){...}, I get the warning that argument y is
> present in the code but missing in the documentation , although it is actually
> NOT in the code. In order to make this reproducible for everybody, I put
> together a little dummy package in which one of the methods leads to exactly
> this warning:
>
>     http://www.bioinf.jku.at/people/bodenhofer/codocMismatchTest_0.0.1.tar.gz
>
> Just run 'R CMD check' on this archive and you'll see. You will also see from
> the code and the corresponding documentation that the warning seems unjustified.
> I tried the following R versions: 2.12.1, 2.13.0, 2.13.1, 2.14.0, 2.14.1,
> 2.15.0, 2.15.1, 2.15.2, 2.16.0 (devel), and all consistently gave the same warning.
>
> Is this a bug or is there a special reason for this behavior? Any help is
> gratefully appreciated!

In ?setMethod there is this paragraph

      It is possible to have some differences between the formal
      arguments to a method supplied to 'setMethod' and those of the
      generic. Roughly, if the generic has ... as one of its arguments,
      then the method may have extra formal arguments, which will be
      matched from the arguments matching ... in the call to 'f'.  (What

and in practice the expectation is that if a generic has formals x, y, and ..., 
then a method will have formals x, y, and possibly additional arguments. None of 
these methods follow this

setMethod("dummyMethod", signature(x="matrix", y="missing"),
           function(x) {})

setMethod("dummyMethod", signature(x="matrix", y="missing"),
           function(x) {})

setMethod("dummyMethod", signature(x="data.frame", y="missing"),
           function(x, ...) {})

each should have been written as, for instance

     setMethod("dummyMethod", signature(x="matrix", y="missing"),
               function(x, y, ...) {})

The reason for the codoc warning stems from how R represents methods with 
signatures different from their generic, typically when _additional_ arguments 
are used,

      (what
      actually happens is that a local function is created inside the
      method, with the modified formal arguments, and the method is
      re-defined to call that local function.)

So e.g.,

> selectMethod(dummyMethod, c("matrix", "missing"))
Method Definition:

function (x, y, ...)
{
     .local <- function (x)
     {
     }
     .local(x, ...)
}

Signatures:
         x        y
target  "matrix" "missing"
defined "matrix" "missing"

and hence the codoc warning

* checking for code/documentation mismatches ... WARNING
Codoc mismatches from documentation object 'dummyMethod':
\S4method{dummyMethod}{data.frame,missing}
   Code: function(x, y, ...)
   Docs: function(x, ...)
   Argument names in code not in docs:
     y
   Mismatches in argument names:
     Position: 2 Code: y Docs: ...

Your other setMethod

also results in code that likely differs from your expectation, e.g., no 
argument matching by position

     setMethod("dummyMethod", signature(x="list", y="missing"),
               function(x, sel=NULL, ...) {})

 > selectMethod(dummyMethod, signature(x="list", y="missing"))
Method Definition:

function (x, y, ...)
{
     .local <- function (x, sel = NULL, ...)
     {
     }
     .local(x, ...)
}

Signatures:
         x      y
target  "list" "missing"
defined "list" "missing"

Hope that helps,

Martin

 >
>
> Thanks in advance and best regards,
> Ulrich
>
>
> ------------------------------------------------------------------------
> *Dr. Ulrich Bodenhofer*
> Associate Professor
> Institute of Bioinformatics
>
> *Johannes Kepler University*
> Altenberger Str. 69
> 4040 Linz, Austria
>
> Tel. +43 732 2468 4526
> Fax +43 732 2468 4539
> bodenhofer at bioinf.jku.at <mailto:bodenhofer at bioinf.jku.at>
> http://www.bioinf.jku.at/ <http://www.bioinf.jku.at>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From jalvesaq at gmail.com  Sat Dec 15 12:36:13 2012
From: jalvesaq at gmail.com (Jakson Alves de Aquino)
Date: Sat, 15 Dec 2012 08:36:13 -0300
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
Message-ID: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>

Currently the function Rstd_Busy() does nothing (src/unix/sys-std.c):

    void attribute_hidden Rstd_Busy(int which)
    {
    }

The function is called through a pointer and R interfaces can change
this pointer and, thus, use a different function. I don't plan to
create a whole new interface to R, but I maintain a package whose aim
is to provide a new feature to R when it's running in a terminal
emulator on Unix systems:

    http://cran.r-project.org/web/packages/setwidth/index.html

The package setwidth updates the value of options("width") whenever R receives
SIGWINCH signal. The package does not set the value of any interface pointer,
but it may make R crash if the terminal emulator is resized while R is busy. I
could avoid the crash if I knew that R is busy at the moment that it receives
the SIGWINCH. Thus my question is: Could Rstd_Busy() set the value of a
variable so packages like setwidth could know that R is busy? The function
could be changed to something like:

    void attribute_hidden Rstd_Busy(int which)
    {
        R_is_busy = which;
    }

And the R_is_busy variable could be accessed either directly or through a "get"
function, like:

    int get_busy_state(){
        return R_is_busy;
    }

Thanks!

-- 
Jakson Alves de Aquino
Federal University of Cear?
Social Sciences Department
www.lepem.ufc.br/aquino.php


From simon.urbanek at r-project.org  Sat Dec 15 17:09:35 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Dec 2012 11:09:35 -0500
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
Message-ID: <CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>


On Dec 15, 2012, at 6:36 AM, Jakson Alves de Aquino wrote:

> Currently the function Rstd_Busy() does nothing (src/unix/sys-std.c):
> 
>    void attribute_hidden Rstd_Busy(int which)
>    {
>    }
> 
> The function is called through a pointer and R interfaces can change
> this pointer and, thus, use a different function. I don't plan to
> create a whole new interface to R, but I maintain a package whose aim
> is to provide a new feature to R when it's running in a terminal
> emulator on Unix systems:
> 
>    http://cran.r-project.org/web/packages/setwidth/index.html
> 
> The package setwidth updates the value of options("width") whenever R receives
> SIGWINCH signal. The package does not set the value of any interface pointer,
> but it may make R crash if the terminal emulator is resized while R is busy. I
> could avoid the crash if I knew that R is busy at the moment that it receives
> the SIGWINCH. Thus my question is: Could Rstd_Busy() set the value of a
> variable so packages like setwidth could know that R is busy? The function
> could be changed to something like:
> 
>    void attribute_hidden Rstd_Busy(int which)
>    {
>        R_is_busy = which;
>    }
> 
> And the R_is_busy variable could be accessed either directly or through a "get"
> function, like:
> 
>    int get_busy_state(){
>        return R_is_busy;
>    }
> 

You're looking at the wrong spot - the Busy callback is meant for UI signaling that R may enter a longer time of processing, it is not really an indicator that R is busy - R can be busy even without the busy state being signaled.

But back to your original question - there are a few spots where you can process you request : the most obvious one is in the ReadConsole callback - that callback doesn't return until the user has entered a line - this would be a way to a GUI to handle this. The other way is to register an input handler and signal your FD when you get SIGWINCH, that guarantees that your handler will be called as soon as possible after the signal has arrived - that is probably what you want (see CarbonEL for a simple example how this is used).

Cheers,
Simon



> Thanks!
> 
> -- 
> Jakson Alves de Aquino
> Federal University of Cear?
> Social Sciences Department
> www.lepem.ufc.br/aquino.php
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nalimilan at club.fr  Sat Dec 15 17:59:56 2012
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 15 Dec 2012 17:59:56 +0100
Subject: [Rd] R CMD INSTALL warnings with conflicting imports
Message-ID: <1355590796.14652.102.camel@milan>

Hi!

This is an issue we encountered when trying to move the Rcmdr package
from the Depends to the Imports field for RcmrPlugin.* plug-in packages.

Rcmdr overrides a few functions from the tcltk package for convenience.
With the current approach, both Rcmdr and tcltk are in the Depends
field, and no warning is printed. When moving them to Imports, and
adding an import(tcltk, Rcmdr) directive to NAMESPACE, we get this
printed *twice* when running R CMD INSTALL:
> Warning messages:
> 1: replacing previous import ?tclvalue? when loading ?Rcmdr?
> 2: replacing previous import ?tkfocus? when loading ?Rcmdr?
> 3: replacing previous import ?ttkentry? when loading ?Rcmdr?
> 4: replacing previous import ?ttkframe? when loading ?Rcmdr?
> 5: replacing previous import ?ttkradiobutton? when loading ?Rcmdr?
> 6: replacing previous import ?ttkscrollbar? when loading ?Rcmdr?

The solution we found is to use importFrom(tcltk, ...) to only import
tcltk fonctions that do not conflict with those exported by Rcmdr. This
works, but is slightly more painful than the old way, since a typical
plugin uses quite a few tcltk functions.


So I wonder what's the rationale behind the warning. Package maintainers
can perfectly control which package's conflicting functions will
override the other's, by specifying the right order in the import()
directive. If they get the order wrong, the failure will be obvious to
them. It does not seem useful to print warnings when installing
packages, because it's not intended at users. If anything, these
warnings would better be reported by R CMD check only.

If the current situation is judged correct, the solution I describe
works for us. I'd just want to be sure I'm not missing something.

Thanks for your work


From ligges at statistik.tu-dortmund.de  Sat Dec 15 18:44:09 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 15 Dec 2012 18:44:09 +0100
Subject: [Rd] Found explanation for R-2.15.2 slowdown in one case;
 caution for any users of La_chol
In-Reply-To: <CAErODj_5cvD78nmC1RBAWGgjKSvPpVwpVsNZMjcQgyjqSraQ3w@mail.gmail.com>
References: <CAErODj_5cvD78nmC1RBAWGgjKSvPpVwpVsNZMjcQgyjqSraQ3w@mail.gmail.com>
Message-ID: <50CCB6E9.8070800@statistik.tu-dortmund.de>



On 14.12.2012 23:31, Paul Johnson wrote:
> 2 days ago, I posted my long message about the observed slowdown in a
> package between R-2.15.0 and R-2.15.2.
>
> Uwe Ligges urged me to make a self-contained R example. That was the
> encouragement I needed. I tracked the problem down to a failing use of
> a LAPACK routine.
>
> R's LAPACK C interface changed one variable in one function. But it
> turned out to be an important change.  In case others have code that
> is behaving in unexpected says, I'd urge package writers to
> double-check their usage of the Cholesky inverse. Here are details:
>
> In R 2.15.0, src/main/lapack.c, we have the prototype:
>
> SEXP La_chol (SEXP A)
>
> BUT in R 2.15.2, the prototype changed:
>
> SEXP La_chol (SEXP A, SEXP pivot)
>
> In the problem case I was studying, the effort to use La_chol was
> wrapped in a "try" catch framework, and when Cholesky failed, it fell
> back to a singular value decomposition. That's much slower, of course.
>
> Hence the program seemed slower under R-2.15.2, but it was really
> failing in a way that I had not noticed.
>
> pj
>


That is the reason why R CMD check gives a WARNING in the checks of your 
package for quite some time now:


checking foreign function calls ... WARNING

Foreign function calls with 'PACKAGE' argument in a base package:
.Call("La_chol", ..., PACKAGE = "base")
.Call("La_chol2inv", ..., PACKAGE = "base")
Packages should not make .C/.Call/.Fortran calls to base packages. They
are not part of the API, for use only by R itself and subject to change
without notice.


So time to fix that. See also:
http://cran.r-project.org/web/checks/check_results_Amelia.html


Best,
Uwe Ligges


From jalvesaq at gmail.com  Sat Dec 15 20:20:40 2012
From: jalvesaq at gmail.com (Jakson Alves de Aquino)
Date: Sat, 15 Dec 2012 16:20:40 -0300
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
	<CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
Message-ID: <CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>

On Sat, Dec 15, 2012 at 1:09 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Dec 15, 2012, at 6:36 AM, Jakson Alves de Aquino wrote:
>> I could avoid the crash if I knew that R is busy at the moment that
>> it receives the SIGWINCH. Thus my question is: Could Rstd_Busy()
>> set the value of a variable so packages like setwidth could know
>> that R is busy?
>
> You're looking at the wrong spot - the Busy callback is meant for UI
> signaling that R may enter a longer time of processing, it is not
> really an indicator that R is busy - R can be busy even without the
> busy state being signaled.

Thanks for your suggestions!

Although the comment above Rstd_Busy() (at src/unix/sys-std.c) says
"actions during (long) computations", the function is called whenever
any command is entered in R Console.

> But back to your original question - there are a few spots where you
> can process you request : the most obvious one is in the ReadConsole
> callback - that callback doesn't return until the user has entered a
> line - this would be a way to a GUI to handle this.

Both ptr_R_Busy and ptr_R_ReadConsole are declared on Rinterface.h,
but I can't use them because setwidth doesn't provide front-end to R
and Rinterface.h has the following statements:

    This header file is to provide hooks for alternative front-ends,
    e.g. GUIs such as GNOME and Cocoa.  [...] It should not be
    included by package sources unless they are providing such a
    front-end.

> The other way is to register an input handler and signal your FD
> when you get SIGWINCH, that guarantees that your handler will be
> called as soon as possible after the signal has arrived - that is
> probably what you want (see CarbonEL for a simple example how this
> is used).

Based on CarbolEL, I added the following to setwidth_Start() function:

    int fds[2];
    if(pipe(fds))
        Rprintf("pipe > 0\n");
    else
        Rprintf("pipe = 0\n");
    ifd = fds[0];
    ofd = fds[1];
    addInputHandler(R_InputHandlers, ifd, &uih, 32);

And, also based on CarbolEL, I created the following uih() function:

    static void uih(void *data) {
      char buf[16];

      if(read(ifd, buf, 16) == 0){
          Rprintf("read = 0 :: %s\n", buf);
          Rprintf("%d written\n", write(ofd, buf, 16));
      } else {
          Rprintf("read != 0\n");
      }
    }

However, the uih() function never gets called.

Best,

-- 
Jakson Alves de Aquino
Federal University of Cear?
Social Sciences Department
www.lepem.ufc.br/aquino.php


From simon.urbanek at r-project.org  Sat Dec 15 21:41:23 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Dec 2012 15:41:23 -0500
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
	<CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
	<CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>
Message-ID: <77436EA2-B617-4267-9694-B1CCB35FF4B2@r-project.org>


On Dec 15, 2012, at 2:20 PM, Jakson Alves de Aquino wrote:

> On Sat, Dec 15, 2012 at 1:09 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> On Dec 15, 2012, at 6:36 AM, Jakson Alves de Aquino wrote:
>>> I could avoid the crash if I knew that R is busy at the moment that
>>> it receives the SIGWINCH. Thus my question is: Could Rstd_Busy()
>>> set the value of a variable so packages like setwidth could know
>>> that R is busy?
>> 
>> You're looking at the wrong spot - the Busy callback is meant for UI
>> signaling that R may enter a longer time of processing, it is not
>> really an indicator that R is busy - R can be busy even without the
>> busy state being signaled.
> 
> Thanks for your suggestions!
> 
> Although the comment above Rstd_Busy() (at src/unix/sys-std.c) says
> "actions during (long) computations", the function is called whenever
> any command is entered in R Console.
> 
>> But back to your original question - there are a few spots where you
>> can process you request : the most obvious one is in the ReadConsole
>> callback - that callback doesn't return until the user has entered a
>> line - this would be a way to a GUI to handle this.
> 
> Both ptr_R_Busy and ptr_R_ReadConsole are declared on Rinterface.h,
> but I can't use them because setwidth doesn't provide front-end to R
> and Rinterface.h has the following statements:
> 
>    This header file is to provide hooks for alternative front-ends,
>    e.g. GUIs such as GNOME and Cocoa.  [...] It should not be
>    included by package sources unless they are providing such a
>    front-end.
> 
>> The other way is to register an input handler and signal your FD
>> when you get SIGWINCH, that guarantees that your handler will be
>> called as soon as possible after the signal has arrived - that is
>> probably what you want (see CarbonEL for a simple example how this
>> is used).
> 
> Based on CarbolEL, I added the following to setwidth_Start() function:
> 
>    int fds[2];
>    if(pipe(fds))
>        Rprintf("pipe > 0\n");
>    else
>        Rprintf("pipe = 0\n");
>    ifd = fds[0];
>    ofd = fds[1];
>    addInputHandler(R_InputHandlers, ifd, &uih, 32);
> 
> And, also based on CarbolEL, I created the following uih() function:
> 
>    static void uih(void *data) {
>      char buf[16];
> 
>      if(read(ifd, buf, 16) == 0){
>          Rprintf("read = 0 :: %s\n", buf);
>          Rprintf("%d written\n", write(ofd, buf, 16));
>      } else {
>          Rprintf("read != 0\n");
>      }
>    }
> 
> However, the uih() function never gets called.
> 

You didn't provide the signal yet - you have the initialization and receiving end ready - now you need to write the piece that triggers the input.

Cheers,
S


> Best,
> 
> -- 
> Jakson Alves de Aquino
> Federal University of Cear?
> Social Sciences Department
> www.lepem.ufc.br/aquino.php
> 
> 


From jalvesaq at gmail.com  Sat Dec 15 23:32:09 2012
From: jalvesaq at gmail.com (Jakson Alves de Aquino)
Date: Sat, 15 Dec 2012 19:32:09 -0300
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <77436EA2-B617-4267-9694-B1CCB35FF4B2@r-project.org>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
	<CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
	<CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>
	<77436EA2-B617-4267-9694-B1CCB35FF4B2@r-project.org>
Message-ID: <CAGBu4CONPpAh2T=3mzGLf9TEgDCW-3P4x2WKeD76FXV44srspg@mail.gmail.com>

On Sat, Dec 15, 2012 at 5:41 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Dec 15, 2012, at 2:20 PM, Jakson Alves de Aquino wrote:
>
>> On Sat, Dec 15, 2012 at 1:09 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> On Dec 15, 2012, at 6:36 AM, Jakson Alves de Aquino wrote:
>>>> I could avoid the crash if I knew that R is busy at the moment that
>>>> it receives the SIGWINCH. Thus my question is: Could Rstd_Busy()
>>>> set the value of a variable so packages like setwidth could know
>>>> that R is busy?
>>>
>>> You're looking at the wrong spot - the Busy callback is meant for UI
>>> signaling that R may enter a longer time of processing, it is not
>>> really an indicator that R is busy - R can be busy even without the
>>> busy state being signaled.
[...]
>>> The other way is to register an input handler and signal your FD
>>> when you get SIGWINCH, that guarantees that your handler will be
>>> called as soon as possible after the signal has arrived - that is
>>> probably what you want (see CarbonEL for a simple example how this
>>> is used).
>>
>> Based on CarbolEL, I added the following to setwidth_Start() function:
>>
>>    int fds[2];
>>    if(pipe(fds))
>>        Rprintf("pipe > 0\n");
>>    else
>>        Rprintf("pipe = 0\n");
>>    ifd = fds[0];
>>    ofd = fds[1];
>>    addInputHandler(R_InputHandlers, ifd, &uih, 32);
>>
>> And, also based on CarbolEL, I created the following uih() function:
>>
>>    static void uih(void *data) {
>>      char buf[16];
>>
>>      if(read(ifd, buf, 16) == 0){
>>          Rprintf("read = 0 :: %s\n", buf);
>>          Rprintf("%d written\n", write(ofd, buf, 16));
>>      } else {
>>          Rprintf("read != 0\n");
>>      }
>>    }
>>
>> However, the uih() function never gets called.
>>
>
> You didn't provide the signal yet - you have the initialization and
> receiving end ready - now you need to write the piece that triggers
> the input.

It works like a charm now. If handle_winch() is called a hundred times
while R is busy, uih() will also be called a hundred times, but only
when R is no longer busy:

    void handle_winch(int sig){
        signal(SIGWINCH, SIG_IGN);
        char buf[16];
        *buf = 0;
        if(write(ofd, buf, 16) <= 0)
            REprintf("setwidth error: write <= 0\n");
        signal(SIGWINCH, handle_winch);
    }

    static void uih(void *data) {
      char buf[16];
      if(read(ifd, buf, 16) == 0)
          REprintf("setwidth error: read = 0\n");
      R_ToplevelExec(setwidth_Set, NULL);
    }

I added the if(read()) and if(write()) to avoid compiler warnings
about return values not being used.

Thank you very much!

-- 
Jakson Alves de Aquino
Federal University of Cear?
Social Sciences Department
www.lepem.ufc.br/aquino.php


From matloff at cs.ucdavis.edu  Sun Dec 16 01:38:50 2012
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 15 Dec 2012 16:38:50 -0800
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command
 line option --max-cores)
Message-ID: <20121216003850.GB9435@laura>

Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

^ In the 'parallel' package there is detectCores(), which tries its best
^ to infer the number of cores on the current machine.  This is useful
^ if you wish to utilize the *maximum* number of cores on the machine.
^ Several are using this to set the number of cores when parallelizing,
^ sometimes also hardcoded within 3rd-party scripts/package code, but
^ there are several settings where you wish to use fewer, e.g. in a
^ compute cluster where you R session is given only a portion of the
^ cores available.  Because of this, I'd like to propose to add
^ getCores(), which by default returns what detectCores() gives, but can

Even if one has the entire machine to oneself, there is often another
very good reason not to use the maximum number of cores:  Using the
maximum number of cores may reduce performance.  This is true in
general, and sometimes especially true when the inferred number of cores
includes hyperthreading.

Norm


From simon.urbanek at r-project.org  Sun Dec 16 04:49:18 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Dec 2012 22:49:18 -0500
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <CAGBu4CONPpAh2T=3mzGLf9TEgDCW-3P4x2WKeD76FXV44srspg@mail.gmail.com>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
	<CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
	<CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>
	<77436EA2-B617-4267-9694-B1CCB35FF4B2@r-project.org>
	<CAGBu4CONPpAh2T=3mzGLf9TEgDCW-3P4x2WKeD76FXV44srspg@mail.gmail.com>
Message-ID: <954366D2-3EC2-43B3-ABB9-16490F011370@r-project.org>


On Dec 15, 2012, at 5:32 PM, Jakson Alves de Aquino wrote:

> On Sat, Dec 15, 2012 at 5:41 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Dec 15, 2012, at 2:20 PM, Jakson Alves de Aquino wrote:
>> 
>>> On Sat, Dec 15, 2012 at 1:09 PM, Simon Urbanek
>>> <simon.urbanek at r-project.org> wrote:
>>>> On Dec 15, 2012, at 6:36 AM, Jakson Alves de Aquino wrote:
>>>>> I could avoid the crash if I knew that R is busy at the moment that
>>>>> it receives the SIGWINCH. Thus my question is: Could Rstd_Busy()
>>>>> set the value of a variable so packages like setwidth could know
>>>>> that R is busy?
>>>> 
>>>> You're looking at the wrong spot - the Busy callback is meant for UI
>>>> signaling that R may enter a longer time of processing, it is not
>>>> really an indicator that R is busy - R can be busy even without the
>>>> busy state being signaled.
> [...]
>>>> The other way is to register an input handler and signal your FD
>>>> when you get SIGWINCH, that guarantees that your handler will be
>>>> called as soon as possible after the signal has arrived - that is
>>>> probably what you want (see CarbonEL for a simple example how this
>>>> is used).
>>> 
>>> Based on CarbolEL, I added the following to setwidth_Start() function:
>>> 
>>>   int fds[2];
>>>   if(pipe(fds))
>>>       Rprintf("pipe > 0\n");
>>>   else
>>>       Rprintf("pipe = 0\n");
>>>   ifd = fds[0];
>>>   ofd = fds[1];
>>>   addInputHandler(R_InputHandlers, ifd, &uih, 32);
>>> 
>>> And, also based on CarbolEL, I created the following uih() function:
>>> 
>>>   static void uih(void *data) {
>>>     char buf[16];
>>> 
>>>     if(read(ifd, buf, 16) == 0){
>>>         Rprintf("read = 0 :: %s\n", buf);
>>>         Rprintf("%d written\n", write(ofd, buf, 16));
>>>     } else {
>>>         Rprintf("read != 0\n");
>>>     }
>>>   }
>>> 
>>> However, the uih() function never gets called.
>>> 
>> 
>> You didn't provide the signal yet - you have the initialization and
>> receiving end ready - now you need to write the piece that triggers
>> the input.
> 
> It works like a charm now. If handle_winch() is called a hundred times
> while R is busy, uih() will also be called a hundred times, but only
> when R is no longer busy:
> 

Note that you're not using the payload of the pipe at all, so you could simply just send a single byte (not that it matters but you don't need the 16-byte packets).

Also you don't want to send anything if the signal is already enqueued, it's pointless to try to send more (you could clog the pipe), so simply use a flag that you set on write and reset it on read -- if that flag is set you don't write anything. That will make sure that you get only one trigger even if more signals arrived while R is busy.  Everything is synchronous here so no need to worry.

Finally, I wouldn't mess with the signal all the time - just keep it active without touching it and use a flag to avoid re-entrance if you really think it's necessary.

Cheers,
Simon



>    void handle_winch(int sig){
>        signal(SIGWINCH, SIG_IGN);
>        char buf[16];
>        *buf = 0;
>        if(write(ofd, buf, 16) <= 0)
>            REprintf("setwidth error: write <= 0\n");
>        signal(SIGWINCH, handle_winch);
>    }
> 
>    static void uih(void *data) {
>      char buf[16];
>      if(read(ifd, buf, 16) == 0)
>          REprintf("setwidth error: read = 0\n");
>      R_ToplevelExec(setwidth_Set, NULL);
>    }
> 
> I added the if(read()) and if(write()) to avoid compiler warnings
> about return values not being used.
> 
> Thank you very much!
> 
> -- 
> Jakson Alves de Aquino
> Federal University of Cear?
> Social Sciences Department
> www.lepem.ufc.br/aquino.php
> 
> 


From simon.urbanek at r-project.org  Sun Dec 16 04:58:34 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Dec 2012 22:58:34 -0500
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command
	line option --max-cores)
In-Reply-To: <20121216003850.GB9435@laura>
References: <20121216003850.GB9435@laura>
Message-ID: <EEE6FB76-7FF2-47D6-891F-4E2FFF89D175@r-project.org>

On Dec 15, 2012, at 7:38 PM, Norm Matloff wrote:

> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> 
> ^ In the 'parallel' package there is detectCores(), which tries its best
> ^ to infer the number of cores on the current machine.  This is useful
> ^ if you wish to utilize the *maximum* number of cores on the machine.
> ^ Several are using this to set the number of cores when parallelizing,
> ^ sometimes also hardcoded within 3rd-party scripts/package code, but
> ^ there are several settings where you wish to use fewer, e.g. in a
> ^ compute cluster where you R session is given only a portion of the
> ^ cores available.  Because of this, I'd like to propose to add
> ^ getCores(), which by default returns what detectCores() gives, but can
> 
> Even if one has the entire machine to oneself, there is often another
> very good reason not to use the maximum number of cores:  Using the
> maximum number of cores may reduce performance.  This is true in
> general, and sometimes especially true when the inferred number of cores
> includes hyperthreading.
> 

Actually, the converse is often true (it depends on the machine architecture, though - I'm assuming true SMP machines here) -- often it is beneficial to run more threads than cores because the time spent waiting for access outside the CPU can be used by other thread that can continue computing. This is in particular true for parallel because of the setup overhead -- typically the real problem is memory, though. That said, the balance is heavily machine and task dependent so any default will be bad for some cases. Typically, for commodity machines with couple dozen cores it's good to overload, for bigger machines it's bad.

Cheers,
Simon


From matloff at cs.ucdavis.edu  Sun Dec 16 05:19:03 2012
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 15 Dec 2012 20:19:03 -0800
Subject: [Rd] SUGGESTION: Add get/setCores() to 'parallel' (and command
 line option --max-cores)
In-Reply-To: <EEE6FB76-7FF2-47D6-891F-4E2FFF89D175@r-project.org>
References: <20121216003850.GB9435@laura>
	<EEE6FB76-7FF2-47D6-891F-4E2FFF89D175@r-project.org>
Message-ID: <20121216041902.GC10687@laura>

On Sat, Dec 15, 2012 at 10:58:34PM -0500, Simon Urbanek wrote:
> On Dec 15, 2012, at 7:38 PM, Norm Matloff wrote:
 
> > Even if one has the entire machine to oneself, there is often
> > another very good reason not to use the maximum number of cores:
> > Using the maximum number of cores may reduce performance.  This is
> > true in general, and sometimes especially true when the inferred
> > number of cores includes hyperthreading.
 
> Actually, the converse is often true (it depends on the machine
> architecture, though - I'm assuming true SMP machines here) -- often
> it is beneficial to run more threads than cores because the time spent
> waiting for access outside the CPU can be used by other thread that
> can continue computing. This is in particular true for parallel
> because of the setup overhead -- typically the real problem is memory,
> though. That said, the balance is heavily machine and task dependent
> so any default will be bad for some cases. Typically, for commodity
> machines with couple dozen cores it's good to overload, for bigger
> machines it's bad.

Yes, it sometimes is beneficial to run more threads than cores.  But I
"typically" is a rather risky term to use.  As usual, this is very
problem-dependent, and what is "typical" for one person may not be so
for another.  I would speculate, for instance, that most embarrassingly
parallel applications can benefit from some degree of oversubscription,
but even then I wouldn't go out on a limb.

At any rate, the main point for the OP is that there are performance
reasons not to set the number of threads/processors equal to the number
of cores.

Norm


From pauljohn32 at gmail.com  Sun Dec 16 05:29:32 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 15 Dec 2012 22:29:32 -0600
Subject: [Rd] Found explanation for R-2.15.2 slowdown in one case;
 caution for any users of La_chol
In-Reply-To: <50CCB6E9.8070800@statistik.tu-dortmund.de>
References: <CAErODj_5cvD78nmC1RBAWGgjKSvPpVwpVsNZMjcQgyjqSraQ3w@mail.gmail.com>
	<50CCB6E9.8070800@statistik.tu-dortmund.de>
Message-ID: <CAErODj8vXaVc5m1XJHkN6dXHZ+C36XambdN4fy6n0um1y7EftQ@mail.gmail.com>

On Sat, Dec 15, 2012 at 11:44 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 14.12.2012 23:31, Paul Johnson wrote:
>>
> That is the reason why R CMD check gives a WARNING in the checks of your
> package for quite some time now:
>
>
> checking foreign function calls ... WARNING
>
> Foreign function calls with 'PACKAGE' argument in a base package:
> .Call("La_chol", ..., PACKAGE = "base")
> .Call("La_chol2inv", ..., PACKAGE = "base")
> Packages should not make .C/.Call/.Fortran calls to base packages. They
> are not part of the API, for use only by R itself and subject to change
> without notice.
>

Just to be clear. Its not *my* package. It is a package we use A LOT
I had to get to the bottom of the problem. I'm *very glad* to
understand it.

>From a user perspective, I wonder if CRAN could warn me somehow?
Would it be a reasonable wishlist request to have the build process
take a snapshot of warnings and then have the installer play them back
to the user when the package is installed?  That would have saved me
some time this week.

Now, when I install that, I don't see a warning. (see below).

> install.packages("Amelia")
Installing package(s) into ?/home/pauljohn/R/x86_64-pc-linux-gnu-library/2.15?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
trying URL 'http://rweb.quant.ku.edu/cran/src/contrib/Amelia_1.6.3.tar.gz'
Content type 'application/x-gzip' length 1060878 bytes (1.0 Mb)
opened URL
==================================================
downloaded 1.0 Mb

* installing *source* package ?Amelia? ...
** package ?Amelia? successfully unpacked and MD5 sums checked
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
   ?amelia.Rnw?
** testing if installed package can be loaded

* DONE (Amelia)

The downloaded source packages are in
        ?/tmp/Rtmpi0CLZe/downloaded_packages?
>
> So time to fix that. See also:
> http://cran.r-project.org/web/checks/check_results_Amelia.html
>
>
> Best,
> Uwe Ligges
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From jwiley.psych at gmail.com  Sun Dec 16 08:37:48 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 15 Dec 2012 23:37:48 -0800
Subject: [Rd] Found explanation for R-2.15.2 slowdown in one case;
 caution for any users of La_chol
In-Reply-To: <CAErODj8vXaVc5m1XJHkN6dXHZ+C36XambdN4fy6n0um1y7EftQ@mail.gmail.com>
References: <CAErODj_5cvD78nmC1RBAWGgjKSvPpVwpVsNZMjcQgyjqSraQ3w@mail.gmail.com>
	<50CCB6E9.8070800@statistik.tu-dortmund.de>
	<CAErODj8vXaVc5m1XJHkN6dXHZ+C36XambdN4fy6n0um1y7EftQ@mail.gmail.com>
Message-ID: <CANz9Z_Jef8LeoW_WzgSUGhLotVSpRijhZ4=4WaREnmXie18D6Q@mail.gmail.com>

On Sat, Dec 15, 2012 at 8:29 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> On Sat, Dec 15, 2012 at 11:44 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>>
>> That is the reason why R CMD check gives a WARNING in the checks of your
>> package for quite some time now:
>>
>> checking foreign function calls ... WARNING
>>
>> Foreign function calls with 'PACKAGE' argument in a base package:
>> .Call("La_chol", ..., PACKAGE = "base")
>> .Call("La_chol2inv", ..., PACKAGE = "base")
>> Packages should not make .C/.Call/.Fortran calls to base packages. They
>> are not part of the API, for use only by R itself and subject to change
>> without notice.

[snip]

> Now, when I install that, I don't see a warning. (see below).

You won't on an install.  Uwe specifically mentioned Rcmd check which
runs more tests and checks than are done during a simple install.

Rcmd check really does catch a lot (there's even been some noise on
this list that it catches *too much*) so if you're having trouble with
a package, it is probably a reasonable place to start with the most
rigorous set of package checks, and then go from there.

Cheers,

Josh


--
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From jalvesaq at gmail.com  Sun Dec 16 11:56:06 2012
From: jalvesaq at gmail.com (Jakson Alves de Aquino)
Date: Sun, 16 Dec 2012 07:56:06 -0300
Subject: [Rd] Could Rstd_Busy do something (src/unix/sys-std.c)?
In-Reply-To: <954366D2-3EC2-43B3-ABB9-16490F011370@r-project.org>
References: <CAGBu4CNTtEcBEA6yB5tM8JkEDdVyTAr2xC+75Ay+dFM30=BTMg@mail.gmail.com>
	<CDB0FA0A-94E8-4BFA-961F-4ADA4ED04A2F@r-project.org>
	<CAGBu4CPT_wK5xjdFxX0WrF=TxiS8-7zYENZ6FP=XkYVo41yyRg@mail.gmail.com>
	<77436EA2-B617-4267-9694-B1CCB35FF4B2@r-project.org>
	<CAGBu4CONPpAh2T=3mzGLf9TEgDCW-3P4x2WKeD76FXV44srspg@mail.gmail.com>
	<954366D2-3EC2-43B3-ABB9-16490F011370@r-project.org>
Message-ID: <CAGBu4COjqwdMRzNcQNi_a2=oRXv5k2j-eZMNOqBOSJ5nvQA+wQ@mail.gmail.com>

On Sun, Dec 16, 2012 at 12:49 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Note that you're not using the payload of the pipe at all, so you
> could simply just send a single byte (not that it matters but you
> don't need the 16-byte packets).
>
> Also you don't want to send anything if the signal is already
> enqueued, it's pointless to try to send more (you could clog the
> pipe), so simply use a flag that you set on write and reset it on
> read -- if that flag is set you don't write anything. That will make
> sure that you get only one trigger even if more signals arrived
> while R is busy.  Everything is synchronous here so no need to
> worry.
>
> Finally, I wouldn't mess with the signal all the time - just keep it
> active without touching it and use a flag to avoid re-entrance if
> you really think it's necessary.

Thanks for the additional suggestions. It's even better now:

    void handle_winch(int sig){
        if(fired)
            return;
        fired = 1;
        char buf[16];
        *buf = 0;
        if(write(ofd, buf, 1) <= 0)
            REprintf("setwidth error: write <= 0\n");
    }

    static void uih(void *data) {
        char buf[16];
        if(read(ifd, buf, 16) == 0)
            REprintf("setwidth error: read = 0\n");
        R_ToplevelExec(setwidth_Set, NULL);
        fired = 0;
    }

Best,

Jakson


From maiagx at gmail.com  Mon Dec 17 03:05:22 2012
From: maiagx at gmail.com (Charlotte Maia)
Date: Mon, 17 Dec 2012 15:05:22 +1300
Subject: [Rd] Download R
Message-ID: <CAOXcFL0+NXrtoEXfCwNo2vWqhPVRbbES1TwyxBdgRjinSTDZhg@mail.gmail.com>

I use Fedora 10.
I need to update my computer's R version.
I apologise if this has come up before.

The Debian and Ubuntu download links appear reasonably up to date.
The Suse download links appear almost up to date.
Unfortunately, the Fedora download links are from 2008/2009.

http://cran.r-project.org/bin/linux/

Should the Fedora links be removed or updated?


From marc_schwartz at me.com  Mon Dec 17 03:33:19 2012
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sun, 16 Dec 2012 20:33:19 -0600
Subject: [Rd] Download R
In-Reply-To: <CAOXcFL0+NXrtoEXfCwNo2vWqhPVRbbES1TwyxBdgRjinSTDZhg@mail.gmail.com>
References: <CAOXcFL0+NXrtoEXfCwNo2vWqhPVRbbES1TwyxBdgRjinSTDZhg@mail.gmail.com>
Message-ID: <BC7B1D64-1672-4AD4-B9DA-BDA1C8287ED6@me.com>

On Dec 16, 2012, at 8:05 PM, Charlotte Maia <maiagx at gmail.com> wrote:

> I use Fedora 10.
> I need to update my computer's R version.
> I apologise if this has come up before.
> 
> The Debian and Ubuntu download links appear reasonably up to date.
> The Suse download links appear almost up to date.
> Unfortunately, the Fedora download links are from 2008/2009.
> 
> http://cran.r-project.org/bin/linux/
> 
> Should the Fedora links be removed or updated?



Fedora has, for several years now, offered R via the normal Fedora yum repos. Thus, the RPMs are no longer on CRAN. The same for RHEL via the EPEL.

That being said, I presume that you are aware that Fedora 10 was EOL'd back in late 2009. Thus, you have not had any bug fixes, patches, security updates, etc. for 3 years, which tends to obviate the reason for using Fedora, which is a bleeding edge Linux distribution.

Fedora only supports a given release for around 18 months and the current stable release is Fedora 17. I would advise you to upgrade your Fedora version. Once you have, you can use:

  yum install R

from the CLI as root to install R.

Also, there is a dedicated e-mail list for R on Fedora:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Any subsequent questions you have about using R on Fedora should be posted there. General R questions should go to R-Help. More info in the Posting Guide:

  http://www.r-project.org/posting-guide.html

Regards,

Marc Schwartz


From edd at debian.org  Mon Dec 17 03:36:20 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 16 Dec 2012 20:36:20 -0600
Subject: [Rd] Download R
In-Reply-To: <CAOXcFL0+NXrtoEXfCwNo2vWqhPVRbbES1TwyxBdgRjinSTDZhg@mail.gmail.com>
References: <CAOXcFL0+NXrtoEXfCwNo2vWqhPVRbbES1TwyxBdgRjinSTDZhg@mail.gmail.com>
Message-ID: <20686.34084.433449.927197@max.nulle.part>


On 17 December 2012 at 15:05, Charlotte Maia wrote:
| I use Fedora 10.
| I need to update my computer's R version.
| I apologise if this has come up before.
| 
| The Debian and Ubuntu download links appear reasonably up to date.

Right :)

| The Suse download links appear almost up to date.
| Unfortunately, the Fedora download links are from 2008/2009.
| 
| http://cran.r-project.org/bin/linux/
| 
| Should the Fedora links be removed or updated?

There are some recent(-ish) R binaries in the EPEL repositories. I am not at
work now and hence cannot check, but I got a new rmp-based machines up to
speed a while back when I needed to.  

Not sure what to do about the CRAN docs though apart from pleading with
Martyn or whoever looks after the meta-information there.

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From bodenhofer at bioinf.jku.at  Mon Dec 17 09:57:59 2012
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Mon, 17 Dec 2012 09:57:59 +0100
Subject: [Rd] Strange, most probably unjustified,
 codoc mismatch for S4 method with one argument plus '...' (re-try)
In-Reply-To: <50CC0A1F.6060504@fhcrc.org>
References: <50CAE773.8070004@bioinf.jku.at> <50CC0A1F.6060504@fhcrc.org>
Message-ID: <50CEDE97.1020706@bioinf.jku.at>

On 12/15/2012 06:26 AM, Martin Morgan wrote:
>
> In ?setMethod there is this paragraph
>
>      It is possible to have some differences between the formal
>      arguments to a method supplied to 'setMethod' and those of the
>      generic. Roughly, if the generic has ... as one of its arguments,
>      then the method may have extra formal arguments, which will be
>      matched from the arguments matching ... in the call to 'f'. (What
>
> and in practice the expectation is that if a generic has formals x, y, 
> and ..., then a method will have formals x, y, and possibly additional 
> arguments.
Thank you very much for your detailed and very helpful reply, Martin! I 
now understand that all formal arguments of the generic should be 
included in the list of arguments of methods even if one of them is not 
needed. My rationale - obviously, I had not looked into the docu well 
enough - was that I need not declare arguments that were not used in the 
function body anyway. Since I have not gotten a warning so far (until I 
experienced the case in my initial posting), I thought this was right.

So, am I right that the problem is rather that the first and third of 
the definitions

> setMethod("dummyMethod", signature(x="matrix", y="missing"),
>           function(x) {})
>
> setMethod("dummyMethod", signature(x="data.frame", y="missing"),
>           function(x, ...) {})
> setMethod("dummyMethod", signature(x="list", y="missing"),
>               function(x, sel=NULL, ...) {})
do NOT result in a warning although they are not correct either while 
the second one correctly results in a warning?

Thanks and best regards,
Ulrich


From marius.hofert at math.ethz.ch  Mon Dec 17 11:39:03 2012
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Mon, 17 Dec 2012 11:39:03 +0100
Subject: [Rd] Suggestion: 'method' slot for format.ftable()
Message-ID: <877gohotdk.fsf@sklar.v.cablecom.net>

Dear R-developers,

I would like to suggest a 'method' slot for format.ftable() (see an adjusted
'format.ftable()' below, taken from the source of R-2.15.2).

At the moment, format.ftable() contains several empty cells due to the way the
row and column labels are printed. This creates problems (= unwanted empty
columns/rows) when converting an ftable to a LaTeX table; see an example based
on 'xtable' below (I am aware of other packages that can create LaTeX
tables). It would be great to have a 'method' slot with several, more compact
versions. This would be helpful in various contexts (if required, I can provide
more details, including an adjusted .Rd).

Cheers,

Marius



##' @title Adjusted format.ftable() (based on ./src/library/stats/R/ftable.R in R-2.15.2)
##' @param x see ?format.ftable
##' @param quote see ?format.ftable
##' @param digits see ?format.ftable
##' @param method different methods of how the formatted ftable is presented;
##'        currently available are:
##'        "non.compact": the default of format.ftable()
##'        "row.compact": without empty row under the column labels
##'        "col.compact": without empty column to the right of the row labels
##'        "compact"    : without neither empty rows nor columns
##' @param sep separation character of row/col labels for method=="compact"
##' @param ... see ?format.ftable
##' @return see ?format.ftable
format.ftable <- function(x, quote=TRUE, digits=getOption("digits"),
                          method=c("non.compact", "row.compact", "col.compact", "compact"),
                          sep=" \\ ", ...)
{
    if(!inherits(x, "ftable"))
        stop("'x' must be an \"ftable\" object")
    charQuote <- function(s)
        if(quote) paste0("\"", s, "\"") else s
    makeLabels <- function(lst) {
        lens <- sapply(lst, length)
        cplensU <- c(1, cumprod(lens))
        cplensD <- rev(c(1, cumprod(rev(lens))))
        y <- NULL
        for (i in rev(seq_along(lst))) {
            ind <- 1 + seq.int(from = 0, to = lens[i] - 1) * cplensD[i + 1]
            tmp <- character(length = cplensD[i])
            tmp[ind] <- charQuote(lst[[i]])
            y <- cbind(rep(tmp, times = cplensU[i]), y)
        }
        y
    }
    makeNames <- function(x) {
        nmx <- names(x)
        if(is.null(nmx))
            nmx <- rep("", length.out = length(x))
        nmx
    }

    xrv <- attr(x, "row.vars")
    xcv <- attr(x, "col.vars")
    method <- match.arg(method)
    LABS <- switch(method,
                   "non.compact"={ # current default
                       cbind(rbind(matrix("", nrow = length(xcv), ncol = length(xrv)),
                                   charQuote(makeNames(xrv)),
                                   makeLabels(xrv)),
                             c(charQuote(makeNames(xcv)),
                               rep("", times = nrow(x) + 1)))
                   },
                   "row.compact"={ # row-compact version
                       cbind(rbind(matrix("", nrow = length(xcv)-1, ncol = length(xrv)),
                                   charQuote(makeNames(xrv)),
                                   makeLabels(xrv)),
                             c(charQuote(makeNames(xcv)),
                               rep("", times = nrow(x))))
                   },
                   "col.compact"={ # column-compact version
                       cbind(rbind(cbind(matrix("", nrow = length(xcv), ncol = length(xrv)-1),
                                         charQuote(makeNames(xcv))),
                                   charQuote(makeNames(xrv)),
                                   makeLabels(xrv)))
                   },
                   "compact"={ # fully compact version
                       l.xcv <- length(xcv)
                       l.xrv <- length(xrv)
                       xrv.nms <- makeNames(xrv)
                       xcv.nms <- makeNames(xcv)
                       mat <- cbind(rbind(cbind(matrix("", nrow = l.xcv-1, ncol = l.xrv-1),
                                                charQuote(makeNames(xcv[-l.xcv]))),
                                          charQuote(xrv.nms),
                                          makeLabels(xrv)))
                       mat[l.xcv, l.xrv] <- paste(tail(xrv.nms, 1), tail(xcv.nms, 1), sep=sep)
                       mat
                   },
                   stop("wrong method"))
    DATA <- rbind(if(length(xcv)) t(makeLabels(xcv)),
                  if(method == "non.compact" || method == "col.compact") rep("", times = ncol(x)),
                  format(unclass(x), digits = digits))
    cbind(apply(LABS, 2L, format, justify = "left"),
	  apply(DATA, 2L, format, justify = "right"))
}



## toy example
(mdat <- matrix(c(1,20,3, -40, 5, 6), nrow=2, ncol=3, byrow=TRUE,
                dimnames=list(a=c("a1", "a2"), b=c("b1", "b2", "b3"))))
ft <- ftable(mdat) # print.ftable() ~> write.ftable() ~> format.ftable()
format.ftable(ft, quote=FALSE)
format.ftable(ft, quote=FALSE, method="row.compact")
format.ftable(ft, quote=FALSE, method="col.compact")
format.ftable(ft, quote=FALSE, method="compact")

## Titanic data set
ft. <- ftable(Titanic, row.vars=1:2, col.vars=3:4)
format.ftable(ft., quote=FALSE)
format.ftable(ft., quote=FALSE, method="row.compact")
format.ftable(ft., quote=FALSE, method="col.compact")
format.ftable(ft., quote=FALSE, method="compact")

## convert to a LaTeX table via 'xtable'
require(xtable)
## current default
print(xtable(format.ftable(ft., quote=FALSE)),
             floating=FALSE, only.contents=TRUE, hline.after=NULL,
             include.rownames=FALSE, include.colnames=FALSE)
## compact version (=> does not introduce empty columns in the LaTeX table)
print(xtable(format.ftable(ft., quote=FALSE, method="compact")),
             floating=FALSE, only.contents=TRUE, hline.after=NULL,
             include.rownames=FALSE, include.colnames=FALSE)




-- 
Eth Zurich
Dr. Marius Hofert
RiskLab, Department of Mathematics
HG E 65.2
R?mistrasse 101
8092 Zurich
Switzerland

Phone +41 44 632 2423
http://www.math.ethz.ch/~hofertj
GPG key fingerprint 8EF4 5842 0EA2 5E1D 3D7F  0E34 AD4C 566E 655F 3F7C


From mtmorgan at fhcrc.org  Mon Dec 17 16:10:48 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 17 Dec 2012 07:10:48 -0800
Subject: [Rd] Strange, most probably unjustified,
 codoc mismatch for S4 method with one argument plus '...' (re-try)
In-Reply-To: <50CEDE97.1020706@bioinf.jku.at>
References: <50CAE773.8070004@bioinf.jku.at> <50CC0A1F.6060504@fhcrc.org>
	<50CEDE97.1020706@bioinf.jku.at>
Message-ID: <50CF35F8.7010102@fhcrc.org>

On 12/17/2012 12:57 AM, Ulrich Bodenhofer wrote:
> On 12/15/2012 06:26 AM, Martin Morgan wrote:
>>
>> In ?setMethod there is this paragraph
>>
>>      It is possible to have some differences between the formal
>>      arguments to a method supplied to 'setMethod' and those of the
>>      generic. Roughly, if the generic has ... as one of its arguments,
>>      then the method may have extra formal arguments, which will be
>>      matched from the arguments matching ... in the call to 'f'. (What
>>
>> and in practice the expectation is that if a generic has formals x, y, and
>> ..., then a method will have formals x, y, and possibly additional arguments.
> Thank you very much for your detailed and very helpful reply, Martin! I now
> understand that all formal arguments of the generic should be included in the
> list of arguments of methods even if one of them is not needed. My rationale -
> obviously, I had not looked into the docu well enough - was that I need not
> declare arguments that were not used in the function body anyway. Since I have
> not gotten a warning so far (until I experienced the case in my initial
> posting), I thought this was right.
>
> So, am I right that the problem is rather that the first and third of the
> definitions
>
>> setMethod("dummyMethod", signature(x="matrix", y="missing"),
>>           function(x) {})
>>
>> setMethod("dummyMethod", signature(x="data.frame", y="missing"),
>>           function(x, ...) {})
>> setMethod("dummyMethod", signature(x="list", y="missing"),
>>               function(x, sel=NULL, ...) {})
> do NOT result in a warning although they are not correct either while the second
> one correctly results in a warning?

I think they should all generate an error when setMethod is called. Martin

>
> Thanks and best regards,
> Ulrich
>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From dan.ayers at Vanderbilt.Edu  Mon Dec 17 15:37:48 2012
From: dan.ayers at Vanderbilt.Edu (Ayers, Gregory D)
Date: Mon, 17 Dec 2012 14:37:48 +0000
Subject: [Rd] R-devel
Message-ID: <49C1D470875A7946A6415B48FF7EA6F60142F9@ITS-HCWNEM101.ds.vanderbilt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121217/42407eb3/attachment.pl>

From renaud at mancala.cbio.uct.ac.za  Tue Dec 18 08:44:36 2012
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 18 Dec 2012 09:44:36 +0200
Subject: [Rd] Call function only when running via R CMD check?
Message-ID: <50D01EE4.2020706@cbio.uct.ac.za>

Hi Henrik (and list),

I am interested in a similar feature, and would be happy to see the 
suggestions you got off-line :)
Have you come up with a robust solution, which would work in a variety 
of situations (in examples, tests, \Sexpr calls, etc..)?
Thank you.

Bests,
Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


From Andreas.Moeltner at med.uni-heidelberg.de  Tue Dec 18 11:38:19 2012
From: Andreas.Moeltner at med.uni-heidelberg.de (Moeltner, Andreas)
Date: Tue, 18 Dec 2012 10:38:19 +0000
Subject: [Rd] tcltk freezing using MS Windows for R-2.14+
Message-ID: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>

R Version 2.15.0/Windows XP

Maybe this will help to identify the problem (I have similar problems with other tcltk-windows, too.)

Inserting some time delay after tktoplevel helps (on my PC):

> test2GUI <- function(){
>     require(tcltk)
>     MainWindow <- tktoplevel()
Sys.sleep(0.1)
>     topMenu <- tkmenu(MainWindow)
>     tkconfigure(MainWindow,menu=topMenu)
>     tkgrab.set(MainWindow)
>     tkfocus(MainWindow)
>}

Cheers
Andreas





Andreas M?ltner


From hb at biostat.ucsf.edu  Tue Dec 18 13:00:09 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 18 Dec 2012 13:00:09 +0100
Subject: [Rd] Call function only when running via R CMD check?
In-Reply-To: <50D01EE4.2020706@cbio.uct.ac.za>
References: <50D01EE4.2020706@cbio.uct.ac.za>
Message-ID: <CAFDcVCQ5RgSJTh+7eiJNDb7zLf_AZUCBQvD7TkXbYY5r+yNx+g@mail.gmail.com>

Hi Renaud,

On Tue, Dec 18, 2012 at 8:44 AM, Renaud Gaujoux <renaud at cbio.uct.ac.za> wrote:
> Hi Henrik (and list),
>
> I am interested in a similar feature, and would be happy to see the
> suggestions you got off-line :)
> Have you come up with a robust solution, which would work in a variety of
> situations (in examples, tests, \Sexpr calls, etc..)?

see queryRCmdCheck() of R.utils.  Example:

# Get the 'R CMD check' status, if any
status <- R.utils::queryRCmdCheck()

if (status != "notRunning") {
  cat("The current R session was launched by R CMD check. Status:",
status, "\n")
} else {
  cat("The current R session was not launched by R CMD check.\n")
}

I haven't tested it with Sweave, but with examples and tests.

R.utils 1.18.0 is on CRAN, but you'd want 1.18.3, because:

Version: 1.18.3 [2012-11-06]
o BUG FIX: queryRCmdCheck() did not detect "tests" evidences when
  'R CMD check' was testing multiple architectures.

It may be another couple of weeks before I submit it to CRAN, but in
the meanwhile you can grab it via:

source("http://aroma-project.org/hbLite.R");
hbLite("R.utils")

Any feedback (positive or negative) is appreciated.

Hope it helps

/Henrik


> Thank you.
>
> Bests,
> Renaud
>
> --
> Renaud Gaujoux
> Computational Biology - University of Cape Town
> South Africa
>
>


From spencer.graves at prodsyse.com  Tue Dec 18 13:24:57 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 18 Dec 2012 04:24:57 -0800
Subject: [Rd] Call function only when running via R CMD check?
In-Reply-To: <CAFDcVCQ5RgSJTh+7eiJNDb7zLf_AZUCBQvD7TkXbYY5r+yNx+g@mail.gmail.com>
References: <50D01EE4.2020706@cbio.uct.ac.za>
	<CAFDcVCQ5RgSJTh+7eiJNDb7zLf_AZUCBQvD7TkXbYY5r+yNx+g@mail.gmail.com>
Message-ID: <50D06099.9050500@prodsyse.com>

Have you considered the CRAN function in "fda"?  Spencer


On 12/18/2012 4:00 AM, Henrik Bengtsson wrote:
> Hi Renaud,
>
> On Tue, Dec 18, 2012 at 8:44 AM, Renaud Gaujoux <renaud at cbio.uct.ac.za> wrote:
>> Hi Henrik (and list),
>>
>> I am interested in a similar feature, and would be happy to see the
>> suggestions you got off-line :)
>> Have you come up with a robust solution, which would work in a variety of
>> situations (in examples, tests, \Sexpr calls, etc..)?
> see queryRCmdCheck() of R.utils.  Example:
>
> # Get the 'R CMD check' status, if any
> status <- R.utils::queryRCmdCheck()
>
> if (status != "notRunning") {
>    cat("The current R session was launched by R CMD check. Status:",
> status, "\n")
> } else {
>    cat("The current R session was not launched by R CMD check.\n")
> }
>
> I haven't tested it with Sweave, but with examples and tests.
>
> R.utils 1.18.0 is on CRAN, but you'd want 1.18.3, because:
>
> Version: 1.18.3 [2012-11-06]
> o BUG FIX: queryRCmdCheck() did not detect "tests" evidences when
>    'R CMD check' was testing multiple architectures.
>
> It may be another couple of weeks before I submit it to CRAN, but in
> the meanwhile you can grab it via:
>
> source("http://aroma-project.org/hbLite.R");
> hbLite("R.utils")
>
> Any feedback (positive or negative) is appreciated.
>
> Hope it helps
>
> /Henrik
>
>
>> Thank you.
>>
>> Bests,
>> Renaud
>>
>> --
>> Renaud Gaujoux
>> Computational Biology - University of Cape Town
>> South Africa
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From renaud at mancala.cbio.uct.ac.za  Tue Dec 18 13:47:53 2012
From: renaud at mancala.cbio.uct.ac.za (Renaud)
Date: Tue, 18 Dec 2012 14:47:53 +0200
Subject: [Rd] Call function only when running via R CMD check?
In-Reply-To: <50D06099.9050500@prodsyse.com>
References: <50D01EE4.2020706@cbio.uct.ac.za>
	<CAFDcVCQ5RgSJTh+7eiJNDb7zLf_AZUCBQvD7TkXbYY5r+yNx+g@mail.gmail.com>
	<50D06099.9050500@prodsyse.com>
Message-ID: <CAHavPHGc+0QTiyn9ke4AiRT6gsCWPp71sQCq8gtEoN1z-L=mqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121218/d701344a/attachment.pl>

From ggrothendieck at gmail.com  Tue Dec 18 18:27:26 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 18 Dec 2012 12:27:26 -0500
Subject: [Rd] Rtools216.exe on Windows
Message-ID: <CAP01uR=A1cx=QjhBGbm0kz1-yg960vrffWL+0jU2GkJn9V=jrQ@mail.gmail.com>

1. If your PATH is very long then on the Select Additional Tasks
screen in the Rtools installer the two check box titles (Edit the
system PATH and Save version number) will be obscured (i.e. you won't
be able to see them at all) making the screen very confusing. One just
sees two boxes on the left and a long path on the right and has no
idea what it all means.

Also even with a short path the first box will not be aligned with the
"Edit system PATH" phrase making it unclear what it refers to.

Either this should be fixed or if Inno Setup makes it difficult to
change then some verbiage should be placed at the top of the screen
explaining what its all about.

2. It would be useful if Rtools placed the paths it uses in the
registry and possibly also in a batch file too such as:

set RTOOLS_PATH=c:\Rtools\bin;c:\Rtools\gcc-4.6.3\bin

so that other software can readily access it or those not wishing to
permanently change their path have other options.

3. Its not clear from the
http://cran.r-project.org/bin/windows/Rtools/ page where the Rtools
installer source is located.  In the Download section of the
http://cran.r-project.org/bin/windows/Rtools page is a link to
http://cran.r-project.org/bin/windows/Rtools/installer.html but the
source-tools link on that page is broken.

4. Rtools puts find.exe on your PATH which can cause existing software
using the built in find.exe in Windows to malfunction.  As a result
its dangerous to permanently add the Rtools paths to your PATH.

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From keith at wehi.EDU.AU  Wed Dec 19 06:27:51 2012
From: keith at wehi.EDU.AU (Keith)
Date: Wed, 19 Dec 2012 16:27:51 +1100
Subject: [Rd] tcltk freezing using MS Windows for R-2.14+
In-Reply-To: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>
References: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>
Message-ID: <50D15057.6030303@wehi.edu.au>

Andreas,

thanks so much for this clue.

I have found that if I reduced the time in seconds from 0.1 to 0.01 to 
0.001 to 0.0001 I only had problems with freezing on the 0.0001 time.

I tested on Win7(64 bit) on an Intel core i7 870 at 2.93GHz (16GB ram)(8 
cores)
and a WinXP (32bit) Pentium 4 3.01GHz (2GB ram) using 
R-2.15.2(2012-10-26) on both.

I had previously found that the tkgrab.set command seemed to be the one 
actually freezing
so I placed the sleep command just before that with the same result as 
it being just after the tktoplevel command.

I am now going to try it in my packages affylmGUI and limmaGUI, probably 
with a sleep time of 0.1 to be on the safe side,

many thanks,

Keith Satterley

On 18/12/2012 9:38 PM, Moeltner, Andreas wrote:
> R Version 2.15.0/Windows XP
>
> Maybe this will help to identify the problem (I have similar problems with other tcltk-windows, too.)
>
> Inserting some time delay after tktoplevel helps (on my PC):
>
>> test2GUI <- function(){
>>      require(tcltk)
>>      MainWindow <- tktoplevel()
> Sys.sleep(0.1)
>>      topMenu <- tkmenu(MainWindow)
>>      tkconfigure(MainWindow,menu=topMenu)
>>      tkgrab.set(MainWindow)
>>      tkfocus(MainWindow)
>> }
> Cheers
> Andreas
>
>
> Andreas M?ltner


______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From Mark.Bravington at csiro.au  Wed Dec 19 07:01:10 2012
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 19 Dec 2012 17:01:10 +1100
Subject: [Rd] tcltk freezing using MS Windows for R-2.14+
In-Reply-To: <50D15057.6030303@wehi.edu.au>
References: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>
	<50D15057.6030303@wehi.edu.au>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A8BDF684BC13@exvic-mbx04.nexus.csiro.au>

Just a caveat about Sys.sleep() etc style fixes:

I've had long-standing problems with tcltk on Windows in my 'debug' package-- i.e. for at least 7 years. The typical syndrome is that the debug window appears just as an empty frame, which has to be manually minimized/maximized/restored (or some permutation thereof) to get it to work properly. The problem is specific to particular machines, particular R versions (it seemingly went away between about 2.8 and 2.13), and indeed to the complexity of stuff in the debug window (more is often better), so reproducible examples are basically impossible. I've tried numerous times changing the order of creation, inserting random calls to 'tkupdate' and/or 'tkupdate idletasks', inserting Sys.sleep(X), etc. Sometimes they seem to work, for a while--- but then they inevitably don't, on someone's machine for some particular problem. So, sorry to be a wet blanket, but I wouldn't get too excited about the reliability of any fix...

Note that I don't recall anyone reporting problems with 'debug' on Linux--- one reason I'm reasonably sure it's not a problem in my code, despite my not properly understanding tcl/tk. On my own machines (Windows), I long-ago fixed the annoyance by writing a DLL that automatically maximizes-minimizes-restores (or whatever), so it doesn't bother me--- but the solution is not CRAN-friendly. I actually do have a beta version of debug with a series of horrible bodges that *may* solve the problem generally (trying to mimic the minimize-maximize-restore sequence), but it's monkeys-on-typewriters stuff, and experience suggests it probably won't work.

Of course, all this isn't the same as total freezing, but my guess is that the same swamp monster is responsible. I think Peter Dalgaard's comment applies; there's something nasty going on between the tcltk and R "event loops". That's as much as I know, and as much as I want to know, since it's way beyond me to fix--- but I live in hope that someone more heroic may one day be able to! 

bye
Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Keith
> Sent: Wednesday, 19 December 2012 4:28 PM
> To: Moeltner, Andreas
> Cc: raffaele.calogero at gmail.com; 'r-devel at r-project.org'
> Subject: Re: [Rd] tcltk freezing using MS Windows for R-2.14+
> 
> Andreas,
> 
> thanks so much for this clue.
> 
> I have found that if I reduced the time in seconds from 0.1 to 0.01 to
> 0.001 to 0.0001 I only had problems with freezing on the 0.0001 time.
> 
> I tested on Win7(64 bit) on an Intel core i7 870 at 2.93GHz 
> (16GB ram)(8
> cores)
> and a WinXP (32bit) Pentium 4 3.01GHz (2GB ram) using
> R-2.15.2(2012-10-26) on both.
> 
> I had previously found that the tkgrab.set command seemed to 
> be the one actually freezing so I placed the sleep command 
> just before that with the same result as it being just after 
> the tktoplevel command.
> 
> I am now going to try it in my packages affylmGUI and 
> limmaGUI, probably with a sleep time of 0.1 to be on the safe side,
> 
> many thanks,
> 
> Keith Satterley
> 
> On 18/12/2012 9:38 PM, Moeltner, Andreas wrote:
> > R Version 2.15.0/Windows XP
> >
> > Maybe this will help to identify the problem (I have 
> similar problems 
> > with other tcltk-windows, too.)
> >
> > Inserting some time delay after tktoplevel helps (on my PC):
> >
> >> test2GUI <- function(){
> >>      require(tcltk)
> >>      MainWindow <- tktoplevel()
> > Sys.sleep(0.1)
> >>      topMenu <- tkmenu(MainWindow)
> >>      tkconfigure(MainWindow,menu=topMenu)
> >>      tkgrab.set(MainWindow)
> >>      tkfocus(MainWindow)
> >> }
> > Cheers
> > Andreas
> >
> >
> > Andreas M?ltner
> 
> 
> ______________________________________________________________________
> The information in this email is confidential and 
> intend...{{dropped:4}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

From nalimilan at club.fr  Wed Dec 19 10:16:14 2012
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 19 Dec 2012 10:16:14 +0100
Subject: [Rd] tcltk freezing using MS Windows for R-2.14+
In-Reply-To: <50D15057.6030303@wehi.edu.au>
References: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>
	<50D15057.6030303@wehi.edu.au>
Message-ID: <1355908574.2059.21.camel@milan>

Le mercredi 19 d?cembre 2012 ? 16:27 +1100, Keith a ?crit :
> Andreas,
> 
> thanks so much for this clue.
> 
> I have found that if I reduced the time in seconds from 0.1 to 0.01 to 
> 0.001 to 0.0001 I only had problems with freezing on the 0.0001 time.
> 
> I tested on Win7(64 bit) on an Intel core i7 870 at 2.93GHz (16GB ram)(8 
> cores)
> and a WinXP (32bit) Pentium 4 3.01GHz (2GB ram) using 
> R-2.15.2(2012-10-26) on both.
> 
> I had previously found that the tkgrab.set command seemed to be the one 
> actually freezing
> so I placed the sleep command just before that with the same result as 
> it being just after the tktoplevel command.
> 
> I am now going to try it in my packages affylmGUI and limmaGUI, probably 
> with a sleep time of 0.1 to be on the safe side,
> 
> many thanks,
Have you filed a bug in the R bug tracking system, as Duncan suggested
you  back in November? I couldn't find it. This is always useful to keep
track of issues.

I'm interested because I experienced freezes with my R Commander plug-in
on a specific Windows 7 configuration, and I wonder whether it might
indeed be related. So consider this as a "me too". ;-)


Regards


From raffaele.calogero at gmail.com  Wed Dec 19 07:43:28 2012
From: raffaele.calogero at gmail.com (Raffaele Calogero)
Date: Wed, 19 Dec 2012 07:43:28 +0100
Subject: [Rd] tcltk freezing using MS Windows for R-2.14+
In-Reply-To: <50D15057.6030303@wehi.edu.au>
References: <A66205E9BC01644FA7EF2506B21345696825E92D@EXC16.ads.krz.uni-heidelberg.de>
	<50D15057.6030303@wehi.edu.au>
Message-ID: <892ED785-4FA5-4873-BC97-B373DB41EAB2@gmail.com>

That's great!
I will also fix oneChannelGUI.
Thanks a lot!
Raffaele

----------------------------------------
Prof. Raffaele A. Calogero
Bioinformatics and Genomics Unit
MBC Centro di Biotecnologie Molecolari
Via Nizza 52, Torino 10126
Tel.   ++39 0116706457
Fax    ++39 0112366457
Mobile ++39 3333827080
email: raffaele.calogero at unito.it
       raffaele.calogero at gmail.com
www:   http://www.bioinformatica.unito.it



On Dec 19, 2012, at 6:27 AM, Keith <keith at wehi.EDU.AU> wrote:

> Andreas,
> 
> thanks so much for this clue.
> 
> I have found that if I reduced the time in seconds from 0.1 to 0.01 to 0.001 to 0.0001 I only had problems with freezing on the 0.0001 time.
> 
> I tested on Win7(64 bit) on an Intel core i7 870 at 2.93GHz (16GB ram)(8 cores)
> and a WinXP (32bit) Pentium 4 3.01GHz (2GB ram) using R-2.15.2(2012-10-26) on both.
> 
> I had previously found that the tkgrab.set command seemed to be the one actually freezing
> so I placed the sleep command just before that with the same result as it being just after the tktoplevel command.
> 
> I am now going to try it in my packages affylmGUI and limmaGUI, probably with a sleep time of 0.1 to be on the safe side,
> 
> many thanks,
> 
> Keith Satterley
> 
> On 18/12/2012 9:38 PM, Moeltner, Andreas wrote:
>> R Version 2.15.0/Windows XP
>> 
>> Maybe this will help to identify the problem (I have similar problems with other tcltk-windows, too.)
>> 
>> Inserting some time delay after tktoplevel helps (on my PC):
>> 
>>> test2GUI <- function(){
>>>     require(tcltk)
>>>     MainWindow <- tktoplevel()
>> Sys.sleep(0.1)
>>>     topMenu <- tkmenu(MainWindow)
>>>     tkconfigure(MainWindow,menu=topMenu)
>>>     tkgrab.set(MainWindow)
>>>     tkfocus(MainWindow)
>>> }
>> Cheers
>> Andreas
>> 
>> 
>> Andreas M?ltner
> 
> 
> ______________________________________________________________________
> The information in this email is confidential and inte...{{dropped:6}}


From e.sevin at epiconcept.fr  Tue Dec 18 13:48:20 2012
From: e.sevin at epiconcept.fr (=?ISO-8859-1?Q?Etienne_S=E9vin?=)
Date: Tue, 18 Dec 2012 13:48:20 +0100
Subject: [Rd] Scanning a R script for potentially insidious commands
Message-ID: <50D06614.9060404@epiconcept.fr>

Hey all,

We are building a R connector for our web application.
The user can upload a script so it can be executed on the server.

Is there a way to scan the script for insidious commands (writing on the
disk for example) and purge them out?
I guess a simple search is not enough so is there a way to analyse the
pseudo code?

Best,

Etienne


From michael.weylandt at gmail.com  Wed Dec 19 12:28:01 2012
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Wed, 19 Dec 2012 11:28:01 +0000
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <50D06614.9060404@epiconcept.fr>
References: <50D06614.9060404@epiconcept.fr>
Message-ID: <C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>



On Dec 18, 2012, at 12:48 PM, Etienne S?vin <e.sevin at epiconcept.fr> wrote:

> Hey all,
> 
> We are building a R connector for our web application.
> The user can upload a script so it can be executed on the server.
> 
> Is there a way to scan the script for insidious commands (writing on the
> disk for example) and purge them out?

Completely, not that I know of: but grepping for system() and eval() should catch a majority of red flags. 

Michael

> I guess a simple search is not enough so is there a way to analyse the
> pseudo code?
> 
> Best,
> 
> Etienne
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Wed Dec 19 12:39:21 2012
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 19 Dec 2012 12:39:21 +0100
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
Message-ID: <CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121219/9e56c4e5/attachment.pl>

From jttkim at googlemail.com  Wed Dec 19 13:02:11 2012
From: jttkim at googlemail.com (Jan T Kim)
Date: Wed, 19 Dec 2012 12:02:11 +0000
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
Message-ID: <20121219120210.GA4036@paxarchia.galaxy.uni>

On Wed, Dec 19, 2012 at 12:39:21PM +0100, Joris Meys wrote:
> The safest way to prevent attacks using an R connector, is managing the
> permissions for the application on your own server. We do that with the
> RStudio Server application we have running. You have to take into account
> that R allows for many interactions with the system. Also file(), dir(),
> unlink() and all sys. functions have the potential to screen and possibly
> alter your system. Not only system() and eval() pose a security problem...

just out of curiosity, how do you disable these functions? Is there
a way to "blacklist" functions as such in R, regardless of what name
is used to call them? Simple string pattern matching (as I understand
Michael's "grepping" suggestion below) can be circumvented by using
the get function, as in

    s <- paste(letters[i], collapse = "");
    f <- get(s);
    f("insidiouscommand");

where i contains suitable indices to produce "system". So the system
function needs disabling as such, as there are innumerable ways to
code up its invocation.

> How to do this exactly, depends very much on both the server and OS
> settings and the specific R connector you use/build. But don't count on R
> alone to provide safety.

Personally, I'd suggest to consider long and hard whether executing
user submitted R code is really necessary, and if that's the case, my
inclination would be to run that on a virtual machine and sandbox that
as much as you can.

Best regards, Jan


> Cheers
> Joris
> 
> On Wed, Dec 19, 2012 at 12:28 PM, Michael Weylandt <
> michael.weylandt at gmail.com> wrote:
> 
> >
> >
> > On Dec 18, 2012, at 12:48 PM, Etienne S?vin <e.sevin at epiconcept.fr> wrote:
> >
> > > Hey all,
> > >
> > > We are building a R connector for our web application.
> > > The user can upload a script so it can be executed on the server.
> > >
> > > Is there a way to scan the script for insidious commands (writing on the
> > > disk for example) and purge them out?
> >
> > Completely, not that I know of: but grepping for system() and eval()
> > should catch a majority of red flags.
> >
> > Michael
> >
> > > I guess a simple search is not enough so is there a way to analyse the
> > > pseudo code?
> > >
> > > Best,
> > >
> > > Etienne
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 	[[alternative HTML version deleted]]
> 

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From jorismeys at gmail.com  Wed Dec 19 13:38:48 2012
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 19 Dec 2012 13:38:48 +0100
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <20121219120210.GA4036@paxarchia.galaxy.uni>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
Message-ID: <CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121219/d0b4447b/attachment.pl>

From edd at debian.org  Wed Dec 19 14:33:41 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 19 Dec 2012 07:33:41 -0600
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
Message-ID: <20689.49717.671544.744493@max.nulle.part>


Jeroen has a package devoted to the sandboxing approach in conjunction with
the system-level AppArmor facility:  RAppArmor.  See

  http://cran.r-project.org/web/packages/RAppArmor/index.html

and more details at

  https://github.com/jeroenooms/RAppArmor#readme

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From gsee000 at gmail.com  Wed Dec 19 14:37:53 2012
From: gsee000 at gmail.com (G See)
Date: Wed, 19 Dec 2012 07:37:53 -0600
Subject: [Rd] read.csv reads more rows than indicated by wc -l
Message-ID: <CA+xi=qYXfHwKch5a3GwQ6QR4923KU2TLrWmM2xt+AQLtLHy8Yg@mail.gmail.com>

When I have a csv file that is more than 6 lines long, not including
the header, and one of the fields is blank for the last few lines, and
there is an extra comma on of the lines with the blank field,
read.csv() makes creates an extra line.

I attached an example file; I'll also paste the contents here:

A,apple
A,orange
A,orange
A,orange
A,orange
A,,,
A,,

-----
wc -l reports that this file has 7 lines

R> system("wc -l test.csv")
7 test.csv

But, read.csv reads 8.

R> read.csv("test.csv", header=FALSE, stringsAsFactors=FALSE)
  V1     V2
1  A  apple
2  A orange
3  A orange
4  A orange
5  A orange
6  A
7
8  A

If I increase the number of commas at the end of the line, it
increases the number of rows.

This R command to read a 7 line csv:

read.csv(header=FALSE, text="A,apple
A,orange
A,orange
A,orange
A,orange
A,,,,,
A,,")

will produce this:

  V1     V2
1  A  apple
2  A orange
3  A orange
4  A orange
5  A orange
6  A
7
8
9  A


But if the file has fewer than 7 lines, it doesn't increase the number of rows.

This R command to read a 6 line csv:
read.csv(header=FALSE, text="A,apple
A,orange
A,orange
A,orange
A,,,,,
A,,")

will produce this:

  V1     V2 V3 V4 V5 V6
1  A  apple NA NA NA NA
2  A orange NA NA NA NA
3  A orange NA NA NA NA
4  A orange NA NA NA NA
5  A        NA NA NA NA
6  A        NA NA NA NA



Is this intended behavior?

Thanks,
Garrett See

R> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          15.2
year           2012
month          10
day            26
svn rev        61015
language       R
version.string R version 2.15.2 (2012-10-26)
nickname       Trick or Treat

R> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

From simon.urbanek at r-project.org  Wed Dec 19 16:46:52 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 19 Dec 2012 10:46:52 -0500
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
Message-ID: <916A272F-6A1D-47DA-AA77-7D64CE0CEE5B@r-project.org>

On Dec 19, 2012, at 7:38 AM, Joris Meys wrote:

> On Wed, Dec 19, 2012 at 1:02 PM, Jan T Kim <jttkim at googlemail.com> wrote:
> 
>> On Wed, Dec 19, 2012 at 12:39:21PM +0100, Joris Meys wrote:
>>> The safest way to prevent attacks using an R connector, is managing the
>>> permissions for the application on your own server. We do that with the
>>> RStudio Server application we have running. You have to take into account
>>> that R allows for many interactions with the system. Also file(), dir(),
>>> unlink() and all sys. functions have the potential to screen and possibly
>>> alter your system. Not only system() and eval() pose a security
>> problem...
>> 
>> just out of curiosity, how do you disable these functions?
> 
> 
> You got me wrong: We don't disable these functions, we just don't give the
> R instance that's executing the file any permissions on the system. So
> trying to run any function that wants to access the system only results in
> error messages. I believe we did that by creating a specific user account
> and linked that to the R application behind the interface. But sandboxing
> (as you mentioned) is just as good.
> 

Creating a *specific* user is not enough as instances can affect each other (i.e. any job running on such system is in jeopardy - you never know if your results were modified by a malicious process). Rserve allows separate uid/gid per connection so that's one way to tackle that - it also makes the separation easier. As Dirk pointed out on Linux there is AppArmor and sandbox on OS X if you want to limit what the user can do.


And, indeed, trying to filter commands is not the right way as it's trivial to circumvent - anyone with access to R has the capability to run arbitrary native code with .C/.Call and you can't disable that without making R unusable.

Cheers,
Simon



> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From gmbecker at ucdavis.edu  Wed Dec 19 17:21:24 2012
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 19 Dec 2012 08:21:24 -0800
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <20689.49717.671544.744493@max.nulle.part>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
	<20689.49717.671544.744493@max.nulle.part>
Message-ID: <CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121219/a7ccf9ff/attachment.pl>

From bbolker at gmail.com  Wed Dec 19 17:43:22 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 19 Dec 2012 16:43:22 +0000
Subject: [Rd] read.csv reads more rows than indicated by wc -l
References: <CA+xi=qYXfHwKch5a3GwQ6QR4923KU2TLrWmM2xt+AQLtLHy8Yg@mail.gmail.com>
Message-ID: <loom.20121219T173426-186@post.gmane.org>

G See <gsee000 <at> gmail.com> writes:

> 
> When I have a csv file that is more than 6 lines long, not including
> the header, and one of the fields is blank for the last few lines, and
> there is an extra comma on of the lines with the blank field,
> read.csv() makes creates an extra line.
> 
> I attached an example file; I'll also paste the contents here:
> 
> A,apple
> A,orange
> A,orange
> A,orange
> A,orange
> A,,,
> A,,
> 
> -----
> wc -l reports that this file has 7 lines
> 
> R> system("wc -l test.csv")
> 7 test.csv
> 
> But, read.csv reads 8.
> 
> R> read.csv("test.csv", header=FALSE, stringsAsFactors=FALSE)
>   V1     V2
> 1  A  apple
> 2  A orange
> 3  A orange
> 4  A orange
> 5  A orange
> 6  A
> 7
> 8  A
> 
> If I increase the number of commas at the end of the line, it
> increases the number of rows.
> 
> This R command to read a 7 line csv:
> 
> read.csv(header=FALSE, text="A,apple
> A,orange
> A,orange
> A,orange
> A,orange
> A,,,,,
> A,,")
> 
> will produce this:
> 
>   V1     V2
> 1  A  apple
> 2  A orange
> 3  A orange
> 4  A orange
> 5  A orange
> 6  A
> 7
> 8
> 9  A
> 
> But if the file has fewer than 7 lines, it doesn't increase the number of rows.
> 
> This R command to read a 6 line csv:
> read.csv(header=FALSE, text="A,apple
> A,orange
> A,orange
> A,orange
> A,,,,,
> A,,")
> 
> will produce this:
> 
>   V1     V2 V3 V4 V5 V6
> 1  A  apple NA NA NA NA
> 2  A orange NA NA NA NA
> 3  A orange NA NA NA NA
> 4  A orange NA NA NA NA
> 5  A        NA NA NA NA
> 6  A        NA NA NA NA
> 
> Is this intended behavior?
> 
> Thanks,
> Garrett See
 
 [snip]

I don't know if it's exactly *intended* or not, but I think it's
more or less as [IMPLICITLY] documented.  From ?read.table,

     The number of data columns is determined by looking at the first
     five lines of input (or the whole file if it has less than five
     lines), or from the length of ?col.names? if it is specified and
     is longer.  This could conceivably be wrong if ?fill? or
     ?blank.lines.skip? are true, so specify ?col.names? if necessary
     (as in the ?Examples?).

txt <- "A,apple
 A,orange
 A,orange
 A,orange
 A,orange
 A,,,,,
 A,,"
read.csv(header=FALSE, text=txt )

What is happening here is that
(1) read.table is determining from the first five lines that
there are two columns;
(2) when it gets to line six, it reads each set of two fields as a
separate row

If you try

read.csv(header=FALSE, text=txt, fill=FALSE,blank.lines.skip=FALSE)

you at least get an error.

But it gets worse:
    
txt2 <- "A,apple
 A,orange
 A,orange
 A,orange
 A,orange
 A,b,c,d,e,f
 A,g"

read.csv(header=FALSE, text=txt2, fill=FALSE,blank.lines.skip=FALSE)

produces bad results even though fill=FALSE and blank.lines.skip=FALSE ...

Even specifying col.names explicitly doesn't help:

read.csv(header=FALSE, text=txt2, col.names=paste0("V",1:2))

At least count.fields() does detect a problem ...

count.fields(textConnection(txt2),sep=",")

Somewhere on my wish/TO DO list is for someone to rewrite read.table for
better robustness *and* efficiency ...


From simon.urbanek at r-project.org  Wed Dec 19 18:12:07 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 19 Dec 2012 12:12:07 -0500
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
	<20689.49717.671544.744493@max.nulle.part>
	<CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>
Message-ID: <52342EBD-789E-4048-AA05-30A44C535321@r-project.org>

On Dec 19, 2012, at 11:21 AM, Gabriel Becker wrote:

> See also: https://github.com/Rapporter/sandboxR
> 
> sandboxR (not written by me) is a proof of concept for security inside R
> (as opposed to security outside R as discussed above) via evaluating all R
> commands in a specialized security environment (R environment that is)
> which contains safe replacements for blacklisted functions.
> 

It is a good example of false security. For the reasons mentioned before this doesn't work and can be circumvented:

> sandbox("XXXX('tail /etc/group')")
_developer:*:204:
_locationd:*:205:
_carddav:*:206:
_detachedsig:*:207:
_trustevaluationagent:*:208:
_odchpass:*:209:
_timezone:*:210:
_lda:*:211:
_cvms:*:212:
_usbmuxd:*:213:
[1] 0

The problem is that you can try to plug holes (and sandboxR is trying hard to plug a lot of them), but there will always be new ones. It's simply the wrong approach IMHO.

Cheers,
Simon



> HTH,
> ~G
> 
> 
> 
> On Wed, Dec 19, 2012 at 5:33 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
>> 
>> Jeroen has a package devoted to the sandboxing approach in conjunction with
>> the system-level AppArmor facility:  RAppArmor.  See
>> 
>>  http://cran.r-project.org/web/packages/RAppArmor/index.html
>> 
>> and more details at
>> 
>>  https://github.com/jeroenooms/RAppArmor#readme
>> 
>> Dirk
>> 
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From gmbecker at ucdavis.edu  Wed Dec 19 19:09:03 2012
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 19 Dec 2012 10:09:03 -0800
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <52342EBD-789E-4048-AA05-30A44C535321@r-project.org>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
	<20689.49717.671544.744493@max.nulle.part>
	<CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>
	<52342EBD-789E-4048-AA05-30A44C535321@r-project.org>
Message-ID: <CADwqtCMoPhpBZobqtKQdn9DN9Cx=JB48psk6A5gPd-XkWScjFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121219/4122aeac/attachment.pl>

From simon.urbanek at r-project.org  Wed Dec 19 19:10:43 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 19 Dec 2012 13:10:43 -0500
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <CADwqtCMoPhpBZobqtKQdn9DN9Cx=JB48psk6A5gPd-XkWScjFg@mail.gmail.com>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
	<20689.49717.671544.744493@max.nulle.part>
	<CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>
	<52342EBD-789E-4048-AA05-30A44C535321@r-project.org>
	<CADwqtCMoPhpBZobqtKQdn9DN9Cx=JB48psk6A5gPd-XkWScjFg@mail.gmail.com>
Message-ID: <5780E08D-BEA6-45A8-8E09-ACB0E751909C@r-project.org>

On Dec 19, 2012, at 1:09 PM, Gabriel Becker wrote:

> Simon,
> 
> I don't really have a horse in this race (as I said I didn't write sandboxR), but it seems like if you control library (to prevent "untrusted" packages, specifically including things like Rcpp and Rffi), and dyn.load the executing arbitrary compiled code issue can be curtailed. If I'm wrong please let me know, I'm always looking to learn.
> 
> I assume XXXX in your example was some C code you whipped up and then loaded using one of the methods above? Or a .Call to an existing internal R function?
> 

No, it's pure R code, I just didn't want to put the exploit on the list ...

Cheers,
S


> ~G
> 
> On Wed, Dec 19, 2012 at 9:12 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> On Dec 19, 2012, at 11:21 AM, Gabriel Becker wrote:
> 
> > See also: https://github.com/Rapporter/sandboxR
> >
> > sandboxR (not written by me) is a proof of concept for security inside R
> > (as opposed to security outside R as discussed above) via evaluating all R
> > commands in a specialized security environment (R environment that is)
> > which contains safe replacements for blacklisted functions.
> >
> 
> It is a good example of false security. For the reasons mentioned before this doesn't work and can be circumvented:
> 
> > sandbox("XXXX('tail /etc/group')")
> _developer:*:204:
> _locationd:*:205:
> _carddav:*:206:
> _detachedsig:*:207:
> _trustevaluationagent:*:208:
> _odchpass:*:209:
> _timezone:*:210:
> _lda:*:211:
> _cvms:*:212:
> _usbmuxd:*:213:
> [1] 0
> 
> The problem is that you can try to plug holes (and sandboxR is trying hard to plug a lot of them), but there will always be new ones. It's simply the wrong approach IMHO.
> 
> Cheers,
> Simon
> 
> 
> 
> > HTH,
> > ~G
> >
> >
> >
> > On Wed, Dec 19, 2012 at 5:33 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> >>
> >> Jeroen has a package devoted to the sandboxing approach in conjunction with
> >> the system-level AppArmor facility:  RAppArmor.  See
> >>
> >>  http://cran.r-project.org/web/packages/RAppArmor/index.html
> >>
> >> and more details at
> >>
> >>  https://github.com/jeroenooms/RAppArmor#readme
> >>
> >> Dirk
> >>
> >> --
> >> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
> > --
> > Gabriel Becker
> > Graduate Student
> > Statistics Department
> > University of California, Davis
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> 


From simon.urbanek at r-project.org  Wed Dec 19 19:47:21 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 19 Dec 2012 13:47:21 -0500
Subject: [Rd] Scanning a R script for potentially insidious commands
In-Reply-To: <5780E08D-BEA6-45A8-8E09-ACB0E751909C@r-project.org>
References: <50D06614.9060404@epiconcept.fr>
	<C388E3C2-611A-4717-8049-D72867AB8BCB@gmail.com>
	<CAO1zAVbqQXsBEz7Uvdjqi0FxE2NxMb3fTZ5MuEFgn3KSaLb_xw@mail.gmail.com>
	<20121219120210.GA4036@paxarchia.galaxy.uni>
	<CAO1zAVaXwrt_f1LN29kJz-2XvoOYn5rz-EuuHnqYfXWrL2sJPg@mail.gmail.com>
	<20689.49717.671544.744493@max.nulle.part>
	<CADwqtCM_OB_HqQ1bHYzKfN00NH41+PGyT0_HcC3aQhSv0TDp0A@mail.gmail.com>
	<52342EBD-789E-4048-AA05-30A44C535321@r-project.org>
	<CADwqtCMoPhpBZobqtKQdn9DN9Cx=JB48psk6A5gPd-XkWScjFg@mail.gmail.com>
	<5780E08D-BEA6-45A8-8E09-ACB0E751909C@r-project.org>
Message-ID: <75EE7C31-DE17-4981-99DC-6DD776B898B8@r-project.org>

On Dec 19, 2012, at 1:10 PM, Simon Urbanek wrote:

> On Dec 19, 2012, at 1:09 PM, Gabriel Becker wrote:
> 
>> Simon,
>> 
>> I don't really have a horse in this race (as I said I didn't write sandboxR), but it seems like if you control library (to prevent "untrusted" packages, specifically including things like Rcpp and Rffi), and dyn.load the executing arbitrary compiled code issue can be curtailed. If I'm wrong please let me know, I'm always looking to learn.
>> 
>> I assume XXXX in your example was some C code you whipped up and then loaded using one of the methods above? Or a .Call to an existing internal R function?
>> 
> 
> No, it's pure R code, I just didn't want to put the exploit on the list ...
> 

I just found another exploit that is harder to catch than the fist one. Both work by giving you unrestricted access directly to any function in any namespace or environment. The first one consists of 15 chars + the function name, the second takes 33 characters + function name (both work on base R, no extra packages needed). They use two entirely separate aspects of R to do it. I don't want to make this an exploit contest, I'm just trying to make the point that you cannot try to secure R by any kind of filtering or pre-processing, because the language is too flexible to make you feel secure. I would strongly discourage anyone from providing an open service that relies on filtering. There is a fairly high probability that the will be a way around it. That's why all realistic approaches work on the back-end.

Cheers,
Simon


> 
>> ~G
>> 
>> On Wed, Dec 19, 2012 at 9:12 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> On Dec 19, 2012, at 11:21 AM, Gabriel Becker wrote:
>> 
>>> See also: https://github.com/Rapporter/sandboxR
>>> 
>>> sandboxR (not written by me) is a proof of concept for security inside R
>>> (as opposed to security outside R as discussed above) via evaluating all R
>>> commands in a specialized security environment (R environment that is)
>>> which contains safe replacements for blacklisted functions.
>>> 
>> 
>> It is a good example of false security. For the reasons mentioned before this doesn't work and can be circumvented:
>> 
>>> sandbox("XXXX('tail /etc/group')")
>> _developer:*:204:
>> _locationd:*:205:
>> _carddav:*:206:
>> _detachedsig:*:207:
>> _trustevaluationagent:*:208:
>> _odchpass:*:209:
>> _timezone:*:210:
>> _lda:*:211:
>> _cvms:*:212:
>> _usbmuxd:*:213:
>> [1] 0
>> 
>> The problem is that you can try to plug holes (and sandboxR is trying hard to plug a lot of them), but there will always be new ones. It's simply the wrong approach IMHO.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>> HTH,
>>> ~G
>>> 
>>> 
>>> 
>>> On Wed, Dec 19, 2012 at 5:33 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>> 
>>>> 
>>>> Jeroen has a package devoted to the sandboxing approach in conjunction with
>>>> the system-level AppArmor facility:  RAppArmor.  See
>>>> 
>>>> http://cran.r-project.org/web/packages/RAppArmor/index.html
>>>> 
>>>> and more details at
>>>> 
>>>> https://github.com/jeroenooms/RAppArmor#readme
>>>> 
>>>> Dirk
>>>> 
>>>> --
>>>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> Gabriel Becker
>>> Graduate Student
>>> Statistics Department
>>> University of California, Davis
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
>> 
>> 
>> -- 
>> Gabriel Becker
>> Graduate Student
>> Statistics Department
>> University of California, Davis
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From maechler at stat.math.ethz.ch  Thu Dec 20 22:05:16 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 20 Dec 2012 22:05:16 +0100
Subject: [Rd] Suggestion: 'method' slot for format.ftable()
In-Reply-To: <877gohotdk.fsf@sklar.v.cablecom.net>
References: <877gohotdk.fsf@sklar.v.cablecom.net>
Message-ID: <20691.32140.189921.534398@stat.math.ethz.ch>

>>>>> Marius Hofert <marius.hofert at math.ethz.ch>
>>>>>     on Mon, 17 Dec 2012 11:39:03 +0100 writes:

    > Dear R-developers, I would like to suggest a 'method' slot
    > for format.ftable() (see an adjusted 'format.ftable()'
    > below, taken from the source of R-2.15.2).

    > At the moment, format.ftable() contains several empty
    > cells due to the way the row and column labels are
    > printed. This creates problems (= unwanted empty
    > columns/rows) when converting an ftable to a LaTeX table;
    > see an example based on 'xtable' below (I am aware of
    > other packages that can create LaTeX tables). It would be
    > great to have a 'method' slot with several, more compact
    > versions. This would be helpful in various contexts (if
    > required, I can provide more details, including an
    > adjusted .Rd).

Dear Marius, this sounds interesting and relevant,
and clearly is 100% back-compatible, so I am planning to adopt
it (with very very slight changes, nothing semantic).

Yes, indeed, for the help page, please provide
a patch against the *current* version, i.e.

  https://svn.r-project.org/R/trunk/src/library/stats/man/read.ftable.Rd

Thank you for your contribution!
Regards,
Martin



    > ##' @title Adjusted format.ftable() (based on ./src/library/stats/R/ftable.R in R-2.15.2)
    > ##' @param x see ?format.ftable
    > ##' @param quote see ?format.ftable
    > ##' @param digits see ?format.ftable
    > ##' @param method different methods of how the formatted ftable is presented;
    > ##'        currently available are:
    > ##'        "non.compact": the default of format.ftable()
    > ##'        "row.compact": without empty row under the column labels
    > ##'        "col.compact": without empty column to the right of the row labels
    > ##'        "compact"    : without neither empty rows nor columns
    > ##' @param sep separation character of row/col labels for method=="compact"
    > ##' @param ... see ?format.ftable
    > ##' @return see ?format.ftable
    > format.ftable <- function(x, quote=TRUE, digits=getOption("digits"),
    > method=c("non.compact", "row.compact", "col.compact", "compact"),
    > sep=" \\ ", ...)
    > {
    > if(!inherits(x, "ftable"))
    > stop("'x' must be an \"ftable\" object")
    > charQuote <- function(s)
    > if(quote) paste0("\"", s, "\"") else s
    > makeLabels <- function(lst) {
    > lens <- sapply(lst, length)
    > cplensU <- c(1, cumprod(lens))
    > cplensD <- rev(c(1, cumprod(rev(lens))))
    > y <- NULL
    > for (i in rev(seq_along(lst))) {
    > ind <- 1 + seq.int(from = 0, to = lens[i] - 1) * cplensD[i + 1]
    > tmp <- character(length = cplensD[i])
    > tmp[ind] <- charQuote(lst[[i]])
    > y <- cbind(rep(tmp, times = cplensU[i]), y)
    > }
    > y
    > }
    > makeNames <- function(x) {
    > nmx <- names(x)
    > if(is.null(nmx))
    > nmx <- rep("", length.out = length(x))
    > nmx
    > }

    > xrv <- attr(x, "row.vars")
    > xcv <- attr(x, "col.vars")
    > method <- match.arg(method)
    > LABS <- switch(method,
    > "non.compact"={ # current default
    > cbind(rbind(matrix("", nrow = length(xcv), ncol = length(xrv)),
    > charQuote(makeNames(xrv)),
    > makeLabels(xrv)),
    > c(charQuote(makeNames(xcv)),
    > rep("", times = nrow(x) + 1)))
    > },
    > "row.compact"={ # row-compact version
    > cbind(rbind(matrix("", nrow = length(xcv)-1, ncol = length(xrv)),
    > charQuote(makeNames(xrv)),
    > makeLabels(xrv)),
    > c(charQuote(makeNames(xcv)),
    > rep("", times = nrow(x))))
    > },
    > "col.compact"={ # column-compact version
    > cbind(rbind(cbind(matrix("", nrow = length(xcv), ncol = length(xrv)-1),
    > charQuote(makeNames(xcv))),
    > charQuote(makeNames(xrv)),
    > makeLabels(xrv)))
    > },
    > "compact"={ # fully compact version
    > l.xcv <- length(xcv)
    > l.xrv <- length(xrv)
    > xrv.nms <- makeNames(xrv)
    > xcv.nms <- makeNames(xcv)
    > mat <- cbind(rbind(cbind(matrix("", nrow = l.xcv-1, ncol = l.xrv-1),
    > charQuote(makeNames(xcv[-l.xcv]))),
    > charQuote(xrv.nms),
    > makeLabels(xrv)))
    > mat[l.xcv, l.xrv] <- paste(tail(xrv.nms, 1), tail(xcv.nms, 1), sep=sep)
    > mat
    > },
    > stop("wrong method"))
    > DATA <- rbind(if(length(xcv)) t(makeLabels(xcv)),
    > if(method == "non.compact" || method == "col.compact") rep("", times = ncol(x)),
    > format(unclass(x), digits = digits))
    > cbind(apply(LABS, 2L, format, justify = "left"),
    > apply(DATA, 2L, format, justify = "right"))
    > }



    > ## toy example
    > (mdat <- matrix(c(1,20,3, -40, 5, 6), nrow=2, ncol=3, byrow=TRUE,
    > dimnames=list(a=c("a1", "a2"), b=c("b1", "b2", "b3"))))
    > ft <- ftable(mdat) # print.ftable() ~> write.ftable() ~> format.ftable()
    > format.ftable(ft, quote=FALSE)
    > format.ftable(ft, quote=FALSE, method="row.compact")
    > format.ftable(ft, quote=FALSE, method="col.compact")
    > format.ftable(ft, quote=FALSE, method="compact")

    > ## Titanic data set
    > ft. <- ftable(Titanic, row.vars=1:2, col.vars=3:4)
    > format.ftable(ft., quote=FALSE)
    > format.ftable(ft., quote=FALSE, method="row.compact")
    > format.ftable(ft., quote=FALSE, method="col.compact")
    > format.ftable(ft., quote=FALSE, method="compact")

    > ## convert to a LaTeX table via 'xtable'
    > require(xtable)
    > ## current default
    > print(xtable(format.ftable(ft., quote=FALSE)),
    > floating=FALSE, only.contents=TRUE, hline.after=NULL,
    > include.rownames=FALSE, include.colnames=FALSE)
    > ## compact version (=> does not introduce empty columns in the LaTeX table)
    > print(xtable(format.ftable(ft., quote=FALSE, method="compact")),
    > floating=FALSE, only.contents=TRUE, hline.after=NULL,
    > include.rownames=FALSE, include.colnames=FALSE)




    > -- 
    > Eth Zurich
    > Dr. Marius Hofert
    > RiskLab, Department of Mathematics
    > HG E 65.2
    > R?mistrasse 101
    > 8092 Zurich
    > Switzerland

    > Phone +41 44 632 2423
    > http://www.math.ethz.ch/~hofertj
    > GPG key fingerprint 8EF4 5842 0EA2 5E1D 3D7F  0E34 AD4C 566E 655F 3F7C

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Thu Dec 20 22:14:13 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 20 Dec 2012 22:14:13 +0100
Subject: [Rd] How to make an <pkg>/configure file executable on Windows/NTFS?
Message-ID: <CAFDcVCRkkFkCb+wZyhY5cDai5fiGedieLR+E-Fb40FDW9xNAyg@mail.gmail.com>

Hi,

in my package, I've got a 'configure' file in the root, e.g.
aroma.affymetrix/configure. (I've also got a configure.win, which
works just fine on Windows). This file must be executable (has a
proper file mode) for 'R CMD INSTALL'/install.packages() to work,
otherwise one gets:

* installing *source* package 'aroma.affymetrix' ...
ERROR: 'configure' exists but is not executable -- see the 'R
Installation and Administration Manual'

*** I build my packages/tar balls on Windows.  Is there are way to
build it such that aroma.affymetrix/configure is executable?


*** Looking at the code
(http://svn.r-project.org/R/trunk/src/library/tools/R/install.R),
there is

if (file_test("-x", "configure")) {
  cmd <- paste(paste(configure_vars, collapse = " "), "./configure",
paste(configure_args, collapse = " "))
  if (debug) message("configure command: ", sQuote(cmd), domain = NA)
  res <- system(cmd)
  if (res) pkgerrmsg("configuration failed", pkg_name)
}  else if (file.exists("configure"))
  errmsg("'configure' exists but is not executable -- see the 'R
Installation and Administration Manual'")

Would it be possible to automatically try to update the file
permissions if not enough, e.g.

if (file_test("-x", "configure")) Sys,chmod("configure", mode="777")
if (file_test("-x", "configure")) {
  ...
}  else if (file.exists("configure"))
  errmsg("'configure' exists but is not executable -- see the 'R
Installation and Administration Manual'")

This would solve the practical problem of not being able to(?) build
tar balls with an executable configure on Windows.  I can also see
how this avoids problems where the file mode on an SVN repository
(think R-forge etc) is overridden by a user on, say, Windows.


*** Related, what about adding support for a cross-platform
<pkg>/configure.R script that is executed by R/Rscript during
installation?

Thank you,

Henrik


From mdowle at mdowle.plus.com  Fri Dec 21 00:46:39 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 20 Dec 2012 23:46:39 +0000
Subject: [Rd] read.csv reads more rows than indicated by wc -l
Message-ID: <4c9a8cbdeb99b562a05db96a02041cb7@imap.plus.net>


Ben,

> Somewhere on my wish/TO DO list is for someone to rewrite read.table 
> for
> better robustness *and* efficiency ...

Wish granted. New in data.table 1.8.7 :

=====
New function fread(), a fast and friendly file reader.
*  header, skip, nrows, sep and colClasses are all auto detected.
*  integers>2^31 are detected and read natively as bit64::integer64.
*  accepts filenames, URLs and "A,B\n1,2\n3,4" directly
*  new implementation entirely in C
*  with a 50MB .csv, 1 million rows x 6 columns :
      read.csv("test.csv")                                        # 
30-60 sec
      read.table("test.csv",<all known tricks and known nrows>)   #    
10 sec
      fread("test.csv")                                           #     
3 sec
* airline data: 658MB csv (7 million rows x 29 columns)
      read.table("2008.csv",<all known tricks and known nrows>)   #   
360 sec
      fread("2008.csv")                                           #    
50 sec
See ?fread. Many thanks to Chris Neff and Garrett See for ideas, 
discussions
and beta testing.
=====

The help page ?fread is fairly well developed :
https://r-forge.r-project.org/scm/viewvc.php/pkg/man/fread.Rd?view=markup&root=datatable

Comments, feedback and bug reports very welcome.

Matthew

http://datatable.r-forge.r-project.org/


From mtmorgan at fhcrc.org  Fri Dec 21 03:11:07 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 20 Dec 2012 18:11:07 -0800
Subject: [Rd] improved methods error
Message-ID: <50D3C53B.3070303@fhcrc.org>

While trying to install a package, I received this error

** preparing package for lazy loading
Error in matchSignature(signature, fdef, where) :
   more elements in the method signature (2) than in the generic  signature (1)

A more helpful variant is

Error in matchSignature(signature, fdef, where) :
   more elements in the method signature (2) than in the generic signature (1) 
for function 'sort'

which comes from (including removal of an extra space between 'generic' and 
'signature'; I'm not sure what diff I should be providing for the po files?)

===================================================================
--- src/library/methods/R/MethodsList.R	(revision 61375)
+++ src/library/methods/R/MethodsList.R	(working copy)
@@ -528,9 +528,10 @@
      if(is.null(names(signature))) {
          which <- seq_along(signature)
          if(length(which) > length(anames))
-          stop(gettextf("more elements in the method signature (%d) than in the 
generic  signature (%d)",
+          stop(gettextf("more elements in the method signature (%d) than in the 
generic signature (%d) for function %s",
                 length(which),
-               length(anames)), domain = NA)
+               length(anames),
+               sQuote(fun at generic)), domain = NA)
      }
      else {
      ## construct a function call with the same naming pattern  &


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From maechler at stat.math.ethz.ch  Fri Dec 21 08:42:46 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Dec 2012 08:42:46 +0100
Subject: [Rd] improved methods error
In-Reply-To: <50D3C53B.3070303@fhcrc.org>
References: <50D3C53B.3070303@fhcrc.org>
Message-ID: <20692.4854.666648.592364@stat.math.ethz.ch>

>>>>> Martin Morgan <mtmorgan at fhcrc.org>
>>>>>     on Thu, 20 Dec 2012 18:11:07 -0800 writes:

    > While trying to install a package, I received this error
    > ** preparing package for lazy loading
    > Error in matchSignature(signature, fdef, where) :
    > more elements in the method signature (2) than in the generic  signature (1)

    > A more helpful variant is

    > Error in matchSignature(signature, fdef, where) :
    > more elements in the method signature (2) than in the generic signature (1) 
    > for function 'sort'

You are right.
Thank you, Martin, for the patch ... [ --> R-devel revision 61376 ]

Martin Maechler


From prawin.pop at gmail.com  Fri Dec 21 11:46:50 2012
From: prawin.pop at gmail.com (Praveen Kumar)
Date: Fri, 21 Dec 2012 02:46:50 -0800 (PST)
Subject: [Rd] rJava is not working in Solaris through java
Message-ID: <1356086810836-4653701.post@n4.nabble.com>

Hi,

we have installed R in solaris 10 sparc machine. After installing R we have
installed rJava package and we did a sample test using R prompt it worked
well. We have written sample Java class to calculate GLM and LM functions.
When we execute the sample java class it returns null for both the
functions. But both the functions are working fine in R console.

sample java class code.



import org.rosuda.JRI.REXP;
import org.rosuda.JRI.RVector;
import org.rosuda.JRI.Rengine;


public class rtest {
        static Rengine re;
 
        public static void main(String []a)
        {
                try
                {
                        re = new Rengine(a, false, null);
                        REXP x11 = re.eval("a<-sample(1:1000,300)");
                        REXP x12 =  re.eval("b<-sample(1:1000,300)");
                        REXP x13 =  re.eval("d<-sample(1:1000,300)");
                        REXP x14 =  re.eval("f<-runif(1:300)");
                        re.eval("value<-glm(f~a+b+d,family=binomial)");
                        REXP x1 = re.eval("value");
                        REXP x2 = re.eval("coef(value)");
                        System.out.println(x1);
                        System.out.println(x2);
                        REXP x111 = re.eval("aa<-c(5,1,3,4,2)");
                        REXP x112 =  re.eval("bb<-c(7,8,6,9,4)");
                        REXP x113 =  re.eval("dd<-c(1,0,1,0,1)");
                        REXP x114 =  re.eval("lm(dd~aa+bb)");
                        System.out.println(x111);
                        System.out.println(x112);
                        System.out.println(x113);
                        System.out.println(x114);
        }
                catch(Exception e)
                {
                        e.printStackTrace();
                        re.end();
                        //s.end();
                }
                finally
                {
                        re.end();
                        //s.end();
                       
                }
        }

}


Thanks in advance.

by,
Praveen Kumar 



--
View this message in context: http://r.789695.n4.nabble.com/rJava-is-not-working-in-Solaris-through-java-tp4653701.html
Sent from the R devel mailing list archive at Nabble.com.


From therneau at mayo.edu  Fri Dec 21 15:05:21 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 21 Dec 2012 08:05:21 -0600
Subject: [Rd] Why can't I "unclass" an array?
Message-ID: <50D46CA1.6010407@mayo.edu>

In a real example I was trying to remove the class from the result of table, just because 
it was to be used as a building block for other things and a simple integer vector seemed 
likely to be most efficient.
   I'm puzzled as to why unclass doesn't work.

 > zed <- table(1:5)
 > class(zed)
[1] "table"
 > class(unclass(zed))
[1] "array"
 > class(unclass(unclass(unclass(zed))))
[1] "array"

 > class(as.vector(zed))
[1] "integer"
 > sessionInfo()
R Under development (unstable) (2012-11-28 r61176)
Platform: i686-pc-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From maechler at stat.math.ethz.ch  Fri Dec 21 15:31:26 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Dec 2012 15:31:26 +0100
Subject: [Rd] Why can't I "unclass" an array?
In-Reply-To: <50D46CA1.6010407@mayo.edu>
References: <50D46CA1.6010407@mayo.edu>
Message-ID: <20692.29374.990737.392628@stat.math.ethz.ch>

>>>>> Terry Therneau <therneau at mayo.edu>
>>>>>     on Fri, 21 Dec 2012 08:05:21 -0600 writes:

    > In a real example I was trying to remove the class from the result of table, just because 
    > it was to be used as a building block for other things and a simple integer vector seemed 
    > likely to be most efficient.

    > I'm puzzled as to why unclass doesn't work.

well  "doesn't work" in this case is really rather an implicit question 
and the topic really has nothing to do with R-devel, I'm sorry
Terry.

--> follow up on R-help  where this belongs.

Martin


From marius.hofert at math.ethz.ch  Sat Dec 22 21:56:09 2012
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Sat, 22 Dec 2012 21:56:09 +0100
Subject: [Rd] Suggestion: 'method' slot for format.ftable()
Message-ID: <878v8pvmae.fsf@sklar.v.cablecom.net>

Dear Martin,

Thanks a lot, that sounds great. Here is the unified diff for ?read.ftable.Rd.

Cheers,

Marius

--- /home/mhofert/R/R-devel/src/library/stats/man/read.ftable.Rd	2012-12-21 02:09:18.488980586 +0100
+++ read.ftable.Rd	2012-12-22 21:45:08.574636009 +0100
@@ -14,9 +14,13 @@
             row.var.names, col.vars, skip = 0)
 
 write.ftable(x, file = "", quote = TRUE, append = FALSE,
-             digits = getOption("digits"))
-
-\method{format}{ftable}(x, quote = TRUE, digits = getOption("digits"), \dots)
+             digits = getOption("digits"),
+             method=c("non.compact", "row.compact", "col.compact", "compact"),
+             sep=" \\ ")
+
+\method{format}{ftable}(x, quote = TRUE, digits = getOption("digits"),
+                        method=c("non.compact", "row.compact",
+                                 "col.compact", "compact"), sep=" \\ ", \dots)
 }
 \arguments{
   \item{file}{either a character string naming a file or a connection
@@ -42,6 +46,22 @@
     the contents of \code{file} will be overwritten.}
   \item{digits}{an integer giving the number of significant digits to
     use for (the cell entries of) \code{x}.}
+  \item{method}{methods of how the formatted \code{"ftable"} object is
+    printed. Available are (see the examples):
+    \describe{
+      \item{"non.compact"}{the default representation of an
+        \code{"ftable"} object.}
+      \item{"row.compact"}{a row-compact version without empty cells
+        under the column labels.}
+      \item{"col.compact"}{a column-compact version without empty cells
+        to the right of the row labels.}
+      \item{"compact"}{a row- and column-compact version. This may imply
+        that a row and a column label have to share the
+        same cell. They are then separated by the character
+        specified by \code{sep}.}
+  }}
+  \item{sep}{separation character for row/column labels if
+    \code{method="compact"}.}
   \item{\dots}{further arguments to be passed to or from methods.}
 }
 \details{
@@ -64,7 +84,9 @@
   table from this using \code{\link{xtabs}}.
 
   \code{write.ftable} writes a flat table to a file, which is useful for
-  generating \sQuote{pretty} ASCII representations of contingency tables.
+  generating \sQuote{pretty} ASCII representations of contingency
+  tables. Different versions are available via the \code{method}
+  argument, which may be useful, for example, for constructing LaTeX tables.
 }
 \seealso{
   \code{\link{ftable}} for more information on flat contingency tables.
@@ -108,6 +130,9 @@
 
 ft22 <- ftable(Titanic, row.vars = 2:1, col.vars = 4:3)
 write.ftable(ft22, quote = FALSE)
+write.ftable(ft22, quote = FALSE, method="row.compact")
+write.ftable(ft22, quote = FALSE, method="col.compact")
+write.ftable(ft22, quote = FALSE, method="compact")
 \dontshow{
 stopifnot(dim(format(ft)) == 4:5,
           dim(format(ftable(UCBAdmissions))) == c(6,9),


From mdowle at mdowle.plus.com  Mon Dec 24 03:22:23 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 24 Dec 2012 02:22:23 +0000
Subject: [Rd] How to ensure -O3 on Win64
Message-ID: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>


Hi,

Similar questions have come up before on the list and elsewhere but I 
haven't found a solution yet.

winbuilder's install.out shows data.table's .c files compiled with -O3 
on Win32 but -O2 on Win64. The same happens on R-Forge. I gather that 
some packages don't work with -O3 so the default is -O2.

I've tried this in data.table's Makevars (entire contents) :

====
MAKEFLAGS="CFLAGS=-O3"                        # added
CFLAGS=-O3                                    # added
PKG_CFLAGS=-O3                                # added
all: $(SHLIB)                                 # no change
	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
====

but -O2 still appears in winbuilder's install.out (after -O3, and I 
believe the last -O is the one that counts) :

gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     
-I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 -Wall  
-std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o

How can I ensure that data.table is compiled with -O3 on Win64?

Thanks, Matthew


From dietrich at ivs.cs.uni-magdeburg.de  Tue Dec 25 12:39:03 2012
From: dietrich at ivs.cs.uni-magdeburg.de (andre__)
Date: Tue, 25 Dec 2012 03:39:03 -0800 (PST)
Subject: [Rd] reinterpreting externalptr in R
Message-ID: <1356435543812-4653908.post@n4.nabble.com>

Hi,

I am using swig to build a wrapper for an c-function to use it in R. I would
like to define a generic function, which gives back a void pointer. On the R
side, I know what this pointer is pointing to, whether it is an integer or
an string, or something else... but I need to somehow reinterpret the
resulting "externalptr" into another form...

a function that looks like the following:

*void* test(){
    std::string str="test";
    return str.c_str();
}*

when I call this from R:

*str <- test()
typeof(str) % result is: "externalptr"*

how could I reinterpret this to a charcterarray, to a numeric, to list, or
...

Thanks for any suggestions ;)



--
View this message in context: http://r.789695.n4.nabble.com/reinterpreting-externalptr-in-R-tp4653908.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Tue Dec 25 18:15:56 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 25 Dec 2012 12:15:56 -0500
Subject: [Rd] reinterpreting externalptr in R
In-Reply-To: <1356435543812-4653908.post@n4.nabble.com>
References: <1356435543812-4653908.post@n4.nabble.com>
Message-ID: <93228B1F-DC73-4D4F-A472-88CFA45ED03C@r-project.org>

On Dec 25, 2012, at 6:39 AM, andre__ wrote:

> Hi,
> 
> I am using swig to build a wrapper for an c-function to use it in R. I would
> like to define a generic function, which gives back a void pointer. On the R
> side, I know what this pointer is pointing to, whether it is an integer or
> an string, or something else... but I need to somehow reinterpret the
> resulting "externalptr" into another form...
> 
> a function that looks like the following:
> 
> *void* test(){
>    std::string str="test";
>    return str.c_str();
> }*
> 
> when I call this from R:
> 
> *str <- test()
> typeof(str) % result is: "externalptr"*
> 
> how could I reinterpret this to a charcterarray, to a numeric, to list, or
> ...
> 

The simple answer is you can't. External pointers are entirely opaque to R, so *you* have to write that code that interprets them. Obviously it's then up to you to create the corresponding R object from the external pointer.

You may want to have a look at interface packages like Rcpp, rJava, Rserve, ... to understand how objects are converted to/from other languages.

Cheers,
Simon



> Thanks for any suggestions ;)
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/reinterpreting-externalptr-in-R-tp4653908.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From romain at r-enthusiasts.com  Wed Dec 26 22:04:02 2012
From: romain at r-enthusiasts.com (romain at r-enthusiasts.com)
Date: Wed, 26 Dec 2012 22:04:02 +0100
Subject: [Rd] reinterpreting externalptr in R
In-Reply-To: <93228B1F-DC73-4D4F-A472-88CFA45ED03C@r-project.org>
References: <1356435543812-4653908.post@n4.nabble.com>
	<93228B1F-DC73-4D4F-A472-88CFA45ED03C@r-project.org>
Message-ID: <7ee891f19a2a29667bd6c324eb736604@r-enthusiasts.com>

Andre,

For Rcpp, you can use the XPtr class template. Say you want to deal 
with pointers to Foo. You can create an R external pointer like this:

SEXP create_xp_foo(){
     Foo* foo = new Foo ;
     XPtr<Foo> xp( foo ) ;
     return xp ;
}

Now, "xp" is an R external pointer, i.e. a SEXP of type EXTPTRSXP, that 
you can send back to the R side. This constructor assumes ownership of 
the pointer, so when the SEXP is no longer protected, it becomes 
candidate for garbage collection, and then the finalizer deletes the 
object using C++ delete operator. The XPtr template lets you control 
these finalizers. We can discuss further if you want to know more.



If you then send it back to the C++ side, you can get back the Foo 
pointer like this:

SEXP use_foo( SEXP xp ){
     XPtr<Foo> foo(xp);
     // conversion operator
     Foo* p_foo = foo ;
     do_whatever( p_foo ) ;
     return R_NilValue ;
}

The XPtr template defines C++ operators so that the XPtr<Foo> object 
can be converted to a Foo*.

You can find details about the XPtr template in Rcpp documentation or 
perhaps just reading the source at r-forge:
https://r-forge.r-project.org/scm/viewvc.php/pkg/Rcpp/inst/include/Rcpp/XPtr.h?view=markup&root=rcpp

This simply builds on the macros that the R api offers, so perhaps 
"writing R extensions" or "R internals" are good sources of information.

Romain


Le 2012-12-25 18:15, Simon Urbanek a ?crit?:
> On Dec 25, 2012, at 6:39 AM, andre__ wrote:
>
>> Hi,
>>
>> I am using swig to build a wrapper for an c-function to use it in R. 
>> I would
>> like to define a generic function, which gives back a void pointer. 
>> On the R
>> side, I know what this pointer is pointing to, whether it is an 
>> integer or
>> an string, or something else... but I need to somehow reinterpret 
>> the
>> resulting "externalptr" into another form...
>>
>> a function that looks like the following:
>>
>> *void* test(){
>>    std::string str="test";
>>    return str.c_str();
>> }*
>>
>> when I call this from R:
>>
>> *str <- test()
>> typeof(str) % result is: "externalptr"*
>>
>> how could I reinterpret this to a charcterarray, to a numeric, to 
>> list, or
>> ...
>>
>
> The simple answer is you can't. External pointers are entirely opaque
> to R, so *you* have to write that code that interprets them. 
> Obviously
> it's then up to you to create the corresponding R object from the
> external pointer.
>
> You may want to have a look at interface packages like Rcpp, rJava,
> Rserve, ... to understand how objects are converted to/from other
> languages.
>
> Cheers,
> Simon
>
>
>
>> Thanks for any suggestions ;)


From rory.winston at gmail.com  Thu Dec 27 09:14:07 2012
From: rory.winston at gmail.com (Rory Winston)
Date: Thu, 27 Dec 2012 08:14:07 +0000
Subject: [Rd] Creating a Factor Object in C code?
Message-ID: <DDF515A2-D7C3-4123-B8EC-DD6D864AC665@gmail.com>

Hi guys

I am currently working on a small bit of bridging code between a database system and R. The database system has the concept of varchars, a la factors in R, as distinct from plain character strings. What I would like to do is when I receive a list of character strings from the remote database system that are of type varchar, turn these into a factor variable. This would ideally need to be done in C code, where the rest of the datatype translation is occuring. 

My first attempt was a bit naive (setting the factor class attribute on a vector of character strings, which obviously results in an error), looking at the R factor() implementation, I can see the core logic for factor conversion is:

 y <- unique(x)
 ind <- sort.list(y)
 y <- as.character(y)
 levels <- unique(y[ind])

So I am guessing this would need to be replicated in C? My question is - is it possible to create a fully-formed factor variable in C code (Ive struggled to find many / any examples), or should this be done in R when the call returns? I would like to make it seamless to the end user, so an automatic conversion to factors would be preferable..

Cheers
-- Rory

From dietrich at ivs.cs.uni-magdeburg.de  Thu Dec 27 11:37:02 2012
From: dietrich at ivs.cs.uni-magdeburg.de (andre__)
Date: Thu, 27 Dec 2012 02:37:02 -0800 (PST)
Subject: [Rd] reinterpreting externalptr in R
In-Reply-To: <1356435543812-4653908.post@n4.nabble.com>
References: <1356435543812-4653908.post@n4.nabble.com>
Message-ID: <1356604622947-4654033.post@n4.nabble.com>

Thanks a lot ... 





--
View this message in context: http://r.789695.n4.nabble.com/reinterpreting-externalptr-in-R-tp4653908p4654033.html
Sent from the R devel mailing list archive at Nabble.com.


From kenahoo at gmail.com  Thu Dec 27 17:08:12 2012
From: kenahoo at gmail.com (Ken Williams)
Date: Thu, 27 Dec 2012 10:08:12 -0600
Subject: [Rd] Doc patch for Sys.time and system.time
Message-ID: <CACrz-Hvdk+rNsYs2hSSjKpg-bt3L55eJs8VV6vOEto_8DLiXeg@mail.gmail.com>

Here?s a patch that adds ?seealso? entries to Sys.time and system.time
docs, to help people who forget what the distinction is between them.

Patch was made against https://svn.r-project.org/R/trunk at 61454 .

 -Ken

From simon.urbanek at r-project.org  Thu Dec 27 18:47:15 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 27 Dec 2012 12:47:15 -0500
Subject: [Rd] Creating a Factor Object in C code?
In-Reply-To: <DDF515A2-D7C3-4123-B8EC-DD6D864AC665@gmail.com>
References: <DDF515A2-D7C3-4123-B8EC-DD6D864AC665@gmail.com>
Message-ID: <6FE1CC5F-31AF-4782-BFDC-693890B3044A@r-project.org>

Rory,

On Dec 27, 2012, at 3:14 AM, Rory Winston wrote:

> Hi guys
> 
> I am currently working on a small bit of bridging code between a database system and R. The database system has the concept of varchars, a la factors in R, as distinct from plain character strings.

varchars are character strings. Factors consists of index and level set, so if your DB doesn't keep those separate, it is not a factor (and below you suggest it doesn't). Even if the DB supports ordered and unordered sets, the drivers typically only return the strings anyway, so you don't get at the set (without querying the schema). To make a point - a factor is if you can have a column consisting of values A,A,B,B and a level set of A,B,C (i.e. C is not used so it is extra information that you cannot express in a character string). if you don't have levels information nor the order then it's just a character vector.


> What I would like to do is when I receive a list of character strings from the remote database system that are of type varchar, turn these into a factor variable. This would ideally need to be done in C code, where the rest of the datatype translation is occuring. 
> 

It really depends on what you want to get out and what your input really is. If your DB will be delivering results in rows, probably the most efficient way to construct a factor from string input is to simply create the index as you go and keep a hash of the levels. Then at the end you just put the two together into one factor object. Note that if your DB doesn't pre-specify the levels the the order is undefined.

If you are collecting the whole character vector first anyway, then I see no real point of not using as.factor() - even from C code.
Note, however, that in such case you should really give the user an option not do to that - dealing with factors is very painful and they are bad for data manipulation so many users prefer to set stringsAsFactors default to FALSE (including me) because it's much more efficient and less error-prone to deal with character vectors. Having to convert factors back to strings is very inefficient (in particular with large data) and superfluous since you already had strings to start with.


> My first attempt was a bit naive (setting the factor class attribute on a vector of character strings, which obviously results in an error), looking at the R factor() implementation, I can see the core logic for factor conversion is:
> 
> y <- unique(x)
> ind <- sort.list(y)
> y <- as.character(y)
> levels <- unique(y[ind])
> 
> So I am guessing this would need to be replicated in C? My question is - is it possible to create a fully-formed factor variable in C code (Ive struggled to find many / any examples), or should this be done in R when the call returns? I would like to make it seamless to the end user, so an automatic conversion to factors would be preferable..
> 

It would not for reasons above which is why it's typically done at R level as an optional post-processing step. That doesn't mean you can't do it in C, but it is somewhat painful as you'll have to hash the levels - it's more convenient to have R do that for you.

Cheers,
Simon



> Cheers
> -- Rory
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Thu Dec 27 18:53:07 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 27 Dec 2012 12:53:07 -0500
Subject: [Rd] How to ensure -O3 on Win64
In-Reply-To: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
References: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
Message-ID: <530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>


On Dec 23, 2012, at 9:22 PM, Matthew Dowle wrote:

> 
> Hi,
> 
> Similar questions have come up before on the list and elsewhere but I haven't found a solution yet.
> 
> winbuilder's install.out shows data.table's .c files compiled with -O3 on Win32 but -O2 on Win64. The same happens on R-Forge. I gather that some packages don't work with -O3 so the default is -O2.
> 
> I've tried this in data.table's Makevars (entire contents) :
> 
> ====
> MAKEFLAGS="CFLAGS=-O3"                        # added
> CFLAGS=-O3                                    # added
> PKG_CFLAGS=-O3                                # added
> all: $(SHLIB)                                 # no change
> 	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
> ====
> 
> but -O2 still appears in winbuilder's install.out (after -O3, and I believe the last -O is the one that counts) :
> 
> gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     -I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 -Wall  -std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o
> 
> How can I ensure that data.table is compiled with -O3 on Win64?
> 

You can't - at least not in a way that doesn't circumvent the R build system. Also it's not portable so you don't want to mess with optimization flags and hard-code it in your package as it's user's choice how they setup R and its flags. You can certainly setup your R to compile with -O3, you just can't impose that on others.

Cheers,
Simon


From kenahoo at gmail.com  Thu Dec 27 19:34:01 2012
From: kenahoo at gmail.com (Ken Williams)
Date: Thu, 27 Dec 2012 12:34:01 -0600
Subject: [Rd] Doc patch for Sys.time and system.time
In-Reply-To: <CACrz-Hvdk+rNsYs2hSSjKpg-bt3L55eJs8VV6vOEto_8DLiXeg@mail.gmail.com>
References: <CACrz-Hvdk+rNsYs2hSSjKpg-bt3L55eJs8VV6vOEto_8DLiXeg@mail.gmail.com>
Message-ID: <CACrz-HtpE1skJToXcNghq1POQ9a+q2ncevawZuezhvEzju5aVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121227/18ed23ac/attachment.pl>

From marius.hofert at math.ethz.ch  Thu Dec 27 23:05:52 2012
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Thu, 27 Dec 2012 23:05:52 +0100
Subject: [Rd] Suggestion: 'method' slot for expand.grid() (incl. diffs)
Message-ID: <871ueb6thb.fsf@sklar.v.cablecom.net>

Dear expeRts,

The order in which the variables vary in expand.grid() is often unintuitive. I
would like to suggest a 'method' slot for expand.grid() which requires only very
little changes (100% backward compatible) and which allows one to control this
order. Please find attached diffs against R-devel.

Cheers,

Marius



### ./src/library/base/R/expand.grid.R #########################################

--- expand.grid.R	2012-12-27 22:37:29.000000000 +0100
+++ expand.grid2.R	2012-12-27 22:41:00.331979950 +0100
@@ -16,7 +16,8 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/

-expand.grid <- function(..., KEEP.OUT.ATTRS = TRUE, stringsAsFactors = TRUE)
+expand.grid <- function(..., KEEP.OUT.ATTRS = TRUE, stringsAsFactors = TRUE,
+                        method = c("decreasing", "increasing"))
 {
     ## x should either be a list or a set of vectors or factors
     nargs <- length(args <- list(...))
@@ -26,7 +27,9 @@
     if(nargs == 0L) return(as.data.frame(list()))
     ## avoid classed args such as data frames: cargs <- args
     cargs <- vector("list", nargs)
-    iArgs <- seq_len(nargs)
+    seqArgs <- seq_len(nargs)
+    method <- match.arg(method)
+    iArgs <- if(method=="decreasing") seqArgs else rev(seqArgs)
     nmc <- paste0("Var", iArgs)
     nm <- names(args)
     if(is.null(nm))


### ./src/library/base/man/expand.grid.Rd ######################################

--- expand.grid.Rd	2012-12-27 22:38:13.000000000 +0100
+++ expand.grid2.Rd	2012-12-27 22:46:53.103964121 +0100
@@ -6,7 +6,8 @@
 \name{expand.grid}
 \title{Create a Data Frame from All Combinations of Factors}
 \usage{
-expand.grid(\dots, KEEP.OUT.ATTRS = TRUE, stringsAsFactors = TRUE)
+expand.grid(\dots, KEEP.OUT.ATTRS = TRUE, stringsAsFactors = TRUE,
+            method = c("decreasing", "increasing"))
 }
 \alias{expand.grid}
 \arguments{
@@ -15,6 +16,15 @@
     attribute (see below) should be computed and returned.}
   \item{stringsAsFactors}{logical specifying if character vectors are
     converted to factors.}
+  \item{method}{method slot for how the resulting data frame is
+    presented. Available are:
+    \describe{
+      \item{"decreasing"}{the default; the variability of the variables
+	is decreasing in the column number.}
+      \item{"increasing"}{the variability of the variables
+	is increasing in the column number.}
+    }
+  }
 }
 \description{
   Create a data frame from all combinations of the supplied vectors or
@@ -52,6 +62,8 @@

 expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),
             sex = c("Male","Female"))
+expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),
+            sex = c("Male","Female"), method = "increasing")

 x <- seq(0, 10, length.out = 100)
 y <- seq(-1, 1, length.out = 20)


From rory.winston at gmail.com  Thu Dec 27 23:43:20 2012
From: rory.winston at gmail.com (Rory Winston)
Date: Thu, 27 Dec 2012 22:43:20 +0000
Subject: [Rd] Creating a Factor Object in C code?
In-Reply-To: <6FE1CC5F-31AF-4782-BFDC-693890B3044A@r-project.org>
References: <DDF515A2-D7C3-4123-B8EC-DD6D864AC665@gmail.com>
	<6FE1CC5F-31AF-4782-BFDC-693890B3044A@r-project.org>
Message-ID: <325AF9D1-FF46-4407-A273-A6BD4555629E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121227/278ce09f/attachment.pl>

From mdowle at mdowle.plus.com  Fri Dec 28 00:08:29 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 27 Dec 2012 23:08:29 +0000
Subject: [Rd] How to ensure -O3 on Win64
In-Reply-To: <530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>
References: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
	<530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>
Message-ID: <0854322745c86a728b20f801743a6c7e@imap.plus.net>

On 27.12.2012 17:53, Simon Urbanek wrote:
> On Dec 23, 2012, at 9:22 PM, Matthew Dowle wrote:
>
>>
>> Hi,
>>
>> Similar questions have come up before on the list and elsewhere but 
>> I haven't found a solution yet.
>>
>> winbuilder's install.out shows data.table's .c files compiled with 
>> -O3 on Win32 but -O2 on Win64. The same happens on R-Forge. I gather 
>> that some packages don't work with -O3 so the default is -O2.
>>
>> I've tried this in data.table's Makevars (entire contents) :
>>
>> ====
>> MAKEFLAGS="CFLAGS=-O3"                        # added
>> CFLAGS=-O3                                    # added
>> PKG_CFLAGS=-O3                                # added
>> all: $(SHLIB)                                 # no change
>> 	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
>> ====
>>
>> but -O2 still appears in winbuilder's install.out (after -O3, and I 
>> believe the last -O is the one that counts) :
>>
>> gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     
>> -I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 -Wall 
>> -std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o
>>
>> How can I ensure that data.table is compiled with -O3 on Win64?
>>
>
> You can't - at least not in a way that doesn't circumvent the R build
> system. Also it's not portable so you don't want to mess with
> optimization flags and hard-code it in your package as it's user's
> choice how they setup R and its flags. You can certainly setup your R
> to compile with -O3, you just can't impose that on others.
>
> Cheers,
> Simon

Thanks Simon. This makes complete sense where users compile packages on 
install (Unix and Mac, and I better check my settings then), but on 
Windows where it's more common for the user to install the pre-compiled 
.zip from CRAN is my concern. This came up because the new fread 
function in data.table wasn't showing as much of a speedup on Win64 as 
on Linux. I'm not 100% sure that non -O3 is the cause, but there are 
some function calls which get iterated a lot (e.g. isspace) and I'd seen 
that inlining was something -O3 did and not -O2.

In general, why wouldn't a user of a package want the best performance 
from -O3?  By non portable do you mean the executable produced by 
winbuilder (or by CRAN) might not run on all Windows machines it's 
installed on (because -O3 (over) optimizes for the machine it's built 
on), or do you mean that -O3 itself might not be available on some 
compilers (and if so which compilers don't have -O3?).

Thanks, Matthew


From murdoch.duncan at gmail.com  Fri Dec 28 01:23:33 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Dec 2012 19:23:33 -0500
Subject: [Rd] Doc patch for Sys.time and system.time
In-Reply-To: <CACrz-HtpE1skJToXcNghq1POQ9a+q2ncevawZuezhvEzju5aVw@mail.gmail.com>
References: <CACrz-Hvdk+rNsYs2hSSjKpg-bt3L55eJs8VV6vOEto_8DLiXeg@mail.gmail.com>
	<CACrz-HtpE1skJToXcNghq1POQ9a+q2ncevawZuezhvEzju5aVw@mail.gmail.com>
Message-ID: <50DCE685.5070302@gmail.com>

These are now in R-devel.  Thanks!

Duncan Murdoch

On 12-12-27 1:34 PM, Ken Williams wrote:
> Duncan noticed that either the sending server (Gmail - shouldn't be the
> case) or receiving server stripped out the attachment.  Here it is again,
> inline.
>
>   -Ken
>
> ===========================
>>From 99766dd8f16804ecddc73f6169be3e42b916b8fa Mon Sep 17 00:00:00 2001
> From: Ken Williams <Ken.Williams at WindLogics.com>
> Date: Thu, 27 Dec 2012 09:58:21 -0600
> Subject: [PATCH] Add system.time link to Sys.time documentation, and vice
>   versa.
>
>
> diff --git a/src/library/base/man/Sys.time.Rd
> b/src/library/base/man/Sys.time.Rd
> index d34571b..f0b0c50 100644
> --- a/src/library/base/man/Sys.time.Rd
> +++ b/src/library/base/man/Sys.time.Rd
> @@ -41,6 +41,8 @@ Sys.Date()
>     string.
>
>     \code{\link{Sys.timezone}}.
> +
> +  \code{\link{system.time}} for measuring elapsed/CPU time of expressions.
>   }
>   \examples{\donttest{
>   Sys.time()
> diff --git a/src/library/base/man/system.time.Rd
> b/src/library/base/man/system.time.Rd
> index 5cd79b7..ad21267 100644
> --- a/src/library/base/man/system.time.Rd
> +++ b/src/library/base/man/system.time.Rd
> @@ -38,6 +38,8 @@ unix.time(expr, gcFirst = TRUE)
>   }
>   \seealso{
>     \code{\link{proc.time}}, \code{\link{time}} which is for time series.
> +
> +  \code{\link{Sys.time}} to get the current date & time.
>   }
>   \examples{
>   require(stats)
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Fri Dec 28 01:41:24 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 27 Dec 2012 19:41:24 -0500
Subject: [Rd] How to ensure -O3 on Win64
In-Reply-To: <0854322745c86a728b20f801743a6c7e@imap.plus.net>
References: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
	<530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>
	<0854322745c86a728b20f801743a6c7e@imap.plus.net>
Message-ID: <2F987F61-CC5A-4089-A7BB-388DB59F34BD@r-project.org>


On Dec 27, 2012, at 6:08 PM, Matthew Dowle wrote:

> On 27.12.2012 17:53, Simon Urbanek wrote:
>> On Dec 23, 2012, at 9:22 PM, Matthew Dowle wrote:
>> 
>>> 
>>> Hi,
>>> 
>>> Similar questions have come up before on the list and elsewhere but I haven't found a solution yet.
>>> 
>>> winbuilder's install.out shows data.table's .c files compiled with -O3 on Win32 but -O2 on Win64. The same happens on R-Forge. I gather that some packages don't work with -O3 so the default is -O2.
>>> 
>>> I've tried this in data.table's Makevars (entire contents) :
>>> 
>>> ====
>>> MAKEFLAGS="CFLAGS=-O3"                        # added
>>> CFLAGS=-O3                                    # added
>>> PKG_CFLAGS=-O3                                # added
>>> all: $(SHLIB)                                 # no change
>>> 	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
>>> ====
>>> 
>>> but -O2 still appears in winbuilder's install.out (after -O3, and I believe the last -O is the one that counts) :
>>> 
>>> gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     -I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 -Wall -std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o
>>> 
>>> How can I ensure that data.table is compiled with -O3 on Win64?
>>> 
>> 
>> You can't - at least not in a way that doesn't circumvent the R build
>> system. Also it's not portable so you don't want to mess with
>> optimization flags and hard-code it in your package as it's user's
>> choice how they setup R and its flags. You can certainly setup your R
>> to compile with -O3, you just can't impose that on others.
>> 
>> Cheers,
>> Simon
> 
> Thanks Simon. This makes complete sense where users compile packages on install (Unix and Mac, and I better check my settings then), but on Windows where it's more common for the user to install the pre-compiled .zip from CRAN is my concern. This came up because the new fread function in data.table wasn't showing as much of a speedup on Win64 as on Linux. I'm not 100% sure that non -O3 is the cause, but there are some function calls which get iterated a lot (e.g. isspace) and I'd seen that inlining was something -O3 did and not -O2.
> 
> In general, why wouldn't a user of a package want the best performance from -O3?

Because it doesn't work? I don't know, you said yourself that -O2 may be there since -O3 breaks - that was not the question, though. (If you are curious about that, ask on CRAN, I don't remember the answer -- note that Win64 compiler support is relatively recent).


>  By non portable do you mean the executable produced by winbuilder (or by CRAN) might not run on all Windows machines it's installed on (because -O3 (over) optimizes for the machine it's built on), or do you mean that -O3 itself might not be available on some compilers (and if so which compilers don't have -O3?).
> 

Non-portable as in -O3 may not be supported or may break (we have seen -O3 trigger bugs in gcc before). If you hard-code it, there is no way around it. The point is that you cannot make decisions for the user in advance, because you don't know the setup the user may use. I agree that Windows is a bit of a special-case in that there are very few choices so the risk of breaking things is lower, but if -O2 is really such a big deal, it is not just your problem and so you may want to investigate it further.

Cheers,
Simon


From simon.urbanek at r-project.org  Fri Dec 28 01:45:12 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 27 Dec 2012 19:45:12 -0500
Subject: [Rd] Creating a Factor Object in C code?
In-Reply-To: <325AF9D1-FF46-4407-A273-A6BD4555629E@gmail.com>
References: <DDF515A2-D7C3-4123-B8EC-DD6D864AC665@gmail.com>
	<6FE1CC5F-31AF-4782-BFDC-693890B3044A@r-project.org>
	<325AF9D1-FF46-4407-A273-A6BD4555629E@gmail.com>
Message-ID: <34ECBDCE-C3ED-465B-9A34-EEA4CCB8D2EB@r-project.org>

On Dec 27, 2012, at 5:43 PM, Rory Winston wrote:

> Hi Simon
> 
> Thanks for the clarification - makes sense and I now think youre right - probably better to avoid an automatic factor conversion and let the user explicitly convert if necessary. And you are right, I did abuse the term factor when referring to varchar - instead of factor, I really meant something like 'internalized strings' a la Java (ie like a factor but with no ordering or distinct levels attributes.
> 

FWIW all strings are internalized in R (for some years now) - hence character vectors are very memory-efficient and essentially what you were looking for.

Cheers,
Simon

> 
> 
> On 27/12/2012, at 5:47 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> varchars are character strings. Factors consists of index and level set, so if your DB doesn't keep those separate, it is not a factor (and below you suggest it doesn't). Even if the DB supports ordered and unordered sets, the drivers typically only return the strings anyway, so you don't get at the set (without querying the schema). To make a point - a factor is if you can have a column consisting of values A,A,B,B and a level set of A,B,C (i.e. C is not used so it is extra information that you cannot express in a character string). if you don't have levels information nor the order then it's just a character vector.
> 


From vitaliy.feoktistov at gmail.com  Fri Dec 28 11:23:00 2012
From: vitaliy.feoktistov at gmail.com (Vitaliy FEOKTISTOV)
Date: Fri, 28 Dec 2012 11:23:00 +0100
Subject: [Rd] linux multi-threaded compilation is running only on one
	processor
Message-ID: <CAGHrqz9gVD8WvzEDvfsMHr3j+WS-pJ74EJaA1-cq9zJOvp9DbQ@mail.gmail.com>

Hello,

I compiled R-2.15.2 with linux intel compilers (see below).

when I execute some R code on a // 4 proc x 4 cores // server
(export MKL_NUM_THREADS = 16)
very often I have the situations where only one processor (4 cores) is
active instead of 4 (16 cores) !

do you know this fact depends on what ?

thank you !

P.S.
many functions of R are single-threaded,
is there a simple way to make them multi-threaded ?


=========================================================================================================

CMP_LIB_PATH=/opt/intel/lib/intel64
MKL_LIB_PATH=/opt/intel/composerxe/mkl/lib/intel64
INC_LIB_PATH=/usr/local/lib

export CC="icc -std=c99"
export CFLAGS="-g -O3 -wd188 -ip"
export F77=ifort
export FFLAGS="-g -O3"
export CXX=icpc
export CXXFLAGS="-g -O3"
export FC=ifort
export FCFLAGS="-g -O3"
export SHLIB_CXXLD=icpc

export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${MKL_LIB_PATH}:${INC_LIB_PATH}:${CMP_LIB_PATH}
export LDFLAGS="-L${MKL_LIB_PATH},-L${INC_LIB_PATH},-L${CMP_LIB_PATH},-Bdirect,--hash-style=both,-Wl,-O1"

export SHLIB_LDFLAGS="-lpthread"
export SHLIB_CXXLDFLAGS="-lpthread"
export MAIN_LDFLAGS="-lpthread"

MKL="-L${MKL_LIB_PATH} -L${INC_LIB_PATH} -lmkl_lapack95_lp64
-lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
./configure --prefix=${INSTALL_DIR} --enable-R-shlib
--with-blas="$MKL" --with-lapack


From simon.urbanek at r-project.org  Fri Dec 28 17:33:00 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 28 Dec 2012 11:33:00 -0500
Subject: [Rd] linux multi-threaded compilation is running only on one
	processor
In-Reply-To: <CAGHrqz9gVD8WvzEDvfsMHr3j+WS-pJ74EJaA1-cq9zJOvp9DbQ@mail.gmail.com>
References: <CAGHrqz9gVD8WvzEDvfsMHr3j+WS-pJ74EJaA1-cq9zJOvp9DbQ@mail.gmail.com>
Message-ID: <AB62B57E-548D-4E1E-BEFB-09F2004F628D@r-project.org>


On Dec 28, 2012, at 5:23 AM, Vitaliy FEOKTISTOV wrote:

> Hello,
> 
> I compiled R-2.15.2 with linux intel compilers (see below).
> 
> when I execute some R code on a // 4 proc x 4 cores // server
> (export MKL_NUM_THREADS = 16)
> very often I have the situations where only one processor (4 cores) is
> active instead of 4 (16 cores) !
> 
> do you know this fact depends on what ?
> 

What code? Usually, this has nothing to do with R but the libraries you're using and their capability to implicitly parallelize the calls used (presumably MKL is your case?). You didn't provide any details on what you are actually doing, but really you should be asking on the lists for the libraries you are using.


> thank you !
> 
> P.S.
> many functions of R are single-threaded, is there a simple way to make them multi-threaded ?
> 

R is not thread-safe, so any parallelization has to be done at native code level. So if "functions of R" is referring to R code then the answer is no (except for the obvious use parallel/multicore where applicable), if it is referring to native functions then the answer is possibly - Luke Tierney has done some of that work -- did you try pnmath? 

Cheers,
Simon


> 
> =========================================================================================================
> 
> CMP_LIB_PATH=/opt/intel/lib/intel64
> MKL_LIB_PATH=/opt/intel/composerxe/mkl/lib/intel64
> INC_LIB_PATH=/usr/local/lib
> 
> export CC="icc -std=c99"
> export CFLAGS="-g -O3 -wd188 -ip"
> export F77=ifort
> export FFLAGS="-g -O3"
> export CXX=icpc
> export CXXFLAGS="-g -O3"
> export FC=ifort
> export FCFLAGS="-g -O3"
> export SHLIB_CXXLD=icpc
> 
> export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${MKL_LIB_PATH}:${INC_LIB_PATH}:${CMP_LIB_PATH}
> export LDFLAGS="-L${MKL_LIB_PATH},-L${INC_LIB_PATH},-L${CMP_LIB_PATH},-Bdirect,--hash-style=both,-Wl,-O1"
> 
> export SHLIB_LDFLAGS="-lpthread"
> export SHLIB_CXXLDFLAGS="-lpthread"
> export MAIN_LDFLAGS="-lpthread"
> 
> MKL="-L${MKL_LIB_PATH} -L${INC_LIB_PATH} -lmkl_lapack95_lp64
> -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
> ./configure --prefix=${INSTALL_DIR} --enable-R-shlib
> --with-blas="$MKL" --with-lapack
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From mdowle at mdowle.plus.com  Fri Dec 28 22:51:02 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Fri, 28 Dec 2012 21:51:02 +0000
Subject: [Rd] How to ensure -O3 on Win64
In-Reply-To: <2F987F61-CC5A-4089-A7BB-388DB59F34BD@r-project.org>
References: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
	<530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>
	<0854322745c86a728b20f801743a6c7e@imap.plus.net>
	<2F987F61-CC5A-4089-A7BB-388DB59F34BD@r-project.org>
Message-ID: <9a1952c77ad4f6b68ccd41ad210a7c2f@imap.plus.net>

On 28.12.2012 00:41, Simon Urbanek wrote:
> On Dec 27, 2012, at 6:08 PM, Matthew Dowle wrote:
>
>> On 27.12.2012 17:53, Simon Urbanek wrote:
>>> On Dec 23, 2012, at 9:22 PM, Matthew Dowle wrote:
>>>
>>>>
>>>> Hi,
>>>>
>>>> Similar questions have come up before on the list and elsewhere 
>>>> but I haven't found a solution yet.
>>>>
>>>> winbuilder's install.out shows data.table's .c files compiled with 
>>>> -O3 on Win32 but -O2 on Win64. The same happens on R-Forge. I gather 
>>>> that some packages don't work with -O3 so the default is -O2.
>>>>
>>>> I've tried this in data.table's Makevars (entire contents) :
>>>>
>>>> ====
>>>> MAKEFLAGS="CFLAGS=-O3"                        # added
>>>> CFLAGS=-O3                                    # added
>>>> PKG_CFLAGS=-O3                                # added
>>>> all: $(SHLIB)                                 # no change
>>>> 	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
>>>> ====
>>>>
>>>> but -O2 still appears in winbuilder's install.out (after -O3, and 
>>>> I believe the last -O is the one that counts) :
>>>>
>>>> gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     
>>>> -I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 
>>>> -Wall -std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o
>>>>
>>>> How can I ensure that data.table is compiled with -O3 on Win64?
>>>>
>>>
>>> You can't - at least not in a way that doesn't circumvent the R 
>>> build
>>> system. Also it's not portable so you don't want to mess with
>>> optimization flags and hard-code it in your package as it's user's
>>> choice how they setup R and its flags. You can certainly setup your 
>>> R
>>> to compile with -O3, you just can't impose that on others.
>>>
>>> Cheers,
>>> Simon
>>
>> Thanks Simon. This makes complete sense where users compile packages 
>> on install (Unix and Mac, and I better check my settings then), but on 
>> Windows where it's more common for the user to install the 
>> pre-compiled .zip from CRAN is my concern. This came up because the 
>> new fread function in data.table wasn't showing as much of a speedup 
>> on Win64 as on Linux. I'm not 100% sure that non -O3 is the cause, but 
>> there are some function calls which get iterated a lot (e.g. isspace) 
>> and I'd seen that inlining was something -O3 did and not -O2.
>>
>> In general, why wouldn't a user of a package want the best 
>> performance from -O3?
>
> Because it doesn't work? I don't know, you said yourself that -O2 may
> be there since -O3 breaks - that was not the question, though. (If 
> you
> are curious about that, ask on CRAN, I don't remember the answer --
> note that Win64 compiler support is relatively recent).

Indeed I had forgotten how recent that was. Ok, this is clicking now.


>>  By non portable do you mean the executable produced by winbuilder 
>> (or by CRAN) might not run on all Windows machines it's installed on 
>> (because -O3 (over) optimizes for the machine it's built on), or do 
>> you mean that -O3 itself might not be available on some compilers (and 
>> if so which compilers don't have -O3?).
>>
>
> Non-portable as in -O3 may not be supported or may break (we have
> seen -O3 trigger bugs in gcc before). If you hard-code it, there is 
> no
> way around it. The point is that you cannot make decisions for the
> user in advance, because you don't know the setup the user may use. I
> agree that Windows is a bit of a special-case in that there are very
> few choices so the risk of breaking things is lower, but if -O2 is
> really such a big deal, it is not just your problem and so you may
> want to investigate it further.

Ok thanks a lot for info. I'll try a few more things and follow up off
r-devel if need be.

Matthew


From ripley at stats.ox.ac.uk  Sat Dec 29 13:29:30 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Dec 2012 12:29:30 +0000
Subject: [Rd] How to ensure -O3 on Win64
In-Reply-To: <2F987F61-CC5A-4089-A7BB-388DB59F34BD@r-project.org>
References: <dbbc6e1436401aa2781e8a2069b360b1@imap.plus.net>
	<530A0026-07D0-4BAF-9E41-68D266FF9E58@r-project.org>
	<0854322745c86a728b20f801743a6c7e@imap.plus.net>
	<2F987F61-CC5A-4089-A7BB-388DB59F34BD@r-project.org>
Message-ID: <50DEE22A.1020006@stats.ox.ac.uk>

On 28/12/2012 00:41, Simon Urbanek wrote:
>
> On Dec 27, 2012, at 6:08 PM, Matthew Dowle wrote:
>
>> On 27.12.2012 17:53, Simon Urbanek wrote:
>>> On Dec 23, 2012, at 9:22 PM, Matthew Dowle wrote:
>>>
>>>>
>>>> Hi,
>>>>
>>>> Similar questions have come up before on the list and elsewhere but I haven't found a solution yet.
>>>>
>>>> winbuilder's install.out shows data.table's .c files compiled with -O3 on Win32 but -O2 on Win64. The same happens on R-Forge. I gather that some packages don't work with -O3 so the default is -O2.
>>>>
>>>> I've tried this in data.table's Makevars (entire contents) :
>>>>
>>>> ====
>>>> MAKEFLAGS="CFLAGS=-O3"                        # added
>>>> CFLAGS=-O3                                    # added
>>>> PKG_CFLAGS=-O3                                # added
>>>> all: $(SHLIB)                                 # no change
>>>> 	mv $(SHLIB) datatable$(SHLIB_EXT)     # no change
>>>> ====
>>>>
>>>> but -O2 still appears in winbuilder's install.out (after -O3, and I believe the last -O is the one that counts) :
>>>>
>>>> gcc -m64 -I"D:/RCompile/recent/R-2.15.2/include" -DNDEBUG     -I"d:/Rcompile/CRANpkg/extralibs215/local215/include"  -O3   -O2 -Wall -std=gnu99 -mtune=core2 -c dogroups.c -o dogroups.o
>>>>
>>>> How can I ensure that data.table is compiled with -O3 on Win64?
>>>>
>>>
>>> You can't - at least not in a way that doesn't circumvent the R build
>>> system. Also it's not portable so you don't want to mess with
>>> optimization flags and hard-code it in your package as it's user's
>>> choice how they setup R and its flags. You can certainly setup your R
>>> to compile with -O3, you just can't impose that on others.
>>>
>>> Cheers,
>>> Simon
>>
>> Thanks Simon. This makes complete sense where users compile packages on install (Unix and Mac, and I better check my settings then), but on Windows where it's more common for the user to install the pre-compiled .zip from CRAN is my concern. This came up because the new fread function in data.table wasn't showing as much of a speedup on Win64 as on Linux. I'm not 100% sure that non -O3 is the cause, but there are some function calls which get iterated a lot (e.g. isspace) and I'd seen that inlining was something -O3 did and not -O2.
>>
>> In general, why wouldn't a user of a package want the best performance from -O3?
>
> Because it doesn't work? I don't know, you said yourself that -O2 may be there since -O3 breaks - that was not the question, though. (If you are curious about that, ask on CRAN, I don't remember the answer -- note that Win64 compiler support is relatively recent).

Compilation with -O3 was not stable, including that some commonly-used 
packages segfaulted.  x64 Windows is still an under-development platform 
for gcc, and a number of issues will not be resolved until at least gcc 
4.8.0.

And BTW, -O3 is not the out-of-the-box default for any R build except 
i386 Windows, including not for the OS X binary packages.  Not sure why 
you are singling out Windows here ....

It isn't just a question of optimization level but also what optimizing 
options the compiler is built with.  We had to discard all the versions 
of gcc 4.6.x built with Graphite optimization as they produced far too 
unstable code on Windows.

>
>>   By non portable do you mean the executable produced by winbuilder (or by CRAN) might not run on all Windows machines it's installed on (because -O3 (over) optimizes for the machine it's built on), or do you mean that -O3 itself might not be available on some compilers (and if so which compilers don't have -O3?).
>>
>
> Non-portable as in -O3 may not be supported or may break (we have seen -O3 trigger bugs in gcc before). If you hard-code it, there is no way around it. The point is that you cannot make decisions for the user in advance, because you don't know the setup the user may use. I agree that Windows is a bit of a special-case in that there are very few choices so the risk of breaking things is lower, but if -O2 is really such a big deal, it is not just your problem and so you may want to investigate it further.

Remember that even if -O3 works on your package with the current 
compiler, it may not with another one.   One reason we update the 
recommended Windows compiler so infrequently is dealing with all the 
fallout from packages which break (almost always because of previously 
unrevealed errors in their code). But, for example, we will consider if 
we want to change the recommended compiler for R 3.0.0 and it is likely 
we will change it during 2013.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From krishnaiah.ac at gmail.com  Fri Dec 28 13:53:48 2012
From: krishnaiah.ac at gmail.com (KRISHNA2222)
Date: Fri, 28 Dec 2012 04:53:48 -0800 (PST)
Subject: [Rd] reference Calling R from C++
Message-ID: <1356699228064-4654144.post@n4.nabble.com>

Hello Guys,

I have been working on integrating R and C++. I have been looking for a nice
reference book which deals with it. I got R-inside but the proper
documentation is not available for that package. If anyone knows some book
please let me know...


Thank you.



--
View this message in context: http://r.789695.n4.nabble.com/reference-Calling-R-from-C-tp4654144.html
Sent from the R devel mailing list archive at Nabble.com.


From sgiannerini at gmail.com  Sat Dec 29 18:04:06 2012
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Sat, 29 Dec 2012 18:04:06 +0100
Subject: [Rd] bug in plot.ts?
In-Reply-To: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
References: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
Message-ID: <CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>

Dear all,

I think I have found a buglet in plot.ts

plot.ts(x=1,type="n")     # correct: does not show the plot
plot.ts(x=1,y=1,type="n") # not correct: does show the plot

I did not investigate the problem in depth but it could be related to
the switch xy.labels, in fact

plot.ts(x=1,y=1,type="n",xy.labels=TRUE) #  does show the plot
plot.ts(x=1,y=1,type="n",xy.labels=FALSE) # does not show the plot

> sessionInfo()
R version 2.15.2 Patched (2012-10-26 r61028)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
[3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
[5] LC_TIME=Italian_Italy.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.2


Kind regards

Simone
______________________________________________________


Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From ruipbarradas at sapo.pt  Sat Dec 29 20:07:46 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 29 Dec 2012 19:07:46 +0000
Subject: [Rd] bug in plot.ts?
In-Reply-To: <CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>
References: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
	<CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>
Message-ID: <50DF3F82.7050205@sapo.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20121229/96c0c656/attachment.pl>

From ruipbarradas at sapo.pt  Sat Dec 29 20:22:33 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 29 Dec 2012 19:22:33 +0000
Subject: [Rd] bug in plot.ts?
In-Reply-To: <50DF3F82.7050205@sapo.pt>
References: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
	<CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>
	<50DF3F82.7050205@sapo.pt>
Message-ID: <50DF42F9.7020001@sapo.pt>

Just to add, on documentation, to my previous post. The following 
illustrates my point.

# This is the last instruction in the original post.
plot.ts(x=1, y=1, type="n", xy.labels=FALSE) # does not show the plot

plot.ts(x=1, y=1, xy.labels=FALSE) # does show the plot, does not label 
it, documented
plot.ts(x=1, y=1, type="n") # does show the plot (labels it), not 
properly documented
plot.ts(x=1:151, y=1:151, type="n") # does not show the plot, documented

Rui Barradas
Em 29-12-2012 19:07, Rui Barradas escreveu:
> Hello,
>
> You're right, it has to do with the argument xy.labels. The relevant
> lines in the source are
> (file src/library/stats/R/ts.R, function plot.ts)
>
>           [...]
>           n <- length(xy $ x)          #-> default for xy.l(ines|abels)
>           if(missing(xy.labels)) xy.labels <- (n <= 150)
>           if(!is.logical(xy.labels)) {
>               if(!is.character(xy.labels))
>                   stop("'xy.labels' must be logical or character")
>               do.lab <- TRUE
>           } else do.lab <- xy.labels
>           [...]
>           ptype <-
>           if(do.lab) "n" else if(missing(type)) "p" else type
>           plot.default(xy, type = ptype,
>           [...]
>           if(do.lab)
>               text(xy, labels =
>                if(is.character(xy.labels)) xy.labels
>                else if(all(tsp(x) == tsp(y))) formatC(time(x), width = 1)
>                else seq_along(xy$x),
>                col = col, cex = cex)
>           if(xy.lines)
>               lines(xy, col = col, lty = lty, lwd = lwd,
>                 type = if(do.lab) "c" else "l")
>           [...]
>
> Note that this is executed only if both 'x' and 'y' are passed to plot.ts.
> The variable 'do.lab' will control the plot.default type and whether the
> points are labeled using text() and the lines() type.
> This variable is set according to xy.labels. This behavior is more or
> less documented in plot.ts:
>
> |"xy.labels|||logical, indicating if |text
> <http://127.0.0.1:29428/library/stats/help/text>()| labels should be
> used for an x-y plot, /or/ character, supplying a vector of labels to be
> used. The default is to label for up to 150 points, and not for more."
>
> but I believe the documentation could be more clear. It could say that
> in the case of a y ~ x plot, to supress the plot xy.labels should be set
> to FALSE.
>
> Hope this helps,
>
> Rui Barradas
> Em 29-12-2012 17:04, Simone Giannerini escreveu:
>> Dear all,
>>
>> I think I have found a buglet in plot.ts
>>
>> plot.ts(x=1,type="n")     # correct: does not show the plot
>> plot.ts(x=1,y=1,type="n") # not correct: does show the plot
>>
>> I did not investigate the problem in depth but it could be related to
>> the switch xy.labels, in fact
>>
>> plot.ts(x=1,y=1,type="n",xy.labels=TRUE) #  does show the plot
>> plot.ts(x=1,y=1,type="n",xy.labels=FALSE) # does not show the plot
>>
>>> sessionInfo()
>> R version 2.15.2 Patched (2012-10-26 r61028)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
>> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
>> [5] LC_TIME=Italian_Italy.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.2
>>
>>
>> Kind regards
>>
>> Simone
>> ______________________________________________________
>>
>>
>> Simone Giannerini
>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>> Universita' di Bologna
>> Via delle belle arti 41 - 40126  Bologna,  ITALY
>> Tel: +39 051 2098262  Fax: +39 051 232153
>> http://www2.stat.unibo.it/giannerini/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sgiannerini at gmail.com  Sun Dec 30 22:23:03 2012
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Sun, 30 Dec 2012 22:23:03 +0100
Subject: [Rd] bug in plot.ts?
In-Reply-To: <50DF42F9.7020001@sapo.pt>
References: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
	<CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>
	<50DF3F82.7050205@sapo.pt> <50DF42F9.7020001@sapo.pt>
Message-ID: <CANcXGiwiY-V-aFXnQsFda0HLFszsxmcCSCUuwAOmvt8oKKvSAg@mail.gmail.com>

Rui,

thanks for looking into this and adding some relevant info,
to me it looks more like a bug than lack of documentation, in any case
we'll see if anyone of the core team would like to comment.

Ciao

Simone

On Sat, Dec 29, 2012 at 8:22 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Just to add, on documentation, to my previous post. The following
> illustrates my point.
>
> # This is the last instruction in the original post.
> plot.ts(x=1, y=1, type="n", xy.labels=FALSE) # does not show the plot
>
> plot.ts(x=1, y=1, xy.labels=FALSE) # does show the plot, does not label it,
> documented
> plot.ts(x=1, y=1, type="n") # does show the plot (labels it), not properly
> documented
> plot.ts(x=1:151, y=1:151, type="n") # does not show the plot, documented
>
> Rui Barradas
> Em 29-12-2012 19:07, Rui Barradas escreveu:
>>
>> Hello,
>>
>> You're right, it has to do with the argument xy.labels. The relevant
>> lines in the source are
>> (file src/library/stats/R/ts.R, function plot.ts)
>>
>>           [...]
>>           n <- length(xy $ x)          #-> default for xy.l(ines|abels)
>>           if(missing(xy.labels)) xy.labels <- (n <= 150)
>>           if(!is.logical(xy.labels)) {
>>               if(!is.character(xy.labels))
>>                   stop("'xy.labels' must be logical or character")
>>               do.lab <- TRUE
>>           } else do.lab <- xy.labels
>>           [...]
>>           ptype <-
>>           if(do.lab) "n" else if(missing(type)) "p" else type
>>           plot.default(xy, type = ptype,
>>           [...]
>>           if(do.lab)
>>               text(xy, labels =
>>                if(is.character(xy.labels)) xy.labels
>>                else if(all(tsp(x) == tsp(y))) formatC(time(x), width = 1)
>>                else seq_along(xy$x),
>>                col = col, cex = cex)
>>           if(xy.lines)
>>               lines(xy, col = col, lty = lty, lwd = lwd,
>>                 type = if(do.lab) "c" else "l")
>>           [...]
>>
>> Note that this is executed only if both 'x' and 'y' are passed to plot.ts.
>> The variable 'do.lab' will control the plot.default type and whether the
>> points are labeled using text() and the lines() type.
>> This variable is set according to xy.labels. This behavior is more or
>> less documented in plot.ts:
>>
>> |"xy.labels|||logical, indicating if |text
>> <http://127.0.0.1:29428/library/stats/help/text>()| labels should be
>> used for an x-y plot, /or/ character, supplying a vector of labels to be
>>
>> used. The default is to label for up to 150 points, and not for more."
>>
>> but I believe the documentation could be more clear. It could say that
>> in the case of a y ~ x plot, to supress the plot xy.labels should be set
>> to FALSE.
>>
>> Hope this helps,
>>
>> Rui Barradas
>> Em 29-12-2012 17:04, Simone Giannerini escreveu:
>>>
>>> Dear all,
>>>
>>> I think I have found a buglet in plot.ts
>>>
>>> plot.ts(x=1,type="n")     # correct: does not show the plot
>>> plot.ts(x=1,y=1,type="n") # not correct: does show the plot
>>>
>>> I did not investigate the problem in depth but it could be related to
>>> the switch xy.labels, in fact
>>>
>>> plot.ts(x=1,y=1,type="n",xy.labels=TRUE) #  does show the plot
>>> plot.ts(x=1,y=1,type="n",xy.labels=FALSE) # does not show the plot
>>>
>>>> sessionInfo()
>>>
>>> R version 2.15.2 Patched (2012-10-26 r61028)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
>>> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
>>> [5] LC_TIME=Italian_Italy.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.15.2
>>>
>>>
>>> Kind regards
>>>
>>> Simone
>>> ______________________________________________________
>>>
>>>
>>> Simone Giannerini
>>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>>> Universita' di Bologna
>>> Via delle belle arti 41 - 40126  Bologna,  ITALY
>>> Tel: +39 051 2098262  Fax: +39 051 232153
>>> http://www2.stat.unibo.it/giannerini/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
___________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From murdoch.duncan at gmail.com  Mon Dec 31 00:57:19 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Dec 2012 18:57:19 -0500
Subject: [Rd] bug in plot.ts?
In-Reply-To: <CANcXGiwiY-V-aFXnQsFda0HLFszsxmcCSCUuwAOmvt8oKKvSAg@mail.gmail.com>
References: <CANcXGiyfmVh=ajUx=Nwbvwa8pzPST3u124mo9MUeZOQrdiHudg@mail.gmail.com>
	<CANcXGiy+ArzGZJ+gDMWrQzsBF2S2hXyUsdGJdi1jZ2TqjHQ--A@mail.gmail.com>
	<50DF3F82.7050205@sapo.pt> <50DF42F9.7020001@sapo.pt>
	<CANcXGiwiY-V-aFXnQsFda0HLFszsxmcCSCUuwAOmvt8oKKvSAg@mail.gmail.com>
Message-ID: <50E0D4DF.7010705@gmail.com>

On 12-12-30 4:23 PM, Simone Giannerini wrote:
> Rui,
>
> thanks for looking into this and adding some relevant info,
> to me it looks more like a bug than lack of documentation, in any case
> we'll see if anyone of the core team would like to comment.

Here's a comment:  submit a patch.

Duncan Murdoch

>
> Ciao
>
> Simone
>
> On Sat, Dec 29, 2012 at 8:22 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Just to add, on documentation, to my previous post. The following
>> illustrates my point.
>>
>> # This is the last instruction in the original post.
>> plot.ts(x=1, y=1, type="n", xy.labels=FALSE) # does not show the plot
>>
>> plot.ts(x=1, y=1, xy.labels=FALSE) # does show the plot, does not label it,
>> documented
>> plot.ts(x=1, y=1, type="n") # does show the plot (labels it), not properly
>> documented
>> plot.ts(x=1:151, y=1:151, type="n") # does not show the plot, documented
>>
>> Rui Barradas
>> Em 29-12-2012 19:07, Rui Barradas escreveu:
>>>
>>> Hello,
>>>
>>> You're right, it has to do with the argument xy.labels. The relevant
>>> lines in the source are
>>> (file src/library/stats/R/ts.R, function plot.ts)
>>>
>>>            [...]
>>>            n <- length(xy $ x)          #-> default for xy.l(ines|abels)
>>>            if(missing(xy.labels)) xy.labels <- (n <= 150)
>>>            if(!is.logical(xy.labels)) {
>>>                if(!is.character(xy.labels))
>>>                    stop("'xy.labels' must be logical or character")
>>>                do.lab <- TRUE
>>>            } else do.lab <- xy.labels
>>>            [...]
>>>            ptype <-
>>>            if(do.lab) "n" else if(missing(type)) "p" else type
>>>            plot.default(xy, type = ptype,
>>>            [...]
>>>            if(do.lab)
>>>                text(xy, labels =
>>>                 if(is.character(xy.labels)) xy.labels
>>>                 else if(all(tsp(x) == tsp(y))) formatC(time(x), width = 1)
>>>                 else seq_along(xy$x),
>>>                 col = col, cex = cex)
>>>            if(xy.lines)
>>>                lines(xy, col = col, lty = lty, lwd = lwd,
>>>                  type = if(do.lab) "c" else "l")
>>>            [...]
>>>
>>> Note that this is executed only if both 'x' and 'y' are passed to plot.ts.
>>> The variable 'do.lab' will control the plot.default type and whether the
>>> points are labeled using text() and the lines() type.
>>> This variable is set according to xy.labels. This behavior is more or
>>> less documented in plot.ts:
>>>
>>> |"xy.labels|||logical, indicating if |text
>>> <http://127.0.0.1:29428/library/stats/help/text>()| labels should be
>>> used for an x-y plot, /or/ character, supplying a vector of labels to be
>>>
>>> used. The default is to label for up to 150 points, and not for more."
>>>
>>> but I believe the documentation could be more clear. It could say that
>>> in the case of a y ~ x plot, to supress the plot xy.labels should be set
>>> to FALSE.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>> Em 29-12-2012 17:04, Simone Giannerini escreveu:
>>>>
>>>> Dear all,
>>>>
>>>> I think I have found a buglet in plot.ts
>>>>
>>>> plot.ts(x=1,type="n")     # correct: does not show the plot
>>>> plot.ts(x=1,y=1,type="n") # not correct: does show the plot
>>>>
>>>> I did not investigate the problem in depth but it could be related to
>>>> the switch xy.labels, in fact
>>>>
>>>> plot.ts(x=1,y=1,type="n",xy.labels=TRUE) #  does show the plot
>>>> plot.ts(x=1,y=1,type="n",xy.labels=FALSE) # does not show the plot
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.15.2 Patched (2012-10-26 r61028)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
>>>> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=Italian_Italy.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_2.15.2
>>>>
>>>>
>>>> Kind regards
>>>>
>>>> Simone
>>>> ______________________________________________________
>>>>
>>>>
>>>> Simone Giannerini
>>>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>>>> Universita' di Bologna
>>>> Via delle belle arti 41 - 40126  Bologna,  ITALY
>>>> Tel: +39 051 2098262  Fax: +39 051 232153
>>>> http://www2.stat.unibo.it/giannerini/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
>


From johan2sson at gmail.com  Sun Dec 30 15:07:49 2012
From: johan2sson at gmail.com (Johan Johansson)
Date: Sun, 30 Dec 2012 15:07:49 +0100
Subject: [Rd] Does dlltools in 64-bit rtools for windows support 64-bit
	machine type?
Message-ID: <CAEeinJ9f1SwgVmtYNtmJqmtM2ZrVHzO1hM3ectLXpcdVbF5RDQ@mail.gmail.com>

Hi,

I've been trying to get the python bridge (rpy2) to build for 64-bit R
and python. The current stumbling block is that mingw can't use the
python27.lib file that comes with CPython and so I need to generate
libpython27.a.

When I use dlltool from rtools to do that however, I end up with a 32-bit file:

>"G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool" -e libpython27.a -d python27.def python27.dll
>objdump -f libpython27.a

libpython27.a:     file format pe-i386

More problematically, x86_64 is not listed as supported by objdump:

Usage G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool <option(s)>
<object-file(s)>
   -m --machine <machine>    Create as DLL for <machine>.  [default: i386]
        possible <machine>: arm[_interwork], i386,
mcore[-elf]{-le|-be}, ppc, thumb

Am I doing it wrong?

Regards,
Johan


From karl.forner at gmail.com  Mon Dec 31 19:08:17 2012
From: karl.forner at gmail.com (Karl Forner)
Date: Mon, 31 Dec 2012 19:08:17 +0100
Subject: [Rd] weird bug with parallel, RSQlite and tcltk
Message-ID: <CAMd4_Ac0+CgORVFfhFAXTttAza1iG1aagZ08j_E-U-rYZspLXg@mail.gmail.com>

Hello,

I spent a lot of a time on a weird bug, and I just managed to narrow it down.

In parallel code (here with parallel::mclappy, but I got it
doMC/multicore too), if the library(tcltk) is loaded, R hangs when
trying to open a DB connection.
I got the same behaviour on two different computers, one dual-core,
and one 2 xeon quad-core.

Here's the code:

library(parallel)
library(RSQLite)
library(tcltk)
#unloadNamespace("tcltk")

res <- mclapply(1:2, function(x) {
	db <- DBI::dbConnect("SQLite", ":memory:")
}, mc.cores=2)
print("Done")	

When I execute it (R --vanilla  < test_parallel_db.R), it hangs
forever, and I have to type several times CTRL+C to interrupt it. I
then get this message:

Warning messages:
1: In selectChildren(ac, 1) : error 'Interrupted system call' in select
2: In selectChildren(ac, 1) : error 'Interrupted system call' in select

Then, just remove library(tcltk), or uncomment
unloadNamespace("tcltk"), and it works fine again.

I guess there's a bug somewhere, but where exactly ?

Best,

Karl Forner

Further info:


R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

ubuntu 12.04 and 12.10

ubuntu package tk8.5


From murdoch.duncan at gmail.com  Mon Dec 31 19:19:26 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 31 Dec 2012 13:19:26 -0500
Subject: [Rd] Does dlltools in 64-bit rtools for windows support 64-bit
 machine type?
In-Reply-To: <CAEeinJ9f1SwgVmtYNtmJqmtM2ZrVHzO1hM3ectLXpcdVbF5RDQ@mail.gmail.com>
References: <CAEeinJ9f1SwgVmtYNtmJqmtM2ZrVHzO1hM3ectLXpcdVbF5RDQ@mail.gmail.com>
Message-ID: <50E1D72E.2010208@gmail.com>

On 12-12-30 9:07 AM, Johan Johansson wrote:
> Hi,
>
> I've been trying to get the python bridge (rpy2) to build for 64-bit R
> and python. The current stumbling block is that mingw can't use the
> python27.lib file that comes with CPython and so I need to generate
> libpython27.a.
>
> When I use dlltool from rtools to do that however, I end up with a 32-bit file:
>
>> "G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool" -e libpython27.a -d python27.def python27.dll
>> objdump -f libpython27.a
>
> libpython27.a:     file format pe-i386
>
> More problematically, x86_64 is not listed as supported by objdump:
>
> Usage G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool <option(s)>
> <object-file(s)>
>     -m --machine <machine>    Create as DLL for <machine>.  [default: i386]
>          possible <machine>: arm[_interwork], i386,
> mcore[-elf]{-le|-be}, ppc, thumb
>
> Am I doing it wrong?

You aren't using the same flags as R uses in its builds.  For 64 bit 
builds, it uses these flags (from MkRules.rules):

DLLTOOLFLAGS=--as $(BINPREF)as $(DT_ARCH) -k

DT_ARCH = -m i386:x86-64 --as-flags --64

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Dec 31 20:43:31 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Dec 2012 19:43:31 +0000
Subject: [Rd] Does dlltools in 64-bit rtools for windows support 64-bit
 machine type?
In-Reply-To: <50E1D72E.2010208@gmail.com>
References: <CAEeinJ9f1SwgVmtYNtmJqmtM2ZrVHzO1hM3ectLXpcdVbF5RDQ@mail.gmail.com>
	<50E1D72E.2010208@gmail.com>
Message-ID: <50E1EAE3.6070703@stats.ox.ac.uk>

On 31/12/2012 18:19, Duncan Murdoch wrote:
> On 12-12-30 9:07 AM, Johan Johansson wrote:
>> Hi,
>>
>> I've been trying to get the python bridge (rpy2) to build for 64-bit R
>> and python. The current stumbling block is that mingw can't use the
>> python27.lib file that comes with CPython and so I need to generate
>> libpython27.a.

BTW, 'mingw' is irrelevant as it has not been used by R for a long time. 
  Mingw's dlltool is indeed 32-bit only.

>> When I use dlltool from rtools to do that however, I end up with a
>> 32-bit file:
>>
>>> "G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool" -e libpython27.a
>>> -d python27.def python27.dll
>>> objdump -f libpython27.a
>>
>> libpython27.a:     file format pe-i386
>>
>> More problematically, x86_64 is not listed as supported by objdump:
>>
>> Usage G:\Rtools\gcc-4.6.3\i686-w64-mingw32\bin\dlltool <option(s)>
>> <object-file(s)>
>>     -m --machine <machine>    Create as DLL for <machine>.  [default:
>> i386]
>>          possible <machine>: arm[_interwork], i386,
>> mcore[-elf]{-le|-be}, ppc, thumb
>>
>> Am I doing it wrong?
>
> You aren't using the same flags as R uses in its builds.  For 64 bit
> builds, it uses these flags (from MkRules.rules):
>
> DLLTOOLFLAGS=--as $(BINPREF)as $(DT_ARCH) -k
>
> DT_ARCH = -m i386:x86-64 --as-flags --64

The irrational mess of flags in GNU bintools is not our doing, and 
suggestions upstream to support e.g. -m64 have fallen on deaf ears.  At 
least a useR does not need to divine this from the bintools 
documentation (at least at the time I had to read the sources as it was 
not in the bintools manual).

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marius.hofert at math.ethz.ch  Mon Dec 31 22:20:48 2012
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Mon, 31 Dec 2012 22:20:48 +0100
Subject: [Rd] weird bug with parallel, RSQlite and tcltk
Message-ID: <87wqvxsytr.fsf@sklar.v.cablecom.net>

Dear Karl,

I get exactly the same warning messages with an Rmpi minimal example (also took
me a while to narrow it down). I posted it on R-sig-hpc (more appropriate for
these issues I believe), some days ago, but haven't received an answer yet.

Cheers,

Marius

PS: https://stat.ethz.ch/pipermail/r-sig-hpc/2012-December/001572.html


From simon.urbanek at r-project.org  Mon Dec 31 22:58:44 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 31 Dec 2012 16:58:44 -0500
Subject: [Rd] weird bug with parallel, RSQlite and tcltk
In-Reply-To: <CAMd4_Ac0+CgORVFfhFAXTttAza1iG1aagZ08j_E-U-rYZspLXg@mail.gmail.com>
References: <CAMd4_Ac0+CgORVFfhFAXTttAza1iG1aagZ08j_E-U-rYZspLXg@mail.gmail.com>
Message-ID: <52B72508-C480-4DF3-B1E6-8B9DDA0DFD78@r-project.org>


On Dec 31, 2012, at 1:08 PM, Karl Forner wrote:

> Hello,
> 
> I spent a lot of a time on a weird bug, and I just managed to narrow it down.
> 

First, tcltk and multicore don't mix well, see the warning in the documentation (it mentions GUIs and AFAIR tcltk fires up a GUI event loop even if you don't actually create GUI elements). Second, using any kind of descriptors in parallel code is asking for trouble since those will be owned by multiple processes. If you use databases files, etc. they must be opened in the parallel code, they cannot be shared by multiple workers. The latter is ok in your code so you're probably bitten by the former.

Cheers,
Simon



> In parallel code (here with parallel::mclappy, but I got it
> doMC/multicore too), if the library(tcltk) is loaded, R hangs when
> trying to open a DB connection.
> I got the same behaviour on two different computers, one dual-core,
> and one 2 xeon quad-core.
> 
> Here's the code:
> 
> library(parallel)
> library(RSQLite)
> library(tcltk)
> #unloadNamespace("tcltk")
> 
> res <- mclapply(1:2, function(x) {
> 	db <- DBI::dbConnect("SQLite", ":memory:")
> }, mc.cores=2)
> print("Done")	
> 
> When I execute it (R --vanilla  < test_parallel_db.R), it hangs
> forever, and I have to type several times CTRL+C to interrupt it. I
> then get this message:
> 
> Warning messages:
> 1: In selectChildren(ac, 1) : error 'Interrupted system call' in select
> 2: In selectChildren(ac, 1) : error 'Interrupted system call' in select
> 
> Then, just remove library(tcltk), or uncomment
> unloadNamespace("tcltk"), and it works fine again.
> 
> I guess there's a bug somewhere, but where exactly ?
> 
> Best,
> 
> Karl Forner
> 
> Further info:
> 
> 
> R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
> Copyright (C) 2012 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> ubuntu 12.04 and 12.10
> 
> ubuntu package tk8.5
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Mon Dec 31 22:59:13 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 31 Dec 2012 16:59:13 -0500
Subject: [Rd] weird bug with parallel, RSQlite and tcltk
In-Reply-To: <87wqvxsytr.fsf@sklar.v.cablecom.net>
References: <87wqvxsytr.fsf@sklar.v.cablecom.net>
Message-ID: <6706E137-D96A-4AB1-B578-FC862031C31D@r-project.org>


On Dec 31, 2012, at 4:20 PM, Marius Hofert wrote:

> Dear Karl,
> 
> I get exactly the same warning messages with an Rmpi minimal example (also took
> me a while to narrow it down). I posted it on R-sig-hpc (more appropriate for
> these issues I believe), some days ago, but haven't received an answer yet.
> 

AFAIR MPI doesn't support forking.

Cheers,
Simon


> Cheers,
> 
> Marius
> 
> PS: https://stat.ethz.ch/pipermail/r-sig-hpc/2012-December/001572.html
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


