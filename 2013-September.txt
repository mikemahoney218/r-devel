From skostysh at princeton.edu  Sun Sep  1 08:45:08 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sun, 1 Sep 2013 02:45:08 -0400
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
Message-ID: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>

'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.

Attached is a patch against r63780 that removes the duplicate
definition and alphabetizes the functions.

I've read that minor patches such as this should be sent to r-devel [1].

Scott

[1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987


--
Scott Kostyshak
Economics PhD Candidate
Princeton University
-------------- next part --------------
Index: src/library/tcltk/R/Tk.R
===================================================================
--- src/library/tcltk/R/Tk.R	(revision 63780)
+++ src/library/tcltk/R/Tk.R	(working copy)
@@ -493,12 +493,11 @@
 tkbbox          <- function(widget, ...) tcl(widget, "bbox", ...)
 tkcanvasx       <- function(widget, ...) tcl(widget, "canvasx", ...)
 tkcanvasy       <- function(widget, ...) tcl(widget, "canvasy", ...)
+tkcget          <- function(widget, ...) tcl(widget, "cget", ...)
 tkcompare       <- function(widget, ...) tcl(widget, "compare", ...)
 tkconfigure     <- function(widget, ...) tcl(widget, "configure", ...)
 tkcoords        <- function(widget, ...) tcl(widget, "coords", ...)
 tkcreate        <- function(widget, ...) tcl(widget, "create", ...)
-tkcget          <- function(widget, ...) tcl(widget, "cget", ...)
-tkcoords        <- function(widget, ...) tcl(widget, "coords", ...)
 tkcurselection  <- function(widget, ...) tcl(widget, "curselection", ...)
 tkdchars        <- function(widget, ...) tcl(widget, "dchars", ...)
 tkdebug         <- function(widget, ...) tcl(widget, "debug", ...)
@@ -508,8 +507,8 @@
 tkdlineinfo     <- function(widget, ...) tcl(widget, "dlineinfo", ...)
 tkdtag          <- function(widget, ...) tcl(widget, "dtag", ...)
 tkdump          <- function(widget, ...) tcl(widget, "dump", ...)
+tkentrycget     <- function(widget, ...) tcl(widget, "entrycget", ...)
 tkentryconfigure <- function(widget, ...) tcl(widget, "entryconfigure", ...)
-tkentrycget     <- function(widget, ...) tcl(widget, "entrycget", ...)
 tkfind          <- function(widget, ...) tcl(widget, "find", ...)
 tkflash         <- function(widget, ...) tcl(widget, "flash", ...)
 tkfraction      <- function(widget, ...) tcl(widget, "fraction", ...)
@@ -535,11 +534,11 @@
 tkmark.unset    <- function(widget, ...) tcl(widget, "mark", "unset", ...)
 tkmove          <- function(widget, ...) tcl(widget, "move", ...)
 tknearest       <- function(widget, ...) tcl(widget, "nearest", ...)
+tkpostcascade   <- function(widget, ...) tcl(widget, "postcascade", ...)
 tkpost          <- function(widget, ...) tcl(widget, "post", ...)
-tkpostcascade   <- function(widget, ...) tcl(widget, "postcascade", ...)
 tkpostscript    <- function(widget, ...) tcl(widget, "postscript", ...)
+tkscan.dragto   <- function(widget, ...) tcl(widget, "scan", "dragto", ...)
 tkscan.mark     <- function(widget, ...) tcl(widget, "scan", "mark", ...)
-tkscan.dragto   <- function(widget, ...) tcl(widget, "scan", "dragto", ...)
 tksearch        <- function(widget, ...) tcl(widget, "search", ...)
 tksee           <- function(widget, ...) tcl(widget, "see", ...)
 tkselect        <- function(widget, ...) tcl(widget, "select", ...)
@@ -563,7 +562,6 @@
     tcl(widget, "selection", "to", ...)
 tkset           <- function(widget, ...) tcl(widget, "set", ...)
 tksize          <- function(widget, ...) tcl(widget, "size", ...)
-tktoggle        <- function(widget, ...) tcl(widget, "toggle", ...)
 tktag.add       <- function(widget, ...) tcl(widget, "tag", "add", ...)
 tktag.bind      <- function(widget, ...) tcl(widget, "tag", "bind", ...)
 tktag.cget      <- function(widget, ...) tcl(widget, "tag", "cget", ...)
@@ -576,6 +574,7 @@
 tktag.raise     <- function(widget, ...) tcl(widget, "tag", "raise", ...)
 tktag.ranges    <- function(widget, ...) tcl(widget, "tag", "ranges", ...)
 tktag.remove    <- function(widget, ...) tcl(widget, "tag", "remove", ...)
+tktoggle        <- function(widget, ...) tcl(widget, "toggle", ...)
 tktype          <- function(widget, ...) tcl(widget, "type", ...)
 tkunpost        <- function(widget, ...) tcl(widget, "unpost", ...)
 tkwindow.cget   <- function(widget, ...) tcl(widget, "window", "cget", ...)

From murdoch.duncan at gmail.com  Sun Sep  1 20:08:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 01 Sep 2013 14:08:53 -0400
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
In-Reply-To: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
References: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
Message-ID: <522382B5.40106@gmail.com>

On 13-09-01 2:45 AM, Scott Kostyshak wrote:
> 'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.
>
> Attached is a patch against r63780 that removes the duplicate
> definition and alphabetizes the functions.
>
> I've read that minor patches such as this should be sent to r-devel [1].
>
> Scott
>
> [1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987

Thanks.  I would not do the alphabetization; that makes it much harder 
to track changes.  But if tkcoords is unnecessarily duplicated, that 
seems like a reasonable change.

Duncan Murdoch


From pdalgd at gmail.com  Sun Sep  1 21:53:57 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 1 Sep 2013 21:53:57 +0200
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
In-Reply-To: <522382B5.40106@gmail.com>
References: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
	<522382B5.40106@gmail.com>
Message-ID: <6CEB142B-5088-44A0-82C6-EE1CB4380034@gmail.com>


On Sep 1, 2013, at 20:08 , Duncan Murdoch wrote:

> On 13-09-01 2:45 AM, Scott Kostyshak wrote:
>> 'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.
>> 
>> Attached is a patch against r63780 that removes the duplicate
>> definition and alphabetizes the functions.
>> 
>> I've read that minor patches such as this should be sent to r-devel [1].
>> 
>> Scott
>> 
>> [1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987
> 
> Thanks.  I would not do the alphabetization; that makes it much harder to track changes.  But if tkcoords is unnecessarily duplicated, that seems like a reasonable change.
> 

That's what I thought at first sight, but actually, the current breach of alphabetization is quite slight, so might be worth fixing after all, since it helps against putting the same function in twice... (the patch has tkpostcascade before tkpost, which is wrong, though).

-pd

> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Mon Sep  2 00:42:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 01 Sep 2013 18:42:25 -0400
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
In-Reply-To: <6CEB142B-5088-44A0-82C6-EE1CB4380034@gmail.com>
References: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
	<522382B5.40106@gmail.com>
	<6CEB142B-5088-44A0-82C6-EE1CB4380034@gmail.com>
Message-ID: <5223C2D1.2020402@gmail.com>

On 13-09-01 3:53 PM, peter dalgaard wrote:
>
> On Sep 1, 2013, at 20:08 , Duncan Murdoch wrote:
>
>> On 13-09-01 2:45 AM, Scott Kostyshak wrote:
>>> 'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.
>>>
>>> Attached is a patch against r63780 that removes the duplicate
>>> definition and alphabetizes the functions.
>>>
>>> I've read that minor patches such as this should be sent to r-devel [1].
>>>
>>> Scott
>>>
>>> [1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987
>>
>> Thanks.  I would not do the alphabetization; that makes it much harder to track changes.  But if tkcoords is unnecessarily duplicated, that seems like a reasonable change.
>>
>
> That's what I thought at first sight, but actually, the current breach of alphabetization is quite slight, so might be worth fixing after all, since it helps against putting the same function in twice... (the patch has tkpostcascade before tkpost, which is wrong, though).

In that case, go ahead.  I didn't look at the patch due to the 
description.  (I have committed the removal of the dupe.)

Duncan Murdoch


From pdalgd at gmail.com  Mon Sep  2 07:37:21 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Sep 2013 07:37:21 +0200
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
In-Reply-To: <5223C2D1.2020402@gmail.com>
References: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
	<522382B5.40106@gmail.com>
	<6CEB142B-5088-44A0-82C6-EE1CB4380034@gmail.com>
	<5223C2D1.2020402@gmail.com>
Message-ID: <20137114-5C05-48B5-B2C3-C63464EA02A8@gmail.com>


On Sep 2, 2013, at 00:42 , Duncan Murdoch wrote:

> On 13-09-01 3:53 PM, peter dalgaard wrote:
>> 
>> On Sep 1, 2013, at 20:08 , Duncan Murdoch wrote:
>> 
>>> On 13-09-01 2:45 AM, Scott Kostyshak wrote:
>>>> 'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.
>>>> 
>>>> Attached is a patch against r63780 that removes the duplicate
>>>> definition and alphabetizes the functions.
>>>> 
>>>> I've read that minor patches such as this should be sent to r-devel [1].
>>>> 
>>>> Scott
>>>> 
>>>> [1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987
>>> 
>>> Thanks.  I would not do the alphabetization; that makes it much harder to track changes.  But if tkcoords is unnecessarily duplicated, that seems like a reasonable change.
>>> 
>> 
>> That's what I thought at first sight, but actually, the current breach of alphabetization is quite slight, so might be worth fixing after all, since it helps against putting the same function in twice... (the patch has tkpostcascade before tkpost, which is wrong, though).
> 
> In that case, go ahead.  I didn't look at the patch due to the description.  (I have committed the removal of the dupe.)
> 

OK, done. R-devel only, like your change. 

> Duncan Murdoch
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From skostysh at princeton.edu  Mon Sep  2 09:39:22 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Mon, 2 Sep 2013 03:39:22 -0400
Subject: [Rd] [PATCH] remove a duplicate tk function definition (and
	alphabetize)
In-Reply-To: <20137114-5C05-48B5-B2C3-C63464EA02A8@gmail.com>
References: <CAE3=dmf7XOBCJ-zNzVEH6HV4-Rz+J5om=WghfjkN4cdnSv0XVQ@mail.gmail.com>
	<522382B5.40106@gmail.com>
	<6CEB142B-5088-44A0-82C6-EE1CB4380034@gmail.com>
	<5223C2D1.2020402@gmail.com>
	<20137114-5C05-48B5-B2C3-C63464EA02A8@gmail.com>
Message-ID: <CAE3=dmdcLhyZ7f2Tc1FgY4xw07557H4osYcgNSaK_EKa1DkchA@mail.gmail.com>

On Mon, Sep 2, 2013 at 1:37 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Sep 2, 2013, at 00:42 , Duncan Murdoch wrote:
>
>> On 13-09-01 3:53 PM, peter dalgaard wrote:
>>>
>>> On Sep 1, 2013, at 20:08 , Duncan Murdoch wrote:
>>>
>>>> On 13-09-01 2:45 AM, Scott Kostyshak wrote:
>>>>> 'tkcoords' is defined twice (in the same way) in src/library/tcltk/R/Tk.R.
>>>>>
>>>>> Attached is a patch against r63780 that removes the duplicate
>>>>> definition and alphabetizes the functions.
>>>>>
>>>>> I've read that minor patches such as this should be sent to r-devel [1].
>>>>>
>>>>> Scott
>>>>>
>>>>> [1] http://permalink.gmane.org/gmane.comp.lang.r.devel/33987
>>>>
>>>> Thanks.  I would not do the alphabetization; that makes it much harder to track changes.  But if tkcoords is unnecessarily duplicated, that seems like a reasonable change.
>>>>
>>>
>>> That's what I thought at first sight, but actually, the current breach of alphabetization is quite slight, so might be worth fixing after all, since it helps against putting the same function in twice... (the patch has tkpostcascade before tkpost, which is wrong, though).
>>
>> In that case, go ahead.  I didn't look at the patch due to the description.  (I have committed the removal of the dupe.)

Thanks.

>>
>
> OK, done. R-devel only, like your change.

Thanks,

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From htl10 at users.sourceforge.net  Tue Sep  3 11:51:28 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 03 Sep 2013 10:51:28 +0100
Subject: [Rd] new bugs and new bundles Re: R/Sweave/cairo/freetype bug fix.
In-Reply-To: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
Message-ID: <5225B120.8050406@users.sourceforge.net>

The most up-to-date version of freetype (2.5.0.1) have problems with at least 
two of the system fonts shipped with Mac OS X. So the "p1" in "2.5.0.1p1":

cairo-1.12.16+freetype-2.5.0.1p1_macosx.tar.bz2
cairo-1.12.16+freetype-2.5.0.1p1_windows.tar.bz2

means "2.5.0.1" + 274207eb9a0e3bb20edf30e9a62e25120d5d15e5 (the fix for one of 
the problems). There might be p2 bundles if 2.5.1 doesn't come out soon enough
with fixes for the rest of the problems.

http://sourceforge.net/projects/outmodedbonsai/files/R/

Just so we are clear, if freetype have problem with a system font, fontconfig 
has problem with a system font, and cairo and R etc.

Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for 
windows and Mac OS X at some stage, but if somebody want to beat me to it, 
please feel free to do so.

Hin-Tak Leung wrote:
> Freetype 2.4.12 was released in early May. Just so that we are clear that this is a freetype bug which affects R's use of Cairo (among other things). So there are updated bundles, and also bundles for Mac OS X as well, for both a patched 2.4.11 and 2.4.12 proper. The accompanying *.txt has a listing of versions.
>
> http://sourceforge.net/projects/outmodedbonsai/files/R/
>
> Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for windows and Mac OS X at some stage, but if somebody want to beat me to it, please feel free to do so.
>
> --- On Tue, 2/4/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:
>
>> --- On Mon, 1/4/13, Hin-Tak Leung
>> <htl10 at users.sourceforge.net>
>> wrote:
>>> --- On Sat, 30/3/13, Hin-Tak Leung
>>> <htl10 at users.sourceforge.net>
>>> wrote:
>>>
>>>> "... was committed to freetype in January and will
>> form
>>> the
>>>> next release (2.4.12)".
>>>
>>> It is perhaps worth repeating the quote:  'The
>> official
>>> R binaries for windows ... are compiled against static
>>> libraries of cairo 1.10.2 ... are firmly in the "do not
>> work
>>> correctly" category'
>>>
>>> The minimum version of cairo to work being 1.11.2. On
>> closer
>>> examination, the official bundle (http://www.rforge.net/Cairo/files/cairo-current-win.tar.gz)
>>> is built with neither fontconfig nor freetype. So even
>> if it
>>> is bumped to current version (1.12.x), it does not
>> work
>>> correctly.
>>
>> Here is a drop-in replacement for the above:
>> http://sourceforge.net/projects/outmodedbonsai/files/R/cairo-1.12.14%2Bft%2Bfc-win.tar.gz
>>
>> Besides being over 2 years more up-to-date, cairo (1.12.14)
>> is also built with fontconfig and freetype enabled, and
>> freetype being 2.4.11 + back-ported patch (https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35)
>> so at least there is a a better chance of R working
>> correctly.
>>
>> The full list of the tar ball is (a superset of the above,
>> due to addition of fontconfig and freetype and their
>> dependencies):
>> -------
>> cairo-1.12.14
>> pixman-0.26.2
>> libpng-1.5.13
>> zlib-1.2.7
>> fontconfig-2.10.1
>> freetype-2.4.11 (patched)
>> glib2-2.34.3
>> expat-2.1.0
>> bzip2-1.0.6
>> libffi-3.0.11
>> gettext-0.18.2
>> ---------
>> This allows the C-based cairo bug demo (#c10) to build so I
>> am sure it is sufficient for building windows R. At some
>> stage I'll rebuild a less-buggy R 2.15.3 for windows, but
>> not for a few weeks so if somebody wants to beat me to it,
>> please feel free to do so.
>>
>>> Perhaps also wasn't clear in the bugzilla thread -
>> everybody
>>> from fontconfig/cairo/freetype involved knew it being
>> the
>>> issue so it has never been explicitly spelled out -
>> the
>>> problem was (is) with cairo's pdf/ps generation, aided
>> by
>>> freetype.
>>>
>>>> ------------------------------
>>>> On Sat, Mar 30, 2013 18:54 GMT Simon Urbanek
>> wrote:
>>>>
>>>>> On Mar 30, 2013, at 9:24 AM, Hin-Tak Leung
>> wrote:
>>>>>
>>>>>> Perhaps that's too much details. There
>> is
>>> (will be)
>>>> a new freetype because of cairo's unanticipated
>> usage
>>> (which
>>>> R uses, among other cairo users). Most people
>> should
>>> upgrade
>>>> or request an upgrade eventually, when they are
>>>> comfortable.
>>>>>>
>>>>>
>>>>> Which versions are affected? R binary for OS
>> X
>>> uses
>>>> freetype 2.4.11 (and cairo 1.12.14) so I just need
>> to
>>> know
>>>> if there is an action item.
>>>>>
>>>>> Thanks,
>>>>> SImon
>>>>>
>>>>>
>>>>>
>>>>>> --- On Sat, 30/3/13, peter dalgaard
>> <pdalgd at gmail.com>
>>>> wrote:
>>>>>>
>>>>>> Huh?
>>>>>>
>>>>>> This is utterly incomprehensible without
>>> reading
>>>> the redhat
>>>>>> bugzilla, and even after reading, I'm not
>> sure
>>> what
>>>> the
>>>>>> issue is. Something with bold Chinese
>> fonts in
>>> X11,
>>>> but
>>>>>> maybe also affecting Latin fonts, ....?
>>>>>>
>>>>>> Please explain yourself.
>>>>>>
>>>>>> -pd
>>>>>>
>>>>>> On Mar 30, 2013, at 09:25 , Hin-Tak
>> Leung
>>> wrote:
>>>>>>
>>>>>>> The problem was first seen with
>> R/Sweave
>>> (#c0)
>>>> then
>>>>>> reproduced directly with cairo (#c10) and
>> was
>>>> eventually
>>>>>> traced to freetype. The 5-part bug fix:
>>>>>>>
>> 610ee58e07090ead529849b2a454bb6c503b4995
>>>>>>>
>> da11e5e7647b668dee46fd0418ea5ecbc33ae3b2
>>>>>>>
>> e1a2ac1900f2f16ec48fb4840a6b7965a8373c2b
>>>>>>>
>> 869fb8c49ddf292d6daf4826172a308973d3e11f
>>>>>>>
>> d56e544d653b09c657911629557ffc5277a503e3
>>>>>>> was committed to freetype in January
>> and
>>> will
>>>> form the
>>>>>> next release (2.4.12). They were back
>> ported
>>> to
>>>> 2.4.11
>>>>>>> https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35
>>>>>>> and the redhat people had further
>>> back-ported
>>>> it to
>>>>>> 2.4.10 for fedora 18/19 (#c51).
>>>>>>>
>>>>>>> The freetype people had reproduced
>> the
>>> problem
>>>> with a
>>>>>> latin font, so this affects most people,
>>> unlike
>>>> what the
>>>>>> initial report (#c0) suggests.
>>>>>>>
>>>>>>> Since freetype is part of X11, most
>>> unix/linux
>>>> users
>>>>>> would be understandably nervous about
>> breaking
>>> X
>>>> (see #c45
>>>>>> for screenshot of broken gnome terminal!)
>> and
>>>> should wait up
>>>>>> to a year before the new and
>> not-yet-released
>>>> 2.4.12 becomes
>>>>>> an official upgrade; or contact their
>>> favourite
>>>> unix vendors
>>>>>> and/or Apple for upgrades. AFAIK,
>> current
>>>> up-to-date linux
>>>>>> distributions ships the rather older
>> 2.4.10,
>>> with
>>>> the
>>>>>> exception of fedora 18/19 (#c51). Mac OS
>> X
>>> 10.5
>>>> ships
>>>>>> freetype 2.3.5 as part of X11; I haven't
>>> bother
>>>> looking up
>>>>>> later Mac OS X's.
>>>>>>>
>>>>>>> The official R binaries for windows
>> and
>>> mac OS
>>>> X are
>>>>>> compiled against static libraries of
>> cairo
>>> 1.10.2
>>>> (over 2
>>>>>> years old), and cairo 1.11.2 and
>> freetype
>>> 2.4.4
>>>>>> respectively, and are firmly in the "do
>> not
>>> work
>>>> correctly"
>>>>>> category.
>>>>>>>
>>>>>>> The long and short of the story is
>> that
>>>> R/Sweave uses a
>>>>>> feature of cairo which wasn't
>> implemented
>>> before
>>>> cairo
>>>>>> 1.11.2 (#c13, Jan 2011), which in turn
>> depends
>>> on a
>>>> feature
>>>>>> of freetype that has been around since
>> 2005
>>> but did
>>>> not
>>>>>> anticipate cairo's usage. It is
>> commendable
>>> that
>>>> the
>>>>>> freetype people did not refer to cairo's
>> usage
>>> as
>>>> "misuse"
>>>>>> but took the patience to address the
>> problem,
>>>> unlike some
>>>>>> group's style.
>>>>>>>
>>>>>>> It has been an interesting few
>> months
>>> returning
>>>> to
>>>>>> freetype after about 17 years, I think.
>>>>>>>
>>>>>>> Here is how to look up what version
>> of
>>> freetype
>>>> -
>>>>>> libfreetype.so.x.y.z for most unix
>> platforms,
>>> and
>>>>>> /usr/X11/lib/libfreetype.x.y.z.dylib on
>> Mac OS
>>> X:
>>>>>>>
>>>>>>> (excerpt from docs/VERSION.DLL)
>>>>>>>
>>>>>>>        version
>>>>>> x.y.z   date of release
>>>>>>>        2.4.11
>>>>>>      6.10.0  Dec 2012
>>>>>>>        2.4.10
>>>>>>      6.9.0   June 2012
>>>>>>>        2.4.9
>>>>
>>>>>> 6.8.1   March 2012
>>>>>>> ...
>>>>>>>        2.4.4
>>>>
>>>>>> 6.6.2   Nov 2010  (official R
>>>> mac
>>>>>> binaries)
>>>>>>> ...
>>>>>>>        2.3.5
>>>>
>>>>>> 6.3.16  July 2007 (Mac OS X 10.5)
>>>>>>>
>>>>>>>
>>>>>>>
>>> ______________________________________________
>>>>>>> R-devel at r-project.org
>>>>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>> --
>>>>>> Peter Dalgaard, Professor,
>>>>>> Center for Statistics, Copenhagen
>> Business
>>> School
>>>>>> Solbjerg Plads 3, 2000 Frederiksberg,
>> Denmark
>>>>>> Phone: (+45)38153501
>>>>>> Email: pd.mes at cbs.dk
>>>>>> Priv: PDalgd at gmail.com
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>> ______________________________________________
>>>>>> R-devel at r-project.org
>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>


From gianluca.mastrantonio at yahoo.it  Tue Sep  3 22:48:43 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Tue, 03 Sep 2013 22:48:43 +0200
Subject: [Rd] libR.so: cannot open shared object file
Message-ID: <52264B2B.5020005@yahoo.it>

Hi all

I have a R code that incorporates a C++ programm. I compiled the C++ 
code with the following:

R CMD SHLIB   Model.cpp -Wall funzioni.cpp

it seems to work fine but when i run the R code i get this error message

Error in dyn.load(paste(dir_func, "Model.so", sep = "")) :
   unable to load shared object '/lustre/work/uuu/RCpp/Model.so':
   libR.so: cannot open shared object file: No such file or directory

I don't know how to fix it.
The code is running on a cluster.

Thanks.


From edd at debian.org  Tue Sep  3 23:14:29 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 3 Sep 2013 16:14:29 -0500
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <52264B2B.5020005@yahoo.it>
References: <52264B2B.5020005@yahoo.it>
Message-ID: <21030.20789.769106.335326@max.nulle.part>


On 3 September 2013 at 22:48, gianluca.mastrantonio at yahoo.it wrote:
| Hi all
| 
| I have a R code that incorporates a C++ programm. I compiled the C++ 
| code with the following:
| 
| R CMD SHLIB   Model.cpp -Wall funzioni.cpp
| 
| it seems to work fine but when i run the R code i get this error message
| 
| Error in dyn.load(paste(dir_func, "Model.so", sep = "")) :
|    unable to load shared object '/lustre/work/uuu/RCpp/Model.so':
|    libR.so: cannot open shared object file: No such file or directory
| 
| I don't know how to fix it.
| The code is running on a cluster.

Qualified guess:  you ran R CMD SHLIB on the _central / master_ node, but not
the _compute_ nodes.   They never got the object file.

One more rigorous approach would be to wrap your function up in a package,
and have each compute node load the package.

Hope this helps,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From gianluca.mastrantonio at yahoo.it  Tue Sep  3 23:27:18 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Tue, 03 Sep 2013 23:27:18 +0200
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <21030.20789.769106.335326@max.nulle.part>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
Message-ID: <52265436.9060800@yahoo.it>

One problem is that i have not the privileges to install a package.


Il 03/09/13 23:14, Dirk Eddelbuettel ha scritto:
> On 3 September 2013 at 22:48, gianluca.mastrantonio at yahoo.it wrote:
> | Hi all
> |
> | I have a R code that incorporates a C++ programm. I compiled the C++
> | code with the following:
> |
> | R CMD SHLIB   Model.cpp -Wall funzioni.cpp
> |
> | it seems to work fine but when i run the R code i get this error message
> |
> | Error in dyn.load(paste(dir_func, "Model.so", sep = "")) :
> |    unable to load shared object '/lustre/work/uuu/RCpp/Model.so':
> |    libR.so: cannot open shared object file: No such file or directory
> |
> | I don't know how to fix it.
> | The code is running on a cluster.
>
> Qualified guess:  you ran R CMD SHLIB on the _central / master_ node, but not
> the _compute_ nodes.   They never got the object file.
>
> One more rigorous approach would be to wrap your function up in a package,
> and have each compute node load the package.
>
> Hope this helps,  Dirk
>


From geoffjentry at hexdump.org  Wed Sep  4 00:04:31 2013
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Tue, 3 Sep 2013 15:04:31 -0700 (PDT)
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <52265436.9060800@yahoo.it>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
Message-ID: <alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>

> One problem is that i have not the privileges to install a package.

If you have a writable area you can install to there with the 
--library=LIB argument and then load the package using the lib.loc command.


From ripley at stats.ox.ac.uk  Wed Sep  4 00:14:23 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 03 Sep 2013 23:14:23 +0100
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
Message-ID: <52265F3F.9080200@stats.ox.ac.uk>

On 03/09/2013 23:04, Geoff Jentry wrote:
>> One problem is that i have not the privileges to install a package.
>
> If you have a writable area you can install to there with the
> --library=LIB argument and then load the package using the lib.loc command.

Actually, that will all happen automatically: package installation will 
create a personal library for you.  See e.g. ?.libPaths


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gianluca.mastrantonio at yahoo.it  Wed Sep  4 00:19:01 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Wed, 04 Sep 2013 00:19:01 +0200
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
Message-ID: <52266055.2000000@yahoo.it>

Can you add some details?

Suppose i have the package Model.tar.gz and my writable are is in 
user/area, what i have to do next to install the package?

Il 04/09/13 00:04, Geoff Jentry ha scritto:
>> One problem is that i have not the privileges to install a package.
>
> If you have a writable area you can install to there with the 
> --library=LIB argument and then load the package using the lib.loc 
> command.
>


From murdoch.duncan at gmail.com  Wed Sep  4 19:53:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Sep 2013 13:53:48 -0400
Subject: [Rd] Comments requested on "changedFiles" function
Message-ID: <522773AC.3030609@gmail.com>

In a number of places internal to R, we need to know which files have 
changed (e.g. after building a vignette).  I've just written a general 
purpose function "changedFiles" that I'll probably commit to R-devel.  
Comments on the design (or bug reports) would be appreciated.

The source for the function and the Rd page for it are inline below.

----- changedFiles.R:
changedFiles <- function(snapshot, timestamp = tempfile("timestamp"), 
file.info = NULL,
              md5sum = FALSE, full.names = FALSE, ...) {
     dosnapshot <- function(args) {
         fullnames <- do.call(list.files, c(full.names = TRUE, args))
         names <- do.call(list.files, c(full.names = full.names, args))
         if (isTRUE(file.info) || (is.character(file.info) && 
length(file.info))) {
             info <- file.info(fullnames)
         rownames(info) <- names
             if (isTRUE(file.info))
                 file.info <- c("size", "isdir", "mode", "mtime")
         } else
             info <- data.frame(row.names=names)
     if (md5sum)
         info <- data.frame(info, md5sum = tools::md5sum(fullnames))
     list(info = info, timestamp = timestamp, file.info = file.info,
          md5sum = md5sum, full.names = full.names, args = args)
     }
     if (missing(snapshot) || !inherits(snapshot, "changedFilesSnapshot")) {
         if (length(timestamp) == 1)
             file.create(timestamp)
         if (missing(snapshot)) snapshot <- "."
         pre <- dosnapshot(list(path = snapshot, ...))
         pre$pre <- pre$info
         pre$info <- NULL
         pre$wd <- getwd()
         class(pre) <- "changedFilesSnapshot"
         return(pre)
     }

     if (missing(timestamp)) timestamp <- snapshot$timestamp
     if (missing(file.info) || isTRUE(file.info)) file.info <- 
snapshot$file.info
     if (identical(file.info, FALSE)) file.info <- NULL
     if (missing(md5sum))    md5sum <- snapshot$md5sum
     if (missing(full.names)) full.names <- snapshot$full.names

     pre <- snapshot$pre
     savewd <- getwd()
     on.exit(setwd(savewd))
     setwd(snapshot$wd)

     args <- snapshot$args
     newargs <- list(...)
     args[names(newargs)] <- newargs
     post <- dosnapshot(args)$info
     prenames <- rownames(pre)
     postnames <- rownames(post)

     added <- setdiff(postnames, prenames)
     deleted <- setdiff(prenames, postnames)
     common <- intersect(prenames, postnames)

     if (length(file.info)) {
         preinfo <- pre[common, file.info]
         postinfo <- post[common, file.info]
         changes <- preinfo != postinfo
     }
     else changes <- matrix(logical(0), nrow = length(common), ncol = 0,
                            dimnames = list(common, character(0)))
     if (length(timestamp))
         changes <- cbind(changes, Newer = file_test("-nt", common, 
timestamp))
     if (md5sum) {
         premd5 <- pre[common, "md5sum"]
         postmd5 <- post[common, "md5sum"]
     changes <- cbind(changes, md5sum = premd5 != postmd5)
     }
     changes1 <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop = FALSE]
     changed <- rownames(changes1)
     structure(list(added = added, deleted = deleted, changed = changed,
         unchanged = setdiff(common, changed), changes = changes), class 
= "changedFiles")
}

print.changedFilesSnapshot <- function(x, ...) {
     cat("changedFiles snapshot:\n timestamp = \"", x$timestamp, "\"\n 
file.info = ",
         if (length(x$file.info)) paste(paste0('"', x$file.info, '"'), 
collapse=","),
         "\n md5sum = ", x$md5sum, "\n args = ", deparse(x$args, control 
= NULL), "\n", sep="")
     x
}

print.changedFiles <- function(x, ...) {
     if (length(x$added)) cat("Files added:\n",  paste0("  ", x$added, 
collapse="\n"), "\n", sep="")
     if (length(x$deleted)) cat("Files deleted:\n",  paste0("  ", 
x$deleted, collapse="\n"), "\n", sep="")
     changes <- x$changes
     changes <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop=FALSE]
     changes <- changes[, colSums(changes, na.rm = TRUE) > 0, drop=FALSE]
     if (nrow(changes)) {
         cat("Files changed:\n")
         print(changes)
     }
     x
}
----------------------

--- changedFiles.Rd:
\name{changedFiles}
\alias{changedFiles}
\alias{print.changedFiles}
\alias{print.changedFilesSnapshot}
\title{
Detect which files have changed
}
\description{
On the first call, \code{changedFiles} takes a snapshot of a selection 
of files.  In subsequent
calls, it takes another snapshot, and returns an object containing data 
on the
differences between the two snapshots.  The snapshots need not be the 
same directory;
this could be used to compare two directories.
}
\usage{
changedFiles(snapshot, timestamp = tempfile("timestamp"), file.info = NULL,
              md5sum = FALSE, full.names = FALSE, ...)
}
\arguments{
   \item{snapshot}{
The path to record, or a previous snapshot.  See the Details.
}
   \item{timestamp}{
The name of a file to write at the time the initial snapshot
is taken.  In subsequent calls, modification times of files will be 
compared to
this file, and newer files will be reported as changed.  Set to \code{NULL}
to skip this test.
}
   \item{file.info}{
A vector of columns from the result of the \code{file.info} function, or 
a logical value.  If
\code{TRUE}, columns \code{c("size", "isdir", "mode", "mtime")} will be 
used.  Set to
\code{FALSE} or \code{NULL} to skip this test.  See the Details.
}
   \item{md5sum}{
A logical value indicating whether MD5 summaries should be taken as part 
of the snapshot.
}
   \item{full.names}{
A logical value indicating whether full names (as in 
\code{\link{list.files}}) should be
recorded.
}
   \item{\dots}{
Additional parameters to pass to \code{\link{list.files}} to control the 
set of files
in the snapshots.
}
}
\details{
This function works in two modes.  If the \code{snapshot} argument is 
missing or is
not of S3 class \code{"changedFilesSnapshot"}, it is used as the 
\code{path} argument
to \code{\link{list.files}} to obtain a list of files.  If it is of class
\code{"changedFilesSnapshot"}, then it is taken to be the baseline file
and a new snapshot is taken and compared with it.  In the latter case, 
missing
arguments default to match those from the initial snapshot.

If the \code{timestamp} argument is length 1, a file with that name is 
created
in the current directory during the initial snapshot, and 
\code{\link{file_test}}
is used to compare the age of all files to it during subsequent calls.

If the \code{file.info} argument is \code{TRUE} or it contains a non-empty
character vector, the indicated columns from the result of a call to
\code{\link{file.info}} will be recorded and compared.

If \code{md5sum} is \code{TRUE}, the \code{tools::\link{md5sum}} function
will be called to record the 32 byte MD5 checksum for each file, and 
these values
will be compared.
}
\value{
In the initial snapshot phase, an object of class 
\code{"changedFilesSnapshot"} is returned.  This
is a list containing the fields
\item{pre}{a dataframe whose rownames are the filenames, and whose 
columns contain the
requested snapshot data}
\item{timestamp, file.info, md5sum, full.names}{a record of the 
arguments in the initial call}
\item{args}{other arguments passed via \code{...} to 
\code{\link{list.files}}.}

In the comparison phase, an object of class \code{"changedFiles"}. This 
is a list containing
\item{added, deleted, changed, unchanged}{character vectors of filenames 
from the before
and after snapshots, with obvious meanings}
\item{changes}{a logical matrix with a row for each common file, and a 
column for each
comparison test.  \code{TRUE} indicates a change in that test.}

\code{\link{print}} methods are defined for each of these types. The
\code{\link{print}} method for \code{"changedFilesSnapshot"} objects
displays the arguments used to produce it, while the one for
\code{"changedFiles"} displays the \code{added}, \code{deleted}
and \code{changed} fields if non-empty, and a submatrix of the 
\code{changes}
matrix containing all of the \code{TRUE} values.
}
\author{
Duncan Murdoch
}
\seealso{
\code{\link{file.info}}, \code{\link{file_test}}, \code{\link{md5sum}}.
}
\examples{
# Create some files in a temporary directory
dir <- tempfile()
dir.create(dir)
writeBin(1, file.path(dir, "file1"))
writeBin(2, file.path(dir, "file2"))
dir.create(file.path(dir, "dir"))

# Take a snapshot
snapshot <- changedFiles(dir, file.info=TRUE, md5sum=TRUE)

# Change one of the files
writeBin(3, file.path(dir, "file2"))

# Display the detected changes
changedFiles(snapshot)
changedFiles(snapshot)$changes
}
\keyword{utilities}
\keyword{file}


From geoffjentry at hexdump.org  Wed Sep  4 20:58:05 2013
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Wed, 4 Sep 2013 11:58:05 -0700 (PDT)
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <52266055.2000000@yahoo.it>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
Message-ID: <alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>

> Can you add some details?
> Suppose i have the package Model.tar.gz and my writable are is in user/area, 
> what i have to do next to install the package?

What I was picturing was something like this (forgive me if syntax isn't 
100%):

mkdir user/area/myRLib
R CMD INSTALL --library=user/area/myRLib Model.tar.gz

and then in R:
library(Model, lib.loc="user/area/myRLib")

Note though Brian Ripley's response to me where he indicates that this is 
handled automatically.

-J


From ripley at stats.ox.ac.uk  Wed Sep  4 22:42:15 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 04 Sep 2013 21:42:15 +0100
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
Message-ID: <52279B27.8060801@stats.ox.ac.uk>

On 04/09/2013 19:58, Geoff Jentry wrote:
>> Can you add some details?
>> Suppose i have the package Model.tar.gz and my writable are is in
>> user/area, what i have to do next to install the package?
>
> What I was picturing was something like this (forgive me if syntax isn't
> 100%):
>
> mkdir user/area/myRLib
> R CMD INSTALL --library=user/area/myRLib Model.tar.gz
>
> and then in R:
> library(Model, lib.loc="user/area/myRLib")
>
> Note though Brian Ripley's response to me where he indicates that this
> is handled automatically.

Yes,  install.packages("Model.tar.gz") should suffice.

>
> -J
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kmillar at google.com  Thu Sep  5 02:02:49 2013
From: kmillar at google.com (Karl Millar)
Date: Wed, 4 Sep 2013 17:02:49 -0700
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522773AC.3030609@gmail.com>
References: <522773AC.3030609@gmail.com>
Message-ID: <CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130904/9b924360/attachment.pl>

From murdoch.duncan at gmail.com  Thu Sep  5 03:10:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Sep 2013 21:10:57 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
Message-ID: <5227DA21.8000202@gmail.com>

On 13-09-04 8:02 PM, Karl Millar wrote:
> Hi Duncan,
>
> I think this functionality would be much easier to use and understand if
> you split it up the functionality of taking snapshots and comparing them
> into separate functions.

Yes, that's another possibility.  Some more comment below...


  In addition, the 'timestamp' functionality
> seems both confusing and brittle to me.  I think it would be better to
> store file modification times in the snapshot and use those instead of
> an external file.  Maybe:

You can do that, using file.info = "mtime", but the file.info snapshots 
are quite a bit slower than using the timestamp file (when looking at a 
big recursive directory of files).

>
> # Take a snapshot of the files.
> takeFileSnapshot(directory, file.info <http://file.info> = TRUE, md5sum
> = FALSE, full.names = FALSE, recursive = TRUE, ...)
>
> # Take a snapshot using the same options as used for snapshot.
> retakeFileSnapshot(snapshot, directory = snapshot$directory) {
>     takeFileSnapshot)(directory, file.info <http://file.info> =
> snapshot$file.info <http://file.info>, md5sum = snapshot$md5sum, etc)
> }
>
> compareFileSnapshots(snapshot1, snapshot2)
> - or -
> getNewFiles(snapshat1, snapshot2)       # These names are probably too
> generic
> getDeletedFiles(snapshot1, snapshot2)
> getUpdatedFiles(snapshot1, snapshot2)
> -or-
> setdiff(snapshot1, snapshot2)  # Unclear how this should treat updated files
>
>
> This approach does have the difficulty that users could attempt to
> compare snapshots that were taken with different options and that can't
> be compared, but that should be an easy error to detect.

I don't want to add too many new functions.  The general R style is to 
have functions that do a lot, rather than have a lot of different 
functions to achieve different parts of related tasks.  This is better 
for interactive use (fewer functions to remember, a simpler help system 
to navigate), though it probably results in less readable code.

I can see an argument for two functions (a get and a compare), but I 
don't think there are many cases where doing two gets and comparing the 
snapshots would be worth the extra runtime.  (It's extra because 
file.info is only a little faster than list.files, and it would be 
unavoidable to call both twice in that version.  Using the timestamp 
file avoids one of those calls, and replaces the other with file_test, 
which takes a similar amount of time.  So overall it's about 20-25% 
faster.)  It also makes the code a bit more complicated, i.e. three 
calls (get, get, compare) instead of two (get, compare).

Thanks for your comments.

Duncan Murdoch


>
> Karl
>
>
> On Wed, Sep 4, 2013 at 10:53 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     In a number of places internal to R, we need to know which files
>     have changed (e.g. after building a vignette).  I've just written a
>     general purpose function "changedFiles" that I'll probably commit to
>     R-devel.  Comments on the design (or bug reports) would be appreciated.
>
>     The source for the function and the Rd page for it are inline below.
>
>     ----- changedFiles.R:
>     changedFiles <- function(snapshot, timestamp =
>     tempfile("timestamp"), file.info <http://file.info> = NULL,
>                   md5sum = FALSE, full.names = FALSE, ...) {
>          dosnapshot <- function(args) {
>              fullnames <- do.call(list.files, c(full.names = TRUE, args))
>              names <- do.call(list.files, c(full.names = full.names, args))
>              if (isTRUE(file.info <http://file.info>) ||
>     (is.character(file.info <http://file.info>) && length(file.info
>     <http://file.info>))) {
>                  info <- file.info <http://file.info>(fullnames)
>              rownames(info) <- names
>                  if (isTRUE(file.info <http://file.info>))
>     file.info <http://file.info> <- c("size", "isdir", "mode", "mtime")
>              } else
>                  info <- data.frame(row.names=names)
>          if (md5sum)
>              info <- data.frame(info, md5sum = tools::md5sum(fullnames))
>          list(info = info, timestamp = timestamp, file.info
>     <http://file.info> = file.info <http://file.info>,
>               md5sum = md5sum, full.names = full.names, args = args)
>          }
>          if (missing(snapshot) || !inherits(snapshot,
>     "changedFilesSnapshot")) {
>              if (length(timestamp) == 1)
>                  file.create(timestamp)
>              if (missing(snapshot)) snapshot <- "."
>              pre <- dosnapshot(list(path = snapshot, ...))
>              pre$pre <- pre$info
>              pre$info <- NULL
>              pre$wd <- getwd()
>              class(pre) <- "changedFilesSnapshot"
>              return(pre)
>          }
>
>          if (missing(timestamp)) timestamp <- snapshot$timestamp
>          if (missing(file.info <http://file.info>) || isTRUE(file.info
>     <http://file.info>)) file.info <http://file.info> <-
>     snapshot$file.info <http://file.info>
>          if (identical(file.info <http://file.info>, FALSE)) file.info
>     <http://file.info> <- NULL
>          if (missing(md5sum))    md5sum <- snapshot$md5sum
>          if (missing(full.names)) full.names <- snapshot$full.names
>
>          pre <- snapshot$pre
>          savewd <- getwd()
>          on.exit(setwd(savewd))
>          setwd(snapshot$wd)
>
>          args <- snapshot$args
>          newargs <- list(...)
>          args[names(newargs)] <- newargs
>          post <- dosnapshot(args)$info
>          prenames <- rownames(pre)
>          postnames <- rownames(post)
>
>          added <- setdiff(postnames, prenames)
>          deleted <- setdiff(prenames, postnames)
>          common <- intersect(prenames, postnames)
>
>          if (length(file.info <http://file.info>)) {
>              preinfo <- pre[common, file.info <http://file.info>]
>              postinfo <- post[common, file.info <http://file.info>]
>              changes <- preinfo != postinfo
>          }
>          else changes <- matrix(logical(0), nrow = length(common), ncol = 0,
>                                 dimnames = list(common, character(0)))
>          if (length(timestamp))
>              changes <- cbind(changes, Newer = file_test("-nt", common,
>     timestamp))
>          if (md5sum) {
>              premd5 <- pre[common, "md5sum"]
>              postmd5 <- post[common, "md5sum"]
>          changes <- cbind(changes, md5sum = premd5 != postmd5)
>          }
>          changes1 <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop
>     = FALSE]
>          changed <- rownames(changes1)
>          structure(list(added = added, deleted = deleted, changed = changed,
>              unchanged = setdiff(common, changed), changes = changes),
>     class = "changedFiles")
>     }
>
>     print.changedFilesSnapshot <- function(x, ...) {
>          cat("changedFiles snapshot:\n timestamp = \"", x$timestamp,
>     "\"\n file.info <http://file.info> = ",
>              if (length(x$file.info <http://file.info>))
>     paste(paste0('"', x$file.info <http://file.info>, '"'), collapse=","),
>              "\n md5sum = ", x$md5sum, "\n args = ", deparse(x$args,
>     control = NULL), "\n", sep="")
>          x
>     }
>
>     print.changedFiles <- function(x, ...) {
>          if (length(x$added)) cat("Files added:\n",  paste0("  ",
>     x$added, collapse="\n"), "\n", sep="")
>          if (length(x$deleted)) cat("Files deleted:\n",  paste0("  ",
>     x$deleted, collapse="\n"), "\n", sep="")
>          changes <- x$changes
>          changes <- changes[rowSums(changes, na.rm = TRUE) > 0, ,
>     drop=FALSE]
>          changes <- changes[, colSums(changes, na.rm = TRUE) > 0,
>     drop=FALSE]
>          if (nrow(changes)) {
>              cat("Files changed:\n")
>              print(changes)
>          }
>          x
>     }
>     ----------------------
>
>     --- changedFiles.Rd:
>     \name{changedFiles}
>     \alias{changedFiles}
>     \alias{print.changedFiles}
>     \alias{print.__changedFilesSnapshot}
>     \title{
>     Detect which files have changed
>     }
>     \description{
>     On the first call, \code{changedFiles} takes a snapshot of a
>     selection of files.  In subsequent
>     calls, it takes another snapshot, and returns an object containing
>     data on the
>     differences between the two snapshots.  The snapshots need not be
>     the same directory;
>     this could be used to compare two directories.
>     }
>     \usage{
>     changedFiles(snapshot, timestamp = tempfile("timestamp"), file.info
>     <http://file.info> = NULL,
>                   md5sum = FALSE, full.names = FALSE, ...)
>     }
>     \arguments{
>        \item{snapshot}{
>     The path to record, or a previous snapshot.  See the Details.
>     }
>        \item{timestamp}{
>     The name of a file to write at the time the initial snapshot
>     is taken.  In subsequent calls, modification times of files will be
>     compared to
>     this file, and newer files will be reported as changed.  Set to
>     \code{NULL}
>     to skip this test.
>     }
>        \item{file.info <http://file.info>}{
>     A vector of columns from the result of the \code{file.info
>     <http://file.info>} function, or a logical value.  If
>     \code{TRUE}, columns \code{c("size", "isdir", "mode", "mtime")} will
>     be used.  Set to
>     \code{FALSE} or \code{NULL} to skip this test.  See the Details.
>     }
>        \item{md5sum}{
>     A logical value indicating whether MD5 summaries should be taken as
>     part of the snapshot.
>     }
>        \item{full.names}{
>     A logical value indicating whether full names (as in
>     \code{\link{list.files}}) should be
>     recorded.
>     }
>        \item{\dots}{
>     Additional parameters to pass to \code{\link{list.files}} to control
>     the set of files
>     in the snapshots.
>     }
>     }
>     \details{
>     This function works in two modes.  If the \code{snapshot} argument
>     is missing or is
>     not of S3 class \code{"changedFilesSnapshot"}, it is used as the
>     \code{path} argument
>     to \code{\link{list.files}} to obtain a list of files.  If it is of
>     class
>     \code{"changedFilesSnapshot"}, then it is taken to be the baseline file
>     and a new snapshot is taken and compared with it.  In the latter
>     case, missing
>     arguments default to match those from the initial snapshot.
>
>     If the \code{timestamp} argument is length 1, a file with that name
>     is created
>     in the current directory during the initial snapshot, and
>     \code{\link{file_test}}
>     is used to compare the age of all files to it during subsequent calls.
>
>     If the \code{file.info <http://file.info>} argument is \code{TRUE}
>     or it contains a non-empty
>     character vector, the indicated columns from the result of a call to
>     \code{\link{file.info <http://file.info>}} will be recorded and
>     compared.
>
>     If \code{md5sum} is \code{TRUE}, the \code{tools::\link{md5sum}}
>     function
>     will be called to record the 32 byte MD5 checksum for each file, and
>     these values
>     will be compared.
>     }
>     \value{
>     In the initial snapshot phase, an object of class
>     \code{"changedFilesSnapshot"} is returned.  This
>     is a list containing the fields
>     \item{pre}{a dataframe whose rownames are the filenames, and whose
>     columns contain the
>     requested snapshot data}
>     \item{timestamp, file.info <http://file.info>, md5sum, full.names}{a
>     record of the arguments in the initial call}
>     \item{args}{other arguments passed via \code{...} to
>     \code{\link{list.files}}.}
>
>     In the comparison phase, an object of class \code{"changedFiles"}.
>     This is a list containing
>     \item{added, deleted, changed, unchanged}{character vectors of
>     filenames from the before
>     and after snapshots, with obvious meanings}
>     \item{changes}{a logical matrix with a row for each common file, and
>     a column for each
>     comparison test.  \code{TRUE} indicates a change in that test.}
>
>     \code{\link{print}} methods are defined for each of these types. The
>     \code{\link{print}} method for \code{"changedFilesSnapshot"} objects
>     displays the arguments used to produce it, while the one for
>     \code{"changedFiles"} displays the \code{added}, \code{deleted}
>     and \code{changed} fields if non-empty, and a submatrix of the
>     \code{changes}
>     matrix containing all of the \code{TRUE} values.
>     }
>     \author{
>     Duncan Murdoch
>     }
>     \seealso{
>     \code{\link{file.info <http://file.info>}}, \code{\link{file_test}},
>     \code{\link{md5sum}}.
>     }
>     \examples{
>     # Create some files in a temporary directory
>     dir <- tempfile()
>     dir.create(dir)
>     writeBin(1, file.path(dir, "file1"))
>     writeBin(2, file.path(dir, "file2"))
>     dir.create(file.path(dir, "dir"))
>
>     # Take a snapshot
>     snapshot <- changedFiles(dir, file.info <http://file.info>=TRUE,
>     md5sum=TRUE)
>
>     # Change one of the files
>     writeBin(3, file.path(dir, "file2"))
>
>     # Display the detected changes
>     changedFiles(snapshot)
>     changedFiles(snapshot)$changes
>     }
>     \keyword{utilities}
>     \keyword{file}
>
>     ________________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


From skostysh at princeton.edu  Thu Sep  5 05:36:45 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 4 Sep 2013 23:36:45 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522773AC.3030609@gmail.com>
References: <522773AC.3030609@gmail.com>
Message-ID: <CAE3=dmcuKNCSJU_kV2mg6=FV9u9XivVaTTSZaWOMQbHYS30A2w@mail.gmail.com>

On Wed, Sep 4, 2013 at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> In a number of places internal to R, we need to know which files have
> changed (e.g. after building a vignette).  I've just written a general
> purpose function "changedFiles" that I'll probably commit to R-devel.
> Comments on the design (or bug reports) would be appreciated.
>
> The source for the function and the Rd page for it are inline below.

This looks like a useful function. Thanks for writing it. I have only
one (picky) comment below.

> ----- changedFiles.R:
> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
> file.info = NULL,
>              md5sum = FALSE, full.names = FALSE, ...) {
>     dosnapshot <- function(args) {
>         fullnames <- do.call(list.files, c(full.names = TRUE, args))
>         names <- do.call(list.files, c(full.names = full.names, args))
>         if (isTRUE(file.info) || (is.character(file.info) &&
> length(file.info))) {
>             info <- file.info(fullnames)
>         rownames(info) <- names
>             if (isTRUE(file.info))
>                 file.info <- c("size", "isdir", "mode", "mtime")
>         } else
>             info <- data.frame(row.names=names)
>     if (md5sum)
>         info <- data.frame(info, md5sum = tools::md5sum(fullnames))
>     list(info = info, timestamp = timestamp, file.info = file.info,
>          md5sum = md5sum, full.names = full.names, args = args)
>     }
>     if (missing(snapshot) || !inherits(snapshot, "changedFilesSnapshot")) {
>         if (length(timestamp) == 1)
>             file.create(timestamp)
>         if (missing(snapshot)) snapshot <- "."
>         pre <- dosnapshot(list(path = snapshot, ...))
>         pre$pre <- pre$info
>         pre$info <- NULL
>         pre$wd <- getwd()
>         class(pre) <- "changedFilesSnapshot"
>         return(pre)
>     }
>
>     if (missing(timestamp)) timestamp <- snapshot$timestamp
>     if (missing(file.info) || isTRUE(file.info)) file.info <-
> snapshot$file.info
>     if (identical(file.info, FALSE)) file.info <- NULL
>     if (missing(md5sum))    md5sum <- snapshot$md5sum
>     if (missing(full.names)) full.names <- snapshot$full.names
>
>     pre <- snapshot$pre
>     savewd <- getwd()
>     on.exit(setwd(savewd))
>     setwd(snapshot$wd)
>
>     args <- snapshot$args
>     newargs <- list(...)
>     args[names(newargs)] <- newargs
>     post <- dosnapshot(args)$info
>     prenames <- rownames(pre)
>     postnames <- rownames(post)
>
>     added <- setdiff(postnames, prenames)
>     deleted <- setdiff(prenames, postnames)
>     common <- intersect(prenames, postnames)
>
>     if (length(file.info)) {
>         preinfo <- pre[common, file.info]
>         postinfo <- post[common, file.info]
>         changes <- preinfo != postinfo
>     }
>     else changes <- matrix(logical(0), nrow = length(common), ncol = 0,
>                            dimnames = list(common, character(0)))
>     if (length(timestamp))
>         changes <- cbind(changes, Newer = file_test("-nt", common,
> timestamp))
>     if (md5sum) {
>         premd5 <- pre[common, "md5sum"]
>         postmd5 <- post[common, "md5sum"]
>     changes <- cbind(changes, md5sum = premd5 != postmd5)
>     }
>     changes1 <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop = FALSE]
>     changed <- rownames(changes1)
>     structure(list(added = added, deleted = deleted, changed = changed,
>         unchanged = setdiff(common, changed), changes = changes), class =
> "changedFiles")
> }
>
> print.changedFilesSnapshot <- function(x, ...) {
>     cat("changedFiles snapshot:\n timestamp = \"", x$timestamp, "\"\n
> file.info = ",
>         if (length(x$file.info)) paste(paste0('"', x$file.info, '"'),
> collapse=","),
>         "\n md5sum = ", x$md5sum, "\n args = ", deparse(x$args, control =
> NULL), "\n", sep="")
>     x
> }
>
> print.changedFiles <- function(x, ...) {
>     if (length(x$added)) cat("Files added:\n",  paste0("  ", x$added,
> collapse="\n"), "\n", sep="")
>     if (length(x$deleted)) cat("Files deleted:\n",  paste0("  ", x$deleted,
> collapse="\n"), "\n", sep="")
>     changes <- x$changes
>     changes <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop=FALSE]
>     changes <- changes[, colSums(changes, na.rm = TRUE) > 0, drop=FALSE]
>     if (nrow(changes)) {
>         cat("Files changed:\n")
>         print(changes)
>     }
>     x
> }
> ----------------------
>
> --- changedFiles.Rd:
> \name{changedFiles}
> \alias{changedFiles}
> \alias{print.changedFiles}
> \alias{print.changedFilesSnapshot}
> \title{
> Detect which files have changed
> }
> \description{
> On the first call, \code{changedFiles} takes a snapshot of a selection of
> files.  In subsequent
> calls, it takes another snapshot, and returns an object containing data on
> the
> differences between the two snapshots.  The snapshots need not be the same
> directory;
> this could be used to compare two directories.
> }
> \usage{
> changedFiles(snapshot, timestamp = tempfile("timestamp"), file.info = NULL,
>              md5sum = FALSE, full.names = FALSE, ...)
> }
> \arguments{
>   \item{snapshot}{
> The path to record, or a previous snapshot.  See the Details.
> }
>   \item{timestamp}{
> The name of a file to write at the time the initial snapshot
> is taken.  In subsequent calls, modification times of files will be compared
> to
> this file, and newer files will be reported as changed.  Set to \code{NULL}
> to skip this test.
> }
>   \item{file.info}{
> A vector of columns from the result of the \code{file.info} function, or a
> logical value.  If
> \code{TRUE}, columns \code{c("size", "isdir", "mode", "mtime")} will be
> used.  Set to
> \code{FALSE} or \code{NULL} to skip this test.  See the Details.
> }
>   \item{md5sum}{
> A logical value indicating whether MD5 summaries should be taken as part of
> the snapshot.
> }
>   \item{full.names}{
> A logical value indicating whether full names (as in
> \code{\link{list.files}}) should be
> recorded.
> }
>   \item{\dots}{
> Additional parameters to pass to \code{\link{list.files}} to control the set
> of files
> in the snapshots.
> }
> }
> \details{
> This function works in two modes.  If the \code{snapshot} argument is
> missing or is
> not of S3 class \code{"changedFilesSnapshot"}, it is used as the \code{path}
> argument
> to \code{\link{list.files}} to obtain a list of files.  If it is of class
> \code{"changedFilesSnapshot"}, then it is taken to be the baseline file
> and a new snapshot is taken and compared with it.  In the latter case,
> missing
> arguments default to match those from the initial snapshot.
>
> If the \code{timestamp} argument is length 1, a file with that name is
> created
> in the current directory during the initial snapshot, and
> \code{\link{file_test}}
> is used to compare the age of all files to it during subsequent calls.
>
> If the \code{file.info} argument is \code{TRUE} or it contains a non-empty
> character vector, the indicated columns from the result of a call to
> \code{\link{file.info}} will be recorded and compared.
>
> If \code{md5sum} is \code{TRUE}, the \code{tools::\link{md5sum}} function
> will be called to record the 32 byte MD5 checksum for each file, and these
> values
> will be compared.
> }
> \value{
> In the initial snapshot phase, an object of class
> \code{"changedFilesSnapshot"} is returned.  This
> is a list containing the fields
> \item{pre}{a dataframe whose rownames are the filenames, and whose columns
> contain the
> requested snapshot data}
> \item{timestamp, file.info, md5sum, full.names}{a record of the arguments in
> the initial call}
> \item{args}{other arguments passed via \code{...} to
> \code{\link{list.files}}.}
>
> In the comparison phase, an object of class \code{"changedFiles"}. This is a
> list containing
> \item{added, deleted, changed, unchanged}{character vectors of filenames
> from the before
> and after snapshots, with obvious meanings}
> \item{changes}{a logical matrix with a row for each common file, and a
> column for each
> comparison test.  \code{TRUE} indicates a change in that test.}
>
> \code{\link{print}} methods are defined for each of these types. The
> \code{\link{print}} method for \code{"changedFilesSnapshot"} objects
> displays the arguments used to produce it, while the one for
> \code{"changedFiles"} displays the \code{added}, \code{deleted}
> and \code{changed} fields if non-empty, and a submatrix of the
> \code{changes}
> matrix containing all of the \code{TRUE} values.
> }
> \author{
> Duncan Murdoch
> }
> \seealso{
> \code{\link{file.info}}, \code{\link{file_test}}, \code{\link{md5sum}}.
> }
> \examples{
> # Create some files in a temporary directory
> dir <- tempfile()
> dir.create(dir)

Should a different name than 'dir' be used since 'dir' is a base function?

Further, if someone is not very familiar with R (or just not in "R
mode" at the time of reading), they might think that 'dir.create' is
calling the create member of the object named 'dir' that you just
made.

Scott

> writeBin(1, file.path(dir, "file1"))
> writeBin(2, file.path(dir, "file2"))
> dir.create(file.path(dir, "dir"))
>
> # Take a snapshot
> snapshot <- changedFiles(dir, file.info=TRUE, md5sum=TRUE)
>
> # Change one of the files
> writeBin(3, file.path(dir, "file2"))
>
> # Display the detected changes
> changedFiles(snapshot)
> changedFiles(snapshot)$changes
> }
> \keyword{utilities}
> \keyword{file}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From peter.meilstrup at gmail.com  Thu Sep  5 06:31:33 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Wed, 4 Sep 2013 21:31:33 -0700
Subject: [Rd] Why does duplicate() make deep copies?
Message-ID: <CAJoaRhZeZ9AXgoT36O+OURe0yZdKmKf8ZSzq_Uig_2dci4UjHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130904/b74ac757/attachment.pl>

From alexios at 4dscape.com  Thu Sep  5 07:18:52 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Thu, 05 Sep 2013 06:18:52 +0100
Subject: [Rd] 'library' or 'require' call to package which was already
 attached by Depends
Message-ID: <5228143C.6010801@4dscape.com>

Hello,

I'm receiving the following NOTE during recent checks of the rmgarch
package:

'library' or 'require' call to 'rugarch' which was already attached by
Depends.

which I traced to the recent changes in R 3.02 Utilities:

 ? packages which are used in ?library()? or ?requires()? calls in the R
code but were already put on the search path _via_ ?Depends?.

However, the code uses the 'library()' call (of a package which is in
'Depends') inside the 'parallel::clusterEvalQ' function which is given
as an option to users for running certain routines in parallel.

Would it be possible to make allowances for this instance of the use of
'library()' or suggest a way to call 'clusterEvalQ' with 'library'
without triggering the NOTE?

Thanks,

Alexios


From simon.urbanek at r-project.org  Thu Sep  5 09:48:15 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 5 Sep 2013 03:48:15 -0400
Subject: [Rd] Why does duplicate() make deep copies?
In-Reply-To: <CAJoaRhZeZ9AXgoT36O+OURe0yZdKmKf8ZSzq_Uig_2dci4UjHg@mail.gmail.com>
References: <CAJoaRhZeZ9AXgoT36O+OURe0yZdKmKf8ZSzq_Uig_2dci4UjHg@mail.gmail.com>
Message-ID: <6ADCBAAD-06BE-4B8C-8427-5FF0A4D11E93@r-project.org>

On Sep 5, 2013, at 12:31 AM, Peter Meilstrup wrote:

> Some experimentation with the below function should convince you that the
> runtime of the bit inside sys.time is proportional to size*number*times. I
> think it should only be proportional to number*times. The function is only
> manipulating a list of references to vectors and not trying to make changes
> to the vectors themselves.
> 
> overcopying <- function(size, number, times) {
>  #Make a list of NUMBER vectors of SIZE, then reorder the list.  The
>  #vectors themselves are never touched, only their references are
>  #moved around.  If R implements "copy on write" correctly the
>  #elapsed time should be ~number*times.
>  L <- replicate(number, list(vector("numeric", size)), simplify=FALSE)
>  system.time(for (i in 1:times) {
>    L[sample(number)] <- L
>  })
> }
> 
> I see that duplicate.c makes a recursive copy of each element when it
> encounters a VECSXP or a LISTSXP, which it seems there should be no need
> for (it should be sufficient to make a shallow copy and ensure NAMED is set
> on the elements.)
> 
> Why is R making apparently unnecessary deep copies?
> 

Because ref counting is not recursive. Changing that breaks a quite a few packages that abuse the fact that copies are currently deep. Main problem with that is that it's pretty much impossible to detect it ahead of time. That said, there are efforts underway by Luke Tierney and Michael Lawrence to see how far we can go without breaking everything.

Cheers,
Simon


From gianluca.mastrantonio at yahoo.it  Thu Sep  5 11:59:17 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Thu, 05 Sep 2013 11:59:17 +0200
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <52279B27.8060801@stats.ox.ac.uk>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk>
Message-ID: <522855F5.3040204@yahoo.it>

First of all, thanks for your help.

I did all the things you told me. I was able to load the library, but then

Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared object 
'/lustre/work/gjona2/Wrap/BayesWrap/libs/BayesWrap.so':
   libR.so: cannot open shared object file: No such file or directory
In addition: Warning message:
package 'BayesWrap' was built under R version 2.15.2
Error: package/namespace load failed for 'BayesWrap'
Execution halted

what does it means?

G.M.

Il 04/09/13 22:42, Prof Brian Ripley ha scritto:
> On 04/09/2013 19:58, Geoff Jentry wrote:
>>> Can you add some details?
>>> Suppose i have the package Model.tar.gz and my writable are is in
>>> user/area, what i have to do next to install the package?
>>
>> What I was picturing was something like this (forgive me if syntax isn't
>> 100%):
>>
>> mkdir user/area/myRLib
>> R CMD INSTALL --library=user/area/myRLib Model.tar.gz
>>
>> and then in R:
>> library(Model, lib.loc="user/area/myRLib")
>>
>> Note though Brian Ripley's response to me where he indicates that this
>> is handled automatically.
>
> Yes,  install.packages("Model.tar.gz") should suffice.
>
>>
>> -J
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Thu Sep  5 12:48:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Sep 2013 06:48:47 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CAE3=dmcuKNCSJU_kV2mg6=FV9u9XivVaTTSZaWOMQbHYS30A2w@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CAE3=dmcuKNCSJU_kV2mg6=FV9u9XivVaTTSZaWOMQbHYS30A2w@mail.gmail.com>
Message-ID: <5228618F.20205@gmail.com>

On 13-09-04 11:36 PM, Scott Kostyshak wrote:
> On Wed, Sep 4, 2013 at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> In a number of places internal to R, we need to know which files have
>> changed (e.g. after building a vignette).  I've just written a general
>> purpose function "changedFiles" that I'll probably commit to R-devel.
>> Comments on the design (or bug reports) would be appreciated.
>>
>> The source for the function and the Rd page for it are inline below.
>
> This looks like a useful function. Thanks for writing it. I have only
> one (picky) comment below.
>
>> ----- changedFiles.R:
>> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
>> file.info = NULL,
>>               md5sum = FALSE, full.names = FALSE, ...) {
>>      dosnapshot <- function(args) {
>>          fullnames <- do.call(list.files, c(full.names = TRUE, args))
>>          names <- do.call(list.files, c(full.names = full.names, args))
>>          if (isTRUE(file.info) || (is.character(file.info) &&
>> length(file.info))) {
>>              info <- file.info(fullnames)
>>          rownames(info) <- names
>>              if (isTRUE(file.info))
>>                  file.info <- c("size", "isdir", "mode", "mtime")
>>          } else
>>              info <- data.frame(row.names=names)
>>      if (md5sum)
>>          info <- data.frame(info, md5sum = tools::md5sum(fullnames))
>>      list(info = info, timestamp = timestamp, file.info = file.info,
>>           md5sum = md5sum, full.names = full.names, args = args)
>>      }
>>      if (missing(snapshot) || !inherits(snapshot, "changedFilesSnapshot")) {
>>          if (length(timestamp) == 1)
>>              file.create(timestamp)
>>          if (missing(snapshot)) snapshot <- "."
>>          pre <- dosnapshot(list(path = snapshot, ...))
>>          pre$pre <- pre$info
>>          pre$info <- NULL
>>          pre$wd <- getwd()
>>          class(pre) <- "changedFilesSnapshot"
>>          return(pre)
>>      }
>>
>>      if (missing(timestamp)) timestamp <- snapshot$timestamp
>>      if (missing(file.info) || isTRUE(file.info)) file.info <-
>> snapshot$file.info
>>      if (identical(file.info, FALSE)) file.info <- NULL
>>      if (missing(md5sum))    md5sum <- snapshot$md5sum
>>      if (missing(full.names)) full.names <- snapshot$full.names
>>
>>      pre <- snapshot$pre
>>      savewd <- getwd()
>>      on.exit(setwd(savewd))
>>      setwd(snapshot$wd)
>>
>>      args <- snapshot$args
>>      newargs <- list(...)
>>      args[names(newargs)] <- newargs
>>      post <- dosnapshot(args)$info
>>      prenames <- rownames(pre)
>>      postnames <- rownames(post)
>>
>>      added <- setdiff(postnames, prenames)
>>      deleted <- setdiff(prenames, postnames)
>>      common <- intersect(prenames, postnames)
>>
>>      if (length(file.info)) {
>>          preinfo <- pre[common, file.info]
>>          postinfo <- post[common, file.info]
>>          changes <- preinfo != postinfo
>>      }
>>      else changes <- matrix(logical(0), nrow = length(common), ncol = 0,
>>                             dimnames = list(common, character(0)))
>>      if (length(timestamp))
>>          changes <- cbind(changes, Newer = file_test("-nt", common,
>> timestamp))
>>      if (md5sum) {
>>          premd5 <- pre[common, "md5sum"]
>>          postmd5 <- post[common, "md5sum"]
>>      changes <- cbind(changes, md5sum = premd5 != postmd5)
>>      }
>>      changes1 <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop = FALSE]
>>      changed <- rownames(changes1)
>>      structure(list(added = added, deleted = deleted, changed = changed,
>>          unchanged = setdiff(common, changed), changes = changes), class =
>> "changedFiles")
>> }
>>
>> print.changedFilesSnapshot <- function(x, ...) {
>>      cat("changedFiles snapshot:\n timestamp = \"", x$timestamp, "\"\n
>> file.info = ",
>>          if (length(x$file.info)) paste(paste0('"', x$file.info, '"'),
>> collapse=","),
>>          "\n md5sum = ", x$md5sum, "\n args = ", deparse(x$args, control =
>> NULL), "\n", sep="")
>>      x
>> }
>>
>> print.changedFiles <- function(x, ...) {
>>      if (length(x$added)) cat("Files added:\n",  paste0("  ", x$added,
>> collapse="\n"), "\n", sep="")
>>      if (length(x$deleted)) cat("Files deleted:\n",  paste0("  ", x$deleted,
>> collapse="\n"), "\n", sep="")
>>      changes <- x$changes
>>      changes <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop=FALSE]
>>      changes <- changes[, colSums(changes, na.rm = TRUE) > 0, drop=FALSE]
>>      if (nrow(changes)) {
>>          cat("Files changed:\n")
>>          print(changes)
>>      }
>>      x
>> }
>> ----------------------
>>
>> --- changedFiles.Rd:
>> \name{changedFiles}
>> \alias{changedFiles}
>> \alias{print.changedFiles}
>> \alias{print.changedFilesSnapshot}
>> \title{
>> Detect which files have changed
>> }
>> \description{
>> On the first call, \code{changedFiles} takes a snapshot of a selection of
>> files.  In subsequent
>> calls, it takes another snapshot, and returns an object containing data on
>> the
>> differences between the two snapshots.  The snapshots need not be the same
>> directory;
>> this could be used to compare two directories.
>> }
>> \usage{
>> changedFiles(snapshot, timestamp = tempfile("timestamp"), file.info = NULL,
>>               md5sum = FALSE, full.names = FALSE, ...)
>> }
>> \arguments{
>>    \item{snapshot}{
>> The path to record, or a previous snapshot.  See the Details.
>> }
>>    \item{timestamp}{
>> The name of a file to write at the time the initial snapshot
>> is taken.  In subsequent calls, modification times of files will be compared
>> to
>> this file, and newer files will be reported as changed.  Set to \code{NULL}
>> to skip this test.
>> }
>>    \item{file.info}{
>> A vector of columns from the result of the \code{file.info} function, or a
>> logical value.  If
>> \code{TRUE}, columns \code{c("size", "isdir", "mode", "mtime")} will be
>> used.  Set to
>> \code{FALSE} or \code{NULL} to skip this test.  See the Details.
>> }
>>    \item{md5sum}{
>> A logical value indicating whether MD5 summaries should be taken as part of
>> the snapshot.
>> }
>>    \item{full.names}{
>> A logical value indicating whether full names (as in
>> \code{\link{list.files}}) should be
>> recorded.
>> }
>>    \item{\dots}{
>> Additional parameters to pass to \code{\link{list.files}} to control the set
>> of files
>> in the snapshots.
>> }
>> }
>> \details{
>> This function works in two modes.  If the \code{snapshot} argument is
>> missing or is
>> not of S3 class \code{"changedFilesSnapshot"}, it is used as the \code{path}
>> argument
>> to \code{\link{list.files}} to obtain a list of files.  If it is of class
>> \code{"changedFilesSnapshot"}, then it is taken to be the baseline file
>> and a new snapshot is taken and compared with it.  In the latter case,
>> missing
>> arguments default to match those from the initial snapshot.
>>
>> If the \code{timestamp} argument is length 1, a file with that name is
>> created
>> in the current directory during the initial snapshot, and
>> \code{\link{file_test}}
>> is used to compare the age of all files to it during subsequent calls.
>>
>> If the \code{file.info} argument is \code{TRUE} or it contains a non-empty
>> character vector, the indicated columns from the result of a call to
>> \code{\link{file.info}} will be recorded and compared.
>>
>> If \code{md5sum} is \code{TRUE}, the \code{tools::\link{md5sum}} function
>> will be called to record the 32 byte MD5 checksum for each file, and these
>> values
>> will be compared.
>> }
>> \value{
>> In the initial snapshot phase, an object of class
>> \code{"changedFilesSnapshot"} is returned.  This
>> is a list containing the fields
>> \item{pre}{a dataframe whose rownames are the filenames, and whose columns
>> contain the
>> requested snapshot data}
>> \item{timestamp, file.info, md5sum, full.names}{a record of the arguments in
>> the initial call}
>> \item{args}{other arguments passed via \code{...} to
>> \code{\link{list.files}}.}
>>
>> In the comparison phase, an object of class \code{"changedFiles"}. This is a
>> list containing
>> \item{added, deleted, changed, unchanged}{character vectors of filenames
>> from the before
>> and after snapshots, with obvious meanings}
>> \item{changes}{a logical matrix with a row for each common file, and a
>> column for each
>> comparison test.  \code{TRUE} indicates a change in that test.}
>>
>> \code{\link{print}} methods are defined for each of these types. The
>> \code{\link{print}} method for \code{"changedFilesSnapshot"} objects
>> displays the arguments used to produce it, while the one for
>> \code{"changedFiles"} displays the \code{added}, \code{deleted}
>> and \code{changed} fields if non-empty, and a submatrix of the
>> \code{changes}
>> matrix containing all of the \code{TRUE} values.
>> }
>> \author{
>> Duncan Murdoch
>> }
>> \seealso{
>> \code{\link{file.info}}, \code{\link{file_test}}, \code{\link{md5sum}}.
>> }
>> \examples{
>> # Create some files in a temporary directory
>> dir <- tempfile()
>> dir.create(dir)
>
> Should a different name than 'dir' be used since 'dir' is a base function?

Such as?

> Further, if someone is not very familiar with R (or just not in "R
> mode" at the time of reading), they might think that 'dir.create' is
> calling the create member of the object named 'dir' that you just
> made.

dir.create is an existing function.  I wouldn't have named it that, but 
that's its name.

Duncan Murdoch

>
> Scott
>
>> writeBin(1, file.path(dir, "file1"))
>> writeBin(2, file.path(dir, "file2"))
>> dir.create(file.path(dir, "dir"))
>>
>> # Take a snapshot
>> snapshot <- changedFiles(dir, file.info=TRUE, md5sum=TRUE)
>>
>> # Change one of the files
>> writeBin(3, file.path(dir, "file2"))
>>
>> # Display the detected changes
>> changedFiles(snapshot)
>> changedFiles(snapshot)$changes
>> }
>> \keyword{utilities}
>> \keyword{file}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Rainer at krugs.de  Thu Sep  5 16:10:07 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 5 Sep 2013 16:10:07 +0200
Subject: [Rd] ASCII art in function documentation?
Message-ID: <m238pjjr5s.fsf@krugs.de>

Hi

I want to include ascii art in a function documentation which should
look as follow:

,----
| +------+------+------+
| | 1/16 | 1/16 | 1/16 |
| +------+------+------+
| | 1/16 | 8/16 | 1/16 |
| +------+------+------+
| | 1/16 | 1/16 | 1/16 |
| +------+------+------+
`----


to keep the monospaced font even in html, I decided to use \code{}:

,----
| \code{+------+------+------+}
| 
| \code{| 1/16 | 1/16 | 1/16 |}
| 
| \code{+------+------+------+}
| 
| \code{| 1/16 | 8/16 | 1/16 |}
| 
| \code{+------+------+------+}
| 
| \code{| 1/16 | 1/16 | 1/16 |}
| 
| \code{+------+------+------+}
`----

But the result was an empty line between each text:

,----
|      '+------+------+------+'
| 
|      '| 1/16 | 1/16 | 1/16 |'
| 
|      '+------+------+------+'
| 
|      '| 1/16 | 8/16 | 1/16 |'
| 
|      '+------+------+------+'
| 
|      '| 1/16 | 1/16 | 1/16 |'
| 
|      '+------+------+------+'
`----

and when no empty lines were included obviously put everything behind
each other.

My question:

Is there a way that I can achieve the ASCII art as shown above? Is there
a way of having a \linebreak which does not insert a new line?

Thanks,

Rainer


-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From sarah.goslee at gmail.com  Thu Sep  5 16:15:54 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Sep 2013 10:15:54 -0400
Subject: [Rd] ASCII art in function documentation?
In-Reply-To: <m238pjjr5s.fsf@krugs.de>
References: <m238pjjr5s.fsf@krugs.de>
Message-ID: <CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>

Untested, but did you try wrapping the whole thing in a single code block:

\code{
all
the
things
}

Sarah

On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> I want to include ascii art in a function documentation which should
> look as follow:
>
> ,----
> | +------+------+------+
> | | 1/16 | 1/16 | 1/16 |
> | +------+------+------+
> | | 1/16 | 8/16 | 1/16 |
> | +------+------+------+
> | | 1/16 | 1/16 | 1/16 |
> | +------+------+------+
> `----
>
>
> to keep the monospaced font even in html, I decided to use \code{}:
>
> ,----
> | \code{+------+------+------+}
> |
> | \code{| 1/16 | 1/16 | 1/16 |}
> |
> | \code{+------+------+------+}
> |
> | \code{| 1/16 | 8/16 | 1/16 |}
> |
> | \code{+------+------+------+}
> |
> | \code{| 1/16 | 1/16 | 1/16 |}
> |
> | \code{+------+------+------+}
> `----
>
> But the result was an empty line between each text:
>
> ,----
> |      '+------+------+------+'
> |
> |      '| 1/16 | 1/16 | 1/16 |'
> |
> |      '+------+------+------+'
> |
> |      '| 1/16 | 8/16 | 1/16 |'
> |
> |      '+------+------+------+'
> |
> |      '| 1/16 | 1/16 | 1/16 |'
> |
> |      '+------+------+------+'
> `----
>
> and when no empty lines were included obviously put everything behind
> each other.
>
> My question:
>
> Is there a way that I can achieve the ASCII art as shown above? Is there
> a way of having a \linebreak which does not insert a new line?
>
> Thanks,
>
> Rainer
>
>
> --


-- 
Sarah Goslee
http://www.functionaldiversity.org


From brian at braverock.com  Thu Sep  5 16:20:27 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 05 Sep 2013 09:20:27 -0500
Subject: [Rd] ASCII art in function documentation?
In-Reply-To: <m238pjjr5s.fsf@krugs.de>
References: <m238pjjr5s.fsf@krugs.de>
Message-ID: <5228932B.8050407@braverock.com>

On 09/05/2013 09:10 AM, Rainer M Krug wrote:
>   want to include ascii art in a function documentation which should
> look as follow:
>
> ,----
> | +------+------+------+
> | | 1/16 | 1/16 | 1/16 |
> | +------+------+------+
> | | 1/16 | 8/16 | 1/16 |
> | +------+------+------+
> | | 1/16 | 1/16 | 1/16 |
> | +------+------+------+
> `----
>
>
> to keep the monospaced font even in html, I decided to use \code{}:

Wouldn't it be best to use the relatively new \figure markup with 
alternate text?

http://cran.r-project.org/doc/manuals/R-exts.html#Figures

Regards,

Brian


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From Rainer at krugs.de  Thu Sep  5 17:10:28 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 5 Sep 2013 17:10:28 +0200
Subject: [Rd] ASCII art in function documentation?
References: <m238pjjr5s.fsf@krugs.de>
	<CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>
Message-ID: <m2txhzcniz.fsf@krugs.de>

Sarah Goslee <sarah.goslee at gmail.com> writes:

> Untested, but did you try wrapping the whole thing in a single code block:

Nope - also in one line.

Rainer

>
> \code{
> all
> the
> things
> }
>
> Sarah
>
> On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Hi
>>
>> I want to include ascii art in a function documentation which should
>> look as follow:
>>
>> ,----
>> | +------+------+------+
>> | | 1/16 | 1/16 | 1/16 |
>> | +------+------+------+
>> | | 1/16 | 8/16 | 1/16 |
>> | +------+------+------+
>> | | 1/16 | 1/16 | 1/16 |
>> | +------+------+------+
>> `----
>>
>>
>> to keep the monospaced font even in html, I decided to use \code{}:
>>
>> ,----
>> | \code{+------+------+------+}
>> |
>> | \code{| 1/16 | 1/16 | 1/16 |}
>> |
>> | \code{+------+------+------+}
>> |
>> | \code{| 1/16 | 8/16 | 1/16 |}
>> |
>> | \code{+------+------+------+}
>> |
>> | \code{| 1/16 | 1/16 | 1/16 |}
>> |
>> | \code{+------+------+------+}
>> `----
>>
>> But the result was an empty line between each text:
>>
>> ,----
>> |      '+------+------+------+'
>> |
>> |      '| 1/16 | 1/16 | 1/16 |'
>> |
>> |      '+------+------+------+'
>> |
>> |      '| 1/16 | 8/16 | 1/16 |'
>> |
>> |      '+------+------+------+'
>> |
>> |      '| 1/16 | 1/16 | 1/16 |'
>> |
>> |      '+------+------+------+'
>> `----
>>
>> and when no empty lines were included obviously put everything behind
>> each other.
>>
>> My question:
>>
>> Is there a way that I can achieve the ASCII art as shown above? Is there
>> a way of having a \linebreak which does not insert a new line?
>>
>> Thanks,
>>
>> Rainer
>>
>>
>> --
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From Rainer at krugs.de  Thu Sep  5 17:12:03 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 5 Sep 2013 17:12:03 +0200
Subject: [Rd] ASCII art in function documentation?
References: <m238pjjr5s.fsf@krugs.de> <5228932B.8050407@braverock.com>
Message-ID: <m2ppsncngc.fsf@krugs.de>

"Brian G. Peterson" <brian at braverock.com> writes:

> On 09/05/2013 09:10 AM, Rainer M Krug wrote:
>>   want to include ascii art in a function documentation which should
>> look as follow:
>>
>> ,----
>> | +------+------+------+
>> | | 1/16 | 1/16 | 1/16 |
>> | +------+------+------+
>> | | 1/16 | 8/16 | 1/16 |
>> | +------+------+------+
>> | | 1/16 | 1/16 | 1/16 |
>> | +------+------+------+
>> `----
>>
>>
>> to keep the monospaced font even in html, I decided to use \code{}:
>
> Wouldn't it be best to use the relatively new \figure markup with
> alternate text?
>
> http://cran.r-project.org/doc/manuals/R-exts.html#Figures

Thanks - mus't have overlooked it.

This would definitely work, but in this case I think ASCII art would be
the better solution.

Thanks,

Rainer

>
> Regards,
>
> Brian
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From Rainer at krugs.de  Thu Sep  5 17:23:57 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 5 Sep 2013 17:23:57 +0200
Subject: [Rd] ASCII art in function documentation - difference html and
	text output?
References: <m238pjjr5s.fsf@krugs.de>
	<CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>
	<m2txhzcniz.fsf@krugs.de>
Message-ID: <m2li3bcmwi.fsf_-_@krugs.de>

Found a solution.

putting \cr at the end of each line inserts a carriage return, but no
additional empty line. So

,----
| \code{+------+------+------+} \cr
| \code{| 1/16 | 1/16 | 1/16 |} \cr
| \code{+------+------+------+} \cr
| \code{| 1/16 | 8/16 | 1/16 |} \cr
| \code{+------+------+------+} \cr
| \code{| 1/16 | 1/16 | 1/16 |} \cr
| \code{+------+------+------+} \cr
`----

produces the desired output.


But interestingly,

,----
| \code{
| +------+------+------+ \cr
| | 1/16 | 1/16 | 1/16 | \cr
| +------+------+------+ \cr
| | 1/16 | 8/16 | 1/16 | \cr
| +------+------+------+ \cr
| | 1/16 | 1/16 | 1/16 | \cr
| +------+------+------+ \cr
| }
`----

produces the correct output in html, 

,----
| </p>
| <p><code> +------+------+------+ <br> | 1/16 | 1/16 | 1/16 |
|   <br> +------+------+------+ <br> | 1/16 | 8/16 | 1/16 | <br>
|   +------+------+------+ <br> | 1/16 | 1/16 | 1/16 | <br>
|   +------+------+------+ <br> </code>
| </p>
`----

but

,----
|      ' +------+------+------+
|      | 1/16 | 1/16 | 1/16 |
| 
|      +------+------+------+
|      | 1/16 | 8/16 | 1/16 |
|      +------+------+------+
|      | 1/16 | 1/16 | 1/16 |
|      +------+------+------+
`----

in the text version - is there a bug somewhere?

Thanks,

Rainer



Rainer M Krug <Rainer at krugs.de> writes:

> Sarah Goslee <sarah.goslee at gmail.com> writes:
>
>> Untested, but did you try wrapping the whole thing in a single code block:
>
> Nope - also in one line.
>
> Rainer
>
>>
>> \code{
>> all
>> the
>> things
>> }
>>
>> Sarah
>>
>> On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>> Hi
>>>
>>> I want to include ascii art in a function documentation which should
>>> look as follow:
>>>
>>> ,----
>>> | +------+------+------+
>>> | | 1/16 | 1/16 | 1/16 |
>>> | +------+------+------+
>>> | | 1/16 | 8/16 | 1/16 |
>>> | +------+------+------+
>>> | | 1/16 | 1/16 | 1/16 |
>>> | +------+------+------+
>>> `----
>>>
>>>
>>> to keep the monospaced font even in html, I decided to use \code{}:
>>>
>>> ,----
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 8/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> `----
>>>
>>> But the result was an empty line between each text:
>>>
>>> ,----
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 1/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 8/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 1/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> `----
>>>
>>> and when no empty lines were included obviously put everything behind
>>> each other.
>>>
>>> My question:
>>>
>>> Is there a way that I can achieve the ASCII art as shown above? Is there
>>> a way of having a \linebreak which does not insert a new line?
>>>
>>> Thanks,
>>>
>>> Rainer
>>>
>>>
>>> --
> <#secure method=pgpmime mode=sign>
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From sarah.goslee at gmail.com  Thu Sep  5 17:31:22 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Sep 2013 11:31:22 -0400
Subject: [Rd] ASCII art in function documentation?
In-Reply-To: <m2txhzcniz.fsf@krugs.de>
References: <m238pjjr5s.fsf@krugs.de>
	<CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>
	<m2txhzcniz.fsf@krugs.de>
Message-ID: <CAM_vjum5a3kz9WHc=OwEocFppVFr8A4FjTqfSseGWiGekUnU6g@mail.gmail.com>

Now that I'm at the computer with my R code, I've used both
\preformatted{}
and \cr to force line breaks.

Some combination of those may work for you.

Sarah


On Thu, Sep 5, 2013 at 11:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> Sarah Goslee <sarah.goslee at gmail.com> writes:
>
>> Untested, but did you try wrapping the whole thing in a single code block:
>
> Nope - also in one line.
>
> Rainer
>
>>
>> \code{
>> all
>> the
>> things
>> }
>>
>> Sarah
>>
>> On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>> Hi
>>>
>>> I want to include ascii art in a function documentation which should
>>> look as follow:
>>>
>>> ,----
>>> | +------+------+------+
>>> | | 1/16 | 1/16 | 1/16 |
>>> | +------+------+------+
>>> | | 1/16 | 8/16 | 1/16 |
>>> | +------+------+------+
>>> | | 1/16 | 1/16 | 1/16 |
>>> | +------+------+------+
>>> `----
>>>
>>>
>>> to keep the monospaced font even in html, I decided to use \code{}:
>>>
>>> ,----
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 8/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> |
>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>> |
>>> | \code{+------+------+------+}
>>> `----
>>>
>>> But the result was an empty line between each text:
>>>
>>> ,----
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 1/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 8/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> |
>>> |      '| 1/16 | 1/16 | 1/16 |'
>>> |
>>> |      '+------+------+------+'
>>> `----
>>>
>>> and when no empty lines were included obviously put everything behind
>>> each other.
>>>
>>> My question:
>>>
>>> Is there a way that I can achieve the ASCII art as shown above? Is there
>>> a way of having a \linebreak which does not insert a new line?
>>>
>>> Thanks,
>>>
>>> Rainer
>>>
>>>
>>> --
> <#secure method=pgpmime mode=sign>
>
> --
> Rainer M. Krug
>
> email: RMKrug<at>gmail<dot>com
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Thu Sep  5 17:36:49 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 5 Sep 2013 10:36:49 -0500
Subject: [Rd] ASCII art in function documentation - difference html and
 text output?
In-Reply-To: <m2li3bcmwi.fsf_-_@krugs.de>
References: <m238pjjr5s.fsf@krugs.de>
	<CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>
	<m2txhzcniz.fsf@krugs.de> <m2li3bcmwi.fsf_-_@krugs.de>
Message-ID: <457DEE8A-84CD-412F-9CE9-85D2A9814AB4@me.com>

Rainer,

Have you tried:

\preformatted{...}

which is documented in R-exts to preserve line breaks:

Indicate text that is a literal example of a piece of a program. Text is displayed using typewriter font if possible. Formatting, e.g. line breaks, is preserved. (Note that this includes a line break after the initial {, so typically text should start on the same line as the command.)
Due to limitations in LaTeX as of this writing, this macro may not be nested within other markup macros other than \dQuote and \sQuote, as errors or bad formatting may result. 


I have not used it myself, but might be worth a try, plus or minus the \cr use.

Regards,

Marc Schwartz

On Sep 5, 2013, at 10:23 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> Found a solution.
> 
> putting \cr at the end of each line inserts a carriage return, but no
> additional empty line. So
> 
> ,----
> | \code{+------+------+------+} \cr
> | \code{| 1/16 | 1/16 | 1/16 |} \cr
> | \code{+------+------+------+} \cr
> | \code{| 1/16 | 8/16 | 1/16 |} \cr
> | \code{+------+------+------+} \cr
> | \code{| 1/16 | 1/16 | 1/16 |} \cr
> | \code{+------+------+------+} \cr
> `----
> 
> produces the desired output.
> 
> 
> But interestingly,
> 
> ,----
> | \code{
> | +------+------+------+ \cr
> | | 1/16 | 1/16 | 1/16 | \cr
> | +------+------+------+ \cr
> | | 1/16 | 8/16 | 1/16 | \cr
> | +------+------+------+ \cr
> | | 1/16 | 1/16 | 1/16 | \cr
> | +------+------+------+ \cr
> | }
> `----
> 
> produces the correct output in html, 
> 
> ,----
> | </p>
> | <p><code> +------+------+------+ <br> | 1/16 | 1/16 | 1/16 |
> |   <br> +------+------+------+ <br> | 1/16 | 8/16 | 1/16 | <br>
> |   +------+------+------+ <br> | 1/16 | 1/16 | 1/16 | <br>
> |   +------+------+------+ <br> </code>
> | </p>
> `----
> 
> but
> 
> ,----
> |      ' +------+------+------+
> |      | 1/16 | 1/16 | 1/16 |
> | 
> |      +------+------+------+
> |      | 1/16 | 8/16 | 1/16 |
> |      +------+------+------+
> |      | 1/16 | 1/16 | 1/16 |
> |      +------+------+------+
> `----
> 
> in the text version - is there a bug somewhere?
> 
> Thanks,
> 
> Rainer
> 
> 
> 
> Rainer M Krug <Rainer at krugs.de> writes:
> 
>> Sarah Goslee <sarah.goslee at gmail.com> writes:
>> 
>>> Untested, but did you try wrapping the whole thing in a single code block:
>> 
>> Nope - also in one line.
>> 
>> Rainer
>> 
>>> 
>>> \code{
>>> all
>>> the
>>> things
>>> }
>>> 
>>> Sarah
>>> 
>>> On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>>> Hi
>>>> 
>>>> I want to include ascii art in a function documentation which should
>>>> look as follow:
>>>> 
>>>> ,----
>>>> | +------+------+------+
>>>> | | 1/16 | 1/16 | 1/16 |
>>>> | +------+------+------+
>>>> | | 1/16 | 8/16 | 1/16 |
>>>> | +------+------+------+
>>>> | | 1/16 | 1/16 | 1/16 |
>>>> | +------+------+------+
>>>> `----
>>>> 
>>>> 
>>>> to keep the monospaced font even in html, I decided to use \code{}:
>>>> 
>>>> ,----
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 8/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> `----
>>>> 
>>>> But the result was an empty line between each text:
>>>> 
>>>> ,----
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 1/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 8/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 1/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> `----
>>>> 
>>>> and when no empty lines were included obviously put everything behind
>>>> each other.
>>>> 
>>>> My question:
>>>> 
>>>> Is there a way that I can achieve the ASCII art as shown above? Is there
>>>> a way of having a \linebreak which does not insert a new line?
>>>> 
>>>> Thanks,
>>>> 
>>>> Rainer
>>>> 
>>>> 
>>>> --
>> <#secure method=pgpmime mode=sign>
>> 
> <#secure method=pgpmime mode=sign>
> 
> -- 
> Rainer M. Krug
> 
> email: RMKrug<at>gmail<dot>com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Rainer at krugs.de  Thu Sep  5 17:49:54 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 5 Sep 2013 17:49:54 +0200
Subject: [Rd] ASCII art in function documentation?
In-Reply-To: <CAM_vjum5a3kz9WHc=OwEocFppVFr8A4FjTqfSseGWiGekUnU6g@mail.gmail.com>
	(Sarah Goslee's message of "Thu, 5 Sep 2013 11:31:22 -0400")
References: <m238pjjr5s.fsf@krugs.de>
	<CAM_vju=9Z_kdWRvBf+r8x=4eS-q-s5Xng+aveF2WJKhuBQXGvA@mail.gmail.com>
	<m2txhzcniz.fsf@krugs.de>
	<CAM_vjum5a3kz9WHc=OwEocFppVFr8A4FjTqfSseGWiGekUnU6g@mail.gmail.com>
Message-ID: <m2hadzclp9.fsf@krugs.de>

OK - it boils down to an roxygen problem.

I will send a separate email for it.
Thanks,

Rainer


Sarah Goslee <sarah.goslee at gmail.com> writes:

> Now that I'm at the computer with my R code, I've used both
> \preformatted{}
> and \cr to force line breaks.
>
> Some combination of those may work for you.
>
> Sarah
>
>
> On Thu, Sep 5, 2013 at 11:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> Sarah Goslee <sarah.goslee at gmail.com> writes:
>>
>>> Untested, but did you try wrapping the whole thing in a single code block:
>>
>> Nope - also in one line.
>>
>> Rainer
>>
>>>
>>> \code{
>>> all
>>> the
>>> things
>>> }
>>>
>>> Sarah
>>>
>>> On Thu, Sep 5, 2013 at 10:10 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>>> Hi
>>>>
>>>> I want to include ascii art in a function documentation which should
>>>> look as follow:
>>>>
>>>> ,----
>>>> | +------+------+------+
>>>> | | 1/16 | 1/16 | 1/16 |
>>>> | +------+------+------+
>>>> | | 1/16 | 8/16 | 1/16 |
>>>> | +------+------+------+
>>>> | | 1/16 | 1/16 | 1/16 |
>>>> | +------+------+------+
>>>> `----
>>>>
>>>>
>>>> to keep the monospaced font even in html, I decided to use \code{}:
>>>>
>>>> ,----
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 8/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> |
>>>> | \code{| 1/16 | 1/16 | 1/16 |}
>>>> |
>>>> | \code{+------+------+------+}
>>>> `----
>>>>
>>>> But the result was an empty line between each text:
>>>>
>>>> ,----
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 1/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 8/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> |
>>>> |      '| 1/16 | 1/16 | 1/16 |'
>>>> |
>>>> |      '+------+------+------+'
>>>> `----
>>>>
>>>> and when no empty lines were included obviously put everything behind
>>>> each other.
>>>>
>>>> My question:
>>>>
>>>> Is there a way that I can achieve the ASCII art as shown above? Is there
>>>> a way of having a \linebreak which does not insert a new line?
>>>>
>>>> Thanks,
>>>>
>>>> Rainer
>>>>
>>>>
>>>> --
>> <#secure method=pgpmime mode=sign>
>>
>> --
>> Rainer M. Krug
>>
>> email: RMKrug<at>gmail<dot>com
>>
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From jefferis at mrc-lmb.cam.ac.uk  Thu Sep  5 18:32:40 2013
From: jefferis at mrc-lmb.cam.ac.uk (Dr Gregory Jefferis)
Date: Thu, 05 Sep 2013 17:32:40 +0100
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522773AC.3030609@gmail.com>
References: <522773AC.3030609@gmail.com>
Message-ID: <77D2ACF0-B309-41B2-BA4A-C7E03834C31B@mrc-lmb.cam.ac.uk>

Dear Duncan,

This certainly looks useful. Might you consider adding the ability to 
supply an alternative digest function? Details below.

I often use a homemade "make" type function which starts by looking at 
modification times e.g. in a private package

https://github.com/jefferis/nat.utils/blob/master/R/make.r

For some of my work, I use hash functions. However because I typically 
work with many large files I often use a special digest process e.g. 
using the crc checksum embedded in a gzip file directly or hashing only 
the part of a large file that is (almost) certain to change.

Perhaps (code unchecked) along the lines of:

changedFiles <- function(snapshot, timestamp = tempfile("timestamp"), 
file.info = NULL,
	digest = FALSE, digestfun=NULL, full.names = FALSE, ...)

if(digest){
	if(is.null(digestfun)) digestfun=tools::md5sum
	else digestfun=match.fun(digestfun)
	info <- data.frame(info, digest = digestfun(fullnames))
}

etc

OR alternatively using only one argument:

changedFiles <- function(snapshot, timestamp = tempfile("timestamp"), 
file.info = NULL,
	digest = FALSE, full.names = FALSE, ...)

if(is.logical(digest)){
	if(digest) digestfun=tools::md5sum
} else {
	# Assume that digest specifies a function that we want to use
	digestfun=match.fun(digest)
	digest=TRUE
}

if(digest)
	info <- data.frame(info, digest = digestfun(fullnames))

etc

Many thanks,

Greg.

On 4 Sep 2013, at 18:53, Duncan Murdoch wrote:

> In a number of places internal to R, we need to know which files have 
> changed (e.g. after building a vignette).  I've just written a general 
> purpose function "changedFiles" that I'll probably commit to R-devel.  
> Comments on the design (or bug reports) would be appreciated.
>
> The source for the function and the Rd page for it are inline below.
>
> ----- changedFiles.R:
> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"), 
> file.info = NULL,
>   md5sum = FALSE, full.names = FALSE, ...) {
> dosnapshot <- function(args) {
> fullnames <- do.call(list.files, c(full.names = TRUE, args))
> names <- do.call(list.files, c(full.names = full.names, args))
> if (isTRUE(file.info) || (is.character(file.info) && 
> length(file.info))) {
>  info <- file.info(fullnames)
> rownames(info) <- names
>  if (isTRUE(file.info))
>      file.info <- c("size", "isdir", "mode", "mtime")
> } else
>  info <- data.frame(row.names=names)
> if (md5sum)
> info <- data.frame(info, md5sum = tools::md5sum(fullnames))
> list(info = info, timestamp = timestamp, file.info = file.info,
> md5sum = md5sum, full.names = full.names, args = args)


--
Gregory Jefferis, PhD                   Tel: 01223 267048
Division of Neurobiology
MRC Laboratory of Molecular Biology
Francis Crick Avenue
Cambridge Biomedical Campus
Cambridge, CB2 OQH, UK

http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
http://jefferislab.org
http://flybrain.stanford.edu


From murdoch.duncan at gmail.com  Thu Sep  5 18:34:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Sep 2013 12:34:47 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <77D2ACF0-B309-41B2-BA4A-C7E03834C31B@mrc-lmb.cam.ac.uk>
References: <522773AC.3030609@gmail.com>
	<77D2ACF0-B309-41B2-BA4A-C7E03834C31B@mrc-lmb.cam.ac.uk>
Message-ID: <5228B2A7.1000803@gmail.com>

On 05/09/2013 12:32 PM, Dr Gregory Jefferis wrote:
> Dear Duncan,
>
> This certainly looks useful. Might you consider adding the ability to
> supply an alternative digest function? Details below.

Thanks, that's a good idea.

Duncan Murdoch
>
> I often use a homemade "make" type function which starts by looking at
> modification times e.g. in a private package
>
> https://github.com/jefferis/nat.utils/blob/master/R/make.r
>
> For some of my work, I use hash functions. However because I typically
> work with many large files I often use a special digest process e.g.
> using the crc checksum embedded in a gzip file directly or hashing only
> the part of a large file that is (almost) certain to change.
>
> Perhaps (code unchecked) along the lines of:
>
> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
> file.info = NULL,
> 	digest = FALSE, digestfun=NULL, full.names = FALSE, ...)
>
> if(digest){
> 	if(is.null(digestfun)) digestfun=tools::md5sum
> 	else digestfun=match.fun(digestfun)
> 	info <- data.frame(info, digest = digestfun(fullnames))
> }
>
> etc
>
> OR alternatively using only one argument:
>
> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
> file.info = NULL,
> 	digest = FALSE, full.names = FALSE, ...)
>
> if(is.logical(digest)){
> 	if(digest) digestfun=tools::md5sum
> } else {
> 	# Assume that digest specifies a function that we want to use
> 	digestfun=match.fun(digest)
> 	digest=TRUE
> }
>
> if(digest)
> 	info <- data.frame(info, digest = digestfun(fullnames))
>
> etc
>
> Many thanks,
>
> Greg.
>
> On 4 Sep 2013, at 18:53, Duncan Murdoch wrote:
>
> > In a number of places internal to R, we need to know which files have
> > changed (e.g. after building a vignette).  I've just written a general
> > purpose function "changedFiles" that I'll probably commit to R-devel.
> > Comments on the design (or bug reports) would be appreciated.
> >
> > The source for the function and the Rd page for it are inline below.
> >
> > ----- changedFiles.R:
> > changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
> > file.info = NULL,
> >   md5sum = FALSE, full.names = FALSE, ...) {
> > dosnapshot <- function(args) {
> > fullnames <- do.call(list.files, c(full.names = TRUE, args))
> > names <- do.call(list.files, c(full.names = full.names, args))
> > if (isTRUE(file.info) || (is.character(file.info) &&
> > length(file.info))) {
> >  info <- file.info(fullnames)
> > rownames(info) <- names
> >  if (isTRUE(file.info))
> >      file.info <- c("size", "isdir", "mode", "mtime")
> > } else
> >  info <- data.frame(row.names=names)
> > if (md5sum)
> > info <- data.frame(info, md5sum = tools::md5sum(fullnames))
> > list(info = info, timestamp = timestamp, file.info = file.info,
> > md5sum = md5sum, full.names = full.names, args = args)
>
>
> --
> Gregory Jefferis, PhD                   Tel: 01223 267048
> Division of Neurobiology
> MRC Laboratory of Molecular Biology
> Francis Crick Avenue
> Cambridge Biomedical Campus
> Cambridge, CB2 OQH, UK
>
> http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
> http://jefferislab.org
> http://flybrain.stanford.edu


From h.wickham at gmail.com  Thu Sep  5 18:49:51 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 5 Sep 2013 11:49:51 -0500
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
Message-ID: <CABdHhvF8PnsnGGkY+Ty3SE3zj3ZYu+_o1NiSQ=uCxeUbyuh3ww@mail.gmail.com>

> This approach does have the difficulty that users could attempt to compare
> snapshots that were taken with different options and that can't be
> compared, but that should be an easy error to detect.

FYI I implemented that approach in testthat:
https://github.com/hadley/testthat/blob/master/R/watcher.r - it's a
bit more general, because it just sits in the background and listens
for changes, dispatching to a callback.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From gianluca.mastrantonio at yahoo.it  Thu Sep  5 22:28:20 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Thu, 05 Sep 2013 22:28:20 +0200
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <522855F5.3040204@yahoo.it>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk> <522855F5.3040204@yahoo.it>
Message-ID: <5228E964.9030406@yahoo.it>

just for completion

i need to use
library(Model, lib.loc="user/area/myRLib")
because if i use
library(Model)
i get this message
Error in library("BayesWrap") : there is no package called 'BayesWrap'




Il 05/09/13 11:59, gianluca.mastrantonio at yahoo.it ha scritto:
> First of all, thanks for your help.
>
> I did all the things you told me. I was able to load the library, but 
> then
>
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object 
> '/lustre/work/gjona2/Wrap/BayesWrap/libs/BayesWrap.so':
>   libR.so: cannot open shared object file: No such file or directory
> In addition: Warning message:
> package 'BayesWrap' was built under R version 2.15.2
> Error: package/namespace load failed for 'BayesWrap'
> Execution halted
>
> what does it means?
>
> G.M.
>
> Il 04/09/13 22:42, Prof Brian Ripley ha scritto:
>> On 04/09/2013 19:58, Geoff Jentry wrote:
>>>> Can you add some details?
>>>> Suppose i have the package Model.tar.gz and my writable are is in
>>>> user/area, what i have to do next to install the package?
>>>
>>> What I was picturing was something like this (forgive me if syntax 
>>> isn't
>>> 100%):
>>>
>>> mkdir user/area/myRLib
>>> R CMD INSTALL --library=user/area/myRLib Model.tar.gz
>>>
>>> and then in R:
>>> library(Model, lib.loc="user/area/myRLib")
>>>
>>> Note though Brian Ripley's response to me where he indicates that this
>>> is handled automatically.
>>
>> Yes,  install.packages("Model.tar.gz") should suffice.
>>
>>>
>>> -J
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From ripley at stats.ox.ac.uk  Thu Sep  5 22:38:22 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 05 Sep 2013 21:38:22 +0100
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <5228E964.9030406@yahoo.it>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk> <522855F5.3040204@yahoo.it>
	<5228E964.9030406@yahoo.it>
Message-ID: <5228EBBE.6080101@stats.ox.ac.uk>

On 05/09/2013 21:28, gianluca.mastrantonio at yahoo.it wrote:
> just for completion
>
> i need to use
> library(Model, lib.loc="user/area/myRLib")
> because if i use
> library(Model)
> i get this message
> Error in library("BayesWrap") : there is no package called 'BayesWrap'

For the record: not if you follow my suggestion.

See ?.libPaths for why.

>
>
>
> Il 05/09/13 11:59, gianluca.mastrantonio at yahoo.it ha scritto:
>> First of all, thanks for your help.
>>
>> I did all the things you told me. I was able to load the library, but
>> then
>>
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>   unable to load shared object
>> '/lustre/work/gjona2/Wrap/BayesWrap/libs/BayesWrap.so':
>>   libR.so: cannot open shared object file: No such file or directory
>> In addition: Warning message:
>> package 'BayesWrap' was built under R version 2.15.2
>> Error: package/namespace load failed for 'BayesWrap'
>> Execution halted
>>
>> what does it means?
>>
>> G.M.
>>
>> Il 04/09/13 22:42, Prof Brian Ripley ha scritto:
>>> On 04/09/2013 19:58, Geoff Jentry wrote:
>>>>> Can you add some details?
>>>>> Suppose i have the package Model.tar.gz and my writable are is in
>>>>> user/area, what i have to do next to install the package?
>>>>
>>>> What I was picturing was something like this (forgive me if syntax
>>>> isn't
>>>> 100%):
>>>>
>>>> mkdir user/area/myRLib
>>>> R CMD INSTALL --library=user/area/myRLib Model.tar.gz
>>>>
>>>> and then in R:
>>>> library(Model, lib.loc="user/area/myRLib")
>>>>
>>>> Note though Brian Ripley's response to me where he indicates that this
>>>> is handled automatically.
>>>
>>> Yes,  install.packages("Model.tar.gz") should suffice.
>>>
>>>>
>>>> -J
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From skostysh at princeton.edu  Thu Sep  5 23:13:57 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Thu, 5 Sep 2013 17:13:57 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <5228618F.20205@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CAE3=dmcuKNCSJU_kV2mg6=FV9u9XivVaTTSZaWOMQbHYS30A2w@mail.gmail.com>
	<5228618F.20205@gmail.com>
Message-ID: <CAE3=dmeY0x0PYmd5W5GkCPDzNXQPSAw0znfBFTeObWercwpYAA@mail.gmail.com>

On Thu, Sep 5, 2013 at 6:48 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-09-04 11:36 PM, Scott Kostyshak wrote:
>>
>> On Wed, Sep 4, 2013 at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> In a number of places internal to R, we need to know which files have
>>> changed (e.g. after building a vignette).  I've just written a general
>>> purpose function "changedFiles" that I'll probably commit to R-devel.
>>> Comments on the design (or bug reports) would be appreciated.
>>>
>>> The source for the function and the Rd page for it are inline below.
>>
>>
>> This looks like a useful function. Thanks for writing it. I have only
>> one (picky) comment below.
>>
>>> ----- changedFiles.R:
>>> changedFiles <- function(snapshot, timestamp = tempfile("timestamp"),
>>> file.info = NULL,
>>>               md5sum = FALSE, full.names = FALSE, ...) {
>>>      dosnapshot <- function(args) {
>>>          fullnames <- do.call(list.files, c(full.names = TRUE, args))
>>>          names <- do.call(list.files, c(full.names = full.names, args))
>>>          if (isTRUE(file.info) || (is.character(file.info) &&
>>> length(file.info))) {
>>>              info <- file.info(fullnames)
>>>          rownames(info) <- names
>>>              if (isTRUE(file.info))
>>>                  file.info <- c("size", "isdir", "mode", "mtime")
>>>          } else
>>>              info <- data.frame(row.names=names)
>>>      if (md5sum)
>>>          info <- data.frame(info, md5sum = tools::md5sum(fullnames))
>>>      list(info = info, timestamp = timestamp, file.info = file.info,
>>>           md5sum = md5sum, full.names = full.names, args = args)
>>>      }
>>>      if (missing(snapshot) || !inherits(snapshot,
>>> "changedFilesSnapshot")) {
>>>          if (length(timestamp) == 1)
>>>              file.create(timestamp)
>>>          if (missing(snapshot)) snapshot <- "."
>>>          pre <- dosnapshot(list(path = snapshot, ...))
>>>          pre$pre <- pre$info
>>>          pre$info <- NULL
>>>          pre$wd <- getwd()
>>>          class(pre) <- "changedFilesSnapshot"
>>>          return(pre)
>>>      }
>>>
>>>      if (missing(timestamp)) timestamp <- snapshot$timestamp
>>>      if (missing(file.info) || isTRUE(file.info)) file.info <-
>>> snapshot$file.info
>>>      if (identical(file.info, FALSE)) file.info <- NULL
>>>      if (missing(md5sum))    md5sum <- snapshot$md5sum
>>>      if (missing(full.names)) full.names <- snapshot$full.names
>>>
>>>      pre <- snapshot$pre
>>>      savewd <- getwd()
>>>      on.exit(setwd(savewd))
>>>      setwd(snapshot$wd)
>>>
>>>      args <- snapshot$args
>>>      newargs <- list(...)
>>>      args[names(newargs)] <- newargs
>>>      post <- dosnapshot(args)$info
>>>      prenames <- rownames(pre)
>>>      postnames <- rownames(post)
>>>
>>>      added <- setdiff(postnames, prenames)
>>>      deleted <- setdiff(prenames, postnames)
>>>      common <- intersect(prenames, postnames)
>>>
>>>      if (length(file.info)) {
>>>          preinfo <- pre[common, file.info]
>>>          postinfo <- post[common, file.info]
>>>          changes <- preinfo != postinfo
>>>      }
>>>      else changes <- matrix(logical(0), nrow = length(common), ncol = 0,
>>>                             dimnames = list(common, character(0)))
>>>      if (length(timestamp))
>>>          changes <- cbind(changes, Newer = file_test("-nt", common,
>>> timestamp))
>>>      if (md5sum) {
>>>          premd5 <- pre[common, "md5sum"]
>>>          postmd5 <- post[common, "md5sum"]
>>>      changes <- cbind(changes, md5sum = premd5 != postmd5)
>>>      }
>>>      changes1 <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop =
>>> FALSE]
>>>      changed <- rownames(changes1)
>>>      structure(list(added = added, deleted = deleted, changed = changed,
>>>          unchanged = setdiff(common, changed), changes = changes), class
>>> =
>>> "changedFiles")
>>> }
>>>
>>> print.changedFilesSnapshot <- function(x, ...) {
>>>      cat("changedFiles snapshot:\n timestamp = \"", x$timestamp, "\"\n
>>> file.info = ",
>>>          if (length(x$file.info)) paste(paste0('"', x$file.info, '"'),
>>> collapse=","),
>>>          "\n md5sum = ", x$md5sum, "\n args = ", deparse(x$args, control
>>> =
>>> NULL), "\n", sep="")
>>>      x
>>> }
>>>
>>> print.changedFiles <- function(x, ...) {
>>>      if (length(x$added)) cat("Files added:\n",  paste0("  ", x$added,
>>> collapse="\n"), "\n", sep="")
>>>      if (length(x$deleted)) cat("Files deleted:\n",  paste0("  ",
>>> x$deleted,
>>> collapse="\n"), "\n", sep="")
>>>      changes <- x$changes
>>>      changes <- changes[rowSums(changes, na.rm = TRUE) > 0, , drop=FALSE]
>>>      changes <- changes[, colSums(changes, na.rm = TRUE) > 0, drop=FALSE]
>>>      if (nrow(changes)) {
>>>          cat("Files changed:\n")
>>>          print(changes)
>>>      }
>>>      x
>>> }
>>> ----------------------
>>>
>>> --- changedFiles.Rd:
>>> \name{changedFiles}
>>> \alias{changedFiles}
>>> \alias{print.changedFiles}
>>> \alias{print.changedFilesSnapshot}
>>> \title{
>>> Detect which files have changed
>>> }
>>> \description{
>>> On the first call, \code{changedFiles} takes a snapshot of a selection of
>>> files.  In subsequent
>>> calls, it takes another snapshot, and returns an object containing data
>>> on
>>> the
>>> differences between the two snapshots.  The snapshots need not be the
>>> same
>>> directory;
>>> this could be used to compare two directories.
>>> }
>>> \usage{
>>> changedFiles(snapshot, timestamp = tempfile("timestamp"), file.info =
>>> NULL,
>>>               md5sum = FALSE, full.names = FALSE, ...)
>>> }
>>> \arguments{
>>>    \item{snapshot}{
>>> The path to record, or a previous snapshot.  See the Details.
>>> }
>>>    \item{timestamp}{
>>> The name of a file to write at the time the initial snapshot
>>> is taken.  In subsequent calls, modification times of files will be
>>> compared
>>> to
>>> this file, and newer files will be reported as changed.  Set to
>>> \code{NULL}
>>> to skip this test.
>>> }
>>>    \item{file.info}{
>>> A vector of columns from the result of the \code{file.info} function, or
>>> a
>>> logical value.  If
>>> \code{TRUE}, columns \code{c("size", "isdir", "mode", "mtime")} will be
>>> used.  Set to
>>> \code{FALSE} or \code{NULL} to skip this test.  See the Details.
>>> }
>>>    \item{md5sum}{
>>> A logical value indicating whether MD5 summaries should be taken as part
>>> of
>>> the snapshot.
>>> }
>>>    \item{full.names}{
>>> A logical value indicating whether full names (as in
>>> \code{\link{list.files}}) should be
>>> recorded.
>>> }
>>>    \item{\dots}{
>>> Additional parameters to pass to \code{\link{list.files}} to control the
>>> set
>>> of files
>>> in the snapshots.
>>> }
>>> }
>>> \details{
>>> This function works in two modes.  If the \code{snapshot} argument is
>>> missing or is
>>> not of S3 class \code{"changedFilesSnapshot"}, it is used as the
>>> \code{path}
>>> argument
>>> to \code{\link{list.files}} to obtain a list of files.  If it is of class
>>> \code{"changedFilesSnapshot"}, then it is taken to be the baseline file
>>> and a new snapshot is taken and compared with it.  In the latter case,
>>> missing
>>> arguments default to match those from the initial snapshot.
>>>
>>> If the \code{timestamp} argument is length 1, a file with that name is
>>> created
>>> in the current directory during the initial snapshot, and
>>> \code{\link{file_test}}
>>> is used to compare the age of all files to it during subsequent calls.
>>>
>>> If the \code{file.info} argument is \code{TRUE} or it contains a
>>> non-empty
>>> character vector, the indicated columns from the result of a call to
>>> \code{\link{file.info}} will be recorded and compared.
>>>
>>> If \code{md5sum} is \code{TRUE}, the \code{tools::\link{md5sum}} function
>>> will be called to record the 32 byte MD5 checksum for each file, and
>>> these
>>> values
>>> will be compared.
>>> }
>>> \value{
>>> In the initial snapshot phase, an object of class
>>> \code{"changedFilesSnapshot"} is returned.  This
>>> is a list containing the fields
>>> \item{pre}{a dataframe whose rownames are the filenames, and whose
>>> columns
>>> contain the
>>> requested snapshot data}
>>> \item{timestamp, file.info, md5sum, full.names}{a record of the arguments
>>> in
>>> the initial call}
>>> \item{args}{other arguments passed via \code{...} to
>>> \code{\link{list.files}}.}
>>>
>>> In the comparison phase, an object of class \code{"changedFiles"}. This
>>> is a
>>> list containing
>>> \item{added, deleted, changed, unchanged}{character vectors of filenames
>>> from the before
>>> and after snapshots, with obvious meanings}
>>> \item{changes}{a logical matrix with a row for each common file, and a
>>> column for each
>>> comparison test.  \code{TRUE} indicates a change in that test.}
>>>
>>> \code{\link{print}} methods are defined for each of these types. The
>>> \code{\link{print}} method for \code{"changedFilesSnapshot"} objects
>>> displays the arguments used to produce it, while the one for
>>> \code{"changedFiles"} displays the \code{added}, \code{deleted}
>>> and \code{changed} fields if non-empty, and a submatrix of the
>>> \code{changes}
>>> matrix containing all of the \code{TRUE} values.
>>> }
>>> \author{
>>> Duncan Murdoch
>>> }
>>> \seealso{
>>> \code{\link{file.info}}, \code{\link{file_test}}, \code{\link{md5sum}}.
>>> }
>>> \examples{
>>> # Create some files in a temporary directory
>>> dir <- tempfile()
>>> dir.create(dir)
>>
>>
>> Should a different name than 'dir' be used since 'dir' is a base function?
>
>
> Such as?

'dir_', 'dir1', 'temp_dir', none of which is a base function. I
thought that it was not recommended to create objects with the same
name as functions, but perhaps this recommended practice is not agreed
on.

>> Further, if someone is not very familiar with R (or just not in "R
>> mode" at the time of reading), they might think that 'dir.create' is
>> calling the create member of the object named 'dir' that you just
>> made.
>
>
> dir.create is an existing function.  I wouldn't have named it that, but
> that's its name.

I meant that if the object is called, e.g. 'temp_dir', one will not
think that 'dir.create' is a call to the 'create' member of 'dir'
because there is no 'dir' object apart from the base function. But
anyone with experience in R would know that this is not how R parses
'dir.create'.

In any case, I shouldn't waste your time on such a minor and subjective thing.

Scott

> Duncan Murdoch
>
>
>>
>> Scott
>>
>>> writeBin(1, file.path(dir, "file1"))
>>> writeBin(2, file.path(dir, "file2"))
>>> dir.create(file.path(dir, "dir"))
>>>
>>> # Take a snapshot
>>> snapshot <- changedFiles(dir, file.info=TRUE, md5sum=TRUE)
>>>
>>> # Change one of the files
>>> writeBin(3, file.path(dir, "file2"))
>>>
>>> # Display the detected changes
>>> changedFiles(snapshot)
>>> changedFiles(snapshot)$changes
>>> }
>>> \keyword{utilities}
>>> \keyword{file}
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From kmillar at google.com  Fri Sep  6 08:46:36 2013
From: kmillar at google.com (Karl Millar)
Date: Thu, 5 Sep 2013 23:46:36 -0700
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <5227DA21.8000202@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
Message-ID: <CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>

Comments inline:


On Wed, Sep 4, 2013 at 6:10 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 13-09-04 8:02 PM, Karl Millar wrote:
>>
>> Hi Duncan,
>>
>> I think this functionality would be much easier to use and understand if
>> you split it up the functionality of taking snapshots and comparing them
>> into separate functions.
>
>
> Yes, that's another possibility.  Some more comment below...
>
>
>
>  In addition, the 'timestamp' functionality
>>
>> seems both confusing and brittle to me.  I think it would be better to
>> store file modification times in the snapshot and use those instead of
>> an external file.  Maybe:
>
>
> You can do that, using file.info = "mtime", but the file.info snapshots are quite a bit slower than using the timestamp file (when looking at a big recursive directory of files).


Sorry, I completely failed to explain what I was thinking here.  There
are a number of issues here, but the biggest one is that you're
implicitly assuming that files that get modified will have mtimes that
come after the timestamp file was created.  This isn't always true,
with the most notable exception being if you download a package from
CRAN and untar it, the mtimes are usually well in the past (at least
with GNU tar on a linux system), so this code won't notice that the
files have changed.

It may be a good idea to store the file sizes as well, which would
help prevent false negatives in the (rare IIRC) cases where the
contents have changed but the mtime values have not.  Since you
already need to call file.info() to get the mtime, this shouldn't
increase the runtime, and the extra memory needed is fairly modest.

>>
>> # Take a snapshot of the files.
>> takeFileSnapshot(directory, file.info <http://file.info> = TRUE, md5sum
>>
>> = FALSE, full.names = FALSE, recursive = TRUE, ...)
>>
>> # Take a snapshot using the same options as used for snapshot.
>> retakeFileSnapshot(snapshot, directory = snapshot$directory) {
>>     takeFileSnapshot)(directory, file.info <http://file.info> =
>> snapshot$file.info <http://file.info>, md5sum = snapshot$md5sum, etc)
>>
>> }
>>
>> compareFileSnapshots(snapshot1, snapshot2)
>> - or -
>> getNewFiles(snapshat1, snapshot2)       # These names are probably too
>> generic
>> getDeletedFiles(snapshot1, snapshot2)
>> getUpdatedFiles(snapshot1, snapshot2)
>> -or-
>> setdiff(snapshot1, snapshot2)  # Unclear how this should treat updated files
>>
>>
>> This approach does have the difficulty that users could attempt to
>> compare snapshots that were taken with different options and that can't
>> be compared, but that should be an easy error to detect.
>
>
> I don't want to add too many new functions.  The general R style is to have functions that do a lot, rather than have a lot of different functions to achieve different parts of related tasks.  This is better for interactive use (fewer functions to remember, a simpler help system to navigate), though it probably results in less readable code.


This is somewhat more nuanced and not particular to interactive use
IMHO.  Having functions that do a lot is good, _as long as the
semantics are always consistent_.  For example, lm() does a huge
amount and has a wide variety of ways that you can specify your data,
but it basically does the same thing no matter how you use it.  On the
other hand, if you have a function that does different things
depending on how you call it (e.g. reshape()) then it's easy to
remember the function name, but much harder to remember how to call it
correctly, harder to understand the documentation and less readable.

>
> I can see an argument for two functions (a get and a compare), but I don't think there are many cases where doing two gets and comparing the snapshots would be worth the extra runtime.  (It's extra because file.info is only a little faster than list.files, and it would be unavoidable to call both twice in that version.  Using the timestamp file avoids one of those calls, and replaces the other with file_test, which takes a similar amount of time.  So overall it's about 20-25% faster.)  It also makes the code a bit more complicated, i.e. three calls (get, get, compare) instead of two (get, compare).


I think a 'snapshotDirectory' and 'compareDirectoryToSnapshot'
combination might work well.

Thanks,

Karl


From murdoch.duncan at gmail.com  Fri Sep  6 11:17:03 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 05:17:03 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
Message-ID: <52299D8F.1000805@gmail.com>

On 13-09-06 2:46 AM, Karl Millar wrote:
> Comments inline:
>
>
> On Wed, Sep 4, 2013 at 6:10 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 13-09-04 8:02 PM, Karl Millar wrote:
>>>
>>> Hi Duncan,
>>>
>>> I think this functionality would be much easier to use and understand if
>>> you split it up the functionality of taking snapshots and comparing them
>>> into separate functions.
>>
>>
>> Yes, that's another possibility.  Some more comment below...
>>
>>
>>
>>   In addition, the 'timestamp' functionality
>>>
>>> seems both confusing and brittle to me.  I think it would be better to
>>> store file modification times in the snapshot and use those instead of
>>> an external file.  Maybe:
>>
>>
>> You can do that, using file.info = "mtime", but the file.info snapshots are quite a bit slower than using the timestamp file (when looking at a big recursive directory of files).
>
>
> Sorry, I completely failed to explain what I was thinking here.  There
> are a number of issues here, but the biggest one is that you're
> implicitly assuming that files that get modified will have mtimes that
> come after the timestamp file was created.  This isn't always true,
> with the most notable exception being if you download a package from
> CRAN and untar it, the mtimes are usually well in the past (at least
> with GNU tar on a linux system), so this code won't notice that the
> files have changed.
>
> It may be a good idea to store the file sizes as well, which would
> help prevent false negatives in the (rare IIRC) cases where the
> contents have changed but the mtime values have not.  Since you
> already need to call file.info() to get the mtime, this shouldn't
> increase the runtime, and the extra memory needed is fairly modest.

If we need to use file.info(), then I store the complete result, so I 
have size if I have mtime.
>
>>>
>>> # Take a snapshot of the files.
>>> takeFileSnapshot(directory, file.info <http://file.info> = TRUE, md5sum
>>>
>>> = FALSE, full.names = FALSE, recursive = TRUE, ...)
>>>
>>> # Take a snapshot using the same options as used for snapshot.
>>> retakeFileSnapshot(snapshot, directory = snapshot$directory) {
>>>      takeFileSnapshot)(directory, file.info <http://file.info> =
>>> snapshot$file.info <http://file.info>, md5sum = snapshot$md5sum, etc)
>>>
>>> }
>>>
>>> compareFileSnapshots(snapshot1, snapshot2)
>>> - or -
>>> getNewFiles(snapshat1, snapshot2)       # These names are probably too
>>> generic
>>> getDeletedFiles(snapshot1, snapshot2)
>>> getUpdatedFiles(snapshot1, snapshot2)
>>> -or-
>>> setdiff(snapshot1, snapshot2)  # Unclear how this should treat updated files
>>>
>>>
>>> This approach does have the difficulty that users could attempt to
>>> compare snapshots that were taken with different options and that can't
>>> be compared, but that should be an easy error to detect.
>>
>>
>> I don't want to add too many new functions.  The general R style is to have functions that do a lot, rather than have a lot of different functions to achieve different parts of related tasks.  This is better for interactive use (fewer functions to remember, a simpler help system to navigate), though it probably results in less readable code.
>
>
> This is somewhat more nuanced and not particular to interactive use
> IMHO.  Having functions that do a lot is good, _as long as the
> semantics are always consistent_.  For example, lm() does a huge
> amount and has a wide variety of ways that you can specify your data,
> but it basically does the same thing no matter how you use it.  On the
> other hand, if you have a function that does different things
> depending on how you call it (e.g. reshape()) then it's easy to
> remember the function name, but much harder to remember how to call it
> correctly, harder to understand the documentation and less readable.
>
>>
>> I can see an argument for two functions (a get and a compare), but I don't think there are many cases where doing two gets and comparing the snapshots would be worth the extra runtime.  (It's extra because file.info is only a little faster than list.files, and it would be unavoidable to call both twice in that version.  Using the timestamp file avoids one of those calls, and replaces the other with file_test, which takes a similar amount of time.  So overall it's about 20-25% faster.)  It also makes the code a bit more complicated, i.e. three calls (get, get, compare) instead of two (get, compare).
>
>
> I think a 'snapshotDirectory' and 'compareDirectoryToSnapshot'
> combination might work well.

I have split it into two functions.  The compare function has two 
snapshot arguments, but if only the "before" is given, it will compute 
the "after" from the current file system.  This makes a cleaner design, 
thanks for the suggestion.

About the function names:  selection of files for the snapshot is done 
by list.files, and that function's "path" argument can be a vector, so 
multiple directories can be recorded at once.  I've chosen 
"fileSnapshot" and "changedFiles" so far, but those aren't perfect.

I need to do a little more cleanup and testing, then I'll put the new 
version online somewhere.

Duncan Murdoch


From groemping at beuth-hochschule.de  Fri Sep  6 11:36:10 2013
From: groemping at beuth-hochschule.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Fri, 6 Sep 2013 11:36:10 +0200
Subject: [Rd] Importing function that is previously imported by other package
Message-ID: <5229A20A.3010601@beuth-hochschule.de>

Dear developeRs,

I encounter the following problem: in the current version of my package 
FrF2, certain calls to a functioni do not work when package combinat is 
loaded, because function combn from combinat masks the function from 
utils that my package uses.
I tried to solve this issue by importing function combn into the 
namespace of FrF2; I don't need to export it, I just want to use it 
internally in the package; I could of course find all occurrences and 
replace them with utils::combn, but I thought that the namespace 
solution would be more elegant, faster, and in the spirit of R 
programming. The fix was successful: the installed package works with 
combinat on the search path.

However, when installing or loading the modified FrF2, I now get the 
warning "replacing previous import by utils::combn when loading 'FrF2'" 
(that's on R-devel, on production R the wording is slightly different, 
but there is also a warning). There is no warning from R CMD check, 
however. In case this is relevant: None of the packages in my "Depends" 
list mentions "utils" under depends, one of the packages FrF2 depends on 
also imports from utils, including utils::combn.

Shouldn't it be possible to have several packages IMport a function of 
the same name without a warning?

Best, Ulrike

-- 
##############################################
## Prof. Dr. Ulrike Groemping
## FB II
## Beuth University of Applied Sciences Berlin
##############################################
## prof.beuth-hochschule.de/groemping
## Phone: +49(0)30 4504 5127
## Fax:   +49(0)30 4504 66 5127
## Home office: +49(0)30 394 04 863
##############################################


From murdoch.duncan at gmail.com  Fri Sep  6 12:53:24 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 06:53:24 -0400
Subject: [Rd] Importing function that is previously imported by other
 package
In-Reply-To: <5229A20A.3010601@beuth-hochschule.de>
References: <5229A20A.3010601@beuth-hochschule.de>
Message-ID: <5229B424.9010905@gmail.com>

On 13-09-06 5:36 AM, Ulrike Gr?mping wrote:
> Dear developeRs,
>
> I encounter the following problem: in the current version of my package
> FrF2, certain calls to a functioni do not work when package combinat is
> loaded, because function combn from combinat masks the function from
> utils that my package uses.
> I tried to solve this issue by importing function combn into the
> namespace of FrF2; I don't need to export it, I just want to use it
> internally in the package; I could of course find all occurrences and
> replace them with utils::combn, but I thought that the namespace
> solution would be more elegant, faster, and in the spirit of R
> programming. The fix was successful: the installed package works with
> combinat on the search path.
>
> However, when installing or loading the modified FrF2, I now get the
> warning "replacing previous import by utils::combn when loading 'FrF2'"
> (that's on R-devel, on production R the wording is slightly different,
> but there is also a warning). There is no warning from R CMD check,
> however. In case this is relevant: None of the packages in my "Depends"
> list mentions "utils" under depends, one of the packages FrF2 depends on
> also imports from utils, including utils::combn.
>
> Shouldn't it be possible to have several packages IMport a function of
> the same name without a warning?
>
> Best, Ulrike
>

I think we need to see the details.  I don't get those warnings with the 
version on CRAN.  Perhaps you are importing it twice, e.g.

import(combinat)
importFrom(utils, combn)

?

Duncan Murdoch


From groemping at beuth-hochschule.de  Fri Sep  6 13:06:36 2013
From: groemping at beuth-hochschule.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Fri, 6 Sep 2013 13:06:36 +0200
Subject: [Rd] Importing function that is previously imported by other
 package
In-Reply-To: <5229B424.9010905@gmail.com>
References: <5229A20A.3010601@beuth-hochschule.de> <5229B424.9010905@gmail.com>
Message-ID: <5229B73C.2040305@beuth-hochschule.de>

Am 06.09.2013 12:53, schrieb Duncan Murdoch:
> On 13-09-06 5:36 AM, Ulrike Gr?mping wrote:
>> Dear developeRs,
>>
>> I encounter the following problem: in the current version of my package
>> FrF2, certain calls to a functioni do not work when package combinat is
>> loaded, because function combn from combinat masks the function from
>> utils that my package uses.
>> I tried to solve this issue by importing function combn into the
>> namespace of FrF2; I don't need to export it, I just want to use it
>> internally in the package; I could of course find all occurrences and
>> replace them with utils::combn, but I thought that the namespace
>> solution would be more elegant, faster, and in the spirit of R
>> programming. The fix was successful: the installed package works with
>> combinat on the search path.
>>
>> However, when installing or loading the modified FrF2, I now get the
>> warning "replacing previous import by utils::combn when loading 'FrF2'"
>> (that's on R-devel, on production R the wording is slightly different,
>> but there is also a warning). There is no warning from R CMD check,
>> however. In case this is relevant: None of the packages in my "Depends"
>> list mentions "utils" under depends, one of the packages FrF2 depends on
>> also imports from utils, including utils::combn.
>>
>> Shouldn't it be possible to have several packages IMport a function of
>> the same name without a warning?
>>
>> Best, Ulrike
>>
>
> I think we need to see the details.  I don't get those warnings with 
> the version on CRAN.  Perhaps you are importing it twice, e.g.
>
> import(combinat)
> importFrom(utils, combn)
>
> ?
>
> Duncan Murdoch
Thanks, that guess was to the point, I did import it twice in my own 
namespace, once with utils in the import list, and once with importFrom.

Best, Ulrike

-- 
##############################################
## Prof. Dr. Ulrike Groemping
## FB II
## Beuth University of Applied Sciences Berlin
##############################################
## prof.beuth-hochschule.de/groemping
## Phone: +49(0)30 4504 5127
## Fax:   +49(0)30 4504 66 5127
## Home office: +49(0)30 394 04 863
##############################################


From stnava at gmail.com  Fri Sep  6 15:28:57 2013
From: stnava at gmail.com (brian avants)
Date: Fri, 6 Sep 2013 09:28:57 -0400
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <5228EBBE.6080101@stats.ox.ac.uk>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk> <522855F5.3040204@yahoo.it>
	<5228E964.9030406@yahoo.it> <5228EBBE.6080101@stats.ox.ac.uk>
Message-ID: <CABWzF4XOMA3tCdxdqERF8LL8Y3WTc7vsxFrqUvzrWO+9EB+81g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130906/44f9bd5b/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Sep  6 15:47:06 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Sep 2013 14:47:06 +0100
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <CABWzF4XOMA3tCdxdqERF8LL8Y3WTc7vsxFrqUvzrWO+9EB+81g@mail.gmail.com>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk> <522855F5.3040204@yahoo.it>
	<5228E964.9030406@yahoo.it> <5228EBBE.6080101@stats.ox.ac.uk>
	<CABWzF4XOMA3tCdxdqERF8LL8Y3WTc7vsxFrqUvzrWO+9EB+81g@mail.gmail.com>
Message-ID: <5229DCDA.80107@stats.ox.ac.uk>

On 06/09/2013 14:28, brian avants wrote:
> Hello Everyone
>
> I have been following this thread because I have similar issues with an
> outside-of-R package.   The problem is related to dylib loading i.e. of
> the form
>
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>    unable to load shared object
> '/Users/stnava/code/gitANTs/ANTsR/src/ANTS/ANTS-build/lib/ANTsR/libs/libRantsRegistration.so':
>
> dlopen(/Users/stnava/code/gitANTs/ANTsR/src/ANTS/ANTS-build/lib/ANTsR/libs/libRantsRegistration.so,
> 6): Library not loaded: libitkdouble-conversion-4.5.1.dylib
>    Referenced from:
> /Users/stnava/code/gitANTs/ANTsR/src/ANTS/ANTS-build/lib/libl_antsRegistration.dylib
>    Reason: image not found
>
> A solution that seems to work on both osx and linux is:
>
> export
> R_LD_LIBRARY_PATH=/Users/stnava/code/gitANTs/ANTsR/src/ANTS/ANTS-build/lib/
>
> but I would really like to avoid this, if possible.    I tried using
> .libPaths ( suspecting it would not work ) and I got the same error as
> above ...

But that was about installing packages, not the linking problem: this 
thread wandered.

> as an aside, there seems very little documentation for R_LD_LIBRARY_PATH
> & I don't recall how I came across it ...  i have some other notes here:

It is not intended for end-user use.  You could just as well have set 
LD_LIBRARY_PATH (or DYLD_LIBRARY_PATH) in the standard way for your OS.

Any approach to setting a library path has problems: on platforms that 
support it and for personal installations I would use -rpath or similar, 
but it has problems for system-wide installations since it uses absolute 
paths.  There is a section ?5.8 in 'Writing R Extensions' about this 
(use a current copy from http://cran.r-project.org/manuals.html).

>
> https://github.com/stnava/ANTsR/blob/master/configure
>
> any thoughts appreciated , at your leisure ...
>
> & thanks, as usual,
>
>
>
> brian
>
>
>
>
> On Thu, Sep 5, 2013 at 4:38 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk
> <mailto:ripley at stats.ox.ac.uk>> wrote:
>
>     On 05/09/2013 21:28, gianluca.mastrantonio at yahoo.it
>     <mailto:gianluca.mastrantonio at yahoo.it> wrote:
>
>         just for completion
>
>         i need to use
>         library(Model, lib.loc="user/area/myRLib")
>         because if i use
>         library(Model)
>         i get this message
>         Error in library("BayesWrap") : there is no package called
>         'BayesWrap'
>
>
>     For the record: not if you follow my suggestion.
>
>     See ?.libPaths for why.
>
>
>
>
>
>         Il 05/09/13 11:59, gianluca.mastrantonio at yahoo.it
>         <mailto:gianluca.mastrantonio at yahoo.it> ha scritto:
>
>             First of all, thanks for your help.
>
>             I did all the things you told me. I was able to load the
>             library, but
>             then
>
>             Error in dyn.load(file, DLLpath = DLLpath, ...) :
>                unable to load shared object
>             '/lustre/work/gjona2/Wrap/__BayesWrap/libs/BayesWrap.so':
>                libR.so: cannot open shared object file: No such file or
>             directory
>             In addition: Warning message:
>             package 'BayesWrap' was built under R version 2.15.2
>             Error: package/namespace load failed for 'BayesWrap'
>             Execution halted
>
>             what does it means?
>
>             G.M.
>
>             Il 04/09/13 22:42, Prof Brian Ripley ha scritto:
>
>                 On 04/09/2013 19:58, Geoff Jentry wrote:
>
>                         Can you add some details?
>                         Suppose i have the package Model.tar.gz and my
>                         writable are is in
>                         user/area, what i have to do next to install the
>                         package?
>
>
>                     What I was picturing was something like this
>                     (forgive me if syntax
>                     isn't
>                     100%):
>
>                     mkdir user/area/myRLib
>                     R CMD INSTALL --library=user/area/myRLib Model.tar.gz
>
>                     and then in R:
>                     library(Model, lib.loc="user/area/myRLib")
>
>                     Note though Brian Ripley's response to me where he
>                     indicates that this
>                     is handled automatically.
>
>
>                 Yes,  install.packages("Model.tar.__gz") should suffice.
>
>
>                     -J
>
>                     ________________________________________________
>                     R-devel at r-project.org <mailto:R-devel at r-project.org>
>                     mailing list
>                     https://stat.ethz.ch/mailman/__listinfo/r-devel
>                     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>
>
>
>
>
>
>     --
>     Brian D. Ripley, ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>
>     Professor of Applied Statistics,
>     http://www.stats.ox.ac.uk/~__ripley/
>     <http://www.stats.ox.ac.uk/~ripley/>
>     University of Oxford,             Tel: +44 1865 272861
>     <tel:%2B44%201865%20272861> (self)
>     1 South Parks Road, +44 1865 272866 <tel:%2B44%201865%20272866> (PA)
>     Oxford OX1 3TG, UK                Fax: +44 1865 272595
>     <tel:%2B44%201865%20272595>
>
>     ________________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gianluca.mastrantonio at yahoo.it  Fri Sep  6 18:11:47 2013
From: gianluca.mastrantonio at yahoo.it (gianluca.mastrantonio at yahoo.it)
Date: Fri, 06 Sep 2013 18:11:47 +0200
Subject: [Rd] libR.so: cannot open shared object file
In-Reply-To: <CABWzF4XOMA3tCdxdqERF8LL8Y3WTc7vsxFrqUvzrWO+9EB+81g@mail.gmail.com>
References: <52264B2B.5020005@yahoo.it>
	<21030.20789.769106.335326@max.nulle.part>
	<52265436.9060800@yahoo.it>
	<alpine.DEB.2.00.1309031503300.30236@cardinals.dreamhost.com>
	<52266055.2000000@yahoo.it>
	<alpine.DEB.2.00.1309041156280.14841@cardinals.dreamhost.com>
	<52279B27.8060801@stats.ox.ac.uk> <522855F5.3040204@yahoo.it>
	<5228E964.9030406@yahoo.it> <5228EBBE.6080101@stats.ox.ac.uk>
	<CABWzF4XOMA3tCdxdqERF8LL8Y3WTc7vsxFrqUvzrWO+9EB+81g@mail.gmail.com>
Message-ID: <5229FEC3.9080707@yahoo.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130906/35d29f55/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep  6 20:20:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 14:20:16 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <52299D8F.1000805@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com>
Message-ID: <522A1CE0.2020203@gmail.com>

I have now put the code into a temporary package for testing; if anyone 
is interested, for a few days it will be downloadable from

fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz

This uses two functions:

fileSnapshot -- takes a snapshot
changedFiles -- compares two snapshots, or one snapshot to the current 
file system


Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Sep  6 21:46:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 15:46:54 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522A1CE0.2020203@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
Message-ID: <522A312E.3040608@gmail.com>

On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
> I have now put the code into a temporary package for testing; if anyone
> is interested, for a few days it will be downloadable from
>
> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz

Sorry, error in the URL.  It should be

http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz

(This time I tested it!  Thanks Scott for the heads-up.)

Duncan Murdoch

>
> This uses two functions:
>
> fileSnapshot -- takes a snapshot
> changedFiles -- compares two snapshots, or one snapshot to the current
> file system
>
>
> Duncan Murdoch


From peter.ruckdeschel at itwm.fraunhofer.de  Fri Sep  6 22:54:27 2013
From: peter.ruckdeschel at itwm.fraunhofer.de (Dr. Peter Ruckdeschel)
Date: Fri, 06 Sep 2013 22:54:27 +0200
Subject: [Rd] directives to explicitely exclude objects from import into
	namespaces
Message-ID: <522A4103.8000009@itwm.fraunhofer.de>

Hi,

recently R CMD check --as-cran has noticed some more issues with
package namespace imports with the recommended remedy to
use importFrom() and friends.

In my case, there was only a conflict restricted to some few imports,
while I would prefer to still import all the non-conflicting objects,
methods, and classes of the respective package namespace.

So would it be possible to have some new directives along the lines

import(<pkg>) ## importing the whole namespace of <pkg> in a first step
notimportFrom(<pkg>, <obj1>, <obj2>,....)
           ##  exclude <obj1>, <obj2>, ... again from the previous namespace import
           ## and, similarly,
notimportMethodsFrom(<pkg>, <meth1>, <meth2>,....)
notimportClassesFrom(<pkg>, <cls1>, <cls2>,....)

in the NAMESPACE file?

Otherwise the list of object, methods, classes to be explicitely imported
(in my case) got very long (and hence hard to maintain) -- much longer
than the list of items to be excluded from an import.

Or have I overseen some obvious, easier way to achieve this?

Best regards, Peter

-- 
Dr. habil. Peter Ruckdeschel, Abteilung Finanzmathematik, F3.17
Fraunhofer ITWM, Fraunhofer Platz 1, 67663 Kaiserslautern
Telefon:  +49 631/31600-4699   Fax:  +49 631/31600-5699
E-Mail :  peter.ruckdeschel at itwm.fraunhofer.de
http://www.itwm.fraunhofer.de/abteilungen/finanzmathematik/mitarbeiterinnen/mitarbeiter/dr-peter-ruckdeschel.html


From skostysh at princeton.edu  Sat Sep  7 01:40:14 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Fri, 6 Sep 2013 19:40:14 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522A312E.3040608@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
Message-ID: <CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>

On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>
>> I have now put the code into a temporary package for testing; if anyone
>> is interested, for a few days it will be downloadable from
>>
>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>
>
> Sorry, error in the URL.  It should be
>
> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz

Works well. A couple of things I noticed:

(1)
md5sum is being called on directories, which causes warnings. (If this
is not viewed as undesirable, please ignore the rest of this comment.)
Should this be the responsibility of the user (by passing arguments to
list.files)? In the example, changing
fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
to
fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
recursive=TRUE")

gets rid of the warnings. But perhaps the user just wants to exclude
directories for the md5sum calculations. This can't be controlled from
fileSnapshot.

Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
or file.info to exclude directories (and then fill in the directories
with NA)?

(2)
If I run example(changedFiles) several times, sometimes I get:

chngdF> changedFiles(snapshot)
File changes:
      mtime md5sum
file2  TRUE   TRUE

and other times I get:

chngdF> changedFiles(snapshot)
File changes:
      md5sum
file2   TRUE

I wonder why.

Scott

> sessionInfo()
R Under development (unstable) (2013-08-31 r63780)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] testpkg_1.0

loaded via a namespace (and not attached):
[1] tools_3.1.0
>


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From murdoch.duncan at gmail.com  Sat Sep  7 02:35:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 20:35:33 -0400
Subject: [Rd] directives to explicitely exclude objects from import into
 namespaces
In-Reply-To: <522A4103.8000009@itwm.fraunhofer.de>
References: <522A4103.8000009@itwm.fraunhofer.de>
Message-ID: <522A74D5.50705@gmail.com>

On 13-09-06 4:54 PM, Dr. Peter Ruckdeschel wrote:
> Hi,
>
> recently R CMD check --as-cran has noticed some more issues with
> package namespace imports with the recommended remedy to
> use importFrom() and friends.
>
> In my case, there was only a conflict restricted to some few imports,
> while I would prefer to still import all the non-conflicting objects,
> methods, and classes of the respective package namespace.
>
> So would it be possible to have some new directives along the lines
>
> import(<pkg>) ## importing the whole namespace of <pkg> in a first step
> notimportFrom(<pkg>, <obj1>, <obj2>,....)
>             ##  exclude <obj1>, <obj2>, ... again from the previous namespace import
>             ## and, similarly,
> notimportMethodsFrom(<pkg>, <meth1>, <meth2>,....)
> notimportClassesFrom(<pkg>, <cls1>, <cls2>,....)
>
> in the NAMESPACE file?
>
> Otherwise the list of object, methods, classes to be explicitely imported
> (in my case) got very long (and hence hard to maintain) -- much longer
> than the list of items to be excluded from an import.

This doesn't make sense to me.  How could it be easier to maintain a 
list over which you don't have control instead of one over which you do 
have control?

Duncan Murdoch


>
> Or have I overseen some obvious, easier way to achieve this?
>
> Best regards, Peter
>


From skostysh at princeton.edu  Sat Sep  7 02:38:29 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Fri, 6 Sep 2013 20:38:29 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
Message-ID: <CAE3=dme78rzE0zXxY8eFGsxfP0WcjuWyAFeTypLwVubmvWy0VQ@mail.gmail.com>

On Fri, Sep 6, 2013 at 7:40 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>
>>> I have now put the code into a temporary package for testing; if anyone
>>> is interested, for a few days it will be downloadable from
>>>
>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>
>>
>> Sorry, error in the URL.  It should be
>>
>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>
> Works well. A couple of things I noticed:
>
> (1)
> md5sum is being called on directories, which causes warnings. (If this
> is not viewed as undesirable, please ignore the rest of this comment.)
> Should this be the responsibility of the user (by passing arguments to
> list.files)? In the example, changing
> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
> to
> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
> recursive=TRUE")
>
> gets rid of the warnings. But perhaps the user just wants to exclude
> directories for the md5sum calculations. This can't be controlled from
> fileSnapshot.
>
> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
> or file.info to exclude directories (and then fill in the directories
> with NA)?
>
> (2)
> If I run example(changedFiles) several times, sometimes I get:
>
> chngdF> changedFiles(snapshot)
> File changes:
>       mtime md5sum
> file2  TRUE   TRUE
>
> and other times I get:
>
> chngdF> changedFiles(snapshot)
> File changes:
>       md5sum
> file2   TRUE
>
> I wonder why.

Putting the following in-between snapshot and writeBin in the example
leads to consistent output:

# allow for mtime to change
Sys.sleep(.1)

Scott

>
> Scott
>
>> sessionInfo()
> R Under development (unstable) (2013-08-31 r63780)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] testpkg_1.0
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
>>
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From murdoch.duncan at gmail.com  Sat Sep  7 02:40:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 20:40:18 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
Message-ID: <522A75F2.5060302@gmail.com>

On 13-09-06 7:40 PM, Scott Kostyshak wrote:
> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>
>>> I have now put the code into a temporary package for testing; if anyone
>>> is interested, for a few days it will be downloadable from
>>>
>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>
>>
>> Sorry, error in the URL.  It should be
>>
>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>
> Works well. A couple of things I noticed:
>
> (1)
> md5sum is being called on directories, which causes warnings. (If this
> is not viewed as undesirable, please ignore the rest of this comment.)
> Should this be the responsibility of the user (by passing arguments to
> list.files)? In the example, changing
> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
> to
> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
> recursive=TRUE")
>
> gets rid of the warnings. But perhaps the user just wants to exclude
> directories for the md5sum calculations. This can't be controlled from
> fileSnapshot.

I don't see the warnings, I just get NA values.  I'll try to see why 
there's a difference.  (One possibility is my platform (Windows); 
another is that I'm generally testing in R-patched and R-devel rather 
than the 3.0.1 release version.)  I would rather suppress the warnings 
than make the user avoid them.

>
> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
> or file.info to exclude directories (and then fill in the directories
> with NA)?
>
> (2)
> If I run example(changedFiles) several times, sometimes I get:
>
> chngdF> changedFiles(snapshot)
> File changes:
>        mtime md5sum
> file2  TRUE   TRUE
>
> and other times I get:
>
> chngdF> changedFiles(snapshot)
> File changes:
>        md5sum
> file2   TRUE
>
> I wonder why.

Sometimes the example runs so quickly that the new version has exactly 
the same modification time as the original.  That's the risk of the 
mtime check.  If you put a delay between, you'll get consistent results.

Duncan Murdoch

>
> Scott
>
>> sessionInfo()
> R Under development (unstable) (2013-08-31 r63780)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] testpkg_1.0
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
>>
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>


From kasperdanielhansen at gmail.com  Sat Sep  7 02:54:52 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 6 Sep 2013 20:54:52 -0400
Subject: [Rd] directives to explicitely exclude objects from import into
	namespaces
In-Reply-To: <522A74D5.50705@gmail.com>
References: <522A4103.8000009@itwm.fraunhofer.de> <522A74D5.50705@gmail.com>
Message-ID: <CAC2h7uvuqJQ4DdmKJA959pvG_SOKYceKjOb6eKh7Vz2_H-67cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130906/a8012958/attachment.pl>

From kmillar at google.com  Sat Sep  7 03:21:32 2013
From: kmillar at google.com (Karl Millar)
Date: Fri, 6 Sep 2013 18:21:32 -0700
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522A75F2.5060302@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
	<522A75F2.5060302@gmail.com>
Message-ID: <CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>

Hi Duncan,

I like the interface of this version a lot better, but there's still a
bunch of implementation details that need fixing:

* As previously mentioned, there are important cases where the mtime
values change in ways that this code doesn't detect.
* If the timestamp file (which is usually in the temp directory) gets
deleted (which can happen after a moderate amount of time of
inactivity on some systems), then the file_test('-nt', ...) will
always return false, even if the file has changed.
* If files get added or deleted between the two calls to list.files in
fileSnapshot, it will fail with an error.
* If the path is on a remote file system, tempdir is local, and
there's significant clock skew, then you can get incorrect results.

Unfortunately, these aren't just theoretical scenarios -- I've had the
misfortune to run up against all of them in the past.

I've attached code that's loosely based on your implementation that
solves these problems AFAICT.  Alternatively, Hadley's code handles
all of these correctly, with the exception that compare_state doesn't
handle the case where safe_digest returns NA very well.

Regards,

Karl

On Fri, Sep 6, 2013 at 5:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-09-06 7:40 PM, Scott Kostyshak wrote:
>>
>> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>>
>>>>
>>>> I have now put the code into a temporary package for testing; if anyone
>>>> is interested, for a few days it will be downloadable from
>>>>
>>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>
>>>
>>>
>>> Sorry, error in the URL.  It should be
>>>
>>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>
>>
>> Works well. A couple of things I noticed:
>>
>> (1)
>> md5sum is being called on directories, which causes warnings. (If this
>> is not viewed as undesirable, please ignore the rest of this comment.)
>> Should this be the responsibility of the user (by passing arguments to
>> list.files)? In the example, changing
>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
>> to
>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
>> recursive=TRUE")
>>
>> gets rid of the warnings. But perhaps the user just wants to exclude
>> directories for the md5sum calculations. This can't be controlled from
>> fileSnapshot.
>
>
> I don't see the warnings, I just get NA values.  I'll try to see why there's
> a difference.  (One possibility is my platform (Windows); another is that
> I'm generally testing in R-patched and R-devel rather than the 3.0.1 release
> version.)  I would rather suppress the warnings than make the user avoid
> them.
>
>
>>
>> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
>> or file.info to exclude directories (and then fill in the directories
>> with NA)?
>>
>> (2)
>> If I run example(changedFiles) several times, sometimes I get:
>>
>> chngdF> changedFiles(snapshot)
>> File changes:
>>        mtime md5sum
>> file2  TRUE   TRUE
>>
>> and other times I get:
>>
>> chngdF> changedFiles(snapshot)
>> File changes:
>>        md5sum
>> file2   TRUE
>>
>> I wonder why.
>
>
> Sometimes the example runs so quickly that the new version has exactly the
> same modification time as the original.  That's the risk of the mtime check.
> If you put a delay between, you'll get consistent results.
>
> Duncan Murdoch
>
>
>>
>> Scott
>>
>>> sessionInfo()
>>
>> R Under development (unstable) (2013-08-31 r63780)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] testpkg_1.0
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.0
>>>
>>>
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From murdoch.duncan at gmail.com  Sat Sep  7 04:03:00 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 22:03:00 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
	<522A75F2.5060302@gmail.com>
	<CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>
Message-ID: <522A8954.3030506@gmail.com>

On 13-09-06 9:21 PM, Karl Millar wrote:
> Hi Duncan,
>
> I like the interface of this version a lot better, but there's still a
> bunch of implementation details that need fixing:
>
> * As previously mentioned, there are important cases where the mtime
> values change in ways that this code doesn't detect.
> * If the timestamp file (which is usually in the temp directory) gets
> deleted (which can happen after a moderate amount of time of
> inactivity on some systems), then the file_test('-nt', ...) will
> always return false, even if the file has changed.

If that happened without user intervention, I think it would break other 
things in R -- the temp directory is supposed to last for the whole 
session.  But I should be checking anyway.

> * If files get added or deleted between the two calls to list.files in
> fileSnapshot, it will fail with an error.

Yours won't work if path contains more than one directory.  This is 
probably a reasonable restriction, but it's inconsistent with 
list.files, so I'd like to avoid it if I can find a way.

Duncan Murdoch

> * If the path is on a remote file system, tempdir is local, and
> there's significant clock skew, then you can get incorrect results.
>
> Unfortunately, these aren't just theoretical scenarios -- I've had the
> misfortune to run up against all of them in the past.
>
> I've attached code that's loosely based on your implementation that
> solves these problems AFAICT.  Alternatively, Hadley's code handles
> all of these correctly, with the exception that compare_state doesn't
> handle the case where safe_digest returns NA very well.
>
> Regards,
>
> Karl
>
> On Fri, Sep 6, 2013 at 5:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-09-06 7:40 PM, Scott Kostyshak wrote:
>>>
>>> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>>
>>>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>>>
>>>>>
>>>>> I have now put the code into a temporary package for testing; if anyone
>>>>> is interested, for a few days it will be downloadable from
>>>>>
>>>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>>
>>>>
>>>>
>>>> Sorry, error in the URL.  It should be
>>>>
>>>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>
>>>
>>> Works well. A couple of things I noticed:
>>>
>>> (1)
>>> md5sum is being called on directories, which causes warnings. (If this
>>> is not viewed as undesirable, please ignore the rest of this comment.)
>>> Should this be the responsibility of the user (by passing arguments to
>>> list.files)? In the example, changing
>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
>>> to
>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
>>> recursive=TRUE")
>>>
>>> gets rid of the warnings. But perhaps the user just wants to exclude
>>> directories for the md5sum calculations. This can't be controlled from
>>> fileSnapshot.
>>
>>
>> I don't see the warnings, I just get NA values.  I'll try to see why there's
>> a difference.  (One possibility is my platform (Windows); another is that
>> I'm generally testing in R-patched and R-devel rather than the 3.0.1 release
>> version.)  I would rather suppress the warnings than make the user avoid
>> them.
>>
>>
>>>
>>> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
>>> or file.info to exclude directories (and then fill in the directories
>>> with NA)?
>>>
>>> (2)
>>> If I run example(changedFiles) several times, sometimes I get:
>>>
>>> chngdF> changedFiles(snapshot)
>>> File changes:
>>>         mtime md5sum
>>> file2  TRUE   TRUE
>>>
>>> and other times I get:
>>>
>>> chngdF> changedFiles(snapshot)
>>> File changes:
>>>         md5sum
>>> file2   TRUE
>>>
>>> I wonder why.
>>
>>
>> Sometimes the example runs so quickly that the new version has exactly the
>> same modification time as the original.  That's the risk of the mtime check.
>> If you put a delay between, you'll get consistent results.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> Scott
>>>
>>>> sessionInfo()
>>>
>>> R Under development (unstable) (2013-08-31 r63780)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>
>>> locale:
>>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] testpkg_1.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.1.0
>>>>
>>>>
>>>
>>>
>>> --
>>> Scott Kostyshak
>>> Economics PhD Candidate
>>> Princeton University
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kmillar at google.com  Sat Sep  7 05:07:36 2013
From: kmillar at google.com (Karl Millar)
Date: Fri, 6 Sep 2013 20:07:36 -0700
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522A8954.3030506@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
	<522A75F2.5060302@gmail.com>
	<CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>
	<522A8954.3030506@gmail.com>
Message-ID: <CABz6aZdqFLG4G_kMMd8Rji+c2YFtoL=NtX5N_Ux0sjRJa89p=A@mail.gmail.com>

On Fri, Sep 6, 2013 at 7:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-09-06 9:21 PM, Karl Millar wrote:
>>
>> Hi Duncan,
>>
>> I like the interface of this version a lot better, but there's still a
>> bunch of implementation details that need fixing:
>>
>> * As previously mentioned, there are important cases where the mtime
>> values change in ways that this code doesn't detect.
>> * If the timestamp file (which is usually in the temp directory) gets
>> deleted (which can happen after a moderate amount of time of
>> inactivity on some systems), then the file_test('-nt', ...) will
>> always return false, even if the file has changed.
>
>
> If that happened without user intervention, I think it would break other
> things in R -- the temp directory is supposed to last for the whole session.
> But I should be checking anyway.

Yes, it does break other things in R -- my experience has been that
the help system seems to be the one that is impacted the most by this.
 FWIW, I've never seen the entire R temp directory deleted, just
individual files and subdirectories in it, but even that probably
depends on how the machine is configured.  I suspect only a few users
ever notice this, but my R use is probably somewhat anomalous and I
think it only happens to R sessions that I haven't used for a few
days.

>> * If files get added or deleted between the two calls to list.files in
>> fileSnapshot, it will fail with an error.
>
>
> Yours won't work if path contains more than one directory.  This is probably
> a reasonable restriction, but it's inconsistent with list.files, so I'd like
> to avoid it if I can find a way.

I'm currently unsure what the behaviour when comparing snapshots with
multiple directories should be.

Presumably we should have the property that (horribly abusing notation
for succinctness):
      compareSnapshots(c(a1, a2),  c(a1, a2))
is the same as concatenating (in some form)
      compareSnapshots(a1, a1) and compareSnapshots(a2, a2)
and there's a bunch of ways we could concatenate -- we could return a
list of results, or a single result where each of the 'added, deleted,
modified' fields are a list, or where we concatenate the 'added,
deleted, modified' fields together into three simple vectors.
Concatenating the vectors together like this is appealing, but unless
you're using the full names, it doesn't include the information of
which directory the changes are in, and using the full names doesn't
work in the case where you're comparing different sets of directories,
e.g. compareSnapshots(c(a1, a2), c(b1, b2)), where there is no
sensible choice for a full name.  The list options don't have this
problem, but are harder to work with, particularly for the common case
where there's only a single directory.  You'd also have to be somewhat
careful with filenames that occur in both directories.

Maybe I'm just being dense, but I don't see a way to do this thats
clear, easy to use and wouldn't confuse users at the moment.

Karl

> Duncan Murdoch
>
>
>> * If the path is on a remote file system, tempdir is local, and
>> there's significant clock skew, then you can get incorrect results.
>>
>> Unfortunately, these aren't just theoretical scenarios -- I've had the
>> misfortune to run up against all of them in the past.
>>
>> I've attached code that's loosely based on your implementation that
>> solves these problems AFAICT.  Alternatively, Hadley's code handles
>> all of these correctly, with the exception that compare_state doesn't
>> handle the case where safe_digest returns NA very well.
>>
>> Regards,
>>
>> Karl
>>
>> On Fri, Sep 6, 2013 at 5:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> On 13-09-06 7:40 PM, Scott Kostyshak wrote:
>>>>
>>>>
>>>> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com>
>>>> wrote:
>>>>>
>>>>>
>>>>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> I have now put the code into a temporary package for testing; if
>>>>>> anyone
>>>>>> is interested, for a few days it will be downloadable from
>>>>>>
>>>>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Sorry, error in the URL.  It should be
>>>>>
>>>>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>>
>>>>
>>>>
>>>> Works well. A couple of things I noticed:
>>>>
>>>> (1)
>>>> md5sum is being called on directories, which causes warnings. (If this
>>>> is not viewed as undesirable, please ignore the rest of this comment.)
>>>> Should this be the responsibility of the user (by passing arguments to
>>>> list.files)? In the example, changing
>>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
>>>> to
>>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
>>>> recursive=TRUE")
>>>>
>>>> gets rid of the warnings. But perhaps the user just wants to exclude
>>>> directories for the md5sum calculations. This can't be controlled from
>>>> fileSnapshot.
>>>
>>>
>>>
>>> I don't see the warnings, I just get NA values.  I'll try to see why
>>> there's
>>> a difference.  (One possibility is my platform (Windows); another is that
>>> I'm generally testing in R-patched and R-devel rather than the 3.0.1
>>> release
>>> version.)  I would rather suppress the warnings than make the user avoid
>>> them.
>>>
>>>
>>>>
>>>> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
>>>> or file.info to exclude directories (and then fill in the directories
>>>> with NA)?
>>>>
>>>> (2)
>>>> If I run example(changedFiles) several times, sometimes I get:
>>>>
>>>> chngdF> changedFiles(snapshot)
>>>> File changes:
>>>>         mtime md5sum
>>>> file2  TRUE   TRUE
>>>>
>>>> and other times I get:
>>>>
>>>> chngdF> changedFiles(snapshot)
>>>> File changes:
>>>>         md5sum
>>>> file2   TRUE
>>>>
>>>> I wonder why.
>>>
>>>
>>>
>>> Sometimes the example runs so quickly that the new version has exactly
>>> the
>>> same modification time as the original.  That's the risk of the mtime
>>> check.
>>> If you put a delay between, you'll get consistent results.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>>
>>>> Scott
>>>>
>>>>> sessionInfo()
>>>>
>>>>
>>>> R Under development (unstable) (2013-08-31 r63780)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>
>>>> locale:
>>>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] testpkg_1.0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.1.0
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> Scott Kostyshak
>>>> Economics PhD Candidate
>>>> Princeton University
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From groemping at bht-berlin.de  Sat Sep  7 14:48:16 2013
From: groemping at bht-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Sat, 7 Sep 2013 05:48:16 -0700 (PDT)
Subject: [Rd] directives to explicitely exclude objects from import into
 namespaces
In-Reply-To: <CAC2h7uvuqJQ4DdmKJA959pvG_SOKYceKjOb6eKh7Vz2_H-67cg@mail.gmail.com>
References: <522A4103.8000009@itwm.fraunhofer.de> <522A74D5.50705@gmail.com>
	<CAC2h7uvuqJQ4DdmKJA959pvG_SOKYceKjOb6eKh7Vz2_H-67cg@mail.gmail.com>
Message-ID: <1378558096101-4675594.post@n4.nabble.com>

I also second Peter's proposal. I think that it is particularly helpful to
save time for maintainers of packages that were developed a longer time ago.
When writing new packages, it is relatively easy to keep track of which
functions from which packages need to be imported; when maintaining older
code, working this out can be a lot of work.

Best, Ulrike



--
View this message in context: http://r.789695.n4.nabble.com/directives-to-explicitely-exclude-objects-from-import-into-namespaces-tp4675564p4675594.html
Sent from the R devel mailing list archive at Nabble.com.


From h.wickham at gmail.com  Sat Sep  7 21:50:51 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 7 Sep 2013 14:50:51 -0500
Subject: [Rd] directives to explicitely exclude objects from import into
	namespaces
In-Reply-To: <1378558096101-4675594.post@n4.nabble.com>
References: <522A4103.8000009@itwm.fraunhofer.de> <522A74D5.50705@gmail.com>
	<CAC2h7uvuqJQ4DdmKJA959pvG_SOKYceKjOb6eKh7Vz2_H-67cg@mail.gmail.com>
	<1378558096101-4675594.post@n4.nabble.com>
Message-ID: <CABdHhvEfjjFXKnNN95skJK2oD-tp6izhr5FsvPrX5A=o8zWxrA@mail.gmail.com>

It's difficult to do by hand, but it's not too hard to automate - take
a look at https://github.com/hadley/roxygen3/blob/master/R/auto-imports.r.
It's part of roxygen3, but the code is relatively straighforward and
doesn't depend on much else in the package.

Hadley

On Sat, Sep 7, 2013 at 7:48 AM, Ulrike Gr?mping <groemping at bht-berlin.de> wrote:
> I also second Peter's proposal. I think that it is particularly helpful to
> save time for maintainers of packages that were developed a longer time ago.
> When writing new packages, it is relatively easy to keep track of which
> functions from which packages need to be imported; when maintaining older
> code, working this out can be a lot of work.
>
> Best, Ulrike
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/directives-to-explicitely-exclude-objects-from-import-into-namespaces-tp4675564p4675594.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From jon at thon.cc  Sun Sep  8 13:35:10 2013
From: jon at thon.cc (Jonathon Love)
Date: Sun, 08 Sep 2013 13:35:10 +0200
Subject: [Rd] building R under mingw 4.7
Message-ID: <522C60EE.6030802@thon.cc>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hi,

We're developing a Qt application that links against R using Rcpp.

Qt5 requires Mingw 4.7, where as R seems to require Mingw 4.6. This
makes linking against R problematic.

Has anyone successfully built R with Mingw 4.7 (or 4.8)? Is this
possible? Is this something being worked on?

with thanks

Jonathon

- -- 

don't use google, use duckduckgo instead:

https://duckduckgo.com/supportus.html





-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
Comment: GPGTools - https://gpgtools.org
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQIcBAEBCgAGBQJSLGDuAAoJEH277gjmPGDYVc8QALEu2p+jF/i5Xw9nzT507/5F
0zDvuvCqgjwLs14JRC8H6P5uyJB914qmYXYwwpGF0XhzZG80EyZyYRGKeeoGXdXg
zrA0LCf9v518GHdhqfv7B3tZKdajBlUkSf6SgEQUArviChIo/laR2UBFqvj0EvVF
U/tsO3EGirSu+p5KGR6bttmTJWXR/x+cRGxP2bwne0EbRYdKMEfdSfnT/bRpmydl
VtUI5kzH7ZJ72ARTI43SRZFCTZQT+lmPk9h4TvdwipFyJjZG1aCoMOAnhwxOzKZ6
2j+cGv221V+8w5Bw+3u6TOlFd6EG8Mh5MaU2Ct0wHDTsgWXomzJMX5IM4GbTF0ms
mYmOyo+j93sGvO0b3C0mIdOLIB99m6ZJ6DrwemYTMZENnAQiCirYMinP/7yl7ut7
6ciRSxDB0B19qTOlSFN007hCDqzwddv5f0aDyQJIy3WNklwWAwAaN1HKcxTqJAVz
CD4tttB0tKyvXILG15RI9ksKLxJyFX41LrUp6V+19HMmymN5GmlMO63pZeHAH1hw
cX5UdW7TQb+GZ0RZKZjcESlPBflxD6GtYP+wjtfb7tStyLiKx51wsYp7/hsFzDzf
AHc8gXwY7DfQTV17m+VuHE4k8+4FGD+wuvD7CotrZRZJ992pewxlJl9/IZD81+zk
fmf6A5soIC+2lq6v7ct1
=1o1e
-----END PGP SIGNATURE-----


From ripley at stats.ox.ac.uk  Sun Sep  8 16:11:54 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 08 Sep 2013 15:11:54 +0100
Subject: [Rd] building R under mingw 4.7
In-Reply-To: <522C60EE.6030802@thon.cc>
References: <522C60EE.6030802@thon.cc>
Message-ID: <522C85AA.6050603@stats.ox.ac.uk>

On 08/09/2013 12:35, Jonathon Love wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> Hi,
>
> We're developing a Qt application that links against R using Rcpp.

We are guessing on Windows, not mentioned here.

> Qt5 requires Mingw 4.7, where as R seems to require Mingw 4.6. This
 > makes linking against R problematic.

AFAICS there are no such versions, and in any case R on Windows supports 
Mingw-w64 (not Mingw which is a separate project).

'R' does not require any particular compiler: you can compile your 
application with whatever you like, and compile R in the same way.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sun Sep  8 16:55:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 08 Sep 2013 10:55:41 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <CABz6aZdqFLG4G_kMMd8Rji+c2YFtoL=NtX5N_Ux0sjRJa89p=A@mail.gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
	<522A75F2.5060302@gmail.com>
	<CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>
	<522A8954.3030506@gmail.com>
	<CABz6aZdqFLG4G_kMMd8Rji+c2YFtoL=NtX5N_Ux0sjRJa89p=A@mail.gmail.com>
Message-ID: <522C8FED.9070406@gmail.com>

On 13-09-06 11:07 PM, Karl Millar wrote:
> On Fri, Sep 6, 2013 at 7:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-09-06 9:21 PM, Karl Millar wrote:
>>>
>>> Hi Duncan,
>>>
>>> I like the interface of this version a lot better, but there's still a
>>> bunch of implementation details that need fixing:
>>>
>>> * As previously mentioned, there are important cases where the mtime
>>> values change in ways that this code doesn't detect.
>>> * If the timestamp file (which is usually in the temp directory) gets
>>> deleted (which can happen after a moderate amount of time of
>>> inactivity on some systems), then the file_test('-nt', ...) will
>>> always return false, even if the file has changed.
>>
>>
>> If that happened without user intervention, I think it would break other
>> things in R -- the temp directory is supposed to last for the whole session.
>> But I should be checking anyway.
>
> Yes, it does break other things in R -- my experience has been that
> the help system seems to be the one that is impacted the most by this.
>   FWIW, I've never seen the entire R temp directory deleted, just
> individual files and subdirectories in it, but even that probably
> depends on how the machine is configured.  I suspect only a few users
> ever notice this, but my R use is probably somewhat anomalous and I
> think it only happens to R sessions that I haven't used for a few
> days.

I use Windows and never see this; deleting temp files is up to me, not 
to the system.  But my understanding was the *nix systems should only 
clean up /tmp on restart, and I don't think an R session will survive a 
restart.

However, you have convinced me that the use of the timestamp file is not 
beneficial enough to be the default.  I'll leave it as an option, but 
add warnings that it might be unreliable.

>
>>> * If files get added or deleted between the two calls to list.files in
>>> fileSnapshot, it will fail with an error.
>>
>>
>> Yours won't work if path contains more than one directory.  This is probably
>> a reasonable restriction, but it's inconsistent with list.files, so I'd like
>> to avoid it if I can find a way.
>
> I'm currently unsure what the behaviour when comparing snapshots with
> multiple directories should be.
>
> Presumably we should have the property that (horribly abusing notation
> for succinctness):
>        compareSnapshots(c(a1, a2),  c(a1, a2))
> is the same as concatenating (in some form)
>        compareSnapshots(a1, a1) and compareSnapshots(a2, a2)
> and there's a bunch of ways we could concatenate -- we could return a
> list of results, or a single result where each of the 'added, deleted,
> modified' fields are a list, or where we concatenate the 'added,
> deleted, modified' fields together into three simple vectors.
> Concatenating the vectors together like this is appealing, but unless
> you're using the full names, it doesn't include the information of
> which directory the changes are in, and using the full names doesn't
> work in the case where you're comparing different sets of directories,
> e.g. compareSnapshots(c(a1, a2), c(b1, b2)), where there is no
> sensible choice for a full name.  The list options don't have this
> problem, but are harder to work with, particularly for the common case
> where there's only a single directory.  You'd also have to be somewhat
> careful with filenames that occur in both directories.
>
> Maybe I'm just being dense, but I don't see a way to do this thats
> clear, easy to use and wouldn't confuse users at the moment.

The way I've done this is to require full.names when multiple dirs are 
on the path.  I've reduced it to one list.files() call per dir, by 
iterating over the path variable and using your approach of calling it 
with full.names = FALSE, then adding the dir if necessary.

I haven't adopted your change that forces comparison of only size and 
mtime from file.info.  I don't see a big cost in storing whatever 
file.info returns (which is system dependent; on Windows I don't see the 
user and group related columns; on Unix I don't see the exe column).
Users might want to detect changes to anything there, and I shouldn't 
make it harder for them.

I've also kept the special-casing of md5sum; it really needs to be 
wrapped in suppressWarnings() (on Unix only).  And I've kept the options 
to specify what changedFiles checks among the file.info columns; I can 
see that you might want a snapshot with everything, but sometimes only 
want to be told about changes in a subset of the attributes.

I've uploaded 
<http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.1.tar.gz> if 
anyone is interested.

Duncan Murdoch

>
> Karl
>
>> Duncan Murdoch
>>
>>
>>> * If the path is on a remote file system, tempdir is local, and
>>> there's significant clock skew, then you can get incorrect results.
>>>
>>> Unfortunately, these aren't just theoretical scenarios -- I've had the
>>> misfortune to run up against all of them in the past.
>>>
>>> I've attached code that's loosely based on your implementation that
>>> solves these problems AFAICT.  Alternatively, Hadley's code handles
>>> all of these correctly, with the exception that compare_state doesn't
>>> handle the case where safe_digest returns NA very well.
>>>
>>> Regards,
>>>
>>> Karl
>>>
>>> On Fri, Sep 6, 2013 at 5:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>>
>>>> On 13-09-06 7:40 PM, Scott Kostyshak wrote:
>>>>>
>>>>>
>>>>> On Fri, Sep 6, 2013 at 3:46 PM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>>
>>>>>> On 06/09/2013 2:20 PM, Duncan Murdoch wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I have now put the code into a temporary package for testing; if
>>>>>>> anyone
>>>>>>> is interested, for a few days it will be downloadable from
>>>>>>>
>>>>>>> fisher.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Sorry, error in the URL.  It should be
>>>>>>
>>>>>> http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.0.tar.gz
>>>>>
>>>>>
>>>>>
>>>>> Works well. A couple of things I noticed:
>>>>>
>>>>> (1)
>>>>> md5sum is being called on directories, which causes warnings. (If this
>>>>> is not viewed as undesirable, please ignore the rest of this comment.)
>>>>> Should this be the responsibility of the user (by passing arguments to
>>>>> list.files)? In the example, changing
>>>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE)
>>>>> to
>>>>> fileSnapshot(dir, file.info=TRUE, md5sum=TRUE, include.dirs=FALSE,
>>>>> recursive=TRUE")
>>>>>
>>>>> gets rid of the warnings. But perhaps the user just wants to exclude
>>>>> directories for the md5sum calculations. This can't be controlled from
>>>>> fileSnapshot.
>>>>
>>>>
>>>>
>>>> I don't see the warnings, I just get NA values.  I'll try to see why
>>>> there's
>>>> a difference.  (One possibility is my platform (Windows); another is that
>>>> I'm generally testing in R-patched and R-devel rather than the 3.0.1
>>>> release
>>>> version.)  I would rather suppress the warnings than make the user avoid
>>>> them.
>>>>
>>>>
>>>>>
>>>>> Or, should the "if (md5sum)" chunk subset "fullnames" using file_test
>>>>> or file.info to exclude directories (and then fill in the directories
>>>>> with NA)?
>>>>>
>>>>> (2)
>>>>> If I run example(changedFiles) several times, sometimes I get:
>>>>>
>>>>> chngdF> changedFiles(snapshot)
>>>>> File changes:
>>>>>          mtime md5sum
>>>>> file2  TRUE   TRUE
>>>>>
>>>>> and other times I get:
>>>>>
>>>>> chngdF> changedFiles(snapshot)
>>>>> File changes:
>>>>>          md5sum
>>>>> file2   TRUE
>>>>>
>>>>> I wonder why.
>>>>
>>>>
>>>>
>>>> Sometimes the example runs so quickly that the new version has exactly
>>>> the
>>>> same modification time as the original.  That's the risk of the mtime
>>>> check.
>>>> If you put a delay between, you'll get consistent results.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>>>
>>>>> Scott
>>>>>
>>>>>> sessionInfo()
>>>>>
>>>>>
>>>>> R Under development (unstable) (2013-08-31 r63780)
>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>
>>>>> locale:
>>>>>     [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>>     [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>>     [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>>     [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>>     [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> other attached packages:
>>>>> [1] testpkg_1.0
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tools_3.1.0
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Scott Kostyshak
>>>>> Economics PhD Candidate
>>>>> Princeton University
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From skostysh at princeton.edu  Mon Sep  9 02:31:07 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sun, 8 Sep 2013 20:31:07 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522C8FED.9070406@gmail.com>
References: <522773AC.3030609@gmail.com>
	<CABz6aZeM3nv1fievjjvXdQ5p+xcD775d1xqCHNjojWn03Ay9Og@mail.gmail.com>
	<5227DA21.8000202@gmail.com>
	<CABz6aZcU1M4hie_-tRORoQmxtxsQ4uCfuxx1=FdTNn6QE6br_w@mail.gmail.com>
	<52299D8F.1000805@gmail.com> <522A1CE0.2020203@gmail.com>
	<522A312E.3040608@gmail.com>
	<CAE3=dmfoDtzNTwFgvn4pZ0b-cdsJVKJPDO8rtBxqJQbfdEHw-w@mail.gmail.com>
	<522A75F2.5060302@gmail.com>
	<CABz6aZe4RpPUjbv6u_OGFJ_Nwx6Es2hYYs1O_AxyJT=yQs0U+A@mail.gmail.com>
	<522A8954.3030506@gmail.com>
	<CABz6aZdqFLG4G_kMMd8Rji+c2YFtoL=NtX5N_Ux0sjRJa89p=A@mail.gmail.com>
	<522C8FED.9070406@gmail.com>
Message-ID: <CAE3=dmfWgg4v8Uc3e5GvdD9HVMFHRWdu8TRwnfZG6HvSP0dYgQ@mail.gmail.com>

On Sun, Sep 8, 2013 at 10:55 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-09-06 11:07 PM, Karl Millar wrote:
>>
>> On Fri, Sep 6, 2013 at 7:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> On 13-09-06 9:21 PM, Karl Millar wrote:
>>>>
>>>>
>>>> Hi Duncan,
>>>>
>>>> I like the interface of this version a lot better, but there's still a
>>>> bunch of implementation details that need fixing:
>>>>
>>>> * As previously mentioned, there are important cases where the mtime
>>>> values change in ways that this code doesn't detect.
>>>> * If the timestamp file (which is usually in the temp directory) gets
>>>> deleted (which can happen after a moderate amount of time of
>>>> inactivity on some systems), then the file_test('-nt', ...) will
>>>> always return false, even if the file has changed.
>>>
>>>
>>>
>>> If that happened without user intervention, I think it would break other
>>> things in R -- the temp directory is supposed to last for the whole
>>> session.
>>> But I should be checking anyway.
>>
>>
>> Yes, it does break other things in R -- my experience has been that
>> the help system seems to be the one that is impacted the most by this.
>>   FWIW, I've never seen the entire R temp directory deleted, just
>> individual files and subdirectories in it, but even that probably
>> depends on how the machine is configured.  I suspect only a few users
>> ever notice this, but my R use is probably somewhat anomalous and I
>> think it only happens to R sessions that I haven't used for a few
>> days.
>
>
> I use Windows and never see this; deleting temp files is up to me, not to
> the system.  But my understanding was the *nix systems should only clean up
> /tmp on restart, and I don't think an R session will survive a restart.
>
> However, you have convinced me that the use of the timestamp file is not
> beneficial enough to be the default.  I'll leave it as an option, but add
> warnings that it might be unreliable.
>
>
>>
>>>> * If files get added or deleted between the two calls to list.files in
>>>> fileSnapshot, it will fail with an error.
>>>
>>>
>>>
>>> Yours won't work if path contains more than one directory.  This is
>>> probably
>>> a reasonable restriction, but it's inconsistent with list.files, so I'd
>>> like
>>> to avoid it if I can find a way.
>>
>>
>> I'm currently unsure what the behaviour when comparing snapshots with
>> multiple directories should be.
>>
>> Presumably we should have the property that (horribly abusing notation
>> for succinctness):
>>        compareSnapshots(c(a1, a2),  c(a1, a2))
>> is the same as concatenating (in some form)
>>        compareSnapshots(a1, a1) and compareSnapshots(a2, a2)
>> and there's a bunch of ways we could concatenate -- we could return a
>> list of results, or a single result where each of the 'added, deleted,
>> modified' fields are a list, or where we concatenate the 'added,
>> deleted, modified' fields together into three simple vectors.
>> Concatenating the vectors together like this is appealing, but unless
>> you're using the full names, it doesn't include the information of
>> which directory the changes are in, and using the full names doesn't
>> work in the case where you're comparing different sets of directories,
>> e.g. compareSnapshots(c(a1, a2), c(b1, b2)), where there is no
>> sensible choice for a full name.  The list options don't have this
>> problem, but are harder to work with, particularly for the common case
>> where there's only a single directory.  You'd also have to be somewhat
>> careful with filenames that occur in both directories.
>>
>> Maybe I'm just being dense, but I don't see a way to do this thats
>> clear, easy to use and wouldn't confuse users at the moment.
>
>
> The way I've done this is to require full.names when multiple dirs are on
> the path.  I've reduced it to one list.files() call per dir, by iterating
> over the path variable and using your approach of calling it with full.names
> = FALSE, then adding the dir if necessary.
>
> I haven't adopted your change that forces comparison of only size and mtime
> from file.info.  I don't see a big cost in storing whatever file.info
> returns (which is system dependent; on Windows I don't see the user and
> group related columns; on Unix I don't see the exe column).
> Users might want to detect changes to anything there, and I shouldn't make
> it harder for them.
>
> I've also kept the special-casing of md5sum; it really needs to be wrapped
> in suppressWarnings() (on Unix only).  And I've kept the options to specify
> what changedFiles checks among the file.info columns; I can see that you
> might want a snapshot with everything, but sometimes only want to be told
> about changes in a subset of the attributes.
>
> I've uploaded
> <http://www.stats.uwo.ca/faculty/murdoch/temp/testpkg_1.1.tar.gz> if anyone
> is interested.

Works well.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From skostysh at princeton.edu  Mon Sep  9 09:00:24 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Mon, 9 Sep 2013 03:00:24 -0400
Subject: [Rd] tools::md5sum(directory) behavior different on Windows vs. Unix
Message-ID: <CAE3=dmcMRCFCH1hdgLhwdjxQ6J+-UPZXXcpL2Za=99_5WnrtNw@mail.gmail.com>

tools::md5sum gives a warning if it receives a directory as an
argument on Unix but not on Windows.

>From what I understand, this happens because in Windows a directory is
not treated as a file so fopen returns NULL. Then, NA is returned
without a warning. On Unix, a directory is treated as a file so fopen
does not return NULL so md5 is run and fails, leading to a warning.

This is a good opportunity for me to understand further (in addition
to [1] and the many places where OS special cases are mentioned) in
which cases R tries to behave the same on Windows as on Unix and in
which cases it allows for differences (in this case, a warning vs. no
warning). For example, it would be straightforward to create a patch
that would lead to the same behavior in this case. tools::md5sum could
either issue a warning for each argument that is a directory or it
could issue no warning (consistent with file.info). Would either patch
be considered?

Or is this difference encouraged because the concept of a file is
different on Unix than on Windows?

Scott

[1] http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What-should-I-expect-to-behave-differently-from-the-Unix-version


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From nalimilan at club.fr  Mon Sep  9 10:49:21 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 09 Sep 2013 10:49:21 +0200
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
Message-ID: <1378716561.5065.29.camel@milan>

Hi!

I experience an error with an invalid UTF-8 character passed to
gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
default) no error happens. (The character itself was read from an
invalid HTML file.) Illustration of the error:

gsub("a", "", "\U3e3965", perl=FALSE)
# [1] "\U3e3965"
gsub("a", "", "\U3e3965", perl=TRUE)
# Error in gsub("a", "", "\U3e3965", perl = TRUE) : 
#   input string 1 is invalid UTF-8


The error message in the second command seems to come from
src/main/grep.c:1640 (in do_gsub):
if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);

utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
described in src/extra/pcre/pcre_valid_utf8.c.



Even more problematic/interesting is the fact that iconv() does not
consider the above character as invalid, as it does not replace it when
using the sub argument. 
> iconv("a\U3e3965", sub="")
[1] "a\U003e3965"

On the contrary, an invalid sequence such as \xff is substituted:
iconv("a\xff", sub="")
# [1] "a"

This makes it difficult to sanitize the string before passing it to
gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
and where. Should iconv() and PCRE be made to agree on the definition of
an invalid UTF-8 sequence?


Regards


From nalimilan at club.fr  Mon Sep  9 11:00:27 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 09 Sep 2013 11:00:27 +0200
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
In-Reply-To: <1378716561.5065.29.camel@milan>
References: <1378716561.5065.29.camel@milan>
Message-ID: <1378717227.5065.32.camel@milan>

...and of course I forgot to add relevant information. This is with
Fedora 19, R 3.0.1 and a UTF-8 locale.

On Windows 7 the problem does not appear, i.e. the gsub(perl=TRUE) call
does not generate any error and \U3e3965 prints a Chinese character
(AFAICT).


R version 3.0.1 (2013-05-16)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=fr_FR.utf8       LC_NUMERIC=C             
 [3] LC_TIME=fr_FR.utf8        LC_COLLATE=fr_FR.utf8    
 [5] LC_MONETARY=fr_FR.utf8    LC_MESSAGES=fr_FR.utf8   
 [7] LC_PAPER=C                LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=fr_FR.utf8 LC_IDENTIFICATION=C      



Le lundi 09 septembre 2013 ? 10:49 +0200, Milan Bouchet-Valat a ?crit :
> Hi!
> 
> I experience an error with an invalid UTF-8 character passed to
> gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
> default) no error happens. (The character itself was read from an
> invalid HTML file.) Illustration of the error:
> 
> gsub("a", "", "\U3e3965", perl=FALSE)
> # [1] "\U3e3965"
> gsub("a", "", "\U3e3965", perl=TRUE)
> # Error in gsub("a", "", "\U3e3965", perl = TRUE) : 
> #   input string 1 is invalid UTF-8
> 
> 
> The error message in the second command seems to come from
> src/main/grep.c:1640 (in do_gsub):
> if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);
> 
> utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
> described in src/extra/pcre/pcre_valid_utf8.c.
> 
> 
> 
> Even more problematic/interesting is the fact that iconv() does not
> consider the above character as invalid, as it does not replace it when
> using the sub argument. 
> > iconv("a\U3e3965", sub="")
> [1] "a\U003e3965"
> 
> On the contrary, an invalid sequence such as \xff is substituted:
> iconv("a\xff", sub="")
> # [1] "a"
> 
> This makes it difficult to sanitize the string before passing it to
> gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
> and where. Should iconv() and PCRE be made to agree on the definition of
> an invalid UTF-8 sequence?
> 
> 
> Regards
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From szehnder at uni-bonn.de  Mon Sep  9 10:22:32 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 9 Sep 2013 10:22:32 +0200
Subject: [Rd] Package installation and path.package
Message-ID: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>

Dear R-Devels,

I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded. Here is the code, I use in my package:


".defaultDBPath"    <- function() 
{
    db.path <- tempfile(pattern     = "mmstructDB", 
                        tmpdir      = file.path(path.package("mmstruct"),
                                                "data", "databases"),
                        fileext     = ".db")
    return(db.path)
}

.mmstructBASE <- setClass("mmstructBASE",
                          		    representation("VIRTUAL",
                                                                    dbName     = "character",
                                                                    dbTable    = "character"),
                                            prototype(dbName      = character(),
                                                            dbTable     = character()
							    )
)

.mmstructDB <- setClass("mmstructDB",                        
                        representation("VIRTUAL",
                                       conn = "SQLiteConnection"),
                        contains = c("mmstructBASE"),
                        prototype(conn  = dbConnect(dbDriver("SQLite"), .defaultDBPath()))
)

I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error? 


Best

Simon

From ripley at stats.ox.ac.uk  Mon Sep  9 14:59:54 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Sep 2013 13:59:54 +0100
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
In-Reply-To: <1378716561.5065.29.camel@milan>
References: <1378716561.5065.29.camel@milan>
Message-ID: <522DC64A.4080502@stats.ox.ac.uk>

On 09/09/2013 09:49, Milan Bouchet-Valat wrote:
> Hi!
>
> I experience an error with an invalid UTF-8 character passed to
> gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
> default) no error happens. (The character itself was read from an
> invalid HTML file.) Illustration of the error:
>
> gsub("a", "", "\U3e3965", perl=FALSE)
> # [1] "\U3e3965"
> gsub("a", "", "\U3e3965", perl=TRUE)
> # Error in gsub("a", "", "\U3e3965", perl = TRUE) :
> #   input string 1 is invalid UTF-8
>
>
> The error message in the second command seems to come from
> src/main/grep.c:1640 (in do_gsub):
> if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);
>
> utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
> described in src/extra/pcre/pcre_valid_utf8.c.
>
>
>
> Even more problematic/interesting is the fact that iconv() does not
> consider the above character as invalid, as it does not replace it when
> using the sub argument.
>> iconv("a\U3e3965", sub="")
> [1] "a\U003e3965"
>
> On the contrary, an invalid sequence such as \xff is substituted:
> iconv("a\xff", sub="")
> # [1] "a"
>
> This makes it difficult to sanitize the string before passing it to
> gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
> and where. Should iconv() and PCRE be made to agree on the definition of
> an invalid UTF-8 sequence?

iconv() is using a system service: read its help page.  So you know 
where to report this ....


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Mon Sep  9 15:26:34 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 9 Sep 2013 09:26:34 -0400
Subject: [Rd] Package installation and path.package
In-Reply-To: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
References: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
Message-ID: <D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>


On Sep 9, 2013, at 4:22 AM, Simon Zehnder wrote:

> Dear R-Devels,
> 
> I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded. Here is the code, I use in my package:
> 
> 
> ".defaultDBPath"    <- function() 
> {
>    db.path <- tempfile(pattern     = "mmstructDB", 
>                        tmpdir      = file.path(path.package("mmstruct"),
>                                                "data", "databases"),
>                        fileext     = ".db")
>    return(db.path)
> }
> 
> .mmstructBASE <- setClass("mmstructBASE",
>                          		    representation("VIRTUAL",
>                                                                    dbName     = "character",
>                                                                    dbTable    = "character"),
>                                            prototype(dbName      = character(),
>                                                            dbTable     = character()
> 							    )
> )
> 
> .mmstructDB <- setClass("mmstructDB",                        
>                        representation("VIRTUAL",
>                                       conn = "SQLiteConnection"),
>                        contains = c("mmstructBASE"),
>                        prototype(conn  = dbConnect(dbDriver("SQLite"), .defaultDBPath()))
> )
> 
> I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error? 
> 

That path to your package is dynamic - in general it will not be know when creating the lazy-load DB, so you really want to put that code in .onLoad() where the path is known.

Cheers,
Simon


> 
> Best
> 
> Simon
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Mon Sep  9 15:29:53 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 9 Sep 2013 09:29:53 -0400
Subject: [Rd] Package installation and path.package
In-Reply-To: <D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
References: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
	<D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
Message-ID: <EEAE5444-3921-49E3-8F72-B4F312D9C1D9@r-project.org>


On Sep 9, 2013, at 9:26 AM, Simon Urbanek wrote:

> 
> On Sep 9, 2013, at 4:22 AM, Simon Zehnder wrote:
> 
>> Dear R-Devels,
>> 
>> I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'.

BTW: if it's truly a temporary file, that that is a really bad idea - most users don't even have write-access to the library. That's why there is a separate facility for tempfiles, because you need something that the user has write-permissions for.


>> When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded. Here is the code, I use in my package:
>> 
>> 
>> ".defaultDBPath"    <- function() 
>> {
>>   db.path <- tempfile(pattern     = "mmstructDB", 
>>                       tmpdir      = file.path(path.package("mmstruct"),
>>                                               "data", "databases"),
>>                       fileext     = ".db")
>>   return(db.path)
>> }
>> 
>> .mmstructBASE <- setClass("mmstructBASE",
>>                         		    representation("VIRTUAL",
>>                                                                   dbName     = "character",
>>                                                                   dbTable    = "character"),
>>                                           prototype(dbName      = character(),
>>                                                           dbTable     = character()
>> 							    )
>> )
>> 
>> .mmstructDB <- setClass("mmstructDB",                        
>>                       representation("VIRTUAL",
>>                                      conn = "SQLiteConnection"),
>>                       contains = c("mmstructBASE"),
>>                       prototype(conn  = dbConnect(dbDriver("SQLite"), .defaultDBPath()))
>> )
>> 
>> I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error? 
>> 
> 
> That path to your package is dynamic - in general it will not be know when creating the lazy-load DB, so you really want to put that code in .onLoad() where the path is known.
> 
> Cheers,
> Simon
> 
> 
>> 
>> Best
>> 
>> Simon
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From edd at debian.org  Mon Sep  9 15:41:42 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 9 Sep 2013 08:41:42 -0500
Subject: [Rd] Package installation and path.package
In-Reply-To: <D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
References: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
	<D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
Message-ID: <21037.53270.901095.347497@max.nulle.part>


On 9 September 2013 at 09:26, Simon Urbanek wrote:
| On Sep 9, 2013, at 4:22 AM, Simon Zehnder wrote:
| > I am writing right now my own package that makes use of 'tempfile' and
| > there within with 'path.package'. When I install it, I get the error: Error
| > in path.package("mypackage") : none of the packages are loaded. Here is the
| > code, I use in my package:
[...]
| That path to your package is dynamic - in general it will not be know when
| creating the lazy-load DB, so you really want to put that code in .onLoad()
| where the path is known. 

And you may want to use   system.file()   rather than path.package(), at
least if I understand the question right.

Here is what I use to share the bibtex file for the Rcpp vignettes with other
Rcpp* package vignettes:

   R> system.file(package="Rcpp", "doc", "Rcpp.bib")
   [1] "/usr/local/lib/R/site-library/Rcpp/doc/Rcpp.bib"
   R> 

Answer conditional on my particular Linux system, but the path is guaranteed
to be valid as long as Rcpp is installed which one can ensure via Depends:
from another package.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From nalimilan at club.fr  Mon Sep  9 18:46:20 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 09 Sep 2013 18:46:20 +0200
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
In-Reply-To: <522DC64A.4080502@stats.ox.ac.uk>
References: <1378716561.5065.29.camel@milan> <522DC64A.4080502@stats.ox.ac.uk>
Message-ID: <1378745180.5065.69.camel@milan>

Le lundi 09 septembre 2013 ? 13:59 +0100, Prof Brian Ripley a ?crit :
> On 09/09/2013 09:49, Milan Bouchet-Valat wrote:
> > Hi!
> >
> > I experience an error with an invalid UTF-8 character passed to
> > gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
> > default) no error happens. (The character itself was read from an
> > invalid HTML file.) Illustration of the error:
> >
> > gsub("a", "", "\U3e3965", perl=FALSE)
> > # [1] "\U3e3965"
> > gsub("a", "", "\U3e3965", perl=TRUE)
> > # Error in gsub("a", "", "\U3e3965", perl = TRUE) :
> > #   input string 1 is invalid UTF-8
> >
> >
> > The error message in the second command seems to come from
> > src/main/grep.c:1640 (in do_gsub):
> > if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);
> >
> > utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
> > described in src/extra/pcre/pcre_valid_utf8.c.
> >
> >
> >
> > Even more problematic/interesting is the fact that iconv() does not
> > consider the above character as invalid, as it does not replace it when
> > using the sub argument.
> >> iconv("a\U3e3965", sub="")
> > [1] "a\U003e3965"
> >
> > On the contrary, an invalid sequence such as \xff is substituted:
> > iconv("a\xff", sub="")
> > # [1] "a"
> >
> > This makes it difficult to sanitize the string before passing it to
> > gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
> > and where. Should iconv() and PCRE be made to agree on the definition of
> > an invalid UTF-8 sequence?
> 
> iconv() is using a system service: read its help page.  So you know 
> where to report this ....
Yeah, but why is "\U003e3965" considered valid by gsub(perl=TRUE) and
printed as a character on Windows 7, and not on Linux? Do you think this
is a separate bug on Windows?


Thanks for your help


From murdoch.duncan at gmail.com  Mon Sep  9 19:21:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Sep 2013 13:21:53 -0400
Subject: [Rd] Comments requested on "changedFiles" function
In-Reply-To: <522773AC.3030609@gmail.com>
References: <522773AC.3030609@gmail.com>
Message-ID: <522E03B1.2020604@gmail.com>

Thanks for everyone's comments on this.  I have now committed a version 
to R-devel.  I don't plan to backport it to 3.0.2 (coming out in a 
couple of weeks), but it should appear in 3.1.0 in the spring, and it's 
conceivable it could make it into 3.0.3 (not yet scheduled).

Duncan Murdoch


From simon.urbanek at r-project.org  Mon Sep  9 19:41:28 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 9 Sep 2013 13:41:28 -0400
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
In-Reply-To: <1378745180.5065.69.camel@milan>
References: <1378716561.5065.29.camel@milan> <522DC64A.4080502@stats.ox.ac.uk>
	<1378745180.5065.69.camel@milan>
Message-ID: <44588C2D-F663-4E65-B58A-302ADA4DD01E@r-project.org>

On Sep 9, 2013, at 12:46 PM, Milan Bouchet-Valat wrote:

> Le lundi 09 septembre 2013 ? 13:59 +0100, Prof Brian Ripley a ?crit :
>> On 09/09/2013 09:49, Milan Bouchet-Valat wrote:
>>> Hi!
>>> 
>>> I experience an error with an invalid UTF-8 character passed to
>>> gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
>>> default) no error happens. (The character itself was read from an
>>> invalid HTML file.) Illustration of the error:
>>> 
>>> gsub("a", "", "\U3e3965", perl=FALSE)
>>> # [1] "\U3e3965"
>>> gsub("a", "", "\U3e3965", perl=TRUE)
>>> # Error in gsub("a", "", "\U3e3965", perl = TRUE) :
>>> #   input string 1 is invalid UTF-8
>>> 
>>> 
>>> The error message in the second command seems to come from
>>> src/main/grep.c:1640 (in do_gsub):
>>> if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);
>>> 
>>> utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
>>> described in src/extra/pcre/pcre_valid_utf8.c.
>>> 
>>> 
>>> 
>>> Even more problematic/interesting is the fact that iconv() does not
>>> consider the above character as invalid, as it does not replace it when
>>> using the sub argument.
>>>> iconv("a\U3e3965", sub="")
>>> [1] "a\U003e3965"
>>> 
>>> On the contrary, an invalid sequence such as \xff is substituted:
>>> iconv("a\xff", sub="")
>>> # [1] "a"
>>> 
>>> This makes it difficult to sanitize the string before passing it to
>>> gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
>>> and where. Should iconv() and PCRE be made to agree on the definition of
>>> an invalid UTF-8 sequence?
>> 
>> iconv() is using a system service: read its help page.  So you know 
>> where to report this ....
> Yeah, but why is "\U003e3965" considered valid by gsub(perl=TRUE) and
> printed as a character on Windows 7, and not on Linux? Do you think this
> is a separate bug on Windows?
> 

As pre RFC 3629 UTF-8 does not support characters beyond U+10FFFF so your U+3E3965 is not encodable in UTF-8 (it is encodable in the older scheme).

The trick is that Windows doesn't have a UTF-8 locale and only supports 16-bit, so it truncates the content to U+3965:

> charToRaw("\U3e3965")
[1] e3 a5 a5

That's why it seemingly works there.

Cheers,
S



> 
> Thanks for your help
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wheezito at yahoo.com  Mon Sep  9 21:23:00 2013
From: wheezito at yahoo.com (=?windows-1252?Q?Luis_Rodr=EDguez?=)
Date: Mon, 9 Sep 2013 14:23:00 -0500
Subject: [Rd] missing documentation entries ... WARNING
Message-ID: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>

Dear R-devel,

I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.

So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.

lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for. 

If anyone has advice on how to pass R CMD check, it would be greatly appreciated.

~luis



***
* checking for missing documentation entries ... WARNING
Undocumented code objects:
  ?lagSelect? ?mod?
Undocumented S4 classes:
  ?commcorrelogram?
Undocumented S4 methods:
  generic 'mod' and siglist 'commcorrelogram'
  generic 'plot' and siglist 'commcorrelogram,missing'

***

From murdoch.duncan at gmail.com  Mon Sep  9 21:49:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Sep 2013 15:49:23 -0400
Subject: [Rd] missing documentation entries ... WARNING
In-Reply-To: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
References: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
Message-ID: <522E2643.6010803@gmail.com>

On 09/09/2013 3:23 PM, Luis Rodr?guez wrote:
> Dear R-devel,
>
> I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.
>
> So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.
>
> lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for.

This message usually indicates that you don't have the relevant \alias{} 
defined correctly. If you do, please post the top of one or two of the 
Rd files, and we can tell you what's missing.  (I'd like to see at least 
the \alias{} and \usage{} sections.)

Duncan Murdoch

>
> If anyone has advice on how to pass R CMD check, it would be greatly appreciated.
>
> ~luis
>
>
>
> ***
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>    ?lagSelect? ?mod?
> Undocumented S4 classes:
>    ?commcorrelogram?
> Undocumented S4 methods:
>    generic 'mod' and siglist 'commcorrelogram'
>    generic 'plot' and siglist 'commcorrelogram,missing'
>
> ***
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nalimilan at club.fr  Mon Sep  9 21:56:48 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 09 Sep 2013 21:56:48 +0200
Subject: [Rd] Invalid UTF-8 with gsub(perl=TRUE) and iconv(sub="")
In-Reply-To: <44588C2D-F663-4E65-B58A-302ADA4DD01E@r-project.org>
References: <1378716561.5065.29.camel@milan>
	<522DC64A.4080502@stats.ox.ac.uk> <1378745180.5065.69.camel@milan>
	<44588C2D-F663-4E65-B58A-302ADA4DD01E@r-project.org>
Message-ID: <1378756608.5065.82.camel@milan>

Le lundi 09 septembre 2013 ? 13:41 -0400, Simon Urbanek a ?crit :
> On Sep 9, 2013, at 12:46 PM, Milan Bouchet-Valat wrote:
> 
> > Le lundi 09 septembre 2013 ? 13:59 +0100, Prof Brian Ripley a ?crit :
> >> On 09/09/2013 09:49, Milan Bouchet-Valat wrote:
> >>> Hi!
> >>> 
> >>> I experience an error with an invalid UTF-8 character passed to
> >>> gsub(..., perl=TRUE); the interesting point is that with perl=FALSE (the
> >>> default) no error happens. (The character itself was read from an
> >>> invalid HTML file.) Illustration of the error:
> >>> 
> >>> gsub("a", "", "\U3e3965", perl=FALSE)
> >>> # [1] "\U3e3965"
> >>> gsub("a", "", "\U3e3965", perl=TRUE)
> >>> # Error in gsub("a", "", "\U3e3965", perl = TRUE) :
> >>> #   input string 1 is invalid UTF-8
> >>> 
> >>> 
> >>> The error message in the second command seems to come from
> >>> src/main/grep.c:1640 (in do_gsub):
> >>> if (!utf8Valid(s)) error(("input string %d is invalid UTF-8"), i+1);
> >>> 
> >>> utf8Valid() relies on valid_utf8() from PCRE, whose behavior is
> >>> described in src/extra/pcre/pcre_valid_utf8.c.
> >>> 
> >>> 
> >>> 
> >>> Even more problematic/interesting is the fact that iconv() does not
> >>> consider the above character as invalid, as it does not replace it when
> >>> using the sub argument.
> >>>> iconv("a\U3e3965", sub="")
> >>> [1] "a\U003e3965"
> >>> 
> >>> On the contrary, an invalid sequence such as \xff is substituted:
> >>> iconv("a\xff", sub="")
> >>> # [1] "a"
> >>> 
> >>> This makes it difficult to sanitize the string before passing it to
> >>> gsub(perl=TRUE). Thus, I'm wondering whether something could be done,
> >>> and where. Should iconv() and PCRE be made to agree on the definition of
> >>> an invalid UTF-8 sequence?
> >> 
> >> iconv() is using a system service: read its help page.  So you know 
> >> where to report this ....
> > Yeah, but why is "\U003e3965" considered valid by gsub(perl=TRUE) and
> > printed as a character on Windows 7, and not on Linux? Do you think this
> > is a separate bug on Windows?
> > 
> 
> As pre RFC 3629 UTF-8 does not support characters beyond U+10FFFF so
> your U+3E3965 is not encodable in UTF-8 (it is encodable in the older
> scheme).
>
> The trick is that Windows doesn't have a UTF-8 locale and only
> supports 16-bit, so it truncates the content to U+3965:
> 
> > charToRaw("\U3e3965")
> [1] e3 a5 a5
> 
> That's why it seemingly works there.
Good catch!

So this is just a matter of iconv() being too tolerant, while PCRE is
right. As Brian Ripley said, I know where to report the bug.


Regards


From hb at biostat.ucsf.edu  Mon Sep  9 23:37:41 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 9 Sep 2013 14:37:41 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
In-Reply-To: <CAFDcVCSsd0KcZCCRv0f-MzUU__PJE9ZkrGF4jxy7dZS9Ci1Wyg@mail.gmail.com>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
	<CAFDcVCSsd0KcZCCRv0f-MzUU__PJE9ZkrGF4jxy7dZS9Ci1Wyg@mail.gmail.com>
Message-ID: <CAFDcVCTtpv-wUYA=N9vmM1Ojmn+WDT7jqsVNqeHw7hpdDbq0HQ@mail.gmail.com>

Any intelligent comments on this before I submit a proposal/patch via
bugs.r-project.org?

/Henrik

On Fri, Aug 30, 2013 at 12:47 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi.
>>
>> On Fri, Aug 30, 2013 at 6:58 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>> This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)
>>
>> For the record, you're referring to R-devel thread 'Correct NAMESPACE
>> approach when writing an S3 method for a generic in another package'
>> started on Aug 24, 2013
>> [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
>> Yes, it's closely related or possibly the same issue.  However, I do
>> not find it odd that the S3 generic function needs to be exported
>> from/available via the namespace.  Hence it needs to be export():ed by
>> at least one package/namespace.
>>
>> The real issue is when two package needs to export a generic function
>> with the same name, e.g. foo().   If the two generic functions are
>> defined differently (e.g. different arguments/signatures), they will
>> be in conflict with each other.  If they are identical, this should
>> not be a problem, but here I might be wrong.  However, there is also
>> the special case where one package reexports the generic function from
>> another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
>> the object 'foo' does actually not existing in the name space of
>> package PkgB - instead it provides a "redirect" to it, e.g.
>>
>>> PkgA::foo
>> function (...)
>> UseMethod("foo")
>> <environment: namespace:PkgA>
>>
>>> PkgB::foo
>> function (...)
>> UseMethod("foo")
>> <environment: namespace:PkgA>
>>
>>> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
>> [1] FALSE
>>
>>> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
>> [1] TRUE
>>
>>> identical(PkgB::foo, PkgA::foo)
>> [1] TRUE
>>
>>
>> The warning on "replacing previous import by 'PkgA::foo' when loading
>> 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
>> base::namespaceImportFrom()
>> [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R],
>> simply because it detects that "foo" (=n) has already been imported to
>> PkgC' namespace (=impenv):
>>
>> if (exists(n, envir = impenv, inherits = FALSE)) {
>>     if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>         ## warn only if generic overwrites a function which
>>         ## it was not derived from
>>         ...
>>     }
>>     warning(sprintf(msg, sQuote(paste(nsname, n, sep = "::")),
>> sQuote(from)), call. = FALSE, domain = NA)
>> }
>>
>> Note how there is already code for avoiding "false" warnings on S4
>> generic function.  This is what we'd like to have also for S3 generic
>> functions, but it's much harder to test for such since they're not
>> formally defined.  However, I'd argue that it is safe to skip the
>> warning *when the variable to be imported does not actually exist in
>> the package being imported* (e.g. when just rexported), i.e.
>>
>>>svn diff namespace.R
>> Index: namespace.R
>> ===================================================================
>> --- namespace.R (revision 63776)
>> +++ namespace.R (working copy)
>> @@ -871,6 +871,10 @@
>>      }
>>      for (n in impnames)
>>         if (exists(n, envir = impenv, inherits = FALSE)) {
>> +            ## warn only if imported variable actually exists in the
>> +            ## namespace imported from, which is not the case if
>> +            ## the variable is rexported from another namespace
>> +            if (!exists(n, envir = ns, inherits = FALSE)) next
>>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>                 ## warn only if generic overwrites a function which
>>                 ## it was not derived from
>
> Ok, if import(PkgA, PkgB) and PkgB reexports a *different* foo() than
> PkgA::foo(), say PkgZ::foo so identical(PkgB::foo, PkgA::foo) is
> FALSE, then there is indeed a conflict.  An alternative patch:
>
>>svn diff namespace.R
> Index: namespace.R
> ===================================================================
> --- namespace.R (revision 63776)
> +++ namespace.R (working copy)
> @@ -871,6 +871,11 @@
>      }
>      for (n in impnames)
>         if (exists(n, envir = impenv, inherits = FALSE)) {
> +            ## warn only if imported variable is non-identical to
> +            ## the one already imported
> +            getImp <- get(n, envir = impenv)
> +            obj <- get(n, envir = ns)
> +            if (identical(obj, getImp)) next
>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>                 ## warn only if generic overwrites a function which
>                 ## it was not derived from
>
> /Henrik
>
>>
>> I'm planning to propose ("wishlist / enhancement"; it may even be a
>> bug) this over at https://bugs.r-project.org/.
>>
>> Comments, anyone?
>>
>> /Henrik
>>
>>
>>> Paul
>>>
>>> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>
>>>>Hi,
>>>>
>>>>SETUP:
>>>>Consider three packages PkgA, PkgB and PkgC.
>>>>
>>>>PkgA defines a generic function foo() and exports it;
>>>>
>>>>export(foo)
>>>>
>>>>PkgB imports PkgA::foo() and re-exports it;
>>>>
>>>>importFrom(PkgA, foo)
>>>>export(foo)
>>>>
>>>>PkgC imports everything from PkgA and PkgB:
>>>>
>>>>imports(PkgA, PkgB)
>>>>
>>>>
>>>>PROBLEM:
>>>>Loading or attaching the namespace of PkgC will generate a warning:
>>>>
>>>>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>>>>
>>>>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>>>>
>>>>* checking whether package 'PkgC' can be installed ... WARNING
>>>>Found the following significant warnings:
>>>>  Warning: replacing previous import by 'PkgA::foo' when loading
>>>>'CellularAutomaton'
>>>>
>>>>
>>>>FALSE?
>>>>Isn't it valid to argue that this is a "false" warning, because
>>>>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>>>>
>>>>
>>>>/Henrik
>>>>
>>>>PS. The above can be avoided by using explicit importFrom() on PkgA
>>>>and PkgB, but that's really tedious.  In my case this is out of my
>>>>reach, because I'm the author of PkgA and PkgB but not many of the
>>>>PkgC packages.
>>>>
>>>>______________________________________________
>>>>R-devel at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-devel


From mtalbert at usgs.gov  Mon Sep  9 22:31:32 2013
From: mtalbert at usgs.gov (Marian Talbert)
Date: Mon, 9 Sep 2013 13:31:32 -0700 (PDT)
Subject: [Rd] How to get R cmd to check Fortran array bounds
Message-ID: <1378758692691-4675727.post@n4.nabble.com>

I'm trying to get the this Fortran array bounds check to run on my code as my
package has been rejected for failing this test.  I read writing R
extensions and it appears to run this test I should use a Makevars file with
one of the following two flags depending on my compiler: 
FCFLAGS = -g -O2 -mtune=native -fbounds-check
FFLAGS = -g -O2 -mtune=native -fbounds-check

and store it in the src subdirectory of my package.  I've tried this using
each of the above in a Makevars file.  It's not giving me the information on
where my code is failing the array bounds check and no warnings about
problems with my Makevars file.  I'm using R 3.0.1 I downloaded Rtools.exe
to match this version of R I'm on windows 64 bit.  
I'm using R cmd check package.name from the command prompt which clearly
checks my package but the Makevars file doesn't seem to change anything. 
I'd appreciate any information on what I need to do to run this test. 
Thanks. 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-get-R-cmd-to-check-Fortran-array-bounds-tp4675727.html
Sent from the R devel mailing list archive at Nabble.com.


From hb at biostat.ucsf.edu  Tue Sep 10 02:26:05 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 9 Sep 2013 17:26:05 -0700
Subject: [Rd] Is it possible to tell 'R CMD check' to accept certain
 filenames starting with a period?
Message-ID: <CAFDcVCR6Nk17W0s+KZ7_-C6NzEfsgvaHQF+KNqrKxpvk-Yj1GA@mail.gmail.com>

I a few of my packages I'd like to be able to add files starting with
a period that installs with the package, e.g.
inst/configs/.BatchJobs.R.   Currently [R Under development (unstable)
(2013-09-08 r63880)], R CMD check --as-cran complaints about this as:

* checking for hidden files and directories ... NOTE
Found the following hidden files and directories:
  inst/configs/.BatchJobs.R
These were most likely included in error. See section 'Package
structure' in the 'Writing R Extensions' manual.

It is not true that this is an error.  Is there a way to tell R CMD
check that it's intentional?  Think .Rcheckignore analogously to
.Rignorebuild and .Rinstignore (I know that does not exist).

/Henrik


From ripley at stats.ox.ac.uk  Tue Sep 10 07:14:34 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Sep 2013 06:14:34 +0100
Subject: [Rd] How to get R cmd to check Fortran array bounds
In-Reply-To: <1378758692691-4675727.post@n4.nabble.com>
References: <1378758692691-4675727.post@n4.nabble.com>
Message-ID: <522EAABA.1070200@stats.ox.ac.uk>

On 09/09/2013 21:31, Marian Talbert wrote:
> I'm trying to get the this Fortran array bounds check to run on my code as my
> package has been rejected for failing this test.  I read writing R
> extensions and it appears to run this test I should use a Makevars file with
> one of the following two flags depending on my compiler:
> FCFLAGS = -g -O2 -mtune=native -fbounds-check
> FFLAGS = -g -O2 -mtune=native -fbounds-check
>
> and store it in the src subdirectory of my package.  I've tried this using

It does not say that.

> each of the above in a Makevars file.  It's not giving me the information on
> where my code is failing the array bounds check and no warnings about
> problems with my Makevars file.  I'm using R 3.0.1 I downloaded Rtools.exe
> to match this version of R I'm on windows 64 bit.
> I'm using R cmd check package.name from the command prompt which clearly
> checks my package but the Makevars file doesn't seem to change anything.
> I'd appreciate any information on what I need to do to run this test

See the 'Writing R Extensions' manual ?4.3.4.

> Thanks.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-get-R-cmd-to-check-Fortran-array-bounds-tp4675727.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sds at gnu.org  Tue Sep 10 16:32:45 2013
From: sds at gnu.org (Sam Steingold)
Date: Tue, 10 Sep 2013 10:32:45 -0400
Subject: [Rd] [PATCH] show vector length in summary()
Message-ID: <8738pcu4qa.fsf@gnu.org>

(summary.default): show the vector length in addition to quantiles


diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
--- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old	2013-03-05 18:02:33.000000000 -0500
+++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R	2013-09-10 10:19:02.682946339 -0400
@@ -39,6 +39,7 @@ summary.default <-
 	qq <- stats::quantile(object)
 	qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
 	names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
+  qq <- c(qq,"Length" = length(object))
 	if(any(nas))
 	    c(qq, "NA's" = sum(nas))
 	else qq

Diff finished.  Tue Sep 10 10:19:40 2013


-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://dhimmi.com http://openvotingconsortium.org
http://thereligionofpeace.com http://www.memritv.org http://camera.org
Between grand theft and a legal fee, there only stands a law degree.


From edd at debian.org  Tue Sep 10 17:21:33 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 10 Sep 2013 10:21:33 -0500
Subject: [Rd] [PATCH] show vector length in summary()
In-Reply-To: <8738pcu4qa.fsf@gnu.org>
References: <8738pcu4qa.fsf@gnu.org>
Message-ID: <21039.14589.7764.131241@max.nulle.part>


On 10 September 2013 at 10:32, Sam Steingold wrote:
| (summary.default): show the vector length in addition to quantiles
| 
| 
| diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
| --- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old	2013-03-05 18:02:33.000000000 -0500
| +++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R	2013-09-10 10:19:02.682946339 -0400
| @@ -39,6 +39,7 @@ summary.default <-
|  	qq <- stats::quantile(object)
|  	qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
|  	names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
| +  qq <- c(qq,"Length" = length(object))
|  	if(any(nas))
|  	    c(qq, "NA's" = sum(nas))
|  	else qq
| 
| Diff finished.  Tue Sep 10 10:19:40 2013

Base R functions are rarely modified; others may have expectations on
summary() returning the six values it returns.

Many alternatives are available, including describe in Hmisc which returns
the count you suggest, and a count of missingness.

R> set.seed(42)
R> describe(rnorm(100))
rnorm(100) 
      n missing  unique    Mean     .05     .10     .25     .50     .75     .90     .95 
    100       0     100 0.03251 -1.7641 -1.2117 -0.6167  0.0898  0.6616  1.3730  1.5116 

lowest : -2.993 -2.656 -2.440 -2.414 -1.781, highest:  1.513  1.576  1.895  2.018  2.287 
R> 


Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From szehnder at uni-bonn.de  Tue Sep 10 17:48:05 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 10 Sep 2013 17:48:05 +0200
Subject: [Rd] Package installation and path.package
In-Reply-To: <EEAE5444-3921-49E3-8F72-B4F312D9C1D9@r-project.org>
References: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
	<D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
	<EEAE5444-3921-49E3-8F72-B4F312D9C1D9@r-project.org>
Message-ID: <A32AA18B-61EC-4D95-9053-2AA4BB1C317B@uni-bonn.de>

Hi Simon,

thank you for this comment! I will do it now the regular way - this is always the most reliable one. 

Best

Simon

On Sep 9, 2013, at 3:29 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> e you need something that the user has write-permissions for.


From szehnder at uni-bonn.de  Tue Sep 10 17:54:05 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 10 Sep 2013 17:54:05 +0200
Subject: [Rd] Package installation and path.package
In-Reply-To: <21037.53270.901095.347497@max.nulle.part>
References: <79265780-D119-450A-93F9-D5BA2A81C9B1@uni-bonn.de>
	<D2208CD6-8CA6-4A21-A112-9CE4E3BA1587@r-project.org>
	<21037.53270.901095.347497@max.nulle.part>
Message-ID: <8430D34F-DA7F-4C89-AB05-D4047CABBDD6@uni-bonn.de>

Hi Dirk,

thanks for the help I take a more thorough look at it. 

Best

Simon

On Sep 9, 2013, at 3:41 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

> 
> On 9 September 2013 at 09:26, Simon Urbanek wrote:
> | On Sep 9, 2013, at 4:22 AM, Simon Zehnder wrote:
> | > I am writing right now my own package that makes use of 'tempfile' and
> | > there within with 'path.package'. When I install it, I get the error: Error
> | > in path.package("mypackage") : none of the packages are loaded. Here is the
> | > code, I use in my package:
> [...]
> | That path to your package is dynamic - in general it will not be know when
> | creating the lazy-load DB, so you really want to put that code in .onLoad()
> | where the path is known. 
> 
> And you may want to use   system.file()   rather than path.package(), at
> least if I understand the question right.
> 
> Here is what I use to share the bibtex file for the Rcpp vignettes with other
> Rcpp* package vignettes:
> 
>   R> system.file(package="Rcpp", "doc", "Rcpp.bib")
>   [1] "/usr/local/lib/R/site-library/Rcpp/doc/Rcpp.bib"
>   R> 
> 
> Answer conditional on my particular Linux system, but the path is guaranteed
> to be valid as long as Rcpp is installed which one can ensure via Depends:
> from another package.
> 
> Dirk
> 
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From sds at gnu.org  Tue Sep 10 18:56:36 2013
From: sds at gnu.org (Sam Steingold)
Date: Tue, 10 Sep 2013 12:56:36 -0400
Subject: [Rd] [PATCH] show vector length in summary()
References: <8738pcu4qa.fsf@gnu.org> <21039.14589.7764.131241@max.nulle.part>
Message-ID: <87y574sji3.fsf@gnu.org>

> * Dirk Eddelbuettel <rqq at qrovna.bet> [2013-09-10 10:21:33 -0500]:
>
> On 10 September 2013 at 10:32, Sam Steingold wrote:
> | (summary.default): show the vector length in addition to quantiles
> | 
> | 
> | diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
> | --- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old	2013-03-05 18:02:33.000000000 -0500
> | +++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R	2013-09-10 10:19:02.682946339 -0400
> | @@ -39,6 +39,7 @@ summary.default <-
> |  	qq <- stats::quantile(object)
> |  	qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
> |  	names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
> | +  qq <- c(qq,"Length" = length(object))
> |  	if(any(nas))
> |  	    c(qq, "NA's" = sum(nas))
> |  	else qq
> | 
> | Diff finished.  Tue Sep 10 10:19:40 2013
>
> Base R functions are rarely modified; others may have expectations on
> summary() returning the six values it returns.

Note that summary sometimes returns 5 values (when there no "NA's").
It is clearly wrong to rely on the details of the return value of a UI function.

> Many alternatives are available, including describe in Hmisc which
> returns the count you suggest, and a count of missingness.

Such a minor issue hardly justifies installing a whole new package.
(but thanks for the suggestion!)

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://www.memritv.org http://palestinefacts.org
http://www.PetitionOnline.com/tap12009/ http://pmw.org.il http://dhimmi.com
WHO ATE MY BREAKFAST PANTS?


From crunch at 3c58.net  Tue Sep 10 23:24:39 2013
From: crunch at 3c58.net (crunch)
Date: Tue, 10 Sep 2013 14:24:39 -0700 (PDT)
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <20130518145434.4194be90@bossiaea>
References: <20130518145434.4194be90@bossiaea>
Message-ID: <1378848279883-4675813.post@n4.nabble.com>

I need to build R on a Centos machine where I have no admin privileges.
Believe I have to build from source, but cannot find the configure script in
the source bundle.  Am I missing something?



--
View this message in context: http://r.789695.n4.nabble.com/R-CMD-config-for-R-3-0-1-tp4667399p4675813.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Tue Sep 10 23:44:41 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Sep 2013 22:44:41 +0100
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <1378848279883-4675813.post@n4.nabble.com>
References: <20130518145434.4194be90@bossiaea>
	<1378848279883-4675813.post@n4.nabble.com>
Message-ID: <522F92C9.5070206@stats.ox.ac.uk>

On 10/09/2013 22:24, crunch wrote:
> I need to build R on a Centos machine where I have no admin privileges.
> Believe I have to build from source, but cannot find the configure script in
> the source bundle.  Am I missing something?

Yes, as it is there.  We can only guess that 'the source bundle' you 
have is not the correct file. As 3.0.2 is close, I would start with 
R-patched from ftp://ftp.stat.math.ethz.ch/Software/R/ (a link on the 
CRAN front page).

It contains an installation manual, online at 
http://cran.r-project.org/doc/manuals/r-patched/R-admin.html

[What may be more of a problem is installing the tools you need: does 
your box have a Fortran compiler, for example?]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Wed Sep 11 00:38:29 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 10 Sep 2013 18:38:29 -0400
Subject: [Rd] [PATCH] show vector length in summary()
In-Reply-To: <87y574sji3.fsf@gnu.org>
References: <8738pcu4qa.fsf@gnu.org> <21039.14589.7764.131241@max.nulle.part>
	<87y574sji3.fsf@gnu.org>
Message-ID: <CCCFD922-6B60-4D4C-8A08-AA17C8745465@r-project.org>


On Sep 10, 2013, at 12:56 PM, Sam Steingold wrote:

>> * Dirk Eddelbuettel <rqq at qrovna.bet> [2013-09-10 10:21:33 -0500]:
>> 
>> On 10 September 2013 at 10:32, Sam Steingold wrote:
>> | (summary.default): show the vector length in addition to quantiles
>> | 
>> | 
>> | diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
>> | --- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old	2013-03-05 18:02:33.000000000 -0500
>> | +++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R	2013-09-10 10:19:02.682946339 -0400
>> | @@ -39,6 +39,7 @@ summary.default <-
>> |  	qq <- stats::quantile(object)
>> |  	qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
>> |  	names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
>> | +  qq <- c(qq,"Length" = length(object))
>> |  	if(any(nas))
>> |  	    c(qq, "NA's" = sum(nas))
>> |  	else qq
>> | 
>> | Diff finished.  Tue Sep 10 10:19:40 2013
>> 
>> Base R functions are rarely modified; others may have expectations on
>> summary() returning the six values it returns.
> 
> Note that summary sometimes returns 5 values (when there no "NA's").
> It is clearly wrong to rely on the details of the return value of a UI function.
> 

.. except that summary() is not a UI function. It is used to create summary *objects*, not some UI output. Although sometimes users like to print such summary objects, that is not the task of summary(). There are quite common programmatic uses of summary() -- one prominent one that comes to my mind is in conjunction with connections.
 (Not that any of this has anything to do with the original question ... )


>> Many alternatives are available, including describe in Hmisc which
>> returns the count you suggest, and a count of missingness.
> 
> Such a minor issue hardly justifies installing a whole new package.
> (but thanks for the suggestion!)
> 
> -- 
> Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
> http://www.childpsy.net/ http://www.memritv.org http://palestinefacts.org
> http://www.PetitionOnline.com/tap12009/ http://pmw.org.il http://dhimmi.com
> WHO ATE MY BREAKFAST PANTS?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From crunch at 3c58.net  Tue Sep 10 23:30:56 2013
From: crunch at 3c58.net (crunch)
Date: Tue, 10 Sep 2013 14:30:56 -0700 (PDT)
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <1378848279883-4675813.post@n4.nabble.com>
References: <20130518145434.4194be90@bossiaea>
	<1378848279883-4675813.post@n4.nabble.com>
Message-ID: <1378848656818-4675814.post@n4.nabble.com>

Also have no cooperation from the admin of the machine, so can't ask for a
yum install.



--
View this message in context: http://r.789695.n4.nabble.com/R-CMD-config-for-R-3-0-1-tp4667399p4675814.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Sep 11 02:39:04 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 10 Sep 2013 20:39:04 -0400
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <1378848656818-4675814.post@n4.nabble.com>
References: <20130518145434.4194be90@bossiaea>
	<1378848279883-4675813.post@n4.nabble.com>
	<1378848656818-4675814.post@n4.nabble.com>
Message-ID: <A34BCB42-029B-4B79-9F9D-4D6FD9F3C64E@r-project.org>

On Sep 10, 2013, at 5:30 PM, crunch wrote:

> Also have no cooperation from the admin of the machine, so can't ask for a
> yum install.
> 

Please follow Brian's advice. If you don't have even Fortran on that machine, then you're really in a pickle: you can extract the gfortran rpm contents (and all dependencies you may need) by hand in any place that you have access to and adjust LD_LIBRARY_PATH for the runtime accordingly. However, it's not a trivial task - it particular if you're not very familiar with subtleties of Linux. (I had to do this fairly recently on a CentOS machine, so I know it's possible, but there are a few gotchas that may require a few symlinks created by hand).

Cheers,
Simon


> 
> --
> View this message in context: http://r.789695.n4.nabble.com/R-CMD-config-for-R-3-0-1-tp4667399p4675814.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From michael.weylandt at gmail.com  Wed Sep 11 04:45:00 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 10 Sep 2013 22:45:00 -0400
Subject: [Rd] [PATCH] show vector length in summary()
In-Reply-To: <CCCFD922-6B60-4D4C-8A08-AA17C8745465@r-project.org>
References: <8738pcu4qa.fsf@gnu.org> <21039.14589.7764.131241@max.nulle.part>
	<87y574sji3.fsf@gnu.org>
	<CCCFD922-6B60-4D4C-8A08-AA17C8745465@r-project.org>
Message-ID: <EB5A3444-BE92-44D9-9148-5C488D7B633F@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130910/66af77a6/attachment.pl>

From rowe at muxspace.com  Wed Sep 11 07:29:29 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Wed, 11 Sep 2013 06:29:29 +0100
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <A34BCB42-029B-4B79-9F9D-4D6FD9F3C64E@r-project.org>
References: <20130518145434.4194be90@bossiaea>
	<1378848279883-4675813.post@n4.nabble.com>
	<1378848656818-4675814.post@n4.nabble.com>
	<A34BCB42-029B-4B79-9F9D-4D6FD9F3C64E@r-project.org>
Message-ID: <6B24A1C4-586E-459D-9C4B-80E5596D22AF@muxspace.com>

As an alternative, you might consider installing a virtual machine in your user space and installing R from there. That way you don't have to do a bunch of one-off gymnastics to get R compiled. 



On Sep 11, 2013, at 1:40 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Sep 10, 2013, at 5:30 PM, crunch wrote:
> 
>> Also have no cooperation from the admin of the machine, so can't ask for a
>> yum install.
> 
> Please follow Brian's advice. If you don't have even Fortran on that machine, then you're really in a pickle: you can extract the gfortran rpm contents (and all dependencies you may need) by hand in any place that you have access to and adjust LD_LIBRARY_PATH for the runtime accordingly. However, it's not a trivial task - it particular if you're not very familiar with subtleties of Linux. (I had to do this fairly recently on a CentOS machine, so I know it's possible, but there are a few gotchas that may require a few symlinks created by hand).
> 
> Cheers,
> Simon
> 
> 
>> 
>> --
>> View this message in context: http://r.789695.n4.nabble.com/R-CMD-config-for-R-3-0-1-tp4667399p4675814.html
>> Sent from the R devel mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From crunch at 3c58.net  Wed Sep 11 07:31:14 2013
From: crunch at 3c58.net (crunch)
Date: Tue, 10 Sep 2013 22:31:14 -0700 (PDT)
Subject: [Rd] [MASS.ts] Error 1
In-Reply-To: <522F92C9.5070206@stats.ox.ac.uk>
References: <20130518145434.4194be90@bossiaea>
	<1378848279883-4675813.post@n4.nabble.com>
	<522F92C9.5070206@stats.ox.ac.uk>
Message-ID: <1378877474763-4675838.post@n4.nabble.com>

I'm making progress building R on Centos, but make is dying just after "begin
installing recommended package MASS" where it complains "Error in
untar2(tarfile, files, list, exdir, restore_times) :
  incomplete block on file
make[2]: *** [MASS.ts] Error 1

I have $R_SHELL defined as /bin/sh, $R_HOME/bin in my $PATH and I
successfully installed the MASS package using: R CMD INSTALL
MASS_7.3-29.tar.gz
just before I ran make a second time.

Do I have a bad package?  What can I do?




--
View this message in context: http://r.789695.n4.nabble.com/R-CMD-config-for-R-3-0-1-tp4667399p4675838.html
Sent from the R devel mailing list archive at Nabble.com.


From sds at gnu.org  Wed Sep 11 18:07:19 2013
From: sds at gnu.org (Sam Steingold)
Date: Wed, 11 Sep 2013 12:07:19 -0400
Subject: [Rd] [PATCH] show vector length in summary()
References: <8738pcu4qa.fsf@gnu.org> <21039.14589.7764.131241@max.nulle.part>
	<87y574sji3.fsf@gnu.org>
	<CCCFD922-6B60-4D4C-8A08-AA17C8745465@r-project.org>
Message-ID: <87ob7zpcjs.fsf@gnu.org>

> * Simon Urbanek <fvzba.heonarx at e-cebwrpg.bet> [2013-09-10 18:38:29 -0400]:
>
> On Sep 10, 2013, at 12:56 PM, Sam Steingold wrote:
>
>>> * Dirk Eddelbuettel <rqq at qrovna.bet> [2013-09-10 10:21:33 -0500]:
>>> 
>>> On 10 September 2013 at 10:32, Sam Steingold wrote:
>>> | (summary.default): show the vector length in addition to quantiles
>>> | 
>>> | 
>>> | diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
>>> | --- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old	2013-03-05 18:02:33.000000000 -0500
>>> | +++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R	2013-09-10 10:19:02.682946339 -0400
>>> | @@ -39,6 +39,7 @@ summary.default <-
>>> |  	qq <- stats::quantile(object)
>>> |  	qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
>>> |  	names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
>>> | +  qq <- c(qq,"Length" = length(object))
>>> |  	if(any(nas))
>>> |  	    c(qq, "NA's" = sum(nas))
>>> |  	else qq
>>> | 
>>> | Diff finished.  Tue Sep 10 10:19:40 2013
>>> 
>>> Base R functions are rarely modified; others may have expectations on
>>> summary() returning the six values it returns.
>> 
>> Note that summary sometimes returns 5 values (when there no "NA's").
>> It is clearly wrong to rely on the details of the return value of a UI function.
>> 
>
> .. except that summary() is not a UI function. It is used to create
> summary *objects*, not some UI output. Although sometimes users like to
> print such summary objects, that is not the task of summary(). There are
> quite common programmatic uses of summary() -- one prominent one that
> comes to my mind is in conjunction with connections.

you mean, saving to files?

>  (Not that any of this has anything to do with the original question ... )

well, it does: what are the "common programmatic uses of summary" which
rely on its number of values?

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://truepeace.org http://www.memritv.org
http://honestreporting.com http://camera.org http://americancensorship.org
To understand recursion, one has to understand recursion first.


From sds at gnu.org  Wed Sep 11 18:11:06 2013
From: sds at gnu.org (Sam Steingold)
Date: Wed, 11 Sep 2013 12:11:06 -0400
Subject: [Rd] [PATCH] show vector length in summary()
References: <8738pcu4qa.fsf@gnu.org> <21039.14589.7764.131241@max.nulle.part>
	<87y574sji3.fsf@gnu.org>
	<CCCFD922-6B60-4D4C-8A08-AA17C8745465@r-project.org>
	<EB5A3444-BE92-44D9-9148-5C488D7B633F@gmail.com>
Message-ID: <87ioy7pcdh.fsf@gnu.org>

> * Michael Weylandt <zvpunry.jrlynaqg at tznvy.pbz> [2013-09-10 22:45:00 -0400]:
>
> On Sep 10, 2013, at 18:38, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
>> 
>> On Sep 10, 2013, at 12:56 PM, Sam Steingold wrote:
>> 
>>>> * Dirk Eddelbuettel <rqq at qrovna.bet> [2013-09-10 10:21:33 -0500]:
>>>> 
>>>> On 10 September 2013 at 10:32, Sam Steingold wrote:
>>>> | (summary.default): show the vector length in addition to quantiles
>>>> | 
>>>> | 
>>>> | diff -u -i -p -F '^(def' -b -w -B /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old /home/sds/src/R-3.0.1/src/library/base/R/summary.R
>>>> | --- /home/sds/src/R-3.0.1/src/library/base/R/summary.R.old    2013-03-05 18:02:33.000000000 -0500
>>>> | +++ /home/sds/src/R-3.0.1/src/library/base/R/summary.R    2013-09-10 10:19:02.682946339 -0400
>>>> | @@ -39,6 +39,7 @@ summary.default <-
>>>> |      qq <- stats::quantile(object)
>>>> |      qq <- signif(c(qq[1L:3L], mean(object), qq[4L:5L]), digits)
>>>> |      names(qq) <- c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
>>>> | +  qq <- c(qq,"Length" = length(object))
>>>> |      if(any(nas))
>>>> |          c(qq, "NA's" = sum(nas))
>>>> |      else qq
>>>> | 
>>>> | Diff finished.  Tue Sep 10 10:19:40 2013
>
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-should-I-write-summary-methods_003f

Yes, I have seen this, thanks for the reminder.
In fact, I have some summary methods in my codebase.
However, adding 46 lines of summary.default to my file just to add one
line is no good.

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://thereligionofpeace.com http://jihadwatch.org
http://camera.org http://palestinefacts.org http://americancensorship.org
A professor is someone who talks in someone else's sleep.


From friendly at yorku.ca  Thu Sep 12 15:38:43 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 12 Sep 2013 09:38:43 -0400
Subject: [Rd] declaring package dependencies
Message-ID: <5231C3E3.3050007@yorku.ca>

I received the following email note re: the vcdExtra package

> A vcd update has shown that packages TIMP and vcdExtra are not 
> declaring their dependence on colorspace/MASS: see
>
> http://cran.r-project.org/web/checks/check_results_vcdExtra.html
But, I can't see what to do to avoid this, nor understand what has 
changed in R devel.

Sure enough, CRAN now reports errors in examples using MASS::loglm(), 
using R Under development (unstable) (2013-09-11 r63906)

 > Caesar.mod0 <- loglm(~Infection + (Risk*Antibiotics*Planned), 
data=Caesar)
Error: could not find function "loglm"

In DESCRIPTION I have
Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)
Suggests: 
ca,gmodels,Fahrmeir,effects,VGAM,plyr,rgl,lmtest,MASS,nnet,ggplot2,Sleuth2,car

and the vcd DESCRIPTION has

Depends: R (>= 2.4.0), grid, stats
Suggests: KernSmooth, mvtnorm, kernlab, HSAUR, coin
Imports: utils, MASS, grDevices, colorspace

so, in an R 3.0.0 console, library(vcdExtra) loads vcd and its dependencies:

 > library(vcdExtra)
Loading required package: vcd
Loading required package: MASS
Loading required package: grid
Loading required package: colorspace
Loading required package: gnm
Warning messages:
1: package ?vcd? was built under R version 3.0.1
2: package ?MASS? was built under R version 3.0.1
 >

Note: these CRAN errors do not occur on R-Forge, using R version 3.0.1 
Patched (2013-08-21 r63645)
and the latest devel version (0.5-11) of vcdExtra.

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From benjamin.hofner at fau.de  Thu Sep 12 15:49:21 2013
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Thu, 12 Sep 2013 06:49:21 -0700 (PDT)
Subject: [Rd] Importing packages in Depend
Message-ID: <1378993761415-4675947.post@n4.nabble.com>

Hi,

I am currently preparing a new version of my package papeR. When I run R CMD
check using the development version of R I get the following note:

Package in Depends field not imported from: ?nlme?, ?lme4?, ?survival?
  These packages needs to imported from for the case when
  this namespace is loaded but not attached.

I now have problems to fix this issue. It is easy to get rid of two of the
three package warnings by using 

import(lme4)
import(survival) 

in my NAMESPACE. Yet, I cannot import nlme as I then get the following
warnings:

Warning: replacing previous import ?VarCorr? when loading ?lme4?
Warning: replacing previous import ?lmList? when loading ?lme4?

I know that nlme is imported in lme4 but I cannot import both at the same
time. Can anyone help me here? I do *not* want or can use importFrom as I
rely on multiple functions and also rely on non-exported methods such as
summary.lme().

Thanks and all the best,
Benjamin



--
View this message in context: http://r.789695.n4.nabble.com/Importing-packages-in-Depend-tp4675947.html
Sent from the R devel mailing list archive at Nabble.com.


From hb at biostat.ucsf.edu  Thu Sep 12 18:46:29 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 12 Sep 2013 09:46:29 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
In-Reply-To: <CAFDcVCTtpv-wUYA=N9vmM1Ojmn+WDT7jqsVNqeHw7hpdDbq0HQ@mail.gmail.com>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
	<CAFDcVCSsd0KcZCCRv0f-MzUU__PJE9ZkrGF4jxy7dZS9Ci1Wyg@mail.gmail.com>
	<CAFDcVCTtpv-wUYA=N9vmM1Ojmn+WDT7jqsVNqeHw7hpdDbq0HQ@mail.gmail.com>
Message-ID: <CAFDcVCS_7rQT6+VPV3OGbr-7P69B3BShHHz6SWWW2-W34pwGKw@mail.gmail.com>

Just for the record, I did submit PR#15451:

'Bug 15451 - PATCH: namespaceImportFrom() not to warn when the
identical object is imported twice' on 2013-09-10
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15451

/Henrik

On Mon, Sep 9, 2013 at 2:37 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Any intelligent comments on this before I submit a proposal/patch via
> bugs.r-project.org?
>
> /Henrik
>
> On Fri, Aug 30, 2013 at 12:47 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> Hi.
>>>
>>> On Fri, Aug 30, 2013 at 6:58 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>>> This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)
>>>
>>> For the record, you're referring to R-devel thread 'Correct NAMESPACE
>>> approach when writing an S3 method for a generic in another package'
>>> started on Aug 24, 2013
>>> [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
>>> Yes, it's closely related or possibly the same issue.  However, I do
>>> not find it odd that the S3 generic function needs to be exported
>>> from/available via the namespace.  Hence it needs to be export():ed by
>>> at least one package/namespace.
>>>
>>> The real issue is when two package needs to export a generic function
>>> with the same name, e.g. foo().   If the two generic functions are
>>> defined differently (e.g. different arguments/signatures), they will
>>> be in conflict with each other.  If they are identical, this should
>>> not be a problem, but here I might be wrong.  However, there is also
>>> the special case where one package reexports the generic function from
>>> another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
>>> the object 'foo' does actually not existing in the name space of
>>> package PkgB - instead it provides a "redirect" to it, e.g.
>>>
>>>> PkgA::foo
>>> function (...)
>>> UseMethod("foo")
>>> <environment: namespace:PkgA>
>>>
>>>> PkgB::foo
>>> function (...)
>>> UseMethod("foo")
>>> <environment: namespace:PkgA>
>>>
>>>> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
>>> [1] FALSE
>>>
>>>> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
>>> [1] TRUE
>>>
>>>> identical(PkgB::foo, PkgA::foo)
>>> [1] TRUE
>>>
>>>
>>> The warning on "replacing previous import by 'PkgA::foo' when loading
>>> 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
>>> base::namespaceImportFrom()
>>> [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R],
>>> simply because it detects that "foo" (=n) has already been imported to
>>> PkgC' namespace (=impenv):
>>>
>>> if (exists(n, envir = impenv, inherits = FALSE)) {
>>>     if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>>         ## warn only if generic overwrites a function which
>>>         ## it was not derived from
>>>         ...
>>>     }
>>>     warning(sprintf(msg, sQuote(paste(nsname, n, sep = "::")),
>>> sQuote(from)), call. = FALSE, domain = NA)
>>> }
>>>
>>> Note how there is already code for avoiding "false" warnings on S4
>>> generic function.  This is what we'd like to have also for S3 generic
>>> functions, but it's much harder to test for such since they're not
>>> formally defined.  However, I'd argue that it is safe to skip the
>>> warning *when the variable to be imported does not actually exist in
>>> the package being imported* (e.g. when just rexported), i.e.
>>>
>>>>svn diff namespace.R
>>> Index: namespace.R
>>> ===================================================================
>>> --- namespace.R (revision 63776)
>>> +++ namespace.R (working copy)
>>> @@ -871,6 +871,10 @@
>>>      }
>>>      for (n in impnames)
>>>         if (exists(n, envir = impenv, inherits = FALSE)) {
>>> +            ## warn only if imported variable actually exists in the
>>> +            ## namespace imported from, which is not the case if
>>> +            ## the variable is rexported from another namespace
>>> +            if (!exists(n, envir = ns, inherits = FALSE)) next
>>>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>>                 ## warn only if generic overwrites a function which
>>>                 ## it was not derived from
>>
>> Ok, if import(PkgA, PkgB) and PkgB reexports a *different* foo() than
>> PkgA::foo(), say PkgZ::foo so identical(PkgB::foo, PkgA::foo) is
>> FALSE, then there is indeed a conflict.  An alternative patch:
>>
>>>svn diff namespace.R
>> Index: namespace.R
>> ===================================================================
>> --- namespace.R (revision 63776)
>> +++ namespace.R (working copy)
>> @@ -871,6 +871,11 @@
>>      }
>>      for (n in impnames)
>>         if (exists(n, envir = impenv, inherits = FALSE)) {
>> +            ## warn only if imported variable is non-identical to
>> +            ## the one already imported
>> +            getImp <- get(n, envir = impenv)
>> +            obj <- get(n, envir = ns)
>> +            if (identical(obj, getImp)) next
>>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>                 ## warn only if generic overwrites a function which
>>                 ## it was not derived from
>>
>> /Henrik
>>
>>>
>>> I'm planning to propose ("wishlist / enhancement"; it may even be a
>>> bug) this over at https://bugs.r-project.org/.
>>>
>>> Comments, anyone?
>>>
>>> /Henrik
>>>
>>>
>>>> Paul
>>>>
>>>> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>
>>>>>Hi,
>>>>>
>>>>>SETUP:
>>>>>Consider three packages PkgA, PkgB and PkgC.
>>>>>
>>>>>PkgA defines a generic function foo() and exports it;
>>>>>
>>>>>export(foo)
>>>>>
>>>>>PkgB imports PkgA::foo() and re-exports it;
>>>>>
>>>>>importFrom(PkgA, foo)
>>>>>export(foo)
>>>>>
>>>>>PkgC imports everything from PkgA and PkgB:
>>>>>
>>>>>imports(PkgA, PkgB)
>>>>>
>>>>>
>>>>>PROBLEM:
>>>>>Loading or attaching the namespace of PkgC will generate a warning:
>>>>>
>>>>>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>>>>>
>>>>>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>>>>>
>>>>>* checking whether package 'PkgC' can be installed ... WARNING
>>>>>Found the following significant warnings:
>>>>>  Warning: replacing previous import by 'PkgA::foo' when loading
>>>>>'CellularAutomaton'
>>>>>
>>>>>
>>>>>FALSE?
>>>>>Isn't it valid to argue that this is a "false" warning, because
>>>>>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>>>>>
>>>>>
>>>>>/Henrik
>>>>>
>>>>>PS. The above can be avoided by using explicit importFrom() on PkgA
>>>>>and PkgB, but that's really tedious.  In my case this is out of my
>>>>>reach, because I'm the author of PkgA and PkgB but not many of the
>>>>>PkgC packages.
>>>>>
>>>>>______________________________________________
>>>>>R-devel at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert902 at gmail.com  Thu Sep 12 18:54:35 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 12 Sep 2013 12:54:35 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5231C3E3.3050007@yorku.ca>
References: <5231C3E3.3050007@yorku.ca>
Message-ID: <5231F1CB.2080801@gmail.com>

Michael

(Several of us are struggling with these changes, so my comments are 
from the newly initiated point of view, rather than the fully 
knowledgeable.)

On 13-09-12 09:38 AM, Michael Friendly wrote:
> I received the following email note re: the vcdExtra package
>
>> A vcd update has shown that packages TIMP and vcdExtra are not
>> declaring their dependence on colorspace/MASS: see
>>
>> http://cran.r-project.org/web/checks/check_results_vcdExtra.html
> But, I can't see what to do to avoid this, nor understand what has
> changed in R devel.

Lots in this respect.
>
> Sure enough, CRAN now reports errors in examples using MASS::loglm(),
> using R Under development (unstable) (2013-09-11 r63906)
>
>  > Caesar.mod0 <- loglm(~Infection + (Risk*Antibiotics*Planned),
> data=Caesar)
> Error: could not find function "loglm"
>
> In DESCRIPTION I have
> Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)

The "modern" way of thinking about this is that the Depends line should 
not have much in it, only things from other packages that you want 
directly available to the user. (There are a few other exceptions 
necessary for packages that have not themselves embraced the "modern" 
way.) Since you may want users of vcdExtra to automatically have access 
to functions in vcd, without needing to execute library(vcd), this 
classifies as one of the official exceptions and you probably want cvd 
in the Depends line. However, chances are that gnm should be in 
Imports:. If vcd is in the Depends line then it is automatically 
attached and your examples do not need library(vcd) or requires(vcd).

The Note

   Unexported object imported by a ?:::? call: ?vcd:::rootogram.default?

is harder to decide how to deal with. (This is sill just a note, but it 
looks to me like a note that will soon become a warning or error.) The 
simple solution is to export rootogram.default from vcd, but that 
exposes it to all users, and really you may just want to expose it to 
packages like vcdExtra. There was some recent discussion about this on 
R-devel. I suggested one possibility would be some sort of limited 
export. Since that was a suggestion that required work by someone else, 
it probably went the same place as most of those suggestion do. The 
solution I have adopted for the main case where this causes me problems 
is to split the classes, generics, and methods into one package, and the 
user functions into another. For example, if you have rootogram.default 
in a package called vcdClasses and exported it, then both vcd and 
vcdExtra can import it, but if it is not in their Depends line then it 
will not be visible to a user that executes library(vcd) or 
library(vcdExtra).

Beware that there is currently a small gotcha if the generics are S3, 
which was discussed recently and a patch submitted by Henrik Bengtsson 
(See Re: [Rd] "False" warning on "replacing previous import" when 
re-exporting identical object .)


Although there has been much moaning about these changes, including my 
own, I think the general logic is a real improvement. The way I think of 
it, the namespace imports for a package provide the equivalent of a 
search path for functions in the package, which is not changed by what 
packages a user or other packages attach or import. Thus a package 
developer has much more certain control over where the functions used by 
the package will come from. This is a trade-off for safety rather than 
convenience, thus the moaning. I am a complete newbie on this, but there 
seems to be a pretty good unofficial description at 
http://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/.

> Suggests:
> ca,gmodels,Fahrmeir,effects,VGAM,plyr,rgl,lmtest,MASS,nnet,ggplot2,Sleuth2,car

If it is only in Suggests you can refer to it in the example by 
MASS::loglm(), or require(MASS)/library(MASS). (I might have that wrong, 
at least one works but I'm not certain of both.)
>
>
> and the vcd DESCRIPTION has
>
> Depends: R (>= 2.4.0), grid, stats
> Suggests: KernSmooth, mvtnorm, kernlab, HSAUR, coin
> Imports: utils, MASS, grDevices, colorspace

Probably grid and stats should be in Imports.

>
> so, in an R 3.0.0 console, library(vcdExtra) loads vcd and its
> dependencies:
>
>  > library(vcdExtra)
> Loading required package: vcd
> Loading required package: MASS
> Loading required package: grid
> Loading required package: colorspace
> Loading required package: gnm
> Warning messages:
> 1: package ?vcd? was built under R version 3.0.1
> 2: package ?MASS? was built under R version 3.0.1
>  >
>
> Note: these CRAN errors do not occur on R-Forge, using R version 3.0.1

Are you actually getting anything to build on R-forge? All my packages 
have been stuck for a couple of weeks, as have many others.

Paul

> Patched (2013-08-21 r63645)
> and the latest devel version (0.5-11) of vcdExtra.
>
> -Michael
>


From hb at biostat.ucsf.edu  Thu Sep 12 19:21:47 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 12 Sep 2013 10:21:47 -0700
Subject: [Rd] Importing packages in Depend
In-Reply-To: <1378993761415-4675947.post@n4.nabble.com>
References: <1378993761415-4675947.post@n4.nabble.com>
Message-ID: <CAFDcVCQeZKqd5gfQ_+NRufpNGsYW8vaoLrfd-d22xZSaxO878Q@mail.gmail.com>

On Thu, Sep 12, 2013 at 6:49 AM, Benjamin Hofner <benjamin.hofner at fau.de> wrote:
> Hi,
>
> I am currently preparing a new version of my package papeR. When I run R CMD
> check using the development version of R I get the following note:
>
> Package in Depends field not imported from: ?nlme?, ?lme4?, ?survival?
>   These packages needs to imported from for the case when
>   this namespace is loaded but not attached.
>
> I now have problems to fix this issue. It is easy to get rid of two of the
> three package warnings by using
>
> import(lme4)
> import(survival)
>
> in my NAMESPACE. Yet, I cannot import nlme as I then get the following
> warnings:
>
> Warning: replacing previous import ?VarCorr? when loading ?lme4?
> Warning: replacing previous import ?lmList? when loading ?lme4?

This happens because 'lme4' re-exports the generic function VarCorr()
that 'nlme' already exports.  R considers this to be a conflict and
generates a warnings, which is detected by 'R CMD check'.   I've been
trying to argue that this warning is unnecessary/not correct because
in these cases, the two objects in conflict are actually the same
identical object.  You can see this by:

> nlme::VarCorr
function (x, sigma = 1, rdig = 3)
UseMethod("VarCorr")
<bytecode: 0x00000000111eb728>
<environment: namespace:nlme>

> lme4::VarCorr
function (x, sigma = 1, rdig = 3)
UseMethod("VarCorr")
<bytecode: 0x00000000111eb728>
<environment: namespace:nlme>

Note how they are both in the same namespace, i.e.

> identical(lme4::VarCorr, nlme::VarCorr)
[1] TRUE


I've submitted a patch for this 'Bug 15451 - PATCH:
namespaceImportFrom() not to warn when the identical object is
imported twice' on 2013-09-10
[https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15451].  The
tricky part is to convince R-core.

Otherwise, the only solution I know of is either to use importFrom():s
or to convince the author of 'lme4' to remove that re-export, which
may not be possible.

/Henrik

>
> I know that nlme is imported in lme4 but I cannot import both at the same
> time. Can anyone help me here? I do *not* want or can use importFrom as I
> rely on multiple functions and also rely on non-exported methods such as
> summary.lme().
>
> Thanks and all the best,
> Benjamin
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Importing-packages-in-Depend-tp4675947.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Sep 12 19:37:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Sep 2013 13:37:29 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5231C3E3.3050007@yorku.ca>
References: <5231C3E3.3050007@yorku.ca>
Message-ID: <5231FBD9.6050802@gmail.com>

On 12/09/2013 9:38 AM, Michael Friendly wrote:
> I received the following email note re: the vcdExtra package
>
> > A vcd update has shown that packages TIMP and vcdExtra are not
> > declaring their dependence on colorspace/MASS: see
> >
> > http://cran.r-project.org/web/checks/check_results_vcdExtra.html
> But, I can't see what to do to avoid this, nor understand what has
> changed in R devel.
>
> Sure enough, CRAN now reports errors in examples using MASS::loglm(),
> using R Under development (unstable) (2013-09-11 r63906)
>
>   > Caesar.mod0 <- loglm(~Infection + (Risk*Antibiotics*Planned),
> data=Caesar)
> Error: could not find function "loglm"

I think this one would be fine if you had library(MASS) or require(MASS) 
or (probably best) used MASS::loglm explicitly.  It may be that in the 
past some other package put MASS on the search list, and that's why it 
worked before.

The distinction is between "loading" and "attaching" a package. Loading 
it (which would be done if you had MASS::loglm, or imported it) 
guarantees that the package is initialized and in memory, but doesn't 
make it visible to the user without the explicit MASS:: prefix.  
Attaching it first loads it, then modifies the user's search list so the 
user can see it.

Loading is less intrusive, so it's preferred over attaching.  Both 
library() and require() would attach it.

Duncan Murdoch
>
> In DESCRIPTION I have
> Depends: R (>= 2.10), vcd, gnm (>= 1.0.3)
> Suggests:
> ca,gmodels,Fahrmeir,effects,VGAM,plyr,rgl,lmtest,MASS,nnet,ggplot2,Sleuth2,car
>
> and the vcd DESCRIPTION has
>
> Depends: R (>= 2.4.0), grid, stats
> Suggests: KernSmooth, mvtnorm, kernlab, HSAUR, coin
> Imports: utils, MASS, grDevices, colorspace
>
> so, in an R 3.0.0 console, library(vcdExtra) loads vcd and its dependencies:
>
>   > library(vcdExtra)
> Loading required package: vcd
> Loading required package: MASS
> Loading required package: grid
> Loading required package: colorspace
> Loading required package: gnm
> Warning messages:
> 1: package ?vcd? was built under R version 3.0.1
> 2: package ?MASS? was built under R version 3.0.1
>   >
>
> Note: these CRAN errors do not occur on R-Forge, using R version 3.0.1
> Patched (2013-08-21 r63645)
> and the latest devel version (0.5-11) of vcdExtra.
>
> -Michael
>


From alku at dtu.dk  Fri Sep 13 13:44:53 2013
From: alku at dtu.dk (alku)
Date: Fri, 13 Sep 2013 04:44:53 -0700 (PDT)
Subject: [Rd] R CMD check fails in R-devel r63910
Message-ID: <1379072693241-4676046.post@n4.nabble.com>

Hi,

The R CMD check is successful in R 3.0.1 but fails to install package
lmerTest under R-devel r63910, 
Here is what I get:

** preparing package for lazy loading
Error in reconcilePropertiesAndPrototype(name, slots, prototype,
superClasses,  : 
  no definition was found for superclass "merMod" in the specification of
class "merModLmerTest"

In DESCRIPTION file I have:
Depends:  Matrix, stats, methods, lme4
Imports: numDeriv, MASS, Hmisc, gplots, pbkrtest

I have classes.R file where I specify that "merModLmerTest" class should
inherit "merMod":

merModLmerTest <- setClass("merModLmerTest", contains = "merMod")

But it seems like in R devel r63910 this line cannot be seen...

This error I have seen for a few days

Alexandra



--
View this message in context: http://r.789695.n4.nabble.com/R-CMD-check-fails-in-R-devel-r63910-tp4676046.html
Sent from the R devel mailing list archive at Nabble.com.


From michael.weylandt at gmail.com  Fri Sep 13 13:57:49 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Fri, 13 Sep 2013 07:57:49 -0400
Subject: [Rd] R CMD check fails in R-devel r63910
In-Reply-To: <1379072693241-4676046.post@n4.nabble.com>
References: <1379072693241-4676046.post@n4.nabble.com>
Message-ID: <865A3576-16BB-4CE3-A823-134CFDC72016@gmail.com>



On Sep 13, 2013, at 7:44, alku <alku at dtu.dk> wrote:

> Hi,
> 
> The R CMD check is successful in R 3.0.1 but fails to install package
> lmerTest under R-devel r63910, 
> Here is what I get:
> 
> ** preparing package for lazy loading
> Error in reconcilePropertiesAndPrototype(name, slots, prototype,
> superClasses,  : 
>  no definition was found for superclass "merMod" in the specification of
> class "merModLmerTest"

The line you point out below isn't relevant to this error: it's saying it can't find a definition of merMod and that it knows you meant to define one since it's part of merModLmerTest. 


> 
> In DESCRIPTION file I have:
> Depends:  Matrix, stats, methods, lme4
> Imports: numDeriv, MASS, Hmisc, gplots, pbkrtest
> 
> I have classes.R file where I specify that "merModLmerTest" class should
> inherit "merMod":
> 
> merModLmerTest <- setClass("merModLmerTest", contains = "merMod")

Which would be trouble if you don't define "merMod" elsewhere. 

M


> 
> But it seems like in R devel r63910 this line cannot be seen...
> 
> This error I have seen for a few days
> 
> Alexandra
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/R-CMD-check-fails-in-R-devel-r63910-tp4676046.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From friendly at yorku.ca  Fri Sep 13 14:31:55 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 13 Sep 2013 08:31:55 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5231FBD9.6050802@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
Message-ID: <523305BB.7090802@yorku.ca>

On 9/12/2013 1:37 PM, Duncan Murdoch wrote:
>
> I think this one would be fine if you had library(MASS) or 
> require(MASS) or (probably best) used MASS::loglm explicitly.  It may 
> be that in the past some other package put MASS on the search list, 
> and that's why it worked before.
>
> The distinction is between "loading" and "attaching" a package. 
> Loading it (which would be done if you had MASS::loglm, or imported 
> it) guarantees that the package is initialized and in memory, but 
> doesn't make it visible to the user without the explicit MASS:: 
> prefix.  Attaching it first loads it, then modifies the user's search 
> list so the user can see it.
>
> Loading is less intrusive, so it's preferred over attaching.  Both 
> library() and require() would attach it.
>
Thanks for this explanation, but I'm still confused about how to avoid 
the wrath of the CRAN-devel
daemon, whose appetite for new morsels of developer flesh seems ever 
increasing and makes
keeping even a stable package up-to-date a moving target.  Perhaps such 
changes in R devel
should be announced on this list for public comment before they are 
enforced in R CMD check.

In vcdExtra, I use MASS::loglm in ~ 6 .Rd examples, a vignette, and also 
provide R code that
extends *.loglm methods.  All of this previously worked by including 
Suggests: MASS, ...
Changing this to Imports: MASS seems rather heavy-handed; I don't really 
want/need all of MASS
in my namespace, and using MASS::loglm in examples seems ugly.  For now, 
I'll use
require(MASS) in each example.

> Attaching it first loads it, then modifies the user's search list so 
> the user can see it. 
Which directive does this?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ripley at stats.ox.ac.uk  Fri Sep 13 15:11:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Sep 2013 14:11:38 +0100
Subject: [Rd] R CMD check fails in R-devel r63910
In-Reply-To: <1379072693241-4676046.post@n4.nabble.com>
References: <1379072693241-4676046.post@n4.nabble.com>
Message-ID: <52330F0A.8050301@stats.ox.ac.uk>

This seems to be nothing to do with R-devel, which has none of those 
classes.

Note that the versions of lme4 currently offered by CRAN for R 3.0.1 and 
R-devel are different.  I expect that is the root of the confusion, 
although as far as I know the one with class "merMod" is the one for 
R-devel.

But the posting guide applies: you have not supplied the 'at a minimum' 
information asked for nor a reproducible example.

n 13/09/2013 12:44, alku wrote:
> Hi,
>
> The R CMD check is successful in R 3.0.1 but fails to install package
> lmerTest under R-devel r63910,
> Here is what I get:
>
> ** preparing package for lazy loading
> Error in reconcilePropertiesAndPrototype(name, slots, prototype,
> superClasses,  :
>    no definition was found for superclass "merMod" in the specification of
> class "merModLmerTest"
>
> In DESCRIPTION file I have:
> Depends:  Matrix, stats, methods, lme4
> Imports: numDeriv, MASS, Hmisc, gplots, pbkrtest
>
> I have classes.R file where I specify that "merModLmerTest" class should
> inherit "merMod":
>
> merModLmerTest <- setClass("merModLmerTest", contains = "merMod")
>
> But it seems like in R devel r63910 this line cannot be seen...
>
> This error I have seen for a few days
>
> Alexandra



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Fri Sep 13 15:51:19 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Sep 2013 09:51:19 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <523305BB.7090802@yorku.ca>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca>
Message-ID: <52331857.8090904@gmail.com>

On 13/09/2013 8:31 AM, Michael Friendly wrote:
> On 9/12/2013 1:37 PM, Duncan Murdoch wrote:
> >
> > I think this one would be fine if you had library(MASS) or
> > require(MASS) or (probably best) used MASS::loglm explicitly.  It may
> > be that in the past some other package put MASS on the search list,
> > and that's why it worked before.
> >
> > The distinction is between "loading" and "attaching" a package.
> > Loading it (which would be done if you had MASS::loglm, or imported
> > it) guarantees that the package is initialized and in memory, but
> > doesn't make it visible to the user without the explicit MASS::
> > prefix.  Attaching it first loads it, then modifies the user's search
> > list so the user can see it.
> >
> > Loading is less intrusive, so it's preferred over attaching.  Both
> > library() and require() would attach it.
> >
> Thanks for this explanation, but I'm still confused about how to avoid
> the wrath of the CRAN-devel
> daemon, whose appetite for new morsels of developer flesh seems ever
> increasing and makes
> keeping even a stable package up-to-date a moving target.  Perhaps such
> changes in R devel
> should be announced on this list for public comment before they are
> enforced in R CMD check.
Changes are generally announced in the NEWS.Rd file long before release, 
but R-devel is an unreleased version, so you won't see the news until it 
is there.  Announcing things that nobody can try leads to fewer useful 
comments than putting them into R-devel where at least people can see 
what is really happening.
>
> In vcdExtra, I use MASS::loglm in ~ 6 .Rd examples, a vignette, and also
> provide R code that
> extends *.loglm methods.  All of this previously worked by including
> Suggests: MASS, ...
> Changing this to Imports: MASS seems rather heavy-handed; I don't really
> want/need all of MASS
> in my namespace, and using MASS::loglm in examples seems ugly.  For now,
> I'll use
> require(MASS) in each example.

If you need a small number of things from MASS in your package code, 
then importing them explicitly is definitely the way to go, e.g. 
importFrom(MASS, loglm).  If you only use them in examples, I wouldn't 
do that, I'd recommend Suggests and use the MASS:: prefix. Whether that 
is ugly is a matter of taste:  it makes it clear to a user where that 
function came from, and doesn't potentially hide objects from other 
packages later in the search path.

On the other hand, require(pkg) is really simple; we have no equivalent 
function that only does the loading, without attaching.
So it's hard to write

if (requireLoadable(MASS)) {
   MASS::loglm( ... )
}

>
> > Attaching it first loads it, then modifies the user's search list so
> > the user can see it.
> Which directive does this?

library() and require() both do it.

Duncan Murdoch
>


From Thomas.Petzoldt at tu-dresden.de  Fri Sep 13 16:01:44 2013
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 13 Sep 2013 16:01:44 +0200
Subject: [Rd] numerical issue in contour.default?
Message-ID: <52331AC8.3060601@tu-dresden.de>

Dear R developers,

I found a small issue while plotting contours of data containing both
"usual" and "very small" numbers. It appeared with both R 3.0.1 and
R-Devel on Windows, and I could reproduce it on Linux. Would it be
possible to solve this before the upcoming release?

Thanks a lot for developing this great software!

Thomas


Example:
########


set.seed(357)
z1 <- matrix(runif(100, -1e-180, 1e-180), nrow = 10)
contour(z1)    # ok

z2 <- matrix(c(runif(50, -1, 1), runif(50, -1e-180, 1e-180)), nrow = 10)
contour(z2)   # Error in contour.default(z) : k != 2 or 4

contour(z2 * 1e20)        # 20 worked, 19 produced error
contour(round(z2, 179))   # rounding to 179 digits works but not 180


> sessionInfo()
R Under development (unstable) (2013-09-11 r63910)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base





-- 
Dr. Thomas Petzoldt
Technische Universitaet Dresden
Faculty of Environmental Sciences
Institute of Hydrobiology
01062 Dresden, Germany

E-Mail: thomas.petzoldt at tu-dresden.de
http://tu-dresden.de/Members/thomas.petzoldt


From edd at debian.org  Fri Sep 13 16:11:43 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 13 Sep 2013 09:11:43 -0500
Subject: [Rd] Fortune! (Re:  declaring package dependencies)
In-Reply-To: <523305BB.7090802@yorku.ca>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca>
Message-ID: <21043.7455.265104.657534@max.nulle.part>


On 13 September 2013 at 08:31, Michael Friendly wrote:
| Thanks for this explanation, but I'm still confused about how to avoid 
| the wrath of the CRAN-devel daemon, whose appetite for new morsels of
| developer flesh seems ever increasing and makes keeping even a stable
| package up-to-date a moving target.

_Obviously_ a fortunes candidate. CCing Achim.

[ And I informed my first-born that her time with us will surely be limited
  as I expect CRAN to demand every submitters first child any day now ... ]

| Perhaps such changes in R devel should be announced on this list for public
| comment before they are enforced in R CMD check.

Many of us have suggested that many times before, but CRAN has the longer
stick and simply refuses to play along. 

"Eventually" the tides will turn and some of us will be fed up enough and
stop uploading.  But so far we still have an (uneasy?) truce, and everybody
is playing (fighting?) along.  

And don't even get me started on the state of r-forge build services...

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Fri Sep 13 16:14:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Sep 2013 10:14:44 -0400
Subject: [Rd] numerical issue in contour.default?
In-Reply-To: <52331AC8.3060601@tu-dresden.de>
References: <52331AC8.3060601@tu-dresden.de>
Message-ID: <52331DD4.5020807@gmail.com>

On 13/09/2013 10:01 AM, Thomas Petzoldt wrote:
> Dear R developers,
>
> I found a small issue while plotting contours of data containing both
> "usual" and "very small" numbers. It appeared with both R 3.0.1 and
> R-Devel on Windows, and I could reproduce it on Linux. Would it be
> possible to solve this before the upcoming release?

I don't see the error in 32 bits, but I do see it in 64 bits.  I think 
it's really unlikely this will be fixed before 3.0.2, unless you send a 
well tested patch in the next few days.  Code freeze is on Wednesday.

Duncan Murdoch
>
> Thanks a lot for developing this great software!
>
> Thomas
>
>
> Example:
> ########
>
>
> set.seed(357)
> z1 <- matrix(runif(100, -1e-180, 1e-180), nrow = 10)
> contour(z1)    # ok
>
> z2 <- matrix(c(runif(50, -1, 1), runif(50, -1e-180, 1e-180)), nrow = 10)
> contour(z2)   # Error in contour.default(z) : k != 2 or 4
>
> contour(z2 * 1e20)        # 20 worked, 19 produced error
> contour(round(z2, 179))   # rounding to 179 digits works but not 180
>
>
> > sessionInfo()
> R Under development (unstable) (2013-09-11 r63910)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
>
>


From edd at debian.org  Fri Sep 13 16:18:54 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 13 Sep 2013 09:18:54 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <52331857.8090904@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
Message-ID: <21043.7886.743370.944182@max.nulle.part>


On 13 September 2013 at 09:51, Duncan Murdoch wrote:
| Changes are generally announced in the NEWS.Rd file long before release, 
| but R-devel is an unreleased version, so you won't see the news until it 
| is there.  Announcing things that nobody can try leads to fewer useful 
| comments than putting them into R-devel where at least people can see 
| what is really happening.

That comment makes sense _in theory_.

Yet _in practice_ it does not as many of us have been shot down by tests in
R-devel which had been implemented within a 48 hour window of the package
submission. 

Absent a time machine or psychic powers, I do not see how package developers
can reasonably be expected to cope with this.

I am not close to Python, but the little I know about their PEP system makes
me think that a process in which changes are first announced as concepts,
then discussed and refined and only thereafter implemented seems somewhat
appealing. 

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ripley at stats.ox.ac.uk  Fri Sep 13 16:37:11 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Sep 2013 15:37:11 +0100
Subject: [Rd] declaring package dependencies
In-Reply-To: <52331857.8090904@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
Message-ID: <52332317.3000607@stats.ox.ac.uk>

On 13/09/2013 14:51, Duncan Murdoch wrote:
> On 13/09/2013 8:31 AM, Michael Friendly wrote:
>> On 9/12/2013 1:37 PM, Duncan Murdoch wrote:
>> >
>> > I think this one would be fine if you had library(MASS) or
>> > require(MASS) or (probably best) used MASS::loglm explicitly.  It may
>> > be that in the past some other package put MASS on the search list,
>> > and that's why it worked before.
>> >
>> > The distinction is between "loading" and "attaching" a package.
>> > Loading it (which would be done if you had MASS::loglm, or imported
>> > it) guarantees that the package is initialized and in memory, but
>> > doesn't make it visible to the user without the explicit MASS::
>> > prefix.  Attaching it first loads it, then modifies the user's search
>> > list so the user can see it.
>> >
>> > Loading is less intrusive, so it's preferred over attaching.  Both
>> > library() and require() would attach it.
>> >
>> Thanks for this explanation, but I'm still confused about how to avoid
>> the wrath of the CRAN-devel
>> daemon, whose appetite for new morsels of developer flesh seems ever
>> increasing and makes
>> keeping even a stable package up-to-date a moving target.  Perhaps such
>> changes in R devel
>> should be announced on this list for public comment before they are
>> enforced in R CMD check.
> Changes are generally announced in the NEWS.Rd file long before release,
> but R-devel is an unreleased version, so you won't see the news until it
> is there.  Announcing things that nobody can try leads to fewer useful
> comments than putting them into R-devel where at least people can see
> what is really happening.
>>
>> In vcdExtra, I use MASS::loglm in ~ 6 .Rd examples, a vignette, and also
>> provide R code that
>> extends *.loglm methods.  All of this previously worked by including
>> Suggests: MASS, ...
>> Changing this to Imports: MASS seems rather heavy-handed; I don't really
>> want/need all of MASS
>> in my namespace, and using MASS::loglm in examples seems ugly.  For now,
>> I'll use
>> require(MASS) in each example.
>
> If you need a small number of things from MASS in your package code,
> then importing them explicitly is definitely the way to go, e.g.
> importFrom(MASS, loglm).  If you only use them in examples, I wouldn't
> do that, I'd recommend Suggests and use the MASS:: prefix. Whether that
> is ugly is a matter of taste:  it makes it clear to a user where that
> function came from, and doesn't potentially hide objects from other
> packages later in the search path.
>
> On the other hand, require(pkg) is really simple; we have no equivalent
> function that only does the loading, without attaching.
> So it's hard to write
>
> if (requireLoadable(MASS)) {
>    MASS::loglm( ... )
> }

?requireNamespace.



>
>>
>> > Attaching it first loads it, then modifies the user's search list so
>> > the user can see it.
>> Which directive does this?
>
> library() and require() both do it.
>
> Duncan Murdoch
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Fri Sep 13 16:38:09 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Sep 2013 10:38:09 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <21043.7886.743370.944182@max.nulle.part>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
Message-ID: <52332351.4070001@gmail.com>

On 13/09/2013 10:18 AM, Dirk Eddelbuettel wrote:
> On 13 September 2013 at 09:51, Duncan Murdoch wrote:
> | Changes are generally announced in the NEWS.Rd file long before release,
> | but R-devel is an unreleased version, so you won't see the news until it
> | is there.  Announcing things that nobody can try leads to fewer useful
> | comments than putting them into R-devel where at least people can see
> | what is really happening.
>
> That comment makes sense _in theory_.
>
> Yet _in practice_ it does not as many of us have been shot down by tests in
> R-devel which had been implemented within a 48 hour window of the package
> submission.

It sounds as though you are talking about CRAN here, not R.  I can't 
speak for CRAN.

>
> Absent a time machine or psychic powers, I do not see how package developers
> can reasonably be expected to cope with this.

I'm a CRAN user as a package developer, and I do get emails about 
changes, but I don't find them overwhelming, and I don't recall 
receiving any that were irrational.  Generally the package is improved 
when I follow their advice.  It has happened that I have been slower 
than they liked in responding, but the world didn't end.

I imagine Rcpp pushes the limits more than my packages do, but I think 
most developers can cope.  After all, the number of packages on CRAN is 
increasing, not decreasing.

Duncan Murdoch

>
> I am not close to Python, but the little I know about their PEP system makes
> me think that a process in which changes are first announced as concepts,
> then discussed and refined and only thereafter implemented seems somewhat
> appealing.
>
> Dirk
>


From ripley at stats.ox.ac.uk  Fri Sep 13 16:44:03 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Sep 2013 15:44:03 +0100
Subject: [Rd] numerical issue in contour.default?
In-Reply-To: <52331DD4.5020807@gmail.com>
References: <52331AC8.3060601@tu-dresden.de> <52331DD4.5020807@gmail.com>
Message-ID: <523324B3.5010603@stats.ox.ac.uk>

On 13/09/2013 15:14, Duncan Murdoch wrote:
> On 13/09/2013 10:01 AM, Thomas Petzoldt wrote:
>> Dear R developers,
>>
>> I found a small issue while plotting contours of data containing both
>> "usual" and "very small" numbers. It appeared with both R 3.0.1 and
>> R-Devel on Windows, and I could reproduce it on Linux. Would it be
>> possible to solve this before the upcoming release?
>
> I don't see the error in 32 bits, but I do see it in 64 bits.  I think
> it's really unlikely this will be fixed before 3.0.2, unless you send a
> well tested patch in the next few days.  Code freeze is on Wednesday.

And not even then: we would not have time to do sufficiently extensive 
checking.

Reporting to bugs.r-project.org with a patch would get the process rolling.

>
> Duncan Murdoch
>>
>> Thanks a lot for developing this great software!
>>
>> Thomas
>>
>>
>> Example:
>> ########
>>
>>
>> set.seed(357)
>> z1 <- matrix(runif(100, -1e-180, 1e-180), nrow = 10)
>> contour(z1)    # ok
>>
>> z2 <- matrix(c(runif(50, -1, 1), runif(50, -1e-180, 1e-180)), nrow = 10)
>> contour(z2)   # Error in contour.default(z) : k != 2 or 4
>>
>> contour(z2 * 1e20)        # 20 worked, 19 produced error
>> contour(round(z2, 179))   # rounding to 179 digits works but not 180
>>
>>
>> > sessionInfo()
>> R Under development (unstable) (2013-09-11 r63910)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Fri Sep 13 16:46:08 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Sep 2013 10:46:08 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <52332317.3000607@stats.ox.ac.uk>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<52332317.3000607@stats.ox.ac.uk>
Message-ID: <52332530.1060805@gmail.com>

On 13/09/2013 10:37 AM, Prof Brian Ripley wrote:
> On 13/09/2013 14:51, Duncan Murdoch wrote:
> > On 13/09/2013 8:31 AM, Michael Friendly wrote:
> >> On 9/12/2013 1:37 PM, Duncan Murdoch wrote:
> >> >
> >> > I think this one would be fine if you had library(MASS) or
> >> > require(MASS) or (probably best) used MASS::loglm explicitly.  It may
> >> > be that in the past some other package put MASS on the search list,
> >> > and that's why it worked before.
> >> >
> >> > The distinction is between "loading" and "attaching" a package.
> >> > Loading it (which would be done if you had MASS::loglm, or imported
> >> > it) guarantees that the package is initialized and in memory, but
> >> > doesn't make it visible to the user without the explicit MASS::
> >> > prefix.  Attaching it first loads it, then modifies the user's search
> >> > list so the user can see it.
> >> >
> >> > Loading is less intrusive, so it's preferred over attaching.  Both
> >> > library() and require() would attach it.
> >> >
> >> Thanks for this explanation, but I'm still confused about how to avoid
> >> the wrath of the CRAN-devel
> >> daemon, whose appetite for new morsels of developer flesh seems ever
> >> increasing and makes
> >> keeping even a stable package up-to-date a moving target.  Perhaps such
> >> changes in R devel
> >> should be announced on this list for public comment before they are
> >> enforced in R CMD check.
> > Changes are generally announced in the NEWS.Rd file long before release,
> > but R-devel is an unreleased version, so you won't see the news until it
> > is there.  Announcing things that nobody can try leads to fewer useful
> > comments than putting them into R-devel where at least people can see
> > what is really happening.
> >>
> >> In vcdExtra, I use MASS::loglm in ~ 6 .Rd examples, a vignette, and also
> >> provide R code that
> >> extends *.loglm methods.  All of this previously worked by including
> >> Suggests: MASS, ...
> >> Changing this to Imports: MASS seems rather heavy-handed; I don't really
> >> want/need all of MASS
> >> in my namespace, and using MASS::loglm in examples seems ugly.  For now,
> >> I'll use
> >> require(MASS) in each example.
> >
> > If you need a small number of things from MASS in your package code,
> > then importing them explicitly is definitely the way to go, e.g.
> > importFrom(MASS, loglm).  If you only use them in examples, I wouldn't
> > do that, I'd recommend Suggests and use the MASS:: prefix. Whether that
> > is ugly is a matter of taste:  it makes it clear to a user where that
> > function came from, and doesn't potentially hide objects from other
> > packages later in the search path.
> >
> > On the other hand, require(pkg) is really simple; we have no equivalent
> > function that only does the loading, without attaching.
> > So it's hard to write
> >
> > if (requireLoadable(MASS)) {
> >    MASS::loglm( ... )
> > }
>
> ?requireNamespace.

Thanks.  I'll switch my packages to use that.

Duncan Murdoch


From Thomas.Petzoldt at tu-dresden.de  Fri Sep 13 16:53:31 2013
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 13 Sep 2013 16:53:31 +0200
Subject: [Rd] numerical issue in contour.default?
In-Reply-To: <523324B3.5010603@stats.ox.ac.uk>
References: <52331AC8.3060601@tu-dresden.de> <52331DD4.5020807@gmail.com>
	<523324B3.5010603@stats.ox.ac.uk>
Message-ID: <523326EB.3020309@tu-dresden.de>

On 13.09.2013 16:44, Prof Brian Ripley wrote:
> On 13/09/2013 15:14, Duncan Murdoch wrote:
>> On 13/09/2013 10:01 AM, Thomas Petzoldt wrote:
>>> Dear R developers,
>>>
>>> I found a small issue while plotting contours of data containing both
>>> "usual" and "very small" numbers. It appeared with both R 3.0.1 and
>>> R-Devel on Windows, and I could reproduce it on Linux. Would it be
>>> possible to solve this before the upcoming release?
>>
>> I don't see the error in 32 bits, but I do see it in 64 bits.  I think
>> it's really unlikely this will be fixed before 3.0.2, unless you send a
>> well tested patch in the next few days.  Code freeze is on Wednesday.

You are right, I can reproduce it only on 64 bit.

> And not even then: we would not have time to do sufficiently extensive
> checking.

Agreed, so I'll put a workaround in my package for now.

> Reporting to bugs.r-project.org with a patch would get the process rolling.

O.K., I will report it. After a look in the sources I would guess that 
it may be in:

src/main/contour-common.h

static int ctr_intersect(double z0, double z1, double zc, double *f)
{
     if ((z0 - zc) * (z1 - zc) < 0.0) {
	*f = (zc - z0) / (z1 -	z0);
	return 1;
     }
     return 0;
}


... but you are right, too many things depend on it.

Many thanks for the immediate feedback!

Thomas


From edd at debian.org  Fri Sep 13 17:02:22 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 13 Sep 2013 10:02:22 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <52332351.4070001@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
Message-ID: <21043.10494.783658.895362@max.nulle.part>


On 13 September 2013 at 10:38, Duncan Murdoch wrote:
| On 13/09/2013 10:18 AM, Dirk Eddelbuettel wrote:
| > On 13 September 2013 at 09:51, Duncan Murdoch wrote:
| > | Changes are generally announced in the NEWS.Rd file long before release,
| > | but R-devel is an unreleased version, so you won't see the news until it
| > | is there.  Announcing things that nobody can try leads to fewer useful
| > | comments than putting them into R-devel where at least people can see
| > | what is really happening.
| >
| > That comment makes sense _in theory_.
| >
| > Yet _in practice_ it does not as many of us have been shot down by tests in
| > R-devel which had been implemented within a 48 hour window of the package
| > submission.
| 
| It sounds as though you are talking about CRAN here, not R.  I can't 
| speak for CRAN.

Hah :) -- in practive you actually do as the service you built to create RSS
summaries of R NEWS changes (ie R Core) is one good way to learn about CRAN
changes as the CRAN folks use the R Core access to R itself (via R CMD check)
to effect change.

And yes: we all want change for the better. 

But we also want a more grown-up process.

| > Absent a time machine or psychic powers, I do not see how package developers
| > can reasonably be expected to cope with this.
| 
| I'm a CRAN user as a package developer, and I do get emails about 
| changes, but I don't find them overwhelming, and I don't recall 
| receiving any that were irrational.  Generally the package is improved 
| when I follow their advice.  It has happened that I have been slower 
| than they liked in responding, but the world didn't end.

Of course they improve. The long arc of history points to progress. Packages
are better than they used to be (cf NAMESPACE discussion). Nobody disputes
that.

But what we take excpetion with is the _process_ and the matter in which
changes are (NOT REALLY) communicated, or even announced with a windows.
 
| I imagine Rcpp pushes the limits more than my packages do, but I think 
| most developers can cope.  After all, the number of packages on CRAN is 
| increasing, not decreasing.

It's not so much Rcpp itself or my 20-ish packages but the fact that we (as
in the Rcpp authors) now stand behind an API that also has to accomodate
changes in R CMD check. Case in point is current (unannounced) change that
makes all Depends: Rcpp become Imports: Rcpp because of the NAMESPACE checks.

Yet I cannot really talk to 135 packages using Rcpp as I have CRAN Policy
document to point to.  

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From pgilbert902 at gmail.com  Fri Sep 13 17:42:28 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 13 Sep 2013 11:42:28 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <21043.10494.783658.895362@max.nulle.part>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
Message-ID: <52333264.10602@gmail.com>



On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
>
> On 13 September 2013 at 10:38, Duncan Murdoch wrote:
> | On 13/09/2013 10:18 AM, Dirk Eddelbuettel wrote:
> | > On 13 September 2013 at 09:51, Duncan Murdoch wrote:
> | > | Changes are generally announced in the NEWS.Rd file long before release,
> | > | but R-devel is an unreleased version, so you won't see the news until it
> | > | is there.  Announcing things that nobody can try leads to fewer useful
> | > | comments than putting them into R-devel where at least people can see
> | > | what is really happening.
> | >
> | > That comment makes sense _in theory_.
> | >
> | > Yet _in practice_ it does not as many of us have been shot down by tests in
> | > R-devel which had been implemented within a 48 hour window of the package
> | > submission.
> |
> | It sounds as though you are talking about CRAN here, not R.  I can't
> | speak for CRAN.
>
> Hah :) -- in practive you actually do as the service you built to create RSS
> summaries of R NEWS changes (ie R Core) is one good way to learn about CRAN
> changes as the CRAN folks use the R Core access to R itself (via R CMD check)
> to effect change.
>
> And yes: we all want change for the better.
>
> But we also want a more grown-up process.
>
> | > Absent a time machine or psychic powers, I do not see how package developers
> | > can reasonably be expected to cope with this.
> |
> | I'm a CRAN user as a package developer, and I do get emails about
> | changes, but I don't find them overwhelming, and I don't recall
> | receiving any that were irrational.  Generally the package is improved
> | when I follow their advice.  It has happened that I have been slower
> | than they liked in responding, but the world didn't end.
>
> Of course they improve. The long arc of history points to progress. Packages
> are better than they used to be (cf NAMESPACE discussion). Nobody disputes
> that.
>
> But what we take excpetion with is the _process_ and the matter in which
> changes are (NOT REALLY) communicated, or even announced with a windows.
>
> | I imagine Rcpp pushes the limits more than my packages do, but I think
> | most developers can cope.  After all, the number of packages on CRAN is
> | increasing, not decreasing.
>
> It's not so much Rcpp itself or my 20-ish packages but the fact that we (as
> in the Rcpp authors) now stand behind an API that also has to accomodate
> changes in R CMD check. Case in point is current (unannounced) change that
> makes all Depends: Rcpp become Imports: Rcpp because of the NAMESPACE checks.

I am a bit confused by this Dirk, so maybe I am missing something. I 
think this is still a "Note" in R-devel so you do have some time to make 
the change, at least several months, maybe more. It is not quite what I 
think of as an "announcement", more like a shot across the bow, but it 
is also not "unannounced".

More importantly, I don't think that the requirement is necessarily to 
change Depends: Rcpp to Imports: Rcpp, the requirement is to put 
imports(Rcpp) in the NAMESPACE file. I think this is so that the package 
continues to work even if the user does something with the search path. 
The decision to change Depends: Rcpp to Imports: Rcpp really depends on 
whether the package author wants Rcpp functions to be available directly 
by users without them needing to specifically attach Rcpp. They are 
available with Depends but with Imports they are just used internally in 
the package.

So, one of us is confused. Usually it is me.
Paul
>
> Yet I cannot really talk to 135 packages using Rcpp as I have CRAN Policy
> document to point to.
>
> Dirk
>


From edd at debian.org  Fri Sep 13 18:00:04 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 13 Sep 2013 11:00:04 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <52333264.10602@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
Message-ID: <21043.13956.782639.908682@max.nulle.part>


On 13 September 2013 at 11:42, Paul Gilbert wrote:
| On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
| > It's not so much Rcpp itself or my 20-ish packages but the fact that we (as
| > in the Rcpp authors) now stand behind an API that also has to accomodate
| > changes in R CMD check. Case in point is current (unannounced) change that
| > makes all Depends: Rcpp become Imports: Rcpp because of the NAMESPACE checks.
| 
| I am a bit confused by this Dirk, so maybe I am missing something. I 
| think this is still a "Note" in R-devel so you do have some time to make 
| the change, at least several months, maybe more. It is not quite what I 
| think of as an "announcement", more like a shot across the bow, but it 
| is also not "unannounced".

One package author [as in user of Rcpp and not an author of it] was told by
CRAN this week to change his package and came to me for help -- so in that
small way the CRAN "non-communication policy" is already creating more work
for me, and makes me look silly as "I don't document what Rcpp-using packages
need" as I sadly still lack the time machine or psychic powers to infer what
may get changed this weekend.
 
| More importantly, I don't think that the requirement is necessarily to 
| change Depends: Rcpp to Imports: Rcpp, the requirement is to put 
| imports(Rcpp) in the NAMESPACE file. I think this is so that the package 
| continues to work even if the user does something with the search path. 
| The decision to change Depends: Rcpp to Imports: Rcpp really depends on 
| whether the package author wants Rcpp functions to be available directly 

Rcpp is a bit of an odd-ball as you mostly need it at compile-time, and you
require very few R-level functions (but there is package initialization etc
pp).  We also only about two handful of functions, and those are for
functionality not all 135 packages use (eg Modules etc).   

But the focus here should not be on my hobby package. The focus needs to be
on how four CRAN maintainers (who do a boatload of amazing work which is
_truly_ appreciated in its thoroughness and reach) could make the life of
authors of 4800+ packages easier by communicating and planning a tad more.

| by users without them needing to specifically attach Rcpp. They are 
| available with Depends but with Imports they are just used internally in 
| the package.
| 
| So, one of us is confused. Usually it is me.

No, no, I usually keep you company. 

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jfox at mcmaster.ca  Fri Sep 13 18:15:22 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 13 Sep 2013 12:15:22 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <52331857.8090904@gmail.com>
References: <5231C3E3.3050007@yorku.ca>
	<5231FBD9.6050802@gmail.com>	<523305BB.7090802@yorku.ca>
	<52331857.8090904@gmail.com>
Message-ID: <004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>

Dear Duncan and Michael,

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Duncan Murdoch
> Sent: Friday, September 13, 2013 9:51 AM
> To: Michael Friendly
> Cc: r-devel
> Subject: Re: [Rd] declaring package dependencies
> 
> On 13/09/2013 8:31 AM, Michael Friendly wrote:
> > On 9/12/2013 1:37 PM, Duncan Murdoch wrote:
> > >
> > > I think this one would be fine if you had library(MASS) or
> > > require(MASS) or (probably best) used MASS::loglm explicitly.  It
> may
> > > be that in the past some other package put MASS on the search list,
> > > and that's why it worked before.
> > >
> > > The distinction is between "loading" and "attaching" a package.
> > > Loading it (which would be done if you had MASS::loglm, or imported
> > > it) guarantees that the package is initialized and in memory, but
> > > doesn't make it visible to the user without the explicit MASS::
> > > prefix.  Attaching it first loads it, then modifies the user's
> search
> > > list so the user can see it.
> > >
> > > Loading is less intrusive, so it's preferred over attaching.  Both
> > > library() and require() would attach it.
> > >
> > Thanks for this explanation, but I'm still confused about how to
> avoid
> > the wrath of the CRAN-devel
> > daemon, whose appetite for new morsels of developer flesh seems ever
> > increasing and makes
> > keeping even a stable package up-to-date a moving target.  Perhaps
> such
> > changes in R devel
> > should be announced on this list for public comment before they are
> > enforced in R CMD check.
> Changes are generally announced in the NEWS.Rd file long before
> release,
> but R-devel is an unreleased version, so you won't see the news until
> it
> is there.  Announcing things that nobody can try leads to fewer useful
> comments than putting them into R-devel where at least people can see
> what is really happening.
> >
> > In vcdExtra, I use MASS::loglm in ~ 6 .Rd examples, a vignette, and
> also
> > provide R code that
> > extends *.loglm methods.  All of this previously worked by including
> > Suggests: MASS, ...
> > Changing this to Imports: MASS seems rather heavy-handed; I don't
> really
> > want/need all of MASS
> > in my namespace, and using MASS::loglm in examples seems ugly.  For
> now,
> > I'll use
> > require(MASS) in each example.
> 
> If you need a small number of things from MASS in your package code,
> then importing them explicitly is definitely the way to go, e.g.
> importFrom(MASS, loglm).  If you only use them in examples, I wouldn't
> do that, I'd recommend Suggests and use the MASS:: prefix. Whether that
> is ugly is a matter of taste:  it makes it clear to a user where that
> function came from, and doesn't potentially hide objects from other
> packages later in the search path.
> 

If I understand this thread, Michael's package doesn't use loglm() -- it
provides methods for objects produced by loglm() and hence "Enhances" the
package.

> On the other hand, require(pkg) is really simple; we have no equivalent
> function that only does the loading, without attaching.
> So it's hard to write
> 
> if (requireLoadable(MASS)) {
>    MASS::loglm( ... )
> }
> 

I understand why one would want to do this sort of thing (say, using
requireNamespace), to avoid attaching the MASS package to the search path
and possibly shadowing objects on the path, but I think that most users --
as opposed to R developers -- will find the package::function( ... ) syntax
in examples not so much ugly as cryptic. I think that we have ample recent
evidence on this list that even developers (I don't exempt myself) are
confused by namespace issues. On balance, I prefer

	if (require(MASS)) {
		loglm( ...)
	}

which tells the user that it's necessary to load MASS before using loglm(). 

It would be nice if examples ran in a "sandbox," so that an example could
read something like

	library(MASS)
	loglm( ... )
	. . .

without affecting the path in the current session, and fail gracefully if
the MASS package weren't available (unlikely, of course, in the case of
MASS, but not more generally).

Best,
 John

> >
> > > Attaching it first loads it, then modifies the user's search list
> so
> > > the user can see it.
> > Which directive does this?
> 
> library() and require() both do it.
> 
> Duncan Murdoch
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gray at clhn.co  Fri Sep 13 19:52:37 2013
From: gray at clhn.co (Gray Calhoun)
Date: Fri, 13 Sep 2013 12:52:37 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>
Message-ID: <20130913175237.GA10588@calhounpc.econ.iastate.edu>

John Fox: (12:15PM on Fri, Sep 13)
[...cut...]
>I think that most users --
>as opposed to R developers -- will find the package::function( ... ) syntax
>in examples not so much ugly as cryptic. I think that we have ample recent
>evidence on this list that even developers (I don't exempt myself) are
>confused by namespace issues. On balance, I prefer
>
>	if (require(MASS)) {
>		loglm( ...)
>	}
>
>which tells the user that it's necessary to load MASS before using loglm().
>
>It would be nice if examples ran in a "sandbox," so that an example could
>read something like
>
>	library(MASS)
>	loglm( ... )
>	. . .
>
>without affecting the path in the current session, and fail gracefully if
>the MASS package weren't available (unlikely, of course, in the case of
>MASS, but not more generally).

Does assigning

     loglm <- MASS::loglm
     loglm( ... )

not work in examples anymore? (with MASS listed under 'Suggests'.)
That seems like it could address both concerns, but it would mask
loglm if it were already defined.

-- 
Gray Calhoun, Assistant Professor of Economics at Iowa State 
http://gray.clhn.co // (515) 294-6271 // 467 Heady Hall


From gmbecker at ucdavis.edu  Fri Sep 13 23:17:14 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 13 Sep 2013 14:17:14 -0700
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
Message-ID: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>

Hey all,

I've run accross what seems to be a bug in the recordPlot/replayPlot
functionality (or at least the lack of a feature which seems pretty
reasonable to expect to be there)

When drawing to a file-based graphics device (I tested with png()), the
file resulting from calling replayPlot on a recordedplot object does not
contain an identical image to that captured by the same graphics device
when used on the plot that was recorded.

Reproducible (at least for me on linux) example:

png("noreplay.png")
plot(1:10)
dev.off()

plot(1:10)
recplot = recordPlot()
png("withreplay.png")
replayPlot(recplot)
dev.off()

The resulting png files are attached. You'll notice that the noreplay.png
has the expected white background, while withoutreplay.png has no/a
transparent background.

This seems likely to be related to the note in ?dev.print :
"
 Note that these functions copy the _device region_ and not a plot:
     the background colour of the device surface is part of what is
     copied.  Most screen devices default to a transparent background,
     which is probably not what is needed when copying to a device such
     as ?png?.
"

Now this may be as intended because it is "not allowed" to draw
recordedplot objects to devices other than the one they were recorded on
(AFAIK the primary purpose of recordedplot objects is fast redraws
internally), but alas that is what my use-case calls for. Furthermore,  I
don't think I'm alone in thinking wistfully about how useful it would be to
have an actual, transportable object class which can fully represent an R
plot in any R-based context.

I'm pretty sure I can compile a patch which does this if it would be
considered, though there would be a delay of a week or two before I could
burrow out from under the mound of other stuff I currently need to be doing

sessionInfo below, and I have also confirmed that the behavior remains
unchanged in the current trunk.

Thanks,
~G

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.0.1 tools_3.0.1

-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis
-------------- next part --------------
A non-text attachment was scrubbed...
Name: noreplay.png
Type: image/png
Size: 4146 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130913/9fae4fc1/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: withreplay.png
Type: image/png
Size: 4184 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130913/9fae4fc1/attachment-0001.png>

From Achim.Zeileis at uibk.ac.at  Sat Sep 14 10:26:52 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 14 Sep 2013 10:26:52 +0200 (CEST)
Subject: [Rd] Fortune! (Re:  declaring package dependencies)
In-Reply-To: <21043.7455.265104.657534@max.nulle.part>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca>
	<21043.7455.265104.657534@max.nulle.part>
Message-ID: <alpine.DEB.2.10.1309141026210.5262@paninaro.uibk.ac.at>

Thanks, added to the devel-version on R-Forge.
Z

On Fri, 13 Sep 2013, Dirk Eddelbuettel wrote:

>
> On 13 September 2013 at 08:31, Michael Friendly wrote:
> | Thanks for this explanation, but I'm still confused about how to avoid
> | the wrath of the CRAN-devel daemon, whose appetite for new morsels of
> | developer flesh seems ever increasing and makes keeping even a stable
> | package up-to-date a moving target.
>
> _Obviously_ a fortunes candidate. CCing Achim.
>
> [ And I informed my first-born that her time with us will surely be limited
>  as I expect CRAN to demand every submitters first child any day now ... ]
>
> | Perhaps such changes in R devel should be announced on this list for public
> | comment before they are enforced in R CMD check.
>
> Many of us have suggested that many times before, but CRAN has the longer
> stick and simply refuses to play along.
>
> "Eventually" the tides will turn and some of us will be fed up enough and
> stop uploading.  But so far we still have an (uneasy?) truce, and everybody
> is playing (fighting?) along.
>
> And don't even get me started on the state of r-forge build services...
>
> Dirk
>
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>


From murdoch.duncan at gmail.com  Sat Sep 14 15:04:12 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 14 Sep 2013 09:04:12 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <21043.13956.782639.908682@max.nulle.part>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
Message-ID: <52345ECC.7090407@gmail.com>

On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>
> On 13 September 2013 at 11:42, Paul Gilbert wrote:
> | On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
> | > It's not so much Rcpp itself or my 20-ish packages but the fact that we (as
> | > in the Rcpp authors) now stand behind an API that also has to accomodate
> | > changes in R CMD check. Case in point is current (unannounced) change that
> | > makes all Depends: Rcpp become Imports: Rcpp because of the NAMESPACE checks.
> |
> | I am a bit confused by this Dirk, so maybe I am missing something. I
> | think this is still a "Note" in R-devel so you do have some time to make
> | the change, at least several months, maybe more. It is not quite what I
> | think of as an "announcement", more like a shot across the bow, but it
> | is also not "unannounced".
>
> One package author [as in user of Rcpp and not an author of it] was told by
> CRAN this week to change his package and came to me for help -- so in that
> small way the CRAN "non-communication policy" is already creating more work
> for me, and makes me look silly as "I don't document what Rcpp-using packages
> need" as I sadly still lack the time machine or psychic powers to infer what
> may get changed this weekend.
>
> | More importantly, I don't think that the requirement is necessarily to
> | change Depends: Rcpp to Imports: Rcpp, the requirement is to put
> | imports(Rcpp) in the NAMESPACE file. I think this is so that the package
> | continues to work even if the user does something with the search path.
> | The decision to change Depends: Rcpp to Imports: Rcpp really depends on
> | whether the package author wants Rcpp functions to be available directly
>
> Rcpp is a bit of an odd-ball as you mostly need it at compile-time, and you
> require very few R-level functions (but there is package initialization etc
> pp).  We also only about two handful of functions, and those are for
> functionality not all 135 packages use (eg Modules etc).
>
> But the focus here should not be on my hobby package. The focus needs to be
> on how four CRAN maintainers (who do a boatload of amazing work which is
> _truly_ appreciated in its thoroughness and reach) could make the life of
> authors of 4800+ packages easier by communicating and planning a tad more.

Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it 
helps me a lot, but if they only did a little bit more work it would 
help me even more."

I suspect they'd be more receptive to suggestions that had them doing 
less work, not more.

Duncan Murdoch

>
> | by users without them needing to specifically attach Rcpp. They are
> | available with Depends but with Imports they are just used internally in
> | the package.
> |
> | So, one of us is confused. Usually it is me.
>
> No, no, I usually keep you company.
>
> Dirk
>


From edd at debian.org  Sat Sep 14 15:14:48 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 14 Sep 2013 08:14:48 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <52345ECC.7090407@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com>
Message-ID: <21044.24904.252175.502172@max.nulle.part>


On 14 September 2013 at 09:04, Duncan Murdoch wrote:
| On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
| > But the focus here should not be on my hobby package. The focus needs to be
| > on how four CRAN maintainers (who do a boatload of amazing work which is
| > _truly_ appreciated in its thoroughness and reach) could make the life of
| > authors of 4800+ packages easier by communicating and planning a tad more.
| 
| Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it 
| helps me a lot, but if they only did a little bit more work it would 
| help me even more."
| 
| I suspect they'd be more receptive to suggestions that had them doing 
| less work, not more.

Presumably that also holds for the authors of the 4800+ packages.  

But my point is not the about "less", it is about "more predictable".
Currently, the system appears to be anything but.  We can do better.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From brian at braverock.com  Sat Sep 14 15:16:50 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 14 Sep 2013 08:16:50 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <52345ECC.7090407@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com>
Message-ID: <523461C2.2060304@braverock.com>

On 09/14/2013 08:04 AM, Duncan Murdoch wrote:
 >> On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>> But the focus here should not be on my hobby package. The focus
>> needs to be on how four CRAN maintainers (who do a boatload of
>> amazing work which is _truly_ appreciated in its thoroughness and
>> reach) could make the life of authors of 4800+ packages easier by
>> communicating and planning a tad more.
>
> Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
> helps me a lot, but if they only did a little bit more work it would
> help me even more."
>
> I suspect they'd be more receptive to suggestions that had them doing
> less work, not more.

I think you're both right.

If the CRAN team would communicate more with this list about pending 
changes, package authors could make those changes before submitting. 
Those submissions that won't pass unannounced R-devel checks waste 
everybody's time, including the time of the CRAN team.

Not to mention, most open source projects seem to have concluded that 
more eyes on pending or proposed changes make everyone's life better in 
the long term.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From pgilbert902 at gmail.com  Sat Sep 14 18:19:11 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 14 Sep 2013 12:19:11 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <52345ECC.7090407@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com>
Message-ID: <52348C7F.5040505@gmail.com>



On 13-09-14 09:04 AM, Duncan Murdoch wrote:
> On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>>
>> On 13 September 2013 at 11:42, Paul Gilbert wrote:
>> | On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
>> | > It's not so much Rcpp itself or my 20-ish packages but the fact
>> that we (as
>> | > in the Rcpp authors) now stand behind an API that also has to
>> accomodate
>> | > changes in R CMD check. Case in point is current (unannounced)
>> change that
>> | > makes all Depends: Rcpp become Imports: Rcpp because of the
>> NAMESPACE checks.
>> |
>> | I am a bit confused by this Dirk, so maybe I am missing something. I
>> | think this is still a "Note" in R-devel so you do have some time to
>> make
>> | the change, at least several months, maybe more. It is not quite what I
>> | think of as an "announcement", more like a shot across the bow, but it
>> | is also not "unannounced".
>>
>> One package author [as in user of Rcpp and not an author of it] was
>> told by
>> CRAN this week to change his package and came to me for help -- so in
>> that
>> small way the CRAN "non-communication policy" is already creating more
>> work
>> for me, and makes me look silly as "I don't document what Rcpp-using
>> packages
>> need" as I sadly still lack the time machine or psychic powers to
>> infer what
>> may get changed this weekend.
>>
>> | More importantly, I don't think that the requirement is necessarily to
>> | change Depends: Rcpp to Imports: Rcpp, the requirement is to put
>> | imports(Rcpp) in the NAMESPACE file. I think this is so that the
>> package
>> | continues to work even if the user does something with the search path.
>> | The decision to change Depends: Rcpp to Imports: Rcpp really depends on
>> | whether the package author wants Rcpp functions to be available
>> directly
>>
>> Rcpp is a bit of an odd-ball as you mostly need it at compile-time,
>> and you
>> require very few R-level functions (but there is package
>> initialization etc
>> pp).  We also only about two handful of functions, and those are for
>> functionality not all 135 packages use (eg Modules etc).
>>
>> But the focus here should not be on my hobby package. The focus needs
>> to be
>> on how four CRAN maintainers (who do a boatload of amazing work which is
>> _truly_ appreciated in its thoroughness and reach) could make the life of
>> authors of 4800+ packages easier by communicating and planning a tad
>> more.
>
> Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
> helps me a lot, but if they only did a little bit more work it would
> help me even more."
>
> I suspect they'd be more receptive to suggestions that had them doing
> less work, not more.

Actually, this is one of the parts that I do not understand. It seems to 
me that it would be a lot less work for CRAN maintainers if the 
implications and necessary changes to packages were explained a bit more 
clearly in a forum like R-devel that many package developers actually 
read regularly. I many not fully understand how much of the response to 
package submission gets done automatically, but I do get the sense that 
there is a fairly large amount of actual human time spent dealing with 
just my submissions alone. If that is representative of all developers, 
then CRAN maintainers don't have time to do much else. (The fact that 
they do much more suggests I may not be representative.)

Two specific points have already been mentioned implicitly. CRAN 
submission testing is often done at a higher/newer level using the 
latest devel version. This results in lots of rejections for things that 
I would fix before submission, if I knew about them. If the tests were 
rolled out with R, and only later incorporated into CRAN submission 
testing, I think there would be a lot less work for the CRAN 
maintainers. (This is ignoring the possibility that CRAN submission is 
really the testing ground for the tests, and to prove the tests requires 
a fair amount of manual involvement. I'm happy to continue contributing 
to this -- I've often felt my many contribution is an endless supply of 
bugs for the checkers to catch.)

The second point is that a facility like R-forge that runs the latest 
checks, on many platforms, is really useful in order to reduce work for 
both package developers and CRAN maintainers. With R-forge broken, the 
implication for additional work for CRAN maintainers seems enormous. But 
even with it working, not all packages are kept on R-forge, and with 
package version dependencies R-forge does not really work. (i.e. I have 
to get new versions of some packages onto CRAN before the new versions 
of other packages will build on R-forge.)  Perhaps the package checking 
part of R-forge should be separated into a pre-submission clearing house 
to which packages are submitted. If they pass checks there then the 
package developer could click on a submit button to do the actual 
submission to CRAN. (Of course there needs to be a mechanism to plead 
for the fact that the test systems do not have needed resources.) 
Something like the daily, but with new pre-release versions of packages 
might actually be better than the R-forge approach, for two reasons. One 
is that package maintainers would only put packages there that they 
think are actually working. (R-forge tries to build my svn copy even 
when I know it is broken.) The second is that it would automatically 
handle the version dependency problem, since package maintainers would 
have the ability to put in place versions that should work together. 
However, this does not need to be run daily. It only needs to be run 
when the checks change, or for a package when the package changes.

Paul

>
> Duncan Murdoch
>
>>
>> | by users without them needing to specifically attach Rcpp. They are
>> | available with Depends but with Imports they are just used
>> internally in
>> | the package.
>> |
>> | So, one of us is confused. Usually it is me.
>>
>> No, no, I usually keep you company.
>>
>> Dirk
>>
>


From mdowle at mdowle.plus.com  Sat Sep 14 20:00:43 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Sat, 14 Sep 2013 19:00:43 +0100
Subject: [Rd] declaring package dependencies
Message-ID: <5234A44B.1050105@mdowle.plus.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130914/a8e4e433/attachment.pl>

From murdoch.duncan at gmail.com  Sun Sep 15 01:01:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 14 Sep 2013 19:01:33 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <21044.24904.252175.502172@max.nulle.part>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com>
	<21044.24904.252175.502172@max.nulle.part>
Message-ID: <5234EACD.7030308@gmail.com>

On 13-09-14 9:14 AM, Dirk Eddelbuettel wrote:
>
> On 14 September 2013 at 09:04, Duncan Murdoch wrote:
> | On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
> | > But the focus here should not be on my hobby package. The focus needs to be
> | > on how four CRAN maintainers (who do a boatload of amazing work which is
> | > _truly_ appreciated in its thoroughness and reach) could make the life of
> | > authors of 4800+ packages easier by communicating and planning a tad more.
> |
> | Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
> | helps me a lot, but if they only did a little bit more work it would
> | help me even more."
> |
> | I suspect they'd be more receptive to suggestions that had them doing
> | less work, not more.
>
> Presumably that also holds for the authors of the 4800+ packages.

No, I don't think it does.  What benefit do the CRAN maintainers get 
from them?

>
> But my point is not the about "less", it is about "more predictable".
> Currently, the system appears to be anything but.  We can do better.

Then go ahead.  Do better.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Sep 15 01:05:19 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 14 Sep 2013 19:05:19 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <523461C2.2060304@braverock.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com> <523461C2.2060304@braverock.com>
Message-ID: <5234EBAF.8010303@gmail.com>

On 13-09-14 9:16 AM, Brian G. Peterson wrote:
> On 09/14/2013 08:04 AM, Duncan Murdoch wrote:
>   >> On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>>> But the focus here should not be on my hobby package. The focus
>>> needs to be on how four CRAN maintainers (who do a boatload of
>>> amazing work which is _truly_ appreciated in its thoroughness and
>>> reach) could make the life of authors of 4800+ packages easier by
>>> communicating and planning a tad more.
>>
>> Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
>> helps me a lot, but if they only did a little bit more work it would
>> help me even more."
>>
>> I suspect they'd be more receptive to suggestions that had them doing
>> less work, not more.
>
> I think you're both right.
>
> If the CRAN team would communicate more with this list about pending
> changes, package authors could make those changes before submitting.
> Those submissions that won't pass unannounced R-devel checks waste
> everybody's time, including the time of the CRAN team.

Paraphrasing again:  "If the CRAN team would do this, then they would 
waste less of everyone's time."

I think you should assume that the CRAN team doesn't choose to waste 
it's own time, so in their judgment, doing more on this list would waste 
more of its time.


>
> Not to mention, most open source projects seem to have concluded that
> more eyes on pending or proposed changes make everyone's life better in
> the long term.

There are no secrets in R.  You are perfectly free to run your package 
against exactly the same version the CRAN team is using.  If you choose 
not to do so, you're the one wasting everyone's time.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Sep 15 01:20:05 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 14 Sep 2013 19:20:05 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <52348C7F.5040505@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com> <52348C7F.5040505@gmail.com>
Message-ID: <5234EF25.2000206@gmail.com>

On 13-09-14 12:19 PM, Paul Gilbert wrote:
>
>
> On 13-09-14 09:04 AM, Duncan Murdoch wrote:
>> On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>>>
>>> On 13 September 2013 at 11:42, Paul Gilbert wrote:
>>> | On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
>>> | > It's not so much Rcpp itself or my 20-ish packages but the fact
>>> that we (as
>>> | > in the Rcpp authors) now stand behind an API that also has to
>>> accomodate
>>> | > changes in R CMD check. Case in point is current (unannounced)
>>> change that
>>> | > makes all Depends: Rcpp become Imports: Rcpp because of the
>>> NAMESPACE checks.
>>> |
>>> | I am a bit confused by this Dirk, so maybe I am missing something. I
>>> | think this is still a "Note" in R-devel so you do have some time to
>>> make
>>> | the change, at least several months, maybe more. It is not quite what I
>>> | think of as an "announcement", more like a shot across the bow, but it
>>> | is also not "unannounced".
>>>
>>> One package author [as in user of Rcpp and not an author of it] was
>>> told by
>>> CRAN this week to change his package and came to me for help -- so in
>>> that
>>> small way the CRAN "non-communication policy" is already creating more
>>> work
>>> for me, and makes me look silly as "I don't document what Rcpp-using
>>> packages
>>> need" as I sadly still lack the time machine or psychic powers to
>>> infer what
>>> may get changed this weekend.
>>>
>>> | More importantly, I don't think that the requirement is necessarily to
>>> | change Depends: Rcpp to Imports: Rcpp, the requirement is to put
>>> | imports(Rcpp) in the NAMESPACE file. I think this is so that the
>>> package
>>> | continues to work even if the user does something with the search path.
>>> | The decision to change Depends: Rcpp to Imports: Rcpp really depends on
>>> | whether the package author wants Rcpp functions to be available
>>> directly
>>>
>>> Rcpp is a bit of an odd-ball as you mostly need it at compile-time,
>>> and you
>>> require very few R-level functions (but there is package
>>> initialization etc
>>> pp).  We also only about two handful of functions, and those are for
>>> functionality not all 135 packages use (eg Modules etc).
>>>
>>> But the focus here should not be on my hobby package. The focus needs
>>> to be
>>> on how four CRAN maintainers (who do a boatload of amazing work which is
>>> _truly_ appreciated in its thoroughness and reach) could make the life of
>>> authors of 4800+ packages easier by communicating and planning a tad
>>> more.
>>
>> Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
>> helps me a lot, but if they only did a little bit more work it would
>> help me even more."
>>
>> I suspect they'd be more receptive to suggestions that had them doing
>> less work, not more.
>
> Actually, this is one of the parts that I do not understand. It seems to
> me that it would be a lot less work for CRAN maintainers if the
> implications and necessary changes to packages were explained a bit more
> clearly in a forum like R-devel that many package developers actually
> read regularly.

Then why don't you explain them?  They aren't secret.

I many not fully understand how much of the response to
> package submission gets done automatically, but I do get the sense that
> there is a fairly large amount of actual human time spent dealing with
> just my submissions alone. If that is representative of all developers,
> then CRAN maintainers don't have time to do much else. (The fact that
> they do much more suggests I may not be representative.)
>
> Two specific points have already been mentioned implicitly. CRAN
> submission testing is often done at a higher/newer level using the
> latest devel version. This results in lots of rejections for things that
> I would fix before submission, if I knew about them.

Then why don't you test against R-devel before submitting?

  If the tests were
> rolled out with R, and only later incorporated into CRAN submission
> testing, I think there would be a lot less work for the CRAN
> maintainers.

I am an R core member, not a member of CRAN.  If I make a change to R, 
I'd like to know the effect it has on the corpus of CRAN and 
Bioconductor packages, but I don't have the computing resources to run 
it against all of those in a reasonable amount of time.  We have heard 
from various corporate users of R (Revolution Computing and Google are 
two) that they would like to contribute to the project, but we don't 
actually see useful contributions from them.

I don't know if you personally have influence with anyone who has such 
resources, but surely some on this list do.  So why don't they write to 
me and tell me how to use their computing resources to run proposed 
changes against all published packages?  I think it's because it's 
easier to do nothing than to do something.  It's certainly easier to say 
that it's the CRAN maintainers' fault for poor communication than it is 
to identify and address the problems.

Duncan Murdoch


  (This is ignoring the possibility that CRAN submission is
> really the testing ground for the tests, and to prove the tests requires
> a fair amount of manual involvement. I'm happy to continue contributing
> to this -- I've often felt my many contribution is an endless supply of
> bugs for the checkers to catch.)
>
> The second point is that a facility like R-forge that runs the latest
> checks, on many platforms, is really useful in order to reduce work for
> both package developers and CRAN maintainers. With R-forge broken, the
> implication for additional work for CRAN maintainers seems enormous. But
> even with it working, not all packages are kept on R-forge, and with
> package version dependencies R-forge does not really work. (i.e. I have
> to get new versions of some packages onto CRAN before the new versions
> of other packages will build on R-forge.)  Perhaps the package checking
> part of R-forge should be separated into a pre-submission clearing house
> to which packages are submitted. If they pass checks there then the
> package developer could click on a submit button to do the actual
> submission to CRAN. (Of course there needs to be a mechanism to plead
> for the fact that the test systems do not have needed resources.)
> Something like the daily, but with new pre-release versions of packages
> might actually be better than the R-forge approach, for two reasons. One
> is that package maintainers would only put packages there that they
> think are actually working. (R-forge tries to build my svn copy even
> when I know it is broken.) The second is that it would automatically
> handle the version dependency problem, since package maintainers would
> have the ability to put in place versions that should work together.
> However, this does not need to be run daily. It only needs to be run
> when the checks change, or for a package when the package changes.
>
> Paul
>
>>
>> Duncan Murdoch
>>
>>>
>>> | by users without them needing to specifically attach Rcpp. They are
>>> | available with Depends but with Imports they are just used
>>> internally in
>>> | the package.
>>> |
>>> | So, one of us is confused. Usually it is me.
>>>
>>> No, no, I usually keep you company.
>>>
>>> Dirk
>>>
>>


From edd at debian.org  Sun Sep 15 02:24:57 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 14 Sep 2013 19:24:57 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <5234EACD.7030308@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com>
	<21044.24904.252175.502172@max.nulle.part>
	<5234EACD.7030308@gmail.com>
Message-ID: <21044.65113.801072.884336@max.nulle.part>


On 14 September 2013 at 19:01, Duncan Murdoch wrote:
| On 13-09-14 9:14 AM, Dirk Eddelbuettel wrote:
| >
| > On 14 September 2013 at 09:04, Duncan Murdoch wrote:
| > | On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
| > | > But the focus here should not be on my hobby package. The focus needs to be
| > | > on how four CRAN maintainers (who do a boatload of amazing work which is
| > | > _truly_ appreciated in its thoroughness and reach) could make the life of
| > | > authors of 4800+ packages easier by communicating and planning a tad more.
| > |
| > | Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
| > | helps me a lot, but if they only did a little bit more work it would
| > | help me even more."
| > |
| > | I suspect they'd be more receptive to suggestions that had them doing
| > | less work, not more.
| >
| > Presumably that also holds for the authors of the 4800+ packages.
| 
| No, I don't think it does.  What benefit do the CRAN maintainers get 
| from them?

As explained by others in the thread, if forthcoming were more clearly
communicated, package authors would be prepared and the CRAN maintainers
would not have to explain it one-by-one as changes are implemented with no
forewarning. 

| > But my point is not the about "less", it is about "more predictable".
| > Currently, the system appears to be anything but.  We can do better.
| 
| Then go ahead.  Do better.

I am trying, eg via this discussion.

But you have now managed to sap all energy I may have had.  I am done here.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mdowle at mdowle.plus.com  Sun Sep 15 11:09:48 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Sun, 15 Sep 2013 10:09:48 +0100
Subject: [Rd] declaring package dependencies
Message-ID: <5235795C.3050903@mdowle.plus.com>


I'm a little surprised by this thread.

I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and 
that's been pretty informative in the past :
http://developer.r-project.org/RSSfeeds.html

Mainly though, I submit to winbuilder before submitting to CRAN, as the 
CRAN policies advise.  winbuilder's R-devel seems to be built daily, 
saving me the time. Since I don't have Windows it kills two birds with 
one stone.  It has caught many problems for me before submitting to CRAN 
and I can't remember it ever not responding in a reasonable time.
http://win-builder.r-project.org/upload.aspx

I've suggested before that winbuilder could be the mechanism to submit 
to CRAN rather than an ftp upload to incoming.  Only if winbuilder 
passed OK on R-devel could it then go to a human.   But iirc there was a 
technical difficulty preventing this.

Matthew


From friendly at yorku.ca  Sun Sep 15 18:52:47 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 15 Sep 2013 12:52:47 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>
References: <5231C3E3.3050007@yorku.ca>
	<5231FBD9.6050802@gmail.com>	<523305BB.7090802@yorku.ca>
	<52331857.8090904@gmail.com>
	<004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>
Message-ID: <5235E5DF.1020806@yorku.ca>

On 9/13/2013 12:15 PM, John Fox wrote:
> If I understand this thread, Michael's package doesn't use loglm() -- it
> provides methods for objects produced by loglm() and hence "Enhances" the
> package.
Well, here's the rub: vcdExtra uses MASS::loglm() in examples, and also 
in R code,
where it provides new S3 methods for loglm objects.  And, this whole 
problem only arose
after vcd (on which I Depend), modified its Imports to:

Imports: utils, MASS, grDevices, colorspace
where, previously, MASS had been a Depends (or Suggests?) there.


For my examples, the old Suggests: MASS worked, but now I've used 
require(MASS) in
each of those examples.  However, the use in R code also triggered an 
error on loglm, even
when I added
Enhances: MASS
to DESCRIPTION.

OK, so I switched to using
Imports: MASS
but even that doesn't cure the problem alone.  I then got:

* checking dependencies in R code ... NOTE
Namespace in Imports field not imported from: 'MASS'
   All declared Imports should be used.
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

but then an Error when an example using the function which called loglm()
directly was run.

> ### ** Examples
>
> data(Titanic, package="datasets")
> # variables are in the order Class, Sex, Age, Survived
> tt <- seq_loglm(Titanic)
1   model.string:  = Class
Error in eval(expr, envir, enclos) : could not find function "loglm"
Calls: seq_loglm -> eval -> eval
Execution halted


So, as several people have suggested, I changed to use MASS::loglm() in 
code,
though it still perplexes me why this is necessary.  At any rate, this 
now passes R devel.
Whew!


Thanks to a suggestion from Mattew Dowle, I'm now using winbuilder (thx, 
Uwe for this!)
and can get rather quick (< 30 min.) feedback on an R-devel build, 
whereas the
R-Forge build cycle often takes a day.

So, my workflow is  now
- R CMD check on local version in StatET
- If OK, send to winbuilder, http://win-builder.r-project.org/upload.aspx
- If OK, commit to R-Forge, and perhaps submit to CRAN if this is the 
final rev
in a development cycle.

But I still feel like I'm spending too much time on satisfying the 
unknown, new
requirements of CRAN checks.  As Dirk said (also deserving to be a fortune),

> Absent a time machine or psychic powers, I do not see how package developers
> can reasonably be expected to cope with this.
The effort by R Core members that goes into R and CRAN is certainly 
herculean and I
appreciate it very much.  Like Dirk, I'm just looking for a little more 
predictability as
CRAN evolves.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From murdoch.duncan at gmail.com  Sun Sep 15 19:34:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Sep 2013 13:34:31 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5235E5DF.1020806@yorku.ca>
References: <5231C3E3.3050007@yorku.ca>
	<5231FBD9.6050802@gmail.com>	<523305BB.7090802@yorku.ca>
	<52331857.8090904@gmail.com>
	<004801ceb09c$72f504d0$58df0e70$@mcmaster.ca>
	<5235E5DF.1020806@yorku.ca>
Message-ID: <5235EFA7.4040204@gmail.com>

On 13-09-15 12:52 PM, Michael Friendly wrote:
> On 9/13/2013 12:15 PM, John Fox wrote:
>> If I understand this thread, Michael's package doesn't use loglm() -- it
>> provides methods for objects produced by loglm() and hence "Enhances" the
>> package.
> Well, here's the rub: vcdExtra uses MASS::loglm() in examples, and also
> in R code,
> where it provides new S3 methods for loglm objects.  And, this whole
> problem only arose
> after vcd (on which I Depend), modified its Imports to:
>
> Imports: utils, MASS, grDevices, colorspace
> where, previously, MASS had been a Depends (or Suggests?) there.
>
>
> For my examples, the old Suggests: MASS worked, but now I've used
> require(MASS) in
> each of those examples.  However, the use in R code also triggered an
> error on loglm, even
> when I added
> Enhances: MASS
> to DESCRIPTION.
>
> OK, so I switched to using
> Imports: MASS
> but even that doesn't cure the problem alone.  I then got:

That just declares that MASS needs to be available, or installation of 
your package should abort.  It doesn't actually import anything.  You 
declare what parts of MASS you want to import in your NAMESPACE file.

>
> * checking dependencies in R code ... NOTE
> Namespace in Imports field not imported from: 'MASS'
>     All declared Imports should be used.
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
>
> but then an Error when an example using the function which called loglm()
> directly was run.

If you had in your NAMESPACE file:

importFrom(MASS, loglm)

you wouldn't get the above error.

>
>> ### ** Examples
>>
>> data(Titanic, package="datasets")
>> # variables are in the order Class, Sex, Age, Survived
>> tt <- seq_loglm(Titanic)
> 1   model.string:  = Class
> Error in eval(expr, envir, enclos) : could not find function "loglm"
> Calls: seq_loglm -> eval -> eval

This looks like you're doing something tricky (those two evals), but 
normally if you are only calling loglm from your own internal code, you 
wouldn't need anything else.

If you have an explicit call to loglm in your example, then it needs to 
be available to the user, so you could use the MASS::loglm notation, or 
(and this is probably a worse choice) you could export loglm from your 
package.


> Execution halted
>
>
> So, as several people have suggested, I changed to use MASS::loglm() in
> code,
> though it still perplexes me why this is necessary.  At any rate, this
> now passes R devel.
> Whew!

That will also work, though the importFrom solution is slightly cleaner 
and faster.  The :: operator takes time to evaluate; with importFrom, it 
is effectively evaluated just once, when your package loads.  (Of 
course, if MASS::loglm is only rarely used, you might not want to load 
it every time, and MASS::loglm might be the better choice.)

>
>
> Thanks to a suggestion from Mattew Dowle, I'm now using winbuilder (thx,
> Uwe for this!)
> and can get rather quick (< 30 min.) feedback on an R-devel build,
> whereas the
> R-Forge build cycle often takes a day.

Yes, thanks Matthew for pointing this out, and Uwe for doing it.

>
> So, my workflow is  now
> - R CMD check on local version in StatET
> - If OK, send to winbuilder, http://win-builder.r-project.org/upload.aspx
> - If OK, commit to R-Forge, and perhaps submit to CRAN if this is the
> final rev
> in a development cycle.
>
> But I still feel like I'm spending too much time on satisfying the
> unknown, new
> requirements of CRAN checks.  As Dirk said (also deserving to be a fortune),
>
>> Absent a time machine or psychic powers, I do not see how package developers
>> can reasonably be expected to cope with this.

These checks are not capricious, they are making your package better. 
For the present example, you were doing things in a way that just 
happened to work because of the way vcd was written.  When it changed, 
your package broke.  If you follow the new instructions, your package 
will be robust against changes like that.

> The effort by R Core members that goes into R and CRAN is certainly
> herculean and I
> appreciate it very much.  Like Dirk, I'm just looking for a little more
> predictability as
> CRAN evolves.

It is more the evolution of R that you are seeing, with CRAN serving as 
a giant testbed.  As we identify predictable coding errors in packages, 
we add checks to R.  If you have made those coding errors, then 
eventually you'll need to fix them.  CRAN is just asking you to do it 
sooner, rather than later.  However, I would guess that if you have an 
urgent fix in the package you are uploading, and something is going to 
stop you from fixing the newly identified problem, they'll be 
sympathetic to the need to allow your package to fix the urgent problem 
and keep the other one unfixed for a short time.

Duncan Murdoch


From pgilbert902 at gmail.com  Sun Sep 15 20:05:39 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 15 Sep 2013 14:05:39 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5234EF25.2000206@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com> <52348C7F.5040505@gmail.com>
	<5234EF25.2000206@gmail.com>
Message-ID: <5235F6F3.6000207@gmail.com>



On 13-09-14 07:20 PM, Duncan Murdoch wrote:
> On 13-09-14 12:19 PM, Paul Gilbert wrote:
>>
>>
>> On 13-09-14 09:04 AM, Duncan Murdoch wrote:
>>> On 13-09-13 12:00 PM, Dirk Eddelbuettel wrote:
>>>>
>>>> On 13 September 2013 at 11:42, Paul Gilbert wrote:
>>>> | On 13-09-13 11:02 AM, Dirk Eddelbuettel wrote:
>>>> | > It's not so much Rcpp itself or my 20-ish packages but the fact
>>>> that we (as
>>>> | > in the Rcpp authors) now stand behind an API that also has to
>>>> accomodate
>>>> | > changes in R CMD check. Case in point is current (unannounced)
>>>> change that
>>>> | > makes all Depends: Rcpp become Imports: Rcpp because of the
>>>> NAMESPACE checks.
>>>> |
>>>> | I am a bit confused by this Dirk, so maybe I am missing something. I
>>>> | think this is still a "Note" in R-devel so you do have some time to
>>>> make
>>>> | the change, at least several months, maybe more. It is not quite
>>>> what I
>>>> | think of as an "announcement", more like a shot across the bow,
>>>> but it
>>>> | is also not "unannounced".
>>>>
>>>> One package author [as in user of Rcpp and not an author of it] was
>>>> told by
>>>> CRAN this week to change his package and came to me for help -- so in
>>>> that
>>>> small way the CRAN "non-communication policy" is already creating more
>>>> work
>>>> for me, and makes me look silly as "I don't document what Rcpp-using
>>>> packages
>>>> need" as I sadly still lack the time machine or psychic powers to
>>>> infer what
>>>> may get changed this weekend.
>>>>
>>>> | More importantly, I don't think that the requirement is
>>>> necessarily to
>>>> | change Depends: Rcpp to Imports: Rcpp, the requirement is to put
>>>> | imports(Rcpp) in the NAMESPACE file. I think this is so that the
>>>> package
>>>> | continues to work even if the user does something with the search
>>>> path.
>>>> | The decision to change Depends: Rcpp to Imports: Rcpp really
>>>> depends on
>>>> | whether the package author wants Rcpp functions to be available
>>>> directly
>>>>
>>>> Rcpp is a bit of an odd-ball as you mostly need it at compile-time,
>>>> and you
>>>> require very few R-level functions (but there is package
>>>> initialization etc
>>>> pp).  We also only about two handful of functions, and those are for
>>>> functionality not all 135 packages use (eg Modules etc).
>>>>
>>>> But the focus here should not be on my hobby package. The focus needs
>>>> to be
>>>> on how four CRAN maintainers (who do a boatload of amazing work
>>>> which is
>>>> _truly_ appreciated in its thoroughness and reach) could make the
>>>> life of
>>>> authors of 4800+ packages easier by communicating and planning a tad
>>>> more.
>>>
>>> Let me paraphrase that:  "The CRAN maintainers do a lot of work, and it
>>> helps me a lot, but if they only did a little bit more work it would
>>> help me even more."
>>>
>>> I suspect they'd be more receptive to suggestions that had them doing
>>> less work, not more.
>>
>> Actually, this is one of the parts that I do not understand. It seems to
>> me that it would be a lot less work for CRAN maintainers if the
>> implications and necessary changes to packages were explained a bit more
>> clearly in a forum like R-devel that many package developers actually
>> read regularly.
>
> Then why don't you explain them?  They aren't secret.

Well, I have been trying to do that on this and related threads over the 
past few weeks. But there is a large credibility difference between my 
explanation of something I am just learning about myself and an 
explanation by a core member or CRAN maintainer of something they have 
implemented. (At least, I hope most readers of this list know there is a 
difference.)

>
> I many not fully understand how much of the response to
>> package submission gets done automatically, but I do get the sense that
>> there is a fairly large amount of actual human time spent dealing with
>> just my submissions alone. If that is representative of all developers,
>> then CRAN maintainers don't have time to do much else. (The fact that
>> they do much more suggests I may not be representative.)
>>
>> Two specific points have already been mentioned implicitly. CRAN
>> submission testing is often done at a higher/newer level using the
>> latest devel version. This results in lots of rejections for things that
>> I would fix before submission, if I knew about them.
>
> Then why don't you test against R-devel before submitting?

I have been relying on R-forge to provide that testing. One practical 
suggestion in this thread (Matthew Dowle) was to test with win-builder 
R-devel. This needs to be amplified. I had thought of win-builder as a 
mechanism to test on Windows, since I rarely work on that platform. 
Following the CRAN submission guidelines I test on win-builder if I am 
not doing the Windows testing on my own machine and the R-forge results 
are not available. (I think for a single package they are equivalent 
when R-forge is working.) But on win-builder I have usually used the 
R-release directory. Using the R-devel directory has the advantage that 
it gives an as-cran test that is almost up-to-date with the one against 
which the package is tested when it is submitted.  Another feature of 
win-builder that I had not recognized is that submitted packages are 
available in its library for a short time, so packages with version 
dependencies can be tested there, whereas they cannot be tested on R-forge.
>
>   If the tests were
>> rolled out with R, and only later incorporated into CRAN submission
>> testing, I think there would be a lot less work for the CRAN
>> maintainers.
>
> I am an R core member, not a member of CRAN.  If I make a change to R,
> I'd like to know the effect it has on the corpus of CRAN and
> Bioconductor packages, but I don't have the computing resources to run
> it against all of those in a reasonable amount of time.  We have heard
> from various corporate users of R (Revolution Computing and Google are
> two) that they would like to contribute to the project, but we don't
> actually see useful contributions from them.
>
> I don't know if you personally have influence with anyone who has such
> resources,

As far as I know I don't have any influence with anybody, but I like 
this suggestion.

Paul

> but surely some on this list do.  So why don't they write to
> me and tell me how to use their computing resources to run proposed
> changes against all published packages?  I think it's because it's
> easier to do nothing than to do something.  It's certainly easier to say
> that it's the CRAN maintainers' fault for poor communication than it is
> to identify and address the problems.
>
> Duncan Murdoch
>
>
>   (This is ignoring the possibility that CRAN submission is
>> really the testing ground for the tests, and to prove the tests requires
>> a fair amount of manual involvement. I'm happy to continue contributing
>> to this -- I've often felt my many contribution is an endless supply of
>> bugs for the checkers to catch.)
>>
>> The second point is that a facility like R-forge that runs the latest
>> checks, on many platforms, is really useful in order to reduce work for
>> both package developers and CRAN maintainers. With R-forge broken, the
>> implication for additional work for CRAN maintainers seems enormous. But
>> even with it working, not all packages are kept on R-forge, and with
>> package version dependencies R-forge does not really work. (i.e. I have
>> to get new versions of some packages onto CRAN before the new versions
>> of other packages will build on R-forge.)  Perhaps the package checking
>> part of R-forge should be separated into a pre-submission clearing house
>> to which packages are submitted. If they pass checks there then the
>> package developer could click on a submit button to do the actual
>> submission to CRAN. (Of course there needs to be a mechanism to plead
>> for the fact that the test systems do not have needed resources.)
>> Something like the daily, but with new pre-release versions of packages
>> might actually be better than the R-forge approach, for two reasons. One
>> is that package maintainers would only put packages there that they
>> think are actually working. (R-forge tries to build my svn copy even
>> when I know it is broken.) The second is that it would automatically
>> handle the version dependency problem, since package maintainers would
>> have the ability to put in place versions that should work together.
>> However, this does not need to be run daily. It only needs to be run
>> when the checks change, or for a package when the package changes.
>>
>> Paul
>>
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> | by users without them needing to specifically attach Rcpp. They are
>>>> | available with Depends but with Imports they are just used
>>>> internally in
>>>> | the package.
>>>> |
>>>> | So, one of us is confused. Usually it is me.
>>>>
>>>> No, no, I usually keep you company.
>>>>
>>>> Dirk
>>>>
>>>
>


From edd at debian.org  Sun Sep 15 20:30:32 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 15 Sep 2013 13:30:32 -0500
Subject: [Rd] R-Forge SVN commit hook to email appears to be broken
Message-ID: <21045.64712.585925.648925@max.nulle.part>


It would appear that commits no longer trigger emails; for Rcpp at least we
are two commits (made earlier today) ahead of what was emailed.  

Maybe the mail agent needs to be restarted?

Many thanks for taking care of r-forge. It is appreciated.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From rowe at muxspace.com  Sun Sep 15 22:04:39 2013
From: rowe at muxspace.com (Brian Rowe)
Date: Sun, 15 Sep 2013 16:04:39 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5235F6F3.6000207@gmail.com>
References: <5231C3E3.3050007@yorku.ca> <5231FBD9.6050802@gmail.com>
	<523305BB.7090802@yorku.ca> <52331857.8090904@gmail.com>
	<21043.7886.743370.944182@max.nulle.part>
	<52332351.4070001@gmail.com>
	<21043.10494.783658.895362@max.nulle.part>
	<52333264.10602@gmail.com>
	<21043.13956.782639.908682@max.nulle.part>
	<52345ECC.7090407@gmail.com> <52348C7F.5040505@gmail.com>
	<5234EF25.2000206@gmail.com> <5235F6F3.6000207@gmail.com>
Message-ID: <EC6DB539-F8D3-49F5-9F73-D5880D67E111@muxspace.com>

Something that might be of use to you guys is crant (https://github.com/muxspace/crant), which is a set of scripts to make package development and testing simpler. With crant you can build out multiple R instances (release, patch, devel) and then run the build chain against each one. It's compatible with devtools, and we're working on a few other conveniences, like testing all the the reverse depends to understand whether a change to a package breaks downstream dependencies. I've certainly bitten myself and incurred the wrath of CRAN a few times because I didn't check this sort of thing thoroughly enough. Running this on a virtual machine ensures that the environment is clean for building/testing. 

Of course, it doesn't address the communication issues (which I find somewhat amusing because the CRAN maintainers always seem to be in absentia during these discussions), but assuming that the CRAN checks are added to the devel branch, it shouldn't matter insomuch as detecting them prior to submission. Understanding the rationale for the change is a different matter.

Brian


On Sep 15, 2013, at 2:05 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> On 13-09-14 07:20 PM, Duncan Murdoch wrote:
>> On 13-09-14 12:19 PM, Paul Gilbert wrote:
>> 
>> I many not fully understand how much of the response to
>>> package submission gets done automatically, but I do get the sense that
>>> there is a fairly large amount of actual human time spent dealing with
>>> just my submissions alone. If that is representative of all developers,
>>> then CRAN maintainers don't have time to do much else. (The fact that
>>> they do much more suggests I may not be representative.)
>>> 
>>> Two specific points have already been mentioned implicitly. CRAN
>>> submission testing is often done at a higher/newer level using the
>>> latest devel version. This results in lots of rejections for things that
>>> I would fix before submission, if I knew about them.
>> 
>> Then why don't you test against R-devel before submitting?
> 
> I have been relying on R-forge to provide that testing. One practical suggestion in this thread (Matthew Dowle) was to test with win-builder R-devel. This needs to be amplified. I had thought of win-builder as a mechanism to test on Windows, since I rarely work on that platform. Following the CRAN submission guidelines I test on win-builder if I am not doing the Windows testing on my own machine and the R-forge results are not available. (I think for a single package they are equivalent when R-forge is working.) But on win-builder I have usually used the R-release directory. Using the R-devel directory has the advantage that it gives an as-cran test that is almost up-to-date with the one against which the package is tested when it is submitted.  Another feature of win-builder that I had not recognized is that submitted packages are available in its library for a short time, so packages with version dependencies can be tested there, whereas they cannot be tested on R-forge.
>> 
>>  If the tests were
>>> rolled out with R, and only later incorporated into CRAN submission
>>> testing, I think there would be a lot less work for the CRAN
>>> maintainers.
>> 
>> I am an R core member, not a member of CRAN.  If I make a change to R,
>> I'd like to know the effect it has on the corpus of CRAN and
>> Bioconductor packages, but I don't have the computing resources to run
>> it against all of those in a reasonable amount of time.  We have heard
>> from various corporate users of R (Revolution Computing and Google are
>> two) that they would like to contribute to the project, but we don't
>> actually see useful contributions from them.
>> 
>> I don't know if you personally have influence with anyone who has such
>> resources,
> 
> As far as I know I don't have any influence with anybody, but I like this suggestion.
> 
> Paul
> 
>> but surely some on this list do.  So why don't they write to
>> me and tell me how to use their computing resources to run proposed
>> changes against all published packages?  I think it's because it's
>> easier to do nothing than to do something.  It's certainly easier to say
>> that it's the CRAN maintainers' fault for poor communication than it is
>> to identify and address the problems.
>> 
>> Duncan Murdoch
>> 
>> 
>>  (This is ignoring the possibility that CRAN submission is
>>> really the testing ground for the tests, and to prove the tests requires
>>> a fair amount of manual involvement. I'm happy to continue contributing
>>> to this -- I've often felt my many contribution is an endless supply of
>>> bugs for the checkers to catch.)
>>> 
>>> The second point is that a facility like R-forge that runs the latest
>>> checks, on many platforms, is really useful in order to reduce work for
>>> both package developers and CRAN maintainers. With R-forge broken, the
>>> implication for additional work for CRAN maintainers seems enormous. But
>>> even with it working, not all packages are kept on R-forge, and with
>>> package version dependencies R-forge does not really work. (i.e. I have
>>> to get new versions of some packages onto CRAN before the new versions
>>> of other packages will build on R-forge.)  Perhaps the package checking
>>> part of R-forge should be separated into a pre-submission clearing house
>>> to which packages are submitted. If they pass checks there then the
>>> package developer could click on a submit button to do the actual
>>> submission to CRAN. (Of course there needs to be a mechanism to plead
>>> for the fact that the test systems do not have needed resources.)
>>> Something like the daily, but with new pre-release versions of packages
>>> might actually be better than the R-forge approach, for two reasons. One
>>> is that package maintainers would only put packages there that they
>>> think are actually working. (R-forge tries to build my svn copy even
>>> when I know it is broken.) The second is that it would automatically
>>> handle the version dependency problem, since package maintainers would
>>> have the ability to put in place versions that should work together.
>>> However, this does not need to be run daily. It only needs to be run
>>> when the checks change, or for a package when the package changes.
>>> 
>>> Paul
>>> 
>>>> 
>>>> Duncan Murdoch
>>>> 


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sun Sep 15 22:13:15 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sun, 15 Sep 2013 22:13:15 +0200
Subject: [Rd] FOSS licence with BuildVignettes: false
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>

Dear All,

I have been checking the metafor package against R-devel. 

R CMD check --as-cran metafor

yields one note:

FOSS licence with BuildVignettes: false

Yes, I have 'BuildVignettes: FALSE' in my DESCRIPTION file. I see at http://developer.r-project.org/blosxom.cgi/R-devel/NEWS:

Tue, 25 Jun 2013
CHANGES IN R-devel UTILITIES

    'R CMD check --as-cran' warns about a false value of the 'DESCRIPTION' field 'BuildVignettes' for Open Source packages, and ignores it (as an Open Source package needs to have complete sources for its vignettes).

My questions are:

1) Is this going to be an issue if I submit a new version of the metafor package to CRAN right now?

2) And if the answer to 1 is "Not right now": Is this going to become an issue in the future? In other words, is it the goal to only allow packages with BuildVignettes=true if they have an FOSS license at some point in the future?

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


From ligges at statistik.tu-dortmund.de  Sun Sep 15 22:19:02 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 15 Sep 2013 22:19:02 +0200
Subject: [Rd] FOSS licence with BuildVignettes: false
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
Message-ID: <52361636.5060305@statistik.tu-dortmund.de>

Setting

BuildVignettes: false

is fine if it is possible to build the vignettes, and the latter is 
checked in CRAN incoming checks (but not the daily checks).

Uwe Ligges








On 15.09.2013 22:13, Viechtbauer Wolfgang (STAT) wrote:
> Dear All,
>
> I have been checking the metafor package against R-devel.
>
> R CMD check --as-cran metafor
>
> yields one note:
>
> FOSS licence with BuildVignettes: false
>
> Yes, I have 'BuildVignettes: FALSE' in my DESCRIPTION file. I see at http://developer.r-project.org/blosxom.cgi/R-devel/NEWS:
>
> Tue, 25 Jun 2013
> CHANGES IN R-devel UTILITIES
>
>      'R CMD check --as-cran' warns about a false value of the 'DESCRIPTION' field 'BuildVignettes' for Open Source packages, and ignores it (as an Open Source package needs to have complete sources for its vignettes).
>
> My questions are:
>
> 1) Is this going to be an issue if I submit a new version of the metafor package to CRAN right now?
>
> 2) And if the answer to 1 is "Not right now": Is this going to become an issue in the future? In other words, is it the goal to only allow packages with BuildVignettes=true if they have an FOSS license at some point in the future?
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bbolker at gmail.com  Mon Sep 16 01:04:21 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 15 Sep 2013 23:04:21 +0000
Subject: [Rd] FOSS licence with BuildVignettes: false
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
	<52361636.5060305@statistik.tu-dortmund.de>
Message-ID: <loom.20130916T005045-889@post.gmane.org>

Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:

> 
> Setting
> 
> BuildVignettes: false
> 
> is fine if it is possible to build the vignettes, and the latter is 
> checked in CRAN incoming checks (but not the daily checks).
> 
> Uwe Ligges

   Hmmm.  I was told by the CRAN maintainers on Aug 7 that

CRAN> "FOSS licence with BuildVignettes: false" is not a false positive, 
CRAN> is fixable, and is mentioned at
CRAN> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#
CRAN>    The-DESCRIPTION-file as not to be used in an FOSS package.

  (I had said in my previous e-mail to CRAN that all NOTEs were
false positives, minor or not fixable.)  Admittedly this e-mail
nowhere said explicitly "you must fix this or we will not accept
it for CRAN", but that was certainly the impression I got.

TFM says

R-exts>   [BuildVignettes: false] should only be used exceptionally, for 
R-exts> example if the PDFs include large figures which are not part of the 
R-exts> package sources (and hence only in packages which do not have an
R-exts> Open Source license).

   So either I'm confused (always a possibility!) or it seems
there are some inconsistencies here ...

> On 15.09.2013 22:13, Viechtbauer Wolfgang (STAT) wrote:
> > Dear All,
> >
> > I have been checking the metafor package against R-devel.
> >
> > R CMD check --as-cran metafor
> >
> > yields one note:
> >
> > FOSS licence with BuildVignettes: false
> >
> > Yes, I have 'BuildVignettes: FALSE' in my DESCRIPTION file. 
> I see at http://developer.r-project.org/blosxom.cgi/R-devel/NEWS:
> >
> > Tue, 25 Jun 2013
> > CHANGES IN R-devel UTILITIES
> >
> >      'R CMD check --as-cran' warns about a false value 
> of the 'DESCRIPTION' field 'BuildVignettes' for Open
> Source packages, and ignores it (as an Open Source package 
> needs to have complete sources for its vignettes).
> >
> > My questions are:
> >
> > 1) Is this going to be an issue if I submit a new 
> version of the metafor package to CRAN right now?
> >
> > 2) And if the answer to 1 is "Not right now": Is this going 
> to become an issue in the future? In other words, is
> it the goal to only allow packages with BuildVignettes=true 
> if they have an FOSS license at some point in
> the future?
> >
> > Best,
> > Wolfgang
> >


From bbolker at gmail.com  Mon Sep 16 01:11:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 15 Sep 2013 23:11:04 +0000
Subject: [Rd] declaring package dependencies
References: <5235795C.3050903@mdowle.plus.com>
Message-ID: <loom.20130916T010538-629@post.gmane.org>

Matthew Dowle <mdowle <at> mdowle.plus.com> writes:

> 
> 
> I'm a little surprised by this thread.
> 
> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and 
> that's been pretty informative in the past :
> http://developer.r-project.org/RSSfeeds.html
> 
> Mainly though, I submit to winbuilder before submitting to CRAN, as the 
> CRAN policies advise.  winbuilder's R-devel seems to be built daily, 
> saving me the time. Since I don't have Windows it kills two birds with 
> one stone.  It has caught many problems for me before submitting to CRAN 
> and I can't remember it ever not responding in a reasonable time.
> http://win-builder.r-project.org/upload.aspx
> 
> I've suggested before that winbuilder could be the mechanism to submit 
> to CRAN rather than an ftp upload to incoming.  Only if winbuilder 
> passed OK on R-devel could it then go to a human.   But iirc there was a 
> technical difficulty preventing this.
> 
> Matthew

  I was planning to write a careful e-mail to CRAN suggesting
essentially this, and I may yet do so, but for now I'll just chime in
and "+1" this.  Yihui Xie made a very similar suggestion sometime
last year (I think).  It would seem so much easier for everyone,
package maintainers *and* CRAN maintainers, to have an automatic
filter of this sort, and I can't figure out any downside other than
needing slightly more computer power (which surely must be a reasonable
tradeoff for fewer human resources!), *if* having the
auto-filter made people sloppier about checking before submitting.
   Do you happen to remember what the technical difficulty was?
If I were a CRAN maintainer (thank goodness I'm not!), overcoming
it would be one of my top priorities ...

  Ben Bolker


From xie at yihui.name  Mon Sep 16 03:58:02 2013
From: xie at yihui.name (Yihui Xie)
Date: Sun, 15 Sep 2013 20:58:02 -0500
Subject: [Rd] declaring package dependencies
In-Reply-To: <loom.20130916T010538-629@post.gmane.org>
References: <5235795C.3050903@mdowle.plus.com>
	<loom.20130916T010538-629@post.gmane.org>
Message-ID: <CANROs4e8=v5S-FAWmKJ4C2aQMp35dqnmyUp_1=8QisU=+iWYdg@mail.gmail.com>

I've been watching this thread closely and trying not to chime in,
because as Brian Rowe mentioned about CRAN's mysterious absence in a
previous reply. CRAN is like a ghost in r-devel (or any other mailing
lists) -- everybody is discussing about it, and nobody has ever seen
it. Perhaps one day useRs will realize that the rings of Saturn are
actually composed of the lost discussions about CRAN. (Just kidding.
No offence. I swear I appreciate the great work of CRAN, and
rep("thank you, CRAN", 1e6).)

Although this discussion may also contribute to the rings of Saturn, I
want to emphasize one final point: requests from package authors do
not necessarily mean more work for CRAN.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Sun, Sep 15, 2013 at 6:11 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Matthew Dowle <mdowle <at> mdowle.plus.com> writes:
>
>>
>>
>> I'm a little surprised by this thread.
>>
>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>> that's been pretty informative in the past :
>> http://developer.r-project.org/RSSfeeds.html
>>
>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>> CRAN policies advise.  winbuilder's R-devel seems to be built daily,
>> saving me the time. Since I don't have Windows it kills two birds with
>> one stone.  It has caught many problems for me before submitting to CRAN
>> and I can't remember it ever not responding in a reasonable time.
>> http://win-builder.r-project.org/upload.aspx
>>
>> I've suggested before that winbuilder could be the mechanism to submit
>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>> passed OK on R-devel could it then go to a human.   But iirc there was a
>> technical difficulty preventing this.
>>
>> Matthew
>
>   I was planning to write a careful e-mail to CRAN suggesting
> essentially this, and I may yet do so, but for now I'll just chime in
> and "+1" this.  Yihui Xie made a very similar suggestion sometime
> last year (I think).  It would seem so much easier for everyone,
> package maintainers *and* CRAN maintainers, to have an automatic
> filter of this sort, and I can't figure out any downside other than
> needing slightly more computer power (which surely must be a reasonable
> tradeoff for fewer human resources!), *if* having the
> auto-filter made people sloppier about checking before submitting.
>    Do you happen to remember what the technical difficulty was?
> If I were a CRAN maintainer (thank goodness I'm not!), overcoming
> it would be one of my top priorities ...
>
>   Ben Bolker


From rowe at muxspace.com  Mon Sep 16 04:46:32 2013
From: rowe at muxspace.com (Brian Rowe)
Date: Sun, 15 Sep 2013 22:46:32 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <CANROs4e8=v5S-FAWmKJ4C2aQMp35dqnmyUp_1=8QisU=+iWYdg@mail.gmail.com>
References: <5235795C.3050903@mdowle.plus.com>
	<loom.20130916T010538-629@post.gmane.org>
	<CANROs4e8=v5S-FAWmKJ4C2aQMp35dqnmyUp_1=8QisU=+iWYdg@mail.gmail.com>
Message-ID: <0671A35F-D263-48F2-B08D-1BC011E2E2FE@muxspace.com>

That reminds me: I once made a suggestion on how to automate some of the CRAN deployment process, but it was shot down as not being useful to them. I do recall a quote that was along the lines of "as long as you don't need help, do whatever you want", so one thought is to just set up a build server that does the building across the three versions of R, checks dependencies, rebuilds when release, patch, or devel are updated, etc. This would ease the burden on package maintainers and would just happen to make the CRAN folks' lives easier by catching a lot of bad builds. A proof of concept on AWS connecting to github or rforge could probably be finished on a six-pack. Speak up if anyone thinks this would be useful.


On Sep 15, 2013, at 9:58 PM, Yihui Xie <xie at yihui.name> wrote:

> I've been watching this thread closely and trying not to chime in,
> because as Brian Rowe mentioned about CRAN's mysterious absence in a
> previous reply. CRAN is like a ghost in r-devel (or any other mailing
> lists) -- everybody is discussing about it, and nobody has ever seen
> it. Perhaps one day useRs will realize that the rings of Saturn are
> actually composed of the lost discussions about CRAN. (Just kidding.
> No offence. I swear I appreciate the great work of CRAN, and
> rep("thank you, CRAN", 1e6).)
> 
> Although this discussion may also contribute to the rings of Saturn, I
> want to emphasize one final point: requests from package authors do
> not necessarily mean more work for CRAN.
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
> 
> 
> On Sun, Sep 15, 2013 at 6:11 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Matthew Dowle <mdowle <at> mdowle.plus.com> writes:
>> 
>>> 
>>> 
>>> I'm a little surprised by this thread.
>>> 
>>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>>> that's been pretty informative in the past :
>>> http://developer.r-project.org/RSSfeeds.html
>>> 
>>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>>> CRAN policies advise.  winbuilder's R-devel seems to be built daily,
>>> saving me the time. Since I don't have Windows it kills two birds with
>>> one stone.  It has caught many problems for me before submitting to CRAN
>>> and I can't remember it ever not responding in a reasonable time.
>>> http://win-builder.r-project.org/upload.aspx
>>> 
>>> I've suggested before that winbuilder could be the mechanism to submit
>>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>>> passed OK on R-devel could it then go to a human.   But iirc there was a
>>> technical difficulty preventing this.
>>> 
>>> Matthew
>> 
>>  I was planning to write a careful e-mail to CRAN suggesting
>> essentially this, and I may yet do so, but for now I'll just chime in
>> and "+1" this.  Yihui Xie made a very similar suggestion sometime
>> last year (I think).  It would seem so much easier for everyone,
>> package maintainers *and* CRAN maintainers, to have an automatic
>> filter of this sort, and I can't figure out any downside other than
>> needing slightly more computer power (which surely must be a reasonable
>> tradeoff for fewer human resources!), *if* having the
>> auto-filter made people sloppier about checking before submitting.
>>   Do you happen to remember what the technical difficulty was?
>> If I were a CRAN maintainer (thank goodness I'm not!), overcoming
>> it would be one of my top priorities ...
>> 
>>  Ben Bolker
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mdowle at mdowle.plus.com  Mon Sep 16 10:56:34 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 16 Sep 2013 09:56:34 +0100
Subject: [Rd] declaring package dependencies
Message-ID: <5236C7C2.8020800@mdowle.plus.com>

On Sep 16, 2013, at 01:46 PM, Brian Rowe wrote:

> That reminds me: I once made a suggestion on how to automate some of the CRAN
> deployment process, but it was shot down as not being useful to them. I do
> recall a quote that was along the lines of "as long as you don't need help,
> do whatever you want", so one thought is to just set up a build server that
> does the building across the three versions of R, checks dependencies, rebuilds
> when release, patch, or devel are updated, etc. This would ease the burden on
> package maintainers and would just happen to make the CRAN folks' lives easier
> by catching a lot of bad builds. A proof of concept on AWS connecting to github
> or rforge could probably be finished on a six-pack. Speak up if anyone thinks
> this would be useful.

Yes useful. But that includes a package build system (which is what breaks on
R-Forge). If you could do that on a six-pack then could you fix R-Forge on a
three-pack first please? The R-Forge build system is itself an open source
package on R-Forge. Anyone can look at it, understand it and change it to be
more stable. That build system is here :

https://r-forge.r-project.org/R/?group_id=34

(I only know this because Stefan told me once. So I suspect others don't know
either, or it hasn't sunk in that we're pushing on an open door.)

Matthew


From mdowle at mdowle.plus.com  Mon Sep 16 11:10:36 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 16 Sep 2013 10:10:36 +0100
Subject: [Rd] declaring package dependencies
Message-ID: <5236CB0C.9050501@mdowle.plus.com>

Ben Bolker wrote :
> Do you happen to remember what the technical difficulty was?

 From memory I think it was that CRAN maintainers didn't have
access to Uwe's winbuilder machine. But often when I get OK
from winbuilder R-devel I don't want it to go to CRAN yet. So
procedures and software would have to be put in place to
handle that (unclear) logic which I didn't propose anything
for or offer any code to do. So time and effort to decide and
time and effort to implement. Just a guess. And maybe some
packages don't run on Windows, so what about those?  It's
all those edge cases that really take the time.

Matthew


From ligges at statistik.tu-dortmund.de  Mon Sep 16 11:19:32 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 16 Sep 2013 11:19:32 +0200
Subject: [Rd] FOSS licence with BuildVignettes: false
In-Reply-To: <loom.20130916T005045-889@post.gmane.org>
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
	<52361636.5060305@statistik.tu-dortmund.de>
	<loom.20130916T005045-889@post.gmane.org>
Message-ID: <5236CD24.40107@statistik.tu-dortmund.de>



On 16.09.2013 01:04, Ben Bolker wrote:
> Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:
>
>>
>> Setting
>>
>> BuildVignettes: false
>>
>> is fine if it is possible to build the vignettes, and the latter is
>> checked in CRAN incoming checks (but not the daily checks).
>>
>> Uwe Ligges
>
>     Hmmm.  I was told by the CRAN maintainers on Aug 7 that
>
> CRAN> "FOSS licence with BuildVignettes: false" is not a false positive,
> CRAN> is fixable, and is mentioned at
> CRAN> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#
> CRAN>    The-DESCRIPTION-file as not to be used in an FOSS package.
>
>    (I had said in my previous e-mail to CRAN that all NOTEs were
> false positives, minor or not fixable.)  Admittedly this e-mail
> nowhere said explicitly "you must fix this or we will not accept
> it for CRAN", but that was certainly the impression I got.
>
> TFM says
>
> R-exts>   [BuildVignettes: false] should only be used exceptionally, for
> R-exts> example if the PDFs include large figures which are not part of the
> R-exts> package sources (and hence only in packages which do not have an
> R-exts> Open Source license).
>
>     So either I'm confused (always a possibility!) or it seems
> there are some inconsistencies here ...

Yes, and I could see really rare circumstances where vignette building 
takes a long time and the maintainer decides not to build vignettes as 
part of the daily checks.
If there were no possible (but typically rather rare) exceptions, this 
would be at least a Warning.

Best,
Uwe Ligges





>
>> On 15.09.2013 22:13, Viechtbauer Wolfgang (STAT) wrote:
>>> Dear All,
>>>
>>> I have been checking the metafor package against R-devel.
>>>
>>> R CMD check --as-cran metafor
>>>
>>> yields one note:
>>>
>>> FOSS licence with BuildVignettes: false
>>>
>>> Yes, I have 'BuildVignettes: FALSE' in my DESCRIPTION file.
>> I see at http://developer.r-project.org/blosxom.cgi/R-devel/NEWS:
>>>
>>> Tue, 25 Jun 2013
>>> CHANGES IN R-devel UTILITIES
>>>
>>>       'R CMD check --as-cran' warns about a false value
>> of the 'DESCRIPTION' field 'BuildVignettes' for Open
>> Source packages, and ignores it (as an Open Source package
>> needs to have complete sources for its vignettes).
>>>
>>> My questions are:
>>>
>>> 1) Is this going to be an issue if I submit a new
>> version of the metafor package to CRAN right now?
>>>
>>> 2) And if the answer to 1 is "Not right now": Is this going
>> to become an issue in the future? In other words, is
>> it the goal to only allow packages with BuildVignettes=true
>> if they have an FOSS license at some point in
>> the future?
>>>
>>> Best,
>>> Wolfgang
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gb at stat.umu.se  Mon Sep 16 09:59:03 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 16 Sep 2013 09:59:03 +0200
Subject: [Rd] declaring package dependencies
In-Reply-To: <5235795C.3050903@mdowle.plus.com>
References: <5235795C.3050903@mdowle.plus.com>
Message-ID: <5236BA47.7070305@stat.umu.se>



On 09/15/2013 11:09 AM, Matthew Dowle wrote:
>
> I'm a little surprised by this thread.
>
> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
> that's been pretty informative in the past :
> http://developer.r-project.org/RSSfeeds.html
>
> Mainly though, I submit to winbuilder before submitting to CRAN, as the
> CRAN policies advise.

Right, but

"Please _do not_ upload BioConductor packages or CRAN packages."

from the winbuilder page.

G?ran

> winbuilder's R-devel seems to be built daily,
> saving me the time. Since I don't have Windows it kills two birds with
> one stone.  It has caught many problems for me before submitting to CRAN
> and I can't remember it ever not responding in a reasonable time.
> http://win-builder.r-project.org/upload.aspx
>
> I've suggested before that winbuilder could be the mechanism to submit
> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
> passed OK on R-devel could it then go to a human.   But iirc there was a
> technical difficulty preventing this.
>
> Matthew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Sep 16 12:38:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Sep 2013 06:38:41 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5236BA47.7070305@stat.umu.se>
References: <5235795C.3050903@mdowle.plus.com> <5236BA47.7070305@stat.umu.se>
Message-ID: <5236DFB1.1060305@gmail.com>

On 13-09-16 3:59 AM, G?ran Brostr?m wrote:
>
>
> On 09/15/2013 11:09 AM, Matthew Dowle wrote:
>>
>> I'm a little surprised by this thread.
>>
>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>> that's been pretty informative in the past :
>> http://developer.r-project.org/RSSfeeds.html
>>
>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>> CRAN policies advise.
>
> Right, but
>
> "Please _do not_ upload BioConductor packages or CRAN packages."
>
> from the winbuilder page.

 From the context, that message is about packages that are already on 
CRAN without Windows binaries already built.

Duncan Murdoch

>
> G?ran
>
>> winbuilder's R-devel seems to be built daily,
>> saving me the time. Since I don't have Windows it kills two birds with
>> one stone.  It has caught many problems for me before submitting to CRAN
>> and I can't remember it ever not responding in a reasonable time.
>> http://win-builder.r-project.org/upload.aspx
>>
>> I've suggested before that winbuilder could be the mechanism to submit
>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>> passed OK on R-devel could it then go to a human.   But iirc there was a
>> technical difficulty preventing this.
>>
>> Matthew
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Sep 16 12:51:42 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Sep 2013 06:51:42 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <CANROs4e8=v5S-FAWmKJ4C2aQMp35dqnmyUp_1=8QisU=+iWYdg@mail.gmail.com>
References: <5235795C.3050903@mdowle.plus.com>
	<loom.20130916T010538-629@post.gmane.org>
	<CANROs4e8=v5S-FAWmKJ4C2aQMp35dqnmyUp_1=8QisU=+iWYdg@mail.gmail.com>
Message-ID: <5236E2BE.9030609@gmail.com>

On 13-09-15 9:58 PM, Yihui Xie wrote:
> I've been watching this thread closely and trying not to chime in,
> because as Brian Rowe mentioned about CRAN's mysterious absence in a
> previous reply.

It's no mystery that they don't discuss CRAN policies on this list. 
That's been stated many times.  I don't expect that to change because 
users on this list make stupid jokes about it.

Duncan Murdoch

CRAN is like a ghost in r-devel (or any other mailing
> lists) -- everybody is discussing about it, and nobody has ever seen
> it. Perhaps one day useRs will realize that the rings of Saturn are
> actually composed of the lost discussions about CRAN. (Just kidding.
> No offence. I swear I appreciate the great work of CRAN, and
> rep("thank you, CRAN", 1e6).)
>
> Although this discussion may also contribute to the rings of Saturn, I
> want to emphasize one final point: requests from package authors do
> not necessarily mean more work for CRAN.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Sun, Sep 15, 2013 at 6:11 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Matthew Dowle <mdowle <at> mdowle.plus.com> writes:
>>
>>>
>>>
>>> I'm a little surprised by this thread.
>>>
>>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>>> that's been pretty informative in the past :
>>> http://developer.r-project.org/RSSfeeds.html
>>>
>>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>>> CRAN policies advise.  winbuilder's R-devel seems to be built daily,
>>> saving me the time. Since I don't have Windows it kills two birds with
>>> one stone.  It has caught many problems for me before submitting to CRAN
>>> and I can't remember it ever not responding in a reasonable time.
>>> http://win-builder.r-project.org/upload.aspx
>>>
>>> I've suggested before that winbuilder could be the mechanism to submit
>>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>>> passed OK on R-devel could it then go to a human.   But iirc there was a
>>> technical difficulty preventing this.
>>>
>>> Matthew
>>
>>    I was planning to write a careful e-mail to CRAN suggesting
>> essentially this, and I may yet do so, but for now I'll just chime in
>> and "+1" this.  Yihui Xie made a very similar suggestion sometime
>> last year (I think).  It would seem so much easier for everyone,
>> package maintainers *and* CRAN maintainers, to have an automatic
>> filter of this sort, and I can't figure out any downside other than
>> needing slightly more computer power (which surely must be a reasonable
>> tradeoff for fewer human resources!), *if* having the
>> auto-filter made people sloppier about checking before submitting.
>>     Do you happen to remember what the technical difficulty was?
>> If I were a CRAN maintainer (thank goodness I'm not!), overcoming
>> it would be one of my top priorities ...
>>
>>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From qrd at sig.com  Mon Sep 16 12:24:35 2013
From: qrd at sig.com (QRD)
Date: Mon, 16 Sep 2013 10:24:35 +0000
Subject: [Rd] Patch: fix segfault from empty raster
Message-ID: <24E99AB65531B7489F15EFF58F1273070147F306@xchmbbal506.ds.susq.com>

Hi,

A colleague recently came across an R crash, which I can boil down to
the following, running under Rgui on Windows 7:

library(ggplot2)
ggplot(data.frame(x=1, y=1, z=4.7), aes(x, y, z=z)) + stat_summary2d()

This reliably causes a segmentation fault.  sessionInfo() below.

What's happening is that (for reasons which I'll discuss with the
ggplot2 developers) the 'colorbar' guide is being built with a zero-size
source raster.

In L_raster() (grid.c), this raster is not a "nativeRaster", so we do

    image = (unsigned int*) R_alloc(n, sizeof(unsigned int));

with n = 0, and R_alloc() gives us a NULL pointer.

The display of this raster requests interpolation, so we end up in
R_GE_rasterInterpolate(), where 'sraster' is NULL, and chaos ensues as
it tries to read source pixels.

It seems to me that it doesn't make sense to display an empty raster, so
I inserted a check in L_raster().  A proof-of-concept patch is attached.
With this patch, R gives an error message instead of a segfault.

Does this seem a sensible change?  If so, could something like it be
incorporated?

Thanks,

Ben.

- - - - 8< - - - -

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_Ireland.1252  LC_CTYPE=English_Ireland.1252
[3] LC_MONETARY=English_Ireland.1252 LC_NUMERIC=C
[5] LC_TIME=English_Ireland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_0.9.3.1

loaded via a namespace (and not attached):
 [1] colorspace_1.2-2   compiler_3.0.1     dichromat_2.0-0    digest_0.6.3
 [5] grid_3.0.1         gtable_0.1.2       labeling_0.2       MASS_7.3-26
 [9] munsell_0.4        plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
[13] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2      tools_3.0.1


From gb at stat.umu.se  Mon Sep 16 13:52:03 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Mon, 16 Sep 2013 13:52:03 +0200
Subject: [Rd] declaring package dependencies
In-Reply-To: <5236DFB1.1060305@gmail.com>
References: <5235795C.3050903@mdowle.plus.com> <5236BA47.7070305@stat.umu.se>
	<5236DFB1.1060305@gmail.com>
Message-ID: <5236F0E3.10909@stat.umu.se>



On 09/16/2013 12:38 PM, Duncan Murdoch wrote:
> On 13-09-16 3:59 AM, G?ran Brostr?m wrote:
>>
>>
>> On 09/15/2013 11:09 AM, Matthew Dowle wrote:
>>>
>>> I'm a little surprised by this thread.
>>>
>>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>>> that's been pretty informative in the past :
>>> http://developer.r-project.org/RSSfeeds.html
>>>
>>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>>> CRAN policies advise.
>>
>> Right, but
>>
>> "Please _do not_ upload BioConductor packages or CRAN packages."
>>
>> from the winbuilder page.
>
>   From the context, that message is about packages that are already on
> CRAN without Windows binaries already built.

Maybe, but that is not what the page says.

Anyway, may I use this facility to check new versions of my CRAN 
packages or not?

G?ran

> Duncan Murdoch
>
>>
>> G?ran
>>
>>> winbuilder's R-devel seems to be built daily,
>>> saving me the time. Since I don't have Windows it kills two birds with
>>> one stone.  It has caught many problems for me before submitting to CRAN
>>> and I can't remember it ever not responding in a reasonable time.
>>> http://win-builder.r-project.org/upload.aspx
>>>
>>> I've suggested before that winbuilder could be the mechanism to submit
>>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>>> passed OK on R-devel could it then go to a human.   But iirc there was a
>>> technical difficulty preventing this.
>>>
>>> Matthew
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From rowe at muxspace.com  Mon Sep 16 14:06:52 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Mon, 16 Sep 2013 08:06:52 -0400
Subject: [Rd] declaring package dependencies
In-Reply-To: <5236C7C2.8020800@mdowle.plus.com>
References: <5236C7C2.8020800@mdowle.plus.com>
Message-ID: <C5FC777B-62E5-41E0-9D7B-5428CC5847D0@muxspace.com>

I haven't used rforge, but I will look check out the scripts. The reason it would be a six-pack of work is that there are generic build systems that handle most of this work. What they don't do is act as a repository, so rforge could remain that while separating out the build process. 


On Sep 16, 2013, at 4:58 AM, Matthew Dowle <mdowle at mdowle.plus.com> wrote:

> On Sep 16, 2013, at 01:46 PM, Brian Rowe wrote:
> 
>> That reminds me: I once made a suggestion on how to automate some of the CRAN
>> deployment process, but it was shot down as not being useful to them. I do
>> recall a quote that was along the lines of "as long as you don't need help,
>> do whatever you want", so one thought is to just set up a build server that
>> does the building across the three versions of R, checks dependencies, rebuilds
>> when release, patch, or devel are updated, etc. This would ease the burden on
>> package maintainers and would just happen to make the CRAN folks' lives easier
>> by catching a lot of bad builds. A proof of concept on AWS connecting to github
>> or rforge could probably be finished on a six-pack. Speak up if anyone thinks
>> this would be useful.
> 
> Yes useful. But that includes a package build system (which is what breaks on
> R-Forge). If you could do that on a six-pack then could you fix R-Forge on a
> three-pack first please? The R-Forge build system is itself an open source
> package on R-Forge. Anyone can look at it, understand it and change it to be
> more stable. That build system is here :
> 
> https://r-forge.r-project.org/R/?group_id=34
> 
> (I only know this because Stefan told me once. So I suspect others don't know
> either, or it hasn't sunk in that we're pushing on an open door.)
> 
> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon Sep 16 14:47:50 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 16 Sep 2013 14:47:50 +0200
Subject: [Rd] declaring package dependencies
In-Reply-To: <5236F0E3.10909@stat.umu.se>
References: <5235795C.3050903@mdowle.plus.com> <5236BA47.7070305@stat.umu.se>
	<5236DFB1.1060305@gmail.com> <5236F0E3.10909@stat.umu.se>
Message-ID: <5236FDF6.4050008@statistik.tu-dortmund.de>



On 16.09.2013 13:52, G?ran Brostr?m wrote:
>
>
> On 09/16/2013 12:38 PM, Duncan Murdoch wrote:
>> On 13-09-16 3:59 AM, G?ran Brostr?m wrote:
>>>
>>>
>>> On 09/15/2013 11:09 AM, Matthew Dowle wrote:
>>>>
>>>> I'm a little surprised by this thread.
>>>>
>>>> I subscribe to the RSS feeds of changes to NEWS (as Dirk mentioned) and
>>>> that's been pretty informative in the past :
>>>> http://developer.r-project.org/RSSfeeds.html
>>>>
>>>> Mainly though, I submit to winbuilder before submitting to CRAN, as the
>>>> CRAN policies advise.
>>>
>>> Right, but
>>>
>>> "Please _do not_ upload BioConductor packages or CRAN packages."
>>>
>>> from the winbuilder page.
>>
>>   From the context, that message is about packages that are already on
>> CRAN without Windows binaries already built.
>
> Maybe, but that is not what the page says.
>
> Anyway, may I use this facility to check new versions of my CRAN
> packages or not?

Yes, before submission, but not if the version is on CRAN already (i.e. 
if the version became a CRAN package).

Best,
Uwe Ligges



>
> G?ran
>
>> Duncan Murdoch
>>
>>>
>>> G?ran
>>>
>>>> winbuilder's R-devel seems to be built daily,
>>>> saving me the time. Since I don't have Windows it kills two birds with
>>>> one stone.  It has caught many problems for me before submitting to
>>>> CRAN
>>>> and I can't remember it ever not responding in a reasonable time.
>>>> http://win-builder.r-project.org/upload.aspx
>>>>
>>>> I've suggested before that winbuilder could be the mechanism to submit
>>>> to CRAN rather than an ftp upload to incoming.  Only if winbuilder
>>>> passed OK on R-devel could it then go to a human.   But iirc there
>>>> was a
>>>> technical difficulty preventing this.
>>>>
>>>> Matthew
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From s.boehringer at lumc.nl  Mon Sep 16 16:12:39 2013
From: s.boehringer at lumc.nl (Stefan Boehringer)
Date: Mon, 16 Sep 2013 16:12:39 +0200
Subject: [Rd] Rcpp modules
Message-ID: <523711D7.2060406@lumc.nl>

Dear all,

my apologies for posting here instead of rcpp-devel (registration for
which did not seem to work). I try to use a Rcpp module outside a
package using the following code which should work according to posts on
this list/rcpp-devel.

library('Rcpp');
dlr = dyn.load('build/libtestlib.so');
mod = Module('testclass', PACKAGE = dlr);
cl = new(mod$testclass);

This results in the error message:
Failed to initialize module pointer: Error in
FUN("_rcpp_module_boot_testclass"[[1L]], ...): no such symbol
_rcpp_module_boot_testclass in package
/home/pingu/src/2013-rcpp-test/rcpptest/build/libtestlib.so

Passing the PACKAGE argument above reportedly should solve this error
but does not seem to do so in my setup. Any suggestion appreciated. The
mentioned symbol exists in the shared object file which is linked agains
libR and libRcpp. Both a build with R CMD SHLIB and/or standard cmake
gives the same result.

Environment:
Linux
R 3.0.1
Rcpp_0.10.4
Freshly compiled from source.

Thanks in advance,

    Stefan


From edd at debian.org  Mon Sep 16 16:31:38 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 16 Sep 2013 09:31:38 -0500
Subject: [Rd] Rcpp modules
In-Reply-To: <523711D7.2060406@lumc.nl>
References: <523711D7.2060406@lumc.nl>
Message-ID: <21047.5706.86124.966609@max.nulle.part>


On 16 September 2013 at 16:12, Stefan Boehringer wrote:
| my apologies for posting here instead of rcpp-devel (registration for
| which did not seem to work). 

It is using the standard Python mailman software, as do lots of other lists.
Your From: field _must_ match you registration. That is the sole requirement.

| I try to use a Rcpp module outside a

Please post Rcpp questions on rcpp-devel.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From pgilbert902 at gmail.com  Mon Sep 16 16:49:19 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 16 Sep 2013 10:49:19 -0400
Subject: [Rd] FOSS licence with BuildVignettes: false
In-Reply-To: <5236CD24.40107@statistik.tu-dortmund.de>
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
	<52361636.5060305@statistik.tu-dortmund.de>
	<loom.20130916T005045-889@post.gmane.org>
	<5236CD24.40107@statistik.tu-dortmund.de>
Message-ID: <52371A6F.6020909@gmail.com>

On 13-09-16 05:19 AM, Uwe Ligges wrote:
...
> Yes, and I could see really rare circumstances where vignette building
> takes a long time and the maintainer decides not to build vignettes as
> part of the daily checks.
...

I thought 'BuildVignettes: FALSE' only turns of assembling the pdf, all 
the code is still run.  I don't think that would affect the time very 
much. Am I wrong (again)?

Paul

> Uwe Ligges
>


From pgilbert902 at gmail.com  Mon Sep 16 17:11:44 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 16 Sep 2013 11:11:44 -0400
Subject: [Rd] helping R-forge build
In-Reply-To: <5236C7C2.8020800@mdowle.plus.com>
References: <5236C7C2.8020800@mdowle.plus.com>
Message-ID: <52371FB0.6040305@gmail.com>

(subject changed from Re: [Rd] declaring package dependencies )
...
> Yes useful. But that includes a package build system (which is what
> breaks on
> R-Forge). If you could do that on a six-pack then could you fix R-Forge
> on a
> three-pack first please? The R-Forge build system is itself an open source
> package on R-Forge. Anyone can look at it, understand it and change it
> to be
> more stable. That build system is here :
>
> https://r-forge.r-project.org/R/?group_id=34
>
> (I only know this because Stefan told me once. So I suspect others don't
> know
> either, or it hasn't sunk in that we're pushing on an open door.)
>
> Matthew

Open code is necessary, but to debug one needs access to logs, etc, to 
see where it is breaking.  Do you know how to find that information?

(And, BTW, there are also tools to help automatically build R and test 
packages at http://automater.r-forge.r-project.org/ .)

Paul


From mdowle at mdowle.plus.com  Mon Sep 16 17:41:01 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 16 Sep 2013 16:41:01 +0100
Subject: [Rd] helping R-forge build
In-Reply-To: <52371FB0.6040305@gmail.com>
References: <5236C7C2.8020800@mdowle.plus.com> <52371FB0.6040305@gmail.com>
Message-ID: <5237268D.1090801@mdowle.plus.com>

On 16/09/13 16:11, Paul Gilbert wrote:
> (subject changed from Re: [Rd] declaring package dependencies )
> ...
>> Yes useful. But that includes a package build system (which is what
>> breaks on
>> R-Forge). If you could do that on a six-pack then could you fix R-Forge
>> on a
>> three-pack first please? The R-Forge build system is itself an open
>> source
>> package on R-Forge. Anyone can look at it, understand it and change it
>> to be
>> more stable. That build system is here :
>>
>> https://r-forge.r-project.org/R/?group_id=34
>>
>> (I only know this because Stefan told me once. So I suspect others don't
>> know
>> either, or it hasn't sunk in that we're pushing on an open door.)
>>
>> Matthew
>
> Open code is necessary, but to debug one needs access to logs, etc, to
> see where it is breaking.  Do you know how to find that information?

There's a link at the bottom of the R-Forge page to :
   http://download.r-forge.r-project.org/STATUS
I don't know if that's enough but it's a start maybe. I've copied Stefan 
in case there are more logs somewhere else.

> (And, BTW, there are also tools to help automatically build R and test
> packages at http://automater.r-forge.r-project.org/ .)

automater looks good! What's the next step?

>
> Paul
>


From hpages at fhcrc.org  Mon Sep 16 21:55:23 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 16 Sep 2013 12:55:23 -0700
Subject: [Rd] a fast table() for the 1D case
In-Reply-To: <5204A61E.9090209@fhcrc.org>
References: <5204A61E.9090209@fhcrc.org>
Message-ID: <5237622B.2030607@fhcrc.org>

Any chance some improvements can be made on table()?

table() is probably one of the most used R functions when working
interactively. Unfortunately it can be incredibly slow, especially
on a logical vector where a simple sum() is hundred times faster
(I actually got into the habit of using sum() instead of table()).
The table1D() proposal below doesn't go as far as using sum() on a
logical vector but it already provides significant speedups for most
use cases.

Thanks,
H.


On 08/09/2013 01:19 AM, Herv? Pag?s wrote:
> Hi,
>
> table1D() below can be up to 60x faster than base::table() for the 1D
> case. Here are the detailed speedups compared to base::table().
>
>    o With a logical vector of length 5M:     11x faster
>                                      (or more if 'useNA="always"')
>
>    o With factor/integer/numeric/character of length 1M and 9 levels
>      (or 9 distinct values for non-factors):
>       - factor:                              60x faster
>       - integer/numeric vector:              12x faster
>       - character vector:                   2.4x faster
>
>    o With factor/integer/numeric/character of length 1M and no
>      duplicates:
>        - factor:                              5x faster
>        - integer vector:                      2x faster
>        - numeric vector:                    1.7x faster
>        - character vector:       no significant speedup
>
> Would be great if this improvement could make it into base::table().
>
> Thanks,
> H.
>
>    ## A fast table() implementation for the 1D case (replacing the '...'
>    ## arg with 'x' and omitting the 'dnn' and 'deparse.level' arguments
>    ## which are unrelated to performance).
>
>    table1D <- function(x, exclude = if (useNA == "no") c(NA, NaN),
>                        useNA = c("no", "ifany", "always"))
>    {
>      if (!missing(exclude) && is.null(exclude)) {
>          useNA <- "always"
>      } else {
>          useNA <- match.arg(useNA)
>      }
>      if (useNA == "always" && !missing(exclude))
>          exclude <- setdiff(exclude, NA)
>      if (is.factor(x)) {
>          x2 <- levels(x)
>          append_NA <- (useNA == "always" ||
>                        useNA == "ifany" && any(is.na(x))) &&
>                       !any(is.na(x2))
>          if (append_NA) {
>              x2 <- c(x2, NA)
>              x <- factor(x, levels=x2, exclude=NULL)
>          }
>          t2 <- tabulate(x, nbins=length(x2))
>          if (!is.null(exclude)) {
>              keep_idx <- which(!(x2 %in% exclude))
>              x2 <- x2[keep_idx]
>              t2 <- t2[keep_idx]
>          }
>      } else {
>          xx <- match(x, x)
>          t <- tabulate(xx, nbins=length(xx))
>          keep_idx <- which(t != 0L)
>          x2 <- x[keep_idx]
>          t2 <- t[keep_idx]
>          if (!is.null(exclude)) {
>              exclude <- as.vector(exclude, typeof(x))
>              keep_idx <- which(!(x2 %in% exclude))
>              x2 <- x2[keep_idx]
>              t2 <- t2[keep_idx]
>          }
>          oo <- order(x2)
>          x2 <- x2[oo]
>          t2 <- t2[oo]
>          append_NA <- useNA == "always" && !any(is.na(x2))
>          if (append_NA) {
>              x2 <- c(x2, NA)
>              t2 <- c(t2, 0L)
>          }
>      }
>      ans <- array(t2)
>      dimnames(ans) <- list(as.character(x2))
>      names(dimnames(ans)) <- "x"  # always set to 'x'
>      class(ans) <- "table"
>      ans
>    }
>
> table1D() also fixes some issues with base::table() that can be exposed
> by running the tests below.
>
>    test_table <- function(FUN_NAME)
>    {
>      FUN <- match.fun(FUN_NAME)
>
>      .make_target <- function(target_names, target_data)
>      {
>          ans <- array(target_data)
>          dimnames(ans) <- list(as.character(target_names))
>          names(dimnames(ans)) <- "x"
>          class(ans) <- "table"
>          ans
>      }
>
>      .check_identical <- function(target, current, varname, extra_args)
>      {
>          if (identical(target, current))
>              return()
>          if (extra_args != "")
>              extra_args <- paste0(", ", extra_args)
>          cat("unexpected result for '", FUN_NAME,
>              "(x=", varname, extra_args, ")'\n", sep="")
>      }
>
>      .test_exclude <- function(x, varname, target_names0, target_data0,
> exclude)
>      {
>          extra_args <- paste0("exclude=", deparse(exclude))
>          current <- FUN(x=x, exclude=exclude)
>          target_names <- target_names0
>          target_data <- target_data0
>          if (is.null(exclude)) {
>              if (!any(is.na(target_names))) {
>                  target_names <- c(target_names, NA)
>                  target_data <- c(target_data, 0L)
>              }
>          } else {
>              if (!is.factor(x)) {
>                  exclude <- as.vector(exclude, typeof(x))
>              } else if (!any(is.na(levels(x)))) {
>                  exclude <- union(exclude, NA)
>              }
>              exclude_idx <- match(exclude, target_names, nomatch=0L)
>              if (any(exclude_idx != 0L)) {
>                  target_names <- target_names[-exclude_idx]
>                  target_data <- target_data[-exclude_idx]
>              }
>          }
>          target <- .make_target(target_names, target_data)
>          .check_identical(target, current, varname, extra_args)
>      }
>
>      .do_exclude_tests <- function(x, varname, target_names0, target_data0,
>                                    more_excludes=NULL)
>      {
>          .BASIC_EXCLUDES <- list(c(NA, NaN), NULL, numeric(0), NA, NaN)
>          excludes <- c(.BASIC_EXCLUDES, more_excludes)
>          for (exclude in excludes)
>              .test_exclude(x, varname, target_names0, target_data0,
> exclude)
>      }
>
>      ## Test on a numeric vector.
>      x0 <- numeric(0)
>      .do_exclude_tests(x0, "x0", character(0), integer(0), list(5.3))
>
>      x1_target_names0 <- c(-9, 4, 5.3, NaN, NA)
>      x1_target_data0 <- c(1L, 2L, 1L, 2L, 3L)
>      x1 <- c(5.3, 4, NaN, 4, NA, NA, NaN, -9, NA)
>      excludes <- list(c(5.3, -9),
>                       c(5.3, NA, -9),
>                       c(5.3, NaN, -9),
>                       c(5.3, 80, -9),
>                       x1_target_names0)
>      .do_exclude_tests(x1, "x1", x1_target_names0, x1_target_data0,
> excludes)
>
>      x2_target_names0 <- c(-9, 4, 5.3, NA, NaN)
>      x2_target_data0 <- c(1L, 2L, 1L, 3L, 2L)
>      x2 <- rev(x1)
>      .do_exclude_tests(x2, "x2", x2_target_names0, x2_target_data0,
> excludes)
>
>      x3_target_names0 <- c(-9, 4, 5.3)
>      x3_target_data0 <- c(1L, 2L, 1L)
>      x3 <- c(5.3, 4, 4, -9)
>      .do_exclude_tests(x3, "x3", x3_target_names0, x3_target_data0,
> excludes)
>
>      ## Test on a factor.
>      f0 <- factor()
>      .do_exclude_tests(f0, "f0", character(0), integer(0), list(5.3))
>
>      f1 <- factor(x1)
>      .do_exclude_tests(f1, "f1", x1_target_names0, x1_target_data0,
> excludes)
>
>      f2 <- factor(x1, exclude=NULL)
>      .do_exclude_tests(f2, "f2", x1_target_names0, x1_target_data0,
> excludes)
>
>      f3_target_names0 <- c(6.82, x1_target_names0, -7.66)
>      f3_target_data0 <- c(0L, 1L, 2L, 1L, 0L, 0L, 0L)
>      f3 <- factor(x3, levels=f3_target_names0, exclude=NULL)
>      .do_exclude_tests(f3, "f3", f3_target_names0, f3_target_data0,
> excludes)
>
>      x4_target_names0 <- c(6.82, -9, 5.3, 4, -7.66)
>      x4_target_data0 <- c(0L, 1L, 1L, 2L, 0L)
>      f4 <- factor(x3, levels=x4_target_names0, exclude=NULL)
>      .do_exclude_tests(f4, "f4", x4_target_names0, x4_target_data0,
> excludes)
>
>      ## Test on a character vector.
>      c0 <- character(0)
>      .do_exclude_tests(c0, "c0", character(0), integer(0), list("Aa"))
>
>      c1 <- c("b", "AA", "", "a", "ab", "NaN", "4", "Aa", NA, "NaN",
> "ab", NA)
>      c1_target_names0 <- sort(unique(c1), na.last=TRUE)
>      c1_target_data0 <- c(1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L)
>      excludes <- list(c("Aa", 4, ""),
>                       c("Aa", NA, 4, "", "Z"),
>                       c("Aa", NaN, 4, "", "Z"),
>                       c("Aa", 4, "", "Z"))
>      .do_exclude_tests(c1, "c1", c1_target_names0, c1_target_data0,
> excludes)
>
>      c2 <- c("b", "AA", "", "a", "ab", "", "", "4", "Aa", "ab")
>      c2_target_names0 <- sort(unique(c2), na.last=TRUE)
>      c2_target_data0 <- c(3L, 1L, 1L, 1L, 1L, 2L, 1L)
>      .do_exclude_tests(c2, "c2", c2_target_names0, c2_target_data0,
> excludes)
>
>      ## Test on a logical vector.
>      l0 <- logical(0)
>      .do_exclude_tests(l0, "l0", character(0), integer(0), list(c("Aa",
> TRUE)))
>
>      l1 <- c(FALSE, FALSE, NA, TRUE, FALSE, FALSE, NA, NA, TRUE)
>      l1_target_names0 <- c(FALSE, TRUE, NA)
>      l1_target_data0 <- c(4L, 2L, 3L)
>      excludes <- list(c(TRUE, FALSE),
>                       c("Aa", NA, TRUE),
>                       c("Aa", NaN, TRUE),
>                       l1_target_names0)
>      .do_exclude_tests(l1, "l1", l1_target_names0, l1_target_data0,
> excludes)
>
>      l2 <- c(FALSE, FALSE, TRUE, FALSE, FALSE, TRUE)
>      l2_target_names0 <- c(FALSE, TRUE)
>      l2_target_data0 <- c(4L, 2L)
>      .do_exclude_tests(l2, "l2", l2_target_names0, l2_target_data0,
> excludes)
>    }
>
>    test_table("table")    # will display some issues
>    test_table("table1D")  # should not display anything
>
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From HodgessE at uhd.edu  Tue Sep 17 02:06:09 2013
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Tue, 17 Sep 2013 00:06:09 +0000
Subject: [Rd] strange behavior for RcmdrPlugin.qual
Message-ID: <FF9DB805FC41CC4E95825A50F680630217A7D170@columbia.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130917/b3c67880/attachment.pl>

From jfox at mcmaster.ca  Tue Sep 17 03:01:09 2013
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 16 Sep 2013 21:01:09 -0400
Subject: [Rd] strange behavior for RcmdrPlugin.qual
In-Reply-To: <FF9DB805FC41CC4E95825A50F680630217A7D170@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F680630217A7D170@columbia.uhd.campus>
Message-ID: <web-474275799@cgpsrv2.cis.mcmaster.ca>

Dear Erin,

I noticed that your RcmdrPlugin.qual package declares qcc under Suggests, and thus qcc isn't necessarily installed along with the plug-in. The menu file for your plug-in requires the presence of qcc to install most of the menu items under the Quality Control menu.

I installed your plug-in via install.packages() on a 64-bit Windows 8 machine, with R 3.0-1 and Rcmdr 2.0-0. When I first loaded the plug-in, both in 64-bit and 32-bit Windows, most of the items under the Quality Control menu didn't appear, because qcc wasn't installed. The menu itself, along with a couple of items, did appear, and so this may not be the same problem as you described. Also, I don't have a 32-bit machine but, as I said, saw identical behaviour under 32- and 64-bit R on a 64-bit machine.

I hope this helps,
 John

On Tue, 17 Sep 2013 00:06:09 +0000
 "Hodgess, Erin" <HodgessE at uhd.edu> wrote:
> Hello!
> 
> Over the weekend, I updated my RcmdrPlugin.qual package.
> 
> It works fine on a 64 bit Windows machine but not a 32 bit.  This is very strange.  The new menu with all of the Quality Control stuff does not appear.
> 
> Have any of you run into this sort of thing before, please?
> 
> Thanks,
> Sincerely,
> Erin
> 
> 
> Erin M. Hodgess, Ph.D.
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From crunch at 3c58.net  Tue Sep 17 01:12:04 2013
From: crunch at 3c58.net (crunch)
Date: Mon, 16 Sep 2013 16:12:04 -0700 (PDT)
Subject: [Rd] JDK not registered
In-Reply-To: <1379206267713-4676149.post@n4.nabble.com>
References: <1379206267713-4676149.post@n4.nabble.com>
Message-ID: <1379373124502-4676286.post@n4.nabble.com>

Given:
$JAVA_HOME=~/jdk1.7.0_40
$R_SHELL=/bin/sh
$PATH=$R_HOME/bin:$JAVA_HOME/bin:...

which jar --> ~/jdk1.7.0_40/bin/jar
which javac --> ~/jdk1.7.0_40/bin/javac
which javah --> ~/jdk1.7.0_40/bin/javah
which java --> '', even though there is one in $JAVA_HOME/bin
whereis java -->
java: /bin/java /usr/bin/java /sbin/java /usr/sbin/java /lib/java
/usr/lib/java /usr/local/bin/java /usr/share/java
   obviously missing the 1.7.0_40 version in $JAVA_HOME/bin as well as the
1.5 version in /usr/bin

If I push into the Rserve package directory and run ./configure, I get:
...
checking Java support in R... present:
interpreter : ''
archiver    : ''
compiler    : ''
header prep.: ''
cpp flags   : ''
java libs   : ''
configure: error: Java Development Kit (JDK) is missing or not registered.

Of course that may be because I have not yet successfully completed a make
of R

if I run R CMD javareconf -e
I get:
Java interpreter : /home1/optimal1/jdk1.7.0_40/jre/bin/java           (why
not the one in the jdk/bin?)
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
Error occurred during initialization of VM
Could not reserve enough space for object heap

*** Java interpreter doesn't work properly.

I have found that $JAVA_HOME/bin/java (and the one in the jre/bin directory)
each complain 
Error occurred during initialization of VM
Could not reserve enough space for object heap
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.

but, if I define:
alias java='$JAVA_HOME/bin/java -Xmx668m -XX:MaxPermSize=128m'
I can run java in SSH, though R CMD javareconf -e
still fails to initialize the VM.

What can I do to get javareconf to run java with those memory limits?




--
View this message in context: http://r.789695.n4.nabble.com/R-build-issues-tp4676149p4676286.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Tue Sep 17 10:25:14 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Sep 2013 09:25:14 +0100
Subject: [Rd] FOSS licence with BuildVignettes: false
In-Reply-To: <52371A6F.6020909@gmail.com>
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
	<52361636.5060305@statistik.tu-dortmund.de>
	<loom.20130916T005045-889@post.gmane.org>
	<5236CD24.40107@statistik.tu-dortmund.de>
	<52371A6F.6020909@gmail.com>
Message-ID: <523811EA.9090300@stats.ox.ac.uk>

On 16/09/2013 15:49, Paul Gilbert wrote:
> On 13-09-16 05:19 AM, Uwe Ligges wrote:
> ...
>> Yes, and I could see really rare circumstances where vignette building
>> takes a long time and the maintainer decides not to build vignettes as
>> part of the daily checks.
> ...
>
> I thought 'BuildVignettes: FALSE' only turns of assembling the pdf, all
> the code is still run.  I don't think that would affect the time very
> much. Am I wrong (again)?

Yes, as the code is run again to re-build the vignettes.

The main use of BuildVignettes: FALSE is when building the vignettes 
requires unusual facilities -- presumably not R ones as it does not turn 
off running the code.  However, for a FOSS package, the means to 
re-build the vignettes has to available to others, and CRAN therefore 
tries it so see if all the sources are available.  Almost every time we 
uncover some problem with the sources and stale vignette PDFs.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kasperdanielhansen at gmail.com  Tue Sep 17 15:56:42 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 17 Sep 2013 09:56:42 -0400
Subject: [Rd] processing of /vignettes and /inst/doc
Message-ID: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130917/56fc2238/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 17 17:29:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 11:29:44 -0400
Subject: [Rd] processing of /vignettes and /inst/doc
In-Reply-To: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
References: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
Message-ID: <52387568.0@gmail.com>

On 17/09/2013 9:56 AM, Kasper Daniel Hansen wrote:
> It is stated in R-exts that Sweave files (.Rnw) are either processed in
> /vignettes or /inst/doc, not both.  Furthermore, it is stated that external
> manuals and other files in /inst/doc will be installed.

The long run intention is that vignettes will be in the vignettes 
directory, and nowhere else.  Files in inst/doc will be installed, but 
they are not vignettes, they are just documentation files.  This has 
been documented for a long time, but it hasn't been enforced.

The new change is that vignettes will be produced at build time, by the 
package maintainer, not by the user, at INSTALL time.  Version 3.0.2 is 
intended to handle tar.gz files built under earlier versions of R 
according to the old rules, and also tarballs built under the new system.

So how your example below is handled depends on which version built the 
tarball.  I'll assume everything is being done with 3.0.2 beta.
>
> This behaviour has been used to deal with the situation where a package has
> two "vignettes", one that is easily processed and one that has a long
> running time.  This could be done by having
>    /vignettes/small.Rnw
>    /inst/doc/big.pdf
> with obvious notation.  Now, big.pdf is really produced by a Sweave
> document, so what we really have is
>    /vignettes/small.Rnw
>    /inst/doc/big.pdf
>    /inst/doc/big.Rnw

Since this package has a vignettes directory, it's assumed that that is 
where the vignettes are.  So the current version doesn't see 
inst/doc/big.Rnw as a vignette.

>
> This used to work, in the sense that the tarball produced by R CMD build
> produced
>    /inst/doc/small.Rnw
>    /inst/doc/small.pdf
>    /inst/doc/big.pdf
>    /inst/doc/big.Rnw
>
> Recently (R-3.0.2 beta, specifically "R version 3.0.2 beta (2013-09-16
> r63937)"), the final tarball only has
>    /inst/doc/small.Rnw
>    /inst/doc/small.pdf
>    /inst/doc/big.Rnw

That looks like a bug, in that inst/doc/big.pdf should still have been 
included as a non-vignette documentation file.  I'll look into that.
>
> If we remove
>    /inst/doc/big.Rnw
> the pdf gets included.  So it seems that the presence of
>    /inst/doc/big.Rnw
> prevents the pdf from being included.
>
> This seems to me to be unwanted behaviour, since R-exts says
>
> "In addition to the help files in Rd format, R packages allow the inclusion
> of documents in arbitrary other formats. The standard location for these is
> subdirectory inst/doc of a source package, the contents will be copied to
> subdirectory docwhen the package is installed."

That statement should be correct, hence current behaviour is a bug.

Duncan Murdoch

>
> However, it is also clear that Sweave docs are "special".  Still, I believe
> the past behaviour was better and more in line with what I infer as the
> intended behaviour.
>
> An example is the ADaCGH2 package in Bioconductor which I am not involved
> with.  I include a cc to the maintainer who reported this on bioc-devel.
>
> Best,
> Kasper
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Sep 17 19:30:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 13:30:50 -0400
Subject: [Rd] processing of /vignettes and /inst/doc
In-Reply-To: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
References: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
Message-ID: <523891CA.5080505@gmail.com>

On 17/09/2013 9:56 AM, Kasper Daniel Hansen wrote:
> It is stated in R-exts that Sweave files (.Rnw) are either processed in
> /vignettes or /inst/doc, not both.  Furthermore, it is stated that external
> manuals and other files in /inst/doc will be installed.
>
> This behaviour has been used to deal with the situation where a package has
> two "vignettes", one that is easily processed and one that has a long
> running time.  This could be done by having
>    /vignettes/small.Rnw
>    /inst/doc/big.pdf
> with obvious notation.  Now, big.pdf is really produced by a Sweave
> document, so what we really have is
>    /vignettes/small.Rnw
>    /inst/doc/big.pdf
>    /inst/doc/big.Rnw
>
> This used to work, in the sense that the tarball produced by R CMD build
> produced
>    /inst/doc/small.Rnw
>    /inst/doc/small.pdf
>    /inst/doc/big.pdf
>    /inst/doc/big.Rnw
>
> Recently (R-3.0.2 beta, specifically "R version 3.0.2 beta (2013-09-16
> r63937)"), the final tarball only has
>    /inst/doc/small.Rnw
>    /inst/doc/small.pdf
>    /inst/doc/big.Rnw
>
> If we remove
>    /inst/doc/big.Rnw
> the pdf gets included.  So it seems that the presence of
>    /inst/doc/big.Rnw
> prevents the pdf from being included.
>
> This seems to me to be unwanted behaviour, since R-exts says
>
> "In addition to the help files in Rd format, R packages allow the inclusion
> of documents in arbitrary other formats. The standard location for these is
> subdirectory inst/doc of a source package, the contents will be copied to
> subdirectory docwhen the package is installed."
>
> However, it is also clear that Sweave docs are "special".  Still, I believe
> the past behaviour was better and more in line with what I infer as the
> intended behaviour.
>
> An example is the ADaCGH2 package in Bioconductor which I am not involved
> with.  I include a cc to the maintainer who reported this on bioc-devel.

This was a bug in the cleanup code after vignettes were built:  it was a 
little too zealous, and cleaned up things it hadn't produced.
After fixing the bug, for a test case like the one described above, R 
3.0.2 will not build the big vignette, but will consider it to be a 
vignette.  R-devel will not consider it to be a vignette.  Both should 
install it into inst/doc in the tarball.

Duncan Murdoch


From edd at debian.org  Tue Sep 17 19:36:18 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 17 Sep 2013 12:36:18 -0500
Subject: [Rd] R-Forge email down? (Re: R-Forge SVN commit hook to email
	appears to be broken)
In-Reply-To: <21045.64712.585925.648925@max.nulle.part>
References: <21045.64712.585925.648925@max.nulle.part>
Message-ID: <21048.37650.161796.228761@max.nulle.part>


On 15 September 2013 at 13:30, Dirk Eddelbuettel wrote:
| 
| It would appear that commits no longer trigger emails; for Rcpp at least we
| are two commits (made earlier today) ahead of what was emailed.  
| 
| Maybe the mail agent needs to be restarted?
| 
| Many thanks for taking care of r-forge. It is appreciated.

I didn't get any follow-up on this yet, and may be wrong on this, but I have
the feeling that email processing seems to be down in general for R-Forge.

The archives for rcpp-devel and rcpp-commits both end on Sep 14, or three
days ago. We made several commits which usually result in prompt emails. 

Did anybody get email from r-forge?  Is it down?  One can still telnet to
port 25 on the box, but as noted above, I cannot see any trace of outgoing
email. 

Thanks,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From kasperdanielhansen at gmail.com  Tue Sep 17 19:47:47 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 17 Sep 2013 13:47:47 -0400
Subject: [Rd] processing of /vignettes and /inst/doc
In-Reply-To: <523891CA.5080505@gmail.com>
References: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
	<523891CA.5080505@gmail.com>
Message-ID: <CAC2h7us8R00kfb-zhtWCSXEXGkNo+Qx9Ft-3b=iD4h5RKjd=ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130917/db2ee8c4/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 17 19:55:20 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 13:55:20 -0400
Subject: [Rd] processing of /vignettes and /inst/doc
In-Reply-To: <CAC2h7us8R00kfb-zhtWCSXEXGkNo+Qx9Ft-3b=iD4h5RKjd=ww@mail.gmail.com>
References: <CAC2h7uungQ9vDa_O54om2+p_=AP6hpeegnmjRyS=K5TJGHMwbg@mail.gmail.com>
	<523891CA.5080505@gmail.com>
	<CAC2h7us8R00kfb-zhtWCSXEXGkNo+Qx9Ft-3b=iD4h5RKjd=ww@mail.gmail.com>
Message-ID: <52389788.4000009@gmail.com>

On 17/09/2013 1:47 PM, Kasper Daniel Hansen wrote:
> Thanks a lot for the speedy fix.
>
> It is a little unclear to me what "considers it to be a vignette" 
> implies. Re-reading R-exts, it is pretty clear on
>   vignettes, Sweave format
>   vignettes, non-Sweave
> but a little unclear on
>   manuals, arbitrary format
> except mentioning that they should go in /inst/doc.
>
> Are such manuals not indexed by the help system?  Not found by 
> vignettes() (and if so, is there another mechanism for discovering them)?

They would not be found by vignettes() or browseVignettes(), but would 
be listed on the HTML help page under "User guides, package vignettes 
and other documentation."

Duncan Murdoch


From edd at debian.org  Tue Sep 17 21:54:07 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 17 Sep 2013 14:54:07 -0500
Subject: [Rd] R-Forge email down? (Re: R-Forge SVN commit hook to
	email	appears to be broken)
In-Reply-To: <20130917213509.33446hrpicqb267h@webmail.wu.ac.at>
References: <21048.39284.806325.970304@fangorn.hornik.net>
	<20130917213509.33446hrpicqb267h@webmail.wu.ac.at>
Message-ID: <21048.45919.515563.402235@max.nulle.part>


Martin,

On 17 September 2013 at 21:35, mpacala at wu.ac.at wrote:
| Hi
| 
| Mailman daemon wasn't running, not sure yet why.
| The good news is that it appears that mailman is running through the  
| built up queue, so everyone should get the mails they should have  
| received

Thanks so much for turning it back on. (And yes, this has happened once or
twice before.  It's just software after all...)

It does indeed look like we are catching up on the queue. 

Cheers, Dirk

 
| Best regards
| Martin
| 
| On 15 September 2013 at 13:30, Dirk Eddelbuettel wrote:
| |
| | It would appear that commits no longer trigger emails; for Rcpp at least we
| | are two commits (made earlier today) ahead of what was emailed.
| |
| | Maybe the mail agent needs to be restarted?
| |
| | Many thanks for taking care of r-forge. It is appreciated.
| 
| I didn't get any follow-up on this yet, and may be wrong on this, but I have
| the feeling that email processing seems to be down in general for R-Forge.
| 
| The archives for rcpp-devel and rcpp-commits both end on Sep 14, or three
| days ago. We made several commits which usually result in prompt emails.
| 
| Did anybody get email from r-forge?  Is it down?  One can still telnet to
| port 25 on the box, but as noted above, I cannot see any trace of outgoing
| email.
| 
| Thanks,  Dirk
| 
| 

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mpacala at wu.ac.at  Tue Sep 17 21:35:09 2013
From: mpacala at wu.ac.at (mpacala at wu.ac.at)
Date: Tue, 17 Sep 2013 21:35:09 +0200
Subject: [Rd] R-Forge email down? (Re: R-Forge SVN commit hook to
	email	appears to be broken)
In-Reply-To: <21048.39284.806325.970304@fangorn.hornik.net>
References: <21048.39284.806325.970304@fangorn.hornik.net>
Message-ID: <20130917213509.33446hrpicqb267h@webmail.wu.ac.at>

Hi

Mailman daemon wasn't running, not sure yet why.
The good news is that it appears that mailman is running through the  
built up queue, so everyone should get the mails they should have  
received

Best regards
Martin

On 15 September 2013 at 13:30, Dirk Eddelbuettel wrote:
|
| It would appear that commits no longer trigger emails; for Rcpp at least we
| are two commits (made earlier today) ahead of what was emailed.
|
| Maybe the mail agent needs to be restarted?
|
| Many thanks for taking care of r-forge. It is appreciated.

I didn't get any follow-up on this yet, and may be wrong on this, but I have
the feeling that email processing seems to be down in general for R-Forge.

The archives for rcpp-devel and rcpp-commits both end on Sep 14, or three
days ago. We made several commits which usually result in prompt emails.

Did anybody get email from r-forge?  Is it down?  One can still telnet to
port 25 on the box, but as noted above, I cannot see any trace of outgoing
email.

Thanks,  Dirk


From szehnder at uni-bonn.de  Wed Sep 18 19:06:05 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 18 Sep 2013 19:06:05 +0200
Subject: [Rd] Design for classes with database connection
Message-ID: <14477DE0-FE60-4AC7-8246-E062322A05AA@uni-bonn.de>

Dear R-Devels,

I am designing right now a package intended to simplify the handling of market microstructure data (tick data, order data, etc). As these data is most times pretty huge and needs to be reordered quite often (e.g. if several security data is batched together or if only a certain time range should be considered) - the package needs to handle this. 

Before I start, I would like to mention some facts which made me decide to construct an own package instead of using e.g. the packages bigmemory, highfrequency, zoo or xts: AFAIK big memory does not provide the opportunity to handle data with different types (timestamp, string and numerics) and their appropriate sorting, for this task databases offer better tools. Package highfrequency is designed to work specifically with a certain data structure and the data in market microstructure has much greater versatility. Packages zoo and xts offer a lot of versatility but do not offer the data sorting ability needed for such big data. 

I would like to get some feedback in regard to my decision and in regard to the short design overview following.  
  
My design idea is now:

1. Base the package on S4 classes, with one class that handles data-reading from external sources, structuring and reordering. Structuring is done in regard to specific data variables, i.e. security ID, company ID, timestamp, price, volume (not all have to be provided, but some surely exist on market microstructure data). The less important variables are considered as a slot @other and are only ordered in regard to the other variables. Something like this:

.mmstruct <- setClass('mmstruct', representation(
			name	= "character",
			index	= "array",
			N		= "integer",
			K		= "integer",
			compiD 	= "array",
			secID  	= "array",
			tradetime	= "POSIXlt",
			flag		= "array",
			price	= "array",
			vol		= "array",
			other	= "data.frame"))

2. To enable a lightweight ordering function, the class should basically create an SQLite database on construction and delete it if 'rm()' is called. Throughout its life an object holds the database path and can execute queries on the database tables. By this, I can use the table sorting of SQLite (e.g. by constructing an index for each important variable). I assume this is faster and more efficient than programming something on my own - why reinventing the wheel? For this I would use VIRTUAL classes like:

.mmstructBASE	<- setClass('mmstructBASE', representation(
					dbName		= "character",
					dbTable		= "character"))

.mmstructDB		<- setClass('mmstructDB', representation(
					conn		= "SQLiteConnection"),
					contains		= c("mmstructBASE"))

.mmstruct <- setClass('mmstruct', representation(
			name	= "character",
			index	= "array",
			N		= "integer",
			K		= "integer",
			compiD 	= "array",
			secID  	= "array",
			tradetime	= "POSIXlt",
			price	= "array",
			vol		= "array",
			other	= "data.frame"),
			contains = c("mmstructDB"))

The slots in the mistrust class hold then a view (e.g. only the head()) of the data or can be used to hold retrieved data from the underlying database. 

3. The workflow would than be something like: 	a) User reads in the data from an external source and gets a data.frame from it. 
											b) This data.frame then can be used to construct an mmstruct object from it by formatting the variables and read them into the SQLite database constructed. 
											c) Given the data structure in the database, the user can sort the data by secID, timestamp etc. and can use several algorithms for cleaning the data (package-specific not in the database) 
											d) Example: The user makes a query to get only price from entries compID = "AA" with tradetime < "2012-03-09" or with trade time only first trading day in a month. This can then be converted e.g. to a 'ts' object in R by coercing 
											e) In addition the user can perform several estimations of market microstructure models by calling package-specific functions. 


Is there a big fault in my design, something I haven't considered? I am very sure on this list are researchers and developers with much more experience. I would like to hear your opinion and ideas. I learn from it and can maybe get to a design which I can then implement for the research on such data and models. 


Best

Simon



 

From xie at yihui.name  Wed Sep 18 19:47:31 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 18 Sep 2013 13:47:31 -0400
Subject: [Rd] getParseData() for imaginary numbers
Message-ID: <CANROs4eL+BT9jqDVcy-MnNHK_g-nVLd0o+aDjk_UU17=cG0DZA@mail.gmail.com>

Hi,

The imaginary unit is gone in the 'text' column in the returned data
frame from getParseData(), e.g. in the example below, perhaps the text
should be 1i instead of 1:

> p=parse(text='1i')
> getParseData(p)
  line1 col1 line2 col2 id parent     token terminal text
1     1    1     1    2  1      2 NUM_CONST     TRUE    1
2     1    1     1    2  2      0      expr    FALSE
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From i.kosmidis at ucl.ac.uk  Thu Sep 19 00:52:18 2013
From: i.kosmidis at ucl.ac.uk (Kosmidis, Ioannis)
Date: Wed, 18 Sep 2013 22:52:18 +0000
Subject: [Rd] dbeta may hang R session for very large values of the shape
 parameters
Message-ID: <73C96EB9-5DA8-48A3-A125-BC65B9B98A45@ucl.ac.uk>

Dear all,

we received a bug report for betareg, that in some cases the optim call in betareg.fit would hang the R session and the command cannot be interrupted by Ctrl-C?

We narrowed down the problem to the dbeta function which is used for the log likelihood evaluation in betareg.fit. 

Particularly, the following command hangs the R session to a 100% CPU usage in all systems we tried it (OS X 10.8.4, Debian GNU Linux, Ubuntu 12.04) with either R-3.0.1 and with the R-devel version (in all systems I waited 3 minutes before I kill R):

## Warning: this will hang the R session
dbeta(0.9, 1e+308, 10)

Furthermore, through a trial and error investigation using the following code

## Warning: this will hang the R session
x <- 0.9
for (i in 0:100) {
 a <- 1e+280*2^i
 b <- 10
 cat("shape1 =", a, "\n")
 cat("shape2 =", b, "\n")
 cat("Beta density", dbeta(x, shape1 = a, shape2 = b), "\n")
 cat("===\n")
}

I noticed that:
* this seems to happen when shape1 is about 1e+308, seemingly irrespective of the value of shape2 (run the above with another value of b), and as it appears only when x>=0.9 and x < 1 (run the above lines with x <- 0.89999 for example and everything works as expected). 
* similar problems are encountered for small x values when shape2 is massive.

I am not sure why this happens but it looks deep to me. The temporary fix for the purposes of betareg was a hack (a simple if command that returns NA for the log likelihood if any shape parameter has values greater than 1e+300 say). 

Nevertheless, I thought that this is an issue worth reporting to R-devel (instead of R-help), especially since dbeta may be used within generic optimisers and figuring that dbeta is the problem can be hard --- it took us some time before we started suspecting dbeta.

Interestingly, this appears to happen close to what R considers infinity. Typing
1.799e+308
into R returns Inf.

I hope the above limited in scope analysis is informative.

Best regards,
Ioannis



-- 
Dr Ioannis Kosmidis
Department of Statistical  Science,
University College,
London, WC1E 6BT, UK
Webpage: http://www.ucl.ac.uk/~ucakiko


From spencer.graves at prodsyse.com  Thu Sep 19 05:35:15 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 18 Sep 2013 20:35:15 -0700
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <5232C11A.7070705@stats.ox.ac.uk>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
Message-ID: <523A70F3.4030805@prodsyse.com>

Hello, All:


	  The vignette with the sos package used "upquote.sty", required for R 
Journal when it was published in 2009.  Current CRAN policy disallows 
"upquote.sty", and I've so far not found a way to pass "R CMD check" 
with sos without upquote.sty.


	  I changed sos.Rnw per an email exchange with Prof. Ripley without 
solving the problem; see below.  The key error messages (see the results 
of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error: 
Environment article undefined" and " sos.tex:558: LaTeX Error: 
\begin{document} ended by \end{article}."  When the article worked, it 
had bot \begin{document} and \begin{article}, with matching \end 
statements for both.  I've tried commenting out either without success.


	  The current nonworking code is available on R-Forge via anonymous SVN 
checkout using "svn checkout 
svn://svn.r-forge.r-project.org/svnroot/rsitesearch/".  Any suggestions 
on how to fix this would be greatly appreciated.


        Thanks,
        Spencer


###### COMPLETE RESULTS FROM R CMD check ########


Microsoft Windows [Version 6.1.7600]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\sgraves>cd 2013
C:\Users\sgraves\2013>cd R_pkgs
C:\Users\sgraves\2013\R_pkgs>cd sos
C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
* checking for file 'sos/DESCRIPTION' ... OK
* preparing 'sos':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* creating vignettes ... ERROR
Loading required package: brew

Attaching package: 'sos'

The following object is masked from 'package:utils':

      ?

Loading required package: WriteXLS
Perl found.

The following Perl modules were not found on this system:

Text::CSV_XS

If you have more than one Perl installation, be sure the correct one was 
used he
re.

Otherwise, please install the missing modules. See the package INSTALL 
file for
more information.

Loading required package: RODBC
Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au>  and 
Rolf Turner
<r.turner at auckland.ac.nz>       with substantial contributions of code by
Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus 
Waagepetersen.
Additional contributions        by Q.W. Ang;    S. Azaele;      C. Beale;
R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; 
R. Bivan
d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; 
J.B. Che
n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; 
J.-F. Co
eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard; 
P.J. Dig
gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores;    N. 
Funwi-Gabga;
          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick; 
   P. Graba
rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; 
M. Herin
g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; 
R. Ihaka
;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; 
M. Kuhn;
          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb; 
   J. Lee;
          G.P. Leser; [... truncated]
Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas 
Bates [ct
b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb], 
Gregor Gorja
nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael 
Laboissiere [ctb
], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian 
Ripley [
ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in 
column 'Autho
r'
Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael 
Ash [ctb],
Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb], 
Andy Cha
ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi 
Pour [c
tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb], 
Uwe Ligg
es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen 
[ctb], Dunc
an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley 
[ctb], Mi
roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column 
'Author'

Perl found.

The following Perl modules were not found on this system:

Text::CSV_XS

If you have more than one Perl installation, be sure the correct one was 
used he
re.

Otherwise, please install the missing modules. See the package INSTALL 
file for
more information.

Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au>  and 
Rolf Turner
<r.turner at auckland.ac.nz>       with substantial contributions of code by
Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus 
Waagepetersen.
Additional contributions        by Q.W. Ang;    S. Azaele;      C. Beale;
R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; 
R. Bivan
d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; 
J.B. Che
n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; 
J.-F. Co
eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard; 
P.J. Dig
gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores;    N. 
Funwi-Gabga;
          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick; 
   P. Graba
rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; 
M. Herin
g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; 
R. Ihaka
;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; 
M. Kuhn;
          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb; 
   J. Lee;
          G.P. Leser; [... truncated]
Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas 
Bates [ct
b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb], 
Gregor Gorja
nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael 
Laboissiere [ctb
], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian 
Ripley [
ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in 
column 'Autho
r'
Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael 
Ash [ctb],
Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb], 
Andy Cha
ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi 
Pour [c
tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb], 
Uwe Ligg
es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen 
[ctb], Dunc
an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley 
[ctb], Mi
roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column 
'Author'

Warning: running command 
'"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
et --pdf "sos.tex"  -I 
"C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status 1
Error: running 'texi2dvi' on 'sos.tex' failed

LaTeX errors:
sos.tex:16: LaTeX Error: Environment article undefined.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help
Your command was ignored.
sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help
Your command was ignored.
Execution halted


On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
> On 13/09/2013 08:30, Spencer Graves wrote:
>> Dear Prof. Ripley:
>>
>>
>>        What do you recommend I do with the vignette that comes with that
>> package?
>>
>>
>>        That vignette is a copy of the article published in the R Journal
>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>> RJournal.sty.  When I removed RJournal.sty from the vignette
>> subdirectory, "R CMD build" failed.  I have no idea what you want me to
>> do to fix this problem.  Further assistance would be appreciated.
>
> Don't spam all the other addressees!
>
> The issue is using RJournal.sty in a vignette with ae fonts.  I am
> guessing that
>
> \usepackage[noae]{Sweave}
>
> might work: otherwise you need to remove the reference to upquote.sty
> in RJournal.sty.
>
>
>>
>>
>>        Thanks,
>>        Spencer Graves
>>
>>
>> p.s.  I understand reasonably well R and the *.Rd documentation
>> standard, thanks in part to your book on "Modern Applied Statistics with
>> S" and the documentation that ships with R. However, this is the only
>> vignette I've written, and I have not used LaTeX much for anything else
>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>> with R and Matlab (Springer).
>>
>>
>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>>> Brian,
>>> I am making changes, downloading new version of Sweave.sty and
>>> upquote.sty. However, it is not clear to me how to properly credit
>>> Fritz Leisch and others for Sweave. Do you mean in the sweave document
>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>>> find anything about this in "Writing R Extensions".
>>> Thanks for any guidance,
>>> Brian
>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>>>> upquote.sty in earlier versions of R and not that currently being
>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>>>> version of upquote.sty.
>>>>
>>>> In particular, they do not work with the 'ae' fonts which are the
>>>> default for Sweave vignettes.   Packages
>>>>
>>>> boolfun calibrate popReconstruct qtlnet
>>>>
>>>> have copies in vignettes and now fail.
>>>>
>>>> Please remove them. Note too that you did not comply with the CRAN
>>>> policies on giving credit by including them in your package but not
>>>> crediting their authors: do check very carefully that there are no
>>>> other missing credits.
>>>>
>>>> Package PSM has vignettes which include upquote.sty.
>>>>
>>>> Packages makeR and sos include RJournal.sty which includes
>>>> upquote.sty: same problem.
>>>>
>>>> Please update your package as soon as possible and definitely before
>>>> the release of 3.0.2 on Sept 25.
>>>>
>>>
>>
>>
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From ripley at stats.ox.ac.uk  Thu Sep 19 09:00:46 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Sep 2013 08:00:46 +0100
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <523A70F3.4030805@prodsyse.com>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com>
Message-ID: <523AA11E.2050805@stats.ox.ac.uk>

This is nothing to do with CRAN policies (nor R).

The issue is that the current upquote.sty does not play with 'ae' fonts 
as used by default by Sweave.  The change is in TeX.

And that was what Spencer Graves was informed.


On 19/09/2013 04:35, Spencer Graves wrote:
> Hello, All:
>
>
>        The vignette with the sos package used "upquote.sty", required
> for R Journal when it was published in 2009.  Current CRAN policy
> disallows "upquote.sty", and I've so far not found a way to pass "R CMD
> check" with sos without upquote.sty.
>
>
>        I changed sos.Rnw per an email exchange with Prof. Ripley without
> solving the problem; see below.  The key error messages (see the results
> of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error:
> Environment article undefined" and " sos.tex:558: LaTeX Error:
> \begin{document} ended by \end{article}."  When the article worked, it
> had bot \begin{document} and \begin{article}, with matching \end
> statements for both.  I've tried commenting out either without success.
>
>
>        The current nonworking code is available on R-Forge via anonymous
> SVN checkout using "svn checkout
> svn://svn.r-forge.r-project.org/svnroot/rsitesearch/".  Any suggestions
> on how to fix this would be greatly appreciated.
>
>
>         Thanks,
>         Spencer
>
>
> ###### COMPLETE RESULTS FROM R CMD check ########
>
>
> Microsoft Windows [Version 6.1.7600]
> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>
> C:\Users\sgraves>cd 2013
> C:\Users\sgraves\2013>cd R_pkgs
> C:\Users\sgraves\2013\R_pkgs>cd sos
> C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
> C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
> * checking for file 'sos/DESCRIPTION' ... OK
> * preparing 'sos':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ... ERROR
> Loading required package: brew
>
> Attaching package: 'sos'
>
> The following object is masked from 'package:utils':
>
>       ?
>
> Loading required package: WriteXLS
> Perl found.
>
> The following Perl modules were not found on this system:
>
> Text::CSV_XS
>
> If you have more than one Perl installation, be sure the correct one was
> used he
> re.
>
> Otherwise, please install the missing modules. See the package INSTALL
> file for
> more information.
>
> Loading required package: RODBC
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au>  and
> Rolf Turner
> <r.turner at auckland.ac.nz>       with substantial contributions of code by
> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
> Waagepetersen.
> Additional contributions        by Q.W. Ang;    S. Azaele;      C. Beale;
> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
> Che
> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
> P.J. Dig
> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores;    N.
> Funwi-Gabga;
>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>    P. Graba
> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
> Herin
> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
> Kuhn;
>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
> J. Lee;
>           G.P. Leser; [... truncated]
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
> Bates [ct
> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
> Gregor Gorja
> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
> Laboissiere [ctb
> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
> Ripley [
> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
> column 'Autho
> r'
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
> Ash [ctb],
> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
> Andy Cha
> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
> Pour [c
> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
> Uwe Ligg
> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
> [ctb], Dunc
> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
> [ctb], Mi
> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
> 'Author'
>
> Perl found.
>
> The following Perl modules were not found on this system:
>
> Text::CSV_XS
>
> If you have more than one Perl installation, be sure the correct one was
> used he
> re.
>
> Otherwise, please install the missing modules. See the package INSTALL
> file for
> more information.
>
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au>  and
> Rolf Turner
> <r.turner at auckland.ac.nz>       with substantial contributions of code by
> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
> Waagepetersen.
> Additional contributions        by Q.W. Ang;    S. Azaele;      C. Beale;
> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
> Che
> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
> P.J. Dig
> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores;    N.
> Funwi-Gabga;
>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>    P. Graba
> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
> Herin
> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
> Kuhn;
>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
> J. Lee;
>           G.P. Leser; [... truncated]
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
> Bates [ct
> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
> Gregor Gorja
> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
> Laboissiere [ctb
> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
> Ripley [
> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
> column 'Autho
> r'
> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
> Ash [ctb],
> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
> Andy Cha
> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
> Pour [c
> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
> Uwe Ligg
> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
> [ctb], Dunc
> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
> [ctb], Mi
> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
> 'Author'
>
> Warning: running command
> '"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
> et --pdf "sos.tex"  -I
> "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
> I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status 1
> Error: running 'texi2dvi' on 'sos.tex' failed
>
> LaTeX errors:
> sos.tex:16: LaTeX Error: Environment article undefined.
>
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help
> Your command was ignored.
> sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.
>
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help
> Your command was ignored.
> Execution halted
>
>
> On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
>> On 13/09/2013 08:30, Spencer Graves wrote:
>>> Dear Prof. Ripley:
>>>
>>>
>>>        What do you recommend I do with the vignette that comes with that
>>> package?
>>>
>>>
>>>        That vignette is a copy of the article published in the R Journal
>>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>>> RJournal.sty.  When I removed RJournal.sty from the vignette
>>> subdirectory, "R CMD build" failed.  I have no idea what you want me to
>>> do to fix this problem.  Further assistance would be appreciated.
>>
>> Don't spam all the other addressees!
>>
>> The issue is using RJournal.sty in a vignette with ae fonts.  I am
>> guessing that
>>
>> \usepackage[noae]{Sweave}
>>
>> might work: otherwise you need to remove the reference to upquote.sty
>> in RJournal.sty.
>>
>>
>>>
>>>
>>>        Thanks,
>>>        Spencer Graves
>>>
>>>
>>> p.s.  I understand reasonably well R and the *.Rd documentation
>>> standard, thanks in part to your book on "Modern Applied Statistics with
>>> S" and the documentation that ships with R. However, this is the only
>>> vignette I've written, and I have not used LaTeX much for anything else
>>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>>> with R and Matlab (Springer).
>>>
>>>
>>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>>>> Brian,
>>>> I am making changes, downloading new version of Sweave.sty and
>>>> upquote.sty. However, it is not clear to me how to properly credit
>>>> Fritz Leisch and others for Sweave. Do you mean in the sweave document
>>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>>>> find anything about this in "Writing R Extensions".
>>>> Thanks for any guidance,
>>>> Brian
>>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>>>>> upquote.sty in earlier versions of R and not that currently being
>>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>>>>> version of upquote.sty.
>>>>>
>>>>> In particular, they do not work with the 'ae' fonts which are the
>>>>> default for Sweave vignettes.   Packages
>>>>>
>>>>> boolfun calibrate popReconstruct qtlnet
>>>>>
>>>>> have copies in vignettes and now fail.
>>>>>
>>>>> Please remove them. Note too that you did not comply with the CRAN
>>>>> policies on giving credit by including them in your package but not
>>>>> crediting their authors: do check very carefully that there are no
>>>>> other missing credits.
>>>>>
>>>>> Package PSM has vignettes which include upquote.sty.
>>>>>
>>>>> Packages makeR and sos include RJournal.sty which includes
>>>>> upquote.sty: same problem.
>>>>>
>>>>> Please update your package as soon as possible and definitely before
>>>>> the release of 3.0.2 on Sept 25.
>>>>>
>>>>
>>>
>>>
>>
>>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Sep 19 13:15:40 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Sep 2013 12:15:40 +0100
Subject: [Rd] dbeta may hang R session for very large values of the
 shape parameters
In-Reply-To: <73C96EB9-5DA8-48A3-A125-BC65B9B98A45@ucl.ac.uk>
References: <73C96EB9-5DA8-48A3-A125-BC65B9B98A45@ucl.ac.uk>
Message-ID: <523ADCDC.9050903@stats.ox.ac.uk>

The issue is underflow to zero in bd0 (C file src/nmath/bd.c).  We'll 
fix that, but given the R 3.0.2 RC is in code freeze and this has 
existed for years, not for 3.0.2.

On 18/09/2013 23:52, Kosmidis, Ioannis wrote:
> Dear all,
>
> we received a bug report for betareg, that in some cases the optim call in betareg.fit would hang the R session and the command cannot be interrupted by Ctrl-C?
>
> We narrowed down the problem to the dbeta function which is used for the log likelihood evaluation in betareg.fit.
>
> Particularly, the following command hangs the R session to a 100% CPU usage in all systems we tried it (OS X 10.8.4, Debian GNU Linux, Ubuntu 12.04) with either R-3.0.1 and with the R-devel version (in all systems I waited 3 minutes before I kill R):
>
> ## Warning: this will hang the R session
> dbeta(0.9, 1e+308, 10)
>
> Furthermore, through a trial and error investigation using the following code
>
> ## Warning: this will hang the R session
> x <- 0.9
> for (i in 0:100) {
>   a <- 1e+280*2^i
>   b <- 10
>   cat("shape1 =", a, "\n")
>   cat("shape2 =", b, "\n")
>   cat("Beta density", dbeta(x, shape1 = a, shape2 = b), "\n")
>   cat("===\n")
> }
>
> I noticed that:
> * this seems to happen when shape1 is about 1e+308, seemingly irrespective of the value of shape2 (run the above with another value of b), and as it appears only when x>=0.9 and x < 1 (run the above lines with x <- 0.89999 for example and everything works as expected).
> * similar problems are encountered for small x values when shape2 is massive.
>
> I am not sure why this happens but it looks deep to me. The temporary fix for the purposes of betareg was a hack (a simple if command that returns NA for the log likelihood if any shape parameter has values greater than 1e+300 say).
>
> Nevertheless, I thought that this is an issue worth reporting to R-devel (instead of R-help), especially since dbeta may be used within generic optimisers and figuring that dbeta is the problem can be hard --- it took us some time before we started suspecting dbeta.
>
> Interestingly, this appears to happen close to what R considers infinity. Typing
> 1.799e+308
> into R returns Inf.
>
> I hope the above limited in scope analysis is informative.
>
> Best regards,
> Ioannis
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Thu Sep 19 13:24:24 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Sep 2013 07:24:24 -0400
Subject: [Rd] getParseData() for imaginary numbers
In-Reply-To: <CANROs4eL+BT9jqDVcy-MnNHK_g-nVLd0o+aDjk_UU17=cG0DZA@mail.gmail.com>
References: <CANROs4eL+BT9jqDVcy-MnNHK_g-nVLd0o+aDjk_UU17=cG0DZA@mail.gmail.com>
Message-ID: <523ADEE8.2030307@gmail.com>

On 13-09-18 1:47 PM, Yihui Xie wrote:
> Hi,
>
> The imaginary unit is gone in the 'text' column in the returned data
> frame from getParseData(), e.g. in the example below, perhaps the text
> should be 1i instead of 1:

Yes, I can confirm the bug.  I'll fix it in R-devel now, and in 
R-patched after 3.0.2 is released next week.

Duncan Murdoch

>
>> p=parse(text='1i')
>> getParseData(p)
>    line1 col1 line2 col2 id parent     token terminal text
> 1     1    1     1    2  1      2 NUM_CONST     TRUE    1
> 2     1    1     1    2  2      0      expr    FALSE
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From I.Kosmidis at ucl.ac.uk  Thu Sep 19 14:51:55 2013
From: I.Kosmidis at ucl.ac.uk (Ioannis Kosmidis)
Date: Thu, 19 Sep 2013 13:51:55 +0100
Subject: [Rd] dbeta may hang R session for very large values of the
 shape parameters
In-Reply-To: <523ADCDC.9050903@stats.ox.ac.uk>
References: <73C96EB9-5DA8-48A3-A125-BC65B9B98A45@ucl.ac.uk>
	<523ADCDC.9050903@stats.ox.ac.uk>
Message-ID: <523AF36B.1080006@ucl.ac.uk>

Dear Brian,

many thanks, that is great.

Best regards,
Ioannis

On 19/09/13 12:15, Prof Brian Ripley wrote:
> The issue is underflow to zero in bd0 (C file src/nmath/bd.c).  We'll
> fix that, but given the R 3.0.2 RC is in code freeze and this has
> existed for years, not for 3.0.2.
>
> On 18/09/2013 23:52, Kosmidis, Ioannis wrote:
>> Dear all,
>>
>> we received a bug report for betareg, that in some cases the optim
>> call in betareg.fit would hang the R session and the command cannot be
>> interrupted by Ctrl-C?
>>
>> We narrowed down the problem to the dbeta function which is used for
>> the log likelihood evaluation in betareg.fit.
>>
>> Particularly, the following command hangs the R session to a 100% CPU
>> usage in all systems we tried it (OS X 10.8.4, Debian GNU Linux,
>> Ubuntu 12.04) with either R-3.0.1 and with the R-devel version (in all
>> systems I waited 3 minutes before I kill R):
>>
>> ## Warning: this will hang the R session
>> dbeta(0.9, 1e+308, 10)
>>
>> Furthermore, through a trial and error investigation using the
>> following code
>>
>> ## Warning: this will hang the R session
>> x <- 0.9
>> for (i in 0:100) {
>>   a <- 1e+280*2^i
>>   b <- 10
>>   cat("shape1 =", a, "\n")
>>   cat("shape2 =", b, "\n")
>>   cat("Beta density", dbeta(x, shape1 = a, shape2 = b), "\n")
>>   cat("===\n")
>> }
>>
>> I noticed that:
>> * this seems to happen when shape1 is about 1e+308, seemingly
>> irrespective of the value of shape2 (run the above with another value
>> of b), and as it appears only when x>=0.9 and x < 1 (run the above
>> lines with x <- 0.89999 for example and everything works as expected).
>> * similar problems are encountered for small x values when shape2 is
>> massive.
>>
>> I am not sure why this happens but it looks deep to me. The temporary
>> fix for the purposes of betareg was a hack (a simple if command that
>> returns NA for the log likelihood if any shape parameter has values
>> greater than 1e+300 say).
>>
>> Nevertheless, I thought that this is an issue worth reporting to
>> R-devel (instead of R-help), especially since dbeta may be used within
>> generic optimisers and figuring that dbeta is the problem can be hard
>> --- it took us some time before we started suspecting dbeta.
>>
>> Interestingly, this appears to happen close to what R considers
>> infinity. Typing
>> 1.799e+308
>> into R returns Inf.
>>
>> I hope the above limited in scope analysis is informative.
>>
>> Best regards,
>> Ioannis
>>
>>
>>
>
>



-- 
Dr Ioannis Kosmidis
Department of Statistical  Science,
University College,
London, WC1E 6BT, UK
Webpage: http://www.ucl.ac.uk/~ucakiko


From pgilbert902 at gmail.com  Fri Sep 20 00:27:14 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 19 Sep 2013 18:27:14 -0400
Subject: [Rd] Design for classes with database connection
In-Reply-To: <14477DE0-FE60-4AC7-8246-E062322A05AA@uni-bonn.de>
References: <14477DE0-FE60-4AC7-8246-E062322A05AA@uni-bonn.de>
Message-ID: <523B7A42.6040206@gmail.com>

Simon

Your idea to use SQLite and the nature of some of the sorting and 
extracting you are suggesting makes me wonder why you are thinking of R 
data structures as the home for the data storage. I would be inclined to 
put the data in an SQL database as the prime repository, then extract 
parts you want with SQL queries and bring them into R for analysis and 
graphics. If the full data set is large, and the parts you want to 
analyze in R at any one time are relatively small, then this will be 
much faster. After all, SQL is primarily for databases, whereas R's 
strength is more in statistics and graphics.

In the project http://tsdbi.r-forge.r-project.org/ I have code that does 
some of the things you probably want. There the focus is on a single 
identifier for a series, and various observation frequencies are 
supported. Tick data is supported (as time stamped data) but not 
extensively tested as I do not work with tick data much. There is a 
function TSquery, currently in TSdbi on CRAN but very shortly being 
split with the SQL specific parts of the interface into a package TSsql. 
It is very much like the queries you seem to have in mind, but I have 
not used it with tick data. It is used to generate a time series by 
formulating a query to a database with several possible sorting fields, 
very much like you describe, and then order the data according to the 
time index.

If your data set is large, then you need to think carefully about which 
fields you index. You certainly do not want to be building the indexes 
on the fly, as you would need to do if you dump all the data out of R 
into an SQL db just to do a sort. If the data set is small then indexing 
does not matter too much. Also, for a small data set there will be much 
less advantage of keeping the data in an SQL db rather than in R. You do 
need to be a bit more specific about what "huge" means. (Tick data for 5 
days or 20 years? A 100 IDs or 10 million?) Large for an R structure is 
not necessarily large for an SQL db. With more specifics I might be able 
to give more suggestions.

(R-SIG-DB may be a better forum for this discussion.)

HTH,
Paul

On 13-09-18 01:06 PM, Simon Zehnder wrote:
> Dear R-Devels,
>
> I am designing right now a package intended to simplify the handling
> of market microstructure data (tick data, order data, etc). As these
> data is most times pretty huge and needs to be reordered quite often
> (e.g. if several security data is batched together or if only a
> certain time range should be considered) - the package needs to
> handle this.
>
> Before I start, I would like to mention some facts which made me
> decide to construct an own package instead of using e.g. the packages
> bigmemory, highfrequency, zoo or xts: AFAIK big memory does not
> provide the opportunity to handle data with different types
> (timestamp, string and numerics) and their appropriate sorting, for
> this task databases offer better tools. Package highfrequency is
> designed to work specifically with a certain data structure and the
> data in market microstructure has much greater versatility. Packages
> zoo and xts offer a lot of versatility but do not offer the data
> sorting ability needed for such big data.
>
> I would like to get some feedback in regard to my decision and in
> regard to the short design overview following.
>
> My design idea is now:
>
> 1. Base the package on S4 classes, with one class that handles
> data-reading from external sources, structuring and reordering.
> Structuring is done in regard to specific data variables, i.e.
> security ID, company ID, timestamp, price, volume (not all have to be
> provided, but some surely exist on market microstructure data). The
> less important variables are considered as a slot @other and are only
> ordered in regard to the other variables. Something like this:
>
> .mmstruct <- setClass('mmstruct', representation( name	=
> "character", index	= "array", N		= "integer", K		= "integer", compiD
> = "array", secID  	= "array", tradetime	= "POSIXlt", flag		=
> "array", price	= "array", vol		= "array", other	= "data.frame"))
>
> 2. To enable a lightweight ordering function, the class should
> basically create an SQLite database on construction and delete it if
> 'rm()' is called. Throughout its life an object holds the database
> path and can execute queries on the database tables. By this, I can
> use the table sorting of SQLite (e.g. by constructing an index for
> each important variable). I assume this is faster and more efficient
> than programming something on my own - why reinventing the wheel? For
> this I would use VIRTUAL classes like:
>
> .mmstructBASE	<- setClass('mmstructBASE', representation( dbName		=
> "character", dbTable		= "character"))
>
> .mmstructDB		<- setClass('mmstructDB', representation( conn		=
> "SQLiteConnection"), contains		= c("mmstructBASE"))
>
> .mmstruct <- setClass('mmstruct', representation( name	=
> "character", index	= "array", N		= "integer", K		= "integer", compiD
> = "array", secID  	= "array", tradetime	= "POSIXlt", price	=
> "array", vol		= "array", other	= "data.frame"), contains =
> c("mmstructDB"))
>
> The slots in the mistrust class hold then a view (e.g. only the
> head()) of the data or can be used to hold retrieved data from the
> underlying database.
>
> 3. The workflow would than be something like: 	a) User reads in the
> data from an external source and gets a data.frame from it. b) This
> data.frame then can be used to construct an mmstruct object from it
> by formatting the variables and read them into the SQLite database
> constructed. c) Given the data structure in the database, the user
> can sort the data by secID, timestamp etc. and can use several
> algorithms for cleaning the data (package-specific not in the
> database) d) Example: The user makes a query to get only price from
> entries compID = "AA" with tradetime < "2012-03-09" or with trade
> time only first trading day in a month. This can then be converted
> e.g. to a 'ts' object in R by coercing e) In addition the user can
> perform several estimations of market microstructure models by
> calling package-specific functions.
>
>
> Is there a big fault in my design, something I haven't considered? I
> am very sure on this list are researchers and developers with much
> more experience. I would like to hear your opinion and ideas. I learn
> from it and can maybe get to a design which I can then implement for
> the research on such data and models.
>
>
> Best
>
> Simon
>
>
>
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>


From romain at r-enthusiasts.com  Fri Sep 20 00:51:52 2013
From: romain at r-enthusiasts.com (romain at r-enthusiasts.com)
Date: Fri, 20 Sep 2013 00:51:52 +0200
Subject: [Rd] Using long long types in C++
Message-ID: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>

Hello,

In Rcpp we'd like to do something useful for types such as long long 
and unsigned long long.

For example, supporting our usual wrap construct. We'd like to be able 
to "wrap" a long long, or perhaps a std::vector<long long> so that it is 
returned to the R side in something meaningful (we are considering 
several options like loosing some precision and returning an int, 
loosing a bit less precision and returning a double or use bit shifting 
tricks and do something compatible with the bit64 package).

To do this, we try to be careful and hide the code behind these two PP 
tests:

#if defined(__GNUC__) &&  defined(__LONG_LONG_MAX__)

which tests for gcc compatible (includes clang) compiler and the 
availability of the long long type.


Now this is not enough and we also have to use __extension__ to disable 
warnings that are emitted by -pedantic. So we have something like this:

#if defined(__GNUC__) &&  defined(__LONG_LONG_MAX__)
     __extension__ typedef long long int rcpp_long_long_type;
     __extension__ typedef unsigned long long int rcpp_ulong_long_type;
     #define RCPP_HAS_LONG_LONG_TYPES
#endif

and for the rest of what we do with these types, we use 
rcpp_long_long_type and rcpp_ulong_long_type and hide the code behind 
#if defined(RCPP_HAS_LONG_LONG_TYPES)


But apparently this is still not enough and on some versions of gcc 
(e.g. 4.7 something), -pedantic still generates the warnings unless we 
also use -Wno-long-long


Dirk tells me that the fact that these warnings show up means that it 
would not be accepted in CRAN. I understand that -pedantic is useful for 
finding potential portability problems, but in that case I believe 
everything is done to isolate the use of long long to a situation where 
we know we can use it given that we test for a compiler (gcc) and its 
known way to check for existence of long long: __LONG_LONG_MAX__

What are my options here ?

Romain


From prlw1 at cam.ac.uk  Fri Sep 20 02:31:45 2013
From: prlw1 at cam.ac.uk (Patrick Welche)
Date: Fri, 20 Sep 2013 01:31:45 +0100
Subject: [Rd] Using long long types in C++
In-Reply-To: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
Message-ID: <20130920003145.GE482@quark>

On Fri, Sep 20, 2013 at 12:51:52AM +0200, romain at r-enthusiasts.com wrote:
> In Rcpp we'd like to do something useful for types such as long long
> and unsigned long long.
...
> But apparently this is still not enough and on some versions of gcc
> (e.g. 4.7 something), -pedantic still generates the warnings unless
> we also use -Wno-long-long

Can you also add -std=c++0x or is that considered as bad as adding
-Wno-long-long?

(and why not use autoconf's AC_TYPE_LONG_LONG_INT and
AC_TYPE_UNSIGNED_LONG_LONG_INT for the tests?)

Cheers,

Patrick


From kmillar at google.com  Fri Sep 20 04:04:22 2013
From: kmillar at google.com (Karl Millar)
Date: Thu, 19 Sep 2013 19:04:22 -0700
Subject: [Rd] Using long long types in C++
In-Reply-To: <20130920003145.GE482@quark>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
Message-ID: <CABz6aZe+=Qk7fKvEOpFFYbucfBYHQmna5nm==QHyhmTjgkQJMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130919/f6807cad/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Sep 20 08:39:30 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Sep 2013 07:39:30 +0100
Subject: [Rd] Using long long types in C++
In-Reply-To: <CABz6aZe+=Qk7fKvEOpFFYbucfBYHQmna5nm==QHyhmTjgkQJMQ@mail.gmail.com>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
	<CABz6aZe+=Qk7fKvEOpFFYbucfBYHQmna5nm==QHyhmTjgkQJMQ@mail.gmail.com>
Message-ID: <523BEDA2.6080905@stats.ox.ac.uk>

On 20/09/2013 03:04, Karl Millar wrote:
> Romain,
>
> Can you use int64_t and uint_t64 instead?  IMHO that would be more useful
> than long long anyway.

'Writing R Extensions' does say

'Do be very careful with passing arguments between R, C and FORTRAN 
code. In particular, long in C will be 32-bit on some R platforms 
(including 64-bit Windows), but 64-bit on most modern Unix and Linux 
platforms. It is rather unlikely that the use of long in C code has been 
thought through: if you need a longer type than int you should use a 
configure test for a C99 type such as int_fast64_t (and failing that, 
long long 42) and typedef your own type to be long or long long, or use 
another suitable type (such as size_t).

Note that int64_t is not portable, even in C99, since its implementation 
is optional.

On 20/09/2013 01:31, Patrick Welche wrote:
 >
 > Can you also add -std=c++0x or is that considered as bad as adding
 > -Wno-long-long?

That is not portable.  It is g++ specific and AFAIR not accepted by the 
version of g++ used on OS X (which dates from 2007).


>
> Karl
> On Sep 19, 2013 5:33 PM, "Patrick Welche" <prlw1 at cam.ac.uk> wrote:
>
>> On Fri, Sep 20, 2013 at 12:51:52AM +0200, romain at r-enthusiasts.com wrote:
>>> In Rcpp we'd like to do something useful for types such as long long
>>> and unsigned long long.
>> ...
>>> But apparently this is still not enough and on some versions of gcc
>>> (e.g. 4.7 something), -pedantic still generates the warnings unless
>>> we also use -Wno-long-long
>>
>> Can you also add -std=c++0x or is that considered as bad as adding
>> -Wno-long-long?
>>
>> (and why not use autoconf's AC_TYPE_LONG_LONG_INT and
>> AC_TYPE_UNSIGNED_LONG_LONG_INT for the tests?)
>>
>> Cheers,
>>
>> Patrick
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain at r-enthusiasts.com  Fri Sep 20 08:44:24 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 20 Sep 2013 08:44:24 +0200
Subject: [Rd] Using long long types in C++
In-Reply-To: <20130920003145.GE482@quark>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
Message-ID: <08131FE2-55C0-4EAE-A038-49E3E2314B86@r-enthusiasts.com>

Le 20 sept. 2013 ? 02:31, Patrick Welche <prlw1 at cam.ac.uk> a ?crit :

> On Fri, Sep 20, 2013 at 12:51:52AM +0200, romain at r-enthusiasts.com wrote:
>> In Rcpp we'd like to do something useful for types such as long long
>> and unsigned long long.
> ...
>> But apparently this is still not enough and on some versions of gcc
>> (e.g. 4.7 something), -pedantic still generates the warnings unless
>> we also use -Wno-long-long
> 
> Can you also add -std=c++0x or is that considered as bad as adding
> -Wno-long-long?

IIRC, a package on CRAN is not allowed to change -std, there is or at least was barriers to forbid this. 

Plus, some of us use the default settings on OSX, this is still (simili) gcc 4.2.1 which has long long but does not implement c++11

> (and why not use autoconf's AC_TYPE_LONG_LONG_INT and
> AC_TYPE_UNSIGNED_LONG_LONG_INT for the tests?)

Because no matter how many precautions we take, if at the end of the day we end up having mentions of long long in the code, even behind sufficient test, it will still generate warnings which i'm told would prevent the cran distribution of the package. 

I'd really like to hear from cran maintainers on this. 

> Cheers,
> 
> Patrick

Because

From romain at r-enthusiasts.com  Fri Sep 20 08:52:33 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 20 Sep 2013 08:52:33 +0200
Subject: [Rd] Using long long types in C++
In-Reply-To: <CABz6aZe+=Qk7fKvEOpFFYbucfBYHQmna5nm==QHyhmTjgkQJMQ@mail.gmail.com>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
	<CABz6aZe+=Qk7fKvEOpFFYbucfBYHQmna5nm==QHyhmTjgkQJMQ@mail.gmail.com>
Message-ID: <F61982C8-034B-40BB-A674-213C2A1C2637@r-enthusiasts.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130920/24eb2d05/attachment.pl>

From eric.malitz at gmail.com  Fri Sep 20 03:47:05 2013
From: eric.malitz at gmail.com (Eric Malitz)
Date: Thu, 19 Sep 2013 20:47:05 -0500
Subject: [Rd] Using long long types in C++
In-Reply-To: <20130920003145.GE482@quark>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
Message-ID: <CAJVuBMkZp3FN4_Z0Ugcnu7s7ScBh7Ci0yAYeYoHxX-UmXEQ2RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130919/88badefc/attachment.pl>

From bhh at xs4all.nl  Fri Sep 20 09:49:50 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 20 Sep 2013 09:49:50 +0200
Subject: [Rd] Using long long types in C++
In-Reply-To: <CAJVuBMkZp3FN4_Z0Ugcnu7s7ScBh7Ci0yAYeYoHxX-UmXEQ2RA@mail.gmail.com>
References: <9df9f69d52dfdddccbf8e32f18dd227a@r-enthusiasts.com>
	<20130920003145.GE482@quark>
	<CAJVuBMkZp3FN4_Z0Ugcnu7s7ScBh7Ci0yAYeYoHxX-UmXEQ2RA@mail.gmail.com>
Message-ID: <10552C30-6DE9-4730-85BE-690A70B9D554@xs4all.nl>


On 20-09-2013, at 03:47, Eric Malitz <eric.malitz at gmail.com> wrote:

> I've been trying desperately to unsubscribe from this. Not that I don't
> like R; but I only wanted help and then ended up on this email list. I've
> put in more than one request to unsubscribe.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

Then surf to the address given at the end of each posting; go to the bottom of that page and follow the instructions for unsubscribing.

Berend


From claudia.beleites at ipht-jena.de  Fri Sep 20 10:57:25 2013
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Fri, 20 Sep 2013 10:57:25 +0200
Subject: [Rd] FOSS licence with BuildVignettes: false
In-Reply-To: <523811EA.9090300@stats.ox.ac.uk>
References: <077E31A57DA26E46AB0D493C9966AC730D87190EAD@UM-MAIL4112.unimaas.nl>
	<52361636.5060305@statistik.tu-dortmund.de>
	<loom.20130916T005045-889@post.gmane.org>
	<5236CD24.40107@statistik.tu-dortmund.de>
	<52371A6F.6020909@gmail.com> <523811EA.9090300@stats.ox.ac.uk>
Message-ID: <20130920105725.59318f26@cbdesktop>

Hi there,

Am Tue, 17 Sep 2013 09:25:14 +0100
schrieb Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> On 16/09/2013 15:49, Paul Gilbert wrote:
> > On 13-09-16 05:19 AM, Uwe Ligges wrote:
> > ...
> >> Yes, and I could see really rare circumstances where vignette
> >> building takes a long time and the maintainer decides not to build
> >> vignettes as part of the daily checks.
> > ...

I have two vignettes that I build externally because the
required data sets are largish (20 and 40 MB zipped), so I provide them
for download on hyperSpec's home page but do not want to burden CRAN
with them. Instructions how to get that data to build the vignette
yourself are one of the first points in the vignette. 

I do /not/ have BuildVignettes: FALSE but a Makefile that
turns of pdflatex for these two only, and dummy .Rnw files that provide
just the appropriate \VignetteIndex etc. entries.

IMHO that is a perfectly reasonable option for FOSS packages, and while
it makes it my responsibility to check the vignette building, a
Makefile for preparing the package takes care of that as well. I can
also make sure that both data and real vignette source are available
there.

For an upcoming spectral unmixing package, however, I'd like to include
a vignette dealing with the cuprite AVIRIS data set (remote sensing
data, a standard data set used on many publications for spectral
unmixing) that can be downloaded from the NASA
(http://aviris.jpl.nasa.gov/data/free_data.html).

Is it acceptable to have a vignette that points to yet another data
source (which is out of my control)?

(I think this question goes mainly to Brian and the author of the part
of the manual cited by Ben).

Best,

Claudia




> >
> > I thought 'BuildVignettes: FALSE' only turns of assembling the pdf,
> > all the code is still run.  I don't think that would affect the
> > time very much. Am I wrong (again)?
> 
> Yes, as the code is run again to re-build the vignettes.
> 
> The main use of BuildVignettes: FALSE is when building the vignettes 
> requires unusual facilities -- presumably not R ones as it does not
> turn off running the code.  However, for a FOSS package, the means to 
> re-build the vignettes has to available to others, and CRAN therefore 
> tries it so see if all the sources are available.  Almost every time
> we uncover some problem with the sources and stale vignette PDFs.



-- 
Claudia Beleites, Chemist
Spectroscopy/Imaging
Institute of Photonic Technology 
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From szehnder at uni-bonn.de  Fri Sep 20 12:43:12 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 20 Sep 2013 12:43:12 +0200
Subject: [Rd] Design for classes with database connection
In-Reply-To: <523B7A42.6040206@gmail.com>
References: <14477DE0-FE60-4AC7-8246-E062322A05AA@uni-bonn.de>
	<523B7A42.6040206@gmail.com>
Message-ID: <BE5335D3-BAFB-4B27-AEBF-EF293A98B31E@uni-bonn.de>

Paul,

thank you very much for this elaborate answer. There are a lot of points which make me rethink what I was planning. Especially I will take a close look on the TSdbi package/source code. Probably this is something I can rely on - that would be very great. 

To conclude very shortly what my idea was: Use R to read the data in and give it a kind of standardised structure, which is then written to SQLite. Use SQLite to store the data and to filter/order it. Use R to get parts of the data and to estimate models on it. The models get an S4 class and have everything they need. 

By huge I think about Tickdata from e.g. Future markets for a year: For DAX Futures this could be around 28.5 Mio. Entries (each entry with timestamp, IDs, price, volume, etc). Another example would be Spot market data for a whole Index (say the Dow30). Usually we get the data from the wrds in a batched form like a csv with all entries for all securities batched. Further order book data with each order send to the exchange for one security for three months - altogether often more than 20 Mio entries (including deleted errors etc.). 

From now on I will move this conversation to R-SIG_DB, as suggested in your last comment.


Best

Simon



On Sep 20, 2013, at 12:27 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:

> Simon
> 
> Your idea to use SQLite and the nature of some of the sorting and extracting you are suggesting makes me wonder why you are thinking of R data structures as the home for the data storage. I would be inclined to put the data in an SQL database as the prime repository, then extract parts you want with SQL queries and bring them into R for analysis and graphics. If the full data set is large, and the parts you want to analyze in R at any one time are relatively small, then this will be much faster. After all, SQL is primarily for databases, whereas R's strength is more in statistics and graphics.
> 
> In the project http://tsdbi.r-forge.r-project.org/ I have code that does some of the things you probably want. There the focus is on a single identifier for a series, and various observation frequencies are supported. Tick data is supported (as time stamped data) but not extensively tested as I do not work with tick data much. There is a function TSquery, currently in TSdbi on CRAN but very shortly being split with the SQL specific parts of the interface into a package TSsql. It is very much like the queries you seem to have in mind, but I have not used it with tick data. It is used to generate a time series by formulating a query to a database with several possible sorting fields, very much like you describe, and then order the data according to the time index.
> 
> If your data set is large, then you need to think carefully about which fields you index. You certainly do not want to be building the indexes on the fly, as you would need to do if you dump all the data out of R into an SQL db just to do a sort. If the data set is small then indexing does not matter too much. Also, for a small data set there will be much less advantage of keeping the data in an SQL db rather than in R. You do need to be a bit more specific about what "huge" means. (Tick data for 5 days or 20 years? A 100 IDs or 10 million?) Large for an R structure is not necessarily large for an SQL db. With more specifics I might be able to give more suggestions.
> 
> (R-SIG-DB may be a better forum for this discussion.)
> 
> HTH,
> Paul
> 
> On 13-09-18 01:06 PM, Simon Zehnder wrote:
>> Dear R-Devels,
>> 
>> I am designing right now a package intended to simplify the handling
>> of market microstructure data (tick data, order data, etc). As these
>> data is most times pretty huge and needs to be reordered quite often
>> (e.g. if several security data is batched together or if only a
>> certain time range should be considered) - the package needs to
>> handle this.
>> 
>> Before I start, I would like to mention some facts which made me
>> decide to construct an own package instead of using e.g. the packages
>> bigmemory, highfrequency, zoo or xts: AFAIK big memory does not
>> provide the opportunity to handle data with different types
>> (timestamp, string and numerics) and their appropriate sorting, for
>> this task databases offer better tools. Package highfrequency is
>> designed to work specifically with a certain data structure and the
>> data in market microstructure has much greater versatility. Packages
>> zoo and xts offer a lot of versatility but do not offer the data
>> sorting ability needed for such big data.
>> 
>> I would like to get some feedback in regard to my decision and in
>> regard to the short design overview following.
>> 
>> My design idea is now:
>> 
>> 1. Base the package on S4 classes, with one class that handles
>> data-reading from external sources, structuring and reordering.
>> Structuring is done in regard to specific data variables, i.e.
>> security ID, company ID, timestamp, price, volume (not all have to be
>> provided, but some surely exist on market microstructure data). The
>> less important variables are considered as a slot @other and are only
>> ordered in regard to the other variables. Something like this:
>> 
>> .mmstruct <- setClass('mmstruct', representation( name	=
>> "character", index	= "array", N		= "integer", K		= "integer", compiD
>> = "array", secID  	= "array", tradetime	= "POSIXlt", flag		=
>> "array", price	= "array", vol		= "array", other	= "data.frame"))
>> 
>> 2. To enable a lightweight ordering function, the class should
>> basically create an SQLite database on construction and delete it if
>> 'rm()' is called. Throughout its life an object holds the database
>> path and can execute queries on the database tables. By this, I can
>> use the table sorting of SQLite (e.g. by constructing an index for
>> each important variable). I assume this is faster and more efficient
>> than programming something on my own - why reinventing the wheel? For
>> this I would use VIRTUAL classes like:
>> 
>> .mmstructBASE	<- setClass('mmstructBASE', representation( dbName		=
>> "character", dbTable		= "character"))
>> 
>> .mmstructDB		<- setClass('mmstructDB', representation( conn		=
>> "SQLiteConnection"), contains		= c("mmstructBASE"))
>> 
>> .mmstruct <- setClass('mmstruct', representation( name	=
>> "character", index	= "array", N		= "integer", K		= "integer", compiD
>> = "array", secID  	= "array", tradetime	= "POSIXlt", price	=
>> "array", vol		= "array", other	= "data.frame"), contains =
>> c("mmstructDB"))
>> 
>> The slots in the mistrust class hold then a view (e.g. only the
>> head()) of the data or can be used to hold retrieved data from the
>> underlying database.
>> 
>> 3. The workflow would than be something like: 	a) User reads in the
>> data from an external source and gets a data.frame from it. b) This
>> data.frame then can be used to construct an mmstruct object from it
>> by formatting the variables and read them into the SQLite database
>> constructed. c) Given the data structure in the database, the user
>> can sort the data by secID, timestamp etc. and can use several
>> algorithms for cleaning the data (package-specific not in the
>> database) d) Example: The user makes a query to get only price from
>> entries compID = "AA" with tradetime < "2012-03-09" or with trade
>> time only first trading day in a month. This can then be converted
>> e.g. to a 'ts' object in R by coercing e) In addition the user can
>> perform several estimations of market microstructure models by
>> calling package-specific functions.
>> 
>> 
>> Is there a big fault in my design, something I haven't considered? I
>> am very sure on this list are researchers and developers with much
>> more experience. I would like to hear your opinion and ideas. I learn
>> from it and can maybe get to a design which I can then implement for
>> the research on such data and models.
>> 
>> 
>> Best
>> 
>> Simon
>> 
>> 
>> 
>> 
>> ______________________________________________ R-devel at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>> 


From bbolker at gmail.com  Sat Sep 21 18:44:49 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Sep 2013 16:44:49 +0000
Subject: [Rd] (no subject)
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
	<CAFDcVCSsd0KcZCCRv0f-MzUU@mail.gmail.com>
Message-ID: <loom.20130921T183612-790@post.gmane.org>

Henrik Bengtsson <hb <at> biostat.ucsf.edu> writes:

> 
> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson 
> <hb <at> biostat.ucsf.edu> wrote:
> > Hi.

[snip]

  Bump ... Henrik, did you ever post this as a request/wishlist at
https://bugs.r-project.org/bugzilla3/ ?  (I don't think so, I couldn't
find it there, but maybe I wasn't looking in the right place.) I
would be curious to know what the response was from R-Core, because
these kinds of warnings are starting to pop up in the nlme/lme4/
downstream package complex.  In particular, 

VarCorr
fixef
lmList
ranef

are defined by nlme, imported and re-exported by lme4.  This doesn't
seem to make any trouble for lme4, but it does cause problems for
some of the downstream packages (such as GRRGI:
[broken URL for Gmane]
http://www.r-project.org/nosvn/R.check/
 r-devel-linux-x86_64-fedora-gcc/GRRGI-00check.html )

(Right now GRRGI uses a pretty crude import-all strategy:
import(nlme,lme4,...); exportPattern("."); which might be
tweaked, but I think the issue is still worth resolving.)

  In a perfect world, I guess some of these generics would be moved
upstream to a package that both nlme and lme4 could import from,
but that seems tricky to do without making fairly major architectural
changes.

  Ben Bolker


> > For the record, you're referring to R-devel thread 'Correct NAMESPACE
> > approach when writing an S3 method for a generic in another package'
> > started on Aug 24, 2013
> > [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
> > Yes, it's closely related or possibly the same issue.  However, I do
> > not find it odd that the S3 generic function needs to be exported
> > from/available via the namespace.  Hence it needs to be export():ed by
> > at least one package/namespace.
> >
> > The real issue is when two package needs to export a generic function
> > with the same name, e.g. foo().   If the two generic functions are
> > defined differently (e.g. different arguments/signatures), they will
> > be in conflict with each other.  If they are identical, this should
> > not be a problem, but here I might be wrong.  However, there is also
> > the special case where one package reexports the generic function from
> > another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
> > the object 'foo' does actually not existing in the name space of
> > package PkgB - instead it provides a "redirect" to it, e.g.
> >
> >> PkgA::foo
> > function (...)
> > UseMethod("foo")
> > <environment: namespace:PkgA>
> >
> >> PkgB::foo
> > function (...)
> > UseMethod("foo")
> > <environment: namespace:PkgA>
> >
> >> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
> > [1] FALSE
> >
> >> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
> > [1] TRUE
> >
> >> identical(PkgB::foo, PkgA::foo)
> > [1] TRUE
> >
> >
> > The warning on "replacing previous import by 'PkgA::foo' when loading
> > 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
> > base::namespaceImportFrom()
> > [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R]

> > Note how there is already code for avoiding "false" warnings on S4
> > generic function.  This is what we'd like to have also for S3 generic
> > functions, but it's much harder to test for such since they're not
> > formally defined.  However, I'd argue that it is safe to skip the
> > warning *when the variable to be imported does not actually exist in
> > the package being imported* (e.g. when just rexported), i.e.
> >


From hb at biostat.ucsf.edu  Sat Sep 21 19:47:53 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 21 Sep 2013 10:47:53 -0700
Subject: [Rd] (no subject)
In-Reply-To: <loom.20130921T183612-790@post.gmane.org>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
	<CAFDcVCSsd0KcZCCRv0f-MzUU@mail.gmail.com>
	<loom.20130921T183612-790@post.gmane.org>
Message-ID: <CAFDcVCR4T2dAo26A6+LVZG8=XKVBABg5fX=tDXCcxF8oOMx3HA@mail.gmail.com>

Hi, it appears that you've lost the original thread

R-devel thread '"False" warning on "replacing previous import" when
re-exporting identical object' started on 2013-08-29
[https://stat.ethz.ch/pipermail/r-devel/2013-August/067321.html].

(and forgot the subject line), so in order to not start yet another
thread I'll close this one and reply/cc you there.

/Henrik


On Sat, Sep 21, 2013 at 9:44 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Henrik Bengtsson <hb <at> biostat.ucsf.edu> writes:
>
>>
>> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson
>> <hb <at> biostat.ucsf.edu> wrote:
>> > Hi.
>
> [snip]
>
>   Bump ... Henrik, did you ever post this as a request/wishlist at
> https://bugs.r-project.org/bugzilla3/ ?  (I don't think so, I couldn't
> find it there, but maybe I wasn't looking in the right place.) I
> would be curious to know what the response was from R-Core, because
> these kinds of warnings are starting to pop up in the nlme/lme4/
> downstream package complex.  In particular,
>
> VarCorr
> fixef
> lmList
> ranef
>
> are defined by nlme, imported and re-exported by lme4.  This doesn't
> seem to make any trouble for lme4, but it does cause problems for
> some of the downstream packages (such as GRRGI:
> [broken URL for Gmane]
> http://www.r-project.org/nosvn/R.check/
>  r-devel-linux-x86_64-fedora-gcc/GRRGI-00check.html )
>
> (Right now GRRGI uses a pretty crude import-all strategy:
> import(nlme,lme4,...); exportPattern("."); which might be
> tweaked, but I think the issue is still worth resolving.)
>
>   In a perfect world, I guess some of these generics would be moved
> upstream to a package that both nlme and lme4 could import from,
> but that seems tricky to do without making fairly major architectural
> changes.
>
>   Ben Bolker
>
>
>> > For the record, you're referring to R-devel thread 'Correct NAMESPACE
>> > approach when writing an S3 method for a generic in another package'
>> > started on Aug 24, 2013
>> > [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
>> > Yes, it's closely related or possibly the same issue.  However, I do
>> > not find it odd that the S3 generic function needs to be exported
>> > from/available via the namespace.  Hence it needs to be export():ed by
>> > at least one package/namespace.
>> >
>> > The real issue is when two package needs to export a generic function
>> > with the same name, e.g. foo().   If the two generic functions are
>> > defined differently (e.g. different arguments/signatures), they will
>> > be in conflict with each other.  If they are identical, this should
>> > not be a problem, but here I might be wrong.  However, there is also
>> > the special case where one package reexports the generic function from
>> > another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
>> > the object 'foo' does actually not existing in the name space of
>> > package PkgB - instead it provides a "redirect" to it, e.g.
>> >
>> >> PkgA::foo
>> > function (...)
>> > UseMethod("foo")
>> > <environment: namespace:PkgA>
>> >
>> >> PkgB::foo
>> > function (...)
>> > UseMethod("foo")
>> > <environment: namespace:PkgA>
>> >
>> >> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
>> > [1] FALSE
>> >
>> >> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
>> > [1] TRUE
>> >
>> >> identical(PkgB::foo, PkgA::foo)
>> > [1] TRUE
>> >
>> >
>> > The warning on "replacing previous import by 'PkgA::foo' when loading
>> > 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
>> > base::namespaceImportFrom()
>> > [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R]
>
>> > Note how there is already code for avoiding "false" warnings on S4
>> > generic function.  This is what we'd like to have also for S3 generic
>> > functions, but it's much harder to test for such since they're not
>> > formally defined.  However, I'd argue that it is safe to skip the
>> > warning *when the variable to be imported does not actually exist in
>> > the package being imported* (e.g. when just rexported), i.e.
>> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Sat Sep 21 20:06:09 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 21 Sep 2013 11:06:09 -0700
Subject: [Rd] "False" warning on "replacing previous import" when
 re-exporting identical object
In-Reply-To: <CAFDcVCS_7rQT6+VPV3OGbr-7P69B3BShHHz6SWWW2-W34pwGKw@mail.gmail.com>
References: <b0soje9u9ai23iirnopichs6.1377871104139@email.android.com>
	<CAFDcVCTg6Sc91gDZwwrjJnTHxXwuqk45GwckLSYVUT2FQ9GJLg@mail.gmail.com>
	<CAFDcVCSsd0KcZCCRv0f-MzUU__PJE9ZkrGF4jxy7dZS9Ci1Wyg@mail.gmail.com>
	<CAFDcVCTtpv-wUYA=N9vmM1Ojmn+WDT7jqsVNqeHw7hpdDbq0HQ@mail.gmail.com>
	<CAFDcVCS_7rQT6+VPV3OGbr-7P69B3BShHHz6SWWW2-W34pwGKw@mail.gmail.com>
Message-ID: <CAFDcVCThouhHWG1GXRH2tox=uL565Q_Yb6O30O0z9ykngRGD2Q@mail.gmail.com>

On Sat, Sep 21, 2013 at 9:44 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Henrik Bengtsson <hb <at> biostat.ucsf.edu> writes:
>
>>
>> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson
>> <hb <at> biostat.ucsf.edu> wrote:
>> > Hi.
>
> [snip]
>
>   Bump ... Henrik, did you ever post this as a request/wishlist at
> https://bugs.r-project.org/bugzilla3/ ?  (I don't think so, I couldn't
> find it there, but maybe I wasn't looking in the right place.)  I

I submitted PR#15451:

'Bug 15451 - PATCH: namespaceImportFrom() not to warn when the
identical object is imported twice' on 2013-09-10
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15451

There was a brief response from Prof. Ripley and then it was closed.
However, I followed up asking [cc:ing BDR and R-core] for
clarification and I gave some further arguments.  There has been no
response to date.


> would be curious to know what the response was from R-Core, because
> these kinds of warnings are starting to pop up in the nlme/lme4/
> downstream package complex.  In particular,
>
> VarCorr
> fixef
> lmList
> ranef
>
> are defined by nlme, imported and re-exported by lme4.  This doesn't
> seem to make any trouble for lme4, but it does cause problems for
> some of the downstream packages (such as GRRGI:
> [broken URL for Gmane]
> http://www.r-project.org/nosvn/R.check/
>  r-devel-linux-x86_64-fedora-gcc/GRRGI-00check.html )
>
> (Right now GRRGI uses a pretty crude import-all strategy:
> import(nlme,lme4,...); exportPattern("."); which might be
> tweaked, but I think the issue is still worth resolving.)

My interpretation of all this is that either re-exports or import():s
has to/should go.  Trying to predict the future of 'R CMD check' and
re-exports are likely to cause issues as it now stands, I'd say, move
towards dropping import() and start using importFrom().  It's a
tedious move but it can be done.  My issue with packages using
importFrom() is that they will be less agile for changes in APIs, e.g.
one function is moved from on package to another (of the same
"family").

>
>   In a perfect world, I guess some of these generics would be moved
> upstream to a package that both nlme and lme4 could import from,
> but that seems tricky to do without making fairly major architectural
> changes.

Yes, that's a very ad hoc workaround (and not part of my perfect world
because then we get back to the time of name/argument clashes) and I
don't think you want to go there.

/Henrik

>
>   Ben Bolker

On Thu, Sep 12, 2013 at 9:46 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Just for the record, I did submit PR#15451:
>
> 'Bug 15451 - PATCH: namespaceImportFrom() not to warn when the
> identical object is imported twice' on 2013-09-10
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15451
>
> /Henrik
>
> On Mon, Sep 9, 2013 at 2:37 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Any intelligent comments on this before I submit a proposal/patch via
>> bugs.r-project.org?
>>
>> /Henrik
>>
>> On Fri, Aug 30, 2013 at 12:47 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> On Fri, Aug 30, 2013 at 11:51 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>> Hi.
>>>>
>>>> On Fri, Aug 30, 2013 at 6:58 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>>>> This is related to the recent thread on correct NAMESPACE approach when writing S3 methods. If your methods are S4 I think pkgB does not need to export the generic. Just export the method and everything works magically and your problem disappears. For S3 methods there seems to be the difficultly you describe. Of course, the difference between S3 and S4 on this appears somewhat bug like. (I have not tested all this very carefully so I may have something wrong.)
>>>>
>>>> For the record, you're referring to R-devel thread 'Correct NAMESPACE
>>>> approach when writing an S3 method for a generic in another package'
>>>> started on Aug 24, 2013
>>>> [https://stat.ethz.ch/pipermail/r-devel/2013-August/067221.html].
>>>> Yes, it's closely related or possibly the same issue.  However, I do
>>>> not find it odd that the S3 generic function needs to be exported
>>>> from/available via the namespace.  Hence it needs to be export():ed by
>>>> at least one package/namespace.
>>>>
>>>> The real issue is when two package needs to export a generic function
>>>> with the same name, e.g. foo().   If the two generic functions are
>>>> defined differently (e.g. different arguments/signatures), they will
>>>> be in conflict with each other.  If they are identical, this should
>>>> not be a problem, but here I might be wrong.  However, there is also
>>>> the special case where one package reexports the generic function from
>>>> another package, e.g. PkgB::foo() exports PkgA:foo().  In this case,
>>>> the object 'foo' does actually not existing in the name space of
>>>> package PkgB - instead it provides a "redirect" to it, e.g.
>>>>
>>>>> PkgA::foo
>>>> function (...)
>>>> UseMethod("foo")
>>>> <environment: namespace:PkgA>
>>>>
>>>>> PkgB::foo
>>>> function (...)
>>>> UseMethod("foo")
>>>> <environment: namespace:PkgA>
>>>>
>>>>> exists("foo", envir=getNamespace("PkgB"), inherits=FALSE)
>>>> [1] FALSE
>>>>
>>>>> exists("foo", envir=getNamespace("PkgB"), inherits=TRUE)
>>>> [1] TRUE
>>>>
>>>>> identical(PkgB::foo, PkgA::foo)
>>>> [1] TRUE
>>>>
>>>>
>>>> The warning on "replacing previous import by 'PkgA::foo' when loading
>>>> 'PkgC'" that occurs due to import(PkgA, PkgB) is generated in
>>>> base::namespaceImportFrom()
>>>> [http://svn.r-project.org/R/trunk/src/library/base/R/namespace.R],
>>>> simply because it detects that "foo" (=n) has already been imported to
>>>> PkgC' namespace (=impenv):
>>>>
>>>> if (exists(n, envir = impenv, inherits = FALSE)) {
>>>>     if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>>>         ## warn only if generic overwrites a function which
>>>>         ## it was not derived from
>>>>         ...
>>>>     }
>>>>     warning(sprintf(msg, sQuote(paste(nsname, n, sep = "::")),
>>>> sQuote(from)), call. = FALSE, domain = NA)
>>>> }
>>>>
>>>> Note how there is already code for avoiding "false" warnings on S4
>>>> generic function.  This is what we'd like to have also for S3 generic
>>>> functions, but it's much harder to test for such since they're not
>>>> formally defined.  However, I'd argue that it is safe to skip the
>>>> warning *when the variable to be imported does not actually exist in
>>>> the package being imported* (e.g. when just rexported), i.e.
>>>>
>>>>>svn diff namespace.R
>>>> Index: namespace.R
>>>> ===================================================================
>>>> --- namespace.R (revision 63776)
>>>> +++ namespace.R (working copy)
>>>> @@ -871,6 +871,10 @@
>>>>      }
>>>>      for (n in impnames)
>>>>         if (exists(n, envir = impenv, inherits = FALSE)) {
>>>> +            ## warn only if imported variable actually exists in the
>>>> +            ## namespace imported from, which is not the case if
>>>> +            ## the variable is rexported from another namespace
>>>> +            if (!exists(n, envir = ns, inherits = FALSE)) next
>>>>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>>>                 ## warn only if generic overwrites a function which
>>>>                 ## it was not derived from
>>>
>>> Ok, if import(PkgA, PkgB) and PkgB reexports a *different* foo() than
>>> PkgA::foo(), say PkgZ::foo so identical(PkgB::foo, PkgA::foo) is
>>> FALSE, then there is indeed a conflict.  An alternative patch:
>>>
>>>>svn diff namespace.R
>>> Index: namespace.R
>>> ===================================================================
>>> --- namespace.R (revision 63776)
>>> +++ namespace.R (working copy)
>>> @@ -871,6 +871,11 @@
>>>      }
>>>      for (n in impnames)
>>>         if (exists(n, envir = impenv, inherits = FALSE)) {
>>> +            ## warn only if imported variable is non-identical to
>>> +            ## the one already imported
>>> +            getImp <- get(n, envir = impenv)
>>> +            obj <- get(n, envir = ns)
>>> +            if (identical(obj, getImp)) next
>>>             if (.isMethodsDispatchOn() && methods:::isGeneric(n, ns)) {
>>>                 ## warn only if generic overwrites a function which
>>>                 ## it was not derived from
>>>
>>> /Henrik
>>>
>>>>
>>>> I'm planning to propose ("wishlist / enhancement"; it may even be a
>>>> bug) this over at https://bugs.r-project.org/.
>>>>
>>>> Comments, anyone?
>>>>
>>>> /Henrik
>>>>
>>>>
>>>>> Paul
>>>>>
>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>>
>>>>>>Hi,
>>>>>>
>>>>>>SETUP:
>>>>>>Consider three packages PkgA, PkgB and PkgC.
>>>>>>
>>>>>>PkgA defines a generic function foo() and exports it;
>>>>>>
>>>>>>export(foo)
>>>>>>
>>>>>>PkgB imports PkgA::foo() and re-exports it;
>>>>>>
>>>>>>importFrom(PkgA, foo)
>>>>>>export(foo)
>>>>>>
>>>>>>PkgC imports everything from PkgA and PkgB:
>>>>>>
>>>>>>imports(PkgA, PkgB)
>>>>>>
>>>>>>
>>>>>>PROBLEM:
>>>>>>Loading or attaching the namespace of PkgC will generate a warning:
>>>>>>
>>>>>>  replacing previous import by 'PkgA::foo' when loading 'PkgC'
>>>>>>
>>>>>>This in turn causes 'R CMD check' on PkgC to generate a WARNING (no-go at CRAN):
>>>>>>
>>>>>>* checking whether package 'PkgC' can be installed ... WARNING
>>>>>>Found the following significant warnings:
>>>>>>  Warning: replacing previous import by 'PkgA::foo' when loading
>>>>>>'CellularAutomaton'
>>>>>>
>>>>>>
>>>>>>FALSE?
>>>>>>Isn't it valid to argue that this is a "false" warning, because
>>>>>>identical(PkgB::foo, PkgA::foo) is TRUE and therefore has no effect?
>>>>>>
>>>>>>
>>>>>>/Henrik
>>>>>>
>>>>>>PS. The above can be avoided by using explicit importFrom() on PkgA
>>>>>>and PkgB, but that's really tedious.  In my case this is out of my
>>>>>>reach, because I'm the author of PkgA and PkgB but not many of the
>>>>>>PkgC packages.
>>>>>>
>>>>>>______________________________________________
>>>>>>R-devel at r-project.org mailing list
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-devel


From tobias.verbeke at openanalytics.eu  Sat Sep 21 20:43:32 2013
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sat, 21 Sep 2013 20:43:32 +0200 (CEST)
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <847693355.1777.1379787265680.JavaMail.zimbra@openanalytics.eu>
Message-ID: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>

L.S.

In this bug report

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14493#c1

it is mentioned that after moving an R installation
one should regenerate the Rscript executable.

Is there an easy way to do so (after an R installation has been
moved)?

I have not found any information in the R installation and 
administration manual.

Many thanks in advance for any pointer.

Best wishes,
Tobias

P.S. The background to this question is the usage of Rscript
calls in the Makevars files of some R packages on CRAN, so
the 'broken' Rscript prevents installation of certain R packages.

-- 

Tobias Verbeke
Manager

OpenAnalytics BVBA
Jupiterstraat 20
2600 Antwerp
Belgium 

E tobias.verbeke at openanalytics.eu
M +32 499 36 33 15
http://www.openanalytics.eu


From edd at debian.org  Sat Sep 21 21:00:12 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 21 Sep 2013 14:00:12 -0500
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
References: <847693355.1777.1379787265680.JavaMail.zimbra@openanalytics.eu>
	<145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
Message-ID: <21053.60604.509740.183222@max.nulle.part>


On 21 September 2013 at 20:43, Tobias Verbeke wrote:
| P.S. The background to this question is the usage of Rscript
| calls in the Makevars files of some R packages on CRAN, so
| the 'broken' Rscript prevents installation of certain R packages.

More details, please. 

AFAICT there is no 'broken' Rscript per se.  Eg for Rcpp, and per hints from
Kurt el al over the years, we have been doing this for a few years

  PKG_CXXFLAGS=-I../inst/include
  PKG_LIBS=`$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)

where a key part is the `$(R_HOME)/bin` which permits you to transparently
switch between R-release, R-devel, R-beforeMove, R-afterMove, R-whatevr, ...
simply by adjusting your shell's $PATH variable, or the R wrapper you for R
CMD, or ...

It. Just. Works.

So if you borked your Rscript somewhere, just use another and quickly rebuild
R for the new location. It is after all a cheap build (and cheaper still if
you use tricks like ccache which I am a huge fan of, or 'make -j8', or ...)

Dirk

PS  ccache is at http://ccache.samba.org/ and should be in any sane Linux distro

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From tobias.verbeke at openanalytics.eu  Sat Sep 21 21:39:12 2013
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sat, 21 Sep 2013 21:39:12 +0200 (CEST)
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <21053.60604.509740.183222@max.nulle.part>
References: <847693355.1777.1379787265680.JavaMail.zimbra@openanalytics.eu>
	<145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<21053.60604.509740.183222@max.nulle.part>
Message-ID: <1021845929.1859.1379792352728.JavaMail.zimbra@openanalytics.eu>

Hi Dirk, 

Many thanks for your reaction.

----- Original Message -----
> From: "Dirk Eddelbuettel" <edd at debian.org>
> To: "Tobias Verbeke" <tobias.verbeke at openanalytics.eu>
> Cc: r-devel at r-project.org
> Sent: Saturday, September 21, 2013 9:00:12 PM
> Subject: Re: [Rd] regenerate Rscript after moving R installation
> 
> 
> On 21 September 2013 at 20:43, Tobias Verbeke wrote:
> | P.S. The background to this question is the usage of Rscript
> | calls in the Makevars files of some R packages on CRAN, so
> | the 'broken' Rscript prevents installation of certain R packages.
> 
> More details, please.
> 
> AFAICT there is no 'broken' Rscript per se.  Eg for Rcpp, and per hints from
> Kurt el al over the years, we have been doing this for a few years
> 
>   PKG_CXXFLAGS=-I../inst/include
>   PKG_LIBS=`$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` $(LAPACK_LIBS)
>   $(BLAS_LIBS) $(FLIBS)

The package that made me discover this was RcppEigen which has indeed

PKG_LIBS=`$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
 
> where a key part is the `$(R_HOME)/bin` which permits you to transparently
> switch between R-release, R-devel, R-beforeMove, R-afterMove, R-whatevr, ...
> simply by adjusting your shell's $PATH variable, or the R wrapper you for R
> CMD, or ...
> 
> It. Just. Works.

It is neat and certainly works, unless R is built on another location (on a build machine)
prior to being put on its final location.

If I read the strace output below correctly, the origin of the problem is the hardcoded
location of the R binary.

tobias at oa-laptop:/opt/architect/architect-stable/plugins/eu.openanalytics.architect.r.server.gtk.linux_stable/R/bin$ strace ./Rscript -e '2+2'
execve("./Rscript", ["./Rscript", "-e", "2+2"], [/* 51 vars */]) = 0
brk(0)                                  = 0x1eb6000
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc7563e1000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=161604, ...}) = 0
mmap(NULL, 161604, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fc7563b9000
close(3)                                = 0
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
open("/lib/x86_64-linux-gnu/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\200\30\2\0\0\0\0\0"..., 832) = 832
fstat(3, {st_mode=S_IFREG|0755, st_size=1811128, ...}) = 0
mmap(NULL, 3925208, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fc755e02000
mprotect(0x7fc755fb7000, 2093056, PROT_NONE) = 0
mmap(0x7fc7561b6000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b4000) = 0x7fc7561b6000
mmap(0x7fc7561bc000, 17624, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fc7561bc000
close(3)                                = 0
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc7563b8000
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc7563b7000
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc7563b6000
arch_prctl(ARCH_SET_FS, 0x7fc7563b7700) = 0
mprotect(0x7fc7561b6000, 16384, PROT_READ) = 0
mprotect(0x601000, 4096, PROT_READ)     = 0
mprotect(0x7fc7563e3000, 4096, PROT_READ) = 0
munmap(0x7fc7563b9000, 161604)          = 0
brk(0)                                  = 0x1eb6000
brk(0x1ed7000)                          = 0x1ed7000
execve("/home/builduser/architect/stable/R-build/sources/R-3.0.1/bin/R", ["/home/builduser/architect/stable/"..., "--slave", "--no-restore", "-e", "2+2", "--args"], [/* 52 vars */]) = -1 ENOENT (No such file or directory)
dup(2)                                  = 3
fcntl(3, F_GETFL)                       = 0x8002 (flags O_RDWR|O_LARGEFILE)
fstat(3, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 3), ...}) = 0
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc7563e0000
lseek(3, 0, SEEK_CUR)                   = -1 ESPIPE (Illegal seek)
write(3, "Rscript execution error: No such"..., 51Rscript execution error: No such file or directory
) = 51
close(3)                                = 0
munmap(0x7fc7563e0000, 4096)            = 0
exit_group(-1)                          = ?
 
> So if you borked your Rscript somewhere, just use another and quickly rebuild
> R for the new location. It is after all a cheap build (and cheaper still if
> you use tricks like ccache which I am a huge fan of, or 'make -j8', or ...)

There is no way to build again since R itself is shipped (in a Debian/Ubuntu package
and as part of Architect) prior to being installed and used on another computer.
The buildstamp that is part of the final installation path of the application is 
generated after the R build (since R is only one component), so changing the --prefix
on the build machine would not work (currently).

I hope this gives more background to the question and would be curious if there are alternatives
to rapidly regenerate the Rscript executable only.

(My other alternative of messing with the path in a hex editor has not been successful :-)

Best wishes,
Tobias

P.S. Architect can be installed from

http://deb.openanalytics.eu/howto.html

sudo apt-get install architect

> 
> Dirk
> 
> PS  ccache is at http://ccache.samba.org/ and should be in any sane Linux
> distro
> 
> --
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>


From edd at debian.org  Sat Sep 21 23:03:37 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 21 Sep 2013 16:03:37 -0500
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <1021845929.1859.1379792352728.JavaMail.zimbra@openanalytics.eu>
References: <847693355.1777.1379787265680.JavaMail.zimbra@openanalytics.eu>
	<145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<21053.60604.509740.183222@max.nulle.part>
	<1021845929.1859.1379792352728.JavaMail.zimbra@openanalytics.eu>
Message-ID: <21054.2473.846704.526560@max.nulle.part>


Tobias,

On 21 September 2013 at 21:39, Tobias Verbeke wrote:
| The package that made me discover this was RcppEigen which has indeed

Never heard of it :)
 
| PKG_LIBS=`$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
|  
| > where a key part is the `$(R_HOME)/bin` which permits you to transparently
| > switch between R-release, R-devel, R-beforeMove, R-afterMove, R-whatevr, ...
| > simply by adjusting your shell's $PATH variable, or the R wrapper you for R
| > CMD, or ...
| > 
| > It. Just. Works.
| 
| It is neat and certainly works, unless R is built on another location (on a build machine)
| prior to being put on its final location.
| 
| If I read the strace output below correctly, the origin of the problem is the hardcoded
| location of the R binary.
[...]
| There is no way to build again since R itself is shipped (in a Debian/Ubuntu package
| and as part of Architect) prior to being installed and used on another computer.
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

I do not know what 'Architekt' is -- but maybe you just mistakenly assume
that you can mv(1) installations at will?  And maybe you can't?  Consider the

        configure --prefix=/some/location/ ...
        make
        make install

where /some/location gets set at compile-time. 

You seem to wish it didn't.  But wishing alone may not make it so. In all
seriousness, these binaries may not be relocatable at will.

| The buildstamp that is part of the final installation path of the application is 
| generated after the R build (since R is only one component), so changing the --prefix
| on the build machine would not work (currently).
| 
| I hope this gives more background to the question and would be curious if there are alternatives
| to rapidly regenerate the Rscript executable only.
| 
| (My other alternative of messing with the path in a hex editor has not been successful :-)

I'd go back to rebuilding for the target location. 

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From tobias.verbeke at openanalytics.eu  Sun Sep 22 00:21:19 2013
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sun, 22 Sep 2013 00:21:19 +0200 (CEST)
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <21054.2473.846704.526560@max.nulle.part>
References: <847693355.1777.1379787265680.JavaMail.zimbra@openanalytics.eu>
	<145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<21053.60604.509740.183222@max.nulle.part>
	<1021845929.1859.1379792352728.JavaMail.zimbra@openanalytics.eu>
	<21054.2473.846704.526560@max.nulle.part>
Message-ID: <1799718350.1916.1379802079979.JavaMail.zimbra@openanalytics.eu>

Hi Dirk, 

----- Original Message -----
> From: "Dirk Eddelbuettel" <edd at debian.org>
> To: "Tobias Verbeke" <tobias.verbeke at openanalytics.eu>
> Cc: "Dirk Eddelbuettel" <edd at debian.org>, r-devel at r-project.org
> Sent: Saturday, September 21, 2013 11:03:37 PM
> Subject: Re: [Rd] regenerate Rscript after moving R installation
> 
> 
> Tobias,
> 
> On 21 September 2013 at 21:39, Tobias Verbeke wrote:
> | The package that made me discover this was RcppEigen which has indeed
> 
> Never heard of it :)
>  
> | PKG_LIBS=`$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` $(LAPACK_LIBS)
> | $(BLAS_LIBS) $(FLIBS)
> |  
> | > where a key part is the `$(R_HOME)/bin` which permits you to
> | > transparently
> | > switch between R-release, R-devel, R-beforeMove, R-afterMove, R-whatevr,
> | > ...
> | > simply by adjusting your shell's $PATH variable, or the R wrapper you for
> | > R
> | > CMD, or ...
> | > 
> | > It. Just. Works.
> | 
> | It is neat and certainly works, unless R is built on another location (on a
> | build machine)
> | prior to being put on its final location.
> | 
> | If I read the strace output below correctly, the origin of the problem is
> | the hardcoded
> | location of the R binary.
> [...]
> | There is no way to build again since R itself is shipped (in a
> | Debian/Ubuntu package
> | and as part of Architect) prior to being installed and used on another
> | computer.
>                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> I do not know what 'Architekt' is -- but maybe you just mistakenly assume

Architect is a cross-platform Eclipse based R IDE with a.o. out-of-the-box Rcpp support ;-)

> that you can mv(1) installations at will?  And maybe you can't?  Consider the
> 
>         configure --prefix=/some/location/ ...
>         make
>         make install
> 
> where /some/location gets set at compile-time.
> 
> You seem to wish it didn't.  But wishing alone may not make it so. In all
> seriousness, these binaries may not be relocatable at will.

That is fair enough. I do not expect R-devel to be populated with Djinns,
but was puzzled (and probably lead down the wrong path) by the fact that 
Rscript was the only stubborn piece in our build procedures.

> | The buildstamp that is part of the final installation path of the
> | application is
> | generated after the R build (since R is only one component), so changing
> | the --prefix
> | on the build machine would not work (currently).
> | 
> | I hope this gives more background to the question and would be curious if
> | there are alternatives
> | to rapidly regenerate the Rscript executable only.
> | 
> | (My other alternative of messing with the path in a hex editor has not been
> | successful :-)
> 
> I'd go back to rebuilding for the target location.

Thank you! I will report back if I find out more.

Best,
Tobias

> 
> Dirk
> 
> --
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>


From simon.urbanek at r-project.org  Sun Sep 22 03:42:30 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 22 Sep 2013 03:42:30 +0200
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
References: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
Message-ID: <B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>

On Sep 21, 2013, at 8:43 PM, Tobias Verbeke <tobias.verbeke at openanalytics.eu> wrote:

> L.S.
> 
> In this bug report
> 
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14493#c1
> 
> it is mentioned that after moving an R installation
> one should regenerate the Rscript executable.
> 
> Is there an easy way to do so (after an R installation has been
> moved)?
> 

You cannot move installed R. Once you run make install, there are several places in which paths get baked in - mainly Rscript and the R start script. What I typically do for deployment on the Labs machines is to use make install rhome=<xxx> where <xxx> is some path that I can always create a symlink in (I also use DESTDIR so that path doesn't actually need to exist on the build machine and it avoid polluting --prefix which is not needed). That way you can move R wherever you want as long so you keep that one symlink up to date.

Cheers,
Simon


> I have not found any information in the R installation and 
> administration manual.
> 
> Many thanks in advance for any pointer.
> 
> Best wishes,
> Tobias
> 
> P.S. The background to this question is the usage of Rscript
> calls in the Makevars files of some R packages on CRAN, so
> the 'broken' Rscript prevents installation of certain R packages.
> 
> -- 
> 
> Tobias Verbeke
> Manager
> 
> OpenAnalytics BVBA
> Jupiterstraat 20
> 2600 Antwerp
> Belgium 
> 
> E tobias.verbeke at openanalytics.eu
> M +32 499 36 33 15
> http://www.openanalytics.eu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Sun Sep 22 03:45:41 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 22 Sep 2013 03:45:41 +0200
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>
References: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>
Message-ID: <537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>

I forgot to mention that some packages bake-in paths as well, so even if you fix both R and Rscript, it will still not work in general.

On Sep 22, 2013, at 3:42 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Sep 21, 2013, at 8:43 PM, Tobias Verbeke <tobias.verbeke at openanalytics.eu> wrote:
> 
>> L.S.
>> 
>> In this bug report
>> 
>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14493#c1
>> 
>> it is mentioned that after moving an R installation
>> one should regenerate the Rscript executable.
>> 
>> Is there an easy way to do so (after an R installation has been
>> moved)?
>> 
> 
> You cannot move installed R. Once you run make install, there are several places in which paths get baked in - mainly Rscript and the R start script. What I typically do for deployment on the Labs machines is to use make install rhome=<xxx> where <xxx> is some path that I can always create a symlink in (I also use DESTDIR so that path doesn't actually need to exist on the build machine and it avoid polluting --prefix which is not needed). That way you can move R wherever you want as long so you keep that one symlink up to date.
> 
> Cheers,
> Simon
> 
> 
>> I have not found any information in the R installation and 
>> administration manual.
>> 
>> Many thanks in advance for any pointer.
>> 
>> Best wishes,
>> Tobias
>> 
>> P.S. The background to this question is the usage of Rscript
>> calls in the Makevars files of some R packages on CRAN, so
>> the 'broken' Rscript prevents installation of certain R packages.
>> 
>> -- 
>> 
>> Tobias Verbeke
>> Manager
>> 
>> OpenAnalytics BVBA
>> Jupiterstraat 20
>> 2600 Antwerp
>> Belgium 
>> 
>> E tobias.verbeke at openanalytics.eu
>> M +32 499 36 33 15
>> http://www.openanalytics.eu
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From tobias.verbeke at openanalytics.eu  Sun Sep 22 09:49:23 2013
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sun, 22 Sep 2013 09:49:23 +0200 (CEST)
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>
References: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>
	<537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>
Message-ID: <2101936180.1999.1379836163411.JavaMail.zimbra@openanalytics.eu>

Dear Simon,

Many thanks for all additional detail and insight into
your practice using rhome and symlinks. Much appreciated!

Best,
Tobias

----- Original Message -----
> From: "Simon Urbanek" <simon.urbanek at r-project.org>
> To: "Tobias Verbeke" <tobias.verbeke at openanalytics.eu>
> Cc: r-devel at r-project.org
> Sent: Sunday, September 22, 2013 3:45:41 AM
> Subject: Re: [Rd] regenerate Rscript after moving R installation
> 
> I forgot to mention that some packages bake-in paths as well, so even if you
> fix both R and Rscript, it will still not work in general.
> 
> On Sep 22, 2013, at 3:42 AM, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> 
> > On Sep 21, 2013, at 8:43 PM, Tobias Verbeke
> > <tobias.verbeke at openanalytics.eu> wrote:
> > 
> >> L.S.
> >> 
> >> In this bug report
> >> 
> >> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14493#c1
> >> 
> >> it is mentioned that after moving an R installation
> >> one should regenerate the Rscript executable.
> >> 
> >> Is there an easy way to do so (after an R installation has been
> >> moved)?
> >> 
> > 
> > You cannot move installed R. Once you run make install, there are several
> > places in which paths get baked in - mainly Rscript and the R start
> > script. What I typically do for deployment on the Labs machines is to use
> > make install rhome=<xxx> where <xxx> is some path that I can always create
> > a symlink in (I also use DESTDIR so that path doesn't actually need to
> > exist on the build machine and it avoid polluting --prefix which is not
> > needed). That way you can move R wherever you want as long so you keep
> > that one symlink up to date.
> > 
> > Cheers,
> > Simon
> > 
> > 
> >> I have not found any information in the R installation and
> >> administration manual.
> >> 
> >> Many thanks in advance for any pointer.
> >> 
> >> Best wishes,
> >> Tobias
> >> 
> >> P.S. The background to this question is the usage of Rscript
> >> calls in the Makevars files of some R packages on CRAN, so
> >> the 'broken' Rscript prevents installation of certain R packages.
> >> 
> >> --
> >> 
> >> Tobias Verbeke
> >> Manager
> >> 
> >> OpenAnalytics BVBA
> >> Jupiterstraat 20
> >> 2600 Antwerp
> >> Belgium
> >> 
> >> E tobias.verbeke at openanalytics.eu
> >> M +32 499 36 33 15
> >> http://www.openanalytics.eu
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> >> 
> > 
> 
>


From bbolker at gmail.com  Sun Sep 22 19:03:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Sep 2013 13:03:45 -0400
Subject: [Rd] type="message" possibility for capture.output() ?
Message-ID: <523F22F1.9010105@ufl.edu>


  As far as I can tell, there's no built-in way to get
capture.output() to capture messages (stderr) instead of
stdout ... suggested, fairly trivial, patch below.

f <- function() {
    message("abc")
    cat("def\n")
}

x <- capture.output(f())
## prints 'abc'
x ## value: "def"

source("~/R/r-devel/src/library/utils/R/capture.output.R")
x <- capture.output(f()) ## unchanged
x <- capture.output(f(),type="message") ## prints 'def': value 'abc'

   Of course, if someone was going to mess with this function more,
it might be nice to have an option to have *both* streams captured ...

Index: capture.output.R
===================================================================
--- capture.output.R	(revision 63969)
+++ capture.output.R	(working copy)
@@ -16,8 +16,10 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/

-capture.output <- function(..., file=NULL, append=FALSE)
+capture.output <- function(..., file=NULL, append=FALSE,
+                           type = c("output", "message"))
 {
+    type <- match.arg(type)
     args <- substitute(list(...))[-1L]

     rval <- NULL; closeit <- TRUE
@@ -31,9 +33,9 @@
     } else
         stop("'file' must be NULL, a character string or a connection")

-    sink(file)
+    sink(file,type=type)
     ## for error recovery: all output will be lost if file=NULL
-    on.exit({sink(); if(closeit) close(file)})
+    on.exit({sink(type=type); if(closeit) close(file)})

     pf <- parent.frame()
     evalVis <- function(expr)
@@ -50,7 +52,7 @@
     }
     ## we need to close the text connection before returning 'rval'
     on.exit()
-    sink()
+    sink(type=type)
     if(closeit) close(file)
     if(is.null(rval)) invisible(NULL) else rval
 }


From josh.m.ulrich at gmail.com  Mon Sep 23 04:03:23 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 22 Sep 2013 21:03:23 -0500
Subject: [Rd] Mailing Lists page, turning off HTML mail
Message-ID: <CAPPM_gSUtWvL-cX72V4gF-zmHX5fWNmA+AdPFQ6wr905UrEiWw@mail.gmail.com>

Hello,

I just noticed that the link to instructions on turning off HTML mail
has been dead for quite some time.  The last capture I could find on
web.archive.org was in mid-2009.
http://web.archive.org/web/20090625155306/http://www.expita.com/nomime.html

For reference, the link is in the following sentence: "For more
details and instructions on turning off HTML for your e-mail software,
see here."

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From ripley at stats.ox.ac.uk  Mon Sep 23 12:55:53 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Sep 2013 11:55:53 +0100
Subject: [Rd] type="message" possibility for capture.output() ?
In-Reply-To: <523F22F1.9010105@ufl.edu>
References: <523F22F1.9010105@ufl.edu>
Message-ID: <52401E39.80704@stats.ox.ac.uk>

That is not safe ... you should at least check if the message stream is 
not already diverted. As the help says:

      Sink-ing the messages stream should be done only with great care.
      For that stream ?file? must be an already open connection, and
      there is no stack of connections.

which seems sufficient warning not to make this any easier (and is why 
it had not been implemented in the past -- it has been discussed).  If 
you have code that you want to run and capture all the output from, it 
is preferable to run it in a separate process and there are lots of 
examples of that in the 'tools' package.

On 22/09/2013 18:03, Ben Bolker wrote:
>
>    As far as I can tell, there's no built-in way to get
> capture.output() to capture messages (stderr) instead of
> stdout ... suggested, fairly trivial, patch below.
>
> f <- function() {
>      message("abc")
>      cat("def\n")
> }
>
> x <- capture.output(f())
> ## prints 'abc'
> x ## value: "def"
>
> source("~/R/r-devel/src/library/utils/R/capture.output.R")
> x <- capture.output(f()) ## unchanged
> x <- capture.output(f(),type="message") ## prints 'def': value 'abc'
>
>     Of course, if someone was going to mess with this function more,
> it might be nice to have an option to have *both* streams captured ...
>
> Index: capture.output.R
> ===================================================================
> --- capture.output.R	(revision 63969)
> +++ capture.output.R	(working copy)
> @@ -16,8 +16,10 @@
>   #  A copy of the GNU General Public License is available at
>   #  http://www.r-project.org/Licenses/
>
> -capture.output <- function(..., file=NULL, append=FALSE)
> +capture.output <- function(..., file=NULL, append=FALSE,
> +                           type = c("output", "message"))
>   {
> +    type <- match.arg(type)
>       args <- substitute(list(...))[-1L]
>
>       rval <- NULL; closeit <- TRUE
> @@ -31,9 +33,9 @@
>       } else
>           stop("'file' must be NULL, a character string or a connection")
>
> -    sink(file)
> +    sink(file,type=type)
>       ## for error recovery: all output will be lost if file=NULL
> -    on.exit({sink(); if(closeit) close(file)})
> +    on.exit({sink(type=type); if(closeit) close(file)})
>
>       pf <- parent.frame()
>       evalVis <- function(expr)
> @@ -50,7 +52,7 @@
>       }
>       ## we need to close the text connection before returning 'rval'
>       on.exit()
> -    sink()
> +    sink(type=type)
>       if(closeit) close(file)
>       if(is.null(rval)) invisible(NULL) else rval
>   }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gdsayshi at gmail.com  Mon Sep 23 14:00:19 2013
From: gdsayshi at gmail.com (Gaurav Dasgupta)
Date: Mon, 23 Sep 2013 17:30:19 +0530
Subject: [Rd] Unable to execute Java MapReduce (Hadoop) code from R using
	rJava
Message-ID: <CACq8Ys3DAT61d7PuJxLaWwKqsn1LCq537+2q5y6fH04YmMV4QQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130923/55631bdb/attachment.pl>

From jeroen.ooms at stat.ucla.edu  Mon Sep 23 20:17:32 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 23 Sep 2013 14:17:32 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
Message-ID: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>

Is there any way to capture output (both stdout and stderr) from
install.packages? Solutions like sink and capture.output don't work
because the install.packages calls out to system2 which is executed in
a separate process:

    test <- capture.output(install.packages("MASS"))

The system2 function does have arguments stdout and stderr but afaik
these cannot be controlled via install.packages. I'm a bit reluctant
to start rolling my own version of install.packages just for this
reason.

Is there any way to somehow grab this output? Or alternatively, is
there a way to make R pipe stdout and stderr from system2 in such a
way that they can be captured with sink or capture.output in the R
parent process?


From dtenenba at fhcrc.org  Mon Sep 23 21:55:40 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 23 Sep 2013 12:55:40 -0700 (PDT)
Subject: [Rd] tar warnings in R-3.0.2 RC when R is installed by a different
 (non-root) user
In-Reply-To: <1600338441.876350.1379965703448.JavaMail.root@fhcrc.org>
Message-ID: <220141431.876438.1379966140031.JavaMail.root@fhcrc.org>

Hi,

I created a package as follows:

> a = 1
> package.skeleton()

Then I got the following output when building the package:

* checking for file ?anRpackage/DESCRIPTION? ... OK
* preparing ?anRpackage?:
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* looking to see if a ?data/datalist? file should be added
* building ?anRpackage_1.0.tar.gz?
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'
Warning: invalid uid value replaced by that for user 'nobody'

One thing to note is that I am logged in as 'pkgbuild' and R was installed by the user 'biocbuild'. I explicitly point to the R that was installed by 'biocbuild' when building the package above. (I used the command "~biocbuild/bbs-2.13-bioc/R/bin/R CMD build anRpackage").

There doesn't seem to be anything wrong with the ownership of the files in anRpackage:

$ ls -lR anRpackage
anRpackage:
total 20
drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 data
-rw-r--r-- 1 pkgbuild users  283 Sep 23 12:42 DESCRIPTION
drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 man
-rw-r--r-- 1 pkgbuild users   31 Sep 23 12:42 NAMESPACE
-rw-r--r-- 1 pkgbuild users  420 Sep 23 12:42 Read-and-delete-me

anRpackage/data:
total 4
-rw-r--r-- 1 pkgbuild users 59 Sep 23 12:42 a.rda

anRpackage/man:
total 8
-rw-r--r-- 1 pkgbuild users 1051 Sep 23 12:42 anRpackage-package.Rd
-rw-r--r-- 1 pkgbuild users  503 Sep 23 12:42 a.Rd

These warnings did not appear with an earlier version of R-patched (r63824).

Thanks,
Dan



> sessionInfo()
R version 3.0.2 RC (2013-09-17 r63944)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From murdoch.duncan at gmail.com  Mon Sep 23 22:20:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Sep 2013 16:20:16 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
Message-ID: <5240A280.1000804@gmail.com>

On 13-09-23 2:17 PM, Jeroen Ooms wrote:
> Is there any way to capture output (both stdout and stderr) from
> install.packages? Solutions like sink and capture.output don't work
> because the install.packages calls out to system2 which is executed in
> a separate process:
>
>      test <- capture.output(install.packages("MASS"))
>
> The system2 function does have arguments stdout and stderr but afaik
> these cannot be controlled via install.packages. I'm a bit reluctant
> to start rolling my own version of install.packages just for this
> reason.
>
> Is there any way to somehow grab this output? Or alternatively, is
> there a way to make R pipe stdout and stderr from system2 in such a
> way that they can be captured with sink or capture.output in the R
> parent process?

See the recent thread 
<https://mailman.stat.ethz.ch/pipermail/r-devel/2013-September/067552.html> 
for an approach to this.

Duncan Murdoch


From spencer.graves at prodsyse.com  Mon Sep 23 23:28:26 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 23 Sep 2013 14:28:26 -0700
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <523AA11E.2050805@stats.ox.ac.uk>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com> <523AA11E.2050805@stats.ox.ac.uk>
Message-ID: <5240B27A.10207@prodsyse.com>

Hello, All:


       Professor Ripley is correct as usual:  I misunderstood his 
original statement of the problem.


       He gave two possible solutions.  I could not make the first 
solution work, and I didn't try the second until someone else on this 
list explained it in slightly more detail.


       The correction passed R CMD check on my local computer.  It has 
been "building" on R-Forge since 2013-09-20 19:19:14+02.  I hope this 
completes soon enough for me to meet Ripley's Sept. 25 deadline for this 
correction to "sos".


       Thanks again to Prof. Ripley and everyone else who took the time 
to read my post.


       Spencer


On 9/19/2013 12:00 AM, Prof Brian Ripley wrote:
> This is nothing to do with CRAN policies (nor R).
>
> The issue is that the current upquote.sty does not play with 'ae' 
> fonts as used by default by Sweave.  The change is in TeX.
>
> And that was what Spencer Graves was informed.
>
>
> On 19/09/2013 04:35, Spencer Graves wrote:
>> Hello, All:
>>
>>
>>        The vignette with the sos package used "upquote.sty", required
>> for R Journal when it was published in 2009.  Current CRAN policy
>> disallows "upquote.sty", and I've so far not found a way to pass "R CMD
>> check" with sos without upquote.sty.
>>
>>
>>        I changed sos.Rnw per an email exchange with Prof. Ripley without
>> solving the problem; see below.  The key error messages (see the results
>> of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error:
>> Environment article undefined" and " sos.tex:558: LaTeX Error:
>> \begin{document} ended by \end{article}."  When the article worked, it
>> had bot \begin{document} and \begin{article}, with matching \end
>> statements for both.  I've tried commenting out either without success.
>>
>>
>>        The current nonworking code is available on R-Forge via anonymous
>> SVN checkout using "svn checkout
>> svn://svn.r-forge.r-project.org/svnroot/rsitesearch/". Any suggestions
>> on how to fix this would be greatly appreciated.
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> ###### COMPLETE RESULTS FROM R CMD check ########
>>
>>
>> Microsoft Windows [Version 6.1.7600]
>> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>>
>> C:\Users\sgraves>cd 2013
>> C:\Users\sgraves\2013>cd R_pkgs
>> C:\Users\sgraves\2013\R_pkgs>cd sos
>> C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
>> C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
>> * checking for file 'sos/DESCRIPTION' ... OK
>> * preparing 'sos':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to re-build vignettes
>> * creating vignettes ... ERROR
>> Loading required package: brew
>>
>> Attaching package: 'sos'
>>
>> The following object is masked from 'package:utils':
>>
>>       ?
>>
>> Loading required package: WriteXLS
>> Perl found.
>>
>> The following Perl modules were not found on this system:
>>
>> Text::CSV_XS
>>
>> If you have more than one Perl installation, be sure the correct one was
>> used he
>> re.
>>
>> Otherwise, please install the missing modules. See the package INSTALL
>> file for
>> more information.
>>
>> Loading required package: RODBC
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>> Rolf Turner
>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van 
>> Liesho
>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>> Waagepetersen.
>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>> Che
>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>> P.J. Dig
>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>> Funwi-Gabga;
>>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>    P. Graba
>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>> Herin
>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. 
>> Ihaka
>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>> Kuhn;
>>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>> J. Lee;
>>           G.P. Leser; [... truncated]
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>> Bates [ct
>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>> Gregor Gorja
>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>> Laboissiere [ctb
>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>> Ripley [
>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>> column 'Autho
>> r'
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>> Ash [ctb],
>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>> Andy Cha
>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>> Pour [c
>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>> Uwe Ligg
>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>> [ctb], Dunc
>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>> [ctb], Mi
>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>> 'Author'
>>
>> Perl found.
>>
>> The following Perl modules were not found on this system:
>>
>> Text::CSV_XS
>>
>> If you have more than one Perl installation, be sure the correct one was
>> used he
>> re.
>>
>> Otherwise, please install the missing modules. See the package INSTALL
>> file for
>> more information.
>>
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>> Rolf Turner
>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van 
>> Liesho
>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>> Waagepetersen.
>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>> Che
>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>> P.J. Dig
>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>> Funwi-Gabga;
>>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>    P. Graba
>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>> Herin
>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. 
>> Ihaka
>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>> Kuhn;
>>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>> J. Lee;
>>           G.P. Leser; [... truncated]
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>> Bates [ct
>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>> Gregor Gorja
>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>> Laboissiere [ctb
>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>> Ripley [
>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>> column 'Autho
>> r'
>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = 
>> test,  :
>>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>> Ash [ctb],
>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>> Andy Cha
>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>> Pour [c
>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>> Uwe Ligg
>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>> [ctb], Dunc
>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>> [ctb], Mi
>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>> 'Author'
>>
>> Warning: running command
>> '"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
>> et --pdf "sos.tex"  -I
>> "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
>> I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status 1
>> Error: running 'texi2dvi' on 'sos.tex' failed
>>
>> LaTeX errors:
>> sos.tex:16: LaTeX Error: Environment article undefined.
>>
>> See the LaTeX manual or LaTeX Companion for explanation.
>> Type  H <return>  for immediate help
>> Your command was ignored.
>> sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.
>>
>> See the LaTeX manual or LaTeX Companion for explanation.
>> Type  H <return>  for immediate help
>> Your command was ignored.
>> Execution halted
>>
>>
>> On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
>>> On 13/09/2013 08:30, Spencer Graves wrote:
>>>> Dear Prof. Ripley:
>>>>
>>>>
>>>>        What do you recommend I do with the vignette that comes with 
>>>> that
>>>> package?
>>>>
>>>>
>>>>        That vignette is a copy of the article published in the R 
>>>> Journal
>>>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>>>> RJournal.sty.  When I removed RJournal.sty from the vignette
>>>> subdirectory, "R CMD build" failed.  I have no idea what you want 
>>>> me to
>>>> do to fix this problem.  Further assistance would be appreciated.
>>>
>>> Don't spam all the other addressees!
>>>
>>> The issue is using RJournal.sty in a vignette with ae fonts. I am
>>> guessing that
>>>
>>> \usepackage[noae]{Sweave}
>>>
>>> might work: otherwise you need to remove the reference to upquote.sty
>>> in RJournal.sty.
>>>
>>>
>>>>
>>>>
>>>>        Thanks,
>>>>        Spencer Graves
>>>>
>>>>
>>>> p.s.  I understand reasonably well R and the *.Rd documentation
>>>> standard, thanks in part to your book on "Modern Applied Statistics 
>>>> with
>>>> S" and the documentation that ships with R. However, this is the only
>>>> vignette I've written, and I have not used LaTeX much for anything 
>>>> else
>>>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>>>> with R and Matlab (Springer).
>>>>
>>>>
>>>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>>>>> Brian,
>>>>> I am making changes, downloading new version of Sweave.sty and
>>>>> upquote.sty. However, it is not clear to me how to properly credit
>>>>> Fritz Leisch and others for Sweave. Do you mean in the sweave 
>>>>> document
>>>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>>>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>>>>> find anything about this in "Writing R Extensions".
>>>>> Thanks for any guidance,
>>>>> Brian
>>>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>>>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>>>>>> upquote.sty in earlier versions of R and not that currently being
>>>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>>>>>> version of upquote.sty.
>>>>>>
>>>>>> In particular, they do not work with the 'ae' fonts which are the
>>>>>> default for Sweave vignettes.   Packages
>>>>>>
>>>>>> boolfun calibrate popReconstruct qtlnet
>>>>>>
>>>>>> have copies in vignettes and now fail.
>>>>>>
>>>>>> Please remove them. Note too that you did not comply with the CRAN
>>>>>> policies on giving credit by including them in your package but not
>>>>>> crediting their authors: do check very carefully that there are no
>>>>>> other missing credits.
>>>>>>
>>>>>> Package PSM has vignettes which include upquote.sty.
>>>>>>
>>>>>> Packages makeR and sos include RJournal.sty which includes
>>>>>> upquote.sty: same problem.
>>>>>>
>>>>>> Please update your package as soon as possible and definitely before
>>>>>> the release of 3.0.2 on Sept 25.


From marc_schwartz at me.com  Mon Sep 23 23:44:15 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 23 Sep 2013 16:44:15 -0500
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <5240B27A.10207@prodsyse.com>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com> <523AA11E.2050805@stats.ox.ac.uk>
	<5240B27A.10207@prodsyse.com>
Message-ID: <A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>

Spencer,

FYI. I just noted in your post below the error message from WriteXLS regarding TEXT::CSV_XS missing.

Please note that in version >=3.0 of WriteXLS (current is 3.2.1), that is no longer required and has been replaced by Text::CSV_PP, which is a Pure Perl module and is included in the WriteXLS CRAN package to reduce the dependencies on nonstandard external Perl modules.

Regards,

Marc Schwartz


On Sep 23, 2013, at 4:28 PM, Spencer Graves <spencer.graves at prodsyse.com> wrote:

> Hello, All:
> 
> 
>      Professor Ripley is correct as usual:  I misunderstood his original statement of the problem.
> 
> 
>      He gave two possible solutions.  I could not make the first solution work, and I didn't try the second until someone else on this list explained it in slightly more detail.
> 
> 
>      The correction passed R CMD check on my local computer.  It has been "building" on R-Forge since 2013-09-20 19:19:14+02.  I hope this completes soon enough for me to meet Ripley's Sept. 25 deadline for this correction to "sos".
> 
> 
>      Thanks again to Prof. Ripley and everyone else who took the time to read my post.
> 
> 
>      Spencer
> 
> 
> On 9/19/2013 12:00 AM, Prof Brian Ripley wrote:
>> This is nothing to do with CRAN policies (nor R).
>> 
>> The issue is that the current upquote.sty does not play with 'ae' fonts as used by default by Sweave.  The change is in TeX.
>> 
>> And that was what Spencer Graves was informed.
>> 
>> 
>> On 19/09/2013 04:35, Spencer Graves wrote:
>>> Hello, All:
>>> 
>>> 
>>>       The vignette with the sos package used "upquote.sty", required
>>> for R Journal when it was published in 2009.  Current CRAN policy
>>> disallows "upquote.sty", and I've so far not found a way to pass "R CMD
>>> check" with sos without upquote.sty.
>>> 
>>> 
>>>       I changed sos.Rnw per an email exchange with Prof. Ripley without
>>> solving the problem; see below.  The key error messages (see the results
>>> of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error:
>>> Environment article undefined" and " sos.tex:558: LaTeX Error:
>>> \begin{document} ended by \end{article}."  When the article worked, it
>>> had bot \begin{document} and \begin{article}, with matching \end
>>> statements for both.  I've tried commenting out either without success.
>>> 
>>> 
>>>       The current nonworking code is available on R-Forge via anonymous
>>> SVN checkout using "svn checkout
>>> svn://svn.r-forge.r-project.org/svnroot/rsitesearch/". Any suggestions
>>> on how to fix this would be greatly appreciated.
>>> 
>>> 
>>>        Thanks,
>>>        Spencer
>>> 
>>> 
>>> ###### COMPLETE RESULTS FROM R CMD check ########
>>> 
>>> 
>>> Microsoft Windows [Version 6.1.7600]
>>> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>>> 
>>> C:\Users\sgraves>cd 2013
>>> C:\Users\sgraves\2013>cd R_pkgs
>>> C:\Users\sgraves\2013\R_pkgs>cd sos
>>> C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
>>> C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
>>> * checking for file 'sos/DESCRIPTION' ... OK
>>> * preparing 'sos':
>>> * checking DESCRIPTION meta-information ... OK
>>> * installing the package to re-build vignettes
>>> * creating vignettes ... ERROR
>>> Loading required package: brew
>>> 
>>> Attaching package: 'sos'
>>> 
>>> The following object is masked from 'package:utils':
>>> 
>>>      ?
>>> 
>>> Loading required package: WriteXLS
>>> Perl found.
>>> 
>>> The following Perl modules were not found on this system:
>>> 
>>> Text::CSV_XS
>>> 
>>> If you have more than one Perl installation, be sure the correct one was
>>> used he
>>> re.
>>> 
>>> Otherwise, please install the missing modules. See the package INSTALL
>>> file for
>>> more information.
>>> 
>>> Loading required package: RODBC
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>>> Rolf Turner
>>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
>>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>>> Waagepetersen.
>>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>>> Che
>>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>>> P.J. Dig
>>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>>> Funwi-Gabga;
>>>          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>>   P. Graba
>>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>>> Herin
>>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
>>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>>> Kuhn;
>>>          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>>> J. Lee;
>>>          G.P. Leser; [... truncated]
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>>> Bates [ct
>>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>>> Gregor Gorja
>>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>>> Laboissiere [ctb
>>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>>> Ripley [
>>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>>> column 'Autho
>>> r'
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>>> Ash [ctb],
>>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>>> Andy Cha
>>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>>> Pour [c
>>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>>> Uwe Ligg
>>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>>> [ctb], Dunc
>>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>>> [ctb], Mi
>>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>>> 'Author'
>>> 
>>> Perl found.
>>> 
>>> The following Perl modules were not found on this system:
>>> 
>>> Text::CSV_XS
>>> 
>>> If you have more than one Perl installation, be sure the correct one was
>>> used he
>>> re.
>>> 
>>> Otherwise, please install the missing modules. See the package INSTALL
>>> file for
>>> more information.
>>> 
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>>> Rolf Turner
>>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
>>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>>> Waagepetersen.
>>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>>> Che
>>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>>> P.J. Dig
>>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>>> Funwi-Gabga;
>>>          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>>   P. Graba
>>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>>> Herin
>>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
>>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>>> Kuhn;
>>>          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>>> J. Lee;
>>>          G.P. Leser; [... truncated]
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>>> Bates [ct
>>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>>> Gregor Gorja
>>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>>> Laboissiere [ctb
>>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>>> Ripley [
>>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>>> column 'Autho
>>> r'
>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>>> Ash [ctb],
>>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>>> Andy Cha
>>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>>> Pour [c
>>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>>> Uwe Ligg
>>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>>> [ctb], Dunc
>>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>>> [ctb], Mi
>>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>>> 'Author'
>>> 
>>> Warning: running command
>>> '"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
>>> et --pdf "sos.tex"  -I
>>> "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
>>> I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status 1
>>> Error: running 'texi2dvi' on 'sos.tex' failed
>>> 
>>> LaTeX errors:
>>> sos.tex:16: LaTeX Error: Environment article undefined.
>>> 
>>> See the LaTeX manual or LaTeX Companion for explanation.
>>> Type  H <return>  for immediate help
>>> Your command was ignored.
>>> sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.
>>> 
>>> See the LaTeX manual or LaTeX Companion for explanation.
>>> Type  H <return>  for immediate help
>>> Your command was ignored.
>>> Execution halted
>>> 
>>> 
>>> On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
>>>> On 13/09/2013 08:30, Spencer Graves wrote:
>>>>> Dear Prof. Ripley:
>>>>> 
>>>>> 
>>>>>       What do you recommend I do with the vignette that comes with that
>>>>> package?
>>>>> 
>>>>> 
>>>>>       That vignette is a copy of the article published in the R Journal
>>>>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>>>>> RJournal.sty.  When I removed RJournal.sty from the vignette
>>>>> subdirectory, "R CMD build" failed.  I have no idea what you want me to
>>>>> do to fix this problem.  Further assistance would be appreciated.
>>>> 
>>>> Don't spam all the other addressees!
>>>> 
>>>> The issue is using RJournal.sty in a vignette with ae fonts. I am
>>>> guessing that
>>>> 
>>>> \usepackage[noae]{Sweave}
>>>> 
>>>> might work: otherwise you need to remove the reference to upquote.sty
>>>> in RJournal.sty.
>>>> 
>>>> 
>>>>> 
>>>>> 
>>>>>       Thanks,
>>>>>       Spencer Graves
>>>>> 
>>>>> 
>>>>> p.s.  I understand reasonably well R and the *.Rd documentation
>>>>> standard, thanks in part to your book on "Modern Applied Statistics with
>>>>> S" and the documentation that ships with R. However, this is the only
>>>>> vignette I've written, and I have not used LaTeX much for anything else
>>>>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>>>>> with R and Matlab (Springer).
>>>>> 
>>>>> 
>>>>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>>>>>> Brian,
>>>>>> I am making changes, downloading new version of Sweave.sty and
>>>>>> upquote.sty. However, it is not clear to me how to properly credit
>>>>>> Fritz Leisch and others for Sweave. Do you mean in the sweave document
>>>>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>>>>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>>>>>> find anything about this in "Writing R Extensions".
>>>>>> Thanks for any guidance,
>>>>>> Brian
>>>>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>>>>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>>>>>>> upquote.sty in earlier versions of R and not that currently being
>>>>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>>>>>>> version of upquote.sty.
>>>>>>> 
>>>>>>> In particular, they do not work with the 'ae' fonts which are the
>>>>>>> default for Sweave vignettes.   Packages
>>>>>>> 
>>>>>>> boolfun calibrate popReconstruct qtlnet
>>>>>>> 
>>>>>>> have copies in vignettes and now fail.
>>>>>>> 
>>>>>>> Please remove them. Note too that you did not comply with the CRAN
>>>>>>> policies on giving credit by including them in your package but not
>>>>>>> crediting their authors: do check very carefully that there are no
>>>>>>> other missing credits.
>>>>>>> 
>>>>>>> Package PSM has vignettes which include upquote.sty.
>>>>>>> 
>>>>>>> Packages makeR and sos include RJournal.sty which includes
>>>>>>> upquote.sty: same problem.
>>>>>>> 
>>>>>>> Please update your package as soon as possible and definitely before
>>>>>>> the release of 3.0.2 on Sept 25.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Sep 23 23:53:08 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Sep 2013 22:53:08 +0100
Subject: [Rd] tar warnings in R-3.0.2 RC when R is installed by a
 different (non-root) user
In-Reply-To: <220141431.876438.1379966140031.JavaMail.root@fhcrc.org>
References: <220141431.876438.1379966140031.JavaMail.root@fhcrc.org>
Message-ID: <5240B844.1080701@stats.ox.ac.uk>

The issue is not the ownership (uname) but the uid.  A tarball can only 
store uids up to 'nobody' (usually 32767), and certainly larger ones 
cannot be unpacked portably.

The warnings did not occur before, but the tarball produced could cause 
problems when unpacking with other tools.

On 23/09/2013 20:55, Dan Tenenbaum wrote:
> Hi,
>
> I created a package as follows:
>
>> a = 1
>> package.skeleton()
>
> Then I got the following output when building the package:
>
> * checking for file ?anRpackage/DESCRIPTION? ... OK
> * preparing ?anRpackage?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * looking to see if a ?data/datalist? file should be added
> * building ?anRpackage_1.0.tar.gz?
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
> Warning: invalid uid value replaced by that for user 'nobody'
>
> One thing to note is that I am logged in as 'pkgbuild' and R was installed by the user 'biocbuild'. I explicitly point to the R that was installed by 'biocbuild' when building the package above. (I used the command "~biocbuild/bbs-2.13-bioc/R/bin/R CMD build anRpackage").
>
> There doesn't seem to be anything wrong with the ownership of the files in anRpackage:
>
> $ ls -lR anRpackage
> anRpackage:
> total 20
> drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 data
> -rw-r--r-- 1 pkgbuild users  283 Sep 23 12:42 DESCRIPTION
> drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 man
> -rw-r--r-- 1 pkgbuild users   31 Sep 23 12:42 NAMESPACE
> -rw-r--r-- 1 pkgbuild users  420 Sep 23 12:42 Read-and-delete-me
>
> anRpackage/data:
> total 4
> -rw-r--r-- 1 pkgbuild users 59 Sep 23 12:42 a.rda
>
> anRpackage/man:
> total 8
> -rw-r--r-- 1 pkgbuild users 1051 Sep 23 12:42 anRpackage-package.Rd
> -rw-r--r-- 1 pkgbuild users  503 Sep 23 12:42 a.Rd
>
> These warnings did not appear with an earlier version of R-patched (r63824).
>
> Thanks,
> Dan
>
>
>
>> sessionInfo()
> R version 3.0.2 RC (2013-09-17 r63944)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From eric.malitz at gmail.com  Mon Sep 23 23:57:17 2013
From: eric.malitz at gmail.com (Eric Malitz)
Date: Mon, 23 Sep 2013 16:57:17 -0500
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com> <523AA11E.2050805@stats.ox.ac.uk>
	<5240B27A.10207@prodsyse.com>
	<A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>
Message-ID: <CAJVuBM=-NiphVa17Q9BYe5Ao_1gdKq1+v+LcMOhDrPKQiTgsfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130923/7ff1bafe/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Sep 24 00:01:15 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 23 Sep 2013 17:01:15 -0500
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <CAJVuBM=-NiphVa17Q9BYe5Ao_1gdKq1+v+LcMOhDrPKQiTgsfQ@mail.gmail.com>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com> <523AA11E.2050805@stats.ox.ac.uk>
	<5240B27A.10207@prodsyse.com>
	<A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>
	<CAJVuBM=-NiphVa17Q9BYe5Ao_1gdKq1+v+LcMOhDrPKQiTgsfQ@mail.gmail.com>
Message-ID: <CAPPM_gR_sQyrQJLZ=86ORF2oNUdGtwX=y78Lam+5vB3F-v1bew@mail.gmail.com>

As Berend Hasselman already told you, "Then surf to the address given
at the end of each posting; go to the bottom of that page and follow
the instructions for unsubscribing."

Here's the link, so you don't have to scroll to the bottom of this
message: https://stat.ethz.ch/mailman/listinfo/r-devel
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Mon, Sep 23, 2013 at 4:57 PM, Eric Malitz <eric.malitz at gmail.com> wrote:
> take me off here
>
>
> On Mon, Sep 23, 2013 at 4:44 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> Spencer,
>>
>> FYI. I just noted in your post below the error message from WriteXLS
>> regarding TEXT::CSV_XS missing.
>>
>> Please note that in version >=3.0 of WriteXLS (current is 3.2.1), that is
>> no longer required and has been replaced by Text::CSV_PP, which is a Pure
>> Perl module and is included in the WriteXLS CRAN package to reduce the
>> dependencies on nonstandard external Perl modules.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>> On Sep 23, 2013, at 4:28 PM, Spencer Graves <spencer.graves at prodsyse.com>
>> wrote:
>>
>> > Hello, All:
>> >
>> >
>> >      Professor Ripley is correct as usual:  I misunderstood his original
>> statement of the problem.
>> >
>> >
>> >      He gave two possible solutions.  I could not make the first
>> solution work, and I didn't try the second until someone else on this list
>> explained it in slightly more detail.
>> >
>> >
>> >      The correction passed R CMD check on my local computer.  It has
>> been "building" on R-Forge since 2013-09-20 19:19:14+02.  I hope this
>> completes soon enough for me to meet Ripley's Sept. 25 deadline for this
>> correction to "sos".
>> >
>> >
>> >      Thanks again to Prof. Ripley and everyone else who took the time to
>> read my post.
>> >
>> >
>> >      Spencer
>> >
>> >
>> > On 9/19/2013 12:00 AM, Prof Brian Ripley wrote:
>> >> This is nothing to do with CRAN policies (nor R).
>> >>
>> >> The issue is that the current upquote.sty does not play with 'ae' fonts
>> as used by default by Sweave.  The change is in TeX.
>> >>
>> >> And that was what Spencer Graves was informed.
>> >>
>> >>
>> >> On 19/09/2013 04:35, Spencer Graves wrote:
>> >>> Hello, All:
>> >>>
>> >>>
>> >>>       The vignette with the sos package used "upquote.sty", required
>> >>> for R Journal when it was published in 2009.  Current CRAN policy
>> >>> disallows "upquote.sty", and I've so far not found a way to pass "R CMD
>> >>> check" with sos without upquote.sty.
>> >>>
>> >>>
>> >>>       I changed sos.Rnw per an email exchange with Prof. Ripley without
>> >>> solving the problem; see below.  The key error messages (see the
>> results
>> >>> of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error:
>> >>> Environment article undefined" and " sos.tex:558: LaTeX Error:
>> >>> \begin{document} ended by \end{article}."  When the article worked, it
>> >>> had bot \begin{document} and \begin{article}, with matching \end
>> >>> statements for both.  I've tried commenting out either without success.
>> >>>
>> >>>
>> >>>       The current nonworking code is available on R-Forge via anonymous
>> >>> SVN checkout using "svn checkout
>> >>> svn://svn.r-forge.r-project.org/svnroot/rsitesearch/". Any suggestions
>> >>> on how to fix this would be greatly appreciated.
>> >>>
>> >>>
>> >>>        Thanks,
>> >>>        Spencer
>> >>>
>> >>>
>> >>> ###### COMPLETE RESULTS FROM R CMD check ########
>> >>>
>> >>>
>> >>> Microsoft Windows [Version 6.1.7600]
>> >>> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>> >>>
>> >>> C:\Users\sgraves>cd 2013
>> >>> C:\Users\sgraves\2013>cd R_pkgs
>> >>> C:\Users\sgraves\2013\R_pkgs>cd sos
>> >>> C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
>> >>> C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
>> >>> * checking for file 'sos/DESCRIPTION' ... OK
>> >>> * preparing 'sos':
>> >>> * checking DESCRIPTION meta-information ... OK
>> >>> * installing the package to re-build vignettes
>> >>> * creating vignettes ... ERROR
>> >>> Loading required package: brew
>> >>>
>> >>> Attaching package: 'sos'
>> >>>
>> >>> The following object is masked from 'package:utils':
>> >>>
>> >>>      ?
>> >>>
>> >>> Loading required package: WriteXLS
>> >>> Perl found.
>> >>>
>> >>> The following Perl modules were not found on this system:
>> >>>
>> >>> Text::CSV_XS
>> >>>
>> >>> If you have more than one Perl installation, be sure the correct one
>> was
>> >>> used he
>> >>> re.
>> >>>
>> >>> Otherwise, please install the missing modules. See the package INSTALL
>> >>> file for
>> >>> more information.
>> >>>
>> >>> Loading required package: RODBC
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>> >>> Rolf Turner
>> >>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>> >>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van
>> Liesho
>> >>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>> >>> Waagepetersen.
>> >>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>> >>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R.
>> Bivan
>> >>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang;
>> J.B.
>> >>> Che
>> >>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F.
>> Co
>> >>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>> >>> P.J. Dig
>> >>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>> >>> Funwi-Gabga;
>> >>>          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>> >>>   P. Graba
>> >>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>> >>> Herin
>> >>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R.
>> Ihaka
>> >>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>> >>> Kuhn;
>> >>>          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>> >>> J. Lee;
>> >>>          G.P. Leser; [... truncated]
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>> >>> Bates [ct
>> >>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>> >>> Gregor Gorja
>> >>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>> >>> Laboissiere [ctb
>> >>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>> >>> Ripley [
>> >>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>> >>> column 'Autho
>> >>> r'
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>> >>> Ash [ctb],
>> >>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>> >>> Andy Cha
>> >>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar
>> Karimi
>> >>> Pour [c
>> >>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>> >>> Uwe Ligg
>> >>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>> >>> [ctb], Dunc
>> >>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>> >>> [ctb], Mi
>> >>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>> >>> 'Author'
>> >>>
>> >>> Perl found.
>> >>>
>> >>> The following Perl modules were not found on this system:
>> >>>
>> >>> Text::CSV_XS
>> >>>
>> >>> If you have more than one Perl installation, be sure the correct one
>> was
>> >>> used he
>> >>> re.
>> >>>
>> >>> Otherwise, please install the missing modules. See the package INSTALL
>> >>> file for
>> >>> more information.
>> >>>
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>> >>> Rolf Turner
>> >>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>> >>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van
>> Liesho
>> >>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>> >>> Waagepetersen.
>> >>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>> >>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R.
>> Bivan
>> >>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang;
>> J.B.
>> >>> Che
>> >>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F.
>> Co
>> >>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>> >>> P.J. Dig
>> >>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>> >>> Funwi-Gabga;
>> >>>          A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>> >>>   P. Graba
>> >>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>> >>> Herin
>> >>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R.
>> Ihaka
>> >>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>> >>> Kuhn;
>> >>>          J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>> >>> J. Lee;
>> >>>          G.P. Leser; [... truncated]
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>> >>> Bates [ct
>> >>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>> >>> Gregor Gorja
>> >>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>> >>> Laboissiere [ctb
>> >>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>> >>> Ripley [
>> >>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>> >>> column 'Autho
>> >>> r'
>> >>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test =
>> test,  :
>> >>>    character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>> >>> Ash [ctb],
>> >>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>> >>> Andy Cha
>> >>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar
>> Karimi
>> >>> Pour [c
>> >>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>> >>> Uwe Ligg
>> >>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>> >>> [ctb], Dunc
>> >>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>> >>> [ctb], Mi
>> >>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>> >>> 'Author'
>> >>>
>> >>> Warning: running command
>> >>> '"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
>> >>> et --pdf "sos.tex"  -I
>> >>> "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
>> >>> I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status
>> 1
>> >>> Error: running 'texi2dvi' on 'sos.tex' failed
>> >>>
>> >>> LaTeX errors:
>> >>> sos.tex:16: LaTeX Error: Environment article undefined.
>> >>>
>> >>> See the LaTeX manual or LaTeX Companion for explanation.
>> >>> Type  H <return>  for immediate help
>> >>> Your command was ignored.
>> >>> sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.
>> >>>
>> >>> See the LaTeX manual or LaTeX Companion for explanation.
>> >>> Type  H <return>  for immediate help
>> >>> Your command was ignored.
>> >>> Execution halted
>> >>>
>> >>>
>> >>> On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
>> >>>> On 13/09/2013 08:30, Spencer Graves wrote:
>> >>>>> Dear Prof. Ripley:
>> >>>>>
>> >>>>>
>> >>>>>       What do you recommend I do with the vignette that comes with
>> that
>> >>>>> package?
>> >>>>>
>> >>>>>
>> >>>>>       That vignette is a copy of the article published in the R
>> Journal
>> >>>>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>> >>>>> RJournal.sty.  When I removed RJournal.sty from the vignette
>> >>>>> subdirectory, "R CMD build" failed.  I have no idea what you want me
>> to
>> >>>>> do to fix this problem.  Further assistance would be appreciated.
>> >>>>
>> >>>> Don't spam all the other addressees!
>> >>>>
>> >>>> The issue is using RJournal.sty in a vignette with ae fonts. I am
>> >>>> guessing that
>> >>>>
>> >>>> \usepackage[noae]{Sweave}
>> >>>>
>> >>>> might work: otherwise you need to remove the reference to upquote.sty
>> >>>> in RJournal.sty.
>> >>>>
>> >>>>
>> >>>>>
>> >>>>>
>> >>>>>       Thanks,
>> >>>>>       Spencer Graves
>> >>>>>
>> >>>>>
>> >>>>> p.s.  I understand reasonably well R and the *.Rd documentation
>> >>>>> standard, thanks in part to your book on "Modern Applied Statistics
>> with
>> >>>>> S" and the documentation that ships with R. However, this is the only
>> >>>>> vignette I've written, and I have not used LaTeX much for anything
>> else
>> >>>>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>> >>>>> with R and Matlab (Springer).
>> >>>>>
>> >>>>>
>> >>>>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>> >>>>>> Brian,
>> >>>>>> I am making changes, downloading new version of Sweave.sty and
>> >>>>>> upquote.sty. However, it is not clear to me how to properly credit
>> >>>>>> Fritz Leisch and others for Sweave. Do you mean in the sweave
>> document
>> >>>>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>> >>>>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>> >>>>>> find anything about this in "Writing R Extensions".
>> >>>>>> Thanks for any guidance,
>> >>>>>> Brian
>> >>>>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>> >>>>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>> >>>>>>> upquote.sty in earlier versions of R and not that currently being
>> >>>>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>> >>>>>>> version of upquote.sty.
>> >>>>>>>
>> >>>>>>> In particular, they do not work with the 'ae' fonts which are the
>> >>>>>>> default for Sweave vignettes.   Packages
>> >>>>>>>
>> >>>>>>> boolfun calibrate popReconstruct qtlnet
>> >>>>>>>
>> >>>>>>> have copies in vignettes and now fail.
>> >>>>>>>
>> >>>>>>> Please remove them. Note too that you did not comply with the CRAN
>> >>>>>>> policies on giving credit by including them in your package but not
>> >>>>>>> crediting their authors: do check very carefully that there are no
>> >>>>>>> other missing credits.
>> >>>>>>>
>> >>>>>>> Package PSM has vignettes which include upquote.sty.
>> >>>>>>>
>> >>>>>>> Packages makeR and sos include RJournal.sty which includes
>> >>>>>>> upquote.sty: same problem.
>> >>>>>>>
>> >>>>>>> Please update your package as soon as possible and definitely
>> before
>> >>>>>>> the release of 3.0.2 on Sept 25.
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Tue Sep 24 00:02:19 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 23 Sep 2013 15:02:19 -0700 (PDT)
Subject: [Rd] tar warnings in R-3.0.2 RC when R is installed by a
 different (non-root) user
In-Reply-To: <5240B844.1080701@stats.ox.ac.uk>
Message-ID: <11859479.880715.1379973739174.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> To: r-devel at r-project.org
> Sent: Monday, September 23, 2013 2:53:08 PM
> Subject: Re: [Rd] tar warnings in R-3.0.2 RC when R is installed by a different (non-root) user
> 
> The issue is not the ownership (uname) but the uid.  A tarball can
> only
> store uids up to 'nobody' (usually 32767), and certainly larger ones
> cannot be unpacked portably.
> 

Thanks. I've changed the uid of this user and the warnings went away.
Dan


> The warnings did not occur before, but the tarball produced could
> cause
> problems when unpacking with other tools.
> 
> On 23/09/2013 20:55, Dan Tenenbaum wrote:
> > Hi,
> >
> > I created a package as follows:
> >
> >> a = 1
> >> package.skeleton()
> >
> > Then I got the following output when building the package:
> >
> > * checking for file ?anRpackage/DESCRIPTION? ... OK
> > * preparing ?anRpackage?:
> > * checking DESCRIPTION meta-information ... OK
> > * checking for LF line-endings in source and make files
> > * checking for empty or unneeded directories
> > * looking to see if a ?data/datalist? file should be added
> > * building ?anRpackage_1.0.tar.gz?
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> > Warning: invalid uid value replaced by that for user 'nobody'
> >
> > One thing to note is that I am logged in as 'pkgbuild' and R was
> > installed by the user 'biocbuild'. I explicitly point to the R
> > that was installed by 'biocbuild' when building the package above.
> > (I used the command "~biocbuild/bbs-2.13-bioc/R/bin/R CMD build
> > anRpackage").
> >
> > There doesn't seem to be anything wrong with the ownership of the
> > files in anRpackage:
> >
> > $ ls -lR anRpackage
> > anRpackage:
> > total 20
> > drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 data
> > -rw-r--r-- 1 pkgbuild users  283 Sep 23 12:42 DESCRIPTION
> > drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 man
> > -rw-r--r-- 1 pkgbuild users   31 Sep 23 12:42 NAMESPACE
> > -rw-r--r-- 1 pkgbuild users  420 Sep 23 12:42 Read-and-delete-me
> >
> > anRpackage/data:
> > total 4
> > -rw-r--r-- 1 pkgbuild users 59 Sep 23 12:42 a.rda
> >
> > anRpackage/man:
> > total 8
> > -rw-r--r-- 1 pkgbuild users 1051 Sep 23 12:42 anRpackage-package.Rd
> > -rw-r--r-- 1 pkgbuild users  503 Sep 23 12:42 a.Rd
> >
> > These warnings did not appear with an earlier version of R-patched
> > (r63824).
> >
> > Thanks,
> > Dan
> >
> >
> >
> >> sessionInfo()
> > R version 3.0.2 RC (2013-09-17 r63944)
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > locale:
> >   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> >   base
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From spencer.graves at prodsyse.com  Tue Sep 24 00:04:02 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 23 Sep 2013 15:04:02 -0700
Subject: [Rd] Vignette problem and CRAN policies
In-Reply-To: <A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>
References: <522D7285.8030205@stats.ox.ac.uk> <522E469C.2030902@stat.wisc.edu>
	<5232BEFA.8090308@prodsyse.com> <5232C11A.7070705@stats.ox.ac.uk>
	<523A70F3.4030805@prodsyse.com>
	<523AA11E.2050805@stats.ox.ac.uk> <5240B27A.10207@prodsyse.com>
	<A47334DB-484B-42A3-9094-B363CDFF55F2@me.com>
Message-ID: <5240BAD2.8030607@prodsyse.com>

Hi, Marc:


       That's great.  I just did update.packages, then tried 
"writeFindFn2xls", and it worked!  "writeFindFn2xls" is programmed to 
try WriteXLS.  Previously, it failed on my 64-bit installation of R, 
because of that very problem.


       I was planning to modify "writeFindFn2xls" to try 
write.xlsx{xlsx}.  I think I'll not bother with that now.


       Thanks again.


       Spencer


On 9/23/2013 2:44 PM, Marc Schwartz wrote:
> Spencer,
>
> FYI. I just noted in your post below the error message from WriteXLS regarding TEXT::CSV_XS missing.
>
> Please note that in version >=3.0 of WriteXLS (current is 3.2.1), that is no longer required and has been replaced by Text::CSV_PP, which is a Pure Perl module and is included in the WriteXLS CRAN package to reduce the dependencies on nonstandard external Perl modules.
>
> Regards,
>
> Marc Schwartz
>
>
> On Sep 23, 2013, at 4:28 PM, Spencer Graves <spencer.graves at prodsyse.com> wrote:
>
>> Hello, All:
>>
>>
>>       Professor Ripley is correct as usual:  I misunderstood his original statement of the problem.
>>
>>
>>       He gave two possible solutions.  I could not make the first solution work, and I didn't try the second until someone else on this list explained it in slightly more detail.
>>
>>
>>       The correction passed R CMD check on my local computer.  It has been "building" on R-Forge since 2013-09-20 19:19:14+02.  I hope this completes soon enough for me to meet Ripley's Sept. 25 deadline for this correction to "sos".
>>
>>
>>       Thanks again to Prof. Ripley and everyone else who took the time to read my post.
>>
>>
>>       Spencer
>>
>>
>> On 9/19/2013 12:00 AM, Prof Brian Ripley wrote:
>>> This is nothing to do with CRAN policies (nor R).
>>>
>>> The issue is that the current upquote.sty does not play with 'ae' fonts as used by default by Sweave.  The change is in TeX.
>>>
>>> And that was what Spencer Graves was informed.
>>>
>>>
>>> On 19/09/2013 04:35, Spencer Graves wrote:
>>>> Hello, All:
>>>>
>>>>
>>>>        The vignette with the sos package used "upquote.sty", required
>>>> for R Journal when it was published in 2009.  Current CRAN policy
>>>> disallows "upquote.sty", and I've so far not found a way to pass "R CMD
>>>> check" with sos without upquote.sty.
>>>>
>>>>
>>>>        I changed sos.Rnw per an email exchange with Prof. Ripley without
>>>> solving the problem; see below.  The key error messages (see the results
>>>> of "R CMD build" below) appear to be "sos.tex:16: LaTeX Error:
>>>> Environment article undefined" and " sos.tex:558: LaTeX Error:
>>>> \begin{document} ended by \end{article}."  When the article worked, it
>>>> had bot \begin{document} and \begin{article}, with matching \end
>>>> statements for both.  I've tried commenting out either without success.
>>>>
>>>>
>>>>        The current nonworking code is available on R-Forge via anonymous
>>>> SVN checkout using "svn checkout
>>>> svn://svn.r-forge.r-project.org/svnroot/rsitesearch/". Any suggestions
>>>> on how to fix this would be greatly appreciated.
>>>>
>>>>
>>>>         Thanks,
>>>>         Spencer
>>>>
>>>>
>>>> ###### COMPLETE RESULTS FROM R CMD check ########
>>>>
>>>>
>>>> Microsoft Windows [Version 6.1.7600]
>>>> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>>>>
>>>> C:\Users\sgraves>cd 2013
>>>> C:\Users\sgraves\2013>cd R_pkgs
>>>> C:\Users\sgraves\2013\R_pkgs>cd sos
>>>> C:\Users\sgraves\2013\R_pkgs\sos>cd pkg
>>>> C:\Users\sgraves\2013\R_pkgs\sos\pkg>R CMD build sos
>>>> * checking for file 'sos/DESCRIPTION' ... OK
>>>> * preparing 'sos':
>>>> * checking DESCRIPTION meta-information ... OK
>>>> * installing the package to re-build vignettes
>>>> * creating vignettes ... ERROR
>>>> Loading required package: brew
>>>>
>>>> Attaching package: 'sos'
>>>>
>>>> The following object is masked from 'package:utils':
>>>>
>>>>       ?
>>>>
>>>> Loading required package: WriteXLS
>>>> Perl found.
>>>>
>>>> The following Perl modules were not found on this system:
>>>>
>>>> Text::CSV_XS
>>>>
>>>> If you have more than one Perl installation, be sure the correct one was
>>>> used he
>>>> re.
>>>>
>>>> Otherwise, please install the missing modules. See the package INSTALL
>>>> file for
>>>> more information.
>>>>
>>>> Loading required package: RODBC
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>>>> Rolf Turner
>>>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>>>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
>>>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>>>> Waagepetersen.
>>>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>>>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>>>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>>>> Che
>>>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>>>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>>>> P.J. Dig
>>>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>>>> Funwi-Gabga;
>>>>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>>>    P. Graba
>>>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>>>> Herin
>>>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
>>>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>>>> Kuhn;
>>>>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>>>> J. Lee;
>>>>           G.P. Leser; [... truncated]
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>>>> Bates [ct
>>>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>>>> Gregor Gorja
>>>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>>>> Laboissiere [ctb
>>>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>>>> Ripley [
>>>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>>>> column 'Autho
>>>> r'
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>>>> Ash [ctb],
>>>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>>>> Andy Cha
>>>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>>>> Pour [c
>>>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>>>> Uwe Ligg
>>>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>>>> [ctb], Dunc
>>>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>>>> [ctb], Mi
>>>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>>>> 'Author'
>>>>
>>>> Perl found.
>>>>
>>>> The following Perl modules were not found on this system:
>>>>
>>>> Text::CSV_XS
>>>>
>>>> If you have more than one Perl installation, be sure the correct one was
>>>> used he
>>>> re.
>>>>
>>>> Otherwise, please install the missing modules. See the package INSTALL
>>>> file for
>>>> more information.
>>>>
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'Adrian Baddeley <Adrian.Baddeley at uwa.edu.au> and
>>>> Rolf Turner
>>>> <r.turner at auckland.ac.nz> with substantial contributions of code by
>>>> Kasper Klitgaard Berthelsen;    Abdollah Jalilian; Marie-Colette van Liesho
>>>> ut;     Ege Rubak;      Dominic Schuhmacher;    and     Rasmus
>>>> Waagepetersen.
>>>> Additional contributions        by Q.W. Ang;    S. Azaele; C. Beale;
>>>> R. Bernhardt;   T. Bendtsen;    A. Bevan;       B. Biggerstaff; R. Bivan
>>>> d;      F. Bonneu;      J. Burgos;      S. Byers;       Y.M. Chang; J.B.
>>>> Che
>>>> n;      I. Chernayavsky;        Y.C. Chin;      B. Christensen; J.-F. Co
>>>> eurjolly;       R. Corria Ainslie;      M. de la Cruz;  P. Dalgaard;
>>>> P.J. Dig
>>>> gle;    P. Donnelly;    I. Dryden;      S. Eglen; O. Flores; N.
>>>> Funwi-Gabga;
>>>>           A. Gault;       M. Genton;      J. Gilbey;      J. Goldstick;
>>>>    P. Graba
>>>> rnik;   C. Graf;        J. Franklin;    U. Hahn;        A. Hardegen; M.
>>>> Herin
>>>> g;      M.B. Hansen;    M. Hazelton;    J. Heikkinen;   K. Hornik; R. Ihaka
>>>> ;       A. Jammalamadaka;       R. John-Chandran;       D. Johnson; M.
>>>> Kuhn;
>>>>           J. Laake;       F. Lavancier;   T. Lawrence;    R.A. Lamb;
>>>> J. Lee;
>>>>           G.P. Leser; [... truncated]
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'John Fox [aut, cre], Sanford Weisberg [aut], Douglas
>>>> Bates [ct
>>>> b], Steve Ellison [ctb], David Firth [ctb], Michael Friendly [ctb],
>>>> Gregor Gorja
>>>> nc [ctb], Spencer Graves [ctb], Richard Heiberger [ctb], Rafael
>>>> Laboissiere [ctb
>>>> ], Georges Monette [ctb], Henric Nilsson [ctb], Derek Ogle [ctb], Brian
>>>> Ripley [
>>>> ctb], Achim Zeileis [ctb], R-Core [ctb]' truncated to 255 bytes in
>>>> column 'Autho
>>>> r'
>>>> Warning in odbcUpdate(channel, query, mydata, coldata[m, ], test = test,  :
>>>>     character data 'John Fox [aut, cre], Liviu Andronic [ctb], Michael
>>>> Ash [ctb],
>>>> Milan Bouchet-Valat [ctb], Theophilius Boye [ctb], Stefano Calza [ctb],
>>>> Andy Cha
>>>> ng [ctb], Philippe Grosjean [ctb], Richard Heiberger [ctb], Kosar Karimi
>>>> Pour [c
>>>> tb], G. Jay Kerns [ctb], Renaud Lancelot [ctb], Matthieu Lesnoff [ctb],
>>>> Uwe Ligg
>>>> es [ctb], Samir Messad [ctb], Martin Maechler [ctb], Robert Muenchen
>>>> [ctb], Dunc
>>>> an Murdoch [ctb], Erich Neuwirth [ctb], Dan Putler [ctb], Brian Ripley
>>>> [ctb], Mi
>>>> roslav Ristic [ctb], Peter Wolf [ctb]' truncated to 255 bytes in column
>>>> 'Author'
>>>>
>>>> Warning: running command
>>>> '"C:\PROGRA~2\MIKTEX~1.9\miktex\bin\texi2dvi.exe" --qui
>>>> et --pdf "sos.tex"  -I
>>>> "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/tex/latex" -
>>>> I "C:/Users/sgraves/pgms/R/R-3.0.1/share/texmf/bibtex/bst"' had status 1
>>>> Error: running 'texi2dvi' on 'sos.tex' failed
>>>>
>>>> LaTeX errors:
>>>> sos.tex:16: LaTeX Error: Environment article undefined.
>>>>
>>>> See the LaTeX manual or LaTeX Companion for explanation.
>>>> Type  H <return>  for immediate help
>>>> Your command was ignored.
>>>> sos.tex:558: LaTeX Error: \begin{document} ended by \end{article}.
>>>>
>>>> See the LaTeX manual or LaTeX Companion for explanation.
>>>> Type  H <return>  for immediate help
>>>> Your command was ignored.
>>>> Execution halted
>>>>
>>>>
>>>> On 9/13/2013 12:39 AM, Prof Brian Ripley wrote:
>>>>> On 13/09/2013 08:30, Spencer Graves wrote:
>>>>>> Dear Prof. Ripley:
>>>>>>
>>>>>>
>>>>>>        What do you recommend I do with the vignette that comes with that
>>>>>> package?
>>>>>>
>>>>>>
>>>>>>        That vignette is a copy of the article published in the R Journal
>>>>>> vol. 1/2, Dec. 2009.  That publication seemed to require me to use
>>>>>> RJournal.sty.  When I removed RJournal.sty from the vignette
>>>>>> subdirectory, "R CMD build" failed.  I have no idea what you want me to
>>>>>> do to fix this problem.  Further assistance would be appreciated.
>>>>> Don't spam all the other addressees!
>>>>>
>>>>> The issue is using RJournal.sty in a vignette with ae fonts. I am
>>>>> guessing that
>>>>>
>>>>> \usepackage[noae]{Sweave}
>>>>>
>>>>> might work: otherwise you need to remove the reference to upquote.sty
>>>>> in RJournal.sty.
>>>>>
>>>>>
>>>>>>
>>>>>>        Thanks,
>>>>>>        Spencer Graves
>>>>>>
>>>>>>
>>>>>> p.s.  I understand reasonably well R and the *.Rd documentation
>>>>>> standard, thanks in part to your book on "Modern Applied Statistics with
>>>>>> S" and the documentation that ships with R. However, this is the only
>>>>>> vignette I've written, and I have not used LaTeX much for anything else
>>>>>> apart from Ramsay, Hooker and Graves (2009) Functional Data Analysis
>>>>>> with R and Matlab (Springer).
>>>>>>
>>>>>>
>>>>>> On 9/9/2013 3:07 PM, Brian S Yandell wrote:
>>>>>>> Brian,
>>>>>>> I am making changes, downloading new version of Sweave.sty and
>>>>>>> upquote.sty. However, it is not clear to me how to properly credit
>>>>>>> Fritz Leisch and others for Sweave. Do you mean in the sweave document
>>>>>>> (*.Rnw)? Or is there a place in the package assembly for this? (it
>>>>>>> seems not in DESCRIPTION or CITATION, but where else). I could not
>>>>>>> find anything about this in "Writing R Extensions".
>>>>>>> Thanks for any guidance,
>>>>>>> Brian
>>>>>>> On 9/9/13 12:02 AM, Prof Brian Ripley wrote:
>>>>>>>> Earlier versions of Sweave.sty and Rd.sty only work with the
>>>>>>>> upquote.sty in earlier versions of R and not that currently being
>>>>>>>> distributed in TeX distributions. R >= 3.0.2 will not contain any
>>>>>>>> version of upquote.sty.
>>>>>>>>
>>>>>>>> In particular, they do not work with the 'ae' fonts which are the
>>>>>>>> default for Sweave vignettes.   Packages
>>>>>>>>
>>>>>>>> boolfun calibrate popReconstruct qtlnet
>>>>>>>>
>>>>>>>> have copies in vignettes and now fail.
>>>>>>>>
>>>>>>>> Please remove them. Note too that you did not comply with the CRAN
>>>>>>>> policies on giving credit by including them in your package but not
>>>>>>>> crediting their authors: do check very carefully that there are no
>>>>>>>> other missing credits.
>>>>>>>>
>>>>>>>> Package PSM has vignettes which include upquote.sty.
>>>>>>>>
>>>>>>>> Packages makeR and sos include RJournal.sty which includes
>>>>>>>> upquote.sty: same problem.
>>>>>>>>
>>>>>>>> Please update your package as soon as possible and definitely before
>>>>>>>> the release of 3.0.2 on Sept 25.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From simon.urbanek at r-project.org  Tue Sep 24 00:34:14 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 24 Sep 2013 00:34:14 +0200
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <5240A280.1000804@gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
Message-ID: <F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>

Duncan,

On Sep 23, 2013, at 10:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-09-23 2:17 PM, Jeroen Ooms wrote:
>> Is there any way to capture output (both stdout and stderr) from
>> install.packages? Solutions like sink and capture.output don't work
>> because the install.packages calls out to system2 which is executed in
>> a separate process:
>> 
>>     test <- capture.output(install.packages("MASS"))
>> 
>> The system2 function does have arguments stdout and stderr but afaik
>> these cannot be controlled via install.packages. I'm a bit reluctant
>> to start rolling my own version of install.packages just for this
>> reason.
>> 
>> Is there any way to somehow grab this output? Or alternatively, is
>> there a way to make R pipe stdout and stderr from system2 in such a
>> way that they can be captured with sink or capture.output in the R
>> parent process?
> 
> See the recent thread <https://mailman.stat.ethz.ch/pipermail/r-devel/2013-September/067552.html> for an approach to this.
> 

Can you, please, elaborate on how it is that relevant? The linked thread is talking about sink() which it irrelevant here (to quote the original e-mail "Solutions like sink and capture.output don't work because the install.packages calls out to system2 which is executed in a separate process:"). Something I missed?

Re original question: there is keep_outputs which allows to re-direct a copy of the output into a file - at least for the actual install part of it. 
On top of my head for full capture I can only think of custom C code that will re-direct stderr/out FDs as desired (it's really trivial to re-direct to files, for dynamic capture it's a little more involved but there are examples that do that).

Cheers,
Simon


From murdoch.duncan at gmail.com  Tue Sep 24 00:50:32 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Sep 2013 18:50:32 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
Message-ID: <5240C5B8.4030301@gmail.com>

On 13-09-23 6:34 PM, Simon Urbanek wrote:
> Duncan,
>
> On Sep 23, 2013, at 10:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 13-09-23 2:17 PM, Jeroen Ooms wrote:
>>> Is there any way to capture output (both stdout and stderr) from
>>> install.packages? Solutions like sink and capture.output don't work
>>> because the install.packages calls out to system2 which is executed in
>>> a separate process:
>>>
>>>      test <- capture.output(install.packages("MASS"))
>>>
>>> The system2 function does have arguments stdout and stderr but afaik
>>> these cannot be controlled via install.packages. I'm a bit reluctant
>>> to start rolling my own version of install.packages just for this
>>> reason.
>>>
>>> Is there any way to somehow grab this output? Or alternatively, is
>>> there a way to make R pipe stdout and stderr from system2 in such a
>>> way that they can be captured with sink or capture.output in the R
>>> parent process?
>>
>> See the recent thread <https://mailman.stat.ethz.ch/pipermail/r-devel/2013-September/067552.html> for an approach to this.
>>
>
> Can you, please, elaborate on how it is that relevant? The linked thread is talking about sink() which it irrelevant here (to quote the original e-mail "Solutions like sink and capture.output don't work because the install.packages calls out to system2 which is executed in a separate process:"). Something I missed?

Brian Ripley's reply describes how it is done in the tools package.  For 
example, as I sent privately to Jeroen,

x <- system2("Rscript", "-e \"install.packages('MASS',
repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)

captures all of the output from installing MASS.  As Jeroen pointed out, 
that isn't identical to running install.packages() in the current 
session; a real version of it should fill in more of the arguments, not 
leave them at their defaults.

Duncan Murdoch



> Re original question: there is keep_outputs which allows to re-direct a copy of the output into a file - at least for the actual install part of it.
> On top of my head for full capture I can only think of custom C code that will re-direct stderr/out FDs as desired (it's really trivial to re-direct to files, for dynamic capture it's a little more involved but there are examples that do that).
>
> Cheers,
> Simon
>
>


From murray at stokely.org  Tue Sep 24 02:18:30 2013
From: murray at stokely.org (Murray Stokely)
Date: Mon, 23 Sep 2013 17:18:30 -0700
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>
References: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>
	<537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>
Message-ID: <CAECWziJa6AcyETHvySnuO5rYFXXrCrcXS9zGdFRov5wsDUj2wA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130923/4d73b6d7/attachment.pl>

From h.wickham at gmail.com  Tue Sep 24 02:20:25 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 23 Sep 2013 19:20:25 -0500
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <5240C5B8.4030301@gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
	<5240C5B8.4030301@gmail.com>
Message-ID: <CABdHhvFmgvADrBJui5=+MjgOOGrjERcipxpiNd2tNP+P_vicDQ@mail.gmail.com>

> Brian Ripley's reply describes how it is done in the tools package.  For
> example, as I sent privately to Jeroen,
>
> x <- system2("Rscript", "-e \"install.packages('MASS',
> repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)
>
> captures all of the output from installing MASS.  As Jeroen pointed out,
> that isn't identical to running install.packages() in the current session; a
> real version of it should fill in more of the arguments, not leave them at
> their defaults.

It does seems a little crazy that you're in a R process, then open
another one, which then opens a 3rd session! (often indirectly by
calling R CMD install which then calls an internal function in tools)

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From pgilbert902 at gmail.com  Tue Sep 24 03:03:33 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 23 Sep 2013 21:03:33 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <CABdHhvFmgvADrBJui5=+MjgOOGrjERcipxpiNd2tNP+P_vicDQ@mail.gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
	<5240C5B8.4030301@gmail.com>
	<CABdHhvFmgvADrBJui5=+MjgOOGrjERcipxpiNd2tNP+P_vicDQ@mail.gmail.com>
Message-ID: <5240E4E5.7030905@gmail.com>


On 13-09-23 08:20 PM, Hadley Wickham wrote:
>> Brian Ripley's reply describes how it is done in the tools package.  For
>> example, as I sent privately to Jeroen,
>>
>> x <- system2("Rscript", "-e \"install.packages('MASS',
>> repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)
>>
>> captures all of the output from installing MASS.  As Jeroen pointed out,
>> that isn't identical to running install.packages() in the current session; a
>> real version of it should fill in more of the arguments, not leave them at
>> their defaults.
>
> It does seems a little crazy that you're in a R process, then open
> another one, which then opens a 3rd session! (often indirectly by
> calling R CMD install which then calls an internal function in tools)

It does seem very much more straight forward to do this in the process 
above R:

   R --vanilla --slave -e "install.packages('whatever',
    repo='http://cran.r-project.org')" >R.out  2>&1

(Omit mailer wrap.) Your mileage may vary depending on your OS.

Paul

>
> Hadley
>


From paul at stat.auckland.ac.nz  Tue Sep 24 04:43:49 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 24 Sep 2013 14:43:49 +1200
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
In-Reply-To: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>
References: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>
Message-ID: <5240FC65.3080402@stat.auckland.ac.nz>

Hi

If you want an explicit background (rather than just relying on what the 
device gives you), you can do something like ...

par(bg="white")
plot(1:10)
recplot = recordPlot()
png("bgreplay.png")
replayPlot(recplot)
dev.off()

Would that satisfy your use case ?

Paul

On 09/14/13 09:17, Gabriel Becker wrote:
> Hey all,
>
> I've run accross what seems to be a bug in the recordPlot/replayPlot
> functionality (or at least the lack of a feature which seems pretty
> reasonable to expect to be there)
>
> When drawing to a file-based graphics device (I tested with png()), the
> file resulting from calling replayPlot on a recordedplot object does not
> contain an identical image to that captured by the same graphics device
> when used on the plot that was recorded.
>
> Reproducible (at least for me on linux) example:
>
> png("noreplay.png")
> plot(1:10)
> dev.off()
>
> plot(1:10)
> recplot = recordPlot()
> png("withreplay.png")
> replayPlot(recplot)
> dev.off()
>
> The resulting png files are attached. You'll notice that the noreplay.png
> has the expected white background, while withoutreplay.png has no/a
> transparent background.
>
> This seems likely to be related to the note in ?dev.print :
> "
>   Note that these functions copy the _device region_ and not a plot:
>       the background colour of the device surface is part of what is
>       copied.  Most screen devices default to a transparent background,
>       which is probably not what is needed when copying to a device such
>       as ?png?.
> "
>
> Now this may be as intended because it is "not allowed" to draw
> recordedplot objects to devices other than the one they were recorded on
> (AFAIK the primary purpose of recordedplot objects is fast redraws
> internally), but alas that is what my use-case calls for. Furthermore,  I
> don't think I'm alone in thinking wistfully about how useful it would be to
> have an actual, transportable object class which can fully represent an R
> plot in any R-based context.
>
> I'm pretty sure I can compile a patch which does this if it would be
> considered, though there would be a delay of a week or two before I could
> burrow out from under the mound of other stuff I currently need to be doing
>
> sessionInfo below, and I have also confirmed that the behavior remains
> unchanged in the current trunk.
>
> Thanks,
> ~G
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.0.1 tools_3.0.1
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From paul at stat.auckland.ac.nz  Tue Sep 24 05:04:45 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 24 Sep 2013 15:04:45 +1200
Subject: [Rd] Patch: fix segfault from empty raster
In-Reply-To: <24E99AB65531B7489F15EFF58F1273070147F306@xchmbbal506.ds.susq.com>
References: <24E99AB65531B7489F15EFF58F1273070147F306@xchmbbal506.ds.susq.com>
Message-ID: <5241014D.30506@stat.auckland.ac.nz>

Hi

Protecting against empty rasters seems like a good idea(!)
Thanks for the report.

Could you please try sending me your suggested patch directly?
(it did not make it through via r-devel)

Paul

On 09/16/13 22:24, QRD wrote:
> Hi,
>
> A colleague recently came across an R crash, which I can boil down to
> the following, running under Rgui on Windows 7:
>
> library(ggplot2)
> ggplot(data.frame(x=1, y=1, z=4.7), aes(x, y, z=z)) + stat_summary2d()
>
> This reliably causes a segmentation fault.  sessionInfo() below.
>
> What's happening is that (for reasons which I'll discuss with the
> ggplot2 developers) the 'colorbar' guide is being built with a zero-size
> source raster.
>
> In L_raster() (grid.c), this raster is not a "nativeRaster", so we do
>
>      image = (unsigned int*) R_alloc(n, sizeof(unsigned int));
>
> with n = 0, and R_alloc() gives us a NULL pointer.
>
> The display of this raster requests interpolation, so we end up in
> R_GE_rasterInterpolate(), where 'sraster' is NULL, and chaos ensues as
> it tries to read source pixels.
>
> It seems to me that it doesn't make sense to display an empty raster, so
> I inserted a check in L_raster().  A proof-of-concept patch is attached.
> With this patch, R gives an error message instead of a segfault.
>
> Does this seem a sensible change?  If so, could something like it be
> incorporated?
>
> Thanks,
>
> Ben.
>
> - - - - 8< - - - -
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_Ireland.1252  LC_CTYPE=English_Ireland.1252
> [3] LC_MONETARY=English_Ireland.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Ireland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ggplot2_0.9.3.1
>
> loaded via a namespace (and not attached):
>   [1] colorspace_1.2-2   compiler_3.0.1     dichromat_2.0-0    digest_0.6.3
>   [5] grid_3.0.1         gtable_0.1.2       labeling_0.2       MASS_7.3-26
>   [9] munsell_0.4        plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
> [13] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2      tools_3.0.1
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From gmbecker at ucdavis.edu  Tue Sep 24 05:31:58 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 23 Sep 2013 20:31:58 -0700
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
In-Reply-To: <5240FC65.3080402@stat.auckland.ac.nz>
References: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>
	<5240FC65.3080402@stat.auckland.ac.nz>
Message-ID: <CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130923/04d99914/attachment.pl>

From eric.malitz at gmail.com  Tue Sep 24 06:42:40 2013
From: eric.malitz at gmail.com (Eric Malitz)
Date: Mon, 23 Sep 2013 23:42:40 -0500
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
In-Reply-To: <CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>
References: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>
	<5240FC65.3080402@stat.auckland.ac.nz>
	<CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>
Message-ID: <CAJVuBMmyxZxaF7jmbwTcjjd6Az02H2HWEKVyL6xX=aBUQB5Ppg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130923/f0dbe99a/attachment.pl>

From hpages at fhcrc.org  Tue Sep 24 07:13:38 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 23 Sep 2013 22:13:38 -0700
Subject: [Rd] library(c("stats4")) produces a misleading error message
Message-ID: <52411F82.2090903@fhcrc.org>

Hi,

This error message is very confusing/misleading for novice users:

   > library(c("stats4"))
   Error in library(c("stats4")) : 'package' must be of length 1

Could it please be improved to mention something about using
'character.only=TRUE' instead?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Tue Sep 24 12:42:10 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 24 Sep 2013 12:42:10 +0200
Subject: [Rd] regenerate Rscript after moving R installation
In-Reply-To: <CAECWziJa6AcyETHvySnuO5rYFXXrCrcXS9zGdFRov5wsDUj2wA@mail.gmail.com>
References: <145722967.1797.1379789012433.JavaMail.zimbra@openanalytics.eu>
	<B83BFFA0-422C-44C4-AD25-3714AA7B754B@r-project.org>
	<537AE145-2367-4EA3-B7EA-7A8417B9A4BE@r-project.org>
	<CAECWziJa6AcyETHvySnuO5rYFXXrCrcXS9zGdFRov5wsDUj2wA@mail.gmail.com>
Message-ID: <71D205E1-82EF-455F-973A-4B677E487E5D@r-project.org>

Murray,

On Sep 24, 2013, at 2:18 AM, Murray Stokely <murray at stokely.org> wrote:

> Simon, do you have some examples of packages with this attribute?

As Brian pointed out, some of them concern linking (I'm typically worried about OS X and Dirk has fixed Rcpp there), but there are also others that store package paths in variables or in supplementary files. Others store system paths as well (i.e. you can move R but not any dependent resources). Unfortunately this is hard to detect, because of lazy-loading (all lazy-load files have the paths baked in the namespace, so they will always include the path that you installed to originally) -- one example of a hard-coded variable is race.


>  Removing the hard-coding of paths in base R and Rscript is one of the many local patches we've maintained in the R I use at my workplace since at least the R 2.5 days.  We do this to enable us to send R and all its dependencies off to build farms, unit test clusters, and production clusters for running parallel computations among other use cases where the path of the build server is irrelevant to the server running the R code.
> 
> I don't recall running into any packages where an absolute path from the build host was hard-coded into the package such that we had to update code to get it to work.  But maybe I'm just not using those packages.
> 

It is hard to detect. The linking ones typically fail right away, but those with hard-coded paths inside may fail only in some use cases.

Cheers,
Simon


>               - Murray
> 
> 
> On Sat, Sep 21, 2013 at 6:45 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> I forgot to mention that some packages bake-in paths as well, so even if you fix both R and Rscript, it will still not work in general.
> 
> On Sep 22, 2013, at 3:42 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> > On Sep 21, 2013, at 8:43 PM, Tobias Verbeke <tobias.verbeke at openanalytics.eu> wrote:
> >
> >> L.S.
> >>
> >> In this bug report
> >>
> >> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14493#c1
> >>
> >> it is mentioned that after moving an R installation
> >> one should regenerate the Rscript executable.
> >>
> >> Is there an easy way to do so (after an R installation has been
> >> moved)?
> >>
> >
> > You cannot move installed R. Once you run make install, there are several places in which paths get baked in - mainly Rscript and the R start script. What I typically do for deployment on the Labs machines is to use make install rhome=<xxx> where <xxx> is some path that I can always create a symlink in (I also use DESTDIR so that path doesn't actually need to exist on the build machine and it avoid polluting --prefix which is not needed). That way you can move R wherever you want as long so you keep that one symlink up to date.
> >
> > Cheers,
> > Simon
> >
> >
> >> I have not found any information in the R installation and
> >> administration manual.
> >>
> >> Many thanks in advance for any pointer.
> >>
> >> Best wishes,
> >> Tobias
> >>
> >> P.S. The background to this question is the usage of Rscript
> >> calls in the Makevars files of some R packages on CRAN, so
> >> the 'broken' Rscript prevents installation of certain R packages.
> >>
> >> --
> >>
> >> Tobias Verbeke
> >> Manager
> >>
> >> OpenAnalytics BVBA
> >> Jupiterstraat 20
> >> 2600 Antwerp
> >> Belgium
> >>
> >> E tobias.verbeke at openanalytics.eu
> >> M +32 499 36 33 15
> >> http://www.openanalytics.eu
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From michael.weylandt at gmail.com  Tue Sep 24 13:32:41 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Tue, 24 Sep 2013 07:32:41 -0400
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
In-Reply-To: <CAJVuBMmyxZxaF7jmbwTcjjd6Az02H2HWEKVyL6xX=aBUQB5Ppg@mail.gmail.com>
References: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>
	<5240FC65.3080402@stat.auckland.ac.nz>
	<CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>
	<CAJVuBMmyxZxaF7jmbwTcjjd6Az02H2HWEKVyL6xX=aBUQB5Ppg@mail.gmail.com>
Message-ID: <AF7481E7-1F03-4A05-8DBE-02BC73FCED47@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130924/626e376c/attachment.pl>

From jeroen.ooms at stat.ucla.edu  Tue Sep 24 16:37:27 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 24 Sep 2013 10:37:27 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <5240C5B8.4030301@gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
	<5240C5B8.4030301@gmail.com>
Message-ID: <CABFfbXtv-7r6uupAaW7oMpiyOukv-GHns=qxqAEXFPBN8CCCsQ@mail.gmail.com>

On Mon, Sep 23, 2013 at 6:50 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> x <- system2("Rscript", "-e \"install.packages('MASS',
> repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)

Thank you, this suggestion seems to work (although I agree that
starting 3 procs to install a single package seems suboptimal). One
additional question: is it safe to assume that the "Rscript"
executable can always be found by the R process (cross platform), or
do I need to modify the example in case Rscript is not in the system
search path?


From h.wickham at gmail.com  Tue Sep 24 17:39:56 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 24 Sep 2013 10:39:56 -0500
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <CABFfbXtv-7r6uupAaW7oMpiyOukv-GHns=qxqAEXFPBN8CCCsQ@mail.gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
	<5240C5B8.4030301@gmail.com>
	<CABFfbXtv-7r6uupAaW7oMpiyOukv-GHns=qxqAEXFPBN8CCCsQ@mail.gmail.com>
Message-ID: <CABdHhvGwYBT-PST_fyD6+zms4RNCj_rSWjh24xhSuRa64-6APQ@mail.gmail.com>

You shouldn't assume - use file.path(R.home("bin"), "R")

Hadley

On Tue, Sep 24, 2013 at 9:37 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> On Mon, Sep 23, 2013 at 6:50 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> x <- system2("Rscript", "-e \"install.packages('MASS',
>> repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)
>
> Thank you, this suggestion seems to work (although I agree that
> starting 3 procs to install a single package seems suboptimal). One
> additional question: is it safe to assume that the "Rscript"
> executable can always be found by the R process (cross platform), or
> do I need to modify the example in case Rscript is not in the system
> search path?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From jeroen.ooms at stat.ucla.edu  Tue Sep 24 20:00:42 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 24 Sep 2013 14:00:42 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
Message-ID: <CABFfbXtorSxOrjaxeWFpeuvxPikKdBXxUO=C1JQAWBUcpt0+qQ@mail.gmail.com>

On Mon, Sep 23, 2013 at 6:34 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On top of my head for full capture I can only think of custom C code that will re-direct stderr/out FDs as desired (it's really trivial to re-direct to files, for dynamic capture it's a little more involved but there are examples that do that).

I had secretly been hoping that system2("whoami", stdout=stdout(),
stderr=stderr()) would capture output streams from the child process
and concatenate to stdout() and stderr() in the parent just as if they
were sent by cat("foo", file=stdout()) and cat("bar", file=stderr())
such that they could be captured from sink() in the parent. However
thinking twice about this, it is probably very difficult to implement
without threads. The event loop in the parent process would need to
poll for buffered output in the child while waiting for it to return
or something.


From hb at biostat.ucsf.edu  Tue Sep 24 20:14:45 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 24 Sep 2013 11:14:45 -0700
Subject: [Rd] recordPlot() on non-interactive graphics device?
Message-ID: <CAFDcVCT0P9kHiYkwvYCS03u7CEZd0kd7V00hhtb+-Otb1mVe_Q@mail.gmail.com>

Hi.

Q. Is there a way to record a plot using grDevices::recordPlot()
without opening an interactive (=visible GUI window) graphics device
(not even for a flash of a second)?


Related: help("recordPlot", package="grDevices") says:

"These functions record and replay the displaylist of the current
graphics device."

Is the intention that recordPlot() should be able to record from _any
type_ of graphics device, or only for _interactive_ ones?   For
instance,

windows(); plot(1:10); g <- recordPlot(); dev.off();
x11(); plot(1:10); g <- recordPlot(); dev.off();
Cairo::CairoWin(); plot(1:10); g <- recordPlot(); dev.off();

all produce 'recordplot' objects that replot the figure with
replayPlot(g), whereas for instance

png("foo.png"); plot(1:10); g <- recordPlot(); dev.off();
pdf("foo.pdf"); plot(1:10); g <- recordPlot(); dev.off();

produce "empty" replayPlot(g) outputs.

Q. It it just a coincident that it appear that
recordPlot()/replayPlot() only works for
grDevices::deviceIsInteractive() graphics devices?  If not, should
?recordPlot clarify that "These functions record and replay the
displaylist of the current [interactive] graphics device."?

Q. ...or is just the fact that currently png(), pdf() etc. won't
populate "the displaylist" (whatever that is), but if they would, then
recordPlot()/replayPlot() would indeed generate an non-empty plot?  If
so, a note like "Note, recordPlot() will often record an empty plot on
non-interactive graphics devices as they do not populate the
displaylist." may be add to the help.


Thanks,

Henrik


From gmbecker at ucdavis.edu  Tue Sep 24 20:25:56 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 24 Sep 2013 11:25:56 -0700
Subject: [Rd] recordPlot() on non-interactive graphics device?
In-Reply-To: <CAFDcVCT0P9kHiYkwvYCS03u7CEZd0kd7V00hhtb+-Otb1mVe_Q@mail.gmail.com>
References: <CAFDcVCT0P9kHiYkwvYCS03u7CEZd0kd7V00hhtb+-Otb1mVe_Q@mail.gmail.com>
Message-ID: <CADwqtCNPm4txdYdngabr7WcsFNh7-O=oFPgCGhgFaEQUSLNEAQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130924/ee591676/attachment.pl>

From gmbecker at ucdavis.edu  Tue Sep 24 20:43:45 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 24 Sep 2013 11:43:45 -0700
Subject: [Rd] recordPlot() on non-interactive graphics device?
In-Reply-To: <CADwqtCNPm4txdYdngabr7WcsFNh7-O=oFPgCGhgFaEQUSLNEAQ@mail.gmail.com>
References: <CAFDcVCT0P9kHiYkwvYCS03u7CEZd0kd7V00hhtb+-Otb1mVe_Q@mail.gmail.com>
	<CADwqtCNPm4txdYdngabr7WcsFNh7-O=oFPgCGhgFaEQUSLNEAQ@mail.gmail.com>
Message-ID: <CADwqtCOFhr1MedUgZFHKoL8Fo77Fqqum7ENCyEXEuJbvGsQknQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130924/0fbb2da8/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 24 21:30:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Sep 2013 15:30:31 -0400
Subject: [Rd] Capture output of install.packages (pipe system2)
In-Reply-To: <CABFfbXtv-7r6uupAaW7oMpiyOukv-GHns=qxqAEXFPBN8CCCsQ@mail.gmail.com>
References: <CABFfbXtWhc48KviWCQXR84xGywm1GU0oMWk1Vk7s0EqbcAfT5g@mail.gmail.com>
	<5240A280.1000804@gmail.com>
	<F165061B-F2DF-47CF-898F-920DC27C0DF7@r-project.org>
	<5240C5B8.4030301@gmail.com>
	<CABFfbXtv-7r6uupAaW7oMpiyOukv-GHns=qxqAEXFPBN8CCCsQ@mail.gmail.com>
Message-ID: <5241E857.70000@gmail.com>

On 13-09-24 10:37 AM, Jeroen Ooms wrote:
> On Mon, Sep 23, 2013 at 6:50 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> x <- system2("Rscript", "-e \"install.packages('MASS',
>> repos='http://probability.ca/cran')\"", stdout=TRUE, stderr=TRUE)
>
> Thank you, this suggestion seems to work (although I agree that
> starting 3 procs to install a single package seems suboptimal).


For something that I only do every few weeks or months, I'd rather 
optimize the use of the programmer's time than that of the processor.  I 
get paid more per hour!

Duncan Murdoch

  One
> additional question: is it safe to assume that the "Rscript"
> executable can always be found by the R process (cross platform), or
> do I need to modify the example in case Rscript is not in the system
> search path?
>


From hb at biostat.ucsf.edu  Tue Sep 24 21:52:34 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 24 Sep 2013 12:52:34 -0700
Subject: [Rd] recordPlot() on non-interactive graphics device?
In-Reply-To: <CADwqtCOFhr1MedUgZFHKoL8Fo77Fqqum7ENCyEXEuJbvGsQknQ@mail.gmail.com>
References: <CAFDcVCT0P9kHiYkwvYCS03u7CEZd0kd7V00hhtb+-Otb1mVe_Q@mail.gmail.com>
	<CADwqtCNPm4txdYdngabr7WcsFNh7-O=oFPgCGhgFaEQUSLNEAQ@mail.gmail.com>
	<CADwqtCOFhr1MedUgZFHKoL8Fo77Fqqum7ENCyEXEuJbvGsQknQ@mail.gmail.com>
Message-ID: <CAFDcVCSk1WWh037ff9uLLVdFnryxELr6OEestZmE1-FRJ_Y4qQ@mail.gmail.com>

Thanks Gabriel.  It works - I did not know about dev.control() and its
help page clearly says that "Initially recording is on for screen
devices, and off for print devices".

I've submitted a patch (PR#15472) for adding a "see also" linking to
dev.control():

Bug 15472 - PATCH: Adding see also link for help("recordPlot",
package="grDevices")
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15472

/Henrik

On Tue, Sep 24, 2013 at 11:43 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> To be a little less terse:
>
> I agree that notes/discussion about what recordPlot/replayPlot do when there
> is no display list and that non-interactive devices don't create a
> displaylist by default but can be instructed to do so via dev.control (at
> least some, I don't claim to have checked them all) would probably be
> helpful, as well as a see also link to dev.control.
>
> ~G
>
>
>
> On Tue, Sep 24, 2013 at 11:25 AM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
>>
>> Henrik,
>>
>> This works for me:
>>
>> > png("test.png")
>> > dev.control(displaylist="enable")
>> > plot(1:10)
>> > rp = recordPlot()
>> > dev.off()
>> X11cairo
>>        2
>> > rp
>>
>> HTH,
>> ~G
>>
>> sessionInfo():
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=C                 LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.1
>>
>>
>>
>> On Tue, Sep 24, 2013 at 11:14 AM, Henrik Bengtsson <hb at biostat.ucsf.edu>
>> wrote:
>>>
>>> Hi.
>>>
>>> Q. Is there a way to record a plot using grDevices::recordPlot()
>>> without opening an interactive (=visible GUI window) graphics device
>>> (not even for a flash of a second)?
>>>
>>>
>>> Related: help("recordPlot", package="grDevices") says:
>>>
>>> "These functions record and replay the displaylist of the current
>>> graphics device."
>>>
>>> Is the intention that recordPlot() should be able to record from _any
>>> type_ of graphics device, or only for _interactive_ ones?   For
>>> instance,
>>>
>>> windows(); plot(1:10); g <- recordPlot(); dev.off();
>>> x11(); plot(1:10); g <- recordPlot(); dev.off();
>>> Cairo::CairoWin(); plot(1:10); g <- recordPlot(); dev.off();
>>>
>>> all produce 'recordplot' objects that replot the figure with
>>> replayPlot(g), whereas for instance
>>>
>>> png("foo.png"); plot(1:10); g <- recordPlot(); dev.off();
>>> pdf("foo.pdf"); plot(1:10); g <- recordPlot(); dev.off();
>>>
>>> produce "empty" replayPlot(g) outputs.
>>>
>>> Q. It it just a coincident that it appear that
>>> recordPlot()/replayPlot() only works for
>>> grDevices::deviceIsInteractive() graphics devices?  If not, should
>>> ?recordPlot clarify that "These functions record and replay the
>>> displaylist of the current [interactive] graphics device."?
>>>
>>> Q. ...or is just the fact that currently png(), pdf() etc. won't
>>> populate "the displaylist" (whatever that is), but if they would, then
>>> recordPlot()/replayPlot() would indeed generate an non-empty plot?  If
>>> so, a note like "Note, recordPlot() will often record an empty plot on
>>> non-interactive graphics devices as they do not populate the
>>> displaylist." may be add to the help.
>>>
>>>
>>> Thanks,
>>>
>>> Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>> --
>> Gabriel Becker
>> Graduate Student
>> Statistics Department
>> University of California, Davis
>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From paul at stat.auckland.ac.nz  Wed Sep 25 02:32:27 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 25 Sep 2013 12:32:27 +1200
Subject: [Rd] inconsistency/bug in recordPlot/replayPlot
In-Reply-To: <CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>
References: <CADwqtCNcmxc6XUjjJxcdz91aOKWe-z4vtqhUrxRs_9wQnwcgQw@mail.gmail.com>	<5240FC65.3080402@stat.auckland.ac.nz>
	<CADwqtCNPu1LR4Q2rmYQJahNqt828_xbT0ZxBVB3qEavO6picxA@mail.gmail.com>
Message-ID: <52422F1B.8070301@stat.auckland.ac.nz>

Hi

Unfortunately, my main advice would be not to rely on recordPlot() 
because it (or at least the underlying display list format) was never 
intended for this sort of thing.  I doubt that helps though :)

I might be able to help more, or look at developing a "transportable 
object class for R graphics", if I had a better understanding of what 
you want to do.  Perhaps off list?

Paul

On 09/24/13 15:31, Gabriel Becker wrote:
> Paul,
>
> Thanks for the response.
>
>
> On Mon, Sep 23, 2013 at 7:43 PM, Paul Murrell <paul at stat.auckland.ac.nz
> <mailto:paul at stat.auckland.ac.nz>> wrote:
>
>     <snip>
>     par(bg="white")
>
>     plot(1:10)
>     recplot = recordPlot()
>     png("bgreplay.png")
>     replayPlot(recplot)
>     dev.off()
>
>     Would that satisfy your use case ?
>
>
> Unfortunately it does not, as my use-case is in a caching/dynamic
> document setting. Thus I am capturing plotting from evaluation of an
> arbitrary piece of code within a series of such evaluations. I cannot be
> guaranteed the code doesn't call dev.off() or explicitly create a new
> device and I wouldn't want to clobber any non-white background set in
> previous code.
>
> I thought putting par(bg="white") after the call to png() (or bg="white"
> in the png call) might work, but it appears that replayPlot is actively
> setting the background to transparent so that didn't fly.
>
> Any other ideas or advice would be appreciated.
> ~G
>
>
>     Paul
>
>
>     On 09/14/13 09:17, Gabriel Becker wrote:
>
>         Hey all,
>
>         I've run accross what seems to be a bug in the recordPlot/replayPlot
>         functionality (or at least the lack of a feature which seems pretty
>         reasonable to expect to be there)
>
>         When drawing to a file-based graphics device (I tested with
>         png()), the
>         file resulting from calling replayPlot on a recordedplot object
>         does not
>         contain an identical image to that captured by the same graphics
>         device
>         when used on the plot that was recorded.
>
>         Reproducible (at least for me on linux) example:
>
>         png("noreplay.png")
>         plot(1:10)
>         dev.off()
>
>         plot(1:10)
>         recplot = recordPlot()
>         png("withreplay.png")
>         replayPlot(recplot)
>         dev.off()
>
>         The resulting png files are attached. You'll notice that the
>         noreplay.png
>         has the expected white background, while withoutreplay.png has no/a
>         transparent background.
>
>         This seems likely to be related to the note in ?dev.print :
>         "
>            Note that these functions copy the _device region_ and not a
>         plot:
>                the background colour of the device surface is part of
>         what is
>                copied.  Most screen devices default to a transparent
>         background,
>                which is probably not what is needed when copying to a
>         device such
>                as ?png?.
>         "
>
>         Now this may be as intended because it is "not allowed" to draw
>         recordedplot objects to devices other than the one they were
>         recorded on
>         (AFAIK the primary purpose of recordedplot objects is fast redraws
>         internally), but alas that is what my use-case calls for.
>         Furthermore,  I
>         don't think I'm alone in thinking wistfully about how useful it
>         would be to
>         have an actual, transportable object class which can fully
>         represent an R
>         plot in any R-based context.
>
>         I'm pretty sure I can compile a patch which does this if it would be
>         considered, though there would be a delay of a week or two
>         before I could
>         burrow out from under the mound of other stuff I currently need
>         to be doing
>
>         sessionInfo below, and I have also confirmed that the behavior
>         remains
>         unchanged in the current trunk.
>
>         Thanks,
>         ~G
>
>             sessionInfo()
>
>         R version 3.0.1 (2013-05-16)
>         Platform: x86_64-pc-linux-gnu (64-bit)
>
>         locale:
>            [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>            [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>            [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>            [7] LC_PAPER=C                 LC_NAME=C
>            [9] LC_ADDRESS=C               LC_TELEPHONE=C
>         [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>         attached base packages:
>         [1] stats     graphics  grDevices utils     datasets  methods   base
>
>         loaded via a namespace (and not attached):
>         [1] compiler_3.0.1 tools_3.0.1
>
>
>
>         ________________________________________________
>         R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-devel
>         <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>
>     --
>     Dr Paul Murrell
>     Department of Statistics
>     The University of Auckland
>     Private Bag 92019
>     Auckland
>     New Zealand
>     64 9 3737599 x85392
>     paul at stat.auckland.ac.nz <mailto:paul at stat.auckland.ac.nz>
>     http://www.stat.auckland.ac.__nz/~paul/
>     <http://www.stat.auckland.ac.nz/~paul/>
>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ripley at stats.ox.ac.uk  Wed Sep 25 10:28:31 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Sep 2013 09:28:31 +0100
Subject: [Rd] R 3.0.2 and LaTeX changes
Message-ID: <52429EAF.9080109@stats.ox.ac.uk>

R 3.0.2 has some changes to work (or work better) with current versions 
of LaTeX style files: this can cause problems for those with older versions.

So the main message is to update your TeX system: all of TeXLive 2013, 
MacTeX 2013 and MiKTeX 2.9 work as expected if up-to-date.


1) In around June the inconsolata package was changed, a lot, and 
changed again in July.  For older versions things appear to work but it 
has been reported recently that in some cases single quotes are silently 
omitted from the PDF file.  To work around this incompatibility, update 
the inconsolata package.  If you cannot do that for your LaTeX 
distribution, you should be able to do so for your own account:

- download the current package from 
http://mirrors.ctan.org/systems/texlive/tlnet/archive/inconsolata.tar.xz

- locate your personal texmf directory by

kpsewhich -var-value=TEXMFHOME

usually ~/texmf (and it may need to be created) and cd there.

- install the current version by something like

tar xf inconsolata.tar.xz

or use untar('inconsolata.tar.xz') in R;

(if there is an ls-R file in that directory, run

mktexlsr .

) then

updmap --enable Map=zi4.map

Alternatively, set environment variable R_RD4PDF to an option such as 
times,beramono,hyper or times,hyper . See
http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Making-the-manuals


2) R used to contain a very old upquote.sty file, but this has been 
removed.  If you have LaTeX style files which refer to upquote.sty or 
use it directly in your package, you may need to remove the usage as 
some recent versions conflict with the ae fonts (the default for 
Sweave).  In particular, remove any old copies of Sweave.sty.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mdowle at mdowle.plus.com  Fri Sep 27 02:48:01 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Fri, 27 Sep 2013 01:48:01 +0100
Subject: [Rd] SET_NAMED in getattrib0
Message-ID: <5244D5C1.7000307@mdowle.plus.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130927/3e32666d/attachment.pl>

From svenetration at gmail.com  Fri Sep 27 03:13:37 2013
From: svenetration at gmail.com (Ron Goldman)
Date: Thu, 26 Sep 2013 21:13:37 -0400
Subject: [Rd] LENGTH function causing name conflict
Message-ID: <CAD-akqMtrO_5UruK_PCwFPS2-JUyPuBE_ON74wic-00311D1nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130926/0dbad251/attachment.pl>

From peter.langfelder at gmail.com  Fri Sep 27 23:04:20 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 27 Sep 2013 14:04:20 -0700
Subject: [Rd] Problems when moving to Imports from Depends
Message-ID: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>

Hi all,

one of my packages uses the rcorr.cens function from the Hmisc
package. Until now I have simply put the Hmisc package into Depends:,
but prodded on by new CRAN requirements, I tried to moving it into
Imports:. However, this fails because rcorr.cens calls the function
is.Surv from survival, which does not seem to be on the search path
when Hmisc is "imported from" rather then being "depended on". (Hmisc
both Depends: on and Imports: from survival, which is a bit confusing
and discouraged by Writing R extensions.)

Do I need to include an explicit dependency on or import from
survival? Or should I leave Hmisc in the "Depends: " field? Apologies
if this is a trivial question - I am not versed in R internals and
couldn't find the answer in the Writing R extensions manual either.

Thanks,

Peter


From edd at debian.org  Fri Sep 27 23:25:50 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Sep 2013 16:25:50 -0500
Subject: [Rd] LENGTH function causing name conflict
In-Reply-To: <CAD-akqMtrO_5UruK_PCwFPS2-JUyPuBE_ON74wic-00311D1nw@mail.gmail.com>
References: <CAD-akqMtrO_5UruK_PCwFPS2-JUyPuBE_ON74wic-00311D1nw@mail.gmail.com>
Message-ID: <21061.63454.995630.754708@max.nulle.part>


On 26 September 2013 at 21:13, Ron Goldman wrote:
| I am attempting to bring R-3.0.2 functionality into a project with a very
| large C++ codebase.  The existing codebase already has a LENGTH function
| defined.  R also defines a LENGTH function.
| 
| I first compiled R as a shared library and linked it into this existing
| codebase, along with RInside. When I run a parseEvalQ with a linear model
| command it will stack dump.  Looking at the backtrace, what is happening is
| that line 51 of lm.c is executing:
| 
| if(n) ny = LENGTH(y)/n;  /* n x ny, or a vector */
| 
| However, the LENGTH call is getting routed into our internal codebase.
|  This causes a stack dump.
| 
| I then tried compiling R as a static library.  After that I couldn't even
| compile my existing code because it flags the issue right off the bat:
| 
| ... error: declaration of C function 'int LENGTH(const ... *)' conflicts
| with
| ... /r/lib64/R/include/Rinternals.h:435: error: previous declaration 'int
| LENGTH(SEXPREC*)' here
| 
| It is not possible to remove/rename the LENGTH function from the existing
| codebase.  Any help would be appreciated in resolving this.

This got discussed a number of times over the years over on the rcpp-devel
list.  The common fixes are


 i)  make sure you define R_NO_REMAP (as our headers do). The Fine Manual says:

	  This remapping can cause problems(1), and can be eliminated by
        defining `R_NO_REMAP' and prepending `Rf_' to _all_ the function names
        used from `Rinternals.h' and `R_ext/Error.h'.

 ii) reordering of headers may help

In sum, and quoting from RcppCommon.h

// include R headers, but set R_NO_REMAP and access everything via Rf_ prefixes
#define R_NO_REMAP
#include <R.h>


Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From kasperdanielhansen at gmail.com  Fri Sep 27 23:50:58 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 27 Sep 2013 23:50:58 +0200
Subject: [Rd] Problems when moving to Imports from Depends
In-Reply-To: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>
References: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>
Message-ID: <CAC2h7uuC2OUNcPeu8ia_omstOqUu-tyZJcMqWVjsZTSkntVFfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130927/d03392b8/attachment.pl>

From peter.langfelder at gmail.com  Sat Sep 28 00:05:59 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 27 Sep 2013 15:05:59 -0700
Subject: [Rd] Problems when moving to Imports from Depends
In-Reply-To: <CAC2h7uuC2OUNcPeu8ia_omstOqUu-tyZJcMqWVjsZTSkntVFfw@mail.gmail.com>
References: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>
	<CAC2h7uuC2OUNcPeu8ia_omstOqUu-tyZJcMqWVjsZTSkntVFfw@mail.gmail.com>
Message-ID: <CA+hbrhUDCEh5EOt8QA_cbOcHcw-+00Qfg7A0cUKuXqt9FOj04A@mail.gmail.com>

On Fri, Sep 27, 2013 at 2:50 PM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
> Peter,
>
> This is a relatively "new" warning from R CMD check (for some definition of
> new).  The authors of Hmisc have clearly not yet gone through the process of
> cleaning it up, as you are doing right now (and there are many other
> packages that still need to address this, including several of mine).  Given
> who the authors are of Hmisc, I would suggest writing to them and ask them
> to look into this, and ask for a time estimate.

thanks for the suggestion, but I must be missing something: since
Hmisc imports survival (as well as Depends: on it), what can Hmisc
change to make the survival functionality visible to my package?

>
> In the meantime, you may have to do something about this, and whatever you
> do I would suggest following the Hmisc package and undo it as soon as
> possible, as the right thing is to fix Hmisc.  Having said that, it is not
> clear to me that you can easily solve this yourself, because I don't think
> that putting survival into your own imports will make the package available
> to Hmisc functions, but it is not impossible there is some way around it.

Well, as I said, things work fine if I leave Hmisc in the Depends:
field, which, however, is against CRAN policy. The trouble is that I
don't have a good way of checking whether something breaks by moving a
package from Depends into Imports...

Peter


From kasperdanielhansen at gmail.com  Sat Sep 28 00:23:14 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Sat, 28 Sep 2013 00:23:14 +0200
Subject: [Rd] Problems when moving to Imports from Depends
In-Reply-To: <CA+hbrhUDCEh5EOt8QA_cbOcHcw-+00Qfg7A0cUKuXqt9FOj04A@mail.gmail.com>
References: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>
	<CAC2h7uuC2OUNcPeu8ia_omstOqUu-tyZJcMqWVjsZTSkntVFfw@mail.gmail.com>
	<CA+hbrhUDCEh5EOt8QA_cbOcHcw-+00Qfg7A0cUKuXqt9FOj04A@mail.gmail.com>
Message-ID: <CAC2h7utDeGzK2+_J90LFbdMsbnark40nXSOOdg-dYwXb+zF+Rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130928/6e63949b/attachment.pl>

From pgilbert902 at gmail.com  Sat Sep 28 00:36:13 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 27 Sep 2013 18:36:13 -0400
Subject: [Rd] Problems when moving to Imports from Depends
In-Reply-To: <CA+hbrhUDCEh5EOt8QA_cbOcHcw-+00Qfg7A0cUKuXqt9FOj04A@mail.gmail.com>
References: <CA+hbrhUVTj7Y6X-yEjbPL5whbyHzgs4tapEr7k4Lv3H+Zya1GQ@mail.gmail.com>
	<CAC2h7uuC2OUNcPeu8ia_omstOqUu-tyZJcMqWVjsZTSkntVFfw@mail.gmail.com>
	<CA+hbrhUDCEh5EOt8QA_cbOcHcw-+00Qfg7A0cUKuXqt9FOj04A@mail.gmail.com>
Message-ID: <5246085D.3000202@gmail.com>



On 13-09-27 06:05 PM, Peter Langfelder wrote:
> On Fri, Sep 27, 2013 at 2:50 PM, Kasper Daniel Hansen
> <kasperdanielhansen at gmail.com> wrote:
>> Peter,
>>
>> This is a relatively "new" warning from R CMD check (for some definition of
>> new).  The authors of Hmisc have clearly not yet gone through the process of
>> cleaning it up, as you are doing right now (and there are many other
>> packages that still need to address this, including several of mine).  Given
>> who the authors are of Hmisc, I would suggest writing to them and ask them
>> to look into this, and ask for a time estimate.
>
> thanks for the suggestion, but I must be missing something: since
> Hmisc imports survival (as well as Depends: on it), what can Hmisc
> change to make the survival functionality visible to my package?

The terminology around "imports" has had many of us confused. (My copy 
of) Hmisc has survival in both Imports: and Depends: in the DESCRIPTION 
file (for which they will now be getting flagged) but it does not have 
it in the NAMSPACE file, which it needs, whether it is in Depends: or 
Imports: (and for which they are getting another flag). When this is 
fixed then the Hmisc function rcorr.cens will look at its own NAMSPACE 
determined path for finding functions, and find is.Surv. As Kasper 
pointed out, this is not really your problem, except of course that you 
need to work around the Hmisc problem. Until Hmisc is fixed, I think you 
have the option of adding survival to Depends:, or leaving Hmisc in 
Depends:. (I would be inclined to leave it the way you had it until 
packages further down the chain are fixed.)

Paul

>
>>
>> In the meantime, you may have to do something about this, and whatever you
>> do I would suggest following the Hmisc package and undo it as soon as
>> possible, as the right thing is to fix Hmisc.  Having said that, it is not
>> clear to me that you can easily solve this yourself, because I don't think
>> that putting survival into your own imports will make the package available
>> to Hmisc functions, but it is not impossible there is some way around it.
>
> Well, as I said, things work fine if I leave Hmisc in the Depends:
> field, which, however, is against CRAN policy. The trouble is that I
> don't have a good way of checking whether something breaks by moving a
> package from Depends into Imports...
>
> Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From skostysh at princeton.edu  Sun Sep 29 10:16:10 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sun, 29 Sep 2013 04:16:10 -0400
Subject: [Rd] tools::md5sum(directory) behavior different on Windows vs.
	Unix
In-Reply-To: <CAE3=dmcMRCFCH1hdgLhwdjxQ6J+-UPZXXcpL2Za=99_5WnrtNw@mail.gmail.com>
References: <CAE3=dmcMRCFCH1hdgLhwdjxQ6J+-UPZXXcpL2Za=99_5WnrtNw@mail.gmail.com>
Message-ID: <CAE3=dmckvqEuGASsLUcK3tjJoN0HyVQENdfZYo3zXHqTQHed_w@mail.gmail.com>

On Mon, Sep 9, 2013 at 3:00 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> tools::md5sum gives a warning if it receives a directory as an
> argument on Unix but not on Windows.
>
> From what I understand, this happens because in Windows a directory is
> not treated as a file so fopen returns NULL. Then, NA is returned
> without a warning. On Unix, a directory is treated as a file so fopen
> does not return NULL so md5 is run and fails, leading to a warning.
>
> This is a good opportunity for me to understand further (in addition
> to [1] and the many places where OS special cases are mentioned) in
> which cases R tries to behave the same on Windows as on Unix and in
> which cases it allows for differences (in this case, a warning vs. no
> warning). For example, it would be straightforward to create a patch
> that would lead to the same behavior in this case. tools::md5sum could
> either issue a warning for each argument that is a directory or it
> could issue no warning (consistent with file.info). Would either patch
> be considered?

Attached is a patch that gives a warning if an element in the file
argument is not a regular file (e.g. is a directory or does not
exist). In my opinion the advantages of this patch are:

(1) the same warnings are generated on all platforms in the case where
one of the elements is a folder.
(2) a warning is also given if a file does not exist.

Comments?

Scott

>
> Or is this difference encouraged because the concept of a file is
> different on Unix than on Windows?
>
> Scott
>
> [1] http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What-should-I-expect-to-behave-differently-from-the-Unix-version
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
-------------- next part --------------
Index: trunk/src/library/tools/R/md5.R
===================================================================
--- trunk/src/library/tools/R/md5.R	(revision 64011)
+++ trunk/src/library/tools/R/md5.R	(working copy)
@@ -17,7 +17,18 @@
 #  http://www.r-project.org/Licenses/
 
 md5sum <- function(files)
-    structure(.Call(Rmd5, files), names=files)
+{
+    reg_ <- file_test("-f", files)
+    regFiles <- files[reg_]
+    notReg <- files[!reg_]
+    if(!all(reg_))
+        warning("The following are not regular files: ",
+                paste(shQuote(notReg), collapse = " "))
+    names(files) <- files
+    files[!reg_] <- NA
+    files[reg_] <- .Call(Rmd5, regFiles)
+    files
+}
 
 .installMD5sums <- function(pkgDir, outDir = pkgDir)
 {
Index: trunk/src/library/tools/man/md5sum.Rd
===================================================================
--- trunk/src/library/tools/man/md5sum.Rd	(revision 64011)
+++ trunk/src/library/tools/man/md5sum.Rd	(working copy)
@@ -18,7 +18,8 @@
 \value{
   A character vector of the same length as \code{files}, with names
   equal to \code{files}. The elements
-  will be \code{NA} for non-existent or unreadable files, otherwise
+  will be \code{NA} for non-existent or unreadable files (in which case
+  a warning will be generated), otherwise
   a 32-character string of hexadecimal digits.
 
   On Windows all files are read in binary mode (as the \code{md5sum}

From atp at piskorski.com  Mon Sep 30 05:26:29 2013
From: atp at piskorski.com (Andrew Piskorski)
Date: Sun, 29 Sep 2013 23:26:29 -0400
Subject: [Rd] how to interpose my own "[" function?
Message-ID: <20130930032629.GA52400@piskorski.com>

I want to create my own "[" function (for use on vectors, matrices,
arrays, etc.), which calls the stock R "[", does some additional work,
and then finally returns the modified result.

But, how do I properly call the stock R "[" function?  It takes a
varying number of positional arguments, and its R-level closure is
just:  .Primitive("[")  It's implemented by do_subset_dflt in
src/main/subset.c.

The only thing I've come up with so far is using eval after crudely
re-constructing the original incoming call (example below), which is
both very slow and gets some of the semantics wrong.

Is there some good way for my function to just say, "take ALL my
incoming arguments, whatever they might be, and pass them as-is to
.Primitive('['), then return control to me here"?  Or said another
way, what I want is to hook the end of the R-level "[" function and do
some extra work there before returning to the user.

Basically, where should I look to figure out how to do this?  Is it
even feasible at all when the call I want to intercept is implemented
in C and is Primitive like "[" is?  Is there some other technique I
should be using instead to accomplish this sort of thing?

Thanks for your help!  Example of awful eval-based code follows:


my.subset <- function(x ,i ,j ,... ,drop=TRUE) { 
   brace.fcn <- get("[",pos="package:base") 
   code <- 'brace.fcn(x,' 
   if (!missing(i))    code <- paste(code ,'i' ,sep="") 
   # This fails to distinguish between the mat[1:21] and mat[1:21,] cases: 
   if (length(dim(x)) > 1 && (missing(i) || length(dim(i)) <= 1)) 
      code <- paste(code ,',' ,sep="") 
   if (!missing(j))    code <- paste(code ,'j' ,sep="") 
   if (!missing(...))  code <- paste(code ,',...' ,sep="") 
   if (!missing(drop)) code <- paste(code ,',drop=drop' ,sep="") 
   code <- paste(code ,')' ,sep="") 
   result <- eval(parse(text=code)) 
   # FINALLY we have the stock result, now modify it some more... 
   result 
} 

-- 
Andrew Piskorski <atp at piskorski.com>


From hb at biostat.ucsf.edu  Mon Sep 30 06:02:24 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 29 Sep 2013 21:02:24 -0700
Subject: [Rd] how to interpose my own "[" function?
In-Reply-To: <20130930032629.GA52400@piskorski.com>
References: <20130930032629.GA52400@piskorski.com>
Message-ID: <CAFDcVCQ3-Tn6nO-ckqpPK5zGq3QddrR_2m++xG4s7wm7D4Nsng@mail.gmail.com>

Typically you use NextMethod(), but otherwise you can either "unclass"
your object first or use .subset().  Not sure from ?.subset whether
that is ok to use or not.

/Henrik

On Sun, Sep 29, 2013 at 8:26 PM, Andrew Piskorski <atp at piskorski.com> wrote:
> I want to create my own "[" function (for use on vectors, matrices,
> arrays, etc.), which calls the stock R "[", does some additional work,
> and then finally returns the modified result.
>
> But, how do I properly call the stock R "[" function?  It takes a
> varying number of positional arguments, and its R-level closure is
> just:  .Primitive("[")  It's implemented by do_subset_dflt in
> src/main/subset.c.
>
> The only thing I've come up with so far is using eval after crudely
> re-constructing the original incoming call (example below), which is
> both very slow and gets some of the semantics wrong.
>
> Is there some good way for my function to just say, "take ALL my
> incoming arguments, whatever they might be, and pass them as-is to
> .Primitive('['), then return control to me here"?  Or said another
> way, what I want is to hook the end of the R-level "[" function and do
> some extra work there before returning to the user.
>
> Basically, where should I look to figure out how to do this?  Is it
> even feasible at all when the call I want to intercept is implemented
> in C and is Primitive like "[" is?  Is there some other technique I
> should be using instead to accomplish this sort of thing?
>
> Thanks for your help!  Example of awful eval-based code follows:
>
>
> my.subset <- function(x ,i ,j ,... ,drop=TRUE) {
>    brace.fcn <- get("[",pos="package:base")
>    code <- 'brace.fcn(x,'
>    if (!missing(i))    code <- paste(code ,'i' ,sep="")
>    # This fails to distinguish between the mat[1:21] and mat[1:21,] cases:
>    if (length(dim(x)) > 1 && (missing(i) || length(dim(i)) <= 1))
>       code <- paste(code ,',' ,sep="")
>    if (!missing(j))    code <- paste(code ,'j' ,sep="")
>    if (!missing(...))  code <- paste(code ,',...' ,sep="")
>    if (!missing(drop)) code <- paste(code ,',drop=drop' ,sep="")
>    code <- paste(code ,')' ,sep="")
>    result <- eval(parse(text=code))
>    # FINALLY we have the stock result, now modify it some more...
>    result
> }
>
> --
> Andrew Piskorski <atp at piskorski.com>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nalimilan at club.fr  Mon Sep 30 14:33:23 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 30 Sep 2013 14:33:23 +0200
Subject: [Rd] read.table() with quoted integers
Message-ID: <1380544403.10008.15.camel@milan>

Hi!


It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
quoted integers as an acceptable value for columns for which
colClasses="integer". But when colClasses is omitted, these columns are
read as integer anyway.

For example, let's consider a file named file.dat, containing:
"1"
"2"

> read.table("file.dat", colClasses="integer")
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : 
  scan() expected 'an integer' and got '"1"'

But:
> str(read.table("file.dat"))
'data.frame':	2 obs. of  1 variable:
 $ V1: int  1 2

The latter result is indeed documented in ?read.table:
     Unless ?colClasses? is specified, all columns are read as
     character columns and then converted using ?type.convert? to
     logical, integer, numeric, complex or (depending on ?as.is?)
     factor as appropriate.  Quotes are (by default) interpreted in all
     fields, so a column of values like ?"42"? will result in an
     integer column.


Should the former behavior be considered a bug?

This creates problems when combined with read.table.ffdf from package
ff, since this function tries to guess the column classes by reading the
first rows of the file, and then passes colClasses to read.table to read
the remaining rows by chunks. A column of quoted integers is correctly
detected as integer in the first read, but read.table() fails in
subsequent reads.


Regards


From Thierry.ONKELINX at inbo.be  Mon Sep 30 14:42:43 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 30 Sep 2013 12:42:43 +0000
Subject: [Rd] predictions in nlme without fixed covariantes
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFAED0B1@inbomail.inbo.be>

Dear all,

predict.lme() throws an error when the fixed part consists of only an intercept and using newdata. See the reproducible example below. I've tracked the error down to asOneFormula() which returns in this case NULL instead of a formula. Changing NULL instead of ~1 in that function (see below) solves the problem in the case of an intercept only model (m1). It does not solve the problem in case of a model without intercept nor covariates (m2). The package with altered asOneFormula() passes R CMD check on my machine.

Best regards,

Thierry Onkelinx

library(nlme)
data(Orthodont)
m0 <- lme(distance ~ Sex, random = ~1|Subject, data = Orthodont)
m1 <- lme(distance ~ 1, random = ~1|Subject, data = Orthodont)
m2 <- lme(distance ~ 0, random = ~1|Subject, data = Orthodont)

test.data <- Orthodont

test.data$Fitted <- predict(m0, level = 0)
test.data$Fitted.Newdata <- predict(m0, level = 0, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))

test.data$Fitted <- predict(m0, level = 1)
test.data$Fitted.Newdata <- predict(m0, level = 1, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))

test.data$Fitted <- predict(m1, level = 0)
test.data$Fitted.Newdata <- predict(m1, level = 0, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))

test.data$Fitted <- predict(m1, level = 1)
test.data$Fitted.Newdata <- predict(m1, level = 1, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))

test.data$Fitted <- predict(m2, level = 0)
test.data$Fitted.Newdata <- predict(m2, level = 0, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))

test.data$Fitted <- predict(m2, level = 1)
test.data$Fitted.Newdata <- predict(m2, level = 1, newdata = test.data)
sum(abs(test.data$Fitted - test.data$Fitted.Newdata))



#new version
asOneFormula <-
  ## Constructs a linear formula with all the variables used in a
  ## list of formulas, except for the names in omit
  function(..., omit = c(".", "pi"))
{
  names <- unique(allVarsRec((list(...))))
  names <- names[is.na(match(names, omit))]
  if (length(names)) {
    eval(parse(text = paste("~", paste(names, collapse = "+")))[[1]])
  } else {
    ~ 1 #this was NULL
  }
}



sessionInfo()
R Under development (unstable) (2013-08-24 r63687)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
[5] LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] grid_3.1.0      lattice_0.20-15 tools_3.1.0
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From josh.m.ulrich at gmail.com  Mon Sep 30 15:38:00 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 30 Sep 2013 08:38:00 -0500
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380544403.10008.15.camel@milan>
References: <1380544403.10008.15.camel@milan>
Message-ID: <CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>

On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Hi!
>
>
> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> quoted integers as an acceptable value for columns for which
> colClasses="integer". But when colClasses is omitted, these columns are
> read as integer anyway.
>
> For example, let's consider a file named file.dat, containing:
> "1"
> "2"
>
>> read.table("file.dat", colClasses="integer")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>   scan() expected 'an integer' and got '"1"'
>
> But:
>> str(read.table("file.dat"))
> 'data.frame':   2 obs. of  1 variable:
>  $ V1: int  1 2
>
> The latter result is indeed documented in ?read.table:
>      Unless ?colClasses? is specified, all columns are read as
>      character columns and then converted using ?type.convert? to
>      logical, integer, numeric, complex or (depending on ?as.is?)
>      factor as appropriate.  Quotes are (by default) interpreted in all
>      fields, so a column of values like ?"42"? will result in an
>      integer column.
>
>
> Should the former behavior be considered a bug?
>
No. If you tell read.table the column is integer and it's actually
character on disk, it should be an error.

> This creates problems when combined with read.table.ffdf from package
> ff, since this function tries to guess the column classes by reading the
> first rows of the file, and then passes colClasses to read.table to read
> the remaining rows by chunks. A column of quoted integers is correctly
> detected as integer in the first read, but read.table() fails in
> subsequent reads.
>
This sounds like a issue with read.table.ffdf.  The column of quoted
integers is *incorrectly* detected as integer because they're actually
character on disk.  read.table.ffdf should rely on how the data are
actually stored on disk (via as.is=TRUE), not how read.table might
convert them once they're read into R.

>
> Regards
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From nalimilan at club.fr  Mon Sep 30 16:45:19 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 30 Sep 2013 16:45:19 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
Message-ID: <1380552319.10008.20.camel@milan>

Le lundi 30 septembre 2013 ? 08:38 -0500, Joshua Ulrich a ?crit :
> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > Hi!
> >
> >
> > It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> > quoted integers as an acceptable value for columns for which
> > colClasses="integer". But when colClasses is omitted, these columns are
> > read as integer anyway.
> >
> > For example, let's consider a file named file.dat, containing:
> > "1"
> > "2"
> >
> >> read.table("file.dat", colClasses="integer")
> > Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
> >   scan() expected 'an integer' and got '"1"'
> >
> > But:
> >> str(read.table("file.dat"))
> > 'data.frame':   2 obs. of  1 variable:
> >  $ V1: int  1 2
> >
> > The latter result is indeed documented in ?read.table:
> >      Unless ?colClasses? is specified, all columns are read as
> >      character columns and then converted using ?type.convert? to
> >      logical, integer, numeric, complex or (depending on ?as.is?)
> >      factor as appropriate.  Quotes are (by default) interpreted in all
> >      fields, so a column of values like ?"42"? will result in an
> >      integer column.
> >
> >
> > Should the former behavior be considered a bug?
> >
> No. If you tell read.table the column is integer and it's actually
> character on disk, it should be an error.
All values in a CSV file are stored as characters on disk, disregarding
the fact that they are surrounded by quotes or not. 1 is saved as
00110001 (ASCII character #49), not 00000001, nor 00000000 00000000
00000000 00000001 (as would for example imply a 32 bit storage of
integers).

So, with all due respect, please refrain from formulating such blatantly
erroneous statements.


Regards


> > This creates problems when combined with read.table.ffdf from package
> > ff, since this function tries to guess the column classes by reading the
> > first rows of the file, and then passes colClasses to read.table to read
> > the remaining rows by chunks. A column of quoted integers is correctly
> > detected as integer in the first read, but read.table() fails in
> > subsequent reads.
> >
> This sounds like a issue with read.table.ffdf.  The column of quoted
> integers is *incorrectly* detected as integer because they're actually
> character on disk.  read.table.ffdf should rely on how the data are
> actually stored on disk (via as.is=TRUE), not how read.table might
> convert them once they're read into R.
> 
> >
> > Regards
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Mon Sep 30 17:07:19 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 30 Sep 2013 10:07:19 -0500
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380552319.10008.20.camel@milan>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
Message-ID: <CAPPM_gSM8nTSiCLPU=aPiQky+jUohkOqwPYFQ44UAyAUn83eZg@mail.gmail.com>

On Mon, Sep 30, 2013 at 9:45 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le lundi 30 septembre 2013 ? 08:38 -0500, Joshua Ulrich a ?crit :
>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> > Hi!
>> >
>> >
>> > It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>> > quoted integers as an acceptable value for columns for which
>> > colClasses="integer". But when colClasses is omitted, these columns are
>> > read as integer anyway.
>> >
>> > For example, let's consider a file named file.dat, containing:
>> > "1"
>> > "2"
>> >
>> >> read.table("file.dat", colClasses="integer")
>> > Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>> >   scan() expected 'an integer' and got '"1"'
>> >
>> > But:
>> >> str(read.table("file.dat"))
>> > 'data.frame':   2 obs. of  1 variable:
>> >  $ V1: int  1 2
>> >
>> > The latter result is indeed documented in ?read.table:
>> >      Unless ?colClasses? is specified, all columns are read as
>> >      character columns and then converted using ?type.convert? to
>> >      logical, integer, numeric, complex or (depending on ?as.is?)
>> >      factor as appropriate.  Quotes are (by default) interpreted in all
>> >      fields, so a column of values like ?"42"? will result in an
>> >      integer column.
>> >
>> >
>> > Should the former behavior be considered a bug?
>> >
>> No. If you tell read.table the column is integer and it's actually
>> character on disk, it should be an error.
> All values in a CSV file are stored as characters on disk, disregarding
> the fact that they are surrounded by quotes or not. 1 is saved as
> 00110001 (ASCII character #49), not 00000001, nor 00000000 00000000
> 00000000 00000001 (as would for example imply a 32 bit storage of
> integers).
>
Yes, I'm aware that write.table creates a character representation of
the data on disk.  That's its purpose.  writeBin is for writing actual
binary representations.  I thought you would understand that by
"actually character on disk" I meant "actually a quoted value".  I
assumed you would understand my intent.

read.table uses scan to read the file.  ?scan says:

     The allowed input for a numeric field is optional whitespace
     followed either ?NA? or an optional sign followed by a decimal or
     hexadecimal constant (see NumericConstants), or ?NaN?, ?Inf? or
     ?infinity? (ignoring case).  Out-of-range values are recorded as
     ?Inf?, ?-Inf? or ?0?.

     For an integer field the allowed input is optional whitespace,
     followed by either ?NA? or an optional sign and one or more digits
     (?0-9?): all out-of-range values are converted to ?NA_integer_?.

There's no mention of quotes being allowed.

> So, with all due respect, please refrain from formulating such blatantly
> erroneous statements.
>
So, with all due respect, please refrain from formulating such
blatantly pedantic responses to someone trying to help you.

>
> Regards
>
>
>> > This creates problems when combined with read.table.ffdf from package
>> > ff, since this function tries to guess the column classes by reading the
>> > first rows of the file, and then passes colClasses to read.table to read
>> > the remaining rows by chunks. A column of quoted integers is correctly
>> > detected as integer in the first read, but read.table() fails in
>> > subsequent reads.
>> >
>> This sounds like a issue with read.table.ffdf.  The column of quoted
>> integers is *incorrectly* detected as integer because they're actually
>> character on disk.  read.table.ffdf should rely on how the data are
>> actually stored on disk (via as.is=TRUE), not how read.table might
>> convert them once they're read into R.
>>
>> >
>> > Regards
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>


From jorismeys at gmail.com  Mon Sep 30 17:10:36 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 30 Sep 2013 17:10:36 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380552319.10008.20.camel@milan>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
Message-ID: <CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130930/30ba42f5/attachment.pl>

From nalimilan at club.fr  Mon Sep 30 17:19:47 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 30 Sep 2013 17:19:47 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAPPM_gSM8nTSiCLPU=aPiQky+jUohkOqwPYFQ44UAyAUn83eZg@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAPPM_gSM8nTSiCLPU=aPiQky+jUohkOqwPYFQ44UAyAUn83eZg@mail.gmail.com>
Message-ID: <1380554387.10008.22.camel@milan>

Le lundi 30 septembre 2013 ? 10:07 -0500, Joshua Ulrich a ?crit :
> On Mon, Sep 30, 2013 at 9:45 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > Le lundi 30 septembre 2013 ? 08:38 -0500, Joshua Ulrich a ?crit :
> >> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> >> > Hi!
> >> >
> >> >
> >> > It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> >> > quoted integers as an acceptable value for columns for which
> >> > colClasses="integer". But when colClasses is omitted, these columns are
> >> > read as integer anyway.
> >> >
> >> > For example, let's consider a file named file.dat, containing:
> >> > "1"
> >> > "2"
> >> >
> >> >> read.table("file.dat", colClasses="integer")
> >> > Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
> >> >   scan() expected 'an integer' and got '"1"'
> >> >
> >> > But:
> >> >> str(read.table("file.dat"))
> >> > 'data.frame':   2 obs. of  1 variable:
> >> >  $ V1: int  1 2
> >> >
> >> > The latter result is indeed documented in ?read.table:
> >> >      Unless ?colClasses? is specified, all columns are read as
> >> >      character columns and then converted using ?type.convert? to
> >> >      logical, integer, numeric, complex or (depending on ?as.is?)
> >> >      factor as appropriate.  Quotes are (by default) interpreted in all
> >> >      fields, so a column of values like ?"42"? will result in an
> >> >      integer column.
> >> >
> >> >
> >> > Should the former behavior be considered a bug?
> >> >
> >> No. If you tell read.table the column is integer and it's actually
> >> character on disk, it should be an error.
> > All values in a CSV file are stored as characters on disk, disregarding
> > the fact that they are surrounded by quotes or not. 1 is saved as
> > 00110001 (ASCII character #49), not 00000001, nor 00000000 00000000
> > 00000000 00000001 (as would for example imply a 32 bit storage of
> > integers).
> >
> Yes, I'm aware that write.table creates a character representation of
> the data on disk.  That's its purpose.  writeBin is for writing actual
> binary representations.  I thought you would understand that by
> "actually character on disk" I meant "actually a quoted value".  I
> assumed you would understand my intent.
> 
> read.table uses scan to read the file.  ?scan says:
> 
>      The allowed input for a numeric field is optional whitespace
>      followed either ?NA? or an optional sign followed by a decimal or
>      hexadecimal constant (see NumericConstants), or ?NaN?, ?Inf? or
>      ?infinity? (ignoring case).  Out-of-range values are recorded as
>      ?Inf?, ?-Inf? or ?0?.
> 
>      For an integer field the allowed input is optional whitespace,
>      followed by either ?NA? or an optional sign and one or more digits
>      (?0-9?): all out-of-range values are converted to ?NA_integer_?.
> 
> There's no mention of quotes being allowed.
> 
> > So, with all due respect, please refrain from formulating such blatantly
> > erroneous statements.
> >
> So, with all due respect, please refrain from formulating such
> blatantly pedantic responses to someone trying to help you.
Sorry, your reply came across as quite abrupt for somebody trying to
help. ;-)

And I'm not really looking for help, honestly, as I found a workaround
some time ago already. I'd just like to know how we could make
read.csv.ffdf() work better in this case, and possibly improve R too.


Regards


> >
> > Regards
> >
> >
> >> > This creates problems when combined with read.table.ffdf from package
> >> > ff, since this function tries to guess the column classes by reading the
> >> > first rows of the file, and then passes colClasses to read.table to read
> >> > the remaining rows by chunks. A column of quoted integers is correctly
> >> > detected as integer in the first read, but read.table() fails in
> >> > subsequent reads.
> >> >
> >> This sounds like a issue with read.table.ffdf.  The column of quoted
> >> integers is *incorrectly* detected as integer because they're actually
> >> character on disk.  read.table.ffdf should rely on how the data are
> >> actually stored on disk (via as.is=TRUE), not how read.table might
> >> convert them once they're read into R.
> >>
> >> >
> >> > Regards
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >> --
> >> Joshua Ulrich  |  about.me/joshuaulrich
> >> FOSS Trading  |  www.fosstrading.com
> >


From jorismeys at gmail.com  Mon Sep 30 17:25:37 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 30 Sep 2013 17:25:37 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380554387.10008.22.camel@milan>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAPPM_gSM8nTSiCLPU=aPiQky+jUohkOqwPYFQ44UAyAUn83eZg@mail.gmail.com>
	<1380554387.10008.22.camel@milan>
Message-ID: <CAO1zAVY8mH_BXpDfBCaT6_ZVSjkJAuenA35kbe=5QOzdnCjDtQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130930/4d980210/attachment.pl>

From nalimilan at club.fr  Mon Sep 30 17:27:39 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 30 Sep 2013 17:27:39 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
Message-ID: <1380554859.10008.30.camel@milan>

Le lundi 30 septembre 2013 ? 17:10 +0200, Joris Meys a ?crit :
> Regardless of whether "stored as character" is interpreted the R way
> or the ASCII way, the point Joshua makes is rather valid. Mainly
> because read.table has an argument quote with default value \"'. This
> means that at least according to R, everything between either " or '
> should be seen as of type character and not integer. 
I don't think the problem is related to the quote argument at all:
> read.table("file.csv", colClasses="integer", quote=NULL)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, : 
  scan() expected 'an integer' and got '"1"'

> The only way these quotes can end up in a .csv file, is when in the
> rendering program (often Excel), these integers are called "character"
> inside the program as well. So they're not treated as integers by the
> person that created the file, so R won't treat them
> as integers either. Note that read.table does read the quoted integers
> as characters, and only afterwards convert those.
Yeah, I understand how the conversion happens, but I wonder whether the
result really makes sense. The fact that you cannot set colClasses to
the classes you are actually getting when reading the file is somewhat
disturbing...

> So yes, this is an issue with read.table.ffdf more than with R itself.
> And the problem is indeed how integers are treated the moment they are
> stored. This refering to the presence/absence of the quote character.
Of course this could be fixed in read.table.ffdf(), but that would be
quite hacky since it could not cleanly rely as currently on
read.table(): it would need to read the file directly to check whether
the fields are quoted or not (since the result of read.table() does not
allow distinguishing their presence). To me this tends to indicate
something is wrong in the way read.table() works.

FWIW, changing the behavior of read.table() to skip quotes when
colClasses="integer" would not break any existing program since it would
only avoid an error where it previously happened, without modifying
working cases.


Regards

> 
> Regards
> Joris
> 
> 
> On Mon, Sep 30, 2013 at 4:45 PM, Milan Bouchet-Valat
> <nalimilan at club.fr> wrote:
>         Le lundi 30 septembre 2013 ? 08:38 -0500, Joshua Ulrich a
>         ?crit :
>         > On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat
>         <nalimilan at club.fr> wrote:
>         > > Hi!
>         > >
>         > >
>         > > It seems that read.table() in R 3.0.1 (Linux 64-bit) does
>         not consider
>         > > quoted integers as an acceptable value for columns for
>         which
>         > > colClasses="integer". But when colClasses is omitted,
>         these columns are
>         > > read as integer anyway.
>         > >
>         > > For example, let's consider a file named file.dat,
>         containing:
>         > > "1"
>         > > "2"
>         > >
>         > >> read.table("file.dat", colClasses="integer")
>         > > Error in scan(file, what, nmax, sep, dec, quote, skip,
>         nlines, na.strings, :
>         > >   scan() expected 'an integer' and got '"1"'
>         > >
>         > > But:
>         > >> str(read.table("file.dat"))
>         > > 'data.frame':   2 obs. of  1 variable:
>         > >  $ V1: int  1 2
>         > >
>         > > The latter result is indeed documented in ?read.table:
>         > >      Unless ?colClasses? is specified, all columns are
>         read as
>         > >      character columns and then converted using
>         ?type.convert? to
>         > >      logical, integer, numeric, complex or (depending on
>         ?as.is?)
>         > >      factor as appropriate.  Quotes are (by default)
>         interpreted in all
>         > >      fields, so a column of values like ?"42"? will result
>         in an
>         > >      integer column.
>         > >
>         > >
>         > > Should the former behavior be considered a bug?
>         > >
>         > No. If you tell read.table the column is integer and it's
>         actually
>         > character on disk, it should be an error.
>         
>         All values in a CSV file are stored as characters on disk,
>         disregarding
>         the fact that they are surrounded by quotes or not. 1 is saved
>         as
>         00110001 (ASCII character #49), not 00000001, nor 00000000
>         00000000
>         00000000 00000001 (as would for example imply a 32 bit storage
>         of
>         integers).
>         
>         So, with all due respect, please refrain from formulating such
>         blatantly
>         erroneous statements.
>         
>         
>         Regards
>         
>         
>         > > This creates problems when combined with read.table.ffdf
>         from package
>         > > ff, since this function tries to guess the column classes
>         by reading the
>         > > first rows of the file, and then passes colClasses to
>         read.table to read
>         > > the remaining rows by chunks. A column of quoted integers
>         is correctly
>         > > detected as integer in the first read, but read.table()
>         fails in
>         > > subsequent reads.
>         > >
>         > This sounds like a issue with read.table.ffdf.  The column
>         of quoted
>         > integers is *incorrectly* detected as integer because
>         they're actually
>         > character on disk.  read.table.ffdf should rely on how the
>         data are
>         > actually stored on disk (via as.is=TRUE), not how read.table
>         might
>         > convert them once they're read into R.
>         >
>         > >
>         > > Regards
>         > >
>         > > ______________________________________________
>         > > R-devel at r-project.org mailing list
>         > > https://stat.ethz.ch/mailman/listinfo/r-devel
>         >
>         > --
>         > Joshua Ulrich  |  about.me/joshuaulrich
>         > FOSS Trading  |  www.fosstrading.com
>         
>         ______________________________________________
>         R-devel at r-project.org mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-devel
>         
> 
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Mon Sep 30 17:46:03 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 30 Sep 2013 17:46:03 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380554859.10008.30.camel@milan>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
	<1380554859.10008.30.camel@milan>
Message-ID: <CAO1zAVYuWtxiH=XXvAAAoXeUrEzMQEEPAYrpFsGzv1TEH36Y-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130930/a5220ea5/attachment.pl>

From hb at biostat.ucsf.edu  Mon Sep 30 17:50:53 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 30 Sep 2013 08:50:53 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380544403.10008.15.camel@milan>
References: <1380544403.10008.15.camel@milan>
Message-ID: <CAFDcVCTmEg-OsbAK_9WU6tbUXDdHYWLzv1dKgep0K9UEar5oZA@mail.gmail.com>

On Mon, Sep 30, 2013 at 5:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Hi!
>
>
> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> quoted integers as an acceptable value for columns for which
> colClasses="integer". But when colClasses is omitted, these columns are
> read as integer anyway.
>
> For example, let's consider a file named file.dat, containing:
> "1"
> "2"
>
>> read.table("file.dat", colClasses="integer")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>   scan() expected 'an integer' and got '"1"'
>
> But:
>> str(read.table("file.dat"))
> 'data.frame':   2 obs. of  1 variable:
>  $ V1: int  1 2
>
> The latter result is indeed documented in ?read.table:
>      Unless ?colClasses? is specified, all columns are read as
>      character columns and then converted using ?type.convert? to
>      logical, integer, numeric, complex or (depending on ?as.is?)
>      factor as appropriate.  Quotes are (by default) interpreted in all
>      fields, so a column of values like ?"42"? will result in an
>      integer column.
>
>
> Should the former behavior be considered a bug?
>
> This creates problems when combined with read.table.ffdf from package
> ff, since this function tries to guess the column classes by reading the
> first rows of the file, and then passes colClasses to read.table to read
> the remaining rows by chunks. A column of quoted integers is correctly
> detected as integer in the first read, but read.table() fails in
> subsequent reads.

The readDataFrame() of the R.filesets package provides argument
'trimQuotes' for this exact reason, i.e. for the purpose of trimming
quotes of columns for which 'colClasses' specifies a numeric type
before passing on to read.table().  Feel free to borrow from its
source code for a patch to ff:read.table.ffdf().  The workaround is in
readDataFrame() for TabularTextFile
[https://r-forge.r-project.org/scm/viewvc.php/pkg/R.filesets/R/TabularTextFile.R?view=markup&root=r-dots];
look for the part that starts with:

  # SPECIAL CASE/WORKAROUND: read.table()/scan() will give an error
  # if a numeric value is quoted and 'colClasses' specifies it as
  # a numeric value.  In order to read such values, we need to remove
  # the quotes first. /HB 2011-07-13

/Henrik
(author of R.filesets)

>
>
> Regards
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Avraham.Adler at guycarp.com  Mon Sep 30 19:47:28 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Mon, 30 Sep 2013 12:47:28 -0500
Subject: [Rd] R-3.0.2 - Win7_64 - alone_decoder.c: Permission denied error
Message-ID: <93A2161604A30C4ABE14AC35CAFC84220164320630@USDFW11XM32.mercer.com>

Hello.

When trying to compile R-3.0.2 on Windows 7 64bit, I get an error relating to "alone_decoder.c: Permission denied." The entire error code is copied below.

	gcc -std=gnu99 -m64 -shared   -o Riconv.dll Riconv.def win_iconv.o
	touch stamp
	gcc -std=gnu99 -m64 -I../../include -I. -Iapi -DLZMA_API_STATIC -DHAVE_CONFIG_H
	-DWIN32  -O3 -Wall -pedantic -march=core-avx-i -O3 --param l1-cache-line-size=64
	 --param l1-cache-size=32 --param l2-cache-size=256   -c alone_decoder.c -o alone_decoder.o
	cc1.exe: fatal error: alone_decoder.c: Permission denied
	compilation terminated.
	make[5]: *** [alone_decoder.o] Error 1
	make[4]: *** [all] Error 2
	make[3]: *** [rlibs] Error 1
	make[2]: *** [../../bin/x64/R.dll] Error 2
	make[1]: *** [rbuild] Error 2
	make: *** [all] Error 2

However, I do *not* get this error when compiling R-patched as of 9/17/2013 using the exact same parameters on the same system. What does this error mean? Is it possible something changed between that version and the release which is causing this error? What may I do to correct the error?

Thank you very much,

Avraham Adler


From Avraham.Adler at guycarp.com  Mon Sep 30 23:40:38 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Mon, 30 Sep 2013 16:40:38 -0500
Subject: [Rd] R-3.0.2 - Win7_64 - alone_decoder.c: Permission denied
 error
Message-ID: <93A2161604A30C4ABE14AC35CAFC842201643D74DF@USDFW11XM32.mercer.com>

My problem appears to have been one of ignorance. I did not realize that once the directories were untarred, that copying the entire tree and renaming it may break permissions even on Windows. It appears that it does, as starting the compile immediately and not on a renamed copy seems to be progressing properly beyond that point.

Thank you,

Avraham Adler


