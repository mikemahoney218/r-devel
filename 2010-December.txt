From maechler at stat.math.ethz.ch  Wed Dec  1 09:39:01 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Dec 2010 09:39:01 +0100
Subject: [Rd] RFC: sapply() limitation from vector to matrix, but not further
Message-ID: <19702.2469.739772.13707@lynne.math.ethz.ch>

sapply() stems from S / S+ times and hence has a long tradition.
In spite of that I think that it should be enhanced...

As the subject mentions, sapply() produces a matrix in cases
where the list components of the lapply(.) results are of the
same length (and ...).
However, it unfortunately "stops there".
E.g., if you *nest* two sapply() calls where the inner one
produces a matrix, very often the logical behavior would be for
the outer sapply() to stack these matrices into an array of 
rank 3 ["array rank"(x) := length(dim(x))].
However it does not do that, e.g., an artifical example

p0 <- function(...) paste(..., sep="")
myF <- function(x,y) {
    stopifnot(length(x) <= 3)
    x <- rep(x, length.out=3)
    ny <- length(y)
    r <- outer(x,y)
    dimnames(r) <- list(p0("r",1:3), p0("C", seq_len(ny)))
    r
}

and

> (v <- structure(10*(5:8), names=LETTERS[1:4]))
 A  B  C  D 
50 60 70 80 

if we let sapply() not simplify, we see the list of same size
matrices it produes:

> sapply(v, myF, y = 2*(1:5), simplify=FALSE)
$A
    C1  C2  C3  C4  C5
r1 100 200 300 400 500
r2 100 200 300 400 500
r3 100 200 300 400 500

$B
    C1  C2  C3  C4  C5
r1 120 240 360 480 600
r2 120 240 360 480 600
r3 120 240 360 480 600

$C
    C1  C2  C3  C4  C5
r1 140 280 420 560 700
r2 140 280 420 560 700
r3 140 280 420 560 700

$D
    C1  C2  C3  C4  C5
r1 160 320 480 640 800
r2 160 320 480 640 800
r3 160 320 480 640 800

However, quite deceptively

> sapply(v, myF, y = 2*(1:5))
        A   B   C   D
 [1,] 100 120 140 160
 [2,] 100 120 140 160
 [3,] 100 120 140 160
 [4,] 200 240 280 320
 [5,] 200 240 280 320
 [6,] 200 240 280 320
 [7,] 300 360 420 480
 [8,] 300 360 420 480
 [9,] 300 360 420 480
[10,] 400 480 560 640
[11,] 400 480 560 640
[12,] 400 480 560 640
[13,] 500 600 700 800
[14,] 500 600 700 800
[15,] 500 600 700 800


My proposal -- implemented and "make check" tested --
is to add an optional argument  'ARRAY'
which allows

> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)
, , A

    C1  C2  C3  C4  C5
r1 100 200 300 400 500
r2 100 200 300 400 500
r3 100 200 300 400 500

, , B

    C1  C2  C3  C4  C5
r1 120 240 360 480 600
r2 120 240 360 480 600
r3 120 240 360 480 600

, , C

    C1  C2  C3  C4  C5
r1 140 280 420 560 700
r2 140 280 420 560 700
r3 140 280 420 560 700

, , D

    C1  C2  C3  C4  C5
r1 160 320 480 640 800
r2 160 320 480 640 800
r3 160 320 480 640 800

> 
-----------

In the best of all worlds, the default would be 'ARRAY = TRUE',
but of course, given the long-standing different behavior,
it seem much too "risky", and my proposal includes remaining
back-compatible with default ARRAY = FALSE.

Martin Maechler,
ETH Zurich


From aleksi.kallio at csc.fi  Wed Dec  1 13:27:12 2010
From: aleksi.kallio at csc.fi (Aleksi Kallio)
Date: Wed, 1 Dec 2010 14:27:12 +0200
Subject: [Rd] Reordering entries in package manual PDF's
Message-ID: <4CF63F20.5030803@csc.fi>

Hello,

I have created my own R package and written the documentation in Rd
format for each of the functions plus the package itself.

However now the functions appear in a random order in the generated PDF
and the package documentation entry is placed in between the functions, 
when I would like it to be first, naturally.

Is there an easy way to specify the order of the entries in the
generated documentation?

Browsing through the R manual and mailing list archives did not find
anything. Rd is all I need, so I would not like to start using any of
the more advanced documentation tools.

Thanks for your help!

All the best,
Aleksi

P.S. Cross-posted from R-help, as instructed by one of the subscribers.


From murdoch.duncan at gmail.com  Wed Dec  1 13:56:21 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 Dec 2010 07:56:21 -0500
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4CF63F20.5030803@csc.fi>
References: <4CF63F20.5030803@csc.fi>
Message-ID: <4CF645F5.4050301@gmail.com>

On 01/12/2010 7:27 AM, Aleksi Kallio wrote:
> Hello,
>
> I have created my own R package and written the documentation in Rd
> format for each of the functions plus the package itself.
>
> However now the functions appear in a random order in the generated PDF
> and the package documentation entry is placed in between the functions,
> when I would like it to be first, naturally.

I think you need to give us more details.  What version of R are you 
using?  How are you producing the PDF?  When I do it in R 2.12.0 using

R CMD Rd2dvi --pdf <mypackage>

I get the pages in alphabetical order, except that the package page 
comes first.

Duncan Murdoch


> Is there an easy way to specify the order of the entries in the
> generated documentation?
>
> Browsing through the R manual and mailing list archives did not find
> anything. Rd is all I need, so I would not like to start using any of
> the more advanced documentation tools.
>
> Thanks for your help!
>
> All the best,
> Aleksi
>
> P.S. Cross-posted from R-help, as instructed by one of the subscribers.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at me.com  Wed Dec  1 14:59:00 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 01 Dec 2010 07:59:00 -0600
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
 but not further
In-Reply-To: <19702.2469.739772.13707@lynne.math.ethz.ch>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
Message-ID: <D5DCB29D-46D5-458C-B315-472699A02AAB@me.com>

On Dec 1, 2010, at 2:39 AM, Martin Maechler wrote:

> sapply() stems from S / S+ times and hence has a long tradition.
> In spite of that I think that it should be enhanced...
> 
> As the subject mentions, sapply() produces a matrix in cases
> where the list components of the lapply(.) results are of the
> same length (and ...).
> However, it unfortunately "stops there".
> E.g., if you *nest* two sapply() calls where the inner one
> produces a matrix, very often the logical behavior would be for
> the outer sapply() to stack these matrices into an array of 
> rank 3 ["array rank"(x) := length(dim(x))].
> However it does not do that, e.g., an artifical example
> 
> p0 <- function(...) paste(..., sep="")
> myF <- function(x,y) {
>    stopifnot(length(x) <= 3)
>    x <- rep(x, length.out=3)
>    ny <- length(y)
>    r <- outer(x,y)
>    dimnames(r) <- list(p0("r",1:3), p0("C", seq_len(ny)))
>    r
> }
> 
> and
> 
>> (v <- structure(10*(5:8), names=LETTERS[1:4]))
> A  B  C  D 
> 50 60 70 80 
> 
> if we let sapply() not simplify, we see the list of same size
> matrices it produes:
> 
>> sapply(v, myF, y = 2*(1:5), simplify=FALSE)
> $A
>    C1  C2  C3  C4  C5
> r1 100 200 300 400 500
> r2 100 200 300 400 500
> r3 100 200 300 400 500
> 
> $B
>    C1  C2  C3  C4  C5
> r1 120 240 360 480 600
> r2 120 240 360 480 600
> r3 120 240 360 480 600
> 
> $C
>    C1  C2  C3  C4  C5
> r1 140 280 420 560 700
> r2 140 280 420 560 700
> r3 140 280 420 560 700
> 
> $D
>    C1  C2  C3  C4  C5
> r1 160 320 480 640 800
> r2 160 320 480 640 800
> r3 160 320 480 640 800
> 
> However, quite deceptively
> 
>> sapply(v, myF, y = 2*(1:5))
>        A   B   C   D
> [1,] 100 120 140 160
> [2,] 100 120 140 160
> [3,] 100 120 140 160
> [4,] 200 240 280 320
> [5,] 200 240 280 320
> [6,] 200 240 280 320
> [7,] 300 360 420 480
> [8,] 300 360 420 480
> [9,] 300 360 420 480
> [10,] 400 480 560 640
> [11,] 400 480 560 640
> [12,] 400 480 560 640
> [13,] 500 600 700 800
> [14,] 500 600 700 800
> [15,] 500 600 700 800
> 
> 
> My proposal -- implemented and "make check" tested --
> is to add an optional argument  'ARRAY'
> which allows
> 
>> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)
> , , A
> 
>    C1  C2  C3  C4  C5
> r1 100 200 300 400 500
> r2 100 200 300 400 500
> r3 100 200 300 400 500
> 
> , , B
> 
>    C1  C2  C3  C4  C5
> r1 120 240 360 480 600
> r2 120 240 360 480 600
> r3 120 240 360 480 600
> 
> , , C
> 
>    C1  C2  C3  C4  C5
> r1 140 280 420 560 700
> r2 140 280 420 560 700
> r3 140 280 420 560 700
> 
> , , D
> 
>    C1  C2  C3  C4  C5
> r1 160 320 480 640 800
> r2 160 320 480 640 800
> r3 160 320 480 640 800
> 
>> 
> -----------
> 
> In the best of all worlds, the default would be 'ARRAY = TRUE',
> but of course, given the long-standing different behavior,
> it seem much too "risky", and my proposal includes remaining
> back-compatible with default ARRAY = FALSE.
> 
> Martin Maechler,
> ETH Zurich


Seems to me to be a reasonable proposal Martin, obviously with the proviso that the current default behavior is unaltered, as you note.

Regards,

Marc


From hadley at rice.edu  Wed Dec  1 15:26:35 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 1 Dec 2010 14:26:35 +0000
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <19702.2469.739772.13707@lynne.math.ethz.ch>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
Message-ID: <AANLkTi=H9k-HSuyqk=XwMm_hmwoc_WOU3azjYnUmAkFP@mail.gmail.com>

I think an even better approach would be to extract the
"simplification" component out of sapply, so that could write

sapply <- function(...) simplify(lapply(...))

(although obviously some arguments would go to lapply and some to simplify).

The advantage of this would be that you could use the same
simplification algorithm in other places.

Hadley

On Wed, Dec 1, 2010 at 8:39 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> sapply() stems from S / S+ times and hence has a long tradition.
> In spite of that I think that it should be enhanced...
>
> As the subject mentions, sapply() produces a matrix in cases
> where the list components of the lapply(.) results are of the
> same length (and ...).
> However, it unfortunately "stops there".
> E.g., if you *nest* two sapply() calls where the inner one
> produces a matrix, very often the logical behavior would be for
> the outer sapply() to stack these matrices into an array of
> rank 3 ["array rank"(x) := length(dim(x))].
> However it does not do that, e.g., an artifical example
>
> p0 <- function(...) paste(..., sep="")
> myF <- function(x,y) {
> ? ?stopifnot(length(x) <= 3)
> ? ?x <- rep(x, length.out=3)
> ? ?ny <- length(y)
> ? ?r <- outer(x,y)
> ? ?dimnames(r) <- list(p0("r",1:3), p0("C", seq_len(ny)))
> ? ?r
> }
>
> and
>
>> (v <- structure(10*(5:8), names=LETTERS[1:4]))
> ?A ?B ?C ?D
> 50 60 70 80
>
> if we let sapply() not simplify, we see the list of same size
> matrices it produes:
>
>> sapply(v, myF, y = 2*(1:5), simplify=FALSE)
> $A
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 100 200 300 400 500
> r2 100 200 300 400 500
> r3 100 200 300 400 500
>
> $B
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 120 240 360 480 600
> r2 120 240 360 480 600
> r3 120 240 360 480 600
>
> $C
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 140 280 420 560 700
> r2 140 280 420 560 700
> r3 140 280 420 560 700
>
> $D
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 160 320 480 640 800
> r2 160 320 480 640 800
> r3 160 320 480 640 800
>
> However, quite deceptively
>
>> sapply(v, myF, y = 2*(1:5))
> ? ? ? ?A ? B ? C ? D
> ?[1,] 100 120 140 160
> ?[2,] 100 120 140 160
> ?[3,] 100 120 140 160
> ?[4,] 200 240 280 320
> ?[5,] 200 240 280 320
> ?[6,] 200 240 280 320
> ?[7,] 300 360 420 480
> ?[8,] 300 360 420 480
> ?[9,] 300 360 420 480
> [10,] 400 480 560 640
> [11,] 400 480 560 640
> [12,] 400 480 560 640
> [13,] 500 600 700 800
> [14,] 500 600 700 800
> [15,] 500 600 700 800
>
>
> My proposal -- implemented and "make check" tested --
> is to add an optional argument ?'ARRAY'
> which allows
>
>> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)
> , , A
>
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 100 200 300 400 500
> r2 100 200 300 400 500
> r3 100 200 300 400 500
>
> , , B
>
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 120 240 360 480 600
> r2 120 240 360 480 600
> r3 120 240 360 480 600
>
> , , C
>
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 140 280 420 560 700
> r2 140 280 420 560 700
> r3 140 280 420 560 700
>
> , , D
>
> ? ?C1 ?C2 ?C3 ?C4 ?C5
> r1 160 320 480 640 800
> r2 160 320 480 640 800
> r3 160 320 480 640 800
>
>>
> -----------
>
> In the best of all worlds, the default would be 'ARRAY = TRUE',
> but of course, given the long-standing different behavior,
> it seem much too "risky", and my proposal includes remaining
> back-compatible with default ARRAY = FALSE.
>
> Martin Maechler,
> ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ripley at stats.ox.ac.uk  Wed Dec  1 15:28:16 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Dec 2010 14:28:16 +0000 (GMT)
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4CF63F20.5030803@csc.fi>
References: <4CF63F20.5030803@csc.fi>
Message-ID: <alpine.LFD.2.00.1012011421250.23656@toucan.stats.ox.ac.uk>

On Wed, 1 Dec 2010, Aleksi Kallio wrote:

> Hello,
>
> I have created my own R package and written the documentation in Rd
> format for each of the functions plus the package itself.
>
> However now the functions appear in a random order in the generated PDF
> and the package documentation entry is placed in between the functions, when 
> I would like it to be first, naturally.

I have never seen anything else.  Please do as the posting guide asked 
you, and given a reproducible example.

All the package manuals on CRAN have the following order:

foo-package.Rd, if present.
the remaining Rd files in alphabetical order in the current locale.

> Is there an easy way to specify the order of the entries in the
> generated documentation?

By the ordering of the names of the Rd files, but your readers will 
find anything other than alphabetical order of main topic unusual and 
maybe puzzling.

You could also call Rd2dvi/Rd2pdf with a list of files.

> Browsing through the R manual and mailing list archives did not find
> anything. Rd is all I need, so I would not like to start using any of
> the more advanced documentation tools.
>
> Thanks for your help!
>
> All the best,
> Aleksi
>
> P.S. Cross-posted from R-help, as instructed by one of the subscribers.

We do prefer posting in only one place.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Wed Dec  1 17:56:26 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 1 Dec 2010 08:56:26 -0800
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <AANLkTi=H9k-HSuyqk=XwMm_hmwoc_WOU3azjYnUmAkFP@mail.gmail.com>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTi=H9k-HSuyqk=XwMm_hmwoc_WOU3azjYnUmAkFP@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003B1D5BD@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Hadley Wickham
> Sent: Wednesday, December 01, 2010 6:27 AM
> To: Martin Maechler
> Cc: R-devel at stat.math.ethz.ch
> Subject: Re: [Rd] RFC: sapply() limitation from vector to 
> matrix,but not further
> 
> I think an even better approach would be to extract the
> "simplification" component out of sapply, so that could write
> 
> sapply <- function(...) simplify(lapply(...))
> 
> (although obviously some arguments would go to lapply and 
> some to simplify).
> 
> The advantage of this would be that you could use the same
> simplification algorithm in other places.

A downside of that approach is that lapply(X,...) can
cause a lot of unneeded memory to be allocated (length(X)
SEXP's).  Those SEXP's would be tossed out by simplify() but
the peak memory usage would remain high.  sapply() can
be written to avoid the intermediate list structure.

vapply() can avoid the intermediate list structure because
it knows what the output of FUN will look like and can
put the results directly into the desired output structure.
Perhaps its processing of the FUN.VALUE argument could be
beefed up so that matrices would be stacked as you want.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> 
> Hadley
> 
> On Wed, Dec 1, 2010 at 8:39 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> > sapply() stems from S / S+ times and hence has a long tradition.
> > In spite of that I think that it should be enhanced...
> >
> > As the subject mentions, sapply() produces a matrix in cases
> > where the list components of the lapply(.) results are of the
> > same length (and ...).
> > However, it unfortunately "stops there".
> > E.g., if you *nest* two sapply() calls where the inner one
> > produces a matrix, very often the logical behavior would be for
> > the outer sapply() to stack these matrices into an array of
> > rank 3 ["array rank"(x) := length(dim(x))].
> > However it does not do that, e.g., an artifical example
> >
> > p0 <- function(...) paste(..., sep="")
> > myF <- function(x,y) {
> > ? ?stopifnot(length(x) <= 3)
> > ? ?x <- rep(x, length.out=3)
> > ? ?ny <- length(y)
> > ? ?r <- outer(x,y)
> > ? ?dimnames(r) <- list(p0("r",1:3), p0("C", seq_len(ny)))
> > ? ?r
> > }
> >
> > and
> >
> >> (v <- structure(10*(5:8), names=LETTERS[1:4]))
> > ?A ?B ?C ?D
> > 50 60 70 80
> >
> > if we let sapply() not simplify, we see the list of same size
> > matrices it produes:
> >
> >> sapply(v, myF, y = 2*(1:5), simplify=FALSE)
> > $A
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 100 200 300 400 500
> > r2 100 200 300 400 500
> > r3 100 200 300 400 500
> >
> > $B
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 120 240 360 480 600
> > r2 120 240 360 480 600
> > r3 120 240 360 480 600
> >
> > $C
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 140 280 420 560 700
> > r2 140 280 420 560 700
> > r3 140 280 420 560 700
> >
> > $D
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 160 320 480 640 800
> > r2 160 320 480 640 800
> > r3 160 320 480 640 800
> >
> > However, quite deceptively
> >
> >> sapply(v, myF, y = 2*(1:5))
> > ? ? ? ?A ? B ? C ? D
> > ?[1,] 100 120 140 160
> > ?[2,] 100 120 140 160
> > ?[3,] 100 120 140 160
> > ?[4,] 200 240 280 320
> > ?[5,] 200 240 280 320
> > ?[6,] 200 240 280 320
> > ?[7,] 300 360 420 480
> > ?[8,] 300 360 420 480
> > ?[9,] 300 360 420 480
> > [10,] 400 480 560 640
> > [11,] 400 480 560 640
> > [12,] 400 480 560 640
> > [13,] 500 600 700 800
> > [14,] 500 600 700 800
> > [15,] 500 600 700 800
> >
> >
> > My proposal -- implemented and "make check" tested --
> > is to add an optional argument ?'ARRAY'
> > which allows
> >
> >> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)
> > , , A
> >
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 100 200 300 400 500
> > r2 100 200 300 400 500
> > r3 100 200 300 400 500
> >
> > , , B
> >
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 120 240 360 480 600
> > r2 120 240 360 480 600
> > r3 120 240 360 480 600
> >
> > , , C
> >
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 140 280 420 560 700
> > r2 140 280 420 560 700
> > r3 140 280 420 560 700
> >
> > , , D
> >
> > ? ?C1 ?C2 ?C3 ?C4 ?C5
> > r1 160 320 480 640 800
> > r2 160 320 480 640 800
> > r3 160 320 480 640 800
> >
> >>
> > -----------
> >
> > In the best of all worlds, the default would be 'ARRAY = TRUE',
> > but of course, given the long-standing different behavior,
> > it seem much too "risky", and my proposal includes remaining
> > back-compatible with default ARRAY = FALSE.
> >
> > Martin Maechler,
> > ETH Zurich
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From Aleksi.Kallio at csc.fi  Wed Dec  1 18:17:59 2010
From: Aleksi.Kallio at csc.fi (Aleksi Kallio)
Date: Wed, 1 Dec 2010 19:17:59 +0200
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4CF645F5.4050301@gmail.com>
References: <4CF63F20.5030803@csc.fi>,<4CF645F5.4050301@gmail.com>
Message-ID: <4FEBB24215A35547BC21FAB42479B21F06B4FE69E7@cscexmb01.csc.local>

Hi,

> R CMD Rd2dvi --pdf <mypackage>
> I get the pages in alphabetical order, except that the package page
> comes first.

I was actually using an ancient version, 2.5. Updating to a later one moved the package page first.

So now the output I'm getting is "good enough". I would still like to reorder functions so that they appear in a more logical order, so if anyone has ideas, please share!

Thanks!

Cheers,
Aleksi


From Aleksi.Kallio at csc.fi  Wed Dec  1 18:25:50 2010
From: Aleksi.Kallio at csc.fi (Aleksi Kallio)
Date: Wed, 1 Dec 2010 19:25:50 +0200
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4FEBB24215A35547BC21FAB42479B21F06B4FE69E7@cscexmb01.csc.local>
References: <4CF63F20.5030803@csc.fi>, <4CF645F5.4050301@gmail.com>,
	<4FEBB24215A35547BC21FAB42479B21F06B4FE69E7@cscexmb01.csc.local>
Message-ID: <4FEBB24215A35547BC21FAB42479B21F06B4FE69E8@cscexmb01.csc.local>

Hi again,

And sorry for the spam.

> So now the output I'm getting is "good enough". I would still like to reorder functions so that they appear in a more logical order, so if anyone has ideas, please share!

Newer R versions also add an index page at the end. In my case it is obsolete, so ideas on how to get rid of it are appreciated.

A pointer to an in-depth technical description of the manual generation process would help, as hacking these kinds of things would be probably quite easy. So far I have not been able to Google anything relevant.

Cheers,
Aleksi


From djsamperi at gmail.com  Wed Dec  1 19:21:27 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 1 Dec 2010 13:21:27 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
Message-ID: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101201/5348997e/attachment.pl>

From murdoch.duncan at gmail.com  Wed Dec  1 19:38:46 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 Dec 2010 13:38:46 -0500
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4FEBB24215A35547BC21FAB42479B21F06B4FE69E8@cscexmb01.csc.local>
References: <4CF63F20.5030803@csc.fi>, <4CF645F5.4050301@gmail.com>,
	<4FEBB24215A35547BC21FAB42479B21F06B4FE69E7@cscexmb01.csc.local>
	<4FEBB24215A35547BC21FAB42479B21F06B4FE69E8@cscexmb01.csc.local>
Message-ID: <4CF69636.7060900@gmail.com>

On 01/12/2010 12:25 PM, Aleksi Kallio wrote:
> Hi again,
>
> And sorry for the spam.
>
> >  So now the output I'm getting is "good enough". I would still like to reorder functions so that they appear in a more logical order, so if anyone has ideas, please share!
>
> Newer R versions also add an index page at the end. In my case it is obsolete, so ideas on how to get rid of it are appreciated.
>
> A pointer to an in-depth technical description of the manual generation process would help, as hacking these kinds of things would be probably quite easy. So far I have not been able to Google anything relevant.

You could look at R Internals for such a thing, but you wouldn't find 
it.  (That manual tends to cover lower level issues.)

Generally in a case like this you need to go to the source code.  First, 
get a copy, then figure out what happens.  Here are the steps:

1. Download the full source from 
http://cran.r-project.org/src/base/R-2/R-2.12.0.tar.gz (or from a 
mirror), and untar it.

2. We use R CMD Rd2dvi to get the output we want.  Looking in 
src/scripts, you can see that the Rd2dvi script does some argument
cleaning, then runs tools:::..Rd2dvi().

3.  Look in src/library/tools/R for the file containing the source to 
..Rd2dvi(); you'll find it in Rd2dvi.R.

You can also see deparsed versions just by printing the tools:::..Rd2dvi 
function, but they may not be as useful as the original source.

I hope that helps.

Duncan Murdoch


From hadley at rice.edu  Wed Dec  1 19:51:54 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 1 Dec 2010 18:51:54 +0000
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003B1D5BD@NA-PA-VBE03.na.tibco.com>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTi=H9k-HSuyqk=XwMm_hmwoc_WOU3azjYnUmAkFP@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70003B1D5BD@NA-PA-VBE03.na.tibco.com>
Message-ID: <AANLkTi=L6H3z6YT+nuKkQsGiVTShQekroK8q28zAXOEV@mail.gmail.com>

> A downside of that approach is that lapply(X,...) can
> cause a lot of unneeded memory to be allocated (length(X)
> SEXP's). ?Those SEXP's would be tossed out by simplify() but
> the peak memory usage would remain high. ?sapply() can
> be written to avoid the intermediate list structure.

But the upside is reusable code that can be used in multiple places -
what about the simplification code used by mapply and tapply? Why are
there three different implementations of simplification?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From djsamperi at gmail.com  Wed Dec  1 21:45:51 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 1 Dec 2010 15:45:51 -0500
Subject: [Rd] [Rcpp-devel]  GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
Message-ID: <AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101201/6c1e5b84/attachment.pl>

From hadley at rice.edu  Wed Dec  1 23:18:39 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 1 Dec 2010 22:18:39 +0000
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
Message-ID: <AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>

> Perhaps a wider community of R users can weigh in on a
> policy decision that was implicitly deemed acceptable on this
> thread. Namely, that it is fine to arbitrarily and
> for no reason deprecate the contributions of past
> authors, and as more progress is made, even more
> disparaging remarks can be added.

What is disparaging about saying "a small portion of the code is based
on code written during 2005 and 2006 by Dominick Samperi"? I read this
as a factual statement saying that the current version of Rcpp is
based on, in a small way, your earlier work.

For reference, a disparaging comment would be something like: "This
package was based code written by Hadley Wickham that made my eyes
bleed", or "The development of this package was driven by the godawful
code that Hadley wrote".

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jorismeys at gmail.com  Thu Dec  2 00:05:14 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 2 Dec 2010 00:05:14 +0100
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
Message-ID: <AANLkTi=AC9xYxO9t4aSzxL589MTmsuJbXhrpEyTo0=jk@mail.gmail.com>

On Wed, Dec 1, 2010 at 9:45 PM, Dominick Samperi <djsamperi at gmail.com> wrote:

> Perhaps a wider community of R users can weigh in on a
> policy decision that was implicitly deemed acceptable on this
> thread. Namely, that it is fine to arbitrarily and
> for no reason deprecate the contributions of past
> authors, and as more progress is made, even more
> disparaging remarks can be added.
>
I agree with Hadley that the remark can hardly be seen as disparaging.
As mainly an R user, I am quite surprised to find out that the rcpp
package originates from you though, so I can understand you would
personally like a line in the sense of

"this package has been originally written by Dominick Samperi in 2005-2006"

But then again, apparently quite a lot changed, so that would -again-
leave a wrong impression and downweigh the effort done by others more
recently. If only the name and a small portion of the code remained,
well, so be it. Seems correct to put it that way. Frankly said: It
ain't your package any more, it's a whole different thing.

Whether or not deprecating the earlier efforts is a policy, is highly
debatable. It seems more a matter of common sense to me: mention the
authors of the _present_ code. And as it goes, I for one am not going
to set "policies" or "politeness rules" in the R community or any
other.

Now personally, I sign the work I do, send it into the world, and
don't bother once I stopped contributing. People who need to know what
I'm worth, will see that in my recent and ongoing work. About all the
rest, I couldn't be bothered less. Seems more healthy for the heart to
me. Then again, I don't care that much about reputation anyway. I'd
like to see my work used, rather than being praised for it. (this is a
general remark, not directed towards you!)

Cheers
Joris
-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From JHZhang at mdanderson.org  Thu Dec  2 00:28:39 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Wed, 1 Dec 2010 17:28:39 -0600
Subject: [Rd] Install package 'Matrix' problem
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E371F8D9@DCPWVMBXC1VS2.mdanderson.edu>

64-bit R-2.12.0 was installed on Sun SPARC Solaris 10. Compiler used is solstudio12.2. Attached is the configure script.
I then tried to install a recommended package called Matrix. The compilation failed with the following messages,
.......
CC -library=stlport4 -G -L/opt/csw/lib/sparcv9 -L/opt/solstudio12.2/prod/lib/v9 -o Matrix.so CHMfactor.o Csparse.o TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o cs_utils.o dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o dppMatrix.o dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o sparseQR.o abIndex.o CHOLMOD.a COLAMD.a AMD.a -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRlapack -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRblas -lifai -lsunimath -lfai -lfai2 -lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai -lfui -lfsu -lsunmath -lmtsk -lm
ld: fatal: file CHMfactor.o: wrong ELF class: ELFCLASS64
ld: fatal: File processing errors. No output written to Matrix.so
make: *** [Matrix.so] Error 2
ERROR: compilation failed for package 'Matrix'
* removing '/apps/sparcv9/R-2.12.0/lib/R/library/Matrix'

Some article suggests theorectically that ld or compiler driver first sees a component .o file which is 32-bit (don't know which one here), and decides that other components should be 32-bit, too, hence the error message, since CHMfactor.o must be a 64-bit object. I just don't know what is the practical way to avoid this situation. I guess I'm posting in the right list, can somebody help?

Jun

From ggrothendieck at gmail.com  Thu Dec  2 00:37:41 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 1 Dec 2010 18:37:41 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
Message-ID: <AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>

On Wed, Dec 1, 2010 at 5:18 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> Perhaps a wider community of R users can weigh in on a
>> policy decision that was implicitly deemed acceptable on this
>> thread. Namely, that it is fine to arbitrarily and
>> for no reason deprecate the contributions of past
>> authors, and as more progress is made, even more
>> disparaging remarks can be added.
>
> What is disparaging about saying "a small portion of the code is based
> on code written during 2005 and 2006 by Dominick Samperi"? I read this
> as a factual statement saying that the current version of Rcpp is
> based on, in a small way, your earlier work.
>
> For reference, a disparaging comment would be something like: "This
> package was based code written by Hadley Wickham that made my eyes
> bleed", or "The development of this package was driven by the godawful
> code that Hadley wrote".
>


Its very difficult to truly assess relative contributions when you mix
in design, coding, level of effort, promotion, etc.   I would not
focus on the single word "disparaging".  I think the poster simply
used the wrong word and perhaps what he meant was more along the lines
of: as the creator of the package he presumably set the design (or
significant elements of the design) for all subsequent work and in
that respect even if its true that the number of lines he generated is
relatively small compared to the current package, that phrase gives
the misleading impression that his contribution was also small.  There
is a difference between something that is true and non-misleading and
something that is true and misleading.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From djsamperi at gmail.com  Thu Dec  2 01:20:46 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 1 Dec 2010 19:20:46 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
Message-ID: <AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101201/00cc04ca/attachment.pl>

From ggrothendieck at gmail.com  Thu Dec  2 01:55:38 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 1 Dec 2010 19:55:38 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
Message-ID: <AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>

On Wed, Dec 1, 2010 at 7:20 PM, Dominick Samperi <djsamperi at gmail.com> wrote:
> On Wed, Dec 1, 2010 at 6:37 PM, Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
>>
>> On Wed, Dec 1, 2010 at 5:18 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> >> Perhaps a wider community of R users can weigh in on a
>> >> policy decision that was implicitly deemed acceptable on this
>> >> thread. Namely, that it is fine to arbitrarily and
>> >> for no reason deprecate the contributions of past
>> >> authors, and as more progress is made, even more
>> >> disparaging remarks can be added.
>> >
>> > What is disparaging about saying "a small portion of the code is based
>> > on code written during 2005 and 2006 by Dominick Samperi"? I read this
>> > as a factual statement saying that the current version of Rcpp is
>> > based on, in a small way, your earlier work.
>> >
>> > For reference, a disparaging comment would be something like: "This
>> > package was based code written by Hadley Wickham that made my eyes
>> > bleed", or "The development of this package was driven by the godawful
>> > code that Hadley wrote".
>> >
>>
>>
>> Its very difficult to truly assess relative contributions when you mix
>> in design, coding, level of effort, promotion, etc. ? I would not
>> focus on the single word "disparaging". ?I think the poster simply
>> used the wrong word and perhaps what he meant was more along the lines
>> of: as the creator of the package he presumably set the design (or
>> significant elements of the design) for all subsequent work and in
>> that respect even if its true that the number of lines he generated is
>> relatively small compared to the current package, that phrase gives
>> the misleading impression that his contribution was also small. ?There
>> is a difference between something that is true and non-misleading and
>> something that is true and misleading.
>
> There is an important element of this discussion that is being overlooked,
> namely, the timing. If indeed my contributions were minimal (and they
> were not for the reasons you suggest) then why was it decided now,
> for this particular release, to update my status? Why not the last
> release? What changed? There were only a few new features added
> to this release. What made the difference?
>
> More importantly, as I suggested in my original post, this practice
> sets an absurd precedent, one that motivated Stallman to write
> the GNU manifesto (where he used the oxygen mask metaphor).
> Should we reevaluate all contributors, present or past, and
> adjust the level of deprecation on the
> author line appropriately before each release?
>
> I suspect that I have contributed far more than some of the
> people listed on the author line. Does this mean that their
> contributions should be discounted accordingly? If not,
> why not?
>
> Thanks for your courage. People who send supportive comments
> tend to send them off-list, not wanting to state them publicly.
>

Just to be clear I have never used the package and am not truly
commenting on this particular case but only the general ideas in this
thread.  Also I was not suggesting that the comments in the code were
purposefully misleading, only that they might be misleading since they
could be interpreted in terms of contribution even though they are
stated in terms of lines of code.  The author of the phrase may very
well have felt that the current team had done a lot of work to add
design ideas and develop and promote the software but perhaps the
unfortunate way in how it was expressed in that phrase that came out
as a seeming comment on the original creator's contribution rather
than the intended comment on their own, presumably also significant,
contribution.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From spencer.graves at structuremonitoring.com  Thu Dec  2 02:19:57 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 01 Dec 2010 17:19:57 -0800
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
Message-ID: <4CF6F43D.9010501@structuremonitoring.com>

Hi, Dominick, et al.:


       I know nothing about about Rcpp, it's history and the 
contributions of Dominick and anyone else.  I think everyone should be 
appropriately recognized for their contributions.


       However, I feel compelled to briefly outline personal experiences 
with collaborators who were so concerned that their contribution be 
properly recognized that it limited our success.  To successfully 
commercialize the ideas, we needed the collaboration of others.  
However, my collaborators' excessive concern about getting "their share" 
made it exceedingly and unreasonably difficult to obtain the extra help 
we needed.


       A famous example of this was the Wright Brothers.  They  invented 
the airplane and spent much of the rest of their lives trying to defend 
their patent.  Wilbur was dead long before it was settled, and Orville 
got so little from it that it was clearly a massive waste of their 
time.  Moreover, "The legal threat suppressed development of the U.S. 
aviation industry." 
(http://en.wikipedia.org/wiki/The_Wright_brothers_patent_war)


       I sincerely hope that this present discussion can be settled in a 
way that does not damage the incredibly productive collaboration that 
has made R the overwhelming success it is.  The future of humanity is 
brighter because R makes it easier (a) for scientists to better 
understand the things they study and (b) for common people to better 
understand and manage the problems they face.


       Best Wishes,
       Spencer Graves


On 12/1/2010 4:20 PM, Dominick Samperi wrote:
> On Wed, Dec 1, 2010 at 6:37 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com>wrote:
>
>> On Wed, Dec 1, 2010 at 5:18 PM, Hadley Wickham<hadley at rice.edu>  wrote:
>>>> Perhaps a wider community of R users can weigh in on a
>>>> policy decision that was implicitly deemed acceptable on this
>>>> thread. Namely, that it is fine to arbitrarily and
>>>> for no reason deprecate the contributions of past
>>>> authors, and as more progress is made, even more
>>>> disparaging remarks can be added.
>>> What is disparaging about saying "a small portion of the code is based
>>> on code written during 2005 and 2006 by Dominick Samperi"? I read this
>>> as a factual statement saying that the current version of Rcpp is
>>> based on, in a small way, your earlier work.
>>>
>>> For reference, a disparaging comment would be something like: "This
>>> package was based code written by Hadley Wickham that made my eyes
>>> bleed", or "The development of this package was driven by the godawful
>>> code that Hadley wrote".
>>>
>>
>> Its very difficult to truly assess relative contributions when you mix
>> in design, coding, level of effort, promotion, etc.   I would not
>> focus on the single word "disparaging".  I think the poster simply
>> used the wrong word and perhaps what he meant was more along the lines
>> of: as the creator of the package he presumably set the design (or
>> significant elements of the design) for all subsequent work and in
>> that respect even if its true that the number of lines he generated is
>> relatively small compared to the current package, that phrase gives
>> the misleading impression that his contribution was also small.  There
>> is a difference between something that is true and non-misleading and
>> something that is true and misleading.
>>
> There is an important element of this discussion that is being overlooked,
> namely, the timing. If indeed my contributions were minimal (and they
> were not for the reasons you suggest) then why was it decided now,
> for this particular release, to update my status? Why not the last
> release? What changed? There were only a few new features added
> to this release. What made the difference?
>
> More importantly, as I suggested in my original post, this practice
> sets an absurd precedent, one that motivated Stallman to write
> the GNU manifesto (where he used the oxygen mask metaphor).
> Should we reevaluate all contributors, present or past, and
> adjust the level of deprecation on the
> author line appropriately before each release?
>
> I suspect that I have contributed far more than some of the
> people listed on the author line. Does this mean that their
> contributions should be discounted accordingly? If not,
> why not?
>
> Thanks for your courage. People who send supportive comments
> tend to send them off-list, not wanting to state them publicly.
>
> Dominick
>
>
>> --
>> Statistics&  Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at structuremonitoring.com  Thu Dec  2 02:21:35 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 01 Dec 2010 17:21:35 -0800
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
Message-ID: <4CF6F49F.6040403@structuremonitoring.com>

Hi, Dominick, et al.:


       I know nothing about about Rcpp, it's history and the 
contributions of Dominick and anyone else.  I think everyone should be 
appropriately recognized for their contributions.


       However, I feel compelled to briefly outline personal experiences 
with collaborators who were so concerned that their contribution be 
properly recognized that it limited our success.  To successfully 
commercialize the ideas, we needed the collaboration of others.  
However, my collaborators' excessive concern about getting "their share" 
made it exceedingly and unreasonably difficult to obtain the extra help 
we needed.


       A famous example of this was the Wright Brothers.  They  invented 
the airplane and spent much of the rest of their lives trying to defend 
their patent.  Wilbur was dead long before it was settled, and Orville 
got so little from it that it was clearly a massive waste of their 
time.  Moreover, "The legal threat suppressed development of the U.S. 
aviation industry." 
(http://en.wikipedia.org/wiki/The_Wright_brothers_patent_war)


       I sincerely hope that this present discussion can be settled in a 
way that does not damage the incredibly productive collaboration that 
has made R the overwhelming success it is.  The future of humanity is 
brighter because R makes it easier (a) for scientists to better 
understand the things they study and (b) for common people to better 
understand and manage the problems they face.


       Best Wishes,
       Spencer Graves


On 12/1/2010 4:55 PM, Gabor Grothendieck wrote:
> On Wed, Dec 1, 2010 at 7:20 PM, Dominick Samperi<djsamperi at gmail.com>  wrote:
>> On Wed, Dec 1, 2010 at 6:37 PM, Gabor Grothendieck<ggrothendieck at gmail.com>
>> wrote:
>>> On Wed, Dec 1, 2010 at 5:18 PM, Hadley Wickham<hadley at rice.edu>  wrote:
>>>>> Perhaps a wider community of R users can weigh in on a
>>>>> policy decision that was implicitly deemed acceptable on this
>>>>> thread. Namely, that it is fine to arbitrarily and
>>>>> for no reason deprecate the contributions of past
>>>>> authors, and as more progress is made, even more
>>>>> disparaging remarks can be added.
>>>> What is disparaging about saying "a small portion of the code is based
>>>> on code written during 2005 and 2006 by Dominick Samperi"? I read this
>>>> as a factual statement saying that the current version of Rcpp is
>>>> based on, in a small way, your earlier work.
>>>>
>>>> For reference, a disparaging comment would be something like: "This
>>>> package was based code written by Hadley Wickham that made my eyes
>>>> bleed", or "The development of this package was driven by the godawful
>>>> code that Hadley wrote".
>>>>
>>>
>>> Its very difficult to truly assess relative contributions when you mix
>>> in design, coding, level of effort, promotion, etc.   I would not
>>> focus on the single word "disparaging".  I think the poster simply
>>> used the wrong word and perhaps what he meant was more along the lines
>>> of: as the creator of the package he presumably set the design (or
>>> significant elements of the design) for all subsequent work and in
>>> that respect even if its true that the number of lines he generated is
>>> relatively small compared to the current package, that phrase gives
>>> the misleading impression that his contribution was also small.  There
>>> is a difference between something that is true and non-misleading and
>>> something that is true and misleading.
>> There is an important element of this discussion that is being overlooked,
>> namely, the timing. If indeed my contributions were minimal (and they
>> were not for the reasons you suggest) then why was it decided now,
>> for this particular release, to update my status? Why not the last
>> release? What changed? There were only a few new features added
>> to this release. What made the difference?
>>
>> More importantly, as I suggested in my original post, this practice
>> sets an absurd precedent, one that motivated Stallman to write
>> the GNU manifesto (where he used the oxygen mask metaphor).
>> Should we reevaluate all contributors, present or past, and
>> adjust the level of deprecation on the
>> author line appropriately before each release?
>>
>> I suspect that I have contributed far more than some of the
>> people listed on the author line. Does this mean that their
>> contributions should be discounted accordingly? If not,
>> why not?
>>
>> Thanks for your courage. People who send supportive comments
>> tend to send them off-list, not wanting to state them publicly.
>>
> Just to be clear I have never used the package and am not truly
> commenting on this particular case but only the general ideas in this
> thread.  Also I was not suggesting that the comments in the code were
> purposefully misleading, only that they might be misleading since they
> could be interpreted in terms of contribution even though they are
> stated in terms of lines of code.  The author of the phrase may very
> well have felt that the current team had done a lot of work to add
> design ideas and develop and promote the software but perhaps the
> unfortunate way in how it was expressed in that phrase that came out
> as a seeming comment on the original creator's contribution rather
> than the intended comment on their own, presumably also significant,
> contribution.
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From djsamperi at gmail.com  Thu Dec  2 02:24:05 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 1 Dec 2010 20:24:05 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
Message-ID: <AANLkTimCE8L9TVuysa9mAUtvSDNFq18gfex6ei+_Sc_c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101201/0b9938fc/attachment.pl>

From djsamperi at gmail.com  Thu Dec  2 02:48:44 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 1 Dec 2010 20:48:44 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <4CF6F43D.9010501@structuremonitoring.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<4CF6F43D.9010501@structuremonitoring.com>
Message-ID: <AANLkTikDFzkTkpk2W2-to_H_Z1sPgsbp5FwagLGe1fJo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101201/56cddbe4/attachment.pl>

From adrian_d at eskimo.com  Thu Dec  2 05:29:04 2010
From: adrian_d at eskimo.com (Adrian Dragulescu)
Date: Wed, 1 Dec 2010 20:29:04 -0800 (PST)
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1012012006450.14603@shell.eskimo.com>


Dominick,

I don't use the Rcpp package but I have been aware of the changes made to 
the package over the years.

I don't see what you are after.  I don't consider the mention about 
your contribution in the authors section disparaging in ANY way.  It seems 
reasonable that as the code base grows, your initial contribution to have 
a smaller and smaller share.  That's all it says.  If you would start 
contributing again to the package development, I'm sure that line can be 
changed.  Romain has gone from 0% to a sizeable share in a quick period 
with some great contributions.  Other authors seem to find a way to 
contribute to the project too.

If it's peer recognition you're after, everybody on this list is already 
aware that you're the original developer of the package.  I personally 
still have a good memory so I don't need another reminder email on this 
topic.

I'm sure there are other projects that you can work on, alone or with 
collaborators, that would benefit the R community.

Cheers, 
Adrian




On Wed, 1 Dec 2010, Dominick Samperi wrote:

> This post asks members of the R community, users and developers,
> to comment on issues related to the GNU Public License
> and R community policies more generally.
>
> The GPL says very little about protecting the the rights of original
> contributors by not disseminating  misleading information about them.
> Indeed, for pragmatic reasons it effectively assumes that original authors
> have no rights regarding their GPL-ed software, and it implicitly leaves
> it up to the community of developers and users to conduct themselves in a
> fair and
> reasonable manner.
>
> After discussing these matters with Richard Stallman I think
> we more-or-less agreed that a GPL "copyright" notice is nothing
> more than a way to deputise people to serve as protectors of the
> principles of the Free Software Foundation (FSF). It has nothing to
> do with protecting the "rights" or the "ideas" of original
> contributors. There is no peer review, no requirement to
> explain your contributions, and anybody can essentially
> do as they please with the software provided they retain
> the copyright/FSF deputy notice---of course, you can
> always work-around this last restriction by modifying the
> implementation and placing it in a new file, because
> nobody is checking (GPL doesn't require it).
>
> The GPL is all about "freedom", not responsibility. It is entirely
> focused on "deregulation", not on the protection of intellectual
> property or professional reputations. It serves the useful purpose
> of making great software more widely available, but it does not
> dictate how people should behave and should not be used
> as a moral compass.  (See recent book titled
> "You are not a gadget: a manifesto", a rejoinder to the
> GNU manifesto.)
>
> As a counterbalance I think the community of developers and
> users need to play a more active role in the evolution of
> shared values and expectations. In this spirit I respectfully request
> that the R community consider the following.
>
> The author line of the latest release of the R package
> Rcpp (0.8.9) was revised as follows:
>
> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>
> To: "a small portion of the code is based on code written during 2005 and
> 2006 by Dominick Samperi"
>
> As it is highly unusual (and largely impossible) to quantify the relative
> size of the the contribution made by each author of GPL'ed software, this
> has
> effectively changed an acknowledgment into a disparaging remark. It
> is also misleading, because I am the original creator of the Rcpp library
> and package (it was forked by Dirk Eddelbuettel and is now effectively
> part of R core development). Incidentally, the README file for
> Rcpp 0.6.7 shows that my contributions and influence were not
> confined to the period 2005-2006.
>
> A look at the change history of Rcpp would quickly reveal that to be
> fair other authors of Rcpp (and perhaps other R package authors)
> should have their contributions qualified with "a small portion of the
> code",
> or "administered by", but this is precisely the kind of monitoring that
> inspired Richard Stallman to say we must "chuck the masks" in the
> GNU Manifesto.
>
> It is obviously a great benefit for the R community to have Rcpp actively
> supported by the R core team. I am very grateful for this. What I do
> have a problem with is the fact that my contributions are disparaged
> by people who have benefited from my past work.
>
> It seems to me that there are two possible resolutions. First, if my
> name is used in the Rcpp package it should be used to provide fair,
> accurate, and courteous acknowledgement for my past contributions.
> Second, if this is not possible, then my name should not be used at all.
> If the second option is selected then the only place my name should
> appear is in the copyright ("deputy") notices.
>
> Incidentally, the fact that the word "copyright" is profoundly misleading in
> the context of GPL is not a new idea, and the word "copyleft" is
> sometimes used instead. But copyleft is not used in source files
> because this would unlink GPL from the well-established legal
> framework associated with "copyright", making it more difficult for
> the FSF to enforce its principles (the critical link is provided by
> the copyright holders or "deputies").
>
> A final clarification: authors of original works do retain a legal
> copyright on  their original work in the sense that they are free
> to modify this work and release it as non-free software (or
> under a different free license), but this has no effect on the
> version that was released under GPL. The latter version and
> all of its progeny belong to the public (or to the FSF from
> a legal point of view).
>
> Please feel free to express your opinion on these matters.
>
> Thanks,
> Dominick
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Thu Dec  2 07:30:22 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Dec 2010 06:30:22 +0000 (GMT)
Subject: [Rd] Install package 'Matrix' problem
In-Reply-To: <5685E4FBA752A441B1975A77A77CD64824E371F8D9@DCPWVMBXC1VS2.mdanderson.edu>
References: <5685E4FBA752A441B1975A77A77CD64824E371F8D9@DCPWVMBXC1VS2.mdanderson.edu>
Message-ID: <alpine.LFD.2.00.1012020612240.13083@gannet.stats.ox.ac.uk>

We need more information, at the minimum the line which compiled 
CHMfactor.o.  Can you make the install log (you may need to run this 
again) and your etc/Makeconf available on-line?

At first sight your C++ compiler is missing -m64: the R-admin manual 
says

'For a 64-bit target add -m64 to the compiler macros and use something 
like LDFLAGS=-L/opt/csw/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 
as appropriate.'

I see I used

CC="cc -xc99 -m64"
CFLAGS="-O -xlibmieee"
F77="f95 -m64"
FFLAGS=-O4
CXX="CC -m64 -library=stlport4"
CXXFLAGS=-O
FC=$F77
FCFLAGS=$FFLAGS
LDFLAGS=-L/usr/local/lib/sparcv9
FCLIBS="-lfai -lfsu -lfai2"

in config.site.  And BTW, it is always worth checking the manuals of 
current R-patched: your compiler postdates the pre-release period for 
R 2.12.0.

On Wed, 1 Dec 2010, Zhang,Jun wrote:

> 64-bit R-2.12.0 was installed on Sun SPARC Solaris 10. Compiler used is solstudio12.2. Attached is the configure script.
> I then tried to install a recommended package called Matrix. The compilation failed with the following messages,
> .......

> CC -library=stlport4 -G -L/opt/csw/lib/sparcv9 
> -L/opt/solstudio12.2/prod/lib/v9 -o Matrix.so CHMfactor.o Csparse.o 
> TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o cs_utils.o 
> dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o dppMatrix.o 
> dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o 
> dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o 
> sparseQR.o abIndex.o CHOLMOD.a COLAMD.a AMD.a 
> -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRlapack 
> -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRblas -lifai -lsunimath -lfai 
> -lfai2 -lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai 
> -lfui -lfsu -lsunmath -lmtsk -lm

> ld: fatal: file CHMfactor.o: wrong ELF class: ELFCLASS64
> ld: fatal: File processing errors. No output written to Matrix.so
> make: *** [Matrix.so] Error 2
> ERROR: compilation failed for package 'Matrix'
> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/Matrix'
>
> Some article suggests theorectically that ld or compiler driver

You need to give references for what you are quoting here (there is 
much misinformation on the Internet).  I suspect it is simply that you 
didn't specify the C++ compiler correctly.

> first sees a component .o file which is 32-bit (don't know which one 
> here), and decides that other components should be 32-bit, too, 
> hence the error message, since CHMfactor.o must be a 64-bit object. 
> I just don't know what is the practical way to avoid this situation. 
> I guess I'm posting in the right list, can somebody help?

Maybe, but really your local IT support is there to help your use of 
your OS: this is a Solaris issue, not an R one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From seanpor at acm.org  Thu Dec  2 08:45:16 2010
From: seanpor at acm.org (Sean O'Riordain)
Date: Thu, 2 Dec 2010 07:45:16 +0000
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <Pine.LNX.4.64.1012012006450.14603@shell.eskimo.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<Pine.LNX.4.64.1012012006450.14603@shell.eskimo.com>
Message-ID: <AANLkTikNNVcPuEdz6barjzEshwkKQ2jGEADfN2wU63ve@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/ad55b8af/attachment.pl>

From gavin.simpson at ucl.ac.uk  Thu Dec  2 08:51:42 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 02 Dec 2010 07:51:42 +0000
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTimCE8L9TVuysa9mAUtvSDNFq18gfex6ei+_Sc_c@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
	<AANLkTimCE8L9TVuysa9mAUtvSDNFq18gfex6ei+_Sc_c@mail.gmail.com>
Message-ID: <1291276302.2454.24.camel@desktop.localdomain>

On Wed, 2010-12-01 at 20:24 -0500, Dominick Samperi wrote:
<snip />
> > Just to be clear I have never used the package and am not truly
> > commenting on this particular case but only the general ideas in this
> > thread.  Also I was not suggesting that the comments in the code were
> > purposefully misleading, only that they might be misleading since they
> > could be interpreted in terms of contribution even though they are
> > stated in terms of lines of code.  The author of the phrase may very
> > well have felt that the current team had done a lot of work to add
> > design ideas and develop and promote the software but perhaps the
> > unfortunate way in how it was expressed in that phrase that came out
> > as a seeming comment on the original creator's contribution rather
> > than the intended comment on their own, presumably also significant,
> > contribution.
> >
> 
> There is no reason given why this
> should happen now, at this moment, and no explanation why
> the same standard should not be applied to other package authors,
> including other authors of Rcpp.

Dominick,

You feel you are the aggrieved party so of course you will find
conspiracy in the timing. An equally plausible explanation is that the
current set of developers on Rcpp intended to alter the "contributions",
to better reflect the current state of the package, some time ago but it
slipped through the cracks.

You are predisposed to see the bad where non may exist. But also, you
should be discussing this in private with the package developers.

There is nothing in this thread of relevance to R-devel (other than to
publicly refute your claims so as to balance the record should someone
come across this in the archives) as this has nothing to do with
developing R. There is no-one here who can speak for the "R Community",
because such a thing is not a concrete entity - you will just get the
opinions of individuals. It is to the credit of this list (R-Devel) that
this has not descended into a vitriolic stream of claim and counter
claim.

As for your claims about R Core, Doug has succinctly and clearly
addressed your claims in that regard, regardless what you may personally
believe. Rcpp is *not* an official product of the R Foundation, and
neither is it part of the R distribution.

Can we please take this elsewhere?

Gavin.

> This is not about this particular case, it is about "general ideas"
> along the lines of your original post.
> 
> Thanks,
> Dominick
> 
> 
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gavin.simpson at ucl.ac.uk  Thu Dec  2 08:55:38 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 02 Dec 2010 07:55:38 +0000
Subject: [Rd] Reordering entries in package manual PDF's
In-Reply-To: <4FEBB24215A35547BC21FAB42479B21F06B4FE69E8@cscexmb01.csc.local>
References: <4CF63F20.5030803@csc.fi>, <4CF645F5.4050301@gmail.com>
	, <4FEBB24215A35547BC21FAB42479B21F06B4FE69E7@cscexmb01.csc.local>
	<4FEBB24215A35547BC21FAB42479B21F06B4FE69E8@cscexmb01.csc.local>
Message-ID: <1291276538.2454.27.camel@desktop.localdomain>

On Wed, 2010-12-01 at 19:25 +0200, Aleksi Kallio wrote:
> Hi again,
> 
> And sorry for the spam.
> 
> > So now the output I'm getting is "good enough". I would still like
> to reorder functions so that they appear in a more logical order, so
> if anyone has ideas, please share!

The manual isn't meant to be a manual in the sense of the thing you get
to help you operate your VCR. It is meant more as a reference manual
hence the alphabetical ordering of functions.

If you want to produce something the guides the user through the use of
your package, consider adding a vignette to your package. Details of
vignettes can be found in the Writing R Extensions manual.

G

> Newer R versions also add an index page at the end. In my case it is
> obsolete, so ideas on how to get rid of it are appreciated.
> 
> A pointer to an in-depth technical description of the manual
> generation process would help, as hacking these kinds of things would
> be probably quite easy. So far I have not been able to Google anything
> relevant.
> 
> Cheers,
> Aleksi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From djsamperi at gmail.com  Thu Dec  2 09:00:04 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 03:00:04 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTikNNVcPuEdz6barjzEshwkKQ2jGEADfN2wU63ve@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<Pine.LNX.4.64.1012012006450.14603@shell.eskimo.com>
	<AANLkTikNNVcPuEdz6barjzEshwkKQ2jGEADfN2wU63ve@mail.gmail.com>
Message-ID: <AANLkTim64KZK+aX2x71MJ9bth+Kq5YkPqGXK4kzGdguQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/fa22f7e8/attachment.pl>

From djsamperi at gmail.com  Thu Dec  2 09:27:58 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 03:27:58 -0500
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <1291276302.2454.24.camel@desktop.localdomain>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
	<AANLkTimCE8L9TVuysa9mAUtvSDNFq18gfex6ei+_Sc_c@mail.gmail.com>
	<1291276302.2454.24.camel@desktop.localdomain>
Message-ID: <AANLkTimv1Tbd3dYsEpjgaBSfLwjZcnG6V88LjLHpxg7C@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/bf98dfb4/attachment.pl>

From landronimirc at gmail.com  Thu Dec  2 10:32:37 2010
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 2 Dec 2010 10:32:37 +0100
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
Message-ID: <AANLkTin4HJzxXZp7LhwMvZZN=+Ay0YZHqX=OfhcF65G6@mail.gmail.com>

Dear all

On Wed, Dec 1, 2010 at 7:21 PM, Dominick Samperi <djsamperi at gmail.com> wrote:
> The author line of the latest release of the R package
> Rcpp (0.8.9) was revised as follows:
>
> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>
> To: "a small portion of the code is based on code written during 2005 and
> 2006 by Dominick Samperi"
>
>From the info given in the thread, personally I'm sympathetic to
Dominick's complaint: the latter message is no proper way to
acknowledge the original author of the package. As I see it, the
project either:
- explicitly mentions the original author and the active (current)
contributors (and perhaps previous ones), or
- lines up all previous contributors in a line and singles out the
active contributors

But saying that the original author's contributions represented some
coding of random importance (implied in the message above), only a
subset of which made it to the current release, sounds disparaging to
my ears, too.

My humble opinion
Liviu


From plummerM at iarc.fr  Thu Dec  2 15:20:54 2010
From: plummerM at iarc.fr (Martyn Plummer)
Date: Thu, 02 Dec 2010 15:20:54 +0100
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
Message-ID: <1291299654.7962.495.camel@braque.iarc.fr>

Dear Dominick,

The R community does not have a conflict resolution mechanism.  We are
quite used to disputes that end with one party, usually a recognized
authority, saying "No, you are objectively, verifiably wrong".   We
cannot, as a group, deal with anything else.

Everybody knows that you have an acrimonious relationship with the
current developers of Rcpp (and if they don't then a cursory look at the
rcpp-devel archives will confirm this).  The issue of the acknowledgment
that you are complaining about is merely a symptom of the further
deterioration of this relationship.   Appeals to authority or public
opinion are not going to help you obtain satisfaction.

Having your free software taken up and developed by other people is not
the worst thing that can happen.  For a free software developer, the
worst thing that can happen is that they get run over by a proverbial
bus and their software dies with them.

Martyn

On Wed, 2010-12-01 at 13:21 -0500, Dominick Samperi wrote:
> This post asks members of the R community, users and developers,
> to comment on issues related to the GNU Public License
> and R community policies more generally.
> 
> The GPL says very little about protecting the the rights of original
> contributors by not disseminating  misleading information about them.
> Indeed, for pragmatic reasons it effectively assumes that original authors
> have no rights regarding their GPL-ed software, and it implicitly leaves
> it up to the community of developers and users to conduct themselves in a
> fair and
> reasonable manner.
> 
> After discussing these matters with Richard Stallman I think
> we more-or-less agreed that a GPL "copyright" notice is nothing
> more than a way to deputise people to serve as protectors of the
> principles of the Free Software Foundation (FSF). It has nothing to
> do with protecting the "rights" or the "ideas" of original
> contributors. There is no peer review, no requirement to
> explain your contributions, and anybody can essentially
> do as they please with the software provided they retain
> the copyright/FSF deputy notice---of course, you can
> always work-around this last restriction by modifying the
> implementation and placing it in a new file, because
> nobody is checking (GPL doesn't require it).
> 
> The GPL is all about "freedom", not responsibility. It is entirely
> focused on "deregulation", not on the protection of intellectual
> property or professional reputations. It serves the useful purpose
> of making great software more widely available, but it does not
> dictate how people should behave and should not be used
> as a moral compass.  (See recent book titled
> "You are not a gadget: a manifesto", a rejoinder to the
> GNU manifesto.)
> 
> As a counterbalance I think the community of developers and
> users need to play a more active role in the evolution of
> shared values and expectations. In this spirit I respectfully request
> that the R community consider the following.
> 
> The author line of the latest release of the R package
> Rcpp (0.8.9) was revised as follows:
> 
> From: "based on code written during 2005 and 2006 by Dominick Samperi"
> 
> To: "a small portion of the code is based on code written during 2005 and
> 2006 by Dominick Samperi"
> 
> As it is highly unusual (and largely impossible) to quantify the relative
> size of the the contribution made by each author of GPL'ed software, this
> has
> effectively changed an acknowledgment into a disparaging remark. It
> is also misleading, because I am the original creator of the Rcpp library
> and package (it was forked by Dirk Eddelbuettel and is now effectively
> part of R core development). Incidentally, the README file for
> Rcpp 0.6.7 shows that my contributions and influence were not
> confined to the period 2005-2006.
> 
> A look at the change history of Rcpp would quickly reveal that to be
> fair other authors of Rcpp (and perhaps other R package authors)
> should have their contributions qualified with "a small portion of the
> code",
> or "administered by", but this is precisely the kind of monitoring that
> inspired Richard Stallman to say we must "chuck the masks" in the
> GNU Manifesto.
> 
> It is obviously a great benefit for the R community to have Rcpp actively
> supported by the R core team. I am very grateful for this. What I do
> have a problem with is the fact that my contributions are disparaged
> by people who have benefited from my past work.
> 
> It seems to me that there are two possible resolutions. First, if my
> name is used in the Rcpp package it should be used to provide fair,
> accurate, and courteous acknowledgement for my past contributions.
> Second, if this is not possible, then my name should not be used at all.
> If the second option is selected then the only place my name should
> appear is in the copyright ("deputy") notices.
> 
> Incidentally, the fact that the word "copyright" is profoundly misleading in
> the context of GPL is not a new idea, and the word "copyleft" is
> sometimes used instead. But copyleft is not used in source files
> because this would unlink GPL from the well-established legal
> framework associated with "copyright", making it more difficult for
> the FSF to enforce its principles (the critical link is provided by
> the copyright holders or "deputies").
> 
> A final clarification: authors of original works do retain a legal
> copyright on  their original work in the sense that they are free
> to modify this work and release it as non-free software (or
> under a different free license), but this has no effect on the
> version that was released under GPL. The latter version and
> all of its progeny belong to the public (or to the FSF from
> a legal point of view).
> 
> Please feel free to express your opinion on these matters.
> 
> Thanks,
> Dominick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From spencer.graves at structuremonitoring.com  Thu Dec  2 16:21:37 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 02 Dec 2010 07:21:37 -0800
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <1291299654.7962.495.camel@braque.iarc.fr>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
Message-ID: <4CF7B981.70404@structuremonitoring.com>

On 12/2/2010 6:20 AM, Martyn Plummer wrote:
> Dear Dominick,
>
> The R community does not have a conflict resolution mechanism.  We are
> quite used to disputes that end with one party, usually a recognized
> authority, saying "No, you are objectively, verifiably wrong".   We
> cannot, as a group, deal with anything else.
>
> Everybody knows that you have an acrimonious relationship with the
> current developers of Rcpp (and if they don't then a cursory look at the
> rcpp-devel archives will confirm this).  The issue of the acknowledgment
> that you are complaining about is merely a symptom of the further
> deterioration of this relationship.   Appeals to authority or public
> opinion are not going to help you obtain satisfaction.
>
> Having your free software taken up and developed by other people is not
> the worst thing that can happen.  For a free software developer, the
> worst thing that can happen is that they get run over by a proverbial
> bus and their software dies with them.

Somewhere close to the worst is that no one every uses your software.
> Martyn
>
> On Wed, 2010-12-01 at 13:21 -0500, Dominick Samperi wrote:
>> This post asks members of the R community, users and developers,
>> to comment on issues related to the GNU Public License
>> and R community policies more generally.
>>
>> The GPL says very little about protecting the the rights of original
>> contributors by not disseminating  misleading information about them.
>> Indeed, for pragmatic reasons it effectively assumes that original authors
>> have no rights regarding their GPL-ed software, and it implicitly leaves
>> it up to the community of developers and users to conduct themselves in a
>> fair and
>> reasonable manner.
>>
>> After discussing these matters with Richard Stallman I think
>> we more-or-less agreed that a GPL "copyright" notice is nothing
>> more than a way to deputise people to serve as protectors of the
>> principles of the Free Software Foundation (FSF). It has nothing to
>> do with protecting the "rights" or the "ideas" of original
>> contributors. There is no peer review, no requirement to
>> explain your contributions, and anybody can essentially
>> do as they please with the software provided they retain
>> the copyright/FSF deputy notice---of course, you can
>> always work-around this last restriction by modifying the
>> implementation and placing it in a new file, because
>> nobody is checking (GPL doesn't require it).
>>
>> The GPL is all about "freedom", not responsibility. It is entirely
>> focused on "deregulation", not on the protection of intellectual
>> property or professional reputations. It serves the useful purpose
>> of making great software more widely available, but it does not
>> dictate how people should behave and should not be used
>> as a moral compass.  (See recent book titled
>> "You are not a gadget: a manifesto", a rejoinder to the
>> GNU manifesto.)
>>
>> As a counterbalance I think the community of developers and
>> users need to play a more active role in the evolution of
>> shared values and expectations. In this spirit I respectfully request
>> that the R community consider the following.
>>
>> The author line of the latest release of the R package
>> Rcpp (0.8.9) was revised as follows:
>>
>> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>>
>> To: "a small portion of the code is based on code written during 2005 and
>> 2006 by Dominick Samperi"
>>
>> As it is highly unusual (and largely impossible) to quantify the relative
>> size of the the contribution made by each author of GPL'ed software, this
>> has
>> effectively changed an acknowledgment into a disparaging remark. It
>> is also misleading, because I am the original creator of the Rcpp library
>> and package (it was forked by Dirk Eddelbuettel and is now effectively
>> part of R core development). Incidentally, the README file for
>> Rcpp 0.6.7 shows that my contributions and influence were not
>> confined to the period 2005-2006.
>>
>> A look at the change history of Rcpp would quickly reveal that to be
>> fair other authors of Rcpp (and perhaps other R package authors)
>> should have their contributions qualified with "a small portion of the
>> code",
>> or "administered by", but this is precisely the kind of monitoring that
>> inspired Richard Stallman to say we must "chuck the masks" in the
>> GNU Manifesto.
>>
>> It is obviously a great benefit for the R community to have Rcpp actively
>> supported by the R core team. I am very grateful for this. What I do
>> have a problem with is the fact that my contributions are disparaged
>> by people who have benefited from my past work.
>>
>> It seems to me that there are two possible resolutions. First, if my
>> name is used in the Rcpp package it should be used to provide fair,
>> accurate, and courteous acknowledgement for my past contributions.
>> Second, if this is not possible, then my name should not be used at all.
>> If the second option is selected then the only place my name should
>> appear is in the copyright ("deputy") notices.
>>
>> Incidentally, the fact that the word "copyright" is profoundly misleading in
>> the context of GPL is not a new idea, and the word "copyleft" is
>> sometimes used instead. But copyleft is not used in source files
>> because this would unlink GPL from the well-established legal
>> framework associated with "copyright", making it more difficult for
>> the FSF to enforce its principles (the critical link is provided by
>> the copyright holders or "deputies").
>>
>> A final clarification: authors of original works do retain a legal
>> copyright on  their original work in the sense that they are free
>> to modify this work and release it as non-free software (or
>> under a different free license), but this has no effect on the
>> version that was released under GPL. The latter version and
>> all of its progeny belong to the public (or to the FSF from
>> a legal point of view).
>>
>> Please feel free to express your opinion on these matters.
>>
>> Thanks,
>> Dominick
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -----------------------------------------------------------------------
> This message and its attachments are strictly confidenti...{{dropped:8}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From djsamperi at gmail.com  Thu Dec  2 16:28:04 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 10:28:04 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <1291299654.7962.495.camel@braque.iarc.fr>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
Message-ID: <AANLkTimBHqwfcyDk2j=xJ1S7=O7QrbpC=MD6DG0kWoRv@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/895003c0/attachment.pl>

From djsamperi at gmail.com  Thu Dec  2 16:31:47 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 10:31:47 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <4CF7B981.70404@structuremonitoring.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
Message-ID: <AANLkTin7jVHRVdNUAt5wFVpMEQ9+c5HJDuMF+7TR4hDa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/1b4ce25b/attachment.pl>

From rvaradhan at jhmi.edu  Thu Dec  2 16:36:30 2010
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 2 Dec 2010 10:36:30 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <4CF7B981.70404@structuremonitoring.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
Message-ID: <002501cb9236$b0c634a0$12529de0$@edu>

Yes, I agree, Spencer.  The worst thing that can happen is for your
ideas/creations to go completely unnoticed.

Here is what David Hume had to say about how his first philosophical work
(Treatise of Human Nature) was received:

"Never literary attempt was more unfortunate than my Treatise of Human
Nature. It fell dead-born from the press, without reaching such distinction
as even to excite a murmur among the zealots"

So, Dominick - please cheer up and try to find some solace in that your work
has had an influence on the R community!

Best,
Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns
Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Spencer Graves
Sent: Thursday, December 02, 2010 10:22 AM
To: Martyn Plummer
Cc: r-devel at r-project.org; rcpp-devel
Subject: Re: [Rd] GPL and R Community Policies (Rcpp)

On 12/2/2010 6:20 AM, Martyn Plummer wrote:
> Dear Dominick,
>
> The R community does not have a conflict resolution mechanism.  We are
> quite used to disputes that end with one party, usually a recognized
> authority, saying "No, you are objectively, verifiably wrong".   We
> cannot, as a group, deal with anything else.
>
> Everybody knows that you have an acrimonious relationship with the
> current developers of Rcpp (and if they don't then a cursory look at the
> rcpp-devel archives will confirm this).  The issue of the acknowledgment
> that you are complaining about is merely a symptom of the further
> deterioration of this relationship.   Appeals to authority or public
> opinion are not going to help you obtain satisfaction.
>
> Having your free software taken up and developed by other people is not
> the worst thing that can happen.  For a free software developer, the
> worst thing that can happen is that they get run over by a proverbial
> bus and their software dies with them.

Somewhere close to the worst is that no one every uses your software.
> Martyn
>
> On Wed, 2010-12-01 at 13:21 -0500, Dominick Samperi wrote:
>> This post asks members of the R community, users and developers,
>> to comment on issues related to the GNU Public License
>> and R community policies more generally.
>>
>> The GPL says very little about protecting the the rights of original
>> contributors by not disseminating  misleading information about them.
>> Indeed, for pragmatic reasons it effectively assumes that original
authors
>> have no rights regarding their GPL-ed software, and it implicitly leaves
>> it up to the community of developers and users to conduct themselves in a
>> fair and
>> reasonable manner.
>>
>> After discussing these matters with Richard Stallman I think
>> we more-or-less agreed that a GPL "copyright" notice is nothing
>> more than a way to deputise people to serve as protectors of the
>> principles of the Free Software Foundation (FSF). It has nothing to
>> do with protecting the "rights" or the "ideas" of original
>> contributors. There is no peer review, no requirement to
>> explain your contributions, and anybody can essentially
>> do as they please with the software provided they retain
>> the copyright/FSF deputy notice---of course, you can
>> always work-around this last restriction by modifying the
>> implementation and placing it in a new file, because
>> nobody is checking (GPL doesn't require it).
>>
>> The GPL is all about "freedom", not responsibility. It is entirely
>> focused on "deregulation", not on the protection of intellectual
>> property or professional reputations. It serves the useful purpose
>> of making great software more widely available, but it does not
>> dictate how people should behave and should not be used
>> as a moral compass.  (See recent book titled
>> "You are not a gadget: a manifesto", a rejoinder to the
>> GNU manifesto.)
>>
>> As a counterbalance I think the community of developers and
>> users need to play a more active role in the evolution of
>> shared values and expectations. In this spirit I respectfully request
>> that the R community consider the following.
>>
>> The author line of the latest release of the R package
>> Rcpp (0.8.9) was revised as follows:
>>
>> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>>
>> To: "a small portion of the code is based on code written during 2005 and
>> 2006 by Dominick Samperi"
>>
>> As it is highly unusual (and largely impossible) to quantify the relative
>> size of the the contribution made by each author of GPL'ed software, this
>> has
>> effectively changed an acknowledgment into a disparaging remark. It
>> is also misleading, because I am the original creator of the Rcpp library
>> and package (it was forked by Dirk Eddelbuettel and is now effectively
>> part of R core development). Incidentally, the README file for
>> Rcpp 0.6.7 shows that my contributions and influence were not
>> confined to the period 2005-2006.
>>
>> A look at the change history of Rcpp would quickly reveal that to be
>> fair other authors of Rcpp (and perhaps other R package authors)
>> should have their contributions qualified with "a small portion of the
>> code",
>> or "administered by", but this is precisely the kind of monitoring that
>> inspired Richard Stallman to say we must "chuck the masks" in the
>> GNU Manifesto.
>>
>> It is obviously a great benefit for the R community to have Rcpp actively
>> supported by the R core team. I am very grateful for this. What I do
>> have a problem with is the fact that my contributions are disparaged
>> by people who have benefited from my past work.
>>
>> It seems to me that there are two possible resolutions. First, if my
>> name is used in the Rcpp package it should be used to provide fair,
>> accurate, and courteous acknowledgement for my past contributions.
>> Second, if this is not possible, then my name should not be used at all.
>> If the second option is selected then the only place my name should
>> appear is in the copyright ("deputy") notices.
>>
>> Incidentally, the fact that the word "copyright" is profoundly misleading
in
>> the context of GPL is not a new idea, and the word "copyleft" is
>> sometimes used instead. But copyleft is not used in source files
>> because this would unlink GPL from the well-established legal
>> framework associated with "copyright", making it more difficult for
>> the FSF to enforce its principles (the critical link is provided by
>> the copyright holders or "deputies").
>>
>> A final clarification: authors of original works do retain a legal
>> copyright on  their original work in the sense that they are free
>> to modify this work and release it as non-free software (or
>> under a different free license), but this has no effect on the
>> version that was released under GPL. The latter version and
>> all of its progeny belong to the public (or to the FSF from
>> a legal point of view).
>>
>> Please feel free to express your opinion on these matters.
>>
>> Thanks,
>> Dominick
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -----------------------------------------------------------------------
> This message and its attachments are strictly confidenti...{{dropped:8}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Thu Dec  2 16:47:05 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 2 Dec 2010 16:47:05 +0100
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTin7jVHRVdNUAt5wFVpMEQ9+c5HJDuMF+7TR4hDa@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<AANLkTin7jVHRVdNUAt5wFVpMEQ9+c5HJDuMF+7TR4hDa@mail.gmail.com>
Message-ID: <AANLkTimqFdDHWJqfn+WipX6E2Eg3bvM7MyuWrE=rdRMM@mail.gmail.com>

On Thu, Dec 2, 2010 at 4:31 PM, Dominick Samperi <djsamperi at gmail.com> wrote:
>
> Worst yet is having to compete with your own work.
>
About which competition are we talking then? I'm sorry, but the vast
majority of the 70000 lines of code of the rcpp are not your work. And
honestly, I don't know of any package that would be able to compete
with the rcpp as it is now. Great package by the way, Dirk, Romain and
the other contributors made something really nice from it.

Cheers
Joris
-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From djsamperi at gmail.com  Thu Dec  2 17:01:11 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 11:01:11 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTimqFdDHWJqfn+WipX6E2Eg3bvM7MyuWrE=rdRMM@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<AANLkTin7jVHRVdNUAt5wFVpMEQ9+c5HJDuMF+7TR4hDa@mail.gmail.com>
	<AANLkTimqFdDHWJqfn+WipX6E2Eg3bvM7MyuWrE=rdRMM@mail.gmail.com>
Message-ID: <AANLkTimnKRYRVLm45dUfu0PNBJTxBvRvanyv4KOuLASo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/49d1d9df/attachment.pl>

From shane.conway at gmail.com  Thu Dec  2 17:09:23 2010
From: shane.conway at gmail.com (Shane Conway)
Date: Thu, 2 Dec 2010 11:09:23 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTimqFdDHWJqfn+WipX6E2Eg3bvM7MyuWrE=rdRMM@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<AANLkTin7jVHRVdNUAt5wFVpMEQ9+c5HJDuMF+7TR4hDa@mail.gmail.com>
	<AANLkTimqFdDHWJqfn+WipX6E2Eg3bvM7MyuWrE=rdRMM@mail.gmail.com>
Message-ID: <AANLkTikvCU_Mp6Pq_7yaGCNFt76A0OwptJ-mJH+gg6en@mail.gmail.com>

Your original question is predicated on the notion that people are
"disseminating misleading information about" you, with this phrase: "a
small portion of the code is based on code written during 2005 and
2006 by Dominick Samperi".  While it may be difficult to qualify
contributions to a joint project, there is absolutely nothing
misleading in this.  It is a statement of fact.  I simply read it to
imply that all the other names listed are still actively involved, and
that the code has evolved significantly since 2006.

As others have already said: please take this up with the package
authors off this list.  There is no basis for trying to introduce a
general discussion with a broader audience about licensing, copyright,
etc. around this issue.

As a side note: I think that the Rcpp package authors should give
serious consideration to appending "The development of this package
was driven by the godawful code that Hadley wrote" to the end of the
acknowledgements.


On Thu, Dec 2, 2010 at 10:47 AM, Joris Meys <jorismeys at gmail.com> wrote:
> On Thu, Dec 2, 2010 at 4:31 PM, Dominick Samperi <djsamperi at gmail.com> wrote:
>>
>> Worst yet is having to compete with your own work.
>>
> About which competition are we talking then? I'm sorry, but the vast
> majority of the 70000 lines of code of the rcpp are not your work. And
> honestly, I don't know of any package that would be able to compete
> with the rcpp as it is now. Great package by the way, Dirk, Romain and
> the other contributors made something really nice from it.
>
> Cheers
> Joris
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Thu Dec  2 17:12:45 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Dec 2010 17:12:45 +0100
Subject: [Rd] [Rcpp-devel] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTimv1Tbd3dYsEpjgaBSfLwjZcnG6V88LjLHpxg7C@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291229176.22825.138.camel@prometheus.geog.ucl.ac.uk>
	<AANLkTin7FvHxY-QwUzEcuggd8bza6U-c-mF3mNh2Aqee@mail.gmail.com>
	<AANLkTikDVXzzkQGHs9SgG-KgeAc9=DetOzcta-q2H7-m@mail.gmail.com>
	<AANLkTi=chJfUkKaNQep5wjxtdvTQxMhW2QqyYT+u-ndC@mail.gmail.com>
	<AANLkTinkyV1mWMiUmq6GxGdKV2OGcBtADVMTi0TbvL1m@mail.gmail.com>
	<AANLkTinOEUO=PgO=Ks=5PmqJvpzWuOXZDooMQ_-3iMWd@mail.gmail.com>
	<AANLkTin5qUm17-LRSi8p1S0idznOFHKw9D3LzekaZaM2@mail.gmail.com>
	<AANLkTinBdr9LfabvP_xbO-NiZmTaPyP2LG_=Q3HXBJ6u@mail.gmail.com>
	<AANLkTimCE8L9TVuysa9mAUtvSDNFq18gfex6ei+_Sc_c@mail.gmail.com>
	<1291276302.2454.24.camel@desktop.localdomain>
	<AANLkTimv1Tbd3dYsEpjgaBSfLwjZcnG6V88LjLHpxg7C@mail.gmail.com>
Message-ID: <19703.50557.543971.768747@lynne.math.ethz.ch>

>>>>> Dominick Samperi <djsamperi at gmail.com>
>>>>>     on Thu, 2 Dec 2010 03:27:58 -0500 writes:

    > On Thu, Dec 2, 2010 at 2:51 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk>wrote:
    >> On Wed, 2010-12-01 at 20:24 -0500, Dominick Samperi wrote:
    >> <snip />
    >> > > Just to be clear I have never used the package and am not truly
    >> > > commenting on this particular case but only the general ideas in this
    >> > > thread.  Also I was not suggesting that the comments in the code were
    >> > > purposefully misleading, only that they might be misleading since they
    >> > > could be interpreted in terms of contribution even though they are
    >> > > stated in terms of lines of code.  The author of the phrase may very
    >> > > well have felt that the current team had done a lot of work to add
    >> > > design ideas and develop and promote the software but perhaps the
    >> > > unfortunate way in how it was expressed in that phrase that came out
    >> > > as a seeming comment on the original creator's contribution rather
    >> > > than the intended comment on their own, presumably also significant,
    >> > > contribution.
    >> > >
    >> >
    >> > There is no reason given why this
    >> > should happen now, at this moment, and no explanation why
    >> > the same standard should not be applied to other package authors,
    >> > including other authors of Rcpp.
    >> 
    >> Dominick,
    >> 
    >> You feel you are the aggrieved party so of course you will find
    >> conspiracy in the timing. An equally plausible explanation is that the
    >> current set of developers on Rcpp intended to alter the "contributions",
    >> to better reflect the current state of the package, some time ago but it
    >> slipped through the cracks.
    >> 

    > While we are in the housecleaning mood, perhaps the "contributions"
    > can be reflected even better by removing all references to my name
    > as I have suggested.


    >> 
    >> You are predisposed to see the bad where non may exist. But also, you
    >> should be discussing this in private with the package developers.
    >> 
    >> There is nothing in this thread of relevance to R-devel (other than to
    >> publicly refute your claims so as to balance the record should someone
    >> come across this in the archives) as this has nothing to do with
    >> developing R. There is no-one here who can speak for the "R Community",
    >> because such a thing is not a concrete entity - you will just get the
    >> opinions of individuals. It is to the credit of this list (R-Devel) that
    >> this has not descended into a vitriolic stream of claim and counter
    >> claim.
    >> 
    >> As for your claims about R Core, Doug has succinctly and clearly
    >> addressed your claims in that regard, regardless what you may personally
    >> believe. Rcpp is *not* an official product of the R Foundation, and
    >> neither is it part of the R distribution.
    >> 
    >> Can we please take this elsewhere?
    >> 
    >> Gavin.

Yes, please.
I think Dominick has received several suggestions and has got a few
views from a tiny but not insignificant fraction of "the R
community". 
--> Thanks to all contributors
    ...
    and that should be *it*.

Martin Maechler, ETH Zurich
(Administrator of the R-devel mailing list)


From pdalgd at gmail.com  Thu Dec  2 17:16:42 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Dec 2010 17:16:42 +0100
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <1291299654.7962.495.camel@braque.iarc.fr>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
Message-ID: <1E0CCD5A-C17C-4BEE-9C72-C4D99424C3E3@gmail.com>


On Dec 2, 2010, at 15:20 , Martyn Plummer wrote:

> Everybody knows that you have an acrimonious relationship with the
> current developers of Rcpp (and if they don't then a cursory look at the
> rcpp-devel archives will confirm this).  The issue of the acknowledgment
> that you are complaining about is merely a symptom of the further
> deterioration of this relationship.   Appeals to authority or public
> opinion are not going to help you obtain satisfaction.

Or, to be precise, YOU (Dominick) have offended people so deeply that they feel compelled to state that your original contributions are by now dwarfed by their own efforts. Rationally, it would have been much more sensible for them just to leave the attribution in place and let it grow old all by itself. 

Given that we are not just a Free Software community but also a scientific one, it is quite reasonable to require proper attribution when people take up someone else's earlier work, but that is as far as it goes. It is not in itself an issue that someone picks up "your" ball and runs with it. That is what I see as the rational stance on the matter.

Unfortunately, the trenches by now have been dug so deeply that any attempt of impartial mediation will be seen by both parties as siding with the other.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From cbeleites at units.it  Thu Dec  2 17:24:55 2010
From: cbeleites at units.it (Claudia Beleites)
Date: Thu, 02 Dec 2010 17:24:55 +0100
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTin4HJzxXZp7LhwMvZZN=+Ay0YZHqX=OfhcF65G6@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<AANLkTin4HJzxXZp7LhwMvZZN=+Ay0YZHqX=OfhcF65G6@mail.gmail.com>
Message-ID: <4CF7C857.5020208@units.it>

On 12/02/2010 10:32 AM, Liviu Andronic wrote:
> Dear all
>
> On Wed, Dec 1, 2010 at 7:21 PM, Dominick Samperi<djsamperi at gmail.com>  wrote:
>> The author line of the latest release of the R package
>> Rcpp (0.8.9) was revised as follows:
>>
>> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>>
>> To: "a small portion of the code is based on code written during 2005 and
>> 2006 by Dominick Samperi"
>>
>> From the info given in the thread, personally I'm sympathetic to
> Dominick's complaint: the latter message is no proper way to
> acknowledge the original author of the package. As I see it, the
> project either:
> - explicitly mentions the original author and the active (current)
> contributors (and perhaps previous ones), or
> - lines up all previous contributors in a line and singles out the
> active contributors
- or in this case say that it was forked (when) from (Author)'s (package) (version)
>
> But saying that the original author's contributions represented some
> coding of random importance (implied in the message above), only a
> subset of which made it to the current release, sounds disparaging to
> my ears, too.
>
> My humble opinion
> Liviu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From ggrothendieck at gmail.com  Thu Dec  2 18:29:41 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Dec 2010 12:29:41 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <4CF7C857.5020208@units.it>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<AANLkTin4HJzxXZp7LhwMvZZN=+Ay0YZHqX=OfhcF65G6@mail.gmail.com>
	<4CF7C857.5020208@units.it>
Message-ID: <AANLkTinb0x-m=cuM7PQHOYUQ301NmNLzWvaExKpfr+32@mail.gmail.com>

On Thu, Dec 2, 2010 at 11:24 AM, Claudia Beleites <cbeleites at units.it> wrote:
> On 12/02/2010 10:32 AM, Liviu Andronic wrote:
>>
>> Dear all
>>
>> On Wed, Dec 1, 2010 at 7:21 PM, Dominick Samperi<djsamperi at gmail.com>
>> ?wrote:
>>>
>>> The author line of the latest release of the R package
>>> Rcpp (0.8.9) was revised as follows:
>>>
>>> From: "based on code written during 2005 and 2006 by Dominick Samperi"
>>>
>>> To: "a small portion of the code is based on code written during 2005 and
>>> 2006 by Dominick Samperi"
>>>
>>> From the info given in the thread, personally I'm sympathetic to
>>
>> Dominick's complaint: the latter message is no proper way to
>> acknowledge the original author of the package. As I see it, the
>> project either:
>> - explicitly mentions the original author and the active (current)
>> contributors (and perhaps previous ones), or
>> - lines up all previous contributors in a line and singles out the
>> active contributors
>
> - or in this case say that it was forked (when) from (Author)'s (package)
> (version)

I think the danger in all this is that future developers might see
this discussion and then conclude that they would be better off
redeveloping existing packages encouraging a wasteful Not Invented
Here attitude rather than stand on the shoulders of others. That would
divert resources into nonproductive duplicative activities and slow
the growth of R.

Perhaps the takeaway is (1) to be particularly careful about forking a
project and (2) also for package developers to try as hard as they can
to write their packages in a such a way that they can be added onto
externally rather than requiring modification of the package itself.
For example, DBI allows external database drivers and Rcmdr allows
external plugins.  zoo can accommodate new classes of index without
modifying zoo itself.  And of course R itself has specific facilities
for encouraging user contributed packages which do not require any
change at all to R itself.

In fact, I wonder if its still not too late for the package in
question.  Perhaps it would be possible to divide it into two packages
-- one would be the new code and the other would be the original base
package with just sufficient modifications to allow the new package to
consist of add-ons to it.  (I haven't actually used the package in
question so I am not sure if this is realistic but thought I would
throw it out as a potential resolution.)

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From djsamperi at gmail.com  Thu Dec  2 20:10:02 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 14:10:02 -0500
Subject: [Rd] GPL and R Community Policies (Rcpp)
In-Reply-To: <AANLkTinb0x-m=cuM7PQHOYUQ301NmNLzWvaExKpfr+32@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<AANLkTin4HJzxXZp7LhwMvZZN=+Ay0YZHqX=OfhcF65G6@mail.gmail.com>
	<4CF7C857.5020208@units.it>
	<AANLkTinb0x-m=cuM7PQHOYUQ301NmNLzWvaExKpfr+32@mail.gmail.com>
Message-ID: <AANLkTinWfyhhnRt7tv_os5zxzgL5bGP5-Qimiue5fa8B@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/291da4fb/attachment.pl>

From JHZhang at mdanderson.org  Thu Dec  2 21:41:00 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Thu, 2 Dec 2010 14:41:00 -0600
Subject: [Rd] Install package 'Matrix' problem
In-Reply-To: <alpine.LFD.2.00.1012020612240.13083@gannet.stats.ox.ac.uk>
References: <5685E4FBA752A441B1975A77A77CD64824E371F8D9@DCPWVMBXC1VS2.mdanderson.edu>
	<alpine.LFD.2.00.1012020612240.13083@gannet.stats.ox.ac.uk>
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E371FA3B@DCPWVMBXC1VS2.mdanderson.edu>

Prof. Ripley,
     I've just done the installation of the R package 'Matrix' to my 64-bit R 2.12.0, and it is loaded fine. Seems adding -m64 to the CXX line solved the problem.

I had,
CC="cc -xc99 -m64 -xarch=sparcvis2"
CXX="CC -library=stlport4"

And now I have (the working version),
CC="cc -xc99 -m64 -xarch=sparcvis2"
CXX="CC -m64 -library=stlport4"

Thank you!

Jun Zhang
System Analyst III
Division of Quantitative Science
FCT4.6109
713-792-2606



-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Thursday, December 02, 2010 12:30 AM
To: Zhang,Jun
Cc: 'r-devel at r-project.org'
Subject: Re: [Rd] Install package 'Matrix' problem

We need more information, at the minimum the line which compiled 
CHMfactor.o.  Can you make the install log (you may need to run this 
again) and your etc/Makeconf available on-line?

At first sight your C++ compiler is missing -m64: the R-admin manual 
says

'For a 64-bit target add -m64 to the compiler macros and use something 
like LDFLAGS=-L/opt/csw/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 
as appropriate.'

I see I used

CC="cc -xc99 -m64"
CFLAGS="-O -xlibmieee"
F77="f95 -m64"
FFLAGS=-O4
CXX="CC -m64 -library=stlport4"
CXXFLAGS=-O
FC=$F77
FCFLAGS=$FFLAGS
LDFLAGS=-L/usr/local/lib/sparcv9
FCLIBS="-lfai -lfsu -lfai2"

in config.site.  And BTW, it is always worth checking the manuals of 
current R-patched: your compiler postdates the pre-release period for 
R 2.12.0.

On Wed, 1 Dec 2010, Zhang,Jun wrote:

> 64-bit R-2.12.0 was installed on Sun SPARC Solaris 10. Compiler used is solstudio12.2. Attached is the configure script.
> I then tried to install a recommended package called Matrix. The compilation failed with the following messages,
> .......

> CC -library=stlport4 -G -L/opt/csw/lib/sparcv9 
> -L/opt/solstudio12.2/prod/lib/v9 -o Matrix.so CHMfactor.o Csparse.o 
> TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o cs_utils.o 
> dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o dppMatrix.o 
> dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o 
> dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o 
> sparseQR.o abIndex.o CHOLMOD.a COLAMD.a AMD.a 
> -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRlapack 
> -L/apps/sparcv9/R-2.12.0/lib/R/lib -lRblas -lifai -lsunimath -lfai 
> -lfai2 -lfsumai -lfprodai -lfminlai -lfmaxlai -lfminvai -lfmaxvai 
> -lfui -lfsu -lsunmath -lmtsk -lm

> ld: fatal: file CHMfactor.o: wrong ELF class: ELFCLASS64
> ld: fatal: File processing errors. No output written to Matrix.so
> make: *** [Matrix.so] Error 2
> ERROR: compilation failed for package 'Matrix'
> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/Matrix'
>
> Some article suggests theorectically that ld or compiler driver

You need to give references for what you are quoting here (there is 
much misinformation on the Internet).  I suspect it is simply that you 
didn't specify the C++ compiler correctly.

> first sees a component .o file which is 32-bit (don't know which one 
> here), and decides that other components should be 32-bit, too, 
> hence the error message, since CHMfactor.o must be a 64-bit object. 
> I just don't know what is the practical way to avoid this situation. 
> I guess I'm posting in the right list, can somebody help?

Maybe, but really your local IT support is there to help your use of 
your OS: this is a Solaris issue, not an R one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shotwelm at musc.edu  Thu Dec  2 22:06:37 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Thu, 02 Dec 2010 16:06:37 -0500
Subject: [Rd] segfault interest?
In-Reply-To: <AANLkTimfYVXRpOZZ5NAw=HaRuHzo6Bq_JPTYgccBZJp_@mail.gmail.com>
References: <AANLkTikfV39Sj+E=GfGL1a8+M+DUgzrF_n+uGKoMPowY@mail.gmail.com>
	<4CED3CA5.605@gmail.com>
	<AANLkTimfYVXRpOZZ5NAw=HaRuHzo6Bq_JPTYgccBZJp_@mail.gmail.com>
Message-ID: <1291323998.2840.122.camel@matt-laptop>

On Wed, 2010-11-24 at 12:12 -0500, ivo welch wrote: 
> I just figured out what is happening.  The root drive (presumably OSX
> virtual memory) becomes depleted.  The error message about "memory not
> mapped" was a hint, too.  So, not really R's fault.  However, I wonder

It still may be R's fault. This segfault occurs because R (or third
party code called by R) attempts to access memory beyond what is
allocated/mapped. It's very likely a programming error. A bug report is
warranted, subject to Duncan's earlier comments. 

Does the segfault only occur when a memory limit is reached?

The top five functions in your traceback (below) are all defined in the
base package...

-Matt

 *** caught segfault *** 
address 0xdc3f9b48, cause 'memory not mapped'
Traceback:
 1: rep.int(seq_len(nx), rep.int(rep.fac, nx))
 2: rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep)
 3: expand.grid(seq_len(nx), seq_len(ny))
 4: merge.data.frame(d, ss)
 5: merge(d, ss)
 6: valid.range(opt)
 7: eval.with.vis(expr, envir, enclos)
 8: eval.with.vis(ei, envir)
 9: source("fut-into-opts.R")

> whether R can be made to abort more gracefully, or at least trap the
> error message and translate it into something more meaningful ("you
> have run out of [virtual] memory when executing 'R statement' ").  of
> course, this may not be possible at all.
> 
> /iaw
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Matthew S. Shotwell
Graduate Student 
Division of Biostatistics and Epidemiology
Medical University of South Carolina


From edd at debian.org  Thu Dec  2 22:35:59 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 2 Dec 2010 15:35:59 -0600
Subject: [Rd] Terminology clarification (Re: GPL and R Community Policies
	(Rcpp)
In-Reply-To: <002501cb9236$b0c634a0$12529de0$@edu>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
Message-ID: <19704.4415.474447.28419@max.nulle.part>


There are repeated claims concerning a "Rcpp fork".  Let's address both terms
in turn.

i)  Rcpp was used in November 2008 as the name for a re-launch of a package
    which had seen releases on CRAN in 2005/2006 during which it was also
    renamed to RcppTemplate. Hence no package of name Rcpp had existed for
    years; the package's own author had moved on to anther name (RcppTemplate
    as it were).  As such, no other package conflicted with the name.

    To my knowledge, there is no 'namespace reservation into eternity' for
    project names their very authors have liberated. If I missed a precedent,
    I would appreciate a pointer.

    We still use the name Rcpp today (in what is an almost entirely rewritten
    package with vastly expanded functionality) as it is useful in
    communicating the basic purpose: integrating R and C++.

ii) The usage of "fork" is simply wrong.  As running 'dict fork' on my Unix
    machine shows (among many other entries covering anything from the eating
    utensil to the system call):

        fork In the open-source community, a fork is what occurs when two (or
           more) versions of a software package's source code are being developed
           in parallel which once shared a common code base, and these multiple
           versions of the source code have irreconcilable differences between
           them. This should not be confused with a development branch, which may
           later be folded back into the original source code base. Nor should it
           be confused with what happens when a new distribution of Linux or some
           other distribution is created, because that largely assembles pieces
           than can and will be used in other distributions without conflict.
        
           Forking is uncommon; in fact, it is so uncommon that individual
           instances loom large in hacker folklore. Notable in this class were the
           http://www.xemacs.org/About/XEmacsVsGNUemacs.html (Emacs/XEmacs fork),
           the GCC/EGCS fork (later healed by a merger) and the forks among the
           FreeBSD, NetBSD, and OpenBSD operating systems.
        
    Note the "when two (or more) versions of a software package's source code
    are being developed in parallel".  

    Ergo, a "fork" would have required another living project with on-going
    development.  But the code previously known at Rcpp/RcppTemplate was
    anything but "living", this can easily be verified by looking at the
    (preferably time-sorted) directory at CRAN (see link [1] below).

So let's please stop calling this a "fork" of Rcpp.  The Rcpp / RcppTemplate
project was not live in late 2008; we changed that and started a relaunch
under the (unused !!) name Rcpp which now, a good two years later, looks
pretty healthy with four contributor and growing use within the R community.
Rcpp has been almost completely rewritten and enhanced, but I fail to see the
bitterness of its original author.  There could be some pride in seeing ideas
re-used.  But to each their own.

Lastly, for the associated 'remove my name' request: I have emails from 2008
requesting this (which I accomodated), I also have emails from 2009 that
requested the reversal (also accomodated).  This is getting old.

Finally, as Ravi wrote:

On 2 December 2010 at 10:36, Ravi Varadhan wrote:
| So, Dominick - please cheer up and try to find some solace in that your work
| has had an influence on the R community!

Seconded.  

I have even older emails (from 2005/2006) where the author complains that no
other R packages use what was then Rcpp.  The code changed a lot, but there
is still some pride to be had in an idea living on, even if (as Peter wrote)
someone else picks up "your" ball and runs with it.

Regards, Dirk


[1] http://cran.r-project.org/src/contrib/Archive/cxxPack/Ancestry/?C=M;O=A

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Thu Dec  2 22:50:22 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 2 Dec 2010 16:50:22 -0500
Subject: [Rd] segfault interest?
In-Reply-To: <1291323998.2840.122.camel@matt-laptop>
References: <AANLkTikfV39Sj+E=GfGL1a8+M+DUgzrF_n+uGKoMPowY@mail.gmail.com>
	<4CED3CA5.605@gmail.com>
	<AANLkTimfYVXRpOZZ5NAw=HaRuHzo6Bq_JPTYgccBZJp_@mail.gmail.com>
	<1291323998.2840.122.camel@matt-laptop>
Message-ID: <01DE9C09-DA2C-419E-8505-C36C8ABEEF0D@r-project.org>

Matt,

please use
R -d gdb
and then "bt" for a more useful trace.

Thanks,
Simon


On Dec 2, 2010, at 4:06 PM, Matt Shotwell wrote:

> On Wed, 2010-11-24 at 12:12 -0500, ivo welch wrote: 
>> I just figured out what is happening.  The root drive (presumably OSX
>> virtual memory) becomes depleted.  The error message about "memory not
>> mapped" was a hint, too.  So, not really R's fault.  However, I wonder
> 
> It still may be R's fault. This segfault occurs because R (or third
> party code called by R) attempts to access memory beyond what is
> allocated/mapped. It's very likely a programming error. A bug report is
> warranted, subject to Duncan's earlier comments. 
> 
> Does the segfault only occur when a memory limit is reached?
> 
> The top five functions in your traceback (below) are all defined in the
> base package...
> 
> -Matt
> 
> *** caught segfault *** 
> address 0xdc3f9b48, cause 'memory not mapped'
> Traceback:
> 1: rep.int(seq_len(nx), rep.int(rep.fac, nx))
> 2: rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep)
> 3: expand.grid(seq_len(nx), seq_len(ny))
> 4: merge.data.frame(d, ss)
> 5: merge(d, ss)
> 6: valid.range(opt)
> 7: eval.with.vis(expr, envir, enclos)
> 8: eval.with.vis(ei, envir)
> 9: source("fut-into-opts.R")
> 
>> whether R can be made to abort more gracefully, or at least trap the
>> error message and translate it into something more meaningful ("you
>> have run out of [virtual] memory when executing 'R statement' ").  of
>> course, this may not be possible at all.
>> 
>> /iaw
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Matthew S. Shotwell
> Graduate Student 
> Division of Biostatistics and Epidemiology
> Medical University of South Carolina
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From djsamperi at gmail.com  Thu Dec  2 23:23:54 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 17:23:54 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <19704.4415.474447.28419@max.nulle.part>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
Message-ID: <AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/1b4774b5/attachment.pl>

From djsamperi at gmail.com  Thu Dec  2 23:50:51 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 17:50:51 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
Message-ID: <AANLkTi=4Gdg07jgqm81art-RMPkr=poGRFjWfCHcnro+@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/1deea344/attachment.pl>

From edd at debian.org  Thu Dec  2 23:58:46 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 2 Dec 2010 16:58:46 -0600
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
Message-ID: <19704.9382.378882.355500@max.nulle.part>


On 2 December 2010 at 17:23, Dominick Samperi wrote:
| OK, since you are so accomodating, then please remove all reference to
| my name from Rcpp as I do not want to be subject to arbitrary revisions of
| my status. I may not have the right to say how my prior work will be used,
| but I think I have the right to ask that my name not be used in the way
| it is used in the recent update.

As I pointed out, you change your mind on this every 12 months, limiting my
patience and willingness for these dances.  It has also been suggested by
other than attribution is clearer if you listed as the maintainer of the
2005/2006 code that we started from in 2008.
 
| On the "fork" question, in November of 2009 you were maintaining
| an old version of my software for your own purposes because I did

Well a glance at the changelog (either from the source, the SVN repo or via
the bottom of http://dirk.eddelbuettel.com/code/rcpp.changelog.html) clearly
shows that by November 2009 we were nine releases into it. There are a full
210 lines of changes including

2009-11-18  Dirk Eddelbuettel  <edd at debian.org>

        * DESCRIPTION: Add Dominick back into Authors per his new request
          reversing his requests to be removed from last December

As I stated, this was maintaining, enhancing, solidifying, ... a codebase I
and others used, using an API and code that we were free to use under GPL.  

You had released nothing from late 2006 to late 2009 -- and as I recall what
you released then (and withdrew weeks later) was not even compatible with
your own old API.  

But our Rcpp was -- that is called "maintaining" code.

| not have time to contribute updates to CRAN. The changes that
| you made were minimal (as a diff would show). GPL permits you

We beg to differ.

| to do this. Whether you call this a fork or not is a language issue.
| 
| In November of 2009 I released an update with many improvements
| including object mapping support that was missing from my old
| software and from the version that you were maintaining. I asked
| you to remove the version you were maintaining so there would
| be only one Rcpp library, and you refused, invited Romain to
| join the project, and added many of the features that I had just
| released. Thus the real "fork" occured in November 2009.

Nonsense -- No code, design, ideas, .... of your shortlived RcppTemplate are
in Rcpp.  

Romain and I repeatedly said so, and we will not let you paint an alternate
history.  

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From djsamperi at gmail.com  Fri Dec  3 00:28:23 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 18:28:23 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <19704.9382.378882.355500@max.nulle.part>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
Message-ID: <AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/aecef886/attachment.pl>

From djsamperi at gmail.com  Fri Dec  3 00:38:50 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 18:38:50 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <19704.9382.378882.355500@max.nulle.part>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
Message-ID: <AANLkTi=OA6bph2wsJg4+GCm8SerDiqtRbCaUM2PFL-pF@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/799d3466/attachment.pl>

From jorismeys at gmail.com  Fri Dec  3 00:43:48 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 3 Dec 2010 00:43:48 +0100
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTi=OA6bph2wsJg4+GCm8SerDiqtRbCaUM2PFL-pF@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTi=OA6bph2wsJg4+GCm8SerDiqtRbCaUM2PFL-pF@mail.gmail.com>
Message-ID: <AANLkTik8PDt4pKSM2XvT0vEdd=az=2n8m6by00pzbRL0@mail.gmail.com>

On Fri, Dec 3, 2010 at 12:38 AM, Dominick Samperi <djsamperi at gmail.com> wrote:

> We? Romain did not arrive on the scene until after November of 2009.
>
> To live outside the law you must be honest --- Bob Dylan.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
Peter Dalgaard and Martin Maechler were pretty clear if you ask me.
Mud slinging can be done at 4chan.com

Goodnight.



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From djsamperi at gmail.com  Fri Dec  3 01:15:34 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 2 Dec 2010 19:15:34 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTik8PDt4pKSM2XvT0vEdd=az=2n8m6by00pzbRL0@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTi=OA6bph2wsJg4+GCm8SerDiqtRbCaUM2PFL-pF@mail.gmail.com>
	<AANLkTik8PDt4pKSM2XvT0vEdd=az=2n8m6by00pzbRL0@mail.gmail.com>
Message-ID: <AANLkTinaC7+wPgE+vdVZd7genJL9HK2ywrRteSe0=aP=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101202/499a2bb3/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Dec  3 09:50:08 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Dec 2010 08:50:08 +0000 (GMT)
Subject: [Rd] proposal for new flag to R CMD INSTALL
In-Reply-To: <AANLkTiko3NLTyhHDyTaukK65K0qLFffJTnOw08uGrYd7@mail.gmail.com>
References: <AANLkTiko3NLTyhHDyTaukK65K0qLFffJTnOw08uGrYd7@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1011300650180.22005@gannet.stats.ox.ac.uk>

Why do you think dependencies are not needed for the help system? At 
some point they will be needed to resolve cross-references: at install 
time if you are generating static HTML.

I've not seen any issues that cannot be solved by --install=fake: I 
have fake installs of a few packages (e.g. ROracle) to allow others to 
be tested (including their help pages).


On Mon, 29 Nov 2010, Kjetil Halvorsen wrote:

> For the purpose of helping in installing only parts of a package
> (in my case, the help system), R CMD INSTALL
> should accept a flag   --no-check-deps
> Below is a diff for R-devel, svn revision    53672
>
>
>
> kjetil at kjetil:~/R/R-devel/src/library/tools/R$ diff install.R.old install.R
> 116a117
>>             "      --no-check-deps      skip test if installed depends/imports",
> 506c507
> <             if (length(miss) > 1)
> ---
>>             if ((length(miss) > 1) && check_deps)
> 510c511
> <             else if (length(miss))
> ---
>>             else if (length(miss) && check_deps)
> 1025a1027
>>     check_deps <- TRUE
> 1133a1136,1137
>>         } else if (a == "--no-check-deps") {
>>             check_deps <- FALSE
>
>
>
> kjetil
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Fri Dec  3 12:59:42 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 3 Dec 2010 19:59:42 +0800
Subject: [Rd] Clean up after "R CMD INSTALL" and/or "R  CMD check"
Message-ID: <20101203195942.04e2945a@bossiaea>

G'day all,

I noticed the following (new) behaviour of R 2.12.0, running on Kubuntu
10.10, when installed with sub-architectures:

When I run "R CMD INSTALL" or "R CMD check" on the source directory of a
package that contains C or FORTRAN code, R creates sub-directories
src-32/ and src-64/ that seem to be copies of the src/ subdirectory
plus the compiled objects.   

These directories are not deleted at the end of a successful
INSTALL/check and I wonder if there is any particular reason for this?
Would it be possible to delete these sub-directories during clean-up
at the end of a successful INSTALL/check?

Cheers,

	Berwin


From diklevich at gmail.com  Fri Dec  3 08:46:11 2010
From: diklevich at gmail.com (Oleksandr Dyklevych)
Date: Fri, 03 Dec 2010 08:46:11 +0100
Subject: [Rd] Strange problems with compiling dll
Message-ID: <op.vm4nu9hu5lpu25@superfuji.lan>


Dear sir\madam!

I'm trying to speed up my R code by writing quite simple dll's in C. But I
faced some problems, and I cannot determine their source.

#include <Rinternals.h>

SEXP mycombin(SEXP N, SEXP k){
       int i, *j, *l, c;
       j = INTEGER(k);l = INTEGER(N);
       c = 1;
       if(j[0] > 0 && j[0] < l[0]){
           if(j[0] <= l[0] - j[0]){
               for(i = l[0]; i >= l[0] - j[0] + 1; i--){
                   c = c * i / (l[0] - i + 1);
               }
           }
           else{
               for(i = l[0]; i <= j[0] + 1; i++){
                   c = c * i / (l[0] - i + 1);
               }
           }
       }
       return ScalarInteger(c);
}

But, when I try to compile it I have 5 errors, and all of them come form
linker and say next (Code::Blocks):

||=== mcb2, Release ===|
obj\Release\conv.o:conv.c|| undefined reference to `INTEGER'|
obj\Release\conv.o:conv.c|| undefined reference to `INTEGER'|
obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
||=== Build finished: 5 errors, 0 warnings ===|


I found out that I need to link Rdll.lib, but to make it I should use
these instructions

make R.exp
lib /def:R.exp /out:Rdll.lib

but i cannot figure out where I should use them.
I'm trying from here C:\Rtools\src\gnuwin32 but each time i get
make: *** No rule to make target `R.exp'.  Stop.

So where should I state this rule and which rule?...

Will you help me, please, to "connect" my C compiler to R?

Best regards,
Oleksandr


From ripley at stats.ox.ac.uk  Fri Dec  3 14:14:44 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Dec 2010 13:14:44 +0000 (GMT)
Subject: [Rd] Clean up after "R CMD INSTALL" and/or "R  CMD check"
In-Reply-To: <20101203195942.04e2945a@bossiaea>
References: <20101203195942.04e2945a@bossiaea>
Message-ID: <alpine.LFD.2.00.1012031228310.7301@toucan.stats.ox.ac.uk>

On Fri, 3 Dec 2010, Berwin A Turlach wrote:

> G'day all,
>
> I noticed the following (new) behaviour of R 2.12.0, running on Kubuntu
> 10.10, when installed with sub-architectures:

Yes, there are new features when there are multiple sub-architectures.

> When I run "R CMD INSTALL" or "R CMD check" on the source directory of a
> package that contains C or FORTRAN code, R creates sub-directories
> src-32/ and src-64/ that seem to be copies of the src/ subdirectory
> plus the compiled objects.
>
> These directories are not deleted at the end of a successful
> INSTALL/check and I wonder if there is any particular reason for this?

Because it might be partially successful and you want to look at the 
generated objects?  In particular 'success' means that the primary 
sub-architecture is installed: others might fail.

> Would it be possible to delete these sub-directories during clean-up
> at the end of a successful INSTALL/check?

Try INSTALL --clean, etc.  But I normally do this from a tarball to 
keep the sources clean and to test the reference sources.

There are a few improvements to R-patched in the detection of 
sub-architectures, so you might like to see if you prefer what it 
does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Fri Dec  3 14:20:51 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 3 Dec 2010 07:20:51 -0600
Subject: [Rd] Strange problems with compiling dll
In-Reply-To: <op.vm4nu9hu5lpu25@superfuji.lan>
References: <op.vm4nu9hu5lpu25@superfuji.lan>
Message-ID: <19704.61107.962213.921800@max.nulle.part>


On 3 December 2010 at 08:46, Oleksandr Dyklevych wrote:
| I'm trying to speed up my R code by writing quite simple dll's in C. But I

Yes, that can be a very appropriate approach and many tools help. Make sure
you read the 'Writing R Extensions' manual though.

| faced some problems, and I cannot determine their source.
| 
| #include <Rinternals.h>
| 
| SEXP mycombin(SEXP N, SEXP k){
|        int i, *j, *l, c;
|        j = INTEGER(k);l = INTEGER(N);
|        c = 1;
|        if(j[0] > 0 && j[0] < l[0]){
|            if(j[0] <= l[0] - j[0]){
|                for(i = l[0]; i >= l[0] - j[0] + 1; i--){
|                    c = c * i / (l[0] - i + 1);
|                }
|            }
|            else{
|                for(i = l[0]; i <= j[0] + 1; i++){
|                    c = c * i / (l[0] - i + 1);
|                }
|            }
|        }
|        return ScalarInteger(c);
| }
| 
| But, when I try to compile it I have 5 errors, and all of them come form
| linker and say next (Code::Blocks):
| 
| ||=== mcb2, Release ===|
| obj\Release\conv.o:conv.c|| undefined reference to `INTEGER'|
| obj\Release\conv.o:conv.c|| undefined reference to `INTEGER'|
| obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
| obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
| obj\Release\conv.o:conv.c|| undefined reference to `Rf_ScalarInteger'|
| ||=== Build finished: 5 errors, 0 warnings ===|

The error messages make me suspect that you are using an unsupported
toolchain.   That is your right, but you are unlikely to find help.  All
documentation suggests to use the gcc/g++ combinations (with minor exceptions
such as the native Solaris compiler etc pp). 

| I found out that I need to link Rdll.lib, but to make it I should use
| these instructions
| 
| make R.exp
| lib /def:R.exp /out:Rdll.lib

That is very clearly unsupported.  Re-visit 'Writing R Extensions', in
particular the Appendix on the Windows toolchain, and try again.
 
| but i cannot figure out where I should use them.
| I'm trying from here C:\Rtools\src\gnuwin32 but each time i get
| make: *** No rule to make target `R.exp'.  Stop.
| 
| So where should I state this rule and which rule?...
| 
| Will you help me, please, to "connect" my C compiler to R?

No. That approach is clearly documented as being unsupported -- so you cannot
expect answers on the principal development list for R.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From berwin at maths.uwa.edu.au  Fri Dec  3 16:23:09 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 3 Dec 2010 23:23:09 +0800
Subject: [Rd] Clean up after "R CMD INSTALL" and/or "R  CMD check"
In-Reply-To: <alpine.LFD.2.00.1012031228310.7301@toucan.stats.ox.ac.uk>
References: <20101203195942.04e2945a@bossiaea>
	<alpine.LFD.2.00.1012031228310.7301@toucan.stats.ox.ac.uk>
Message-ID: <20101203232309.7f266be8@absentia>

G'day Brian,

On Fri, 3 Dec 2010 13:14:44 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> > I noticed the following (new) behaviour of R 2.12.0, running on
> > Kubuntu 10.10, when installed with sub-architectures:
> 
> Yes, there are new features when there are multiple sub-architectures.

Indeed.  One new feature seems to be that if the installation of a
package via
	R arch=XXX CMD INSTALL --libs-only
fails then the package is not completely removed but rather the
previously install version is re-installed.  IIRC, I had requested this
behaviour some years ago and it is nice to see it now implemented. :)
 
> > These directories are not deleted at the end of a successful
> > INSTALL/check and I wonder if there is any particular reason for
> > this?
> 
> Because it might be partially successful and you want to look at the 
> generated objects?  

I agree that it would be helpful to look at the generated objects if
the INSTALL/check is only partially successful, that's why I asked
about a successful INSTALL/check.  However, it looks...

> In particular 'success' means that the primary sub-architecture is
> installed: others might fail.

... as if we have different definitions of what constitutes 'success';
I take 'success' as meaning successful installation for all
architectures, but accept that you are using the official definition. :)

> > Would it be possible to delete these sub-directories during clean-up
> > at the end of a successful INSTALL/check?
> 
> Try INSTALL --clean, etc.  

This does not seem to help, the directories in question are not removed.

> But I normally do this from a tarball to keep the sources clean and
> to test the reference sources.

I used to do this too but changed my habits when it was once pointed out
to me that the section "Checking and building packages" in the "Writing
R Extensions" manual starts with:

	Before using these tools, please check that your package can be
	installed and loaded.  @code{R CMD check} will @emph{inter
	alia} do this, but you may get more detailed error messages
	doing the checks directly.
 
IIRC, the context was that it took me some time to track down a problem
via "R CMD check foo.tar.gz" as the error messages were not as helpful
in locating the problem as the error messages of "R CMD INSTALL" would
have been.  But if "R CMD INSTALL" is to be run before "R CMD check"
and/or "R CMD build" it has to be run on the source directory, hasn't
it?  This looks like a chicken-and-egg problem. :)

Or are you now saying that it is o.k. to first run "R CMD build" and
then "R CMD INSTALL" on the tarball?

> There are a few improvements to R-patched in the detection of 
> sub-architectures, so you might like to see if you prefer what it 
> does.

I tried with:
   R version 2.13.0 Under development (unstable) (2010-12-02 r53747)
and
   R version 2.12.0 Patched (2010-12-02 r53747)
and I did not see any different behaviour.  The subdirectories src-32/
and src-64/ are created and not deleted.

Thank you very much for your comments/insights. 

Cheers,

	Berwin


From nashjc at uottawa.ca  Fri Dec  3 16:57:21 2010
From: nashjc at uottawa.ca (Prof. John C Nash)
Date: Fri, 03 Dec 2010 10:57:21 -0500
Subject: [Rd] Competing with one's own work
Message-ID: <4CF91361.7090005@uottawa.ca>

No, this is not about Rcpp, but a comment in that overly long discussion raised a question
that has been in my mind for a while.

This is that one may have work that is used in R in the base functionality and there are
improvements that should be incorporated.

For me, this concerns the BFGS, Nelder-Mead and CG options of optim(), which are based on
the 1990 edition (Pascal codes) of my 1979 book "Compact numerical methods...", which were
themselves derived from other people's work. By the time Brian Ripley took that work (with
permission, even though not strictly required. Thanks!) there were already some
improvements to these same algorithms (mainly bounds and masks) in the BASIC codes of the
1987 book by Mary Walker-Smith and I. However, BASIC to R is not something I'd wish on
anyone.

Now there are some R packages, including some I've been working on, that do offer
improvements on the optim() offerings. I would not say mine are yet fully ready for
incorporation into the base, but they are pretty close. Equally I think some of the tools
in the base should be deprecated and users encouraged to try other routines. It is also
getting more and more important that novice users be provided with sensible guidance and
robust default settings and choices. In many areas, users are faced with more choice than
is efficient for the majority of problems.

My question is: How should such changes be suggested / assisted? It seems to me that this
is beyond a simple feature request. Some discussion on pros and cons would be appropriate,
and those like myself who are familiar with particular tools can and should offer help.

Alternatively, is there a document available in the style "Writing R Extensions" that has
a title like "How the R Base Packages are Updated"? A brief search was negative.

I'm happy to compete with my own prior work to provide improvements. It would be nice to
see some of those improvements become the benchmark for further progress.


Best,

John Nash


From murdoch.duncan at gmail.com  Fri Dec  3 17:12:52 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 Dec 2010 11:12:52 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <4CF91361.7090005@uottawa.ca>
References: <4CF91361.7090005@uottawa.ca>
Message-ID: <4CF91704.7070605@gmail.com>

On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
> No, this is not about Rcpp, but a comment in that overly long discussion raised a question
> that has been in my mind for a while.
>
> This is that one may have work that is used in R in the base functionality and there are
> improvements that should be incorporated.
>
> For me, this concerns the BFGS, Nelder-Mead and CG options of optim(), which are based on
> the 1990 edition (Pascal codes) of my 1979 book "Compact numerical methods...", which were
> themselves derived from other people's work. By the time Brian Ripley took that work (with
> permission, even though not strictly required. Thanks!) there were already some
> improvements to these same algorithms (mainly bounds and masks) in the BASIC codes of the
> 1987 book by Mary Walker-Smith and I. However, BASIC to R is not something I'd wish on
> anyone.
>
> Now there are some R packages, including some I've been working on, that do offer
> improvements on the optim() offerings. I would not say mine are yet fully ready for
> incorporation into the base, but they are pretty close. Equally I think some of the tools
> in the base should be deprecated and users encouraged to try other routines. It is also
> getting more and more important that novice users be provided with sensible guidance and
> robust default settings and choices. In many areas, users are faced with more choice than
> is efficient for the majority of problems.
>
> My question is: How should such changes be suggested / assisted? It seems to me that this
> is beyond a simple feature request. Some discussion on pros and cons would be appropriate,
> and those like myself who are familiar with particular tools can and should offer help.
>
> Alternatively, is there a document available in the style "Writing R Extensions" that has
> a title like "How the R Base Packages are Updated"? A brief search was negative.
>
> I'm happy to compete with my own prior work to provide improvements. It would be nice to
> see some of those improvements become the benchmark for further progress.


There are answers at many different levels to your questions.  The 
simplest is that base packages are part of R, so they get updated when a 
member of R Core updates them, and the updates get released when a new 
version of R is released.

So if you want a change, you need to convince a member of the core to 
make it.  Pointing out a bug is the easiest way to do this:  bugs 
usually get fixed quickly, if they are clearly demonstrated.

If you want a bigger change, you need to make a convincing argument in 
favour of it.  If you pick a topic that is of particular interest to one 
core member, and you can convince him to make the change, then it will 
happen.  If pick some obscure topic that's not of interest to anyone, 
you'll need a very strong argument to make it interesting.  Part of any 
of these arguments is explaining why the change needs to be made to the 
base, why it can't just be published in a contributed package.  (That's 
why bug fixes are easy, and big additions to the base packages are not.)

Duncan Murdoch


From rvaradhan at jhmi.edu  Fri Dec  3 18:01:15 2010
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 3 Dec 2010 12:01:15 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <4CF91704.7070605@gmail.com>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
Message-ID: <003601cb930b$b28205a0$178610e0$@edu>

Dear Duncan, 

What constitutes a convincing argument for making significant changes?
Taking the example of optimization algorithms (say, for smooth objective
functions), how does one make a convincing argument that a particular class
of algorithms are "better" than another class? This can be a difficult task,
but quite doable with good benchmarking practices.  

Supposing for the moment that such a convincing argument has been made, is
that sufficient to get the R-core to act upon it?  Are there compelling
factors other than just "algorithm A is better than algorithm B"?

I'd think that the argument is relatively easy if the need for the change is
driven by consumer demand. But, even here I am not sure how to make an
argument to the R-core to consider the big changes.  For example, there is a
reasonable demand for constrained (smooth) optimization algorithms in R
(based on R-help queries).  Currently, there are only 3 packages that can
handle this.  However, in the base distribution only `constrOptim' function
is provided, which cannot handle anything more than linear, inequality
constraints.  I think that the base distribution needs to have a package for
constrained optimization that can handle linear/nonlinear and
equality/inequality constraints.  

John, thanks for raising an important issue.

Thanks & Best,
Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns
Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Duncan Murdoch
Sent: Friday, December 03, 2010 11:13 AM
To: nashjc at uottawa.ca
Cc: r-devel at r-project.org
Subject: Re: [Rd] Competing with one's own work

On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
> No, this is not about Rcpp, but a comment in that overly long discussion
raised a question
> that has been in my mind for a while.
>
> This is that one may have work that is used in R in the base functionality
and there are
> improvements that should be incorporated.
>
> For me, this concerns the BFGS, Nelder-Mead and CG options of optim(),
which are based on
> the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
methods...", which were
> themselves derived from other people's work. By the time Brian Ripley took
that work (with
> permission, even though not strictly required. Thanks!) there were already
some
> improvements to these same algorithms (mainly bounds and masks) in the
BASIC codes of the
> 1987 book by Mary Walker-Smith and I. However, BASIC to R is not something
I'd wish on
> anyone.
>
> Now there are some R packages, including some I've been working on, that
do offer
> improvements on the optim() offerings. I would not say mine are yet fully
ready for
> incorporation into the base, but they are pretty close. Equally I think
some of the tools
> in the base should be deprecated and users encouraged to try other
routines. It is also
> getting more and more important that novice users be provided with
sensible guidance and
> robust default settings and choices. In many areas, users are faced with
more choice than
> is efficient for the majority of problems.
>
> My question is: How should such changes be suggested / assisted? It seems
to me that this
> is beyond a simple feature request. Some discussion on pros and cons would
be appropriate,
> and those like myself who are familiar with particular tools can and
should offer help.
>
> Alternatively, is there a document available in the style "Writing R
Extensions" that has
> a title like "How the R Base Packages are Updated"? A brief search was
negative.
>
> I'm happy to compete with my own prior work to provide improvements. It
would be nice to
> see some of those improvements become the benchmark for further progress.


There are answers at many different levels to your questions.  The 
simplest is that base packages are part of R, so they get updated when a 
member of R Core updates them, and the updates get released when a new 
version of R is released.

So if you want a change, you need to convince a member of the core to 
make it.  Pointing out a bug is the easiest way to do this:  bugs 
usually get fixed quickly, if they are clearly demonstrated.

If you want a bigger change, you need to make a convincing argument in 
favour of it.  If you pick a topic that is of particular interest to one 
core member, and you can convince him to make the change, then it will 
happen.  If pick some obscure topic that's not of interest to anyone, 
you'll need a very strong argument to make it interesting.  Part of any 
of these arguments is explaining why the change needs to be made to the 
base, why it can't just be published in a contributed package.  (That's 
why bug fixes are easy, and big additions to the base packages are not.)

Duncan Murdoch

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From bates at stat.wisc.edu  Fri Dec  3 19:28:03 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Dec 2010 12:28:03 -0600
Subject: [Rd] Competing with one's own work
In-Reply-To: <003601cb930b$b28205a0$178610e0$@edu>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu>
Message-ID: <AANLkTimZRyzWACEtoHUzu9VtusugjtO4p1sqnRxSqkfr@mail.gmail.com>

On Fri, Dec 3, 2010 at 11:01 AM, Ravi Varadhan <rvaradhan at jhmi.edu> wrote:
> Dear Duncan,

> What constitutes a convincing argument for making significant changes?
> Taking the example of optimization algorithms (say, for smooth objective
> functions), how does one make a convincing argument that a particular class
> of algorithms are "better" than another class? This can be a difficult task,
> but quite doable with good benchmarking practices.

> Supposing for the moment that such a convincing argument has been made, is
> that sufficient to get the R-core to act upon it? ?Are there compelling
> factors other than just "algorithm A is better than algorithm B"?

> I'd think that the argument is relatively easy if the need for the change is
> driven by consumer demand. But, even here I am not sure how to make an
> argument to the R-core to consider the big changes. ?For example, there is a
> reasonable demand for constrained (smooth) optimization algorithms in R
> (based on R-help queries). ?Currently, there are only 3 packages that can
> handle this. ?However, in the base distribution only `constrOptim' function
> is provided, which cannot handle anything more than linear, inequality
> constraints. ?I think that the base distribution needs to have a package for
> constrained optimization that can handle linear/nonlinear and
> equality/inequality constraints.

constrOptim is in the stats package, not the base package.  Functions
that are already in the required packages are maintained by R core.
If you know of bugs in such functions you should report them.  Because
there is a heavy burden in maintaining the large corpus of software in
R and its required packages, additions are viewed skeptically,
Adopting new capabilities and new code in a required package like
stats means that some member of R core has to be willing to maintain
it.  If the capabilities can be incorporated in a contributed package
then that is the preferred method of extending R. The burden of
maintaining the code, fixing bugs or other infelicities, etc. is on
the package maintainer.

I don't see anything in what you are proposing that could not be
incorporated in a contributed package.

> John, thanks for raising an important issue.
>
> Thanks & Best,
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns
> Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Duncan Murdoch
> Sent: Friday, December 03, 2010 11:13 AM
> To: nashjc at uottawa.ca
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Competing with one's own work
>
> On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
>> No, this is not about Rcpp, but a comment in that overly long discussion
> raised a question
>> that has been in my mind for a while.
>>
>> This is that one may have work that is used in R in the base functionality
> and there are
>> improvements that should be incorporated.
>>
>> For me, this concerns the BFGS, Nelder-Mead and CG options of optim(),
> which are based on
>> the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
> methods...", which were
>> themselves derived from other people's work. By the time Brian Ripley took
> that work (with
>> permission, even though not strictly required. Thanks!) there were already
> some
>> improvements to these same algorithms (mainly bounds and masks) in the
> BASIC codes of the
>> 1987 book by Mary Walker-Smith and I. However, BASIC to R is not something
> I'd wish on
>> anyone.
>>
>> Now there are some R packages, including some I've been working on, that
> do offer
>> improvements on the optim() offerings. I would not say mine are yet fully
> ready for
>> incorporation into the base, but they are pretty close. Equally I think
> some of the tools
>> in the base should be deprecated and users encouraged to try other
> routines. It is also
>> getting more and more important that novice users be provided with
> sensible guidance and
>> robust default settings and choices. In many areas, users are faced with
> more choice than
>> is efficient for the majority of problems.
>>
>> My question is: How should such changes be suggested / assisted? It seems
> to me that this
>> is beyond a simple feature request. Some discussion on pros and cons would
> be appropriate,
>> and those like myself who are familiar with particular tools can and
> should offer help.
>>
>> Alternatively, is there a document available in the style "Writing R
> Extensions" that has
>> a title like "How the R Base Packages are Updated"? A brief search was
> negative.
>>
>> I'm happy to compete with my own prior work to provide improvements. It
> would be nice to
>> see some of those improvements become the benchmark for further progress.
>
>
> There are answers at many different levels to your questions. ?The
> simplest is that base packages are part of R, so they get updated when a
> member of R Core updates them, and the updates get released when a new
> version of R is released.
>
> So if you want a change, you need to convince a member of the core to
> make it. ?Pointing out a bug is the easiest way to do this: ?bugs
> usually get fixed quickly, if they are clearly demonstrated.
>
> If you want a bigger change, you need to make a convincing argument in
> favour of it. ?If you pick a topic that is of particular interest to one
> core member, and you can convince him to make the change, then it will
> happen. ?If pick some obscure topic that's not of interest to anyone,
> you'll need a very strong argument to make it interesting. ?Part of any
> of these arguments is explaining why the change needs to be made to the
> base, why it can't just be published in a contributed package. ?(That's
> why bug fixes are easy, and big additions to the base packages are not.)
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rvaradhan at jhmi.edu  Fri Dec  3 20:00:26 2010
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 3 Dec 2010 14:00:26 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <AANLkTimZRyzWACEtoHUzu9VtusugjtO4p1sqnRxSqkfr@mail.gmail.com>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu>
	<AANLkTimZRyzWACEtoHUzu9VtusugjtO4p1sqnRxSqkfr@mail.gmail.com>
Message-ID: <006101cb931c$58a8dca0$09fa95e0$@edu>

Dear Doug,

Thank you for the response.

"constrOptim is in the stats package, not the base package."

Yes, I know, and I meant to say base *distribution* rather than base
package.  

"The burden of maintaining the code, fixing bugs or other infelicities, etc.
is on the package maintainer."

Of course.

"I don't see anything in what you are proposing that could not be
incorporated in a contributed package."

I agree, and it has already been done.  

What I am really asking is this: what is the rationale behind having a
package incorporated into the base distribution? 

Best,
Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns
Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu


-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Friday, December 03, 2010 1:28 PM
To: Ravi Varadhan
Cc: Duncan Murdoch; nashjc at uottawa.ca; r-devel at r-project.org
Subject: Re: [Rd] Competing with one's own work

On Fri, Dec 3, 2010 at 11:01 AM, Ravi Varadhan <rvaradhan at jhmi.edu> wrote:
> Dear Duncan,

> What constitutes a convincing argument for making significant changes?
> Taking the example of optimization algorithms (say, for smooth objective
> functions), how does one make a convincing argument that a particular
class
> of algorithms are "better" than another class? This can be a difficult
task,
> but quite doable with good benchmarking practices.

> Supposing for the moment that such a convincing argument has been made, is
> that sufficient to get the R-core to act upon it? ?Are there compelling
> factors other than just "algorithm A is better than algorithm B"?

> I'd think that the argument is relatively easy if the need for the change
is
> driven by consumer demand. But, even here I am not sure how to make an
> argument to the R-core to consider the big changes. ?For example, there is
a
> reasonable demand for constrained (smooth) optimization algorithms in R
> (based on R-help queries). ?Currently, there are only 3 packages that can
> handle this. ?However, in the base distribution only `constrOptim'
function
> is provided, which cannot handle anything more than linear, inequality
> constraints. ?I think that the base distribution needs to have a package
for
> constrained optimization that can handle linear/nonlinear and
> equality/inequality constraints.

constrOptim is in the stats package, not the base package.  Functions
that are already in the required packages are maintained by R core.
If you know of bugs in such functions you should report them.  Because
there is a heavy burden in maintaining the large corpus of software in
R and its required packages, additions are viewed skeptically,
Adopting new capabilities and new code in a required package like
stats means that some member of R core has to be willing to maintain
it.  If the capabilities can be incorporated in a contributed package
then that is the preferred method of extending R. The burden of
maintaining the code, fixing bugs or other infelicities, etc. is on
the package maintainer.

I don't see anything in what you are proposing that could not be
incorporated in a contributed package.

> John, thanks for raising an important issue.
>
> Thanks & Best,
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns
> Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Duncan Murdoch
> Sent: Friday, December 03, 2010 11:13 AM
> To: nashjc at uottawa.ca
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Competing with one's own work
>
> On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
>> No, this is not about Rcpp, but a comment in that overly long discussion
> raised a question
>> that has been in my mind for a while.
>>
>> This is that one may have work that is used in R in the base
functionality
> and there are
>> improvements that should be incorporated.
>>
>> For me, this concerns the BFGS, Nelder-Mead and CG options of optim(),
> which are based on
>> the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
> methods...", which were
>> themselves derived from other people's work. By the time Brian Ripley
took
> that work (with
>> permission, even though not strictly required. Thanks!) there were
already
> some
>> improvements to these same algorithms (mainly bounds and masks) in the
> BASIC codes of the
>> 1987 book by Mary Walker-Smith and I. However, BASIC to R is not
something
> I'd wish on
>> anyone.
>>
>> Now there are some R packages, including some I've been working on, that
> do offer
>> improvements on the optim() offerings. I would not say mine are yet fully
> ready for
>> incorporation into the base, but they are pretty close. Equally I think
> some of the tools
>> in the base should be deprecated and users encouraged to try other
> routines. It is also
>> getting more and more important that novice users be provided with
> sensible guidance and
>> robust default settings and choices. In many areas, users are faced with
> more choice than
>> is efficient for the majority of problems.
>>
>> My question is: How should such changes be suggested / assisted? It seems
> to me that this
>> is beyond a simple feature request. Some discussion on pros and cons
would
> be appropriate,
>> and those like myself who are familiar with particular tools can and
> should offer help.
>>
>> Alternatively, is there a document available in the style "Writing R
> Extensions" that has
>> a title like "How the R Base Packages are Updated"? A brief search was
> negative.
>>
>> I'm happy to compete with my own prior work to provide improvements. It
> would be nice to
>> see some of those improvements become the benchmark for further progress.
>
>
> There are answers at many different levels to your questions. ?The
> simplest is that base packages are part of R, so they get updated when a
> member of R Core updates them, and the updates get released when a new
> version of R is released.
>
> So if you want a change, you need to convince a member of the core to
> make it. ?Pointing out a bug is the easiest way to do this: ?bugs
> usually get fixed quickly, if they are clearly demonstrated.
>
> If you want a bigger change, you need to make a convincing argument in
> favour of it. ?If you pick a topic that is of particular interest to one
> core member, and you can convince him to make the change, then it will
> happen. ?If pick some obscure topic that's not of interest to anyone,
> you'll need a very strong argument to make it interesting. ?Part of any
> of these arguments is explaining why the change needs to be made to the
> base, why it can't just be published in a contributed package. ?(That's
> why bug fixes are easy, and big additions to the base packages are not.)
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Fri Dec  3 20:18:32 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 Dec 2010 14:18:32 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <003601cb930b$b28205a0$178610e0$@edu>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu>
Message-ID: <4CF94288.3020301@gmail.com>

On 03/12/2010 12:01 PM, Ravi Varadhan wrote:
> Dear Duncan,
>
> What constitutes a convincing argument for making significant changes?

I don't think there's any answer to that other than "an argument that 
convinces someone to make the changes".  What would convince you to work 
on a problem?   Your answer is very different from mine, and mine is 
different from that of anyone else in the core group.


> Taking the example of optimization algorithms (say, for smooth objective
> functions), how does one make a convincing argument that a particular class
> of algorithms are "better" than another class? This can be a difficult task,
> but quite doable with good benchmarking practices.

I don't see how that's relevant.  That's an argument to make to users, 
not to the core group.   A user wants to use the best optimizer for 
his/her own problem.  The core group wants functions in base R that we 
will maintain.

> Supposing for the moment that such a convincing argument has been made, is
> that sufficient to get the R-core to act upon it?

By definition, yes.


> Are there compelling
> factors other than just "algorithm A is better than algorithm B"?

Yes.  The decision about whether it belongs in a package or in base R is 
about who should maintain the code.  If I think it is fantastic code, 
but you will do a better job of maintaining it than I will, then there's 
no way I'd put it in base R.

> I'd think that the argument is relatively easy if the need for the change is
> driven by consumer demand.  But, even here I am not sure how to make an
> argument to the R-core to consider the big changes.  For example, there is a
> reasonable demand for constrained (smooth) optimization algorithms in R
> (based on R-help queries).  Currently, there are only 3 packages that can
> handle this.  However, in the base distribution only `constrOptim' function
> is provided, which cannot handle anything more than linear, inequality
> constraints.  I think that the base distribution needs to have a package for
> constrained optimization that can handle linear/nonlinear and
> equality/inequality constraints.

As Doug said, "I don't see anything in what you are proposing that could 
not be incorporated in a contributed package."

I think I answered your followup question above:  the rationale for 
including it in base R is because someone in the core team is in a 
better position to maintain the code than an outside package maintainer 
would be.

Duncan Murdoch

> John, thanks for raising an important issue.
>
> Thanks&  Best,
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns
> Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Duncan Murdoch
> Sent: Friday, December 03, 2010 11:13 AM
> To: nashjc at uottawa.ca
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Competing with one's own work
>
> On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
> >  No, this is not about Rcpp, but a comment in that overly long discussion
> raised a question
> >  that has been in my mind for a while.
> >
> >  This is that one may have work that is used in R in the base functionality
> and there are
> >  improvements that should be incorporated.
> >
> >  For me, this concerns the BFGS, Nelder-Mead and CG options of optim(),
> which are based on
> >  the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
> methods...", which were
> >  themselves derived from other people's work. By the time Brian Ripley took
> that work (with
> >  permission, even though not strictly required. Thanks!) there were already
> some
> >  improvements to these same algorithms (mainly bounds and masks) in the
> BASIC codes of the
> >  1987 book by Mary Walker-Smith and I. However, BASIC to R is not something
> I'd wish on
> >  anyone.
> >
> >  Now there are some R packages, including some I've been working on, that
> do offer
> >  improvements on the optim() offerings. I would not say mine are yet fully
> ready for
> >  incorporation into the base, but they are pretty close. Equally I think
> some of the tools
> >  in the base should be deprecated and users encouraged to try other
> routines. It is also
> >  getting more and more important that novice users be provided with
> sensible guidance and
> >  robust default settings and choices. In many areas, users are faced with
> more choice than
> >  is efficient for the majority of problems.
> >
> >  My question is: How should such changes be suggested / assisted? It seems
> to me that this
> >  is beyond a simple feature request. Some discussion on pros and cons would
> be appropriate,
> >  and those like myself who are familiar with particular tools can and
> should offer help.
> >
> >  Alternatively, is there a document available in the style "Writing R
> Extensions" that has
> >  a title like "How the R Base Packages are Updated"? A brief search was
> negative.
> >
> >  I'm happy to compete with my own prior work to provide improvements. It
> would be nice to
> >  see some of those improvements become the benchmark for further progress.
>
>
> There are answers at many different levels to your questions.  The
> simplest is that base packages are part of R, so they get updated when a
> member of R Core updates them, and the updates get released when a new
> version of R is released.
>
> So if you want a change, you need to convince a member of the core to
> make it.  Pointing out a bug is the easiest way to do this:  bugs
> usually get fixed quickly, if they are clearly demonstrated.
>
> If you want a bigger change, you need to make a convincing argument in
> favour of it.  If you pick a topic that is of particular interest to one
> core member, and you can convince him to make the change, then it will
> happen.  If pick some obscure topic that's not of interest to anyone,
> you'll need a very strong argument to make it interesting.  Part of any
> of these arguments is explaining why the change needs to be made to the
> base, why it can't just be published in a contributed package.  (That's
> why bug fixes are easy, and big additions to the base packages are not.)
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rvaradhan at jhmi.edu  Fri Dec  3 20:20:51 2010
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 3 Dec 2010 14:20:51 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <4CF94288.3020301@gmail.com>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu> <4CF94288.3020301@gmail.com>
Message-ID: <006501cb931f$32a478e0$97ed6aa0$@edu>

"The decision about whether it belongs in a package or in base R is 
about who should maintain the code."  

Ok.  I understand it now.

Thanks,
Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns
Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, December 03, 2010 2:19 PM
To: Ravi Varadhan
Cc: nashjc at uottawa.ca; r-devel at r-project.org
Subject: Re: [Rd] Competing with one's own work

On 03/12/2010 12:01 PM, Ravi Varadhan wrote:
> Dear Duncan,
>
> What constitutes a convincing argument for making significant changes?

I don't think there's any answer to that other than "an argument that 
convinces someone to make the changes".  What would convince you to work 
on a problem?   Your answer is very different from mine, and mine is 
different from that of anyone else in the core group.


> Taking the example of optimization algorithms (say, for smooth objective
> functions), how does one make a convincing argument that a particular
class
> of algorithms are "better" than another class? This can be a difficult
task,
> but quite doable with good benchmarking practices.

I don't see how that's relevant.  That's an argument to make to users, 
not to the core group.   A user wants to use the best optimizer for 
his/her own problem.  The core group wants functions in base R that we 
will maintain.

> Supposing for the moment that such a convincing argument has been made, is
> that sufficient to get the R-core to act upon it?

By definition, yes.


> Are there compelling
> factors other than just "algorithm A is better than algorithm B"?

Yes.  The decision about whether it belongs in a package or in base R is 
about who should maintain the code.  If I think it is fantastic code, 
but you will do a better job of maintaining it than I will, then there's 
no way I'd put it in base R.

> I'd think that the argument is relatively easy if the need for the change
is
> driven by consumer demand.  But, even here I am not sure how to make an
> argument to the R-core to consider the big changes.  For example, there is
a
> reasonable demand for constrained (smooth) optimization algorithms in R
> (based on R-help queries).  Currently, there are only 3 packages that can
> handle this.  However, in the base distribution only `constrOptim'
function
> is provided, which cannot handle anything more than linear, inequality
> constraints.  I think that the base distribution needs to have a package
for
> constrained optimization that can handle linear/nonlinear and
> equality/inequality constraints.

As Doug said, "I don't see anything in what you are proposing that could 
not be incorporated in a contributed package."

I think I answered your followup question above:  the rationale for 
including it in base R is because someone in the core team is in a 
better position to maintain the code than an outside package maintainer 
would be.

Duncan Murdoch

> John, thanks for raising an important issue.
>
> Thanks&  Best,
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns
> Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Duncan Murdoch
> Sent: Friday, December 03, 2010 11:13 AM
> To: nashjc at uottawa.ca
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Competing with one's own work
>
> On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
> >  No, this is not about Rcpp, but a comment in that overly long
discussion
> raised a question
> >  that has been in my mind for a while.
> >
> >  This is that one may have work that is used in R in the base
functionality
> and there are
> >  improvements that should be incorporated.
> >
> >  For me, this concerns the BFGS, Nelder-Mead and CG options of optim(),
> which are based on
> >  the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
> methods...", which were
> >  themselves derived from other people's work. By the time Brian Ripley
took
> that work (with
> >  permission, even though not strictly required. Thanks!) there were
already
> some
> >  improvements to these same algorithms (mainly bounds and masks) in the
> BASIC codes of the
> >  1987 book by Mary Walker-Smith and I. However, BASIC to R is not
something
> I'd wish on
> >  anyone.
> >
> >  Now there are some R packages, including some I've been working on,
that
> do offer
> >  improvements on the optim() offerings. I would not say mine are yet
fully
> ready for
> >  incorporation into the base, but they are pretty close. Equally I think
> some of the tools
> >  in the base should be deprecated and users encouraged to try other
> routines. It is also
> >  getting more and more important that novice users be provided with
> sensible guidance and
> >  robust default settings and choices. In many areas, users are faced
with
> more choice than
> >  is efficient for the majority of problems.
> >
> >  My question is: How should such changes be suggested / assisted? It
seems
> to me that this
> >  is beyond a simple feature request. Some discussion on pros and cons
would
> be appropriate,
> >  and those like myself who are familiar with particular tools can and
> should offer help.
> >
> >  Alternatively, is there a document available in the style "Writing R
> Extensions" that has
> >  a title like "How the R Base Packages are Updated"? A brief search was
> negative.
> >
> >  I'm happy to compete with my own prior work to provide improvements. It
> would be nice to
> >  see some of those improvements become the benchmark for further
progress.
>
>
> There are answers at many different levels to your questions.  The
> simplest is that base packages are part of R, so they get updated when a
> member of R Core updates them, and the updates get released when a new
> version of R is released.
>
> So if you want a change, you need to convince a member of the core to
> make it.  Pointing out a bug is the easiest way to do this:  bugs
> usually get fixed quickly, if they are clearly demonstrated.
>
> If you want a bigger change, you need to make a convincing argument in
> favour of it.  If you pick a topic that is of particular interest to one
> core member, and you can convince him to make the change, then it will
> happen.  If pick some obscure topic that's not of interest to anyone,
> you'll need a very strong argument to make it interesting.  Part of any
> of these arguments is explaining why the change needs to be made to the
> base, why it can't just be published in a contributed package.  (That's
> why bug fixes are easy, and big additions to the base packages are not.)
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pgilbert at bank-banque-canada.ca  Fri Dec  3 20:35:35 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 3 Dec 2010 19:35:35 +0000
Subject: [Rd] Competing with one's own work
In-Reply-To: <AANLkTimZRyzWACEtoHUzu9VtusugjtO4p1sqnRxSqkfr@mail.gmail.com>
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu>
	<AANLkTimZRyzWACEtoHUzu9VtusugjtO4p1sqnRxSqkfr@mail.gmail.com>
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D01691F@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

At one time I lobbied for putting something in base or a required package, and it was suggested that the idea at the time was to remove things rather than add them. Generally, I agree that is a good idea, so I did not lobby more. 

When this question comes up it is always asked, and answered, in terms of putting things in. However, is there a process for moving things out to normal packages rather than keeping them in required packages or base?

Paul

>-----Original Message-----
>From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>project.org] On Behalf Of Douglas Bates
>Sent: December 3, 2010 1:28 PM
>To: Ravi Varadhan
>Cc: r-devel at r-project.org; nashjc at uottawa.ca
>Subject: Re: [Rd] Competing with one's own work
>
>On Fri, Dec 3, 2010 at 11:01 AM, Ravi Varadhan <rvaradhan at jhmi.edu>
>wrote:
>> Dear Duncan,
>
>> What constitutes a convincing argument for making significant changes?
>> Taking the example of optimization algorithms (say, for smooth
>objective
>> functions), how does one make a convincing argument that a particular
>class
>> of algorithms are "better" than another class? This can be a difficult
>task,
>> but quite doable with good benchmarking practices.
>
>> Supposing for the moment that such a convincing argument has been
>made, is
>> that sufficient to get the R-core to act upon it? ?Are there
>compelling
>> factors other than just "algorithm A is better than algorithm B"?
>
>> I'd think that the argument is relatively easy if the need for the
>change is
>> driven by consumer demand. But, even here I am not sure how to make an
>> argument to the R-core to consider the big changes. ?For example,
>there is a
>> reasonable demand for constrained (smooth) optimization algorithms in
>R
>> (based on R-help queries). ?Currently, there are only 3 packages that
>can
>> handle this. ?However, in the base distribution only `constrOptim'
>function
>> is provided, which cannot handle anything more than linear, inequality
>> constraints. ?I think that the base distribution needs to have a
>package for
>> constrained optimization that can handle linear/nonlinear and
>> equality/inequality constraints.
>
>constrOptim is in the stats package, not the base package.  Functions
>that are already in the required packages are maintained by R core.
>If you know of bugs in such functions you should report them.  Because
>there is a heavy burden in maintaining the large corpus of software in
>R and its required packages, additions are viewed skeptically,
>Adopting new capabilities and new code in a required package like
>stats means that some member of R core has to be willing to maintain
>it.  If the capabilities can be incorporated in a contributed package
>then that is the preferred method of extending R. The burden of
>maintaining the code, fixing bugs or other infelicities, etc. is on
>the package maintainer.
>
>I don't see anything in what you are proposing that could not be
>incorporated in a contributed package.
>
>> John, thanks for raising an important issue.
>>
>> Thanks & Best,
>> Ravi.
>>
>> -------------------------------------------------------
>> Ravi Varadhan, Ph.D.
>> Assistant Professor,
>> Division of Geriatric Medicine and Gerontology School of Medicine
>Johns
>> Hopkins University
>>
>> Ph. (410) 502-2619
>> email: rvaradhan at jhmi.edu
>>
>>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>project.org]
>> On Behalf Of Duncan Murdoch
>> Sent: Friday, December 03, 2010 11:13 AM
>> To: nashjc at uottawa.ca
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Competing with one's own work
>>
>> On 03/12/2010 10:57 AM, Prof. John C Nash wrote:
>>> No, this is not about Rcpp, but a comment in that overly long
>discussion
>> raised a question
>>> that has been in my mind for a while.
>>>
>>> This is that one may have work that is used in R in the base
>functionality
>> and there are
>>> improvements that should be incorporated.
>>>
>>> For me, this concerns the BFGS, Nelder-Mead and CG options of
>optim(),
>> which are based on
>>> the 1990 edition (Pascal codes) of my 1979 book "Compact numerical
>> methods...", which were
>>> themselves derived from other people's work. By the time Brian Ripley
>took
>> that work (with
>>> permission, even though not strictly required. Thanks!) there were
>already
>> some
>>> improvements to these same algorithms (mainly bounds and masks) in
>the
>> BASIC codes of the
>>> 1987 book by Mary Walker-Smith and I. However, BASIC to R is not
>something
>> I'd wish on
>>> anyone.
>>>
>>> Now there are some R packages, including some I've been working on,
>that
>> do offer
>>> improvements on the optim() offerings. I would not say mine are yet
>fully
>> ready for
>>> incorporation into the base, but they are pretty close. Equally I
>think
>> some of the tools
>>> in the base should be deprecated and users encouraged to try other
>> routines. It is also
>>> getting more and more important that novice users be provided with
>> sensible guidance and
>>> robust default settings and choices. In many areas, users are faced
>with
>> more choice than
>>> is efficient for the majority of problems.
>>>
>>> My question is: How should such changes be suggested / assisted? It
>seems
>> to me that this
>>> is beyond a simple feature request. Some discussion on pros and cons
>would
>> be appropriate,
>>> and those like myself who are familiar with particular tools can and
>> should offer help.
>>>
>>> Alternatively, is there a document available in the style "Writing R
>> Extensions" that has
>>> a title like "How the R Base Packages are Updated"? A brief search
>was
>> negative.
>>>
>>> I'm happy to compete with my own prior work to provide improvements.
>It
>> would be nice to
>>> see some of those improvements become the benchmark for further
>progress.
>>
>>
>> There are answers at many different levels to your questions. ?The
>> simplest is that base packages are part of R, so they get updated when
>a
>> member of R Core updates them, and the updates get released when a new
>> version of R is released.
>>
>> So if you want a change, you need to convince a member of the core to
>> make it. ?Pointing out a bug is the easiest way to do this: ?bugs
>> usually get fixed quickly, if they are clearly demonstrated.
>>
>> If you want a bigger change, you need to make a convincing argument in
>> favour of it. ?If you pick a topic that is of particular interest to
>one
>> core member, and you can convince him to make the change, then it will
>> happen. ?If pick some obscure topic that's not of interest to anyone,
>> you'll need a very strong argument to make it interesting. ?Part of
>any
>> of these arguments is explaining why the change needs to be made to
>the
>> base, why it can't just be published in a contributed package.
>?(That's
>> why bug fixes are easy, and big additions to the base packages are
>not.)
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential in...{{dropped:26}}


From djsamperi at gmail.com  Fri Dec  3 21:49:46 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 3 Dec 2010 15:49:46 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
Message-ID: <AANLkTi=NtZz0DKpPrm9zOc_0SfKU0UnzmxLetmL3HfDH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101203/e8d799c2/attachment.pl>

From bbolker at gmail.com  Fri Dec  3 22:08:29 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 3 Dec 2010 21:08:29 +0000 (UTC)
Subject: [Rd] Competing with one's own work
References: <4CF91361.7090005@uottawa.ca> <4CF91704.7070605@gmail.com>
	<003601cb930b$b28205a0$178610e0$@edu> <4CF94288.3020301@gmail.com>
	<006501cb931f$32a478e0$97ed6aa0$@edu>
Message-ID: <loom.20101203T214523-53@post.gmane.org>

Ravi Varadhan <rvaradhan <at> jhmi.edu> writes:

> 
> "The decision about whether it belongs in a package or in base R is 
> about who should maintain the code."  
> 
> Ok.  I understand it now.
> 
> Thanks,
> Ravi.
> 

   A point that may not have been made (sorry if it was and I missed it):

A better question might be how packages get added to the *recommended*
package list (rather than how code gets added to "base R").  Of the
16 recommended packages, 2 are maintained by R-core itself, 12 by various
R-core members acting as individuals (I assume), and 2 by non-R-core
people. It seems that if a contributed package sticks around long enough
and proves itself sufficiently useful and of sufficiently high quality
(and well enough maintained), that it could then be suggested as
a recommended package.

i1 <- installed.packages()
i2 <- i1[!is.na(i1[,"Priority"]),]
ff <- function(x) table(sapply(x[,"Package"],maintainer))
ff(i2[i2[,"Priority"]=="base",])

R Core Team <R-core at r-project.org> 
                                12 

ff(i2[i2[,"Priority"]=="recommended",])

           Brian Ripley <ripley at stats.ox.ac.uk> 
                                              7 
Deepayan Sarkar <deepayan.sarkar at r-project.org> 
                                              2 
 Doug and Martin <Matrix-authors at R-project.org> 
                                              1 
             Luke Tierney <luke at stat.uiowa.edu> 
                                              1 
   Martin Maechler <maechler at stat.math.ethz.ch> 
                                              1 
                  R-core <R-core at R-project.org> 
                                              1 
                  R-core <R-core at r-project.org> 
                                              1 
          Simon Wood <simon.wood at r-project.org> 
                                              1 
       Terry Therneau <therneau.terry at mayo.edu> 
                                              1


From JHZhang at mdanderson.org  Fri Dec  3 23:15:08 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Fri, 3 Dec 2010 16:15:08 -0600
Subject: [Rd] Problem installing RCurl
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101203/d87a6e6c/attachment.pl>

From duncan at wald.ucdavis.edu  Sat Dec  4 00:59:27 2010
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 03 Dec 2010 15:59:27 -0800
Subject: [Rd] Problem installing RCurl
In-Reply-To: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>
References: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>
Message-ID: <4CF9845F.5070804@wald.ucdavis.edu>


Hi Jun

On 12/3/10 2:15 PM, Zhang,Jun wrote:
> I have 64-bit R 2 12 0 installed on Solaris 10 of Sun Sparc. When I tried to install RCurl, it failed with the following lines,
> 
> ...............
> Version has CURLOPT_SSL_SESSIONID_CACHE
> libcurl version: libcurl 7.19.6
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> cc -xc99 -m64 -xarch=sparcvis2 -I/apps/sparcv9/R-2.12.0/lib/R/include -I/opt/csw/include -DHAVE_LIBIDN_FIELD=1 -DHAVE_CURLOPT_URL=1 -DHAVE_CURLINFO_EFFECTIVE_URL=1 .........(omitted here is very long, all upper case) -DHAVE_CURLOPT_SSL_SESSIONID_CACHE=1 -I/opt/csw/include    -KPIC  -xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2 -c base64.c -o base64.o
> "/opt/csw/include/curl/curlrules.h", line 144: zero or negative subscript

This error indicates that the compiler (cc with flags -xc99 -m64, etc.) sees the size of the 'long' data type in C
is different from what was seen when libcurl was configured, built and installed.

So basically the compiler and/or the compiler flags were different.

How was libcurl installed - from source or from a pre-built binary ?
What compiler and flags were used?

  D.


> "base64.c", line 25: warning: assignment type mismatch:
>         pointer to const char "=" pointer to unsigned char
> "base64.c", line 39: warning: argument #1 is incompatible with prototype:
>         prototype: pointer to const char : "/apps/sparcv9/R-2.12.0/lib/R/include/Rinternals.h", line 1042
>         argument : pointer to unsigned char
> "base64.c", line 60: warning: assignment type mismatch:
>         pointer to const char "=" pointer to unsigned char
> cc: acomp failed for base64.c
> make: *** [base64.o] Error 2
> ERROR: compilation failed for package 'RCurl'
> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/RCurl'
> 
> The downloaded packages are in
>         '/tmp/Rtmpo67mNX/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Warning message:
> In install.packages("RCurl") :
>   installation of package 'RCurl' had non-zero exit status
>>
> 
> What is the problem?
> 
> Jun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Dec  4 08:03:14 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Dec 2010 07:03:14 +0000 (GMT)
Subject: [Rd] Problem installing RCurl
In-Reply-To: <4CF9845F.5070804@wald.ucdavis.edu>
References: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>
	<4CF9845F.5070804@wald.ucdavis.edu>
Message-ID: <alpine.LFD.2.00.1012040641190.29989@gannet.stats.ox.ac.uk>

On Fri, 3 Dec 2010, Duncan Temple Lang wrote:

>
> Hi Jun
>
> On 12/3/10 2:15 PM, Zhang,Jun wrote:
>> I have 64-bit R 2 12 0 installed on Solaris 10 of Sun Sparc. When I tried to install RCurl, it failed with the following lines,
>>
>> ...............
>> Version has CURLOPT_SSL_SESSIONID_CACHE
>> libcurl version: libcurl 7.19.6
>> configure: creating ./config.status
>> config.status: creating src/Makevars
>> ** libs
>> cc -xc99 -m64 -xarch=sparcvis2 -I/apps/sparcv9/R-2.12.0/lib/R/include -I/opt/csw/include -DHAVE_LIBIDN_FIELD=1 -DHAVE_CURLOPT_URL=1 -DHAVE_CURLINFO_EFFECTIVE_URL=1 .........(omitted here is very long, all upper case) -DHAVE_CURLOPT_SSL_SESSIONID_CACHE=1 -I/opt/csw/include    -KPIC  -xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2 -c base64.c -o base64.o
>> "/opt/csw/include/curl/curlrules.h", line 144: zero or negative subscript
>
> This error indicates that the compiler (cc with flags -xc99 -m64, 
> etc.) sees the size of the 'long' data type in C is different from 
> what was seen when libcurl was configured, built and installed.
>
> So basically the compiler and/or the compiler flags were different.
>
> How was libcurl installed - from source or from a pre-built binary ?
> What compiler and flags were used?

The header is from a prebuilt binary (from OpenCSW).  That is built 
with gcc and not the Sun compiler.  And curlbuild.h says

/* Allow 32 and 64 bit headers to coexist */
#if defined __amd64 || defined __x86_64 || defined __sparcv9
#include "curlbuild-64.h"
#else
#include "curlbuild-32.h"
#endif

which AFAIK are gcc and not Sun defines.  You could try adding 
-D__sparcv9 to the CPPFLAGS, or compile RCurl with OpenCSW's gcc 
build (but 64-bit gcc is another can of worms).

I've pointed out to Jun Zhang several times that 64-bit Sparc Solaris 
is really pushing it, and 32-bit R on Sparc Solaris has been much more 
successful.  Given that x86_64 boxes (Solaris or Linux) are so much 
faster at computation than Sparc ones, I don't see the point of 
building 64-bit Sparc Solaris R -- if 32-bit R is not enough you need 
a faster machine.

>
>  D.
>
>
>> "base64.c", line 25: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> "base64.c", line 39: warning: argument #1 is incompatible with prototype:
>>         prototype: pointer to const char : "/apps/sparcv9/R-2.12.0/lib/R/include/Rinternals.h", line 1042
>>         argument : pointer to unsigned char
>> "base64.c", line 60: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> cc: acomp failed for base64.c
>> make: *** [base64.o] Error 2
>> ERROR: compilation failed for package 'RCurl'
>> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/RCurl'
>>
>> The downloaded packages are in
>>         '/tmp/Rtmpo67mNX/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Warning message:
>> In install.packages("RCurl") :
>>   installation of package 'RCurl' had non-zero exit status
>>>
>>
>> What is the problem?
>>
>> Jun
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nakama at ki.rim.or.jp  Sat Dec  4 13:53:42 2010
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Sat, 4 Dec 2010 21:53:42 +0900
Subject: [Rd] SurviveGotoBLAS2 for Win64 (human sacrifice release)
Message-ID: <AANLkTina-mGgcnWqvHHsXR6gQxtP0C9+Aah1JvaXwy3-@mail.gmail.com>

Hi,

I put below Rblas.dll(GotoBLAS2 for Win64).
http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/windows/x64/Rblas.dll
It's a tryal phase.

-- 
EI-JI Nakama? <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>


From mdsumner at gmail.com  Sat Dec  4 14:11:40 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 5 Dec 2010 00:11:40 +1100
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTi=NtZz0DKpPrm9zOc_0SfKU0UnzmxLetmL3HfDH@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
	<AANLkTi=NtZz0DKpPrm9zOc_0SfKU0UnzmxLetmL3HfDH@mail.gmail.com>
Message-ID: <AANLkTingqLfXi0vyfdD11m4Y1J4rRGm-APsoUuu7jzx3@mail.gmail.com>

Christ, can we remove all references from the mailing lists while we're at it?



On Sat, Dec 4, 2010 at 7:49 AM, Dominick Samperi <djsamperi at gmail.com> wrote:
> Dirk,
>
> Please let me know whether or not you will comply with my request to remove
> references to my name in Rcpp (except copyright notices).
>
> Thanks,
> Dominick
>
> On Thu, Dec 2, 2010 at 6:28 PM, Dominick Samperi <djsamperi at gmail.com>wrote:
>
>>
>>
>> On Thu, Dec 2, 2010 at 5:58 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>>>
>>> On 2 December 2010 at 17:23, Dominick Samperi wrote:
>>> | OK, since you are so accomodating, then please remove all reference to
>>> | my name from Rcpp as I do not want to be subject to arbitrary revisions
>>> of
>>> | my status. I may not have the right to say how my prior work will be
>>> used,
>>> | but I think I have the right to ask that my name not be used in the way
>>> | it is used in the recent update.
>>>
>>> As I pointed out, you change your mind on this every 12 months, limiting
>>> my
>>> patience and willingness for these dances. ?It has also been suggested by
>>> other than attribution is clearer if you listed as the maintainer of the
>>> 2005/2006 code that we started from in 2008.
>>>
>>
>> The change that this thread is a reaction to happened a few days ago, not
>> 12 months ago. If I wavered in the past it was because I was being
>> forced to compete with my own work, not a pleasant place to be.
>>
>> Are you telling me that you refuse to stop using my name
>> in Rcpp (except in copyright notices)?
>>
>> Are you telling me that you will continue to use my name and
>> update the associated status as you see fit, whether or not I
>> approve or consent to those changes?
>>
>> Please answer yes or no.
>>
>> Thanks,
>> Dominick
>>
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From jayemerson at gmail.com  Sat Dec  4 15:35:07 2010
From: jayemerson at gmail.com (Jay Emerson)
Date: Sat, 4 Dec 2010 09:35:07 -0500
Subject: [Rd] Competing with one's own work (Prof. John C Nash)
Message-ID: <AANLkTikF6HmS=zSUPjBnSyKFQGkGMyNMK-sLw-3xbVj8@mail.gmail.com>

John, thanks for starting (or restarting) this thread.? I'd like to
add to the discussion with another concrete example, about as simple
as it gets, which may help focus at least part of this discussion.

I have worked with Taylor Arnold to implement a method developed in
Conover (1972) for Kolmogorov-Smirnov goodness-of-fit tests for
discrete distributions (one-sample only).? We needed this for an
applied problem.? It seemed to be a natural extension to
stats::ks.test(), so we modified that code (commenting every addition
very carefully) and modifying ks.test.Rd in parallel (and with
commenting).? For convenience, we put this in a package ks.test that
is on R-Forge but not submitted to CRAN.? We've written a short paper
about this (and also implemented similar Cramer-von Mises tests in
package cvm.test).

1. I think the cvm.test function/package is suitable for CRAN (rather,
I can't make a compelling argument it should be added to the base
distribution).? It doesn't directly extend anything in the base R
distribution at the moment (at least, to my knowledge).

2. I think it would be ideal for stats::ks.test() to be updated using
the new ks.test.R and ks.test.Rd.  I'll spare you the longer argument,
but there are simple examples of a "bug" (quotes intended, because it
surrounds non-intended functionality with discrete distributions) in
stats::ks.test().

3. Finally, I note the presence of a <FIXME> in stats::ks.test() that
looks rather straightforward.? I'd be happy to do this <FIXME> as part
of this contribution (though perhaps I should read the cited paper and
conduct some simple simulations).  A simple, "that would be great,
Jay" or "don't bother" would suffice -- it may be that someone else is
working on it.

Thoughts welcome, either on these particular issues, or on the manner
in which they relate to John's thread.

Cheers,

Jay


--
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From djsamperi at gmail.com  Sat Dec  4 16:17:55 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 4 Dec 2010 10:17:55 -0500
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTingqLfXi0vyfdD11m4Y1J4rRGm-APsoUuu7jzx3@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
	<AANLkTi=NtZz0DKpPrm9zOc_0SfKU0UnzmxLetmL3HfDH@mail.gmail.com>
	<AANLkTingqLfXi0vyfdD11m4Y1J4rRGm-APsoUuu7jzx3@mail.gmail.com>
Message-ID: <AANLkTi=CRf6ZxGZMP4yRYns4jhExfEWM_V8X8vPrYB_O@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101204/ecf4b33e/attachment.pl>

From romain at r-enthusiasts.com  Sat Dec  4 18:12:02 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Sat, 04 Dec 2010 18:12:02 +0100
Subject: [Rd] Enough (was: Terminology clarification (Re: GPL and R
 Community	Policies (Rcpp))
In-Reply-To: <AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>	<1291299654.7962.495.camel@braque.iarc.fr>	<4CF7B981.70404@structuremonitoring.com>	<002501cb9236$b0c634a0$12529de0$@edu>	<19704.4415.474447.28419@max.nulle.part>	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
Message-ID: <4CFA7662.9050409@r-enthusiasts.com>

Dear Dominick,

Thank you so much for the numerous reminders about this request of yours.

You will be pleased to know that as part of our ongoing search for 
quality, the current development version of the Rcpp package no longer 
contains code from what we call the `classic Rcpp' API. We owe this 
classic API to your contribution and for that we are grateful. It will 
be released as another package outside of Rcpp as a courtesy to R users 
and CRAN package maintainers who still want to use this API which we 
consider deprecated.

As of the current svn status of Rcpp (rev 2711 on r-forge), your name 
appears in several places, detailed below. Feel free to take whatever 
actions you find appropriate if this does not suit your needs.

Lastly, please do not take R-devel hostage of this thread anymore. Feel 
free to send your questions and remarks to the place where it belongs: 
the Rcpp-devel mailing list.


Regards,

Romain




$ grep -R Samperi * | grep -v .svn
DESCRIPTION: 'classic Rcpp API' was written during 2005 and 2006 by 
Dominick Samperi.
debian/copyright:R / C++ interface package. Rcpp was written by Dominick 
Samperi,
debian/copyright:   2005 and 2006 by Dominick Samperi
inst/announce/ANNOUNCE-0.6.0.txt:Rcpp was initially written by Dominick 
Samperi as part of his contributions
inst/doc/Rcpp-introduction.Rnw:\pkg{Rcpp} first appeared in 2005 as a 
contribution (by Samperi) to the
inst/doc/Rcpp-introduction.Rnw:in early 2006. Several releases (all by 
Samperi) followed in quick succession
inst/doc/Rcpp.bib:  author =	 {Dominick Samperi},
inst/doc/Rcpp.bib:@Manual{Samperi:2009:RcppTemplate,
inst/doc/Rcpp.bib:  author =	 {Dominick Samperi},
inst/README:Rcpp continues and extends earlier work by Dominick Samperi 
which he initially
inst/THANKS:Dominick Samperi        for starting what we now call the 
Classic Rcpp
man/Rcpp-package.Rd:  The initial versions of Rcpp were written by 
Dominick Samperi during 2005 and
src/Makevars.win:# (C) Dominick Samperi and Uwe Ligges and gratefully 
acknowledged


* In the DESCRIPTION file [1] in the Description field
* In the debian/copyright file [2]
* in the ANNOUNCE-0.6.0.txt file which records the announcement that was 
made about the relauch of Rcpp. The file is a plain text copy of the 
email that was sent to the R-pkgs mailing list on 2008/12/03 [3].
* In the Rcpp-introduction.Rnw file [4]. In the Historical context 
subsection.
* In the Rcpp.bib file [5] that we use to reference to creations of yours.
* In the README file [6] where we acknowledge that Rcpp initiated from you.
* In the THANKS file [7] where we acknowledge your involvment.
* In the Makevars.win file [8]

[1] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/DESCRIPTION?root=rcpp
[2] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/debian/copyright?root=rcpp
[3] https://stat.ethz.ch/pipermail/r-packages/2008/000980.html
[4] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/inst/doc/Rcpp-introduction.Rnw?root=rcpp
[5] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/inst/doc/Rcpp.bib?root=rcpp
[6] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/inst/README?root=rcpp
[7] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/inst/THANKS?root=rcpp
[8] 
https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/Rcpp/src/Makevars.win?root=rcpp



Le 03/12/10 00:28, Dominick Samperi a ?crit :
 >
 > On Thu, Dec 2, 2010 at 5:58 PM, Dirk Eddelbuettel<edd at debian.org>  wrote:
 >
 >>
 >> On 2 December 2010 at 17:23, Dominick Samperi wrote:
 >> | OK, since you are so accomodating, then please remove all reference to
 >> | my name from Rcpp as I do not want to be subject to arbitrary 
revisions
 >> of
 >> | my status. I may not have the right to say how my prior work will be
 >> used,
 >> | but I think I have the right to ask that my name not be used in 
the way
 >> | it is used in the recent update.
 >>
 >> As I pointed out, you change your mind on this every 12 months, 
limiting my
 >> patience and willingness for these dances.  It has also been 
suggested by
 >> other than attribution is clearer if you listed as the maintainer of the
 >> 2005/2006 code that we started from in 2008.
 >>
 >
 > The change that this thread is a reaction to happened a few days ago, not
 > 12 months ago. If I wavered in the past it was because I was being
 > forced to compete with my own work, not a pleasant place to be.
 >
 > Are you telling me that you refuse to stop using my name
 > in Rcpp (except in copyright notices)?
 >
 > Are you telling me that you will continue to use my name and
 > update the associated status as you see fit, whether or not I
 > approve or consent to those changes?
 >
 > Please answer yes or no.
 >
 > Thanks,
 > Dominick


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/gpCSpH : Evolution of Rcpp code size
|- http://bit.ly/hovakS : RcppGSL initial release
`- http://bit.ly/iaxTdO : parser 0.0-12


From djsamperi at gmail.com  Sat Dec  4 19:09:53 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 4 Dec 2010 13:09:53 -0500
Subject: [Rd] Enough (was: Terminology clarification (Re: GPL and R
 Community Policies (Rcpp))
In-Reply-To: <4CFA7662.9050409@r-enthusiasts.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
	<4CFA7662.9050409@r-enthusiasts.com>
Message-ID: <AANLkTi=3+qvsTyX=5J_FcGBYuS1=wbz7T0NDYBBQ_YDf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101204/065d1144/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Dec  5 09:04:17 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 5 Dec 2010 08:04:17 +0000 (GMT)
Subject: [Rd] SurviveGotoBLAS2 for Win64 (human sacrifice release)
In-Reply-To: <AANLkTina-mGgcnWqvHHsXR6gQxtP0C9+Aah1JvaXwy3-@mail.gmail.com>
References: <AANLkTina-mGgcnWqvHHsXR6gQxtP0C9+Aah1JvaXwy3-@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1012050751410.23933@gannet.stats.ox.ac.uk>

Ei-ji,

Thank you for looking into this.  I had also noticed that GotoBLAS2 
now has a compatible licence and started looking into using it on 
Windows.  However, like most BLAS this is tied to a particular chip 
(you don't say what you used: my machine is identified as penryn) and 
I am undecided if it is worth provided a range of pre-compiled 
GotoBLAS2 Rblas.dll (or how wide the range would need to be to be 
useful).  Maybe just "core2" would be useful: maybe penryn, 
dunnington, nehalem and atom are needed.  (A quick look suggests 
dunnington is not used, and nehalem is only used on x86_64.)

So I'd identified this as something which would need quite a bit of 
thought, maybe something to be done for R 2.13.0.

Brian


On Sat, 4 Dec 2010, Ei-ji Nakama wrote:

> Hi,
>
> I put below Rblas.dll(GotoBLAS2 for Win64).
> http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/windows/x64/Rblas.dll
> It's a tryal phase.
>
> -- 
> EI-JI Nakama? <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From nakama at ki.rim.or.jp  Sun Dec  5 16:02:40 2010
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Mon, 6 Dec 2010 00:02:40 +0900
Subject: [Rd] SurviveGotoBLAS2 for Win64 (human sacrifice release)
In-Reply-To: <alpine.LFD.2.00.1012050751410.23933@gannet.stats.ox.ac.uk>
References: <AANLkTina-mGgcnWqvHHsXR6gQxtP0C9+Aah1JvaXwy3-@mail.gmail.com>
	<alpine.LFD.2.00.1012050751410.23933@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTimxntOsR24qMYExcgQtssY3h_Tee_diA5G_X8Oi@mail.gmail.com>

Hi,

2010/12/5 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>?However, like most BLAS this is tied to a particular chip (you don't say what you
> used: my machine is identified as penryn) and I am undecided if it is worth
> provided a range of pre-compiled GotoBLAS2 Rblas.dll (or how wide the range
> would need to be to be useful).

It is the build with DYNAMIC_ARCH.

> ?Maybe just "core2" would be useful: maybe penryn, dunnington, nehalem
> and atom are needed. ?(A quick look suggests dunnington is not used,
> and nehalem is only used on x86_64.)

If CPU is not identified, an appropriate routine is not used.
However, neither the model of CPU nor the value of the exmodel etc
completely have the rule.
The stack alignments of Win64 are 8bytes in default.
However, stack alignments of Win32 is 4bytes (mingw,thread and DLL case).
Therefore, it doesn't run.
If the results of a lot of CPUID(http://www.etallen.com/cpuid.html)
are collected,
the automatic recognition is ameliorable.

$ ./cpuid | sed -n '/^CPU 0:/,/^CPU 1:/p'|grep "vendor_id" -B0 -C8
  vendor_id = "GenuineIntel"
  version information (1/eax):
     processor type  = primary processor (0)
     family          = Intel Pentium Pro/II/III/Celeron/Core/Core
2/Atom, AMD Athlon/Duron, Cyrix M2, VIA C3 (6)
     model           = 0xc (12)
     stepping id     = 0x2 (2)
     extended family = 0x0 (0)
     extended model  = 0x2 (2)
     (simple synth)  = Intel Core i7-900 (Gulftown B1) / Core i7-980X
(Gulftown B1) / Xeon Processor 3600 (Westmere-EP B1) / Xeon Processor
5600 (Westmere-EP B1), 32nm

> So I'd identified this as something which would need quite a bit of thought,
> maybe something to be done for R 2.13.0.

I reaction may be dull.
-- 
EI-JI Nakama? <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>


From murdoch.duncan at gmail.com  Sun Dec  5 16:12:03 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 05 Dec 2010 10:12:03 -0500
Subject: [Rd] Competing with one's own work
In-Reply-To: <loom.20101203T214523-53@post.gmane.org>
References: <4CF91361.7090005@uottawa.ca>
	<4CF91704.7070605@gmail.com>	<003601cb930b$b28205a0$178610e0$@edu>
	<4CF94288.3020301@gmail.com>	<006501cb931f$32a478e0$97ed6aa0$@edu>
	<loom.20101203T214523-53@post.gmane.org>
Message-ID: <4CFBABC3.10702@gmail.com>

On 03/12/2010 4:08 PM, Ben Bolker wrote:
> Ravi Varadhan<rvaradhan<at>  jhmi.edu>  writes:
>
>>
>> "The decision about whether it belongs in a package or in base R is
>> about who should maintain the code."
>>
>> Ok.  I understand it now.
>>
>> Thanks,
>> Ravi.
>>
>
>     A point that may not have been made (sorry if it was and I missed it):
>
> A better question might be how packages get added to the *recommended*
> package list (rather than how code gets added to "base R").

I haven't seen any other response to this, so I'll give an incomplete one.

Packages get added to the recommended list when the core is convinced 
they should be.  It doesn't happen often:  Matrix was the most recent 
addition in R 2.9.0; before that I think it was codetools in 2.5.0.

Being recommended means that the release schedule needs to be 
coordinated with R's releases, because there should be a code freeze 
when R is frozen, and the author needs to be responsive to bug reports. 
  (There can be releases outside of R releases; this is a difference 
from base packages, which are only released with R.)

If a package is recommended, then it needs to be rebuilt to run the R 
tests.  This means tests of base R functionality can depend on a 
recommended package; it also means every additional recommended package 
slows down the tests.  (And it's a real pain on those rare occasions 
when a bug in a recommended package causes a test to fail, because we 
can't necessarily fix the recommended package.)

So just because a package is good quality and contains useful or 
important code, it shouldn't necessarily become a recommended package. 
I don't think there are clear rules about when it should, just as there 
aren't for other R changes.

Duncan Murdoch


> Of the
> 16 recommended packages, 2 are maintained by R-core itself, 12 by various
> R-core members acting as individuals (I assume), and 2 by non-R-core
> people. It seems that if a contributed package sticks around long enough
> and proves itself sufficiently useful and of sufficiently high quality
> (and well enough maintained), that it could then be suggested as
> a recommended package.
>
> i1<- installed.packages()
> i2<- i1[!is.na(i1[,"Priority"]),]
> ff<- function(x) table(sapply(x[,"Package"],maintainer))
> ff(i2[i2[,"Priority"]=="base",])
>
> R Core Team<R-core at r-project.org>
>                                  12
>
> ff(i2[i2[,"Priority"]=="recommended",])
>
>             Brian Ripley<ripley at stats.ox.ac.uk>
>                                                7
> Deepayan Sarkar<deepayan.sarkar at r-project.org>
>                                                2
>   Doug and Martin<Matrix-authors at R-project.org>
>                                                1
>               Luke Tierney<luke at stat.uiowa.edu>
>                                                1
>     Martin Maechler<maechler at stat.math.ethz.ch>
>                                                1
>                    R-core<R-core at R-project.org>
>                                                1
>                    R-core<R-core at r-project.org>
>                                                1
>            Simon Wood<simon.wood at r-project.org>
>                                                1
>         Terry Therneau<therneau.terry at mayo.edu>
>                                                1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From chris.jewell at warwick.ac.uk  Mon Dec  6 16:43:34 2010
From: chris.jewell at warwick.ac.uk (Chris Jewell)
Date: Mon, 6 Dec 2010 15:43:34 +0000
Subject: [Rd] R with ATLAS avoids Linux cpu affinity
Message-ID: <91017BEA-2AF0-4040-888A-6C09D0690B9C@warwick.ac.uk>

Hi all,

I have a problem with cpu affinity in my R-2.11.1 installation compiled against ATLAS running on a Linux (Ubuntu 10.04) cluster under GridEngine.  I wish to use Grid Engine's core binding feature to bind user processes into the number of cores they request on the cluster, thus preventing badly behaved multi-threaded libraries from consuming more cores than requested.  An example of this is R compiled against multithreaded ATLAS, which needs to be bound into a single core if a user submits a 1 core job.  Grid Engine achieves this through the sched_setaffinity system call under Linux 2.6.  For most applications (including if I write a test C program that uses ATLAS BLAS), this works well, and prevents threads from 'leaking' outside the cpu set they are assigned.  However, R appears to be able to avoid the core binding.  This is *very* strange as I was under the impression that any child processes or threads inherit the cpu affinity of the parent.

Does anyone have experience of this and could offer a comment or solution?

Thanks,

Chris

--
Dr Chris Jewell
Department of Statistics
University of Warwick
Coventry
CV4 7AL
UK
Tel: +44 (0)24 7615 0778


From edd at debian.org  Mon Dec  6 17:03:04 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 6 Dec 2010 10:03:04 -0600
Subject: [Rd] R with ATLAS avoids Linux cpu affinity
In-Reply-To: <91017BEA-2AF0-4040-888A-6C09D0690B9C@warwick.ac.uk>
References: <91017BEA-2AF0-4040-888A-6C09D0690B9C@warwick.ac.uk>
Message-ID: <19709.2360.287048.26325@max.nulle.part>


Chris,

On 6 December 2010 at 15:43, Chris Jewell wrote:
| Hi all,
| 
| I have a problem with cpu affinity in my R-2.11.1 installation compiled against ATLAS running on a Linux (Ubuntu 10.04) cluster under GridEngine.  I wish to use Grid Engine's core binding feature to bind user processes into the number of cores they request on the cluster, thus preventing badly behaved multi-threaded libraries from consuming more cores than requested.  An example of this is R compiled against multithreaded ATLAS, which needs to be bound into a single core if a user submits a 1 core job.  Grid Engine achieves this through the sched_setaffinity system call under Linux 2.6.  For most applications (including if I write a test C program that uses ATLAS BLAS), this works well, and prevents threads from 'leaking' outside the cpu set they are assigned.  However, R appears to be able to avoid the core binding.  This is *very* strange as I was under the impression that any child processes or threads inherit the cpu affinity of the parent.
| 
| Does anyone have experience of this and could offer a comment or solution? 

Atlas will _always_ use all the cores 'compiled in'.  

Ubuntu's current package just uses one (as it is not a multithreaded
build). This will change with future package as per the Debian / Ubuntu
package maintainer.  If you built Atlas locally, you may be use all cores
(depending on how you built).

There is simply no way to 'scale up or down' dynamically with Atlas -- but
both MKL and GotoBLAS2 can do this.  See my package / paper on BLAS and GPU
benchmarking (cf http://dirk.eddelbuettel.com/blog/code/gcbd/ for two posts
and links) for details.

AFAICT R should not alter CPU affinity.  So if I were you I'd swap the BLAS
implementation and try again.  As you are on Ubuntu, you can try the MKL that
comes with the (now a littler older) Revolution R in Ubuntu 9.10; otherwise I
can highly recommend the GotoBLAS2 helper package listed in my paper for a
local GotoBLAS2 built.   The script may be out of sync with the fairly recent
license change of GotoBLAS2 (to the more liberal BSD license permitting
redistribution).  With some luck we will GotoBLAS2 deb packages in future
Debian and Ubuntu releases.

Hth,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From therneau at mayo.edu  Mon Dec  6 18:35:25 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 06 Dec 2010 11:35:25 -0600
Subject: [Rd] Competing with one's own work
Message-ID: <1291656925.22256.17.camel@punchbuggy>

Ben raised an interesting point: "A better question might be how
packages get added to the *recommended*
package list (rather than how code gets added to "base R")."

  As maintainer of survival one of the surprising things is the number
of packages that depend on mine.  This has caused me to change my
opinion over the last few years about how much expansion of the package
should occur.  I used to feel bad that the package doesn't keep up with
everything, now I tend to vote for putting new ideas elsewhere.
Consider competing risks for instance.  The cleanest way to code this is
to extend the Surv(time, status) construct to allow more than a 0/1
status variable.  I thought about this seriously, and realized that such
a change would have ripple effects on some of the other routines -- an
extra if statement here and there.  This is doable, but what about the
effect on the 153 dependent packages!  The stability of survival is now
more important than its feature set.
  My first extention to random effects (a very simplistic one) was
incorporated into the main survival package.  I've pushed the later
developments into thier own package.  It was definitely the right
choice.
        
        Terry T


From wdunlap at tibco.com  Mon Dec  6 19:03:27 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 6 Dec 2010 10:03:27 -0800
Subject: [Rd] when to use pairlist instead list
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003B1DD94@NA-PA-VBE03.na.tibco.com>

I was writing some assertion tests for modelling-related
code I had written and was surprised to see one test
fail because the "specials" attribute of the output of
terms() is a "pairlist" instead of a "list".  In 2.12.0
I get:

  > dput(attr(terms(y~Spec(x1)+x2, specials=c("Spec")), "specials"))
  list(Spec = 2L)
  >  all.equal(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
"specials"), list(Spec=2L))
  [1] "Modes: pairlist, list"
  >  all.equal(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
"specials"), pairlist(Spec=2L))
  [1] TRUE
  >  identical(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
"specials"), pairlist(Spec=2L))
  [1] TRUE

I was wondering if there was a reason for using pairlist
instead of list here or it it was just an historical
artifact.  In general, when should one use pairlists?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From JHZhang at mdanderson.org  Mon Dec  6 20:26:45 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Mon, 6 Dec 2010 13:26:45 -0600
Subject: [Rd] Problem installing RCurl
In-Reply-To: <alpine.LFD.2.00.1012040641190.29989@gannet.stats.ox.ac.uk>
References: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>
	<4CF9845F.5070804@wald.ucdavis.edu>
	<alpine.LFD.2.00.1012040641190.29989@gannet.stats.ox.ac.uk>
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E6A301F5@DCPWVMBXC1VS2.mdanderson.edu>

Thank you both for your reply.
After reading your responses, I removed the existing CSWcurl, and compiled curl-7.21.2 from source using solstudio (the same compiler I got R-2.12.0 in place) to /opt/csw. Tried to install RCurl, I got the same error, the only difference is the include file's line number,

"/opt/csw/include/curl/curlrules.h", line 143: zero or negative subscript

The line 143 is the third line of the following, the variable must have been defined outside the file.
typedef char
  __curl_rule_01__
    [CurlchkszEQ(long, CURL_SIZEOF_LONG)];

I don't know what value the compiler expect, but can I define it here if I know?

As to the bit, this machine's got 64G memory, I simply has no choice but to compile 64-bit R.

Jun

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
Sent: Saturday, December 04, 2010 1:03 AM
To: Duncan Temple Lang
Cc: r-devel at r-project.org
Subject: Re: [Rd] Problem installing RCurl

On Fri, 3 Dec 2010, Duncan Temple Lang wrote:

>
> Hi Jun
>
> On 12/3/10 2:15 PM, Zhang,Jun wrote:
>> I have 64-bit R 2 12 0 installed on Solaris 10 of Sun Sparc. When I tried to install RCurl, it failed with the following lines,
>>
>> ...............
>> Version has CURLOPT_SSL_SESSIONID_CACHE
>> libcurl version: libcurl 7.19.6
>> configure: creating ./config.status
>> config.status: creating src/Makevars
>> ** libs
>> cc -xc99 -m64 -xarch=sparcvis2 -I/apps/sparcv9/R-2.12.0/lib/R/include -I/opt/csw/include -DHAVE_LIBIDN_FIELD=1 -DHAVE_CURLOPT_URL=1 -DHAVE_CURLINFO_EFFECTIVE_URL=1 .........(omitted here is very long, all upper case) -DHAVE_CURLOPT_SSL_SESSIONID_CACHE=1 -I/opt/csw/include    -KPIC  -xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2 -c base64.c -o base64.o
>> "/opt/csw/include/curl/curlrules.h", line 144: zero or negative subscript
>
> This error indicates that the compiler (cc with flags -xc99 -m64, 
> etc.) sees the size of the 'long' data type in C is different from 
> what was seen when libcurl was configured, built and installed.
>
> So basically the compiler and/or the compiler flags were different.
>
> How was libcurl installed - from source or from a pre-built binary ?
> What compiler and flags were used?

The header is from a prebuilt binary (from OpenCSW).  That is built 
with gcc and not the Sun compiler.  And curlbuild.h says

/* Allow 32 and 64 bit headers to coexist */
#if defined __amd64 || defined __x86_64 || defined __sparcv9
#include "curlbuild-64.h"
#else
#include "curlbuild-32.h"
#endif

which AFAIK are gcc and not Sun defines.  You could try adding 
-D__sparcv9 to the CPPFLAGS, or compile RCurl with OpenCSW's gcc 
build (but 64-bit gcc is another can of worms).

I've pointed out to Jun Zhang several times that 64-bit Sparc Solaris 
is really pushing it, and 32-bit R on Sparc Solaris has been much more 
successful.  Given that x86_64 boxes (Solaris or Linux) are so much 
faster at computation than Sparc ones, I don't see the point of 
building 64-bit Sparc Solaris R -- if 32-bit R is not enough you need 
a faster machine.

>
>  D.
>
>
>> "base64.c", line 25: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> "base64.c", line 39: warning: argument #1 is incompatible with prototype:
>>         prototype: pointer to const char : "/apps/sparcv9/R-2.12.0/lib/R/include/Rinternals.h", line 1042
>>         argument : pointer to unsigned char
>> "base64.c", line 60: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> cc: acomp failed for base64.c
>> make: *** [base64.o] Error 2
>> ERROR: compilation failed for package 'RCurl'
>> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/RCurl'
>>
>> The downloaded packages are in
>>         '/tmp/Rtmpo67mNX/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Warning message:
>> In install.packages("RCurl") :
>>   installation of package 'RCurl' had non-zero exit status
>>>
>>
>> What is the problem?
>>
>> Jun
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Dec  6 20:49:40 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Dec 2010 19:49:40 +0000 (GMT)
Subject: [Rd] when to use pairlist instead list
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003B1DD94@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70003B1DD94@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.1012061924370.25014@gannet.stats.ox.ac.uk>

On Mon, 6 Dec 2010, William Dunlap wrote:

> I was writing some assertion tests for modelling-related
> code I had written and was surprised to see one test
> fail because the "specials" attribute of the output of
> terms() is a "pairlist" instead of a "list".  In 2.12.0
> I get:
>
>  > dput(attr(terms(y~Spec(x1)+x2, specials=c("Spec")), "specials"))
>  list(Spec = 2L)
>  >  all.equal(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
> "specials"), list(Spec=2L))
>  [1] "Modes: pairlist, list"
>  >  all.equal(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
> "specials"), pairlist(Spec=2L))
>  [1] TRUE
>  >  identical(attr(terms(y~Spec(x1)+x2, specials=c("Spec")),
> "specials"), pairlist(Spec=2L))
>  [1] TRUE
>
> I was wondering if there was a reason for using pairlist
> instead of list here or it it was just an historical
> artifact.  In general, when should one use pairlists?

Probably never directly.  But indirectly, a lot as for example 
argument lists are pairlists.

Looking at the code, I think this one is simply history.  For 
completeness I will correct ?terms.object.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chris.jewell at warwick.ac.uk  Mon Dec  6 20:58:36 2010
From: chris.jewell at warwick.ac.uk (Chris Jewell)
Date: Mon, 6 Dec 2010 19:58:36 +0000
Subject: [Rd] R with ATLAS avoids Linux cpu affinity
In-Reply-To: <19709.2360.287048.26325@max.nulle.part>
References: <91017BEA-2AF0-4040-888A-6C09D0690B9C@warwick.ac.uk>
	<19709.2360.287048.26325@max.nulle.part>
Message-ID: <408D77D5-A33A-455E-99C8-6608EACE6F3A@warwick.ac.uk>


On 6 Dec 2010, at 16:03, Dirk Eddelbuettel wrote:
> AFAICT R should not alter CPU affinity.  So if I were you I'd swap the BLAS
> implementation and try again.  As you are on Ubuntu, you can try the MKL that
> comes with the (now a littler older) Revolution R in Ubuntu 9.10; otherwise I
> can highly recommend the GotoBLAS2 helper package listed in my paper for a
> local GotoBLAS2 built.   The script may be out of sync with the fairly recent
> license change of GotoBLAS2 (to the more liberal BSD license permitting
> redistribution).  With some luck we will GotoBLAS2 deb packages in future
> Debian and Ubuntu releases.


Thanks for the comments, Dirk.  I take your point about ATLAS having the cores compiled in.  I have replaced ATLAS with ACML, and all works fine.

Cheers,

Chris


--
Dr Chris Jewell
Department of Statistics
University of Warwick
Coventry
CV4 7AL
UK
Tel: +44 (0)24 7615 0778


From JHZhang at mdanderson.org  Tue Dec  7 00:15:18 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Mon, 6 Dec 2010 17:15:18 -0600
Subject: [Rd] Problem installing RCurl
In-Reply-To: <5685E4FBA752A441B1975A77A77CD64824E6A301F5@DCPWVMBXC1VS2.mdanderson.edu>
References: <5685E4FBA752A441B1975A77A77CD64824E371FBA0@DCPWVMBXC1VS2.mdanderson.edu>
	<4CF9845F.5070804@wald.ucdavis.edu>
	<alpine.LFD.2.00.1012040641190.29989@gannet.stats.ox.ac.uk>
	<5685E4FBA752A441B1975A77A77CD64824E6A301F5@DCPWVMBXC1VS2.mdanderson.edu>
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E6A3026D@DCPWVMBXC1VS2.mdanderson.edu>

I tried to give CPPFLAGS the value -D__sparcv9, the compiler complaint about "cross compiling".
And then I tried CPPFLAGS="-D__sparcv9 -U__sparcv8", export it, installation of curl-7.21.2 is fine, but give me just the 32-bit result.

Any hint will be appreciated to buil the 64-bit curl (only then I have hope to install RCurl). 

Jun

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Zhang,Jun
Sent: Monday, December 06, 2010 1:27 PM
To: 'Prof Brian Ripley'; 'Duncan Temple Lang'
Cc: 'r-devel at r-project.org'
Subject: Re: [Rd] Problem installing RCurl

Thank you both for your reply.
After reading your responses, I removed the existing CSWcurl, and compiled curl-7.21.2 from source using solstudio (the same compiler I got R-2.12.0 in place) to /opt/csw. Tried to install RCurl, I got the same error, the only difference is the include file's line number,

"/opt/csw/include/curl/curlrules.h", line 143: zero or negative subscript

The line 143 is the third line of the following, the variable must have been defined outside the file.
typedef char
  __curl_rule_01__
    [CurlchkszEQ(long, CURL_SIZEOF_LONG)];

I don't know what value the compiler expect, but can I define it here if I know?

As to the bit, this machine's got 64G memory, I simply has no choice but to compile 64-bit R.

Jun

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
Sent: Saturday, December 04, 2010 1:03 AM
To: Duncan Temple Lang
Cc: r-devel at r-project.org
Subject: Re: [Rd] Problem installing RCurl

On Fri, 3 Dec 2010, Duncan Temple Lang wrote:

>
> Hi Jun
>
> On 12/3/10 2:15 PM, Zhang,Jun wrote:
>> I have 64-bit R 2 12 0 installed on Solaris 10 of Sun Sparc. When I tried to install RCurl, it failed with the following lines,
>>
>> ...............
>> Version has CURLOPT_SSL_SESSIONID_CACHE
>> libcurl version: libcurl 7.19.6
>> configure: creating ./config.status
>> config.status: creating src/Makevars
>> ** libs
>> cc -xc99 -m64 -xarch=sparcvis2 -I/apps/sparcv9/R-2.12.0/lib/R/include -I/opt/csw/include -DHAVE_LIBIDN_FIELD=1 -DHAVE_CURLOPT_URL=1 -DHAVE_CURLINFO_EFFECTIVE_URL=1 .........(omitted here is very long, all upper case) -DHAVE_CURLOPT_SSL_SESSIONID_CACHE=1 -I/opt/csw/include    -KPIC  -xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2 -c base64.c -o base64.o
>> "/opt/csw/include/curl/curlrules.h", line 144: zero or negative subscript
>
> This error indicates that the compiler (cc with flags -xc99 -m64, 
> etc.) sees the size of the 'long' data type in C is different from 
> what was seen when libcurl was configured, built and installed.
>
> So basically the compiler and/or the compiler flags were different.
>
> How was libcurl installed - from source or from a pre-built binary ?
> What compiler and flags were used?

The header is from a prebuilt binary (from OpenCSW).  That is built 
with gcc and not the Sun compiler.  And curlbuild.h says

/* Allow 32 and 64 bit headers to coexist */
#if defined __amd64 || defined __x86_64 || defined __sparcv9
#include "curlbuild-64.h"
#else
#include "curlbuild-32.h"
#endif

which AFAIK are gcc and not Sun defines.  You could try adding 
-D__sparcv9 to the CPPFLAGS, or compile RCurl with OpenCSW's gcc 
build (but 64-bit gcc is another can of worms).

I've pointed out to Jun Zhang several times that 64-bit Sparc Solaris 
is really pushing it, and 32-bit R on Sparc Solaris has been much more 
successful.  Given that x86_64 boxes (Solaris or Linux) are so much 
faster at computation than Sparc ones, I don't see the point of 
building 64-bit Sparc Solaris R -- if 32-bit R is not enough you need 
a faster machine.

>
>  D.
>
>
>> "base64.c", line 25: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> "base64.c", line 39: warning: argument #1 is incompatible with prototype:
>>         prototype: pointer to const char : "/apps/sparcv9/R-2.12.0/lib/R/include/Rinternals.h", line 1042
>>         argument : pointer to unsigned char
>> "base64.c", line 60: warning: assignment type mismatch:
>>         pointer to const char "=" pointer to unsigned char
>> cc: acomp failed for base64.c
>> make: *** [base64.o] Error 2
>> ERROR: compilation failed for package 'RCurl'
>> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/RCurl'
>>
>> The downloaded packages are in
>>         '/tmp/Rtmpo67mNX/downloaded_packages'
>> Updating HTML index of packages in '.Library'
>> Warning message:
>> In install.packages("RCurl") :
>>   installation of package 'RCurl' had non-zero exit status
>>>
>>
>> What is the problem?
>>
>> Jun
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at structuremonitoring.com  Tue Dec  7 00:32:44 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 06 Dec 2010 15:32:44 -0800
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
Message-ID: <4CFD729C.6050704@structuremonitoring.com>

Hello:


       The example "integrate(dnorm,0,20000)" says it "fails on many 
systems".  I just got 0 from it, when I should have gotten either an 
error or something close to 0.5.  I got this with R 2.12.0 under both 
Windows Vista_x64 and Linux (Fedora 13);  see the results from Windows 
below.  I thought you might want to know.


       Thanks for all your work in creating and maintaining R.


       Best Wishes,
       Spencer Graves
###############################

integrate(dnorm,0,20000) ## fails on many systems
0 with absolute error < 0
 > sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From ripley at stats.ox.ac.uk  Tue Dec  7 08:41:16 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Dec 2010 07:41:16 +0000 (GMT)
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <4CFD729C.6050704@structuremonitoring.com>
References: <4CFD729C.6050704@structuremonitoring.com>
Message-ID: <alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>

On Mon, 6 Dec 2010, Spencer Graves wrote:

> Hello:
>
>
>      The example "integrate(dnorm,0,20000)" says it "fails on many systems". 
> I just got 0 from it, when I should have gotten either an error or something 
> close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and 
> Linux (Fedora 13);  see the results from Windows below.  I thought you might 
> want to know.

Well, isn't that exactly what the help page says happens?  That 
example is part of a section entitled

      ## integrate can fail if misused

and is part of the illustration of

      If the function is
      approximately constant (in particular, zero) over nearly all its
      range it is possible that the result and error estimate may be
      seriously wrong.



>
>
>      Thanks for all your work in creating and maintaining R.
>
>
>      Best Wishes,
>      Spencer Graves
> ###############################
>
> integrate(dnorm,0,20000) ## fails on many systems
> 0 with absolute error < 0
>> sessionInfo()
> R version 2.12.0 (2010-10-15)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From baptiste.auguie at googlemail.com  Tue Dec  7 09:07:56 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Tue, 7 Dec 2010 09:07:56 +0100
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <4CFD729C.6050704@structuremonitoring.com>
References: <4CFD729C.6050704@structuremonitoring.com>
Message-ID: <AANLkTikzd5j2dG97FWNMxcJCm3MwfRjAs4y8X-pgmhnA@mail.gmail.com>

Hi,

I was recently given some interesting tips on a similar issue, see
R-help "puzzle with integrate over infinite range"
<http://www.r-help.com/list/85/713882.html>

Maybe "fails" can be a bit misleading here (fails to produce the
actual result vs. returning an error message). As a result of this
previous discussion, I don't think it would be possible to return an
error: as far as the algorithm knows, the value it calculated is 0
because the integrand was 0 everywhere. To know better, the program
would need to sample the integrand at more points (which can be
achieved by changing the interval, or better, by setting the tolerance
to a lower value).

baptiste



On 7 December 2010 00:32, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hello:
>
>
> ? ? ?The example "integrate(dnorm,0,20000)" says it "fails on many systems".
> ?I just got 0 from it, when I should have gotten either an error or
> something close to 0.5. ?I got this with R 2.12.0 under both Windows
> Vista_x64 and Linux (Fedora 13); ?see the results from Windows below. ?I
> thought you might want to know.
>
>
> ? ? ?Thanks for all your work in creating and maintaining R.
>
>
> ? ? ?Best Wishes,
> ? ? ?Spencer Graves
> ###############################
>
> integrate(dnorm,0,20000) ## fails on many systems
> 0 with absolute error < 0
>> sessionInfo()
> R version 2.12.0 (2010-10-15)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue Dec  7 09:28:16 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Dec 2010 09:28:16 +0100
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
References: <4CFD729C.6050704@structuremonitoring.com>
	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
Message-ID: <19709.61472.158760.44576@lynne.math.ethz.ch>

>>>>> Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:

    > On Mon, 6 Dec 2010, Spencer Graves wrote:
    >> Hello:
    >> 
    >> 
    >> The example "integrate(dnorm,0,20000)" says it "fails on many systems". 
    >> I just got 0 from it, when I should have gotten either an error or something 
    >> close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and 
    >> Linux (Fedora 13);  see the results from Windows below.  I thought you might 
    >> want to know.

    > Well, isn't that exactly what the help page says happens?  That 
    > example is part of a section entitled

    > ## integrate can fail if misused

    > and is part of the illustration of

    > If the function is
    > approximately constant (in particular, zero) over nearly all its
    > range it is possible that the result and error estimate may be
    > seriously wrong.

yes, of course, 
and the issue has been known for ``ages''  ..
..........
..........
but it seems that too many useRs are not reading the help
page carefully, but only browse it quickly.
I think we (R developers) have to live with this fact
and should consider adapting to it a bit more, particularly in
this case (see below)

    >> 
    >> Thanks for all your work in creating and maintaining R.
    >> 
    >> 
    >> Best Wishes,
    >> Spencer Graves
    >> ###############################

    >> 
    >> integrate(dnorm,0,20000) ## fails on many systems

    >> 0 with absolute error < 0

and this is particularly unsatisfactory for another reason:

"absolute error < 0"   
is *always* incorrect, so I think we should change *some*thing.

We could just use "<=" (and probably should in any case, or  
"< ~= x" which would convey ``is less than about x'' which I
think is all we can say),
but could consider giving a different message when the integral
evaluates to 0 or, rather actually,
only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
as the latter indicates that the algorithm treated the integrand
f(.) as if f() was a linear function.

But in my quick experiments, even for linear (incl. constant)
functions, the 'abs.error' returned is never 0.

If we want to be cautious,
such a warning could be made explicitly suppressable by an argument
      .warn.if.doubtful = TRUE

An additional possibility I'd like to try, is a new argument
   'min.subdivisions = 3' which specifies the *minimal* number
of subdivisions to be used in addition to the already present
   'subdivisions = 100' (= the maximum number of subintervals.)

Martin Maechler,
ETH Zurich


From dam_damdeo33 at hotmail.com  Mon Dec  6 17:25:39 2010
From: dam_damdeo33 at hotmail.com (Alexandre)
Date: Mon, 6 Dec 2010 08:25:39 -0800 (PST)
Subject: [Rd] Wait for user input with readline()
In-Reply-To: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
References: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
Message-ID: <1291652739318-3074781.post@n4.nabble.com>


Hi,

I have a similar problem as the one of Nate. The point is that I want to
design an interactive script that need the value of two variables (x and y).

So my script as designed for the moment is :

x <- as.numeric (readline(prompt="What is the value of x? "))
y <- as.numeric (readline(prompt="What is the value of y? "))

x
y 

But the problem is that if I run this script, values returned for x and y
will be "NA" like you can see below :

> x <- as.numeric (readline(prompt="What is the value of x? "))
What is the value of x? 
> y <- as.numeric (readline(prompt="What is the value of y? "))
What is the value of y? 
> x
[1] NA
> y
[1] NA

I have no problem to understand why, because R software does not let the
time to enter the value for each variable. So Nate and I want to know if
there is a way, to "force" R to wait the entrance of the value of each
variable like written below:

First step of the script : 

> x <- as.numeric (readline(prompt="What is the value of x? "))
What is the value of x? 5

Second step of the script :

> y <- as.numeric (readline(prompt="What is the value of y? "))
What is the value of y? 9

Finally :

> x
[1] 5
> y
[1] 9

I hope that my english is not to bad and that you've understand what I mean.

Regards

Alexandre

-- 
View this message in context: http://r.789695.n4.nabble.com/Wait-for-user-input-with-readline-tp3054517p3074781.html
Sent from the R devel mailing list archive at Nabble.com.


From mdsumner at gmail.com  Tue Dec  7 10:09:36 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 7 Dec 2010 20:09:36 +1100
Subject: [Rd] Terminology clarification (Re: GPL and R Community
	Policies (Rcpp)
In-Reply-To: <AANLkTi=CRf6ZxGZMP4yRYns4jhExfEWM_V8X8vPrYB_O@mail.gmail.com>
References: <AANLkTinGXVwSQpQe4iMrxN2r=jbo4Z3kn0uju9T627AV@mail.gmail.com>
	<1291299654.7962.495.camel@braque.iarc.fr>
	<4CF7B981.70404@structuremonitoring.com>
	<002501cb9236$b0c634a0$12529de0$@edu>
	<19704.4415.474447.28419@max.nulle.part>
	<AANLkTikCS8ti2mGxOJ03KQZRq2HvCOVRfCq6HQaAMkKT@mail.gmail.com>
	<19704.9382.378882.355500@max.nulle.part>
	<AANLkTinmzSBR7TGUmLFtvqs4NLVedM-2509vecWsu5E9@mail.gmail.com>
	<AANLkTi=NtZz0DKpPrm9zOc_0SfKU0UnzmxLetmL3HfDH@mail.gmail.com>
	<AANLkTingqLfXi0vyfdD11m4Y1J4rRGm-APsoUuu7jzx3@mail.gmail.com>
	<AANLkTi=CRf6ZxGZMP4yRYns4jhExfEWM_V8X8vPrYB_O@mail.gmail.com>
Message-ID: <AANLkTinkc8GNt6NE27CGtG-FrabwiAp46m3oPmZ04X3z@mail.gmail.com>

Well, I'm very sorry for the outburst, it was completely inappropriate.

I don't actually mind the inconvenience - it's rather instructive as
to how badly things can go. I was lasshing out as it's really just
ironic that you want to stamp out references to yourself in a package
(how many on this list really knew the details before, or cared?) but
have now immortalized your contribution in the loudest way here on a
list where it's really not relevant.

Cheers, Mike.


On Sun, Dec 5, 2010 at 2:17 AM, Dominick Samperi <djsamperi at gmail.com> wrote:
>
>
> On Sat, Dec 4, 2010 at 8:11 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>> Christ, can we remove all references from the mailing lists while we're at
>> it?
>
> Look, I want to release software to CRAN, and I would like to
> do it without having to explain those remarks in Rcpp. I understand
> your frustration, but the authors of Rcpp have made it clear that
> private emails will be ignored. I think I have the right to decline
> the kind of "acknowledgement" that appears in Rcpp, and there
> is no rule that says it must be retained.
>
> This is a very simple resolution that would end this thread (to
> the delight of many readers I am sure).
>
> Sorry for the inconvenience,
> Dominick
>
>>
>>
>>
>> On Sat, Dec 4, 2010 at 7:49 AM, Dominick Samperi <djsamperi at gmail.com>
>> wrote:
>> > Dirk,
>> >
>> > Please let me know whether or not you will comply with my request to
>> > remove
>> > references to my name in Rcpp (except copyright notices).
>>
>> >
>> > Thanks,
>> > Dominick
>> >
>> > On Thu, Dec 2, 2010 at 6:28 PM, Dominick Samperi
>> > <djsamperi at gmail.com>wrote:
>> >
>> >>
>> >>
>> >> On Thu, Dec 2, 2010 at 5:58 PM, Dirk Eddelbuettel <edd at debian.org>
>> >> wrote:
>> >>
>> >>>
>> >>> On 2 December 2010 at 17:23, Dominick Samperi wrote:
>> >>> | OK, since you are so accomodating, then please remove all reference
>> >>> to
>> >>> | my name from Rcpp as I do not want to be subject to arbitrary
>> >>> revisions
>> >>> of
>> >>> | my status. I may not have the right to say how my prior work will be
>> >>> used,
>> >>> | but I think I have the right to ask that my name not be used in the
>> >>> way
>> >>> | it is used in the recent update.
>> >>>
>> >>> As I pointed out, you change your mind on this every 12 months,
>> >>> limiting
>> >>> my
>> >>> patience and willingness for these dances. ?It has also been suggested
>> >>> by
>> >>> other than attribution is clearer if you listed as the maintainer of
>> >>> the
>> >>> 2005/2006 code that we started from in 2008.
>> >>>
>> >>
>> >> The change that this thread is a reaction to happened a few days ago,
>> >> not
>> >> 12 months ago. If I wavered in the past it was because I was being
>> >> forced to compete with my own work, not a pleasant place to be.
>> >>
>> >> Are you telling me that you refuse to stop using my name
>> >> in Rcpp (except in copyright notices)?
>> >>
>> >> Are you telling me that you will continue to use my name and
>> >> update the associated status as you see fit, whether or not I
>> >> approve or consent to those changes?
>> >>
>> >> Please answer yes or no.
>> >>
>> >> Thanks,
>> >> Dominick
>> >>
>> >>
>> >>
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>> --
>> Michael Sumner
>> Institute for Marine and Antarctic Studies, University of Tasmania
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From jpnolan at american.edu  Tue Dec  7 14:38:47 2010
From: jpnolan at american.edu (John Nolan)
Date: Tue, 7 Dec 2010 08:38:47 -0500
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <19709.61472.158760.44576@lynne.math.ethz.ch>
References: <19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
Message-ID: <OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>

I have wrestled with this problem before.  I think correcting
the warning to "absolute error ~<= 0" is a good idea, and printing 
a warning if subdivisions==1 is also helpful.  Also, including
a simple example like the one that started this thread on the
help page for integrate might make the issue more clear to users.

But min.subdivisions is probably not.  On the example with dnorm( ),
I doubt 3 subdivisions would work.  The problem isn't that
we aren't sudividing enough, the problem is that the integrand
is 0 (in double precision) on most of the region and the
algorithm isn't designed to handle this.  There is no way to
determine how many subdivisions are necessary to get a reasonable
answer without a detailed analysis of the integrand.

I've gotten useful results with integrands that are monotonic on
the tail with a "self-triming integration" routine
like the following:

>right.trimmed.integrate <- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
+ # trim the region of integration on the right until f(x) > epsilon
+ 
+ a <- lower; b <- upper
+ while ( (b-a>min.width) && (f(b)<epsilon) ) { b <- (a+b)/2 }
+ 
+ return( integrate(f,a,b,...) ) }

> right.trimmed.integrate( dnorm, 0, 20000 )  # test
0.5 with absolute error < 9.2e-05

This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
etc.  Setting the tolerances epsilon and min.width is an issue,
but an explicit discussion of these values could encourage people to
think about the problem in their specific case.  And of course, none
of this guarantees a correct answer, especially if someone tries this
on non-monotonic integrands with complicated 0 sets.  One could write 
a somewhat more user-friendly version where the user has to specify 
some property (or set of properties) of the integrand, e.g. "right-tail 
decreasing to 0", etc. and have the algorithm try to do smart
trimming based on this.  But perhaps this getting too involved.

In the end, there is no general solution because any solution
depends on the specific nature of the integrand.  Clearer messages,
warnings in suspicious cases like subdivisions==1, and a simple
example explaining what the issue is in the help page would help
some people.

John
 
 ...........................................................................

 John P. Nolan
 Math/Stat Department
 227 Gray Hall
 American University
 4400 Massachusetts Avenue, NW
 Washington, DC 20016-8050

 jpnolan at american.edu
 202.885.3140 voice
 202.885.3155 fax
 http://academic2.american.edu/~jpnolan
 ...........................................................................

-----r-devel-bounces at r-project.org wrote: ----- 
To: r-devel at r-project.org, Prof Brian Ripley <ripley at stats.ox.ac.uk>
From: Martin Maechler 
Sent by: r-devel-bounces at r-project.org
Date: 12/07/2010 03:29AM
Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0

>>>>> Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:

    > On Mon, 6 Dec 2010, Spencer Graves wrote:
    >> Hello:
    >> 
    >> 
    >> The example "integrate(dnorm,0,20000)" says it "fails on many systems". 
    >> I just got 0 from it, when I should have gotten either an error or something 
    >> close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and 
    >> Linux (Fedora 13);  see the results from Windows below.  I thought you might 
    >> want to know.

    > Well, isn't that exactly what the help page says happens?  That 
    > example is part of a section entitled

    > ## integrate can fail if misused

    > and is part of the illustration of

    > If the function is
    > approximately constant (in particular, zero) over nearly all its
    > range it is possible that the result and error estimate may be
    > seriously wrong.

yes, of course, 
and the issue has been known for ``ages''  ..
..........
..........
but it seems that too many useRs are not reading the help
page carefully, but only browse it quickly.
I think we (R developers) have to live with this fact
and should consider adapting to it a bit more, particularly in
this case (see below)

    >> 
    >> Thanks for all your work in creating and maintaining R.
    >> 
    >> 
    >> Best Wishes,
    >> Spencer Graves
    >> ###############################

    >> 
    >> integrate(dnorm,0,20000) ## fails on many systems

    >> 0 with absolute error < 0

and this is particularly unsatisfactory for another reason:

"absolute error < 0"   
is *always* incorrect, so I think we should change *some*thing.

We could just use "<=" (and probably should in any case, or  
"< ~= x" which would convey ``is less than about x'' which I
think is all we can say),
but could consider giving a different message when the integral
evaluates to 0 or, rather actually,
only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
as the latter indicates that the algorithm treated the integrand
f(.) as if f() was a linear function.

But in my quick experiments, even for linear (incl. constant)
functions, the 'abs.error' returned is never 0.

If we want to be cautious,
such a warning could be made explicitly suppressable by an argument
      .warn.if.doubtful = TRUE

An additional possibility I'd like to try, is a new argument
   'min.subdivisions = 3' which specifies the *minimal* number
of subdivisions to be used in addition to the already present
   'subdivisions = 100' (= the maximum number of subintervals.)

Martin Maechler,
ETH Zurich

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From pchausse at uwaterloo.ca  Tue Dec  7 15:46:10 2010
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Tue, 07 Dec 2010 09:46:10 -0500
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
References: <19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
Message-ID: <4CFE48B2.2090804@uwaterloo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101207/b08969b1/attachment.pl>

From jpnolan at american.edu  Tue Dec  7 16:02:06 2010
From: jpnolan at american.edu (John Nolan)
Date: Tue, 7 Dec 2010 10:02:06 -0500
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <4CFE48B2.2090804@uwaterloo.ca>
References: <4CFE48B2.2090804@uwaterloo.ca>,
	<19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>
	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
Message-ID: <OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>

Putting in Inf for the upper bound does not work in general:
all 3 of the following should give 0.5

> integrate( dnorm, 0, Inf )
0.5 with absolute error < 4.7e-05

> integrate( dnorm, 0, Inf, sd=100000 )
Error in integrate(dnorm, 0, Inf, sd = 1e+05) : 
  the integral is probably divergent

> integrate( dnorm, 0, Inf, sd=10000000 )
5.570087e-05 with absolute error < 0.00010

Numerical quadrature methods look at a finite number of
points, and you can find examples that will confuse any
algorithm.  Rather than hope a general method will solve
all problems, users should look at their integrand and
pick an appropriate region of integration.

John Nolan, American U.


-----r-devel-bounces at r-project.org wrote: ----- 
To: r-devel at r-project.org
From: Pierre Chausse 
Sent by: r-devel-bounces at r-project.org
Date: 12/07/2010 09:46AM
Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0

  The warning about "absolute error == 0" would not be sufficient 
because if you do
 > integrate(dnorm, 0, 5000)
2.326323e-06 with absolute error < 4.6e-06

We get reasonable absolute error and wrong answer. For very high upper 
bound, it seems more stable to use "Inf". In that case, another 
.External is used which seems to be optimized for high or low bounds:

 > integrate(dnorm, 0,Inf)
0.5 with absolute error < 4.7e-05


On 10-12-07 8:38 AM, John Nolan wrote:
> I have wrestled with this problem before.  I think correcting
> the warning to "absolute error ~<= 0" is a good idea, and printing
> a warning if subdivisions==1 is also helpful.  Also, including
> a simple example like the one that started this thread on the
> help page for integrate might make the issue more clear to users.
>
> But min.subdivisions is probably not.  On the example with dnorm( ),
> I doubt 3 subdivisions would work.  The problem isn't that
> we aren't sudividing enough, the problem is that the integrand
> is 0 (in double precision) on most of the region and the
> algorithm isn't designed to handle this.  There is no way to
> determine how many subdivisions are necessary to get a reasonable
> answer without a detailed analysis of the integrand.
>
> I've gotten useful results with integrands that are monotonic on
> the tail with a "self-triming integration" routine
> like the following:
>
>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
> + # trim the region of integration on the right until f(x)>  epsilon
> +
> + a<- lower; b<- upper
> + while ( (b-a>min.width)&&  (f(b)<epsilon) ) { b<- (a+b)/2 }
> +
> + return( integrate(f,a,b,...) ) }
>
>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
> 0.5 with absolute error<  9.2e-05
>
> This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
> etc.  Setting the tolerances epsilon and min.width is an issue,
> but an explicit discussion of these values could encourage people to
> think about the problem in their specific case.  And of course, none
> of this guarantees a correct answer, especially if someone tries this
> on non-monotonic integrands with complicated 0 sets.  One could write
> a somewhat more user-friendly version where the user has to specify
> some property (or set of properties) of the integrand, e.g. "right-tail
> decreasing to 0", etc. and have the algorithm try to do smart
> trimming based on this.  But perhaps this getting too involved.
>
> In the end, there is no general solution because any solution
> depends on the specific nature of the integrand.  Clearer messages,
> warnings in suspicious cases like subdivisions==1, and a simple
> example explaining what the issue is in the help page would help
> some people.
>
> John
>
>   ...........................................................................
>
>   John P. Nolan
>   Math/Stat Department
>   227 Gray Hall
>   American University
>   4400 Massachusetts Avenue, NW
>   Washington, DC 20016-8050
>
>   jpnolan at american.edu
>   202.885.3140 voice
>   202.885.3155 fax
>   http://academic2.american.edu/~jpnolan
>   ...........................................................................
>
> -----r-devel-bounces at r-project.org wrote: -----
> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
> From: Martin Maechler
> Sent by: r-devel-bounces at r-project.org
> Date: 12/07/2010 03:29AM
> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>
>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>      on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>      >  On Mon, 6 Dec 2010, Spencer Graves wrote:
>      >>  Hello:
>      >>
>      >>
>      >>  The example "integrate(dnorm,0,20000)" says it "fails on many systems".
>      >>  I just got 0 from it, when I should have gotten either an error or something
>      >>  close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and
>      >>  Linux (Fedora 13);  see the results from Windows below.  I thought you might
>      >>  want to know.
>
>      >  Well, isn't that exactly what the help page says happens?  That
>      >  example is part of a section entitled
>
>      >  ## integrate can fail if misused
>
>      >  and is part of the illustration of
>
>      >  If the function is
>      >  approximately constant (in particular, zero) over nearly all its
>      >  range it is possible that the result and error estimate may be
>      >  seriously wrong.
>
> yes, of course,
> and the issue has been known for ``ages''  ..
> ..........
> ..........
> but it seems that too many useRs are not reading the help
> page carefully, but only browse it quickly.
> I think we (R developers) have to live with this fact
> and should consider adapting to it a bit more, particularly in
> this case (see below)
>
>      >>
>      >>  Thanks for all your work in creating and maintaining R.
>      >>
>      >>
>      >>  Best Wishes,
>      >>  Spencer Graves
>      >>  ###############################
>
>      >>
>      >>  integrate(dnorm,0,20000) ## fails on many systems
>
>      >>  0 with absolute error<  0
>
> and this is particularly unsatisfactory for another reason:
>
> "absolute error<  0"
> is *always* incorrect, so I think we should change *some*thing.
>
> We could just use "<=" (and probably should in any case, or
> "<  ~= x" which would convey ``is less than about x'' which I
> think is all we can say),
> but could consider giving a different message when the integral
> evaluates to 0 or, rather actually,
> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
> as the latter indicates that the algorithm treated the integrand
> f(.) as if f() was a linear function.
>
> But in my quick experiments, even for linear (incl. constant)
> functions, the 'abs.error' returned is never 0.
>
> If we want to be cautious,
> such a warning could be made explicitly suppressable by an argument
>        .warn.if.doubtful = TRUE
>
> An additional possibility I'd like to try, is a new argument
>     'min.subdivisions = 3' which specifies the *minimal* number
> of subdivisions to be used in addition to the already present
>     'subdivisions = 100' (= the maximum number of subintervals.)
>
> Martin Maechler,
> ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
*Pierre Chauss?*
Assistant Professor
Department of Economics
University of Waterloo

	[[alternative HTML version deleted]]


______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From Greg.Snow at imail.org  Tue Dec  7 17:48:40 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 7 Dec 2010 09:48:40 -0700
Subject: [Rd] Wait for user input with readline()
In-Reply-To: <1291652739318-3074781.post@n4.nabble.com>
References: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
	<1291652739318-3074781.post@n4.nabble.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6340BEA8C4@LP-EXMBVS10.CO.IHC.COM>

Part of the problem seems to be that R is set up to run in 1 of 2 modes (I may be over generalizing or over simplifying here), the modes are interactive where you type in a command, R processes it and gives results, you type in another command, etc.  The other is Batch mode where everything is processed without user interaction.

You (and others) seem to want some combination of the 2, but it is not clear exactly how to merge the 2 modes for general.  You are asking the computer to try to read your mind about when to use the next line of the script as input and when to wait for the user.

Some possibilities for you being able to tell the computer what to do:

Convert your script to a function with the readlines inside the function, then run the function from the prompt (then the readlines will expect user input).

Use tcltk (or other GUI tools) to have a separate box pop-up to get the input (this will not allow the entry to ever be automated, the script will wait until the entry is submitted).

You could combine these using if statements on the results of the interactive() function to help decide whether to pop up the boxes or not.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Alexandre
> Sent: Monday, December 06, 2010 9:26 AM
> To: r-devel at r-project.org
> Subject: Re: [Rd] Wait for user input with readline()
> 
> 
> Hi,
> 
> I have a similar problem as the one of Nate. The point is that I want
> to
> design an interactive script that need the value of two variables (x
> and y).
> 
> So my script as designed for the moment is :
> 
> x <- as.numeric (readline(prompt="What is the value of x? "))
> y <- as.numeric (readline(prompt="What is the value of y? "))
> 
> x
> y
> 
> But the problem is that if I run this script, values returned for x and
> y
> will be "NA" like you can see below :
> 
> > x <- as.numeric (readline(prompt="What is the value of x? "))
> What is the value of x?
> > y <- as.numeric (readline(prompt="What is the value of y? "))
> What is the value of y?
> > x
> [1] NA
> > y
> [1] NA
> 
> I have no problem to understand why, because R software does not let
> the
> time to enter the value for each variable. So Nate and I want to know
> if
> there is a way, to "force" R to wait the entrance of the value of each
> variable like written below:
> 
> First step of the script :
> 
> > x <- as.numeric (readline(prompt="What is the value of x? "))
> What is the value of x? 5
> 
> Second step of the script :
> 
> > y <- as.numeric (readline(prompt="What is the value of y? "))
> What is the value of y? 9
> 
> Finally :
> 
> > x
> [1] 5
> > y
> [1] 9
> 
> I hope that my english is not to bad and that you've understand what I
> mean.
> 
> Regards
> 
> Alexandre
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Wait-for-
> user-input-with-readline-tp3054517p3074781.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From savicky at cs.cas.cz  Tue Dec  7 18:19:21 2010
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 7 Dec 2010 18:19:21 +0100
Subject: [Rd] Wait for user input with readline()
In-Reply-To: <1291652739318-3074781.post@n4.nabble.com>
References: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
	<1291652739318-3074781.post@n4.nabble.com>
Message-ID: <20101207171921.GA21470@cs.cas.cz>

On Mon, Dec 06, 2010 at 08:25:39AM -0800, Alexandre wrote:
> 
> Hi,
> 
> I have a similar problem as the one of Nate. The point is that I want to
> design an interactive script that need the value of two variables (x and y).
> 
> So my script as designed for the moment is :
> 
> x <- as.numeric (readline(prompt="What is the value of x? "))
> y <- as.numeric (readline(prompt="What is the value of y? "))
> 
> x
> y 
> 
> But the problem is that if I run this script, values returned for x and y
> will be "NA" like you can see below :

How do you call your code? Function readline() does not wait for
user input in a non-interactive session, for example R CMD BATCH
or Rscript.

Another situation, when readline() does not wait is, when you copy
a block of code and paste it to a running session, even if it is
interactive. If readline() is not the last line of the code, then
the next line of code is used instead of the user input.

Petr Savicky.


From simon.urbanek at r-project.org  Tue Dec  7 19:09:02 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 7 Dec 2010 13:09:02 -0500
Subject: [Rd] Wait for user input with readline()
In-Reply-To: <20101207171921.GA21470@cs.cas.cz>
References: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
	<1291652739318-3074781.post@n4.nabble.com>
	<20101207171921.GA21470@cs.cas.cz>
Message-ID: <5C3B1203-2810-4CBE-9501-A3F2A36C18C3@r-project.org>


On Dec 7, 2010, at 12:19 PM, Petr Savicky wrote:

> On Mon, Dec 06, 2010 at 08:25:39AM -0800, Alexandre wrote:
>> 
>> Hi,
>> 
>> I have a similar problem as the one of Nate. The point is that I want to
>> design an interactive script that need the value of two variables (x and y).
>> 
>> So my script as designed for the moment is :
>> 
>> x <- as.numeric (readline(prompt="What is the value of x? "))
>> y <- as.numeric (readline(prompt="What is the value of y? "))
>> 
>> x
>> y 
>> 
>> But the problem is that if I run this script, values returned for x and y
>> will be "NA" like you can see below :
> 
> How do you call your code? Function readline() does not wait for
> user input in a non-interactive session, for example R CMD BATCH
> or Rscript.
> 
> Another situation, when readline() does not wait is, when you copy
> a block of code and paste it to a running session, even if it is
> interactive. If readline() is not the last line of the code, then
> the next line of code is used instead of the user input.
> 

You can't tell R code and input apart in cases like
R < myScript.R
but you can if you use source() or Rscript -- and you can treat them differently.

I assume what Alexandre wants is something like:
input=file("stdin")
print(readLines(input,1))
which works both in interactive and non-interactive setting and expects input in both cases (if you use Rscript or R -e 'source("...")' ).

Cheers,
Simon


From spencer.graves at structuremonitoring.com  Wed Dec  8 01:57:49 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 07 Dec 2010 16:57:49 -0800
Subject: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
 integrate(dnorm, 0, 20000) = 0)
In-Reply-To: <OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
References: <4CFE48B2.2090804@uwaterloo.ca>,
	<19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
Message-ID: <4CFED80D.5090404@structuremonitoring.com>

       What do you think about changing the verbiage with that example 
in "integrate.Rd" from "fails on many systems" to something like
"gives wrong answer without warning on many systems"?


       If I had write access to the core R code, I'd change this 
myself:  I'm probably not the only user who might think that saying 
something "fails" suggest it gives an error message.  Many contributions 
on this thread make it clear that it will never be possible to write an 
integrate function that won't give a "wrong answer without warning" in 
some cases.


       Thanks,
       Spencer


#############################
On 12/7/2010 7:02 AM, John Nolan wrote:
> Putting in Inf for the upper bound does not work in general:
> all 3 of the following should give 0.5
>
>> integrate( dnorm, 0, Inf )
> 0.5 with absolute error<  4.7e-05
>
>> integrate( dnorm, 0, Inf, sd=100000 )
> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>    the integral is probably divergent
>
>> integrate( dnorm, 0, Inf, sd=10000000 )
> 5.570087e-05 with absolute error<  0.00010
>
> Numerical quadrature methods look at a finite number of
> points, and you can find examples that will confuse any
> algorithm.  Rather than hope a general method will solve
> all problems, users should look at their integrand and
> pick an appropriate region of integration.
>
> John Nolan, American U.
>
>
> -----r-devel-bounces at r-project.org wrote: -----
> To: r-devel at r-project.org
> From: Pierre Chausse
> Sent by: r-devel-bounces at r-project.org
> Date: 12/07/2010 09:46AM
> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>
>    The warning about "absolute error == 0" would not be sufficient
> because if you do
>   >  integrate(dnorm, 0, 5000)
> 2.326323e-06 with absolute error<  4.6e-06
>
> We get reasonable absolute error and wrong answer. For very high upper
> bound, it seems more stable to use "Inf". In that case, another
> .External is used which seems to be optimized for high or low bounds:
>
>   >  integrate(dnorm, 0,Inf)
> 0.5 with absolute error<  4.7e-05
>
>
> On 10-12-07 8:38 AM, John Nolan wrote:
>> I have wrestled with this problem before.  I think correcting
>> the warning to "absolute error ~<= 0" is a good idea, and printing
>> a warning if subdivisions==1 is also helpful.  Also, including
>> a simple example like the one that started this thread on the
>> help page for integrate might make the issue more clear to users.
>>
>> But min.subdivisions is probably not.  On the example with dnorm( ),
>> I doubt 3 subdivisions would work.  The problem isn't that
>> we aren't sudividing enough, the problem is that the integrand
>> is 0 (in double precision) on most of the region and the
>> algorithm isn't designed to handle this.  There is no way to
>> determine how many subdivisions are necessary to get a reasonable
>> answer without a detailed analysis of the integrand.
>>
>> I've gotten useful results with integrands that are monotonic on
>> the tail with a "self-triming integration" routine
>> like the following:
>>
>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
>> + # trim the region of integration on the right until f(x)>   epsilon
>> +
>> + a<- lower; b<- upper
>> + while ( (b-a>min.width)&&   (f(b)<epsilon) ) { b<- (a+b)/2 }
>> +
>> + return( integrate(f,a,b,...) ) }
>>
>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>> 0.5 with absolute error<   9.2e-05
>>
>> This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
>> etc.  Setting the tolerances epsilon and min.width is an issue,
>> but an explicit discussion of these values could encourage people to
>> think about the problem in their specific case.  And of course, none
>> of this guarantees a correct answer, especially if someone tries this
>> on non-monotonic integrands with complicated 0 sets.  One could write
>> a somewhat more user-friendly version where the user has to specify
>> some property (or set of properties) of the integrand, e.g. "right-tail
>> decreasing to 0", etc. and have the algorithm try to do smart
>> trimming based on this.  But perhaps this getting too involved.
>>
>> In the end, there is no general solution because any solution
>> depends on the specific nature of the integrand.  Clearer messages,
>> warnings in suspicious cases like subdivisions==1, and a simple
>> example explaining what the issue is in the help page would help
>> some people.
>>
>> John
>>
>>    ...........................................................................
>>
>>    John P. Nolan
>>    Math/Stat Department
>>    227 Gray Hall
>>    American University
>>    4400 Massachusetts Avenue, NW
>>    Washington, DC 20016-8050
>>
>>    jpnolan at american.edu
>>    202.885.3140 voice
>>    202.885.3155 fax
>>    http://academic2.american.edu/~jpnolan
>>    ...........................................................................
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>> From: Martin Maechler
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 03:29AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>       on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>       >   On Mon, 6 Dec 2010, Spencer Graves wrote:
>>       >>   Hello:
>>       >>
>>       >>
>>       >>   The example "integrate(dnorm,0,20000)" says it "fails on many systems".
>>       >>   I just got 0 from it, when I should have gotten either an error or something
>>       >>   close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and
>>       >>   Linux (Fedora 13);  see the results from Windows below.  I thought you might
>>       >>   want to know.
>>
>>       >   Well, isn't that exactly what the help page says happens?  That
>>       >   example is part of a section entitled
>>
>>       >   ## integrate can fail if misused
>>
>>       >   and is part of the illustration of
>>
>>       >   If the function is
>>       >   approximately constant (in particular, zero) over nearly all its
>>       >   range it is possible that the result and error estimate may be
>>       >   seriously wrong.
>>
>> yes, of course,
>> and the issue has been known for ``ages''  ..
>> ..........
>> ..........
>> but it seems that too many useRs are not reading the help
>> page carefully, but only browse it quickly.
>> I think we (R developers) have to live with this fact
>> and should consider adapting to it a bit more, particularly in
>> this case (see below)
>>
>>       >>
>>       >>   Thanks for all your work in creating and maintaining R.
>>       >>
>>       >>
>>       >>   Best Wishes,
>>       >>   Spencer Graves
>>       >>   ###############################
>>
>>       >>
>>       >>   integrate(dnorm,0,20000) ## fails on many systems
>>
>>       >>   0 with absolute error<   0
>>
>> and this is particularly unsatisfactory for another reason:
>>
>> "absolute error<   0"
>> is *always* incorrect, so I think we should change *some*thing.
>>
>> We could just use "<=" (and probably should in any case, or
>> "<   ~= x" which would convey ``is less than about x'' which I
>> think is all we can say),
>> but could consider giving a different message when the integral
>> evaluates to 0 or, rather actually,
>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>> as the latter indicates that the algorithm treated the integrand
>> f(.) as if f() was a linear function.
>>
>> But in my quick experiments, even for linear (incl. constant)
>> functions, the 'abs.error' returned is never 0.
>>
>> If we want to be cautious,
>> such a warning could be made explicitly suppressable by an argument
>>         .warn.if.doubtful = TRUE
>>
>> An additional possibility I'd like to try, is a new argument
>>      'min.subdivisions = 3' which specifies the *minimal* number
>> of subdivisions to be used in addition to the already present
>>      'subdivisions = 100' (= the maximum number of subintervals.)
>>
>> Martin Maechler,
>> ETH Zurich
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From jpnolan at american.edu  Wed Dec  8 05:08:33 2010
From: jpnolan at american.edu (John Nolan)
Date: Tue, 7 Dec 2010 23:08:33 -0500
Subject: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
	integrate(dnorm, 0, 20000) = 0)
In-Reply-To: <4CFED80D.5090404@structuremonitoring.com>
References: <4CFED80D.5090404@structuremonitoring.com>,
	<4CFE48B2.2090804@uwaterloo.ca>,
	<19709.61472.158760.44576@lynne.math.ethz.ch>, 
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
Message-ID: <OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>

R developers understand intimately how things work, and terse
descriptions are sufficient.  However, most typical R users 
would benefit from clearer documentation.  In multiple places 
I've found the R documentation to be correct and understandable 
AFTER I've figured a function out.  

And to be fair, this problem with integrate( ) isn't really R's 
fault: the QUADPACK routines that R uses are very good algorithms, 
but neither they nor any other package can handle all cases.  

I would support reasonable changes in the documentation for
integrate( ).   Just saying it "gives wrong answer without 
warning on many systems" seems misleading (it works fine in
many cases) and it doesn't help a user understand how to use
integrate( ) correctly/carefully.  IMO a simple example like 
this one w/ dnorm would catch peoples attention and a couple 
lines of explanation/warning would then make more sense.  

John Nolan, American U


-----Spencer Graves <spencer.graves at structuremonitoring.com> wrote: ----- 
To: John Nolan <jpnolan at american.edu>
From: Spencer Graves <spencer.graves at structuremonitoring.com>
Date: 12/07/2010 07:58PM
Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0)

       What do you think about changing the verbiage with that example 
in "integrate.Rd" from "fails on many systems" to something like
"gives wrong answer without warning on many systems"?


       If I had write access to the core R code, I'd change this 
myself:  I'm probably not the only user who might think that saying 
something "fails" suggest it gives an error message.  Many contributions 
on this thread make it clear that it will never be possible to write an 
integrate function that won't give a "wrong answer without warning" in 
some cases.


       Thanks,
       Spencer


#############################
On 12/7/2010 7:02 AM, John Nolan wrote:
> Putting in Inf for the upper bound does not work in general:
> all 3 of the following should give 0.5
>
>> integrate( dnorm, 0, Inf )
> 0.5 with absolute error<  4.7e-05
>
>> integrate( dnorm, 0, Inf, sd=100000 )
> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>    the integral is probably divergent
>
>> integrate( dnorm, 0, Inf, sd=10000000 )
> 5.570087e-05 with absolute error<  0.00010
>
> Numerical quadrature methods look at a finite number of
> points, and you can find examples that will confuse any
> algorithm.  Rather than hope a general method will solve
> all problems, users should look at their integrand and
> pick an appropriate region of integration.
>
> John Nolan, American U.
>
>
> -----r-devel-bounces at r-project.org wrote: -----
> To: r-devel at r-project.org
> From: Pierre Chausse
> Sent by: r-devel-bounces at r-project.org
> Date: 12/07/2010 09:46AM
> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>
>    The warning about "absolute error == 0" would not be sufficient
> because if you do
>   >  integrate(dnorm, 0, 5000)
> 2.326323e-06 with absolute error<  4.6e-06
>
> We get reasonable absolute error and wrong answer. For very high upper
> bound, it seems more stable to use "Inf". In that case, another
> .External is used which seems to be optimized for high or low bounds:
>
>   >  integrate(dnorm, 0,Inf)
> 0.5 with absolute error<  4.7e-05
>
>
> On 10-12-07 8:38 AM, John Nolan wrote:
>> I have wrestled with this problem before.  I think correcting
>> the warning to "absolute error ~<= 0" is a good idea, and printing
>> a warning if subdivisions==1 is also helpful.  Also, including
>> a simple example like the one that started this thread on the
>> help page for integrate might make the issue more clear to users.
>>
>> But min.subdivisions is probably not.  On the example with dnorm( ),
>> I doubt 3 subdivisions would work.  The problem isn't that
>> we aren't sudividing enough, the problem is that the integrand
>> is 0 (in double precision) on most of the region and the
>> algorithm isn't designed to handle this.  There is no way to
>> determine how many subdivisions are necessary to get a reasonable
>> answer without a detailed analysis of the integrand.
>>
>> I've gotten useful results with integrands that are monotonic on
>> the tail with a "self-triming integration" routine
>> like the following:
>>
>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
>> + # trim the region of integration on the right until f(x)>   epsilon
>> +
>> + a<- lower; b<- upper
>> + while ( (b-a>min.width)&&   (f(b)<epsilon) ) { b<- (a+b)/2 }
>> +
>> + return( integrate(f,a,b,...) ) }
>>
>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>> 0.5 with absolute error<   9.2e-05
>>
>> This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
>> etc.  Setting the tolerances epsilon and min.width is an issue,
>> but an explicit discussion of these values could encourage people to
>> think about the problem in their specific case.  And of course, none
>> of this guarantees a correct answer, especially if someone tries this
>> on non-monotonic integrands with complicated 0 sets.  One could write
>> a somewhat more user-friendly version where the user has to specify
>> some property (or set of properties) of the integrand, e.g. "right-tail
>> decreasing to 0", etc. and have the algorithm try to do smart
>> trimming based on this.  But perhaps this getting too involved.
>>
>> In the end, there is no general solution because any solution
>> depends on the specific nature of the integrand.  Clearer messages,
>> warnings in suspicious cases like subdivisions==1, and a simple
>> example explaining what the issue is in the help page would help
>> some people.
>>
>> John
>>
>>    ...........................................................................
>>
>>    John P. Nolan
>>    Math/Stat Department
>>    227 Gray Hall
>>    American University
>>    4400 Massachusetts Avenue, NW
>>    Washington, DC 20016-8050
>>
>>    jpnolan at american.edu
>>    202.885.3140 voice
>>    202.885.3155 fax
>>    http://academic2.american.edu/~jpnolan
>>    ...........................................................................
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>> From: Martin Maechler
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 03:29AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>       on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>       >   On Mon, 6 Dec 2010, Spencer Graves wrote:
>>       >>   Hello:
>>       >>
>>       >>
>>       >>   The example "integrate(dnorm,0,20000)" says it "fails on many systems".
>>       >>   I just got 0 from it, when I should have gotten either an error or something
>>       >>   close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and
>>       >>   Linux (Fedora 13);  see the results from Windows below.  I thought you might
>>       >>   want to know.
>>
>>       >   Well, isn't that exactly what the help page says happens?  That
>>       >   example is part of a section entitled
>>
>>       >   ## integrate can fail if misused
>>
>>       >   and is part of the illustration of
>>
>>       >   If the function is
>>       >   approximately constant (in particular, zero) over nearly all its
>>       >   range it is possible that the result and error estimate may be
>>       >   seriously wrong.
>>
>> yes, of course,
>> and the issue has been known for ``ages''  ..
>> ..........
>> ..........
>> but it seems that too many useRs are not reading the help
>> page carefully, but only browse it quickly.
>> I think we (R developers) have to live with this fact
>> and should consider adapting to it a bit more, particularly in
>> this case (see below)
>>
>>       >>
>>       >>   Thanks for all your work in creating and maintaining R.
>>       >>
>>       >>
>>       >>   Best Wishes,
>>       >>   Spencer Graves
>>       >>   ###############################
>>
>>       >>
>>       >>   integrate(dnorm,0,20000) ## fails on many systems
>>
>>       >>   0 with absolute error<   0
>>
>> and this is particularly unsatisfactory for another reason:
>>
>> "absolute error<   0"
>> is *always* incorrect, so I think we should change *some*thing.
>>
>> We could just use "<=" (and probably should in any case, or
>> "<   ~= x" which would convey ``is less than about x'' which I
>> think is all we can say),
>> but could consider giving a different message when the integral
>> evaluates to 0 or, rather actually,
>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>> as the latter indicates that the algorithm treated the integrand
>> f(.) as if f() was a linear function.
>>
>> But in my quick experiments, even for linear (incl. constant)
>> functions, the 'abs.error' returned is never 0.
>>
>> If we want to be cautious,
>> such a warning could be made explicitly suppressable by an argument
>>         .warn.if.doubtful = TRUE
>>
>> An additional possibility I'd like to try, is a new argument
>>      'min.subdivisions = 3' which specifies the *minimal* number
>> of subdivisions to be used in addition to the already present
>>      'subdivisions = 100' (= the maximum number of subintervals.)
>>
>> Martin Maechler,
>> ETH Zurich
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

From d.scott at auckland.ac.nz  Wed Dec  8 07:12:51 2010
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 08 Dec 2010 19:12:51 +1300
Subject: [Rd] Suggested change to integrate.Rd (was: Re: 0.5
 !=	integrate(dnorm, 0, 20000) = 0)
In-Reply-To: <OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
References: <4CFED80D.5090404@structuremonitoring.com>,
	<4CFE48B2.2090804@uwaterloo.ca>,
	<19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
	<OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
Message-ID: <4CFF21E3.5010604@auckland.ac.nz>

If changes are to be made to integrate it would be nice if the following 
was fixed:
 > integrate(dnorm, -Inf, -Inf)
1 with absolute error < 9.4e-05

Note that integrate manages ok when not dealing with Inf or -Inf:
 > integrate(dnorm, -500, -500)
0 with absolute error < 0

David Scott




On 8/12/2010 5:08 p.m., John Nolan wrote:
> R developers understand intimately how things work, and terse
> descriptions are sufficient.  However, most typical R users
> would benefit from clearer documentation.  In multiple places
> I've found the R documentation to be correct and understandable
> AFTER I've figured a function out.
>
> And to be fair, this problem with integrate( ) isn't really R's
> fault: the QUADPACK routines that R uses are very good algorithms,
> but neither they nor any other package can handle all cases.
>
> I would support reasonable changes in the documentation for
> integrate( ).   Just saying it "gives wrong answer without
> warning on many systems" seems misleading (it works fine in
> many cases) and it doesn't help a user understand how to use
> integrate( ) correctly/carefully.  IMO a simple example like
> this one w/ dnorm would catch peoples attention and a couple
> lines of explanation/warning would then make more sense.
>
> John Nolan, American U
>
>
> -----Spencer Graves<spencer.graves at structuremonitoring.com>  wrote: -----
> To: John Nolan<jpnolan at american.edu>
> From: Spencer Graves<spencer.graves at structuremonitoring.com>
> Date: 12/07/2010 07:58PM
> Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
> Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0)
>
>         What do you think about changing the verbiage with that example
> in "integrate.Rd" from "fails on many systems" to something like
> "gives wrong answer without warning on many systems"?
>
>
>         If I had write access to the core R code, I'd change this
> myself:  I'm probably not the only user who might think that saying
> something "fails" suggest it gives an error message.  Many contributions
> on this thread make it clear that it will never be possible to write an
> integrate function that won't give a "wrong answer without warning" in
> some cases.
>
>
>         Thanks,
>         Spencer
>
>
> #############################
> On 12/7/2010 7:02 AM, John Nolan wrote:
>> Putting in Inf for the upper bound does not work in general:
>> all 3 of the following should give 0.5
>>
>>> integrate( dnorm, 0, Inf )
>> 0.5 with absolute error<   4.7e-05
>>
>>> integrate( dnorm, 0, Inf, sd=100000 )
>> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>>     the integral is probably divergent
>>
>>> integrate( dnorm, 0, Inf, sd=10000000 )
>> 5.570087e-05 with absolute error<   0.00010
>>
>> Numerical quadrature methods look at a finite number of
>> points, and you can find examples that will confuse any
>> algorithm.  Rather than hope a general method will solve
>> all problems, users should look at their integrand and
>> pick an appropriate region of integration.
>>
>> John Nolan, American U.
>>
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org
>> From: Pierre Chausse
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 09:46AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>     The warning about "absolute error == 0" would not be sufficient
>> because if you do
>>    >   integrate(dnorm, 0, 5000)
>> 2.326323e-06 with absolute error<   4.6e-06
>>
>> We get reasonable absolute error and wrong answer. For very high upper
>> bound, it seems more stable to use "Inf". In that case, another
>> .External is used which seems to be optimized for high or low bounds:
>>
>>    >   integrate(dnorm, 0,Inf)
>> 0.5 with absolute error<   4.7e-05
>>
>>
>> On 10-12-07 8:38 AM, John Nolan wrote:
>>> I have wrestled with this problem before.  I think correcting
>>> the warning to "absolute error ~<= 0" is a good idea, and printing
>>> a warning if subdivisions==1 is also helpful.  Also, including
>>> a simple example like the one that started this thread on the
>>> help page for integrate might make the issue more clear to users.
>>>
>>> But min.subdivisions is probably not.  On the example with dnorm( ),
>>> I doubt 3 subdivisions would work.  The problem isn't that
>>> we aren't sudividing enough, the problem is that the integrand
>>> is 0 (in double precision) on most of the region and the
>>> algorithm isn't designed to handle this.  There is no way to
>>> determine how many subdivisions are necessary to get a reasonable
>>> answer without a detailed analysis of the integrand.
>>>
>>> I've gotten useful results with integrands that are monotonic on
>>> the tail with a "self-triming integration" routine
>>> like the following:
>>>
>>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
>>> + # trim the region of integration on the right until f(x)>    epsilon
>>> +
>>> + a<- lower; b<- upper
>>> + while ( (b-a>min.width)&&    (f(b)<epsilon) ) { b<- (a+b)/2 }
>>> +
>>> + return( integrate(f,a,b,...) ) }
>>>
>>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>>> 0.5 with absolute error<    9.2e-05
>>>
>>> This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
>>> etc.  Setting the tolerances epsilon and min.width is an issue,
>>> but an explicit discussion of these values could encourage people to
>>> think about the problem in their specific case.  And of course, none
>>> of this guarantees a correct answer, especially if someone tries this
>>> on non-monotonic integrands with complicated 0 sets.  One could write
>>> a somewhat more user-friendly version where the user has to specify
>>> some property (or set of properties) of the integrand, e.g. "right-tail
>>> decreasing to 0", etc. and have the algorithm try to do smart
>>> trimming based on this.  But perhaps this getting too involved.
>>>
>>> In the end, there is no general solution because any solution
>>> depends on the specific nature of the integrand.  Clearer messages,
>>> warnings in suspicious cases like subdivisions==1, and a simple
>>> example explaining what the issue is in the help page would help
>>> some people.
>>>
>>> John
>>>
>>>     ...........................................................................
>>>
>>>     John P. Nolan
>>>     Math/Stat Department
>>>     227 Gray Hall
>>>     American University
>>>     4400 Massachusetts Avenue, NW
>>>     Washington, DC 20016-8050
>>>
>>>     jpnolan at american.edu
>>>     202.885.3140 voice
>>>     202.885.3155 fax
>>>     http://academic2.american.edu/~jpnolan
>>>     ...........................................................................
>>>
>>> -----r-devel-bounces at r-project.org wrote: -----
>>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>> From: Martin Maechler
>>> Sent by: r-devel-bounces at r-project.org
>>> Date: 12/07/2010 03:29AM
>>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>>
>>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>>        on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>>        >    On Mon, 6 Dec 2010, Spencer Graves wrote:
>>>        >>    Hello:
>>>        >>
>>>        >>
>>>        >>    The example "integrate(dnorm,0,20000)" says it "fails on many systems".
>>>        >>    I just got 0 from it, when I should have gotten either an error or something
>>>        >>    close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and
>>>        >>    Linux (Fedora 13);  see the results from Windows below.  I thought you might
>>>        >>    want to know.
>>>
>>>        >    Well, isn't that exactly what the help page says happens?  That
>>>        >    example is part of a section entitled
>>>
>>>        >    ## integrate can fail if misused
>>>
>>>        >    and is part of the illustration of
>>>
>>>        >    If the function is
>>>        >    approximately constant (in particular, zero) over nearly all its
>>>        >    range it is possible that the result and error estimate may be
>>>        >    seriously wrong.
>>>
>>> yes, of course,
>>> and the issue has been known for ``ages''  ..
>>> ..........
>>> ..........
>>> but it seems that too many useRs are not reading the help
>>> page carefully, but only browse it quickly.
>>> I think we (R developers) have to live with this fact
>>> and should consider adapting to it a bit more, particularly in
>>> this case (see below)
>>>
>>>        >>
>>>        >>    Thanks for all your work in creating and maintaining R.
>>>        >>
>>>        >>
>>>        >>    Best Wishes,
>>>        >>    Spencer Graves
>>>        >>    ###############################
>>>
>>>        >>
>>>        >>    integrate(dnorm,0,20000) ## fails on many systems
>>>
>>>        >>    0 with absolute error<    0
>>>
>>> and this is particularly unsatisfactory for another reason:
>>>
>>> "absolute error<    0"
>>> is *always* incorrect, so I think we should change *some*thing.
>>>
>>> We could just use "<=" (and probably should in any case, or
>>> "<    ~= x" which would convey ``is less than about x'' which I
>>> think is all we can say),
>>> but could consider giving a different message when the integral
>>> evaluates to 0 or, rather actually,
>>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>>> as the latter indicates that the algorithm treated the integrand
>>> f(.) as if f() was a linear function.
>>>
>>> But in my quick experiments, even for linear (incl. constant)
>>> functions, the 'abs.error' returned is never 0.
>>>
>>> If we want to be cautious,
>>> such a warning could be made explicitly suppressable by an argument
>>>          .warn.if.doubtful = TRUE
>>>
>>> An additional possibility I'd like to try, is a new argument
>>>       'min.subdivisions = 3' which specifies the *minimal* number
>>> of subdivisions to be used in addition to the already present
>>>       'subdivisions = 100' (= the maximum number of subintervals.)
>>>
>>> Martin Maechler,
>>> ETH Zurich
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From jorismeys at gmail.com  Wed Dec  8 11:26:51 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 8 Dec 2010 11:26:51 +0100
Subject: [Rd] possible bug in chron packages
Message-ID: <AANLkTim1m5md+R9HHh2Vcao990mfxoeZJ+CP5YZUhPUX@mail.gmail.com>

Dear,

According to the documentation, the parameters given in "dates" are
passed to the function "chron". When trying this out, it turns out
that this apparently doesn't happen, eg:

> dates("20100101",format="Ymd",out.format="day mon year")
[1] 01/01/10
> chron("20100101",format="Ymd",out.format="day mon year")
[1] 01 Jan 2010

I would expect the outcome of both functions to be the same, or am I
overlooking something?

Kind regards
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From gavin.simpson at ucl.ac.uk  Wed Dec  8 11:59:47 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 08 Dec 2010 10:59:47 +0000
Subject: [Rd] possible bug in chron packages
In-Reply-To: <AANLkTim1m5md+R9HHh2Vcao990mfxoeZJ+CP5YZUhPUX@mail.gmail.com>
References: <AANLkTim1m5md+R9HHh2Vcao990mfxoeZJ+CP5YZUhPUX@mail.gmail.com>
Message-ID: <1291805987.2418.19.camel@desktop.localdomain>

On Wed, 2010-12-08 at 11:26 +0100, Joris Meys wrote:
> Dear,
> 
> According to the documentation, the parameters given in "dates" are
> passed to the function "chron". When trying this out, it turns out
> that this apparently doesn't happen, eg:
> 
> > dates("20100101",format="Ymd",out.format="day mon year")
> [1] 01/01/10
> > chron("20100101",format="Ymd",out.format="day mon year")
> [1] 01 Jan 2010

It does actually. If you read the code and/or debug `dates` to see what
is happening, `out.format` is passed on to `chron` which does its thing
and passes back the correctly formatted object as specified by
`out.format`.

However, `dates` then goes on to unclass the returned object and then
stick back on a class. It also tries to preserve the "format" in the
first line of `dates`

fmt <- attr(x, "format")

but in your example this is NULL as `x` is just a character. The code
reapplies this stored format later on with

attr(out, "format") <- fmt

as the last line before returning out.

The "format" attribute of the object returned by `chron` never gets
stored or used on the object returned form `dates`.

G

> I would expect the outcome of both functions to be the same, or am I
> overlooking something?
> 
> Kind regards
> Joris
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From dam_damdeo33 at hotmail.com  Wed Dec  8 09:57:48 2010
From: dam_damdeo33 at hotmail.com (Alexandre)
Date: Wed, 8 Dec 2010 00:57:48 -0800 (PST)
Subject: [Rd] Wait for user input with readline()
In-Reply-To: <5C3B1203-2810-4CBE-9501-A3F2A36C18C3@r-project.org>
References: <AANLkTikAG_8ynt2+SP=b5WYJ2u2w5iwqit=0R_1FDsJr@mail.gmail.com>
	<1291652739318-3074781.post@n4.nabble.com>
	<20101207171921.GA21470@cs.cas.cz>
	<5C3B1203-2810-4CBE-9501-A3F2A36C18C3@r-project.org>
Message-ID: <1291798668564-3077878.post@n4.nabble.com>


Thanks all,

Even if I'm not an expert in programmation, I'll try to compile informations
and try to sort my problem.

Alexandre
-- 
View this message in context: http://r.789695.n4.nabble.com/Wait-for-user-input-with-readline-tp3054517p3077878.html
Sent from the R devel mailing list archive at Nabble.com.


From spencer.graves at structuremonitoring.com  Wed Dec  8 14:45:21 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 08 Dec 2010 05:45:21 -0800
Subject: [Rd] Suggested change to integrate.Rd
In-Reply-To: <OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
References: <4CFED80D.5090404@structuremonitoring.com>,
	<4CFE48B2.2090804@uwaterloo.ca>,
	<19709.61472.158760.44576@lynne.math.ethz.ch>,
	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
	<OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
Message-ID: <4CFF8BF1.5000203@structuremonitoring.com>

Hi, John:


Maybe change it to something like "gives wrong answer without warning on 
many systems (see 'Note' above)", as the 'Note' does provide more detail.


Thanks,
Spencer


On 12/7/2010 8:08 PM, John Nolan wrote:
> R developers understand intimately how things work, and terse
> descriptions are sufficient.  However, most typical R users
> would benefit from clearer documentation.  In multiple places
> I've found the R documentation to be correct and understandable
> AFTER I've figured a function out.
>
> And to be fair, this problem with integrate( ) isn't really R's
> fault: the QUADPACK routines that R uses are very good algorithms,
> but neither they nor any other package can handle all cases.
>
> I would support reasonable changes in the documentation for
> integrate( ).   Just saying it "gives wrong answer without
> warning on many systems" seems misleading (it works fine in
> many cases) and it doesn't help a user understand how to use
> integrate( ) correctly/carefully.  IMO a simple example like
> this one w/ dnorm would catch peoples attention and a couple
> lines of explanation/warning would then make more sense.
>
> John Nolan, American U
>
>
> -----Spencer Graves<spencer.graves at structuremonitoring.com>  wrote: -----
> To: John Nolan<jpnolan at american.edu>
> From: Spencer Graves<spencer.graves at structuremonitoring.com>
> Date: 12/07/2010 07:58PM
> Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
> Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0)
>
>         What do you think about changing the verbiage with that example
> in "integrate.Rd" from "fails on many systems" to something like
> "gives wrong answer without warning on many systems"?
>
>
>         If I had write access to the core R code, I'd change this
> myself:  I'm probably not the only user who might think that saying
> something "fails" suggest it gives an error message.  Many contributions
> on this thread make it clear that it will never be possible to write an
> integrate function that won't give a "wrong answer without warning" in
> some cases.
>
>
>         Thanks,
>         Spencer
>
>
> #############################
> On 12/7/2010 7:02 AM, John Nolan wrote:
>> Putting in Inf for the upper bound does not work in general:
>> all 3 of the following should give 0.5
>>
>>> integrate( dnorm, 0, Inf )
>> 0.5 with absolute error<   4.7e-05
>>
>>> integrate( dnorm, 0, Inf, sd=100000 )
>> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>>     the integral is probably divergent
>>
>>> integrate( dnorm, 0, Inf, sd=10000000 )
>> 5.570087e-05 with absolute error<   0.00010
>>
>> Numerical quadrature methods look at a finite number of
>> points, and you can find examples that will confuse any
>> algorithm.  Rather than hope a general method will solve
>> all problems, users should look at their integrand and
>> pick an appropriate region of integration.
>>
>> John Nolan, American U.
>>
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org
>> From: Pierre Chausse
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 09:46AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>     The warning about "absolute error == 0" would not be sufficient
>> because if you do
>>    >   integrate(dnorm, 0, 5000)
>> 2.326323e-06 with absolute error<   4.6e-06
>>
>> We get reasonable absolute error and wrong answer. For very high upper
>> bound, it seems more stable to use "Inf". In that case, another
>> .External is used which seems to be optimized for high or low bounds:
>>
>>    >   integrate(dnorm, 0,Inf)
>> 0.5 with absolute error<   4.7e-05
>>
>>
>> On 10-12-07 8:38 AM, John Nolan wrote:
>>> I have wrestled with this problem before.  I think correcting
>>> the warning to "absolute error ~<= 0" is a good idea, and printing
>>> a warning if subdivisions==1 is also helpful.  Also, including
>>> a simple example like the one that started this thread on the
>>> help page for integrate might make the issue more clear to users.
>>>
>>> But min.subdivisions is probably not.  On the example with dnorm( ),
>>> I doubt 3 subdivisions would work.  The problem isn't that
>>> we aren't sudividing enough, the problem is that the integrand
>>> is 0 (in double precision) on most of the region and the
>>> algorithm isn't designed to handle this.  There is no way to
>>> determine how many subdivisions are necessary to get a reasonable
>>> answer without a detailed analysis of the integrand.
>>>
>>> I've gotten useful results with integrands that are monotonic on
>>> the tail with a "self-triming integration" routine
>>> like the following:
>>>
>>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100, min.width=1e-10, ... ) {
>>> + # trim the region of integration on the right until f(x)>    epsilon
>>> +
>>> + a<- lower; b<- upper
>>> + while ( (b-a>min.width)&&    (f(b)<epsilon) ) { b<- (a+b)/2 }
>>> +
>>> + return( integrate(f,a,b,...) ) }
>>>
>>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>>> 0.5 with absolute error<    9.2e-05
>>>
>>> This can be adapted to left trim or (left and right) trim, abs(f(x)-c)>epsilon,
>>> etc.  Setting the tolerances epsilon and min.width is an issue,
>>> but an explicit discussion of these values could encourage people to
>>> think about the problem in their specific case.  And of course, none
>>> of this guarantees a correct answer, especially if someone tries this
>>> on non-monotonic integrands with complicated 0 sets.  One could write
>>> a somewhat more user-friendly version where the user has to specify
>>> some property (or set of properties) of the integrand, e.g. "right-tail
>>> decreasing to 0", etc. and have the algorithm try to do smart
>>> trimming based on this.  But perhaps this getting too involved.
>>>
>>> In the end, there is no general solution because any solution
>>> depends on the specific nature of the integrand.  Clearer messages,
>>> warnings in suspicious cases like subdivisions==1, and a simple
>>> example explaining what the issue is in the help page would help
>>> some people.
>>>
>>> John
>>>
>>>     ...........................................................................
>>>
>>>     John P. Nolan
>>>     Math/Stat Department
>>>     227 Gray Hall
>>>     American University
>>>     4400 Massachusetts Avenue, NW
>>>     Washington, DC 20016-8050
>>>
>>>     jpnolan at american.edu
>>>     202.885.3140 voice
>>>     202.885.3155 fax
>>>     http://academic2.american.edu/~jpnolan
>>>     ...........................................................................
>>>
>>> -----r-devel-bounces at r-project.org wrote: -----
>>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>> From: Martin Maechler
>>> Sent by: r-devel-bounces at r-project.org
>>> Date: 12/07/2010 03:29AM
>>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>>
>>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>>        on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>>        >    On Mon, 6 Dec 2010, Spencer Graves wrote:
>>>        >>    Hello:
>>>        >>
>>>        >>
>>>        >>    The example "integrate(dnorm,0,20000)" says it "fails on many systems".
>>>        >>    I just got 0 from it, when I should have gotten either an error or something
>>>        >>    close to 0.5.  I got this with R 2.12.0 under both Windows Vista_x64 and
>>>        >>    Linux (Fedora 13);  see the results from Windows below.  I thought you might
>>>        >>    want to know.
>>>
>>>        >    Well, isn't that exactly what the help page says happens?  That
>>>        >    example is part of a section entitled
>>>
>>>        >    ## integrate can fail if misused
>>>
>>>        >    and is part of the illustration of
>>>
>>>        >    If the function is
>>>        >    approximately constant (in particular, zero) over nearly all its
>>>        >    range it is possible that the result and error estimate may be
>>>        >    seriously wrong.
>>>
>>> yes, of course,
>>> and the issue has been known for ``ages''  ..
>>> ..........
>>> ..........
>>> but it seems that too many useRs are not reading the help
>>> page carefully, but only browse it quickly.
>>> I think we (R developers) have to live with this fact
>>> and should consider adapting to it a bit more, particularly in
>>> this case (see below)
>>>
>>>        >>
>>>        >>    Thanks for all your work in creating and maintaining R.
>>>        >>
>>>        >>
>>>        >>    Best Wishes,
>>>        >>    Spencer Graves
>>>        >>    ###############################
>>>
>>>        >>
>>>        >>    integrate(dnorm,0,20000) ## fails on many systems
>>>
>>>        >>    0 with absolute error<    0
>>>
>>> and this is particularly unsatisfactory for another reason:
>>>
>>> "absolute error<    0"
>>> is *always* incorrect, so I think we should change *some*thing.
>>>
>>> We could just use "<=" (and probably should in any case, or
>>> "<    ~= x" which would convey ``is less than about x'' which I
>>> think is all we can say),
>>> but could consider giving a different message when the integral
>>> evaluates to 0 or, rather actually,
>>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>>> as the latter indicates that the algorithm treated the integrand
>>> f(.) as if f() was a linear function.
>>>
>>> But in my quick experiments, even for linear (incl. constant)
>>> functions, the 'abs.error' returned is never 0.
>>>
>>> If we want to be cautious,
>>> such a warning could be made explicitly suppressable by an argument
>>>          .warn.if.doubtful = TRUE
>>>
>>> An additional possibility I'd like to try, is a new argument
>>>       'min.subdivisions = 3' which specifies the *minimal* number
>>> of subdivisions to be used in addition to the already present
>>>       'subdivisions = 100' (= the maximum number of subintervals.)
>>>
>>> Martin Maechler,
>>> ETH Zurich
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>


From rvaradhan at jhmi.edu  Wed Dec  8 16:43:46 2010
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 8 Dec 2010 10:43:46 -0500
Subject: [Rd] Suggested change to integrate.Rd (was: Re: 0.5
	!=	integrate(dnorm, 0, 20000) = 0)
In-Reply-To: <OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
References: <4CFED80D.5090404@structuremonitoring.com>
	<4CFE48B2.2090804@uwaterloo.ca>
	<19709.61472.158760.44576@lynne.math.ethz.ch>
	<4CFD729C.6050704@structuremonitoring.com>
	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
	<OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
Message-ID: <005201cb96ee$b35a1800$1a0e4800$@edu>

Hi,

My honest and (not so) humble opinion is that no amount of clear and
explicit warning can totally prevent the inappropriate use of any tool.
Users will continue to use the tools, without doing the necessary background
work to figure out whether the that tool is the appropriate one for their
particular problem.  If things can go so horribly wrong in such a simple
case, imagine all the snares and traps present in complex, high-dimensional
integration.  Even the best cubature rules or the MCMC methods can give
wrong results.  Even worse, how in heaven's name can we be sure that the
answer is any good?  The simple and best solution is to understand your
integrand as best as you can.  I realize that this may be viewed as being
too pedantic, but unfortunately, it is also the best advice.

Best,
Ravi.
-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns
Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of John Nolan
Sent: Tuesday, December 07, 2010 11:09 PM
To: spencer.graves at structuremonitoring.com
Cc: r-devel at r-project.org
Subject: Re: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
integrate(dnorm, 0, 20000) = 0)

R developers understand intimately how things work, and terse
descriptions are sufficient.  However, most typical R users 
would benefit from clearer documentation.  In multiple places 
I've found the R documentation to be correct and understandable 
AFTER I've figured a function out.  

And to be fair, this problem with integrate( ) isn't really R's 
fault: the QUADPACK routines that R uses are very good algorithms, 
but neither they nor any other package can handle all cases.  

I would support reasonable changes in the documentation for
integrate( ).   Just saying it "gives wrong answer without 
warning on many systems" seems misleading (it works fine in
many cases) and it doesn't help a user understand how to use
integrate( ) correctly/carefully.  IMO a simple example like 
this one w/ dnorm would catch peoples attention and a couple 
lines of explanation/warning would then make more sense.  

John Nolan, American U


-----Spencer Graves <spencer.graves at structuremonitoring.com> wrote: ----- 
To: John Nolan <jpnolan at american.edu>
From: Spencer Graves <spencer.graves at structuremonitoring.com>
Date: 12/07/2010 07:58PM
Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 !=
integrate(dnorm,0,20000) = 0)

       What do you think about changing the verbiage with that example 
in "integrate.Rd" from "fails on many systems" to something like
"gives wrong answer without warning on many systems"?


       If I had write access to the core R code, I'd change this 
myself:  I'm probably not the only user who might think that saying 
something "fails" suggest it gives an error message.  Many contributions 
on this thread make it clear that it will never be possible to write an 
integrate function that won't give a "wrong answer without warning" in 
some cases.


       Thanks,
       Spencer


#############################
On 12/7/2010 7:02 AM, John Nolan wrote:
> Putting in Inf for the upper bound does not work in general:
> all 3 of the following should give 0.5
>
>> integrate( dnorm, 0, Inf )
> 0.5 with absolute error<  4.7e-05
>
>> integrate( dnorm, 0, Inf, sd=100000 )
> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>    the integral is probably divergent
>
>> integrate( dnorm, 0, Inf, sd=10000000 )
> 5.570087e-05 with absolute error<  0.00010
>
> Numerical quadrature methods look at a finite number of
> points, and you can find examples that will confuse any
> algorithm.  Rather than hope a general method will solve
> all problems, users should look at their integrand and
> pick an appropriate region of integration.
>
> John Nolan, American U.
>
>
> -----r-devel-bounces at r-project.org wrote: -----
> To: r-devel at r-project.org
> From: Pierre Chausse
> Sent by: r-devel-bounces at r-project.org
> Date: 12/07/2010 09:46AM
> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>
>    The warning about "absolute error == 0" would not be sufficient
> because if you do
>   >  integrate(dnorm, 0, 5000)
> 2.326323e-06 with absolute error<  4.6e-06
>
> We get reasonable absolute error and wrong answer. For very high upper
> bound, it seems more stable to use "Inf". In that case, another
> .External is used which seems to be optimized for high or low bounds:
>
>   >  integrate(dnorm, 0,Inf)
> 0.5 with absolute error<  4.7e-05
>
>
> On 10-12-07 8:38 AM, John Nolan wrote:
>> I have wrestled with this problem before.  I think correcting
>> the warning to "absolute error ~<= 0" is a good idea, and printing
>> a warning if subdivisions==1 is also helpful.  Also, including
>> a simple example like the one that started this thread on the
>> help page for integrate might make the issue more clear to users.
>>
>> But min.subdivisions is probably not.  On the example with dnorm( ),
>> I doubt 3 subdivisions would work.  The problem isn't that
>> we aren't sudividing enough, the problem is that the integrand
>> is 0 (in double precision) on most of the region and the
>> algorithm isn't designed to handle this.  There is no way to
>> determine how many subdivisions are necessary to get a reasonable
>> answer without a detailed analysis of the integrand.
>>
>> I've gotten useful results with integrands that are monotonic on
>> the tail with a "self-triming integration" routine
>> like the following:
>>
>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100,
min.width=1e-10, ... ) {
>> + # trim the region of integration on the right until f(x)>   epsilon
>> +
>> + a<- lower; b<- upper
>> + while ( (b-a>min.width)&&   (f(b)<epsilon) ) { b<- (a+b)/2 }
>> +
>> + return( integrate(f,a,b,...) ) }
>>
>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>> 0.5 with absolute error<   9.2e-05
>>
>> This can be adapted to left trim or (left and right) trim,
abs(f(x)-c)>epsilon,
>> etc.  Setting the tolerances epsilon and min.width is an issue,
>> but an explicit discussion of these values could encourage people to
>> think about the problem in their specific case.  And of course, none
>> of this guarantees a correct answer, especially if someone tries this
>> on non-monotonic integrands with complicated 0 sets.  One could write
>> a somewhat more user-friendly version where the user has to specify
>> some property (or set of properties) of the integrand, e.g. "right-tail
>> decreasing to 0", etc. and have the algorithm try to do smart
>> trimming based on this.  But perhaps this getting too involved.
>>
>> In the end, there is no general solution because any solution
>> depends on the specific nature of the integrand.  Clearer messages,
>> warnings in suspicious cases like subdivisions==1, and a simple
>> example explaining what the issue is in the help page would help
>> some people.
>>
>> John
>>
>>
...........................................................................
>>
>>    John P. Nolan
>>    Math/Stat Department
>>    227 Gray Hall
>>    American University
>>    4400 Massachusetts Avenue, NW
>>    Washington, DC 20016-8050
>>
>>    jpnolan at american.edu
>>    202.885.3140 voice
>>    202.885.3155 fax
>>    http://academic2.american.edu/~jpnolan
>>
...........................................................................
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>> From: Martin Maechler
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 03:29AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>       on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>       >   On Mon, 6 Dec 2010, Spencer Graves wrote:
>>       >>   Hello:
>>       >>
>>       >>
>>       >>   The example "integrate(dnorm,0,20000)" says it "fails on many
systems".
>>       >>   I just got 0 from it, when I should have gotten either an
error or something
>>       >>   close to 0.5.  I got this with R 2.12.0 under both Windows
Vista_x64 and
>>       >>   Linux (Fedora 13);  see the results from Windows below.  I
thought you might
>>       >>   want to know.
>>
>>       >   Well, isn't that exactly what the help page says happens?  That
>>       >   example is part of a section entitled
>>
>>       >   ## integrate can fail if misused
>>
>>       >   and is part of the illustration of
>>
>>       >   If the function is
>>       >   approximately constant (in particular, zero) over nearly all
its
>>       >   range it is possible that the result and error estimate may be
>>       >   seriously wrong.
>>
>> yes, of course,
>> and the issue has been known for ``ages''  ..
>> ..........
>> ..........
>> but it seems that too many useRs are not reading the help
>> page carefully, but only browse it quickly.
>> I think we (R developers) have to live with this fact
>> and should consider adapting to it a bit more, particularly in
>> this case (see below)
>>
>>       >>
>>       >>   Thanks for all your work in creating and maintaining R.
>>       >>
>>       >>
>>       >>   Best Wishes,
>>       >>   Spencer Graves
>>       >>   ###############################
>>
>>       >>
>>       >>   integrate(dnorm,0,20000) ## fails on many systems
>>
>>       >>   0 with absolute error<   0
>>
>> and this is particularly unsatisfactory for another reason:
>>
>> "absolute error<   0"
>> is *always* incorrect, so I think we should change *some*thing.
>>
>> We could just use "<=" (and probably should in any case, or
>> "<   ~= x" which would convey ``is less than about x'' which I
>> think is all we can say),
>> but could consider giving a different message when the integral
>> evaluates to 0 or, rather actually,
>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>> as the latter indicates that the algorithm treated the integrand
>> f(.) as if f() was a linear function.
>>
>> But in my quick experiments, even for linear (incl. constant)
>> functions, the 'abs.error' returned is never 0.
>>
>> If we want to be cautious,
>> such a warning could be made explicitly suppressable by an argument
>>         .warn.if.doubtful = TRUE
>>
>> An additional possibility I'd like to try, is a new argument
>>      'min.subdivisions = 3' which specifies the *minimal* number
>> of subdivisions to be used in addition to the already present
>>      'subdivisions = 100' (= the maximum number of subintervals.)
>>
>> Martin Maechler,
>> ETH Zurich
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Wed Dec  8 17:32:50 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 8 Dec 2010 11:32:50 -0500
Subject: [Rd] directory structure of R 2.12.0 distribution
Message-ID: <AANLkTik8RcZAt31D=+XeK3dQSavLtECQ2=cT3m-v3vOr@mail.gmail.com>

I am just revising my batch files which call R and have a question
regarding the directory structure of the R distribution in R 2.12.0.

Prior to R 2.12.0 the R executables were in R_HOME\bin but now are in
R_HOME\bin\i386 on my machine.  I assume that there is a different
subdirectory of bin on 64 bit machines.   Is that right?

Is it always the case that there is exactly one subdirectory of bin
and that the R executables are there?

Or is it possible that there are more than one subdirectory in bin?
If more than one is possible how do we know which one is the one to
use?

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From kevin.r.coombes at gmail.com  Wed Dec  8 17:43:19 2010
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Wed, 08 Dec 2010 10:43:19 -0600
Subject: [Rd] directory structure of R 2.12.0 distribution
In-Reply-To: <AANLkTik8RcZAt31D=+XeK3dQSavLtECQ2=cT3m-v3vOr@mail.gmail.com>
References: <AANLkTik8RcZAt31D=+XeK3dQSavLtECQ2=cT3m-v3vOr@mail.gmail.com>
Message-ID: <4CFFB5A7.6050406@gmail.com>

Hi,

On my 64-bit machine, there are two subdirectories:
     i386
     x64
I usually want to use the 64-bit executable.  However, some packages 
have not yet been compiled for a 64-bit machine, so for those I need to 
use the 32-bit i386 subdirectory.

     Kevin

On 12/8/2010 10:32 AM, Gabor Grothendieck wrote:
> I am just revising my batch files which call R and have a question
> regarding the directory structure of the R distribution in R 2.12.0.
>
> Prior to R 2.12.0 the R executables were in R_HOME\bin but now are in
> R_HOME\bin\i386 on my machine.  I assume that there is a different
> subdirectory of bin on 64 bit machines.   Is that right?
>
> Is it always the case that there is exactly one subdirectory of bin
> and that the R executables are there?
>
> Or is it possible that there are more than one subdirectory in bin?
> If more than one is possible how do we know which one is the one to
> use?
>


From ggrothendieck at gmail.com  Wed Dec  8 17:55:20 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 8 Dec 2010 11:55:20 -0500
Subject: [Rd] directory structure of R 2.12.0 distribution
In-Reply-To: <4CFFB5A7.6050406@gmail.com>
References: <AANLkTik8RcZAt31D=+XeK3dQSavLtECQ2=cT3m-v3vOr@mail.gmail.com>
	<4CFFB5A7.6050406@gmail.com>
Message-ID: <AANLkTin0iLhhOWh6v9VYWthbi+=WT_nMEm=2bjXLjqh2@mail.gmail.com>

On Wed, Dec 8, 2010 at 11:43 AM, Kevin R. Coombes
<kevin.r.coombes at gmail.com> wrote:
> Hi,
>
> On my 64-bit machine, there are two subdirectories:
> ? ?i386
> ? ?x64
> I usually want to use the 64-bit executable. ?However, some packages have
> not yet been compiled for a 64-bit machine, so for those I need to use the
> 32-bit i386 subdirectory.
>

Thanks.

Is there something at installation time that says which to use?

Is there a registry entry?

Is this documented anywhere?

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Wed Dec  8 19:07:14 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Dec 2010 13:07:14 -0500
Subject: [Rd] directory structure of R 2.12.0 distribution
In-Reply-To: <AANLkTin0iLhhOWh6v9VYWthbi+=WT_nMEm=2bjXLjqh2@mail.gmail.com>
References: <AANLkTik8RcZAt31D=+XeK3dQSavLtECQ2=cT3m-v3vOr@mail.gmail.com>	<4CFFB5A7.6050406@gmail.com>
	<AANLkTin0iLhhOWh6v9VYWthbi+=WT_nMEm=2bjXLjqh2@mail.gmail.com>
Message-ID: <4CFFC952.4070903@gmail.com>

Gabor Grothendieck wrote:
> On Wed, Dec 8, 2010 at 11:43 AM, Kevin R. Coombes
> <kevin.r.coombes at gmail.com> wrote:
>> Hi,
>>
>> On my 64-bit machine, there are two subdirectories:
>>    i386
>>    x64
>> I usually want to use the 64-bit executable.  However, some packages have
>> not yet been compiled for a 64-bit machine, so for those I need to use the
>> 32-bit i386 subdirectory.
>>
> 
> Thanks.
> 
> Is there something at installation time that says which to use?

No, that's up to the user.  If you want to run 32 bit R, use i386.  If 
you want to run 64 bit R, use x64.  (You need to be on 64 bit Windows 
and to have chosen to install both to have this choice.)

> Is there a registry entry?

There's an entry in the 32 bit registry if you install 32 bit R, and one 
in the 64 bit registry if you install 64 bit R.  Writing R Extensions 
discusses this.

> 
> Is this documented anywhere?

It was announced in the CHANGES file, and there's a description in the R 
Admin manual as well as the Writing R Extensions manual.

Duncan Murdoch


From spencer.graves at structuremonitoring.com  Wed Dec  8 23:30:17 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 08 Dec 2010 14:30:17 -0800
Subject: [Rd] Suggested change to integrate.Rd
In-Reply-To: <OF3BD612D8.7EC00A6C-ON852577F3.007897A3-852577F3.007AF384@american.edu>
References: <4CFED80D.5090404@structuremonitoring.com>
	<4CFE48B2.2090804@uwaterloo.ca>
	<19709.61472.158760.44576@lynne.math.ethz.ch>
	<4CFD729C.6050704@structuremonitoring.com>
	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
	<OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>
	<005201cb96ee$b35a1800$1a0e4800$@edu>
	<OF3BD612D8.7EC00A6C-ON852577F3.007897A3-852577F3.007AF384@american.edu>
Message-ID: <4D0006F9.6070202@structuremonitoring.com>

That sounds like a great idea to me:  This should give the Core R team 
more time to worry about the code by delegating maintenance of the help 
files to a larger group.


Spencer


On 12/8/2010 2:22 PM, John Nolan wrote:
> Well, you can't idiot-proof things, but you can give clear descriptions and
> warnings.
> To take things to the extreme, one can eliminate all help files.  If a user
> really wants
> to understand things, they can read the source code, right?
>
> This is a general question for r-dev: who are the help files aimed at? If
> the
> answer is experts only, then don't put any more effort into help files.
> But if you
> want more users to be able to do more things, then more explanation will
> help.
>
> Perhaps there should be a "documentation team" (r-doc?) that intersects
> r-dev, but
> focuses on documentation?
>
> John,  American U
>
>
>
>
> From:	"Ravi Varadhan"<rvaradhan at jhmi.edu>
> To:	"'John Nolan'"<jpnolan at american.edu>,
>              <spencer.graves at structuremonitoring.com>
> Cc:	<r-devel at r-project.org>
> Date:	12/08/2010 10:43 AM
> Subject:	RE: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
>              integrate(dnorm, 0, 20000) = 0)
>
>
>
> Hi,
>
> My honest and (not so) humble opinion is that no amount of clear and
> explicit warning can totally prevent the inappropriate use of any tool.
> Users will continue to use the tools, without doing the necessary
> background
> work to figure out whether the that tool is the appropriate one for their
> particular problem.  If things can go so horribly wrong in such a simple
> case, imagine all the snares and traps present in complex, high-dimensional
> integration.  Even the best cubature rules or the MCMC methods can give
> wrong results.  Even worse, how in heaven's name can we be sure that the
> answer is any good?  The simple and best solution is to understand your
> integrand as best as you can.  I realize that this may be viewed as being
> too pedantic, but unfortunately, it is also the best advice.
>
> Best,
> Ravi.
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns
> Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of John Nolan
> Sent: Tuesday, December 07, 2010 11:09 PM
> To: spencer.graves at structuremonitoring.com
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
> integrate(dnorm, 0, 20000) = 0)
>
> R developers understand intimately how things work, and terse
> descriptions are sufficient.  However, most typical R users
> would benefit from clearer documentation.  In multiple places
> I've found the R documentation to be correct and understandable
> AFTER I've figured a function out.
>
> And to be fair, this problem with integrate( ) isn't really R's
> fault: the QUADPACK routines that R uses are very good algorithms,
> but neither they nor any other package can handle all cases.
>
> I would support reasonable changes in the documentation for
> integrate( ).   Just saying it "gives wrong answer without
> warning on many systems" seems misleading (it works fine in
> many cases) and it doesn't help a user understand how to use
> integrate( ) correctly/carefully.  IMO a simple example like
> this one w/ dnorm would catch peoples attention and a couple
> lines of explanation/warning would then make more sense.
>
> John Nolan, American U
>
>
> -----Spencer Graves<spencer.graves at structuremonitoring.com>  wrote: -----
> To: John Nolan<jpnolan at american.edu>
> From: Spencer Graves<spencer.graves at structuremonitoring.com>
> Date: 12/07/2010 07:58PM
> Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
> Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 !=
> integrate(dnorm,0,20000) = 0)
>
>         What do you think about changing the verbiage with that example
> in "integrate.Rd" from "fails on many systems" to something like
> "gives wrong answer without warning on many systems"?
>
>
>         If I had write access to the core R code, I'd change this
> myself:  I'm probably not the only user who might think that saying
> something "fails" suggest it gives an error message.  Many contributions
> on this thread make it clear that it will never be possible to write an
> integrate function that won't give a "wrong answer without warning" in
> some cases.
>
>
>         Thanks,
>         Spencer
>
>
> #############################
> On 12/7/2010 7:02 AM, John Nolan wrote:
>> Putting in Inf for the upper bound does not work in general:
>> all 3 of the following should give 0.5
>>
>>> integrate( dnorm, 0, Inf )
>> 0.5 with absolute error<   4.7e-05
>>
>>> integrate( dnorm, 0, Inf, sd=100000 )
>> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>>     the integral is probably divergent
>>
>>> integrate( dnorm, 0, Inf, sd=10000000 )
>> 5.570087e-05 with absolute error<   0.00010
>>
>> Numerical quadrature methods look at a finite number of
>> points, and you can find examples that will confuse any
>> algorithm.  Rather than hope a general method will solve
>> all problems, users should look at their integrand and
>> pick an appropriate region of integration.
>>
>> John Nolan, American U.
>>
>>
>> -----r-devel-bounces at r-project.org wrote: -----
>> To: r-devel at r-project.org
>> From: Pierre Chausse
>> Sent by: r-devel-bounces at r-project.org
>> Date: 12/07/2010 09:46AM
>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>
>>     The warning about "absolute error == 0" would not be sufficient
>> because if you do
>>    >   integrate(dnorm, 0, 5000)
>> 2.326323e-06 with absolute error<   4.6e-06
>>
>> We get reasonable absolute error and wrong answer. For very high upper
>> bound, it seems more stable to use "Inf". In that case, another
>> .External is used which seems to be optimized for high or low bounds:
>>
>>    >   integrate(dnorm, 0,Inf)
>> 0.5 with absolute error<   4.7e-05
>>
>>
>> On 10-12-07 8:38 AM, John Nolan wrote:
>>> I have wrestled with this problem before.  I think correcting
>>> the warning to "absolute error ~<= 0" is a good idea, and printing
>>> a warning if subdivisions==1 is also helpful.  Also, including
>>> a simple example like the one that started this thread on the
>>> help page for integrate might make the issue more clear to users.
>>>
>>> But min.subdivisions is probably not.  On the example with dnorm( ),
>>> I doubt 3 subdivisions would work.  The problem isn't that
>>> we aren't sudividing enough, the problem is that the integrand
>>> is 0 (in double precision) on most of the region and the
>>> algorithm isn't designed to handle this.  There is no way to
>>> determine how many subdivisions are necessary to get a reasonable
>>> answer without a detailed analysis of the integrand.
>>>
>>> I've gotten useful results with integrands that are monotonic on
>>> the tail with a "self-triming integration" routine
>>> like the following:
>>>
>>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100,
> min.width=1e-10, ... ) {
>>> + # trim the region of integration on the right until f(x)>    epsilon
>>> +
>>> + a<- lower; b<- upper
>>> + while ( (b-a>min.width)&&    (f(b)<epsilon) ) { b<- (a+b)/2 }
>>> +
>>> + return( integrate(f,a,b,...) ) }
>>>
>>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>>> 0.5 with absolute error<    9.2e-05
>>>
>>> This can be adapted to left trim or (left and right) trim,
> abs(f(x)-c)>epsilon,
>>> etc.  Setting the tolerances epsilon and min.width is an issue,
>>> but an explicit discussion of these values could encourage people to
>>> think about the problem in their specific case.  And of course, none
>>> of this guarantees a correct answer, especially if someone tries this
>>> on non-monotonic integrands with complicated 0 sets.  One could write
>>> a somewhat more user-friendly version where the user has to specify
>>> some property (or set of properties) of the integrand, e.g. "right-tail
>>> decreasing to 0", etc. and have the algorithm try to do smart
>>> trimming based on this.  But perhaps this getting too involved.
>>>
>>> In the end, there is no general solution because any solution
>>> depends on the specific nature of the integrand.  Clearer messages,
>>> warnings in suspicious cases like subdivisions==1, and a simple
>>> example explaining what the issue is in the help page would help
>>> some people.
>>>
>>> John
>>>
>>>
> ...........................................................................
>>>     John P. Nolan
>>>     Math/Stat Department
>>>     227 Gray Hall
>>>     American University
>>>     4400 Massachusetts Avenue, NW
>>>     Washington, DC 20016-8050
>>>
>>>     jpnolan at american.edu
>>>     202.885.3140 voice
>>>     202.885.3155 fax
>>>     http://academic2.american.edu/~jpnolan
>>>
> ...........................................................................
>>> -----r-devel-bounces at r-project.org wrote: -----
>>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>> From: Martin Maechler
>>> Sent by: r-devel-bounces at r-project.org
>>> Date: 12/07/2010 03:29AM
>>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>>
>>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>>        on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>>        >    On Mon, 6 Dec 2010, Spencer Graves wrote:
>>>        >>    Hello:
>>>        >>
>>>        >>
>>>        >>    The example "integrate(dnorm,0,20000)" says it "fails on many
> systems".
>>>        >>    I just got 0 from it, when I should have gotten either an
> error or something
>>>        >>    close to 0.5.  I got this with R 2.12.0 under both Windows
> Vista_x64 and
>>>        >>    Linux (Fedora 13);  see the results from Windows below.  I
> thought you might
>>>        >>    want to know.
>>>
>>>        >    Well, isn't that exactly what the help page says happens?
> That
>>>        >    example is part of a section entitled
>>>
>>>        >    ## integrate can fail if misused
>>>
>>>        >    and is part of the illustration of
>>>
>>>        >    If the function is
>>>        >    approximately constant (in particular, zero) over nearly all
> its
>>>        >    range it is possible that the result and error estimate may be
>>>        >    seriously wrong.
>>>
>>> yes, of course,
>>> and the issue has been known for ``ages''  ..
>>> ..........
>>> ..........
>>> but it seems that too many useRs are not reading the help
>>> page carefully, but only browse it quickly.
>>> I think we (R developers) have to live with this fact
>>> and should consider adapting to it a bit more, particularly in
>>> this case (see below)
>>>
>>>        >>
>>>        >>    Thanks for all your work in creating and maintaining R.
>>>        >>
>>>        >>
>>>        >>    Best Wishes,
>>>        >>    Spencer Graves
>>>        >>    ###############################
>>>
>>>        >>
>>>        >>    integrate(dnorm,0,20000) ## fails on many systems
>>>
>>>        >>    0 with absolute error<    0
>>>
>>> and this is particularly unsatisfactory for another reason:
>>>
>>> "absolute error<    0"
>>> is *always* incorrect, so I think we should change *some*thing.
>>>
>>> We could just use "<=" (and probably should in any case, or
>>> "<    ~= x" which would convey ``is less than about x'' which I
>>> think is all we can say),
>>> but could consider giving a different message when the integral
>>> evaluates to 0 or, rather actually,
>>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>>> as the latter indicates that the algorithm treated the integrand
>>> f(.) as if f() was a linear function.
>>>
>>> But in my quick experiments, even for linear (incl. constant)
>>> functions, the 'abs.error' returned is never 0.
>>>
>>> If we want to be cautious,
>>> such a warning could be made explicitly suppressable by an argument
>>>          .warn.if.doubtful = TRUE
>>>
>>> An additional possibility I'd like to try, is a new argument
>>>       'min.subdivisions = 3' which specifies the *minimal* number
>>> of subdivisions to be used in addition to the already present
>>>       'subdivisions = 100' (= the maximum number of subintervals.)
>>>
>>> Martin Maechler,
>>> ETH Zurich
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From murdoch.duncan at gmail.com  Thu Dec  9 02:42:11 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Dec 2010 20:42:11 -0500
Subject: [Rd] Suggested change to integrate.Rd
In-Reply-To: <4D0006F9.6070202@structuremonitoring.com>
References: <4CFED80D.5090404@structuremonitoring.com>	<4CFE48B2.2090804@uwaterloo.ca>	<19709.61472.158760.44576@lynne.math.ethz.ch>	<4CFD729C.6050704@structuremonitoring.com>	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>	<OF1912B964.47975B0D-ON852577F3.0016C1B2-852577F3.0016C1B4@american.edu>	<005201cb96ee$b35a1800$1a0e4800$@edu>	<OF3BD612D8.7EC00A6C-ON852577F3.007897A3-852577F3.007AF384@american.edu>
	<4D0006F9.6070202@structuremonitoring.com>
Message-ID: <4D0033F3.6070504@gmail.com>

On 08/12/2010 5:30 PM, Spencer Graves wrote:
> That sounds like a great idea to me:  This should give the Core R team
> more time to worry about the code by delegating maintenance of the help
> files to a larger group.

There's nothing stopping you from writing documentation.  Lots of people 
write books; some of them are quite good.  You could also contribute to 
the R Wiki, or start your own.

If the documentation is good, people will use it.  If the documentation 
written by people other than the core group is better than what we 
write, then people will read it instead of ours.

I don't think it would be practical to have primary documentation 
written by people separate from the code developers, because writing the 
documentation is such an important part of developing the code.  But 
there could certainly be a team of people who take the standard 
documentation and improve it, or replace it.  All the tools for 
converting the .Rd or .Rnw source into various formats are there.

Duncan Murdoch


>
> Spencer
>
>
> On 12/8/2010 2:22 PM, John Nolan wrote:
>> Well, you can't idiot-proof things, but you can give clear descriptions and
>> warnings.
>> To take things to the extreme, one can eliminate all help files.  If a user
>> really wants
>> to understand things, they can read the source code, right?
>>
>> This is a general question for r-dev: who are the help files aimed at? If
>> the
>> answer is experts only, then don't put any more effort into help files.
>> But if you
>> want more users to be able to do more things, then more explanation will
>> help.
>>
>> Perhaps there should be a "documentation team" (r-doc?) that intersects
>> r-dev, but
>> focuses on documentation?
>>
>> John,  American U
>>
>>
>>
>>
>> From:	"Ravi Varadhan"<rvaradhan at jhmi.edu>
>> To:	"'John Nolan'"<jpnolan at american.edu>,
>>               <spencer.graves at structuremonitoring.com>
>> Cc:	<r-devel at r-project.org>
>> Date:	12/08/2010 10:43 AM
>> Subject:	RE: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
>>               integrate(dnorm, 0, 20000) = 0)
>>
>>
>>
>> Hi,
>>
>> My honest and (not so) humble opinion is that no amount of clear and
>> explicit warning can totally prevent the inappropriate use of any tool.
>> Users will continue to use the tools, without doing the necessary
>> background
>> work to figure out whether the that tool is the appropriate one for their
>> particular problem.  If things can go so horribly wrong in such a simple
>> case, imagine all the snares and traps present in complex, high-dimensional
>> integration.  Even the best cubature rules or the MCMC methods can give
>> wrong results.  Even worse, how in heaven's name can we be sure that the
>> answer is any good?  The simple and best solution is to understand your
>> integrand as best as you can.  I realize that this may be viewed as being
>> too pedantic, but unfortunately, it is also the best advice.
>>
>> Best,
>> Ravi.
>> -------------------------------------------------------
>> Ravi Varadhan, Ph.D.
>> Assistant Professor,
>> Division of Geriatric Medicine and Gerontology School of Medicine Johns
>> Hopkins University
>>
>> Ph. (410) 502-2619
>> email: rvaradhan at jhmi.edu
>>
>>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
>> On Behalf Of John Nolan
>> Sent: Tuesday, December 07, 2010 11:09 PM
>> To: spencer.graves at structuremonitoring.com
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Suggested change to integrate.Rd (was: Re: 0.5 !=
>> integrate(dnorm, 0, 20000) = 0)
>>
>> R developers understand intimately how things work, and terse
>> descriptions are sufficient.  However, most typical R users
>> would benefit from clearer documentation.  In multiple places
>> I've found the R documentation to be correct and understandable
>> AFTER I've figured a function out.
>>
>> And to be fair, this problem with integrate( ) isn't really R's
>> fault: the QUADPACK routines that R uses are very good algorithms,
>> but neither they nor any other package can handle all cases.
>>
>> I would support reasonable changes in the documentation for
>> integrate( ).   Just saying it "gives wrong answer without
>> warning on many systems" seems misleading (it works fine in
>> many cases) and it doesn't help a user understand how to use
>> integrate( ) correctly/carefully.  IMO a simple example like
>> this one w/ dnorm would catch peoples attention and a couple
>> lines of explanation/warning would then make more sense.
>>
>> John Nolan, American U
>>
>>
>> -----Spencer Graves<spencer.graves at structuremonitoring.com>   wrote: -----
>> To: John Nolan<jpnolan at american.edu>
>> From: Spencer Graves<spencer.graves at structuremonitoring.com>
>> Date: 12/07/2010 07:58PM
>> Cc: pchausse at uwaterloo.ca, r-devel at r-project.org
>> Subject: Suggested change to integrate.Rd (was: Re: [Rd] 0.5 !=
>> integrate(dnorm,0,20000) = 0)
>>
>>          What do you think about changing the verbiage with that example
>> in "integrate.Rd" from "fails on many systems" to something like
>> "gives wrong answer without warning on many systems"?
>>
>>
>>          If I had write access to the core R code, I'd change this
>> myself:  I'm probably not the only user who might think that saying
>> something "fails" suggest it gives an error message.  Many contributions
>> on this thread make it clear that it will never be possible to write an
>> integrate function that won't give a "wrong answer without warning" in
>> some cases.
>>
>>
>>          Thanks,
>>          Spencer
>>
>>
>> #############################
>> On 12/7/2010 7:02 AM, John Nolan wrote:
>>> Putting in Inf for the upper bound does not work in general:
>>> all 3 of the following should give 0.5
>>>
>>>> integrate( dnorm, 0, Inf )
>>> 0.5 with absolute error<    4.7e-05
>>>
>>>> integrate( dnorm, 0, Inf, sd=100000 )
>>> Error in integrate(dnorm, 0, Inf, sd = 1e+05) :
>>>      the integral is probably divergent
>>>
>>>> integrate( dnorm, 0, Inf, sd=10000000 )
>>> 5.570087e-05 with absolute error<    0.00010
>>>
>>> Numerical quadrature methods look at a finite number of
>>> points, and you can find examples that will confuse any
>>> algorithm.  Rather than hope a general method will solve
>>> all problems, users should look at their integrand and
>>> pick an appropriate region of integration.
>>>
>>> John Nolan, American U.
>>>
>>>
>>> -----r-devel-bounces at r-project.org wrote: -----
>>> To: r-devel at r-project.org
>>> From: Pierre Chausse
>>> Sent by: r-devel-bounces at r-project.org
>>> Date: 12/07/2010 09:46AM
>>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>>
>>>      The warning about "absolute error == 0" would not be sufficient
>>> because if you do
>>>     >    integrate(dnorm, 0, 5000)
>>> 2.326323e-06 with absolute error<    4.6e-06
>>>
>>> We get reasonable absolute error and wrong answer. For very high upper
>>> bound, it seems more stable to use "Inf". In that case, another
>>> .External is used which seems to be optimized for high or low bounds:
>>>
>>>     >    integrate(dnorm, 0,Inf)
>>> 0.5 with absolute error<    4.7e-05
>>>
>>>
>>> On 10-12-07 8:38 AM, John Nolan wrote:
>>>> I have wrestled with this problem before.  I think correcting
>>>> the warning to "absolute error ~<= 0" is a good idea, and printing
>>>> a warning if subdivisions==1 is also helpful.  Also, including
>>>> a simple example like the one that started this thread on the
>>>> help page for integrate might make the issue more clear to users.
>>>>
>>>> But min.subdivisions is probably not.  On the example with dnorm( ),
>>>> I doubt 3 subdivisions would work.  The problem isn't that
>>>> we aren't sudividing enough, the problem is that the integrand
>>>> is 0 (in double precision) on most of the region and the
>>>> algorithm isn't designed to handle this.  There is no way to
>>>> determine how many subdivisions are necessary to get a reasonable
>>>> answer without a detailed analysis of the integrand.
>>>>
>>>> I've gotten useful results with integrands that are monotonic on
>>>> the tail with a "self-triming integration" routine
>>>> like the following:
>>>>
>>>>> right.trimmed.integrate<- function( f, lower, upper, epsilon=1e-100,
>> min.width=1e-10, ... ) {
>>>> + # trim the region of integration on the right until f(x)>     epsilon
>>>> +
>>>> + a<- lower; b<- upper
>>>> + while ( (b-a>min.width)&&     (f(b)<epsilon) ) { b<- (a+b)/2 }
>>>> +
>>>> + return( integrate(f,a,b,...) ) }
>>>>
>>>>> right.trimmed.integrate( dnorm, 0, 20000 )  # test
>>>> 0.5 with absolute error<     9.2e-05
>>>>
>>>> This can be adapted to left trim or (left and right) trim,
>> abs(f(x)-c)>epsilon,
>>>> etc.  Setting the tolerances epsilon and min.width is an issue,
>>>> but an explicit discussion of these values could encourage people to
>>>> think about the problem in their specific case.  And of course, none
>>>> of this guarantees a correct answer, especially if someone tries this
>>>> on non-monotonic integrands with complicated 0 sets.  One could write
>>>> a somewhat more user-friendly version where the user has to specify
>>>> some property (or set of properties) of the integrand, e.g. "right-tail
>>>> decreasing to 0", etc. and have the algorithm try to do smart
>>>> trimming based on this.  But perhaps this getting too involved.
>>>>
>>>> In the end, there is no general solution because any solution
>>>> depends on the specific nature of the integrand.  Clearer messages,
>>>> warnings in suspicious cases like subdivisions==1, and a simple
>>>> example explaining what the issue is in the help page would help
>>>> some people.
>>>>
>>>> John
>>>>
>>>>
>> ...........................................................................
>>>>      John P. Nolan
>>>>      Math/Stat Department
>>>>      227 Gray Hall
>>>>      American University
>>>>      4400 Massachusetts Avenue, NW
>>>>      Washington, DC 20016-8050
>>>>
>>>>      jpnolan at american.edu
>>>>      202.885.3140 voice
>>>>      202.885.3155 fax
>>>>      http://academic2.american.edu/~jpnolan
>>>>
>> ...........................................................................
>>>> -----r-devel-bounces at r-project.org wrote: -----
>>>> To: r-devel at r-project.org, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>> From: Martin Maechler
>>>> Sent by: r-devel-bounces at r-project.org
>>>> Date: 12/07/2010 03:29AM
>>>> Subject: Re: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
>>>>
>>>>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>>>>         on Tue, 7 Dec 2010 07:41:16 +0000 (GMT) writes:
>>>>         >     On Mon, 6 Dec 2010, Spencer Graves wrote:
>>>>         >>     Hello:
>>>>         >>
>>>>         >>
>>>>         >>     The example "integrate(dnorm,0,20000)" says it "fails on many
>> systems".
>>>>         >>     I just got 0 from it, when I should have gotten either an
>> error or something
>>>>         >>     close to 0.5.  I got this with R 2.12.0 under both Windows
>> Vista_x64 and
>>>>         >>     Linux (Fedora 13);  see the results from Windows below.  I
>> thought you might
>>>>         >>     want to know.
>>>>
>>>>         >     Well, isn't that exactly what the help page says happens?
>> That
>>>>         >     example is part of a section entitled
>>>>
>>>>         >     ## integrate can fail if misused
>>>>
>>>>         >     and is part of the illustration of
>>>>
>>>>         >     If the function is
>>>>         >     approximately constant (in particular, zero) over nearly all
>> its
>>>>         >     range it is possible that the result and error estimate may be
>>>>         >     seriously wrong.
>>>>
>>>> yes, of course,
>>>> and the issue has been known for ``ages''  ..
>>>> ..........
>>>> ..........
>>>> but it seems that too many useRs are not reading the help
>>>> page carefully, but only browse it quickly.
>>>> I think we (R developers) have to live with this fact
>>>> and should consider adapting to it a bit more, particularly in
>>>> this case (see below)
>>>>
>>>>         >>
>>>>         >>     Thanks for all your work in creating and maintaining R.
>>>>         >>
>>>>         >>
>>>>         >>     Best Wishes,
>>>>         >>     Spencer Graves
>>>>         >>     ###############################
>>>>
>>>>         >>
>>>>         >>     integrate(dnorm,0,20000) ## fails on many systems
>>>>
>>>>         >>     0 with absolute error<     0
>>>>
>>>> and this is particularly unsatisfactory for another reason:
>>>>
>>>> "absolute error<     0"
>>>> is *always* incorrect, so I think we should change *some*thing.
>>>>
>>>> We could just use "<=" (and probably should in any case, or
>>>> "<     ~= x" which would convey ``is less than about x'' which I
>>>> think is all we can say),
>>>> but could consider giving a different message when the integral
>>>> evaluates to 0 or, rather actually,
>>>> only when the error bound ('abs.error') is 0 *and* 'subdivisions == 1'
>>>> as the latter indicates that the algorithm treated the integrand
>>>> f(.) as if f() was a linear function.
>>>>
>>>> But in my quick experiments, even for linear (incl. constant)
>>>> functions, the 'abs.error' returned is never 0.
>>>>
>>>> If we want to be cautious,
>>>> such a warning could be made explicitly suppressable by an argument
>>>>           .warn.if.doubtful = TRUE
>>>>
>>>> An additional possibility I'd like to try, is a new argument
>>>>        'min.subdivisions = 3' which specifies the *minimal* number
>>>> of subdivisions to be used in addition to the already present
>>>>        'subdivisions = 100' (= the maximum number of subintervals.)
>>>>
>>>> Martin Maechler,
>>>> ETH Zurich
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From friendly at yorku.ca  Thu Dec  9 16:05:50 2010
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 09 Dec 2010 10:05:50 -0500
Subject: [Rd] warning creating an as.array method in a package
Message-ID: <4D00F04E.4080209@yorku.ca>

I posted on this topic to r-help, but never got a sufficient answer, so 
I'm reposting here.

[Env:  R 2.11.1, Win Xp, using Eclipse/StatET]

In a package I'm working on, I want to create as.matrix() and as.array() 
methods for a particular kind of
object (log odds ratios). These are returned in a loddsratio object as 
the $coefficients component,
a vector, but really reflect an underlying (R-1)x(C-1)xstrata array, 
whose attributes are contained in other components.

These are all properly declared in the NAMESPACE as S3 methods,

...
S3method(dim, loddsratio)
S3method(dimnames, loddsratio)
S3method(print, loddsratio)
S3method(vcov, loddsratio)
S3method(as.matrix, loddsratio)
S3method(as.array, loddsratio)

Yet, when I run R CMD check, R CMD build, etc. or even load the package, 
I get the warning,

 > library(vcdExtra)
Loading required package: vcd
Loading required package: MASS
Loading required package: grid
Loading required package: colorspace
Loading required package: gnm
Warning message:
found an S4 version of ?as.array? so it has not been imported correctly

 > showMethods("as.array")
Function: as.array (package base)
x="ANY"
x="Matrix"

But as.array does show up as a method for my class:

 > methods(class="loddsratio")
[1] as.array.loddsratio*      as.data.frame.loddsratio*
[3] as.matrix.loddsratio*     coef.loddsratio*
[5] confint.loddsratio*       dim.loddsratio*
[7] dimnames.loddsratio*      print.loddsratio*
[9] vcov.loddsratio*

    Non-visible functions are asterisked
 >

Is there some work-around so I can have an S3 as.array() method in my 
package and avoid this warning?



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From tal.galili at gmail.com  Fri Dec 10 11:40:47 2010
From: tal.galili at gmail.com (Tal Galili)
Date: Fri, 10 Dec 2010 12:40:47 +0200
Subject: [Rd] Consistency of variable storage in R and Sys.setlocale (is
 this a feature or bug)?
Message-ID: <AANLkTin7Jipu=bHu56T79yHj0y_rE3t=aR+JqA+GzVHY@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101210/2bd045f8/attachment.pl>

From mtalbert at usgs.gov  Thu Dec  9 19:11:33 2010
From: mtalbert at usgs.gov (Marian K Talbert)
Date: Thu, 9 Dec 2010 11:11:33 -0700
Subject: [Rd] How to call DBLEPR in Fortran code to be used by R
Message-ID: <OF94431EEA.C43B442D-ON872577F4.0063A87A-872577F4.0063EFE2@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101209/5997a31c/attachment.pl>

From murdoch.duncan at gmail.com  Fri Dec 10 14:19:57 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Dec 2010 08:19:57 -0500
Subject: [Rd] How to call DBLEPR in Fortran code to be used by R
In-Reply-To: <OF94431EEA.C43B442D-ON872577F4.0063A87A-872577F4.0063EFE2@usgs.gov>
References: <OF94431EEA.C43B442D-ON872577F4.0063A87A-872577F4.0063EFE2@usgs.gov>
Message-ID: <4D0228FD.7050100@gmail.com>

On 09/12/2010 1:11 PM, Marian K Talbert wrote:
> Hi
>
> I've built a dll using Fortran code and can call it by either R or
> Fortran. Calling by the former gives me the wrong answer and the later
> gives the correct answer.

That sounds like a type problem.  Are you using double precision variables?


>    From what I've read, it looks like I should use
> the subroutines DBLEPR, INTPR and REALPR to get values to show up in R
> which I hope will allow me to find the error.  I've downloaded the
> R-2.12.0.tar.gz but have been unable to find these subroutines or any
> examples of how to get Fortran to recognize them.  Obviously when I try to
> compile I get undefined reference to 'dblepr_'.  So I was wondering if
> there is some way I can specify in the makefile or possibly by building
> the dll using R CMD SHLIB where to find these subroutines or where else
> this information might need to be.  I noticed in Venables book that the
> functionality of these subroutines can be compiler dependent but there is
> no specification of which compilers might work.  I'm using gfortran could
> this be an issue?

You should use

R CMD SHLIB source.f

to compile your Fortran.  Does the example of dblepr in Writing R 
Extensions work for you?

Duncan Murdoch

> Thanks,
>
> Marian Talbert
> ASRC Management Servics
> Contracted To:
> US Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg C
> Fort Collins, CO 80526
> Phone: 970-226-9108
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From friendly at yorku.ca  Fri Dec 10 16:18:49 2010
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 10 Dec 2010 10:18:49 -0500
Subject: [Rd] warning creating an as.array method in a package
In-Reply-To: <4D00F04E.4080209@yorku.ca>
References: <4D00F04E.4080209@yorku.ca>
Message-ID: <4D0244D9.70809@yorku.ca>

I found a solution to this problem, but don't understand why it was 
necessary. In a clean workspace, I get:

 > methods(as.array)
[1] as.array.default
 > showMethods("as.array")

Function "as.array":
  <not a generic function>

So, I just added the generic definition to my package, making with 
warnings go away.

as.array <- function(x, ...)
	UseMethod("as.array")

as.array.loddsratio <- function (x, log=x$log, ...)
	drop(array(coef(x, log = log), dim = dim(x), dimnames=dimnames(x)))

Yet, help(as.array) says:

as.array is a generic function for coercing to arrays. The default 
method does so by attaching a dim attribute to it. It also attaches 
dimnames if x has names.   Is this a documentation error?

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.11.1
 >

On 12/9/2010 10:05 AM, Michael Friendly wrote:
> I posted on this topic to r-help, but never got a sufficient answer, so
> I'm reposting here.
>
> [Env: R 2.11.1, Win Xp, using Eclipse/StatET]
>
> In a package I'm working on, I want to create as.matrix() and as.array()
> methods for a particular kind of
> object (log odds ratios). These are returned in a loddsratio object as
> the $coefficients component,
> a vector, but really reflect an underlying (R-1)x(C-1)xstrata array,
> whose attributes are contained in other components.
>
> These are all properly declared in the NAMESPACE as S3 methods,
>
> ...
> S3method(dim, loddsratio)
> S3method(dimnames, loddsratio)
> S3method(print, loddsratio)
> S3method(vcov, loddsratio)
> S3method(as.matrix, loddsratio)
> S3method(as.array, loddsratio)
>
> Yet, when I run R CMD check, R CMD build, etc. or even load the package,
> I get the warning,
>
>  > library(vcdExtra)
> Loading required package: vcd
> Loading required package: MASS
> Loading required package: grid
> Loading required package: colorspace
> Loading required package: gnm
> Warning message:
> found an S4 version of ?as.array? so it has not been imported correctly
>
>  > showMethods("as.array")
> Function: as.array (package base)
> x="ANY"
> x="Matrix"
>
> But as.array does show up as a method for my class:
>
>  > methods(class="loddsratio")
> [1] as.array.loddsratio* as.data.frame.loddsratio*
> [3] as.matrix.loddsratio* coef.loddsratio*
> [5] confint.loddsratio* dim.loddsratio*
> [7] dimnames.loddsratio* print.loddsratio*
> [9] vcov.loddsratio*
>
> Non-visible functions are asterisked
>  >
>
> Is there some work-around so I can have an S3 as.array() method in my
> package and avoid this warning?
>
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From Niels.R.Hansen+lists at math.ku.dk  Sat Dec 11 08:23:39 2010
From: Niels.R.Hansen+lists at math.ku.dk (Niels Richard Hansen)
Date: Fri, 10 Dec 2010 23:23:39 -0800
Subject: [Rd] 'identical' and the warning "ignoring non-pairlist attributes"
Message-ID: <4D0326FB.1030505@math.ku.dk>

Dear R developers

Using the 'foreach' package I encounter warnings like

Warning message:
In identical(.combine, cbind) : ignoring non-pairlist attributes

Warnings appear once in a new R-session when I run a
particular piece of code - and not again. I understand from
the source code of 'identical' that the function checks and
believes that .combine and cbind have non-pairlist attributes, but I
don't understand how this can be the case

I have produced the following minimal example

data.frame()[rep(1,1e6), ]
library(foreach)
identical(foreach:::defcombine, cbind)

resulting in

[1] FALSE
Warning message:
In identical(foreach:::defcombine, cbind) :
   ignoring non-pairlist attributes

The warning is not related to the foreach package it seems. I get
the same kind of warning with e.g.

identical(spatial:::trmat, cbind)

in a new R-session. Many other functions I have tried do, however,
not result in the warning. The warning depends on the supposedly completely
unrelated data frame operation. It seems also to be related to the
fact that the data frame is empty and I extract a large number of
columns out of this empty data frame. I would highly appreciate help
on this to get rid of the warning in my own package.

Thanks, Niels

R version 2.12.1 RC (2010-12-10 r53825)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] foreach_1.3.0   codetools_0.2-6 iterators_1.0.3

(or
other attached packages:
[1] spatial_7.3-2)

-- 
Niels Richard Hansen                     Web:   www.math.ku.dk/~richard	
Associate Professor                      Email: Niels.R.Hansen at math.ku.dk
Department of Mathematical Sciences             nielsrichardhansen at gmail.com
University of Copenhagen                 Skype: nielsrichardhansen.dk	
Universitetsparken 5                     Phone: +1 510 502 8161	
2100 Copenhagen ?
Denmark


From pdalgd at gmail.com  Sat Dec 11 11:23:08 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 11 Dec 2010 11:23:08 +0100
Subject: [Rd] 'identical' and the warning "ignoring non-pairlist
	attributes"
In-Reply-To: <4D0326FB.1030505@math.ku.dk>
References: <4D0326FB.1030505@math.ku.dk>
Message-ID: <0BC90576-12DA-4679-B4A7-370DA1643A08@gmail.com>


On Dec 11, 2010, at 08:23 , Niels Richard Hansen wrote:

> Dear R developers
> 
> Using the 'foreach' package I encounter warnings like
> 
> Warning message:
> In identical(.combine, cbind) : ignoring non-pairlist attributes
> 
> Warnings appear once in a new R-session when I run a
> particular piece of code - and not again. I understand from
> the source code of 'identical' that the function checks and
> believes that .combine and cbind have non-pairlist attributes, but I
> don't understand how this can be the case
> 
> I have produced the following minimal example
> 
> data.frame()[rep(1,1e6), ]
> library(foreach)
> identical(foreach:::defcombine, cbind)
> 
> resulting in
> 
> [1] FALSE
> Warning message:
> In identical(foreach:::defcombine, cbind) :
>  ignoring non-pairlist attributes
> 
> The warning is not related to the foreach package it seems. I get
> the same kind of warning with e.g.
> 
> identical(spatial:::trmat, cbind)
> 
> in a new R-session. Many other functions I have tried do, however,
> not result in the warning. The warning depends on the supposedly completely
> unrelated data frame operation. It seems also to be related to the
> fact that the data frame is empty and I extract a large number of
> columns out of this empty data frame. I would highly appreciate help
> on this to get rid of the warning in my own package.

Hm, I think you might have tickled a buglet here. I can debug it down to a comparison of two CHARSXPs, both having CHARSXP attributes. I'm a getting a little rusty on debugging at that level, but I don't think CHARSXPs are supposed to _have_ attributes in any meaningful context, so perhaps identical() just shouldn't check. On the other hand, it could also be the sign of a memory overrun in the preceding memory-intensive operation. 


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Sat Dec 11 21:47:47 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 11 Dec 2010 21:47:47 +0100
Subject: [Rd] 'identical' and the warning "ignoring non-pairlist
	attributes"
In-Reply-To: <0BC90576-12DA-4679-B4A7-370DA1643A08@gmail.com>
References: <4D0326FB.1030505@math.ku.dk>
	<0BC90576-12DA-4679-B4A7-370DA1643A08@gmail.com>
Message-ID: <D1EEC8DE-83C8-48F2-81C4-7F0580C3FC27@gmail.com>


On Dec 11, 2010, at 11:23 , peter dalgaard wrote:

> 
> On Dec 11, 2010, at 08:23 , Niels Richard Hansen wrote:
> 
>> Dear R developers
>> 
>> Using the 'foreach' package I encounter warnings like
>> 
>> Warning message:
>> In identical(.combine, cbind) : ignoring non-pairlist attributes
>> 
>> Warnings appear once in a new R-session when I run a
>> particular piece of code - and not again. I understand from
>> the source code of 'identical' that the function checks and
>> believes that .combine and cbind have non-pairlist attributes, but I
>> don't understand how this can be the case
>> 
>> I have produced the following minimal example
>> 
>> data.frame()[rep(1,1e6), ]
>> library(foreach)
>> identical(foreach:::defcombine, cbind)
>> 
>> resulting in
>> 
>> [1] FALSE
>> Warning message:
>> In identical(foreach:::defcombine, cbind) :
>> ignoring non-pairlist attributes
>> 
>> The warning is not related to the foreach package it seems. I get
>> the same kind of warning with e.g.
>> 
>> identical(spatial:::trmat, cbind)
>> 
>> in a new R-session. Many other functions I have tried do, however,
>> not result in the warning. The warning depends on the supposedly completely
>> unrelated data frame operation. It seems also to be related to the
>> fact that the data frame is empty and I extract a large number of
>> columns out of this empty data frame. I would highly appreciate help
>> on this to get rid of the warning in my own package.
> 
> Hm, I think you might have tickled a buglet here. I can debug it down to a comparison of two CHARSXPs, both having CHARSXP attributes. I'm a getting a little rusty on debugging at that level, but I don't think CHARSXPs are supposed to _have_ attributes in any meaningful context, so perhaps identical() just shouldn't check. On the other hand, it could also be the sign of a memory overrun in the preceding memory-intensive operation. 
> 

Robert Gentleman pointed out offlist that attributes of CHARSXP are being used for cacheing and hashing, so skipping the comparison is what makes sense. I have fixed this for R-devel now (tampering with 2.12.1 RC for this sort of reason is probably best avoided).


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j.e.aten at gmail.com  Sun Dec 12 03:04:07 2010
From: j.e.aten at gmail.com (Jason E. Aten)
Date: Sat, 11 Dec 2010 20:04:07 -0600
Subject: [Rd] R <-> Haskell
Message-ID: <AANLkTik2Cv-6nzbEnEkgVDT5Y-SN72HT6sBT0gbc5to0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101211/45a873e3/attachment.pl>

From ggrothendieck at gmail.com  Sun Dec 12 04:19:20 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 11 Dec 2010 22:19:20 -0500
Subject: [Rd] R <-> Haskell
In-Reply-To: <AANLkTik2Cv-6nzbEnEkgVDT5Y-SN72HT6sBT0gbc5to0@mail.gmail.com>
References: <AANLkTik2Cv-6nzbEnEkgVDT5Y-SN72HT6sBT0gbc5to0@mail.gmail.com>
Message-ID: <AANLkTi=cZaTnFe6GnYVbWXEQdjbEm_uSOtVXwrjRbMFc@mail.gmail.com>

On Sat, Dec 11, 2010 at 9:04 PM, Jason E. Aten <j.e.aten at gmail.com> wrote:
> I'd like to develop, if there is not one already, an interface between R
> code and Haskell code, to allow R code to call Haskell (compiled) code, and
> vice-versa. ?But in the interest of not reinventing the wheel, does anyone
> on this list know of existing bindings for Haskell code?
>
> There is support for loading plugins in Haskell, and for an eval() like set
> of functions provided by the Haskell hs-plugin package that evaluates
> arbitrary strings in the IO monad.
> http://www.cse.unsw.edu.au/~dons/hs-plugins/paper/ describes this
> functionality. For example:
>
> #include <stdio.h>
> #include "RunHaskell.h"
>
> int main(int argc, char *argv[]) {
> ?int *p;
> ?hs_init(&argc, &argv);
> ?p = hs_eval_i("foldl1 (+) [0 .. 10]"); /* this is Haskell code */
> ?printf("%d\n", *p); hs_exit();
> }
>
>
>
> That said, i don't think it will be that difficutl. ?But I imagine the
> hardest part of this will be getting the memory management for garbage
> collection right. I thought I would start by looking at how the rJava or
> rJython packages handle memory. If anyone has pointers or advice on
> integrating R's garbage collection with another language's garbage
> collection, I'd welcome suggestions and warnings about pitfalls.
>

You might look at:

http://home.gna.org/ocaml-r/

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From j.e.aten at gmail.com  Sun Dec 12 07:40:15 2010
From: j.e.aten at gmail.com (Jason E. Aten)
Date: Sun, 12 Dec 2010 00:40:15 -0600
Subject: [Rd] R <-> Haskell
In-Reply-To: <AANLkTi=cZaTnFe6GnYVbWXEQdjbEm_uSOtVXwrjRbMFc@mail.gmail.com>
References: <AANLkTik2Cv-6nzbEnEkgVDT5Y-SN72HT6sBT0gbc5to0@mail.gmail.com>
	<AANLkTi=cZaTnFe6GnYVbWXEQdjbEm_uSOtVXwrjRbMFc@mail.gmail.com>
Message-ID: <AANLkTikt1yFG+-RYNQRT6guYL03ncBToQULs+Z25s7c+@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101212/7a0df1d2/attachment.pl>

From Niels.R.Hansen+lists at math.ku.dk  Sun Dec 12 07:49:16 2010
From: Niels.R.Hansen+lists at math.ku.dk (Niels Richard Hansen)
Date: Sat, 11 Dec 2010 22:49:16 -0800
Subject: [Rd] 'identical' and the warning "ignoring non-pairlist
	attributes"
In-Reply-To: <D1EEC8DE-83C8-48F2-81C4-7F0580C3FC27@gmail.com>
References: <4D0326FB.1030505@math.ku.dk>
	<0BC90576-12DA-4679-B4A7-370DA1643A08@gmail.com>
	<D1EEC8DE-83C8-48F2-81C4-7F0580C3FC27@gmail.com>
Message-ID: <4D04706C.4080605@math.ku.dk>



On 11/12/10 12.47, peter dalgaard wrote:
>
> On Dec 11, 2010, at 11:23 , peter dalgaard wrote:
>
>>
>> On Dec 11, 2010, at 08:23 , Niels Richard Hansen wrote:
>>
>>> Dear R developers
>>>
>>> Using the 'foreach' package I encounter warnings like
>>>
>>> Warning message: In identical(.combine, cbind) : ignoring non-pairlist
>>> attributes
>>>
>>> Warnings appear once in a new R-session when I run a particular piece of
>>> code - and not again. I understand from the source code of 'identical'
>>> that the function checks and believes that .combine and cbind have
>>> non-pairlist attributes, but I don't understand how this can be the case
>>>
>>> I have produced the following minimal example
>>>
>>> data.frame()[rep(1,1e6), ] library(foreach)
>>> identical(foreach:::defcombine, cbind)
>>>
>>> resulting in
>>>
>>> [1] FALSE Warning message: In identical(foreach:::defcombine, cbind) :
>>> ignoring non-pairlist attributes
>>>
>>> The warning is not related to the foreach package it seems. I get the
>>> same kind of warning with e.g.
>>>
>>> identical(spatial:::trmat, cbind)
>>>
>>> in a new R-session. Many other functions I have tried do, however, not
>>> result in the warning. The warning depends on the supposedly completely
>>> unrelated data frame operation. It seems also to be related to the fact
>>> that the data frame is empty and I extract a large number of columns out
>>> of this empty data frame. I would highly appreciate help on this to get
>>> rid of the warning in my own package.
>>
>> Hm, I think you might have tickled a buglet here. I can debug it down to a
>> comparison of two CHARSXPs, both having CHARSXP attributes. I'm a getting a
>> little rusty on debugging at that level, but I don't think CHARSXPs are
>> supposed to _have_ attributes in any meaningful context, so perhaps
>> identical() just shouldn't check. On the other hand, it could also be the
>> sign of a memory overrun in the preceding memory-intensive operation.
>>
>
> Robert Gentleman pointed out offlist that attributes of CHARSXP are being
> used for cacheing and hashing, so skipping the comparison is what makes
> sense. I have fixed this for R-devel now (tampering with 2.12.1 RC for this
> sort of reason is probably best avoided).
>
>

Peter, thanks for looking into this. I know very little about the R
implementation at the level you are talking about. For the record
it is pretty easy to avoid the warning by checking and _not_
doing the inefficient subsetting of an empty data frame ...

- Niels

-- 
Niels Richard Hansen                     Web:   www.math.ku.dk/~richard	
Associate Professor                      Email: Niels.R.Hansen at math.ku.dk
Department of Mathematical Sciences             nielsrichardhansen at gmail.com
University of Copenhagen                 Skype: nielsrichardhansen.dk	
Universitetsparken 5                     Phone: +1 510 502 8161	
2100 Copenhagen ?
Denmark


From pdalgd at gmail.com  Sun Dec 12 10:49:58 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 12 Dec 2010 10:49:58 +0100
Subject: [Rd] 'identical' and the warning "ignoring non-pairlist
	attributes"
In-Reply-To: <4D04706C.4080605@math.ku.dk>
References: <4D0326FB.1030505@math.ku.dk>
	<0BC90576-12DA-4679-B4A7-370DA1643A08@gmail.com>
	<D1EEC8DE-83C8-48F2-81C4-7F0580C3FC27@gmail.com>
	<4D04706C.4080605@math.ku.dk>
Message-ID: <572052D5-340B-420A-B02C-8C828DC470C4@gmail.com>


On Dec 12, 2010, at 07:49 , Niels Richard Hansen wrote:

> Peter, thanks for looking into this. I know very little about the R
> implementation at the level you are talking about. For the record
> it is pretty easy to avoid the warning by checking and _not_
> doing the inefficient subsetting of an empty data frame ...
> 
> - Niels

It's not something that you'd be expected to know about, but this is r-devel and sometimes we think aloud, hoping that it rings a bell with some other reader...

I don't think it is the empty data frame per se that tickles the bug. Rather, it is an issue of having generated so much activity creating character constants that there are nontrivial hash-chains plus maybe the fact that you are using identical() to compare language-level objects. The attributes of the  were 

(gdb) p Rf_PrintValue(ax)
<CHARSXP: "NA.43436">

(gdb) p Rf_PrintValue(ay)
<CHARSXP: "NA.64694">

and the (sub-) objects that were being compared at the time were

(gdb) p Rf_PrintValue(y)
<CHARSXP: "...">

(gdb) p Rf_PrintValue(x)
<CHARSXP: "a">

"a" and "..." are from argument lists of the functions that you are comparing, and I would assume that the "NA.43436" and "NA.64694" come from  rownames of the million-row data frame that you were creating.


(For the uninitiated: a hash table is used for by-name lookup. It works by computing a numerical "hash-index" based on the name, hoping to replace a linear search by a simple indexed lookup. If two or more names have the same hash index, a final linear search through a chained list of names is necessary.) 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From arthur.charpentier at gmail.com  Mon Dec 13 18:36:42 2010
From: arthur.charpentier at gmail.com (Arthur Charpentier)
Date: Mon, 13 Dec 2010 12:36:42 -0500
Subject: [Rd] errors in getconnection or scan
Message-ID: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101213/5e0bbec9/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec 13 18:50:32 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 13 Dec 2010 12:50:32 -0500
Subject: [Rd] errors in getconnection or scan
In-Reply-To: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>
References: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>
Message-ID: <4D065CE8.6030302@gmail.com>

On 13/12/2010 12:36 PM, Arthur Charpentier wrote:
> I was wondering if there was a function like "does connection exists" ?

See ?showConnections.

> I am currently using loops to build up a database, and I have either
>
>>   B = getConnection(localization)
> Error in getConnection(localization) : there is no connection -2147483648
> In addition: Warning message:
> In getConnection(localization) : NAs introduced by coercion

Where did the localization variable come from?  getConnection is pretty 
rarely used.

>
> or
>
>>   B = scan(localization)
> Error in file(file, "r") : cannot open the connection
> In addition: Warning message:
> In file(file, "r") : cannot open: HTTP status was '404 Not Found'
>
> is there a way to test where localization is an html page, or not ? and to
> say that if localization does exist, then scan it ?

What's your definition of an html page?  Testing for valid html is hard.

Duncan Murdoch


From arthur.charpentier at gmail.com  Mon Dec 13 18:56:43 2010
From: arthur.charpentier at gmail.com (Arthur Charpentier)
Date: Mon, 13 Dec 2010 12:56:43 -0500
Subject: [Rd] errors in getconnection or scan
In-Reply-To: <4D065CE8.6030302@gmail.com>
References: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>
	<4D065CE8.6030302@gmail.com>
Message-ID: <AANLkTi=3NrwZMd15zkZK5rJ+Ndp9czG8_fRw8DdH+aD6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101213/3f307dbe/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec 13 19:17:49 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 13 Dec 2010 13:17:49 -0500
Subject: [Rd] errors in getconnection or scan
In-Reply-To: <AANLkTi=3NrwZMd15zkZK5rJ+Ndp9czG8_fRw8DdH+aD6@mail.gmail.com>
References: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>	<4D065CE8.6030302@gmail.com>
	<AANLkTi=3NrwZMd15zkZK5rJ+Ndp9czG8_fRw8DdH+aD6@mail.gmail.com>
Message-ID: <4D06634D.7090809@gmail.com>

On 13/12/2010 12:56 PM, Arthur Charpentier wrote:
> sorry... localization is a string of characters
> for instance
> localization =
> paste("http://www.resultsfromtennis.com/",year,"/atp/",city,".html",sep="")
> where year is 2006 and city can be "wimbledon"
> hence here, since the page
> "http://www.resultsfromtennis.com/2007/atp/wimbledon.html" does exist, I
> can get the tables inside
> but
> "http://www.resultsfromtennis.com/1977/atp/shertogenbosch.html"
> does not exist... is there a way to detect that the html page does not
> exist ?

If you try to read it and get an error, you will know there's a problem. 
  For example,

x <- "http://cran.r-project.ogr"  # has a typo
con <- url(x)
html <- readLines(con)

This should produce an error, but might give you a junk page if your DNS 
provider substitutes for it.  You can catch the error using

html <- try(readLines(con), silent=TRUE)
if (inherits(html, "try-error")) cat("Error!")

Duncan Murdoch

>
>
> 2010/12/13 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>
>
>     On 13/12/2010 12:36 PM, Arthur Charpentier wrote:
>
>         I was wondering if there was a function like "does connection
>         exists" ?
>
>
>     See ?showConnections.
>
>
>         I am currently using loops to build up a database, and I have either
>
>               B = getConnection(localization)
>
>         Error in getConnection(localization) : there is no connection
>         -2147483648
>         In addition: Warning message:
>         In getConnection(localization) : NAs introduced by coercion
>
>
>     Where did the localization variable come from?  getConnection is
>     pretty rarely used.
>
>
>
>         or
>
>               B = scan(localization)
>
>         Error in file(file, "r") : cannot open the connection
>         In addition: Warning message:
>         In file(file, "r") : cannot open: HTTP status was '404 Not Found'
>
>         is there a way to test where localization is an html page, or
>         not ? and to
>         say that if localization does exist, then scan it ?
>
>
>     What's your definition of an html page?  Testing for valid html is hard.
>
>     Duncan Murdoch
>
>


From arthur.charpentier at gmail.com  Mon Dec 13 19:42:21 2010
From: arthur.charpentier at gmail.com (Arthur Charpentier)
Date: Mon, 13 Dec 2010 13:42:21 -0500
Subject: [Rd] errors in getconnection or scan
In-Reply-To: <4D06634D.7090809@gmail.com>
References: <AANLkTim7MRasN2+SuSThq-mszf4w7isYim1LBTVxVLgf@mail.gmail.com>
	<4D065CE8.6030302@gmail.com>
	<AANLkTi=3NrwZMd15zkZK5rJ+Ndp9czG8_fRw8DdH+aD6@mail.gmail.com>
	<4D06634D.7090809@gmail.com>
Message-ID: <AANLkTik5yMcpWDaq_Uo2c003ADp+SSPVhtQRBfyeLg3O@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101213/e7b3dfb2/attachment.pl>

From macrakis at alum.mit.edu  Tue Dec 14 01:52:49 2010
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 13 Dec 2010 19:52:49 -0500
Subject: [Rd] 0.5 != integrate(dnorm,0,20000) = 0
In-Reply-To: <OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
References: <19709.61472.158760.44576@lynne.math.ethz.ch>
	<4CFD729C.6050704@structuremonitoring.com>
	<alpine.LFD.2.00.1012070734070.10594@gannet.stats.ox.ac.uk>
	<OF8288EBC8.20FC0DC2-ON852577F2.004AF65E-852577F2.004AF661@american.edu>
	<4CFE48B2.2090804@uwaterloo.ca>
	<OF0969FD50.6188C4C4-ON852577F2.005296E8-852577F2.005296EC@american.edu>
Message-ID: <AANLkTikbnyL1iXUD4ZBoini5vG8oQUtLeJCnujTNRGX3@mail.gmail.com>

I'd suggest that the original sin here is calling some particular
numerical integration routine 'integrate', which gives the user an
illusory sense of power.... Functions have to be well-behaved in
various ways for quadrature to work well, and you've got to expect
things like

> integrate(function(x)tan(x),0,pi)
Error in integrate(function(x) tan(x), 0, pi) :
  roundoff error is detected in the extrapolation table   <<< a 'good'
error -- tells the user something's wrong
> integrate(function(x)tan(x)^2,0,pi)
1751.054 with absolute error < 0                                  <<< oops
> integrate(function(x)1/(x-pi/2)^2,0,pi)                         <<< the same pole (analytically)
Error in integrate(function(x) 1/(x - pi/2)^2, 0, pi) :         <<<
gets a useful error in this form
  non-finite function value

But by that argument, I suppose you shouldn't call floating-point
addition "+" :-)

                -s


From romain at r-enthusiasts.com  Tue Dec 14 12:40:04 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Tue, 14 Dec 2010 12:40:04 +0100
Subject: [Rd] embed Sweave driver in .Rnw file
Message-ID: <4D075794.3010201@r-enthusiasts.com>

Hello,

Sweave lets you use alternative drivers through the driver argument, and 
several packages take advantage of that and define custom Sweave driver 
for various purposes. Most of them are listed on the Reproducible 
Research CTV: 
(http://cran.r-project.org/web/views/ReproducibleResearch.html)

The next natural step is for package developpers to take advantage of 
this in their vignettes. In Rcpp we work around the way package building 
works and we do:
- let R build a dummy vignette
- then use the inst/doc/Makefile to replace it with a vignette that is 
processed by the driver from the highlight package (giving syntax 
highlighting).

I played with Sweave so that it would be able to create the driver from 
some text included in the text of the .Rnw file:

$ svn diff
Index: src/library/utils/R/Sweave.R
===================================================================
--- src/library/utils/R/Sweave.R	(revision 53846)
+++ src/library/utils/R/Sweave.R	(working copy)
@@ -20,6 +20,16 @@
  # We don't need srclines for code, but we do need it for text, and 
it's easiest
  # to just keep it for everything.

+SweaveGetDriver <- function(file){
+    txt <- readLines(file)
+    line <- grep( "\\SweaveDriver", txt, value = TRUE )
+    if( length(line) ){
+        txt <- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L] )
+        driver <- try( eval( parse( text = txt ) ), silent = TRUE )
+        if( !inherits( driver, "try-error") ) driver
+    }
+}
+
  Sweave <- function(file, driver=RweaveLatex(),
                     syntax=getOption("SweaveSyntax"), ...)
  {
@@ -28,7 +38,9 @@
      else if(is.function(driver))
          driver <- driver()

-
+    drv <- SweaveGetDriver(file)
+    if( !is.null(drv) ) driver <- drv
+
      if(is.null(syntax))
          syntax <- SweaveGetSyntax(file)
      if(is.character(syntax))



This allows one to write something like this in their file:

%\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }

So that when calling :

 > Sweave( "somefile.Rnw" )

the highlight driver is used instead of the default driver.

Could something like that be added to Sweave ?

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/fT2rZM : highlight 0.2-5
|- http://bit.ly/gpCSpH : Evolution of Rcpp code size
`- http://bit.ly/hovakS : RcppGSL initial release


From friedrich.leisch at stat.uni-muenchen.de  Tue Dec 14 13:21:55 2010
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Tue, 14 Dec 2010 13:21:55 +0100
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <4D075794.3010201@r-enthusiasts.com>
References: <4D075794.3010201@r-enthusiasts.com>
Message-ID: <19719.24931.968293.80971@angua.stat.uni-muenchen.de>

>>>>> On Tue, 14 Dec 2010 12:40:04 +0100,
>>>>> Romain Francois (RF) wrote:

  > Hello,
  > Sweave lets you use alternative drivers through the driver argument, and 
  > several packages take advantage of that and define custom Sweave driver 
  > for various purposes. Most of them are listed on the Reproducible 
  > Research CTV: 
  > (http://cran.r-project.org/web/views/ReproducibleResearch.html)

  > The next natural step is for package developpers to take advantage of 
  > this in their vignettes. In Rcpp we work around the way package building 
  > works and we do:
  > - let R build a dummy vignette
  > - then use the inst/doc/Makefile to replace it with a vignette that is 
  > processed by the driver from the highlight package (giving syntax 
  > highlighting).

  > I played with Sweave so that it would be able to create the driver from 
  > some text included in the text of the .Rnw file:

  > $ svn diff
  > Index: src/library/utils/R/Sweave.R
  > ===================================================================
  > --- src/library/utils/R/Sweave.R	(revision 53846)
  > +++ src/library/utils/R/Sweave.R	(working copy)
  > @@ -20,6 +20,16 @@
  >   # We don't need srclines for code, but we do need it for text, and 
  > it's easiest
  >   # to just keep it for everything.

  > +SweaveGetDriver <- function(file){
  > +    txt <- readLines(file)
  > +    line <- grep( "\\SweaveDriver", txt, value = TRUE )
  > +    if( length(line) ){
  > +        txt <- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L] )
  > +        driver <- try( eval( parse( text = txt ) ), silent = TRUE )
  > +        if( !inherits( driver, "try-error") ) driver
  > +    }
  > +}
  > +
  >   Sweave <- function(file, driver=RweaveLatex(),
  >                      syntax=getOption("SweaveSyntax"), ...)
  >   {
  > @@ -28,7 +38,9 @@
  >       else if(is.function(driver))
  >           driver <- driver()

  > -
  > +    drv <- SweaveGetDriver(file)
  > +    if( !is.null(drv) ) driver <- drv
  > +
  >       if(is.null(syntax))
  >           syntax <- SweaveGetSyntax(file)
  >       if(is.character(syntax))



  > This allows one to write something like this in their file:

  > %\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }

  > So that when calling :

  >> Sweave( "somefile.Rnw" )

  > the highlight driver is used instead of the default driver.

  > Could something like that be added to Sweave ?

Yes, sure!

Will have a look at the patch later this week and apply it if it
passes the tests. The patch is against a current r-devel?

Best,
Fritz


From romain at r-enthusiasts.com  Tue Dec 14 13:38:07 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Tue, 14 Dec 2010 13:38:07 +0100
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <19719.24931.968293.80971@angua.stat.uni-muenchen.de>
References: <4D075794.3010201@r-enthusiasts.com>
	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
Message-ID: <4D07652F.9030709@r-enthusiasts.com>

Le 14/12/10 13:21, Friedrich Leisch a ?crit :
>>>>>> On Tue, 14 Dec 2010 12:40:04 +0100,
>>>>>> Romain Francois (RF) wrote:
>
>    >  Hello,
>    >  Sweave lets you use alternative drivers through the driver argument, and
>    >  several packages take advantage of that and define custom Sweave driver
>    >  for various purposes. Most of them are listed on the Reproducible
>    >  Research CTV:
>    >  (http://cran.r-project.org/web/views/ReproducibleResearch.html)
>
>    >  The next natural step is for package developpers to take advantage of
>    >  this in their vignettes. In Rcpp we work around the way package building
>    >  works and we do:
>    >  - let R build a dummy vignette
>    >  - then use the inst/doc/Makefile to replace it with a vignette that is
>    >  processed by the driver from the highlight package (giving syntax
>    >  highlighting).
>
>    >  I played with Sweave so that it would be able to create the driver from
>    >  some text included in the text of the .Rnw file:
>
>    >  $ svn diff
>    >  Index: src/library/utils/R/Sweave.R
>    >  ===================================================================
>    >  --- src/library/utils/R/Sweave.R	(revision 53846)
>    >  +++ src/library/utils/R/Sweave.R	(working copy)
>    >  @@ -20,6 +20,16 @@
>    >    # We don't need srclines for code, but we do need it for text, and
>    >  it's easiest
>    >    # to just keep it for everything.
>
>    >  +SweaveGetDriver<- function(file){
>    >  +    txt<- readLines(file)
>    >  +    line<- grep( "\\SweaveDriver", txt, value = TRUE )
>    >  +    if( length(line) ){
>    >  +        txt<- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L] )
>    >  +        driver<- try( eval( parse( text = txt ) ), silent = TRUE )
>    >  +        if( !inherits( driver, "try-error") ) driver
>    >  +    }
>    >  +}
>    >  +
>    >    Sweave<- function(file, driver=RweaveLatex(),
>    >                       syntax=getOption("SweaveSyntax"), ...)
>    >    {
>    >  @@ -28,7 +38,9 @@
>    >        else if(is.function(driver))
>    >            driver<- driver()
>
>    >  -
>    >  +    drv<- SweaveGetDriver(file)
>    >  +    if( !is.null(drv) ) driver<- drv
>    >  +
>    >        if(is.null(syntax))
>    >            syntax<- SweaveGetSyntax(file)
>    >        if(is.character(syntax))
>
>
>
>    >  This allows one to write something like this in their file:
>
>    >  %\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }
>
>    >  So that when calling :
>
>    >>  Sweave( "somefile.Rnw" )
>
>    >  the highlight driver is used instead of the default driver.
>
>    >  Could something like that be added to Sweave ?
>
> Yes, sure!
>
> Will have a look at the patch later this week and apply it if it
> passes the tests.

Great. Let me know if I can expand on it (documentation, etc ...)

> The patch is against a current r-devel?

yes. rev 53846.

> Best,
> Fritz



-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/fT2rZM : highlight 0.2-5
|- http://bit.ly/gpCSpH : Evolution of Rcpp code size
`- http://bit.ly/hovakS : RcppGSL initial release


From djsamperi at gmail.com  Tue Dec 14 15:54:40 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 14 Dec 2010 09:54:40 -0500
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <19719.24931.968293.80971@angua.stat.uni-muenchen.de>
References: <4D075794.3010201@r-enthusiasts.com>
	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
Message-ID: <AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101214/5d04ec3b/attachment.pl>

From murdoch.duncan at gmail.com  Tue Dec 14 16:26:23 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Dec 2010 10:26:23 -0500
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>
References: <4D075794.3010201@r-enthusiasts.com>	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
	<AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>
Message-ID: <4D078C9F.90008@gmail.com>

On 14/12/2010 9:54 AM, Dominick Samperi wrote:
> Another question about Sweave (actually it is more a question
> about TeX). Is there a reliable (system-independent) way to
> use Sweave.sty without having to place it in the current working
> directory? MiKTeX under Windows has dropped the use of
> TEXINPUTS, and this complicates the problem.

If you run it from R, the right path will be put in place.  The 
tools::texi2dvi function does this.

> Furthermore, you cannot refer to Sweave.sty using its full path
> as this would obviously not be system-independent.
>
> Yet another small issue: If I configure Sweave to use a
> temp directory for its temp files, and if this temp directory
> does not exist, TeX fails with error diagnostics that is not
> clear at all. Is there a way to have TeX automatically
> create the directory if necessary?

I don't understand this one.  Are you talking about a "prefix=somedir/" 
option to Sweave?  That needs to be there before TeX is run.  I 
sometimes put a  dir.create("somedir", showWarnings=FALSE) call in an 
early chunk in the document to create it.

Duncan Murdoch

> Thanks,
> Dominick
>
> On Tue, Dec 14, 2010 at 7:21 AM, Friedrich Leisch<
> friedrich.leisch at stat.uni-muenchen.de>  wrote:
>
> >  >>>>>  On Tue, 14 Dec 2010 12:40:04 +0100,
> >  >>>>>  Romain Francois (RF) wrote:
> >
> >   >  Hello,
> >   >  Sweave lets you use alternative drivers through the driver argument, and
> >   >  several packages take advantage of that and define custom Sweave driver
> >   >  for various purposes. Most of them are listed on the Reproducible
> >   >  Research CTV:
> >   >  (http://cran.r-project.org/web/views/ReproducibleResearch.html)
> >
> >   >  The next natural step is for package developpers to take advantage of
> >   >  this in their vignettes. In Rcpp we work around the way package building
> >   >  works and we do:
> >   >  - let R build a dummy vignette
> >   >  - then use the inst/doc/Makefile to replace it with a vignette that is
> >   >  processed by the driver from the highlight package (giving syntax
> >   >  highlighting).
> >
> >   >  I played with Sweave so that it would be able to create the driver from
> >   >  some text included in the text of the .Rnw file:
> >
> >   >  $ svn diff
> >   >  Index: src/library/utils/R/Sweave.R
> >   >  ===================================================================
> >   >  --- src/library/utils/R/Sweave.R    (revision 53846)
> >   >  +++ src/library/utils/R/Sweave.R    (working copy)
> >   >  @@ -20,6 +20,16 @@
> >   >    # We don't need srclines for code, but we do need it for text, and
> >   >  it's easiest
> >   >    # to just keep it for everything.
> >
> >   >  +SweaveGetDriver<- function(file){
> >   >  +    txt<- readLines(file)
> >   >  +    line<- grep( "\\SweaveDriver", txt, value = TRUE )
> >   >  +    if( length(line) ){
> >   >  +        txt<- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L] )
> >   >  +        driver<- try( eval( parse( text = txt ) ), silent = TRUE )
> >   >  +        if( !inherits( driver, "try-error") ) driver
> >   >  +    }
> >   >  +}
> >   >  +
> >   >    Sweave<- function(file, driver=RweaveLatex(),
> >   >                       syntax=getOption("SweaveSyntax"), ...)
> >   >    {
> >   >  @@ -28,7 +38,9 @@
> >   >        else if(is.function(driver))
> >   >            driver<- driver()
> >
> >   >  -
> >   >  +    drv<- SweaveGetDriver(file)
> >   >  +    if( !is.null(drv) ) driver<- drv
> >   >  +
> >   >        if(is.null(syntax))
> >   >            syntax<- SweaveGetSyntax(file)
> >   >        if(is.character(syntax))
> >
> >
> >
> >   >  This allows one to write something like this in their file:
> >
> >   >  %\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }
> >
> >   >  So that when calling :
> >
> >   >>  Sweave( "somefile.Rnw" )
> >
> >   >  the highlight driver is used instead of the default driver.
> >
> >   >  Could something like that be added to Sweave ?
> >
> >  Yes, sure!
> >
> >  Will have a look at the patch later this week and apply it if it
> >  passes the tests. The patch is against a current r-devel?
> >
> >  Best,
> >  Fritz
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From djsamperi at gmail.com  Tue Dec 14 16:52:49 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 14 Dec 2010 10:52:49 -0500
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <4D078C9F.90008@gmail.com>
References: <4D075794.3010201@r-enthusiasts.com>
	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
	<AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>
	<4D078C9F.90008@gmail.com>
Message-ID: <AANLkTimvKRz+xb-C473qB25-RoQEHDkGviygNZbNAaFo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101214/19ddcc8e/attachment.pl>

From jari.oksanen at oulu.fi  Tue Dec 14 16:59:23 2010
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 14 Dec 2010 17:59:23 +0200
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
Message-ID: <C92D60FB.142C5%jari.oksanen@oulu.fi>

Hello R Developers,

Dear R-developers, 

I ran some standard tests with currently (today morning) compiled R release
candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these tests used
plot.TukeyHSD function. This worked OK on the screen (X11 device), but
PostScript file could not be rendered. The following example had the problem
with me:

postscript(file="tukeyplot.ps")
example(plot.TukeyHSD)
dev.off()

I couldn't view the resulting file with evince in Linux nor in the standard
Preview in MacOS. When I compared the generated "tukeyplot.ps" to the same
file generated with an older R in my Mac, I found one difference:

$ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
--- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
+++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
@@ -172,5 +172,5 @@
 0 setgray
 0.00 setlinewidth
-[ 3.00 5.00] 0 setdash
+[ 0.00 0.00] 0 setdash
 np
 660.06 91.44 m

Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
fixed the problem both in Linux and in Mac. Evidently something has changed,
and probably somewhere else than in plot.TukeyHSD (which hasn't changed
since r51093 in trunk and never in R-2-12-branch). I know nothing about
PostScript so that I cannot say anything more (and I know viewers can fail
with standard conforming PostScript but it is a bit disconcerting that two
viewers fail when they worked earlier).

Cheers, Jari Oksanen


From murdoch.duncan at gmail.com  Tue Dec 14 17:13:44 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Dec 2010 11:13:44 -0500
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <AANLkTimvKRz+xb-C473qB25-RoQEHDkGviygNZbNAaFo@mail.gmail.com>
References: <4D075794.3010201@r-enthusiasts.com>	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>	<AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>	<4D078C9F.90008@gmail.com>
	<AANLkTimvKRz+xb-C473qB25-RoQEHDkGviygNZbNAaFo@mail.gmail.com>
Message-ID: <4D0797B8.6090009@gmail.com>

On 14/12/2010 10:52 AM, Dominick Samperi wrote:
> Both of my questions were not clear, sorry.
>
> What I really want to do is have a customized version of Sweave.sty
> (Sweave++.sty)
> included automatically from some designated area, like the include directory
> of another
> package, rather than requiring the user to keep a version in the local
> directory. Since
> the changes are minor, it might make more sense to solve this by
> incorporating
> them into Sweave.sty.

I don't know a way to refer to package directories from a Sweave 
document.   It might be possible to write an R function that writes out 
system-dependent \usepackage{} commands, and put that in a results=tex 
code chunk.  However, I'm not certain LaTeX can handle Windows paths in 
general (spaces and tildes both seem to cause problems, and I don't know 
a way to avoid both), so this might be impossible.

> On the temp directory, yes, I'm talking about Sweave's prefix option. Your
> suggestion
> to use dir.create() sounds like a reasonable work-around for the fact that
> TeX cannot perform OS-level functions.

The directory needs to be in place by the time you write out a figure or 
concordance from Sweave, so TeX can't be involved in creating it.

> Yet another small issue that I'm sure others have encountered is that
> TeX processing will fail under Linux when the source files contain DOS CR's,
> and
> the error diagnostics would leave you in the dark. The only fix that I could
> come up with is to remove the CR's manually using tr. Is there a better way?

I think it is most productive to think of the .tex output from Sweave as 
system-dependent object files, not portable source.  I'm pretty sure 
Sweave can read CR/LF files on any system and will write out local line 
endings.  So it's only a problem when you distribute the .tex output of 
Sweave, not when you distribute the .Rnw input.  (I understand there are 
circumstances where this is unavoidable, but you shouldn't be surprised 
when object files aren't portable.)

Duncan Murdoch

> Thanks,
> Dominick
>
> On Tue, Dec 14, 2010 at 10:26 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>wrote:
>
> >  On 14/12/2010 9:54 AM, Dominick Samperi wrote:
> >
> >>  Another question about Sweave (actually it is more a question
> >>  about TeX). Is there a reliable (system-independent) way to
> >>  use Sweave.sty without having to place it in the current working
> >>  directory? MiKTeX under Windows has dropped the use of
> >>  TEXINPUTS, and this complicates the problem.
> >>
> >
> >  If you run it from R, the right path will be put in place.  The
> >  tools::texi2dvi function does this.
> >
> >
> >   Furthermore, you cannot refer to Sweave.sty using its full path
> >>  as this would obviously not be system-independent.
> >>
> >>  Yet another small issue: If I configure Sweave to use a
> >>  temp directory for its temp files, and if this temp directory
> >>  does not exist, TeX fails with error diagnostics that is not
> >>  clear at all. Is there a way to have TeX automatically
> >>  create the directory if necessary?
> >>
> >
> >  I don't understand this one.  Are you talking about a "prefix=somedir/"
> >  option to Sweave?  That needs to be there before TeX is run.  I sometimes
> >  put a  dir.create("somedir", showWarnings=FALSE) call in an early chunk in
> >  the document to create it.
> >
> >  Duncan Murdoch
> >
> >   Thanks,
> >>  Dominick
> >>
> >>  On Tue, Dec 14, 2010 at 7:21 AM, Friedrich Leisch<
> >>  friedrich.leisch at stat.uni-muenchen.de>   wrote:
> >>
> >>  >   >>>>>   On Tue, 14 Dec 2010 12:40:04 +0100,
> >>  >   >>>>>   Romain Francois (RF) wrote:
> >>  >
> >>  >    >   Hello,
> >>  >    >   Sweave lets you use alternative drivers through the driver
> >>  argument, and
> >>  >    >   several packages take advantage of that and define custom Sweave
> >>  driver
> >>  >    >   for various purposes. Most of them are listed on the Reproducible
> >>  >    >   Research CTV:
> >>  >    >   (http://cran.r-project.org/web/views/ReproducibleResearch.html)
> >>  >
> >>  >    >   The next natural step is for package developpers to take advantage
> >>  of
> >>  >    >   this in their vignettes. In Rcpp we work around the way package
> >>  building
> >>  >    >   works and we do:
> >>  >    >   - let R build a dummy vignette
> >>  >    >   - then use the inst/doc/Makefile to replace it with a vignette that
> >>  is
> >>  >    >   processed by the driver from the highlight package (giving syntax
> >>  >    >   highlighting).
> >>  >
> >>  >    >   I played with Sweave so that it would be able to create the driver
> >>  from
> >>  >    >   some text included in the text of the .Rnw file:
> >>  >
> >>  >    >   $ svn diff
> >>  >    >   Index: src/library/utils/R/Sweave.R
> >>  >    >   ===================================================================
> >>  >    >   --- src/library/utils/R/Sweave.R    (revision 53846)
> >>  >    >   +++ src/library/utils/R/Sweave.R    (working copy)
> >>  >    >   @@ -20,6 +20,16 @@
> >>  >    >     # We don't need srclines for code, but we do need it for text,
> >>  and
> >>  >    >   it's easiest
> >>  >    >     # to just keep it for everything.
> >>  >
> >>  >    >   +SweaveGetDriver<- function(file){
> >>  >    >   +    txt<- readLines(file)
> >>  >    >   +    line<- grep( "\\SweaveDriver", txt, value = TRUE )
> >>  >    >   +    if( length(line) ){
> >>  >    >   +        txt<- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L]
> >>  )
> >>  >    >   +        driver<- try( eval( parse( text = txt ) ), silent = TRUE )
> >>  >    >   +        if( !inherits( driver, "try-error") ) driver
> >>  >    >   +    }
> >>  >    >   +}
> >>  >    >   +
> >>  >    >     Sweave<- function(file, driver=RweaveLatex(),
> >>  >    >                        syntax=getOption("SweaveSyntax"), ...)
> >>  >    >     {
> >>  >    >   @@ -28,7 +38,9 @@
> >>  >    >         else if(is.function(driver))
> >>  >    >             driver<- driver()
> >>  >
> >>  >    >   -
> >>  >    >   +    drv<- SweaveGetDriver(file)
> >>  >    >   +    if( !is.null(drv) ) driver<- drv
> >>  >    >   +
> >>  >    >         if(is.null(syntax))
> >>  >    >             syntax<- SweaveGetSyntax(file)
> >>  >    >         if(is.character(syntax))
> >>  >
> >>  >
> >>  >
> >>  >    >   This allows one to write something like this in their file:
> >>  >
> >>  >    >   %\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }
> >>  >
> >>  >    >   So that when calling :
> >>  >
> >>  >    >>   Sweave( "somefile.Rnw" )
> >>  >
> >>  >    >   the highlight driver is used instead of the default driver.
> >>  >
> >>  >    >   Could something like that be added to Sweave ?
> >>  >
> >>  >   Yes, sure!
> >>  >
> >>  >   Will have a look at the patch later this week and apply it if it
> >>  >   passes the tests. The patch is against a current r-devel?
> >>  >
> >>  >   Best,
> >>  >   Fritz
> >>  >
> >>  >   ______________________________________________
> >>  >   R-devel at r-project.org mailing list
> >>  >   https://stat.ethz.ch/mailman/listinfo/r-devel
> >>  >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
>


From bbolker at gmail.com  Tue Dec 14 18:27:43 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Dec 2010 17:27:43 +0000 (UTC)
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
References: <C92D60FB.142C5%jari.oksanen@oulu.fi>
Message-ID: <loom.20101214T174819-887@post.gmane.org>

Jari Oksanen <jari.oksanen <at> oulu.fi> writes:

> 
> Hello R Developers,
> 
> Dear R-developers, 
> 
> I ran some standard tests with currently (today morning) compiled R release
> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these tests used
> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
> PostScript file could not be rendered. The following example had the problem
> with me:
> 
> postscript(file="tukeyplot.ps")
> example(plot.TukeyHSD)
> dev.off()
> 
> I couldn't view the resulting file with evince in Linux nor in the standard
> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the same
> file generated with an older R in my Mac, I found one difference:
> 
> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
> @@ -172,5 +172,5 @@
>  0 setgray
>  0.00 setlinewidth
> -[ 3.00 5.00] 0 setdash
> +[ 0.00 0.00] 0 setdash
>  np
>  660.06 91.44 m
> 
> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
> fixed the problem both in Linux and in Mac. Evidently something has changed,
> and probably somewhere else than in plot.TukeyHSD (which hasn't changed
> since r51093 in trunk and never in R-2-12-branch). I know nothing about
> PostScript so that I cannot say anything more (and I know viewers can fail
> with standard conforming PostScript but it is a bit disconcerting that two
> viewers fail when they worked earlier).

  I must really be avoiding work today ...

  I can diagnose this (I think) but don't know the best way to 
solve it.

  At this point, line widths on PDF devices were allowed to be <1.

==========
r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1 line
Changed paths:
   M /trunk/NEWS
   M /trunk/src/library/grDevices/src/devPS.c

allow lwd less than 1 on PDF device
==========

  The behavior of PDF devices (by experiment) is to draw a 0-width
line as 1 pixel wide, at whatever resolution is currently being
rendered.  On the other hand, 0-width lines appear to break PostScript.
(with the Linux viewer 'evince' I get warnings about "rangecheck -15"
when trying to view such a file).

  plot.TukeyHSD  contains the lines

abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
abline(v = 0, lty = 2, lwd = 0, ...)

  which are presumably meant to render minimum-width lines.

  I don't know whether it makes more sense to (1) change plot.TukeyHSD
to use positive widths (although that may not help: I tried setting
lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
(2) change the postscript driver to *not* allow line widths < 1 (i.e.,
distinguish between PS and PDF and revert to the pre-r52180 behaviour
for PS only).  

  On reflection #2 seems to make more sense, but digging through devPS.c
it's not immediately obvious to me where/how in SetLineStyle or
PostScriptSetLineTexture one can tell whether the current driver
is PS or PDF ...


From djsamperi at gmail.com  Tue Dec 14 18:28:52 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 14 Dec 2010 12:28:52 -0500
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <4D0797B8.6090009@gmail.com>
References: <4D075794.3010201@r-enthusiasts.com>
	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
	<AANLkTik=2RZ51R6msUidj2hLJyboZc8g1HiLiaeo6+kB@mail.gmail.com>
	<4D078C9F.90008@gmail.com>
	<AANLkTimvKRz+xb-C473qB25-RoQEHDkGviygNZbNAaFo@mail.gmail.com>
	<4D0797B8.6090009@gmail.com>
Message-ID: <AANLkTikzp7dykt9=jLKHXaTOmP3yyiTEJ_dUxLg+mFHX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101214/5cd5b48e/attachment.pl>

From ehlers at ucalgary.ca  Tue Dec 14 19:16:12 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Tue, 14 Dec 2010 10:16:12 -0800
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <loom.20101214T174819-887@post.gmane.org>
References: <C92D60FB.142C5%jari.oksanen@oulu.fi>
	<loom.20101214T174819-887@post.gmane.org>
Message-ID: <4D07B46C.8030808@ucalgary.ca>

On 2010-12-14 09:27, Ben Bolker wrote:
> Jari Oksanen<jari.oksanen<at>  oulu.fi>  writes:
>
>>
>> Hello R Developers,
>>
>> Dear R-developers,
>>
>> I ran some standard tests with currently (today morning) compiled R release
>> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these tests used
>> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
>> PostScript file could not be rendered. The following example had the problem
>> with me:
>>
>> postscript(file="tukeyplot.ps")
>> example(plot.TukeyHSD)
>> dev.off()
>>
>> I couldn't view the resulting file with evince in Linux nor in the standard
>> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the same
>> file generated with an older R in my Mac, I found one difference:
>>
>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>> @@ -172,5 +172,5 @@
>>   0 setgray
>>   0.00 setlinewidth
>> -[ 3.00 5.00] 0 setdash
>> +[ 0.00 0.00] 0 setdash
>>   np
>>   660.06 91.44 m
>>
>> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
>> fixed the problem both in Linux and in Mac. Evidently something has changed,
>> and probably somewhere else than in plot.TukeyHSD (which hasn't changed
>> since r51093 in trunk and never in R-2-12-branch). I know nothing about
>> PostScript so that I cannot say anything more (and I know viewers can fail
>> with standard conforming PostScript but it is a bit disconcerting that two
>> viewers fail when they worked earlier).
>
>    I must really be avoiding work today ...
>
>    I can diagnose this (I think) but don't know the best way to
> solve it.
>
>    At this point, line widths on PDF devices were allowed to be<1.
>
> ==========
> r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1 line
> Changed paths:
>     M /trunk/NEWS
>     M /trunk/src/library/grDevices/src/devPS.c
>
> allow lwd less than 1 on PDF device
> ==========
>
>    The behavior of PDF devices (by experiment) is to draw a 0-width
> line as 1 pixel wide, at whatever resolution is currently being
> rendered.  On the other hand, 0-width lines appear to break PostScript.
> (with the Linux viewer 'evince' I get warnings about "rangecheck -15"
> when trying to view such a file).
>
>    plot.TukeyHSD  contains the lines
>
> abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
> abline(v = 0, lty = 2, lwd = 0, ...)
>
>    which are presumably meant to render minimum-width lines.
>
>    I don't know whether it makes more sense to (1) change plot.TukeyHSD
> to use positive widths (although that may not help: I tried setting
> lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
> (2) change the postscript driver to *not* allow line widths<  1 (i.e.,
> distinguish between PS and PDF and revert to the pre-r52180 behaviour
> for PS only).
>
>    On reflection #2 seems to make more sense, but digging through devPS.c
> it's not immediately obvious to me where/how in SetLineStyle or
> PostScriptSetLineTexture one can tell whether the current driver
> is PS or PDF ...
>
That may not do it. I find the same problem (fixed by
Jari's replacement of [ 0.00 0.00] with [ 3.00 5.00];
haven't tried anything else yet) when I use pdf()
instead of postscript().
This is on Vista.

Peter Ehlers


From bbolker at gmail.com  Tue Dec 14 19:20:24 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Dec 2010 13:20:24 -0500
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <4D07B46C.8030808@ucalgary.ca>
References: <C92D60FB.142C5%jari.oksanen@oulu.fi>
	<loom.20101214T174819-887@post.gmane.org>
	<4D07B46C.8030808@ucalgary.ca>
Message-ID: <4D07B568.6000505@gmail.com>

On 10-12-14 01:16 PM, Peter Ehlers wrote:
> On 2010-12-14 09:27, Ben Bolker wrote:
>> Jari Oksanen<jari.oksanen<at>  oulu.fi>  writes:
>>
>>>
>>> Hello R Developers,
>>>
>>> Dear R-developers,
>>>
>>> I ran some standard tests with currently (today morning) compiled R
>>> release
>>> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these
>>> tests used
>>> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
>>> PostScript file could not be rendered. The following example had the
>>> problem
>>> with me:
>>>
>>> postscript(file="tukeyplot.ps")
>>> example(plot.TukeyHSD)
>>> dev.off()
>>>
>>> I couldn't view the resulting file with evince in Linux nor in the
>>> standard
>>> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the
>>> same
>>> file generated with an older R in my Mac, I found one difference:
>>>
>>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>>> @@ -172,5 +172,5 @@
>>>   0 setgray
>>>   0.00 setlinewidth
>>> -[ 3.00 5.00] 0 setdash
>>> +[ 0.00 0.00] 0 setdash
>>>   np
>>>   660.06 91.44 m
>>>
>>> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
>>> fixed the problem both in Linux and in Mac. Evidently something has
>>> changed,
>>> and probably somewhere else than in plot.TukeyHSD (which hasn't changed
>>> since r51093 in trunk and never in R-2-12-branch). I know nothing about
>>> PostScript so that I cannot say anything more (and I know viewers can
>>> fail
>>> with standard conforming PostScript but it is a bit disconcerting
>>> that two
>>> viewers fail when they worked earlier).
>>
>>    I must really be avoiding work today ...
>>
>>    I can diagnose this (I think) but don't know the best way to
>> solve it.
>>
>>    At this point, line widths on PDF devices were allowed to be<1.
>>
>> ==========
>> r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1 line
>> Changed paths:
>>     M /trunk/NEWS
>>     M /trunk/src/library/grDevices/src/devPS.c
>>
>> allow lwd less than 1 on PDF device
>> ==========
>>
>>    The behavior of PDF devices (by experiment) is to draw a 0-width
>> line as 1 pixel wide, at whatever resolution is currently being
>> rendered.  On the other hand, 0-width lines appear to break PostScript.
>> (with the Linux viewer 'evince' I get warnings about "rangecheck -15"
>> when trying to view such a file).
>>
>>    plot.TukeyHSD  contains the lines
>>
>> abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
>> abline(v = 0, lty = 2, lwd = 0, ...)
>>
>>    which are presumably meant to render minimum-width lines.
>>
>>    I don't know whether it makes more sense to (1) change plot.TukeyHSD
>> to use positive widths (although that may not help: I tried setting
>> lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
>> (2) change the postscript driver to *not* allow line widths<  1 (i.e.,
>> distinguish between PS and PDF and revert to the pre-r52180 behaviour
>> for PS only).
>>
>>    On reflection #2 seems to make more sense, but digging through devPS.c
>> it's not immediately obvious to me where/how in SetLineStyle or
>> PostScriptSetLineTexture one can tell whether the current driver
>> is PS or PDF ...
>>
> That may not do it. I find the same problem (fixed by
> Jari's replacement of [ 0.00 0.00] with [ 3.00 5.00];
> haven't tried anything else yet) when I use pdf()
> instead of postscript().
> This is on Vista.
> 
> Peter Ehlers

  With PDF, I get "invalid value for a dash setting" from evince --
perhaps the dash lengths are being set relative to the line width?
(Could investigate but had better continue with other things ...)

  Ben Bolker


From xie at yihui.name  Tue Dec 14 22:17:54 2010
From: xie at yihui.name (Yihui Xie)
Date: Tue, 14 Dec 2010 15:17:54 -0600
Subject: [Rd] redesign R.css for HTML help pages
Message-ID: <AANLkTikZrucJ5d=rQyts2q-RnfVOePn6dJbaYx_ThVCZ@mail.gmail.com>

Hi,

I feel the CSS definitions for the HTML help pages are not visually
appealing enough. I admit this is a very subjective matter, so I don't
have strong arguments for this wishlist, although I wrote my version
of R.css with some web design instructions in mind (e.g. use
browser-safe sans-serif fonts).

Anyway, here is what I've done:
https://github.com/yihui/configuration/raw/master/R.css

This CSS file is under file.path(R.home('doc'), 'html') after installation.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From mtalbert at usgs.gov  Tue Dec 14 21:25:58 2010
From: mtalbert at usgs.gov (Marian K Talbert)
Date: Tue, 14 Dec 2010 13:25:58 -0700
Subject: [Rd] How to specify compiler options when using R CMD SHLIB
Message-ID: <OFB3963020.794B5282-ON872577F9.006FE2D3-872577F9.00703E23@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101214/168a3b88/attachment.pl>

From edd at debian.org  Tue Dec 14 23:00:12 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Dec 2010 16:00:12 -0600
Subject: [Rd] How to specify compiler options when using R CMD SHLIB
In-Reply-To: <OFB3963020.794B5282-ON872577F9.006FE2D3-872577F9.00703E23@usgs.gov>
References: <OFB3963020.794B5282-ON872577F9.006FE2D3-872577F9.00703E23@usgs.gov>
Message-ID: <19719.59628.328369.100289@max.nulle.part>


On 14 December 2010 at 13:25, Marian K Talbert wrote:
| Hi
| 
| I've built a dll using Fortran code and can call it by either R or 
| Fortran. Calling by the former gives me the wrong answer and the later
| gives the correct answer.
| 
| >From what I've read, it looks like I should use the subroutines DBLEPR, 
| INTPR and REALPR to print to the R console rather than using Fortran 
| standard I/O and that if I use the command 
| R CMD SHLIB source.f that these subroutines will automatically be found 
| (Please correct me if I'm wrong about any of this). The problem is that I 
| have to specify the gfortran compiler option -fno-range-check in order for 
| my code to compile. I've tried setting PKG_FCFLAGS=-fno-range-check in a 
| file named Makevars under the same directory as my Fortran files but this 
| doesn't seem to be the right place because R CMD SHLIB still produces 
| error messages related to integer overflow (the same error as when I run 
| gfortran -c MRPP.f90 as opposed to gfortran -c MRPP.f90 -fno-range-check) 
| when I type
| 
| R CMD SHLIB MRPP.f90. 
| 
| So I was wondering if anyone could tell me how compiler option should be 
| specified when using R CMD SHLIB?

I use 

  ~/.R/Makevars 

where you can set all variables your in in 

  $RHOME/etc/Makeconf

Setting the as environment variables will also work by virtue of make (and
that is what the inline package does).

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From fabio.ufla at yahoo.com.br  Wed Dec 15 03:30:18 2010
From: fabio.ufla at yahoo.com.br (=?utf-8?B?RmFiaW8gTWF0aGlhcyBDb3Jyw6ph?=)
Date: Tue, 14 Dec 2010 18:30:18 -0800 (PST)
Subject: [Rd] Namespace File
Message-ID: <592815.53322.qm@web59709.mail.ac4.yahoo.com>

Dear Colleagues,

I am developing a library. However I am having the following problem with the 
file NAMESPACE.

My file contains:

useDynLib(Bayesthres, vuA)

export(Bayesthres, 
    random.effects, 
    fixed.effects,
    )

exportClasses("Bayesthres")

 


My function is:


Avuall <- function(Zz, Dd, A, Vu, FL)
  {
    m <- dim(A)[1]
    n <- dim(A)[2]
    tc <- length(Vu)
    ifc <- unlist(lapply(FL$fl, function(x) length(levels(x))))
    il <-  1
    ic <- ifc[1]
    for(i in 2:tc){
      ic[i] <- ifc[i]+ic[i-1]
      il[i] <- ic[i]-ifc[i]+1
    }
    storage.mode(A) <- "double"
    Aux <- .Fortran("vuA", as.double(Vu), A=A, as.integer(ic), as.integer(il), 
as.integer(m), 

    as.integer(n), as.integer(tc), PACKAGE="Bayesthres")$A
    V <- rbind(Zz, cbind(Dd,Aux))
    return(V)
  }


The vuA file was written in Fortran95. It's within the src directory.

However the following error appears in R CMD check

Error in .Fortran("vuA", as.double(Vu), A = A, as.integer(ic), as.integer(il),  
: 

name simbol in Fortran "vua" not is in DLL library "Bayesthres"
Error : unable to load R code in package 'Bayesthres'
ERROR: lazy loading failed for package ?Bayesthres?

Where can I be wrong?

Thank you very much!


              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz





From allane at cybaea.com  Wed Dec 15 09:35:02 2010
From: allane at cybaea.com (Allan Engelhardt)
Date: Wed, 15 Dec 2010 08:35:02 +0000
Subject: [Rd] Consistency of variable storage in R and Sys.setlocale (is
 this a feature or bug)?
In-Reply-To: <AANLkTin7Jipu=bHu56T79yHj0y_rE3t=aR+JqA+GzVHY@mail.gmail.com>
References: <AANLkTin7Jipu=bHu56T79yHj0y_rE3t=aR+JqA+GzVHY@mail.gmail.com>
Message-ID: <4D087DB6.60602@cybaea.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101215/d674dd15/attachment.pl>

From dieter.menne at menne-biomed.de  Wed Dec 15 09:37:39 2010
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 15 Dec 2010 00:37:39 -0800 (PST)
Subject: [Rd] redesign R.css for HTML help pages
In-Reply-To: <AANLkTikZrucJ5d=rQyts2q-RnfVOePn6dJbaYx_ThVCZ@mail.gmail.com>
References: <AANLkTikZrucJ5d=rQyts2q-RnfVOePn6dJbaYx_ThVCZ@mail.gmail.com>
Message-ID: <1292402259047-3088588.post@n4.nabble.com>



Yihui Xie-2 wrote:
> 
> 
> I feel the CSS definitions for the HTML help pages are not visually
> appealing enough.
> 
> .....
> 

The whole system needs an overhaul.

https://github.com/hadley/helpr

Looks quite good, but search engine not yet portable.

Dieter


-- 
View this message in context: http://r.789695.n4.nabble.com/redesign-R-css-for-HTML-help-pages-tp3088024p3088588.html
Sent from the R devel mailing list archive at Nabble.com.


From fabio.ufla at yahoo.com.br  Wed Dec 15 12:57:01 2010
From: fabio.ufla at yahoo.com.br (=?iso-8859-1?Q?Fabio_Mathias_Corr=EAa?=)
Date: Wed, 15 Dec 2010 03:57:01 -0800 (PST)
Subject: [Rd] Namespace File
Message-ID: <362962.42310.qm@web59712.mail.ac4.yahoo.com>

Dear colleagues,


Problem solved with:


".First.lib" <- function(lib, pkg)
{
  library.dynam("Bayesthres", package = pkg, lib.loc = lib)
  return(invisible(0))
}





 
              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz





From simon.urbanek at r-project.org  Wed Dec 15 16:41:34 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 15 Dec 2010 10:41:34 -0500
Subject: [Rd] Namespace File
In-Reply-To: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
Message-ID: <80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>


On Dec 15, 2010, at 6:57 AM, Fabio Mathias Corr?a wrote:

> Dear colleagues,
> 
> 
> Problem solved with:
> 
> 
> ".First.lib" <- function(lib, pkg)
> {
>  library.dynam("Bayesthres", package = pkg, lib.loc = lib)
>  return(invisible(0))
> }
> 

Well, that's shooting at a clay pigeon with a missile ;). You could have done the same simply using
useDynLib(Bayesthres)
in the NAMESPACE.

Your issue is very likely just a mixup of cases as there is no "vuA" symbol in Fortran as all symbols are lower-case (at the object file level).

Cheers,
Simon


From fabio.ufla at yahoo.com.br  Wed Dec 15 19:31:45 2010
From: fabio.ufla at yahoo.com.br (=?utf-8?B?RmFiaW8gTWF0aGlhcyBDb3Jyw6ph?=)
Date: Wed, 15 Dec 2010 10:31:45 -0800 (PST)
Subject: [Rd]  Namespace File
In-Reply-To: <80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
Message-ID: <970548.83885.qm@web59712.mail.ac4.yahoo.com>

Dear Simon

By using useDynLib (Bayesthres) in NAMESPACE file. Appeared another error:

Error in dyn.load("Bayesthres.so") : 
  unable to load shared object '/home/fmc/Bayesthres/Bayesthres.so':
  /home/fmc/Bayesthres/Bayesthres.so: cannot open shared object file: No such 
file or directory
ERROR: lazy loading failed for package ?Bayesthres?
* removing ?/home/fmc/Bayesthres.Rcheck/Bayesthres?

 
Now he is not recognizing the file Bayesthres.so

Grateful for the help.



              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz




----- Mensagem original ----
De: Simon Urbanek <simon.urbanek at r-project.org>
Para: Fabio Mathias Corr?a <fabio.ufla at yahoo.com.br>
Cc: r-devel at r-project.org
Enviadas: Quarta-feira, 15 de Dezembro de 2010 13:41:34
Assunto: Re: [Rd] Namespace File


On Dec 15, 2010, at 6:57 AM, Fabio Mathias Corr?a wrote:

> Dear colleagues,
> 
> 
> Problem solved with:
> 
> 
> ".First.lib" <- function(lib, pkg)
> {
>  library.dynam("Bayesthres", package = pkg, lib.loc = lib)
>  return(invisible(0))
> }
> 

Well, that's shooting at a clay pigeon with a missile ;). You could have done 
the same simply using
useDynLib(Bayesthres)
in the NAMESPACE.

Your issue is very likely just a mixup of cases as there is no "vuA" symbol in 
Fortran as all symbols are lower-case (at the object file level).

Cheers,
Simon


 

From simon.urbanek at r-project.org  Wed Dec 15 19:42:34 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 15 Dec 2010 13:42:34 -0500
Subject: [Rd] Namespace File
In-Reply-To: <970548.83885.qm@web59712.mail.ac4.yahoo.com>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
Message-ID: <FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>


On Dec 15, 2010, at 1:31 PM, Fabio Mathias Corr?a wrote:

> Dear Simon
> 
> By using useDynLib (Bayesthres) in NAMESPACE file. Appeared another error:
> 
> Error in dyn.load("Bayesthres.so") : 
>  unable to load shared object '/home/fmc/Bayesthres/Bayesthres.so':
>  /home/fmc/Bayesthres/Bayesthres.so: cannot open shared object file: No such 
> file or directory
> ERROR: lazy loading failed for package ?Bayesthres?
> * removing ?/home/fmc/Bayesthres.Rcheck/Bayesthres?
> 
> 


... but that's an entirely wrong place - I suspect you have some real issues in the way your package is constructed. Are you sure you have the correct layout and are using the *packaged* sources and not your working tree? (You didn't tell us anything about the package so there are many things that may be wrong - also you omitted the most basic details such as R version and platform...)

Cheers,
Simon


> Now he is not recognizing the file Bayesthres.so
> 
> Grateful for the help.
> 
> 
> 
>              F?bio Mathias Corr?a
>         Departamento de Estat?stica
>   Universidade Estadual de Santa Cruz
> 
> 
> 
> 
> ----- Mensagem original ----
> De: Simon Urbanek <simon.urbanek at r-project.org>
> Para: Fabio Mathias Corr?a <fabio.ufla at yahoo.com.br>
> Cc: r-devel at r-project.org
> Enviadas: Quarta-feira, 15 de Dezembro de 2010 13:41:34
> Assunto: Re: [Rd] Namespace File
> 
> 
> On Dec 15, 2010, at 6:57 AM, Fabio Mathias Corr?a wrote:
> 
>> Dear colleagues,
>> 
>> 
>> Problem solved with:
>> 
>> 
>> ".First.lib" <- function(lib, pkg)
>> {
>> library.dynam("Bayesthres", package = pkg, lib.loc = lib)
>> return(invisible(0))
>> }
>> 
> 
> Well, that's shooting at a clay pigeon with a missile ;). You could have done 
> the same simply using
> useDynLib(Bayesthres)
> in the NAMESPACE.
> 
> Your issue is very likely just a mixup of cases as there is no "vuA" symbol in 
> Fortran as all symbols are lower-case (at the object file level).
> 
> Cheers,
> Simon
> 
> 
> 
> 
> 


From fabio.ufla at yahoo.com.br  Wed Dec 15 19:56:11 2010
From: fabio.ufla at yahoo.com.br (=?iso-8859-1?Q?Fabio_Mathias_Corr=EAa?=)
Date: Wed, 15 Dec 2010 10:56:11 -0800 (PST)
Subject: [Rd]  Namespace File
In-Reply-To: <FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
	<FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
Message-ID: <55476.99277.qm@web59712.mail.ac4.yahoo.com>

Dear,

I am using Ubuntu linux and R2.12.0
The trial version is in my home.

\home\Bayesthres~$

To perform the R CMD check

\home~$ R CMD check Bayesthres

Within the directory Bayesthres, have:

Directories: inst, man, R and src

Files: DESCRIPTION AND NAMESPACE

Best wishes

F?bio




... but that's an entirely wrong place - I suspect you have some real issues in 
the way your package is constructed. Are you sure you have the correct layout 
and are using the *packaged* sources and not your working tree? (You didn't tell 
us anything about the package so there are many things that may be wrong - also 
you omitted the most basic details such as R version and platform...)

Cheers,
Simon


 
              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz





From simon.urbanek at r-project.org  Wed Dec 15 20:10:21 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 15 Dec 2010 14:10:21 -0500
Subject: [Rd] Namespace File
In-Reply-To: <55476.99277.qm@web59712.mail.ac4.yahoo.com>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
	<FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
	<55476.99277.qm@web59712.mail.ac4.yahoo.com>
Message-ID: <2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>


On Dec 15, 2010, at 1:56 PM, Fabio Mathias Corr?a wrote:

> Dear,
> 
> I am using Ubuntu linux and R2.12.0
> The trial version is in my home.
> 
> \home\Bayesthres~$
> 
> To perform the R CMD check
> 
> \home~$ R CMD check Bayesthres
> 

That is in general not a good idea, especially if you ever run things inside by hand for testing (because that will pollute the build). Make sure you clean your tree and use R CMD build followed by R CMD check on the resulting tar ball. Does the issue persist?


> Within the directory Bayesthres, have:
> 
> Directories: inst, man, R and src
> 

What is in inst? Make sure you have no binaries there.

Cheers,
Simon


> 
> ... but that's an entirely wrong place - I suspect you have some real issues in 
> the way your package is constructed. Are you sure you have the correct layout 
> and are using the *packaged* sources and not your working tree? (You didn't tell 
> us anything about the package so there are many things that may be wrong - also 
> you omitted the most basic details such as R version and platform...)
> 
> Cheers,
> Simon
> 
> 
> 
>              F?bio Mathias Corr?a
>         Departamento de Estat?stica
>   Universidade Estadual de Santa Cruz
> 
> 
> 
> 
> 


From fabio.ufla at yahoo.com.br  Wed Dec 15 21:24:03 2010
From: fabio.ufla at yahoo.com.br (=?iso-8859-1?Q?Fabio_Mathias_Corr=EAa?=)
Date: Wed, 15 Dec 2010 12:24:03 -0800 (PST)
Subject: [Rd]  Namespace File
In-Reply-To: <2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
	<FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
	<55476.99277.qm@web59712.mail.ac4.yahoo.com>
	<2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>
Message-ID: <94265.94375.qm@web59706.mail.ac4.yahoo.com>

 The inst has CITATION only.

Best wishes



              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz





What is in inst? Make sure you have no binaries there.

Cheers,
Simon


> 
> 
>              F?bio Mathias Corr?a
>         Departamento de Estat?stica
>   Universidade Estadual de Santa Cruz
> 
> 
> 
> 
> 


    

From fabio.ufla at yahoo.com.br  Wed Dec 15 21:34:50 2010
From: fabio.ufla at yahoo.com.br (=?utf-8?B?RmFiaW8gTWF0aGlhcyBDb3Jyw6ph?=)
Date: Wed, 15 Dec 2010 12:34:50 -0800 (PST)
Subject: [Rd]  Namespace File
In-Reply-To: <2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
	<FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
	<55476.99277.qm@web59712.mail.ac4.yahoo.com>
	<2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>
Message-ID: <386784.94946.qm@web59704.mail.ac4.yahoo.com>

See the complete log

fmc at raquel-laptop ~ $ R CMD check Bayesthres
* using log directory ?/home/fmc/Bayesthres.Rcheck?
* using R version 2.12.0 (2010-10-15)
* using platform: i486-pc-linux-gnu (32-bit)
* using session charset: UTF-8
* checking for file ?Bayesthres/DESCRIPTION? ... OK
* this is package ?Bayesthres? version ?0.1-0?
* checking package dependencies ... OK
* checking if this is a source package ... WARNING
Subdirectory ?Bayesthres/src? contains object files.
* checking for executable files ... OK
* checking whether package ?Bayesthres? can be installed ... ERROR
Installation failed.
See ?/home/fmc/Bayesthres.Rcheck/00install.out? for details.


File 00install.out

Error in dyn.load("Bayesthres.so") : 
  unable to load shared object '/home/fmc/Bayesthres/Bayesthres.so':
  /home/fmc/Bayesthres/Bayesthres.so: cannot open shared object file: No such 
file or directory
ERROR: lazy loading failed for package ?Bayesthres?
* removing ?/home/fmc/Bayesthres.Rcheck/Bayesthres?

Best wishes



 
              F?bio Mathias Corr?a
         Departamento de Estat?stica
   Universidade Estadual de Santa Cruz




----- Mensagem original ----
De: Simon Urbanek <simon.urbanek at r-project.org>
Para: Fabio Mathias Corr?a <fabio.ufla at yahoo.com.br>
Cc: R-devel <r-devel at r-project.org>
Enviadas: Quarta-feira, 15 de Dezembro de 2010 17:10:21
Assunto: Re: [Rd] Namespace File


On Dec 15, 2010, at 1:56 PM, Fabio Mathias Corr?a wrote:

> Dear,
> 
> I am using Ubuntu linux and R2.12.0
> The trial version is in my home.
> 
> \home\Bayesthres~$
> 
> To perform the R CMD check
> 
> \home~$ R CMD check Bayesthres
> 

That is in general not a good idea, especially if you ever run things inside by 
hand for testing (because that will pollute the build). Make sure you clean your 
tree and use R CMD build followed by R CMD check on the resulting tar ball. Does 
the issue persist?


> Within the directory Bayesthres, have:
> 
> Directories: inst, man, R and src
> 

What is in inst? Make sure you have no binaries there.

Cheers,
Simon


> 
> ... but that's an entirely wrong place - I suspect you have some real issues in 
>
> the way your package is constructed. Are you sure you have the correct layout 
> and are using the *packaged* sources and not your working tree? (You didn't 
>tell 
>
> us anything about the package so there are many things that may be wrong - also 
>
> you omitted the most basic details such as R version and platform...)
> 
> Cheers,
> Simon
> 
> 
> 
>              F?bio Mathias Corr?a
>         Departamento de Estat?stica
>   Universidade Estadual de Santa Cruz
> 
> 
> 
> 
> 





From simon.urbanek at r-project.org  Wed Dec 15 21:57:22 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 15 Dec 2010 15:57:22 -0500
Subject: [Rd] Namespace File
In-Reply-To: <386784.94946.qm@web59704.mail.ac4.yahoo.com>
References: <362962.42310.qm@web59712.mail.ac4.yahoo.com>
	<80693E0D-7A0C-4678-B714-314421FFEC32@r-project.org>
	<970548.83885.qm@web59712.mail.ac4.yahoo.com>
	<FBEFE8CB-40B0-4AAC-B9ED-D7837297C975@r-project.org>
	<55476.99277.qm@web59712.mail.ac4.yahoo.com>
	<2BCFE4FC-C71E-4912-A71A-2F894684F5D8@r-project.org>
	<386784.94946.qm@web59704.mail.ac4.yahoo.com>
Message-ID: <83093245-2C5C-42B0-9374-339F46107992@r-project.org>

Fabio,

you must have
dyn.load("Bayesthres.so")
somewhere in your R code according to your output - that is wrong and have to remove it as that will happen automatically via NAMESPACE.
Also, please, do read what I wrote in the last e-mail - you're still running it on your working copy.

Cheers,
Simon

BTW: in order to avoid us having to guess what you did wrong it would be much easier if you simply put the package somewhere so we can check it - that would save us and you quite a bit of time.


On Dec 15, 2010, at 3:34 PM, Fabio Mathias Corr?a wrote:

> See the complete log
> 
> fmc at raquel-laptop ~ $ R CMD check Bayesthres
> * using log directory ?/home/fmc/Bayesthres.Rcheck?
> * using R version 2.12.0 (2010-10-15)
> * using platform: i486-pc-linux-gnu (32-bit)
> * using session charset: UTF-8
> * checking for file ?Bayesthres/DESCRIPTION? ... OK
> * this is package ?Bayesthres? version ?0.1-0?
> * checking package dependencies ... OK
> * checking if this is a source package ... WARNING
> Subdirectory ?Bayesthres/src? contains object files.
> * checking for executable files ... OK
> * checking whether package ?Bayesthres? can be installed ... ERROR
> Installation failed.
> See ?/home/fmc/Bayesthres.Rcheck/00install.out? for details.
> 
> 
> File 00install.out
> 
> Error in dyn.load("Bayesthres.so") : 
>  unable to load shared object '/home/fmc/Bayesthres/Bayesthres.so':
>  /home/fmc/Bayesthres/Bayesthres.so: cannot open shared object file: No such 
> file or directory
> ERROR: lazy loading failed for package ?Bayesthres?
> * removing ?/home/fmc/Bayesthres.Rcheck/Bayesthres?
> 
> Best wishes
> 
> 
> 
> 
>              F?bio Mathias Corr?a
>         Departamento de Estat?stica
>   Universidade Estadual de Santa Cruz
> 
> 
> 
> 
> ----- Mensagem original ----
> De: Simon Urbanek <simon.urbanek at r-project.org>
> Para: Fabio Mathias Corr?a <fabio.ufla at yahoo.com.br>
> Cc: R-devel <r-devel at r-project.org>
> Enviadas: Quarta-feira, 15 de Dezembro de 2010 17:10:21
> Assunto: Re: [Rd] Namespace File
> 
> 
> On Dec 15, 2010, at 1:56 PM, Fabio Mathias Corr?a wrote:
> 
>> Dear,
>> 
>> I am using Ubuntu linux and R2.12.0
>> The trial version is in my home.
>> 
>> \home\Bayesthres~$
>> 
>> To perform the R CMD check
>> 
>> \home~$ R CMD check Bayesthres
>> 
> 
> That is in general not a good idea, especially if you ever run things inside by 
> hand for testing (because that will pollute the build). Make sure you clean your 
> tree and use R CMD build followed by R CMD check on the resulting tar ball. Does 
> the issue persist?
> 
> 
>> Within the directory Bayesthres, have:
>> 
>> Directories: inst, man, R and src
>> 
> 
> What is in inst? Make sure you have no binaries there.
> 
> Cheers,
> Simon
> 
> 
>> 
>> ... but that's an entirely wrong place - I suspect you have some real issues in 
>> 
>> the way your package is constructed. Are you sure you have the correct layout 
>> and are using the *packaged* sources and not your working tree? (You didn't 
>> tell 
>> 
>> us anything about the package so there are many things that may be wrong - also 
>> 
>> you omitted the most basic details such as R version and platform...)
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>             F?bio Mathias Corr?a
>>        Departamento de Estat?stica
>>  Universidade Estadual de Santa Cruz
>> 
>> 
>> 
>> 
>> 
> 
> 
> 
> 
> 


From p.murrell at auckland.ac.nz  Thu Dec 16 03:24:47 2010
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 16 Dec 2010 15:24:47 +1300
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <4D07B568.6000505@gmail.com>
References: <C92D60FB.142C5%jari.oksanen@oulu.fi>	<loom.20101214T174819-887@post.gmane.org>	<4D07B46C.8030808@ucalgary.ca>
	<4D07B568.6000505@gmail.com>
Message-ID: <4D09786F.9020103@auckland.ac.nz>

Hi

According to the PostScript Language Reference Manual and the PDF 
Reference, in both PDF and PostScript ...

... a line width of zero is valid, but not recommended (and is clearly 
not supported by some viewers).

... a line dash pattern cannot be specified as all zero lengths.
(So, because R generates the line dash pattern proportional to the line 
width, a specification of lwd=0 and 
lty=anything-other-than-"solid"-or-"none" does not make sense.)

I think three fixes are required:

(i)  Enforce a minimum line width of 0.01 (mainly because that is not 
zero, but also because that is the smallest value greater than zero when 
you round to 2dp like the PDF and PostScript devices do and it's still 
REALLY thin).

(ii) If the line dash pattern ends up as all zeroes (to 2dp), because 
the line width is so small (thin), force the dash pattern to "solid" 
instead.

(iii) plot.TukeyHSD() should not use lwd=0  (0.5 is plenty difference to 
be obviously "lighter" than the main plot lines)

I will commit these unless there are better suggestions or bitter 
objections.

Paul

On 15/12/2010 7:20 a.m., Ben Bolker wrote:
> On 10-12-14 01:16 PM, Peter Ehlers wrote:
>> On 2010-12-14 09:27, Ben Bolker wrote:
>>> Jari Oksanen<jari.oksanen<at>   oulu.fi>   writes:
>>>
>>>>
>>>> Hello R Developers,
>>>>
>>>> Dear R-developers,
>>>>
>>>> I ran some standard tests with currently (today morning) compiled R
>>>> release
>>>> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these
>>>> tests used
>>>> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
>>>> PostScript file could not be rendered. The following example had the
>>>> problem
>>>> with me:
>>>>
>>>> postscript(file="tukeyplot.ps")
>>>> example(plot.TukeyHSD)
>>>> dev.off()
>>>>
>>>> I couldn't view the resulting file with evince in Linux nor in the
>>>> standard
>>>> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the
>>>> same
>>>> file generated with an older R in my Mac, I found one difference:
>>>>
>>>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>>>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>>>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>>>> @@ -172,5 +172,5 @@
>>>>    0 setgray
>>>>    0.00 setlinewidth
>>>> -[ 3.00 5.00] 0 setdash
>>>> +[ 0.00 0.00] 0 setdash
>>>>    np
>>>>    660.06 91.44 m
>>>>
>>>> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
>>>> fixed the problem both in Linux and in Mac. Evidently something has
>>>> changed,
>>>> and probably somewhere else than in plot.TukeyHSD (which hasn't changed
>>>> since r51093 in trunk and never in R-2-12-branch). I know nothing about
>>>> PostScript so that I cannot say anything more (and I know viewers can
>>>> fail
>>>> with standard conforming PostScript but it is a bit disconcerting
>>>> that two
>>>> viewers fail when they worked earlier).
>>>
>>>     I must really be avoiding work today ...
>>>
>>>     I can diagnose this (I think) but don't know the best way to
>>> solve it.
>>>
>>>     At this point, line widths on PDF devices were allowed to be<1.
>>>
>>> ==========
>>> r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1 line
>>> Changed paths:
>>>      M /trunk/NEWS
>>>      M /trunk/src/library/grDevices/src/devPS.c
>>>
>>> allow lwd less than 1 on PDF device
>>> ==========
>>>
>>>     The behavior of PDF devices (by experiment) is to draw a 0-width
>>> line as 1 pixel wide, at whatever resolution is currently being
>>> rendered.  On the other hand, 0-width lines appear to break PostScript.
>>> (with the Linux viewer 'evince' I get warnings about "rangecheck -15"
>>> when trying to view such a file).
>>>
>>>     plot.TukeyHSD  contains the lines
>>>
>>> abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
>>> abline(v = 0, lty = 2, lwd = 0, ...)
>>>
>>>     which are presumably meant to render minimum-width lines.
>>>
>>>     I don't know whether it makes more sense to (1) change plot.TukeyHSD
>>> to use positive widths (although that may not help: I tried setting
>>> lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
>>> (2) change the postscript driver to *not* allow line widths<   1 (i.e.,
>>> distinguish between PS and PDF and revert to the pre-r52180 behaviour
>>> for PS only).
>>>
>>>     On reflection #2 seems to make more sense, but digging through devPS.c
>>> it's not immediately obvious to me where/how in SetLineStyle or
>>> PostScriptSetLineTexture one can tell whether the current driver
>>> is PS or PDF ...
>>>
>> That may not do it. I find the same problem (fixed by
>> Jari's replacement of [ 0.00 0.00] with [ 3.00 5.00];
>> haven't tried anything else yet) when I use pdf()
>> instead of postscript().
>> This is on Vista.
>>
>> Peter Ehlers
>
>    With PDF, I get "invalid value for a dash setting" from evince --
> perhaps the dash lengths are being set relative to the line width?
> (Could investigate but had better continue with other things ...)
>
>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From bbolker at gmail.com  Thu Dec 16 05:03:16 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Dec 2010 23:03:16 -0500
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <4D09786F.9020103@auckland.ac.nz>
References: <C92D60FB.142C5%jari.oksanen@oulu.fi>	<loom.20101214T174819-887@post.gmane.org>	<4D07B46C.8030808@ucalgary.ca>
	<4D07B568.6000505@gmail.com> <4D09786F.9020103@auckland.ac.nz>
Message-ID: <4D098F84.6030901@gmail.com>

On 10-12-15 09:24 PM, Paul Murrell wrote:
> Hi
> 
> According to the PostScript Language Reference Manual and the PDF
> Reference, in both PDF and PostScript ...
> 
> ... a line width of zero is valid, but not recommended (and is clearly
> not supported by some viewers).
> 
> ... a line dash pattern cannot be specified as all zero lengths.
> (So, because R generates the line dash pattern proportional to the line
> width, a specification of lwd=0 and
> lty=anything-other-than-"solid"-or-"none" does not make sense.)
> 
> I think three fixes are required:
> 
> (i)  Enforce a minimum line width of 0.01 (mainly because that is not
> zero, but also because that is the smallest value greater than zero when
> you round to 2dp like the PDF and PostScript devices do and it's still
> REALLY thin).
> 
> (ii) If the line dash pattern ends up as all zeroes (to 2dp), because
> the line width is so small (thin), force the dash pattern to "solid"
> instead.
> 
> (iii) plot.TukeyHSD() should not use lwd=0  (0.5 is plenty difference to
> be obviously "lighter" than the main plot lines)
> 
> I will commit these unless there are better suggestions or bitter
> objections.
> 

  That sounds great to me.  Proposed corresponding documentation change:

Index: pdf.Rd
===================================================================
--- pdf.Rd	(revision 53854)
+++ pdf.Rd	(working copy)
@@ -149,7 +149,10 @@
   viewers.  (PDF 1.4 requires Acrobat 5 or later.)

   Line widths as controlled by \code{par(lwd=)} are in multiples of
-  1/96 inch.  Multiples less than 1 are allowed.  \code{pch="."} with
+  1/96 inch.  Multiples less than 1 are allowed; line widths less
+  than 0.01 will be set equal to this minimum value.  Line dashes
+  are set proportional to line width; dash patterns less than 0.01
+  will be set to solid.  \code{pch="."} with
   \code{cex = 1} corresponds to a square of side 1/72 inch, which is
   also the \sQuote{pixel} size assumed for graphics parameters such as
   \code{"cra"}.

> Paul
> 
> On 15/12/2010 7:20 a.m., Ben Bolker wrote:
>> On 10-12-14 01:16 PM, Peter Ehlers wrote:
>>> On 2010-12-14 09:27, Ben Bolker wrote:
>>>> Jari Oksanen<jari.oksanen<at>   oulu.fi>   writes:
>>>>
>>>>>
>>>>> Hello R Developers,
>>>>>
>>>>> Dear R-developers,
>>>>>
>>>>> I ran some standard tests with currently (today morning) compiled R
>>>>> release
>>>>> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these
>>>>> tests used
>>>>> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
>>>>> PostScript file could not be rendered. The following example had the
>>>>> problem
>>>>> with me:
>>>>>
>>>>> postscript(file="tukeyplot.ps")
>>>>> example(plot.TukeyHSD)
>>>>> dev.off()
>>>>>
>>>>> I couldn't view the resulting file with evince in Linux nor in the
>>>>> standard
>>>>> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the
>>>>> same
>>>>> file generated with an older R in my Mac, I found one difference:
>>>>>
>>>>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>>>>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>>>>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>>>>> @@ -172,5 +172,5 @@
>>>>>    0 setgray
>>>>>    0.00 setlinewidth
>>>>> -[ 3.00 5.00] 0 setdash
>>>>> +[ 0.00 0.00] 0 setdash
>>>>>    np
>>>>>    660.06 91.44 m
>>>>>
>>>>> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash"
>>>>> also
>>>>> fixed the problem both in Linux and in Mac. Evidently something has
>>>>> changed,
>>>>> and probably somewhere else than in plot.TukeyHSD (which hasn't
>>>>> changed
>>>>> since r51093 in trunk and never in R-2-12-branch). I know nothing
>>>>> about
>>>>> PostScript so that I cannot say anything more (and I know viewers can
>>>>> fail
>>>>> with standard conforming PostScript but it is a bit disconcerting
>>>>> that two
>>>>> viewers fail when they worked earlier).
>>>>
>>>>     I must really be avoiding work today ...
>>>>
>>>>     I can diagnose this (I think) but don't know the best way to
>>>> solve it.
>>>>
>>>>     At this point, line widths on PDF devices were allowed to be<1.
>>>>
>>>> ==========
>>>> r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1
>>>> line
>>>> Changed paths:
>>>>      M /trunk/NEWS
>>>>      M /trunk/src/library/grDevices/src/devPS.c
>>>>
>>>> allow lwd less than 1 on PDF device
>>>> ==========
>>>>
>>>>     The behavior of PDF devices (by experiment) is to draw a 0-width
>>>> line as 1 pixel wide, at whatever resolution is currently being
>>>> rendered.  On the other hand, 0-width lines appear to break PostScript.
>>>> (with the Linux viewer 'evince' I get warnings about "rangecheck -15"
>>>> when trying to view such a file).
>>>>
>>>>     plot.TukeyHSD  contains the lines
>>>>
>>>> abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
>>>> abline(v = 0, lty = 2, lwd = 0, ...)
>>>>
>>>>     which are presumably meant to render minimum-width lines.
>>>>
>>>>     I don't know whether it makes more sense to (1) change
>>>> plot.TukeyHSD
>>>> to use positive widths (although that may not help: I tried setting
>>>> lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
>>>> (2) change the postscript driver to *not* allow line widths<   1 (i.e.,
>>>> distinguish between PS and PDF and revert to the pre-r52180 behaviour
>>>> for PS only).
>>>>
>>>>     On reflection #2 seems to make more sense, but digging through
>>>> devPS.c
>>>> it's not immediately obvious to me where/how in SetLineStyle or
>>>> PostScriptSetLineTexture one can tell whether the current driver
>>>> is PS or PDF ...
>>>>
>>> That may not do it. I find the same problem (fixed by
>>> Jari's replacement of [ 0.00 0.00] with [ 3.00 5.00];
>>> haven't tried anything else yet) when I use pdf()
>>> instead of postscript().
>>> This is on Vista.
>>>
>>> Peter Ehlers
>>
>>    With PDF, I get "invalid value for a dash setting" from evince --
>> perhaps the dash lengths are being set relative to the line width?
>> (Could investigate but had better continue with other things ...)
>>
>>    Ben Bolker
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jari.oksanen at oulu.fi  Thu Dec 16 06:09:01 2010
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 16 Dec 2010 07:09:01 +0200
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <4D09786F.9020103@auckland.ac.nz>
Message-ID: <C92F6B8D.1439C%jari.oksanen@oulu.fi>

On 16/12/10 04:24 AM, "Paul Murrell" <p.murrell at auckland.ac.nz> wrote:

> Hi
> 
> According to the PostScript Language Reference Manual and the PDF
> Reference, in both PDF and PostScript ...
> 
> ... a line width of zero is valid, but not recommended (and is clearly
> not supported by some viewers).
> 
> ... a line dash pattern cannot be specified as all zero lengths.
> (So, because R generates the line dash pattern proportional to the line
> width, a specification of lwd=0 and
> lty=anything-other-than-"solid"-or-"none" does not make sense.)
> 
> I think three fixes are required:
> 
> (i)  Enforce a minimum line width of 0.01 (mainly because that is not
> zero, but also because that is the smallest value greater than zero when
> you round to 2dp like the PDF and PostScript devices do and it's still
> REALLY thin).
> 
> (ii) If the line dash pattern ends up as all zeroes (to 2dp), because
> the line width is so small (thin), force the dash pattern to "solid"
> instead.
> 
> (iii) plot.TukeyHSD() should not use lwd=0  (0.5 is plenty difference to
> be obviously "lighter" than the main plot lines)
> 
> I will commit these unless there are better suggestions or bitter
> objections.
> 
Paul,

The difference between working previous (of R 2.11.1) and failing
current-still-yesterday (R 2.12.1 RC) was:

$ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
--- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
+++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
@@ -172,5 +172,5 @@
 0 setgray
 0.00 setlinewidth
-[ 3.00 5.00] 0 setdash
+[ 0.00 0.00] 0 setdash
 np
 660.06 91.44 m

So 0.00 setlinewidth worked, but [0.00 0.00] 0 setdash failed. Assuming
PostScript is anything like English, it is the all-zero dash that caused the
failure. 

Cheers, Jari Oksanen
> Paul
> 
> On 15/12/2010 7:20 a.m., Ben Bolker wrote:
>> On 10-12-14 01:16 PM, Peter Ehlers wrote:
>>> On 2010-12-14 09:27, Ben Bolker wrote:
>>>> Jari Oksanen<jari.oksanen<at>   oulu.fi>   writes:
>>>> 
>>>>> 
>>>>> Hello R Developers,
>>>>> 
>>>>> Dear R-developers,
>>>>> 
>>>>> I ran some standard tests with currently (today morning) compiled R
>>>>> release
>>>>> candidate in Linux R 2.12.1 RC (2010-12-13 r53843). Some of these
>>>>> tests used
>>>>> plot.TukeyHSD function. This worked OK on the screen (X11 device), but
>>>>> PostScript file could not be rendered. The following example had the
>>>>> problem
>>>>> with me:
>>>>> 
>>>>> postscript(file="tukeyplot.ps")
>>>>> example(plot.TukeyHSD)
>>>>> dev.off()
>>>>> 
>>>>> I couldn't view the resulting file with evince in Linux nor in the
>>>>> standard
>>>>> Preview in MacOS. When I compared the generated "tukeyplot.ps" to the
>>>>> same
>>>>> file generated with an older R in my Mac, I found one difference:
>>>>> 
>>>>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>>>>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>>>>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>>>>> @@ -172,5 +172,5 @@
>>>>>    0 setgray
>>>>>    0.00 setlinewidth
>>>>> -[ 3.00 5.00] 0 setdash
>>>>> +[ 0.00 0.00] 0 setdash
>>>>>    np
>>>>>    660.06 91.44 m
>>>>> 
>>>>> Editing the changed line to its old value "[ 3.00 5.00] 0 setdash" also
>>>>> fixed the problem both in Linux and in Mac. Evidently something has
>>>>> changed,
>>>>> and probably somewhere else than in plot.TukeyHSD (which hasn't changed
>>>>> since r51093 in trunk and never in R-2-12-branch). I know nothing about
>>>>> PostScript so that I cannot say anything more (and I know viewers can
>>>>> fail
>>>>> with standard conforming PostScript but it is a bit disconcerting
>>>>> that two
>>>>> viewers fail when they worked earlier).
>>>> 
>>>>     I must really be avoiding work today ...
>>>> 
>>>>     I can diagnose this (I think) but don't know the best way to
>>>> solve it.
>>>> 
>>>>     At this point, line widths on PDF devices were allowed to be<1.
>>>> 
>>>> ==========
>>>> r52180 | murrell | 2010-06-02 23:20:33 -0400 (Wed, 02 Jun 2010) | 1 line
>>>> Changed paths:
>>>>      M /trunk/NEWS
>>>>      M /trunk/src/library/grDevices/src/devPS.c
>>>> 
>>>> allow lwd less than 1 on PDF device
>>>> ==========
>>>> 
>>>>     The behavior of PDF devices (by experiment) is to draw a 0-width
>>>> line as 1 pixel wide, at whatever resolution is currently being
>>>> rendered.  On the other hand, 0-width lines appear to break PostScript.
>>>> (with the Linux viewer 'evince' I get warnings about "rangecheck -15"
>>>> when trying to view such a file).
>>>> 
>>>>     plot.TukeyHSD  contains the lines
>>>> 
>>>> abline(h = yvals, lty = 1, lwd = 0, col = "lightgray")
>>>> abline(v = 0, lty = 2, lwd = 0, ...)
>>>> 
>>>>     which are presumably meant to render minimum-width lines.
>>>> 
>>>>     I don't know whether it makes more sense to (1) change plot.TukeyHSD
>>>> to use positive widths (although that may not help: I tried setting
>>>> lwd=1e-5 and got the line widths rounded to 0 in the PostScript file);
>>>> (2) change the postscript driver to *not* allow line widths<   1 (i.e.,
>>>> distinguish between PS and PDF and revert to the pre-r52180 behaviour
>>>> for PS only).
>>>> 
>>>>     On reflection #2 seems to make more sense, but digging through devPS.c
>>>> it's not immediately obvious to me where/how in SetLineStyle or
>>>> PostScriptSetLineTexture one can tell whether the current driver
>>>> is PS or PDF ...
>>>> 
>>> That may not do it. I find the same problem (fixed by
>>> Jari's replacement of [ 0.00 0.00] with [ 3.00 5.00];
>>> haven't tried anything else yet) when I use pdf()
>>> instead of postscript().
>>> This is on Vista.
>>> 
>>> Peter Ehlers
>> 
>>    With PDF, I get "invalid value for a dash setting" from evince --
>> perhaps the dash lengths are being set relative to the line width?
>> (Could investigate but had better continue with other things ...)
>> 
>>    Ben Bolker
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From seanpor at acm.org  Thu Dec 16 09:12:47 2010
From: seanpor at acm.org (Sean O'Riordain)
Date: Thu, 16 Dec 2010 08:12:47 +0000
Subject: [Rd] possible minor mis-spelling in "R Data Import/Export"
Message-ID: <AANLkTin6knEsvT=H-eAv8kOfLfEb_CXnr0dfHs9mT+Z0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101216/05601eb9/attachment.pl>

From bbolker at gmail.com  Thu Dec 16 14:17:26 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 16 Dec 2010 08:17:26 -0500
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <C92F6B8D.1439C%jari.oksanen@oulu.fi>
References: <C92F6B8D.1439C%jari.oksanen@oulu.fi>
Message-ID: <4D0A1166.90203@gmail.com>

On 10-12-16 12:09 AM, Jari Oksanen wrote:
> On 16/12/10 04:24 AM, "Paul Murrell" <p.murrell at auckland.ac.nz> wrote:
> 
>> Hi
>>
>> According to the PostScript Language Reference Manual and the PDF
>> Reference, in both PDF and PostScript ...
>>
>> ... a line width of zero is valid, but not recommended (and is clearly
>> not supported by some viewers).
>>
>> ... a line dash pattern cannot be specified as all zero lengths.
>> (So, because R generates the line dash pattern proportional to the line
>> width, a specification of lwd=0 and
>> lty=anything-other-than-"solid"-or-"none" does not make sense.)
>>
>> I think three fixes are required:
>>
>> (i)  Enforce a minimum line width of 0.01 (mainly because that is not
>> zero, but also because that is the smallest value greater than zero when
>> you round to 2dp like the PDF and PostScript devices do and it's still
>> REALLY thin).
>>
>> (ii) If the line dash pattern ends up as all zeroes (to 2dp), because
>> the line width is so small (thin), force the dash pattern to "solid"
>> instead.
>>
>> (iii) plot.TukeyHSD() should not use lwd=0  (0.5 is plenty difference to
>> be obviously "lighter" than the main plot lines)
>>
>> I will commit these unless there are better suggestions or bitter
>> objections.
>>
> Paul,
> 
> The difference between working previous (of R 2.11.1) and failing
> current-still-yesterday (R 2.12.1 RC) was:
> 
> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
> @@ -172,5 +172,5 @@
>  0 setgray
>  0.00 setlinewidth
> -[ 3.00 5.00] 0 setdash
> +[ 0.00 0.00] 0 setdash
>  np
>  660.06 91.44 m
> 
> So 0.00 setlinewidth worked, but [0.00 0.00] 0 setdash failed. Assuming
> PostScript is anything like English, it is the all-zero dash that caused the
> failure. 
> 
> Cheers, Jari Oksanen

  Yes; I think Paul's fix #2 does this, and fixes #1 and #3 are trying
to avoid problems in the future ...

  cheers
    Ben Bolker


From christian.kohler at klinik.uni-regensburg.de  Thu Dec 16 14:31:07 2010
From: christian.kohler at klinik.uni-regensburg.de (Christian Kohler)
Date: Thu, 16 Dec 2010 14:31:07 +0100
Subject: [Rd] 'libRblas.so' missing in R 2.12.1
Message-ID: <4D0A149B.7090901@klinik.uni-regensburg.de>

Dear R developers,

I just compiled the latest version of R (2.12.1) and noticed that 'libRblas.so' is missing in the '/x86_64/src/extra/blas' subdirectory of my
R-installation.

Did I miss ongoing discussions on the Mailinglist about this or might it be a local problem?

Thanks for this brilliant software.

Best
Christian
-- 

Christian Kohler
Institute of Functional Genomics
 ~ Statistical Bioinformatics ~
University of Regensburg (BioPark I)
D-93053 Regensburg (Germany)

Tel. +49 941 943 5055
Fax  +49 941 943 5020
christian.kohler at klinik.uni-regensburg.de


From hpages at fhcrc.org  Thu Dec 16 19:14:14 2010
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 16 Dec 2010 10:14:14 -0800
Subject: [Rd] faster base::sequence
In-Reply-To: <4CF2275F.8030209@r-enthusiasts.com>
References: <4CF216AF.909@r-enthusiasts.com>	<alpine.LFD.2.00.1011280925250.24961@gannet.stats.ox.ac.uk>
	<4CF2275F.8030209@r-enthusiasts.com>
Message-ID: <4D0A56F6.3070900@fhcrc.org>

Hi Romain,

FWIW I see at least 2 small differences in the way sequence_c()
behaves with respect to good old sequence(): zeros and names.

 > sequence(c(a=5, b=0, c=2))
a1 a2 a3 a4 a5 c1 c2
  1  2  3  4  5  1  2

sequence_c() ignores the names and doesn't support zeros in the input.

Cheers,
H.


On 11/28/2010 01:56 AM, Romain Francois wrote:
> Le 28/11/10 10:30, Prof Brian Ripley a ?crit :
>> Is sequence used enough to warrant this? As the help page says
>>
>> Note that ?sequence <- function(nvec) unlist(lapply(nvec,
>> seq_len))? and it mainly exists in reverence to the very early
>> history of R.
>
> I don't know. Would it be used more if it were more efficient ?
>
>> I regard it as unsafe to assume that NA_INTEGER will always be negative,
>> and bear in mind that at some point not so far off R integers (or at
>> least lengths) will need to be more than 32-bit.
>
> sure. updated and dressed up as a patch.
>
> I've made it a .Call because I'm not really comfortable with .Internal,
> etc ...
>
> Do you mean that I should also use something else instead of "int" and
> "int*". Is there some future proof typedef or macro for the type
> associated with INTSXP ?
>
>
>> On Sun, 28 Nov 2010, Romain Francois wrote:
>>
>>> Hello,
>>>
>>> Based on yesterday's R-help thread (help: program efficiency), and
>>> following Bill's suggestions, it appeared that sequence:
>>>
>>>> sequence
>>> function (nvec)
>>> unlist(lapply(nvec, seq_len))
>>> <environment: namespace:base>
>>>
>>> could benefit from being written in C to avoid unnecessary memory
>>> allocations.
>>>
>>> I made this version using inline:
>>>
>>> require( inline )
>>> sequence_c <- local( {
>>> fx <- cfunction( signature( x = "integer"), '
>>> int n = length(x) ;
>>> int* px = INTEGER(x) ;
>>> int x_i, s = 0 ;
>>> /* error checking */
>>> for( int i=0; i<n; i++){
>>> x_i = px[i] ;
>>> /* this includes the check for NA */
>>> if( x_i <= 0 ) error( "needs non negative integer" ) ;
>>> s += x_i ;
>>> }
>>>
>>> SEXP res = PROTECT( allocVector( INTSXP, s ) ) ;
>>> int * p_res = INTEGER(res) ;
>>> for( int i=0; i<n; i++){
>>> x_i = px[i] ;
>>> for( int j=0; j<x_i; j++, p_res++)
>>> *p_res = j+1 ;
>>> }
>>> UNPROTECT(1) ;
>>> return res ;
>>> ' )
>>> function( nvec ){
>>> fx( as.integer(nvec) )
>>> }
>>> })
>>>
>>>
>>> And here are some timings:
>>>
>>>> x <- 1:10000
>>>> system.time( a <- sequence(x ) )
>>> utilisateur syst?me ?coul?
>>> 0.191 0.108 0.298
>>>> system.time( b <- sequence_c(x ) )
>>> utilisateur syst?me ?coul?
>>> 0.060 0.063 0.122
>>>> identical( a, b )
>>> [1] TRUE
>>>
>>>
>>>
>>>> system.time( for( i in 1:10000) sequence(1:10) )
>>> utilisateur syst?me ?coul?
>>> 0.119 0.000 0.119
>>>>
>>>> system.time( for( i in 1:10000) sequence_c(1:10) )
>>> utilisateur syst?me ?coul?
>>> 0.019 0.000 0.019
>>>
>>>
>>> I would write a proper patch if someone from R-core is willing to push
>>> it.
>>>
>>> Romain
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ggrothendieck at gmail.com  Fri Dec 17 15:32:18 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Dec 2010 09:32:18 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
Message-ID: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>

Consider this:

> letters[c(2, 3)]
[1] "b" "c"
> letters[c(2, NA)]
[1] "b" NA
> letters[c(NA, 3)]
[1] NA  "c"
> letters[c(NA, NA)]
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA

The result is a 2-vector in each case until we get to c(NA, NA) and
then it unexpectedly changes from returning a 2-vector to returning a
26-vector.  I think most people would have expected that the answer
would be c(NA, NA).


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Fri Dec 17 15:58:52 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Dec 2010 09:58:52 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>
References: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>
Message-ID: <4D0B7AAC.4070602@gmail.com>

On 17/12/2010 9:32 AM, Gabor Grothendieck wrote:
> Consider this:
>
> >  letters[c(2, 3)]
> [1] "b" "c"
> >  letters[c(2, NA)]
> [1] "b" NA
> >  letters[c(NA, 3)]
> [1] NA  "c"
> >  letters[c(NA, NA)]
>   [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> [26] NA
>
> The result is a 2-vector in each case until we get to c(NA, NA) and
> then it unexpectedly changes from returning a 2-vector to returning a
> 26-vector.  I think most people would have expected that the answer
> would be c(NA, NA).
>

This is because  c(NA, NA) is a logical vector, so it gets recycled to 
the length of letters, whereas c(NA, 3) and the others are numeric 
vectors, so they aren't recycled, they're converted to integer indices.  
So the surprise is due to not recognizing that NA is logical.  You 
wouldn't expect a length 1 result from letters[TRUE], would you?

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Dec 17 16:18:01 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Dec 2010 10:18:01 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <4D0B7AAC.4070602@gmail.com>
References: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>
	<4D0B7AAC.4070602@gmail.com>
Message-ID: <AANLkTimQhjXwbeO6aw0vD7xERtesREOHg6G+6wGGDcbB@mail.gmail.com>

On Fri, Dec 17, 2010 at 9:58 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 17/12/2010 9:32 AM, Gabor Grothendieck wrote:
>>
>> Consider this:
>>
>> > ?letters[c(2, 3)]
>> [1] "b" "c"
>> > ?letters[c(2, NA)]
>> [1] "b" NA
>> > ?letters[c(NA, 3)]
>> [1] NA ?"c"
>> > ?letters[c(NA, NA)]
>> ?[1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
>> NA NA
>> [26] NA
>>
>> The result is a 2-vector in each case until we get to c(NA, NA) and
>> then it unexpectedly changes from returning a 2-vector to returning a
>> 26-vector. ?I think most people would have expected that the answer
>> would be c(NA, NA).
>>
>
> This is because ?c(NA, NA) is a logical vector, so it gets recycled to the
> length of letters, whereas c(NA, 3) and the others are numeric vectors, so
> they aren't recycled, they're converted to integer indices. ?So the surprise
> is due to not recognizing that NA is logical. ?You wouldn't expect a length
> 1 result from letters[TRUE], would you?

One tends not to distinguish between logical NA's and integer NA's.
In fact R represents both of them as NA on output so this does  seem
highly error prone.

> NA # logical
[1] NA
> NA_integer_ # integer
[1] NA


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Fri Dec 17 16:37:21 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Dec 2010 10:37:21 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <AANLkTimQhjXwbeO6aw0vD7xERtesREOHg6G+6wGGDcbB@mail.gmail.com>
References: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>
	<4D0B7AAC.4070602@gmail.com>
	<AANLkTimQhjXwbeO6aw0vD7xERtesREOHg6G+6wGGDcbB@mail.gmail.com>
Message-ID: <4D0B83B1.3050702@gmail.com>

On 17/12/2010 10:18 AM, Gabor Grothendieck wrote:
> On Fri, Dec 17, 2010 at 9:58 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
> >  On 17/12/2010 9:32 AM, Gabor Grothendieck wrote:
> >>
> >>  Consider this:
> >>
> >>  >    letters[c(2, 3)]
> >>  [1] "b" "c"
> >>  >    letters[c(2, NA)]
> >>  [1] "b" NA
> >>  >    letters[c(NA, 3)]
> >>  [1] NA  "c"
> >>  >    letters[c(NA, NA)]
> >>    [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> >>  NA NA
> >>  [26] NA
> >>
> >>  The result is a 2-vector in each case until we get to c(NA, NA) and
> >>  then it unexpectedly changes from returning a 2-vector to returning a
> >>  26-vector.  I think most people would have expected that the answer
> >>  would be c(NA, NA).
> >>
> >
> >  This is because  c(NA, NA) is a logical vector, so it gets recycled to the
> >  length of letters, whereas c(NA, 3) and the others are numeric vectors, so
> >  they aren't recycled, they're converted to integer indices.  So the surprise
> >  is due to not recognizing that NA is logical.  You wouldn't expect a length
> >  1 result from letters[TRUE], would you?
>
> One tends not to distinguish between logical NA's and integer NA's.
> In fact R represents both of them as NA on output so this does  seem
> highly error prone.
>
> >  NA # logical
> [1] NA
> >  NA_integer_ # integer
> [1] NA
>

I agree it's error prone, but I don't know a good solution.  The ability 
to distinguish them on input is a relatively recent addition (in 
2.5.0).  Changing the display on output would confuse a lot of people.

Duncan Murdoch


From ted.harding at wlandres.net  Fri Dec 17 16:40:14 2010
From: ted.harding at wlandres.net ( (Ted Harding))
Date: Fri, 17 Dec 2010 15:40:14 -0000 (GMT)
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <AANLkTikMgfMC35MPrr7DGtToovTFsbWMrM3fGX=bskA3@mail.gmail.com>
Message-ID: <XFMail.101217154014.ted.harding@wlandres.net>

On 17-Dec-10 14:32:18, Gabor Grothendieck wrote:
> Consider this:
> 
>> letters[c(2, 3)]
> [1] "b" "c"
>> letters[c(2, NA)]
> [1] "b" NA
>> letters[c(NA, 3)]
> [1] NA  "c"
>> letters[c(NA, NA)]
>  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA NA
> [26] NA
> 
> The result is a 2-vector in each case until we get to c(NA, NA) and
> then it unexpectedly changes from returning a 2-vector to returning a
> 26-vector.  I think most people would have expected that the answer
> would be c(NA, NA).

I'm not sure that it is suprising! Consider
  letters[NA]
which returns exactly the same result. Then consider that 'letters' is
simply a 26-element character vector c("a",...). Now consider

  x <- c(1,2,3,4,5,6,7,8,9,10,11,12,13)
  x[NA]
  # [1] NA NA NA NA NA NA NA NA NA NA NA NA NA

In other words, x[NA] for any vector x will test each index 1:length(x)
against NA, and will find that it's NA, since it doesn't know whether
the index matches or not. Therefore it returns NA for that index, and
will do the same for every index. So it's telling you: "For each of my
elements a,b,c,d,e,f,... I have to tell you that I don't know whether
you want it or not". You also get similar behavior for x==NA.

If anything might be surprising (though that also admits a logical
explanation), is the result

  letters[c(2, NA)]
  # [1] "b" NA

since the result being asked for by the first element of c(2,NA) is
definite -- so far so good -- but then you would expect it to have the
same problem with what is being asked for by NA. This time, it seems
that because the 2-element vector c(2,NA) is being submitted, its
length over-rides the length of the response that would be given for
x[NA]: "You asked for a 2-element extraction from letters; I can see
what you want for the first, but not for the second".

However, that logic does not work for letters[c(NA,NA)] which still
returns the 26-element result!

After all that, I'm inclined to the view that letters[NA] should
return one element (NA), letters[c(NA,NA)] should return 2 (NA,NA),
etc.; and that the same should apply to all vectors accessed by [].
The above behaviour seems to contradict [what I can understand from]
what is said in ?"[":

NAs in indexing:
     When extracting, a numerical, logical or character 'NA' index
     picks an unknown element and so returns 'NA' in the corresponding
     element of a logical, integer, numeric, complex or character
     result, and 'NULL' for a list.  (It returns '00' for a raw
     result.]

since that seems to imply that x[c(NA,NA)] should return c(NA,NA)
and not rep(NA,length(x))!

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at wlandres.net>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Dec-10                                       Time: 15:40:03
------------------------------ XFMail ------------------------------


From murdoch.duncan at gmail.com  Fri Dec 17 16:55:44 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Dec 2010 10:55:44 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <XFMail.101217154014.ted.harding@wlandres.net>
References: <XFMail.101217154014.ted.harding@wlandres.net>
Message-ID: <4D0B8800.30007@gmail.com>

On 17/12/2010 10:40 AM, (Ted Harding) wrote:
> On 17-Dec-10 14:32:18, Gabor Grothendieck wrote:
> >  Consider this:
> >
> >>  letters[c(2, 3)]
> >  [1] "b" "c"
> >>  letters[c(2, NA)]
> >  [1] "b" NA
> >>  letters[c(NA, 3)]
> >  [1] NA  "c"
> >>  letters[c(NA, NA)]
> >   [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> >  NA NA NA
> >  [26] NA
> >
> >  The result is a 2-vector in each case until we get to c(NA, NA) and
> >  then it unexpectedly changes from returning a 2-vector to returning a
> >  26-vector.  I think most people would have expected that the answer
> >  would be c(NA, NA).
>
> I'm not sure that it is suprising! Consider
>    letters[NA]
> which returns exactly the same result. Then consider that 'letters' is
> simply a 26-element character vector c("a",...). Now consider
>
>    x<- c(1,2,3,4,5,6,7,8,9,10,11,12,13)
>    x[NA]
>    # [1] NA NA NA NA NA NA NA NA NA NA NA NA NA
>
> In other words, x[NA] for any vector x will test each index 1:length(x)
> against NA, and will find that it's NA, since it doesn't know whether
> the index matches or not. Therefore it returns NA for that index, and
> will do the same for every index. So it's telling you: "For each of my
> elements a,b,c,d,e,f,... I have to tell you that I don't know whether
> you want it or not". You also get similar behavior for x==NA.
>
> If anything might be surprising (though that also admits a logical
> explanation), is the result
>
>    letters[c(2, NA)]
>    # [1] "b" NA
>
> since the result being asked for by the first element of c(2,NA) is
> definite -- so far so good -- but then you would expect it to have the
> same problem with what is being asked for by NA. This time, it seems
> that because the 2-element vector c(2,NA) is being submitted, its
> length over-rides the length of the response that would be given for
> x[NA]: "You asked for a 2-element extraction from letters; I can see
> what you want for the first, but not for the second".
>
> However, that logic does not work for letters[c(NA,NA)] which still
> returns the 26-element result!
>
> After all that, I'm inclined to the view that letters[NA] should
> return one element (NA), letters[c(NA,NA)] should return 2 (NA,NA),
> etc.; and that the same should apply to all vectors accessed by [].
> The above behaviour seems to contradict [what I can understand from]
> what is said in ?"[":
>
> NAs in indexing:
>       When extracting, a numerical, logical or character 'NA' index
>       picks an unknown element and so returns 'NA' in the corresponding
>       element of a logical, integer, numeric, complex or character
>       result, and 'NULL' for a list.  (It returns '00' for a raw
>       result.]
>
> since that seems to imply that x[c(NA,NA)] should return c(NA,NA)
> and not rep(NA,length(x))!

I don't know where that quote came from, but it is not quite relevant 
here.  The relevant quote is in the Language Definition, talking about 
indices by type of index:

"Logical. The indexing i should generally have the same length as x. If 
it is shorter, then
its elements will be recycled as discussed in Section 3.3 [Elementary 
arithmetic operations],
page 14. If it is longer, then x is conceptually extended with NAs. The 
selected values of x
are those for which i is TRUE."

The Introduction to R gets this wrong:

"A logical vector. In this case the index vector must be of the same 
length as the vector
from which elements are to be selected. Values corresponding to TRUE in 
the index vector
are selected and those corresponding to FALSE are omitted."

The "must" in that quote is too strong; the Language Definition gets it 
right.  Perhaps the behaviour described in the Intro manual would be 
less confusing:  letters[c(NA,NA)] would give an error or warning, 
something like "logical index of incorrect length".  But I suspect 
people rely on the recycling of logical vectors, so there'd be a lot of 
complaints if we made that change.

Duncan Murdoch


From matloff at cs.ucdavis.edu  Fri Dec 17 17:56:31 2010
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Fri, 17 Dec 2010 08:56:31 -0800
Subject: [Rd] GUI's and R background processes
Message-ID: <20101217165631.GA27947@laura>

(Sorry, originally sent to wrong list.)

Anne, you can accomplish your goal by using my Rdsm package, which adds
a threads-like capability to R.  You can download it from CRAN.  

Look in particular in the examples/ directory.  The file WebProbe.R is
pretty much exactly the same usage that you want.  Look at Auction.R
too. 

You may also find my UseR! presentation on Rdsm to be helpful,
user2010.org/slides/Matloff.pdf

You could do the same thing, though less directly and I believe less
conveniently, using some of the packages Louis mentioned, as well as
bigmemory.

Norm Matloff


From stvjc at channing.harvard.edu  Fri Dec 17 20:12:16 2010
From: stvjc at channing.harvard.edu (Vincent Carey)
Date: Fri, 17 Dec 2010 14:12:16 -0500
Subject: [Rd] diagnosing a CMD check failure
Message-ID: <AANLkTinid3gNcmdaTEYN0nve9_xypXy_NRY0-uVoR9wm@mail.gmail.com>

I have created a quite minimal package with a simple R program in the
tests subfolder.

When I run CMD check, I get

* checking examples ... OK
* checking for unstated dependencies in tests ... OK
* checking tests ...sh: : No such file or directory
 ERROR

I don't see a way of diagnosing this.  The content of tests is the program t1.R

rex-bash-3.2$ cat t1.R
date()

On other machines I can successfully check the package, so it must be
a problem with my particular
configuration but how can I track down the problem?

> sessionInfo()
R version 2.13.0 Under development (unstable) (2010-11-11 r53555)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base


From murdoch.duncan at gmail.com  Fri Dec 17 21:01:20 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 Dec 2010 15:01:20 -0500
Subject: [Rd] diagnosing a CMD check failure
In-Reply-To: <AANLkTinid3gNcmdaTEYN0nve9_xypXy_NRY0-uVoR9wm@mail.gmail.com>
References: <AANLkTinid3gNcmdaTEYN0nve9_xypXy_NRY0-uVoR9wm@mail.gmail.com>
Message-ID: <4D0BC190.5070108@gmail.com>

On 17/12/2010 2:12 PM, Vincent Carey wrote:
> I have created a quite minimal package with a simple R program in the
> tests subfolder.
>
> When I run CMD check, I get
>
> * checking examples ... OK
> * checking for unstated dependencies in tests ... OK
> * checking tests ...sh: : No such file or directory
>   ERROR
>
> I don't see a way of diagnosing this.  The content of tests is the program t1.R
>
> rex-bash-3.2$ cat t1.R
> date()
>
> On other machines I can successfully check the package, so it must be
> a problem with my particular
> configuration but how can I track down the problem?

Try running tools::.check_packages directly.  The problem is coming in 
the local function run_tests.

Duncan Murdoch

> >  sessionInfo()
> R version 2.13.0 Under development (unstable) (2010-11-11 r53555)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From stvjc at channing.harvard.edu  Fri Dec 17 21:38:48 2010
From: stvjc at channing.harvard.edu (Vincent Carey)
Date: Fri, 17 Dec 2010 15:38:48 -0500
Subject: [Rd] diagnosing a CMD check failure
In-Reply-To: <4D0BC190.5070108@gmail.com>
References: <AANLkTinid3gNcmdaTEYN0nve9_xypXy_NRY0-uVoR9wm@mail.gmail.com>
	<4D0BC190.5070108@gmail.com>
Message-ID: <AANLkTinS01LmqTxrR_etg-4WR+1Mpz6tAbHBEz-Ph_6F@mail.gmail.com>

That got me a little further.  system2() seems not to like my system.

> system("date")
Fri Dec 17 15:35:21 EST 2010
> system2("date")
sh: : No such file or directory

This is with 2.13 r53555.

On Fri, Dec 17, 2010 at 3:01 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 17/12/2010 2:12 PM, Vincent Carey wrote:
>>
>> I have created a quite minimal package with a simple R program in the
>> tests subfolder.
>>
>> When I run CMD check, I get
>>
>> * checking examples ... OK
>> * checking for unstated dependencies in tests ... OK
>> * checking tests ...sh: : No such file or directory
>> ?ERROR
>>
>> I don't see a way of diagnosing this. ?The content of tests is the program
>> t1.R
>>
>> rex-bash-3.2$ cat t1.R
>> date()
>>
>> On other machines I can successfully check the package, so it must be
>> a problem with my particular
>> configuration but how can I track down the problem?
>
> Try running tools::.check_packages directly. ?The problem is coming in the
> local function run_tests.
>
> Duncan Murdoch
>
>> > ?sessionInfo()
>> R version 2.13.0 Under development (unstable) (2010-11-11 r53555)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices datasets ?utils ? ? methods ? base
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From dtenenba at fhcrc.org  Fri Dec 17 21:41:57 2010
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 17 Dec 2010 12:41:57 -0800
Subject: [Rd] diagnosing a CMD check failure
In-Reply-To: <AANLkTinS01LmqTxrR_etg-4WR+1Mpz6tAbHBEz-Ph_6F@mail.gmail.com>
References: <AANLkTinid3gNcmdaTEYN0nve9_xypXy_NRY0-uVoR9wm@mail.gmail.com>
	<4D0BC190.5070108@gmail.com>
	<AANLkTinS01LmqTxrR_etg-4WR+1Mpz6tAbHBEz-Ph_6F@mail.gmail.com>
Message-ID: <AANLkTi=BAHkoeypGY0Zu8crwkVu1NCKxYxeLZ+F2sh29@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101217/8f32ebd0/attachment.pl>

From radford at cs.toronto.edu  Sat Dec 18 15:12:18 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 18 Dec 2010 09:12:18 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
Message-ID: <20101218141218.GA26473@cs.toronto.edu>

Duncan Murdoch writes:

  The relevant quote is in the Language Definition, talking about
  indices by type of index:

  "Logical. The indexing i should generally have the same length as
  x. If it is shorter, then its elements will be recycled as discussed
  in Section 3.3 [Elementary arithmetic operations], page 14. If it is
  longer, then x is conceptually extended with NAs. The selected values
  of x are those for which i is TRUE."

But this certainly does not justify the actual behaviour.  It says
that, for example, (1:3)[NA] should not be a vector of three NAs, but
rather a vector of length zero - since NONE of the indexes are TRUE.

The actual behaviour of NA in a logical index makes no sense.  It
makes sense that NA in an integer index produces an NA in the result,
since this NA might correctly express the uncertainty in the value at
this position that follows from the uncertainty in the index (and
hence produce sensible results in subsequent operations).  But NA in a
logical index should lead to a result that is of uncertain length.
However, R has no mechanism for expressing such uncertainty, so it
makes more sense that NA in a logical index should produce an error.

   Radford Neal


From Niels.R.Hansen at math.ku.dk  Fri Dec 17 18:42:53 2010
From: Niels.R.Hansen at math.ku.dk (Niels Richard Hansen)
Date: Fri, 17 Dec 2010 09:42:53 -0800
Subject: [Rd] How to use the RUnit tracker in unit tests?
Message-ID: <4D0BA11D.8000804@math.ku.dk>

R-developers

Does anybody know how I incorporate the use of the tracker in RUnit
in the unit tests?

I have read the RUnit Vignette, help pages and searched around,
but I could find no examples of using 'inspect' in the unit
test functions. Moreover, doing so, I tried something like

library(RUnit)
myFunction <- function(x) {
	return(x)
}
track <- tracker()
track$init()

test.someTestFunction <- function() {
   y <- 10
   res <- inspect(myFunction(y), track = track)
   checkEquals(res, 10)
}

which works fine, when calling test.someTestFunction() from
the command line, but embedded in a test suite, I get
Error in eval(expr, envir, enclos) : object 'y' not found

Another question/suggestion: The 'inspect' function inserts
track points in the code, and this could perhaps be used
differently. Instead of doing it in a local copy of the code
(as I understand it is done), it could be done in the original
function, like 'trace' can replace the original code, I believe.
Then every subsequent call will be tracked, until inspection is
stopped. I imagine something like

startInspection(myFunction, track = track)
[ or startInspection(myFunction, signature = "numeric", track = track)]
myFunction(10)
stopInspection(myFunction)

Is this already around?

Best, Niels

-- 
Niels Richard Hansen                     Web:   www.math.ku.dk/~richard	
Associate Professor                      Email: Niels.R.Hansen at math.ku.dk
Department of Mathematical Sciences             nielsrichardhansen at gmail.com
University of Copenhagen                 Skype: nielsrichardhansen.dk	
Universitetsparken 5                     Phone: +1 510 502 8161	
2100 Copenhagen ?
Denmark


From murdoch.duncan at gmail.com  Sat Dec 18 18:23:30 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 18 Dec 2010 12:23:30 -0500
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <20101218141218.GA26473@cs.toronto.edu>
References: <20101218141218.GA26473@cs.toronto.edu>
Message-ID: <4D0CEE12.2070406@gmail.com>

On 18/12/2010 9:12 AM, Radford Neal wrote:
> Duncan Murdoch writes:
>
>    The relevant quote is in the Language Definition, talking about
>    indices by type of index:
>
>    "Logical. The indexing i should generally have the same length as
>    x. If it is shorter, then its elements will be recycled as discussed
>    in Section 3.3 [Elementary arithmetic operations], page 14. If it is
>    longer, then x is conceptually extended with NAs. The selected values
>    of x are those for which i is TRUE."
>
> But this certainly does not justify the actual behaviour.  It says
> that, for example, (1:3)[NA] should not be a vector of three NAs, but
> rather a vector of length zero - since NONE of the indexes are TRUE.
>
> The actual behaviour of NA in a logical index makes no sense.  It
> makes sense that NA in an integer index produces an NA in the result,
> since this NA might correctly express the uncertainty in the value at
> this position that follows from the uncertainty in the index (and
> hence produce sensible results in subsequent operations).  But NA in a
> logical index should lead to a result that is of uncertain length.
> However, R has no mechanism for expressing such uncertainty, so it
> makes more sense that NA in a logical index should produce an error.
>

I agree that the behaviour is not particularly obvious, but I'm not so 
sure it should produce an error.  We should get an error when the input 
is likely to be accidental or due to a misconception and the output 
could be accepted and lead to wrong results later.  I think using an NA 
in a logical index is probably due to a misconception (e.g. thinking it 
is an NA_integer_), but the results are so weird that they are unlikely 
to pass unnoticed.

And presumably whoever chose this behaviour back in the ancient past 
thought there was some use in including NA in a logical index, and 
someone out there in the real world has made use of it.

But I wouldn't object if R version 3 gave errors for logical index 
vectors that were the wrong length or that contained NAs.

Duncan Murdoch


From wdunlap at tibco.com  Sat Dec 18 23:16:58 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 18 Dec 2010 14:16:58 -0800
Subject: [Rd] Surprising behavior of letters[c(NA, NA)]
In-Reply-To: <4D0CEE12.2070406@gmail.com>
References: <20101218141218.GA26473@cs.toronto.edu>
	<4D0CEE12.2070406@gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003C2D822@NA-PA-VBE03.na.tibco.com>

I'm agnostic at this point about the recycling rules
for logical subscripting, but I've been coming around
to thinking that x[logicalSubscript] should only return
the values of x such that the corresponding value
of logicalSubscript is TRUE.  Values in logicalSubscript
of NA and FALSE should be treated the same: the
corresponding value of x should not be put into the
output subset.  I know this change will break low-level
tests, but I suspect it will make more user-written
code start working than to start breaking when logical
NA's are used in subscripts.

I've asked people why they use the idiom
    x[which(condition)]
instead of the simpler
    x[condition]
Some new users don't know the simpler one works, but
more experienced users say they use which() because
it treats NA's the same a FALSES.

I've heard the same response when I ask about using
subset(dataFrame,condition) instead of dataFrame[condition,].
subset() uses non-standard evaluation rules that
leads to convoluted code involving substitute() and the
like when you want to use it in a general function,
but people use it in part because it treats logical NA's
as though they were FALSE's.

I sometimes use an is.true() function in subscript expressions
   is.true <- function(x) !is.na(x) & x
   vec[is.true(condition)]  
but it seems like a waste of time (and it gets confused
with the isTRUE() function).

A separate but related point is that using logical NA as a
subscript to vector with names gives a nonoptimal result:
  > c(one=1,two=2,three=3,four=4)[c(TRUE,NA,FALSE,TRUE)]
   one <NA> four 
     1   NA    4  
Why isn't the second element of the result called "two"?
As it stands we only know that there was an NA in the subscript,
somewhere between the first and fourth element.

An unrelated point concerns the builtin constants NA, NA_integer_,
NA_real_, etc, where all modes of NA's are generally printed as
just NA.  This seems to lead to misleading tests, like
   x[NA] # integer or logical NA?
but when analyzing data I think you rarely use a typed-in NA
in an expression.  The NA's generally come from data you have
read in from an external source (where NA is rarely used to
indicate missing values) and you always have to make sure
the data columns of imported data have the expected types.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Saturday, December 18, 2010 9:24 AM
> To: Radford Neal
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Surprising behavior of letters[c(NA, NA)]
> 
> On 18/12/2010 9:12 AM, Radford Neal wrote:
> > Duncan Murdoch writes:
> >
> >    The relevant quote is in the Language Definition, talking about
> >    indices by type of index:
> >
> >    "Logical. The indexing i should generally have the same length as
> >    x. If it is shorter, then its elements will be recycled 
> as discussed
> >    in Section 3.3 [Elementary arithmetic operations], page 
> 14. If it is
> >    longer, then x is conceptually extended with NAs. The 
> selected values
> >    of x are those for which i is TRUE."
> >
> > But this certainly does not justify the actual behaviour.  It says
> > that, for example, (1:3)[NA] should not be a vector of 
> three NAs, but
> > rather a vector of length zero - since NONE of the indexes are TRUE.
> >
> > The actual behaviour of NA in a logical index makes no sense.  It
> > makes sense that NA in an integer index produces an NA in 
> the result,
> > since this NA might correctly express the uncertainty in 
> the value at
> > this position that follows from the uncertainty in the index (and
> > hence produce sensible results in subsequent operations).  
> But NA in a
> > logical index should lead to a result that is of uncertain length.
> > However, R has no mechanism for expressing such uncertainty, so it
> > makes more sense that NA in a logical index should produce an error.
> >
> 
> I agree that the behaviour is not particularly obvious, but 
> I'm not so 
> sure it should produce an error.  We should get an error when 
> the input 
> is likely to be accidental or due to a misconception and the output 
> could be accepted and lead to wrong results later.  I think 
> using an NA 
> in a logical index is probably due to a misconception (e.g. 
> thinking it 
> is an NA_integer_), but the results are so weird that they 
> are unlikely 
> to pass unnoticed.
> 
> And presumably whoever chose this behaviour back in the ancient past 
> thought there was some use in including NA in a logical index, and 
> someone out there in the real world has made use of it.
> 
> But I wouldn't object if R version 3 gave errors for logical index 
> vectors that were the wrong length or that contained NAs.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ggrothendieck at gmail.com  Sat Dec 18 23:24:48 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 18 Dec 2010 17:24:48 -0500
Subject: [Rd] Rcmd SHLIB error
Message-ID: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>

I am getting this error message when I try to run Rcmd SHLIB myprog.c.
 There appears to be a missing / between etc and i386 in the path.  I
am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
How can I resolve this?

C:\tmp2>Rcmd SHLIB myprog.c
cygwin warning:
  MS-DOS style path detected: C:/PROGRA~1/R/R-212~1.X/etci386/Makeconf
  Preferred POSIX equivalent is: /cygdrive/c/PROGRA~1/R/R-212~1.X/etci386/Makeco
nf
  CYGWIN environment variable option "nodosfilewarning" turns off this warning.
  Consult the user's guide for more details about POSIX paths:
    http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
make: C:/PROGRA~1/R/R-212~1.X/etci386/Makeconf: No such file or directory
make: *** No rule to make target `C:/PROGRA~1/R/R-212~1.X/etci386/Makeconf'.  St
op.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From djsamperi at gmail.com  Sun Dec 19 02:23:30 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 18 Dec 2010 20:23:30 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
Message-ID: <AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101218/805831eb/attachment.pl>

From ggrothendieck at gmail.com  Sun Dec 19 12:06:41 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 19 Dec 2010 06:06:41 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
Message-ID: <AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>

On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi <djsamperi at gmail.com> wrote:
>
>
> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>>
>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>> ?There appears to be a missing / between etc and i386 in the path. ?I
>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>> r53864) and just downloaded Rtools 2.12 today. ? Is this a bug in R?
>> How can I resolve this?
>
> This is due to new behavior in CYGWIN (the basis for Rtools). The
> new CYGWIN does not like non-standard paths that have C: in them.
> Some CYGWIN programs will not work when fed file names using
> this syntax, but normally this is just a warning. The warning can be
> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
> Another solution is to use POSIX equivalent paths of the form
> /cydrive/c/PROG..., but this would require more extensive changes
> to build scripts, etc.
>
> There is another change that causes Rtools tar to choke in some
> circumstances under Windows because it tries to change ownership
> of the files extracted when it shouldn't. These error
> messags can be suppressed by using the Control Panel to set
> TAR_OPTIONS=--no-same-owner.
>

I am still wondering what to do about this?  I have created a
directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
workaround and there must be some better resolution than that.  Also I
am wondering if this same problem will crop up elsewhere.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Sun Dec 19 12:39:24 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 Dec 2010 06:39:24 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
Message-ID: <4D0DEEEC.6020202@gmail.com>

On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>  wrote:
>>
>>
>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>> <ggrothendieck at gmail.com>  wrote:
>>>
>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>   There appears to be a missing / between etc and i386 in the path.  I
>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>> How can I resolve this?
>>
>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>> new CYGWIN does not like non-standard paths that have C: in them.
>> Some CYGWIN programs will not work when fed file names using
>> this syntax, but normally this is just a warning. The warning can be
>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>> Another solution is to use POSIX equivalent paths of the form
>> /cydrive/c/PROG..., but this would require more extensive changes
>> to build scripts, etc.
>>
>> There is another change that causes Rtools tar to choke in some
>> circumstances under Windows because it tries to change ownership
>> of the files extracted when it shouldn't. These error
>> messags can be suppressed by using the Control Panel to set
>> TAR_OPTIONS=--no-same-owner.
>>
>
> I am still wondering what to do about this?  I have created a
> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
> workaround and there must be some better resolution than that.  Also I
> am wondering if this same problem will crop up elsewhere.
>

You could try running within Cygwin, as I do, on the theory that what 
works for me might work for you.  I do use the "nodosfilewarning" 
setting as Dominick mentioned.

However, I will say that my Windows build system is much less reliable 
than it used to be.  I don't know the cause:  I started 64 bit builds on 
Windows 7 at around the same time as I upgraded Cygwin, so it could be 
any of those causes.  I'm tending to believe it's a Cygwin problem or a 
Cygwin-Win7 incompatibility, but I haven't had time to work out a 
reliable system.  (Symptoms I see are that very few overnight builds are 
succeeding; almost all the ones you see on CRAN/bin/windows/base have 
required manual restarts after they've failed partway through.)

Unfortunately, I am not going to have the time to diagnose or fix this 
in the next couple of months.  If you have spare time, you might want to 
try older versions of the Rtools (perhaps mixing new compilers with old 
Rtools/bin and Cygwin DLLs).

Duncan Murdoch


From ggrothendieck at gmail.com  Sun Dec 19 13:01:16 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 19 Dec 2010 07:01:16 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <4D0DEEEC.6020202@gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
Message-ID: <AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>

On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>
>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>> ?wrote:
>>>
>>>
>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>> <ggrothendieck at gmail.com> ?wrote:
>>>>
>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>> ?There appears to be a missing / between etc and i386 in the path. ?I
>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>> r53864) and just downloaded Rtools 2.12 today. ? Is this a bug in R?
>>>> How can I resolve this?
>>>
>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>> new CYGWIN does not like non-standard paths that have C: in them.
>>> Some CYGWIN programs will not work when fed file names using
>>> this syntax, but normally this is just a warning. The warning can be
>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>> Another solution is to use POSIX equivalent paths of the form
>>> /cydrive/c/PROG..., but this would require more extensive changes
>>> to build scripts, etc.
>>>
>>> There is another change that causes Rtools tar to choke in some
>>> circumstances under Windows because it tries to change ownership
>>> of the files extracted when it shouldn't. These error
>>> messags can be suppressed by using the Control Panel to set
>>> TAR_OPTIONS=--no-same-owner.
>>>
>>
>> I am still wondering what to do about this? ?I have created a
>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>> Makeconf into it. ?That lets me use Rcmd SHLIB but its quite an ugly
>> workaround and there must be some better resolution than that. ?Also I
>> am wondering if this same problem will crop up elsewhere.
>>
>
> You could try running within Cygwin, as I do, on the theory that what works
> for me might work for you. ?I do use the "nodosfilewarning" setting as
> Dominick mentioned.
>
> However, I will say that my Windows build system is much less reliable than
> it used to be. ?I don't know the cause: ?I started 64 bit builds on Windows
> 7 at around the same time as I upgraded Cygwin, so it could be any of those
> causes. ?I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
> incompatibility, but I haven't had time to work out a reliable system.
> ?(Symptoms I see are that very few overnight builds are succeeding; almost
> all the ones you see on CRAN/bin/windows/base have required manual restarts
> after they've failed partway through.)
>
> Unfortunately, I am not going to have the time to diagnose or fix this in
> the next couple of months. ?If you have spare time, you might want to try
> older versions of the Rtools (perhaps mixing new compilers with old
> Rtools/bin and Cygwin DLLs).
>
> Duncan Murdoch
>

Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path set?


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Sun Dec 19 15:07:02 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 Dec 2010 09:07:02 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
Message-ID: <4D0E1186.90009@gmail.com>

On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>
>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>   wrote:
>>>>
>>>>
>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>> <ggrothendieck at gmail.com>    wrote:
>>>>>
>>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>>>   There appears to be a missing / between etc and i386 in the path.  I
>>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>>>> How can I resolve this?
>>>>
>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>> Some CYGWIN programs will not work when fed file names using
>>>> this syntax, but normally this is just a warning. The warning can be
>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>> Another solution is to use POSIX equivalent paths of the form
>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>> to build scripts, etc.
>>>>
>>>> There is another change that causes Rtools tar to choke in some
>>>> circumstances under Windows because it tries to change ownership
>>>> of the files extracted when it shouldn't. These error
>>>> messags can be suppressed by using the Control Panel to set
>>>> TAR_OPTIONS=--no-same-owner.
>>>>
>>>
>>> I am still wondering what to do about this?  I have created a
>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
>>> workaround and there must be some better resolution than that.  Also I
>>> am wondering if this same problem will crop up elsewhere.
>>>
>>
>> You could try running within Cygwin, as I do, on the theory that what works
>> for me might work for you.  I do use the "nodosfilewarning" setting as
>> Dominick mentioned.
>>
>> However, I will say that my Windows build system is much less reliable than
>> it used to be.  I don't know the cause:  I started 64 bit builds on Windows
>> 7 at around the same time as I upgraded Cygwin, so it could be any of those
>> causes.  I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>> incompatibility, but I haven't had time to work out a reliable system.
>>   (Symptoms I see are that very few overnight builds are succeeding; almost
>> all the ones you see on CRAN/bin/windows/base have required manual restarts
>> after they've failed partway through.)
>>
>> Unfortunately, I am not going to have the time to diagnose or fix this in
>> the next couple of months.  If you have spare time, you might want to try
>> older versions of the Rtools (perhaps mixing new compilers with old
>> Rtools/bin and Cygwin DLLs).
>>
>> Duncan Murdoch
>>
>
> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path set?

I don't know.  Possibilities include src/gnuwin32/fixed/Makefile line 31 
(where a bad R_ARCH would do it).  Do you have R_ARCH set as an 
environment variable or on the command line when you call make? I think 
the latter would override the setting in MkRules, I'm not sure about the 
former.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sun Dec 19 15:57:26 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Dec 2010 14:57:26 +0000 (GMT)
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <4D0DEEEC.6020202@gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
Message-ID: <alpine.LFD.2.00.1012191450010.22241@gannet.stats.ox.ac.uk>

On Sun, 19 Dec 2010, Duncan Murdoch wrote:

> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com> 
>> wrote:
>>> 
>>> 
>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>> <ggrothendieck at gmail.com>  wrote:
>>>> 
>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>>   There appears to be a missing / between etc and i386 in the path.  I
>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>>> How can I resolve this?
>>> 
>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>> new CYGWIN does not like non-standard paths that have C: in them.
>>> Some CYGWIN programs will not work when fed file names using
>>> this syntax, but normally this is just a warning. The warning can be
>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>> Another solution is to use POSIX equivalent paths of the form
>>> /cydrive/c/PROG..., but this would require more extensive changes
>>> to build scripts, etc.
>>> 
>>> There is another change that causes Rtools tar to choke in some
>>> circumstances under Windows because it tries to change ownership
>>> of the files extracted when it shouldn't. These error
>>> messags can be suppressed by using the Control Panel to set
>>> TAR_OPTIONS=--no-same-owner.

All of which is in the manual (including what the circumstances are).

>> I am still wondering what to do about this?  I have created a
>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
>> workaround and there must be some better resolution than that.  Also I
>> am wondering if this same problem will crop up elsewhere.
>> 
>
> You could try running within Cygwin, as I do, on the theory that what works 
> for me might work for you.  I do use the "nodosfilewarning" setting as 
> Dominick mentioned.
>
> However, I will say that my Windows build system is much less reliable than 
> it used to be.  I don't know the cause:  I started 64 bit builds on Windows 7 
> at around the same time as I upgraded Cygwin, so it could be any of those 
> causes.  I'm tending to believe it's a Cygwin problem or a Cygwin-Win7 
> incompatibility, but I haven't had time to work out a reliable system. 
> (Symptoms I see are that very few overnight builds are succeeding; almost all 
> the ones you see on CRAN/bin/windows/base have required manual restarts after 
> they've failed partway through.)
>
> Unfortunately, I am not going to have the time to diagnose or fix this in the 
> next couple of months.  If you have spare time, you might want to try older 
> versions of the Rtools (perhaps mixing new compilers with old Rtools/bin and 
> Cygwin DLLs).

It seems to be the updated Cygwin in Rtools: working in 64-bit Win7 is 
very reliable for me (by the standards of Windows) using the 
pre-October version: the October update fails more often than not when 
building R from scratch (e.g. sh or make hangs).  People using 32-bit 
XP seem to have more success with the latest version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Sun Dec 19 16:04:02 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 19 Dec 2010 10:04:02 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <4D0E1186.90009@gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
	<4D0E1186.90009@gmail.com>
Message-ID: <AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>

On Sun, Dec 19, 2010 at 9:07 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
>>
>> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>>
>>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>> ?wrote:
>>>>>
>>>>>
>>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>>> <ggrothendieck at gmail.com> ? ?wrote:
>>>>>>
>>>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>>>> ?There appears to be a missing / between etc and i386 in the path. ?I
>>>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>>>> r53864) and just downloaded Rtools 2.12 today. ? Is this a bug in R?
>>>>>> How can I resolve this?
>>>>>
>>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>>> Some CYGWIN programs will not work when fed file names using
>>>>> this syntax, but normally this is just a warning. The warning can be
>>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>>> Another solution is to use POSIX equivalent paths of the form
>>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>>> to build scripts, etc.
>>>>>
>>>>> There is another change that causes Rtools tar to choke in some
>>>>> circumstances under Windows because it tries to change ownership
>>>>> of the files extracted when it shouldn't. These error
>>>>> messags can be suppressed by using the Control Panel to set
>>>>> TAR_OPTIONS=--no-same-owner.
>>>>>
>>>>
>>>> I am still wondering what to do about this? ?I have created a
>>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>>> Makeconf into it. ?That lets me use Rcmd SHLIB but its quite an ugly
>>>> workaround and there must be some better resolution than that. ?Also I
>>>> am wondering if this same problem will crop up elsewhere.
>>>>
>>>
>>> You could try running within Cygwin, as I do, on the theory that what
>>> works
>>> for me might work for you. ?I do use the "nodosfilewarning" setting as
>>> Dominick mentioned.
>>>
>>> However, I will say that my Windows build system is much less reliable
>>> than
>>> it used to be. ?I don't know the cause: ?I started 64 bit builds on
>>> Windows
>>> 7 at around the same time as I upgraded Cygwin, so it could be any of
>>> those
>>> causes. ?I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>>> incompatibility, but I haven't had time to work out a reliable system.
>>> ?(Symptoms I see are that very few overnight builds are succeeding;
>>> almost
>>> all the ones you see on CRAN/bin/windows/base have required manual
>>> restarts
>>> after they've failed partway through.)
>>>
>>> Unfortunately, I am not going to have the time to diagnose or fix this in
>>> the next couple of months. ?If you have spare time, you might want to try
>>> older versions of the Rtools (perhaps mixing new compilers with old
>>> Rtools/bin and Cygwin DLLs).
>>>
>>> Duncan Murdoch
>>>
>>
>> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path
>> set?
>
> I don't know. ?Possibilities include src/gnuwin32/fixed/Makefile line 31
> (where a bad R_ARCH would do it). ?Do you have R_ARCH set as an environment
> variable or on the command line when you call make? I think the latter would
> override the setting in MkRules, I'm not sure about the former.
>

Thanks.  I now have a better workaround.  The batch file shown below
works but if /i386 is changed to i386 then it fails because it looks
for a directory called etci386:

  setlocal
  set R_ARCH=/i386
  "C:\Program Files\R\R-2.12.x\bin\i386\Rcmd.exe" SHLIB myprog.c
  endlocal

1. It seems the / is missing between etc and $(R_ARCH) on lines 31 and
38 of that Makefile (or if etci386 is intended then the actual
structure of R that is installed is wrong).
2. page 8 of R-admin manual says that there is an --arch argument with
values i386, 32, x64, 64 but neither "Rcmd --help" nor "Rcmd SHLIB
--help" document an argument for setting the architecture.
3. on page 12 of the R-ext manual it refers to
R_HOME/etcR_ARCH/Makeconf so the documentation and how the Makefile
works seems inconsistent with the actual R directory structure which
is etc/i386 and not etci386.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Sun Dec 19 16:25:22 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 19 Dec 2010 10:25:22 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
	<4D0E1186.90009@gmail.com>
	<AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
Message-ID: <23627D39-6F5E-48D2-AC09-29AF7CF3D1E9@r-project.org>


On Dec 19, 2010, at 10:04 AM, Gabor Grothendieck wrote:

> On Sun, Dec 19, 2010 at 9:07 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
>>> 
>>> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>  wrote:
>>>> 
>>>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>>> 
>>>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>>>  wrote:
>>>>>> 
>>>>>> 
>>>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>>>> <ggrothendieck at gmail.com>    wrote:
>>>>>>> 
>>>>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>>>>>  There appears to be a missing / between etc and i386 in the path.  I
>>>>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>>>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>>>>>> How can I resolve this?
>>>>>> 
>>>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>>>> Some CYGWIN programs will not work when fed file names using
>>>>>> this syntax, but normally this is just a warning. The warning can be
>>>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>>>> Another solution is to use POSIX equivalent paths of the form
>>>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>>>> to build scripts, etc.
>>>>>> 
>>>>>> There is another change that causes Rtools tar to choke in some
>>>>>> circumstances under Windows because it tries to change ownership
>>>>>> of the files extracted when it shouldn't. These error
>>>>>> messags can be suppressed by using the Control Panel to set
>>>>>> TAR_OPTIONS=--no-same-owner.
>>>>>> 
>>>>> 
>>>>> I am still wondering what to do about this?  I have created a
>>>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>>>> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
>>>>> workaround and there must be some better resolution than that.  Also I
>>>>> am wondering if this same problem will crop up elsewhere.
>>>>> 
>>>> 
>>>> You could try running within Cygwin, as I do, on the theory that what
>>>> works
>>>> for me might work for you.  I do use the "nodosfilewarning" setting as
>>>> Dominick mentioned.
>>>> 
>>>> However, I will say that my Windows build system is much less reliable
>>>> than
>>>> it used to be.  I don't know the cause:  I started 64 bit builds on
>>>> Windows
>>>> 7 at around the same time as I upgraded Cygwin, so it could be any of
>>>> those
>>>> causes.  I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>>>> incompatibility, but I haven't had time to work out a reliable system.
>>>>  (Symptoms I see are that very few overnight builds are succeeding;
>>>> almost
>>>> all the ones you see on CRAN/bin/windows/base have required manual
>>>> restarts
>>>> after they've failed partway through.)
>>>> 
>>>> Unfortunately, I am not going to have the time to diagnose or fix this in
>>>> the next couple of months.  If you have spare time, you might want to try
>>>> older versions of the Rtools (perhaps mixing new compilers with old
>>>> Rtools/bin and Cygwin DLLs).
>>>> 
>>>> Duncan Murdoch
>>>> 
>>> 
>>> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path
>>> set?
>> 
>> I don't know.  Possibilities include src/gnuwin32/fixed/Makefile line 31
>> (where a bad R_ARCH would do it).  Do you have R_ARCH set as an environment
>> variable or on the command line when you call make? I think the latter would
>> override the setting in MkRules, I'm not sure about the former.
>> 
> 
> Thanks.  I now have a better workaround.  The batch file shown below
> works but if /i386 is changed to i386

That is wrong - the R_ARCH always includes the slash - it's not to be confused with the --arch argument and r_arch configure variable!

This fact has nothing to do with Windows - that is the general rule for r_arch and R_ARCH in multi-arch R on all platforms (and I would recommend reading up on that as Windows users seem to be oblivious to the multi-arch support which has been in R for years).

I don't have Win at home so I can't have a look, but the above is the wrong part to "fix".

Cheers,
Simon


> then it fails because it looks
> for a directory called etci386:
> 
>  setlocal
>  set R_ARCH=/i386
>  "C:\Program Files\R\R-2.12.x\bin\i386\Rcmd.exe" SHLIB myprog.c
>  endlocal
> 
> 1. It seems the / is missing between etc and $(R_ARCH) on lines 31 and
> 38 of that Makefile (or if etci386 is intended then the actual
> structure of R that is installed is wrong).
> 2. page 8 of R-admin manual says that there is an --arch argument with
> values i386, 32, x64, 64 but neither "Rcmd --help" nor "Rcmd SHLIB
> --help" document an argument for setting the architecture.
> 3. on page 12 of the R-ext manual it refers to
> R_HOME/etcR_ARCH/Makeconf so the documentation and how the Makefile
> works seems inconsistent with the actual R directory structure which
> is etc/i386 and not etci386.
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Sun Dec 19 16:31:16 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 Dec 2010 10:31:16 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
	<4D0E1186.90009@gmail.com>
	<AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
Message-ID: <4D0E2544.7050301@gmail.com>

On 19/12/2010 10:04 AM, Gabor Grothendieck wrote:
> On Sun, Dec 19, 2010 at 9:07 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
>>>
>>> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>    wrote:
>>>>
>>>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>>>
>>>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>>>   wrote:
>>>>>>
>>>>>>
>>>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>>>> <ggrothendieck at gmail.com>      wrote:
>>>>>>>
>>>>>>> I am getting this error message when I try to run Rcmd SHLIB myprog.c.
>>>>>>>   There appears to be a missing / between etc and i386 in the path.  I
>>>>>>> am on Windows Vista and am using R version 2.12.1 Patched (2010-12-16
>>>>>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>>>>>> How can I resolve this?
>>>>>>
>>>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>>>> Some CYGWIN programs will not work when fed file names using
>>>>>> this syntax, but normally this is just a warning. The warning can be
>>>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>>>> Another solution is to use POSIX equivalent paths of the form
>>>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>>>> to build scripts, etc.
>>>>>>
>>>>>> There is another change that causes Rtools tar to choke in some
>>>>>> circumstances under Windows because it tries to change ownership
>>>>>> of the files extracted when it shouldn't. These error
>>>>>> messags can be suppressed by using the Control Panel to set
>>>>>> TAR_OPTIONS=--no-same-owner.
>>>>>>
>>>>>
>>>>> I am still wondering what to do about this?  I have created a
>>>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>>>> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
>>>>> workaround and there must be some better resolution than that.  Also I
>>>>> am wondering if this same problem will crop up elsewhere.
>>>>>
>>>>
>>>> You could try running within Cygwin, as I do, on the theory that what
>>>> works
>>>> for me might work for you.  I do use the "nodosfilewarning" setting as
>>>> Dominick mentioned.
>>>>
>>>> However, I will say that my Windows build system is much less reliable
>>>> than
>>>> it used to be.  I don't know the cause:  I started 64 bit builds on
>>>> Windows
>>>> 7 at around the same time as I upgraded Cygwin, so it could be any of
>>>> those
>>>> causes.  I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>>>> incompatibility, but I haven't had time to work out a reliable system.
>>>>   (Symptoms I see are that very few overnight builds are succeeding;
>>>> almost
>>>> all the ones you see on CRAN/bin/windows/base have required manual
>>>> restarts
>>>> after they've failed partway through.)
>>>>
>>>> Unfortunately, I am not going to have the time to diagnose or fix this in
>>>> the next couple of months.  If you have spare time, you might want to try
>>>> older versions of the Rtools (perhaps mixing new compilers with old
>>>> Rtools/bin and Cygwin DLLs).
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path
>>> set?
>>
>> I don't know.  Possibilities include src/gnuwin32/fixed/Makefile line 31
>> (where a bad R_ARCH would do it).  Do you have R_ARCH set as an environment
>> variable or on the command line when you call make? I think the latter would
>> override the setting in MkRules, I'm not sure about the former.
>>
>
> Thanks.  I now have a better workaround.  The batch file shown below
> works but if /i386 is changed to i386 then it fails because it looks
> for a directory called etci386:
>
>    setlocal
>    set R_ARCH=/i386
>    "C:\Program Files\R\R-2.12.x\bin\i386\Rcmd.exe" SHLIB myprog.c
>    endlocal
>
> 1. It seems the / is missing between etc and $(R_ARCH) on lines 31 and
> 38 of that Makefile (or if etci386 is intended then the actual
> structure of R that is installed is wrong).

No, the slash is supposed to be part of R_ARCH, which isn't a variable 
you should need to set.  It is set in MkRules, as I mentioned above.

> 2. page 8 of R-admin manual says that there is an --arch argument with
> values i386, 32, x64, 64 but neither "Rcmd --help" nor "Rcmd SHLIB
> --help" document an argument for setting the architecture.

That argument appears to work for me.  If you want to submit a patch so 
--help displays it, I'll take a look.

> 3. on page 12 of the R-ext manual it refers to
> R_HOME/etcR_ARCH/Makeconf so the documentation and how the Makefile
> works seems inconsistent with the actual R directory structure which
> is etc/i386 and not etci386.
>

See 1.

Duncan Murdoch


From smlee at hko.gov.hk  Sun Dec 19 16:47:53 2010
From: smlee at hko.gov.hk (smlee at hko.gov.hk)
Date: Sun, 19 Dec 2010 23:47:53 +0800
Subject: [Rd] Unable to build R-2.10.0 and later releases on AIX 6.1
Message-ID: <4D0E2929.2010509@hko.gov.hk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101219/04b808fe/attachment.pl>

From ggrothendieck at gmail.com  Sun Dec 19 21:09:37 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 19 Dec 2010 15:09:37 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <4D0E2544.7050301@gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
	<4D0E1186.90009@gmail.com>
	<AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
	<4D0E2544.7050301@gmail.com>
Message-ID: <AANLkTikRRcfFs82zRsT1tHmzdrkV30R5cJ9+JMQ+RABi@mail.gmail.com>

On Sun, Dec 19, 2010 at 10:31 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 19/12/2010 10:04 AM, Gabor Grothendieck wrote:
>>
>> On Sun, Dec 19, 2010 at 9:07 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
>>>>
>>>> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> ? ?wrote:
>>>>>
>>>>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>>>>
>>>>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>>>> ?wrote:
>>>>>>>
>>>>>>>
>>>>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>>>>> <ggrothendieck at gmail.com> ? ? ?wrote:
>>>>>>>>
>>>>>>>> I am getting this error message when I try to run Rcmd SHLIB
>>>>>>>> myprog.c.
>>>>>>>> ?There appears to be a missing / between etc and i386 in the path.
>>>>>>>> ?I
>>>>>>>> am on Windows Vista and am using R version 2.12.1 Patched
>>>>>>>> (2010-12-16
>>>>>>>> r53864) and just downloaded Rtools 2.12 today. ? Is this a bug in R?
>>>>>>>> How can I resolve this?
>>>>>>>
>>>>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>>>>> Some CYGWIN programs will not work when fed file names using
>>>>>>> this syntax, but normally this is just a warning. The warning can be
>>>>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>>>>> Another solution is to use POSIX equivalent paths of the form
>>>>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>>>>> to build scripts, etc.
>>>>>>>
>>>>>>> There is another change that causes Rtools tar to choke in some
>>>>>>> circumstances under Windows because it tries to change ownership
>>>>>>> of the files extracted when it shouldn't. These error
>>>>>>> messags can be suppressed by using the Control Panel to set
>>>>>>> TAR_OPTIONS=--no-same-owner.
>>>>>>>
>>>>>>
>>>>>> I am still wondering what to do about this? ?I have created a
>>>>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>>>>> Makeconf into it. ?That lets me use Rcmd SHLIB but its quite an ugly
>>>>>> workaround and there must be some better resolution than that. ?Also I
>>>>>> am wondering if this same problem will crop up elsewhere.
>>>>>>
>>>>>
>>>>> You could try running within Cygwin, as I do, on the theory that what
>>>>> works
>>>>> for me might work for you. ?I do use the "nodosfilewarning" setting as
>>>>> Dominick mentioned.
>>>>>
>>>>> However, I will say that my Windows build system is much less reliable
>>>>> than
>>>>> it used to be. ?I don't know the cause: ?I started 64 bit builds on
>>>>> Windows
>>>>> 7 at around the same time as I upgraded Cygwin, so it could be any of
>>>>> those
>>>>> causes. ?I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>>>>> incompatibility, but I haven't had time to work out a reliable system.
>>>>> ?(Symptoms I see are that very few overnight builds are succeeding;
>>>>> almost
>>>>> all the ones you see on CRAN/bin/windows/base have required manual
>>>>> restarts
>>>>> after they've failed partway through.)
>>>>>
>>>>> Unfortunately, I am not going to have the time to diagnose or fix this
>>>>> in
>>>>> the next couple of months. ?If you have spare time, you might want to
>>>>> try
>>>>> older versions of the Rtools (perhaps mixing new compilers with old
>>>>> Rtools/bin and Cygwin DLLs).
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>
>>>> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path
>>>> set?
>>>
>>> I don't know. ?Possibilities include src/gnuwin32/fixed/Makefile line 31
>>> (where a bad R_ARCH would do it). ?Do you have R_ARCH set as an
>>> environment
>>> variable or on the command line when you call make? I think the latter
>>> would
>>> override the setting in MkRules, I'm not sure about the former.
>>>
>>
>> Thanks. ?I now have a better workaround. ?The batch file shown below
>> works but if /i386 is changed to i386 then it fails because it looks
>> for a directory called etci386:
>>
>> ? setlocal
>> ? set R_ARCH=/i386
>> ? "C:\Program Files\R\R-2.12.x\bin\i386\Rcmd.exe" SHLIB myprog.c
>> ? endlocal
>>
>> 1. It seems the / is missing between etc and $(R_ARCH) on lines 31 and
>> 38 of that Makefile (or if etci386 is intended then the actual
>> structure of R that is installed is wrong).
>
> No, the slash is supposed to be part of R_ARCH, which isn't a variable you
> should need to set. ?It is set in MkRules, as I mentioned above.
>
>> 2. page 8 of R-admin manual says that there is an --arch argument with
>> values i386, 32, x64, 64 but neither "Rcmd --help" nor "Rcmd SHLIB
>> --help" document an argument for setting the architecture.
>
> That argument appears to work for me. ?If you want to submit a patch so
> --help displays it, I'll take a look.
>
>> 3. on page 12 of the R-ext manual it refers to
>> R_HOME/etcR_ARCH/Makeconf so the documentation and how the Makefile
>> works seems inconsistent with the actual R directory structure which
>> is etc/i386 and not etci386.
>>
>
> See 1.
>

For now I have addressed this in my publicly available Windows
batchfiles so that when using them R_ARCH can have or not have a / and
they will still work.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Sun Dec 19 22:12:47 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 Dec 2010 16:12:47 -0500
Subject: [Rd] Rcmd SHLIB error
In-Reply-To: <AANLkTikRRcfFs82zRsT1tHmzdrkV30R5cJ9+JMQ+RABi@mail.gmail.com>
References: <AANLkTikdEtj2phJUhFj4nDY_M7jqywPzS6YkonVzgyTr@mail.gmail.com>
	<AANLkTimLjKgnQx-uV-6z4qBgu7R5HJwt9K6uYAe4tPWc@mail.gmail.com>
	<AANLkTi=wt-bdfgBA4iGRLb4B-N-MVNttG0JMLEbmMBX5@mail.gmail.com>
	<4D0DEEEC.6020202@gmail.com>
	<AANLkTinUHPPGzOeXy48iyQUc3ONmH_E3vj9W-BupABhW@mail.gmail.com>
	<4D0E1186.90009@gmail.com>
	<AANLkTim=c8xbaS_SyVJZajhLiMayzFnNhshr4TNqA84z@mail.gmail.com>
	<4D0E2544.7050301@gmail.com>
	<AANLkTikRRcfFs82zRsT1tHmzdrkV30R5cJ9+JMQ+RABi@mail.gmail.com>
Message-ID: <4D0E754F.60308@gmail.com>

On 19/12/2010 3:09 PM, Gabor Grothendieck wrote:
> On Sun, Dec 19, 2010 at 10:31 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 19/12/2010 10:04 AM, Gabor Grothendieck wrote:
>>>
>>> On Sun, Dec 19, 2010 at 9:07 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>    wrote:
>>>>
>>>> On 19/12/2010 7:01 AM, Gabor Grothendieck wrote:
>>>>>
>>>>> On Sun, Dec 19, 2010 at 6:39 AM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com>      wrote:
>>>>>>
>>>>>> On 19/12/2010 6:06 AM, Gabor Grothendieck wrote:
>>>>>>>
>>>>>>> On Sat, Dec 18, 2010 at 8:23 PM, Dominick Samperi<djsamperi at gmail.com>
>>>>>>>   wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sat, Dec 18, 2010 at 5:24 PM, Gabor Grothendieck
>>>>>>>> <ggrothendieck at gmail.com>        wrote:
>>>>>>>>>
>>>>>>>>> I am getting this error message when I try to run Rcmd SHLIB
>>>>>>>>> myprog.c.
>>>>>>>>>   There appears to be a missing / between etc and i386 in the path.
>>>>>>>>>   I
>>>>>>>>> am on Windows Vista and am using R version 2.12.1 Patched
>>>>>>>>> (2010-12-16
>>>>>>>>> r53864) and just downloaded Rtools 2.12 today.   Is this a bug in R?
>>>>>>>>> How can I resolve this?
>>>>>>>>
>>>>>>>> This is due to new behavior in CYGWIN (the basis for Rtools). The
>>>>>>>> new CYGWIN does not like non-standard paths that have C: in them.
>>>>>>>> Some CYGWIN programs will not work when fed file names using
>>>>>>>> this syntax, but normally this is just a warning. The warning can be
>>>>>>>> suppressed by using the Control Panel to set CYGWIN=nodosfilewarning.
>>>>>>>> Another solution is to use POSIX equivalent paths of the form
>>>>>>>> /cydrive/c/PROG..., but this would require more extensive changes
>>>>>>>> to build scripts, etc.
>>>>>>>>
>>>>>>>> There is another change that causes Rtools tar to choke in some
>>>>>>>> circumstances under Windows because it tries to change ownership
>>>>>>>> of the files extracted when it shouldn't. These error
>>>>>>>> messags can be suppressed by using the Control Panel to set
>>>>>>>> TAR_OPTIONS=--no-same-owner.
>>>>>>>>
>>>>>>>
>>>>>>> I am still wondering what to do about this?  I have created a
>>>>>>> directory called C:\PROGRA~1\R\R-212~1.X\etci386 and have copied
>>>>>>> Makeconf into it.  That lets me use Rcmd SHLIB but its quite an ugly
>>>>>>> workaround and there must be some better resolution than that.  Also I
>>>>>>> am wondering if this same problem will crop up elsewhere.
>>>>>>>
>>>>>>
>>>>>> You could try running within Cygwin, as I do, on the theory that what
>>>>>> works
>>>>>> for me might work for you.  I do use the "nodosfilewarning" setting as
>>>>>> Dominick mentioned.
>>>>>>
>>>>>> However, I will say that my Windows build system is much less reliable
>>>>>> than
>>>>>> it used to be.  I don't know the cause:  I started 64 bit builds on
>>>>>> Windows
>>>>>> 7 at around the same time as I upgraded Cygwin, so it could be any of
>>>>>> those
>>>>>> causes.  I'm tending to believe it's a Cygwin problem or a Cygwin-Win7
>>>>>> incompatibility, but I haven't had time to work out a reliable system.
>>>>>>   (Symptoms I see are that very few overnight builds are succeeding;
>>>>>> almost
>>>>>> all the ones you see on CRAN/bin/windows/base have required manual
>>>>>> restarts
>>>>>> after they've failed partway through.)
>>>>>>
>>>>>> Unfortunately, I am not going to have the time to diagnose or fix this
>>>>>> in
>>>>>> the next couple of months.  If you have spare time, you might want to
>>>>>> try
>>>>>> older versions of the Rtools (perhaps mixing new compilers with old
>>>>>> Rtools/bin and Cygwin DLLs).
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>
>>>>> Where in the sources is the C:\PROGRA~1\R\R-212~1.X\etci386 [sic] path
>>>>> set?
>>>>
>>>> I don't know.  Possibilities include src/gnuwin32/fixed/Makefile line 31
>>>> (where a bad R_ARCH would do it).  Do you have R_ARCH set as an
>>>> environment
>>>> variable or on the command line when you call make? I think the latter
>>>> would
>>>> override the setting in MkRules, I'm not sure about the former.
>>>>
>>>
>>> Thanks.  I now have a better workaround.  The batch file shown below
>>> works but if /i386 is changed to i386 then it fails because it looks
>>> for a directory called etci386:
>>>
>>>    setlocal
>>>    set R_ARCH=/i386
>>>    "C:\Program Files\R\R-2.12.x\bin\i386\Rcmd.exe" SHLIB myprog.c
>>>    endlocal
>>>
>>> 1. It seems the / is missing between etc and $(R_ARCH) on lines 31 and
>>> 38 of that Makefile (or if etci386 is intended then the actual
>>> structure of R that is installed is wrong).
>>
>> No, the slash is supposed to be part of R_ARCH, which isn't a variable you
>> should need to set.  It is set in MkRules, as I mentioned above.
>>
>>> 2. page 8 of R-admin manual says that there is an --arch argument with
>>> values i386, 32, x64, 64 but neither "Rcmd --help" nor "Rcmd SHLIB
>>> --help" document an argument for setting the architecture.
>>
>> That argument appears to work for me.  If you want to submit a patch so
>> --help displays it, I'll take a look.
>>
>>> 3. on page 12 of the R-ext manual it refers to
>>> R_HOME/etcR_ARCH/Makeconf so the documentation and how the Makefile
>>> works seems inconsistent with the actual R directory structure which
>>> is etc/i386 and not etci386.
>>>
>>
>> See 1.
>>
>
> For now I have addressed this in my publicly available Windows
> batchfiles so that when using them R_ARCH can have or not have a / and
> they will still work.
>

That's definitely the wrong approach.  You'll just confuse people about 
the meaning of R_ARCH if you misuse it that way.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Dec 20 01:34:20 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Dec 2010 00:34:20 +0000 (GMT)
Subject: [Rd] Unable to build R-2.10.0 and later releases on AIX 6.1
In-Reply-To: <4D0E2929.2010509@hko.gov.hk>
References: <4D0E2929.2010509@hko.gov.hk>
Message-ID: <alpine.LFD.2.00.1012200030170.3939@gannet.stats.ox.ac.uk>

So presumably an AIX header is incautiously using 'truncate' as a 
macro and setting it to 'truncate64'.

Try adding

# undef truncate

after

# undef open

at ca line 46 of that file.

On Sun, 19 Dec 2010, smlee at hko.gov.hk wrote:

> Hi,
>
> I have been able to build R-2.9.2 on AIX 6.1 and AIX 5.2. However, I
> failed to build R-2.10.0 and later releases on these AIX platforms. The
> error messages I got are attached below:
>
> "connections.c", line 461.10: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
> "connections.c", line 772.10: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
> "connections.c", line 930.10: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
> "connections.c", line 2011.10: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
> "connections.c", line 2319.14: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
> "connections.c", line 3094.10: 1506-022 (S) "truncate64" is not a member
> of "struct Rconn".
>
> My configure script is attached below:
>
> #!/bin/ksh
> PRFX=`pwd`
> OBJECT_MODE=32
> LIBICONV=/opt/freeware
> CPPFLAGS="-I$LIBICONV/include -I/usr/lpp/X11/include/X11"
> LDFLAGS="-L$LIBICONV/lib -L/usr/lib -L/usr/X11R6/lib"
> CONFIG_SHELL=/usr/bin/bash
> MAKE=/opt/freeware/bin/make
> CC="xlc"
> CXX="xlc++"
> FC="xlf"
> F77="xlf"
> CFLAGS="-qarch=auto -qcache=auto -qtune=auto -O3 -qstrict -ma"
> FFLAGS="-qarch=auto -qcache=auto -qtune=auto -O3 -qstrict"
> FCFLAGS="-qarch=auto -qcache=auto -qtune=auto -O3 -qstrict"
> CXXFLAGS="-qarch=auto -qcache=auto -qtune=auto -O3 -qstrict"
> export OBJECT_MODE LIBICONV CC CFLAGS CXX CXXFLAGS F77 CPPFLAGS LDFLAGS
> export CONFIG_SHELL MAKE
> export FCFLAGS FFLAGS FC
> ./configure --prefix=$PRFX --without-readline --without-recommended-packages
>
> Regards,
>
> Arnold
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smlee at hko.gov.hk  Mon Dec 20 02:29:12 2010
From: smlee at hko.gov.hk (smlee at hko.gov.hk)
Date: Mon, 20 Dec 2010 09:29:12 +0800
Subject: [Rd] Unable to build R-2.10.0 and later releases on AIX 6.1
In-Reply-To: <alpine.LFD.2.00.1012200030170.3939@gannet.stats.ox.ac.uk>
References: <4D0E2929.2010509@hko.gov.hk>
	<alpine.LFD.2.00.1012200030170.3939@gannet.stats.ox.ac.uk>
Message-ID: <4D0EB168.2050804@hko.gov.hk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101220/25039ec2/attachment.pl>

From john.maindonald at anu.edu.au  Tue Dec 21 09:23:21 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 21 Dec 2010 21:23:21 +1300
Subject: [Rd] Bug report 14459 -- procedure for handling follow-up issues
Message-ID: <C1D0177D-4E10-45CC-A4EE-B86E51B985B1@anu.edu.au>

Although the specific behaviour that was reported has been fixed, bugs 
remain in Sweave's processing of comment lines when keep.source=TRUE

This is in some senses a follow-up from earlier bugs.  Hence the query --
what is the preferred procedure, to submit a new bug report?  (Another option 
might be to add a comment to the web page for bug 14459.)

Is there now a preference to submit via the web page, rather than send a message
to r-bugs at r-project.org?  If so, the relevant paragraph in the FAQ surely requires 
updating:

<<<
On Unix-like systems a bug report can be generated using the function bug.report(). This automatically includes the version information and sends the bug to the correct address. Alternatively the bug report can be emailed to R-bugs at R-project.org or submitted to the Web page at http://bugs.R-project.org/. Please try including results of sessionInfo() in your bug report.
>>>

I have posted files test10.Rnw, test11.Rnw, and test12.Rnw that demonstrate the bugs at 
http://www.maths.anu.edu.au/~johnm/r/issues/
The output files test10.tex, test11.tex and test12.tex are from r53870 on 
x86_64-apple-darwin9.8.0/x86_64 (64-bit)

test10.Rnw has a code chunk that begins and ends with a comment.  
An NA appears following the final comment.  This disappears if I
remove the initial comment line.

test11.Rnw follows a comment line with a named code chunk.  The
comment line does not appear in the output.

test12.Rnw places a line of code between the comment line and the
named code chunk.  The comment line does now appear in the output.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


From jorismeys at gmail.com  Tue Dec 21 14:50:05 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 21 Dec 2010 14:50:05 +0100
Subject: [Rd] Warning message when items of Hmisc are masked by loading a
	package.
Message-ID: <AANLkTimEH1erHL28M_wmqfAXJpphSCR-P=CB4FU4P1fy@mail.gmail.com>

I've noticed that I get a warning message every time a package masks
some functions from Hmisc. The warning message says :

Warning message:
In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist attributes

This happens with eg:
library(plyr)
library(xtable)

I think I've seen this passing by before, but I'm not sure any more.
Just thought I'd mention it.
Cheers
Joris

> R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "2"

$minor
[1] "12.1"

$year
[1] "2010"

$month
[1] "12"

$day
[1] "16"

$`svn rev`
[1] "53855"

$language
[1] "R"

$version.string
[1] "R version 2.12.1 (2010-12-16)"

> Sys.info()
     sysname      release      version     nodename      machine
 login         user
   "Windows"      "7 x64" "build 7600"  "JFMEYS-PC"        "x86"
"Joris"      "Joris"

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Tue Dec 21 14:51:11 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 21 Dec 2010 14:51:11 +0100
Subject: [Rd] Warning message when items of Hmisc are masked by loading
	a package.
In-Reply-To: <AANLkTimEH1erHL28M_wmqfAXJpphSCR-P=CB4FU4P1fy@mail.gmail.com>
References: <AANLkTimEH1erHL28M_wmqfAXJpphSCR-P=CB4FU4P1fy@mail.gmail.com>
Message-ID: <AANLkTimgMsOOYesJ0sZ_8mOg8ENwo6=haUgiriYn7H2B@mail.gmail.com>

PS : This did not happen in R 2.12.0, it just occured when I installed
the new R version today.
Cheers
Joris

On Tue, Dec 21, 2010 at 2:50 PM, Joris Meys <jorismeys at gmail.com> wrote:
> I've noticed that I get a warning message every time a package masks
> some functions from Hmisc. The warning message says :
>
> Warning message:
> In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist attributes
>
> This happens with eg:
> library(plyr)
> library(xtable)
>
> I think I've seen this passing by before, but I'm not sure any more.
> Just thought I'd mention it.
> Cheers
> Joris
>
>> R.Version()
> $platform
> [1] "i386-pc-mingw32"
>
> $arch
> [1] "i386"
>
> $os
> [1] "mingw32"
>
> $system
> [1] "i386, mingw32"
>
> $status
> [1] ""
>
> $major
> [1] "2"
>
> $minor
> [1] "12.1"
>
> $year
> [1] "2010"
>
> $month
> [1] "12"
>
> $day
> [1] "16"
>
> $`svn rev`
> [1] "53855"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 2.12.1 (2010-12-16)"
>
>> Sys.info()
> ? ? sysname ? ? ?release ? ? ?version ? ? nodename ? ? ?machine
> ?login ? ? ? ? user
> ? "Windows" ? ? ?"7 x64" "build 7600" ?"JFMEYS-PC" ? ? ? ?"x86"
> "Joris" ? ? ?"Joris"
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From murdoch.duncan at gmail.com  Tue Dec 21 15:14:24 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Dec 2010 09:14:24 -0500
Subject: [Rd] Bug report 14459 -- procedure for handling follow-up issues
In-Reply-To: <C1D0177D-4E10-45CC-A4EE-B86E51B985B1@anu.edu.au>
References: <C1D0177D-4E10-45CC-A4EE-B86E51B985B1@anu.edu.au>
Message-ID: <4D10B640.3000700@gmail.com>

On 21/12/2010 3:23 AM, John Maindonald wrote:
> Although the specific behaviour that was reported has been fixed, bugs
> remain in Sweave's processing of comment lines when keep.source=TRUE
>
> This is in some senses a follow-up from earlier bugs.  Hence the query --
> what is the preferred procedure, to submit a new bug report?  (Another option
> might be to add a comment to the web page for bug 14459.)
>
> Is there now a preference to submit via the web page, rather than send a message
> to r-bugs at r-project.org?  If so, the relevant paragraph in the FAQ surely requires
> updating:
>
> <<<
> On Unix-like systems a bug report can be generated using the function bug.report(). This automatically includes the version information and sends the bug to the correct address. Alternatively the bug report can be emailed to R-bugs at R-project.org or submitted to the Web page at http://bugs.R-project.org/. Please try including results of sessionInfo() in your bug report.
>>>>
>
> I have posted files test10.Rnw, test11.Rnw, and test12.Rnw that demonstrate the bugs at
> http://www.maths.anu.edu.au/~johnm/r/issues/
> The output files test10.tex, test11.tex and test12.tex are from r53870 on
> x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> test10.Rnw has a code chunk that begins and ends with a comment.
> An NA appears following the final comment.  This disappears if I
> remove the initial comment line.

This is now fixed.  It was a different bug than 14459.

> test11.Rnw follows a comment line with a named code chunk.  The
> comment line does not appear in the output.
>
> test12.Rnw places a line of code between the comment line and the
> named code chunk.  The comment line does now appear in the output.

These look like a different issue, and are still unfixed, and are 
unlikely to be fixed soon.

The problem is that the handling of source references in Sweave is 
messy, and needs a major cleanup, which takes time.  Between now and at 
least mid-February I won't have the time it would take, and I don't know 
anyone else who would do it.  So I would not bet on these fixes getting 
done before 2.13.0.

The problems I know about are these:

   - if you use a named chunk <<chunkname>> in another, you won't get
leading and trailing comments on the named chunk.

   - if you mix named chunks and \SweaveInput, you won't get the 
original source at all in the expanded chunks.

Your examples look like the first of these.  I had thought the comments 
had to be in the chunk to get lost, but apparently not.

Just to make priorities clear:  in the short term I will fix bugs where 
NAs show up inappropriately.  I will not fix bugs involving dropping 
leading or trailing comments when there are simple workarounds.  (The 
workaround in your case is not to use the named chunk.)

Duncan Murdoch


>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Tue Dec 21 17:03:32 2010
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 21 Dec 2010 17:03:32 +0100
Subject: [Rd] Warning message when items of Hmisc are masked by loading
	a package.
In-Reply-To: <C7690A34-2C29-4B93-B2F6-2FD1F06BE9F2@comcast.net>
References: <AANLkTimEH1erHL28M_wmqfAXJpphSCR-P=CB4FU4P1fy@mail.gmail.com>
	<AANLkTimgMsOOYesJ0sZ_8mOg8ENwo6=haUgiriYn7H2B@mail.gmail.com>
	<C7690A34-2C29-4B93-B2F6-2FD1F06BE9F2@comcast.net>
Message-ID: <AANLkTimL2QvKOVQrYk=7Mxg5QKU-zwa8=oCp0M30nu0r@mail.gmail.com>

I know the masking message is standard behaviour. It is the warning mesage

> Warning message:
> In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist attributes

that puzzles me. And that's something I noticed only in 2.12.1

Cheers
Joris


On Tue, Dec 21, 2010 at 4:59 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> I thought that was standard behavior? It's been happening when I load Hmisc
> since the dawn of time (or 3 years anyway.... back to R 2.8.0 at least.)
> ?Hmisc masks some function(s) in survival.
>
> #----------
> Attaching package: 'Hmisc'
>
> The following object(s) are masked from 'package:survival':
>
> ? ?untangle.specials
>
> The following object(s) are masked from 'package:base':
>
> ? ?format.pval, round.POSIXt, trunc.POSIXt, units
>
>
> Attaching package: 'rms'
>
> The following object(s) are masked from 'package:survival':
>
> ? ?Surv
> #---------------
>
> It only seems fair that if you later mask functions in Hmisc that you also
> get a warning:
>
>
> #----------------
>> library (reshape)
> Loading required package: plyr
>
> Attaching package: 'plyr'
>
> The following object(s) are masked from 'package:Hmisc':
>
> ? ?is.discrete, summarize
>
>
> Attaching package: 'reshape'
>
> The following object(s) are masked from 'package:plyr':
>
> ? ?round_any
>
> #-----------------
>
> --
> David.
>
>
>
> On Dec 21, 2010, at 8:51 AM, Joris Meys wrote:
>
>> PS : This did not happen in R 2.12.0, it just occured when I installed
>> the new R version today.
>> Cheers
>> Joris
>>
>> On Tue, Dec 21, 2010 at 2:50 PM, Joris Meys <jorismeys at gmail.com> wrote:
>>>
>>> I've noticed that I get a warning message every time a package masks
>>> some functions from Hmisc. The warning message says :
>>>
>>> Warning message:
>>> In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist
>>> attributes
>>>
>>> This happens with eg:
>>> library(plyr)
>>> library(xtable)
>>>
>>> I think I've seen this passing by before, but I'm not sure any more.
>>> Just thought I'd mention it.
>>> Cheers
>>> Joris
>>>
>>>> R.Version()
>>>
>>> $platform
>>> [1] "i386-pc-mingw32"
>>>
>>> $arch
>>> [1] "i386"
>>>
>>> $os
>>> [1] "mingw32"
>>>
>>> $system
>>> [1] "i386, mingw32"
>>>
>>> $status
>>> [1] ""
>>>
>>> $major
>>> [1] "2"
>>>
>>> $minor
>>> [1] "12.1"
>>>
>>> $year
>>> [1] "2010"
>>>
>>> $month
>>> [1] "12"
>>>
>>> $day
>>> [1] "16"
>>>
>>> $`svn rev`
>>> [1] "53855"
>>>
>>> $language
>>> [1] "R"
>>>
>>> $version.string
>>> [1] "R version 2.12.1 (2010-12-16)"
>>>
>>>> Sys.info()
>>>
>>> ? ?sysname ? ? ?release ? ? ?version ? ? nodename ? ? ?machine
>>> ?login ? ? ? ? user
>>> ?"Windows" ? ? ?"7 x64" "build 7600" ?"JFMEYS-PC" ? ? ? ?"x86"
>>> "Joris" ? ? ?"Joris"
>>>
>>> --
>>> Joris Meys
>>> Statistical consultant
>
> David Winsemius, MD
> West Hartford, CT
>
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From pdalgd at gmail.com  Tue Dec 21 17:25:44 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Dec 2010 17:25:44 +0100
Subject: [Rd] Warning message when items of Hmisc are masked by loading
	a package.
In-Reply-To: <AANLkTimL2QvKOVQrYk=7Mxg5QKU-zwa8=oCp0M30nu0r@mail.gmail.com>
References: <AANLkTimEH1erHL28M_wmqfAXJpphSCR-P=CB4FU4P1fy@mail.gmail.com>
	<AANLkTimgMsOOYesJ0sZ_8mOg8ENwo6=haUgiriYn7H2B@mail.gmail.com>
	<C7690A34-2C29-4B93-B2F6-2FD1F06BE9F2@comcast.net>
	<AANLkTimL2QvKOVQrYk=7Mxg5QKU-zwa8=oCp0M30nu0r@mail.gmail.com>
Message-ID: <205AE2C4-A6AE-4A07-8494-041C9A9D5FE9@gmail.com>


On Dec 21, 2010, at 17:03 , Joris Meys wrote:

> I know the masking message is standard behaviour. It is the warning mesage
> 
>> Warning message:
>> In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist attributes
> 
> that puzzles me. And that's something I noticed only in 2.12.1
> 

It's a buglet in identical and somewhat older than that (as old as CHARSXP cacheing, I'd expect). It was fixed in R-devel a couple of weeks ago, but not deemed important enough to break code freeze for 2.12.1.

-pd

> Cheers
> Joris
> 
> 
> On Tue, Dec 21, 2010 at 4:59 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> I thought that was standard behavior? It's been happening when I load Hmisc
>> since the dawn of time (or 3 years anyway.... back to R 2.8.0 at least.)
>>  Hmisc masks some function(s) in survival.
>> 
>> #----------
>> Attaching package: 'Hmisc'
>> 
>> The following object(s) are masked from 'package:survival':
>> 
>>    untangle.specials
>> 
>> The following object(s) are masked from 'package:base':
>> 
>>    format.pval, round.POSIXt, trunc.POSIXt, units
>> 
>> 
>> Attaching package: 'rms'
>> 
>> The following object(s) are masked from 'package:survival':
>> 
>>    Surv
>> #---------------
>> 
>> It only seems fair that if you later mask functions in Hmisc that you also
>> get a warning:
>> 
>> 
>> #----------------
>>> library (reshape)
>> Loading required package: plyr
>> 
>> Attaching package: 'plyr'
>> 
>> The following object(s) are masked from 'package:Hmisc':
>> 
>>    is.discrete, summarize
>> 
>> 
>> Attaching package: 'reshape'
>> 
>> The following object(s) are masked from 'package:plyr':
>> 
>>    round_any
>> 
>> #-----------------
>> 
>> --
>> David.
>> 
>> 
>> 
>> On Dec 21, 2010, at 8:51 AM, Joris Meys wrote:
>> 
>>> PS : This did not happen in R 2.12.0, it just occured when I installed
>>> the new R version today.
>>> Cheers
>>> Joris
>>> 
>>> On Tue, Dec 21, 2010 at 2:50 PM, Joris Meys <jorismeys at gmail.com> wrote:
>>>> 
>>>> I've noticed that I get a warning message every time a package masks
>>>> some functions from Hmisc. The warning message says :
>>>> 
>>>> Warning message:
>>>> In identical(get(., i), get(., lib.pos)) : ignoring non-pairlist
>>>> attributes
>>>> 
>>>> This happens with eg:
>>>> library(plyr)
>>>> library(xtable)
>>>> 
>>>> I think I've seen this passing by before, but I'm not sure any more.
>>>> Just thought I'd mention it.
>>>> Cheers
>>>> Joris
>>>> 
>>>>> R.Version()
>>>> 
>>>> $platform
>>>> [1] "i386-pc-mingw32"
>>>> 
>>>> $arch
>>>> [1] "i386"
>>>> 
>>>> $os
>>>> [1] "mingw32"
>>>> 
>>>> $system
>>>> [1] "i386, mingw32"
>>>> 
>>>> $status
>>>> [1] ""
>>>> 
>>>> $major
>>>> [1] "2"
>>>> 
>>>> $minor
>>>> [1] "12.1"
>>>> 
>>>> $year
>>>> [1] "2010"
>>>> 
>>>> $month
>>>> [1] "12"
>>>> 
>>>> $day
>>>> [1] "16"
>>>> 
>>>> $`svn rev`
>>>> [1] "53855"
>>>> 
>>>> $language
>>>> [1] "R"
>>>> 
>>>> $version.string
>>>> [1] "R version 2.12.1 (2010-12-16)"
>>>> 
>>>>> Sys.info()
>>>> 
>>>>    sysname      release      version     nodename      machine
>>>>  login         user
>>>>  "Windows"      "7 x64" "build 7600"  "JFMEYS-PC"        "x86"
>>>> "Joris"      "Joris"
>>>> 
>>>> --
>>>> Joris Meys
>>>> Statistical consultant
>> 
>> David Winsemius, MD
>> West Hartford, CT
>> 
>> 
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kenahoo at gmail.com  Tue Dec 21 18:50:06 2010
From: kenahoo at gmail.com (Ken Williams)
Date: Tue, 21 Dec 2010 11:50:06 -0600
Subject: [Rd] Bug filed on unzip() function
Message-ID: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>

Hi,

A few days ago I filed a bug report on the unzip() function:

  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462

I haven't gotten any comments yet, so I thought I'd ask for comments
here.  I also see on the description of R-devel that the list "also
receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
I don't see it here.

Eventually I would like to help unzip() gain large-file support, such
as is offered by http://info-zip.org/UnZip.html version 6.0.  A
corresponding zip() function would be nice too.

Thanks.

 -Ken


From john.maindonald at anu.edu.au  Tue Dec 21 21:52:27 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 22 Dec 2010 09:52:27 +1300
Subject: [Rd] Bug report 14459 -- procedure for handling follow-up issues
In-Reply-To: <4D10B640.3000700@gmail.com>
References: <C1D0177D-4E10-45CC-A4EE-B86E51B985B1@anu.edu.au>
	<4D10B640.3000700@gmail.com>
Message-ID: <BD66CBE5-0DBA-4FC6-9556-7B76230467F3@anu.edu.au>

Thanks.  It is useful to have a list of items that are outstanding.
I will experiment a bit more, but may revert to using R-2.11.1 for
running Sweave().  Did any of these issues arise for R-2.11.1?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 22/12/2010, at 3:14 AM, Duncan Murdoch wrote:

> On 21/12/2010 3:23 AM, John Maindonald wrote:
>> Although the specific behaviour that was reported has been fixed, bugs
>> remain in Sweave's processing of comment lines when keep.source=TRUE
>> 
>> This is in some senses a follow-up from earlier bugs.  Hence the query --
>> what is the preferred procedure, to submit a new bug report?  (Another option
>> might be to add a comment to the web page for bug 14459.)
>> 
>> Is there now a preference to submit via the web page, rather than send a message
>> to r-bugs at r-project.org?  If so, the relevant paragraph in the FAQ surely requires
>> updating:
>> 
>> <<<
>> On Unix-like systems a bug report can be generated using the function bug.report(). This automatically includes the version information and sends the bug to the correct address. Alternatively the bug report can be emailed to R-bugs at R-project.org or submitted to the Web page at http://bugs.R-project.org/. Please try including results of sessionInfo() in your bug report.
>>>>> 
>> 
>> I have posted files test10.Rnw, test11.Rnw, and test12.Rnw that demonstrate the bugs at
>> http://www.maths.anu.edu.au/~johnm/r/issues/
>> The output files test10.tex, test11.tex and test12.tex are from r53870 on
>> x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> 
>> test10.Rnw has a code chunk that begins and ends with a comment.
>> An NA appears following the final comment.  This disappears if I
>> remove the initial comment line.
> 
> This is now fixed.  It was a different bug than 14459.
> 
>> test11.Rnw follows a comment line with a named code chunk.  The
>> comment line does not appear in the output.
>> 
>> test12.Rnw places a line of code between the comment line and the
>> named code chunk.  The comment line does now appear in the output.
> 
> These look like a different issue, and are still unfixed, and are unlikely to be fixed soon.
> 
> The problem is that the handling of source references in Sweave is messy, and needs a major cleanup, which takes time.  Between now and at least mid-February I won't have the time it would take, and I don't know anyone else who would do it.  So I would not bet on these fixes getting done before 2.13.0.
> 
> The problems I know about are these:
> 
> - if you use a named chunk <<chunkname>> in another, you won't get
> leading and trailing comments on the named chunk.
> 
> - if you mix named chunks and \SweaveInput, you won't get the original source at all in the expanded chunks.
> 
> Your examples look like the first of these.  I had thought the comments had to be in the chunk to get lost, but apparently not.
> 
> Just to make priorities clear:  in the short term I will fix bugs where NAs show up inappropriately.  I will not fix bugs involving dropping leading or trailing comments when there are simple workarounds.  (The workaround in your case is not to use the named chunk.)
> 
> Duncan Murdoch
> 
> 
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Tue Dec 21 21:59:34 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Dec 2010 15:59:34 -0500
Subject: [Rd] Bug report 14459 -- procedure for handling follow-up issues
In-Reply-To: <BD66CBE5-0DBA-4FC6-9556-7B76230467F3@anu.edu.au>
References: <C1D0177D-4E10-45CC-A4EE-B86E51B985B1@anu.edu.au>
	<4D10B640.3000700@gmail.com>
	<BD66CBE5-0DBA-4FC6-9556-7B76230467F3@anu.edu.au>
Message-ID: <4D111536.7060200@gmail.com>

On 21/12/2010 3:52 PM, John Maindonald wrote:
> Thanks.  It is useful to have a list of items that are outstanding.
> I will experiment a bit more, but may revert to using R-2.11.1 for
> running Sweave().  Did any of these issues arise for R-2.11.1?

That's up to you to figure out, but it would be more helpful to keep 
working with 2.12.1-patched, to flush out any more bugs, or to 
contribute patches.

Duncan Murdoch

> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 22/12/2010, at 3:14 AM, Duncan Murdoch wrote:
>
> >  On 21/12/2010 3:23 AM, John Maindonald wrote:
> >>  Although the specific behaviour that was reported has been fixed, bugs
> >>  remain in Sweave's processing of comment lines when keep.source=TRUE
> >>
> >>  This is in some senses a follow-up from earlier bugs.  Hence the query --
> >>  what is the preferred procedure, to submit a new bug report?  (Another option
> >>  might be to add a comment to the web page for bug 14459.)
> >>
> >>  Is there now a preference to submit via the web page, rather than send a message
> >>  to r-bugs at r-project.org?  If so, the relevant paragraph in the FAQ surely requires
> >>  updating:
> >>
> >>  <<<
> >>  On Unix-like systems a bug report can be generated using the function bug.report(). This automatically includes the version information and sends the bug to the correct address. Alternatively the bug report can be emailed to R-bugs at R-project.org or submitted to the Web page at http://bugs.R-project.org/. Please try including results of sessionInfo() in your bug report.
> >>>>>
> >>
> >>  I have posted files test10.Rnw, test11.Rnw, and test12.Rnw that demonstrate the bugs at
> >>  http://www.maths.anu.edu.au/~johnm/r/issues/
> >>  The output files test10.tex, test11.tex and test12.tex are from r53870 on
> >>  x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> >>
> >>  test10.Rnw has a code chunk that begins and ends with a comment.
> >>  An NA appears following the final comment.  This disappears if I
> >>  remove the initial comment line.
> >
> >  This is now fixed.  It was a different bug than 14459.
> >
> >>  test11.Rnw follows a comment line with a named code chunk.  The
> >>  comment line does not appear in the output.
> >>
> >>  test12.Rnw places a line of code between the comment line and the
> >>  named code chunk.  The comment line does now appear in the output.
> >
> >  These look like a different issue, and are still unfixed, and are unlikely to be fixed soon.
> >
> >  The problem is that the handling of source references in Sweave is messy, and needs a major cleanup, which takes time.  Between now and at least mid-February I won't have the time it would take, and I don't know anyone else who would do it.  So I would not bet on these fixes getting done before 2.13.0.
> >
> >  The problems I know about are these:
> >
> >  - if you use a named chunk<<chunkname>>  in another, you won't get
> >  leading and trailing comments on the named chunk.
> >
> >  - if you mix named chunks and \SweaveInput, you won't get the original source at all in the expanded chunks.
> >
> >  Your examples look like the first of these.  I had thought the comments had to be in the chunk to get lost, but apparently not.
> >
> >  Just to make priorities clear:  in the short term I will fix bugs where NAs show up inappropriately.  I will not fix bugs involving dropping leading or trailing comments when there are simple workarounds.  (The workaround in your case is not to use the named chunk.)
> >
> >  Duncan Murdoch
> >
> >
> >>
> >>  John Maindonald             email: john.maindonald at anu.edu.au
> >>  phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >>  Centre for Mathematics&   Its Applications, Room 1194,
> >>  John Dedman Mathematical Sciences Building (Building 27)
> >>  Australian National University, Canberra ACT 0200.
> >>  http://www.maths.anu.edu.au/~johnm
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From p.murrell at auckland.ac.nz  Tue Dec 21 23:16:26 2010
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 22 Dec 2010 11:16:26 +1300
Subject: [Rd] postscript failure manifests in plot.TukeyHSD
In-Reply-To: <4D0A1166.90203@gmail.com>
References: <C92F6B8D.1439C%jari.oksanen@oulu.fi> <4D0A1166.90203@gmail.com>
Message-ID: <4D11273A.108@auckland.ac.nz>

Hi

On 17/12/2010 2:17 a.m., Ben Bolker wrote:
> On 10-12-16 12:09 AM, Jari Oksanen wrote:
>> On 16/12/10 04:24 AM, "Paul Murrell"<p.murrell at auckland.ac.nz>  wrote:
>>
>>> Hi
>>>
>>> According to the PostScript Language Reference Manual and the PDF
>>> Reference, in both PDF and PostScript ...
>>>
>>> ... a line width of zero is valid, but not recommended (and is clearly
>>> not supported by some viewers).
>>>
>>> ... a line dash pattern cannot be specified as all zero lengths.
>>> (So, because R generates the line dash pattern proportional to the line
>>> width, a specification of lwd=0 and
>>> lty=anything-other-than-"solid"-or-"none" does not make sense.)
>>>
>>> I think three fixes are required:
>>>
>>> (i)  Enforce a minimum line width of 0.01 (mainly because that is not
>>> zero, but also because that is the smallest value greater than zero when
>>> you round to 2dp like the PDF and PostScript devices do and it's still
>>> REALLY thin).
>>>
>>> (ii) If the line dash pattern ends up as all zeroes (to 2dp), because
>>> the line width is so small (thin), force the dash pattern to "solid"
>>> instead.
>>>
>>> (iii) plot.TukeyHSD() should not use lwd=0  (0.5 is plenty difference to
>>> be obviously "lighter" than the main plot lines)
>>>
>>> I will commit these unless there are better suggestions or bitter
>>> objections.
>>>
>> Paul,
>>
>> The difference between working previous (of R 2.11.1) and failing
>> current-still-yesterday (R 2.12.1 RC) was:
>>
>> $ diff -U2 oldtukeyplot.ps /Volumes/TIKKU/tukeyplot.ps
>> --- oldtukeyplot.ps    2010-12-14 12:06:07.000000000 +0200
>> +++ /Volumes/TIKKU/tukeyplot.ps    2010-12-14 12:13:32.000000000 +0200
>> @@ -172,5 +172,5 @@
>>   0 setgray
>>   0.00 setlinewidth
>> -[ 3.00 5.00] 0 setdash
>> +[ 0.00 0.00] 0 setdash
>>   np
>>   660.06 91.44 m
>>
>> So 0.00 setlinewidth worked, but [0.00 0.00] 0 setdash failed. Assuming
>> PostScript is anything like English, it is the all-zero dash that caused the
>> failure.

Thanks Jari.  Since the PDF and PostScript references recommend NOT 
using 0 line width I think it is still worthwhile enforcing a lower limit.

>> Cheers, Jari Oksanen
>
>    Yes; I think Paul's fix #2 does this, and fixes #1 and #3 are trying
> to avoid problems in the future ...

Thanks for your help with this Ben and for the documentation 
suggestions.  The fixes have now been committed to the development version.

Paul

>    cheers
>      Ben Bolker

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From wht_crl at yahoo.com  Wed Dec 22 18:27:59 2010
From: wht_crl at yahoo.com (carol white)
Date: Wed, 22 Dec 2010 09:27:59 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
Message-ID: <695094.94551.qm@web62005.mail.re1.yahoo.com>

Hi,
I created a Sweave file (see below). when I want to convert tex 
file generated from it into pdf, I get error message as follows:

> texi2dvi("test.tex", pdf=TRUE)
Error in texi2dvi("test.tex", pdf = TRUE) : 
  Running 'texi2dvi' on 'test.tex' failed.
LaTeX errors:
! Undefined control sequence.
l.8 \begin
          {Schunk}
? 
! Interruption.
! Interruption.
<to be read again> 
                   {
l.8 \begin{
           Schunk}
! Undefined control sequence.
l.9 \begin
          {Sinput}
The control sequence at the end of the top line
of your error message was never \def'ed. If you have
------------------------
test.Rnw

\usepackage{Sweave}
\ documentclass [ a4paper ]{ article }
\ title { Sweave Example 1}
\ begin { document }
\ maketitle
In this example we embed parts of the examples from the
help page into a \ LaTeX {} document :
<<a>>=
y=2
y = y +1
@
which shows that the location parameter of the Ozone
distribution varies significantly from month to month . Finally we
include a boxplot of the data :

\end{ document }


From murdoch.duncan at gmail.com  Wed Dec 22 18:42:07 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 22 Dec 2010 12:42:07 -0500
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <695094.94551.qm@web62005.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
Message-ID: <4D12386F.8010102@gmail.com>

On 22/12/2010 12:27 PM, carol white wrote:
> Hi,
> I created a Sweave file (see below). when I want to convert tex
> file generated from it into pdf, I get error message as follows:
>
> >  texi2dvi("test.tex", pdf=TRUE)
> Error in texi2dvi("test.tex", pdf = TRUE) :
>    Running 'texi2dvi' on 'test.tex' failed.
> LaTeX errors:
> ! Undefined control sequence.
> l.8 \begin
>            {Schunk}

The Schunk, Sinput, and Soutput environments are defined in Sweave 
package.  Something went wrong and latex didn't find them, either 
because it didn't find Sweave.sty, or because it did, but that file has 
been messed up.


> ?
> ! Interruption.
> ! Interruption.
> <to be read again>
>                     {
> l.8 \begin{
>             Schunk}
> ! Undefined control sequence.
> l.9 \begin
>            {Sinput}
> The control sequence at the end of the top line
> of your error message was never \def'ed. If you have
> ------------------------
> test.Rnw
>
> \usepackage{Sweave}
> \ documentclass [ a4paper ]{ article }
> \ title { Sweave Example 1}
> \ begin { document }
> \ maketitle

Are there really spaces between the backslashes and the macros?  I think 
that doesn't work.  You should also have the \usepackage{Sweave} line 
after the opening \documentclass line.

Duncan Murdoch

> In this example we embed parts of the examples from the
> help page into a \ LaTeX {} document :
> <<a>>=
> y=2
> y = y +1
> @
> which shows that the location parameter of the Ozone
> distribution varies significantly from month to month . Finally we
> include a boxplot of the data :
>
> \end{ document }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wht_crl at yahoo.com  Wed Dec 22 19:30:36 2010
From: wht_crl at yahoo.com (carol white)
Date: Wed, 22 Dec 2010 10:30:36 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <4D12386F.8010102@gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
Message-ID: <406979.19878.qm@web62004.mail.re1.yahoo.com>

Should the Sweave package be in /usr/share/texmf/tex/latex/? How about 
Sweave.sty?

Thanks



----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Wed, December 22, 2010 6:42:07 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 22/12/2010 12:27 PM, carol white wrote:
> Hi,
> I created a Sweave file (see below). when I want to convert tex
> file generated from it into pdf, I get error message as follows:
> 
> >  texi2dvi("test.tex", pdf=TRUE)
> Error in texi2dvi("test.tex", pdf = TRUE) :
>    Running 'texi2dvi' on 'test.tex' failed.
> LaTeX errors:
> ! Undefined control sequence.
> l.8 \begin
>            {Schunk}

The Schunk, Sinput, and Soutput environments are defined in Sweave package.  
Something went wrong and latex didn't find them, either because it didn't find 
Sweave.sty, or because it did, but that file has been messed up.


> ?
> ! Interruption.
> ! Interruption.
> <to be read again>
>                     {
> l.8 \begin{
>             Schunk}
> ! Undefined control sequence.
> l.9 \begin
>            {Sinput}
> The control sequence at the end of the top line
> of your error message was never \def'ed. If you have
> ------------------------
> test.Rnw
> 
> \usepackage{Sweave}
> \ documentclass [ a4paper ]{ article }
> \ title { Sweave Example 1}
> \ begin { document }
> \ maketitle

Are there really spaces between the backslashes and the macros?  I think that 
doesn't work.  You should also have the \usepackage{Sweave} line after the 
opening \documentclass line.

Duncan Murdoch

> In this example we embed parts of the examples from the
> help page into a \ LaTeX {} document :
> <<a>>=
> y=2
> y = y +1
> @
> which shows that the location parameter of the Ozone
> distribution varies significantly from month to month . Finally we
> include a boxplot of the data :
> 
> \end{ document }
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From JHZhang at mdanderson.org  Wed Dec 22 20:04:38 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Wed, 22 Dec 2010 13:04:38 -0600
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <406979.19878.qm@web62004.mail.re1.yahoo.com>
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E6EFA3BD@DCPWVMBXC1VS2.mdanderson.edu>

Define the envvar LC_ALL with value "C" will reduce the texi2dvi error. Sweave.sty need to be at the right location depend on the kind of tex installation.

Jun

----- Original Message -----
From: carol white [mailto:wht_crl at yahoo.com]
Sent: Wednesday, December 22, 2010 12:30 PM
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: r-devel at r-project.org <r-devel at r-project.org>
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

Should the Sweave package be in /usr/share/texmf/tex/latex/? How about 
Sweave.sty?

Thanks



----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Wed, December 22, 2010 6:42:07 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 22/12/2010 12:27 PM, carol white wrote:
> Hi,
> I created a Sweave file (see below). when I want to convert tex
> file generated from it into pdf, I get error message as follows:
> 
> >  texi2dvi("test.tex", pdf=TRUE)
> Error in texi2dvi("test.tex", pdf = TRUE) :
>    Running 'texi2dvi' on 'test.tex' failed.
> LaTeX errors:
> ! Undefined control sequence.
> l.8 \begin
>            {Schunk}

The Schunk, Sinput, and Soutput environments are defined in Sweave package.  
Something went wrong and latex didn't find them, either because it didn't find 
Sweave.sty, or because it did, but that file has been messed up.


> ?
> ! Interruption.
> ! Interruption.
> <to be read again>
>                     {
> l.8 \begin{
>             Schunk}
> ! Undefined control sequence.
> l.9 \begin
>            {Sinput}
> The control sequence at the end of the top line
> of your error message was never \def'ed. If you have
> ------------------------
> test.Rnw
> 
> \usepackage{Sweave}
> \ documentclass [ a4paper ]{ article }
> \ title { Sweave Example 1}
> \ begin { document }
> \ maketitle

Are there really spaces between the backslashes and the macros?  I think that 
doesn't work.  You should also have the \usepackage{Sweave} line after the 
opening \documentclass line.

Duncan Murdoch

> In this example we embed parts of the examples from the
> help page into a \ LaTeX {} document :
> <<a>>=
> y=2
> y = y +1
> @
> which shows that the location parameter of the Ozone
> distribution varies significantly from month to month . Finally we
> include a boxplot of the data :
> 
> \end{ document }
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Wed Dec 22 20:44:20 2010
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 22 Dec 2010 14:44:20 -0500
Subject: [Rd] Error checking in Sys.sleep
Message-ID: <AANLkTikHqmS4DpqLoL7AKeFaY5x3pONFb20arYS2z4w=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101222/033efec3/attachment.pl>

From murdoch.duncan at gmail.com  Wed Dec 22 22:33:01 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 22 Dec 2010 16:33:01 -0500
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <406979.19878.qm@web62004.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
Message-ID: <4D126E8D.4070303@gmail.com>

On 22/12/2010 1:30 PM, carol white wrote:
> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
> Sweave.sty?

I meant Sweave.sty, there's no separate Sweave package.  It should be in 
the R home directory, somewhere within share/texmf.

Duncan Murdoch

> Thanks
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 6:42:07 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 12:27 PM, carol white wrote:
> >  Hi,
> >  I created a Sweave file (see below). when I want to convert tex
> >  file generated from it into pdf, I get error message as follows:
> >
> >  >   texi2dvi("test.tex", pdf=TRUE)
> >  Error in texi2dvi("test.tex", pdf = TRUE) :
> >     Running 'texi2dvi' on 'test.tex' failed.
> >  LaTeX errors:
> >  ! Undefined control sequence.
> >  l.8 \begin
> >             {Schunk}
>
> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
> Something went wrong and latex didn't find them, either because it didn't find
> Sweave.sty, or because it did, but that file has been messed up.
>
>
> >  ?
> >  ! Interruption.
> >  ! Interruption.
> >  <to be read again>
> >                      {
> >  l.8 \begin{
> >              Schunk}
> >  ! Undefined control sequence.
> >  l.9 \begin
> >             {Sinput}
> >  The control sequence at the end of the top line
> >  of your error message was never \def'ed. If you have
> >  ------------------------
> >  test.Rnw
> >
> >  \usepackage{Sweave}
> >  \ documentclass [ a4paper ]{ article }
> >  \ title { Sweave Example 1}
> >  \ begin { document }
> >  \ maketitle
>
> Are there really spaces between the backslashes and the macros?  I think that
> doesn't work.  You should also have the \usepackage{Sweave} line after the
> opening \documentclass line.
>
> Duncan Murdoch
>
> >  In this example we embed parts of the examples from the
> >  help page into a \ LaTeX {} document :
> >  <<a>>=
> >  y=2
> >  y = y +1
> >  @
> >  which shows that the location parameter of the Ozone
> >  distribution varies significantly from month to month . Finally we
> >  include a boxplot of the data :
> >
> >  \end{ document }
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From d.scott at auckland.ac.nz  Wed Dec 22 23:35:43 2010
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 23 Dec 2010 11:35:43 +1300
Subject: [Rd] License statement
Message-ID: <4D127D3F.4030503@auckland.ac.nz>

  I am writing a package for a company for its internal use only.

What is an appropriate license statement for the DESCRIPTION file?

I would like a statement which reflects the private and proprietary 
nature of the package, giving copyright to the writer and the company. I 
also don't want to violate the licensing of R and the packages I am 
using (RODBC, ggplot2, zoo).

David Scott

-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From murdoch.duncan at gmail.com  Wed Dec 22 23:48:14 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 22 Dec 2010 17:48:14 -0500
Subject: [Rd] License statement
In-Reply-To: <4D127D3F.4030503@auckland.ac.nz>
References: <4D127D3F.4030503@auckland.ac.nz>
Message-ID: <4D12802E.2010809@gmail.com>

On 22/12/2010 5:35 PM, David Scott wrote:
>    I am writing a package for a company for its internal use only.
>
> What is an appropriate license statement for the DESCRIPTION file?

I think "Internal use only, not for distribution" is reasonable.  The 
copyright statement is separate from the license; you can list that 
somewhere else.

>
> I would like a statement which reflects the private and proprietary
> nature of the package, giving copyright to the writer and the company. I
> also don't want to violate the licensing of R and the packages I am
> using (RODBC, ggplot2, zoo).

I don't know the license terms of those packages, but the license of R 
lets you use it with your own private code with very few restrictions. 
The restrictions come if you choose to make copies or modifications of R 
and give or sell them to people.  So if you are giving this company your 
own package, we don't care how you license it to them.

If you are putting together an installer that includes both R and the 
package, then I would say you must license the package under the GPL, 
and make the source code available to the company you're giving it to. 
You needn't distribute it to anyone else, but you can't stop the company 
from doing so.  So if it is private because you don't want it released 
but the company might want to redistribute it, then don't package it 
with R.  If it is private because the company doesn't want it released, 
then license it in whatever way you and they agree is reasonable.

But don't trust what I write as legal advice.

Duncan Murdoch


From scott at aitrus.org  Thu Dec 23 03:04:13 2010
From: scott at aitrus.org (Scott Gonyea)
Date: Wed, 22 Dec 2010 18:04:13 -0800
Subject: [Rd] License statement
In-Reply-To: <4D127D3F.4030503@auckland.ac.nz>
References: <4D127D3F.4030503@auckland.ac.nz>
Message-ID: <EC90680B-2B36-466F-A269-D1D7D5D1ADA9@aitrus.org>

Heh.  That's annoying.  The R Mailing List should really set the "reply-to" header.

I wrote two e-mail, so here they are:


There's a 'source' command in R, so I should not use that word.  If you're not copying out chunks of code and inserting them, you own the code itself.  No one can somehow take that away from you, unless they paid you to write it and your contract does not say that you own it.

The big issue is "bundling."  ie, creating a .tgz with all of the R packages AND your stuff (source code OR binary), IF your licenses are incompatible AND you intend to distribute your new "package"--that is, distribution external from whichever entity claims ownership.

Scott


Which was a correction to:


The issue is the bundling of the code, contained inside those packages.  As long as you're not sourcing material from inside them, license it how you want.  If you want, your license should be stamped at the top of your source files with something like:

# [COMPANY] CONFIDENTIAL. DISTRIBUTION OF THIS SOURCE CODE IS PROHIBITED. [HR POLICY]

Scott


Scott^3

On Dec 22, 2010, at 2:35 PM, David Scott wrote:

> I am writing a package for a company for its internal use only.
> 
> What is an appropriate license statement for the DESCRIPTION file?
> 
> I would like a statement which reflects the private and proprietary nature of the package, giving copyright to the writer and the company. I also don't want to violate the licensing of R and the packages I am using (RODBC, ggplot2, zoo).
> 
> David Scott
> 
> -- 
> _________________________________________________________________
> David Scott	Department of Statistics
> 		The University of Auckland, PB 92019
> 		Auckland 1142,    NEW ZEALAND
> Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
> Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018
> 
> Director of Consulting, Department of Statistics
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wht_crl at yahoo.com  Thu Dec 23 11:26:17 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Dec 2010 02:26:17 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <4D126E8D.4070303@gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
Message-ID: <108778.25309.qm@web62001.mail.re1.yahoo.com>

When I copied Sweave.sty in the directory where I ran R, I didn't have any 
error. But this is not the good solution as R can be run in any folder.

I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc folder 
in my R package to create the vignette. I ran R CMD check and it doesn find 
texi2dvi.



----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Wed, December 22, 2010 10:33:01 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 22/12/2010 1:30 PM, carol white wrote:
> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
> Sweave.sty?

I meant Sweave.sty, there's no separate Sweave package.  It should be in 
the R home directory, somewhere within share/texmf.

Duncan Murdoch

> Thanks
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 6:42:07 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 12:27 PM, carol white wrote:
> >  Hi,
> >  I created a Sweave file (see below). when I want to convert tex
> >  file generated from it into pdf, I get error message as follows:
> >
> >  >   texi2dvi("test.tex", pdf=TRUE)
> >  Error in texi2dvi("test.tex", pdf = TRUE) :
> >     Running 'texi2dvi' on 'test.tex' failed.
> >  LaTeX errors:
> >  ! Undefined control sequence.
> >  l.8 \begin
> >             {Schunk}
>
> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
> Something went wrong and latex didn't find them, either because it didn't find
> Sweave.sty, or because it did, but that file has been messed up.
>
>
> >  ?
> >  ! Interruption.
> >  ! Interruption.
> >  <to be read again>
> >                      {
> >  l.8 \begin{
> >              Schunk}
> >  ! Undefined control sequence.
> >  l.9 \begin
> >             {Sinput}
> >  The control sequence at the end of the top line
> >  of your error message was never \def'ed. If you have
> >  ------------------------
> >  test.Rnw
> >
> >  \usepackage{Sweave}
> >  \ documentclass [ a4paper ]{ article }
> >  \ title { Sweave Example 1}
> >  \ begin { document }
> >  \ maketitle
>
> Are there really spaces between the backslashes and the macros?  I think that
> doesn't work.  You should also have the \usepackage{Sweave} line after the
> opening \documentclass line.
>
> Duncan Murdoch
>
> >  In this example we embed parts of the examples from the
> >  help page into a \ LaTeX {} document :
> >  <<a>>=
> >  y=2
> >  y = y +1
> >  @
> >  which shows that the location parameter of the Ozone
> >  distribution varies significantly from month to month . Finally we
> >  include a boxplot of the data :
> >
> >  \end{ document }
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From wht_crl at yahoo.com  Thu Dec 23 11:47:45 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Dec 2010 02:47:45 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file-cont.
In-Reply-To: <4D126E8D.4070303@gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
Message-ID: <778215.50829.qm@web62004.mail.re1.yahoo.com>

I also copied Sweave.sty in the directory of my Rnw file (according to 
http://www.stat.uni-muenchen.de/~leisch/Sweave/FAQ.html) but texi2dvi not found 
when I ran R CMD check. I also found this solution inconvenient because if one 
develops different R packages, he shouldn't copy the Sweave.sty in all 
directores containing Rnw file. 




----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Wed, December 22, 2010 10:33:01 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 22/12/2010 1:30 PM, carol white wrote:
> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
> Sweave.sty?

I meant Sweave.sty, there's no separate Sweave package.  It should be in 
the R home directory, somewhere within share/texmf.

Duncan Murdoch

> Thanks
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 6:42:07 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 12:27 PM, carol white wrote:
> >  Hi,
> >  I created a Sweave file (see below). when I want to convert tex
> >  file generated from it into pdf, I get error message as follows:
> >
> >  >   texi2dvi("test.tex", pdf=TRUE)
> >  Error in texi2dvi("test.tex", pdf = TRUE) :
> >     Running 'texi2dvi' on 'test.tex' failed.
> >  LaTeX errors:
> >  ! Undefined control sequence.
> >  l.8 \begin
> >             {Schunk}
>
> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
> Something went wrong and latex didn't find them, either because it didn't find
> Sweave.sty, or because it did, but that file has been messed up.
>
>
> >  ?
> >  ! Interruption.
> >  ! Interruption.
> >  <to be read again>
> >                      {
> >  l.8 \begin{
> >              Schunk}
> >  ! Undefined control sequence.
> >  l.9 \begin
> >             {Sinput}
> >  The control sequence at the end of the top line
> >  of your error message was never \def'ed. If you have
> >  ------------------------
> >  test.Rnw
> >
> >  \usepackage{Sweave}
> >  \ documentclass [ a4paper ]{ article }
> >  \ title { Sweave Example 1}
> >  \ begin { document }
> >  \ maketitle
>
> Are there really spaces between the backslashes and the macros?  I think that
> doesn't work.  You should also have the \usepackage{Sweave} line after the
> opening \documentclass line.
>
> Duncan Murdoch
>
> >  In this example we embed parts of the examples from the
> >  help page into a \ LaTeX {} document :
> >  <<a>>=
> >  y=2
> >  y = y +1
> >  @
> >  which shows that the location parameter of the Ozone
> >  distribution varies significantly from month to month . Finally we
> >  include a boxplot of the data :
> >
> >  \end{ document }
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From ligges at statistik.tu-dortmund.de  Thu Dec 23 12:03:43 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 23 Dec 2010 12:03:43 +0100
Subject: [Rd] Error in generating sweave-tex -> pdf file-cont.
In-Reply-To: <778215.50829.qm@web62004.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>	<4D12386F.8010102@gmail.com>	<406979.19878.qm@web62004.mail.re1.yahoo.com>	<4D126E8D.4070303@gmail.com>
	<778215.50829.qm@web62004.mail.re1.yahoo.com>
Message-ID: <4D132C8F.2020503@statistik.tu-dortmund.de>



On 23.12.2010 11:47, carol white wrote:
> I also copied Sweave.sty in the directory of my Rnw file (according to
> http://www.stat.uni-muenchen.de/~leisch/Sweave/FAQ.html) but texi2dvi not found
> when I ran R CMD check. I also found this solution inconvenient because if one
> develops different R packages, he shouldn't copy the Sweave.sty in all
> directores containing Rnw file.


You can also add the R subdirectory that includes Sweave.sty and freinds 
to the search path for your TeX distribution.
In that case you won't need to pay attention on Sweave.sty upgrades.

Uwe Ligges



>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 10:33:01 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 1:30 PM, carol white wrote:
>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>> Sweave.sty?
>
> I meant Sweave.sty, there's no separate Sweave package.  It should be in
> the R home directory, somewhere within share/texmf.
>
> Duncan Murdoch
>
>> Thanks
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Wed, December 22, 2010 6:42:07 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>
>> On 22/12/2010 12:27 PM, carol white wrote:
>>>   Hi,
>>>   I created a Sweave file (see below). when I want to convert tex
>>>   file generated from it into pdf, I get error message as follows:
>>>
>>>   >    texi2dvi("test.tex", pdf=TRUE)
>>>   Error in texi2dvi("test.tex", pdf = TRUE) :
>>>      Running 'texi2dvi' on 'test.tex' failed.
>>>   LaTeX errors:
>>>   ! Undefined control sequence.
>>>   l.8 \begin
>>>              {Schunk}
>>
>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>> Something went wrong and latex didn't find them, either because it didn't find
>> Sweave.sty, or because it did, but that file has been messed up.
>>
>>
>>>   ?
>>>   ! Interruption.
>>>   ! Interruption.
>>>   <to be read again>
>>>                       {
>>>   l.8 \begin{
>>>               Schunk}
>>>   ! Undefined control sequence.
>>>   l.9 \begin
>>>              {Sinput}
>>>   The control sequence at the end of the top line
>>>   of your error message was never \def'ed. If you have
>>>   ------------------------
>>>   test.Rnw
>>>
>>>   \usepackage{Sweave}
>>>   \ documentclass [ a4paper ]{ article }
>>>   \ title { Sweave Example 1}
>>>   \ begin { document }
>>>   \ maketitle
>>
>> Are there really spaces between the backslashes and the macros?  I think that
>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>> opening \documentclass line.
>>
>> Duncan Murdoch
>>
>>>   In this example we embed parts of the examples from the
>>>   help page into a \ LaTeX {} document :
>>>   <<a>>=
>>>   y=2
>>>   y = y +1
>>>   @
>>>   which shows that the location parameter of the Ozone
>>>   distribution varies significantly from month to month . Finally we
>>>   include a boxplot of the data :
>>>
>>>   \end{ document }
>>>
>>>   ______________________________________________
>>>   R-devel at r-project.org mailing list
>>>   https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Dec 23 13:21:14 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Dec 2010 07:21:14 -0500
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <108778.25309.qm@web62001.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
Message-ID: <4D133EBA.2030408@gmail.com>

On 23/12/2010 5:26 AM, carol white wrote:
> When I copied Sweave.sty in the directory where I ran R, I didn't have any
> error. But this is not the good solution as R can be run in any folder.
>
> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc folder
> in my R package to create the vignette. I ran R CMD check and it doesn find
> texi2dvi.

texi2dvi is both a function name in R (in the tools package) and a GNU 
utility that comes with texinfo and some TeX distributions, but 
apparently not with yours.  See the R Installation and Administration 
manual for suggestions on where to get it.  If that doesn't help, you 
might get help on this list by stating the versions of everything you're 
using: R, your OS, and TeX.

Duncan Murdoch

>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 10:33:01 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 1:30 PM, carol white wrote:
>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>> Sweave.sty?
>
> I meant Sweave.sty, there's no separate Sweave package.  It should be in
> the R home directory, somewhere within share/texmf.
>
> Duncan Murdoch
>
>> Thanks
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Wed, December 22, 2010 6:42:07 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>
>> On 22/12/2010 12:27 PM, carol white wrote:
>>>   Hi,
>>>   I created a Sweave file (see below). when I want to convert tex
>>>   file generated from it into pdf, I get error message as follows:
>>>
>>>   >    texi2dvi("test.tex", pdf=TRUE)
>>>   Error in texi2dvi("test.tex", pdf = TRUE) :
>>>      Running 'texi2dvi' on 'test.tex' failed.
>>>   LaTeX errors:
>>>   ! Undefined control sequence.
>>>   l.8 \begin
>>>              {Schunk}
>>
>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>> Something went wrong and latex didn't find them, either because it didn't find
>> Sweave.sty, or because it did, but that file has been messed up.
>>
>>
>>>   ?
>>>   ! Interruption.
>>>   ! Interruption.
>>>   <to be read again>
>>>                       {
>>>   l.8 \begin{
>>>               Schunk}
>>>   ! Undefined control sequence.
>>>   l.9 \begin
>>>              {Sinput}
>>>   The control sequence at the end of the top line
>>>   of your error message was never \def'ed. If you have
>>>   ------------------------
>>>   test.Rnw
>>>
>>>   \usepackage{Sweave}
>>>   \ documentclass [ a4paper ]{ article }
>>>   \ title { Sweave Example 1}
>>>   \ begin { document }
>>>   \ maketitle
>>
>> Are there really spaces between the backslashes and the macros?  I think that
>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>> opening \documentclass line.
>>
>> Duncan Murdoch
>>
>>>   In this example we embed parts of the examples from the
>>>   help page into a \ LaTeX {} document :
>>>   <<a>>=
>>>   y=2
>>>   y = y +1
>>>   @
>>>   which shows that the location parameter of the Ozone
>>>   distribution varies significantly from month to month . Finally we
>>>   include a boxplot of the data :
>>>
>>>   \end{ document }
>>>
>>>   ______________________________________________
>>>   R-devel at r-project.org mailing list
>>>   https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
>
>


From gavin.simpson at ucl.ac.uk  Thu Dec 23 13:32:59 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 23 Dec 2010 12:32:59 +0000
Subject: [Rd] License statement
In-Reply-To: <EC90680B-2B36-466F-A269-D1D7D5D1ADA9@aitrus.org>
References: <4D127D3F.4030503@auckland.ac.nz>
	<EC90680B-2B36-466F-A269-D1D7D5D1ADA9@aitrus.org>
Message-ID: <1293107579.2415.8.camel@desktop.localdomain>

On Wed, 2010-12-22 at 18:04 -0800, Scott Gonyea wrote:
> Heh.  That's annoying.  The R Mailing List should really set the
> "reply-to" header.

No it shouldn't, if you mean set the list as the reply-to address that
i. If I want to reply to a message you sent, I Reply to you. If I want
that reply to go to all recipients of *your* message I Reply-All
instead. Users should think about where their messages go not blindly
click things in their mailer.

I am on one list where the Reply-To header *is* set (to the list) and
you would not believe the amount of crap, personal replies we get there
because users click Reply without thinking and send their stuff to the
list.

G

> I wrote two e-mail, so here they are:
> 
> 
> There's a 'source' command in R, so I should not use that word.  If
> you're not copying out chunks of code and inserting them, you own the
> code itself.  No one can somehow take that away from you, unless they
> paid you to write it and your contract does not say that you own it.
> 
> The big issue is "bundling."  ie, creating a .tgz with all of the R
> packages AND your stuff (source code OR binary), IF your licenses are
> incompatible AND you intend to distribute your new "package"--that is,
> distribution external from whichever entity claims ownership.
> 
> Scott
> 
> 
> Which was a correction to:
> 
> 
> The issue is the bundling of the code, contained inside those
> packages.  As long as you're not sourcing material from inside them,
> license it how you want.  If you want, your license should be stamped
> at the top of your source files with something like:
> 
> # [COMPANY] CONFIDENTIAL. DISTRIBUTION OF THIS SOURCE CODE IS
> PROHIBITED. [HR POLICY]
> 
> Scott
> 
> 
> Scott^3
> 
> On Dec 22, 2010, at 2:35 PM, David Scott wrote:
> 
> > I am writing a package for a company for its internal use only.
> > 
> > What is an appropriate license statement for the DESCRIPTION file?
> > 
> > I would like a statement which reflects the private and proprietary nature of the package, giving copyright to the writer and the company. I also don't want to violate the licensing of R and the packages I am using (RODBC, ggplot2, zoo).
> > 
> > David Scott
> > 
> > -- 
> > _________________________________________________________________
> > David Scott	Department of Statistics
> > 		The University of Auckland, PB 92019
> > 		Auckland 1142,    NEW ZEALAND
> > Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
> > Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018
> > 
> > Director of Consulting, Department of Statistics
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ligges at statistik.tu-dortmund.de  Thu Dec 23 13:44:15 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 23 Dec 2010 13:44:15 +0100
Subject: [Rd] Bug filed on unzip() function
In-Reply-To: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
Message-ID: <4D13441F.9010906@statistik.tu-dortmund.de>

This message contains a good question:

Is there any reason why the bug reports are no longer mailed to R-devel?
I'd appreciate to get a notice what is going on in the bug repository 
without having to look on those web pages.

Best wishes,
Uwe



On 21.12.2010 18:50, Ken Williams wrote:
> Hi,
>
> A few days ago I filed a bug report on the unzip() function:
>
>    https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
>
> I haven't gotten any comments yet, so I thought I'd ask for comments
> here.  I also see on the description of R-devel that the list "also
> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
> I don't see it here.
>
> Eventually I would like to help unzip() gain large-file support, such
> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
> corresponding zip() function would be nice too.
>
> Thanks.
>
>   -Ken
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wht_crl at yahoo.com  Thu Dec 23 13:46:13 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Dec 2010 04:46:13 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <4D133EBA.2030408@gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
Message-ID: <744506.27662.qm@web62001.mail.re1.yahoo.com>

R installation and admin manual doesn't tell where to save Sweave.sty. 

I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)

Cheers,



----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Thu, December 23, 2010 1:21:14 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 23/12/2010 5:26 AM, carol white wrote:
> When I copied Sweave.sty in the directory where I ran R, I didn't have any
> error. But this is not the good solution as R can be run in any folder.
>
> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc 
folder
> in my R package to create the vignette. I ran R CMD check and it doesn find
> texi2dvi.

texi2dvi is both a function name in R (in the tools package) and a GNU 
utility that comes with texinfo and some TeX distributions, but 
apparently not with yours.  See the R Installation and Administration 
manual for suggestions on where to get it.  If that doesn't help, you 
might get help on this list by stating the versions of everything you're 
using: R, your OS, and TeX.

Duncan Murdoch

>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Wed, December 22, 2010 10:33:01 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 22/12/2010 1:30 PM, carol white wrote:
>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>> Sweave.sty?
>
> I meant Sweave.sty, there's no separate Sweave package.  It should be in
> the R home directory, somewhere within share/texmf.
>
> Duncan Murdoch
>
>> Thanks
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Wed, December 22, 2010 6:42:07 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>
>> On 22/12/2010 12:27 PM, carol white wrote:
>>>   Hi,
>>>   I created a Sweave file (see below). when I want to convert tex
>>>   file generated from it into pdf, I get error message as follows:
>>>
>>>   >    texi2dvi("test.tex", pdf=TRUE)
>>>   Error in texi2dvi("test.tex", pdf = TRUE) :
>>>      Running 'texi2dvi' on 'test.tex' failed.
>>>   LaTeX errors:
>>>   ! Undefined control sequence.
>>>   l.8 \begin
>>>              {Schunk}
>>
>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>> Something went wrong and latex didn't find them, either because it didn't 
find
>> Sweave.sty, or because it did, but that file has been messed up.
>>
>>
>>>   ?
>>>   ! Interruption.
>>>   ! Interruption.
>>>   <to be read again>
>>>                       {
>>>   l.8 \begin{
>>>               Schunk}
>>>   ! Undefined control sequence.
>>>   l.9 \begin
>>>              {Sinput}
>>>   The control sequence at the end of the top line
>>>   of your error message was never \def'ed. If you have
>>>   ------------------------
>>>   test.Rnw
>>>
>>>   \usepackage{Sweave}
>>>   \ documentclass [ a4paper ]{ article }
>>>   \ title { Sweave Example 1}
>>>   \ begin { document }
>>>   \ maketitle
>>
>> Are there really spaces between the backslashes and the macros?  I think that
>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>> opening \documentclass line.
>>
>> Duncan Murdoch
>>
>>>   In this example we embed parts of the examples from the
>>>   help page into a \ LaTeX {} document :
>>>   <<a>>=
>>>   y=2
>>>   y = y +1
>>>   @
>>>   which shows that the location parameter of the Ozone
>>>   distribution varies significantly from month to month . Finally we
>>>   include a boxplot of the data :
>>>
>>>   \end{ document }
>>>
>>>   ______________________________________________
>>>  R-devel at r-project.org mailing list
>>>  https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
>
>


From murdoch.duncan at gmail.com  Thu Dec 23 14:01:26 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Dec 2010 08:01:26 -0500
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <744506.27662.qm@web62001.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
	<744506.27662.qm@web62001.mail.re1.yahoo.com>
Message-ID: <4D134826.3000806@gmail.com>

On 23/12/2010 7:46 AM, carol white wrote:
> R installation and admin manual doesn't tell where to save Sweave.sty.

You shouldn't need to move it.


> I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)

That R is pretty old.  I wouldn't be surprised if the current release 
handled things better.  But the thing that appears to be missing on your 
system is texinfo, and that's not part of R.

Duncan Murdoch

>
> Cheers,
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Thu, December 23, 2010 1:21:14 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 23/12/2010 5:26 AM, carol white wrote:
>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>> error. But this is not the good solution as R can be run in any folder.
>>
>> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc
> folder
>> in my R package to create the vignette. I ran R CMD check and it doesn find
>> texi2dvi.
>
> texi2dvi is both a function name in R (in the tools package) and a GNU
> utility that comes with texinfo and some TeX distributions, but
> apparently not with yours.  See the R Installation and Administration
> manual for suggestions on where to get it.  If that doesn't help, you
> might get help on this list by stating the versions of everything you're
> using: R, your OS, and TeX.
>
> Duncan Murdoch
>
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Wed, December 22, 2010 10:33:01 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>
>> On 22/12/2010 1:30 PM, carol white wrote:
>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>> Sweave.sty?
>>
>> I meant Sweave.sty, there's no separate Sweave package.  It should be in
>> the R home directory, somewhere within share/texmf.
>>
>> Duncan Murdoch
>>
>>> Thanks
>>>
>>>
>>>
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex ->    pdf file
>>>
>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>    Hi,
>>>>    I created a Sweave file (see below). when I want to convert tex
>>>>    file generated from it into pdf, I get error message as follows:
>>>>
>>>>    >     texi2dvi("test.tex", pdf=TRUE)
>>>>    Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>       Running 'texi2dvi' on 'test.tex' failed.
>>>>    LaTeX errors:
>>>>    ! Undefined control sequence.
>>>>    l.8 \begin
>>>>               {Schunk}
>>>
>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>> Something went wrong and latex didn't find them, either because it didn't
> find
>>> Sweave.sty, or because it did, but that file has been messed up.
>>>
>>>
>>>>    ?
>>>>    ! Interruption.
>>>>    ! Interruption.
>>>>    <to be read again>
>>>>                        {
>>>>    l.8 \begin{
>>>>                Schunk}
>>>>    ! Undefined control sequence.
>>>>    l.9 \begin
>>>>               {Sinput}
>>>>    The control sequence at the end of the top line
>>>>    of your error message was never \def'ed. If you have
>>>>    ------------------------
>>>>    test.Rnw
>>>>
>>>>    \usepackage{Sweave}
>>>>    \ documentclass [ a4paper ]{ article }
>>>>    \ title { Sweave Example 1}
>>>>    \ begin { document }
>>>>    \ maketitle
>>>
>>> Are there really spaces between the backslashes and the macros?  I think that
>>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>>> opening \documentclass line.
>>>
>>> Duncan Murdoch
>>>
>>>>    In this example we embed parts of the examples from the
>>>>    help page into a \ LaTeX {} document :
>>>>    <<a>>=
>>>>    y=2
>>>>    y = y +1
>>>>    @
>>>>    which shows that the location parameter of the Ozone
>>>>    distribution varies significantly from month to month . Finally we
>>>>    include a boxplot of the data :
>>>>
>>>>    \end{ document }
>>>>
>>>>    ______________________________________________
>>>>   R-devel at r-project.org mailing list
>>>>   https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>
>>
>>
>
>
>


From wht_crl at yahoo.com  Thu Dec 23 14:14:08 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Dec 2010 05:14:08 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <4D134826.3000806@gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
	<744506.27662.qm@web62001.mail.re1.yahoo.com>
	<4D134826.3000806@gmail.com>
Message-ID: <487879.49500.qm@web62001.mail.re1.yahoo.com>

Another question that I have is the following:

If I want to create the package vignette on a server for which I don't have 
admin rights to install Sweave.sty, where is the best place to save this file if 
I want to run from anywhere in my home directoy or do I have to put this file in 
a directory where I should always run from there?

I also attach Sweave.sty to check if it the right file.




----- Original Message ----
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Thu, December 23, 2010 2:01:26 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

On 23/12/2010 7:46 AM, carol white wrote:
> R installation and admin manual doesn't tell where to save Sweave.sty.

You shouldn't need to move it.


> I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)

That R is pretty old.  I wouldn't be surprised if the current release 
handled things better.  But the thing that appears to be missing on your 
system is texinfo, and that's not part of R.

Duncan Murdoch

>
> Cheers,
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch<murdoch.duncan at gmail.com>
> To: carol white<wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Thu, December 23, 2010 1:21:14 PM
> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>
> On 23/12/2010 5:26 AM, carol white wrote:
>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>> error. But this is not the good solution as R can be run in any folder.
>>
>> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc
> folder
>> in my R package to create the vignette. I ran R CMD check and it doesn find
>> texi2dvi.
>
> texi2dvi is both a function name in R (in the tools package) and a GNU
> utility that comes with texinfo and some TeX distributions, but
> apparently not with yours.  See the R Installation and Administration
> manual for suggestions on where to get it.  If that doesn't help, you
> might get help on this list by stating the versions of everything you're
> using: R, your OS, and TeX.
>
> Duncan Murdoch
>
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Wed, December 22, 2010 10:33:01 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>
>> On 22/12/2010 1:30 PM, carol white wrote:
>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>> Sweave.sty?
>>
>> I meant Sweave.sty, there's no separate Sweave package.  It should be in
>> the R home directory, somewhere within share/texmf.
>>
>> Duncan Murdoch
>>
>>> Thanks
>>>
>>>
>>>
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex ->    pdf file
>>>
>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>    Hi,
>>>>    I created a Sweave file (see below). when I want to convert tex
>>>>    file generated from it into pdf, I get error message as follows:
>>>>
>>>>    >     texi2dvi("test.tex", pdf=TRUE)
>>>>    Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>       Running 'texi2dvi' on 'test.tex' failed.
>>>>    LaTeX errors:
>>>>    ! Undefined control sequence.
>>>>    l.8 \begin
>>>>               {Schunk}
>>>
>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>> Something went wrong and latex didn't find them, either because it didn't
> find
>>> Sweave.sty, or because it did, but that file has been messed up.
>>>
>>>
>>>>    ?
>>>>    ! Interruption.
>>>>    ! Interruption.
>>>>    <to be read again>
>>>>                        {
>>>>    l.8 \begin{
>>>>                Schunk}
>>>>    ! Undefined control sequence.
>>>>    l.9 \begin
>>>>               {Sinput}
>>>>    The control sequence at the end of the top line
>>>>    of your error message was never \def'ed. If you have
>>>>    ------------------------
>>>>    test.Rnw
>>>>
>>>>    \usepackage{Sweave}
>>>>    \ documentclass [ a4paper ]{ article }
>>>>    \ title { Sweave Example 1}
>>>>    \ begin { document }
>>>>    \ maketitle
>>>
>>> Are there really spaces between the backslashes and the macros?  I think 
that
>>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>>> opening \documentclass line.
>>>
>>> Duncan Murdoch
>>>
>>>>    In this example we embed parts of the examples from the
>>>>    help page into a \ LaTeX {} document :
>>>>    <<a>>=
>>>>    y=2
>>>>    y = y +1
>>>>    @
>>>>    which shows that the location parameter of the Ozone
>>>>    distribution varies significantly from month to month . Finally we
>>>>    include a boxplot of the data :
>>>>
>>>>    \end{ document }
>>>>
>>>>    ______________________________________________
>>>>  R-devel at r-project.org mailing list
>>>>  https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>
>>
>>
>
>
>


      

From kasperdanielhansen at gmail.com  Thu Dec 23 17:13:58 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 23 Dec 2010 08:13:58 -0800
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <487879.49500.qm@web62001.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
	<744506.27662.qm@web62001.mail.re1.yahoo.com>
	<4D134826.3000806@gmail.com>
	<487879.49500.qm@web62001.mail.re1.yahoo.com>
Message-ID: <AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>

Hi Carol

As you now know, this is because per default R/Sweave puts the line
  \usepackage{Sweave}
in the generated tex file.  This means the tex file is "portable", but
it also implies that Sweave.sty needs to be "installed" in your tex
installation.  Or you can put the Sweave.sty in the directory of the
Rnw file since tex usually is set up to search the same directory.

An alternative is to get R to generate a line like
  \usepackage{FULL_PATH_TO_SWEAVE.STY}
in the tex document.  This implies that the tex file can only be
tex'ed on a setup where the Sweave.sty is at the same place - hence it
kind of break portability.  Now portability of the tex file does not
matter to many users - most of us think of the tex file as an
intermediate file and only care about the Rnw file and the final PDF.
You get this behaviour by setting the environment variable
  SWEAVE_STYLEPATH_DEFAULT
to
  TRUE
An easy way to do this is to include the following line in your .Rprofile
 Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")

This trick also fixes running Sweave on a system where you do not have
admin rights.

Kasper

On Thu, Dec 23, 2010 at 5:14 AM, carol white <wht_crl at yahoo.com> wrote:
> Another question that I have is the following:
>
> If I want to create the package vignette on a server for which I don't have
> admin rights to install Sweave.sty, where is the best place to save this file if
> I want to run from anywhere in my home directoy or do I have to put this file in
> a directory where I should always run from there?
>
> I also attach Sweave.sty to check if it the right file.
>
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: carol white <wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Thu, December 23, 2010 2:01:26 PM
> Subject: Re: [Rd] Error in generating sweave-tex -> pdf file
>
> On 23/12/2010 7:46 AM, carol white wrote:
>> R installation and admin manual doesn't tell where to save Sweave.sty.
>
> You shouldn't need to move it.
>
>
>> I use R 2.10.0, fedora 10 and, tex ?Version 3.141592-1.40.3 (Web2C 7.5.6)
>
> That R is pretty old. ?I wouldn't be surprised if the current release
> handled things better. ?But the thing that appears to be missing on your
> system is texinfo, and that's not part of R.
>
> Duncan Murdoch
>
>>
>> Cheers,
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Thu, December 23, 2010 1:21:14 PM
>> Subject: Re: [Rd] Error in generating sweave-tex -> ?pdf file
>>
>> On 23/12/2010 5:26 AM, carol white wrote:
>>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>>> error. But this is not the good solution as R can be run in any folder.
>>>
>>> I copied Sweave.sty in ?/usr/share/texmf/. I put my Rnw file in inst/doc
>> folder
>>> in my R package to create the vignette. I ran R CMD check and it doesn find
>>> texi2dvi.
>>
>> texi2dvi is both a function name in R (in the tools package) and a GNU
>> utility that comes with texinfo and some TeX distributions, but
>> apparently not with yours. ?See the R Installation and Administration
>> manual for suggestions on where to get it. ?If that doesn't help, you
>> might get help on this list by stating the versions of everything you're
>> using: R, your OS, and TeX.
>>
>> Duncan Murdoch
>>
>>>
>>>
>>>
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wed, December 22, 2010 10:33:01 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex -> ? pdf file
>>>
>>> On 22/12/2010 1:30 PM, carol white wrote:
>>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>>> Sweave.sty?
>>>
>>> I meant Sweave.sty, there's no separate Sweave package. ?It should be in
>>> the R home directory, somewhere within share/texmf.
>>>
>>> Duncan Murdoch
>>>
>>>> Thanks
>>>>
>>>>
>>>>
>>>> ----- Original Message ----
>>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>>> To: carol white<wht_crl at yahoo.com>
>>>> Cc: r-devel at r-project.org
>>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>>> Subject: Re: [Rd] Error in generating sweave-tex -> ? ?pdf file
>>>>
>>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>> ? ?Hi,
>>>>> ? ?I created a Sweave file (see below). when I want to convert tex
>>>>> ? ?file generated from it into pdf, I get error message as follows:
>>>>>
>>>>> ? ?> ? ? texi2dvi("test.tex", pdf=TRUE)
>>>>> ? ?Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>> ? ? ? Running 'texi2dvi' on 'test.tex' failed.
>>>>> ? ?LaTeX errors:
>>>>> ? ?! Undefined control sequence.
>>>>> ? ?l.8 \begin
>>>>> ? ? ? ? ? ? ? {Schunk}
>>>>
>>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>>> Something went wrong and latex didn't find them, either because it didn't
>> find
>>>> Sweave.sty, or because it did, but that file has been messed up.
>>>>
>>>>
>>>>> ? ??
>>>>> ? ?! Interruption.
>>>>> ? ?! Interruption.
>>>>> ? ?<to be read again>
>>>>> ? ? ? ? ? ? ? ? ? ? ? ?{
>>>>> ? ?l.8 \begin{
>>>>> ? ? ? ? ? ? ? ?Schunk}
>>>>> ? ?! Undefined control sequence.
>>>>> ? ?l.9 \begin
>>>>> ? ? ? ? ? ? ? {Sinput}
>>>>> ? ?The control sequence at the end of the top line
>>>>> ? ?of your error message was never \def'ed. If you have
>>>>> ? ?------------------------
>>>>> ? ?test.Rnw
>>>>>
>>>>> ? ?\usepackage{Sweave}
>>>>> ? ?\ documentclass [ a4paper ]{ article }
>>>>> ? ?\ title { Sweave Example 1}
>>>>> ? ?\ begin { document }
>>>>> ? ?\ maketitle
>>>>
>>>> Are there really spaces between the backslashes and the macros? ?I think
> that
>>>> doesn't work. ?You should also have the \usepackage{Sweave} line after the
>>>> opening \documentclass line.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>> ? ?In this example we embed parts of the examples from the
>>>>> ? ?help page into a \ LaTeX {} document :
>>>>> ? ?<<a>>=
>>>>> ? ?y=2
>>>>> ? ?y = y +1
>>>>> ? ?@
>>>>> ? ?which shows that the location parameter of the Ozone
>>>>> ? ?distribution varies significantly from month to month . Finally we
>>>>> ? ?include a boxplot of the data :
>>>>>
>>>>> ? ?\end{ document }
>>>>>
>>>>> ? ?______________________________________________
>>>>> ?R-devel at r-project.org mailing list
>>>>> ?https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From marc_schwartz at me.com  Thu Dec 23 17:42:06 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Dec 2010 10:42:06 -0600
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
	<744506.27662.qm@web62001.mail.re1.yahoo.com>
	<4D134826.3000806@gmail.com>
	<487879.49500.qm@web62001.mail.re1.yahoo.com>
	<AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>
Message-ID: <39776546-FF40-4559-9B99-3869E9E6E06A@me.com>

Hi,

Sorry for the late entry here, but I just noted that Carol is running Fedora 10, which has not been actively supported for just over a year. It went End of Life (EOL) in December of 2009, which means that your Fedora 10 installation has been without bug/security fixes, application patches and other important updates since then.

The only actively supported released versions of Fedora are 13 and 14. So you should really update the underlying Fedora installation ASAP, which will also get you to R version 2.12.x, which is available via Fedora's yum updates for 13 and 14.

At this point, it would be prudent to move to Fedora 14, given that Fedora 13 will go EOL late next Spring after Fedora 15 is released. So you may as well give yourself a longer time frame of support, given Fedora's aggressive version update/EOL schedule.

HTH,

Marc Schwartz

On Dec 23, 2010, at 10:13 AM, Kasper Daniel Hansen wrote:

> Hi Carol
> 
> As you now know, this is because per default R/Sweave puts the line
>  \usepackage{Sweave}
> in the generated tex file.  This means the tex file is "portable", but
> it also implies that Sweave.sty needs to be "installed" in your tex
> installation.  Or you can put the Sweave.sty in the directory of the
> Rnw file since tex usually is set up to search the same directory.
> 
> An alternative is to get R to generate a line like
>  \usepackage{FULL_PATH_TO_SWEAVE.STY}
> in the tex document.  This implies that the tex file can only be
> tex'ed on a setup where the Sweave.sty is at the same place - hence it
> kind of break portability.  Now portability of the tex file does not
> matter to many users - most of us think of the tex file as an
> intermediate file and only care about the Rnw file and the final PDF.
> You get this behaviour by setting the environment variable
>  SWEAVE_STYLEPATH_DEFAULT
> to
>  TRUE
> An easy way to do this is to include the following line in your .Rprofile
> Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")
> 
> This trick also fixes running Sweave on a system where you do not have
> admin rights.
> 
> Kasper
> 
> On Thu, Dec 23, 2010 at 5:14 AM, carol white <wht_crl at yahoo.com> wrote:
>> Another question that I have is the following:
>> 
>> If I want to create the package vignette on a server for which I don't have
>> admin rights to install Sweave.sty, where is the best place to save this file if
>> I want to run from anywhere in my home directoy or do I have to put this file in
>> a directory where I should always run from there?
>> 
>> I also attach Sweave.sty to check if it the right file.
>> 
>> 
>> 
>> 
>> ----- Original Message ----
>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>> To: carol white <wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Thu, December 23, 2010 2:01:26 PM
>> Subject: Re: [Rd] Error in generating sweave-tex -> pdf file
>> 
>> On 23/12/2010 7:46 AM, carol white wrote:
>>> R installation and admin manual doesn't tell where to save Sweave.sty.
>> 
>> You shouldn't need to move it.
>> 
>> 
>>> I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)
>> 
>> That R is pretty old.  I wouldn't be surprised if the current release
>> handled things better.  But the thing that appears to be missing on your
>> system is texinfo, and that's not part of R.
>> 
>> Duncan Murdoch
>> 
>>> 
>>> Cheers,
>>> 
>>> 
>>> 
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Thu, December 23, 2010 1:21:14 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>>> 
>>> On 23/12/2010 5:26 AM, carol white wrote:
>>>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>>>> error. But this is not the good solution as R can be run in any folder.
>>>> 
>>>> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc
>>> folder
>>>> in my R package to create the vignette. I ran R CMD check and it doesn find
>>>> texi2dvi.
>>> 
>>> texi2dvi is both a function name in R (in the tools package) and a GNU
>>> utility that comes with texinfo and some TeX distributions, but
>>> apparently not with yours.  See the R Installation and Administration
>>> manual for suggestions on where to get it.  If that doesn't help, you
>>> might get help on this list by stating the versions of everything you're
>>> using: R, your OS, and TeX.
>>> 
>>> Duncan Murdoch
>>> 
>>>> 
>>>> 
>>>> 
>>>> ----- Original Message ----
>>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>>> To: carol white<wht_crl at yahoo.com>
>>>> Cc: r-devel at r-project.org
>>>> Sent: Wed, December 22, 2010 10:33:01 PM
>>>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>>> 
>>>> On 22/12/2010 1:30 PM, carol white wrote:
>>>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>>>> Sweave.sty?
>>>> 
>>>> I meant Sweave.sty, there's no separate Sweave package.  It should be in
>>>> the R home directory, somewhere within share/texmf.
>>>> 
>>>> Duncan Murdoch
>>>> 
>>>>> Thanks
>>>>> 
>>>>> 
>>>>> 
>>>>> ----- Original Message ----
>>>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>>>> To: carol white<wht_crl at yahoo.com>
>>>>> Cc: r-devel at r-project.org
>>>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>>>> Subject: Re: [Rd] Error in generating sweave-tex ->    pdf file
>>>>> 
>>>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>>>    Hi,
>>>>>>    I created a Sweave file (see below). when I want to convert tex
>>>>>>    file generated from it into pdf, I get error message as follows:
>>>>>> 
>>>>>>    >     texi2dvi("test.tex", pdf=TRUE)
>>>>>>    Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>>>       Running 'texi2dvi' on 'test.tex' failed.
>>>>>>    LaTeX errors:
>>>>>>    ! Undefined control sequence.
>>>>>>    l.8 \begin
>>>>>>               {Schunk}
>>>>> 
>>>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>>>> Something went wrong and latex didn't find them, either because it didn't
>>> find
>>>>> Sweave.sty, or because it did, but that file has been messed up.
>>>>> 
>>>>> 
>>>>>>    ?
>>>>>>    ! Interruption.
>>>>>>    ! Interruption.
>>>>>>    <to be read again>
>>>>>>                        {
>>>>>>    l.8 \begin{
>>>>>>                Schunk}
>>>>>>    ! Undefined control sequence.
>>>>>>    l.9 \begin
>>>>>>               {Sinput}
>>>>>>    The control sequence at the end of the top line
>>>>>>    of your error message was never \def'ed. If you have
>>>>>>    ------------------------
>>>>>>    test.Rnw
>>>>>> 
>>>>>>    \usepackage{Sweave}
>>>>>>    \ documentclass [ a4paper ]{ article }
>>>>>>    \ title { Sweave Example 1}
>>>>>>    \ begin { document }
>>>>>>    \ maketitle
>>>>> 
>>>>> Are there really spaces between the backslashes and the macros?  I think
>> that
>>>>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>>>>> opening \documentclass line.
>>>>> 
>>>>> Duncan Murdoch
>>>>> 
>>>>>>    In this example we embed parts of the examples from the
>>>>>>    help page into a \ LaTeX {} document :
>>>>>>    <<a>>=
>>>>>>    y=2
>>>>>>    y = y +1
>>>>>>    @
>>>>>>    which shows that the location parameter of the Ozone
>>>>>>    distribution varies significantly from month to month . Finally we
>>>>>>    include a boxplot of the data :
>>>>>> 
>>>>>>    \end{ document }


From wht_crl at yahoo.com  Thu Dec 23 19:02:19 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Dec 2010 10:02:19 -0800 (PST)
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>
	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>
	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>
	<744506.27662.qm@web62001.mail.re1.yahoo.com>
	<4D134826.3000806@gmail.com>
	<487879.49500.qm@web62001.mail.re1.yahoo.com>
	<AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>
Message-ID: <554326.29855.qm@web62007.mail.re1.yahoo.com>

Thanks for all replies.

I found Sweave.sty in the system files of my local machine. It was sitting in 
/usr/share/R/texmf/. The content is the same as the file sent previously. So the 
file has always been in the system but R has been unable to find it.

I put the sty file in the home directory, in the folder where the Rnw file is, 
used \usepackage{/usr/share/R/texmf/Sweave.sty},
set SWEAVE_STYLEPATH_DEFAUL = TRUE, 

still with R CMD check, texi2dvi can't be found.

Recall that before I started to create the package vignette, I could generated 
the pdf file of the tex file by invoking texi2dvi in an R session after loading 
library(tools).

Best,

Carol


----- Original Message ----
From: Kasper Daniel Hansen <kasperdanielhansen at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-devel at r-project.org
Sent: Thu, December 23, 2010 5:13:58 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

Hi Carol

As you now know, this is because per default R/Sweave puts the line
  \usepackage{Sweave}
in the generated tex file.  This means the tex file is "portable", but
it also implies that Sweave.sty needs to be "installed" in your tex
installation.  Or you can put the Sweave.sty in the directory of the
Rnw file since tex usually is set up to search the same directory.

An alternative is to get R to generate a line like
  \usepackage{FULL_PATH_TO_SWEAVE.STY}
in the tex document.  This implies that the tex file can only be
tex'ed on a setup where the Sweave.sty is at the same place - hence it
kind of break portability.  Now portability of the tex file does not
matter to many users - most of us think of the tex file as an
intermediate file and only care about the Rnw file and the final PDF.
You get this behaviour by setting the environment variable
  SWEAVE_STYLEPATH_DEFAULT
to
  TRUE
An easy way to do this is to include the following line in your .Rprofile
Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")

This trick also fixes running Sweave on a system where you do not have
admin rights.

Kasper

On Thu, Dec 23, 2010 at 5:14 AM, carol white <wht_crl at yahoo.com> wrote:
> Another question that I have is the following:
>
> If I want to create the package vignette on a server for which I don't have
> admin rights to install Sweave.sty, where is the best place to save this file 
>if
> I want to run from anywhere in my home directoy or do I have to put this file 
>in
> a directory where I should always run from there?
>
> I also attach Sweave.sty to check if it the right file.
>
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: carol white <wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Thu, December 23, 2010 2:01:26 PM
> Subject: Re: [Rd] Error in generating sweave-tex -> pdf file
>
> On 23/12/2010 7:46 AM, carol white wrote:
>> R installation and admin manual doesn't tell where to save Sweave.sty.
>
> You shouldn't need to move it.
>
>
>> I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)
>
> That R is pretty old.  I wouldn't be surprised if the current release
> handled things better.  But the thing that appears to be missing on your
> system is texinfo, and that's not part of R.
>
> Duncan Murdoch
>
>>
>> Cheers,
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Thu, December 23, 2010 1:21:14 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>>
>> On 23/12/2010 5:26 AM, carol white wrote:
>>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>>> error. But this is not the good solution as R can be run in any folder.
>>>
>>> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc
>> folder
>>> in my R package to create the vignette. I ran R CMD check and it doesn find
>>> texi2dvi.
>>
>> texi2dvi is both a function name in R (in the tools package) and a GNU
>> utility that comes with texinfo and some TeX distributions, but
>> apparently not with yours.  See the R Installation and Administration
>> manual for suggestions on where to get it.  If that doesn't help, you
>> might get help on this list by stating the versions of everything you're
>> using: R, your OS, and TeX.
>>
>> Duncan Murdoch
>>
>>>
>>>
>>>
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wed, December 22, 2010 10:33:01 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>>
>>> On 22/12/2010 1:30 PM, carol white wrote:
>>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>>> Sweave.sty?
>>>
>>> I meant Sweave.sty, there's no separate Sweave package.  It should be in
>>> the R home directory, somewhere within share/texmf.
>>>
>>> Duncan Murdoch
>>>
>>>> Thanks
>>>>
>>>>
>>>>
>>>> ----- Original Message ----
>>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>>> To: carol white<wht_crl at yahoo.com>
>>>> Cc: r-devel at r-project.org
>>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>>> Subject: Re: [Rd] Error in generating sweave-tex ->    pdf file
>>>>
>>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>>    Hi,
>>>>>    I created a Sweave file (see below). when I want to convert tex
>>>>>    file generated from it into pdf, I get error message as follows:
>>>>>
>>>>>    >     texi2dvi("test.tex", pdf=TRUE)
>>>>>    Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>>       Running 'texi2dvi' on 'test.tex' failed.
>>>>>    LaTeX errors:
>>>>>    ! Undefined control sequence.
>>>>>    l.8 \begin
>>>>>               {Schunk}
>>>>
>>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>>> Something went wrong and latex didn't find them, either because it didn't
>> find
>>>> Sweave.sty, or because it did, but that file has been messed up.
>>>>
>>>>
>>>>>    ?
>>>>>    ! Interruption.
>>>>>    ! Interruption.
>>>>>    <to be read again>
>>>>>                        {
>>>>>    l.8 \begin{
>>>>>                Schunk}
>>>>>    ! Undefined control sequence.
>>>>>    l.9 \begin
>>>>>               {Sinput}
>>>>>    The control sequence at the end of the top line
>>>>>    of your error message was never \def'ed. If you have
>>>>>    ------------------------
>>>>>    test.Rnw
>>>>>
>>>>>    \usepackage{Sweave}
>>>>>    \ documentclass [ a4paper ]{ article }
>>>>>    \ title { Sweave Example 1}
>>>>>    \ begin { document }
>>>>>    \ maketitle
>>>>
>>>> Are there really spaces between the backslashes and the macros?  I think
> that
>>>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>>>> opening \documentclass line.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>    In this example we embed parts of the examples from the
>>>>>    help page into a \ LaTeX {} document :
>>>>>    <<a>>=
>>>>>    y=2
>>>>>    y = y +1
>>>>>    @
>>>>>    which shows that the location parameter of the Ozone
>>>>>    distribution varies significantly from month to month . Finally we
>>>>>    include a boxplot of the data :
>>>>>
>>>>>    \end{ document }
>>>>>
>>>>>    ______________________________________________
>>>>>  R-devel at r-project.org mailing list
>>>>>  https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From JHZhang at mdanderson.org  Thu Dec 23 20:31:51 2010
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Thu, 23 Dec 2010 13:31:51 -0600
Subject: [Rd] Error in generating sweave-tex -> pdf file
In-Reply-To: <554326.29855.qm@web62007.mail.re1.yahoo.com>
References: <695094.94551.qm@web62005.mail.re1.yahoo.com>
	<4D12386F.8010102@gmail.com>	<406979.19878.qm@web62004.mail.re1.yahoo.com>
	<4D126E8D.4070303@gmail.com>	<108778.25309.qm@web62001.mail.re1.yahoo.com>
	<4D133EBA.2030408@gmail.com>	<744506.27662.qm@web62001.mail.re1.yahoo.com>
	<4D134826.3000806@gmail.com>	<487879.49500.qm@web62001.mail.re1.yahoo.com>
	<AANLkTi=6aD5j21NDpuOzRnWUrtkr8dwhzOFifK9Wu5wN@mail.gmail.com>
	<554326.29855.qm@web62007.mail.re1.yahoo.com>
Message-ID: <5685E4FBA752A441B1975A77A77CD64824E765A2F4@DCPWVMBXC1VS2.mdanderson.edu>

The sub-package texinfo-tex is freely available on the internet. Install it, and /usr/bin/texi2dvi should be one of its components. You may need admin privilege to do that. 

Jun

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of carol white
Sent: Thursday, December 23, 2010 12:02 PM
To: Kasper Daniel Hansen
Cc: r-devel at r-project.org
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

Thanks for all replies.

I found Sweave.sty in the system files of my local machine. It was sitting in 
/usr/share/R/texmf/. The content is the same as the file sent previously. So the 
file has always been in the system but R has been unable to find it.

I put the sty file in the home directory, in the folder where the Rnw file is, 
used \usepackage{/usr/share/R/texmf/Sweave.sty},
set SWEAVE_STYLEPATH_DEFAUL = TRUE, 

still with R CMD check, texi2dvi can't be found.

Recall that before I started to create the package vignette, I could generated 
the pdf file of the tex file by invoking texi2dvi in an R session after loading 
library(tools).

Best,

Carol


----- Original Message ----
From: Kasper Daniel Hansen <kasperdanielhansen at gmail.com>
To: carol white <wht_crl at yahoo.com>
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-devel at r-project.org
Sent: Thu, December 23, 2010 5:13:58 PM
Subject: Re: [Rd] Error in generating sweave-tex -> pdf file

Hi Carol

As you now know, this is because per default R/Sweave puts the line
  \usepackage{Sweave}
in the generated tex file.  This means the tex file is "portable", but
it also implies that Sweave.sty needs to be "installed" in your tex
installation.  Or you can put the Sweave.sty in the directory of the
Rnw file since tex usually is set up to search the same directory.

An alternative is to get R to generate a line like
  \usepackage{FULL_PATH_TO_SWEAVE.STY}
in the tex document.  This implies that the tex file can only be
tex'ed on a setup where the Sweave.sty is at the same place - hence it
kind of break portability.  Now portability of the tex file does not
matter to many users - most of us think of the tex file as an
intermediate file and only care about the Rnw file and the final PDF.
You get this behaviour by setting the environment variable
  SWEAVE_STYLEPATH_DEFAULT
to
  TRUE
An easy way to do this is to include the following line in your .Rprofile
Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")

This trick also fixes running Sweave on a system where you do not have
admin rights.

Kasper

On Thu, Dec 23, 2010 at 5:14 AM, carol white <wht_crl at yahoo.com> wrote:
> Another question that I have is the following:
>
> If I want to create the package vignette on a server for which I don't have
> admin rights to install Sweave.sty, where is the best place to save this file 
>if
> I want to run from anywhere in my home directoy or do I have to put this file 
>in
> a directory where I should always run from there?
>
> I also attach Sweave.sty to check if it the right file.
>
>
>
>
> ----- Original Message ----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: carol white <wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Sent: Thu, December 23, 2010 2:01:26 PM
> Subject: Re: [Rd] Error in generating sweave-tex -> pdf file
>
> On 23/12/2010 7:46 AM, carol white wrote:
>> R installation and admin manual doesn't tell where to save Sweave.sty.
>
> You shouldn't need to move it.
>
>
>> I use R 2.10.0, fedora 10 and, tex  Version 3.141592-1.40.3 (Web2C 7.5.6)
>
> That R is pretty old.  I wouldn't be surprised if the current release
> handled things better.  But the thing that appears to be missing on your
> system is texinfo, and that's not part of R.
>
> Duncan Murdoch
>
>>
>> Cheers,
>>
>>
>>
>> ----- Original Message ----
>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>> To: carol white<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Sent: Thu, December 23, 2010 1:21:14 PM
>> Subject: Re: [Rd] Error in generating sweave-tex ->  pdf file
>>
>> On 23/12/2010 5:26 AM, carol white wrote:
>>> When I copied Sweave.sty in the directory where I ran R, I didn't have any
>>> error. But this is not the good solution as R can be run in any folder.
>>>
>>> I copied Sweave.sty in  /usr/share/texmf/. I put my Rnw file in inst/doc
>> folder
>>> in my R package to create the vignette. I ran R CMD check and it doesn find
>>> texi2dvi.
>>
>> texi2dvi is both a function name in R (in the tools package) and a GNU
>> utility that comes with texinfo and some TeX distributions, but
>> apparently not with yours.  See the R Installation and Administration
>> manual for suggestions on where to get it.  If that doesn't help, you
>> might get help on this list by stating the versions of everything you're
>> using: R, your OS, and TeX.
>>
>> Duncan Murdoch
>>
>>>
>>>
>>>
>>> ----- Original Message ----
>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>> To: carol white<wht_crl at yahoo.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wed, December 22, 2010 10:33:01 PM
>>> Subject: Re: [Rd] Error in generating sweave-tex ->   pdf file
>>>
>>> On 22/12/2010 1:30 PM, carol white wrote:
>>>> Should the Sweave package be in /usr/share/texmf/tex/latex/? How about
>>>> Sweave.sty?
>>>
>>> I meant Sweave.sty, there's no separate Sweave package.  It should be in
>>> the R home directory, somewhere within share/texmf.
>>>
>>> Duncan Murdoch
>>>
>>>> Thanks
>>>>
>>>>
>>>>
>>>> ----- Original Message ----
>>>> From: Duncan Murdoch<murdoch.duncan at gmail.com>
>>>> To: carol white<wht_crl at yahoo.com>
>>>> Cc: r-devel at r-project.org
>>>> Sent: Wed, December 22, 2010 6:42:07 PM
>>>> Subject: Re: [Rd] Error in generating sweave-tex ->    pdf file
>>>>
>>>> On 22/12/2010 12:27 PM, carol white wrote:
>>>>>    Hi,
>>>>>    I created a Sweave file (see below). when I want to convert tex
>>>>>    file generated from it into pdf, I get error message as follows:
>>>>>
>>>>>    >     texi2dvi("test.tex", pdf=TRUE)
>>>>>    Error in texi2dvi("test.tex", pdf = TRUE) :
>>>>>       Running 'texi2dvi' on 'test.tex' failed.
>>>>>    LaTeX errors:
>>>>>    ! Undefined control sequence.
>>>>>    l.8 \begin
>>>>>               {Schunk}
>>>>
>>>> The Schunk, Sinput, and Soutput environments are defined in Sweave package.
>>>> Something went wrong and latex didn't find them, either because it didn't
>> find
>>>> Sweave.sty, or because it did, but that file has been messed up.
>>>>
>>>>
>>>>>    ?
>>>>>    ! Interruption.
>>>>>    ! Interruption.
>>>>>    <to be read again>
>>>>>                        {
>>>>>    l.8 \begin{
>>>>>                Schunk}
>>>>>    ! Undefined control sequence.
>>>>>    l.9 \begin
>>>>>               {Sinput}
>>>>>    The control sequence at the end of the top line
>>>>>    of your error message was never \def'ed. If you have
>>>>>    ------------------------
>>>>>    test.Rnw
>>>>>
>>>>>    \usepackage{Sweave}
>>>>>    \ documentclass [ a4paper ]{ article }
>>>>>    \ title { Sweave Example 1}
>>>>>    \ begin { document }
>>>>>    \ maketitle
>>>>
>>>> Are there really spaces between the backslashes and the macros?  I think
> that
>>>> doesn't work.  You should also have the \usepackage{Sweave} line after the
>>>> opening \documentclass line.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>    In this example we embed parts of the examples from the
>>>>>    help page into a \ LaTeX {} document :
>>>>>    <<a>>=
>>>>>    y=2
>>>>>    y = y +1
>>>>>    @
>>>>>    which shows that the location parameter of the Ozone
>>>>>    distribution varies significantly from month to month . Finally we
>>>>>    include a boxplot of the data :
>>>>>
>>>>>    \end{ document }
>>>>>
>>>>>    ______________________________________________
>>>>>  R-devel at r-project.org mailing list
>>>>>  https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Dec 24 03:24:02 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 23 Dec 2010 21:24:02 -0500
Subject: [Rd] Bug filed on unzip() function
In-Reply-To: <4D13441F.9010906@statistik.tu-dortmund.de>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
Message-ID: <7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>

On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:

> This message contains a good question:
> 
> Is there any reason why the bug reports are no longer mailed to R-devel?

The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.

I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.


> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
> 

I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.

Cheers,
Simon



> 
> On 21.12.2010 18:50, Ken Williams wrote:
>> Hi,
>> 
>> A few days ago I filed a bug report on the unzip() function:
>> 
>>   https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
>> 
>> I haven't gotten any comments yet, so I thought I'd ask for comments
>> here.  I also see on the description of R-devel that the list "also
>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
>> I don't see it here.
>> 
>> Eventually I would like to help unzip() gain large-file support, such
>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
>> corresponding zip() function would be nice too.
>> 
>> Thanks.
>> 
>>  -Ken
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From marc_schwartz at me.com  Fri Dec 24 06:22:46 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Dec 2010 23:22:46 -0600
Subject: [Rd] Bug filed on unzip() function
In-Reply-To: <7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
Message-ID: <E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>

On Dec 23, 2010, at 8:24 PM, Simon Urbanek wrote:

> On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:
> 
>> This message contains a good question:
>> 
>> Is there any reason why the bug reports are no longer mailed to R-devel?
> 
> The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.
> 
> I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.
> 
> 
>> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
>> 
> 
> I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.
> 
> Cheers,
> Simon

I don't know what the volume of traffic would be from Bugzilla these days versus what it used to be from Jitterbug.

One of the issues with Jitterbug and the cc'ing of bug reports and comments to R-devel, is that the e-mails would frequently come from the participants in the bug report who were not subscribers to R-devel. That required that the R-devel moderators manually approve those e-mails, which added overhead. In fact, since moving to Bugzilla, the volume of manual approvals on R-devel has declined notably since those e-mails are no longer mirrored.

There is not an easy way to interact with Bugzilla via e-mail as there was with Jitterbug. The last time that I looked into this during the transition, it would require e-mails with a very specific formatting and name-value pair style entries in the message body, which could then be parsed by Bugzilla for inclusion into the underlying database. So one could not just reply to a Bugzilla bug report or comment with a free form e-mail as could be done with Jitterbug.

If an e-mail list mirror is desired, I would vote for a separate READ-ONLY list that folks could subscribe to and/or perhaps have an RSS feed that could be followed for updates. Making the list read-only would obviate situations where somebody replied to a bug report and/or comment via e-mail, where that reply would of course not make it into the Bugzilla repo thread, resulting in a loss of information.

With Bugzilla, the results of search queries generate an RSS feed link at the bottom of the query results page (see the "Feed" link), which can be subscribed to using one's favorite RSS reader. That would be one way of keeping track of new/open bug reports.

One could, if desired, create custom queries in Bugzilla using the Advanced Search functionality and then use the resultant RSS feed link to keep track of updates to the particular query result set.

Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.

That's my $0.02.

Regards,

Marc Schwartz

> 
> 
>> 
>> On 21.12.2010 18:50, Ken Williams wrote:
>>> Hi,
>>> 
>>> A few days ago I filed a bug report on the unzip() function:
>>> 
>>>  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
>>> 
>>> I haven't gotten any comments yet, so I thought I'd ask for comments
>>> here.  I also see on the description of R-devel that the list "also
>>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
>>> I don't see it here.
>>> 
>>> Eventually I would like to help unzip() gain large-file support, such
>>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
>>> corresponding zip() function would be nice too.
>>> 
>>> Thanks.
>>> 
>>> -Ken


From pburns at pburns.seanet.com  Fri Dec 24 11:27:23 2010
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 24 Dec 2010 10:27:23 +0000
Subject: [Rd] minor problem in strsplit help file
Message-ID: <4D14758B.9070009@pburns.seanet.com>

The 'extended' argument to 'strsplit'
has been removed, but it is still mentioned
in the argument items in the help file
for 'fixed' and 'perl'.

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From kenahoo at gmail.com  Fri Dec 24 17:24:19 2010
From: kenahoo at gmail.com (Ken Williams)
Date: Fri, 24 Dec 2010 10:24:19 -0600
Subject: [Rd] Bug filed on unzip() function
In-Reply-To: <E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
Message-ID: <AANLkTimUpiF=huAybBOys-NAASCF_Rz5NvB4WuQ1JdS=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101224/2485f2f4/attachment.pl>

From Simon.Urbanek at r-project.org  Fri Dec 24 17:32:11 2010
From: Simon.Urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Dec 2010 11:32:11 -0500
Subject: [Rd] Bugs e-mails and R-devel [Was: Bug filed on unzip() function]
In-Reply-To: <E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
Message-ID: <B931ADEC-E9E7-4E96-851D-1F3E11A28C67@r-project.org>

On Dec 24, 2010, at 12:22 AM, Marc Schwartz wrote:

> On Dec 23, 2010, at 8:24 PM, Simon Urbanek wrote:
> 
>> On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:
>> 
>>> This message contains a good question:
>>> 
>>> Is there any reason why the bug reports are no longer mailed to R-devel?
>> 
>> The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.
>> 
>> I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.
>> 
>> 
>>> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
>>> 
>> 
>> I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.
>> 
>> Cheers,
>> Simon
> 
> I don't know what the volume of traffic would be from Bugzilla these days versus what it used to be from Jitterbug.
> 
> One of the issues with Jitterbug and the cc'ing of bug reports and comments to R-devel, is that the e-mails would frequently come from the participants in the bug report who were not subscribers to R-devel. That required that the R-devel moderators manually approve those e-mails, which added overhead. In fact, since moving to Bugzilla, the volume of manual approvals on R-devel has declined notably since those e-mails are no longer mirrored.
> 

That is an interesting point and confirms my feeling that the dual-mode approach has serious implications.


> There is not an easy way to interact with Bugzilla via e-mail as there was with Jitterbug. The last time that I looked into this during the transition, it would require e-mails with a very specific formatting and name-value pair style entries in the message body, which could then be parsed by Bugzilla for inclusion into the underlying database. So one could not just reply to a Bugzilla bug report or comment with a free form e-mail as could be done with Jitterbug.
> 

We work around that for R-bugs by injecting the comments directly into the bugzilla database. The rationale is that no extra e-mail notification is needed since the e-mail (hopefully) went to all parties involved so bypassing bugzilla for the update is fine. So far it seemed to work just fine. (The only additional service I was thinking of would be to allow the change of status by e-mail - using some define keyword/phrase - so you don't have to go back to the website to close a bug).


> If an e-mail list mirror is desired, I would vote for a separate READ-ONLY list that folks could subscribe to and/or perhaps have an RSS feed that could be followed for updates. Making the list read-only would obviate situations where somebody replied to a bug report and/or comment via e-mail, where that reply would of course not make it into the Bugzilla repo thread, resulting in a loss of information.
> 

Maybe the reply-to could be R-bugs which would solve the reply issue, but the original issue of non-registered users replying would still remain with even bigger consequences (the replies would not even go to bugzilla). However, I could generate bounce e-mails for those, notifying the sender that he is not registered and thus his post will be discarded - not sure if that helps, though (and it may lead to issues with spammers getting replies). Also it would increase the traffic on R-bugs which would make manual screening (which is what I do at the moment for people that try to e-mail new reports to R-bugs) almost impossible.


> With Bugzilla, the results of search queries generate an RSS feed link at the bottom of the query results page (see the "Feed" link), which can be subscribed to using one's favorite RSS reader. That would be one way of keeping track of new/open bug reports.
> 

That sounds like a good idea to me - especially since it's there already ;).


> One could, if desired, create custom queries in Bugzilla using the Advanced Search functionality and then use the resultant RSS feed link to keep track of updates to the particular query result set.
> 
> Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.
> 

This is happening, but only to the assignees, so currently on R-core or to individuals.

Thanks for the comments,
Simon


> That's my $0.02.
> 
> Regards,
> 
> Marc Schwartz
> 
>> 
>> 
>>> 
>>> On 21.12.2010 18:50, Ken Williams wrote:
>>>> Hi,
>>>> 
>>>> A few days ago I filed a bug report on the unzip() function:
>>>> 
>>>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
>>>> 
>>>> I haven't gotten any comments yet, so I thought I'd ask for comments
>>>> here.  I also see on the description of R-devel that the list "also
>>>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
>>>> I don't see it here.
>>>> 
>>>> Eventually I would like to help unzip() gain large-file support, such
>>>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
>>>> corresponding zip() function would be nice too.
>>>> 
>>>> Thanks.
>>>> 
>>>> -Ken
> 
> 


From Simon.Urbanek at r-project.org  Fri Dec 24 18:51:58 2010
From: Simon.Urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Dec 2010 12:51:58 -0500
Subject: [Rd] Bug filed on unzip() function
In-Reply-To: <AANLkTimUpiF=huAybBOys-NAASCF_Rz5NvB4WuQ1JdS=@mail.gmail.com>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
	<AANLkTimUpiF=huAybBOys-NAASCF_Rz5NvB4WuQ1JdS=@mail.gmail.com>
Message-ID: <899068FB-0C72-4E5E-8EA2-701C26561929@r-project.org>

On Dec 24, 2010, at 11:24 AM, Ken Williams wrote:

> On Thu, Dec 23, 2010 at 11:22 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.
> 
> Well, as a concrete data point - nobody's yet commented on the bug report, or on this list, about the original issue I brought up:  https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
> 
> I haven't filed bug reports before, but in your experience does Warnocking like this happen frequently?
> 

Well, it's holiday time and quite few people are traveling, so chances of getting responses at this time of the year are quite low. The same applies for the August conference/travel time (IMHO). Since there is usually no more than one person that may take up on it, just that one person being away is enough for getting no response until he's back and ready to answer (unless it's a high impact issue which means more people will potentially look into it).

[That said, personally, I looked at the report but the obscurity and it's low impact was enough to make it a low priority for me - but that was just my personal rationalization for not looking into it if you want to know ;)]

And as I mentioned there are reminders of open bugs to the assignees twice a week (R-core for most bugs), so the chance of a bug report being unnoticed is close to zero.

Cheers,
Simon


From shotwelm at musc.edu  Fri Dec 24 20:45:48 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Fri, 24 Dec 2010 14:45:48 -0500
Subject: [Rd] Bugs e-mails and R-devel [Was: Bug filed on unzip()
 function]
In-Reply-To: <B931ADEC-E9E7-4E96-851D-1F3E11A28C67@r-project.org>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
	<B931ADEC-E9E7-4E96-851D-1F3E11A28C67@r-project.org>
Message-ID: <1293219949.1740.13.camel@matt-laptop>

I do keep track of R's bug reports by RSS (Atom actually), but it's a
bit more complicated than just copying the `feed' link after following
the Show open bugs new-to-old link. If you use that feed, you will get
the earliest 100 entries, starting Jan 28, 2000. I have had good luck
monitoring the most recent bug reports using the following feed link
(query):

https://bugs.r-project.org/bugzilla3/buglist.cgi?chfieldfrom=-4w&chfieldto=Now&query_format=advanced&title=Bug%20List&ctype=atom

This query gives you the all the changes in the last four weeks
(chfieldfrom=-4w). Of course, you can customize your query and the
corresponding RSS/Atom feed using the Bugzilla advanced search feature
here:

https://bugs.r-project.org/bugzilla3/query.cgi?format=advanced

Cheers and Happy Holidays,
Matt



On Fri, 2010-12-24 at 11:32 -0500, Simon Urbanek wrote:
> On Dec 24, 2010, at 12:22 AM, Marc Schwartz wrote:
> 
> > On Dec 23, 2010, at 8:24 PM, Simon Urbanek wrote:
> > 
> >> On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:
> >> 
> >>> This message contains a good question:
> >>> 
> >>> Is there any reason why the bug reports are no longer mailed to R-devel?
> >> 
> >> The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.
> >> 
> >> I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.
> >> 
> >> 
> >>> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
> >>> 
> >> 
> >> I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.
> >> 
> >> Cheers,
> >> Simon
> > 
> > I don't know what the volume of traffic would be from Bugzilla these days versus what it used to be from Jitterbug.
> > 
> > One of the issues with Jitterbug and the cc'ing of bug reports and comments to R-devel, is that the e-mails would frequently come from the participants in the bug report who were not subscribers to R-devel. That required that the R-devel moderators manually approve those e-mails, which added overhead. In fact, since moving to Bugzilla, the volume of manual approvals on R-devel has declined notably since those e-mails are no longer mirrored.
> > 
> 
> That is an interesting point and confirms my feeling that the dual-mode approach has serious implications.
> 
> 
> > There is not an easy way to interact with Bugzilla via e-mail as there was with Jitterbug. The last time that I looked into this during the transition, it would require e-mails with a very specific formatting and name-value pair style entries in the message body, which could then be parsed by Bugzilla for inclusion into the underlying database. So one could not just reply to a Bugzilla bug report or comment with a free form e-mail as could be done with Jitterbug.
> > 
> 
> We work around that for R-bugs by injecting the comments directly into the bugzilla database. The rationale is that no extra e-mail notification is needed since the e-mail (hopefully) went to all parties involved so bypassing bugzilla for the update is fine. So far it seemed to work just fine. (The only additional service I was thinking of would be to allow the change of status by e-mail - using some define keyword/phrase - so you don't have to go back to the website to close a bug).
> 
> 
> > If an e-mail list mirror is desired, I would vote for a separate READ-ONLY list that folks could subscribe to and/or perhaps have an RSS feed that could be followed for updates. Making the list read-only would obviate situations where somebody replied to a bug report and/or comment via e-mail, where that reply would of course not make it into the Bugzilla repo thread, resulting in a loss of information.
> > 
> 
> Maybe the reply-to could be R-bugs which would solve the reply issue, but the original issue of non-registered users replying would still remain with even bigger consequences (the replies would not even go to bugzilla). However, I could generate bounce e-mails for those, notifying the sender that he is not registered and thus his post will be discarded - not sure if that helps, though (and it may lead to issues with spammers getting replies). Also it would increase the traffic on R-bugs which would make manual screening (which is what I do at the moment for people that try to e-mail new reports to R-bugs) almost impossible.
> 
> 
> > With Bugzilla, the results of search queries generate an RSS feed link at the bottom of the query results page (see the "Feed" link), which can be subscribed to using one's favorite RSS reader. That would be one way of keeping track of new/open bug reports.
> > 
> 
> That sounds like a good idea to me - especially since it's there already ;).
> 
> 
> > One could, if desired, create custom queries in Bugzilla using the Advanced Search functionality and then use the resultant RSS feed link to keep track of updates to the particular query result set.
> > 
> > Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.
> > 
> 
> This is happening, but only to the assignees, so currently on R-core or to individuals.
> 
> Thanks for the comments,
> Simon
> 
> 
> > That's my $0.02.
> > 
> > Regards,
> > 
> > Marc Schwartz
> > 
> >> 
> >> 
> >>> 
> >>> On 21.12.2010 18:50, Ken Williams wrote:
> >>>> Hi,
> >>>> 
> >>>> A few days ago I filed a bug report on the unzip() function:
> >>>> 
> >>>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
> >>>> 
> >>>> I haven't gotten any comments yet, so I thought I'd ask for comments
> >>>> here.  I also see on the description of R-devel that the list "also
> >>>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
> >>>> I don't see it here.
> >>>> 
> >>>> Eventually I would like to help unzip() gain large-file support, such
> >>>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
> >>>> corresponding zip() function would be nice too.
> >>>> 
> >>>> Thanks.
> >>>> 
> >>>> -Ken
> > 
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Matthew S. Shotwell
Graduate Student 
Division of Biostatistics and Epidemiology
Medical University of South Carolina


From Simon.Urbanek at r-project.org  Fri Dec 24 21:05:26 2010
From: Simon.Urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Dec 2010 15:05:26 -0500
Subject: [Rd] Bugs e-mails and R-devel
In-Reply-To: <1293219949.1740.13.camel@matt-laptop>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
	<B931ADEC-E9E7-4E96-851D-1F3E11A28C67@r-project.org>
	<1293219949.1740.13.camel@matt-laptop>
Message-ID: <E1DF4F36-4FC1-4E50-8F5C-AEE42F111BC9@r-project.org>


On Dec 24, 2010, at 2:45 PM, Matt Shotwell wrote:

> I do keep track of R's bug reports by RSS (Atom actually), but it's a
> bit more complicated than just copying the `feed' link after following
> the Show open bugs new-to-old link. If you use that feed, you will get
> the earliest 100 entries, starting Jan 28, 2000.


Actually, the "recommended" link (first on the page) leads to a new-to-old open bugs query -- that's at least what I use most of the time -- and the feed link from there does work as expected.

Cheers,
Simon


> I have had good luck
> monitoring the most recent bug reports using the following feed link
> (query):
> 
> https://bugs.r-project.org/bugzilla3/buglist.cgi?chfieldfrom=-4w&chfieldto=Now&query_format=advanced&title=Bug%20List&ctype=atom
> 
> This query gives you the all the changes in the last four weeks
> (chfieldfrom=-4w). Of course, you can customize your query and the
> corresponding RSS/Atom feed using the Bugzilla advanced search feature
> here:
> 
> https://bugs.r-project.org/bugzilla3/query.cgi?format=advanced
> 
> Cheers and Happy Holidays,
> Matt
> 
> 
> 
> On Fri, 2010-12-24 at 11:32 -0500, Simon Urbanek wrote:
>> On Dec 24, 2010, at 12:22 AM, Marc Schwartz wrote:
>> 
>>> On Dec 23, 2010, at 8:24 PM, Simon Urbanek wrote:
>>> 
>>>> On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:
>>>> 
>>>>> This message contains a good question:
>>>>> 
>>>>> Is there any reason why the bug reports are no longer mailed to R-devel?
>>>> 
>>>> The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.
>>>> 
>>>> I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.
>>>> 
>>>> 
>>>>> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
>>>>> 
>>>> 
>>>> I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.
>>>> 
>>>> Cheers,
>>>> Simon
>>> 
>>> I don't know what the volume of traffic would be from Bugzilla these days versus what it used to be from Jitterbug.
>>> 
>>> One of the issues with Jitterbug and the cc'ing of bug reports and comments to R-devel, is that the e-mails would frequently come from the participants in the bug report who were not subscribers to R-devel. That required that the R-devel moderators manually approve those e-mails, which added overhead. In fact, since moving to Bugzilla, the volume of manual approvals on R-devel has declined notably since those e-mails are no longer mirrored.
>>> 
>> 
>> That is an interesting point and confirms my feeling that the dual-mode approach has serious implications.
>> 
>> 
>>> There is not an easy way to interact with Bugzilla via e-mail as there was with Jitterbug. The last time that I looked into this during the transition, it would require e-mails with a very specific formatting and name-value pair style entries in the message body, which could then be parsed by Bugzilla for inclusion into the underlying database. So one could not just reply to a Bugzilla bug report or comment with a free form e-mail as could be done with Jitterbug.
>>> 
>> 
>> We work around that for R-bugs by injecting the comments directly into the bugzilla database. The rationale is that no extra e-mail notification is needed since the e-mail (hopefully) went to all parties involved so bypassing bugzilla for the update is fine. So far it seemed to work just fine. (The only additional service I was thinking of would be to allow the change of status by e-mail - using some define keyword/phrase - so you don't have to go back to the website to close a bug).
>> 
>> 
>>> If an e-mail list mirror is desired, I would vote for a separate READ-ONLY list that folks could subscribe to and/or perhaps have an RSS feed that could be followed for updates. Making the list read-only would obviate situations where somebody replied to a bug report and/or comment via e-mail, where that reply would of course not make it into the Bugzilla repo thread, resulting in a loss of information.
>>> 
>> 
>> Maybe the reply-to could be R-bugs which would solve the reply issue, but the original issue of non-registered users replying would still remain with even bigger consequences (the replies would not even go to bugzilla). However, I could generate bounce e-mails for those, notifying the sender that he is not registered and thus his post will be discarded - not sure if that helps, though (and it may lead to issues with spammers getting replies). Also it would increase the traffic on R-bugs which would make manual screening (which is what I do at the moment for people that try to e-mail new reports to R-bugs) almost impossible.
>> 
>> 
>>> With Bugzilla, the results of search queries generate an RSS feed link at the bottom of the query results page (see the "Feed" link), which can be subscribed to using one's favorite RSS reader. That would be one way of keeping track of new/open bug reports.
>>> 
>> 
>> That sounds like a good idea to me - especially since it's there already ;).
>> 
>> 
>>> One could, if desired, create custom queries in Bugzilla using the Advanced Search functionality and then use the resultant RSS feed link to keep track of updates to the particular query result set.
>>> 
>>> Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.
>>> 
>> 
>> This is happening, but only to the assignees, so currently on R-core or to individuals.
>> 
>> Thanks for the comments,
>> Simon
>> 
>> 
>>> That's my $0.02.
>>> 
>>> Regards,
>>> 
>>> Marc Schwartz
>>> 
>>>> 
>>>> 
>>>>> 
>>>>> On 21.12.2010 18:50, Ken Williams wrote:
>>>>>> Hi,
>>>>>> 
>>>>>> A few days ago I filed a bug report on the unzip() function:
>>>>>> 
>>>>>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
>>>>>> 
>>>>>> I haven't gotten any comments yet, so I thought I'd ask for comments
>>>>>> here.  I also see on the description of R-devel that the list "also
>>>>>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
>>>>>> I don't see it here.
>>>>>> 
>>>>>> Eventually I would like to help unzip() gain large-file support, such
>>>>>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
>>>>>> corresponding zip() function would be nice too.
>>>>>> 
>>>>>> Thanks.
>>>>>> 
>>>>>> -Ken
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Matthew S. Shotwell
> Graduate Student 
> Division of Biostatistics and Epidemiology
> Medical University of South Carolina
> 
> 


From shotwelm at musc.edu  Fri Dec 24 22:03:21 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Fri, 24 Dec 2010 16:03:21 -0500
Subject: [Rd] Bugs e-mails and R-devel
In-Reply-To: <E1DF4F36-4FC1-4E50-8F5C-AEE42F111BC9@r-project.org>
References: <AANLkTi=nv5fVvEJVBKPVPMCSbOEK6tEQqU1J4i=faWo9@mail.gmail.com>
	<4D13441F.9010906@statistik.tu-dortmund.de>
	<7A28758A-92FF-40F8-B23D-FA062853CB25@r-project.org>
	<E1730885-C99C-4A59-BA64-2A9C26A650AD@me.com>
	<B931ADEC-E9E7-4E96-851D-1F3E11A28C67@r-project.org>
	<1293219949.1740.13.camel@matt-laptop>
	<E1DF4F36-4FC1-4E50-8F5C-AEE42F111BC9@r-project.org>
Message-ID: <1293224601.1740.22.camel@matt-laptop>

On Fri, 2010-12-24 at 15:05 -0500, Simon Urbanek wrote:
> On Dec 24, 2010, at 2:45 PM, Matt Shotwell wrote:
> 
> > I do keep track of R's bug reports by RSS (Atom actually), but it's a
> > bit more complicated than just copying the `feed' link after following
> > the Show open bugs new-to-old link. If you use that feed, you will get
> > the earliest 100 entries, starting Jan 28, 2000.
> 
> 
> Actually, the "recommended" link (first on the page) leads to a new-to-old open bugs query -- that's at least what I use most of the time -- and the feed link from there does work as expected.

Ahh, that's right. I see now that my feed aggregator (Liferea) was
apparently caching the oldest 100, and no more!?!

Still, the Bugzilla feeds are very customizable; it's a neat feature.

-Matt

> 
> Cheers,
> Simon
> 
> 
> > I have had good luck
> > monitoring the most recent bug reports using the following feed link
> > (query):
> > 
> > https://bugs.r-project.org/bugzilla3/buglist.cgi?chfieldfrom=-4w&chfieldto=Now&query_format=advanced&title=Bug%20List&ctype=atom
> > 
> > This query gives you the all the changes in the last four weeks
> > (chfieldfrom=-4w). Of course, you can customize your query and the
> > corresponding RSS/Atom feed using the Bugzilla advanced search feature
> > here:
> > 
> > https://bugs.r-project.org/bugzilla3/query.cgi?format=advanced
> > 
> > Cheers and Happy Holidays,
> > Matt
> > 
> > 
> > 
> > On Fri, 2010-12-24 at 11:32 -0500, Simon Urbanek wrote:
> >> On Dec 24, 2010, at 12:22 AM, Marc Schwartz wrote:
> >> 
> >>> On Dec 23, 2010, at 8:24 PM, Simon Urbanek wrote:
> >>> 
> >>>> On Dec 23, 2010, at 7:44 AM, Uwe Ligges wrote:
> >>>> 
> >>>>> This message contains a good question:
> >>>>> 
> >>>>> Is there any reason why the bug reports are no longer mailed to R-devel?
> >>>> 
> >>>> The way Bugzilla works is that all parties involved in a bug get e-mails - but then they get all of them including all updates of the status, replies etc. One way to get involved is to be the assignee for a bug and most bugs have R-core as the assignee so that's where it goes. Although we could add R-devel on the CC list it would mean that *every* change to a bug will result in a message and I suspect R-devel subscribers would not be quite happy about that.
> >>>> 
> >>>> I don't know of any provision that would make it possible to broadcast the initial report only. Moreover, doing so on R-devel would be somewhat problematic, because people might reply to all and thus some correspondence would still land on R-devel whereas replies via website would not - and that could lead to a serious confusion.
> >>>> 
> >>>> 
> >>>>> I'd appreciate to get a notice what is going on in the bug repository without having to look on those web pages.
> >>>>> 
> >>>> 
> >>>> I could add you to the CC list of any (or all) components - that's one way (it could be interesting to see how it works traffic-wise). Another would be to have a dedicated list for the bug traffic (R-bugs is not a list). Or, as I said, we could put R-devel on the CC list for all components. I wouldn't mind doing so, but I'm not sure what the R-devel readership would say... Comments are welcome.
> >>>> 
> >>>> Cheers,
> >>>> Simon
> >>> 
> >>> I don't know what the volume of traffic would be from Bugzilla these days versus what it used to be from Jitterbug.
> >>> 
> >>> One of the issues with Jitterbug and the cc'ing of bug reports and comments to R-devel, is that the e-mails would frequently come from the participants in the bug report who were not subscribers to R-devel. That required that the R-devel moderators manually approve those e-mails, which added overhead. In fact, since moving to Bugzilla, the volume of manual approvals on R-devel has declined notably since those e-mails are no longer mirrored.
> >>> 
> >> 
> >> That is an interesting point and confirms my feeling that the dual-mode approach has serious implications.
> >> 
> >> 
> >>> There is not an easy way to interact with Bugzilla via e-mail as there was with Jitterbug. The last time that I looked into this during the transition, it would require e-mails with a very specific formatting and name-value pair style entries in the message body, which could then be parsed by Bugzilla for inclusion into the underlying database. So one could not just reply to a Bugzilla bug report or comment with a free form e-mail as could be done with Jitterbug.
> >>> 
> >> 
> >> We work around that for R-bugs by injecting the comments directly into the bugzilla database. The rationale is that no extra e-mail notification is needed since the e-mail (hopefully) went to all parties involved so bypassing bugzilla for the update is fine. So far it seemed to work just fine. (The only additional service I was thinking of would be to allow the change of status by e-mail - using some define keyword/phrase - so you don't have to go back to the website to close a bug).
> >> 
> >> 
> >>> If an e-mail list mirror is desired, I would vote for a separate READ-ONLY list that folks could subscribe to and/or perhaps have an RSS feed that could be followed for updates. Making the list read-only would obviate situations where somebody replied to a bug report and/or comment via e-mail, where that reply would of course not make it into the Bugzilla repo thread, resulting in a loss of information.
> >>> 
> >> 
> >> Maybe the reply-to could be R-bugs which would solve the reply issue, but the original issue of non-registered users replying would still remain with even bigger consequences (the replies would not even go to bugzilla). However, I could generate bounce e-mails for those, notifying the sender that he is not registered and thus his post will be discarded - not sure if that helps, though (and it may lead to issues with spammers getting replies). Also it would increase the traffic on R-bugs which would make manual screening (which is what I do at the moment for people that try to e-mail new reports to R-bugs) almost impossible.
> >> 
> >> 
> >>> With Bugzilla, the results of search queries generate an RSS feed link at the bottom of the query results page (see the "Feed" link), which can be subscribed to using one's favorite RSS reader. That would be one way of keeping track of new/open bug reports.
> >>> 
> >> 
> >> That sounds like a good idea to me - especially since it's there already ;).
> >> 
> >> 
> >>> One could, if desired, create custom queries in Bugzilla using the Advanced Search functionality and then use the resultant RSS feed link to keep track of updates to the particular query result set.
> >>> 
> >>> Also, I don't know what the typical response time has been on Bugzilla once a bug report is filed. Perhaps something could be noted there so that bug reporters might have some expectation that a comment/reply might be forthcoming within X days of filing. After that time frame, some recommended form of follow up communication could take place as a tickler/reminder of sorts.
> >>> 
> >> 
> >> This is happening, but only to the assignees, so currently on R-core or to individuals.
> >> 
> >> Thanks for the comments,
> >> Simon
> >> 
> >> 
> >>> That's my $0.02.
> >>> 
> >>> Regards,
> >>> 
> >>> Marc Schwartz
> >>> 
> >>>> 
> >>>> 
> >>>>> 
> >>>>> On 21.12.2010 18:50, Ken Williams wrote:
> >>>>>> Hi,
> >>>>>> 
> >>>>>> A few days ago I filed a bug report on the unzip() function:
> >>>>>> 
> >>>>>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14462
> >>>>>> 
> >>>>>> I haven't gotten any comments yet, so I thought I'd ask for comments
> >>>>>> here.  I also see on the description of R-devel that the list "also
> >>>>>> receives all (filtered, i.e. non-spam!) bug reports from R-bugs", but
> >>>>>> I don't see it here.
> >>>>>> 
> >>>>>> Eventually I would like to help unzip() gain large-file support, such
> >>>>>> as is offered by http://info-zip.org/UnZip.html version 6.0.  A
> >>>>>> corresponding zip() function would be nice too.
> >>>>>> 
> >>>>>> Thanks.
> >>>>>> 
> >>>>>> -Ken
> >>> 
> >>> 
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > -- 
> > Matthew S. Shotwell
> > Graduate Student 
> > Division of Biostatistics and Epidemiology
> > Medical University of South Carolina
> > 
> > 
> 

-- 
Matthew S. Shotwell
Graduate Student 
Division of Biostatistics and Epidemiology
Medical University of South Carolina


From ggrothendieck at gmail.com  Sat Dec 25 00:49:52 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Dec 2010 18:49:52 -0500
Subject: [Rd] LazyLoad changes the class of objects
In-Reply-To: <Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>
References: <971536df0710120004k236f017je01153dcf55869dd@mail.gmail.com>
	<Pine.LNX.4.64.0710170759210.12037@nokomis.stat.uiowa.edu>
Message-ID: <AANLkTimEoV6v9bsSj4YQv53c78_GOVzG8Tac1=St0SaV@mail.gmail.com>

On Wed, Oct 17, 2007 at 8:59 AM, Luke Tierney <luke at stat.uiowa.edu> wrote:
> Yes, attributes are not preserved, though why that should matter
> given the frequent strong recommendations in this list against
> using attributes on environments or other reference objects is
> beyond me. More importantly, locking and active bindings are not
> preserved either. ?Will look into fixing this this 2.7.
>

1. The above message from 2007 was about the possibility of fixing the
fact that attributes on top level environments are stripped if
LazyLoad: yes in a package's DESCRIPTION file.   (They are not
stripped if LazyLoad: false so that case works as expected -- its only
the LazyLoad: true case that has this behavior.)  Can this be finally
fixed?

2. There was an R News article at the time that mentioned an
undocumented 25K code size threshold that determined whether LazyLoad
was turned on or off in those cases where LazyLoad was not specified
in the DESCRIPTION file.  Is that still the case?   If not then what
is the default?  Its not mentioned in the R-ext manual.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pauljohn32 at gmail.com  Sun Dec 26 22:30:08 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 26 Dec 2010 15:30:08 -0600
Subject: [Rd] environment question
Message-ID: <AANLkTimOu+-HhcQZ1DKdZCCvWe_=J66UGaWZdv4w=TLD@mail.gmail.com>

Hello, everybody.

I'm putting together some lecture notes and course exercises on R
programming.  My plan is to pick some R packages, ask students to read
through code and see why things work, maybe make some changes.  As I
look for examples, I'm running up against the problem that packages
use coding idioms that are unfamiliar to me.

A difficult thing for me is explaining scope of variables in R
functions.  When should we pass an object to a function, when should
we let the R system search about for an object?  I've been puzzling
through ?environment for quite a while.

Here's an example from one of the packages that I like, called "ltm".
In the function "ltm.fit" the work of calculating estimates is sent to
different functions like "EM' and "loglikltm" and "scoreltm".  Before
that, this is used:

environment(EM) <- environment(loglikltm) <- environment(scoreltm) <-
environment()

##and then EM is called
res.EM <- EM(betas, constraint, control$iter.em, control$verbose)

I want to make sure I understand this. The environment line gets the
current environment and then assigns it for those 3 functions, right?
All variables and functions that can be accessed from the current
position in the code become available to function EM, loglikltm,
scoreltm.

So, which options should be explicitly inserted into a function call,
which should be left in the environment for R to find when it needs
them?

1. I *think* that when EM is called, the variables "betas",
"constraint", and "control" are already in the environment.

The EM function is declared like this, using the same words "beta" and
"constraint"

EM <-
function (betas, constraint, iter, verbose = FALSE) {

It seems to me that if I wrote the function call like this (leave out
"betas" and "constraint")

res.EM <- EM(control$iter.em, control$verbose)

R will run EM and go find "betas" and "constraint" in the environment,
there was no need to name them as arguments.


2 Is a function like EM allowed to alter objects that it finds through
the environment, ones that are not passed as arguments? I understand
that a function cannot alter an object that is passed explicitly, but
what about the ones it grabs from the environment?

If you have ideas about packages that might be handy teaching
examples, please let me know.

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From pdalgd at gmail.com  Sun Dec 26 23:39:58 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 26 Dec 2010 23:39:58 +0100
Subject: [Rd] environment question
In-Reply-To: <AANLkTimOu+-HhcQZ1DKdZCCvWe_=J66UGaWZdv4w=TLD@mail.gmail.com>
References: <AANLkTimOu+-HhcQZ1DKdZCCvWe_=J66UGaWZdv4w=TLD@mail.gmail.com>
Message-ID: <1A391F0E-C30B-464D-B53F-E23A4064A626@gmail.com>


On Dec 26, 2010, at 22:30 , Paul Johnson wrote:

> Hello, everybody.
> 
> I'm putting together some lecture notes and course exercises on R
> programming.  My plan is to pick some R packages, ask students to read
> through code and see why things work, maybe make some changes.  As I
> look for examples, I'm running up against the problem that packages
> use coding idioms that are unfamiliar to me.
> 
> A difficult thing for me is explaining scope of variables in R
> functions.  When should we pass an object to a function, when should
> we let the R system search about for an object?  I've been puzzling
> through ?environment for quite a while.
> 
> Here's an example from one of the packages that I like, called "ltm".
> In the function "ltm.fit" the work of calculating estimates is sent to
> different functions like "EM' and "loglikltm" and "scoreltm".  Before
> that, this is used:
> 
> environment(EM) <- environment(loglikltm) <- environment(scoreltm) <-
> environment()
> 
> ##and then EM is called
> res.EM <- EM(betas, constraint, control$iter.em, control$verbose)
> 
> I want to make sure I understand this. The environment line gets the
> current environment and then assigns it for those 3 functions, right?
> All variables and functions that can be accessed from the current
> position in the code become available to function EM, loglikltm,
> scoreltm.

Yes. I'm pretty sure that the net effect is the same as redefining the three functions inside the current function. I.e.

g <- function(fee){fee+fie(fum)}
f <- function(foo){
  environment(g) <- environment()
  fum <- 3.14
  g(foo)
}

is equivalent to

g <- function(fee){fee+fie(fum)}
f <- function(foo){
  g <- function(fee){fee+fie(fum)}
  fum <- 3.14
  g(foo)
}

since a local copy must be created before the environment of g can be changed.

> 
> So, which options should be explicitly inserted into a function call,
> which should be left in the environment for R to find when it needs
> them?

First of all, those are arguments, not options. Arguments can be optional (when there is a default, mostly) but that is something else. Options are set with, say, options(width=60).

> 
> 1. I *think* that when EM is called, the variables "betas",
> "constraint", and "control" are already in the environment.
> 
> The EM function is declared like this, using the same words "beta" and
> "constraint"
> 
> EM <-
> function (betas, constraint, iter, verbose = FALSE) {
> 
> It seems to me that if I wrote the function call like this (leave out
> "betas" and "constraint")
> 
> res.EM <- EM(control$iter.em, control$verbose)
> 
> R will run EM and go find "betas" and "constraint" in the environment,
> there was no need to name them as arguments.

Well, only if the call is always EM(betas, constraints, ....). They could on occasion be matched to something else.


> 
> 
> 2 Is a function like EM allowed to alter objects that it finds through
> the environment, ones that are not passed as arguments? I understand
> that a function cannot alter an object that is passed explicitly, but
> what about the ones it grabs from the environment?
> 

You are "allowed" to alter anything that you can find. Sometimes it is just a very bad idea, and/or bad programming style...

The superassignment operator "<<-" was explicitly designed to allow modification of objects in the lexical scope of a function, so at least in some cases, it must be considered good style to use it (examples can be found in the paper by Ihaka and Gentleman on lexical scope, 1996 IIRC). However, some care must be taken; in particular, if you don't make sure that the object already exists in the appropriate environment, another object of the same name might get clobbered, e.g. in the global environment.

Best,
-pd

(& thanks for that KU t-shirt, by the way!)

> If you have ideas about packages that might be handy teaching
> examples, please let me know.
> 
> pj
> -- 
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pauljohn32 at gmail.com  Mon Dec 27 04:34:51 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 26 Dec 2010 21:34:51 -0600
Subject: [Rd] 'libRblas.so' missing in R 2.12.1
In-Reply-To: <4D0A149B.7090901@klinik.uni-regensburg.de>
References: <4D0A149B.7090901@klinik.uni-regensburg.de>
Message-ID: <AANLkTimmiOw+mj=wdEHwOHV_kXS3pPbyuV4vvrchj6Df@mail.gmail.com>

On Thu, Dec 16, 2010 at 7:31 AM, Christian Kohler
<christian.kohler at klinik.uni-regensburg.de> wrote:
> Dear R developers,
>
> I just compiled the latest version of R (2.12.1) and noticed that 'libRblas.so' is missing in the '/x86_64/src/extra/blas' subdirectory of my
> R-installation.
>
> Did I miss ongoing discussions on the Mailinglist about this or might it be a local problem?
>
> Christian Kohler

Hi, Christian:

Did  you get an answer? I'm guessing you asked because you want to
follow along with the optimization advice in the R Install Guide,
section "A.3.1.5 Shared BLAS"

I've asked the same thing myself.  Depending on the configure options
you specified, libRblas may be built as a shared library or R may be
linked against an external blas.   There seems to be some tension and
the experts will give you differing advice about whether R should be a
shared library and whether you should allow libRblas.so to be built.
The Install manual says that a non-shared library will load more
quickly, but, of course, if the blas is built into R itself, then you
can't play games pointing the symbolic link to other shared library
implementations.

If you have access to a Ubuntu system, you will notice there is no
libRblas.so supplied in the packages they provide.  They are pointing
to a shared library blas from the intel kernel math library.

The last time I looked, that was configured like this:

      ./configure --prefix=/usr                       \
                   --with-cairo                        \
                   --with-jpeglib                      \
                   --with-pango                        \
                   --with-png                          \
                   --with-readline                     \
                   --with-tcltk                        \
                   --with-system-bzlib                 \
                   --with-system-pcre                  \
                   --with-system-zlib                  \
                   --mandir=/usr/share/man             \
                   --infodir=/usr/share/info           \
                   --datadir=/usr/share/R/share        \
                   --includedir=/usr/share/R/include   \
                   $(atlas)            \
                   $(lapack)           \
                   --without-gnome                     \
                   --enable-R-profiling                \
                   --enable-R-shlib                    \
                   --enable-memory-profiling           \
                   --without-recommended-packages      \
                   --build $(buildarch)

$(atlas) draws its value from the rules file

atlas           = --with-blas

Similarly, $(lapack)

lapack          = --with-lapack


If you want to get libRblas.so out, you need to remove the atlas and
lapack lines. Also, watch out for this configure option:

--disable-BLAS-shlib.

If you take out the atlas/lapack statements, you get libRblas.so, and
then you can follow along with R install manual to replace that with a
link to one of the optimized blas libraries.

However, my experience, and that of at least one other person, is that
the speedup you will observe from that is not too substantial.

http://www.cybaea.net/Blogs/Data/Faster-R-through-better-BLAS.html


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From murdoch.duncan at gmail.com  Mon Dec 27 12:24:42 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Dec 2010 06:24:42 -0500
Subject: [Rd] environment question
In-Reply-To: <AANLkTimOu+-HhcQZ1DKdZCCvWe_=J66UGaWZdv4w=TLD@mail.gmail.com>
References: <AANLkTimOu+-HhcQZ1DKdZCCvWe_=J66UGaWZdv4w=TLD@mail.gmail.com>
Message-ID: <4D18777A.4010306@gmail.com>

On 10-12-26 4:30 PM, Paul Johnson wrote:
 > Hello, everybody.
 >
 > I'm putting together some lecture notes and course exercises on R
 > programming.  My plan is to pick some R packages, ask students to read
 > through code and see why things work, maybe make some changes.  As I
 > look for examples, I'm running up against the problem that packages
 > use coding idioms that are unfamiliar to me.
 >
 > A difficult thing for me is explaining scope of variables in R
 > functions.  When should we pass an object to a function, when should
 > we let the R system search about for an object?  I've been puzzling
 > through ?environment for quite a while.

Take a look at the Language Definition, not just the ?environment page.

 >
 > Here's an example from one of the packages that I like, called "ltm".
 > In the function "ltm.fit" the work of calculating estimates is sent to
 > different functions like "EM' and "loglikltm" and "scoreltm".  Before
 > that, this is used:
 >
 > environment(EM)<- environment(loglikltm)<- environment(scoreltm)<-
 > environment()
 >
 > ##and then EM is called
 > res.EM<- EM(betas, constraint, control$iter.em, control$verbose)
 >
 > I want to make sure I understand this. The environment line gets the
 > current environment and then assigns it for those 3 functions, right?
 > All variables and functions that can be accessed from the current
 > position in the code become available to function EM, loglikltm,
 > scoreltm.

That's one way to think of it, but it is slightly more accurate to say 
that three new functions are created, whose associated environments are 
set to the current environment.

 >
 > So, which options should be explicitly inserted into a function call,
 > which should be left in the environment for R to find when it needs
 > them?

That's a matter of style.  I would say that it is usually better style 
not to mess around with a function's environment.

 >
 > 1. I *think* that when EM is called, the variables "betas",
 > "constraint", and "control" are already in the environment.

That need not be true, as long as they are in the environment by the 
time EM, loglikltm, scoreltm are called.

 >
 > The EM function is declared like this, using the same words "beta" and
 > "constraint"
 >
 > EM<-
 > function (betas, constraint, iter, verbose = FALSE) {
 >
 > It seems to me that if I wrote the function call like this (leave out
 > "betas" and "constraint")
 >
 > res.EM<- EM(control$iter.em, control$verbose)
 >
 > R will run EM and go find "betas" and "constraint" in the environment,
 > there was no need to name them as arguments.

Including them as arguments means that new local copies will be created 
in the evaluation frame.

 >
 >
 > 2 Is a function like EM allowed to alter objects that it finds through
 > the environment, ones that are not passed as arguments? I understand
 > that a function cannot alter an object that is passed explicitly, but
 > what about the ones it grabs from the environment?

Yes it's allowed, but the usual rules of assignment won't do it.  Read 
about the <<- operator for modifying things that are not local.  In summary:

  beta <- 1

creates or modifies a new local variable, while

  beta <<- 1

goes looking for beta, and modifies the first one it finds.  If it fails 
to find one, it creates one in the global environment.

Duncan Murdoch

 > If you have ideas about packages that might be handy teaching
 > examples, please let me know.
 >
 > pj


From maechler at stat.math.ethz.ch  Mon Dec 27 16:59:43 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Dec 2010 16:59:43 +0100
Subject: [Rd] minor problem in strsplit help file
In-Reply-To: <4D14758B.9070009@pburns.seanet.com>
References: <4D14758B.9070009@pburns.seanet.com>
Message-ID: <19736.47087.849991.590997@cmath-6.math.ethz.ch>

>>>>> "PatB" == Patrick Burns <pburns at pburns.seanet.com>
>>>>>     on Fri, 24 Dec 2010 10:27:23 +0000 writes:

    PatB> The 'extended' argument to 'strsplit' has been
    PatB> removed, but it is still mentioned in the argument
    PatB> items in the help file for 'fixed' and 'perl'.

Indeed; thank you Pat!
I've committed a fix.

Martin

    PatB> -- Patrick Burns pburns at pburns.seanet.com twitter:
    PatB> @portfolioprobe http://www.portfolioprobe.com/blog
    PatB> http://www.burns-stat.com (home of 'Some hints for the
    PatB> R beginner' and 'The R Inferno')


From friendly at yorku.ca  Mon Dec 27 17:32:26 2010
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 27 Dec 2010 11:32:26 -0500
Subject: [Rd] aperm() should retain class of input object
Message-ID: <4D18BF9A.6040404@yorku.ca>

aperm() was designed for multidimensional arrays, but is also useful for 
table objects, particularly
with the lattice, vcd and vcdExtra packages.  But aperm() was designed 
and implemented before other
related object classes were conceived, and I propose a small tune-up to 
make it more generally useful.

The problem is that  aperm() always returns an object of class 'array', 
which causes problems for methods
designed for table objects. It also requires some package writers to 
implement both .array and .table
methods for the same functionality, usually one in terms of the other.
Some examples of unexpected, and initially perplexing results (when only 
methods for one class are implemented)
are shown below.


 > library(vcd)
 > pairs(UCBAdmissions, shade=TRUE)
 > UCB <- aperm(UCBAdmissions, c(2, 1, 3))
 >
 > # UCB is now an array, not a table
 > pairs(UCB, shade=TRUE)
There were 50 or more warnings (use warnings() to see the first 50)
 >
 > # fix it, to get pairs.table
 > class(UCB) <- "table"
 > pairs(UCB, shade=TRUE)
 >



Of course, I can define a new function, tperm() that does what I think 
should be the expected behavior:

# aperm, for table objects

tperm <- function(a, perm, resize = TRUE) {
     result <- aperm(a, per, resize)
     class(result) <- class(a)
     result
}

But I think it is more natural to include this functionality in aperm() 
itself.  Thus, I propose the following
revision of base::aperm(), at the R level:

aperm <- function (a, perm, resize = TRUE, keep.class=TRUE)
{
     if (missing(perm))
         perm <- integer(0L)
     result <- .Internal(aperm(a, perm, resize))
     if(keep.class) class(result) <- class(a)
     result
}


I don't think this would break any existing code, except where someone 
depended on coercion to an array.
The drop-in replacement for aperm would set keep.class=FALSE by default, 
but I think TRUE is  more
natural.

FWIW, here are the methods for table and array objects
from my current (non-representative) session.

 > methods(class="table")
  [1] as.data.frame.table barchart.table*     cloud.table*        
contourplot.table*  dotplot.table*
  [6] head.table*         levelplot.table*    pairs.table*        
plot.table*         print.table
[11] summary.table       tail.table*

    Non-visible functions are asterisked
 >
 > methods(class="array")
[1] anyDuplicated.array as.data.frame.array as.raster.array*    
barchart.array*     contourplot.array*  dotplot.array*
[7] duplicated.array    levelplot.array*    unique.array


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From maechler at stat.math.ethz.ch  Mon Dec 27 22:55:53 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Dec 2010 22:55:53 +0100
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <AANLkTi=L6H3z6YT+nuKkQsGiVTShQekroK8q28zAXOEV@mail.gmail.com>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTi=H9k-HSuyqk=XwMm_hmwoc_WOU3azjYnUmAkFP@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70003B1D5BD@NA-PA-VBE03.na.tibco.com>
	<AANLkTi=L6H3z6YT+nuKkQsGiVTShQekroK8q28zAXOEV@mail.gmail.com>
Message-ID: <AANLkTik3FP+7rZWWhUpt=G0FMeFnp9Vs8R4cm+BN6P3R@mail.gmail.com>

Finally finding time to come back to this.
Remember that I've started the thread by proposing a version of sapply()
which does not just "stop" with making a matrix() from the lapply() result, but
instead --- only when the new argument ARRAY = TRUE is set ---
may return an array() of any (appropriate) order, in those cases where
the lapply() result elements all return an array of the same dim().

On Wed, Dec 1, 2010 at 19:51, Hadley Wickham <hadley at rice.edu> wrote:
>> A downside of that approach is that lapply(X,...) can
>> cause a lot of unneeded memory to be allocated (length(X)
>> SEXP's). ?Those SEXP's would be tossed out by simplify() but
>> the peak memory usage would remain high. ?sapply() can
>> be written to avoid the intermediate list structure.
>
> But the upside is reusable code that can be used in multiple places -
> what about the simplification code used by mapply and tapply? Why are
> there three different implementations of simplification?
>
> Hadley

I have now looked into using a version of what Hadley had proposed.
Note (to Bill's point) that the current implementation of sapply()
does go via lapply() and
that we have  vapply()  as a faster version of sapply()  with less
copying (hopefully).

Very unfortunately, vapply() .. which was only created 13 months ago,
has inherited the ``illogical''  behavior of  sapply()
in that it does not make up higher rank arrays if the single element
is already a matrix (say).
...
Consequently, we also need a patch to vapply(),
and I do wonder if we should not make "ARRAY=TRUE" the default there,
since with vapply() you specify a result value, and if you specify a
matrix, the total result should stack these matrices into an array of
rank 3, etc.
Looking at it, the patch is not so much work... notably if we don't
use a new argument but really let  FUN.VALUE determine what the result
should look like.

More comments are stil welcome...
Martin


From ggrothendieck at gmail.com  Mon Dec 27 23:06:25 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Dec 2010 17:06:25 -0500
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <19702.2469.739772.13707@lynne.math.ethz.ch>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
Message-ID: <AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>

On Wed, Dec 1, 2010 at 3:39 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> My proposal -- implemented and "make check" tested --
> is to add an optional argument ?'ARRAY'
> which allows
>
>> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)

It would reduce the proliferation of arguments if the simplify=
argument were extended to allow this, e.g. simplify = "array" or
perhaps simplify = n would allow a maximum of n dimensions.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From djsamperi at gmail.com  Tue Dec 28 05:56:26 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 27 Dec 2010 23:56:26 -0500
Subject: [Rd] rJava question
Message-ID: <AANLkTik4xi4WjYXTLnw=T=zF1ufwNiF9gPy9mcKKPEZd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101227/6439fcda/attachment.pl>

From timhesterberg at gmail.com  Tue Dec 28 15:43:13 2010
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Tue, 28 Dec 2010 06:43:13 -0800
Subject: [Rd] aperm() should retain class of input object
In-Reply-To: <4D18BF9A.6040404@yorku.ca> (message from Michael Friendly on
	Mon, 27 Dec 2010 11:32:26 -0500)
References: <4D18BF9A.6040404@yorku.ca>
Message-ID: <yajf7heu9cvy.fsf@gmail.com>

Having aperm() return an object of the same class is dangerous, there
are undoubtedly classes for which that is not appropriate, producing an
illegal object for that class or quietly giving incorrect results.

Three alternatives are to:
* add the keep.class option but with default FALSE
* make aperm a generic function 
  - without a keep.class argument
  - with a ... argument
  - methods for classes like table could have keep.class = TRUE
* make aperm a generic function 
  - without a keep.class argument
  - with a ... argument
  - default method have keep.class = TRUE

The third option would give the proposed behavior by default, but
allow a way out for classes where the behavior is wrong.  This puts
the burden on a class author to realize the potential problem with
aperm, so my preference is one of the first two options.

>aperm() was designed for multidimensional arrays, but is also useful for
>table objects, particularly
>with the lattice, vcd and vcdExtra packages.  But aperm() was designed
>and implemented before other
>related object classes were conceived, and I propose a small tune-up to
>make it more generally useful.
>
>The problem is that  aperm() always returns an object of class 'array',
>which causes problems for methods
>designed for table objects. It also requires some package writers to
>implement both .array and .table
>methods for the same functionality, usually one in terms of the other.
>Some examples of unexpected, and initially perplexing results (when only
>methods for one class are implemented)
>are shown below.
>
>
> > library(vcd)
> > pairs(UCBAdmissions, shade=TRUE)
> > UCB <- aperm(UCBAdmissions, c(2, 1, 3))
> >
> > # UCB is now an array, not a table
> > pairs(UCB, shade=TRUE)
>There were 50 or more warnings (use warnings() to see the first 50)
> >
> > # fix it, to get pairs.table
> > class(UCB) <- "table"
> > pairs(UCB, shade=TRUE)
> >
>
>
>
>Of course, I can define a new function, tperm() that does what I think
>should be the expected behavior:
>
># aperm, for table objects
>
>tperm <- function(a, perm, resize = TRUE) {
>     result <- aperm(a, per, resize)
>     class(result) <- class(a)
>     result
>}
>
>But I think it is more natural to include this functionality in aperm()
>itself.  Thus, I propose the following
>revision of base::aperm(), at the R level:
>
>aperm <- function (a, perm, resize = TRUE, keep.class=TRUE)
>{
>     if (missing(perm))
>         perm <- integer(0L)
>     result <- .Internal(aperm(a, perm, resize))
>     if(keep.class) class(result) <- class(a)
>     result
>}
>
>
>I don't think this would break any existing code, except where someone
>depended on coercion to an array.
>The drop-in replacement for aperm would set keep.class=FALSE by default,
>but I think TRUE is  more
>natural.
>
>FWIW, here are the methods for table and array objects
>from my current (non-representative) session.
>
> > methods(class="table")
>  [1] as.data.frame.table barchart.table*     cloud.table*
>contourplot.table*  dotplot.table*
>  [6] head.table*         levelplot.table*    pairs.table*
>plot.table*         print.table
>[11] summary.table       tail.table*
>
>    Non-visible functions are asterisked
> >
> > methods(class="array")
>[1] anyDuplicated.array as.data.frame.array as.raster.array*
>barchart.array*     contourplot.array*  dotplot.array*
>[7] duplicated.array    levelplot.array*    unique.array
>
>
>--
>Michael Friendly     Email: friendly AT yorku DOT ca
>Professor, Psychology Dept.
>York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
>4700 Keele Street    Web:http://www.datavis.ca
>Toronto, ONT  M3J 1P3 CANADA


From maechler at stat.math.ethz.ch  Tue Dec 28 16:49:49 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Dec 2010 16:49:49 +0100
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>
Message-ID: <19738.1821.84824.284589@cmath-6.math.ethz.ch>

>>>>> Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Mon, 27 Dec 2010 17:06:25 -0500 writes:

    > On Wed, Dec 1, 2010 at 3:39 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> My proposal -- implemented and "make check" tested -- is
    >> to add an optional argument ?'ARRAY' which allows
    >> 
    >>> sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)

    > It would reduce the proliferation of arguments if the
    > simplify= argument were extended to allow this,
    > e.g. simplify = "array" or perhaps simplify = n would
    > allow a maximum of n dimensions.

That's a good idea, though it makes the
implementation/documentation very slightly more complicated.

I'm interested to get more feedback on my other questions,
notably the only about *changing*  vapply() (on the C-level) to
behave "logical" in the sense of adding one  dim(.)ension in
those cases, the FUN.VALUE (result prototype) has a dim().


Martin


From tplate at acm.org  Tue Dec 28 19:14:36 2010
From: tplate at acm.org (Tony Plate)
Date: Tue, 28 Dec 2010 11:14:36 -0700
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
 but not further
In-Reply-To: <19738.1821.84824.284589@cmath-6.math.ethz.ch>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>	<AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>
	<19738.1821.84824.284589@cmath-6.math.ethz.ch>
Message-ID: <4D1A290C.8040205@acm.org>

The abind() function from the abind package is an alternative here -- it can take a list argument, which makes it easy to use with the result of lapply().  It's also able take direction about which dimension to join on.

 > x <- list(a=1,b=2,c=3)
 > f <- function(v) matrix(v, nrow=2, ncol=4)
 > sapply(x, f)
      a b c
[1,] 1 2 3
[2,] 1 2 3
[3,] 1 2 3
[4,] 1 2 3
[5,] 1 2 3
[6,] 1 2 3
[7,] 1 2 3
[8,] 1 2 3
 >
 > # The 'along=' argument to abind() determines on which dimension
 > # the list elements are joined.  Use a fractional value to put the new
 > # dimension between existing ones.
 >
 > dim(abind(lapply(x, f), along=0))
[1] 3 2 4
 > dim(abind(lapply(x, f), along=1.5))
[1] 2 3 4
 > dim(abind(lapply(x, f), along=3))
[1] 2 4 3
 > abind(lapply(x, f), along=3)
, , a

      [,1] [,2] [,3] [,4]
[1,]    1    1    1    1
[2,]    1    1    1    1

, , b

      [,1] [,2] [,3] [,4]
[1,]    2    2    2    2
[2,]    2    2    2    2

, , c

      [,1] [,2] [,3] [,4]
[1,]    3    3    3    3
[2,]    3    3    3    3

 >

On 12/28/2010 8:49 AM, Martin Maechler wrote:
>>>>>> Gabor Grothendieck<ggrothendieck at gmail.com>
>>>>>>      on Mon, 27 Dec 2010 17:06:25 -0500 writes:
>      >  On Wed, Dec 1, 2010 at 3:39 AM, Martin Maechler
>      >  <maechler at stat.math.ethz.ch>  wrote:
>      >>  My proposal -- implemented and "make check" tested -- is
>      >>  to add an optional argument  'ARRAY' which allows
>      >>
>      >>>  sapply(v, myF, y = 2*(1:5), ARRAY=TRUE)
>
>      >  It would reduce the proliferation of arguments if the
>      >  simplify= argument were extended to allow this,
>      >  e.g. simplify = "array" or perhaps simplify = n would
>      >  allow a maximum of n dimensions.
>
> That's a good idea, though it makes the
> implementation/documentation very slightly more complicated.
>
> I'm interested to get more feedback on my other questions,
> notably the only about *changing*  vapply() (on the C-level) to
> behave "logical" in the sense of adding one  dim(.)ension in
> those cases, the FUN.VALUE (result prototype) has a dim().
>
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Tue Dec 28 20:05:46 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 28 Dec 2010 14:05:46 -0500
Subject: [Rd] rJava question
In-Reply-To: <AANLkTik4xi4WjYXTLnw=T=zF1ufwNiF9gPy9mcKKPEZd@mail.gmail.com>
References: <AANLkTik4xi4WjYXTLnw=T=zF1ufwNiF9gPy9mcKKPEZd@mail.gmail.com>
Message-ID: <345492BD-A0EF-4ED5-A074-2C0C76FE3F1E@r-project.org>

Dominick,

On Dec 27, 2010, at 11:56 PM, Dominick Samperi wrote:

> After some trial and error I figured out how to pass matrices from R to java
> and back using rJava, but this method is not documented and I wonder if there is a
> better way?
> 

stats-rosuda-devel is the rJava list you want to use.


> Anyway, here is what I found works:
> 
> (m = matrix(as.double(1:12),3,4))
> [shows m as you would expect]
> 
> jtest <- .jnew("JTest")
> (v <- .jcall(jtest, '[[D], 'myfunc', .jarray(m), evalArray=FALSE))
> [shows v = m + 10]
> 
> Here the JTest class has a method named myfunc that accepts
> a double[][] and returns a double[][]. It simply adds 10 to every
> element.
> 

The above is plain wrong (well, that's actually a guess since you didn't provide even the signature of the method) - matrices in R are vectors, so the type is double[]. In Java there is no matrix type, so it's up to the application to represent matrices and there are many ways - some more efficient than others. From your example above it seems that you are using double[][] -- so you have to allocate the extra objects one way or another (that's why it's inefficient to represent matrices that way).

But from your e-mail I have the feeling that your questions is rather about calling a method that returns double[][], so for example:
public static double[][] pass();
where double[][] is a rectangular array (i.e. length of all inner arrays is equal).

Unfortunately .jcall is a bit inconsistent due to bug that was introduced with the new J() API. So the intended behavior is (using class Test with the method above):
> J("Test")$pass()
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16

The $ operator makes sure that the result is converted to a native R form where possible, including recursive structures like double[][].

However, the intention of .jcall() was to never perform recursive evaluation, so this is intended:

> .jcall("Test","[[D","pass", evalArray=TRUE)
[[1]]
[1] "Java-Array-Object[D:[D at 11ddcde"

[[2]]
[1] "Java-Array-Object[D:[D at 18fb1f7"

[[3]]
[1] "Java-Array-Object[D:[D at ed0338"

[[4]]
[1] "Java-Array-Object[D:[D at 6e70c7"


The intended behavior (and true in older version of rJava) was for .jcall with evalArray=FALSE to return the reference:

> .jcall("Test","[[D","pass", evalArray=FALSE)
[1] "Java-Array-Object[[D:[[D at 8f4fb3"

Unfortunately, the bug is that .jcall uses rJava:::newArray() to create the reference which defaults to simplify=TRUE so the current (buggy) behavior is:

> .jcall("Test","[[D","pass", evalArray=FALSE)
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16


The real issue is that:
a) if the bug is fixed, .jcall() can return just the reference which is intended
but
b) there is currently no exposed API for rJava:::newArray so the simplification is not available in any form for references if the bug is fixed (other than using the J/$ API).

That's why I was hesitant so far to fix the bug, but I really should -- which is why the behavior your discovered will change. However, then I need to add some API to be able to convert a reference in the same way that rJava:::newArray provides and expose it - I didn't think through that part, so that's why I got stuck.

I hope it helps...
Cheers,
Simon

(PS: please continue any discussion on stats-rosuda-devel)


> The parameter 'evalArray' is confusing because when
> evalArray=TRUE the result is NOT evaluated (a list is returned
> that you then have to apply .jevalArray to do get the answer).
> 
> There seems to be an option to have a java reference returned
> instead of the actual matrix. Can the R side manipulate the
> matrix (on the java side) through this reference?
> 
> Thanks,
> Dominick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From maechler at stat.math.ethz.ch  Tue Dec 28 20:06:07 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Dec 2010 20:06:07 +0100
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <4D1A290C.8040205@acm.org>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>
	<19738.1821.84824.284589@cmath-6.math.ethz.ch>
	<4D1A290C.8040205@acm.org>
Message-ID: <AANLkTikeGUT5yCLrhg7kA-8=QQsWcr6B8s1w5weoEbvO@mail.gmail.com>

On Tue, Dec 28, 2010 at 19:14, Tony Plate <tplate at acm.org> wrote:
> The abind() function from the abind package is an alternative here -- it can
> take a list argument, which makes it easy to use with the result of
> lapply(). ?It's also able take direction about which dimension to join on.
>
>> x <- list(a=1,b=2,c=3)
>> f <- function(v) matrix(v, nrow=2, ncol=4)
>> sapply(x, f)
> ? ? a b c
> [1,] 1 2 3
> [2,] 1 2 3
> [3,] 1 2 3
> [4,] 1 2 3
> [5,] 1 2 3
> [6,] 1 2 3
> [7,] 1 2 3
> [8,] 1 2 3
>>
>> # The 'along=' argument to abind() determines on which dimension
>> # the list elements are joined. ?Use a fractional value to put the new
>> # dimension between existing ones.
>>
>> dim(abind(lapply(x, f), along=0))
> [1] 3 2 4
>> dim(abind(lapply(x, f), along=1.5))
> [1] 2 3 4
>> dim(abind(lapply(x, f), along=3))
> [1] 2 4 3
>> abind(lapply(x, f), along=3)
> , , a
>
> ? ? [,1] [,2] [,3] [,4]
> [1,] ? ?1 ? ?1 ? ?1 ? ?1
> [2,] ? ?1 ? ?1 ? ?1 ? ?1
>
> , , b
>
> ? ? [,1] [,2] [,3] [,4]
> [1,] ? ?2 ? ?2 ? ?2 ? ?2
> [2,] ? ?2 ? ?2 ? ?2 ? ?2
>
> , , c
>
> ? ? [,1] [,2] [,3] [,4]
> [1,] ? ?3 ? ?3 ? ?3 ? ?3
> [2,] ? ?3 ? ?3 ? ?3 ? ?3
>

Thank you, Tony.
Indeed, yes,  abind() is nice here (and in the good ol' APL spirit !)

Wanting to keep things both simple *and* fast here, of course,
hence I currently contemplate the following code,
where the new  simplify2array()  is  considerably simpler than  abind():

##' "Simplify" a list of commonly structured components into an array.
##'
##' @title simplify list() to an array if the list elements are
structurally equal
##' @param x a list, typically resulting from lapply()
##' @param higher logical indicating if an array() of "higher rank"
##'  should be returned when appropriate, namely when all elements of
##' \code{x} have the same \code{\link{dim}()}ension.
##' @return x itself, or an array if the simplification "is sensible"
simplify2array <- function(x, higher = TRUE)
{
    if(length(common.len <- unique(unlist(lapply(x, length)))) > 1L)
        return(x)
    if(common.len == 1L)
        unlist(x, recursive = FALSE)
    else if(common.len > 1L) {
        n <- length(x)
        ## make sure that array(*) will not call rep() {e.g. for 'call's}:
        r <- as.vector(unlist(x, recursive = FALSE))
        if(higher && length(c.dim <- unique(lapply(x, dim))) == 1 &&
           is.numeric(c.dim <- c.dim[[1L]]) &&
           prod(d <- c(c.dim, n)) == length(r)) {

            iN1 <- is.null(n1 <- dimnames(x[[1L]]))
            n2 <- names(x)
            dnam <-
                if(!(iN1 && is.null(n2)))
                    c(if(iN1) rep.int(list(n1), length(c.dim)) else n1,
                      list(n2)) ## else NULL
            array(r, dim = d, dimnames = dnam)

        } else if(prod(d <- c(common.len, n)) == length(r))
            array(r, dim = d,
                  dimnames= if(!(is.null(n1 <- names(x[[1L]])) &
                  is.null(n2 <- names(x)))) list(n1,n2))
        else x
    }
    else x
}

sapply <- function(X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE)
{
    FUN <- match.fun(FUN)
    answer <- lapply(X, FUN, ...)
    if(USE.NAMES && is.character(X) && is.null(names(answer)))
	names(answer) <- X
    if(!identical(simplify, FALSE) && length(answer))
	simplify2array(answer, higher = (simplify == "array"))
    else answer
}


From kleiman at rohan.sdsu.edu  Wed Dec 29 08:37:18 2010
From: kleiman at rohan.sdsu.edu (Elliot Todd Kleiman)
Date: Tue, 28 Dec 2010 23:37:18 -0800 (PST)
Subject: [Rd] \VignetteKeywords{}, for KEYWORDS or for free-tagging?
Message-ID: <Pine.GSO.4.64.1012282323310.9121@rohan.sdsu.edu>

Hi R-devel,

[Question]:

* Is there a KEYWORDS file to lookup 'keywords' to supply
the vignette command, '\VignetteKeywords{}'?

-or, is the pkg writer free to tag the vignette using any
keywords he/she chooses? i.e., free-tagging.

Thank you,

+ Elliot Kleiman
__________________________
San Diego State University
http://www.sdsu.edu/


From friendly at yorku.ca  Wed Dec 29 14:33:07 2010
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 29 Dec 2010 08:33:07 -0500
Subject: [Rd] aperm() should retain class of input object
In-Reply-To: <yajf7heu9cvy.fsf@gmail.com>
References: <4D18BF9A.6040404@yorku.ca> <yajf7heu9cvy.fsf@gmail.com>
Message-ID: <4D1B3893.8040500@yorku.ca>

On 12/28/2010 9:43 AM, Tim Hesterberg wrote:
> Having aperm() return an object of the same class is dangerous, there
> are undoubtedly classes for which that is not appropriate, producing an
> illegal object for that class or quietly giving incorrect results.
OK.  I can see that my initial proposal would be dangerous for xtabs 
objects without further
modifications and that it is unwise to change default behavior in base 
functions without
very strong reasons.
> Three alternatives are to:
> * add the keep.class option but with default FALSE
This first option is the minimally invasive corrective surgery.
This would put the burden on the user (or package writer), but at least 
make it known
that keep.class=TRUE is an option.  This version is

## add keep.class, non-generic
aperm <- function (a, perm, resize = TRUE, keep.class=FALSE)
{
     if (missing(perm))
         perm <- integer(0L)
     result <- .Internal(aperm(a, perm, resize))
     if(keep.class) class(result) <- class(a)
     result
}

> * make aperm a generic function
>    - without a keep.class argument
>    - with a ... argument
>    - methods for classes like table could have keep.class = TRUE
This would be much better, as long as an aperm.table method was added to 
base, to complement table() itself,
and gives the desired behavior for table objects by default.
This version seems to be:

## make generic, with ...
aperm <- function(a, ...)
     UseMethod("aperm", ...)

aperm.default <- function (a, perm, resize = TRUE, ...)
{
     if (missing(perm))
         perm <- integer(0L)
     .Internal(aperm(a, perm, resize))
}

aperm.table <- function(a, perm, resize=TRUE, keep.class=TRUE, ...)
{
     result <- aperm.default(a, perm, resize=resize)
     if(keep.class) class(result) <- class(a)
     result
}

But it throws an error, maybe because I haven't redefined aperm as a 
generic:

 > UCB <- aperm(UCBAdmissions, c(2,1,3))
Error in aperm(UCBAdmissions, c(2, 1, 3)) :
   '...' used in an incorrect context

The .table method does work as desired:

 > UCB <- aperm.table(UCBAdmissions, c(2,1,3))
 > str(UCB)
  table [1:2, 1:2, 1:6] 512 89 313 19 353 17 207 8 120 202 ...
  - attr(*, "dimnames")=List of 3
   ..$ Gender: chr [1:2] "Male" "Female"
   ..$ Admit : chr [1:2] "Admitted" "Rejected"
   ..$ Dept  : chr [1:6] "A" "B" "C" "D" ...
 >

> * make aperm a generic function
>    - without a keep.class argument
>    - with a ... argument
>    - default method have keep.class = TRUE
>
> The third option would give the proposed behavior by default, but
> allow a way out for classes where the behavior is wrong.  This puts
> the burden on a class author to realize the potential problem with
> aperm, so my preference is one of the first two options.
>
>> aperm() was designed for multidimensional arrays, but is also useful for
>> table objects, particularly
>> with the lattice, vcd and vcdExtra packages.  But aperm() was designed
>> and implemented before other
>> related object classes were conceived, and I propose a small tune-up to
>> make it more generally useful.
>>
>> The problem is that  aperm() always returns an object of class 'array',
>> which causes problems for methods
>> designed for table objects. It also requires some package writers to
>> implement both .array and .table
>> methods for the same functionality, usually one in terms of the other.
>> Some examples of unexpected, and initially perplexing results (when only
>> methods for one class are implemented)
>> are shown below.
>>
>>
>>> library(vcd)
>>> pairs(UCBAdmissions, shade=TRUE)
>>> UCB<- aperm(UCBAdmissions, c(2, 1, 3))
>>>
>>> # UCB is now an array, not a table
>>> pairs(UCB, shade=TRUE)
>> There were 50 or more warnings (use warnings() to see the first 50)
>>> # fix it, to get pairs.table
>>> class(UCB)<- "table"
>>> pairs(UCB, shade=TRUE)
>>>
>>
>>
>> Of course, I can define a new function, tperm() that does what I think
>> should be the expected behavior:
>>
>> # aperm, for table objects
>>
>> tperm<- function(a, perm, resize = TRUE) {
>>      result<- aperm(a, per, resize)
>>      class(result)<- class(a)
>>      result
>> }
>>
>> But I think it is more natural to include this functionality in aperm()
>> itself.  Thus, I propose the following
>> revision of base::aperm(), at the R level:
>>
>> aperm<- function (a, perm, resize = TRUE, keep.class=TRUE)
>> {
>>      if (missing(perm))
>>          perm<- integer(0L)
>>      result<- .Internal(aperm(a, perm, resize))
>>      if(keep.class) class(result)<- class(a)
>>      result
>> }
>>
>>
>> I don't think this would break any existing code, except where someone
>> depended on coercion to an array.
>> The drop-in replacement for aperm would set keep.class=FALSE by default,
>> but I think TRUE is  more
>> natural.
>>
>> FWIW, here are the methods for table and array objects
> >from my current (non-representative) session.
>>> methods(class="table")
>>   [1] as.data.frame.table barchart.table*     cloud.table*
>> contourplot.table*  dotplot.table*
>>   [6] head.table*         levelplot.table*    pairs.table*
>> plot.table*         print.table
>> [11] summary.table       tail.table*
>>
>>     Non-visible functions are asterisked
>>> methods(class="array")
>> [1] anyDuplicated.array as.data.frame.array as.raster.array*
>> barchart.array*     contourplot.array*  dotplot.array*
>> [7] duplicated.array    levelplot.array*    unique.array
>>
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept.
>> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From maechler at stat.math.ethz.ch  Wed Dec 29 15:30:33 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Dec 2010 15:30:33 +0100
Subject: [Rd] aperm() should retain class of input object
In-Reply-To: <4D1B3893.8040500@yorku.ca>
References: <4D18BF9A.6040404@yorku.ca> <yajf7heu9cvy.fsf@gmail.com>
	<4D1B3893.8040500@yorku.ca>
Message-ID: <19739.17929.868218.413392@cmath-6.math.ethz.ch>

>>>>> Michael Friendly <friendly at yorku.ca>
>>>>>     on Wed, 29 Dec 2010 08:33:07 -0500 writes:

    > On 12/28/2010 9:43 AM, Tim Hesterberg wrote:
    >> Having aperm() return an object of the same class is dangerous, there
    >> are undoubtedly classes for which that is not appropriate, producing an
    >> illegal object for that class or quietly giving incorrect results.
    > OK.  I can see that my initial proposal would be dangerous for xtabs 
    > objects without further
    > modifications and that it is unwise to change default behavior in base 
    > functions without
    > very strong reasons.

    >> Three alternatives are to:
    >> * add the keep.class option but with default FALSE
    > This first option is the minimally invasive corrective surgery.
    > This would put the burden on the user (or package writer), but at least 
    > make it known
    > that keep.class=TRUE is an option.  This version is

    > ## add keep.class, non-generic
    > aperm <- function (a, perm, resize = TRUE, keep.class=FALSE)
    > {
    > if (missing(perm))
    > perm <- integer(0L)
    > result <- .Internal(aperm(a, perm, resize))
    > if(keep.class) class(result) <- class(a)
    > result
    > }

    >> * make aperm a generic function
    >> - without a keep.class argument
    >> - with a ... argument
    >> - methods for classes like table could have keep.class = TRUE
    > This would be much better, as long as an aperm.table method was added to 
    > base, to complement table() itself,
    > and gives the desired behavior for table objects by default.
    > This version seems to be:

    > ## make generic, with ...
    > aperm <- function(a, ...)
    > UseMethod("aperm", ...)

use      UseMethod("aperm")

instead and then all is fine


    > aperm.default <- function (a, perm, resize = TRUE, ...)
    > {
    > if (missing(perm))
    > perm <- integer(0L)
    > .Internal(aperm(a, perm, resize))
    > }

    > aperm.table <- function(a, perm, resize=TRUE, keep.class=TRUE, ...)
    > {
    > result <- aperm.default(a, perm, resize=resize)
    > if(keep.class) class(result) <- class(a)
    > result
    > }

    > But it throws an error, maybe because I haven't redefined aperm as a 
    > generic:

    >> UCB <- aperm(UCBAdmissions, c(2,1,3))
    > Error in aperm(UCBAdmissions, c(2, 1, 3)) :
    > '...' used in an incorrect context

.. well,  because you've used extraneous "..." in the S3 generic
definition (see above).

I'm really sympathetic with your proposal and would indeed
implement it (for R-devel aka "R 2.13.0 to be")
unless someone has good arguments for something else.
{{well, my version *would* keep the  'perm = NULL' default for
  both default and table methods.}}

Martin Maechler, ETH Zurich



    > The .table method does work as desired:

    >> UCB <- aperm.table(UCBAdmissions, c(2,1,3))
    >> str(UCB)
    > table [1:2, 1:2, 1:6] 512 89 313 19 353 17 207 8 120 202 ...
    > - attr(*, "dimnames")=List of 3
    > ..$ Gender: chr [1:2] "Male" "Female"
    > ..$ Admit : chr [1:2] "Admitted" "Rejected"
    > ..$ Dept  : chr [1:6] "A" "B" "C" "D" ...
    >> 

    >> * make aperm a generic function
    >> - without a keep.class argument
    >> - with a ... argument
    >> - default method have keep.class = TRUE
    >> 
    >> The third option would give the proposed behavior by default, but
    >> allow a way out for classes where the behavior is wrong.  This puts
    >> the burden on a class author to realize the potential problem with
    >> aperm, so my preference is one of the first two options.
    >> 
    >>> aperm() was designed for multidimensional arrays, but is also useful for
    >>> table objects, particularly
    >>> with the lattice, vcd and vcdExtra packages.  But aperm() was designed
    >>> and implemented before other
    >>> related object classes were conceived, and I propose a small tune-up to
    >>> make it more generally useful.
    >>> 
    >>> The problem is that  aperm() always returns an object of class 'array',
    >>> which causes problems for methods
    >>> designed for table objects. It also requires some package writers to
    >>> implement both .array and .table
    >>> methods for the same functionality, usually one in terms of the other.
    >>> Some examples of unexpected, and initially perplexing results (when only
    >>> methods for one class are implemented)
    >>> are shown below.
    >>> 
    >>> 
    >>>> library(vcd)
    >>>> pairs(UCBAdmissions, shade=TRUE)
    >>>> UCB<- aperm(UCBAdmissions, c(2, 1, 3))
    >>>> 
    >>>> # UCB is now an array, not a table
    >>>> pairs(UCB, shade=TRUE)
    >>> There were 50 or more warnings (use warnings() to see the first 50)
    >>>> # fix it, to get pairs.table
    >>>> class(UCB)<- "table"
    >>>> pairs(UCB, shade=TRUE)
    >>>> 
    >>> 
    >>> 
    >>> Of course, I can define a new function, tperm() that does what I think
    >>> should be the expected behavior:
    >>> 
    >>> # aperm, for table objects
    >>> 
    >>> tperm<- function(a, perm, resize = TRUE) {
    >>> result<- aperm(a, per, resize)
    >>> class(result)<- class(a)
    >>> result
    >>> }
    >>> 
    >>> But I think it is more natural to include this functionality in aperm()
    >>> itself.  Thus, I propose the following
    >>> revision of base::aperm(), at the R level:
    >>> 
    >>> aperm<- function (a, perm, resize = TRUE, keep.class=TRUE)
    >>> {
    >>> if (missing(perm))
    >>> perm<- integer(0L)
    >>> result<- .Internal(aperm(a, perm, resize))
    >>> if(keep.class) class(result)<- class(a)
    >>> result
    >>> }
    >>> 
    >>> 
    >>> I don't think this would break any existing code, except where someone
    >>> depended on coercion to an array.
    >>> The drop-in replacement for aperm would set keep.class=FALSE by default,
    >>> but I think TRUE is  more
    >>> natural.
    >>> 
    >>> FWIW, here are the methods for table and array objects
    >> >from my current (non-representative) session.
    >>>> methods(class="table")
    >>> [1] as.data.frame.table barchart.table*     cloud.table*
    >>> contourplot.table*  dotplot.table*
    >>> [6] head.table*         levelplot.table*    pairs.table*
    >>> plot.table*         print.table
    >>> [11] summary.table       tail.table*
    >>> 
    >>> Non-visible functions are asterisked
    >>>> methods(class="array")
    >>> [1] anyDuplicated.array as.data.frame.array as.raster.array*
    >>> barchart.array*     contourplot.array*  dotplot.array*
    >>> [7] duplicated.array    levelplot.array*    unique.array
    >>> 
    >>> 
    >>> --
    >>> Michael Friendly     Email: friendly AT yorku DOT ca
    >>> Professor, Psychology Dept.
    >>> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
    >>> 4700 Keele Street    Web:http://www.datavis.ca
    >>> Toronto, ONT  M3J 1P3 CANADA


    > -- 
    > Michael Friendly     Email: friendly AT yorku DOT ca
    > Professor, Psychology Dept.
    > York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
    > 4700 Keele Street    Web:   http://www.datavis.ca
    > Toronto, ONT  M3J 1P3 CANADA

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From kevin.r.coombes at gmail.com  Wed Dec 29 17:45:21 2010
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Wed, 29 Dec 2010 10:45:21 -0600
Subject: [Rd] Want non-ASCII characters in data package
Message-ID: <4D1B65A1.1020203@gmail.com>

Hi,

I have a data frame that includes several names that (if typeset 
correctly) require accented characters not available in the ASCII 
character set.

I'd like to include this data frame as example data in an R package.  
I'd also like the R CMD check warning about the use of non-ASCII 
characters to go away, in part so I could submit the package somewhere 
that wouldn't balk at the presence of the warning.  (I gather from older 
posts that there are environment variables to skip this check.  Those 
will work for me personally but will not necessarily appease the 
maintainers of sites like CRAN where I might want to submit the package.)

Is there any way to use the correctly accented characters by setting a 
different character encoding or equivalent for the data frame? Or am I 
forced to remove the offending accents in order to be ASCII-pure and 
thus leave people and places with an incorrect representation of their 
names?

     Kevin


From pgilbert at bank-banque-canada.ca  Wed Dec 29 18:44:22 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 29 Dec 2010 17:44:22 +0000
Subject: [Rd] R-forge out?
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D01E292@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20101229/047043be/attachment.pl>

From murdoch.duncan at gmail.com  Wed Dec 29 18:51:09 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Dec 2010 12:51:09 -0500
Subject: [Rd] R-forge out?
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D01E292@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
References: <6441154A9FF1CD4386AF4ABF141A056D01E292@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
Message-ID: <4D1B750D.1020606@gmail.com>

On 29/12/2010 12:44 PM, Paul Gilbert wrote:
> Is anyone else having trouble connecting to R-forge svn?  (Perhaps I missed an outage announcement, or is it bad weather?)

I've also had trouble since yesterday.  The main web page also appears 
to be down...

Duncan Murdoch


From josh.m.ulrich at gmail.com  Wed Dec 29 20:21:26 2010
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 29 Dec 2010 13:21:26 -0600
Subject: [Rd] as.POSIXlt.factor and '...'
Message-ID: <AANLkTim++ZXSQquZ7sUOC0b1NqZqzGx3wMAPg1u2HH53@mail.gmail.com>

I noticed a difference in how as.POSIXct handled the 'format' argument
when 'x' is character versus when 'x' is a factor.  For example:

myFormat <- "%d-%m-%Y"
myDateStr <- format(Sys.Date()+1:5,myFormat)
as.POSIXct(myDateStr, format=myFormat)
as.POSIXct(factor(myDateStr), format=myFormat)

It seems to be caused by '...' not being passed in as.POSIXlt.factor.
Would it make sense to change the function to pass '...'?  I.e. from:
as.POSIXlt.factor <- function(x, ...) as.POSIXlt(as.character(x))
to:
as.POSIXlt.factor <- function(x, ...) as.POSIXlt(as.character(x), ...)

Regards,
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com


From matteo at naufraghi.net  Thu Dec 30 13:50:26 2010
From: matteo at naufraghi.net (Matteo Bertini)
Date: Thu, 30 Dec 2010 13:50:26 +0100
Subject: [Rd] key-value mapping in C inside R?
Message-ID: <4D1C8012.7050403@naufraghi.net>

I'm testing some modifications in arima.c.
I've noticed that a big internal array of double (rbar) is usually 
sparse and I'd like to add an option to store it as key-value mapping.

Is there a library function or some other approach already used inside 
the R core for key-value mappings?

Thanks,
Matteo Bertini


From simon.urbanek at r-project.org  Thu Dec 30 16:03:53 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 30 Dec 2010 10:03:53 -0500
Subject: [Rd] key-value mapping in C inside R?
In-Reply-To: <4D1C8012.7050403@naufraghi.net>
References: <4D1C8012.7050403@naufraghi.net>
Message-ID: <59A3C41D-ADC8-4B67-B83E-97E490B491FE@r-project.org>


On Dec 30, 2010, at 7:50 AM, Matteo Bertini wrote:

> I'm testing some modifications in arima.c.
> I've noticed that a big internal array of double (rbar) is usually sparse and I'd like to add an option to store it as key-value mapping.
> 
> Is there a library function or some other approach already used inside the R core for key-value mappings?
> 

environment created with hash=TRUE, e.g.:
e = new.env(TRUE, emptyenv())
e[["foo"]] = "bar"

You can even set "size" with the expected size if you know it in advance.

Cheers,
Simon


From matteo at naufraghi.net  Thu Dec 30 17:25:48 2010
From: matteo at naufraghi.net (Matteo Bertini)
Date: Thu, 30 Dec 2010 17:25:48 +0100
Subject: [Rd] key-value mapping in C inside R?
In-Reply-To: <59A3C41D-ADC8-4B67-B83E-97E490B491FE@r-project.org>
References: <4D1C8012.7050403@naufraghi.net>
	<59A3C41D-ADC8-4B67-B83E-97E490B491FE@r-project.org>
Message-ID: <146E8656-8D6A-4FFC-AB4B-BB0E8570F105@naufraghi.net>

Il giorno 30/dic/2010, alle ore 16.03, Simon Urbanek ha scritto:

> On Dec 30, 2010, at 7:50 AM, Matteo Bertini wrote:
> 
>> I'm testing some modifications in arima.c.
>> I've noticed that a big internal array of double (rbar) is usually sparse and I'd like to add an option to store it as key-value mapping.
>> 
>> Is there a library function or some other approach already used inside the R core for key-value mappings?
>> 
> 
> environment created with hash=TRUE, e.g.:
> e = new.env(TRUE, emptyenv())
> e[["foo"]] = "bar"
> 
> You can even set "size" with the expected size if you know it in advance.

Interesting, but is it possible to use this from the C code?

Thanks,
Matteo

From simon.urbanek at r-project.org  Thu Dec 30 19:16:59 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 30 Dec 2010 13:16:59 -0500
Subject: [Rd] key-value mapping in C inside R?
In-Reply-To: <146E8656-8D6A-4FFC-AB4B-BB0E8570F105@naufraghi.net>
References: <4D1C8012.7050403@naufraghi.net>
	<59A3C41D-ADC8-4B67-B83E-97E490B491FE@r-project.org>
	<146E8656-8D6A-4FFC-AB4B-BB0E8570F105@naufraghi.net>
Message-ID: <663226FA-CC47-45C3-9702-545FD347086E@r-project.org>


On Dec 30, 2010, at 11:25 AM, Matteo Bertini wrote:

> Il giorno 30/dic/2010, alle ore 16.03, Simon Urbanek ha scritto:
> 
>> On Dec 30, 2010, at 7:50 AM, Matteo Bertini wrote:
>> 
>>> I'm testing some modifications in arima.c.
>>> I've noticed that a big internal array of double (rbar) is usually sparse and I'd like to add an option to store it as key-value mapping.
>>> 
>>> Is there a library function or some other approach already used inside the R core for key-value mappings?
>>> 
>> 
>> environment created with hash=TRUE, e.g.:
>> e = new.env(TRUE, emptyenv())
>> e[["foo"]] = "bar"
>> 
>> You can even set "size" with the expected size if you know it in advance.
> 
> Interesting, but is it possible to use this from the C code?
> 

Sure, assignment:
void defineVar(SEXP symbol, SEXP value, SEXP rho)
retrieval:
SEXP findVarInFrame(SEXP rho, SEXP symbol)

so the above assignment would be in C
defineVar(install("foo"), mkString("bar"), env)
where env is the environment created above.

Cheers,
Simon


From mdsumner at gmail.com  Thu Dec 30 21:10:16 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 31 Dec 2010 07:10:16 +1100
Subject: [Rd] minor outdated link error in MkRules.dist
Message-ID: <AANLkTimdp_PREq2KkOth3bpTWx_t4tE5btyVvTgW1Kjj@mail.gmail.com>

Hello,

The file [R]/src/gnuwin32/MkRules.dist contains the following link:

http://www.stats.ox.ac.uk/pub/Rtools/goodies/local.zip

It seems this has been updated to be

http://www.stats.ox.ac.uk/pub/Rtools/goodies/Win32/local.zip

This in R-patched_2010-12-27_r53886.

Cheers, Mike.


-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From hadley at rice.edu  Thu Dec 30 21:34:18 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 30 Dec 2010 14:34:18 -0600
Subject: [Rd] key-value mapping in C inside R?
In-Reply-To: <4D1C8012.7050403@naufraghi.net>
References: <4D1C8012.7050403@naufraghi.net>
Message-ID: <AANLkTinpt1Ssi2Cg4SRgtmkSPib9UGA4fggZmVM=tmuu@mail.gmail.com>

Why not use a sparse Matrix package?
Hadley

On Thu, Dec 30, 2010 at 6:50 AM, Matteo Bertini <matteo at naufraghi.net> wrote:
> I'm testing some modifications in arima.c.
> I've noticed that a big internal array of double (rbar) is usually sparse
> and I'd like to add an option to store it as key-value mapping.
>
> Is there a library function or some other approach already used inside the R
> core for key-value mappings?
>
> Thanks,
> Matteo Bertini
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From mdsumner at gmail.com  Thu Dec 30 22:13:14 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 31 Dec 2010 08:13:14 +1100
Subject: [Rd] problem building R 2.12.1 64-bit on Windows 7
Message-ID: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>

Hello,

I am stuck trying to build 64-bit R 2.12.1 on Windows 7, hopefully the
problem is obvious and someone can point out what I'm missing.

Well into the "make all recommended" process, I get an error:

make[4]: *** [Rzlib.dll] Error 4

(A longer report on the error in the build print is below - there
is also help output from sed that I have included but don't know if it
is relevant. )

If I follow the same set up but choose a 32-bit build it runs
successfully to completion and I can run R.

I have tried this on two different machines running 64-bit Windows
with the released R 2.12.1. The error is the same when using
R-patched_2010-12-27_r53886.

I'm sorry if this is something obvious, but I believe I've followed
the instructions carefully and do not know what I might be doing
wrong.

As far as I can tell I should not need to modify BINPREF64 or SYMPAT64
if use Rtools 2.12. Is that correct?

A description of the set up and build process follows.

Best regards, Mike.


----------------------------------
Context
----------------------------------

Using Rtools212.exe, with MiKTeX, no static HTML help, and no
installer build.

Everything installed is Run As Administrator, including the command
prompt used to build R.

-----------------------------------
Environment Variables
-----------------------------------

These environment variables are set:

PATH

Rtools and MiKTeX installed, with the following at the start of PATH:

c:\inst\R\Rtools\bin;c:\inst\R\Rtools\perl\bin;c:\inst\R\Rtools\MinGW\bin;c:\inst\R\Rtools\MinGW64\bin;C:\inst\MiKTeX\miktex\bin;

TAR_OPTIONS

Options to avoid messages when extracting sources:

--no-same-owner --no-same-permissions

TMPDIR

I can write to this directory:

G:\systemTEMP

--------------------------------
Build steps
--------------------------------

1) Extract from the archive

tar -xf R-patched_2010-12-27_r53886.tar.gz

2) Copy Rsrc "src/" and "Tcl/" into R-patched/ from the relevant 64
bit Rtools source

3) Create the following file [R_HOME]/src/gnuwin32/MkRules.local

# 32- or 64-bit Windows?
WIN = 64

JPEGDIR = jpeg-8a

4) Make

cd R-patched/src/gnuwin32
make all recommended


---------------------------------
Error message in context
---------------------------------
. . .
making uncompr.d from uncompr.c
making zutil.d from zutil.c
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c adler32.c -o adler32.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c compress.c -o compress.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c crc32.c -o crc32.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c deflate.c -o deflate.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c gzio.c -o gzio.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c infback.c -o infback.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c inffast.c -o inffast.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c inflate.c -o inflate.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c inftrees.c -o inftrees.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c trees.c -o trees.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c uncompr.c -o uncompr.o
gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
-DR_ARCH='"x64"' -DW64 -c zutil.c -o zutil.o
Usage: sed [OPTION]... {script-only-if-no-other-script} [input-file]...

  -n, --quiet, --silent
                 suppress automatic printing of pattern space
  -e script, --expression=script
                 add the script to the commands to be executed
  -f script-file, --file=script-file
                 add the contents of script-file to the commands to be executed
  --follow-symlinks
                 follow symlinks when processing in place
  -i[SUFFIX], --in-place[=SUFFIX]
                 edit files in place (makes backup if extension supplied)
  -b, --binary
                 open files in binary mode (CR+LFs are not processed specially)
  -l N, --line-length=N
                 specify the desired line-wrap length for the `l' command
  --posix
                 disable all GNU extensions.
  -r, --regexp-extended
                 use extended regular expressions in the script.
  -s, --separate
                 consider files as separate rather than as a single continuous
                 long stream.
  -u, --unbuffered
                 load minimal amounts of data from the input files and flush
                 the output buffers more often
      --help     display this help and exit
      --version  output version information and exit

If no -e, --expression, -f, or --file option is given, then the first
non-option argument is taken as the sed script to interpret.  All
remaining arguments are names of input files; if no input files are
specified, then the standard input is read.

GNU sed home page: <http://www.gnu.org/software/sed/>.
General help using GNU software: <http://www.gnu.org/gethelp/>.
make[4]: *** [Rzlib.dll] Error 4
make[3]: *** [rlibs] Error 1
make[2]: *** [../../bin/x64/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2




-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From murdoch.duncan at gmail.com  Thu Dec 30 23:19:54 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Dec 2010 17:19:54 -0500
Subject: [Rd] problem building R 2.12.1 64-bit on Windows 7
In-Reply-To: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>
References: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>
Message-ID: <4D1D058A.8000600@gmail.com>

On 10-12-30 4:13 PM, Michael Sumner wrote:
> Hello,
>
> I am stuck trying to build 64-bit R 2.12.1 on Windows 7, hopefully the
> problem is obvious and someone can point out what I'm missing.
>
> Well into the "make all recommended" process, I get an error:
>
> make[4]: *** [Rzlib.dll] Error 4
>
> (A longer report on the error in the build print is below - there
> is also help output from sed that I have included but don't know if it
> is relevant. )
>
> If I follow the same set up but choose a 32-bit build it runs
> successfully to completion and I can run R.
>
> I have tried this on two different machines running 64-bit Windows
> with the released R 2.12.1. The error is the same when using
> R-patched_2010-12-27_r53886.
>
> I'm sorry if this is something obvious, but I believe I've followed
> the instructions carefully and do not know what I might be doing
> wrong.
>
> As far as I can tell I should not need to modify BINPREF64 or SYMPAT64
> if use Rtools 2.12. Is that correct?
>
> A description of the set up and build process follows.
>
> Best regards, Mike.
>
>
> ----------------------------------
> Context
> ----------------------------------
>
> Using Rtools212.exe, with MiKTeX, no static HTML help, and no
> installer build.
>
> Everything installed is Run As Administrator, including the command
> prompt used to build R.
>
> -----------------------------------
> Environment Variables
> -----------------------------------
>
> These environment variables are set:
>
> PATH
>
> Rtools and MiKTeX installed, with the following at the start of PATH:
>
> c:\inst\R\Rtools\bin;c:\inst\R\Rtools\perl\bin;c:\inst\R\Rtools\MinGW\bin;c:\inst\R\Rtools\MinGW64\bin;C:\inst\MiKTeX\miktex\bin;
>
> TAR_OPTIONS
>
> Options to avoid messages when extracting sources:
>
> --no-same-owner --no-same-permissions
>
> TMPDIR
>
> I can write to this directory:
>
> G:\systemTEMP
>
> --------------------------------
> Build steps
> --------------------------------
>
> 1) Extract from the archive
>
> tar -xf R-patched_2010-12-27_r53886.tar.gz
>
> 2) Copy Rsrc "src/" and "Tcl/" into R-patched/ from the relevant 64
> bit Rtools source
>
> 3) Create the following file [R_HOME]/src/gnuwin32/MkRules.local
>
> # 32- or 64-bit Windows?
> WIN = 64
>
> JPEGDIR = jpeg-8a
>
> 4) Make
>
> cd R-patched/src/gnuwin32
> make all recommended
>
>
> ---------------------------------
> Error message in context
> ---------------------------------
> . . .
> making uncompr.d from uncompr.c
> making zutil.d from zutil.c
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c adler32.c -o adler32.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c compress.c -o compress.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c crc32.c -o crc32.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c deflate.c -o deflate.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c gzio.c -o gzio.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c infback.c -o infback.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c inffast.c -o inffast.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c inflate.c -o inflate.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c inftrees.c -o inftrees.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c trees.c -o trees.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c uncompr.c -o uncompr.o
> gcc -std=gnu99   -I../../include -DHAVE_CONFIG_H -O3 -Wall -pedantic
> -DR_ARCH='"x64"' -DW64 -c zutil.c -o zutil.o
> Usage: sed [OPTION]... {script-only-if-no-other-script} [input-file]...
>
>    -n, --quiet, --silent
>                   suppress automatic printing of pattern space
>    -e script, --expression=script
>                   add the script to the commands to be executed
>    -f script-file, --file=script-file
>                   add the contents of script-file to the commands to be executed
>    --follow-symlinks
>                   follow symlinks when processing in place
>    -i[SUFFIX], --in-place[=SUFFIX]
>                   edit files in place (makes backup if extension supplied)
>    -b, --binary
>                   open files in binary mode (CR+LFs are not processed specially)
>    -l N, --line-length=N
>                   specify the desired line-wrap length for the `l' command
>    --posix
>                   disable all GNU extensions.
>    -r, --regexp-extended
>                   use extended regular expressions in the script.
>    -s, --separate
>                   consider files as separate rather than as a single continuous
>                   long stream.
>    -u, --unbuffered
>                   load minimal amounts of data from the input files and flush
>                   the output buffers more often
>        --help     display this help and exit
>        --version  output version information and exit
>
> If no -e, --expression, -f, or --file option is given, then the first
> non-option argument is taken as the sed script to interpret.  All
> remaining arguments are names of input files; if no input files are
> specified, then the standard input is read.
>
> GNU sed home page:<http://www.gnu.org/software/sed/>.
> General help using GNU software:<http://www.gnu.org/gethelp/>.
> make[4]: *** [Rzlib.dll] Error 4
> make[3]: *** [rlibs] Error 1
> make[2]: *** [../../bin/x64/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2

I don't know what's going wrong.  At that point it is supposed to be 
making Rzlib.dll (as the error at the end shows it was).  That is made 
using src/extra/zlib/Makefile.win. I don't see any calls to "sed" in 
there, but there's one in the implicit rule to make the .dll (in 
src/gnuwin32/MkRules), namely

$(SED) -n $(SYMPAT)

Do you have a definition for SYMPAT that overrides ours, or SYMPAT64 
(which is used in ours)?

If that's not it, you could remove the @ sign from the beginning of that 
line in MkRules, and see what it is trying to do just before it dies.

Duncan Murdoch


From pdalgd at gmail.com  Fri Dec 31 00:34:58 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 31 Dec 2010 00:34:58 +0100
Subject: [Rd] problem building R 2.12.1 64-bit on Windows 7
In-Reply-To: <4D1D058A.8000600@gmail.com>
References: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>
	<4D1D058A.8000600@gmail.com>
Message-ID: <78F4D16E-7D81-4493-86F4-92C76907C4B8@gmail.com>


On Dec 30, 2010, at 23:19 , Duncan Murdoch wrote:

> On 10-12-30 4:13 PM, Michael Sumner wrote:
>> Hello,
>> ...
>> make[4]: *** [Rzlib.dll] Error 4
>> make[3]: *** [rlibs] Error 1
>> make[2]: *** [../../bin/x64/R.dll] Error 2
>> make[1]: *** [rbuild] Error 2
>> make: *** [all] Error 2
> 
> I don't know what's going wrong.  At that point it is supposed to be making Rzlib.dll (as the error at the end shows it was).  That is made using src/extra/zlib/Makefile.win. I don't see any calls to "sed" in there, but there's one in the implicit rule to make the .dll (in src/gnuwin32/MkRules), namely
> 
> $(SED) -n $(SYMPAT)
> 
> Do you have a definition for SYMPAT that overrides ours, or SYMPAT64 (which is used in ours)?
> 
> If that's not it, you could remove the @ sign from the beginning of that line in MkRules, and see what it is trying to do just before it dies.
> 
> Duncan Murdoch

Off-the-cuff: Is there a virus scanner active on the system? We have had a couple of reports that turned out to be antivirus software swiping files away for checking right under the nose of their confused maker...

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mdsumner at gmail.com  Fri Dec 31 00:53:47 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 31 Dec 2010 10:53:47 +1100
Subject: [Rd] problem building R 2.12.1 64-bit on Windows 7
In-Reply-To: <78F4D16E-7D81-4493-86F4-92C76907C4B8@gmail.com>
References: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>
	<4D1D058A.8000600@gmail.com>
	<78F4D16E-7D81-4493-86F4-92C76907C4B8@gmail.com>
Message-ID: <AANLkTi=jAjNdE9rJEM6Lh99-yFfMqd8qaKHEeyRc_ZKz@mail.gmail.com>

Hello, thank you both - in an earlier test I turned off Kaspersky
completely to check that but saw no difference, but I'm only going on
my memory for that.

I'll check again more completely later today and also try turning on
the reporting for the sed line in MkRules as Duncan suggested.

I don't have an override for SYMPAT or SYMPAT64.

Cheers, Mike.



On Fri, Dec 31, 2010 at 10:34 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Dec 30, 2010, at 23:19 , Duncan Murdoch wrote:
>
>> On 10-12-30 4:13 PM, Michael Sumner wrote:
>>> Hello,
>>> ...
>>> make[4]: *** [Rzlib.dll] Error 4
>>> make[3]: *** [rlibs] Error 1
>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>> make[1]: *** [rbuild] Error 2
>>> make: *** [all] Error 2
>>
>> I don't know what's going wrong. ?At that point it is supposed to be making Rzlib.dll (as the error at the end shows it was). ?That is made using src/extra/zlib/Makefile.win. I don't see any calls to "sed" in there, but there's one in the implicit rule to make the .dll (in src/gnuwin32/MkRules), namely
>>
>> $(SED) -n $(SYMPAT)
>>
>> Do you have a definition for SYMPAT that overrides ours, or SYMPAT64 (which is used in ours)?
>>
>> If that's not it, you could remove the @ sign from the beginning of that line in MkRules, and see what it is trying to do just before it dies.
>>
>> Duncan Murdoch
>
> Off-the-cuff: Is there a virus scanner active on the system? We have had a couple of reports that turned out to be antivirus software swiping files away for checking right under the nose of their confused maker...
>
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk ?Priv: PDalgd at gmail.com
>
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From mdsumner at gmail.com  Fri Dec 31 05:12:01 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 31 Dec 2010 15:12:01 +1100
Subject: [Rd] problem building R 2.12.1 64-bit on Windows 7
In-Reply-To: <AANLkTi=jAjNdE9rJEM6Lh99-yFfMqd8qaKHEeyRc_ZKz@mail.gmail.com>
References: <AANLkTim2N85SDbd2aPdJ5Xhk_1U=pz=DrveLZZYVAi-Z@mail.gmail.com>
	<4D1D058A.8000600@gmail.com>
	<78F4D16E-7D81-4493-86F4-92C76907C4B8@gmail.com>
	<AANLkTi=jAjNdE9rJEM6Lh99-yFfMqd8qaKHEeyRc_ZKz@mail.gmail.com>
Message-ID: <AANLkTin780=vGqe1zjA-+y8NPXwr8gsxCYuG8niwsi2t@mail.gmail.com>

Hello,

It seems the problem was as elementary as me mis-interpreting the
instructions in 3.1.3 of the R Installation and Administration manual:

"Look at ?MkRules.dist? and if settings need to be altered, copy it to
?MkRules.local? and edit the settings there."

I took that to mean that you only copy the settings that need to be
altered to a new local file, so the majority of required settings
weren't passed to MkRules itself. "Copy it" means copy the file, not
just the setting/s - a poor reading on my part, and easily checked by
seeing the resulting MkRules file.

make all recommended ran to completion without error, and with
Kaspersky in full operation.

Thanks again for the patience, I've added my updated notes below.

Cheers, Mike.

----------------------------------
Context
----------------------------------

Using Rtools212.exe, with MiKTeX, no static HTML help, and no
installer build.

Everything installed is Run As Administrator, including the command
prompt used to build R.

-----------------------------------
Environment Variables
-----------------------------------

These environment variables are set:

PATH

Rtools and MiKTeX installed, with the following at the start of PATH:

c:\inst\R\Rtools\bin;c:\inst\R\Rtools\perl\bin;c:\inst\R\Rtools\MinGW\bin;c:\inst\R\Rtools\MinGW64\bin;C:\inst\MiKTeX\miktex\bin;

TAR_OPTIONS

Options to avoid messages when extracting sources:

--no-same-owner --no-same-permissions

TMPDIR

I can write to this directory:

G:\systemTEMP

--------------------------------
Build steps
--------------------------------


1) Extract from the archive

tar -xf R-patched_2010-12-27_r53886.tar.gz

2) Copy Rsrc "src/" and "Tcl/" into R-patched/ from the relevant 64
bit Rtools source

3) Copy [R_HOME]/src/gnuwin32/MkRules.dist as MkRules.local and make
the following changes (the jpeg setting is not required I think, I
just want to report exactly what I did)

diff MkRules.dist MkRules.local

< WIN = 32
---
> WIN = 64
64c64
< # JPEGDIR = jpeg-8a
---
> JPEGDIR = jpeg-8a


4) Make

cd R-patched/src/gnuwin32
make all recommended





On Fri, Dec 31, 2010 at 10:53 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Hello, thank you both - in an earlier test I turned off Kaspersky
> completely to check that but saw no difference, but I'm only going on
> my memory for that.
>
> I'll check again more completely later today and also try turning on
> the reporting for the sed line in MkRules as Duncan suggested.
>
> I don't have an override for SYMPAT or SYMPAT64.
>
> Cheers, Mike.
>
>
>
> On Fri, Dec 31, 2010 at 10:34 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>> On Dec 30, 2010, at 23:19 , Duncan Murdoch wrote:
>>
>>> On 10-12-30 4:13 PM, Michael Sumner wrote:
>>>> Hello,
>>>> ...
>>>> make[4]: *** [Rzlib.dll] Error 4
>>>> make[3]: *** [rlibs] Error 1
>>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>>> make[1]: *** [rbuild] Error 2
>>>> make: *** [all] Error 2
>>>
>>> I don't know what's going wrong. ?At that point it is supposed to be making Rzlib.dll (as the error at the end shows it was). ?That is made using src/extra/zlib/Makefile.win. I don't see any calls to "sed" in there, but there's one in the implicit rule to make the .dll (in src/gnuwin32/MkRules), namely
>>>
>>> $(SED) -n $(SYMPAT)
>>>
>>> Do you have a definition for SYMPAT that overrides ours, or SYMPAT64 (which is used in ours)?
>>>
>>> If that's not it, you could remove the @ sign from the beginning of that line in MkRules, and see what it is trying to do just before it dies.
>>>
>>> Duncan Murdoch
>>
>> Off-the-cuff: Is there a virus scanner active on the system? We have had a couple of reports that turned out to be antivirus software swiping files away for checking right under the nose of their confused maker...
>>
>> --
>> Peter Dalgaard
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk ?Priv: PDalgd at gmail.com
>>
>>
>
>
>
> --
> Michael Sumner
> Institute for Marine and Antarctic Studies, University of Tasmania
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


