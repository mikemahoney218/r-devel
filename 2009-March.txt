From ligges at statistik.tu-dortmund.de  Sun Mar  1 00:30:19 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Sun,  1 Mar 2009 00:30:19 +0100 (CET)
Subject: [Rd] Cannot install some packages (PR#13559)
Message-ID: <20090228233019.DF5B82834322@mail.pubhealth.ku.dk>



robert.peck1 at myfairpoint.net wrote:
> Full_Name: Robert Peck
> Version: 2.8.1
> OS: XP Home
> Submission from: (NULL) (71.168.114.196)
> 
> 
> There are some packages that I cannot install on my PC.


I doubt this is a bug. Some or all packages? Is there some pattern?
Are you installing with sufficient privileges?



> Example: LearnBayes
> 
> The following output is sent back:
> 
>> utils:::menuInstallPkgs()
> trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.8/LearnBayes_2.0.zip'
> Content type 'application/zip' length 379068 bytes (370 Kb)
> opened URL
> downloaded 370 Kb
> 
> package 'LearnBayes' successfully unpacked and MD5 sums checked
> Error in normalizePath(path) : 
>   path[1]: The system cannot find the file specified

This looks like the package has successfully installed (as the message 
indicates) but you have problems for updating some search indizes and 
other files for the help system. Which is probably a permission problem.

Have you tried to run LearnBayes? I guess it will work.

Uwe LIgges



> 
>    I have reinstalled R several times and tried different mirror sites.
> 
>    Robert Peck
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rominarengel at gmail.com  Sun Mar  1 00:50:39 2009
From: rominarengel at gmail.com (Romina Rengel)
Date: Sat, 28 Feb 2009 21:50:39 -0200
Subject: [Rd] Help on Making R Packages
Message-ID: <dd0883100902281550o70fb76acq19bacef38b22e797@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090228/72ffe8f0/attachment.pl>

From john.maindonald at anu.edu.au  Sun Mar  1 04:55:06 2009
From: john.maindonald at anu.edu.au (john.maindonald at anu.edu.au)
Date: Sun,  1 Mar 2009 04:55:06 +0100 (CET)
Subject: [Rd] Wishlist for plot.lm() (PR#13560)
Message-ID: <20090301035506.8F3482834322@mail.pubhealth.ku.dk>

Full_Name: John Maindonald
Version: R-2.8.1
OS: MacOS X 10.5.6
Submission from: (NULL) (203.173.3.75)


The following code demonstrates an annoyance with plot.lm():

library(DAAGxtras)
x11(width=3.75, height=4)
nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
plot(nihills.lm, which=5)

OR try the following
xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
plot(lm(y ~ x, data=xy), which=5)

The "Cook's distance" text overplots the label for the point with the smallest
residual.  This is an issue when the size of the plot is much less than the
default, and the pointsize is not reduced proportionately.


I suggest the following:
     xx <- hii
     xx[xx >= 1] <- NA
## Insert new code
     fracht <- (1.25*par()$cin[2])/par()$pin[2]
     ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
## End insert new code
     plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
          ylim = ylim, main = main, xlab = "Leverage",
          ylab = ylab5, type = "n", ...)

Then, about 15 lines further down, replace
       legend("bottomleft", legend = "Cook's distance",
              lty = 2, col = 2, bty = "n")

by
       legend("bottomleft", legend = "Cook's distance",
              lty = 2, col = 2, text.col=2, bty = "n", y.intersp=0.5)
         # This changes the legend color to agree with the line color

Another possibility, suggested by John Fox, is to replace the caption by "Cook's
distance contours", and omit the legend entirely.  

Both John Fox and myself are comfortable with either of these fixes.

Test the changes with:
x11()
nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
plot(nihills.lm, which=5)
xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
plot(lm(y ~ x, data=xy), which=5)
x11(width=3.75, height=4)
plot(nihills.lm, which=5)
plot(lm(y ~ x, data=xy), which=5)


From ligges at statistik.tu-dortmund.de  Sun Mar  1 10:41:06 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 01 Mar 2009 10:41:06 +0100
Subject: [Rd] Help on Making R Packages
In-Reply-To: <dd0883100902281550o70fb76acq19bacef38b22e797@mail.gmail.com>
References: <dd0883100902281550o70fb76acq19bacef38b22e797@mail.gmail.com>
Message-ID: <49AA5832.3080708@statistik.tu-dortmund.de>



Romina Rengel wrote:
> I'm trying to make a R package for a work in university. It?s my first time
> and i made some modifications on Pam algorithm that is included on cluster
> package.
> So before run Rcmd build command i made the next things:
> 1- I modified pam.c and cluster.h code. I added two new arguments on pam.
> 2- I modified pam.q, i added there my two new arguments.
> 4- I create all the necessary subdirectories (man, data, src, R, etc) and
> files necessaries. I put on c:\Cluster2
> 5- I run on cmd: Rcmd build --force --binary c:/cluster2
> And the package was created (file .zip)
> 6- I installed and load my package on R
> 
> After this i tried to test with Ruspini dataset
> so I write something like:
> 
> x <-ruspini
> dd <- pam(x,3)


Do you have an adapted R function in your package?
I'd suggest to rename your function slightly (as well as the C API) in 
order to avoid conflicts with the original pam(), particularly in case 
you need the cluster package to be loaded.

Uwe Ligges

> But an error happens, function pam not recognize my 2 new arguments. It's
> like function PAM on R is not linked to my pam code on C++.
> I really need if someone can help me and tell me what i?m doing wrong.
> 
> Thank you
> 
> Romina
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sun Mar  1 11:51:06 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Mar 2009 10:51:06 +0000 (GMT)
Subject: [Rd] using predict method with an offset
In-Reply-To: <49A7B912.2090907@warwick.ac.uk>
References: <20090226151508.3x9abc7i0wgssk4k@imp.inserm.fr>
	<49A7B912.2090907@warwick.ac.uk>
Message-ID: <alpine.OSX.1.00.0903010817540.25856@tystie.local>

The para quoted dates from before the stats package was split off in 
2003, and is historical (it was true at one point, but not in R 
2.0.0, the earliest running version I have).

There is however still some truth lurking there: the code is

 	offset <- if (!is.null(off.num <- attr(tt, "offset")))
 	    eval(attr(tt, "variables")[[off.num+1]], newdata)
 	else if (!is.null(object$offset))
 	    eval(object$call$offset, newdata)

so if there is an offset term in the formula, the offset argument is 
ignored (unlike when fitting).  Further, this is wrong if there is 
more than one offset term.  Both of those would be pretty unusual, but 
I'll commit fixes for them.

predict.glm calls predict.lm to do this, so the same issues apply to 
it.

I've always thought that an 'offset' argument to lm and glm was an 
unnecessary complication (I think it predates the offset() function in 
R, although it is in the White Book p.222, for glm only).

On Fri, 27 Feb 2009, Heather Turner wrote:

> Hi Ken,
>
> First of all, whether you specify the offset by the argument or in the
> formula, your code requires that q25 is the same length as the variable
> Contr. You can set this up by defining your new data as follows:
>
> nd <- data.frame( Contr = cc , q25 = qlogis(0.25))
>
> This sorts out the problem of the warnings/errors. Secondly your two
> calls to predict give different results because you have not specified
> the same type - the first is predicting on the response scale and the
> second is predicting on the link scale. If you use
>
> predict(c1.glm, newdata = nd, type = "response")
> predict(c1f.glm, newdata = nd, type = "response")
>
> you get the same result. This does seem to go against the documentation
> however, so it would seem that the paragraph you quoted should be taken
> out of the help file for predict.lm.
>
> Best wishes,
>
> Heather
>
> Kenneth Knoblauch wrote:
>> Hi,
>>
>> I have run into another problem using offsets, this time with
>> the predict function, where there seems to be a contradiction
>> again between the behavior and the help page.
>>
>> On the man page for predict.lm, it says
>>
>> Offsets specified by offset in the fit by lm will not be included in
>> predictions, whereas those specified by an offset term in the formula
>> will be.
>>
>> While it indicates nothings about offsets under ?predict.glm, predict.glm
>> calls predict.lm. when there is a newdata argument.
>>
>> In the example below, the behavior is the opposite of the help
>> page, if I am understanding it correctly, and a warning is thrown
>> when it does seem to work as desired.
>>
>> c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
>> ), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
>> 103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
>> ), row.names = c("13", "15", "17", "19", "21", "23"), class = "data.frame")
>>
>> q25 <- rep( qlogis( 0.25 ), nrow(c1) )
>>
>> # offset defined in arguments
>> c1.glm <- glm( cbind(Correct, Incorrect) ~ Contr - 1, binomial,
>>     c1, offset = q25 )
>> # offset defined in formula
>> c1f.glm <- glm( cbind(Correct, Incorrect) ~ Contr + offset(q25) -1,
>>     binomial, c1 )
>> cc <- seq( 0, 1, len = 10 )
>> nd <- data.frame( Contr = cc )
>>
>> When predict used with model for which offset was defined in
>> the arguments, offset is taken into account and a warning
>> is emitted.
>>
>> predict(c1.glm, newdata = nd, type = "response")
>>
>>         1         2         3         4         5         6         7
>> 0.2500000 0.8859251 0.9945037 0.9997628 0.9999898 0.9999996 1.0000000
>>         8         9        10
>> 1.0000000 1.0000000 1.0000000
>> Warning message:
>> In predictor + offset :
>>   longer object length is not a multiple of shorter object length
>>
>> When predict used with model for which offset was defined in
>> the formula, an error occurs
>>
>> predict( c1f.glm, newdata = nd )
>>
>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
>> = object$xlevels) :
>>   variable lengths differ (found for 'offset(q25)')
>>
>> even if a column for offset is included in newdata,
>>
>> ndf <- cbind( nd, "offset(q25)" = rep( qlogis(0.25), length(cc) ) )
>> predict( c1f.glm, newdata = ndf )
>>
>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
>> = object$xlevels) :
>>   variable lengths differ (found for 'offset(q25)')
>>
>> unless there is a special way to specify the offset to predict
>> that I haven't been able to figure out.
>>
>> traceback indicates the problem, again, with model.frame.default
>>
>> Thank you for any clarification.
>>
>> best,
>>
>> Ken
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From plwm2 at cam.ac.uk  Sun Mar  1 12:10:04 2009
From: plwm2 at cam.ac.uk (plwm2 at cam.ac.uk)
Date: Sun,  1 Mar 2009 12:10:04 +0100 (CET)
Subject: [Rd] Colour mistake (PR#13562)
Message-ID: <20090301111004.536FB2834322@mail.pubhealth.ku.dk>

Full_Name: Peter Man
Version: 2.8.1
OS: Windows Vista
Submission from: (NULL) (128.232.240.217)


When typing out any command (for example 'log'), and using auto-completion of
that command by pressing tab twice in order to view all possible 'completions',
when you next press anything, the command turns blue rather than keeping the
original red colour.


From ripley at stats.ox.ac.uk  Mon Mar  2 09:31:02 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Mar 2009 08:31:02 +0000 (GMT)
Subject: [Rd] Colour mistake (PR#13562)
In-Reply-To: <20090301111004.536FB2834322@mail.pubhealth.ku.dk>
References: <20090301111004.536FB2834322@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903020747490.12644@gannet.stats.ox.ac.uk>

This is the way Rgui (which I guess you mean as Rterm
does not use colours) was intended to work, so it is not a 'mistake'.

Rather than 'red' and 'blue', Rgui has user-selectable separate 
colours for user input (default DarkRed) and for R output (default 
NavyBlue).  When you do what I believe you did (at least if 'anything' 
is not TAB again) you are accepting a completion, which is R output 
and hence is in the 'R output' colour.

What I understand you were expecting was that completions be treated 
as user input.  That is I think fairly simple to do, and I've made the 
change in R-devel (r48038).  Please try that (snapshots will be 
available tomorrow UK time) and let us know if you find the behaviour 
more intuitive.

On Sun, 1 Mar 2009, plwm2 at cam.ac.uk wrote:

> Full_Name: Peter Man
> Version: 2.8.1
> OS: Windows Vista
> Submission from: (NULL) (128.232.240.217)
>
>
> When typing out any command (for example 'log'), and using auto-completion of
> that command by pressing tab twice in order to view all possible 'completions',
> when you next press anything, the command turns blue rather than keeping the
> original red colour.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Mar  2 11:16:21 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Mar 2009 11:16:21 +0100
Subject: [Rd] Unexpected side effect of the ":::" operator on the value
	of isGeneric
In-Reply-To: <49A97BEF.60907@ebi.ac.uk>
References: <49A58AA7.8030500@ebi.ac.uk>
	<18857.8527.746773.902464@cmath-5.math.ethz.ch>
	<49A97BEF.60907@ebi.ac.uk>
Message-ID: <18859.45557.476230.481491@stat.math.ethz.ch>

>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
>>>>>     on Sat, 28 Feb 2009 18:01:19 +0000 writes:

    Wolfi> Dear Martin name masking is a separate issue, which I
    Wolfi> do not want to explore here.

    Wolfi> If one accepts the notion that unrelated generics of
    Wolfi> the same name may exist in different namespaces (user
    Wolfi> confusion aside, I don't see a technical reason why
    Wolfi> one shouldn't), then I find the behaviour of R in the
    Wolfi> below case puzzling: the value of
    Wolfi> "showMethods(something)" called from the global
    Wolfi> environment depends on whether or not the expression
    Wolfi> "package::something" has previously been
    Wolfi> evaluated. The value of isGeneric(something) is
    Wolfi> different when called from top-level and when called
    Wolfi> within showMethods.

    Wolfi> Best wishes Wolfgang


    Wolfi> PS1: I do apologize if this behaviour is intentional,
    Wolfi> and documented somewhere. I would then be puzzled
    Wolfi> even more though.

    Wolfi> PS2: My code example used ":::", and there are some
    Wolfi> vague warnings in its man page that ":::" is
    Wolfi> "dangerous". The problem also occurs with "::".

Thank you, Wolfgang (and Martin Morgan), for the clarification,
here and off-line. 
Just for a public summary:  
You have convinced me that this is indeed pointing to a bug in the current
R implementation, and IIUC, at least one expert (JMC) is looking at a fix.

Regards,
Martin


From ct529 at york.ac.uk  Mon Mar  2 11:41:43 2009
From: ct529 at york.ac.uk (Corrado)
Date: Mon, 2 Mar 2009 10:41:43 +0000
Subject: [Rd] Distance between clusters
Message-ID: <200903021041.44279.ct529@york.ac.uk>

Dear friends

I reformulate the question. I think I did not formulate it properly.

I have some data on some sites. I can define a dissimilarity between each pair 
of sites. Using this dissimilarity, I have clustered the sites using the 
hclust algorithm, with method ward. I then obtain 48 clusters, by cutting the 
tree using cutree with k=48. 

I would now like to estimate the distance between each pair of the 48 
resulting clusters. I have read the documentation, but I cannot find a 
solution.

Any clue on how I can do that?

This is a snippet of the code:

distPredTurn<-as.dist(dissimilarityMatrix)
hctr<-hclust(distPredTurn,"ward")
cutree(hctr,k=48)


Regards
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk


From marycmeyer at mac.com  Mon Mar  2 17:15:03 2009
From: marycmeyer at mac.com (marycmeyer at mac.com)
Date: Mon,  2 Mar 2009 17:15:03 +0100 (CET)
Subject: [Rd] R does not start on my MacBook Pro3,1 (PR#13565)
Message-ID: <20090302161504.3A7D9282BE89@mail.pubhealth.ku.dk>

Help!   I was running R code and started getting error messages that  
would not stop repeating.  I force-quit R, but when I attempted to run  
it again, it would not start (Icon kept bouncing until I force-quit  
again).  I restarted the computer, then I reinstalled R, but that did  
not fix the problem.  I deleted everything I could find related to R,  
and installed again. Each time I install I get a "successful" message,  
but it does not start.  I don't know what to try next.

I have the latest versions of the operating system.

Thanks very much for your time.

Sincerely,
Mary Meyer
Statistics Department
Colorado State University

meyer at stat.colostate.edu

	[[alternative HTML version deleted]]


From mathieu.ribatet at epfl.ch  Mon Mar  2 20:19:25 2009
From: mathieu.ribatet at epfl.ch (Mathieu Ribatet)
Date: Mon, 02 Mar 2009 20:19:25 +0100
Subject: [Rd] R does not start on my MacBook Pro3,1 (PR#13565)
In-Reply-To: <20090302161504.3A7D9282BE89@mail.pubhealth.ku.dk>
References: <20090302161504.3A7D9282BE89@mail.pubhealth.ku.dk>
Message-ID: <1236021565.6298.2.camel@mathieu-laptop>

I'm not sure this will work under MacOS but you should try to run R from
a shell and see any informative message displayed in it.

Cheers,
Mathieu

* it might be useful to give us some details about the code you ran and
caused the issue.

Le lundi 02 mars 2009 ? 17:15 +0100, marycmeyer at mac.com a ?crit :
> Help!   I was running R code and started getting error messages that  
> would not stop repeating.  I force-quit R, but when I attempted to run  
> it again, it would not start (Icon kept bouncing until I force-quit  
> again).  I restarted the computer, then I reinstalled R, but that did  
> not fix the problem.  I deleted everything I could find related to R,  
> and installed again. Each time I install I get a "successful" message,  
> but it does not start.  I don't know what to try next.
> 
> I have the latest versions of the operating system.
> 
> Thanks very much for your time.
> 
> Sincerely,
> Mary Meyer
> Statistics Department
> Colorado State University
> 
> meyer at stat.colostate.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Institute of Mathematics
Ecole Polytechnique F?d?rale de Lausanne
STAT-IMA-FSB-EPFL, Station 8
CH-1015 Lausanne   Switzerland
http://stat.epfl.ch/
Tel: + 41 (0)21 693 7907


From pgilbert at bank-banque-canada.ca  Mon Mar  2 23:00:08 2009
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 02 Mar 2009 17:00:08 -0500
Subject: [Rd] S4 data dump or?
Message-ID: <49AC56E8.50502@bank-banque-canada.ca>

I am trying to dump some data in a file that I will add to a package.  
The data has an attribute which is a S4 object, and this seems to cause 
problems.   What is the preferred way to write a file with a dataset 
that has some S4 parts, so that it can be included in a package?

Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential in...{{dropped:26}}


From ripley at stats.ox.ac.uk  Tue Mar  3 08:27:37 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Mar 2009 07:27:37 +0000 (GMT)
Subject: [Rd] S4 data dump or?
In-Reply-To: <49AC56E8.50502@bank-banque-canada.ca>
References: <49AC56E8.50502@bank-banque-canada.ca>
Message-ID: <alpine.OSX.1.00.0903030714540.53034@tystie.local>

On Mon, 2 Mar 2009, Paul Gilbert wrote:

> I am trying to dump some data in a file that I will add to a package.  The 
> data has an attribute which is a S4 object, and this seems to cause problems. 
> What is the preferred way to write a file with a dataset that has some S4 
> parts, so that it can be included in a package?

Using save() seems almost always preferable to dump(): usually a 
smaller result, avoids representation error changes for numeric types 
and encoding issues for some character vectors, works for almost all 
objects.

I am guessing that the note on ?dump about objects of type S4 is the 
issue here.

> Paul Gilbert

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Tue Mar  3 09:55:48 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 09:55:48 +0100
Subject: [Rd] execution time of .packages
Message-ID: <49ACF094.7010209@dbmail.com>

Hello,

The first time in a session I call .packages( all.available = T ), it 
takes a long time (I have many packages installed from CRAN):

 > system.time( packs <- .packages( all = T ) )
  user  system elapsed
 0.738   0.276  43.787

When I call it again, the time is now much reduced, so there must be 
some caching somewhere. I would like to try to reduce the  time it takes 
the first time, but I have not been able to identify where the caching 
takes place, and so how I can remove it to try to improve the running 
time without the caching. Without this, I have to restart my computer 
each time to vanish the caching to test a new version of the function 
(this is not going to happen)

Here is the .packages function, I am suspicious about this part : "ans 
<- c(ans, nam)" which grows the ans vector each time a suitable package 
is found, this does not sound right.

 > .packages
function (all.available = FALSE, lib.loc = NULL)
{                                               
    if (is.null(lib.loc))                       
        lib.loc <- .libPaths()                  
    if (all.available) {                        
        ans <- character(0L)                    
        lib.loc <- lib.loc[file.exists(lib.loc)]
        valid_package_version_regexp <- 
.standard_regexps()$valid_package_version                                                                             

        for (lib in lib.loc) 
{                                                
            a <- list.files(lib, all.files = FALSE, full.names = 
FALSE)       
            for (nam in a) 
{                                                  
                pfile <- file.path(lib, nam, "Meta", 
"package.rds")           
                if 
(file.exists(pfile))                                       
                  info <- 
.readRDS(pfile)$DESCRIPTION[c("Package",            
                    
"Version")]                                               
                else 
next                                                     
                if ((length(info) != 2L) || any(is.na(info)))
                  next
                if (!grepl(valid_package_version_regexp, info["Version"]))
                  next
                ans <- c(ans, nam)   ########## suspicious about this
            }
        }
        return(unique(ans))
    }
    s <- search()
    return(invisible(substring(s[substr(s, 1L, 8L) == "package:"],
        9)))
}


 > version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          9.0
year           2009
month          02
day            08
svn rev        47879
language       R
version.string R version 2.9.0 Under development (unstable) (2009-02-08 
r47879)


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ripley at stats.ox.ac.uk  Tue Mar  3 10:58:50 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Mar 2009 09:58:50 +0000 (GMT)
Subject: [Rd] execution time of .packages
In-Reply-To: <49ACF094.7010209@dbmail.com>
References: <49ACF094.7010209@dbmail.com>
Message-ID: <alpine.OSX.1.00.0903030927420.6041@tystie.local>

The caching is in the disc system: you need to find and read the 
package metadata for every package.  AFAIK it is not easy to flush the 
disc cache, but quite easy to overwrite it with later reads.  (Google 
for more info.)

If you are not concerned about validity of the installed packages you 
could skip the tests and hence the reads.

Your times are quite a bit slower than mine, so a faster disc system 
might help.  Since my server has just been rebooted (for a new 
kernel), with all of CRAN and most of BioC I get

> system.time( packs <- .packages( all = T ) )
    user  system elapsed
   0.518   0.262  25.042
> system.time( packs <- .packages( all = T ) )
    user  system elapsed
   0.442   0.080   0.522
> length(packs)
[1] 2096

There's a similar issue when installing packages: the Perl code reads 
the indices from every visible package to resolve links, and that can 
be slow the first time.


On Tue, 3 Mar 2009, Romain Francois wrote:

> Hello,
>
> The first time in a session I call .packages( all.available = T ), it takes a 
> long time (I have many packages installed from CRAN):
>
>> system.time( packs <- .packages( all = T ) )
> user  system elapsed
> 0.738   0.276  43.787
>
> When I call it again, the time is now much reduced, so there must be some 
> caching somewhere. I would like to try to reduce the  time it takes the first 
> time, but I have not been able to identify where the caching takes place, and 
> so how I can remove it to try to improve the running time without the 
> caching. Without this, I have to restart my computer each time to vanish the 
> caching to test a new version of the function (this is not going to happen)
>
> Here is the .packages function, I am suspicious about this part : "ans <- 
> c(ans, nam)" which grows the ans vector each time a suitable package is 
> found, this does not sound right.

It's OK as there are only going to be ca 2000 packages.  Try 
profiling this: .readRDS and grepl take most of the time.

>> .packages
> function (all.available = FALSE, lib.loc = NULL)
> {                                                  if (is.null(lib.loc)) 
> lib.loc <- .libPaths()                     if (all.available) { 
> ans <- character(0L)                           lib.loc <- 
> lib.loc[file.exists(lib.loc)]
>       valid_package_version_regexp <- 
> .standard_regexps()$valid_package_version
>       for (lib in lib.loc) { 
> a <- list.files(lib, all.files = FALSE, full.names = FALSE) 
> for (nam in a) { 
> pfile <- file.path(lib, nam, "Meta", "package.rds") 
> if (file.exists(pfile)) 
> info <- .readRDS(pfile)$DESCRIPTION[c("Package", 
> "Version")]                                                              else 
> next                                                                    if 
> ((length(info) != 2L) || any(is.na(info)))
>                 next
>               if (!grepl(valid_package_version_regexp, info["Version"]))
>                 next
>               ans <- c(ans, nam)   ########## suspicious about this
>           }
>       }
>       return(unique(ans))
>   }
>   s <- search()
>   return(invisible(substring(s[substr(s, 1L, 8L) == "package:"],
>       9)))
> }
>
>
>> version
>              _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          9.0
> year           2009
> month          02
> day            08
> svn rev        47879
> language       R
> version.string R version 2.9.0 Under development (unstable) (2009-02-08 
> r47879)
>
>
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Tue Mar  3 11:48:18 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 11:48:18 +0100
Subject: [Rd] execution time of .packages
In-Reply-To: <alpine.OSX.1.00.0903030927420.6041@tystie.local>
References: <49ACF094.7010209@dbmail.com>
	<alpine.OSX.1.00.0903030927420.6041@tystie.local>
Message-ID: <49AD0AF2.8090607@dbmail.com>

Prof Brian Ripley wrote:
> The caching is in the disc system: you need to find and read the 
> package metadata for every package.  AFAIK it is not easy to flush the 
> disc cache, but quite easy to overwrite it with later reads.  (Google 
> for more info.)
Thanks for the info, I'll try to find my way with these directions.

> If you are not concerned about validity of the installed packages you 
> could skip the tests and hence the reads.
>
> Your times are quite a bit slower than mine, so a faster disc system 
> might help.  Since my server has just been rebooted (for a new 
> kernel), with all of CRAN and most of BioC I get
>
>> system.time( packs <- .packages( all = T ) )
>    user  system elapsed
>   0.518   0.262  25.042
>> system.time( packs <- .packages( all = T ) )
>    user  system elapsed
>   0.442   0.080   0.522
>> length(packs)
> [1] 2096
>
> There's a similar issue when installing packages: the Perl code reads 
> the indices from every visible package to resolve links, and that can 
> be slow the first time.
>
>
> On Tue, 3 Mar 2009, Romain Francois wrote:
>
>> Hello,
>>
>> The first time in a session I call .packages( all.available = T ), it 
>> takes a long time (I have many packages installed from CRAN):
>>
>>> system.time( packs <- .packages( all = T ) )
>> user  system elapsed
>> 0.738   0.276  43.787
>>
>> When I call it again, the time is now much reduced, so there must be 
>> some caching somewhere. I would like to try to reduce the  time it 
>> takes the first time, but I have not been able to identify where the 
>> caching takes place, and so how I can remove it to try to improve the 
>> running time without the caching. Without this, I have to restart my 
>> computer each time to vanish the caching to test a new version of the 
>> function (this is not going to happen)
>>
>> Here is the .packages function, I am suspicious about this part : 
>> "ans <- c(ans, nam)" which grows the ans vector each time a suitable 
>> package is found, this does not sound right.
>
> It's OK as there are only going to be ca 2000 packages.  Try profiling 
> this: .readRDS and grepl take most of the time.
I usually do not trust the result of the profiler when a for loop is 
involved, as it tends to miss the point (or maybe I am).

Consider this script below, the profiler reports 0.22 seconds when the 
actual time spent is about 6 seconds,  and would blame rnorm as the 
bottleneck when the inefficiency is in with growing the data structure.

Rprof( )
x <- numeric( )
for( i in 1:10000){
  x <- c( x, rnorm(10) )
}
Rprof( NULL )
print( summaryRprof( ) )

$ time Rscript --vanilla profexample.R
$by.self
        self.time self.pct total.time total.pct
"rnorm"      0.22      100       0.22       100

$by.total
        total.time total.pct self.time self.pct
"rnorm"       0.22       100      0.22      100

$sampling.time
[1] 0.22

real    0m6.164s
user    0m5.156s
sys     0m0.737s

$ time Rscript --vanilla -e "rnorm(10)"
 [1]  0.836411851  1.762081444  1.076305644  2.063515383  0.643254750
 [6]  1.698620443 -1.774479062 -0.432886214 -0.007949533  0.284089832

real    0m0.224s
user    0m0.187s
sys     0m0.024s


Now, if i replace the for loop with a similar silly lapply construct, 
profiler tells me a rather different story:

Rprof( )
x <- numeric( )
y <- lapply( 1:10000, function(i){
    x <<- c( x, rnorm(10) )
    NULL
} )
Rprof( NULL )
print( summaryRprof( ) )

$ time Rscript --vanilla prof2.R
$by.self                                           
         self.time self.pct total.time total.pct   
"FUN"         6.48     96.1       6.68      99.1   
"rnorm"       0.20      3.0       0.20       3.0
"lapply"      0.06      0.9       6.74     100.0

$by.total
         total.time total.pct self.time self.pct
"lapply"       6.74     100.0      0.06      0.9
"FUN"          6.68      99.1      6.48     96.1
"rnorm"        0.20       3.0      0.20      3.0

$sampling.time
[1] 6.74

real    0m8.352s
user    0m4.762s
sys     0m2.574s

Or let us wrap the for loop of the first example in a function:

Rprof( )
x <- numeric( )
ffor <- function(){
    for( i in 1:10000){
      x <- c( x, rnorm(10) )
    }
}
ffor()
Rprof( NULL )
print( summaryRprof( ) )
  

$ time Rscript --vanilla prof3.R
$by.self
        self.time self.pct total.time total.pct
"ffor"        5.4     96.4        5.6     100.0
"rnorm"       0.2      3.6        0.2       3.6

$by.total
        total.time total.pct self.time self.pct
"ffor"         5.6     100.0       5.4     96.4
"rnorm"        0.2       3.6       0.2      3.6

$sampling.time
[1] 5.6

real    0m6.379s
user    0m5.408s
sys     0m0.717s



Maybe I get this all wrong, maybe the global assignment operator is 
responsible for some of the time in the second example. But how can I 
analyse the result of profiler in the first example when it seems to 
only be interested in the .22 seconds when I want to know what is going 
on with the rest of the time.

Is it possible to treat "for" as a function when writing the profiler 
data so that I can trust it more ?

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ripley at stats.ox.ac.uk  Tue Mar  3 12:22:49 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Mar 2009 11:22:49 +0000 (GMT)
Subject: [Rd] execution time of .packages
In-Reply-To: <49AD0AF2.8090607@dbmail.com>
References: <49ACF094.7010209@dbmail.com>
	<alpine.OSX.1.00.0903030927420.6041@tystie.local>
	<49AD0AF2.8090607@dbmail.com>
Message-ID: <alpine.LFD.2.00.0903031107530.12745@gannet.stats.ox.ac.uk>

On Tue, 3 Mar 2009, Romain Francois wrote:

> Prof Brian Ripley wrote:
>> The caching is in the disc system: you need to find and read the package 
>> metadata for every package.  AFAIK it is not easy to flush the disc cache, 
>> but quite easy to overwrite it with later reads.  (Google for more info.)
> Thanks for the info, I'll try to find my way with these directions.
>
>> If you are not concerned about validity of the installed packages you could 
>> skip the tests and hence the reads.
>> 
>> Your times are quite a bit slower than mine, so a faster disc system might 
>> help.  Since my server has just been rebooted (for a new kernel), with all 
>> of CRAN and most of BioC I get
>> 
>>> system.time( packs <- .packages( all = T ) )
>>    user  system elapsed
>>   0.518   0.262  25.042
>>> system.time( packs <- .packages( all = T ) )
>>    user  system elapsed
>>   0.442   0.080   0.522
>>> length(packs)
>> [1] 2096
>> 
>> There's a similar issue when installing packages: the Perl code reads the 
>> indices from every visible package to resolve links, and that can be slow 
>> the first time.
>> 
>> 
>> On Tue, 3 Mar 2009, Romain Francois wrote:
>> 
>>> Hello,
>>> 
>>> The first time in a session I call .packages( all.available = T ), it 
>>> takes a long time (I have many packages installed from CRAN):
>>> 
>>>> system.time( packs <- .packages( all = T ) )
>>> user  system elapsed
>>> 0.738   0.276  43.787
>>> 
>>> When I call it again, the time is now much reduced, so there must be some 
>>> caching somewhere. I would like to try to reduce the  time it takes the 
>>> first time, but I have not been able to identify where the caching takes 
>>> place, and so how I can remove it to try to improve the running time 
>>> without the caching. Without this, I have to restart my computer each time 
>>> to vanish the caching to test a new version of the function (this is not 
>>> going to happen)
>>> 
>>> Here is the .packages function, I am suspicious about this part : "ans <- 
>>> c(ans, nam)" which grows the ans vector each time a suitable package is 
>>> found, this does not sound right.
>> 
>> It's OK as there are only going to be ca 2000 packages.  Try profiling 
>> this: .readRDS and grepl take most of the time.

> I usually do not trust the result of the profiler when a for loop is 
> involved, as it tends to miss the point (or maybe I am).

Here are the data for the actual example (repeated for this message):

> Rprof()
> system.time( packs <- .packages( all = T ) )
    user  system elapsed
   0.447   0.078   0.525
> Rprof(NULL)
> summaryRprof()
$by.self
                    self.time self.pct total.time total.pct
"grepl"                 0.18     34.6       0.18      34.6
".readRDS"              0.12     23.1       0.20      38.5
".packages"             0.08     15.4       0.50      96.2
"close.connection"      0.04      7.7       0.04       7.7
"close"                 0.02      3.8       0.06      11.5
"file.exists"           0.02      3.8       0.02       3.8
"gc"                    0.02      3.8       0.02       3.8
"gzfile"                0.02      3.8       0.02       3.8
"list"                  0.02      3.8       0.02       3.8
"system.time"           0.00      0.0       0.52     100.0
"file.path"             0.00      0.0       0.02       3.8

$by.total
                    total.time total.pct self.time self.pct
"system.time"            0.52     100.0      0.00      0.0
".packages"              0.50      96.2      0.08     15.4
".readRDS"               0.20      38.5      0.12     23.1
"grepl"                  0.18      34.6      0.18     34.6
"close"                  0.06      11.5      0.02      3.8
"close.connection"       0.04       7.7      0.04      7.7
"file.exists"            0.02       3.8      0.02      3.8
"gc"                     0.02       3.8      0.02      3.8
"gzfile"                 0.02       3.8      0.02      3.8
"list"                   0.02       3.8      0.02      3.8
"file.path"              0.02       3.8      0.00      0.0

$sampling.time
[1] 0.52

there is little tiime unaccounted for, and 0.38 sec is going in 
.readRDS and grepl.  Whereas

system.time({
ans <- character(0)
for(i in 1:2096) ans <- c(ans, "foo")
})

takes 0.024 secs, negligible here (one profiler tick).

> Consider this script below,

Whether profiling works in other examples is beside the point here.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Tue Mar  3 12:59:26 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 12:59:26 +0100
Subject: [Rd] execution time of .packages
In-Reply-To: <alpine.LFD.2.00.0903031107530.12745@gannet.stats.ox.ac.uk>
References: <49ACF094.7010209@dbmail.com>
	<alpine.OSX.1.00.0903030927420.6041@tystie.local>
	<49AD0AF2.8090607@dbmail.com>
	<alpine.LFD.2.00.0903031107530.12745@gannet.stats.ox.ac.uk>
Message-ID: <49AD1B9E.30608@dbmail.com>

Prof Brian Ripley wrote:
> On Tue, 3 Mar 2009, Romain Francois wrote:
>
>> Prof Brian Ripley wrote:
>>> The caching is in the disc system: you need to find and read the 
>>> package metadata for every package.  AFAIK it is not easy to flush 
>>> the disc cache, but quite easy to overwrite it with later reads.  
>>> (Google for more info.)
>> Thanks for the info, I'll try to find my way with these directions.
>>
>>> If you are not concerned about validity of the installed packages 
>>> you could skip the tests and hence the reads.
>>>
>>> Your times are quite a bit slower than mine, so a faster disc system 
>>> might help.  Since my server has just been rebooted (for a new 
>>> kernel), with all of CRAN and most of BioC I get
>>>
>>>> system.time( packs <- .packages( all = T ) )
>>>    user  system elapsed
>>>   0.518   0.262  25.042
>>>> system.time( packs <- .packages( all = T ) )
>>>    user  system elapsed
>>>   0.442   0.080   0.522
>>>> length(packs)
>>> [1] 2096
>>>
>>> There's a similar issue when installing packages: the Perl code 
>>> reads the indices from every visible package to resolve links, and 
>>> that can be slow the first time.
>>>
>>>
>>> On Tue, 3 Mar 2009, Romain Francois wrote:
>>>
>>>> Hello,
>>>>
>>>> The first time in a session I call .packages( all.available = T ), 
>>>> it takes a long time (I have many packages installed from CRAN):
>>>>
>>>>> system.time( packs <- .packages( all = T ) )
>>>> user  system elapsed
>>>> 0.738   0.276  43.787
>>>>
>>>> When I call it again, the time is now much reduced, so there must 
>>>> be some caching somewhere. I would like to try to reduce the  time 
>>>> it takes the first time, but I have not been able to identify where 
>>>> the caching takes place, and so how I can remove it to try to 
>>>> improve the running time without the caching. Without this, I have 
>>>> to restart my computer each time to vanish the caching to test a 
>>>> new version of the function (this is not going to happen)
>>>>
>>>> Here is the .packages function, I am suspicious about this part : 
>>>> "ans <- c(ans, nam)" which grows the ans vector each time a 
>>>> suitable package is found, this does not sound right.
>>>
>>> It's OK as there are only going to be ca 2000 packages.  Try 
>>> profiling this: .readRDS and grepl take most of the time.
>
>> I usually do not trust the result of the profiler when a for loop is 
>> involved, as it tends to miss the point (or maybe I am).
>
> Here are the data for the actual example (repeated for this message):
>
>> Rprof()
>> system.time( packs <- .packages( all = T ) )
>    user  system elapsed
>   0.447   0.078   0.525
>> Rprof(NULL)
>> summaryRprof()
> $by.self
>                    self.time self.pct total.time total.pct
> "grepl"                 0.18     34.6       0.18      34.6
> ".readRDS"              0.12     23.1       0.20      38.5
> ".packages"             0.08     15.4       0.50      96.2
> "close.connection"      0.04      7.7       0.04       7.7
> "close"                 0.02      3.8       0.06      11.5
> "file.exists"           0.02      3.8       0.02       3.8
> "gc"                    0.02      3.8       0.02       3.8
> "gzfile"                0.02      3.8       0.02       3.8
> "list"                  0.02      3.8       0.02       3.8
> "system.time"           0.00      0.0       0.52     100.0
> "file.path"             0.00      0.0       0.02       3.8
>
> $by.total
>                    total.time total.pct self.time self.pct
> "system.time"            0.52     100.0      0.00      0.0
> ".packages"              0.50      96.2      0.08     15.4
> ".readRDS"               0.20      38.5      0.12     23.1
> "grepl"                  0.18      34.6      0.18     34.6
> "close"                  0.06      11.5      0.02      3.8
> "close.connection"       0.04       7.7      0.04      7.7
> "file.exists"            0.02       3.8      0.02      3.8
> "gc"                     0.02       3.8      0.02      3.8
> "gzfile"                 0.02       3.8      0.02      3.8
> "list"                   0.02       3.8      0.02      3.8
> "file.path"              0.02       3.8      0.00      0.0
>
> $sampling.time
> [1] 0.52
>
> there is little tiime unaccounted for, and 0.38 sec is going in 
> .readRDS and grepl.  Whereas
>
> system.time({
> ans <- character(0)
> for(i in 1:2096) ans <- c(ans, "foo")
> })
>
> takes 0.024 secs, negligible here (one profiler tick).
Here is what happens to me if I restart the computer:

 > Rprof( )
 > system.time( packs <- .packages( all = T ) )
   user  system elapsed
  0.888   0.342  35.589
 > Rprof(NULL)
 > summaryRprof()
$by.self
                   self.time self.pct total.time total.pct
".readRDS"              0.34     28.8       0.64      54.2
".packages"             0.14     11.9       1.16      98.3
"file.exists"           0.14     11.9       0.14      11.9
"gzfile"                0.12     10.2       0.16      13.6
"close"                 0.10      8.5       0.14      11.9
"grepl"                 0.08      6.8       0.10       8.5
"$"                     0.08      6.8       0.08       6.8
"file.path"             0.06      5.1       0.06       5.1
"close.connection"      0.04      3.4       0.04       3.4
"getOption"             0.02      1.7       0.04       3.4
"as.character"          0.02      1.7       0.02       1.7
"gc"                    0.02      1.7       0.02       1.7
"options"               0.02      1.7       0.02       1.7
"system.time"           0.00      0.0       1.18     100.0

$by.total
                   total.time total.pct self.time self.pct
"system.time"            1.18     100.0      0.00      0.0
".packages"              1.16      98.3      0.14     11.9
".readRDS"               0.64      54.2      0.34     28.8
"gzfile"                 0.16      13.6      0.12     10.2
"file.exists"            0.14      11.9      0.14     11.9
"close"                  0.14      11.9      0.10      8.5
"grepl"                  0.10       8.5      0.08      6.8
"$"                      0.08       6.8      0.08      6.8
"file.path"              0.06       5.1      0.06      5.1
"close.connection"       0.04       3.4      0.04      3.4
"getOption"              0.04       3.4      0.02      1.7
"as.character"           0.02       1.7      0.02      1.7
"gc"                     0.02       1.7      0.02      1.7
"options"                0.02       1.7      0.02      1.7

$sampling.time
[1] 1.18

I'd like to know what is happening in the 35.589  - 1.18 seconds, and 
the profiler won't tell me.

About the time spent by grepl, we could take this down by calling it 
once instead of many times

 > system.time( grepl( valid_package_version_regexp, versions ) )
   user  system elapsed
  0.003   0.000   0.009
 > system.time( for(v in versions) grepl( valid_package_version_regexp, 
v ) )  
  user  system elapsed
  0.100   0.000   0.136

>> Consider this script below,
>
> Whether profiling works in other examples is beside the point here.
I'll make another thread on that.

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From romain.francois at dbmail.com  Tue Mar  3 13:33:14 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 13:33:14 +0100
Subject: [Rd] profiler and loops
Message-ID: <49AD238A.1060502@dbmail.com>

Hello,

(This is follow up from this thread: 
http://www.nabble.com/execution-time-of-.packages-td22304833.html but 
with a different focus)

I am often confused by the result of the profiler, when a loop is 
involved. Consider these two scripts:

script1:

Rprof( )
x <- numeric( )
   for( i in 1:10000){
     x <- c( x, rnorm(10) )
   }
Rprof( NULL )
print( summaryRprof( ) )


script2:

Rprof( )
ffor <- function(){
   x <- numeric( )
   for( i in 1:10000){
     x <- c( x, rnorm(10) )
   }
}
ffor()
Rprof( NULL )
print( summaryRprof( ) )


[]$ time Rscript --vanilla script1.R
$by.self
       self.time self.pct total.time total.pct
"rnorm"      0.22      100       0.22       100

$by.total
       total.time total.pct self.time self.pct
"rnorm"       0.22       100      0.22      100

$sampling.time
[1] 0.22

real    0m7.786s
user    0m5.192s
sys     0m0.735s

[]$$ time Rscript --vanilla script2.R
$by.self
       self.time self.pct total.time total.pct
"ffor"       4.94     92.5       5.34     100.0
"rnorm"      0.40      7.5       0.40       7.5

$by.total
       total.time total.pct self.time self.pct
"ffor"        5.34     100.0      4.94     92.5
"rnorm"       0.40       7.5      0.40      7.5

$sampling.time
[1] 5.34


real    0m7.841s
user    0m5.152s
sys     0m0.712s



In the first one, I call a for loop from the top level and in the second 
one, the loop is wrapped in a function call. This shows the inability of 
the profiler to point loops as responsible for bottlenecks. The coder of 
script1 would not know what to do to improve on the script.

I have had a quick look in the code, and here are a few thoughts:

in the function "doprof" in eval.c,  this loop write the call stack on 
the profiler file:

for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
   if ((cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN))
       && TYPEOF(cptr->call) == LANGSXP) {
       SEXP fun = CAR(cptr->call);
       if (!newline) newline = 1;
       fprintf(R_ProfileOutfile, "\"%s\" ",
           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
           "<Anonymous>");
   }
   }
  so we can see it only cares about context CTXT_FUNCTION and 
CTXT_BUILTIN, when for loops play with CTXT_LOOP (this is again in 
eval.c within the do_for function)

begincontext(&cntxt, CTXT_LOOP, R_NilValue, rho, R_BaseEnv, R_NilValue,
        R_NilValue);
 
which as the name implies, begins the context of the for loop. The 
begincontext function looks like this :

void begincontext(RCNTXT * cptr, int flags,
         SEXP syscall, SEXP env, SEXP sysp,
         SEXP promargs, SEXP callfun)
{
   cptr->nextcontext = R_GlobalContext;
   cptr->cstacktop = R_PPStackTop;
   cptr->evaldepth = R_EvalDepth;
   cptr->callflag = flags;
   cptr->call = syscall;
   cptr->cloenv = env;
   cptr->sysparent = sysp;
   cptr->conexit = R_NilValue;
   cptr->cend = NULL;
   cptr->promargs = promargs;
   cptr->callfun = callfun;
   cptr->vmax = vmaxget();
   cptr->intsusp = R_interrupts_suspended;
   cptr->handlerstack = R_HandlerStack;
   cptr->restartstack = R_RestartStack;
   cptr->prstack = R_PendingPromises;
#ifdef BYTECODE
   cptr->nodestack = R_BCNodeStackTop;
# ifdef BC_INT_STACK
   cptr->intstack = R_BCIntStackTop;
# endif
#endif
   R_GlobalContext = cptr;
}


So it could be possible to set the last argument of the begincontext 
function to "for" and use this code in the doprof function:


for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
 if ( ( cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN ) )
       && TYPEOF(cptr->call) == LANGSXP) {
       SEXP fun = CAR(cptr->call);
       if (!newline) newline = 1;
       fprintf(R_ProfileOutfile, "\"%s\" ",
           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
           "<Anonymous>");
   } else if( cptr->callflag & CTXT_LOOP){
     SEXP fun = CAR(cptr->syscall);
     if (!newline) newline = 1;
     fprintf(R_ProfileOutfile, "\"%s\" ", CHAR(PRINTNAME(fun)) );
   }
}

so that we see for in the list of "functions" that appear in the 
profiler file.

Obviously I am taking some shortcuts here, because of the other loops, 
but I would like to make a formal patch with this. Before I do that, I'd 
like to know :
- is this has a chance of breaking something else (does the CTXT_LOOP 
being R_NilValue is used elsewhere)
- would this feature be welcome.
- Should I differentiate real functions with loops in the output file, 
maybe I can write "[for]" instead of for to emphacize this is not a 
function.

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ripley at stats.ox.ac.uk  Tue Mar  3 13:41:44 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Mar 2009 12:41:44 +0000 (GMT)
Subject: [Rd] execution time of .packages
In-Reply-To: <49AD1B9E.30608@dbmail.com>
References: <49ACF094.7010209@dbmail.com>
	<alpine.OSX.1.00.0903030927420.6041@tystie.local>
	<49AD0AF2.8090607@dbmail.com>
	<alpine.LFD.2.00.0903031107530.12745@gannet.stats.ox.ac.uk>
	<49AD1B9E.30608@dbmail.com>
Message-ID: <alpine.LFD.2.00.0903031226430.19225@gannet.stats.ox.ac.uk>

Let me repeat: what is happening for me in the equivalent of your 
35.589 - 1.18 seconds is that R is waiting for my OS to read its discs 
(and they can be heard chuntering away).  As the R process is not 
runniing at those times, the profiler is not running either (on a 
Unix-alike: on Windows the profiler does measure elapsed time).  I 
expect it will be the same explanation for you.

What I have already suggested is that if you want to save time, do not 
read and check the package.rds files.   As far as I can see they were 
checked at installation in any recent version of R.  Just check their 
existence.

On Tue, 3 Mar 2009, Romain Francois wrote:

> Prof Brian Ripley wrote:
>> On Tue, 3 Mar 2009, Romain Francois wrote:
>> 
>>> Prof Brian Ripley wrote:
>>>> The caching is in the disc system: you need to find and read the package 
>>>> metadata for every package.  AFAIK it is not easy to flush the disc 
>>>> cache, but quite easy to overwrite it with later reads.  (Google for more 
>>>> info.)
>>> Thanks for the info, I'll try to find my way with these directions.
>>> 
>>>> If you are not concerned about validity of the installed packages you 
>>>> could skip the tests and hence the reads.
>>>> 
>>>> Your times are quite a bit slower than mine, so a faster disc system 
>>>> might help.  Since my server has just been rebooted (for a new kernel), 
>>>> with all of CRAN and most of BioC I get
>>>> 
>>>>> system.time( packs <- .packages( all = T ) )
>>>>    user  system elapsed
>>>>   0.518   0.262  25.042
>>>>> system.time( packs <- .packages( all = T ) )
>>>>    user  system elapsed
>>>>   0.442   0.080   0.522
>>>>> length(packs)
>>>> [1] 2096
>>>> 
>>>> There's a similar issue when installing packages: the Perl code reads the 
>>>> indices from every visible package to resolve links, and that can be slow 
>>>> the first time.
>>>> 
>>>> 
>>>> On Tue, 3 Mar 2009, Romain Francois wrote:
>>>> 
>>>>> Hello,
>>>>> 
>>>>> The first time in a session I call .packages( all.available = T ), it 
>>>>> takes a long time (I have many packages installed from CRAN):
>>>>> 
>>>>>> system.time( packs <- .packages( all = T ) )
>>>>> user  system elapsed
>>>>> 0.738   0.276  43.787
>>>>> 
>>>>> When I call it again, the time is now much reduced, so there must be 
>>>>> some caching somewhere. I would like to try to reduce the  time it takes 
>>>>> the first time, but I have not been able to identify where the caching 
>>>>> takes place, and so how I can remove it to try to improve the running 
>>>>> time without the caching. Without this, I have to restart my computer 
>>>>> each time to vanish the caching to test a new version of the function 
>>>>> (this is not going to happen)
>>>>> 
>>>>> Here is the .packages function, I am suspicious about this part : "ans 
>>>>> <- c(ans, nam)" which grows the ans vector each time a suitable package 
>>>>> is found, this does not sound right.
>>>> 
>>>> It's OK as there are only going to be ca 2000 packages.  Try profiling 
>>>> this: .readRDS and grepl take most of the time.
>> 
>>> I usually do not trust the result of the profiler when a for loop is 
>>> involved, as it tends to miss the point (or maybe I am).
>> 
>> Here are the data for the actual example (repeated for this message):
>> 
>>> Rprof()
>>> system.time( packs <- .packages( all = T ) )
>>    user  system elapsed
>>   0.447   0.078   0.525
>>> Rprof(NULL)
>>> summaryRprof()
>> $by.self
>>                    self.time self.pct total.time total.pct
>> "grepl"                 0.18     34.6       0.18      34.6
>> ".readRDS"              0.12     23.1       0.20      38.5
>> ".packages"             0.08     15.4       0.50      96.2
>> "close.connection"      0.04      7.7       0.04       7.7
>> "close"                 0.02      3.8       0.06      11.5
>> "file.exists"           0.02      3.8       0.02       3.8
>> "gc"                    0.02      3.8       0.02       3.8
>> "gzfile"                0.02      3.8       0.02       3.8
>> "list"                  0.02      3.8       0.02       3.8
>> "system.time"           0.00      0.0       0.52     100.0
>> "file.path"             0.00      0.0       0.02       3.8
>> 
>> $by.total
>>                    total.time total.pct self.time self.pct
>> "system.time"            0.52     100.0      0.00      0.0
>> ".packages"              0.50      96.2      0.08     15.4
>> ".readRDS"               0.20      38.5      0.12     23.1
>> "grepl"                  0.18      34.6      0.18     34.6
>> "close"                  0.06      11.5      0.02      3.8
>> "close.connection"       0.04       7.7      0.04      7.7
>> "file.exists"            0.02       3.8      0.02      3.8
>> "gc"                     0.02       3.8      0.02      3.8
>> "gzfile"                 0.02       3.8      0.02      3.8
>> "list"                   0.02       3.8      0.02      3.8
>> "file.path"              0.02       3.8      0.00      0.0
>> 
>> $sampling.time
>> [1] 0.52
>> 
>> there is little tiime unaccounted for, and 0.38 sec is going in .readRDS 
>> and grepl.  Whereas
>> 
>> system.time({
>> ans <- character(0)
>> for(i in 1:2096) ans <- c(ans, "foo")
>> })
>> 
>> takes 0.024 secs, negligible here (one profiler tick).
> Here is what happens to me if I restart the computer:
>
>> Rprof( )
>> system.time( packs <- .packages( all = T ) )
>  user  system elapsed
> 0.888   0.342  35.589
>> Rprof(NULL)
>> summaryRprof()
> $by.self
>                  self.time self.pct total.time total.pct
> ".readRDS"              0.34     28.8       0.64      54.2
> ".packages"             0.14     11.9       1.16      98.3
> "file.exists"           0.14     11.9       0.14      11.9
> "gzfile"                0.12     10.2       0.16      13.6
> "close"                 0.10      8.5       0.14      11.9
> "grepl"                 0.08      6.8       0.10       8.5
> "$"                     0.08      6.8       0.08       6.8
> "file.path"             0.06      5.1       0.06       5.1
> "close.connection"      0.04      3.4       0.04       3.4
> "getOption"             0.02      1.7       0.04       3.4
> "as.character"          0.02      1.7       0.02       1.7
> "gc"                    0.02      1.7       0.02       1.7
> "options"               0.02      1.7       0.02       1.7
> "system.time"           0.00      0.0       1.18     100.0
>
> $by.total
>                  total.time total.pct self.time self.pct
> "system.time"            1.18     100.0      0.00      0.0
> ".packages"              1.16      98.3      0.14     11.9
> ".readRDS"               0.64      54.2      0.34     28.8
> "gzfile"                 0.16      13.6      0.12     10.2
> "file.exists"            0.14      11.9      0.14     11.9
> "close"                  0.14      11.9      0.10      8.5
> "grepl"                  0.10       8.5      0.08      6.8
> "$"                      0.08       6.8      0.08      6.8
> "file.path"              0.06       5.1      0.06      5.1
> "close.connection"       0.04       3.4      0.04      3.4
> "getOption"              0.04       3.4      0.02      1.7
> "as.character"           0.02       1.7      0.02      1.7
> "gc"                     0.02       1.7      0.02      1.7
> "options"                0.02       1.7      0.02      1.7
>
> $sampling.time
> [1] 1.18
>
> I'd like to know what is happening in the 35.589  - 1.18 seconds, and the 
> profiler won't tell me.
>
> About the time spent by grepl, we could take this down by calling it once 
> instead of many times
>
>> system.time( grepl( valid_package_version_regexp, versions ) )
>  user  system elapsed
> 0.003   0.000   0.009
>> system.time( for(v in versions) grepl( valid_package_version_regexp, v ) ) 
> user  system elapsed
> 0.100   0.000   0.136
>
>>> Consider this script below,
>> 
>> Whether profiling works in other examples is beside the point here.
> I'll make another thread on that.
>
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Tue Mar  3 13:39:10 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 13:39:10 +0100
Subject: [Rd] execution time of .packages
In-Reply-To: <alpine.LFD.2.00.0903031226430.19225@gannet.stats.ox.ac.uk>
References: <49ACF094.7010209@dbmail.com>
	<alpine.OSX.1.00.0903030927420.6041@tystie.local>
	<49AD0AF2.8090607@dbmail.com>
	<alpine.LFD.2.00.0903031107530.12745@gannet.stats.ox.ac.uk>
	<49AD1B9E.30608@dbmail.com>
	<alpine.LFD.2.00.0903031226430.19225@gannet.stats.ox.ac.uk>
Message-ID: <49AD24EE.2020009@dbmail.com>

Prof Brian Ripley wrote:
> Let me repeat: what is happening for me in the equivalent of your 
> 35.589 - 1.18 seconds is that R is waiting for my OS to read its discs 
> (and they can be heard chuntering away).  As the R process is not 
> runniing at those times, the profiler is not running either (on a 
> Unix-alike: on Windows the profiler does measure elapsed time).  I 
> expect it will be the same explanation for you.
Thank you. I get it this time.

> What I have already suggested is that if you want to save time, do not 
> read and check the package.rds files.   As far as I can see they were 
> checked at installation in any recent version of R.  Just check their 
> existence.
>
> On Tue, 3 Mar 2009, Romain Francois wrote:
>
>> Prof Brian Ripley wrote:
>>> On Tue, 3 Mar 2009, Romain Francois wrote:
>>>
>>>> Prof Brian Ripley wrote:
>>>>> The caching is in the disc system: you need to find and read the 
>>>>> package metadata for every package.  AFAIK it is not easy to flush 
>>>>> the disc cache, but quite easy to overwrite it with later reads.  
>>>>> (Google for more info.)
>>>> Thanks for the info, I'll try to find my way with these directions.
>>>>
>>>>> If you are not concerned about validity of the installed packages 
>>>>> you could skip the tests and hence the reads.
>>>>>
>>>>> Your times are quite a bit slower than mine, so a faster disc 
>>>>> system might help.  Since my server has just been rebooted (for a 
>>>>> new kernel), with all of CRAN and most of BioC I get
>>>>>
>>>>>> system.time( packs <- .packages( all = T ) )
>>>>>    user  system elapsed
>>>>>   0.518   0.262  25.042
>>>>>> system.time( packs <- .packages( all = T ) )
>>>>>    user  system elapsed
>>>>>   0.442   0.080   0.522
>>>>>> length(packs)
>>>>> [1] 2096
>>>>>
>>>>> There's a similar issue when installing packages: the Perl code 
>>>>> reads the indices from every visible package to resolve links, and 
>>>>> that can be slow the first time.
>>>>>
>>>>>
>>>>> On Tue, 3 Mar 2009, Romain Francois wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> The first time in a session I call .packages( all.available = T 
>>>>>> ), it takes a long time (I have many packages installed from CRAN):
>>>>>>
>>>>>>> system.time( packs <- .packages( all = T ) )
>>>>>> user  system elapsed
>>>>>> 0.738   0.276  43.787
>>>>>>
>>>>>> When I call it again, the time is now much reduced, so there must 
>>>>>> be some caching somewhere. I would like to try to reduce the  
>>>>>> time it takes the first time, but I have not been able to 
>>>>>> identify where the caching takes place, and so how I can remove 
>>>>>> it to try to improve the running time without the caching. 
>>>>>> Without this, I have to restart my computer each time to vanish 
>>>>>> the caching to test a new version of the function (this is not 
>>>>>> going to happen)
>>>>>>
>>>>>> Here is the .packages function, I am suspicious about this part : 
>>>>>> "ans <- c(ans, nam)" which grows the ans vector each time a 
>>>>>> suitable package is found, this does not sound right.
>>>>>
>>>>> It's OK as there are only going to be ca 2000 packages.  Try 
>>>>> profiling this: .readRDS and grepl take most of the time.
>>>
>>>> I usually do not trust the result of the profiler when a for loop 
>>>> is involved, as it tends to miss the point (or maybe I am).
>>>
>>> Here are the data for the actual example (repeated for this message):
>>>
>>>> Rprof()
>>>> system.time( packs <- .packages( all = T ) )
>>>    user  system elapsed
>>>   0.447   0.078   0.525
>>>> Rprof(NULL)
>>>> summaryRprof()
>>> $by.self
>>>                    self.time self.pct total.time total.pct
>>> "grepl"                 0.18     34.6       0.18      34.6
>>> ".readRDS"              0.12     23.1       0.20      38.5
>>> ".packages"             0.08     15.4       0.50      96.2
>>> "close.connection"      0.04      7.7       0.04       7.7
>>> "close"                 0.02      3.8       0.06      11.5
>>> "file.exists"           0.02      3.8       0.02       3.8
>>> "gc"                    0.02      3.8       0.02       3.8
>>> "gzfile"                0.02      3.8       0.02       3.8
>>> "list"                  0.02      3.8       0.02       3.8
>>> "system.time"           0.00      0.0       0.52     100.0
>>> "file.path"             0.00      0.0       0.02       3.8
>>>
>>> $by.total
>>>                    total.time total.pct self.time self.pct
>>> "system.time"            0.52     100.0      0.00      0.0
>>> ".packages"              0.50      96.2      0.08     15.4
>>> ".readRDS"               0.20      38.5      0.12     23.1
>>> "grepl"                  0.18      34.6      0.18     34.6
>>> "close"                  0.06      11.5      0.02      3.8
>>> "close.connection"       0.04       7.7      0.04      7.7
>>> "file.exists"            0.02       3.8      0.02      3.8
>>> "gc"                     0.02       3.8      0.02      3.8
>>> "gzfile"                 0.02       3.8      0.02      3.8
>>> "list"                   0.02       3.8      0.02      3.8
>>> "file.path"              0.02       3.8      0.00      0.0
>>>
>>> $sampling.time
>>> [1] 0.52
>>>
>>> there is little tiime unaccounted for, and 0.38 sec is going in 
>>> .readRDS and grepl.  Whereas
>>>
>>> system.time({
>>> ans <- character(0)
>>> for(i in 1:2096) ans <- c(ans, "foo")
>>> })
>>>
>>> takes 0.024 secs, negligible here (one profiler tick).
>> Here is what happens to me if I restart the computer:
>>
>>> Rprof( )
>>> system.time( packs <- .packages( all = T ) )
>>  user  system elapsed
>> 0.888   0.342  35.589
>>> Rprof(NULL)
>>> summaryRprof()
>> $by.self
>>                  self.time self.pct total.time total.pct
>> ".readRDS"              0.34     28.8       0.64      54.2
>> ".packages"             0.14     11.9       1.16      98.3
>> "file.exists"           0.14     11.9       0.14      11.9
>> "gzfile"                0.12     10.2       0.16      13.6
>> "close"                 0.10      8.5       0.14      11.9
>> "grepl"                 0.08      6.8       0.10       8.5
>> "$"                     0.08      6.8       0.08       6.8
>> "file.path"             0.06      5.1       0.06       5.1
>> "close.connection"      0.04      3.4       0.04       3.4
>> "getOption"             0.02      1.7       0.04       3.4
>> "as.character"          0.02      1.7       0.02       1.7
>> "gc"                    0.02      1.7       0.02       1.7
>> "options"               0.02      1.7       0.02       1.7
>> "system.time"           0.00      0.0       1.18     100.0
>>
>> $by.total
>>                  total.time total.pct self.time self.pct
>> "system.time"            1.18     100.0      0.00      0.0
>> ".packages"              1.16      98.3      0.14     11.9
>> ".readRDS"               0.64      54.2      0.34     28.8
>> "gzfile"                 0.16      13.6      0.12     10.2
>> "file.exists"            0.14      11.9      0.14     11.9
>> "close"                  0.14      11.9      0.10      8.5
>> "grepl"                  0.10       8.5      0.08      6.8
>> "$"                      0.08       6.8      0.08      6.8
>> "file.path"              0.06       5.1      0.06      5.1
>> "close.connection"       0.04       3.4      0.04      3.4
>> "getOption"              0.04       3.4      0.02      1.7
>> "as.character"           0.02       1.7      0.02      1.7
>> "gc"                     0.02       1.7      0.02      1.7
>> "options"                0.02       1.7      0.02      1.7
>>
>> $sampling.time
>> [1] 1.18
>>
>> I'd like to know what is happening in the 35.589  - 1.18 seconds, and 
>> the profiler won't tell me.
>>
>> About the time spent by grepl, we could take this down by calling it 
>> once instead of many times
>>
>>> system.time( grepl( valid_package_version_regexp, versions ) )
>>  user  system elapsed
>> 0.003   0.000   0.009
>>> system.time( for(v in versions) grepl( valid_package_version_regexp, 
>>> v ) ) 
>> user  system elapsed
>> 0.100   0.000   0.136
>>
>>>> Consider this script below,
>>>
>>> Whether profiling works in other examples is beside the point here.
>> I'll make another thread on that.
>>
>> -- 
>> Romain Francois
>> Independent R Consultant
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>>
>>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ml-it-r-devel at epigenomics.com  Tue Mar  3 17:23:12 2009
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Tue, 03 Mar 2009 17:23:12 +0100
Subject: [Rd] R 2.9.0 devel: package installation with configure-args option
Message-ID: <gojlhg$i5g$1@perl.epigenomics.epi>


Hi,

trying
to install a package containing C code and requiring non-default configure argument
settings the incantation (this has worked for R <= 2.8.1 on the same architectures)

R CMD INSTALL --configure-args="--with-opt1 --with-opt2" packname

does always result in a warning
Warning: unknown option '--with-opt2'

and consequently the option is ignored. Reverting the order of options results in the now
last option to be ignored. Alternative quoting has not provided a solution.

Using

R CMD INSTALL --configure-args=--with-opt1 --configure-args=--with-opt2 packname

does provide a workaround, though. Is this the (new to me) and only intended way to
provide more than one configure argument?
I checked ?INSTALL and the referenced R-admin sec. 'Configuration variables' but still am
not clear on this.

Regards, Matthias


R version 2.9.0 Under development (unstable) (2009-03-02 r48041)
on Ubuntu 8.04, 8.10

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-0                            fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
                                            Oliver Schacht PhD (CFO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From romain.francois at dbmail.com  Tue Mar  3 17:23:36 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 17:23:36 +0100
Subject: [Rd] profiler and loops
In-Reply-To: <49AD238A.1060502@dbmail.com>
References: <49AD238A.1060502@dbmail.com>
Message-ID: <49AD5988.4060104@dbmail.com>


Hello,

Please find attached a patch against svn implementing this proposal.

The part I don't fully understand is the part involving the function  
loopWithContect, so I've put "[loop]" in there instead of "[for]", 
"[while]" or "[repeat]" because I don't really know how to extract the 
information.

With the script1 from my previous post, summaryRprof produces this:

[]$ /home/romain/workspace/R-trunk/bin/Rscript script1.R
$by.self
        self.time self.pct total.time total.pct
"[for]"      5.32     98.9       5.38     100.0
"rnorm"      0.06      1.1       0.06       1.1

$by.total
        total.time total.pct self.time self.pct
"[for]"       5.38     100.0      5.32     98.9
"rnorm"       0.06       1.1      0.06      1.1

$sampling.time
[1] 5.38

Romain


Romain Francois wrote:
> Hello,
>
> (This is follow up from this thread: 
> http://www.nabble.com/execution-time-of-.packages-td22304833.html but 
> with a different focus)
>
> I am often confused by the result of the profiler, when a loop is 
> involved. Consider these two scripts:
>
> script1:
>
> Rprof( )
> x <- numeric( )
>   for( i in 1:10000){
>     x <- c( x, rnorm(10) )
>   }
> Rprof( NULL )
> print( summaryRprof( ) )
>
>
> script2:
>
> Rprof( )
> ffor <- function(){
>   x <- numeric( )
>   for( i in 1:10000){
>     x <- c( x, rnorm(10) )
>   }
> }
> ffor()
> Rprof( NULL )
> print( summaryRprof( ) )
>
>
> []$ time Rscript --vanilla script1.R
> $by.self
>       self.time self.pct total.time total.pct
> "rnorm"      0.22      100       0.22       100
>
> $by.total
>       total.time total.pct self.time self.pct
> "rnorm"       0.22       100      0.22      100
>
> $sampling.time
> [1] 0.22
>
> real    0m7.786s
> user    0m5.192s
> sys     0m0.735s
>
> []$$ time Rscript --vanilla script2.R
> $by.self
>       self.time self.pct total.time total.pct
> "ffor"       4.94     92.5       5.34     100.0
> "rnorm"      0.40      7.5       0.40       7.5
>
> $by.total
>       total.time total.pct self.time self.pct
> "ffor"        5.34     100.0      4.94     92.5
> "rnorm"       0.40       7.5      0.40      7.5
>
> $sampling.time
> [1] 5.34
>
>
> real    0m7.841s
> user    0m5.152s
> sys     0m0.712s
>
>
>
> In the first one, I call a for loop from the top level and in the 
> second one, the loop is wrapped in a function call. This shows the 
> inability of the profiler to point loops as responsible for 
> bottlenecks. The coder of script1 would not know what to do to improve 
> on the script.
>
> I have had a quick look in the code, and here are a few thoughts:
>
> in the function "doprof" in eval.c,  this loop write the call stack on 
> the profiler file:
>
> for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
>   if ((cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN))
>       && TYPEOF(cptr->call) == LANGSXP) {
>       SEXP fun = CAR(cptr->call);
>       if (!newline) newline = 1;
>       fprintf(R_ProfileOutfile, "\"%s\" ",
>           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
>           "<Anonymous>");
>   }
>   }
>  so we can see it only cares about context CTXT_FUNCTION and 
> CTXT_BUILTIN, when for loops play with CTXT_LOOP (this is again in 
> eval.c within the do_for function)
>
> begincontext(&cntxt, CTXT_LOOP, R_NilValue, rho, R_BaseEnv, R_NilValue,
>        R_NilValue);
>
> which as the name implies, begins the context of the for loop. The 
> begincontext function looks like this :
>
> void begincontext(RCNTXT * cptr, int flags,
>         SEXP syscall, SEXP env, SEXP sysp,
>         SEXP promargs, SEXP callfun)
> {
>   cptr->nextcontext = R_GlobalContext;
>   cptr->cstacktop = R_PPStackTop;
>   cptr->evaldepth = R_EvalDepth;
>   cptr->callflag = flags;
>   cptr->call = syscall;
>   cptr->cloenv = env;
>   cptr->sysparent = sysp;
>   cptr->conexit = R_NilValue;
>   cptr->cend = NULL;
>   cptr->promargs = promargs;
>   cptr->callfun = callfun;
>   cptr->vmax = vmaxget();
>   cptr->intsusp = R_interrupts_suspended;
>   cptr->handlerstack = R_HandlerStack;
>   cptr->restartstack = R_RestartStack;
>   cptr->prstack = R_PendingPromises;
> #ifdef BYTECODE
>   cptr->nodestack = R_BCNodeStackTop;
> # ifdef BC_INT_STACK
>   cptr->intstack = R_BCIntStackTop;
> # endif
> #endif
>   R_GlobalContext = cptr;
> }
>
>
> So it could be possible to set the last argument of the begincontext 
> function to "for" and use this code in the doprof function:
>
>
> for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
> if ( ( cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN ) )
>       && TYPEOF(cptr->call) == LANGSXP) {
>       SEXP fun = CAR(cptr->call);
>       if (!newline) newline = 1;
>       fprintf(R_ProfileOutfile, "\"%s\" ",
>           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
>           "<Anonymous>");
>   } else if( cptr->callflag & CTXT_LOOP){
>     SEXP fun = CAR(cptr->syscall);
>     if (!newline) newline = 1;
>     fprintf(R_ProfileOutfile, "\"%s\" ", CHAR(PRINTNAME(fun)) );
>   }
> }
>
> so that we see for in the list of "functions" that appear in the 
> profiler file.
>
> Obviously I am taking some shortcuts here, because of the other loops, 
> but I would like to make a formal patch with this. Before I do that, 
> I'd like to know :
> - is this has a chance of breaking something else (does the CTXT_LOOP 
> being R_NilValue is used elsewhere)
> - would this feature be welcome.
> - Should I differentiate real functions with loops in the output file, 
> maybe I can write "[for]" instead of for to emphacize this is not a 
> function.
>
> Romain
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: profilerWithLoop.diff
Type: text/x-patch
Size: 1715 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090303/fcc638a4/attachment.bin>

From pgilbert at bank-banque-canada.ca  Tue Mar  3 17:59:42 2009
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 03 Mar 2009 11:59:42 -0500
Subject: [Rd] S4 data dump or?
In-Reply-To: <alpine.OSX.1.00.0903030714540.53034@tystie.local>
References: <49AC56E8.50502@bank-banque-canada.ca>
	<alpine.OSX.1.00.0903030714540.53034@tystie.local>
Message-ID: <49AD61FE.5030409@bank-banque-canada.ca>


Prof Brian Ripley wrote:
> On Mon, 2 Mar 2009, Paul Gilbert wrote:
> 
>> I am trying to dump some data in a file that I will add to a package.  
>> The data has an attribute which is a S4 object, and this seems to 
>> cause problems. What is the preferred way to write a file with a 
>> dataset that has some S4 parts, so that it can be included in a package?
> 
> 
> Using save() seems almost always preferable to dump(): usually a smaller 
> result, avoids representation error changes for numeric types and 
> encoding issues for some character vectors, works for almost all objects.

Ok.  I thought I was having a problem with save()/load() too, but it 
seems that problem was something else. I have this working now.
> 
> I am guessing that the note on ?dump about objects of type S4 is the 
> issue here.

Yes, the S4 object causes source() of the dump()ed file to fail.

Thanks,
Paul
> 
>> Paul Gilbert
> 
> 
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From karenoel1 at gmail.com  Tue Mar  3 18:20:31 2009
From: karenoel1 at gmail.com (Karen Noel)
Date: Tue, 3 Mar 2009 12:20:31 -0500
Subject: [Rd] make check reg-tests-1.R error on solaris
Message-ID: <78c13c910903030920u1c24f552t610c49a95b26a496@mail.gmail.com>

R 2.5.1 compiled, passed the make check and has been successfully
running for a couple
years on a Sun Fire V490 running Solaris 9. I need a newer version of
R, but can't get a
newer version of R to pass the make check. I've tried 2.8.1, 2.7.2,
2.6.2 and 2.6.0. (2.5.1 still
passes on this server) At this point I thought I'd try to compile it
on another Sun server
(Solaris 10), but it had the same problem. Configuring with no options
didn't help. I
commented out the failed test from the Makefile to see if it would
pass the rest of the tests.
It passes all the rest of the tests. Here is the failure error from make check.

make[2]: Entering directory `/usr/local/src/R-2.8.1/tests'
running regression tests
make[3]: Entering directory `/usr/local/src/R-2.8.1/tests'
running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
make[3]: Leaving directory `/usr/local/src/R-2.8.1/tests'
make[2]: *** [test-Reg] Error 2
make[2]: Leaving directory `/usr/local/src/R-2.8.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/src/R-2.8.1/tests'
make: *** [check] Error 2
bash-2.05#

Here is output from reg-tests-1.Rout.fail.

[1] "41c6167e" "dir1" "dir2" "dirs" "file275c23f2"
[6] "file33f963f2" "moredirs"
> file.create(file.path(dd, "somefile"))
[1] TRUE TRUE TRUE TRUE
> dir(".", recursive=TRUE)
[1] "41c6167e" "dir1/somefile" "dir2/somefile"
[4] "dirs/somefile" "file275c23f2" "file33f963f2"
[7] "moredirs/somefile"
> stopifnot(unlink("dir?") == 1) # not an error
Error: unlink("dir?") == 1 is not TRUE
Execution halted
rm: Cannot remove any directory in the path of the current working directory
/tmp/RtmprBjF6W

Looking through the archives I did find a couple other people with
this error, both running
Solaris 10. PR#10501 and PR#11738 have quite a lot of information
about this error, but I
don't see any resolution for them.

This looks like it could possibly be enough of a problem that I
haven't put 2.8.1 in
production. Can you help me with a resolution or let me know if it is
safe to ignore? I'd
appreciate it.

Thank you!
Karen


From romain.francois at dbmail.com  Tue Mar  3 18:27:35 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 03 Mar 2009 18:27:35 +0100
Subject: [Rd] profiler and loops
In-Reply-To: <49AD5988.4060104@dbmail.com>
References: <49AD238A.1060502@dbmail.com> <49AD5988.4060104@dbmail.com>
Message-ID: <49AD6887.4030206@dbmail.com>

Please ignore the previous patch which did not take into account the 
conditional compilation of doprof on windows. This one does, but was not 
tested on windows.

Romain

Romain Francois wrote:
>
> Hello,
>
> Please find attached a patch against svn implementing this proposal.
>
> The part I don't fully understand is the part involving the function  
> loopWithContect, so I've put "[loop]" in there instead of "[for]", 
> "[while]" or "[repeat]" because I don't really know how to extract the 
> information.
>
> With the script1 from my previous post, summaryRprof produces this:
>
> []$ /home/romain/workspace/R-trunk/bin/Rscript script1.R
> $by.self
>        self.time self.pct total.time total.pct
> "[for]"      5.32     98.9       5.38     100.0
> "rnorm"      0.06      1.1       0.06       1.1
>
> $by.total
>        total.time total.pct self.time self.pct
> "[for]"       5.38     100.0      5.32     98.9
> "rnorm"       0.06       1.1      0.06      1.1
>
> $sampling.time
> [1] 5.38
>
> Romain
>
>
> Romain Francois wrote:
>> Hello,
>>
>> (This is follow up from this thread: 
>> http://www.nabble.com/execution-time-of-.packages-td22304833.html but 
>> with a different focus)
>>
>> I am often confused by the result of the profiler, when a loop is 
>> involved. Consider these two scripts:
>>
>> script1:
>>
>> Rprof( )
>> x <- numeric( )
>>   for( i in 1:10000){
>>     x <- c( x, rnorm(10) )
>>   }
>> Rprof( NULL )
>> print( summaryRprof( ) )
>>
>>
>> script2:
>>
>> Rprof( )
>> ffor <- function(){
>>   x <- numeric( )
>>   for( i in 1:10000){
>>     x <- c( x, rnorm(10) )
>>   }
>> }
>> ffor()
>> Rprof( NULL )
>> print( summaryRprof( ) )
>>
>>
>> []$ time Rscript --vanilla script1.R
>> $by.self
>>       self.time self.pct total.time total.pct
>> "rnorm"      0.22      100       0.22       100
>>
>> $by.total
>>       total.time total.pct self.time self.pct
>> "rnorm"       0.22       100      0.22      100
>>
>> $sampling.time
>> [1] 0.22
>>
>> real    0m7.786s
>> user    0m5.192s
>> sys     0m0.735s
>>
>> []$$ time Rscript --vanilla script2.R
>> $by.self
>>       self.time self.pct total.time total.pct
>> "ffor"       4.94     92.5       5.34     100.0
>> "rnorm"      0.40      7.5       0.40       7.5
>>
>> $by.total
>>       total.time total.pct self.time self.pct
>> "ffor"        5.34     100.0      4.94     92.5
>> "rnorm"       0.40       7.5      0.40      7.5
>>
>> $sampling.time
>> [1] 5.34
>>
>>
>> real    0m7.841s
>> user    0m5.152s
>> sys     0m0.712s
>>
>>
>>
>> In the first one, I call a for loop from the top level and in the 
>> second one, the loop is wrapped in a function call. This shows the 
>> inability of the profiler to point loops as responsible for 
>> bottlenecks. The coder of script1 would not know what to do to 
>> improve on the script.
>>
>> I have had a quick look in the code, and here are a few thoughts:
>>
>> in the function "doprof" in eval.c,  this loop write the call stack 
>> on the profiler file:
>>
>> for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
>>   if ((cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN))
>>       && TYPEOF(cptr->call) == LANGSXP) {
>>       SEXP fun = CAR(cptr->call);
>>       if (!newline) newline = 1;
>>       fprintf(R_ProfileOutfile, "\"%s\" ",
>>           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
>>           "<Anonymous>");
>>   }
>>   }
>>  so we can see it only cares about context CTXT_FUNCTION and 
>> CTXT_BUILTIN, when for loops play with CTXT_LOOP (this is again in 
>> eval.c within the do_for function)
>>
>> begincontext(&cntxt, CTXT_LOOP, R_NilValue, rho, R_BaseEnv, R_NilValue,
>>        R_NilValue);
>>
>> which as the name implies, begins the context of the for loop. The 
>> begincontext function looks like this :
>>
>> void begincontext(RCNTXT * cptr, int flags,
>>         SEXP syscall, SEXP env, SEXP sysp,
>>         SEXP promargs, SEXP callfun)
>> {
>>   cptr->nextcontext = R_GlobalContext;
>>   cptr->cstacktop = R_PPStackTop;
>>   cptr->evaldepth = R_EvalDepth;
>>   cptr->callflag = flags;
>>   cptr->call = syscall;
>>   cptr->cloenv = env;
>>   cptr->sysparent = sysp;
>>   cptr->conexit = R_NilValue;
>>   cptr->cend = NULL;
>>   cptr->promargs = promargs;
>>   cptr->callfun = callfun;
>>   cptr->vmax = vmaxget();
>>   cptr->intsusp = R_interrupts_suspended;
>>   cptr->handlerstack = R_HandlerStack;
>>   cptr->restartstack = R_RestartStack;
>>   cptr->prstack = R_PendingPromises;
>> #ifdef BYTECODE
>>   cptr->nodestack = R_BCNodeStackTop;
>> # ifdef BC_INT_STACK
>>   cptr->intstack = R_BCIntStackTop;
>> # endif
>> #endif
>>   R_GlobalContext = cptr;
>> }
>>
>>
>> So it could be possible to set the last argument of the begincontext 
>> function to "for" and use this code in the doprof function:
>>
>>
>> for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
>> if ( ( cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN ) )
>>       && TYPEOF(cptr->call) == LANGSXP) {
>>       SEXP fun = CAR(cptr->call);
>>       if (!newline) newline = 1;
>>       fprintf(R_ProfileOutfile, "\"%s\" ",
>>           TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
>>           "<Anonymous>");
>>   } else if( cptr->callflag & CTXT_LOOP){
>>     SEXP fun = CAR(cptr->syscall);
>>     if (!newline) newline = 1;
>>     fprintf(R_ProfileOutfile, "\"%s\" ", CHAR(PRINTNAME(fun)) );
>>   }
>> }
>>
>> so that we see for in the list of "functions" that appear in the 
>> profiler file.
>>
>> Obviously I am taking some shortcuts here, because of the other 
>> loops, but I would like to make a formal patch with this. Before I do 
>> that, I'd like to know :
>> - is this has a chance of breaking something else (does the CTXT_LOOP 
>> being R_NilValue is used elsewhere)
>> - would this feature be welcome.
>> - Should I differentiate real functions with loops in the output 
>> file, maybe I can write "[for]" instead of for to emphacize this is 
>> not a function.
>>
>> Romain
>>

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: profilerWithLoop.diff
Type: text/x-patch
Size: 2102 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090303/f4136f7b/attachment.bin>

From ripley at stats.ox.ac.uk  Tue Mar  3 18:44:50 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Mar 2009 17:44:50 +0000 (GMT)
Subject: [Rd] R 2.9.0 devel: package installation with configure-args
 option
In-Reply-To: <gojlhg$i5g$1@perl.epigenomics.epi>
References: <gojlhg$i5g$1@perl.epigenomics.epi>
Message-ID: <alpine.LFD.2.00.0903031737560.27426@gannet.stats.ox.ac.uk>

That version of R is 'under development' and the INSTALL file says

## FIXME: this loses quotes, so filepaths with spaces in get broken up

so it is I think the same as a known issue.

The whole package installation process has been completely 
reconstructed for R-devel, and the process is not quite finished.
And this is a low priority as there are effective workarounds.

On Tue, 3 Mar 2009, ml-it-r-devel at epigenomics.com wrote:

> 
> Hi,
> 
> trying
> to install a package containing C code and requiring non-default configure argument
> settings the incantation (this has worked for R <= 2.8.1 on the same architectures)
> 
> R CMD INSTALL --configure-args="--with-opt1 --with-opt2" packname
> 
> does always result in a warning
> Warning: unknown option '--with-opt2'
> 
> and consequently the option is ignored. Reverting the order of options results in the now
> last option to be ignored. Alternative quoting has not provided a solution.
> 
> Using
> 
> R CMD INSTALL --configure-args=--with-opt1 --configure-args=--with-opt2 packname
> 
> does provide a workaround, though. Is this the (new to me) and only intended way to
> provide more than one configure argument?
> I checked ?INSTALL and the referenced R-admin sec. 'Configuration variables' but still am
> not clear on this.
> 
> Regards, Matthias
> 
> 
> R version 2.9.0 Under development (unstable) (2009-03-02 r48041)
> on Ubuntu 8.04, 8.10
> 
> -- 
> Matthias Burger                     Project Manager/ Biostatistician
> Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
> phone:+49-30-24345-0                            fax:+49-30-24345-555
> http://www.epigenomics.com           matthias.burger at epigenomics.com
> --
> Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
> Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
>                                             Oliver Schacht PhD (CFO)
> Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From weigand.stephen at gmail.com  Wed Mar  4 00:43:01 2009
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Tue, 3 Mar 2009 17:43:01 -0600
Subject: [Rd] X11.Rd has a dead link
Message-ID: <bc47d3330903031543p61035d33lbced1a537b9c45ce@mail.gmail.com>

In X11.Rd the Resources section has the following dead link:

  http://web.mit.edu/answers/xwindows/xwindows_resources.html

I never saw the target document but is this its new URL:

  http://kb.mit.edu/confluence/pages/viewpage.action?pageId=3907291

Thank you,

Stephen

-- 
Rochester, Minn. USA


From richard_raubertas at merck.com  Wed Mar  4 02:10:07 2009
From: richard_raubertas at merck.com (richard_raubertas at merck.com)
Date: Wed,  4 Mar 2009 02:10:07 +0100 (CET)
Subject: [Rd] 'anova.gls' in 'nlme' (PR#13567)
Message-ID: <20090304011007.DAD5C2834311@mail.pubhealth.ku.dk>

There is a bug in 'anova.gls' in the 'nlme' package (3.1-90).  The=20
bug is triggered by calling the function with a single 'gls' object=20
and specifying the 'Terms' argument but not the 'L' argument:

> library(nlme)
>  fm1Orth.gls <- gls(distance ~ Sex * I(age - 11), Orthodont,
+                      correlation =3D corSymm(form =3D ~ 1 | Subject),
+                      weights =3D varIdent(form =3D ~ 1 | age))
>  anova(fm1Orth.gls)
Denom. DF: 104=20
                numDF  F-value p-value
(Intercept)         1 4246.041  <.0001
Sex                 1    7.718  0.0065
I(age - 11)         1  116.806  <.0001
Sex:I(age - 11)     1    7.402  0.0076
>  anova(fm1Orth.gls, Terms=3D"Sex")
Error in anova.gls(fm1Orth.gls, Terms =3D "Sex") :=20
  object "noZeroColL" not found
>

The bug is in the following lines near the end:

 if (!missing(L)) {
    if (nrow(L) > 1)
        attr(aod, "L") <- L[, noZeroColL, drop =3D FALSE]
    else attr(aod, "L") <- L[, noZeroColL]
 }

where the problem is that when 'Terms' is provided, earlier code=20
sets 'L' (so it is no longer missing) but does not set 'noZeroColL'.

In the similar function 'anova.lme' the problem is avoided by the=20
first line

 Lmiss <- missing(L)

and then testing whether 'Lmiss' is TRUE in the rest of the=20
function, rather than 'missing(L)'.

Rich Raubertas
Merck & Co.

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D

> sessionInfo()
R version 2.8.1 (2008-12-22)=20
i386-pc-mingw32=20

locale:
LC_COLLATE=3DEnglish_United States.1252;LC_CTYPE=3DEnglish_United
States.1252;LC_MONETARY=3DEnglish_United
States.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


other attached packages:
[1] nlme_3.1-90

loaded via a namespace (and not attached):
[1] grid_2.8.1      lattice_0.17-20 tools_2.8.1   =20
>=20
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From grgoswami at gmail.com  Wed Mar  4 03:59:07 2009
From: grgoswami at gmail.com (Gopi Goswami)
Date: Tue, 3 Mar 2009 21:59:07 -0500
Subject: [Rd] S4 helper functions: regular or generic?
In-Reply-To: <6phzlgar3c7.fsf@gopher4.fhcrc.org>
References: <5811e0170902250359k3de97428h8f92f5882dcdab87@mail.gmail.com>
	<6phzlgar3c7.fsf@gopher4.fhcrc.org>
Message-ID: <5811e0170903031859l23069ec4k757c5e924e9dc212@mail.gmail.com>

Dear Martin,


Thanks a lot for your help, apologies for this very late reply. I
decided to go with your suggestion, write a regular function. I guess
this avoids doing

obj <- as(foo(as(obj, 'Base')), 'Derived')

and then repopulating the extra slots of of the 'Derived' class.


Regards,
gopi.


On Wed, Feb 25, 2009 at 9:36 AM, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> Hi Gopi --
>
> Gopi Goswami <grgoswami at gmail.com> writes:
>
>> Hi there,
>>
>>
>> I want to write helper functions for a base class, which will be used
>> by its subclasses in the S4 world. This function ___will___ update
>> certain slots of its argument object. Please help me decide which one
>> of the following is a better approach with respect to coding style,
>> memory usage and speed:
>>
>
> My opinion:
>
>> o ? Write a regular function.
>
> memory and speed
>
>> o ? Declare a generic and implement it just for the base class.
>
> coding 'style', but style is subjective.
>
> There are other aspects of S4, e.g., type checking, method dispatch,
> programmatically defined and discoverable API, ... (positives),
> cumbersome documentation (negative).
>
> My usual pattern of development is to be seduced by the siren of
> speed, only to regret boxing myself in.
>
> I find that my S4 objects typically serve as containers for
> coordinating other entities. ?The important methods typically extract
> R 'base' objects from the S4 class, manipulate them, and repackage the
> result as S4. The time and speed issues are in the manipulation, not
> in the extraction / repackaging. This is contrast to, say, an
> implementation of a tree-like data structure with a collection of
> 'Node' objects, where tree operations would require access to each
> object and would be horribly slow in S4 (and perhaps R when nodes were
> represented as a list, say, at least compared to a C-level
> representation, or an alternative representation that took advantage
> of R's language characteristics).
>
> Martin
>
>>
>> Thanks for sharing your insight and time,
>> gopi.
>> http://gopi-goswami.net/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Martin Morgan
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M2 B169
> Phone: (206) 667-2793
>


From hpages at fhcrc.org  Wed Mar  4 04:19:04 2009
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Tue, 03 Mar 2009 19:19:04 -0800
Subject: [Rd] callNextMethod() doesn't pass down arguments
Message-ID: <20090303191904.1p825oo8qgw00s48@webmail.fhcrc.org>

Hi,

According to its man page, callNextMethod() (called with
no argument) should call the next method "with the arguments
to the current method passed down to the next method".
But, for the "[[" and "[" generics (primitives), the argument
after the dots doesn't seem to be passed down:

setClass("A", representation(thing="ANY"))
setClass("B", contains="A")

setMethod("[[", "A",
     function(x, i, j, ..., exact=TRUE) return(exact))
setMethod("[[", "B",
     function(x, i, j, ..., exact=TRUE) callNextMethod())

> b <- new("B")
> b[[3]]
[1] TRUE
> b[[3, exact=FALSE]]
[1] TRUE

setMethod("[", "A",
     function(x, i, j, ..., drop=TRUE) return(drop))
setMethod("[", "B",
     function(x, i, j, ..., drop=TRUE) callNextMethod())

> b[3]
[1] TRUE
> b[3, drop=FALSE]
[1] TRUE

I tried this with R 2.8.0 and 2.9.0 (r47727).

Cheers,
H.


From Thomas.Petzoldt at tu-dresden.de  Wed Mar  4 13:08:47 2009
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Wed, 04 Mar 2009 13:08:47 +0100
Subject: [Rd] CRAN package check on MacOS: sh: line 1: gs: command not found
Message-ID: <49AE6F4F.30609@tu-dresden.de>

Dear R developers,

I recently observed a NOTE on several MaxOS X package checks:

sh: line 1: gs: command not found
!!! Error: Closing Ghostscript (exit status: 127)!
/usr/bin/texi2dvi: thumbpdf exited with bad status, quitting.


See for details:

http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/simecol-00check.html

or

http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/fxregime-00check.html


Does anybody know what's wrong here?

Thanks a lot

Thomas Petzoldt


-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From ripley at stats.ox.ac.uk  Wed Mar  4 13:28:19 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Mar 2009 12:28:19 +0000 (GMT)
Subject: [Rd] CRAN package check on MacOS: sh: line 1: gs: command not
 found
In-Reply-To: <49AE6F4F.30609@tu-dresden.de>
References: <49AE6F4F.30609@tu-dresden.de>
Message-ID: <alpine.LFD.2.00.0903041224530.4463@toucan.stats.ox.ac.uk>

On Wed, 4 Mar 2009, Thomas Petzoldt wrote:

> Dear R developers,
>
> I recently observed a NOTE on several MaxOS X package checks:
>
> sh: line 1: gs: command not found
> !!! Error: Closing Ghostscript (exit status: 127)!
> /usr/bin/texi2dvi: thumbpdf exited with bad status, quitting.
>
>
> See for details:
>
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/simecol-00check.html
>
> or
>
> http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/fxregime-00check.html
>
>
> Does anybody know what's wrong here?

Almost certainly a problem on the Mac build machine.  So

1) Asking on R-sig-mac is more likely to get an answer
2) I believe Simon Urbanek is travelling and only he can do anything 
about that machine.

Unfortunately there are rather a lot of problems with the MacOS 
checks, so I tend to ignore them (but then I do have a Mac or two of 
my own to check on).

>
> Thanks a lot
>
> Thomas Petzoldt
>
>
> -- 
> Thomas Petzoldt
> Technische Universitaet Dresden
> Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
> 01062 Dresden                      http://tu-dresden.de/hydrobiologie/
> GERMANY
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdpeng at gmail.com  Wed Mar  4 16:00:34 2009
From: rdpeng at gmail.com (Roger Peng)
Date: Wed, 4 Mar 2009 10:00:34 -0500
Subject: [Rd] Fontconfig warning with X11() on MAC OS X 10.4
In-Reply-To: <22205067.post@talk.nabble.com>
References: <22205067.post@talk.nabble.com>
Message-ID: <66f3bd910903040700j19091c6hb6c877cdde3e693c@mail.gmail.com>

I realize this doesn't directly answer your question, but seeing as
you're on a Mac, have you tried using the quartz device?

-roger

On Wed, Feb 25, 2009 at 10:27 AM, MerliseClyde <clyde at stat.duke.edu> wrote:
>
> I posted previously about problems with X11() on my MAC using R 2.8.1 .
> After installing the securilty update for Tiger this morning, X11() now
> works from an xterm :-)
>
> However, I receive the following warnings with any plotting command using
> the default X11 settings.
> Fontconfig warning: no <cachedir> elements found. Check configuration.
> Fontconfig warning: adding
> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>
> Everything works fine with the Xlib option:
>
>> X11(type="Xlib")
>> plot(1:10) ?# no problems!
>> X11(type="cairo")
>> plot(1:10)
> Fontconfig warning: no <cachedir> elements found. Check configuration.
> Fontconfig warning: adding
> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>
> subsequent commands with X11/cairo plot with no errors.
>
> If I quit R, and start a new session I continue to receive the Fontconfig
> warning.
>
> Any suggestions on what is wrong with my font configuration?
> (mainly annoying :-)
>
> Thanks!
> Merlise
> Version:
> ?platform = i386-apple-darwin8.11.1
> ?arch = i386
> ?os = darwin8.11.1
> ?system = i386, darwin8.11.1
> ?status =
> ?major = 2
> ?minor = 8.1
> ?year = 2008
> ?month = 12
> ?day = 22
> ?svn rev = 47281
> ?language = R
> ?version.string = R version 2.8.1 (2008-12-22)
>
>
> --
> View this message in context: http://www.nabble.com/Fontconfig-warning-with-X11%28%29-on-MAC-OS-X-10.4-tp22205067p22205067.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From simon.urbanek at r-project.org  Wed Mar  4 16:37:24 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 4 Mar 2009 10:37:24 -0500
Subject: [Rd] Fontconfig warning with X11() on MAC OS X 10.4
In-Reply-To: <22205067.post@talk.nabble.com>
References: <22205067.post@talk.nabble.com>
Message-ID: <F9F05D02-8CF2-4C5C-8D1E-73BF0A365A4C@r-project.org>


On Feb 25, 2009, at 10:27 , MerliseClyde wrote:

>
> I posted previously about problems with X11() on my MAC using R  
> 2.8.1 .
> After installing the securilty update for Tiger this morning, X11()  
> now
> works from an xterm :-)
>
> However, I receive the following warnings with any plotting command  
> using
> the default X11 settings.
> Fontconfig warning: no <cachedir> elements found. Check configuration.
> Fontconfig warning: adding
> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/ 
> cache</cachedir>
> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>

Try re-installing R from the CRAN binary -- apparently your FC  
configuration was somehow blown away (strangely since it resides  
within R.framework).

Cheers,
S

PS: This is a sort of question you should send to R-SIG-Mac, really ...


> Everything works fine with the Xlib option:
>
>> X11(type="Xlib")
>> plot(1:10)  # no problems!
>> X11(type="cairo")
>> plot(1:10)
> Fontconfig warning: no <cachedir> elements found. Check configuration.
> Fontconfig warning: adding
> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/ 
> cache</cachedir>
> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>
> subsequent commands with X11/cairo plot with no errors.
>
> If I quit R, and start a new session I continue to receive the  
> Fontconfig
> warning.
>
> Any suggestions on what is wrong with my font configuration?
> (mainly annoying :-)
>
> Thanks!
> Merlise
> Version:
> platform = i386-apple-darwin8.11.1
> arch = i386
> os = darwin8.11.1
> system = i386, darwin8.11.1
> status =
> major = 2
> minor = 8.1
> year = 2008
> month = 12
> day = 22
> svn rev = 47281
> language = R
> version.string = R version 2.8.1 (2008-12-22)
>
>
> -- 
> View this message in context: http://www.nabble.com/Fontconfig-warning-with-X11%28%29-on-MAC-OS-X-10.4-tp22205067p22205067.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From clyde at stat.duke.edu  Wed Mar  4 16:08:43 2009
From: clyde at stat.duke.edu (Merlise Clyde)
Date: Wed, 4 Mar 2009 10:08:43 -0500 (EST)
Subject: [Rd] Fontconfig warning with X11() on MAC OS X 10.4
In-Reply-To: <66f3bd910903040700j19091c6hb6c877cdde3e693c@mail.gmail.com>
References: <22205067.post@talk.nabble.com>
	<66f3bd910903040700j19091c6hb6c877cdde3e693c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0903041001330.19720@okeeffe.isds.duke.edu>

Thanks --

Quartz works perfectly fine under R in an xterm, so do the graphics 
functions in the Cairo package. I usually run R from emacs under X11 on 
both my MAC and  linux box, so just use to the "default" graphics device 
opening with no problems after issuing a graphics command rather than 
having to take the extra step to open the device then issue the plot 
command.

BTW, I have no problem on another MacBook running Leopard.

best,
Merlise


On Wed, 4 Mar 2009, Roger Peng wrote:

> I realize this doesn't directly answer your question, but seeing as
> you're on a Mac, have you tried using the quartz device?
>
> -roger
>
> On Wed, Feb 25, 2009 at 10:27 AM, MerliseClyde <clyde at stat.duke.edu> wrote:
>>
>> I posted previously about problems with X11() on my MAC using R 2.8.1 .
>> After installing the securilty update for Tiger this morning, X11() now
>> works from an xterm :-)
>>
>> However, I receive the following warnings with any plotting command using
>> the default X11 settings.
>> Fontconfig warning: no <cachedir> elements found. Check configuration.
>> Fontconfig warning: adding
>> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
>> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>>
>> Everything works fine with the Xlib option:
>>
>>> X11(type="Xlib")
>>> plot(1:10) ?# no problems!
>>> X11(type="cairo")
>>> plot(1:10)
>> Fontconfig warning: no <cachedir> elements found. Check configuration.
>> Fontconfig warning: adding
>> <cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
>> Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>
>>
>> subsequent commands with X11/cairo plot with no errors.
>>
>> If I quit R, and start a new session I continue to receive the Fontconfig
>> warning.
>>
>> Any suggestions on what is wrong with my font configuration?
>> (mainly annoying :-)
>>
>> Thanks!
>> Merlise
>> Version:
>> ?platform = i386-apple-darwin8.11.1
>> ?arch = i386
>> ?os = darwin8.11.1
>> ?system = i386, darwin8.11.1
>> ?status =
>> ?major = 2
>> ?minor = 8.1
>> ?year = 2008
>> ?month = 12
>> ?day = 22
>> ?svn rev = 47281
>> ?language = R
>> ?version.string = R version 2.8.1 (2008-12-22)
>>
>>
>> --
>> View this message in context: http://www.nabble.com/Fontconfig-warning-with-X11%28%29-on-MAC-OS-X-10.4-tp22205067p22205067.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
>

-- 
__________________________________________________
|                                                |
| Merlise Clyde,  Associate Professor            |
| Department of Statistical Science              |
| 223E  Old Chemistry, BOX 90251                 |
| Duke University                                |
| Durham, NC  27708-0251                         |
|                                                |
| Office Phone: (919) 681-8440                   |
| Fax:          (919) 684-8594                   |
| email:        clyde at stat.duke.edu              |
| web:          http://www.stat.duke.edu/~clyde  |
|________________________________________________|

From hpages at fhcrc.org  Wed Mar  4 19:25:35 2009
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Wed, 04 Mar 2009 10:25:35 -0800
Subject: [Rd] "names<-" doesn't raise an error
Message-ID: <20090304102535.e63qkfy58gw0coc8@webmail.fhcrc.org>

Hi,

When a method is not defined for an object, you
expect to get an error. But this is not the case for
"names<-". You can use "names<-" on any S4 object: it
will remain silent, giving you the impression that it
actually did something:

   setClass("A", representation(vals="numeric"))
   setMethod("names", "A", function(x) names(x at vals))

   > vals <- 8:2
   > names(vals) <- letters[1:7]
   > a <- new("A", vals=vals)
   > names(a)
   [1] "a" "b" "c" "d" "e" "f" "g"
   > names(a) <- LETTERS[1:7]         # no error
   > names(a)
   [1] "a" "b" "c" "d" "e" "f" "g"    # nothing has changed

Shouldn't "names<-" return an error like "[" or "[<-" do
in such situation?

   > a[2]
   Error in a[2] : object of type 'S4' is not subsettable
   > a[2] <- 55
   Error in a[2] <- 55 : object of type 'S4' is not subsettable

That would make it more convenient to implement classes where
instances have immutable names. For now I need to use the
following workaround:

   setReplaceMethod("names", "A", function(x, value) stop("cannot set  
my names"))

   > names(a) <- LETTERS[1:7]
   Error in `names<-`(`*tmp*`, value = c("A", "B", "C", "D", "E", "F", "G" :
     cannot set my names

but that shouldn't be necessary.

Thanks!
H.


From therneau at mayo.edu  Thu Mar  5 02:15:53 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 4 Mar 2009 19:15:53 -0600 (CST)
Subject: [Rd] methods package
Message-ID: <200903050115.n251Frjs006726@yacko.mayo.edu>

  I'm working on the next version of coxme, one step of which is converting
the bdsmatrix library from Splus to R.  Actually, it is a conversion from
S4 methods as first described in the Green book to S4 methods as they 
currently exist.  Mostly it's going ok, but not entirely.

  1. The biggest issue is lack of documentation.  The online help pages have
not been a help; they keep saying it's "as found in the green book - almost".
I've looked for the package on CRAN in the hopes for more there, but can't
find it.  Perchance there is something obvious that I am missing?

  2. The changes are small but numerous.  The current one that has me puzzled
is a method for addition:
   setMethod(Ops, signature=c('numeric', 'bdsmatrix'), ....

Let xmat be ordinary and bmat be a bdsmatrix.  In the old code "xmat + bmat"
fell to this method (which knows what to do), in the current R I get
failure due to no method found.  is.numeric(xmat) is TRUE.
   What is the fix?

 3. In the green book the examples used .Dim and .Dimnames slots, the Matrix
library uses Dim and Dimnames.  Is there a good reason to choose one or the
other?

  I'll be out of town for the next few days (son's wedding) so instant response
is not necessary.

	Terry Therneau


From therneau at mayo.edu  Thu Mar  5 02:38:06 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 4 Mar 2009 19:38:06 -0600 (CST)
Subject: [Rd] Two documentation questions
Message-ID: <200903050138.n251c6qr006942@yacko.mayo.edu>

 1. I often like to put bits of the output into the manual pages.  (We can
have a discussion of the value of this elsewhere -- I think it is sometimes
a good thing.)
  In R I need to surround these with \dontrun{} for the sake of the tester, 
which is fine.  But the printed output contains 
	## Not run
and 
        ## End (not run)

comments, which defeats the purpose of the lines by breaking them off from
the their context.  How do I turn these off?  For printing \dontrun should
be a no-op.  Or at least I should have the option of making it so -- I'm rather
opinionated about the format of things I prepare for teaching purposes.
You can assume medium Tex skills in answering; my book is in Latex but I
don't create my own formats.       

2. In the pdf for the survival package, or at least the one generated by R CMD
check, the entries are in a random order.  Can I fix this?  It makes reading
the document to look for errors rather challenging.  (That is, when I'm 
looking at a particular Rd file, and want to see what it turned out to be.)

   Terry Therneau


From ggrothendieck at gmail.com  Thu Mar  5 03:03:37 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 4 Mar 2009 21:03:37 -0500
Subject: [Rd] Two documentation questions
In-Reply-To: <200903050138.n251c6qr006942@yacko.mayo.edu>
References: <200903050138.n251c6qr006942@yacko.mayo.edu>
Message-ID: <971536df0903041803u1644bf52m62b1d6dd76473d7b@mail.gmail.com>

Perhaps you could just place the output in comments.

print(5) # 5

head(BOD, 2)
#   Time demand
# 1    1    8.3
# 2    2   10.3

On Wed, Mar 4, 2009 at 8:38 PM, Terry Therneau <therneau at mayo.edu> wrote:
> ?1. I often like to put bits of the output into the manual pages. ?(We can
> have a discussion of the value of this elsewhere -- I think it is sometimes
> a good thing.)
> ?In R I need to surround these with \dontrun{} for the sake of the tester,
> which is fine. ?But the printed output contains
> ? ? ? ?## Not run
> and
> ? ? ? ?## End (not run)
>
> comments, which defeats the purpose of the lines by breaking them off from
> the their context. ?How do I turn these off? ?For printing \dontrun should
> be a no-op. ?Or at least I should have the option of making it so -- I'm rather
> opinionated about the format of things I prepare for teaching purposes.
> You can assume medium Tex skills in answering; my book is in Latex but I
> don't create my own formats.
>
> 2. In the pdf for the survival package, or at least the one generated by R CMD
> check, the entries are in a random order. ?Can I fix this? ?It makes reading
> the document to look for errors rather challenging. ?(That is, when I'm
> looking at a particular Rd file, and want to see what it turned out to be.)
>
> ? Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Dan.Kelley at dal.ca  Wed Mar  4 21:33:49 2009
From: Dan.Kelley at dal.ca (Dan Kelley)
Date: Wed, 4 Mar 2009 12:33:49 -0800 (PST)
Subject: [Rd]  patch for axis.POSIXct (related to timezones)
Message-ID: <22338700.post@talk.nabble.com>


I am finding that axis.POSIXct uses the local timezone for deciding where to
put tic marks, even if the data being plotted are in another time zone.  The
solution is to use attr() to copy from the 'x' (provided as an argument) to
the 'z' (used for the 'at' locations). 

I have pasted my proposed solution in section 1 below (as a diff).  Then, in
section 2, I'll put some test code that I wrote, when I was figuring this
out.

I am not entirely sure whether it's OK, or helpful, to post a diff here.  I
don't understand the R development model well enough to know how to suggest
changes, and ?axis.POSIXct does not list an author, so that's why I'm
posting here.

(All of this matters because I am sharing code with people working in
different timezones; I want the timezone of the data to carry over to the
graph.)

Section 1: patch to axis.POSIXct
====================

(Note that the line numbers may be wrong; I'm not working with the source
for axis.POSIXct, but rather with the output from a listing of the function
in the terminal).

~$ diff -Naur axis.POSIXct.R my.axis.POSIXct.R 
--- axis.POSIXct.R	2009-03-04 16:22:18.000000000 -0400
+++ my.axis.POSIXct.R	2009-03-04 16:22:56.000000000 -0400
@@ -1,4 +1,4 @@
-axis.POSIXct <- function (side, x, at, format, labels = TRUE, ...)
+my.axis.POSIXct <- function (side, x, at, format, labels = TRUE, ...)
 {
     mat <- missing(at) || is.null(at)
     if (!mat)
@@ -9,6 +9,7 @@
     else 3:4]
     d <- range[2] - range[1]
     z <- c(range, x[is.finite(x)])
+    attr(z, "tzone") <- attr(x, "tzone")
     if (d < 1.1 * 60) {
         sc <- 1
         if (missing(format))
@@ -41,6 +42,7 @@
         zz <- pretty(z/sc)
         z <- zz * sc
         class(z) <- c("POSIXt", "POSIXct")
+        attr(z, "tzone") <- attr(x, "tzone")
         if (sc == 60 * 60 * 24)
             z <- as.POSIXct(round(z, "days"))
         if (missing(format))
@@ -48,6 +50,7 @@
     }
     else if (d < 1.1 * 60 * 60 * 24 * 365) {
         class(z) <- c("POSIXt", "POSIXct")
+        attr(z, "tzone") <- attr(x, "tzone")
         zz <- as.POSIXlt(z)
         zz$mday <- zz$wday <- zz$yday <- 1
         zz$isdst <- -1
@@ -65,6 +68,7 @@
     }
     else {
         class(z) <- c("POSIXt", "POSIXct")
+        attr(z, "tzone") <- attr(x, "tzone")
         zz <- as.POSIXlt(z)
         zz$mday <- zz$wday <- zz$yday <- 1
         zz$isdst <- -1
~$ 


Section 2.  Test code
=============

# fake some data, and draw a vertical line at midnight ... note how
# the latter will be in the wrong place (unless the computer is set to UTC).
tc <- c("2008-06-28 15:50:00 UTC","2008-06-28 20:50:00 UTC","2008-06-29
01:50:00 UTC",
       "2008-06-29 06:50:00 UTC","2008-06-29 11:50:00 UTC","2008-06-29
16:50:00 UTC",
       "2008-06-29 21:50:00 UTC","2008-06-30 02:50:00 UTC","2008-06-30
07:50:00 UTC",
       "2008-06-30 12:50:00 UTC")
t <- as.POSIXct(tc, tz="UTC")           # note using UTC

p <- c(2.4998, 0.4687, 2.7120, 2.0676, 0.5614, 2.6121, 0.5161, 2.9572,
2.2567, 0.3820)

t0 <- as.POSIXct("2008-06-29 00:00:00", tz="UTC")
par(mfrow=c(2,1))
plot(t, p, type='l')
abline(v=t0, col='red')

plot(t, p, type='l', axes=FALSE)
box()
axis(2)
source("~/my.axis.POSIXct.R")
my.axis.POSIXct(side=1, x=t)
abline(v=t0, col='red')



-- 
View this message in context: http://www.nabble.com/patch-for-axis.POSIXct-%28related-to-timezones%29-tp22338700p22338700.html
Sent from the R devel mailing list archive at Nabble.com.


From jose.perezsuarez at csiro.au  Thu Mar  5 05:58:14 2009
From: jose.perezsuarez at csiro.au (per243)
Date: Wed, 4 Mar 2009 20:58:14 -0800 (PST)
Subject: [Rd]  problems with nls?
Message-ID: <22345292.post@talk.nabble.com>


I need to make nonlinear regression with the posterior script, but how is the
problem? I have error in library (nls), package 'nls' has been merged into
'stats'.
I need help?
What other forms I have to make nonlinear regression? and how I find to
calculate statistics y residuals, scatterplot.

thanks



SCRIPT

ros<-read.table("Dataset.csv",header=T,sep=",")
ros
attach(ros)


# preliminaries

options(width=44)
options(digits=3)
    
## Nonlinear Regression

par(mfrow=c(1,2))

attach(ros)
plot(U1.7km, R, main="(a)")


library(nls)
mod1<-nls(R ~
beta1*(U1.7km^beta2)+(Hm^beta3)),start=list(beta1=2.031,beta2=0.800,beta3=-0.255),
trace = TRUE)

summary(mod1)
coef(mod1)
coef(summary(mod1))

lines(R, fitted.values(mod1), lwd=2)

plot(R, residuals(mod1), type="b", main="(b)")
abline(h=0, lty=2)

-- 
View this message in context: http://www.nabble.com/problems-with-nls--tp22345292p22345292.html
Sent from the R devel mailing list archive at Nabble.com.


From rhafen at stat.purdue.edu  Wed Mar  4 22:10:10 2009
From: rhafen at stat.purdue.edu (rhafen at stat.purdue.edu)
Date: Wed,  4 Mar 2009 22:10:10 +0100 (CET)
Subject: [Rd] bug (PR#13570)
Message-ID: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>


<<insert bug report here>>

This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac and  
for windows.  The problem is with loess degree=0 smoothing.  For  
example, try the following:

x <- 1:100
y <- rnorm(100)
plot(x, y)
lines(predict(loess(y ~ x, degree=0, span=0.5)))

This is obviously wrong.

R 2.8

--please do not edit the information below--

Version:
  platform = i386-apple-darwin8.11.1
  arch = i386
  os = darwin8.11.1
  system = i386, darwin8.11.1
  status =
  major = 2
  minor = 8.1
  year = 2008
  month = 12
  day = 22
  svn rev = 47281
  language = R
  version.string = R version 2.8.1 (2008-12-22)

GUI:
  R-GUI 1.27 (5301)

Locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

Search Path:
  .GlobalEnv, tools:RGUI, package:stats, package:graphics,  
package:grDevices, package:utils, package:datasets, package:Rutils,  
package:methods, Autoloads, package:base


From ripley at stats.ox.ac.uk  Thu Mar  5 08:50:42 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 07:50:42 +0000 (GMT)
Subject: [Rd] patch for axis.POSIXct (related to timezones)
In-Reply-To: <22338700.post@talk.nabble.com>
References: <22338700.post@talk.nabble.com>
Message-ID: <alpine.LFD.2.00.0903050746270.22802@gannet.stats.ox.ac.uk>

This is the appropriate forum, and thank you for the comments.
At a quick look it might be simpler to use the 'tz' argument to 
as.POSIXlt, but I'll look in more detail and commit a change later 
today.

On Wed, 4 Mar 2009, Dan Kelley wrote:

>
> I am finding that axis.POSIXct uses the local timezone for deciding where to
> put tic marks, even if the data being plotted are in another time zone.  The
> solution is to use attr() to copy from the 'x' (provided as an argument) to
> the 'z' (used for the 'at' locations).
>
> I have pasted my proposed solution in section 1 below (as a diff).  Then, in
> section 2, I'll put some test code that I wrote, when I was figuring this
> out.
>
> I am not entirely sure whether it's OK, or helpful, to post a diff here.  I
> don't understand the R development model well enough to know how to suggest
> changes, and ?axis.POSIXct does not list an author, so that's why I'm
> posting here.
>
> (All of this matters because I am sharing code with people working in
> different timezones; I want the timezone of the data to carry over to the
> graph.)
>
> Section 1: patch to axis.POSIXct
> ====================
>
> (Note that the line numbers may be wrong; I'm not working with the source
> for axis.POSIXct, but rather with the output from a listing of the function
> in the terminal).
>
> ~$ diff -Naur axis.POSIXct.R my.axis.POSIXct.R
> --- axis.POSIXct.R	2009-03-04 16:22:18.000000000 -0400
> +++ my.axis.POSIXct.R	2009-03-04 16:22:56.000000000 -0400
> @@ -1,4 +1,4 @@
> -axis.POSIXct <- function (side, x, at, format, labels = TRUE, ...)
> +my.axis.POSIXct <- function (side, x, at, format, labels = TRUE, ...)
> {
>     mat <- missing(at) || is.null(at)
>     if (!mat)
> @@ -9,6 +9,7 @@
>     else 3:4]
>     d <- range[2] - range[1]
>     z <- c(range, x[is.finite(x)])
> +    attr(z, "tzone") <- attr(x, "tzone")
>     if (d < 1.1 * 60) {
>         sc <- 1
>         if (missing(format))
> @@ -41,6 +42,7 @@
>         zz <- pretty(z/sc)
>         z <- zz * sc
>         class(z) <- c("POSIXt", "POSIXct")
> +        attr(z, "tzone") <- attr(x, "tzone")
>         if (sc == 60 * 60 * 24)
>             z <- as.POSIXct(round(z, "days"))
>         if (missing(format))
> @@ -48,6 +50,7 @@
>     }
>     else if (d < 1.1 * 60 * 60 * 24 * 365) {
>         class(z) <- c("POSIXt", "POSIXct")
> +        attr(z, "tzone") <- attr(x, "tzone")
>         zz <- as.POSIXlt(z)
>         zz$mday <- zz$wday <- zz$yday <- 1
>         zz$isdst <- -1
> @@ -65,6 +68,7 @@
>     }
>     else {
>         class(z) <- c("POSIXt", "POSIXct")
> +        attr(z, "tzone") <- attr(x, "tzone")
>         zz <- as.POSIXlt(z)
>         zz$mday <- zz$wday <- zz$yday <- 1
>         zz$isdst <- -1
> ~$
>
>
> Section 2.  Test code
> =============
>
> # fake some data, and draw a vertical line at midnight ... note how
> # the latter will be in the wrong place (unless the computer is set to UTC).
> tc <- c("2008-06-28 15:50:00 UTC","2008-06-28 20:50:00 UTC","2008-06-29
> 01:50:00 UTC",
>       "2008-06-29 06:50:00 UTC","2008-06-29 11:50:00 UTC","2008-06-29
> 16:50:00 UTC",
>       "2008-06-29 21:50:00 UTC","2008-06-30 02:50:00 UTC","2008-06-30
> 07:50:00 UTC",
>       "2008-06-30 12:50:00 UTC")
> t <- as.POSIXct(tc, tz="UTC")           # note using UTC
>
> p <- c(2.4998, 0.4687, 2.7120, 2.0676, 0.5614, 2.6121, 0.5161, 2.9572,
> 2.2567, 0.3820)
>
> t0 <- as.POSIXct("2008-06-29 00:00:00", tz="UTC")
> par(mfrow=c(2,1))
> plot(t, p, type='l')
> abline(v=t0, col='red')
>
> plot(t, p, type='l', axes=FALSE)
> box()
> axis(2)
> source("~/my.axis.POSIXct.R")
> my.axis.POSIXct(side=1, x=t)
> abline(v=t0, col='red')
>
>
>
> -- 
> View this message in context: http://www.nabble.com/patch-for-axis.POSIXct-%28related-to-timezones%29-tp22338700p22338700.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Thu Mar  5 09:07:20 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 5 Mar 2009 00:07:20 -0800 (PST)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0903050007200.20286@hymn32.u.washington.edu>


Could you explain what you are seeing that is wrong?

In R 2.7.2, which is what I have here, it looks ok, and the NEWS file doesn't list any changes since 2.7.1.

      -thomas


On Wed, 4 Mar 2009 rhafen at stat.purdue.edu wrote:

>
> <<insert bug report here>>
>
> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac and
> for windows.  The problem is with loess degree=0 smoothing.  For
> example, try the following:
>
> x <- 1:100
> y <- rnorm(100)
> plot(x, y)
> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>
> This is obviously wrong.
>
> R 2.8
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-apple-darwin8.11.1
>  arch = i386
>  os = darwin8.11.1
>  system = i386, darwin8.11.1
>  status =
>  major = 2
>  minor = 8.1
>  year = 2008
>  month = 12
>  day = 22
>  svn rev = 47281
>  language = R
>  version.string = R version 2.8.1 (2008-12-22)
>
> GUI:
>  R-GUI 1.27 (5301)
>
> Locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> Search Path:
>  .GlobalEnv, tools:RGUI, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, package:Rutils,
> package:methods, Autoloads, package:base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From p.dalgaard at biostat.ku.dk  Thu Mar  5 09:09:27 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 05 Mar 2009 09:09:27 +0100
Subject: [Rd] bug (PR#13570)
In-Reply-To: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
Message-ID: <49AF88B7.1000002@biostat.ku.dk>

rhafen at stat.purdue.edu wrote:
> <<insert bug report here>>
> 
> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac and  
> for windows.  The problem is with loess degree=0 smoothing.  For  
> example, try the following:
> 
> x <- 1:100
> y <- rnorm(100)
> plot(x, y)
> lines(predict(loess(y ~ x, degree=0, span=0.5)))
> 
> This is obviously wrong.

Obvious? How? I don't see anything particularly odd (on Linux).

> 
> R 2.8
> 
> --please do not edit the information below--
> 
> Version:
>   platform = i386-apple-darwin8.11.1
>   arch = i386
>   os = darwin8.11.1
>   system = i386, darwin8.11.1
>   status =
>   major = 2
>   minor = 8.1
>   year = 2008
>   month = 12
>   day = 22
>   svn rev = 47281
>   language = R
>   version.string = R version 2.8.1 (2008-12-22)
> 
> GUI:
>   R-GUI 1.27 (5301)
> 
> Locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> Search Path:
>   .GlobalEnv, tools:RGUI, package:stats, package:graphics,  
> package:grDevices, package:utils, package:datasets, package:Rutils,  
> package:methods, Autoloads, package:base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From r-ml at nn7.de  Thu Mar  5 09:33:27 2009
From: r-ml at nn7.de (Soeren Sonnenburg)
Date: Thu, 05 Mar 2009 09:33:27 +0100
Subject: [Rd] calling Rf_initEmbeddedR twice gives an error
Message-ID: <1236242007.29694.116.camel@localhost>

Dear all,

I've written a R to python/octave/r translator that (so you can call
python from R etc and vice versa) enabling you to e.g. call matplotlib
which just runs fine on the first command

when I do

    Rf_initEmbeddedR(2, argv);
    Rf_endEmbeddedR(0);

    Rf_initEmbeddedR(2, argv);
    Rf_endEmbeddedR(0);

I get this error

Error in .Call("R_isMethodsDispatchOn", onOff, PACKAGE = "base") : 
  Incorrect number of arguments (2), expecting 1 for R_isMethodsDispatchOn
Error in gzfile(file) : invalid 'encoding' argument
Fatal error: unable to restore saved data in .RData


I've recognized that there were others with that problem - which is
marked user error here
http://bugs.r-project.org/cgi-bin/R/trashcan?id=12644;user=guest;selectid=12644


Unfortunately it is nowhere stated what one should have called...   Any
of
    R_dot_Last();
    R_RunExitFinalizers();
    R_gc();

does not help either...

However I can trigger the problem on the R cmdline when I do:
.Call("R_isMethodsDispatchOn", 1,2, PACKAGE = "base") : 

also looking at src/main/registration.c I don't see a reason why it
should be wrong:    CALLDEF(R_isMethodsDispatchOn, 1)...

Any ideas?

Soeren


From maechler at stat.math.ethz.ch  Thu Mar  5 09:45:36 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Thu,  5 Mar 2009 09:45:36 +0100 (CET)
Subject: [Rd] besselI inaccurate for negative integer order (PR#13556)
Message-ID: <20090305084536.8D05C2832191@mail.pubhealth.ku.dk>

>>>>> "JL" == Jerry Lewis <Jerry.Lewis at biogenidec.com>
>>>>>     on Thu, 26 Feb 2009 16:15:11 +0100 (CET) writes:

    JL> Full_Name: Jerry W. Lewis
    JL> Version: 2.8.1
    JL> OS: Windows XP Professional
    JL> Submission from: (NULL) (198.180.131.16)


    JL> It should be the case that
    JL> besselI(x,-nu) == besselI(x,nu) == besselI(x,abs(nu))
    JL> for integer nu, yet R currently can return ridiculous values when nu is a
    JL> negative integer.

    JL> For instance, besselI(9.6,-44) returns -234626490 instead of the correct value
    JL> of 5.9041042646307223e-25, while besselI(9.6,44) gives essentially machine
    JL> accuracy.

Yes.  I have committed a bug-fix to both R-patched and R-devel.

Thank you for the report!
Martin Maechler, ETH Zurich


    JL> This is more than an idle mathematical curiosity, since
    JL> one consequence is that dskellam in the VGAM package can
    JL> return values <0 or >1.


From ripley at stats.ox.ac.uk  Thu Mar  5 09:49:16 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 08:49:16 +0000 (GMT)
Subject: [Rd] problems with nls?
In-Reply-To: <22345292.post@talk.nabble.com>
References: <22345292.post@talk.nabble.com>
Message-ID: <alpine.LFD.2.00.0903050842090.24370@gannet.stats.ox.ac.uk>

I don't see why this is relevant to R-devel rather than R-help.

Your script must be very old: the NEWS for R 1.9.0 said

         Packages ctest, eda, modreg, mva, nls, stepfun and ts have been
         merged into stats, and lqs has been returned to MASS.

That's 5 years ago now.

Function nls() still exists, and is in the 'stats' package which is 
loaded in a default R session.

On Wed, 4 Mar 2009, per243 wrote:

> I need to make nonlinear regression with the posterior script, but how is the
> problem? I have error in library (nls), package 'nls' has been merged into
> 'stats'.

It was _not_ an error:

> library(nls)
Warning message:
package 'nls' has been merged into 'stats'

so if your script did not run something else was the error.  (We don't 
have the dataset, so cannot reproduce what you did.)

> I need help?
> What other forms I have to make nonlinear regression? and how I find to
> calculate statistics y residuals, scatterplot.

Please read 'An Introduction to R' and then a basic book on 
statistics with R.

>
> thanks
>
>
>
> SCRIPT
>
> ros<-read.table("Dataset.csv",header=T,sep=",")
> ros
> attach(ros)
>
>
> # preliminaries
>
> options(width=44)
> options(digits=3)
>
> ## Nonlinear Regression
>
> par(mfrow=c(1,2))
>
> attach(ros)
> plot(U1.7km, R, main="(a)")
>
>
> library(nls)
> mod1<-nls(R ~
> beta1*(U1.7km^beta2)+(Hm^beta3)),start=list(beta1=2.031,beta2=0.800,beta3=-0.255),
> trace = TRUE)
>
> summary(mod1)
> coef(mod1)
> coef(summary(mod1))
>
> lines(R, fitted.values(mod1), lwd=2)
>
> plot(R, residuals(mod1), type="b", main="(b)")
> abline(h=0, lty=2)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Thu Mar  5 10:43:01 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 5 Mar 2009 17:43:01 +0800
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49AF88B7.1000002@biostat.ku.dk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
Message-ID: <20090305174301.20099b11@berwin-nus1>

G'day Peter,

On Thu, 05 Mar 2009 09:09:27 +0100
Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> rhafen at stat.purdue.edu wrote:
> > <<insert bug report here>>
> > 
> > This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
> > and for windows.  The problem is with loess degree=0 smoothing.
> > For example, try the following:
> > 
> > x <- 1:100
> > y <- rnorm(100)
> > plot(x, y)
> > lines(predict(loess(y ~ x, degree=0, span=0.5)))
> > 
> > This is obviously wrong.
> 
> Obvious? How? I don't see anything particularly odd (on Linux).

Neither did I on linux; but the OP mentioned mac and windows. 

On windows, on running that code, the lines() command added a lot of
vertical lines; most spanning the complete window but some only part.  

Executing the code a second time (or in steps) gave sensible
results.  

My guess would be that some memory is not correctly allocated or
initialised.  Or is it something like an object with storage mode
"integer" being passed to a double?  But then, why doesn't it show on
linux?

Happy bug hunting.  If my guess is correct, then I have no idea how to
track down such things under windows.....

Cheers,

	Berwin


From ml-it-r-devel at epigenomics.com  Thu Mar  5 11:14:48 2009
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Thu, 05 Mar 2009 11:14:48 +0100
Subject: [Rd] methods package
In-Reply-To: <200903050115.n251Frjs006726@yacko.mayo.edu>
References: <200903050115.n251Frjs006726@yacko.mayo.edu>
Message-ID: <49AFA618.9010200@epigenomics.com>

Terry Therneau wrote:
>   I'm working on the next version of coxme, one step of which is converting
> the bdsmatrix library from Splus to R.  Actually, it is a conversion from
> S4 methods as first described in the Green book to S4 methods as they 
> currently exist.  Mostly it's going ok, but not entirely.
> 
>   1. The biggest issue is lack of documentation.  The online help pages have
> not been a help; they keep saying it's "as found in the green book - almost".
> I've looked for the package on CRAN in the hopes for more there, but can't
> find it.  Perchance there is something obvious that I am missing?
> 
>   2. The changes are small but numerous.  The current one that has me puzzled
> is a method for addition:
>    setMethod(Ops, signature=c('numeric', 'bdsmatrix'), ....
> 
> Let xmat be ordinary and bmat be a bdsmatrix.  In the old code "xmat + bmat"
> fell to this method (which knows what to do), in the current R I get
> failure due to no method found.  is.numeric(xmat) is TRUE.
>    What is the fix?

Assuming xmat to be a numeric matrix e.g. diag(n).
S4 inheritance will be determined by is() and
is(xmat, "numeric") will be FALSE

So one solution is to provide explicit methods for signature 'matrix' i.e.
 setMethod(Ops, signature=c('matrix', 'bdsmatrix'), ....
 setMethod(Ops, signature=c('bdsmatrix', 'matrix'), ....

  Matthias

>  3. In the green book the examples used .Dim and .Dimnames slots, the Matrix
> library uses Dim and Dimnames.  Is there a good reason to choose one or the
> other?
> 
>   I'll be out of town for the next few days (son's wedding) so instant response
> is not necessary.
> 
> 	Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-0                            fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
                                            Oliver Schacht PhD (CFO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From ligges at statistik.tu-dortmund.de  Thu Mar  5 12:14:26 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 05 Mar 2009 12:14:26 +0100
Subject: [Rd] bug (PR#13570)
In-Reply-To: <20090305174301.20099b11@berwin-nus1>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
Message-ID: <49AFB412.2060807@statistik.tu-dortmund.de>

Berwin A Turlach wrote:
> G'day Peter,
> 
> On Thu, 05 Mar 2009 09:09:27 +0100
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> 
>> rhafen at stat.purdue.edu wrote:
>>> <<insert bug report here>>
>>>
>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>> and for windows.  The problem is with loess degree=0 smoothing.
>>> For example, try the following:
>>>
>>> x <- 1:100
>>> y <- rnorm(100)
>>> plot(x, y)
>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>
>>> This is obviously wrong.
>> Obvious? How? I don't see anything particularly odd (on Linux).
> 
> Neither did I on linux; but the OP mentioned mac and windows. 
> 
> On windows, on running that code, the lines() command added a lot of
> vertical lines; most spanning the complete window but some only part.  
> 
> Executing the code a second time (or in steps) gave sensible
> results.  
> 
> My guess would be that some memory is not correctly allocated or
> initialised.  Or is it something like an object with storage mode
> "integer" being passed to a double?  But then, why doesn't it show on
> linux?
> 
> Happy bug hunting.  If my guess is correct, then I have no idea how to
> track down such things under windows.....
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
weeks) and report if you still see it. I do not under R-devel (but do 
under R-release), so my guess is that something called by loess() has 
been fixed in the meantime.

Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
but the loess computations.

Uwe Ligges


From ligges at statistik.tu-dortmund.de  Thu Mar  5 12:15:37 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Thu,  5 Mar 2009 12:15:37 +0100 (CET)
Subject: [Rd] bug (PR#13570)
Message-ID: <20090305111537.12F232832198@mail.pubhealth.ku.dk>

Berwin A Turlach wrote:
> G'day Peter,
> 
> On Thu, 05 Mar 2009 09:09:27 +0100
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> 
>> rhafen at stat.purdue.edu wrote:
>>> <<insert bug report here>>
>>>
>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>> and for windows.  The problem is with loess degree=0 smoothing.
>>> For example, try the following:
>>>
>>> x <- 1:100
>>> y <- rnorm(100)
>>> plot(x, y)
>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>
>>> This is obviously wrong.
>> Obvious? How? I don't see anything particularly odd (on Linux).
> 
> Neither did I on linux; but the OP mentioned mac and windows. 
> 
> On windows, on running that code, the lines() command added a lot of
> vertical lines; most spanning the complete window but some only part.  
> 
> Executing the code a second time (or in steps) gave sensible
> results.  
> 
> My guess would be that some memory is not correctly allocated or
> initialised.  Or is it something like an object with storage mode
> "integer" being passed to a double?  But then, why doesn't it show on
> linux?
> 
> Happy bug hunting.  If my guess is correct, then I have no idea how to
> track down such things under windows.....
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
weeks) and report if you still see it. I do not under R-devel (but do 
under R-release), so my guess is that something called by loess() has 
been fixed in the meantime.

Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
but the loess computations.

Uwe Ligges


From ripley at stats.ox.ac.uk  Thu Mar  5 12:30:28 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 11:30:28 +0000 (GMT)
Subject: [Rd] Two documentation questions
In-Reply-To: <200903050138.n251c6qr006942@yacko.mayo.edu>
References: <200903050138.n251c6qr006942@yacko.mayo.edu>
Message-ID: <alpine.LFD.2.00.0903050756500.22802@gannet.stats.ox.ac.uk>

On Wed, 4 Mar 2009, Terry Therneau wrote:

> 1. I often like to put bits of the output into the manual pages.  (We can
> have a discussion of the value of this elsewhere -- I think it is sometimes
> a good thing.)

I presume you mean in the \examples section of the .Rd files, not 
elsewhere in the help.

>  In R I need to surround these with \dontrun{} for the sake of the tester,
> which is fine.  But the printed output contains
> 	## Not run
> and
>        ## End (not run)

'printed output'?  We have conversion to text, HTML, latex and .R, and 
they are all done separately.  I guess you are only concerned with 
conversion to latex?

> comments, which defeats the purpose of the lines by breaking them off from
> the their context.  How do I turn these off?  For printing \dontrun should
> be a no-op.

I'm not sure why it 'should'. Conversion to latex is not just for 
printing, nor is \dontrun primarily for output.  Indeed, at one point 
a couple of months ago the parseRd function required what was in 
\dontrun to be valid R code.

I certainly find having the \dontrun material in the package PDF 
manual helpful on occasion.

> Or at least I should have the option of making it so -- I'm rather
> opinionated about the format of things I prepare for teaching purposes.
> You can assume medium Tex skills in answering; my book is in Latex but I
> don't create my own formats.

If you mean conversion to latex, you could either alter Rdconv.pm 
or post-process the output: this is in a verbatim-like section so it 
would not be easy to do so in LaTeX.  If I did this often I would be 
adding some markup for this purpose, but post-processing in R should 
be easy (and tools:::massageExamples (in R-devel) does so).

> 2. In the pdf for the survival package, or at least the one 
> generated by R CMD check, the entries are in a random order.  Can I 
> fix this?  It makes reading the document to look for errors rather 
> challenging.  (That is, when I'm looking at a particular Rd file, 
> and want to see what it turned out to be.)

They should not be 'random'.  E.g. 
http://cran.r-project.org/web/packages/survival/survival.pdf is not: 
it is in alphabetical order (C locale), and that is what I see for R 
CMD check in 2.8.1 (but in the collation order of the locale; this is 
done by Perl so depends on what it thinks is appropriate).

This is one of the things that is changing for R 2.9.0, and hence in 
current R-devel.  R CMD check will always uses R CMD Rd2dvi, and that 
produces PDF manuals in alphabetic order of the Rd files, in the 
current locale (I think Rd2dvi was always in C collation in earlier 
versions).

R CMD check was more a check of the latex conversion of the files, not 
a final manual (it got bundles wrong, for example, omitted the 
DESCRIPTIOM and did not check that the index worked). R-devel it does 
produce a standard package manual, and the collation is by R.

Collation is a messy area with lots of OS-dependent errors.  That's 
why in R-devel we have moved almost all this to R code, where we can 
control it (and can replace the OS's collation services by ICU if 
available).  And relevant to you is

> sort(c("Surv", "surv", "survdiff"))
[1] "surv"     "Surv"     "survdiff"

which is what ICU thinks is right in English (and for one set of 
English rules, it is -- further it allows you to tune them).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Mar  5 12:56:45 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 06:56:45 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49AFB412.2060807@statistik.tu-dortmund.de>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
Message-ID: <49AFBDFD.5000001@stats.uwo.ca>

Uwe Ligges wrote:
> Berwin A Turlach wrote:
>   
>> G'day Peter,
>>
>> On Thu, 05 Mar 2009 09:09:27 +0100
>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>
>>     
>>> rhafen at stat.purdue.edu wrote:
>>>       
>>>> <<insert bug report here>>
>>>>
>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>> For example, try the following:
>>>>
>>>> x <- 1:100
>>>> y <- rnorm(100)
>>>> plot(x, y)
>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>
>>>> This is obviously wrong.
>>>>         
>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>       
>> Neither did I on linux; but the OP mentioned mac and windows. 
>>
>> On windows, on running that code, the lines() command added a lot of
>> vertical lines; most spanning the complete window but some only part.  
>>
>> Executing the code a second time (or in steps) gave sensible
>> results.  
>>
>> My guess would be that some memory is not correctly allocated or
>> initialised.  Or is it something like an object with storage mode
>> "integer" being passed to a double?  But then, why doesn't it show on
>> linux?
>>
>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>> track down such things under windows.....
>>
>> Cheers,
>>
>> 	Berwin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>     
>
>
> Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
> weeks) and report if you still see it. I do not under R-devel (but do 
> under R-release), so my guess is that something called by loess() has 
> been fixed in the meantime.
>
> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
> but the loess computations.

I still see it in R-patched (haven't tried R-devel yet).  So I think it 
is worth tracking down and fixing; I'll do it later today.

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu Mar  5 13:00:36 2009
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Thu,  5 Mar 2009 13:00:36 +0100 (CET)
Subject: [Rd] bug (PR#13570)
Message-ID: <20090305120036.E39E4283218A@mail.pubhealth.ku.dk>

Uwe Ligges wrote:
> Berwin A Turlach wrote:
>   
>> G'day Peter,
>>
>> On Thu, 05 Mar 2009 09:09:27 +0100
>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>
>>     
>>> rhafen at stat.purdue.edu wrote:
>>>       
>>>> <<insert bug report here>>
>>>>
>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>> For example, try the following:
>>>>
>>>> x <- 1:100
>>>> y <- rnorm(100)
>>>> plot(x, y)
>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>
>>>> This is obviously wrong.
>>>>         
>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>       
>> Neither did I on linux; but the OP mentioned mac and windows. 
>>
>> On windows, on running that code, the lines() command added a lot of
>> vertical lines; most spanning the complete window but some only part.  
>>
>> Executing the code a second time (or in steps) gave sensible
>> results.  
>>
>> My guess would be that some memory is not correctly allocated or
>> initialised.  Or is it something like an object with storage mode
>> "integer" being passed to a double?  But then, why doesn't it show on
>> linux?
>>
>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>> track down such things under windows.....
>>
>> Cheers,
>>
>> 	Berwin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>     
>
>
> Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
> weeks) and report if you still see it. I do not under R-devel (but do 
> under R-release), so my guess is that something called by loess() has 
> been fixed in the meantime.
>
> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
> but the loess computations.

I still see it in R-patched (haven't tried R-devel yet).  So I think it 
is worth tracking down and fixing; I'll do it later today.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Thu Mar  5 13:10:20 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 12:10:20 +0000 (GMT)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49AFB412.2060807@statistik.tu-dortmund.de>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
Message-ID: <alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>

Undortunately the example is random, so not really reproducible (and I 
see nothing wrong on my Mac). However, Linux valgrind on R-devel is 
showing a problem:

==3973== Conditional jump or move depends on uninitialised value(s)
==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
==3973==    by 0xD761600: lowesa_ (loessf.f:769)
==3973==    by 0xD736E47: loess_raw (loessc.c:117)

(The uninitiialized value is in someone else's code and I suspect it 
was either never intended to work or never tested.)  No essential 
change has been made to the loess code for many years.

I would not have read the documentation to say that degree = 0 was a 
reasonable value. It is not to my mind 'a polynomial surface', and 
loess() is described as a 'local regression' for degree 1 or 2 in 
the reference.  So unless anyone wants to bury their heads in that 
code I think a perfectly adequate fix would be to disallow degree = 0.
(I vaguely recall debating allowing in the code ca 10 years ago.)

On Thu, 5 Mar 2009, Uwe Ligges wrote:

> Berwin A Turlach wrote:
>> G'day Peter,
>> 
>> On Thu, 05 Mar 2009 09:09:27 +0100
>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> 
>>> rhafen at stat.purdue.edu wrote:
>>>> <<insert bug report here>>
>>>> 
>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>> For example, try the following:
>>>> 
>>>> x <- 1:100
>>>> y <- rnorm(100)
>>>> plot(x, y)
>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>> 
>>>> This is obviously wrong.
>>> Obvious? How? I don't see anything particularly odd (on Linux).
>> 
>> Neither did I on linux; but the OP mentioned mac and windows. 
>> On windows, on running that code, the lines() command added a lot of
>> vertical lines; most spanning the complete window but some only part. 
>> Executing the code a second time (or in steps) gave sensible
>> results. 
>> My guess would be that some memory is not correctly allocated or
>> initialised.  Or is it something like an object with storage mode
>> "integer" being passed to a double?  But then, why doesn't it show on
>> linux?
>> 
>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>> track down such things under windows.....
>> 
>> Cheers,
>>
>> 	Berwin
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> Please can you folks try under R-devel (to be R-2.9.0 in a couple of weeks) 
> and report if you still see it. I do not under R-devel (but do under 
> R-release), so my guess is that something called by loess() has been fixed in 
> the meantime.
>
> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) but 
> the loess computations.
>
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Thu Mar  5 13:35:29 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 05 Mar 2009 13:35:29 +0100
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
Message-ID: <49AFC711.1030902@biostat.ku.dk>

Prof Brian Ripley wrote:
> Undortunately the example is random, so not really reproducible (and I
> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
> showing a problem:
> 
> ==3973== Conditional jump or move depends on uninitialised value(s)
> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
> 
> (The uninitiialized value is in someone else's code and I suspect it was
> either never intended to work or never tested.)  No essential change has
> been made to the loess code for many years.
> 
> I would not have read the documentation to say that degree = 0 was a
> reasonable value. It is not to my mind 'a polynomial surface', and
> loess() is described as a 'local regression' for degree 1 or 2 in the
> reference.  So unless anyone wants to bury their heads in that code I
> think a perfectly adequate fix would be to disallow degree = 0.
> (I vaguely recall debating allowing in the code ca 10 years ago.)

The code itself has

    if (!match(degree, 0:2, 0))
        stop("'degree' must be 0, 1 or 2")

though. "Local fitting of a constant" essentially becomes kernel
smoothing, right?


> On Thu, 5 Mar 2009, Uwe Ligges wrote:
> 
>> Berwin A Turlach wrote:
>>> G'day Peter,
>>>
>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>
>>>> rhafen at stat.purdue.edu wrote:
>>>>> <<insert bug report here>>
>>>>>
>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>> For example, try the following:
>>>>>
>>>>> x <- 1:100
>>>>> y <- rnorm(100)
>>>>> plot(x, y)
>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>
>>>>> This is obviously wrong.
>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>
>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>> windows, on running that code, the lines() command added a lot of
>>> vertical lines; most spanning the complete window but some only part.
>>> Executing the code a second time (or in steps) gave sensible
>>> results. My guess would be that some memory is not correctly
>>> allocated or
>>> initialised.  Or is it something like an object with storage mode
>>> "integer" being passed to a double?  But then, why doesn't it show on
>>> linux?
>>>
>>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>>> track down such things under windows.....
>>>
>>> Cheers,
>>>
>>>     Berwin
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> Please can you folks try under R-devel (to be R-2.9.0 in a couple of
>> weeks) and report if you still see it. I do not under R-devel (but do
>> under R-release), so my guess is that something called by loess() has
>> been fixed in the meantime.
>>
>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>> (release) but the loess computations.
>>
>> Uwe Ligges
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Mar  5 13:59:32 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 12:59:32 +0000 (GMT)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49AFC711.1030902@biostat.ku.dk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
Message-ID: <alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>

On Thu, 5 Mar 2009, Peter Dalgaard wrote:

> Prof Brian Ripley wrote:
>> Undortunately the example is random, so not really reproducible (and I
>> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
>> showing a problem:
>>
>> ==3973== Conditional jump or move depends on uninitialised value(s)
>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>
>> (The uninitiialized value is in someone else's code and I suspect it was
>> either never intended to work or never tested.)  No essential change has
>> been made to the loess code for many years.
>>
>> I would not have read the documentation to say that degree = 0 was a
>> reasonable value. It is not to my mind 'a polynomial surface', and
>> loess() is described as a 'local regression' for degree 1 or 2 in the
>> reference.  So unless anyone wants to bury their heads in that code I
>> think a perfectly adequate fix would be to disallow degree = 0.
>> (I vaguely recall debating allowing in the code ca 10 years ago.)
>
> The code itself has
>
>    if (!match(degree, 0:2, 0))
>        stop("'degree' must be 0, 1 or 2")
>
> though. "Local fitting of a constant" essentially becomes kernel
> smoothing, right?

I do know the R code allows it: the question is whether it is worth 
the effort of finding the problem(s) in the underlying c/dloess code, 
whose manual (and our reference) is entirely about 1 or 2.  I am 
concerned that there may be other things lurking in the degree=0 case 
if it was never tested (in the netlib version: I am sure it was only 
minmally tested through my R interface).

I checked the original documentation on netlib and that says

29      DIM     dimension of local regression
                 1               constant
                 d+1             linear   (default)
                 (d+2)(d+1)/2    quadratic
                 Modified by ehg127 if cdeg<tdeg.

which seems to confirm that degree = 0 was intended to be allowed, and 
what I dimly recall from ca 1998 is debating whether the R code should 
allow that or not.

If left to me I would say I did not wish to continue to support degree 
= 0.

>
>
>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>
>>> Berwin A Turlach wrote:
>>>> G'day Peter,
>>>>
>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>
>>>>> rhafen at stat.purdue.edu wrote:
>>>>>> <<insert bug report here>>
>>>>>>
>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>>> For example, try the following:
>>>>>>
>>>>>> x <- 1:100
>>>>>> y <- rnorm(100)
>>>>>> plot(x, y)
>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>
>>>>>> This is obviously wrong.
>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>>
>>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>>> windows, on running that code, the lines() command added a lot of
>>>> vertical lines; most spanning the complete window but some only part.
>>>> Executing the code a second time (or in steps) gave sensible
>>>> results. My guess would be that some memory is not correctly
>>>> allocated or
>>>> initialised.  Or is it something like an object with storage mode
>>>> "integer" being passed to a double?  But then, why doesn't it show on
>>>> linux?
>>>>
>>>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>>>> track down such things under windows.....
>>>>
>>>> Cheers,
>>>>
>>>>     Berwin
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple of
>>> weeks) and report if you still see it. I do not under R-devel (but do
>>> under R-release), so my guess is that something called by loess() has
>>> been fixed in the meantime.
>>>
>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>> (release) but the loess computations.
>>>
>>> Uwe Ligges
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From therneau at mayo.edu  Thu Mar  5 14:12:21 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 5 Mar 2009 07:12:21 -0600 (CST)
Subject: [Rd] documentation questions
Message-ID: <200903051312.n25DCLCa011798@yacko.mayo.edu>


You've answered my question 2 about why the manual was in odd order
> R CMD check was more of a check of the latex version of the files, not
> the final manual.

I was looking at the result of R CMD check, and it was in random order
(perhaps file date?), not just a different collation choice. Very odd.
I will cease worrying about what I might have "done wrong".

I omitted the important version information: R version 2.7.1 (2008-06-23)
on Linux.  

My other question was apparently unclear.  
  looking at the pdf output (because it is nicest to read) 
  I refer to it as "printed" because that's what I very often do for any
substantial chunk of reading (>2 pages).  Easier on my eyes.  
  Talking only about the example section
  The question is what the result of \dontrun should be when producing a
product that is meant to be read by a human, and I will assume that this is
the primary target of the latex process.  I oject to the comment that it adds.

  I would much prefer that it not add extraneous comments to my examples.  I
do want the items bracketed by \dontrun to appear -- if I didn't think the
lines were useful I wouldn't have put them there.  Perhaps because I like
printed versions I like examples to show not just legal input, but give
feedback on what the code does; thus make it to the extent possible look
like a shapshot of a session and not just a set of legal input.  It is most
often output that I will have bracketed.  (wrt Gabor's comment, I would rather
not turn it into a comment block; it would not look at all like that on
the screen).  
  There will be two levels to the response: argue that I really shouldn't
want to do this, and suggestions on how or how not to accomplish it.  Wrt
the first -- I need to consider this more.  You may convince me.  Wrt th
second:
   I don't know perl, but looked at Rdconv.pm.  It looks like changing the line
to $text= undefine_command($text, "dontrun") would do what I want; but that's
a guess, and it would only change the local behavior
   I'll have to pull down R-devel to understand the tools::: comment.
   Yes, verbatim sections in Tex are subtle.

  Thanks for the input.


From ripley at stats.ox.ac.uk  Thu Mar  5 14:30:38 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 13:30:38 +0000 (GMT)
Subject: [Rd] documentation questions
In-Reply-To: <200903051312.n25DCLCa011798@yacko.mayo.edu>
References: <200903051312.n25DCLCa011798@yacko.mayo.edu>
Message-ID: <alpine.LFD.2.00.0903051317580.7007@gannet.stats.ox.ac.uk>

I read

> For printing \dontrun should be a no-op.

to mean that it should produce no output, but I suspect you meant you 
wanted it to pass its argument through verbatim.

If we were continuing with the Rdconv.pm I would be suggesting adding 
some markup for that job (e.g. \verbdontrun), but as we are 
transitioning to another system adding anything right now is a lot of 
extra work.

To change Rdconv.pm for latex, the line is (in code2latex, l.2639 in 
R-devel)

     $text = replace_addnl_command($text, "dontrun",
 				  "## Not run: ", "## End(Not run)");

and AFAICS it would need to be

     $text = undefine_command($text, "dontrun");



On Thu, 5 Mar 2009, Terry Therneau wrote:

>
> You've answered my question 2 about why the manual was in odd order
>> R CMD check was more of a check of the latex version of the files, not
>> the final manual.
>
> I was looking at the result of R CMD check, and it was in random order
> (perhaps file date?), not just a different collation choice. Very odd.
> I will cease worrying about what I might have "done wrong".
>
> I omitted the important version information: R version 2.7.1 (2008-06-23)
> on Linux.

Looking more closely, it all depends how Perl lists directories: that 
could be in almost any order but I am seeing collated orders.

> My other question was apparently unclear.
>  looking at the pdf output (because it is nicest to read)
>  I refer to it as "printed" because that's what I very often do for any
> substantial chunk of reading (>2 pages).  Easier on my eyes.
>  Talking only about the example section
>  The question is what the result of \dontrun should be when producing a
> product that is meant to be read by a human, and I will assume that this is
> the primary target of the latex process.  I oject to the comment that it adds.
>
>  I would much prefer that it not add extraneous comments to my examples.  I
> do want the items bracketed by \dontrun to appear -- if I didn't think the
> lines were useful I wouldn't have put them there.  Perhaps because I like
> printed versions I like examples to show not just legal input, but give
> feedback on what the code does; thus make it to the extent possible look
> like a shapshot of a session and not just a set of legal input.  It is most
> often output that I will have bracketed.  (wrt Gabor's comment, I would rather
> not turn it into a comment block; it would not look at all like that on
> the screen).
>  There will be two levels to the response: argue that I really shouldn't
> want to do this, and suggestions on how or how not to accomplish it.  Wrt
> the first -- I need to consider this more.  You may convince me.  Wrt th
> second:
>   I don't know perl, but looked at Rdconv.pm.  It looks like changing the line
> to $text= undefine_command($text, "dontrun") would do what I want; but that's
> a guess, and it would only change the local behavior
>   I'll have to pull down R-devel to understand the tools::: comment.
>   Yes, verbatim sections in Tex are subtle.
>
>  Thanks for the input.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  5 15:01:43 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 14:01:43 +0000 (GMT)
Subject: [Rd] R 2.9.0 devel: package installation with configure-args
 option
In-Reply-To: <alpine.LFD.2.00.0903031737560.27426@gannet.stats.ox.ac.uk>
References: <gojlhg$i5g$1@perl.epigenomics.epi>
	<alpine.LFD.2.00.0903031737560.27426@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.00.0903051359020.8287@gannet.stats.ox.ac.uk>

I think this should now work (one of several 'FIXME' issues addressed 
in the latest commit -- there are still some to go, but 2.9.0 is not 
due for 6 weeks).

It is always useful to have a real test example, though.  (I used rgl 
in relation to some discussion about paths on r-sig-mac.)

On Tue, 3 Mar 2009, Prof Brian Ripley wrote:

> That version of R is 'under development' and the INSTALL file says
>
> ## FIXME: this loses quotes, so filepaths with spaces in get broken up
>
> so it is I think the same as a known issue.
>
> The whole package installation process has been completely reconstructed for 
> R-devel, and the process is not quite finished.
> And this is a low priority as there are effective workarounds.
>
> On Tue, 3 Mar 2009, ml-it-r-devel at epigenomics.com wrote:
>
>> 
>> Hi,
>> 
>> trying
>> to install a package containing C code and requiring non-default configure 
>> argument
>> settings the incantation (this has worked for R <= 2.8.1 on the same 
>> architectures)
>> 
>> R CMD INSTALL --configure-args="--with-opt1 --with-opt2" packname
>> 
>> does always result in a warning
>> Warning: unknown option '--with-opt2'
>> 
>> and consequently the option is ignored. Reverting the order of options 
>> results in the now
>> last option to be ignored. Alternative quoting has not provided a solution.
>> 
>> Using
>> 
>> R CMD INSTALL --configure-args=--with-opt1 --configure-args=--with-opt2 
>> packname
>> 
>> does provide a workaround, though. Is this the (new to me) and only 
>> intended way to
>> provide more than one configure argument?
>> I checked ?INSTALL and the referenced R-admin sec. 'Configuration 
>> variables' but still am
>> not clear on this.
>> 
>> Regards, Matthias
>> 
>> 
>> R version 2.9.0 Under development (unstable) (2009-03-02 r48041)
>> on Ubuntu 8.04, 8.10
>> 
>> -- 
>> Matthias Burger                     Project Manager/ Biostatistician
>> Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
>> phone:+49-30-24345-0                            fax:+49-30-24345-555
>> http://www.epigenomics.com           matthias.burger at epigenomics.com
>> --
>> Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
>> Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
>>                                             Oliver Schacht PhD (CFO)
>> Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From krcoombes at mdacc.tmc.edu  Thu Mar  5 15:24:36 2009
From: krcoombes at mdacc.tmc.edu (Kevin R. Coombes)
Date: Thu, 05 Mar 2009 08:24:36 -0600
Subject: [Rd] Two documentation questions
In-Reply-To: <alpine.LFD.2.00.0903050756500.22802@gannet.stats.ox.ac.uk>
References: <200903050138.n251c6qr006942@yacko.mayo.edu>
	<alpine.LFD.2.00.0903050756500.22802@gannet.stats.ox.ac.uk>
Message-ID: <49AFE0A4.9070703@mdacc.tmc.edu>



Prof Brian Ripley wrote:
> On Wed, 4 Mar 2009, Terry Therneau wrote:
> [SNIP]
>> 2. In the pdf for the survival package, or at least the one generated 
>> by R CMD check, the entries are in a random order.  Can I fix this?  
>> It makes reading the document to look for errors rather challenging.  
>> (That is, when I'm looking at a particular Rd file, and want to see 
>> what it turned out to be.)
>
> They should not be 'random'.  E.g. 
> http://cran.r-project.org/web/packages/survival/survival.pdf is not: 
> it is in alphabetical order (C locale), and that is what I see for R 
> CMD check in 2.8.1 (but in the collation order of the locale; this is 
> done by Perl so depends on what it thinks is appropriate).
>
> This is one of the things that is changing for R 2.9.0, and hence in 
> current R-devel.  R CMD check will always uses R CMD Rd2dvi, and that 
> produces PDF manuals in alphabetic order of the Rd files, in the 
> current locale (I think Rd2dvi was always in C collation in earlier 
> versions).
I think the key point here is "alphabetical order of the .Rd files".  If 
you do not choose the names of those files carefully, the PDF file 
produced by R CMD check may indeed appear to be random....
    -- Kevin
>
> R CMD check was more a check of the latex conversion of the files, not 
> a final manual (it got bundles wrong, for example, omitted the 
> DESCRIPTIOM and did not check that the index worked). R-devel it does 
> produce a standard package manual, and the collation is by R.
>
> Collation is a messy area with lots of OS-dependent errors.  That's 
> why in R-devel we have moved almost all this to R code, where we can 
> control it (and can replace the OS's collation services by ICU if 
> available).  And relevant to you is
>
>> sort(c("Surv", "surv", "survdiff"))
> [1] "surv"     "Surv"     "survdiff"
>
> which is what ICU thinks is right in English (and for one set of 
> English rules, it is -- further it allows you to tune them).
>


From therneau at mayo.edu  Thu Mar  5 16:10:04 2009
From: therneau at mayo.edu (therneau at mayo.edu)
Date: Thu,  5 Mar 2009 16:10:04 +0100 (CET)
Subject: [Rd] Typo in extensions manual (PR#13573)
Message-ID: <20090305151005.41CF2283218C@mail.pubhealth.ku.dk>

http://streaming.stat.iastate.edu/CRAN/
Writing R extensions
Online html version, 3/5/09

Section 1.6.6, second sentence
 "For instance, the stats package has..."

  From the context of sentences in the next paragraph I think it should say stats4. 

	Terry T.


From murdoch at stats.uwo.ca  Thu Mar  5 16:40:23 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 10:40:23 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
Message-ID: <49AFF267.2020608@stats.uwo.ca>

On 3/5/2009 7:10 AM, Prof Brian Ripley wrote:
> Undortunately the example is random, so not really reproducible (and I 
> see nothing wrong on my Mac). However, Linux valgrind on R-devel is 
> showing a problem:

I can reproduce it using y <- sin(x) instead of rnorm(100), on R-patched 
(not R-devel).


> 
> ==3973== Conditional jump or move depends on uninitialised value(s)
> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)

I don't see why there would be errors at those spots, but I did try 
tracing into loessf.f, and it's really a maze of code.  In case someone 
wants to follow up, it looks as though the ehg128 function returns a 
garbage value on the first call.  Working backwards through it, this is 
because the local variable s is garbage, because g(0,1) (an array, not a 
function call) is garbage at line 957, which is because it got set as 
garbage somewhere between being initialized at line 918, and line 957.
I think the problem happened at lines 950/951, but I didn't follow up to 
see why.


> 
> (The uninitiialized value is in someone else's code and I suspect it 
> was either never intended to work or never tested.)  No essential 
> change has been made to the loess code for many years.
> 
> I would not have read the documentation to say that degree = 0 was a 
> reasonable value. It is not to my mind 'a polynomial surface', and 
> loess() is described as a 'local regression' for degree 1 or 2 in 
> the reference.  So unless anyone wants to bury their heads in that 
> code I think a perfectly adequate fix would be to disallow degree = 0.
> (I vaguely recall debating allowing in the code ca 10 years ago.)

I agree that's the best solution.

Duncan Murdoch

> 
> On Thu, 5 Mar 2009, Uwe Ligges wrote:
> 
>> Berwin A Turlach wrote:
>>> G'day Peter,
>>> 
>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>> 
>>>> rhafen at stat.purdue.edu wrote:
>>>>> <<insert bug report here>>
>>>>> 
>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>> For example, try the following:
>>>>> 
>>>>> x <- 1:100
>>>>> y <- rnorm(100)
>>>>> plot(x, y)
>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>> 
>>>>> This is obviously wrong.
>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>> 
>>> Neither did I on linux; but the OP mentioned mac and windows. 
>>> On windows, on running that code, the lines() command added a lot of
>>> vertical lines; most spanning the complete window but some only part. 
>>> Executing the code a second time (or in steps) gave sensible
>>> results. 
>>> My guess would be that some memory is not correctly allocated or
>>> initialised.  Or is it something like an object with storage mode
>>> "integer" being passed to a double?  But then, why doesn't it show on
>>> linux?
>>> 
>>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>>> track down such things under windows.....
>>> 
>>> Cheers,
>>>
>>> 	Berwin
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> Please can you folks try under R-devel (to be R-2.9.0 in a couple of weeks) 
>> and report if you still see it. I do not under R-devel (but do under 
>> R-release), so my guess is that something called by loess() has been fixed in 
>> the meantime.
>>
>> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) but 
>> the loess computations.
>>
>> Uwe Ligges
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From murdoch at stats.uwo.ca  Thu Mar  5 17:03:26 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 11:03:26 -0500
Subject: [Rd] Firefox 3 and HTML Search
In-Reply-To: <496B442C.2030508@stats.uwo.ca>
References: <4967828C.3030408@stats.uwo.ca> <496B442C.2030508@stats.uwo.ca>
Message-ID: <49AFF7CE.3080904@stats.uwo.ca>

Firefox 3.0.7 has been released, and it fixes the bug described below.

Duncan Murdoch

On 1/12/2009 8:22 AM, Duncan Murdoch wrote:
> On 1/9/2009 11:59 AM, Duncan Murdoch wrote:
>> I finally upgraded to Firefox 3.05 from 2.x, and now I can reproduce a 
>> bug a colleague has been complaining about but which I hadn't been able 
>> to reproduce before.  In Windows, set Firefox as the default browser. 
>> Then in Rgui (seems to affect all versions up to R-devel), use the menu 
>> to open HTML Help, and choose "Search Engine and Keywords".
>> 
>> Enter a keyword (e.g. plot), and click on "Search".
>> 
>> Things are a lot slower than they used to be with Firefox 2, but 
>> eventually I get a result, starting out
>> 
>> Search Results
>> The search string was "plot"
>> 
>> base-defunct
>>      Defunct Functions in Base Package
>> expression
>>      Unevaluated Expressions
>> 
>> 
>> However, the current URL is not the same as it was before:  it is now 
>> listed as
>> 
>> file:///<RHOME>/doc/html/index.html
>> 
>> so the links don't work:  they are entered as 
>> "../../../library/base/html/base-defunct.html", etc. in the source, and 
>> the expect the current directory to be
>> 
>> file:///<RHOME>/doc/html/search/
>> 
>> If I set Internet Explorer as my default browser (yuck), things are 
>> fine, so this is a Firefox 3 bug, or a new Java bug, or an R bug that 
>> was masked before.
>> 
>> Any suggestions of workarounds?
> 
> As Brian and Marc pointed out, this is a Firefox 3.0 bug.  As it turns 
> out, it was repaired in November, but not approved for release in 3.0.5 
> or 3.0.6 (due this month??).  I've been told it will make it into 3.0.7.
> 
> For more on this, see
> 
> https://bugzilla.mozilla.org/show_bug.cgi?id=445004
> 
> Duncan Murdoch
>


From romain.francois at dbmail.com  Thu Mar  5 17:02:59 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 05 Mar 2009 17:02:59 +0100
Subject: [Rd] persistence of data
Message-ID: <49AFF7B3.9000807@dbmail.com>

Hello,

I am developing a package that needs data to persist between sessions of 
R (For example a sqlite database file, or simple dumps of R data with 
save/load). What I am using so far is :

file.path( Sys.getenv( "HOME"), ".R", "myPackage" )

but I was wondering if I am missing an "official" way to do this, 
similar to system.file does for installed packages. I am aware of the 
inst directory but this does not solve the problem in cases where the 
library is read only.

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Thu Mar  5 17:25:04 2009
From: savicky at cs.cas.cz (savicky at cs.cas.cz)
Date: Thu,  5 Mar 2009 17:25:04 +0100 (CET)
Subject: [Rd] Spearman's rank correlation test (PR#13574)
Message-ID: <20090305162504.70C6A2832191@mail.pubhealth.ku.dk>

Full_Name: Petr Savicky
Version: 2.7.2, 2.8.1, 2.9.0
OS: Linux
Submission from: (NULL) (147.231.6.9)


The p-value of Spearman's rank correlation test is calculated in
  cor.test(x, y, method="spearman")
using algorithm AS 89. However, the way how AS 89 is used incures error,
which may be an order of magnitude larger than the error of the original
algorithm.

The paper, which introduced AS 89, provides error bounds, which are larger
than the actual error. The reason may be, that current implementation of
AS 89 uses more acurate estimate of the distribution function of the normal
distribution. The error of the R implementation of cor.test() for positive
correlation and n = 11 is larger than this pessimistic upper bound.

The problem is discussed in more detail in R-devel postings
  https://stat.ethz.ch/pipermail/r-devel/2009-January/051936.html
  https://stat.ethz.ch/pipermail/r-devel/2009-February/052112.html

A patch correcting the problem in the current development version
  R version 2.9.0 Under development (unstable) (2009-03-03 r48046)
is as follows.

--- R-devel/src/library/stats/R/cor.test.R  2008-12-14 17:51:56.000000000 +0100
+++ R-cor.test/src/library/stats/R/cor.test.R   2009-03-05 10:39:07.383841736
+0100
@@ -151,9 +151,9 @@
                 pspearman <- function(q, n, lower.tail = TRUE) {
                     if(n <= 1290 && exact) # n*(n^2 - 1) does not overflow
                         .C("prho",
                            as.integer(n),
-                           as.double(round(q) + lower.tail),
+                           as.double(round(q) + 2*lower.tail),
                            p = double(1L),
                            integer(1L),
                            as.logical(lower.tail),
                            PACKAGE = "stats")$p


From jmc at r-project.org  Thu Mar  5 18:08:57 2009
From: jmc at r-project.org (John Chambers)
Date: Thu, 05 Mar 2009 09:08:57 -0800
Subject: [Rd] methods package
In-Reply-To: <200903050115.n251Frjs006726@yacko.mayo.edu>
References: <200903050115.n251Frjs006726@yacko.mayo.edu>
Message-ID: <49B00729.6040008@r-project.org>

Hi Terry,

Terry Therneau wrote:
>   I'm working on the next version of coxme, one step of which is converting
> the bdsmatrix library from Splus to R.  Actually, it is a conversion from
> S4 methods as first described in the Green book to S4 methods as they 
> currently exist.  Mostly it's going ok, but not entirely.
>
>   1. The biggest issue is lack of documentation.  The online help pages have
> not been a help; they keep saying it's "as found in the green book - almost".
> I've looked for the package on CRAN in the hopes for more there, but can't
> find it.  Perchance there is something obvious that I am missing?
>   
Well, one is that there is a 2008 book, "Software for Data Analysis", 
that I wrote partly to describe this and other topics from an R 
perspective.  It's a reference on most pages of documentation related to 
methods (in R version 2.8.1; you should be using that and/or the r-devel 
version if you're revising a package).

John

>   2. The changes are small but numerous.  The current one that has me puzzled
> is a method for addition:
>    setMethod(Ops, signature=c('numeric', 'bdsmatrix'), ....
>
> Let xmat be ordinary and bmat be a bdsmatrix.  In the old code "xmat + bmat"
> fell to this method (which knows what to do), in the current R I get
> failure due to no method found.  is.numeric(xmat) is TRUE.
>    What is the fix?
>
>  3. In the green book the examples used .Dim and .Dimnames slots, the Matrix
> library uses Dim and Dimnames.  Is there a good reason to choose one or the
> other?
>
>   I'll be out of town for the next few days (son's wedding) so instant response
> is not necessary.
>
> 	Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ligges at statistik.tu-dortmund.de  Thu Mar  5 19:25:10 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Thu,  5 Mar 2009 19:25:10 +0100 (CET)
Subject: [Rd] Bug in Rdconv(.pm) (PR#13575)
Message-ID: <20090305182510.B50602832191@mail.pubhealth.ku.dk>

For the record (and as privately discussed with Brian Ripley), happens 
with all recent versions of R including R-devel from today:


Consider a simple a.Rd file containing the lines

==================
\name{a}
\title{a}
\value{\code{a} \code{\link[a]{a}} \pkg{a}
    \item{a}{a}
}
==================


with these lines, I get, e.g.:



==================
R CMD Rdconv --type="txt" a.Rd

a                  package:unknown                  R Documentation

a

Value:

     'a' 'a' 'a'
Can't find Unicode property definition "k" at 
d:/Rcompile/recent/R/share/perl/R/Rdconv.pm line 2173,
<$rdfile> line 5.
==================

Version:
  platform = i386-pc-mingw32
  arch = i386
  os = mingw32
  system = i386, mingw32
  status = Under development (unstable)
  major = 2
  minor = 9.0
  year = 2009
  month = 03
  day = 03
  svn rev = 48046
  language = R
  version.string = R version 2.9.0 Under development (unstable) 
(2009-03-03 r48046)

Windows Server 2008 x64 (build 6001) Service Pack 1

Locale:
LC_COLLATE=C;LC_CTYPE=German_Germany.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=C

Search Path:
  .GlobalEnv, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:methods, Autoloads, package:base



Uwe Ligges


From therneau at mayo.edu  Thu Mar  5 19:29:29 2009
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 5 Mar 2009 12:29:29 -0600
Subject: [Rd] methods package
In-Reply-To: <49B00729.6040008@r-project.org>
Message-ID: <EDFDBF4E8E9AE049A9BB81801F493041271E4B@msgebe21.mfad.mfroot.org>

John,

> the 2008 book ...
 I suspected that I had overlooked something simple.  This fits the
bill.

> R 2.8.1
 I have been using 2.7.  I will update.

   Thanks for the help.

	Terry


From ripley at stats.ox.ac.uk  Thu Mar  5 19:53:16 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 18:53:16 +0000 (GMT)
Subject: [Rd] Bug in Rdconv(.pm) (PR#13575)
In-Reply-To: <20090305182510.B50602832191@mail.pubhealth.ku.dk>
References: <20090305182510.B50602832191@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903051850210.24770@gannet.stats.ox.ac.uk>

The problem is that \pkg gets included (unescaped) in a Perl 
substitution, and in modern Perl \p has a meaning (Unicode property).

Needs to be escaped/quoted, or the code to work a different way (which 
is probably preferable).

On Thu, 5 Mar 2009, ligges at statistik.tu-dortmund.de wrote:

> For the record (and as privately discussed with Brian Ripley), happens
> with all recent versions of R including R-devel from today:
>
>
> Consider a simple a.Rd file containing the lines
>
> ==================
> \name{a}
> \title{a}
> \value{\code{a} \code{\link[a]{a}} \pkg{a}
>    \item{a}{a}
> }
> ==================
>
>
> with these lines, I get, e.g.:
>
>
>
> ==================
> R CMD Rdconv --type="txt" a.Rd
>
> a                  package:unknown                  R Documentation
>
> a
>
> Value:
>
>     'a' 'a' 'a'
> Can't find Unicode property definition "k" at
> d:/Rcompile/recent/R/share/perl/R/Rdconv.pm line 2173,
> <$rdfile> line 5.
> ==================
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = Under development (unstable)
>  major = 2
>  minor = 9.0
>  year = 2009
>  month = 03
>  day = 03
>  svn rev = 48046
>  language = R
>  version.string = R version 2.9.0 Under development (unstable)
> (2009-03-03 r48046)
>
> Windows Server 2008 x64 (build 6001) Service Pack 1
>
> Locale:
> LC_COLLATE=C;LC_CTYPE=German_Germany.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=C
>
> Search Path:
>  .GlobalEnv, package:stats, package:graphics, package:grDevices,
> package:utils, package:datasets, package:methods, Autoloads, package:base
>
>
>
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  5 20:05:41 2009
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu,  5 Mar 2009 20:05:41 +0100 (CET)
Subject: [Rd] (PR#13553) wishlist boxplot
Message-ID: <20090305190541.D2E0C28321B0@mail.pubhealth.ku.dk>

No objections from Martin or elsewhere, so I have now committed this.

Thanks, Uwe.

On Tue, 24 Feb 2009, Uwe Ligges wrote:

> [CCing Martin and Brian who had both done most svn commits of boxplot.R so 
> far]
>
>
> A very minor wishlist item that I should have already reported years ago:
>
> All the time when I need presentation/publication quality boxplots, I add 
> par(lend=1) in my code in order to suppress the ugly median line that does 
> not stop at the end of the box given the rounded line endings.
>
> Ugly example:
>
> boxplot(1:10, lwd=30)
>
>
>
> I'd like the following very minor change for boxplots:
>
> D:\Rcompile\recent\R\src\library\graphics\R>diff -u boxplot.R boxplot-new.R
> --- boxplot.R   2009-02-24 18:04:47.265625000 +0100
> +++ boxplot-new.R       2009-02-24 18:10:02.000000000 +0100
> @@ -148,7 +148,7 @@
>         ## Median
>         xysegments(xP(x, -wntch), stats[3L],
>                xP(x, +wntch), stats[3L],
> -               lty = medlty[i], lwd = medlwd[i], col = medcol[i])
> +               lty = medlty[i], lwd = medlwd[i], col = medcol[i], lend=1)
>         xypoints(x, stats[3L],
>              pch = medpch[i], cex = medcex[i], col= medcol[i], bg = 
> medbg[i])
>         ## Whiskers
>
>
>
> Best wishes,
> Uwe Ligges
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  5 20:09:33 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Mar 2009 19:09:33 +0000 (GMT)
Subject: [Rd] heatmap without dendrogams (PR#13512)
In-Reply-To: <20090219180038.947CF2834155@mail.pubhealth.ku.dk>
References: <20090219180038.947CF2834155@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903051909090.24770@gannet.stats.ox.ac.uk>

Thanks Uwe, I've added your patch to R-devel (2.9.0 to be).

On Thu, 19 Feb 2009, ligges at statistik.tu-dortmund.de wrote:

>
>
> j.j.goeman at lumc.nl wrote:
>> Full_Name: Jelle Goeman
>> Version: 2.8.1
>> OS: Win XP
>> Submission from: (NULL) (87.212.67.197)
>>
>>
>> I get the following error message when I try to make a heatmap (package stats),
>> without the associated dendrograms.
>>
>> X <- matrix(rnorm(200),20,10)
>> XX <- crossprod(X)
>> heatmap(XX, Rowv= NA, revC=TRUE)
>> Error in rev(ddr) : object "ddr" not found
>> heatmap(XX, Rowv= NA, sym=TRUE)
>> Error in heatmap(XX, Rowv = NA, sym = TRUE) : object "ddr" not found
>>
>> According to the help file, this should work; indeed it does if I set revC or
>> sym to FALSE. Seems like ddr should be initialized to something like 1:ncol(X)
>> for the no-dendrogram case.
>>
>> Kind regards,
>>
>> Jelle
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> Since it looks like nobody answered so far, let me suggest a patch:
>
>
>
> D:\RCompile\recent\R\src\library\stats\R>diff -u  dendrogram.R
> dendrogram.R-new
> --- dendrogram.R        2009-02-19 18:54:18.832062400 +0100
> +++ dendrogram.R-new    2009-02-19 18:52:29.612961900 +0100
> @@ -699,7 +699,7 @@
>      x <- t(x)
>      if(revC) { # x columns reversed
>      iy <- nr:1
> -    ddr <- rev(ddr)
> +    if(doRdend) ddr <- rev(ddr)
>      x <- x[,iy]
>      } else iy <- 1L:nr
>
>
>
> Best wishes,
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Thu Mar  5 21:46:14 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 5 Mar 2009 14:46:14 -0600 (CST)
Subject: [Rd] Package issue
Message-ID: <200903052046.n25KkEJu003595@yacko.mayo.edu>

 I've converted the bdsmatrix package (used by coxme) to the newer style of
S4, and uploaded it.  It is in the pkg directory of survival, on r-forge.
I'm stuck on something that is almost certainly a namespace issue. I've 
borrowed liberally from Matrix (a big help) and read the documentation, and
just upgraded to 2.8.1 - but still stuck.

  All the tests work when I run them "by hand", but tests/gchol2.R fails 
when run from R CMD check.  The failure looks a lot like a method for
    setMethod('diag', 'gchol')
is not being found.  

 The NAMESPACE file exports diag, along with several other methods that
do work.  Any help would be appreciated. 

	Terry Therneau


From mark_difford at yahoo.co.uk  Thu Mar  5 13:36:44 2009
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 5 Mar 2009 04:36:44 -0800 (PST)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <20090305111537.12F232832198@mail.pubhealth.ku.dk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<20090305111537.12F232832198@mail.pubhealth.ku.dk>
Message-ID: <22350779.post@talk.nabble.com>


Hi Uwe,

This is not a problem under Vista, using "a" development version (mine now
somewhat outdated).

Regards, Mark.

sessionInfo()
R version 2.9.0 Under development (unstable) (2009-01-22 r47686) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_South Africa.1252;LC_CTYPE=English_South
Africa.1252;LC_MONETARY=English_South
Africa.1252;LC_NUMERIC=C;LC_TIME=English_South Africa.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods  
base     

other attached packages:
[1] ade4_1.4-10     Design_2.1-2    survival_2.34-1 Hmisc_3.5-2    

loaded via a namespace (and not attached):
[1] cluster_1.11.12    gamlss_1.9-4       grid_2.9.0         lattice_0.17-20   
latticeExtra_0.5-4
[6] MASS_7.2-45        tools_2.9.0 


Uwe Ligges-3 wrote:
> 
> Berwin A Turlach wrote:
>> G'day Peter,
>> 
>> On Thu, 05 Mar 2009 09:09:27 +0100
>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> 
>>> rhafen at stat.purdue.edu wrote:
>>>> <<insert bug report here>>
>>>>
>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>> For example, try the following:
>>>>
>>>> x <- 1:100
>>>> y <- rnorm(100)
>>>> plot(x, y)
>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>
>>>> This is obviously wrong.
>>> Obvious? How? I don't see anything particularly odd (on Linux).
>> 
>> Neither did I on linux; but the OP mentioned mac and windows. 
>> 
>> On windows, on running that code, the lines() command added a lot of
>> vertical lines; most spanning the complete window but some only part.  
>> 
>> Executing the code a second time (or in steps) gave sensible
>> results.  
>> 
>> My guess would be that some memory is not correctly allocated or
>> initialised.  Or is it something like an object with storage mode
>> "integer" being passed to a double?  But then, why doesn't it show on
>> linux?
>> 
>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>> track down such things under windows.....
>> 
>> Cheers,
>> 
>> 	Berwin
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
> weeks) and report if you still see it. I do not under R-devel (but do 
> under R-release), so my guess is that something called by loess() has 
> been fixed in the meantime.
> 
> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
> but the loess computations.
> 
> Uwe Ligges
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/bug-%28PR-13570%29-tp22346406p22350779.html
Sent from the R devel mailing list archive at Nabble.com.


From pfarina at mat.puc.cl  Thu Mar  5 15:55:04 2009
From: pfarina at mat.puc.cl (pfarina at mat.puc.cl)
Date: Thu,  5 Mar 2009 15:55:04 +0100 (CET)
Subject: [Rd] problem building a package with C code (PR#13572)
Message-ID: <20090305145505.2FC97283218F@mail.pubhealth.ku.dk>

Hi, my name is Paula. Im trying to learn how to build an R package in
Windows XP using a simple example which includes a C source code. The
foo.c file is located in mypkg/src/foo.c.

I used the command  Rcmd build --force --binary [pkgpath]. The problem is
when I install the zip file in R the function foo doesn?t exist.

The result a recieved during the building process is copied below.

I really appreciate some help....I very new on it and I have spent a lot
of time trying to solve the problem alone without success.

Thanks a lot

Paula Fari?a


C:\>cd C:\Archivos de programa\R\R-2.7.2\bin

C:\Archivos de programa\R\R-2.7.2\bin>Rcmd build --force --binary
D:\2009\c2r\my
pkg
* checking for file 'D:\2009\c2r\mypkg/DESCRIPTION' ... OK
* preparing 'D:\2009\c2r\mypkg':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source and make files
    file 'mypkg/src/foo.c' had non-LF line endings
* checking for empty or unneeded directories
* building binary distribution
WARNING: some HTML links may not be found
installing R.css in C:/DOCUME~1/Lir/CONFIG~1/Temp/Rinst96073413

Using auto-selected zip options ''

---------- Making package mypkg ------------
  adding build stamp to DESCRIPTION
  making DLL ...
making foo.d from foo.c
gcc  -std=gnu99  -Ic:/ARCHIV~1/R/R-27~1.2/include     -O3 -Wall  -c foo.c
-o foo
.o
windres --preprocessor="gcc -E -xc -DRC_INVOKED" -I
c:/ARCHIV~1/R/R-27~1.2/inclu
de  -i mypkg_res.rc -o mypkg_res.o
gcc  -std=gnu99  -shared -s  -o mypkg.dll mypkg.def foo.o mypkg_res.o 
-Lc:/ARCH
IV~1/R/R-27~1.2/bin    -lR
  ... DLL made
  installing DLL
  installing R files
  installing data files
  installing man source files
  installing indices
  not zipping data
  installing help
 >>> Building/Updating help pages for package 'mypkg'
     Formats: text html latex example chm
  d                                 text    html    latex   example chm
  e                                 text    html    latex   example chm
  f                                 text    html    latex   example chm
  g                                 text    html    latex   example chm
  mypkg-package                     text    html    latex   example chm
Microsoft HTML Help Compiler 4.74.8702

Compiling c:\DOCUME~1\Lir\CONFIG~1\Temp\Rbuild96033789\mypkg\chm\mypkg.chm


Compile time: 0 minutes, 2 seconds
6       Topics
11      Local links
0       Internet links
1       Graphic


Created c:\DOCUME~1\Lir\CONFIG~1\Temp\Rbuild96033789\mypkg\chm\mypkg.chm,
18,792
 bytes
Compression increased file by 2,040 bytes.
  adding MD5 sums

packaged installation of package 'mypkg' as mypkg_1.0.zip
* DONE (mypkg)


C:\Archivos de programa\R\R-2.7.2\bin>


From bpbryant at gmail.com  Thu Mar  5 18:29:05 2009
From: bpbryant at gmail.com (Ben Bryant)
Date: Thu, 5 Mar 2009 09:29:05 -0800
Subject: [Rd] Chunk of text won't show up when compiling Rd file
Message-ID: <885c6fdd0903050929l15fa3213t10969af2ae303761@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090305/74d0dedb/attachment.pl>

From ivowel at gmail.com  Thu Mar  5 15:22:04 2009
From: ivowel at gmail.com (ivo welch)
Date: Thu, 5 Mar 2009 09:22:04 -0500
Subject: [Rd] question
Message-ID: <50d1c22d0903050622s2f450835k3edeb8c7f8f4df01@mail.gmail.com>

dear R developers:  it is of course easy for a third party to make
suggestions if this third party is both clueless and does not put in
any work.  with these caveats, let me suggest something.

The syntax for returning multiple arguments does not strike me as
particularly appealing.  would it not possible to allow syntax like:

   f= function() { return( rnorm(10), rnorm(20) ) }
   (a,d$b) = f()

this would just hide the list conversion and unconversion.  yes, I
know how to accomplish this with lists, but it does not seem pretty or
natural.

regards,

/ivo


From rhafen at stat.purdue.edu  Thu Mar  5 15:42:57 2009
From: rhafen at stat.purdue.edu (Ryan Hafen)
Date: Thu, 5 Mar 2009 09:42:57 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
Message-ID: <E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>


On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:

> On Thu, 5 Mar 2009, Peter Dalgaard wrote:
>
>> Prof Brian Ripley wrote:
>>> Undortunately the example is random, so not really reproducible  
>>> (and I
>>> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
>>> showing a problem:
>>>
>>> ==3973== Conditional jump or move depends on uninitialised value(s)
>>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>>
>>> (The uninitiialized value is in someone else's code and I suspect  
>>> it was
>>> either never intended to work or never tested.)  No essential  
>>> change has
>>> been made to the loess code for many years.
>>>
>>> I would not have read the documentation to say that degree = 0 was a
>>> reasonable value. It is not to my mind 'a polynomial surface', and
>>> loess() is described as a 'local regression' for degree 1 or 2 in  
>>> the
>>> reference.  So unless anyone wants to bury their heads in that  
>>> code I
>>> think a perfectly adequate fix would be to disallow degree = 0.
>>> (I vaguely recall debating allowing in the code ca 10 years ago.)
>>
>> The code itself has
>>
>>   if (!match(degree, 0:2, 0))
>>       stop("'degree' must be 0, 1 or 2")
>>
>> though. "Local fitting of a constant" essentially becomes kernel
>> smoothing, right?
>
> I do know the R code allows it: the question is whether it is worth  
> the effort of finding the problem(s) in the underlying c/dloess  
> code, whose manual (and our reference) is entirely about 1 or 2.  I  
> am concerned that there may be other things lurking in the degree=0  
> case if it was never tested (in the netlib version: I am sure it was  
> only minmally tested through my R interface).
>
> I checked the original documentation on netlib and that says
>
> 29      DIM     dimension of local regression
>                1               constant
>                d+1             linear   (default)
>                (d+2)(d+1)/2    quadratic
>                Modified by ehg127 if cdeg<tdeg.
>
> which seems to confirm that degree = 0 was intended to be allowed,  
> and what I dimly recall from ca 1998 is debating whether the R code  
> should allow that or not.
>
> If left to me I would say I did not wish to continue to support  
> degree = 0.

True.  There are plenty of reasons why one wouldn't want to use  
degree=0 anyway.  And I'm sure there are plenty of other simple ways  
to achieve the same effect.

I ran into the problem because some code I'm planning on distributing  
as part of a paper submission "blends" partway down to degree 0  
smoothing at the endpoints to reduce the variance.  The only bad  
effect of disallowing degree 0 is for anyone with code depending on  
it, although there are probably few that use it and better to disallow  
than to give an incorrect computation.  I got around the problem by  
installing a modified loess by one of Cleveland's former students: https://centauri.stat.purdue.edu:98/loess/ 
  (but don't want to require others who use my code to do so as well).

What is very strange to me is that it has been working fine in  
previous R versions (tested on 2.7.1 and 2.6.1) and nothing has  
changed in the loess source but yet it is having problems on 2.8.1.   
Would this suggest it not being a problem with the netlib code?

Also strange that it reportedly works on Linux but not on Mac or  
Windows.  On the mac, the effect was much smaller. With windows, it  
was predicting values like 2e215 whereas on the mac, you would almost  
believe the results were legitimate if you didn't think about the fact  
that a weighted moving average involving half the data shouldn't  
oscillate so much.

If the consensus is to keep degree=0, I'd be happy to help try to find  
the problem or provide a test case or something.  Thanks for looking  
into this.

Ryan



>>
>>
>>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>>
>>>> Berwin A Turlach wrote:
>>>>> G'day Peter,
>>>>>
>>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>>
>>>>>> rhafen at stat.purdue.edu wrote:
>>>>>>> <<insert bug report here>>
>>>>>>>
>>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>>>> For example, try the following:
>>>>>>>
>>>>>>> x <- 1:100
>>>>>>> y <- rnorm(100)
>>>>>>> plot(x, y)
>>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>>
>>>>>>> This is obviously wrong.
>>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>>>
>>>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>>>> windows, on running that code, the lines() command added a lot of
>>>>> vertical lines; most spanning the complete window but some only  
>>>>> part.
>>>>> Executing the code a second time (or in steps) gave sensible
>>>>> results. My guess would be that some memory is not correctly
>>>>> allocated or
>>>>> initialised.  Or is it something like an object with storage mode
>>>>> "integer" being passed to a double?  But then, why doesn't it  
>>>>> show on
>>>>> linux?
>>>>>
>>>>> Happy bug hunting.  If my guess is correct, then I have no idea  
>>>>> how to
>>>>> track down such things under windows.....
>>>>>
>>>>> Cheers,
>>>>>
>>>>>    Berwin
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple  
>>>> of
>>>> weeks) and report if you still see it. I do not under R-devel  
>>>> (but do
>>>> under R-release), so my guess is that something called by loess()  
>>>> has
>>>> been fixed in the meantime.
>>>>
>>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>>> (release) but the loess computations.
>>>>
>>>> Uwe Ligges
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>>
>> --
>>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)  
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)  
>> 35327907
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Thu Mar  5 23:17:51 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 05 Mar 2009 23:17:51 +0100
Subject: [Rd] Package issue
In-Reply-To: <200903052046.n25KkEJu003595@yacko.mayo.edu>
References: <200903052046.n25KkEJu003595@yacko.mayo.edu>
Message-ID: <49B04F8F.3020501@statistik.tu-dortmund.de>

Terry,

1. R CMD build on your package reports at least two warnings for me.

2. R CMD check gives dozens of warnings even before the test cases where 
it already stops in gtest.R rather than anaything called gchol2.R.

3. There is no tests/gchol2.R  !!!

Perhaps you want to clean up some other issues or update the svn 
repository before you post again?

Best wishes,
Uwe



Terry Therneau wrote:
>  I've converted the bdsmatrix package (used by coxme) to the newer style of
> S4, and uploaded it.  It is in the pkg directory of survival, on r-forge.
> I'm stuck on something that is almost certainly a namespace issue. I've 
> borrowed liberally from Matrix (a big help) and read the documentation, and
> just upgraded to 2.8.1 - but still stuck.
> 
>   All the tests work when I run them "by hand", but tests/gchol2.R fails 
> when run from R CMD check.  The failure looks a lot like a method for
>     setMethod('diag', 'gchol')
> is not being found.  
> 
>  The NAMESPACE file exports diag, along with several other methods that
> do work.  Any help would be appreciated. 
> 
> 	Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Thu Mar  5 23:21:03 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 05 Mar 2009 23:21:03 +0100
Subject: [Rd] bug (PR#13570)
In-Reply-To: <22350779.post@talk.nabble.com>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<20090305111537.12F232832198@mail.pubhealth.ku.dk>
	<22350779.post@talk.nabble.com>
Message-ID: <49B0504F.8070400@statistik.tu-dortmund.de>



Mark Difford wrote:
> Hi Uwe,
> 
> This is not a problem under Vista, using "a" development version (mine now
> somewhat outdated).

Mark, as others have reported and debugged so far and you can see on the 
lists, the problem is more serious than I thought it is and it is 
probably also a problem under R-devel and here are just some nice lucky 
circumstances that we do not observe obvious miscalculations any more.

Best,
Uwe



> 
> Regards, Mark.
> 
> sessionInfo()
> R version 2.9.0 Under development (unstable) (2009-01-22 r47686) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_South Africa.1252;LC_CTYPE=English_South
> Africa.1252;LC_MONETARY=English_South
> Africa.1252;LC_NUMERIC=C;LC_TIME=English_South Africa.1252
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods  
> base     
> 
> other attached packages:
> [1] ade4_1.4-10     Design_2.1-2    survival_2.34-1 Hmisc_3.5-2    
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.11.12    gamlss_1.9-4       grid_2.9.0         lattice_0.17-20   
> latticeExtra_0.5-4
> [6] MASS_7.2-45        tools_2.9.0 
> 
> 
> Uwe Ligges-3 wrote:
>> Berwin A Turlach wrote:
>>> G'day Peter,
>>>
>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>
>>>> rhafen at stat.purdue.edu wrote:
>>>>> <<insert bug report here>>
>>>>>
>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>> For example, try the following:
>>>>>
>>>>> x <- 1:100
>>>>> y <- rnorm(100)
>>>>> plot(x, y)
>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>
>>>>> This is obviously wrong.
>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>> Neither did I on linux; but the OP mentioned mac and windows. 
>>>
>>> On windows, on running that code, the lines() command added a lot of
>>> vertical lines; most spanning the complete window but some only part.  
>>>
>>> Executing the code a second time (or in steps) gave sensible
>>> results.  
>>>
>>> My guess would be that some memory is not correctly allocated or
>>> initialised.  Or is it something like an object with storage mode
>>> "integer" being passed to a double?  But then, why doesn't it show on
>>> linux?
>>>
>>> Happy bug hunting.  If my guess is correct, then I have no idea how to
>>> track down such things under windows.....
>>>
>>> Cheers,
>>>
>>> 	Berwin
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> Please can you folks try under R-devel (to be R-2.9.0 in a couple of 
>> weeks) and report if you still see it. I do not under R-devel (but do 
>> under R-release), so my guess is that something called by loess() has 
>> been fixed in the meantime.
>>
>> Moreover it is not the plot stuff that was wrong under R-2.8.1 (release) 
>> but the loess computations.
>>
>> Uwe Ligges
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From ggrothendieck at gmail.com  Thu Mar  5 23:25:59 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 5 Mar 2009 17:25:59 -0500
Subject: [Rd] question
In-Reply-To: <50d1c22d0903050622s2f450835k3edeb8c7f8f4df01@mail.gmail.com>
References: <50d1c22d0903050622s2f450835k3edeb8c7f8f4df01@mail.gmail.com>
Message-ID: <971536df0903051425h31070a46h76fc666b35fc3d78@mail.gmail.com>

I posted this a few years ago (but found I never really had a
need for it):

http://tolstoy.newcastle.edu.au/R/help/04/06/1430.html



On Thu, Mar 5, 2009 at 9:22 AM, ivo welch <ivowel at gmail.com> wrote:
> dear R developers: ?it is of course easy for a third party to make
> suggestions if this third party is both clueless and does not put in
> any work. ?with these caveats, let me suggest something.
>
> The syntax for returning multiple arguments does not strike me as
> particularly appealing. ?would it not possible to allow syntax like:
>
> ? f= function() { return( rnorm(10), rnorm(20) ) }
> ? (a,d$b) = f()
>
> this would just hide the list conversion and unconversion. ?yes, I
> know how to accomplish this with lists, but it does not seem pretty or
> natural.
>
> regards,
>
> /ivo
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Greg.Snow at imail.org  Fri Mar  6 00:01:26 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 5 Mar 2009 16:01:26 -0700
Subject: [Rd] bug (PR#13570)
In-Reply-To: <E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>

I see the same problem on Windows XP.

But if I run loess with surface='direct' then the results are correct.  So it looks like the problem comes from the smoothing/interpolating, not the main loess algorithm.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Ryan Hafen
> Sent: Thursday, March 05, 2009 7:43 AM
> To: Prof Brian Ripley
> Cc: Uwe Ligges; Berwin A Turlach; r-devel at stat.math.ethz.ch; Peter
> Dalgaard
> Subject: Re: [Rd] bug (PR#13570)
> 
> 
> On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:
> 
> > On Thu, 5 Mar 2009, Peter Dalgaard wrote:
> >
> >> Prof Brian Ripley wrote:
> >>> Undortunately the example is random, so not really reproducible
> >>> (and I
> >>> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
> >>> showing a problem:
> >>>
> >>> ==3973== Conditional jump or move depends on uninitialised value(s)
> >>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
> >>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
> >>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
> >>>
> >>> (The uninitiialized value is in someone else's code and I suspect
> >>> it was
> >>> either never intended to work or never tested.)  No essential
> >>> change has
> >>> been made to the loess code for many years.
> >>>
> >>> I would not have read the documentation to say that degree = 0 was
> a
> >>> reasonable value. It is not to my mind 'a polynomial surface', and
> >>> loess() is described as a 'local regression' for degree 1 or 2 in
> >>> the
> >>> reference.  So unless anyone wants to bury their heads in that
> >>> code I
> >>> think a perfectly adequate fix would be to disallow degree = 0.
> >>> (I vaguely recall debating allowing in the code ca 10 years ago.)
> >>
> >> The code itself has
> >>
> >>   if (!match(degree, 0:2, 0))
> >>       stop("'degree' must be 0, 1 or 2")
> >>
> >> though. "Local fitting of a constant" essentially becomes kernel
> >> smoothing, right?
> >
> > I do know the R code allows it: the question is whether it is worth
> > the effort of finding the problem(s) in the underlying c/dloess
> > code, whose manual (and our reference) is entirely about 1 or 2.  I
> > am concerned that there may be other things lurking in the degree=0
> > case if it was never tested (in the netlib version: I am sure it was
> > only minmally tested through my R interface).
> >
> > I checked the original documentation on netlib and that says
> >
> > 29      DIM     dimension of local regression
> >                1               constant
> >                d+1             linear   (default)
> >                (d+2)(d+1)/2    quadratic
> >                Modified by ehg127 if cdeg<tdeg.
> >
> > which seems to confirm that degree = 0 was intended to be allowed,
> > and what I dimly recall from ca 1998 is debating whether the R code
> > should allow that or not.
> >
> > If left to me I would say I did not wish to continue to support
> > degree = 0.
> 
> True.  There are plenty of reasons why one wouldn't want to use
> degree=0 anyway.  And I'm sure there are plenty of other simple ways
> to achieve the same effect.
> 
> I ran into the problem because some code I'm planning on distributing
> as part of a paper submission "blends" partway down to degree 0
> smoothing at the endpoints to reduce the variance.  The only bad
> effect of disallowing degree 0 is for anyone with code depending on
> it, although there are probably few that use it and better to disallow
> than to give an incorrect computation.  I got around the problem by
> installing a modified loess by one of Cleveland's former students:
> https://centauri.stat.purdue.edu:98/loess/
>   (but don't want to require others who use my code to do so as well).
> 
> What is very strange to me is that it has been working fine in
> previous R versions (tested on 2.7.1 and 2.6.1) and nothing has
> changed in the loess source but yet it is having problems on 2.8.1.
> Would this suggest it not being a problem with the netlib code?
> 
> Also strange that it reportedly works on Linux but not on Mac or
> Windows.  On the mac, the effect was much smaller. With windows, it
> was predicting values like 2e215 whereas on the mac, you would almost
> believe the results were legitimate if you didn't think about the fact
> that a weighted moving average involving half the data shouldn't
> oscillate so much.
> 
> If the consensus is to keep degree=0, I'd be happy to help try to find
> the problem or provide a test case or something.  Thanks for looking
> into this.
> 
> Ryan
> 
> 
> 
> >>
> >>
> >>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
> >>>
> >>>> Berwin A Turlach wrote:
> >>>>> G'day Peter,
> >>>>>
> >>>>> On Thu, 05 Mar 2009 09:09:27 +0100
> >>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> >>>>>
> >>>>>> rhafen at stat.purdue.edu wrote:
> >>>>>>> <<insert bug report here>>
> >>>>>>>
> >>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for
> mac
> >>>>>>> and for windows.  The problem is with loess degree=0 smoothing.
> >>>>>>> For example, try the following:
> >>>>>>>
> >>>>>>> x <- 1:100
> >>>>>>> y <- rnorm(100)
> >>>>>>> plot(x, y)
> >>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
> >>>>>>>
> >>>>>>> This is obviously wrong.
> >>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
> >>>>>
> >>>>> Neither did I on linux; but the OP mentioned mac and windows. On
> >>>>> windows, on running that code, the lines() command added a lot of
> >>>>> vertical lines; most spanning the complete window but some only
> >>>>> part.
> >>>>> Executing the code a second time (or in steps) gave sensible
> >>>>> results. My guess would be that some memory is not correctly
> >>>>> allocated or
> >>>>> initialised.  Or is it something like an object with storage mode
> >>>>> "integer" being passed to a double?  But then, why doesn't it
> >>>>> show on
> >>>>> linux?
> >>>>>
> >>>>> Happy bug hunting.  If my guess is correct, then I have no idea
> >>>>> how to
> >>>>> track down such things under windows.....
> >>>>>
> >>>>> Cheers,
> >>>>>
> >>>>>    Berwin
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>>
> >>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple
> >>>> of
> >>>> weeks) and report if you still see it. I do not under R-devel
> >>>> (but do
> >>>> under R-release), so my guess is that something called by loess()
> >>>> has
> >>>> been fixed in the meantime.
> >>>>
> >>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
> >>>> (release) but the loess computations.
> >>>>
> >>>> Uwe Ligges
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>
> >>
> >> --
> >>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)
> >> 35327918
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)
> >> 35327907
> >>
> >>
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sgiannerini at gmail.com  Fri Mar  6 00:48:55 2009
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Fri, 6 Mar 2009 00:48:55 +0100
Subject: [Rd] quantile(), IQR() and median() for factors
Message-ID: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>

Dear all,

from the help page of quantile:

"x ??? numeric vectors whose sample quantiles are wanted. Missing
values are ignored."

from the help page of IQR:

"x ??? a numeric vector."

as a matter of facts it seems that both quantile() and IQR() do not
check for the presence of a numeric input.
See the following:

set.seed(11)
x <- rbinom(n=11,size=2,prob=.5)
x <- factor(x,ordered=TRUE)
x
?[1] 1 0 1 0 0 2 0 1 2 0 0
Levels: 0 < 1 < 2

> quantile(x)
? 0%? 25%? 50%? 75% 100%
?? 0 <NA>??? 0 <NA>??? 2
Levels: 0 < 1 < 2
Warning messages:
1: In Ops.ordered((1 - h), qs[i]) :
? '*' is not meaningful for ordered factors
2: In Ops.ordered(h, x[hi[i]]) : '*' is not meaningful for ordered factors

> IQR(x)
[1] 1

whereas median has the check:

> median(x)
Error in median.default(x) : need numeric data

I also take the opportunity to ask your comments on the following
related subject:

In my opinion it would be convenient that median() and the like
(quantile(), IQR()) be implemented for ordered factors for which in
fact
they can be well defined. For instance, in this way functions like
apply(x,FUN=median,...) could be used without the need of further
processing for
data frames that contain both numeric variables and ordered factors.
If on the one hand, to my limited knowledge, in English introductory
statistics
textbooks the fact that the median is well defined for ordered
categorical variables is only mentioned marginally,
on the other hand, in the Italian Statistics literature this is often
discussed in detail and this could mislead students and practitioners
that might
expect median() to work for ordered factors.

In this message

https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html

Martin Maechler considers the possibility of doing such a job by
allowing for extra arguments "low" and "high" as it is done for mad().
I am willing to give a contribution if requested, and comments are welcome.

Thank you for the attention,

kind regards,

Simone

> R.version
?????????????? _
platform?????? i386-pc-mingw32
arch?????????? i386
os???????????? mingw32
system???????? i386, mingw32
status
major????????? 2
minor????????? 8.1
year?????????? 2008
month????????? 12
day??????????? 22
svn rev??????? 47281
language?????? R
version.string R version 2.8.1 (2008-12-22)

?LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252

--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126 ?Bologna, ?ITALY
Tel: +39 051 2098262 ?Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From murdoch at stats.uwo.ca  Fri Mar  6 01:49:47 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 19:49:47 -0500
Subject: [Rd] Chunk of text won't show up when compiling Rd file
In-Reply-To: <885c6fdd0903050929l15fa3213t10969af2ae303761@mail.gmail.com>
References: <885c6fdd0903050929l15fa3213t10969af2ae303761@mail.gmail.com>
Message-ID: <49B0732B.70906@stats.uwo.ca>

On 05/03/2009 12:29 PM, Ben Bryant wrote:
> Greetings -
> 
> I am trying to document the "value" section of a function.  The function
> returns a list, but the list itself also has attributes.  I would like to
> itemize the list entries, and itemize the attributes, but in between I would
> like to have a sentence or two about the attributes in general.  However,
> for some reason this intermediate sentence won't show up in the compiled
> version, so that it appears the attributes are all just elements in the
> returned list.  Something is making the assumption that the itemized list
> must be uninterrupted, and I don't know the code to tell it not to do that.
> I presume it is a very easy fix, but I haven't been able to get at it.
> 
> I pasted some example explanatory Rd code below.
> 
> Thanks!
> -Ben Bryant

Could you give your example a try in R-devel, with one of the new 
conversion functions, e.g. tools::Rd2HTML?  I don't think these new 
functions are used by default even in R-devel, but if they solve your 
problem, there will be less motivation to fix the legacy functions.

Duncan Murdoch

> 
> 
> %%%%% Just the Value Section:
> 
> \value{
> Here I have a paragraph giving the general description of the output form.
> Then I have an itemized list describing the elements.
> 
>    \item{listobject1}{Description of list object 1}
>    \item{listobject2}{Description of list object 2}
>   %... etc
>    \item{lastlistobject}{Description of the last list object}
> 
> THEN, here I have a general description of the attributes, and the text
> represented by this sentence is what doesn't show up, because it's in
> between more of an itemized list.
> 
>    \item{attribute1}{details of attribute 1}
>    \item{attribute 2}{details of attribute 2}
> 
> Then I have text here, and this text does show up.
> }
> 
> %%%%
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri Mar  6 01:51:50 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 19:51:50 -0500
Subject: [Rd] problem building a package with C code (PR#13572)
In-Reply-To: <20090305145505.2FC97283218F@mail.pubhealth.ku.dk>
References: <20090305145505.2FC97283218F@mail.pubhealth.ku.dk>
Message-ID: <49B073A6.4060005@stats.uwo.ca>

On 05/03/2009 9:55 AM, pfarina at mat.puc.cl wrote:
> Hi, my name is Paula. Im trying to learn how to build an R package in
> Windows XP using a simple example which includes a C source code. The
> foo.c file is located in mypkg/src/foo.c.
> 
> I used the command  Rcmd build --force --binary [pkgpath]. The problem is
> when I install the zip file in R the function foo doesn?t exist.
> 
> The result a recieved during the building process is copied below.
> 
> I really appreciate some help....I very new on it and I have spent a lot
> of time trying to solve the problem alone without success.

I'd guess you didn't load the dll.  See my useR2008 talk for the steps 
needed to produce a package containing C code.  It looks as though 
you're close.

Duncan Murdoch

> 
> Thanks a lot
> 
> Paula Fari?a
> 
> 
> C:\>cd C:\Archivos de programa\R\R-2.7.2\bin
> 
> C:\Archivos de programa\R\R-2.7.2\bin>Rcmd build --force --binary
> D:\2009\c2r\my
> pkg
> * checking for file 'D:\2009\c2r\mypkg/DESCRIPTION' ... OK
> * preparing 'D:\2009\c2r\mypkg':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * removing junk files
> * checking for LF line-endings in source and make files
>     file 'mypkg/src/foo.c' had non-LF line endings
> * checking for empty or unneeded directories
> * building binary distribution
> WARNING: some HTML links may not be found
> installing R.css in C:/DOCUME~1/Lir/CONFIG~1/Temp/Rinst96073413
> 
> Using auto-selected zip options ''
> 
> ---------- Making package mypkg ------------
>   adding build stamp to DESCRIPTION
>   making DLL ...
> making foo.d from foo.c
> gcc  -std=gnu99  -Ic:/ARCHIV~1/R/R-27~1.2/include     -O3 -Wall  -c foo.c
> -o foo
> .o
> windres --preprocessor="gcc -E -xc -DRC_INVOKED" -I
> c:/ARCHIV~1/R/R-27~1.2/inclu
> de  -i mypkg_res.rc -o mypkg_res.o
> gcc  -std=gnu99  -shared -s  -o mypkg.dll mypkg.def foo.o mypkg_res.o 
> -Lc:/ARCH
> IV~1/R/R-27~1.2/bin    -lR
>   ... DLL made
>   installing DLL
>   installing R files
>   installing data files
>   installing man source files
>   installing indices
>   not zipping data
>   installing help
>  >>> Building/Updating help pages for package 'mypkg'
>      Formats: text html latex example chm
>   d                                 text    html    latex   example chm
>   e                                 text    html    latex   example chm
>   f                                 text    html    latex   example chm
>   g                                 text    html    latex   example chm
>   mypkg-package                     text    html    latex   example chm
> Microsoft HTML Help Compiler 4.74.8702
> 
> Compiling c:\DOCUME~1\Lir\CONFIG~1\Temp\Rbuild96033789\mypkg\chm\mypkg.chm
> 
> 
> Compile time: 0 minutes, 2 seconds
> 6       Topics
> 11      Local links
> 0       Internet links
> 1       Graphic
> 
> 
> Created c:\DOCUME~1\Lir\CONFIG~1\Temp\Rbuild96033789\mypkg\chm\mypkg.chm,
> 18,792
>  bytes
> Compression increased file by 2,040 bytes.
>   adding MD5 sums
> 
> packaged installation of package 'mypkg' as mypkg_1.0.zip
> * DONE (mypkg)
> 
> 
> C:\Archivos de programa\R\R-2.7.2\bin>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri Mar  6 02:09:57 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Mar 2009 20:09:57 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>	<49AFB412.2060807@statistik.tu-dortmund.de>	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>	<49AFC711.1030902@biostat.ku.dk>	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
Message-ID: <49B077E5.4010505@stats.uwo.ca>

On 05/03/2009 9:42 AM, Ryan Hafen wrote:
> On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:
> 
>> On Thu, 5 Mar 2009, Peter Dalgaard wrote:
>>
>>> Prof Brian Ripley wrote:
>>>> Undortunately the example is random, so not really reproducible  
>>>> (and I
>>>> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
>>>> showing a problem:
>>>>
>>>> ==3973== Conditional jump or move depends on uninitialised value(s)
>>>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>>>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>>>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>>>
>>>> (The uninitiialized value is in someone else's code and I suspect  
>>>> it was
>>>> either never intended to work or never tested.)  No essential  
>>>> change has
>>>> been made to the loess code for many years.
>>>>
>>>> I would not have read the documentation to say that degree = 0 was a
>>>> reasonable value. It is not to my mind 'a polynomial surface', and
>>>> loess() is described as a 'local regression' for degree 1 or 2 in  
>>>> the
>>>> reference.  So unless anyone wants to bury their heads in that  
>>>> code I
>>>> think a perfectly adequate fix would be to disallow degree = 0.
>>>> (I vaguely recall debating allowing in the code ca 10 years ago.)
>>> The code itself has
>>>
>>>   if (!match(degree, 0:2, 0))
>>>       stop("'degree' must be 0, 1 or 2")
>>>
>>> though. "Local fitting of a constant" essentially becomes kernel
>>> smoothing, right?
>> I do know the R code allows it: the question is whether it is worth  
>> the effort of finding the problem(s) in the underlying c/dloess  
>> code, whose manual (and our reference) is entirely about 1 or 2.  I  
>> am concerned that there may be other things lurking in the degree=0  
>> case if it was never tested (in the netlib version: I am sure it was  
>> only minmally tested through my R interface).
>>
>> I checked the original documentation on netlib and that says
>>
>> 29      DIM     dimension of local regression
>>                1               constant
>>                d+1             linear   (default)
>>                (d+2)(d+1)/2    quadratic
>>                Modified by ehg127 if cdeg<tdeg.
>>
>> which seems to confirm that degree = 0 was intended to be allowed,  
>> and what I dimly recall from ca 1998 is debating whether the R code  
>> should allow that or not.
>>
>> If left to me I would say I did not wish to continue to support  
>> degree = 0.
> 
> True.  There are plenty of reasons why one wouldn't want to use  
> degree=0 anyway.  And I'm sure there are plenty of other simple ways  
> to achieve the same effect.
> 
> I ran into the problem because some code I'm planning on distributing  
> as part of a paper submission "blends" partway down to degree 0  
> smoothing at the endpoints to reduce the variance.  The only bad  
> effect of disallowing degree 0 is for anyone with code depending on  
> it, although there are probably few that use it and better to disallow  
> than to give an incorrect computation.  I got around the problem by  
> installing a modified loess by one of Cleveland's former students: https://centauri.stat.purdue.edu:98/loess/ 
>   (but don't want to require others who use my code to do so as well).
> 
> What is very strange to me is that it has been working fine in  
> previous R versions (tested on 2.7.1 and 2.6.1) and nothing has  
> changed in the loess source but yet it is having problems on 2.8.1.   
> Would this suggest it not being a problem with the netlib code?
> 
> Also strange that it reportedly works on Linux but not on Mac or  
> Windows.  On the mac, the effect was much smaller. With windows, it  
> was predicting values like 2e215 whereas on the mac, you would almost  
> believe the results were legitimate if you didn't think about the fact  
> that a weighted moving average involving half the data shouldn't  
> oscillate so much.

I think it's pretty clear that it's using an uninitialized value.  On 
other systems (and previous versions) we've just been lucky, and those 
locations held values like 0.0 that didn't matter.

> If the consensus is to keep degree=0, I'd be happy to help try to find  
> the problem or provide a test case or something.  Thanks for looking  
> into this.

I'd say right now the consensus among R core members is that nobody 
wants to support degree=0, but if you're volunteering, the consensus 
could change.

Duncan Murdoch

> 
> Ryan
> 
> 
> 
>>>
>>>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>>>
>>>>> Berwin A Turlach wrote:
>>>>>> G'day Peter,
>>>>>>
>>>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>>>
>>>>>>> rhafen at stat.purdue.edu wrote:
>>>>>>>> <<insert bug report here>>
>>>>>>>>
>>>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for mac
>>>>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>>>>> For example, try the following:
>>>>>>>>
>>>>>>>> x <- 1:100
>>>>>>>> y <- rnorm(100)
>>>>>>>> plot(x, y)
>>>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>>>
>>>>>>>> This is obviously wrong.
>>>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>>>>> windows, on running that code, the lines() command added a lot of
>>>>>> vertical lines; most spanning the complete window but some only  
>>>>>> part.
>>>>>> Executing the code a second time (or in steps) gave sensible
>>>>>> results. My guess would be that some memory is not correctly
>>>>>> allocated or
>>>>>> initialised.  Or is it something like an object with storage mode
>>>>>> "integer" being passed to a double?  But then, why doesn't it  
>>>>>> show on
>>>>>> linux?
>>>>>>
>>>>>> Happy bug hunting.  If my guess is correct, then I have no idea  
>>>>>> how to
>>>>>> track down such things under windows.....
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>>    Berwin
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple  
>>>>> of
>>>>> weeks) and report if you still see it. I do not under R-devel  
>>>>> (but do
>>>>> under R-release), so my guess is that something called by loess()  
>>>>> has
>>>>> been fixed in the meantime.
>>>>>
>>>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>>>> (release) but the loess computations.
>>>>>
>>>>> Uwe Ligges
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>
>>> --
>>>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)  
>>> 35327918
>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)  
>>> 35327907
>>>
>>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhafen at stat.purdue.edu  Fri Mar  6 02:18:06 2009
From: rhafen at stat.purdue.edu (Ryan Hafen)
Date: Thu, 5 Mar 2009 20:18:06 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>

That is true - good point.

lp1 <- predict(loess(y ~ x, degree=0))
lp2 <- predict(loess(y ~ x, degree=0,  
control=loess.control(surface="direct")))
sort(abs(lp1-lp2))

It appears that the interpolating fit is correct at the vertices.  I  
know when degree>=1, the interpolation uses the slopes of the local  
fits to get a better approximation.  Perhaps it's still trying to do  
this with degree=0 but the slopes aren't available.  And we have just  
been lucky in the past with uninitialized values?  If this is the  
problem it would probably be very simple to fix and I'd love to see  
degree=0 stay.  I will see if I can figure it out.


On Mar 5, 2009, at 6:01 PM, Greg Snow wrote:

> I see the same problem on Windows XP.
>
> But if I run loess with surface='direct' then the results are  
> correct.  So it looks like the problem comes from the smoothing/ 
> interpolating, not the main loess algorithm.
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Ryan Hafen
>> Sent: Thursday, March 05, 2009 7:43 AM
>> To: Prof Brian Ripley
>> Cc: Uwe Ligges; Berwin A Turlach; r-devel at stat.math.ethz.ch; Peter
>> Dalgaard
>> Subject: Re: [Rd] bug (PR#13570)
>>
>>
>> On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:
>>
>>> On Thu, 5 Mar 2009, Peter Dalgaard wrote:
>>>
>>>> Prof Brian Ripley wrote:
>>>>> Undortunately the example is random, so not really reproducible
>>>>> (and I
>>>>> see nothing wrong on my Mac). However, Linux valgrind on R-devel  
>>>>> is
>>>>> showing a problem:
>>>>>
>>>>> ==3973== Conditional jump or move depends on uninitialised  
>>>>> value(s)
>>>>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>>>>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>>>>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>>>>
>>>>> (The uninitiialized value is in someone else's code and I suspect
>>>>> it was
>>>>> either never intended to work or never tested.)  No essential
>>>>> change has
>>>>> been made to the loess code for many years.
>>>>>
>>>>> I would not have read the documentation to say that degree = 0 was
>> a
>>>>> reasonable value. It is not to my mind 'a polynomial surface', and
>>>>> loess() is described as a 'local regression' for degree 1 or 2 in
>>>>> the
>>>>> reference.  So unless anyone wants to bury their heads in that
>>>>> code I
>>>>> think a perfectly adequate fix would be to disallow degree = 0.
>>>>> (I vaguely recall debating allowing in the code ca 10 years ago.)
>>>>
>>>> The code itself has
>>>>
>>>>  if (!match(degree, 0:2, 0))
>>>>      stop("'degree' must be 0, 1 or 2")
>>>>
>>>> though. "Local fitting of a constant" essentially becomes kernel
>>>> smoothing, right?
>>>
>>> I do know the R code allows it: the question is whether it is worth
>>> the effort of finding the problem(s) in the underlying c/dloess
>>> code, whose manual (and our reference) is entirely about 1 or 2.  I
>>> am concerned that there may be other things lurking in the degree=0
>>> case if it was never tested (in the netlib version: I am sure it was
>>> only minmally tested through my R interface).
>>>
>>> I checked the original documentation on netlib and that says
>>>
>>> 29      DIM     dimension of local regression
>>>               1               constant
>>>               d+1             linear   (default)
>>>               (d+2)(d+1)/2    quadratic
>>>               Modified by ehg127 if cdeg<tdeg.
>>>
>>> which seems to confirm that degree = 0 was intended to be allowed,
>>> and what I dimly recall from ca 1998 is debating whether the R code
>>> should allow that or not.
>>>
>>> If left to me I would say I did not wish to continue to support
>>> degree = 0.
>>
>> True.  There are plenty of reasons why one wouldn't want to use
>> degree=0 anyway.  And I'm sure there are plenty of other simple ways
>> to achieve the same effect.
>>
>> I ran into the problem because some code I'm planning on distributing
>> as part of a paper submission "blends" partway down to degree 0
>> smoothing at the endpoints to reduce the variance.  The only bad
>> effect of disallowing degree 0 is for anyone with code depending on
>> it, although there are probably few that use it and better to  
>> disallow
>> than to give an incorrect computation.  I got around the problem by
>> installing a modified loess by one of Cleveland's former students:
>> https://centauri.stat.purdue.edu:98/loess/
>>  (but don't want to require others who use my code to do so as well).
>>
>> What is very strange to me is that it has been working fine in
>> previous R versions (tested on 2.7.1 and 2.6.1) and nothing has
>> changed in the loess source but yet it is having problems on 2.8.1.
>> Would this suggest it not being a problem with the netlib code?
>>
>> Also strange that it reportedly works on Linux but not on Mac or
>> Windows.  On the mac, the effect was much smaller. With windows, it
>> was predicting values like 2e215 whereas on the mac, you would almost
>> believe the results were legitimate if you didn't think about the  
>> fact
>> that a weighted moving average involving half the data shouldn't
>> oscillate so much.
>>
>> If the consensus is to keep degree=0, I'd be happy to help try to  
>> find
>> the problem or provide a test case or something.  Thanks for looking
>> into this.
>>
>> Ryan
>>
>>
>>
>>>>
>>>>
>>>>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>>>>
>>>>>> Berwin A Turlach wrote:
>>>>>>> G'day Peter,
>>>>>>>
>>>>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>>>>
>>>>>>>> rhafen at stat.purdue.edu wrote:
>>>>>>>>> <<insert bug report here>>
>>>>>>>>>
>>>>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for
>> mac
>>>>>>>>> and for windows.  The problem is with loess degree=0  
>>>>>>>>> smoothing.
>>>>>>>>> For example, try the following:
>>>>>>>>>
>>>>>>>>> x <- 1:100
>>>>>>>>> y <- rnorm(100)
>>>>>>>>> plot(x, y)
>>>>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>>>>
>>>>>>>>> This is obviously wrong.
>>>>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>>>>>
>>>>>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>>>>>> windows, on running that code, the lines() command added a lot  
>>>>>>> of
>>>>>>> vertical lines; most spanning the complete window but some only
>>>>>>> part.
>>>>>>> Executing the code a second time (or in steps) gave sensible
>>>>>>> results. My guess would be that some memory is not correctly
>>>>>>> allocated or
>>>>>>> initialised.  Or is it something like an object with storage  
>>>>>>> mode
>>>>>>> "integer" being passed to a double?  But then, why doesn't it
>>>>>>> show on
>>>>>>> linux?
>>>>>>>
>>>>>>> Happy bug hunting.  If my guess is correct, then I have no idea
>>>>>>> how to
>>>>>>> track down such things under windows.....
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>>   Berwin
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>
>>>>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple
>>>>>> of
>>>>>> weeks) and report if you still see it. I do not under R-devel
>>>>>> (but do
>>>>>> under R-release), so my guess is that something called by loess()
>>>>>> has
>>>>>> been fixed in the meantime.
>>>>>>
>>>>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>>>>> (release) but the loess computations.
>>>>>>
>>>>>> Uwe Ligges
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)
>>>> 35327918
>>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)
>>>> 35327907
>>>>
>>>>
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From btyner at gmail.com  Fri Mar  6 02:24:21 2009
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 05 Mar 2009 20:24:21 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
Message-ID: <49B07B45.3040308@gmail.com>

Hi

Nice to hear from you Ryan. I also do not have the capability to debug 
on windows; however, there is a chance that the behavior you are seeing 
is caused by the following bug noted in my thesis (available on 
ProQuest; email me if you don't have access):

"When lambda = 0 there are no local slopes to aid the blending 
algorithm, yet the
interpolator would still assume they were available, and thus use 
arbitrary values
from memory. This had implications for both fit and tr[L] computation. 
In the
updated code these are set equal to zero which seems the best automatic 
rule when
lambda = 0." [lambda refers to degree]

I submitted a bug fix to Eric Grosse, the maintainer of the netlib 
routines; the fixed lines of fortran are identified in the comments at 
(just search for my email address):

http://www.netlib.org/a/loess

These fixes would be relatively simple to incorporate into R's version 
of loessf.f

Alternatively, a quick check would be for someone to compile the source 
package at https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz 
and test it on windows. Though this package incorporates this and a few 
other fixes, please be aware that it the routines are converted to C and 
thus there is a slight performance hit compared to the fortran.

Hope this helps,
Ben

Ryan Hafen wrote:
> That is true - good point.
>
> lp1 <- predict(loess(y ~ x, degree=0))
> lp2 <- predict(loess(y ~ x, degree=0, 
> control=loess.control(surface="direct")))
> sort(abs(lp1-lp2))
>
> It appears that the interpolating fit is correct at the vertices.  I 
> know when degree>=1, the interpolation uses the slopes of the local 
> fits to get a better approximation.  Perhaps it's still trying to do 
> this with degree=0 but the slopes aren't available.  And we have just 
> been lucky in the past with uninitialized values?  If this is the 
> problem it would probably be very simple to fix and I'd love to see 
> degree=0 stay.  I will see if I can figure it out.
>
>
> On Mar 5, 2009, at 6:01 PM, Greg Snow wrote:
>
>> I see the same problem on Windows XP.
>>
>> But if I run loess with surface='direct' then the results are 
>> correct.  So it looks like the problem comes from the 
>> smoothing/interpolating, not the main loess algorithm.
>>
>> -- 
>> Gregory (Greg) L. Snow Ph.D.
>> Statistical Data Center
>> Intermountain Healthcare
>> greg.snow at imail.org
>> 801.408.8111
>>
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>> project.org] On Behalf Of Ryan Hafen
>>> Sent: Thursday, March 05, 2009 7:43 AM
>>> To: Prof Brian Ripley
>>> Cc: Uwe Ligges; Berwin A Turlach; r-devel at stat.math.ethz.ch; Peter
>>> Dalgaard
>>> Subject: Re: [Rd] bug (PR#13570)
>>>
>>>
>>> On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:
>>>
>>>> On Thu, 5 Mar 2009, Peter Dalgaard wrote:
>>>>
>>>>> Prof Brian Ripley wrote:
>>>>>> Undortunately the example is random, so not really reproducible
>>>>>> (and I
>>>>>> see nothing wrong on my Mac). However, Linux valgrind on R-devel is
>>>>>> showing a problem:
>>>>>>
>>>>>> ==3973== Conditional jump or move depends on uninitialised value(s)
>>>>>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>>>>>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>>>>>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>>>>>
>>>>>> (The uninitiialized value is in someone else's code and I suspect
>>>>>> it was
>>>>>> either never intended to work or never tested.)  No essential
>>>>>> change has
>>>>>> been made to the loess code for many years.
>>>>>>
>>>>>> I would not have read the documentation to say that degree = 0 was
>>> a
>>>>>> reasonable value. It is not to my mind 'a polynomial surface', and
>>>>>> loess() is described as a 'local regression' for degree 1 or 2 in
>>>>>> the
>>>>>> reference.  So unless anyone wants to bury their heads in that
>>>>>> code I
>>>>>> think a perfectly adequate fix would be to disallow degree = 0.
>>>>>> (I vaguely recall debating allowing in the code ca 10 years ago.)
>>>>>
>>>>> The code itself has
>>>>>
>>>>>  if (!match(degree, 0:2, 0))
>>>>>      stop("'degree' must be 0, 1 or 2")
>>>>>
>>>>> though. "Local fitting of a constant" essentially becomes kernel
>>>>> smoothing, right?
>>>>
>>>> I do know the R code allows it: the question is whether it is worth
>>>> the effort of finding the problem(s) in the underlying c/dloess
>>>> code, whose manual (and our reference) is entirely about 1 or 2.  I
>>>> am concerned that there may be other things lurking in the degree=0
>>>> case if it was never tested (in the netlib version: I am sure it was
>>>> only minmally tested through my R interface).
>>>>
>>>> I checked the original documentation on netlib and that says
>>>>
>>>> 29      DIM     dimension of local regression
>>>>               1               constant
>>>>               d+1             linear   (default)
>>>>               (d+2)(d+1)/2    quadratic
>>>>               Modified by ehg127 if cdeg<tdeg.
>>>>
>>>> which seems to confirm that degree = 0 was intended to be allowed,
>>>> and what I dimly recall from ca 1998 is debating whether the R code
>>>> should allow that or not.
>>>>
>>>> If left to me I would say I did not wish to continue to support
>>>> degree = 0.
>>>
>>> True.  There are plenty of reasons why one wouldn't want to use
>>> degree=0 anyway.  And I'm sure there are plenty of other simple ways
>>> to achieve the same effect.
>>>
>>> I ran into the problem because some code I'm planning on distributing
>>> as part of a paper submission "blends" partway down to degree 0
>>> smoothing at the endpoints to reduce the variance.  The only bad
>>> effect of disallowing degree 0 is for anyone with code depending on
>>> it, although there are probably few that use it and better to disallow
>>> than to give an incorrect computation.  I got around the problem by
>>> installing a modified loess by one of Cleveland's former students:
>>> https://centauri.stat.purdue.edu:98/loess/
>>>  (but don't want to require others who use my code to do so as well).
>>>
>>> What is very strange to me is that it has been working fine in
>>> previous R versions (tested on 2.7.1 and 2.6.1) and nothing has
>>> changed in the loess source but yet it is having problems on 2.8.1.
>>> Would this suggest it not being a problem with the netlib code?
>>>
>>> Also strange that it reportedly works on Linux but not on Mac or
>>> Windows.  On the mac, the effect was much smaller. With windows, it
>>> was predicting values like 2e215 whereas on the mac, you would almost
>>> believe the results were legitimate if you didn't think about the fact
>>> that a weighted moving average involving half the data shouldn't
>>> oscillate so much.
>>>
>>> If the consensus is to keep degree=0, I'd be happy to help try to find
>>> the problem or provide a test case or something.  Thanks for looking
>>> into this.
>>>
>>> Ryan
>>>
>>>
>>>
>>>>>
>>>>>
>>>>>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>>>>>
>>>>>>> Berwin A Turlach wrote:
>>>>>>>> G'day Peter,
>>>>>>>>
>>>>>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>>>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>>>>>
>>>>>>>>> rhafen at stat.purdue.edu wrote:
>>>>>>>>>> <<insert bug report here>>
>>>>>>>>>>
>>>>>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for
>>> mac
>>>>>>>>>> and for windows.  The problem is with loess degree=0 smoothing.
>>>>>>>>>> For example, try the following:
>>>>>>>>>>
>>>>>>>>>> x <- 1:100
>>>>>>>>>> y <- rnorm(100)
>>>>>>>>>> plot(x, y)
>>>>>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>>>>>
>>>>>>>>>> This is obviously wrong.
>>>>>>>>> Obvious? How? I don't see anything particularly odd (on Linux).
>>>>>>>>
>>>>>>>> Neither did I on linux; but the OP mentioned mac and windows. On
>>>>>>>> windows, on running that code, the lines() command added a lot of
>>>>>>>> vertical lines; most spanning the complete window but some only
>>>>>>>> part.
>>>>>>>> Executing the code a second time (or in steps) gave sensible
>>>>>>>> results. My guess would be that some memory is not correctly
>>>>>>>> allocated or
>>>>>>>> initialised.  Or is it something like an object with storage mode
>>>>>>>> "integer" being passed to a double?  But then, why doesn't it
>>>>>>>> show on
>>>>>>>> linux?
>>>>>>>>
>>>>>>>> Happy bug hunting.  If my guess is correct, then I have no idea
>>>>>>>> how to
>>>>>>>> track down such things under windows.....
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>>   Berwin
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>>
>>>>>>> Please can you folks try under R-devel (to be R-2.9.0 in a couple
>>>>>>> of
>>>>>>> weeks) and report if you still see it. I do not under R-devel
>>>>>>> (but do
>>>>>>> under R-release), so my guess is that something called by loess()
>>>>>>> has
>>>>>>> been fixed in the meantime.
>>>>>>>
>>>>>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>>>>>> (release) but the loess computations.
>>>>>>>
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>>>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>>>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)
>>>>> 35327918
>>>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)
>>>>> 35327907
>>>>>
>>>>>
>>>>
>>>> -- 
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>



From rhafen at stat.purdue.edu  Fri Mar  6 02:29:36 2009
From: rhafen at stat.purdue.edu (Ryan Hafen)
Date: Thu, 5 Mar 2009 20:29:36 -0500
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49B07B45.3040308@gmail.com>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
	<49B07B45.3040308@gmail.com>
Message-ID: <CBBBAA85-F853-48C2-AAAD-C1DBBDC35442@stat.purdue.edu>

Excellent, Ben!  Thanks!!


On Mar 5, 2009, at 8:24 PM, Benjamin Tyner wrote:

> Hi
>
> Nice to hear from you Ryan. I also do not have the capability to  
> debug on windows; however, there is a chance that the behavior you  
> are seeing is caused by the following bug noted in my thesis  
> (available on ProQuest; email me if you don't have access):
>
> "When lambda = 0 there are no local slopes to aid the blending  
> algorithm, yet the
> interpolator would still assume they were available, and thus use  
> arbitrary values
> from memory. This had implications for both fit and tr[L]  
> computation. In the
> updated code these are set equal to zero which seems the best  
> automatic rule when
> lambda = 0." [lambda refers to degree]
>
> I submitted a bug fix to Eric Grosse, the maintainer of the netlib  
> routines; the fixed lines of fortran are identified in the comments  
> at (just search for my email address):
>
> http://www.netlib.org/a/loess
>
> These fixes would be relatively simple to incorporate into R's  
> version of loessf.f
>
> Alternatively, a quick check would be for someone to compile the  
> source package at https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz 
>  and test it on windows. Though this package incorporates this and a  
> few other fixes, please be aware that it the routines are converted  
> to C and thus there is a slight performance hit compared to the  
> fortran.
>
> Hope this helps,
> Ben
>
> Ryan Hafen wrote:
>> That is true - good point.
>>
>> lp1 <- predict(loess(y ~ x, degree=0))
>> lp2 <- predict(loess(y ~ x, degree=0,  
>> control=loess.control(surface="direct")))
>> sort(abs(lp1-lp2))
>>
>> It appears that the interpolating fit is correct at the vertices.   
>> I know when degree>=1, the interpolation uses the slopes of the  
>> local fits to get a better approximation.  Perhaps it's still  
>> trying to do this with degree=0 but the slopes aren't available.   
>> And we have just been lucky in the past with uninitialized values?   
>> If this is the problem it would probably be very simple to fix and  
>> I'd love to see degree=0 stay.  I will see if I can figure it out.
>>
>>
>> On Mar 5, 2009, at 6:01 PM, Greg Snow wrote:
>>
>>> I see the same problem on Windows XP.
>>>
>>> But if I run loess with surface='direct' then the results are  
>>> correct.  So it looks like the problem comes from the smoothing/ 
>>> interpolating, not the main loess algorithm.
>>>
>>> -- 
>>> Gregory (Greg) L. Snow Ph.D.
>>> Statistical Data Center
>>> Intermountain Healthcare
>>> greg.snow at imail.org
>>> 801.408.8111
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>> project.org] On Behalf Of Ryan Hafen
>>>> Sent: Thursday, March 05, 2009 7:43 AM
>>>> To: Prof Brian Ripley
>>>> Cc: Uwe Ligges; Berwin A Turlach; r-devel at stat.math.ethz.ch; Peter
>>>> Dalgaard
>>>> Subject: Re: [Rd] bug (PR#13570)
>>>>
>>>>
>>>> On Mar 5, 2009, at 7:59 AM, Prof Brian Ripley wrote:
>>>>
>>>>> On Thu, 5 Mar 2009, Peter Dalgaard wrote:
>>>>>
>>>>>> Prof Brian Ripley wrote:
>>>>>>> Undortunately the example is random, so not really reproducible
>>>>>>> (and I
>>>>>>> see nothing wrong on my Mac). However, Linux valgrind on R- 
>>>>>>> devel is
>>>>>>> showing a problem:
>>>>>>>
>>>>>>> ==3973== Conditional jump or move depends on uninitialised  
>>>>>>> value(s)
>>>>>>> ==3973==    at 0xD76017B: ehg141_ (loessf.f:532)
>>>>>>> ==3973==    by 0xD761600: lowesa_ (loessf.f:769)
>>>>>>> ==3973==    by 0xD736E47: loess_raw (loessc.c:117)
>>>>>>>
>>>>>>> (The uninitiialized value is in someone else's code and I  
>>>>>>> suspect
>>>>>>> it was
>>>>>>> either never intended to work or never tested.)  No essential
>>>>>>> change has
>>>>>>> been made to the loess code for many years.
>>>>>>>
>>>>>>> I would not have read the documentation to say that degree = 0  
>>>>>>> was
>>>> a
>>>>>>> reasonable value. It is not to my mind 'a polynomial surface',  
>>>>>>> and
>>>>>>> loess() is described as a 'local regression' for degree 1 or 2  
>>>>>>> in
>>>>>>> the
>>>>>>> reference.  So unless anyone wants to bury their heads in that
>>>>>>> code I
>>>>>>> think a perfectly adequate fix would be to disallow degree = 0.
>>>>>>> (I vaguely recall debating allowing in the code ca 10 years  
>>>>>>> ago.)
>>>>>>
>>>>>> The code itself has
>>>>>>
>>>>>> if (!match(degree, 0:2, 0))
>>>>>>     stop("'degree' must be 0, 1 or 2")
>>>>>>
>>>>>> though. "Local fitting of a constant" essentially becomes kernel
>>>>>> smoothing, right?
>>>>>
>>>>> I do know the R code allows it: the question is whether it is  
>>>>> worth
>>>>> the effort of finding the problem(s) in the underlying c/dloess
>>>>> code, whose manual (and our reference) is entirely about 1 or  
>>>>> 2.  I
>>>>> am concerned that there may be other things lurking in the  
>>>>> degree=0
>>>>> case if it was never tested (in the netlib version: I am sure it  
>>>>> was
>>>>> only minmally tested through my R interface).
>>>>>
>>>>> I checked the original documentation on netlib and that says
>>>>>
>>>>> 29      DIM     dimension of local regression
>>>>>              1               constant
>>>>>              d+1             linear   (default)
>>>>>              (d+2)(d+1)/2    quadratic
>>>>>              Modified by ehg127 if cdeg<tdeg.
>>>>>
>>>>> which seems to confirm that degree = 0 was intended to be allowed,
>>>>> and what I dimly recall from ca 1998 is debating whether the R  
>>>>> code
>>>>> should allow that or not.
>>>>>
>>>>> If left to me I would say I did not wish to continue to support
>>>>> degree = 0.
>>>>
>>>> True.  There are plenty of reasons why one wouldn't want to use
>>>> degree=0 anyway.  And I'm sure there are plenty of other simple  
>>>> ways
>>>> to achieve the same effect.
>>>>
>>>> I ran into the problem because some code I'm planning on  
>>>> distributing
>>>> as part of a paper submission "blends" partway down to degree 0
>>>> smoothing at the endpoints to reduce the variance.  The only bad
>>>> effect of disallowing degree 0 is for anyone with code depending on
>>>> it, although there are probably few that use it and better to  
>>>> disallow
>>>> than to give an incorrect computation.  I got around the problem by
>>>> installing a modified loess by one of Cleveland's former students:
>>>> https://centauri.stat.purdue.edu:98/loess/
>>>> (but don't want to require others who use my code to do so as  
>>>> well).
>>>>
>>>> What is very strange to me is that it has been working fine in
>>>> previous R versions (tested on 2.7.1 and 2.6.1) and nothing has
>>>> changed in the loess source but yet it is having problems on 2.8.1.
>>>> Would this suggest it not being a problem with the netlib code?
>>>>
>>>> Also strange that it reportedly works on Linux but not on Mac or
>>>> Windows.  On the mac, the effect was much smaller. With windows, it
>>>> was predicting values like 2e215 whereas on the mac, you would  
>>>> almost
>>>> believe the results were legitimate if you didn't think about the  
>>>> fact
>>>> that a weighted moving average involving half the data shouldn't
>>>> oscillate so much.
>>>>
>>>> If the consensus is to keep degree=0, I'd be happy to help try to  
>>>> find
>>>> the problem or provide a test case or something.  Thanks for  
>>>> looking
>>>> into this.
>>>>
>>>> Ryan
>>>>
>>>>
>>>>
>>>>>>
>>>>>>
>>>>>>> On Thu, 5 Mar 2009, Uwe Ligges wrote:
>>>>>>>
>>>>>>>> Berwin A Turlach wrote:
>>>>>>>>> G'day Peter,
>>>>>>>>>
>>>>>>>>> On Thu, 05 Mar 2009 09:09:27 +0100
>>>>>>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>>>>>>>
>>>>>>>>>> rhafen at stat.purdue.edu wrote:
>>>>>>>>>>> <<insert bug report here>>
>>>>>>>>>>>
>>>>>>>>>>> This is a CRITICAL bug!!!  I have verified it in R 2.8.1 for
>>>> mac
>>>>>>>>>>> and for windows.  The problem is with loess degree=0  
>>>>>>>>>>> smoothing.
>>>>>>>>>>> For example, try the following:
>>>>>>>>>>>
>>>>>>>>>>> x <- 1:100
>>>>>>>>>>> y <- rnorm(100)
>>>>>>>>>>> plot(x, y)
>>>>>>>>>>> lines(predict(loess(y ~ x, degree=0, span=0.5)))
>>>>>>>>>>>
>>>>>>>>>>> This is obviously wrong.
>>>>>>>>>> Obvious? How? I don't see anything particularly odd (on  
>>>>>>>>>> Linux).
>>>>>>>>>
>>>>>>>>> Neither did I on linux; but the OP mentioned mac and  
>>>>>>>>> windows. On
>>>>>>>>> windows, on running that code, the lines() command added a  
>>>>>>>>> lot of
>>>>>>>>> vertical lines; most spanning the complete window but some  
>>>>>>>>> only
>>>>>>>>> part.
>>>>>>>>> Executing the code a second time (or in steps) gave sensible
>>>>>>>>> results. My guess would be that some memory is not correctly
>>>>>>>>> allocated or
>>>>>>>>> initialised.  Or is it something like an object with storage  
>>>>>>>>> mode
>>>>>>>>> "integer" being passed to a double?  But then, why doesn't it
>>>>>>>>> show on
>>>>>>>>> linux?
>>>>>>>>>
>>>>>>>>> Happy bug hunting.  If my guess is correct, then I have no  
>>>>>>>>> idea
>>>>>>>>> how to
>>>>>>>>> track down such things under windows.....
>>>>>>>>>
>>>>>>>>> Cheers,
>>>>>>>>>
>>>>>>>>>  Berwin
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>
>>>>>>>>
>>>>>>>> Please can you folks try under R-devel (to be R-2.9.0 in a  
>>>>>>>> couple
>>>>>>>> of
>>>>>>>> weeks) and report if you still see it. I do not under R-devel
>>>>>>>> (but do
>>>>>>>> under R-release), so my guess is that something called by  
>>>>>>>> loess()
>>>>>>>> has
>>>>>>>> been fixed in the meantime.
>>>>>>>>
>>>>>>>> Moreover it is not the plot stuff that was wrong under R-2.8.1
>>>>>>>> (release) but the loess computations.
>>>>>>>>
>>>>>>>> Uwe Ligges
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>>>>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>>>>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)
>>>>>> 35327918
>>>>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)
>>>>>> 35327907
>>>>>>
>>>>>>
>>>>>
>>>>> -- 
>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


From bbuchsbaum at berkeley.edu  Fri Mar  6 03:16:40 2009
From: bbuchsbaum at berkeley.edu (Bradley Buchsbaum)
Date: Thu, 5 Mar 2009 21:16:40 -0500
Subject: [Rd] array subsetting of S4 object that inherits from "array"
Message-ID: <43ec92880903051816s2ff14f8oc8a34d8260caf80@mail.gmail.com>

Hi,

I have an S4 class that inherits from "array" but does not add generic
implementations of the "[" method.

A simplified example is:

setClass("fooarray", contains="array")

If I create a "fooarray" object and subset it with a one-dimensional
index vector, the return value is of class "fooarray". Other variants
(see below), however, return primitive values consistent with
"ordinary" array subsetting.

x <- new("fooarray", array(0,c(10,10,10)))

class(x[1,1,1])        # prints "numeric"
class(x[1,,])           # prints "matrix"
class(x[1])             #  prints "fooarray"
class(x[1:10])        #  prints "fooarray"


This behavior seems to have been introduced in R2.8.1 as I have not
encountered it before. I tested it on R.2.7.0 and confirmed that
class(x[1]) returned "numeric".

In my case, the desired behavior is for array subsetting in all cases
to return primitive data structures, so if there is a way to override
the new behavior I would opt for that.

Regards,

Brad Buchsbaum

R version 2.8.1 (2008-12-22)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



-- 
Bradley R. Buchsbaum
Rotman Research Institute
3560 Bathurst St.
Toronto, ON Canada M6A 2E1
email: bbuchsbaum at rotman-baycrest.on.ca


From ripley at stats.ox.ac.uk  Fri Mar  6 08:45:39 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Mar 2009 07:45:39 +0000 (GMT)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49B07B45.3040308@gmail.com>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
	<49B07B45.3040308@gmail.com>
Message-ID: <alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>

On Thu, 5 Mar 2009, Benjamin Tyner wrote:

> Hi
>
> Nice to hear from you Ryan. I also do not have the capability to debug on 
> windows; however, there is a chance that the behavior you are seeing is 
> caused by the following bug noted in my thesis (available on ProQuest; email 
> me if you don't have access):
>
> "When lambda = 0 there are no local slopes to aid the blending algorithm, yet 
> the
> interpolator would still assume they were available, and thus use arbitrary 
> values
> from memory. This had implications for both fit and tr[L] computation. In the
> updated code these are set equal to zero which seems the best automatic rule 
> when
> lambda = 0." [lambda refers to degree]
>
> I submitted a bug fix to Eric Grosse, the maintainer of the netlib routines; 
> the fixed lines of fortran are identified in the comments at (just search for 
> my email address):
>
> http://www.netlib.org/a/loess
>
> These fixes would be relatively simple to incorporate into R's version of 
> loessf.f

The fixes from dloess even more simply, since R's code is based on 
dloess.  Thank you for the suggestion.

Given how tricky this is to reproduce, I went back to my example under 
valgrind.  If I use the latest dloess code, it crashes, but by 
selectively importing some of the differences I can get it to work.

So it looks as if we are on the road to a solution, but something in 
the current version (not necessarily in these changes) is incompatible 
with the current R code and I need to dig further (not for a few 
days).

> Alternatively, a quick check would be for someone to compile the source 
> package at https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz and 
> test it on windows. Though this package incorporates this and a few other 
> fixes, please be aware that it the routines are converted to C and thus there 
> is a slight performance hit compared to the fortran.
>
> Hope this helps,
> Ben

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Mar  6 08:59:48 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 6 Mar 2009 08:59:48 +0100
Subject: [Rd] array subsetting of S4 object that inherits from "array"
In-Reply-To: <43ec92880903051816s2ff14f8oc8a34d8260caf80@mail.gmail.com>
References: <43ec92880903051816s2ff14f8oc8a34d8260caf80@mail.gmail.com>
Message-ID: <18864.55284.31829.871144@stat.math.ethz.ch>

>>>>> "BB" == Bradley Buchsbaum <bbuchsbaum at berkeley.edu>
>>>>>     on Thu, 5 Mar 2009 21:16:40 -0500 writes:

    BB> Hi,
    BB> I have an S4 class that inherits from "array" but does not add generic
    BB> implementations of the "[" method.

    BB> A simplified example is:

    BB> setClass("fooarray", contains="array")

    BB> If I create a "fooarray" object and subset it with a one-dimensional
    BB> index vector, the return value is of class "fooarray". Other variants
    BB> (see below), however, return primitive values consistent with
    BB> "ordinary" array subsetting.

    BB> x <- new("fooarray", array(0,c(10,10,10)))

    BB> class(x[1,1,1])        # prints "numeric"
    BB> class(x[1,,])           # prints "matrix"
    BB> class(x[1])             #  prints "fooarray"
    BB> class(x[1:10])        #  prints "fooarray"


    BB> This behavior seems to have been introduced in R2.8.1 as I have not
    BB> encountered it before. I tested it on R.2.7.0 and confirmed that
    BB> class(x[1]) returned "numeric".

    BB> In my case, the desired behavior is for array subsetting in all cases
    BB> to return primitive data structures, so if there is a way to override
    BB> the new behavior I would opt for that.

Yes,  the new behavior was introduced (into R 2.8.0) by me,
and ... coincidence ?! ...  two days ago, in e-talking with John
Chambers, I have been convinced, that the new feature really has
been a mis-feature.  Consequentley, yesterday (!) I'v committed
changes to both R-patched (2.8.1 patched) and R-devel which we
revert the mis-feature.

So, the override is to use  "2.8.1 patched" (or newer).

I'm sorry for my thinko that may also affect other
R-S4-programmers [of course I hope "not", but then there's
Murphy's law].

Regards,
Martin Maechler, ETH Zurich




    BB> Regards,

    BB> Brad Buchsbaum

    BB> R version 2.8.1 (2008-12-22)
    BB> i386-pc-mingw32

    BB> locale:
    BB> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
    BB> States.1252;LC_MONETARY=English_United
    BB> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

    BB> attached base packages:
    BB> [1] stats     graphics  grDevices utils     datasets  methods   base



    BB> -- 
    BB> Bradley R. Buchsbaum
    BB> Rotman Research Institute
    BB> 3560 Bathurst St.
    BB> Toronto, ON Canada M6A 2E1
    BB> email: bbuchsbaum at rotman-baycrest.on.ca

    BB> ______________________________________________
    BB> R-devel at r-project.org mailing list
    BB> https://stat.ethz.ch/mailman/listinfo/r-devel


From Manuel.Eugster at stat.uni-muenchen.de  Fri Mar  6 09:11:38 2009
From: Manuel.Eugster at stat.uni-muenchen.de (Manuel J. A. Eugster)
Date: Fri, 06 Mar 2009 09:11:38 +0100
Subject: [Rd] [SoC09-Info] Application starts next week.
Message-ID: <49B0DABA.8090202@stat.uni-muenchen.de>

Hi everybody,

next week is the week when mentoring organizations can
apply for the Google Summer of Code. As I already wrote
in my first mail, the idea is to submit our ideas by
March 10.

Currently three ideas are on the list[1]:

    * Development of crantastic.org
      by Hadley Wickham

    * Movement Ecology add-ons for adehabitat package
      by Damiano G. Preatoni

    * Party On! New Recursive Partytioning Tools
      by Torsten Hothorn and Achim Zeileis

Don't hesitate to chip in other ideas; the more ideas
are on the list the better it is for the application.

BTW: Do mentors whose projects weren't realized last
summer (see [2]) want to re-submit their projects?



Best,

Manuel.


[1] http://www.r-project.org/soc09
[2] http://www.r-project.org/soc08/ideas.html


From ml-it-r-devel at epigenomics.com  Fri Mar  6 13:55:00 2009
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Fri, 06 Mar 2009 13:55:00 +0100
Subject: [Rd] R 2.9.0 devel: package installation with configure-args
 option
In-Reply-To: <alpine.LFD.2.00.0903051359020.8287@gannet.stats.ox.ac.uk>
References: <gojlhg$i5g$1@perl.epigenomics.epi>
	<alpine.LFD.2.00.0903031737560.27426@gannet.stats.ox.ac.uk>
	<alpine.LFD.2.00.0903051359020.8287@gannet.stats.ox.ac.uk>
Message-ID: <49B11D24.4070105@epigenomics.com>

Prof Brian Ripley wrote:
> I think this should now work (one of several 'FIXME' issues addressed in
> the latest commit -- there are still some to go, but 2.9.0 is not due
> for 6 weeks).

tested and confirmed with R devel revision r48059;
more than one configure arguments are now handled correctly.

Thank you for the fix!

Regards, Matthias

> It is always useful to have a real test example, though.  (I used rgl in
> relation to some discussion about paths on r-sig-mac.)
> 
> On Tue, 3 Mar 2009, Prof Brian Ripley wrote:
> 
>> That version of R is 'under development' and the INSTALL file says
>>
>> ## FIXME: this loses quotes, so filepaths with spaces in get broken up
>>
>> so it is I think the same as a known issue.
>>
>> The whole package installation process has been completely
>> reconstructed for R-devel, and the process is not quite finished.
>> And this is a low priority as there are effective workarounds.
>>
>> On Tue, 3 Mar 2009, ml-it-r-devel at epigenomics.com wrote:
>>
>>>
>>> Hi,
>>>
>>> trying
>>> to install a package containing C code and requiring non-default
>>> configure argument
>>> settings the incantation (this has worked for R <= 2.8.1 on the same
>>> architectures)
>>>
>>> R CMD INSTALL --configure-args="--with-opt1 --with-opt2" packname
>>>
>>> does always result in a warning
>>> Warning: unknown option '--with-opt2'
>>>
>>> and consequently the option is ignored. Reverting the order of
>>> options results in the now
>>> last option to be ignored. Alternative quoting has not provided a
>>> solution.
>>>
>>> Using
>>>
>>> R CMD INSTALL --configure-args=--with-opt1
>>> --configure-args=--with-opt2 packname
>>>
>>> does provide a workaround, though. Is this the (new to me) and only
>>> intended way to
>>> provide more than one configure argument?
>>> I checked ?INSTALL and the referenced R-admin sec. 'Configuration
>>> variables' but still am
>>> not clear on this.
>>>
>>> Regards, Matthias
>>>
>>>
>>> R version 2.9.0 Under development (unstable) (2009-03-02 r48041)
>>> on Ubuntu 8.04, 8.10
>>>
>>> -- 
>>> Matthias Burger                     Project Manager/ Biostatistician
>>> Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
>>> phone:+49-30-24345-0                            fax:+49-30-24345-555
>>> http://www.epigenomics.com           matthias.burger at epigenomics.com
>>> -- 
>>> Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
>>> Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
>>>                                             Oliver Schacht PhD (CFO)
>>> Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
> 


-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-0                            fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
                                            Oliver Schacht PhD (CFO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From P.Dalgaard at biostat.ku.dk  Fri Mar  6 15:57:22 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 06 Mar 2009 15:57:22 +0100
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>	<49AF88B7.1000002@biostat.ku.dk>	<20090305174301.20099b11@berwin-nus1>	<49AFB412.2060807@statistik.tu-dortmund.de>	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>	<49AFC711.1030902@biostat.ku.dk>	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>	<49B07B45.3040308@gmail.com>
	<alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
Message-ID: <49B139D2.5060101@biostat.ku.dk>

Prof Brian Ripley wrote:
> On Thu, 5 Mar 2009, Benjamin Tyner wrote:
[...]
>>
>> I submitted a bug fix to Eric Grosse, the maintainer of the netlib
>> routines; the fixed lines of fortran are identified in the comments at
>> (just search for my email address):
>>
>> http://www.netlib.org/a/loess
>>
>> These fixes would be relatively simple to incorporate into R's version
>> of loessf.f
> 
> The fixes from dloess even more simply, since R's code is based on
> dloess.  Thank you for the suggestion.
> 
> Given how tricky this is to reproduce, I went back to my example under
> valgrind.  If I use the latest dloess code, it crashes, but by
> selectively importing some of the differences I can get it to work.
> 
> So it looks as if we are on the road to a solution, but something in the
> current version (not necessarily in these changes) is incompatible with
> the current R code and I need to dig further (not for a few days).

What a nice "war story" this is!

Good that it now seems fixable; even though degree=0 is not of much
practical use, it is the sort of thing people like to have available
when explaining how the method works.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From rmh at temple.edu  Fri Mar  6 16:55:04 2009
From: rmh at temple.edu (rmh at temple.edu)
Date: Fri,  6 Mar 2009 16:55:04 +0100 (CET)
Subject: [Rd] bug in summary.aovlist() with split= and (PR#13579)
Message-ID: <20090306155505.0ECCE282EFF0@mail.pubhealth.ku.dk>


-------62a8e378fd5c9332aae960888fd28459
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

# R for Windows will not send your bug report automatically.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs at r-project.org
#

######################################################


summary.aovlist() with split= and expand.split=TRUE
gives two different types of nonsensical results for a:b
in the Within stratum in the two different expansions of tmp3.aov.

S-Plus gives appropriate results and I attach them for comparison.
There are three attached files.
 split.r   source
 split.rt  R transcript showing nonsense results
 split.st  S-Plus transcript showing appropriate results

Rich


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 8.1
 year = 2008
 month = 12
 day = 22
 svn rev = 47281
 language = R
 version.string = R version 2.8.1 (2008-12-22)

Windows XP (build 2600) Service Pack 3

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:RcmdrPlugin.HH, package:Rcmdr, package:car, package:tcltk, package:fortunes, 
package:VGAM, package:stats4, package:splines, package:HH, package:leaps, package:multcomp, 
package:mvtnorm, package:grid, package:lattice, package:stats, package:graphics, package:datasets, 
package:grDevices, package:rcom, package:rscproxy, package:utils, package:methods, RExcelEnv, 
RcmdrEnv, Autoloads, package:base

-------62a8e378fd5c9332aae960888fd28459
Content-Type: text/plain;
	name="split.r"
Content-Disposition: inline;
	filename="split.r"
Content-Transfer-Encoding: quoted-printable

tmp <- data.frame(y=3Drnorm(48),
                  a=3Drep(letters[1:3]=
, 16),
                  b=3Drep(rep(LETTERS[1:4], each=3D3),4),
     =
             block=3Drep(LETTERS[5:6], each=3D24)
                  )
=

tmp.aov <- aov(y ~ a*b, data=3Dtmp)
summary(tmp.aov,
        split=3D=
list(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,x=3D3)),
        expan=
d.split=3DTRUE)

tmp2.aov <- aov(y ~ Error(block) + a*b, data=3Dtmp)
=
summary(tmp2.aov,
        split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(=
v=3D1,w=3D2,x=3D3)),
        expand.split=3DTRUE)
summary(tmp2.aov,
 =
       split=3Dlist(a=3Dlist(t=3D1,u=3D2)),
        expand.split=3DTRUE=
)

tmp3.aov <- aov(y ~ Error(block/a) + a*b, data=3Dtmp)
summary(tmp3=
.aov,
        split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,=
x=3D3)),
        expand.split=3DTRUE)
summary(tmp3.aov,
        split=
=3Dlist(a=3Dlist(t=3D1,u=3D2)),
        expand.split=3DTRUE)

-------62a8e378fd5c9332aae960888fd28459
Content-Type: text/plain;
	name="split.rt"
Content-Disposition: inline;
	filename="split.rt"
Content-Transfer-Encoding: quoted-printable

> tmp <- data.frame(y=3Drnorm(48),
+                   a=3Drep(letters[=
1:3], 16),
+                   b=3Drep(rep(LETTERS[1:4], each=3D3),4),
+                   block=3Drep(LETTERS[5:6], each=3D24)
+             =
      )
> =

> tmp.aov <- aov(y ~ a*b, data=3Dtmp)
> summary(tmp.aov,
+         spl=
it=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,x=3D3)),
+       =
  expand.split=3DTRUE)
            Df Sum Sq Mean Sq F value Pr(>F)
a =
           2  2.060   1.030  1.0528 0.3595
  a: t       1  1.411   1.41=
1  1.4416 0.2377
  a: u       1  0.650   0.650  0.6639 0.4205
b       =
     3  0.839   0.280  0.2859 0.8353
  b: v       1  0.264   0.264  0.2=
702 0.6063
  b: w       1  0.001   0.001  0.0013 0.9711
  b: x       1=
  0.573   0.573  0.5860 0.4489
a:b          6  2.300   0.383  0.3918 0.=
8794
  a:b: t.v   1  0.556   0.556  0.5685 0.4558
  a:b: u.v   1  0.99=
8   0.998  1.0203 0.3192
  a:b: t.w   1  0.171   0.171  0.1747 0.6785
=
  a:b: u.w   1  0.092   0.092  0.0942 0.7607
  a:b: t.x   1  0.361   0.=
361  0.3685 0.5476
  a:b: u.x   1  0.122   0.122  0.1246 0.7261
Residu=
als   36 35.226   0.978               =

> =

> tmp2.aov <- aov(y ~ Error(block) + a*b, data=3Dtmp)
> summary(tmp2.ao=
v,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,x=
=3D3)),
+         expand.split=3DTRUE)

Error: block
          Df  S=
um Sq Mean Sq F value Pr(>F)
Residuals  1 0.57849 0.57849              =
 =


Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
a         =
  2  2.060   1.030  1.0406 0.3639
  a: t      1  1.411   1.411  1.4250 =
0.2406
  a: u      1  0.650   0.650  0.6563 0.4234
b           3  0.83=
9   0.280  0.2826 0.8376
  b: v      1  0.264   0.264  0.2671 0.6085
 =
 b: w      1  0.001   0.001  0.0013 0.9713
  b: x      1  0.573   0.573=
  0.5793 0.4517
a:b         6  2.300   0.383  0.3873 0.8822
  a:b: t.v=
  1  0.556   0.556  0.5619 0.4585
  a:b: u.v  1  0.998   0.998  1.0085 =
0.3222
  a:b: t.w  1  0.171   0.171  0.1727 0.6803
  a:b: u.w  1  0.09=
2   0.092  0.0931 0.7621
  a:b: t.x  1  0.361   0.361  0.3642 0.5500
 =
 a:b: u.x  1  0.122   0.122  0.1232 0.7277
Residuals  35 34.647   0.990=
               =

> summary(tmp2.aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2)),
+  =
       expand.split=3DTRUE)

Error: block
          Df  Sum Sq Mean S=
q F value Pr(>F)
Residuals  1 0.57849 0.57849               =


Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
a          =
2  2.060   1.030  1.0406 0.3639
  a: t     1  1.411   1.411  1.4250 0.2=
406
  a: u     1  0.650   0.650  0.6563 0.4234
b          3  0.839   0=
.280  0.2826 0.8376
a:b        6  2.300   0.383  0.3873 0.8822
  a:b: =
t   3  1.088   0.363  0.3663 0.7777
  a:b: u   3  1.212   0.404  0.4082=
 0.7480
Residuals 35 34.647   0.990               =

> =

> tmp3.aov <- aov(y ~ Error(block/a) + a*b, data=3Dtmp)
> summary(tmp3.=
aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2=
,x=3D3)),
+         expand.split=3DTRUE)

Error: block
          Df =
 Sum Sq Mean Sq F value Pr(>F)
Residuals  1 0.57849 0.57849            =
   =


Error: block:a
          Df Sum Sq Mean Sq F value Pr(>F)
a         =
 2 2.0603  1.0301  0.4883 0.6719
  a: t     1 1.4106  1.4106  0.6686 0.=
4994
  a: u     1 0.6497  0.6497  0.3079 0.6347
Residuals  2 4.2194  2=
.1097               =


Error: Within
           Df  Sum Sq Mean Sq F value Pr(>F)
b        =
   3  0.8392  0.2797  0.3034 0.8227
  b: v      1  0.2644  0.2644  0.28=
68 0.5959
  b: w      1  0.0013  0.0013  0.0014 0.9703
  b: x      1  =
0.5734  0.5734  0.6219 0.4360
a:b         6  2.3002  0.3834  0.4158 0.8=
632
  a:b: t.v  1                               =

  a:b: u.v  1                               =

  a:b: t.w  1                               =

  a:b: u.w  1                               =

  a:b: t.x  1                               =

  a:b: u.x  1                               =

Residuals  33 30.4279  0.9221               =

> summary(tmp3.aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2)),
+  =
       expand.split=3DTRUE)

Error: block
          Df  Sum Sq Mean S=
q F value Pr(>F)
Residuals  1 0.57849 0.57849               =


Error: block:a
          Df Sum Sq Mean Sq F value Pr(>F)
a         =
 2 2.0603  1.0301  0.4883 0.6719
  a: t     1 1.4106  1.4106  0.6686 0.=
4994
  a: u     1 0.6497  0.6497  0.3079 0.6347
Residuals  2 4.2194  2=
.1097               =


Error: Within
          Df  Sum Sq Mean Sq F value Pr(>F)
b         =
 3  0.8392  0.2797  0.3034 0.8227
a:b        6  2.3002  0.3834  0.4158 =
0.8632
  a:b: t   0  0.0000                       =

  a:b: u   0  0.0000                       =

Residuals 33 30.4279  0.9221               =

> =

> version
               _                           =

platform       i386-pc-mingw32             =

arch           i386                        =

os             mingw32                     =

system         i386, mingw32               =

status                                     =

major          2                           =

minor          8.1                         =

year           2008                        =

month          12                          =

day            22                          =

svn rev        47281                       =

language       R                           =

version.string R version 2.8.1 (2008-12-22)
> =


-------62a8e378fd5c9332aae960888fd28459
Content-Type: text/plain;
	name="split.st"
Content-Disposition: inline;
	filename="split.st"
Content-Transfer-Encoding: quoted-printable

> tmp <- data.frame(y=3Drnorm(48),
+                   a=3Drep(letters[=
1:3], 16),
+                   b=3Drep(rep(LETTERS[1:4], each=3D3),4),
+                   block=3Drep(LETTERS[5:6], each=3D24)
+             =
      )
> =

> tmp.aov <- aov(y ~ a*b, data=3Dtmp)
> summary(tmp.aov,
+         spl=
it=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,x=3D3)),
+       =
  expand.split=3DTRUE)
           Df Sum of Sq  Mean Sq  F Value     Pr=
(F) =

         a  2   0.36016 0.180078 0.141799 0.8682780
      a: t  1   0.0=
3839 0.038393 0.030232 0.8629384
      a: u  1   0.32176 0.321762 0.253=
366 0.6177813
         b  3   4.96430 1.654765 1.303014 0.2883921
    =
  b: v  1   4.84859 4.848586 3.817929 0.0585102
      b: w  1   0.10289=
 0.102887 0.081017 0.7775555
      b: x  1   0.01282 0.012823 0.010097 =
0.9205175
       a:b  6   3.78177 0.630295 0.496314 0.8068076
  a:b: t=
.v  1   0.08038 0.080378 0.063292 0.8027964
  a:b: u.v  1   0.68080 0.6=
80800 0.536083 0.4688007
  a:b: t.w  1   2.29276 2.292763 1.805394 0.18=
74701
  a:b: u.w  1   0.47283 0.472829 0.372321 0.5455749
  a:b: t.x  =
1   0.10382 0.103815 0.081747 0.7765822
  a:b: u.x  1   0.15119 0.15118=
5 0.119048 0.7320772
 Residuals 36  45.71826 1.269952                  =
 =

> =

> tmp2.aov <- aov(y ~ Error(block) + a*b, data=3Dtmp)
> summary(tmp2.ao=
v,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2,x=
=3D3)),
+         expand.split=3DTRUE)
Error: block =

          Df  Sum of Sq    Mean Sq F Value Pr(F) =

Residuals  1 0.01256877 0.01256877              =


Error: Within =

           Df Sum of Sq  Mean Sq  F Value     Pr(F) =

         a  2   0.36016 0.180078 0.137898 0.8716586
      a: t  1   0.0=
3839 0.038393 0.029401 0.8648450
      a: u  1   0.32176 0.321762 0.246=
395 0.6227280
         b  3   4.96430 1.654765 1.267168 0.3006705
    =
  b: v  1   4.84859 4.848586 3.712896 0.0621432
      b: w  1   0.10289=
 0.102887 0.078788 0.7805996
      b: x  1   0.01282 0.012823 0.009819 =
0.9216304
       a:b  6   3.78177 0.630295 0.482660 0.8166555
  a:b: t=
.v  1   0.08038 0.080378 0.061551 0.8055105
  a:b: u.v  1   0.68080 0.6=
80800 0.521335 0.4750693
  a:b: t.w  1   2.29276 2.292763 1.755727 0.19=
37442
  a:b: u.w  1   0.47283 0.472829 0.362078 0.5512326
  a:b: t.x  =
1   0.10382 0.103815 0.079498 0.7796389
  a:b: u.x  1   0.15119 0.15118=
5 0.115773 0.7356989
 Residuals 35  45.70569 1.305877                  =
 =


> summary(tmp2.aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2)),
+=
         expand.split=3DTRUE)
Error: block =

          Df  Sum of Sq    Mean Sq F Value Pr(F) =

Residuals  1 0.01256877 0.01256877              =


Error: Within =

          Df Sum of Sq  Mean Sq  F Value     Pr(F) =

        a  2   0.36016 0.180078 0.137898 0.8716586
     a: t  1   0.038=
39 0.038393 0.029401 0.8648450
     a: u  1   0.32176 0.321762 0.246395=
 0.6227280
        b  3   4.96430 1.654765 1.267168 0.3006705
      a:=
b  6   3.78177 0.630295 0.482660 0.8166555
   a:b: t  3   2.47696 0.825=
652 0.632259 0.5991524
   a:b: u  3   1.30481 0.434938 0.333062 0.80147=
81
Residuals 35  45.70569 1.305877                   =


> =

> tmp3.aov <- aov(y ~ Error(block/a) + a*b, data=3Dtmp)
> summary(tmp3.=
aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2), b=3Dlist(v=3D1,w=3D2=
,x=3D3)),
+         expand.split=3DTRUE)
Error: block =

          Df  Sum of Sq    Mean Sq F Value Pr(F) =

Residuals  1 0.01256877 0.01256877              =


Error: a %in% block =

          Df Sum of Sq  Mean Sq   F Value     Pr(F) =

        a  2  0.360156 0.180078 0.0884982 0.9186970
     a: t  1  0.038=
393 0.038393 0.0188683 0.9033255
     a: u  1  0.321762 0.321762 0.1581=
281 0.7293139
Residuals  2  4.069638 2.034819                    =


Error: Within =

           Df Sum of Sq  Mean Sq  F Value     Pr(F) =

         b  3   4.96430 1.654765 1.311538 0.2871289
      b: v  1   4.8=
4859 4.848586 3.842903 0.0584446
      b: w  1   0.10289 0.102887 0.081=
546 0.7769973
      b: x  1   0.01282 0.012823 0.010163 0.9203096
    =
   a:b  6   3.78177 0.630295 0.499561 0.8040295
  a:b: t.v  1   0.08038=
 0.080378 0.063706 0.8022963
  a:b: u.v  1   0.68080 0.680800 0.539590 =
0.4677908
  a:b: t.w  1   2.29276 2.292763 1.817204 0.1868277
  a:b: u=
.w  1   0.47283 0.472829 0.374756 0.5446185
  a:b: t.x  1   0.10382 0.1=
03815 0.082282 0.7760218
  a:b: u.x  1   0.15119 0.151185 0.119827 0.73=
14199
 Residuals 33  41.63605 1.261699                   =


> summary(tmp3.aov,
+         split=3Dlist(a=3Dlist(t=3D1,u=3D2)),
+=
         expand.split=3DTRUE)
Error: block =

          Df  Sum of Sq    Mean Sq F Value Pr(F) =

Residuals  1 0.01256877 0.01256877              =


Error: a %in% block =

          Df Sum of Sq  Mean Sq   F Value     Pr(F) =

        a  2  0.360156 0.180078 0.0884982 0.9186970
     a: t  1  0.038=
393 0.038393 0.0188683 0.9033255
     a: u  1  0.321762 0.321762 0.1581=
281 0.7293139
Residuals  2  4.069638 2.034819                    =


Error: Within =

          Df Sum of Sq  Mean Sq  F Value     Pr(F) =

        b  3   4.96430 1.654765 1.311538 0.2871289
      a:b  6   3.781=
77 0.630295 0.499561 0.8040295
   a:b: t  3   2.47696 0.825652 0.654397=
 0.5859203
   a:b: u  3   1.30481 0.434938 0.344724 0.7931477
Residual=
s 33  41.63605 1.261699                   =


> version
TIBCO Spotfire S+ Version 8.1.1 for Microsoft Windows : 200=
8 =

> =


-------62a8e378fd5c9332aae960888fd28459--


From romain.francois at dbmail.com  Fri Mar  6 17:30:09 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 06 Mar 2009 17:30:09 +0100
Subject: [Rd] Bug in codetools ?
Message-ID: <49B14F91.4010608@dbmail.com>

Hello,

Is this a bug in codetools:

 > codetools::showTree( body( glm) )
("{" (<- call (match.call)) (if (is.character family) (<- family (get 
family "function" (parent.frame)))) (if (is.function family) (<- 
family(family))) (if (is.null ($ family family)) ("{" (print family) 
(stop "'family' not recognized"))) (if (missing data) (<- data 
(environment formula))) (<- mf (match.call FALSE)) (<- m (match (c 
"formula" "data" "subset" "weights" "na.action" "etastart" "mustart" 
"offset") (names mf) 0L)) (<- mf ([ mf (c 1 m))) (<- ($ mf 
drop.unused.levels) TRUE) (<- ([[ mf 1L) (as.name "model.frame")) (<- mf 
(eval mf (parent.frame))) (switch method (return mf) 1 (stop "invalid 
'method': " method)) (<- mt (attr mf "terms")) (<- Y (model.response mf 
"any")) (if (== (length (dim Y)) 1L) ("{" (<- nm (rownames Y)) (<- (dim 
Y) NULL) (if (! (is.null nm)) (<- (names Y) nm)))) (<- X (if (! 
(is.empty.model mt)) (model.matrix mtmf contrasts) (matrix Error in 
typeof(e) :
  element 1 is empty;
   the part of the args list of '.Internal' being evaluated was:
   (x)


The problem seems to happen because of the call to matrix with a missing 
argument in glm: matrix(, NROW(Y), 0L)

The fix is to rewrite showTreeCall like this :

showTreeCall <- function (e, w)
{
    w$write("(")
    walkCode(e[[1]], w)
    for (a in as.list(e[-1])) {
        if( !missing(a)){
                w$write(" ")
                walkCode(a, w)
        }
    }
    w$write(")")
}

 > version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          9.0
year           2009
month          03
day            03
svn rev        48044
language       R
version.string R version 2.9.0 Under development (unstable) (2009-03-03 
r48044)

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From Greg.Snow at imail.org  Fri Mar  6 18:05:18 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Fri, 6 Mar 2009 10:05:18 -0700
Subject: [Rd] quantile(), IQR() and median() for factors
In-Reply-To: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>
References: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034BF4@LP-EXMBVS10.CO.IHC.COM>

I like the idea of median and friends working on ordered factors.  Just a couple of thoughts on possible implementations.

Adding extra checks and functionality will slow down the function.  For a single evaluation on a given dataset this slowdown will not be noticeable, but inside of a simulation, bootstrap, or other high iteration technique, it could matter.  I would suggest creating a core function that does just the calculations (median, quantile, iqr) assuming that the data passed in is correct without doing any checks or anything fancy.  Then the user callable function (median et. al.) would do the checks dispatch to other functions for anything fancy, etc. then call the core function with the clean data.  The common user would not really notice a difference, but someone programming a high iteration technique could clean the data themselves, then call the core function directly bypassing the checks/branches.

Just out of curiosity (from someone who only learned from English (Americanized at that) and not Italian texts), what would the median of [Low, Low, Medium, High] be?

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Simone Giannerini
> Sent: Thursday, March 05, 2009 4:49 PM
> To: R-devel
> Subject: [Rd] quantile(), IQR() and median() for factors
> 
> Dear all,
> 
> from the help page of quantile:
> 
> "x ??? numeric vectors whose sample quantiles are wanted. Missing
> values are ignored."
> 
> from the help page of IQR:
> 
> "x ??? a numeric vector."
> 
> as a matter of facts it seems that both quantile() and IQR() do not
> check for the presence of a numeric input.
> See the following:
> 
> set.seed(11)
> x <- rbinom(n=11,size=2,prob=.5)
> x <- factor(x,ordered=TRUE)
> x
> ?[1] 1 0 1 0 0 2 0 1 2 0 0
> Levels: 0 < 1 < 2
> 
> > quantile(x)
> ? 0%? 25%? 50%? 75% 100%
> ?? 0 <NA>??? 0 <NA>??? 2
> Levels: 0 < 1 < 2
> Warning messages:
> 1: In Ops.ordered((1 - h), qs[i]) :
> ? '*' is not meaningful for ordered factors
> 2: In Ops.ordered(h, x[hi[i]]) : '*' is not meaningful for ordered
> factors
> 
> > IQR(x)
> [1] 1
> 
> whereas median has the check:
> 
> > median(x)
> Error in median.default(x) : need numeric data
> 
> I also take the opportunity to ask your comments on the following
> related subject:
> 
> In my opinion it would be convenient that median() and the like
> (quantile(), IQR()) be implemented for ordered factors for which in
> fact
> they can be well defined. For instance, in this way functions like
> apply(x,FUN=median,...) could be used without the need of further
> processing for
> data frames that contain both numeric variables and ordered factors.
> If on the one hand, to my limited knowledge, in English introductory
> statistics
> textbooks the fact that the median is well defined for ordered
> categorical variables is only mentioned marginally,
> on the other hand, in the Italian Statistics literature this is often
> discussed in detail and this could mislead students and practitioners
> that might
> expect median() to work for ordered factors.
> 
> In this message
> 
> https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html
> 
> Martin Maechler considers the possibility of doing such a job by
> allowing for extra arguments "low" and "high" as it is done for mad().
> I am willing to give a contribution if requested, and comments are
> welcome.
> 
> Thank you for the attention,
> 
> kind regards,
> 
> Simone
> 
> > R.version
> ?????????????? _
> platform?????? i386-pc-mingw32
> arch?????????? i386
> os???????????? mingw32
> system???????? i386, mingw32
> status
> major????????? 2
> minor????????? 8.1
> year?????????? 2008
> month????????? 12
> day??????????? 22
> svn rev??????? 47281
> language?????? R
> version.string R version 2.8.1 (2008-12-22)
> 
> ?LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=
> Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252
> 
> --
> ______________________________________________________
> 
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126 ?Bologna, ?ITALY
> Tel: +39 051 2098262 ?Fax: +39 051 232153
> http://www2.stat.unibo.it/giannerini/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Fri Mar  6 18:36:40 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Mar 2009 17:36:40 +0000 (GMT)
Subject: [Rd] quantile(), IQR() and median() for factors
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034BF4@LP-EXMBVS10.CO.IHC.COM>
References: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034BF4@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.00.0903061728110.8784@gannet.stats.ox.ac.uk>

On Fri, 6 Mar 2009, Greg Snow wrote:

> I like the idea of median and friends working on ordered factors. 
> Just a couple of thoughts on possible implementations.
>
> Adding extra checks and functionality will slow down the function. 
> For a single evaluation on a given dataset this slowdown will not be 
> noticeable, but inside of a simulation, bootstrap, or other high 
> iteration technique, it could matter.  I would suggest creating a 
> core function that does just the calculations (median, quantile, 
> iqr) assuming that the data passed in is correct without doing any 
> checks or anything fancy.  Then the user callable function (median 
> et. al.) would do the checks dispatch to other functions for 
> anything fancy, etc. then call the core function with the clean 
> data.  The common user would not really notice a difference, but 
> someone programming a high iteration technique could clean the data 
> themselves, then call the core function directly bypassing the 
> checks/branches.

Since median and quantile are already generic, adding a 'ordered' 
method would be zero cost to other uses.  And the factor check at the 
head of median.default could be replaced by median.factor if someone 
could show a convincing performance difference.

> Just out of curiosity (from someone who only learned from English 
> (Americanized at that) and not Italian texts), what would the median 
> of [Low, Low, Medium, High] be?

I don't think it is 'the' median but 'a' median.  (Even English 
Wikipedia says the median is not unique for even numbers of inputs.)

>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Simone Giannerini
>> Sent: Thursday, March 05, 2009 4:49 PM
>> To: R-devel
>> Subject: [Rd] quantile(), IQR() and median() for factors
>>
>> Dear all,
>>
>> from the help page of quantile:
>>
>> "x ??? numeric vectors whose sample quantiles are wanted. Missing
>> values are ignored."
>>
>> from the help page of IQR:
>>
>> "x ??? a numeric vector."
>>
>> as a matter of facts it seems that both quantile() and IQR() do not
>> check for the presence of a numeric input.
>> See the following:
>>
>> set.seed(11)
>> x <- rbinom(n=11,size=2,prob=.5)
>> x <- factor(x,ordered=TRUE)
>> x
>> ?[1] 1 0 1 0 0 2 0 1 2 0 0
>> Levels: 0 < 1 < 2
>>
>>> quantile(x)
>> ? 0%? 25%? 50%? 75% 100%
>> ?? 0 <NA>??? 0 <NA>??? 2
>> Levels: 0 < 1 < 2
>> Warning messages:
>> 1: In Ops.ordered((1 - h), qs[i]) :
>> ? '*' is not meaningful for ordered factors
>> 2: In Ops.ordered(h, x[hi[i]]) : '*' is not meaningful for ordered
>> factors
>>
>>> IQR(x)
>> [1] 1
>>
>> whereas median has the check:
>>
>>> median(x)
>> Error in median.default(x) : need numeric data
>>
>> I also take the opportunity to ask your comments on the following
>> related subject:
>>
>> In my opinion it would be convenient that median() and the like
>> (quantile(), IQR()) be implemented for ordered factors for which in
>> fact
>> they can be well defined. For instance, in this way functions like
>> apply(x,FUN=median,...) could be used without the need of further
>> processing for
>> data frames that contain both numeric variables and ordered factors.
>> If on the one hand, to my limited knowledge, in English introductory
>> statistics
>> textbooks the fact that the median is well defined for ordered
>> categorical variables is only mentioned marginally,
>> on the other hand, in the Italian Statistics literature this is often
>> discussed in detail and this could mislead students and practitioners
>> that might
>> expect median() to work for ordered factors.
>>
>> In this message
>>
>> https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html
>>
>> Martin Maechler considers the possibility of doing such a job by
>> allowing for extra arguments "low" and "high" as it is done for mad().
>> I am willing to give a contribution if requested, and comments are
>> welcome.
>>
>> Thank you for the attention,
>>
>> kind regards,
>>
>> Simone
>>
>>> R.version
>> ?????????????? _
>> platform?????? i386-pc-mingw32
>> arch?????????? i386
>> os???????????? mingw32
>> system???????? i386, mingw32
>> status
>> major????????? 2
>> minor????????? 8.1
>> year?????????? 2008
>> month????????? 12
>> day??????????? 22
>> svn rev??????? 47281
>> language?????? R
>> version.string R version 2.8.1 (2008-12-22)
>>
>> ?LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=
>> Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252
>>
>> --
>> ______________________________________________________
>>
>> Simone Giannerini
>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>> Universita' di Bologna
>> Via delle belle arti 41 - 40126 ?Bologna, ?ITALY
>> Tel: +39 051 2098262 ?Fax: +39 051 232153
>> http://www2.stat.unibo.it/giannerini/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sgiannerini at gmail.com  Fri Mar  6 22:07:36 2009
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Fri, 6 Mar 2009 22:07:36 +0100
Subject: [Rd] quantile(), IQR() and median() for factors
In-Reply-To: <alpine.LFD.2.00.0903061728110.8784@gannet.stats.ox.ac.uk>
References: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034BF4@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.00.0903061728110.8784@gannet.stats.ox.ac.uk>
Message-ID: <3c12769c0903061307s107608bctd403de1192ceaf9b@mail.gmail.com>

Dear Greg,

thank you for your comments,
as Prof. Ripley pointed out, in the case of even sample size the
median is not unique and is formed by the two central observations or
a function of them, if that makes sense.



Dear Prof. Ripley,

thank you for your concern,

may I notice that (in case of non-negative data) one can get the
median from mad() with center=0,constant=1


> mad(1:10,center=0,constant=1)
[1] 5.5
> mad(1:10,center=0,constant=1,high=TRUE)
[1] 6
> mad(1:10,center=0,constant=1,low=TRUE)
[1] 5

so that it seems that part of the code of mad() might be a starting
point, at least for median().
I confirm my availability to work on the matter if requested.

Kind regards,

Simone


On Fri, Mar 6, 2009 at 6:36 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Fri, 6 Mar 2009, Greg Snow wrote:
>
>> I like the idea of median and friends working on ordered factors. Just a
>> couple of thoughts on possible implementations.
>>
>> Adding extra checks and functionality will slow down the function. For a
>> single evaluation on a given dataset this slowdown will not be noticeable,
>> but inside of a simulation, bootstrap, or other high iteration technique, it
>> could matter. ?I would suggest creating a core function that does just the
>> calculations (median, quantile, iqr) assuming that the data passed in is
>> correct without doing any checks or anything fancy. ?Then the user callable
>> function (median et. al.) would do the checks dispatch to other functions
>> for anything fancy, etc. then call the core function with the clean data.
>> ?The common user would not really notice a difference, but someone
>> programming a high iteration technique could clean the data themselves, then
>> call the core function directly bypassing the checks/branches.
>
> Since median and quantile are already generic, adding a 'ordered' method
> would be zero cost to other uses. ?And the factor check at the head of
> median.default could be replaced by median.factor if someone could show a
> convincing performance difference.
>
>> Just out of curiosity (from someone who only learned from English
>> (Americanized at that) and not Italian texts), what would the median of
>> [Low, Low, Medium, High] be?
>
> I don't think it is 'the' median but 'a' median. ?(Even English Wikipedia
> says the median is not unique for even numbers of inputs.)
>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> Statistical Data Center
>> Intermountain Healthcare
>> greg.snow at imail.org
>> 801.408.8111
>>
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>> project.org] On Behalf Of Simone Giannerini
>>> Sent: Thursday, March 05, 2009 4:49 PM
>>> To: R-devel
>>> Subject: [Rd] quantile(), IQR() and median() for factors
>>>
>>> Dear all,
>>>
>>> from the help page of quantile:
>>>
>>> "x ??? numeric vectors whose sample quantiles are wanted. Missing
>>> values are ignored."
>>>
>>> from the help page of IQR:
>>>
>>> "x ??? a numeric vector."
>>>
>>> as a matter of facts it seems that both quantile() and IQR() do not
>>> check for the presence of a numeric input.
>>> See the following:
>>>
>>> set.seed(11)
>>> x <- rbinom(n=11,size=2,prob=.5)
>>> x <- factor(x,ordered=TRUE)
>>> x
>>> ?[1] 1 0 1 0 0 2 0 1 2 0 0
>>> Levels: 0 < 1 < 2
>>>
>>>> quantile(x)
>>>
>>> ? 0%? 25%? 50%? 75% 100%
>>> ?? 0 <NA>??? 0 <NA>??? 2
>>> Levels: 0 < 1 < 2
>>> Warning messages:
>>> 1: In Ops.ordered((1 - h), qs[i]) :
>>> ? '*' is not meaningful for ordered factors
>>> 2: In Ops.ordered(h, x[hi[i]]) : '*' is not meaningful for ordered
>>> factors
>>>
>>>> IQR(x)
>>>
>>> [1] 1
>>>
>>> whereas median has the check:
>>>
>>>> median(x)
>>>
>>> Error in median.default(x) : need numeric data
>>>
>>> I also take the opportunity to ask your comments on the following
>>> related subject:
>>>
>>> In my opinion it would be convenient that median() and the like
>>> (quantile(), IQR()) be implemented for ordered factors for which in
>>> fact
>>> they can be well defined. For instance, in this way functions like
>>> apply(x,FUN=median,...) could be used without the need of further
>>> processing for
>>> data frames that contain both numeric variables and ordered factors.
>>> If on the one hand, to my limited knowledge, in English introductory
>>> statistics
>>> textbooks the fact that the median is well defined for ordered
>>> categorical variables is only mentioned marginally,
>>> on the other hand, in the Italian Statistics literature this is often
>>> discussed in detail and this could mislead students and practitioners
>>> that might
>>> expect median() to work for ordered factors.
>>>
>>> In this message
>>>
>>> https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html
>>>
>>> Martin Maechler considers the possibility of doing such a job by
>>> allowing for extra arguments "low" and "high" as it is done for mad().
>>> I am willing to give a contribution if requested, and comments are
>>> welcome.
>>>
>>> Thank you for the attention,
>>>
>>> kind regards,
>>>
>>> Simone
>>>
>>>> R.version
>>>
>>> ?????????????? _
>>> platform?????? i386-pc-mingw32
>>> arch?????????? i386
>>> os???????????? mingw32
>>> system???????? i386, mingw32
>>> status
>>> major????????? 2
>>> minor????????? 8.1
>>> year?????????? 2008
>>> month????????? 12
>>> day??????????? 22
>>> svn rev??????? 47281
>>> language?????? R
>>> version.string R version 2.8.1 (2008-12-22)
>>>
>>> ?LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=
>>> Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252
>>>
>>> --
>>> ______________________________________________________
>>>
>>> Simone Giannerini
>>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>>> Universita' di Bologna
>>> Via delle belle arti 41 - 40126 ?Bologna, ?ITALY
>>> Tel: +39 051 2098262 ?Fax: +39 051 232153
>>> http://www2.stat.unibo.it/giannerini/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595



-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From Greg.Snow at imail.org  Fri Mar  6 22:14:30 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Fri, 6 Mar 2009 14:14:30 -0700
Subject: [Rd] quantile(), IQR() and median() for factors
In-Reply-To: <3c12769c0903061307s107608bctd403de1192ceaf9b@mail.gmail.com>
References: <3c12769c0903051548m22e58c0p27a980e939d42342@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034BF4@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.00.0903061728110.8784@gannet.stats.ox.ac.uk>
	<3c12769c0903061307s107608bctd403de1192ceaf9b@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034DAD@LP-EXMBVS10.CO.IHC.COM>

Yes I have discussed right continuous, left continous, etc. definitions for the median in numeric data.  I was just curious what the discussion was in texts that cover quantiles/medians of ordered categorical data in detail.

I do not expect Low.5 as computer output for the median (but Low.Medium does make sense in a way).  Back in my theory classes when we actually needed a firm definition I remember using the left continuous mainly (Low for the example), but I don't remember why we chose that over the right continuous version, probably just the teachers/books preference (I do remember it made things simpler than using the average of the middle 2 when n was even).

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: Simone Giannerini [mailto:sgiannerini at gmail.com]
> Sent: Friday, March 06, 2009 2:08 PM
> To: Prof Brian Ripley
> Cc: Greg Snow; R-devel
> Subject: Re: [Rd] quantile(), IQR() and median() for factors
> 
> Dear Greg,
> 
> thank you for your comments,
> as Prof. Ripley pointed out, in the case of even sample size the
> median is not unique and is formed by the two central observations or
> a function of them, if that makes sense.
> 
> 
> 
> Dear Prof. Ripley,
> 
> thank you for your concern,
> 
> may I notice that (in case of non-negative data) one can get the
> median from mad() with center=0,constant=1
> 
> 
> > mad(1:10,center=0,constant=1)
> [1] 5.5
> > mad(1:10,center=0,constant=1,high=TRUE)
> [1] 6
> > mad(1:10,center=0,constant=1,low=TRUE)
> [1] 5
> 
> so that it seems that part of the code of mad() might be a starting
> point, at least for median().
> I confirm my availability to work on the matter if requested.
> 
> Kind regards,
> 
> Simone
> 
> 
> On Fri, Mar 6, 2009 at 6:36 PM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
> > On Fri, 6 Mar 2009, Greg Snow wrote:
> >
> >> I like the idea of median and friends working on ordered factors.
> Just a
> >> couple of thoughts on possible implementations.
> >>
> >> Adding extra checks and functionality will slow down the function.
> For a
> >> single evaluation on a given dataset this slowdown will not be
> noticeable,
> >> but inside of a simulation, bootstrap, or other high iteration
> technique, it
> >> could matter. ?I would suggest creating a core function that does
> just the
> >> calculations (median, quantile, iqr) assuming that the data passed
> in is
> >> correct without doing any checks or anything fancy. ?Then the user
> callable
> >> function (median et. al.) would do the checks dispatch to other
> functions
> >> for anything fancy, etc. then call the core function with the clean
> data.
> >> ?The common user would not really notice a difference, but someone
> >> programming a high iteration technique could clean the data
> themselves, then
> >> call the core function directly bypassing the checks/branches.
> >
> > Since median and quantile are already generic, adding a 'ordered'
> method
> > would be zero cost to other uses. ?And the factor check at the head
> of
> > median.default could be replaced by median.factor if someone could
> show a
> > convincing performance difference.
> >
> >> Just out of curiosity (from someone who only learned from English
> >> (Americanized at that) and not Italian texts), what would the median
> of
> >> [Low, Low, Medium, High] be?
> >
> > I don't think it is 'the' median but 'a' median. ?(Even English
> Wikipedia
> > says the median is not unique for even numbers of inputs.)
> >
> >>
> >> --
> >> Gregory (Greg) L. Snow Ph.D.
> >> Statistical Data Center
> >> Intermountain Healthcare
> >> greg.snow at imail.org
> >> 801.408.8111
> >>
> >>
> >>> -----Original Message-----
> >>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> >>> project.org] On Behalf Of Simone Giannerini
> >>> Sent: Thursday, March 05, 2009 4:49 PM
> >>> To: R-devel
> >>> Subject: [Rd] quantile(), IQR() and median() for factors
> >>>
> >>> Dear all,
> >>>
> >>> from the help page of quantile:
> >>>
> >>> "x ??? numeric vectors whose sample quantiles are wanted. Missing
> >>> values are ignored."
> >>>
> >>> from the help page of IQR:
> >>>
> >>> "x ??? a numeric vector."
> >>>
> >>> as a matter of facts it seems that both quantile() and IQR() do not
> >>> check for the presence of a numeric input.
> >>> See the following:
> >>>
> >>> set.seed(11)
> >>> x <- rbinom(n=11,size=2,prob=.5)
> >>> x <- factor(x,ordered=TRUE)
> >>> x
> >>> ?[1] 1 0 1 0 0 2 0 1 2 0 0
> >>> Levels: 0 < 1 < 2
> >>>
> >>>> quantile(x)
> >>>
> >>> ? 0%? 25%? 50%? 75% 100%
> >>> ?? 0 <NA>??? 0 <NA>??? 2
> >>> Levels: 0 < 1 < 2
> >>> Warning messages:
> >>> 1: In Ops.ordered((1 - h), qs[i]) :
> >>> ? '*' is not meaningful for ordered factors
> >>> 2: In Ops.ordered(h, x[hi[i]]) : '*' is not meaningful for ordered
> >>> factors
> >>>
> >>>> IQR(x)
> >>>
> >>> [1] 1
> >>>
> >>> whereas median has the check:
> >>>
> >>>> median(x)
> >>>
> >>> Error in median.default(x) : need numeric data
> >>>
> >>> I also take the opportunity to ask your comments on the following
> >>> related subject:
> >>>
> >>> In my opinion it would be convenient that median() and the like
> >>> (quantile(), IQR()) be implemented for ordered factors for which in
> >>> fact
> >>> they can be well defined. For instance, in this way functions like
> >>> apply(x,FUN=median,...) could be used without the need of further
> >>> processing for
> >>> data frames that contain both numeric variables and ordered
> factors.
> >>> If on the one hand, to my limited knowledge, in English
> introductory
> >>> statistics
> >>> textbooks the fact that the median is well defined for ordered
> >>> categorical variables is only mentioned marginally,
> >>> on the other hand, in the Italian Statistics literature this is
> often
> >>> discussed in detail and this could mislead students and
> practitioners
> >>> that might
> >>> expect median() to work for ordered factors.
> >>>
> >>> In this message
> >>>
> >>> https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html
> >>>
> >>> Martin Maechler considers the possibility of doing such a job by
> >>> allowing for extra arguments "low" and "high" as it is done for
> mad().
> >>> I am willing to give a contribution if requested, and comments are
> >>> welcome.
> >>>
> >>> Thank you for the attention,
> >>>
> >>> kind regards,
> >>>
> >>> Simone
> >>>
> >>>> R.version
> >>>
> >>> ?????????????? _
> >>> platform?????? i386-pc-mingw32
> >>> arch?????????? i386
> >>> os???????????? mingw32
> >>> system???????? i386, mingw32
> >>> status
> >>> major????????? 2
> >>> minor????????? 8.1
> >>> year?????????? 2008
> >>> month????????? 12
> >>> day??????????? 22
> >>> svn rev??????? 47281
> >>> language?????? R
> >>> version.string R version 2.8.1 (2008-12-22)
> >>>
> >>>
> ?LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=
> >>> Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252
> >>>
> >>> --
> >>> ______________________________________________________
> >>>
> >>> Simone Giannerini
> >>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> >>> Universita' di Bologna
> >>> Via delle belle arti 41 - 40126 ?Bologna, ?ITALY
> >>> Tel: +39 051 2098262 ?Fax: +39 051 232153
> >>> http://www2.stat.unibo.it/giannerini/
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > --
> > Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> > 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> 
> 
> 
> --
> ______________________________________________________
> 
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126  Bologna,  ITALY
> Tel: +39 051 2098262  Fax: +39 051 232153
> http://www2.stat.unibo.it/giannerini/
> ______________________________________________________


From jmc at r-project.org  Fri Mar  6 23:12:00 2009
From: jmc at r-project.org (John Chambers)
Date: Fri, 06 Mar 2009 14:12:00 -0800
Subject: [Rd] S4 objects for S3 methods
Message-ID: <49B19FB0.9030606@r-project.org>

Some modifications have been committed for the r-devel version today 
that modify (essentially, correct a bug in) the communication of objects 
to an S3 method from an S4 class that extends the S3 class.

This is one of a sequence of changes designed to make S4 classes work 
more generally and consistently with S3 methods and classes.

In 2.8.0, support was provided for S4 classes that extend S3 classes, 
partly by making S3 method dispatch recognize the inheritance.

The catch was that the S3 method would get the S4 object.  Two problems 
with that:

1. The S3 method would fail if it tried to use the S3 class information 
directly, since the class attribute was the S4 class.

2. More seriously, if the method used the object, modified it and 
returned the result, it had a good chance of returning an invalid object 
seeming to come from the S4 class.

The modification to deal with this now delivers to the S3 method the 
inherited S3 object.  (This turned out to be somewhat harder than the 
original change, since it impacts several pieces of internal code.)  A 
revision of the function asS4() deals with similar concerns--see the 
documentation.

The change does not affect default methods.  It would be tempting to 
convert S4 objects for those, but some S3 generics attempt to deal with 
S4 objects, e.g., str().  A change to the primitives that dispatch 
methods is more plausible, but for the moment all that was added was 
more explicit error messages if a non-vector S4 object is supplied.

For more information see the section on inheriting from non-S4 classes 
in the documentation ?Classes.

It would be helpful if package maintainers would check this and previous 
changes by running their code against the r-devel version of R, before 
that becomes 2.9.0.  Please report any new errors (provided, of course, 
that the same code works with 2.8.1).

John


From jwlong at llnl.gov  Fri Mar  6 23:17:47 2009
From: jwlong at llnl.gov (Jeff Long)
Date: Fri, 6 Mar 2009 14:17:47 -0800
Subject: [Rd] Fix for foreign package segfault on Solaris 10 Intel
Message-ID: <p06230977c5d7517b8dc8@[134.9.94.26]>

Like a couple of other posters in the past year, I was seeing R 2.8.1 
segfault in the foreign package on my Solaris 10 Intel system:

       > library(foreign)

       *** caught segfault ***
       address fe1d5c70, cause 'invalid permissions'

       Traceback:
            1: .C("spss_init", PACKAGE = "foreign")
            2: fun(...)

This happened whether I built with gcc3, gcc4, or SunStudio 12.

Using pstack I found that the code was crashing in avl_create(). 
Using truss I found that identically named functions in the Solaris 
/lib/libavl.so.1 library were being used instead of the AVL functions 
provided in avl.c in the foreign package. To verify, I replaced all 
of the "avl_" and "AVL_" patterns in foreign/src/*.[ch] with "ravl_" 
and "RAVL_" respectively. Once I made this change, loading the 
foreign package caused no further problems.

An alternative workaround was a hack involving symlinks and 
LD_LIBRARY_PATH, but that was not satisfactory. Since the foreign avl 
functions are incompatible with the ones provided by the standard Sun 
library, this approach has other potential gotchas.

FYI.

Jeff


From ripley at stats.ox.ac.uk  Sat Mar  7 00:20:49 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Mar 2009 23:20:49 +0000 (GMT)
Subject: [Rd] Fix for foreign package segfault on Solaris 10 Intel
In-Reply-To: <p06230977c5d7517b8dc8@[134.9.94.26]>
References: <p06230977c5d7517b8dc8@[134.9.94.26]>
Message-ID: <alpine.OSX.1.00.0903062310220.68760@tystie.local>

Can you show us the output you get from building foreign, and explain 
how it comes to be linked against libavl?  I get (SunStudio 12)

cc -xc99 -G -L/opt/csw/lib -o foreign.so R_systat.o Rdbfread.o 
Rdbfwrite.o SASxport.o avl.o dbfopen.o file-handle.o format.o init.o 
minitab.o pfm-read.o sfm-read.o spss.o stataread.o

and ldd library/foreign/libs/foreign.so reveals no dependencies (and 
the R binary is not linked against libavl either).

I can see that linking against libavl could cause problems, but have 
no idea why that might be happening.


On Fri, 6 Mar 2009, Jeff Long wrote:

> Like a couple of other posters in the past year, I was seeing R 2.8.1 
> segfault in the foreign package on my Solaris 10 Intel system:
>
>      > library(foreign)
>
>      *** caught segfault ***
>      address fe1d5c70, cause 'invalid permissions'
>
>      Traceback:
>           1: .C("spss_init", PACKAGE = "foreign")
>           2: fun(...)
>
> This happened whether I built with gcc3, gcc4, or SunStudio 12.
>
> Using pstack I found that the code was crashing in avl_create(). Using truss 
> I found that identically named functions in the Solaris /lib/libavl.so.1 
> library were being used instead of the AVL functions provided in avl.c in the 
> foreign package. To verify, I replaced all of the "avl_" and "AVL_" patterns 
> in foreign/src/*.[ch] with "ravl_" and "RAVL_" respectively. Once I made this 
> change, loading the foreign package caused no further problems.
>
> An alternative workaround was a hack involving symlinks and LD_LIBRARY_PATH, 
> but that was not satisfactory. Since the foreign avl functions are 
> incompatible with the ones provided by the standard Sun library, this 
> approach has other potential gotchas.
>
> FYI.
>
> Jeff
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mark.Bravington at csiro.au  Sat Mar  7 01:43:51 2009
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Sat, 7 Mar 2009 11:43:51 +1100
Subject: [Rd] question
In-Reply-To: <971536df0903051425h31070a46h76fc666b35fc3d78@mail.gmail.com>
References: <50d1c22d0903050622s2f450835k3edeb8c7f8f4df01@mail.gmail.com>,
	<971536df0903051425h31070a46h76fc666b35fc3d78@mail.gmail.com>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F87051705E41B@exvic-mbx03.nexus.csiro.au>

[ivo welch wrote:]

> The syntax for returning multiple arguments does not strike me as
> particularly appealing.  would it not possible to allow syntax like:
>
>   f= function() { return( rnorm(10), rnorm(20) ) }
>   (a,d$b) = f()
>


FWIW, my own solution is to define a "multi-assign operator":

'%<-%' <- function( a, b){
  # a must be of the form '{thing1;thing2;...}'
  a <- as.list( substitute( a))[-1]
  e <- sys.parent()
  stopifnot( length( b) == length( a))
  for( i in seq_along( a))
    eval( call( '<-', a[[ i]], b[[i]]), envir=e)
  NULL
}

Then I can write 

{a;d$b} %<-% f()

Actually it should probably return b invisibly, so that it can be chained a la {c$e$f;g$h} %<-% {a;d$b} %<-% f()

I haven't checked it exhaustively but it has done the job OK for me.

The name '%<-%' does already feature in one R package, can't remember which but it's to do with graph theory, so you might be better off calling it something else. I use the synonym %:=% which is closer to what I think R should have called its assignment operator in the first place ;)

HTH

Mark Bravington
CSIRO
Hobart
Australia



________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Gabor Grothendieck [ggrothendieck at gmail.com]
Sent: 06 March 2009 09:25
To: ivo welch
Cc: r-devel at r-project.org
Subject: Re: [Rd] question

I posted this a few years ago (but found I never really had a
need for it):

http://tolstoy.newcastle.edu.au/R/help/04/06/1430.html



On Thu, Mar 5, 2009 at 9:22 AM, ivo welch <ivowel at gmail.com> wrote:
> dear R developers:  it is of course easy for a third party to make
> suggestions if this third party is both clueless and does not put in
> any work.  with these caveats, let me suggest something.
>
> The syntax for returning multiple arguments does not strike me as
> particularly appealing.  would it not possible to allow syntax like:
>
>   f= function() { return( rnorm(10), rnorm(20) ) }
>   (a,d$b) = f()
>
> this would just hide the list conversion and unconversion.  yes, I
> know how to accomplish this with lists, but it does not seem pretty or
> natural.
>
> regards,
>
> /ivo
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From jwlong at llnl.gov  Sat Mar  7 01:52:50 2009
From: jwlong at llnl.gov (Jeff Long)
Date: Fri, 6 Mar 2009 16:52:50 -0800
Subject: [Rd] Fix for foreign package segfault on Solaris 10 Intel
In-Reply-To: <alpine.OSX.1.00.0903062310220.68760@tystie.local>
References: <p06230977c5d7517b8dc8@[134.9.94.26]>
	<alpine.OSX.1.00.0903062310220.68760@tystie.local>
Message-ID: <p0623097cc5d770e2e9e9@[134.9.94.26]>

I built it several times with a variety of flags and compilers. 
Here's what was used for the gcc3 build:

/opt/csw/gcc3/bin/gcc -std=gnu99 -G -L/opt/sfw/lib -L/opt/csw/lib 
-L/opt/local/lib -L/usr/apps/cdat32/NetCDF/lib -o foreign.so avl.o 
dbfopen.o file-handle.o format.o init.o minitab.o pfm-read.o 
Rdbfread.o Rdbfwrite.o R_systat.o SASxport.o sfm-read.o spss.o 
stataread.o   -L/admin/users/jwlong/R/src/R-2.8.1/lib -lR

On my system, the main R shared library shows a dependency on libavl, 
and hence so does foreign.so and the R binary:

  % ldd R
         libR.so =>       /opt/local/lib/R/lib/libR.so
         libRblas.so =>   /opt/local/lib/R/lib/libRblas.so
         libc.so.1 =>     /lib/libc.so.1
         libg2c.so.0 =>   /opt/csw/lib/libg2c.so.0
         libm.so.2 =>     /lib/libm.so.2
         libintl.so.8 =>  /opt/csw/lib/libintl.so.8
         libreadline.so.4 =>      /opt/csw/lib/libreadline.so.4
         libncurses.so.5 =>       /opt/csw/lib/libncurses.so.5
         libnsl.so.1 =>   /lib/libnsl.so.1
         libsocket.so.1 =>        /lib/libsocket.so.1
         libdl.so.1 =>    /lib/libdl.so.1
         libiconv.so.2 =>         /opt/csw/lib/libiconv.so.2
         libm.so.1 =>     /lib/libm.so.1
         libgcc_s.so.1 =>         /opt/csw/lib/libgcc_s.so.1
         libsec.so.1 =>   /lib/libsec.so.1
         libmp.so.2 =>    /lib/libmp.so.2
         libmd.so.1 =>    /lib/libmd.so.1
         libscf.so.1 =>   /lib/libscf.so.1
         libavl.so.1 =>   /lib/libavl.so.1
         libdoor.so.1 =>  /lib/libdoor.so.1
         libuutil.so.1 =>         /lib/libuutil.so.1
         libgen.so.1 =>   /lib/libgen.so.1


Looking through these various shared libs, it looks like 
/lib/libsec.so.1 is the one that pulls in libavl. And libintl is what 
pulls in libsec. And R itself pulls in libintl.

Jeff


==========================================
At 11:20 PM +0000 3/6/09, Prof Brian Ripley wrote:
>Can you show us the output you get from building foreign, and 
>explain how it comes to be linked against libavl?  I get (SunStudio 
>12)
>
>cc -xc99 -G -L/opt/csw/lib -o foreign.so R_systat.o Rdbfread.o 
>Rdbfwrite.o SASxport.o avl.o dbfopen.o file-handle.o format.o init.o 
>minitab.o pfm-read.o sfm-read.o spss.o stataread.o
>
>and ldd library/foreign/libs/foreign.so reveals no dependencies (and 
>the R binary is not linked against libavl either).
>
>I can see that linking against libavl could cause problems, but have 
>no idea why that might be happening.
>
>
>On Fri, 6 Mar 2009, Jeff Long wrote:
>
>>Like a couple of other posters in the past year, I was seeing R 
>>2.8.1 segfault in the foreign package on my Solaris 10 Intel system:
>>
>>      > library(foreign)
>>
>>      *** caught segfault ***
>>      address fe1d5c70, cause 'invalid permissions'
>>
>>      Traceback:
>>           1: .C("spss_init", PACKAGE = "foreign")
>>           2: fun(...)
>>
>>This happened whether I built with gcc3, gcc4, or SunStudio 12.
>>
>>Using pstack I found that the code was crashing in avl_create(). 
>>Using truss I found that identically named functions in the Solaris 
>>/lib/libavl.so.1 library were being used instead of the AVL 
>>functions provided in avl.c in the foreign package. To verify, I 
>>replaced all of the "avl_" and "AVL_" patterns in 
>>foreign/src/*.[ch] with "ravl_" and "RAVL_" respectively. Once I 
>>made this change, loading the foreign package caused no further 
>>problems.
>>
>>An alternative workaround was a hack involving symlinks and 
>>LD_LIBRARY_PATH, but that was not satisfactory. Since the foreign 
>>avl functions are incompatible with the ones provided by the 
>>standard Sun library, this approach has other potential gotchas.
>>
>>FYI.
>>
>>Jeff
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https:// stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http:// www. stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Mar  7 08:25:17 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 7 Mar 2009 07:25:17 +0000 (GMT)
Subject: [Rd] Fix for foreign package segfault on Solaris 10 Intel
In-Reply-To: <p0623097cc5d770e2e9e9@[134.9.94.26]>
References: <p06230977c5d7517b8dc8@[134.9.94.26]>
	<alpine.OSX.1.00.0903062310220.68760@tystie.local>
	<p0623097cc5d770e2e9e9@[134.9.94.26]>
Message-ID: <alpine.LFD.2.00.0903070704530.14375@gannet.stats.ox.ac.uk>

Interesting, thanks.  So

1) This is a shared R library build (not the default, and AFAIR no one 
reporting this has mentioned that -- not you, for example) and

2) You have a third-party libintl.

One solution would seem to be to ask R to use the libintl in the 
sources by (I think) --with-included-gettext .

I'll look into modifying foreign, but the combination of 1) and 2) 
could apply to alomost any library on the system and hence any symbol 
name in any package.

It's odd that you have -L/usr/apps/cdat32/NetCDF/lib in there, another 
potential cause for problems.

On Fri, 6 Mar 2009, Jeff Long wrote:

> I built it several times with a variety of flags and compilers. Here's what 
> was used for the gcc3 build:
>
> /opt/csw/gcc3/bin/gcc -std=gnu99 -G -L/opt/sfw/lib -L/opt/csw/lib 
> -L/opt/local/lib -L/usr/apps/cdat32/NetCDF/lib -o foreign.so avl.o dbfopen.o 
> file-handle.o format.o init.o minitab.o pfm-read.o Rdbfread.o Rdbfwrite.o 
> R_systat.o SASxport.o sfm-read.o spss.o stataread.o 
> -L/admin/users/jwlong/R/src/R-2.8.1/lib -lR
>
> On my system, the main R shared library shows a dependency on libavl, and 
> hence so does foreign.so and the R binary:
>
> % ldd R
>        libR.so =>       /opt/local/lib/R/lib/libR.so
>        libRblas.so =>   /opt/local/lib/R/lib/libRblas.so
>        libc.so.1 =>     /lib/libc.so.1
>        libg2c.so.0 =>   /opt/csw/lib/libg2c.so.0
>        libm.so.2 =>     /lib/libm.so.2
>        libintl.so.8 =>  /opt/csw/lib/libintl.so.8
>        libreadline.so.4 =>      /opt/csw/lib/libreadline.so.4
>        libncurses.so.5 =>       /opt/csw/lib/libncurses.so.5
>        libnsl.so.1 =>   /lib/libnsl.so.1
>        libsocket.so.1 =>        /lib/libsocket.so.1
>        libdl.so.1 =>    /lib/libdl.so.1
>        libiconv.so.2 =>         /opt/csw/lib/libiconv.so.2
>        libm.so.1 =>     /lib/libm.so.1
>        libgcc_s.so.1 =>         /opt/csw/lib/libgcc_s.so.1
>        libsec.so.1 =>   /lib/libsec.so.1
>        libmp.so.2 =>    /lib/libmp.so.2
>        libmd.so.1 =>    /lib/libmd.so.1
>        libscf.so.1 =>   /lib/libscf.so.1
>        libavl.so.1 =>   /lib/libavl.so.1
>        libdoor.so.1 =>  /lib/libdoor.so.1
>        libuutil.so.1 =>         /lib/libuutil.so.1
>        libgen.so.1 =>   /lib/libgen.so.1
>
>
> Looking through these various shared libs, it looks like /lib/libsec.so.1 is 
> the one that pulls in libavl. And libintl is what pulls in libsec. And R 
> itself pulls in libintl.
>
> Jeff
>
>
> ==========================================
> At 11:20 PM +0000 3/6/09, Prof Brian Ripley wrote:
>> Can you show us the output you get from building foreign, and explain how 
>> it comes to be linked against libavl?  I get (SunStudio 12)
>> 
>> cc -xc99 -G -L/opt/csw/lib -o foreign.so R_systat.o Rdbfread.o Rdbfwrite.o 
>> SASxport.o avl.o dbfopen.o file-handle.o format.o init.o minitab.o 
>> pfm-read.o sfm-read.o spss.o stataread.o
>> 
>> and ldd library/foreign/libs/foreign.so reveals no dependencies (and the R 
>> binary is not linked against libavl either).
>> 
>> I can see that linking against libavl could cause problems, but have no 
>> idea why that might be happening.
>> 
>> 
>> On Fri, 6 Mar 2009, Jeff Long wrote:
>> 
>>> Like a couple of other posters in the past year, I was seeing R 2.8.1 
>>> segfault in the foreign package on my Solaris 10 Intel system:
>>>
>>>      > library(foreign)
>>>
>>>      *** caught segfault ***
>>>      address fe1d5c70, cause 'invalid permissions'
>>>
>>>      Traceback:
>>>           1: .C("spss_init", PACKAGE = "foreign")
>>>           2: fun(...)
>>> 
>>> This happened whether I built with gcc3, gcc4, or SunStudio 12.
>>> 
>>> Using pstack I found that the code was crashing in avl_create(). Using 
>>> truss I found that identically named functions in the Solaris 
>>> /lib/libavl.so.1 library were being used instead of the AVL functions 
>>> provided in avl.c in the foreign package. To verify, I replaced all of the 
>>> "avl_" and "AVL_" patterns in foreign/src/*.[ch] with "ravl_" and "RAVL_" 
>>> respectively. Once I made this change, loading the foreign package caused 
>>> no further problems.
>>> 
>>> An alternative workaround was a hack involving symlinks and 
>>> LD_LIBRARY_PATH, but that was not satisfactory. Since the foreign avl 
>>> functions are incompatible with the ones provided by the standard Sun 
>>> library, this approach has other potential gotchas.
>>> 
>>> FYI.
>>> 
>>> Jeff
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https:// stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http:// www. stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 10:34:31 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 10:34:31 +0100
Subject: [Rd] question
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F87051705E41B@exvic-mbx03.nexus.csiro.au>
References: <50d1c22d0903050622s2f450835k3edeb8c7f8f4df01@mail.gmail.com>,
	<971536df0903051425h31070a46h76fc666b35fc3d78@mail.gmail.com>
	<62C82B39B8A85E4B95A18F7F7B852F87051705E41B@exvic-mbx03.nexus.csiro.au>
Message-ID: <49B23FA7.9090006@idi.ntnu.no>

Mark.Bravington at csiro.au wrote:
>   
>> The syntax for returning multiple arguments does not strike me as
>> particularly appealing.  would it not possible to allow syntax like:
>>
>>   f= function() { return( rnorm(10), rnorm(20) ) }
>>   (a,d$b) = f()
>>
>>     
>
>
> FWIW, my own solution is to define a "multi-assign operator":
>
> '%<-%' <- function( a, b){
>   # a must be of the form '{thing1;thing2;...}'
>   a <- as.list( substitute( a))[-1]
>   e <- sys.parent()
>   stopifnot( length( b) == length( a))
>   for( i in seq_along( a))
>     eval( call( '<-', a[[ i]], b[[i]]), envir=e)
>   NULL
> }
>   

you might want to have the check less stringent, so that rhs may consist
of more values that the lhs has variables.  or even skip the check and
assign NULL to a[i] for i > length(b).  another idea is to allow %<-% to
be used with just one variable on the lhs.

here's a modified version:

    '%<-%' <- function(a, b){
        a <- as.list( substitute(a))
        if (length(a) > 1)
            a <- a[-1]
        if (length(a) > length(b))
            b <- c(b, rep(list(NULL), length(a) - length(b)))
        e <- sys.parent()
        for( i in seq_along( a))
            eval( call( '<-', a[[ i]], b[[i]]), envir=e)
        NULL }

    {a; b} %<-% 1:2
    # a = 1; b = 2
    a %<-% 3:4
    # a = 3
    {a; b} %<-% 5
    # a = 5; b = NULL


vQ


From ggrothendieck at gmail.com  Sat Mar  7 15:28:45 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Mar 2009 09:28:45 -0500
Subject: [Rd] question
In-Reply-To: <000325575fc2f3201e046488263f@google.com>
References: <49B23FA7.9090006@idi.ntnu.no>
	<000325575fc2f3201e046488263f@google.com>
Message-ID: <971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>

Why?   Can you demonstrate any situations where its useful?  Despite
having my own facility for this I've found that over the years I
have never used it.

On Sat, Mar 7, 2009 at 9:23 AM,  <ivowel at gmail.com> wrote:
> Gentlemen---these are all very clever workarounds, but please forgive me for
> voicing my own opinion: IMHO, returning multiple values in a statistical
> language should really be part of the language itself. there should be a
> standard syntax of some sort, whatever it may be, that everyone should be
> able to use and which easily transfers from one local computer to another.
> It should not rely on clever hacks in the .Rprofile that are different from
> user to user, and which leave a reader of end user R code baffled at first
> by all the magic that is going on. Even the R tutorials for beginners should
> show a multiple-value return example right at the point where function calls
> and return values are first explained.
>
> I really do not understand why the earlier implementation of "multiple-value
> returns" was deprecated. then again, I am a naive end user, not a computer
> language expert. I probably would not even understand the nuances of syntax
> ambiguities that may have arisen. (this is my shortcoming.)
>
> regards,
>
> /iaw
>
>
> On Mar 7, 2009 4:34am, Wacek Kusnierczyk
> <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>> Mark.Bravington at csiro.au wrote:
>>
>> >
>>
>> >> The syntax for returning multiple arguments does not strike me as
>>
>> >> particularly appealing. ?would it not possible to allow syntax like:
>>
>> >>
>>
>> >> ? f= function() { return( rnorm(10), rnorm(20) ) }
>>
>> >> ? (a,d$b) = f()
>>
>> >>
>>
>> >>
>>
>> >
>>
>> >
>>
>> > FWIW, my own solution is to define a "multi-assign operator":
>>
>> >
>>
>> > '%
>> > ? # a must be of the form '{thing1;thing2;...}'
>>
>> > ? a
>> > ? e
>> > ? stopifnot( length( b) == length( a))
>>
>> > ? for( i in seq_along( a))
>>
>> > ? ? eval( call( '
>> > ? NULL
>>
>> > }
>>
>> >
>>
>>
>>
>> you might want to have the check less stringent, so that rhs may consist
>>
>> of more values that the lhs has variables. ?or even skip the check and
>>
>> assign NULL to a[i] for i > length(b). ?another idea is to allow %
>> be used with just one variable on the lhs.
>>
>>
>>
>> here's a modified version:
>>
>>
>>
>> ? ?'%
>> ? ? ? ?a
>> ? ? ? ?if (length(a) > 1)
>>
>> ? ? ? ? ? ?a
>> ? ? ? ?if (length(a) > length(b))
>>
>> ? ? ? ? ? ?b
>> ? ? ? ?e
>> ? ? ? ?for( i in seq_along( a))
>>
>> ? ? ? ? ? ?eval( call( '
>> ? ? ? ?NULL }
>>
>>
>>
>> ? ?{a; b} %
>> ? ?# a = 1; b = 2
>>
>> ? ?a %
>> ? ?# a = 3
>>
>> ? ?{a; b} %
>> ? ?# a = 5; b = NULL
>>
>>
>>
>>
>>
>> vQ
>>


From ivowel at gmail.com  Sat Mar  7 15:23:58 2009
From: ivowel at gmail.com (ivowel at gmail.com)
Date: Sat, 07 Mar 2009 14:23:58 +0000
Subject: [Rd] question
In-Reply-To: <49B23FA7.9090006@idi.ntnu.no>
Message-ID: <000325575fc2f3201e046488263f@google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090307/23721f98/attachment.pl>

From ivowel at gmail.com  Sat Mar  7 15:38:39 2009
From: ivowel at gmail.com (ivo welch)
Date: Sat, 7 Mar 2009 09:38:39 -0500
Subject: [Rd] question
In-Reply-To: <971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>
References: <49B23FA7.9090006@idi.ntnu.no>
	<000325575fc2f3201e046488263f@google.com>
	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>
Message-ID: <50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>

hi gabor:  this would be difficult to do.  I don't think you want to
read my programs.  it would give you an appreciation of what ugly
horror programs end users can write in the beautiful R language  ;-).

clearly, one can work around the lack of such a feature.
multiple-return values are syntax sugar.  but maybe it helps to
explain how I got to my own view.  I had to send an R program to
someone who had never used it before.  without knowing R, he could
literally read the entire program.  the only thing that stumped him
was the multiple return values.  In my program, he saw

  f= function() { return(list(a=myvector1, b=myvector2)) }

  result=f()
  a= result$a
  b= result$a
  rm(result)

I had picked this method up over the years reading r-help.  of course,
I had 10 return values, not two, each return value with its own long
name.  I think it would have been a whole lot nicer if I could have
written FOR HIM simply

  f= function() { return(myvector1,myvector2); }
  (a,b)= f()

again, its syntax sugar.  I would find such syntax a whole lot more
appealing.  and I often write functions that pass back a main program,
but also some debug or other information.  maybe I am the only one...

regards,

/iaw


On Sat, Mar 7, 2009 at 9:28 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Why? ? Can you demonstrate any situations where its useful? ?Despite
> having my own facility for this I've found that over the years I
> have never used it.
>
> On Sat, Mar 7, 2009 at 9:23 AM, ?<ivowel at gmail.com> wrote:
>> Gentlemen---these are all very clever workarounds, but please forgive me for
>> voicing my own opinion: IMHO, returning multiple values in a statistical
>> language should really be part of the language itself. there should be a
>> standard syntax of some sort, whatever it may be, that everyone should be
>> able to use and which easily transfers from one local computer to another.
>> It should not rely on clever hacks in the .Rprofile that are different from
>> user to user, and which leave a reader of end user R code baffled at first
>> by all the magic that is going on. Even the R tutorials for beginners should
>> show a multiple-value return example right at the point where function calls
>> and return values are first explained.
>>
>> I really do not understand why the earlier implementation of "multiple-value
>> returns" was deprecated. then again, I am a naive end user, not a computer
>> language expert. I probably would not even understand the nuances of syntax
>> ambiguities that may have arisen. (this is my shortcoming.)
>>
>> regards,
>>
>> /iaw
>>
>>
>> On Mar 7, 2009 4:34am, Wacek Kusnierczyk
>> <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>>> Mark.Bravington at csiro.au wrote:
>>>
>>> >
>>>
>>> >> The syntax for returning multiple arguments does not strike me as
>>>
>>> >> particularly appealing. ?would it not possible to allow syntax like:
>>>
>>> >>
>>>
>>> >> ? f= function() { return( rnorm(10), rnorm(20) ) }
>>>
>>> >> ? (a,d$b) = f()
>>>
>>> >>
>>>
>>> >>
>>>
>>> >
>>>
>>> >
>>>
>>> > FWIW, my own solution is to define a "multi-assign operator":
>>>
>>> >
>>>
>>> > '%
>>> > ? # a must be of the form '{thing1;thing2;...}'
>>>
>>> > ? a
>>> > ? e
>>> > ? stopifnot( length( b) == length( a))
>>>
>>> > ? for( i in seq_along( a))
>>>
>>> > ? ? eval( call( '
>>> > ? NULL
>>>
>>> > }
>>>
>>> >
>>>
>>>
>>>
>>> you might want to have the check less stringent, so that rhs may consist
>>>
>>> of more values that the lhs has variables. ?or even skip the check and
>>>
>>> assign NULL to a[i] for i > length(b). ?another idea is to allow %
>>> be used with just one variable on the lhs.
>>>
>>>
>>>
>>> here's a modified version:
>>>
>>>
>>>
>>> ? ?'%
>>> ? ? ? ?a
>>> ? ? ? ?if (length(a) > 1)
>>>
>>> ? ? ? ? ? ?a
>>> ? ? ? ?if (length(a) > length(b))
>>>
>>> ? ? ? ? ? ?b
>>> ? ? ? ?e
>>> ? ? ? ?for( i in seq_along( a))
>>>
>>> ? ? ? ? ? ?eval( call( '
>>> ? ? ? ?NULL }
>>>
>>>
>>>
>>> ? ?{a; b} %
>>> ? ?# a = 1; b = 2
>>>
>>> ? ?a %
>>> ? ?# a = 3
>>>
>>> ? ?{a; b} %
>>> ? ?# a = 5; b = NULL
>>>
>>>
>>>
>>>
>>>
>>> vQ
>>>
>


From ggrothendieck at gmail.com  Sat Mar  7 15:45:54 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Mar 2009 09:45:54 -0500
Subject: [Rd] question
In-Reply-To: <50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
References: <49B23FA7.9090006@idi.ntnu.no>
	<000325575fc2f3201e046488263f@google.com>
	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>
	<50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
Message-ID: <971536df0903070645x6f93663y9969f1d2df875d29@mail.gmail.com>

On Sat, Mar 7, 2009 at 9:38 AM, ivo welch <ivowel at gmail.com> wrote:
> hi gabor: ?this would be difficult to do. ?I don't think you want to
> read my programs. ?it would give you an appreciation of what ugly
> horror programs end users can write in the beautiful R language ?;-).
>
> clearly, one can work around the lack of such a feature.
> multiple-return values are syntax sugar. ?but maybe it helps to
> explain how I got to my own view. ?I had to send an R program to
> someone who had never used it before. ?without knowing R, he could
> literally read the entire program. ?the only thing that stumped him
> was the multiple return values. ?In my program, he saw
>
> ?f= function() { return(list(a=myvector1, b=myvector2)) }
>
> ?result=f()
> ?a= result$a
> ?b= result$a
> ?rm(result)
>
> I had picked this method up over the years reading r-help. ?of course,
> I had 10 return values, not two, each return value with its own long
> name. ?I think it would have been a whole lot nicer if I could have
> written FOR HIM simply
>
> ?f= function() { return(myvector1,myvector2); }
> ?(a,b)= f()

The function would be better written

f <- function() list(a = myvector1, b = myvector2)

and then called:

L <- f()






>
> again, its syntax sugar. ?I would find such syntax a whole lot more
> appealing. ?and I often write functions that pass back a main program,
> but also some debug or other information. ?maybe I am the only one...
>
> regards,
>
> /iaw
>
>
> On Sat, Mar 7, 2009 at 9:28 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> Why? ? Can you demonstrate any situations where its useful? ?Despite
>> having my own facility for this I've found that over the years I
>> have never used it.
>>
>> On Sat, Mar 7, 2009 at 9:23 AM, ?<ivowel at gmail.com> wrote:
>>> Gentlemen---these are all very clever workarounds, but please forgive me for
>>> voicing my own opinion: IMHO, returning multiple values in a statistical
>>> language should really be part of the language itself. there should be a
>>> standard syntax of some sort, whatever it may be, that everyone should be
>>> able to use and which easily transfers from one local computer to another.
>>> It should not rely on clever hacks in the .Rprofile that are different from
>>> user to user, and which leave a reader of end user R code baffled at first
>>> by all the magic that is going on. Even the R tutorials for beginners should
>>> show a multiple-value return example right at the point where function calls
>>> and return values are first explained.
>>>
>>> I really do not understand why the earlier implementation of "multiple-value
>>> returns" was deprecated. then again, I am a naive end user, not a computer
>>> language expert. I probably would not even understand the nuances of syntax
>>> ambiguities that may have arisen. (this is my shortcoming.)
>>>
>>> regards,
>>>
>>> /iaw
>>>
>>>
>>> On Mar 7, 2009 4:34am, Wacek Kusnierczyk
>>> <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>>>> Mark.Bravington at csiro.au wrote:
>>>>
>>>> >
>>>>
>>>> >> The syntax for returning multiple arguments does not strike me as
>>>>
>>>> >> particularly appealing. ?would it not possible to allow syntax like:
>>>>
>>>> >>
>>>>
>>>> >> ? f= function() { return( rnorm(10), rnorm(20) ) }
>>>>
>>>> >> ? (a,d$b) = f()
>>>>
>>>> >>
>>>>
>>>> >>
>>>>
>>>> >
>>>>
>>>> >
>>>>
>>>> > FWIW, my own solution is to define a "multi-assign operator":
>>>>
>>>> >
>>>>
>>>> > '%
>>>> > ? # a must be of the form '{thing1;thing2;...}'
>>>>
>>>> > ? a
>>>> > ? e
>>>> > ? stopifnot( length( b) == length( a))
>>>>
>>>> > ? for( i in seq_along( a))
>>>>
>>>> > ? ? eval( call( '
>>>> > ? NULL
>>>>
>>>> > }
>>>>
>>>> >
>>>>
>>>>
>>>>
>>>> you might want to have the check less stringent, so that rhs may consist
>>>>
>>>> of more values that the lhs has variables. ?or even skip the check and
>>>>
>>>> assign NULL to a[i] for i > length(b). ?another idea is to allow %
>>>> be used with just one variable on the lhs.
>>>>
>>>>
>>>>
>>>> here's a modified version:
>>>>
>>>>
>>>>
>>>> ? ?'%
>>>> ? ? ? ?a
>>>> ? ? ? ?if (length(a) > 1)
>>>>
>>>> ? ? ? ? ? ?a
>>>> ? ? ? ?if (length(a) > length(b))
>>>>
>>>> ? ? ? ? ? ?b
>>>> ? ? ? ?e
>>>> ? ? ? ?for( i in seq_along( a))
>>>>
>>>> ? ? ? ? ? ?eval( call( '
>>>> ? ? ? ?NULL }
>>>>
>>>>
>>>>
>>>> ? ?{a; b} %
>>>> ? ?# a = 1; b = 2
>>>>
>>>> ? ?a %
>>>> ? ?# a = 3
>>>>
>>>> ? ?{a; b} %
>>>> ? ?# a = 5; b = NULL
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> vQ
>>>>
>>
>


From lgautier at gmail.com  Sat Mar  7 15:51:24 2009
From: lgautier at gmail.com (Laurent Gautier)
Date: Sat, 07 Mar 2009 15:51:24 +0100
Subject: [Rd] Follow-up on the wish for a visibility flag with tryEval ?
Message-ID: <49B289EC.7040608@gmail.com>

Dear list,

Did the wish for an official API for evaluating expressions while 
keeping an eye on the R_Visible flag (see:
https://stat.ethz.ch/pipermail/r-devel/2007-April/045258.html
) lead to something ?

I could not find a sign of it the current (R-2.8.1 and R-2.9-dev) R defines.


Thanks,


L.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 16:26:43 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 16:26:43 +0100
Subject: [Rd] question
In-Reply-To: <000325575fc2f3201e046488263f@google.com>
References: <000325575fc2f3201e046488263f@google.com>
Message-ID: <49B29233.7040205@idi.ntnu.no>

ivowel at gmail.com wrote:
> Gentlemen---these are all very clever workarounds, 

hacks around the lack of a feature

> but please forgive me for voicing my own opinion: IMHO, returning
> multiple values in a statistical language should really be part of the
> language itself. 

returning multiple values is supported by many programming languages, in
particular scripting languages.  while in r you can use the %<-% hack or
have functions return lists of values, it  could indeed be useful to
have such a feature in a statistical language like r.


> there should be a standard syntax of some sort, 

if you mean that r should have such a syntax, you're likely to learn
more about saying 'should' soon. 

> whatever it may be, that everyone should be able to use and which
> easily transfers from one local computer to another. It should not
> rely on clever hacks in the .Rprofile that are different from user to
> user, and which leave a reader of end user R code baffled at first by
> all the magic that is going on. Even the R tutorials for beginners
> should show a multiple-value return example right at the point where
> function calls and return values are first explained.

as gabor says in another post, you probably should first show why having
multiple value returns would be useful in r.  however, i don't think
there are good counterarguments anyway, and putting on you the burden of
proving a relatively obvious (or not so?) thing is a weak escape.

to call for a reference, sec. 9.2.3, p. 450+ in [1] provides some
discussion and examples.

vQ

[1] Design Concepts in Programming Languages, Turbak and Gifford with
Sheldon, MIT 2008


From ggrothendieck at gmail.com  Sat Mar  7 17:06:15 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Mar 2009 11:06:15 -0500
Subject: [Rd] question
In-Reply-To: <49B29233.7040205@idi.ntnu.no>
References: <000325575fc2f3201e046488263f@google.com>
	<49B29233.7040205@idi.ntnu.no>
Message-ID: <971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>

On Sat, Mar 7, 2009 at 10:26 AM, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> ivowel at gmail.com wrote:
>> Gentlemen---these are all very clever workarounds,
>
> hacks around the lack of a feature
>
>> but please forgive me for voicing my own opinion: IMHO, returning
>> multiple values in a statistical language should really be part of the
>> language itself.
>
> returning multiple values is supported by many programming languages, in
> particular scripting languages. ?while in r you can use the %<-% hack or
> have functions return lists of values, it ?could indeed be useful to
> have such a feature in a statistical language like r.
>
>
>> there should be a standard syntax of some sort,
>
> if you mean that r should have such a syntax, you're likely to learn
> more about saying 'should' soon.
>
>> whatever it may be, that everyone should be able to use and which
>> easily transfers from one local computer to another. It should not
>> rely on clever hacks in the .Rprofile that are different from user to
>> user, and which leave a reader of end user R code baffled at first by
>> all the magic that is going on. Even the R tutorials for beginners
>> should show a multiple-value return example right at the point where
>> function calls and return values are first explained.
>
> as gabor says in another post, you probably should first show why having
> multiple value returns would be useful in r. ?however, i don't think
> there are good counterarguments anyway, and putting on you the burden of
> proving a relatively obvious (or not so?) thing is a weak escape.
>
> to call for a reference, sec. 9.2.3, p. 450+ in [1] provides some
> discussion and examples.
>

The fact that other languages is an argument for further consideration
but not a definitive argument for it.

I have had this feature for years via my workaround yet I never
use it which seems a good argument against it.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 17:35:48 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 17:35:48 +0100
Subject: [Rd] question
In-Reply-To: <971536df0903070645x6f93663y9969f1d2df875d29@mail.gmail.com>
References: <49B23FA7.9090006@idi.ntnu.no>	
	<000325575fc2f3201e046488263f@google.com>	
	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>	
	<50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
	<971536df0903070645x6f93663y9969f1d2df875d29@mail.gmail.com>
Message-ID: <49B2A264.6030409@idi.ntnu.no>

Gabor Grothendieck wrote:
> On Sat, Mar 7, 2009 at 9:38 AM, ivo welch <ivowel at gmail.com> wrote:
>   
>> hi gabor:  this would be difficult to do.  I don't think you want to
>> read my programs.  it would give you an appreciation of what ugly
>> horror programs end users can write in the beautiful R language  ;-).
>>
>> clearly, one can work around the lack of such a feature.
>> multiple-return values are syntax sugar.  but maybe it helps to
>> explain how I got to my own view.  I had to send an R program to
>> someone who had never used it before.  without knowing R, he could
>> literally read the entire program.  the only thing that stumped him
>> was the multiple return values.  In my program, he saw
>>
>>  f= function() { return(list(a=myvector1, b=myvector2)) }
>>
>>  result=f()
>>  a= result$a
>>  b= result$a
>>  rm(result)
>>
>> I had picked this method up over the years reading r-help.  of course,
>> I had 10 return values, not two, each return value with its own long
>> name.  I think it would have been a whole lot nicer if I could have
>> written FOR HIM simply
>>
>>  f= function() { return(myvector1,myvector2); }
>>  (a,b)= f()
>>     
>
> The function would be better written
>
> f <- function() list(a = myvector1, b = myvector2)
>
> and then called:
>
> L <- f()
>   

that's exactly what ivo shows above, with an explanation of why he finds
it inconvenient. 

one point that could be made in favour of multiple return values is that
when you return a list, you a) have a nuissance object, some of whose
components may not be of interest at all, and b) elongate the value
lookup path (list$variable vs. variable), both of which add performance
penalty -- which is surely negligible in many cases.

you can  of course use with, as here:

    with(f(),
       <do something with a and b>)

which rather remotely resembles call-with-values in scheme or receive in
guile, but this adds a penalty again (with constructs a new local
environment) and makes the code less readable.  it also suffers from the
same problem as accessing the variables explicitly from the returned
list (as l$a, for example), namely, that the variable names are as given
by the author rather than the user of the function.

i have had occasions where it would be convenient to be able to do
something like

    c(first, last) = f(...)[1, 4]

or
   
    c(left, right) = f(...)[c('u.glyNAME', 'uninformative.name')]

as to the usefulness of capturing multiple return values each in a
variable on its own, it's really at the heart of perl, where you can
capture the return either into an array variable or into a collection of
scalar (and array) variables:

    @values = &function(...)
    ($first, $second, @rest) = function(...)

but of course, r is not perl and vice versa, so this is a red herring
argument.


vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 17:37:53 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 17:37:53 +0100
Subject: [Rd] question
In-Reply-To: <971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>
References: <000325575fc2f3201e046488263f@google.com>	
	<49B29233.7040205@idi.ntnu.no>
	<971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>
Message-ID: <49B2A2E1.20508@idi.ntnu.no>

Gabor Grothendieck wrote:
>
>> as gabor says in another post, you probably should first show why having
>> multiple value returns would be useful in r.  however, i don't think
>> there are good counterarguments anyway, and putting on you the burden of
>> proving a relatively obvious (or not so?) thing is a weak escape.
>>
>> to call for a reference, sec. 9.2.3, p. 450+ in [1] provides some
>> discussion and examples.
>>
>>     
>
> The fact that other languages is an argument for further consideration
> but not a definitive argument for it.
>   

of course!

> I have had this feature for years via my workaround yet I never
> use it which seems a good argument against it.
>   

the fact that another programmer is an argument for further
consideration but not a definitive argument against it.

vQ


From ggrothendieck at gmail.com  Sat Mar  7 17:46:42 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Mar 2009 11:46:42 -0500
Subject: [Rd] question
In-Reply-To: <49B2A2E1.20508@idi.ntnu.no>
References: <000325575fc2f3201e046488263f@google.com>
	<49B29233.7040205@idi.ntnu.no>
	<971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>
	<49B2A2E1.20508@idi.ntnu.no>
Message-ID: <971536df0903070846h3692e809ga195d126da37de5e@mail.gmail.com>

On Sat, Mar 7, 2009 at 11:37 AM, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> Gabor Grothendieck wrote:
>>
>>> as gabor says in another post, you probably should first show why having
>>> multiple value returns would be useful in r. ?however, i don't think
>>> there are good counterarguments anyway, and putting on you the burden of
>>> proving a relatively obvious (or not so?) thing is a weak escape.
>>>
>>> to call for a reference, sec. 9.2.3, p. 450+ in [1] provides some
>>> discussion and examples.
>>>
>>>
>>
>> The fact that other languages is an argument for further consideration
>> but not a definitive argument for it.
>>
>
> of course!
>
>> I have had this feature for years via my workaround yet I never
>> use it which seems a good argument against it.
>>
>
> the fact that another programmer is an argument for further
> consideration but not a definitive argument against it.

I've provided an argument against it and no one has provided one
for it. The so-called identical code Ivo showed was not identical
and, in fact, was flawed.  Your first/last example could be
written:

f <- function() letters
L <- structure(f()[1:2], names = c("first", "last"))

or one could define a function to do that without having
to modify the language.   Given the relative infrequency
of this it hardly seems to merit a language feature.


From pburns at pburns.seanet.com  Sat Mar  7 18:19:43 2009
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 07 Mar 2009 17:19:43 +0000
Subject: [Rd] question
In-Reply-To: <50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
References: <49B23FA7.9090006@idi.ntnu.no>	<000325575fc2f3201e046488263f@google.com>	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>
	<50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
Message-ID: <49B2ACAF.5030905@pburns.seanet.com>

One idea of program design is that users
should be protected against themselves.

It is my experience that users, especially
novices, tend to over-split items rather than
over-clump items.  The fact that items are
returned by the same function call would
argue to me that there is a connection between
the items.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of "The R Inferno" and "A Guide for the Unwilling S User")

ivo welch wrote:
> hi gabor:  this would be difficult to do.  I don't think you want to
> read my programs.  it would give you an appreciation of what ugly
> horror programs end users can write in the beautiful R language  ;-).
>
> clearly, one can work around the lack of such a feature.
> multiple-return values are syntax sugar.  but maybe it helps to
> explain how I got to my own view.  I had to send an R program to
> someone who had never used it before.  without knowing R, he could
> literally read the entire program.  the only thing that stumped him
> was the multiple return values.  In my program, he saw
>
>   f= function() { return(list(a=myvector1, b=myvector2)) }
>
>   result=f()
>   a= result$a
>   b= result$a
>   rm(result)
>
> I had picked this method up over the years reading r-help.  of course,
> I had 10 return values, not two, each return value with its own long
> name.  I think it would have been a whole lot nicer if I could have
> written FOR HIM simply
>
>   f= function() { return(myvector1,myvector2); }
>   (a,b)= f()
>
> again, its syntax sugar.  I would find such syntax a whole lot more
> appealing.  and I often write functions that pass back a main program,
> but also some debug or other information.  maybe I am the only one...
>
> regards,
>
> /iaw
>
>
> On Sat, Mar 7, 2009 at 9:28 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>   
>> Why?   Can you demonstrate any situations where its useful?  Despite
>> having my own facility for this I've found that over the years I
>> have never used it.
>>
>> On Sat, Mar 7, 2009 at 9:23 AM,  <ivowel at gmail.com> wrote:
>>     
>>> Gentlemen---these are all very clever workarounds, but please forgive me for
>>> voicing my own opinion: IMHO, returning multiple values in a statistical
>>> language should really be part of the language itself. there should be a
>>> standard syntax of some sort, whatever it may be, that everyone should be
>>> able to use and which easily transfers from one local computer to another.
>>> It should not rely on clever hacks in the .Rprofile that are different from
>>> user to user, and which leave a reader of end user R code baffled at first
>>> by all the magic that is going on. Even the R tutorials for beginners should
>>> show a multiple-value return example right at the point where function calls
>>> and return values are first explained.
>>>
>>> I really do not understand why the earlier implementation of "multiple-value
>>> returns" was deprecated. then again, I am a naive end user, not a computer
>>> language expert. I probably would not even understand the nuances of syntax
>>> ambiguities that may have arisen. (this is my shortcoming.)
>>>
>>> regards,
>>>
>>> /iaw
>>>
>>>
>>> On Mar 7, 2009 4:34am, Wacek Kusnierczyk
>>> <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>>>       
>>>> Mark.Bravington at csiro.au wrote:
>>>>
>>>>         
>>>>>> The syntax for returning multiple arguments does not strike me as
>>>>>>             
>>>>>> particularly appealing.  would it not possible to allow syntax like:
>>>>>>             
>>>>>>   f= function() { return( rnorm(10), rnorm(20) ) }
>>>>>>             
>>>>>>   (a,d$b) = f()
>>>>>>             
>>>>> FWIW, my own solution is to define a "multi-assign operator":
>>>>>           
>>>>> '%
>>>>>   # a must be of the form '{thing1;thing2;...}'
>>>>>           
>>>>>   a
>>>>>   e
>>>>>   stopifnot( length( b) == length( a))
>>>>>           
>>>>>   for( i in seq_along( a))
>>>>>           
>>>>>     eval( call( '
>>>>>   NULL
>>>>>           
>>>>> }
>>>>>           
>>>>
>>>> you might want to have the check less stringent, so that rhs may consist
>>>>
>>>> of more values that the lhs has variables.  or even skip the check and
>>>>
>>>> assign NULL to a[i] for i > length(b).  another idea is to allow %
>>>> be used with just one variable on the lhs.
>>>>
>>>>
>>>>
>>>> here's a modified version:
>>>>
>>>>
>>>>
>>>>    '%
>>>>        a
>>>>        if (length(a) > 1)
>>>>
>>>>            a
>>>>        if (length(a) > length(b))
>>>>
>>>>            b
>>>>        e
>>>>        for( i in seq_along( a))
>>>>
>>>>            eval( call( '
>>>>        NULL }
>>>>
>>>>
>>>>
>>>>    {a; b} %
>>>>    # a = 1; b = 2
>>>>
>>>>    a %
>>>>    # a = 3
>>>>
>>>>    {a; b} %
>>>>    # a = 5; b = NULL
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> vQ
>>>>
>>>>         
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From Thomas.Petzoldt at TU-Dresden.de  Sat Mar  7 18:38:45 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Sat, 07 Mar 2009 18:38:45 +0100
Subject: [Rd] question
In-Reply-To: <49B2ACAF.5030905@pburns.seanet.com>
References: <49B23FA7.9090006@idi.ntnu.no>	<000325575fc2f3201e046488263f@google.com>	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>	<50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>
	<49B2ACAF.5030905@pburns.seanet.com>
Message-ID: <49B2B125.4030609@TU-Dresden.de>

Patrick Burns wrote:
> One idea of program design is that users
> should be protected against themselves.
> 
> It is my experience that users, especially
> novices, tend to over-split items rather than
> over-clump items.  The fact that items are
> returned by the same function call would
> argue to me that there is a connection between
> the items.
> 
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of "The R Inferno" and "A Guide for the Unwilling S User")

Hi Gabor, Patrick, Ivo and vQ,

I agree with Patrick and Gabor that it is not needed. IMHO it is good 
design that a function (in a mathematical sense) returns ONE object, let 
it a single value, a list or an S3/S4 object. This can be passed to 
another function as a whole or can be splitted to its parts according to 
different needs. If only single parts are required, than I would suggest 
to use accessor functions preferably written as generics working on 
returned S3 or S4 objects. I'm strongly against going back to the past S 
behaviour and I wonder a little bit about this discussion. I like it to 
have a clean workspace with only a few objects.

Thomas Petzoldt


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 21:19:54 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 21:19:54 +0100
Subject: [Rd] question
In-Reply-To: <971536df0903070846h3692e809ga195d126da37de5e@mail.gmail.com>
References: <000325575fc2f3201e046488263f@google.com>	
	<49B29233.7040205@idi.ntnu.no>	
	<971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>	
	<49B2A2E1.20508@idi.ntnu.no>
	<971536df0903070846h3692e809ga195d126da37de5e@mail.gmail.com>
Message-ID: <49B2D6EA.4080907@idi.ntnu.no>

Gabor Grothendieck wrote:
>
> I've provided an argument against it and no one has provided one
> for it. The so-called identical code Ivo showed was not identical
> and, in fact, was flawed.  

no, you're wrong.  you think of the part where ivo shows what he'd like
to have;  the example i was referring to was almost identical with
yours, except for the explicit return and '=' used for assignment. 


> Your first/last example could be
> written:
>
> f <- function() letters
> L <- structure(f()[1:2], names = c("first", "last"))
>   

indeed, but:

- this still does not allow one to use the names directly, only as
L$first etc., with the syntactic and semantic (longer lookup times) penalty;

- using structure you add yet another source of performance penalty; a
quick naive benchmark hints that it doubles the time elapsed if the
returned list is inaccessible otherwise, and adds one order of magnitude
if the list has to be copied:

    f1= function() as.list(letters)
    f2 =local({ letters = as.list(letters);  function() letters })

    source('http://rbenchmark.googlecode.com/svn/trunk/benchmark.r')
    benchmark(replications=10000, columns=c('test', 'elapsed'),
       'f1 direct'=f1(),
       'f1 structure'=structure(f1(), names=letters),
       'f2 direct'=f2(),
       'f2 structure'=structure(f2(), names=letters))

    #           test elapsed
    # 1    f1 direct   0.171
    # 2 f1 structure   0.693
    # 3    f2 direct   0.048
    # 4 f2 structure   0.594

instead of a syntactically (and semantically, if done appropriately)
clean solution:

    c(a, b) = f()[1,3]
    # work with a and b

you offer a glut:

    l = structure(f()[1,3], names=c('a', 'b'))
    # work with l$a and l$b


> or one could define a function to do that without having
> to modify the language.   Given the relative infrequency
> of this it hardly seems to merit a language feature.
>   

infrequency of what?  of people's inventing ugly hacks to get arround
the inability to capture multiple return values directly?  sure, this is
a good argument against having someone do the job, but is it a good
argument against having the feature in the language?

vQ


From ggrothendieck at gmail.com  Sat Mar  7 22:03:36 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Mar 2009 16:03:36 -0500
Subject: [Rd] question
In-Reply-To: <49B2D6EA.4080907@idi.ntnu.no>
References: <000325575fc2f3201e046488263f@google.com>
	<49B29233.7040205@idi.ntnu.no>
	<971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>
	<49B2A2E1.20508@idi.ntnu.no>
	<971536df0903070846h3692e809ga195d126da37de5e@mail.gmail.com>
	<49B2D6EA.4080907@idi.ntnu.no>
Message-ID: <971536df0903071303j2cf200a7i88185a75c4a3985d@mail.gmail.com>

On Sat, Mar 7, 2009 at 3:19 PM, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> Gabor Grothendieck wrote:
>>
>> I've provided an argument against it and no one has provided one
>> for it. The so-called identical code Ivo showed was not identical
>> and, in fact, was flawed.
>
> no, you're wrong. ?you think of the part where ivo shows what he'd like
> to have; ?the example i was referring to was almost identical with
> yours, except for the explicit return and '=' used for assignment.
>
>
>> Your first/last example could be
>> written:
>>
>> f <- function() letters
>> L <- structure(f()[1:2], names = c("first", "last"))
>>
>
> indeed, but:
>
> - this still does not allow one to use the names directly, only as
> L$first etc., with the syntactic and semantic (longer lookup times) penalty;

That's how it should be done. Using the auto split you get many
variables which is not desirable.  it encourages bad programming.

>
> - using structure you add yet another source of performance penalty; a
> quick naive benchmark hints that it doubles the time elapsed if the
> returned list is inaccessible otherwise, and adds one order of magnitude
> if the list has to be copied:

There is no difference between structure and assignment. They are both
operations.  If there is a timing difference that is a different question.

>
> ? ?f1= function() as.list(letters)
> ? ?f2 =local({ letters = as.list(letters); ?function() letters })
>
> ? ?source('http://rbenchmark.googlecode.com/svn/trunk/benchmark.r')
> ? ?benchmark(replications=10000, columns=c('test', 'elapsed'),
> ? ? ? 'f1 direct'=f1(),
> ? ? ? 'f1 structure'=structure(f1(), names=letters),
> ? ? ? 'f2 direct'=f2(),
> ? ? ? 'f2 structure'=structure(f2(), names=letters))
>
> ? ?# ? ? ? ? ? test elapsed
> ? ?# 1 ? ?f1 direct ? 0.171
> ? ?# 2 f1 structure ? 0.693
> ? ?# 3 ? ?f2 direct ? 0.048
> ? ?# 4 f2 structure ? 0.594
>
> instead of a syntactically (and semantically, if done appropriately)
> clean solution:
>
> ? ?c(a, b) = f()[1,3]
> ? ?# work with a and b
>
> you offer a glut:
>
> ? ?l = structure(f()[1,3], names=c('a', 'b'))
> ? ?# work with l$a and l$b
>
>
>> or one could define a function to do that without having
>> to modify the language. ? Given the relative infrequency
>> of this it hardly seems to merit a language feature.
>>
>
> infrequency of what? ?of people's inventing ugly hacks to get arround
> the inability to capture multiple return values directly? ?sure, this is
> a good argument against having someone do the job, but is it a good
> argument against having the feature in the language?

I have never had to use it even though I had it available for years.
I do lots of R code so I think it speaks for itself.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 22:13:12 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 22:13:12 +0100
Subject: [Rd] question
In-Reply-To: <971536df0903071303j2cf200a7i88185a75c4a3985d@mail.gmail.com>
References: <000325575fc2f3201e046488263f@google.com>	
	<49B29233.7040205@idi.ntnu.no>	
	<971536df0903070806g38eee325q2e0cc5f2da8141b4@mail.gmail.com>	
	<49B2A2E1.20508@idi.ntnu.no>	
	<971536df0903070846h3692e809ga195d126da37de5e@mail.gmail.com>	
	<49B2D6EA.4080907@idi.ntnu.no>
	<971536df0903071303j2cf200a7i88185a75c4a3985d@mail.gmail.com>
Message-ID: <49B2E368.3020505@idi.ntnu.no>

Gabor Grothendieck wrote:
>
>> - this still does not allow one to use the names directly, only as
>> L$first etc., with the syntactic and semantic (longer lookup times) penalty;
>>     
>
> That's how it should be done. Using the auto split you get many
> variables which is not desirable.  it encourages bad programming.
>
>   

please provide a reference for this claim.  for both the 'should' and
the 'bad'.

>> - using structure you add yet another source of performance penalty; a
>> quick naive benchmark hints that it doubles the time elapsed if the
>> returned list is inaccessible otherwise, and adds one order of magnitude
>> if the list has to be copied:
>>     
>
> There is no difference between structure and assignment. They are both
> operations.  If there is a timing difference that is a different question.
>   

as far as i get the r semantics, applying structure modifies the object,
and causes the content to be copied if the object is referred to from
elsewhere.  here's where structure does add a considerable performance
penalty.


>
>>> or one could define a function to do that without having
>>> to modify the language.   Given the relative infrequency
>>> of this it hardly seems to merit a language feature.
>>>
>>>       
>> infrequency of what?  of people's inventing ugly hacks to get arround
>> the inability to capture multiple return values directly?  sure, this is
>> a good argument against having someone do the job, but is it a good
>> argument against having the feature in the language?
>>     
>
> I have never had to use it even though I had it available for years.
> I do lots of R code so I think it speaks for itself.
>   

it speaks for yourself.  it tells nothing about what others would like. 
it's quite possible that few would like it, but it does not follow from
that you wouldn't.

vQ


From murdoch at stats.uwo.ca  Sat Mar  7 23:26:34 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 07 Mar 2009 17:26:34 -0500
Subject: [Rd] Follow-up on the wish for a visibility flag with tryEval ?
In-Reply-To: <49B289EC.7040608@gmail.com>
References: <49B289EC.7040608@gmail.com>
Message-ID: <49B2F49A.90904@stats.uwo.ca>

On 07/03/2009 9:51 AM, Laurent Gautier wrote:
> Dear list,
> 
> Did the wish for an official API for evaluating expressions while 
> keeping an eye on the R_Visible flag (see:
> https://stat.ethz.ch/pipermail/r-devel/2007-April/045258.html
> ) lead to something ?
> 
> I could not find a sign of it the current (R-2.8.1 and R-2.9-dev) R defines.

You should read the NEWS file, where you'll find withVisible mentioned.

Duncan Murdoch


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar  7 23:28:32 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 07 Mar 2009 23:28:32 +0100
Subject: [Rd] question
In-Reply-To: <49B2B125.4030609@TU-Dresden.de>
References: <49B23FA7.9090006@idi.ntnu.no>	<000325575fc2f3201e046488263f@google.com>	<971536df0903070628x46a4951dt9d14da97ea720dd0@mail.gmail.com>	<50d1c22d0903070638g2a2f65dexefc45b69d4118dfe@mail.gmail.com>	<49B2ACAF.5030905@pburns.seanet.com>
	<49B2B125.4030609@TU-Dresden.de>
Message-ID: <49B2F510.6050906@idi.ntnu.no>

Thomas Petzoldt wrote:
> Patrick Burns wrote:
>> One idea of program design is that users
>> should be protected against themselves.

... and r coherently implements this idea :]

>>
>> It is my experience that users, especially
>> novices, tend to over-split items rather than
>> over-clump items.  The fact that items are
>> returned by the same function call would
>> argue to me that there is a connection between
>> the items.
>>
>>
>> Patrick Burns
>> patrick at burns-stat.com
>> +44 (0)20 8525 0696
>> http://www.burns-stat.com
>> (home of "The R Inferno" and "A Guide for the Unwilling S User")
>
> Hi Gabor, Patrick, Ivo and vQ,

hello thomas,

>
> I agree with Patrick and Gabor that it is not needed. IMHO it is good
> design that a function (in a mathematical sense) returns ONE object,
> let it a single value, a list or an S3/S4 object. 

in r functions are not functions in the mathematical sense.  r is not
quite a functional programming language, though it's certainly closer to
fp than c or fortran, say.

if one were really interested in whether the feature is desired as a
convenience rather than in enforcing one's own opinion, one'd ask
users.  it's certainly not *needed* in the sense that you can do without
it -- but then there are many more features in r which are not needed
(and some of them are more harmful than multiple return values would be).


> This can be passed to another function as a whole or can be splitted
> to its parts according to different needs. 

right, but that's extra work with coding and performance penalty. 

> If only single parts are required, than I would suggest to use
> accessor functions preferably written as generics working on returned
> S3 or S4 objects. I'm strongly against going back to the past S
> behaviour and I wonder a little bit about this discussion. 

i don't know that s behaviour, it's quite possible that it was really
wrong.  but the fact that s had it wrong (if it did) does not mean that
multiple return values are wrong per se.

> I like it to have a clean workspace with only a few objects.

why would letting others choose for themselves be a bad idea?  that's
what perl, python, ruby, or more recent languages such as scala, do --
functions can return (tuples of) multiple values which you can capture
separately and/or collectively.  multiple assignment is a fairly common
feature in modern programming languages.

it seems that this is a remote dream in r, because 'users should be
protected against themselves'.

vQ


From manikandan_narayanan at merck.com  Sun Mar  8 02:00:07 2009
From: manikandan_narayanan at merck.com (manikandan_narayanan at merck.com)
Date: Sun,  8 Mar 2009 02:00:07 +0100 (CET)
Subject: [Rd] typo in qpois help (PR#13583)
Message-ID: <20090308010007.A9045282BE89@mail.pubhealth.ku.dk>

Full_Name: Manikandan Narayanan
Version: 2.8.1
OS: Linux
Submission from: (NULL) (155.91.45.231)


Here is an excerpt from qpois help page (?qpois): 

     The quantile is left continuous: 'qgeom(q, prob)' is the largest
     integer x such that P(X <= x) < q.

  I think the "qgeom" here should be "qpois" instead. Please correct this typo
in ?qpois, since it's misleading in its current form. 

Thanks!


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Mar  8 14:56:13 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 08 Mar 2009 14:56:13 +0100
Subject: [Rd] question
In-Reply-To: <000325575fc2f3201e046488263f@google.com>
References: <000325575fc2f3201e046488263f@google.com>
Message-ID: <49B3CE7D.7040900@idi.ntnu.no>

ivowel at gmail.com wrote:
> Gentlemen---these are all very clever workarounds, but please forgive me  
> for voicing my own opinion: IMHO, returning multiple values in a  
> statistical language should really be part of the language itself. there  
> should be a standard syntax of some sort, whatever it may be, that everyone  
> should be able to use and which easily transfers from one local computer to  
> another. It should not rely on clever hacks in the .Rprofile that are  
> different from user to user, and which leave a reader of end user R code  
> baffled at first by all the magic that is going on. Even the R tutorials  
> for beginners should show a multiple-value return example right at the  
> point where function calls and return values are first explained.
>
>   

hi again,

i was playing a bit with the idea of multiple assignment, and came up
with a simple codebit [1] that redefines the operator '='.  it hasn't
been extensively tested and is by no means foolproof, but allows various
sorts of tricks with multiple assignments:

    source('http://miscell.googlecode.com/svn/rvalues/rvalues.r',
local=TRUE)

    a = function(n) 1:n
    # a is a function

    b = a(3)
    # b is c(1, 2, 3)

    c(c, d) = a(1)
    # c is 1, d is NULL

    c(a, b) = list(b, a)
    # swap: a is 1:3, b is a function

    # these are equivalent:
    c(a, b) = 1:2
    {a; b} = 1:2
    list(a, b) = 1:2

    a = data.frame(x=1:3, y=3)
    # a is a 2-column data frame

    c(a, b) = data.frame(x=1:3, b=3)
    # a is c(1, 2, 3), b is c(3, 3, 3)

and so on.  this is sort of pattern matching as in some functional
languages, but only sort of:  it does not do recursive matching, for
example:

    c(c(a, b), c) = list(1:2, 3)
    # error
    # not: a = 1, b = 2, c = 3
 
anyway, it's just a toy for which there is no need.

vQ


[1] svn checkout */http/*://miscell.googlecode.com/svn/rvalues


From lgautier at gmail.com  Sun Mar  8 20:22:19 2009
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 08 Mar 2009 20:22:19 +0100
Subject: [Rd] Follow-up on the wish for a visibility flag with tryEval ?
In-Reply-To: <49B2F49A.90904@stats.uwo.ca>
References: <49B289EC.7040608@gmail.com> <49B2F49A.90904@stats.uwo.ca>
Message-ID: <49B41AEB.6090903@gmail.com>

I guess that I should have been reminding that the thread referred to is 
mostly about C API-level utilities (and the subject for this thread 
should be mentioning more precisely *R_tryEval()* ).

Wrapping evaluation from C-level in an R-level withVisible() call is 
certainly possible if this is the only way to do it:

- a C-level utility function is probably becoming handy (and that's 
mostly what the wish is about, AFAIUI).

- the traceback has at least one added layer from the call to 
withVisible(); this is something supplementary to take care of when 
writing a GUI for example.

Those are possible reasons why the threads tells that withVisible() 
[R-level] is a temporary option, waiting for something like 
R_tryEvalWithVis() [C-level].


Can't I find any such C-level because there isn't any, or because I just 
missed it ?



Thanks,





L.




Duncan Murdoch wrote:
> On 07/03/2009 9:51 AM, Laurent Gautier wrote:
>> Dear list,
>>
>> Did the wish for an official API for evaluating expressions while 
>> keeping an eye on the R_Visible flag (see:
>> https://stat.ethz.ch/pipermail/r-devel/2007-April/045258.html
>> ) lead to something ?
>>
>> I could not find a sign of it the current (R-2.8.1 and R-2.9-dev) R 
>> defines.
> 
> You should read the NEWS file, where you'll find withVisible mentioned.
> 
> Duncan Murdoch


From r-ml at nn7.de  Sun Mar  8 21:48:11 2009
From: r-ml at nn7.de (Soeren Sonnenburg)
Date: Sun, 08 Mar 2009 21:48:11 +0100
Subject: [Rd] [RFC] running octave, python from within R
Message-ID: <1236545291.23095.31.camel@localhost>

Dear all,

a Shogun 0.7.1 is out and available at http://www.shogun-toolbox.org

which contains one new feature that might be of interest to
R users. The eierlegendewollmilchsau interface. In
case you don't know what this term stands for use google images :-)

It is one file that will interface shogun to octave,r,python,matlab. It
provides commands to run code in foreign languages:

Example:

library(elwms)

A=matrix(c(1.0,2,3, 4,5,6), nrow = 2, ncol=3)
B=matrix(c(1.0,1,1, 0,0,0), nrow = 2, ncol=3)
pythoncode=sprintf('import numpy\nresults=tuple([A+B])');
elwms('run_python', 'pythoncode', 'print "hi"')
C=elwms('run_python', 'A',A, 'B',B, 'pythoncode', pythoncode)
D=elwms('run_python', 'A',A+1, 'B',B*2, 'pythoncode', pythoncode)
pythoncode=sprintf('import numpy\nresults=(A, B, [ "bla1",
"bla2" ])\n');
X=elwms('run_python', 'A',A, 'B',B, 'pythoncode', pythoncode)
print(A)
print(B)
print(C)
print(D)
print(X)


This would pass around matrices A and B do some processing and return
results. So you could use your old octave/matlab scriptspassing around
strings cells, or whatever matrices/stringsor plot some nice figures via
matplotlib in python

See http://www.shogun-toolbox.org/doc/elwmsinterface.html .
Don't even try to run octave from python from octave etc nested.
Neither octave, R nor python-numpy nor libshogun supports this :-)

Soeren


From rpeng at jhsph.edu  Mon Mar  9 02:20:46 2009
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 8 Mar 2009 21:20:46 -0400
Subject: [Rd] patch for 'merge' docs
Message-ID: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>

I've never quite understood the documentation for the 'all' argument
to 'merge'. I'm pretty sure using 'all = L' doesn't work but I'm open
to correction here. In any event, I've attached a patch.

-roger

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/

From khansen at stat.berkeley.edu  Mon Mar  9 02:30:50 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Sun, 8 Mar 2009 18:30:50 -0700
Subject: [Rd] patch for 'merge' docs
In-Reply-To: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>
References: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>
Message-ID: <93D7EDD5-4C4F-422A-9324-DF18E37FE269@stat.berkeley.edu>

Roger

(I think) L is shorthand for some logical value, ie. TRUE or FALSE.  
That has always been pretty clear to me. Your patch was stripped.

Kasper

On Mar 8, 2009, at 18:20 , Roger D. Peng wrote:

> I've never quite understood the documentation for the 'all' argument
> to 'merge'. I'm pretty sure using 'all = L' doesn't work but I'm open
> to correction here. In any event, I've attached a patch.
>
> -roger
>
> -- 
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Mar  9 08:20:20 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Mar 2009 07:20:20 +0000 (GMT)
Subject: [Rd] typo in qpois help (PR#13583)
In-Reply-To: <20090308010007.A9045282BE89@mail.pubhealth.ku.dk>
References: <20090308010007.A9045282BE89@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903090719500.21902@gannet.stats.ox.ac.uk>

Thank you, changed in R-patched and R-devel now.

On Sun, 8 Mar 2009, manikandan_narayanan at merck.com wrote:

> Full_Name: Manikandan Narayanan
> Version: 2.8.1
> OS: Linux
> Submission from: (NULL) (155.91.45.231)
>
>
> Here is an excerpt from qpois help page (?qpois):
>
>     The quantile is left continuous: 'qgeom(q, prob)' is the largest
>     integer x such that P(X <= x) < q.
>
>  I think the "qgeom" here should be "qpois" instead. Please correct this typo
> in ?qpois, since it's misleading in its current form.
>
> Thanks!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chalabi at phys.ethz.ch  Mon Mar  9 09:19:44 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Mon, 9 Mar 2009 09:19:44 +0100
Subject: [Rd] S4 objects for S3 methods
In-Reply-To: <49B19FB0.9030606@r-project.org>
References: <49B19FB0.9030606@r-project.org>
Message-ID: <20090309091944.2d5c594d@mimi>

>>>> "JC" == John Chambers <jmc at r-project.org>
>>>> on Fri, 06 Mar 2009 14:12:00 -0800

   JC> Some modifications have been committed for the r-devel
   JC> version today
   JC> that modify (essentially, correct a bug in) the communication
   JC> of objects
   JC> to an S3 method from an S4 class that extends the S3 class.
   JC>
   JC> This is one of a sequence of changes designed to make S4
   JC> classes work
   JC> more generally and consistently with S3 methods and classes.
   JC>
   JC> In 2.8.0, support was provided for S4 classes that extend
   JC> S3 classes,
   JC> partly by making S3 method dispatch recognize the inheritance.
   JC>
   JC> The catch was that the S3 method would get the S4 object.
   JC> Two problems
   JC> with that:
   JC>
   JC> 1. The S3 method would fail if it tried to use the S3 class
   JC> information
   JC> directly, since the class attribute was the S4 class.
   JC>
   JC> 2. More seriously, if the method used the object, modified
   JC> it and
   JC> returned the result, it had a good chance of returning an
   JC> invalid object
   JC> seeming to come from the S4 class.
   JC>
   JC> The modification to deal with this now delivers to the S3
   JC> method the
   JC> inherited S3 object.  (This turned out to be somewhat harder
   JC> than the
   JC> original change, since it impacts several pieces of internal
   JC> code.)  A
   JC> revision of the function asS4() deals with similar concerns--see
   JC> the
   JC> documentation.
   JC>
   JC> The change does not affect default methods.  It would be
   JC> tempting to
   JC> convert S4 objects for those, but some S3 generics attempt to
   JC> deal with
   JC> S4 objects, e.g., str().  A change to the primitives that
   JC> dispatch
   JC> methods is more plausible, but for the moment all that was
   JC> added was
   JC> more explicit error messages if a non-vector S4 object is
   JC> supplied.
   JC>
   JC> For more information see the section on inheriting from
   JC> non-S4 classes
   JC> in the documentation ?Classes.
   JC>
   JC> It would be helpful if package maintainers would check this
   JC> and previous
   JC> changes by running their code against the r-devel version of
   JC> R, before
   JC> that becomes 2.9.0.  Please report any new errors (provided,
   JC> of course,
   JC> that the same code works with 2.8.1).
   JC>
   JC> John
   JC>
  

Dear John,

it seems that S3 methods for an S4 class which extents a
matrix cannot be defined as it used to be the case in 2.8.1.

For example

## code
setClass("aTest",
         representation(.Data = "matrix",
                        comment = "character"))


c1 <- new("aTest", .Data = matrix(1:4, ncol = 2), comment = "aTest")

# it seems that it is no longer possible to define an S3
# method for the class aTest

print.aTest <- function(x, ...)
{
    cat("\n", x at comment, "\n")
    print(getDataPart(x))
}

print.aTest(c1)
print(c1) # works in 2.8.1

# another example could be
as.matrix.aTest <- function(x, ...) getDataPart(x)

as.matrix.aTest(c1)
as.matrix(c1) # works in 2.8.1

## end code


Is this the expected behavior?


Best regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From ripley at stats.ox.ac.uk  Mon Mar  9 10:12:02 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Mar 2009 09:12:02 +0000 (GMT)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
	<49B07B45.3040308@gmail.com>
	<alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.00.0903090910590.25123@gannet.stats.ox.ac.uk>

I've found the discrepancy, so the patched code from current dloess is 
now available in R-patched and R-devel.

On Fri, 6 Mar 2009, Prof Brian Ripley wrote:

> On Thu, 5 Mar 2009, Benjamin Tyner wrote:
>
>> Hi
>> 
>> Nice to hear from you Ryan. I also do not have the capability to debug on 
>> windows; however, there is a chance that the behavior you are seeing is 
>> caused by the following bug noted in my thesis (available on ProQuest; 
>> email me if you don't have access):
>> 
>> "When lambda = 0 there are no local slopes to aid the blending algorithm, 
>> yet the
>> interpolator would still assume they were available, and thus use arbitrary 
>> values
>> from memory. This had implications for both fit and tr[L] computation. In 
>> the
>> updated code these are set equal to zero which seems the best automatic 
>> rule when
>> lambda = 0." [lambda refers to degree]
>> 
>> I submitted a bug fix to Eric Grosse, the maintainer of the netlib 
>> routines; the fixed lines of fortran are identified in the comments at 
>> (just search for my email address):
>> 
>> http://www.netlib.org/a/loess
>> 
>> These fixes would be relatively simple to incorporate into R's version of 
>> loessf.f
>
> The fixes from dloess even more simply, since R's code is based on dloess. 
> Thank you for the suggestion.
>
> Given how tricky this is to reproduce, I went back to my example under 
> valgrind.  If I use the latest dloess code, it crashes, but by selectively 
> importing some of the differences I can get it to work.
>
> So it looks as if we are on the road to a solution, but something in the 
> current version (not necessarily in these changes) is incompatible with the 
> current R code and I need to dig further (not for a few days).
>
>> Alternatively, a quick check would be for someone to compile the source 
>> package at https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz and 
>> test it on windows. Though this package incorporates this and a few other 
>> fixes, please be aware that it the routines are converted to C and thus 
>> there is a slight performance hit compared to the fortran.
>> 
>> Hope this helps,
>> Ben
>
> [...]
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From csardi.gabor at gmail.com  Mon Mar  9 11:56:41 2009
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Mon, 9 Mar 2009 11:56:41 +0100
Subject: [Rd] Windows builder down
Message-ID: <d70c15d40903090356n2db468bha5325da7abc61e01@mail.gmail.com>

Dear Uwe and all,

the build service at http://win-builder.r-project.org/ seems to be
down. Do you have any information on whether and when it will be
functional again?

Best Regards,
Gabor

-- 
Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM


From rpeng at jhsph.edu  Mon Mar  9 13:17:49 2009
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 9 Mar 2009 08:17:49 -0400
Subject: [Rd] patch for 'merge' docs
In-Reply-To: <93D7EDD5-4C4F-422A-9324-DF18E37FE269@stat.berkeley.edu>
References: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>
	<93D7EDD5-4C4F-422A-9324-DF18E37FE269@stat.berkeley.edu>
Message-ID: <66f3bd910903090517j334ec015u99ef366cc56f668c@mail.gmail.com>

Hmm, I see what you mean, and I'd be willing to accept that logic if I
could find a single other instance in the R documentation where that
shorthand was used. But I suppose this might be the only instance
where such a shorthand is necessary.

-roger

On Sun, Mar 8, 2009 at 9:30 PM, Kasper Daniel Hansen
<khansen at stat.berkeley.edu> wrote:
> Roger
>
> (I think) L is shorthand for some logical value, ie. TRUE or FALSE. That has
> always been pretty clear to me. Your patch was stripped.
>
> Kasper
>
> On Mar 8, 2009, at 18:20 , Roger D. Peng wrote:
>
>> I've never quite understood the documentation for the 'all' argument
>> to 'merge'. I'm pretty sure using 'all = L' doesn't work but I'm open
>> to correction here. In any event, I've attached a patch.
>>
>> -roger
>>
>> --
>> Roger D. Peng ?| ?http://www.biostat.jhsph.edu/~rpeng/
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From P.Dalgaard at biostat.ku.dk  Mon Mar  9 13:47:01 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 09 Mar 2009 13:47:01 +0100
Subject: [Rd] patch for 'merge' docs
In-Reply-To: <66f3bd910903090517j334ec015u99ef366cc56f668c@mail.gmail.com>
References: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>	<93D7EDD5-4C4F-422A-9324-DF18E37FE269@stat.berkeley.edu>
	<66f3bd910903090517j334ec015u99ef366cc56f668c@mail.gmail.com>
Message-ID: <49B50FC5.7080206@biostat.ku.dk>

Roger D. Peng wrote:
> Hmm, I see what you mean, and I'd be willing to accept that logic if I
> could find a single other instance in the R documentation where that
> shorthand was used. But I suppose this might be the only instance
> where such a shorthand is necessary.

Could you repeat what the patch was (presumably your mailer claimed that
it was non-text)?

The text could probably improved if it confuses the reader. Most of what
it says is actually implied by the argument defaults (all.x=all,
all.y=all), and it is not perfectly logical anyway (all sets the
_default_ for all.x and all.y, but you can still set e.g. all=T, all.y=F).

I think we could simplify the text to something like

     all: logical; Provides a convenient way to set both 'all.x' and
             'all.y' (defined below).

> -roger
> 
> On Sun, Mar 8, 2009 at 9:30 PM, Kasper Daniel Hansen
> <khansen at stat.berkeley.edu> wrote:
>> Roger
>>
>> (I think) L is shorthand for some logical value, ie. TRUE or FALSE. That has
>> always been pretty clear to me. Your patch was stripped.
>>
>> Kasper
>>
>> On Mar 8, 2009, at 18:20 , Roger D. Peng wrote:
>>
>>> I've never quite understood the documentation for the 'all' argument
>>> to 'merge'. I'm pretty sure using 'all = L' doesn't work but I'm open
>>> to correction here. In any event, I've attached a patch.
>>>
>>> -roger
>>>
>>> --
>>> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
> 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From ligges at statistik.tu-dortmund.de  Mon Mar  9 14:02:37 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 09 Mar 2009 14:02:37 +0100
Subject: [Rd] Windows builder down
In-Reply-To: <d70c15d40903090356n2db468bha5325da7abc61e01@mail.gmail.com>
References: <d70c15d40903090356n2db468bha5325da7abc61e01@mail.gmail.com>
Message-ID: <49B5136D.1010502@statistik.tu-dortmund.de>



G?bor Cs?rdi wrote:
> Dear Uwe and all,
> 
> the build service at http://win-builder.r-project.org/ seems to be
> down. Do you have any information on whether and when it will be
> functional again?


No idea what happened. The Webserver process dies. Should be running 
again. Thanks for your message!

Best,
Uwe



> Best Regards,
> Gabor
>


From rpeng at jhsph.edu  Mon Mar  9 14:18:55 2009
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 9 Mar 2009 09:18:55 -0400
Subject: [Rd] patch for 'merge' docs
In-Reply-To: <49B50FC5.7080206@biostat.ku.dk>
References: <66f3bd910903081820g75a3260ew1ce1c5864b17c711@mail.gmail.com>
	<93D7EDD5-4C4F-422A-9324-DF18E37FE269@stat.berkeley.edu>
	<66f3bd910903090517j334ec015u99ef366cc56f668c@mail.gmail.com>
	<49B50FC5.7080206@biostat.ku.dk>
Message-ID: <66f3bd910903090618k1c22d5c9xcad4a0d52133fe87@mail.gmail.com>

My patch was not particularly great. I think the Peter's alternative
makes (more) sense.

-roger

On Mon, Mar 9, 2009 at 8:47 AM, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
> Roger D. Peng wrote:
>> Hmm, I see what you mean, and I'd be willing to accept that logic if I
>> could find a single other instance in the R documentation where that
>> shorthand was used. But I suppose this might be the only instance
>> where such a shorthand is necessary.
>
> Could you repeat what the patch was (presumably your mailer claimed that
> it was non-text)?
>
> The text could probably improved if it confuses the reader. Most of what
> it says is actually implied by the argument defaults (all.x=all,
> all.y=all), and it is not perfectly logical anyway (all sets the
> _default_ for all.x and all.y, but you can still set e.g. all=T, all.y=F).
>
> I think we could simplify the text to something like
>
> ? ? all: logical; Provides a convenient way to set both 'all.x' and
> ? ? ? ? ? ? 'all.y' (defined below).
>
>> -roger
>>
>> On Sun, Mar 8, 2009 at 9:30 PM, Kasper Daniel Hansen
>> <khansen at stat.berkeley.edu> wrote:
>>> Roger
>>>
>>> (I think) L is shorthand for some logical value, ie. TRUE or FALSE. That has
>>> always been pretty clear to me. Your patch was stripped.
>>>
>>> Kasper
>>>
>>> On Mar 8, 2009, at 18:20 , Roger D. Peng wrote:
>>>
>>>> I've never quite understood the documentation for the 'all' argument
>>>> to 'merge'. I'm pretty sure using 'all = L' doesn't work but I'm open
>>>> to correction here. In any event, I've attached a patch.
>>>>
>>>> -roger
>>>>
>>>> --
>>>> Roger D. Peng ?| ?http://www.biostat.jhsph.edu/~rpeng/
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>
>
> --
> ? O__ ?---- Peter Dalgaard ? ? ? ? ? ? ?ster Farimagsgade 5, Entr.B
> ?c/ /'_ --- Dept. of Biostatistics ? ? PO Box 2099, 1014 Cph. K
> ?(*) \(*) -- University of Copenhagen ? Denmark ? ? ?Ph: ?(+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk) ? ? ? ? ? ? ?FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From guangchuangyu at gmail.com  Mon Mar  9 14:55:39 2009
From: guangchuangyu at gmail.com (guangchuang yu)
Date: Mon, 9 Mar 2009 21:55:39 +0800
Subject: [Rd] bug of *switch* function
Message-ID: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090309/175792a2/attachment.pl>

From P.Dalgaard at biostat.ku.dk  Mon Mar  9 15:21:32 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 09 Mar 2009 15:21:32 +0100
Subject: [Rd] bug of *switch* function
In-Reply-To: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
References: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
Message-ID: <49B525EC.7070004@biostat.ku.dk>

guangchuang yu wrote:
> Hi,
> 
> When I call the *switch* function first time, it works. but when I call it
> at the second time, it does nothing. The version I use is R version 2.9.0
> Under development (unstable) (2009-02-21 r47969)
> 
> 
> here is the output:
> 
>> organism="human"
>>     species <- switch(organism,
>         human <- "Hs",
>         fly <- "Dm",
>         mouse <- "Mm",
>         rat <- "Rn",
>         yeast <- "Sc"
>     )
>  species <- switch(organism,
> +   human <- "Hs",
> +   fly <- "Dm",
> +   mouse <- "Mm",
> +   rat <- "Rn",
> +   yeast <- "Sc"
> +  )
>> species
> [1] "Hs"
>> organism="yeast"
>>     species <- switch(organism,
>         human <- "Hs",
>         fly <- "Dm",
>         mouse <- "Mm",
>         rat <- "Rn",
>         yeast <- "Sc"
>     )
>  species <- switch(organism,
> +   human <- "Hs",
> +   fly <- "Dm",
> +   mouse <- "Mm",
> +   rat <- "Rn",
> +   yeast <- "Sc"
> +  )
>> species
> [1] "Hs"
> 
> 
> when I change *organism* to "yeast", and call *switch* function again,
> *species* suppose to be changed to "Sc", but it remain it's original value.
> 
> You can see my screenshot at
> http://ygc.azpala.com/2009/03/09/bug-of-r-29-dev
> 

Wrong syntax. Check the examples of ?switch.

If the first argument to switch is not numeric, and does not match the
name of any named argument (of which you have none), then the result is
 the first unnamed argument (i.e. "Hs").

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From jeff.a.ryan at gmail.com  Mon Mar  9 15:31:13 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 9 Mar 2009 09:31:13 -0500
Subject: [Rd] bug of *switch* function
In-Reply-To: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
References: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
Message-ID: <e8e755250903090731g66ba567fq63c37810f7c9b8d@mail.gmail.com>

This isn't a bug in R.

You are assigning within the switch statement, and it is returning the
first TRUE value (human).

Use "=" not "<-"

species <- switch(organism, human="HS", fly="DM", yeast="SC")
> species
[1] "SC"


HTH
Jeff

On Mon, Mar 9, 2009 at 8:55 AM, guangchuang yu <guangchuangyu at gmail.com> wrote:
> Hi,
>
> When I call the *switch* function first time, it works. but when I call it
> at the second time, it does nothing. The version I use is R version 2.9.0
> Under development (unstable) (2009-02-21 r47969)
>
>
> here is the output:
>
>> organism="human"
>> ? ? species <- switch(organism,
> ? ? ? ?human <- "Hs",
> ? ? ? ?fly <- "Dm",
> ? ? ? ?mouse <- "Mm",
> ? ? ? ?rat <- "Rn",
> ? ? ? ?yeast <- "Sc"
> ? ?)
> ?species <- switch(organism,
> + ? human <- "Hs",
> + ? fly <- "Dm",
> + ? mouse <- "Mm",
> + ? rat <- "Rn",
> + ? yeast <- "Sc"
> + ?)
>> species
> [1] "Hs"
>> organism="yeast"
>> ? ? species <- switch(organism,
> ? ? ? ?human <- "Hs",
> ? ? ? ?fly <- "Dm",
> ? ? ? ?mouse <- "Mm",
> ? ? ? ?rat <- "Rn",
> ? ? ? ?yeast <- "Sc"
> ? ?)
> ?species <- switch(organism,
> + ? human <- "Hs",
> + ? fly <- "Dm",
> + ? mouse <- "Mm",
> + ? rat <- "Rn",
> + ? yeast <- "Sc"
> + ?)
>> species
> [1] "Hs"
>
>
> when I change *organism* to "yeast", and call *switch* function again,
> *species* suppose to be changed to "Sc", but it remain it's original value.
>
> You can see my screenshot at
> http://ygc.azpala.com/2009/03/09/bug-of-r-29-dev
>
> --
> Bests,
> Guangchuang Yu
>
> --~--~---------~--~----~------------~-------~--~----~
> Rm 848 Dept 9
> Institute of Radiation Medicine
> 27 Taiping Rd. Haidian Dist.
> Beijing, 100850, China
> Telephone: (86)-010-66931422
> Mobile: +86-13439009806
> Email: guangchuangyu at gmail.com
> -~----------~----~----~----~------~----~------~--~---
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From guangchuangyu at gmail.com  Mon Mar  9 15:35:06 2009
From: guangchuangyu at gmail.com (guangchuang yu)
Date: Mon, 9 Mar 2009 22:35:06 +0800
Subject: [Rd] bug of *switch* function
In-Reply-To: <e8e755250903090731g66ba567fq63c37810f7c9b8d@mail.gmail.com>
References: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
	<e8e755250903090731g66ba567fq63c37810f7c9b8d@mail.gmail.com>
Message-ID: <bc1181630903090735n4cafc4dak11c404394814ca4a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090309/36e7654d/attachment.pl>

From josh.m.ulrich at gmail.com  Mon Mar  9 15:46:31 2009
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Mon, 9 Mar 2009 09:46:31 -0500
Subject: [Rd] bug of *switch* function
In-Reply-To: <bc1181630903090735n4cafc4dak11c404394814ca4a@mail.gmail.com>
References: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
	<e8e755250903090731g66ba567fq63c37810f7c9b8d@mail.gmail.com>
	<bc1181630903090735n4cafc4dak11c404394814ca4a@mail.gmail.com>
Message-ID: <8cca69990903090746u7600e052l7244603c974616e6@mail.gmail.com>

Because "<-" assigs a value.  It does not name the alternatives.
Again, please read ?switch.

These two examples are the same:
> organism <- 'foo'
> (species <- switch(organism, human <- "HS", fly <- "DM", yeast <- "SC"))
[1] "HS"
> (species <- switch(organism, "HS", "DM", "SC"))
[1] "HS"


Josh
--
http://quantemplation.blogspot.com



On Mon, Mar 9, 2009 at 9:35 AM, guangchuang yu <guangchuangyu at gmail.com> wrote:
> But Why ?
>
> Why can not use "<-" ?
>
> On Mon, Mar 9, 2009 at 10:31 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
>
>> This isn't a bug in R.
>>
>> You are assigning within the switch statement, and it is returning the
>> first TRUE value (human).
>>
>> Use "=" not "<-"
>>
>> species <- switch(organism, human="HS", fly="DM", yeast="SC")
>> > species
>> [1] "SC"
>>
>>
>> HTH
>> Jeff
>>
>> On Mon, Mar 9, 2009 at 8:55 AM, guangchuang yu <guangchuangyu at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > When I call the *switch* function first time, it works. but when I call
>> it
>> > at the second time, it does nothing. The version I use is R version 2.9.0
>> > Under development (unstable) (2009-02-21 r47969)
>> >
>> >
>> > here is the output:
>> >
>> >> organism="human"
>> >> ? ? species <- switch(organism,
>> > ? ? ? ?human <- "Hs",
>> > ? ? ? ?fly <- "Dm",
>> > ? ? ? ?mouse <- "Mm",
>> > ? ? ? ?rat <- "Rn",
>> > ? ? ? ?yeast <- "Sc"
>> > ? ?)
>> > ?species <- switch(organism,
>> > + ? human <- "Hs",
>> > + ? fly <- "Dm",
>> > + ? mouse <- "Mm",
>> > + ? rat <- "Rn",
>> > + ? yeast <- "Sc"
>> > + ?)
>> >> species
>> > [1] "Hs"
>> >> organism="yeast"
>> >> ? ? species <- switch(organism,
>> > ? ? ? ?human <- "Hs",
>> > ? ? ? ?fly <- "Dm",
>> > ? ? ? ?mouse <- "Mm",
>> > ? ? ? ?rat <- "Rn",
>> > ? ? ? ?yeast <- "Sc"
>> > ? ?)
>> > ?species <- switch(organism,
>> > + ? human <- "Hs",
>> > + ? fly <- "Dm",
>> > + ? mouse <- "Mm",
>> > + ? rat <- "Rn",
>> > + ? yeast <- "Sc"
>> > + ?)
>> >> species
>> > [1] "Hs"
>> >
>> >
>> > when I change *organism* to "yeast", and call *switch* function again,
>> > *species* suppose to be changed to "Sc", but it remain it's original
>> value.
>> >
>> > You can see my screenshot at
>> > http://ygc.azpala.com/2009/03/09/bug-of-r-29-dev
>> >
>> > --
>> > Bests,
>> > Guangchuang Yu
>> >
>> > --~--~---------~--~----~------------~-------~--~----~
>> > Rm 848 Dept 9
>> > Institute of Radiation Medicine
>> > 27 Taiping Rd. Haidian Dist.
>> > Beijing, 100850, China
>> > Telephone: (86)-010-66931422
>> > Mobile: +86-13439009806
>> > Email: guangchuangyu at gmail.com
>> > -~----------~----~----~----~------~----~------~--~---
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>
>
>
> --
> Bests,
> Guangchuang Yu
>
> --~--~---------~--~----~------------~-------~--~----~
> Rm 848 Dept 9
> Institute of Radiation Medicine
> 27 Taiping Rd. Haidian Dist.
> Beijing, 100850, China
> Telephone: (86)-010-66931422
> Mobile: +86-13439009806
> Email: guangchuangyu at gmail.com
> -~----------~----~----~----~------~----~------~--~---
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From therneau at mayo.edu  Mon Mar  9 16:29:48 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 9 Mar 2009 10:29:48 -0500 (CDT)
Subject: [Rd] Package issue
Message-ID: <200903091529.n29FTmg00011@hsrnfs-101.mayo.edu>

> 2. R CMD check gives dozens of warnings ...

 Yes, I see a lot of warnings too, but I think that they can and should be 
ignored.
  1. There is a set where the generic function has "..." and my realization of 
the generic has a named argument.  But this is exactly what the ... is for in a 
generic!  
  
  2. Undocumented objects and classes.  I have a couple to fill in, agreed.  But 
I don't agree with CMD check's admonition to add a page for every instance of a 
method.  For instance diag() for a bdsmatrix is no different than for any other 
matrix, so what is there to document?
  
  I'm willing to be corrected on this.

  3. The 00install.out file showed one mismatched brace in one .Rd file.  I'll 
fix that.
  
  4. The 00check.log file gives a WARNING that the src directory contains object 
files.  This is very odd, since the CMD check process itself put them there.

---

> .... before it stops in gtest.R.  There is no gchol2.R!

 This was my mistake in the original message.  It perhaps comes from trying to 
send something out as I was heading for the door.  My apologies.

  To reprise, my problem was a test (gtest.R) that ran perfectly when the code 
was local, but failed when it was attached as a library.
  To understand the error better I used R CMD INSTALL to create a local library 
and ran the tests there.  The problem was not diag() as I had supposed but 
as.matrix.gchol.  I had forgotton one S3method line in the NAMESPACE file.
 
  The library now loads and tests correctly.  
  
  	Terry T.


From dsoudant at ifremer.fr  Mon Mar  9 16:35:06 2009
From: dsoudant at ifremer.fr (dsoudant at ifremer.fr)
Date: Mon,  9 Mar 2009 16:35:06 +0100 (CET)
Subject: [Rd] [boot] bootstrap issue when at least one strata has only one
	observation (PR#13584)
Message-ID: <20090309153506.D419F283431A@mail.pubhealth.ku.dk>

Full_Name: Dominique Soudant
Version: 2.4.1
OS: Winbdows
Submission from: (NULL) (134.246.54.61)


R 2.4.1
boot 1.2-27 

Let us consider the following example with 8 strata, one observation for each :

> library(boot)
> df <- data.frame(Values=runif(8),month=1:8)
> df
      Values month
1 0.02721540     1
2 0.13618392     2
3 0.99979095     3
4 0.80441083     4
5 0.42374115     5
6 0.04928531     6
7 0.34387447     7
8 0.13277458     8
> P90 <- function(DataIn,i){
+   DataIn <- DataIn[i,]
+   P90 <- round(quantile(as.numeric(DataIn$Values)
+                         ,probs=0.9
+                         ,names=FALSE
+                         ,type=4)
+               ,digits=1)
+   return(P90)
+ }
> 
> bootP90 <- boot(df,P90,10,strata=df$month)
> bootP90$t
      [,1]
 [1,]  0.2
 [2,]  0.5
 [3,]  0.8
 [4,]  0.2
 [5,]  0.2
 [6,]  1.0
 [7,]  0.5
 [8,]  1.0
 [9,]  0.8
[10,]  1.0

Results are differents, they should be equal. I guess that the issue is coming
from the function ordinary.array() from the boot package : 

ordinary.array <- function (n, R, strata)
{
    output <- matrix(0, R, n)
    inds <- as.integer(names(table(strata)))
    for (is in inds) {
        gp <- c(1:n)[strata == is]
        output[, gp] <- matrix(sample(gp, R * length(gp), replace = TRUE),
            nrow = R)
    }
    output
}

> ordinary.array(8,10,1:8)
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
 [1,]    1    1    2    2    1    1    5    2
 [2,]    1    1    2    2    3    3    2    5
 [3,]    1    2    1    4    2    1    1    7
 [4,]    1    1    3    2    5    5    3    6
 [5,]    1    1    2    4    5    3    7    1
 [6,]    1    2    2    4    4    6    1    8
 [7,]    1    1    2    2    4    2    7    5
 [8,]    1    2    3    2    3    4    1    7
 [9,]    1    2    2    1    1    3    1    2
[10,]    1    1    2    4    5    1    1    5

In ordinary.array(), the issue is coming from sample() : 
[quote]If x has length 1 and x >= 1, sampling takes place from 1:x[/quote]
Note that when only one strata has only one observation, the problem is
identical 
> ordinary.array(7,10,c(rep(1:3,each=2),4))
      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
 [1,]    1    2    3    3    6    5    6
 [2,]    2    2    3    4    5    5    7
 [3,]    2    2    4    4    6    5    5
 [4,]    1    1    4    4    6    5    1
 [5,]    2    2    3    3    6    5    7
 [6,]    1    2    3    4    5    5    1
 [7,]    1    2    4    3    6    6    5
 [8,]    2    1    3    4    5    6    2
 [9,]    2    2    3    4    6    6    4
[10,]    2    2    4    3    6    5    2 
but less detectable in the results.

The same results are obtained with : 
R 2.8.1
boot 1.2-35

Best regards.


From jmc at r-project.org  Mon Mar  9 17:53:06 2009
From: jmc at r-project.org (John Chambers)
Date: Mon, 09 Mar 2009 09:53:06 -0700
Subject: [Rd] A Design Error (Re:  S4 objects for S3 methods)
In-Reply-To: <20090309091944.2d5c594d@mimi>
References: <49B19FB0.9030606@r-project.org> <20090309091944.2d5c594d@mimi>
Message-ID: <49B54972.7040807@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090309/6004907e/attachment.pl>

From murdoch at stats.uwo.ca  Mon Mar  9 18:24:24 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 09 Mar 2009 13:24:24 -0400
Subject: [Rd] Package issue
In-Reply-To: <200903091529.n29FTmg00011@hsrnfs-101.mayo.edu>
References: <200903091529.n29FTmg00011@hsrnfs-101.mayo.edu>
Message-ID: <49B550C8.8@stats.uwo.ca>

On 3/9/2009 11:29 AM, Terry Therneau wrote:
>> 2. R CMD check gives dozens of warnings ...
> 
>  Yes, I see a lot of warnings too, but I think that they can and should be 
> ignored.
>   1. There is a set where the generic function has "..." and my realization of 
> the generic has a named argument.  But this is exactly what the ... is for in a 
> generic!  

This could cause trouble for users.  If the generic has a ... arg, a 
user has been promised that they can use any arguments there.  You might 
want it to be an error to use an arg that isn't supported by the 
particular class the user has, but it's better just to ignore the extra 
args (and document that you'll do that), rather than raise an error when 
a user uses one.


>   
>   2. Undocumented objects and classes.  I have a couple to fill in, agreed.  But 
> I don't agree with CMD check's admonition to add a page for every instance of a 
> method.  For instance diag() for a bdsmatrix is no different than for any other 
> matrix, so what is there to document?

You can just point to the diag.Rd page in your documentation.  In this 
case, that's a little inconvenient because you didn't write the generic, 
so you do need a whole page for diag.bdsmatrix.  (That page can handle 
lots of other methods for standard generics too.)  But if you had 
written the generic, it's simply a matter of adding another couple of 
lines to the generic's page.  It's useful, because it gives you a chance 
to document which optional parameters are supported by your particular 
method.

>   I'm willing to be corrected on this.
> 
>   3. The 00install.out file showed one mismatched brace in one .Rd file.  I'll 
> fix that.
>   
>   4. The 00check.log file gives a WARNING that the src directory contains object 
> files.  This is very odd, since the CMD check process itself put them there.

You can ignore this error if you don't get it when checking the source 
tarball.  If you get it there, that's not ignorable.  (I think R-forge 
checks the directory rather than the tarball, not sure what Uwe does.)

Duncan Murdoch

> ---
> 
>> .... before it stops in gtest.R.  There is no gchol2.R!
> 
>  This was my mistake in the original message.  It perhaps comes from trying to 
> send something out as I was heading for the door.  My apologies.
> 
>   To reprise, my problem was a test (gtest.R) that ran perfectly when the code 
> was local, but failed when it was attached as a library.
>   To understand the error better I used R CMD INSTALL to create a local library 
> and ran the tests there.  The problem was not diag() as I had supposed but 
> as.matrix.gchol.  I had forgotton one S3method line in the NAMESPACE file.
>  
>   The library now loads and tests correctly.  
>   
>   	Terry T.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon Mar  9 19:19:44 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 09 Mar 2009 19:19:44 +0100
Subject: [Rd] Package issue
In-Reply-To: <49B550C8.8@stats.uwo.ca>
References: <200903091529.n29FTmg00011@hsrnfs-101.mayo.edu>
	<49B550C8.8@stats.uwo.ca>
Message-ID: <49B55DC0.7050408@statistik.tu-dortmund.de>



Duncan Murdoch wrote:
> On 3/9/2009 11:29 AM, Terry Therneau wrote:
>>> 2. R CMD check gives dozens of warnings ...
>>
>>  Yes, I see a lot of warnings too, but I think that they can and 
>> should be ignored.
>>   1. There is a set where the generic function has "..." and my 
>> realization of the generic has a named argument.  But this is exactly 
>> what the ... is for in a generic!  
> 
> This could cause trouble for users.  If the generic has a ... arg, a 
> user has been promised that they can use any arguments there.  You might 
> want it to be an error to use an arg that isn't supported by the 
> particular class the user has, but it's better just to ignore the extra 
> args (and document that you'll do that), rather than raise an error when 
> a user uses one.
> 
> 
>>     2. Undocumented objects and classes.  I have a couple to fill in, 
>> agreed.  But I don't agree with CMD check's admonition to add a page 
>> for every instance of a method.  For instance diag() for a bdsmatrix 
>> is no different than for any other matrix, so what is there to document?
> 
> You can just point to the diag.Rd page in your documentation.  In this 
> case, that's a little inconvenient because you didn't write the generic, 
> so you do need a whole page for diag.bdsmatrix.  (That page can handle 
> lots of other methods for standard generics too.)  But if you had 
> written the generic, it's simply a matter of adding another couple of 
> lines to the generic's page.  It's useful, because it gives you a chance 
> to document which optional parameters are supported by your particular 
> method.
> 
>>   I'm willing to be corrected on this.
>>
>>   3. The 00install.out file showed one mismatched brace in one .Rd 
>> file.  I'll fix that.
>>     4. The 00check.log file gives a WARNING that the src directory 
>> contains object files.  This is very odd, since the CMD check process 
>> itself put them there.
> 
> You can ignore this error if you don't get it when checking the source 
> tarball.  If you get it there, that's not ignorable.  (I think R-forge 
> checks the directory rather than the tarball, not sure what Uwe does.)

Neither, I am checking in maintainer's mode (which is close to checking 
on a directory, but also somewhat different, particularly in this case). 
Anyway, in principle check assumes to run on the tarball but it also 
allows to check on the directory.

Thanks for your explanations, being back in Dortmund since 1 day now 
there are so many administrative tasks ...

Best,
Uwe



> Duncan Murdoch
> 
>> ---
>>
>>> .... before it stops in gtest.R.  There is no gchol2.R!
>>
>>  This was my mistake in the original message.  It perhaps comes from 
>> trying to send something out as I was heading for the door.  My 
>> apologies.
>>
>>   To reprise, my problem was a test (gtest.R) that ran perfectly when 
>> the code was local, but failed when it was attached as a library.
>>   To understand the error better I used R CMD INSTALL to create a 
>> local library and ran the tests there.  The problem was not diag() as 
>> I had supposed but as.matrix.gchol.  I had forgotton one S3method line 
>> in the NAMESPACE file.
>>  
>>   The library now loads and tests correctly.          Terry T.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Mon Mar  9 19:32:43 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 9 Mar 2009 13:32:43 -0500 (CDT)
Subject: [Rd] Package issue
Message-ID: <200903091832.n29IWhg03500@hsrnfs-101.mayo.edu>

Duncan,
  When    
   The generic solve method has "(a, b, ...)"
   I have "solve.gchol(a, b, full=TRUE, ...)"
   
I was assuming that I would still get an error from CMD check.  These are the
ones that I argued as "unavoidable".  
But... I just checked, and none of those were the squawkers, only the few where
I negelected to put the ... in my function.
  So I stand corrected again. Your argument for inclusion of ... when the 
generic contains it is persuasive.
  
  
  Undocumented objects: I have messages about %*%, ], dim, dimnames, and diag; 
all of which did not have optional arguments.  I wrote manual pages for those 
generics that did, like solve, but see less use for those that don't.   I could 
add them to the class definition page though.
  
  
  Again, thanks to all for their help.
  
  	Terry T.


From macrakis at alum.mit.edu  Mon Mar  9 20:13:56 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 9 Mar 2009 15:13:56 -0400
Subject: [Rd] E`<`<rrors in recursive default argument references
Message-ID: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>

Tested in: R version 2.8.1 (2008-12-22) / Windows

Recursive default argument references normally give nice clear errors.
 In the first set of examples, you get the error:

  Error in ... :
  promise already under evaluation: recursive default argument
reference or earlier problems?

  (function(a = a) a      ) ()
  (function(a = a) c(a)   ) ()
  (function(a = a) a[1]   ) ()
  (function(a = a) a[[1]] ) ()
  (function(a = a) a$x    ) ()
  (function(a = a) mean(a) )   ()
  (function(a = a) sort(a) ) ()
  (function(a = a) as.list(a) ) ()

But in the following examples, R seems not to detect the 'promise
already under evaluation' condition and instead gets a stack overflow,
with the error message:

  Error: C stack usage is too close to the limit

  (function(a = a)  (a)    ) ()
  (function(a = a)  -a     ) ()
  (function(a = a) var(a) ) ()
  (function(a = a) sum(a) ) ()
  (function(a = a) is.vector(a) ) ()
  (function(a = a) as.numeric(a) ) ()

I don't understand why the two sets of examples behave differently.

            -s


From ripley at stats.ox.ac.uk  Mon Mar  9 20:36:33 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Mar 2009 19:36:33 +0000 (GMT)
Subject: [Rd] Parallel makes
Message-ID: <alpine.OSX.1.00.0903090948140.75856@tystie.local>

Now multi-core machines are more widely available, we have gotten to 
stress-test the parallel building capabilities of R and of packages. 
The current Windows and Mac build machines are both 8-core and I test 
on an 8-core machine.  These are all fairly recent changes of hardware 
and the following applies only to R-devel, the version to become 2.9.0 
next month.

Parallel builds of R under Unix-alikes have long been supported, and 
now allow rather more to be done in parallel.  Using 'make -j' will 
work on a machine with enough resources, and gives something like a 3x 
speed up.  THe main limiting factor is converting help, which is done 
serially and is likely remain so until we move to R-based conversion. 
New for this version is the ability to install in parallel (e.g. 'make 
-j install install-pdf').  It is also possible to check the R build in 
parallel, but the output is so intermingled that it is hard to see any 
discrepancies.  However, few people build R from scratch every day and 
for those with such powerful machines building R is probably already 
fast enough (ca 3 mins).

When installing or checking a single package, the only thing done in 
parallel is making any compiled code (2.8.x ran tests in the 'tests' 
directory in parallel, but this is not currently done).  The standard 
procedures work safely with parallel make, but users who write 
Makevars or Makefile files need to take this into account.  For 
example, yesterday's Rcsdp/src/Makevars has

PHONY: all

all: before $(SHLIB)

before: Csdp.ts

but this 'before' target has to be completed before $(SHLIB) can be 
built (and it failed to install for me).  I am aware that the 
documentation did not stress this sufficiently in the past, and 
'Writing R Extensions' has been revised to do so.  (And the package 
has been updated with alacrity, thank you.)

Because Windows users are much less likely to be aware of these issues 
and because of the last para below, Uwe and I tweaked the procedures 
for the Windows build machine so that packages are always 
installed/checked with a non-paralle make.

Installing/updating packages in parallel can help a lot, and we've 
made two changes to facilitate that.  First, there is a new option for 
R CMD INSTALL, --pkglock.  This uses locks on a per-package basis so 
prevents more than one process trying to install a package at the same 
time, but allows several packages to be installed to the same library 
simultaneously.  This places the onus on the caller to ensure that 
dependencies are installed first, and the 'Ncpus' option to 
install.packages() provides a way to marshall package installation to 
make best use of multiple CPUs.

Under Windows 'make all' and 'make recommended; (but not 'make 
distribution') can each be done in parallel.  There are some question 
marks over how well the 'make; used on Windows works in parallel (we 
found one case where it worked incorrectly and had to rethink 
share/make/winshlib.mk) so it should be used with caution.

Please give these new facilties a go and report (here) how you get 
on.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar  9 22:40:06 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 09 Mar 2009 22:40:06 +0100
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
Message-ID: <49B58CB6.6030804@idi.ntnu.no>

Stavros Macrakis wrote:
> Tested in: R version 2.8.1 (2008-12-22) / Windows
>
> Recursive default argument references normally give nice clear errors.
>  In the first set of examples, you get the error:
>
>   Error in ... :
>   promise already under evaluation: recursive default argument
> reference or earlier problems?
>
>   (function(a = a) a      ) ()
>   (function(a = a) c(a)   ) ()
>   (function(a = a) a[1]   ) ()
>   (function(a = a) a[[1]] ) ()
>   (function(a = a) a$x    ) ()
>   (function(a = a) mean(a) )   ()
>   (function(a = a) sort(a) ) ()
>   (function(a = a) as.list(a) ) ()
>
> But in the following examples, R seems not to detect the 'promise
> already under evaluation' condition and instead gets a stack overflow,
> with the error message:
>
>   Error: C stack usage is too close to the limit
>   

when i run these examples, the execution seems to get into an endless
loop with no error messages whatsoever.  how much time does it take
before you get the error?  (using r 2.8.0 and also the latest r-devel).

vQ

>   (function(a = a)  (a)    ) ()
>   (function(a = a)  -a     ) ()
>   

btw. ?'-' talks about '-' as a *binary* operator, but the only example
given there which uses '-' uses it as a *unary* operator.  since '-'()
complains that '-' takes 1 or 2 arguments, it might be a good idea to
acknowledge it in the man page.

>   (function(a = a) var(a) ) ()
>   (function(a = a) sum(a) ) ()
>   (function(a = a) is.vector(a) ) ()
>   (function(a = a) as.numeric(a) ) ()
>
> I don't understand why the two sets of examples behave differently.
>   

a bug in excel?

vQ


From macrakis at alum.mit.edu  Mon Mar  9 23:31:40 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 9 Mar 2009 18:31:40 -0400
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <49B58CB6.6030804@idi.ntnu.no>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
	<49B58CB6.6030804@idi.ntnu.no>
Message-ID: <8b356f880903091531p670869bdx7f9c68e67c145862@mail.gmail.com>

On Mon, Mar 9, 2009 at 5:40 PM, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> Stavros Macrakis wrote:
>> Tested in: R version 2.8.1 (2008-12-22) / Windows

> when i run these examples, the execution seems to get into an endless
> loop with no error messages whatsoever. ?how much time does it take
> before you get the error? ?(using r 2.8.0 and also the latest r-devel).

In 2.8.1/Windows (32 bit), they return immediately, though the
stack-overflow case is about 13x slower.

> system.time(for (i in 1:100) {trySilent((function(a=a)(a))())})
   user  system elapsed
   0.67    0.00    0.67
> system.time(for (i in 1:100) {trySilent((function(a=a)as.POSIXct(a))())})
   user  system elapsed
   0.05    0.00    0.05

Are you running under 64 bits?  How long does a vanilla infinite
recursion take to fail on your machine?  I get:

> system.time(for (i in 1:100) trySilent({fff <- function()fff(); fff()}))
   user  system elapsed
   0.27    0.00    0.26

         -s


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar  9 23:42:34 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 09 Mar 2009 23:42:34 +0100
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <8b356f880903091531p670869bdx7f9c68e67c145862@mail.gmail.com>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>	
	<49B58CB6.6030804@idi.ntnu.no>
	<8b356f880903091531p670869bdx7f9c68e67c145862@mail.gmail.com>
Message-ID: <49B59B5A.7010008@idi.ntnu.no>

Stavros Macrakis wrote:
> On Mon, Mar 9, 2009 at 5:40 PM, Wacek Kusnierczyk
> <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>   
>> Stavros Macrakis wrote:
>>     
>>> Tested in: R version 2.8.1 (2008-12-22) / Windows
>>>       
>
>   
>> when i run these examples, the execution seems to get into an endless
>> loop with no error messages whatsoever.  how much time does it take
>> before you get the error?  (using r 2.8.0 and also the latest r-devel).
>>     
>
> In 2.8.1/Windows (32 bit), they return immediately, though the
> stack-overflow case is about 13x slower.
>
>   
>> system.time(for (i in 1:100) {trySilent((function(a=a)(a))())})
>>     
>    user  system elapsed
>    0.67    0.00    0.67
>   

this won't stop within a minute, running at 100% cpu, have to kill the
process.

>> system.time(for (i in 1:100) {trySilent((function(a=a)as.POSIXct(a))())})
>>     
>    user  system elapsed
>    0.05    0.00    0.05
>   
   user  system elapsed
  0.064   0.000   0.067


> Are you running under 64 bits?  How long does a vanilla infinite
> recursion take to fail on your machine?  I get:
>   

32 bits ubuntu 8.04

>   
>> system.time(for (i in 1:100) trySilent({fff <- function()fff(); fff()}))
>>     
>    user  system elapsed
>    0.27    0.00    0.26
>   

   user  system elapsed
  0.204   0.008   0.212


vQ

PS i'm looking into the sources; in src/main/eval.c:317 there is a check
for whether the promise has been seen:

    if(PRSEEN(e))

it appears that when i evaluate

    (function(a=a) -a)()

the check is not passed (the condition is false -- promise not seen). 
seems like the evaluation goes into a loop before the promise is marked
as seen.  (or i misunderstand the code, likely.)

vQ


From p.dalgaard at biostat.ku.dk  Tue Mar 10 00:21:25 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 10 Mar 2009 00:21:25 +0100
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
Message-ID: <49B5A475.90105@biostat.ku.dk>

Stavros Macrakis wrote:
> Tested in: R version 2.8.1 (2008-12-22) / Windows
> 
> Recursive default argument references normally give nice clear errors.
>  In the first set of examples, you get the error:
> 
>   Error in ... :
>   promise already under evaluation: recursive default argument
> reference or earlier problems?
> 
>   (function(a = a) a      ) ()
>   (function(a = a) c(a)   ) ()
>   (function(a = a) a[1]   ) ()
>   (function(a = a) a[[1]] ) ()
>   (function(a = a) a$x    ) ()
>   (function(a = a) mean(a) )   ()
>   (function(a = a) sort(a) ) ()
>   (function(a = a) as.list(a) ) ()
> 
> But in the following examples, R seems not to detect the 'promise
> already under evaluation' condition and instead gets a stack overflow,
> with the error message:
> 
>   Error: C stack usage is too close to the limit
> 
>   (function(a = a)  (a)    ) ()
>   (function(a = a)  -a     ) ()
>   (function(a = a) var(a) ) ()
>   (function(a = a) sum(a) ) ()
>   (function(a = a) is.vector(a) ) ()
>   (function(a = a) as.numeric(a) ) ()
> 
> I don't understand why the two sets of examples behave differently.

Ouch!!!

This shouldn't happen, I'm pretty sure. In particular not the apparently 
unstoppable loop under Linux. Thanks for pointing it out.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From macrakis at alum.mit.edu  Tue Mar 10 00:31:53 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 9 Mar 2009 19:31:53 -0400
Subject: [Rd] bug of *switch* function
In-Reply-To: <8cca69990903090746u7600e052l7244603c974616e6@mail.gmail.com>
References: <bc1181630903090655o1db1a397leb831a804c202761@mail.gmail.com>
	<e8e755250903090731g66ba567fq63c37810f7c9b8d@mail.gmail.com>
	<bc1181630903090735n4cafc4dak11c404394814ca4a@mail.gmail.com>
	<8cca69990903090746u7600e052l7244603c974616e6@mail.gmail.com>
Message-ID: <8b356f880903091631m4f287214k399aa99ad2dddecb@mail.gmail.com>

On Mon, Mar 9, 2009 at 8:55 AM, guangchuang yu
<guangchuangyu at gmail.com> asked why switch(..., a <- 3, ...) doesn't
have the same effect as switch(..., a=3, ...).

In most contexts, `<-` and `=` are synonymous in R, and mean
assignment. In function-argument position, however, an infix `=` names
the argument.  Switch depends on the argument names.

            -s


From bpbryant at gmail.com  Tue Mar 10 00:57:58 2009
From: bpbryant at gmail.com (Ben Bryant)
Date: Mon, 9 Mar 2009 16:57:58 -0700
Subject: [Rd] Chunk of text won't show up when compiling Rd file
In-Reply-To: <49B0732B.70906@stats.uwo.ca>
References: <885c6fdd0903050929l15fa3213t10969af2ae303761@mail.gmail.com>
	<49B0732B.70906@stats.uwo.ca>
Message-ID: <885c6fdd0903091657i6b336d76id56df9a8d423628f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090309/8cc199d4/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Mar 10 08:41:44 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Mar 2009 07:41:44 +0000 (GMT)
Subject: [Rd] Chunk of text won't show up when compiling Rd file
In-Reply-To: <885c6fdd0903091657i6b336d76id56df9a8d423628f@mail.gmail.com>
References: <885c6fdd0903050929l15fa3213t10969af2ae303761@mail.gmail.com>
	<49B0732B.70906@stats.uwo.ca>
	<885c6fdd0903091657i6b336d76id56df9a8d423628f@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0903100720430.10577@gannet.stats.ox.ac.uk>

On Mon, 9 Mar 2009, Ben Bryant wrote:

> Greetings -
>
> Thanks for the response and apologies for the delay.
>
> I was actually unable to get even the example script for Rd2HTML to work in
> 2.9.0dev, which may be due to my lack of general programming savvy, or
> possibly my working on a windows machine?

So, no information on what went wrong.  Your example works for me in 
R-devel, even on Windows.

> In the meantime I found a workaround to address my immediate needs 
> (just including another section in the Rd file).  The most helpful I 
> can be with my current level of knowledge is to include a full Rd 
> text that reproduces the error, if someone would like to give it a 
> shot.  (below).

\value sections are somewhat special.  In versions < 2 of Rd format it 
starts out as a standard text section but the first \item macro turns 
it into a \describe list. And this *is* how they are documented:

'If a list with multiple values is returned, you can use entries of 
the form

           \item{comp_i}{Description of comp_i.}

for each component of the list returned. Optional text may precede 
this list (see the introductory example for rle).'

I take that to mean that text can only *precede* a list.  You are 
expecting something to work that is AFAICS undocumented and not 
intended to work.


In the current Rd2 conversion additional text after \item sections 
terminates the list, so this behaves more as you want (as a set of 
lists).  However, Rd2 conversion is not released as yet, and almost 
certainly will not be in 2.9.0.  (I don't think the change in 
behaviour has yet been agreed by R-core.)

>
> Thanks,
> -Ben
>
> %FAKE FUNCTION DOCUMENTATION TO ILLUSTRATE PROBLEM
>
> \name{fake}
> \alias{fake}
>
> \title{Fake function documentation}
> \description{This is a sample to show a possible bug in the Rd compiler,
> which may actually be generally desirable behavior, but behavior that is
> encoded in a somewhat opaque way.  See the Value section for what is going
> on.
> }
>
> \usage{
> sdprim(x, y = NULL)
> }
>
> \arguments{
>  \item{x}{The usual inputs.}
>  \item{y}{The usual outputs.}
> }
>
> \details{
> A good bit of text on the details.
> }
>
> \value{
> Here I have a paragraph giving the general description of the output form.
> Then I have an itemized list describing the elements.
>
>  \item{listobject1}{Description of list object 1}
>  \item{listobject2}{Description of list object 2}
> %... etc
>  \item{lastlistobject}{Description of the last list object}
>
> THEN, here I have a general description of the attributes, and the text
> represented by this sentence is what doesn't show up, because it's in
> between more of an itemized list.
>
>  \item{attribute1}{details of attribute 1}
>  \item{attribute2}{details of attribute 2}
>
> Then I have text here, and this text does show up.
> }
>
> \author{anonymous}
>
> \examples{
>
> #are not too relevant.
>
> }
>
> \keyword{robust}
>
>
>
>
>
>
> On Thu, Mar 5, 2009 at 5:49 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>
>> On 05/03/2009 12:29 PM, Ben Bryant wrote:
>>
>>> Greetings -
>>>
>>> I am trying to document the "value" section of a function.  The function
>>> returns a list, but the list itself also has attributes.  I would like to
>>> itemize the list entries, and itemize the attributes, but in between I
>>> would
>>> like to have a sentence or two about the attributes in general.  However,
>>> for some reason this intermediate sentence won't show up in the compiled
>>> version, so that it appears the attributes are all just elements in the
>>> returned list.  Something is making the assumption that the itemized list
>>> must be uninterrupted, and I don't know the code to tell it not to do
>>> that.
>>> I presume it is a very easy fix, but I haven't been able to get at it.
>>>
>>> I pasted some example explanatory Rd code below.
>>>
>>> Thanks!
>>> -Ben Bryant
>>>
>>
>> Could you give your example a try in R-devel, with one of the new
>> conversion functions, e.g. tools::Rd2HTML?  I don't think these new
>> functions are used by default even in R-devel, but if they solve your
>> problem, there will be less motivation to fix the legacy functions.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> %%%%% Just the Value Section:
>>>
>>> \value{
>>> Here I have a paragraph giving the general description of the output form.
>>> Then I have an itemized list describing the elements.
>>>
>>>   \item{listobject1}{Description of list object 1}
>>>   \item{listobject2}{Description of list object 2}
>>>  %... etc
>>>   \item{lastlistobject}{Description of the last list object}
>>>
>>> THEN, here I have a general description of the attributes, and the text
>>> represented by this sentence is what doesn't show up, because it's in
>>> between more of an itemized list.
>>>
>>>   \item{attribute1}{details of attribute 1}
>>>   \item{attribute 2}{details of attribute 2}
>>>
>>> Then I have text here, and this text does show up.
>>> }
>>>
>>> %%%%
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hkawakat at gmail.com  Tue Mar 10 08:51:42 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Tue, 10 Mar 2009 07:51:42 +0000
Subject: [Rd] r-devel tarball build failure on windows
Message-ID: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>

Hi,

On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
have cygwin on my path) -make all recommended- for the latest R-devel
tarball (svn revision: 48093) fails when trying to build the
recommended packages:

--- Making recommended packages

----- installing recommended package KernSmooth
Warning: invalid package 'KernSmooth.tgz'
Error: ERROR: no packages specified
make[1]: *** [KernSmooth.ts] Error 1
make: *** [recommended] Error 2

Looking at R_HOME/src/library/Recommended shows that none of the
timestamp files .ts are generated(?) in that directory. If I manually
create the empty timestamp files, build completes but -make check-
failed. I suspect something with my build tools is not right but what
could that be?

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From ligges at statistik.tu-dortmund.de  Tue Mar 10 09:06:21 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 10 Mar 2009 09:06:21 +0100
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
Message-ID: <49B61F7D.7020006@statistik.tu-dortmund.de>


Hiroyuki Kawakatsu wrote:
> Hi,
> 
> On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
> have cygwin on my path) -make all recommended- for the latest R-devel
> tarball (svn revision: 48093) fails when trying to build the
> recommended packages:


1. Have you asked make rsync-recommended before (i.e. are the packages 
actually there)?

2. If so, please install the cygwin dlls and try to remove cygwin from 
your path. The may very well be some version conflicts in I cannot build 
R / R packages if a full cygwin installation is around.

Uwe Ligges



> 
> --- Making recommended packages
> 
> ----- installing recommended package KernSmooth
> Warning: invalid package 'KernSmooth.tgz'
> Error: ERROR: no packages specified
> make[1]: *** [KernSmooth.ts] Error 1
> make: *** [recommended] Error 2
> 
> Looking at R_HOME/src/library/Recommended shows that none of the
> timestamp files .ts are generated(?) in that directory. If I manually
> create the empty timestamp files, build completes but -make check-
> failed. I suspect something with my build tools is not right but what
> could that be?
> 
> h.


From gabraham at csse.unimelb.edu.au  Tue Mar 10 11:02:07 2009
From: gabraham at csse.unimelb.edu.au (Gad Abraham)
Date: Tue, 10 Mar 2009 21:02:07 +1100
Subject: [Rd] S4 generic masking S3 generic when using namespace
Message-ID: <49B63A9F.60403@csse.unimelb.edu.au>

Hi,

I have two example packages, test1 and test2, where the only code in 
them is:

setGeneric("predict", function(object, ...) standardGeneric("predict"))

(get them from http://www.cs.mu.oz.au/~gabraham/test1.tar and 
http://www.cs.mu.oz.au/~gabraham/test2.tar)

The difference between them is that first does not have a namespace, and 
loads fine. The second has a namespace but generates a warning:
 > library(test2)

Attaching package: 'test2'


	The following object(s) are masked from package:stats :

	 predict



Is this an intended behaviour? If I ignore this masking warning, do I 
risk unintended consequences later down the track?

Thanks,
Gad



 > sessionInfo()
R version 2.8.1 (2008-12-22)
i386-apple-darwin8.11.1

locale:
en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] test2_0.1


-- 
Gad Abraham
MEng Student, Dept. CSSE and NICTA
The University of Melbourne
Parkville 3010, Victoria, Australia
email: gabraham at csse.unimelb.edu.au
web: http://www.csse.unimelb.edu.au/~gabraham


From dsoudant at ifremer.fr  Tue Mar 10 01:35:09 2009
From: dsoudant at ifremer.fr (dsoudant at ifremer.fr)
Date: Tue, 10 Mar 2009 01:35:09 +0100 (CET)
Subject: [Rd] [boot] bootstrap issue when at least one strata has only one
	(PR#13586)
Message-ID: <20090310003509.80BA0283416A@mail.pubhealth.ku.dk>

Full_Name: Dominique Soudant
Version: 2.4.1
OS: Winbdows
Submission from: (NULL) (134.246.54.61)


R 2.4.1
boot 1.2-27 

Let us consider the following example with 8 strata, one observation for each :

> library(boot)
> df <- data.frame(Values=runif(8),month=1:8)
> df
      Values month
1 0.02721540     1
2 0.13618392     2
3 0.99979095     3
4 0.80441083     4
5 0.42374115     5
6 0.04928531     6
7 0.34387447     7
8 0.13277458     8
> P90 <- function(DataIn,i){
+   DataIn <- DataIn[i,]
+   P90 <- round(quantile(as.numeric(DataIn$Values)
+                         ,probs=0.9
+                         ,names=FALSE
+                         ,type=4)
+               ,digits=1)
+   return(P90)
+ }
> 
> bootP90 <- boot(df,P90,10,strata=df$month)
> bootP90$t
      [,1]
 [1,]  0.2
 [2,]  0.5
 [3,]  0.8
 [4,]  0.2
 [5,]  0.2
 [6,]  1.0
 [7,]  0.5
 [8,]  1.0
 [9,]  0.8
[10,]  1.0

Results are differents, they should be equal. I guess that the issue is coming
from the function ordinary.array() from the boot package : 

ordinary.array <- function (n, R, strata)
{
    output <- matrix(0, R, n)
    inds <- as.integer(names(table(strata)))
    for (is in inds) {
        gp <- c(1:n)[strata == is]
        output[, gp] <- matrix(sample(gp, R * length(gp), replace = TRUE),
            nrow = R)
    }
    output
}

> ordinary.array(8,10,1:8)
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
 [1,]    1    1    2    2    1    1    5    2
 [2,]    1    1    2    2    3    3    2    5
 [3,]    1    2    1    4    2    1    1    7
 [4,]    1    1    3    2    5    5    3    6
 [5,]    1    1    2    4    5    3    7    1
 [6,]    1    2    2    4    4    6    1    8
 [7,]    1    1    2    2    4    2    7    5
 [8,]    1    2    3    2    3    4    1    7
 [9,]    1    2    2    1    1    3    1    2
[10,]    1    1    2    4    5    1    1    5

In ordinary.array(), the issue is coming from sample() : 
[quote]If x has length 1 and x >= 1, sampling takes place from 1:x[/quote]
Note that when only one strata has only one observation, the problem is
identical 
> ordinary.array(7,10,c(rep(1:3,each=2),4))
      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
 [1,]    1    2    3    3    6    5    6
 [2,]    2    2    3    4    5    5    7
 [3,]    2    2    4    4    6    5    5
 [4,]    1    1    4    4    6    5    1
 [5,]    2    2    3    3    6    5    7
 [6,]    1    2    3    4    5    5    1
 [7,]    1    2    4    3    6    6    5
 [8,]    2    1    3    4    5    6    2
 [9,]    2    2    3    4    6    6    4
[10,]    2    2    4    3    6    5    2 
but less detectable in the results.

The same results are obtained with : 
R 2.8.1
boot 1.2-35

Best regards.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From osklyar at maninvestments.com  Tue Mar 10 11:16:35 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Tue, 10 Mar 2009 10:16:35 -0000
Subject: [Rd] S4 generic masking S3 generic when using namespace
In-Reply-To: <49B63A9F.60403@csse.unimelb.edu.au>
References: <49B63A9F.60403@csse.unimelb.edu.au>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF72A@mildnpexmb01.maninvestments.ad.man.com>

Try using setGeneric("predict") without further arguments, this should
work as it will take the existing 'predict' definition and convert it
into S4 generic. This works nicely for me for all plot, print etc
methods

* R   
*** R 2.9.0 (svn -r 47821) [/share/research/R-devel/20090203/lib64/R]
***
> setGeneric("predict")
[1] "predict"
> predict
standardGeneric for "predict" defined from package "stats"

function (object, ...) 
standardGeneric("predict")
<environment: 0xe24b080>
Methods may be defined for arguments: object
Use  showMethods("predict")  for currently available ones.

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Gad Abraham
> Sent: 10 March 2009 10:02
> To: R-devel at r-project.org
> Subject: [Rd] S4 generic masking S3 generic when using namespace
> 
> Hi,
> 
> I have two example packages, test1 and test2, where the only code in 
> them is:
> 
> setGeneric("predict", function(object, ...) 
> standardGeneric("predict"))
> 
> (get them from http://www.cs.mu.oz.au/~gabraham/test1.tar and 
> http://www.cs.mu.oz.au/~gabraham/test2.tar)
> 
> The difference between them is that first does not have a 
> namespace, and 
> loads fine. The second has a namespace but generates a warning:
>  > library(test2)
> 
> Attaching package: 'test2'
> 
> 
> 	The following object(s) are masked from package:stats :
> 
> 	 predict
> 
> 
> 
> Is this an intended behaviour? If I ignore this masking warning, do I 
> risk unintended consequences later down the track?
> 
> Thanks,
> Gad
> 
> 
> 
>  > sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-apple-darwin8.11.1
> 
> locale:
> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] test2_0.1
> 
> 
> -- 
> Gad Abraham
> MEng Student, Dept. CSSE and NICTA
> The University of Melbourne
> Parkville 3010, Victoria, Australia
> email: gabraham at csse.unimelb.edu.au
> web: http://www.csse.unimelb.edu.au/~gabraham
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From P.Dalgaard at biostat.ku.dk  Tue Mar 10 11:52:48 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 10 Mar 2009 11:52:48 +0100
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <49B61F7D.7020006@statistik.tu-dortmund.de>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
	<49B61F7D.7020006@statistik.tu-dortmund.de>
Message-ID: <49B64680.4070406@biostat.ku.dk>

Uwe Ligges wrote:
> 
> Hiroyuki Kawakatsu wrote:
>> Hi,
>>
>> On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
>> have cygwin on my path) -make all recommended- for the latest R-devel
>> tarball (svn revision: 48093) fails when trying to build the
>> recommended packages:
> 
> 
> 1. Have you asked make rsync-recommended before (i.e. are the packages
> actually there)?
> 
> 2. If so, please install the cygwin dlls and try to remove cygwin from
> your path. The may very well be some version conflicts in I cannot build
> R / R packages if a full cygwin installation is around.
> 
> Uwe Ligges

This bit apjaworski last week, but the naughty boy didn't include
R-devel in the discussion....

It boils down to problems with symlink handling. You unpack the tar file
and the .tgz links look like ordinary files with strange contents to
other tools.

The workaround is to run

make Rpwd.exe
make link-recommended

(or, maybe, to unpack with a different tar version, but I really don't
know).

> 
> 
>>
>> --- Making recommended packages
>>
>> ----- installing recommended package KernSmooth
>> Warning: invalid package 'KernSmooth.tgz'
>> Error: ERROR: no packages specified
>> make[1]: *** [KernSmooth.ts] Error 1
>> make: *** [recommended] Error 2
>>
>> Looking at R_HOME/src/library/Recommended shows that none of the
>> timestamp files .ts are generated(?) in that directory. If I manually
>> create the empty timestamp files, build completes but -make check-
>> failed. I suspect something with my build tools is not right but what
>> could that be?
>>
>> h.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Mark.Bravington at csiro.au  Tue Mar 10 11:52:30 2009
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Tue, 10 Mar 2009 21:52:30 +1100
Subject: [Rd] suggestion/request: install.packages and unnecessary file
 modifications
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F87051705E427@exvic-mbx03.nexus.csiro.au>

Dear R-devel

When 'install.packages' runs, it updates all html files in all packages. Mostly, there seems to be no actual change to the html file contents, but the date/time does change. This has causing been me a bit of trouble, because I keep synchronized versions of R on several different machines, and whenever I install a package, many MB of file transfers are required; my slow upload link can't cope.

The culprit appears to be 'utils:::fixup.package.URLs'. Adding the commented lines below, near the end of the function, avoids the unnecessary rewrite.

Mark Bravington
CSIRO
Hobart
Australia

    for (f in files) {
        page <- readLines(f)
        old.page <- page # MVB
        page <- gsub(olddoc, doc, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(oldbase, base, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(oldutils, utils, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(oldgraphics, graphics, page, fixed = TRUE, 
            useBytes = TRUE)
        page <- gsub(oldstats, stats, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(olddata, datasets, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(oldgrD, grD, page, fixed = TRUE, useBytes = TRUE)
        page <- gsub(oldmeth, meth, page, fixed = TRUE, useBytes = TRUE)
        if( identical( page, old.page)) # MVB
    next # MVB
        out <- try(file(f, open = "w"), silent = TRUE)
        if (inherits(out, "try-error")) {
            warning(gettextf("cannot update '%s'", f), domain = NA)
            next
        }
        writeLines(page, out)
        close(out)
    }
    return(TRUE)
}


From Manuel.Eugster at stat.uni-muenchen.de  Tue Mar 10 12:45:18 2009
From: Manuel.Eugster at stat.uni-muenchen.de (Manuel J. A. Eugster)
Date: Tue, 10 Mar 2009 12:45:18 +0100
Subject: [Rd] [SoC09-Idea] cranlab.
Message-ID: <49B652CE.9060005@stat.uni-muenchen.de>

Hi everybody,

just another Google Summer of Code project idea.


Best,

Manuel.


----------------------------------------------------------------------

cranlab -- "You can't control what you can't measure" [0]


Mentor: Manuel J. A. Eugster


Summary: The aim of this project is the (1) implementation of software
metrics to analyze R packages and (2) the creation of a CRAN software
metrics monitor.


Required skills: Good R programming skills. Basic knowledge of
software engineering and software metrics measurements are useful.


Description: Software metrics are measures of some properties of
software. In software engineering they are used to monitor improvement
of projects; common metrics include 'source lines of code', 'code
coverage' or 'software package metrics' (see, e.g., [1]).

First step of this project is the implementation of an R package which
calculates software metrics of R packages. The implementation must be
flexible, i.e., a basic set of metrics will be implemented, but others
can be added later on.

Second step is the creation of a CRAN software metrics monitor. This
means a service which continuously calculates software metrics of CRAN
packages and provides the (raw) data. As a first analyzing step a
dashboard provides simple basic plots of the data.


Programming exercise: How many functions has the archetypes package [2]?
Write some R code which counts them.



[0] Tom DeMarco. Controlling Software Projects: Management,
     Measurement and Estimation
[1] http://en.wikipedia.org/wiki/Software_metrics
[2] http://cran.at.r-project.org/web/packages/archetypes/


From romain.francois at dbmail.com  Tue Mar 10 13:41:29 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 10 Mar 2009 13:41:29 +0100
Subject: [Rd] [SoC09-Idea] Integrated debugger
Message-ID: <49B65FF9.1030203@dbmail.com>

Hello,

Hello,

Here is an idea for a google summer of code project I am willing to mentor.

Romain


Summary: Create an integrated debugger.

Required skills: R skills. Experience of using a debugger. Front-end 
skills depending on the chosen front-end(s).

Description: Debugging R code usually involves a lot of work from the
command line with the use of functions such as browser, debug, trace, 
recover. The debug package provides additional debugging functionalities 
and concepts to R internal debugging capabilities: code display, 
graceful error recovery, line-numbered conditional breakpoints,
access to exit code, flow control, and full keyboard input.

The current front-end used by the debug package is based on tcltk, and
although tcltk offers universal portability wherever R is installed, it 
does not compete with current alternatives in terms of user-experience.

The goal of this project is to create an integrated debugger for R,
based on the debug package but coupled with another front-end. Possible
front-ends are listed below, ordered by current experience of the mentor.

- biocep [java,swing] : http://biocep-distrib.r-forge.r-project.org/
- sciviews-k [mozilla,javascript] 
http://www.sciviews.org/SciViews-K/index.html
- statet [java,eclipse,swt]: http://www.walware.de/goto/statet

If you are interested in the project: I you are coming
from an R standpoint, have a look at the debug package and make a few 
design suggestions about how the package could be modified to support 
alternative front-ends. If you come from a front-end standpoint,
make a few suggestions on how you would present the information.


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From chalabi at phys.ethz.ch  Tue Mar 10 14:26:41 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Tue, 10 Mar 2009 14:26:41 +0100
Subject: [Rd] A Design Error (Re:  S4 objects for S3 methods)
In-Reply-To: <49B54972.7040807@r-project.org>
References: <49B19FB0.9030606@r-project.org> <20090309091944.2d5c594d@mimi>
	<49B54972.7040807@r-project.org>
Message-ID: <20090310142641.0674d29c@mimi>

>>>> "JC" == John Chambers <jmc at r-project.org>
>>>> on Mon, 09 Mar 2009 09:53:06 -0700

   JC> As Yohan points out, and as we found in testing CRAN packages,
   JC> there are
   JC> a number of examples where programmers have written S3 methods
   JC> for S4
   JC> classes, such as print.aTest() below.
   JC>
   JC> This may well have seemed an easy and convenient mechanism,
   JC> but it is a
   JC> design error with potentially disastrous consequences.
   JC> Note that this
   JC> is fundamentally different from an S3 method defined for an
   JC> S3 class and
   JC> inherited by an S4 class that extends the S3 class.
   JC>
   JC> We haven't decided whether to re-enable this, but if so it
   JC> will be with
   JC> a warning at user call and/or at package check time.
   JC>
   JC> Please turn such methods into legitimate S4 methods.
   JC> Usually the change
   JC> is a simple call to setMethod(); in some cases, such as this
   JC> example you
   JC> may need a bit more work, such as a show() method to call
   JC> the print.*
   JC> function.
   JC>
   JC> DETAILS:
   JC>
   JC> There are at least two serious flaws in this mechanism, plus
   JC> some minor
   JC> defects.
   JC>
   JC> 1. S3 dispatch does not know about S4 class inheritance.
   JC> So if as a user of Yohan's code, for example, I define a class
   JC> setClass(bTest, contains = aTest)
   JC> then that class will not inherit any of the S3 methods.
   JC> In the case of
   JC> print, that will be obvious.  The disaster waiting to happen
   JC> is when the
   JC> method involves numerical results, in which case I may be
   JC> getting
   JC> erroneous results, with no hint of the problem.
   JC>
   JC> 2. Conversely, S4 dispatch does not know about the S3 method.
   JC> So, if my new class was:
   JC> setClass(bTest, contains = c(aTest, waffle7)
   JC> suppose waffle7 has some huge inheritance, in the midst of
   JC> which is a
   JC> method for a generic function of importance.  I expect to
   JC> inherit the
   JC> method for aTest because it's for a direct superclass, but I
   JC> won't, no
   JC> matter how far up the tree the other method occurs.  (Even if
   JC> point 1
   JC> were fixed)
   JC>
   JC> Again, this would be obvious for a print method, but potentially
   JC> disastrous elsewhere.
   JC>
   JC> There are other minor issues, such as efficiency: the S3 method
   JC> requires two dispatches and perhaps may do some extra copying.
   JC> But 1
   JC> and 2 are the killers.
   JC>
   JC> Just to anticipate a suggestion: Yes, we could perhaps fix 1
   JC> by adding
   JC> code to the S3 dispatch, but this would ambiguate the legitimate
   JC> attempt
   JC> to handle inherited valid S3 methods correctly.
   JC>
   JC> John

Dear John, 

Thank you for the detailed explanation.

I completely understand that it is a design error and that it should be
fixed.  As you said it is a matter of using 'setMethod'. 

My main concern is that such a change happens one month before a new
release. This is very little time for developers to make their packages
consistent with the new release.

As a side note, I have noticed that it is still possible to define S3
methods for S4 classes which do not contains a super-class like matrix.
But the disastrous consequences that you explained would still be
possible in my opinion.

setClass("aTest", representation(.Data = "matrix", comment = "character"))
a <- new("aTest", .Data = matrix(1:4, ncol = 2), comment = "aTest")
as.matrix.aTest <- function(x, ...) getDataPart(x)
as.matrix(a) # returns same S4 object

# but
setClass("bTest", representation(Data = "matrix", comment = "character"))
b <- new("bTest", Data = matrix(1:4, ncol = 2), comment = "hello")
as.matrix.bTest <- function(x, ...) b at Data
as.matrix(b) # does work

Are you planing to turn this off too?

Again, I understand that developers should conform with the S4 style
but a one month notice is very short in my opinion. Moreover adding a
warning in R CMD check would be the same because developer won't be
able to submit packages since CRAN only accepts packages which pass R
CMD check without warnings.

Best regards,
Yohan



-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From ligges at statistik.tu-dortmund.de  Tue Mar 10 15:11:30 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 10 Mar 2009 15:11:30 +0100
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <49B64680.4070406@biostat.ku.dk>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
	<49B61F7D.7020006@statistik.tu-dortmund.de>
	<49B64680.4070406@biostat.ku.dk>
Message-ID: <49B67512.6060309@statistik.tu-dortmund.de>



Peter Dalgaard wrote:
> Uwe Ligges wrote:
>> Hiroyuki Kawakatsu wrote:
>>> Hi,
>>>
>>> On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
>>> have cygwin on my path) -make all recommended- for the latest R-devel
>>> tarball (svn revision: 48093) fails when trying to build the
>>> recommended packages:
>>
>> 1. Have you asked make rsync-recommended before (i.e. are the packages
>> actually there)?
>>
>> 2. If so, please install the cygwin dlls and try to remove cygwin from
>> your path. The may very well be some version conflicts in I cannot build
>> R / R packages if a full cygwin installation is around.
>>
>> Uwe Ligges
> 
> This bit apjaworski last week, but the naughty boy didn't include
> R-devel in the discussion....
> 
> It boils down to problems with symlink handling. You unpack the tar file
> and the .tgz links look like ordinary files with strange contents to
> other tools.
> 
> The workaround is to run
> 
> make Rpwd.exe
> make link-recommended
> 
> (or, maybe, to unpack with a different tar version, but I really don't
> know).


Ah, sure, thanks, I always build from svn sources and hence say

make rsync-recommended
make recommended

If you omit
  make rsync-recommended
you will need at least
  make link-recommended
which is in fact the same but without the rsync step.

Uwe


>>
>>> --- Making recommended packages
>>>
>>> ----- installing recommended package KernSmooth
>>> Warning: invalid package 'KernSmooth.tgz'
>>> Error: ERROR: no packages specified
>>> make[1]: *** [KernSmooth.ts] Error 1
>>> make: *** [recommended] Error 2
>>>
>>> Looking at R_HOME/src/library/Recommended shows that none of the
>>> timestamp files .ts are generated(?) in that directory. If I manually
>>> create the empty timestamp files, build completes but -make check-
>>> failed. I suspect something with my build tools is not right but what
>>> could that be?
>>>
>>> h.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 15:44:01 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 15:44:01 +0100
Subject: [Rd] surprising behaviour of names<-
Message-ID: <49B67CB1.8060005@idi.ntnu.no>

playing with 'names<-', i observed the following:
  
    x = 1
    names(x)
    # NULL
    'names<-'(x, 'foo')
    # c(foo=1)
    names(x)
    # NULL

where 'names<-' has a functional flavour (does not change x), but:

    x = 1:2
    names(x)
    # NULL
    'names<-'(x, 'foo')
    # c(foo=1, 2)
    names(x)
    # "foo" NA
  
where 'names<-' seems to perform a side effect on x (destructively
modifies x).  furthermore:

    x = c(foo=1)
    names(x)
    # "foo"
    'names<-'(x, NULL)
    names(x)
    # NULL
    'names<-'(x, 'bar')
    names(x)
    # "bar" !!!

    x = c(foo=1)
    names(x)
    # "foo"
    'names<-'(x, 'bar')
    names(x)
    # "bar" !!!

where 'names<-' is not only able to destructively remove names from x,
but also destructively add or modify them (quite unlike in the first
example above).

analogous code but using 'dimnames<-' on a matrix performs a side effect
on the matrix even if it initially does not have dimnames:

    x = matrix(1,1,1)
    dimnames(x)
    # NULL
    'dimnames<-'(x, list('foo', 'bar'))
    dimnames(x)
    # list("foo", "bar")

this is incoherent with the first example above, in that in both cases
the structure initially has no names or dimnames attribute, but the end
result is different in the two examples.

is there something i misunderstand here?


there is another, minor issue with names:

    'names<-'(1, c('foo', 'bar'))
    # error: 'names' attribute [2] must be the same length as the vector [1]

    'names<-'(1:2, 'foo')
    # no error

since ?names says that "If 'value' is shorter than 'x', it is extended
by character 'NA's to the length of 'x'" (where x is the vector and
value is the names vector), the error message above should say that the
names attribute must be *at most*, not *exactly*, of the length of the
vector.

regards,
vQ


From lbraglia at gmail.com  Tue Mar 10 15:45:10 2009
From: lbraglia at gmail.com (lbraglia at gmail.com)
Date: Tue, 10 Mar 2009 15:45:10 +0100 (CET)
Subject: [Rd] ?as.POSIXct (PR#13587)
Message-ID: <20090310144511.0347B282BE82@mail.pubhealth.ku.dk>

Full_Name: Luca Braglia
Version: 2.8
OS: Windows
Submission from: (NULL) (85.18.136.110)


>From ?as.POSIXct

     ## SPSS dates (R-help 2006-02-17)
     z <- c(10485849600, 10477641600, 10561104000, 10562745600)
     as.Date(as.POSIXct(z, origin="1582-10-14", tz="GMT"))
                                           ^^

It should be 15 (Gregorian calendar adoption day, when SPSS starts to count
seconds behind dates) . With 14, I used a .sav dataset imported with read.spss,
and after as.Date(as.POSIXct()) I got (obviously)

R.date = SPSS.date - 1

Bye  (and thank you for givin'us R)


From P.Dalgaard at biostat.ku.dk  Tue Mar 10 16:10:49 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 10 Mar 2009 16:10:49 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B67CB1.8060005@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>
Message-ID: <49B682F9.8050307@biostat.ku.dk>

Wacek Kusnierczyk wrote:
> playing with 'names<-', i observed the following:
>   
>     x = 1
>     names(x)
>     # NULL
>     'names<-'(x, 'foo')
>     # c(foo=1)
>     names(x)
>     # NULL
> 
> where 'names<-' has a functional flavour (does not change x), but:
> 
>     x = 1:2
>     names(x)
>     # NULL
>     'names<-'(x, 'foo')
>     # c(foo=1, 2)
>     names(x)
>     # "foo" NA
>   
> where 'names<-' seems to perform a side effect on x (destructively
> modifies x).  furthermore:
> 
>     x = c(foo=1)
>     names(x)
>     # "foo"
>     'names<-'(x, NULL)
>     names(x)
>     # NULL
>     'names<-'(x, 'bar')
>     names(x)
>     # "bar" !!!
> 
>     x = c(foo=1)
>     names(x)
>     # "foo"
>     'names<-'(x, 'bar')
>     names(x)
>     # "bar" !!!
> 
> where 'names<-' is not only able to destructively remove names from x,
> but also destructively add or modify them (quite unlike in the first
> example above).
> 
> analogous code but using 'dimnames<-' on a matrix performs a side effect
> on the matrix even if it initially does not have dimnames:
> 
>     x = matrix(1,1,1)
>     dimnames(x)
>     # NULL
>     'dimnames<-'(x, list('foo', 'bar'))
>     dimnames(x)
>     # list("foo", "bar")
> 
> this is incoherent with the first example above, in that in both cases
> the structure initially has no names or dimnames attribute, but the end
> result is different in the two examples.
> 
> is there something i misunderstand here?

Only the ideology/pragmatism... In principle, R has call-by-value
semantics and a function does not destructively modify its arguments(*),
and foo(x)<-bar behaves like x <- "foo<-"(x, bar). HOWEVER, this has
obvious performance repercussions (think x <- rnorm(1e7); x[1] <- 0), so
we do allow destructive modification by replacement functions, PROVIDED
that the x is not used by anything else. On the least suspicion that
something else is using the object, a copy of x is made before the
modification.

So

(A) you should not use code like y <- "foo<-"(x, bar)

because

(B) you cannot (easily) predict whether or not x will be modified
destructively

--------
(*) unless you mess with match.call() or substitute() and the like. But
that's a different story.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From hkawakat at gmail.com  Tue Mar 10 18:00:14 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Tue, 10 Mar 2009 17:00:14 +0000
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <49B67512.6060309@statistik.tu-dortmund.de>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
	<49B61F7D.7020006@statistik.tu-dortmund.de>
	<49B64680.4070406@biostat.ku.dk>
	<49B67512.6060309@statistik.tu-dortmund.de>
Message-ID: <307b90470903101000l4a4d9d49rfc3b84767ab6abc5@mail.gmail.com>

On 3/10/09, Uwe Ligges wrote:
>
>  Peter Dalgaard wrote:
>
> > Uwe Ligges wrote:
> >
> > > Hiroyuki Kawakatsu wrote:
> > >
> > > > Hi,
> > > >
> > > > On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
> > > > have cygwin on my path) -make all recommended- for the latest R-devel
> > > > tarball (svn revision: 48093) fails when trying to build the
> > > > recommended packages:
> > > >
> > > 1. Have you asked make rsync-recommended before (i.e. are the packages
> > > actually there)?


No, I did not run make rsync-recommended. I never had to before when
building from a tarball. And, yes, the packages were there (both
.tar.gz and .tgz but not .ts). But as Peter points out below, the
symlinks were probably corrupted.


> > > 2. If so, please install the cygwin dlls and try to remove cygwin from
> > > your path. The may very well be some version conflicts in I cannot build
> > > R / R packages if a full cygwin installation is around.


I did install them but they looked identical to the ones I have from
cygwin. So I removed them before building.


> > > Uwe Ligges
> >
> > This bit apjaworski last week, but the naughty boy didn't include
> > R-devel in the discussion....
> >
> > It boils down to problems with symlink handling. You unpack the tar file
> > and the .tgz links look like ordinary files with strange contents to
> > other tools.
> >
> > The workaround is to run
> >
> > make Rpwd.exe
> > make link-recommended
> >
> > (or, maybe, to unpack with a different tar version, but I really don't
> > know).


Many thanks for this. Once I run these two, -make all recommended- and
-make check- completes as expected (still with cygwin on my path). So
when you say "workaround", is there something wrong with my tools or
the tarball or ...?


>  Ah, sure, thanks, I always build from svn sources and hence say
>
>  make rsync-recommended
>  make recommended
>
>  If you omit
>   make rsync-recommended
>  you will need at least
>   make link-recommended
>  which is in fact the same but without the rsync step.
[...]

When I last built R-devel from the tarball on windows (when Rtools29
was identical to Rtools28), -make all recommended- as given in the
R-admin manual "just worked". So I did not think of running these
additional makes. (The R-admin manual does say to run make
link-recommended if you are not using the tarball.)

By the way, I noticed that -make all recommended- still builds the CHM
help files for certain packages (e.g. Matrix) even though I set
USE_CHM=FALSE in MkRules. Is this expected?

Thanks for all your help.
h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 18:07:30 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 18:07:30 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B682F9.8050307@biostat.ku.dk>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
Message-ID: <49B69E52.7050402@idi.ntnu.no>

Peter Dalgaard wrote:
> Wacek Kusnierczyk wrote:
>   
>> playing with 'names<-', i observed the following:
>>   
>>     x = 1
>>     names(x)
>>     # NULL
>>     'names<-'(x, 'foo')
>>     # c(foo=1)
>>     names(x)
>>     # NULL
>>
>> where 'names<-' has a functional flavour (does not change x), but:
>>
>>     x = 1:2
>>     names(x)
>>     # NULL
>>     'names<-'(x, 'foo')
>>     # c(foo=1, 2)
>>     names(x)
>>     # "foo" NA
>>   
>> where 'names<-' seems to perform a side effect on x (destructively
>> modifies x).  furthermore:
>>
>>     x = c(foo=1)
>>     names(x)
>>     # "foo"
>>     'names<-'(x, NULL)
>>     names(x)
>>     # NULL
>>     'names<-'(x, 'bar')
>>     names(x)
>>     # "bar" !!!
>>
>>     x = c(foo=1)
>>     names(x)
>>     # "foo"
>>     'names<-'(x, 'bar')
>>     names(x)
>>     # "bar" !!!
>>
>> where 'names<-' is not only able to destructively remove names from x,
>> but also destructively add or modify them (quite unlike in the first
>> example above).
>>
>> analogous code but using 'dimnames<-' on a matrix performs a side effect
>> on the matrix even if it initially does not have dimnames:
>>
>>     x = matrix(1,1,1)
>>     dimnames(x)
>>     # NULL
>>     'dimnames<-'(x, list('foo', 'bar'))
>>     dimnames(x)
>>     # list("foo", "bar")
>>
>> this is incoherent with the first example above, in that in both cases
>> the structure initially has no names or dimnames attribute, but the end
>> result is different in the two examples.
>>
>> is there something i misunderstand here?
>>     
>
> Only the ideology/pragmatism... In principle, R has call-by-value
> semantics and a function does not destructively modify its arguments(*),
> and foo(x)<-bar behaves like x <- "foo<-"(x, bar). HOWEVER, this has
> obvious performance repercussions (think x <- rnorm(1e7); x[1] <- 0), so
> we do allow destructive modification by replacement functions, PROVIDED
> that the x is not used by anything else. On the least suspicion that
> something else is using the object, a copy of x is made before the
> modification.
>
> So
>
> (A) you should not use code like y <- "foo<-"(x, bar)
>
> because
>
> (B) you cannot (easily) predict whether or not x will be modified
> destructively
>
>   

that's fine, thanks, but i must be terribly stupid as i do not see how
this explains the examples above.  where is the x used by something else
in the first example, so that 'names<-'(x, 'foo') does *not* modify x
destructively, while it does in the other cases?

i just can't see how your explanation fits the examples -- it probably
does, but i beg you show it explicitly.
thanks.

vQ


From macrakis at alum.mit.edu  Tue Mar 10 18:35:59 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 10 Mar 2009 13:35:59 -0400
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B69E52.7050402@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B69E52.7050402@idi.ntnu.no>
Message-ID: <8b356f880903101035l5e9a6a1bk3abdd3537801c7b0@mail.gmail.com>

>> (B) you cannot (easily) predict whether or not x will be modified
>> destructively
>
> that's fine, thanks, but i must be terribly stupid as i do not see how
> this explains the examples above. ?where is the x used by something else
> in the first example, so that 'names<-'(x, 'foo') does *not* modify x
> destructively, while it does in the other cases?
>
> i just can't see how your explanation fits the examples -- it probably
> does, but i beg you show it explicitly.

I think the following shows what Peter was referring to:

In this case, there is only one pointer to the value of x:

x <- c(1,2)
> "names<-"(x,"foo")
 foo <NA>
   1    2
> x
 foo <NA>
   1    2

In this case, there are two:

> x <- c(1,2)
> y <- x
> "names<-"(x,"foo")
 foo <NA>
   1    2
> x
[1] 1 2
> y
[1] 1 2

It seems as though `names<-` and the like cannot be treated as R
functions (which do not modify their arguments) but as special
internal routines which do sometimes modify their arguments.

          -s


From ripley at stats.ox.ac.uk  Tue Mar 10 18:42:46 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Mar 2009 17:42:46 +0000 (GMT)
Subject: [Rd] ?as.POSIXct (PR#13587)
In-Reply-To: <20090310144511.0347B282BE82@mail.pubhealth.ku.dk>
References: <20090310144511.0347B282BE82@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903101708540.10382@auk.stats.ox.ac.uk>

On Tue, 10 Mar 2009, lbraglia at gmail.com wrote:

> Full_Name: Luca Braglia
> Version: 2.8
> OS: Windows
> Submission from: (NULL) (85.18.136.110)
>
>
>> From ?as.POSIXct
>
>     ## SPSS dates (R-help 2006-02-17)
>     z <- c(10485849600, 10477641600, 10561104000, 10562745600)
>     as.Date(as.POSIXct(z, origin="1582-10-14", tz="GMT"))
>                                           ^^
>
> It should be 15 (Gregorian calendar adoption day, when SPSS starts to count
> seconds behind dates) . With 14, I used a .sav dataset imported with read.spss,
> and after as.Date(as.POSIXct()) I got (obviously)
>
> R.date = SPSS.date - 1

Hmm, from the SPSS 'Programming and Data Management' guide:

'Internally, dates and date/times are stored as the number of seconds 
from October 14, 1582, and times are stored as the number of seconds 
from midnight.'

Now, they might just mean the last second of October 14, 1582, but 
that is not how many other people have read this (including those in 
the thread mentioned).

Wikipedia for example describes October 15, 1582 as the first day of 
the Gregorian calendar, which makes 1582-10-14 day zero.

Given that this is an example only, I don't think we should change it 
without quite strong evidence that SPSS's documentation is misleading.


> Bye  (and thank you for givin'us R)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 18:58:02 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 18:58:02 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <8b356f880903101035l5e9a6a1bk3abdd3537801c7b0@mail.gmail.com>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>	
	<49B69E52.7050402@idi.ntnu.no>
	<8b356f880903101035l5e9a6a1bk3abdd3537801c7b0@mail.gmail.com>
Message-ID: <49B6AA2A.2040000@idi.ntnu.no>

Stavros Macrakis wrote:
>>> (B) you cannot (easily) predict whether or not x will be modified
>>> destructively
>>>       
>> that's fine, thanks, but i must be terribly stupid as i do not see how
>> this explains the examples above.  where is the x used by something else
>> in the first example, so that 'names<-'(x, 'foo') does *not* modify x
>> destructively, while it does in the other cases?
>>
>> i just can't see how your explanation fits the examples -- it probably
>> does, but i beg you show it explicitly.
>>     
>
> I think the following shows what Peter was referring to:
>
> In this case, there is only one pointer to the value of x:
>
> x <- c(1,2)
>   
>> "names<-"(x,"foo")
>>     
>  foo <NA>
>    1    2
>   
>> x
>>     
>  foo <NA>
>    1    2
>
> In this case, there are two:
>
>   
>> x <- c(1,2)
>> y <- x
>> "names<-"(x,"foo")
>>     
>  foo <NA>
>    1    2
>   
>> x
>>     
> [1] 1 2
>   
>> y
>>     
> [1] 1 2
>   

that is and was clear to me, but none of my examples was of the second
form, and hence i think peter's answer did not answer my question. 
what's the difference here:

    x = 1
    'names<-'(x, 'foo')
    names(x)
    # NULL

    x = c(foo=1)
    'names<-'(x, 'foo')
    names(x)
    # "foo"

certainly not something like what you show.   what's the difference here:

    x = 1
    'names<-'(x, 'foo')
    names(x)
    # NULL
  
    x = 1:2
    'names<-'(x, c('foo', 'bar'))
    names(x)
    # "foo" "bar"

certainly not something like what you show.

> It seems as though `names<-` and the like cannot be treated as R
> functions (which do not modify their arguments) but as special
> internal routines which do sometimes modify their arguments.
>   

they seem to behave somewhat like macros:

    'names<-'(a, b)

with the destructive 'names<-' is sort of replaced with

    a = 'names<-'(a, b)

with a functional 'names<-'.  but this still does not explain the
incoherence above.  my problem was and is not that 'names<-' is not a
pure function, but that it sometimes is, sometimes is not, without any
obvious explanation.  that is, i suspect (not claim) that the behaviour
is not a design feature, but an incident.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 19:03:57 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 19:03:57 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B682F9.8050307@biostat.ku.dk>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
Message-ID: <49B6AB8D.20801@idi.ntnu.no>

Peter Dalgaard wrote:
>
> (*) unless you mess with match.call() or substitute() and the like. But
> that's a different story.
>   

different or not, it is a story that happens quite often -- too often,
perhaps -- to the degree that one may be tempted to say that the
semantics of argument passing in r is a mess. which of course is not
true, but since it is possible to mess with match.call & co, people
(including r core) do mess with them, and the result is obviously a
mess.  on top of the clear call-by-need semantics -- and on the surface,
you cannot tell how the arguments of a function will be taken (by
value?  by reference?  not at all?), which in effect looks like a messy
semantics.

vQ


From ripley at stats.ox.ac.uk  Tue Mar 10 19:18:36 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Mar 2009 18:18:36 +0000 (GMT)
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <307b90470903101000l4a4d9d49rfc3b84767ab6abc5@mail.gmail.com>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
	<49B61F7D.7020006@statistik.tu-dortmund.de>
	<49B64680.4070406@biostat.ku.dk>
	<49B67512.6060309@statistik.tu-dortmund.de>
	<307b90470903101000l4a4d9d49rfc3b84767ab6abc5@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0903101809060.25625@gannet.stats.ox.ac.uk>

This is another of those things which is not yet finished (you will 
see mention of the removed cross-building scripts in the relevant 
Makefile.win).

Expect it to work from the tarball before GFF in 10 day's time.

There's another intermittent problem with dependencies in the current 
sources that I will commit a fix for shortly.

Geberally, you should not necessarily expect R to build on Windows 
from snapshots tarballs prior to GFF: use svn+rsync (as that is what 
the developers use).

On Tue, 10 Mar 2009, Hiroyuki Kawakatsu wrote:

> On 3/10/09, Uwe Ligges wrote:
>>
>>  Peter Dalgaard wrote:
>>
>>> Uwe Ligges wrote:
>>>
>>>> Hiroyuki Kawakatsu wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> On my windows (xp) machine with Rtools29 (excluding cygwin dlls as I
>>>>> have cygwin on my path) -make all recommended- for the latest R-devel
>>>>> tarball (svn revision: 48093) fails when trying to build the
>>>>> recommended packages:
>>>>>
>>>> 1. Have you asked make rsync-recommended before (i.e. are the packages
>>>> actually there)?
>
>
> No, I did not run make rsync-recommended. I never had to before when
> building from a tarball. And, yes, the packages were there (both
> .tar.gz and .tgz but not .ts). But as Peter points out below, the
> symlinks were probably corrupted.
>
>
>>>> 2. If so, please install the cygwin dlls and try to remove cygwin from
>>>> your path. The may very well be some version conflicts in I cannot build
>>>> R / R packages if a full cygwin installation is around.
>
>
> I did install them but they looked identical to the ones I have from
> cygwin. So I removed them before building.
>
>
>>>> Uwe Ligges
>>>
>>> This bit apjaworski last week, but the naughty boy didn't include
>>> R-devel in the discussion....
>>>
>>> It boils down to problems with symlink handling. You unpack the tar file
>>> and the .tgz links look like ordinary files with strange contents to
>>> other tools.
>>>
>>> The workaround is to run
>>>
>>> make Rpwd.exe
>>> make link-recommended
>>>
>>> (or, maybe, to unpack with a different tar version, but I really don't
>>> know).
>
>
> Many thanks for this. Once I run these two, -make all recommended- and
> -make check- completes as expected (still with cygwin on my path). So
> when you say "workaround", is there something wrong with my tools or
> the tarball or ...?
>
>
>>  Ah, sure, thanks, I always build from svn sources and hence say
>>
>>  make rsync-recommended
>>  make recommended
>>
>>  If you omit
>>   make rsync-recommended
>>  you will need at least
>>   make link-recommended
>>  which is in fact the same but without the rsync step.
> [...]
>
> When I last built R-devel from the tarball on windows (when Rtools29
> was identical to Rtools28), -make all recommended- as given in the
> R-admin manual "just worked". So I did not think of running these
> additional makes. (The R-admin manual does say to run make
> link-recommended if you are not using the tarball.)
>
> By the way, I noticed that -make all recommended- still builds the CHM
> help files for certain packages (e.g. Matrix) even though I set
> USE_CHM=FALSE in MkRules. Is this expected?
>
> Thanks for all your help.
> h.
> -- 
> +---
> | Hiroyuki Kawakatsu
> | Business School, Dublin City University
> | Dublin 9, Ireland. Tel +353 (0)1 700 7496
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From michael_karsh at earthlink.net  Tue Mar 10 21:35:15 2009
From: michael_karsh at earthlink.net (michael_karsh at earthlink.net)
Date: Tue, 10 Mar 2009 21:35:15 +0100 (CET)
Subject: [Rd] logical comparison of functions (PR#13588)
Message-ID: <20090310203515.74F2D2832196@mail.pubhealth.ku.dk>

Full_Name: Michael Aaron Karsh
Version: 2.8.0
OS: Windows XP
Submission from: (NULL) (164.67.71.215)


When I try to say if (method==f), where f is a function, it says that the
comparison is only possible for list and atomic types.  I tried saying if
(method!=f), and it gave the same error message.  Would it be possible to repair
it say that == and != comparisons would be possible for functions?


From murdoch at stats.uwo.ca  Tue Mar 10 22:01:05 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 10 Mar 2009 17:01:05 -0400
Subject: [Rd] logical comparison of functions (PR#13588)
In-Reply-To: <20090310203515.74F2D2832196@mail.pubhealth.ku.dk>
References: <20090310203515.74F2D2832196@mail.pubhealth.ku.dk>
Message-ID: <49B6D511.2080509@stats.uwo.ca>

On 10/03/2009 4:35 PM, michael_karsh at earthlink.net wrote:
> Full_Name: Michael Aaron Karsh
> Version: 2.8.0
> OS: Windows XP
> Submission from: (NULL) (164.67.71.215)
> 
> 
> When I try to say if (method==f), where f is a function, it says that the
> comparison is only possible for list and atomic types.  I tried saying if
> (method!=f), and it gave the same error message.  Would it be possible to repair
> it say that == and != comparisons would be possible for functions?

This is not a bug.  Please don't report things as bugs when they aren't. 
  "==" and "!=" are for atomic vectors, as documented.

Use identical() for more general comparisons, as documented on the man 
page for ==.

Duncan Murdoch


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 22:12:53 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 22:12:53 +0100
Subject: [Rd] logical comparison of functions (PR#13588)
In-Reply-To: <49B6D511.2080509@stats.uwo.ca>
References: <20090310203515.74F2D2832196@mail.pubhealth.ku.dk>
	<49B6D511.2080509@stats.uwo.ca>
Message-ID: <49B6D7D5.2000706@idi.ntnu.no>

Duncan Murdoch wrote:
> On 10/03/2009 4:35 PM, michael_karsh at earthlink.net wrote:
>> Full_Name: Michael Aaron Karsh
>> Version: 2.8.0
>> OS: Windows XP
>> Submission from: (NULL) (164.67.71.215)
>>
>>
>> When I try to say if (method==f), where f is a function, it says that
>> the
>> comparison is only possible for list and atomic types.  I tried
>> saying if
>> (method!=f), and it gave the same error message.  Would it be
>> possible to repair
>> it say that == and != comparisons would be possible for functions?
>
> This is not a bug.  Please don't report things as bugs when they
> aren't.  "==" and "!=" are for atomic vectors, as documented.
>
> Use identical() for more general comparisons, as documented on the man
> page for ==.

note that in most programming languages comparing function objects is
either not supported or returns false unless you compare a function
object to itself.  r is a notable exception:

    identical(function(a) a, function(a) a)
    # TRUE

which would be false in all other languages i know;  however,

    identical(function(a) a, function(b) b)
    # FALSE

though they are surely identical functionally.

btw. it's not necessarily intuitive that == works only for atomic vectors.

vQ


From amredd at gmail.com  Tue Mar 10 22:49:02 2009
From: amredd at gmail.com (Andrew Redd)
Date: Tue, 10 Mar 2009 16:49:02 -0500
Subject: [Rd] dger_ in BLAS definition
Message-ID: <4d17c3500903101449q52d5cb84xf4250c20c57479a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090310/e56d598d/attachment.pl>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 10 23:16:57 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Mar 2009 23:16:57 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B682F9.8050307@biostat.ku.dk>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
Message-ID: <49B6E6D9.7010809@idi.ntnu.no>

i got an offline response saying that my original post may have not been
clear as to what the problem was, essentially, and that i may need to
restate it in words, in addition to code.

the problem is:  the performance of 'names<-' is incoherent, in that in
some situations it acts in a functional manner, producing a copy of its
argument with the names changed, while in others it changes the object
in-place (and returns it), without copying first.  your explanation
below is of course valid, but does not seem to address the issue.  in
the examples below, there is always (or so it seems) just one reference
to the object.

why are the following functional:

    x = 1;  'names<-'(x, 'foo'); names(x)
    x = 'foo'; 'names<-'(x, 'foo');  names(x)

while these are destructive:

    x = c(1);  'names<-'(x, 'foo'); names(x)
    x = c('foo'); 'names<-'(x, 'foo');  names(x)

it is claimed that in r a singular value is a one-element vector, and
indeed,

    identical(1, c(1))
    # TRUE
    all.equal(is(1), is(c(1)))
    # TRUE

i also do not understand the difference here:

    x = c(1); 'names<-'(x, 'foo'); names(x)
    # "foo"
    x = c(1); names(x); 'names<-'(x, 'foo'); names(x)
    # "foo"
    x = c(1); print(x); 'names<-'(x, 'foo'); names(x)
    # NULL
    x = c(1); print(c(x)); 'names<-'(x, 'foo'); names(x)
    # "foo"

does print, but not names, increase the reference count for x when
applied to x, but not to c(x)?

if the issue is that there is, in those examples where x is left
unchanged, an additional reference to x that causes the value of x to be
copied, could you please explain how and when this additional reference
is created?


thanks,
vQ




Peter Dalgaard wrote:
>
>> is there something i misunderstand here?
>>     
>
> Only the ideology/pragmatism... In principle, R has call-by-value
> semantics and a function does not destructively modify its arguments(*),
> and foo(x)<-bar behaves like x <- "foo<-"(x, bar). HOWEVER, this has
> obvious performance repercussions (think x <- rnorm(1e7); x[1] <- 0), so
> we do allow destructive modification by replacement functions, PROVIDED
> that the x is not used by anything else. On the least suspicion that
> something else is using the object, a copy of x is made before the
> modification.
>
> So
>
> (A) you should not use code like y <- "foo<-"(x, bar)
>
> because
>
> (B) you cannot (easily) predict whether or not x will be modified
> destructively
>
> --------
> (*) unless you mess with match.call() or substitute() and the like. But
> that's a different story.
>
>
>   


-- 
-------------------------------------------------------------------------------
Wacek Kusnierczyk, MD PhD

Email: waku at idi.ntnu.no
Phone: +47 73591875, +47 72574609

Department of Computer and Information Science (IDI)
Faculty of Information Technology, Mathematics and Electrical Engineering (IME)
Norwegian University of Science and Technology (NTNU)
Sem Saelands vei 7, 7491 Trondheim, Norway
Room itv303

Bioinformatics & Gene Regulation Group
Department of Cancer Research and Molecular Medicine (IKM)
Faculty of Medicine (DMF)
Norwegian University of Science and Technology (NTNU)
Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
Room 231.05.060


From dutangc at gmail.com  Tue Mar 10 23:23:10 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Tue, 10 Mar 2009 23:23:10 +0100
Subject: [Rd] dger_ in BLAS definition
In-Reply-To: <4d17c3500903101449q52d5cb84xf4250c20c57479a8@mail.gmail.com>
References: <4d17c3500903101449q52d5cb84xf4250c20c57479a8@mail.gmail.com>
Message-ID: <6450561D-6094-48EF-86E9-3BD09CAEF80A@gmail.com>

Yes x and y arguments are unchanged on exit, cf. http://www.mathkeisan.com/UsersGuide/man/dger.html

This is the work of the R core team to update those files, but I fear  
there are other functions which are not well declared.

Will you agree to take a look at the BLAS.h file? It will be very  
useful if you have time to do it.

(A year ago, I check the lapack.h and there was some wrong  
declarations like zgecon function.)

Christophe


Le 10 mars 09 ? 22:49, Andrew Redd a ?crit :

> I'm developing some software and running into compiling warning:
> conditionals.c:104: warning: passing argument 4 of 'dger_' discards
> qualifiers from pointer target type
> conditionals.c:104: warning: passing argument 6 of 'dger_' discards
> qualifiers from pointer target type
>
> the netlib documentation states that the arguments x and y should be
> unchanged on exit.  Should should imply the defintion:
>
> F77_NAME(dger)(const int * const m, const int * const n, const  
> double *
> const alpha,
>           double const * const x, const int *const incx,
>           double const * const y, const int *const incy,
>           double * const a, const int * const lda);
>
> the current definition is missing the appropriate consts:
> F77_NAME(dger)(const int *m, const int *n, const double *alpha,
>           double *x, const int *incx,
>           double *y, const int *incy,
>           double *a, const int *lda);
>
> I don't want my code compiling with warnings that shouldn't be  
> there.  Are
> there suggestions of how to work around this?
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Christophe Dutang
Ph. D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From gabraham at csse.unimelb.edu.au  Wed Mar 11 01:59:30 2009
From: gabraham at csse.unimelb.edu.au (Gad Abraham)
Date: Wed, 11 Mar 2009 11:59:30 +1100
Subject: [Rd] S4 generic masking S3 generic when using namespace
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF72A@mildnpexmb01.maninvestments.ad.man.com>
References: <49B63A9F.60403@csse.unimelb.edu.au>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF72A@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <49B70CF2.2000709@csse.unimelb.edu.au>

Sklyar, Oleg (London) wrote:
> Try using setGeneric("predict") without further arguments, this should
> work as it will take the existing 'predict' definition and convert it
> into S4 generic. This works nicely for me for all plot, print etc
> methods
> 
> * R   
> *** R 2.9.0 (svn -r 47821) [/share/research/R-devel/20090203/lib64/R]
> ***
>> setGeneric("predict")
> [1] "predict"

Great, thanks.

-- 
Gad Abraham
MEng Student, Dept. CSSE and NICTA
The University of Melbourne
Parkville 3010, Victoria, Australia
email: gabraham at csse.unimelb.edu.au
web: http://www.csse.unimelb.edu.au/~gabraham


From btyner at gmail.com  Wed Mar 11 02:09:22 2009
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 10 Mar 2009 21:09:22 -0400
Subject: [Rd] bug (PR#13570)
In-Reply-To: <alpine.LFD.2.00.0903090910590.25123@gannet.stats.ox.ac.uk>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
	<49B07B45.3040308@gmail.com>
	<alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
	<alpine.LFD.2.00.0903090910590.25123@gannet.stats.ox.ac.uk>
Message-ID: <49B70F42.3040206@gmail.com>

Many thanks Brian for tracking this down. Was it fixed by

      c next line is not in current dloess
	        	  goto 7

in ehg136? If this needs to be in the netlib version as well, we should 
inform Eric Grosse.

While we're at it, there are a few more inconsistencies (not nearly as 
serious as PR#13570 so I hesitate to call them bugs) regarding the 
definition of leaf cell membership (certain .lt. should be .le. ) in 
ehg128, ehg137, and ehg138 (not currently used); it seems I neglected to 
mention these to Eric. If you are interested in these I can submit a 
patch and will notify Eric as well.

Finally, perhaps now is as good a time as any to point out that in the 
documentation, the bit about cross-terms in

    \item{drop.square}{for fits with more than one predictor and
        \code{degree=2}, should the quadratic term (and cross-terms) be
        dropped for particular predictors?

is incorrect -- cross terms are not dropped in this implementation of 
loess.

Thanks again,
Ben

Prof Brian Ripley wrote:
> I've found the discrepancy, so the patched code from current dloess is 
> now available in R-patched and R-devel.
>
> On Fri, 6 Mar 2009, Prof Brian Ripley wrote:
>
>> On Thu, 5 Mar 2009, Benjamin Tyner wrote:
>>
>>> Hi
>>>
>>> Nice to hear from you Ryan. I also do not have the capability to 
>>> debug on windows; however, there is a chance that the behavior you 
>>> are seeing is caused by the following bug noted in my thesis 
>>> (available on ProQuest; email me if you don't have access):
>>>
>>> "When lambda = 0 there are no local slopes to aid the blending 
>>> algorithm, yet the
>>> interpolator would still assume they were available, and thus use 
>>> arbitrary values
>>> from memory. This had implications for both fit and tr[L] 
>>> computation. In the
>>> updated code these are set equal to zero which seems the best 
>>> automatic rule when
>>> lambda = 0." [lambda refers to degree]
>>>
>>> I submitted a bug fix to Eric Grosse, the maintainer of the netlib 
>>> routines; the fixed lines of fortran are identified in the comments 
>>> at (just search for my email address):
>>>
>>> http://www.netlib.org/a/loess
>>>
>>> These fixes would be relatively simple to incorporate into R's 
>>> version of loessf.f
>>
>> The fixes from dloess even more simply, since R's code is based on 
>> dloess. Thank you for the suggestion.
>>
>> Given how tricky this is to reproduce, I went back to my example 
>> under valgrind.  If I use the latest dloess code, it crashes, but by 
>> selectively importing some of the differences I can get it to work.
>>
>> So it looks as if we are on the road to a solution, but something in 
>> the current version (not necessarily in these changes) is 
>> incompatible with the current R code and I need to dig further (not 
>> for a few days).
>>
>>> Alternatively, a quick check would be for someone to compile the 
>>> source package at 
>>> https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz and 
>>> test it on windows. Though this package incorporates this and a few 
>>> other fixes, please be aware that it the routines are converted to C 
>>> and thus there is a slight performance hit compared to the fortran.
>>>
>>> Hope this helps,
>>> Ben
>>
>> [...]
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>


From jeff.hamann at forestinformatics.com  Wed Mar 11 02:18:41 2009
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Tue, 10 Mar 2009 18:18:41 -0700
Subject: [Rd] libf95.a: could not read symbols?
Message-ID: <49B71171.8040400@forestinformatics.com>

I'm sorry for having to post this, but I've run out of ideas. I've been
trying to build R-2.8.1 from source for installation on FreeBSD 6.4
(seems to be working fine on osx) and keep getting the same results,
regardless of how I set ./configure


$ ./configure --enable-R-shlib --with-x=no --with-blas FFLAGS="-fpic"

R is now configured for x86_64-unknown-freebsd6.0

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       f95  -fpic

  C++ compiler:              g++  -g -O2
  Fortran 90/95 compiler:    g95 -g -O2
  Obj-C compiler:	      -g -O2

  Interfaces supported:      tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, TIFF, iconv, MBCS, NLS
  Options enabled:           shared R library, shared BLAS, R profiling

  Recommended packages:      yes

$ make

generates the following results:

$ make
creating src/scripts/R.fe
config.status: creating src/include/config.h
config.status: src/include/config.h is unchanged
Rmath.h is unchanged
gcc -std=gnu99 -shared -L/usr/local/lib -o libRblas.so blas.o
cmplxblas.o -L/usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3
-lf95 -lm # xerbla.o
/usr/bin/ld:
/usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3/libf95.a(ff.o):
relocation R_X86_64_32S can not be used when making a shared object;
recompile with -fPIC
/usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3/libf95.a: could
not read symbols: Bad value
*** Error code 1

Stop in /usr/home/hamannj/R-2.8.1/src/extra/blas.
*** Error code 1

Stop in /usr/home/hamannj/R-2.8.1/src/extra/blas.
*** Error code 1

Stop in /usr/home/hamannj/R-2.8.1/src/extra.
*** Error code 1

Stop in /usr/home/hamannj/R-2.8.1/src.
*** Error code 1

Stop in /usr/home/hamannj/R-2.8.1.
you have mail
$

Is this is problem with g95, gcc(s) or something I'm not doing
correctly? Should I try to build an earlier version instead? I've tried
building the g95 freebsd port (not from source) and can't seem to get
any traction...

any ideas?
Thanks.







-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 258 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090310/26ae693c/attachment.bin>

From edd at debian.org  Wed Mar 11 03:06:23 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 10 Mar 2009 21:06:23 -0500
Subject: [Rd]  [SoC09-Idea] RQuantLib
Message-ID: <18871.7327.201637.566029@ron.nulle.part>


RQuantLib -- Bridging R and QuantLib

Mentor: Dirk Eddelbuettel

Summary: The goal of this Summer of Code project is to 
   a) extend the coverage of QuantLib [1] code available to R by adding more
      wrapper functions to RQuantLib [2], and to

   b) provide additional functionality to QuantLib by leveraging the numerous
      statistical facilities in R -- this could be anything from standard to
      robust estimation methods, data visualization or report creation via
      tools like Sweave.

Required skills: Good R and C++ programming skills. At least some familiarity
   with basic open source tools like svn, make, ... is beneficial as
   well. Some understanding of financial economics may be helpful but is not
   required.

Description: QuantLib, the premier free/open-source library for modeling,
   trading, and risk management, provides a comprehensive software framework
   for quantitative finance.  QuantLib has been developed since Nov 2000 and
   is now approaching an initial 1.0 release at which point the API will be
   frozen.  This makes it a good point in time to start building more code on
   top of the API.

   RQuantLib, first released in 2002 as a proof-of-concept, provides a subset
   of the available QuantLib functonality. Many more asset classed and
   methods are now available.

   This Summer of Code project provides ample scope for a student to first
   learn about possible extensions to RQuantLib, to learn about interfaces
   from R to underlying libraries and back, and to then design, architect and
   implement some meaningful extension.

Programming exercise: Take the current RQuantLib package and provide a new
   function that exposes functionality from QuantLib to R, preferably with a
   tests/ file and a help file.

References:
   [1] http://www.quantlib.org
   [2] http://cran.r-project.org/web/packages/RQuantLib/index.html as well as
       http://r-forge.r-project.org/projects/rquantlib/ as well as
       http://dirk.eddelbuettel.com/code/rquantlib.html 

-- 
Three out of two people have difficulties with fractions.


From ripley at stats.ox.ac.uk  Wed Mar 11 03:57:45 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2009 02:57:45 +0000 (GMT)
Subject: [Rd] bug (PR#13570)
In-Reply-To: <49B70F42.3040206@gmail.com>
References: <20090304211010.A588D2832180@mail.pubhealth.ku.dk>
	<49AF88B7.1000002@biostat.ku.dk>
	<20090305174301.20099b11@berwin-nus1>
	<49AFB412.2060807@statistik.tu-dortmund.de>
	<alpine.LFD.2.00.0903051121300.2646@gannet.stats.ox.ac.uk>
	<49AFC711.1030902@biostat.ku.dk>
	<alpine.LFD.2.00.0903051237560.3864@gannet.stats.ox.ac.uk>
	<E0F590EA-8F52-44A6-AD5D-E050BD6740D7@stat.purdue.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CC034A04@LP-EXMBVS10.CO.IHC.COM>
	<7A1AA352-D2E8-48A2-BDE3-FF48B71E28D9@stat.purdue.edu>
	<49B07B45.3040308@gmail.com>
	<alpine.LFD.2.00.0903060718570.24770@auk.stats.ox.ac.uk>
	<alpine.LFD.2.00.0903090910590.25123@gannet.stats.ox.ac.uk>
	<49B70F42.3040206@gmail.com>
Message-ID: <alpine.LFD.2.00.0903110249210.23248@gannet.stats.ox.ac.uk>

On Tue, 10 Mar 2009, Benjamin Tyner wrote:

> Many thanks Brian for tracking this down. Was it fixed by
>
>     c next line is not in current dloess
> 	        	  goto 7
>
> in ehg136? If this needs to be in the netlib version as well, we should 
> inform Eric Grosse.

The difference was in the argument list of one of the functions 
(ehg124?).  It was 'just' a question of looking at 354 diff sections, 
not all of which I understood, including that commented above.

> While we're at it, there are a few more inconsistencies (not nearly as 
> serious as PR#13570 so I hesitate to call them bugs) regarding the definition 
> of leaf cell membership (certain .lt. should be .le. ) in ehg128, ehg137, and 
> ehg138 (not currently used); it seems I neglected to mention these to Eric. 
> If you are interested in these I can submit a patch and will notify Eric as 
> well.

Please do let me know and I'll merge in.

> Finally, perhaps now is as good a time as any to point out that in the 
> documentation, the bit about cross-terms in
>
>   \item{drop.square}{for fits with more than one predictor and
>       \code{degree=2}, should the quadratic term (and cross-terms) be
>       dropped for particular predictors?
>
> is incorrect -- cross terms are not dropped in this implementation of loess.

Thanks, I will incorporate that.

> Thanks again,
> Ben
>
> Prof Brian Ripley wrote:
>> I've found the discrepancy, so the patched code from current dloess is now 
>> available in R-patched and R-devel.
>> 
>> On Fri, 6 Mar 2009, Prof Brian Ripley wrote:
>> 
>>> On Thu, 5 Mar 2009, Benjamin Tyner wrote:
>>> 
>>>> Hi
>>>> 
>>>> Nice to hear from you Ryan. I also do not have the capability to debug on 
>>>> windows; however, there is a chance that the behavior you are seeing is 
>>>> caused by the following bug noted in my thesis (available on ProQuest; 
>>>> email me if you don't have access):
>>>> 
>>>> "When lambda = 0 there are no local slopes to aid the blending algorithm, 
>>>> yet the
>>>> interpolator would still assume they were available, and thus use 
>>>> arbitrary values
>>>> from memory. This had implications for both fit and tr[L] computation. In 
>>>> the
>>>> updated code these are set equal to zero which seems the best automatic 
>>>> rule when
>>>> lambda = 0." [lambda refers to degree]
>>>> 
>>>> I submitted a bug fix to Eric Grosse, the maintainer of the netlib 
>>>> routines; the fixed lines of fortran are identified in the comments at 
>>>> (just search for my email address):
>>>> 
>>>> http://www.netlib.org/a/loess
>>>> 
>>>> These fixes would be relatively simple to incorporate into R's version of 
>>>> loessf.f
>>> 
>>> The fixes from dloess even more simply, since R's code is based on dloess. 
>>> Thank you for the suggestion.
>>> 
>>> Given how tricky this is to reproduce, I went back to my example under 
>>> valgrind.  If I use the latest dloess code, it crashes, but by selectively 
>>> importing some of the differences I can get it to work.
>>> 
>>> So it looks as if we are on the road to a solution, but something in the 
>>> current version (not necessarily in these changes) is incompatible with 
>>> the current R code and I need to dig further (not for a few days).
>>> 
>>>> Alternatively, a quick check would be for someone to compile the source 
>>>> package at https://centauri.stat.purdue.edu:98/loess/loess_0.4-1.tar.gz 
>>>> and test it on windows. Though this package incorporates this and a few 
>>>> other fixes, please be aware that it the routines are converted to C and 
>>>> thus there is a slight performance hit compared to the fortran.
>>>> 
>>>> Hope this helps,
>>>> Ben
>>> 
>>> [...]
>>> 
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Mar 11 04:13:52 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2009 03:13:52 +0000 (GMT)
Subject: [Rd] libf95.a: could not read symbols?
In-Reply-To: <49B71171.8040400@forestinformatics.com>
References: <49B71171.8040400@forestinformatics.com>
Message-ID: <alpine.LFD.2.00.0903110303340.23248@gannet.stats.ox.ac.uk>

Where did FFLAGS come from here (looks like you meant FPICFLAGS)?

But that will only postpone the problem: to build R as a shared 
library you need PIC libraries, and your Fortran library is apparently 
not PIC (gcc does not generate PIC code by default on x86_64, and g95 
as a gcc derivative is presumably the same).  Even if you don't build 
R as shared library, the problem is likely to crop up in some packages 
(probably including stats).

gcc 4.0.3 is rather old (and rather too early in the gcc4 series). 
Can you get a later compiler quite (prrferably gcc + gfortran)?

On Tue, 10 Mar 2009, Jeff Hamann wrote:

> I'm sorry for having to post this, but I've run out of ideas. I've been
> trying to build R-2.8.1 from source for installation on FreeBSD 6.4
> (seems to be working fine on osx) and keep getting the same results,
> regardless of how I set ./configure
>
>
> $ ./configure --enable-R-shlib --with-x=no --with-blas FFLAGS="-fpic"
>
> R is now configured for x86_64-unknown-freebsd6.0
>
>  Source directory:          .
>  Installation directory:    /usr/local
>
>  C compiler:                gcc -std=gnu99  -g -O2
>  Fortran 77 compiler:       f95  -fpic
>
>  C++ compiler:              g++  -g -O2
>  Fortran 90/95 compiler:    g95 -g -O2
>  Obj-C compiler:	      -g -O2
>
>  Interfaces supported:      tcltk
>  External libraries:        readline
>  Additional capabilities:   PNG, JPEG, TIFF, iconv, MBCS, NLS
>  Options enabled:           shared R library, shared BLAS, R profiling
>
>  Recommended packages:      yes
>
> $ make
>
> generates the following results:
>
> $ make
> creating src/scripts/R.fe
> config.status: creating src/include/config.h
> config.status: src/include/config.h is unchanged
> Rmath.h is unchanged
> gcc -std=gnu99 -shared -L/usr/local/lib -o libRblas.so blas.o
> cmplxblas.o -L/usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3
> -lf95 -lm # xerbla.o
> /usr/bin/ld:
> /usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3/libf95.a(ff.o):
> relocation R_X86_64_32S can not be used when making a shared object;
> recompile with -fPIC
> /usr/local/lib/gcc-lib/x86_64-portbld-freebsd6.0/4.0.3/libf95.a: could
> not read symbols: Bad value
> *** Error code 1
>
> Stop in /usr/home/hamannj/R-2.8.1/src/extra/blas.
> *** Error code 1
>
> Stop in /usr/home/hamannj/R-2.8.1/src/extra/blas.
> *** Error code 1
>
> Stop in /usr/home/hamannj/R-2.8.1/src/extra.
> *** Error code 1
>
> Stop in /usr/home/hamannj/R-2.8.1/src.
> *** Error code 1
>
> Stop in /usr/home/hamannj/R-2.8.1.
> you have mail
> $
>
> Is this is problem with g95, gcc(s) or something I'm not doing
> correctly? Should I try to build an earlier version instead? I've tried
> building the g95 freebsd port (not from source) and can't seem to get
> any traction...
>
> any ideas?
> Thanks.
>
>
>
>
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dannychia at berkeley.edu  Wed Mar 11 05:05:11 2009
From: dannychia at berkeley.edu (dannychia at berkeley.edu)
Date: Wed, 11 Mar 2009 05:05:11 +0100 (CET)
Subject: [Rd] website feature request - a roadmap (PR#13589)
Message-ID: <20090311040511.7AF152832187@mail.pubhealth.ku.dk>

Full_Name: Danny Chia
Version: 2.8.1
OS: Windows
Submission from: (NULL) (169.229.100.137)


This is more of a feature request, but it would be nice if the CRAN website had
some sort of roadmap for R. That way, users would know what to expect for future
versions of R.


From ripley at stats.ox.ac.uk  Wed Mar 11 10:24:39 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2009 09:24:39 +0000 (GMT)
Subject: [Rd] website feature request - a roadmap (PR#13589)
In-Reply-To: <20090311040511.7AF152832187@mail.pubhealth.ku.dk>
References: <20090311040511.7AF152832187@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0903110911130.23931@auk.stats.ox.ac.uk>

Have you seen developer.r-project.org?  All the relevant 
information is there. For the medium-term (up to 6 months) the NEWS 
file in the R-devel version of R indicates currently intended changes.

CRAN is a distribution network, and distinct from www.r-project.org 
and developer.r-project.org.

The R project does not have staff, and all plans are subject to 
ther availability of volunteer help.  In practice that means that 
long-term goals are subject to some indefinite delays as the 
circumstances of individuals change.

On Wed, 11 Mar 2009, dannychia at berkeley.edu wrote:

> Full_Name: Danny Chia
> Version: 2.8.1
> OS: Windows
> Submission from: (NULL) (169.229.100.137)
>
>
> This is more of a feature request, but it would be nice if the CRAN 
> website had some sort of roadmap for R. That way, users would know 
> what to expect for future versions of R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hkawakat at gmail.com  Wed Mar 11 12:28:29 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Wed, 11 Mar 2009 11:28:29 +0000
Subject: [Rd] configure fail for XML package on freebsd
Message-ID: <307b90470903110428i1635c94btd2f457b893e3580c@mail.gmail.com>

Hi,

I am having problems installing the XML package with R-devel on
freebsd. If I simply do install.packages("XML"), it says that the
parser.h file is not found. After reading the INSTALL file, I have set

setenv  XML_CONFIG /usr/local/bin/xml2-config
setenv  LIBXML_LIBDIR -L/usr/local/lib
setenv  LIBXML_INCDIR -I/usr/local/include/libxml2/libxml

and install.packages("XML") fails with

checking for stdint.h... (cached) yes
checking for unistd.h... (cached) yes
checking for libxml/parser.h... (cached) no
checking for gnome-xml/parser.h... (cached) no
Located parser file -I/usr/local/include/libxml2/libxml/parser.h
checking for gzopen in -lz... yes
checking for xmlParseFile in -lxml2... yes
You are trying to use a version 2.* edition of libxml
but an incompatible library. The header files and library seem to be
mismatched. If you have specified LIBXML_INCDIR, make certain to also
specify an appropriate LIBXML_LIBDIR if the libxml2 library is not in
the default
directories.
ERROR: configuration failed for package 'XML'
* Removing '/usr/local/share/R-devel/library/XML'
Warning in install.packages("XML", clean = TRUE) :
  installation of package 'XML' had non-zero exit status

Some version info on my machine:

erdos# portversion -F "libxml*"
libxml2-2.7.3               =

erdos# xml2-config --version
2.7.3

erdos# ls /usr/local/lib/libxml*
/usr/local/lib/libxml2.a         /usr/local/lib/libxmlparse.so@
/usr/local/lib/libxml2.la*       /usr/local/lib/libxmlparse.so.1*
/usr/local/lib/libxml2.so@       /usr/local/lib/libxmltok.a
/usr/local/lib/libxml2.so.5*     /usr/local/lib/libxmltok.la*
/usr/local/lib/libxmlparse.a     /usr/local/lib/libxmltok.so@
/usr/local/lib/libxmlparse.la*   /usr/local/lib/libxmltok.so.1*

The header LIBXML_INCDIR/xmlversion.h does define version as 2.7.3.
Does anyone have an idea of what may be going wrong?

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From duncan at wald.ucdavis.edu  Wed Mar 11 14:14:24 2009
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 11 Mar 2009 06:14:24 -0700
Subject: [Rd] configure fail for XML package on freebsd
In-Reply-To: <307b90470903110428i1635c94btd2f457b893e3580c@mail.gmail.com>
References: <307b90470903110428i1635c94btd2f457b893e3580c@mail.gmail.com>
Message-ID: <49B7B930.9090003@wald.ucdavis.edu>


Hi Hiroyuki



Hiroyuki Kawakatsu wrote:
> Hi,
> 
> I am having problems installing the XML package with R-devel on
> freebsd. If I simply do install.packages("XML"), it says that the
> parser.h file is not found. After reading the INSTALL file, I have set
> 
> setenv  XML_CONFIG /usr/local/bin/xml2-config
> setenv  LIBXML_LIBDIR -L/usr/local/lib
> setenv  LIBXML_INCDIR -I/usr/local/include/libxml2/libxml

That should probably be
  setenv  LIBXML_INCDIR -I/usr/local/include/libxml2

(rather than having the additional /libxml after it.)

Did you install libxml2 version 2.7.3 yourself,
i.e. separately from the installation of the operating system?
Is /usr/local/lib being searched for .so files by your dynamic
loader?

Try

   ldd `which xmllint`

to see what shared libraries it finds? Does it list
libxml2.so.2 and if so, where is the file to which it points -
/usr/lib or /usr/local/lib ? If it is /usr/lib, that is the
problem.

If this doesn't identify the problem, please download
the XML_2.3-0.tar.gz file and issue the commands

   tar zxf XML_2.3-0.tar.gz
   R CMD INSTALL XML

and send me the file XML/config.log and I can try to
find out what is going wrong form the details in that.

Thanks,
   D.


> 
> and install.packages("XML") fails with
> 
> checking for stdint.h... (cached) yes
> checking for unistd.h... (cached) yes
> checking for libxml/parser.h... (cached) no
> checking for gnome-xml/parser.h... (cached) no
> Located parser file -I/usr/local/include/libxml2/libxml/parser.h
> checking for gzopen in -lz... yes
> checking for xmlParseFile in -lxml2... yes
> You are trying to use a version 2.* edition of libxml
> but an incompatible library. The header files and library seem to be
> mismatched. If you have specified LIBXML_INCDIR, make certain to also
> specify an appropriate LIBXML_LIBDIR if the libxml2 library is not in
> the default
> directories.
> ERROR: configuration failed for package 'XML'
> * Removing '/usr/local/share/R-devel/library/XML'
> Warning in install.packages("XML", clean = TRUE) :
>   installation of package 'XML' had non-zero exit status
> 
> Some version info on my machine:
> 
> erdos# portversion -F "libxml*"
> libxml2-2.7.3               =
> 
> erdos# xml2-config --version
> 2.7.3
> 
> erdos# ls /usr/local/lib/libxml*
> /usr/local/lib/libxml2.a         /usr/local/lib/libxmlparse.so@
> /usr/local/lib/libxml2.la*       /usr/local/lib/libxmlparse.so.1*
> /usr/local/lib/libxml2.so@       /usr/local/lib/libxmltok.a
> /usr/local/lib/libxml2.so.5*     /usr/local/lib/libxmltok.la*
> /usr/local/lib/libxmlparse.a     /usr/local/lib/libxmltok.so@
> /usr/local/lib/libxmlparse.la*   /usr/local/lib/libxmltok.so.1*
> 
> The header LIBXML_INCDIR/xmlversion.h does define version as 2.7.3.
> Does anyone have an idea of what may be going wrong?
> 
> h.


From chalabi at phys.ethz.ch  Wed Mar 11 14:55:57 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 11 Mar 2009 14:55:57 +0100
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
Message-ID: <20090311145557.5c9b57e0@mimi>

Dear R developers,

As you might have noticed, recent changes in R-dev will not allow the  
definition of S3 methods with S4 classes.

But until now, we have defined "time<-" in our 'timeSeries' package as  
an S3 generic because other packages are using the same function.  
Indeed, if we had defined it as an S4 generic, the other packages  
would not coexist well with ours.

Another package might overwrite the generic and its methods when both  
packages are loaded.

In my understanding the only way to avoid this problem is to add

`time<-`
function (x, value)
{
    UseMethod("time<-")
}

in the 'stats' package.

As a wish for the forthcoming R version I would like to ask you if you  
could add "time<-" as a generic function in the 'stats' package to  
prevent conflicts and to ensure that packages continue to work well  
together.

Thank you in advance for your feedback!


-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From hkawakat at gmail.com  Wed Mar 11 14:57:27 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Wed, 11 Mar 2009 13:57:27 +0000
Subject: [Rd] configure fail for XML package on freebsd
In-Reply-To: <49B7B930.9090003@wald.ucdavis.edu>
References: <307b90470903110428i1635c94btd2f457b893e3580c@mail.gmail.com>
	<49B7B930.9090003@wald.ucdavis.edu>
Message-ID: <307b90470903110657o14a7178ere9c5a5ea06b0d91d@mail.gmail.com>

On 3/11/09, Duncan Temple Lang wrote:
[...]
>
>  That should probably be
>   setenv  LIBXML_INCDIR -I/usr/local/include/libxml2
>
>  (rather than having the additional /libxml after it.)

OK, thanks. But this still fails.

>  Did you install libxml2 version 2.7.3 yourself,
>  i.e. separately from the installation of the operating system?

I did not install myself. It must have been installed as dependency of
some other package.

>  Is /usr/local/lib being searched for .so files by your dynamic
>  loader?
>
>  Try
>
>   ldd `which xmllint`
>
>  to see what shared libraries it finds? Does it list
>  libxml2.so.2 and if so, where is the file to which it points -
>  /usr/lib or /usr/local/lib ? If it is /usr/lib, that is the
>  problem.

erdos# ldd `which xmllint`
/usr/local/bin/xmllint:
        libxml2.so.5 => /usr/local/lib/libxml2.so.5 (0x80063e000)
        libz.so.4 => /lib/libz.so.4 (0x800884000)
        libiconv.so.3 => /usr/local/lib/libiconv.so.3 (0x800998000)
        libm.so.5 => /lib/libm.so.5 (0x800b91000)
        libc.so.7 => /lib/libc.so.7 (0x800cab000)


>  If this doesn't identify the problem, please download
>  the XML_2.3-0.tar.gz file and issue the commands
>
>   tar zxf XML_2.3-0.tar.gz
>   R CMD INSTALL XML
>
>  and send me the file XML/config.log and I can try to
>  find out what is going wrong form the details in that.
[...]

Aha, thanks for the hint. Once I checked the config.log file, I found
the source of the error. XML was using a different version of gcc than
that used from building R-devel. So the solution was simply to do

R CMD INSTALL --configure-vars="MAKE=gmake CC=gcc44 ..." XML

Thanks very much for your help. Is there a way to automagically use
the configure-vars used to build R for any package installs without
having to explicitly pass them as above?

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From r.hijmans at gmail.com  Wed Mar 11 15:40:44 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 11 Mar 2009 22:40:44 +0800
Subject: [Rd] configure fail for XML package on freebsd
In-Reply-To: <307b90470903110657o14a7178ere9c5a5ea06b0d91d@mail.gmail.com>
References: <307b90470903110428i1635c94btd2f457b893e3580c@mail.gmail.com>
	<49B7B930.9090003@wald.ucdavis.edu>
	<307b90470903110657o14a7178ere9c5a5ea06b0d91d@mail.gmail.com>
Message-ID: <dc22b2570903110740i1b2785end92d99e6bb3a2513@mail.gmail.com>

I would like to write an S4 generic for 'median', but I am not sure
how to do this properly as the function does not have a "..." argument

I can do this

setGeneric("median", function(x, na.rm=FALSE)
	standardGeneric("median"))

but I want to be able to pass it a number of objects of the same
class, so I need a ... argument; or use signature='list' which is not
very useful.

I can do this:

setGeneric("median", function(x, ..., na.rm=FALSE)
	standardGeneric("median"))

and

setMethod('median', signature(x='ANY'),
function(x, ..., na.rm=FALSE){ x <- c(x, ...)
return(stats::median(x, na.rm=na.rm))
#	}
#)

setMethod("median", signature(x='Raster'),
	function(x, ..., na.rm=FALSE){

#		rasters <- list(...)


From r.hijmans at gmail.com  Wed Mar 11 15:45:35 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 11 Mar 2009 22:45:35 +0800
Subject: [Rd] generic method for median
Message-ID: <dc22b2570903110745w2960b0efm1ad625b2722c7a1d@mail.gmail.com>

Sorry, I pressed the wrong button (tab in gmail is tricky) , here is
my message again, now more complete, and with the right subject:

I would like to write an S4 generic for 'median', but I am not sure
how to do this properly as the function does not have a "..." argument

I can do this
setGeneric("median", function(x, na.rm=FALSE)
 ? ? ? ?standardGeneric("median"))

 but I want to be able to pass it a number of objects of the same
 class, so I need a ... argument; or use signature='list' which is not
 very useful.

 I can do this:

 setGeneric("median", function(x, ..., na.rm=FALSE)
 ? ? ? ?standardGeneric("median"))

 and

 setMethod('median', signature(x='ANY'),
 function(x, ..., na.rm=FALSE){ x <- c(x, ...)
 return(stats::median(x, na.rm=na.rm)) } )

and

setMethod("median", signature(x='Raster'),
? ? ? ?function(x, ..., na.rm=FALSE){
})

etcetera,

but that gives an ugly message at startup about my package hiding
median from stats.

Is there a solution for this, or does the stats::median function need
to be changed?

Thanks, Robert

> # ? ? ? ? ? ? ? rasters <- list(...)
>


From simon.urbanek at r-project.org  Wed Mar 11 15:52:27 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 11 Mar 2009 10:52:27 -0400
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B6E6D9.7010809@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
Message-ID: <96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>

Wacek,

Peter gave you a full answer explaining it very well. If you really  
want to be able to trace each instance yourself, you have to learn far  
more about R internals than you apparently know (and Peter hinted at  
that). Internally x=1 an x=c(1) are slightly different in that the  
former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is  
what causes the difference in behavior as Peter explained. The reason  
is that c(1) creates a copy of the 1 (which is a constant [=unmutable]  
thus requiring a copy) and the new copy has no other references and  
thus can be modified and hence NAMED(x) = 0.

Cheers,
Simon


On Mar 10, 2009, at 18:16 , Wacek Kusnierczyk wrote:

> i got an offline response saying that my original post may have not  
> been
> clear as to what the problem was, essentially, and that i may need to
> restate it in words, in addition to code.
>
> the problem is:  the performance of 'names<-' is incoherent, in that  
> in
> some situations it acts in a functional manner, producing a copy of  
> its
> argument with the names changed, while in others it changes the object
> in-place (and returns it), without copying first.  your explanation
> below is of course valid, but does not seem to address the issue.  in
> the examples below, there is always (or so it seems) just one  
> reference
> to the object.
>
> why are the following functional:
>
>    x = 1;  'names<-'(x, 'foo'); names(x)
>    x = 'foo'; 'names<-'(x, 'foo');  names(x)
>
> while these are destructive:
>
>    x = c(1);  'names<-'(x, 'foo'); names(x)
>    x = c('foo'); 'names<-'(x, 'foo');  names(x)
>
> it is claimed that in r a singular value is a one-element vector, and
> indeed,
>
>    identical(1, c(1))
>    # TRUE
>    all.equal(is(1), is(c(1)))
>    # TRUE
>
> i also do not understand the difference here:
>
>    x = c(1); 'names<-'(x, 'foo'); names(x)
>    # "foo"
>    x = c(1); names(x); 'names<-'(x, 'foo'); names(x)
>    # "foo"
>    x = c(1); print(x); 'names<-'(x, 'foo'); names(x)
>    # NULL
>    x = c(1); print(c(x)); 'names<-'(x, 'foo'); names(x)
>    # "foo"
>
> does print, but not names, increase the reference count for x when
> applied to x, but not to c(x)?
>
> if the issue is that there is, in those examples where x is left
> unchanged, an additional reference to x that causes the value of x  
> to be
> copied, could you please explain how and when this additional  
> reference
> is created?
>
>
> thanks,
> vQ
>
>
>
>
> Peter Dalgaard wrote:
>>
>>> is there something i misunderstand here?
>>>
>>
>> Only the ideology/pragmatism... In principle, R has call-by-value
>> semantics and a function does not destructively modify its  
>> arguments(*),
>> and foo(x)<-bar behaves like x <- "foo<-"(x, bar). HOWEVER, this has
>> obvious performance repercussions (think x <- rnorm(1e7); x[1] <-  
>> 0), so
>> we do allow destructive modification by replacement functions,  
>> PROVIDED
>> that the x is not used by anything else. On the least suspicion that
>> something else is using the object, a copy of x is made before the
>> modification.
>>
>> So
>>
>> (A) you should not use code like y <- "foo<-"(x, bar)
>>
>> because
>>
>> (B) you cannot (easily) predict whether or not x will be modified
>> destructively
>>
>> --------
>> (*) unless you mess with match.call() or substitute() and the like.  
>> But
>> that's a different story.
>>
>>
>>
>
>
> -- 
> -------------------------------------------------------------------------------
> Wacek Kusnierczyk, MD PhD
>
> Email: waku at idi.ntnu.no
> Phone: +47 73591875, +47 72574609
>
> Department of Computer and Information Science (IDI)
> Faculty of Information Technology, Mathematics and Electrical  
> Engineering (IME)
> Norwegian University of Science and Technology (NTNU)
> Sem Saelands vei 7, 7491 Trondheim, Norway
> Room itv303
>
> Bioinformatics & Gene Regulation Group
> Department of Cancer Research and Molecular Medicine (IKM)
> Faculty of Medicine (DMF)
> Norwegian University of Science and Technology (NTNU)
> Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
> Room 231.05.060
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Wed Mar 11 16:03:32 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 11 Mar 2009 11:03:32 -0400
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
Message-ID: <8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>


On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:

> Wacek,
>
> Peter gave you a full answer explaining it very well. If you really  
> want to be able to trace each instance yourself, you have to learn  
> far more about R internals than you apparently know (and Peter  
> hinted at that). Internally x=1 an x=c(1) are slightly different in  
> that the former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0  
> which is what causes the difference in behavior as Peter explained.  
> The reason is that c(1) creates a copy of the 1 (which is a constant  
> [=unmutable] thus requiring a copy) and the new copy has no other  
> references and thus can be modified and hence NAMED(x) = 0.
>

Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above --  
since NAMED(c(1)) = 0 and once it's assigned to x it becomes NAMED(x)  
= 1 -- this is just a detail on how things work with assignment, the  
explanation above is still correct since duplication happens  
conditional on NAMED == 2.

Cheers,
Simon


> On Mar 10, 2009, at 18:16 , Wacek Kusnierczyk wrote:
>
>> i got an offline response saying that my original post may have not  
>> been
>> clear as to what the problem was, essentially, and that i may need to
>> restate it in words, in addition to code.
>>
>> the problem is:  the performance of 'names<-' is incoherent, in  
>> that in
>> some situations it acts in a functional manner, producing a copy of  
>> its
>> argument with the names changed, while in others it changes the  
>> object
>> in-place (and returns it), without copying first.  your explanation
>> below is of course valid, but does not seem to address the issue.  in
>> the examples below, there is always (or so it seems) just one  
>> reference
>> to the object.
>>
>> why are the following functional:
>>
>>   x = 1;  'names<-'(x, 'foo'); names(x)
>>   x = 'foo'; 'names<-'(x, 'foo');  names(x)
>>
>> while these are destructive:
>>
>>   x = c(1);  'names<-'(x, 'foo'); names(x)
>>   x = c('foo'); 'names<-'(x, 'foo');  names(x)
>>
>> it is claimed that in r a singular value is a one-element vector, and
>> indeed,
>>
>>   identical(1, c(1))
>>   # TRUE
>>   all.equal(is(1), is(c(1)))
>>   # TRUE
>>
>> i also do not understand the difference here:
>>
>>   x = c(1); 'names<-'(x, 'foo'); names(x)
>>   # "foo"
>>   x = c(1); names(x); 'names<-'(x, 'foo'); names(x)
>>   # "foo"
>>   x = c(1); print(x); 'names<-'(x, 'foo'); names(x)
>>   # NULL
>>   x = c(1); print(c(x)); 'names<-'(x, 'foo'); names(x)
>>   # "foo"
>>
>> does print, but not names, increase the reference count for x when
>> applied to x, but not to c(x)?
>>
>> if the issue is that there is, in those examples where x is left
>> unchanged, an additional reference to x that causes the value of x  
>> to be
>> copied, could you please explain how and when this additional  
>> reference
>> is created?
>>
>>
>> thanks,
>> vQ
>>
>>
>>
>>
>> Peter Dalgaard wrote:
>>>
>>>> is there something i misunderstand here?
>>>>
>>>
>>> Only the ideology/pragmatism... In principle, R has call-by-value
>>> semantics and a function does not destructively modify its  
>>> arguments(*),
>>> and foo(x)<-bar behaves like x <- "foo<-"(x, bar). HOWEVER, this has
>>> obvious performance repercussions (think x <- rnorm(1e7); x[1] <-  
>>> 0), so
>>> we do allow destructive modification by replacement functions,  
>>> PROVIDED
>>> that the x is not used by anything else. On the least suspicion that
>>> something else is using the object, a copy of x is made before the
>>> modification.
>>>
>>> So
>>>
>>> (A) you should not use code like y <- "foo<-"(x, bar)
>>>
>>> because
>>>
>>> (B) you cannot (easily) predict whether or not x will be modified
>>> destructively
>>>
>>> --------
>>> (*) unless you mess with match.call() or substitute() and the  
>>> like. But
>>> that's a different story.
>>>
>>>
>>>
>>
>>
>> -- 
>> -------------------------------------------------------------------------------
>> Wacek Kusnierczyk, MD PhD
>>
>> Email: waku at idi.ntnu.no
>> Phone: +47 73591875, +47 72574609
>>
>> Department of Computer and Information Science (IDI)
>> Faculty of Information Technology, Mathematics and Electrical  
>> Engineering (IME)
>> Norwegian University of Science and Technology (NTNU)
>> Sem Saelands vei 7, 7491 Trondheim, Norway
>> Room itv303
>>
>> Bioinformatics & Gene Regulation Group
>> Department of Cancer Research and Molecular Medicine (IKM)
>> Faculty of Medicine (DMF)
>> Norwegian University of Science and Technology (NTNU)
>> Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
>> Room 231.05.060
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From luke at stat.uiowa.edu  Wed Mar 11 17:49:32 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Wed, 11 Mar 2009 11:49:32 -0500 (CDT)
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <49B5A475.90105@biostat.ku.dk>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
	<49B5A475.90105@biostat.ku.dk>
Message-ID: <alpine.LFD.2.00.0903111128340.5957@nokomis.stat.uiowa.edu>

Looks like an infinite recursion in R_isMissing, which I think may be
turned into an infinite loop if the C compiler is doing tail call
optimization.  I need to understand why this is written the way it is
and also why another case that I would expect to also have this
problem does not before identifying the appropriate fix.

luke

On Tue, 10 Mar 2009, Peter Dalgaard wrote:

> Stavros Macrakis wrote:
>> Tested in: R version 2.8.1 (2008-12-22) / Windows
>> 
>> Recursive default argument references normally give nice clear errors.
>>  In the first set of examples, you get the error:
>>
>>   Error in ... :
>>   promise already under evaluation: recursive default argument
>> reference or earlier problems?
>>
>>   (function(a = a) a      ) ()
>>   (function(a = a) c(a)   ) ()
>>   (function(a = a) a[1]   ) ()
>>   (function(a = a) a[[1]] ) ()
>>   (function(a = a) a$x    ) ()
>>   (function(a = a) mean(a) )   ()
>>   (function(a = a) sort(a) ) ()
>>   (function(a = a) as.list(a) ) ()
>> 
>> But in the following examples, R seems not to detect the 'promise
>> already under evaluation' condition and instead gets a stack overflow,
>> with the error message:
>>
>>   Error: C stack usage is too close to the limit
>>
>>   (function(a = a)  (a)    ) ()
>>   (function(a = a)  -a     ) ()
>>   (function(a = a) var(a) ) ()
>>   (function(a = a) sum(a) ) ()
>>   (function(a = a) is.vector(a) ) ()
>>   (function(a = a) as.numeric(a) ) ()
>> 
>> I don't understand why the two sets of examples behave differently.
>
> Ouch!!!
>
> This shouldn't happen, I'm pretty sure. In particular not the apparently 
> unstoppable loop under Linux. Thanks for pointing it out.
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jmc at r-project.org  Wed Mar 11 17:57:43 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 11 Mar 2009 09:57:43 -0700
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
In-Reply-To: <20090311145557.5c9b57e0@mimi>
References: <20090311145557.5c9b57e0@mimi>
Message-ID: <49B7ED87.3090102@r-project.org>

Whatever one wants for an S3 generic, it's not needed to do what, 
presumably, you want here.

And for sure it is no excuse for S3 methods for S4 classes.

Back to basics: To write S4 methods for an existing function, the clean 
and simple way is usually:

setGeneric("time<-")

If your package depends on one that has S3  methods for this function, 
there will be a version of the function imported into your namespace.  
That function will then be the default method.

Presumably you want to ensure that S3 methods, for S3 classes, are still 
dispatched.  Quite reasonable and it should follow from the call to 
setGeneric.

If you wanted to have your own S3 methods or if you weren't willing to 
assume an S3 generic imported, you could do a 2-line version:

R(r48103)> `time<-` <- function(x, value) UseMethod("time<-")
R(r48103)> setGeneric("time<-")
[1] "time<-"
R(r48103)> showMethods("time<-", include = TRUE)
Function: time<- (package .GlobalEnv)
x="ANY"
function (x, value)
UseMethod("time<-")

As a postscript, here is the current plan, not yet committed, pending 
some more testing:
  - the bad methods will be allowed
  - warnings when a class is defined with such methods for a superclass
  - probably some other warnings, but not for an ordinary call to the 
method (it's the MISSING calls to the method that are the disaster).

More later,
  John


Yohan Chalabi wrote:
> Dear R developers,
>
> As you might have noticed, recent changes in R-dev will not allow the  
> definition of S3 methods with S4 classes.
>
> But until now, we have defined "time<-" in our 'timeSeries' package as  
> an S3 generic because other packages are using the same function.  
> Indeed, if we had defined it as an S4 generic, the other packages  
> would not coexist well with ours.
>
> Another package might overwrite the generic and its methods when both  
> packages are loaded.
>
> In my understanding the only way to avoid this problem is to add
>
> `time<-`
> function (x, value)
> {
>     UseMethod("time<-")
> }
>
> in the 'stats' package.
>
> As a wish for the forthcoming R version I would like to ask you if you  
> could add "time<-" as a generic function in the 'stats' package to  
> prevent conflicts and to ensure that packages continue to work well  
> together.
>
> Thank you in advance for your feedback!
>
>
>


From mniksere at scs.carleton.ca  Wed Mar 11 15:09:40 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Wed, 11 Mar 2009 10:09:40 -0400
Subject: [Rd] Compiling R-2.8.1 on Sparc Solaris 10: libRlapack.so: symbol
 __vlog_: referenced symbol not found
Message-ID: <49B7C624.9080700@scs.carleton.ca>

Hi,

I am compiling R2.8.1 on a Sun M4000 machine with Solaris 10.
I am using Sun Studio 12.
I get the following error:

cc -xtarget=native64 -G -L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9 -o 
grDevices.so chull.o devNull.o devPicTeX.o devPS.o devQuartz.o init.o
mkdir ../../../../library/grDevices/libs
Warning in solve.default(rgb) :
   unable to load shared library 
'/export/admin-home/nikser/R-2.8.1/modules//lapack.so':
   ld.so.1: R: fatal: relocation error: file 
/export/admin-home/nikser/R-2.8.1/lib/libRlapack.so: symbol __vlog_: 
referenced symbol not found
Error in solve.default(rgb) : lapack routines cannot be loaded
Error: unable to load R code in package 'grDevices'
Execution halted
*** Error code 1
The following command caused the error:
echo "tools:::makeLazyLoading(\"grDevices\")" | \
   R_DEFAULT_PACKAGES=NULL LC_ALL=C ../../../bin/R --vanilla --slave > 
/dev/null
make: Fatal error: Command failed for target `all'
Current working directory 
/export/admin-home/nikser/R-2.8.1/src/library/grDevices

I set the following environment variables:

export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
export CFLAGS="-I/usr/sfw/include -I/opt/csw/include"
export R_PAPERSIZE=letter
export CC="cc -xtarget=native64"
export FC="f95 -xtarget=native64"
export CXX="CC -xtarget=native64"
export CPPFLAGS="-I/usr/sfw/include -I/opt/csw/include"
export CFLAGS="-O -xlibmieee"
export F77="f95 -xtarget=native64"
export CXXFLAGS=-O
export FFLAGS="-O4 -xlibmopt -libmil -xvector=lib -fround=nearest"
export FCFLAGS=$FFLAGS
export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
export SHLIB_CXXLDFLAGS="-G -lCstd"
export BLAS_LIBS=-xlic_lib=sunperf
export LIBS="-lmvec"
export SHLIB_CFLAGS=-lmvec

and:

./configure --prefix=/opt/R-2.8.1 --enable-threads=solaris --with-blas

Could you please help me to pinpoint the problem.

Thanks
--
Mohammad


From ripley at stats.ox.ac.uk  Wed Mar 11 20:23:28 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2009 19:23:28 +0000 (GMT)
Subject: [Rd] Compiling R-2.8.1 on Sparc Solaris 10: libRlapack.so:
 symbol __vlog_: referenced symbol not found
In-Reply-To: <49B7C624.9080700@scs.carleton.ca>
References: <49B7C624.9080700@scs.carleton.ca>
Message-ID: <alpine.LFD.2.00.0903111920250.2878@gannet.stats.ox.ac.uk>

Please try the options recommended in the R-admin manual: these do not 
include using sunperf.

But if you want to choose your own options, ask your local Solaris 
help as this is not an R issue.

On Wed, 11 Mar 2009, Mohammad Nikseresht wrote:

> Hi,
>
> I am compiling R2.8.1 on a Sun M4000 machine with Solaris 10.
> I am using Sun Studio 12.
> I get the following error:
>
> cc -xtarget=native64 -G -L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9 -o 
> grDevices.so chull.o devNull.o devPicTeX.o devPS.o devQuartz.o init.o
> mkdir ../../../../library/grDevices/libs
> Warning in solve.default(rgb) :
>  unable to load shared library 
> '/export/admin-home/nikser/R-2.8.1/modules//lapack.so':
>  ld.so.1: R: fatal: relocation error: file 
> /export/admin-home/nikser/R-2.8.1/lib/libRlapack.so: symbol __vlog_: 
> referenced symbol not found
> Error in solve.default(rgb) : lapack routines cannot be loaded
> Error: unable to load R code in package 'grDevices'
> Execution halted
> *** Error code 1
> The following command caused the error:
> echo "tools:::makeLazyLoading(\"grDevices\")" | \
>  R_DEFAULT_PACKAGES=NULL LC_ALL=C ../../../bin/R --vanilla --slave > 
> /dev/null
> make: Fatal error: Command failed for target `all'
> Current working directory 
> /export/admin-home/nikser/R-2.8.1/src/library/grDevices
>
> I set the following environment variables:
>
> export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
> export CFLAGS="-I/usr/sfw/include -I/opt/csw/include"
> export R_PAPERSIZE=letter
> export CC="cc -xtarget=native64"
> export FC="f95 -xtarget=native64"
> export CXX="CC -xtarget=native64"
> export CPPFLAGS="-I/usr/sfw/include -I/opt/csw/include"
> export CFLAGS="-O -xlibmieee"
> export F77="f95 -xtarget=native64"
> export CXXFLAGS=-O
> export FFLAGS="-O4 -xlibmopt -libmil -xvector=lib -fround=nearest"
> export FCFLAGS=$FFLAGS
> export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
> export SHLIB_CXXLDFLAGS="-G -lCstd"
> export BLAS_LIBS=-xlic_lib=sunperf
> export LIBS="-lmvec"
> export SHLIB_CFLAGS=-lmvec
>
> and:
>
> ./configure --prefix=/opt/R-2.8.1 --enable-threads=solaris --with-blas
>
> Could you please help me to pinpoint the problem.
>
> Thanks
> --
> Mohammad
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Mar 11 20:29:14 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 11 Mar 2009 20:29:14 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
References: <49B67CB1.8060005@idi.ntnu.no>
	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
Message-ID: <49B8110A.5060909@idi.ntnu.no>

Simon Urbanek wrote:
> Wacek,
>
> Peter gave you a full answer explaining it very well. If you really
> want to be able to trace each instance yourself, you have to learn far
> more about R internals than you apparently know (and Peter hinted at
> that). Internally x=1 an x=c(1) are slightly different in that the
> former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is
> what causes the difference in behavior as Peter explained. The reason
> is that c(1) creates a copy of the 1 (which is a constant [=unmutable]
> thus requiring a copy) and the new copy has no other references and
> thus can be modified and hence NAMED(x) = 0.


simon, thanks for the explanation, it's now as clear as i might expect.

now i'm concerned with what you say:  that to understand something
visible to the user one needs to "learn far more about R internals than
one apparently knows".  your response suggests that to use r without
confusion one needs to know the internals, and this would be a really
bad thing to say..  i have long been concerned with that r unnecessarily
exposes users to its internals, and here's one more example of how the
interface fails to hide the guts.  (and peter did not give me a full
answer, but a vague hint.)

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Mar 11 20:31:18 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 11 Mar 2009 20:31:18 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
Message-ID: <49B81186.4070107@idi.ntnu.no>

Simon Urbanek wrote:
>
> On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
>
>> Wacek,
>>
>> Peter gave you a full answer explaining it very well. If you really
>> want to be able to trace each instance yourself, you have to learn
>> far more about R internals than you apparently know (and Peter hinted
>> at that). Internally x=1 an x=c(1) are slightly different in that the
>> former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is
>> what causes the difference in behavior as Peter explained. The reason
>> is that c(1) creates a copy of the 1 (which is a constant
>> [=unmutable] thus requiring a copy) and the new copy has no other
>> references and thus can be modified and hence NAMED(x) = 0.
>>
>
> Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above --
> since NAMED(c(1)) = 0 and once it's assigned to x it becomes NAMED(x)
> = 1 -- this is just a detail on how things work with assignment, the
> explanation above is still correct since duplication happens
> conditional on NAMED == 2.

i guess this is what every user needs to know to understand the
behaviour one can observe on the surface?  thanks for further
clarifications.

vQ


From Fraser_Sim at URMC.Rochester.edu  Wed Mar 11 21:15:36 2009
From: Fraser_Sim at URMC.Rochester.edu (Sim, Fraser)
Date: Wed, 11 Mar 2009 16:15:36 -0400
Subject: [Rd] Building R for Vistax64
Message-ID: <82377DC24E19614291D0B5A4A89DAD7401158B31@e2k3ms5.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090311/5600c198/attachment.pl>

From chalabi at phys.ethz.ch  Wed Mar 11 21:44:24 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 11 Mar 2009 21:44:24 +0100
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
In-Reply-To: <49B7ED87.3090102@r-project.org>
References: <20090311145557.5c9b57e0@mimi>
	<49B7ED87.3090102@r-project.org>
Message-ID: <20090311214424.558b4dff@mimi>

>>>> "JC" == John Chambers <jmc at r-project.org>
>>>> on Wed, 11 Mar 2009 09:57:43 -0700

   JC> Whatever one wants for an S3 generic, it's not needed to do what,
   JC> presumably, you want here.
   JC>
   JC> And for sure it is no excuse for S3 methods for S4 classes.
   JC>
   JC> Back to basics: To write S4 methods for an existing function, the clean
   JC> and simple way is usually:
   JC>
   JC> setGeneric("time<-")
   JC>
   JC> If your package depends on one that has S3  methods for this function,
   JC> there will be a version of the function imported into your namespace.
   JC> That function will then be the default method.
   JC>
   JC> Presumably you want to ensure that S3 methods, for S3 classes, are still
   JC> dispatched.  Quite reasonable and it should follow from the call to
   JC> setGeneric.
   JC>
   JC> If you wanted to have your own S3 methods or if you weren't willing to
   JC> assume an S3 generic imported, you could do a 2-line version:
   JC>
   JC> R(r48103)> `time<-` <- function(x, value) UseMethod("time<-")
   JC> R(r48103)> setGeneric("time<-")
   JC> [1] "time<-"
   JC> R(r48103)> showMethods("time<-", include = TRUE)
   JC> Function: time<- (package .GlobalEnv)
   JC> x="ANY"
   JC> function (x, value)
   JC> UseMethod("time<-")

In my opinion you example only works in '.GlobalEnv' environement, but
does not work when implemented in a package.

I wrote a small package to illustrate the problem.

## R code
oldDir <- getwd()
setwd(tempdir())

url <- "http://nic.phys.ethz.ch/~chalabi/timeProb_0.001.tar.gz"
download.file(url, "timeProb_0.001.tar.gz")
install.packages("timeProb_0.001.tar.gz", repos = NULL)

# you also need to install another package which uses `time<-`.
# for example zoo
if(!require(zoo))
    install.packages("zoo")

# Now we quit and start a new R session
setwd(oldDir)
q()

# new R

# we first load timeProb
library(timeProb)

# and then run the demo
demo(timeProb)

# now we quit and start again a new session
q()

# new R

# but now we first load zoo and after timeProb
library(zoo)
library(timeProb)

# and run again the demo
demo(timeProb)

## end R code

As far as I understand it, two packages can not coexist if one of
them defines an S3 generic and the other one defines an S4 generic
with the same name.

Or am I missing an option when defining the S4 generic?

   JC>
   JC> As a postscript, here is the current plan, not yet committed, pending
   JC> some more testing:
   JC>   - the bad methods will be allowed
   JC>   - warnings when a class is defined with such methods for a superclass
   JC>   - probably some other warnings, but not for an ordinary call to the
   JC> method (it's the MISSING calls to the method that are the disaster).
   JC>

Thanks for giving more information concerning the current plan.

   JC> More later,
   JC>   John
   JC>


regards,
Yohan

--
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From ripley at stats.ox.ac.uk  Wed Mar 11 22:03:45 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2009 21:03:45 +0000 (GMT)
Subject: [Rd] Building R for Vistax64
In-Reply-To: <82377DC24E19614291D0B5A4A89DAD7401158B31@e2k3ms5.urmc-sh.rochester.edu>
References: <82377DC24E19614291D0B5A4A89DAD7401158B31@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <alpine.LFD.2.00.0903112101400.13532@gannet.stats.ox.ac.uk>

Look in MkRules and the rw-FAQ. You can easily build R under Mingw64, 
but no one has reported making it run -- and several have reported 
failures.

Commercail vendors have built 64-bit R under other Windwos compilers.

On Wed, 11 Mar 2009, Sim, Fraser wrote:

> Hi all,
>
>
>
> I have successfully built from source the 32-bit version of R on my
> Vista 64-bit box. I was hoping to graduate to a 64-bit version so I
> could analyze some larger data sets. I have 8gb RAM installed.
>
>
>
> I downloaded the latest 64-bit versions of Perl and MinGW but wasn't
> sure how to edit the source code to have it build using the 64-bit
> versions. I did change my PATH variable to point to the bin directories
> of the 64-bit Perl and MinGW packages.
>
>
>
> Any pointers would be very helpful.
>
>
>
> Thanks,
>
> Fraser
>
> Fraser Sim, PhD
> Assistant Professor of Neurology & Neurosurgery
> University of Rochester
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kelley.dan at gmail.com  Wed Mar 11 23:06:02 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Wed, 11 Mar 2009 15:06:02 -0700 (PDT)
Subject: [Rd]  better function name: make or as
Message-ID: <22465595.post@talk.nabble.com>


I've written a function (for the 'oce' package) that takes a list of one type
of object (a "station", observations made by a ship at one location), and
creates another object (a "section", containing a sequence of station
observations).

My question is, should I name my function "make.section()" or
"as.section()"?

I wouldd like to pattern the name on other R functions, but I'm having
difficulty understanding when 'as' and 'make' are used.  (At the moment, I
am using 'make', because it seems to me that 'as' is mainly for mapping
input to output on a sort of one-to-one basis.)

Any suggestions?


-- 
View this message in context: http://www.nabble.com/better-function-name%3A-make-or-as-tp22465595p22465595.html
Sent from the R devel mailing list archive at Nabble.com.


From david at revolution-computing.com  Wed Mar 11 23:40:53 2009
From: david at revolution-computing.com (David M Smith)
Date: Wed, 11 Mar 2009 15:40:53 -0700
Subject: [Rd] Building R for Vistax64
In-Reply-To: <82377DC24E19614291D0B5A4A89DAD7401158B31@e2k3ms5.urmc-sh.rochester.edu>
References: <82377DC24E19614291D0B5A4A89DAD7401158B31@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <475a3c8f0903111540j33bf7beds8542e56b8281158c@mail.gmail.com>

On Wed, Mar 11, 2009 at 1:15 PM, Sim, Fraser
<Fraser_Sim at urmc.rochester.edu> wrote:
> Hi all,
>
> I have successfully built from source the 32-bit version of R on my
> Vista 64-bit box. I was hoping to graduate to a 64-bit version so I
> could analyze some larger data sets. I have 8gb RAM installed.

We (REvolution Computing) are beta testing a 64-bit build of R (2.7.2)
and its packages for Windows now.  There's more information at:

http://www.revolution-computing.com/products/windows-64bit.php

# David Smith

-- 
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (Seattle, USA)


From dmaszle at mendelbio.com  Thu Mar 12 01:55:12 2009
From: dmaszle at mendelbio.com (dmaszle at mendelbio.com)
Date: Thu, 12 Mar 2009 01:55:12 +0100 (CET)
Subject: [Rd] help.search(): "Error in .readRDS(hs_file) : error reading
	from connection" (PR#13591)
Message-ID: <20090312005512.E446428321A9@mail.pubhealth.ku.dk>

Full_Name: Don Maszle
Version: R version 2.8.1 (2008-12-22)
OS: Linux hood.mendelbio.com 2.6.18-128.el5 #1 SMP Wed Dec 17 11:41:38 EST 2008 x86_64 x86_64 x86_64 GNU/Linux
Submission from: (NULL) (206.86.87.3)


I have resolved the problem, but this is a possible regression to a problem
listed in the bug fixes for 2.3.1.

After a new installation, help.search() on any search string without a package
restriction issued:

  "Error in .readRDS(hs_file) : error reading from connection"

With a package restriction, it would work fine.  (See two probable but not
directly observed exceptions below.)

I installed 2.8.1 from an RPM from CRAN.  While installing additional packages,
my installation crashed due to me underestimating the required disk space.  An
apparent result of that was that one or two Meta/hsearch.rds files were not
created properly.  The ones in R.cache and Depela existed, but were of zero
size.  Once I re-installed those packages the problem went away.

>From the 2.3.1 comments, I assume this should not break the entire help.search
system, unless the R.cache index file is needed to cache other files!

Also, before reinstallation, I tried to run help.search('', package='R.cache',
rebuild=T) but it did not seem to have any effect.

~drm


From jmc at r-project.org  Thu Mar 12 03:10:29 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 11 Mar 2009 19:10:29 -0700
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
In-Reply-To: <20090311214424.558b4dff@mimi>
References: <20090311145557.5c9b57e0@mimi>	<49B7ED87.3090102@r-project.org>
	<20090311214424.558b4dff@mimi>
Message-ID: <49B86F15.3060700@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090311/56a4b92d/attachment.pl>

From berwin at maths.uwa.edu.au  Thu Mar 12 08:40:08 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 12 Mar 2009 15:40:08 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B81186.4070107@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
Message-ID: <20090312154008.56706f38@berwin-nus1>

On Wed, 11 Mar 2009 20:31:18 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Simon Urbanek wrote:
> >
> > On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
> >
> >> Wacek,
> >>
> >> Peter gave you a full answer explaining it very well. If you really
> >> want to be able to trace each instance yourself, you have to learn
> >> far more about R internals than you apparently know (and Peter
> >> hinted at that). Internally x=1 an x=c(1) are slightly different
> >> in that the former has NAMED(x) = 2 whereas the latter has
> >> NAMED(x) = 0 which is what causes the difference in behavior as
> >> Peter explained. The reason is that c(1) creates a copy of the 1
> >> (which is a constant [=unmutable] thus requiring a copy) and the
> >> new copy has no other references and thus can be modified and
> >> hence NAMED(x) = 0.
> >>
> >
> > Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above
> > -- since NAMED(c(1)) = 0 and once it's assigned to x it becomes
> > NAMED(x) = 1 -- this is just a detail on how things work with
> > assignment, the explanation above is still correct since
> > duplication happens conditional on NAMED == 2.
> 
> i guess this is what every user needs to know to understand the
> behaviour one can observe on the surface? 

Nope, only users who prefer to write '+'(1,2) instead of 1+2, or
'names<-'(x, 'foo') instead of names(x)='foo'.

Attempting to change the name attribute of x via 'names<-'(x, 'foo')
looks to me as if one relies on a side effect of the function
'names<-'; which, in my book would be a bad thing.  I.e. relying on side
effects of a function, or writing functions with side effects which are
then called for their side-effects;  this, of course, excludes
functions like plot() :)  I never had the need to call 'names<-'()
directly and cannot foresee circumstances in which I would do so.

Plenty of users, including me, are happy using the latter forms and,
hence, never have to bother with understanding these implementation
details or have to bother about them.  

Your mileage obviously varies, but that is when you have to learn about
these internal details.  If you call functions because of their
side-effects, you better learn what the side-effects are exactly.

Cheers,

	Berwin


From berwin at maths.uwa.edu.au  Thu Mar 12 08:46:16 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 12 Mar 2009 15:46:16 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B8110A.5060909@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<49B8110A.5060909@idi.ntnu.no>
Message-ID: <20090312154616.5b650ce2@berwin-nus1>

On Wed, 11 Mar 2009 20:29:14 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Simon Urbanek wrote:
> > Wacek,
> >
> > Peter gave you a full answer explaining it very well. If you really
> > want to be able to trace each instance yourself, you have to learn
> > far more about R internals than you apparently know (and Peter
> > hinted at that). Internally x=1 an x=c(1) are slightly different in
> > that the former has NAMED(x) = 2 whereas the latter has NAMED(x) =
> > 0 which is what causes the difference in behavior as Peter
> > explained. The reason is that c(1) creates a copy of the 1 (which
> > is a constant [=unmutable] thus requiring a copy) and the new copy
> > has no other references and thus can be modified and hence NAMED(x)
> > = 0.
> 
> 
> simon, thanks for the explanation, it's now as clear as i might
> expect.
> 
> now i'm concerned with what you say:  that to understand something
> visible to the user one needs to "learn far more about R internals
> than one apparently knows".  your response suggests that to use r
> without confusion one needs to know the internals, 

Simon can probably speak for himself, but according to my reading he
has not suggested anything similar to what you suggest he suggested. :)

> and this would be a really bad thing to say.. 

No problems, since he did not say anything vaguely similar to what you
suggest he said.

Cheers,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 10:05:36 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 10:05:36 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312154008.56706f38@berwin-nus1>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
Message-ID: <49B8D060.8090206@idi.ntnu.no>

Berwin A Turlach wrote:
> On Wed, 11 Mar 2009 20:31:18 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>   
>> Simon Urbanek wrote:
>>     
>>> On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
>>>
>>>       
>>>> Wacek,
>>>>
>>>> Peter gave you a full answer explaining it very well. If you really
>>>> want to be able to trace each instance yourself, you have to learn
>>>> far more about R internals than you apparently know (and Peter
>>>> hinted at that). Internally x=1 an x=c(1) are slightly different
>>>> in that the former has NAMED(x) = 2 whereas the latter has
>>>> NAMED(x) = 0 which is what causes the difference in behavior as
>>>> Peter explained. The reason is that c(1) creates a copy of the 1
>>>> (which is a constant [=unmutable] thus requiring a copy) and the
>>>> new copy has no other references and thus can be modified and
>>>> hence NAMED(x) = 0.
>>>>
>>>>         
>>> Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above
>>> -- since NAMED(c(1)) = 0 and once it's assigned to x it becomes
>>> NAMED(x) = 1 -- this is just a detail on how things work with
>>> assignment, the explanation above is still correct since
>>> duplication happens conditional on NAMED == 2.
>>>       
>> i guess this is what every user needs to know to understand the
>> behaviour one can observe on the surface? 
>>     
>
> Nope, only users who prefer to write '+'(1,2) instead of 1+2, or
> 'names<-'(x, 'foo') instead of names(x)='foo'.
>
>   

well, as far as i remember, it has been said on this list that in r the
infix syntax is equivalent to the prefix syntax, so no one wanting to
use the form above should be afraid of different semantics;  these two
forms should be perfectly equivalent.  after all,

    x = 1
    names(x) = 'foo'
    names(x)

should return NULL, because when the second assignment is made, we need
to make a copy of the value of x, so it is the copy that should have
changed names, not the value of x (which would still be the original 1).

on the other hand, the fact that

    names(x) = 'foo'

is (or so it seems) a shorthand for

    x = 'names<-'(x, 'foo')

is precisely why i'd think that the prefix 'names<-' should never do
destructive modifications, because that's what x = 'names<-'(x, 'foo'),
and thus also names(x) = 'foo', is for.

i guess the above is sort of blasphemy.

> Attempting to change the name attribute of x via 'names<-'(x, 'foo')
> looks to me as if one relies on a side effect of the function
> 'names<-'; which, in my book would be a bad thing.  

indeed;  so, for coherence, 'names<-' should always do the modification
on a copy.  it would then have semantics different from the infix form
of 'names<-', but at least consistently so.



> I.e. relying on side
> effects of a function, or writing functions with side effects which are
> then called for their side-effects;  this, of course, excludes
> functions like plot() :)  I never had the need to call 'names<-'()
> directly and cannot foresee circumstances in which I would do so.
>   

> Plenty of users, including me, are happy using the latter forms and,
> hence, never have to bother with understanding these implementation
> details or have to bother about them.  
>
> Your mileage obviously varies, but that is when you have to learn about
> these internal details.  If you call functions because of their
> side-effects, you better learn what the side-effects are exactly.
>   

well, i can imagine a user using the prefix 'names<-' precisely under
the assumption that it will perform functionally;  i.e., 'names<-'(x,
'foo') will always produce a copy of x with the new names, and never
change the x.  that there will be a destructive modification made to x
on some, but not all, occasions, is hardly a good thing in this context
-- and it's not a situation where a user wants to use the function
"because of its side effects", quite to the contrary.  this was actually
the situation i had when i first discovered the surprizing behaviour of
'names<-';  i thought 'names<-' did *not* have side effects.

cheers, and thanks for the discussion.
vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 10:08:08 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 10:08:08 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312154616.5b650ce2@berwin-nus1>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<49B8110A.5060909@idi.ntnu.no>
	<20090312154616.5b650ce2@berwin-nus1>
Message-ID: <49B8D0F8.2080602@idi.ntnu.no>

Berwin A Turlach wrote:
> On Wed, 11 Mar 2009 20:29:14 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>   
>> Simon Urbanek wrote:
>>     
>>> Wacek,
>>>
>>> Peter gave you a full answer explaining it very well. If you really
>>> want to be able to trace each instance yourself, you have to learn
>>> far more about R internals than you apparently know (and Peter
>>> hinted at that). Internally x=1 an x=c(1) are slightly different in
>>> that the former has NAMED(x) = 2 whereas the latter has NAMED(x) =
>>> 0 which is what causes the difference in behavior as Peter
>>> explained. The reason is that c(1) creates a copy of the 1 (which
>>> is a constant [=unmutable] thus requiring a copy) and the new copy
>>> has no other references and thus can be modified and hence NAMED(x)
>>> = 0.
>>>       
>> simon, thanks for the explanation, it's now as clear as i might
>> expect.
>>
>> now i'm concerned with what you say:  that to understand something
>> visible to the user one needs to "learn far more about R internals
>> than one apparently knows".  your response suggests that to use r
>> without confusion one needs to know the internals, 
>>     
>
> Simon can probably speak for himself, but according to my reading he
> has not suggested anything similar to what you suggest he suggested. :)
>   

so i did not say *he* suggested this.  'your response suggests' does
not, on my reading, imply any intention from simon's side.  but it's you
who is an expert in (a dialect of) english, so i won't argue.


>   
>> and this would be a really bad thing to say.. 
>>     
>
> No problems, since he did not say anything vaguely similar to what you
> suggest he said.
>   

let's not depart from the point.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 10:21:18 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 10:21:18 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B8D060.8090206@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
Message-ID: <49B8D40E.5000103@idi.ntnu.no>

Wacek Kusnierczyk wrote:
>
> is precisely why i'd think that the prefix 'names<-' should never do
> destructive modifications, because that's what x = 'names<-'(x, 'foo'),
> and thus also names(x) = 'foo', is for.
>
>   

to make the point differently, i'd expect the following two to be
equivalent:

    x = c(1); 'names<-'(x, 'foo'); names(x)
    # "foo"

    x = c(1); do.call('names<-', list(x, 'foo')); names(x)
    # NULL

but they're obviously not.  and of course, just that i'd expect it is
not a strong argument.

vQ


From berwin at maths.uwa.edu.au  Thu Mar 12 10:32:31 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 12 Mar 2009 17:32:31 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B8D060.8090206@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
Message-ID: <20090312173231.7a2929df@berwin-nus1>

On Thu, 12 Mar 2009 10:05:36 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> well, as far as i remember, it has been said on this list that in r
> the infix syntax is equivalent to the prefix syntax, [...]

Whoever said that must have been at that moment not as precise as he or
she could have been.  Also, R does not behave according to what people
say on this list (which is good, because some times people they wrong
things on this list) but according to how it is documented to do; at
least that is what people on this list (and others) say. :)

And the R Language manual (ignoring for the moment that it is a draft
and all that), clearly states that 

	names(x) <- c("a","b")

is equivalent to
	
	'*tmp*' <- x
         x <- "names<-"('*tmp*', value=c("a","b"))

[...]
> well, i can imagine a user using the prefix 'names<-' precisely under
> the assumption that it will perform functionally;  

You mean
	y <- 'names<-'(x, "foo")
instead of
	y <- x
	names(y) <- "foo"
?

Fair enough.  But I would still prefer the latter version this it is
(for me) easier to read and to decipher the intention of the code.

> i.e., 'names<-'(x, 'foo') will always produce a copy of x with the
> new names, and never change the x.  

I am not sure whether R ever behaved in that way, but as Peter pointed
out, this would be quite undesirable from a memory management and
performance point of view.  Image that every time you modify a (name)
component of a large object a new copy of that object is created.
 
> cheers, and thanks for the discussion.

You are welcome.

Cheers,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 10:53:19 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 10:53:19 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312173231.7a2929df@berwin-nus1>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
Message-ID: <49B8DB8F.5030704@idi.ntnu.no>

Berwin A Turlach wrote:
>
> Whoever said that must have been at that moment not as precise as he or
> she could have been.  Also, R does not behave according to what people
> say on this list (which is good, because some times people they wrong
> things on this list) but according to how it is documented to do; at
> least that is what people on this list (and others) say. :)
>   

well, ?'names<-' says:

"
Value:
     For 'names<-', the updated object. 
"

which is only partially correct, in that the value will sometimes be an
updated *copy* of the object.

> And the R Language manual (ignoring for the moment that it is a draft
> and all that), 

since we must...

> clearly states that 
>
> 	names(x) <- c("a","b")
>
> is equivalent to
> 	
> 	'*tmp*' <- x
>          x <- "names<-"('*tmp*', value=c("a","b"))
>   

... and?  does this say anything about what 'names<-'(...) actually
returns?  updated *tmp*, or a copy of it?


> [...]
>   
>> well, i can imagine a user using the prefix 'names<-' precisely under
>> the assumption that it will perform functionally;  
>>     
>
> You mean
> 	y <- 'names<-'(x, "foo")
> instead of
> 	y <- x
> 	names(y) <- "foo"
> ?
>   

what i mean is, rather precisely, that 'names<-'(x, 'foo') will produce
a *new* object with a copy of the value of x and names as specified, and
will *not*, under any circumstances, modify x.

the first line above does not quite address this, e.g.:

    x = c(1)
    y = 'names<-'(x, 'foo')
    names(x)
    # "foo", 'should' be NULL


> Fair enough.  But I would still prefer the latter version this it is
> (for me) easier to read and to decipher the intention of the code.
>   

you're welcome to use it.  but this is personal preference, and i'm
trying to discuss the semantics of r here.  what you show is a way to
clutter the code, and you need to explicitly name the new object, while,
in functional programming, it is typical to operate on anonymous objects
passed from one function to another, e.g.

    f('names<-'(x, 'foo'))

which would have to become

    y = x
    names(y) = 'foo'
    f(y)

or

    f({y = x; names(y) = 'foo'; y})

with 'y' being a nuissance name.


>> i.e., 'names<-'(x, 'foo') will always produce a copy of x with the
>> new names, and never change the x.  
>>     
>
> I am not sure whether R ever behaved in that way, but as Peter pointed
> out, this would be quite undesirable from a memory management and
> performance point of view.  

why?  you can still use the infix names<- with destructive semantics to
avoid copying. 


> Image that every time you modify a (name)
> component of a large object a new copy of that object is created.
>   

see above.  besides, r has been several times claimed here (but see your
remark above) to be a functional language, and in this context it is
surprising that the smart (i mean it) copy-on-assignment mechanism,
which is an implementational optimization, not only becomes visible, but
also makes functions (hmm, procedures?) such as 'names<-' non-functional
-- in some, but not all, cases.

vQ


From hamstersquats at web.de  Thu Mar 12 11:15:40 2009
From: hamstersquats at web.de (Thomas Roth (geb. Kaliwe))
Date: Thu, 12 Mar 2009 11:15:40 +0100
Subject: [Rd] S4 coerce as.data.frame for lm
Message-ID: <49B8E0CC.3040905@web.de>

#Hi,
#
#I posted this already on r-help... with no success :-(
#
#For a given class test, an object of class test cannot be used as data 
in the lm method although as.data.frame was implemented... where's my 
mistake?
#
#Suppose i have defined a S4 class test

#S4 Class test containting a slot data
#which is of type data.frame

setClass(Class = "test", representation = representation(name = 
"character", data = "data.frame") 
temp = new("test")   #temp is of class test

temp at data = faithful   #assign some data to it

#now define as.data.frame for class test
setMethod("as.data.frame", "test", function(x, row.names = NULL, 
optional = FALSE)
{

 return(x at data)

}
)

as.data.frame(temp)   #works

lm(eruptions ~ waiting, data = temp)   #doesn't work


#Thank you for any hints
#Thomas Roth



#from the lm help page
|#data| - an optional data frame, list or environment (or object 
coercible by |as.data.frame| to a data frame) containing the variables 
in the model. If not found in |data|, the variables are taken from 
|environment(formula)|, typically the #environment from which |lm| is 
called.


From jmacdon at med.umich.edu  Thu Mar 12 14:17:09 2009
From: jmacdon at med.umich.edu (James MacDonald)
Date: Thu, 12 Mar 2009 09:17:09 -0400
Subject: [Rd] iconv.dll in Windows
Message-ID: <49B8D31B.47B0.00EE.0@med.umich.edu>

I recently built R-devel on Windows XP (sessionInfo below), and when loading libraries that require the iconv.dll was getting an error stating that 'This application has failed to start because iconv.dll was not found. Re-installing the application may fix this problem.'.

An R-2.8.1 that I installed using the Windows installer has this dll in R-2.8.1/bin, whereas in R-devel it is still in R-devel/src/gnuwin32/unicode. Moving the dll  to R-devel/bin alleviates the problem.

I built using the recent recommendations of P. Dalgaard  (make Rpwd.exe, make link-recommended, make all recommended). I don't see anything in the NEWS for this version, but maybe I missed something?

Best,

Jim

> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-03-11 r48117) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
[1] XML_1.99-0
-- 

James W. MacDonald, M.S.
Biostatistician
Douglas Lab
5912 Buhl
1241 E. Catherine St.
Ann Arbor MI 48109-5618
734-615-7826


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues


From berwin at maths.uwa.edu.au  Thu Mar 12 14:35:08 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 12 Mar 2009 21:35:08 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B8DB8F.5030704@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no>
Message-ID: <20090312213508.719afa73@berwin5>

On Thu, 12 Mar 2009 10:53:19 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> well, ?'names<-' says:
> 
> "
> Value:
>      For 'names<-', the updated object. 
> "
> 
> which is only partially correct, in that the value will sometimes be
> an updated *copy* of the object.

But since R supposedly uses call-by-value (though we know how to
circumvent that, don't we?) wouldn't you always expect that a copy of
the object is returned?
 
> > And the R Language manual (ignoring for the moment that it is a
> > draft and all that), 
> 
> since we must...
> 
> > clearly states that 
> >
> > 	names(x) <- c("a","b")
> >
> > is equivalent to
> > 	
> > 	'*tmp*' <- x
> >          x <- "names<-"('*tmp*', value=c("a","b"))
> >   
> 
> ... and?  

This seems to suggest that in this case the infix and prefix syntax
is not equivalent as it does not say that 
	names(x) <- c("a","b")
is equivalent to
	x <- "names<-"(x, value=c("a","b"))
and I was commenting on the claim that the infix syntax is equivalent
to the prefix syntax.

> does this say anything about what 'names<-'(...) actually
> returns?  updated *tmp*, or a copy of it?

Since R uses pass-by-value, you would expect the latter, wouldn't
you?  If you entertain the idea that 'names<-' updates *tmp* and
returns the updated *tmp*, then you believe that 'names<-' behaves in a
non-standard way and should take appropriate care.

And the fact that a variable *tmp* is used hints to the fact that
'names<-' might have side-effect.  If 'names<-' has side effects,
then it might not be well defined with what value x ends up with if
one executes:
	x <- 'names<-'(x, value=c("a","b"))  

This is similar to the discussion what value i should have in the
following C snippet:
	i = 0;
 	i += i++;
 
[..]
> > I am not sure whether R ever behaved in that way, but as Peter
> > pointed out, this would be quite undesirable from a memory
> > management and performance point of view.  
> 
> why?  you can still use the infix names<- with destructive semantics
> to avoid copying. 

I guess that would require a rewrite (or extension) of the parser.  To
me, Section 10.1.2 of the Language Definition manual suggests that once
an expression is parsed, you cannot distinguish any more whether
'names<-' was called using infix syntax or prefix syntax.

Thus, I guess you want to start a discussion with R Core whether it is
worthwhile to change the parser such that it keeps track on whether a
function was used with infix notation or prefix notation and to
provide for most (all?) assignment operators implementations that use
destructive semantics if the infix version was used and always copy if
the prefix notation is used. 

Cheers,

	Berwin


From ligges at statistik.tu-dortmund.de  Thu Mar 12 14:55:55 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 12 Mar 2009 14:55:55 +0100
Subject: [Rd] iconv.dll in Windows
In-Reply-To: <49B8D31B.47B0.00EE.0@med.umich.edu>
References: <49B8D31B.47B0.00EE.0@med.umich.edu>
Message-ID: <49B9146B.70802@statistik.tu-dortmund.de>

See .../R/src/gnuwin32/CHANGES:

     o	iconv() is now done by a version of Yukihiro Nakadaira's
	win_iconv rather than by libiconv.  This version is based on
	Windows' codepages and is not quite as comprehensive as
	libiconv: it is however much smaller and easier to maintain.
	The implementation here is 100% compatible: you can drop in
	libiconv's iconv.dll as a replacement if you need it, from
	http://www.stats.ox.ac.uk/pub/Rtools/Riconv.dll.

	To avoid name conflicts with Gtk+, it has been renamed to
	Riconv.dll.

Uwe Ligges



James MacDonald wrote:
> I recently built R-devel on Windows XP (sessionInfo below), and when loading libraries that require the iconv.dll was getting an error stating that 'This application has failed to start because iconv.dll was not found. Re-installing the application may fix this problem.'.
> 
> An R-2.8.1 that I installed using the Windows installer has this dll in R-2.8.1/bin, whereas in R-devel it is still in R-devel/src/gnuwin32/unicode. Moving the dll  to R-devel/bin alleviates the problem.
> 
> I built using the recent recommendations of P. Dalgaard  (make Rpwd.exe, make link-recommended, make all recommended). I don't see anything in the NEWS for this version, but maybe I missed something?
> 
> Best,
> 
> Jim
> 
>> sessionInfo()
> R version 2.9.0 Under development (unstable) (2009-03-11 r48117) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base     
> 
> other attached packages:
> [1] XML_1.99-0


From ripley at stats.ox.ac.uk  Thu Mar 12 15:03:14 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Mar 2009 14:03:14 +0000 (GMT)
Subject: [Rd] iconv.dll in Windows
In-Reply-To: <49B9146B.70802@statistik.tu-dortmund.de>
References: <49B8D31B.47B0.00EE.0@med.umich.edu>
	<49B9146B.70802@statistik.tu-dortmund.de>
Message-ID: <alpine.LFD.2.00.0903121401540.31819@gannet.stats.ox.ac.uk>

On Thu, 12 Mar 2009, Uwe Ligges wrote:

> See .../R/src/gnuwin32/CHANGES:
>
>    o	iconv() is now done by a version of Yukihiro Nakadaira's
> 	win_iconv rather than by libiconv.  This version is based on
> 	Windows' codepages and is not quite as comprehensive as
> 	libiconv: it is however much smaller and easier to maintain.
> 	The implementation here is 100% compatible: you can drop in
> 	libiconv's iconv.dll as a replacement if you need it, from
> 	http://www.stats.ox.ac.uk/pub/Rtools/Riconv.dll.
>
> 	To avoid name conflicts with Gtk+, it has been renamed to
> 	Riconv.dll.

and

     o   Since iconv.dll has been renamed, packages wanting to link
         against it need to use -lRiconv (or, hetter, use the entry
         points in R_exts/Riconv.h).


>
> Uwe Ligges
>
>
>
> James MacDonald wrote:
>> I recently built R-devel on Windows XP (sessionInfo below), and when 
>> loading libraries that require the iconv.dll was getting an error stating 
>> that 'This application has failed to start because iconv.dll was not found. 
>> Re-installing the application may fix this problem.'.
>> 
>> An R-2.8.1 that I installed using the Windows installer has this dll in 
>> R-2.8.1/bin, whereas in R-devel it is still in 
>> R-devel/src/gnuwin32/unicode. Moving the dll  to R-devel/bin alleviates the 
>> problem.
>> 
>> I built using the recent recommendations of P. Dalgaard  (make Rpwd.exe, 
>> make link-recommended, make all recommended). I don't see anything in the 
>> NEWS for this version, but maybe I missed something?
>> 
>> Best,
>> 
>> Jim
>> 
>>> sessionInfo()
>> R version 2.9.0 Under development (unstable) (2009-03-11 r48117) 
>> i386-pc-mingw32 
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
>> States.1252;LC_MONETARY=English_United 
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices datasets  utils     methods   base 
>> other attached packages:
>> [1] XML_1.99-0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 15:21:50 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 15:21:50 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312213508.719afa73@berwin5>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>
	<20090312213508.719afa73@berwin5>
Message-ID: <49B91A7E.50107@idi.ntnu.no>

Berwin A Turlach wrote:
> On Thu, 12 Mar 2009 10:53:19 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>   
>> well, ?'names<-' says:
>>
>> "
>> Value:
>>      For 'names<-', the updated object. 
>> "
>>
>> which is only partially correct, in that the value will sometimes be
>> an updated *copy* of the object.
>>     
>
> But since R supposedly 

*supposedly*

> uses call-by-value (though we know how to
> circumvent that, don't we?) 

we know how a lot of built-ins hack around this, don't we, and we also
know that call-by-value is not really the argument passing mechanism in r.

> wouldn't you always expect that a copy of
> the object is returned?
>   

indeed!  that's what i have said previously, no?  there is still space
for the smart (i mean it) copy-on-assignment behaviour, but it should
not be visible to the user, in particular, not in that 'names<-'
destructively modifies the object it is given when the refcount is 1. 
in my humble opinion, there is either a design flaw or a bug here.


>  
>   
>>> And the R Language manual (ignoring for the moment that it is a
>>> draft and all that), 
>>>       
>> since we must...
>>
>>     
>>> clearly states that 
>>>
>>> 	names(x) <- c("a","b")
>>>
>>> is equivalent to
>>> 	
>>> 	'*tmp*' <- x
>>>          x <- "names<-"('*tmp*', value=c("a","b"))
>>>   
>>>       
>> ... and?  
>>     
>
> This seems to suggest 

seems to suggest?  is not the purpose of documentation to clearly,
ideally beyond any doubt, specify what is to be specified?

> that in this case the infix and prefix syntax
> is not equivalent as it does not say that 
>   

are you suggesting fortune telling from what the docs do *not* say?

> 	names(x) <- c("a","b")
> is equivalent to
> 	x <- "names<-"(x, value=c("a","b"))
> and I was commenting on the claim that the infix syntax is equivalent
> to the prefix syntax.
>
>   
>> does this say anything about what 'names<-'(...) actually
>> returns?  updated *tmp*, or a copy of it?
>>     
>
> Since R uses pass-by-value, 

since?  it doesn't!

> you would expect the latter, wouldn't
> you?  

yes, that's what i'd expect in a functional language.

> If you entertain the idea that 'names<-' updates *tmp* and
> returns the updated *tmp*, then you believe that 'names<-' behaves in a
> non-standard way and should take appropriate care.
>   

i got lost in your argumentation.  i have given examples of where
'names<-' destructively modifies and returns the updated object, not a
copy.  what is your point here?

> And the fact that a variable *tmp* is used hints to the fact that
> 'names<-' might have side-effect.  

are you suggesting fortune telling from the fact that a variable *tmp*
is used?


> If 'names<-' has side effects,
> then it might not be well defined with what value x ends up with if
> one executes:
> 	x <- 'names<-'(x, value=c("a","b"))  
>   

not really, unless you mean the returned object in the referential sense
(memory location) versus value conceptually.  here x will obviously have
the value of the original x plus the names, *but* indeed you cannot tell
from this snippet whether after the assignment x will be the same,
though updated, object or will rather be an updated copy:

    x = c(1)
    x = 'names<-'(x, 'foo')
    # x is the same object

    x = c(1)
    y = x
    x = 'names<-'(x, 'foo')
    # x is another object

so, as you say, it is not well defined with what object will x end up as
its value, though the value of the object visible to the user is well
defined.  rewrite the above and play:

    x = c(1)
    y = 'names<-'(x, 'foo')
    names(x)

what are the names of x?  is y identical (sensu refernce) with x, is y
different (sensu reference) but indiscernible (sensu value) from x, or
is y different (sensu value) from x in that y has names and x doesn't?



> This is similar to the discussion what value i should have in the
> following C snippet:
> 	i = 0;
>  	i += i++;
>   

nonsense, it's a *completely* different issue.  here you touch the issue
of the order of evaluation, and not of whether an object is copied or
modified;  above, the inverse is true.

in fact, your example is useless because the result here is clearly
specified by the semantics (as far as i know -- prove me wrong).  you
lookup i (0) and i (0) (the order does not matter here), add these
values (0), assign to i (0), and increase i (1). 

i have a better example for you:

    int i = 0;
    i += ++i - ++i

which will give different final values for i in c (2 with gcc 4.2, 1
with gcc 3.4), c# and java (-1), perl (2) and php (1).  again, this has
nothing to do with the above.



>  
> [..]
>   
>>> I am not sure whether R ever behaved in that way, but as Peter
>>> pointed out, this would be quite undesirable from a memory
>>> management and performance point of view.  
>>>       
>> why?  you can still use the infix names<- with destructive semantics
>> to avoid copying. 
>>     
>
> I guess that would require a rewrite (or extension) of the parser.  To
> me, Section 10.1.2 of the Language Definition manual suggests that once
> an expression is parsed, you cannot distinguish any more whether
> 'names<-' was called using infix syntax or prefix syntax.
>   

but this must be nonsense, since:

    x = 1
    'names<-'(x, 'foo')
    names(x)
    # NULL

    x = 1
    names(x) <- 'foo'
    names(x)
    # "foo"

clearly, there is not only syntactic difference here.  but it might be
that 10.1.2 does not suggest anything like what you say.


> Thus, I guess you want to start a discussion with R Core whether it is
> worthwhile to change the parser such that it keeps track on whether a
> function was used with infix notation or prefix notation and to
> provide for most (all?) assignment operators implementations that use
> destructive semantics if the infix version was used and always copy if
> the prefix notation is used. 
>   

as i explained a few months ago, i study r to find examples of bad
design.  if anyone in the r core is interested in having the problems i
report fixed, i'm happy to get involved in a discussion about the design
and implementation.  if not, i'm happy with just pointing out the issues.

cheers,
vQ


From ripley at stats.ox.ac.uk  Thu Mar 12 15:22:47 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Mar 2009 14:22:47 +0000 (GMT)
Subject: [Rd] r-devel tarball build failure on windows
In-Reply-To: <307b90470903101000l4a4d9d49rfc3b84767ab6abc5@mail.gmail.com>
References: <307b90470903100051j2992efcdt144d4e47ccce17fb@mail.gmail.com>
	<49B61F7D.7020006@statistik.tu-dortmund.de>
	<49B64680.4070406@biostat.ku.dk>
	<49B67512.6060309@statistik.tu-dortmund.de>
	<307b90470903101000l4a4d9d49rfc3b84767ab6abc5@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0903112210300.15896@gannet.stats.ox.ac.uk>

I realized that there was a different point tacked on here that has 
not been answered:

On Tue, 10 Mar 2009, Hiroyuki Kawakatsu wrote:

[...]

> By the way, I noticed that -make all recommended- still builds the CHM
> help files for certain packages (e.g. Matrix) even though I set
> USE_CHM=FALSE in MkRules. Is this expected?

Yes, it was expected.  MkRules is only used for building R, not 
installing packages.  The default for installing contributed packages 
is to build CHM help if and only if the Help Compiler is available, so 
all recommended packages followed that rule.

We haven't made a final decision yet whether to support CHM help in 
future versions (and one point R-devel did not do so and it was 
planned to drop this for 2.9.0): my expectations are that we will 
support it in 2.9.0 and that USE_CHM will then control the options 
used to install the recommended packages, but that support may be 
withdrawn at some not too distant point.

I intend in the next week or so (GFF is Mar 20) to review what loose 
ends there are in package installation and Windows builds and tidy 
them up.  Once we have an alpha pre-release, reports on such matters 
will be welcome but until then they are a distraction.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at stat.uiowa.edu  Thu Mar 12 15:38:34 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Thu, 12 Mar 2009 09:38:34 -0500 (CDT)
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <alpine.LFD.2.00.0903111128340.5957@nokomis.stat.uiowa.edu>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>
	<49B5A475.90105@biostat.ku.dk>
	<alpine.LFD.2.00.0903111128340.5957@nokomis.stat.uiowa.edu>
Message-ID: <alpine.LFD.2.00.0903120937410.5957@nokomis.stat.uiowa.edu>

Thanks to Stavros for the report.  This should now be fixed in R-devel.

luke

On Wed, 11 Mar 2009, luke at stat.uiowa.edu wrote:

> Looks like an infinite recursion in R_isMissing, which I think may be
> turned into an infinite loop if the C compiler is doing tail call
> optimization.  I need to understand why this is written the way it is
> and also why another case that I would expect to also have this
> problem does not before identifying the appropriate fix.
>
> luke
>
> On Tue, 10 Mar 2009, Peter Dalgaard wrote:
>
>> Stavros Macrakis wrote:
>>> Tested in: R version 2.8.1 (2008-12-22) / Windows
>>> 
>>> Recursive default argument references normally give nice clear errors.
>>>  In the first set of examples, you get the error:
>>>
>>>   Error in ... :
>>>   promise already under evaluation: recursive default argument
>>> reference or earlier problems?
>>>
>>>   (function(a = a) a      ) ()
>>>   (function(a = a) c(a)   ) ()
>>>   (function(a = a) a[1]   ) ()
>>>   (function(a = a) a[[1]] ) ()
>>>   (function(a = a) a$x    ) ()
>>>   (function(a = a) mean(a) )   ()
>>>   (function(a = a) sort(a) ) ()
>>>   (function(a = a) as.list(a) ) ()
>>> 
>>> But in the following examples, R seems not to detect the 'promise
>>> already under evaluation' condition and instead gets a stack overflow,
>>> with the error message:
>>>
>>>   Error: C stack usage is too close to the limit
>>>
>>>   (function(a = a)  (a)    ) ()
>>>   (function(a = a)  -a     ) ()
>>>   (function(a = a) var(a) ) ()
>>>   (function(a = a) sum(a) ) ()
>>>   (function(a = a) is.vector(a) ) ()
>>>   (function(a = a) as.numeric(a) ) ()
>>> 
>>> I don't understand why the two sets of examples behave differently.
>> 
>> Ouch!!!
>> 
>> This shouldn't happen, I'm pretty sure. In particular not the apparently 
>> unstoppable loop under Linux. Thanks for pointing it out.
>> 
>> 
>> 
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 15:51:11 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 15:51:11 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B91A7E.50107@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no>
Message-ID: <49B9215F.5030201@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> Berwin A Turlach wrote:
>   
>
>> This is similar to the discussion what value i should have in the
>> following C snippet:
>> 	i = 0;
>>  	i += i++;
>>   
>>     
>
>
> in fact, your example is useless because the result here is clearly
> specified by the semantics (as far as i know -- prove me wrong).  you
> lookup i (0) and i (0) (the order does not matter here), add these
> values (0), assign to i (0), and increase i (1). 
>   

i'm happy to prove myself wrong.  the c programming language, 2nd ed. by
ritchie and kernigan, has the following discussion:

"
One unhappy situation is typified by the statement

    a[i] = i++;

The question is whether the subscript is the old value of i or the new.
Compilers can interpret
this in different ways, and generate different answers depending on
their interpretation. The
standard intentionally leaves most such matters unspecified.
"

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 15:54:35 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 15:54:35 +0100
Subject: [Rd] E`<`<rrors in recursive default argument references
In-Reply-To: <alpine.LFD.2.00.0903120937410.5957@nokomis.stat.uiowa.edu>
References: <8b356f880903091213o33e27e8di878e4ec574347015@mail.gmail.com>	<49B5A475.90105@biostat.ku.dk>	<alpine.LFD.2.00.0903111128340.5957@nokomis.stat.uiowa.edu>
	<alpine.LFD.2.00.0903120937410.5957@nokomis.stat.uiowa.edu>
Message-ID: <49B9222B.4090204@idi.ntnu.no>

luke at stat.uiowa.edu wrote:
> Thanks to Stavros for the report.  This should now be fixed in R-devel.

indeed, though i find some of the error messages strange:

    (function(a=a) -a)()
    # Error in (function(a = a) -a)() :
    #  element 1 is empty;
    #   the part of the args list of '-' being evaluated was:
    #   (a)

    (function(a=a) c(a))()
    # Error in (function(a = a) c(a))() :
    #   promise already under evaluation: recursive default argument
reference or earlier problems?

why are they different?

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 16:12:03 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 16:12:03 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
References: <49B67CB1.8060005@idi.ntnu.no>
	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
Message-ID: <49B92643.6060401@idi.ntnu.no>

Simon Urbanek wrote:
>
> On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
>
>> Wacek,
>>
>> Peter gave you a full answer explaining it very well. If you really
>> want to be able to trace each instance yourself, you have to learn
>> far more about R internals than you apparently know (and Peter hinted
>> at that). Internally x=1 an x=c(1) are slightly different in that the
>> former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is
>> what causes the difference in behavior as Peter explained. The reason
>> is that c(1) creates a copy of the 1 (which is a constant
>> [=unmutable] thus requiring a copy) and the new copy has no other
>> references and thus can be modified and hence NAMED(x) = 0.
>>
>
> Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above --
> since NAMED(c(1)) = 0 and once it's assigned to x it becomes NAMED(x)
> = 1 -- this is just a detail on how things work with assignment, the
> explanation above is still correct since duplication happens
> conditional on NAMED == 2.

there is an interesting corollary.  self-assignment seems to increase
the reference count:

    x = 1;  'names<-'(x, 'foo'); names(x)
    # NULL

    x = 1;  x = x;  'names<-'(x, 'foo'); names(x)
    # "foo"

vQ


From berwin at maths.uwa.edu.au  Thu Mar 12 16:12:40 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 12 Mar 2009 23:12:40 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B91A7E.50107@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no>
Message-ID: <20090312231240.6a061f0b@berwin5>

On Thu, 12 Mar 2009 15:21:50 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

[...]   
> >>> And the R Language manual (ignoring for the moment that it is a
> >>> draft and all that), 
> >>>       
> >> since we must...
> >>
> >>     
> >>> clearly states that 
> >>>
> >>> 	names(x) <- c("a","b")
> >>>
> >>> is equivalent to
> >>> 	
> >>> 	'*tmp*' <- x
> >>>          x <- "names<-"('*tmp*', value=c("a","b"))
> >>>   
> >>>       
> >> ... and?  
> >>     
> >
> > This seems to suggest 
> 
> seems to suggest?  is not the purpose of documentation to clearly,
> ideally beyond any doubt, specify what is to be specified?

The R Language Definition manual is still a draft. :)

> > that in this case the infix and prefix syntax
> > is not equivalent as it does not say that 
> >   
> 
> are you suggesting fortune telling from what the docs do *not* say?

My experience is that sometimes you have to realise what is not
stated.  I remember a discussion with somebody who asked why he could
not run, on windows, R CMD INSTALL on a *.zip file.  I pointed out to
him that the documentation states that you can run R CMD INSTALL on
*.tar.gz or *.tgz files and, thus, there should be no expectation that
it can be run on *.zip file.

YMMV, but when I read a passage like this in R documentation, I start
to wonder why it is stated that 
	names(x) <- c("a","b")
is equivalent to 
	*tmp* <- x
	x <- "names<-"('*tmp*', value=c("a","b"))
and the simpler construct
	x <- "names<-"(x, value=c("a", "b"))
is not used.  There must be a reason, nobody likes to type
unnecessarily long code.  And, after thinking about this for a while,
the penny might drop.

[...] 
> >> does this say anything about what 'names<-'(...) actually
> >> returns?  updated *tmp*, or a copy of it?
> >>     
> >
> > Since R uses pass-by-value, 
> 
> since?  it doesn't!

For all practical purposes it is as long as standard evaluation is
used.  One just have to be aware that some functions evaluate their
arguments in a non-standard way.  

[...]
> > If you entertain the idea that 'names<-' updates *tmp* and
> > returns the updated *tmp*, then you believe that 'names<-' behaves
> > in a non-standard way and should take appropriate care. 
> 
> i got lost in your argumentation.  [..]

I was commenting on "does this say anything about what 'names<-'(...)
actually returns?  updated *tmp*, or a copy of it?"

As I said, if you entertain the idea that 'names<-' returns an updated
*tmp*, then you believe that 'names<-' behaves in a non-standard way
and appropriate care has to be taken.

> > And the fact that a variable *tmp* is used hints to the fact that
> > 'names<-' might have side-effect.  
> 
> are you suggesting fortune telling from the fact that a variable *tmp*
> is used?

Nothing to do with fortune telling.  One reads the manual, one wonders
why is this construct used instead of an apparently much more simple
one, one reflects and investigates, one realises why the given
construct is stated as the equivalent: because "names<-" has
side-effects.

> > This is similar to the discussion what value i should have in the
> > following C snippet:
> > 	i = 0;
> >  	i += i++;
> >   
> 
> nonsense, it's a *completely* different issue.  here you touch the
> issue of the order of evaluation, and not of whether an object is
> copied or modified;  above, the inverse is true.

Sorry, there was a typo above.  The second statement should have been
	i = i++;

Then on some abstract level they are the same; an object appears on the
left hand side of an assignment but is also modified in the expression
assigned to it.  So what value should it end up with?

   
> >> why?  you can still use the infix names<- with destructive
> >> semantics to avoid copying. 
> >>     
> >
> > I guess that would require a rewrite (or extension) of the parser.
> > To me, Section 10.1.2 of the Language Definition manual suggests
> > that once an expression is parsed, you cannot distinguish any more
> > whether 'names<-' was called using infix syntax or prefix syntax.
> >   
> 
> but this must be nonsense, since:
> 
>     x = 1
>     'names<-'(x, 'foo')
>     names(x)
>     # NULL
> 
>     x = 1
>     names(x) <- 'foo'
>     names(x)
>     # "foo"
> 
> clearly, there is not only syntactic difference here.  but it might be
> that 10.1.2 does not suggest anything like what you say.

Please tell me how this example contradicts my reading of 10.1.2 that
the expressions 
	'names<-'(x, 'foo')
and
	names(x) <- 'foo'
once they are parsed, produce exactly the same parse tree and that it
becomes impossible to tell from the parse tree whether originally the
infix syntax or the prefix syntax was used.  In fact, the last sentence
in section 10.1.2 strongly suggests to me that the parse tree stores
all function calls as if prefix notation was used.  But it is probably
my English again.....

> > Thus, I guess you want to start a discussion with R Core whether it
> > is worthwhile to change the parser such that it keeps track on
> > whether a function was used with infix notation or prefix notation
> > and to provide for most (all?) assignment operators implementations
> > that use destructive semantics if the infix version was used and
> > always copy if the prefix notation is used. 
> >   
> 
> as i explained a few months ago, i study r to find examples of bad
> design.  if anyone in the r core is interested in having the problems
> i report fixed, 

Well, whether something is bad design and/or is a problem is in the eye
of the beholder.

Cheers,

	Berwin


From simon.urbanek at r-project.org  Thu Mar 12 17:47:24 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 12 Mar 2009 12:47:24 -0400
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B92643.6060401@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>
	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B92643.6060401@idi.ntnu.no>
Message-ID: <1C7E6CAE-222C-4A7D-B9E6-CC27692D65BB@r-project.org>


On Mar 12, 2009, at 11:12 , Wacek Kusnierczyk wrote:

> Simon Urbanek wrote:
>>
>> On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
>>
>>> Wacek,
>>>
>>> Peter gave you a full answer explaining it very well. If you really
>>> want to be able to trace each instance yourself, you have to learn
>>> far more about R internals than you apparently know (and Peter  
>>> hinted
>>> at that). Internally x=1 an x=c(1) are slightly different in that  
>>> the
>>> former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is
>>> what causes the difference in behavior as Peter explained. The  
>>> reason
>>> is that c(1) creates a copy of the 1 (which is a constant
>>> [=unmutable] thus requiring a copy) and the new copy has no other
>>> references and thus can be modified and hence NAMED(x) = 0.
>>>
>>
>> Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above --
>> since NAMED(c(1)) = 0 and once it's assigned to x it becomes NAMED(x)
>> = 1 -- this is just a detail on how things work with assignment, the
>> explanation above is still correct since duplication happens
>> conditional on NAMED == 2.
>
> there is an interesting corollary.  self-assignment seems to  
> increase the reference count:
>
>    x = 1;  'names<-'(x, 'foo'); names(x)
>    # NULL
>
>    x = 1;  x = x;  'names<-'(x, 'foo'); names(x)
>    # "foo"
>

Not for me, at least in current R:

 > x = 1;  'names<-'(x, 'foo'); names(x)
foo
   1
NULL
 > x = 1;  x = x;  'names<-'(x, 'foo'); names(x)
foo
   1
NULL

(both R 2.8.1 and R-devel 3/11/09, darwin 9.6)

In addition, you still got it backwards - your output suggests that  
the assignment created a new, clean copy. Functional call of `names<-`  
(whose side-effect on x is undefined BTW) is destructive when you get  
a clean copy (e.g. as a result of the c function) and non-destructive  
when the object was referenced. It is left as an exercise to the  
reader to reason why constants such as 1 are referenced.

Cheers,
Simon


From zhou.zfang at gmail.com  Thu Mar 12 18:45:39 2009
From: zhou.zfang at gmail.com (Zhou Fang)
Date: Thu, 12 Mar 2009 17:45:39 +0000
Subject: [Rd] How does R handle interrupts?
Message-ID: <b19557450903121045n35841c10s530e4ba4dce82cf1@mail.gmail.com>

Hi,

I wonder if anyone can clear some things up for me to help me read the
R source code.

Suppose R receives SIGINT whilst processing R code... Where is that
handled? What gets called?

If you have R >source a script, where is that script stored? How does
R keep track of where it is in the script?

My overall goal is to find out if there's a way somehow so that on a
signal, R could be made to modify, possibly temporarily the script it
is currently executing in an useful way, by, say, inserting
'browser()' at the next convenient point, or running an user-set
function, or something. Unless there's some reason why allowing this
is a very bad idea?

Thanks for any help that can be provided.

Zhou Fang


From mniksere at scs.carleton.ca  Thu Mar 12 20:03:57 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Thu, 12 Mar 2009 15:03:57 -0400
Subject: [Rd] Compiling R-2.8.1 on Sparc Solaris 10: libRlapack.so:
 symbol __vlog_: referenced symbol not found
In-Reply-To: <alpine.LFD.2.00.0903111920250.2878@gannet.stats.ox.ac.uk>
References: <49B7C624.9080700@scs.carleton.ca>
	<alpine.LFD.2.00.0903111920250.2878@gannet.stats.ox.ac.uk>
Message-ID: <49B95C9D.3040603@scs.carleton.ca>

Problem was solved by adding "-lmvec" to FLIBS in Makeconf.
__vlog_ is part of libmvec.so but apparently configure does not chose 
the proper option (-lmvec).

--
Mohammad Nikseresht
Software/System Engineer
HPCVL, Carleton University
mniksere at scs.carleton.ca
613-520-2600 x8758



Prof Brian Ripley wrote:
> Please try the options recommended in the R-admin manual: these do not 
> include using sunperf.
> 
> But if you want to choose your own options, ask your local Solaris help 
> as this is not an R issue.
> 
> On Wed, 11 Mar 2009, Mohammad Nikseresht wrote:
> 
>> Hi,
>>
>> I am compiling R2.8.1 on a Sun M4000 machine with Solaris 10.
>> I am using Sun Studio 12.
>> I get the following error:
>>
>> cc -xtarget=native64 -G -L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9 
>> -o grDevices.so chull.o devNull.o devPicTeX.o devPS.o devQuartz.o init.o
>> mkdir ../../../../library/grDevices/libs
>> Warning in solve.default(rgb) :
>>  unable to load shared library 
>> '/export/admin-home/nikser/R-2.8.1/modules//lapack.so':
>>  ld.so.1: R: fatal: relocation error: file 
>> /export/admin-home/nikser/R-2.8.1/lib/libRlapack.so: symbol __vlog_: 
>> referenced symbol not found
>> Error in solve.default(rgb) : lapack routines cannot be loaded
>> Error: unable to load R code in package 'grDevices'
>> Execution halted
>> *** Error code 1
>> The following command caused the error:
>> echo "tools:::makeLazyLoading(\"grDevices\")" | \
>>  R_DEFAULT_PACKAGES=NULL LC_ALL=C ../../../bin/R --vanilla --slave > 
>> /dev/null
>> make: Fatal error: Command failed for target `all'
>> Current working directory 
>> /export/admin-home/nikser/R-2.8.1/src/library/grDevices
>>
>> I set the following environment variables:
>>
>> export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
>> export CFLAGS="-I/usr/sfw/include -I/opt/csw/include"
>> export R_PAPERSIZE=letter
>> export CC="cc -xtarget=native64"
>> export FC="f95 -xtarget=native64"
>> export CXX="CC -xtarget=native64"
>> export CPPFLAGS="-I/usr/sfw/include -I/opt/csw/include"
>> export CFLAGS="-O -xlibmieee"
>> export F77="f95 -xtarget=native64"
>> export CXXFLAGS=-O
>> export FFLAGS="-O4 -xlibmopt -libmil -xvector=lib -fround=nearest"
>> export FCFLAGS=$FFLAGS
>> export LDFLAGS="-L/usr/sfw/lib/sparcv9 -L/opt/csw/lib/sparcv9"
>> export SHLIB_CXXLDFLAGS="-G -lCstd"
>> export BLAS_LIBS=-xlic_lib=sunperf
>> export LIBS="-lmvec"
>> export SHLIB_CFLAGS=-lmvec
>>
>> and:
>>
>> ./configure --prefix=/opt/R-2.8.1 --enable-threads=solaris --with-blas
>>
>> Could you please help me to pinpoint the problem.
>>
>> Thanks
>> -- 
>> Mohammad
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From mniksere at scs.carleton.ca  Thu Mar 12 20:16:14 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Thu, 12 Mar 2009 15:16:14 -0400
Subject: [Rd] Error compiling rgl package
Message-ID: <49B95F7E.5020406@scs.carleton.ca>

Hi,

I receive the following error while I try to install rgl package:

CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
-I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H -I/usr/include/libpng12 
-DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
-I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
-I/usr/sfw/include -I/opt/csw/include    -KPIC  -O -c Background.cpp -o 
Background.o
"math.h", line 47: Error: modf is not a member of file level.
"math.h", line 48: Error: modff is not a member of file level.
"Shape.hpp", line 58: Error: The function "strncpy" must have a prototype.
3 Error(s) detected.

I am using Sun studio 12.
I suspect that this is an incompatibility between g++ and Sun studio CC.
I would appreciate any you could share your experience with me.


Thanks

--
Mohammad Nikseresht
Software/System Engineer
HPCVL, Carleton University
mniksere at scs.carleton.ca
613-520-2600 x8758


From gkerns at ysu.edu  Thu Mar 12 21:24:19 2009
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Thu, 12 Mar 2009 16:24:19 -0400
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312231240.6a061f0b@berwin5>
References: <49B67CB1.8060005@idi.ntnu.no>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no> <20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no> <20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
Message-ID: <a695148b0903121324q16003f8cj549c1027b9019e43@mail.gmail.com>

Wacek Kusnierczyk wrote:

[snip]

> as i explained a few months ago, i study r to find examples of bad
> design.  if anyone in the r core is interested in having the problems i
> report fixed, i'm happy to get involved in a discussion about the design
> and implementation.  if not, i'm happy with just pointing out the issues.

:-)

I am prompted to imagine someone pointing out to the volunteers of the
International Red Cross - on the field of a natural disaster, no less
- that their uniforms are not an acceptably consistent shade of
pink... or that the screws on their tourniquets do not have the
appropriate pitch as to minimize the friction for the turner...

As a practicing statistician I am simply thankful that the bleeding is
stopped.   :-)

Cheers to R-Core (and the hundreds of other volunteers).
Jay



***************************************************
G. Jay Kerns, Ph.D.
Associate Professor
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 21:26:15 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 21:26:15 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090312231240.6a061f0b@berwin5>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>
	<20090312231240.6a061f0b@berwin5>
Message-ID: <49B96FE7.2060705@idi.ntnu.no>

Berwin A Turlach wrote:
> On Thu, 12 Mar 2009 15:21:50 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>   
>> seems to suggest?  is not the purpose of documentation to clearly,
>> ideally beyond any doubt, specify what is to be specified?
>>     
>
> The R Language Definition manual is still a draft. :)
>   

this is indeed a good explanation for all sorts of nonsense.  worse if
stuff tends to persist despite critique.

>   
>>> that in this case the infix and prefix syntax
>>> is not equivalent as it does not say that 
>>>   
>>>       
>> are you suggesting fortune telling from what the docs do *not* say?
>>     
>
> My experience is that sometimes you have to realise what is not
> stated.  

in general, yes.  in r, this often ends up with 'have you seen the
documentation saying that??' in response.

> I remember a discussion with somebody who asked why he could
> not run, on windows, R CMD INSTALL on a *.zip file.  I pointed out to
> him that the documentation states that you can run R CMD INSTALL on
> *.tar.gz or *.tgz files and, thus, there should be no expectation that
> it can be run on *.zip file.
>   

yes, that's a good point.  this reminds me of a (possibly anectodal)
lady who sued the manufacturer of her microwave after she had dried in
it her cat after a bath.

> YMMV, but when I read a passage like this in R documentation, I start
> to wonder why it is stated that 
> 	names(x) <- c("a","b")
> is equivalent to 
> 	*tmp* <- x
> 	x <- "names<-"('*tmp*', value=c("a","b"))
> and the simpler construct
> 	x <- "names<-"(x, value=c("a", "b"))
> is not used.  There must be a reason, 

got an explanation:  because it probably is as drafty as the
aforementioned document.

> nobody likes to type
> unnecessarily long code.  And, after thinking about this for a while,
> the penny might drop.
>   

that's cool.  instead of stating what 'names<-' does or does not, one
expresses it in a convoluted way an makes you guess from a *tmp*
variable. a nice exercise, i like it.

> [...] 
>   
>>>> does this say anything about what 'names<-'(...) actually
>>>> returns?  updated *tmp*, or a copy of it?
>>>>     
>>>>         
>>> Since R uses pass-by-value, 
>>>       
>> since?  it doesn't!
>>     
>
> For all practical purposes it is as long as standard evaluation is
> used.  One just have to be aware that some functions evaluate their
> arguments in a non-standard way.  
>   

it's maybe a bit of hairsplitting, but what you have in r is not exactly
what is called 'pass by value'.  here's a relevant quote from [1], p. 309:

"
In the call-by-name (CBN) mechanism, a formal parameter names the
computation designated by an unevaluated argument expression.

In the call-by-value (CBV) mechanism, a formal parameter names the value
of an evaluated argument expression.

In the call-by-need or lazy evaluation (CBL), the formal parameter name
can be bound to a location that originally stores the computation of the
argument expression. The first time the parameter is referenced, the
computation is performed, but the resulting value is cached at the
location and is used on every subsequent reference. Thus, the argument
expression is evaluated at most once and is never evaluated at all if
the parameter is never referenced.
"

note the 'unevaluated' and 'evaluated'.  you're free to have your pick. 

but it is possible to send an argument to a function that makes an
assignment to the argument, and yet the assignment is made to the
original, not to a copy:

    foo = function(arg) arg$foo = foo

    e = new.env()
    foo(e)
    e$foo
      
are you sure this is pass by value?

it appears that r has a pass-by-need mechanism that dispatches to
pass-by-value or pass-by-reference depending on the type of the object. 
with this semantics, all sorts of mess are possible, and 'names<-'
provides one example.

[1] design concepts in programming languages, turbak and gifford, mit
press 2008


> [...]
>   
>>> If you entertain the idea that 'names<-' updates *tmp* and
>>> returns the updated *tmp*, then you believe that 'names<-' behaves
>>> in a non-standard way and should take appropriate care. 
>>>       
>> i got lost in your argumentation.  [..]
>>     
>
> I was commenting on "does this say anything about what 'names<-'(...)
> actually returns?  updated *tmp*, or a copy of it?"
>
> As I said, if you entertain the idea that 'names<-' returns an updated
> *tmp*, then you believe that 'names<-' behaves in a non-standard way
> and appropriate care has to be taken.
>
>   

i can check, by experimentation, whether 'names<-' returns a copy or the
original; even if i can establish that it returns the original after
having modified it, it's not something to entertain.  maybe you
entertain the idea of your users performing the guesswork instead of
reading an unambiguous specification.  you have already said that you
don't care if your users get confused, it would fit the image.

and actually, in the example we discuss, 'names<-' does *not* return an
updated *tmp*, so there's even less to entertain.  for fun and more
guesswork, the example could have been:

    x = x
    x = 'names<-'(x, value=c('a', 'b'))

for your interest in well written documentation, ?names says that the
argument x is 'an r object', and nowhere does it say that environment is
not an r object.  it also says what the value of 'names<-' applied to
pairlists is.  the following error message is doubly surprising:

    e = new.env()
    'names<-'(e, 'foo')
    # Error: names() applied to a non-vector

firstly, because it would seem that there's nothing wrong in applying
names to an environment;  from ?'$':

"
    x$name

    name: A literal character string or a name (possibly backtick
          quoted).  For extraction, this is normally (see under
          'Environments') partially matched to the 'names' of the
          object.
"

secondly, because, as ?names says, names can be applied to pairlists,
which are not vectors, and the following does not give an error as above:

    p = pairlist()
    is.vector(p)
    # FALSE
    names(p)
    # names successfully applied to a non-vector
   
assure me this is not a mess, but a well-documented design feature.


>>> And the fact that a variable *tmp* is used hints to the fact that
>>> 'names<-' might have side-effect.  
>>>       
>> are you suggesting fortune telling from the fact that a variable *tmp*
>> is used?
>>     
>
> Nothing to do with fortune telling.  One reads the manual, one wonders
> why is this construct used instead of an apparently much more simple
> one, one reflects and investigates, one realises why the given
> construct is stated as the equivalent: because "names<-" has
> side-effects.
>   

... and one wonders why r man pages have to be read in O(e^n) time.

>   
>>> This is similar to the discussion what value i should have in the
>>> following C snippet:
>>> 	i = 0;
>>>  	i += i++;
>>>   
>>>       
>> nonsense, it's a *completely* different issue.  here you touch the
>> issue of the order of evaluation, and not of whether an object is
>> copied or modified;  above, the inverse is true.
>>     
>
> Sorry, there was a typo above.  The second statement should have been
> 	i = i++;
>   

it was fine, as i acknowledged in another mail, i got into deep trouble
and had to admit the specification does not guarantee the final value. 
but it was irrelevant.

> Then on some abstract level they are the same; an object appears on the
> left hand side of an assignment but is also modified in the expression
> assigned to it.  So what value should it end up with?
>   

on this abstract level it's fine, but we can go up to the most
philosophical issue this way.  let's not.

>    
>   
>>>> why?  you can still use the infix names<- with destructive
>>>> semantics to avoid copying. 
>>>>     
>>>>         
>>> I guess that would require a rewrite (or extension) of the parser.
>>> To me, Section 10.1.2 of the Language Definition manual suggests
>>> that once an expression is parsed, you cannot distinguish any more
>>> whether 'names<-' was called using infix syntax or prefix syntax.
>>>   
>>>       
>> but this must be nonsense, since:
>>
>>     x = 1
>>     'names<-'(x, 'foo')
>>     names(x)
>>     # NULL
>>
>>     x = 1
>>     names(x) <- 'foo'
>>     names(x)
>>     # "foo"
>>
>> clearly, there is not only syntactic difference here.  but it might be
>> that 10.1.2 does not suggest anything like what you say.
>>     
>
> Please tell me how this example contradicts my reading of 10.1.2 that
> the expressions 
> 	'names<-'(x, 'foo')
> and
> 	names(x) <- 'foo'
> once they are parsed, produce exactly the same parse tree and that it
> becomes impossible to tell from the parse tree whether originally the
> infix syntax or the prefix syntax was used.  

because if they produced the same parse tree, you would either have to
have the same result in both cases (because the same parse tree is
interpreted), or you'd have to magically interpret the same tree in two
different ways, depending on the (lost in translation) original
syntactic form.  or:  the interpreter interprets the parse tree
simultaneously looking at the original expression to choose the right
way to interpret the tree.

please tell me how this example does *not* show that the two forms have
different semantics (and then, how do they have the same parse trees?).

> In fact, the last sentence
> in section 10.1.2 strongly suggests to me that the parse tree stores
> all function calls as if prefix notation was used.  But it is probably
> my English again.....
>   

please see above.

>   
>>> Thus, I guess you want to start a discussion with R Core whether it
>>> is worthwhile to change the parser such that it keeps track on
>>> whether a function was used with infix notation or prefix notation
>>> and to provide for most (all?) assignment operators implementations
>>> that use destructive semantics if the infix version was used and
>>> always copy if the prefix notation is used. 
>>>   
>>>       
>> as i explained a few months ago, i study r to find examples of bad
>> design.  if anyone in the r core is interested in having the problems
>> i report fixed, 
>>     
>
> Well, whether something is bad design and/or is a problem is in the eye
> of the beholder.
>   

i have never claimed that what i call bad design is what r developers
call bad design.  more and more, it appears that we disagree.  i just
collect and point out what i think is bad design.  others obviously have
their take.

cheers,
vQ


From Mark.Bravington at csiro.au  Thu Mar 12 21:45:18 2009
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 12 Mar 2009 21:45:18 +0100 (CET)
Subject: [Rd] installed.packages and package info cache buglet (PR#13592)
Message-ID: <20090312204518.C7516282EF2D@mail.pubhealth.ku.dk>

Looks like there is a buglet in 'installed.packages', around line 17:

    for (lib in lib.loc) {
        dest <- file.path(tempdir(), paste("libloc_", URLencode(lib,=20
            TRUE), paste(fields, collapse =3D ","), ".rds", sep =3D ""))
        if (!noCache && file.exists(dest) && file.info(dest)$mtime >=20
            file.info(lib.loc)$mtime) {

                      ^^^^^^^
                     =20
The 'lib.loc' should be 'lib', otherwise the comparison is always against t=
he first library in 'lib.loc', not against the one being checked. [Normally=
 the multiple test in '>' would flag a warning from 'if', but the &&s mean =
that only the first element is used.]

I can't provide a reproducible example for this, because it's so installati=
on-dependent.

Still present in R-devel from 8th March.

Mark Bravington
CSIRO
Hobart
Australia

--please do not edit the information below--

Version:
 platform =3D i386-pc-mingw32
 arch =3D i386
 os =3D mingw32
 system =3D i386, mingw32
 status =3D Patched
 major =3D 2
 minor =3D 8.1
 year =3D 2009
 month =3D 02
 day =3D 12
 svn rev =3D 47919
 language =3D R
 version.string =3D R version 2.8.1 Patched (2009-02-12 r47919)

Windows XP (build 2600) Service Pack 2

Locale:
LC_COLLATE=3DEnglish_Australia.1252;LC_CTYPE=3DEnglish_Australia.1252;LC_MO=
NETARY=3DEnglish_Australia.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_Australia.=
1252

Search Path:
 .GlobalEnv, package:grDevices, package:ad, package:chstuff, package:handy2=
, package:tweedie, package:statmod, package:handy, package:debug, package:m=
vbutils, mvb.session.info, package:tools, package:tcltk, package:boot, pack=
age:stats, package:graphics, package:utils, package:methods, Autoloads, pac=
kage:base


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 21:54:34 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 21:54:34 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <1C7E6CAE-222C-4A7D-B9E6-CC27692D65BB@r-project.org>
References: <49B67CB1.8060005@idi.ntnu.no>
	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B92643.6060401@idi.ntnu.no>
	<1C7E6CAE-222C-4A7D-B9E6-CC27692D65BB@r-project.org>
Message-ID: <49B9768A.9070103@idi.ntnu.no>

Simon Urbanek wrote:
>
> On Mar 12, 2009, at 11:12 , Wacek Kusnierczyk wrote:
>
>> Simon Urbanek wrote:
>>>
>>> On Mar 11, 2009, at 10:52 , Simon Urbanek wrote:
>>>
>>>> Wacek,
>>>>
>>>> Peter gave you a full answer explaining it very well. If you really
>>>> want to be able to trace each instance yourself, you have to learn
>>>> far more about R internals than you apparently know (and Peter hinted
>>>> at that). Internally x=1 an x=c(1) are slightly different in that the
>>>> former has NAMED(x) = 2 whereas the latter has NAMED(x) = 0 which is
>>>> what causes the difference in behavior as Peter explained. The reason
>>>> is that c(1) creates a copy of the 1 (which is a constant
>>>> [=unmutable] thus requiring a copy) and the new copy has no other
>>>> references and thus can be modified and hence NAMED(x) = 0.
>>>>
>>>
>>> Errata: to be precise replace NAMED(x) = 0 with NAMED(x) = 1 above --
>>> since NAMED(c(1)) = 0 and once it's assigned to x it becomes NAMED(x)
>>> = 1 -- this is just a detail on how things work with assignment, the
>>> explanation above is still correct since duplication happens
>>> conditional on NAMED == 2.
>>
>> there is an interesting corollary.  self-assignment seems to increase
>> the reference count:
>>
>>    x = 1;  'names<-'(x, 'foo'); names(x)
>>    # NULL
>>
>>    x = 1;  x = x;  'names<-'(x, 'foo'); names(x)
>>    # "foo"
>>
>
> Not for me, at least in current R:

not for me either.  i messed up the example, sorry.  here's the intended
version:

    x = c(1);  'names<-'(x, 'foo');  names(x)
    # "foo"

    x = c(1);  x = x; 'names<-'(x, 'foo');  names(x)
    # NULL
  

>
> > x = 1;  'names<-'(x, 'foo'); names(x)
> foo
>   1
> NULL
> > x = 1;  x = x;  'names<-'(x, 'foo'); names(x)
> foo
>   1
> NULL
>
> (both R 2.8.1 and R-devel 3/11/09, darwin 9.6)
>
> In addition, you still got it backwards - your output suggests that
> the assignment created a new, clean copy. Functional call of `names<-`
> (whose side-effect on x is undefined BTW) is destructive when you get
> a clean copy (e.g. as a result of the c function) and non-destructive
> when the object was referenced. It is left as an exercise to the
> reader to reason why constants such as 1 are referenced.

all true, again because of my mistake. 

anyway, it may be suprising that with all its smartness (i mean it)
about copy-on-assingment, r does not see that it makes no sense to
increase refcount here.  of course, you can't judge from just the
syntactic form 'x=x', but still it should not be very difficult to have
the interpreter see when it finds an object named 'x' in the same
environment where it attempts the assignment.  (of course, who'd do
self-assignments in practical code?)

cheers,
vQ


From josh.m.ulrich at gmail.com  Thu Mar 12 21:57:22 2009
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Thu, 12 Mar 2009 15:57:22 -0500
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <a695148b0903121324q16003f8cj549c1027b9019e43@mail.gmail.com>
References: <49B67CB1.8060005@idi.ntnu.no> <49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1> <49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1> <49B8DB8F.5030704@idi.ntnu.no>
	<20090312213508.719afa73@berwin5> <49B91A7E.50107@idi.ntnu.no>
	<20090312231240.6a061f0b@berwin5>
	<a695148b0903121324q16003f8cj549c1027b9019e43@mail.gmail.com>
Message-ID: <8cca69990903121357g3027d40cgcd67f0d5dd54973b@mail.gmail.com>

On Thu, Mar 12, 2009 at 3:24 PM, G. Jay Kerns <gkerns at ysu.edu> wrote:
> Wacek Kusnierczyk wrote:
>
> [snip]
>
>> as i explained a few months ago, i study r to find examples of bad
>> design. ?if anyone in the r core is interested in having the problems i
>> report fixed, i'm happy to get involved in a discussion about the design
>> and implementation. ?if not, i'm happy with just pointing out the issues.
>
> :-)
>
> I am prompted to imagine someone pointing out to the volunteers of the
> International Red Cross - on the field of a natural disaster, no less
> - that their uniforms are not an acceptably consistent shade of
> pink... or that the screws on their tourniquets do not have the
> appropriate pitch as to minimize the friction for the turner...

Your analogy may overstate the case a bit, since R volunteers - while
providing a valuable service to the community - are not dealing with
matters of life and death.

Habitat for Humanity (an organization that provides free housing to
the under-privileged) would be a better comparison.  I'm sure those
volunteers would appreciate a critique of their work, provided the
critique was not condescending and focused on serving the community
better, not to showcase the acumen of the one giving the critique.

>
> As a practicing statistician I am simply thankful that the bleeding is
> stopped. ? :-)
>
> Cheers to R-Core (and the hundreds of other volunteers).
> Jay
>

I second that.  Thanks to R-Core et al for all their generous efforts.

>
>
> ***************************************************
> G. Jay Kerns, Ph.D.
> Associate Professor
> Department of Mathematics & Statistics
> Youngstown State University
> Youngstown, OH 44555-0002 USA
> Office: 1035 Cushwa Hall
> Phone: (330) 941-3310 Office (voice mail)
> -3302 Department
> -3170 FAX
> E-mail: gkerns at ysu.edu
> http://www.cc.ysu.edu/~gjkerns/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Best,
Josh
--
http://quantemplation.blogspot.com


From murdoch at stats.uwo.ca  Thu Mar 12 22:01:41 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 12 Mar 2009 17:01:41 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49B95F7E.5020406@scs.carleton.ca>
References: <49B95F7E.5020406@scs.carleton.ca>
Message-ID: <49B97835.2090004@stats.uwo.ca>

Mohammad Nikseresht wrote:
> Hi,
>
> I receive the following error while I try to install rgl package:
>
> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H -I/usr/include/libpng12 
> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
> -I/usr/sfw/include -I/opt/csw/include    -KPIC  -O -c Background.cpp -o 
> Background.o
> "math.h", line 47: Error: modf is not a member of file level.
> "math.h", line 48: Error: modff is not a member of file level.
> "Shape.hpp", line 58: Error: The function "strncpy" must have a prototype.
> 3 Error(s) detected.
>
> I am using Sun studio 12.
> I suspect that this is an incompatibility between g++ and Sun studio CC.
> I would appreciate any you could share your experience with me.
>   

I have no experience with Sun compilers; I have only compiled rgl in 
gcc.  I'd be happy to accept patches that make it more portable, but I 
can't test them.

Duncan Murdoch


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 12 22:06:19 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Mar 2009 22:06:19 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <a695148b0903121324q16003f8cj549c1027b9019e43@mail.gmail.com>
References: <49B67CB1.8060005@idi.ntnu.no>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>
	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>
	<20090312231240.6a061f0b@berwin5>
	<a695148b0903121324q16003f8cj549c1027b9019e43@mail.gmail.com>
Message-ID: <49B9794B.7040606@idi.ntnu.no>

G. Jay Kerns wrote:
> Wacek Kusnierczyk wrote:
>
>
>   
> I am prompted to imagine someone pointing out to the volunteers of the
> International Red Cross - on the field of a natural disaster, no less
> - that their uniforms are not an acceptably consistent shade of
> pink... or that the screws on their tourniquets do not have the
> appropriate pitch as to minimize the friction for the turner...
>
>   

not that it is very accurate, because unintuitive and confusing
semantics may lead to hidden and dangerous errors in users' code.  wrong
shade of a uniform might lead to the person being shot, for example, but
then your point vanishes.


> As a practicing statistician I am simply thankful that the bleeding is
> stopped.   :-)
>   

when it is stopped, not turned to an internal bleeding, which you simply
don't see.

> Cheers to R-Core (and the hundreds of other volunteers).
>
>   

absolutely.

vQ


From gkerns at ysu.edu  Fri Mar 13 00:56:38 2009
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Thu, 12 Mar 2009 19:56:38 -0400
Subject: [Rd] analogy was: surprising behaviour of names<-
Message-ID: <a695148b0903121656y59f4877fxdd3e730f09ed5d7f@mail.gmail.com>

Dear Josh,

> Your analogy may overstate the case a bit,

Agreed.  :-)

> since R volunteers - while
> providing a valuable service to the community - are not dealing with
> matters of life and death.

I see your point, and it is well taken.  At the same time, in my view,
statistics are like firearms in every respect save one: they typically
don't rust when you leave them outside in the rain.

Regards,
Jay




***************************************************
G. Jay Kerns, Ph.D.
Associate Professor
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/


From berwin at maths.uwa.edu.au  Fri Mar 13 05:03:09 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 13 Mar 2009 12:03:09 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49B96FE7.2060705@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
	<49B96FE7.2060705@idi.ntnu.no>
Message-ID: <20090313120309.7acb13e5@berwin-nus1>

On Thu, 12 Mar 2009 21:26:15 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> > YMMV, but when I read a passage like this in R documentation, I
> > start to wonder why it is stated that 
> > 	names(x) <- c("a","b")
> > is equivalent to 
> > 	*tmp* <- x
> > 	x <- "names<-"('*tmp*', value=c("a","b"))
> > and the simpler construct
> > 	x <- "names<-"(x, value=c("a", "b"))
> > is not used.  There must be a reason, 
> 
> got an explanation:  because it probably is as drafty as the
> aforementioned document.

Your grasp of what "draft manual" means in the context of R
documentation seems to be as tenuous as the grasp of intelligent
design/creationist proponents on what it means in science to label a
body of knowledge a "(scientific) theory". :)

[...]
> but it is possible to send an argument to a function that makes an
> assignment to the argument, and yet the assignment is made to the
> original, not to a copy:
> 
>     foo = function(arg) arg$foo = foo
> 
>     e = new.env()
>     foo(e)
>     e$foo
>       
> are you sure this is pass by value?

But that is what environments are for, aren't they?  And it is
documented behaviour.  Read section 2.1.10 ("Environments") in the R
Language Definition, in particular the last paragraph:

  Unlike most other R objects, environments are not copied when 
  passed to functions or used in assignments.  Thus, if you assign the
  same environment to several symbols and change one, the others will
  change too.  In particular, assigning attributes to an environment can
  lead to surprises.

[..]
> and actually, in the example we discuss, 'names<-' does *not* return
> an updated *tmp*, so there's even less to entertain.  

How do you know?  Are you sure?  Have you by now studied what goes on
under the hood?

> for fun and more guesswork, the example could have been:
> 
>     x = x
>     x = 'names<-'(x, value=c('a', 'b'))

But it is manifestly not written that way in the manual; and for good
reasons since 'names<-' might have side effects which invokes in the
last line undefined behaviour.  Just as in the equivalent C snippet
that I mentioned.

> for your interest in well written documentation, ?names says that the
> argument x is 'an r object', and nowhere does it say that environment
> is not an r object.  it also says what the value of 'names<-' applied
> to pairlists is.  the following error message is doubly surprising:
> 
>     e = new.env()
>     'names<-'(e, 'foo')
>     # Error: names() applied to a non-vector

But names are implemented by assigning a "name" attribute to the
object; as you should know.  And the above documentation suggests that
it is not a good idea to assign attributed to environments.  So why
would you expect this to work?

> firstly, because it would seem that there's nothing wrong in applying
> names to an environment;  from ?'$':
> 
> "
>     x$name
> 
>     name: A literal character string or a name (possibly backtick
>           quoted).  For extraction, this is normally (see under
>           'Environments') partially matched to the 'names' of the
>           object.
> "

I fail to see the relevance of this.

> secondly, because, as ?names says, names can be applied to pairlists,

Yes, but it does not say that names can be applied to environment.
And it explicitly says that the "default methods get and set the
'"name"' attribute of..." and (other) documentation warns you about
setting attributes on environments.

> which are not vectors, and the following does not give an error as
> above:
> 
>     p = pairlist()
>     is.vector(p)
>     # FALSE
>     names(p)
>     # names successfully applied to a non-vector
>    
> assure me this is not a mess, but a well-documented design feature.

It is documented, if it is well-documented depends on your definition
of "well-documented". :)

> ... and one wonders why r man pages have to be read in O(e^n) time.

I believe patches to documentation are also welcome; and perhaps more
readily accepted than patches to code. 

[...]  
> >>> I guess that would require a rewrite (or extension) of the parser.
> >>> To me, Section 10.1.2 of the Language Definition manual suggests
> >>> that once an expression is parsed, you cannot distinguish any more
> >>> whether 'names<-' was called using infix syntax or prefix syntax.
> >>>   
> >>>       
> >> but this must be nonsense, since:
> >>
> >>     x = 1
> >>     'names<-'(x, 'foo')
> >>     names(x)
> >>     # NULL
> >>
> >>     x = 1
> >>     names(x) <- 'foo'
> >>     names(x)
> >>     # "foo"
> >>
> >> clearly, there is not only syntactic difference here.  but it
> >> might be that 10.1.2 does not suggest anything like what you say.
> >>     
> >
> > Please tell me how this example contradicts my reading of 10.1.2
> > that the expressions 
> > 	'names<-'(x, 'foo')
> > and
> > 	names(x) <- 'foo'
> > once they are parsed, produce exactly the same parse tree and that
> > it becomes impossible to tell from the parse tree whether
> > originally the infix syntax or the prefix syntax was used.  
> 
> because if they produced the same parse tree, you would either have to
> have the same result in both cases (because the same parse tree is
> interpreted), [...]

Sorry, looks as if I was too fast (again). 

'names<-'(x,'foo') should create (more or less) a parse tree equivalent
to that expression and then return the value of the call to
'names<-' (as it does).  I said "more or less" because some temporary
variables might be created whose named field is set to 1 so that "some
primitive functions can be optimized to avoid a copy" ("R Internals",
pages 3/4).

names(x) <- 'foo' should create (more or less) a parse tree equivalent
to " '<-'(x, 'names'<-(x,'foo')) ".  I say "more or less" for similar
reasons as above.

My point is that when the evaluator works through the parse tree and
comes to the 'names'<-(c, 'foo') part, it cannot tell (without
analysing what was before in the parse tree and what comes after; and
this analysis might be difficult if temporary variables are created)
whether the user used the prefix syntax or the infix syntax.

I have no idea whether this can easily be changed and whether it is
worthwhile to do such a change.  As I said, you will have to take this
up with R Core.

Cheers,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 13 11:43:55 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 13 Mar 2009 11:43:55 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090313120309.7acb13e5@berwin-nus1>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>
	<20090313120309.7acb13e5@berwin-nus1>
Message-ID: <49BA38EB.3000004@idi.ntnu.no>

Berwin A Turlach wrote:
>
>>     foo = function(arg) arg$foo = foo
>>
>>     e = new.env()
>>     foo(e)
>>     e$foo
>>       
>> are you sure this is pass by value?
>>     
>
> But that is what environments are for, aren't they?  

might be.

> And it is
> documented behaviour.  

sure!

> Read section 2.1.10 ("Environments") in the R
> Language Definition, 

haven't objected to that.  i object to your 'r uses pass by value',
which is only partially correct.

> in particular the last paragraph:
>
>   Unlike most other R objects, environments are not copied when 
>   passed to functions or used in assignments.  Thus, if you assign the
>   same environment to several symbols and change one, the others will
>   change too.  In particular, assigning attributes to an environment can
>   lead to surprises.
>
> [..]
>   
>> and actually, in the example we discuss, 'names<-' does *not* return
>> an updated *tmp*, so there's even less to entertain.  
>>     
>
> How do you know?  Are you sure?  Have you by now studied what goes on
> under the hood?
>   

yes, a bit.  but in this example, it's enough to look into *tmp* to see
that it hasn't got the names added, and since x does have names, names<-
must have returned a copy of *tmp* rather than *tmp* changed:
   
    x = 1
    tmp = x
    x = 'names<-'(tmp, 'foo')
    names(tmp)
    # NULL

you suggested that "One reads the manual, (...) one reflects and
investigates, ..." -- had you done it, you wouldn't have asked the question.



>   
>> for fun and more guesswork, the example could have been:
>>
>>     x = x
>>     x = 'names<-'(x, value=c('a', 'b'))
>>     
>
> But it is manifestly not written that way in the manual; and for good
> reasons since 'names<-' might have side effects which invokes in the
> last line undefined behaviour.  Just as in the equivalent C snippet
> that I mentioned.
>   

i just can't get it why the manual does not manifestly explain what
'names<-' does, and leaves you doing the guesswork you suggest.

vQ


From osklyar at maninvestments.com  Fri Mar 13 15:04:19 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Fri, 13 Mar 2009 14:04:19 -0000
Subject: [Rd] Rd \usage clause for an S4 replace method
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF73D@mildnpexmb01.maninvestments.ad.man.com>

Given S4 methods [ and [<-, how do I write the Rd-file usage clause for
the latter one?
What I have now is:

\S4method{[}{TimeSeries,TimeDate,missing}(x, i, j, ..., drop)
\S4method{[<-}{TimeSeries,TimeDate,missing,ANY}(x, i, j, ..., value)

which results in the following output:

    ## S4 method for signature 'TimeSeries, TimeDate, missing':
    x[i, j, ..., drop]
    \S4method{[<-}{TimeSeries,TimeDate,missing,ANY}(x, i, j, ..., value)

How should I document the latter? Thanks.


Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From berwin at maths.uwa.edu.au  Fri Mar 13 16:47:55 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 13 Mar 2009 23:47:55 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BA38EB.3000004@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
	<49B96FE7.2060705@idi.ntnu.no>
	<20090313120309.7acb13e5@berwin-nus1>
	<49BA38EB.3000004@idi.ntnu.no>
Message-ID: <20090313234755.6f6e08c9@berwin5>

On Fri, 13 Mar 2009 11:43:55 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:
>
> > And it is documented behaviour.  
> 
> sure!

Glad to see that we agree on this.

> > Read section 2.1.10 ("Environments") in the R
> > Language Definition, 
> 
> haven't objected to that.  i object to your 'r uses pass by value',
> which is only partially correct.

Well, I used qualifiers and did not stated it categorically. 
 
> >> and actually, in the example we discuss, 'names<-' does *not*
> >> return an updated *tmp*, so there's even less to entertain.  
> >>     
> >
> > How do you know?  Are you sure?  Have you by now studied what goes
> > on under the hood?
> 
> yes, a bit.  but in this example, it's enough to look into *tmp* to
> see that it hasn't got the names added, and since x does have names,
> names<- must have returned a copy of *tmp* rather than *tmp* changed:
>    
>     x = 1
>     tmp = x
>     x = 'names<-'(tmp, 'foo')
>     names(tmp)
>     # NULL

Indeed, if you type these two commands on the command line, then it is
not surprising that a copy of tmp is returned since you create a
temporary object that ends up in the symbol table and persist after the
commands are finished.

Obviously, assuming that R really executes 
	*tmp* <- x
	x <- "names<-"('*tmp*', value=c("a","b"))
under the hood, in the C code, then *tmp* does not end up in the symbol
table and does not persist beyond the execution of 
	names(x) <- c("a","b")

This looks to me as one of the situations where a value of 1 is used
for the named field of some of the objects involves so that a copy can
be avoided.  That's why I asked whether you looked under the hood.

> you suggested that "One reads the manual, (...) one reflects and
> investigates, ..."

Indeed, and I am not giving up hope that one day you will master this
art.

> -- had you done it, you wouldn't have asked the  question.

Sorry, I forgot that you have a tendency to interpret statements
extremely verbatim and with little reference to the context in which
they are made.  I will try to be more explicit in future.

> >> for fun and more guesswork, the example could have been:
> >>
> >>     x = x
> >>     x = 'names<-'(x, value=c('a', 'b'))
> >>     
> >
> > But it is manifestly not written that way in the manual; and for
> > good reasons since 'names<-' might have side effects which invokes
> > in the last line undefined behaviour.  Just as in the equivalent C
> > snippet that I mentioned.
> 
> i just can't get it why the manual does not manifestly explain what
> 'names<-' does, and leaves you doing the guesswork you suggest.

As I said before, patched to documentation are also welcome.

Best wishes,
	
	Berwin


From ripley at stats.ox.ac.uk  Fri Mar 13 17:13:38 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Mar 2009 16:13:38 +0000 (GMT)
Subject: [Rd] Rd \usage clause for an S4 replace method
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF73D@mildnpexmb01.maninvestments.ad.man.com>
References: <1A68FCB28DE72F4BA3B967E6506CCE43047DF73D@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <alpine.LFD.2.00.0903131608460.23780@gannet.stats.ox.ac.uk>

That's not how you use it, surely?

The obvious to me

\usage{
\S4method{[}{TimeSeries,TimeDate,missing}(x, i, j, ..., drop)
\S4method{[}{TimeSeries,TimeDate,missing,ANY}(x, i, j, ...) <- value
}

works.  There is an example of a replacement method using \method in 
'Writing R Extensions', so expecting \S4method to work in the same way 
seems reasonable to me (and I didn't write or document any of this).

On Fri, 13 Mar 2009, Sklyar, Oleg (London) wrote:

> Given S4 methods [ and [<-, how do I write the Rd-file usage clause for
> the latter one?
> What I have now is:
>
> \S4method{[}{TimeSeries,TimeDate,missing}(x, i, j, ..., drop)
> \S4method{[<-}{TimeSeries,TimeDate,missing,ANY}(x, i, j, ..., value)
>
> which results in the following output:
>
>    ## S4 method for signature 'TimeSeries, TimeDate, missing':
>    x[i, j, ..., drop]
>    \S4method{[<-}{TimeSeries,TimeDate,missing,ANY}(x, i, j, ..., value)
>
> How should I document the latter? Thanks.
>
>
> Dr Oleg Sklyar
> Research Technologist
> AHL / Man Investments Ltd
> +44 (0)20 7144 3107
> osklyar at maninvestments.com
>
> **********************************************************************
> Please consider the environment before printing this email or its attachments.
> The contents of this email are for the named addressees ...{{dropped:19}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 13 19:41:42 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 13 Mar 2009 19:41:42 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090313234755.6f6e08c9@berwin5>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>
	<20090313234755.6f6e08c9@berwin5>
Message-ID: <49BAA8E6.3080407@idi.ntnu.no>

Berwin A Turlach wrote:
>
>> sure!
>>     
>
> Glad to see that we agree on this.
>   

owe you a beer.

>   
>>> Read section 2.1.10 ("Environments") in the R
>>> Language Definition, 
>>>       
>> haven't objected to that.  i object to your 'r uses pass by value',
>> which is only partially correct.
>>     
>
> Well, I used qualifiers and did not stated it categorically. 
>   

indeed, you said "R supposedly uses call-by-value (though we know how to
circumvent that, don't we?)".

in that vain, R supposedly can be used to do valid statistical
computations (though we know how to circumvent it) ;)


>  
>   
>>>> and actually, in the example we discuss, 'names<-' does *not*
>>>> return an updated *tmp*, so there's even less to entertain.  
>>>>     
>>>>         
>>> How do you know?  Are you sure?  Have you by now studied what goes
>>> on under the hood?
>>>       
>> yes, a bit.  but in this example, it's enough to look into *tmp* to
>> see that it hasn't got the names added, and since x does have names,
>> names<- must have returned a copy of *tmp* rather than *tmp* changed:
>>    
>>     x = 1
>>     tmp = x
>>     x = 'names<-'(tmp, 'foo')
>>     names(tmp)
>>     # NULL
>>     
>
> Indeed, if you type these two commands on the command line, then it is
> not surprising that a copy of tmp is returned since you create a
> temporary object that ends up in the symbol table and persist after the
> commands are finished.
>   

what does command line have to do with it?

> Obviously, assuming that R really executes 
> 	*tmp* <- x
> 	x <- "names<-"('*tmp*', value=c("a","b"))
> under the hood, in the C code, then *tmp* does not end up in the symbol
> table 

no?

> and does not persist beyond the execution of 
> 	names(x) <- c("a","b")
>   

no?

i guess you have looked under the hood;  point me to the relevant code.

> This looks to me as one of the situations where a value of 1 is used
> for the named field of some of the objects involves so that a copy can
> be avoided.  That's why I asked whether you looked under the hood.
>   

anyway, what happens under the hood is much less interesting from the
user's perspective that what can be seen over the hood.  what i can see,
is that 'names<-' will incoherently perform in-place modification or
copy-on-assignment. 

yes, *if* you are able to predict the refcount of the object passed to
'names<-' *then* you can predict what 'names<-' will do, but in general
you may not have the chance.  and in general, this should not matter
because it should be unobservable, but it isn't.

back to your i += i++ example, the outcome may differ from a compiler to
a compiler, but, i guess, compilers will implement the order coherently,
so that whatever version they choose, the outcome will be predictable,
and not dependent on some earlier code.  (prove me wrong.  or maybe i'll
do it myself.)

>   
>> you suggested that "One reads the manual, (...) one reflects and
>> investigates, ..."
>>     
>
> Indeed, and I am not giving up hope that one day you will master this
> art.
>   

well, this time i meant you.


>   
>> -- had you done it, you wouldn't have asked the  question.
>>     
>
> Sorry, I forgot that you have a tendency to interpret statements
> extremely verbatim 

yes, i have two hooks installed:  one says \begin{verbatim}, the other
says \end{verbatim}.


> and with little reference to the context in which
> they are made.  

not that you're trying to be extremely accurate or polite here...

> I will try to be more explicit in future.
>   

it will certainly do good to you.


>>
>> i just can't get it why the manual does not manifestly explain what
>> 'names<-' does, and leaves you doing the guesswork you suggest.
>>     
>
> As I said before, patched to documentation are also welcome.
>   

i'll give it a try.


> Best wishes,
>   

hope you mean it.

likewise,
vQ


From dkor at northwestern.edu  Fri Mar 13 20:11:38 2009
From: dkor at northwestern.edu (Daniel Kornhauser)
Date: Fri, 13 Mar 2009 14:11:38 -0500
Subject: [Rd] Does anybody have some starter code in Java to instance a
	standalone JGRConsole ?
Message-ID: <332394640903131211x5fcf9284t9f28e0b2f39d0cca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090313/026cec56/attachment.pl>

From wdunlap at tibco.com  Fri Mar 13 20:19:15 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Mar 2009 12:19:15 -0700
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BAA8E6.3080407@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no><20090313234755.6f6e08c9@berwin5>
	<49BAA8E6.3080407@idi.ntnu.no>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700DF10EE@NA-PA-VBE03.na.tibco.com>

Would it make anyone any happier if the manual said
that the replacement functions should not be called
in the form
   xNew <- `func<-` (xOld, value)
and should only be used as
   func(xToBeChanged) <- value
? 

The explanation
      names(x) <- c("a","b")
  is equivalent to
      '*tmp*' <- x
      x <- "names<-"('*tmp*', value=c("a","b"))
could also be extended a bit, adding a line like
      rm(`*tmp*`)
Those 3 lines should be considered an atomic operation:
the value that `*tmp*` or `x` may have or what is
in the symbol table at various points in that sequence 
is not defined.  (Letting details be explicitly undefined
is important: it gives developers room to improve the
efficiency of the interpreter and tells users where not to go.) 


Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Wacek Kusnierczyk
> Sent: Friday, March 13, 2009 11:42 AM
> To: Berwin A Turlach
> Cc: r-devel at r-project.org List
> Subject: Re: [Rd] surprising behaviour of names<-
> ... blah blah blah
> >>     x = 1
> >>     tmp = x
> >>     x = 'names<-'(tmp, 'foo')
> >>     names(tmp)
> >>     # NULL


From tplate at acm.org  Fri Mar 13 20:28:05 2009
From: tplate at acm.org (Tony Plate)
Date: Fri, 13 Mar 2009 13:28:05 -0600
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BA38EB.3000004@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>
	<49BA38EB.3000004@idi.ntnu.no>
Message-ID: <49BAB3C5.9010401@acm.org>

Wacek Kusnierczyk wrote:
> [snip]
> i just can't get it why the manual does not manifestly explain what
> 'names<-' does, and leaves you doing the guesswork you suggest.
>
>   
I'm having trouble understanding the point of this discussion.  Someone 
is calling a replacement function in a way that it's not meant to be 
used, and is them complaining about it not doing what he thinks it 
should, or about the documentation not describing what happens when one 
does that?

Is there anything incorrect or missing in the help page for normal usage 
of the replacement function for 'names'? (i.e., when used in an 
expression like 'names(x) <- ...')

R does give one the ability to use its facilities in non-standard ways.  
However, I don't see much value in the help page for 'gun' attempting to 
describe the ways in which the bones in your foot will be shattered 
should you choose to point the gun at your foot and pull the trigger.  
Reminds me of the story of the guy in New York, who after injuring his 
back in refrigerator-carrying race, sued the manufacturer of the 
refrigerator for not having a warning label against that sort of use.

-- Tony Plate


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 13 21:39:37 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 13 Mar 2009 21:39:37 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700DF10EE@NA-PA-VBE03.na.tibco.com>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no><20090313234755.6f6e08c9@berwin5>	<49BAA8E6.3080407@idi.ntnu.no>
	<77EB52C6DD32BA4D87471DCD70C8D700DF10EE@NA-PA-VBE03.na.tibco.com>
Message-ID: <49BAC489.7070006@idi.ntnu.no>

William Dunlap wrote:
> Would it make anyone any happier if the manual said
> that the replacement functions should not be called
> in the form
>    xNew <- `func<-` (xOld, value)
> and should only be used as
>    func(xToBeChanged) <- value
>   

surely better than guesswork.

> ? 
>
> The explanation
>       names(x) <- c("a","b")
>   is equivalent to
>       '*tmp*' <- x
>       x <- "names<-"('*tmp*', value=c("a","b"))
> could also be extended a bit, adding a line like
>       rm(`*tmp*`)
> Those 3 lines should be considered an atomic operation:
> the value that `*tmp*` or `x` may have or what is
> in the symbol table at various points in that sequence 
> is not defined.  (Letting details be explicitly undefined
> is important: it gives developers room to improve the
> efficiency of the interpreter and tells users where not to go.) 
>   

there is a difference between letting things be undefined and explicitly
stating that things are unspecified.  the c99 standard [1], for example,
is explicit about the non-determinism of expressions that involve side
effects, as it is about that some expressions may actually not be
evaluated if the optimizer decides so. 

berwin has already suggested that one reads from what docs do *not*
say;  it's a very bad idea.  it's best that the documentation *does* say
that, for example, a particular function should be used only in the
infix form because the semantics of the prefix form are not guaranteed
and may change in future versions.

if the current state is that 'names<-' will modify the object it is
given as an argument in some situations, but not in others, and this is
visible to the user, the best thing to do is to give an explicit warning
-- perhaps with an annotation that things may change, if they may.

best,
vQ


[1] http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 13 21:51:47 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 13 Mar 2009 21:51:47 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BAB3C5.9010401@acm.org>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>
	<49BAB3C5.9010401@acm.org>
Message-ID: <49BAC763.5040104@idi.ntnu.no>

Tony Plate wrote:
> Wacek Kusnierczyk wrote:
>> [snip]
>> i just can't get it why the manual does not manifestly explain what
>> 'names<-' does, and leaves you doing the guesswork you suggest.
>>
>>   
> I'm having trouble understanding the point of this discussion. 
> Someone is calling a replacement function in a way that it's not meant
> to be used, and is them complaining about it not doing what he thinks
> it should, or about the documentation not describing what happens when
> one does that?

where is it written that the function is not meant to be used this way? 
you get an example in the man page, showing precisely how it could be
used that way.  it also explains the value of 'names<-':

"
 For 'names<-', the updated object.  (Note that the value of
     'names(x) <- value' is that of the assignment, 'value', not the
     return value from the left-hand side.)
"

it does speak of 'names<-' used in prefix form, and does not do it in
any negative (discouraging) way.

>
> Is there anything incorrect or missing in the help page for normal
> usage of the replacement function for 'names'? (i.e., when used in an
> expression like 'names(x) <- ...')

what is missing here in the first place is a specification of what
'normal' means.  as far as i can see from the man page, 'normal' does
not exclude prefix use.  and if so, what is missing in the help page is
a clear statement what an application of 'names<-' will do, in the sense
of what a user may observe.

>
> R does give one the ability to use its facilities in non-standard
> ways.  However, I don't see much value in the help page for 'gun'
> attempting to describe the ways in which the bones in your foot will
> be shattered should you choose to point the gun at your foot and pull
> the trigger.  Reminds me of the story of the guy in New York, who
> after injuring his back in refrigerator-carrying race, sued the
> manufacturer of the refrigerator for not having a warning label
> against that sort of use.

very funny.  little relevant.

vQ


From maechler at stat.math.ethz.ch  Fri Mar 13 22:25:26 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri, 13 Mar 2009 22:25:26 +0100 (CET)
Subject: [Rd] installed.packages and package info cache buglet (PR#13592)
Message-ID: <20090313212526.72D892834323@mail.pubhealth.ku.dk>

>>>>> Mark Bravington <Mark.Bravington at csiro.au>
>>>>>     on Thu, 12 Mar 2009 21:45:18 +0100 (CET) writes:

>> Looks like there is a buglet in 'installed.packages', around line 17:
>> 
>>     for (lib in lib.loc) {
>>         dest <- file.path(tempdir(), paste("libloc_", URLencode(lib,=20
>>             TRUE), paste(fields, collapse =3D ","), ".rds", sep =3D ""))
>>         if (!noCache && file.exists(dest) && file.info(dest)$mtime >=20
>>             file.info(lib.loc)$mtime) {
>> 
>>                       ^^^^^^^
>>                      =20
>> The 'lib.loc' should be 'lib', otherwise the comparison is always against t=
>> he first library in 'lib.loc', not against the one being checked. [Normally=
>>  the multiple test in '>' would flag a warning from 'if', but the &&s mean =
>> that only the first element is used.]
>> 
>> I can't provide a reproducible example for this, because it's so installati=
>> on-dependent.
>> 
>> Still present in R-devel from 8th March.

and today.  Thank you, Mark,  I've corrected it (in R-devel
only).

Martin Maechler, ETH Zurich


>> Mark Bravington
>> CSIRO
>> Hobart
>> Australia


From vogranovich at jumptrading.com  Fri Mar 13 23:24:43 2009
From: vogranovich at jumptrading.com (Vadim Ogranovich)
Date: Fri, 13 Mar 2009 17:24:43 -0500
Subject: [Rd] lsfit w/ rank-deficient x
Message-ID: <22D850BC39A25742977325ADDE208E770271F71FC6@chiexchange02.w2k.jumptrading.com>

Dear R-devel,

It seems that lsfit incorrectly reports coefficients when the input matrix 'x' is rank-deficient, see the example below:

## here values of 'b' and 'c' are incorrectly swapped
> x <- cbind(a=rnorm(100), b=0, c=rnorm(100)); y <- rnorm(100); lsfit(x, y)$coef
 Intercept          a          b          c
-0.0227787  0.1042860 -0.1729261  0.0000000
Warning message:
In lsfit(x, y) : 'X' matrix was collinear

## correct values
> lsfit(x[,-2], y)$coef
 Intercept          a          c
-0.0227787  0.1042860 -0.1729261


I looked inside the lsfit code and it appears that even though rank-deficiency is detected there is no attempt to patch the coefficients. Why is that?

Taking clues from the code it appears that the following trick might do the work:

> foo <- lsfit(x, y)
Warning message:
In lsfit(x, y) : 'X' matrix was collinear
> structure(foo$coefficients[foo$qr$pivot], names=names(foo$coefficients))
  Intercept           a           b           c
 0.14857345 -0.07473099  0.00000000  0.12835155


Is this reliable or there are cases when it may fail?

Thanks,
Vadim

P.S.

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          7.1
year           2008
month          06
day            23
svn rev        45970
language       R
version.string R version 2.7.1 (2008-06-23)
>

Note: This email is for the confidential use of the named addressee(s) only and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you are hereby notified that any review, dissemination or copying of this email is strictly prohibited, and to please notify the sender immediately and destroy this email and any attachments.  Email transmission cannot be guaranteed to be secure or error-free.  Jump Trading, therefore, does not make any guarantees as to the completeness or accuracy of this email or any attachments.  This email is for informational purposes only and does not constitute a recommendation, offer, request or solicitation of any kind to buy, sell, subscribe, redeem or perform any type of transaction of a financial product.


From tplate at acm.org  Sat Mar 14 00:24:35 2009
From: tplate at acm.org (Tony Plate)
Date: Fri, 13 Mar 2009 17:24:35 -0600
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BAC763.5040104@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>	<49BAB3C5.9010401@acm.org>
	<49BAC763.5040104@idi.ntnu.no>
Message-ID: <49BAEB33.8040708@acm.org>

Wacek Kusnierczyk wrote:
> Tony Plate wrote:
>   
>> Wacek Kusnierczyk wrote:
>>     
>>> [snip]
>>> i just can't get it why the manual does not manifestly explain what
>>> 'names<-' does, and leaves you doing the guesswork you suggest.
>>>
>>>   
>>>       
>> I'm having trouble understanding the point of this discussion. 
>> Someone is calling a replacement function in a way that it's not meant
>> to be used, and is them complaining about it not doing what he thinks
>> it should, or about the documentation not describing what happens when
>> one does that?
>>     
>
> where is it written that the function is not meant to be used this way? 
> you get an example in the man page, showing precisely how it could be
> used that way.  it also explains the value of 'names<-':
>
> "
>  For 'names<-', the updated object.  (Note that the value of
>      'names(x) <- value' is that of the assignment, 'value', not the
>      return value from the left-hand side.)
> "
>
> it does speak of 'names<-' used in prefix form, and does not do it in
> any negative (discouraging) way.
>
>   
>> Is there anything incorrect or missing in the help page for normal
>> usage of the replacement function for 'names'? (i.e., when used in an
>> expression like 'names(x) <- ...')
>>     
>
> what is missing here in the first place is a specification of what
> 'normal' means.  as far as i can see from the man page, 'normal' does
> not exclude prefix use.  and if so, what is missing in the help page is
> a clear statement what an application of 'names<-' will do, in the sense
> of what a user may observe.
>   
Fair enough.  I looked at the help page for "names" after sending my 
email, and was surprised to see the following in the "DETAILS" section:

   "It is possible to update just part of the names attribute via the 
general rules: see the examples. This works because the expression there 
is evaluated as |z <- "names<-"(z, "[<-"(names(z), 3, "c2"))|. "

To me, this paragraph is far more confusing than enlightening, 
especially as also gives the impression that it's OK to use a 
replacement function in a functional form.  In my own personal opinion 
it would be a enhancement to remove that example from the documentation, 
and just say you can do things like 'names(x)[2:3] <- c("a","b")'.

I often use name replacement functions in a functional way, and because 
one can't use 'names<-' etc in this way, I define my own functions like 
the following:

set.names <- function(n,x) {names(x) <- n; x}

(and similarly for set.rownames(), set colnames(), etc.)

I would highly recommend you do this rather than try to use a call like 
"names<-"(x, ...).

-- Tony Plate

(I guess that if on the label of fridge there is a picture of a guy 
carrying it on his back, then Mr. Fridge-Racer might have some grounds 
for suing.)


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar 14 00:58:42 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 14 Mar 2009 00:58:42 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BAEB33.8040708@acm.org>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>	<49BAB3C5.9010401@acm.org>
	<49BAC763.5040104@idi.ntnu.no> <49BAEB33.8040708@acm.org>
Message-ID: <49BAF332.4040503@idi.ntnu.no>

Tony Plate wrote:
> Wacek Kusnierczyk wrote:
>> Tony Plate wrote:
>>    
>>> Is there anything incorrect or missing in the help page for normal
>>> usage of the replacement function for 'names'? (i.e., when used in an
>>> expression like 'names(x) <- ...')
>>>     
>>
>> what is missing here in the first place is a specification of what
>> 'normal' means.  as far as i can see from the man page, 'normal' does
>> not exclude prefix use.  and if so, what is missing in the help page is
>> a clear statement what an application of 'names<-' will do, in the sense
>> of what a user may observe.
>>   
> Fair enough.  I looked at the help page for "names" after sending my
> email, and was surprised to see the following in the "DETAILS" section:
>
>   "It is possible to update just part of the names attribute via the
> general rules: see the examples. This works because the expression
> there is evaluated as |z <- "names<-"(z, "[<-"(names(z), 3, "c2"))|. "
>
> To me, this paragraph is far more confusing than enlightening,
> especially as also gives the impression that it's OK to use a
> replacement function in a functional form.  In my own personal opinion
> it would be a enhancement to remove that example from the
> documentation, and just say you can do things like 'names(x)[2:3] <-
> c("a","b")'.

i must say that this part of the man page does explain things to me. 
much less the code [1] berwin suggested as a piece to read and
investigate (slightly modified):

    tmp = x
    x = 'names<-'(tmp, 'foo')

berwin's conclusion seemed to be that this code
hints/suggests/fortune-tells the user that 'names<-' might be doing side
effects. 

this code illustrates what names(x) = 'foo' (the infix form) does --
that it destructively modifies x.  now, if the code were to illustrate
that the prefix form does perform side effects too, then the following
would be enough:

    'names<-'(x, 'foo')

if the code were to illustrate that the prefix form, unlike the infix
form, does not perform side effects, then the following would suffice
for a discussion:

    x = 'names<-'(x, 'foo')

if the code wee to illustrate that the prefix form may or may not do
side effects depending on the situation, then it surely fails to show
that, unless the user performs some sophisticated inference which i am
not capable of, or, more likely, unless the user already knows that this
was to be shown.

without a discussion, the example is simply an unworked rubbish.  and
it's obviously wrong; it says that (slightly and irrelevantly simplified)

    names(x) = 'foo'

"is equivalent to"

    tmp = x
    x = 'names<-'(tmp, 'foo')

which is nonsense, because in the latter case you either have an
additional binding that you don't have in the former case, or, worse,
you rebind, possibly with a different value, a name that has had a
binding already.  it's a gritty-nitty detail, but so is most of
statistics based on nitty-gritty details which non-statisticians are
happy to either ignore or be ignorant about.


[1] http://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html#Comments

>
> I often use name replacement functions in a functional way, and
> because one can't use 'names<-' etc in this way, 

note, this 'because' does not follow in any way from the man page, or
the section of 'r language definition' referred to above.


> I define my own functions like the following:
>
> set.names <- function(n,x) {names(x) <- n; x}

it appears that

    set.names = function(n, x) 'names<-'(x, n)

would do the job (guess why).

>
> (and similarly for set.rownames(), set colnames(), etc.)
>
> I would highly recommend you do this rather than try to use a call
> like "names<-"(x, ...).

i'm almost tempted to extend your recommendation to 'define your own
function for about every function already in r' ;)

vQ


From berwin at maths.uwa.edu.au  Sat Mar 14 05:20:34 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 14 Mar 2009 12:20:34 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BAA8E6.3080407@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
	<49B96FE7.2060705@idi.ntnu.no>
	<20090313120309.7acb13e5@berwin-nus1>
	<49BA38EB.3000004@idi.ntnu.no> <20090313234755.6f6e08c9@berwin5>
	<49BAA8E6.3080407@idi.ntnu.no>
Message-ID: <20090314122034.696f6c33@absentia>

On Fri, 13 Mar 2009 19:41:42 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> > Glad to see that we agree on this.
> >   
> 
> owe you a beer.

O.k., if we ever meet is is first your shout and then mine.
 
> >> haven't objected to that.  i object to your 'r uses pass by value',
> >> which is only partially correct.
> >>     
> >
> > Well, I used qualifiers and did not stated it categorically. 
> >   
> 
> indeed, you said "R supposedly uses call-by-value (though we know how
> to circumvent that, don't we?)".
> 
> in that vain, R supposedly can be used to do valid statistical
> computations (though we know how to circumvent it) ;)

Sure, use Excel? ;-)
 
> > Indeed, if you type these two commands on the command line, then it
> > is not surprising that a copy of tmp is returned since you create a
> > temporary object that ends up in the symbol table and persist after
> > the commands are finished.
> >   
> 
> what does command line have to do with it?

If you want to find out what goes on under the hood, it is not
necessarily sufficient to do the same calculations on the command line.
 
> > Obviously, assuming that R really executes 
> > 	*tmp* <- x
> > 	x <- "names<-"('*tmp*', value=c("a","b"))
> > under the hood, in the C code, then *tmp* does not end up in the
> > symbol table 
> 
> no?

Well, I don't see any new object created in my workspace after
	x <- 4
	names(x) <- "foo"
Do you?

> i guess you have looked under the hood;  point me to the relevant
> code.

No I did not, because I am not interested in knowing such intimate
details of R, but it seems you were interested.
 
> yes, *if* you are able to predict the refcount of the object passed to
> 'names<-' *then* you can predict what 'names<-' will do, [...] 

I think Simon pointed already out that you seem to have a wrong
picture of what is going on.  As far as I know, there is no refcount
for objects.  

The relevant documentation would be R Language Manual, 1.1 SEXPs:

  What R users think of as variables or objects are symbols which are
  bound to a value. The value can be thought of as either a SEXP (a
  pointer), or the structure it points to, a SEXPREC (and there are
  alternative forms used for vectors, namely VECSXP pointing to
  VECTOR_SEXPREC structures).

and 1.1.2 Rest of header:

  The named field is set and accessed by the SET_NAMED
  and NAMED macros, and take values 0, 1 and 2. R has a `call by value'
  illusion, so an assignment like

      b <- a

  appears to make a copy of a and refer to it as b. However, if neither
  a nor b are subsequently altered there is no need to copy. What really
  happens is that a new symbol b is bound to the same value as a and the
  named field on the value object is set (in this case to 2). When an
  object is about to be altered, the named field is consulted. A value
  of 2 means that the object must be duplicated before being changed.
  (Note that this does not say that it is necessary to duplicate, only
  that it should be duplicated whether necessary or not.) A value of 0
  means that it is known that no other SEXP shares data with this
  object, and so it may safely be altered. A value of 1 is used for
  situations like

      dim(a) <- c(7, 2)

  where in principle two copies of a exist for the duration of the
  computation as (in principle)

      a <- `dim<-`(a, c(7, 2))

  but for no longer, and so some primitive functions can be optimized to
  avoid a copy in this case. 

> but in general you may not have the chance. [...]

Agreed.

> and in general, this should not matter because it should be
> unobservable, but it isn't.

That's your opinion (to which you are entitled).  Unfortunately (for
you), the designers of R decided on a design which allows them to
reduce the number of copies that have to be made.

> >> you suggested that "One reads the manual, (...) one reflects and
> >> investigates, ..."
> >>     
> >
> > Indeed, and I am not giving up hope that one day you will master
> > this art.
> >   
> 
> well, this time i meant you.
 
Rest assure I have read and reflected on that part of the manual.  

And I guess it boils down to how you interpret what "is equivalent to"
means.

For me it means that those two commands are what is executed in the C
engine once the "names(x)<-c("a","b")" expression is parsed and the
parse list arrives at the interpreter.  To investigate whether that is
the case, one would have to look at the C code, and I have little
inclination to do so.  But that would be necessary to answer the
question whether *tmp* or a copy of *tmp* is returned, if one is really
interested in this question.  Or whether a *tmp* object is created at
all.

You seem to take "is equivalent to" to mean that issuing
"names(x)<-c("a","b")" on the command line has the same effect as
issuing those two other commands on the command line and addressing
whether *tmp* or a copy of *tmp* is returned in this case.  Fair
enough, but it addresses a different question.  And, as you said
yourself in another e-mail, on the command line these two versions are
not equivalent since one creates an additional object.


I was under the impression that you were interested to understand what
happens if you issue the commands
	names(x) <- "foo"
and
	"names<-"(x, "foo")
and I must agree with Simon, the answer by Peter was explaining it very
well to someone familiar with the documentation of R.  The fact that
you found that answer unsatisfactory suggests that you could improve
your familiarity with the documentation.  Simon's answers provided
already more details and I provided you with pointers to what I believe
to be relevant documentation.  It's now up to you whether, and how, you
want to digest this information/documentation.  And some questions are
not answered by the documentation and you will have to look into the
code to get the answers to those questions.  

The ultimate documentation is the source code which is freely available
(not sure whom I am paraphrasing here).

Best wishes,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar 14 07:22:34 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 14 Mar 2009 07:22:34 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090314122034.696f6c33@absentia>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>	<20090313234755.6f6e08c9@berwin5>	<49BAA8E6.3080407@idi.ntnu.no>
	<20090314122034.696f6c33@absentia>
Message-ID: <49BB4D2A.40806@idi.ntnu.no>

Berwin A Turlach wrote:
> On Fri, 13 Mar 2009 19:41:42 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>
>   
>> indeed, you said "R supposedly uses call-by-value (though we know how
>> to circumvent that, don't we?)".
>>
>> in that vain, R supposedly can be used to do valid statistical
>> computations (though we know how to circumvent it) ;)
>>     
>
> Sure, use Excel? ;-)
>   

no, it has a buggy round

>  
>   
>>> Indeed, if you type these two commands on the command line, then it
>>> is not surprising that a copy of tmp is returned since you create a
>>> temporary object that ends up in the symbol table and persist after
>>> the commands are finished.
>>>   
>>>       
>> what does command line have to do with it?
>>     
>
> If you want to find out what goes on under the hood, it is not
> necessarily sufficient to do the same calculations on the command line.
>  
>   
>>> Obviously, assuming that R really executes 
>>> 	*tmp* <- x
>>> 	x <- "names<-"('*tmp*', value=c("a","b"))
>>> under the hood, in the C code, then *tmp* does not end up in the
>>> symbol table 
>>>       
>> no?
>>     
>
> Well, I don't see any new object created in my workspace after
> 	x <- 4
> 	names(x) <- "foo"
> Do you?
>   

of course not.  that's why i'd say the two above are *not* equivalent. 

i haven't noticed the 'in the c code';  do you mean the r interpreter
actually generates, in the c code, such r expressions for itself to
evaluate?


>   
>> i guess you have looked under the hood;  point me to the relevant
>> code.
>>     
>
> No I did not, because I am not interested in knowing such intimate
> details of R, but it seems you were interested.
>   

yes, but then your claim about what happens under the hood, in the c
code, is a pure stipulation.  and you got the example from the r
language definition sec. 10.2, which says the forms are equivalent, with
no 'under the hood, in the c code' comment.

you're just showing that your statements cannot be taken seriously.


>  
>   
>> yes, *if* you are able to predict the refcount of the object passed to
>> 'names<-' *then* you can predict what 'names<-' will do, [...] 
>>     
>
> I think Simon pointed already out that you seem to have a wrong
> picture of what is going on.  As far as I know, there is no refcount
> for objects.  
>
> The relevant documentation would be R Language Manual, 1.1 SEXPs:
>
>   What R users think of as variables or objects are symbols which are
>   bound to a value. The value can be thought of as either a SEXP (a
>   pointer), or the structure it points to, a SEXPREC (and there are
>   alternative forms used for vectors, namely VECSXP pointing to
>   VECTOR_SEXPREC structures).
>
> and 1.1.2 Rest of header:
>
>   The named field is set and accessed by the SET_NAMED
>   and NAMED macros, and take values 0, 1 and 2. R has a `call by value'
>   illusion, so an assignment like
>
>       b <- a
>
>   appears to make a copy of a and refer to it as b. However, if neither
>   a nor b are subsequently altered there is no need to copy. What really
>   happens is that a new symbol b is bound to the same value as a and the
>   named field on the value object is set (in this case to 2). When an
>   object is about to be altered, the named field is consulted. A value
>   of 2 means that the object must be duplicated before being changed.
>   (Note that this does not say that it is necessary to duplicate, only
>   that it should be duplicated whether necessary or not.) A value of 0
>   means that it is known that no other SEXP shares data with this
>   object, and so it may safely be altered. A value of 1 is used for
>   situations like
>
>       dim(a) <- c(7, 2)
>
>   where in principle two copies of a exist for the duration of the
>   computation as (in principle)
>
>       a <- `dim<-`(a, c(7, 2))
>
>   but for no longer, and so some primitive functions can be optimized to
>   avoid a copy in this case. 
>
>   

so what you quote effectively talks about a specific refcount
mechanism.  it's not refcount that would be used by the garbage
collector, but it's a refcount, or maybe refflag.


>> and in general, this should not matter because it should be
>> unobservable, but it isn't.
>>     
>
> That's your opinion (to which you are entitled).  

yes, that's my opinion:  the effects of implementation tricks should not
be observable by the user, because they can lead to hard to explain and
debug behaviour in the user's program.  you surely don't suggest that
all users consult the source code before writing programs in r.


> Unfortunately (for
> you), the designers of R decided on a design which allows them to
> reduce the number of copies that have to be made.
>   

and that's excellent, only that they failed to hide the mechanism below
the interface.  or maybe they decided not to hide it?

> I was under the impression that you were interested to understand what
> happens if you issue the commands
> 	names(x) <- "foo"
> and
> 	"names<-"(x, "foo")
> and I must agree with Simon, the answer by Peter was explaining it very
> well to someone familiar with the documentation of R.  The fact that
> you found that answer unsatisfactory suggests that you could improve
> your familiarity with the documentation.  

i have indeed learned what prefix 'names<-' does and now i know that the
surprising behaviour is due to the observability of the internal
optimization.

thanks to simon, peter, and you for your answers which allowed me to
learn this ugly detail.

vQ


From tlumley at u.washington.edu  Sat Mar 14 09:58:25 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 14 Mar 2009 01:58:25 -0700 (PDT)
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700DF10EE@NA-PA-VBE03.na.tibco.com>
Message-ID: <Pine.LNX.4.43.0903140158250.14976@hymn14.u.washington.edu>

On Fri, 13 Mar 2009, William Dunlap wrote:

> Would it make anyone any happier if the manual said
> that the replacement functions should not be called
> in the form
>   xNew <- `func<-` (xOld, value)
> and should only be used as
>   func(xToBeChanged) <- value
> ?

That was my reaction, too.  The discussion reminded me of old comp.lang.c threads about i=i++ and similar issues. The anomalies in
   xNew <- `func<-` (xOld, value) 
arise precisely because it isn't supposed to be used that way.

My other proposal for 'rigidly defined areas of doubt and uncertainty' has been the evaluation order of the *apply family (eg, does apply process the columns left to right, or right to left, or however it feels like?).


       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From berwin at maths.uwa.edu.au  Sat Mar 14 12:24:34 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 14 Mar 2009 19:24:34 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BB4D2A.40806@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
	<49B96FE7.2060705@idi.ntnu.no>
	<20090313120309.7acb13e5@berwin-nus1>
	<49BA38EB.3000004@idi.ntnu.no> <20090313234755.6f6e08c9@berwin5>
	<49BAA8E6.3080407@idi.ntnu.no> <20090314122034.696f6c33@absentia>
	<49BB4D2A.40806@idi.ntnu.no>
Message-ID: <20090314192434.6f21600b@absentia>

On Sat, 14 Mar 2009 07:22:34 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

[...]
> > Well, I don't see any new object created in my workspace after
> > 	x <- 4
> > 	names(x) <- "foo"
> > Do you?
> >   
> 
> of course not.  that's why i'd say the two above are *not*
> equivalent. 
> 
> i haven't noticed the 'in the c code';  do you mean the r interpreter
> actually generates, in the c code, such r expressions for itself to
> evaluate?

As I said before, I have little knowledge about how the parser works and
what goes on under the hood; and I have also little time and
inclination to learn about it.  

But if you are interested in these details, then by all means invest
the time to investigate.

Alternatively, you would hope that Simon eventually finishes the book
that he is writing on programming in R; as I understand it, that book
would explain part of these issues in details.  Hopefully, along with
the book he makes the tools that he has for introspection available.

> >> i guess you have looked under the hood;  point me to the relevant
> >> code.     
> >
> > No I did not, because I am not interested in knowing such intimate
> > details of R, but it seems you were interested.
> >   
> 
> yes, but then your claim about what happens under the hood, in the c
> code, is a pure stipulation.  

I made no claim about what is going on under the hood because I have no
knowledge about these matters.  But, yes, I was speculating of what
might go on.

> and you got the example from the r language definition sec. 10.2,
> which says the forms are equivalent, with no 'under the hood, in the
> c code' comment.

Trying to figure out what a writer/painter actually means/says beyond
the explicitly stated/painted, something that is summed up in Australia
(and other places) under the term "critical thinking", was not high in
the curriculum of your school, was it? :-)

> you're just showing that your statements cannot be taken seriously.

Usually, my statement can be taken seriously, unless followed by some
indication that I said them tongue-in-cheek.  Of course, statements
that I allegedly made but were in fact put into my mouth cannot, and
should not, be taken seriously.

> >> yes, *if* you are able to predict the refcount of the object
> >> passed to 'names<-' *then* you can predict what 'names<-' will do,
> >> [...] 
> >
> > I think Simon pointed already out that you seem to have a wrong
> > picture of what is going on.  [...]
>
> so what you quote effectively talks about a specific refcount
> mechanism.  it's not refcount that would be used by the garbage
> collector, but it's a refcount, or maybe refflag.

Fair enough, if you call this a refcount then there is no problem.
Whenever I came across the term refcount in my readings, it was
referring to different mechanisms, typically mechanisms that kept exact
track on how often an object was referred too.  So I would not call the
value of the named field a refcount.  And we can agree to call it from
now on a refcount as long as we realise what mechanism is really used.
 
> yes, that's my opinion:  the effects of implementation tricks should
> not be observable by the user, because they can lead to hard to
> explain and debug behaviour in the user's program.  you surely don't
> suggest that all users consult the source code before writing
> programs in r.

Indeed, I am not suggesting this.  Only users who use/rely on
features that are not sufficiently documented would have to study the
source code to find out what the exact behaviour is.  But, of course,
this could be fraught with danger since the behaviour could change
without warning.

> i have indeed learned what prefix 'names<-' does and now i know that
> the surprising behaviour is due to the observability of the internal
> optimization.
> 
> thanks to simon, peter, and you for your answers which allowed me to
> learn this ugly detail.

You are welcome.

Cheers,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar 14 16:36:12 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 14 Mar 2009 16:36:12 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090314192434.6f21600b@absentia>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>	<20090313234755.6f6e08c9@berwin5>	<49BAA8E6.3080407@idi.ntnu.no>	<20090314122034.696f6c33@absentia>	<49BB4D2A.40806@idi.ntnu.no>
	<20090314192434.6f21600b@absentia>
Message-ID: <49BBCEEC.1030100@idi.ntnu.no>

Berwin A Turlach wrote:
> On Sat, 14 Mar 2009 07:22:34 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
> [...]
>   
>>> Well, I don't see any new object created in my workspace after
>>> 	x <- 4
>>> 	names(x) <- "foo"
>>> Do you?
>>>   
>>>       
>> of course not.  that's why i'd say the two above are *not*
>> equivalent. 
>>
>> i haven't noticed the 'in the c code';  do you mean the r interpreter
>> actually generates, in the c code, such r expressions for itself to
>> evaluate?
>>     
>
> As I said before, I have little knowledge about how the parser works and
> what goes on under the hood; and I have also little time and
> inclination to learn about it.  
>
> But if you are interested in these details, then by all means invest
> the time to investigate.
>
>   

berwin, you're playing radio erewan now.  i talk about what the user
sees at the interface, and you talk about c code.  then you admit you
don't know the code, and suggest i examine it if i'm interested.  i
incidentally am, but the whole point was that the user should not be
forced to look under the hood to know the interface to a function. 
prefix 'names<-' seems to have a certain behaviour that is not properly
documented.

> Alternatively, you would hope that Simon eventually finishes the book
> that he is writing on programming in R; as I understand it, that book
> would explain part of these issues in details.  Hopefully, along with
> the book he makes the tools that he has for introspection available.
>   

simon:  i'd be happy to contribute in any way you might find useful.

>   
>>>> i guess you have looked under the hood;  point me to the relevant
>>>> code.     
>>>>         
>>> No I did not, because I am not interested in knowing such intimate
>>> details of R, but it seems you were interested.
>>>   
>>>       
>> yes, but then your claim about what happens under the hood, in the c
>> code, is a pure stipulation.  
>>     
>
> I made no claim about what is going on under the hood because I have no
> knowledge about these matters.  But, yes, I was speculating of what
> might go on.
>   

owe me a beer.

>   
>> and you got the example from the r language definition sec. 10.2,
>> which says the forms are equivalent, with no 'under the hood, in the
>> c code' comment.
>>     
>
> Trying to figure out what a writer/painter actually means/says beyond
> the explicitly stated/painted, something that is summed up in Australia
> (and other places) under the term "critical thinking", was not high in
> the curriculum of your school, was it? :-)
>   

sure, but probably not the way you seem to think about.  have you
incidentally read ferdydurke by gombrowicz? 


>   
>> you're just showing that your statements cannot be taken seriously.
>>     
>
> Usually, my statement can be taken seriously, unless followed by some
> indication that I said them tongue-in-cheek.  Of course, statements
> that I allegedly made but were in fact put into my mouth cannot, and
> should not, be taken seriously.
>   

i'm talking about your speculations about what the parser does (wrt.
infix and prefix forms having exactly the same parse tree), rather vague
statements such as "'names<-'(x,'foo') should create (more or less) a
parse tree equivalent to that expression", and other statements (surely,
qualified with 'assuming', 'strongly suggests', and the like), coupled
with your admitting that you in fact don?t know what happens there, is
not particularly reassuring.
>   
>>>> yes, *if* you are able to predict the refcount of the object
>>>> passed to 'names<-' *then* you can predict what 'names<-' will do,
>>>> [...] 
>>>>         
>>> I think Simon pointed already out that you seem to have a wrong
>>> picture of what is going on.  [...]
>>>       
>> so what you quote effectively talks about a specific refcount
>> mechanism.  it's not refcount that would be used by the garbage
>> collector, but it's a refcount, or maybe refflag.
>>     
>
> Fair enough, if you call this a refcount then there is no problem.
> Whenever I came across the term refcount in my readings, it was
> referring to different mechanisms, typically mechanisms that kept exact
> track on how often an object was referred too.  So I would not call the
> value of the named field a refcount.  And we can agree to call it from
> now on a refcount as long as we realise what mechanism is really used.
>   

the major point of the discussion was that 'names<-' will sometimes
modify and othertimes copy its argument.  you chose to justify this by
looking under the hood, and i suppose you were pretty clear what i meant
by refcount, because it should have been clear from the context.

>  
>   
>> yes, that's my opinion:  the effects of implementation tricks should
>> not be observable by the user, because they can lead to hard to
>> explain and debug behaviour in the user's program.  you surely don't
>> suggest that all users consult the source code before writing
>> programs in r.
>>     
>
> Indeed, I am not suggesting this.  Only users who use/rely on
> features that are not sufficiently documented would have to study the
> source code to find out what the exact behaviour is.  But, of course,
> this could be fraught with danger since the behaviour could change
> without warning.
>   

... and one of my points was precisely that 'names<-' is not
sufficiently documented.  could we agree on this, please?

best,
vQ


From Florian.S.Gross at web.de  Sun Mar 15 16:25:24 2009
From: Florian.S.Gross at web.de (Florian Gross)
Date: Sun, 15 Mar 2009 16:25:24 +0100
Subject: [Rd] Summer of Code, LLVM, parallelization and R
Message-ID: <E4AD01F4-2190-4BB9-815C-8DE33E055D2A@web.de>

Hi everybody,

I'm currently working towards my Master's degree as a student of  
Computer Science at the University of Saarbr?cken and highly  
interested in compiler construction, interpretation techniques,  
optimization, programming languages and more. :)

Two professors of my university approached me about an interesting  
project just a few days ago: Developing a LLVM-based JIT compilation  
back-end for R. The primary goal would be the generation of parallel /  
vectorized code, but other ways of increasing performance might be  
very interesting as well.

I've thought a bit about this and am now wondering if this would make  
sense as a project for Google's Summer of Code program -- I have seen  
that the R foundation was accepted as a mentoring organization in 2008  
and has applied to be one again in this year.

I've already taken part in the SoC program thrice (working on Novell's  
JScript.NET compiler and run-time environment in 2005, writing a  
debugger for the Ruby programming language in 2006 and working on a  
detailed specification for the Ruby programming language in 2007) and  
it has always been a lot of fun and a great experience. One thing that  
was particularly helpful was getting into contact with the development  
communities so easily.

What do you folks think? Would this be of benefit to the R community?  
Would it be a good candidate for this year's SoC installment? :)

Also, if some thinking in this direction has already been done or if  
you have any other pointers, please don't hesitate to reply!

Thanks a lot in advance!

Kind regards,
Florian Gross

From chalabi at phys.ethz.ch  Sun Mar 15 16:31:02 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Sun, 15 Mar 2009 16:31:02 +0100
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
In-Reply-To: <49B86F15.3060700@r-project.org>
References: <20090311145557.5c9b57e0@mimi> <49B7ED87.3090102@r-project.org>
	<20090311214424.558b4dff@mimi> <49B86F15.3060700@r-project.org>
Message-ID: <20090315163102.6b114261@mimi>

>>>> "JC" == John Chambers <jmc at r-project.org>
>>>> on Wed, 11 Mar 2009 19:10:29 -0700

   JC> The problems are related to masking objects (in this case ) in
   JC> the search list, not especially related to methods.
   JC>
   JC> It was in order to get around such problems that NAMESPACE
   JC> was added to
   JC> R.  You should use it, but it applies to evaluating calls
   JC> to functions
   JC> in the package, by avoiding the dependency on the order of
   JC> packages in
   JC> the search list.  To ensure correct results, you need to call a
   JC> function from your package (i.e., one that is not masked).  The
   JC> computations in the function will see what has been imported
   JC> into the
   JC> namespace.
   JC>
   JC> For example, if you do the following:
   JC>
   JC> 1.  add a NAMESPACE file, for example containing:
   JC>
   JC> import(stats)
   JC> import(zoo)
   JC> exportPattern(^[a-zA-Z])
   JC>
   JC> 2.  Do the computations in a function in your package,
   JC> say doDemo(),
   JC> with a few show(time()) lines added to print things.
   JC>
   JC> 3.  With the import(zoo), no need to define as an S3 generic.
   JC>
   JC> Then things behave with or without zoo attached, because the
   JC> computations are defined by your namespace.


Thank you for your responses.

'timeSeries' and 'zoo' both have functionality for time series
management. Although they have similar concepts, they are intrinsically
different; the former package uses S4 classes and the latter S3 classes.

Until now both packages have been able to coexist and have been  
independent from each other.

As I mentioned in my previous post, both packages define methods to  
extract timestamps of their respective classes with the function  
'time' .

I agree with you that if we had used a function name and its  
assignment version defined in 'zoo', we should import it from their  
namespace. But in this case, 'time<-' is the natural extension of a  
function already present in a base package.

Until now we defined the S3 generic 'time<-' so that both packages  
could coexist without needing to import the function from the  
namespace of the other. But this workaround won't work anymore if we  
define an S4 generic.

We are thus asking the R developers if they could add 'time<-'  as a  
generic in 'stats' because it is the natural extension of an existing  
function. This will ensure that packages can continue to coexist and  
remain independent.

Best regards,
Yohan

-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From macrakis at alum.mit.edu  Sun Mar 15 16:49:38 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 15 Mar 2009 11:49:38 -0400
Subject: [Rd] Assigning to factor[[i]]
Message-ID: <8b356f880903150849t3d0c5e33q5a08a620d5dacd73@mail.gmail.com>

I am a bit confused about the semantics of classes, [, and [[.

For at least some important built-in classes (factors and dates), both
the getter and the setter methods of [ operate on the class, but
though the getter method of [[ operates on the class, the setter
method operates on the underlying vector.  Is this behavior
documented? (I haven't found any documentation of it.) Is it
intentional?  (i.e. is it a bug or a feature?)  There are also cases
where invalid assignments don't signal an error.

A simple example:

> fact <- factor(2,levels=2:4)        # master copy
> f0 <- fact; f0; dput(f0)
[1] 2
Levels: 2 3 4
structure(1L, .Label = c("2", "3", "4"), class = "factor")

> f0 <- fact; f0[1] <- 3; f0; dput(f0)     # use [ setter
[1] 3
Levels: 2 3 4
structure(2L, .Label = c("2", "3", "4"), class = "factor")


> f0 <- fact; f0[[1]] <- 3L; f0; dput(f0)   # use [[ setter
[1] 4                                                    # ? didn't
convert 3 to factor
Levels: 2 3 4
structure(3L, .Label = c("2", "3", "4"), class = "factor")   #
modified underlying vector
> f0[1]
[1] 4
Levels: 2 3 4
# but result is a valid factor

> f0 <- fact; f0[[1]] <- 3; f0; dput(f0)   # use [[ setter
[1] 4
Levels: 2 3 4
structure(3, .Label = c("2", "3", "4"), class = "factor")  # didn't
convert to 3L
> f0[1]
Error in class(y) <- oldClass(x) :
  adding class "factor" to an invalid object

I suppose f0[1] and f0[[1]] fail here because the underlying vector
must be integer and not numeric? If so, why didn't assigning to
f0[[1]] cause an error? And why didn't printing f0 cause the same
error?

Here are some more examples. Consider

fac <- factor(c("b","a","c"),levels=c("b","c","a"))

f <- fac; f[1] <- "c"; dput(f)
# structure(c(2L, 3L, 2L), .Label = c("b", "c", "a"), class = "factor")
#### OK, implicit conversion of "c" to factor(c) was performed

f <- fac; f[1] <- 25; dput(f)
# Warning message:
# In `[<-.factor`(`*tmp*`, 1, value = 25) :
#   invalid factor level, NAs generated
# structure(c(NA, 3L, 2L), .Label = c("b", "c", "a"), class = "factor")
#### OK, error given for invalid value, which becomes an NA
#### Same thing happens for f[1]<-"foo"

So far, so good.  Now compare to what happens with fac[[...]] <- ...

f <- fac; f[[1]] <- 25; dput(f)
# structure(c(25, 3, 2), .Label = c("b", "c", "a"), class = "factor")
#### No error given, but invalid factor generated

f <- fac; f[[1]] <- "c"; dput(f)
# structure(c("c", "3", "2"), .Label = c("b", "c", "a"), class = "factor")
#### No conversion performed; no error given; invalid factor generated

f
# [1] <NA> <NA> <NA>
# Levels: b c a
#### Prints as though it were factor(c(NA,NA,NA)) with no warning/error

f[]
# Error in class(y) <- oldClass(x) :
#  adding class "factor" to an invalid object
#### But f[] gives an error
#### Same error with f[1] and f[[1]]

Another interesting case is f[1] <- list(NULL) -- which correctly
gives an error -- versus f[[1]] <- list(), which gives no error but
results in an f which is not a factor at all:

f <- fac; f[[1]]<-list(); class(f); dput(f)
[1] "list"
list(list(), 3L, 2L)

I can see that being able to modify the underlying vector of a classed
object directly would be very valuable functionality, but there is an
assymmetry here: f[[1]]<- modifies the underlying vector, but f[[1]]
accesses the classed vector.  Presumably you need to do
unclass(f)[[1]] to see the underlying value.  But on the other hand,
unclass doesn't have a setter (`unclass<-`), so you can't say
unclass(f)[[1]] <- ...

I have not been able to find documentation of all this in the R
Language Definition or in the man page for [/[[, but perhaps I'm
looking in the wrong place?

            -s


From macrakis at alum.mit.edu  Sun Mar 15 17:28:06 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 15 Mar 2009 12:28:06 -0400
Subject: [Rd] Conversion and rounding of POSIXct
Message-ID: <8b356f880903150928j15ef1d24tba7ae84e409deafa@mail.gmail.com>

POSIXct/lt supports fractional seconds (see Sub-second Accuracy
section of man page), but there seem to be some inconsistencies in
their handling.

Converting to POSIXlt and back does not give back the same time for
times before the origin:

> t0 <- as.POSIXct('1934-01-05 23:59:59.00001')
> t0
[1] "1934-01-06 00:00:00 EST"      # rounding issue, see below
> as.POSIXlt(t0)
[1] "1934-01-06 00:00:00 EST"
> as.POSIXct(as.POSIXlt(t0))
[1] "1934-01-06 00:00:01 EST"   # ???
> as.POSIXct(as.POSIXlt(t0)) - t0
Time difference of 1 secs

Also, POSIXct always rounds up when printing for times before the origin:

> as.POSIXct('1934-01-05 10:10:23')
[1] "1934-01-05 10:10:23 EST"
> as.POSIXct('1934-01-05 10:10:23.00001')
[1] "1934-01-05 10:10:24 EST"

and always rounds down when printing times after the origin:

as.POSIXct('2010-01-05 23:59:59.4')
[1] "2010-01-05 23:59:59 EST"
> as.POSIXct('2010-01-05 23:59:59.6')
[1] "2010-01-05 23:59:59 EST"
> as.POSIXct('2010-01-05 23:59:59.999')
[1] "2010-01-05 23:59:59 EST"

But the Description section says that POSIXct "represent[s] calendar
dates and times (to the nearest second)".  "Nearest" would seem to
imply printing rounding-to-nearest, not rounding-up or rounding-down.


From edd at debian.org  Sun Mar 15 18:04:22 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 15 Mar 2009 12:04:22 -0500
Subject: [Rd] Conversion and rounding of POSIXct
In-Reply-To: <8b356f880903150928j15ef1d24tba7ae84e409deafa@mail.gmail.com>
References: <8b356f880903150928j15ef1d24tba7ae84e409deafa@mail.gmail.com>
Message-ID: <18877.13590.70146.994092@ron.nulle.part>


Stavros,

Two really quick comments:

a) you need to enable sub-second print formats
b) AFAIK pre-epoch times are second-class citizens

R> options("digits.secs"=6)   ## print with 6 digits for microseconds
R> t0 <- as.POSIXct('1974-01-05 23:59:59.00001')
R> t0
[1] "1974-01-05 23:59:59.00001 CST"
R> as.POSIXlt(t0)
[1] "1974-01-05 23:59:59.00001 CST"
R> as.POSIXct(as.POSIXlt(t0)) - t0
Time difference of 0 secs

All that said, POSIXt is still under-documented and rather mysterious so I
won't / can't comment on all aspects of your post but the above should shed
some light on the first few items.

Hth, Dirk

-- 
Three out of two people have difficulties with fractions.


From macrakis at alum.mit.edu  Sun Mar 15 18:10:54 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 15 Mar 2009 13:10:54 -0400
Subject: [Rd] Conversion and rounding of POSIXct
In-Reply-To: <18877.13590.70146.994092@ron.nulle.part>
References: <8b356f880903150928j15ef1d24tba7ae84e409deafa@mail.gmail.com>
	<18877.13590.70146.994092@ron.nulle.part>
Message-ID: <8b356f880903151010m67d3231fr53e351837c8ed1d@mail.gmail.com>

On Sun, Mar 15, 2009 at 1:04 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

Dirk,

Thanks for your reply.

> a) you need to enable sub-second print formats

Yes, if I want to display sub-second printing.  But I was just looking
at the rounding behavior.

> b) AFAIK pre-epoch times are second-class citizens

In what sense?  That bugs in their handling won't be fixed?  If so, it
would be nice to document that.

Thanks again,

           -s


From murdoch at stats.uwo.ca  Sun Mar 15 18:44:46 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 15 Mar 2009 13:44:46 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49B95F7E.5020406@scs.carleton.ca>
References: <49B95F7E.5020406@scs.carleton.ca>
Message-ID: <49BD3E8E.9090206@stats.uwo.ca>

On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
> Hi,
> 
> I receive the following error while I try to install rgl package:
> 
> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H -I/usr/include/libpng12 
> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
> -I/usr/sfw/include -I/opt/csw/include    -KPIC  -O -c Background.cpp -o 
> Background.o
> "math.h", line 47: Error: modf is not a member of file level.
> "math.h", line 48: Error: modff is not a member of file level.
> "Shape.hpp", line 58: Error: The function "strncpy" must have a prototype.
> 3 Error(s) detected.
> 
> I am using Sun studio 12.
> I suspect that this is an incompatibility between g++ and Sun studio CC.
> I would appreciate any you could share your experience with me.

Brian Ripley contributed some patches that should help with this.  Could 
you check out the source from R-forge, and confirm that it now compiles 
on your system?  (Or wait for the tarball there to be updated to 0.84-1 
in a few hours, and download that.)

Thanks Brian, for the patch.

Duncan Murdoch


From jmc at r-project.org  Sun Mar 15 19:14:29 2009
From: jmc at r-project.org (John Chambers)
Date: Sun, 15 Mar 2009 11:14:29 -0700
Subject: [Rd] Could you please add "time<-" as a generic function in the
 'stats' package ?
In-Reply-To: <20090315163102.6b114261@mimi>
References: <20090311145557.5c9b57e0@mimi>	<49B7ED87.3090102@r-project.org>	<20090311214424.558b4dff@mimi>	<49B86F15.3060700@r-project.org>
	<20090315163102.6b114261@mimi>
Message-ID: <49BD4585.2030101@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090315/e2cdfcf7/attachment.pl>

From macrakis at alum.mit.edu  Sun Mar 15 19:31:43 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 15 Mar 2009 14:31:43 -0400
Subject: [Rd] Definition of [[
Message-ID: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>

The semantics of [ and [[ don't seem to be fully specified in the
Reference manual.  In particular, I can't find where the following
cases are covered:

> cc <- c(1); ll <- list(1)

> cc[3]
[1] NA
OK, RefMan says: If i is positive and exceeds length(x) then the
corresponding selection is NA.

> dput(ll[3])
list(NULL)
? i is positive and exceeds length(x); why isn't this list(NA)?

> ll[[3]]
Error in list(1)[[3]] : subscript out of bounds
? Why does this return NA for an atomic vector, but give an error for
a generic vector?

> cc[[3]] <- 34; dput(cc)
c(1, NA, 34)
OK

ll[[3]] <- 34; dput(ll)
list(1, NULL, 34)
Why is second element NULL, not NA?
And why is it OK to set an undefined ll[[3]], but not to get it?

I assume that these are features, not bugs, but I can't find
documentation for them.

            -s


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Mar 15 21:01:33 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 15 Mar 2009 21:01:33 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090313234755.6f6e08c9@berwin5>
References: <49B67CB1.8060005@idi.ntnu.no>
	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>
	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>
	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>
	<20090313234755.6f6e08c9@berwin5>
Message-ID: <49BD5E9D.1030601@idi.ntnu.no>

Berwin A Turlach wrote:
>
> Obviously, assuming that R really executes 
> 	*tmp* <- x
> 	x <- "names<-"('*tmp*', value=c("a","b"))
> under the hood, in the C code, then *tmp* does not end up in the symbol
> table and does not persist beyond the execution of 
> 	names(x) <- c("a","b")
>
>   

to prove that i take you seriously, i have peeked into the code, and
found that indeed there is a temporary binding for *tmp* made behind the
scenes -- sort of. unfortunately, it is not done carefully enough to
avoid possible interference with the user's code:

'*tmp*' = 0
`*tmp*`
# 0

x = 1
names(x) = 'foo'
`*tmp*`
# error: object "*tmp*" not found

`*ugly*`

given that `*tmp*`is a perfectly legal (though some would say
'non-standard') name, it would be good if somewhere here a warning were
issued -- perhaps where i assign to `*tmp*`, because `*tmp*` is not just
any non-standard name, but one that is 'obviously' used under the hood
to perform black magic.

it also appears that the explanation given in, e.g., the r language
definition (draft, of course) sec. 3.4.4:

"
Assignment to subsets of a structure is a special case of a general
mechanism for complex
assignment:
x[3:5] <- 13:15
The result of this commands is as if the following had been executed
?*tmp*? <- x
x <- "[<-"(?*tmp*?, 3:5, value=13:15)
"

is incomplete (because the final result is not '*tmp*' having the value
of x, as it might seem, but rather '*tmp*' having been unbound).

so the suggestion for the documenters is to add to the end of the
section (or wherever else it is appropriate) a warning to the effect
that in the end '*tmp*' will be removed, even if the user has explicitly
defined it earlier in the same scope.

or maybe have the implementation not rely on a user-forgeable name? for
example, the '.Last.value' name is automatically bound to the most
recently returned value, but it resides in package:base and does not
collide with bindings using it made by the user:

.Last.value = 0

1
.Last.value
# 0, not 1

1
base::.Last.value
# 1, not 0


why could not '*tmp*' be bound and unbound outside of the user's
namespace? (i guess it's easier to update the docs -- or just ignore the
issue.)


on the margin, traceback('<-') will pick only one of the uses of '<-'
suggested by the code above:

x <- 1:10

trace('<-')
x[3:5] <- 13:15
# trace: x[3:5] <- 13:15
# trace: x <- `[<-`(`*tmp*`, 3:5, value = 13:15)

which is somewhat confusing, because then '*tmp*' appears in the trace
somewhat ex machina. (again, the explanation is in the source code, but
the traceback could have been more informative.)

cheers,
vQ


From murdoch at stats.uwo.ca  Sun Mar 15 21:43:29 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 15 Mar 2009 16:43:29 -0400
Subject: [Rd] Definition of [[
In-Reply-To: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>
References: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>
Message-ID: <49BD6871.9070304@stats.uwo.ca>

On 15/03/2009 2:31 PM, Stavros Macrakis wrote:
> The semantics of [ and [[ don't seem to be fully specified in the
> Reference manual.  In particular, I can't find where the following
> cases are covered:
> 
>> cc <- c(1); ll <- list(1)
> 
>> cc[3]
> [1] NA
> OK, RefMan says: If i is positive and exceeds length(x) then the
> corresponding selection is NA.
> 
>> dput(ll[3])
> list(NULL)
> ? i is positive and exceeds length(x); why isn't this list(NA)?

Because the sentence you read was talking about "simple vectors", and ll 
is presumably not a simple vector.  So what is a simple vector?  That is 
not explicitly defined, and it probably should be.  I think it is 
"atomic vectors, except those with a class that has a method for [".

> 
>> ll[[3]]
> Error in list(1)[[3]] : subscript out of bounds
> ? Why does this return NA for an atomic vector, but give an error for
> a generic vector?
> 
>> cc[[3]] <- 34; dput(cc)
> c(1, NA, 34)
> OK
> 
> ll[[3]] <- 34; dput(ll)
> list(1, NULL, 34)
> Why is second element NULL, not NA?

NA is a length 1 atomic vector with a specific type matching the type of 
c.  It makes more sense in this context to put in a NULL, and return a 
list(NULL) for ll[3].

> And why is it OK to set an undefined ll[[3]], but not to get it?

Lots of code grows vectors by setting elements beyond the end of them, 
so whether or not that's a good idea, it's not likely to change.

I think an argument could be made that ll[[toobig]] should return NULL 
rather than trigger an error, but on the other hand, the current 
behaviour allows the programmer to choose:  if you are assuming that a 
particular element exists, use ll[[element]], and R will tell you when 
your assumption is wrong.  If you aren't sure, use ll[element] and 
you'll get NA or list(NULL) if the element isn't there.

> I assume that these are features, not bugs, but I can't find
> documentation for them.

There is more documentation in the man page for Extract, but I think it 
is incomplete.  The most complete documentation is of course the source 
code, but it may not answer the question of what's intentional and 
what's accidental.

Duncan Murdoch


From macrakis at alum.mit.edu  Sun Mar 15 22:30:07 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 15 Mar 2009 17:30:07 -0400
Subject: [Rd] Definition of [[
In-Reply-To: <49BD6871.9070304@stats.uwo.ca>
References: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>
	<49BD6871.9070304@stats.uwo.ca>
Message-ID: <8b356f880903151430x31d4165t6e54d99a0826c093@mail.gmail.com>

Duncan,

Thanks for the reply.

On Sun, Mar 15, 2009 at 4:43 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 15/03/2009 2:31 PM, Stavros Macrakis wrote:

>> dput(ll[3])
>> list(NULL)
>> ? i is positive and exceeds length(x); why isn't this list(NA)?
>
> Because the sentence you read was talking about "simple vectors", and ll is
> presumably not a simple vector. ?So what is a simple vector? ?That is not
> explicitly defined, and it probably should be. ?I think it is "atomic
> vectors, except those with a class that has a method for [".

The three subsections of 3.4 Indexing are 3.4.1 Indexing by vectors,
3.4.2 Indexing matrices and arrays, 3.4.3 Indexing other structures,
and 3.4.4 Subset assignment, so the context seems to be saying that
"simple vectors" are those which are not matrices or arrays, and those
("other structures") which do not overload [.

Even if the definition of 'simple vector' were clarified to cover only
atomic vectors, I still can't find any text specifying that list(3)[5]
=> lsit(NULL).

For that matter, it would leave the subscripting of important
built-ins such as factors and dates, etc. undefined. Obviously the
intuition is that vectors of factors or vectors of dates would do the
'same thing' as vectors of integers or of strings, but 3.4.3 doesn't
say what that thing is....

>>> ll[[3]]
>>
>> Error in list(1)[[3]] : subscript out of bounds
>> ? Why does this return NA for an atomic vector, but give an error for
>> a generic vector?
>>
>>> cc[[3]] <- 34; dput(cc)
>>
>> c(1, NA, 34)
>> OK
>>
>> ll[[3]] <- 34; dput(ll)
>> list(1, NULL, 34)
>> Why is second element NULL, not NA?
>
> NA is a length 1 atomic vector with a specific type matching the type of c.
> ?It makes more sense in this context to put in a NULL, and return a
> list(NULL) for ll[3].

Understood that that's the rationale, but where is it documented?

Also, if that's the rationale, it seems to say that NULL is the
equivalent of NA for list elements, but in fact NULL does not function
like NA:

> is.na(NULL)
logical(0)
Warning message:
In is.na(NULL) : is.na() applied to non-(list or vector) of type 'NULL'
> is.na(list(NULL))
[1] FALSE

Indeed, NA seems to both up-convert and down-convert nicely to other
forms of NA:

> dput(as.integer(as.logical(c(TRUE,NA,TRUE))))
c(1L, NA, 1L)
> dput(as.logical(as.integer(c(TRUE,NA,TRUE))))
c(TRUE, NA, TRUE)

and are not converted to NULL when converted to generic vector:

> dput(as.list(c(TRUE,NA,TRUE)))
list(TRUE, NA, TRUE)

and NA is preserved when downconverting:

> dput(as.logical(as.list(c(TRUE,NA,23))))
c(TRUE, NA, TRUE)

But if you try to downconvert NULL, you get an error

> dput(as.integer(list(NULL)))
Error in isS4(x) : (list) object cannot be coerced to type 'integer'

So I don't see why NULL is the right way to represent NA, especially
since NULL is a perfectly good list element, distinct from NA.

>> And why is it OK to set an undefined ll[[3]], but not to get it?
>
> Lots of code grows vectors by setting elements beyond the end of them, so
> whether or not that's a good idea, it's not likely to change.

I wasn't suggesting changing this.

> I think an argument could be made that ll[[toobig]] should return NULL
> rather than trigger an error, but on the other hand, the current behaviour
> allows the programmer to choose: ?if you are assuming that a particular
> element exists, use ll[[element]], and R will tell you when your assumption
> is wrong. ?If you aren't sure, use ll[element] and you'll get NA or
> list(NULL) if the element isn't there.

Yes, that could make sense, but why would it be true for ll[[toobig]]
but not cc[[toobig]]?

>> I assume that these are features, not bugs, but I can't find
>> documentation for them.

> There is more documentation in the man page for Extract, but I think it is
> incomplete.

Yes, I was looking at that man page, and I don't think it resolves any
of the above questions.

> The most complete documentation is of course the source code,
> but it may not answer the question of what's intentional and what's
> accidental.

Well, that's one issue.  But another is that there should be a
specification addressed to users, who should not have to understand
internals.

             -s


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Mar 15 22:44:06 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 15 Mar 2009 22:44:06 +0100
Subject: [Rd] Definition of [[
In-Reply-To: <8b356f880903151430x31d4165t6e54d99a0826c093@mail.gmail.com>
References: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>	<49BD6871.9070304@stats.uwo.ca>
	<8b356f880903151430x31d4165t6e54d99a0826c093@mail.gmail.com>
Message-ID: <49BD76A6.6090206@idi.ntnu.no>

Stavros Macrakis wrote:
>
> Well, that's one issue.  But another is that there should be a
> specification addressed to users, who should not have to understand
> internals.
>   

this should really be taken seriously.

vQ


From sarmad at um.ac.ir  Sun Mar 15 20:35:11 2009
From: sarmad at um.ac.ir (sarmad at um.ac.ir)
Date: Sun, 15 Mar 2009 20:35:11 +0100 (CET)
Subject: [Rd] miscomputation (PR#13594)
Message-ID: <20090315193511.B39E1282BE82@mail.pubhealth.ku.dk>

Full_Name: Majid Sarmad
Version: 2.8.1
OS: Linux / Windows
Submission from: (NULL) (194.225.128.135)


With thanks to Alberto Viglione, in HW.tests function of homtest package, there
is the following line 

V2 <- (sum(ni * ((ti - tauReg)^2 + (t3i - tau3Reg)^2))/sum(ni)   )^0.5


which is a mistyping and leads to a miscomputation. It must be

V2 <- sum(ni * ((ti - tauReg)^2 + (t3i - tau3Reg)^2)   ^0.5)   /sum(ni)


as it is in help file of the function:

V2 = sum[i from 1 to k] ni {(t^(i) - t^R)^2 + (t3^(i) - t3^R)^2}^(1/2) / sum[i
from 1 to k] ni


Similarly, in

V2s[i] <- (sum(ni * ((ti.sim - tauReg.sim)^2 + (t3i.sim - 
    tau3Reg.sim)^2))/sum(ni))^0.5


From dvdbooth at cs.com  Mon Mar 16 00:30:09 2009
From: dvdbooth at cs.com (dvdbooth at cs.com)
Date: Mon, 16 Mar 2009 00:30:09 +0100 (CET)
Subject: [Rd] Bug Report Fwd: MANOVA Data (PR#13595)
Message-ID: <20090315233009.B117E282C768@mail.pubhealth.ku.dk>


 Hi.? There appears to be a bug in R function manova.? My friend and I both ran it the same way as shown below (his run) with the shown data set. His results are shown below. we both got the same results.? I was running with R 2.3.1. I'm not sure what version he used.
Thanks very much,
David Booth
Kent State University


 


 

-----Original Message-----
From: dvdbooth at cs.com
To: kberk at ilstu.edu
Sent: Sun, 15 Mar 2009 7:01 pm
Subject: Re: MANOVA Data











 Ken,

Did you notice that Wilks, Roy, etc p-values are all the same?? Pillai is almost the SAS result.? Can't figure it out.? I'll submit a bug report. What's Velleman going to talk about?? Thanks for looking at the R.

Best,

Dave





 





 



-----Original Message-----

From: Ken Berk <kberk at ilstu.edu>

To: dvdbooth at cs.com

Sent: Sun, 15 Mar 2009 3:45 pm

Subject: Re: Fwd: MANOVA Data














At 08:07 PM 3/5/2009, you wrote:



Hi Ken,


I've run the attached data set ( a one way MANOVA ex. from the SAS manual
chapter on MANOVA) in both SAS and R and I don't get the same
results.? Do you have any suggestions about how I can find out
what's going on?


Thanks,


Dave







-----Original Message-----


From: dvdbooth at cs.com


To: DvdBooth at aol.com


Sent: Thu, 5 Mar 2009 5:06 pm


Subject: MANOVA Data










Email message sent from CompuServe - visit us today at
http://www.cs.com





Email message sent from CompuServe - visit us today at
http://www.cs.com








Hello, David




My R results are clearly crap, as shown below.




The degrees of freedom are clearly wrong, as is apparent when looking at
the univariate anovas.




SAS gives the correct answers.




I don't know what to do about R.




Ken







COUNT??? REWGRP??? COMMIT???
SATIS??? STAY


1????
1????????
16???????
19?????? 18


2????
1????????
18???????
15?????? 17


3????
1????????
18???????
14?????? 14


4????
1????????
16???????
20?????? 10


5????
1????????
15???????
13?????? 17


6????
1????????
12???????
15?????? 11


7????
2????????
16???????
20?????? 13


8????
2????????
18???????
14?????? 16


9????
2????????
13???????
10?????? 14


10??? 2????????
17???????
13?????? 19


11??? 2????????
14???????
18?????? 15


12??? 2????????
19???????
16?????? 18


13??? 3????????
20???????
18?????? 16


14??? 3????????
18???????
15?????? 19


15??? 3????????
13???????
14?????? 17


16??? 3????????
12???????
16?????? 15


17??? 3????????
16???????
17?????? 18


18??? 3????????
14???????
19?????? 15




> attach(booth)


> Y <- cbind(COMMIT, SATIS, STAY)


> fit <- manova(Y ~ REWGRP)


> summary(fit, test="Pillai")


????????? Df? Pillai
approx F num Df den Df Pr(>F)


REWGRP???? 1 0.22731?
1.37283????? 3???? 14
0.2918


Residuals
16?????????????????????????????????????



> summary(fit, test="Wilks")


????????? Df??
Wilks approx F num Df den Df Pr(>F)


REWGRP???? 1 0.77269?
1.37283????? 3???? 14
0.2918


Residuals
16?????????????????????????????????????



> summary(fit, test="Hotelling-Lawley")


????????? Df
Hotelling-Lawley approx F num Df den Df Pr(>F)


REWGRP????
1????????? 0.29418?
1.37283????? 3???? 14
0.2918


Residuals
16??????????????????????????????????????????????



> summary(fit, test="Roy")


?????????
Df???? Roy approx F num Df den Df Pr(>F)


REWGRP???? 1 0.29418?
1.37283????? 3???? 14
0.2918


Residuals
16?????????????????????????????????????



> summary(fit)


????????? Df? Pillai
approx F num Df den Df Pr(>F)


REWGRP???? 1 0.22731?
1.37283????? 3???? 14
0.2918


Residuals
16?????????????????????????????????????



> summary.aov(fit)


?Response COMMIT :


???????????
Df? Sum Sq Mean Sq F value Pr(>F)


REWGRP?????? 1??
0.333?? 0.333? 0.0532 0.8204


Residuals?? 16 100.167??
6.260??????????????





?Response SATIS :


???????????
Df? Sum Sq Mean Sq F value Pr(>F)


REWGRP?????? 1??
0.750?? 0.750? 0.0945 0.7625


Residuals?? 16 127.028??
7.939??????????????





?Response STAY :


??????????? Df Sum
Sq Mean Sq F value Pr(>F)


REWGRP?????? 1 14.083? 14.083?
2.3013 0.1488


Residuals?? 16 97.917??
6.120??????????????





> 




 






Email message sent from CompuServe - visit us today at http://www.cs.com





 

________________________________________________________________________
Email message sent from CompuServe - visit us today at http://www.cs.com

	[[alternative HTML version deleted]]


From murdoch at stats.uwo.ca  Mon Mar 16 00:46:45 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 15 Mar 2009 19:46:45 -0400
Subject: [Rd] Definition of [[
In-Reply-To: <8b356f880903151430x31d4165t6e54d99a0826c093@mail.gmail.com>
References: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>	
	<49BD6871.9070304@stats.uwo.ca>
	<8b356f880903151430x31d4165t6e54d99a0826c093@mail.gmail.com>
Message-ID: <49BD9365.9000909@stats.uwo.ca>

Just a couple of inline comments down below:

On 15/03/2009 5:30 PM, Stavros Macrakis wrote:
> Duncan,
> 
> Thanks for the reply.
> 
> On Sun, Mar 15, 2009 at 4:43 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 15/03/2009 2:31 PM, Stavros Macrakis wrote:
> 
>>> dput(ll[3])
>>> list(NULL)
>>> ? i is positive and exceeds length(x); why isn't this list(NA)?
>> Because the sentence you read was talking about "simple vectors", and ll is
>> presumably not a simple vector.  So what is a simple vector?  That is not
>> explicitly defined, and it probably should be.  I think it is "atomic
>> vectors, except those with a class that has a method for [".
> 
> The three subsections of 3.4 Indexing are 3.4.1 Indexing by vectors,
> 3.4.2 Indexing matrices and arrays, 3.4.3 Indexing other structures,
> and 3.4.4 Subset assignment, so the context seems to be saying that
> "simple vectors" are those which are not matrices or arrays, and those
> ("other structures") which do not overload [.
> 
> Even if the definition of 'simple vector' were clarified to cover only
> atomic vectors, I still can't find any text specifying that list(3)[5]
> => lsit(NULL).
> 
> For that matter, it would leave the subscripting of important
> built-ins such as factors and dates, etc. undefined. Obviously the
> intuition is that vectors of factors or vectors of dates would do the
> 'same thing' as vectors of integers or of strings, but 3.4.3 doesn't
> say what that thing is....
> 
>>>> ll[[3]]
>>> Error in list(1)[[3]] : subscript out of bounds
>>> ? Why does this return NA for an atomic vector, but give an error for
>>> a generic vector?
>>>
>>>> cc[[3]] <- 34; dput(cc)
>>> c(1, NA, 34)
>>> OK
>>>
>>> ll[[3]] <- 34; dput(ll)
>>> list(1, NULL, 34)
>>> Why is second element NULL, not NA?
>> NA is a length 1 atomic vector with a specific type matching the type of c.
>>  It makes more sense in this context to put in a NULL, and return a
>> list(NULL) for ll[3].
> 
> Understood that that's the rationale, but where is it documented?
> 
> Also, if that's the rationale, it seems to say that NULL is the
> equivalent of NA for list elements, but in fact NULL does not function
> like NA:
> 
>> is.na(NULL)
> logical(0)
> Warning message:
> In is.na(NULL) : is.na() applied to non-(list or vector) of type 'NULL'
>> is.na(list(NULL))
> [1] FALSE
> 
> Indeed, NA seems to both up-convert and down-convert nicely to other
> forms of NA:
> 
>> dput(as.integer(as.logical(c(TRUE,NA,TRUE))))
> c(1L, NA, 1L)
>> dput(as.logical(as.integer(c(TRUE,NA,TRUE))))
> c(TRUE, NA, TRUE)
> 
> and are not converted to NULL when converted to generic vector:
> 
>> dput(as.list(c(TRUE,NA,TRUE)))
> list(TRUE, NA, TRUE)
> 
> and NA is preserved when downconverting:
> 
>> dput(as.logical(as.list(c(TRUE,NA,23))))
> c(TRUE, NA, TRUE)
> 
> But if you try to downconvert NULL, you get an error
> 
>> dput(as.integer(list(NULL)))
> Error in isS4(x) : (list) object cannot be coerced to type 'integer'
> 
> So I don't see why NULL is the right way to represent NA, especially
> since NULL is a perfectly good list element, distinct from NA.
> 
>>> And why is it OK to set an undefined ll[[3]], but not to get it?
>> Lots of code grows vectors by setting elements beyond the end of them, so
>> whether or not that's a good idea, it's not likely to change.
> 
> I wasn't suggesting changing this.
> 
>> I think an argument could be made that ll[[toobig]] should return NULL
>> rather than trigger an error, but on the other hand, the current behaviour
>> allows the programmer to choose:  if you are assuming that a particular
>> element exists, use ll[[element]], and R will tell you when your assumption
>> is wrong.  If you aren't sure, use ll[element] and you'll get NA or
>> list(NULL) if the element isn't there.
> 
> Yes, that could make sense, but why would it be true for ll[[toobig]]
> but not cc[[toobig]]?

But it is:

 > cc <- c(1)
 > cc[[3]]
Error in cc[[3]] : subscript out of bounds

>>> I assume that these are features, not bugs, but I can't find
>>> documentation for them.
> 
>> There is more documentation in the man page for Extract, but I think it is
>> incomplete.
> 
> Yes, I was looking at that man page, and I don't think it resolves any
> of the above questions.
> 
>> The most complete documentation is of course the source code,
>> but it may not answer the question of what's intentional and what's
>> accidental.
> 
> Well, that's one issue.  But another is that there should be a
> specification addressed to users, who should not have to understand
> internals.

I agree, but not so strongly that I will drop everything and write one.

Duncan Murdoch


From rpeng at jhsph.edu  Mon Mar 16 01:45:56 2009
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Sun, 15 Mar 2009 20:45:56 -0400
Subject: [Rd] Using and 'eval' and environments with active bindings
Message-ID: <66f3bd910903151745k42407ec4xb4771fa3e7ef4ac2@mail.gmail.com>

The following code produces an error in current R-devel

f <- function(value) {
        if(!missing(value))
                100
        else
                2
}
e <- new.env()
makeActiveBinding("x", f, e)
eval(substitute(list(x)), e)

The error, after calling 'eval' is

Error in eval(expr, envir, enclos) :
  element 1 is empty;
   the part of the args list of 'list' being evaluated was:
   (x)


It has something to do with the change in R_isMissing in revision
r48118 but I'm not quite knowledgeable enough to understand what the
problem is. In R 2.8.1 the result was simply


> eval(substitute(list(x)), e)
[[1]]
[1] 2

I can't say I know what the output should be but I'd like some
clarification on whether this is a bug.

Thanks,
-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From edd at debian.org  Mon Mar 16 02:01:29 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 15 Mar 2009 20:01:29 -0500
Subject: [Rd] [OT] Debian now has a new section 'gnu-r'
Message-ID: <18877.42217.17405.788669@ron.nulle.part>


Joerg Jaspert, one of the ftpmasters / archive maintainers within Debian,
today posted a new list of 'Sections' to debian-devel-announce (see eg here
http://www.nabble.com/forum/ViewPost.jtp?post=22524830&framed=y )

This now includes a new Section: 

   gnu-r                    Everything about GNU R, a statistical computation and
                            graphics system 

which gives R just about the same footing Perl and Python had -- a new
section in the archive (and Ruby, Java, Haskell, OcaML, Php got the same
treatment). I think none of the 'R-within-Debian' maintainers saw this
coming.   For the record, the current list of R packages within Debian is
included below.

Cheers, Dirk


r-base-dev			gnu-r
r-base-core			gnu-r
r-base-core-ra			gnu-r
r-base				gnu-r			
r-cran-abind			gnu-r
r-cran-acepack			gnu-r
r-cran-adapt			gnu-r
r-cran-bayesm			gnu-r
r-cran-bitops			gnu-r
r-cran-boot			gnu-r
r-cran-cairodevice		gnu-r
r-cran-car			gnu-r
r-cran-catools			gnu-r
r-cran-chron			gnu-r
r-cran-cluster			gnu-r
r-cran-coda			gnu-r
r-cran-codetools		gnu-r
r-cran-combinat			gnu-r
r-cran-date			gnu-r
r-cran-dbi			gnu-r
r-cran-design			gnu-r
r-cran-eco			gnu-r
r-cran-effects			gnu-r
r-cran-farma			gnu-r
r-cran-fasianoptions		gnu-r
r-cran-fassets			gnu-r
r-cran-fbasics			gnu-r
r-cran-fbonds			gnu-r
r-cran-fcalendar		gnu-r
r-cran-fcopulae			gnu-r
r-cran-fecofin			gnu-r
r-cran-fexoticoptions		gnu-r
r-cran-fextremes		gnu-r
r-cran-fgarch			gnu-r
r-cran-fimport			gnu-r
r-cran-fmultivar		gnu-r
r-cran-fnonlinear		gnu-r
r-cran-foptions			gnu-r
r-cran-foreign			gnu-r
r-cran-fportfolio		gnu-r
r-cran-fregression		gnu-r
r-cran-fseries			gnu-r
r-cran-ftrading			gnu-r
r-cran-funitroots		gnu-r
r-cran-futilities		gnu-r
r-cran-gdata			gnu-r
r-cran-getopt			gnu-r
r-cran-gmaps			gnu-r
r-cran-gmodels			gnu-r
r-cran-gplots			gnu-r
r-cran-gregmisc			gnu-r
r-cran-gtools			gnu-r
r-cran-hdf5			gnu-r
r-cran-hmisc			gnu-r
r-cran-its			gnu-r
r-cran-jit			gnu-r
r-cran-kernsmooth		gnu-r
r-cran-latticeextra		gnu-r
r-cran-lattice			gnu-r
r-cran-lme4			gnu-r
r-cran-lmtest			gnu-r
r-cran-lpsolve			gnu-r
r-cran-mapdata			gnu-r
r-cran-maps			gnu-r
r-cran-matchit			gnu-r
r-cran-matrix			gnu-r
r-cran-mcmcpack			gnu-r
r-cran-mgcv			gnu-r
r-cran-misc3d			gnu-r
r-cran-mnormt			gnu-r
r-cran-mnp			gnu-r
r-cran-multcomp			gnu-r
r-cran-mvtnorm			gnu-r
r-cran-nlme			gnu-r
r-cran-nws			gnu-r
r-cran-plotrix			gnu-r
r-cran-polspline		gnu-r
r-cran-pscl			gnu-r
r-cran-psy			gnu-r
r-cran-qtl			gnu-r
r-cran-quadprog			gnu-r
r-cran-rcmdr			gnu-r
r-cran-rcolorbrewer		gnu-r
r-cran-rcpp			gnu-r
r-cran-relimp			gnu-r
r-cran-rggobi			gnu-r
r-cran-rgl			gnu-r
r-cran-rglpk			gnu-r
r-cran-rgtk2			gnu-r
r-cran-rjava			gnu-r
r-cran-rmetrics			gnu-r
r-cran-rmpi			gnu-r
r-cran-rmysql			gnu-r
r-cran-robustbase		gnu-r
r-cran-rocr			gnu-r
r-cran-rodbc			gnu-r
r-cran-rpart			gnu-r
r-cran-rpvm			gnu-r
r-cran-rquantlib		gnu-r
r-cran-rserve			gnu-r
r-cran-rsprng			gnu-r
r-cran-runit			gnu-r
r-cran-sandwich			gnu-r
r-cran-sm			gnu-r
r-cran-sn			gnu-r
r-cran-snow			gnu-r
r-cran-strucchange		gnu-r
r-cran-survival			gnu-r
r-cran-timedate			gnu-r
r-cran-timeseries		gnu-r
r-cran-tkrplot			gnu-r
r-cran-tseries			gnu-r
r-cran-urca			gnu-r
r-cran-vgam			gnu-r
r-cran-vr			gnu-r
r-cran-xml			gnu-r
r-cran-zelig			gnu-r
r-cran-zoo			gnu-r
r-mathlib			gnu-r
r-noncran-lindsey		gnu-r
r-other-gking-matchit		gnu-r
r-recommended			gnu-r
r-cran-colorspace		gnu-r
r-cran-epibasix			gnu-r
r-cran-epitools			gnu-r
r-cran-genetics			gnu-r
r-cran-haplo.stats		gnu-r
r-cran-qvalue			gnu-r
r-cran-randomforest		gnu-r
r-cran-sp			gnu-r
r-cran-xtable			gnu-r
r-other-bio3d			gnu-r



-- 
Three out of two people have difficulties with fractions.


From berwin at maths.uwa.edu.au  Mon Mar 16 03:26:25 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 16 Mar 2009 10:26:25 +0800
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BD5E9D.1030601@idi.ntnu.no>
References: <49B67CB1.8060005@idi.ntnu.no> <49B682F9.8050307@biostat.ku.dk>
	<49B6E6D9.7010809@idi.ntnu.no>
	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>
	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>
	<49B81186.4070107@idi.ntnu.no>
	<20090312154008.56706f38@berwin-nus1>
	<49B8D060.8090206@idi.ntnu.no>
	<20090312173231.7a2929df@berwin-nus1>
	<49B8DB8F.5030704@idi.ntnu.no> <20090312213508.719afa73@berwin5>
	<49B91A7E.50107@idi.ntnu.no> <20090312231240.6a061f0b@berwin5>
	<49B96FE7.2060705@idi.ntnu.no>
	<20090313120309.7acb13e5@berwin-nus1>
	<49BA38EB.3000004@idi.ntnu.no> <20090313234755.6f6e08c9@berwin5>
	<49BD5E9D.1030601@idi.ntnu.no>
Message-ID: <20090316102625.1d93ded4@berwin-nus1>

G'day Wacek,

On Sun, 15 Mar 2009 21:01:33 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:
> >
> > Obviously, assuming that R really executes 
> > 	*tmp* <- x
> > 	x <- "names<-"('*tmp*', value=c("a","b"))
> > under the hood, in the C code, then *tmp* does not end up in the
> > symbol table and does not persist beyond the execution of 
> > 	names(x) <- c("a","b")
> >
> >   
> 
> to prove that i take you seriously, i have peeked into the code, and
> found that indeed there is a temporary binding for *tmp* made behind
> the scenes -- sort of. unfortunately, it is not done carefully enough
> to avoid possible interference with the user's code:
> 
> '*tmp*' = 0
> `*tmp*`
> # 0
> 
> x = 1
> names(x) = 'foo'
> `*tmp*`
> # error: object "*tmp*" not found
> 
> `*ugly*`

I agree, and I am a bit flabbergasted.  I had not expected that
something like this would happen and I am indeed not aware of anything
in the documentation that warns about this; but others may prove me
wrong on this.

> given that `*tmp*`is a perfectly legal (though some would say
> 'non-standard') name, it would be good if somewhere here a warning
> were issued -- perhaps where i assign to `*tmp*`, because `*tmp*` is
> not just any non-standard name, but one that is 'obviously' used
> under the hood to perform black magic.

Now I wonder whether there are any other objects (with non-standard)
names) that can be nuked by operations performed under the hood.  

I guess the best thing is to stay away from non-standard names, if only
to save the typing of back-ticks. :)

Thanks for letting me know, I have learned something new today.

Cheers,

	Berwin


From tlumley at u.washington.edu  Mon Mar 16 09:06:34 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 16 Mar 2009 01:06:34 -0700 (PDT)
Subject: [Rd] Definition of [[
In-Reply-To: <8b356f880903151131j53765d2fo5aaa8a84dc971817@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0903160106340.14839@hymn33.u.washington.edu>

On Sun, 15 Mar 2009, Stavros Macrakis wrote:

> The semantics of [ and [[ don't seem to be fully specified in the
> Reference manual.  In particular, I can't find where the following
> cases are covered:
>
>> cc <- c(1); ll <- list(1)
>
>> cc[3]
> [1] NA
> OK, RefMan says: If i is positive and exceeds length(x) then the
> corresponding selection is NA.
>
>> dput(ll[3])
> list(NULL)
> ? i is positive and exceeds length(x); why isn't this list(NA)?

I think some of these are because there are only NAs for character, logical, and the numeric types. There isn't an NA of list type.

This one shouldn't be list(NA) - which NA would it use?  It should be some sort of list(_NA_list_) type, and list(NULL) is playing that role.


>> ll[[3]]
> Error in list(1)[[3]] : subscript out of bounds
> ? Why does this return NA for an atomic vector, but give an error for
> a generic vector?

Again, because there isn't an NA of generic vector type.

>> cc[[3]] <- 34; dput(cc)
> c(1, NA, 34)
> OK
>
> ll[[3]] <- 34; dput(ll)
> list(1, NULL, 34)
> Why is second element NULL, not NA?
> And why is it OK to set an undefined ll[[3]], but not to get it?

Same reason for NULL vs NA.  The fact that setting works may just be an inconsistency -- as you can see from previous discussions, R often does not effectively forbid code that shouldn't work -- or it may be bug-compatibility with some version of S or S-PLUS.


      -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Mon Mar 16 09:10:33 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 16 Mar 2009 01:10:33 -0700 (PDT)
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <49BD5E9D.1030601@idi.ntnu.no>
Message-ID: <Pine.LNX.4.43.0903160110330.14839@hymn33.u.washington.edu>


Wacek,

In this case I think the *tmp* dates from the days before backticks, when it was not a legal name (it still isn't) and it was much, much harder to use illegal names, so the collision issue really didn't exist.

You're right about the documentation.

       -thomas


On Sun, 15 Mar 2009, Wacek Kusnierczyk wrote:

> Berwin A Turlach wrote:
>>
>> Obviously, assuming that R really executes
>> 	*tmp* <- x
>> 	x <- "names<-"('*tmp*', value=c("a","b"))
>> under the hood, in the C code, then *tmp* does not end up in the symbol
>> table and does not persist beyond the execution of
>> 	names(x) <- c("a","b")
>
> to prove that i take you seriously, i have peeked into the code, and
> found that indeed there is a temporary binding for *tmp* made behind the
> scenes -- sort of. unfortunately, it is not done carefully enough to
> avoid possible interference with the user's code:
>
> '*tmp*' = 0
> `*tmp*`
> # 0
>
> x = 1
> names(x) = 'foo'
> `*tmp*`
> # error: object "*tmp*" not found
>
> `*ugly*`
>
> given that `*tmp*`is a perfectly legal (though some would say
> 'non-standard') name, it would be good if somewhere here a warning were
> issued -- perhaps where i assign to `*tmp*`, because `*tmp*` is not just
> any non-standard name, but one that is 'obviously' used under the hood
> to perform black magic.
>
> it also appears that the explanation given in, e.g., the r language
> definition (draft, of course) sec. 3.4.4:
>
> "
> Assignment to subsets of a structure is a special case of a general
> mechanism for complex
> assignment:
> x[3:5] <- 13:15
> The result of this commands is as if the following had been executed
> ?*tmp*? <- x
> x <- "[<-"(?*tmp*?, 3:5, value=13:15)
> "
>
> is incomplete (because the final result is not '*tmp*' having the value
> of x, as it might seem, but rather '*tmp*' having been unbound).
>
> so the suggestion for the documenters is to add to the end of the
> section (or wherever else it is appropriate) a warning to the effect
> that in the end '*tmp*' will be removed, even if the user has explicitly
> defined it earlier in the same scope.
>
> or maybe have the implementation not rely on a user-forgeable name? for
> example, the '.Last.value' name is automatically bound to the most
> recently returned value, but it resides in package:base and does not
> collide with bindings using it made by the user:
>
> .Last.value = 0
>
> 1
> .Last.value
> # 0, not 1
>
> 1
> base::.Last.value
> # 1, not 0
>
>
> why could not '*tmp*' be bound and unbound outside of the user's
> namespace? (i guess it's easier to update the docs -- or just ignore the
> issue.)
>
>
> on the margin, traceback('<-') will pick only one of the uses of '<-'
> suggested by the code above:
>
> x <- 1:10
>
> trace('<-')
> x[3:5] <- 13:15
> # trace: x[3:5] <- 13:15
> # trace: x <- `[<-`(`*tmp*`, 3:5, value = 13:15)
>
> which is somewhat confusing, because then '*tmp*' appears in the trace
> somewhat ex machina. (again, the explanation is in the source code, but
> the traceback could have been more informative.)
>
> cheers,
> vQ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 16 09:16:34 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 16 Mar 2009 09:16:34 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <20090316102625.1d93ded4@berwin-nus1>
References: <49B67CB1.8060005@idi.ntnu.no>	<49B682F9.8050307@biostat.ku.dk>	<49B6E6D9.7010809@idi.ntnu.no>	<96A4BB14-D6EA-44B1-B524-6DB139F3A7F8@r-project.org>	<8CCAAAD3-919F-462F-A616-F4FDDB46D975@r-project.org>	<49B81186.4070107@idi.ntnu.no>	<20090312154008.56706f38@berwin-nus1>	<49B8D060.8090206@idi.ntnu.no>	<20090312173231.7a2929df@berwin-nus1>	<49B8DB8F.5030704@idi.ntnu.no>	<20090312213508.719afa73@berwin5>	<49B91A7E.50107@idi.ntnu.no>	<20090312231240.6a061f0b@berwin5>	<49B96FE7.2060705@idi.ntnu.no>	<20090313120309.7acb13e5@berwin-nus1>	<49BA38EB.3000004@idi.ntnu.no>	<20090313234755.6f6e08c9@berwin5>	<49BD5E9D.1030601@idi.ntnu.no>
	<20090316102625.1d93ded4@berwin-nus1>
Message-ID: <49BE0AE2.1020909@idi.ntnu.no>

Berwin A Turlach wrote:
>
>> '*tmp*' = 0
>> `*tmp*`
>> # 0
>>
>> x = 1
>> names(x) = 'foo'
>> `*tmp*`
>> # error: object "*tmp*" not found
>>
>> `*ugly*`
>>     
>
> I agree, and I am a bit flabbergasted.  I had not expected that
> something like this would happen and I am indeed not aware of anything
> in the documentation that warns about this; but others may prove me
> wrong on this.
>   

hopefully.

>   
>> given that `*tmp*`is a perfectly legal (though some would say
>> 'non-standard') name, it would be good if somewhere here a warning
>> were issued -- perhaps where i assign to `*tmp*`, because `*tmp*` is
>> not just any non-standard name, but one that is 'obviously' used
>> under the hood to perform black magic.
>>     
>
> Now I wonder whether there are any other objects (with non-standard)
> names) that can be nuked by operations performed under the hood.  
>   

any such risk should be clearly documented, if not with a warning issued
each time the user risks h{is,er} workspace corrupted by the under-the-hood.


> I guess the best thing is to stay away from non-standard names, if only
> to save the typing of back-ticks. :)
>   

agree.  but then, there may be -- and probably are -- other such 'best
to stay away' things in r, all of which should be documented so that a
user know what may happen on the surface, *without* having to peek under
the hood.


> Thanks for letting me know, I have learned something new today.
>   

wow.  most of my fiercely truculent ranting is meant to point out things
that may not be intentional, or if they are, they seem to me design
flaws rather than features -- so that either i learn that i am ignorant
or wrong, or someone else does, pro bono.  hopefully.

vQ


From tlumley at u.washington.edu  Mon Mar 16 09:26:27 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 16 Mar 2009 01:26:27 -0700 (PDT)
Subject: [Rd] Definition of [[
In-Reply-To: <49BD76A6.6090206@idi.ntnu.no>
Message-ID: <Pine.LNX.4.43.0903160126270.14839@hymn33.u.washington.edu>

On Sun, 15 Mar 2009, Wacek Kusnierczyk wrote:

> Stavros Macrakis wrote:
>>
>> Well, that's one issue.  But another is that there should be a
>> specification addressed to users, who should not have to understand
>> internals.
>>
>
> this should really be taken seriously.
>

Well, the lack of such a specification is a documented bug (see the FAQ on bug reporting), and I think everyone agrees it would be useful, just not as useful as what they would have to stop doing to write it.  In fact, such a document may well have a higher priority than it deserves: people who would want that sort of documentation are overrepresented in R-core compared to the general R user community.

There was a panel talk at DSC2005 (yes, four years ago) on the possibilities for a joint R/S language standard. That would have provided an external stimulus and a framework for finding all the inconsistencies. It didn't really eventuate.

      -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 16 09:28:39 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 16 Mar 2009 09:28:39 +0100
Subject: [Rd] Definition of [[
In-Reply-To: <Pine.LNX.4.43.0903160106340.14839@hymn33.u.washington.edu>
References: <Pine.LNX.4.43.0903160106340.14839@hymn33.u.washington.edu>
Message-ID: <49BE0DB7.4020705@idi.ntnu.no>

somewhat one the side,

    l = list(1)
   
    l[[2]]
    # error, index out of bounds

    l[2][[1]]
    # NULL

that is, we can't extract from l any element at an index exceeding the
list's length (if we could, it would have been NULL or some sort of
_NA_list), but we can extract a sublist at an index out of bounds, and
from that sublist extract the element (which is NULL, 'the _NA_list').

that's not necessarily wrong, but "the item at index i" (l[[i]]) is not
equivalent to "the item in the sublist at index i".

vQ



Thomas Lumley wrote:
> On Sun, 15 Mar 2009, Stavros Macrakis wrote:
>
>> The semantics of [ and [[ don't seem to be fully specified in the
>> Reference manual.  In particular, I can't find where the following
>> cases are covered:
>>
>>> cc <- c(1); ll <- list(1)
>>
>>> cc[3]
>> [1] NA
>> OK, RefMan says: If i is positive and exceeds length(x) then the
>> corresponding selection is NA.
>>
>>> dput(ll[3])
>> list(NULL)
>> ? i is positive and exceeds length(x); why isn't this list(NA)?
>
> I think some of these are because there are only NAs for character,
> logical, and the numeric types. There isn't an NA of list type.
>
> This one shouldn't be list(NA) - which NA would it use?  It should be
> some sort of list(_NA_list_) type, and list(NULL) is playing that role.
>
>
>>> ll[[3]]
>> Error in list(1)[[3]] : subscript out of bounds
>> ? Why does this return NA for an atomic vector, but give an error for
>> a generic vector?
>
> Again, because there isn't an NA of generic vector type.
>
>>> cc[[3]] <- 34; dput(cc)
>> c(1, NA, 34)
>> OK
>>
>> ll[[3]] <- 34; dput(ll)
>> list(1, NULL, 34)
>> Why is second element NULL, not NA?
>> And why is it OK to set an undefined ll[[3]], but not to get it?
>
> Same reason for NULL vs NA.  The fact that setting works may just be
> an inconsistency -- as you can see from previous discussions, R often
> does not effectively forbid code that shouldn't work -- or it may be
> bug-compatibility with some version of S or S-PLUS.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 16 09:29:49 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 16 Mar 2009 09:29:49 +0100
Subject: [Rd] surprising behaviour of names<-
In-Reply-To: <Pine.LNX.4.43.0903160110330.14839@hymn33.u.washington.edu>
References: <Pine.LNX.4.43.0903160110330.14839@hymn33.u.washington.edu>
Message-ID: <49BE0DFD.8040305@idi.ntnu.no>

Thomas Lumley wrote:
>
> Wacek,
>
> In this case I think the *tmp* dates from the days before backticks,
> when it was not a legal name (it still isn't) and it was much, much
> harder to use illegal names, so the collision issue really didn't exist.
>

thanks for the explanation.

> You're right about the documentation.
>


thanks for the acknowledgement.

vQ


From tlumley at u.washington.edu  Mon Mar 16 09:28:28 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 16 Mar 2009 01:28:28 -0700 (PDT)
Subject: [Rd] miscomputation (PR#13594)
In-Reply-To: <20090315193511.B39E1282BE82@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0903160128280.14839@hymn33.u.washington.edu>


Please report bugs in packages to the package maintainer, NOT to r-bugs.

       -thomas

On Sun, 15 Mar 2009 sarmad at um.ac.ir wrote:

> Full_Name: Majid Sarmad
> Version: 2.8.1
> OS: Linux / Windows
> Submission from: (NULL) (194.225.128.135)
>
>
> With thanks to Alberto Viglione, in HW.tests function of homtest package, there
> is the following line
>
> V2 <- (sum(ni * ((ti - tauReg)^2 + (t3i - tau3Reg)^2))/sum(ni)   )^0.5
>
>
> which is a mistyping and leads to a miscomputation. It must be
>
> V2 <- sum(ni * ((ti - tauReg)^2 + (t3i - tau3Reg)^2)   ^0.5)   /sum(ni)
>
>
> as it is in help file of the function:
>
> V2 = sum[i from 1 to k] ni {(t^(i) - t^R)^2 + (t3^(i) - t3^R)^2}^(1/2) / sum[i
> from 1 to k] ni
>
>
> Similarly, in
>
> V2s[i] <- (sum(ni * ((ti.sim - tauReg.sim)^2 + (t3i.sim -
>    tau3Reg.sim)^2))/sum(ni))^0.5
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Mon Mar 16 09:59:58 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 16 Mar 2009 01:59:58 -0700 (PDT)
Subject: [Rd] Bug Report Fwd: MANOVA Data (PR#13595)
In-Reply-To: <20090315233009.B117E282C768@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0903160159580.14839@hymn33.u.washington.edu>


David,

2.3.1 is a bit old to be reporting bugs -- we do ask people to check that their problem is still present in a contemporary version of R. However, your data do still give the same output in R 2.7.2 (which is not current, but was current less than a year ago).

I've tidied up the code to remove all the weird characters:

booth<-read.table(tmp<-textConnection("COUNT REWGRP COMMIT SATIS STAY
1 1 16 19 18
2 1 18 15 17
3 1 18 14 14
4 1 16 20 10
5 1 15 13 17
6 1 12 15 11
7 2 16 20 13
8 2 18 14 16
9 2 13 10 14
10 2 17 13 19
11 2 14 18 15
12 2 19 16 18
13 3 20 18 16
14 3 18 15 19
15 3 13 14 17
16 3 12 16 15
17 3 16 17 18
18 3 14 19 15
"),header=TRUE)

fit<-manova(cbind(COMMIT,SATIS,STAY)~REWGRP,data=booth)


Now, as to the question of whether this is a bug.  You don't give the SAS answers that you are happy with, just the R answers. This makes it a lot more difficult.

It's possible that there is a bug in manova(), but another possibility, since you are concerned about degrees of freedom, and based on the last three letters of the name of your predictor variable, is that you wanted

> fit2<-manova(cbind(COMMIT,SATIS,STAY)~factor(REWGRP),data=booth)
> summary(fit2, test="Pillai")
                Df  Pillai approx F num Df den Df Pr(>F)
factor(REWGRP)  2 0.28342  0.77049      6     28 0.5995
Residuals      15                                      
> summary(fit2, test="Roy")
                Df     Roy approx F num Df den Df Pr(>F)
factor(REWGRP)  2 0.31963  1.49159      3     14 0.2599
Residuals      15                                      
> summary(fit2, test="Hotelling")
                Df Hotelling-Lawley approx F num Df den Df Pr(>F)
factor(REWGRP)  2          0.36261  0.72521      6     24 0.6336
Residuals      15



Googling for the variable names and SAS, MANOVA found some programs in which REWGRP was specified as a CLASS variable, ie, a factor.

Also

http://my.safaribooksonline.com/9781590474174/ch11lev1sec3

has what might be the output of this code.  The test statistics all match the ones in R, but the p-values are slightly different except for Wilks' lambda.

So, it looks as though at least you need to specify that the variable is a factor.  I will have to leave the question of whether the p-values are correct to someone with more knowledge of MANOVA.  It does seem from the documentation that agreement with SAS is intended at least for the Pillai trace and Roy's largest root.

We do appreciate bug reports, but it shouldn't be necessary to do all this work to find out what you think the correct answer is.

       -thomas


On Mon, 16 Mar 2009 dvdbooth at cs.com wrote:

>
> Hi.? There appears to be a bug in R function manova.? My friend and I both ran it the same way as shown below (his run) with the shown data set. His results are shown below. we both got the same results.? I was running with R 2.3.1. I'm not sure what version he used.
> Thanks very much,
> David Booth
> Kent State University
>
>
>
>
>
>
>
> -----Original Message-----
> From: dvdbooth at cs.com
> To: kberk at ilstu.edu
> Sent: Sun, 15 Mar 2009 7:01 pm
> Subject: Re: MANOVA Data
>
>
>
>
>
>
>
>
>
>
>
> Ken,
>
> Did you notice that Wilks, Roy, etc p-values are all the same?? Pillai is almost the SAS result.? Can't figure it out.? I'll submit a bug report. What's Velleman going to talk about?? Thanks for looking at the R.
>
> Best,
>
> Dave
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> -----Original Message-----
>
> From: Ken Berk <kberk at ilstu.edu>
>
> To: dvdbooth at cs.com
>
> Sent: Sun, 15 Mar 2009 3:45 pm
>
> Subject: Re: Fwd: MANOVA Data
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> At 08:07 PM 3/5/2009, you wrote:
>
>
>
> Hi Ken,
>
>
> I've run the attached data set ( a one way MANOVA ex. from the SAS manual
> chapter on MANOVA) in both SAS and R and I don't get the same
> results.? Do you have any suggestions about how I can find out
> what's going on?
>
>
> Thanks,
>
>
> Dave
>
>
>
>
>
>
>
> -----Original Message-----
>
>
> From: dvdbooth at cs.com
>
>
> To: DvdBooth at aol.com
>
>
> Sent: Thu, 5 Mar 2009 5:06 pm
>
>
> Subject: MANOVA Data
>
>
>
>
>
>
>
>
>
>
> Email message sent from CompuServe - visit us today at
> http://www.cs.com
>
>
>
>
>
> Email message sent from CompuServe - visit us today at
> http://www.cs.com
>
>
>
>
>
>
>
>
> Hello, David
>
>
>
>
> My R results are clearly crap, as shown below.
>
>
>
>
> The degrees of freedom are clearly wrong, as is apparent when looking at
> the univariate anovas.
>
>
>
>
> SAS gives the correct answers.
>
>
>
>
> I don't know what to do about R.
>
>
>
>
> Ken
>
>
>
>
>
>
>
> COUNT??? REWGRP??? COMMIT???
> SATIS??? STAY
>
>
> 1????
> 1????????
> 16???????
> 19?????? 18
>
>
> 2????
> 1????????
> 18???????
> 15?????? 17
>
>
> 3????
> 1????????
> 18???????
> 14?????? 14
>
>
> 4????
> 1????????
> 16???????
> 20?????? 10
>
>
> 5????
> 1????????
> 15???????
> 13?????? 17
>
>
> 6????
> 1????????
> 12???????
> 15?????? 11
>
>
> 7????
> 2????????
> 16???????
> 20?????? 13
>
>
> 8????
> 2????????
> 18???????
> 14?????? 16
>
>
> 9????
> 2????????
> 13???????
> 10?????? 14
>
>
> 10??? 2????????
> 17???????
> 13?????? 19
>
>
> 11??? 2????????
> 14???????
> 18?????? 15
>
>
> 12??? 2????????
> 19???????
> 16?????? 18
>
>
> 13??? 3????????
> 20???????
> 18?????? 16
>
>
> 14??? 3????????
> 18???????
> 15?????? 19
>
>
> 15??? 3????????
> 13???????
> 14?????? 17
>
>
> 16??? 3????????
> 12???????
> 16?????? 15
>
>
> 17??? 3????????
> 16???????
> 17?????? 18
>
>
> 18??? 3????????
> 14???????
> 19?????? 15
>
>
>
>
>> attach(booth)
>
>
>> Y <- cbind(COMMIT, SATIS, STAY)
>
>
>> fit <- manova(Y ~ REWGRP)
>
>
>> summary(fit, test="Pillai")
>
>
> ????????? Df? Pillai
> approx F num Df den Df Pr(>F)
>
>
> REWGRP???? 1 0.22731?
> 1.37283????? 3???? 14
> 0.2918
>
>
> Residuals
> 16?????????????????????????????????????
>
>
>
>> summary(fit, test="Wilks")
>
>
> ????????? Df??
> Wilks approx F num Df den Df Pr(>F)
>
>
> REWGRP???? 1 0.77269?
> 1.37283????? 3???? 14
> 0.2918
>
>
> Residuals
> 16?????????????????????????????????????
>
>
>
>> summary(fit, test="Hotelling-Lawley")
>
>
> ????????? Df
> Hotelling-Lawley approx F num Df den Df Pr(>F)
>
>
> REWGRP????
> 1????????? 0.29418?
> 1.37283????? 3???? 14
> 0.2918
>
>
> Residuals
> 16??????????????????????????????????????????????
>
>
>
>> summary(fit, test="Roy")
>
>
> ?????????
> Df???? Roy approx F num Df den Df Pr(>F)
>
>
> REWGRP???? 1 0.29418?
> 1.37283????? 3???? 14
> 0.2918
>
>
> Residuals
> 16?????????????????????????????????????
>
>
>
>> summary(fit)
>
>
> ????????? Df? Pillai
> approx F num Df den Df Pr(>F)
>
>
> REWGRP???? 1 0.22731?
> 1.37283????? 3???? 14
> 0.2918
>
>
> Residuals
> 16?????????????????????????????????????
>
>
>
>> summary.aov(fit)
>
>
> ?Response COMMIT :
>
>
> ???????????
> Df? Sum Sq Mean Sq F value Pr(>F)
>
>
> REWGRP?????? 1??
> 0.333?? 0.333? 0.0532 0.8204
>
>
> Residuals?? 16 100.167??
> 6.260??????????????
>
>
>
>
>
> ?Response SATIS :
>
>
> ???????????
> Df? Sum Sq Mean Sq F value Pr(>F)
>
>
> REWGRP?????? 1??
> 0.750?? 0.750? 0.0945 0.7625
>
>
> Residuals?? 16 127.028??
> 7.939??????????????
>
>
>
>
>
> ?Response STAY :
>
>
> ??????????? Df Sum
> Sq Mean Sq F value Pr(>F)
>
>
> REWGRP?????? 1 14.083? 14.083?
> 2.3013 0.1488
>
>
> Residuals?? 16 97.917??
> 6.120??????????????
>
>
>
>
>
>>
>
>
>
>
>
>
>
>
>
>
>
> Email message sent from CompuServe - visit us today at http://www.cs.com
>
>
>
>
>
>
>
> ________________________________________________________________________
> Email message sent from CompuServe - visit us today at http://www.cs.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Thomas.Petzoldt at tu-dresden.de  Mon Mar 16 12:16:01 2009
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Mon, 16 Mar 2009 12:16:01 +0100
Subject: [Rd] vignette index not linked into HTML help system for package
Message-ID: <49BE34F1.5040908@tu-dresden.de>

Dear R developers,

I observed that the html help page index entry "Read overview or browse 
directory" for package vignettes is missing in recent R-devel.

This happened on two independent computers (WinXP Prof. SP3, German) 
with R-devel compiled from sources svn rev. 48125 resp. 48128
It's the same for my own and also for more prominent packages as well 
(e.g. grid).

The vignettes and the index.html files exist and vignette() as well as 
browseVignettes() work as expected.

I have not found anything about this in NEWS or "Writing R extensions", 
which says:

"At install time an HTML index for all vignettes is automatically 
created from the \VignetteIndexEntry statements unless a file index.html 
exists in directory inst/doc. This index is linked into the HTML help 
system for each package."


Have I missed something?

Thanks a lot

Thomas Petzoldt



-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From luke at stat.uiowa.edu  Mon Mar 16 14:12:05 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Mon, 16 Mar 2009 08:12:05 -0500 (CDT)
Subject: [Rd] Summer of Code, LLVM, parallelization and R
In-Reply-To: <E4AD01F4-2190-4BB9-815C-8DE33E055D2A@web.de>
References: <E4AD01F4-2190-4BB9-815C-8DE33E055D2A@web.de>
Message-ID: <Pine.LNX.4.64.0903160805080.2661@itasca2.wildberry.org>

There is ongoing work on developing a byte code compiler for R.  A
preliminary implementation is available and the corresponding byte
code engine is part of the R distribution.  The initial engine has
been a useful proof of concept but is in the process of being
rewritten from scratch, in part with an eye to supporting
parallelization at least of vectorized math operations; I expect to
make signitficant progress on this over the coming summer.  There are
a lot of open design issues relating to changes or adjustments
(e.g. via declarations) in the R language that might be needed or help
in generating good code, which makes this too loosely specified to
make a good SoC project at the moment.  By summer 2010 it may have
jelled to the point where it is reasonable to spin off projects to,
for example, target lower level VMs like LLVM or JVM or .Net's VM from
the higher level R VM code.

Best,

luke

On Sun, 15 Mar 2009, Florian Gross wrote:

> Hi everybody,
>
> I'm currently working towards my Master's degree as a student of Computer 
> Science at the University of Saarbr?cken and highly interested in compiler 
> construction, interpretation techniques, optimization, programming languages 
> and more. :)
>
> Two professors of my university approached me about an interesting project 
> just a few days ago: Developing a LLVM-based JIT compilation back-end for R. 
> The primary goal would be the generation of parallel / vectorized code, but 
> other ways of increasing performance might be very interesting as well.
>
> I've thought a bit about this and am now wondering if this would make sense 
> as a project for Google's Summer of Code program -- I have seen that the R 
> foundation was accepted as a mentoring organization in 2008 and has applied 
> to be one again in this year.
>
> I've already taken part in the SoC program thrice (working on Novell's 
> JScript.NET compiler and run-time environment in 2005, writing a debugger for 
> the Ruby programming language in 2006 and working on a detailed specification 
> for the Ruby programming language in 2007) and it has always been a lot of 
> fun and a great experience. One thing that was particularly helpful was 
> getting into contact with the development communities so easily.
>
> What do you folks think? Would this be of benefit to the R community? Would 
> it be a good candidate for this year's SoC installment? :)
>
> Also, if some thinking in this direction has already been done or if you have 
> any other pointers, please don't hesitate to reply!
>
> Thanks a lot in advance!
>
> Kind regards,
> Florian Gross
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From mniksere at scs.carleton.ca  Mon Mar 16 14:31:10 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Mon, 16 Mar 2009 09:31:10 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49BD3E8E.9090206@stats.uwo.ca>
References: <49B95F7E.5020406@scs.carleton.ca> <49BD3E8E.9090206@stats.uwo.ca>
Message-ID: <49BE549E.2000706@scs.carleton.ca>

Hi,

Unfortunately I still get the same errors:

CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include -I/usr/sfw/include 
-I/opt/csw/include -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE 
-Iext/ftgl -I/usr/sfw/include/freetype2 -I/usr/sfw/include -Iext 
-I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include -I/opt/csw/include 
    -KPIC  -O -c Background.cpp -o Background.o
"math.h", line 47: Error: modf is not a member of file level.
"math.h", line 48: Error: modff is not a member of file level.
"Shape.hpp", line 58: Error: The function "strncpy" must have a prototype.
3 Error(s) detected.
*** Error code 3



--
Mohammad

Duncan Murdoch wrote:
> On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
>> Hi,
>>
>> I receive the following error while I try to install rgl package:
>>
>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
>> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H -I/usr/include/libpng12 
>> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
>> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
>> -I/usr/sfw/include -I/opt/csw/include    -KPIC  -O -c Background.cpp 
>> -o Background.o
>> "math.h", line 47: Error: modf is not a member of file level.
>> "math.h", line 48: Error: modff is not a member of file level.
>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>> prototype.
>> 3 Error(s) detected.
>>
>> I am using Sun studio 12.
>> I suspect that this is an incompatibility between g++ and Sun studio CC.
>> I would appreciate any you could share your experience with me.
> 
> Brian Ripley contributed some patches that should help with this.  Could 
> you check out the source from R-forge, and confirm that it now compiles 
> on your system?  (Or wait for the tarball there to be updated to 0.84-1 
> in a few hours, and download that.)
> 
> Thanks Brian, for the patch.
> 
> Duncan Murdoch


From chiefmurphy at gmail.com  Mon Mar 16 14:36:53 2009
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Mon, 16 Mar 2009 06:36:53 -0700
Subject: [Rd] Match .3 in a sequence
Message-ID: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090316/b93e2438/attachment.pl>

From murdoch at stats.uwo.ca  Mon Mar 16 15:04:37 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 16 Mar 2009 10:04:37 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49BE549E.2000706@scs.carleton.ca>
References: <49B95F7E.5020406@scs.carleton.ca> <49BD3E8E.9090206@stats.uwo.ca>
	<49BE549E.2000706@scs.carleton.ca>
Message-ID: <49BE5C75.6070907@stats.uwo.ca>

On 3/16/2009 9:31 AM, Mohammad Nikseresht wrote:
> Hi,
> 
> Unfortunately I still get the same errors:
> 
> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include -I/usr/sfw/include 
> -I/opt/csw/include -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE 
> -Iext/ftgl -I/usr/sfw/include/freetype2 -I/usr/sfw/include -Iext 
> -I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include -I/opt/csw/include 
>     -KPIC  -O -c Background.cpp -o Background.o
> "math.h", line 47: Error: modf is not a member of file level.
> "math.h", line 48: Error: modff is not a member of file level.
> "Shape.hpp", line 58: Error: The function "strncpy" must have a prototype.
> 3 Error(s) detected.
> *** Error code 3

That looks like the previous version:  there's no longer a math.h in the 
package.  Maybe you downloaded too quickly, or downloaded to the 
directory containing the old source and have a mix of both?

Duncan Murdoch

> 
> 
> --
> Mohammad
> 
> Duncan Murdoch wrote:
>> On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
>>> Hi,
>>>
>>> I receive the following error while I try to install rgl package:
>>>
>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
>>> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H -I/usr/include/libpng12 
>>> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
>>> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
>>> -I/usr/sfw/include -I/opt/csw/include    -KPIC  -O -c Background.cpp 
>>> -o Background.o
>>> "math.h", line 47: Error: modf is not a member of file level.
>>> "math.h", line 48: Error: modff is not a member of file level.
>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>> prototype.
>>> 3 Error(s) detected.
>>>
>>> I am using Sun studio 12.
>>> I suspect that this is an incompatibility between g++ and Sun studio CC.
>>> I would appreciate any you could share your experience with me.
>> 
>> Brian Ripley contributed some patches that should help with this.  Could 
>> you check out the source from R-forge, and confirm that it now compiles 
>> on your system?  (Or wait for the tarball there to be updated to 0.84-1 
>> in a few hours, and download that.)
>> 
>> Thanks Brian, for the patch.
>> 
>> Duncan Murdoch


From murdoch at stats.uwo.ca  Mon Mar 16 15:12:51 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 16 Mar 2009 10:12:51 -0400
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
Message-ID: <49BE5E63.9010800@stats.uwo.ca>

On 3/16/2009 9:36 AM, Daniel Murphy wrote:
> Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I get
>> 0.3 %in% seq(from=.2,to=.3)
> [1] FALSE
> Yet
>> 0.3 %in% c(.2,.3)
> [1] TRUE
> For arbitrary sequences, this "invisible .3" has been problematic. What is
> the best way to work around this?

Don't assume that computations on floating point values are exact. 
Generally computations on small integers *are* exact, so you could 
change that to

3 %in% seq(from=2, to=3)

and get the expected result.  You can divide by 10 just before you use 
the number, or if you're starting with one decimal place, multiply by 10 
*and round to an integer* before doing the test.  Alternatively, use 
some approximate test rather than an exact one, e.g. all.equal() (but 
you'll need a bit of work to make use of all.equal() in an expression 
like 0.3 %in% c(.2,.3)).

Duncan Murdoch


From ggrothendieck at gmail.com  Mon Mar 16 15:35:34 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Mar 2009 10:35:34 -0400
Subject: [Rd] Summer of Code, LLVM, parallelization and R
In-Reply-To: <E4AD01F4-2190-4BB9-815C-8DE33E055D2A@web.de>
References: <E4AD01F4-2190-4BB9-815C-8DE33E055D2A@web.de>
Message-ID: <971536df0903160735x3583e217tadfcd95dcd9a07a5@mail.gmail.com>

In addition to the work Luke is doing there is Ra:

http://www.milbo.users.sonic.net/ra

On Sun, Mar 15, 2009 at 11:25 AM, Florian Gross <Florian.S.Gross at web.de> wrote:
> Hi everybody,
>
> I'm currently working towards my Master's degree as a student of Computer
> Science at the University of Saarbr?cken and highly interested in compiler
> construction, interpretation techniques, optimization, programming languages
> and more. :)
>
> Two professors of my university approached me about an interesting project
> just a few days ago: Developing a LLVM-based JIT compilation back-end for R.
> The primary goal would be the generation of parallel / vectorized code, but
> other ways of increasing performance might be very interesting as well.
>
> I've thought a bit about this and am now wondering if this would make sense
> as a project for Google's Summer of Code program -- I have seen that the R
> foundation was accepted as a mentoring organization in 2008 and has applied
> to be one again in this year.
>
> I've already taken part in the SoC program thrice (working on Novell's
> JScript.NET compiler and run-time environment in 2005, writing a debugger
> for the Ruby programming language in 2006 and working on a detailed
> specification for the Ruby programming language in 2007) and it has always
> been a lot of fun and a great experience. One thing that was particularly
> helpful was getting into contact with the development communities so easily.
>
> What do you folks think? Would this be of benefit to the R community? Would
> it be a good candidate for this year's SoC installment? :)
>
> Also, if some thinking in this direction has already been done or if you
> have any other pointers, please don't hesitate to reply!
>
> Thanks a lot in advance!
>
> Kind regards,
> Florian Gross
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 16 16:04:09 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 16 Mar 2009 16:04:09 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <49BE5E63.9010800@stats.uwo.ca>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<49BE5E63.9010800@stats.uwo.ca>
Message-ID: <49BE6A69.3060309@idi.ntnu.no>

Duncan Murdoch wrote:
> On 3/16/2009 9:36 AM, Daniel Murphy wrote:
>> Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3).
>> I get
>>> 0.3 %in% seq(from=.2,to=.3)
>> [1] FALSE
>> Yet
>>> 0.3 %in% c(.2,.3)
>> [1] TRUE
>> For arbitrary sequences, this "invisible .3" has been problematic.
>> What is
>> the best way to work around this?
>
> Don't assume that computations on floating point values are exact.
> Generally computations on small integers *are* exact, so you could
> change that to
>
> 3 %in% seq(from=2, to=3)
>
> and get the expected result.  You can divide by 10 just before you use
> the number, or if you're starting with one decimal place, multiply by
> 10 *and round to an integer* before doing the test.  Alternatively,
> use some approximate test rather than an exact one, e.g. all.equal()
> (but you'll need a bit of work to make use of all.equal() in an
> expression like 0.3 %in% c(.2,.3)).


there's also the problem that seq(from=0.2, to=0.3) does *not* include
0.3 (in whatever internal form), simply because the default step is 1. 
however,

    0.3 %in% seq(from=.2,to=.3, by=0.1)
    # FALSE

so it won't help anyway.  (but in general be careful about using seq and
the like.)

vQ


From macrakis at alum.mit.edu  Mon Mar 16 16:24:41 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 16 Mar 2009 11:24:41 -0400
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
Message-ID: <8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>

Well, first of all, seq(from=.2,to=.3) gives c(0.2), so I assume you
really mean something like seq(from=.2,to=.3,by=.1), which gives
c(0.2, 0.3).

%in% tests for exact equality, which is almost never a good idea with
floating-point numbers.

You need to define what exactly you mean by "in" for floating-point
numbers.  What sort of tolerance are you willing to allow?

Some possibilities would be for example:

approxin <- function(x,list,tol) any(abs(list-x)<tol)   # absolute tolerance

rapproxin <- function(x,list,tol) (x==0 && 0 %in% list) ||
any(abs((list-x)/x)<=tol,na.rm=TRUE)
     # relative tolerance; only exact 0 will match 0

Hope this helps,

          -s

On Mon, Mar 16, 2009 at 9:36 AM, Daniel Murphy <chiefmurphy at gmail.com> wrote:
> Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I get
>> 0.3 %in% seq(from=.2,to=.3)
> [1] FALSE
> Yet
>> 0.3 %in% c(.2,.3)
> [1] TRUE
> For arbitrary sequences, this "invisible .3" has been problematic. What is
> the best way to work around this?


From mniksere at scs.carleton.ca  Mon Mar 16 16:38:11 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Mon, 16 Mar 2009 11:38:11 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49BE5C75.6070907@stats.uwo.ca>
References: <49B95F7E.5020406@scs.carleton.ca> <49BD3E8E.9090206@stats.uwo.ca>
	<49BE549E.2000706@scs.carleton.ca> <49BE5C75.6070907@stats.uwo.ca>
Message-ID: <49BE7263.5010904@scs.carleton.ca>

I downloaded source tarball this morning from:
http://cran.at.r-project.org/
It is rgl_0.84.tar.gz but it does contain a math.h!
where can I find version 0.84-1?

Thanks
--
Mohammad Nikseresht


Duncan Murdoch wrote:
> On 3/16/2009 9:31 AM, Mohammad Nikseresht wrote:
>> Hi,
>>
>> Unfortunately I still get the same errors:
>>
>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include -I/usr/sfw/include 
>> -I/opt/csw/include -DHAVE_PNG_H -I/usr/include/libpng12 
>> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
>> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
>> -I/usr/sfw/include -I/opt/csw/include     -KPIC  -O -c Background.cpp 
>> -o Background.o
>> "math.h", line 47: Error: modf is not a member of file level.
>> "math.h", line 48: Error: modff is not a member of file level.
>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>> prototype.
>> 3 Error(s) detected.
>> *** Error code 3
> 
> That looks like the previous version:  there's no longer a math.h in the 
> package.  Maybe you downloaded too quickly, or downloaded to the 
> directory containing the old source and have a mix of both?
> 
> Duncan Murdoch
> 
>>
>>
>> -- 
>> Mohammad
>>
>> Duncan Murdoch wrote:
>>> On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
>>>> Hi,
>>>>
>>>> I receive the following error while I try to install rgl package:
>>>>
>>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H 
>>>> -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl 
>>>> -I/usr/sfw/include/freetype2 -I/usr/sfw/include -Iext 
>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include 
>>>> -I/opt/csw/include    -KPIC  -O -c Background.cpp -o Background.o
>>>> "math.h", line 47: Error: modf is not a member of file level.
>>>> "math.h", line 48: Error: modff is not a member of file level.
>>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>>> prototype.
>>>> 3 Error(s) detected.
>>>>
>>>> I am using Sun studio 12.
>>>> I suspect that this is an incompatibility between g++ and Sun studio 
>>>> CC.
>>>> I would appreciate any you could share your experience with me.
>>>
>>> Brian Ripley contributed some patches that should help with this.  
>>> Could you check out the source from R-forge, and confirm that it now 
>>> compiles on your system?  (Or wait for the tarball there to be 
>>> updated to 0.84-1 in a few hours, and download that.)
>>>
>>> Thanks Brian, for the patch.
>>>
>>> Duncan Murdoch


From luke at stat.uiowa.edu  Mon Mar 16 16:37:30 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Mon, 16 Mar 2009 10:37:30 -0500 (CDT)
Subject: [Rd] Using and 'eval' and environments with active bindings
In-Reply-To: <66f3bd910903151745k42407ec4xb4771fa3e7ef4ac2@mail.gmail.com>
References: <66f3bd910903151745k42407ec4xb4771fa3e7ef4ac2@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0903161036450.5957@nokomis.stat.uiowa.edu>

Thanks for the report.  I meant to have R_isMissing always return
FALSE for active binding but had it returning TRUE intead.  Fixed now
in R-devel.

luke

On Sun, 15 Mar 2009, Roger D. Peng wrote:

> The following code produces an error in current R-devel
>
> f <- function(value) {
>        if(!missing(value))
>                100
>        else
>                2
> }
> e <- new.env()
> makeActiveBinding("x", f, e)
> eval(substitute(list(x)), e)
>
> The error, after calling 'eval' is
>
> Error in eval(expr, envir, enclos) :
>  element 1 is empty;
>   the part of the args list of 'list' being evaluated was:
>   (x)
>
>
> It has something to do with the change in R_isMissing in revision
> r48118 but I'm not quite knowledgeable enough to understand what the
> problem is. In R 2.8.1 the result was simply
>
>
>> eval(substitute(list(x)), e)
> [[1]]
> [1] 2
>
> I can't say I know what the output should be but I'd like some
> clarification on whether this is a bug.
>
> Thanks,
> -roger
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From murdoch at stats.uwo.ca  Mon Mar 16 17:21:02 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 16 Mar 2009 12:21:02 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49BE7263.5010904@scs.carleton.ca>
References: <49B95F7E.5020406@scs.carleton.ca> <49BD3E8E.9090206@stats.uwo.ca>
	<49BE549E.2000706@scs.carleton.ca> <49BE5C75.6070907@stats.uwo.ca>
	<49BE7263.5010904@scs.carleton.ca>
Message-ID: <49BE7C6E.10708@stats.uwo.ca>

On 3/16/2009 11:38 AM, Mohammad Nikseresht wrote:
> I downloaded source tarball this morning from:
> http://cran.at.r-project.org/
> It is rgl_0.84.tar.gz but it does contain a math.h!
> where can I find version 0.84-1?

It's on R-forge.  You can download it as

http://r-forge.r-project.org/src/contrib/rgl_0.84-1.tar.gz

Duncan Murdoch

> 
> Thanks
> --
> Mohammad Nikseresht
> 
> 
> Duncan Murdoch wrote:
>> On 3/16/2009 9:31 AM, Mohammad Nikseresht wrote:
>>> Hi,
>>>
>>> Unfortunately I still get the same errors:
>>>
>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include -I/usr/sfw/include 
>>> -I/opt/csw/include -DHAVE_PNG_H -I/usr/include/libpng12 
>>> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
>>> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
>>> -I/usr/sfw/include -I/opt/csw/include     -KPIC  -O -c Background.cpp 
>>> -o Background.o
>>> "math.h", line 47: Error: modf is not a member of file level.
>>> "math.h", line 48: Error: modff is not a member of file level.
>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>> prototype.
>>> 3 Error(s) detected.
>>> *** Error code 3
>> 
>> That looks like the previous version:  there's no longer a math.h in the 
>> package.  Maybe you downloaded too quickly, or downloaded to the 
>> directory containing the old source and have a mix of both?
>> 
>> Duncan Murdoch
>> 
>>>
>>>
>>> -- 
>>> Mohammad
>>>
>>> Duncan Murdoch wrote:
>>>> On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
>>>>> Hi,
>>>>>
>>>>> I receive the following error while I try to install rgl package:
>>>>>
>>>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
>>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H 
>>>>> -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl 
>>>>> -I/usr/sfw/include/freetype2 -I/usr/sfw/include -Iext 
>>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include 
>>>>> -I/opt/csw/include    -KPIC  -O -c Background.cpp -o Background.o
>>>>> "math.h", line 47: Error: modf is not a member of file level.
>>>>> "math.h", line 48: Error: modff is not a member of file level.
>>>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>>>> prototype.
>>>>> 3 Error(s) detected.
>>>>>
>>>>> I am using Sun studio 12.
>>>>> I suspect that this is an incompatibility between g++ and Sun studio 
>>>>> CC.
>>>>> I would appreciate any you could share your experience with me.
>>>>
>>>> Brian Ripley contributed some patches that should help with this.  
>>>> Could you check out the source from R-forge, and confirm that it now 
>>>> compiles on your system?  (Or wait for the tarball there to be 
>>>> updated to 0.84-1 in a few hours, and download that.)
>>>>
>>>> Thanks Brian, for the patch.
>>>>
>>>> Duncan Murdoch


From mniksere at scs.carleton.ca  Mon Mar 16 17:40:41 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Mon, 16 Mar 2009 12:40:41 -0400
Subject: [Rd] Error compiling rgl package
In-Reply-To: <49BE7C6E.10708@stats.uwo.ca>
References: <49B95F7E.5020406@scs.carleton.ca> <49BD3E8E.9090206@stats.uwo.ca>
	<49BE549E.2000706@scs.carleton.ca> <49BE5C75.6070907@stats.uwo.ca>
	<49BE7263.5010904@scs.carleton.ca> <49BE7C6E.10708@stats.uwo.ca>
Message-ID: <49BE8109.9050300@scs.carleton.ca>


rgl_0.84-1.tar.gz compiled and installed successfully on our system.
Solaris 10 sparc, Sun Studio 12.

Thank you very much!
--
Mohammad Nikseresht


Duncan Murdoch wrote:
> On 3/16/2009 11:38 AM, Mohammad Nikseresht wrote:
>> I downloaded source tarball this morning from:
>> http://cran.at.r-project.org/
>> It is rgl_0.84.tar.gz but it does contain a math.h!
>> where can I find version 0.84-1?
> 
> It's on R-forge.  You can download it as
> 
> http://r-forge.r-project.org/src/contrib/rgl_0.84-1.tar.gz
> 
> Duncan Murdoch
> 
>>
>> Thanks
>> -- 
>> Mohammad Nikseresht
>>
>>
>> Duncan Murdoch wrote:
>>> On 3/16/2009 9:31 AM, Mohammad Nikseresht wrote:
>>>> Hi,
>>>>
>>>> Unfortunately I still get the same errors:
>>>>
>>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include -I/usr/sfw/include 
>>>> -I/opt/csw/include -DHAVE_PNG_H -I/usr/include/libpng12 
>>>> -DHAVE_FREETYPE -Iext/ftgl -I/usr/sfw/include/freetype2 
>>>> -I/usr/sfw/include -Iext -I/opt/SUNWhpc/HPC8.1/sun/include 
>>>> -I/usr/sfw/include -I/opt/csw/include     -KPIC  -O -c 
>>>> Background.cpp -o Background.o
>>>> "math.h", line 47: Error: modf is not a member of file level.
>>>> "math.h", line 48: Error: modff is not a member of file level.
>>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>>> prototype.
>>>> 3 Error(s) detected.
>>>> *** Error code 3
>>>
>>> That looks like the previous version:  there's no longer a math.h in 
>>> the package.  Maybe you downloaded too quickly, or downloaded to the 
>>> directory containing the old source and have a mix of both?
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>
>>>> -- 
>>>> Mohammad
>>>>
>>>> Duncan Murdoch wrote:
>>>>> On 12/03/2009 3:16 PM, Mohammad Nikseresht wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I receive the following error while I try to install rgl package:
>>>>>>
>>>>>> CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
>>>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -DHAVE_PNG_H 
>>>>>> -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl 
>>>>>> -I/usr/sfw/include/freetype2 -I/usr/sfw/include -Iext 
>>>>>> -I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include 
>>>>>> -I/opt/csw/include    -KPIC  -O -c Background.cpp -o Background.o
>>>>>> "math.h", line 47: Error: modf is not a member of file level.
>>>>>> "math.h", line 48: Error: modff is not a member of file level.
>>>>>> "Shape.hpp", line 58: Error: The function "strncpy" must have a 
>>>>>> prototype.
>>>>>> 3 Error(s) detected.
>>>>>>
>>>>>> I am using Sun studio 12.
>>>>>> I suspect that this is an incompatibility between g++ and Sun 
>>>>>> studio CC.
>>>>>> I would appreciate any you could share your experience with me.
>>>>>
>>>>> Brian Ripley contributed some patches that should help with this.  
>>>>> Could you check out the source from R-forge, and confirm that it 
>>>>> now compiles on your system?  (Or wait for the tarball there to be 
>>>>> updated to 0.84-1 in a few hours, and download that.)
>>>>>
>>>>> Thanks Brian, for the patch.
>>>>>
>>>>> Duncan Murdoch


From savicky at cs.cas.cz  Mon Mar 16 17:41:54 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 16 Mar 2009 17:41:54 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
Message-ID: <20090316164154.GB15686@cs.cas.cz>

On Mon, Mar 16, 2009 at 06:36:53AM -0700, Daniel Murphy wrote:
> Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I get
> > 0.3 %in% seq(from=.2,to=.3)
> [1] FALSE

As others already pointed out, you should use seq(from=0.2,to=0.3,by=0.1)
to get 0.3 in the sequence. In order to get correct %in%, it is also
possible to use round(), for example
  > 0.3 %in% round(seq(from=0.2,to=0.3,by=0.1),digits=1)
  [1] TRUE

See FAQ 7.31
  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
or 
  http://wiki.r-project.org/rwiki/doku.php?id=misc:r_accuracy:decimal_numbers
for more detail.

Petr.


From mniksere at scs.carleton.ca  Mon Mar 16 18:54:41 2009
From: mniksere at scs.carleton.ca (Mohammad Nikseresht)
Date: Mon, 16 Mar 2009 13:54:41 -0400
Subject: [Rd] Error Compiling clusterSim on Solaris
Message-ID: <49BE9261.2050903@scs.carleton.ca>

Hi,

I receive the following error when I try to install cluserSim package on 
  Sparc Solaris 10 using Sun Studio 12:
I have compiled and installed a 64 bit version of R.

CC -xtarget=native64 -I/opt/R-2.8.1/lib/R/include 
-I/opt/SUNWhpc/HPC8.1/sun/include -I/usr/sfw/include -I/opt/csw/include 
    -KPIC  -O -c clusterSim.cpp -o clusterSim.o
"clusterSim.cpp", line 14: Error: An integer constant expression is 
required within the array subscript operator.
1 Error(s) detected.
*** Error code 1
make: Fatal error: Command failed for target `clusterSim.o'
I would appreciate it if you could share your experience with me.


Thanks

--
Mohammad Nikseresht


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 16 21:19:58 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 16 Mar 2009 21:19:58 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <20090316164154.GB15686@cs.cas.cz>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<20090316164154.GB15686@cs.cas.cz>
Message-ID: <49BEB46E.9090601@idi.ntnu.no>

Petr Savicky wrote:
> On Mon, Mar 16, 2009 at 06:36:53AM -0700, Daniel Murphy wrote:
>   
>> Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I get
>>     
>>> 0.3 %in% seq(from=.2,to=.3)
>>>       
>> [1] FALSE
>>     
>
> As others already pointed out, you should use seq(from=0.2,to=0.3,by=0.1)
> to get 0.3 in the sequence. In order to get correct %in%, it is also
> possible to use round(), for example
>   > 0.3 %in% round(seq(from=0.2,to=0.3,by=0.1),digits=1)
>   [1] TRUE
>
>   

half-jokingly, there's another solution, which avoids rounding:

    0.3 %in% (seq(0.4, 0.5, 0.1)-0.2)
    # TRUE

vQ


From chiefmurphy at gmail.com  Mon Mar 16 23:53:49 2009
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Mon, 16 Mar 2009 15:53:49 -0700
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
Message-ID: <48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090316/76dae5d5/attachment.pl>

From macrakis at alum.mit.edu  Tue Mar 17 00:39:23 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 16 Mar 2009 19:39:23 -0400
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
Message-ID: <8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>

The factor approach is horrifically ugly and dangerous.

Even if it didn't have the extraordinarily poor behavior documented
below, it simply isn't well-defined what it should do.  The explicit
approximation route is far far preferable in every way: more
predictable, more controllable, and even (though it hardly matters
usually) faster.

Let's look at the extraordinarily poor behavior I was mentioning. Consider:

nums <- (.3 + 2e-16 * c(-2,-1,1,2)); nums
[1] 0.3 0.3 0.3 0.3

Though they all print as .3 with the default precision (which is
normal and expected), they are all different from .3:

nums - .3 =>  -3.885781e-16 -2.220446e-16  2.220446e-16  3.885781e-16

When we convert nums to a factor, we get:

fact <- as.factor(nums); fact
[1] 0.300000000000000 0.3               0.3               0.300000000000000
Levels: 0.300000000000000 0.3 0.3 0.300000000000000

Not clear what the difference between 0.300000000000000 and 0.3 is
supposed to be, nor why some 0.300000000000000 are < .3 and others are
> .3, but let's put that aside for the moment.

Now let's look at the relations among the factor values:

fact[1]==fact[2]
[1] FALSE
> fact[1]==fact[4]
[1] TRUE

So though nums[1] < nums[2] < nums[3] < nums[4], fact[1] compares
*unequal* to fact[2] though it compares *equal* to fact[4].
Apparently R is comparing the *names* of the levels rather than the
indexes in the factor.  This would be weird even if it didn't lead to
this very bad case.

Hope this helps,

             -s


On Mon, Mar 16, 2009 at 6:53 PM, Daniel Murphy <chiefmurphy at gmail.com> wrote:
> I have a matrix whose columns were filled with values which were functions
> of cvseq<-seq(.2,.3,by=.1) (and a row value of mode integer). To do a lookup
> for cv=.3 later, I wanted to match(.3,cvseq), which gave me NA, hence my
> question. I thought R would match .3 in cvseq within?.Machine$double.eps,
> but I can understand it if .3 and the second element of cvseq would not have
> identical bits.
> Besides the helpful suggestions below, I also tried
>> cvseqf <- as.factor(cvseq)
>> match(.3,cvseq)
> [1] 2
> which worked.
> In general, would it be better to go the enumeration route via as.factor or
> the approximation route?
> Thanks for the help.
> -Dan
>
> On Mon, Mar 16, 2009 at 8:24 AM, Stavros Macrakis <macrakis at alum.mit.edu>
> wrote:
>>
>> Well, first of all, seq(from=.2,to=.3) gives c(0.2), so I assume you
>> really mean something like seq(from=.2,to=.3,by=.1), which gives
>> c(0.2, 0.3).
>>
>> %in% tests for exact equality, which is almost never a good idea with
>> floating-point numbers.
>>
>> You need to define what exactly you mean by "in" for floating-point
>> numbers. ?What sort of tolerance are you willing to allow?
>>
>> Some possibilities would be for example:
>>
>> approxin <- function(x,list,tol) any(abs(list-x)<tol) ? # absolute
>> tolerance
>>
>> rapproxin <- function(x,list,tol) (x==0 && 0 %in% list) ||
>> any(abs((list-x)/x)<=tol,na.rm=TRUE)
>> ? ? # relative tolerance; only exact 0 will match 0
>>
>> Hope this helps,
>>
>> ? ? ? ? ?-s
>>
>> On Mon, Mar 16, 2009 at 9:36 AM, Daniel Murphy <chiefmurphy at gmail.com>
>> wrote:
>> > Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I
>> > get
>> >> 0.3 %in% seq(from=.2,to=.3)
>> > [1] FALSE
>> > Yet
>> >> 0.3 %in% c(.2,.3)
>> > [1] TRUE
>> > For arbitrary sequences, this "invisible .3" has been problematic. What
>> > is
>> > the best way to work around this?
>
>


From nakama at ki.rim.or.jp  Tue Mar 17 04:12:15 2009
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Tue, 17 Mar 2009 12:12:15 +0900
Subject: [Rd] [R] R with MKL
In-Reply-To: <fb1538e20903161533u599d8c00mef61f71bf2427a39@mail.gmail.com>
References: <fb1538e20903161533u599d8c00mef61f71bf2427a39@mail.gmail.com>
Message-ID: <dc41e1260903162012y2d3d2414o41fbe5082945b7ae@mail.gmail.com>

Hi

> I have seen a lot of problems from people trying to compile R with
> MKL. So I am writing my experience in case it helps and to ask one
> question. I installed R-2.8.1.patched in Ubuntu 9.04 (gcc 4.3.3) using
> MKL 10.1.1.019.

Do you use gcc and gfortran?

> I configured correctly (following MKL userguide) with :
>
> sudo ./configure --with-blas="-I/opt/intel/mkl/10.1.1.019/include
> -L/opt/intel/mkl/10.1.1.019/lib/em64t -lmkl_intel_lp64
> -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
> --with-lapack="-I/opt/intel/mkl/10.1.1.019/include
> -L/opt/intel/mkl/10.1.1.019/lib/em64t -lmkl_intel_lp64
> -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"

cited reference https://svn.r-project.org/R/trunk/doc/manual/R-admin.texi
| You are strongly encouraged to read the MKL User's Guide
| <snip>
| @example
| MKL="   -L$@{MKL_LIB_PATH@}                               \
|         -Wl,--start-group                               \
|                 $@{MKL_LIB_PATH@}/libmkl_gf_lp64.a        \
|                 $@{MKL_LIB_PATH@}/libmkl_gnu_thread.a     \
|                 $@{MKL_LIB_PATH@}/libmkl_core.a           \
|         -Wl,--end-group                                 \
|         -liomp5 -lpthread"
| @end example

However, It is a little different.( -lgomp and configure line)

MKL="   -L$@{MKL_LIB_PATH@}                               \
        -Wl,--start-group                               \
                $@{MKL_LIB_PATH@}/libmkl_gf_lp64.a        \
                $@{MKL_LIB_PATH@}/libmkl_gnu_thread.a     \
                $@{MKL_LIB_PATH@}/libmkl_core.a           \
        -Wl,--end-group                                 \
        -lgomp -lpthread"
./configure --with-blas="$MKL" --with-lapack="$MKL"

> But in order to compile had to edit src/modules/lapack/vecLibg95c.c
> and comment out the include. Weird, since I am not building for Mac.

Please note the thing that ABI of fortran is different with Intel compiler
and GNU compiler.
difficult to detect the mistake.
-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From keith at wehi.EDU.AU  Tue Mar 17 04:44:04 2009
From: keith at wehi.EDU.AU (Keith Satterley)
Date: Tue, 17 Mar 2009 14:44:04 +1100
Subject: [Rd] link in base help file fails.
Message-ID: <49BF1C84.80303@wehi.edu.au>

I run R on MS Windows. In R2.9.0dev, I type ?base to get "R help for package 
base" to open. I then select ".First" from the list of contents, getting a page 
headed: "Initialization at Start of an R Session". About half way down there is 
a sentence:

The command-line flag --vanilla implies --no-site-file, --no-init-file, 
--no-restore and --no-environ. Under Windows, it also implies --no-Rconsole, 
which prevents loading the ?Rconsole? file.

The last occurrence of the word Rconsole is in blue text and underlined, a link. 
On clicking on this link, I get a page headed "This program cannot display the 
webpage" with advice on "Most likely causes:" and "What you can try".

Other links work satisfactorily on that page. My internet connection is working.

I presume there is a problem with this Rconsole link.

 > sessionInfo()
R version 2.9.0 Under development (unstable) (2009-03-13 r48127)
i386-pc-mingw32

locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base
 >

cheers,

Keith

========================
Keith Satterley
Bioinformatics Division
The Walter and Eliza Hall Institute of Medical Research
Parkville, Melbourne,
Victoria, Australia


From chiefmurphy at gmail.com  Tue Mar 17 05:13:31 2009
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Mon, 16 Mar 2009 21:13:31 -0700
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
Message-ID: <48f8cced0903162113q5884630cl3fbdb5bad1a4176@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090316/dab1b5dd/attachment.pl>

From savicky at cs.cas.cz  Tue Mar 17 07:07:49 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 17 Mar 2009 07:07:49 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
Message-ID: <20090317060749.GA24730@cs.cas.cz>

On Mon, Mar 16, 2009 at 07:39:23PM -0400, Stavros Macrakis wrote:
...
> Let's look at the extraordinarily poor behavior I was mentioning. Consider:
> 
> nums <- (.3 + 2e-16 * c(-2,-1,1,2)); nums
> [1] 0.3 0.3 0.3 0.3
> 
> Though they all print as .3 with the default precision (which is
> normal and expected), they are all different from .3:
> 
> nums - .3 =>  -3.885781e-16 -2.220446e-16  2.220446e-16  3.885781e-16
> 
> When we convert nums to a factor, we get:
> 
> fact <- as.factor(nums); fact
> [1] 0.300000000000000 0.3               0.3               0.300000000000000
> Levels: 0.300000000000000 0.3 0.3 0.300000000000000
> 
> Not clear what the difference between 0.300000000000000 and 0.3 is
> supposed to be, nor why some 0.300000000000000 are < .3 and others are
...

When creating a factor from numeric vector, the list of levels and the
assignment of original elements to the levels is done using
double precision. Since the four elements in the vector are distinct,
we get four distinct levels. After this is done, the levels attribute is
formed using as.character(). This can map different numbers to the same
string, so in the example above, this leads to a factor, which contains
repeated levels.

This part of the problem may be avoided using

  fact <- as.factor(as.character(nums)); fact
  [1] 0.300000000000000 0.3               0.3               0.300000000000000
  Levels: 0.3 0.300000000000000

The reason for having 0.300000000000000 and 0.3 is that as.character()
works the same as printing with digits=15. The R printing mechanism
works in two steps. In the first step it tries to determine the shortest 
format needed to achieve the required relative precision of the output.
This step uses an algorithm, which need not provide an accurate result.
The next step is that the number is printed using C function sprintf
with the chosen format. This step is accurate, so we cannot get wrong
digits. We only can get wrong number of digits.

In order to avoid using 15 digits in as.character(), we can use round(,digits),
with digits argument appropriate for the current situation.

  > fact <- as.factor(round(nums,digits=1)); fact
  [1] 0.3 0.3 0.3 0.3
  Levels: 0.3

Petr.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 17 10:15:39 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 17 Mar 2009 10:15:39 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <20090317060749.GA24730@cs.cas.cz>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
	<20090317060749.GA24730@cs.cas.cz>
Message-ID: <49BF6A3B.1080200@idi.ntnu.no>

Petr Savicky wrote:
> On Mon, Mar 16, 2009 at 07:39:23PM -0400, Stavros Macrakis wrote:
> ...
>   
>> Let's look at the extraordinarily poor behavior I was mentioning. Consider:
>>
>> nums <- (.3 + 2e-16 * c(-2,-1,1,2)); nums
>> [1] 0.3 0.3 0.3 0.3
>>
>> Though they all print as .3 with the default precision (which is
>> normal and expected), they are all different from .3:
>>
>> nums - .3 =>  -3.885781e-16 -2.220446e-16  2.220446e-16  3.885781e-16
>>
>> When we convert nums to a factor, we get:
>>
>> fact <- as.factor(nums); fact
>> [1] 0.300000000000000 0.3               0.3               0.300000000000000
>> Levels: 0.300000000000000 0.3 0.3 0.300000000000000
>>
>> Not clear what the difference between 0.300000000000000 and 0.3 is
>> supposed to be, nor why some 0.300000000000000 are < .3 and others are
>>     
> ...
>
> When creating a factor from numeric vector, the list of levels and the
> assignment of original elements to the levels is done using
> double precision. Since the four elements in the vector are distinct,
> we get four distinct levels. After this is done, the levels attribute is
> formed using as.character(). This can map different numbers to the same
> string, so in the example above, this leads to a factor, which contains
> repeated levels.
>
> This part of the problem may be avoided using
>
>   fact <- as.factor(as.character(nums)); fact
>   [1] 0.300000000000000 0.3               0.3               0.300000000000000
>   Levels: 0.3 0.300000000000000
>
> The reason for having 0.300000000000000 and 0.3 is that as.character()
> works the same as printing with digits=15. The R printing mechanism
> works in two steps. In the first step it tries to determine the shortest 
> format needed to achieve the required relative precision of the output.
> This step uses an algorithm, which need not provide an accurate result.
> The next step is that the number is printed using C function sprintf
> with the chosen format. This step is accurate, so we cannot get wrong
> digits. We only can get wrong number of digits.
>
> In order to avoid using 15 digits in as.character(), we can use round(,digits),
> with digits argument appropriate for the current situation.
>
>   > fact <- as.factor(round(nums,digits=1)); fact
>   [1] 0.3 0.3 0.3 0.3
>   Levels: 0.3
>
>   

with the examples above, it looks like a design flaw that factor levels
and their *labels* are messed up into one clump.  if, in the above,
levels were the numbers, and their labels were produced with
as.character, as you show, but kept separately (or generated on the fly,
when displaying the factor), the problem would have been solved.  you
would then have something like:
  
    nums <- (.3 + 2e-16 * c(-2,-1,1,2)); nums   
    # [1] 0.3 0.3 0.3 0.3
   
    sum(nums[rep(1:4, each=4)] == nums[rep(1:4, 4)])
    # 4

    fact <- as.factor(nums); fact
    # [1] 0.300000000000000 0.3 0.3 0.300000000000000
    # Levels: 0.300000000000000 0.3 0.3 0.300000000000000
  
    sum(fact[rep(1:4, each=4)] == fact[rep(1:4, 4)])
    # 4 (currently, it's 8)
   
there's one more curiosity about factors, in particular, ordered factors:

    ord <- as.ordered(nums); ord
    # [1] 0.300000000000000 0.3               0.3              
0.300000000000000
    # Levels: 0.300000000000000 < 0.3 < 0.3 < 0.300000000000000

    ord[1] < ord[4]
    # TRUE
    ord[1] == ord[4]
    # TRUE

vQ


From plummer at iarc.fr  Tue Mar 17 10:39:35 2009
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 17 Mar 2009 10:39:35 +0100
Subject: [Rd] [R] R with MKL
In-Reply-To: <dc41e1260903162012y2d3d2414o41fbe5082945b7ae@mail.gmail.com>
References: <fb1538e20903161533u599d8c00mef61f71bf2427a39@mail.gmail.com>
	<dc41e1260903162012y2d3d2414o41fbe5082945b7ae@mail.gmail.com>
Message-ID: <1237282775.3044.14.camel@localhost.localdomain>

On Tue, 2009-03-17 at 12:12 +0900, Ei-ji Nakama wrote:
> Hi
> 
> > I have seen a lot of problems from people trying to compile R with
> > MKL. So I am writing my experience in case it helps and to ask one
> > question. I installed R-2.8.1.patched in Ubuntu 9.04 (gcc 4.3.3) using
> > MKL 10.1.1.019.
> 
> Do you use gcc and gfortran?
> 
> > I configured correctly (following MKL userguide) with :
> >
> > sudo ./configure --with-blas="-I/opt/intel/mkl/10.1.1.019/include
> > -L/opt/intel/mkl/10.1.1.019/lib/em64t -lmkl_intel_lp64
> > -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
> > --with-lapack="-I/opt/intel/mkl/10.1.1.019/include
> > -L/opt/intel/mkl/10.1.1.019/lib/em64t -lmkl_intel_lp64
> > -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
> 
> cited reference https://svn.r-project.org/R/trunk/doc/manual/R-admin.texi
> | You are strongly encouraged to read the MKL User's Guide
> | <snip>
> | @example
> | MKL="   -L$@{MKL_LIB_PATH@}                               \
> |         -Wl,--start-group                               \
> |                 $@{MKL_LIB_PATH@}/libmkl_gf_lp64.a        \
> |                 $@{MKL_LIB_PATH@}/libmkl_gnu_thread.a     \
> |                 $@{MKL_LIB_PATH@}/libmkl_core.a           \
> |         -Wl,--end-group                                 \
> |         -liomp5 -lpthread"
> | @end example
> 
> However, It is a little different.( -lgomp and configure line)
> 
> MKL="   -L$@{MKL_LIB_PATH@}                               \
>         -Wl,--start-group                               \
>                 $@{MKL_LIB_PATH@}/libmkl_gf_lp64.a        \
>                 $@{MKL_LIB_PATH@}/libmkl_gnu_thread.a     \
>                 $@{MKL_LIB_PATH@}/libmkl_core.a           \
>         -Wl,--end-group                                 \
>         -lgomp -lpthread"
> ./configure --with-blas="$MKL" --with-lapack="$MKL"

Yes I see. If you are statically linking to MKL, you want to link to the
GNU OMP runtime for portability. Sorry about that.

> > But in order to compile had to edit src/modules/lapack/vecLibg95c.c
> > and comment out the include. Weird, since I am not building for Mac.
> 
> Please note the thing that ABI of fortran is different with Intel compiler
> and GNU compiler.
> difficult to detect the mistake.

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From savicky at cs.cas.cz  Tue Mar 17 11:10:28 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 17 Mar 2009 11:10:28 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <49BF6A3B.1080200@idi.ntnu.no>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
	<20090317060749.GA24730@cs.cas.cz> <49BF6A3B.1080200@idi.ntnu.no>
Message-ID: <20090317101028.GA17676@cs.cas.cz>

On Tue, Mar 17, 2009 at 10:15:39AM +0100, Wacek Kusnierczyk wrote:
...
> there's one more curiosity about factors, in particular, ordered factors:
> 
>     ord <- as.ordered(nums); ord
>     # [1] 0.300000000000000 0.3               0.3              
> 0.300000000000000
>     # Levels: 0.300000000000000 < 0.3 < 0.3 < 0.300000000000000
> 
>     ord[1] < ord[4]
>     # TRUE
>     ord[1] == ord[4]
>     # TRUE
...

The following workaround should help in most cases.

  nums <- (.3 + 2e-16 * c(-2,-1,1,2))
  nums # [1] 0.3 0.3 0.3 0.3
  nums <- signif(nums, digits=15)
  as.ordered(nums) # Levels: 0.3
  as.factor(nums) # Levels: 0.3

Petr.


From murdoch at stats.uwo.ca  Tue Mar 17 11:38:04 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 17 Mar 2009 06:38:04 -0400
Subject: [Rd] link in base help file fails.
In-Reply-To: <49BF1C84.80303@wehi.edu.au>
References: <49BF1C84.80303@wehi.edu.au>
Message-ID: <49BF7D8C.6040506@stats.uwo.ca>

On 16/03/2009 11:44 PM, Keith Satterley wrote:
> I run R on MS Windows. In R2.9.0dev, I type ?base to get "R help for package 
> base" to open. I then select ".First" from the list of contents, getting a page 
> headed: "Initialization at Start of an R Session". About half way down there is 
> a sentence:


Thanks for the report.  I can reproduce this problem with CHM help, but 
not HTML help.  I'll investigate, but it might be a limitation of the 
format.  (It's not new in R2.9.0, it is present in 2.8.1 as well.)

Duncan Murdoch

> 
> The command-line flag --vanilla implies --no-site-file, --no-init-file, 
> --no-restore and --no-environ. Under Windows, it also implies --no-Rconsole, 
> which prevents loading the ?Rconsole? file.
> 
> The last occurrence of the word Rconsole is in blue text and underlined, a link. 
> On clicking on this link, I get a page headed "This program cannot display the 
> webpage" with advice on "Most likely causes:" and "What you can try".
> 
> Other links work satisfactorily on that page. My internet connection is working.
> 
> I presume there is a problem with this Rconsole link.
> 
>  > sessionInfo()
> R version 2.9.0 Under development (unstable) (2009-03-13 r48127)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>  >
> 
> cheers,
> 
> Keith
> 
> ========================
> Keith Satterley
> Bioinformatics Division
> The Walter and Eliza Hall Institute of Medical Research
> Parkville, Melbourne,
> Victoria, Australia
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at u.washington.edu  Tue Mar 17 11:45:03 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 17 Mar 2009 03:45:03 -0700 (PDT)
Subject: [Rd] exporting s3 and s4 methods
Message-ID: <Pine.LNX.4.43.0903170345030.31782@hymn12.u.washington.edu>


If a package defined an S3 generic and an S4 generic for the same function (so as to add methods for S4 classes to the existing code), how do I set up the namespace to have them exported?

With 
import(stats)
exportMethods(bigglm)
importClassesFrom(DBI)
useDynLib(biglm)
export(biglm)
export(bigglm)
in NAMESPACE, the S3 generic is not exported.
> methods("bigglm")
[1] bigglm.RODBC*      bigglm.data.frame* bigglm.function*

    Non-visible functions are asterisked
Warning messages:
1: In findGeneric(generic.function, parent.frame()) :
   'bigglm' is a formal generic function; S3 methods will not likely be found
2: In methods("bigglm") : function 'bigglm' appears not to be generic


[This is R 2.7.2, admittedly a little ancient]

       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 17 11:57:14 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 17 Mar 2009 11:57:14 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <49BF6A3B.1080200@idi.ntnu.no>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>	<20090317060749.GA24730@cs.cas.cz>
	<49BF6A3B.1080200@idi.ntnu.no>
Message-ID: <49BF820A.908@idi.ntnu.no>

Wacek Kusnierczyk wrote:
>
>  
> there's one more curiosity about factors, in particular, ordered factors:
>
>     ord <- as.ordered(nums); ord
>     # [1] 0.300000000000000 0.3               0.3              
> 0.300000000000000
>     # Levels: 0.300000000000000 < 0.3 < 0.3 < 0.300000000000000
>
>     ord[1] < ord[4]
>     # TRUE
>     ord[1] == ord[4]
>     # TRUE
>   

as a corollary, the warning printed when comparing elements of a factor
is misleading:

    f = factor(1:2)
    f[1] < f[2]
    # [1] NA
    # Warning message:
    # In Ops.factor(f[1], f[2]) : < not meaningful for factors

    g = as.ordered(f)
    is.factor(g)
    # TRUE
    g[1] < g[2]
    # TRUE


< *is* meaningful for factors, though not for unordered ones.  the
warning is generated in Ops.factor, src/library/base/all.R:7162, and
with my limited knowledge of the r internals i can't judge how easy it
is to fix the problem.

vQ


From murdoch at stats.uwo.ca  Tue Mar 17 13:15:19 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 17 Mar 2009 08:15:19 -0400
Subject: [Rd] link in base help file fails.
In-Reply-To: <49BF1C84.80303@wehi.edu.au>
References: <49BF1C84.80303@wehi.edu.au>
Message-ID: <49BF9457.3090708@stats.uwo.ca>

On 16/03/2009 11:44 PM, Keith Satterley wrote:
> I run R on MS Windows. In R2.9.0dev, I type ?base to get "R help for package 
> base" to open. I then select ".First" from the list of contents, getting a page 
> headed: "Initialization at Start of an R Session". About half way down there is 
> a sentence:
> 
> The command-line flag --vanilla implies --no-site-file, --no-init-file, 
> --no-restore and --no-environ. Under Windows, it also implies --no-Rconsole, 
> which prevents loading the ?Rconsole? file.
> 
> The last occurrence of the word Rconsole is in blue text and underlined, a link. 
> On clicking on this link, I get a page headed "This program cannot display the 
> webpage" with advice on "Most likely causes:" and "What you can try".
> 
> Other links work satisfactorily on that page. My internet connection is working.
> 
> I presume there is a problem with this Rconsole link.

After a little looking, this turns out to be a limitation of the CHM 
help file production.  With other formats that support links you don't 
need to specify which package a link goes to, but with CHM help, you do. 
  Since Rconsole is documented in the utils package, this link from base 
failed in that format.

I've fixed other external links to that particular topic, but I imagine 
there are lots of other cross-package links that will still fail in CHM 
files.  Since we will likely replace the file conversion system soon, 
and since CHM files are no longer supported by Microsoft, I am not 
planning to try to fix the old conversion code.  If the fix was easy, it 
would have been in place from the beginning.  But if someone else wants 
to put together a patch (to share/perl/R/Rdconv.pm), I'll test it.

So for now I'd recommend using HTML help rather than CHM help.

Duncan Murdoch

> 
>  > sessionInfo()
> R version 2.9.0 Under development (unstable) (2009-03-13 r48127)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>  >
> 
> cheers,
> 
> Keith
> 
> ========================
> Keith Satterley
> Bioinformatics Division
> The Walter and Eliza Hall Institute of Medical Research
> Parkville, Melbourne,
> Victoria, Australia
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From didier_morel at yahoo.fr  Tue Mar 17 13:24:41 2009
From: didier_morel at yahoo.fr (Morel Didier)
Date: Tue, 17 Mar 2009 05:24:41 -0700 (PDT)
Subject: [Rd] R freeze when loading dll with dyn.load
Message-ID: <903318.56099.qm@web24715.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090317/2784ac9a/attachment.pl>

From simon.urbanek at r-project.org  Tue Mar 17 14:04:59 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Mar 2009 09:04:59 -0400
Subject: [Rd] R freeze when loading dll with dyn.load
In-Reply-To: <903318.56099.qm@web24715.mail.ird.yahoo.com>
References: <903318.56099.qm@web24715.mail.ird.yahoo.com>
Message-ID: <CF9C4DF9-FD71-4EE0-A641-AC40892BF94B@r-project.org>


On Mar 17, 2009, at 8:24 , Morel Didier wrote:

> Good morning,
>
> I am investigating dll import in R under Windows XP. Using examples  
> I found on the internet, I started with a very simple dll, e.g.  
> including only the basic function:
>
> void
> {
> *x2 = x*x;
> }sqr(doublex, double*x2)
>

This is not a valid C code. What you may have possibly meant is

void sqr(double *x, double *x2) {
  *x2 = *x * *x;
}

 > dyn.load("tt.dll")
 > .C("sqr",4,0)
[[1]]
[1] 4

[[2]]
[1] 16

Cheers,
S


> I compiled it as a dll with Eclipse and Cygwin's gcc.

You should be using MinGW - I don't think anything else is directly  
supported (see R Windows FAQ).

Cheers,
S


> It works when I call it with another simple .exe C program, compile  
> with Eclipse and gcc as well. I can do what I want with x2 after I  
> have called the function.
>
> However, R freezes when I try to load it with the following command:
>
> dyn.load('c:/.../sqr/Release/sqr.dll')
>
> I know the path I provide is correct, it's the same without the .dll  
> extension and providing an invalid path makes the function returning  
> an error message (LoadLibrary failure...) but not freeze. Has anyone  
> an idea of what is happening?
>
> Thanks for your help,
> Best regards,
> Didier.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Tue Mar 17 15:04:39 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 17 Mar 2009 10:04:39 -0400
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <20090317060749.GA24730@cs.cas.cz>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
	<20090317060749.GA24730@cs.cas.cz>
Message-ID: <8b356f880903170704x5816183of63b0220edef4a62@mail.gmail.com>

Petr,

Thank you for the detailed diagnosis of the bizarre behavior I
reported, which seems to indicate several distinct problems in the
underlying code:

1) Factor allows repeated levels, e.g. factor(c(1),c(1,1,1)), with no
warning or error.

2) Even from distinct inputs, factor of a numeric vector may generate
repeated levels, because it only uses 15 digits.

3) The algorithm to determine the shortest format is inconsistent with
the algorithm to actually print, giving pathological cases like 0.3
vs. 0.300000000000000.

About:

> In order to avoid using 15 digits in as.character(), we can use round(,digits),
> with digits argument appropriate for the current situation.
>
> ?> fact <- as.factor(round(nums,digits=1)); fact
> ?[1] 0.3 0.3 0.3 0.3
> ?Levels: 0.3

The original problem was testing whether a floating-point number was a
member of a vector.  rounding and then converting to a factor seem
like a very poor way of doing that, even if the above problems were
resolved.  Comparing with a tolerance seems much more robust, clean,
and efficient.

           -s


From rhurlin at gwdg.de  Tue Mar 17 16:11:43 2009
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 17 Mar 2009 16:11:43 +0100
Subject: [Rd] R does not compile any more on FreeBSD 8.0-CURRENT
Message-ID: <49BFBDAF.304@gwdg.de>

On a recent FreeBSD 8.0-CURRENT (i386) building R (any version) breaks 
with the following messages:

----------------------------------------------------------------------
[...snip...]
gcc -std=gnu99 -I. -I../../src/include -I../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c wilcox.c -o wilcox.o
gcc -std=gnu99 -I. -I../../src/include -I../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c signrank.c -o signrank.o
rm -rf libnmath.a
ar cr libnmath.a mlutils.o d1mach.o i1mach.o fmax2.o fmin2.o fprec.o 
fround.o ftrunc.o sign.o fsign.o imax2.o imin2.o chebyshev.o log1p.o 
expm1.o lgammacor.o gammalims.o stirlerr.o bd0.o gamma.o lgamma.o 
gamma_cody.o beta.o lbeta.o polygamma.o bessel_i.o bessel_j.o bessel_k.o
bessel_y.o choose.o snorm.o sexp.o dgamma.o pgamma.o qgamma.o rgamma.o
dbeta.o pbeta.o qbeta.o rbeta.o dunif.o punif.o qunif.o runif.o dnorm.o 
pnorm.o qnorm.o rnorm.o dlnorm.o plnorm.o qlnorm.o rlnorm.o df.o pf.o
qf.o rf.o dnf.o dt.o pt.o qt.o rt.o dnt.o dchisq.o pchisq.o qchisq.o
rchisq.o rnchisq.o dbinom.o pbinom.o qbinom.o rbinom.o rmultinom.o
dcauchy.o pcauchy.o qcauchy.o rcauchy.o dexp.o pexp.o qexp.o rexp.o 
dgeom.o pgeom.o qgeom.o rgeom.o dhyper.o phyper.o qhyper.o rhyper.o
dnbinom.o pnbinom.o qnbinom.o rnbinom.o dpois.o ppois.o qpois.o rpois.o 
dweibull.o pweibull.o qweibull.o rweibull.o dlogis.o plogis.o qlogis.o 
rlogis.o dnchisq.o pnchisq.o qnchisq.o dnbeta.o pnbeta.o qnbeta.o pnf.o 
pnt.o qnf.o qnt.o ptukey.o qtukey.o toms708.o wilcox.o signrank.o
ranlib libnmath.a
config.status: creating src/unix/Makefile
make: /usr/local/R-devel/srcunix: No such file or directory
*** Error code 2

Stop in /usr/local/R-devel/src/unix.
*** Error code 1

Stop in /usr/local/R-devel/src.
*** Error code 1

Stop in /usr/local/R-devel.
----------------------------------------------------------------------

The path /usr/local/R-devel/srcunix does not exist but .../src/unix/ 
does. As a workaround I am able to do

cd src/unix
make
cd ../..
make

A second break with the same error does occur at 
/usr/local/R-devel/srcmain. Again this workaround works

cd src/main
make
cd ../..
make

Now the compilation finished without another break. What could be the 
reason for this 'path break'?  So long it seems that this error on 
FreeBSD 8.0-CURRENT only appears with R and no other third party software.

Potentially this is an error within latest FreeBSD code (?) and I have 
to ask on the FreeBSD mailing list. But before I wanted to ask on 
r-devel at . Perhaps someone here has an idea? Any hints are very welcome.

Thanks in advance,
Rainer Hurling


From savicky at cs.cas.cz  Tue Mar 17 16:21:44 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 17 Mar 2009 16:21:44 +0100
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <8b356f880903170704x5816183of63b0220edef4a62@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903161553u7969905ck69e7ebd7831f1f3a@mail.gmail.com>
	<8b356f880903161639q29e8bf4eh29624516bf8aa783@mail.gmail.com>
	<20090317060749.GA24730@cs.cas.cz>
	<8b356f880903170704x5816183of63b0220edef4a62@mail.gmail.com>
Message-ID: <20090317152144.GB3740@cs.cas.cz>

On Tue, Mar 17, 2009 at 10:04:39AM -0400, Stavros Macrakis wrote:
...
> 1) Factor allows repeated levels, e.g. factor(c(1),c(1,1,1)), with no
> warning or error.

Yes, this is a confusing behavior, since repeated levels are never meaningful.

> 2) Even from distinct inputs, factor of a numeric vector may generate
> repeated levels, because it only uses 15 digits.

I think, 15 digits is a reasonable choice. Mapping double precision numbers
and character strings with a given decimal precision is never bijective.
With 15 digits, we can achive that every character value has unique double
precision representation, but not vice versa. With 17 digits, we have a unique
character string for each double precision number, but not vice versa.
What is better?

Specification of as.character says() that the numbers are represented with
15 significant digits. So, I think, if as.factor() applies signif(,digits=15)
to a numeric vector before determining the levels using sort(unique.default(x),
this could help to eliminate most of the problems without being in conflict
with the existing specification.

> 3) The algorithm to determine the shortest format is inconsistent with
> the algorithm to actually print, giving pathological cases like 0.3
> vs. 0.300000000000000.

I do not exactly understand what you mean by inconsistent. If you do
  nums <- (.3 + 2e-16 * c(-2,-1,1,2))
  options(digits=15)
  for (x in nums) print(x)
  # [1] 0.300000000000000
  # [1] 0.3
  # [1] 0.3
  # [1] 0.300000000000000
  as.character(nums)
  # [1] "0.300000000000000" "0.3"               "0.3"              
  # [4] "0.300000000000000"
then print and as.character are consistent. Printing the whole vector
behaves differently, since it uses the same format for all numbers.

> The original problem was testing whether a floating-point number was a
> member of a vector.  rounding and then converting to a factor seem
> like a very poor way of doing that, even if the above problems were
> resolved.  Comparing with a tolerance seems much more robust, clean,
> and efficient.

Definitely, using comparison tolerance is a meaningful approach. Its disadvantage
is that the relation abs(x - y) <= eps is not transitive. So, it may also produce
confusing results in some situations. I think that one has to choose the right
solution depending on the application.

Petr.


From chiefmurphy at gmail.com  Tue Mar 17 16:26:03 2009
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Tue, 17 Mar 2009 08:26:03 -0700
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>
	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
Message-ID: <48f8cced0903170826m6957766dj402bfdfe1390368d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090317/05401ebf/attachment.pl>

From jmc at r-project.org  Tue Mar 17 17:41:57 2009
From: jmc at r-project.org (John Chambers)
Date: Tue, 17 Mar 2009 09:41:57 -0700
Subject: [Rd] exporting s3 and s4 methods
In-Reply-To: <Pine.LNX.4.43.0903170345030.31782@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0903170345030.31782@hymn12.u.washington.edu>
Message-ID: <49BFD2D5.60605@r-project.org>

You shouldn't have to export the S3 function:  in the normal practice, 
setGeneric("biglm") or just a setMethod("biglm", ....) will cause the S3 
function (like any existing function) to become the default method for 
the S4 generic.  There is only one object called "biglm".

It's important though to use the default, one argument, call to 
setGeneric().  Otherwise the two functions are not consistent and can't 
exist in the same namespace.  Also, the situation is different if the S3 
function is in another package, as discussed in a previous thread here 
recently.

The warning messages below, if they are still current, are misleading, 
and usually outright wrong.  The code should look at the default method 
for the S4 generic.

John

PS: if this is the biglm() in the biglm package, the current CRAN 
version is not a generic of any flavor.  Presumably this is a new 
version?  Just curious, this has no effect on the above comments.

Thomas Lumley wrote:
>
> If a package defined an S3 generic and an S4 generic for the same 
> function (so as to add methods for S4 classes to the existing code), 
> how do I set up the namespace to have them exported?
>
> With import(stats)
> exportMethods(bigglm)
> importClassesFrom(DBI)
> useDynLib(biglm)
> export(biglm)
> export(bigglm)
> in NAMESPACE, the S3 generic is not exported.
>> methods("bigglm")
> [1] bigglm.RODBC*      bigglm.data.frame* bigglm.function*
>
>    Non-visible functions are asterisked
> Warning messages:
> 1: In findGeneric(generic.function, parent.frame()) :
>   'bigglm' is a formal generic function; S3 methods will not likely be 
> found
> 2: In methods("bigglm") : function 'bigglm' appears not to be generic
>
>
> [This is R 2.7.2, admittedly a little ancient]
>
>       -thomas
>
> Thomas Lumley            Assoc. Professor, Biostatistics
> tlumley at u.washington.edu    University of Washington, Seattle
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From vogranovich at jumptrading.com  Tue Mar 17 18:14:45 2009
From: vogranovich at jumptrading.com (Vadim Ogranovich)
Date: Tue, 17 Mar 2009 12:14:45 -0500
Subject: [Rd] lsfit w/ rank-deficient x
In-Reply-To: <22D850BC39A25742977325ADDE208E770271F71FC6@chiexchange02.w2k.jumptrading.com>
References: <22D850BC39A25742977325ADDE208E770271F71FC6@chiexchange02.w2k.jumptrading.com>
Message-ID: <22D850BC39A25742977325ADDE208E770271F71FC9@chiexchange02.w2k.jumptrading.com>

Actually, the correct permutation is given by the inverse of qr$pivot:

foo$coefficients[foo$qr$pivot] <- foo$coefficients

Here foo is an object returned by lsfit, see below.



-----Original Message-----
From: Vadim Ogranovich
Sent: Friday, March 13, 2009 5:25 PM
To: 'r-devel at r-project.org'
Subject: lsfit w/ rank-deficient x

Dear R-devel,

It seems that lsfit incorrectly reports coefficients when the input matrix 'x' is rank-deficient, see the example below:

## here values of 'b' and 'c' are incorrectly swapped
> x <- cbind(a=rnorm(100), b=0, c=rnorm(100)); y <- rnorm(100); lsfit(x, y)$coef
 Intercept          a          b          c
-0.0227787  0.1042860 -0.1729261  0.0000000
Warning message:
In lsfit(x, y) : 'X' matrix was collinear

## correct values
> lsfit(x[,-2], y)$coef
 Intercept          a          c
-0.0227787  0.1042860 -0.1729261


I looked inside the lsfit code and it appears that even though rank-deficiency is detected there is no attempt to patch the coefficients. Why is that?

Taking clues from the code it appears that the following trick might do the work:

> foo <- lsfit(x, y)
Warning message:
In lsfit(x, y) : 'X' matrix was collinear
> structure(foo$coefficients[foo$qr$pivot], names=names(foo$coefficients))
  Intercept           a           b           c
 0.14857345 -0.07473099  0.00000000  0.12835155


Is this reliable or there are cases when it may fail?

Thanks,
Vadim

P.S.

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          7.1
year           2008
month          06
day            23
svn rev        45970
language       R
version.string R version 2.7.1 (2008-06-23)
>

Note: This email is for the confidential use of the named addressee(s) only and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you are hereby notified that any review, dissemination or copying of this email is strictly prohibited, and to please notify the sender immediately and destroy this email and any attachments.  Email transmission cannot be guaranteed to be secure or error-free.  Jump Trading, therefore, does not make any guarantees as to the completeness or accuracy of this email or any attachments.  This email is for informational purposes only and does not constitute a recommendation, offer, request or solicitation of any kind to buy, sell, subscribe, redeem or perform any type of transaction of a financial product.


From tlumley at u.washington.edu  Tue Mar 17 18:15:56 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 17 Mar 2009 10:15:56 -0700 (PDT)
Subject: [Rd] exporting s3 and s4 methods
In-Reply-To: <49BFD2D5.60605@r-project.org>
Message-ID: <Pine.LNX.4.43.0903171015560.1676@hymn13.u.washington.edu>

On Tue, 17 Mar 2009, John Chambers wrote:

> It's important though to use the default, one argument, call to setGeneric(). 
> Otherwise the two functions are not consistent and can't exist in the same 
> namespace.

Thanks. Does this include restricting which arguments are used for dispatch? I have
  setGeneric("bigglm", signature=c("formula","data"))
to dispatch just on the first two arguments.

I will try to run everything on my desktop back in Seattle to see if there are still problems under r-devel -- my laptop is staying with its current version of R until my book goes to the publisher.


> PS: if this is the biglm() in the biglm package, the current CRAN version is 
> not a generic of any flavor.  Presumably this is a new version?

You're missing a 'g'. It's bigglm(), which is S3-generic already.  The current version uses S3 inheritance on SQLiteConnection (which works, but doesn't extend to other DBIConnection objects, as you pointed out previously).


       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From drosen at stat.berkeley.edu  Tue Mar 17 18:25:46 2009
From: drosen at stat.berkeley.edu (David Rosenberg)
Date: Tue, 17 Mar 2009 13:25:46 -0400
Subject: [Rd] Putting demo shell scripts, text files,
	and RScript files with a package?
Message-ID: <DFA3F1EC-ECC0-4E95-BB7D-F8EE561A2D89@stat.berkeley.edu>

I've written a package to assist with using R in Hadoop Streaming.

The main point of the package is to help make command-line runnable  
RScript files.  I'd like to provide a demo RScript file, a demo data  
file (e.g. a plaintext file, not something already processed by R) ,  
as well as demo bash shell scripts that demonstrate how to run the job  
from the command line and in a Hadoop cluster.

My best idea so far for distributing these files is to package the  
contents of these files as a list of strings in a data file in the  
data directory, and include a function in the package, say  
generateDemoFolder(targetDir), that writes the files to a user- 
specified directory, ready for use from the command line.

Any suggestions?


Thanks,


David


From murdoch at stats.uwo.ca  Tue Mar 17 20:15:25 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 17 Mar 2009 15:15:25 -0400
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <48f8cced0903170826m6957766dj402bfdfe1390368d@mail.gmail.com>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com>
	<48f8cced0903170826m6957766dj402bfdfe1390368d@mail.gmail.com>
Message-ID: <49BFF6CD.7090302@stats.uwo.ca>

On 3/17/2009 11:26 AM, Daniel Murphy wrote:
> Is this a reasonably fast way to do an approximate match of a vector x to
> values in a list?
> 
> match.approx  <- function(x,list,tol=.0001)
>     sapply(apply(abs(outer(list,x,"-"))<tol,2,which),"[",1)

If you are willing to assume that the list values are all multiples of 
2*tol, then it's easy:  just divide both x and list by 2*tol, round to 
nearest integer, and use the regular match function.

If not, it becomes harder; I'd probably use a solution like yours.

Duncan Murdoch

> 
> Thanks.
> -Dan
> 
> On Mon, Mar 16, 2009 at 8:24 AM, Stavros Macrakis <macrakis at alum.mit.edu>wrote:
> 
>> Well, first of all, seq(from=.2,to=.3) gives c(0.2), so I assume you
>> really mean something like seq(from=.2,to=.3,by=.1), which gives
>> c(0.2, 0.3).
>>
>> %in% tests for exact equality, which is almost never a good idea with
>> floating-point numbers.
>>
>> You need to define what exactly you mean by "in" for floating-point
>> numbers.  What sort of tolerance are you willing to allow?
>>
>> Some possibilities would be for example:
>>
>> approxin <- function(x,list,tol) any(abs(list-x)<tol)   # absolute
>> tolerance
>>
>> rapproxin <- function(x,list,tol) (x==0 && 0 %in% list) ||
>> any(abs((list-x)/x)<=tol,na.rm=TRUE)
>>     # relative tolerance; only exact 0 will match 0
>>
>> Hope this helps,
>>
>>          -s
>>
>> On Mon, Mar 16, 2009 at 9:36 AM, Daniel Murphy <chiefmurphy at gmail.com>
>> wrote:
>> > Hello:I am trying to match the value 0.3 in the sequence seq(.2,.3). I
>> get
>> >> 0.3 %in% seq(from=.2,to=.3)
>> > [1] FALSE
>> > Yet
>> >> 0.3 %in% c(.2,.3)
>> > [1] TRUE
>> > For arbitrary sequences, this "invisible .3" has been problematic. What
>> is
>> > the best way to work around this?
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From zwerdlds at gmail.com  Tue Mar 17 20:51:44 2009
From: zwerdlds at gmail.com (David Zwerdling)
Date: Tue, 17 Mar 2009 12:51:44 -0700
Subject: [Rd] Embedding R Engine in Cocoa
Message-ID: <a5fee3720903171251n3f5db115l982f886d23062f3c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090317/df6a69d7/attachment.pl>

From armstrong.whit at gmail.com  Tue Mar 17 21:45:40 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 17 Mar 2009 16:45:40 -0400
Subject: [Rd] question on "row.names" attribute of dataframe when called
	from a compiled package
Message-ID: <8ec76080903171345h98a17efx67aed1f861d0d271@mail.gmail.com>

Why does the following show a class attribute of "character" when
using the interpreter:

x <- data.frame(hat=1:10)
class(rownames(x))  ## returns [1] "character"

but when called from c/cpp, the rownames attribute has no class
attribute, and is in fact a vector of INTSXP?

> .Call("print_class_of_rownames", x, package = "test")
length(x): 10
TYPEOF(x): 13
R_ClassSymbol is null.
NULL
>

is this the intended behaviour?

-Whit


here is my test code:

SEXP print_class_of_rownames(SEXP dataframe_sexp) {
  SEXP x = getAttrib(dataframe_sexp,install("row.names"));
  cout << "length(x): " << length(x) << endl;
  cout << "TYPEOF(x): " << TYPEOF(x) << endl;
  if(getAttrib(x, R_ClassSymbol)==R_NilValue) {
    cout << "R_ClassSymbol is null." << endl;
  } else {
    cout << "R_ClassSymbol is a good value." << endl;
  }
  return R_NilValue;
}


From simon.urbanek at r-project.org  Tue Mar 17 22:49:33 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Mar 2009 17:49:33 -0400
Subject: [Rd] question on "row.names" attribute of dataframe when called
	from a compiled package
In-Reply-To: <8ec76080903171345h98a17efx67aed1f861d0d271@mail.gmail.com>
References: <8ec76080903171345h98a17efx67aed1f861d0d271@mail.gmail.com>
Message-ID: <C6DE79D9-41FF-40BA-AD60-0E93E0F0644D@r-project.org>


On Mar 17, 2009, at 16:45 , Whit Armstrong wrote:

> Why does the following show a class attribute of "character" when  
> using the interpreter:
>
> x <- data.frame(hat=1:10)
> class(rownames(x))  ## returns [1] "character"
>
> but when called from c/cpp, the rownames attribute has no class  
> attribute

Note the difference between class("foo") and attr("foo", "class") -  
some classes are implicit.


> , and is in fact a vector of INTSXP?
>

Because the internal representation of automatic row names is c(NA, - 
dim(d)[1]) where d is the data frame. This is not exposed at the R  
level, though, since it's an implementation optimization.


>> .Call("print_class_of_rownames", x, package = "test")
> length(x): 10
> TYPEOF(x): 13
> R_ClassSymbol is null.
> NULL
>>
>
> is this the intended behaviour?
>

Yes - it saves a lot of space when using large datasets with automatic  
names.

Cheers,
Simon


> -Whit
>
>
> here is my test code:
>
> SEXP print_class_of_rownames(SEXP dataframe_sexp) {
>  SEXP x = getAttrib(dataframe_sexp,install("row.names"));
>  cout << "length(x): " << length(x) << endl;
>  cout << "TYPEOF(x): " << TYPEOF(x) << endl;
>  if(getAttrib(x, R_ClassSymbol)==R_NilValue) {
>    cout << "R_ClassSymbol is null." << endl;
>  } else {
>    cout << "R_ClassSymbol is a good value." << endl;
>  }
>  return R_NilValue;
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Tue Mar 17 23:24:04 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Mar 2009 18:24:04 -0400
Subject: [Rd] Embedding R Engine in Cocoa
In-Reply-To: <a5fee3720903171251n3f5db115l982f886d23062f3c@mail.gmail.com>
References: <a5fee3720903171251n3f5db115l982f886d23062f3c@mail.gmail.com>
Message-ID: <4FC4F408-17D6-4B73-A18D-FAB4E61C1F7E@r-project.org>


On Mar 17, 2009, at 15:51 , David Zwerdling wrote:

> Hello Everyone,
> I'm attempting to use the R-Engine from the Mac R.app GUI project to  
> embed R
> in an Objective-C application I'm writing.
>
> However, after a few days of trying, dependencies to the GUI keep  
> tying me
> down.  I don't need anything fancy, I'm just feeding in vectors and  
> running
> regressions on them, but even that seems to escape me.
>
> I've seen on the outdated R/Cocoa page that there's a standalone  
> engine *
> somewhere.*  But I don't know if that's outdated information too.
>

There is a stand-alone version, indeed, at
https://svn.r-project.org/R-packages/branches/stand-alone-REngine

It needed a few small adjustments to match current R version, but it  
should be ok now. Don't forget to use R CMD when running your program,  
though, so the demo in the above should work with

make
R CMD ./test

The default setup is now OS X but there are instructions in the  
Makefile on how to use it on other unices and I have tested it  
successfully with Linux and libFoundation.

Cheers,
Simon



> So, is there a simple project or tutorial out there that will allow  
> me to
> interact with R programmatically?
>
> Thanks,
> David Zwerdling
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jmc at r-project.org  Wed Mar 18 01:59:49 2009
From: jmc at r-project.org (John Chambers)
Date: Tue, 17 Mar 2009 17:59:49 -0700
Subject: [Rd] exporting s3 and s4 methods
In-Reply-To: <Pine.LNX.4.43.0903171015560.1676@hymn13.u.washington.edu>
References: <Pine.LNX.4.43.0903171015560.1676@hymn13.u.washington.edu>
Message-ID: <49C04785.80406@r-project.org>

Thomas Lumley wrote:
> On Tue, 17 Mar 2009, John Chambers wrote:
>
>> It's important though to use the default, one argument, call to 
>> setGeneric(). Otherwise the two functions are not consistent and 
>> can't exist in the same namespace.
>
> Thanks. Does this include restricting which arguments are used for 
> dispatch? I have
> setGeneric("bigglm", signature=c("formula","data"))
> to dispatch just on the first two arguments.
That seems not to disturb anything. (It's really only the arguments 
affecting the default that would break things directly. The other 
non-defaults are a problem if multiple packages turn the same S3 
function into a generic in inconsistent ways. But here you own both the 
S3 and S4 versions.)

(R2.8.1)> foo <- function(x,y,z)UseMethod("foo")
(R2.8.1)> setGeneric("foo", signature = c("x", "y"))
[1] "foo"
(R2.8.1)> getMethod(foo) # the default
Method Definition (Class ?derivedDefaultMethod?):

function (x, y, z)
UseMethod("foo")

Signatures:

target
defined
(R2.8.1)> foo at signature
[1] "x" "y"

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Wed Mar 18 08:52:51 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Mar 2009 08:52:51 +0100
Subject: [Rd] Putting demo shell scripts, text files,
	and RScript files with a package?
In-Reply-To: <DFA3F1EC-ECC0-4E95-BB7D-F8EE561A2D89@stat.berkeley.edu>
References: <DFA3F1EC-ECC0-4E95-BB7D-F8EE561A2D89@stat.berkeley.edu>
Message-ID: <18880.43091.248097.403193@stat.math.ethz.ch>

>>>>> "DR" == David Rosenberg <drosen at stat.berkeley.edu>
>>>>>     on Tue, 17 Mar 2009 13:25:46 -0400 writes:

    DR> I've written a package to assist with using R in Hadoop Streaming.
    DR> The main point of the package is to help make command-line runnable  
    DR> RScript files.  I'd like to provide a demo RScript file, a demo data  
    DR> file (e.g. a plaintext file, not something already processed by R) ,  
    DR> as well as demo bash shell scripts that demonstrate how to run the job  
    DR> from the command line and in a Hadoop cluster.

    DR> My best idea so far for distributing these files is to package the  
    DR> contents of these files as a list of strings in a data file in the  
    DR> data directory, and include a function in the package, say  
    DR> generateDemoFolder(targetDir), that writes the files to a user- 
    DR> specified directory, ready for use from the command line.

I think you've overlooked the  possibility  of   <sourcePkg>/inst/

I would use something like  <sourcePkg>/inst/scripts/
which will become           <installedPkg>/scripts/

[accessible from within R  by  system.file("scripts", package= "<yourPkg>")

One "famous" example being the  R scripts for Venables&Ripley's
MASS book, available from all R installations via
     system.file("scripts", package="MASS")

e.g.

 > list.files(system.file("scripts", package="MASS"))
 [1] "ch01.R" "ch02.R" "ch03.R" "ch04.R" "ch05.R" "ch06.R" "ch07.R" "ch08.R" "ch09.R"
[10] "ch10.R" "ch11.R" "ch12.R" "ch13.R" "ch14.R" "ch15.R" "ch16.R"

or 
 > source(system.file("scripts", "ch01.R", package="MASS"))

{ which ends in an error: It's not made for source();
  it might well be source()able if  
 
  'if(interactive()) '     where replaced by
  'if(dev.interactive()) ' 

}

Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Wed Mar 18 13:05:59 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Mar 2009 12:05:59 +0000 (GMT)
Subject: [Rd] Bug in Rdconv(.pm) (PR#13575)
In-Reply-To: <alpine.LFD.2.00.0903051850210.24770@gannet.stats.ox.ac.uk>
References: <20090305182510.B50602832191@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0903051850210.24770@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.00.0903181204060.11340@gannet.stats.ox.ac.uk>

This is fixed now in R-devel.

Meanwhile a similar issue was found with \kbd in a \value{} preamble, 
but only in Perl 5.10.x (and the same fix resolves that).

On Thu, 5 Mar 2009, Prof Brian Ripley wrote:

> The problem is that \pkg gets included (unescaped) in a Perl substitution, 
> and in modern Perl \p has a meaning (Unicode property).
>
> Needs to be escaped/quoted, or the code to work a different way (which is 
> probably preferable).
>
> On Thu, 5 Mar 2009, ligges at statistik.tu-dortmund.de wrote:
>
>> For the record (and as privately discussed with Brian Ripley), happens
>> with all recent versions of R including R-devel from today:
>> 
>> 
>> Consider a simple a.Rd file containing the lines
>> 
>> ==================
>> \name{a}
>> \title{a}
>> \value{\code{a} \code{\link[a]{a}} \pkg{a}
>>    \item{a}{a}
>> }
>> ==================
>> 
>> 
>> with these lines, I get, e.g.:
>> 
>> 
>> 
>> ==================
>> R CMD Rdconv --type="txt" a.Rd
>> 
>> a                  package:unknown                  R Documentation
>> 
>> a
>> 
>> Value:
>>
>>     'a' 'a' 'a'
>> Can't find Unicode property definition "k" at
>> d:/Rcompile/recent/R/share/perl/R/Rdconv.pm line 2173,
>> <$rdfile> line 5.
>> ==================
>> 
>> Version:
>>  platform = i386-pc-mingw32
>>  arch = i386
>>  os = mingw32
>>  system = i386, mingw32
>>  status = Under development (unstable)
>>  major = 2
>>  minor = 9.0
>>  year = 2009
>>  month = 03
>>  day = 03
>>  svn rev = 48046
>>  language = R
>>  version.string = R version 2.9.0 Under development (unstable)
>> (2009-03-03 r48046)
>> 
>> Windows Server 2008 x64 (build 6001) Service Pack 1
>> 
>> Locale:
>> LC_COLLATE=C;LC_CTYPE=German_Germany.1252;LC_MONETARY=C;LC_NUMERIC=C;LC_TIME=C
>> 
>> Search Path:
>>  .GlobalEnv, package:stats, package:graphics, package:grDevices,
>> package:utils, package:datasets, package:methods, Autoloads, package:base
>> 
>> 
>> 
>> Uwe Ligges
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rphilosof at health.sdu.dk  Wed Mar 18 13:59:13 2009
From: rphilosof at health.sdu.dk (Rune Schjellerup Philosof)
Date: Wed, 18 Mar 2009 13:59:13 +0100
Subject: [Rd]  R thread safe
References: 1131389848.436fa39855a52@webmail.unibas.ch
Message-ID: <49C0F021.8000108@health.sdu.dk>

Duncan Temple Lang wrote (Mon Nov 7 22:35:22 CET 2005):
>R is not yet thread safe.
>We are working on it, and I hope to make some progress before
>the end of the year.  (This one even!)
>
> D.

How is this going along?

For some things it would be simpler to use threads compared to
processes, to avoid the added complexity of passing the results back to
a master process.

With the emerging multicore processors it is essential that users can
easily make use of them.

A simple example of use:
  data1 <- data2 <- matrix(0, r, c)
  dataFiller <- function(i) {
   tmp <- someCalculation(i)
   data1[, i] <<- tmp$result1
   data2[, i] <<- tmp$result2
  }
  runParallelInThreads(1:c, dataFiller)

If this can be done almost as fast and simple with processes, for
instance using the multicore package, then I think it needs to be better
documented.

-- 
Regards
Rune Schjellerup Philosof


From michael_karsh at earthlink.net  Wed Mar 18 08:15:08 2009
From: michael_karsh at earthlink.net (michael_karsh at earthlink.net)
Date: Wed, 18 Mar 2009 08:15:08 +0100 (CET)
Subject: [Rd] lm function (PR#13608)
Message-ID: <20090318071508.D040A2832197@mail.pubhealth.ku.dk>

Full_Name: Michael Aaron Karsh
Version: 2.8.0
OS: Windows XP
Submission from: (NULL) (75.61.109.172)


I tried using the lm function to regress the third column listed below on the
second column listed below.  It gave me an error message.  My code is below.

> HDISWLSdata=read.table("RHDISWLS.txt")
> HDISWLSdata
                           V1  V2   V3
1                     DENMARK .82 .949
2                 SWITZERLAND .82 .955
3                     AUSTRIA .78 .948
4                     ICELAND .78 .968
5                     BAHAMAS .77 .845
6                     FINLAND .77 .952
7                      SWEDEN .77 .956
8                      BHUTAN .76 .579
9            BRUNEIDARUSSALAM .76 .894
10                     CANADA .76 .961
11                    IRELAND .76 .959
12                 LUXEMBOURG .76 .944
13                  COSTARICA .75 .846
14                      MALTA .75 .878
15                NETHERLANDS .75 .953
16          ANTIGUAANDBARBUDA .74 .815
17                   MALAYSIA .74 .811
18                 NEWZEALAND .74 .943
19                     NORWAY .74 .968
20                 SEYCHELLES .74 .843
21            STKITTSANDNEVIS .74 .821
22                        UAE .74 .868
23                        USA .74 .951
24                    VANUATU .74 .674
25                  VENEZUELA .74 .792
26                  AUSTRALIA .73 .962
27                   BARBADOS .73 .892
28                    BELGIUM .73 .946
29                   DOMINICA .73 .798
30                       OMAN .73 .814
31                SAUDIARABIA .73 .812
32                   SURINAME .73 .774
33                    BAHRAIN .72 .866
34                   COLUMBIA .72 .791
35                    GERMANY .72 .935
36                     GUYANA .72  .75
37                   HONDURAS .72   .7
38                     KUWAIT .72 .891
39                     PANAMA .72 .812
40  STVINCENTANDTHEGRENADINES .72 .761
41              UNITEDKINGDOM .71 .946
42          DOMINICANREPUBLIC  .7 .779
43                  GUATEMALA  .7 .689
44                    JAMAICA  .7 .736
45                      QATAR  .7 .875
46                      SPAIN  .7 .949
47                    STLUCIA  .7 .795
48                     BELIZE .69 .778
49                     CYPRUS .69 .903
50                      ITALY .69 .941
51                     MEXICO .69 .829
52                  SINGAPORE .69 .922
53             SOLOMONISLANDS .69 .602
54          TRINIDADANDTOBAGO .69 .814
55                  ARGENTINA .68 .869
56                       FIJI .67 .762
57                     ISRAEL .67 .932
58                   MONGOLIA .67   .7
59         SAOTOMEANDPRINCIPE .67 .654
60                 ELSALVADOR .66 .735
61                     FRANCE .66 .952
62                   HONGKONG .66 .937
63                  INDONESIA .66 .728
64                 KYRGYZSTAN .66 .696
65                   MALDIVES .66 .741
66                   SLOVENIA .66 .917
67                     TAIWAN .66 .925
68                  EASTTIMOR .66 .514
69                      TONGA .66 .819
70                      CHILE .65 .867
71                    GRENADA .65 .777
72                  MAURITIUS .65 .804
73                    NAMIBIA .65  .65
74                   PARAGUAY .65 .755
75                   THAILAND .65 .781
76              CZECHREPUBLIC .64 .891
77                PHILIPPINES .64 .771
78                    TUNISIA .64 .766
79                 UZBEKISTAN .64 .702
80                     BRAZIL .63   .8
81                      CHINA .63 .777
82                       CUBA .63 .838
83                     GREECE .63 .926
84                  NICARAGUA .63  .71
85             PAPUANEWGUINEA .63  .53
86                    URUGUAY .63 .852
87                      GABON .62 .677
88                      GHANA .62 .553
89                      JAPAN .62 .953
90                      YEMEN .62 .508
91                   PORTUGAL .61 .897
92                   SRILANKA .61 .743
93                 TAJIKISTAN .61 .673
94                    VIETNAM .61 .733
95                       IRAN  .6 .759
96                    COMOROS .59 .561
97                    CROATIA .59  .85
98                     POLAND .59  .87
99                  CAPEVERDE .58 .736
100                KAZAKHSTAN .58 .794
101                MADAGASCAR .58 .533
102                SOUTHKOREA .58 .921
103                BANGLADESH .57 .547
104                     CONGO .57 .548
105                    GAMBIA .57 .502
106                   HUNGARY .57 .874
107                     LIBYA .57 .818
108               SOUTHAFRICA .57 .674
109                  CAMBODIA .56 .598
110                   ECUADOR .56 .772
111                     KENYA .56 .521
112                   LEBANON .56 .772
113                   MOROCCO .56 .646
114                      PERU .56 .773
115                   SENEGAL .56 .499
116                   BOLIVIA .55 .695
117                     HAITI .55 .529
118                     NEPAL .55 .534
119                   NIGERIA .55  .47
120                  TANZANIA .55 .467
121                     BENIN .54 .437
122                  BOTSWANA .54 .654
123              GUINEABISSAU .54 .374
124                     INDIA .54 .619
125                      LAOS .54 .601
126                MOZAMBIQUE .54 .384
127                 PALESTINE .54 .731
128                  SLOVAKIA .54 .863
129                     BURMA .53 .583
130                      MALI .53  .38
131                MAURITANIA .53  .55
132                    TURKEY .53 .775
133                   ALGERIA .52 .733
134          EQUATORIALGUINEA .52 .642
135                   ROMANIA .52 .813
136     BOSNIAANDHERZEGOVENIA .51 .803
137                  CAMEROON .51 .532
138                   ESTONIA .51  .86
139                    GUINEA .51 .456
140                    JORDAN .51 .773
141                     SYRIA .51 .724
142               SIERRALEONE  .5 .336
143                AZERBAIJAN .49 .746
144    CENTRALAFRICANREPUBLIC .49 .384
145                 MACEDONIA .49 .801
146                      TOGO .49 .512
147                    ZAMBIA .49 .434
148                    ANGOLA .48 .446
149                  DJIBOUTI .48 .516
150                     EGYPT .48 .708
151               BURKINAFASO .47  .37
152                  ETHIOPIA .47 .406
153                    LATVIA .47 .855
154                 LITHUANIA .47 .862
155                    UGANDA .47 .505
156                   ALBANIA .46 .801
157                    MALAWI .46 .437
158                      CHAD .45 .388
159                IVORYCOAST .45 .432
160                     NIGER .45 .374
161                   ERITREA .44 .483
162                    RWANDA .44 .452
163                  BULGARIA .43 .824
164                   LESOTHO .43 .549
165                  PAKISTAN .43 .551
166                    RUSSIA .43 .802
167                 SWAZILAND .42 .547
168                   GEORGIA .41 .745
169                   BELARUS  .4 .804
170              TURKMENISTAN  .4 .713
171                   ARMENIA .37 .775
172                     SUDAN .36 .526
173                   UKRAINE .36 .788
174                   MOLDOVA .35 .708
175                     ZAIRE .33 .411
176                  ZIMBABWE .33 .513
177                   BURUNDI  .3    ?
178                         ?   ? .413
> country <- HDISWLSdata[,1]
> SWLS <- HDISWLSdata[,2]
> HDI <- HDISWLSdata[,2]
> HDI <- HDISWLSdata[,3]
> country
  [1] DENMARK                   SWITZERLAND               AUSTRIA               
   ICELAND                  
  [5] BAHAMAS                   FINLAND                   SWEDEN                
   BHUTAN                   
  [9] BRUNEIDARUSSALAM          CANADA                    IRELAND               
   LUXEMBOURG               
 [13] COSTARICA                 MALTA                     NETHERLANDS           
   ANTIGUAANDBARBUDA        
 [17] MALAYSIA                  NEWZEALAND                NORWAY                
   SEYCHELLES               
 [21] STKITTSANDNEVIS           UAE                       USA                   
   VANUATU                  
 [25] VENEZUELA                 AUSTRALIA                 BARBADOS              
   BELGIUM                  
 [29] DOMINICA                  OMAN                      SAUDIARABIA           
   SURINAME                 
 [33] BAHRAIN                   COLUMBIA                  GERMANY               
   GUYANA                   
 [37] HONDURAS                  KUWAIT                    PANAMA                
   STVINCENTANDTHEGRENADINES
 [41] UNITEDKINGDOM             DOMINICANREPUBLIC         GUATEMALA             
   JAMAICA                  
 [45] QATAR                     SPAIN                     STLUCIA               
   BELIZE                   
 [49] CYPRUS                    ITALY                     MEXICO                
   SINGAPORE                
 [53] SOLOMONISLANDS            TRINIDADANDTOBAGO         ARGENTINA             
   FIJI                     
 [57] ISRAEL                    MONGOLIA                  SAOTOMEANDPRINCIPE    
   ELSALVADOR               
 [61] FRANCE                    HONGKONG                  INDONESIA             
   KYRGYZSTAN               
 [65] MALDIVES                  SLOVENIA                  TAIWAN                
   EASTTIMOR                
 [69] TONGA                     CHILE                     GRENADA               
   MAURITIUS                
 [73] NAMIBIA                   PARAGUAY                  THAILAND              
   CZECHREPUBLIC            
 [77] PHILIPPINES               TUNISIA                   UZBEKISTAN            
   BRAZIL                   
 [81] CHINA                     CUBA                      GREECE                
   NICARAGUA                
 [85] PAPUANEWGUINEA            URUGUAY                   GABON                 
   GHANA                    
 [89] JAPAN                     YEMEN                     PORTUGAL              
   SRILANKA                 
 [93] TAJIKISTAN                VIETNAM                   IRAN                  
   COMOROS                  
 [97] CROATIA                   POLAND                    CAPEVERDE             
   KAZAKHSTAN               
[101] MADAGASCAR                SOUTHKOREA                BANGLADESH            
   CONGO                    
[105] GAMBIA                    HUNGARY                   LIBYA                 
   SOUTHAFRICA              
[109] CAMBODIA                  ECUADOR                   KENYA                 
   LEBANON                  
[113] MOROCCO                   PERU                      SENEGAL               
   BOLIVIA                  
[117] HAITI                     NEPAL                     NIGERIA               
   TANZANIA                 
[121] BENIN                     BOTSWANA                  GUINEABISSAU          
   INDIA                    
[125] LAOS                      MOZAMBIQUE                PALESTINE             
   SLOVAKIA                 
[129] BURMA                     MALI                      MAURITANIA            
   TURKEY                   
[133] ALGERIA                   EQUATORIALGUINEA          ROMANIA               
   BOSNIAANDHERZEGOVENIA    
[137] CAMEROON                  ESTONIA                   GUINEA                
   JORDAN                   
[141] SYRIA                     SIERRALEONE               AZERBAIJAN            
   CENTRALAFRICANREPUBLIC   
[145] MACEDONIA                 TOGO                      ZAMBIA                
   ANGOLA                   
[149] DJIBOUTI                  EGYPT                     BURKINAFASO           
   ETHIOPIA                 
[153] LATVIA                    LITHUANIA                 UGANDA                
   ALBANIA                  
[157] MALAWI                    CHAD                      IVORYCOAST            
   NIGER                    
[161] ERITREA                   RWANDA                    BULGARIA              
   LESOTHO                  
[165] PAKISTAN                  RUSSIA                    SWAZILAND             
   GEORGIA                  
[169] BELARUS                   TURKMENISTAN              ARMENIA               
   SUDAN                    
[173] UKRAINE                   MOLDOVA                   ZAIRE                 
   ZIMBABWE                 
[177] BURUNDI                   ?                        
178 Levels: ? ALBANIA ALGERIA ANGOLA ANTIGUAANDBARBUDA ARGENTINA ARMENIA
AUSTRALIA AUSTRIA AZERBAIJAN BAHAMAS ... ZIMBABWE
> SWLS
  [1] .82 .82 .78 .78 .77 .77 .77 .76 .76 .76 .76 .76 .75 .75 .75 .74 .74 .74
.74 .74 .74 .74 .74 .74 .74 .73 .73 .73 .73
 [30] .73 .73 .73 .72 .72 .72 .72 .72 .72 .72 .72 .71 .7  .7  .7  .7  .7  .7 
.69 .69 .69 .69 .69 .69 .69 .68 .67 .67 .67
 [59] .67 .66 .66 .66 .66 .66 .66 .66 .66 .66 .66 .65 .65 .65 .65 .65 .65 .64
.64 .64 .64 .63 .63 .63 .63 .63 .63 .63 .62
 [88] .62 .62 .62 .61 .61 .61 .61 .6  .59 .59 .59 .58 .58 .58 .58 .57 .57 .57
.57 .57 .57 .56 .56 .56 .56 .56 .56 .56 .55
[117] .55 .55 .55 .55 .54 .54 .54 .54 .54 .54 .54 .54 .53 .53 .53 .53 .52 .52
.52 .51 .51 .51 .51 .51 .51 .5  .49 .49 .49
[146] .49 .49 .48 .48 .48 .47 .47 .47 .47 .47 .46 .46 .45 .45 .45 .44 .44 .43
.43 .43 .43 .42 .41 .4  .4  .37 .36 .36 .35
[175] .33 .33 .3  ?  
46 Levels: ? .3 .33 .35 .36 .37 .4 .41 .42 .43 .44 .45 .46 .47 .48 .49 .5 .51
.52 .53 .54 .55 .56 .57 .58 .59 .6 ... .82
> HDI
  [1] .949 .955 .948 .968 .845 .952 .956 .579 .894 .961 .959 .944 .846 .878 .953
.815 .811 .943 .968 .843 .821 .868 .951
 [24] .674 .792 .962 .892 .946 .798 .814 .812 .774 .866 .791 .935 .75  .7   .891
.812 .761 .946 .779 .689 .736 .875 .949
 [47] .795 .778 .903 .941 .829 .922 .602 .814 .869 .762 .932 .7   .654 .735 .952
.937 .728 .696 .741 .917 .925 .514 .819
 [70] .867 .777 .804 .65  .755 .781 .891 .771 .766 .702 .8   .777 .838 .926 .71 
.53  .852 .677 .553 .953 .508 .897 .743
 [93] .673 .733 .759 .561 .85  .87  .736 .794 .533 .921 .547 .548 .502 .874 .818
.674 .598 .772 .521 .772 .646 .773 .499
[116] .695 .529 .534 .47  .467 .437 .654 .374 .619 .601 .384 .731 .863 .583 .38 
.55  .775 .733 .642 .813 .803 .532 .86 
[139] .456 .773 .724 .336 .746 .384 .801 .512 .434 .446 .516 .708 .37  .406 .855
.862 .505 .801 .437 .388 .432 .374 .483
[162] .452 .824 .549 .551 .802 .547 .745 .804 .713 .775 .526 .788 .708 .411 .513
?    .413
154 Levels: ? .336 .37 .374 .38 .384 .388 .406 .411 .413 .432 .434 .437 .446
.452 .456 .467 .47 .483 .499 .502 ... .968
> lm(SWLS ~ HDI)
Error in storage.mode(y) <- "double" : 
  invalid to change the storage mode of a factor
In addition: Warning message:
In model.response(mf, "numeric") :
  using type="numeric" with a factor response will be ignored


From tlumley at u.washington.edu  Wed Mar 18 14:25:55 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 18 Mar 2009 06:25:55 -0700 (PDT)
Subject: [Rd] lm function (PR#13608)
In-Reply-To: <20090318071508.D040A2832197@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0903180625550.29882@hymn13.u.washington.edu>


This is not a bug.  You forgot to use the header=TRUE argument to read.table(), so your variables weren't recognized as numeric.

Please don't use r-bugs unless you are sure there is a bug in R. Use r-help to ask for help.

      -thomas


On Wed, 18 Mar 2009 michael_karsh at earthlink.net wrote:

> Full_Name: Michael Aaron Karsh
> Version: 2.8.0
> OS: Windows XP
> Submission from: (NULL) (75.61.109.172)
>
>
> I tried using the lm function to regress the third column listed below on the
> second column listed below.  It gave me an error message.  My code is below.
>
>> HDISWLSdata=read.table("RHDISWLS.txt")
>> HDISWLSdata
>                           V1  V2   V3
> 1                     DENMARK .82 .949
> 2                 SWITZERLAND .82 .955
> 3                     AUSTRIA .78 .948
> 4                     ICELAND .78 .968
> 5                     BAHAMAS .77 .845
> 6                     FINLAND .77 .952
> 7                      SWEDEN .77 .956
> 8                      BHUTAN .76 .579
> 9            BRUNEIDARUSSALAM .76 .894
> 10                     CANADA .76 .961
> 11                    IRELAND .76 .959
> 12                 LUXEMBOURG .76 .944
> 13                  COSTARICA .75 .846
> 14                      MALTA .75 .878
> 15                NETHERLANDS .75 .953
> 16          ANTIGUAANDBARBUDA .74 .815
> 17                   MALAYSIA .74 .811
> 18                 NEWZEALAND .74 .943
> 19                     NORWAY .74 .968
> 20                 SEYCHELLES .74 .843
> 21            STKITTSANDNEVIS .74 .821
> 22                        UAE .74 .868
> 23                        USA .74 .951
> 24                    VANUATU .74 .674
> 25                  VENEZUELA .74 .792
> 26                  AUSTRALIA .73 .962
> 27                   BARBADOS .73 .892
> 28                    BELGIUM .73 .946
> 29                   DOMINICA .73 .798
> 30                       OMAN .73 .814
> 31                SAUDIARABIA .73 .812
> 32                   SURINAME .73 .774
> 33                    BAHRAIN .72 .866
> 34                   COLUMBIA .72 .791
> 35                    GERMANY .72 .935
> 36                     GUYANA .72  .75
> 37                   HONDURAS .72   .7
> 38                     KUWAIT .72 .891
> 39                     PANAMA .72 .812
> 40  STVINCENTANDTHEGRENADINES .72 .761
> 41              UNITEDKINGDOM .71 .946
> 42          DOMINICANREPUBLIC  .7 .779
> 43                  GUATEMALA  .7 .689
> 44                    JAMAICA  .7 .736
> 45                      QATAR  .7 .875
> 46                      SPAIN  .7 .949
> 47                    STLUCIA  .7 .795
> 48                     BELIZE .69 .778
> 49                     CYPRUS .69 .903
> 50                      ITALY .69 .941
> 51                     MEXICO .69 .829
> 52                  SINGAPORE .69 .922
> 53             SOLOMONISLANDS .69 .602
> 54          TRINIDADANDTOBAGO .69 .814
> 55                  ARGENTINA .68 .869
> 56                       FIJI .67 .762
> 57                     ISRAEL .67 .932
> 58                   MONGOLIA .67   .7
> 59         SAOTOMEANDPRINCIPE .67 .654
> 60                 ELSALVADOR .66 .735
> 61                     FRANCE .66 .952
> 62                   HONGKONG .66 .937
> 63                  INDONESIA .66 .728
> 64                 KYRGYZSTAN .66 .696
> 65                   MALDIVES .66 .741
> 66                   SLOVENIA .66 .917
> 67                     TAIWAN .66 .925
> 68                  EASTTIMOR .66 .514
> 69                      TONGA .66 .819
> 70                      CHILE .65 .867
> 71                    GRENADA .65 .777
> 72                  MAURITIUS .65 .804
> 73                    NAMIBIA .65  .65
> 74                   PARAGUAY .65 .755
> 75                   THAILAND .65 .781
> 76              CZECHREPUBLIC .64 .891
> 77                PHILIPPINES .64 .771
> 78                    TUNISIA .64 .766
> 79                 UZBEKISTAN .64 .702
> 80                     BRAZIL .63   .8
> 81                      CHINA .63 .777
> 82                       CUBA .63 .838
> 83                     GREECE .63 .926
> 84                  NICARAGUA .63  .71
> 85             PAPUANEWGUINEA .63  .53
> 86                    URUGUAY .63 .852
> 87                      GABON .62 .677
> 88                      GHANA .62 .553
> 89                      JAPAN .62 .953
> 90                      YEMEN .62 .508
> 91                   PORTUGAL .61 .897
> 92                   SRILANKA .61 .743
> 93                 TAJIKISTAN .61 .673
> 94                    VIETNAM .61 .733
> 95                       IRAN  .6 .759
> 96                    COMOROS .59 .561
> 97                    CROATIA .59  .85
> 98                     POLAND .59  .87
> 99                  CAPEVERDE .58 .736
> 100                KAZAKHSTAN .58 .794
> 101                MADAGASCAR .58 .533
> 102                SOUTHKOREA .58 .921
> 103                BANGLADESH .57 .547
> 104                     CONGO .57 .548
> 105                    GAMBIA .57 .502
> 106                   HUNGARY .57 .874
> 107                     LIBYA .57 .818
> 108               SOUTHAFRICA .57 .674
> 109                  CAMBODIA .56 .598
> 110                   ECUADOR .56 .772
> 111                     KENYA .56 .521
> 112                   LEBANON .56 .772
> 113                   MOROCCO .56 .646
> 114                      PERU .56 .773
> 115                   SENEGAL .56 .499
> 116                   BOLIVIA .55 .695
> 117                     HAITI .55 .529
> 118                     NEPAL .55 .534
> 119                   NIGERIA .55  .47
> 120                  TANZANIA .55 .467
> 121                     BENIN .54 .437
> 122                  BOTSWANA .54 .654
> 123              GUINEABISSAU .54 .374
> 124                     INDIA .54 .619
> 125                      LAOS .54 .601
> 126                MOZAMBIQUE .54 .384
> 127                 PALESTINE .54 .731
> 128                  SLOVAKIA .54 .863
> 129                     BURMA .53 .583
> 130                      MALI .53  .38
> 131                MAURITANIA .53  .55
> 132                    TURKEY .53 .775
> 133                   ALGERIA .52 .733
> 134          EQUATORIALGUINEA .52 .642
> 135                   ROMANIA .52 .813
> 136     BOSNIAANDHERZEGOVENIA .51 .803
> 137                  CAMEROON .51 .532
> 138                   ESTONIA .51  .86
> 139                    GUINEA .51 .456
> 140                    JORDAN .51 .773
> 141                     SYRIA .51 .724
> 142               SIERRALEONE  .5 .336
> 143                AZERBAIJAN .49 .746
> 144    CENTRALAFRICANREPUBLIC .49 .384
> 145                 MACEDONIA .49 .801
> 146                      TOGO .49 .512
> 147                    ZAMBIA .49 .434
> 148                    ANGOLA .48 .446
> 149                  DJIBOUTI .48 .516
> 150                     EGYPT .48 .708
> 151               BURKINAFASO .47  .37
> 152                  ETHIOPIA .47 .406
> 153                    LATVIA .47 .855
> 154                 LITHUANIA .47 .862
> 155                    UGANDA .47 .505
> 156                   ALBANIA .46 .801
> 157                    MALAWI .46 .437
> 158                      CHAD .45 .388
> 159                IVORYCOAST .45 .432
> 160                     NIGER .45 .374
> 161                   ERITREA .44 .483
> 162                    RWANDA .44 .452
> 163                  BULGARIA .43 .824
> 164                   LESOTHO .43 .549
> 165                  PAKISTAN .43 .551
> 166                    RUSSIA .43 .802
> 167                 SWAZILAND .42 .547
> 168                   GEORGIA .41 .745
> 169                   BELARUS  .4 .804
> 170              TURKMENISTAN  .4 .713
> 171                   ARMENIA .37 .775
> 172                     SUDAN .36 .526
> 173                   UKRAINE .36 .788
> 174                   MOLDOVA .35 .708
> 175                     ZAIRE .33 .411
> 176                  ZIMBABWE .33 .513
> 177                   BURUNDI  .3    ?
> 178                         ?   ? .413
>> country <- HDISWLSdata[,1]
>> SWLS <- HDISWLSdata[,2]
>> HDI <- HDISWLSdata[,2]
>> HDI <- HDISWLSdata[,3]
>> country
>  [1] DENMARK                   SWITZERLAND               AUSTRIA
>   ICELAND
>  [5] BAHAMAS                   FINLAND                   SWEDEN
>   BHUTAN
>  [9] BRUNEIDARUSSALAM          CANADA                    IRELAND
>   LUXEMBOURG
> [13] COSTARICA                 MALTA                     NETHERLANDS
>   ANTIGUAANDBARBUDA
> [17] MALAYSIA                  NEWZEALAND                NORWAY
>   SEYCHELLES
> [21] STKITTSANDNEVIS           UAE                       USA
>   VANUATU
> [25] VENEZUELA                 AUSTRALIA                 BARBADOS
>   BELGIUM
> [29] DOMINICA                  OMAN                      SAUDIARABIA
>   SURINAME
> [33] BAHRAIN                   COLUMBIA                  GERMANY
>   GUYANA
> [37] HONDURAS                  KUWAIT                    PANAMA
>   STVINCENTANDTHEGRENADINES
> [41] UNITEDKINGDOM             DOMINICANREPUBLIC         GUATEMALA
>   JAMAICA
> [45] QATAR                     SPAIN                     STLUCIA
>   BELIZE
> [49] CYPRUS                    ITALY                     MEXICO
>   SINGAPORE
> [53] SOLOMONISLANDS            TRINIDADANDTOBAGO         ARGENTINA
>   FIJI
> [57] ISRAEL                    MONGOLIA                  SAOTOMEANDPRINCIPE
>   ELSALVADOR
> [61] FRANCE                    HONGKONG                  INDONESIA
>   KYRGYZSTAN
> [65] MALDIVES                  SLOVENIA                  TAIWAN
>   EASTTIMOR
> [69] TONGA                     CHILE                     GRENADA
>   MAURITIUS
> [73] NAMIBIA                   PARAGUAY                  THAILAND
>   CZECHREPUBLIC
> [77] PHILIPPINES               TUNISIA                   UZBEKISTAN
>   BRAZIL
> [81] CHINA                     CUBA                      GREECE
>   NICARAGUA
> [85] PAPUANEWGUINEA            URUGUAY                   GABON
>   GHANA
> [89] JAPAN                     YEMEN                     PORTUGAL
>   SRILANKA
> [93] TAJIKISTAN                VIETNAM                   IRAN
>   COMOROS
> [97] CROATIA                   POLAND                    CAPEVERDE
>   KAZAKHSTAN
> [101] MADAGASCAR                SOUTHKOREA                BANGLADESH
>   CONGO
> [105] GAMBIA                    HUNGARY                   LIBYA
>   SOUTHAFRICA
> [109] CAMBODIA                  ECUADOR                   KENYA
>   LEBANON
> [113] MOROCCO                   PERU                      SENEGAL
>   BOLIVIA
> [117] HAITI                     NEPAL                     NIGERIA
>   TANZANIA
> [121] BENIN                     BOTSWANA                  GUINEABISSAU
>   INDIA
> [125] LAOS                      MOZAMBIQUE                PALESTINE
>   SLOVAKIA
> [129] BURMA                     MALI                      MAURITANIA
>   TURKEY
> [133] ALGERIA                   EQUATORIALGUINEA          ROMANIA
>   BOSNIAANDHERZEGOVENIA
> [137] CAMEROON                  ESTONIA                   GUINEA
>   JORDAN
> [141] SYRIA                     SIERRALEONE               AZERBAIJAN
>   CENTRALAFRICANREPUBLIC
> [145] MACEDONIA                 TOGO                      ZAMBIA
>   ANGOLA
> [149] DJIBOUTI                  EGYPT                     BURKINAFASO
>   ETHIOPIA
> [153] LATVIA                    LITHUANIA                 UGANDA
>   ALBANIA
> [157] MALAWI                    CHAD                      IVORYCOAST
>   NIGER
> [161] ERITREA                   RWANDA                    BULGARIA
>   LESOTHO
> [165] PAKISTAN                  RUSSIA                    SWAZILAND
>   GEORGIA
> [169] BELARUS                   TURKMENISTAN              ARMENIA
>   SUDAN
> [173] UKRAINE                   MOLDOVA                   ZAIRE
>   ZIMBABWE
> [177] BURUNDI                   ?
> 178 Levels: ? ALBANIA ALGERIA ANGOLA ANTIGUAANDBARBUDA ARGENTINA ARMENIA
> AUSTRALIA AUSTRIA AZERBAIJAN BAHAMAS ... ZIMBABWE
>> SWLS
>  [1] .82 .82 .78 .78 .77 .77 .77 .76 .76 .76 .76 .76 .75 .75 .75 .74 .74 .74
> .74 .74 .74 .74 .74 .74 .74 .73 .73 .73 .73
> [30] .73 .73 .73 .72 .72 .72 .72 .72 .72 .72 .72 .71 .7  .7  .7  .7  .7  .7
> .69 .69 .69 .69 .69 .69 .69 .68 .67 .67 .67
> [59] .67 .66 .66 .66 .66 .66 .66 .66 .66 .66 .66 .65 .65 .65 .65 .65 .65 .64
> .64 .64 .64 .63 .63 .63 .63 .63 .63 .63 .62
> [88] .62 .62 .62 .61 .61 .61 .61 .6  .59 .59 .59 .58 .58 .58 .58 .57 .57 .57
> .57 .57 .57 .56 .56 .56 .56 .56 .56 .56 .55
> [117] .55 .55 .55 .55 .54 .54 .54 .54 .54 .54 .54 .54 .53 .53 .53 .53 .52 .52
> .52 .51 .51 .51 .51 .51 .51 .5  .49 .49 .49
> [146] .49 .49 .48 .48 .48 .47 .47 .47 .47 .47 .46 .46 .45 .45 .45 .44 .44 .43
> .43 .43 .43 .42 .41 .4  .4  .37 .36 .36 .35
> [175] .33 .33 .3  ?
> 46 Levels: ? .3 .33 .35 .36 .37 .4 .41 .42 .43 .44 .45 .46 .47 .48 .49 .5 .51
> .52 .53 .54 .55 .56 .57 .58 .59 .6 ... .82
>> HDI
>  [1] .949 .955 .948 .968 .845 .952 .956 .579 .894 .961 .959 .944 .846 .878 .953
> .815 .811 .943 .968 .843 .821 .868 .951
> [24] .674 .792 .962 .892 .946 .798 .814 .812 .774 .866 .791 .935 .75  .7   .891
> .812 .761 .946 .779 .689 .736 .875 .949
> [47] .795 .778 .903 .941 .829 .922 .602 .814 .869 .762 .932 .7   .654 .735 .952
> .937 .728 .696 .741 .917 .925 .514 .819
> [70] .867 .777 .804 .65  .755 .781 .891 .771 .766 .702 .8   .777 .838 .926 .71
> .53  .852 .677 .553 .953 .508 .897 .743
> [93] .673 .733 .759 .561 .85  .87  .736 .794 .533 .921 .547 .548 .502 .874 .818
> .674 .598 .772 .521 .772 .646 .773 .499
> [116] .695 .529 .534 .47  .467 .437 .654 .374 .619 .601 .384 .731 .863 .583 .38
> .55  .775 .733 .642 .813 .803 .532 .86
> [139] .456 .773 .724 .336 .746 .384 .801 .512 .434 .446 .516 .708 .37  .406 .855
> .862 .505 .801 .437 .388 .432 .374 .483
> [162] .452 .824 .549 .551 .802 .547 .745 .804 .713 .775 .526 .788 .708 .411 .513
> ?    .413
> 154 Levels: ? .336 .37 .374 .38 .384 .388 .406 .411 .413 .432 .434 .437 .446
> .452 .456 .467 .47 .483 .499 .502 ... .968
>> lm(SWLS ~ HDI)
> Error in storage.mode(y) <- "double" :
>  invalid to change the storage mode of a factor
> In addition: Warning message:
> In model.response(mf, "numeric") :
>  using type="numeric" with a factor response will be ignored
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From simon.urbanek at r-project.org  Wed Mar 18 14:28:48 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 18 Mar 2009 09:28:48 -0400
Subject: [Rd] R thread safe
In-Reply-To: <49C0F021.8000108@health.sdu.dk>
References: 1131389848.436fa39855a52@webmail.unibas.ch
	<49C0F021.8000108@health.sdu.dk>
Message-ID: <4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>


On Mar 18, 2009, at 8:59 , Rune Schjellerup Philosof wrote:

> Duncan Temple Lang wrote (Mon Nov 7 22:35:22 CET 2005):
>> R is not yet thread safe.
>> We are working on it, and I hope to make some progress before
>> the end of the year.  (This one even!)
>>
>> D.
>
> How is this going along?
>
> For some things it would be simpler to use threads compared to
> processes, to avoid the added complexity of passing the results back  
> to
> a master process.
>
> With the emerging multicore processors it is essential that users can
> easily make use of them.
>
> A simple example of use:
>  data1 <- data2 <- matrix(0, r, c)
>  dataFiller <- function(i) {
>   tmp <- someCalculation(i)
>   data1[, i] <<- tmp$result1
>   data2[, i] <<- tmp$result2
>  }
>  runParallelInThreads(1:c, dataFiller)
>
> If this can be done almost as fast and simple with processes, for
> instance using the multicore package, then I think it needs to be  
> better
> documented.
>

Can you elaborate on the last sentence, please? Things cannot happen  
if you don't ask ...

Cheers,
Simon


> -- 
> Regards
> Rune Schjellerup Philosof
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From rphilosof at health.sdu.dk  Wed Mar 18 14:45:17 2009
From: rphilosof at health.sdu.dk (Rune Schjellerup Philosof)
Date: Wed, 18 Mar 2009 14:45:17 +0100
Subject: [Rd] R thread safe
In-Reply-To: <4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
References: 1131389848.436fa39855a52@webmail.unibas.ch
	<49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
Message-ID: <49C0FAED.6030604@health.sdu.dk>

Simon Urbanek wrote:
> On Mar 18, 2009, at 8:59 , Rune Schjellerup Philosof wrote:
>> A simple example of use:
>>  data1 <- data2 <- matrix(0, r, c)
>>  dataFiller <- function(i) {
>>   tmp <- someCalculation(i)
>>   data1[, i] <<- tmp$result1
>>   data2[, i] <<- tmp$result2
>>  }
>>  runParallelInThreads(1:c, dataFiller)
>>
>> If this can be done almost as fast and simple with processes, for
>> instance using the multicore package, then I think it needs to be better
>> documented.
>
> Can you elaborate on the last sentence, please? Things cannot happen
> if you don't ask ...
>

What I meant with the sentence was:
- How would you do the example above using the multicore package?
- What is the magnitude of speed reduction comparing the multicore
solution with the hypothetical solution using threads?

-- 
Cheers
Rune Schjellerup Philosof


From chalabi at phys.ethz.ch  Wed Mar 18 14:47:03 2009
From: chalabi at phys.ethz.ch (Yohan Chalabi)
Date: Wed, 18 Mar 2009 14:47:03 +0100
Subject: [Rd] Why S4 methods of S3 'base' generics are not used in 'base'
 functions ?
Message-ID: <20090318144703.54e02ec1@mimi>

Dear list,

It seems that S4 methods defined for an S3 'base' generic
are not used in 'base' functions.

This can be problematic when 'base' functions start with 
something like 'as.matrix'.


### START R code

setClass("classA", contains = "matrix",
         representation(realData = "numeric"))

setMethod("as.matrix", "classA", function(x) callGeneric(x at realData))

x <- new("classA", diag(1:4), realData = 1:4)

as.matrix(x)

## # as intended
##      [,1]
## [1,]    1
## [2,]    2
## [3,]    3
## [4,]    4

# but as.matrix in 'base' functions dispatches to the default S3
# method rather than to the S4 method defined above.
scale(x)
scale(as.matrix(x))

# Note that S4 methods are well dispatched for functions which are
# not S3 generics.
setMethod("dimnames", "classA",
          function(x) list(NULL, as.character(x at realData)))
dimnames(x)

solve(x) # here row names are properly assigned thanks to the 'dimnames'
         # method defined above.

### END R code

What is your recommended solution to make S4 methods of S3 'base'
generics work in 'base' functions?

A solution could be to overwrite 'as.matrix' in '.Load' and force it to
use the S4 method with S4 objects. But doing so looks to me rather
dangerous because it would lead to conflicts between packages.

Another solution could be to define S3 methods. But, as it has been
already explained on the list, it is a design error.

Thanks in advance for any suggestion!

Best regards,
Yohan


-- 
PhD student
Swiss Federal Institute of Technology
Zurich

www.ethz.ch


From r.ted.byers at gmail.com  Wed Mar 18 15:11:25 2009
From: r.ted.byers at gmail.com (Ted Byers)
Date: Wed, 18 Mar 2009 10:11:25 -0400
Subject: [Rd] R thread safe
In-Reply-To: <4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
Message-ID: <4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>

On Wed, Mar 18, 2009 at 9:28 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Things cannot happen if you don't ask ...
>
> Cheers,
> Simon
>
Then I have two questions.

1) What multicore package?  I didn't know there was one, and would be
interested in seeing what it does.

2) Has there been any consideration of using Intel's threading
building blocks library?  They do have an open source version. It can
apparently be built on Unix and Windows, and since it is open source,
you can adapt it to any platform that you need to support if there is
one that it doesn't presently support. And it allows a programmer to
work at a higher logical level than if he focussed largely on the
lower level details of creating and managing threads (for example, one
can create a 'parrallel for loop' and the library, once properly
initialized, will handle creating and cleaning up after any new
threads that may be needed): now that is a freedom in multithreaded
programming I truly appreciate.  According to the documentation I have
read, it scales well to larger numbers of processors or cores.  The
code in it that I have studied is all C++, so if there is much C++
code in R, it presents an option.  I do know, though, that in my C++
code where it would provide a benefit (mostly vector and matrix
algebra), most of it would need to be completely rewritten.  It does
present a rather different way of thinking about multithreaded
programming (it reminds me of the sort of thing I did when writing
code to run on a supercomputer supporting vector algebra decades ago).
 With ITT, if Lapack was rewritten to take advantage of it, much of
the code would look quite different from what it does today.  Of
course, if you're already using it, I might as well shut up and go
away.  ;-)  I am just learning to use it, as I am just learning to use
R, so I am afraid I can't offer much more info than this, though.

Cheers,

Ted


From h.wickham at gmail.com  Wed Mar 18 15:56:16 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 18 Mar 2009 09:56:16 -0500
Subject: [Rd] R thread safe
In-Reply-To: <4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
Message-ID: <f8e6ff050903180756g25a9023cyaef9485c6210857b@mail.gmail.com>

On Wed, Mar 18, 2009 at 9:11 AM, Ted Byers <r.ted.byers at gmail.com> wrote:
> On Wed, Mar 18, 2009 at 9:28 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Things cannot happen if you don't ask ...
>>
>> Cheers,
>> Simon
>>
> Then I have two questions.
>
> 1) What multicore package? ?I didn't know there was one, and would be
> interested in seeing what it does.

http://tinyurl.com/cudqqf

;)

Hadley



-- 
http://had.co.nz/


From simon.urbanek at r-project.org  Wed Mar 18 16:06:53 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 18 Mar 2009 11:06:53 -0400
Subject: [Rd] R thread safe
In-Reply-To: <49C0FAED.6030604@health.sdu.dk>
References: 1131389848.436fa39855a52@webmail.unibas.ch
	<49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<49C0FAED.6030604@health.sdu.dk>
Message-ID: <50800910-1355-4752-8D68-21D2D9822268@r-project.org>


On Mar 18, 2009, at 9:45 , Rune Schjellerup Philosof wrote:

> Simon Urbanek wrote:
>> On Mar 18, 2009, at 8:59 , Rune Schjellerup Philosof wrote:
>>> A simple example of use:
>>> data1 <- data2 <- matrix(0, r, c)
>>> dataFiller <- function(i) {
>>>  tmp <- someCalculation(i)
>>>  data1[, i] <<- tmp$result1
>>>  data2[, i] <<- tmp$result2
>>> }
>>> runParallelInThreads(1:c, dataFiller)
>>>
>>> If this can be done almost as fast and simple with processes, for
>>> instance using the multicore package, then I think it needs to be  
>>> better
>>> documented.
>>
>> Can you elaborate on the last sentence, please? Things cannot happen
>> if you don't ask ...
>>
>
> What I meant with the sentence was:
> - How would you do the example above using the multicore package?

There are many ways, but for example with automated dispatch to the  
cores:

l=mclapply(1:c, someCaluculation)
for (i in 1:c) { data1[,i] = l[[i]]$result1; data2[,i] = l[[i]] 
$result2 }


> - What is the magnitude of speed reduction comparing the multicore  
> solution with the hypothetical solution using threads?

That really depends on the duration of the computation performed since  
the difference is essentially just the setup cost (there is also some  
cost associated with result transfer*). Since you simply cannot use  
threads in R there is no realistic way to compare it ;).

The closest I can get to answering the question is to simply measure  
the overhead. On my machine (8-core Xeon 3.3GHz) I get something like  
this:
forking cost: 1.3ms
data management cost: 0.6ms
(measured by sequentially spawning and collecting 1000 parallel jobs  
of the form function(...) NULL)
This is a really negligible cost unless you are running thousands of  
parallel processes which would be entirely pointless since there are  
very few machines with 1000 cores ;). Note that in practice you are  
spawning only as many jobs as you have cores (or slightly more), so  
the overhead is not really an issue at all.

Cheers,
Simon

(*) - this is usually not an issue, but if you had really large result  
sets it could be of interest to change the implementation a bit.  
Currently the results are passed back in a pipe, but it would be  
possible (albeit possibly less portable) to use shared memory instead.


From edd at debian.org  Wed Mar 18 16:16:27 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 18 Mar 2009 10:16:27 -0500
Subject: [Rd] R thread safe
In-Reply-To: <f8e6ff050903180756g25a9023cyaef9485c6210857b@mail.gmail.com>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
	<f8e6ff050903180756g25a9023cyaef9485c6210857b@mail.gmail.com>
Message-ID: <18881.4171.835510.847817@ron.nulle.part>


On 18 March 2009 at 09:56, hadley wickham wrote:
| On Wed, Mar 18, 2009 at 9:11 AM, Ted Byers <r.ted.byers at gmail.com> wrote:
| > 1) What multicore package?  I didn't know there was one, and would be
| > interested in seeing what it does.
| 
| http://tinyurl.com/cudqqf
| 
| ;)

Readers of the CRANberries RSS feed knew about 'multicore' the day it
appeared in CRAN.  Subscriptions are free, just ask your friendly
neighbourhood RSS reader, or, if you must, hit the html pages by hand.

The original announcement is at
    https://stat.ethz.ch/pipermail/r-packages/2007/000317.html

For the impatient, the html view is at
    http://dirk.eddelbuettel.com/cranberries/

Dirk

-- 
Three out of two people have difficulties with fractions.


From simon.urbanek at r-project.org  Wed Mar 18 16:32:15 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 18 Mar 2009 11:32:15 -0400
Subject: [Rd] R thread safe
In-Reply-To: <4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
Message-ID: <83E1179B-072A-42F1-98FB-A06790DA393D@r-project.org>


On Mar 18, 2009, at 10:11 , Ted Byers wrote:

> On Wed, Mar 18, 2009 at 9:28 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Things cannot happen if you don't ask ...
>>
>> Cheers,
>> Simon
>>
> Then I have two questions.
>
> 1) What multicore package?  I didn't know there was one, and would  
> be interested in seeing what it does.
>


It's on CRAN, so just look at it for yourself:

http://cran.at.r-project.org/web/packages/multicore/index.html

multicore: Parallel processing of R code on machines with multiple  
cores or CPUs
This package provides a way of running parallel computations in R on  
machines with multiple cores or CPUs. Jobs can share the entire  
initial workspace and it provides methods for results collection.

It's actually referenced in several places of the R website ...


> 2) Has there been any consideration of using Intel's threading  
> building blocks library?

I don't think so, because IMHO it makes no sense - you're missing the  
main point that R is not thread safe. There are ways to use threads  
from within R very cautiously (see Luke's parallelized vector math  
operations for R for example). There are many good methods to use  
threads in general (pthreads, OpenMP, GCD, ...) and you can do that as  
long as you don't use memory allocation in R and don't call any R  
functions that may do that (which is most of them ;)). Making R thread- 
safe is not really an issue of a threading toolkit...

Cheers,
Simon


>  They do have an open source version. It can
> apparently be built on Unix and Windows, and since it is open source,
> you can adapt it to any platform that you need to support if there is
> one that it doesn't presently support. And it allows a programmer to
> work at a higher logical level than if he focussed largely on the
> lower level details of creating and managing threads (for example, one
> can create a 'parrallel for loop' and the library, once properly
> initialized, will handle creating and cleaning up after any new
> threads that may be needed): now that is a freedom in multithreaded
> programming I truly appreciate.  According to the documentation I have
> read, it scales well to larger numbers of processors or cores.  The
> code in it that I have studied is all C++, so if there is much C++
> code in R, it presents an option.  I do know, though, that in my C++
> code where it would provide a benefit (mostly vector and matrix
> algebra), most of it would need to be completely rewritten.  It does
> present a rather different way of thinking about multithreaded
> programming (it reminds me of the sort of thing I did when writing
> code to run on a supercomputer supporting vector algebra decades ago).
> With ITT, if Lapack was rewritten to take advantage of it, much of
> the code would look quite different from what it does today.  Of
> course, if you're already using it, I might as well shut up and go
> away.  ;-)  I am just learning to use it, as I am just learning to use
> R, so I am afraid I can't offer much more info than this, though.
>
> Cheers,
>
> Ted
>
>


From khansen at stat.berkeley.edu  Wed Mar 18 16:53:33 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Wed, 18 Mar 2009 08:53:33 -0700
Subject: [Rd] R thread safe
In-Reply-To: <4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
Message-ID: <9EED5E6C-DC10-4DCC-B840-FB352FDE00A9@stat.berkeley.edu>

On Mar 18, 2009, at 7:11 , Ted Byers wrote:

>  of thing I did when writing
> code to run on a supercomputer supporting vector algebra decades ago).
> With ITT, if Lapack was rewritten to take advantage of it, much of
> the code would look quite different from what it does today.  Of
> course, if you're already using it, I might as well shut up and go
> away.  ;-)  I am just learning to use it, as I am just learning to use
> R, so I am afraid I can't offer much more info than this, though.

For the purpose of matrix computations with BLAS/Lapack, use an  
optimized, multithreaded BLAS implementation. That way you use the  
multiple cores for "free" when you do matrix algebra, which is often  
(but not always) the heavy part of a computation. People have been  
doing this for a long time on OS X where it is default to use an  
implementation provided by Apple. I don't know exactly how to set this  
up for Linux or Windows.

Kasper


From kevin.hendricks at sympatico.ca  Wed Mar 18 17:08:17 2009
From: kevin.hendricks at sympatico.ca (Kevin Hendricks)
Date: Wed, 18 Mar 2009 12:08:17 -0400
Subject: [Rd] R thread safe
In-Reply-To: <83E1179B-072A-42F1-98FB-A06790DA393D@r-project.org>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
	<83E1179B-072A-42F1-98FB-A06790DA393D@r-project.org>
Message-ID: <BLU0-SMTP15182A31C747C6DD88103A87990@phx.gbl>

>

Hi,


> I don't think so, because IMHO it makes no sense - you're missing  
> the main point that R is not thread safe. There are ways to use  
> threads from within R very cautiously (see Luke's parallelized  
> vector math operations for R for example). There are many good  
> methods to use threads in general (pthreads, OpenMP, GCD, ...) and  
> you can do that as long as you don't use memory allocation in R and  
> don't call any R functions that may do that (which is most of  
> them ;)). Making R thread-safe is not really an issue of a threading  
> toolkit...


Memory allocation does not necessarily make a function non-reentrant  
unless non-shared static variables are involved.  There are a number  
of thread-safe malloc implementations.    I admit,  I have not looked  
at the R-internals in a long time.

Based on converting code to be thread safe when I helped port the JDK  
to Linux, I was amazed about how much code was already reentrant  
capable and therefore basically thread-safe (or could be made so with  
small effort - adding a few locks).  In fact the original JVM (jdk  
1.0) had a "green-threads" implementation that basically ended up  
adding wrappers to most of the memory allocation and io system calls  
system calls to make the whole thing work.

  How much of the code itself is now reentrant safe - I noticed that  
some of the R-internal routines actually used reentrant code and even  
recursion?  How hard would it be to make the internal object/memory  
allocation scheme thread-safe?  As you noted there are many posix  
threads (pthreads) implmentations out there.

Is there any official effort underway to make R thread-safe? If so,  
are they looking for volunteers.  Would making R fully thread-safe  
really make that much sense given you can parallelize vector/matrix  
operations now (as you noted) which probably provides the most bang  
for the buck.

Thanks,

Kevin


From ncrookston at fs.fed.us  Wed Mar 18 17:37:46 2009
From: ncrookston at fs.fed.us (Nicholas L Crookston)
Date: Wed, 18 Mar 2009 09:37:46 -0700
Subject: [Rd] R thread safe
In-Reply-To: <BLU0-SMTP15182A31C747C6DD88103A87990@phx.gbl>
Message-ID: <OF38069B82.C52CF0CC-ON8825757D.00591526-8825757D.005B596D@fs.fed.us>

> Is there any official effort underway to make R thread-safe? If so,
> are they looking for volunteers. 

I'm looking forward to the answer to this question!

> Would making R fully thread-safe
> really make that much sense given you can parallelize vector/matrix
> operations now (as you noted) which probably provides the most bang
> for the buck.

There are applications that could benefit from running several threads, 
yet not to accomplish the vector/matrix operations using blas. I thought
about working on this and have picked up several important comments from
this discussion. I have wondered, for example, if there is an option that 
a user can set to limit the number of threads (package multicore uses
an option to set the number of cores). It seems that we need to agree
on a few basic rules. If there are some already outlined, I would like 
to have a reference to them. If not, perhaps there is an 
on-going discussion on the topic someone could point me to.

> Thanks,

Nick.

Nicholas L. Crookston, Operations Research Analyst
Rocky Mountain Research Station
USDA Forest Service
1221 South Main, Moscow, ID 83843
Office: (208) 883-2317, FAX: (208) 883-2318
EMail: ncrookston at fs.fed.us


From tlumley at u.washington.edu  Wed Mar 18 17:42:31 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 18 Mar 2009 09:42:31 -0700 (PDT)
Subject: [Rd] exporting s3 and s4 methods
In-Reply-To: <49C04785.80406@r-project.org>
Message-ID: <Pine.LNX.4.43.0903180942310.8322@hymn31.u.washington.edu>


I'm still having problems getting a package to define both S3 and S4 methods for the same new generic, on a current r-devel (version 48144).

Symptoms
> example(bigglm)

bigglm> data(trees)

bigglm> ff<-log(Volume)~log(Girth)+log(Height)

bigglm> a <- bigglm(ff,data=trees, chunksize=10, sandwich=TRUE)
Error in UseMethod("bigglm", data) : no applicable method for "bigglm"

> showMethods("bigglm")
Function: bigglm (package biglm)
formula="ANY", data="ANY"
formula="ANY", data="DBIConnection"
formula="formula", data="data.frame"
     (inherited from: formula="ANY", data="ANY")

> bigglm          
standardGeneric for "bigglm" defined from package "biglm"

function (formula, data, family = gaussian(), ...) 
standardGeneric("bigglm")
<environment: 0x8554240>
Methods may be defined for arguments: formula, data
Use  showMethods("bigglm")  for currently available ones.
> getMethod("bigglm",c("ANY","ANY"))
Method Definition (Class "derivedDefaultMethod"):

function (formula, data, family = gaussian(), ...) 
UseMethod("bigglm", data)
<environment: namespace:biglm>

Signatures:
         formula data 
target  "ANY"   "ANY"
defined "ANY"   "ANY"

>  methods("bigglm")
[1] bigglm.data.frame* bigglm.function*   bigglm.RODBC*

    Non-visible functions are asterisked
Warning messages:
1: In findGeneric(generic.function, parent.frame()) :
   'bigglm' is a formal generic function; S3 methods will not likely be found
2: In methods("bigglm") : function 'bigglm' appears not to be generic

In the NAMESPACE file I have
import(stats)
useDynLib(biglm)
importClassesFrom(DBI)
exportMethods(bigglm)
export(biglm)
export(bigglm)
S3method(bigglm,data.frame)
S3method(bigglm,"function")
S3method(bigglm, RODBC)

and in the code
bigglm<-function(formula, data, family=gaussian(),...)
     UseMethod("bigglm", data)
setGeneric("bigglm", signature=c("formula","data"))


bigglm.data.frame<-function(formula, data, ..., chunksize=5000){ <snip>

setMethod("bigglm",
            c("ANY","DBIConnection"),
            function(formula, data, family = gaussian(),
                                    tablename, ..., chunksize=5000){
              terms<-terms(formula)
              modelvars<-all.vars(formula)
      <snip>


Any suggestions?

     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From simon.urbanek at r-project.org  Wed Mar 18 18:00:49 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 18 Mar 2009 13:00:49 -0400
Subject: [Rd] R thread safe
In-Reply-To: <BLU0-SMTP15182A31C747C6DD88103A87990@phx.gbl>
References: <49C0F021.8000108@health.sdu.dk>
	<4BD0BA7D-242B-4D27-A346-745AB8AD088E@r-project.org>
	<4f1819890903180711pcdd2bdbuc4eb15f7af8575f4@mail.gmail.com>
	<83E1179B-072A-42F1-98FB-A06790DA393D@r-project.org>
	<BLU0-SMTP15182A31C747C6DD88103A87990@phx.gbl>
Message-ID: <077CDE8C-BA85-4E3C-846C-0C6BFEB7DFC4@r-project.org>

Kevin,

On Mar 18, 2009, at 12:08 , Kevin Hendricks wrote:

>> I don't think so, because IMHO it makes no sense - you're missing  
>> the main point that R is not thread safe. There are ways to use  
>> threads from within R very cautiously (see Luke's parallelized  
>> vector math operations for R for example). There are many good  
>> methods to use threads in general (pthreads, OpenMP, GCD, ...) and  
>> you can do that as long as you don't use memory allocation in R and  
>> don't call any R functions that may do that (which is most of  
>> them ;)). Making R thread-safe is not really an issue of a  
>> threading toolkit...
>
>
> Memory allocation does not necessarily make a function non-reentrant  
> unless non-shared static variables are involved.  There are a number  
> of thread-safe malloc implementations.    I admit,  I have not  
> looked at the R-internals in a long time.
>

I'm not talking about system-level memory allocation, but at R level  
which uses a garbage collector that is not thread safe and it does  
involve global variables. However, I'm not the right person to comment  
on those issues in detail, but just be assured that several people  
very well versed in the R internals have already looked at this (see  
below).
In addition, there are many more issues in R, because a lot of  
concepts in R just assume sequential operation (graphics devices,  
global options, hooks etc. - see below).


> Based on converting code to be thread safe when I helped port the  
> JDK to Linux, I was amazed about how much code was already reentrant  
> capable and therefore basically thread-safe (or could be made so  
> with small effort - adding a few locks).  In fact the original JVM  
> (jdk 1.0) had a "green-threads" implementation that basically ended  
> up adding wrappers to most of the memory allocation and io system  
> calls system calls to make the whole thing work.
>
> How much of the code itself is now reentrant safe - I noticed that  
> some of the R-internal routines actually used reentrant code and  
> even recursion?  How hard would it be to make the internal object/ 
> memory allocation scheme thread-safe?  As you noted there are many  
> posix threads (pthreads) implmentations out there.
>
> Is there any official effort underway to make R thread-safe?

I know that Duncan TL was looking into this since he did the job for S  
while ago, but I'm not sure how far he got. Luke Tierney has written  
up some thoughts on the issue and despite the document being quite  
dated I think it's still very applicable to today's R:
http://www.stat.uiowa.edu/~luke/R/thrgui/thrgui.pdf

Cheers,
Simon


> If so, are they looking for volunteers.  Would making R fully thread- 
> safe really make that much sense given you can parallelize vector/ 
> matrix operations now (as you noted) which probably provides the  
> most bang for the buck.
>
> Thanks,
>
> Kevin
>
>


From jmc at r-project.org  Wed Mar 18 19:13:13 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 18 Mar 2009 11:13:13 -0700
Subject: [Rd] Why S4 methods of S3 'base' generics are not used in
 'base' functions ?
In-Reply-To: <20090318144703.54e02ec1@mimi>
References: <20090318144703.54e02ec1@mimi>
Message-ID: <49C139B9.6040302@r-project.org>

The short answer is because S3 method dispatch knows nothing about S4 
methods and never has (but maybe should).  You select S4 methods by 
creating and calling an S4 generic outside of base, and base functions 
don't call it.

Details:

Your assertion is not entirely correct.  As always, you need to look at 
the individual function.

There are two different situations.  While, e.g., both `+` and as.matrix 
can have S3 or S4 methods, the mechanism is different.

R(r48116)> `+`
function (e1, e2)  .Primitive("+")
R(r48116)> as.matrix
function (x, ...)
UseMethod("as.matrix")
<environment: namespace:base>

In either case, S4 methods will be dispatched _if_ the package involved 
has correctly defined them, but the mechanism is different, and in one 
case requires the call to come from somewhere that sees the S4 methods.

For primitives, no explicit S4 generic function is defined.  Instead, 
the underlying C  code dispatches S4 methods once a package has "turned 
on" methods for that function.

For S3 generics, such as as.matrix, the setMethod() in the package 
creates an S4 generic.  This function calls for the S4 method dispatch. 
The object base::as.matrix is still an S3 generic. While it might be 
good for UseMethod() to recognize that S4 methods exist, it doesn't and 
won't for 2.9.0.

The problem with the call to scale() is then that scale.default calls 
as.matrix() _from the base namespace_  (as it should) and the resulting 
UseMethod() doesn't dispatch the S4 method (where I tend to agree with 
you that it sensibly should, given that x is an S4 object). To see the 
behavior, trace the two versions:

R(r48116)> find("as.matrix")
[1] ".GlobalEnv"   "package:base"
R(r48116)> trace(as.matrix) ## in global env.
R(r48116)> y <- scale(x) ## no trace() output
R(r48116)> trace(base::as.matrix) ## in base
R(r48116)> y <- scale(x)
trace: as.matrix(x)
R(r48116)>

Until UseMethod() does S4 dispatch, you will need to supply base 
functions with objects they understand, as in your second call to scale().

Without taking back my diatribe on S3 methods for S4 classes, I believe 
they now do work again for R 2.9.0, so you can decide whether you should 
revise and how.

John

Yohan Chalabi wrote:
> Dear list,
>
> It seems that S4 methods defined for an S3 'base' generic
> are not used in 'base' functions.
>
> This can be problematic when 'base' functions start with 
> something like 'as.matrix'.
>
>
> ### START R code
>
> setClass("classA", contains = "matrix",
>          representation(realData = "numeric"))
>
> setMethod("as.matrix", "classA", function(x) callGeneric(x at realData))
>
> x <- new("classA", diag(1:4), realData = 1:4)
>
> as.matrix(x)
>
> ## # as intended
> ##      [,1]
> ## [1,]    1
> ## [2,]    2
> ## [3,]    3
> ## [4,]    4
>
> # but as.matrix in 'base' functions dispatches to the default S3
> # method rather than to the S4 method defined above.
> scale(x)
> scale(as.matrix(x))
>
> # Note that S4 methods are well dispatched for functions which are
> # not S3 generics.
> setMethod("dimnames", "classA",
>           function(x) list(NULL, as.character(x at realData)))
> dimnames(x)
>
> solve(x) # here row names are properly assigned thanks to the 'dimnames'
>          # method defined above.
>
> ### END R code
>
> What is your recommended solution to make S4 methods of S3 'base'
> generics work in 'base' functions?
>
> A solution could be to overwrite 'as.matrix' in '.Load' and force it to
> use the S4 method with S4 objects. But doing so looks to me rather
> dangerous because it would lead to conflicts between packages.
>
> Another solution could be to define S3 methods. But, as it has been
> already explained on the list, it is a design error.
>
> Thanks in advance for any suggestion!
>
> Best regards,
> Yohan
>
>
>


From jmc at r-project.org  Wed Mar 18 19:19:15 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 18 Mar 2009 11:19:15 -0700
Subject: [Rd] exporting s3 and s4 methods
In-Reply-To: <Pine.LNX.4.43.0903180942310.8322@hymn31.u.washington.edu>
References: <Pine.LNX.4.43.0903180942310.8322@hymn31.u.washington.edu>
Message-ID: <49C13B23.40807@r-project.org>

Could you send me your package code, off-list.  I think the problem may 
be related to non-exported S3 method objects.

John

Thomas Lumley wrote:
>
> I'm still having problems getting a package to define both S3 and S4 
> methods for the same new generic, on a current r-devel (version 48144).
>
> Symptoms
>> example(bigglm)
>
> bigglm> data(trees)
>
> bigglm> ff<-log(Volume)~log(Girth)+log(Height)
>
> bigglm> a <- bigglm(ff,data=trees, chunksize=10, sandwich=TRUE)
> Error in UseMethod("bigglm", data) : no applicable method for "bigglm"
>
>> showMethods("bigglm")
> Function: bigglm (package biglm)
> formula="ANY", data="ANY"
> formula="ANY", data="DBIConnection"
> formula="formula", data="data.frame"
>     (inherited from: formula="ANY", data="ANY")
>
>> bigglm          
> standardGeneric for "bigglm" defined from package "biglm"
>
> function (formula, data, family = gaussian(), ...) 
> standardGeneric("bigglm")
> <environment: 0x8554240>
> Methods may be defined for arguments: formula, data
> Use  showMethods("bigglm")  for currently available ones.
>> getMethod("bigglm",c("ANY","ANY"))
> Method Definition (Class "derivedDefaultMethod"):
>
> function (formula, data, family = gaussian(), ...) UseMethod("bigglm", 
> data)
> <environment: namespace:biglm>
>
> Signatures:
>         formula data target  "ANY"   "ANY"
> defined "ANY"   "ANY"
>
>>  methods("bigglm")
> [1] bigglm.data.frame* bigglm.function*   bigglm.RODBC*
>
>    Non-visible functions are asterisked
> Warning messages:
> 1: In findGeneric(generic.function, parent.frame()) :
>   'bigglm' is a formal generic function; S3 methods will not likely be 
> found
> 2: In methods("bigglm") : function 'bigglm' appears not to be generic
>
> In the NAMESPACE file I have
> import(stats)
> useDynLib(biglm)
> importClassesFrom(DBI)
> exportMethods(bigglm)
> export(biglm)
> export(bigglm)
> S3method(bigglm,data.frame)
> S3method(bigglm,"function")
> S3method(bigglm, RODBC)
>
> and in the code
> bigglm<-function(formula, data, family=gaussian(),...)
>     UseMethod("bigglm", data)
> setGeneric("bigglm", signature=c("formula","data"))
>
>
> bigglm.data.frame<-function(formula, data, ..., chunksize=5000){ <snip>
>
> setMethod("bigglm",
>            c("ANY","DBIConnection"),
>            function(formula, data, family = gaussian(),
>                                    tablename, ..., chunksize=5000){
>              terms<-terms(formula)
>              modelvars<-all.vars(formula)
>      <snip>
>
>
> Any suggestions?
>
>     -thomas
>
> Thomas Lumley            Assoc. Professor, Biostatistics
> tlumley at u.washington.edu    University of Washington, Seattle
>
>


From wdunlap at tibco.com  Wed Mar 18 19:49:59 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Mar 2009 11:49:59 -0700
Subject: [Rd] Match .3 in a sequence
In-Reply-To: <49BFF6CD.7090302@stats.uwo.ca>
References: <48f8cced0903160636k112500f6k4b8d46c1ac775d89@mail.gmail.com>	<8b356f880903160824q4fb9068br1f22601064a8042d@mail.gmail.com><48f8cced0903170826m6957766dj402bfdfe1390368d@mail.gmail.com>
	<49BFF6CD.7090302@stats.uwo.ca>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700DF190C@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Tuesday, March 17, 2009 12:15 PM
> To: Daniel Murphy
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Match .3 in a sequence
> 
> On 3/17/2009 11:26 AM, Daniel Murphy wrote:
> > Is this a reasonably fast way to do an approximate match of 
> a vector x to
> > values in a list?
> > 
> > match.approx  <- function(x,list,tol=.0001)
> >     sapply(apply(abs(outer(list,x,"-"))<tol,2,which),"[",1)
> 
> If you are willing to assume that the list values are all 
> multiples of 
> 2*tol, then it's easy:  just divide both x and list by 2*tol, 
> round to 
> nearest integer, and use the regular match function.
> 
> If not, it becomes harder; I'd probably use a solution like yours.
> 
> Duncan Murdoch

Here are 2 other implentations of that match.approx function
which use much less memory (and are faster) when the length
of 'x' and 'list' are long (>100, say).  The first uses 
approx(method="const") to figure out which entries in the
list are just below and above each entry in x and the second 
uses sorting tricks to do the same thing.  Then you only have
to figure out if the closest of those 2 entries is close enough.

The original one above fails when tol>min(diff(sort(list))).

match.approx2 <-
function(x,list,tol=.0001) {
    o1 <- rep.int(c(FALSE,TRUE),
c(length(x),length(list)))[order(c(x,list))]
    o2 <- rep.int(c(FALSE,TRUE),
c(length(x),length(list)))[order(c(x,list))]
   
    below <- approx(list, list, xout=x, method="constant", f=0)$y
    above <- approx(list, list, xout=x, method="constant", f=1)$y
    stopifnot(all(below<=x, na.rm=TRUE), all(above>=x, na.rm=TRUE))
    closestInList <- ifelse(x-below < above-x, below, above)
    closestInList[x<min(list)] <- min(list)
    closestInList[x>max(list)] <- max(list)
    closestInList[abs(x-closestInList)>tol] <- NA
    match(closestInList, list)
}
match.approx3 <-
function(x, list, tol=.0001){
    stopifnot(length(list)>0, !any(is.na(x)), !any(is.na(list)))
    oox <- order(order(x)) # essentially rank(x)
    i <- rep(c(FALSE,TRUE), c(length(x),length(list)))[order(c(x,
list))]
    i <- cumsum(i)[!i] + 1L
    i[i > length(list)] <- NA
    i <- order(list)[i]
    leastUpperBound <- i[oox]
    i <- rep(c(TRUE,FALSE), c(length(list),length(x)))[order(c(list,
x))]
    i <- cumsum(i)[!i]
    i[i < 1L] <- NA
    i <- order(list)[i]
    greatestLowerBound <- i[oox]
    closestInList <-
        ifelse(is.na(greatestLowerBound),
            leastUpperBound, # above max(list)
            ifelse(is.na(leastUpperBound),
                greatestLowerBound, # below min(list)
 
ifelse(x-list[greatestLowerBound]<list[leastUpperBound]-x,
                    greatestLowerBound,
                    leastUpperBound)))
    if (tol<Inf)
        closestInList[abs(x - list[closestInList])>tol] <- NA
    closestInList
}

> > 
> > Thanks.
> > -Dan
> > 
> > On Mon, Mar 16, 2009 at 8:24 AM, Stavros Macrakis 
> <macrakis at alum.mit.edu>wrote:
> > 
> >> Well, first of all, seq(from=.2,to=.3) gives c(0.2), so I 
> assume you
> >> really mean something like seq(from=.2,to=.3,by=.1), which gives
> >> c(0.2, 0.3).
> >>
> >> %in% tests for exact equality, which is almost never a 
> good idea with
> >> floating-point numbers.
> >>
> >> You need to define what exactly you mean by "in" for floating-point
> >> numbers.  What sort of tolerance are you willing to allow?
> >>
> >> Some possibilities would be for example:
> >>
> >> approxin <- function(x,list,tol) any(abs(list-x)<tol)   # absolute
> >> tolerance
> >>
> >> rapproxin <- function(x,list,tol) (x==0 && 0 %in% list) ||
> >> any(abs((list-x)/x)<=tol,na.rm=TRUE)
> >>     # relative tolerance; only exact 0 will match 0
> >>
> >> Hope this helps,
> >>
> >>          -s
> >>
> >> On Mon, Mar 16, 2009 at 9:36 AM, Daniel Murphy 
> <chiefmurphy at gmail.com>
> >> wrote:
> >> > Hello:I am trying to match the value 0.3 in the sequence 
> seq(.2,.3). I
> >> get
> >> >> 0.3 %in% seq(from=.2,to=.3)
> >> > [1] FALSE
> >> > Yet
> >> >> 0.3 %in% c(.2,.3)
> >> > [1] TRUE
> >> > For arbitrary sequences, this "invisible .3" has been 
> problematic. What
> >> is
> >> > the best way to work around this?
> >>
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From Manuel.Eugster at stat.uni-muenchen.de  Wed Mar 18 20:24:48 2009
From: Manuel.Eugster at stat.uni-muenchen.de (Manuel J. A. Eugster)
Date: Wed, 18 Mar 2009 20:24:48 +0100 (CET)
Subject: [Rd] [SoC09-Info] R-Foundation accepted.
Message-ID: <1830.213.97.161.20.1237404288.squirrel@webmail.lrz-muenchen.de>

Hi everybody,

Google has accepted the R-Foundation as mentoring organization
for the Summer of Code 2009. Jippi!

Thus, the idea for the next few days (18.-23.) is that "Would-be
student participants discuss application ideas with mentoring
organizations" (our collected ideas or their new ideas). Then,
from March 23 to April 3, the students apply for projects with
their project proposals. Until April 15, all potential mentors
discuss, review and rank student proposals, and then Google
assigns the number of sponsored projects (slots).

In advance: all potential mentors must register at the official
GSoC webpage [1] and send an request to the R-Project organization.


Best,

Manuel.

[1] http://socghop.appspot.com/


From wdunlap at tibco.com  Thu Mar 19 00:00:51 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Mar 2009 16:00:51 -0700
Subject: [Rd] sprintf("%d", integer(0)) aborts
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700DF1A0E@NA-PA-VBE03.na.tibco.com>

In R's sprintf() if any of the arguments has length 0
the function aborts.  E.g.,

   > sprintf("%d", integer(0))
   Error in sprintf("%d", integer(0)) : zero-length argument
   > sprintf(character(), integer(0))
   Error in sprintf(character(), integer(0)) :
     'fmt' is not a non-empty character vector

This comes up in code like
   x[nchar(x)==0] <- sprintf("No. %d", seq_along(x)[nchar(x)==0])
which works if x contains any empty strings
   x<-c("One","Two","") # changes "" -> "No. 3"
but not if it doesn't
   x<-c("One","Two","Three") # throws error instead of doing nothing

When I wrote S+'s sprintf() I had it act like the binary
arithmetic operators, returning a zero long result if any
argument were zero long.  (Otherwise its result is as long
as the longest input.)  I think it would be nice if R's
sprintf did this also.

Currently you must add defensive code (if (any(nchar(x)==0))...)
to make functions using sprintf to work in all cases and that
muddies up the code and slows things down.

Do you think this is a reasonable thing to do?  I've attached
a possible patch to src/main/sprintf.c makes the examples above
return character(0).

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 

-------------------------------------------------------------------

Index: sprintf.c
===================================================================
--- sprintf.c   (revision 48148)
+++ sprintf.c   (working copy)
@@ -79,13 +79,13 @@
     static R_StringBuffer outbuff = {NULL, 0, MAXELTSIZE};
     Rboolean use_UTF8;

-    outputString = R_AllocStringBuffer(0, &outbuff);
-
     /* grab the format string */
     nargs = length(args);
     format = CAR(args);
-    if (!isString(format) || length(format) == 0)
+    if (!isString(format))
        error(_("'fmt' is not a non-empty character vector"));
+    if (length(format) == 0)
+       return allocVector(STRSXP, 0) ;
     args = CDR(args); nargs--;
     if(nargs >= 100)
        error(_("only 100 arguments are allowed"));
@@ -97,9 +97,12 @@
     for(i = 0; i < nargs; i++) {
        lens[i] = length(a[i]);
        if(lens[i] == 0)
-           error(_("zero-length argument"));
+           return allocVector(STRSXP, 0) ;
        if(maxlen < lens[i]) maxlen = lens[i];
     }
+
+    outputString = R_AllocStringBuffer(0, &outbuff);
+
     if(maxlen % length(format))
        error(_("arguments cannot be recycled to the same length"));
     for(i = 0; i < nargs; i++)

From nakama at ki.rim.or.jp  Thu Mar 19 02:08:21 2009
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 19 Mar 2009 10:08:21 +0900
Subject: [Rd] [R] R with MKL
In-Reply-To: <dc41e1260903180517i10ede2e1p73d2bf0750ac2d6b@mail.gmail.com>
References: <fb1538e20903161533u599d8c00mef61f71bf2427a39@mail.gmail.com>
	<dc41e1260903162012y2d3d2414o41fbe5082945b7ae@mail.gmail.com>
	<fb1538e20903172251u3ad9cd64lcc27d305b26acdce@mail.gmail.com>
	<dc41e1260903180517i10ede2e1p73d2bf0750ac2d6b@mail.gmail.com>
Message-ID: <dc41e1260903181808l58b9522bx977dca4b39b9cb4@mail.gmail.com>

bug of MKL 11.0...

_gfortran_internal_malloc64 and _gfortran_internal_free is needed by [cz]labrad
in libmkl_gnu_thread.
There is it in libgfortran of gfortran-4.1 as an outside symbol, but
there is not it for
gfortran-4.2 or latter.
Many people pushed forward old gfortran, but there was not the problem
in gfortran-4.2
or latter.
if I did it as follows in my environment because the contents were
malloc and free either.

  # my copy for editing
  MKL_LIB_PATH=/usr/local/mkl
  ORIG_MKL_LIB_PATH=/opt/intel/Compiler/11.0/*/mkl/lib/em64t/
  mkdir $MKL_LIB_PATH
  cp $ORIG_MKL_LIB_PATH/{libmkl_gf_lp64,libmkl_core}.a $MKL_LIB_PATH
  cp $ORIG_MKL_LIB_PATH/libmkl_gnu_thread.a $MKL_LIB_PATH

  # add of _gfortran_internal_malloc64 and _gfortran_internal_free to
libmkl_gnu_thread.a
  wget http://prs.ism.ac.jp/~nakama/mkl/mkl_gf.c
  gcc -O3 -fPIC -g -c mkl_gf.c
  ar r $MKL_LIB_PATH/libmkl_gnu_thread.a mkl_gf.o

Because I may be recovered in the newer version, this work is unnecessary for
outside symbol if _gfortran_internal_free disappears.

 $ nm -A libmkl_gnu_thread.a |grep _gfortran_internal   # MKL11.0 now
libmkl_gnu_thread.a:zlabrd_omp.o:                 U _gfortran_internal_free
libmkl_gnu_thread.a:zlabrd_omp.o:                 U _gfortran_internal_malloc64
libmkl_gnu_thread.a:clabrd_omp.o:                 U _gfortran_internal_free
libmkl_gnu_thread.a:clabrd_omp.o:                 U _gfortran_internal_malloc64

Welcome to Hell of MKL.;-)

2009/3/18 Ei-ji Nakama <nakama at ki.rim.or.jp>:
> Hi Cristi?n.
>
>>> However, It is a little different.( -lgomp and configure line)
>>>
>>> MKL=" ? -L$@{MKL_LIB_PATH@} ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
>>> ? ? ? ?-Wl,--start-group ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
>>> ? ? ? ? ? ? ? ?$@{MKL_LIB_PATH@}/libmkl_gf_lp64.a ? ? ? ?\
>>> ? ? ? ? ? ? ? ?$@{MKL_LIB_PATH@}/libmkl_gnu_thread.a ? ? \
>>> ? ? ? ? ? ? ? ?$@{MKL_LIB_PATH@}/libmkl_core.a ? ? ? ? ? \
>>> ? ? ? ?-Wl,--end-group ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
>>> ? ? ? ?-lgomp -lpthread"
>>> ./configure --with-blas="$MKL" --with-lapack="$MKL"
>>>
>> ...
>>
>> Thanks for all your answers. I read carefully the userguide and the
>> admin guide. I now understand that with gfortran I need to use
>> libmkl_gf_lp64 and libmkl_gnu_thread, either shared or static.
>> Unfortunately for MKL version 10.1.1.019, libmkl_gnu_thread links
>> against the symbol "_gfortran_internal_malloc64" which was present in
>> gcc-4.1 and is not present anymore in gcc-4.3.
>
> However, the support ?of openmp is gcc-4.2 or latter.
>
>> So my alternatives are installing an older compiler, waiting for a
>> newer MKL version, building R with Intel compiler or switching away
>> from MKL.
>
> Please download the following files, and test the procedure to which
> the file is written first.
>
> ? ? ?http://prs.ism.ac.jp/~nakama/mkl/mkl_gf.c
>

-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From maechler at stat.math.ethz.ch  Thu Mar 19 09:09:11 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 19 Mar 2009 09:09:11 +0100
Subject: [Rd] suggestion/request: install.packages and unnecessary file
	modifications
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F87051705E427@exvic-mbx03.nexus.csiro.au>
References: <62C82B39B8A85E4B95A18F7F7B852F87051705E427@exvic-mbx03.nexus.csiro.au>
Message-ID: <18881.64935.651682.73321@stat.math.ethz.ch>

Thank you, Mark,

I've now committed (a version of) your suggestion to R-devel
(destined to become R 2.9.0 on April 17).

Martin Maechler, ETH Zurich

>>>>>   <Mark.Bravington at csiro.au>
>>>>>     on Tue, 10 Mar 2009 21:52:30 +1100 writes:

    > Dear R-devel
    > When 'install.packages' runs, it updates all html files in all packages. Mostly, there seems to be no actual change to the html file contents, but the date/time does change. This has causing been me a bit of trouble, because I keep synchronized versions of R on several different machines, and whenever I install a package, many MB of file transfers are required; my slow upload link can't cope.

    > The culprit appears to be 'utils:::fixup.package.URLs'. Adding the commented lines below, near the end of the function, avoids the unnecessary rewrite.

    > Mark Bravington
    > CSIRO
    > Hobart
    > Australia

    > for (f in files) {
    > page <- readLines(f)
    > old.page <- page # MVB
    > page <- gsub(olddoc, doc, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(oldbase, base, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(oldutils, utils, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(oldgraphics, graphics, page, fixed = TRUE, 
    > useBytes = TRUE)
    > page <- gsub(oldstats, stats, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(olddata, datasets, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(oldgrD, grD, page, fixed = TRUE, useBytes = TRUE)
    > page <- gsub(oldmeth, meth, page, fixed = TRUE, useBytes = TRUE)
    > if( identical( page, old.page)) # MVB
    > next # MVB
    > out <- try(file(f, open = "w"), silent = TRUE)
    > if (inherits(out, "try-error")) {
    > warning(gettextf("cannot update '%s'", f), domain = NA)
    > next
    > }
    > writeLines(page, out)
    > close(out)
    > }
    > return(TRUE)
    > }

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 19 10:17:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 19 Mar 2009 10:17:20 +0100
Subject: [Rd] [R] incoherent conversions from/to raw
In-Reply-To: <49C1833F.3050302@idi.ntnu.no>
References: <49C1833F.3050302@idi.ntnu.no>
Message-ID: <49C20DA0.2030008@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> interestingly,
>
>     c(1, as.raw(1))
>     # error: type 'raw' is unimplemented in 'RealAnswer'
>
>   

three more comments.


(1)
the above is interesting in the light of what ?c says:

"
The output type is determined from the highest type of the
     components in the hierarchy NULL < raw < logical < integer < real
     < complex < character < list < expression.
"

which seems to suggest that raw components should be coerced to whatever
the highest type among all arguments to c, which clearly doesn't happen:

    test = function(type)
        c(as.raw(1), get(sprintf('as.%s',type))(1))

    for (type in c('null', 'logical', 'integer', 'real', 'complex',
'character', 'list', 'expression'))
       tryCatch(test(type), error = function(e) cat(sprintf("raw won't
coerce to %s type\n", type)))

which shows that raw won't coerce to the four first types in the
'hierarchy' (excluding NULL), but it will to character, list, and
expression.

suggestion:   improve the documentation, or adapt the implementation to
a more coherent design.



(2)
incidentally, there's a bug somewhere there related to the condition
system and printing:

    tryCatch(stop(), error=function(e) print(e))
    # works just fine

    tryCatch(stop(), error=function(e) sprintf('%s', e))
    # *** caught segfault ***
    # address (nil), cause 'memory not mapped'

    # Traceback:
    # 1: sprintf("%s", e)
    # 2: value[[3]](cond)
    # 3: tryCatchOne(expr, names, parentenv, handlers[[1]])
    # 4: tryCatchList(expr, classes, parentenv, handlers)
    # 5: tryCatch(stop(), error = function(e) sprintf("%s", e))

    # Possible actions:
    # 1: abort (with core dump, if enabled)
    # 2: normal R exit
    # 3: exit R without saving workspace
    # 4: exit R saving workspace
    # Selection:
 
interestingly, it is possible to stay in the session by typing ^C.  the
session seems to work, but if the tryCatch above is tried once again, a
segfault causes r to crash immediately:

    # ^C
    tryCatch(stop(), error=function(e) sprintf('%s', e))
    # [whoever at wherever] $

however, this doesn't happen if some other code is evaluated first:

    # ^C
    x = 1:10^8
    tryCatch(stop(), error=function(e) sprintf('%s', e))
    # Error in sprintf("%s", e) : 'getEncChar' must be called on a CHARSXP
  
this can't be a feature.  (tried in both 2.8.0 and r-devel;  version
info at the bottom.)

suggestion:  trace down and fix the bug.



(3)
the error argument to tryCatch is used in two examples in ?tryCatch, but
it is not explained anywhere in the help page.  one can guess that the
argument name corresponds to the class of conditions the handler will
handle, but it would be helpful to have this stated explicitly.  the
help page simply says:

"
   If a condition is signaled while evaluating 'expr' then
     established handlers are checked, starting with the most recently
     established ones, for one matching the class of the condition.
     When several handlers are supplied in a single 'tryCatch' then the
     first one is considered more recent than the second. 
"

which is uninformative in this respect -- what does 'one matching the
class' mean?

suggestion:  improve the documentation.

vQ


> version
               _                          
platform       i686-pc-linux-gnu          
arch           i686                       
os             linux-gnu                  
system         i686, linux-gnu            
status                                    
major          2                          
minor          8.0                        
year           2008                       
month          10                         
day            20                         
svn rev        46754                      
language       R                          
version.string R version 2.8.0 (2008-10-20)



> version
              
_                                                              
platform      
i686-pc-linux-gnu                                              
arch          
i686                                                           
os            
linux-gnu                                                      
system         i686,
linux-gnu                                                
status         Under development
(unstable)                                   
major         
2                                                              
minor         
9.0                                                            
year          
2009                                                           
month         
03                                                             
day           
19                                                             
svn rev       
48152                                                          
language      
R                                                              
version.string R version 2.9.0 Under development (unstable) (2009-03-19
r48152)


From hkawakat at gmail.com  Thu Mar 19 10:37:11 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Thu, 19 Mar 2009 09:37:11 +0000
Subject: [Rd] R does not compile any more on FreeBSD 8.0-CURRENT
Message-ID: <307b90470903190237p73869d19p742003c9a46f6188@mail.gmail.com>

Rainer Hurling wrote:
> On a recent FreeBSD 8.0-CURRENT (i386) building R (any version)
> breaks with the following messages:
[...]

I run 7.1-RELEASE (amd64) so I cannot comment on any potential issues
with 8.0-CURRENT. On my machine the r-devel tarball (r48148) builds
without any problems but I use

./configure MAKE=gmake

Have you tried gmake?

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From ripley at stats.ox.ac.uk  Thu Mar 19 11:34:03 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Mar 2009 10:34:03 +0000 (GMT)
Subject: [Rd] sprintf("%d", integer(0)) aborts
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700DF1A0E@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700DF1A0E@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.0903191024300.12166@gannet.stats.ox.ac.uk>

On Wed, 18 Mar 2009, William Dunlap wrote:

> In R's sprintf() if any of the arguments has length 0
> the function aborts.  E.g.,
>
>   > sprintf("%d", integer(0))
>   Error in sprintf("%d", integer(0)) : zero-length argument
>   > sprintf(character(), integer(0))
>   Error in sprintf(character(), integer(0)) :
>     'fmt' is not a non-empty character vector
>
> This comes up in code like
>   x[nchar(x)==0] <- sprintf("No. %d", seq_along(x)[nchar(x)==0])
> which works if x contains any empty strings
>   x<-c("One","Two","") # changes "" -> "No. 3"
> but not if it doesn't
>   x<-c("One","Two","Three") # throws error instead of doing nothing
>
> When I wrote S+'s sprintf() I had it act like the binary
> arithmetic operators, returning a zero long result if any
> argument were zero long.  (Otherwise its result is as long
> as the longest input.)  I think it would be nice if R's
> sprintf did this also.
>
> Currently you must add defensive code (if (any(nchar(x)==0))...)
> to make functions using sprintf to work in all cases and that
> muddies up the code and slows things down.
>
> Do you think this is a reasonable thing to do?  I've attached
> a possible patch to src/main/sprintf.c makes the examples above
> return character(0).

Yes.  It was deliberate that it works (and is documented) the way it 
is, and I've not previously seen any problematic examples.  But at 
least for the ... args, allowing zero-length arguments seems very 
reasonable.  I'm less convinced by zero-length formats, but the rule 
may be easier to explain if we allow them.

This will need a documentation change, and I'll look into it when I 
can.

>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
> -------------------------------------------------------------------
>
> Index: sprintf.c
> ===================================================================
> --- sprintf.c   (revision 48148)
> +++ sprintf.c   (working copy)
> @@ -79,13 +79,13 @@
>     static R_StringBuffer outbuff = {NULL, 0, MAXELTSIZE};
>     Rboolean use_UTF8;
>
> -    outputString = R_AllocStringBuffer(0, &outbuff);
> -
>     /* grab the format string */
>     nargs = length(args);
>     format = CAR(args);
> -    if (!isString(format) || length(format) == 0)
> +    if (!isString(format))
>        error(_("'fmt' is not a non-empty character vector"));
> +    if (length(format) == 0)
> +       return allocVector(STRSXP, 0) ;
>     args = CDR(args); nargs--;
>     if(nargs >= 100)
>        error(_("only 100 arguments are allowed"));
> @@ -97,9 +97,12 @@
>     for(i = 0; i < nargs; i++) {
>        lens[i] = length(a[i]);
>        if(lens[i] == 0)
> -           error(_("zero-length argument"));
> +           return allocVector(STRSXP, 0) ;
>        if(maxlen < lens[i]) maxlen = lens[i];
>     }
> +
> +    outputString = R_AllocStringBuffer(0, &outbuff);
> +
>     if(maxlen % length(format))
>        error(_("arguments cannot be recycled to the same length"));
>     for(i = 0; i < nargs; i++)
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bilel.masmoudi at gmail.com  Thu Mar 19 12:33:11 2009
From: bilel.masmoudi at gmail.com (Bilel)
Date: Thu, 19 Mar 2009 12:33:11 +0100
Subject: [Rd] using R with java
In-Reply-To: <e37a704c0903190417u14cb934ch6e54e5c2fb371fcf@mail.gmail.com>
References: <e37a704c0903190417u14cb934ch6e54e5c2fb371fcf@mail.gmail.com>
Message-ID: <e37a704c0903190433v67467e39tf6de30abf6c86415@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090319/c92be961/attachment.pl>

From simon.urbanek at r-project.org  Thu Mar 19 14:18:49 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Mar 2009 09:18:49 -0400
Subject: [Rd] using R with java
In-Reply-To: <e37a704c0903190433v67467e39tf6de30abf6c86415@mail.gmail.com>
References: <e37a704c0903190417u14cb934ch6e54e5c2fb371fcf@mail.gmail.com>
	<e37a704c0903190433v67467e39tf6de30abf6c86415@mail.gmail.com>
Message-ID: <39D791D9-9060-484D-B03F-4D6BB71D8BD3@r-project.org>


On Mar 19, 2009, at 7:33 , Bilel wrote:

> Hi,
>>
>> I am a java programmer, an I want to use R from java. could so help  
>> me thanks for telling me whether I 'm using the good mailing list.
>>

There's rJava package for this and the mailing list for that package is
http://mailman.rz.uni-augsburg.de/mailman/listinfo/stats-rosuda-devel
so feel free to ask there for help.

Cheer,
Simon


From wdunlap at tibco.com  Thu Mar 19 16:20:58 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Mar 2009 08:20:58 -0700
Subject: [Rd] sprintf("%d", integer(0)) aborts
In-Reply-To: <alpine.LFD.2.00.0903191024300.12166@gannet.stats.ox.ac.uk>
References: <77EB52C6DD32BA4D87471DCD70C8D700DF1A0E@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.0903191024300.12166@gannet.stats.ox.ac.uk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700E8EC77@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Thursday, March 19, 2009 3:34 AM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] sprintf("%d", integer(0)) aborts
> 
> On Wed, 18 Mar 2009, William Dunlap wrote:
> 
> > In R's sprintf() if any of the arguments has length 0
> > the function aborts.  E.g.,
> >
> >   > sprintf("%d", integer(0))
> >   Error in sprintf("%d", integer(0)) : zero-length argument
> >   > sprintf(character(), integer(0))
> >   Error in sprintf(character(), integer(0)) :
> >     'fmt' is not a non-empty character vector
> >
> > This comes up in code like
> >   x[nchar(x)==0] <- sprintf("No. %d", seq_along(x)[nchar(x)==0])
> > which works if x contains any empty strings
> >   x<-c("One","Two","") # changes "" -> "No. 3"
> > but not if it doesn't
> >   x<-c("One","Two","Three") # throws error instead of doing nothing
> >
> > When I wrote S+'s sprintf() I had it act like the binary
> > arithmetic operators, returning a zero long result if any
> > argument were zero long.  (Otherwise its result is as long
> > as the longest input.)  I think it would be nice if R's
> > sprintf did this also.
> >
> > Currently you must add defensive code (if (any(nchar(x)==0))...)
> > to make functions using sprintf to work in all cases and that
> > muddies up the code and slows things down.
> >
> > Do you think this is a reasonable thing to do?  I've attached
> > a possible patch to src/main/sprintf.c makes the examples above
> > return character(0).
> 
> Yes.  It was deliberate that it works (and is documented) the way it 
> is, and I've not previously seen any problematic examples.

I was prompted to suggest the change by a note from Jim Holtman
in yesterday's R-help:

   > system.time({
   +     x <- sample(50000)  # test data
   +     x[sample(50000,10000)] <- 'asdfasdf'  # characters strings
   +     which.num <- grep("^[ 0-9]+$", x)  # find numbers
   +     # convert to leading 0
   +     x[which.num] <- sprintf("%018.0f", as.numeric(x[which.num]))
   +     x[-which.num] <- toupper(x[-which.num])
   + })

This code failed when I converted it to a function to run
through sapply because then which.num was often integer(0).
When used in production it would probably work for a long time
before seeing a sample in which which.num was integer(0).
(Of course, it would then silently mess up on the next line,
x[-which.num]<-...)

>  But at 
> least for the ... args, allowing zero-length arguments seems very 
> reasonable.  I'm less convinced by zero-length formats, but the rule 
> may be easier to explain if we allow them.

Those were my thoughts as well.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


From maechler at stat.math.ethz.ch  Fri Mar 20 10:46:17 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 20 Mar 2009 10:46:17 +0100
Subject: [Rd] [R] which.na
In-Reply-To: <46B8F50B47374D0FB12E205F51C291FA@DD4XFW31>
References: <816b5ce40903191837y58f6dc0bw98f5cdbd41f11484@mail.gmail.com>
	<46B8F50B47374D0FB12E205F51C291FA@DD4XFW31>
Message-ID: <18883.26089.830116.969445@lynne.math.ethz.ch>

>>>>> "CAPE" == Charles Annis, P E <Charles.Annis at statisticalengineering.com>
>>>>>     on Thu, 19 Mar 2009 22:46:10 -0400 writes:

    >> ?is.na
    >> x <- c(NA, 3, 4, 5, NA)
    >> which(is.na(x))
    CAPE> [1] 1 5

well, of course.

But note that  which.na(.) could be implemented to be 
faster (because needing much less memory) than the above,
notably when  x  is large and  has only few NAs

But this now has *REALLY*  changed into a topic belonging to
R-devel, not R-help

--> hence I've diverted the thread to there.

I have recently entertained similar thoughts, i.e. wished for R
functions that compute  
	  which( function_returning_logical(..) )
and also
	    any( function_returning_logical(..) )

directly {on .Internal i.e. C-level} instead of going to
construct the potentially huge logical vector.

For what functions should this happen?
I agree that  is.na() is one of them; but then, why not
    is.nan() /  is.finite() 
too?

Instead of defining a slew of such functions  
which.foo(), which.bar(), any.foo(), any.bar(), etc,
it would be nice to have a generic interface such as

   whichApply(x, is.na)
   whichApply(x, is.nan)

   anyApply(x, is.na) 

where internally, for some functions {in a given internal
table}, the fast shortcut would be used, and for others the
interface would be equivalent to  which( thatFunction( x ) )

Martin Maechler, ETH Zurich (and R Core team)


    CAPE> Charles Annis, P.E.

    CAPE> Charles.Annis at StatisticalEngineering.com
    CAPE> phone: 561-352-9699
    CAPE> eFax:  614-455-3265
    CAPE> http://www.StatisticalEngineering.com
 

    CAPE> -----Original Message-----
    CAPE> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
    CAPE> Behalf Of Santosh
    CAPE> Sent: Thursday, March 19, 2009 9:37 PM
    CAPE> To: r-help at r-project.org
    CAPE> Subject: [R] which.na

    CAPE> Hi R- users

    CAPE> I was wondering if there is any function equivalent to which.na used in S+?

    CAPE> Thanks much in advance!

    CAPE> Regards,
    CAPE> Santosh

    CAPE> [[alternative HTML version deleted]]

    CAPE> ______________________________________________
    CAPE> R-help at r-project.org mailing list
    CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
    CAPE> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    CAPE> and provide commented, minimal, self-contained, reproducible code.

    CAPE> ______________________________________________
    CAPE> R-help at r-project.org mailing list
    CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
    CAPE> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    CAPE> and provide commented, minimal, self-contained, reproducible code.


From murdoch at stats.uwo.ca  Fri Mar 20 11:28:50 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 20 Mar 2009 06:28:50 -0400
Subject: [Rd] [R] which.na
In-Reply-To: <18883.26089.830116.969445@lynne.math.ethz.ch>
References: <816b5ce40903191837y58f6dc0bw98f5cdbd41f11484@mail.gmail.com>	<46B8F50B47374D0FB12E205F51C291FA@DD4XFW31>
	<18883.26089.830116.969445@lynne.math.ethz.ch>
Message-ID: <49C36FE2.7070407@stats.uwo.ca>

Martin Maechler wrote:
>>>>>> "CAPE" == Charles Annis, P E <Charles.Annis at statisticalengineering.com>
>>>>>>     on Thu, 19 Mar 2009 22:46:10 -0400 writes:
>>>>>>             
>
>     >> ?is.na
>     >> x <- c(NA, 3, 4, 5, NA)
>     >> which(is.na(x))
>     CAPE> [1] 1 5
>
> well, of course.
>
> But note that  which.na(.) could be implemented to be 
> faster (because needing much less memory) than the above,
> notably when  x  is large and  has only few NAs
>
> But this now has *REALLY*  changed into a topic belonging to
> R-devel, not R-help
>
> --> hence I've diverted the thread to there.
>
> I have recently entertained similar thoughts, i.e. wished for R
> functions that compute  
> 	  which( function_returning_logical(..) )
> and also
> 	    any( function_returning_logical(..) )
>
> directly {on .Internal i.e. C-level} instead of going to
> construct the potentially huge logical vector.
>
> For what functions should this happen?
> I agree that  is.na() is one of them; but then, why not
>     is.nan() /  is.finite() 
> too?
>
> Instead of defining a slew of such functions  
> which.foo(), which.bar(), any.foo(), any.bar(), etc,
> it would be nice to have a generic interface such as
>
>    whichApply(x, is.na)
>    whichApply(x, is.nan)
>
>    anyApply(x, is.na) 
>
> where internally, for some functions {in a given internal
> table}, the fast shortcut would be used, and for others the
> interface would be equivalent to  which( thatFunction( x ) )
>   
A couple of different interfaces to the same idea:

  - which() could recognize a few thatFunction(x) calls before 
evaluating them, and do the fast internal version.  (This is hard 
because it needs to know
that the user hasn't redefined is.na, etc.  Probably not worth doing.)

  - which() could gain a new arg, so that

       which(x, test=is.na)

    would do as your whichApply() does.

Duncan Murdoch
> Martin Maechler, ETH Zurich (and R Core team)
>
>
>     CAPE> Charles Annis, P.E.
>
>     CAPE> Charles.Annis at StatisticalEngineering.com
>     CAPE> phone: 561-352-9699
>     CAPE> eFax:  614-455-3265
>     CAPE> http://www.StatisticalEngineering.com
>  
>
>     CAPE> -----Original Message-----
>     CAPE> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>     CAPE> Behalf Of Santosh
>     CAPE> Sent: Thursday, March 19, 2009 9:37 PM
>     CAPE> To: r-help at r-project.org
>     CAPE> Subject: [R] which.na
>
>     CAPE> Hi R- users
>
>     CAPE> I was wondering if there is any function equivalent to which.na used in S+?
>
>     CAPE> Thanks much in advance!
>
>     CAPE> Regards,
>     CAPE> Santosh
>
>     CAPE> [[alternative HTML version deleted]]
>
>     CAPE> ______________________________________________
>     CAPE> R-help at r-project.org mailing list
>     CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>     CAPE> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     CAPE> and provide commented, minimal, self-contained, reproducible code.
>
>     CAPE> ______________________________________________
>     CAPE> R-help at r-project.org mailing list
>     CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>     CAPE> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     CAPE> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From r.m.parizi at gmail.com  Thu Mar 19 13:08:57 2009
From: r.m.parizi at gmail.com (RMP)
Date: Thu, 19 Mar 2009 05:08:57 -0700 (PDT)
Subject: [Rd] using R with java
In-Reply-To: <e37a704c0903190433v67467e39tf6de30abf6c86415@mail.gmail.com>
References: <e37a704c0903190433v67467e39tf6de30abf6c86415@mail.gmail.com>
Message-ID: <22598846.post@talk.nabble.com>


Hi,

In order to do this you should use JRI (Java R Interface).
Note, you should first download rJava package within which you can find the
JRI library.

Good luck!
RMP


Bilel Masmoudi wrote:
> 
> Hi,
>>
>> I am a java programmer, an I want to use R from java.
>> could so help me
>> thanks for telling me whether I 'm using the good mailing list.
>>
>> thanks!!
>>
>>
>>
> 
> 
> -- 
> Bilel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Re%3A-using-R-with-java-tp22598392p22598846.html
Sent from the R devel mailing list archive at Nabble.com.


From anne.gilman at gmail.com  Fri Mar 20 06:15:12 2009
From: anne.gilman at gmail.com (anne.gilman at gmail.com)
Date: Fri, 20 Mar 2009 06:15:12 +0100 (CET)
Subject: [Rd] v2.8.1 crashes on quit(save="yes") or just won't save
	(PR#13612)
Message-ID: <20090320051512.29F252832182@mail.pubhealth.ku.dk>

Full_Name: Anne Gilman
Version: 2.8.1
OS: Mac OS X  10.4.11
Submission from: (NULL) (132.177.75.245)


Dear R Team,

Today I upgraded from R 2.2.2 to 2.8.1  ...then I restarted, did a bunch of
work, and tried to quit.  (Note that I have oodles of stuff saved in the work
environment; took almost a full minute to start up.)  After over 10 minutes, it
was still trying to close up, and the problem (below) for DBfetch was mentioned,
plus it said

*** caught segfault ***  
address 0x7fffdeb1  
cause 'memory not mapped'  

(retyped from my notes, no way to grab)

After about five more minutes, I did a Force Quit.  Then I reproduced the bug. 
I opened R, loaded a CSV file from my previous day's work, then quit - here's
what happened:

> quit(save="yes")
Error in .Call("R_lazyLoadDBfetch", key, file, compressed, hook, PACKAGE =
"base") : 
  C symbol name "R_lazyLoadDBfetch" not in DLL for package "base"
> quit(save="no")

(that latter command worked, 2nd time, no need for Force Quit)

Yarg!  I know I can work around this using write.csv(), but I guess my lesson is
never to change versions in the middle of one's dissertation analyses!

with thanks,

Anne G.


From waku at idi.ntnu.no  Fri Mar 20 09:20:09 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Fri, 20 Mar 2009 09:20:09 +0100 (CET)
Subject: [Rd] sprintf causes a segfault (PR#13613)
Message-ID: <20090320082009.68A86283219E@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.8.0 and 2.10.0 r48163
OS: Ubuntu 8.04 Linux 32bit
Submission from: (NULL) (129.241.198.172)


the following code illustrates a problem with sprintf which consistently causes
a segfault when applied to certain type of arguments.  it also shows
inconsistent consequences of the segfault:

   (e = tryCatch(stop(), error=identity))
   # e is an error object

   sprintf('%d', e)
   # error in sprintf("%d", e) : unsupported type

   sprintf('%f', e)
   # error in sprintf("%f", e) : (list) object cannot be coerced to type
'double'

   sprintf('%s', e)
   # segfault reported, with a choice of options for how to exit the session

it is possible not to leave the session, by simply typing ^c (ctrl-c).  (which
should probably be prohibited.)  if one stays in the session, then trying to
evaluate sprintf('%s', e) will cause a segfault with immediate crash (r is
silently closed), but not necessarily if some other code is executed first.  in
the latter case, there may be no segfault, but an error message might be printed
instead:

   e = tryCatch(stop(), error=identity)
   sprintf('%s', e)
   # segfault, choice of options
   # ^c, stay in the session
   e = tryCatch(stop(), error=identity)
   sprintf('%s', e)
   # segfault, immediate exit
 
   e = tryCatch(stop(), error=identity)
   sprintf('%s', e)
   # segfault, choice of options
   # ^c, stay in the session
   e = tryCatch(stop(), error=identity)
   x = 1 # possibly, whatever code would do
   sprintf('%s', e)
   # [1] "Error in doTryCatch(return(expr), name, parentenv, handler): \n"
   # [2] "Error in doTryCatch(return(expr), name, parentenv, handler): \n"
   sprintf('%s', e)
   # segfault, immediate exit

in the second code snippet above, on some executions the error message was
printed. on others a segfault caused immediate exit.  (the pattern seems to
differ between 2.8.0 and 2.10.0-devel.)


From macrakis at alum.mit.edu  Fri Mar 20 15:17:02 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 20 Mar 2009 10:17:02 -0400
Subject: [Rd] [R] which.na
In-Reply-To: <49C36FE2.7070407@stats.uwo.ca>
References: <816b5ce40903191837y58f6dc0bw98f5cdbd41f11484@mail.gmail.com>
	<46B8F50B47374D0FB12E205F51C291FA@DD4XFW31>
	<18883.26089.830116.969445@lynne.math.ethz.ch>
	<49C36FE2.7070407@stats.uwo.ca>
Message-ID: <8b356f880903200717t76075da2vd5fb0762031d49c9@mail.gmail.com>

There are many other useful extensions one might imagine along these lines.

For instance, we could have an argument for stopping the 'which'
calculation at the first result (or the first N results), which is
often useful (cf. any).

But I think it would be much cleaner for things like this to be done
in a compiler.  I suppose another possibility would be to have
low-level interfaces like which(a, test=xxx, count=nnn) which could be
used for optimization or for a source-to-source optimizer.

              -s

On Fri, Mar 20, 2009 at 6:28 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> Martin Maechler wrote:
>>>>>>>
>>>>>>> "CAPE" == Charles Annis, P E
>>>>>>> <Charles.Annis at statisticalengineering.com>
>>>>>>> ? ?on Thu, 19 Mar 2009 22:46:10 -0400 writes:
>>>>>>>
>>
>> ? ?>> ?is.na
>> ? ?>> x <- c(NA, 3, 4, 5, NA)
>> ? ?>> which(is.na(x))
>> ? ?CAPE> [1] 1 5
>>
>> well, of course.
>>
>> But note that ?which.na(.) could be implemented to be faster (because
>> needing much less memory) than the above,
>> notably when ?x ?is large and ?has only few NAs
>>
>> But this now has *REALLY* ?changed into a topic belonging to
>> R-devel, not R-help
>>
>> --> hence I've diverted the thread to there.
>>
>> I have recently entertained similar thoughts, i.e. wished for R
>> functions that compute ? ? ? ? ? ?which( function_returning_logical(..) )
>> and also
>> ? ? ? ? ? ?any( function_returning_logical(..) )
>>
>> directly {on .Internal i.e. C-level} instead of going to
>> construct the potentially huge logical vector.
>>
>> For what functions should this happen?
>> I agree that ?is.na() is one of them; but then, why not
>> ? ?is.nan() / ?is.finite() too?
>>
>> Instead of defining a slew of such functions ?which.foo(), which.bar(),
>> any.foo(), any.bar(), etc,
>> it would be nice to have a generic interface such as
>>
>> ? whichApply(x, is.na)
>> ? whichApply(x, is.nan)
>>
>> ? anyApply(x, is.na)
>> where internally, for some functions {in a given internal
>> table}, the fast shortcut would be used, and for others the
>> interface would be equivalent to ?which( thatFunction( x ) )
>>
>
> A couple of different interfaces to the same idea:
>
> ?- which() could recognize a few thatFunction(x) calls before evaluating
> them, and do the fast internal version. ?(This is hard because it needs to
> know
> that the user hasn't redefined is.na, etc. ?Probably not worth doing.)
>
> ?- which() could gain a new arg, so that
>
> ? ? ?which(x, test=is.na)
>
> ? would do as your whichApply() does.
>
> Duncan Murdoch
>>
>> Martin Maechler, ETH Zurich (and R Core team)
>>
>>
>> ? ?CAPE> Charles Annis, P.E.
>>
>> ? ?CAPE> Charles.Annis at StatisticalEngineering.com
>> ? ?CAPE> phone: 561-352-9699
>> ? ?CAPE> eFax: ?614-455-3265
>> ? ?CAPE> http://www.StatisticalEngineering.com
>>
>> ? ?CAPE> -----Original Message-----
>> ? ?CAPE> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On
>> ? ?CAPE> Behalf Of Santosh
>> ? ?CAPE> Sent: Thursday, March 19, 2009 9:37 PM
>> ? ?CAPE> To: r-help at r-project.org
>> ? ?CAPE> Subject: [R] which.na
>>
>> ? ?CAPE> Hi R- users
>>
>> ? ?CAPE> I was wondering if there is any function equivalent to which.na
>> used in S+?
>>
>> ? ?CAPE> Thanks much in advance!
>>
>> ? ?CAPE> Regards,
>> ? ?CAPE> Santosh
>>
>> ? ?CAPE> [[alternative HTML version deleted]]
>>
>> ? ?CAPE> ______________________________________________
>> ? ?CAPE> R-help at r-project.org mailing list
>> ? ?CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>> ? ?CAPE> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> ? ?CAPE> and provide commented, minimal, self-contained, reproducible
>> code.
>>
>> ? ?CAPE> ______________________________________________
>> ? ?CAPE> R-help at r-project.org mailing list
>> ? ?CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>> ? ?CAPE> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> ? ?CAPE> and provide commented, minimal, self-contained, reproducible
>> code.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Fri Mar 20 15:56:26 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 20 Mar 2009 15:56:26 +0100
Subject: [Rd] v2.8.1 crashes on quit(save="yes") or just won't
	save	(PR#13612)
In-Reply-To: <20090320051512.29F252832182@mail.pubhealth.ku.dk>
References: <20090320051512.29F252832182@mail.pubhealth.ku.dk>
Message-ID: <49C3AE9A.7010402@statistik.tu-dortmund.de>



anne.gilman at gmail.com wrote:
> Full_Name: Anne Gilman
> Version: 2.8.1
> OS: Mac OS X  10.4.11
> Submission from: (NULL) (132.177.75.245)
> 
> 
> Dear R Team,
> 
> Today I upgraded from R 2.2.2 to 2.8.1  ...then I restarted, did a bunch of
> work, and tried to quit.  (Note that I have oodles of stuff saved in the work
> environment; took almost a full minute to start up.)  After over 10 minutes, it
> was still trying to close up, and the problem (below) for DBfetch was mentioned,
> plus it said
> 
> *** caught segfault ***  
> address 0x7fffdeb1  
> cause 'memory not mapped'  
> 
> (retyped from my notes, no way to grab)
> 
> After about five more minutes, I did a Force Quit.  Then I reproduced the bug. 
> I opened R, loaded a CSV file from my previous day's work, then quit - here's
> what happened:
> 
>> quit(save="yes")
> Error in .Call("R_lazyLoadDBfetch", key, file, compressed, hook, PACKAGE =
> "base") : 
>   C symbol name "R_lazyLoadDBfetch" not in DLL for package "base"

The error message sounds like you mixed up an installation with new 
R-2.8.1 and some old packages (maybe including base itself?!) that are 
still in  some library you are loading packages from.

Please do a clean installation and update all you packages. If you have 
a separate library than the standard one, please remove all base 
packages from that library.

Uwe Ligges



>> quit(save="no")
 >>
> (that latter command worked, 2nd time, no need for Force Quit)
> 
> Yarg!  I know I can work around this using write.csv(), but I guess my lesson is
> never to change versions in the middle of one's dissertation analyses!
> 
> with thanks,
> 
> Anne G.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhurlin at gwdg.de  Fri Mar 20 17:39:52 2009
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Fri, 20 Mar 2009 17:39:52 +0100
Subject: [Rd] R does not compile any more on FreeBSD 8.0-CURRENT
In-Reply-To: <307b90470903190237p73869d19p742003c9a46f6188@mail.gmail.com>
References: <307b90470903190237p73869d19p742003c9a46f6188@mail.gmail.com>
Message-ID: <49C3C6D8.5050804@gwdg.de>

On 19.03.2009 10:37 (UTC+1), Hiroyuki Kawakatsu wrote:
> Rainer Hurling wrote:
>> On a recent FreeBSD 8.0-CURRENT (i386) building R (any version)
>> breaks with the following messages:
> [...]
> 
> I run 7.1-RELEASE (amd64) so I cannot comment on any potential issues
> with 8.0-CURRENT. On my machine the r-devel tarball (r48148) builds
> without any problems but I use
> 
> ./configure MAKE=gmake
> 
> Have you tried gmake?
> 
> h.

Yes, I tried gmake with same result. This behaviour is only with CURRENT 
from ~ 5th march 2009 on. Before that I have been able to compile with 
standard (bsd) make.

Thank you for this question,
Rainer


From wdunlap at tibco.com  Fri Mar 20 17:52:24 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Mar 2009 09:52:24 -0700
Subject: [Rd] [R] which.na
In-Reply-To: <18883.26089.830116.969445@lynne.math.ethz.ch>
References: <816b5ce40903191837y58f6dc0bw98f5cdbd41f11484@mail.gmail.com><46B8F50B47374D0FB12E205F51C291FA@DD4XFW31>
	<18883.26089.830116.969445@lynne.math.ethz.ch>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700E8EF9E@NA-PA-VBE03.na.tibco.com>

If you are considering emulating the S/S+ which.na, which.nan,
etc., family of functions to save space you might also consider
the related anyMissing function (I don't know why it
isn't any.is.na to match the pattern).  anyMissing(x) returns
the same result as any(is.na(x)) or length(which.na(x)) but
stops scanning the input when it sees the first NA, saving time
and space in the common idiom of stopifnot(!any(is.na(x))).
(BTW, Should R have a stopif() function to avoid that double negative?)

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Maechler
> Sent: Friday, March 20, 2009 2:46 AM
> To: Charles.Annis at statisticalengineering.com
> Cc: 'Santosh'; R-devel at stat.math.ethz.ch
> Subject: Re: [Rd] [R] which.na
> 
> >>>>> "CAPE" == Charles Annis, P E 
> <Charles.Annis at statisticalengineering.com>
> >>>>>     on Thu, 19 Mar 2009 22:46:10 -0400 writes:
> 
>     >> ?is.na
>     >> x <- c(NA, 3, 4, 5, NA)
>     >> which(is.na(x))
>     CAPE> [1] 1 5
> 
> well, of course.
> 
> But note that  which.na(.) could be implemented to be 
> faster (because needing much less memory) than the above,
> notably when  x  is large and  has only few NAs
> 
> But this now has *REALLY*  changed into a topic belonging to
> R-devel, not R-help
> 
> --> hence I've diverted the thread to there.
> 
> I have recently entertained similar thoughts, i.e. wished for R
> functions that compute  
> 	  which( function_returning_logical(..) )
> and also
> 	    any( function_returning_logical(..) )
> 
> directly {on .Internal i.e. C-level} instead of going to
> construct the potentially huge logical vector.
> 
> For what functions should this happen?
> I agree that  is.na() is one of them; but then, why not
>     is.nan() /  is.finite() 
> too?
> 
> Instead of defining a slew of such functions  
> which.foo(), which.bar(), any.foo(), any.bar(), etc,
> it would be nice to have a generic interface such as
> 
>    whichApply(x, is.na)
>    whichApply(x, is.nan)
> 
>    anyApply(x, is.na) 
> 
> where internally, for some functions {in a given internal
> table}, the fast shortcut would be used, and for others the
> interface would be equivalent to  which( thatFunction( x ) )
> 
> Martin Maechler, ETH Zurich (and R Core team)
> 
> 
>     CAPE> Charles Annis, P.E.
> 
>     CAPE> Charles.Annis at StatisticalEngineering.com
>     CAPE> phone: 561-352-9699
>     CAPE> eFax:  614-455-3265
>     CAPE> http://www.StatisticalEngineering.com
>  
> 
>     CAPE> -----Original Message-----
>     CAPE> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On
>     CAPE> Behalf Of Santosh
>     CAPE> Sent: Thursday, March 19, 2009 9:37 PM
>     CAPE> To: r-help at r-project.org
>     CAPE> Subject: [R] which.na
> 
>     CAPE> Hi R- users
> 
>     CAPE> I was wondering if there is any function equivalent 
> to which.na used in S+?
> 
>     CAPE> Thanks much in advance!
> 
>     CAPE> Regards,
>     CAPE> Santosh
> 
>     CAPE> [[alternative HTML version deleted]]
> 
>     CAPE> ______________________________________________
>     CAPE> R-help at r-project.org mailing list
>     CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>     CAPE> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
>     CAPE> and provide commented, minimal, self-contained, 
> reproducible code.
> 
>     CAPE> ______________________________________________
>     CAPE> R-help at r-project.org mailing list
>     CAPE> https://stat.ethz.ch/mailman/listinfo/r-help
>     CAPE> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
>     CAPE> and provide commented, minimal, self-contained, 
> reproducible code.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From romain.francois at dbmail.com  Fri Mar 20 19:56:07 2009
From: romain.francois at dbmail.com (romain.francois at dbmail.com)
Date: Fri, 20 Mar 2009 19:56:07 +0100 (CET)
Subject: [Rd] Why does the lexical analyzer drop comments ?
Message-ID: <8903928.174261237575367141.JavaMail.www@wwumf0207>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090320/b55d3cf7/attachment.pl>

From murdoch at stats.uwo.ca  Fri Mar 20 20:18:24 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 20 Mar 2009 15:18:24 -0400
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <8903928.174261237575367141.JavaMail.www@wwumf0207>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
Message-ID: <49C3EC00.5080302@stats.uwo.ca>

On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
> It happens in the token function in gram.c: 
> 
> ? ? ?  c = SkipSpace();
> ? ? ?  if (c == '#') c = SkipComment();
> 
> and then SkipComment goes like that: 
> 
> static int SkipComment(void)
> {
> ? ? ?  int c;
> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
> ? ? ?  if (c == R_EOF) EndOfFile = 2;
> ? ? ?  return c;
> }
> 
> which effectively drops comments.
> 
> Would it be possible to keep the information somewhere ? 
> 
> The source code says this: 
> 
> ? *?  The function yylex() scans the input, breaking it into
> ? *?  tokens which are then passed to the parser.?  The lexical
> ? *?  analyser maintains a symbol table (in a very messy fashion).
> 
> so my question is could we use this symbol table to keep track of, say, COMMENT tokens. 
> 
> Why would I even care about that ? I'm writing a package that will
> perform syntax highlighting of R source code based on the output of the
> parser, and it seems a waste to drop the comments. 
> 
> An also, when you print a function to the R console, you don't get the comments, and some of them might be useful to the user.
> 
> Am I mad if I contemplate looking into this ? 

Comments are syntactically the same as whitespace.  You don't want them 
to affect the parsing.

If you're doing syntax highlighting, you can determine the whitespace by
looking at the srcref records, and then parse that to determine what 
isn't being counted as tokens.  (I think you'll find a few things there 
besides whitespace, but it is a fairly limited set, so shouldn't be too 
hard to recognize.)

The Rd parser is different, because in an Rd file, whitespace is 
significant, so it gets kept.

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Fri Mar 20 21:47:04 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 20 Mar 2009 21:47:04 +0100
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C3EC00.5080302@stats.uwo.ca>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
	<49C3EC00.5080302@stats.uwo.ca>
Message-ID: <49C400C8.7040208@biostat.ku.dk>

Duncan Murdoch wrote:
> On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
>> It happens in the token function in gram.c:
>> ? ? ?  c = SkipSpace();
>> ? ? ?  if (c == '#') c = SkipComment();
>>
>> and then SkipComment goes like that:
>> static int SkipComment(void)
>> {
>> ? ? ?  int c;
>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>> ? ? ?  return c;
>> }
>>
>> which effectively drops comments.
>>
>> Would it be possible to keep the information somewhere ?
>> The source code says this:
>> ? *?  The function yylex() scans the input, breaking it into
>> ? *?  tokens which are then passed to the parser.?  The lexical
>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>
>> so my question is could we use this symbol table to keep track of, 
>> say, COMMENT tokens.
>> Why would I even care about that ? I'm writing a package that will
>> perform syntax highlighting of R source code based on the output of the
>> parser, and it seems a waste to drop the comments.
>> An also, when you print a function to the R console, you don't get the 
>> comments, and some of them might be useful to the user.
>>
>> Am I mad if I contemplate looking into this ? 
> 
> Comments are syntactically the same as whitespace.  You don't want them 
> to affect the parsing.

Well, you might, but there is quite some madness lying that way.

Back in the bronze age, we did actually try to keep comments attached to 
(AFAIR) the preceding token. One problem is that the elements of the 
parse tree typically involve multiple tokens, and if comments after 
different tokens get stored in the same place something is not going 
back where it came from when deparsing. So we had problems with comments 
moving from one end of a loop the other and the like.

You could try extending the scheme by encoding which part of a syntactic 
structure the comment belongs to, but consider for instance how many 
places in a function call you can stick in a comment.

f #here
( #here
a #here (possibly)
= #here
1 #this one belongs to the argument, though
) #but here as well

> 
> If you're doing syntax highlighting, you can determine the whitespace by
> looking at the srcref records, and then parse that to determine what 
> isn't being counted as tokens.  (I think you'll find a few things there 
> besides whitespace, but it is a fairly limited set, so shouldn't be too 
> hard to recognize.)
> 
> The Rd parser is different, because in an Rd file, whitespace is 
> significant, so it gets kept.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From romain.francois at dbmail.com  Fri Mar 20 21:57:38 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 20 Mar 2009 21:57:38 +0100
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C400C8.7040208@biostat.ku.dk>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
	<49C3EC00.5080302@stats.uwo.ca> <49C400C8.7040208@biostat.ku.dk>
Message-ID: <49C40342.60203@dbmail.com>

Peter Dalgaard wrote:
> Duncan Murdoch wrote:
>> On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
>>> It happens in the token function in gram.c:
>>> ? ? ?  c = SkipSpace();
>>> ? ? ?  if (c == '#') c = SkipComment();
>>>
>>> and then SkipComment goes like that:
>>> static int SkipComment(void)
>>> {
>>> ? ? ?  int c;
>>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>>> ? ? ?  return c;
>>> }
>>>
>>> which effectively drops comments.
>>>
>>> Would it be possible to keep the information somewhere ?
>>> The source code says this:
>>> ? *?  The function yylex() scans the input, breaking it into
>>> ? *?  tokens which are then passed to the parser.?  The lexical
>>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>>
>>> so my question is could we use this symbol table to keep track of, 
>>> say, COMMENT tokens.
>>> Why would I even care about that ? I'm writing a package that will
>>> perform syntax highlighting of R source code based on the output of the
>>> parser, and it seems a waste to drop the comments.
>>> An also, when you print a function to the R console, you don't get 
>>> the comments, and some of them might be useful to the user.
>>>
>>> Am I mad if I contemplate looking into this ? 
>>
>> Comments are syntactically the same as whitespace.  You don't want 
>> them to affect the parsing.
>
> Well, you might, but there is quite some madness lying that way.
>
> Back in the bronze age, we did actually try to keep comments attached 
> to (AFAIR) the preceding token. One problem is that the elements of 
> the parse tree typically involve multiple tokens, and if comments 
> after different tokens get stored in the same place something is not 
> going back where it came from when deparsing. So we had problems with 
> comments moving from one end of a loop the other and the like.
Ouch. That helps picturing the kind of madness ...

Another way could be to record comments separately (similarly to srcfile 
attribute for example) instead of dropping them entirely, but I guess 
this is the same as Duncan's idea, which is easier to set up.

> You could try extending the scheme by encoding which part of a 
> syntactic structure the comment belongs to, but consider for instance 
> how many places in a function call you can stick in a comment.
>
> f #here
> ( #here
> a #here (possibly)
> = #here
> 1 #this one belongs to the argument, though
> ) #but here as well
>
>>
>> If you're doing syntax highlighting, you can determine the whitespace by
>> looking at the srcref records, and then parse that to determine what 
>> isn't being counted as tokens.  (I think you'll find a few things 
>> there besides whitespace, but it is a fairly limited set, so 
>> shouldn't be too hard to recognize.)
>>
>> The Rd parser is different, because in an Rd file, whitespace is 
>> significant, so it gets kept.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From rhurlin at gwdg.de  Fri Mar 20 22:19:02 2009
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Fri, 20 Mar 2009 22:19:02 +0100
Subject: [Rd] [SOLVED] Re: R does not compile any more on FreeBSD 8.0-CURRENT
In-Reply-To: <49BFBDAF.304@gwdg.de>
References: <49BFBDAF.304@gwdg.de>
Message-ID: <49C40846.3090702@gwdg.de>

Todays (03/20/2009) update of FreeBSD 8.0-CURRENT solved the problem. 
The two pathes are resolving again. So building and installing R on 
CURRENT works again :-)

Thanks for your patience,
Rainer


On 17.03.2009 16:11 (UTC+1), Rainer Hurling wrote:
> On a recent FreeBSD 8.0-CURRENT (i386) building R (any version) breaks 
> with the following messages:
> 
> ----------------------------------------------------------------------
> [...snip...]
> gcc -std=gnu99 -I. -I../../src/include -I../../src/include 
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c wilcox.c -o wilcox.o
> gcc -std=gnu99 -I. -I../../src/include -I../../src/include 
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c signrank.c -o signrank.o
> rm -rf libnmath.a
> ar cr libnmath.a mlutils.o d1mach.o i1mach.o fmax2.o fmin2.o fprec.o 
> fround.o ftrunc.o sign.o fsign.o imax2.o imin2.o chebyshev.o log1p.o 
> expm1.o lgammacor.o gammalims.o stirlerr.o bd0.o gamma.o lgamma.o 
> gamma_cody.o beta.o lbeta.o polygamma.o bessel_i.o bessel_j.o bessel_k.o
> bessel_y.o choose.o snorm.o sexp.o dgamma.o pgamma.o qgamma.o rgamma.o
> dbeta.o pbeta.o qbeta.o rbeta.o dunif.o punif.o qunif.o runif.o dnorm.o 
> pnorm.o qnorm.o rnorm.o dlnorm.o plnorm.o qlnorm.o rlnorm.o df.o pf.o
> qf.o rf.o dnf.o dt.o pt.o qt.o rt.o dnt.o dchisq.o pchisq.o qchisq.o
> rchisq.o rnchisq.o dbinom.o pbinom.o qbinom.o rbinom.o rmultinom.o
> dcauchy.o pcauchy.o qcauchy.o rcauchy.o dexp.o pexp.o qexp.o rexp.o 
> dgeom.o pgeom.o qgeom.o rgeom.o dhyper.o phyper.o qhyper.o rhyper.o
> dnbinom.o pnbinom.o qnbinom.o rnbinom.o dpois.o ppois.o qpois.o rpois.o 
> dweibull.o pweibull.o qweibull.o rweibull.o dlogis.o plogis.o qlogis.o 
> rlogis.o dnchisq.o pnchisq.o qnchisq.o dnbeta.o pnbeta.o qnbeta.o pnf.o 
> pnt.o qnf.o qnt.o ptukey.o qtukey.o toms708.o wilcox.o signrank.o
> ranlib libnmath.a
> config.status: creating src/unix/Makefile
> make: /usr/local/R-devel/srcunix: No such file or directory
> *** Error code 2
> 
> Stop in /usr/local/R-devel/src/unix.
> *** Error code 1
> 
> Stop in /usr/local/R-devel/src.
> *** Error code 1
> 
> Stop in /usr/local/R-devel.
> ----------------------------------------------------------------------
> 
> The path /usr/local/R-devel/srcunix does not exist but .../src/unix/ 
> does. As a workaround I am able to do
> 
> cd src/unix
> make
> cd ../..
> make
> 
> A second break with the same error does occur at 
> /usr/local/R-devel/srcmain. Again this workaround works
> 
> cd src/main
> make
> cd ../..
> make
> 
> Now the compilation finished without another break. What could be the 
> reason for this 'path break'?  So long it seems that this error on 
> FreeBSD 8.0-CURRENT only appears with R and no other third party software.
> 
> Potentially this is an error within latest FreeBSD code (?) and I have 
> to ask on the FreeBSD mailing list. But before I wanted to ask on 
> r-devel at . Perhaps someone here has an idea? Any hints are very welcome.
> 
> Thanks in advance,
> Rainer Hurling


From romain.francois at dbmail.com  Fri Mar 20 23:05:08 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 20 Mar 2009 23:05:08 +0100
Subject: [Rd] throwing a "condition" when the current working directory
	changes
Message-ID: <49C41314.9010908@dbmail.com>

Hi,

Would it make sense to throw a condition when the working directory 
changes, so that interested parties (such as guis can act based on the 
change using an appropriate calling handler), and not interested parties 
can just ignore it.

For example, something like this:

setwd <- function (dir) {
       out <- .Internal(setwd(dir))
       setwdCondition <- simpleCondition( paste( "setwd: ", dir)  )
       class( setwdCondition ) <- c("setwd", "condition" )
       setwdCondition$dir <- dir
       signalCondition( setwdCondition )
       invisible( out )
}

which could handled like this to have your prompt responding to changes 
of current directory:

withCallingHandlers( f()  , setwd = function(e) options( prompt = 
sprintf( "[%s]> ", e$dir )  )   )

Beyond the simple example, would it make sense to define a set of 
condition or events, or is this abusing the concept of conditions and 
something else should be used ? hooks ?

Also, is there a way to "register" a calling handler so that it listens 
to every top-level command. Something like options( "error") but for 
handling other kinds of conditions ?

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 20 23:51:12 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 20 Mar 2009 23:51:12 +0100
Subject: [Rd] sprintf causes a segfault (PR#13613)
In-Reply-To: <20090320082009.68A86283219E@mail.pubhealth.ku.dk>
References: <20090320082009.68A86283219E@mail.pubhealth.ku.dk>
Message-ID: <49C41DE0.3070205@idi.ntnu.no>

strangely enough, the way r handles the same sequence of expressions on
different occasions varies:

    # fresh session 1
    e = simpleError('foo')
    sprintf('%s', e)
    # segfault: address 0x202, cause memory not mapped
    # ^c
    sprintf('%s', e)
    # error in sprintf("%s", e) : 'getEncChar' must be called on a CHARSXP
  
    # fresh session 2
    e = simpleError('foo')
    sprintf('%s', e)
    # segfault: address (nil), cause memory not mapped
    # ^c
    sprintf('%s', e)
    # segfault, exit

note the difference in the address and how this relates to the outcome
of the second execution of sprintf('%s', e)

vQ


Waclaw.Marcin.Kusnierczyk at idi.ntnu.no wrote:
> the following code illustrates a problem with sprintf which consistently causes
> a segfault when applied to certain type of arguments.  it also shows
> inconsistent consequences of the segfault:
>
>    (e = tryCatch(stop(), error=identity))
>    # e is an error object
>
>    sprintf('%d', e)
>    # error in sprintf("%d", e) : unsupported type
>
>    sprintf('%f', e)
>    # error in sprintf("%f", e) : (list) object cannot be coerced to type
> 'double'
>
>    sprintf('%s', e)
>    # segfault reported, with a choice of options for how to exit the session
>
> it is possible not to leave the session, by simply typing ^c (ctrl-c).  (which
> should probably be prohibited.)  if one stays in the session, then trying to
> evaluate sprintf('%s', e) will cause a segfault with immediate crash (r is
> silently closed), but not necessarily if some other code is executed first.  in
> the latter case, there may be no segfault, but an error message might be printed
> instead:
>
>    e = tryCatch(stop(), error=identity)
>    sprintf('%s', e)
>    # segfault, choice of options
>    # ^c, stay in the session
>    e = tryCatch(stop(), error=identity)
>    sprintf('%s', e)
>    # segfault, immediate exit
>  
>    e = tryCatch(stop(), error=identity)
>    sprintf('%s', e)
>    # segfault, choice of options
>    # ^c, stay in the session
>    e = tryCatch(stop(), error=identity)
>    x = 1 # possibly, whatever code would do
>    sprintf('%s', e)
>    # [1] "Error in doTryCatch(return(expr), name, parentenv, handler): \n"
>    # [2] "Error in doTryCatch(return(expr), name, parentenv, handler): \n"
>    sprintf('%s', e)
>    # segfault, immediate exit
>
> in the second code snippet above, on some executions the error message was
> printed. on others a segfault caused immediate exit.  (the pattern seems to
> differ between 2.8.0 and 2.10.0-devel.)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wiese at gfz-potsdam.de  Fri Mar 20 20:00:14 2009
From: wiese at gfz-potsdam.de (wiese at gfz-potsdam.de)
Date: Fri, 20 Mar 2009 20:00:14 +0100 (CET)
Subject: [Rd] minor tick marks for plots (PR#13616)
Message-ID: <20090320190014.D61922834316@mail.pubhealth.ku.dk>


Hello,

I think I found a bug:

 > windows(1,width = 10, height = 10, pointsize = 5,xpos = 0, ypos = 0 )
 > hdata[1:3,1] <- c(1,10,15)
 > hdata[1:3,2] <- c(2,1,4)
 > plot(hdata[,1],hdata[,2],xaxt="n")
 > axis(1,at=c(2,10,14))
 > minor.tick(nx=2, ny=1,tick.ratio=1)

the minor tick marks appear between the tick marks which would have been 
drawn without the option xaxt="n".

I use R.2.8.1.

Best Regards
Bernd Wiese




Dr. Bernd Wiese
Dipl.-Ing., MSc

Centre for CO2 Storage
Phone.: +49 (0)331/288-1823
FAX: +49 (0)331/288-1529
Email: wiese at gfz-potsdam.de
Building A34, room 204
___________________________________

Helmholtz Centre Potsdam
GFZ German Research Centre For Geosciences
Public Law Foundation State of Brandenburg
Telegrafenberg, 14473 Potsdam


From murdoch at stats.uwo.ca  Sat Mar 21 11:57:20 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 21 Mar 2009 06:57:20 -0400
Subject: [Rd] minor tick marks for plots (PR#13616)
In-Reply-To: <20090320190014.D61922834316@mail.pubhealth.ku.dk>
References: <20090320190014.D61922834316@mail.pubhealth.ku.dk>
Message-ID: <49C4C810.6030406@stats.uwo.ca>

On 20/03/2009 3:00 PM, wiese at gfz-potsdam.de wrote:
> Hello,
> 
> I think I found a bug:
> 
>  > windows(1,width = 10, height = 10, pointsize = 5,xpos = 0, ypos = 0 )
>  > hdata[1:3,1] <- c(1,10,15)
>  > hdata[1:3,2] <- c(2,1,4)
>  > plot(hdata[,1],hdata[,2],xaxt="n")
>  > axis(1,at=c(2,10,14))
>  > minor.tick(nx=2, ny=1,tick.ratio=1)
> 
> the minor tick marks appear between the tick marks which would have been 
> drawn without the option xaxt="n".
> 

minor.tick is not a base R function, so this is not an R bug, if it's a 
bug at all.  There's a function by that name in the Hmisc package, but 
you don't give enough information (e.g. printing sessionInfo()) so I 
can't tell if that's the one you used.

Duncan Murdoch


From mtmorgan at fhcrc.org  Sat Mar 21 16:14:13 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 21 Mar 2009 08:14:13 -0700
Subject: [Rd] unlink fails to remove symbolic links
Message-ID: <6phocvuhpru.fsf@gopher4.fhcrc.org>

unlink fails to remove symbolic links. This is more prominent now --
when a package creates symbolic links during installation, 00LOCK is
not removed.

Martin

> setwd(tempdir())
> fl <- tempfile(); file.create(fl)
[1] TRUE
> lnFile <- tempfile(); system(paste("ln -s", fl, lnFile))
> list.files()
[1] "file19495cff" "file74b0dc51"
> unlink(fl); unlink(lnFile)
> list.files()
[1] "file19495cff"
> lnFile
[1] "/tmp/Rtmpb0kd7B/file19495cff"

> sessionInfo()
R version 2.10.0 Under development (unstable) (2009-03-21 r48173)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-\
8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.10.0

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From mtmorgan at fhcrc.org  Sat Mar 21 17:22:31 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 21 Mar 2009 09:22:31 -0700
Subject: [Rd] unlink fails to remove symbolic links
In-Reply-To: <6phocvuhpru.fsf@gopher4.fhcrc.org> (Martin Morgan's message of
	"Sat, 21 Mar 2009 08:14:13 -0700")
References: <6phocvuhpru.fsf@gopher4.fhcrc.org>
Message-ID: <6phfxh6hmm0.fsf@gopher4.fhcrc.org>

A little more precisely, unlink fails when the file being unlinked is
a broken symbolic link (as in the example below). This is because
R_FileExists checks stat() == 0, and stat fails (returns -1) when
trying to resolve the broken link. Perhaps lstat() is more
appropriate?

Martin

Martin Morgan <mtmorgan at fhcrc.org> writes:

> unlink fails to remove symbolic links. This is more prominent now --
> when a package creates symbolic links during installation, 00LOCK is
> not removed.
>
> Martin
>
>> setwd(tempdir())
>> fl <- tempfile(); file.create(fl)
> [1] TRUE
>> lnFile <- tempfile(); system(paste("ln -s", fl, lnFile))
>> list.files()
> [1] "file19495cff" "file74b0dc51"
>> unlink(fl); unlink(lnFile)
>> list.files()
> [1] "file19495cff"
>> lnFile
> [1] "/tmp/Rtmpb0kd7B/file19495cff"
>
>> sessionInfo()
> R version 2.10.0 Under development (unstable) (2009-03-21 r48173)
> x86_64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-\
> 8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.10.0

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From murdoch at stats.uwo.ca  Sat Mar 21 17:50:15 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 21 Mar 2009 12:50:15 -0400
Subject: [Rd] vignette index not linked into HTML help system for package
In-Reply-To: <49BE34F1.5040908@tu-dresden.de>
References: <49BE34F1.5040908@tu-dresden.de>
Message-ID: <49C51AC7.4090204@stats.uwo.ca>

On 16/03/2009 7:16 AM, Thomas Petzoldt wrote:
> Dear R developers,
> 
> I observed that the html help page index entry "Read overview or browse 
> directory" for package vignettes is missing in recent R-devel.

Thanks for the report.  This is fixed now and will make it into the next 
release.  The code to build the HTML page was translated from Perl to R, 
and the lines to do this part were accidentally omitted.

Duncan Murdoch

> This happened on two independent computers (WinXP Prof. SP3, German) 
> with R-devel compiled from sources svn rev. 48125 resp. 48128
> It's the same for my own and also for more prominent packages as well 
> (e.g. grid).
> 
> The vignettes and the index.html files exist and vignette() as well as 
> browseVignettes() work as expected.
> 
> I have not found anything about this in NEWS or "Writing R extensions", 
> which says:
> 
> "At install time an HTML index for all vignettes is automatically 
> created from the \VignetteIndexEntry statements unless a file index.html 
> exists in directory inst/doc. This index is linked into the HTML help 
> system for each package."
> 
> 
> Have I missed something?
> 
> Thanks a lot
> 
> Thomas Petzoldt
> 
> 
>


From ripley at stats.ox.ac.uk  Sat Mar 21 18:03:12 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Mar 2009 17:03:12 +0000 (GMT)
Subject: [Rd] unlink fails to remove symbolic links
In-Reply-To: <6phfxh6hmm0.fsf@gopher4.fhcrc.org>
References: <6phocvuhpru.fsf@gopher4.fhcrc.org>
	<6phfxh6hmm0.fsf@gopher4.fhcrc.org>
Message-ID: <alpine.LFD.2.00.0903211650550.1830@gannet.stats.ox.ac.uk>

On Sat, 21 Mar 2009, Martin Morgan wrote:

> A little more precisely, unlink fails when the file being unlinked is
> a broken symbolic link (as in the example below). This is because
> R_FileExists checks stat() == 0, and stat fails (returns -1) when
> trying to resolve the broken link. Perhaps lstat() is more
> appropriate?

lstat is not portable, and I don't think it is appropriate for most
uses of R_FileExists.

I don't think there is anything new about this, and it does seem only 
to apply to broken links.  At a quick look the best solution looks to 
be to remove the pretest, but I need to check in more detail.


>
> Martin
>
> Martin Morgan <mtmorgan at fhcrc.org> writes:
>
>> unlink fails to remove symbolic links. This is more prominent now --
>> when a package creates symbolic links during installation, 00LOCK is
>> not removed.
>>
>> Martin
>>
>>> setwd(tempdir())
>>> fl <- tempfile(); file.create(fl)
>> [1] TRUE
>>> lnFile <- tempfile(); system(paste("ln -s", fl, lnFile))
>>> list.files()
>> [1] "file19495cff" "file74b0dc51"
>>> unlink(fl); unlink(lnFile)
>>> list.files()
>> [1] "file19495cff"
>>> lnFile
>> [1] "/tmp/Rtmpb0kd7B/file19495cff"
>>
>>> sessionInfo()
>> R version 2.10.0 Under development (unstable) (2009-03-21 r48173)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-\
>> 8;LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.10.0
>
> -- 
> Martin Morgan
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M2 B169
> Phone: (206) 667-2793
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From charlie at stat.umn.edu  Sat Mar 21 22:21:00 2009
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sat, 21 Mar 2009 16:21:00 -0500
Subject: [Rd] documenting datasets with more than one object
In-Reply-To: <mailman.19.1237633205.16201.r-devel@r-project.org>
References: <mailman.19.1237633205.16201.r-devel@r-project.org>
Message-ID: <20090321212100.GA16232@stat.umn.edu>

I am trying to put an rda (R save image) file that contains multiple R
objects in a contributed package.  From the example of the BJsales data
in package "datasets" it seems this is o. k.  But I am puzzled by some
of what "Writing R Extensions" says.

Section 1.1.3 mentions datalist files.  Do I have to have one in this case?

Section 2.1.2 says

    The \usage entry is always bar or (for packages which do not use
    lazy-loading of data) data(bar). (In particular, only document a
    single data object per Rd file.) 

What does that mean?  I have to describe all of the objects in the file,
but I only "document" one of them?  Is the Rd file for BJsales just wrong?

What if the rda file is sim.rda and so data(sim) is used to load it, but
"sim" is not the name of one of the R objects in rda file?

Is there a better example for how to do this?

My package passes R CMD check but I don't want to ship it to CRAN if it
is doing something considered harmful.
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Mar 22 01:36:02 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 22 Mar 2009 01:36:02 +0100
Subject: [Rd] gsub('(.).(.)(.)', '\\3\\2\\1', 'gsub')
Message-ID: <49C587F2.7010204@idi.ntnu.no>

there seems to be something wrong with r's regexing.  consider the
following example:

    gregexpr('a*|b', 'ab')
    # positions: 1 2
    # lengths: 1 1

    gsub('a*|b', '.', 'ab')
    # ..

where the pattern matches any number of 'a's or one b, and replaces the
match with a dot, globally.  the answer is correct (assuming a dfa
engine).  however,

    gregexpr('a*|b', 'ab', perl=TRUE)
    # positions: 1 2
    # lengths: 1 0

    gsub('a*|b', '.', 'ab', perl=TRUE)
    # .b.

where the pattern is identical, but the result is wrong.  perl uses an
nfa (if it used a dfa, the result would still be wrong), and in the
above example it should find *four* matches, collectively including
*all* letters in the input, thus producing *four* dots (and *only* dots)
in the output:

    perl -le '
       $input = qq|ab|;
       print qq|match: "$_"| foreach $input =~ /a*|b/g;
       $input =~ s/a*|b/./g;
       print qq|output: "$input"|;'
    # match: "a"
    # match: ""
    # match: "b"
    # match: ""
    # output: "...."

since with perl=TRUE both gregexpr and gsub seem to use pcre, i've
checked the example with pcretest, and also with a trivial c program
(available on demand) using the pcre api;  there were four matches,
exactly as in the perl bit above.

the results above are surprising, and suggest a bug in r's use of pcre
rather than in pcre itself.  possibly, the issue is that when an empty
sting is matched (with a*, for example), the next attempt is not trying
to match a non-empty string at the same position, but rather an empty
string again at the next position.  for example,

    gsub('a|b|c', '.', 'abc', perl=TRUE)
    # "...", correct

    gsub('a*|b|c', '.', 'abc', perl=TRUE)
    # ".b.c.", wrong

    gsub('a|b*|c', '.', 'abc', perl=TRUE)
    # "..c.", wrong (but now only 'c' remains)

    gsub('a|b*|c', '.', 'aba', perl=TRUE)
    # "...", incidentally correct


without detailed analysis of the code, i guess the bug is located
somewhere in src/main/pcre.c, and is distributed among the do_p*
functions, so that multiple fixes may be needed.

vQ


From orsolyaaa at freemail.hu  Sun Mar 22 13:02:05 2009
From: orsolyaaa at freemail.hu (vincze orsolya)
Date: Sun, 22 Mar 2009 13:02:05 +0100 (CET)
Subject: [Rd] multicollinearity
Message-ID: <freemail.20090222130205.14908@fm23.freemail.hu>

Dear R users,

I'm analysing some data, and I'm using an lme function.
 I have a problem with choosing the  right order for three of my explanatory variables, which shows collinearity. Is there any rules to make the decision?(r.squared?) Or it's better if I choose the order,  that I think gives me more information about the data?
 
Say x1 is the variable with the highest r.squared, x3 is with the lowest.
If i use
      m1=lme(y~x1+x2+x3,...)
 x2, and x3 is not significant,

 but if i use 
       m2=lme(y~x2+x3+x1, ...) 
all of the 3 variable is significant.

 I would prefer the the m2, because it gives me more ionformation about the dat, but in this case I have to leave in the model x2 and x3, which causes the increase in AIC.

What's the solution?
Can anybody help me?

Cheers




________________________________________________________
&#8222;Olyan cikkeket akarunk, amelyek k?zelebb viszik az orsz?got ahhoz, hogy n?pbut?t?s ?s alantas ?szt?n?k helyett v?giggondolt gondolatok ir?ny?ts?k.&#8221; &#8211; komment.hu
http://ad.adverticum.net/b/cl,1,6022,318025,391319/click.prm


From romain.francois at dbmail.com  Sun Mar 22 21:50:51 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sun, 22 Mar 2009 21:50:51 +0100
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C40342.60203@dbmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>	<49C3EC00.5080302@stats.uwo.ca>
	<49C400C8.7040208@biostat.ku.dk> <49C40342.60203@dbmail.com>
Message-ID: <49C6A4AB.2020300@dbmail.com>

Romain Francois wrote:
> Peter Dalgaard wrote:
>> Duncan Murdoch wrote:
>>> On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
>>>> It happens in the token function in gram.c:
>>>> ? ? ?  c = SkipSpace();
>>>> ? ? ?  if (c == '#') c = SkipComment();
>>>>
>>>> and then SkipComment goes like that:
>>>> static int SkipComment(void)
>>>> {
>>>> ? ? ?  int c;
>>>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>>>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>>>> ? ? ?  return c;
>>>> }
>>>>
>>>> which effectively drops comments.
>>>>
>>>> Would it be possible to keep the information somewhere ?
>>>> The source code says this:
>>>> ? *?  The function yylex() scans the input, breaking it into
>>>> ? *?  tokens which are then passed to the parser.?  The lexical
>>>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>>>
>>>> so my question is could we use this symbol table to keep track of, 
>>>> say, COMMENT tokens.
>>>> Why would I even care about that ? I'm writing a package that will
>>>> perform syntax highlighting of R source code based on the output of 
>>>> the
>>>> parser, and it seems a waste to drop the comments.
>>>> An also, when you print a function to the R console, you don't get 
>>>> the comments, and some of them might be useful to the user.
>>>>
>>>> Am I mad if I contemplate looking into this ? 
>>>
>>> Comments are syntactically the same as whitespace.  You don't want 
>>> them to affect the parsing.
>>
>> Well, you might, but there is quite some madness lying that way.
>>
>> Back in the bronze age, we did actually try to keep comments attached 
>> to (AFAIR) the preceding token. One problem is that the elements of 
>> the parse tree typically involve multiple tokens, and if comments 
>> after different tokens get stored in the same place something is not 
>> going back where it came from when deparsing. So we had problems with 
>> comments moving from one end of a loop the other and the like.
> Ouch. That helps picturing the kind of madness ...
>
> Another way could be to record comments separately (similarly to 
> srcfile attribute for example) instead of dropping them entirely, but 
> I guess this is the same as Duncan's idea, which is easier to set up.
>
>> You could try extending the scheme by encoding which part of a 
>> syntactic structure the comment belongs to, but consider for instance 
>> how many places in a function call you can stick in a comment.
>>
>> f #here
>> ( #here
>> a #here (possibly)
>> = #here
>> 1 #this one belongs to the argument, though
>> ) #but here as well
Coming back on this. I actually get two expressions:

 > p <- parse( "/tmp/parsing.R")
 > str( p )
length 2 expression(f, (a = 1))
 - attr(*, "srcref")=List of 2
  ..$ :Class 'srcref'  atomic [1:6] 1 1 1 1 1 1
  .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
  ..$ :Class 'srcref'  atomic [1:6] 2 1 6 1 1 1
  .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
 - attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>

But anyway, if I drop the first comment, then I get one expression with 
some srcref information:

 > p <- parse( "/tmp/parsing.R")
 > str( p )
length 1 expression(f(a = 1))
 - attr(*, "srcref")=List of 1
  ..$ :Class 'srcref'  atomic [1:6] 1 1 5 1 1 1
  .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>
 - attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>

but as far as i can see, there is only srcref information for that 
expression as a whole, it does not go beyond, so I am not sure I can 
implement Duncan's proposal without more detailed information from the 
parser, since I will only have the chance to check if a whitespace is 
actually a comment if it is between two expressions with a srcref.

Would it be sensible then to retain the comments and their srcref 
information, but separate from the tokens used for the actual parsing, 
in some other attribute of the output of parse ?

Romain

>>>
>>> If you're doing syntax highlighting, you can determine the 
>>> whitespace by
>>> looking at the srcref records, and then parse that to determine what 
>>> isn't being counted as tokens.  (I think you'll find a few things 
>>> there besides whitespace, but it is a fairly limited set, so 
>>> shouldn't be too hard to recognize.)
>>>
>>> The Rd parser is different, because in an Rd file, whitespace is 
>>> significant, so it gets kept.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From murdoch at stats.uwo.ca  Mon Mar 23 01:04:24 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Mar 2009 20:04:24 -0400
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C6A4AB.2020300@dbmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>	<49C3EC00.5080302@stats.uwo.ca>	<49C400C8.7040208@biostat.ku.dk>
	<49C40342.60203@dbmail.com> <49C6A4AB.2020300@dbmail.com>
Message-ID: <49C6D208.4060009@stats.uwo.ca>

On 22/03/2009 4:50 PM, Romain Francois wrote:
> Romain Francois wrote:
>> Peter Dalgaard wrote:
>>> Duncan Murdoch wrote:
>>>> On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
>>>>> It happens in the token function in gram.c:
>>>>> ? ? ?  c = SkipSpace();
>>>>> ? ? ?  if (c == '#') c = SkipComment();
>>>>>
>>>>> and then SkipComment goes like that:
>>>>> static int SkipComment(void)
>>>>> {
>>>>> ? ? ?  int c;
>>>>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>>>>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>>>>> ? ? ?  return c;
>>>>> }
>>>>>
>>>>> which effectively drops comments.
>>>>>
>>>>> Would it be possible to keep the information somewhere ?
>>>>> The source code says this:
>>>>> ? *?  The function yylex() scans the input, breaking it into
>>>>> ? *?  tokens which are then passed to the parser.?  The lexical
>>>>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>>>>
>>>>> so my question is could we use this symbol table to keep track of, 
>>>>> say, COMMENT tokens.
>>>>> Why would I even care about that ? I'm writing a package that will
>>>>> perform syntax highlighting of R source code based on the output of 
>>>>> the
>>>>> parser, and it seems a waste to drop the comments.
>>>>> An also, when you print a function to the R console, you don't get 
>>>>> the comments, and some of them might be useful to the user.
>>>>>
>>>>> Am I mad if I contemplate looking into this ? 
>>>> Comments are syntactically the same as whitespace.  You don't want 
>>>> them to affect the parsing.
>>> Well, you might, but there is quite some madness lying that way.
>>>
>>> Back in the bronze age, we did actually try to keep comments attached 
>>> to (AFAIR) the preceding token. One problem is that the elements of 
>>> the parse tree typically involve multiple tokens, and if comments 
>>> after different tokens get stored in the same place something is not 
>>> going back where it came from when deparsing. So we had problems with 
>>> comments moving from one end of a loop the other and the like.
>> Ouch. That helps picturing the kind of madness ...
>>
>> Another way could be to record comments separately (similarly to 
>> srcfile attribute for example) instead of dropping them entirely, but 
>> I guess this is the same as Duncan's idea, which is easier to set up.
>>
>>> You could try extending the scheme by encoding which part of a 
>>> syntactic structure the comment belongs to, but consider for instance 
>>> how many places in a function call you can stick in a comment.
>>>
>>> f #here
>>> ( #here
>>> a #here (possibly)
>>> = #here
>>> 1 #this one belongs to the argument, though
>>> ) #but here as well
> Coming back on this. I actually get two expressions:
> 
>  > p <- parse( "/tmp/parsing.R")
>  > str( p )
> length 2 expression(f, (a = 1))
>  - attr(*, "srcref")=List of 2
>   ..$ :Class 'srcref'  atomic [1:6] 1 1 1 1 1 1
>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
>   ..$ :Class 'srcref'  atomic [1:6] 2 1 6 1 1 1
>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
>  - attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
> 
> But anyway, if I drop the first comment, then I get one expression with 
> some srcref information:
> 
>  > p <- parse( "/tmp/parsing.R")
>  > str( p )
> length 1 expression(f(a = 1))
>  - attr(*, "srcref")=List of 1
>   ..$ :Class 'srcref'  atomic [1:6] 1 1 5 1 1 1
>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>
>  - attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>
> 
> but as far as i can see, there is only srcref information for that 
> expression as a whole, it does not go beyond, so I am not sure I can 
> implement Duncan's proposal without more detailed information from the 
> parser, since I will only have the chance to check if a whitespace is 
> actually a comment if it is between two expressions with a srcref.


Currently srcrefs are only attached to whole statements.  Since your 
source only included one or two statements, you only get one or two 
srcrefs.  It would not be hard to attach a srcref to every 
subexpression; there hasn't been a need for that before, so I didn't do 
it just for the sake of efficiency.

However, it might make sense for you to have your own parser, based on 
the grammar in R's parser, but handling white space differently. 
Certainly it would make sense to do that before making changes to the 
base R one.  The whole source is in src/main/gram.y; if you're not 
familiar with Bison, I can give you a hand.

Duncan Murdoch

> 
> Would it be sensible then to retain the comments and their srcref 
> information, but separate from the tokens used for the actual parsing, 
> in some other attribute of the output of parse ?
> 
> Romain
> 
>>>> If you're doing syntax highlighting, you can determine the 
>>>> whitespace by
>>>> looking at the srcref records, and then parse that to determine what 
>>>> isn't being counted as tokens.  (I think you'll find a few things 
>>>> there besides whitespace, but it is a fairly limited set, so 
>>>> shouldn't be too hard to recognize.)
>>>>
>>>> The Rd parser is different, because in an Rd file, whitespace is 
>>>> significant, so it gets kept.
>>>>
>>>> Duncan Murdoch
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From romain.francois at dbmail.com  Mon Mar 23 08:10:52 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Mon, 23 Mar 2009 08:10:52 +0100
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C6D208.4060009@stats.uwo.ca>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>	<49C3EC00.5080302@stats.uwo.ca>	<49C400C8.7040208@biostat.ku.dk>
	<49C40342.60203@dbmail.com> <49C6A4AB.2020300@dbmail.com>
	<49C6D208.4060009@stats.uwo.ca>
Message-ID: <49C735FC.10408@dbmail.com>

Duncan Murdoch wrote:
> On 22/03/2009 4:50 PM, Romain Francois wrote:
>> Romain Francois wrote:
>>> Peter Dalgaard wrote:
>>>> Duncan Murdoch wrote:
>>>>> On 3/20/2009 2:56 PM, romain.francois at dbmail.com wrote:
>>>>>> It happens in the token function in gram.c:
>>>>>> ? ? ?  c = SkipSpace();
>>>>>> ? ? ?  if (c == '#') c = SkipComment();
>>>>>>
>>>>>> and then SkipComment goes like that:
>>>>>> static int SkipComment(void)
>>>>>> {
>>>>>> ? ? ?  int c;
>>>>>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>>>>>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>>>>>> ? ? ?  return c;
>>>>>> }
>>>>>>
>>>>>> which effectively drops comments.
>>>>>>
>>>>>> Would it be possible to keep the information somewhere ?
>>>>>> The source code says this:
>>>>>> ? *?  The function yylex() scans the input, breaking it into
>>>>>> ? *?  tokens which are then passed to the parser.?  The lexical
>>>>>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>>>>>
>>>>>> so my question is could we use this symbol table to keep track 
>>>>>> of, say, COMMENT tokens.
>>>>>> Why would I even care about that ? I'm writing a package that will
>>>>>> perform syntax highlighting of R source code based on the output 
>>>>>> of the
>>>>>> parser, and it seems a waste to drop the comments.
>>>>>> An also, when you print a function to the R console, you don't 
>>>>>> get the comments, and some of them might be useful to the user.
>>>>>>
>>>>>> Am I mad if I contemplate looking into this ? 
>>>>> Comments are syntactically the same as whitespace.  You don't want 
>>>>> them to affect the parsing.
>>>> Well, you might, but there is quite some madness lying that way.
>>>>
>>>> Back in the bronze age, we did actually try to keep comments 
>>>> attached to (AFAIR) the preceding token. One problem is that the 
>>>> elements of the parse tree typically involve multiple tokens, and 
>>>> if comments after different tokens get stored in the same place 
>>>> something is not going back where it came from when deparsing. So 
>>>> we had problems with comments moving from one end of a loop the 
>>>> other and the like.
>>> Ouch. That helps picturing the kind of madness ...
>>>
>>> Another way could be to record comments separately (similarly to 
>>> srcfile attribute for example) instead of dropping them entirely, 
>>> but I guess this is the same as Duncan's idea, which is easier to 
>>> set up.
>>>
>>>> You could try extending the scheme by encoding which part of a 
>>>> syntactic structure the comment belongs to, but consider for 
>>>> instance how many places in a function call you can stick in a 
>>>> comment.
>>>>
>>>> f #here
>>>> ( #here
>>>> a #here (possibly)
>>>> = #here
>>>> 1 #this one belongs to the argument, though
>>>> ) #but here as well
>> Coming back on this. I actually get two expressions:
>>
>>  > p <- parse( "/tmp/parsing.R")
>>  > str( p )
>> length 2 expression(f, (a = 1))
>>  - attr(*, "srcref")=List of 2
>>   ..$ :Class 'srcref'  atomic [1:6] 1 1 1 1 1 1
>>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
>>   ..$ :Class 'srcref'  atomic [1:6] 2 1 6 1 1 1
>>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
>>  - attr(*, "srcfile")=Class 'srcfile' <environment: 0x95c3c00>
>>
>> But anyway, if I drop the first comment, then I get one expression 
>> with some srcref information:
>>
>>  > p <- parse( "/tmp/parsing.R")
>>  > str( p )
>> length 1 expression(f(a = 1))
>>  - attr(*, "srcref")=List of 1
>>   ..$ :Class 'srcref'  atomic [1:6] 1 1 5 1 1 1
>>   .. .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>
>>  - attr(*, "srcfile")=Class 'srcfile' <environment: 0x9bca314>
>>
>> but as far as i can see, there is only srcref information for that 
>> expression as a whole, it does not go beyond, so I am not sure I can 
>> implement Duncan's proposal without more detailed information from 
>> the parser, since I will only have the chance to check if a 
>> whitespace is actually a comment if it is between two expressions 
>> with a srcref.
>
> Currently srcrefs are only attached to whole statements.  Since your 
> source only included one or two statements, you only get one or two 
> srcrefs.  It would not be hard to attach a srcref to every 
> subexpression; there hasn't been a need for that before, so I didn't 
> do it just for the sake of efficiency.

I understand that. I wanted to make sure I did not miss something.

> However, it might make sense for you to have your own parser, based on 
> the grammar in R's parser, but handling white space differently. 
> Certainly it would make sense to do that before making changes to the 
> base R one.  The whole source is in src/main/gram.y; if you're not 
> familiar with Bison, I can give you a hand.

Thank you, I appreciate your help. Having my own parser is the option I 
am slowly converging to.
I'll start with reading bison documentation. Besides bison documents, is 
there R specific documentation on how the R parser was written ?

>
> Duncan Murdoch
>
>>
>> Would it be sensible then to retain the comments and their srcref 
>> information, but separate from the tokens used for the actual 
>> parsing, in some other attribute of the output of parse ?
>>
>> Romain
>>
>>>>> If you're doing syntax highlighting, you can determine the 
>>>>> whitespace by
>>>>> looking at the srcref records, and then parse that to determine 
>>>>> what isn't being counted as tokens.  (I think you'll find a few 
>>>>> things there besides whitespace, but it is a fairly limited set, 
>>>>> so shouldn't be too hard to recognize.)
>>>>>
>>>>> The Rd parser is different, because in an Rd file, whitespace is 
>>>>> significant, so it gets kept.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From hshen_1998 at yahoo.com  Sun Mar 22 16:24:34 2009
From: hshen_1998 at yahoo.com (hong shen)
Date: Sun, 22 Mar 2009 08:24:34 -0700 (PDT)
Subject: [Rd] all.equal is hard to use
Message-ID: <733596.697.qm@web36802.mail.mud.yahoo.com>


Hi,

I have extensive programming experience (Winodws, Unix, scripting, compiled languages, you name it) but new to R.

I found that it is quite hard to interpret the results returned by all.equal (base). The main problem is that when attributes are compared, they are sorted in attr.all.equal but in the result, the index of diff component is from the sorted list not the original list. I think that adding the component name to the printout may make users' life a little bit easier like

function (target, current, check.attributes = TRUE, ...) 
{
    msg <- if (check.attributes) 
        # if it is called by attr.all.equal(), target and current
        # are lists returned from attributes(original target | current). 
        # So attributes of target and current are the attributes of attributes,
        # which contains only "names". 
        attr.all.equal(target, current, ...)
    iseq <- if (length(target) == length(current)) {
        # if the length is equal, iseq will be a (1, 2, ... length)
        seq_along(target)
    }
    else {
        if (!is.null(msg)) 
            # remove old msg about "Lengths"
            msg <- msg[-grep("\\bLengths\\b", msg)]
        nc <- min(length(target), length(current))
        msg <- c(msg, paste("Length mismatch: comparison on first", 
            nc, "components"))
        # iseq is (1,2, ..., shorter of two lengthes)
        seq_len(nc)
    }
    for (i in iseq) {
        # compare each element in the list with all.equal.
        mi <- all.equal(target[[i]], current[[i]], check.attributes = check.attributes, 
            ...)
        if (is.character(mi)) {
           ############################################################
           #### print out name if possible ############################
           if (!is.null(names(target)[i]) && !is.null(names(current)[i]))
             msg <- c(msg, paste("Component ", i, ": ", mi, "with target name: ", names(target)[i], ", current name: ", 

names(current)[i], sep = ""))
           else if (!is.null(names(target)[i]))
             msg <- c(msg, paste("Component ", i, ": ", mi, "with target name: ", names(target)[i], sep = ""))
           else if (!is.null(names(current)[i]))
             msg <- c(msg, paste("Component ", i, ": ", mi, "with current name: ", names(current)[i], sep = ""))
           else
	     msg <- c(msg, paste("Component ", i, ": ", mi, sep = ""))
           ############################################################
        }
    }
    if (is.null(msg)) 
        TRUE
    else msg
}

Hong Shen


From waku at idi.ntnu.no  Sun Mar 22 01:40:08 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Sun, 22 Mar 2009 01:40:08 +0100 (CET)
Subject: [Rd] gsub('(.).(.)(.)', '\\3\\2\\1', 'gsub') (PR#13617)
Message-ID: <20090322004008.994C02832189@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.10.0 r48181
OS: Ubuntu 8.04 Linux 32bit
Submission from: (NULL) (129.241.199.135)


there seems to be something wrong with r's regexing.  consider the following
example:

    gregexpr('a*|b', 'ab')
    # positions: 1 2
    # lengths: 1 1

    gsub('a*|b', '.', 'ab')
    # ..

where the pattern matches any number of 'a's or one b, and replaces the match
with a dot, globally.  the answer is correct (assuming a dfa engine).  however,

    gregexpr('a*|b', 'ab', perl=TRUE)
    # positions: 1 2
    # lengths: 1 0

    gsub('a*|b', '.', 'ab', perl=TRUE)
    # .b.

where the pattern is identical, but the result is wrong.  perl uses an nfa (if
it used a dfa, the result would still be wrong), and in the above example it
should find *four* matches, collectively including *all* letters in the input,
thus producing *four* dots (and *only* dots) in the output:

    perl -le '
       $input = qq|ab|;
       print qq|match: "$_"| foreach $input =~ /a*|b/g;
       $input =~ s/a*|b/./g;
       print qq|output: "$input"|;'
    # match: "a"
    # match: ""
    # match: "b"
    # match: ""
    # output: "...."

since with perl=TRUE both gregexpr and gsub seem to use pcre, i've checked the
example with pcretest, and also with a trivial c program (available on demand)
using the pcre api;  there were four matches, exactly as in the perl bit above.

the results above are surprising, and suggest a bug in r's use of pcre rather
than in pcre itself.  possibly, the issue is that when an empty sting is matched
(with a*, for example), the next attempt is not trying to match a non-empty
string at the same position, but rather an empty string again at the next
position.  for example,

    gsub('a|b|c', '.', 'abc', perl=TRUE)
    # "...", correct

    gsub('a*|b|c', '.', 'abc', perl=TRUE)
    # ".b.c.", wrong

    gsub('a|b*|c', '.', 'abc', perl=TRUE)
    # "..c.", wrong (but now only 'c' remains)

    gsub('a|b*|c', '.', 'aba', perl=TRUE)
    # "...", incidentally correct


without detailed analysis of the code, i guess the bug is located somewhere in
src/main/pcre.c, and is distributed among the do_p* functions, so that multiple
fixes may be needed.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 23 09:52:19 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Mar 2009 09:52:19 +0100
Subject: [Rd] incoherent treatment of NULL
Message-ID: <49C74DC3.3090700@idi.ntnu.no>

somewhat related to a previous discussion [1] on how 'names<-' would
sometimes modify its argument in place, and sometimes produce a modified
copy without changing the original, here's another example of how it
becomes visible to the user when r makes or doesn't make a copy of an
object:

    x = NULL
    dput(x)
    # NULL
    class(x) = 'integer'
    # error: invalid (NULL) left side of assignment

    x = c()
    dput(x)
    # NULL
    class(x) = 'integer'
    dput(x)
    # integer(0)

in both cases, x ends up with the value NULL (the no-value object).  in
both cases, dput explains that x is NULL.  in both cases, an attempt is
made to make x be an empty integer vector.  the first fails, because it
tries to modify NULL itself, the latter apparently does not and succeeds.

however, the following has a different pattern:

    x = NULL
    dput(x)
    # NULL
    names(x) = character(0)
    # error: attempt to set an attribute on NULL

    x = c()
    dput(x)
    # NULL
    names(x) = character(0)
    # error: attempt to set an attribute on NULL

and also:

    x = c()
    class(x) = 'integer'
    # fine
    class(x) = 'foo'
    # error: attempt to set an attribute on NULL

how come?  the behaviour can obviously be explained by looking at the
source code (hardly surprisingly, because it is as it is because the
source is as it is), and referring to the NAMED property (i.e., the
sxpinfo.named field of a SEXPREC struct).  but can the *design* be
justified?  can the apparent incoherences visible above the interface be
defended? 

why should the first example above be unable to produce an empty integer
vector? 

why is it possible to set a class attribute, but not a names attribute,
on c()? 

why is it possible to set the class attribute in c() to 'integer', but
not to 'foo'? 

why are there different error messages for apparently the same problem?


vQ


[1] search the rd archives for 'surprising behaviour of names<-'


From maechler at stat.math.ethz.ch  Mon Mar 23 10:38:09 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Mar 2009 10:38:09 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <49C74DC3.3090700@idi.ntnu.no>
References: <49C74DC3.3090700@idi.ntnu.no>
Message-ID: <18887.22657.574884.473000@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 23 Mar 2009 09:52:19 +0100 writes:

    WK> somewhat related to a previous discussion [1] on how 'names<-' would
    WK> sometimes modify its argument in place, and sometimes produce a modified
    WK> copy without changing the original, here's another example of how it
    WK> becomes visible to the user when r makes or doesn't make a copy of an
    WK> object:

    WK> x = NULL
    WK> dput(x)
    WK> # NULL
    WK> class(x) = 'integer'
    WK> # error: invalid (NULL) left side of assignment

does not happen for me in R-2.8.1,  R-patched or newer

So you must be using your own patched version of  R ?

????


    WK> x = c()
    WK> dput(x)
    WK> # NULL
    WK> class(x) = 'integer'
    WK> dput(x)
    WK> # integer(0)

    WK> in both cases, x ends up with the value NULL (the no-value object).  in
    WK> both cases, dput explains that x is NULL.  in both cases, an attempt is
    WK> made to make x be an empty integer vector.  the first fails, because it
    WK> tries to modify NULL itself, the latter apparently does not and succeeds.

    WK> however, the following has a different pattern:

    WK> x = NULL
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL

    WK> x = c()
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL

    WK> and also:

    WK> x = c()
    WK> class(x) = 'integer'
    WK> # fine
    WK> class(x) = 'foo'
    WK> # error: attempt to set an attribute on NULL

    WK> how come?  the behaviour can obviously be explained by looking at the
    WK> source code (hardly surprisingly, because it is as it is because the
    WK> source is as it is), and referring to the NAMED property (i.e., the
    WK> sxpinfo.named field of a SEXPREC struct).  but can the *design* be
    WK> justified?  can the apparent incoherences visible above the interface be
    WK> defended? 

    WK> why should the first example above be unable to produce an empty integer
    WK> vector? 

    WK> why is it possible to set a class attribute, but not a names attribute,
    WK> on c()? 

    WK> why is it possible to set the class attribute in c() to 'integer', but
    WK> not to 'foo'? 

    WK> why are there different error messages for apparently the same problem?


    WK> vQ


    WK> [1] search the rd archives for 'surprising behaviour of names<-'

    WK> ______________________________________________
    WK> R-devel at r-project.org mailing list
    WK> https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 23 10:56:37 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Mar 2009 10:56:37 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <18887.22657.574884.473000@lynne.math.ethz.ch>
References: <49C74DC3.3090700@idi.ntnu.no>
	<18887.22657.574884.473000@lynne.math.ethz.ch>
Message-ID: <49C75CD5.10903@idi.ntnu.no>

Martin Maechler wrote:
>>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>>
>>>>>>             
>     WK> somewhat related to a previous discussion [1] on how 'names<-' would
>     WK> sometimes modify its argument in place, and sometimes produce a modified
>     WK> copy without changing the original, here's another example of how it
>     WK> becomes visible to the user when r makes or doesn't make a copy of an
>     WK> object:
>
>     WK> x = NULL
>     WK> dput(x)
>     WK> # NULL
>     WK> class(x) = 'integer'
>     WK> # error: invalid (NULL) left side of assignment
>
> does not happen for me in R-2.8.1,  R-patched or newer
>
> So you must be using your own patched version of  R ?
>   

oops, i meant to use 2.8.1 or devel for testing.  you're right, in this
example there is no error reported in > 2.8.0, but see below.

>
>     WK> x = c()
>     WK> dput(x)
>     WK> # NULL
>     WK> class(x) = 'integer'
>     WK> dput(x)
>     WK> # integer(0)
>
>     WK> in both cases, x ends up with the value NULL (the no-value object).  in
>     WK> both cases, dput explains that x is NULL.  in both cases, an attempt is
>     WK> made to make x be an empty integer vector.  the first fails, because it
>     WK> tries to modify NULL itself, the latter apparently does not and succeeds.
>
>     WK> however, the following has a different pattern:
>
>     WK> x = NULL
>     WK> dput(x)
>     WK> # NULL
>     WK> names(x) = character(0)
>     WK> # error: attempt to set an attribute on NULL
>   

i get the error in devel.


>     WK> x = c()
>     WK> dput(x)
>     WK> # NULL
>     WK> names(x) = character(0)
>     WK> # error: attempt to set an attribute on NULL
>   

i get the error in devel.

>     WK> and also:
>
>     WK> x = c()
>     WK> class(x) = 'integer'
>     WK> # fine
>     WK> class(x) = 'foo'
>     WK> # error: attempt to set an attribute on NULL
>   

i get the error in devel.

it doesn't seem coherent to me:  why can i set the class, but not names
attribute on both NULL and c()?  why can i set the class attribute to
'integer', but not to 'foo', as i could on a non-empty vector:

    x = 1
    class(x) = 'foo'
    # just fine

i'd naively expect to be able to create an empty vector classed 'foo',
displayed perhaps as

    # speculation
    x = NULL
    class(x) = 'foo'
    x
    # foo(0)

or maybe as

    x
    # NULL
    # attr(, "class")
    # [1] "foo"

vQ


From murdoch at stats.uwo.ca  Mon Mar 23 12:30:38 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 23 Mar 2009 07:30:38 -0400
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49C735FC.10408@dbmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>	<49C3EC00.5080302@stats.uwo.ca>	<49C400C8.7040208@biostat.ku.dk>	<49C40342.60203@dbmail.com>
	<49C6A4AB.2020300@dbmail.com>	<49C6D208.4060009@stats.uwo.ca>
	<49C735FC.10408@dbmail.com>
Message-ID: <49C772DE.6060307@stats.uwo.ca>

On 23/03/2009 3:10 AM, Romain Francois wrote:
> Duncan Murdoch wrote:
  ....
>> However, it might make sense for you to have your own parser, based on 
>> the grammar in R's parser, but handling white space differently. 
>> Certainly it would make sense to do that before making changes to the 
>> base R one.  The whole source is in src/main/gram.y; if you're not 
>> familiar with Bison, I can give you a hand.
> 
> Thank you, I appreciate your help. Having my own parser is the option I 
> am slowly converging to.
> I'll start with reading bison documentation. Besides bison documents, is 
> there R specific documentation on how the R parser was written ?

I don't think so.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Mon Mar 23 15:44:16 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Mar 2009 15:44:16 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <49C75CD5.10903@idi.ntnu.no>
References: <49C74DC3.3090700@idi.ntnu.no>
	<18887.22657.574884.473000@lynne.math.ethz.ch>
	<49C75CD5.10903@idi.ntnu.no>
Message-ID: <18887.41024.25380.419956@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 23 Mar 2009 10:56:37 +0100 writes:

    WK> Martin Maechler wrote:
    >>>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
    >>>>>>> 
    >>>>>>> 
    WK> somewhat related to a previous discussion [1] on how 'names<-' would
    WK> sometimes modify its argument in place, and sometimes produce a modified
    WK> copy without changing the original, here's another example of how it
    WK> becomes visible to the user when r makes or doesn't make a copy of an
    WK> object:
    >> 
    WK> x = NULL
    WK> dput(x)
    WK> # NULL
    WK> class(x) = 'integer'
    WK> # error: invalid (NULL) left side of assignment
    >> 
    >> does not happen for me in R-2.8.1,  R-patched or newer
    >> 
    >> So you must be using your own patched version of  R ?
    >> 

    WK> oops, i meant to use 2.8.1 or devel for testing.  you're right, in this
    WK> example there is no error reported in > 2.8.0, but see below.

ok

 [...... omitted part no longer relevant ........]

    WK> however, the following has a different pattern:
    >> 
    WK> x = NULL
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL
    >> 

    WK> i get the error in devel.

Yes,  NULL is NULL is NULL !   Do read  ?NULL !   [ ;-) ]

more verbously,  all NULL objects in R are identical, or as the
help page says, there's only ``*The* NULL Object'' in R,
i.e., NULL cannot get any attributes.

    WK> x = c()
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL
    >> 

    WK> i get the error in devel.

of course!  
   [I think *you* should have noticed that  NULL and c()  *are* identical]

    WK> and also:
    >> 
    WK> x = c()
    WK> class(x) = 'integer'
    WK> # fine
"fine" yes; 
here, the convention has been to change NULL into integer(0);
and no, this won't change, if you find it inconsistent.


    WK> class(x) = 'foo'
    WK> # error: attempt to set an attribute on NULL
    >> 

    WK> i get the error in devel.

No, not if you evaluate the statements above (where 'x' has
become  'integer(0)' in the mean time).

But yes, you get in something like

    x <- c();  class(x) <- "foo"

and I do agree that there's a buglet : 
The error message should be slightly more precise,
--- improvement proposals are welcome ---
but an error nontheless

    WK> it doesn't seem coherent to me:  why can i set the class, 

you cannot set it, you can *change* it.

    WK> but not names
    WK> attribute on both NULL and c()?  why can i set the class attribute to
    WK> 'integer', but not to 'foo', as i could on a non-empty vector:

    WK> x = 1
    WK> class(x) = 'foo'
    WK> # just fine

mainly because 'NULL is NULL is NULL' 
(NULL cannot have attributes)

    WK> i'd naively expect to be able to create an empty vector classed 'foo',

yes, but that expectation is wrong

    WK> displayed perhaps as

    WK> # speculation
    WK> x = NULL
    WK> class(x) = 'foo'
    WK> x
    WK> # foo(0)

    WK> or maybe as

    WK> x
    WK> # NULL
    WK> # attr(, "class")
    WK> # [1] "foo"

    WK> vQ

    WK> ______________________________________________
    WK> R-devel at r-project.org mailing list
    WK> https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 23 16:11:04 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Mar 2009 16:11:04 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <18887.41024.25380.419956@lynne.math.ethz.ch>
References: <49C74DC3.3090700@idi.ntnu.no>	<18887.22657.574884.473000@lynne.math.ethz.ch>	<49C75CD5.10903@idi.ntnu.no>
	<18887.41024.25380.419956@lynne.math.ethz.ch>
Message-ID: <49C7A688.7080501@idi.ntnu.no>

Martin Maechler wrote:
>
>  [...... omitted part no longer relevant ........]
>
>     WK> however, the following has a different pattern:
>     >> 
>     WK> x = NULL
>     WK> dput(x)
>     WK> # NULL
>     WK> names(x) = character(0)
>     WK> # error: attempt to set an attribute on NULL
>     >> 
>
>     WK> i get the error in devel.
>
> Yes,  NULL is NULL is NULL !   Do read  ?NULL !   [ ;-) ]
>
> more verbously,  all NULL objects in R are identical, or as the
> help page says, there's only ``*The* NULL Object'' in R,
> i.e., NULL cannot get any attributes.
>   

yes, but that's not the issue.  the issue is that names(x)<- seems to
try to attach an attribute to NULL, while it could, in principle, do the
same as class(x)<-, i.e., coerce x to some type (and hence attach the
name attribute not to NULL, but to the coerced-to object).

but, as someone else explained to me behind the scenes, the matters are
a little bit, so to speak, untidy:

    x = NULL
    class(x) = 'integer'
    # just fine

    x = NULL
    attr(x, 'class') = 'integer'
    # no go

where class()<-, but not attr(,'class')<-, will try to coerce x to an
object of the storage *mode* 'integer', hence the former succeeds
(because it sets, roughly, the 'integer' class on an empty integer
vector), while the latter fails (because it tries to set the 'integer'
class on NULL itself).

what was not clear to me is not why setting a class on NULL fails here,
but why it is setting on NULL in the first place.  after all,

    x = 1
    names(x) = 'foo'

is setting names on a *copy* of 1, not on *the* 1, so why could not
class()<- create a 'copy' of NULL, i.e., an empty vector of some type
(perhaps raw, as the lowest in the hierarchy).


>     WK> x = c()
>     WK> dput(x)
>     WK> # NULL
>     WK> names(x) = character(0)
>     WK> # error: attempt to set an attribute on NULL
>     >> 
>
>     WK> i get the error in devel.
>
> of course!  
>    [I think *you* should have noticed that  NULL and c()  *are* identical]
>
>     WK> and also:
>     >> 
>     WK> x = c()
>     WK> class(x) = 'integer'
>     WK> # fine
> "fine" yes; 
> here, the convention has been to change NULL into integer(0);
> and no, this won't change, if you find it inconsistent.
>   

that's ok, this is what i'd expect in the other cases, too (modulo the
actual storage mode).


>
>     WK> class(x) = 'foo'
>     WK> # error: attempt to set an attribute on NULL
>     >> 
>
>     WK> i get the error in devel.
>
> No, not if you evaluate the statements above (where 'x' has
> become  'integer(0)' in the mean time).
>
> But yes, you get in something like
>
>     x <- c();  class(x) <- "foo"
>   

that's what i meant, must have forgotten the x = c().

> and I do agree that there's a buglet : 
> The error message should be slightly more precise,
> --- improvement proposals are welcome ---
> but an error nontheless
>
>     WK> it doesn't seem coherent to me:  why can i set the class, 
>
> you cannot set it, you can *change* it.
>   

terminological wars? 

btw. the class of NULL is "NULL";  why can't nullify an object by
setting its class to 'NULL'?

    x = 1
    class(x) = 'NULL'
    x
    # *not* NULL

and one more interesting example:

    x = 1:2
    class(x) = 'NULL'
    x
    # [1] 1 2
    # attr(,"class") "NULL"
    x[1]
    # 1
    x[2]
    # 2
    is.vector(x)
    # FALSE

hurray!!! apparently, i've alchemized a non-vector vector...  (you can
do it in r-devel, for that matter).



>     WK> but not names
>     WK> attribute on both NULL and c()?  why can i set the class attribute to
>     WK> 'integer', but not to 'foo', as i could on a non-empty vector:
>
>     WK> x = 1
>     WK> class(x) = 'foo'
>     WK> # just fine
>
> mainly because 'NULL is NULL is NULL' 
> (NULL cannot have attributes)
>   

yes yes yes;  the question was, once again:  why is x still NULL?

>     WK> i'd naively expect to be able to create an empty vector classed 'foo',
>
> yes, but that expectation is wrong
>   

wrt. the actual state of matters, not necessarily wrt. the ideal state
of matters ;)  (i don't insist)

vQ


From maechler at stat.math.ethz.ch  Mon Mar 23 17:33:17 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Mar 2009 17:33:17 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <49C7A688.7080501@idi.ntnu.no>
References: <49C74DC3.3090700@idi.ntnu.no>
	<18887.22657.574884.473000@lynne.math.ethz.ch>
	<49C75CD5.10903@idi.ntnu.no>
	<18887.41024.25380.419956@lynne.math.ethz.ch>
	<49C7A688.7080501@idi.ntnu.no>
Message-ID: <18887.47565.277797.490023@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 23 Mar 2009 16:11:04 +0100 writes:

    WK> Martin Maechler wrote:
    >> 
    >> [...... omitted part no longer relevant ........]
    >> 
    WK> however, the following has a different pattern:
    >> >> 
    WK> x = NULL
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL
    >> >> 
    >> 
    WK> i get the error in devel.
    >> 
    >> Yes,  NULL is NULL is NULL !   Do read  ?NULL !   [ ;-) ]
    >> 
    >> more verbously,  all NULL objects in R are identical, or as the
    >> help page says, there's only ``*The* NULL Object'' in R,
    >> i.e., NULL cannot get any attributes.
    >> 

    WK> yes, but that's not the issue.  the issue is that names(x)<- seems to
    WK> try to attach an attribute to NULL, while it could, in principle, do the
    WK> same as class(x)<-, i.e., coerce x to some type (and hence attach the
    WK> name attribute not to NULL, but to the coerced-to object).

yes, it could;  but really, the  fact that  'class<-' works is
the exception.  The other variants (with the error message) are
the rule.

    WK> but, as someone else explained to me behind the scenes, the matters are
    WK> a little bit, so to speak, untidy:

    WK> x = NULL
    WK> class(x) = 'integer'
    WK> # just fine

    WK> x = NULL
    WK> attr(x, 'class') = 'integer'
    WK> # no go

    WK> where class()<-, but not attr(,'class')<-, will try to coerce x to an
    WK> object of the storage *mode* 'integer', hence the former succeeds
    WK> (because it sets, roughly, the 'integer' class on an empty integer
    WK> vector), while the latter fails (because it tries to set the 'integer'
    WK> class on NULL itself).

    WK> what was not clear to me is not why setting a class on NULL fails here,
    WK> but why it is setting on NULL in the first place.  after all,

    WK> x = 1
    WK> names(x) = 'foo'

    WK> is setting names on a *copy* of 1, not on *the* 1, so why could not
    WK> class()<- create a 'copy' of NULL, i.e., an empty vector of some type
    WK> (perhaps raw, as the lowest in the hierarchy).

yes, it could.  I personally don't think this would add any
value to R's behavior;  rather, for most useRs I'd think it
rather helps to get an error in such a case, than a  raw(0)
object.

Also, note (here and further below),
that Using   "class(.) <-  <className>"
is an S3 idiom   and S3 classes  ``don't really exist'', 
the "class" attribute being a useful hack,
and many of us would rather like to work and improve working
with S4 classes (& generics & methods) than to fiddle with  'class<-'.

In S4, you'd  use  setClass(.), new(.) and  setAs(.),
typically, for defining and changing classes of objects.

But maybe I have now lead you into a direction I will later
regret, 
....
when you start telling us about the perceived inconsistencies of
S4 classes, methods, etc.
BTW: If you go there, please do use  R 2.9.0 (or newer)
     exclusively.

    WK> x = c()
    WK> dput(x)
    WK> # NULL
    WK> names(x) = character(0)
    WK> # error: attempt to set an attribute on NULL
    >> >> 
    >> 
    WK> i get the error in devel.
    >> 
    >> of course!  
    >> [I think *you* should have noticed that  NULL and c()  *are* identical]
    >> 
    WK> and also:
    >> >> 
    WK> x = c()
    WK> class(x) = 'integer'
    WK> # fine
    >> "fine" yes; 
    >> here, the convention has been to change NULL into integer(0);
    >> and no, this won't change, if you find it inconsistent.
    >> 

    WK> that's ok, this is what i'd expect in the other cases, too (modulo the
    WK> actual storage mode).


    >> 
    WK> class(x) = 'foo'
    WK> # error: attempt to set an attribute on NULL
    >> >> 
    >> 
    WK> i get the error in devel.
    >> 
    >> No, not if you evaluate the statements above (where 'x' has
    >> become  'integer(0)' in the mean time).
    >> 
    >> But yes, you get in something like
    >> 
    >> x <- c();  class(x) <- "foo"
    >> 

    WK> that's what i meant, must have forgotten the x = c().

    >> and I do agree that there's a buglet : 
    >> The error message should be slightly more precise,
    >> --- improvement proposals are welcome ---
    >> but an error nontheless
    >> 
    WK> it doesn't seem coherent to me:  why can i set the class, 
    >> 
    >> you cannot set it, you can *change* it.
    >> 

    WK> terminological wars? 

    WK> btw. the class of NULL is "NULL";  why can't nullify an object by
    WK> setting its class to 'NULL'?

    WK> x = 1
    WK> class(x) = 'NULL'
    WK> x
    WK> # *not* NULL

see above {S4 / S3 / ...}; 
If you want to  "nullify", rather use
more (S-language) idiomatic calls like

    as(x, "NULL")
or  
    as.null(x)

both of which do work.

Regards,
Martin


    WK> and one more interesting example:

    WK> x = 1:2
    WK> class(x) = 'NULL'
    WK> x
    WK> # [1] 1 2
    WK> # attr(,"class") "NULL"
    WK> x[1]
    WK> # 1
    WK> x[2]
    WK> # 2
    WK> is.vector(x)
    WK> # FALSE

    WK> hurray!!! apparently, i've alchemized a non-vector vector...  (you can
    WK> do it in r-devel, for that matter).



    WK> but not names
    WK> attribute on both NULL and c()?  why can i set the class attribute to
    WK> 'integer', but not to 'foo', as i could on a non-empty vector:
    >> 
    WK> x = 1
    WK> class(x) = 'foo'
    WK> # just fine
    >> 
    >> mainly because 'NULL is NULL is NULL' 
    >> (NULL cannot have attributes)
    >> 

    WK> yes yes yes;  the question was, once again:  why is x still NULL?

    WK> i'd naively expect to be able to create an empty vector classed 'foo',
    >> 
    >> yes, but that expectation is wrong
    >> 

    WK> wrt. the actual state of matters, not necessarily wrt. the ideal state
    WK> of matters ;)  (i don't insist)

    WK> vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 23 21:27:11 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Mar 2009 21:27:11 +0100
Subject: [Rd] incoherent treatment of NULL
In-Reply-To: <18887.47565.277797.490023@lynne.math.ethz.ch>
References: <49C74DC3.3090700@idi.ntnu.no>	<18887.22657.574884.473000@lynne.math.ethz.ch>	<49C75CD5.10903@idi.ntnu.no>	<18887.41024.25380.419956@lynne.math.ethz.ch>	<49C7A688.7080501@idi.ntnu.no>
	<18887.47565.277797.490023@lynne.math.ethz.ch>
Message-ID: <49C7F09F.10301@idi.ntnu.no>

Martin Maechler wrote:
>
>     >> more verbously,  all NULL objects in R are identical, or as the
>     >> help page says, there's only ``*The* NULL Object'' in R,
>     >> i.e., NULL cannot get any attributes.
>     >> 
>
>     WK> yes, but that's not the issue.  the issue is that names(x)<- seems to
>     WK> try to attach an attribute to NULL, while it could, in principle, do the
>     WK> same as class(x)<-, i.e., coerce x to some type (and hence attach the
>     WK> name attribute not to NULL, but to the coerced-to object).
>
> yes, it could;  but really, the  fact that  'class<-' works is
> the exception.  The other variants (with the error message) are
> the rule.
>   

ok.

> Also, note (here and further below),
> that Using   "class(.) <-  <className>"
> is an S3 idiom   and S3 classes  ``don't really exist'', 
> the "class" attribute being a useful hack,
> and many of us would rather like to work and improve working
> with S4 classes (& generics & methods) than to fiddle with  'class<-'.
>
> In S4, you'd  use  setClass(.), new(.) and  setAs(.),
> typically, for defining and changing classes of objects.
>
> But maybe I have now lead you into a direction I will later
> regret, 
> ....
> when you start telling us about the perceived inconsistencies of
> S4 classes, methods, etc.
> BTW: If you go there, please do use  R 2.9.0 (or newer)
>   

using latest r-devel for the most part.

i think you will probably not regret your words;  from what i've seen
already, s4 classes are the last thing i'd ever try to learn in r.  but
yes, there would certainly be lots of issues to complain about.  i'll
rather wait for s5.

regards,
vQ


From bonner.reed at yale.edu  Mon Mar 23 19:55:14 2009
From: bonner.reed at yale.edu (bonner.reed at yale.edu)
Date: Mon, 23 Mar 2009 19:55:14 +0100 (CET)
Subject: [Rd] Error in Package Description (PR#13618)
Message-ID: <20090323185515.045C32832199@mail.pubhealth.ku.dk>

In the Installer for R.8.1 for Mac OSX Tiger or higher, the  
description of the GNU Fortran package in the customize option writes  
Fortran as "Fotran."  Just a minor error, but should be fixed if  
revisited.

-Bonner Reed
Yale Univ.


From cgenolin at u-paris10.fr  Mon Mar 23 23:25:48 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 23 Mar 2009 23:25:48 +0100
Subject: [Rd] matplot and lend="butt"
Message-ID: <49C80C6C.3050707@u-paris10.fr>

Hi the list,

I am using matplot with the option lend="butt", but only the first line 
(the black) is printed correctly  :

 > matplot(matrix(1:9,3),type="c",lwd=10,lty=1,lend="butt")

Is it a bug ?
I am using R2.8.1 under windows XP pack3.

Christophe


From ggrothendieck at gmail.com  Mon Mar 23 23:36:22 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 23 Mar 2009 18:36:22 -0400
Subject: [Rd] matplot and lend="butt"
In-Reply-To: <49C80C6C.3050707@u-paris10.fr>
References: <49C80C6C.3050707@u-paris10.fr>
Message-ID: <971536df0903231536m7fef589are3b25bcba176b70c@mail.gmail.com>

It looks to be a bug.  Here is the code and notice that ... is passed to
plot (which plots the first series) but not to lines (which plots the rest):

    if (!add) {
        ii <- ii[-1]
        plot(x[, 1], y[, 1], type = type[1], xlab = xlab, ylab = ylab,
            xlim = xlim, ylim = ylim, lty = lty[1], lwd = lwd[1],
            pch = pch[1], col = col[1], cex = cex[1], bg = bg[1],
            ...)
    }
    for (i in ii) {
        lines(x[, i], y[, i], type = type[i], lty = lty[i], lwd = lwd[i],
            pch = pch[i], col = col[i], cex = cex[i], bg = bg[i])
    }

This is from 2.8.1 patched but I noticed the same thing in
"R version 2.9.0 Under development (unstable) (2009-03-02 r48041)"


On Mon, Mar 23, 2009 at 6:25 PM, Christophe Genolini
<cgenolin at u-paris10.fr> wrote:
> Hi the list,
>
> I am using matplot with the option lend="butt", but only the first line (the
> black) is printed correctly ?:
>
>> matplot(matrix(1:9,3),type="c",lwd=10,lty=1,lend="butt")
>
> Is it a bug ?
> I am using R2.8.1 under windows XP pack3.
>
> Christophe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cgenolin at u-paris10.fr  Tue Mar 24 00:25:11 2009
From: cgenolin at u-paris10.fr (cgenolin at u-paris10.fr)
Date: Tue, 24 Mar 2009 00:25:11 +0100 (CET)
Subject: [Rd] matplot does not considere the parametre lend (PR#13619)
Message-ID: <20090323232511.7420F283218F@mail.pubhealth.ku.dk>

Full_Name: Christophe Genolini
Version: 2.8.1, but also 2.9
OS: Windows XP
Submission from: (NULL) (82.225.59.146)


I am using matplot with the option lend="butt", but only the first line (the
black) is printed correctly  :

> matplot(matrix(1:9,3),type="c",lwd=10,lty=1,lend="butt")

Gabor Grothendieck find the problem in matplot code:
the ... is passed to plot (which plots the first series) but not to lines (which
plots the rest):

    if (!add) {
        ii <- ii[-1]
        plot(x[, 1], y[, 1], type = type[1], xlab = xlab, ylab = ylab,
            xlim = xlim, ylim = ylim, lty = lty[1], lwd = lwd[1],
            pch = pch[1], col = col[1], cex = cex[1], bg = bg[1],
            ...)
    }
    for (i in ii) {
        lines(x[, i], y[, i], type = type[i], lty = lty[i], lwd = lwd[i],
            pch = pch[i], col = col[i], cex = cex[i], bg = bg[i])
    }


From cgenolin at u-paris10.fr  Tue Mar 24 00:35:09 2009
From: cgenolin at u-paris10.fr (cgenolin at u-paris10.fr)
Date: Tue, 24 Mar 2009 00:35:09 +0100 (CET)
Subject: [Rd] savePlot export "strange" eps (PR#13620)
Message-ID: <20090323233509.D35A8283218F@mail.pubhealth.ku.dk>

Full_Name: Christophe Genolini
Version: 2.8.1
OS: Windows XP
Submission from: (NULL) (82.225.59.146)


savePlot export "eps" graph that seems to be incorrect. 

Trying to incorporate them in a LaTeX file, I get : 
++++++++++++++++++++++
Cannot determine size of graphics in foo.eps (no BoundingBox)
----------------------

Trying to open them with GSview, I get :
++++++++++++++++++++++
GSview 4.9 2007-11-18
AFPL Ghostscript 8.54 (2006-05-17)
Copyright (C) 2005 artofcode LLC, Benicia, CA.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Displaying non DSC file C:/Documents and Settings/Christophe/Mes
documents/Recherche/Trajectoires/kmeal/trajectories/testsDev/toti.eps
Error: /undefined in 
Operand stack:

Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--  
--nostringval--   2   %stopped_push   --nostringval--   --nostringval--   false 
 1   %stopped_push   1   3   %oparray_pop   1   3   %oparray_pop   1   3  
%oparray_pop   1   3   %oparray_pop   .runexec2   --nostringval--  
--nostringval--   --nostringval--   2   %stopped_push   --nostringval--
Dictionary stack:
   --dict:1130/1686(ro)(G)--   --dict:0/20(G)--   --dict:74/200(L)--
Current allocation mode is local
Last OS error: No such file or directory

--- Begin offending input ---
   ?      L   z  f          C  fC   EMF   $6  7     
   l       ?    ?                ?? ?
 G r a p h A p p     %        ?%
       ?%        ?%        ?%        ?%        ?%        ?%       
?%        ?%        ?%        ?%        ?K   @   0                  
N   N   y  @  N   N   y  @  %        ?%        ?:      
   _   8      8       8         
                       %               
   ;            l   *  6      Z  ?  <      @      f   ?  `  0  %   
    ?(         %        ?%        ?K   @   0                   N   N 
 y  @  N   N   y  @  %        ?%        ?:      
   _   8      8       8         
                       %               
   ;            m  ?  6      Z  ?  <      @      g  ?  `  ?  %   
    ?(         %        ?%        ?K   @   0                         
 ?  ?          ?  ?  %        ?%        ?:      
   _   8      8       8                            
--- End offending input ---
file offset = 1024
gsapi_run_string_continue returns -101


From murdoch at stats.uwo.ca  Tue Mar 24 00:35:15 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 23 Mar 2009 19:35:15 -0400
Subject: [Rd] matplot does not considere the parametre lend (PR#13619)
In-Reply-To: <20090323232511.7420F283218F@mail.pubhealth.ku.dk>
References: <20090323232511.7420F283218F@mail.pubhealth.ku.dk>
Message-ID: <49C81CB3.7090905@stats.uwo.ca>

On 23/03/2009 7:25 PM, cgenolin at u-paris10.fr wrote:
> Full_Name: Christophe Genolini
> Version: 2.8.1, but also 2.9
> OS: Windows XP
> Submission from: (NULL) (82.225.59.146)
> 
> 
> I am using matplot with the option lend="butt", but only the first line (the
> black) is printed correctly  :
> 
>> matplot(matrix(1:9,3),type="c",lwd=10,lty=1,lend="butt")

I'd call this another case where it is performing as documented, but 
should probably be changed (but not by me).  In the meantime, there's 
the simple workaround:

save <- par(lend="butt")
matplot(matrix(1:9,3),type="c",lwd=10,lty=1)
par(save)

Duncan Murdoch

> 
> Gabor Grothendieck find the problem in matplot code:
> the ... is passed to plot (which plots the first series) but not to lines (which
> plots the rest):
> 
>     if (!add) {
>         ii <- ii[-1]
>         plot(x[, 1], y[, 1], type = type[1], xlab = xlab, ylab = ylab,
>             xlim = xlim, ylim = ylim, lty = lty[1], lwd = lwd[1],
>             pch = pch[1], col = col[1], cex = cex[1], bg = bg[1],
>             ...)
>     }
>     for (i in ii) {
>         lines(x[, i], y[, i], type = type[i], lty = lty[i], lwd = lwd[i],
>             pch = pch[i], col = col[i], cex = cex[i], bg = bg[i])
>     }
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Tue Mar 24 00:37:52 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 23 Mar 2009 19:37:52 -0400
Subject: [Rd] dput(as.list(function...)...) bug
Message-ID: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>

Tested in R 2.8.1 Windows

> ff <- formals(function(x)1)
> ff1 <- as.list(function(x)1)[1]
# ff1 acts the same as ff in the examples below, but is a list rather
than a pairlist

> dput( ff , control=c("warnIncomplete"))
list(x = )

This string is not parsable, but dput does not give a warning as specified.

> dput( ff , control=c("all","warnIncomplete"))
list(x = quote())

This string is parseable, but quote() is not evaluable, and again dput
does not give a warning as specified.

In fact, I don't know how to write out ff$x.  It appears to be the
zero-length name:

    is.name(ff$x) => TRUE
    as.character(ff$x) => ""

but there is no obvious way to create such an object:

    as.name("") => execution error
    quote(``) => parse error

The above examples should either produce a parseable and evaluable
output (preferable), or give a warning.

            -s

PS As a matter of comparative linguistics, many versions of Lisp allow
zero-length symbols/names.  But R coerces strings to symbols/names in
a way that Lisp does not, so that might be an invitation to obscure
bugs in R where it is rarely problematic in Lisp.

PPS dput(pairlist(23),control="all") also gives the same output as
dput(list(23),control="all"), but as I understand it, pairlists will
become non-user-visible at some point.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 24 00:39:58 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Mar 2009 00:39:58 +0100
Subject: [Rd] [R] variance/mean
In-Reply-To: <001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>
References: <20090322041729.6LTZR.3025252.root@mp11>
	<49C601BD.3080506@idi.ntnu.no>
	<001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>
Message-ID: <49C81DCE.1030901@idi.ntnu.no>


(this post suggests a patch to the sources, so i allow myself to divert
it to r-devel)

Bert Gunter wrote:
> x a numeric vector, matrix or data frame. 
> y NULL (default) or a vector, matrix or data frame with compatible
> dimensions to x. The default is equivalent to y = x (but more efficient). 
>
>   
bert points to an interesting fragment of ?var:  it suggests that
computing var(x) is more efficient than computing var(x,x), for any x
valid as input to var.  indeed:

    set.seed(0)
    x = matrix(rnorm(10000), 100, 100)

    library(rbenchmark)
    benchmark(replications=1000, columns=c('test', 'elapsed'),
       var(x),
       var(x, x))
    #        test elapsed
    # 1    var(x)   1.091
    # 2 var(x, x)   2.051

that's of course, so to speak, unreasonable:  for what var(x) does is
actually computing the covariance of x and x, which should be the same
as var(x,x). 

the hack is that if y is given, there's an overhead of memory allocation
for *both* x and y when y is given, as seen in src/main/cov.c:720+.
incidentally, it seems that the problem can be solved with a trivial fix
(see the attached patch), so that

    set.seed(0)
    x = matrix(rnorm(10000), 100, 100)

    library(rbenchmark)
    benchmark(replications=1000, columns=c('test', 'elapsed'),
       var(x),
       var(x, x))
    #        test elapsed
    # 1    var(x)   1.121
    # 2 var(x, x)   1.107

with the quick checks

    all.equal(var(x), var(x, x))
    # TRUE
   
    all(var(x) == var(x, x))
    # TRUE

and for cor it seems to make cor(x,x) slightly faster than cor(x), while
originally it was twice slower:

    # original
    benchmark(replications=1000, columns=c('test', 'elapsed'),
       cor(x),
       cor(x, x))
    #        test elapsed
    # 1    cor(x)   1.196
    # 2 cor(x, x)   2.253
   
    # patched
    benchmark(replications=1000, columns=c('test', 'elapsed'),
       cor(x),
       cor(x, x))
    #        test elapsed
    # 1    cor(x)   1.207
    # 2 cor(x, x)   1.204

(there is a visible penalty due to an additional pointer test, but it's
10ms on 1000 replications with 10000 data points, which i think is
negligible.)

> This is as clear as I would know how to state. 

i believe bert is right.

however, with the above fix, this can now be rewritten as:

"
x: a numeric vector, matrix or data frame. 
y: a vector, matrix or data frame with dimensions compatible to those of x. 
By default, y = x. 
"

which, to my simple mind, is even more clear than what bert would know
how to state, and less likely to cause the sort of confusion that
originated this thread.

the attached patch suggests modifications to src/main/cov.c and
src/library/stats/man/cor.Rd.
it has been prepared and checked as follows:

    svn co https://svn.r-project.org/R/trunk trunk
    cd trunk
    # edited the sources
    svn diff > cov.diff
    svn revert -R src
    patch -p0 < cov.diff

    tools/rsync-recommended
    ./configure
    make
    make check
    bin/R
    # subsequent testing within R

if you happen to consider this patch for a commit, please be sure to
examine and test it carefully first.

vQ
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cov.diff
Type: text/x-diff
Size: 1620 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090324/ae847de4/attachment.bin>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 24 00:53:43 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Mar 2009 00:53:43 +0100
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
Message-ID: <49C82107.5000708@idi.ntnu.no>

Stavros Macrakis wrote:
> Tested in R 2.8.1 Windows
>
>   
>> ff <- formals(function(x)1)
>> ff1 <- as.list(function(x)1)[1]
>>     
> # ff1 acts the same as ff in the examples below, but is a list rather
> than a pairlist
>
>   
>> dput( ff , control=c("warnIncomplete"))
>>     
> list(x = )
>
> This string is not parsable, but dput does not give a warning as specified.
>
>   

same in 2.10.0 r48200, ubuntu 8.04 linux 32 bit


>> dput( ff , control=c("all","warnIncomplete"))
>>     
> list(x = quote())
>   

likewise.

> This string is parseable, but quote() is not evaluable, and again dput
> does not give a warning as specified.
>
> In fact, I don't know how to write out ff$x.  It appears to be the
> zero-length name:
>
>     is.name(ff$x) => TRUE
>     as.character(ff$x) => ""
>
> but there is no obvious way to create such an object:
>
>     as.name("") => execution error
>     quote(``) => parse error
>
> The above examples should either produce a parseable and evaluable
> output (preferable), or give a warning.
>   

interestingly,

    quote(NULL)
    # NULL

    as.name(NULL)
    # Error in as.name(NULL) :
    #  invalid type/length (symbol/0) in vector allocation

?sj.

vQ

>             -s
>
> PS As a matter of comparative linguistics, many versions of Lisp allow
> zero-length symbols/names.  But R coerces strings to symbols/names in
> a way that Lisp does not, so that might be an invitation to obscure
> bugs in R where it is rarely problematic in Lisp.
>
> PPS dput(pairlist(23),control="all") also gives the same output as
> dput(list(23),control="all"), but as I understand it, pairlists will
> become non-user-visible at some point.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
-------------------------------------------------------------------------------
Wacek Kusnierczyk, MD PhD

Email: waku at idi.ntnu.no
Phone: +47 73591875, +47 72574609

Department of Computer and Information Science (IDI)
Faculty of Information Technology, Mathematics and Electrical Engineering (IME)
Norwegian University of Science and Technology (NTNU)
Sem Saelands vei 7, 7491 Trondheim, Norway
Room itv303

Bioinformatics & Gene Regulation Group
Department of Cancer Research and Molecular Medicine (IKM)
Faculty of Medicine (DMF)
Norwegian University of Science and Technology (NTNU)
Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
Room 231.05.060


From murdoch at stats.uwo.ca  Tue Mar 24 01:28:07 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 23 Mar 2009 20:28:07 -0400
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
Message-ID: <49C82917.6090409@stats.uwo.ca>

On 23/03/2009 7:37 PM, Stavros Macrakis wrote:
> Tested in R 2.8.1 Windows
> 
>> ff <- formals(function(x)1)
>> ff1 <- as.list(function(x)1)[1]
> # ff1 acts the same as ff in the examples below, but is a list rather
> than a pairlist
> 
>> dput( ff , control=c("warnIncomplete"))
> list(x = )
> 
> This string is not parsable, but dput does not give a warning as specified.

That's not what "warnIncomplete" is documented to do.  The docs (in 
?.deparseOpts) say

  'warnIncomplete' Some exotic objects such as environments,
           external pointers, etc. can not be deparsed properly.  This
           option causes a warning to be issued if any of those may give
           problems.

           Also, the parser in R < 2.7.0 would only accept strings of up
           to 8192 bytes, and this option gives a warning for longer
           strings.

As far as I can see, none of those conditions apply here:  ff is not one 
of those exotic objects or a very long string.  The really relevant 
comment is in the dput documentation:

"Deparsing an object is difficult, and not always possible."

Yes, it would be nice if deparsing and parsing were mutual inverses, but 
they're not, and are documented not to be.


>> dput( ff , control=c("all","warnIncomplete"))
> list(x = quote())
> 
> This string is parseable, but quote() is not evaluable, and again dput
> does not give a warning as specified.
> 
> In fact, I don't know how to write out ff$x. 

I don't know of any input that will parse to it.


  It appears to be the
> zero-length name:
> 
>     is.name(ff$x) => TRUE
>     as.character(ff$x) => ""

This may give you a hint:

 > y <- ff$x
 > y
Error: argument "y" is missing, with no default

It's a special internal thing that triggers the missing value error when 
evaluated.  It probably shouldn't be user visible at all.

Duncan Murdoch

> 
> but there is no obvious way to create such an object:
> 
>     as.name("") => execution error
>     quote(``) => parse error
> 
> The above examples should either produce a parseable and evaluable
> output (preferable), or give a warning.
> 
>             -s
> 
> PS As a matter of comparative linguistics, many versions of Lisp allow
> zero-length symbols/names.  But R coerces strings to symbols/names in
> a way that Lisp does not, so that might be an invitation to obscure
> bugs in R where it is rarely problematic in Lisp.
> 
> PPS dput(pairlist(23),control="all") also gives the same output as
> dput(list(23),control="all"), but as I understand it, pairlists will
> become non-user-visible at some point.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Tue Mar 24 02:02:51 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Mar 2009 18:02:51 -0700
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <49C82917.6090409@stats.uwo.ca>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
	<49C82917.6090409@stats.uwo.ca>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700E8F49B@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Monday, March 23, 2009 5:28 PM
> To: Stavros Macrakis
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] dput(as.list(function...)...) bug
> 
> On 23/03/2009 7:37 PM, Stavros Macrakis wrote:
> > Tested in R 2.8.1 Windows
> > 
> >> ff <- formals(function(x)1)
> >> ff1 <- as.list(function(x)1)[1]
> > # ff1 acts the same as ff in the examples below, but is a 
> list rather
> > than a pairlist
> > 
> >> dput( ff , control=c("warnIncomplete"))
> > list(x = )
> > 
> > This string is not parsable, but dput does not give a 
> warning as specified.

The string "list(x = )" is parsable:
  z <- parse(text="list(x = )")
Evaluating the resulting expression results in a run-time error:
  eval(z)
  Error in eval(expr, envir, enclos) :
    element 1 is empty;
     the part of the args list of 'list' being evaluated was:
     (x = )
That is the same sort of error you get from running list(,):
list wants all of its arguments to be present.

With other functions such a construct will run in R, although its result
does not match that of S+ (or SV4):

  > f<-function(x,y,z)c(x=if(missing(x))"<missing>"else x,
                        y=if(missing(y))"<missing>" else y,
                        z=if(missing(z))"<missing>" else z)
  R> f(x=,2,3)
            x           y           z
          "2"         "3" "<missing>"
  S+> f(x=,2,3)
             x   y   z
   "<missing>" "2" "3"
or
  R> f(y=,1,3)
            x           y           z
          "1"         "3" "<missing>"
  S+> f(y=,1,3)
     x           y   z
   "1" "<missing>" "3"

R and S+ act the same if you skip an argument by position
  > f(1,,3)
     x           y   z
   "1" "<missing>" "3"
but differ if you use name=<nothing>: in S+ it skips an argument by name
and in R it is ignored by ordinary functions (where
typeof(func)=="closure").

I wouldn't say this is recommended or often used or the point
of the original post.
 
Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> 
> That's not what "warnIncomplete" is documented to do.  The docs (in 
> ?.deparseOpts) say
> 
>   'warnIncomplete' Some exotic objects such as environments,
>            external pointers, etc. can not be deparsed properly.  This
>            option causes a warning to be issued if any of 
> those may give
>            problems.
> 
>            Also, the parser in R < 2.7.0 would only accept 
> strings of up
>            to 8192 bytes, and this option gives a warning for longer
>            strings.
> 
> As far as I can see, none of those conditions apply here:  ff 
> is not one 
> of those exotic objects or a very long string.  The really relevant 
> comment is in the dput documentation:
> 
> "Deparsing an object is difficult, and not always possible."
> 
> Yes, it would be nice if deparsing and parsing were mutual 
> inverses, but 
> they're not, and are documented not to be.
> 
> 
> >> dput( ff , control=c("all","warnIncomplete"))
> > list(x = quote())
> > 
> > This string is parseable, but quote() is not evaluable, and 
> again dput
> > does not give a warning as specified.
> > 
> > In fact, I don't know how to write out ff$x. 
> 
> I don't know of any input that will parse to it.
> 
> 
>   It appears to be the
> > zero-length name:
> > 
> >     is.name(ff$x) => TRUE
> >     as.character(ff$x) => ""
> 
> This may give you a hint:
> 
>  > y <- ff$x
>  > y
> Error: argument "y" is missing, with no default
> 
> It's a special internal thing that triggers the missing value 
> error when 
> evaluated.  It probably shouldn't be user visible at all.
> 
> Duncan Murdoch
> 
> > 
> > but there is no obvious way to create such an object:
> > 
> >     as.name("") => execution error
> >     quote(``) => parse error
> > 
> > The above examples should either produce a parseable and evaluable
> > output (preferable), or give a warning.
> > 
> >             -s
> > 
> > PS As a matter of comparative linguistics, many versions of 
> Lisp allow
> > zero-length symbols/names.  But R coerces strings to 
> symbols/names in
> > a way that Lisp does not, so that might be an invitation to obscure
> > bugs in R where it is rarely problematic in Lisp.
> > 
> > PPS dput(pairlist(23),control="all") also gives the same output as
> > dput(list(23),control="all"), but as I understand it, pairlists will
> > become non-user-visible at some point.
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From wdunlap at tibco.com  Tue Mar 24 02:17:41 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Mar 2009 18:17:41 -0700
Subject: [Rd] [R] variance/mean
In-Reply-To: <49C81DCE.1030901@idi.ntnu.no>
References: <20090322041729.6LTZR.3025252.root@mp11><49C601BD.3080506@idi.ntnu.no><001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>
	<49C81DCE.1030901@idi.ntnu.no>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700E8F4A1@NA-PA-VBE03.na.tibco.com>

Doesn't Fortran still require that the arguments to
a function not alias each other (in whole or in part)?
I could imagine that var() might call into Fortran code
(BLAS or LAPACK).  Wouldn you want to chance erroneous
results  at a high optimization level to save a bit of
time in an unusual situation?

(I could also imagine someone changing the R interpreter
so that x and x[-length(x)] could share the same memory
block and that could cause Fortran aliasing problems as
well.)

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Wacek Kusnierczyk
> Sent: Monday, March 23, 2009 4:40 PM
> To: r-devel at r-project.org
> Cc: r-help at r-project.org; rkevinburton at charter.net; Bert Gunter
> Subject: Re: [Rd] [R] variance/mean
> 
> 
> (this post suggests a patch to the sources, so i allow myself 
> to divert
> it to r-devel)
> 
> Bert Gunter wrote:
> > x a numeric vector, matrix or data frame. 
> > y NULL (default) or a vector, matrix or data frame with compatible
> > dimensions to x. The default is equivalent to y = x (but 
> more efficient). 
> >
> >   
> bert points to an interesting fragment of ?var:  it suggests that
> computing var(x) is more efficient than computing var(x,x), for any x
> valid as input to var.  indeed:
> 
>     set.seed(0)
>     x = matrix(rnorm(10000), 100, 100)
> 
>     library(rbenchmark)
>     benchmark(replications=1000, columns=c('test', 'elapsed'),
>        var(x),
>        var(x, x))
>     #        test elapsed
>     # 1    var(x)   1.091
>     # 2 var(x, x)   2.051
> 
> that's of course, so to speak, unreasonable:  for what var(x) does is
> actually computing the covariance of x and x, which should be the same
> as var(x,x). 
> 
> the hack is that if y is given, there's an overhead of memory 
> allocation
> for *both* x and y when y is given, as seen in src/main/cov.c:720+.
> incidentally, it seems that the problem can be solved with a 
> trivial fix
> (see the attached patch), so that
> 
>     set.seed(0)
>     x = matrix(rnorm(10000), 100, 100)
> 
>     library(rbenchmark)
>     benchmark(replications=1000, columns=c('test', 'elapsed'),
>        var(x),
>        var(x, x))
>     #        test elapsed
>     # 1    var(x)   1.121
>     # 2 var(x, x)   1.107
> 
> with the quick checks
> 
>     all.equal(var(x), var(x, x))
>     # TRUE
>    
>     all(var(x) == var(x, x))
>     # TRUE
> 
> and for cor it seems to make cor(x,x) slightly faster than 
> cor(x), while
> originally it was twice slower:
> 
>     # original
>     benchmark(replications=1000, columns=c('test', 'elapsed'),
>        cor(x),
>        cor(x, x))
>     #        test elapsed
>     # 1    cor(x)   1.196
>     # 2 cor(x, x)   2.253
>    
>     # patched
>     benchmark(replications=1000, columns=c('test', 'elapsed'),
>        cor(x),
>        cor(x, x))
>     #        test elapsed
>     # 1    cor(x)   1.207
>     # 2 cor(x, x)   1.204
> 
> (there is a visible penalty due to an additional pointer 
> test, but it's
> 10ms on 1000 replications with 10000 data points, which i think is
> negligible.)
> 
> > This is as clear as I would know how to state. 
> 
> i believe bert is right.
> 
> however, with the above fix, this can now be rewritten as:
> 
> "
> x: a numeric vector, matrix or data frame. 
> y: a vector, matrix or data frame with dimensions compatible 
> to those of x. 
> By default, y = x. 
> "
> 
> which, to my simple mind, is even more clear than what bert would know
> how to state, and less likely to cause the sort of confusion that
> originated this thread.
> 
> the attached patch suggests modifications to src/main/cov.c and
> src/library/stats/man/cor.Rd.
> it has been prepared and checked as follows:
> 
>     svn co https://svn.r-project.org/R/trunk trunk
>     cd trunk
>     # edited the sources
>     svn diff > cov.diff
>     svn revert -R src
>     patch -p0 < cov.diff
> 
>     tools/rsync-recommended
>     ./configure
>     make
>     make check
>     bin/R
>     # subsequent testing within R
> 
> if you happen to consider this patch for a commit, please be sure to
> examine and test it carefully first.
> 
> vQ
> 


From wdunlap at tibco.com  Tue Mar 24 02:25:55 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Mar 2009 18:25:55 -0700
Subject: [Rd] [R] variance/mean
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700E8F4A1@NA-PA-VBE03.na.tibco.com>
References: <20090322041729.6LTZR.3025252.root@mp11><49C601BD.3080506@idi.ntnu.no><001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com><49C81DCE.1030901@idi.ntnu.no>
	<77EB52C6DD32BA4D87471DCD70C8D700E8F4A1@NA-PA-VBE03.na.tibco.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700E8F4A2@NA-PA-VBE03.na.tibco.com>

Oops, I was thinking backwards.  This sort of
hack could avoid the Fortran aliasing rules, not
run afoul of them.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
> Sent: Monday, March 23, 2009 6:18 PM
> To: Wacek Kusnierczyk; r-devel at r-project.org
> Subject: Re: [Rd] [R] variance/mean
> 
> Doesn't Fortran still require that the arguments to
> a function not alias each other (in whole or in part)?
> I could imagine that var() might call into Fortran code
> (BLAS or LAPACK).  Wouldn you want to chance erroneous
> results  at a high optimization level to save a bit of
> time in an unusual situation?
> 
> (I could also imagine someone changing the R interpreter
> so that x and x[-length(x)] could share the same memory
> block and that could cause Fortran aliasing problems as
> well.)
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com  
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org 
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Wacek 
> Kusnierczyk
> > Sent: Monday, March 23, 2009 4:40 PM
> > To: r-devel at r-project.org
> > Cc: r-help at r-project.org; rkevinburton at charter.net; Bert Gunter
> > Subject: Re: [Rd] [R] variance/mean
> > 
> > 
> > (this post suggests a patch to the sources, so i allow myself 
> > to divert
> > it to r-devel)
> > 
> > Bert Gunter wrote:
> > > x a numeric vector, matrix or data frame. 
> > > y NULL (default) or a vector, matrix or data frame with compatible
> > > dimensions to x. The default is equivalent to y = x (but 
> > more efficient). 
> > >
> > >   
> > bert points to an interesting fragment of ?var:  it suggests that
> > computing var(x) is more efficient than computing var(x,x), 
> for any x
> > valid as input to var.  indeed:
> > 
> >     set.seed(0)
> >     x = matrix(rnorm(10000), 100, 100)
> > 
> >     library(rbenchmark)
> >     benchmark(replications=1000, columns=c('test', 'elapsed'),
> >        var(x),
> >        var(x, x))
> >     #        test elapsed
> >     # 1    var(x)   1.091
> >     # 2 var(x, x)   2.051
> > 
> > that's of course, so to speak, unreasonable:  for what 
> var(x) does is
> > actually computing the covariance of x and x, which should 
> be the same
> > as var(x,x). 
> > 
> > the hack is that if y is given, there's an overhead of memory 
> > allocation
> > for *both* x and y when y is given, as seen in src/main/cov.c:720+.
> > incidentally, it seems that the problem can be solved with a 
> > trivial fix
> > (see the attached patch), so that
> > 
> >     set.seed(0)
> >     x = matrix(rnorm(10000), 100, 100)
> > 
> >     library(rbenchmark)
> >     benchmark(replications=1000, columns=c('test', 'elapsed'),
> >        var(x),
> >        var(x, x))
> >     #        test elapsed
> >     # 1    var(x)   1.121
> >     # 2 var(x, x)   1.107
> > 
> > with the quick checks
> > 
> >     all.equal(var(x), var(x, x))
> >     # TRUE
> >    
> >     all(var(x) == var(x, x))
> >     # TRUE
> > 
> > and for cor it seems to make cor(x,x) slightly faster than 
> > cor(x), while
> > originally it was twice slower:
> > 
> >     # original
> >     benchmark(replications=1000, columns=c('test', 'elapsed'),
> >        cor(x),
> >        cor(x, x))
> >     #        test elapsed
> >     # 1    cor(x)   1.196
> >     # 2 cor(x, x)   2.253
> >    
> >     # patched
> >     benchmark(replications=1000, columns=c('test', 'elapsed'),
> >        cor(x),
> >        cor(x, x))
> >     #        test elapsed
> >     # 1    cor(x)   1.207
> >     # 2 cor(x, x)   1.204
> > 
> > (there is a visible penalty due to an additional pointer 
> > test, but it's
> > 10ms on 1000 replications with 10000 data points, which i think is
> > negligible.)
> > 
> > > This is as clear as I would know how to state. 
> > 
> > i believe bert is right.
> > 
> > however, with the above fix, this can now be rewritten as:
> > 
> > "
> > x: a numeric vector, matrix or data frame. 
> > y: a vector, matrix or data frame with dimensions compatible 
> > to those of x. 
> > By default, y = x. 
> > "
> > 
> > which, to my simple mind, is even more clear than what bert 
> would know
> > how to state, and less likely to cause the sort of confusion that
> > originated this thread.
> > 
> > the attached patch suggests modifications to src/main/cov.c and
> > src/library/stats/man/cor.Rd.
> > it has been prepared and checked as follows:
> > 
> >     svn co https://svn.r-project.org/R/trunk trunk
> >     cd trunk
> >     # edited the sources
> >     svn diff > cov.diff
> >     svn revert -R src
> >     patch -p0 < cov.diff
> > 
> >     tools/rsync-recommended
> >     ./configure
> >     make
> >     make check
> >     bin/R
> >     # subsequent testing within R
> > 
> > if you happen to consider this patch for a commit, please be sure to
> > examine and test it carefully first.
> > 
> > vQ
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From p.dalgaard at biostat.ku.dk  Tue Mar 24 08:52:58 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 24 Mar 2009 08:52:58 +0100
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <49C82917.6090409@stats.uwo.ca>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
	<49C82917.6090409@stats.uwo.ca>
Message-ID: <49C8915A.4070306@biostat.ku.dk>

Duncan Murdoch wrote:
> On 23/03/2009 7:37 PM, Stavros Macrakis wrote:

>  It appears to be the
>> zero-length name:
>>
>>     is.name(ff$x) => TRUE
>>     as.character(ff$x) => ""
> 
> This may give you a hint:
> 
>  > y <- ff$x
>  > y
> Error: argument "y" is missing, with no default
> 
> It's a special internal thing that triggers the missing value error when 
> evaluated.  It probably shouldn't be user visible at all.

Yes, it actually is the zero-length name that is being used for this, 
but that is not really useful knowledge because it is forbidden to 
create them as `` or as.name(""). We did briefly consider making the 
missing object a real R object, but the semantics are too weird:

Basically, you can only assign it once, next time you get errors:

 > x <- alist(a=)$a
 > missing(x)
[1] TRUE
 > y <- x
Error: argument "x" is missing, with no default
 > l <- alist(a=, b=2)
 > l$b <- x
Error: argument "x" is missing, with no default

And, as you think about it, you realize that you cannot disable these 
mechanisms, because _something_ has to trap use of missing arguments.

It does actually work to define a function mvi() which returns the 
missing value indicator and have things like

 > list(x= mvi(), b= quote(!x))
$x


$b
!x

work. I'd hate writing its help page, though.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From groemp at tfh-berlin.de  Tue Mar 24 09:33:14 2009
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Tue, 24 Mar 2009 01:33:14 -0700 (PDT)
Subject: [Rd]  Error in FrF2 example on Mac OS
Message-ID: <22675998.post@talk.nabble.com>


Dear all,

I just noticed that the 0.9 update for FrF2 did not work out for Mac OS due
to an error in an example that ran without error on all other platforms. I
do not find any reason for this. In the past, umlauts or tab characters have
sometimes been an issue, but I didn't find any of these. The function
definition is 

FrF2(nruns = NULL, nfactors = NULL, factor.names = if (!is.null(nfactors)) {
if (nfactors <= 50) Letters[1:nfactors] else
paste("F", 1:nfactors, sep = "")} else NULL,
default.levels = c(-1, 1), generators = NULL, resolution = NULL,
estimable = NULL, max.nfree2fis = FALSE,
randomize = TRUE, seed = NULL, ...){...}

and the simplest call to this function fails: 
FrF2(8,4)
gives the custom error message "nruns must be a power of 2.", which is
generated in the first check within function FrF2: 

    if (!is.null(nruns)){
       k <- floor(log2(nruns))
       if (!2^k==nruns) stop("nruns must be a power of 2.")}

Would the Mac (different from all other systems) require FrF2(nruns=8,
nfactors=4) ? Or what else could be the issue here ?

Thanks for any pointers!

Regards, Ulrike
-- 
View this message in context: http://www.nabble.com/Error-in-FrF2-example-on-Mac-OS-tp22675998p22675998.html
Sent from the R devel mailing list archive at Nabble.com.


From groemp at tfh-berlin.de  Tue Mar 24 10:33:31 2009
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Tue, 24 Mar 2009 02:33:31 -0700 (PDT)
Subject: [Rd]  Size of (objects in) sysdata.rda
Message-ID: <22676784.post@talk.nabble.com>


Dear all,

in my package FrF2, I currently face a trade-off of object size and
calculation run times. I would like to work with catalogues with some
pre-calculated information, and calculate some other information on an
as-needed basis. 

Is there any experience as to what sizes of objects in sysdata.rda will make
a package difficult to handle / slow ? If I would put into the catalogues
what I currently consider useful, I would most likely end up with an rda
file that takes more than 30 seconds to load on my machine. With the current
structure, it would consist almost exclusively of one massive list. I
suspect that this is not very wise. Would it help to lazy-load data and
split the list into several smaller ones (the larger ones of which will not
be used all that often) ? 
Or do I need a different strategy altogether ? 

Thanks for any advice!

Regards, Ulrike
-- 
View this message in context: http://www.nabble.com/Size-of-%28objects-in%29-sysdata.rda-tp22676784p22676784.html
Sent from the R devel mailing list archive at Nabble.com.


From krcabrer at une.net.co  Tue Mar 24 05:44:09 2009
From: krcabrer at une.net.co (Kenneth Roy Cabrera Torres)
Date: Mon, 23 Mar 2009 23:44:09 -0500
Subject: [Rd] Is aggregate() function changing?
Message-ID: <1237869849.2652.17.camel@localhost>

Hi R developers and debian users:

Finally I found how to work with aggregate() function
on the last patched version fo R.

I you use this command it fails:
  
 aggregate(state.x77, list(Region = state.region), mean)

But if you modify it in this way, it works!:

 aggregate(state.x77, list(Region = state.region), function(x) mean(x) )

Is it necesary to change the example?

What is changing in aggregate() function?

Thank you for your attention.

Kenneth.
>sessionInfo()

R version 2.8.1 Patched (2009-03-18 r48193) 
x86_64-unknown-linux-gnu 

locale:
LC_CTYPE=es_CO.UTF-8;LC_NUMERIC=C;LC_TIME=es_CO.UTF-8;LC_COLLATE=es_CO.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_CO.UTF-8;LC_PAPER=es_CO.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_CO.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From murdoch at stats.uwo.ca  Tue Mar 24 12:07:28 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 24 Mar 2009 07:07:28 -0400
Subject: [Rd] Is aggregate() function changing?
In-Reply-To: <1237869849.2652.17.camel@localhost>
References: <1237869849.2652.17.camel@localhost>
Message-ID: <49C8BEF0.9030805@stats.uwo.ca>

On 24/03/2009 12:44 AM, Kenneth Roy Cabrera Torres wrote:
> Hi R developers and debian users:
> 
> Finally I found how to work with aggregate() function
> on the last patched version fo R.
> 
> I you use this command it fails:
>   
>  aggregate(state.x77, list(Region = state.region), mean)
> 
> But if you modify it in this way, it works!:
> 
>  aggregate(state.x77, list(Region = state.region), function(x) mean(x) )
> 
> Is it necesary to change the example?
> 
> What is changing in aggregate() function?

I get identical results from those, but if I had a local variable (not a 
function) named "mean", the first one would not work:

 > mean <- 2
 > aggregate(state.x77, list(Region = state.region), mean)
Error in FUN(X[[1L]], ...) : element 1 is empty;
    the part of the args list of 'is.list' being evaluated was:
    (INDEX)

I suspect that is what is going wrong for you.

Duncan Murdoch


> 
> Thank you for your attention.
> 
> Kenneth.
>> sessionInfo()
> 
> R version 2.8.1 Patched (2009-03-18 r48193) 
> x86_64-unknown-linux-gnu 
> 
> locale:
> LC_CTYPE=es_CO.UTF-8;LC_NUMERIC=C;LC_TIME=es_CO.UTF-8;LC_COLLATE=es_CO.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_CO.UTF-8;LC_PAPER=es_CO.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_CO.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Mar 24 12:56:05 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 24 Mar 2009 07:56:05 -0400
Subject: [Rd] Is aggregate() function changing?
In-Reply-To: <49C8BEF0.9030805@stats.uwo.ca>
References: <1237869849.2652.17.camel@localhost>
	<49C8BEF0.9030805@stats.uwo.ca>
Message-ID: <971536df0903240456s1abcb9d8s94553fcd4be569be@mail.gmail.com>

On Tue, Mar 24, 2009 at 7:07 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 24/03/2009 12:44 AM, Kenneth Roy Cabrera Torres wrote:
>>
>> Hi R developers and debian users:
>>
>> Finally I found how to work with aggregate() function
>> on the last patched version fo R.
>>
>> I you use this command it fails:
>> ??aggregate(state.x77, list(Region = state.region), mean)
>>
>> But if you modify it in this way, it works!:
>>
>> ?aggregate(state.x77, list(Region = state.region), function(x) mean(x) )
>>
>> Is it necesary to change the example?
>>
>> What is changing in aggregate() function?
>
> I get identical results from those, but if I had a local variable (not a
> function) named "mean", the first one would not work:
>
>> mean <- 2
>> aggregate(state.x77, list(Region = state.region), mean)
> Error in FUN(X[[1L]], ...) : element 1 is empty;
> ? the part of the args list of 'is.list' being evaluated was:
> ? (INDEX)
>
> I suspect that is what is going wrong for you.
>

although "mean" in quotes works even then:

> mean <- 1
> aggregate(state.x77, list(Region = state.region), "mean")
         Region Population   Income Illiteracy Life Exp    Murder  HS Grad
1     Northeast   5495.111 4570.222   1.000000 71.26444  4.722222 53.96667
2         South   4208.125 4011.938   1.737500 69.70625 10.581250 44.34375
3 North Central   4803.000 4611.083   0.700000 71.76667  5.275000 54.51667
4          West   2915.308 4702.615   1.023077 71.23462  7.215385 62.00000
     Frost      Area
1 132.7778  18141.00
2  64.6250  54605.12
3 138.8333  62652.00
4 102.1538 134463.00


From ligges at statistik.tu-dortmund.de  Tue Mar 24 14:45:57 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 24 Mar 2009 14:45:57 +0100
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <22675998.post@talk.nabble.com>
References: <22675998.post@talk.nabble.com>
Message-ID: <49C8E415.3060702@statistik.tu-dortmund.de>



Ulrike Gr?mping wrote:
> Dear all,
> 
> I just noticed that the 0.9 update for FrF2 did not work out for Mac OS due
> to an error in an example that ran without error on all other platforms. I
> do not find any reason for this. In the past, umlauts or tab characters have
> sometimes been an issue, but I didn't find any of these. The function
> definition is 
> 
> FrF2(nruns = NULL, nfactors = NULL, factor.names = if (!is.null(nfactors)) {
> if (nfactors <= 50) Letters[1:nfactors] else
> paste("F", 1:nfactors, sep = "")} else NULL,
> default.levels = c(-1, 1), generators = NULL, resolution = NULL,
> estimable = NULL, max.nfree2fis = FALSE,
> randomize = TRUE, seed = NULL, ...){...}
> 
> and the simplest call to this function fails: 
> FrF2(8,4)
> gives the custom error message "nruns must be a power of 2.", which is
> generated in the first check within function FrF2: 
> 
>     if (!is.null(nruns)){
>        k <- floor(log2(nruns))
>        if (!2^k==nruns) stop("nruns must be a power of 2.")}


Probably a rounding issue on different platforms?
I guess the test should be something like:

if (!is.null(nruns)){
   if(!isTRUE(all.equal(log2(nruns) %% 1, 0)))
     stop("nruns must be a power of 2.")
}


Uwe




> Would the Mac (different from all other systems) require FrF2(nruns=8,
> nfactors=4) ? Or what else could be the issue here ?
> 
> Thanks for any pointers!
> 
> Regards, Ulrike


From macrakis at alum.mit.edu  Tue Mar 24 15:02:17 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 24 Mar 2009 10:02:17 -0400
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <49C82917.6090409@stats.uwo.ca>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>
	<49C82917.6090409@stats.uwo.ca>
Message-ID: <8b356f880903240702r1fc09311rd4d2cd05898cb33a@mail.gmail.com>

Peter, Duncan,

I understand that the missing value indicator is special and will not
behave like an ordinary value in evaluation. I was only discussing its
handling in the text representation functions dput and dump.

Duncan,

You are absolutely right that "list(x=)" is parseable (though not
evaluable).  My mistake.

However, the point stands that dput/dget do not successfully recreate
the object, and do not give an error as promised in the documentation.

I said: "dput does not give a warning as specified" and you quoted
?.deparseOpts:

     Some exotic objects such as environments,?external pointers, etc.
can not [sic] be
     deparsed properly. ?This?option causes a warning to be issued if
any of those
     may give?problems....

You apparently read this to mean that only environments and external
pointers are "exotic objects":

     That's not what "warnIncomplete" is documented to do....  As far
as I can see, none
     of those conditions apply here:  ff is not one of those exotic
objects or a very long
     string....

However, they are listed as examples ("such as"); and there is an
"etc." indicating that there are other, unnamed, exotic objects (and
the missing value indicator seems pretty exotic to me...).  What's
more, the sentence explicitly says that the warning is issued "if
*any* of those may give problems" (not "some"); the definition is not
in terms of a list of "exotic objects", but in terms of the behavior
of "giving problems".

That is the plain English sense of the passage, and also the
substantively reasonable one.

          -s


From ligges at statistik.tu-dortmund.de  Tue Mar 24 15:02:19 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 24 Mar 2009 15:02:19 +0100
Subject: [Rd] Size of (objects in) sysdata.rda
In-Reply-To: <22676784.post@talk.nabble.com>
References: <22676784.post@talk.nabble.com>
Message-ID: <49C8E7EB.3090502@statistik.tu-dortmund.de>



Ulrike Gr?mping wrote:
> Dear all,
> 
> in my package FrF2, I currently face a trade-off of object size and
> calculation run times. I would like to work with catalogues with some
> pre-calculated information, and calculate some other information on an
> as-needed basis. 
> 
> Is there any experience as to what sizes of objects in sysdata.rda will make
> a package difficult to handle / slow ? If I would put into the catalogues
> what I currently consider useful, I would most likely end up with an rda
> file that takes more than 30 seconds to load on my machine. With the current
> structure, it would consist almost exclusively of one massive list. I
> suspect that this is not very wise. Would it help to lazy-load data and
> split the list into several smaller ones (the larger ones of which will not
> be used all that often) ? 

Sounds good!

Uwe


> Or do I need a different strategy altogether ? 
> 
> Thanks for any advice!
> 
> Regards, Ulrike


From savicky at cs.cas.cz  Tue Mar 24 15:17:28 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 24 Mar 2009 15:17:28 +0100
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <49C8E415.3060702@statistik.tu-dortmund.de>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
Message-ID: <20090324141728.GC4963@cs.cas.cz>

On Tue, Mar 24, 2009 at 02:45:57PM +0100, Uwe Ligges wrote:
> >gives the custom error message "nruns must be a power of 2.", which is
> >generated in the first check within function FrF2: 
> >
> >    if (!is.null(nruns)){
> >       k <- floor(log2(nruns))
> >       if (!2^k==nruns) stop("nruns must be a power of 2.")}
> 
> 
> Probably a rounding issue on different platforms?
> I guess the test should be something like:
> 
> if (!is.null(nruns)){
>   if(!isTRUE(all.equal(log2(nruns) %% 1, 0)))
>     stop("nruns must be a power of 2.")
> }

Probably, k is needed also later. Assumig that 2^k works correctly,
the following could be sufficient

   if (!is.null(nruns)){
      k <- round(log2(nruns))
      if (!2^k==nruns) stop("nruns must be a power of 2.")}

In order to test the assumption, one can use

  x <- 2^(0:100 + 0) # use double exponent to be sure
  all(x == floor(x))

Powers of two are represented exactly, since they have only one significant bit.

Petr.


From groemping at tfh-berlin.de  Tue Mar 24 15:25:51 2009
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Tue, 24 Mar 2009 15:25:51 +0100
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <49C8E415.3060702@statistik.tu-dortmund.de>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
Message-ID: <20090324142003.M54540@tfh-berlin.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090324/4ad3e089/attachment.pl>

From murdoch at stats.uwo.ca  Tue Mar 24 15:30:12 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 24 Mar 2009 10:30:12 -0400
Subject: [Rd] dput(as.list(function...)...) bug
In-Reply-To: <8b356f880903240702r1fc09311rd4d2cd05898cb33a@mail.gmail.com>
References: <8b356f880903231637v4d5d879dqe51c2d52a73802e4@mail.gmail.com>	<49C82917.6090409@stats.uwo.ca>
	<8b356f880903240702r1fc09311rd4d2cd05898cb33a@mail.gmail.com>
Message-ID: <49C8EE74.6030306@stats.uwo.ca>

On 3/24/2009 10:02 AM, Stavros Macrakis wrote:
> Peter, Duncan,
> 
> I understand that the missing value indicator is special and will not
> behave like an ordinary value in evaluation. I was only discussing its
> handling in the text representation functions dput and dump.
> 
> Duncan,
> 
> You are absolutely right that "list(x=)" is parseable (though not
> evaluable).  My mistake.
> 
> However, the point stands that dput/dget do not successfully recreate
> the object, and do not give an error as promised in the documentation.
> 
> I said: "dput does not give a warning as specified" and you quoted
> ?.deparseOpts:
> 
>      Some exotic objects such as environments, external pointers, etc.
> can not [sic] be
>      deparsed properly.  This option causes a warning to be issued if
> any of those
>      may give problems....
> 
> You apparently read this to mean that only environments and external
> pointers are "exotic objects":
> 
>      That's not what "warnIncomplete" is documented to do....  As far
> as I can see, none
>      of those conditions apply here:  ff is not one of those exotic
> objects or a very long
>      string....
> 
> However, they are listed as examples ("such as"); and there is an
> "etc." indicating that there are other, unnamed, exotic objects (and
> the missing value indicator seems pretty exotic to me...).  What's
> more, the sentence explicitly says that the warning is issued "if
> *any* of those may give problems" (not "some"); the definition is not
> in terms of a list of "exotic objects", but in terms of the behavior
> of "giving problems".
> 
> That is the plain English sense of the passage, and also the
> substantively reasonable one.

It's a documentation problem.  There is not supposed to be a promise to 
warn in every case.

There are two ways to fix this:  the easy way is to patch the docs, the 
very hard way is to analyze the deparser, and make it detect every case 
where it will produce something that doesn't parse back to something 
identical to the original.  If you want to volunteer to do the latter, 
I'll hold off, otherwise I'll fix the docs to weaken the apparent promise.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Tue Mar 24 15:35:18 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 24 Mar 2009 15:35:18 +0100
Subject: [Rd] savePlot export "strange" eps (PR#13620)
In-Reply-To: <20090323233509.D35A8283218F@mail.pubhealth.ku.dk>
References: <20090323233509.D35A8283218F@mail.pubhealth.ku.dk>
Message-ID: <49C8EFA6.2020309@statistik.tu-dortmund.de>



cgenolin at u-paris10.fr wrote:
> Full_Name: Christophe Genolini
> Version: 2.8.1
> OS: Windows XP
> Submission from: (NULL) (82.225.59.146)
> 
> 
> savePlot export "eps" graph that seems to be incorrect. 


Looks like you saved an EMF rather than an eps file???

Uwe Ligges



> Trying to incorporate them in a LaTeX file, I get : 
> ++++++++++++++++++++++
> Cannot determine size of graphics in foo.eps (no BoundingBox)
> ----------------------
> 
> Trying to open them with GSview, I get :
> ++++++++++++++++++++++
> GSview 4.9 2007-11-18
> AFPL Ghostscript 8.54 (2006-05-17)
> Copyright (C) 2005 artofcode LLC, Benicia, CA.  All rights reserved.
> This software comes with NO WARRANTY: see the file PUBLIC for details.
> Displaying non DSC file C:/Documents and Settings/Christophe/Mes
> documents/Recherche/Trajectoires/kmeal/trajectories/testsDev/toti.eps
> Error: /undefined in 
> Operand stack:
> 
> Execution stack:
>    %interp_exit   .runexec2   --nostringval--   --nostringval--  
> --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   false 
>  1   %stopped_push   1   3   %oparray_pop   1   3   %oparray_pop   1   3  
> %oparray_pop   1   3   %oparray_pop   .runexec2   --nostringval--  
> --nostringval--   --nostringval--   2   %stopped_push   --nostringval--
> Dictionary stack:
>    --dict:1130/1686(ro)(G)--   --dict:0/20(G)--   --dict:74/200(L)--
> Current allocation mode is local
> Last OS error: No such file or directory
> 
> --- Begin offending input ---
>    ?      L   z  f          C  fC   EMF   $6  7     
>    l       ?    ?                ?? ? G r a p h A p p     %        ?%
>        ?%        ?%        ?%        ?%        ?%        ?%       
> ?%        ?%        ?%        ?%        ?K   @   0                  
> N   N   y  @  N   N   y  @  %        ?%        ?:      
>    _   8      8       8         
>                        %               
>    ;            l   *  6      Z  ?  <      @      f   ?  `  0  %   
>     ?(         %        ?%        ?K   @   0                   N   N 
>  y  @  N   N   y  @  %        ?%        ?:      
>    _   8      8       8         
>                        %               
>    ;            m  ?  6      Z  ?  <      @      g  ?  `  ?  %   
>     ?(         %        ?%        ?K   @   0                         
>  ?  ?          ?  ?  %        ?%        ?:      
>    _   8      8       8                            
> --- End offending input ---
> file offset = 1024
> gsapi_run_string_continue returns -101
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemp at tfh-berlin.de  Tue Mar 24 15:41:31 2009
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Tue, 24 Mar 2009 07:41:31 -0700 (PDT)
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <20090324141728.GC4963@cs.cas.cz>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
	<20090324141728.GC4963@cs.cas.cz>
Message-ID: <22681913.post@talk.nabble.com>



Petr Savicky wrote:
> 
> On Tue, Mar 24, 2009 at 02:45:57PM +0100, Uwe Ligges wrote:
>> >gives the custom error message "nruns must be a power of 2.", which is
>> >generated in the first check within function FrF2: 
>> >
>> >    if (!is.null(nruns)){
>> >       k <- floor(log2(nruns))
>> >       if (!2^k==nruns) stop("nruns must be a power of 2.")}
>> 
>> 
>> Probably a rounding issue on different platforms?
>> I guess the test should be something like:
>> 
>> if (!is.null(nruns)){
>>   if(!isTRUE(all.equal(log2(nruns) %% 1, 0)))
>>     stop("nruns must be a power of 2.")
>> }
> 
> Probably, k is needed also later. Assumig that 2^k works correctly,
> the following could be sufficient
> 
>    if (!is.null(nruns)){
>       k <- round(log2(nruns))
>       if (!2^k==nruns) stop("nruns must be a power of 2.")}
> 
> In order to test the assumption, one can use
> 
>   x <- 2^(0:100 + 0) # use double exponent to be sure
>   all(x == floor(x))
> 
> Powers of two are represented exactly, since they have only one
> significant bit.
> 
> Petr.
> 

Yes, round instead of floor should also do the job, if rounding is the
issue. But then, with powers of 2 indeed being represented exactly (I would
expect even on Macs), maybe rounding is not the issue? I have no possibility
to check this, since I do not have access to a Mac with R installed. On my
windows machine, 
all(log2(x)==floor(log2(x))) 
with x as defined above yields TRUE.

Regards, Ulrike
-- 
View this message in context: http://www.nabble.com/Error-in-FrF2-example-on-Mac-OS-tp22675998p22681913.html
Sent from the R devel mailing list archive at Nabble.com.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 24 16:15:22 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Mar 2009 16:15:22 +0100
Subject: [Rd] [R] variance/mean
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700E8F4A1@NA-PA-VBE03.na.tibco.com>
References: <20090322041729.6LTZR.3025252.root@mp11><49C601BD.3080506@idi.ntnu.no><001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>
	<49C81DCE.1030901@idi.ntnu.no>
	<77EB52C6DD32BA4D87471DCD70C8D700E8F4A1@NA-PA-VBE03.na.tibco.com>
Message-ID: <49C8F90A.2030809@idi.ntnu.no>

William Dunlap wrote:
> Doesn't Fortran still require that the arguments to
> a function not alias each other (in whole or in part)?
>   

what do you mean?  the following works pretty fine:

    echo '
        program foo
        implicit none

        integer, target :: a = 1
        integer, pointer :: p1, p2, p3
        integer :: gee

        p1 => a
        p2 => a
        p3 => a
        write(*,*) p1, p2, p3
        call bar (p1, p2, p3)
        write(*,*) p1, p2, p3
        a = gee(p1, p2, p3)
        write(*,*) p1, p2, p3
      
        end program foo

        subroutine bar (p1, p2, p3)
        integer :: p1, p2, p3
        p3 = p1 + p2
        end subroutine bar

        function gee(p1, p2, p3)
        integer :: p1, p2, p3, gee
        p3 = p1 + p2
        gee = p3
        return
        end function gee

    ' > foo.f95

    gfortran foo.f95 -o foo
    ./foo
    # 1 1 1
    # 2 2 2
    # 4 4 4

clearly, p1, p2, and p3 are aliases of each other, and there is an
assignment made in both the subroutine and the function.  have i
misunderstood what you said?

vQ


From cgenolin at u-paris10.fr  Tue Mar 24 16:52:26 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Tue, 24 Mar 2009 16:52:26 +0100
Subject: [Rd] savePlot export "strange" eps (PR#13620)
In-Reply-To: <49C8EFA6.2020309@statistik.tu-dortmund.de>
References: <20090323233509.D35A8283218F@mail.pubhealth.ku.dk>
	<49C8EFA6.2020309@statistik.tu-dortmund.de>
Message-ID: <49C901BA.3080305@u-paris10.fr>

Sorry for that... I find a strange behavior in "savePlot" ; before 
report a bug, I read the posting guide and I try to simplify my exemple 
as much as possible. Doing this, I change my code and I remove the " 
type='eps' " option... Sorry !

Let's start this again.

When I use savePlot(file="toto.eps",type="eps") and I try to incorporate 
"toto.eps" in a LaTeX document, I get a strange behavior:
LaTeX run normaly, so does dvips. But the generated postscript include a 
graph that overwirte the line above it.
If my latex is

bonjour bonjour2 bonjour3
\begin{center}
 \includegraphics[width=12cm]{toto.eps}
\end{center}

Then "bonjour2 bonjour3" is hidden by the graph.

Version: 2.8.1
OS: Windows XP
LaTeX : Miktex 2.7

Christophe

>
>
> cgenolin at u-paris10.fr wrote:
>> Full_Name: Christophe Genolini
>> Version: 2.8.1
>> OS: Windows XP
>> Submission from: (NULL) (82.225.59.146)
>>
>>
>> savePlot export "eps" graph that seems to be incorrect. 
>
>
> Looks like you saved an EMF rather than an eps file???
>
> Uwe Ligges
>
>
>
>> Trying to incorporate them in a LaTeX file, I get : 
>> ++++++++++++++++++++++
>> Cannot determine size of graphics in foo.eps (no BoundingBox)
>> ----------------------
>>
>> Trying to open them with GSview, I get :
>> ++++++++++++++++++++++
>> GSview 4.9 2007-11-18
>> AFPL Ghostscript 8.54 (2006-05-17)
>> Copyright (C) 2005 artofcode LLC, Benicia, CA.  All rights reserved.
>> This software comes with NO WARRANTY: see the file PUBLIC for details.
>> Displaying non DSC file C:/Documents and Settings/Christophe/Mes
>> documents/Recherche/Trajectoires/kmeal/trajectories/testsDev/toti.eps
>> Error: /undefined in 
>> Operand stack:
>>
>> Execution stack:
>>    %interp_exit   .runexec2   --nostringval--   --nostringval--  
>> --nostringval--   2   %stopped_push   --nostringval--   
>> --nostringval--   false  1   %stopped_push   1   3   %oparray_pop   
>> 1   3   %oparray_pop   1   3  %oparray_pop   1   3   %oparray_pop   
>> .runexec2   --nostringval--  --nostringval--   --nostringval--   2   
>> %stopped_push   --nostringval--
>> Dictionary stack:
>>    --dict:1130/1686(ro)(G)--   --dict:0/20(G)--   --dict:74/200(L)--
>> Current allocation mode is local
>> Last OS error: No such file or directory
>>
>> --- Begin offending input ---
>>    ?      L   z  f          C  fC   EMF   $6  7        
>> l       ?    ?                ?? ? G r a p h A p p     
>> %        ?%
>>        ?%        ?%        ?%        ?%        ?%        
>> ?%       ?%        ?%        ?%        ?%        ?K   @   
>> 0                  N   N   y  @  N   N   y  @  %        
>> ?%        ?:         _   8      8       8         
>>                        %                  ;            l   *  
>> 6      Z  ?  <      @      f   ?  `  0  %   
>>     ?(         %        ?%        ?K   @   0             
>>       N   N  y  @  N   N   y  @  %        ?%        ?:   
>>       _   8      8       8                                %   
>>                ;            m  ?  6      Z  ?  <      
>> @      g  ?  `  ?  %   
>>     ?(         %        ?%        ?K   @   0             
>>              ?  ?          ?  ?  %        ?%        ?:   
>>       _   8      8       8                            --- End 
>> offending input ---
>> file offset = 1024
>> gsapi_run_string_continue returns -101
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From michael.herzhoff at hotmail.de  Tue Mar 24 16:25:08 2009
From: michael.herzhoff at hotmail.de (michael.herzhoff at hotmail.de)
Date: Tue, 24 Mar 2009 16:25:08 +0100 (CET)
Subject: [Rd] Write in Table with Schema (PR#13622)
Message-ID: <20090324152508.CC9922832196@mail.pubhealth.ku.dk>

Full_Name: Michael
Version: actual
OS: windows
Submission from: (NULL) (77.87.228.65)


To Save Data to MS SQL Server 2005 i take this function:
ok <- sqlSave(write_channel , target_data, tablename="Import.R_Data",
append=TRUE, fast=FALSE, safer=TRUE, nastring=NULL, rownames=FALSE);

The Table with the name "Import.R_Data" is not writing. It always take
"dbo.Import.R_Data".

So it is not possible to secure Tables with the roles sucurity.

Can you help me?

Kind regards
Michael


From savicky at cs.cas.cz  Wed Mar 25 07:27:31 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 25 Mar 2009 07:27:31 +0100
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <22681913.post@talk.nabble.com>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
	<20090324141728.GC4963@cs.cas.cz> <22681913.post@talk.nabble.com>
Message-ID: <20090325062731.GA29613@cs.cas.cz>

On Tue, Mar 24, 2009 at 07:41:31AM -0700, Ulrike Gr?mping wrote:
> > Probably, k is needed also later. Assumig that 2^k works correctly,
> > the following could be sufficient
> > 
> >    if (!is.null(nruns)){
> >       k <- round(log2(nruns))
> >       if (!2^k==nruns) stop("nruns must be a power of 2.")}
> > 
> > In order to test the assumption, one can use
> > 
> >   x <- 2^(0:100 + 0) # use double exponent to be sure
> >   all(x == floor(x))
> > 
> > Powers of two are represented exactly, since they have only one
> > significant bit.
> > 
> > Petr.
> > 
> 
> Yes, round instead of floor should also do the job, if rounding is the
> issue. But then, with powers of 2 indeed being represented exactly (I would
> expect even on Macs), maybe rounding is not the issue? I have no possibility
> to check this, since I do not have access to a Mac with R installed. On my
> windows machine, 
> all(log2(x)==floor(log2(x))) 
> with x as defined above yields TRUE.

Christophe Dutang tested this on Mac with the result
  >  x <- 2^(0:100 + 0)
  >  all(x == floor(x))
  [1] TRUE
  >  all(log2(x) == floor(log2(x)))
  [1] TRUE
  > x
    [1] 1.000000e+00 2.000000e+00 4.000000e+00 8.000000e+00 1.600000e+01
    [6] 3.200000e+01 6.400000e+01 1.280000e+02 2.560000e+02 5.120000e+02
   [11] 1.024000e+03 2.048000e+03 4.096000e+03 8.192000e+03 1.638400e+04
   [16] 3.276800e+04 6.553600e+04 1.310720e+05 2.621440e+05 5.242880e+05
   [21] 1.048576e+06 2.097152e+06 4.194304e+06 8.388608e+06 1.677722e+07
   [26] 3.355443e+07 6.710886e+07 1.342177e+08 2.684355e+08 5.368709e+08
   [31] 1.073742e+09 2.147484e+09 4.294967e+09 8.589935e+09 1.717987e+10
   ...

Without an analysis of the error directly on Mac, it is hard to guess, what
is the problem. What could also be tested is, whether the input nruns is an
integer or not. Either strictly, 
  if (nruns != floor(nruns)) stop("nruns not an integer")
or with some tolerance
  nruns0 <- nruns
  nruns <- round(nruns)
  if (!isTRUE(all.equal(nruns, nruns0))) stop("nruns not an integer")

Petr.


From zwerdlds at gmail.com  Wed Mar 25 07:44:53 2009
From: zwerdlds at gmail.com (David Zwerdling)
Date: Tue, 24 Mar 2009 23:44:53 -0700
Subject: [Rd] More Embedding REngine in Cocoa
Message-ID: <BB1B7916-01CB-4BE5-8EC8-14D42185B603@gmail.com>

Hello once again,
After locating the standalone REngine object set, I am having  
difficulty integrating them into the XCode project I intend to use  
them in.

Suppose one started with the REngine standalone source and a blank  
XCode file, what special modifications need to be made to allow the  
source files to see inside R.framework?  Importing the framework into  
the project, setting the header and framework search paths hasn't done  
anything for me yet.  The files are complaining about the R.h file not  
existing.  Using the R.app as a reference, I was unable to find  
specifically how it adds the R/ directory visibility to the  
application headers at link or compile time.

I was able to compile and run the test file inside the REngine  
standalone.  However, I don't know how to initiate my application in  
XCode using the R CMD command.  What impacts will this have to the  
existing program?  Finally, I was also unable to find any sort of  
implementation of this in RGui.  Is this even necessary from XCode?

I hope this is enough detail.  Thanks in advance.
David Zwerdling
zwerdlds at gmail.com


From groemp at tfh-berlin.de  Wed Mar 25 07:50:01 2009
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Tue, 24 Mar 2009 23:50:01 -0700 (PDT)
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <20090325062731.GA29613@cs.cas.cz>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
	<20090324141728.GC4963@cs.cas.cz> <22681913.post@talk.nabble.com>
	<20090325062731.GA29613@cs.cas.cz>
Message-ID: <22696051.post@talk.nabble.com>




Petr Savicky wrote:
> 
> On Tue, Mar 24, 2009 at 07:41:31AM -0700, Ulrike Gr?mping wrote:
>> > Probably, k is needed also later. Assumig that 2^k works correctly,
>> > the following could be sufficient
>> > 
>> >    if (!is.null(nruns)){
>> >       k <- round(log2(nruns))
>> >       if (!2^k==nruns) stop("nruns must be a power of 2.")}
>> > 
>> > In order to test the assumption, one can use
>> > 
>> >   x <- 2^(0:100 + 0) # use double exponent to be sure
>> >   all(x == floor(x))
>> > 
>> > Powers of two are represented exactly, since they have only one
>> > significant bit.
>> > 
>> > Petr.
>> > 
>> 
>> Yes, round instead of floor should also do the job, if rounding is the
>> issue. But then, with powers of 2 indeed being represented exactly (I
>> would
>> expect even on Macs), maybe rounding is not the issue? I have no
>> possibility
>> to check this, since I do not have access to a Mac with R installed. On
>> my
>> windows machine, 
>> all(log2(x)==floor(log2(x))) 
>> with x as defined above yields TRUE.
> 
> Christophe Dutang tested this on Mac with the result
>   >  x <- 2^(0:100 + 0)
>   >  all(x == floor(x))
>   [1] TRUE
>   >  all(log2(x) == floor(log2(x)))
>   [1] TRUE
>   > x
>     [1] 1.000000e+00 2.000000e+00 4.000000e+00 8.000000e+00 1.600000e+01
>     [6] 3.200000e+01 6.400000e+01 1.280000e+02 2.560000e+02 5.120000e+02
>    [11] 1.024000e+03 2.048000e+03 4.096000e+03 8.192000e+03 1.638400e+04
>    [16] 3.276800e+04 6.553600e+04 1.310720e+05 2.621440e+05 5.242880e+05
>    [21] 1.048576e+06 2.097152e+06 4.194304e+06 8.388608e+06 1.677722e+07
>    [26] 3.355443e+07 6.710886e+07 1.342177e+08 2.684355e+08 5.368709e+08
>    [31] 1.073742e+09 2.147484e+09 4.294967e+09 8.589935e+09 1.717987e+10
>    ...
> 
> Without an analysis of the error directly on Mac, it is hard to guess,
> what
> is the problem. What could also be tested is, whether the input nruns is
> an
> integer or not. Either strictly, 
>   if (nruns != floor(nruns)) stop("nruns not an integer")
> or with some tolerance
>   nruns0 <- nruns
>   nruns <- round(nruns)
>   if (!isTRUE(all.equal(nruns, nruns0))) stop("nruns not an integer")
> 
> Petr.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

Thanks for this test report, sounds as though rounding may not be the issue
here. I've uploaded the version with round instead of floor anyway, together
with a few more bug fixes, and I'll see what happens with the Mac checks on
CRAN. With Mac users being a minority, I'm not willing to complicate things
for other platforms in order to accomodate Mac fixes that I can't even check
myself. But I don't think that this can be all that complicated. If rounding
is not the root cause, someone will certainly come up with another idea.
I'll report back, whether the rounding error approach solved the problem.

Regards, Ulrike 

-- 
View this message in context: http://www.nabble.com/Error-in-FrF2-example-on-Mac-OS-tp22675998p22696051.html
Sent from the R devel mailing list archive at Nabble.com.


From krcabrer at une.net.co  Wed Mar 25 04:10:29 2009
From: krcabrer at une.net.co (Kenneth Roy Cabrera Torres)
Date: Tue, 24 Mar 2009 22:10:29 -0500
Subject: [Rd] Is aggregate() function changing?
In-Reply-To: <49C8BEF0.9030805@stats.uwo.ca>
References: <1237869849.2652.17.camel@localhost>
	<49C8BEF0.9030805@stats.uwo.ca>
Message-ID: <1237950629.2652.25.camel@localhost>

Thank your Dr. Duncan Murdoch:

Yes, you are right! 
I look for a "mean" variable and there it was!!!
It seems to work on the non-patched 2.8.1 version because
I start a new session on a diferent directory, and with
the patched 2.8.1 I use an already created .Rdata where
a "mean" variable exist with a 0 value.

Thank you very much for your help.

Sorry for this silly questions.

Kenneth

El mar, 24-03-2009 a las 07:07 -0400, Duncan Murdoch escribi?:
> On 24/03/2009 12:44 AM, Kenneth Roy Cabrera Torres wrote:
> > Hi R developers and debian users:
> > 
> > Finally I found how to work with aggregate() function
> > on the last patched version fo R.
> > 
> > I you use this command it fails:
> >   
> >  aggregate(state.x77, list(Region = state.region), mean)
> > 
> > But if you modify it in this way, it works!:
> > 
> >  aggregate(state.x77, list(Region = state.region), function(x) mean(x) )
> > 
> > Is it necesary to change the example?
> > 
> > What is changing in aggregate() function?
> 
> I get identical results from those, but if I had a local variable (not a 
> function) named "mean", the first one would not work:
> 
>  > mean <- 2
>  > aggregate(state.x77, list(Region = state.region), mean)
> Error in FUN(X[[1L]], ...) : element 1 is empty;
>     the part of the args list of 'is.list' being evaluated was:
>     (INDEX)
> 
> I suspect that is what is going wrong for you.
> 
> Duncan Murdoch
> 
> 
> > 
> > Thank you for your attention.
> > 
> > Kenneth.
> >> sessionInfo()
> > 
> > R version 2.8.1 Patched (2009-03-18 r48193) 
> > x86_64-unknown-linux-gnu 
> > 
> > locale:
> > LC_CTYPE=es_CO.UTF-8;LC_NUMERIC=C;LC_TIME=es_CO.UTF-8;LC_COLLATE=es_CO.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_CO.UTF-8;LC_PAPER=es_CO.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_CO.UTF-8;LC_IDENTIFICATION=C
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Wed Mar 25 15:16:08 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 25 Mar 2009 10:16:08 -0400
Subject: [Rd] More Embedding REngine in Cocoa
In-Reply-To: <BB1B7916-01CB-4BE5-8EC8-14D42185B603@gmail.com>
References: <BB1B7916-01CB-4BE5-8EC8-14D42185B603@gmail.com>
Message-ID: <C784F79E-2BE3-4441-A69A-AC15968BAB31@r-project.org>

DAvid,

On Mar 25, 2009, at 2:44 , David Zwerdling wrote:

> Hello once again,
> After locating the standalone REngine object set, I am having  
> difficulty integrating them into the XCode project I intend to use  
> them in.
>
> Suppose one started with the REngine standalone source and a blank  
> XCode file, what special modifications need to be made to allow the  
> source files to see inside R.framework?  Importing the framework  
> into the project, setting the header and framework search paths  
> hasn't done anything for me yet.

You only need to set the header path to include Headers and  
PrivateHeaders of the R.framework - everything else follows  
automatically from adding the R.framework to the project.

 From R.xcodeproj:
HEADER_SEARCH_PATHS = (
	/Library/Frameworks/R.framework/Headers,
         /Library/Frameworks/R.framework/PrivateHeaders,
);

That's all.


>  The files are complaining about the R.h file not existing.  Using  
> the R.app as a reference, I was unable to find specifically how it  
> adds the R/ directory visibility to the application headers at link  
> or compile time.
>

See above.


> I was able to compile and run the test file inside the REngine  
> standalone.  However, I don't know how to initiate my application in  
> XCode using the R CMD command.  What impacts will this have to the  
> existing program?

Essentially R CMD sets up the environment for R automatically. If you  
have a stand-alone application and you cannot (or don't want to) use R  
CMD then have a look at the R.app GUI - it creates the environment  
itself in RController.m l.306-373 (current SVN r5376). The following  
code (l.375-420) then sets up the locale - it may be a bit more  
complicated than what you need, but you just have to ensure you're  
running in a UTF-8 locale. [Note:


>  Finally, I was also unable to find any sort of implementation of  
> this in RGui.  Is this even necessary from XCode?
>

See above.

Cheers,
Simon



> I hope this is enough detail.  Thanks in advance.
> David Zwerdling
> zwerdlds at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Wed Mar 25 15:32:59 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 25 Mar 2009 10:32:59 -0400
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <22681913.post@talk.nabble.com>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
	<20090324141728.GC4963@cs.cas.cz> <22681913.post@talk.nabble.com>
Message-ID: <AF49CB02-992F-4EE9-A763-534191EA5D72@r-project.org>


On Mar 24, 2009, at 10:41 , Ulrike Gr?mping wrote:

>
>
> Petr Savicky wrote:
>>
>> On Tue, Mar 24, 2009 at 02:45:57PM +0100, Uwe Ligges wrote:
>>>> gives the custom error message "nruns must be a power of 2.",  
>>>> which is
>>>> generated in the first check within function FrF2:
>>>>
>>>>   if (!is.null(nruns)){
>>>>      k <- floor(log2(nruns))
>>>>      if (!2^k==nruns) stop("nruns must be a power of 2.")}
>>>
>>>
>>> Probably a rounding issue on different platforms?
>>> I guess the test should be something like:
>>>
>>> if (!is.null(nruns)){
>>>  if(!isTRUE(all.equal(log2(nruns) %% 1, 0)))
>>>    stop("nruns must be a power of 2.")
>>> }
>>
>> Probably, k is needed also later. Assumig that 2^k works correctly,
>> the following could be sufficient
>>
>>   if (!is.null(nruns)){
>>      k <- round(log2(nruns))
>>      if (!2^k==nruns) stop("nruns must be a power of 2.")}
>>
>> In order to test the assumption, one can use
>>
>>  x <- 2^(0:100 + 0) # use double exponent to be sure
>>  all(x == floor(x))
>>
>> Powers of two are represented exactly, since they have only one
>> significant bit.
>>
>> Petr.
>>
>
> Yes, round instead of floor should also do the job, if rounding is the
> issue. But then, with powers of 2 indeed being represented exactly  
> (I would
> expect even on Macs), maybe rounding is not the issue? I have no  
> possibility
> to check this, since I do not have access to a Mac with R installed.  
> On my
> windows machine,
> all(log2(x)==floor(log2(x)))
> with x as defined above yields TRUE.
>

What you're missing is that you cannot rely on log2 to give you an  
integer. The test above bears no relevance to your problem - this is  
not about representing 2^x - this is about log2 which you cannot  
expect to satisfy log2(2^b) == b numerically since it could as well be  
computed log(x)/log(2) which is not exactly representable. Use round  
and all is well :).

 > which(floor(log2(2^x))!=x)
  [1]  4  7  8 13 14 15 25 27 29 49 53 57 64 97
 > which(round(log2(2^x))!=x)
integer(0)

Cheers,
Simon

>
> View this message in context: http://www.nabble.com/Error-in-FrF2-example-on-Mac-OS-tp22675998p22681913.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From audrey at ebi.ac.uk  Wed Mar 25 16:42:50 2009
From: audrey at ebi.ac.uk (audrey at ebi.ac.uk)
Date: Wed, 25 Mar 2009 15:42:50 -0000 (GMT)
Subject: [Rd] no internal function "int.unzip" in R 2.9 on Windows
In-Reply-To: <49B6BB51.9090106@fhcrc.org>
References: <49B6BB51.9090106@fhcrc.org>
Message-ID: <47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>

Dear list,

Using R 2.9, I have the following error on Windows when I try using
.Internal(int.unzip(...)):

> .Internal(int.unzip("test.zip",NULL, "."))
Error in .Internal(int.unzip("test.zip", NULL, ".")) :
  no internal function "int.unzip"

The same error also happens with R 2.10 but not on R 2.8. And it does not
happen with R 2.9 on Mac or Unix.
I have googled the error message but cannot find much.

Does anyone know if the way R calls unzip functions on Windows has changed
and if this is permanent?
I am sorry if I miss something obvious, but any suggestions on how I can
fix the problem?
I want to keep using int.unzip and not the utils function unzip because I
use its output afterwards in my script.

Best wishes,
Audrey


From murdoch at stats.uwo.ca  Wed Mar 25 16:56:17 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 25 Mar 2009 11:56:17 -0400
Subject: [Rd] no internal function "int.unzip" in R 2.9 on Windows
In-Reply-To: <47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>
References: <49B6BB51.9090106@fhcrc.org>
	<47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>
Message-ID: <49CA5421.2070709@stats.uwo.ca>

On 3/25/2009 11:42 AM, audrey at ebi.ac.uk wrote:
> Dear list,
> 
> Using R 2.9, I have the following error on Windows when I try using
> .Internal(int.unzip(...)):
> 
>> .Internal(int.unzip("test.zip",NULL, "."))
> Error in .Internal(int.unzip("test.zip", NULL, ".")) :
>   no internal function "int.unzip"
> 
> The same error also happens with R 2.10 but not on R 2.8. And it does not
> happen with R 2.9 on Mac or Unix.
> I have googled the error message but cannot find much.
> 
> Does anyone know if the way R calls unzip functions on Windows has changed
> and if this is permanent?
> I am sorry if I miss something obvious, but any suggestions on how I can
> fix the problem?
> I want to keep using int.unzip and not the utils function unzip because I
> use its output afterwards in my script.

Generally internal things that aren't documented as part of the API are 
subject to change without notice.  Rather than relying on the way 
certain functions happen to work in certain versions, if you find that 
one of the documented functions doesn't do what you want, you should 
point out the problem with it and submit a patch.

You can see how the unzip function in the utils package works by looking 
at the source, or just printing it in the console.  It doesn't refer to 
int.unzip, but I wouldn't count on its current behaviour being 
"permanent":  it's undocumented internal implementation, which you use 
at your own risk.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Wed Mar 25 17:01:56 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Mar 2009 17:01:56 +0100
Subject: [Rd] no internal function "int.unzip" in R 2.9 on Windows
In-Reply-To: <47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>
References: <49B6BB51.9090106@fhcrc.org>
	<47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>
Message-ID: <49CA5574.7070906@statistik.tu-dortmund.de>



audrey at ebi.ac.uk wrote:
> Dear list,
> 
> Using R 2.9, I have the following error on Windows when I try using
> .Internal(int.unzip(...)):
> 
>> .Internal(int.unzip("test.zip",NULL, "."))
> Error in .Internal(int.unzip("test.zip", NULL, ".")) :
>   no internal function "int.unzip"
> 
> The same error also happens with R 2.10 but not on R 2.8. And it does not
> happen with R 2.9 on Mac or Unix.
> I have googled the error message but cannot find much.
> 
> Does anyone know if the way R calls unzip functions on Windows has changed
> and if this is permanent?

Indeed, there was a change and int.unzip was never documented as part of 
the API. It was intended to work "Internal"ly.

You can use the unzip() function in package utils now, see the NEWS file.

Best,
Uwe Ligges





> I am sorry if I miss something obvious, but any suggestions on how I can
> fix the problem?
> I want to keep using int.unzip and not the utils function unzip because I
> use its output afterwards in my script.
> 
> Best wishes,
> Audrey
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From audrey at ebi.ac.uk  Wed Mar 25 17:06:18 2009
From: audrey at ebi.ac.uk (audrey at ebi.ac.uk)
Date: Wed, 25 Mar 2009 16:06:18 -0000 (GMT)
Subject: [Rd] no internal function "int.unzip" in R 2.9 on Windows
In-Reply-To: <49CA5421.2070709@stats.uwo.ca>
References: <49B6BB51.9090106@fhcrc.org>
	<47603.86.9.125.71.1237995770.squirrel@webmail.ebi.ac.uk>
	<49CA5421.2070709@stats.uwo.ca>
Message-ID: <57479.86.9.125.71.1237997178.squirrel@webmail.ebi.ac.uk>

Dear Duncan and Uwe,

Thank you for your prompt answers. I will have a look at the unzip
function and try to modify it to make it producing the output I want.

Cheers,
Audrey


> On 3/25/2009 11:42 AM, audrey at ebi.ac.uk wrote:
>> Dear list,
>>
>> Using R 2.9, I have the following error on Windows when I try using
>> .Internal(int.unzip(...)):
>>
>>> .Internal(int.unzip("test.zip",NULL, "."))
>> Error in .Internal(int.unzip("test.zip", NULL, ".")) :
>>   no internal function "int.unzip"
>>
>> The same error also happens with R 2.10 but not on R 2.8. And it does
>> not
>> happen with R 2.9 on Mac or Unix.
>> I have googled the error message but cannot find much.
>>
>> Does anyone know if the way R calls unzip functions on Windows has
>> changed
>> and if this is permanent?
>> I am sorry if I miss something obvious, but any suggestions on how I can
>> fix the problem?
>> I want to keep using int.unzip and not the utils function unzip because
>> I
>> use its output afterwards in my script.
>
> Generally internal things that aren't documented as part of the API are
> subject to change without notice.  Rather than relying on the way
> certain functions happen to work in certain versions, if you find that
> one of the documented functions doesn't do what you want, you should
> point out the problem with it and submit a patch.
>
> You can see how the unzip function in the utils package works by looking
> at the source, or just printing it in the console.  It doesn't refer to
> int.unzip, but I wouldn't count on its current behaviour being
> "permanent":  it's undocumented internal implementation, which you use
> at your own risk.
>
> Duncan Murdoch
>


From s.wood at bath.ac.uk  Wed Mar 25 18:10:10 2009
From: s.wood at bath.ac.uk (s.wood at bath.ac.uk)
Date: Wed, 25 Mar 2009 18:10:10 +0100 (CET)
Subject: [Rd] get_all_vars fails with matrices (PR#13624)
Message-ID: <20090325171010.619532834149@mail.pubhealth.ku.dk>

Hi,

According to the help file for model.frame/get_all_vars, the following should 
produce the same output from both functions, but it doesn't...

> dat <- list(X=matrix(1:15,5,3),z=26:30)
> model.frame(~z+X,dat)
   z X.1 X.2 X.3
1 26   1   6  11
2 27   2   7  12
3 28   3   8  13
4 29   4   9  14
5 30   5  10  15
> get_all_vars(~z+X,dat)
[1] z    X    <NA> <NA>
<0 rows> (or 0-length row.names)
>                              
-- the equivalent works ok if there are no matrices involved. 

I'm using  R version 2.9.0 alpha (2009-03-24 r48212) (Suse linux 10 and 11, 64 
bit intel). I found the problem while trying to fix a problem in an mgcv 
plotting routine.

best,
Simon
-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From Joerg.Betzin at dza.de  Wed Mar 25 16:47:00 2009
From: Joerg.Betzin at dza.de (Joerg Betzin)
Date: Wed, 25 Mar 2009 16:47:00 +0100
Subject: [Rd] linking environments
Message-ID: <OF2D459B18.6AF836C2-ONC1257584.0055D84D-C1257584.0056C217@dza.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090325/5e5cbb41/attachment.pl>

From odoehring at googlemail.com  Wed Mar 25 14:29:56 2009
From: odoehring at googlemail.com (=?ISO-8859-1?Q?Orlando_D=F6hring?=)
Date: Wed, 25 Mar 2009 13:29:56 +0000
Subject: [Rd] Listing of LAPACK error codes
Message-ID: <d3c1ff960903250629t7fcc5befn48f2bd25b2f54846@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090325/f7a198ea/attachment.pl>

From murdoch at stats.uwo.ca  Wed Mar 25 19:41:00 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 25 Mar 2009 14:41:00 -0400
Subject: [Rd] linking environments
In-Reply-To: <OF2D459B18.6AF836C2-ONC1257584.0055D84D-C1257584.0056C217@dza.de>
References: <OF2D459B18.6AF836C2-ONC1257584.0055D84D-C1257584.0056C217@dza.de>
Message-ID: <49CA7ABC.3080307@stats.uwo.ca>

On 3/25/2009 11:47 AM, Joerg Betzin wrote:
> Dear R-helpers,
> 
> I try to use nested R-functions as follows:

You didn't use nested functions.  They would look like this:

  help1 <- function(){
      help2 <- function(){
          if (x == 1)
                  cat("Hello world x = 1")
      }

      x <- 1
      help2()
  }

Because help2 is now nested within help1, it can see all the local 
variables in help1, so things work with it done this way.

There are tricks to define help2 outside of help1 but allow it to see 
the variables within there, but I'd keep it simple and avoid them.

Duncan Murdoch

> 
> help1 = function(){
>         x = 1
>         help2()
> }
> 
> with
> 
> help2 = function(){
>         if (x == 1)
>                 cat("Hello world x = 1")
> }
> 
> If I compile these functions and run help1()
> an error message occurs
>         Fehler in help2() : objekt "x" nicht gefunden
> 
> in english "error in help2(): object "x" not found"
> 
> If I change help1 to
> 
> help1 = function(){
>         x <<- 1
>         help2()
> }
> 
> so that "x" is now defined at the global environment it works fine.
> But the problem is, now "x" is defined also outside of help1 and this is 
> not desired !
> 
> Is there any usable solution for this problem?
> But, the original problem is to assign new values for "x" in help1 inside 
> help2 !
> 
> Thanks in advance
>  
> J?rg Betzin
> ---------------------------------------------------
> Deutsches Zentrum f?r Altersfragen
> Manfred-von-Richthofen-Str. 2
> 12101 Berlin
> Tel. (030) 260740-20
> E-Mail: joerg.betzin at dza.de
> URL: http://www.dza.de
> ---------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From smckinney at bccrc.ca  Wed Mar 25 19:48:03 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 25 Mar 2009 11:48:03 -0700
Subject: [Rd] linking environments
References: <26782_1238005950_1238005950_OF2D459B18.6AF836C2-ONC1257584.0055D84D-C1257584.0056C217@dza.de>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB0328A66F@crcmail1.BCCRC.CA>


> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org on behalf of Joerg Betzin
> Sent: Wed 3/25/2009 8:47 AM
> To: r-devel at r-project.org
> Subject: [Rd] linking environments
>  
> Dear R-helpers,
> 
> I try to use nested R-functions as follows:


Looks like a question for R-help, not R-devel.
It's better to post such questions to the
R-help at r-project.org mailing list.


> 
> help1 = function(){
>         x = 1
>         help2()
> }
> 
> with
> 
> help2 = function(){
>         if (x == 1)
>                 cat("Hello world x = 1")
> }
> 
> If I compile these functions and run help1()
> an error message occurs
>         Fehler in help2() : objekt "x" nicht gefunden
> 
> in english "error in help2(): object "x" not found"
> 

Why not pass the value of x from help1
to help2?

help1 <- function(){
        x <- 1
        help2(x)
}



help2 <- function(x){
        if (x == 1)
                cat("Hello world x = 1")
}




> help1 <- function(){
+         x <- 1
+         help2(x)
+ }
> 
> 
> 
> help2 <- function(x){
+         if (x == 1)
+                 cat("Hello world x = 1")
+ }
> 
> 
> 
> help1()
Hello world x = 1> 



(No compiling is involved.)

> If I change help1 to
> 
> help1 = function(){
>         x <<- 1
>         help2()
> }
> 
> so that "x" is now defined at the global environment it works fine.
> But the problem is, now "x" is defined also outside of help1 and this is 
> not desired !
> 
> Is there any usable solution for this problem?
> But, the original problem is to assign new values for "x" in help1 inside 
> help2 !

Is this a homework problem?

Some reading of 
?environment
will help answer this.

> 
> Thanks in advance
>  
> J?rg Betzin
> ---------------------------------------------------
> Deutsches Zentrum f?r Altersfragen
> Manfred-von-Richthofen-Str. 2
> 12101 Berlin
> Tel. (030) 260740-20
> E-Mail: joerg.betzin at dza.de
> URL: http://www.dza.de
> ---------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 



Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C. 
V5Z 1L3
Canada


From p.dalgaard at biostat.ku.dk  Wed Mar 25 19:54:38 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 25 Mar 2009 19:54:38 +0100
Subject: [Rd] get_all_vars fails with matrices (PR#13624)
In-Reply-To: <20090325171010.619532834149@mail.pubhealth.ku.dk>
References: <20090325171010.619532834149@mail.pubhealth.ku.dk>
Message-ID: <49CA7DEE.50402@biostat.ku.dk>

s.wood at bath.ac.uk wrote:
> Hi,
> 
> According to the help file for model.frame/get_all_vars, the following should 
> produce the same output from both functions, but it doesn't...
> 
>> dat <- list(X=matrix(1:15,5,3),z=26:30)
>> model.frame(~z+X,dat)
>    z X.1 X.2 X.3
> 1 26   1   6  11
> 2 27   2   7  12
> 3 28   3   8  13
> 4 29   4   9  14
> 5 30   5  10  15
>> get_all_vars(~z+X,dat)
> [1] z    X    <NA> <NA>
> <0 rows> (or 0-length row.names)
>>                              
> -- the equivalent works ok if there are no matrices involved. 
> 
> I'm using  R version 2.9.0 alpha (2009-03-24 r48212) (Suse linux 10 and 11, 64 
> bit intel). I found the problem while trying to fix a problem in an mgcv 
> plotting routine.
> 
> best,
> Simon

This works, though:

 > dat <- data.frame(X=I(matrix(1:15,5,3)),z=26:30)
 > get_all_vars(~z+X,dat)
    z X.1 X.2 X.3
1 26   1   6  11
2 27   2   7  12
3 28   3   8  13
4 29   4   9  14
5 30   5  10  15

but there is something special with lists:

 > dat <- as.data.frame(list(X=I(matrix(1:15,5,3)),z=26:30))
 > get_all_vars(~z+X,dat)
    z X.1 X.2 X.3
1 26   1   6  11
2 27   2   7  12
3 28   3   8  13
4 29   4   9  14
5 30   5  10  15
 > dat <- data.frame(list(X=I(matrix(1:15,5,3)),z=26:30))
 > get_all_vars(~z+X,dat)
    z X.1 X.2 X.3
1 26   1   6  11
2 27   2   7  12
3 28   3   8  13
4 29   4   9  14
5 30   5  10  15
 > dat <- list(X=I(matrix(1:15,5,3)),z=26:30)
 > get_all_vars(~z+X,dat)
[1] z X
<0 rows> (or 0-length row.names)
 >


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From jason at acm.org  Wed Mar 25 20:07:21 2009
From: jason at acm.org (Jason Riedy)
Date: Wed, 25 Mar 2009 15:07:21 -0400
Subject: [Rd] Listing of LAPACK error codes
In-Reply-To: <d3c1ff960903250629t7fcc5befn48f2bd25b2f54846@mail.gmail.com>
	("Orlando =?utf-8?Q?D=C3=B6hring=22's?= message of "Wed, 25 Mar 2009
	13:29:56 +0000")
References: <d3c1ff960903250629t7fcc5befn48f2bd25b2f54846@mail.gmail.com>
Message-ID: <87eiwl1kwm.fsf@sparse.dyndns.org>

And Orlando D?hring writes:
> Is there a listing for the error codes from Lapack routine 'dsyevr'?

The HTML-ized LAPACK functions are at http://www.netlib.org/lapack/explore-html/
although they may lag behind releases a little bit.  The page for
dsyevr.f is:
  http://www.netlib.org/lapack/explore-html/dsyevr.f.html

And the LAPACK mailing list is at lapack at cs.utk.edu, although as
with all such projects, responses may be a *long* time in coming.

> Especially I am interested about the meaning and handling of error codes 1
> and 2.

The high-level drivers like DSYEVR dispatch to different internal
routines depending on what was requested.  That makes documenting the
error codes a little painful...

For some of the routines involved, INFO.eq.1 or 2 implies 1 or 2
entries didn't converge, either when reducing a tridiagonal to
diagonal, in bisection, or in inverse iteration.  For another, but
only if you're requesting the ilo-th through ihi-th eigenvalues, 2
would imply non-monotonic arithmetic, and I would be *very*
surprised.

So likely something somewhere didn't converge.  Picking parameters
that *always* converge for eigenvalues is an open problem.

Have you tried this on different platforms, or with different BLAS?
Can you release the data that causes the problem?

Jason


From ripley at stats.ox.ac.uk  Wed Mar 25 20:08:35 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Mar 2009 19:08:35 +0000 (GMT)
Subject: [Rd] Listing of LAPACK error codes
In-Reply-To: <d3c1ff960903250629t7fcc5befn48f2bd25b2f54846@mail.gmail.com>
References: <d3c1ff960903250629t7fcc5befn48f2bd25b2f54846@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0903251905500.15405@gannet.stats.ox.ac.uk>

On Wed, 25 Mar 2009, Orlando D?hring wrote:

> Professor Ripley commented on LAPACK error codes:
> https://stat.ethz.ch/pipermail/r-help/2007-March/127702.html and says
> "Internal LAPACK errors are usually problems with arithmetic accuracy,
> and as such are compiler- and CPU-specific."
>
> Is there a listing for the error codes from Lapack routine 'dsyevr'?
> Especially I am interested about the meaning and handling of error codes 1
> and 2. In Lapack.c I only see the reference to the variable info in certain
> Fortran code:

I read the LAPACK sources: I know of no other documentation.  (You 
seem to have missed the sources, which are part of R.)

>    F77_CALL(dsyevr)(jobv, range, uplo, &n, rx, &n, &vl, &vu, &il, &iu,
> &abstol, &m, rvalues, rz, &n, isuppz, &tmp, &lwork, &itmp, &liwork, &info);
>    if (info != 0)
>        error(_("error code %d from Lapack routine '%s'"), info, "dsyevr");
>    lwork = (int) tmp;
>    liwork = itmp;
>
>    work = (double *) R_alloc(lwork, sizeof(double));
>    iwork = (int *) R_alloc(liwork, sizeof(int));
>    F77_CALL(dsyevr)(jobv, range, uplo, &n, rx, &n, &vl, &vu, &il, &iu,
> &abstol, &m, rvalues, rz, &n, isuppz, work, &lwork, iwork, &liwork, &info);
>    if (info != 0)
>        error(_("error code %d from Lapack routine '%s'"), info, "dsyevr");
>
> 	[[alternative HTML version deleted]]

Overdue to read the posting guide ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From groemping at tfh-berlin.de  Thu Mar 26 00:09:19 2009
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Thu, 26 Mar 2009 00:09:19 +0100
Subject: [Rd] Error in FrF2 example on Mac OS
In-Reply-To: <AF49CB02-992F-4EE9-A763-534191EA5D72@r-project.org>
References: <22675998.post@talk.nabble.com>
	<49C8E415.3060702@statistik.tu-dortmund.de>
	<20090324141728.GC4963@cs.cas.cz> <22681913.post@talk.nabble.com>
	<AF49CB02-992F-4EE9-A763-534191EA5D72@r-project.org>
Message-ID: <20090325230712.M2675@tfh-berlin.de>

---------- Original Message ----------- 
 From: Simon Urbanek <simon.urbanek at r-project.org> 
 To: Ulrike Gr?mping <groemp at tfh-berlin.de> 
 Cc: r-devel at r-project.org 
 Sent: Wed, 25 Mar 2009 10:32:59 -0400 
 Subject: Re: [Rd] Error in FrF2 example on Mac OS

> On Mar 24, 2009, at 10:41 , Ulrike Gr?mping wrote: 
> 
> > 
> > 
> > Petr Savicky wrote: 
> >> 
> >> On Tue, Mar 24, 2009 at 02:45:57PM +0100, Uwe Ligges wrote: 
> >>>> gives the custom error message "nruns must be a power of 2.", ? 
> >>>> which is 
> >>>> generated in the first check within function FrF2: 
> >>>> 
> >>>> ? if (!is.null(nruns)){ 
> >>>> ? ? ?k <- floor(log2(nruns)) 
> >>>> ? ? ?if (!2^k==nruns) stop("nruns must be a power of 2.")} 
> >>> 
> >>> 
> >>> Probably a rounding issue on different platforms? 
> >>> I guess the test should be something like: 
> >>> 
> >>> if (!is.null(nruns)){ 
> >>> ?if(!isTRUE(all.equal(log2(nruns) %% 1, 0))) 
> >>> ? ?stop("nruns must be a power of 2.") 
> >>> } 
> >> 
> >> Probably, k is needed also later. Assumig that 2^k works correctly, 
> >> the following could be sufficient 
> >> 
> >> ? if (!is.null(nruns)){ 
> >> ? ? ?k <- round(log2(nruns)) 
> >> ? ? ?if (!2^k==nruns) stop("nruns must be a power of 2.")} 
> >> 
> >> In order to test the assumption, one can use 
> >> 
> >> ?x <- 2^(0:100 + 0) # use double exponent to be sure 
> >> ?all(x == floor(x)) 
> >> 
> >> Powers of two are represented exactly, since they have only one 
> >> significant bit. 
> >> 
> >> Petr. 
> >> 
> > 
> > Yes, round instead of floor should also do the job, if rounding is the 
> > issue. But then, with powers of 2 indeed being represented exactly ? 
> > (I would 
> > expect even on Macs), maybe rounding is not the issue? I have no ? 
> > possibility 
> > to check this, since I do not have access to a Mac with R installed. ? 
> > On my 
> > windows machine, 
> > all(log2(x)==floor(log2(x))) 
> > with x as defined above yields TRUE. 
> > 
> 
> What you're missing is that you cannot rely on log2 to give you an ? 
> integer. The test above bears no relevance to your problem - this is ? 
> not about representing 2^x - this is about log2 which you cannot ? 
> expect to satisfy log2(2^b) == b numerically since it could as well be ? 
> computed log(x)/log(2) which is not exactly representable. Use round ? 
> and all is well :). 
> 
> > which(floor(log2(2^x))!=x) 
> ?[1] ?4 ?7 ?8 13 14 15 25 27 29 49 53 57 64 97 
> > which(round(log2(2^x))!=x) 
> integer(0) 
> 
> Cheers, 
> Simon 
> 

Yes, round did indeed solve the problem, it just surprises me that the Mac is
so different from the other (binary) animals.

Regards,
Ulrike


From romain.francois at dbmail.com  Thu Mar 26 11:42:14 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 26 Mar 2009 11:42:14 +0100
Subject: [Rd] [R] "[.data.frame" and lapply
In-Reply-To: <74B0C31F-6950-41A8-BF20-460479750DA0@exeter.ac.uk>
References: <0935362A-34E7-4711-B2F4-8FB72108950B@exeter.ac.uk>
	<49CB32C0.1010500@dbmail.com>
	<74B0C31F-6950-41A8-BF20-460479750DA0@exeter.ac.uk>
Message-ID: <49CB5C06.8080603@dbmail.com>

[moving this from R-help to R-devel]

Hi,

Right, so when you call `[`, the dispatch is made internally :

 > d <- data.frame( x = 1:5, y = rnorm(5), z = rnorm(5) )
 > trace( `[.data.frame` )
 > d[ , 1:2]   # ensuring the 1:2 is passed to j and the i is passed as 
missing
Tracing `[.data.frame`(d, , 1:2) on entry
  x           y
1 1  0.98946922
2 2  0.05323895
3 3 -0.21803664
4 4 -0.47607043
5 5  1.23366151

 > d[ 1:2] # only on argument, so it goes in i
Tracing `[.data.frame`(d, 1:2) on entry
  x           y
1 1  0.98946922
2 2  0.05323895
3 3 -0.21803664
4 4 -0.47607043
5 5  1.23366151

But that does not explain why this is hapening:

 > d[ i = 1:2]
Tracing `[.data.frame`(d, i = 1:2) on entry
  x           y
1 1  0.98946922
2 2  0.05323895
3 3 -0.21803664
4 4 -0.47607043
5 5  1.23366151

 > d[ j = 1:2]
Tracing `[.data.frame`(d, j = 1:2) on entry
  x           y          z
1 1  0.98946922 -0.5233134
2 2  0.05323895  1.3646683
3 3 -0.21803664 -0.4998344
4 4 -0.47607043 -1.8849618
5 5  1.23366151  0.6723562

Arguments are dispatched to `[.data.frame` with their names, and 
`[.data.frame` gets confused. I'm not suggesting allowing named 
arguments because it already works, what does not work is how 
`[.data.frame` treats them, and that needs to be changed, this is a bug.

Romain

 > version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          9.0
year           2009
month          03
day            09
svn rev        48093
language       R
version.string R version 2.9.0 Under development (unstable) (2009-03-09 
r48093)




baptiste auguie wrote:
> Hi,
>
> I got an off-line clarification from Martin Morgan which makes me 
> believe it's not a bug (admittedly, I was close to suggesting it before).
>
> Basically, "[" is a .Primitive, for which the help page says,
>
>
>> The advantage of |.Primitive| over |.Internal 
>> <file:///Library/Frameworks/R.framework/Resources/library/base/html/Internal.html>| functions 
>> is the potential efficiency of argument passing. However, this is 
>> done by ignoring argument names and using positional matching of 
>> arguments (unless arranged differently for specific primitives such 
>> as |rep 
>> <file:///Library/Frameworks/R.framework/Resources/library/base/html/rep.html>|), 
>> so this is discouraged for functions of more than one argument.
>
> This explains why in my tests the argument names i and j were 
> completely ignored and only the number and order of arguments changed 
> the result. 
>
> I've learnt my lesson here, but I wonder what could be done to make 
> this discovery easier for others:
>
> - add a note in the documentation of each .Primitive function (at 
> least a link to ?.Primitive)
>
> - add such an example in lapply (all examples are for named arguments)
>
> - echo a warning if trying to pass named arguments to a .Primitive
>
> - allow for named arguments as you suggest
>
> I'm not sure the last two would be possible without some cost in 
> efficiency.
>
>
> Many thanks,
>
> baptiste
>
>
>
>
> On 26 Mar 2009, at 07:46, Romain Francois wrote:
>
>>
>> Hi,
>>
>> This is a bug I think. [.data.frame treats its arguments differently
>> depending on the number of arguments.
>>
>>> d <- data.frame(x = rnorm(5), y = rnorm(5), z = rnorm(5) )
>>> d[, 1:2]
>>             x           y
>> 1   0.45141341  0.03943654
>> 2  -0.87954548  1.83690210
>> 3  -0.91083710  0.22758584
>> 4   0.06924279  1.26799176
>> 5  -0.20477052 -0.25873225
>>> base:::`[.data.frame`( d, j=1:2)
>>             x           y          z
>> 1   0.45141341  0.03943654 -0.8971957
>> 2  -0.87954548  1.83690210  0.9083281
>> 3  -0.91083710  0.22758584 -0.3104906
>> 4   0.06924279  1.26799176  1.2625699
>> 5  -0.20477052 -0.25873225  0.5228342
>> but also:
>>> d[ j=1:2]
>>            x           y          z
>> 1  0.45141341  0.03943654 -0.8971957
>> 2 -0.87954548  1.83690210  0.9083281
>> 3 -0.91083710  0.22758584 -0.3104906
>> 4  0.06924279  1.26799176  1.2625699
>> 5 -0.20477052 -0.25873225  0.5228342
>>
>> `[.data.frame` only is called with two arguments in the second case, so
>> the following condition is true:
>>
>> if(Narg < 3L) {  # list-like indexing or matrix indexing
>>
>> And then, the function assumes the argument it has been passed is i, and
>> eventually calls NextMethod("[") which I think calls
>> `[.listof`(x,i,...), since i is missing in `[.data.frame` it is not
>> passed to `[.listof`, so you have something equivalent to as.list(d)[].
>>
>> I think we can replace the condition with this one:
>>
>> if(Narg < 3L && !has.j) {  # list-like indexing or matrix indexing
>>
>> or this:
>>
>> if(Narg < 3L) {  # list-like indexing or matrix indexing
>>        if(has.j) i <- j
>>
>>> `[.data.frame`(d, j=1:2)
>>            x           y
>> 1  0.45141341  0.03943654
>> 2 -0.87954548  1.83690210
>> 3 -0.91083710  0.22758584
>> 4  0.06924279  1.26799176
>> 5 -0.20477052 -0.25873225
>>
>> However, we would still have this, which is expected (same as d[1:2] ):
>>
>>> `[.data.frame`(d, i=1:2)
>>            x           y
>> 1  0.45141341  0.03943654
>> 2 -0.87954548  1.83690210
>> 3 -0.91083710  0.22758584
>> 4  0.06924279  1.26799176
>> 5 -0.20477052 -0.25873225
>>
>> Romain
>>
>> baptiste auguie wrote:
>>> Dear all,
>>>
>>>
>>> Trying to extract a few rows for each element of a list of
>>> data.frames, I'm puzzled by the following behaviour,
>>>
>>>
>>>> d <- lapply(1:4,  function(i) data.frame(x=rnorm(5), y=rnorm(5)))
>>>> str(d)
>>>>
>>>> lapply(d, "[", i= c(1)) # fine,  this extracts the first columns
>>>> lapply(d, "[", j= c(1, 3)) # doesn't do nothing ?!
>>>>
>>>> library(plyr)
>>>>
>>>> llply(d, "[", j= c(1, 3)) # same
>>>
>>>
>>> Am i misinterpreting the meaning of "j", which I thought was an
>>> argument of the method "[.data.frame"?
>>>
>>>
>>>> args(`[.data.frame`)
>>>> function (x, i, j, drop = if (missing(i)) TRUE else length(cols) ==
>>>>   1)
>>>>
>>>
>>> Many thanks,
>>>
>>> baptiste
>>>
>>> _____________________________
>>>
>>> Baptiste Augui?
>>>
>>> School of Physics
>>> University of Exeter
>>> Stocker Road,
>>> Exeter, Devon,
>>> EX4 4QL, UK
>>>
>>> Phone: +44 1392 264187
>>>
>>> http://newton.ex.ac.uk/research/emag
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>> -- 
>> Romain Francois
>> Independent R Consultant
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>>
>>
>
> _____________________________
>
> Baptiste Augui?
>
> School of Physics
> University of Exeter
> Stocker Road,
> Exeter, Devon,
> EX4 4QL, UK
>
> Phone: +44 1392 264187
>
> http://newton.ex.ac.uk/research/emag
> ______________________________
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From znmeb at cesmail.net  Thu Mar 26 15:15:24 2009
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Thu, 26 Mar 2009 07:15:24 -0700
Subject: [Rd] Building R-alpha with ATLAS libraries?
Message-ID: <af0420cd0903260715q75e175ebp9d5844ee5192606@mail.gmail.com>

I'm trying to build R-alpha using the ATLAS libraries as described in
the R-admin manual, section A.3.1.1 (BLAS) and A.3.2 (LAPACK). I built
ATLAS with LAPACK as described in the ATLAS documentation, and the
ATLAS version is the latest, 3.9.10. The platform is openSUSE 11.1
x86_64 with GCC 4.3.2.

"configure" is finding the ATLAS BLAS all right, but it is not finding
the ATLAS LAPACK. The configure command string is

./configure --enable-threads --disable-R-profiling \
  --with-blas="-L/usr/local/atlas/lib -lptf77blas -lpthread -latlas" \
  --with-lapack="-L/usr/local/atlas/lib -llapack -lptcblas" \
  --with-tcltk --with-cairo --with-libpng --with-jpeglib --with-x \
  2>&1 | tee ../R-alpha-config.log

Here's what's in the "R-alpha-config.log" file when it gets to the
library check part:

checking for dgemm_ in -L/usr/local/atlas/lib -lptf77blas -lpthread
-latlas... yes
checking whether double complex BLAS can be used... yes
checking whether the BLAS is complete... yes
checking for zgeev_... no
checking for zgeev_ in -L/usr/local/atlas/lib -llapack -lptcblas... no
checking for zgeev_ in -llapack... no

I looked in "R-alpha/config.log" and it looks like "configure" is not
searching the right libraries for "zgeev_":

configure:38501: checking for zgeev_
configure:38565: gcc -std=gnu99 -o conftest -O3 -march=native -g -pipe
 -I/usr/local/include  -L/usr/local/lib64 conftest.c
-L/usr/local/atlas/lib -lptf77blas -lpthread -latlas  -lgfortran -lm
-ldl -lm  >&5
/tmp/ccETmjPn.o: In function `main':
/home/Projects/linux_perf_viz/build-scripts/R-alpha/conftest.c:218:
undefined reference to `zgeev_'
collect2: ld returned 1 exit status
configure:38571: $? = 1

I checked the ATLAS libraries and "zgeev_" is there. Did I miss
something in the "configure" parameters?
-- 
M. Edward (Ed) Borasky
http://www.linkedin.com/in/edborasky

I've never met a happy clam. In fact, most of them were pretty steamed.


From s.wood at bath.ac.uk  Thu Mar 26 16:17:33 2009
From: s.wood at bath.ac.uk (Simon Wood)
Date: Thu, 26 Mar 2009 15:17:33 +0000
Subject: [Rd] get_all_vars fails with matrices (PR#13624)
In-Reply-To: <49CA7DEE.50402@biostat.ku.dk>
References: <20090325171010.619532834149@mail.pubhealth.ku.dk>
	<49CA7DEE.50402@biostat.ku.dk>
Message-ID: <200903261517.33443.s.wood@bath.ac.uk>

It's not just lists that are odd...

> X <- matrix(1:15,5,3)
> z <- 26:30
> model.frame(~z+X)
   z X.1 X.2 X.3
1 26   1   6  11
2 27   2   7  12
3 28   3   8  13
4 29   4   9  14
5 30   5  10  15
> get_all_vars(~z+X)
[1] z    X    <NA> <NA>

... which is again a problem when trying to pick up unprocessed versions of 
the variables used by a modelling function....   


On Wednesday 25 March 2009 18:54, Peter Dalgaard wrote:
> s.wood at bath.ac.uk wrote:
> > Hi,
> >
> > According to the help file for model.frame/get_all_vars, the following
> > should produce the same output from both functions, but it doesn't...
> >
> >> dat <- list(X=matrix(1:15,5,3),z=26:30)
> >> model.frame(~z+X,dat)
> >
> >    z X.1 X.2 X.3
> > 1 26   1   6  11
> > 2 27   2   7  12
> > 3 28   3   8  13
> > 4 29   4   9  14
> > 5 30   5  10  15
> >
> >> get_all_vars(~z+X,dat)
> >
> > [1] z    X    <NA> <NA>
> > <0 rows> (or 0-length row.names)
> >
> > -- the equivalent works ok if there are no matrices involved.
> >
> > I'm using  R version 2.9.0 alpha (2009-03-24 r48212) (Suse linux 10 and
> > 11, 64 bit intel). I found the problem while trying to fix a problem in
> > an mgcv plotting routine.
> >
> > best,
> > Simon
>
> This works, though:
>  > dat <- data.frame(X=I(matrix(1:15,5,3)),z=26:30)
>  > get_all_vars(~z+X,dat)
>
>     z X.1 X.2 X.3
> 1 26   1   6  11
> 2 27   2   7  12
> 3 28   3   8  13
> 4 29   4   9  14
> 5 30   5  10  15
>
> but there is something special with lists:
>  > dat <- as.data.frame(list(X=I(matrix(1:15,5,3)),z=26:30))
>  > get_all_vars(~z+X,dat)
>
>     z X.1 X.2 X.3
> 1 26   1   6  11
> 2 27   2   7  12
> 3 28   3   8  13
> 4 29   4   9  14
> 5 30   5  10  15
>
>  > dat <- data.frame(list(X=I(matrix(1:15,5,3)),z=26:30))
>  > get_all_vars(~z+X,dat)
>
>     z X.1 X.2 X.3
> 1 26   1   6  11
> 2 27   2   7  12
> 3 28   3   8  13
> 4 29   4   9  14
> 5 30   5  10  15
>
>  > dat <- list(X=I(matrix(1:15,5,3)),z=26:30)
>  > get_all_vars(~z+X,dat)
>
> [1] z X
> <0 rows> (or 0-length row.names)

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From macrakis at alum.mit.edu  Thu Mar 26 16:44:25 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 26 Mar 2009 11:44:25 -0400
Subject: [Rd] Error message for matrix(1)[[1,,]]
Message-ID: <8b356f880903260844t2714131ft4f16489e84b527b5@mail.gmail.com>

> matrix(1)[[1,]]
Error in matrix(1)[[1, ]] : invalid subscript type 'symbol'

This is of course an incorrect use of [[, but I think the error
message could be more helpful.
I will guess that it is interpreting the missing value indicator as a
symbol, since I get the same error message for

> matrix(1)[[ quote(a=), ]]

          -s

PS quote(a=) seems to be the easiest way to get the missing value
indicator as a value.  Is it by design that it returns the MVI? Or is
it a missing error check?


From osklyar at maninvestments.com  Thu Mar 26 17:03:13 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 26 Mar 2009 16:03:13 -0000
Subject: [Rd] typo in sprintf format string segfaults R
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7A2@mildnpexmb01.maninvestments.ad.man.com>

typo as simple as %S instead of %s segfaults R devel:

*** R 2.9.0 (svn -r 47821) [/share/research/R-devel/20090203/lib64/R]
***
> sprintf("%S%d", "aaa", 1)

 *** caught segfault ***
address 0x8000, cause 'memory not mapped'

Traceback:
 1: sprintf("%S%d", "aaa", 1)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace

-------------------------------------------------------------
> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-02-02 r47821) 
x86_64-unknown-linux-gnu 

locale:
C

attached base packages:
[1] stats     graphics  utils     datasets  grDevices methods   base


Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Mar 26 17:27:43 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 26 Mar 2009 17:27:43 +0100
Subject: [Rd] typo in sprintf format string segfaults R
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7A2@mildnpexmb01.maninvestments.ad.man.com>
References: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7A2@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <49CBACFF.4030706@idi.ntnu.no>

Sklyar, Oleg (London) wrote:
> typo as simple as %S instead of %s segfaults R devel:
>   

not exactly:

    sprintf('%S', 'aa')
    # error: unrecognised format at end of string

without a segfault.  but with another format specifier behind, it will
cause a segfault.

interestingly, here's again the same problem i have reported recently: 
that you are given a number of options for how to leave the session, but
you can type ^c and stay in a semi-working session.  (and the next
execution of the above will  then cause a segfault with immediate exit.)

vQ


From ligges at statistik.tu-dortmund.de  Thu Mar 26 19:34:28 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 26 Mar 2009 19:34:28 +0100
Subject: [Rd] savePlot export "strange" eps (PR#13620)
In-Reply-To: <49C901BA.3080305@u-paris10.fr>
References: <20090323233509.D35A8283218F@mail.pubhealth.ku.dk>
	<49C8EFA6.2020309@statistik.tu-dortmund.de>
	<49C901BA.3080305@u-paris10.fr>
Message-ID: <49CBCAB4.2070203@statistik.tu-dortmund.de>



Christophe Genolini wrote:
> Sorry for that... I find a strange behavior in "savePlot" ; before 
> report a bug, I read the posting guide and I try to simplify my exemple 
> as much as possible. Doing this, I change my code and I remove the " 
> type='eps' " option... Sorry !
> 
> Let's start this again.
> 
> When I use savePlot(file="toto.eps",type="eps") and I try to incorporate 
> "toto.eps" in a LaTeX document, I get a strange behavior:
> LaTeX run normaly, so does dvips. But the generated postscript include a 
> graph that overwirte the line above it.
> If my latex is
> 
> bonjour bonjour2 bonjour3
> \begin{center}
> \includegraphics[width=12cm]{toto.eps}
> \end{center}
> 
> Then "bonjour2 bonjour3" is hidden by the graph.


No so for me, but let me (what you still not did), give a reproducible 
example:

I opened some vanilla R-2.8.1 under Windows using

RGui --vanilla

in R:

plot(1:10)
savePlot(file="d:/temp/toto.eps", type="eps")

Then I created a LaTeX document:

\documentclass{article}
\usepackage{graphicx}
\begin{document}
bonjour bonjour2 bonjour3
\begin{center}
  \includegraphics[width=12cm]{toto.eps}
\end{center}
\end{document}


and ran LaTeX and dvips.

All is fine.  So, *please*, specify a reproducible example or we cannot 
help. I presume you have a LaTeX problem. Anyway, a better way to export 
your graphs would be to use a proper device directly - independent of 
what happens here.

And also, this is still not proved to be a bug, particularly not in R!

Uwe Ligges




> Version: 2.8.1
> OS: Windows XP
> LaTeX : Miktex 2.7
> 
> Christophe
> 
>>
>>
>> cgenolin at u-paris10.fr wrote:
>>> Full_Name: Christophe Genolini
>>> Version: 2.8.1
>>> OS: Windows XP
>>> Submission from: (NULL) (82.225.59.146)
>>>
>>>
>>> savePlot export "eps" graph that seems to be incorrect. 
>>
>>
>> Looks like you saved an EMF rather than an eps file???
>>
>> Uwe Ligges
>>
>>
>>
>>> Trying to incorporate them in a LaTeX file, I get : 
>>> ++++++++++++++++++++++
>>> Cannot determine size of graphics in foo.eps (no BoundingBox)
>>> ----------------------
>>>
>>> Trying to open them with GSview, I get :
>>> ++++++++++++++++++++++
>>> GSview 4.9 2007-11-18
>>> AFPL Ghostscript 8.54 (2006-05-17)
>>> Copyright (C) 2005 artofcode LLC, Benicia, CA.  All rights reserved.
>>> This software comes with NO WARRANTY: see the file PUBLIC for details.
>>> Displaying non DSC file C:/Documents and Settings/Christophe/Mes
>>> documents/Recherche/Trajectoires/kmeal/trajectories/testsDev/toti.eps
>>> Error: /undefined in 
>>> Operand stack:
>>>
>>> Execution stack:
>>>    %interp_exit   .runexec2   --nostringval--   --nostringval--  
>>> --nostringval--   2   %stopped_push   --nostringval--   
>>> --nostringval--   false  1   %stopped_push   1   3   %oparray_pop   
>>> 1   3   %oparray_pop   1   3  %oparray_pop   1   3   %oparray_pop   
>>> .runexec2   --nostringval--  --nostringval--   --nostringval--   2   
>>> %stopped_push   --nostringval--
>>> Dictionary stack:
>>>    --dict:1130/1686(ro)(G)--   --dict:0/20(G)--   --dict:74/200(L)--
>>> Current allocation mode is local
>>> Last OS error: No such file or directory
>>>
>>> --- Begin offending input ---
>>>    ?      L   z  f          C  fC   EMF   $6  7        
>>> l       ?    ?                ?? ? G r a p h A p p     
>>> %        ?%
>>>        ?%        ?%        ?%        ?%        ?%        
>>> ?%       ?%        ?%        ?%        ?%        ?K   @   
>>> 0                  N   N   y  @  N   N   y  @  %        
>>> ?%        ?:         _   8      8       8         
>>>                        %                  ;            l   *  
>>> 6      Z  ?  <      @      f   ?  `  0  %   
>>>     ?(         %        ?%        ?K   @   0             
>>>       N   N  y  @  N   N   y  @  %        ?%        ?:   
>>>       _   8      8       8                                %   
>>>                ;            m  ?  6      Z  ?  <      
>>> @      g  ?  `  ?  %   
>>>     ?(         %        ?%        ?K   @   0             
>>>              ?  ?          ?  ?  %        ?%        ?:   
>>>       _   8      8       8                            --- End 
>>> offending input ---
>>> file offset = 1024
>>> gsapi_run_string_continue returns -101
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From laverty at math.utah.edu  Thu Mar 26 21:00:14 2009
From: laverty at math.utah.edu (laverty at math.utah.edu)
Date: Thu, 26 Mar 2009 21:00:14 +0100 (CET)
Subject: [Rd] Console colors do not stick (PR#13625)
Message-ID: <20090326200014.C8346282BE82@mail.pubhealth.ku.dk>

Full_Name: Sean Laverty
Version: R version 2.8.1 (2008-12-22)
OS: os x 10.5.6
Submission from: (NULL) (155.101.41.13)


In the console colors window, colors do not stick when palettes are closed.  All
custom colors are replaced by blue.  I've tried all palettes - crayons, sliders,
wheel, spectrum.

"R.bug.report" 30L, 582C[2;1H<<insert bug report here>>[6;1H--please do not
edit the information below--
Version:
 platform = i386-apple-darwin8.11.1
 arch = i386
 os = darwin8.11.1
 system = i386, darwin8.11.1
 status =
 major = 2
 minor = 8.1
 year = 2008
 month = 12
 day = 22
 svn rev = 47281
 language = R
 version.string = R version 2.8.1 (2008-12-22)
GUI:[1;1H


From osklyar at maninvestments.com  Fri Mar 27 16:56:31 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Fri, 27 Mar 2009 15:56:31 -0000
Subject: [Rd] imporving performance of slicing on matrices and S4 their
	derivatives
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7AF@mildnpexmb01.maninvestments.ad.man.com>

Dear list.

It is a known issue that accessing slots of S4 objects and in particular
accessing .Data slots is slow in R. However, what surprises me are two
things demonstrated in the code below (runnable with 'inline', my times
are in the comments):

- copying data out of a large 3x1e7 .Data slot into a matrix can be
easily made 3-4 times faster than accessing a .Data slot which I believe
grabs a reference (and as copying can be avoided the acceleration should
be even more dramatic). It is surprising that this memory inefficient
operation is faster than such a simple thing like getting a reference!

- getting a column, or columns, from an atomic R matrix or actually an
S4 object derived from it, can be up to 10 times faster than using
standard slicing with the [-operator (yes, less generic, but with such
performance gain we do definitely use it).

My point is: should not [-operators for atomic objects and @.Data be
redesigned? The code here is just an example for double storage-mode and
without any checks though. Adding checks and colnames etc does not lead
to performance degradation.

I was originally thinking that the dispatch looking up a particular [
implementation for an object is the issue, but in fact it is not the
case as redefining [ or $ as S4 methods (!) to use the mcol below for an
S4 object shows the same performance gains as the diret use of use of
mcol/mcols!

Any comments welcome!


## --- code ----------------------------------------------------
## available from CRAN, needs compilers installed
library(inline)

## get 1 column of a matrix to use instead of [-operator 
## (same performance gains if index is a character or on multiple
columns or
## when getting multiple columns as matrix and assigning the names from
input)

body = "/* test for column extraction: no checks here for code
simplicity */
    int nrow = Rf_nrows(m);
    int i = INTEGER(index)[0] - 1;
    SEXP res;
    PROTECT(res = allocVector(REALSXP, nrow));
    memcpy(REAL(res), &(REAL(m)[i*nrow]), nrow*sizeof(double));
    UNPROTECT(1);
    return res;"

mcol = cfunction(signature(m="matrix", index="integer"), body=body, 
    includes="#include <string.h>")
    
## get A COPY of the @.Data slot from an object derived from
numeric/matrix

body = "/* test performance of getting A COPY of @.Data, keeping
dimnames */
    int nrow = Rf_nrows(m);
    int ncol = Rf_ncols(m);
    SEXP res, dim;
    PROTECT(res = allocVector(REALSXP, nrow*ncol));
    PROTECT(dim = allocVector(INTSXP, 2));
    INTEGER(dim)[0] = nrow;
    INTEGER(dim)[1] = ncol;
    SET_DIM(res, dim);
    if (GET_DIMNAMES(m)!= R_NilValue)
        SET_DIMNAMES(res, Rf_duplicate(GET_DIMNAMES(m)));
    if (ncol>0 && nrow>0)
        memcpy(REAL(res), REAL(m), nrow*ncol*sizeof(double));
    UNPROTECT(2);
    return res;"

mcols = cfunction(signature(m="matrix"), body=body, 
    includes="#include <string.h>")

## --- tests ---------------------------------------------------
m = matrix(runif(3e7), nc=3)

setClass("MyClass", representation("matrix", comment="character"))
dat = new("MyClass", m, comment="test object")

mean(sapply(1:20, function(i) system.time(dat at .Data)[1] ))
## output: [1] 0.2526
mean(sapply(1:20, function(i) system.time(mcols(dat))[1] ))
## output: [1] 0.08215

mean(sapply(1:50, function(i) system.time(m[,2])[1] ))
## output: [1] 0.1222
mean(sapply(1:50, function(i) system.time(mcol(m,2L))[1] ))
## output: [1] 0.02596
mean(sapply(1:50, function(i) system.time(dat[,2])[1] ))
## output: [1] 0.1269
mean(sapply(1:50, function(i) system.time(mcol(dat,2L))[1] ))
## output: [1] 0.02584

---
> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-02-02 r47821) 
x86_64-unknown-linux-gnu 

locale:
C

attached base packages:
[1] stats     graphics  utils     datasets  grDevices methods   base


other attached packages:
[1] inline_0.3.3



Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From simon.urbanek at r-project.org  Fri Mar 27 17:36:55 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 27 Mar 2009 12:36:55 -0400
Subject: [Rd] Console colors do not stick (PR#13625)
In-Reply-To: <20090326200014.C8346282BE82@mail.pubhealth.ku.dk>
References: <20090326200014.C8346282BE82@mail.pubhealth.ku.dk>
Message-ID: <EDB8F5FF-5159-43B5-821A-4ABDCD443E82@r-project.org>


On Mar 26, 2009, at 4:00 PM, laverty at math.utah.edu wrote:

> Full_Name: Sean Laverty
> Version: R version 2.8.1 (2008-12-22)
> OS: os x 10.5.6
> Submission from: (NULL) (155.101.41.13)
>
>
> In the console colors window, colors do not stick when palettes are  
> closed.

You have to select another swatch *before* closing the window to  
prevent this from happening.

It's still a bug, though, and I'll see if we can do something about it  
(the swatch reverts to its default color when queried on the close...).


Cheers,
Simon


>  All
> custom colors are replaced by blue.  I've tried all palettes -  
> crayons, sliders,
> wheel, spectrum.
>
> "R.bug.report" 30L, 582C[2;1H<<insert bug report here>>[6;1H-- 
> please do not
> edit the information below--
> Version:
> platform = i386-apple-darwin8.11.1
> arch = i386
> os = darwin8.11.1
> system = i386, darwin8.11.1
> status =
> major = 2
> minor = 8.1
> year = 2008
> month = 12
> day = 22
> svn rev = 47281
> language = R
> version.string = R version 2.8.1 (2008-12-22)
> GUI:[1;1H
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From osklyar at maninvestments.com  Fri Mar 27 17:54:37 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Fri, 27 Mar 2009 16:54:37 -0000
Subject: [Rd] consistent segfaults in ROracle with one of the databases
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7B1@mildnpexmb01.maninvestments.ad.man.com>

Dear list.

Has anybody had any issues with ROracle, namely consistently leading to
a segmentation fault? One of our oracle databases seems to have certain
issues at the moment (do not know what exactly though) and if that one
is queried ROracle definitely fails with a segmentation fault. Any
ideas? Here is the trace and below is also a type of query that crashes
it:

 *** caught segfault ***
address 0x1, cause 'memory not mapped'

Traceback:
 1: .Call("RS_Ora_exec", ps = as(ps, "integer"), data = data,
data.classes = df.classes,     buf.size = as.integer(ora.buf.size),
PACKAGE = .OraPkgName)
 2: oraExecStatement(ps, ora.buf.size = as(ora.buf.size, "integer"))
 3: doTryCatch(return(expr), name, parentenv, handler)
 4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
 5: tryCatchList(expr, classes, parentenv, handlers)
 6: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
if (!is.null(call)) {        if (identical(call[[1L]],
quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
"\n")[[1L]]        if (14L + nchar(dcall, type = "w") + nchar(sm[1L],
type = "w") >             LONG)             prefix <- paste(prefix, "\n
", sep = "")    }    else prefix <- "Error : "    msg <- paste(prefix,
conditionMessage(e), "\n", sep = "")
.Internal(seterrmessage(msg[1L]))    if (!silent &&
identical(getOption("show.error.messages"),         TRUE)) {
cat(msg, file = stderr())        .Internal(printDeferredWarnings())    }
invisible(structure(msg, class = "try-error"))})
 7: try({    ps <- oraPrepareStatement(con, statement, bind = NULL)
rs <- oraExecStatement(ps, ora.buf.size = as(ora.buf.size,
"integer"))})
 8: oraExecDirect(con, statement, ...)
 9: oraQuickSQL(conn, statement, ...)
10: dbGetQuery(dotsConnection(), qry)

--
This is the type of query (template) that crashes it, I know this is not
too helpful as you cannot run it, but maybe someone spots a certain
pattern in it:

SELECT TIMESTAMP, VALUE, VM FROM
    (WITH ev AS
        (SELECT audit_key_new key, audit_date dt, audit_batch_nbr,
audit_date
            FROM dots_audit.audit_event
            WHERE table_name='VALUE_PROPERTY_MAP'),
    jfsm AS
        (SELECT audit_key, fund_id, fund_mult
            FROM dots_audit.value_property_map WHERE property_id='%s'
         UNION SELECT audit_key, value_id, value_mult
            FROM dots.value_property_map WHERE property_id='%s')
    SELECT DISTINCT
        ev.dt - to_date('01011970','ddmmyyyy') TIMESTAMP,
        jfsm.value_id VALUE,
        jfsm.value_mult VM,
        RANK() OVER (PARTITION BY audit_batch_nbr, value_id ORDER BY dt
DESC) r
        FROM jfsm, ev WHERE audit_key=ev.key)
    WHERE r=1 ORDER BY TIMESTAMP DESC 

--
> library(ROracle)
Loading required package: DBI
> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-02-02 r47821) 
x86_64-unknown-linux-gnu 

locale:
LC_CTYPE=en_GB;LC_NUMERIC=C;LC_TIME=en_GB;LC_COLLATE=C;LC_MONETARY=C;LC_
MESSAGES=en_GB;LC_PAPER=en_GB;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_M
EASUREMENT=en_GB;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  utils     datasets  grDevices methods   base


other attached packages:
[1] ROracle_0.5-9 DBI_0.2-4    

--

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From simon.urbanek at r-project.org  Fri Mar 27 19:49:15 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 27 Mar 2009 14:49:15 -0400
Subject: [Rd] Console colors do not stick (PR#13625)
In-Reply-To: <EDB8F5FF-5159-43B5-821A-4ABDCD443E82@r-project.org>
References: <20090326200014.C8346282BE82@mail.pubhealth.ku.dk>
	<EDB8F5FF-5159-43B5-821A-4ABDCD443E82@r-project.org>
Message-ID: <F4720B17-C9FD-49E8-90D8-902EBCB904EF@r-project.org>


On Mar 27, 2009, at 12:36 , Simon Urbanek wrote:

>
> On Mar 26, 2009, at 4:00 PM, laverty at math.utah.edu wrote:
>
>> Full_Name: Sean Laverty
>> Version: R version 2.8.1 (2008-12-22)
>> OS: os x 10.5.6
>> Submission from: (NULL) (155.101.41.13)
>>
>>
>> In the console colors window, colors do not stick when palettes are  
>> closed.
>
> You have to select another swatch *before* closing the window to  
> prevent this from happening.
>
> It's still a bug, though, and I'll see if we can do something about  
> it (the swatch reverts to its default color when queried on the  
> close...).
>

Should be fixed (or more precisely worked around) in the GUI rev. 5380.

Cheers,
Simon


>
>
>> All
>> custom colors are replaced by blue.  I've tried all palettes -  
>> crayons, sliders,
>> wheel, spectrum.
>>
>> "R.bug.report" 30L, 582C[2;1H<<insert bug report here>>[6;1H-- 
>> please do not
>> edit the information below--
>> Version:
>> platform = i386-apple-darwin8.11.1
>> arch = i386
>> os = darwin8.11.1
>> system = i386, darwin8.11.1
>> status =
>> major = 2
>> minor = 8.1
>> year = 2008
>> month = 12
>> day = 22
>> svn rev = 47281
>> language = R
>> version.string = R version 2.8.1 (2008-12-22)
>> GUI:[1;1H
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Mar 27 22:27:41 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 27 Mar 2009 22:27:41 +0100
Subject: [Rd] [R] "[.data.frame" and lapply
In-Reply-To: <49CB32C0.1010500@dbmail.com>
References: <0935362A-34E7-4711-B2F4-8FB72108950B@exeter.ac.uk>
	<49CB32C0.1010500@dbmail.com>
Message-ID: <49CD44CD.4070009@idi.ntnu.no>

redirected to r-devel, because there are implementational details of
[.data.frame discussed here.  spoiler: at the bottom there is a fairly
interesting performance result.

Romain Francois wrote:
>
> Hi,
>
> This is a bug I think. [.data.frame treats its arguments differently
> depending on the number of arguments.

you might want to hesitate a bit before you say that something in r is a
bug, if only because it drives certain people mad.  r is a carefully
tested software, and [.data.frame is such a basic function that if what
you talk about were a bug, it wouldn't have persisted until now.

treating the arguments differently depending on their number is actually
(if clearly...) documented:  if there is one index (the 'i'), it selects
columns.  if there are two, 'i' selects rows.

however, not all seems fine, there might be a design flaw:

    # dummy data frame
    d = structure(names=paste('col', 1:3, sep='.'),
        data.frame(row.names=paste('row', 1:3, sep='.'),
           matrix(1:9, 3, 3)))

    d[1:2]
    # correctly selects two first columns
    # 1:2 passed to [.data.frame as i, no j given

    d[,1:2]
    # correctly selects two first columns
    # 1:2 passed to [.data.frame as j, i given the missing argument
value (note the comma)

    d[,i=1:2]
    # correctly selects two first rows
    # 1:2 passed to [.data.frame as i, j given the missing argument
value (note the comma)

    d[j=1:2,]
    # correctly selects two first columns
    # 1:2 passed to [.data.frame as j, i given the missing argument
value (note the comma)

    d[i=1:2]
    # correctly (arguably) selects the first two columns
    # 1:2 passed to [.data.frame as i, no j given
  
    d[j=1:2]
    # wrong: returns the whole data frame
    # does not recognize the index as i because it is explicitly named 'j'
    # does not recognize the index as j because there is only one index

i say this *might* be a design flaw because it's hard to judge what the
design really is.  the r language definition (!) [1, sec. 3.4.3 p. 18] says:

"   The most important example of a class method for [ is that used for
data frames. It is not
be described in detail here (see the help page for [.data.frame, but in
broad terms, if two
indices are supplied (even if one is empty) it creates matrix-like
indexing for a structure that is
basically a list of vectors of the same length. If a single index is
supplied, it is interpreted as
indexing the list of columns?in that case the drop argument is ignored,
with a warning."

it does not say what happens when only one *named* index argument is
given.  from the above, it would indeed seem that there is a *bug*
here:  in the last example above only one index is given, and yet
columns are not selected, even though the *language definition* says
they should.  (so it's not a documented feature, it's a
contra-definitional misfeature -- a bug?)

somewhat on the side, the 'matrix-like indexing' above is fairly
misleading;  just try the same patterns of indexing -- one index, two
indices, named indices -- on a data frame and a matrix of the same shape:

    m = matrix(1:9, 3, 3)
    md = data.frame(m)

    md[1]
    # the first column
    m[1]
    # the first element (i.e., m[1,1])

    md[,i=3]
    # third row
    m[,i=3]
    # third column


the quote above refers to the ?'[.data.frame' for details. 
unfortunately, it the help page a lump of explanations for various
'['-like operators, and it is *not* a definition of any sort.  it does
not provide much more detail on '[.data.frame' -- it is hardly as a
design specification.  in particular, it does not explain the issue of
named arguments to '[.data.frame' at all.


`[.data.frame` only is called with two arguments in the second case,  
> so
> the following condition is true:
>
> if(Narg < 3L) {  # list-like indexing or matrix indexing
>
> And then, the function assumes the argument it has been passed is i,  
> and
> eventually calls NextMethod("[") which I think calls
> `[.listof`(x,i,...), since i is missing in `[.data.frame` it is not
> passed to `[.listof`, so you have something equivalent to as.list(d) 
> [].
>
> I think we can replace the condition with this one:
>
> if(Narg < 3L && !has.j) {  # list-like indexing or matrix indexing
>
> or this:
>
> if(Narg < 3L) {  # list-like indexing or matrix indexing
>        if(has.j) i <- j
>


indeed, for a moment i thought a trivial fix somewhere there would
suffice.  unfortunately, the code for [.data.frame [2, lines 500-641] is
so clean and readable that i had to give up reading it, forget fixing. 
instead, i wrote an new version of '[.data.frame' from scratch.  it
fixes (or at least seems to fix, as far as my quick assessment goes) the
problem.  the function subdf (see the attached dataframe.r) is the new
version of '[.data.frame':

    # dummy data frame
    d = structure(names=paste('col', 1:3, sep='.'),
        data.frame(row.names=paste('row', 1:3, sep='.'),
           matrix(1:9, 3, 3)))

    d[j=1:2]
    # incorrect: the whole data frame

    subdf(d, j=1:2)
    # correct, only the first two columns

otherwise, subdf returns results equivalent (sensu all.equal;  see
below) to those returned by [.data.frame on the same input, modulo some
more or less minor details.  for example, i think the dropped-drop
warnings go wrong in the original:

    d[1, drop=FALSE]
    # warning: drop argument will be ignored

which suggests that dimensions will be dropped, while the intention is
that the actual argument will be ignored and the value will be FALSE
instead (while the default is TRUE, since i is specified).  well, it's
just one more confusing bit in r.  the rewritten version warns about
dropped drop only if it is explicitly TRUE:

    subdf(d, 1, drop=FALSE)
    # no warning
    subdf(d, 1, drop=TRUE)
    # warning

another issue the differs in my version is that i don't see much sense
in being able to select rows by indexing with NA:

    d[NA,1]
    # one row filled with NAs

    d[NA,]
    # data frame of the shape of d, filled with NAs

which is incoherent with how NA are treated in columns indices (i.e.,
raise an error).  the rewritten version raises an error if any element
of any index is an NA.

these minor differences are easily modifiable should compliance with the
original 'design' be desirable.

interestingly, there is a reduction in code by some 40 lines (~30%) wrt.
the original, even though the new code is quite redundant (but thus were
the original, too).  with a little effort, it can be compressed further,
but i felt it would become more convoluted and less readable, and also
less efficient.  procedural abstraction could help, but would also
negatively impact performance.  (presumably, an implementation in c
would run faster.)

incidentally (here's the best part!), my version seems to perform much
better than the original, at least in a limited set of naive
benchmarks.  here are some results, which you can (hopefully) reproduce
using the code in the attached test.r.  the data is a dummy df with 1k
rows and 1k columns, filled with rnorm;  each indexing was repeated 1000
times for both the original and the modified version:

   original patched ratio   test                                    
1  0.002    0.001      2.00 d[]                                     
2  0.027    0.001     27.00 d[drop = FALSE]                         
3  0.025    0.002     12.50 d[drop = TRUE]                          
4  0.026    0.002     13.00 d[, drop = FALSE]                       
5  0.026    0.003      8.67 d[, drop = TRUE]                        
6  1.274    0.002    637.00 d[, ]                                   
7  1.255    0.001   1255.00 d[, , ]                                 
8  1.183    0.001   1183.00 d[, , drop = FALSE]                     
9  1.183    0.003    394.33 d[, , drop = TRUE]                      
10 0.013    0.011      1.18 d[r]                                    
11 0.040    0.034      1.18 d[r, drop = TRUE]                       
12 0.037    0.010      3.70 d[r, drop = FALSE]                      
13 0.012    0.011      1.09 d[i = r]                                
14 0.036    0.034      1.06 d[i = r, drop = TRUE]                   
15 0.037    0.011      3.36 d[i = r, drop = FALSE]                  
16 0.222    0.163      1.36 d[rr]                                   
17 0.247    0.112      2.21 d[rr, drop = FALSE]                     
18 0.204    0.144      1.42 d[rr, drop = TRUE]                      
19 0.174    0.120      1.45 d[i = rr]                               
20 0.201    0.125      1.61 d[i = rr, drop = FALSE]                 
21 0.215    0.147      1.46 d[i = rr, drop = TRUE]                  
22 2.266    1.159      1.96 d[rr, ]                                 
23 2.236    1.164      1.92 d[rr, , drop = FALSE]                   
24 2.275    1.171      1.94 d[rr, , drop = TRUE]                    
25 2.269    1.165      1.95 d[i = rr, ]                             
26 2.264    1.155      1.96 d[i = rr, , drop = FALSE]               
27 2.290    1.189      1.93 d[i = rr, , drop = TRUE]                
28 2.301    1.198      1.92 d[, i = rr]                             
29 2.239    1.158      1.93 d[, i = rr, drop = FALSE]               
30 2.310    1.161      1.99 d[, i = rr, drop = TRUE]                
31 0.002    0.003      0.67 d[j = c]                                
32 0.026    0.011      2.36 d[j = c, drop = FALSE]                  
33 0.026    0.003      8.67 d[j = c, drop = TRUE]                   
34 0.001    0.111      0.01 d[j = cc]                               
35 0.025    0.110      0.23 d[j = cc, drop = FALSE]                 
36 0.025    0.111      0.23 d[j = cc, drop = TRUE]                  
37 0.243    0.051      4.76 d[rr, cc]                               
38 0.243    0.051      4.76 d[rr, cc, drop = FALSE]                 
39 0.244    0.050      4.88 d[rr, cc, drop = TRUE]                  
40 0.244    0.051      4.78 d[i = rr, cc]                           
41 0.243    0.050      4.86 d[i = rr, cc, drop = FALSE]             
42 0.244    0.051      4.78 d[i = rr, cc, drop = TRUE]              
43 0.243    0.052      4.67 d[cc, i = rr]                           
44 0.244    0.050      4.88 d[cc, i = rr, drop = FALSE]             
45 0.247    0.052      4.75 d[cc, i = rr, drop = TRUE]              
46 0.244    0.050      4.88 d[i = rr, j = cc]                       
47 0.244    0.051      4.78 d[i = rr, j = cc, drop = FALSE]         
48 0.244    0.051      4.78 d[i = rr, j = cc, drop = TRUE]          
49 0.244    0.051      4.78 d[j = cc, i = rr]                       
50 0.243    0.051      4.76 d[j = cc, i = rr, drop = FALSE]         
51 0.245    0.051      4.80 d[j = cc, i = rr, drop = TRUE]          
52 0.002    0.155      0.01 d[j = cn]                               
53 0.429    0.139      3.09 d[i = rn, j = cn]                       
54 1.791    0.690      2.60 d[i = c(TRUE, FALSE), j = c(FALSE, TRUE)]

(note:  the benchmark relies on a feature of rbenchmark that i have just
added, so you may need to download/update the package before trying.)

in some tests, the difference is two orders of magnitude; in some it's a
factor of 2-5;  in some there's no significant difference.  in only a
few cases, the original is way faster (e.g., tests 34 and 52), but this
is because the original is wrong there (it simply ignores the index, so
no wonder).

all the expressions above used in benchmarking were also used to test
the equivalence of output from the original and the new version (see
test.r again), and all of them were negative (no difference) -- except
for the cases where the original was wrong.


i'd consider making a patch for src/library/base/R/dataframe.R, but
there's a hack here:  it seems that some code relies on some part of the
'design' that differs between the rewrite and the original, and the new
code does not make (dataframe.R does, but then other sources fail). 
anyway, sourcing the attached dataframe.R suffices for testing. 

i will be happy to learn where my implementation, benchmarking, and/or
result checking are naive or wrong in any way, as they surely are.


vQ



[1] http://cran.r-project.org/doc/manuals/R-lang.pdf
[2] http://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dataframe.r
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090327/230f7872/attachment.pl>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test.r
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090327/230f7872/attachment-0001.pl>

From manikandan_narayanan at merck.com  Sat Mar 28 00:05:12 2009
From: manikandan_narayanan at merck.com (manikandan_narayanan at merck.com)
Date: Sat, 28 Mar 2009 00:05:12 +0100 (CET)
Subject: [Rd] read.table on long lines buggy (PR #13626) (sorry not a
	bug!) (PR#13627)
Message-ID: <20090327230512.89C4F282C768@mail.pubhealth.ku.dk>

Hi,=20
  Sorry, didn't notice a quote in the longer line that was causing the
problem. Everything works fine with read.table(quote=3D"",...). Please
remove PR#13626 report - I tried to do so from the bug tracking web
interface, but did not have the permissions.  Thanks!


Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From romain.francois at dbmail.com  Sat Mar 28 11:09:52 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 28 Mar 2009 11:09:52 +0100
Subject: [Rd] [R] "[.data.frame" and lapply
In-Reply-To: <49CD44CD.4070009@idi.ntnu.no>
References: <0935362A-34E7-4711-B2F4-8FB72108950B@exeter.ac.uk>
	<49CB32C0.1010500@dbmail.com> <49CD44CD.4070009@idi.ntnu.no>
Message-ID: <49CDF770.3010102@dbmail.com>

Wacek Kusnierczyk wrote:
> redirected to r-devel, because there are implementational details of
> [.data.frame discussed here.  spoiler: at the bottom there is a fairly
> interesting performance result.
>
> Romain Francois wrote:
>   
>> Hi,
>>
>> This is a bug I think. [.data.frame treats its arguments differently
>> depending on the number of arguments.
>>     
>
> you might want to hesitate a bit before you say that something in r is a
> bug, if only because it drives certain people mad.  r is a carefully
> tested software, and [.data.frame is such a basic function that if what
> you talk about were a bug, it wouldn't have persisted until now.
>   
I did hesitate, and would be prepared to look the other way of someone 
shows me proper evidence that this makes sense.

 > d <- data.frame( x = 1:10, y = 1:10, z = 1:10 )
 > d[ j=1 ]
    x  y  z
1   1  1  1
2   2  2  2
3   3  3  3
4   4  4  4
5   5  5  5
6   6  6  6
7   7  7  7
8   8  8  8
9   9  9  9
10 10 10 10

"If a single index is supplied, it is interpreted as indexing the list 
of columns". Clearly this does not happen here, and this is because 
NextMethod gets confused.

I have not looked your implementation in details, but it misses array 
indexing, as in:

 > d <- data.frame( x = 1:10, y = 1:10, z = 1:10 )
 > m <- cbind( 5:7, 1:3 )
 > m
     [,1] [,2]
[1,]    5    1
[2,]    6    2
[3,]    7    3
 > d[m]
[1] 5 6 7
 > subdf( d, m )
Error in subdf(d, m) : undefined columns selected

"Matrix indexing using '[' is not recommended, and barely
     supported.  For extraction, 'x' is first coerced to a matrix. For
     replacement a logical matrix (only) can be used to select the
     elements to be replaced in the same way as for a matrix."

You might also want to look at `[<-.data.frame`.

 > d[j=2] <- 1:10
Error in `[<-.data.frame`(`*tmp*`, j = 2, value = 1:10) :
  element 1 is empty;
   the part of the args list of 'is.logical' being evaluated was:
   (i)
 > d[2] <- 10:1
 > d
    x  y  z
1   1 10  1
2   2  9  2
3   3  8  3
4   4  7  4
5   5  6  5
6   6  5  6
7   7  4  7
8   8  3  8
9   9  2  9
10 10  1 10

This is probably less of an issue, because there is very little chance 
for people to use this construct, but for the first one, if not used 
directly, it still has good chances to be used within some fooapply 
call, as in the original post. Although it might have been preferable to 
use subset as the applied function.

Romain
> treating the arguments differently depending on their number is actually
> (if clearly...) documented:  if there is one index (the 'i'), it selects
> columns.  if there are two, 'i' selects rows.
>
> however, not all seems fine, there might be a design flaw:
>
>     # dummy data frame
>     d = structure(names=paste('col', 1:3, sep='.'),
>         data.frame(row.names=paste('row', 1:3, sep='.'),
>            matrix(1:9, 3, 3)))
>
>     d[1:2]
>     # correctly selects two first columns
>     # 1:2 passed to [.data.frame as i, no j given
>
>     d[,1:2]
>     # correctly selects two first columns
>     # 1:2 passed to [.data.frame as j, i given the missing argument
> value (note the comma)
>
>     d[,i=1:2]
>     # correctly selects two first rows
>     # 1:2 passed to [.data.frame as i, j given the missing argument
> value (note the comma)
>
>     d[j=1:2,]
>     # correctly selects two first columns
>     # 1:2 passed to [.data.frame as j, i given the missing argument
> value (note the comma)
>
>     d[i=1:2]
>     # correctly (arguably) selects the first two columns
>     # 1:2 passed to [.data.frame as i, no j given
>   
>     d[j=1:2]
>     # wrong: returns the whole data frame
>     # does not recognize the index as i because it is explicitly named 'j'
>     # does not recognize the index as j because there is only one index
>
> i say this *might* be a design flaw because it's hard to judge what the
> design really is.  the r language definition (!) [1, sec. 3.4.3 p. 18] says:
>
> "   The most important example of a class method for [ is that used for
> data frames. It is not
> be described in detail here (see the help page for [.data.frame, but in
> broad terms, if two
> indices are supplied (even if one is empty) it creates matrix-like
> indexing for a structure that is
> basically a list of vectors of the same length. If a single index is
> supplied, it is interpreted as
> indexing the list of columns?in that case the drop argument is ignored,
> with a warning."
>
> it does not say what happens when only one *named* index argument is
> given.  from the above, it would indeed seem that there is a *bug*
> here:  in the last example above only one index is given, and yet
> columns are not selected, even though the *language definition* says
> they should.  (so it's not a documented feature, it's a
> contra-definitional misfeature -- a bug?)
>
> somewhat on the side, the 'matrix-like indexing' above is fairly
> misleading;  just try the same patterns of indexing -- one index, two
> indices, named indices -- on a data frame and a matrix of the same shape:
>
>     m = matrix(1:9, 3, 3)
>     md = data.frame(m)
>
>     md[1]
>     # the first column
>     m[1]
>     # the first element (i.e., m[1,1])
>
>     md[,i=3]
>     # third row
>     m[,i=3]
>     # third column
>
>
> the quote above refers to the ?'[.data.frame' for details. 
> unfortunately, it the help page a lump of explanations for various
> '['-like operators, and it is *not* a definition of any sort.  it does
> not provide much more detail on '[.data.frame' -- it is hardly as a
> design specification.  in particular, it does not explain the issue of
> named arguments to '[.data.frame' at all.
>
>
> `[.data.frame` only is called with two arguments in the second case,  
>   
>> so
>> the following condition is true:
>>
>> if(Narg < 3L) {  # list-like indexing or matrix indexing
>>
>> And then, the function assumes the argument it has been passed is i,  
>> and
>> eventually calls NextMethod("[") which I think calls
>> `[.listof`(x,i,...), since i is missing in `[.data.frame` it is not
>> passed to `[.listof`, so you have something equivalent to as.list(d) 
>> [].
>>
>> I think we can replace the condition with this one:
>>
>> if(Narg < 3L && !has.j) {  # list-like indexing or matrix indexing
>>
>> or this:
>>
>> if(Narg < 3L) {  # list-like indexing or matrix indexing
>>        if(has.j) i <- j
>>
>>     
>
>
> indeed, for a moment i thought a trivial fix somewhere there would
> suffice.  unfortunately, the code for [.data.frame [2, lines 500-641] is
> so clean and readable that i had to give up reading it, forget fixing. 
> instead, i wrote an new version of '[.data.frame' from scratch.  it
> fixes (or at least seems to fix, as far as my quick assessment goes) the
> problem.  the function subdf (see the attached dataframe.r) is the new
> version of '[.data.frame':
>
>     # dummy data frame
>     d = structure(names=paste('col', 1:3, sep='.'),
>         data.frame(row.names=paste('row', 1:3, sep='.'),
>            matrix(1:9, 3, 3)))
>
>     d[j=1:2]
>     # incorrect: the whole data frame
>
>     subdf(d, j=1:2)
>     # correct, only the first two columns
>
> otherwise, subdf returns results equivalent (sensu all.equal;  see
> below) to those returned by [.data.frame on the same input, modulo some
> more or less minor details.  for example, i think the dropped-drop
> warnings go wrong in the original:
>
>     d[1, drop=FALSE]
>     # warning: drop argument will be ignored
>
> which suggests that dimensions will be dropped, while the intention is
> that the actual argument will be ignored and the value will be FALSE
> instead (while the default is TRUE, since i is specified).  well, it's
> just one more confusing bit in r.  the rewritten version warns about
> dropped drop only if it is explicitly TRUE:
>
>     subdf(d, 1, drop=FALSE)
>     # no warning
>     subdf(d, 1, drop=TRUE)
>     # warning
>
> another issue the differs in my version is that i don't see much sense
> in being able to select rows by indexing with NA:
>
>     d[NA,1]
>     # one row filled with NAs
>
>     d[NA,]
>     # data frame of the shape of d, filled with NAs
>
> which is incoherent with how NA are treated in columns indices (i.e.,
> raise an error).  the rewritten version raises an error if any element
> of any index is an NA.
>
> these minor differences are easily modifiable should compliance with the
> original 'design' be desirable.
>
> interestingly, there is a reduction in code by some 40 lines (~30%) wrt.
> the original, even though the new code is quite redundant (but thus were
> the original, too).  with a little effort, it can be compressed further,
> but i felt it would become more convoluted and less readable, and also
> less efficient.  procedural abstraction could help, but would also
> negatively impact performance.  (presumably, an implementation in c
> would run faster.)
>
> incidentally (here's the best part!), my version seems to perform much
> better than the original, at least in a limited set of naive
> benchmarks.  here are some results, which you can (hopefully) reproduce
> using the code in the attached test.r.  the data is a dummy df with 1k
> rows and 1k columns, filled with rnorm;  each indexing was repeated 1000
> times for both the original and the modified version:
>
>    original patched ratio   test                                    
> 1  0.002    0.001      2.00 d[]                                     
> 2  0.027    0.001     27.00 d[drop = FALSE]                         
> 3  0.025    0.002     12.50 d[drop = TRUE]                          
> 4  0.026    0.002     13.00 d[, drop = FALSE]                       
> 5  0.026    0.003      8.67 d[, drop = TRUE]                        
> 6  1.274    0.002    637.00 d[, ]                                   
> 7  1.255    0.001   1255.00 d[, , ]                                 
> 8  1.183    0.001   1183.00 d[, , drop = FALSE]                     
> 9  1.183    0.003    394.33 d[, , drop = TRUE]                      
> 10 0.013    0.011      1.18 d[r]                                    
> 11 0.040    0.034      1.18 d[r, drop = TRUE]                       
> 12 0.037    0.010      3.70 d[r, drop = FALSE]                      
> 13 0.012    0.011      1.09 d[i = r]                                
> 14 0.036    0.034      1.06 d[i = r, drop = TRUE]                   
> 15 0.037    0.011      3.36 d[i = r, drop = FALSE]                  
> 16 0.222    0.163      1.36 d[rr]                                   
> 17 0.247    0.112      2.21 d[rr, drop = FALSE]                     
> 18 0.204    0.144      1.42 d[rr, drop = TRUE]                      
> 19 0.174    0.120      1.45 d[i = rr]                               
> 20 0.201    0.125      1.61 d[i = rr, drop = FALSE]                 
> 21 0.215    0.147      1.46 d[i = rr, drop = TRUE]                  
> 22 2.266    1.159      1.96 d[rr, ]                                 
> 23 2.236    1.164      1.92 d[rr, , drop = FALSE]                   
> 24 2.275    1.171      1.94 d[rr, , drop = TRUE]                    
> 25 2.269    1.165      1.95 d[i = rr, ]                             
> 26 2.264    1.155      1.96 d[i = rr, , drop = FALSE]               
> 27 2.290    1.189      1.93 d[i = rr, , drop = TRUE]                
> 28 2.301    1.198      1.92 d[, i = rr]                             
> 29 2.239    1.158      1.93 d[, i = rr, drop = FALSE]               
> 30 2.310    1.161      1.99 d[, i = rr, drop = TRUE]                
> 31 0.002    0.003      0.67 d[j = c]                                
> 32 0.026    0.011      2.36 d[j = c, drop = FALSE]                  
> 33 0.026    0.003      8.67 d[j = c, drop = TRUE]                   
> 34 0.001    0.111      0.01 d[j = cc]                               
> 35 0.025    0.110      0.23 d[j = cc, drop = FALSE]                 
> 36 0.025    0.111      0.23 d[j = cc, drop = TRUE]                  
> 37 0.243    0.051      4.76 d[rr, cc]                               
> 38 0.243    0.051      4.76 d[rr, cc, drop = FALSE]                 
> 39 0.244    0.050      4.88 d[rr, cc, drop = TRUE]                  
> 40 0.244    0.051      4.78 d[i = rr, cc]                           
> 41 0.243    0.050      4.86 d[i = rr, cc, drop = FALSE]             
> 42 0.244    0.051      4.78 d[i = rr, cc, drop = TRUE]              
> 43 0.243    0.052      4.67 d[cc, i = rr]                           
> 44 0.244    0.050      4.88 d[cc, i = rr, drop = FALSE]             
> 45 0.247    0.052      4.75 d[cc, i = rr, drop = TRUE]              
> 46 0.244    0.050      4.88 d[i = rr, j = cc]                       
> 47 0.244    0.051      4.78 d[i = rr, j = cc, drop = FALSE]         
> 48 0.244    0.051      4.78 d[i = rr, j = cc, drop = TRUE]          
> 49 0.244    0.051      4.78 d[j = cc, i = rr]                       
> 50 0.243    0.051      4.76 d[j = cc, i = rr, drop = FALSE]         
> 51 0.245    0.051      4.80 d[j = cc, i = rr, drop = TRUE]          
> 52 0.002    0.155      0.01 d[j = cn]                               
> 53 0.429    0.139      3.09 d[i = rn, j = cn]                       
> 54 1.791    0.690      2.60 d[i = c(TRUE, FALSE), j = c(FALSE, TRUE)]
>
> (note:  the benchmark relies on a feature of rbenchmark that i have just
> added, so you may need to download/update the package before trying.)
>
> in some tests, the difference is two orders of magnitude; in some it's a
> factor of 2-5;  in some there's no significant difference.  in only a
> few cases, the original is way faster (e.g., tests 34 and 52), but this
> is because the original is wrong there (it simply ignores the index, so
> no wonder).
>
> all the expressions above used in benchmarking were also used to test
> the equivalence of output from the original and the new version (see
> test.r again), and all of them were negative (no difference) -- except
> for the cases where the original was wrong.
>
>
> i'd consider making a patch for src/library/base/R/dataframe.R, but
> there's a hack here:  it seems that some code relies on some part of the
> 'design' that differs between the rewrite and the original, and the new
> code does not make (dataframe.R does, but then other sources fail). 
> anyway, sourcing the attached dataframe.R suffices for testing. 
>
> i will be happy to learn where my implementation, benchmarking, and/or
> result checking are naive or wrong in any way, as they surely are.
>
>
> vQ
>
>
>
> [1] http://cran.r-project.org/doc/manuals/R-lang.pdf
> [2] http://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Mar 28 19:47:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 28 Mar 2009 19:47:20 +0100
Subject: [Rd] [R] "[.data.frame" and lapply
In-Reply-To: <49CDF770.3010102@dbmail.com>
References: <0935362A-34E7-4711-B2F4-8FB72108950B@exeter.ac.uk>
	<49CB32C0.1010500@dbmail.com> <49CD44CD.4070009@idi.ntnu.no>
	<49CDF770.3010102@dbmail.com>
Message-ID: <49CE70B8.6070607@idi.ntnu.no>

Romain Francois wrote:
> Wacek Kusnierczyk wrote:
>> redirected to r-devel, because there are implementational details of
>> [.data.frame discussed here.  spoiler: at the bottom there is a fairly
>> interesting performance result.
>>
>> Romain Francois wrote:
>>  
>>> Hi,
>>>
>>> This is a bug I think. [.data.frame treats its arguments differently
>>> depending on the number of arguments.
>>>     
>>
>> you might want to hesitate a bit before you say that something in r is a
>> bug, if only because it drives certain people mad.  r is a carefully
>> tested software, and [.data.frame is such a basic function that if what
>> you talk about were a bug, it wouldn't have persisted until now.
>>   
> I did hesitate, and would be prepared to look the other way of someone
> shows me proper evidence that this makes sense.
>
> > d <- data.frame( x = 1:10, y = 1:10, z = 1:10 )
> > d[ j=1 ]
>    x  y  z
> 1   1  1  1
> 2   2  2  2
> 3   3  3  3
> 4   4  4  4
> 5   5  5  5
> 6   6  6  6
> 7   7  7  7
> 8   8  8  8
> 9   9  9  9
> 10 10 10 10
>
> "If a single index is supplied, it is interpreted as indexing the list
> of columns". Clearly this does not happen here, and this is because
> NextMethod gets confused.

obviously.  it seems that there is a bug here, and that it results from
the lack of clear design specification.

>
> I have not looked your implementation in details, but it misses array
> indexing, as in:

yes;  i didn't take it into consideration, but (still without detailed
analysis) i guess it should not be difficult to extend the code to
handle this.



>
> > d <- data.frame( x = 1:10, y = 1:10, z = 1:10 )
> > m <- cbind( 5:7, 1:3 )
> > m
>     [,1] [,2]
> [1,]    5    1
> [2,]    6    2
> [3,]    7    3
> > d[m]
> [1] 5 6 7
> > subdf( d, m )
> Error in subdf(d, m) : undefined columns selected

this should be easy to handle by checking if i is a matrix and then
indexing by its first column as i and the second as j.

>
> "Matrix indexing using '[' is not recommended, and barely
>     supported.  For extraction, 'x' is first coerced to a matrix. For
>     replacement a logical matrix (only) can be used to select the
>     elements to be replaced in the same way as for a matrix."

yes, here's how it's done (original comment):

    if(is.matrix(i))
        return(as.matrix(x)[i])  # desperate measures

and i can easily add this to my code, at virtually no additional expense.

it's probably not a good idea to convert x to a matrix, x would often be
much more data than the index matrix m, so it's presumably much more
efficient, on average, to fiddle with i instead.

there are some potentially confusing issues here:

    m = cbind(8:10, 1:3)
   
    d[m]
    # 3-element vector, as you could expect

    d[t(m)]
    # 6-element vector

t(m) has dimensionality inappropriate for matrix indexing (it has 3
columns), so it gets flattened into a vector;  however, it does not work
like in the case of a single vector index where columns would be selected:

    d[as.vector(t(m))]
    # error: undefined columns selected

i think it would be more appropriate to raise an error in a case like
d[t(m)].

furthermore, if a matrix is used in a two-index form, the matrix is
flattened again and is used to select rows (not elements, as in
d[t(m)]).  note also that the help page says that "for extraction, 'x'
is first coerced to a matrix".  it fails to explain that if *two*
indices are used of which at least one is a matrix, no coercion is
done.  that is, the matrix is again flattened into a vector, but here
[.data.frame forgets that it was a matrix (unlike in d[t(m)]):

    is(d[m])
    # a character vector, matrix indexing

    is(d[t(m)])
    # a character vector, vector indexing of elements, not columns

    is(d[m,])
    # a data frame, row indexing
   
and finally, the fact that d[m] in fact converts x (i.e., d) to a matrix
before the indexing means that the types of values in a some columns in
d may get coerced to another type:

    d[,2] = as.character(d[,2])
    is(d[,1])
    # integer vector
    is(d[,2])
    # character vector

    is(d[1:2, 1])
    # integer vector
    is(d[cbind(1:2, 1)])
    # character vector


for all it's worth, i think matrix indexing of data frames should be
dropped:

    d[m]
    # error: ...

 and if one needs it, it's as simple as

    as.matrix(d)[m]

where the conversion of d to a matrix is explicit.

on the side, [.data.frame is able to index matrices:

    '[.data.frame'(as.matrix(d), m)
    # same as as.matrix(d)[m]

which is, so to speak, nonsense, since '[.data.frame' is designed
specifically to handle data frames;  i'd expect an error to be raised
here (or a warning, at the very least).

to summarize, the fact that subdf does not handle matrix indices is not
an issue.  anyway, thanks for the comment!

best,
vQ


From mtmorgan at fhcrc.org  Sun Mar 29 06:06:27 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 28 Mar 2009 21:06:27 -0700
Subject: [Rd] Recent setClass fails where previous succeeded
Message-ID: <6ph7i29as70.fsf@gopher4.fhcrc.org>

These lines of code

setClass("A", representation(x="numeric"))
setMethod(initialize, "A", function(.Object, ...) stop("oops"))
setClass("B", representation("A"))

result in

> setClass("B", representation("A"))
Error in initialize(value, ...) : oops

in

R version 2.9.0 alpha (2009-03-28 r48239)
R version 2.10.0 Under development (unstable) (2009-03-28 r48239) 

but not in r48182. 

In addition, in package code, the error above does NOT lead to removal
of the partially installed package, or of the lock on the package
directory, corrupting the user installation.

For more context, the actual code adds arguments to initialize and
expects them to be provided by calls to 'new'; 'new' is not exposed
directly to the user but via a constructor that always provides
appropriate arguments. A specific example occurs when trying to
install the package Biostrings v 2.11.44 from the Bioconductor devel
repository.

Martin
-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From manikandan_narayanan at merck.com  Fri Mar 27 03:18:34 2009
From: manikandan_narayanan at merck.com (manikandan_narayanan at merck.com)
Date: Fri, 27 Mar 2009 03:18:34 +0100 (CET)
Subject: [Rd] read.table on long lines buggy (PR#13626)
Message-ID: <20090327021834.46F35282EFF0@mail.pubhealth.ku.dk>

Full_Name: Manikandan Narayanan
Version: 2.8.1
OS: linux-gnu
Submission from: (NULL) (155.91.28.231)


Hi R-folks, 
  I have two three-line text files: tst1, tst2 (they are the same except that
the second line is longer in tst1; see cat() cmds below). 

  read.table is only able to read the 3rd line in tst1, however reads tst2
correctly as shown below. This happens both in R 2.5.1 (windows) and R 2.8.1
(linux-gnu). 

  Seems to be an issue with read.table operating on long lines. It caused me
quite some trouble before uncovering this one from reading a bigger file I had!
Please take care of this one or suggest me safer ways of working with long
lines!

Thanks,  
Mani

> cat(file="tst1", "a:15S_RRNA, 21S_RRNA, AAC1, AAC3\nb:AAP1, ACN9, ALG1, ALG11,
ALG12, ALG13, ALG14, ALG2, ALG3, ALG5, ALG6, ALG7, ALG8, ALG9, AMS1, ANP1, ARA1,
ATH1, BCH1, BCH2, BMH1, BMH2, BNI4, BUD7, CAX4, CDC19, CHS3, CHS5, CHS6, CHS7,
CIT2, CTS1, CWH41, DDP1, DIE2, DIP5, DLD1, DOG1, DOG2, DPM1, ELM1, ENO1, ENO2,
EOS1, ERD1, EXG1, FBA1, FBP1, FBP26, FDH1, FKS1, GAC1, GAL1, GAL10, GAL2, GAL3,
GAL4, GAL7, GAL80, GCY1, GDA1, GDB1, GFA1, GIP2, GLC3, GLC7, GLC8, GLG1, GLG2,
GLK1, GLO2, GLO4, GNA1, GND1, GND2, GNT1, GPH1, GPM1, GRE3, GSC2, GSY1, GSY2,
GTB1, GUT2, HAP4, HKR1, HOC1, HOR2, HPF1, HXK1, HXK2, HXT4, ICL1, IMP2', INM1,
INM2, ITR1, KAR2, KEG1, KNH1, KRE2, KRE5\nc:ABC1")
> read.table("tst1", sep=":", stringsAsFactors=F)[,1]
[1] "c"
Warning message:
In read.table("tmp1", sep = ":", stringsAsFactors = F) :
  incomplete final line found by readTableHeader on 'tmp1'

> cat(file="tst2", "a:15S_RRNA, 21S_RRNA, AAC1, AAC3\nb:AAP1, ACN9, ALG1, ALG11,
ALG12, ALG13, ALG14, ALG2, ALG3, ALG5, ALG6, ALG7, ALG8, ALG9, AMS1, ANP1, ARA1,
ATH1, BCH1, BCH2, BMH1, BMH2, BNI4, BUD7, CAX4, CDC19, CHS3, CHS5, CHS6, CHS7,
CIT2, CTS1, CWH41, DDP1, DIE2, DIP5, DLD1, DOG1, DOG2, DPM1, ELM1, ENO1, ENO2,
EOS1, ERD1, EXG1, FBA1, FBP1, FBP26, FDH1, FKS1, GAC1, GAL1, GAL10, GAL2, GAL3,
GAL4, GAL7, GAL80, GCY1, GDA1, GDB1, GFA1, GIP2, GLC3, GLC7, GLC8, GLG1, GLG2,
GLK1, GLO2, GLO4, GNA1, GND1, GND2, GNT1, GPH1\nc:ABC1\n")
> read.table("tst2", sep=":", stringsAsFactors=F)[,1]
[1] "a" "b" "c"


From oetzel at wiwi.uni-frankfurt.de  Fri Mar 27 09:17:00 2009
From: oetzel at wiwi.uni-frankfurt.de (soetzel)
Date: Fri, 27 Mar 2009 01:17:00 -0700 (PDT)
Subject: [Rd]  prediction in DPpackage
Message-ID: <22737533.post@talk.nabble.com>


Hallo,

I?m using the the DPpackage to estimate a Bayesian semiparametric
generalized additive model with the PSgam-command. 

To compare the estimator with other estimators, I want to compare the mean
squared error 
for in sample and out-of sample predictions. For linear models, I typically
use the 
?fitted?-command to estimate the fitted values. Unfortunately, this command
does not work 
with the PSgam.

Is there chance to get fitted value in sample and out sample with your
package?

I would greatly appreciate your response!

Sebastian
-- 
View this message in context: http://www.nabble.com/prediction-in-DPpackage-tp22737533p22737533.html
Sent from the R devel mailing list archive at Nabble.com.


From waku at idi.ntnu.no  Sat Mar 28 09:40:15 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Sat, 28 Mar 2009 09:40:15 +0100 (CET)
Subject: [Rd] Incorrect behaviour of [.data.frame (PR#13628)
Message-ID: <20090328084015.0FF19282C768@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.8.0 and 2.10.0 r48231
OS: Ubuntu 8.04 Linux 32 bit
Submission from: (NULL) (80.202.30.36)


According to the R Language definition (sec. 3.4.3), [.data.frame has the
following properties:

"if two indices are supplied (even if one is empty) it creates matrix-like
indexing for a structure that is basically a list of vectors of the same length.
If a single index is supplied, it is interpreted as indexing the list of
columns?in that case the drop argument is ignored, with a warning."

A similar explanation is given in ?'[.data.frame'.  However, in specific cases,
this is not how [.data.frame works:

   # dummy demo data frame
   d = data.frame(matrix(1:9, 3, 3))

   d[j=1]
   # the whole data frame

The example illustrates behaviour that is incorrect wrt. the documentation: 
only a single index is given, but it is not that the respective columns are
selected.

This might be an implementational bug (i.e., the function ignores the argument
because it is explicitly named 'j', and ignores the argument j because only one
index is given); in which case the implementation should be improved.

This might also be an intended feature that is not appropriately documented; in
which case the documentation should be improved.

It is hard for me to judge which is the case, because there is no clear
specification of what [.data.frame should do in specific situations.

Regards,
Wacek


From waku at idi.ntnu.no  Sun Mar 29 01:20:11 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Sun, 29 Mar 2009 01:20:11 +0100 (CET)
Subject: [Rd] Another incorrect behaviour of [.data.frame (PR#13629)
Message-ID: <20090329002011.BFB34282C76F@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.8.0 and 2.10.0 r48231
OS: Ubuntu 8.04 Linux 32 bit
Submission from: (NULL) (129.241.198.65)


In a previous report (Incorrect behaviour of [.data.frame (PR#13628), awaiting
approval) I showed that [.data.frame behaves incorrectly (i.e., in contradiction
to what ?'[.data.frame' and the R Language Definition say):

   d = data.frame(a=1:3, b=4:6)
   d[j=2]
   # returns the whole data frame, not just the second column

There appears to be one more issue with [.data.frame:

   d[x=1]
   # a list, not a data frame

and also

   d[x=1:2]
   # returns a *list* with the contents of the two columns of d

The argument 'x' is a legal argument to [.data.frame.  What happens here is that
[.data.frame receives 1:2 as the argument 'x' (because of name-based argument
matching) and d as the argument 'i' (because of subsequent positional argument
matching).  When [.data.frame calls NextMethod('['), a list is returned, and
then [.data.frame wraps the list into a structure as follows:

   return(structure(y, class = oldClass(x), 
      row.names = .row_names_info(x, 0L)))

(src/library/base/r/dataframe.R:531-532)  since x is 1:2 and oldClass(1:2) is
NULL, the structure is a list and not a data frame, and thus the final result.

The result is clearly incorrect wrt. the documentation:  

- there should be no dimension dropping when only one index is given (even if
drop=TRUE; the list-like indexing d[i], line 507 in the source);

- there should be no dimension dropping if more than one column is selected.

Furthermore, even the fact that d[x=1:2] succeeds is surprising:  [.data.frame
should try to select from 1:2 using d as an index, which should fail.  It seems
that the call to NextMethod incorrectly matches the arguments, and receives the
first (unnamed) argument of [.data.frame (which is d) as the data frame and the
second argument (named 'x', which is 1:2) as the index, and returns a list of
columns instead of raising an error.

Regards,
vQ


From jmc at r-project.org  Sun Mar 29 20:09:46 2009
From: jmc at r-project.org (John Chambers)
Date: Sun, 29 Mar 2009 11:09:46 -0700
Subject: [Rd] Recent setClass fails where previous succeeded
In-Reply-To: <6ph7i29as70.fsf@gopher4.fhcrc.org>
References: <6ph7i29as70.fsf@gopher4.fhcrc.org>
Message-ID: <49CFB96A.7010400@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090329/c527322e/attachment.pl>

From cstrato at aon.at  Sun Mar 29 21:31:05 2009
From: cstrato at aon.at (cstrato)
Date: Sun, 29 Mar 2009 21:31:05 +0200
Subject: [Rd] Compiler options for Makefile.win
Message-ID: <49CFCC79.9090409@aon.at>

Dear all,

For certain reasons I have to compile the source code of my package on 
Windows XP using Microsoft Visual Studio 9.0, thus I had to create a 
"Makefile.win". Now I have a question regarding compiler options /MT vs 
/MD for Makefile.win.

The following partial output shows that when building my package on 
Windows XP using "R CMD build --binary xps" with compiler option /MT 
everything is ok:

- - - - - - - -
  running src/Makefile.win ...
"C:\Programme\Microsoft Visual Studio 9.0\VC\bin/cl" /I"C:\root/include" 
/FIw32p
ragma.h /MT /EHsc /Ox /D "MSVC" /D "WIN32" /c TStat.cxx
Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 15.00.21022.08 
for 80x86
Copyright (C) Microsoft Corporation.  All rights reserved.

TStat.cxx


Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,304 bytes
Compression decreased file by 442,728 bytes.
** building package indices ...
** MD5 sums
* DONE (xps)
* creating vignettes ... OK
* cleaning src


Created c:\home\Rabbitus\temp\Rbuild210430099\xps\chm\xps.chm, 166,308 bytes
Compression decreased file by 442,724 bytes.
** building package indices ...
** MD5 sums
packaged installation of 'xps' as xps_1.3.8.zip
* DONE (xps)
- - - - - - - -

As you see the package was built correctly.


However, when I change the compiler option in "Makefile.win" to /MD the 
build stops at the following position:

- - - - - - - -
Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,306 bytes
Compression decreased file by 442,726 bytes.
** building package indices ...
** MD5 sums
* DONE (xps)
* creating vignettes ...Terminating on signal SIGINT(2)
- - - - - - - -

As you see I had to terminate the build process manually after 15 min .

My question is now:
Do you know why I can build my package w/o problems when using option 
/MT but not when using option /MD?

As a note, I am using "R-2.9.0alpha-win32.exe" which I have downloaded 
today.

Thank you in advance.

Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From waku at idi.ntnu.no  Sun Mar 29 22:40:11 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Sun, 29 Mar 2009 22:40:11 +0200 (CEST)
Subject: [Rd] if does not covert raw to logical (PR#13630)
Message-ID: <20090329204012.04223282C76F@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.8.0 and 2.10.0 r48242
OS: Ubuntu 8.04 Linux 32 bit
Submission from: (NULL) (80.202.30.36)


The following raises an error:

   if (as.raw(1)) 1
   # error: unimplemented type 'raw' in 'asLogical'

However, ?'if' says:

" 
Arguments:

    cond: A length-one logical vector that is not 'NA'. Conditions of
          length greater than one are accepted with a warning, but only
          the first element is used.  Other types are coerced to
          logical if possible, ignoring any class. 
"

and the help page does not mention raw type arguments to 'if' at all. 

The error above is in clear contradiction to the documentation.  This might be a
flaw in the documentation, but the following succeeds:

   ifelse(raw(1), 1, 0)
   # 1

which suggests that the error above is a bug (i.e., the implementation fails to
convert raw to logical).

The same problem involves 'while':

   while(as.raw(1)) break
   # error: unimplemented type 'raw' in 'asLogical'

Regards,
vQ


From Rob.Hyndman at buseco.monash.edu.au  Sun Mar 29 23:43:33 2009
From: Rob.Hyndman at buseco.monash.edu.au (Rob Hyndman)
Date: Mon, 30 Mar 2009 08:43:33 +1100
Subject: [Rd] Error in help file for quantile()
Message-ID: <905db6ff0903291443u34583052m8899dcbf77fba034@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090330/c912cbf5/attachment.pl>

From Ted.Harding at manchester.ac.uk  Mon Mar 30 00:08:52 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Sun, 29 Mar 2009 23:08:52 +0100 (BST)
Subject: [Rd] Error in help file for quantile()
In-Reply-To: <905db6ff0903291443u34583052m8899dcbf77fba034@mail.gmail.com>
Message-ID: <XFMail.090329230852.Ted.Harding@manchester.ac.uk>

On 29-Mar-09 20:43:33, Rob Hyndman wrote:
> For some reason, the help file on quantile() says "Missing values are
> ignored" in the description of the x argument. Yet this is only true
> if na.rm=TRUE. I suggest the help file is amended to remove the words
> "Missing values are ignored".
> Rob

True enough -- in that if, as in the default, na.rm == FALSE,
then applying quantile() to a vector with NAs yields the error
message:

quantile(X1)
# Error in quantile.default(X1) : 
#   missing values and NaN's not allowed if 'na.rm' is FALSE

So either you have na.rm==TRUE, in which case it doesn't need
saying that "Missing values are ignored" (unless you really
want to spell it out in the form "Missing values are ignored if
called with na.rm=TRUE; otherwise an error message is produced"),
or you have na.rm==FALSE, in which case you get the error message
and know where you stand.

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 29-Mar-09                                       Time: 23:08:50
------------------------------ XFMail ------------------------------


From murdoch at stats.uwo.ca  Mon Mar 30 00:27:58 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Mar 2009 18:27:58 -0400
Subject: [Rd] Error in help file for quantile()
In-Reply-To: <905db6ff0903291443u34583052m8899dcbf77fba034@mail.gmail.com>
References: <905db6ff0903291443u34583052m8899dcbf77fba034@mail.gmail.com>
Message-ID: <49CFF5EE.9050303@stats.uwo.ca>

On 29/03/2009 5:43 PM, Rob Hyndman wrote:
> For some reason, the help file on quantile() says "Missing values are
> ignored" in the description of the x argument. Yet this is only true
> if na.rm=TRUE. I suggest the help file is amended to remove the words
> "Missing values are ignored".

Thanks, I'll fix that.

Duncan Murdoch


From saptarshi.guha at gmail.com  Mon Mar 30 03:45:43 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 29 Mar 2009 21:45:43 -0400
Subject: [Rd] Setting the names attribute of a list?
Message-ID: <1e7471d50903291845n1d37356i57ec2124ebc5047e@mail.gmail.com>

Hello,
I have created a vector with 2 elements(see code below)
I am calling this function many thousands of times (hundreds of
thousands) after some time
i get
 *** caught segfault ***
address 0x5, cause 'memory not mapped'
However, if i dont set the R_NamesSymbol, I do not get any such error.
Am I doing this correctly?

Thank you
Saptarshi

==CODE===

// kxp and usar are two SEXP's which have not been protected
SEXP res
PROTECT(res);
res= allocVector(VECSXP, 2);
SET_VECTOR_ELT(res,0,kxp);
SET_VECTOR_ELT(res,1,usar);

names=allocVector(VECSXP,2);PROTECT(names); //A
SET_VECTOR_ELT(names, 0, mkChar("key")); //A
SET_VECTOR_ELT(names, 1, mkChar("value")); //A
setAttrib(res, R_NamesSymbol,names); //A
UNPROTECT(2);
return(res);


Saptarshi Guha


From saptarshi.guha at gmail.com  Mon Mar 30 04:28:12 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 29 Mar 2009 22:28:12 -0400
Subject: [Rd] Setting the names attribute of a list?
In-Reply-To: <6ph8wmnrcnm.fsf@gopher4.fhcrc.org>
References: <1e7471d50903291845n1d37356i57ec2124ebc5047e@mail.gmail.com>
	<6ph8wmnrcnm.fsf@gopher4.fhcrc.org>
Message-ID: <1e7471d50903291928x3164f1a3yf10b180daee5fb6d@mail.gmail.com>

Much thanks. I was protecting the pointer and not what it was pointing to.
The reason I wasn't protecting kxp,usar was because the R external
manual mentioned

5.9.1 Handling the effects of garbage collection
"Protecting an R object automatically protects all the R objects
pointed to in the corresponding SEXPREC, for example all elements of a
protected list are automatically protected."

Before protecting res in the  correct manner, I tried
a) not protecting usar, kxp
b) protecting usar,kxp
In (a), R hung, i.e nothing happened, just got stuck in a call, with
(b) I succesffuly ran it 4MM times.

Have I mis-understood the 5.9.1?

Thanks for your inputs.
Saptarshi Guha



On Sun, Mar 29, 2009 at 10:02 PM, Martin Morgan <mtmorgan at fhcrc.org> wrote:

>> // kxp and usar are two SEXP's which have not been protected
>> SEXP res
>> PROTECT(res);
>> res= allocVector(VECSXP, 2);
>
> usually you would not want to allocate when there are unprotected
> variables, so kxp, usar should be protected before this...
>
> You want to protect the result of the allocation, not the location of
> the variable, i.e.,
>
> PROTECT(res = allocVector(VECSXP, 2));
>
>> SET_VECTOR_ELT(res,0,kxp);
>> SET_VECTOR_ELT(res,1,usar);
>>
>> names=allocVector(VECSXP,2);PROTECT(names); //A
>> SET_VECTOR_ELT(names, 0, mkChar("key")); //A
>> SET_VECTOR_ELT(names, 1, mkChar("value")); //A
>> setAttrib(res, R_NamesSymbol,names); //A
>> UNPROTECT(2);
>> return(res);
>>
>>
>> Saptarshi Guha
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Martin Morgan
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M2 B169
> Phone: (206) 667-2793
>


From saptarshi.guha at gmail.com  Mon Mar 30 05:23:58 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 29 Mar 2009 23:23:58 -0400
Subject: [Rd] CTRL-C during .Call causes R to quit to command line
Message-ID: <1e7471d50903292023y415529bcmdc0467139df17da@mail.gmail.com>

Hello,
During a .Call e.g
while(TRUE){
    value <-rhsqnextKVR(rdr)  ## has .Call in this function
    if(is.null(value)) break;
  }
if I press CTRL-C, R exits straight to the command line.

Q: How can I prevent this? I should point out that my library uses
JNI, so I'm not sure if that is causing it.
I'm using R-2.8 on Linux (RHEL 5)
Thank you in advance
Regards
Saptarshi


From osklyar at maninvestments.com  Mon Mar 30 11:09:28 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Mon, 30 Mar 2009 10:09:28 +0100
Subject: [Rd] CTRL-C during .Call causes R to quit to command line
In-Reply-To: <1e7471d50903292023y415529bcmdc0467139df17da@mail.gmail.com>
References: <1e7471d50903292023y415529bcmdc0467139df17da@mail.gmail.com>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF7B2@mildnpexmb01.maninvestments.ad.man.com>

If you use JNI or rJava, you should start the VM with -Xrs argument,
otherwise the descibed things happen as Java catches the Ctrl-C
interrupt

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Saptarshi Guha
> Sent: 30 March 2009 04:24
> To: r-devel at r-project.org
> Subject: [Rd] CTRL-C during .Call causes R to quit to command line
> 
> Hello,
> During a .Call e.g
> while(TRUE){
>     value <-rhsqnextKVR(rdr)  ## has .Call in this function
>     if(is.null(value)) break;
>   }
> if I press CTRL-C, R exits straight to the command line.
> 
> Q: How can I prevent this? I should point out that my library uses
> JNI, so I'm not sure if that is causing it.
> I'm using R-2.8 on Linux (RHEL 5)
> Thank you in advance
> Regards
> Saptarshi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From sgiannerini at gmail.com  Mon Mar 30 12:15:15 2009
From: sgiannerini at gmail.com (sgiannerini at gmail.com)
Date: Mon, 30 Mar 2009 12:15:15 +0200 (CEST)
Subject: [Rd] quantile and IQR do not check for numeric input (PR#13631)
Message-ID: <20090330101515.2C6BB2832198@mail.pubhealth.ku.dk>

This report follows the post

http://tolstoy.newcastle.edu.au/R/e6/devel/09/03/0760.html

where it is shown that quantile() and IQR() do not work as documented.
In fact they do not check for numeric input even if the documentation says =
:

?quantile
x      numeric vectors whose sample quantiles are wanted. Missing
values are ignored.

?IQR

x 	a numeric vector.

> quantile(factor(1:9))
  0%  25%  50%  75% 100%
   1    3    5    7    9
Levels: 1 2 3 4 5 6 7 8 9

> IQR(factor(1:9))
[1] 4

> R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         alpha
major          2
minor          9.0
year           2009
month          03
day            26
svn rev        48224
language       R
version.string R version 2.9.0 alpha (2009-03-26 r48224)

--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126 =A0Bologna, =A0ITALY
Tel: +39 051 2098262 =A0Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From tlumley at u.washington.edu  Mon Mar 30 13:50:56 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 30 Mar 2009 04:50:56 -0700 (PDT)
Subject: [Rd] quantile and IQR do not check for numeric input (PR#13631)
In-Reply-To: <20090330101515.2C6BB2832198@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0903300450560.15385@hymn12.u.washington.edu>

On Mon, 30 Mar 2009 sgiannerini at gmail.com wrote:

> This report follows the post
>
> http://tolstoy.newcastle.edu.au/R/e6/devel/09/03/0760.html
>
> where it is shown that quantile() and IQR() do not work as documented.

Nothing of the sort is shown! The thread argued that methods for these functions for ordered factors would be useful.

> In fact they do not check for numeric input even if the documentation says =
> :
>
> ?quantile
> x      numeric vectors whose sample quantiles are wanted. Missing
> values are ignored.
>
> ?IQR
>
> x 	a numeric vector.
>

The documentation says that you are not allowed to pass anything except a numeric vector to quantile() and IQR(). It doesn't, for example, say you can pass an arbitrary vector that will be checked to see if it is numeric. If you have code that passes a factor to IQR(), the bug is in that code.

On the other hand, as someone else has since reported, the 'missing values are ignored' statement in ?quantile is wrong (or at least incomplete).


     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From murdoch at stats.uwo.ca  Mon Mar 30 14:16:25 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 30 Mar 2009 08:16:25 -0400
Subject: [Rd] quantile and IQR do not check for numeric input (PR#13631)
In-Reply-To: <Pine.LNX.4.43.0903300450560.15385@hymn12.u.washington.edu>
References: <Pine.LNX.4.43.0903300450560.15385@hymn12.u.washington.edu>
Message-ID: <49D0B819.9000907@stats.uwo.ca>

On 3/30/2009 7:50 AM, Thomas Lumley wrote:
> On Mon, 30 Mar 2009 sgiannerini at gmail.com wrote:
> 
>> This report follows the post
>>
>> http://tolstoy.newcastle.edu.au/R/e6/devel/09/03/0760.html
>>
>> where it is shown that quantile() and IQR() do not work as documented.
> 
> Nothing of the sort is shown! The thread argued that methods for these functions for ordered factors would be useful.
> 
>> In fact they do not check for numeric input even if the documentation says =
>> :
>>
>> ?quantile
>> x      numeric vectors whose sample quantiles are wanted. Missing
>> values are ignored.
>>
>> ?IQR
>>
>> x 	a numeric vector.
>>
> 
> The documentation says that you are not allowed to pass anything except a numeric vector to quantile() and IQR(). It doesn't, for example, say you can pass an arbitrary vector that will be checked to see if it is numeric. If you have code that passes a factor to IQR(), the bug is in that code.
> 
> On the other hand, as someone else has since reported, the 'missing values are ignored' statement in ?quantile is wrong (or at least incomplete).

I think that statement was wrong, and I fixed it last night, but then 
didn't get it committed.  The commit will make it into 2.9 and R-devel 
today.

Duncan Murdoch


From sgiannerini at gmail.com  Mon Mar 30 14:57:36 2009
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 30 Mar 2009 14:57:36 +0200
Subject: [Rd] quantile and IQR do not check for numeric input (PR#13631)
In-Reply-To: <Pine.LNX.4.43.0903300450560.15385@hymn12.u.washington.edu>
References: <20090330101515.2C6BB2832198@mail.pubhealth.ku.dk>
	<Pine.LNX.4.43.0903300450560.15385@hymn12.u.washington.edu>
Message-ID: <3c12769c0903300557v7c5c3d8cp927b3f3273561300@mail.gmail.com>

Dear Thomas,

On Mon, Mar 30, 2009 at 1:50 PM, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Mon, 30 Mar 2009 sgiannerini at gmail.com wrote:
>
>> This report follows the post
>>
>> http://tolstoy.newcastle.edu.au/R/e6/devel/09/03/0760.html
>>
>> where it is shown that quantile() and IQR() do not work as documented.
>
> Nothing of the sort is shown! The thread argued that methods for these
> functions for ordered factors would be useful.

in the original thread  I initiated the matters were two (at least in
my intention)

1. quantile() and IQR() do not check for numeric input whereas
median() has a check (for a factor input). This has nothing to deal
with ordered factors

2. the opportunity of having methods for ordered factors for
quantile() and the like.

If, for some reason, you think that it is ok to have such check for
median but not for quantile and IQR then take this as a wishlist. BTW
also var() and the like do not check for factor input while mean() has
the check.

> x <- factor(letters[1:9])
> x
[1] a b c d e f g h i
Levels: a b c d e f g h i
> mean(x)
[1] NA
Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
> var(x)
[1] 7.5


Regards

Simone

>
>> In fact they do not check for numeric input even if the documentation says
>> =
>> :
>>
>> ?quantile
>> x ? ? ?numeric vectors whose sample quantiles are wanted. Missing
>> values are ignored.
>>
>> ?IQR
>>
>> x ? ? ? a numeric vector.
>>
>
> The documentation says that you are not allowed to pass anything except a
> numeric vector to quantile() and IQR(). It doesn't, for example, say you can
> pass an arbitrary vector that will be checked to see if it is numeric. If
> you have code that passes a factor to IQR(), the bug is in that code.
>
> On the other hand, as someone else has since reported, the 'missing values
> are ignored' statement in ?quantile is wrong (or at least incomplete).
>
>
> ? ?-thomas
>
> Thomas Lumley ? ? ? ? ? ? ? ? ? Assoc. Professor, Biostatistics
> tlumley at u.washington.edu ? ? ? ?University of Washington, Seattle
>
>
>



-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153
http://www2.stat.unibo.it/giannerini/


From waku at idi.ntnu.no  Mon Mar 30 15:10:10 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Mon, 30 Mar 2009 15:10:10 +0200 (CEST)
Subject: [Rd] duplicated fails to rise correct errors (PR#13632)
Message-ID: <20090330131010.37554283218B@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.8.0 and 2.10.0 r48242
OS: Ubuntu 8.04 Linux 32 bit
Submission from: (NULL) (129.241.110.161)


In the following code:

   duplicated(data.frame(), incomparables=NA)
   # Error in if (!is.logical(incomparables) || incomparables)
.NotYetUsed("incomparables != FALSE") : 
   # missing value where TRUE/FALSE needed

the raised error is clearly not the one intended to be raised.

?duplicated says:

"
incomparables: a vector of values that cannot be compared. 'FALSE' is a
          special value, meaning that all values can be compared, and
          may be the only value accepted for methods other than the
          default.  It will be coerced internally to the same type as
          'x'.

(...)

     Values in 'incomparables' will never be marked as duplicated. This
     is intended to be used for a fairly small set of values and will
     not be efficient for a very large set.
"

However, in duplicated.data.frame (which is called when duplicated is applied to
a data frame, as above) the parameter 'incomparables' is defunct.  The
documentation fails to explain this, and it might be a good idea to improve it.

In the code for duplicated.data.frame there is an attempt to intercept any use
of the parameter 'incomparables' with a value other than FALSE and to raise an
appropriate error, but this attempt fails with, e.g., incomparables=NA.

Incidentally, the attempt to intercept incomparables != FALSE fails completely
(i.e., the call to duplicated succeeds) with certain inputs:

   duplicated(data.frame(logical=c(TRUE, TRUE)), incomparables=c(FALSE, TRUE))
   # [1] FALSE TRUE

while

   duplicated(c(TRUE, TRUE), incomparables=c(FALSE, TRUE))
   # [1] FALSE FALSE


Regards,
vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 30 15:18:25 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 30 Mar 2009 15:18:25 +0200
Subject: [Rd] duplicated fails to rise correct errors (PR#13632)
In-Reply-To: <20090330131010.37554283218B@mail.pubhealth.ku.dk>
References: <20090330131010.37554283218B@mail.pubhealth.ku.dk>
Message-ID: <49D0C6A1.30907@idi.ntnu.no>

the bug seems to have a trivial solution;  as far as i can see, it suffices to 
replace

    if (!is.logical(incomparables) || incomparables)

with

    if(!identical(incomparables, FALSE))

in all its occurrences in src/library/base/R/duplicated.R

attached is a patch created, successfully tested and installed on Ubuntu 8.04 
Linux 32 bit as follows:

    svn co https://svn.r-project.org/R/trunk trunk
    cd trunk
    # edit src/library/base/R/duplicated.R
    svn diff > duplicated.R.diff

    svn revert -R src
    patch -p0 < duplicated.R.diff
    tools/rsync-recommended
    ./configure
    make
    make check

and now

    duplicated(data.frame(), incomparables=NA)
    # error: argument 'incomparables != FALSE' is not used (yet)

regards,
vQ



Waclaw.Marcin.Kusnierczyk at idi.ntnu.no wrote:
> Full_Name: Wacek Kusnierczyk
> Version: 2.8.0 and 2.10.0 r48242
> OS: Ubuntu 8.04 Linux 32 bit
> Submission from: (NULL) (129.241.110.161)
>
>
> In the following code:
>
>    duplicated(data.frame(), incomparables=NA)
>    # Error in if (!is.logical(incomparables) || incomparables)
> .NotYetUsed("incomparables != FALSE") : 
>    # missing value where TRUE/FALSE needed
>
> the raised error is clearly not the one intended to be raised.
>
> ?duplicated says:
>
> "
> incomparables: a vector of values that cannot be compared. 'FALSE' is a
>           special value, meaning that all values can be compared, and
>           may be the only value accepted for methods other than the
>           default.  It will be coerced internally to the same type as
>           'x'.
>
> (...)
>
>      Values in 'incomparables' will never be marked as duplicated. This
>      is intended to be used for a fairly small set of values and will
>      not be efficient for a very large set.
> "
>
> However, in duplicated.data.frame (which is called when duplicated is applied to
> a data frame, as above) the parameter 'incomparables' is defunct.  The
> documentation fails to explain this, and it might be a good idea to improve it.
>
> In the code for duplicated.data.frame there is an attempt to intercept any use
> of the parameter 'incomparables' with a value other than FALSE and to raise an
> appropriate error, but this attempt fails with, e.g., incomparables=NA.
>
> Incidentally, the attempt to intercept incomparables != FALSE fails completely
> (i.e., the call to duplicated succeeds) with certain inputs:
>
>    duplicated(data.frame(logical=c(TRUE, TRUE)), incomparables=c(FALSE, TRUE))
>    # [1] FALSE TRUE
>
> while
>
>    duplicated(c(TRUE, TRUE), incomparables=c(FALSE, TRUE))
>    # [1] FALSE FALSE
>
>
> Regards,
> vQ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
-------------------------------------------------------------------------------
Wacek Kusnierczyk, MD PhD

Email: waku at idi.ntnu.no
Phone: +47 73591875, +47 72574609

Department of Computer and Information Science (IDI)
Faculty of Information Technology, Mathematics and Electrical Engineering (IME)
Norwegian University of Science and Technology (NTNU)
Sem Saelands vei 7, 7491 Trondheim, Norway
Room itv303

Bioinformatics & Gene Regulation Group
Department of Cancer Research and Molecular Medicine (IKM)
Faculty of Medicine (DMF)
Norwegian University of Science and Technology (NTNU)
Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
Room 231.05.060

-------------------------------------------------------------------------------

-------------- next part --------------
A non-text attachment was scrubbed...
Name: duplicated.R.diff
Type: text/x-diff
Size: 1536 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090330/c2595605/attachment.bin>

From maechler at stat.math.ethz.ch  Mon Mar 30 18:55:29 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon, 30 Mar 2009 18:55:29 +0200 (CEST)
Subject: [Rd] if does not covert raw to logical (PR#13630)
Message-ID: <20090330165529.121662832183@mail.pubhealth.ku.dk>

Thank you, Wacek,
for

>>>>> Wacek Kusnierczyk <waku at idi.ntnu.no>
>>>>>     on Sun, 29 Mar 2009 22:40:11 +0200 (CEST) writes:

    > Full_Name: Wacek Kusnierczyk
    > Version: 2.8.0 and 2.10.0 r48242
    > OS: Ubuntu 8.04 Linux 32 bit
    > Submission from: (NULL) (80.202.30.36)


    > The following raises an error:

    > if (as.raw(1)) 1
    > # error: unimplemented type 'raw' in 'asLogical'

    > However, ?'if' says:

    > " 
    > Arguments:

    > cond: A length-one logical vector that is not 'NA'. Conditions of
    > length greater than one are accepted with a warning, but only
    > the first element is used.  Other types are coerced to
    > logical if possible, ignoring any class. 
    > "

    > and the help page does not mention raw type arguments to 'if' at all. 

    > The error above is in clear contradiction to the documentation.  This might be a
    > flaw in the documentation, but the following succeeds:

    > ifelse(raw(1), 1, 0)
    > # 1

    > which suggests that the error above is a bug (i.e., the implementation fails to
    > convert raw to logical).

    > The same problem involves 'while':

    > while(as.raw(1)) break
    > # error: unimplemented type 'raw' in 'asLogical'

indeed, it was pretty straightforward hard to implement the missing case in
asLogical(.) and I will commit my patch to the sources tomorrow
{being busy otherwise for the rest of today}.

Note that  the  raw data type has been a newish addition to R a
while ago though,  and if you find further cases where
such raw objects do not "work" as documented,
we'd gladly accept further such reports.

Regards,
Martin Maechler, ETH Zurich


From kjetilbrinchmannhalvorsen at gmail.com  Mon Mar 30 20:40:03 2009
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Mon, 30 Mar 2009 14:40:03 -0400
Subject: [Rd] Gamma funtion(s) bug
Message-ID: <556e90a80903301140o28caffe2g16717cbf581f2953@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090330/56f22fc4/attachment.pl>

From Ted.Harding at manchester.ac.uk  Mon Mar 30 20:55:38 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Mon, 30 Mar 2009 19:55:38 +0100 (BST)
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <556e90a80903301140o28caffe2g16717cbf581f2953@mail.gmail.com>
Message-ID: <XFMail.090330195538.Ted.Harding@manchester.ac.uk>

On 30-Mar-09 18:40:03, Kjetil Halvorsen wrote:
> With R 2.8.1 on ubuntu I get:
>> gamma(-1)
> [1] NaN
> Warning message:
> In gamma(-1) : NaNs produced
>> lgamma(-1)
> [1] Inf
> Warning message:
> value out of range in 'lgamma'
> 
> Is'nt the first one right, and the second one (lgamma)
> should also be NaN?
> Kjetil

That is surely correct! Since lim[x->(-1)+] gamma(x) = +Inf,
while lim[x->(-1)-] gamma(x) = -Inf, at gamma(-1) one cannot
choose between +Inf and -Inf, so surely is is NaN.

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 30-Mar-09                                       Time: 19:55:33
------------------------------ XFMail ------------------------------


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Mar 30 22:15:24 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Waclaw.Marcin.Kusnierczyk at idi.ntnu.no)
Date: Mon, 30 Mar 2009 22:15:24 +0200 (CEST)
Subject: [Rd] if does not covert raw to logical (PR#13630)
Message-ID: <20090330201524.DB16E2832183@mail.pubhealth.ku.dk>

Martin Maechler wrote:
> Thank you, Wacek,
>   
happy to serve.
(...)
> indeed, it was pretty straightforward hard to implement the missing case in
> asLogical(.) and I will commit my patch to the sources tomorrow
> {being busy otherwise for the rest of today}.
>   

thanks!

> Note that  the  raw data type has been a newish addition to R a
> while ago though,  and if you find further cases where
> such raw objects do not "work" as documented,
> we'd gladly accept further such reports.
>   

yes, i'll keep sniffing.

best,
vQ


From murdoch at stats.uwo.ca  Mon Mar 30 22:37:51 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 30 Mar 2009 16:37:51 -0400
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <XFMail.090330195538.Ted.Harding@manchester.ac.uk>
References: <XFMail.090330195538.Ted.Harding@manchester.ac.uk>
Message-ID: <49D12D9F.1000203@stats.uwo.ca>

On 3/30/2009 2:55 PM, (Ted Harding) wrote:
> On 30-Mar-09 18:40:03, Kjetil Halvorsen wrote:
>> With R 2.8.1 on ubuntu I get:
>>> gamma(-1)
>> [1] NaN
>> Warning message:
>> In gamma(-1) : NaNs produced
>>> lgamma(-1)
>> [1] Inf
>> Warning message:
>> value out of range in 'lgamma'
>> 
>> Is'nt the first one right, and the second one (lgamma)
>> should also be NaN?
>> Kjetil
> 
> That is surely correct! Since lim[x->(-1)+] gamma(x) = +Inf,
> while lim[x->(-1)-] gamma(x) = -Inf, at gamma(-1) one cannot
> choose between +Inf and -Inf, so surely is is NaN.

But lgamma(x) is log(abs(gamma(x))), so it looks okay to me.

Duncan Murdoch


From Ted.Harding at manchester.ac.uk  Mon Mar 30 23:28:54 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Mon, 30 Mar 2009 22:28:54 +0100 (BST)
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <49D12D9F.1000203@stats.uwo.ca>
Message-ID: <XFMail.090330222854.Ted.Harding@manchester.ac.uk>

On 30-Mar-09 20:37:51, Duncan Murdoch wrote:
> On 3/30/2009 2:55 PM, (Ted Harding) wrote:
>> On 30-Mar-09 18:40:03, Kjetil Halvorsen wrote:
>>> With R 2.8.1 on ubuntu I get:
>>>> gamma(-1)
>>> [1] NaN
>>> Warning message:
>>> In gamma(-1) : NaNs produced
>>>> lgamma(-1)
>>> [1] Inf
>>> Warning message:
>>> value out of range in 'lgamma'
>>> 
>>> Is'nt the first one right, and the second one (lgamma)
>>> should also be NaN?
>>> Kjetil
>> 
>> That is surely correct! Since lim[x->(-1)+] gamma(x) = +Inf,
>> while lim[x->(-1)-] gamma(x) = -Inf, at gamma(-1) one cannot
>> choose between +Inf and -Inf, so surely is is NaN.
> 
> But lgamma(x) is log(abs(gamma(x))), so it looks okay to me.
> 
> Duncan Murdoch

Oops, yes! That's what comes of talking off the top of my head
(I don't think I've ever had occasion to evaluate lgamma(x)
for negative x, so never consciously checked in ?lgamma).

Thanks, Duncan!
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 30-Mar-09                                       Time: 22:28:52
------------------------------ XFMail ------------------------------


From marc_schwartz at me.com  Tue Mar 31 00:55:54 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 30 Mar 2009 17:55:54 -0500
Subject: [Rd] Possible bug in summary.survfit - 'scale' argument ignored?
Message-ID: <7F6A2326-6959-458F-9F50-DA3910CB16A5@me.com>

Hi all,

Using:

   R version 2.8.1 Patched (2009-03-07 r48068)

on OSX (10.5.6) with survival version:

   Version:            2.35-3
   Date:               2009-02-10


I get the following using the first example in ?summary.survfit:

 > summary( survfit( Surv(futime, fustat)~1, data=ovarian))
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

  time n.risk n.event survival std.err lower 95% CI upper 95% CI
    59     26       1    0.962  0.0377        0.890        1.000
   115     25       1    0.923  0.0523        0.826        1.000
   156     24       1    0.885  0.0627        0.770        1.000
   268     23       1    0.846  0.0708        0.718        0.997
   329     22       1    0.808  0.0773        0.670        0.974
   353     21       1    0.769  0.0826        0.623        0.949
   365     20       1    0.731  0.0870        0.579        0.923
   431     17       1    0.688  0.0919        0.529        0.894
   464     15       1    0.642  0.0965        0.478        0.862
   475     14       1    0.596  0.0999        0.429        0.828
   563     12       1    0.546  0.1032        0.377        0.791
   638     11       1    0.497  0.1051        0.328        0.752


 > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
365.25)
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

  time n.risk n.event survival std.err lower 95% CI upper 95% CI
    59     26       1    0.962  0.0377        0.890        1.000
   115     25       1    0.923  0.0523        0.826        1.000
   156     24       1    0.885  0.0627        0.770        1.000
   268     23       1    0.846  0.0708        0.718        0.997
   329     22       1    0.808  0.0773        0.670        0.974
   353     21       1    0.769  0.0826        0.623        0.949
   365     20       1    0.731  0.0870        0.579        0.923
   431     17       1    0.688  0.0919        0.529        0.894
   464     15       1    0.642  0.0965        0.478        0.862
   475     14       1    0.596  0.0999        0.429        0.828
   563     12       1    0.546  0.1032        0.377        0.791
   638     11       1    0.497  0.1051        0.328        0.752

Of course the time periods in the second output should be scaled to  
years, that is (time / 365.25).

I noted this today running some Sweave code, but not sure when the  
actual change in behavior occurred.  I can replicate the same behavior  
on a Windows machine here as well, so this is not OSX specific.

Regards,

Marc Schwartz


From mail at joeconway.com  Tue Mar 31 05:44:38 2009
From: mail at joeconway.com (Joe Conway)
Date: Mon, 30 Mar 2009 20:44:38 -0700
Subject: [Rd] external equiv to R_serialize()?
Message-ID: <49D191A6.8010905@joeconway.com>

I'm trying to efficiently allow conversion of R objects to PostgreSQL 
bytea (raw binary) datatype within PL/R for persistent storage in 
Postgres tables. I have found R_serialize() which looks like what I 
need, -- e.g. R_serialize(object, NULL, FALSE, NULL) -- except that it 
is marked attribute_hidden. Is there some other externally available 
interface that I can use?

Thanks,

Joe


From ripley at stats.ox.ac.uk  Tue Mar 31 07:59:15 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 31 Mar 2009 06:59:15 +0100 (BST)
Subject: [Rd] external equiv to R_serialize()?
In-Reply-To: <49D191A6.8010905@joeconway.com>
References: <49D191A6.8010905@joeconway.com>
Message-ID: <alpine.LFD.2.00.0903310655041.19538@gannet.stats.ox.ac.uk>

On Mon, 30 Mar 2009, Joe Conway wrote:

> I'm trying to efficiently allow conversion of R objects to PostgreSQL bytea 
> (raw binary) datatype within PL/R for persistent storage in Postgres tables. 
> I have found R_serialize() which looks like what I need, -- e.g. 
> R_serialize(object, NULL, FALSE, NULL) -- except that it is marked 
> attribute_hidden. Is there some other externally available interface that I 
> can use?

R_Serialize is in Rinternals.h.  R_serialize is a wrapper using 
connections, and connections do not have a public API.

Do note the comments in ?serialize: 'persistent' storage of objects in 
an experimental format is somewhat contradictory.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Mar 31 08:59:59 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Mar 2009 08:59:59 +0200
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <XFMail.090330222854.Ted.Harding@manchester.ac.uk>
References: <49D12D9F.1000203@stats.uwo.ca>
	<XFMail.090330222854.Ted.Harding@manchester.ac.uk>
Message-ID: <18897.49007.275534.467989@lynne.math.ethz.ch>

>>>>> "TH" == Ted Harding <Ted.Harding at manchester.ac.uk>
>>>>>     on Mon, 30 Mar 2009 22:28:54 +0100 (BST) writes:

    TH> On 30-Mar-09 20:37:51, Duncan Murdoch wrote:
    >> On 3/30/2009 2:55 PM, (Ted Harding) wrote:
    >>> On 30-Mar-09 18:40:03, Kjetil Halvorsen wrote:
    >>>> With R 2.8.1 on ubuntu I get:
    >>>>> gamma(-1)
    >>>> [1] NaN
    >>>> Warning message:
    >>>> In gamma(-1) : NaNs produced
    >>>>> lgamma(-1)
    >>>> [1] Inf
    >>>> Warning message:
    >>>> value out of range in 'lgamma'
    >>>> 
    >>>> Is'nt the first one right, and the second one (lgamma)
    >>>> should also be NaN?
    >>>> Kjetil
    >>> 
    >>> That is surely correct! Since lim[x->(-1)+] gamma(x) = +Inf,
    >>> while lim[x->(-1)-] gamma(x) = -Inf, at gamma(-1) one cannot
    >>> choose between +Inf and -Inf, so surely is is NaN.
    >> 
    >> But lgamma(x) is log(abs(gamma(x))), so it looks okay to me.
    >> 
    >> Duncan Murdoch

    TH> Oops, yes! That's what comes of talking off the top of my head
    TH> (I don't think I've ever had occasion to evaluate lgamma(x)
    TH> for negative x, so never consciously checked in ?lgamma).

    TH> Thanks, Duncan!

Indeed.... as we all know, a picture can be worth a thousand words,
and a simple R call such as
       plot(lgamma, -7, 0, n=1000)
would have saved many words, and notably spared us from
yet-another erroneous non-bug report.

Martin


From ankheedutta at gmail.com  Tue Mar 31 06:30:11 2009
From: ankheedutta at gmail.com (ankheedutta at gmail.com)
Date: Tue, 31 Mar 2009 06:30:11 +0200 (CEST)
Subject: [Rd] installing RMySQL (PR#13633)
Message-ID: <20090331043011.D20E92832183@mail.pubhealth.ku.dk>

Full_Name: Ankhee Dutta
Version: 2.3
OS: LINUX
Submission from: (NULL) (202.141.12.97)




I have a linux system of Mandriva-2007 with R version 2.3.0 and MySQL with
5.0.0. I have also got DBI-R database interface version-0.1-11 installed on
my Linux system.While installing RMySQL package version 0.5-11 i am  facing
 problem .

while installation the error report which is coming is as follows:



* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... no
checking for /usr/local/mysql/include/
mysql/mysql.h... no
checking for /opt/include/mysql/mysql.h... no
checking for /include/mysql/mysql.h... no

Configuration error:
 could not find the MySQL installation include and/or library
 directories.  Manually specify the location of the MySQL
 libraries and the header files and re-run R CMD INSTALL.

INSTRUCTIONS:

1. Define and export the 2 shell variables PKG_CPPFLAGS and
  PKG_LIBS to include the directory for header files (*.h)
  and libraries, for example (using Bourne shell syntax):

     export PKG_CPPFLAGS="-I<MySQL-include-dir>"
     export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"

  Re-run the R INSTALL command:

     R CMD INSTALL RMySQL_<version>.tar.gz

2. Alternatively, you may pass the configure arguments
     --with-mysql-dir=<base-dir> (distribution directory)
  or
     --with-mysql-inc=<base-inc> (where MySQL header files reside)
     --with-mysql-lib=<base-lib> (where MySQL libraries reside)
  in the call to R INSTALL --configure-args='...'

  R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
RMySQL_<version>.tar.gz

ERROR: configuration failed for package 'RMySQL'
** Removing '/usr/lib/R/library/RMySQL'


From maechler at stat.math.ethz.ch  Tue Mar 31 12:05:37 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Mar 2009 12:05:37 +0200
Subject: [Rd] [R] incoherent conversions from/to raw
In-Reply-To: <49C20DA0.2030008@idi.ntnu.no>
References: <49C1833F.3050302@idi.ntnu.no>
	<49C20DA0.2030008@idi.ntnu.no>
Message-ID: <18897.60145.524748.849078@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 19 Mar 2009 10:17:20 +0100 writes:

    WK> Wacek Kusnierczyk wrote:
    >> interestingly,
    >> 
    >> c(1, as.raw(1))
    >> # error: type 'raw' is unimplemented in 'RealAnswer'
    >> 
    >> 

    WK> three more comments.


    WK> (1)
    WK> the above is interesting in the light of what ?c says:

    WK> "
    WK> The output type is determined from the highest type of the
    WK> components in the hierarchy NULL < raw < logical < integer < real
    WK> < complex < character < list < expression.
    WK> "

    WK> which seems to suggest that raw components should be coerced to whatever
    WK> the highest type among all arguments to c, which clearly doesn't happen:

    WK> test = function(type)
    WK> c(as.raw(1), get(sprintf('as.%s',type))(1))

    WK> for (type in c('null', 'logical', 'integer', 'real', 'complex',
    WK> 'character', 'list', 'expression'))
    WK> tryCatch(test(type), error = function(e) cat(sprintf("raw won't
    WK> coerce to %s type\n", type)))

    WK> which shows that raw won't coerce to the four first types in the
    WK> 'hierarchy' (excluding NULL), but it will to character, list, and
    WK> expression.

    WK> suggestion:   improve the documentation, or adapt the implementation to
    WK> a more coherent design.

Thank you, Wacek.

I've decided to adapt the implementation
such that all the above  c(<raw> , <type>)  calls' implicit
coercions will work.


    WK> (2)
    WK> incidentally, there's a bug somewhere there related to the condition
    WK> system and printing:

    WK> tryCatch(stop(), error=function(e) print(e))
    WK> # works just fine

    WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
    WK> # *** caught segfault ***
    WK> # address (nil), cause 'memory not mapped'

    WK> # Traceback:
    WK> # 1: sprintf("%s", e)
    WK> # 2: value[[3]](cond)
    WK> # 3: tryCatchOne(expr, names, parentenv, handlers[[1]])
    WK> # 4: tryCatchList(expr, classes, parentenv, handlers)
    WK> # 5: tryCatch(stop(), error = function(e) sprintf("%s", e))

    WK> # Possible actions:
    WK> # 1: abort (with core dump, if enabled)
    WK> # 2: normal R exit
    WK> # 3: exit R without saving workspace
    WK> # 4: exit R saving workspace
    WK> # Selection:
 
    WK> interestingly, it is possible to stay in the session by typing ^C.  the
    WK> session seems to work, but if the tryCatch above is tried once again, a
    WK> segfault causes r to crash immediately:

    WK> # ^C
    WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
    WK> # [whoever at wherever] $

    WK> however, this doesn't happen if some other code is evaluated first:

    WK> # ^C
    WK> x = 1:10^8
    WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
    WK> # Error in sprintf("%s", e) : 'getEncChar' must be called on a CHARSXP
  
    WK> this can't be a feature.  (tried in both 2.8.0 and r-devel;  version
    WK> info at the bottom.)

    WK> suggestion:  trace down and fix the bug.

[not me, at least not now.]


    WK> (3)
    WK> the error argument to tryCatch is used in two examples in ?tryCatch, but
    WK> it is not explained anywhere in the help page.  one can guess that the
    WK> argument name corresponds to the class of conditions the handler will
    WK> handle, but it would be helpful to have this stated explicitly.  the
    WK> help page simply says:

    WK> "
    WK> If a condition is signaled while evaluating 'expr' then
    WK> established handlers are checked, starting with the most recently
    WK> established ones, for one matching the class of the condition.
    WK> When several handlers are supplied in a single 'tryCatch' then the
    WK> first one is considered more recent than the second. 
    WK> "

    WK> which is uninformative in this respect -- what does 'one matching the
    WK> class' mean?

    WK> suggestion:  improve the documentation.

Patches to  tryCatch.Rd  are gladly accepted
and quite possibly applied to the sources without much changes.
Thanks in advance!

Martin Maechler, ETH Zurich


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 31 12:29:02 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 31 Mar 2009 12:29:02 +0200
Subject: [Rd] [R] incoherent conversions from/to raw
In-Reply-To: <18897.60145.524748.849078@lynne.math.ethz.ch>
References: <49C1833F.3050302@idi.ntnu.no>	<49C20DA0.2030008@idi.ntnu.no>
	<18897.60145.524748.849078@lynne.math.ethz.ch>
Message-ID: <49D1F06E.30108@idi.ntnu.no>

Martin Maechler wrote:

(...)

>     WK> which shows that raw won't coerce to the four first types in the
>     WK> 'hierarchy' (excluding NULL), but it will to character, list, and
>     WK> expression.
>
>     WK> suggestion:   improve the documentation, or adapt the implementation to
>     WK> a more coherent design.
>
> Thank you, Wacek.
>
> I've decided to adapt the implementation
> such that all the above  c(<raw> , <type>)  calls' implicit
> coercions will work.
>   

great!

>
>     WK> (2)
>     WK> incidentally, there's a bug somewhere there related to the condition
>     WK> system and printing:
>
>     WK> tryCatch(stop(), error=function(e) print(e))
>     WK> # works just fine
>
>     WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
>     WK> # *** caught segfault ***
>     WK> # address (nil), cause 'memory not mapped'
>
>     WK> # Traceback:
>     WK> # 1: sprintf("%s", e)
>     WK> # 2: value[[3]](cond)
>     WK> # 3: tryCatchOne(expr, names, parentenv, handlers[[1]])
>     WK> # 4: tryCatchList(expr, classes, parentenv, handlers)
>     WK> # 5: tryCatch(stop(), error = function(e) sprintf("%s", e))
>
>     WK> # Possible actions:
>     WK> # 1: abort (with core dump, if enabled)
>     WK> # 2: normal R exit
>     WK> # 3: exit R without saving workspace
>     WK> # 4: exit R saving workspace
>     WK> # Selection:
>  
>     WK> interestingly, it is possible to stay in the session by typing ^C.  the
>     WK> session seems to work, but if the tryCatch above is tried once again, a
>     WK> segfault causes r to crash immediately:
>
>     WK> # ^C
>     WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
>     WK> # [whoever at wherever] $
>
>     WK> however, this doesn't happen if some other code is evaluated first:
>
>     WK> # ^C
>     WK> x = 1:10^8
>     WK> tryCatch(stop(), error=function(e) sprintf('%s', e))
>     WK> # Error in sprintf("%s", e) : 'getEncChar' must be called on a CHARSXP
>   
>     WK> this can't be a feature.  (tried in both 2.8.0 and r-devel;  version
>     WK> info at the bottom.)
>
>     WK> suggestion:  trace down and fix the bug.
>
> [not me, at least not now.]
>   

sure;  i might try to find the bug in spare time, but can't promise.

>
>     WK> (3)
>     WK> the error argument to tryCatch is used in two examples in ?tryCatch, but
>     WK> it is not explained anywhere in the help page.  one can guess that the
>     WK> argument name corresponds to the class of conditions the handler will
>     WK> handle, but it would be helpful to have this stated explicitly.  the
>     WK> help page simply says:
>
>     WK> "
>     WK> If a condition is signaled while evaluating 'expr' then
>     WK> established handlers are checked, starting with the most recently
>     WK> established ones, for one matching the class of the condition.
>     WK> When several handlers are supplied in a single 'tryCatch' then the
>     WK> first one is considered more recent than the second. 
>     WK> "
>
>     WK> which is uninformative in this respect -- what does 'one matching the
>     WK> class' mean?
>
>     WK> suggestion:  improve the documentation.
>
> Patches to  tryCatch.Rd  are gladly accepted
> and quite possibly applied to the sources without much changes.
>   

ok, if you're willing to accept my suggestions i can try to suggest a
patch to the rd.


> Thanks in advance!
>   

you're welcome.

best,
vQ


From xieyihui at gmail.com  Tue Mar 31 14:16:47 2009
From: xieyihui at gmail.com (Yihui Xie)
Date: Tue, 31 Mar 2009 20:16:47 +0800
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <8903928.174261237575367141.JavaMail.www@wwumf0207>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
Message-ID: <89b6b8c90903310516y2d59b1fvf112f566bb9ba3ed@mail.gmail.com>

Hi Romain,

I've been thinking for quite a long time on how to keep comments when
parsing R code and finally got a trick with inspiration from one of my
friends, i.e. to mask the comments in special assignments to "cheat" R
parser:

# keep.comment: whether to keep the comments or not
# keep.blank.line: preserve blank lines or not?
# begin.comment and end.comment: special identifiers that mark the orignial
#     comments as 'begin.comment = "#[ comments ]end.comment"'
#     and these marks will be removed after the modified code is parsed
tidy.source <- function(source = "clipboard", keep.comment = TRUE,
    keep.blank.line = FALSE, begin.comment, end.comment, ...) {
    # parse and deparse the code
    tidy.block = function(block.text) {
        exprs = parse(text = block.text)
        n = length(exprs)
        res = character(n)
        for (i in 1:n) {
            dep = paste(deparse(exprs[i]), collapse = "\n")
            res[i] = substring(dep, 12, nchar(dep) - 1)
        }
        return(res)
    }
    text.lines = readLines(source, warn = FALSE)
    if (keep.comment) {
        # identifier for comments
        identifier = function() paste(sample(LETTERS), collapse = "")
        if (missing(begin.comment))
            begin.comment = identifier()
        if (missing(end.comment))
            end.comment = identifier()
        # remove leading and trailing white spaces
        text.lines = gsub("^[[:space:]]+|[[:space:]]+$", "",
            text.lines)
        # make sure the identifiers are not in the code
        # or the original code might be modified
        while (length(grep(sprintf("%s|%s", begin.comment, end.comment),
            text.lines))) {
            begin.comment = identifier()
            end.comment = identifier()
        }
        head.comment = substring(text.lines, 1, 1) == "#"
        # add identifiers to comment lines to cheat R parser
        if (any(head.comment)) {
            text.lines[head.comment] = gsub("\"", "\'",
text.lines[head.comment])
            text.lines[head.comment] = sprintf("%s=\"%s%s\"",
                begin.comment, text.lines[head.comment], end.comment)
        }
        # keep blank lines?
        blank.line = text.lines == ""
        if (any(blank.line) & keep.blank.line)
            text.lines[blank.line] = sprintf("%s=\"%s\"", begin.comment,
                end.comment)
        text.tidy = tidy.block(text.lines)
        # remove the identifiers
        text.tidy = gsub(sprintf("%s = \"|%s\"", begin.comment,
            end.comment), "", text.tidy)
    }
    else {
        text.tidy = tidy.block(text.lines)
    }
    cat(paste(text.tidy, collapse = "\n"), "\n", ...)
    invisible(text.tidy)
}

The above function can deal with comments which are in single lines, e.g.

f = tempfile()
writeLines('
  # rotation of the word "Animation"
# in a loop; change the angle and color
# step by step
for (i in 1:360) {
# redraw the plot again and again
plot(1,ann=FALSE,type="n",axes=FALSE)
# rotate; use rainbow() colors
text(1,1,"Animation",srt=i,col=rainbow(360)[i],cex=7*i/360)
# pause for a while
Sys.sleep(0.01)}
', f)

Then parse the code file 'f':

> tidy.source(f)
# rotation of the word 'Animation'
# in a loop; change the angle and color
# step by step
for (i in 1:360) {
    # redraw the plot again and again
    plot(1, ann = FALSE, type = "n", axes = FALSE)
    # rotate; use rainbow() colors
    text(1, 1, "Animation", srt = i, col = rainbow(360)[i], cex = 7 *
        i/360)
    # pause for a while
    Sys.sleep(0.01)
}

Of course this function has some limitations: it does not support
inline comments or comments which are inside incomplete code lines.
Peter's example

f #here
( #here
a #here (possibly)
= #here
1 #this one belongs to the argument, though
) #but here as well

will be parsed as

f
(a = 1)

I'm quite interested in syntax highlighting of R code and saw your
previous discussions in another posts (with Jose Quesada, etc). I'd
like to do something for your package if I could be of some help.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
Mobile: +86-15810805877
Homepage: http://www.yihui.name
School of Statistics, Room 1037, Mingde Main Building,
Renmin University of China, Beijing, 100872, China



2009/3/21  <romain.francois at dbmail.com>:
>
> It happens in the token function in gram.c:
>
> ?????? c = SkipSpace();
> ?????? if (c == '#') c = SkipComment();
>
> and then SkipComment goes like that:
>
> static int SkipComment(void)
> {
> ?????? int c;
> ?????? while ((c = xxgetc()) != '\n' && c != R_EOF) ;
> ?????? if (c == R_EOF) EndOfFile = 2;
> ?????? return c;
> }
>
> which effectively drops comments.
>
> Would it be possible to keep the information somewhere ?
>
> The source code says this:
>
> ??*?? The function yylex() scans the input, breaking it into
> ??*?? tokens which are then passed to the parser.?? The lexical
> ??*?? analyser maintains a symbol table (in a very messy fashion).
>
> so my question is could we use this symbol table to keep track of, say, COMMENT tokens.
>
> Why would I even care about that ? I'm writing a package that will
> perform syntax highlighting of R source code based on the output of the
> parser, and it seems a waste to drop the comments.
>
> An also, when you print a function to the R console, you don't get the comments, and some of them might be useful to the user.
>
> Am I mad if I contemplate looking into this ?
>
> Romain
>
> --
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
>


From romain.francois at dbmail.com  Tue Mar 31 14:26:27 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 31 Mar 2009 14:26:27 +0200
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <89b6b8c90903310516y2d59b1fvf112f566bb9ba3ed@mail.gmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
	<89b6b8c90903310516y2d59b1fvf112f566bb9ba3ed@mail.gmail.com>
Message-ID: <49D20BF3.7090503@dbmail.com>

Hi,

Thank you for this (inspired) trick. I am currently in the process of 
extracting out the parser from R (ie the gram.y file) and making a 
custom parser using the same grammar but structuring the output in a 
different manner, more suitable for what the syntax highlighter will need.

You will find the project here: 
http://r-forge.r-project.org/projects/highlight/
Feel free to "request to join" on the project if you feel you can make 
useful contributions.

At the moment, I am concentrating efforts deep down in the parser code, 
but there are other challenges:
- once the expressions are parsed, we will need something that 
investigates to find evidence about function calls, to get an idea of 
where the function is defined (by the user, in a package, ...) . This is 
tricky, and unless you actually evaluate the code, there will be some 
errors made.
- once the evidence is collected, other functions (renderers) will have 
the task to render the evidence using html, latex, rtf, ansi escape 
codes, ... the idea here is to design the system so that other packages 
can implement custom renderers to format the evidence in their markup 
language

Romain

Yihui Xie wrote:
> Hi Romain,
>
> I've been thinking for quite a long time on how to keep comments when
> parsing R code and finally got a trick with inspiration from one of my
> friends, i.e. to mask the comments in special assignments to "cheat" R
> parser
>
> # keep.comment: whether to keep the comments or not
> # keep.blank.line: preserve blank lines or not?
> # begin.comment and end.comment: special identifiers that mark the orignial
> #     comments as 'begin.comment = "#[ comments ]end.comment"'
> #     and these marks will be removed after the modified code is parsed
> tidy.source <- function(source = "clipboard", keep.comment = TRUE,
>     keep.blank.line = FALSE, begin.comment, end.comment, ...) {
>     # parse and deparse the code
>     tidy.block = function(block.text) {
>         exprs = parse(text = block.text)
>         n = length(exprs)
>         res = character(n)
>         for (i in 1:n) {
>             dep = paste(deparse(exprs[i]), collapse = "\n")
>             res[i] = substring(dep, 12, nchar(dep) - 1)
>         }
>         return(res)
>     }
>     text.lines = readLines(source, warn = FALSE)
>     if (keep.comment) {
>         # identifier for comments
>         identifier = function() paste(sample(LETTERS), collapse = "")
>         if (missing(begin.comment))
>             begin.comment = identifier()
>         if (missing(end.comment))
>             end.comment = identifier()
>         # remove leading and trailing white spaces
>         text.lines = gsub("^[[:space:]]+|[[:space:]]+$", "",
>             text.lines)
>         # make sure the identifiers are not in the code
>         # or the original code might be modified
>         while (length(grep(sprintf("%s|%s", begin.comment, end.comment),
>             text.lines))) {
>             begin.comment = identifier()
>             end.comment = identifier()
>         }
>         head.comment = substring(text.lines, 1, 1) == "#"
>         # add identifiers to comment lines to cheat R parser
>         if (any(head.comment)) {
>             text.lines[head.comment] = gsub("\"", "\'",
> text.lines[head.comment])
>             text.lines[head.comment] = sprintf("%s=\"%s%s\"",
>                 begin.comment, text.lines[head.comment], end.comment)
>         }
>         # keep blank lines?
>         blank.line = text.lines == ""
>         if (any(blank.line) & keep.blank.line)
>             text.lines[blank.line] = sprintf("%s=\"%s\"", begin.comment,
>                 end.comment)
>         text.tidy = tidy.block(text.lines)
>         # remove the identifiers
>         text.tidy = gsub(sprintf("%s = \"|%s\"", begin.comment,
>             end.comment), "", text.tidy)
>     }
>     else {
>         text.tidy = tidy.block(text.lines)
>     }
>     cat(paste(text.tidy, collapse = "\n"), "\n", ...)
>     invisible(text.tidy)
> }
>
> The above function can deal with comments which are in single lines, e.g.
>
> f = tempfile()
> writeLines('
>   # rotation of the word "Animation"
> # in a loop; change the angle and color
> # step by step
> for (i in 1:360) {
> # redraw the plot again and again
> plot(1,ann=FALSE,type="n",axes=FALSE)
> # rotate; use rainbow() colors
> text(1,1,"Animation",srt=i,col=rainbow(360)[i],cex=7*i/360)
> # pause for a while
> Sys.sleep(0.01)}
> ', f)
>
> Then parse the code file 'f':
>
>   
>> tidy.source(f)
>>     
> # rotation of the word 'Animation'
> # in a loop; change the angle and color
> # step by step
> for (i in 1:360) {
>     # redraw the plot again and again
>     plot(1, ann = FALSE, type = "n", axes = FALSE)
>     # rotate; use rainbow() colors
>     text(1, 1, "Animation", srt = i, col = rainbow(360)[i], cex = 7 *
>         i/360)
>     # pause for a while
>     Sys.sleep(0.01)
> }
>
> Of course this function has some limitations: it does not support
> inline comments or comments which are inside incomplete code lines.
> Peter's example
>
> f #here
> ( #here
> a #here (possibly)
> = #here
> 1 #this one belongs to the argument, though
> ) #but here as well
>
> will be parsed as
>
> f
> (a = 1)
>
> I'm quite interested in syntax highlighting of R code and saw your
> previous discussions in another posts (with Jose Quesada, etc). I'd
> like to do something for your package if I could be of some help.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
> Mobile: +86-15810805877
> Homepage: http://www.yihui.name
> School of Statistics, Room 1037, Mingde Main Building,
> Renmin University of China, Beijing, 100872, China
>
>
>
> 2009/3/21  <romain.francois at dbmail.com>:
>   
>> It happens in the token function in gram.c:
>>
>> ? ? ?  c = SkipSpace();
>> ? ? ?  if (c == '#') c = SkipComment();
>>
>> and then SkipComment goes like that:
>>
>> static int SkipComment(void)
>> {
>> ? ? ?  int c;
>> ? ? ?  while ((c = xxgetc()) != '\n' && c != R_EOF) ;
>> ? ? ?  if (c == R_EOF) EndOfFile = 2;
>> ? ? ?  return c;
>> }
>>
>> which effectively drops comments.
>>
>> Would it be possible to keep the information somewhere ?
>>
>> The source code says this:
>>
>> ? *?  The function yylex() scans the input, breaking it into
>> ? *?  tokens which are then passed to the parser.?  The lexical
>> ? *?  analyser maintains a symbol table (in a very messy fashion).
>>
>> so my question is could we use this symbol table to keep track of, say, COMMENT tokens.
>>
>> Why would I even care about that ? I'm writing a package that will
>> perform syntax highlighting of R source code based on the output of the
>> parser, and it seems a waste to drop the comments.
>>
>> An also, when you print a function to the R console, you don't get the comments, and some of them might be useful to the user.
>>
>> Am I mad if I contemplate looking into this ?
>>
>> Romain
>>
>> --
>> Romain Francois
>> Independent R Consultant
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>>
>>     
>
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From marc_schwartz at me.com  Tue Mar 31 14:48:11 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 31 Mar 2009 07:48:11 -0500
Subject: [Rd] Possible bug in summary.survfit - 'scale' argument ignored?
In-Reply-To: <7F6A2326-6959-458F-9F50-DA3910CB16A5@me.com>
References: <7F6A2326-6959-458F-9F50-DA3910CB16A5@me.com>
Message-ID: <D9757384-E63D-462A-8FBE-A30B3C533310@me.com>

On Mar 30, 2009, at 5:55 PM, Marc Schwartz wrote:

> Hi all,
>
> Using:
>
>  R version 2.8.1 Patched (2009-03-07 r48068)
>
> on OSX (10.5.6) with survival version:
>
>  Version:            2.35-3
>  Date:               2009-02-10
>
>
> I get the following using the first example in ?summary.survfit:
>
> > summary( survfit( Surv(futime, fustat)~1, data=ovarian))
> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)
>
> time n.risk n.event survival std.err lower 95% CI upper 95% CI
>   59     26       1    0.962  0.0377        0.890        1.000
>  115     25       1    0.923  0.0523        0.826        1.000
>  156     24       1    0.885  0.0627        0.770        1.000
>  268     23       1    0.846  0.0708        0.718        0.997
>  329     22       1    0.808  0.0773        0.670        0.974
>  353     21       1    0.769  0.0826        0.623        0.949
>  365     20       1    0.731  0.0870        0.579        0.923
>  431     17       1    0.688  0.0919        0.529        0.894
>  464     15       1    0.642  0.0965        0.478        0.862
>  475     14       1    0.596  0.0999        0.429        0.828
>  563     12       1    0.546  0.1032        0.377        0.791
>  638     11       1    0.497  0.1051        0.328        0.752
>
>
> > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
> 365.25)
> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)
>
> time n.risk n.event survival std.err lower 95% CI upper 95% CI
>   59     26       1    0.962  0.0377        0.890        1.000
>  115     25       1    0.923  0.0523        0.826        1.000
>  156     24       1    0.885  0.0627        0.770        1.000
>  268     23       1    0.846  0.0708        0.718        0.997
>  329     22       1    0.808  0.0773        0.670        0.974
>  353     21       1    0.769  0.0826        0.623        0.949
>  365     20       1    0.731  0.0870        0.579        0.923
>  431     17       1    0.688  0.0919        0.529        0.894
>  464     15       1    0.642  0.0965        0.478        0.862
>  475     14       1    0.596  0.0999        0.429        0.828
>  563     12       1    0.546  0.1032        0.377        0.791
>  638     11       1    0.497  0.1051        0.328        0.752
>
> Of course the time periods in the second output should be scaled to  
> years, that is (time / 365.25).
>
> I noted this today running some Sweave code, but not sure when the  
> actual change in behavior occurred.  I can replicate the same  
> behavior on a Windows machine here as well, so this is not OSX  
> specific.


A quick follow up here. I reverted to:

   R version 2.8.1 (2008-12-22)

which includes survival version:

Version:       2.34-1
Date:          2008-03-31


In that version, I get:

 > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
365.25)
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

   time n.risk n.event survival std.err lower 95% CI upper 95% CI
  0.162     26       1    0.962  0.0377        0.890        1.000
  0.315     25       1    0.923  0.0523        0.826        1.000
  0.427     24       1    0.885  0.0627        0.770        1.000
  0.734     23       1    0.846  0.0708        0.718        0.997
  0.901     22       1    0.808  0.0773        0.670        0.974
  0.966     21       1    0.769  0.0826        0.623        0.949
  0.999     20       1    0.731  0.0870        0.579        0.923
  1.180     17       1    0.688  0.0919        0.529        0.894
  1.270     15       1    0.642  0.0965        0.478        0.862
  1.300     14       1    0.596  0.0999        0.429        0.828
  1.541     12       1    0.546  0.1032        0.377        0.791
  1.747     11       1    0.497  0.1051        0.328        0.752


So the functional loss of the 'scale' argument took place subsequent  
to that release. From a review of the code in both versions, it would  
appear that substantive changes took place to the function in the  
intervening time frame, including the addition of the 'rmean' and  
'extend' arguments. One of the changes appears to be the setting of:

   stime <- fit$time/scale

in the old version and I do not see a parallel adjustment in the time  
scale in the new version and the subsequent use of fit$time later in  
the new function.

Given the substantive changes to the function code, I am hesitant to  
propose patches for fear of introducing breakage elsewhere. I also  
need to get some work done for a client today, before I leave for  
vacation tomorrow for a week, otherwise I would spend more time  
evaluating possible patches.

I hope that the above is enough to give Terry and Thomas some narrowed  
focus.

Regards,

Marc


From maechler at stat.math.ethz.ch  Tue Mar 31 15:20:28 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Mar 2009 15:20:28 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are duplicates?"}
In-Reply-To: <49D0BA70.3090005@idi.ntnu.no>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>
	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>
	<49D0BA70.3090005@idi.ntnu.no>
Message-ID: <18898.6300.26434.413865@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 30 Mar 2009 14:26:24 +0200 writes:

    WK> Michael Dewey wrote:
    >> At 05:07 30/03/2009, Aaron M. Swoboda wrote:
    >>> I would like to know which rows are duplicates of each other, not
    >>> simply that a row is duplicate of another row. In the following
    >>> example rows 1 and 3 are duplicates.
    >>> 
    >>> > x <- c(1,3,1)
    >>> > y <- c(2,4,2)
    >>> > z <- c(3,4,3)
    >>> > data <- data.frame(x,y,z)
    >>> x y z
    >>> 1 1 2 3
    >>> 2 3 4 4
    >>> 3 1 2 3
    >> 

    WK> i don't have any solution significantly better than what you have
    WK> already been given.  but i have a warning instead.

    WK> in the below, you use both 'duplicated' and 'unique' on data frames, and
    WK> the proposed solution relies on the latter.  you may want to try to
    WK> avoid both when working with data frames;  this is because of how they
    WK> do (or don't) work.

    WK> duplicated (and unique, which calls duplicated) simply pastes the
    WK> content of each row into a *string*, and then works on the strings. 
    WK> this means that NAs in the data frame are converted to "NA"s, and "NA"
    WK> == "NA", obviously, so that rows that include NAs and are otherwise
    WK> identical will be considered *identical*.

    WK> that's not bad (yet), but you should be aware.  however, duplicated has
    WK> a parameter named 'incomparables', explained in ?duplicated as follows:

    WK> "
    WK> incomparables: a vector of values that cannot be compared. 'FALSE' is a
    WK> special value, meaning that all values can be compared, and
    WK> may be the only value accepted for methods other than the
    WK> default.  It will be coerced internally to the same type as
    WK> 'x'.
    WK> "

    WK> and also

    WK> "
    WK> Values in 'incomparables' will never be marked as duplicated. This
    WK> is intended to be used for a fairly small set of values and will
    WK> not be efficient for a very large set.
    WK> "

    WK> that is, for example:

    WK> vector = c(NA, NA)
    WK> duplicated(vector)
    WK> # [1] FALSE TRUE
    WK> duplicated(vector), incomparables=NA)
    WK> # [1] FALSE FALSE

    WK> list = list(NA, NA)
    WK> duplicated(list)
    WK> # [1] FALSE TRUE
    WK> duplicated(list, incomparables=NA)
    WK> # [1] FALSE FALSE


    WK> what the documentation *fails* to tell you is that the parameter
    WK> 'incomparables' is defunct

No, not "defunct", but the contrary of it,
"not yet implemented" !

    WK> in duplicated.data.frame, which you can see in its
    WK> source code (below), or in the following example:

    WK> # data as above, or any data frame
    WK> duplicated(data, incomparables=NA)
    WK> # Error in if (!is.logical(incomparables) || incomparables)
    WK> .NotYetUsed("incomparables != FALSE") :
    WK> #   missing value where TRUE/FALSE needed

    WK> the error message here is *confusing*.  
yes!

    WK> the error is raised because the
    WK> author of the code made a mistake and apparently haven't carefully
((plural or singular ??))

    WK> examined and tested his product;  the code goes:
((aah, ... "singular" ...))

    WK> duplicated.data.frame
    WK> # function (x, incomparables = FALSE, fromLast = FALSE, ...)
    WK> # {
    WK> #    if (!is.logical(incomparables) || incomparables)
    WK> #        .NotYetUsed("incomparables != FALSE")
    WK> #    duplicated(do.call("paste", c(x, sep = "\r")), fromLast = fromLast)
    WK> # }
    WK> # <environment: namespace:base>

    WK> clearly, the intention here is to raise an error with a (still hardly
    WK> clear) message as in:

    WK> .NotYetUsed("incomparables != FALSE")
    WK> # Error: argument 'incomparables != FALSE' is not used (yet)

    WK> but instead, if(NA) is evaluated (because '!is.logical(NA) || NA'
    WK> evaluates, *obviously*, to NA) and hence the uninformative error message.

    WK> take home point:  rtfm, *but* don't believe it.

and then be helpful to the R community and send a bug report
*with* a patch if {as in this case} you are able to...

Well, that' no longer needed here,
I'll fix that easily myself.

Martin

    WK> vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 31 16:03:12 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 31 Mar 2009 16:03:12 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are
	duplicates?"}
In-Reply-To: <18898.6300.26434.413865@lynne.math.ethz.ch>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>	<49D0BA70.3090005@idi.ntnu.no>
	<18898.6300.26434.413865@lynne.math.ethz.ch>
Message-ID: <49D222A0.7020601@idi.ntnu.no>

Martin Maechler wrote:
>
>     WK> what the documentation *fails* to tell you is that the parameter
>     WK> 'incomparables' is defunct
>
> No, not "defunct", but the contrary of it,
> "not yet implemented" !
>   

that's my bad english, again.  sorry.

>     WK> # data as above, or any data frame
>     WK> duplicated(data, incomparables=NA)
>     WK> # Error in if (!is.logical(incomparables) || incomparables)
>     WK> .NotYetUsed("incomparables != FALSE") :
>     WK> #   missing value where TRUE/FALSE needed
>
>     WK> the error message here is *confusing*.  
> yes!
>   

!

>     WK> the error is raised because the
>     WK> author of the code made a mistake and apparently haven't carefully
> ((plural or singular ??))
>   

i guess "hasn't" was intended.  i'd need to ask the author.

>     WK> examined and tested his product;  the code goes:
> ((aah, ... "singular" ...))
>   

my guesswork, anyway.

>     WK> duplicated.data.frame
>     WK> # function (x, incomparables = FALSE, fromLast = FALSE, ...)
>     WK> # {
>     WK> #    if (!is.logical(incomparables) || incomparables)
>     WK> #        .NotYetUsed("incomparables != FALSE")
>     WK> #    duplicated(do.call("paste", c(x, sep = "\r")), fromLast = fromLast)
>     WK> # }
>     WK> # <environment: namespace:base>
>
>     WK> clearly, the intention here is to raise an error with a (still hardly
>     WK> clear) message as in:
>
>     WK> .NotYetUsed("incomparables != FALSE")
>     WK> # Error: argument 'incomparables != FALSE' is not used (yet)
>
>     WK> but instead, if(NA) is evaluated (because '!is.logical(NA) || NA'
>     WK> evaluates, *obviously*, to NA) and hence the uninformative error message.
>
>     WK> take home point:  rtfm, *but* don't believe it.
>
> and then be helpful to the R community and send a bug report
> *with* a patch if {as in this case} you are able to...
>
> Well, that' no longer needed here,
> I'll fix that easily myself.
>   

but i *have* sent a patch already!

vQ


From macrakis at alum.mit.edu  Tue Mar 31 16:18:35 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 31 Mar 2009 10:18:35 -0400
Subject: [Rd] as.data.frame peculiarities
Message-ID: <8b356f880903310718m2c17857btb6e4c18258a31ebb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/89f96cbb/attachment.pl>

From h.wickham at gmail.com  Tue Mar 31 16:26:15 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 31 Mar 2009 09:26:15 -0500
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <49D20BF3.7090503@dbmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>
	<89b6b8c90903310516y2d59b1fvf112f566bb9ba3ed@mail.gmail.com>
	<49D20BF3.7090503@dbmail.com>
Message-ID: <f8e6ff050903310726o78e9ba0k3d56233e19ba43b8@mail.gmail.com>

> At the moment, I am concentrating efforts deep down in the parser code, but
> there are other challenges:
> - once the expressions are parsed, we will need something that investigates
> to find evidence about function calls, to get an idea of where the function
> is defined (by the user, in a package, ...) . This is tricky, and unless you
> actually evaluate the code, there will be some errors made.

Are you aware of Luke Tierney's codetools package?  That would seem to
be the place to start.

Hadley

-- 
http://had.co.nz/


From romain.francois at dbmail.com  Tue Mar 31 16:39:04 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 31 Mar 2009 16:39:04 +0200
Subject: [Rd] Why does the lexical analyzer drop comments ?
In-Reply-To: <f8e6ff050903310726o78e9ba0k3d56233e19ba43b8@mail.gmail.com>
References: <8903928.174261237575367141.JavaMail.www@wwumf0207>	
	<89b6b8c90903310516y2d59b1fvf112f566bb9ba3ed@mail.gmail.com>	
	<49D20BF3.7090503@dbmail.com>
	<f8e6ff050903310726o78e9ba0k3d56233e19ba43b8@mail.gmail.com>
Message-ID: <49D22B08.2030007@dbmail.com>

hadley wickham wrote:
>> At the moment, I am concentrating efforts deep down in the parser code, but
>> there are other challenges:
>> - once the expressions are parsed, we will need something that investigates
>> to find evidence about function calls, to get an idea of where the function
>> is defined (by the user, in a package, ...) . This is tricky, and unless you
>> actually evaluate the code, there will be some errors made.
>>     
>
> Are you aware of Luke Tierney's codetools package?  That would seem to
> be the place to start.
>   
Yep. Plan to combine the more verbose information out of the modified 
parser with the same guess machine that checkUsage uses.
Another side effect is that we could imagine to link error patterns 
identified by checkUsage (no visible binding for global variable "y", 
...) to actual locations on the file (for example the place where the 
variable y is used in that case ), which at the moment is not possible 
because the parser only locates entire expression (semantic groupings) 
and not tokens.

 > f <- function( x = 2) {
+ y + 2
+ }
 > checkUsage( f )
<anonymous>: no visible binding for global variable ?y?

> Hadley
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From bolker at ufl.edu  Tue Mar 31 17:08:45 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 31 Mar 2009 15:08:45 +0000 (UTC)
Subject: [Rd] Gamma funtion(s) bug
References: <49D12D9F.1000203@stats.uwo.ca>
	<XFMail.090330222854.Ted.Harding@manchester.ac.uk>
	<18897.49007.275534.467989@lynne.math.ethz.ch>
Message-ID: <loom.20090331T150244-162@post.gmane.org>

Martin Maechler <maechler <at> stat.math.ethz.ch> writes:

>     >> But lgamma(x) is log(abs(gamma(x))), so it looks okay to me.
>     >> 
>     >> Duncan Murdoch
> 
>     TH> Oops, yes! That's what comes of talking off the top of my head
>     TH> (I don't think I've ever had occasion to evaluate lgamma(x)
>     TH> for negative x, so never consciously checked in ?lgamma).
> 
>     TH> Thanks, Duncan!
> 
> Indeed.... as we all know, a picture can be worth a thousand words,
> and a simple R call such as
>        plot(lgamma, -7, 0, n=1000)
> would have saved many words, and notably spared us from
> yet-another erroneous non-bug report.
> 
> Martin

 In Kjetil's defense, he didn't submit an actual bug report --
and although his subject line does contain the word "bug",
I read his "bug report" as asking a question.  People are
allowed to make mistakes ...

  While I was reading ?lgamma I noticed that the "See Also"
section refers to gammaCody(), which is now defunct.  Perhaps
remove the sentence?

  Ben Bolker


From armstrong.whit at gmail.com  Tue Mar 31 17:45:43 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 31 Mar 2009 11:45:43 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
Message-ID: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>

for the moment, I'm using:

.onAttach <- function(libname, pkgname) {
    .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
}

.onUnload <- function(libpath) {
    dbDisconnect(.bbg.db.conn)
}


which results in a hidden global variable in the global environment.

I would prefer to make the assignment only in the package namespace.
I've looked at assignInNamespace, but I can't seem to make it work.

Is there a preferred method for doing this?

When I try adding an assignment directly in the source file, I get the
"cannot change value of locked binding" error.

What am I missing?

Thanks,
Whit


From maechler at stat.math.ethz.ch  Tue Mar 31 17:55:38 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Mar 2009 17:55:38 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are
	duplicates?"}
In-Reply-To: <49D222A0.7020601@idi.ntnu.no>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>
	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>
	<49D0BA70.3090005@idi.ntnu.no>
	<18898.6300.26434.413865@lynne.math.ethz.ch>
	<49D222A0.7020601@idi.ntnu.no>
Message-ID: <18898.15610.610205.300523@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Tue, 31 Mar 2009 16:03:12 +0200 writes:

    WK> Martin Maechler wrote:

[................]

    WK> duplicated.data.frame
    WK> # function (x, incomparables = FALSE, fromLast = FALSE, ...)
    WK> # {
    WK> #    if (!is.logical(incomparables) || incomparables)
    WK> #        .NotYetUsed("incomparables != FALSE")
    WK> #    duplicated(do.call("paste", c(x, sep = "\r")), fromLast = fromLast)
    WK> # }
    WK> # <environment: namespace:base>
    >> 
    WK> clearly, the intention here is to raise an error with a (still hardly
    WK> clear) message as in:
    >> 
    WK> .NotYetUsed("incomparables != FALSE")
    WK> # Error: argument 'incomparables != FALSE' is not used (yet)
    >> 
    WK> but instead, if(NA) is evaluated (because '!is.logical(NA) || NA'
    WK> evaluates, *obviously*, to NA) and hence the uninformative error message.
    >> 
    WK> take home point:  rtfm, *but* don't believe it.
    >> 
    >> and then be helpful to the R community and send a bug report
    >> *with* a patch if {as in this case} you are able to...
    >> 
    >> Well, that' no longer needed here,
    >> I'll fix that easily myself.
    >> 

    WK> but i *have* sent a patch already!

Ok, I believe you.  But I think you did not mention that during
this thread, ... and/or I must have overlooked your patch.

In any case the problem is now solved
[well, a better solution of course would add the "not-yet"
 functionality..]; 
thank you for the contribution.

Martin


From mail at joeconway.com  Tue Mar 31 17:54:45 2009
From: mail at joeconway.com (Joe Conway)
Date: Tue, 31 Mar 2009 08:54:45 -0700
Subject: [Rd] external equiv to R_serialize()?
In-Reply-To: <alpine.LFD.2.00.0903310655041.19538@gannet.stats.ox.ac.uk>
References: <49D191A6.8010905@joeconway.com>
	<alpine.LFD.2.00.0903310655041.19538@gannet.stats.ox.ac.uk>
Message-ID: <49D23CC5.4050300@joeconway.com>

Prof Brian Ripley wrote:
> On Mon, 30 Mar 2009, Joe Conway wrote:
> 
>> I'm trying to efficiently allow conversion of R objects to PostgreSQL 
>> bytea (raw binary) datatype within PL/R for persistent storage in 
>> Postgres tables. I have found R_serialize() which looks like what I 
>> need, -- e.g. R_serialize(object, NULL, FALSE, NULL) -- except that it 
>> is marked attribute_hidden. Is there some other externally available 
>> interface that I can use?
> 
> R_Serialize is in Rinternals.h.  R_serialize is a wrapper using 
> connections, and connections do not have a public API.

OK, thanks.

> Do note the comments in ?serialize: 'persistent' storage of objects in 
> an experimental format is somewhat contradictory.

Good point -- I'll put a suitable warning in my documentation. The 
typical use case people describe is more of a "materialized view" than 
it is primary storage, so I think this is still very useful.

Thank you for your response.

Joe


From peter.ruckdeschel at web.de  Tue Mar 31 16:41:10 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Tue, 31 Mar 2009 16:41:10 +0200
Subject: [Rd] Wishlist: optional svn-revision number tag in package
 DESCRIPTION file
Message-ID: <gqta20$7ua$1@ger.gmane.org>

Hi,

just a little wish :

Could we have one (or maybe more) standardized optional tag(s)
for package DESCRIPTION files to cover svn revision info?
This would be very useful for bug reporting...

I know that any developer is already free to append corresponding lines
to DESCRIPTION files to do something of this sort --- e.g. lines like

LastChangedDate: {$LastChangedDate: 2009-03-31 $}
LastChangedRevision: {$LastChangedRevision: 447 $}

and correspondingly setting the svn keyword properties "LastChangedDate"
and "LastChangedRevision" would clearly do (even without Makefile /
configure ...)

But as package development under svn (especially under r-forge)
is just so frequent, it would be nice to have a recommended
format that could be read out in a standardized form, say
by a function like packageDescription from package 'utils':-)

I would vote for optional extra tags "LastChangedDate"
and "LastChangedRevision".

I have attached a commented and correspondingly
modified version of packageDescription() --- if you find it
helpful feel free to integrate it to package 'utils'.

Best,
Peter
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: indices.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/b3da15ad/attachment.pl>

From ggrothendieck at gmail.com  Tue Mar 31 18:31:57 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Mar 2009 12:31:57 -0400
Subject: [Rd] Wishlist: optional svn-revision number tag in package
	DESCRIPTION file
In-Reply-To: <gqta20$7ua$1@ger.gmane.org>
References: <gqta20$7ua$1@ger.gmane.org>
Message-ID: <971536df0903310931v7c71d127wecea339c63390186@mail.gmail.com>

We need to make sure we understand the implications
for packages developed under the other major version
control systems like git, bzr and hg.

On Tue, Mar 31, 2009 at 10:41 AM, Peter Ruckdeschel
<peter.ruckdeschel at web.de> wrote:
> Hi,
>
> just a little wish :
>
> Could we have one (or maybe more) standardized optional tag(s)
> for package DESCRIPTION files to cover svn revision info?
> This would be very useful for bug reporting...
>
> I know that any developer is already free to append corresponding lines
> to DESCRIPTION files to do something of this sort --- e.g. lines like
>
> LastChangedDate: {$LastChangedDate: 2009-03-31 $}
> LastChangedRevision: {$LastChangedRevision: 447 $}
>
> and correspondingly setting the svn keyword properties "LastChangedDate"
> and "LastChangedRevision" would clearly do (even without Makefile /
> configure ...)
>
> But as package development under svn (especially under r-forge)
> is just so frequent, it would be nice to have a recommended
> format that could be read out in a standardized form, say
> by a function like packageDescription from package 'utils':-)
>
> I would vote for optional extra tags "LastChangedDate"
> and "LastChangedRevision".
>
> I have attached a commented and correspondingly
> modified version of packageDescription() --- if you find it
> helpful feel free to integrate it to package 'utils'.
>
> Best,
> Peter
>
> # ?File src/library/utils/R/indices.R
> # ?Part of the R package, http://www.R-project.org
> #
> # ?This program is free software; you can redistribute it and/or modify
> # ?it under the terms of the GNU General Public License as published by
> # ?the Free Software Foundation; either version 2 of the License, or
> # ?(at your option) any later version.
> #
> # ?This program is distributed in the hope that it will be useful,
> # ?but WITHOUT ANY WARRANTY; without even the implied warranty of
> # ?MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ?See the
> # ?GNU General Public License for more details.
> #
> # ?A copy of the GNU General Public License is available at
> # ?http://www.r-project.org/Licenses/
>
> packageDescription <- function(pkg, lib.loc=NULL, fields=NULL, drop=TRUE,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? encoding = "")
> {
> ? ?retval <- list()
> ? ?if(!is.null(fields)){
> ? ? ? ?fields <- as.character(fields)
> ? ? ? ?retval[fields] <- NA
> ? ?}
>
> ? ?pkgpath <- ""
> ? ?## If the NULL default for lib.loc is used, the loaded packages are
> ? ?## searched before the libraries.
> ? ?if(is.null(lib.loc)) {
> ? ? ? ?if(pkg == "base")
> ? ? ? ? ? ?pkgpath <- file.path(.Library, "base")
> ? ? ? ?else if((envname <- paste("package:", pkg, sep = ""))
> ? ? ? ? ? ? ? ?%in% search()) {
> ? ? ? ? ? ?pkgpath <- attr(as.environment(envname), "path")
> ? ? ? ? ? ?## could be NULL if a perverse user has been naming environmnents
> ? ? ? ? ? ?## to look like packages.
> ? ? ? ? ? ?if(is.null(pkgpath)) pkgpath <- ""
> ? ? ? ?}
> ? ?}
> ? ?if(pkgpath == "") {
> ? ? ? ?libs <- if(is.null(lib.loc)) .libPaths() else lib.loc
> ? ? ? ?for(lib in libs)
> ? ? ? ? ? ?if(file.access(file.path(lib, pkg), 5) == 0L) {
> ? ? ? ? ? ? ? ?pkgpath <- file.path(lib, pkg)
> ? ? ? ? ? ? ? ?break
> ? ? ? ? ? ?}
> ? ?}
> ? ?if(pkgpath == "") {
> ? ? ? ?## This is slow and does a lot of checking we do here,
> ? ? ? ?## but is needed for versioned installs
> ? ? ? ?pkgpath <- system.file(package = pkg, lib.loc = lib.loc)
> ? ? ? ?if(pkgpath == "") {
> ? ? ? ? ? ?warning(gettextf("no package '%s' was found", pkg), domain = NA)
> ? ? ? ? ? ?return(NA)
> ? ? ? ?}
> ? ?}
>
> ? ?## New in 2.7.0: look for installed metadata first.
>
> ? ?if(file.exists(file <- file.path(pkgpath, "Meta", "package.rds"))) {
> ? ? ? ?desc <- .readRDS(file)$DESCRIPTION
> ? ? ? ?if(length(desc) < 1)
> ? ? ? ? ? ?stop(gettextf("metadata of package '%s' is corrupt", pkg),
> ? ? ? ? ? ? ? ? domain = NA)
> ? ? ? ?desc <- as.list(desc)
> ? ?} else if(file.exists(file <- file.path(pkgpath,"DESCRIPTION"))) {
> ? ? ? ?dcf <- read.dcf(file=file)
> ? ? ? ?if(NROW(dcf) < 1L)
> ? ? ? ? ? ?stop(gettextf("DESCRIPTION file of package '%s' is corrupt", pkg),
> ? ? ? ? ? ? ? ? domain = NA)
> ? ? ? ?desc <- as.list(dcf[1,])
> ? ?} else file <- ""
>
> ? ?if(file != "") {
> ? ? ? ?## read the Encoding field if any
> ? ? ? ?enc <- desc[["Encoding"]]
> ? ? ? ?if(!is.null(enc) && !is.na(encoding)) {
> ? ? ? ? ? ?## Determine encoding and re-encode if necessary and possible.
> ? ? ? ? ? ?if((encoding != "" || Sys.getlocale("LC_CTYPE") != "C")
> ? ? ? ? ? ? ? && capabilities("iconv")) {
> ? ? ? ? ? ? ? ?## might have an invalid encoding ...
> ? ? ? ? ? ? ? ?newdesc <- try(lapply(desc, iconv, from=enc, to=encoding))
> ? ? ? ? ? ? ? ?if(!inherits(newdesc, "try-error")) desc <- newdesc
> ? ? ? ? ? ? ? ?else
> ? ? ? ? ? ? ? ? ? ?warning("'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible", call. = FALSE)
> ? ? ? ? ? ?} else
> ? ? ? ? ? ? ? ?warning("'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible", call. = FALSE)
> ? ? ? ?}
> ? ? ? ?## Peter Ruckdeschel: 31-03-09: set ok even if fields is NULL
> ? ? ? ?ok <- NULL
> ? ? ? ?if(length(names(desc)))
> ? ? ? ? ? ?ok <- 1:length(names(desc))
> ? ? ? ?## <- end of code by P.R.
> ? ? ? ?if(!is.null(fields)){
> ? ? ? ? ? ?ok <- names(desc) %in% fields
> ? ? ? ? ? ?retval[names(desc)[ok]] <- desc[ok]
> ? ? ? ?}
> ? ? ? ?else
> ? ? ? ? ? ?retval[names(desc)] <- desc
> ? ?}
>
> ? ?if((file == "") || (length(retval) == 0)){
> ? ? ? ?warning(gettextf("DESCRIPTION file of package '%s' is missing or broken", pkg), domain = NA)
> ? ? ? ?return(NA)
> ? ?}
>
> ? ?## Peter Ruckdeschel: 31-03-09: digest svn-filled svn property tags:
> ? ?for (i in c("LastChangedDate","LastChangedRevision"))
> ? ? ? ?if (i %in% names(desc)[ok])
> ? ? ? ? ? ?retval[i] <- gsub(" \\$\\}$","",
> ? ? ? ? ? ? ? ?gsub(paste("\\{\\$",i,": ",sep=""),"",
> ? ? ? ? ? ? ? ? ? retval[i]))
> ? ?## <- end of code by P.R.
>
> ? ?if(drop & length(fields) == 1L)
> ? ? ? ?return(retval[[1L]])
>
> ? ?class(retval) <- "packageDescription"
> ? ?if(!is.null(fields)) attr(retval, "fields") <- fields
> ? ?attr(retval, "file") <- file
> ? ?retval
> }
>
>
> print.packageDescription <- function(x, ...)
> {
> ? ?xx <- x
> ? ?xx[] <- lapply(xx, function(x) if(is.na(x)) "NA" else x)
> ? ?write.dcf(as.data.frame.list(xx, optional = TRUE))
> ? ?cat("\n-- File:", attr(x, "file"), "\n")
> ? ?if(!is.null(attr(x, "fields"))){
> ? ? ? ?cat("-- Fields read: ")
> ? ? ? ?cat(attr(x, "fields"), sep=", ")
> ? ? ? ?cat("\n")
> ? ?}
> ? ?invisible(x)
> }
>
> index.search <- function(topic, path, file = "AnIndex", type = "help")
> ? ?.Internal(index.search(topic, path, file, .Platform$file.sep, type))
>
> print.packageIQR <-
> function(x, ...)
> {
> ? ?db <- x$results
> ? ?## Split according to Package.
> ? ?out <- if(nrow(db) == 0L)
> ? ? ? ? NULL
> ? ?else
> ? ? ? ?lapply(split(1 : nrow(db), db[, "Package"]),
> ? ? ? ? ? ? ? function(ind) db[ind, c("Item", "Title"),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?drop = FALSE])
> ? ?outFile <- tempfile("RpackageIQR")
> ? ?outConn <- file(outFile, open = "w")
> ? ?first <- TRUE
> ? ?for(pkg in names(out)) {
> ? ? ? ?writeLines(paste(ifelse(first, "", "\n"), x$title,
> ? ? ? ? ? ? ? ? ? ? ? ? " in package ", sQuote(pkg), ":\n",
> ? ? ? ? ? ? ? ? ? ? ? ? sep = ""),
> ? ? ? ? ? ? ? ? ? outConn)
> ? ? ? ?writeLines(formatDL(out[[pkg]][, "Item"],
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?out[[pkg]][, "Title"]),
> ? ? ? ? ? ? ? ? ? outConn)
> ? ? ? ?first <- FALSE
> ? ?}
> ? ?if(first) {
> ? ? ? ?close(outConn)
> ? ? ? ?unlink(outFile)
> ? ? ? ?writeLines(paste("no", tolower(x$title), "found"))
> ? ? ? ?if(!is.null(x$footer))
> ? ? ? ? ? ?writeLines(c("", x$footer))
> ? ?}
> ? ?else {
> ? ? ? ?if(!is.null(x$footer))
> ? ? ? ? ? ?writeLines(c("\n", x$footer), outConn)
> ? ? ? ?close(outConn)
> ? ? ? ?file.show(outFile, delete.file = TRUE,
> ? ? ? ? ? ? ? ? ?title = paste("R", tolower(x$title)))
> ? ?}
> ? ?invisible(x)
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From mtmorgan at fhcrc.org  Tue Mar 31 18:41:01 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 31 Mar 2009 09:41:01 -0700
Subject: [Rd] what is the preferred method to create a package local
 variable?
In-Reply-To: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com> (Whit
	Armstrong's message of "Tue, 31 Mar 2009 11:45:43 -0400")
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
Message-ID: <6phocvh7ihu.fsf@gopher4.fhcrc.org>

Hi Whit --

Whit Armstrong <armstrong.whit at gmail.com> writes:

> for the moment, I'm using:
>
> .onAttach <- function(libname, pkgname) {
>     .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
> }
>
> .onUnload <- function(libpath) {
>     dbDisconnect(.bbg.db.conn)
> }
>
>
> which results in a hidden global variable in the global environment.
>
> I would prefer to make the assignment only in the package namespace.
> I've looked at assignInNamespace, but I can't seem to make it work.
>
> Is there a preferred method for doing this?

I don't konw about preferred, but one method is

pkgVars <- local({
    x <- NULL
    list(getX=function() x, setX=function(value) x <<- value)
})

with use

> pkgVars$getX()
NULL
> pkgVars$setX(123)
> pkgVars$getX()
[1] 123

This introduces a different programming paradigm (a list of functions)
that might not be familiar for end-users and is not readily amenable
to documentation. A probably better way is

pkgVars <- new.env(parent=emptyenv())
getX <- function() get("x", pkgVars, inherits=FALSE)
setX <- function(value) assign("x", value, envir=pkgVars)

> getX()
Error in get("x", pkgVars, inherits = FALSE) : object 'x' not found
> setX(123)
> getX()
[1] 123

A tidier response to the first getX() could be arranged with something
like

pkgVars <- local({
    env <- new.env(parent=emptyenv())
    env[["x"]] <- NULL
    env
})

pkgVars, getX, and setX can be exported from the name space or not.

FWIW, usually one wants .onLoad rather than .onAttach, so that a
package import-ing your package (not just depend-ing, or when used
directly in an interactive session) will execute the setup code.

Hope that helps and is not too misleading.

Martin

> When I try adding an assignment directly in the source file, I get the
> "cannot change value of locked binding" error.
>
> What am I missing?
>
> Thanks,
> Whit
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From h.wickham at gmail.com  Tue Mar 31 18:53:16 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 31 Mar 2009 11:53:16 -0500
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
Message-ID: <f8e6ff050903310953ye9e188eob864616ec00da5ac@mail.gmail.com>

For saving the previous plot in ggplot2, I use the following:

.plot_store <- function() {
  .last_plot <- NULL

  list(
    get = function() .last_plot,
    set = function(value) .last_plot <<- value
  )
}
.store <- .plot_store()

set_last_plot <- function(value) .store$set(value)
last_plot <- function() .store$get()

which is basically equivalent to Martin's first suggestion, with some
wrapper functions.

Hadley

On Tue, Mar 31, 2009 at 10:45 AM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> for the moment, I'm using:
>
> .onAttach <- function(libname, pkgname) {
> ? ?.bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
> }
>
> .onUnload <- function(libpath) {
> ? ?dbDisconnect(.bbg.db.conn)
> }
>
>
> which results in a hidden global variable in the global environment.
>
> I would prefer to make the assignment only in the package namespace.
> I've looked at assignInNamespace, but I can't seem to make it work.
>
> Is there a preferred method for doing this?
>
> When I try adding an assignment directly in the source file, I get the
> "cannot change value of locked binding" error.
>
> What am I missing?
>
> Thanks,
> Whit
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
http://had.co.nz/


From murdoch at stats.uwo.ca  Tue Mar 31 18:58:23 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 31 Mar 2009 12:58:23 -0400
Subject: [Rd] Wishlist: optional svn-revision number tag in package
 DESCRIPTION file
In-Reply-To: <gqta20$7ua$1@ger.gmane.org>
References: <gqta20$7ua$1@ger.gmane.org>
Message-ID: <49D24BAF.7060405@stats.uwo.ca>

On 3/31/2009 10:41 AM, Peter Ruckdeschel wrote:
> Hi,
> 
> just a little wish :
> 
> Could we have one (or maybe more) standardized optional tag(s)
> for package DESCRIPTION files to cover svn revision info?
> This would be very useful for bug reporting...
> 
> I know that any developer is already free to append corresponding lines
> to DESCRIPTION files to do something of this sort --- e.g. lines like
> 
> LastChangedDate: {$LastChangedDate: 2009-03-31 $}
> LastChangedRevision: {$LastChangedRevision: 447 $}

That will give you the last change to the DESCRIPTION file, not the last 
change to the package, so it could be misleading.  Last time I looked, 
there wasn't a way in svn to auto update a file that wasn't involved in 
a changeset.  (You could put something into your build script to call 
svnversion, but I don't know anything simpler.)

Duncan Murdoch


> 
> and correspondingly setting the svn keyword properties "LastChangedDate"
> and "LastChangedRevision" would clearly do (even without Makefile /
> configure ...)
> 
> But as package development under svn (especially under r-forge)
> is just so frequent, it would be nice to have a recommended
> format that could be read out in a standardized form, say
> by a function like packageDescription from package 'utils':-)
> 
> I would vote for optional extra tags "LastChangedDate"
> and "LastChangedRevision".
> 
> I have attached a commented and correspondingly
> modified version of packageDescription() --- if you find it
> helpful feel free to integrate it to package 'utils'.


From ligges at statistik.tu-dortmund.de  Tue Mar 31 19:06:09 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 Mar 2009 19:06:09 +0200
Subject: [Rd] installing RMySQL (PR#13633)
In-Reply-To: <20090331043011.D20E92832183@mail.pubhealth.ku.dk>
References: <20090331043011.D20E92832183@mail.pubhealth.ku.dk>
Message-ID: <49D24D81.4050203@statistik.tu-dortmund.de>



ankheedutta at gmail.com wrote:
> Full_Name: Ankhee Dutta
> Version: 2.3


1. Please read the FAQs on how to report bugs: Always use a recent 
version of R, your version has been released roughly 36 months ago! 
R-2.9.0 is to be released in April. Hence please check bugs with the 
current pre-release version!

2. This is about package RMySQL, hence again, please read the FAQs on 
how to report bugs: Bug reports on contributed packages should go to the 
package maintainer, not to the R bug tracking system.

3. This is probably not even a bug in RMySQL. You obviously have not 
installed the MySQL header files (i.e. devel files).

Uwe Ligges




> OS: LINUX
> Submission from: (NULL) (202.141.12.97)
> 
> 
> 
> 
> I have a linux system of Mandriva-2007 with R version 2.3.0 and MySQL with
> 5.0.0. I have also got DBI-R database interface version-0.1-11 installed on
> my Linux system.While installing RMySQL package version 0.5-11 i am  facing
>  problem .
> 
> while installation the error report which is coming is as follows:
> 
> 
> 
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... no
> checking for mysql.h... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... no
> checking for /usr/local/mysql/include/
> mysql/mysql.h... no
> checking for /opt/include/mysql/mysql.h... no
> checking for /include/mysql/mysql.h... no
> 
> Configuration error:
>  could not find the MySQL installation include and/or library
>  directories.  Manually specify the location of the MySQL
>  libraries and the header files and re-run R CMD INSTALL.
> 
> INSTRUCTIONS:
> 
> 1. Define and export the 2 shell variables PKG_CPPFLAGS and
>   PKG_LIBS to include the directory for header files (*.h)
>   and libraries, for example (using Bourne shell syntax):
> 
>      export PKG_CPPFLAGS="-I<MySQL-include-dir>"
>      export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"
> 
>   Re-run the R INSTALL command:
> 
>      R CMD INSTALL RMySQL_<version>.tar.gz
> 
> 2. Alternatively, you may pass the configure arguments
>      --with-mysql-dir=<base-dir> (distribution directory)
>   or
>      --with-mysql-inc=<base-inc> (where MySQL header files reside)
>      --with-mysql-lib=<base-lib> (where MySQL libraries reside)
>   in the call to R INSTALL --configure-args='...'
> 
>   R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
> RMySQL_<version>.tar.gz
> 
> ERROR: configuration failed for package 'RMySQL'
> ** Removing '/usr/lib/R/library/RMySQL'
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Mar 31 19:09:48 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Mar 2009 13:09:48 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
Message-ID: <971536df0903311009y27fd70f8g9413fbb66ab5fe8d@mail.gmail.com>

Look at the zzz.R file in the lattice package and the .LatticeEnv
variable in particular.
Also, when running lattice try this and look for .LatticeEnv in the output:

ls(asNamespace("lattice"), all = TRUE)


On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> for the moment, I'm using:
>
> .onAttach <- function(libname, pkgname) {
> ? ?.bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
> }
>
> .onUnload <- function(libpath) {
> ? ?dbDisconnect(.bbg.db.conn)
> }
>
>
> which results in a hidden global variable in the global environment.
>
> I would prefer to make the assignment only in the package namespace.
> I've looked at assignInNamespace, but I can't seem to make it work.
>
> Is there a preferred method for doing this?
>
> When I try adding an assignment directly in the source file, I get the
> "cannot change value of locked binding" error.
>
> What am I missing?
>
> Thanks,
> Whit
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Tue Mar 31 19:21:48 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 31 Mar 2009 12:21:48 -0500
Subject: [Rd] Wishlist: optional svn-revision number tag in package
 DESCRIPTION file
In-Reply-To: <49D24BAF.7060405@stats.uwo.ca>
References: <gqta20$7ua$1@ger.gmane.org>
	<49D24BAF.7060405@stats.uwo.ca>
Message-ID: <18898.20780.532565.750117@ron.nulle.part>


On 31 March 2009 at 12:58, Duncan Murdoch wrote:
| On 3/31/2009 10:41 AM, Peter Ruckdeschel wrote:
| > Could we have one (or maybe more) standardized optional tag(s)
| > for package DESCRIPTION files to cover svn revision info?
| > This would be very useful for bug reporting...

Indeed. I am doing something similar with local packages at work.

| > I know that any developer is already free to append corresponding lines
| > to DESCRIPTION files to do something of this sort --- e.g. lines like
| > 
| > LastChangedDate: {$LastChangedDate: 2009-03-31 $}
| > LastChangedRevision: {$LastChangedRevision: 447 $}
| 
| That will give you the last change to the DESCRIPTION file, not the last 
| change to the package, so it could be misleading.  Last time I looked, 
| there wasn't a way in svn to auto update a file that wasn't involved in 
| a changeset.  (You could put something into your build script to call 
| svnversion, but I don't know anything simpler.)

Yes, I have been using configure for that (which can be really any type of
executable script rather than something from autoconf). One can then either
update a placeholder in DESCRIPTION.in to substitute the revision number
and/or create a package-local function reporting svn revision, build time,
etc.  

It may make sense to think about a more general scheme. A common problem is
of course once again portability and the set of required tools.

Dirk

-- 
Three out of two people have difficulties with fractions.


From macrakis at alum.mit.edu  Tue Mar 31 19:27:21 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 31 Mar 2009 13:27:21 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <6phocvh7ihu.fsf@gopher4.fhcrc.org>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
	<6phocvh7ihu.fsf@gopher4.fhcrc.org>
Message-ID: <8b356f880903311027o7f550d66n12b8608c605f92dd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/6c205414/attachment.pl>

From mtmorgan at fhcrc.org  Tue Mar 31 19:51:08 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 31 Mar 2009 10:51:08 -0700
Subject: [Rd] what is the preferred method to create a package local
 variable?
In-Reply-To: <8b356f880903311027o7f550d66n12b8608c605f92dd@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>	
	<6phocvh7ihu.fsf@gopher4.fhcrc.org>
	<8b356f880903311027o7f550d66n12b8608c605f92dd@mail.gmail.com>
Message-ID: <49D2580C.1070602@fhcrc.org>

Stavros Macrakis wrote:
> On Tue, Mar 31, 2009 at 12:41 PM, Martin Morgan <mtmorgan at fhcrc.org 
> <mailto:mtmorgan at fhcrc.org>> wrote:
> 
>     I don't konw about preferred, but one method is
> 
>     pkgVars <- local({
>        x <- NULL
>        list(getX=function() x, setX=function(value) x <<- value)
>     })
> 
>     with use
> 
>      > pkgVars$getX()
>     ...
>     This introduces a different programming paradigm (a list of functions)
>     that might not be familiar for end-users and is not readily amenable
>     to documentation.
> 
> 
> Why "not readily amenable to documentation"?  If the user doesn't need

in the sense that ?pkgVars$getX would not do anything useful (I guess -- 
perhaps if there were an alias, I don't really know) and that R CMD 
check would not detect inconsistencies between 'usage', code, and 
documentation, for instance.

> to understand the structure, he can consider the "$" as simply part of 

but that would be additional syntax for the user to learn, which would 
be counter-productive.

> the function name.  And I wouldn't name it pkgVars but pkg.

In general I would rather expose the interface than the object, which 
lead me to my so-called 'better way'.

>  
> 
>     A probably better way is
> 
>     pkgVars <- new.env(parent=emptyenv())
>     getX <- function() get("x", pkgVars, inherits=FALSE)
>     setX <- function(value) assign("x", value, envir=pkgVars)
> 
> 
> I think a simpler, clearer way to make getX etc. globally visible is:
> 
>   local({
>    x <- NULL
>    getX <<- function() x
>    setX  <<- function(value) x <<- value
>  })

By 'globally' you mean in the package name space, I guess (this is 
relying on a fairly nuanced understanding of what the 'top' environment 
is during package building). For me the paradigm of <<- to the top 
environment (or first getX found in the search path) opens the door to 
doing dumb things like overwriting user variables. Maybe a risk you're 
willing to engage within your own name space...

Martin

> 
> To my taste, this is much cleaner than explicitly referencing environments.
> 
>             -s


-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From mail at joeconway.com  Tue Mar 31 21:17:56 2009
From: mail at joeconway.com (Joe Conway)
Date: Tue, 31 Mar 2009 12:17:56 -0700
Subject: [Rd] external equiv to R_serialize()?
In-Reply-To: <alpine.LFD.2.00.0903310655041.19538@gannet.stats.ox.ac.uk>
References: <49D191A6.8010905@joeconway.com>
	<alpine.LFD.2.00.0903310655041.19538@gannet.stats.ox.ac.uk>
Message-ID: <49D26C64.3090609@joeconway.com>

Prof Brian Ripley wrote:
> On Mon, 30 Mar 2009, Joe Conway wrote:
> 
>> I'm trying to efficiently allow conversion of R objects to PostgreSQL 
>> bytea (raw binary) datatype within PL/R for persistent storage in 
>> Postgres tables. I have found R_serialize() which looks like what I 
>> need, -- e.g. R_serialize(object, NULL, FALSE, NULL) -- except that it 
>> is marked attribute_hidden. Is there some other externally available 
>> interface that I can use?
> 
> R_Serialize is in Rinternals.h.  R_serialize is a wrapper using 
> connections, and connections do not have a public API.

Sorry if I'm missing something, but it seems that although R_Serialize() 
is public, the support functions needed to use R_outpstream_t are not. 
So I'm back to my initial question -- is there an alternative public 
interface that I can use?

Thanks,

Joe


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 31 21:24:12 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 31 Mar 2009 21:24:12 +0200
Subject: [Rd] as.data.frame peculiarities
In-Reply-To: <8b356f880903310718m2c17857btb6e4c18258a31ebb@mail.gmail.com>
References: <8b356f880903310718m2c17857btb6e4c18258a31ebb@mail.gmail.com>
Message-ID: <49D26DDC.3000003@idi.ntnu.no>

Stavros Macrakis wrote:
> The documentation of as.data.frame is not explicit about how it generates
> column names for the simple vector case, but it seems to use the character
> form of the quoted argument, e.g.
>
> names(as.data.frame(1:3))
> [1] "1:3"
>
> But there is a strange case:
>
> names(as.data.frame(c("a")))
> [1] "if (stringsAsFactors) factor(x) else x"
>
>   

gosh!  you don't even need the c():

    names(as.data.frame(''))
    # same as above

i thought you don''t even need the '', but then you're served with the
following highly informative message:

    names(as.data.frame())
    # Error in as.data.frame() :
    #   element 1 is empty;
    #    the part of the args list of 'is.null' being evaluated was:
    #    (x)
   
which actually comes from as.data.frame().


> I feel fairly comfortable calling this a bug, though there is no explicit
> specification.
>   

maybe there is none so that it can always be claimed that you deal with
an intentional, but not (yet) documented feature, rather than a bug.

let's investigate this feature.  in

    names(as.data.frame('a'))

as.data.frame is generic, 'a' is character, thus
as.data.frame.character(x, ...)  is called with x = 'a'.  here's  the
code for as.data.frame.character:

    function (x, ..., stringsAsFactors = default.stringsAsFactors())
        as.data.frame.vector(if (stringsAsFactors) factor(x) else x, ...)

and the as.data.frame.vector it calls:

    function (x, row.names = NULL, optional = FALSE, ...)
    {
        nrows <- length(x)
        nm <- paste(deparse(substitute(x), width.cutoff = 500L),
            collapse = " ")
        if (is.null(row.names)) {
            if (nrows == 0L)
                row.names <- character(0L)
            else if (length(row.names <- names(x)) == nrows &&
!any(duplicated(row.names))) {
            }
            else row.names <- .set_row_names(nrows)
        }
        names(x) <- NULL
        value <- list(x)
        if (!optional)
            names(value) <- nm
        attr(value, "row.names") <- row.names
        class(value) <- "data.frame"
        value
    }

watch carefully:  nm = paste(deparse(substitute(x)), width.cutoff=500L),
that is:

    nm = paste("if (stringsAsFactors) factor(x) else x", width.cutoff=500L)


x = factor('a'), row.names==NULL, names(x)==NULL, and nrows = 1, and
thus row.names = .set_row_names(1) = c(NA, -1)  (interesting; see
.set_row_names).

and then we have:

    x = factor('a') # the input
    names(x) = NULL
    value = list(x) # value == list(factor('a'))
    names(value) = "if (stringsAsFactors) factor(x) else x" # the value
of nm
    attr(value, 'row.names') = c(NA, -1) # the value of row.names
    class(value) = 'data.frame'
    value

here you go:  as some say, the answer is always in the code.  that's how
ugly hacks with deparse/substitute lead r core developers to produce
ugly bugs.  very useful, indeed.
   

> There is another strange case which I don't understand.
>
> The specification of 'optional' is:
>
>    optional: logical. If 'TRUE', setting row names and converting column
>           names (to syntactic names: see 'make.names') is optional.
>
> I am not sure what this means and why it is useful.  In practice, it seems
> to produce a structure of class data.frame which exhibits some very odd
> behavior:
>
>   
>> d <- as.data.frame(c("a"),optional=TRUE)
>> class(d)
>>     
> [1] "data.frame"
>   
>> d
>>     
>   structure("a", class = "AsIs")                   <<< where does this
> column name come from?
> 1                              a'
>   

gosh...  rtfc, again; code as above, but this time optional=TRUE so
names(value) = nm does not apply:

    x = factor('a') # the input
    names(x) = NULL
    value = list(x) # value == list(factor('a'))
    attr(value, 'row.names') = c(NA, -1) # the value of row.names
    class(value) = 'data.frame'
    value

here you go.


>> names(d)
>>     
> NULL                                            <<< not from names()
>   

yes, because it was explicitly set to NULL, second line above.

>> dput(d)
>>     
> structure(list(structure(1L, .Label = "a", class = "factor")), row.names =
> c(NA,
> -1L), class = "data.frame")            <<< and it doesn't show up in dput
>   

yes, because there are no names there!  it's format.data.frame, called
from print.data.frame, called from print(value), that makes up this
column name;  rtfc.

seems like there's a need for post-implementation design.


for the desserts, here's another curious, somewhat related example:

    data = data.frame(1)
    row.names(data) = TRUE
    data
    #      X1
    # TRUE  1
   
    as.data.frame(1, row.names=TRUE)
    # Error in attr(value, "row.names") <- row.names :
    #   row names must be 'character' or 'integer', not 'logical'

probably not a bug, because ?as.data.frame says:

"
row.names: 'NULL' or a character vector giving the row names for the
          data frame.  Missing values are not allowed.
"

so it's rather a design flaw.  much harder to fix in r.


best,
vQ


From zwerdlds at gmail.com  Tue Mar 31 21:25:47 2009
From: zwerdlds at gmail.com (David Zwerdling)
Date: Tue, 31 Mar 2009 12:25:47 -0700
Subject: [Rd] Compile R Library with GCC garbage collection on or supported
Message-ID: <a5fee3720903311225k3446b8a3t5f8dd8fcb9da247d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/9fccf2dc/attachment.pl>

From rdpeng at gmail.com  Tue Mar 31 21:35:46 2009
From: rdpeng at gmail.com (Roger Peng)
Date: Tue, 31 Mar 2009 15:35:46 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
Message-ID: <66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>

I usually use environments for this. So, in one of the R files for the
package, just do

.localstuff <- new.env()

Then, in functions you can do things like

.localstuff$bbg.db.conn <- dbConnect(...)

-roger

On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> for the moment, I'm using:
>
> .onAttach <- function(libname, pkgname) {
> ? ?.bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
> }
>
> .onUnload <- function(libpath) {
> ? ?dbDisconnect(.bbg.db.conn)
> }
>
>
> which results in a hidden global variable in the global environment.
>
> I would prefer to make the assignment only in the package namespace.
> I've looked at assignInNamespace, but I can't seem to make it work.
>
> Is there a preferred method for doing this?
>
> When I try adding an assignment directly in the source file, I get the
> "cannot change value of locked binding" error.
>
> What am I missing?
>
> Thanks,
> Whit
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From phgrosjean at sciviews.org  Tue Mar 31 21:51:20 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 31 Mar 2009 21:51:20 +0200
Subject: [Rd] what is the preferred method to create a package
	local	variable?
In-Reply-To: <66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>
Message-ID: <49D27438.6010806@sciviews.org>

The best way is to have those variable hidden in the package's 
workspace, as explained by Roger Peng.

However, if you like to use a mechanism managing an environment 
specifically dedicated to temporary variables very easily, look at 
assignTemp() and getTemp() from svMisc package. The advantage is an 
easier sharing of such variables between different packages (plus the 
bonus of easy management of default values, overwriting or not of 
current content if the variable already exists, ...). The temporary 
environment (TempEnv) is always located in the forelast position just 
before 'base'.

In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
Best,

Philippe Grosjean


Roger Peng wrote:
> I usually use environments for this. So, in one of the R files for the
> package, just do
> 
> .localstuff <- new.env()
> 
> Then, in functions you can do things like
> 
> .localstuff$bbg.db.conn <- dbConnect(...)
> 
> -roger
> 
> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
> <armstrong.whit at gmail.com> wrote:
>> for the moment, I'm using:
>>
>> .onAttach <- function(libname, pkgname) {
>>    .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>> }
>>
>> .onUnload <- function(libpath) {
>>    dbDisconnect(.bbg.db.conn)
>> }
>>
>>
>> which results in a hidden global variable in the global environment.
>>
>> I would prefer to make the assignment only in the package namespace.
>> I've looked at assignInNamespace, but I can't seem to make it work.
>>
>> Is there a preferred method for doing this?
>>
>> When I try adding an assignment directly in the source file, I get the
>> "cannot change value of locked binding" error.
>>
>> What am I missing?
>>
>> Thanks,
>> Whit
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Mar 31 21:58:52 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 31 Mar 2009 21:58:52 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are
	duplicates?"}
In-Reply-To: <18898.15610.610205.300523@lynne.math.ethz.ch>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>	<49D0BA70.3090005@idi.ntnu.no>	<18898.6300.26434.413865@lynne.math.ethz.ch>	<49D222A0.7020601@idi.ntnu.no>
	<18898.15610.610205.300523@lynne.math.ethz.ch>
Message-ID: <49D275FC.9000204@idi.ntnu.no>

Martin Maechler wrote:
>
>     >> 
>     >> and then be helpful to the R community and send a bug report
>     >> *with* a patch if {as in this case} you are able to...
>     >> 
>     >> Well, that' no longer needed here,
>     >> I'll fix that easily myself.
>     >> 
>
>     WK> but i *have* sent a patch already!
>
> Ok, I believe you.  But I think you did not mention that during
> this thread, ... and/or I must have overlooked your patch.
>
> In any case the problem is now solved
> [well, a better solution of course would add the "not-yet"
>  functionality..]; 
> thank you for the contribution.
>   

i attach the patch post for reference.  note that you need to fix all of
the functions in duplicated.R that share the buggy code.  (yes, this was
another thread;  i submitted a bug report, and then sent a follow-up
post with a patch).

vQ


-------------- next part --------------
An embedded message was scrubbed...
From: Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
Subject: Re: [Rd] duplicated fails to rise correct errors (PR#13632)
Date: Mon, 30 Mar 2009 15:18:25 +0200
Size: 9138
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/b97b0022/attachment.mht>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: duplicated.R.diff
Type: text/x-diff
Size: 1536 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090331/b97b0022/attachment.bin>

