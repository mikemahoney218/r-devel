From Antoine.Lizee at ucsf.edu  Fri Aug  1 04:46:29 2014
From: Antoine.Lizee at ucsf.edu (Lizee, Antoine)
Date: Fri, 1 Aug 2014 02:46:29 +0000
Subject: [Rd] Conversion for Date to POSIXct : Small Bug in
 as.POSIXct.Date() ?
Message-ID: <F22EB940B488C545AA92FC7B292D7E085EB46F@ex09.net.ucsf.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140801/31cdd950/attachment.pl>

From ross at biostat.ucsf.edu  Fri Aug  1 19:53:37 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 01 Aug 2014 10:53:37 -0700
Subject: [Rd] modifying a persistent (reference) class
Message-ID: <1406915617.9451.47.camel@localhost>

I saved objects that were defined using several reference classes.
Later I modified the definition of reference classes a bit, creating new
functions and deleting old ones.  The total number of functions did not
change.  When I read them back I could only access some of the original
data.

I asked on the user list and someone suggested sticking with the old
class definitions, creating new classes, reading in the old data, and
converting it to the new classes.  This would be awkward (I want the
"new" classes to have the same name as the "old" ones), and I can
probably just leave the old definitions and define the new functions I
need outside of the reference classes.

Are there any better alternatives?

On reflection, it's a little surprising that changing the code for a
reference class makes any difference to an existing instance, since all
the function definitions seem to be attached to the instance.  One
problem I've had in the past was precisely that redefining a method in a
reference class did not change the behavior of existing instances.  So
I've tried to follow the advice to keep the methods light-weight.

In this case I was trying to move from a show method (that just printed)
to a summary method that returned a summary object.  So I wanted to add
a summary method and redefine the show to call summary in the base
class, removing all the subclass definitions of show.

Regular S4 classes are obviously not as sensitive since they usually
don't include the functions that operate on them, but I suppose if you
changed the slots you'd be in similar trouble.

Some systems keep track of versions of class definitions and allow one
to write code to migrate old to new forms automatically when the data
are read in.  Does R have anything like that?

The system on which I encountered the problems was running R 2.15.


From rowe at muxspace.com  Fri Aug  1 20:42:39 2014
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Fri, 1 Aug 2014 14:42:39 -0400
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <1406915617.9451.47.camel@localhost>
References: <1406915617.9451.47.camel@localhost>
Message-ID: <852F505F-BB94-4825-A118-40D685240574@muxspace.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140801/d08e2793/attachment.pl>

From ross at biostat.ucsf.edu  Fri Aug  1 21:18:00 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 01 Aug 2014 12:18:00 -0700
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <852F505F-BB94-4825-A118-40D685240574@muxspace.com>
References: <1406915617.9451.47.camel@localhost>
	<852F505F-BB94-4825-A118-40D685240574@muxspace.com>
Message-ID: <1406920680.9451.64.camel@localhost>

On Fri, 2014-08-01 at 14:42 -0400, Brian Lee Yung Rowe wrote:
> Ross,
> 
> 
> This is generally a hard problem in software systems. The only
> language I know that explicitly addresses it is Erlang. Ultimately you
> need a system upgrade process, which defines how to update the data in
> your system to match a new version of the system. You could do this by
> writing a script that 
> 1) loads the old version of your library
> 2) loads your data/serialized reference classes
> 3) exports data to some intermediate format (eg a list)
> 4) loads new version of library
> 5) imports data from intermediate format
My recollection is that in Gemstone's smalltalk database you can define
methods associated with a class that describe how to change an instance
from one version to another.  You also have the choice of upgrading all
persistent objects at once or doing so lazily, i.e., as they are
retrieved.

The brittleness of the representation depends partly on the details.  If
a class has 2 slots, a and b, and the only thing on disk is the contents
of a and the contents of b, almost any change will screw things up.
However, if the slot name is persisted with the instance it's much
easier to reconstruct the instance of the class changes (if slot c is
added and not on disk, set it to nil; if b is removed, throw it out when
reading from disk).  Once could also persist the class definition, or
key elements of it, with individual instances referring to the
definition.

I don't know which, if any of these strategies, R uses for reference or
other classes.
> 
> 
> Once you've gone through the upgrade process, arguably it's better to
> persist the data in a format that is decoupled from your objects since
> then future upgrades would simply be
> 1) load new library
> 2) import data from intermediate format
Arguably :)  As I said, some representations could do this
automatically.  And there are still issues such as a change in the type
of a slot, or rules for filling new slots, that would require
intervention.

In my experience with other object systems, usually methods are
attributes of the class.  For R reference classes they appear to be
attributes of the instance, potentially modifiable on a per-instance
basis.

Ross
> 
> 
> which is no different from day-to-day operation of your app/system (ie
> you're always writing to and reading from the intermediate format). 
> 
> 
> Warm regards,
> Brian
> 
> ?????
> Brian Lee Yung Rowe
> Founder, Zato Novo
> Professor, M.S. Data Analytics, CUNY
> 
> On Aug 1, 2014, at 1:54 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> 
> 
> > I saved objects that were defined using several reference classes.
> > Later I modified the definition of reference classes a bit, creating
> > new
> > functions and deleting old ones.  The total number of functions did
> > not
> > change.  When I read them back I could only access some of the
> > original
> > data.
> > 
> > I asked on the user list and someone suggested sticking with the old
> > class definitions, creating new classes, reading in the old data,
> > and
> > converting it to the new classes.  This would be awkward (I want the
> > "new" classes to have the same name as the "old" ones), and I can
> > probably just leave the old definitions and define the new functions
> > I
> > need outside of the reference classes.
> > 
> > Are there any better alternatives?
> > 
> > On reflection, it's a little surprising that changing the code for a
> > reference class makes any difference to an existing instance, since
> > all
> > the function definitions seem to be attached to the instance.  One
> > problem I've had in the past was precisely that redefining a method
> > in a
> > reference class did not change the behavior of existing instances.
> >  So
> > I've tried to follow the advice to keep the methods light-weight.
> > 
> > In this case I was trying to move from a show method (that just
> > printed)
> > to a summary method that returned a summary object.  So I wanted to
> > add
> > a summary method and redefine the show to call summary in the base
> > class, removing all the subclass definitions of show.
> > 
> > Regular S4 classes are obviously not as sensitive since they usually
> > don't include the functions that operate on them, but I suppose if
> > you
> > changed the slots you'd be in similar trouble.
> > 
> > Some systems keep track of versions of class definitions and allow
> > one
> > to write code to migrate old to new forms automatically when the
> > data
> > are read in.  Does R have anything like that?
> > 
> > The system on which I encountered the problems was running R 2.15.
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 


From rowe at muxspace.com  Fri Aug  1 22:06:37 2014
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Fri, 1 Aug 2014 16:06:37 -0400
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <1406920680.9451.64.camel@localhost>
References: <1406915617.9451.47.camel@localhost>
	<852F505F-BB94-4825-A118-40D685240574@muxspace.com>
	<1406920680.9451.64.camel@localhost>
Message-ID: <6AF0CD15-A22B-4072-9A29-C184FF4E5DA2@muxspace.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140801/d2d84eb7/attachment.pl>

From ross at biostat.ucsf.edu  Fri Aug  1 22:47:52 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 01 Aug 2014 13:47:52 -0700
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <6AF0CD15-A22B-4072-9A29-C184FF4E5DA2@muxspace.com>
References: <1406915617.9451.47.camel@localhost>
	<852F505F-BB94-4825-A118-40D685240574@muxspace.com>
	<1406920680.9451.64.camel@localhost>
	<6AF0CD15-A22B-4072-9A29-C184FF4E5DA2@muxspace.com>
Message-ID: <1406926072.9451.90.camel@localhost>

On Fri, 2014-08-01 at 16:06 -0400, Brian Lee Yung Rowe wrote:
> Ross,
> 
> 
> Ah I didn't think about Smalltalk. Doesn't surprise me that they
> supported upgrades of this sort. That aside I think the question is
> whether it's realistic for a language like R to support such a
> mechanism automatically. Smalltalk and Erlang both have tight
> semantics that would be hard to establish in R (given the multiple
> object systems and dispatching systems). 
> 
> 
> I'm a functional guy so to me it's natural to separate the data from
> the functions/methods. Having spent years writing OOP code I walked
> away concluding that OOP makes things more complicated for the sake of
> being OOP (eg no first class functions). 
In smalltalk everything is an object, and that includes functions,
including class methods.
> Obviously that's changing, and in a language like R it's less of an
> issue. However, something like object serialization smells
> suspiciously similar. If you know that serializing objects is brittle,
> why not look for an alternative approach as opposed to chasing that
> rainbow?
My immediate problem is/was that I have serialized objects representing
weeks of CPU time.  I have to work with them, not some other
representation they might have.  And it's much more natural to work with
R's native persistence than some other scheme I cook up.

I think persistence requires serialization.  The serialization can be
more or less brittle, but I don't think there is an alternative to
serialization.

Since I just worked around my immediate problem a few minutes ago (by
retaining the original class definitions and using setMethod to create
summary methods), my interests are a bit more theoretical.

First, I'd like to understand more about exactly what is saved to disk
for reference and other classes, in particular how much meta-information
they contain.  And my mental model for reference class persistence is
clearly wrong, because in that model instances based on old definitions
come back intact (albeit not with the new method definitions or other
new slots), whereas mine seemed to come back damaged.

Second, I'm still hoping for some elegant way around this problem (how
to redefine classes and still use saved versions from older definitions)
for the future, both with reference and regular classes.  Or at least
some rules about what changes, if any, are safe to make in class
definitions after an instance has been persisted.
> 
Third, if changes to R could make things better, I'm hoping some
developers might take them up.  I realize that is unlikely to happen,
for many good reasons, but I can still hope :)

Ross
> 
> Warm regards,
> Brian
> 
> ?????
> Brian Lee Yung Rowe
> Founder, Zato Novo
> Professor, M.S. Data Analytics, CUNY
> 
> On Aug 1, 2014, at 3:33 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> 
> 
> > On Fri, 2014-08-01 at 14:42 -0400, Brian Lee Yung Rowe wrote:
> > > Ross,
> > > 
> > > 
> > > This is generally a hard problem in software systems. The only
> > > language I know that explicitly addresses it is Erlang. Ultimately
> > > you
> > > need a system upgrade process, which defines how to update the
> > > data in
> > > your system to match a new version of the system. You could do
> > > this by
> > > writing a script that 
> > > 1) loads the old version of your library
> > > 2) loads your data/serialized reference classes
> > > 3) exports data to some intermediate format (eg a list)
> > > 4) loads new version of library
> > > 5) imports data from intermediate format
> > My recollection is that in Gemstone's smalltalk database you can
> > define
> > methods associated with a class that describe how to change an
> > instance
> > from one version to another.  You also have the choice of upgrading
> > all
> > persistent objects at once or doing so lazily, i.e., as they are
> > retrieved.
> > 
> > The brittleness of the representation depends partly on the
> > details.  If
> > a class has 2 slots, a and b, and the only thing on disk is the
> > contents
> > of a and the contents of b, almost any change will screw things up.
> > However, if the slot name is persisted with the instance it's much
> > easier to reconstruct the instance of the class changes (if slot c
> > is
> > added and not on disk, set it to nil; if b is removed, throw it out
> > when
> > reading from disk).  Once could also persist the class definition,
> > or
> > key elements of it, with individual instances referring to the
> > definition.
> > 
> > I don't know which, if any of these strategies, R uses for reference
> > or
> > other classes.
> > > 
> > > 
> > > Once you've gone through the upgrade process, arguably it's better
> > > to
> > > persist the data in a format that is decoupled from your objects
> > > since
> > > then future upgrades would simply be
> > > 1) load new library
> > > 2) import data from intermediate format
> > Arguably :)  As I said, some representations could do this
> > automatically.  And there are still issues such as a change in the
> > type
> > of a slot, or rules for filling new slots, that would require
> > intervention.
> > 
> > In my experience with other object systems, usually methods are
> > attributes of the class.  For R reference classes they appear to be
> > attributes of the instance, potentially modifiable on a per-instance
> > basis.
> > 
> > Ross
> > > 
> > > 
> > > which is no different from day-to-day operation of your app/system
> > > (ie
> > > you're always writing to and reading from the intermediate
> > > format). 
> > > 
> > > 
> > > Warm regards,
> > > Brian
> > > 
> > > ?????
> > > Brian Lee Yung Rowe
> > > Founder, Zato Novo
> > > Professor, M.S. Data Analytics, CUNY
> > > 
> > > On Aug 1, 2014, at 1:54 PM, Ross Boylan <ross at biostat.ucsf.edu>
> > > wrote:
> > > 
> > > 
> > > > I saved objects that were defined using several reference
> > > > classes.
> > > > Later I modified the definition of reference classes a bit,
> > > > creating
> > > > new
> > > > functions and deleting old ones.  The total number of functions
> > > > did
> > > > not
> > > > change.  When I read them back I could only access some of the
> > > > original
> > > > data.
> > > > 
> > > > I asked on the user list and someone suggested sticking with the
> > > > old
> > > > class definitions, creating new classes, reading in the old
> > > > data,
> > > > and
> > > > converting it to the new classes.  This would be awkward (I want
> > > > the
> > > > "new" classes to have the same name as the "old" ones), and I
> > > > can
> > > > probably just leave the old definitions and define the new
> > > > functions
> > > > I
> > > > need outside of the reference classes.
> > > > 
> > > > Are there any better alternatives?
> > > > 
> > > > On reflection, it's a little surprising that changing the code
> > > > for a
> > > > reference class makes any difference to an existing instance,
> > > > since
> > > > all
> > > > the function definitions seem to be attached to the instance.
> > > >  One
> > > > problem I've had in the past was precisely that redefining a
> > > > method
> > > > in a
> > > > reference class did not change the behavior of existing
> > > > instances.
> > > > So
> > > > I've tried to follow the advice to keep the methods
> > > > light-weight.
> > > > 
> > > > In this case I was trying to move from a show method (that just
> > > > printed)
> > > > to a summary method that returned a summary object.  So I wanted
> > > > to
> > > > add
> > > > a summary method and redefine the show to call summary in the
> > > > base
> > > > class, removing all the subclass definitions of show.
> > > > 
> > > > Regular S4 classes are obviously not as sensitive since they
> > > > usually
> > > > don't include the functions that operate on them, but I suppose
> > > > if
> > > > you
> > > > changed the slots you'd be in similar trouble.
> > > > 
> > > > Some systems keep track of versions of class definitions and
> > > > allow
> > > > one
> > > > to write code to migrate old to new forms automatically when the
> > > > data
> > > > are read in.  Does R have anything like that?
> > > > 
> > > > The system on which I encountered the problems was running R
> > > > 2.15.
> > > > 
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > 
> > 
> > 
> > 


From csardi.gabor at gmail.com  Fri Aug  1 23:00:46 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 1 Aug 2014 17:00:46 -0400
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <1406926072.9451.90.camel@localhost>
References: <1406915617.9451.47.camel@localhost>
	<852F505F-BB94-4825-A118-40D685240574@muxspace.com>
	<1406920680.9451.64.camel@localhost>
	<6AF0CD15-A22B-4072-9A29-C184FF4E5DA2@muxspace.com>
	<1406926072.9451.90.camel@localhost>
Message-ID: <CABtg=KmbOqBiUmW_mAjShCRYKnFcfkbE17Hwi3_=0TtAHLEH9A@mail.gmail.com>

On Fri, Aug 1, 2014 at 4:47 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
[...]
> First, I'd like to understand more about exactly what is saved to disk
> for reference and other classes, in particular how much meta-information
> they contain.  And my mental model for reference class persistence is
> clearly wrong, because in that model instances based on old definitions
> come back intact (albeit not with the new method definitions or other
> new slots), whereas mine seemed to come back damaged.
>
> Second, I'm still hoping for some elegant way around this problem (how
> to redefine classes and still use saved versions from older definitions)
> for the future, both with reference and regular classes.  Or at least
> some rules about what changes, if any, are safe to make in class
> definitions after an instance has been persisted.
>>
> Third, if changes to R could make things better, I'm hoping some
> developers might take them up.  I realize that is unlikely to happen,
> for many good reasons, but I can still hope :)

I believe that the brand new R6 class system can do this. I mean your
saved instances from old classes will be read back properly, with the
old methods. They are on CRAN and also here if you want to experiment:
https://github.com/wch/R6

Best,
Gabor


From winstonchang1 at gmail.com  Fri Aug  1 23:34:25 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Fri, 1 Aug 2014 16:34:25 -0500
Subject: [Rd] modifying a persistent (reference) class
In-Reply-To: <CABtg=KmbOqBiUmW_mAjShCRYKnFcfkbE17Hwi3_=0TtAHLEH9A@mail.gmail.com>
References: <1406915617.9451.47.camel@localhost>
	<852F505F-BB94-4825-A118-40D685240574@muxspace.com>
	<1406920680.9451.64.camel@localhost>
	<6AF0CD15-A22B-4072-9A29-C184FF4E5DA2@muxspace.com>
	<1406926072.9451.90.camel@localhost>
	<CABtg=KmbOqBiUmW_mAjShCRYKnFcfkbE17Hwi3_=0TtAHLEH9A@mail.gmail.com>
Message-ID: <CAFOpNVEJFHCDxdwLX7xGdUtnS6ZBM8V9HRcUgvkTLb0m2xo-Dg@mail.gmail.com>

R6 objects are basically just environments, so they're probably pretty
simple to save and restore (I haven't tested it out, though).

-Winston

On Fri, Aug 1, 2014 at 4:00 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Fri, Aug 1, 2014 at 4:47 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> [...]
>> First, I'd like to understand more about exactly what is saved to disk
>> for reference and other classes, in particular how much meta-information
>> they contain.  And my mental model for reference class persistence is
>> clearly wrong, because in that model instances based on old definitions
>> come back intact (albeit not with the new method definitions or other
>> new slots), whereas mine seemed to come back damaged.
>>
>> Second, I'm still hoping for some elegant way around this problem (how
>> to redefine classes and still use saved versions from older definitions)
>> for the future, both with reference and regular classes.  Or at least
>> some rules about what changes, if any, are safe to make in class
>> definitions after an instance has been persisted.
>>>
>> Third, if changes to R could make things better, I'm hoping some
>> developers might take them up.  I realize that is unlikely to happen,
>> for many good reasons, but I can still hope :)
>
> I believe that the brand new R6 class system can do this. I mean your
> saved instances from old classes will be read back properly, with the
> old methods. They are on CRAN and also here if you want to experiment:
> https://github.com/wch/R6
>
> Best,
> Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From xie at yihui.name  Sun Aug  3 21:30:11 2014
From: xie at yihui.name (Yihui Xie)
Date: Sun, 3 Aug 2014 15:30:11 -0400
Subject: [Rd] Parsing and deparsing of escaped unicode characters
In-Reply-To: <CABFfbXtZdJsr2igTxDEo2KP5St+fRDxsNRnpa_udkp+yFHDCMQ@mail.gmail.com>
References: <CABFfbXtZdJsr2igTxDEo2KP5St+fRDxsNRnpa_udkp+yFHDCMQ@mail.gmail.com>
Message-ID: <CANROs4cMLx_L2VhGgLShQgeiAz+nAyzH34H4jtkRcMefby-YzQ@mail.gmail.com>

The behavior depends on the specific locale. When these characters are
deparsed in a Chinese locale, they work fine, but in an English
locale, they will get escaped:

> x <- "I like \u5BFF\u53F8"
> x
[1] "I like ??"
> deparse(x)
[1] "\"I like ??\""
> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
[2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> Sys.setlocale(,'English')
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> x
[1] "I like ??"
> deparse(x)
[1] "\"I like <U+5BFF><U+53F8>\""

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Mon, Jul 28, 2014 at 4:47 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> In both R and JSON (and many other languages), unicode characters can
> be escaped using a backslash followed by a lowercase "u" and a 4 digit
> hex code. However when deparsing a character vector in R on Windows,
> the non-latin characters get escaped as "<U+" followed by their 4
> digit hex code and ">":
>
>> x <- "I like \u5BFF\u53F8"
>> cat(x)
> I like ??
>> src <- deparse(x)
>> cat(src)
> "I like <U+5BFF><U+53F8>"
>
> Same thing happens on linux when we disable UTF8:
>
> Sys.setlocale("LC_ALL", "C")
> x <- "I like \u5BFF\u53F8"
> nchar(x) #9, seems OK
> cat(deparse(x))
> "I like <U+5BFF><U+53F8>"
>
> As a result, the code does not parse() back into the proper unicode
> characters. I am currently using a regular expression to convert the
> output of deparse into something that parse() (and json) supports:
>
> utf8conv <- function(x) {
>   gsub("<U\\+([0-9A-F]{4})>","\\\\u\\1",x)
> }
>
>> src <- utf8conv(src)
>> y <- parse(text=src)[[1]]
>> identical(x, y)
> [1] TRUE
>
> However this is suboptimal because it introduces a big performance
> overhead for large text. Several things are unclear to me:
>
>  - Why does deparse() use a different escape notation than parse? Is
> there a way to make deparse output \uXXXX for unicode instead?
>  - Why does deparse on windows escape this in the first place, and not
> keep the actual character when the locale supports it?
>
>  > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From friendly at yorku.ca  Sun Aug  3 23:15:51 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 03 Aug 2014 17:15:51 -0400
Subject: [Rd] listof
In-Reply-To: <CF5661163F77A44781208D9AC4FDEA72621441DD5C@IS-WIN-376.staffad.uwa.edu.au>
References: <CF5661163F77A44781208D9AC4FDEA72621441DD5C@IS-WIN-376.staffad.uwa.edu.au>
Message-ID: <53DEA687.20308@yorku.ca>

An interesting topic, but I'll only respond with my own experience,
and that is, while 'listof' could be usefully extended there was not
enough meat on the bones to want to do so. I think this is a limitation
of the S3 class/method structure, as I see it.

In several packages (effects, heplots, candisc, vcdExtra) I/we
deal with lists of objects of a given class, and want to define
methods for plot(), summary(), print(), etc.  In these cases, the
simplest solution was to designate a new class, e.g., 'efflist'
for a list of effects in a univariate lm/glm/polr/ ... model
or 'candiscList' for a list of candisc objects.  Methods for the
*list class could then use an apply() construct over the list
items.

Most recently,
in the effects package, we implemented some effects plot methods
for multivariate linear models. This is essentially a two-way collection
of effects for terms x responses, but how to represent this in the
class structure to re-use the existing code for a single effect
of a given response variable?

The solution used here was to define a new class, 'mlm.efflist', with 
new methods for this class.  This works within the current S3 class
scheme, but doesn't provide an extendible semantics.

-Michael


On 7/29/2014 11:20 PM, Adrian Baddeley wrote:
> Dear R developers
>
> A question about the class 'listof',  defined in package 'stats'.
>
> Other than its definition and use in the code for 'anova',
> we can't see that the class 'listof' is used for anything else
> (in recommended packages, or elsewhere).
>
> In the spatstat package we have been using a 'listof'
> to represent a list of spatial objects of the same class
> (such as point patterns, or pixel images)
> and we've defined a plot method.
>
> Is it OK for us to hijack an existing class in this way,
> or is this a violation of some future plans/ design feature of R ?
>
> We're about to publish a book on spatstat
> so I would much appreciate advice if we need to change it.
>
> regards
> Adrian
>
> Prof Adrian Baddeley FAA
> University of Western Australia
>


From sven.templer at gmail.com  Mon Aug  4 16:22:49 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 4 Aug 2014 16:22:49 +0200
Subject: [Rd] abs, dots and an S4 method.
Message-ID: <CAHuTOvpFoez_5t4dTjdL+p+MSJg+4jRxTptPp_eBk=FN=NXKqw@mail.gmail.com>

Hello,

using the primitive abs(x) does not allow more than just the 'x'
argument in an S4 method, e.g. abs(x, arg2), since there is no '...'
as in trunc(x, ...).

To add a ... argument to abs(x), is it sufficient to change the arity
in src/main/names.c for abs as in trunc to a value of '-1'? So it
allows any number of arguments, not only 1? Or do I miss something
about it?

I found no clue checking the src/main/arithmetic.c do_abs and
do_trunc, or as proposed in R internals the do_switch in
src/main/builtin.c.

It would be very nice to have an abs S4 method, so to have the dots in there.

Thank you!
Sven.


From j.keirstead at imperial.ac.uk  Mon Aug  4 14:07:42 2014
From: j.keirstead at imperial.ac.uk (Keirstead, James E)
Date: Mon, 4 Aug 2014 12:07:42 +0000
Subject: [Rd] Preferred way to include internal data in package?
Message-ID: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>

Hi,

I?m developing a package and would like to include some data sets for internal use only, e.g. configuration parameters for functions.  What is the preferred way of doing this?  If I put them in data/, then R CMD check asks me to document them but I?d prefer it if they floated beneath the surface, without the users awareness.

Many thanks,
James

From jeroen.ooms at stat.ucla.edu  Mon Aug  4 17:30:22 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 4 Aug 2014 17:30:22 +0200
Subject: [Rd] Preferred way to include internal data in package?
In-Reply-To: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
Message-ID: <CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>

> I?m developing a package and would like to include some data sets for internal use only, e.g. configuration parameters for functions.  What is the preferred way of doing this?  If I put them in data/, then R CMD check asks me to document them but I?d prefer it if they floated beneath the surface, without the users awareness.

Perhaps in sysdata.rda. See "Writing R Extensions".


From j.keirstead at imperial.ac.uk  Mon Aug  4 18:11:00 2014
From: j.keirstead at imperial.ac.uk (Keirstead, James E)
Date: Mon, 4 Aug 2014 16:11:00 +0000
Subject: [Rd] Preferred way to include internal data in package?
In-Reply-To: <CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
	<CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>
Message-ID: <6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>

I saw that, but actually I was wondering if there was a more general method.  I?d like to use plain text files if I can, instead of Rda files, since they?re easier to maintain (and it?s a small file).

On 4 Aug 2014, at 16:30, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:

>> I?m developing a package and would like to include some data sets for internal use only, e.g. configuration parameters for functions.  What is the preferred way of doing this?  If I put them in data/, then R CMD check asks me to document them but I?d prefer it if they floated beneath the surface, without the users awareness.
> 
> Perhaps in sysdata.rda. See "Writing R Extensions".


From csardi.gabor at gmail.com  Mon Aug  4 18:23:16 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Mon, 4 Aug 2014 12:23:16 -0400
Subject: [Rd] Preferred way to include internal data in package?
In-Reply-To: <6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
	<CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>
	<6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>
Message-ID: <CABtg=K=42Sz0xWU56+LSWsC0zTa+fxK6brd2PLQ9qS6RJrwiYw@mail.gmail.com>

If you want to keep it as text, then you can just put it in the code:

mydata <-
'"","mpg","cyl","disp","hp","drat","wt","qsec","vs","am","gear","carb"
"Mazda RX4",21,6,160,110,3.9,2.62,16.46,0,1,4,4
"Mazda RX4 Wag",21,6,160,110,3.9,2.875,17.02,0,1,4,4
"Datsun 710",22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
'

and then you can read from it via text connections:

read.csv(textConnection(mydata))

Gabor

On Mon, Aug 4, 2014 at 12:11 PM, Keirstead, James E
<j.keirstead at imperial.ac.uk> wrote:
> I saw that, but actually I was wondering if there was a more general method.  I?d like to use plain text files if I can, instead of Rda files, since they?re easier to maintain (and it?s a small file).
>
> On 4 Aug 2014, at 16:30, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>
>>> I?m developing a package and would like to include some data sets for internal use only, e.g. configuration parameters for functions.  What is the preferred way of doing this?  If I put them in data/, then R CMD check asks me to document them but I?d prefer it if they floated beneath the surface, without the users awareness.
>>
>> Perhaps in sysdata.rda. See "Writing R Extensions".
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroen.ooms at stat.ucla.edu  Mon Aug  4 18:37:44 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 4 Aug 2014 18:37:44 +0200
Subject: [Rd] Preferred way to include internal data in package?
In-Reply-To: <6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
	<CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>
	<6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>
Message-ID: <CABFfbXvXk7ZHNWvdcryX-vL921QUJ85pQRVof0db6oFzW7c5ug@mail.gmail.com>

On Mon, Aug 4, 2014 at 6:11 PM, Keirstead, James E
<j.keirstead at imperial.ac.uk> wrote:
> I saw that, but actually I was wondering if there was a more general method.  I?d like to use plain text files if I can, instead of Rda files, since they?re easier to maintain (and it?s a small file).

Well then can just deparse() your data object and put it in your one
of your regular R text files, in the same was as you would do for a
function.


From cboettig at gmail.com  Mon Aug  4 18:38:37 2014
From: cboettig at gmail.com (Carl Boettiger)
Date: Mon, 4 Aug 2014 09:38:37 -0700
Subject: [Rd] Preferred way to include internal data in package?
In-Reply-To: <CABtg=K=42Sz0xWU56+LSWsC0zTa+fxK6brd2PLQ9qS6RJrwiYw@mail.gmail.com>
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
	<CABFfbXvZK-p-ob2Lzea0Zoeh3vogMkDkooyhKHbWc61wYbHdSA@mail.gmail.com>
	<6EAB4931-0C1C-4D51-AC4D-C5086785E47D@imperial.ac.uk>
	<CABtg=K=42Sz0xWU56+LSWsC0zTa+fxK6brd2PLQ9qS6RJrwiYw@mail.gmail.com>
Message-ID: <CAN_1p9x_KEd_eUtTwDJo+CAMP1keqNiiqK6w6mkmU9MSDXhWMg@mail.gmail.com>

I would think that putting them in an appropriate subdirectory in inst
might be preferable, e.g. inst/examples, and then reading the data in
with ?system.file where necessary?

(I have frequently been instructed that data ought not be mixed with
code, as it makes both code and data harder to read, maintain, or
reuse.  On the other hand, if there's a good reason to avoid
system.file for this, I'd be happy to be enlightened so that I too
could improve my practices).

Cheers,

Carl

On Mon, Aug 4, 2014 at 9:23 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> If you want to keep it as text, then you can just put it in the code:
>
> mydata <-
> '"","mpg","cyl","disp","hp","drat","wt","qsec","vs","am","gear","carb"
> "Mazda RX4",21,6,160,110,3.9,2.62,16.46,0,1,4,4
> "Mazda RX4 Wag",21,6,160,110,3.9,2.875,17.02,0,1,4,4
> "Datsun 710",22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
> '
>
> and then you can read from it via text connections:
>
> read.csv(textConnection(mydata))
>
> Gabor
>
> On Mon, Aug 4, 2014 at 12:11 PM, Keirstead, James E
> <j.keirstead at imperial.ac.uk> wrote:
>> I saw that, but actually I was wondering if there was a more general method.  I?d like to use plain text files if I can, instead of Rda files, since they?re easier to maintain (and it?s a small file).
>>
>> On 4 Aug 2014, at 16:30, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>>
>>>> I?m developing a package and would like to include some data sets for internal use only, e.g. configuration parameters for functions.  What is the preferred way of doing this?  If I put them in data/, then R CMD check asks me to document them but I?d prefer it if they floated beneath the surface, without the users awareness.
>>>
>>> Perhaps in sysdata.rda. See "Writing R Extensions".
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/


From ccberry at ucsd.edu  Mon Aug  4 22:04:45 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Mon, 4 Aug 2014 20:04:45 +0000
Subject: [Rd] Preferred way to include internal data in package?
References: <6445D029-9700-4ACA-ABF8-79335461F260@imperial.ac.uk>
Message-ID: <loom.20140804T215821-863@post.gmane.org>

Keirstead, James E <j.keirstead <at> imperial.ac.uk> writes:

> 
> Hi,
> 
> I?m developing a package and would like to include some data sets for 
> internal use only, e.g.
> configuration parameters for functions.  What is the preferred way of 
> doing this?  If I put them in data/,
> then R CMD check asks me to document them but I?d prefer it if they 
> floated beneath the surface, without
> the users awareness.


>From WRE Section 1.1.6 Data in packages:

[The data subdirectory] should not be used for other data files needed by 
the package, and the convention has grown up to use directory inst/extdata 
for such files.

---

So, put them in inst/extdata. 

HTH,

Chuck


From gcr at wisdomandwonder.com  Tue Aug  5 20:18:40 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Tue, 5 Aug 2014 13:18:40 -0500
Subject: [Rd] Minor documentation change for assign
Message-ID: <CAAjq1mf77uKJXj2y9N57snQGau8PmwY6kJV3+OhosR=KCejJsQ@mail.gmail.com>

Good afternoon,

Today I was reading the documentation

,----
| help('<<-');
`----
.

The passage (I added the asterisks)

      The operators '' are normally only used in functions, and
      cause a search *to* made through parent environments for an
      existing definition of the variable being assigned.  If such
      a

looks like it might have wanted to have been phrased as

      The operators '' are normally only used in functions, and
      cause a search *to be* made through parent environments for
      an existing definition of the variable being assigned.  If
      such a
.

Wanted to share that with the devs, and if that is a wanted change do
people usually submit patches
or what is the preferred mechanism?

,----
| sessionInfo()
`----

,----
| R version 3.1.1 (2014-07-10)
| Platform: x86_64-apple-darwin13.2.0 (64-bit)
|
| locale:
| [1] en_US/en_US/en_US/C/en_US/en_US
|
| attached base packages:
| [1] stats     graphics  grDevices utils     datasets  methods   base
|
| loaded via a namespace (and not attached):
| [1] compiler_3.1.1 tools_3.1.1
`----

Kind regards,

Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From gcr at wisdomandwonder.com  Tue Aug  5 20:49:07 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Tue, 5 Aug 2014 13:49:07 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
Message-ID: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>

Hi,

Today I got curious about whether or not I /could/ remove `attach' from
my system so:
- Backed it up
- Implemented a new one
- Like this

,----
| attach.old <<- attach
| attach <<- function(...) {stop("NEVER USE ATTACH")}
`----

I got the error:

,----
| Error: cannot change value of locked binding for 'attach'
`----

If I unlock `attach' I assume that I could stomp on it... however is
that even a good idea?

What will I break?

My goal was never to allow `attach' in my system, but it was just an
idea.

Kind regards,

Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From istazahn at gmail.com  Tue Aug  5 21:18:54 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 5 Aug 2014 15:18:54 -0400
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
Message-ID: <CA+vqiLFYhZY0Hx2=GNf=H-hO6M6aC+U701f1e3Ok9Rg08JVCTQ@mail.gmail.com>

On Tue, Aug 5, 2014 at 2:49 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
> Hi,
>
> Today I got curious about whether or not I /could/ remove `attach' from
> my system so:
> - Backed it up
> - Implemented a new one
> - Like this
>
> ,----
> | attach.old <<- attach
> | attach <<- function(...) {stop("NEVER USE ATTACH")}
> `----

Just masking it with your own function, e.g.,

attach <- function(...) {stop("NEVER USE ATTACH")}

should be enough to discourage you from using it.

>
> I got the error:
>
> ,----
> | Error: cannot change value of locked binding for 'attach'
> `----
>
> If I unlock `attach' I assume that I could stomp on it... however is
> that even a good idea?
>
> What will I break?

Anything that uses attach.

>
> My goal was never to allow `attach' in my system, but it was just an
> idea.
>
> Kind regards,
>
> Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
> ?Wisdom begins in wonder.? --Socrates
> ((? (x) (x x)) (? (x) (x x)))
> ?Life has become immeasurably better since I have been forced to stop
> taking it seriously.? --Thompson
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From winstonchang1 at gmail.com  Tue Aug  5 21:47:36 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 5 Aug 2014 14:47:36 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
Message-ID: <CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>

On Tue, Aug 5, 2014 at 1:49 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>
> Hi,
>
> Today I got curious about whether or not I /could/ remove `attach' from
> my system so:
> - Backed it up
> - Implemented a new one
> - Like this
>
> ,----
> | attach.old <<- attach
> | attach <<- function(...) {stop("NEVER USE ATTACH")}
> `----
>
> I got the error:
>
> ,----
> | Error: cannot change value of locked binding for 'attach'
> `----
>
> If I unlock `attach' I assume that I could stomp on it... however is
> that even a good idea?
>
> What will I break?


If you change the base package environment's copy of `attach` (via
`as.environment('package:base')`) , probably not much will break,
except for your own code. If, on the other hand, you change the base
namespace's copy of `attach` (via `asNamespace('base')`, any package
that's subsequently loaded and uses `attach` would run into problems.
Still, either way is probably not a good idea.

I agree with Ista: assigning it yourself in the the global environment
is a better idea. If you want to keep your global env clear of stuff
like this, you can put it in an environment and attach that
environment as a parent of global:

e <- new.env()
e$attach <-  function(...) {stop("NEVER USE ATTACH")}
base::attach(e, name = "my_stuff", warn.conflicts = FALSE)

# Test it out:
attach()

# You can see that the "my_stuff" env is the parent of global env
search()


-Winston


From gcr at wisdomandwonder.com  Tue Aug  5 23:37:03 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Tue, 5 Aug 2014 16:37:03 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
	<CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>
Message-ID: <CAAjq1mdQxg=E8VQxQhsOW+H2f0M4N-yj8dTxx-nZ-ADrbTt1MQ@mail.gmail.com>

That is delightful.

When I run it like this:
? Start R
? Nothing in .Rprofile
? Paste in your code
?????
? gcrenv <- new.env()
? gcrenv$attach.old <- attach
? gcrenv$attach <- function(...){stop("NEVER USE ATTACH")}
? base::attach(gcrenv, name="gcr", warn.conflicts = FALSE)
?????
? I get exactly what is expected, I think
?????
? search()
?????
?????
?  [1] ".GlobalEnv"        "gcr"               "ESSR"
?  [4] "package:stats"     "package:graphics"  "package:grDevices"
?  [7] "package:utils"     "package:datasets"  "package:methods"
? [10] "Autoloads"         "package:base"
?????

Just to be sure:
? Is that what is expected?
? I am surprised because I thought that `gcr' would come first before
  `.GlobalEnv'
  ? Perhaps I mis understand, as `.GlobalEnv' is actually the "REPL"?

My goal is to move that to my .Rprofile so that it is "always run" and I
can forget about it more or less.

Reading [this] I felt like `.First' would be the right place to put it,
but then read further to find that packages are only loaded /after/
`.First' has completed.  Curious, I tried it just to be sure. I am now
:).

This is the .Rprofile file:

?????
? cat(".Rprofile: Setting CMU repository\n")
? r = getOption("repos")
? r["CRAN"] = "http://lib.stat.cmu.edu/R/CRAN/"
? options(repos = r)
? rm(r)
?
? .First <- function() {
?    ?same code as above?
? }
?????

(I included the repository load, and understand it should not impact
things here)

This is run after normal startup of R:

?????
? search()
?????
?????
?  [1] ".GlobalEnv"        "package:stats"     "package:graphics"
?  [4] "package:grDevices" "package:utils"     "package:datasets"
?  [7] "gcr"               "package:methods"   "Autoloads"
? [10] "package:base"
?????

When I read this, I read it as:
? My rebind of `attach' occurs
? Then all of the packages are loaded and they are referring to
  my-rebound `attach'
? That is a problem because it *will* break package code
? Clearly me putting that code in `.Rprofile' is the wrong place.

What I am looking for now is the "right way" to achieve what is
demonstarted but automatically via a startup file.

My ideas:
? Manually paste the step each time
? Always use Emacs and ESS to run R and add a hook so that the code will
  be run after ESS loads
? Something I am missing


[this]
http://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Tue, Aug 5, 2014 at 2:47 PM, Winston Chang <winstonchang1 at gmail.com> wrote:
> On Tue, Aug 5, 2014 at 1:49 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>>
>> Hi,
>>
>> Today I got curious about whether or not I /could/ remove `attach' from
>> my system so:
>> - Backed it up
>> - Implemented a new one
>> - Like this
>>
>> ,----
>> | attach.old <<- attach
>> | attach <<- function(...) {stop("NEVER USE ATTACH")}
>> `----
>>
>> I got the error:
>>
>> ,----
>> | Error: cannot change value of locked binding for 'attach'
>> `----
>>
>> If I unlock `attach' I assume that I could stomp on it... however is
>> that even a good idea?
>>
>> What will I break?
>
>
> If you change the base package environment's copy of `attach` (via
> `as.environment('package:base')`) , probably not much will break,
> except for your own code. If, on the other hand, you change the base
> namespace's copy of `attach` (via `asNamespace('base')`, any package
> that's subsequently loaded and uses `attach` would run into problems.
> Still, either way is probably not a good idea.
>
> I agree with Ista: assigning it yourself in the the global environment
> is a better idea. If you want to keep your global env clear of stuff
> like this, you can put it in an environment and attach that
> environment as a parent of global:
>
> e <- new.env()
> e$attach <-  function(...) {stop("NEVER USE ATTACH")}
> base::attach(e, name = "my_stuff", warn.conflicts = FALSE)
>
> # Test it out:
> attach()
>
> # You can see that the "my_stuff" env is the parent of global env
> search()
>
>
> -Winston


From jdavison at fhcrc.org  Wed Aug  6 00:47:34 2014
From: jdavison at fhcrc.org (Davison, Jerry)
Date: Tue, 5 Aug 2014 15:47:34 -0700 (PDT)
Subject: [Rd] More than one package document with the same name
In-Reply-To: <1166876707.1617144.1407278729662.JavaMail.root@fhcrc.org>
Message-ID: <790648282.1617209.1407278854275.JavaMail.root@fhcrc.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140805/7b1208f4/attachment.pl>

From john.archie.mckown at gmail.com  Wed Aug  6 02:10:28 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 5 Aug 2014 19:10:28 -0500
Subject: [Rd] More than one package document with the same name
In-Reply-To: <790648282.1617209.1407278854275.JavaMail.root@fhcrc.org>
References: <1166876707.1617144.1407278729662.JavaMail.root@fhcrc.org>
	<790648282.1617209.1407278854275.JavaMail.root@fhcrc.org>
Message-ID: <CAAJSdjg2evn7VW52bB_os9D9C5p4DAwy36Nrf6=Hqt5RwBa6MQ@mail.gmail.com>

On Tue, Aug 5, 2014 at 5:47 PM, Davison, Jerry <jdavison at fhcrc.org> wrote:
> Hi,
>
> I sent this to the Bioconductor mailing list (q.v.), replies recommended this forum. Here it is:
> A suggestion. Typically a package provides documentation of two types, one or more vignettes and a reference manual; and they have the same file name, PackageName.pdf.  When downloaded some file name manipulation is required, or accept PackageName(1).pdf.
>
> I suggest the documents be given different names, for example the reference manual could be named PackageNameRefMan.pdf. Package checking could enforce the rule.
> Jerry
>

Sounds like you want to put all the pdf files in a single directory. I
like that too. I cheat. I run Linux. I have a ~/Documents/R-pdfs in
which I keep "symlinks" to all the pdf files. And I do it similar to
the way that you indicate. I make the name of the pdf be
${enclosing_directory}_${original_pdf_name.pdf}. I do something like:

cd ~/Documents/R-pdf
find /usr/lib64/R -name '*.pdf'|\
while read i;do
  file=${i##*/};
  dir=${i%%/doc/*.pdf};
  package=${dir##*/};
  ln -s "$i" "${package}_${file}";
done

Above won't work if anything has a blank in it. Windows people tend to
do this. Most UNIX people are better trained.

It would be nice if the packagers did this. But the above works for
me. On Linux and other UNIX like systems. Won't work for the poor,
benighted Windows people. But I think something similar is possible.
But I don't know Windows well enough.

Maranatha! <><
John McKown


From winstonchang1 at gmail.com  Wed Aug  6 02:54:38 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 5 Aug 2014 19:54:38 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAAjq1mdQxg=E8VQxQhsOW+H2f0M4N-yj8dTxx-nZ-ADrbTt1MQ@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
	<CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>
	<CAAjq1mdQxg=E8VQxQhsOW+H2f0M4N-yj8dTxx-nZ-ADrbTt1MQ@mail.gmail.com>
Message-ID: <CAFOpNVGhSqjJSk4mpa5=W_069npCj7RBx0ZCLqObysxW5=1jgA@mail.gmail.com>

On Tue, Aug 5, 2014 at 4:37 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>
> That is delightful.
>
> When I run it like this:
> ? Start R
> ? Nothing in .Rprofile
> ? Paste in your code
> ?????
> ? gcrenv <- new.env()
> ? gcrenv$attach.old <- attach
> ? gcrenv$attach <- function(...){stop("NEVER USE ATTACH")}
> ? base::attach(gcrenv, name="gcr", warn.conflicts = FALSE)
> ?????
> ? I get exactly what is expected, I think
> ?????
> ? search()
> ?????
> ?????
> ?  [1] ".GlobalEnv"        "gcr"               "ESSR"
> ?  [4] "package:stats"     "package:graphics"  "package:grDevices"
> ?  [7] "package:utils"     "package:datasets"  "package:methods"
> ? [10] "Autoloads"         "package:base"
> ?????
>
> Just to be sure:
> ? Is that what is expected?
> ? I am surprised because I thought that `gcr' would come first before
>   `.GlobalEnv'
>   ? Perhaps I mis understand, as `.GlobalEnv' is actually the "REPL"?
>
> My goal is to move that to my .Rprofile so that it is "always run" and I
> can forget about it more or less.
>
> Reading [this] I felt like `.First' would be the right place to put it,
> but then read further to find that packages are only loaded /after/
> `.First' has completed.  Curious, I tried it just to be sure. I am now
> :).
>
> This is the .Rprofile file:
>
> ?????
> ? cat(".Rprofile: Setting CMU repository\n")
> ? r = getOption("repos")
> ? r["CRAN"] = "http://lib.stat.cmu.edu/R/CRAN/"
> ? options(repos = r)
> ? rm(r)
> ?
> ? .First <- function() {
> ?    ?same code as above?
> ? }
> ?????
>
> (I included the repository load, and understand it should not impact
> things here)
>
> This is run after normal startup of R:
>
> ?????
> ? search()
> ?????
> ?????
> ?  [1] ".GlobalEnv"        "package:stats"     "package:graphics"
> ?  [4] "package:grDevices" "package:utils"     "package:datasets"
> ?  [7] "gcr"               "package:methods"   "Autoloads"
> ? [10] "package:base"
> ?????
>
> When I read this, I read it as:
> ? My rebind of `attach' occurs
> ? Then all of the packages are loaded and they are referring to
>   my-rebound `attach'
> ? That is a problem because it *will* break package code
> ? Clearly me putting that code in `.Rprofile' is the wrong place.
>

That order for search path should actually be fine. To understand why,
you first have to know the difference between the _binding_
environment for an object, and the _enclosing_ environment for a
function.

The binding environment is where you can find an object. For example,
in the global env, you have a bunch bindings (we often call them
variables), that point to various objects - vectors, data frames,
other environments, etc.

The enclosing environment for a function is where the function "runs
in" when it's called.

Most R objects have just a binding environment (a variable or
reference that points to the object); functions also have an enclosing
environment. These two environments aren't necessarily the same.

When you run search(), it shows the set of environments where R will
look for an object of a given name, when you run stuff at the console
(and are in the global env). The trick is that, although you can find
a function (they are bound bound) in one of these _package_
environments, those functions run in (are enclosed by) a different
environment: the a corresponding _namespace_ environment.

The way that a namespace environment is set up with the arrangement of
its ancestor environments, it will find the base namespace version of
`attach` before it finds yours, even if your personal gcr environment
comes early in the search path.

=========================
# Here's an example to illustrate. The `utils::alarm` function calls
`cat`, which is in base.

alarm
# function ()
# {
#     cat("\a")
#     flush.console()
# }
# <environment: namespace:utils>


# Running it makes the screen flash or beep
alarm()
# [screen flashes]


# We'll put a replacement version of cat early in the search path,
between utils and base
my_stuff <- new.env()
my_stuff$cat <- function(...) stop("Tried to call cat")
base::attach(my_stuff, pos=length(search()) - 1, name="my_stuff")

search()
#  [1] ".GlobalEnv"        "tools:rstudio"     "package:stats"
"package:graphics"
#  [5] "package:grDevices" "package:utils"     "package:datasets"
"package:methods"
#  [9] "my_stuff"          "Autoloads"         "package:base"

# Calling cat from the console gives the error, as expected
cat()
# Error in cat() : Tried to call cat

# But when we run alarm(), it still gets the real version of `cat()`,
# because it finds the the original base namespace version of cat
# before it finds yours.
alarm()
# [screen flashes]

==========================

You can even alter package environments without affecting the
corresponding namespace environment. The exception to the package and
namespace environments being distinct is the base environment; change
one and you change the other. (I just realized this and have to
retract my earlier statement about the behavior being different if
change attach in the base package env vs. the base namespace env.)

-Winston


From evandev at gastrograph.com  Wed Aug  6 15:47:55 2014
From: evandev at gastrograph.com (Evan Farrell)
Date: Wed, 6 Aug 2014 09:47:55 -0400
Subject: [Rd] Can't use custom package on windows 64-bit
Message-ID: <CABwr+hiiOQfqo8DnLAnhVSZqepjzYn1XVuz0QLV_QVb04H0iBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140806/78157dc7/attachment.pl>

From edd at debian.org  Wed Aug  6 16:49:33 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 6 Aug 2014 09:49:33 -0500
Subject: [Rd] Can't use custom package on windows 64-bit
In-Reply-To: <CABwr+hiiOQfqo8DnLAnhVSZqepjzYn1XVuz0QLV_QVb04H0iBw@mail.gmail.com>
References: <CABwr+hiiOQfqo8DnLAnhVSZqepjzYn1XVuz0QLV_QVb04H0iBw@mail.gmail.com>
Message-ID: <21474.16509.155682.221834@max.nulle.part>


On 6 August 2014 at 09:47, Evan Farrell wrote:
| I've been developing a package to use S3 bucket on AWS by using libs3 code.
|  I have two problems.  The first is, by standard, it will attempt to
| install i386 and x64 if I don't have a configure.win.
| 
| The problem with this is that while everything appears to compile
| correctly, I get this error when trying to load the x64 library:
| 
| "LoadLibrary error:  %1 is not a valid Win32 application"
| 
| I am able to load the 32-bit library, but when I try to load that in
| Rstudio, it says: "package is not installed for 'arch=x64'".  Now I know
| that I can simply switch Rstudio to point to 32-bit R, but that is not
| ideal.
| 
| 
| Is there a way to easily fix that?  So that I can either compile correctly
| the 64-bit, or I can run the 32-bit in 64-bit R.
| 
| Here's my source code:  https://github.com/Gastrograph/RS3

Thanks for that pointer.  Could you consider "just" using Linux for now?

Doing Windows is entirely doable, but more involved.  As I recall, you need
tricks such as not using a configure.win in order to build with both default
arches on Windows.

There are packages that do this, and you can "borrow" solutions from them.
But none springs to my mind rightaway as I tend to deploy on Linux first, or else
work with the very kind CRAN folks and have them provide 32 and 64 bit
libraries on the builders themselves (as eg recently with hiredis) :)
Medium-term you could do this too as libS3 is open source.

Until then you can of course emulate that scheme perfectly well by building
the 32 and 64 bit DLLs, store them in your repo and have Makevars.win point
to them via the same env var trick used at CRAN.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kyzyl at his.com  Wed Aug  6 17:07:42 2014
From: kyzyl at his.com (Terrence Ireland)
Date: Wed, 06 Aug 2014 11:07:42 -0400
Subject: [Rd] Subscripting Matrices
Message-ID: <53E244BE.8040208@his.com>

There seems to be a result type difference when subscripting a 6 x 1 
matrix as compared to a 3 x 2 matrix that is caused by the ncol = 1 
compared to ncol > 1.

 > ThinMatrix <- matrix(1:6,ncol=1)
 > ThinMatrix
      [,1]
[1,]    1
[2,]    2
[3,]    3
[4,]    4
[5,]    5
[6,]    6
 > FatMatrix <- matrix(1:6,ncol=2)
 > FatMatrix
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > dim(ThinMatrix[TRUE,])
NULL                                      #Though this value should be 6 1
 > dim(FatMatrix[TRUE,])
[1] 3 2

Thanks for your help.

Terry Ireland


From csardi.gabor at gmail.com  Wed Aug  6 17:13:38 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 6 Aug 2014 11:13:38 -0400
Subject: [Rd] Subscripting Matrices
In-Reply-To: <53E244BE.8040208@his.com>
References: <53E244BE.8040208@his.com>
Message-ID: <CABtg=KmPC=CAWpztakWhiYCPSwWibGG43BfPQU-D9F0V-7ytTg@mail.gmail.com>

You want `drop=FALSE`:

> dim(ThinMatrix[TRUE, , drop=FALSE])
[1] 6 1

>From ?"[":

    drop: For matrices and arrays.  If ?TRUE? the result is coerced to
          the lowest possible dimension (see the examples).  This only
          works for extracting elements, not for the replacement.  See
          ?drop? for further details.

And R inferno 8.1.44:
http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

Gabor

On Wed, Aug 6, 2014 at 11:07 AM, Terrence Ireland <kyzyl at his.com> wrote:
> There seems to be a result type difference when subscripting a 6 x 1 matrix
> as compared to a 3 x 2 matrix that is caused by the ncol = 1 compared to
> ncol > 1.
>
>> ThinMatrix <- matrix(1:6,ncol=1)
>> ThinMatrix
>      [,1]
> [1,]    1
> [2,]    2
> [3,]    3
> [4,]    4
> [5,]    5
> [6,]    6
>> FatMatrix <- matrix(1:6,ncol=2)
>> FatMatrix
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
>> dim(ThinMatrix[TRUE,])
> NULL                                      #Though this value should be 6 1
>> dim(FatMatrix[TRUE,])
> [1] 3 2
>
> Thanks for your help.
>
> Terry Ireland
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at me.com  Wed Aug  6 17:17:28 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 06 Aug 2014 10:17:28 -0500
Subject: [Rd] Subscripting Matrices
In-Reply-To: <53E244BE.8040208@his.com>
References: <53E244BE.8040208@his.com>
Message-ID: <4513EF07-08D4-48B7-A067-28C0E02FB35C@me.com>

On Aug 6, 2014, at 10:07 AM, Terrence Ireland <kyzyl at his.com> wrote:

> There seems to be a result type difference when subscripting a 6 x 1 matrix as compared to a 3 x 2 matrix that is caused by the ncol = 1 compared to ncol > 1.
> 
> > ThinMatrix <- matrix(1:6,ncol=1)
> > ThinMatrix
>     [,1]
> [1,]    1
> [2,]    2
> [3,]    3
> [4,]    4
> [5,]    5
> [6,]    6
> > FatMatrix <- matrix(1:6,ncol=2)
> > FatMatrix
>     [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> > dim(ThinMatrix[TRUE,])
> NULL                                      #Though this value should be 6 1
> > dim(FatMatrix[TRUE,])
> [1] 3 2
> 
> Thanks for your help.
> 
> Terry Ireland


Hi,

This question really should have gone to R-Help, not R-Devel and it is a FAQ:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-my-matrices-lose-dimensions_003f

> str(ThinMatrix[TRUE,])
 int [1:6] 1 2 3 4 5 6


Regards,

Marc Schwartz


From ripley at stats.ox.ac.uk  Wed Aug  6 17:31:33 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 06 Aug 2014 16:31:33 +0100
Subject: [Rd] Can't use custom package on windows 64-bit
In-Reply-To: <CABwr+hiiOQfqo8DnLAnhVSZqepjzYn1XVuz0QLV_QVb04H0iBw@mail.gmail.com>
References: <CABwr+hiiOQfqo8DnLAnhVSZqepjzYn1XVuz0QLV_QVb04H0iBw@mail.gmail.com>
Message-ID: <53E24A55.1010906@stats.ox.ac.uk>

On 06/08/2014 14:47, Evan Farrell wrote:
> I've been developing a package to use S3 bucket on AWS by using libs3 code.
>   I have two problems.  The first is, by standard, it will attempt to
> install i386 and x64 if I don't have a configure.win.

Or if you use --force-biarch or --merge-multiarch: see ?INSTALL and 
'Writing R Extensions'.

> The problem with this is that while everything appears to compile
> correctly, I get this error when trying to load the x64 library:
>
> "LoadLibrary error:  %1 is not a valid Win32 application"
>
> I am able to load the 32-bit library, but when I try to load that in
> Rstudio, it says: "package is not installed for 'arch=x64'".  Now I know
> that I can simply switch Rstudio to point to 32-bit R, but that is not
> ideal.

That' s confusing error message from Windows.  It most likely means that 
some DLL which your package's DLL is trying to link to cannot be found, 
or can be found but is 32-bit.  (In theory at least a 64-bit DLL of the 
required name will be found first, if there is one.)

> Is there a way to easily fix that?  So that I can either compile correctly
> the 64-bit, or I can run the 32-bit in 64-bit R.

You cannot load 32-bit DLLs into a 64-bit process. (Here that means the 
process linking to the R DLL: RStudio is just an arm's-length front end 
that communicates with a client in a separate process.)

>
> Here's my source code:  https://github.com/Gastrograph/RS3

You copy DLLs into the package from elsewhere, and likely they are the 
problem.  If you call dyn.load() on each of those you may get a more 
informative error message.  Using 'Dependency Walker' (see Writing R 
Extensions) can sometimes be revealing as to which DLL is missing/corrupt.

>
> Thank you!
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pauljohn32 at gmail.com  Wed Aug  6 20:10:32 2014
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 6 Aug 2014 13:10:32 -0500
Subject: [Rd] portableParalleSeeds Package violation, CRAN exception?
Message-ID: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>

I'm writing to ask for a policy exception, or advice on how to make
this package CRAN allowable.

http://rweb.quant.ku.edu/kran/src/contrib/portableParallelSeeds_0.9.tar.gz

Yesterday I tried to submit a package on CRAN and Dr Ripley pointed
out that I had not understood the instructions about packages.  Here's
the part where the R check gives a Note

* checking R code for possible problems ... NOTE
Found the following assignments to the global environment:
File ?portableParallelSeeds/R/initPortableStreams.R?:
   assign("currentStream", n, envir = .GlobalEnv)
   assign("currentStates", curStates, envir = .GlobalEnv)
   assign("currentStream", 1L, envir = .GlobalEnv)
   assign("startStates", runSeeds, envir = .GlobalEnv)
   assign("currentStates", runSeeds, envir = .GlobalEnv)
   assign("currentStream", as.integer(currentStream), envir = .GlobalEnv)
   assign("startStates", runSeeds, envir = .GlobalEnv)
   assign("currentStates", runSeeds, envir = .GlobalEnv)

Altering the user's environment requires a special arrangement with
CRAN. I believe this is justified, I'll sketch the reasons now. But,
mostly, I'm at your mercy and if there is any way to make this
possible, I would be very grateful.

To control & replace random number streams, it really is necessary to
alter the workspace. That's where the random generator state is
stored.  It is acknowledged in Robert Gentleman' s Book, R Programming
for Bionformatics "The decision to have these [random generator]
functions manipulate a global variable, .Random.seed, is slightly
unfortunate as it makes it somewhat more difficult to manage several
different random number streams simultaneously? (Gentleman, 2009, p.
201).

I have developed an understandable set of wrapper functions that handle this.

Some of you may recall this project. I've asked about it here a couple
of times. We allow separate streams of randoms for different purposes
within a single R run. There is a framework to save 1000s of those
sets in a file, so it can be used on a cluster or in a single
workstation.  This is handy because, when 1 run in 10,000 on the
cluster exhibits some weird behavior, we can easily re-initiate that
interactively and see what's going on.

I have a  vignette "pps" that explains. I dropped a copy of that here
in case you don't want to get the package:

http://pj.freefaculty.org/scraps/pps.pdf

While working on that, I gained a considerably deeper understanding of
random generators and seeds.  That is what this vignette is about

http://pj.freefaculty.org/scraps/PRNG-basics.pdf


We've been running simulations on our cluster with the
portableParallelSeeds framework for 2 years, we've never had any
trouble.  We are able to re-start runs, verify random number draws in
separate streams.

PJ
-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From dtenenba at fhcrc.org  Wed Aug  6 20:25:29 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 6 Aug 2014 11:25:29 -0700 (PDT)
Subject: [Rd] More than one package document with the same name
In-Reply-To: <CAAJSdjg2evn7VW52bB_os9D9C5p4DAwy36Nrf6=Hqt5RwBa6MQ@mail.gmail.com>
Message-ID: <2073925534.1642398.1407349529636.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "John McKown" <john.archie.mckown at gmail.com>
> To: "Jerry Davison" <jdavison at fhcrc.org>
> Cc: r-devel at r-project.org
> Sent: Tuesday, August 5, 2014 5:10:28 PM
> Subject: Re: [Rd] More than one package document with the same name
> 
> On Tue, Aug 5, 2014 at 5:47 PM, Davison, Jerry <jdavison at fhcrc.org>
> wrote:
> > Hi,
> >
> > I sent this to the Bioconductor mailing list (q.v.), replies
> > recommended this forum. Here it is:
> > A suggestion. Typically a package provides documentation of two
> > types, one or more vignettes and a reference manual; and they have
> > the same file name, PackageName.pdf.  When downloaded some file
> > name manipulation is required, or accept PackageName(1).pdf.
> >
> > I suggest the documents be given different names, for example the
> > reference manual could be named PackageNameRefMan.pdf. Package
> > checking could enforce the rule.
> > Jerry
> >
> 
> Sounds like you want to put all the pdf files in a single directory.


Actually I think the issue (and Jerry can correct me if I'm wrong) is that sometimes users want to download the documentation for a package from the package landing page on Bioconductor or CRAN (without installing the package). If both files are called pkg.pdf, then your web browser wants to rename the second one to (e.g.) pkg(1).pdf (different browsers handle this differently). 
Also, the two names on their own don't give you a clue as to which file is which.

My own suggestion would be that the manual be renamed to pkg-manual.pdf. That places no restrictions on vignette file names and makes it clear which file is the manual.

Dan


> I
> like that too. I cheat. I run Linux. I have a ~/Documents/R-pdfs in
> which I keep "symlinks" to all the pdf files. And I do it similar to
> the way that you indicate. I make the name of the pdf be
> ${enclosing_directory}_${original_pdf_name.pdf}. I do something like:
> 
> cd ~/Documents/R-pdf
> find /usr/lib64/R -name '*.pdf'|\
> while read i;do
>   file=${i##*/};
>   dir=${i%%/doc/*.pdf};
>   package=${dir##*/};
>   ln -s "$i" "${package}_${file}";
> done
> 
> Above won't work if anything has a blank in it. Windows people tend
> to
> do this. Most UNIX people are better trained.
> 
> It would be nice if the packagers did this. But the above works for
> me. On Linux and other UNIX like systems. Won't work for the poor,
> benighted Windows people. But I think something similar is possible.
> But I don't know Windows well enough.
> 
> Maranatha! <><
> John McKown
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Wed Aug  6 20:20:43 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 6 Aug 2014 14:20:43 -0400
Subject: [Rd] portableParalleSeeds Package violation, CRAN exception?
In-Reply-To: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
References: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
Message-ID: <CABtg=K=4O5NE31RZr_jzKXXua+76YCVaaMEOKr_xv5tbyp65mw@mail.gmail.com>

Why not place them in the package environment? Gabor

On Wed, Aug 6, 2014 at 2:10 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> I'm writing to ask for a policy exception, or advice on how to make
> this package CRAN allowable.
>
> http://rweb.quant.ku.edu/kran/src/contrib/portableParallelSeeds_0.9.tar.gz
>
> Yesterday I tried to submit a package on CRAN and Dr Ripley pointed
> out that I had not understood the instructions about packages.  Here's
> the part where the R check gives a Note
>
> * checking R code for possible problems ... NOTE
> Found the following assignments to the global environment:
> File ?portableParallelSeeds/R/initPortableStreams.R?:
>    assign("currentStream", n, envir = .GlobalEnv)
>    assign("currentStates", curStates, envir = .GlobalEnv)
>    assign("currentStream", 1L, envir = .GlobalEnv)
>    assign("startStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStream", as.integer(currentStream), envir = .GlobalEnv)
>    assign("startStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStates", runSeeds, envir = .GlobalEnv)
>
> Altering the user's environment requires a special arrangement with
> CRAN. I believe this is justified, I'll sketch the reasons now. But,
> mostly, I'm at your mercy and if there is any way to make this
> possible, I would be very grateful.
>
> To control & replace random number streams, it really is necessary to
> alter the workspace. That's where the random generator state is
> stored.  It is acknowledged in Robert Gentleman' s Book, R Programming
> for Bionformatics "The decision to have these [random generator]
> functions manipulate a global variable, .Random.seed, is slightly
> unfortunate as it makes it somewhat more difficult to manage several
> different random number streams simultaneously? (Gentleman, 2009, p.
> 201).
>
> I have developed an understandable set of wrapper functions that handle this.
>
> Some of you may recall this project. I've asked about it here a couple
> of times. We allow separate streams of randoms for different purposes
> within a single R run. There is a framework to save 1000s of those
> sets in a file, so it can be used on a cluster or in a single
> workstation.  This is handy because, when 1 run in 10,000 on the
> cluster exhibits some weird behavior, we can easily re-initiate that
> interactively and see what's going on.
>
> I have a  vignette "pps" that explains. I dropped a copy of that here
> in case you don't want to get the package:
>
> http://pj.freefaculty.org/scraps/pps.pdf
>
> While working on that, I gained a considerably deeper understanding of
> random generators and seeds.  That is what this vignette is about
>
> http://pj.freefaculty.org/scraps/PRNG-basics.pdf
>
>
> We've been running simulations on our cluster with the
> portableParallelSeeds framework for 2 years, we've never had any
> trouble.  We are able to re-start runs, verify random number draws in
> separate streams.
>
> PJ
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Wed Aug  6 21:48:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 Aug 2014 12:48:23 -0700
Subject: [Rd] portableParalleSeeds Package violation, CRAN exception?
In-Reply-To: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
References: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
Message-ID: <CAF8bMcbHBHHo-e0XyppvF3m+bBgBjSyAev18=BqTmWu5R-+4HA@mail.gmail.com>

You can make an environment called streamsEnv in your package by adding
   streamsEnv <- new.env()
to one of your R/*.R files. (its parent environment will be
namespace:yourPackage) and your functions can assign things to this
environment instead of to .GlobalEnv.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 6, 2014 at 11:10 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> I'm writing to ask for a policy exception, or advice on how to make
> this package CRAN allowable.
>
> http://rweb.quant.ku.edu/kran/src/contrib/portableParallelSeeds_0.9.tar.gz
>
> Yesterday I tried to submit a package on CRAN and Dr Ripley pointed
> out that I had not understood the instructions about packages.  Here's
> the part where the R check gives a Note
>
> * checking R code for possible problems ... NOTE
> Found the following assignments to the global environment:
> File ?portableParallelSeeds/R/initPortableStreams.R?:
>    assign("currentStream", n, envir = .GlobalEnv)
>    assign("currentStates", curStates, envir = .GlobalEnv)
>    assign("currentStream", 1L, envir = .GlobalEnv)
>    assign("startStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStream", as.integer(currentStream), envir = .GlobalEnv)
>    assign("startStates", runSeeds, envir = .GlobalEnv)
>    assign("currentStates", runSeeds, envir = .GlobalEnv)
>
> Altering the user's environment requires a special arrangement with
> CRAN. I believe this is justified, I'll sketch the reasons now. But,
> mostly, I'm at your mercy and if there is any way to make this
> possible, I would be very grateful.
>
> To control & replace random number streams, it really is necessary to
> alter the workspace. That's where the random generator state is
> stored.  It is acknowledged in Robert Gentleman' s Book, R Programming
> for Bionformatics "The decision to have these [random generator]
> functions manipulate a global variable, .Random.seed, is slightly
> unfortunate as it makes it somewhat more difficult to manage several
> different random number streams simultaneously? (Gentleman, 2009, p.
> 201).
>
> I have developed an understandable set of wrapper functions that handle this.
>
> Some of you may recall this project. I've asked about it here a couple
> of times. We allow separate streams of randoms for different purposes
> within a single R run. There is a framework to save 1000s of those
> sets in a file, so it can be used on a cluster or in a single
> workstation.  This is handy because, when 1 run in 10,000 on the
> cluster exhibits some weird behavior, we can easily re-initiate that
> interactively and see what's going on.
>
> I have a  vignette "pps" that explains. I dropped a copy of that here
> in case you don't want to get the package:
>
> http://pj.freefaculty.org/scraps/pps.pdf
>
> While working on that, I gained a considerably deeper understanding of
> random generators and seeds.  That is what this vignette is about
>
> http://pj.freefaculty.org/scraps/PRNG-basics.pdf
>
>
> We've been running simulations on our cluster with the
> portableParallelSeeds framework for 2 years, we've never had any
> trouble.  We are able to re-start runs, verify random number draws in
> separate streams.
>
> PJ
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomk at 0xdata.com  Wed Aug  6 07:01:55 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Tue, 5 Aug 2014 22:01:55 -0700
Subject: [Rd] R process (and forked children via system2) are limited to 1
	core?
Message-ID: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>


Hi,


(Using R 3.1.1 on Ubuntu 12.04.4 LTS)


What is the recommended way for R to fork a (non-R) process that is not CPU limited?
Currently I am using R's system2() call, and this is inheriting the environment of the R process.


I notice that (at least on Linux) when I am poking around /proc that the R process itself is setting up cpu limitations for itself (max 1 core).


Using strace, I see the following:

(strace output)
out.20612:sched_setaffinity(0, 128, {100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}) = 0


And proc shows:

(cat /proc/nnn/status)
Cpus_allowed:   00000001
Cpus_allowed_list:      0


See that the Cpus_allowed bitmask is a single core.  Normally it's fff...f.


I want my child process (java in this case) not to share this limitation.  What is the recommended way of doing this from R?
Any ideas or suggestions appreciated!


Thanks,
Tom


From njs at pobox.com  Wed Aug  6 23:20:34 2014
From: njs at pobox.com (Nathaniel Smith)
Date: Wed, 6 Aug 2014 22:20:34 +0100
Subject: [Rd] R process (and forked children via system2) are limited to
	1 core?
In-Reply-To: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>
References: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>
Message-ID: <CAPJVwBn6E4DwP7yji8mLXZ5JiSeJVPLCBpAyAPTaTFO_fporKQ@mail.gmail.com>

On Wed, Aug 6, 2014 at 6:01 AM, Tom Kraljevic <tomk at 0xdata.com> wrote:
>
> Hi,
>
>
> (Using R 3.1.1 on Ubuntu 12.04.4 LTS)
>
>
> What is the recommended way for R to fork a (non-R) process that is not CPU limited?
> Currently I am using R's system2() call, and this is inheriting the environment of the R process.
>
>
> I notice that (at least on Linux) when I am poking around /proc that the R process itself is setting up cpu limitations for itself (max 1 core).
>
>
> Using strace, I see the following:
>
> (strace output)
> out.20612:sched_setaffinity(0, 128, {100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}) = 0
>
>
> And proc shows:
>
> (cat /proc/nnn/status)
> Cpus_allowed:   00000001
> Cpus_allowed_list:      0
>
>
> See that the Cpus_allowed bitmask is a single core.  Normally it's fff...f.

When I run R I see:

Cpus_allowed:    ff
Cpus_allowed_list:    0-7

It's possible (likely?) that the culprit here isn't R but rather some
other library that R is loading. Are you using OpenBLAS? By default
OpenBLAS will set an obnoxious cpu mask, unless you override this
using some obscure build system settings. (There might be a runtime
option for disabling it too, I don't remember.  Note also that this is
just one of several obnoxious things OpenBLAS does unless you override
a bunch of obscure build system defaults -- building OpenBLAS
correctly is highly non-trivial.)

-n

-- 
Nathaniel J. Smith
Postdoctoral researcher - Informatics - University of Edinburgh
http://vorpus.org


From tomk at 0xdata.com  Wed Aug  6 23:31:58 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Wed, 6 Aug 2014 14:31:58 -0700
Subject: [Rd] R process (and forked children via system2) are limited to
	1 core?
In-Reply-To: <CAPJVwBn6E4DwP7yji8mLXZ5JiSeJVPLCBpAyAPTaTFO_fporKQ@mail.gmail.com>
References: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>
	<CAPJVwBn6E4DwP7yji8mLXZ5JiSeJVPLCBpAyAPTaTFO_fporKQ@mail.gmail.com>
Message-ID: <655D905D-F0F5-419A-9A69-D77952B7C04B@0xdata.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140806/4ac2b26d/attachment.pl>

From njs at pobox.com  Wed Aug  6 23:41:33 2014
From: njs at pobox.com (Nathaniel Smith)
Date: Wed, 6 Aug 2014 22:41:33 +0100
Subject: [Rd] R process (and forked children via system2) are limited to
	1 core?
In-Reply-To: <655D905D-F0F5-419A-9A69-D77952B7C04B@0xdata.com>
References: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>
	<CAPJVwBn6E4DwP7yji8mLXZ5JiSeJVPLCBpAyAPTaTFO_fporKQ@mail.gmail.com>
	<655D905D-F0F5-419A-9A69-D77952B7C04B@0xdata.com>
Message-ID: <CAPJVwBmYNWU908uwcmWMyF-H4JOuMBbWiG939YNP8XG+yXMM7g@mail.gmail.com>

On Wed, Aug 6, 2014 at 10:31 PM, Tom Kraljevic <tomk at 0xdata.com> wrote:
>
> Hi Nathaniel,
>
>
>
> Thanks for the suggestion.
>
> I?m actually not really using R to do any real work.
> I?m starting the R H2O package (a Java machine learning package) and
> forwarding all the work to H2O.
>
>
>
> This is the list of packages I have in R:
>
>
>> search()
>  [1] ".GlobalEnv"        "package:h2o"       "package:tools"
>  [4] "package:statmod"   "package:rjson"     "package:RCurl"
>  [7] "package:bitops"    "package:stats"     "package:graphics"
> [10] "package:grDevices" "package:utils"     "package:datasets"
> [13] "package:methods"   "Autoloads"         "package:base"
>
>
> And here is the /proc info
>
> tomk at mr-0xb4:~$ ps -efww | grep R | grep tomk
> tomk      8366 13845  1 14:25 pts/0    00:00:01 /usr/lib/R/bin/exec/R
> tomk     12960 27363  0 14:27 pts/3    00:00:00 grep --color=auto R
> tomk at mr-0xb4:~$ grep Cpus /proc/8366/status
> Cpus_allowed:   00000001
> Cpus_allowed_list:      0
>
>
>
> As you can see, my R is super vanilla.  I haven?t configured hardly
> anything.  I?m just loading a few plain packages.

My suggestion is just a guess, really, but: R always uses (and thus
loads by default) some underlying C library to implement its core
linear algebra routines. OpenBLAS is one of the libraries that it
might possibly be using, depending on how your R was set up.

Anyway, it looks like the quick way to check for this particular
possible culprit is to run

env OPENBLAS_MAIN_FREE=1 R

and see if that helps.

-n

-- 
Nathaniel J. Smith
Postdoctoral researcher - Informatics - University of Edinburgh
http://vorpus.org


From tomk at 0xdata.com  Thu Aug  7 00:12:09 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Wed, 6 Aug 2014 15:12:09 -0700
Subject: [Rd] R process (and forked children via system2) are limited to
	1 core?
In-Reply-To: <CAPJVwBmYNWU908uwcmWMyF-H4JOuMBbWiG939YNP8XG+yXMM7g@mail.gmail.com>
References: <D1A68D4C-12E4-44B2-9DD7-B14FEDA55002@0xdata.com>
	<CAPJVwBn6E4DwP7yji8mLXZ5JiSeJVPLCBpAyAPTaTFO_fporKQ@mail.gmail.com>
	<655D905D-F0F5-419A-9A69-D77952B7C04B@0xdata.com>
	<CAPJVwBmYNWU908uwcmWMyF-H4JOuMBbWiG939YNP8XG+yXMM7g@mail.gmail.com>
Message-ID: <441143F0-46B2-48A3-B003-25BD447CFFF1@0xdata.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140806/1553cfae/attachment.pl>

From tomk at 0xdata.com  Tue Aug  5 04:49:04 2014
From: tomk at 0xdata.com (Tom Kraljevic)
Date: Mon, 4 Aug 2014 19:49:04 -0700
Subject: [Rd] R process (and forked children via system2) are limited to 1
	core?
Message-ID: <C18CFF68-673E-4879-8D07-7CE4E8BF164B@0xdata.com>


Hi,


(Using R 3.1.1 on Ubuntu 12.04.4 LTS)


What is the recommended way for R to fork a (non-R) process that is not CPU limited?
Currently I am using R?s system2() call, and this is inheriting the environment of the R process.


I notice that (at least on Linux) when I am poking around /proc that the R process itself is setting up cpu limitations for itself (max 1 core).


Using strace, I see the following:

(strace output)
out.20612:sched_setaffinity(0, 128, {100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}) = 0


And proc shows:

(cat /proc/nnn/status)
Cpus_allowed:   00000001
Cpus_allowed_list:      0


See that the Cpus_allowed bitmask is a single core.  Normally it?s fff?f.


I want my child process (java in this case) not to share this limitation.  What is the recommended way of doing this from R?
Any ideas or suggestions appreciated!


Thanks,
Tom


From kirill.mueller at ivt.baug.ethz.ch  Thu Aug  7 02:15:00 2014
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?B?S2lyaWxsIE3DvGxsZXI=?=)
Date: Thu, 7 Aug 2014 02:15:00 +0200
Subject: [Rd] UTC time zone on Windows
Message-ID: <53E2C504.8030605@ivt.baug.ethz.ch>

Hi


I'm having trouble running R CMD build and check with UTC time zone 
setting in Windows Server 2012. I can't seem to get rid of the following 
warning:

   unable to identify current timezone 'C':
please set environment variable 'TZ'

However, setting TZ to either "Europe/London" or "GMT Standard Time" 
didn't help.

It seems to me that the warning originates in registryTZ.c 
(https://github.com/wch/r-source/blob/776708efe6003e36f02587ad47b2eaaaa19e2f69/src/extra/tzone/registryTZ.c#L363). 
I have therefore looked at 
HKLM\SYSTEM\CurrentControlSet\Control\TimeZoneInformation, to learn that 
TimeZoneKeyName is set to "UTC". This time zone is not defined in 
TZtable, but is present in this machine's 
HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Time Zones. (Also, the 
text of the warning permits the possibility that only the first 
character of the time zone is used for the warning message -- in the 
code, a const wchar_t* is used for a %s placeholder.)

Below is a link to the log of such a failing run. The first 124 lines 
are registry dumps, output of R CMD * is near the end of the log at 
lines 212 and 224.

https://ci.appveyor.com/project/krlmlr/r-appveyor/build/1.0.36

This happens with R 3.1.1 and R-devel r66309.

Is there a workaround I have missed, short of updating TZtable? How can 
I help updating TZtable? Thanks!


Cheers

Kirill


From maechler at stat.math.ethz.ch  Thu Aug  7 10:51:51 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Aug 2014 10:51:51 +0200
Subject: [Rd] RFC: diag(x, n)  not preserving integer and logical x
Message-ID: <21475.15911.157158.65610@stat.math.ethz.ch>

This is not at all something new(*). As maintainer of the
Matrix  package, I don't like this inconsistency of base R's diag().
We have had the following -- forever, almost surely inherited
from S and S+  :

diag(x) preserves the storage mode of x  for  'complex' and
'double' precision,  but converts integer and logicals to double :

  > storage.mode(x <- 1i + 1:7); storage.mode(diag(x))
  [1] "complex"
  [1] "complex"
  > storage.mode(x <- 0 + 1:7);  storage.mode(diag(x))
  [1] "double"
  [1] "double"

  > storage.mode(x <- 1:7);      storage.mode(diag(x))
  [1] "integer"
  [1] "double"
  > storage.mode(x <- 1:7 > 3);  storage.mode(diag(x))
  [1] "logical"
  [1] "double"

and so it is actually a bit cumbersome (and a memory waste in
the case of large matrices) to create a diagonal integer or
logical matrix.

The help page does not mention the current behavior, though you
may say it alludes to the fact that logicals are treated as 0/1
implicitly (**)

If I change this behavior such that logical and integer x are
preserved,

	make check-all

which includes all checks, including those of all recommended
packages (including Matrix!) successfully runs through; so at
least  base + Recommended R never relies on the current
behavior, nor should any "well programmed" R code ...

Hence my proposal, somewhat tentative for now,
to change this  diag(.) behavior.

Martin Maechler

*) and possibly something we "can not" change in R, because too
   much code implicitely may be depending on it,  but now I hope
   we can still...

**) BTW, also including the somewhat amusing case of diag(c("A","B")).


From lawrence.michael at gene.com  Thu Aug  7 23:11:19 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 7 Aug 2014 14:11:19 -0700
Subject: [Rd] portableParalleSeeds Package violation, CRAN exception?
In-Reply-To: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
References: <CAErODj-ikqYuUa-hc89x=kANsSM6BmzOx8RR58MqNOiTKO2S_Q@mail.gmail.com>
Message-ID: <CAOQ5Nye_GkyXF2_rBWKU2=TZ7GZVKTo5OYW=YF01AzJcWo7L+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140807/92023a80/attachment.pl>

From jwiley.psych at gmail.com  Fri Aug  8 01:35:03 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 8 Aug 2014 09:35:03 +1000
Subject: [Rd] How to (appropropriately) use require in a package?
Message-ID: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140808/10c2e61a/attachment.pl>

From christopher.g.green at gmail.com  Fri Aug  8 01:53:49 2014
From: christopher.g.green at gmail.com (Chris Green)
Date: Thu, 7 Aug 2014 16:53:49 -0700
Subject: [Rd] How to (appropropriately) use require in a package?
In-Reply-To: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
References: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
Message-ID: <CAKtC-d1HjQvGFybojyAgJhVLHTJkLwfQOk3bw3dmFtk_T2ahYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140807/784701a6/attachment.pl>

From jwiley.psych at gmail.com  Fri Aug  8 01:58:55 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 8 Aug 2014 09:58:55 +1000
Subject: [Rd] How to (appropropriately) use require in a package?
In-Reply-To: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
References: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
Message-ID: <CANz9Z_KqOMyRJ0XGr+eCYs5yzYc=v6gXptL+wZN3TpGNLyDMrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140808/1c730d33/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Aug  8 08:47:33 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 08 Aug 2014 07:47:33 +0100
Subject: [Rd] How to (appropropriately) use require in a package?
In-Reply-To: <CANz9Z_KqOMyRJ0XGr+eCYs5yzYc=v6gXptL+wZN3TpGNLyDMrw@mail.gmail.com>
References: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
	<CANz9Z_KqOMyRJ0XGr+eCYs5yzYc=v6gXptL+wZN3TpGNLyDMrw@mail.gmail.com>
Message-ID: <53E47285.4030604@stats.ox.ac.uk>

The safe, elegant way to do this is to use namespace scoping: it is 
still not at all clear why 'other code' needs PkgB *on the search path*.

In other cases seen in CRAN submissions, 'other code' has been in PkgA's 
namespace, and hence things in PkgB's exports have been visible as it 
was imported by PkgA and hence in the environment tree for functions in 
PkgA.  Then namespace scoping will ensure that PkgB's namespace is 
loaded on the cluster workers.


On 08/08/2014 00:58, Joshua Wiley wrote:
> Someone kindly pointed out that it is not clear from my email why Depends
> will not work.  A more complete example is:
>
> PkgA:
> f <- function(ncores) {
>    cl <- makeCluster(ncores)
>
>    clusterEvalQ(cl, {
>      require(PkgB)
>    })
>    [other code]
>
>    ### this is the code I want to work and need to be able to call
>    ### PkgB functions on each of the cluster slaves
>    output <- parLapply(cl, 1:n, function(i) {
>      [code from my package and using some functions from PkgB]
>    })
>
> }
>
> As far as I know, just because I add PkgB to the Depends (or imports,
> whatever) of PkgA, does not mean that the cluster started by PkgA will
> automatically have PkgB loaded and functions available.
>
> Thanks!
>
>
>
> On Fri, Aug 8, 2014 at 9:35 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>
>> Dear All,
>>
>> What is the preferred way for Package A, to initialize a cluster, and load
>> Package B on all nodes?
>>
>> I am writing a package that parallelizes some functions through the use of
>> a cluster if useRs are on a Windows machine (using parLapply and family).
>>   I also make use of another package in some of my code, so it is necessary
>> to load the required packages on each slave once the cluster is started.
>>
>> Right now, I have done this, by evaluating require(packages) on each
>> slave; however, Rcmd check has a note that I should remove the "require" in
>> my code.
>>
>> Thanks!
>>
>> Josh
>>
>> --
>> Joshua F. Wiley
>> Ph.D. Student, UCLA Department of Psychology
>> http://joshuawiley.com/
>> Senior Analyst, Elkhart Group Ltd.
>> http://elkhartgroup.com
>> Office: 260.673.5518
>>
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jwiley.psych at gmail.com  Fri Aug  8 09:22:31 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 8 Aug 2014 17:22:31 +1000
Subject: [Rd] How to (appropropriately) use require in a package?
In-Reply-To: <53E47285.4030604@stats.ox.ac.uk>
References: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>
	<CANz9Z_KqOMyRJ0XGr+eCYs5yzYc=v6gXptL+wZN3TpGNLyDMrw@mail.gmail.com>
	<53E47285.4030604@stats.ox.ac.uk>
Message-ID: <CANz9Z_K5RjAKM0J7g71PJM6e6n58ez9hmPfkQ=GTgkgwqMTjsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140808/8e2a2063/attachment.pl>

From btyner at gmail.com  Fri Aug  8 16:03:07 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 08 Aug 2014 10:03:07 -0400
Subject: [Rd] could not find function "anyNA" when building tools package in
 R 3.1.1
Message-ID: <53E4D89B.50702@gmail.com>

Hello,

When building R from source, during the part where the 'tools' package
is built, I get:

make[6]: Entering directory `/home/btyner/R-3.1.1/src/library/tools/src'
make[6]: Leaving directory `/home/btyner/R-3.1.1/src/library/tools/src'
make[5]: Leaving directory `/home/btyner/R-3.1.1/src/library/tools/src'
make[4]: Leaving directory `/home/btyner/R-3.1.1/src/library/tools'
Error in .deparseOpts(control) : could not find function "anyNA"
Calls: ::: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
Execution halted
make[3]: *** [all] Error 1
make[3]: Leaving directory `/home/btyner/R-3.1.1/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/btyner/R-3.1.1/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/btyner/R-3.1.1/src'
make: *** [R] Error 1

wondering if anyone has seen this before or has any suggestions as to
what the problem could be? Here is some platform information:

uname -m = x86_64
uname -r = 2.6.32-358.18.1.el6.x86_64
uname -s = Linux

Happy to provide more info as needed.

Regards
Ben



From murdoch.duncan at gmail.com  Fri Aug  8 16:51:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 08 Aug 2014 10:51:10 -0400
Subject: [Rd] RFC: diag(x, n)  not preserving integer and logical x
In-Reply-To: <21475.15911.157158.65610@stat.math.ethz.ch>
References: <21475.15911.157158.65610@stat.math.ethz.ch>
Message-ID: <53E4E3DE.8050001@gmail.com>

On 07/08/2014, 4:51 AM, Martin Maechler wrote:
> This is not at all something new(*). As maintainer of the
> Matrix  package, I don't like this inconsistency of base R's diag().
> We have had the following -- forever, almost surely inherited
> from S and S+  :
> 
> diag(x) preserves the storage mode of x  for  'complex' and
> 'double' precision,  but converts integer and logicals to double :
> 
>   > storage.mode(x <- 1i + 1:7); storage.mode(diag(x))
>   [1] "complex"
>   [1] "complex"
>   > storage.mode(x <- 0 + 1:7);  storage.mode(diag(x))
>   [1] "double"
>   [1] "double"
> 
>   > storage.mode(x <- 1:7);      storage.mode(diag(x))
>   [1] "integer"
>   [1] "double"
>   > storage.mode(x <- 1:7 > 3);  storage.mode(diag(x))
>   [1] "logical"
>   [1] "double"
> 
> and so it is actually a bit cumbersome (and a memory waste in
> the case of large matrices) to create a diagonal integer or
> logical matrix.
> 
> The help page does not mention the current behavior, though you
> may say it alludes to the fact that logicals are treated as 0/1
> implicitly (**)
> 

I think the change to preserve integer makes sense, but preserving
logical does not.  A diagonal matrix has zeros off the diagonal, and
they are not logical.  Having diag() sometimes return a matrix with
FALSE off the diagonal just looks wrong.

Duncan Murdoch

> If I change this behavior such that logical and integer x are
> preserved,
> 
> 	make check-all
> 
> which includes all checks, including those of all recommended
> packages (including Matrix!) successfully runs through; so at
> least  base + Recommended R never relies on the current
> behavior, nor should any "well programmed" R code ...
> 
> Hence my proposal, somewhat tentative for now,
> to change this  diag(.) behavior.
> 
> Martin Maechler
> 
> *) and possibly something we "can not" change in R, because too
>    much code implicitely may be depending on it,  but now I hope
>    we can still...
> 
> **) BTW, also including the somewhat amusing case of diag(c("A","B")).
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Uwe.Ligges at R-project.org  Fri Aug  8 18:41:13 2014
From: Uwe.Ligges at R-project.org (Uwe Ligges)
Date: Fri, 08 Aug 2014 18:41:13 +0200
Subject: [Rd] Looking for new maintainer of orphans R2HTML SemiPar cghseg
 hexbin lgtdl monreg muhaz operators pamr
Message-ID: <53E4FDA9.70903@R-project.org>

Dear maintainers and R-devel,

Several orphaned CRAN packages are about to be archived due to 
outstanding QC problems, but have CRAN and BioC packages depending on 
them which would be broken by the archival (and hence need archiving 
alongside).
Therefore we are looking for new maintainers taking over maintainership 
for one or more of the following packages:

R2HTML SemiPar cghseg hexbin lgtdl monreg muhaz operators pamr

Package maintainers whose packages depend on one of these may be natural 
candidates to become new maintainers.
Hence this messages is addressed to all these maintainers via BCC and to 
R-devel.

See

   <http://CRAN.R-project.org/package=R2HTML>
   <http://CRAN.R-project.org/package=SemiPar>
   <http://CRAN.R-project.org/package=cghseg>
   <http://CRAN.R-project.org/package=hexbin>
   <http://CRAN.R-project.org/package=lgtdl>
   <http://CRAN.R-project.org/package=monreg>
   <http://CRAN.R-project.org/package=muhaz>
   <http://CRAN.R-project.org/package=operators>
   <http://CRAN.R-project.org/package=pamr>

for information on the QC issues and the reverse dependencies.

Best wishes,
Uwe Ligges
(for the CRAN team)


From htl10 at users.sourceforge.net  Fri Aug  8 19:42:07 2014
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 8 Aug 2014 18:42:07 +0100
Subject: [Rd] Looking for new maintainer of orphans R2HTML SemiPar
	cghseg hexbin lgtdl monreg muhaz operators pamr
Message-ID: <1407519727.26155.YahooMailBasic@web172305.mail.ir2.yahoo.com>

At least as far as I am concerned, I'll remove dependency on hexbin, if it comes to that.
The dependency is only used in some vignettes, and quite non-essential, and perhaps,
undesirable, in fact.

--------------------------------------------
On Fri, 8/8/14, Uwe Ligges <Uwe.Ligges at R-project.org> wrote:

 Subject: Looking for new maintainer of orphans R2HTML SemiPar cghseg hexbin lgtdl monreg muhaz operators pamr
 To: "R-Devel" <r-devel at r-project.org>
 Cc: "CRAN" <cran at R-project.org>
 Date: Friday, 8 August, 2014, 17:41

 Dear maintainers and R-devel,

 Several orphaned CRAN packages are about to be archived due
 to 
 outstanding QC problems, but have CRAN and BioC packages
 depending on 
 them which would be broken by the archival (and hence need
 archiving 
 alongside).
 Therefore we are looking for new maintainers taking over
 maintainership 
 for one or more of the following packages:

 R2HTML SemiPar cghseg hexbin lgtdl monreg muhaz operators
 pamr

 Package maintainers whose packages depend on one of these
 may be natural 
 candidates to become new maintainers.
 Hence this messages is addressed to all these maintainers
 via BCC and to 
 R-devel.

 See

 ???<http://CRAN.R-project.org/package=R2HTML>
 ???<http://CRAN.R-project.org/package=SemiPar>
 ???<http://CRAN.R-project.org/package=cghseg>
 ???<http://CRAN.R-project.org/package=hexbin>
 ???<http://CRAN.R-project.org/package=lgtdl>
 ???<http://CRAN.R-project.org/package=monreg>
 ???<http://CRAN.R-project.org/package=muhaz>
 ???<http://CRAN.R-project.org/package=operators>
 ???<http://CRAN.R-project.org/package=pamr>

 for information on the QC issues and the reverse
 dependencies.

 Best wishes,
 Uwe Ligges
 (for the CRAN team)


From andrezda10 at yandex.com  Sat Aug  9 10:56:58 2014
From: andrezda10 at yandex.com (=?utf-8?B?QW5kcsOpIFouIEQuIEEu?=)
Date: Sat, 09 Aug 2014 05:56:58 -0300
Subject: [Rd] Compilation problems
Message-ID: <915151407574618@web19m.yandex.ru>

Hello,

I'm trying to compile and install R for my user in a machine without admin privileges. I have done this before, so this is fine. But I have 2 problems with R compilation right now.


After ./configure --prefix=/home/me/dir/ I get this:

================================

R is now configured for x86_64-unknown-linux-gnu

  Source directory:          .
  Installation directory:    /home/balacobaco/bbin

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       gfortran  -g -O2

  C++ compiler:              g++  -g -O2
  C++ 11 compiler:           g++  -std=c++11 -g -O2
  Fortran 90/95 compiler:    gfortran -g -O2
  Obj-C compiler:	      

  Interfaces supported:      X11, tcltk
  External libraries:        readline, ICU
  Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo
  Options enabled:           shared BLAS, R profiling

  Recommended packages:      yes

configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally

================================

Problem 1) How do I get rid of this warning about "inconsolata.sty" and "zi4.sty". Can I have this file locally for my installation or compilation? Where do I download it? Where do I put them?


Problem 2) The compilation fails with the following message:

================================
(...)
configuring Java ...
Java interpreter : /usr/bin/java
Could not create the Java virtual machine.
Error occurred during initialization of VM
Could not reserve enough space for object heap

*** Java interpreter doesn't work properly.

make[1]: [stamp-java] Error 1 (ignored)
make[1]: Leaving directory `/home/me/dir'

================================

What happened? What's wrong with my server's java? What caused this error, so I can try to fix or skip it, if possible.

Thank you,

Andre'


From andrezda10 at yandex.com  Sat Aug  9 16:50:16 2014
From: andrezda10 at yandex.com (=?utf-8?B?QW5kcsOpIFouIEQuIEEu?=)
Date: Sat, 09 Aug 2014 11:50:16 -0300
Subject: [Rd] Compilation problems
Message-ID: <1398961407595816@web25m.yandex.ru>

>  Worst case is that you'll have to install TeX in your local user directory.

I'll try to find it again. The search I tried didn't look as easy, very few results, none helpful. And if I could install *just the fonts* on my local dir, instead of the full TeX, it would be perfect. But I don't know how to do it. Is it possible?


> Second, your JVM is requesting more memory than is available on the
> box. How much memory do you have available? Make sure you have a
> sufficient amount that is free. Worst case you can set the Xmx variable
> to reduce max memory allowed to the JVM, but your app performance
> will be pathetic.

The Xmx variable from what? From R's code? Or is it java config?
The server is pretty big. 12GiB RaM and 500GiB of disk free. Process' limits may exist (I guess), but I don't know how to find about them.


Andre'



---------------------------- "Brian Lee Yung Rowe" wrote: ----------------------------


> Hi your first problem is a common issue. Make sure you TeX installation has the inconsolata.sty file installed. There are numerous pages on the web to address this. Worst case is that you'll have to install TeX in your local user directory.
> 
> Second, your JVM is requesting more memory than is available on the box. How much memory do you have available? Make sure you have a sufficient amount that is free. Worst case you can set the Xmx variable to reduce max memory allowed to the JVM, but your app performance will be pathetic.
> 
> Good luck,
> Brian
> 
> ?????
> Brian Lee Yung RoweFounder, Zato Novo
> Professor, M.S. Data Analytics, CUNY
> 
> On Aug 9, 2014, at 7:41 AM, "Andr? Z. D. A." <andrezda10 at yandex.com> wrote:
> 
>> Hello,
>>
>> I'm trying to compile and install R for my user in a machine without admin privileges. I have done this before, so this is fine. But I have 2 problems with R compilation right now.
>>
>> After ./configure --prefix=/home/me/dir/ I get this:
>>
>> ================================
>>
>> R is now configured for x86_64-unknown-linux-gnu
>>
>> Source directory: .
>> Installation directory: /home/balacobaco/bbin
>>
>> C compiler: gcc -std=gnu99 -g -O2
>> Fortran 77 compiler: gfortran -g -O2
>>
>> C++ compiler: g++ -g -O2
>> C++ 11 compiler: g++ -std=c++11 -g -O2
>> Fortran 90/95 compiler: gfortran -g -O2
>> Obj-C compiler:
>>
>> Interfaces supported: X11, tcltk
>> External libraries: readline, ICU
>> Additional capabilities: PNG, JPEG, TIFF, NLS, cairo
>> Options enabled: shared BLAS, R profiling
>>
>> Recommended packages: yes
>>
>> configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally
>>
>> ================================
>>
>> Problem 1) How do I get rid of this warning about "inconsolata.sty" and "zi4.sty". Can I have this file locally for my installation or compilation? Where do I download it? Where do I put them?
>>
>> Problem 2) The compilation fails with the following message:
>>
>> ================================
>> (...)
>> configuring Java ...
>> Java interpreter : /usr/bin/java
>> Could not create the Java virtual machine.
>> Error occurred during initialization of VM
>> Could not reserve enough space for object heap
>>
>> *** Java interpreter doesn't work properly.
>>
>> make[1]: [stamp-java] Error 1 (ignored)
>> make[1]: Leaving directory `/home/me/dir'
>>
>> ================================
>>
>> What happened? What's wrong with my server's java? What caused this error, so I can try to fix or skip it, if possible.
>>
>> Thank you,
>>
>> Andre'
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From gcr at wisdomandwonder.com  Sun Aug 10 16:13:55 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 09:13:55 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAFOpNVGhSqjJSk4mpa5=W_069npCj7RBx0ZCLqObysxW5=1jgA@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
	<CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>
	<CAAjq1mdQxg=E8VQxQhsOW+H2f0M4N-yj8dTxx-nZ-ADrbTt1MQ@mail.gmail.com>
	<CAFOpNVGhSqjJSk4mpa5=W_069npCj7RBx0ZCLqObysxW5=1jgA@mail.gmail.com>
Message-ID: <CAAjq1mdUipkarVbyR7X5jG0eoqHwUW4tBMKy43wW0ygP3G1=Rg@mail.gmail.com>

Thank you for that pleasant and concise explanation!

I will keep at it.
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Tue, Aug 5, 2014 at 7:54 PM, Winston Chang <winstonchang1 at gmail.com> wrote:
> On Tue, Aug 5, 2014 at 4:37 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>>
>> That is delightful.
>>
>> When I run it like this:
>> ? Start R
>> ? Nothing in .Rprofile
>> ? Paste in your code
>> ?????
>> ? gcrenv <- new.env()
>> ? gcrenv$attach.old <- attach
>> ? gcrenv$attach <- function(...){stop("NEVER USE ATTACH")}
>> ? base::attach(gcrenv, name="gcr", warn.conflicts = FALSE)
>> ?????
>> ? I get exactly what is expected, I think
>> ?????
>> ? search()
>> ?????
>> ?????
>> ?  [1] ".GlobalEnv"        "gcr"               "ESSR"
>> ?  [4] "package:stats"     "package:graphics"  "package:grDevices"
>> ?  [7] "package:utils"     "package:datasets"  "package:methods"
>> ? [10] "Autoloads"         "package:base"
>> ?????
>>
>> Just to be sure:
>> ? Is that what is expected?
>> ? I am surprised because I thought that `gcr' would come first before
>>   `.GlobalEnv'
>>   ? Perhaps I mis understand, as `.GlobalEnv' is actually the "REPL"?
>>
>> My goal is to move that to my .Rprofile so that it is "always run" and I
>> can forget about it more or less.
>>
>> Reading [this] I felt like `.First' would be the right place to put it,
>> but then read further to find that packages are only loaded /after/
>> `.First' has completed.  Curious, I tried it just to be sure. I am now
>> :).
>>
>> This is the .Rprofile file:
>>
>> ?????
>> ? cat(".Rprofile: Setting CMU repository\n")
>> ? r = getOption("repos")
>> ? r["CRAN"] = "http://lib.stat.cmu.edu/R/CRAN/"
>> ? options(repos = r)
>> ? rm(r)
>> ?
>> ? .First <- function() {
>> ?    ?same code as above?
>> ? }
>> ?????
>>
>> (I included the repository load, and understand it should not impact
>> things here)
>>
>> This is run after normal startup of R:
>>
>> ?????
>> ? search()
>> ?????
>> ?????
>> ?  [1] ".GlobalEnv"        "package:stats"     "package:graphics"
>> ?  [4] "package:grDevices" "package:utils"     "package:datasets"
>> ?  [7] "gcr"               "package:methods"   "Autoloads"
>> ? [10] "package:base"
>> ?????
>>
>> When I read this, I read it as:
>> ? My rebind of `attach' occurs
>> ? Then all of the packages are loaded and they are referring to
>>   my-rebound `attach'
>> ? That is a problem because it *will* break package code
>> ? Clearly me putting that code in `.Rprofile' is the wrong place.
>>
>
> That order for search path should actually be fine. To understand why,
> you first have to know the difference between the _binding_
> environment for an object, and the _enclosing_ environment for a
> function.
>
> The binding environment is where you can find an object. For example,
> in the global env, you have a bunch bindings (we often call them
> variables), that point to various objects - vectors, data frames,
> other environments, etc.
>
> The enclosing environment for a function is where the function "runs
> in" when it's called.
>
> Most R objects have just a binding environment (a variable or
> reference that points to the object); functions also have an enclosing
> environment. These two environments aren't necessarily the same.
>
> When you run search(), it shows the set of environments where R will
> look for an object of a given name, when you run stuff at the console
> (and are in the global env). The trick is that, although you can find
> a function (they are bound bound) in one of these _package_
> environments, those functions run in (are enclosed by) a different
> environment: the a corresponding _namespace_ environment.
>
> The way that a namespace environment is set up with the arrangement of
> its ancestor environments, it will find the base namespace version of
> `attach` before it finds yours, even if your personal gcr environment
> comes early in the search path.
>
> =========================
> # Here's an example to illustrate. The `utils::alarm` function calls
> `cat`, which is in base.
>
> alarm
> # function ()
> # {
> #     cat("\a")
> #     flush.console()
> # }
> # <environment: namespace:utils>
>
>
> # Running it makes the screen flash or beep
> alarm()
> # [screen flashes]
>
>
> # We'll put a replacement version of cat early in the search path,
> between utils and base
> my_stuff <- new.env()
> my_stuff$cat <- function(...) stop("Tried to call cat")
> base::attach(my_stuff, pos=length(search()) - 1, name="my_stuff")
>
> search()
> #  [1] ".GlobalEnv"        "tools:rstudio"     "package:stats"
> "package:graphics"
> #  [5] "package:grDevices" "package:utils"     "package:datasets"
> "package:methods"
> #  [9] "my_stuff"          "Autoloads"         "package:base"
>
> # Calling cat from the console gives the error, as expected
> cat()
> # Error in cat() : Tried to call cat
>
> # But when we run alarm(), it still gets the real version of `cat()`,
> # because it finds the the original base namespace version of cat
> # before it finds yours.
> alarm()
> # [screen flashes]
>
> ==========================
>
> You can even alter package environments without affecting the
> corresponding namespace environment. The exception to the package and
> namespace environments being distinct is the base environment; change
> one and you change the other. (I just realized this and have to
> retract my earlier statement about the behavior being different if
> change attach in the base package env vs. the base namespace env.)
>
> -Winston


From gcr at wisdomandwonder.com  Sun Aug 10 19:00:13 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 12:00:13 -0500
Subject: [Rd] Is it a good idea or even possible to redefine attach?
In-Reply-To: <CAAjq1mdUipkarVbyR7X5jG0eoqHwUW4tBMKy43wW0ygP3G1=Rg@mail.gmail.com>
References: <CAAjq1mfLzRdcYRb4waXBYx6t7h6rr7u0rkJDCGgySf9LaSYi2A@mail.gmail.com>
	<CAFOpNVHMjWx0rO-uzsp-s0m3iGKGXO_fzNfSe2p92WcHdy4t7w@mail.gmail.com>
	<CAAjq1mdQxg=E8VQxQhsOW+H2f0M4N-yj8dTxx-nZ-ADrbTt1MQ@mail.gmail.com>
	<CAFOpNVGhSqjJSk4mpa5=W_069npCj7RBx0ZCLqObysxW5=1jgA@mail.gmail.com>
	<CAAjq1mdUipkarVbyR7X5jG0eoqHwUW4tBMKy43wW0ygP3G1=Rg@mail.gmail.com>
Message-ID: <CAAjq1mdy6tkz-PV+w_Byy-_19Rav-=OgJ_sGbmwsKUXwoRgGkw@mail.gmail.com>

As it turns out, my approach was a bit aggressive. A critical package
was using it and could see my new attach!

I will just warn, and encourage:

.First <- function() {
    gcr <- new.env()
    gcr$unsafe.attach <- attach
    gcr$attach <- function(...) {
        warning("NEVER USE ATTACH! Use `unsafe.attach` if you must.")
        unsafe.attach(...)
    }
    base::attach(gcr, name="gcr", warn.conflicts = FALSE)
}
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Sun, Aug 10, 2014 at 9:13 AM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
> Thank you for that pleasant and concise explanation!
>
> I will keep at it.
> Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
> ?Wisdom begins in wonder.? --Socrates
> ((? (x) (x x)) (? (x) (x x)))
> ?Life has become immeasurably better since I have been forced to stop
> taking it seriously.? --Thompson
>
>
> On Tue, Aug 5, 2014 at 7:54 PM, Winston Chang <winstonchang1 at gmail.com> wrote:
>> On Tue, Aug 5, 2014 at 4:37 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>>>
>>> That is delightful.
>>>
>>> When I run it like this:
>>> ? Start R
>>> ? Nothing in .Rprofile
>>> ? Paste in your code
>>> ?????
>>> ? gcrenv <- new.env()
>>> ? gcrenv$attach.old <- attach
>>> ? gcrenv$attach <- function(...){stop("NEVER USE ATTACH")}
>>> ? base::attach(gcrenv, name="gcr", warn.conflicts = FALSE)
>>> ?????
>>> ? I get exactly what is expected, I think
>>> ?????
>>> ? search()
>>> ?????
>>> ?????
>>> ?  [1] ".GlobalEnv"        "gcr"               "ESSR"
>>> ?  [4] "package:stats"     "package:graphics"  "package:grDevices"
>>> ?  [7] "package:utils"     "package:datasets"  "package:methods"
>>> ? [10] "Autoloads"         "package:base"
>>> ?????
>>>
>>> Just to be sure:
>>> ? Is that what is expected?
>>> ? I am surprised because I thought that `gcr' would come first before
>>>   `.GlobalEnv'
>>>   ? Perhaps I mis understand, as `.GlobalEnv' is actually the "REPL"?
>>>
>>> My goal is to move that to my .Rprofile so that it is "always run" and I
>>> can forget about it more or less.
>>>
>>> Reading [this] I felt like `.First' would be the right place to put it,
>>> but then read further to find that packages are only loaded /after/
>>> `.First' has completed.  Curious, I tried it just to be sure. I am now
>>> :).
>>>
>>> This is the .Rprofile file:
>>>
>>> ?????
>>> ? cat(".Rprofile: Setting CMU repository\n")
>>> ? r = getOption("repos")
>>> ? r["CRAN"] = "http://lib.stat.cmu.edu/R/CRAN/"
>>> ? options(repos = r)
>>> ? rm(r)
>>> ?
>>> ? .First <- function() {
>>> ?    ?same code as above?
>>> ? }
>>> ?????
>>>
>>> (I included the repository load, and understand it should not impact
>>> things here)
>>>
>>> This is run after normal startup of R:
>>>
>>> ?????
>>> ? search()
>>> ?????
>>> ?????
>>> ?  [1] ".GlobalEnv"        "package:stats"     "package:graphics"
>>> ?  [4] "package:grDevices" "package:utils"     "package:datasets"
>>> ?  [7] "gcr"               "package:methods"   "Autoloads"
>>> ? [10] "package:base"
>>> ?????
>>>
>>> When I read this, I read it as:
>>> ? My rebind of `attach' occurs
>>> ? Then all of the packages are loaded and they are referring to
>>>   my-rebound `attach'
>>> ? That is a problem because it *will* break package code
>>> ? Clearly me putting that code in `.Rprofile' is the wrong place.
>>>
>>
>> That order for search path should actually be fine. To understand why,
>> you first have to know the difference between the _binding_
>> environment for an object, and the _enclosing_ environment for a
>> function.
>>
>> The binding environment is where you can find an object. For example,
>> in the global env, you have a bunch bindings (we often call them
>> variables), that point to various objects - vectors, data frames,
>> other environments, etc.
>>
>> The enclosing environment for a function is where the function "runs
>> in" when it's called.
>>
>> Most R objects have just a binding environment (a variable or
>> reference that points to the object); functions also have an enclosing
>> environment. These two environments aren't necessarily the same.
>>
>> When you run search(), it shows the set of environments where R will
>> look for an object of a given name, when you run stuff at the console
>> (and are in the global env). The trick is that, although you can find
>> a function (they are bound bound) in one of these _package_
>> environments, those functions run in (are enclosed by) a different
>> environment: the a corresponding _namespace_ environment.
>>
>> The way that a namespace environment is set up with the arrangement of
>> its ancestor environments, it will find the base namespace version of
>> `attach` before it finds yours, even if your personal gcr environment
>> comes early in the search path.
>>
>> =========================
>> # Here's an example to illustrate. The `utils::alarm` function calls
>> `cat`, which is in base.
>>
>> alarm
>> # function ()
>> # {
>> #     cat("\a")
>> #     flush.console()
>> # }
>> # <environment: namespace:utils>
>>
>>
>> # Running it makes the screen flash or beep
>> alarm()
>> # [screen flashes]
>>
>>
>> # We'll put a replacement version of cat early in the search path,
>> between utils and base
>> my_stuff <- new.env()
>> my_stuff$cat <- function(...) stop("Tried to call cat")
>> base::attach(my_stuff, pos=length(search()) - 1, name="my_stuff")
>>
>> search()
>> #  [1] ".GlobalEnv"        "tools:rstudio"     "package:stats"
>> "package:graphics"
>> #  [5] "package:grDevices" "package:utils"     "package:datasets"
>> "package:methods"
>> #  [9] "my_stuff"          "Autoloads"         "package:base"
>>
>> # Calling cat from the console gives the error, as expected
>> cat()
>> # Error in cat() : Tried to call cat
>>
>> # But when we run alarm(), it still gets the real version of `cat()`,
>> # because it finds the the original base namespace version of cat
>> # before it finds yours.
>> alarm()
>> # [screen flashes]
>>
>> ==========================
>>
>> You can even alter package environments without affecting the
>> corresponding namespace environment. The exception to the package and
>> namespace environments being distinct is the base environment; change
>> one and you change the other. (I just realized this and have to
>> retract my earlier statement about the behavior being different if
>> change attach in the base package env vs. the base namespace env.)
>>
>> -Winston


From gcr at wisdomandwonder.com  Sun Aug 10 19:22:46 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 12:22:46 -0500
Subject: [Rd] How to redefine `require' to generate a warning and delegate
 work to the original require?
Message-ID: <CAAjq1md_zS1JUDp1-OM2dUwHWm6fDedOe1Eq9uwyFTRy8F-UUw@mail.gmail.com>

Good afternoon,

My goal is to warn the user any time that they use the `require'
function. The reason is that they probably wanted to use `library'
instead. There is a case where they should use the former though, so I
just want to issue a warning.

My approach was to:
? Re-bind `require' to `original.require'
? Re-implement `require' to
  ? Warn the user
  ? Delegate the real work back to `original-require'
  ? Like this inside of my `.Rprofile':

?????
? .First <- function() {
?     gcr <- new.env()
?     gcr$original.require(...) <- require
?     gcr$require <- function(...) {
?         warning("Are you sure you wanted `require` instead of `library`?")
?         original.require(...)
?     }
?     base::attach(gcr, name="gcr", warn.conflicts = FALSE)
? }
?????

On startup I get the following error though:

?????
? Error in gcr$original.require(...) <- require :
?   '...' used in an incorrect context
?????

What am I doing wrong here and what should I have read to grok my
mistake?

?????
? > sessionInfo()
? R version 3.1.1 (2014-07-10)
? Platform: x86_64-apple-darwin13.2.0 (64-bit)
?
? locale:
? [1] en_US/en_US/en_US/C/en_US/en_US
?
? attached base packages:
? [1] stats     graphics  grDevices utils     datasets  methods   base
?
? loaded via a namespace (and not attached):
? [1] compiler_3.1.1 tools_3.1.1
?????

Kind regards,

Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From jeroen.ooms at stat.ucla.edu  Sun Aug 10 20:14:33 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 10 Aug 2014 20:14:33 +0200
Subject: [Rd] How to redefine `require' to generate a warning and
 delegate work to the original require?
In-Reply-To: <CAAjq1md_zS1JUDp1-OM2dUwHWm6fDedOe1Eq9uwyFTRy8F-UUw@mail.gmail.com>
References: <CAAjq1md_zS1JUDp1-OM2dUwHWm6fDedOe1Eq9uwyFTRy8F-UUw@mail.gmail.com>
Message-ID: <CABFfbXsA5THxJXfN=+m6wW=F8WRsWjhvP4LzM_tm1UFb3mW=Yw@mail.gmail.com>

On Sun, Aug 10, 2014 at 7:22 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>
> ? Error in gcr$original.require(...) <- require :
> ?   '...' used in an incorrect context

I think you mean: gcr$original.require <- base::require. You don't
need the parentheses since you are not defining or calling a function.
You are simply assigning an object to another environment.

Basic questions about R usage/syntax like these are better suited for
the r-help list or stack-overflow. Have a look at:
https://stat.ethz.ch/mailman/listinfo/r-devel.


From gcr at wisdomandwonder.com  Sun Aug 10 20:18:21 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 13:18:21 -0500
Subject: [Rd] "Fastest" way to merge 300+ .5MB dataframes?
Message-ID: <CAAjq1mepNYOdWv5yOD_iM3-BC9Pyek2He0rudXOiKX+nDS8cJg@mail.gmail.com>

Good afternoon,

Today I was working on a practice problem. It was simple, and perhaps
even realistic. It looked like this:
? Get a list of all the data files in a directory
? Load each file into a dataframe
? Merge them into a single data frame

Because all of the columns were the same, the simplest solution in my
mind was to `Reduce' the vector of dataframes with a call to
`merge'. That worked fine, I got what was expected. That is key
actually. It is literally a one-liner, and there will never be index
or scoping errors with it.

Now with that in mind, what is the idiomatic way? Do people usually do
something else because it is /faster/ (by some definition)?

Kind regards,


Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From josh.m.ulrich at gmail.com  Sun Aug 10 20:28:44 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 10 Aug 2014 13:28:44 -0500
Subject: [Rd] "Fastest" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAjq1mepNYOdWv5yOD_iM3-BC9Pyek2He0rudXOiKX+nDS8cJg@mail.gmail.com>
References: <CAAjq1mepNYOdWv5yOD_iM3-BC9Pyek2He0rudXOiKX+nDS8cJg@mail.gmail.com>
Message-ID: <CAPPM_gRhOLiQsyk=+1-KYy2MKgQhPurUYw5NR5sQQkB=Q5ceXg@mail.gmail.com>

The same comment Jeroen Ooms made about your last email also applies
to this one: it is better suited to R-help.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Sun, Aug 10, 2014 at 1:18 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
> Good afternoon,
>
> Today I was working on a practice problem. It was simple, and perhaps
> even realistic. It looked like this:
> ? Get a list of all the data files in a directory
> ? Load each file into a dataframe
> ? Merge them into a single data frame
>
> Because all of the columns were the same, the simplest solution in my
> mind was to `Reduce' the vector of dataframes with a call to
> `merge'. That worked fine, I got what was expected. That is key
> actually. It is literally a one-liner, and there will never be index
> or scoping errors with it.
>
> Now with that in mind, what is the idiomatic way? Do people usually do
> something else because it is /faster/ (by some definition)?
>
> Kind regards,
>
>
> Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
> ?Wisdom begins in wonder.? --Socrates
> ((? (x) (x x)) (? (x) (x x)))
> ?Life has become immeasurably better since I have been forced to stop
> taking it seriously.? --Thompson
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gcr at wisdomandwonder.com  Sun Aug 10 20:49:33 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 13:49:33 -0500
Subject: [Rd] "Fastest" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAPPM_gRhOLiQsyk=+1-KYy2MKgQhPurUYw5NR5sQQkB=Q5ceXg@mail.gmail.com>
References: <CAAjq1mepNYOdWv5yOD_iM3-BC9Pyek2He0rudXOiKX+nDS8cJg@mail.gmail.com>
	<CAPPM_gRhOLiQsyk=+1-KYy2MKgQhPurUYw5NR5sQQkB=Q5ceXg@mail.gmail.com>
Message-ID: <CAAjq1meFa+7Z02xaEstDQ4Sh3KwM8q2037asKUvWCvP=tpbUSg@mail.gmail.com>

My sincere apologies.

Having read http://www.r-project.org/posting-guide.html , I had wanted
to post this one to R-help.
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Sun, Aug 10, 2014 at 1:28 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> The same comment Jeroen Ooms made about your last email also applies
> to this one: it is better suited to R-help.
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
>
> On Sun, Aug 10, 2014 at 1:18 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>> Good afternoon,
>>
>> Today I was working on a practice problem. It was simple, and perhaps
>> even realistic. It looked like this:
>> ? Get a list of all the data files in a directory
>> ? Load each file into a dataframe
>> ? Merge them into a single data frame
>>
>> Because all of the columns were the same, the simplest solution in my
>> mind was to `Reduce' the vector of dataframes with a call to
>> `merge'. That worked fine, I got what was expected. That is key
>> actually. It is literally a one-liner, and there will never be index
>> or scoping errors with it.
>>
>> Now with that in mind, what is the idiomatic way? Do people usually do
>> something else because it is /faster/ (by some definition)?
>>
>> Kind regards,
>>
>>
>> Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
>> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
>> ?Wisdom begins in wonder.? --Socrates
>> ((? (x) (x x)) (? (x) (x x)))
>> ?Life has become immeasurably better since I have been forced to stop
>> taking it seriously.? --Thompson
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From gcr at wisdomandwonder.com  Sun Aug 10 20:57:04 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 13:57:04 -0500
Subject: [Rd] How to redefine `require' to generate a warning and
 delegate work to the original require?
In-Reply-To: <CABFfbXsA5THxJXfN=+m6wW=F8WRsWjhvP4LzM_tm1UFb3mW=Yw@mail.gmail.com>
References: <CAAjq1md_zS1JUDp1-OM2dUwHWm6fDedOe1Eq9uwyFTRy8F-UUw@mail.gmail.com>
	<CABFfbXsA5THxJXfN=+m6wW=F8WRsWjhvP4LzM_tm1UFb3mW=Yw@mail.gmail.com>
Message-ID: <CAAjq1mdY5eWS-9ASHLxWBgW=ohj5CxkLpHs_OTMWR7hAh-8cbQ@mail.gmail.com>

Jeroen, my sincere apologies.

Having read http://www.r-project.org/posting-guide.html I had
determined that my question was specifically "discussion about code
development in R" and was not in the realm of those who "want to use R
to solve problems but who are not necessarily interested in or
knowledgeable about programming".

As such, I posted it here.

Where did I go wrong?

Thanks for letting me know on both parts and have a great day.
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Sun, Aug 10, 2014 at 1:14 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> On Sun, Aug 10, 2014 at 7:22 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>>
>> ? Error in gcr$original.require(...) <- require :
>> ?   '...' used in an incorrect context
>
> I think you mean: gcr$original.require <- base::require. You don't
> need the parentheses since you are not defining or calling a function.
> You are simply assigning an object to another environment.
>
> Basic questions about R usage/syntax like these are better suited for
> the r-help list or stack-overflow. Have a look at:
> https://stat.ethz.ch/mailman/listinfo/r-devel.


From winstonchang1 at gmail.com  Mon Aug 11 03:46:59 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Sun, 10 Aug 2014 20:46:59 -0500
Subject: [Rd] Error when assigning value in environment which is a locked
	binding
Message-ID: <CAFOpNVFrbLFjv0xf78bLfx_Q5e6K4REFX=zxysLTKuQLJbxxmQ@mail.gmail.com>

If an environment x contains a locked binding y which is also an
environment, and then you try to assign a value to a binding inside of
y, it can either succeed or fail, depending on how you refer to
environment y.

x <- new.env()
x$y <- new.env()
lockEnvironment(x, bindings = TRUE)

# This assignment fails
x$y$z <- 1
# Error in x$y$z <- 1 : cannot change value of locked binding for 'y'

# Saving x$y to another variable, and then assigning there works
y2 <- x$y
y2$z <- 10  # OK
print(x$y$z)
# 10


Is this a bug or a feature? I realize that x$y is a locked binding
while y2 is not.

-Winston


From winstonchang1 at gmail.com  Mon Aug 11 04:07:24 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Sun, 10 Aug 2014 21:07:24 -0500
Subject: [Rd] Error when assigning value in environment which is a
	locked binding
In-Reply-To: <CAFOpNVFrbLFjv0xf78bLfx_Q5e6K4REFX=zxysLTKuQLJbxxmQ@mail.gmail.com>
References: <CAFOpNVFrbLFjv0xf78bLfx_Q5e6K4REFX=zxysLTKuQLJbxxmQ@mail.gmail.com>
Message-ID: <CAFOpNVE7KT=FaxxLN2VyP=jMp9B1C9DVs4EcdTTJp0GKRtkjUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140810/f6ae566a/attachment.pl>

From pdalgd at gmail.com  Mon Aug 11 15:31:49 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Aug 2014 15:31:49 +0200
Subject: [Rd] Compilation problems
In-Reply-To: <1398961407595816@web25m.yandex.ru>
References: <1398961407595816@web25m.yandex.ru>
Message-ID: <977D8F42-E3A5-442E-A914-CEF709D1728F@gmail.com>


On 09 Aug 2014, at 16:50 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:

>> Worst case is that you'll have to install TeX in your local user directory.
> 
> I'll try to find it again. The search I tried didn't look as easy, very few results, none helpful. And if I could install *just the fonts* on my local dir, instead of the full TeX, it would be perfect. But I don't know how to do it. Is it possi


If you are playing with the R-devel branch (or rather, trunk), then just hold your horses for a little while. There seems to be a reversed-logic bug that bites if you have inconsolata.sty and not zi4.sty.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From andrezda10 at yandex.com  Mon Aug 11 15:46:26 2014
From: andrezda10 at yandex.com (=?utf-8?B?QW5kcsOpIFouIEQuIEEu?=)
Date: Mon, 11 Aug 2014 10:46:26 -0300
Subject: [Rd] Compilation problems
Message-ID: <1351701407764786@web25m.yandex.ru>

No, Peter, I have the "(2014-07-10, Sock it to Me) R-3.1.1.tar.gz" source. Thanks for pointing it. So (I hope) it should be ok. Right?


-------- Peter Dalgaard, Professor wrote:
> If you are playing with the R-devel branch (or rather, trunk), then just hold
> your horses for a little while. There seems to be a reversed-logic bug that
> bites if you have inconsolata.sty and not zi4.sty.


From maechler at stat.math.ethz.ch  Mon Aug 11 16:26:54 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 Aug 2014 16:26:54 +0200
Subject: [Rd] RFC: diag(x, n)  not preserving integer and logical x
In-Reply-To: <53E4E3DE.8050001@gmail.com>
References: <21475.15911.157158.65610@stat.math.ethz.ch>
	<53E4E3DE.8050001@gmail.com>
Message-ID: <21480.53934.34861.185682@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Fri, 8 Aug 2014 10:51:10 -0400 writes:

Thank you, Duncan (read inline) 

    > On 07/08/2014, 4:51 AM, Martin Maechler wrote:
    >> This is not at all something new(*). As maintainer of the
    >> Matrix package, I don't like this inconsistency of base
    >> R's diag().  We have had the following -- forever, almost
    >> surely inherited from S and S+ :
    >> 
    >> diag(x) preserves the storage mode of x for 'complex' and
    >> 'double' precision, but converts integer and logicals to
    >> double :
    >> 
    >> > storage.mode(x <- 1i + 1:7); storage.mode(diag(x)) [1]
    >> "complex" [1] "complex" > storage.mode(x <- 0 + 1:7);
    >> storage.mode(diag(x)) [1] "double" [1] "double"
    >> 
    >> > storage.mode(x <- 1:7); storage.mode(diag(x)) [1]
    >> "integer" [1] "double" > storage.mode(x <- 1:7 > 3);
    >> storage.mode(diag(x)) [1] "logical" [1] "double"
    >> 
    >> and so it is actually a bit cumbersome (and a memory
    >> waste in the case of large matrices) to create a diagonal
    >> integer or logical matrix.
    >> 
    >> The help page does not mention the current behavior,
    >> though you may say it alludes to the fact that logicals
    >> are treated as 0/1 implicitly (**)
    >> 

    > I think the change to preserve integer makes sense, but
    > preserving logical does not.  A diagonal matrix has zeros
    > off the diagonal, and they are not logical.  

That's true if you come from the usual mathematical thinking
about matrices; and the same would extend to triangular
matrices, too.

In (S and) R however, matrices and array()s have always been
more general than in applied math (and have allowed any atomic (and even
more general) content).

    > Having diag() sometimes return a matrix with FALSE off the diagonal just
    > looks wrong.

[... if you have never seen them ..]
OTOH, sparse matrices (in the Matrix package) and also sparse
and dense triangular matrices (all with their classes) have
always (in the Matrix package) had their logical counter parts,

  > Diagonal(5)
  5 x 5 diagonal matrix of class "ddiMatrix"
       [,1] [,2] [,3] [,4] [,5]
  [1,]    1    .    .    .    .
  [2,]    .    1    .    .    .
  [3,]    .    .    1    .    .
  [4,]    .    .    .    1    .
  [5,]    .    .    .    .    1
  > Diagonal(5) > 0
  5 x 5 diagonal matrix of class "ldiMatrix"
       [,1] [,2] [,3] [,4] [,5]
  [1,] TRUE    .    .    .    .
  [2,]    . TRUE    .    .    .
  [3,]    .    . TRUE    .    .
  [4,]    .    .    . TRUE    .
  [5,]    .    .    .    . TRUE
  > 

and if you consider any sparseness for logical matrices, typical
application cases would have the TRUE to be rare rather than the
FALSE... and then of course, we have had the  as.numeric(<logical>)
behavior of S and R, all this leading to 
the usual  FALSE <==> 0  mapping 


    >> If I change this behavior such that logical and integer x
    >> are preserved,
    >> 
    >> make check-all
    >> 
    >> which includes all checks, including those of all
    >> recommended packages (including Matrix!) successfully
    >> runs through; so at least base + Recommended R never
    >> relies on the current behavior, nor should any "well
    >> programmed" R code ...
    >> 
    >> Hence my proposal, somewhat tentative for now, to change
    >> this diag(.) behavior.
    >> 
    >> Martin Maechler
    >> 
    >> *) and possibly something we "can not" change in R,
    >> because too much code implicitely may be depending on it,
    >> but now I hope we can still...
    >> 
    >> **) BTW, also including the somewhat amusing case of
    >> diag(c("A","B")).
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>


From pdalgd at gmail.com  Mon Aug 11 16:49:08 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Aug 2014 16:49:08 +0200
Subject: [Rd] Compilation problems
In-Reply-To: <1351701407764786@web25m.yandex.ru>
References: <1351701407764786@web25m.yandex.ru>
Message-ID: <4FB8F35C-AE2F-4A86-9CC7-046315F9C2D5@gmail.com>


On 11 Aug 2014, at 15:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:

> No, Peter, I have the "(2014-07-10, Sock it to Me) R-3.1.1.tar.gz" source. Thanks for pointing it. So (I hope) it should be ok. Right?

Not unlikely. (I goofed and thought that it only affected the development version.)

Check 

kpsewhich inconsolata.sty

if it is found, and zi4.sty is not, then it should be fixed by an upcoming patch release.

-pd

> 
> 
> -------- Peter Dalgaard, Professor wrote:
>> If you are playing with the R-devel branch (or rather, trunk), then just hold
>> your horses for a little while. There seems to be a reversed-logic bug that
>> bites if you have inconsolata.sty and not zi4.sty.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Mon Aug 11 16:41:30 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 11 Aug 2014 10:41:30 -0400
Subject: [Rd] Error when assigning value in environment which is a
	locked binding
In-Reply-To: <CAFOpNVE7KT=FaxxLN2VyP=jMp9B1C9DVs4EcdTTJp0GKRtkjUA@mail.gmail.com>
References: <CAFOpNVFrbLFjv0xf78bLfx_Q5e6K4REFX=zxysLTKuQLJbxxmQ@mail.gmail.com>
	<CAFOpNVE7KT=FaxxLN2VyP=jMp9B1C9DVs4EcdTTJp0GKRtkjUA@mail.gmail.com>
Message-ID: <0DF7F806-5F58-4D3D-A60D-3438ECD61F4D@r-project.org>


On Aug 10, 2014, at 10:07 PM, Winston Chang <winstonchang1 at gmail.com> wrote:

> Another oddity - even though there's an error thrown in assignment to
> x$y$z, the assignment succeeds.
> 
> x <- new.env()
> x$y <- new.env()
> lockEnvironment(x, bindings = TRUE)
> x$y$z <- 1
> # Error in x$y$z <- 1 : cannot change value of locked binding for 'y'
> 
> x$y$z
> # [1] 1
> 
> 
> So I assume there must be a bug somewhere in here.
> 

Why?

In both cases (including your previous post) the you have two separate assignments: (x$y)$z <-1 followed by x$y <- y. So the first one always succeeds since there is no reason for it not to, but the second one doesn't because the binding is locked. 

I presume the confusion comes from the fact that environments are mutable, so x$y changes even if it was not assigned so it's irrelevant if the second assignment succeeds or not.

Cheers,
Simon


> -Winston
> 
> 
> 
> On Sun, Aug 10, 2014 at 8:46 PM, Winston Chang <winstonchang1 at gmail.com>
> wrote:
> 
>> If an environment x contains a locked binding y which is also an
>> environment, and then you try to assign a value to a binding inside of
>> y, it can either succeed or fail, depending on how you refer to
>> environment y.
>> 
>> x <- new.env()
>> x$y <- new.env()
>> lockEnvironment(x, bindings = TRUE)
>> 
>> # This assignment fails
>> x$y$z <- 1
>> # Error in x$y$z <- 1 : cannot change value of locked binding for 'y'
>> 
>> # Saving x$y to another variable, and then assigning there works
>> y2 <- x$y
>> y2$z <- 10  # OK
>> print(x$y$z)
>> # 10
>> 
>> 
>> Is this a bug or a feature? I realize that x$y is a locked binding
>> while y2 is not.
>> 
>> -Winston
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From wdunlap at tibco.com  Mon Aug 11 17:43:18 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Aug 2014 08:43:18 -0700
Subject: [Rd] RFC: diag(x, n) not preserving integer and logical x
In-Reply-To: <21480.53934.34861.185682@stat.math.ethz.ch>
References: <21475.15911.157158.65610@stat.math.ethz.ch>
	<53E4E3DE.8050001@gmail.com>
	<21480.53934.34861.185682@stat.math.ethz.ch>
Message-ID: <CAF8bMcb6+=_uRg_bYSKQ9hx6TjkjVy7aByj=uL1XE59rGx3z4A@mail.gmail.com>

Would you allow a list argument to diag() as well?  I see that
Matrix::Diagonal does not accept it.  Perhaps nothing in Matrix deals
with matrices of lists, but they are handy and for diag() it may be
simpler to allow lists than to check for and reject them.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 11, 2014 at 7:26 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Fri, 8 Aug 2014 10:51:10 -0400 writes:
>
> Thank you, Duncan (read inline)
>
>     > On 07/08/2014, 4:51 AM, Martin Maechler wrote:
>     >> This is not at all something new(*). As maintainer of the
>     >> Matrix package, I don't like this inconsistency of base
>     >> R's diag().  We have had the following -- forever, almost
>     >> surely inherited from S and S+ :
>     >>
>     >> diag(x) preserves the storage mode of x for 'complex' and
>     >> 'double' precision, but converts integer and logicals to
>     >> double :
>     >>
>     >> > storage.mode(x <- 1i + 1:7); storage.mode(diag(x)) [1]
>     >> "complex" [1] "complex" > storage.mode(x <- 0 + 1:7);
>     >> storage.mode(diag(x)) [1] "double" [1] "double"
>     >>
>     >> > storage.mode(x <- 1:7); storage.mode(diag(x)) [1]
>     >> "integer" [1] "double" > storage.mode(x <- 1:7 > 3);
>     >> storage.mode(diag(x)) [1] "logical" [1] "double"
>     >>
>     >> and so it is actually a bit cumbersome (and a memory
>     >> waste in the case of large matrices) to create a diagonal
>     >> integer or logical matrix.
>     >>
>     >> The help page does not mention the current behavior,
>     >> though you may say it alludes to the fact that logicals
>     >> are treated as 0/1 implicitly (**)
>     >>
>
>     > I think the change to preserve integer makes sense, but
>     > preserving logical does not.  A diagonal matrix has zeros
>     > off the diagonal, and they are not logical.
>
> That's true if you come from the usual mathematical thinking
> about matrices; and the same would extend to triangular
> matrices, too.
>
> In (S and) R however, matrices and array()s have always been
> more general than in applied math (and have allowed any atomic (and even
> more general) content).
>
>     > Having diag() sometimes return a matrix with FALSE off the diagonal just
>     > looks wrong.
>
> [... if you have never seen them ..]
> OTOH, sparse matrices (in the Matrix package) and also sparse
> and dense triangular matrices (all with their classes) have
> always (in the Matrix package) had their logical counter parts,
>
>   > Diagonal(5)
>   5 x 5 diagonal matrix of class "ddiMatrix"
>        [,1] [,2] [,3] [,4] [,5]
>   [1,]    1    .    .    .    .
>   [2,]    .    1    .    .    .
>   [3,]    .    .    1    .    .
>   [4,]    .    .    .    1    .
>   [5,]    .    .    .    .    1
>   > Diagonal(5) > 0
>   5 x 5 diagonal matrix of class "ldiMatrix"
>        [,1] [,2] [,3] [,4] [,5]
>   [1,] TRUE    .    .    .    .
>   [2,]    . TRUE    .    .    .
>   [3,]    .    . TRUE    .    .
>   [4,]    .    .    . TRUE    .
>   [5,]    .    .    .    . TRUE
>   >
>
> and if you consider any sparseness for logical matrices, typical
> application cases would have the TRUE to be rare rather than the
> FALSE... and then of course, we have had the  as.numeric(<logical>)
> behavior of S and R, all this leading to
> the usual  FALSE <==> 0  mapping
>
>
>     >> If I change this behavior such that logical and integer x
>     >> are preserved,
>     >>
>     >> make check-all
>     >>
>     >> which includes all checks, including those of all
>     >> recommended packages (including Matrix!) successfully
>     >> runs through; so at least base + Recommended R never
>     >> relies on the current behavior, nor should any "well
>     >> programmed" R code ...
>     >>
>     >> Hence my proposal, somewhat tentative for now, to change
>     >> this diag(.) behavior.
>     >>
>     >> Martin Maechler
>     >>
>     >> *) and possibly something we "can not" change in R,
>     >> because too much code implicitely may be depending on it,
>     >> but now I hope we can still...
>     >>
>     >> **) BTW, also including the somewhat amusing case of
>     >> diag(c("A","B")).
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From radford at cs.toronto.edu  Mon Aug 11 19:48:25 2014
From: radford at cs.toronto.edu (Radford Neal)
Date: Mon, 11 Aug 2014 13:48:25 -0400
Subject: [Rd] diag(x, n) not preserving integer and logical x
Message-ID: <20140811174825.GA2543@cs.toronto.edu>

Martin Maechler wrote:
> diag(x) preserves the storage mode of x  for  'complex' and
> 'double' precision,  but converts integer and logicals to double :

Duncan Murdoch wrote:
> I think the change to preserve integer makes sense, but preserving
> logical does not.  A diagonal matrix has zeros off the diagonal, and
> they are not logical.  Having diag() sometimes return a matrix with
> FALSE off the diagonal just looks wrong.

Making diag(1:10) return an integer matrix does make sense, but it
could still be undesirable.  Often, the user will have intended to
get a real matrix, and will after another operation, but only after an
unnecessary coercion is done. For example: x<-diag(1:10); x[1,2]<-2.0

I personally think keeping diag(1:10) integer is best, but I thought 
I'd point out the contrary argument.

Having diag(rep(TRUE,10)) return a logical matrix with FALSE off the
diagonal does not strike me as too odd.  It makes sense if you think
of (FALSE, TRUE) as forming a field under operations of sum=XOR and
product=AND.  And of course it will typically be converted to a 0/1
matrix later if that's what was actually intended.

   Radford Neal


From sleepingwell at gmail.com  Tue Aug 12 08:29:52 2014
From: sleepingwell at gmail.com (Simon Knapp)
Date: Tue, 12 Aug 2014 16:29:52 +1000
Subject: [Rd] Define 'in' for new class
Message-ID: <CAA+5f=1yhAbDL9ndk75A88UrBujFZ1DdfY7Q0AO1OODH6-zeZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140812/32f7e133/attachment.pl>

From pdalgd at gmail.com  Tue Aug 12 09:28:05 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Aug 2014 09:28:05 +0200
Subject: [Rd] Define 'in' for new class
In-Reply-To: <CAA+5f=1yhAbDL9ndk75A88UrBujFZ1DdfY7Q0AO1OODH6-zeZA@mail.gmail.com>
References: <CAA+5f=1yhAbDL9ndk75A88UrBujFZ1DdfY7Q0AO1OODH6-zeZA@mail.gmail.com>
Message-ID: <4C06649A-38B1-47B3-9B7D-F5F0D2393E16@gmail.com>


On 12 Aug 2014, at 08:29 , Simon Knapp <sleepingwell at gmail.com> wrote:

> Hi List,
> 
> Is it possible to define how 'in' works for an object of a specific class
> (to achieve a similar result to implementing the iterator protocol in a
> class Python)?
> 

No, because 'in' doesn't really exist, it is "syntactic sugar" to sweeten a call to the "for" function with its three arguments. E.g.

> `for`(i,1:2,print(i))
[1] 1
[1] 2

So what you're really asking for is something like a `for` with class dispatch or the two first arguments replaced by an iterator mechanism. That's not in the cards, at least at the moment, but I suppose it isn't completely out of the question either -- ideas of this sort get bandied around occasionally. It would require changes to R's internals; it is not something you can do in (say) a package.


> Cheers,
> Simon Knapp
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Tue Aug 12 15:47:01 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Aug 2014 09:47:01 -0400
Subject: [Rd] RFC: diag(x, n)  not preserving integer and logical x
In-Reply-To: <21480.53934.34861.185682@stat.math.ethz.ch>
References: <21475.15911.157158.65610@stat.math.ethz.ch>	<53E4E3DE.8050001@gmail.com>
	<21480.53934.34861.185682@stat.math.ethz.ch>
Message-ID: <53EA1AD5.1000808@gmail.com>

On 11/08/2014, 10:26 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Fri, 8 Aug 2014 10:51:10 -0400 writes:
> 
> Thank you, Duncan (read inline) 
> 
>     > On 07/08/2014, 4:51 AM, Martin Maechler wrote:
>     >> This is not at all something new(*). As maintainer of the
>     >> Matrix package, I don't like this inconsistency of base
>     >> R's diag().  We have had the following -- forever, almost
>     >> surely inherited from S and S+ :
>     >> 
>     >> diag(x) preserves the storage mode of x for 'complex' and
>     >> 'double' precision, but converts integer and logicals to
>     >> double :
>     >> 
>     >> > storage.mode(x <- 1i + 1:7); storage.mode(diag(x)) [1]
>     >> "complex" [1] "complex" > storage.mode(x <- 0 + 1:7);
>     >> storage.mode(diag(x)) [1] "double" [1] "double"
>     >> 
>     >> > storage.mode(x <- 1:7); storage.mode(diag(x)) [1]
>     >> "integer" [1] "double" > storage.mode(x <- 1:7 > 3);
>     >> storage.mode(diag(x)) [1] "logical" [1] "double"
>     >> 
>     >> and so it is actually a bit cumbersome (and a memory
>     >> waste in the case of large matrices) to create a diagonal
>     >> integer or logical matrix.
>     >> 
>     >> The help page does not mention the current behavior,
>     >> though you may say it alludes to the fact that logicals
>     >> are treated as 0/1 implicitly (**)
>     >> 
> 
>     > I think the change to preserve integer makes sense, but
>     > preserving logical does not.  A diagonal matrix has zeros
>     > off the diagonal, and they are not logical.  
> 
> That's true if you come from the usual mathematical thinking
> about matrices; and the same would extend to triangular
> matrices, too.

I'm not objecting to having a logical matrix, I'm objecting to saying
that a matrix with FALSE off the diagonal is a diagonal matrix.  A
diagonal matrix is one with zeros off the diagonal.

> 
> In (S and) R however, matrices and array()s have always been
> more general than in applied math (and have allowed any atomic (and even
> more general) content).
> 
>     > Having diag() sometimes return a matrix with FALSE off the diagonal just
>     > looks wrong.
> 
> [... if you have never seen them ..]
> OTOH, sparse matrices (in the Matrix package) and also sparse
> and dense triangular matrices (all with their classes) have
> always (in the Matrix package) had their logical counter parts,
> 
>   > Diagonal(5)
>   5 x 5 diagonal matrix of class "ddiMatrix"
>        [,1] [,2] [,3] [,4] [,5]
>   [1,]    1    .    .    .    .
>   [2,]    .    1    .    .    .
>   [3,]    .    .    1    .    .
>   [4,]    .    .    .    1    .
>   [5,]    .    .    .    .    1
>   > Diagonal(5) > 0
>   5 x 5 diagonal matrix of class "ldiMatrix"
>        [,1] [,2] [,3] [,4] [,5]
>   [1,] TRUE    .    .    .    .
>   [2,]    . TRUE    .    .    .
>   [3,]    .    . TRUE    .    .
>   [4,]    .    .    . TRUE    .
>   [5,]    .    .    .    . TRUE

That is completely different, and I have no objection to it.  Where I
would have an objection is if you got that result from

diag(rep(TRUE, 5))

or

Diagonal(rep(TRUE, 5))

Duncan Murdoch

>   > 
> 
> and if you consider any sparseness for logical matrices, typical
> application cases would have the TRUE to be rare rather than the
> FALSE... and then of course, we have had the  as.numeric(<logical>)
> behavior of S and R, all this leading to 
> the usual  FALSE <==> 0  mapping 
> 
> 
>     >> If I change this behavior such that logical and integer x
>     >> are preserved,
>     >> 
>     >> make check-all
>     >> 
>     >> which includes all checks, including those of all
>     >> recommended packages (including Matrix!) successfully
>     >> runs through; so at least base + Recommended R never
>     >> relies on the current behavior, nor should any "well
>     >> programmed" R code ...
>     >> 
>     >> Hence my proposal, somewhat tentative for now, to change
>     >> this diag(.) behavior.
>     >> 
>     >> Martin Maechler
>     >> 
>     >> *) and possibly something we "can not" change in R,
>     >> because too much code implicitely may be depending on it,
>     >> but now I hope we can still...
>     >> 
>     >> **) BTW, also including the somewhat amusing case of
>     >> diag(c("A","B")).
>     >> 
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> 
>


From pdalgd at gmail.com  Tue Aug 12 16:15:36 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Aug 2014 16:15:36 +0200
Subject: [Rd] Compilation problems
In-Reply-To: <4FB8F35C-AE2F-4A86-9CC7-046315F9C2D5@gmail.com>
References: <1351701407764786@web25m.yandex.ru>
	<4FB8F35C-AE2F-4A86-9CC7-046315F9C2D5@gmail.com>
Message-ID: <04BA8608-D0EF-4F17-B859-AF4051E787E1@gmail.com>


On 11 Aug 2014, at 16:49 , peter dalgaard <pdalgd at gmail.com> wrote:

> 
> On 11 Aug 2014, at 15:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:
> 
>> No, Peter, I have the "(2014-07-10, Sock it to Me) R-3.1.1.tar.gz" source. Thanks for pointing it. So (I hope) it should be ok. Right?
> 
> Not unlikely. (I goofed and thought that it only affected the development version.)
> 
> Check 
> 
> kpsewhich inconsolata.sty
> 
> if it is found, and zi4.sty is not, then it should be fixed by an upcoming patch release.


... and for a quick fix, edit the configure script. There is a section looking like this

if test -n "${KPSEWHICH}"; then
  ${KPSEWHICH} zi4.sty > /dev/null
  if test $? -eq 0; then
     { $as_echo "$as_me:${as_lineno-$LINENO}: result: found zi4.sty" >&5
$as_echo "found zi4.sty" >&6; }
  else
    ${KPSEWHICH} inconsolata.sty > /dev/null
    if test $? -ne 0; then
      { $as_echo "$as_me:${as_lineno-$LINENO}: result: found inconsolata.sty" >&5

(Search for "incons" and you'll get there.) 

Change the -ne in the penultimate line to -eq and rerun configure. This isn't the correct fix because configure is autogenerated from other files, but it should get you going.

-pd

> 
> -pd
> 
>> 
>> 
>> -------- Peter Dalgaard, Professor wrote:
>>> If you are playing with the R-devel branch (or rather, trunk), then just hold
>>> your horses for a little while. There seems to be a reversed-logic bug that
>>> bites if you have inconsolata.sty and not zi4.sty.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Tue Aug 12 16:30:43 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Aug 2014 07:30:43 -0700
Subject: [Rd] Define 'in' for new class
In-Reply-To: <4C06649A-38B1-47B3-9B7D-F5F0D2393E16@gmail.com>
References: <CAA+5f=1yhAbDL9ndk75A88UrBujFZ1DdfY7Q0AO1OODH6-zeZA@mail.gmail.com>
	<4C06649A-38B1-47B3-9B7D-F5F0D2393E16@gmail.com>
Message-ID: <CACk-te3FNEABxBaB-4r_A5K3yNw=8UFXBCD_QAdJ6YPMVJPkKw@mail.gmail.com>

See the 'iterators' package on CRAN.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Aug 12, 2014 at 12:28 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On 12 Aug 2014, at 08:29 , Simon Knapp <sleepingwell at gmail.com> wrote:
>
>> Hi List,
>>
>> Is it possible to define how 'in' works for an object of a specific class
>> (to achieve a similar result to implementing the iterator protocol in a
>> class Python)?
>>
>
> No, because 'in' doesn't really exist, it is "syntactic sugar" to sweeten a call to the "for" function with its three arguments. E.g.
>
>> `for`(i,1:2,print(i))
> [1] 1
> [1] 2
>
> So what you're really asking for is something like a `for` with class dispatch or the two first arguments replaced by an iterator mechanism. That's not in the cards, at least at the moment, but I suppose it isn't completely out of the question either -- ideas of this sort get bandied around occasionally. It would require changes to R's internals; it is not something you can do in (say) a package.
>
>
>> Cheers,
>> Simon Knapp
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Max.Kuhn at pfizer.com  Tue Aug 12 18:24:20 2014
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Tue, 12 Aug 2014 16:24:20 +0000
Subject: [Rd] Looking for new maintainer of orphans R2HTML SemiPar
 cghseg hexbin lgtdl monreg muhaz operators pamr
In-Reply-To: <53E4FDA9.70903@R-project.org>
References: <53E4FDA9.70903@R-project.org>
Message-ID: <D00FB734.283EE%max.kuhn@pfizer.com>

Uwe,

Thanks for the email. What is the expected data that pamr will be off the
main CRAN package list? I don't want to maintain that package but I have
an old, independent implementation of that classifier that I can include
in caret. 

Thanks again,

Max

On 8/8/14 12:41 PM, "Uwe Ligges" <Uwe.Ligges at R-project.org> wrote:

>Dear maintainers and R-devel,
>
>Several orphaned CRAN packages are about to be archived due to
>outstanding QC problems, but have CRAN and BioC packages depending on
>them which would be broken by the archival (and hence need archiving
>alongside).
>Therefore we are looking for new maintainers taking over maintainership
>for one or more of the following packages:
>
>R2HTML SemiPar cghseg hexbin lgtdl monreg muhaz operators pamr
>
>Package maintainers whose packages depend on one of these may be natural
>candidates to become new maintainers.
>Hence this messages is addressed to all these maintainers via BCC and to
>R-devel.
>
>See
>
>   <http://CRAN.R-project.org/package=R2HTML>
>   <http://CRAN.R-project.org/package=SemiPar>
>   <http://CRAN.R-project.org/package=cghseg>
>   <http://CRAN.R-project.org/package=hexbin>
>   <http://CRAN.R-project.org/package=lgtdl>
>   <http://CRAN.R-project.org/package=monreg>
>   <http://CRAN.R-project.org/package=muhaz>
>   <http://CRAN.R-project.org/package=operators>
>   <http://CRAN.R-project.org/package=pamr>
>
>for information on the QC issues and the reverse dependencies.
>
>Best wishes,
>Uwe Ligges
>(for the CRAN team)


From ligges at statistik.tu-dortmund.de  Tue Aug 12 22:58:44 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 12 Aug 2014 22:58:44 +0200
Subject: [Rd] Looking for new maintainer of orphans R2HTML SemiPar
 cghseg hexbin lgtdl monreg muhaz operators pamr
In-Reply-To: <D00FB734.283EE%max.kuhn@pfizer.com>
References: <53E4FDA9.70903@R-project.org> <D00FB734.283EE%max.kuhn@pfizer.com>
Message-ID: <53EA8004.6000702@statistik.tu-dortmund.de>



On 12.08.2014 18:24, Kuhn, Max wrote:
> Uwe,
>
> Thanks for the email. What is the expected data that pamr will be off the
> main CRAN package list? I don't want to maintain that package but I have
> an old, independent implementation of that classifier that I can include
> in caret.


We have found a volunteer taking over maintainership for pamr.

Best,
Uwe


> Thanks again,
>
> Max
>
> On 8/8/14 12:41 PM, "Uwe Ligges" <Uwe.Ligges at R-project.org> wrote:
>
>> Dear maintainers and R-devel,
>>
>> Several orphaned CRAN packages are about to be archived due to
>> outstanding QC problems, but have CRAN and BioC packages depending on
>> them which would be broken by the archival (and hence need archiving
>> alongside).
>> Therefore we are looking for new maintainers taking over maintainership
>> for one or more of the following packages:
>>
>> R2HTML SemiPar cghseg hexbin lgtdl monreg muhaz operators pamr
>>
>> Package maintainers whose packages depend on one of these may be natural
>> candidates to become new maintainers.
>> Hence this messages is addressed to all these maintainers via BCC and to
>> R-devel.
>>
>> See
>>
>>    <http://CRAN.R-project.org/package=R2HTML>
>>    <http://CRAN.R-project.org/package=SemiPar>
>>    <http://CRAN.R-project.org/package=cghseg>
>>    <http://CRAN.R-project.org/package=hexbin>
>>    <http://CRAN.R-project.org/package=lgtdl>
>>    <http://CRAN.R-project.org/package=monreg>
>>    <http://CRAN.R-project.org/package=muhaz>
>>    <http://CRAN.R-project.org/package=operators>
>>    <http://CRAN.R-project.org/package=pamr>
>>
>> for information on the QC issues and the reverse dependencies.
>>
>> Best wishes,
>> Uwe Ligges
>> (for the CRAN team)
>


From pdalgd at gmail.com  Wed Aug 13 11:15:24 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 13 Aug 2014 11:15:24 +0200
Subject: [Rd] Compilation problems
In-Reply-To: <2376271407919565@web30m.yandex.ru>
References: <2376271407919565@web30m.yandex.ru>
Message-ID: <85765E3D-DEE8-414A-94F3-1F8553226B4C@gmail.com>

Well, I didn't go there because I don't have a clue....

What I usually try in such circumstances is to Google the error message and see if any ideas crop up. Looks like it is common to several applications that use Java, so not likely an R issue per se.

I'd look into 

- how to provoke the error to occur without make
- what are your resource limits (ulimit -a  is your friend)?
- are any environment variables affecting the Java memory use? If not, perhaps you need to set them to values less than the max allowed. Or twiddle command line options.

etc.

-pd

On 13 Aug 2014, at 10:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:

> Thanks a lot for this atention, Peter. But the fonts problem is just a warning: "configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally". So, no worries. I can live with render errors for the manuals. :)
> 
> But the error I have with the 'make' is with Java. I don't know why. I even restarted the compilation again (the only detail I change is to pass "--prefix=/home/me/r/" to configure, to install it on my own folder instead of defaults). Then a "make" without arguments and it ends with this:
> 
> ---------------------------------------------------------
> configuring Java ...
> Java interpreter : /usr/bin/java
> Could not create the Java virtual machine.
> Error occurred during initialization of VM
> Could not reserve enough space for object heap
> 
> *** Java interpreter doesn't work properly.
> 
> make[1]: [stamp-java] Error 1 (ignored)
> make[1]: Leaving directory `/home/me/r-src-second-try/R-3.1.1'
> 
> ---------------------------------------------------------
> 
> 
> But how do anyone explain that onde a second run of 'make' it finished!? And on two more times it won't show the error again!
> 
> Lets try to run R. Done 'make install'... and then run... it works!
> 
> I'm lost. A bug? Something is not working as it should? What? Or is it fine??
> 
> Andre'
> 
> 
>> On 11 Aug 2014, at 16:49 , peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> On 11 Aug 2014, at 15:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:
>>> 
>>>> No, Peter, I have the "(2014-07-10, Sock it to Me) R-3.1.1.tar.gz" source. Thanks for pointing it. So (I hope) it should be ok. Right?
>>> 
>>> Not unlikely. (I goofed and thought that it only affected the development version.)
>>> 
>>> Check
>>> 
>>> kpsewhich inconsolata.sty
>>> 
>>> if it is found, and zi4.sty is not, then it should be fixed by an upcoming patch release.
>> 
>> ... and for a quick fix, edit the configure script. There is a section looking like this
>> 
>> if test -n "${KPSEWHICH}"; then
>> ${KPSEWHICH} zi4.sty > /dev/null
>> if test $? -eq 0; then
>> { $as_echo "$as_me:${as_lineno-$LINENO}: result: found zi4.sty" >&5
>> $as_echo "found zi4.sty" >&6; }
>> else
>> ${KPSEWHICH} inconsolata.sty > /dev/null
>> if test $? -ne 0; then
>> { $as_echo "$as_me:${as_lineno-$LINENO}: result: found inconsolata.sty" >&5
>> 
>> (Search for "incons" and you'll get there.)
>> 
>> Change the -ne in the penultimate line to -eq and rerun configure. This isn't the correct fix because configure is autogenerated from other files, but it should get you going.
>> 
>> -pd
>> 
>>> -pd
>>> 
>>>> -------- Peter Dalgaard, Professor wrote:
>>>> 
>>>>> If you are playing with the R-devel branch (or rather, trunk), then just hold
>>>>> your horses for a little while. There seems to be a reversed-logic bug that
>>>>> bites if you have inconsolata.sty and not zi4.sty.
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kirill.mueller at ivt.baug.ethz.ch  Wed Aug 13 12:51:41 2014
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?B?S2lyaWxsIE3DvGxsZXI=?=)
Date: Wed, 13 Aug 2014 12:51:41 +0200
Subject: [Rd] Request to review a patch for rpart
Message-ID: <53EB433D.5020101@ivt.baug.ethz.ch>

Dear list


For my work, it would be helpful if rpart worked seamlessly with an 
empty model:

library(rpart); rpart(formula=y~0, data=data.frame(y=factor(1:10)))

Currently, an unrelated error (originating from na.rpart) is thrown.

At some point in the near future, I'd like to release a package to CRAN 
which uses rpart and relies on that functionality. I have prepared a 
patch (minor modifications at three places, and a test) which I'd like 
to propose for inclusion in the next CRAN release of rpart. The patch 
can be reviewed at https://github.com/krlmlr/rpart/tree/empty-model, the 
files (based on the current CRAN release 4.1-8) can be downloaded from 
https://github.com/krlmlr/rpart/archive/empty-model.zip.

Thanks for your attention.


With kindest regards

Kirill M?ller


From rowe at muxspace.com  Wed Aug 13 14:10:15 2014
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Wed, 13 Aug 2014 08:10:15 -0400
Subject: [Rd] Compilation problems
In-Reply-To: <85765E3D-DEE8-414A-94F3-1F8553226B4C@gmail.com>
References: <2376271407919565@web30m.yandex.ru>
	<85765E3D-DEE8-414A-94F3-1F8553226B4C@gmail.com>
Message-ID: <7E170D2A-887B-4DAD-ABAC-AF26D3453A41@muxspace.com>

I would add it would be useful to know what system you are on and how much overall memory the machine has (not to mention how many other users are on the box). If you are on a linux variant, you can see installed memory by running: cat /proc/meminfo. You might also want to look at top to see how many resources are being used by you and others.

Regarding Java, if you had done a search for 'java xmx', you'd see that you can control the maximum heap size of the JVM using this option. [1]   So, if you know how much memory you have available on your system, then you can set this value to something lower and verify that you can start the JVM in isolation. As for specifics, I wouldn't know, since you didn't provide the JVM version you're using. Try java -version to give us specifics.

Brian

[1] http://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/jrdocs/refman/optionX.html

?????
Brian Lee Yung Rowe
Founder, Zato Novo
Professor, M.S. Data Analytics, CUNY




On Aug 13, 2014, at 5:15 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Well, I didn't go there because I don't have a clue....
> 
> What I usually try in such circumstances is to Google the error message and see if any ideas crop up. Looks like it is common to several applications that use Java, so not likely an R issue per se.
> 
> I'd look into 
> 
> - how to provoke the error to occur without make
> - what are your resource limits (ulimit -a  is your friend)?
> - are any environment variables affecting the Java memory use? If not, perhaps you need to set them to values less than the max allowed. Or twiddle command line options.
> 
> etc.
> 
> -pd
> 
> On 13 Aug 2014, at 10:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:
> 
>> Thanks a lot for this atention, Peter. But the fonts problem is just a warning: "configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF vignettes and package manuals will not be rendered optimally". So, no worries. I can live with render errors for the manuals. :)
>> 
>> But the error I have with the 'make' is with Java. I don't know why. I even restarted the compilation again (the only detail I change is to pass "--prefix=/home/me/r/" to configure, to install it on my own folder instead of defaults). Then a "make" without arguments and it ends with this:
>> 
>> ---------------------------------------------------------
>> configuring Java ...
>> Java interpreter : /usr/bin/java
>> Could not create the Java virtual machine.
>> Error occurred during initialization of VM
>> Could not reserve enough space for object heap
>> 
>> *** Java interpreter doesn't work properly.
>> 
>> make[1]: [stamp-java] Error 1 (ignored)
>> make[1]: Leaving directory `/home/me/r-src-second-try/R-3.1.1'
>> 
>> ---------------------------------------------------------
>> 
>> 
>> But how do anyone explain that onde a second run of 'make' it finished!? And on two more times it won't show the error again!
>> 
>> Lets try to run R. Done 'make install'... and then run... it works!
>> 
>> I'm lost. A bug? Something is not working as it should? What? Or is it fine??
>> 
>> Andre'
>> 
>> 
>>> On 11 Aug 2014, at 16:49 , peter dalgaard <pdalgd at gmail.com> wrote:
>>> 
>>>> On 11 Aug 2014, at 15:46 , Andr? Z. D. A. <andrezda10 at yandex.com> wrote:
>>>> 
>>>>> No, Peter, I have the "(2014-07-10, Sock it to Me) R-3.1.1.tar.gz" source. Thanks for pointing it. So (I hope) it should be ok. Right?
>>>> 
>>>> Not unlikely. (I goofed and thought that it only affected the development version.)
>>>> 
>>>> Check
>>>> 
>>>> kpsewhich inconsolata.sty
>>>> 
>>>> if it is found, and zi4.sty is not, then it should be fixed by an upcoming patch release.
>>> 
>>> ... and for a quick fix, edit the configure script. There is a section looking like this
>>> 
>>> if test -n "${KPSEWHICH}"; then
>>> ${KPSEWHICH} zi4.sty > /dev/null
>>> if test $? -eq 0; then
>>> { $as_echo "$as_me:${as_lineno-$LINENO}: result: found zi4.sty" >&5
>>> $as_echo "found zi4.sty" >&6; }
>>> else
>>> ${KPSEWHICH} inconsolata.sty > /dev/null
>>> if test $? -ne 0; then
>>> { $as_echo "$as_me:${as_lineno-$LINENO}: result: found inconsolata.sty" >&5
>>> 
>>> (Search for "incons" and you'll get there.)
>>> 
>>> Change the -ne in the penultimate line to -eq and rerun configure. This isn't the correct fix because configure is autogenerated from other files, but it should get you going.
>>> 
>>> -pd
>>> 
>>>> -pd
>>>> 
>>>>> -------- Peter Dalgaard, Professor wrote:
>>>>> 
>>>>>> If you are playing with the R-devel branch (or rather, trunk), then just hold
>>>>>> your horses for a little while. There seems to be a reversed-logic bug that
>>>>>> bites if you have inconsolata.sty and not zi4.sty.
>>>> 
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From btyner at gmail.com  Wed Aug 13 14:52:54 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 13 Aug 2014 08:52:54 -0400
Subject: [Rd] could not find function "anyNA" when building tools
 package in R 3.1.1
In-Reply-To: <53E4D89B.50702@gmail.com>
References: <53E4D89B.50702@gmail.com>
Message-ID: <53EB5FA6.4070706@gmail.com>

I figured out what I did wrong. The end of my $LDFLAGS contained
"-Wl,-rpath,/path/to/an/old/R/installation/lib64/R/lib" (which predated
anyNA) and I was also using --enable-R-shlib, so possibly related to
PR#15790 (I say possibly, because I was not using "make install-libR").


From jeroenooms at gmail.com  Wed Aug 13 15:58:44 2014
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 13 Aug 2014 15:58:44 +0200
Subject: [Rd] Compilation problems
In-Reply-To: <915151407574618@web19m.yandex.ru>
References: <915151407574618@web19m.yandex.ru>
Message-ID: <CABFfbXsqrSypnfiCHSuF3o+MRspmysGL3aY6OXx0_Czz2NjaEg@mail.gmail.com>

On Sat, Aug 9, 2014 at 10:56 AM, Andr? Z. D. A. <andrezda10 at yandex.com> wrote:
> Could not create the Java virtual machine.
> Error occurred during initialization of VM
> Could not reserve enough space for object heap

I have seen this error before when running java inside a vm container
(openvz, lxc) where the kernel does not give java permission to query
the amount of available memory, and hence java assumes it must be 0.
In these cases you need to manually set the MaxHeapSize by passing a
parameter to java, see:
http://stackoverflow.com/questions/4401396/could-not-reserve-enough-space-for-object-heap.

I am not sure where in the compilation that java gets invoked, and if
there is a way to pass parameters. Perhaps you can use the
_JAVA_OPTIONS environment variable.


From kirill.mueller at ivt.baug.ethz.ch  Wed Aug 13 16:24:41 2014
From: kirill.mueller at ivt.baug.ethz.ch (=?windows-1252?Q?Kirill_M=FCller?=)
Date: Wed, 13 Aug 2014 16:24:41 +0200
Subject: [Rd] UTC time zone on Windows
In-Reply-To: <53E2C504.8030605@ivt.baug.ethz.ch>
References: <53E2C504.8030605@ivt.baug.ethz.ch>
Message-ID: <53EB7529.2030304@ivt.baug.ethz.ch>

I have just replicated this in a fresh Windows 8.1 machine (x86), in 
both R 3.1.1 and R-devel. I have attached a screenshot.


Cheers

Kirill



On 08/07/2014 02:15 AM, Kirill M?ller wrote:
> Hi
>
>
> I'm having trouble running R CMD build and check with UTC time zone 
> setting in Windows Server 2012. I can't seem to get rid of the 
> following warning:
>
>   unable to identify current timezone 'C':
> please set environment variable 'TZ'
>
> However, setting TZ to either "Europe/London" or "GMT Standard Time" 
> didn't help.
>
> It seems to me that the warning originates in registryTZ.c 
> (https://github.com/wch/r-source/blob/776708efe6003e36f02587ad47b2eaaaa19e2f69/src/extra/tzone/registryTZ.c#L363). 
> I have therefore looked at 
> HKLM\SYSTEM\CurrentControlSet\Control\TimeZoneInformation, to learn 
> that TimeZoneKeyName is set to "UTC". This time zone is not defined in 
> TZtable, but is present in this machine's 
> HKLM\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Time Zones. (Also, 
> the text of the warning permits the possibility that only the first 
> character of the time zone is used for the warning message -- in the 
> code, a const wchar_t* is used for a %s placeholder.)
>
> Below is a link to the log of such a failing run. The first 124 lines 
> are registry dumps, output of R CMD * is near the end of the log at 
> lines 212 and 224.
>
> https://ci.appveyor.com/project/krlmlr/r-appveyor/build/1.0.36
>
> This happens with R 3.1.1 and R-devel r66309.
>
> Is there a workaround I have missed, short of updating TZtable? How 
> can I help updating TZtable? Thanks!
>
>
> Cheers
>
> Kirill
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2014-08-13 16:23:16.png
Type: image/png
Size: 143198 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20140813/1e451beb/attachment.png>

From michael.haupt at oracle.com  Thu Aug 14 19:57:38 2014
From: michael.haupt at oracle.com (Michael Haupt)
Date: Thu, 14 Aug 2014 10:57:38 -0700
Subject: [Rd] `*tmp*`
Message-ID: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>

Hello,

given that `*tmp*` is removed after a replacement, how can code like this work? Is there some special handling for a variable named `*tmp*` when it comes to make element assignments?

> x<-c(1,2)
> x[1]<-42
> `*tmp*`[1]<-7 # I would expect this one to fail
> `*tmp*`
Error: object '*tmp*' not found

Confused greetings,

Michael

-- 
Dr. Michael Haupt
Principal Member of Technical Staff
Phone: +49 331 200 7277, Fax: +49 331 200 7561
Oracle Labs
Oracle Deutschland B.V. & Co. KG, Schiffbauergasse 14, 14467 Potsdam, Germany


From luke-tierney at uiowa.edu  Thu Aug 14 21:08:30 2014
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 14 Aug 2014 14:08:30 -0500
Subject: [Rd] `*tmp*`
In-Reply-To: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>
References: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>
Message-ID: <alpine.DEB.2.02.1408141406320.2519@luke-Latitude>

On Thu, 14 Aug 2014, Michael Haupt wrote:

> Hello,
>
> given that `*tmp*` is removed after a replacement, how can code like this work? Is there some special handling for a variable named `*tmp*` when it comes to make element assignments?
>
>> x<-c(1,2)
>> x[1]<-42
>> `*tmp*`[1]<-7 # I would expect this one to fail
>> `*tmp*`
> Error: object '*tmp*' not found

This is a consequence of the tricks the interpreter implementation
currently plays to do complex assignments. Compiled code works
differently:

> library(compiler)
> cmpfun(function() {
+            x<-c(1,2)
+    x[1]<-42
+    `*tmp*`[1]<-7 # I would expect this one to fail
+ })()
Error in cmpfun(function() { : object '*tmp*' not found

luke

>
> Confused greetings,
>
> Michael
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From michael.haupt at oracle.com  Thu Aug 14 23:35:28 2014
From: michael.haupt at oracle.com (Michael Haupt)
Date: Thu, 14 Aug 2014 14:35:28 -0700
Subject: [Rd] `*tmp*`
In-Reply-To: <alpine.DEB.2.02.1408141406320.2519@luke-Latitude>
References: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>
	<alpine.DEB.2.02.1408141406320.2519@luke-Latitude>
Message-ID: <ED79E0D0-D4AD-4457-8AEB-DB053A6CDE82@oracle.com>

Hi Luke,

Am 14.08.2014 um 12:08 schrieb luke-tierney at uiowa.edu:
> This is a consequence of the tricks the interpreter implementation
> currently plays to do complex assignments. Compiled code works
> differently:
> 
>> library(compiler)
>> cmpfun(function() {
> +            x<-c(1,2)
> +    x[1]<-42
> +    `*tmp*`[1]<-7 # I would expect this one to fail
> + })()
> Error in cmpfun(function() { : object '*tmp*' not found

aha, thank you very much! So the behaviour of the AST and bytecode interpreters differ. Which one is authoritative? Can I cherry-pick? (I'll pick the bytecode interpreter's version if I may.)

Is there actually any code out there that *uses* `*tmp*` and would hence break if the bytecode interpreter was used? Is it encouraged to not directly access `*tmp*`?

I'm asking all these questions because, in FastR, we're currently quite closely mirroring the AST interpreter's behaviour for complex assignments - if this is not an absolute must-have, I'd be very happy about being able to apply a much leaner implementation instead.

Best,

Michael

-- 
Dr. Michael Haupt
Principal Member of Technical Staff
Phone: +49 331 200 7277, Fax: +49 331 200 7561
Oracle Labs
Oracle Deutschland B.V. & Co. KG, Schiffbauergasse 14, 14467 Potsdam, Germany


From axel.urbiz at gmail.com  Fri Aug 15 02:51:53 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 14 Aug 2014 20:51:53 -0400
Subject: [Rd] Package manual Tex file
Message-ID: <CAAyVsX+hr7PP7SdZeZif--nxnoZi5ncAM9Kk_ub_k7_WP78nXQ@mail.gmail.com>

Dear All,

My apologies if the question is ambiguous.

I can create the pdf manual from a package I've built from "R CMD check
fooPackage". Is there a way to get the Tex file for the package manual pdf?
Well, I presume there is Tex code "behind" a package manual pdf file. But
if so, how can I get it?

I'm on Mac OS.


Thanks,
Axel.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Aug 15 12:31:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Aug 2014 06:31:55 -0400
Subject: [Rd] Package manual Tex file
In-Reply-To: <CAAyVsX+hr7PP7SdZeZif--nxnoZi5ncAM9Kk_ub_k7_WP78nXQ@mail.gmail.com>
References: <CAAyVsX+hr7PP7SdZeZif--nxnoZi5ncAM9Kk_ub_k7_WP78nXQ@mail.gmail.com>
Message-ID: <53EDE19B.4060500@gmail.com>

On 14/08/2014, 8:51 PM, Axel Urbiz wrote:
> Dear All,
> 
> My apologies if the question is ambiguous.
> 
> I can create the pdf manual from a package I've built from "R CMD check
> fooPackage". Is there a way to get the Tex file for the package manual pdf?
> Well, I presume there is Tex code "behind" a package manual pdf file. But
> if so, how can I get it?
> 
> I'm on Mac OS.

In the shell, run

R CMD Rd2pdf --no-clean fooPackage

Duncan Murdoch


From gmbecker at ucdavis.edu  Fri Aug 15 18:44:52 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 15 Aug 2014 09:44:52 -0700
Subject: [Rd] Request to review a patch for rpart
In-Reply-To: <53EB433D.5020101@ivt.baug.ethz.ch>
References: <53EB433D.5020101@ivt.baug.ethz.ch>
Message-ID: <CADwqtCMSarZp9Pv3RcOa7qazDjGCN1sNtvimu_QRVE3WpK9XpA@mail.gmail.com>

Kirill,

Perhaps I'm just being obtuse, but what are you proposing rpart do in the
case of an empty model?  Return a "tree" that always guesses the most
common label, or doesn't guess at all (NA)? It doesn't seem like you'd need
rpart for either of those.

~G


On Wed, Aug 13, 2014 at 3:51 AM, Kirill M?ller <
kirill.mueller at ivt.baug.ethz.ch> wrote:

> Dear list
>
>
> For my work, it would be helpful if rpart worked seamlessly with an empty
> model:
>
> library(rpart); rpart(formula=y~0, data=data.frame(y=factor(1:10)))
>
> Currently, an unrelated error (originating from na.rpart) is thrown.
>
> At some point in the near future, I'd like to release a package to CRAN
> which uses rpart and relies on that functionality. I have prepared a patch
> (minor modifications at three places, and a test) which I'd like to propose
> for inclusion in the next CRAN release of rpart. The patch can be reviewed
> at https://github.com/krlmlr/rpart/tree/empty-model, the files (based on
> the current CRAN release 4.1-8) can be downloaded from
> https://github.com/krlmlr/rpart/archive/empty-model.zip.
>
> Thanks for your attention.
>
>
> With kindest regards
>
> Kirill M?ller
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From kirill.mueller at ivt.baug.ethz.ch  Fri Aug 15 19:55:00 2014
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?B?S2lyaWxsIE3DvGxsZXI=?=)
Date: Fri, 15 Aug 2014 19:55:00 +0200
Subject: [Rd] Request to review a patch for rpart
In-Reply-To: <CADwqtCMSarZp9Pv3RcOa7qazDjGCN1sNtvimu_QRVE3WpK9XpA@mail.gmail.com>
References: <53EB433D.5020101@ivt.baug.ethz.ch>
	<CADwqtCMSarZp9Pv3RcOa7qazDjGCN1sNtvimu_QRVE3WpK9XpA@mail.gmail.com>
Message-ID: <53EE4974.20908@ivt.baug.ethz.ch>

Gabriel


Thanks for your feedback. Indeed, I was not particularly clear here. The 
empty model is just a very special case in a more general setting. I'd 
have to work around this deficiency in my code -- sure I can do that, 
but I thought a generic solution should be possible. In particular, I'm 
using predict.rpart(..., type = "prob") -- this just reflects the 
observed relative frequencies.


Cheers

Kirill


On 08/15/2014 06:44 PM, Gabriel Becker wrote:
> Kirill,
>
> Perhaps I'm just being obtuse, but what are you proposing rpart do in 
> the case of an empty model?  Return a "tree" that always guesses the 
> most common label, or doesn't guess at all (NA)? It doesn't seem like 
> you'd need rpart for either of those.
>
> ~G
>
>
> On Wed, Aug 13, 2014 at 3:51 AM, Kirill M?ller 
> <kirill.mueller at ivt.baug.ethz.ch 
> <mailto:kirill.mueller at ivt.baug.ethz.ch>> wrote:
>
>     Dear list
>
>
>     For my work, it would be helpful if rpart worked seamlessly with
>     an empty model:
>
>     library(rpart); rpart(formula=y~0, data=data.frame(y=factor(1:10)))
>
>     Currently, an unrelated error (originating from na.rpart) is thrown.
>
>     At some point in the near future, I'd like to release a package to
>     CRAN which uses rpart and relies on that functionality. I have
>     prepared a patch (minor modifications at three places, and a test)
>     which I'd like to propose for inclusion in the next CRAN release
>     of rpart. The patch can be reviewed at
>     https://github.com/krlmlr/rpart/tree/empty-model, the files (based
>     on the current CRAN release 4.1-8) can be downloaded from
>     https://github.com/krlmlr/rpart/archive/empty-model.zip.
>
>     Thanks for your attention.
>
>
>     With kindest regards
>
>     Kirill M?ller
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From peter.meilstrup at gmail.com  Fri Aug 15 20:05:19 2014
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Fri, 15 Aug 2014 11:05:19 -0700
Subject: [Rd] `*tmp*`
In-Reply-To: <ED79E0D0-D4AD-4457-8AEB-DB053A6CDE82@oracle.com>
References: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>
	<alpine.DEB.2.02.1408141406320.2519@luke-Latitude>
	<ED79E0D0-D4AD-4457-8AEB-DB053A6CDE82@oracle.com>
Message-ID: <085039CE-4AB3-4AA7-BBEF-B0E59ACE542A@gmail.com>

AFAIK there is not supposed to be any user level code that depends on the existence of *tmp*, but there are knock-on effects (evaluating code in a locked environment can succeed with byte code and fail with the interpreter, for instance)

Peter

> On Aug 14, 2014, at 14:35, Michael Haupt <michael.haupt at oracle.com> wrote:
> 
> Hi Luke,
> 
>> Am 14.08.2014 um 12:08 schrieb luke-tierney at uiowa.edu:
>> This is a consequence of the tricks the interpreter implementation
>> currently plays to do complex assignments. Compiled code works
>> differently:
>> 
>>> library(compiler)
>>> cmpfun(function() {
>> +            x<-c(1,2)
>> +    x[1]<-42
>> +    `*tmp*`[1]<-7 # I would expect this one to fail
>> + })()
>> Error in cmpfun(function() { : object '*tmp*' not found
> 
> aha, thank you very much! So the behaviour of the AST and bytecode interpreters differ. Which one is authoritative? Can I cherry-pick? (I'll pick the bytecode interpreter's version if I may.)
> 
> Is there actually any code out there that *uses* `*tmp*` and would hence break if the bytecode interpreter was used? Is it encouraged to not directly access `*tmp*`?
> 
> I'm asking all these questions because, in FastR, we're currently quite closely mirroring the AST interpreter's behaviour for complex assignments - if this is not an absolute must-have, I'd be very happy about being able to apply a much leaner implementation instead.
> 
> Best,
> 
> Michael
> 
> -- 
> Dr. Michael Haupt
> Principal Member of Technical Staff
> Phone: +49 331 200 7277, Fax: +49 331 200 7561
> Oracle Labs
> Oracle Deutschland B.V. & Co. KG, Schiffbauergasse 14, 14467 Potsdam, Germany
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From axel.urbiz at gmail.com  Fri Aug 15 22:47:40 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 15 Aug 2014 16:47:40 -0400
Subject: [Rd] Package manual Tex file
In-Reply-To: <53EDE19B.4060500@gmail.com>
References: <CAAyVsX+hr7PP7SdZeZif--nxnoZi5ncAM9Kk_ub_k7_WP78nXQ@mail.gmail.com>
	<53EDE19B.4060500@gmail.com>
Message-ID: <CAAyVsXKpOTw9kg=EEJ6=tu4WOhMWhQ0nyeXenK690wLgKsOi9w@mail.gmail.com>

Hi Duncan,


Thanks for your response.


The command  "R CMD Rd2pdf --no-clean fooPackage" is creating the pdf file
with the package manual but not the .tex file. I find this odd given that
the following is part of the log:


"Hmm ... looks like a package

Converting Rd files to LaTeX .

Creating pdf output from LaTeX ...

(/Users/package manual/.Rd2pdf14087/Rd2.tex

LaTeX2e <2009/09/24>"


I don't see the .Rd2pdf14087 folder (Note also that I'm on Mac OS and I set
the options to see all hidden files).


Alternatively, the command below successfully creates the .tex file for me.
However, I wonder if there is a way to do this for all .Rd files at once
(including the DESCRIPTION file).


R CMD Rdconv -o fooFUN.tex --type=latex fooFUN.Rd



Thanks again for your help,

Axel.


On Fri, Aug 15, 2014 at 6:31 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 14/08/2014, 8:51 PM, Axel Urbiz wrote:
> > Dear All,
> >
> > My apologies if the question is ambiguous.
> >
> > I can create the pdf manual from a package I've built from "R CMD check
> > fooPackage". Is there a way to get the Tex file for the package manual
> pdf?
> > Well, I presume there is Tex code "behind" a package manual pdf file. But
> > if so, how can I get it?
> >
> > I'm on Mac OS.
>
> In the shell, run
>
> R CMD Rd2pdf --no-clean fooPackage
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Aug 15 22:54:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Aug 2014 16:54:56 -0400
Subject: [Rd] Package manual Tex file
In-Reply-To: <CAAyVsXKpOTw9kg=EEJ6=tu4WOhMWhQ0nyeXenK690wLgKsOi9w@mail.gmail.com>
References: <CAAyVsX+hr7PP7SdZeZif--nxnoZi5ncAM9Kk_ub_k7_WP78nXQ@mail.gmail.com>	<53EDE19B.4060500@gmail.com>
	<CAAyVsXKpOTw9kg=EEJ6=tu4WOhMWhQ0nyeXenK690wLgKsOi9w@mail.gmail.com>
Message-ID: <53EE73A0.4090308@gmail.com>

On 15/08/2014, 4:47 PM, Axel Urbiz wrote:
> Hi Duncan, 
> 
> 
> Thanks for your response.
> 
> 
> The command  "R CMD Rd2pdf --no-clean fooPackage" is creating the pdf
> file with the package manual but not the .tex file. I find this odd
> given that the following is part of the log:
> 
> 
> "Hmm ... looks like a package
> 
> Converting Rd files to LaTeX .
> 
> Creating pdf output from LaTeX ...
> 
> (/Users/package manual/.Rd2pdf14087/Rd2.tex
> 
> LaTeX2e <2009/09/24>"
> 
> 
> I don't see the .Rd2pdf14087 folder (Note also that I'm on Mac OS and I
> set the options to see all hidden files).
> 

I don't see what you describe.  On Mac OS I see this output:

$ R CMD Rd2pdf --no-clean tables
Hmm ... looks like a package
Converting Rd files to LaTeX ..
Creating pdf output from LaTeX ...

This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013)
 restricted \write18 enabled.
entering extended mode
(/Users/murdoch/svn/MyR/.Rd2pdf4517/Rd2.tex

[ many lines deleted ]

Output written on Rd2.pdf (23 pages, 134164 bytes).
Transcript written on Rd2.log.
Saving output to 'tables.pdf' ...
Done
You may want to clean up by 'rm -rf .Rd2pdf4517'

murdoch at djmair ~/svn/MyR
$ cd .Rd2pdf4517/

murdoch at djmair ~/svn/MyR/.Rd2pdf4517
$ ls
Rd2.aux  Rd2.ilg  Rd2.log  Rd2.pdf  Rd2.toc
Rd2.idx  Rd2.ind  Rd2.out  Rd2.tex

Duncan Murdoch

> 
> Alternatively, the command below successfully creates the .tex file for
> me. However, I wonder if there is a way to do this for all .Rd files at
> once (including the DESCRIPTION file).
> 
> 
> R CMD Rdconv -o fooFUN.tex --type=latex fooFUN.Rd
> 
> 
> 
> Thanks again for your help,
> 
> Axel.
> 
> 
> 
> On Fri, Aug 15, 2014 at 6:31 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 14/08/2014, 8:51 PM, Axel Urbiz wrote:
>     > Dear All,
>     >
>     > My apologies if the question is ambiguous.
>     >
>     > I can create the pdf manual from a package I've built from "R CMD
>     check
>     > fooPackage". Is there a way to get the Tex file for the package
>     manual pdf?
>     > Well, I presume there is Tex code "behind" a package manual pdf
>     file. But
>     > if so, how can I get it?
>     >
>     > I'm on Mac OS.
> 
>     In the shell, run
> 
>     R CMD Rd2pdf --no-clean fooPackage
> 
>     Duncan Murdoch
> 
>


From andrezda10 at yandex.com  Sat Aug 16 05:03:54 2014
From: andrezda10 at yandex.com (=?utf-8?B?QW5kcsOpIFouIEQuIEEu?=)
Date: Sat, 16 Aug 2014 00:03:54 -0300
Subject: [Rd] Compilation problems
Message-ID: <3473671408158234@web28m.yandex.ru>

It is not a virtual machine. But every process has it's memory limited. And Java will insanely (try to) reserve 1/4 of memory for its heap on every run, by default. Ugly language, that would be at least 3GB on this server. So the fix is -Xms and -Xmx passed using _JAVA_OPTIONS variable. Now it happily runs saying:

"Picked up _JAVA_OPTIONS: -Xmx64m -Xms6m"



> I have seen this error before when running java inside a vm container
> (openvz, lxc) where the kernel does not give java permission to query
> the amount of available memory, and hence java assumes it must be 0.
> In these cases you need to manually set the MaxHeapSize by passing a
> parameter to java, see:
> http://stackoverflow.com/questions/4401396/could-not-reserve-enough-space-for-object-heap.
> 
> I am not sure where in the compilation that java gets invoked, and if
> there is a way to pass parameters. Perhaps you can use the
> _JAVA_OPTIONS environment variable.


From therneau at mayo.edu  Mon Aug 18 20:55:51 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 18 Aug 2014 13:55:51 -0500
Subject: [Rd] patch for rpart
In-Reply-To: <mailman.17.1408010406.569.r-devel@r-project.org>
References: <mailman.17.1408010406.569.r-devel@r-project.org>
Message-ID: <27747b$932m5g@ironport10.mayo.edu>



On 08/14/2014 05:00 AM, r-devel-request at r-project.org wrote:
> Dear list
>
>
> For my work, it would be helpful if rpart worked seamlessly with an
> empty model:
>
> library(rpart); rpart(formula=y~0, data=data.frame(y=factor(1:10)))
>
> Currently, an unrelated error (originating from na.rpart) is thrown.
>
> At some point in the near future, I'd like to release a package to CRAN
> which uses rpart and relies on that functionality. I have prepared a
> patch (minor modifications at three places, and a test) which I'd like
> to propose for inclusion in the next CRAN release of rpart. The patch
> can be reviewed athttps://github.com/krlmlr/rpart/tree/empty-model, the
> files (based on the current CRAN release 4.1-8) can be downloaded from
> https://github.com/krlmlr/rpart/archive/empty-model.zip.
>
> Thanks for your attention.
>
>
> With kindest regards
>
> Kirill M?ller

In general I try to make functions behave in edge cases, so am symptatheic to your 
request.  But I won't get to it for months at least, even if I say yes.  Brian Ripley is 
the official maintainer of rpart at this time, send a note directly to him.  If neither 
Brian nor I can fit it in, no one else will.

Terry Therneau


From richierocks at gmail.com  Tue Aug 19 15:28:03 2014
From: richierocks at gmail.com (Richard Cotton)
Date: Tue, 19 Aug 2014 16:28:03 +0300
Subject: [Rd] Is using devtools::release no longer allowed?
Message-ID: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>

I recently tried to submit a package to CRAN using the release
function in the devtools package and got the response:

> The policies asked you to use the webform: do so in future.

I think that the relevant line in the policies are:

> When submitting a package to CRAN you should use the submission form at
> http://CRAN.R-project.org/submit.html (and not send an email). You will be sent
> a confirmation email which needs to be accepted.

> If this fails, upload by anonymous ftp to ftp://CRAN.R-project.org/incoming/ and
> send a (plain text ASCII) email at the same time, with subject line as specified below.

As far as I know, the release function uses the second method, so I
don't quite understand what the problem is.

Has that method of submission been banned?

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From murdoch.duncan at gmail.com  Tue Aug 19 15:54:49 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Aug 2014 09:54:49 -0400
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
Message-ID: <53F35729.2090301@gmail.com>

On 19/08/2014 9:28 AM, Richard Cotton wrote:
> I recently tried to submit a package to CRAN using the release
> function in the devtools package and got the response:
>
> > The policies asked you to use the webform: do so in future.
>
> I think that the relevant line in the policies are:
>
> > When submitting a package to CRAN you should use the submission form at
> > http://CRAN.R-project.org/submit.html (and not send an email). You will be sent
> > a confirmation email which needs to be accepted.
>
> > If this fails, upload by anonymous ftp to ftp://CRAN.R-project.org/incoming/ and
> > send a (plain text ASCII) email at the same time, with subject line as specified below.
>
> As far as I know, the release function uses the second method, so I
> don't quite understand what the problem is.
>
> Has that method of submission been banned?
>
Presumably the second method is less convenient for the CRAN maintainers 
than the first, so you should only use it if the first method fails.  As 
the policy says.

Duncan Murdoch


From edd at debian.org  Tue Aug 19 16:19:29 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Aug 2014 09:19:29 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
Message-ID: <21491.23793.389413.468373@max.nulle.part>


Hi Richie,

On 19 August 2014 at 16:28, Richard Cotton wrote:
| I recently tried to submit a package to CRAN using the release
| function in the devtools package and got the response:
| 
| > The policies asked you to use the webform: do so in future.
| 
| I think that the relevant line in the policies are:
| 
| > When submitting a package to CRAN you should use the submission form at
| > http://CRAN.R-project.org/submit.html (and not send an email). You will be sent
| > a confirmation email which needs to be accepted.
| 
| > If this fails, upload by anonymous ftp to ftp://CRAN.R-project.org/incoming/ and
| > send a (plain text ASCII) email at the same time, with subject line as specified below.
| 
| As far as I know, the release function uses the second method, so I
| don't quite understand what the problem is.
| 
| Has that method of submission been banned?

i)   AFAICT devtools is just one package by one very talented and prolific
     author -- but it was never blessed by R Core or CRAN, so the first error here
     may just be your assumptions.  Then again, I presume devtools 'just' used
     ftp and the issue may be that ftp might be deprecated. 

ii)  CRAN Policies change, but to our chagrin changes are (were?) somewhat
     infrequently communicated. However, just this weekend I (and presumably
     a larger number of other package author, so I assume you were included)
     received an email by Kurt Hornik with a changeset over the last few
     months. So as of today the preference for the webform must count as
     announced.

iii) Because of ii) and the lack of communication, I created a cronjob based
     on code in and writing to a github repo [1] and posting via twitter [2]
     so you have options for remaining informed if you so desire.

iv)  I haven't had an upload in a few days, but I must have upload well in
     excess of one hundred times via ftp [3] so if it really is frowned upon
     now per i) I am sure to miss it.

Hope this helps,  Dirk


[1] https://github.com/eddelbuettel/crp

[2] https://twitter.com/CRANPolicyWatch

[3] ncftp has a ~/.ncftp/ directory which makes this quasi-stateful and trivial

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ligges at statistik.tu-dortmund.de  Tue Aug 19 19:51:56 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 19 Aug 2014 19:51:56 +0200
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <53F35729.2090301@gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
Message-ID: <53F38EBC.8010809@statistik.tu-dortmund.de>



On 19.08.2014 15:54, Duncan Murdoch wrote:
> On 19/08/2014 9:28 AM, Richard Cotton wrote:
>> I recently tried to submit a package to CRAN using the release
>> function in the devtools package and got the response:
>>
>> > The policies asked you to use the webform: do so in future.
>>
>> I think that the relevant line in the policies are:
>>
>> > When submitting a package to CRAN you should use the submission form at
>> > http://CRAN.R-project.org/submit.html (and not send an email). You
>> will be sent
>> > a confirmation email which needs to be accepted.
>>
>> > If this fails, upload by anonymous ftp to
>> ftp://CRAN.R-project.org/incoming/ and
>> > send a (plain text ASCII) email at the same time, with subject line
>> as specified below.
>>
>> As far as I know, the release function uses the second method, so I
>> don't quite understand what the problem is.
>>
>> Has that method of submission been banned?
>>
> Presumably the second method is less convenient for the CRAN maintainers
> than the first, so you should only use it if the first method fails.  As
> the policy says.

Right, we receive lots of mails with insufficient information, hence we 
introduced the webform.
If there is something else we complain about (like in your case) or the 
mail is insufficient, we will mention that the webform should be the way 
to submit unless that fails for some reason. That way we get better 
prepared information for the manual part of our checks.

So to all listeners: Future submission by means of the webform, please.

Thank you and best wishes,
Uwe Ligges







>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Tue Aug 19 20:14:52 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Aug 2014 13:14:52 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <53F38EBC.8010809@statistik.tu-dortmund.de>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
Message-ID: <21491.37916.790888.953720@max.nulle.part>


On 19 August 2014 at 19:51, Uwe Ligges wrote:
| So to all listeners: Future submission by means of the webform, please.

I hereby offer one beer to the first person who shows me how to use RSelenium
to drive the webform from a script.

Dirk 
(who used the webform in textmode earlier today over a ssh connection)

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From cboettig at gmail.com  Tue Aug 19 20:40:32 2014
From: cboettig at gmail.com (Carl Boettiger)
Date: Tue, 19 Aug 2014 11:40:32 -0700
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <21491.37916.790888.953720@max.nulle.part>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
Message-ID: <CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>

Dirk, listeners,

Perhaps you would consider using omegahat's RHTMLForms instead?

    library("RHTMLForms")
    forms <- getHTMLFormDescription("http://xmpalantir.wu.ac.at/cransubmit/
")
    submit_to_cran <- createFunction(forms[[1]])

Should create a function called "submit_to_cran" with arguments
corresponding to the webform blanks, e.g.

submit_to_cran(name = "packagename", email = "youremail", uploaded_file =
"package.tar.gz", comment = "the optional comment")

(clearly you could fill those details in from the submitting package
description).  I haven't tested this.


Cheers,

Carl




On Tue, Aug 19, 2014 at 11:14 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 19 August 2014 at 19:51, Uwe Ligges wrote:
> | So to all listeners: Future submission by means of the webform, please.
>
> I hereby offer one beer to the first person who shows me how to use
> RSelenium
> to drive the webform from a script.
>
> Dirk
> (who used the webform in textmode earlier today over a ssh connection)
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Aug 19 20:53:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Aug 2014 14:53:54 -0400
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>	<53F35729.2090301@gmail.com>	<53F38EBC.8010809@statistik.tu-dortmund.de>	<21491.37916.790888.953720@max.nulle.part>
	<CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>
Message-ID: <53F39D42.9070708@gmail.com>

On 19/08/2014 2:40 PM, Carl Boettiger wrote:
> Dirk, listeners,
>
> Perhaps you would consider using omegahat's RHTMLForms instead?
>
>      library("RHTMLForms")
>      forms <- getHTMLFormDescription("http://xmpalantir.wu.ac.at/cransubmit/
> ")
>      submit_to_cran <- createFunction(forms[[1]])
>
> Should create a function called "submit_to_cran" with arguments
> corresponding to the webform blanks, e.g.
>
> submit_to_cran(name = "packagename", email = "youremail", uploaded_file =
> "package.tar.gz", comment = "the optional comment")
>
> (clearly you could fill those details in from the submitting package
> description).  I haven't tested this.
>
>

If you use this, make sure you test it well enough to get it perfect the 
very first time you use it.  If I were a CRAN administrator and received 
a series of bad submissions from someone who was working out the bugs, I 
would not find it difficult either technically or morally to permanently 
ban that user from ever submitting anything again.

Duncan Murdoch


From kasperdanielhansen at gmail.com  Tue Aug 19 21:53:24 2014
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 19 Aug 2014 15:53:24 -0400
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <53F39D42.9070708@gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>
	<53F39D42.9070708@gmail.com>
Message-ID: <CAC2h7ut+XbTNwe=scXZ-=YihphLTruXO3UuO2CsrnumJxBDL2w@mail.gmail.com>

Given the seeming need for automated submission to CRAN, perhaps the repos
maintainers could consider making a function available that allows one to
do so, for example
  source("http://www.cran.r-project.org/submit_to_cran.R")
  submit_to_cran("PACKAGE.TARBALL", REQUIRED_ARGUMENTS)
or perhaps be interested in a community developed script?  Although I
recognize how easy it is for me to suggest work for others, it seems like
such a script would cut down on everyones work, long-term.

Best,
Kasper




On Tue, Aug 19, 2014 at 2:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/08/2014 2:40 PM, Carl Boettiger wrote:
>
>> Dirk, listeners,
>>
>> Perhaps you would consider using omegahat's RHTMLForms instead?
>>
>>      library("RHTMLForms")
>>      forms <- getHTMLFormDescription("http://xmpalantir.wu.ac.at/
>> cransubmit/
>> ")
>>      submit_to_cran <- createFunction(forms[[1]])
>>
>> Should create a function called "submit_to_cran" with arguments
>> corresponding to the webform blanks, e.g.
>>
>> submit_to_cran(name = "packagename", email = "youremail", uploaded_file =
>> "package.tar.gz", comment = "the optional comment")
>>
>> (clearly you could fill those details in from the submitting package
>> description).  I haven't tested this.
>>
>>
>>
> If you use this, make sure you test it well enough to get it perfect the
> very first time you use it.  If I were a CRAN administrator and received a
> series of bad submissions from someone who was working out the bugs, I
> would not find it difficult either technically or morally to permanently
> ban that user from ever submitting anything again.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tlumley at uw.edu  Tue Aug 19 22:01:11 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Wed, 20 Aug 2014 08:01:11 +1200
Subject: [Rd] capture.output on S4 slot
In-Reply-To: <1405659808262.54155@uni.sydney.edu.au>
References: <1405659808262.54155@uni.sydney.edu.au>
Message-ID: <CAJ55+dKua0a+iG7LqbUgBjOB1qGOsubfqcBnpVutZQu84miwMQ@mail.gmail.com>

On Fri, Jul 18, 2014 at 4:00 PM, Dario Strbenac
<dstr7320 at uni.sydney.edu.au> wrote:
> Hello,
>
> capture.output produces a different result if the S4 object was created with a constructor than if the body of the constructor is copied and pasted.
>
> setClass("TransformParams", representation(
>   transform = "function",
>   otherParams = "list")
> )
>
> setGeneric("TransformParams", function(transform, ...)
> {standardGeneric("TransformParams")})
> setMethod("TransformParams", character(0), function()
> {
>   new("TransformParams", transform = function(){}, otherParams = list())
> })
>
>> capture.output(TransformParams()@transform)
> [1] "function () "             "{"
> [3] "}"                        "<environment: 0x363bd60>"
>> capture.output(new("TransformParams", transform = function(){}, otherParams = list())@transform)
> [1] "function(){}"
>
> Why is the function split into three parts if a constructor is used ?
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia


Dario,

When you use the constructor, the environment of the function is the
environment inside the constructor; when you use new() it is
R_GlobalEnv

The way functions print is that they print their environment when it
isn't something special like R_GlobalEnv. Since capture.output
captures the printed output, that's what it sees.

The function isn't split up; the printed output is.

   -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From rowe at muxspace.com  Tue Aug 19 22:18:20 2014
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Tue, 19 Aug 2014 16:18:20 -0400
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CAC2h7ut+XbTNwe=scXZ-=YihphLTruXO3UuO2CsrnumJxBDL2w@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>
	<53F39D42.9070708@gmail.com>
	<CAC2h7ut+XbTNwe=scXZ-=YihphLTruXO3UuO2CsrnumJxBDL2w@mail.gmail.com>
Message-ID: <07136ADA-054E-4A5C-9C64-FE6D9352C014@muxspace.com>

Isn't the source for CRAN itself open source? One option is to run a test server that can respond with a success or failure message based on the submission. 

?????
Brian Lee Yung Rowe
Founder, Zato Novo
Professor, M.S. Data Analytics, CUNY

> On Aug 19, 2014, at 3:55 PM, Kasper Daniel Hansen <kasperdanielhansen at gmail.com> wrote:
> 
> Given the seeming need for automated submission to CRAN, perhaps the repos
> maintainers could consider making a function available that allows one to
> do so, for example
>  source("http://www.cran.r-project.org/submit_to_cran.R")
>  submit_to_cran("PACKAGE.TARBALL", REQUIRED_ARGUMENTS)
> or perhaps be interested in a community developed script?  Although I
> recognize how easy it is for me to suggest work for others, it seems like
> such a script would cut down on everyones work, long-term.
> 
> Best,
> Kasper
> 
> 
> 
> 
> On Tue, Aug 19, 2014 at 2:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>>> On 19/08/2014 2:40 PM, Carl Boettiger wrote:
>>> 
>>> Dirk, listeners,
>>> 
>>> Perhaps you would consider using omegahat's RHTMLForms instead?
>>> 
>>>     library("RHTMLForms")
>>>     forms <- getHTMLFormDescription("http://xmpalantir.wu.ac.at/
>>> cransubmit/
>>> ")
>>>     submit_to_cran <- createFunction(forms[[1]])
>>> 
>>> Should create a function called "submit_to_cran" with arguments
>>> corresponding to the webform blanks, e.g.
>>> 
>>> submit_to_cran(name = "packagename", email = "youremail", uploaded_file =
>>> "package.tar.gz", comment = "the optional comment")
>>> 
>>> (clearly you could fill those details in from the submitting package
>>> description).  I haven't tested this.
>> If you use this, make sure you test it well enough to get it perfect the
>> very first time you use it.  If I were a CRAN administrator and received a
>> series of bad submissions from someone who was working out the bugs, I
>> would not find it difficult either technically or morally to permanently
>> ban that user from ever submitting anything again.
>> 
>> Duncan Murdoch
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Wed Aug 20 00:05:56 2014
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 20 Aug 2014 00:05:56 +0200
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <21491.37916.790888.953720@max.nulle.part>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
Message-ID: <CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>

On Tue, Aug 19, 2014 at 8:14 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> I hereby offer one beer to the first person who shows me how to use RSelenium
> to drive the webform from a script.

Below is a simple script that simulates the form. No crazy RSelenium
browser interactions; I just reverse engineered the HTML form. Tested
and it works.

https://gist.github.com/jeroenooms/48be418e87100d7ea1a2

Not sure if CRAN maintainers will appreciate this, though. The "I have
read the CRAN policies" confirmation page is probably there for a
reason. Also the script will obviously break if CRAN decides to change
the form parameters. However I do agree with many others that some way
to automate the submission process is useful. Perhaps Uwe can comment.


From edd at debian.org  Wed Aug 20 00:14:23 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Aug 2014 17:14:23 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
Message-ID: <21491.52287.808003.627086@max.nulle.part>


On 20 August 2014 at 00:05, Jeroen Ooms wrote:
| On Tue, Aug 19, 2014 at 8:14 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
| >
| > I hereby offer one beer to the first person who shows me how to use RSelenium
| > to drive the webform from a script.
| 
| Below is a simple script that simulates the form. 

I presume Heineken will be ok?  

I may double this up to two beers as your solution avoids Java.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From gmbecker at ucdavis.edu  Wed Aug 20 00:15:36 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 19 Aug 2014 15:15:36 -0700
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
Message-ID: <CADwqtCNMUVgefkjADS9i2gWi8SfTa5hfR5d-6DN4Y4rFmMQMNg@mail.gmail.com>

On Tue, Aug 19, 2014 at 3:05 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> On Tue, Aug 19, 2014 at 8:14 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> https://gist.github.com/jeroenooms/48be418e87100d7ea1a2
>
> Not sure if CRAN maintainers will appreciate this, though. The "I have
> read the CRAN policies" confirmation page is probably there for a
> reason.


I agree. I think we've entered the realm of "yes, it would be easy to do,
but don't". An arms race with CRAN re: automating submission doesn't seem
like a good way forward.

~G



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Aug 20 00:21:57 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 20 Aug 2014 00:21:57 +0200
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CABFfbXv1vaF8JpKnSOpWNkMsCN43s-yV0yEkm8jjF3AcYGvhAQ@mail.gmail.com>
Message-ID: <53F3CE05.1010107@statistik.tu-dortmund.de>



On 20.08.2014 00:05, Jeroen Ooms wrote:
> On Tue, Aug 19, 2014 at 8:14 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>> I hereby offer one beer to the first person who shows me how to use RSelenium
>> to drive the webform from a script.
>
> Below is a simple script that simulates the form. No crazy RSelenium
> browser interactions; I just reverse engineered the HTML form. Tested
> and it works.
>
> https://gist.github.com/jeroenooms/48be418e87100d7ea1a2
>
> Not sure if CRAN maintainers will appreciate this, though. The "I have
> read the CRAN policies" confirmation page is probably there for a
> reason.

Indeed! And we want people to actively think about that for each 
submission. Hence I'd appreciate if people take the time to think about 
a submission in advance, e.g. while tackling the cumbersome task to open 
the webbrowser. ;-)


> Also the script will obviously break if CRAN decides to change
> the form parameters. However I do agree with many others that some way
> to automate the submission process is useful. Perhaps Uwe can comment.


The form may change and we do not guarantee back compatibility. More 
parts of the submission / check procedure will be automated (as also 
happened in the past) and this is work in progress.


Please note that CRAN is not intended as a development platform but for 
more or less stable package releases that won't change too frequently, 
hence we expect that for the not so frequent event of a package 
submission, it is *not too much work for the package maintainer* to use 
the webbrowsr for a submission. It is *much more work for the CRAN 
mintainers* telling 40 people each day that they forgot to read the 
policies and that they submit without thinking about the submission 
carefully in advance - with an update few hours later or asking to 
rename a package .....

Best,
Uwe


From peter.langfelder at gmail.com  Wed Aug 20 22:11:53 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 20 Aug 2014 13:11:53 -0700
Subject: [Rd] as.Date.character suggestion
Message-ID: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>

The default format="" in as.Date.character is supremely confusing. The
help shows as.Date defined as

## S3 method for class 'character'
     as.Date(x, format = "", ...)

yet the function behaves very differently when format is not specified
and when it is specified to its default:

as.Date("2012-01-01")
[1] "2012-01-01"
> as.Date("2012-01-01", format = "")
[1] "2014-08-20"  ### Gives today.


The default setting is never used, because if format is not given,
values "%Y-%m-%d" and "%Y/%m/%d" are tried for it (rather than "").

My suggestion is to leave out the default "" for format in as.Date:

as.Date(x, format, ...)

If this causes a conflict in the S3 dispatching, at least indicate in
the help that the default is never used and the function works
differently if format is specified to its default.

Thanks,

Peter


From murdoch.duncan at gmail.com  Wed Aug 20 22:18:36 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Aug 2014 16:18:36 -0400
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
Message-ID: <53F5029C.3080909@gmail.com>

On 20/08/2014, 4:11 PM, Peter Langfelder wrote:
> The default format="" in as.Date.character is supremely confusing. The
> help shows as.Date defined as
> 
> ## S3 method for class 'character'
>      as.Date(x, format = "", ...)
> 
> yet the function behaves very differently when format is not specified
> and when it is specified to its default:
> 
> as.Date("2012-01-01")
> [1] "2012-01-01"
>> as.Date("2012-01-01", format = "")
> [1] "2014-08-20"  ### Gives today.
> 
> 
> The default setting is never used, because if format is not given,
> values "%Y-%m-%d" and "%Y/%m/%d" are tried for it (rather than "").
> 
> My suggestion is to leave out the default "" for format in as.Date:
> 
> as.Date(x, format, ...)
> 
> If this causes a conflict in the S3 dispatching, at least indicate in
> the help that the default is never used and the function works
> differently if format is specified to its default.

Wouldn't it be simpler to change the test from

if (missing(format))

to

if (format == "")

?

Duncan Murdoch


From peter.langfelder at gmail.com  Wed Aug 20 22:50:11 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 20 Aug 2014 13:50:11 -0700
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <53F5029C.3080909@gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
Message-ID: <CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>

That would be my preferred solution, but it would break backwards
compatibility for format="", so others may disagree.

Peter

On Wed, Aug 20, 2014 at 1:18 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/08/2014, 4:11 PM, Peter Langfelder wrote:
>> The default format="" in as.Date.character is supremely confusing. The
>> help shows as.Date defined as
>>
>> ## S3 method for class 'character'
>>      as.Date(x, format = "", ...)
>>
>> yet the function behaves very differently when format is not specified
>> and when it is specified to its default:
>>
>> as.Date("2012-01-01")
>> [1] "2012-01-01"
>>> as.Date("2012-01-01", format = "")
>> [1] "2014-08-20"  ### Gives today.
>>
>>
>> The default setting is never used, because if format is not given,
>> values "%Y-%m-%d" and "%Y/%m/%d" are tried for it (rather than "").
>>
>> My suggestion is to leave out the default "" for format in as.Date:
>>
>> as.Date(x, format, ...)
>>
>> If this causes a conflict in the S3 dispatching, at least indicate in
>> the help that the default is never used and the function works
>> differently if format is specified to its default.
>
> Wouldn't it be simpler to change the test from
>
> if (missing(format))
>
> to
>
> if (format == "")
>
> ?
>
> Duncan Murdoch
>


From gmbecker at ucdavis.edu  Thu Aug 21 01:52:39 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 20 Aug 2014 16:52:39 -0700
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
	<CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
Message-ID: <CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>

Could do both to preserve bc...

if(missing(format) || !nchar(format))

~G


On Wed, Aug 20, 2014 at 1:50 PM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> That would be my preferred solution, but it would break backwards
> compatibility for format="", so others may disagree.
>
> Peter
>
> On Wed, Aug 20, 2014 at 1:18 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 20/08/2014, 4:11 PM, Peter Langfelder wrote:
> >> The default format="" in as.Date.character is supremely confusing. The
> >> help shows as.Date defined as
> >>
> >> ## S3 method for class 'character'
> >>      as.Date(x, format = "", ...)
> >>
> >> yet the function behaves very differently when format is not specified
> >> and when it is specified to its default:
> >>
> >> as.Date("2012-01-01")
> >> [1] "2012-01-01"
> >>> as.Date("2012-01-01", format = "")
> >> [1] "2014-08-20"  ### Gives today.
> >>
> >>
> >> The default setting is never used, because if format is not given,
> >> values "%Y-%m-%d" and "%Y/%m/%d" are tried for it (rather than "").
> >>
> >> My suggestion is to leave out the default "" for format in as.Date:
> >>
> >> as.Date(x, format, ...)
> >>
> >> If this causes a conflict in the S3 dispatching, at least indicate in
> >> the help that the default is never used and the function works
> >> differently if format is specified to its default.
> >
> > Wouldn't it be simpler to change the test from
> >
> > if (missing(format))
> >
> > to
> >
> > if (format == "")
> >
> > ?
> >
> > Duncan Murdoch
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Thu Aug 21 01:59:24 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 20 Aug 2014 16:59:24 -0700
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
	<CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
	<CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>
Message-ID: <CA+hbrhUr9jV8Jxb5Bjo4SXC-eriY7or39JmOc5XY-X=Ph5C38A@mail.gmail.com>

On Wed, Aug 20, 2014 at 4:52 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Could do both to preserve bc...
>
> if(missing(format) || !nchar(format))
>

No, the problem is that the function behaves differently when format
is missing than when it equals its default. Removing this difference
necessarily changes behaviour and hence (at least in principle) breaks
backward compatibility.

Peter


From gmbecker at ucdavis.edu  Thu Aug 21 02:21:34 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 20 Aug 2014 17:21:34 -0700
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <CA+hbrhUr9jV8Jxb5Bjo4SXC-eriY7or39JmOc5XY-X=Ph5C38A@mail.gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
	<CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
	<CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>
	<CA+hbrhUr9jV8Jxb5Bjo4SXC-eriY7or39JmOc5XY-X=Ph5C38A@mail.gmail.com>
Message-ID: <CADwqtCNQ8JnB=5-FKcSWc6XYujWbvSALLjUnOc7su4RqR6RHWw@mail.gmail.com>

Ah, my mistake, I read too fast. (My code is also wrong, embarassingly).

It seems like it's behavior when you pass it "" is simply a bug, then.

Sorry for the noise,

~G




On Wed, Aug 20, 2014 at 4:59 PM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> On Wed, Aug 20, 2014 at 4:52 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> > Could do both to preserve bc...
> >
> > if(missing(format) || !nchar(format))
> >
>
> No, the problem is that the function behaves differently when format
> is missing than when it equals its default. Removing this difference
> necessarily changes behaviour and hence (at least in principle) breaks
> backward compatibility.
>
> Peter
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From andrezda10 at yandex.com  Thu Aug 21 04:28:14 2014
From: andrezda10 at yandex.com (=?utf-8?B?QW5kcsOpIFouIEQuIEEu?=)
Date: Wed, 20 Aug 2014 23:28:14 -0300
Subject: [Rd] as.Date.character suggestion
Message-ID: <775661408588094@web19j.yandex.ru>

Your arguments seems like: "we can't fix bugs or improve anything because this would break backward compatibility". If the described behavior should be important on many common cases, create a new function. Or new release, deprecated uses for some functions.

Or maybe, add a new argument that allows the user to choose the old or new behavior. The default of this argument might be based on compilation flag or environment variable (this should be possible on all OSes).

But just discarding changes like this, doesn't evolve anything.


> On Wed, Aug 20, 2014 at 4:52 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> 
>> Could do both to preserve bc...
>>
>> if(missing(format) || !nchar(format))
> 
> No, the problem is that the function behaves differently when format
> is missing than when it equals its default. Removing this difference
> necessarily changes behaviour and hence (at least in principle) breaks
> backward compatibility.
> 
> Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Thu Aug 21 09:28:34 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Aug 2014 09:28:34 +0200
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <CADwqtCNQ8JnB=5-FKcSWc6XYujWbvSALLjUnOc7su4RqR6RHWw@mail.gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
	<CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
	<CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>
	<CA+hbrhUr9jV8Jxb5Bjo4SXC-eriY7or39JmOc5XY-X=Ph5C38A@mail.gmail.com>
	<CADwqtCNQ8JnB=5-FKcSWc6XYujWbvSALLjUnOc7su4RqR6RHWw@mail.gmail.com>
Message-ID: <FAF4F39F-4B65-4AE5-8A39-7558624BEEE3@gmail.com>


On 21 Aug 2014, at 02:21 , Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> Ah, my mistake, I read too fast. (My code is also wrong, embarassingly).
> 
> It seems like it's behavior when you pass it "" is simply a bug, then.
> 
> Sorry for the noise,
> 
> ~G
> 

It's not a bug, it's just that you are at the mercy of strptime() if you do specify a format. If the format doesn't contain a conversion for some component, you get the value corresponding to the current date and leftover characters are just ignored, e.g.

> strptime("1-1foo","%m-%d")
[1] "2014-01-01"

and the extreme case is that a "" format gives current date, whatever the input. On Mac OSX Mavericks anyway --- this stuff is system-dependent.

So I think Peter Langfelder is absolutely right, remove the default, which is never used anyway, and possibly update the documentation with a more direct reference to strptime(). This should have near-zero effect on the semantics. 

Peter D.

> 
> 
> 
> On Wed, Aug 20, 2014 at 4:59 PM, Peter Langfelder <
> peter.langfelder at gmail.com> wrote:
> 
>> On Wed, Aug 20, 2014 at 4:52 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>>> Could do both to preserve bc...
>>> 
>>> if(missing(format) || !nchar(format))
>>> 
>> 
>> No, the problem is that the function behaves differently when format
>> is missing than when it equals its default. Removing this difference
>> necessarily changes behaviour and hence (at least in principle) breaks
>> backward compatibility.
>> 
>> Peter
>> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From igauravsehrawat at gmail.com  Thu Aug 21 10:11:43 2014
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Thu, 21 Aug 2014 13:41:43 +0530
Subject: [Rd] Why R-project source code is not on Github
Message-ID: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>

R-Project is missing something important in regards to its development ,
one simply can't ignore Github ,where collaboration is at it's best .

OR If i am wrong is this the correct R-source :
https://github.com/wch/r-source

Is anyone thinking to bring R-project org on Github ? Maybe there might be
some difficulty while porting its version system to Github .

Just a suggestion .

Thanks
Gaurav Sehrawat
http://igauravsehrawat.com

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Aug 21 12:40:47 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 21 Aug 2014 05:40:47 -0500
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
Message-ID: <69D351C3-AA81-430E-8F66-D06863C18702@me.com>

On Aug 21, 2014, at 3:11 AM, Gaurav Sehrawat <igauravsehrawat at gmail.com> wrote:

> R-Project is missing something important in regards to its development ,
> one simply can't ignore Github ,where collaboration is at it's best .
> 
> OR If i am wrong is this the correct R-source :
> https://github.com/wch/r-source
> 
> Is anyone thinking to bring R-project org on Github ? Maybe there might be
> some difficulty while porting its version system to Github .
> 
> Just a suggestion .
> 
> Thanks
> Gaurav Sehrawat
> http://igauravsehrawat.com


The link you have above is to a read-only mirror (perhaps not the only one) of the R source code that is kept in the official Subversion repo:

  https://svn.r-project.org/R/

There are also some documents that describe R's development cycle and related processes:

  http://www.r-project.org/certification.html

Your suggestion to move to Github is perhaps based upon a false premise, that the R community at large has the ability to directly post code/patches to the official distribution. We can contribute code and patches, primarily here on R-Devel, to the code base. However, only the members of R Core team (http://www.r-project.org/contributors.html) have write access to the SVN repo above and have to approve any such contributions.

Since the current SVN based system works well for them and provides restricted write access that they can control, there is no motivation to move to an alternative version control system unless they would find it to be superior for their own development processes.

That being said, there are a number of contributing projects that have packages on CRAN, that do use Github, myself included. There is also R-Forge (https://r-forge.r-project.org), which provides another SVN based platform for community package development.

Regards,

Marc Schwartz


From b.rowlingson at lancaster.ac.uk  Thu Aug 21 12:59:37 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 21 Aug 2014 11:59:37 +0100
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <4c8452a2a2404cb280c78db26ee8ffd6@EX-1-HT0.lancs.local>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
	<4c8452a2a2404cb280c78db26ee8ffd6@EX-1-HT0.lancs.local>
Message-ID: <CANVKczOfSvUzYWrjvF8S6boMG2SyPno0U3ueQOHs6tp0Y7nhqQ@mail.gmail.com>

On Thu, Aug 21, 2014 at 11:40 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

> Your suggestion to move to Github is perhaps based upon a false premise, that the R community at large has the ability to directly post code/patches to the official distribution.

That's not the false premise here. This is:

 "one simply can't ignore Github ,where collaboration is at it's best"
- Gaurav Sehrawat

speaking as someone often labelled a git[hub]-fanboy, even I can find
reasons to debate this statement.

Barry


From richierocks at gmail.com  Thu Aug 21 15:26:20 2014
From: richierocks at gmail.com (Richard Cotton)
Date: Thu, 21 Aug 2014 16:26:20 +0300
Subject: [Rd] The behaviour of setting names differs between lists and
	atomic vectors
Message-ID: <CAPp_+=fwKAD19GAce7veeZMndmZ9W7aKm+MN393ZCz-jD=80fQ@mail.gmail.com>

If you set the names in a list, some cat-style processing seems to
happen.  For example, backslashes are modified.  This behaviour
doesn't happen with atomic vectors.  Compare, for example:

setNames(1, "a\\b")
## a\\b
##   1
setNames(list(1), "a\\b")
## $`a\b`
## [1] 1

Notice that the name of the element in the list has been changed to
'a', 'backspace'.

Is this behaviour intended, or a bug?

-- 
Regards,
Richie


From murdoch.duncan at gmail.com  Thu Aug 21 15:47:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Aug 2014 09:47:52 -0400
Subject: [Rd] The behaviour of setting names differs between lists and
 atomic vectors
In-Reply-To: <CAPp_+=fwKAD19GAce7veeZMndmZ9W7aKm+MN393ZCz-jD=80fQ@mail.gmail.com>
References: <CAPp_+=fwKAD19GAce7veeZMndmZ9W7aKm+MN393ZCz-jD=80fQ@mail.gmail.com>
Message-ID: <53F5F888.4020602@gmail.com>

On 21/08/2014 9:26 AM, Richard Cotton wrote:
> If you set the names in a list, some cat-style processing seems to
> happen.  For example, backslashes are modified.  This behaviour
> doesn't happen with atomic vectors.  Compare, for example:
>
> setNames(1, "a\\b")
> ## a\\b
> ##   1
> setNames(list(1), "a\\b")
> ## $`a\b`
> ## [1] 1
>
> Notice that the name of the element in the list has been changed to
> 'a', 'backspace'.
>
> Is this behaviour intended, or a bug?
>
I think there's a bug, but not in names<- (or setNames, which calls 
it).  The bug is in the printing, as you'll see if you look at
names(setNames(list(1), "a\\b")).

Duncan Murdoch


From pdalgd at gmail.com  Thu Aug 21 16:03:03 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Aug 2014 16:03:03 +0200
Subject: [Rd] as.Date.character suggestion
In-Reply-To: <FAF4F39F-4B65-4AE5-8A39-7558624BEEE3@gmail.com>
References: <CA+hbrhUZnZMMPL9gfK3rYzR7z9K8tEwsyFC2VOa_y0Lu254bZQ@mail.gmail.com>
	<53F5029C.3080909@gmail.com>
	<CA+hbrhUaZgCBjfwhT7Nnu9g3Xjsub_EdHSvmz5KksSFwgNS_4A@mail.gmail.com>
	<CADwqtCMLWqOJ5KF4HWdF63iOpMwafDjA1bxTaPpJHe6+2Q2jvA@mail.gmail.com>
	<CA+hbrhUr9jV8Jxb5Bjo4SXC-eriY7or39JmOc5XY-X=Ph5C38A@mail.gmail.com>
	<CADwqtCNQ8JnB=5-FKcSWc6XYujWbvSALLjUnOc7su4RqR6RHWw@mail.gmail.com>
	<FAF4F39F-4B65-4AE5-8A39-7558624BEEE3@gmail.com>
Message-ID: <0A1A1F8F-07E7-4893-9378-B5EAA1BE2B09@gmail.com>

Now done, for R-devel only. This can't be high priority.

-pd

On 21 Aug 2014, at 09:28 , peter dalgaard <pdalgd at gmail.com> wrote:

> 
> So I think Peter Langfelder is absolutely right, remove the default, which is never used anyway, and possibly update the documentation with a more direct reference to strptime(). This should have near-zero effect on the semantics. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Aug 21 16:11:38 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Aug 2014 16:11:38 +0200
Subject: [Rd] The behaviour of setting names differs between lists and
	atomic vectors
In-Reply-To: <53F5F888.4020602@gmail.com>
References: <CAPp_+=fwKAD19GAce7veeZMndmZ9W7aKm+MN393ZCz-jD=80fQ@mail.gmail.com>
	<53F5F888.4020602@gmail.com>
Message-ID: <43333C94-B4C2-43FB-ADC8-582FD089F776@gmail.com>


On 21 Aug 2014, at 15:47 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 21/08/2014 9:26 AM, Richard Cotton wrote:
>> If you set the names in a list, some cat-style processing seems to
>> happen.  For example, backslashes are modified.  This behaviour
>> doesn't happen with atomic vectors.  Compare, for example:
>> 
>> setNames(1, "a\\b")
>> ## a\\b
>> ##   1
>> setNames(list(1), "a\\b")
>> ## $`a\b`
>> ## [1] 1
>> 
>> Notice that the name of the element in the list has been changed to
>> 'a', 'backspace'.
>> 
>> Is this behaviour intended, or a bug?
>> 
> I think there's a bug, but not in names<- (or setNames, which calls it).  The bug is in the printing, as you'll see if you look at
> names(setNames(list(1), "a\\b")).
> 

Yep, slight variant:

> l <- list(`a\\b`=1)
> l
$`a\b`
[1] 1

> l$`a\b`
NULL
> l$`a\\b`
[1] 1


> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Thu Aug 21 16:35:01 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 21 Aug 2014 09:35:01 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
Message-ID: <CABdHhvHBp-tGgH4zsRC_WFRkpRzF936nv-0Pe=hG5DDGtCFcyw@mail.gmail.com>

On Tue, Aug 19, 2014 at 8:28 AM, Richard Cotton <richierocks at gmail.com> wrote:
> I recently tried to submit a package to CRAN using the release
> function in the devtools package and got the response:
>
>> The policies asked you to use the webform: do so in future.
>
> I think that the relevant line in the policies are:
>
>> When submitting a package to CRAN you should use the submission form at
>> http://CRAN.R-project.org/submit.html (and not send an email). You will be sent
>> a confirmation email which needs to be accepted.
>
>> If this fails, upload by anonymous ftp to ftp://CRAN.R-project.org/incoming/ and
>> send a (plain text ASCII) email at the same time, with subject line as specified below.
>
> As far as I know, the release function uses the second method, so I
> don't quite understand what the problem is.

The development version of devtools uses the web form method. I will
endeavour to track changes to the CRAN release process as closely as
possible, but as noted elsewhere in this thread, those changes are not
always well communicated. The devtools philosophy is "anything that
can be automated, should be automated".

You may also be eligible for the devtools guarantee: "if because of a
bug in devtools a member of R-core gets angry with you, I will send
you a handwritten apology note. Just forward me the email and your
address, and I'll get a card in the mail."

Hadley

-- 
http://had.co.nz/


From geoffjentry at hexdump.org  Thu Aug 21 17:07:46 2014
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Thu, 21 Aug 2014 08:07:46 -0700 (PDT)
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <53F39D42.9070708@gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<53F35729.2090301@gmail.com>
	<53F38EBC.8010809@statistik.tu-dortmund.de>
	<21491.37916.790888.953720@max.nulle.part>
	<CAN_1p9zjfN=Fokxc9++sPbdef91udg_YFH5eDoHiMrFkAz7B5w@mail.gmail.com>
	<53F39D42.9070708@gmail.com>
Message-ID: <alpine.DEB.2.00.1408210807130.30864@cardhu.dreamhost.com>

On Tue, 19 Aug 2014, Duncan Murdoch wrote:
> If you use this, make sure you test it well enough to get it perfect the very 
> first time you use it.  If I were a CRAN administrator and received a series 
> of bad submissions from someone who was working out the bugs, I would not 
> find it difficult either technically or morally to permanently ban that user 
> from ever submitting anything again.

I think what Duncan is saying here is to make sure to log in as Dirk 
before testing your potentially buggy CRAN webform submitter.


From luke-tierney at uiowa.edu  Thu Aug 21 17:09:39 2014
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 21 Aug 2014 10:09:39 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <CABdHhvHBp-tGgH4zsRC_WFRkpRzF936nv-0Pe=hG5DDGtCFcyw@mail.gmail.com>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<CABdHhvHBp-tGgH4zsRC_WFRkpRzF936nv-0Pe=hG5DDGtCFcyw@mail.gmail.com>
Message-ID: <alpine.LFD.2.10.1408211007580.2660@nokomis.stat.uiowa.edu>

On Thu, 21 Aug 2014, Hadley Wickham wrote:

> On Tue, Aug 19, 2014 at 8:28 AM, Richard Cotton <richierocks at gmail.com> wrote:
>> I recently tried to submit a package to CRAN using the release
>> function in the devtools package and got the response:
>>
>>> The policies asked you to use the webform: do so in future.
>>
>> I think that the relevant line in the policies are:
>>
>>> When submitting a package to CRAN you should use the submission form at
>>> http://CRAN.R-project.org/submit.html (and not send an email). You will be sent
>>> a confirmation email which needs to be accepted.
>>
>>> If this fails, upload by anonymous ftp to ftp://CRAN.R-project.org/incoming/ and
>>> send a (plain text ASCII) email at the same time, with subject line as specified below.
>>
>> As far as I know, the release function uses the second method, so I
>> don't quite understand what the problem is.
>
> The development version of devtools uses the web form method. I will
> endeavour to track changes to the CRAN release process as closely as
> possible, but as noted elsewhere in this thread, those changes are not
> always well communicated. The devtools philosophy is "anything that
> can be automated, should be automated".
>
> You may also be eligible for the devtools guarantee: "if because of a
> bug in devtools a member of R-core gets angry with you, I will send
> you a handwritten apology note. Just forward me the email and your
> address, and I'll get a card in the mail."
>
> Hadley
>
>

I think I'm seeing the Rcaptcha package on the horizon ...

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From h.wickham at gmail.com  Thu Aug 21 17:27:54 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 21 Aug 2014 10:27:54 -0500
Subject: [Rd] Is using devtools::release no longer allowed?
In-Reply-To: <alpine.LFD.2.10.1408211007580.2660@nokomis.stat.uiowa.edu>
References: <CAPp_+=f5V4GmfndxD-e96Er+kqVB0kKtYQfUHK8XvMFKXw3USg@mail.gmail.com>
	<CABdHhvHBp-tGgH4zsRC_WFRkpRzF936nv-0Pe=hG5DDGtCFcyw@mail.gmail.com>
	<alpine.LFD.2.10.1408211007580.2660@nokomis.stat.uiowa.edu>
Message-ID: <CABdHhvExa19QMsZNpJk5Ep9X13HyUmjOJK1jaADjaku_k6wJ7w@mail.gmail.com>

> I think I'm seeing the Rcaptcha package on the horizon ...

Devtools actually makes you perform a cognitively challenge set of
tasks before submitting. One of them is:

Have you read and do you agree to the the CRAN policies?
(http://cran.r-project.org/web/packages/policies.html)
1: No way
2: No
3: For sure

Each time the function is run both the answers are randomised so the
next time you might get

Have you read and do you agree to the the CRAN policies?
(http://cran.r-project.org/web/packages/policies.html)
1: Not yet
2: Definitely
3: Nope

The goal is to force you (as much as possible) to actually read the
question and think about the answer.

Hadley


-- 
http://had.co.nz/


From simon.urbanek at r-project.org  Thu Aug 21 17:58:18 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 21 Aug 2014 11:58:18 -0400
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <69D351C3-AA81-430E-8F66-D06863C18702@me.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>
Message-ID: <E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>


On Aug 21, 2014, at 6:40 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

> On Aug 21, 2014, at 3:11 AM, Gaurav Sehrawat <igauravsehrawat at gmail.com> wrote:
> 
>> R-Project is missing something important in regards to its development ,
>> one simply can't ignore Github ,where collaboration is at it's best .
>> 
>> OR If i am wrong is this the correct R-source :
>> https://github.com/wch/r-source
>> 
>> Is anyone thinking to bring R-project org on Github ? Maybe there might be
>> some difficulty while porting its version system to Github .
>> 
>> Just a suggestion .
>> 
>> Thanks
>> Gaurav Sehrawat
>> http://igauravsehrawat.com
> 
> 
> The link you have above is to a read-only mirror (perhaps not the only one) of the R source code that is kept in the official Subversion repo:
> 
>  https://svn.r-project.org/R/
> 
> There are also some documents that describe R's development cycle and related processes:
> 
>  http://www.r-project.org/certification.html
> 
> Your suggestion to move to Github is perhaps based upon a false premise, that the R community at large has the ability to directly post code/patches to the official distribution. We can contribute code and patches, primarily here on R-Devel, to the code base. However, only the members of R Core team (http://www.r-project.org/contributors.html) have write access to the SVN repo above and have to approve any such contributions.
> 

How is this different from Github? Github just makes it much easier to create and post patches to the project - it has nothing to do with write access - typically on Github the community has no write access, either. Using pull requests is certainly much less fragile than e-mails and patches are based on forked branches, so you can directly build the patched version if you want without manually applying the patch - and you see the whole history so you can pick out things logically. You can comment on individual patches to discuss them and even individual commits - often leading to a quick round trip time of revising it.

Cheers,
Simon


> Since the current SVN based system works well for them and provides restricted write access that they can control, there is no motivation to move to an alternative version control system unless they would find it to be superior for their own development processes.
> 
> That being said, there are a number of contributing projects that have packages on CRAN, that do use Github, myself included. There is also R-Forge (https://r-forge.r-project.org), which provides another SVN based platform for community package development.
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ucfagls at gmail.com  Thu Aug 21 20:32:31 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Thu, 21 Aug 2014 12:32:31 -0600
Subject: [Rd] Inconsistent handling of data frames in min(), max(),
	and mean()
Message-ID: <CAAHES9xbRKCaoxurSHHNtnwKnk6vaVUrXQ30KNfpy=W-ATF+qQ@mail.gmail.com>

This inconsistency recently came to my attention:

> df <- data.frame(A = 1:10, B = rnorm(10))
> min(df)
[1] -1.768958
> max(df)
[1] 10
> mean(df)
[1] NA
Warning message:
In mean.default(df) : argument is not numeric or logical: returning NA

I recall the times where `mean(df)` would give `colMeans(df)` and this
behaviour was deemed inconsistent. It seems though that the change has
removed one inconsistency and replaced it with another.

Am I missing good reasons why there couldn't be a `mean.data.frame()`
method which worked like `max()` etc when given a data frame? Namely that
they return the required statistic *only* when presented with a data frame
of all numeric variables? E.g.

> df <- data.frame(A = 1:10, B = rnorm(10), C = factor(rep(c("A","B"), each
= 5)))
> max(df)
Error in FUN(X[[1L]], ...) :
  only defined on a data frame with all numeric variables

I would expect `mean(df)` to fail with the same error as for `max(df)` with
the new example `df` but for would return the same as `mean(as.matrix(df))`
or `mean(colMeans(df))` if given an entirely numeric data frame:

> mean(colMeans(df[, 1:2]))
[1] 2.78366
> mean(as.matrix(df[, 1:2]))
[1] 2.78366
> mean(df[,1:2])
[1] 2.78366

I just can't see the sense in having `mean` work the way it does now?

Thanks,

Gavin

-- 

Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From xie at yihui.name  Fri Aug 22 06:00:04 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 21 Aug 2014 23:00:04 -0500
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>
	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>
Message-ID: <CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>

As someone who has merged more than a hundred pull requests on Github,
I cannot agree more. Sometimes I can take patches on my mobile phone
while I'm still in bed if they look reasonable and simple enough.
Sometimes the patches are not worth emails back and forth, such as the
correction of typos. I cannot think of anything else that is more
efficient than being able to discuss the patch right in the lines of
diff's.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Aug 21, 2014 at 10:58 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Aug 21, 2014, at 6:40 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Aug 21, 2014, at 3:11 AM, Gaurav Sehrawat <igauravsehrawat at gmail.com> wrote:
>>
>>> R-Project is missing something important in regards to its development ,
>>> one simply can't ignore Github ,where collaboration is at it's best .
>>>
>>> OR If i am wrong is this the correct R-source :
>>> https://github.com/wch/r-source
>>>
>>> Is anyone thinking to bring R-project org on Github ? Maybe there might be
>>> some difficulty while porting its version system to Github .
>>>
>>> Just a suggestion .
>>>
>>> Thanks
>>> Gaurav Sehrawat
>>> http://igauravsehrawat.com
>>
>>
>> The link you have above is to a read-only mirror (perhaps not the only one) of the R source code that is kept in the official Subversion repo:
>>
>>  https://svn.r-project.org/R/
>>
>> There are also some documents that describe R's development cycle and related processes:
>>
>>  http://www.r-project.org/certification.html
>>
>> Your suggestion to move to Github is perhaps based upon a false premise, that the R community at large has the ability to directly post code/patches to the official distribution. We can contribute code and patches, primarily here on R-Devel, to the code base. However, only the members of R Core team (http://www.r-project.org/contributors.html) have write access to the SVN repo above and have to approve any such contributions.
>>
>
> How is this different from Github? Github just makes it much easier to create and post patches to the project - it has nothing to do with write access - typically on Github the community has no write access, either. Using pull requests is certainly much less fragile than e-mails and patches are based on forked branches, so you can directly build the patched version if you want without manually applying the patch - and you see the whole history so you can pick out things logically. You can comment on individual patches to discuss them and even individual commits - often leading to a quick round trip time of revising it.
>
> Cheers,
> Simon


From rdevelmail at 163.com  Fri Aug 22 08:32:22 2014
From: rdevelmail at 163.com (PO SU)
Date: Fri, 22 Aug 2014 14:32:22 +0800 (CST)
Subject: [Rd] [R-devel] what are labels in struct sxpinfo_struct from
 Rinternals.h mean?
Message-ID: <1f556350.17e90.147fc6a7bc9.Coremail.rdevelmail@163.com>


Dear Rdevelers,
? ? ?The following struct is in the Rinternals.h. I want to know ?the meanings of labels or names like "gp,mark,obj,named,trace....." . TKS!


struct sxpinfo_struct {
? ? SEXPTYPE type ? ? ?: ?5;/* ==> (FUNSXP == 99) %% 2^5 == 3 == CLOSXP
			 ? ? * -> warning: `type' is narrower than values
			 ? ? * ? ? ? ? ? ? ?of its type
			 ? ? * when SEXPTYPE was an enum */
? ? unsigned int obj ? : ?1;
? ? unsigned int named : ?2;
? ? unsigned int gp ? ?: 16;
? ? unsigned int mark ?: ?1;
? ? unsigned int debug : ?1;
? ? unsigned int trace : ?1; ?/* functions and memory tracing */
? ? unsigned int spare : ?1; ?/* currently unused */
? ? unsigned int gcgen : ?1; ?/* old generation number */
? ? unsigned int gccls : ?3; ?/* node class */
}; /*		 ? ?Tot: 32 */




--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU

From ripley at stats.ox.ac.uk  Fri Aug 22 09:15:08 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 22 Aug 2014 08:15:08 +0100
Subject: [Rd] [R-devel] what are labels in struct sxpinfo_struct from
 Rinternals.h mean?
In-Reply-To: <1f556350.17e90.147fc6a7bc9.Coremail.rdevelmail@163.com>
References: <1f556350.17e90.147fc6a7bc9.Coremail.rdevelmail@163.com>
Message-ID: <53F6EDFC.3080207@stats.ox.ac.uk>

Once again[*], you really should study the posting guide.  The 
documentation is the 'R Internals manual', and it does cover this.

fortunes::fortune(14) applies.

[*] After two postings on R-help which ignored it, one reply to which 
pointed out this manual.

On 22/08/2014 07:32, PO SU wrote:
>
> Dear Rdevelers,
>       The following struct is in the Rinternals.h. I want to know  the meanings of labels or names like "gp,mark,obj,named,trace....." . TKS!
>
>
> struct sxpinfo_struct {
>      SEXPTYPE type      :  5;/* ==> (FUNSXP == 99) %% 2^5 == 3 == CLOSXP
> 			     * -> warning: `type' is narrower than values
> 			     *              of its type
> 			     * when SEXPTYPE was an enum */
>      unsigned int obj   :  1;
>      unsigned int named :  2;
>      unsigned int gp    : 16;
>      unsigned int mark  :  1;
>      unsigned int debug :  1;
>      unsigned int trace :  1;  /* functions and memory tracing */
>      unsigned int spare :  1;  /* currently unused */
>      unsigned int gcgen :  1;  /* old generation number */
>      unsigned int gccls :  3;  /* node class */
> }; /*		    Tot: 32 */
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From maechler at stat.math.ethz.ch  Fri Aug 22 10:23:45 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Aug 2014 10:23:45 +0200
Subject: [Rd] Inconsistent handling of data frames in min(), max(),
	and mean()
In-Reply-To: <CAAHES9xbRKCaoxurSHHNtnwKnk6vaVUrXQ30KNfpy=W-ATF+qQ@mail.gmail.com>
References: <CAAHES9xbRKCaoxurSHHNtnwKnk6vaVUrXQ30KNfpy=W-ATF+qQ@mail.gmail.com>
Message-ID: <21494.65041.729804.184640@stat.math.ethz.ch>

>>>>> Gavin Simpson <ucfagls at gmail.com>
>>>>>     on Thu, 21 Aug 2014 12:32:31 -0600 writes:

    > This inconsistency recently came to my attention:
    >> df <- data.frame(A = 1:10, B = rnorm(10)) 
    >> min(df)
    > [1] -1.768958
    >> max(df)
    > [1] 10
    >> mean(df)
    > [1] NA Warning message: In mean.default(df) : argument is
    > not numeric or logical: returning NA

I would tend to agree (:-) that mean() should rather give an error here
(and read on).

    > I recall the times where `mean(df)` would give
    > `colMeans(df)` and this behaviour was deemed
    > inconsistent. 
    
    > It seems though that the change has removed one
    > inconsistency and replaced it with another. 

The whole idea of removing the mean method for data frames was
that there are many more summary functions, e.g. median, and it
seems wrong to write a data frame method for each of them; then
why for *some* of them.
So we *did* keep the  Summary.data.frame  group method,
and that's why min(), max(), sum(),.. work  {though sum() will be
slightly slower than colSums()}.

When teaching R, the audience should learn to use  apply() or
similar functions, e.g. from the hadleyverse,
because that is the general approach of dealing with matrix-like
objects that is indeed how I think users should start thinking
of data frames.


    > Am I missing good reasons why there couldn't be a
    > `mean.data.frame()` method which worked like `max()` etc
    > when given a data frame?
yes, see above.
[ There's no consistent end after that: Why is median() different, why would
 sd(), var(), ... not work ?]

    >  Namely that they return the
    > required statistic *only* when presented with a data frame
    > of all numeric variables? E.g.

    >> df <- data.frame(A = 1:10, B = rnorm(10), C =
    >> factor(rep(c("A","B"), each
    > = 5)))
    >> max(df)
    > Error in FUN(X[[1L]], ...) : only defined on a data frame
    > with all numeric variables

    > I would expect `mean(df)` to fail with the same error as
    > for `max(df)` with the new example `df` but for would
    > return the same as `mean(as.matrix(df))` or
    > `mean(colMeans(df))` if given an entirely numeric data
    > frame:

    >> mean(colMeans(df[, 1:2]))
    > [1] 2.78366
    >> mean(as.matrix(df[, 1:2]))
    > [1] 2.78366
    >> mean(df[,1:2])
    > [1] 2.78366

    > I just can't see the sense in having `mean` work the way
    > it does now?

I agree. It would be better to give an error.
E.g.,  mean.default could start with  

    if(is.object(x)) 
       stop("there is no mean() method for ", class(x)[1], " objects")


    > Thanks,
    > Gavin

    > -- 

    > Gavin Simpson, PhD

    > 	[[alternative HTML version deleted]]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 ( hmmm... and that on R-devel ... )


From leo.lahti at iki.fi  Fri Aug 22 12:09:42 2014
From: leo.lahti at iki.fi (Leo Lahti)
Date: Fri, 22 Aug 2014 12:09:42 +0200
Subject: [Rd] markdown vignette with the vignette command
Message-ID: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>

Dear list,

we have a markdown vignette for our package in vignette/vignette.md

This is not visible from within R with the vignette(package = "mypackage")
command.

I assume the reason is that the vignette function only shows PDF vignettes.
Is there any way to circumvent this and display markdown vignettes directly
from within R?

I tried to seek the answer from R archives and search engines but could not
find the solution so far.

best regards,
Leo Lahti

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Aug 22 13:04:57 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 Aug 2014 07:04:57 -0400
Subject: [Rd] markdown vignette with the vignette command
In-Reply-To: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>
References: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>
Message-ID: <53F723D9.8010707@gmail.com>

On 22/08/2014, 6:09 AM, Leo Lahti wrote:
> Dear list,
> 
> we have a markdown vignette for our package in vignette/vignette.md
> 
> This is not visible from within R with the vignette(package = "mypackage")
> command.
> 
> I assume the reason is that the vignette function only shows PDF vignettes.
> Is there any way to circumvent this and display markdown vignettes directly
> from within R?
> 
> I tried to seek the answer from R archives and search engines but could not
> find the solution so far.
> 

If you are using a current version of R, it should just work.  For example,

vignette("knitr-markdown")

works for me when knitr is attached.  If knitr was not attached, I'd
have to list it in the pkg argument of the vignette call.

Duncan Murdoch


From leo.lahti at iki.fi  Fri Aug 22 14:06:33 2014
From: leo.lahti at iki.fi (Leo Lahti)
Date: Fri, 22 Aug 2014 14:06:33 +0200
Subject: [Rd] markdown vignette with the vignette command
In-Reply-To: <53F723D9.8010707@gmail.com>
References: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>
	<53F723D9.8010707@gmail.com>
Message-ID: <CAHm4+KAEUeVwhsrikeiiJ8OYxiLdGN+W7yS1odu9TaXFe2A3aw@mail.gmail.com>

Solved, thanks!

Leo


On Fri, Aug 22, 2014 at 1:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 22/08/2014, 6:09 AM, Leo Lahti wrote:
> > Dear list,
> >
> > we have a markdown vignette for our package in vignette/vignette.md
> >
> > This is not visible from within R with the vignette(package =
> "mypackage")
> > command.
> >
> > I assume the reason is that the vignette function only shows PDF
> vignettes.
> > Is there any way to circumvent this and display markdown vignettes
> directly
> > from within R?
> >
> > I tried to seek the answer from R archives and search engines but could
> not
> > find the solution so far.
> >
>
> If you are using a current version of R, it should just work.  For example,
>
> vignette("knitr-markdown")
>
> works for me when knitr is attached.  If knitr was not attached, I'd
> have to list it in the pkg argument of the vignette call.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Aug 22 14:36:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 Aug 2014 08:36:52 -0400
Subject: [Rd] markdown vignette with the vignette command
In-Reply-To: <CAHm4+KAEUeVwhsrikeiiJ8OYxiLdGN+W7yS1odu9TaXFe2A3aw@mail.gmail.com>
References: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>	<53F723D9.8010707@gmail.com>
	<CAHm4+KAEUeVwhsrikeiiJ8OYxiLdGN+W7yS1odu9TaXFe2A3aw@mail.gmail.com>
Message-ID: <53F73964.1010303@gmail.com>

On 22/08/2014 8:06 AM, Leo Lahti wrote:
> Solved, thanks!
>
Could you post a short description of the solution, in case this problem 
arises for anyone else?  These posts are archived, and can be a useful 
resource for others.

Duncan Murdoch

>
> On Fri, Aug 22, 2014 at 1:04 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 22/08/2014, 6:09 AM, Leo Lahti wrote:
>     > Dear list,
>     >
>     > we have a markdown vignette for our package in
>     vignette/vignette.md <http://vignette.md>
>     >
>     > This is not visible from within R with the vignette(package =
>     "mypackage")
>     > command.
>     >
>     > I assume the reason is that the vignette function only shows PDF
>     vignettes.
>     > Is there any way to circumvent this and display markdown
>     vignettes directly
>     > from within R?
>     >
>     > I tried to seek the answer from R archives and search engines
>     but could not
>     > find the solution so far.
>     >
>
>     If you are using a current version of R, it should just work.  For
>     example,
>
>     vignette("knitr-markdown")
>
>     works for me when knitr is attached.  If knitr was not attached, I'd
>     have to list it in the pkg argument of the vignette call.
>
>     Duncan Murdoch
>
>


From leo.lahti at iki.fi  Fri Aug 22 14:42:10 2014
From: leo.lahti at iki.fi (Leo Lahti)
Date: Fri, 22 Aug 2014 14:42:10 +0200
Subject: [Rd] markdown vignette with the vignette command
In-Reply-To: <53F73964.1010303@gmail.com>
References: <CAHm4+KC4yDmHbTMHm7gOSTUzAoqfut4vJ0ZRbOVEeJw5RBm1cw@mail.gmail.com>
	<53F723D9.8010707@gmail.com>
	<CAHm4+KAEUeVwhsrikeiiJ8OYxiLdGN+W7yS1odu9TaXFe2A3aw@mail.gmail.com>
	<53F73964.1010303@gmail.com>
Message-ID: <CAHm4+KAqHahRMt7Pn+jFCnE4CSW+SwZOKwwNSLC+MZWX=PcHBQ@mail.gmail.com>

I followed the instructions in
http://cran.r-project.org/web/packages/knitr/vignettes/knitr-markdown.html

   - add *.Rmd files under the vignettes directory
   - add VignetteBuilder: knitr to the DESCRIPTION file
   - specify the vignette engine \VignetteEngine{knitr::knitr} in the Rmd
   files (inside HTML comments)

Leo


On Fri, Aug 22, 2014 at 2:36 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 22/08/2014 8:06 AM, Leo Lahti wrote:
>
>> Solved, thanks!
>>
>>  Could you post a short description of the solution, in case this problem
> arises for anyone else?  These posts are archived, and can be a useful
> resource for others.
>
> Duncan Murdoch
>
>
>> On Fri, Aug 22, 2014 at 1:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 22/08/2014, 6:09 AM, Leo Lahti wrote:
>>     > Dear list,
>>     >
>>     > we have a markdown vignette for our package in
>>     vignette/vignette.md <http://vignette.md>
>>
>>     >
>>     > This is not visible from within R with the vignette(package =
>>     "mypackage")
>>     > command.
>>     >
>>     > I assume the reason is that the vignette function only shows PDF
>>     vignettes.
>>     > Is there any way to circumvent this and display markdown
>>     vignettes directly
>>     > from within R?
>>     >
>>     > I tried to seek the answer from R archives and search engines
>>     but could not
>>     > find the solution so far.
>>     >
>>
>>     If you are using a current version of R, it should just work.  For
>>     example,
>>
>>     vignette("knitr-markdown")
>>
>>     works for me when knitr is attached.  If knitr was not attached, I'd
>>     have to list it in the pkg argument of the vignette call.
>>
>>     Duncan Murdoch
>>
>>
>>
>

	[[alternative HTML version deleted]]


From henrik.singmann at psychologie.uni-freiburg.de  Fri Aug 22 19:05:45 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Fri, 22 Aug 2014 19:05:45 +0200
Subject: [Rd] How to (appropropriately) use require in a package?
In-Reply-To: <CANz9Z_K5RjAKM0J7g71PJM6e6n58ez9hmPfkQ=GTgkgwqMTjsQ@mail.gmail.com>
References: <CANz9Z_+MukG_A8fc-3+b9_m6=R2tDGrq+w1WKECbFK2BNeK4sA@mail.gmail.com>	<CANz9Z_KqOMyRJ0XGr+eCYs5yzYc=v6gXptL+wZN3TpGNLyDMrw@mail.gmail.com>	<53E47285.4030604@stats.ox.ac.uk>
	<CANz9Z_K5RjAKM0J7g71PJM6e6n58ez9hmPfkQ=GTgkgwqMTjsQ@mail.gmail.com>
Message-ID: <53F77869.3030501@psychologie.uni-freiburg.de>

Dear Joshua,

Sorry for resurrecting this thread, but I was on holidays earlier. I also had that problem and unfortunately using loadNamespace() as suggested by Prof. Ripley didn't work in my case (the reason is that the cluster is created by the user and the call executed on the cluster can contain additional function calls from the loaded package which are passed by the user).

I settled on the following construct that doesn't seem to raise issues with R CMD check:

junk <- clusterCall(cl = cl, "require", package = "lme4", character.only = TRUE)

Let's hope it continues to not raise any flags.

Best,
Henrik


Am 08.08.2014 09:22, schrieb Joshua Wiley:
> Dear Professor Ripley,
>
> PkgB does not need to be on the search path---importing into the namespace
> is fine.  I did not realize that namespace scoping ensured that if a
> cluster is created from within a package, that packages entire environment
> tree is available on all the workers.
> I tried to apply how makeCluster works from an interactive R session, where
> functions from packages that are loaded when the cluster is created are not
> available on the workers, to how it works from within a package.
>
> Thanks for your reply,
>
> Josh
>
>
>
> On Fri, Aug 8, 2014 at 4:47 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
>
>> The safe, elegant way to do this is to use namespace scoping: it is still
>> not at all clear why 'other code' needs PkgB *on the search path*.
>>
>> In other cases seen in CRAN submissions, 'other code' has been in PkgA's
>> namespace, and hence things in PkgB's exports have been visible as it was
>> imported by PkgA and hence in the environment tree for functions in PkgA.
>>   Then namespace scoping will ensure that PkgB's namespace is loaded on the
>> cluster workers.
>>
>>
>>
>> On 08/08/2014 00:58, Joshua Wiley wrote:
>>
>>> Someone kindly pointed out that it is not clear from my email why Depends
>>> will not work.  A more complete example is:
>>>
>>> PkgA:
>>> f <- function(ncores) {
>>>     cl <- makeCluster(ncores)
>>>
>>>     clusterEvalQ(cl, {
>>>       require(PkgB)
>>>     })
>>>     [other code]
>>>
>>>     ### this is the code I want to work and need to be able to call
>>>     ### PkgB functions on each of the cluster slaves
>>>     output <- parLapply(cl, 1:n, function(i) {
>>>       [code from my package and using some functions from PkgB]
>>>     })
>>>
>>> }
>>>
>>> As far as I know, just because I add PkgB to the Depends (or imports,
>>> whatever) of PkgA, does not mean that the cluster started by PkgA will
>>> automatically have PkgB loaded and functions available.
>>>
>>> Thanks!
>>>
>>>
>>>
>>> On Fri, Aug 8, 2014 at 9:35 AM, Joshua Wiley <jwiley.psych at gmail.com>
>>> wrote:
>>>
>>>   Dear All,
>>>>
>>>> What is the preferred way for Package A, to initialize a cluster, and
>>>> load
>>>> Package B on all nodes?
>>>>
>>>> I am writing a package that parallelizes some functions through the use
>>>> of
>>>> a cluster if useRs are on a Windows machine (using parLapply and family).
>>>>    I also make use of another package in some of my code, so it is
>>>> necessary
>>>> to load the required packages on each slave once the cluster is started.
>>>>
>>>> Right now, I have done this, by evaluating require(packages) on each
>>>> slave; however, Rcmd check has a note that I should remove the "require"
>>>> in
>>>> my code.
>>>>
>>>> Thanks!
>>>>
>>>> Josh
>>>>
>>>> --
>>>> Joshua F. Wiley
>>>> Ph.D. Student, UCLA Department of Psychology
>>>> http://joshuawiley.com/
>>>> Senior Analyst, Elkhart Group Ltd.
>>>> http://elkhartgroup.com
>>>> Office: 260.673.5518
>>>>
>>>>
>>>
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
>

-- 
Dr. Henrik Singmann
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From ucfagls at gmail.com  Fri Aug 22 20:51:15 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 22 Aug 2014 12:51:15 -0600
Subject: [Rd] Inconsistent handling of data frames in min(), max(),
	and mean()
In-Reply-To: <21494.65041.729804.184640@stat.math.ethz.ch>
References: <CAAHES9xbRKCaoxurSHHNtnwKnk6vaVUrXQ30KNfpy=W-ATF+qQ@mail.gmail.com>
	<21494.65041.729804.184640@stat.math.ethz.ch>
Message-ID: <CAAHES9y4MobWUrHx2uawspsOnNzsobqpAh2-+poW-fS0ssmB0A@mail.gmail.com>

Thanks Martin

(sorry about the HTML - GMail and my incompetent use of it; hopefully I've
beaten it into submission this time).

I can see the point of view, however the inconsistency remains whether one
patches the other summary stat functions to work as if given a matrix or
squash all the Summary.data.frame methods as well.

More comments in-line

On 22 August 2014 02:23, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> >>>>> Gavin Simpson <ucfagls at gmail.com>
> >>>>>     on Thu, 21 Aug 2014 12:32:31 -0600 writes:
>
 <snip/>

>     >> mean(df)
>     > [1] NA Warning message: In mean.default(df) : argument is
>     > not numeric or logical: returning NA
>
> I would tend to agree (:-) that mean() should rather give an error here
> (and read on).
>
>     > I recall the times where `mean(df)` would give
>     > `colMeans(df)` and this behaviour was deemed
>     > inconsistent.
>
>     > It seems though that the change has removed one
>     > inconsistency and replaced it with another.
>
> The whole idea of removing the mean method for data frames was
> that there are many more summary functions, e.g. median, and it
> seems wrong to write a data frame method for each of them; then
> why for *some* of them.
> So we *did* keep the  Summary.data.frame  group method,
> and that's why min(), max(), sum(),.. work  {though sum() will be
> slightly slower than colSums()}.
>

and gives a different answer, unless you meant sum(colSums(df)) == sum(df)?


> When teaching R, the audience should learn to use  apply() or
> similar functions, e.g. from the hadleyverse,
> because that is the general approach of dealing with matrix-like
> objects that is indeed how I think users should start thinking
> of data frames.


This actually came up because someone was wanting the mean over all columns
(of a dataset where columns represented repeated measures per patient,
rows), hence `apply()` is not really suitable here and we've switched the
example to do `mean(as.matrix(df))` to get what they wanted.

I wasn't suggesting having `mean()` do anything like `colMeans()` or the
`mean.data.frame` of old.

I was wondering why we couldn't gain some semblance of consistency by
making *all* (although I didn't mention them) these related functions work
on a data frame (with all numeric columns) as if it were a matrix, just
like `min()`, `max()`, `range()` etc do now.

    > Am I missing good reasons why there couldn't be a
>     > `mean.data.frame()` method which worked like `max()` etc
>     > when given a data frame?
> yes, see above.
> [ There's no consistent end after that: Why is median() different, why
> would
>  sd(), var(), ... not work ?]


I don't see why they shouldn't if `max()` etc work *for an entirely numeric
data frame*.


>     >  Namely that they return the

    > required statistic *only* when presented with a data frame
>     > of all numeric variables? E.g.
>
<snip />

>     > I just can't see the sense in having `mean` work the way
>     > it does now?
>
> I agree. It would be better to give an error.
> E.g.,  mean.default could start with
>
>     if(is.object(x))
>        stop("there is no mean() method for ", class(x)[1], " objects")


That would give a nicer error message but wouldn't solve the deeper issue
of a lack of consistency, which *is* an issue for people when trying to
learn R.

So, can't we either kill off the summary group method for data frames or
identify a set of functions which should work similarly to the existing
summary group method members? Assuming that a patch would be forthcoming
with documentation rather than relying on RCore to do this manually?


>     > Thanks,
>     > Gavin
>
>     > --
>
>     > Gavin Simpson, PhD
>
>     >   [[alternative HTML version deleted]]
>         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>  ( hmmm... and that on R-devel ... )
>

Yeah, sorry. Hopefully fixed now!


G

-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From marius.hofert at uwaterloo.ca  Fri Aug 22 22:03:13 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 22 Aug 2014 16:03:13 -0400
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
Message-ID: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>

Hi,

Both under the current R-devel (r66456) and a version from about 3
months ago, I experience the following behavior:

> parallel::detectCores(TRUE)
Error in system(cmd, TRUE) : error in running command
> traceback()
3: system(cmd, TRUE)
2: gsub("^ +", "", system(cmd, TRUE)[1])
1: parallel::detectCores(TRUE)
>

This is on Ubuntu 14.04. Does anybody else see this? [I currently have
quite a heavy workload, otherwise I would have installed and tested it
also under 3.1.1]

Cheers,

Marius


From tobias.verbeke at openanalytics.eu  Fri Aug 22 23:18:18 2014
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Fri, 22 Aug 2014 23:18:18 +0200 (CEST)
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
Message-ID: <1053586613.144079.1408742298054.JavaMail.zimbra@openanalytics.eu>

----- Original Message -----
> From: "Marius Hofert" <marius.hofert at uwaterloo.ca>
> To: "R-devel" <r-devel at r-project.org>
> Sent: Friday, August 22, 2014 10:03:13 PM
> Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd, TRUE) : error in running command
> 
> Hi,
> 
> Both under the current R-devel (r66456) and a version from about 3
> months ago, I experience the following behavior:
> 
> > parallel::detectCores(TRUE)
> Error in system(cmd, TRUE) : error in running command
> > traceback()
> 3: system(cmd, TRUE)
> 2: gsub("^ +", "", system(cmd, TRUE)[1])
> 1: parallel::detectCores(TRUE)
> >
> 
> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
> quite a heavy workload, otherwise I would have installed and tested it
> also under 3.1.1]

Same under R 3.1.1

> parallel::detectCores(TRUE)
Error in system(cmd, TRUE) : error in running command

Best,
Tobias


From ruipbarradas at sapo.pt  Fri Aug 22 23:53:35 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 22 Aug 2014 22:53:35 +0100
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <1053586613.144079.1408742298054.JavaMail.zimbra@openanalytics.eu>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<1053586613.144079.1408742298054.JavaMail.zimbra@openanalytics.eu>
Message-ID: <53F7BBDF.8010606@sapo.pt>

Hello,

Inline.

Em 22-08-2014 22:18, Tobias Verbeke escreveu:
> ----- Original Message -----
>> From: "Marius Hofert" <marius.hofert at uwaterloo.ca>
>> To: "R-devel" <r-devel at r-project.org>
>> Sent: Friday, August 22, 2014 10:03:13 PM
>> Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd, TRUE) : error in running command
>>
>> Hi,
>>
>> Both under the current R-devel (r66456) and a version from about 3
>> months ago, I experience the following behavior:
>>
>>> parallel::detectCores(TRUE)
>> Error in system(cmd, TRUE) : error in running command
>>> traceback()
>> 3: system(cmd, TRUE)
>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>> 1: parallel::detectCores(TRUE)
>>>
>>
>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>> quite a heavy workload, otherwise I would have installed and tested it
>> also under 3.1.1]
>
> Same under R 3.1.1
>
>> parallel::detectCores(TRUE)
> Error in system(cmd, TRUE) : error in running command

I'm Using R 3.1.1 on Windows 7 and it works.

 > parallel::detectCores(TRUE)
[1] 4
 > sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] parallel_3.1.1

Rui Barradas
>
> Best,
> Tobias
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Sat Aug 23 00:13:40 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 22 Aug 2014 15:13:40 -0700
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
Message-ID: <CAF8bMcZ7OLT=z-Tdk_zMtVj2F_YV=a268gPfdRHccwFUGSxtFA@mail.gmail.com>

The same is true in R-2.14.1 on  Ubuntu 12.04.4 LTS .  Put a trace on
system with
  trace(system, quote(print(command)))
  parallel::detectCores(TRUE)
and you will see the offending shell command.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 22, 2014 at 1:03 PM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Hi,
>
> Both under the current R-devel (r66456) and a version from about 3
> months ago, I experience the following behavior:
>
>> parallel::detectCores(TRUE)
> Error in system(cmd, TRUE) : error in running command
>> traceback()
> 3: system(cmd, TRUE)
> 2: gsub("^ +", "", system(cmd, TRUE)[1])
> 1: parallel::detectCores(TRUE)
>>
>
> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
> quite a heavy workload, otherwise I would have installed and tested it
> also under 3.1.1]
>
> Cheers,
>
> Marius
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dwinsemius at comcast.net  Sat Aug 23 00:41:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Aug 2014 15:41:23 -0700
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
	TRUE) : error in running command
In-Reply-To: <53F7BBDF.8010606@sapo.pt>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<1053586613.144079.1408742298054.JavaMail.zimbra@openanalytics.eu>
	<53F7BBDF.8010606@sapo.pt>
Message-ID: <92742B4C-3D01-49D6-8B71-FE0C6D9F6712@comcast.net>


On Aug 22, 2014, at 2:53 PM, Rui Barradas wrote:

> Hello,
> 
> Inline.
> 
> Em 22-08-2014 22:18, Tobias Verbeke escreveu:
>> ----- Original Message -----
>>> From: "Marius Hofert" <marius.hofert at uwaterloo.ca>
>>> To: "R-devel" <r-devel at r-project.org>
>>> Sent: Friday, August 22, 2014 10:03:13 PM
>>> Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd, TRUE) : error in running command
>>> 
>>> Hi,
>>> 
>>> Both under the current R-devel (r66456) and a version from about 3
>>> months ago, I experience the following behavior:
>>> 
>>>> parallel::detectCores(TRUE)
>>> Error in system(cmd, TRUE) : error in running command
>>>> traceback()
>>> 3: system(cmd, TRUE)
>>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>>> 1: parallel::detectCores(TRUE)
>>>> 
>>> 
>>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>>> quite a heavy workload, otherwise I would have installed and tested it
>>> also under 3.1.1]
>> 
>> Same under R 3.1.1
>> 
>>> parallel::detectCores(TRUE)
>> Error in system(cmd, TRUE) : error in running command
> 
> I'm Using R 3.1.1 on Windows 7 and it works.
> 
> > parallel::detectCores(TRUE)
> [1] 4
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)

Works on a 6 year-old MacPro with R 3.1.0

>  parallel::detectCores(TRUE)
[1] 8

>  sessionInfo()
R version 3.1.0 Patched (2014-04-21 r65431)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

-- 
david.

> 


David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sat Aug 23 00:57:35 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 22 Aug 2014 15:57:35 -0700
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<51eca682339a4cb5b14cc327e37ff02a@CONNHUB4.connect.uwaterloo.ca>
	<CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>
Message-ID: <CAF8bMcYVJN_mziYEoVAHkxJv9rxPxvm9Qv501iYm8o4NRsABxQ@mail.gmail.com>

There is no /usr/sbin/sysctl on my Ubuntu 12.04 machine.  There is a
/sbin/sysctl, but it does not accept the '-n hw.ncpu' arguments.  Its
/usr/bin/nproc [-all] will tell the number of available [installed]
processing units and 'cat /proc/cpuinfo | grep processor | wc -l' will
also give the number of installed processing units.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 22, 2014 at 3:17 PM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Thanks, Bill. The output is:
>
>> trace(system, quote(print(command)))
>   parallel::detectCores(TRUE)
> Tracing function "system" in package "base"
> [1] "system"
>>
> Tracing system(cmd, TRUE) on entry
> [1] "/usr/sbin/sysctl -n hw.ncpu 2>/dev/null"
> Error in system(cmd, TRUE) : error in running command
>>
>
> On Fri, Aug 22, 2014 at 6:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> The same is true in R-2.14.1 on  Ubuntu 12.04.4 LTS .  Put a trace on
>> system with
>>   trace(system, quote(print(command)))
>>   parallel::detectCores(TRUE)
>> and you will see the offending shell command.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Aug 22, 2014 at 1:03 PM, Marius Hofert
>> <marius.hofert at uwaterloo.ca> wrote:
>>> Hi,
>>>
>>> Both under the current R-devel (r66456) and a version from about 3
>>> months ago, I experience the following behavior:
>>>
>>>> parallel::detectCores(TRUE)
>>> Error in system(cmd, TRUE) : error in running command
>>>> traceback()
>>> 3: system(cmd, TRUE)
>>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>>> 1: parallel::detectCores(TRUE)
>>>>
>>>
>>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>>> quite a heavy workload, otherwise I would have installed and tested it
>>> also under 3.1.1]
>>>
>>> Cheers,
>>>
>>> Marius
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From mauricio.zambrano at udec.cl  Sat Aug 23 00:15:49 2014
From: mauricio.zambrano at udec.cl (Mauricio Zambrano-Bigiarini)
Date: Fri, 22 Aug 2014 18:15:49 -0400
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
Message-ID: <53F7C115.9030608@udec.cl>



On 22/08/14 16:03, Marius Hofert wrote:
> Hi,
>
> Both under the current R-devel (r66456) and a version from about 3
> months ago, I experience the following behavior:
>
>> parallel::detectCores(TRUE)
> Error in system(cmd, TRUE) : error in running command
>> traceback()
> 3: system(cmd, TRUE)
> 2: gsub("^ +", "", system(cmd, TRUE)[1])
> 1: parallel::detectCores(TRUE)
>>
>
> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
> quite a heavy workload, otherwise I would have installed and tested it
> also under 3.1.1]

I also get the same error:

Error in system(cmd, TRUE) : error in running command


R 3.1.1 on Linux Mint 17 (based on Ubuntu 14.04)

sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] raster_2.2-31 sp_1.0-15

loaded via a namespace (and not attached):
[1] grid_3.1.1      lattice_0.20-29 tools_3.1.1

Cheers,

Mauricio

-- 
=======================================================
Assistant Professor,
Faculty of Environmental Sciences and EULA-Chile Centre
University of Concepcion, Concepcion, Chile
=======================================================
"The only things in life you regret, are
the risks that you didn't take" (Anonymous)
=======================================================
Linux user #454569 -- Linux Mint user

From marius.hofert at uwaterloo.ca  Sat Aug 23 00:17:25 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 22 Aug 2014 18:17:25 -0400
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <51eca682339a4cb5b14cc327e37ff02a@CONNHUB4.connect.uwaterloo.ca>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<51eca682339a4cb5b14cc327e37ff02a@CONNHUB4.connect.uwaterloo.ca>
Message-ID: <CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>

Thanks, Bill. The output is:

> trace(system, quote(print(command)))
  parallel::detectCores(TRUE)
Tracing function "system" in package "base"
[1] "system"
>
Tracing system(cmd, TRUE) on entry
[1] "/usr/sbin/sysctl -n hw.ncpu 2>/dev/null"
Error in system(cmd, TRUE) : error in running command
>

On Fri, Aug 22, 2014 at 6:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
> The same is true in R-2.14.1 on  Ubuntu 12.04.4 LTS .  Put a trace on
> system with
>   trace(system, quote(print(command)))
>   parallel::detectCores(TRUE)
> and you will see the offending shell command.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Aug 22, 2014 at 1:03 PM, Marius Hofert
> <marius.hofert at uwaterloo.ca> wrote:
>> Hi,
>>
>> Both under the current R-devel (r66456) and a version from about 3
>> months ago, I experience the following behavior:
>>
>>> parallel::detectCores(TRUE)
>> Error in system(cmd, TRUE) : error in running command
>>> traceback()
>> 3: system(cmd, TRUE)
>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>> 1: parallel::detectCores(TRUE)
>>>
>>
>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>> quite a heavy workload, otherwise I would have installed and tested it
>> also under 3.1.1]
>>
>> Cheers,
>>
>> Marius
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Aug 23 08:01:13 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 23 Aug 2014 07:01:13 +0100 (BST)
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<51eca682339a4cb5b14cc327e37ff02a@CONNHUB4.connect.uwaterloo.ca>
	<CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1408230656290.4032@gannet.stats.ox.ac.uk>

But parallel::detectCores(TRUE) is a call of desparation: this ran 
code intended for FreeBSD.

If all else fails read the help:

      It has methods to do so for Linux, OS X, FreeBSD, Solaris, Irix
      and Windows.  ?detectCores(TRUE)? could be tried on other
      Unix-alike systems.


On Fri, 22 Aug 2014, Marius Hofert wrote:

> Thanks, Bill. The output is:
>
>> trace(system, quote(print(command)))
>  parallel::detectCores(TRUE)
> Tracing function "system" in package "base"
> [1] "system"
>>
> Tracing system(cmd, TRUE) on entry
> [1] "/usr/sbin/sysctl -n hw.ncpu 2>/dev/null"
> Error in system(cmd, TRUE) : error in running command
>>
>
> On Fri, Aug 22, 2014 at 6:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> The same is true in R-2.14.1 on  Ubuntu 12.04.4 LTS .  Put a trace on
>> system with
>>   trace(system, quote(print(command)))
>>   parallel::detectCores(TRUE)
>> and you will see the offending shell command.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Aug 22, 2014 at 1:03 PM, Marius Hofert
>> <marius.hofert at uwaterloo.ca> wrote:
>>> Hi,
>>>
>>> Both under the current R-devel (r66456) and a version from about 3
>>> months ago, I experience the following behavior:
>>>
>>>> parallel::detectCores(TRUE)
>>> Error in system(cmd, TRUE) : error in running command
>>>> traceback()
>>> 3: system(cmd, TRUE)
>>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>>> 1: parallel::detectCores(TRUE)
>>>>
>>>
>>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>>> quite a heavy workload, otherwise I would have installed and tested it
>>> also under 3.1.1]
>>>
>>> Cheers,
>>>
>>> Marius
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK

From marius.hofert at uwaterloo.ca  Sat Aug 23 03:22:02 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 22 Aug 2014 21:22:02 -0400
Subject: [Rd] parallel::detectCores(TRUE) gives: Error in system(cmd,
 TRUE) : error in running command
In-Reply-To: <02f417ad30f442459e90f3fde00f7ceb@CONNHUB4.connect.uwaterloo.ca>
References: <CAM3-KjZ2OtUx6Hz88WuM4A4AV8_OAey4MvWjz8ZKMRDQi=jgdQ@mail.gmail.com>
	<51eca682339a4cb5b14cc327e37ff02a@CONNHUB4.connect.uwaterloo.ca>
	<CAM3-Kjb-E2U=SaTigq7D-SBhG_ox=R8o-c9ZgwqpvspKweOEEw@mail.gmail.com>
	<02f417ad30f442459e90f3fde00f7ceb@CONNHUB4.connect.uwaterloo.ca>
Message-ID: <CAM3-KjYqk8PAugz4_KTKm+7NTQ+1Q1wH+vRjuWMgw+m8CCFXFA@mail.gmail.com>

On Fri, Aug 22, 2014 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
> There is no /usr/sbin/sysctl on my Ubuntu 12.04 machine.  There is a
> /sbin/sysctl, but it does not accept the '-n hw.ncpu' arguments.  Its
> /usr/bin/nproc [-all] will tell the number of available [installed]
> processing units and 'cat /proc/cpuinfo | grep processor | wc -l' will
> also give the number of installed processing units.

both commands give me '4'.


> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Aug 22, 2014 at 3:17 PM, Marius Hofert
> <marius.hofert at uwaterloo.ca> wrote:
>> Thanks, Bill. The output is:
>>
>>> trace(system, quote(print(command)))
>>   parallel::detectCores(TRUE)
>> Tracing function "system" in package "base"
>> [1] "system"
>>>
>> Tracing system(cmd, TRUE) on entry
>> [1] "/usr/sbin/sysctl -n hw.ncpu 2>/dev/null"
>> Error in system(cmd, TRUE) : error in running command
>>>
>>
>> On Fri, Aug 22, 2014 at 6:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> The same is true in R-2.14.1 on  Ubuntu 12.04.4 LTS .  Put a trace on
>>> system with
>>>   trace(system, quote(print(command)))
>>>   parallel::detectCores(TRUE)
>>> and you will see the offending shell command.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Fri, Aug 22, 2014 at 1:03 PM, Marius Hofert
>>> <marius.hofert at uwaterloo.ca> wrote:
>>>> Hi,
>>>>
>>>> Both under the current R-devel (r66456) and a version from about 3
>>>> months ago, I experience the following behavior:
>>>>
>>>>> parallel::detectCores(TRUE)
>>>> Error in system(cmd, TRUE) : error in running command
>>>>> traceback()
>>>> 3: system(cmd, TRUE)
>>>> 2: gsub("^ +", "", system(cmd, TRUE)[1])
>>>> 1: parallel::detectCores(TRUE)
>>>>>
>>>>
>>>> This is on Ubuntu 14.04. Does anybody else see this? [I currently have
>>>> quite a heavy workload, otherwise I would have installed and tested it
>>>> also under 3.1.1]
>>>>
>>>> Cheers,
>>>>
>>>> Marius
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From skostysh at princeton.edu  Sun Aug 24 05:44:18 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 23 Aug 2014 23:44:18 -0400
Subject: [Rd] [patch] Add support for editor function in edit.default
In-Reply-To: <CAE3=dmfOvQQPcWu8=5+_Nd-EXE8HAnywrT9g67pYfxBx0exWxQ@mail.gmail.com>
References: <CAE3=dmfOvQQPcWu8=5+_Nd-EXE8HAnywrT9g67pYfxBx0exWxQ@mail.gmail.com>
Message-ID: <CAE3=dmcNk_oSHdbKGjTAsCL0Kk6MDt+F-zeyn+KwG-myXUk9EQ@mail.gmail.com>

On Tue, May 20, 2014 at 5:55 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> Regarding the following extract of ?options:
>      ?editor?: a non-empty string, or a function that is called with a
>           file path as argument.
>
> edit.default currently calls the function with three arguments: name,
> file, and title. For example, running the following

To be clear with what I view as problematic, note in the above that
the documentation says the function is called with a file path as an
argument, suggesting one argument; but in practice it is called with
three arguments.

> vimCmd <- 'vim -c "set ft=r"'
> vimEdit <- function(file_) system(paste(vimCmd, file_))
> options(editor = vimEdit)
> myls <- edit(ls)
>
> gives "Error in editor(name, file, title) : unused arguments (file, title)".
>
> The attached patch changes edit.default to call the editor function
> with just the file path. There is at least one inconsistent behavior
> that this patch causes in its current form. It does not obey the
> following (from ?edit):
>      Calling ?edit()?, with no arguments, will result in the temporary
> file being reopened for further editing.
>
> I see two ways to address this: (1) add a getEdFile() function to
> utils/edit.R that calls a function getEd() defined in edit.c that
> returns DefaultFileName; or (2) this patch could be rewritten in C in
> a new function in edit.c.
>
> Is there any interest in this patch?
> If not, would there be interest in an update of the docs, either
> ?options (stating the possibility that if 'editor' is a function, it
> might be called with 'name', 'file', and 'title' arguments) or ?edit
>  ?

Any interest in this patch? If not, would a patch for the
documentation be considered?

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From igauravsehrawat at gmail.com  Sun Aug 24 13:10:23 2014
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Sun, 24 Aug 2014 16:40:23 +0530
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>
	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>
	<CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>
Message-ID: <CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>

I was moreover concerned over bridging gap between web2.0 and web1.0
development methodologies  & thus passing code to younger generation .

But never mind . Sooner or later .

Cheers.


On Fri, Aug 22, 2014 at 9:30 AM, Yihui Xie <xie at yihui.name> wrote:

> As someone who has merged more than a hundred pull requests on Github,
> I cannot agree more. Sometimes I can take patches on my mobile phone
> while I'm still in bed if they look reasonable and simple enough.
> Sometimes the patches are not worth emails back and forth, such as the
> correction of typos. I cannot think of anything else that is more
> efficient than being able to discuss the patch right in the lines of
> diff's.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Thu, Aug 21, 2014 at 10:58 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
> >
> > On Aug 21, 2014, at 6:40 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
> >
> >> On Aug 21, 2014, at 3:11 AM, Gaurav Sehrawat <igauravsehrawat at gmail.com>
> wrote:
> >>
> >>> R-Project is missing something important in regards to its development
> ,
> >>> one simply can't ignore Github ,where collaboration is at it's best .
> >>>
> >>> OR If i am wrong is this the correct R-source :
> >>> https://github.com/wch/r-source
> >>>
> >>> Is anyone thinking to bring R-project org on Github ? Maybe there
> might be
> >>> some difficulty while porting its version system to Github .
> >>>
> >>> Just a suggestion .
> >>>
> >>> Thanks
> >>> Gaurav Sehrawat
> >>> http://igauravsehrawat.com
> >>
> >>
> >> The link you have above is to a read-only mirror (perhaps not the only
> one) of the R source code that is kept in the official Subversion repo:
> >>
> >>  https://svn.r-project.org/R/
> >>
> >> There are also some documents that describe R's development cycle and
> related processes:
> >>
> >>  http://www.r-project.org/certification.html
> >>
> >> Your suggestion to move to Github is perhaps based upon a false
> premise, that the R community at large has the ability to directly post
> code/patches to the official distribution. We can contribute code and
> patches, primarily here on R-Devel, to the code base. However, only the
> members of R Core team (http://www.r-project.org/contributors.html) have
> write access to the SVN repo above and have to approve any such
> contributions.
> >>
> >
> > How is this different from Github? Github just makes it much easier to
> create and post patches to the project - it has nothing to do with write
> access - typically on Github the community has no write access, either.
> Using pull requests is certainly much less fragile than e-mails and patches
> are based on forked branches, so you can directly build the patched version
> if you want without manually applying the patch - and you see the whole
> history so you can pick out things logically. You can comment on individual
> patches to discuss them and even individual commits - often leading to a
> quick round trip time of revising it.
> >
> > Cheers,
> > Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Sun Aug 24 19:24:02 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 24 Aug 2014 19:24:02 +0200
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>
	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>
	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>
	<CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>
	<CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>
Message-ID: <CABFfbXuND0PZ1e04y+MwYP_4gaXfi4tyoaXofXnaw=Eh8bNB-Q@mail.gmail.com>

On Sun, Aug 24, 2014 at 1:10 PM, Gaurav Sehrawat
<igauravsehrawat at gmail.com> wrote:
>
> But never mind . Sooner or later.

These things take time, but a lot has happened over the past years. By
now all activity of r-base [1] cran [2] and r-forge [3] is
continuously mirrored on Github, which already gives unprecedented
insight in developments. At least several r-core members [4,5,6,7,8]
have been spotted on Github, and this years useR2014 website [9] was
developed and hosted completely on Github. It seems like a matter of
time until the benefits outweigh the cost of a migration, even to the
more conservative stakeholders.

However moving development of a medium sized, 20 year old open source
project is not trivial. You are dealing with a large commit history
and many contributors that all have to overhaul their familiar tools
and development practices overnight. There is also the infrastructure
of nightly builds and CRAN r-devel package checking that relies on the
svn. Moreover moving to Github means changes in communications, for
example replacing the current bug tracking system to Github "issues".
In addition, several members are skeptical about putting source code
in the hands of a for-profit US company, and other legal issues. These
are just some of the concerns that would need to be addressed to get
everyone on board.

My (limited) experience with these things is that the most critical
piece of making such a transition actually happen is not just a
general consensus that a is preferable over b, but rather a detailed
proposal outlining what the migration would involve, the
cost/benefits, a planning, and someone that is willing to take the
lead. Only on the basis of such a serious proposal you can have a
discussion in which everyone can voice concerns, be assured that
his/her interests are secure, and the idea can eventually be put up
for a vote.

Jeroen

[1] https://github.com/wch/r-source
[2] https://github.com/cran
[3] https://github.com/rforge
[4] https://github.com/s-u
[5] https://github.com/mmaechler
[6] https://github.com/duncantl
[7] https://github.com/pmur002
[8] https://github.com/dmbates
[9] https://github.com/user2014


From spencer.graves at structuremonitoring.com  Sun Aug 24 20:22:47 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 24 Aug 2014 11:22:47 -0700
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <CABFfbXuND0PZ1e04y+MwYP_4gaXfi4tyoaXofXnaw=Eh8bNB-Q@mail.gmail.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>	<CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>	<CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>
	<CABFfbXuND0PZ1e04y+MwYP_4gaXfi4tyoaXofXnaw=Eh8bNB-Q@mail.gmail.com>
Message-ID: <53FA2D77.5010605@structuremonitoring.com>

On 8/24/2014 10:24 AM, Jeroen Ooms wrote:
> On Sun, Aug 24, 2014 at 1:10 PM, Gaurav Sehrawat
> <igauravsehrawat at gmail.com> wrote:
>> But never mind . Sooner or later.
> These things take time, but a lot has happened over the past years. By
> now all activity of r-base [1] cran [2] and r-forge [3] is
> continuously mirrored on Github, which already gives unprecedented
> insight in developments. At least several r-core members [4,5,6,7,8]
> have been spotted on Github, and this years useR2014 website [9] was
> developed and hosted completely on Github. It seems like a matter of
> time until the benefits outweigh the cost of a migration, even to the
> more conservative stakeholders.
>
> However moving development of a medium sized, 20 year old open source
> project is not trivial. You are dealing with a large commit history
> and many contributors that all have to overhaul their familiar tools
> and development practices overnight. There is also the infrastructure
> of nightly builds and CRAN r-devel package checking that relies on the
> svn. Moreover moving to Github means changes in communications, for
> example replacing the current bug tracking system to Github "issues".
> In addition, several members are skeptical about putting source code
> in the hands of a for-profit US company, and other legal issues. These
> are just some of the concerns that would need to be addressed to get
> everyone on board.


       Am I correct that we could use Git without Github?


       If yes, the planning might involve a cost-benefit comparison of 
what would be required bring up a not-for-profit alternative to Github 
(e.g., RGit.org or FreeGit.org or ...), and whether the risks of 
problems with that would be more or less than the risks associated with 
"putting source code in the hands of a for-profit US company".


       Spencer


p.s.  Regarding the risks of "putting source code in the hands of a 
for-profit US company," I would naively expect that it should be easy 
and cheap for someone to program a server to make daily backup copies of 
whatever we want from Github.  This could provide an insurance policy in 
case events push the group to leave Github. Many (most?) of those who 
read this may remember how LibreOffice forked from Open Office.  A 
friend told me that MySQL has a much larger user (and developer?) base 
than LibreOffice, and every Oracle executive doubtless knows that MySQL 
could similarly be forked relatively easily.

> My (limited) experience with these things is that the most critical
> piece of making such a transition actually happen is not just a
> general consensus that a is preferable over b, but rather a detailed
> proposal outlining what the migration would involve, the
> cost/benefits, a planning, and someone that is willing to take the
> lead. Only on the basis of such a serious proposal you can have a
> discussion in which everyone can voice concerns, be assured that
> his/her interests are secure, and the idea can eventually be put up
> for a vote.
>
> Jeroen
>
> [1] https://github.com/wch/r-source
> [2] https://github.com/cran
> [3] https://github.com/rforge
> [4] https://github.com/s-u
> [5] https://github.com/mmaechler
> [6] https://github.com/duncantl
> [7] https://github.com/pmur002
> [8] https://github.com/dmbates
> [9] https://github.com/user2014
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rowe at muxspace.com  Sun Aug 24 20:43:16 2014
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Sun, 24 Aug 2014 14:43:16 -0400
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <53FA2D77.5010605@structuremonitoring.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>	<CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>	<CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>
	<CABFfbXuND0PZ1e04y+MwYP_4gaXfi4tyoaXofXnaw=Eh8bNB-Q@mail.gmail.com>
	<53FA2D77.5010605@structuremonitoring.com>
Message-ID: <4DE91FA7-2CE8-4057-A6D9-BE03A9E8EEB0@muxspace.com>

One thing to note about git vs svn is that each git repository is a complete repository containing the full history, so despite github acting as a central repository, it is not the same as a central svn repository. In svn the central repository is typically the only repository with a complete revision history, but that is not the case with git.

?????
Brian Lee Yung Rowe
Founder, Zato Novo
Professor, M.S. Data Analytics, CUNY




On Aug 24, 2014, at 2:22 PM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:

>> In addition, several members are skeptical about putting source code
>> in the hands of a for-profit US company, and other legal issues. These
>> are just some of the concerns that would need to be addressed to get
>> everyone on board.
> 
> 
>      Am I correct that we could use Git without Github?
> 
> 
>      If yes, the planning might involve a cost-benefit comparison of what would be required bring up a not-for-profit alternative to Github (e.g., RGit.org or FreeGit.org or ...), and whether the risks of problems with that would be more or less than the risks associated with "putting source code in the hands of a for-profit US company".
> 
> 
>      Spencer
> 
> 
> p.s.  Regarding the risks of "putting source code in the hands of a for-profit US company," I would naively expect that it should be easy and cheap for someone to program a server to make daily backup copies of whatever we want from Github.  This could provide an insurance policy in case events push the group to leave Github. Many (most?) of those who read this may remember how LibreOffice forked from Open Office.  A friend told me that MySQL has a much larger user (and developer?) base than LibreOffice, and every Oracle executive doubtless knows that MySQL could similarly be forked relatively easily.


	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Mon Aug 25 02:55:51 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 24 Aug 2014 20:55:51 -0400
Subject: [Rd] Why R-project source code is not on Github
In-Reply-To: <53FA2D77.5010605@structuremonitoring.com>
References: <CAC2qNN50TnpgCK_J027aBwn4Obm52O3CqqJ=2oTeetT=okWDWw@mail.gmail.com>	<69D351C3-AA81-430E-8F66-D06863C18702@me.com>	<E2C615A5-EFB9-4BCA-9696-258AB8859BBA@r-project.org>	<CANROs4ewiNwp-p1-e-jgGh1CSQtz55emjhKSeNpD00VFxhJn2Q@mail.gmail.com>	<CAC2qNN59QafjkpnvLHsucNpoXvCe2AgYDRexsXD=s7r5sUjdmA@mail.gmail.com>
	<CABFfbXuND0PZ1e04y+MwYP_4gaXfi4tyoaXofXnaw=Eh8bNB-Q@mail.gmail.com>
	<53FA2D77.5010605@structuremonitoring.com>
Message-ID: <B09FF375-EBBB-4C83-B3BB-FBFDC1628779@r-project.org>


On Aug 24, 2014, at 2:22 PM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:

> On 8/24/2014 10:24 AM, Jeroen Ooms wrote:
>> On Sun, Aug 24, 2014 at 1:10 PM, Gaurav Sehrawat
>> <igauravsehrawat at gmail.com> wrote:
>>> But never mind . Sooner or later.
>> These things take time, but a lot has happened over the past years. By
>> now all activity of r-base [1] cran [2] and r-forge [3] is
>> continuously mirrored on Github, which already gives unprecedented
>> insight in developments. At least several r-core members [4,5,6,7,8]
>> have been spotted on Github, and this years useR2014 website [9] was
>> developed and hosted completely on Github. It seems like a matter of
>> time until the benefits outweigh the cost of a migration, even to the
>> more conservative stakeholders.
>> 
>> However moving development of a medium sized, 20 year old open source
>> project is not trivial. You are dealing with a large commit history
>> and many contributors that all have to overhaul their familiar tools
>> and development practices overnight. There is also the infrastructure
>> of nightly builds and CRAN r-devel package checking that relies on the
>> svn. Moreover moving to Github means changes in communications, for
>> example replacing the current bug tracking system to Github "issues".
>> In addition, several members are skeptical about putting source code
>> in the hands of a for-profit US company, and other legal issues. These
>> are just some of the concerns that would need to be addressed to get
>> everyone on board.
> 
> 
>      Am I correct that we could use Git without Github?
> 

No. git is the necessary evil if you deal with Github (almost - Github actually supports direct SVN access as well) - but there is no point in using git alone. I hate git*, but I love Github (despite being very cynical about it before I tried pushing some of my packages there - and seeing the actual impact). The whole point are the collaborative features - and it's hard to get those right (many tried and failed such as GitLab) which is exactly what Github did.

Cheers,
Simon


* -  git is great for people who like to compile their own Linux kernel every week. Yes, I have done that when I was young - it was fun and I felt great having all the fine control, but once you get a life and just want to get things done, you really don't want to deal with things at such a level anymore. There are better alternatives, but Github placed the bet on git which is what counts in the end. But this is OT so flame me directly if you wish.


>      If yes, the planning might involve a cost-benefit comparison of what would be required bring up a not-for-profit alternative to Github (e.g., RGit.org or FreeGit.org or ...), and whether the risks of problems with that would be more or less than the risks associated with "putting source code in the hands of a for-profit US company".
> 
> 
>      Spencer
> 
> 
> p.s.  Regarding the risks of "putting source code in the hands of a for-profit US company," I would naively expect that it should be easy and cheap for someone to program a server to make daily backup copies of whatever we want from Github.  This could provide an insurance policy in case events push the group to leave Github. Many (most?) of those who read this may remember how LibreOffice forked from Open Office.  A friend told me that MySQL has a much larger user (and developer?) base than LibreOffice, and every Oracle executive doubtless knows that MySQL could similarly be forked relatively easily.
> 
>> My (limited) experience with these things is that the most critical
>> piece of making such a transition actually happen is not just a
>> general consensus that a is preferable over b, but rather a detailed
>> proposal outlining what the migration would involve, the
>> cost/benefits, a planning, and someone that is willing to take the
>> lead. Only on the basis of such a serious proposal you can have a
>> discussion in which everyone can voice concerns, be assured that
>> his/her interests are secure, and the idea can eventually be put up
>> for a vote.
>> 
>> Jeroen
>> 
>> [1] https://github.com/wch/r-source
>> [2] https://github.com/cran
>> [3] https://github.com/rforge
>> [4] https://github.com/s-u
>> [5] https://github.com/mmaechler
>> [6] https://github.com/duncantl
>> [7] https://github.com/pmur002
>> [8] https://github.com/dmbates
>> [9] https://github.com/user2014
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From jorismeys at gmail.com  Mon Aug 25 16:27:50 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 25 Aug 2014 16:27:50 +0200
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
Message-ID: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>

Dear all,

I initially ran into this problem while rebuilding a package dependent on
nleqslv. I got the following error:

Error in match.arg(global) : 'arg' must be of length 1

This didn't occur in previous versions of nleqslv, but did in the current
one (2.4). I think I pinned the problem down to the following example:

Take two functions:

test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
  x <- match.arg(x)
  global <- match.arg(global)
  return(list(x,global))
}

test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
  test(x=x,global=global)
}

test2() calls an "internal" function test() that uses the same arguments.
Note that for x both functions have exactly the same defaults, but not for
global.

Calling test2() gives the reported error:

> test2()
 Error in match.arg(global) : 'arg' must be of length 1

I see the point of this error (global is not seen by test2() as default
settings but as a character vector I presume), but I wonder why this isn't
the case for x. Is this by design? If so, is there a part of the manual I
overlooked?

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Aug 25 17:22:18 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Aug 2014 10:22:18 -0500
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
In-Reply-To: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
References: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
Message-ID: <CABdHhvG9eT_teREJrSUr-tkmFfrKar7a-MgzBi+-RtNAs5kX6A@mail.gmail.com>

This is one of the perils of non-standard evaluation - functions are
no longer referentially transparent.

Hadley

On Mon, Aug 25, 2014 at 9:27 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Dear all,
>
> I initially ran into this problem while rebuilding a package dependent on
> nleqslv. I got the following error:
>
> Error in match.arg(global) : 'arg' must be of length 1
>
> This didn't occur in previous versions of nleqslv, but did in the current
> one (2.4). I think I pinned the problem down to the following example:
>
> Take two functions:
>
> test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
>   x <- match.arg(x)
>   global <- match.arg(global)
>   return(list(x,global))
> }
>
> test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
>   test(x=x,global=global)
> }
>
> test2() calls an "internal" function test() that uses the same arguments.
> Note that for x both functions have exactly the same defaults, but not for
> global.
>
> Calling test2() gives the reported error:
>
>> test2()
>  Error in match.arg(global) : 'arg' must be of length 1
>
> I see the point of this error (global is not seen by test2() as default
> settings but as a character vector I presume), but I wonder why this isn't
> the case for x. Is this by design? If so, is there a part of the manual I
> overlooked?
>
> Cheers
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From gmbecker at ucdavis.edu  Mon Aug 25 17:50:24 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 25 Aug 2014 08:50:24 -0700
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
In-Reply-To: <CABdHhvG9eT_teREJrSUr-tkmFfrKar7a-MgzBi+-RtNAs5kX6A@mail.gmail.com>
References: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
	<CABdHhvG9eT_teREJrSUr-tkmFfrKar7a-MgzBi+-RtNAs5kX6A@mail.gmail.com>
Message-ID: <CADwqtCPvfvVZP+eo4WFYTvHP4VeBGTEiBRLc5Az5+GnNX0UWkw@mail.gmail.com>

More specifically, you're satisifying and not satisfying

    if (identical(arg, choices))
        return(arg[1L])

within the definition of match.args for x, and global, respectively.

arg is what is passed to the function (outer default) but choices isn't
specified so match.args uses nonstandard evaluation to populate it with the
default value *in the the call frame from which match.args was called*,
i.e. the *inner* default value. (See the details section of ?match.args)

The take away here is that match.args without explicitly setting choices is
dangerous except in top level functions, and that more generally
non-standard evaluation is dangerous and should be used sparingly and with
care.

~G


On Mon, Aug 25, 2014 at 8:22 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> This is one of the perils of non-standard evaluation - functions are
> no longer referentially transparent.
>
> Hadley
>
> On Mon, Aug 25, 2014 at 9:27 AM, Joris Meys <jorismeys at gmail.com> wrote:
> > Dear all,
> >
> > I initially ran into this problem while rebuilding a package dependent on
> > nleqslv. I got the following error:
> >
> > Error in match.arg(global) : 'arg' must be of length 1
> >
> > This didn't occur in previous versions of nleqslv, but did in the current
> > one (2.4). I think I pinned the problem down to the following example:
> >
> > Take two functions:
> >
> > test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
> >   x <- match.arg(x)
> >   global <- match.arg(global)
> >   return(list(x,global))
> > }
> >
> > test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
> >   test(x=x,global=global)
> > }
> >
> > test2() calls an "internal" function test() that uses the same arguments.
> > Note that for x both functions have exactly the same defaults, but not
> for
> > global.
> >
> > Calling test2() gives the reported error:
> >
> >> test2()
> >  Error in match.arg(global) : 'arg' must be of length 1
> >
> > I see the point of this error (global is not seen by test2() as default
> > settings but as a character vector I presume), but I wonder why this
> isn't
> > the case for x. Is this by design? If so, is there a part of the manual I
> > overlooked?
> >
> > Cheers
> > Joris
> >
> > --
> > Joris Meys
> > Statistical consultant
> >
> > Ghent University
> > Faculty of Bioscience Engineering
> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >
> > tel : +32 9 264 59 87
> > Joris.Meys at Ugent.be
> > -------------------------------
> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Aug 25 17:53:58 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 25 Aug 2014 17:53:58 +0200
Subject: [Rd] The behaviour of setting names differs between lists
	and	atomic vectors
In-Reply-To: <43333C94-B4C2-43FB-ADC8-582FD089F776@gmail.com>
References: <CAPp_+=fwKAD19GAce7veeZMndmZ9W7aKm+MN393ZCz-jD=80fQ@mail.gmail.com>
	<53F5F888.4020602@gmail.com>
	<43333C94-B4C2-43FB-ADC8-582FD089F776@gmail.com>
Message-ID: <21499.23574.26909.459333@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Thu, 21 Aug 2014 16:11:38 +0200 writes:

    > On 21 Aug 2014, at 15:47 , Duncan Murdoch
    > <murdoch.duncan at gmail.com> wrote:

    >> On 21/08/2014 9:26 AM, Richard Cotton wrote:
    >>> If you set the names in a list, some cat-style
    >>> processing seems to happen.  For example, backslashes
    >>> are modified.  This behaviour doesn't happen with atomic
    >>> vectors.  Compare, for example:
    >>> 
    >>> setNames(1, "a\\b") ## a\\b ## 1 setNames(list(1),
    >>> "a\\b") ## $`a\b` ## [1] 1
    >>> 
    >>> Notice that the name of the element in the list has been
    >>> changed to 'a', 'backspace'.
    >>> 
    >>> Is this behaviour intended, or a bug?
    >>> 
    >> I think there's a bug, but not in names<- (or setNames,
    >> which calls it).  The bug is in the printing, as you'll
    >> see if you look at names(setNames(list(1), "a\\b")).
    >> 

    > Yep, slight variant:

    >> l <- list(`a\\b`=1) l
    > $`a\b` [1] 1

    >> l$`a\b`
    > NULL
    >> l$`a\\b`
    > [1] 1

With thanks to the OP, Richie,
this is now  fixed in  R-devel and R-patched, i.e., in any next
version of R.

Martin Maechler,
ETH Zurich


From pdalgd at gmail.com  Mon Aug 25 18:22:57 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 25 Aug 2014 18:22:57 +0200
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
In-Reply-To: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
References: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
Message-ID: <F1AABEEB-574A-42F1-B162-471F2DB5CF86@gmail.com>


On 25 Aug 2014, at 16:27 , Joris Meys <jorismeys at gmail.com> wrote:

> Dear all,
> 
> I initially ran into this problem while rebuilding a package dependent on
> nleqslv. I got the following error:
> 
> Error in match.arg(global) : 'arg' must be of length 1
> 
> This didn't occur in previous versions of nleqslv, but did in the current
> one (2.4). I think I pinned the problem down to the following example:
> 
> Take two functions:
> 
> test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
>  x <- match.arg(x)
>  global <- match.arg(global)
>  return(list(x,global))
> }
> 
> test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
>  test(x=x,global=global)
> }
> 
> test2() calls an "internal" function test() that uses the same arguments.
> Note that for x both functions have exactly the same defaults, but not for
> global.
> 
> Calling test2() gives the reported error:
> 
>> test2()
> Error in match.arg(global) : 'arg' must be of length 1
> 
> I see the point of this error (global is not seen by test2() as default
> settings but as a character vector I presume), but I wonder why this isn't
> the case for x. Is this by design? If so, is there a part of the manual I
> overlooked?
> 

What you are experiencing would seem to amount to this:

> f <- function(x=c("a","b","c")) {x <- letters[1:3] ; match.arg(x)}
> f()
[1] "a"
> f <- function(x=c("a","b","c")) {x <- letters[1:2] ; match.arg(x)}
> f()
Error in match.arg(x) : 'arg' must be of length 1

Words to that effect appear in the Details section of ?match.arg

-Peter D

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bhh at xs4all.nl  Mon Aug 25 18:49:49 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 25 Aug 2014 18:49:49 +0200
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
In-Reply-To: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
References: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
Message-ID: <5B378047-E835-4AA2-80FD-214E782E575C@xs4all.nl>


On 25-08-2014, at 16:27, Joris Meys <jorismeys at gmail.com> wrote:

> Dear all,
> 
> I initially ran into this problem while rebuilding a package dependent on
> nleqslv. I got the following error:
> 
> Error in match.arg(global) : 'arg' must be of length 1
> 
> This didn't occur in previous versions of nleqslv, but did in the current
> one (2.4). I think I pinned the problem down to the following example:
> 
> Take two functions:
> 
> test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
>  x <- match.arg(x)
>  global <- match.arg(global)
>  return(list(x,global))
> }
> 
> test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
>  test(x=x,global=global)
> }
> 

Can?t  the problem easily be avoided by using a slightly modified version of the test2() function?

test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
 x <- match.arg(x)
global <- match.arg(global)
 test(x=x,global=global)
}

Then test2() would be calling test() as it was intended to be called.
I?ve tried that and it appears to solve the problem.

So before calling nleqslv within another function use match.arg on those arguments with the same name and different defaults.
And (possibly) document that some arguments expect a single value.

Berend


From rpruim at calvin.edu  Mon Aug 25 20:10:48 2014
From: rpruim at calvin.edu (Randall Pruim)
Date: Mon, 25 Aug 2014 18:10:48 +0000
Subject: [Rd] vignette index going AWOL
Message-ID: <BDF32633-2F32-4757-8B8A-3DCDA8FB92D5@calvin.edu>

I?m preparing a package (fastR) for submission to CRAN, but the vignette index keeps going AWOL, or at least R CMD check ?as-cran thinks so. I?ve tried several things and gave myself the weekend to think of other things, but I can?t figure it out.  Perhaps someone on the list can lend a hand.

Here?s one example situation, where I build the index.html file myself and put it in inst/doc/index.html

$ cat fastR.Rcheck/00check.log | grep -v OK
* using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
* using R Under development (unstable) (2014-08-21 r66456)
* using platform: x86_64-apple-darwin13.1.0 (64-bit)
* using session charset: UTF-8
* checking extension type ... Package
* this is package ?fastR? version ?0.8-0?
* checking CRAN incoming feasibility ... NOTE
Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
Package has a VignetteBuilder field but no prebuilt vignette index.
NOTE: There was 1 note.

$ tar -tf fastR_0.8-0.tar.gz | grep inst/doc
fastR/inst/doc/
fastR/inst/doc/Errata.Rnw
fastR/inst/doc/Errata.pdf
fastR/inst/doc/Updates.R
fastR/inst/doc/Updates.Rnw
fastR/inst/doc/Updates.pdf
fastR/inst/doc/index.html

There is an index.html in the tar ball.  And If I install the package from the tar ball, the index appears as it should in the package. 

I would be happy with the auto-generated index, but that doesn?t seem to be working either.  If I remove index.html I get

$ grep -v OK fastR.Rcheck/00check.log 
* using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
* using R Under development (unstable) (2014-08-21 r66456)
* using platform: x86_64-apple-darwin13.1.0 (64-bit)
* using session charset: UTF-8
* checking extension type ... Package
* this is package ?fastR? version ?0.8-1?
* checking CRAN incoming feasibility ... NOTE
Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
Package has a VignetteBuilder field but no prebuilt vignette index.
NOTE: There was 1 note.

$ tar -tf fastR_0.8-1.tar.gz | grep inst/doc
fastR/inst/doc/
fastR/inst/doc/Errata.Rnw
fastR/inst/doc/Errata.pdf
fastR/inst/doc/Updates.R
fastR/inst/doc/Updates.Rnw
fastR/inst/doc/Updates.pdf

Comparing with other successful packages created last week, it doesn?t appear that the tar ball contains the vignette index for those either ? or perhaps I don?t know what I?m looking for.

$ tar -tf mosaic_0.9.1-3.tar.gz | grep -i index
mosaic/demo/00Index

(mosaic passes checks fine and are already on CRAN.)

Both packages use knitr to convert Rnw to PDF.  mosaic also uses R.rsp to include static PDFs.

$ grep -i vig  mosaic/DESCRIPTION
VignetteBuilder: knitr, R.rsp

[09:22][rpruim at Mac21521:~/projects/github]
$ grep -i vig  fastR/DESCRIPTION
VignetteBuilder: knitr

$ grep  Vig mosaic/vignettes/*Rnw
%\VignetteIndexEntry{mosaic resources}
%\VignettePackage{mosaic}
%\VignetteKeywords{mosaic, vignettes, resources, references}
%\VignetteEngine{knitr::knitr} 

$ grep  Vig fastR/vignettes/*Rnw
fastR/vignettes/Errata.Rnw:%\VignetteEngine{knitr::knitr} 
fastR/vignettes/Errata.Rnw:%\VignetteIndexEntry{Errata}
fastR/vignettes/Errata.Rnw:%\VignettePackage{fastR}
fastR/vignettes/Errata.Rnw:%\VignetteKeywords{fastR, vignettes}
fastR/vignettes/Updates.Rnw:%\VignetteEngine{knitr::knitr} 
fastR/vignettes/Updates.Rnw:%\VignetteIndexEntry{Updates to R Programming in FASt}
fastR/vignettes/Updates.Rnw:%\VignettePackage{fastR}
fastR/vignettes/Updates.Rnw:%\VignetteKeywords{mosaic, fastR, vignettes, resources}

There must be some subtle difference between my two packages that I just can?t spot.  

Thanks in advance for any pointers about where to look.   

?rjp

PS.  The package is on github and installs fine (vignette index included, even though there is no index.html in the repo) using install_github("fastR", "rpruim")

From kevinushey at gmail.com  Mon Aug 25 20:17:34 2014
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 25 Aug 2014 11:17:34 -0700
Subject: [Rd] vignette index going AWOL
In-Reply-To: <BDF32633-2F32-4757-8B8A-3DCDA8FB92D5@calvin.edu>
References: <BDF32633-2F32-4757-8B8A-3DCDA8FB92D5@calvin.edu>
Message-ID: <CAJXgQP1ZMVW+nqp+dAqFHL7sBTcTK4N9megYCTpbiS2vR_87jg@mail.gmail.com>

Hi Randall,

I notice that, in your .Rbuildignore, you have the entry:

    ^build$

and I suspect this is the culprit (having being bitten by a similar
problem before). Some part of the R build / install process creates /
uses that directory, but having it excluded in .Rbuildignore will
cause you grief.

In general, you probably have to consider `build` reserved for use by
R, when developing R packages.

Cheers,
Kevin

On Mon, Aug 25, 2014 at 11:10 AM, Randall Pruim <rpruim at calvin.edu> wrote:
> I?m preparing a package (fastR) for submission to CRAN, but the vignette index keeps going AWOL, or at least R CMD check ?as-cran thinks so. I?ve tried several things and gave myself the weekend to think of other things, but I can?t figure it out.  Perhaps someone on the list can lend a hand.
>
> Here?s one example situation, where I build the index.html file myself and put it in inst/doc/index.html
>
> $ cat fastR.Rcheck/00check.log | grep -v OK
> * using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
> * using R Under development (unstable) (2014-08-21 r66456)
> * using platform: x86_64-apple-darwin13.1.0 (64-bit)
> * using session charset: UTF-8
> * checking extension type ... Package
> * this is package ?fastR? version ?0.8-0?
> * checking CRAN incoming feasibility ... NOTE
> Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
> Package has a VignetteBuilder field but no prebuilt vignette index.
> NOTE: There was 1 note.
>
> $ tar -tf fastR_0.8-0.tar.gz | grep inst/doc
> fastR/inst/doc/
> fastR/inst/doc/Errata.Rnw
> fastR/inst/doc/Errata.pdf
> fastR/inst/doc/Updates.R
> fastR/inst/doc/Updates.Rnw
> fastR/inst/doc/Updates.pdf
> fastR/inst/doc/index.html
>
> There is an index.html in the tar ball.  And If I install the package from the tar ball, the index appears as it should in the package.
>
> I would be happy with the auto-generated index, but that doesn?t seem to be working either.  If I remove index.html I get
>
> $ grep -v OK fastR.Rcheck/00check.log
> * using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
> * using R Under development (unstable) (2014-08-21 r66456)
> * using platform: x86_64-apple-darwin13.1.0 (64-bit)
> * using session charset: UTF-8
> * checking extension type ... Package
> * this is package ?fastR? version ?0.8-1?
> * checking CRAN incoming feasibility ... NOTE
> Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
> Package has a VignetteBuilder field but no prebuilt vignette index.
> NOTE: There was 1 note.
>
> $ tar -tf fastR_0.8-1.tar.gz | grep inst/doc
> fastR/inst/doc/
> fastR/inst/doc/Errata.Rnw
> fastR/inst/doc/Errata.pdf
> fastR/inst/doc/Updates.R
> fastR/inst/doc/Updates.Rnw
> fastR/inst/doc/Updates.pdf
>
> Comparing with other successful packages created last week, it doesn?t appear that the tar ball contains the vignette index for those either ? or perhaps I don?t know what I?m looking for.
>
> $ tar -tf mosaic_0.9.1-3.tar.gz | grep -i index
> mosaic/demo/00Index
>
> (mosaic passes checks fine and are already on CRAN.)
>
> Both packages use knitr to convert Rnw to PDF.  mosaic also uses R.rsp to include static PDFs.
>
> $ grep -i vig  mosaic/DESCRIPTION
> VignetteBuilder: knitr, R.rsp
>
> [09:22][rpruim at Mac21521:~/projects/github]
> $ grep -i vig  fastR/DESCRIPTION
> VignetteBuilder: knitr
>
> $ grep  Vig mosaic/vignettes/*Rnw
> %\VignetteIndexEntry{mosaic resources}
> %\VignettePackage{mosaic}
> %\VignetteKeywords{mosaic, vignettes, resources, references}
> %\VignetteEngine{knitr::knitr}
>
> $ grep  Vig fastR/vignettes/*Rnw
> fastR/vignettes/Errata.Rnw:%\VignetteEngine{knitr::knitr}
> fastR/vignettes/Errata.Rnw:%\VignetteIndexEntry{Errata}
> fastR/vignettes/Errata.Rnw:%\VignettePackage{fastR}
> fastR/vignettes/Errata.Rnw:%\VignetteKeywords{fastR, vignettes}
> fastR/vignettes/Updates.Rnw:%\VignetteEngine{knitr::knitr}
> fastR/vignettes/Updates.Rnw:%\VignetteIndexEntry{Updates to R Programming in FASt}
> fastR/vignettes/Updates.Rnw:%\VignettePackage{fastR}
> fastR/vignettes/Updates.Rnw:%\VignetteKeywords{mosaic, fastR, vignettes, resources}
>
> There must be some subtle difference between my two packages that I just can?t spot.
>
> Thanks in advance for any pointers about where to look.
>
> ?rjp
>
> PS.  The package is on github and installs fine (vignette index included, even though there is no index.html in the repo) using install_github("fastR", "rpruim")
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpruim at calvin.edu  Mon Aug 25 20:28:51 2014
From: rpruim at calvin.edu (Randall Pruim)
Date: Mon, 25 Aug 2014 18:28:51 +0000
Subject: [Rd] vignette index going AWOL
In-Reply-To: <CAJXgQP1ZMVW+nqp+dAqFHL7sBTcTK4N9megYCTpbiS2vR_87jg@mail.gmail.com>
References: <BDF32633-2F32-4757-8B8A-3DCDA8FB92D5@calvin.edu>
	<CAJXgQP1ZMVW+nqp+dAqFHL7sBTcTK4N9megYCTpbiS2vR_87jg@mail.gmail.com>
Message-ID: <0EA61CE4-E8D6-4A6D-9140-E5E1DB0B6E63@calvin.edu>

Indeed!  That should say ?builds? rather than ?build?.  It is the directory where I keep old tar balls from the package.  I see builds is there as well.  Somewhere along the way I must have stuttered while editing and introduced the problematic line.  I?ve removed it and things are back to sanity.

Sometimes it just takes another set of eyes to see the obvious.

?rjp

On Aug 25, 2014, at 2:17 PM, Kevin Ushey <kevinushey at gmail.com> wrote:

> Hi Randall,
> 
> I notice that, in your .Rbuildignore, you have the entry:
> 
>    ^build$
> 
> and I suspect this is the culprit (having being bitten by a similar
> problem before). Some part of the R build / install process creates /
> uses that directory, but having it excluded in .Rbuildignore will
> cause you grief.
> 
> In general, you probably have to consider `build` reserved for use by
> R, when developing R packages.
> 
> Cheers,
> Kevin
> 
> On Mon, Aug 25, 2014 at 11:10 AM, Randall Pruim <rpruim at calvin.edu> wrote:
>> I?m preparing a package (fastR) for submission to CRAN, but the vignette index keeps going AWOL, or at least R CMD check ?as-cran thinks so. I?ve tried several things and gave myself the weekend to think of other things, but I can?t figure it out.  Perhaps someone on the list can lend a hand.
>> 
>> Here?s one example situation, where I build the index.html file myself and put it in inst/doc/index.html
>> 
>> $ cat fastR.Rcheck/00check.log | grep -v OK
>> * using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
>> * using R Under development (unstable) (2014-08-21 r66456)
>> * using platform: x86_64-apple-darwin13.1.0 (64-bit)
>> * using session charset: UTF-8
>> * checking extension type ... Package
>> * this is package ?fastR? version ?0.8-0?
>> * checking CRAN incoming feasibility ... NOTE
>> Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
>> Package has a VignetteBuilder field but no prebuilt vignette index.
>> NOTE: There was 1 note.
>> 
>> $ tar -tf fastR_0.8-0.tar.gz | grep inst/doc
>> fastR/inst/doc/
>> fastR/inst/doc/Errata.Rnw
>> fastR/inst/doc/Errata.pdf
>> fastR/inst/doc/Updates.R
>> fastR/inst/doc/Updates.Rnw
>> fastR/inst/doc/Updates.pdf
>> fastR/inst/doc/index.html
>> 
>> There is an index.html in the tar ball.  And If I install the package from the tar ball, the index appears as it should in the package.
>> 
>> I would be happy with the auto-generated index, but that doesn?t seem to be working either.  If I remove index.html I get
>> 
>> $ grep -v OK fastR.Rcheck/00check.log
>> * using log directory ?/Users/rpruim/projects/github/fastR/fastR.Rcheck?
>> * using R Under development (unstable) (2014-08-21 r66456)
>> * using platform: x86_64-apple-darwin13.1.0 (64-bit)
>> * using session charset: UTF-8
>> * checking extension type ... Package
>> * this is package ?fastR? version ?0.8-1?
>> * checking CRAN incoming feasibility ... NOTE
>> Maintainer: ?Randall Pruim <rpruim at calvin.edu>?
>> Package has a VignetteBuilder field but no prebuilt vignette index.
>> NOTE: There was 1 note.
>> 
>> $ tar -tf fastR_0.8-1.tar.gz | grep inst/doc
>> fastR/inst/doc/
>> fastR/inst/doc/Errata.Rnw
>> fastR/inst/doc/Errata.pdf
>> fastR/inst/doc/Updates.R
>> fastR/inst/doc/Updates.Rnw
>> fastR/inst/doc/Updates.pdf
>> 
>> Comparing with other successful packages created last week, it doesn?t appear that the tar ball contains the vignette index for those either ? or perhaps I don?t know what I?m looking for.
>> 
>> $ tar -tf mosaic_0.9.1-3.tar.gz | grep -i index
>> mosaic/demo/00Index
>> 
>> (mosaic passes checks fine and are already on CRAN.)
>> 
>> Both packages use knitr to convert Rnw to PDF.  mosaic also uses R.rsp to include static PDFs.
>> 
>> $ grep -i vig  mosaic/DESCRIPTION
>> VignetteBuilder: knitr, R.rsp
>> 
>> [09:22][rpruim at Mac21521:~/projects/github]
>> $ grep -i vig  fastR/DESCRIPTION
>> VignetteBuilder: knitr
>> 
>> $ grep  Vig mosaic/vignettes/*Rnw
>> %\VignetteIndexEntry{mosaic resources}
>> %\VignettePackage{mosaic}
>> %\VignetteKeywords{mosaic, vignettes, resources, references}
>> %\VignetteEngine{knitr::knitr}
>> 
>> $ grep  Vig fastR/vignettes/*Rnw
>> fastR/vignettes/Errata.Rnw:%\VignetteEngine{knitr::knitr}
>> fastR/vignettes/Errata.Rnw:%\VignetteIndexEntry{Errata}
>> fastR/vignettes/Errata.Rnw:%\VignettePackage{fastR}
>> fastR/vignettes/Errata.Rnw:%\VignetteKeywords{fastR, vignettes}
>> fastR/vignettes/Updates.Rnw:%\VignetteEngine{knitr::knitr}
>> fastR/vignettes/Updates.Rnw:%\VignetteIndexEntry{Updates to R Programming in FASt}
>> fastR/vignettes/Updates.Rnw:%\VignettePackage{fastR}
>> fastR/vignettes/Updates.Rnw:%\VignetteKeywords{mosaic, fastR, vignettes, resources}
>> 
>> There must be some subtle difference between my two packages that I just can?t spot.
>> 
>> Thanks in advance for any pointers about where to look.
>> 
>> ?rjp
>> 
>> PS.  The package is on github and installs fine (vignette index included, even though there is no index.html in the repo) using install_github("fastR", "rpruim")
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Tue Aug 26 10:44:09 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 26 Aug 2014 10:44:09 +0200
Subject: [Rd] dubious behaviour of match.arg() with nested functions.
In-Reply-To: <5B378047-E835-4AA2-80FD-214E782E575C@xs4all.nl>
References: <CAO1zAVb_R22qDehCxzn7WCJhbPTYw8+aWYWzqM4KZEUJaTEnpg@mail.gmail.com>
	<5B378047-E835-4AA2-80FD-214E782E575C@xs4all.nl>
Message-ID: <CAO1zAVb_0t8DYp1VuZ42+tvoxG+zKvH17tRRn1duUwiFahKTWA@mail.gmail.com>

Dear all,

thank you for the explanations, crystal clear now. I'm also officially an
idiot. Functions in files in a package belong to that package and not to
some other package that happens to appear in the name of said function. Ah,
the merits of inheritance (inheriting a complex code base in this case...)

Cheers
Joris


On Mon, Aug 25, 2014 at 6:49 PM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> On 25-08-2014, at 16:27, Joris Meys <jorismeys at gmail.com> wrote:
>
> > Dear all,
> >
> > I initially ran into this problem while rebuilding a package dependent on
> > nleqslv. I got the following error:
> >
> > Error in match.arg(global) : 'arg' must be of length 1
> >
> > This didn't occur in previous versions of nleqslv, but did in the current
> > one (2.4). I think I pinned the problem down to the following example:
> >
> > Take two functions:
> >
> > test <- function(x=c("q","r","s"),global=c("d","e","r","z","q")){
> >  x <- match.arg(x)
> >  global <- match.arg(global)
> >  return(list(x,global))
> > }
> >
> > test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
> >  test(x=x,global=global)
> > }
> >
>
> Can?t  the problem easily be avoided by using a slightly modified version
> of the test2() function?
>
> test2 <- function(x=c("q","r","s"),global=c("d","z","q")){
>  x <- match.arg(x)
> global <- match.arg(global)
>  test(x=x,global=global)
> }
>
> Then test2() would be calling test() as it was intended to be called.
> I?ve tried that and it appears to solve the problem.
>
> So before calling nleqslv within another function use match.arg on those
> arguments with the same name and different defaults.
> And (possibly) document that some arguments expect a single value.
>
> Berend
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Tue Aug 26 18:53:03 2014
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 26 Aug 2014 11:53:03 -0500
Subject: [Rd] `*tmp*`
In-Reply-To: <ED79E0D0-D4AD-4457-8AEB-DB053A6CDE82@oracle.com>
References: <E643113C-AC37-4CFF-83BF-B4B92191F1B6@oracle.com>
	<alpine.DEB.2.02.1408141406320.2519@luke-Latitude>
	<ED79E0D0-D4AD-4457-8AEB-DB053A6CDE82@oracle.com>
Message-ID: <alpine.DEB.2.02.1408261138250.2513@luke-Latitude>

On Thu, 14 Aug 2014, Michael Haupt wrote:

> Hi Luke,
>
> Am 14.08.2014 um 12:08 schrieb luke-tierney at uiowa.edu:
>> This is a consequence of the tricks the interpreter implementation
>> currently plays to do complex assignments. Compiled code works
>> differently:
>>
>>> library(compiler)
>>> cmpfun(function() {
>> +            x<-c(1,2)
>> +    x[1]<-42
>> +    `*tmp*`[1]<-7 # I would expect this one to fail
>> + })()
>> Error in cmpfun(function() { : object '*tmp*' not found
>
> aha, thank you very much! So the behaviour of the AST and bytecode interpreters differ. Which one is authoritative? Can I cherry-pick? (I'll pick the bytecode interpreter's version if I may.)
>
> Is there actually any code out there that *uses* `*tmp*` and would hence break if the bytecode interpreter was used? Is it encouraged to not directly access `*tmp*`?

There should not be -- the language manual I believe had language that
suggests that this is an implementation detail that should not be
relied upon.

>
> I'm asking all these questions because, in FastR, we're currently quite closely mirroring the AST interpreter's behaviour for complex assignments - if this is not an absolute must-have, I'd be very happy about being able to apply a much leaner implementation instead.

The compiler tries to stay very close to the interpreter. The main
departures are (a) assuming certain bindings are not changeable, based
on optimization level, and (b) cleaning up semantics in cases where
the interpreter does things to either improve performance or simplify
implementation that are not really desirable. These departures should
be described in the noweb file in the compielr package.

(b) applies to the complex assignment mechanism. The use of *tmp* was
convenient but unclean. The byte code interpreter has a stack that is
can use for storing the intermediate stuff that *tmp* is used for in
the interpreter. It would be possible in priciple to make the match
the compiler behavior. I don't know how hard it would be to do so
without a performance hit (or maybe with a gain) -- I just haven't
looked.

The complex assignment mechanism is a very tricky bit of code, and
there are a lot of hidden pitfalls and a number of hidden assumptions
needed for it to work reliable, especially with respect to avoiding
duplication of LHS values, but duplicating when necessary. Another
know issue is that in nested complex assignments the index expressions
will get evaluated twice, which means expressions with side effects
(e.g. ones that generate a random number and update a seed) don't do
what users expect (they _do_ do what the language manual says, since
it implies the multiple evaluation). Addressing this is hard given the
lazy evaluation/nonstandard eval combination, but it would be nice to
see if we can do better.

I keep meaning to write up notes on my current understanding of the
assignment mechanism. I may get to it in a month or two; if i do it
will appear in the R-dev-web tree.

Best,

luke

>
> Best,
>
> Michael
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From friendly at yorku.ca  Tue Aug 26 23:58:34 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 26 Aug 2014 17:58:34 -0400
Subject: [Rd] no visible binding for global variable for data sets in a
	package
Message-ID: <53FD030A.1020709@yorku.ca>

I'm updating the Lahman package of baseball statistics to the 2013 
release. In addition to
the main data sets, the package also contains several convenience 
functions that make use
of these data sets.  These now trigger the notes below from R CMD check 
run with
Win builder, R-devel.  How can I avoid these?

* using R Under development (unstable) (2014-08-25 r66471)
* using platform: x86_64-w64-mingw32 (64-bit)
   ...
* checking R code for possible problems ... NOTE
Label: no visible binding for global variable 'battingLabels'
Label: no visible binding for global variable 'pitchingLabels'
Label: no visible binding for global variable 'fieldingLabels'
battingStats: no visible binding for global variable 'Batting'
battingStats: no visible global function definition for 'mutate'
playerInfo: no visible binding for global variable 'Master'
teamInfo: no visible binding for global variable 'Teams'

One such function:

## function for accessing variable labels

Label <- function(var, labels=rbind(battingLabels, pitchingLabels, 
fieldingLabels)) {
     wanted <- which(labels[,1]==var)
     if (length(wanted)) labels[wanted[1],2] else var
}


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From maechler at stat.math.ethz.ch  Wed Aug 27 11:24:36 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 27 Aug 2014 11:24:36 +0200
Subject: [Rd] no visible binding for global variable for data sets in
	a	package
In-Reply-To: <53FD030A.1020709@yorku.ca>
References: <53FD030A.1020709@yorku.ca>
Message-ID: <21501.41940.216907.982935@stat.math.ethz.ch>

>>>>> Michael Friendly <friendly at yorku.ca>
>>>>>     on Tue, 26 Aug 2014 17:58:34 -0400 writes:

    > I'm updating the Lahman package of baseball statistics to the 2013 
    > release. In addition to
    > the main data sets, the package also contains several convenience 
    > functions that make use
    > of these data sets.  These now trigger the notes below from R CMD check 
    > run with
    > Win builder, R-devel.  How can I avoid these?

    > * using R Under development (unstable) (2014-08-25 r66471)
    > * using platform: x86_64-w64-mingw32 (64-bit)
    > ...
    > * checking R code for possible problems ... NOTE
    > Label: no visible binding for global variable 'battingLabels'
    > Label: no visible binding for global variable 'pitchingLabels'
    > Label: no visible binding for global variable 'fieldingLabels'
    > battingStats: no visible binding for global variable 'Batting'
    > battingStats: no visible global function definition for 'mutate'
    > playerInfo: no visible binding for global variable 'Master'
    > teamInfo: no visible binding for global variable 'Teams'

    > One such function:

    > ## function for accessing variable labels

    > Label <- function(var, labels=rbind(battingLabels, pitchingLabels, 
    > fieldingLabels)) {
    > wanted <- which(labels[,1]==var)
    > if (length(wanted)) labels[wanted[1],2] else var
    > }

and you are using the data sets you mentioned before,
(and the checking has been changed recently here).

This is a bit subtle:
Your data sets are part of your package (thanks to the default
lazyData), but *not* part of the namespace of your package.
Now, the reasoning goes as following: if someone uses a function
from your package, say Label() above, 
by
	Lahman::Label(..)
and your package has not been attached to the search path,
your user will get an error, as the datasets are not found by
Label().

If you consider something like   Lahman::Label(..)
for a bit and the emphasis we put on R functions being the
primary entities, you can understand the current, i.e. new, 
R CMD check warnings.

I see the following two options for you:

1) export all these data sets from your NAMESPACE
   For this (I thinK), you must define them in  Lahman/R/ possibly via a 
   Lahman/R/sysdata.rda

2) rewrite your functions such that ensure the data sets are
   loaded when they are used.


"2)" actually works by adding    
   	stopifnot(require(Lahman, quietly=TRUE))
  as first line in Label() and other such functions.

It works in the sense that  Lahman::Label("yearID")  will
work even when Lahman is not in the search path,
but   R-devel CMD check   will still give the same NOTE,
though you can argue that that note is actally a "false positive".
   
Not sure about another elegant way to make "2)" work, apart from
using  data() on each of the datasets inside the
function.  As I haven't tried it, that may *still* give a
(false) NOTE..

This is a somewhat interesting problem, and I wonder if everyone
else has solved it with '1)' rather than a version of '2)'.

Martin


From pdalgd at gmail.com  Wed Aug 27 12:09:57 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Aug 2014 12:09:57 +0200
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <21501.41940.216907.982935@stat.math.ethz.ch>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
Message-ID: <38F4FA18-F930-4B08-A87E-36583576AB38@gmail.com>

The change would seem to be this

      \item \command{R CMD check} now by default checks code usage
      directly on the package namespace without loading and attaching
      the package and its suggests and enhances.

and perhaps the remedies could be stated more clearly?

Putting the data objects in the namespace would seem the obvious thing to do.

One oddity is that they are sort of in there already:

> Lahman::battingLabels
    variable                             label
1   playerID                    Player ID code
2     yearID                              Year
3      stint                    Player's stint
4     teamID                              Team
5       lgID                            League
6          G                             Games
7  G_batting                   Games as batter
8         AB                           At Bats
9          R                              Runs
10         H                              Hits
11       X2B                           Doubles
12       X3B                           Triples
13        HR                          Homeruns
14       RBI                    Runs Batted In
15        SB                      Stolen Bases
16        CS                   Caught Stealing
17        BB                     Base on Balls
18        SO                        Strikeouts
19       IBB                 Intentional walks
20       HBP                      Hit by pitch
21        SH                    Sacrifice hits
22        SF                   Sacrifice flies
23      GIDP        Grounded into double plays
24     G_Old Old version of games (deprecated)

But then again, actually not:

> Lahman::Label()
Error in rbind(battingLabels, pitchingLabels, fieldingLabels) : 
  object 'battingLabels' not found

This is documented (:: can access datasets made available by lazy-loading), but it sort of suggests that we might want to improve consistency in this area. 

-pd   


On 27 Aug 2014, at 11:24 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Michael Friendly <friendly at yorku.ca>
>>>>>>    on Tue, 26 Aug 2014 17:58:34 -0400 writes:
> 
>> I'm updating the Lahman package of baseball statistics to the 2013 
>> release. In addition to
>> the main data sets, the package also contains several convenience 
>> functions that make use
>> of these data sets.  These now trigger the notes below from R CMD check 
>> run with
>> Win builder, R-devel.  How can I avoid these?
> 
>> * using R Under development (unstable) (2014-08-25 r66471)
>> * using platform: x86_64-w64-mingw32 (64-bit)
>> ...
>> * checking R code for possible problems ... NOTE
>> Label: no visible binding for global variable 'battingLabels'
>> Label: no visible binding for global variable 'pitchingLabels'
>> Label: no visible binding for global variable 'fieldingLabels'
>> battingStats: no visible binding for global variable 'Batting'
>> battingStats: no visible global function definition for 'mutate'
>> playerInfo: no visible binding for global variable 'Master'
>> teamInfo: no visible binding for global variable 'Teams'
> 
>> One such function:
> 
>> ## function for accessing variable labels
> 
>> Label <- function(var, labels=rbind(battingLabels, pitchingLabels, 
>> fieldingLabels)) {
>> wanted <- which(labels[,1]==var)
>> if (length(wanted)) labels[wanted[1],2] else var
>> }
> 
> and you are using the data sets you mentioned before,
> (and the checking has been changed recently here).
> 
> This is a bit subtle:
> Your data sets are part of your package (thanks to the default
> lazyData), but *not* part of the namespace of your package.
> Now, the reasoning goes as following: if someone uses a function
> from your package, say Label() above, 
> by
> 	Lahman::Label(..)
> and your package has not been attached to the search path,
> your user will get an error, as the datasets are not found by
> Label().
> 
> If you consider something like   Lahman::Label(..)
> for a bit and the emphasis we put on R functions being the
> primary entities, you can understand the current, i.e. new, 
> R CMD check warnings.
> 
> I see the following two options for you:
> 
> 1) export all these data sets from your NAMESPACE
>   For this (I thinK), you must define them in  Lahman/R/ possibly via a 
>   Lahman/R/sysdata.rda
> 
> 2) rewrite your functions such that ensure the data sets are
>   loaded when they are used.
> 
> 
> "2)" actually works by adding    
>   	stopifnot(require(Lahman, quietly=TRUE))
>  as first line in Label() and other such functions.
> 
> It works in the sense that  Lahman::Label("yearID")  will
> work even when Lahman is not in the search path,
> but   R-devel CMD check   will still give the same NOTE,
> though you can argue that that note is actally a "false positive".
> 
> Not sure about another elegant way to make "2)" work, apart from
> using  data() on each of the datasets inside the
> function.  As I haven't tried it, that may *still* give a
> (false) NOTE..
> 
> This is a somewhat interesting problem, and I wonder if everyone
> else has solved it with '1)' rather than a version of '2)'.
> 
> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mario at emmenlauer.de  Wed Aug 27 10:03:40 2014
From: mario at emmenlauer.de (Mario Emmenlauer)
Date: Wed, 27 Aug 2014 10:03:40 +0200
Subject: [Rd] working with huge memory: single precision?
Message-ID: <53FD90DC.80802@emmenlauer.de>


Hello,

I'm very new to R and don't know much about it yet. I would like
to develop R-programs that work with data of sizes of 10^10 - 10^11
data points. We have very-high-memory machines with ~256 GB, but it
would significantly help if I could store the data points in single
precision in RAM instead of double precision. Is that possible?

In the documentation I found a sentence saying its not supported,
at least not out of the box. But I am quite desperate and would also
consider working with an alpha version or with extension packages?

Ideally I would like type promotion to work, i.e. that when using
the data in math operations they should be promoted to double.

Any help is greatly appreciated! All the best,

    Mario



-- 
Mario Emmenlauer BioDataAnalysis             Mobil: +49-(0)151-68108489
Balanstrasse 43                    mailto: mario.emmenlauer * unibas.ch
D-81669 M?nchen                          http://www.marioemmenlauer.de/


From jon at thon.cc  Wed Aug 27 11:45:23 2014
From: jon at thon.cc (Jonathon Love)
Date: Wed, 27 Aug 2014 11:45:23 +0200
Subject: [Rd] R, OSX, should creating SVGs request XQuartz
Message-ID: <53FDA8B3.5020606@thon.cc>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

hi,

on OS X, when you try and use something which depends on X11, and you
don't have XQuartz installed, you receive an error message, it directs
you to download XQuartz, and then it euthanizes your process.

(my guess is that there is a skeleton X11 dylib installed in OS X by
default, and it is responsible for the error message and the
euthanasia. once XQuartz is installed, the skeleton dylib is replaced
with a functioning version)

in my application, i write SVGs using:

grDevices::svg( ... )

this provokes the X11 error message. i was wondering if this is an
erroneous/unnecessary loading of X11, or if grDevices::svg() does in
fact rely on X11 functions?

obviously, if i can avoid making my users install XQuartz if it isn't
necessary (not to mention avoiding the abrupt euthanizing of my
program), that would be ideal from my perspective.

with thanks

jonathon


- -- 

JASP - A Fresh Way to Do Statistics
http://jasp-stats.org/

- --

How happy is he born and taught,
That serveth not another's will;
Whose armour is his honest thought,
And simple truth his utmost skill

This man is freed from servile bands
Of hope to rise, or fear to fall:
Lord of himself, though not of lands,
And, having nothing, yet hath all.

  -- Sir Henry Wotton





-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJT/aizAAoJEH277gjmPGDYDH4P/3gRNBLCM81s6psZQRSY9lfe
jZQ9ZqpjIk68ulyRwl2JxrkHuzCHYbSh6cYRk6N2CBgdxQnfYG0De8dOUHMX6bfh
263yROUTcvQ1/jztqNlvhW0MbpnzVtoCkCXvuAzMx9R0CdLzqmUGZUTkdLESPpdE
5zOkIRtcO/pMuq92MRl3ucYGsP7T+bXRTLY64ZkFnJT3vpNVPBwcIFYigdoxw9cw
8l+PY2iyAn5wyoHbB523GWun5jqgwY1YFnXblftuI5yN5Y1UybOqwfWKnO1367bS
Bsw8Z4oXidTqblfvchDiyD1V/nfrm6f8BdAdi/sZZYh/jWB2vYNdgdVNGBi/R85O
inVqZzxZ/KU30sV+HVW+H3d798m9mWwTtOA9hsO+bXYsxwYsVUhwSHaUACxN7bz3
vXN3C1zq7HvtsOOR+wMpMIrDvTgwx1MKpFUhbA7n8+acqh+nIkNttSS+I6SAA9EO
gP//lBoFy57a5bU1U2vlmvqtWHfJKeIU3BDSchoLn+WUfTdaccKtfgk898lb+Ciu
UIKOocWHrE8cIXUdk+7C6GyrVecZa4fe/LAid1NDbDRgK2Bi5vGeYydA+8OGJzlG
K6m8fpme0mApOopsXrOLURlscY7829/TK9CrM9F+zHD8xm7cs330KHn650aiF0pB
2q2TifMU7Kxar1FiY+Uq
=a93C
-----END PGP SIGNATURE-----


From jwiley.psych at gmail.com  Wed Aug 27 12:47:28 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 27 Aug 2014 20:47:28 +1000
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <38F4FA18-F930-4B08-A87E-36583576AB38@gmail.com>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
	<38F4FA18-F930-4B08-A87E-36583576AB38@gmail.com>
Message-ID: <CANz9Z_+Bwz7avU55Yh9UV-V4fOZYrdWkkziBeMhQYw3PLuXSWg@mail.gmail.com>

I have had similar notes, but in cases where the dataset was created
internally by a function:

* checking R code for possible problems ... NOTE
vm_diagnostics: no visible binding for global variable 'Median'
vm_diagnostics: no visible binding for global variable 'Index'
vm_diagnostics: no visible binding for global variable 'LL'
vm_diagnostics: no visible binding for global variable 'UL'

and the relevant code is here (the function creates a dataset called
'sigma' and always names the variables Index, Median, LL, UL):

  p.sigma <- ggplot(sigma, aes(Index, Median, ymin = LL, ymax = UL)) +
    geom_pointrange() +
    labs(y = "Median + 95% CI for Sigma") +
    theme_classic()

is the appropriate way to remove warnings in this case also to have the
function attach the data it internally created?




On Wed, Aug 27, 2014 at 8:09 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> The change would seem to be this
>
>       \item \command{R CMD check} now by default checks code usage
>       directly on the package namespace without loading and attaching
>       the package and its suggests and enhances.
>
> and perhaps the remedies could be stated more clearly?
>
> Putting the data objects in the namespace would seem the obvious thing to
> do.
>
> One oddity is that they are sort of in there already:
>
> > Lahman::battingLabels
>     variable                             label
> 1   playerID                    Player ID code
> 2     yearID                              Year
> 3      stint                    Player's stint
> 4     teamID                              Team
> 5       lgID                            League
> 6          G                             Games
> 7  G_batting                   Games as batter
> 8         AB                           At Bats
> 9          R                              Runs
> 10         H                              Hits
> 11       X2B                           Doubles
> 12       X3B                           Triples
> 13        HR                          Homeruns
> 14       RBI                    Runs Batted In
> 15        SB                      Stolen Bases
> 16        CS                   Caught Stealing
> 17        BB                     Base on Balls
> 18        SO                        Strikeouts
> 19       IBB                 Intentional walks
> 20       HBP                      Hit by pitch
> 21        SH                    Sacrifice hits
> 22        SF                   Sacrifice flies
> 23      GIDP        Grounded into double plays
> 24     G_Old Old version of games (deprecated)
>
> But then again, actually not:
>
> > Lahman::Label()
> Error in rbind(battingLabels, pitchingLabels, fieldingLabels) :
>   object 'battingLabels' not found
>
> This is documented (:: can access datasets made available by
> lazy-loading), but it sort of suggests that we might want to improve
> consistency in this area.
>
> -pd
>
>
> On 27 Aug 2014, at 11:24 , Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
> >>>>>> Michael Friendly <friendly at yorku.ca>
> >>>>>>    on Tue, 26 Aug 2014 17:58:34 -0400 writes:
> >
> >> I'm updating the Lahman package of baseball statistics to the 2013
> >> release. In addition to
> >> the main data sets, the package also contains several convenience
> >> functions that make use
> >> of these data sets.  These now trigger the notes below from R CMD check
> >> run with
> >> Win builder, R-devel.  How can I avoid these?
> >
> >> * using R Under development (unstable) (2014-08-25 r66471)
> >> * using platform: x86_64-w64-mingw32 (64-bit)
> >> ...
> >> * checking R code for possible problems ... NOTE
> >> Label: no visible binding for global variable 'battingLabels'
> >> Label: no visible binding for global variable 'pitchingLabels'
> >> Label: no visible binding for global variable 'fieldingLabels'
> >> battingStats: no visible binding for global variable 'Batting'
> >> battingStats: no visible global function definition for 'mutate'
> >> playerInfo: no visible binding for global variable 'Master'
> >> teamInfo: no visible binding for global variable 'Teams'
> >
> >> One such function:
> >
> >> ## function for accessing variable labels
> >
> >> Label <- function(var, labels=rbind(battingLabels, pitchingLabels,
> >> fieldingLabels)) {
> >> wanted <- which(labels[,1]==var)
> >> if (length(wanted)) labels[wanted[1],2] else var
> >> }
> >
> > and you are using the data sets you mentioned before,
> > (and the checking has been changed recently here).
> >
> > This is a bit subtle:
> > Your data sets are part of your package (thanks to the default
> > lazyData), but *not* part of the namespace of your package.
> > Now, the reasoning goes as following: if someone uses a function
> > from your package, say Label() above,
> > by
> >       Lahman::Label(..)
> > and your package has not been attached to the search path,
> > your user will get an error, as the datasets are not found by
> > Label().
> >
> > If you consider something like   Lahman::Label(..)
> > for a bit and the emphasis we put on R functions being the
> > primary entities, you can understand the current, i.e. new,
> > R CMD check warnings.
> >
> > I see the following two options for you:
> >
> > 1) export all these data sets from your NAMESPACE
> >   For this (I thinK), you must define them in  Lahman/R/ possibly via a
> >   Lahman/R/sysdata.rda
> >
> > 2) rewrite your functions such that ensure the data sets are
> >   loaded when they are used.
> >
> >
> > "2)" actually works by adding
> >       stopifnot(require(Lahman, quietly=TRUE))
> >  as first line in Label() and other such functions.
> >
> > It works in the sense that  Lahman::Label("yearID")  will
> > work even when Lahman is not in the search path,
> > but   R-devel CMD check   will still give the same NOTE,
> > though you can argue that that note is actally a "false positive".
> >
> > Not sure about another elegant way to make "2)" work, apart from
> > using  data() on each of the datasets inside the
> > function.  As I haven't tried it, that may *still* give a
> > (false) NOTE..
> >
> > This is a somewhat interesting problem, and I wonder if everyone
> > else has solved it with '1)' rather than a version of '2)'.
> >
> > Martin
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Wed Aug 27 13:02:51 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 27 Aug 2014 11:02:51 +0000
Subject: [Rd] no visible binding for global variable for data sets in
	a	package
In-Reply-To: <mailman.24.1409133611.20308.r-devel@r-project.org>
References: <mailman.24.1409133611.20308.r-devel@r-project.org>
Message-ID: <61E8505F-5946-4461-AE56-B20CE0AF3B8F@anu.edu.au>

Re solution 2, the following is in the function tabFarsDead()
the latest (0.55) version of gamclass:

  data('FARS', package='gamclass', envir=environment())
  FARS <- get("FARS", envir=environment())

The second statement is, strictly, redundant, but it
makes the syntax checker happy.  Another possibility
might be:

  FARS <- NULL
 data('FARS', package='gamclass', envir=environment())

I do not know whether this passes.

An FAQ that offers preferred solutions to such chestnuts,
or a web page, or a blog, would seem to me useful.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

phone : +61 2 (6125)3473    fax  : +61 2(6125)5549

Centre for Mathematics & Its Applications, Room 1194,

John Dedman Mathematical Sciences Building (Building 27)

Australian National University, Canberra ACT 0200.


On 27 Aug 2014, at 20:00, <r-devel-request at r-project.org<mailto:r-devel-request at r-project.org>> <r-devel-request at r-project.org<mailto:r-devel-request at r-project.org>> wrote:

From: Martin Maechler <maechler at stat.math.ethz.ch<mailto:maechler at stat.math.ethz.ch>>
Subject: Re: [Rd] no visible binding for global variable for data sets in a package
Date: 27 August 2014 19:24:36 AEST
To: Michael Friendly <friendly at yorku.ca<mailto:friendly at yorku.ca>>
Cc: r-devel <r-devel at r-project.org<mailto:r-devel at r-project.org>>
Reply-To: Martin Maechler <maechler at stat.math.ethz.ch<mailto:maechler at stat.math.ethz.ch>>


Michael Friendly <friendly at yorku.ca<mailto:friendly at yorku.ca>>
   on Tue, 26 Aug 2014 17:58:34 -0400 writes:

I'm updating the Lahman package of baseball statistics to the 2013
release. In addition to
the main data sets, the package also contains several convenience
functions that make use
of these data sets.  These now trigger the notes below from R CMD check
run with
Win builder, R-devel.  How can I avoid these?

* using R Under development (unstable) (2014-08-25 r66471)
* using platform: x86_64-w64-mingw32 (64-bit)
...
* checking R code for possible problems ... NOTE
Label: no visible binding for global variable 'battingLabels'
Label: no visible binding for global variable 'pitchingLabels'
Label: no visible binding for global variable 'fieldingLabels'
battingStats: no visible binding for global variable 'Batting'
battingStats: no visible global function definition for 'mutate'
playerInfo: no visible binding for global variable 'Master'
teamInfo: no visible binding for global variable 'Teams'

One such function:

## function for accessing variable labels

Label <- function(var, labels=rbind(battingLabels, pitchingLabels,
fieldingLabels)) {
wanted <- which(labels[,1]==var)
if (length(wanted)) labels[wanted[1],2] else var
}

and you are using the data sets you mentioned before,
(and the checking has been changed recently here).

This is a bit subtle:
Your data sets are part of your package (thanks to the default
lazyData), but *not* part of the namespace of your package.
Now, the reasoning goes as following: if someone uses a function
from your package, say Label() above,
by
Lahman::Label(..)
and your package has not been attached to the search path,
your user will get an error, as the datasets are not found by
Label().

If you consider something like   Lahman::Label(..)
for a bit and the emphasis we put on R functions being the
primary entities, you can understand the current, i.e. new,
R CMD check warnings.

I see the following two options for you:

1) export all these data sets from your NAMESPACE
  For this (I thinK), you must define them in  Lahman/R/ possibly via a
  Lahman/R/sysdata.rda

2) rewrite your functions such that ensure the data sets are
  loaded when they are used.


"2)" actually works by adding
   stopifnot(require(Lahman, quietly=TRUE))
 as first line in Label() and other such functions.

It works in the sense that  Lahman::Label("yearID")  will
work even when Lahman is not in the search path,
but   R-devel CMD check   will still give the same NOTE,
though you can argue that that note is actally a "false positive".

Not sure about another elegant way to make "2)" work, apart from
using  data() on each of the datasets inside the
function.  As I haven't tried it, that may *still* give a
(false) NOTE..

This is a somewhat interesting problem, and I wonder if everyone
else has solved it with '1)' rather than a version of '2)'.

Martin


	[[alternative HTML version deleted]]


From friendly at yorku.ca  Wed Aug 27 15:29:57 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 27 Aug 2014 09:29:57 -0400
Subject: [Rd] no visible binding for global variable for data sets in a
 package
In-Reply-To: <21501.41940.216907.982935@stat.math.ethz.ch>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
Message-ID: <53FDDD55.1040807@yorku.ca>

On 8/27/2014 5:24 AM, Martin Maechler wrote:
>>>>>> Michael Friendly <friendly at yorku.ca>
>>>>>>      on Tue, 26 Aug 2014 17:58:34 -0400 writes:
>      > I'm updating the Lahman package of baseball statistics to the 2013
>      > release. In addition to
>      > the main data sets, the package also contains several convenience
>      > functions that make use
>      > of these data sets.  These now trigger the notes below from R CMD check
>      > run with
>      > Win builder, R-devel.  How can I avoid these?
>
>      > * using R Under development (unstable) (2014-08-25 r66471)
>      > * using platform: x86_64-w64-mingw32 (64-bit)
>      > ...
>      > * checking R code for possible problems ... NOTE
>      > Label: no visible binding for global variable 'battingLabels'
>      > Label: no visible binding for global variable 'pitchingLabels'
>      > Label: no visible binding for global variable 'fieldingLabels'
>      > battingStats: no visible binding for global variable 'Batting'
>      > battingStats: no visible global function definition for 'mutate'
>      > playerInfo: no visible binding for global variable 'Master'
>      > teamInfo: no visible binding for global variable 'Teams'
>
>      > One such function:
>
>      > ## function for accessing variable labels
>
>      > Label <- function(var, labels=rbind(battingLabels, pitchingLabels,
>      > fieldingLabels)) {
>      > wanted <- which(labels[,1]==var)
>      > if (length(wanted)) labels[wanted[1],2] else var
>      > }
>
> and you are using the data sets you mentioned before,
> (and the checking has been changed recently here).
>
> This is a bit subtle:
> Your data sets are part of your package (thanks to the default
> lazyData), but *not* part of the namespace of your package.
> Now, the reasoning goes as following: if someone uses a function
> from your package, say Label() above,
> by
> 	Lahman::Label(..)
> and your package has not been attached to the search path,
> your user will get an error, as the datasets are not found by
> Label().
>
> If you consider something like   Lahman::Label(..)
> for a bit and the emphasis we put on R functions being the
> primary entities, you can understand the current, i.e. new,
> R CMD check warnings.
Thanks for this explicit explanation.  Now I understand why this occurs.
>
> I see the following two options for you:
>
> 1) export all these data sets from your NAMESPACE
>     For this (I thinK), you must define them in  Lahman/R/ possibly via a
>     Lahman/R/sysdata.rda
Not sure I quite understand how this would work.  My NAMESPACE currently 
exports
the few functions in this package:

# all the rest is data
export(battingStats,
     playerInfo,teamInfo,
     Label
     )

Do you mean to simply add all the data sets ('globals')  that are 
referred to in these functions?

# all the rest is data
export(battingStats,
     playerInfo,teamInfo,
     Label,
     battingLabels, pitchingLabels, fieldingLabels,
     Batting, Master, Teams
     )

That seems a bit odd.  Can you actually export data?  Maybe there is a 
need for a
separate NAMESPACE declaration, that might be called either of

exportdata()
globaldata()

>
> 2) rewrite your functions such that ensure the data sets are
>     loaded when they are used.
>
>
> "2)" actually works by adding
>     	stopifnot(require(Lahman, quietly=TRUE))
>    as first line in Label() and other such functions.
>
> It works in the sense that  Lahman::Label("yearID")  will
> work even when Lahman is not in the search path,
> but   R-devel CMD check   will still give the same NOTE,
> though you can argue that that note is actally a "false positive".
So, this would be version 1 of "2)":

Label <- function(var, labels) {
     stopifnot(require(Lahman, quietly=TRUE))
     if(missing(labels)) labels <- rbind(battingLabels, pitchingLabels, 
fieldingLabels)
     wanted <- which(labels[,1]==var)
     if (length(wanted)) labels[wanted[1],2] else var
}

And this would be version 2, using data():

Label <- function(var, labels) {
     stopifnot(require(Lahman, quietly=TRUE))
     if(missing(labels)) {
         data(battingLabels); data(pitchingLabels); data(fieldingLabels)
         labels <- rbind(battingLabels, pitchingLabels, fieldingLabels)
         }
     wanted <- which(labels[,1]==var)
     if (length(wanted)) labels[wanted[1],2] else var
}


>     
> Not sure about another elegant way to make "2)" work, apart from
> using  data() on each of the datasets inside the
> function.  As I haven't tried it, that may *still* give a
> (false) NOTE..
>
> This is a somewhat interesting problem, and I wonder if everyone
> else has solved it with '1)' rather than a version of '2)'.
>
> Martin
>     


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From simon.urbanek at r-project.org  Wed Aug 27 15:43:16 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 27 Aug 2014 09:43:16 -0400
Subject: [Rd] working with huge memory: single precision?
In-Reply-To: <53FD90DC.80802@emmenlauer.de>
References: <53FD90DC.80802@emmenlauer.de>
Message-ID: <1A3BE161-C838-4E3D-A24F-257A19F2D9FC@r-project.org>

Mario,

On Aug 27, 2014, at 4:03 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:

> 
> Hello,
> 
> I'm very new to R and don't know much about it yet. I would like
> to develop R-programs that work with data of sizes of 10^10 - 10^11
> data points. We have very-high-memory machines with ~256 GB, but it
> would significantly help if I could store the data points in single
> precision in RAM instead of double precision. Is that possible?
> 

You can (e.g. in raw vectors), but it may not help much since you can't operate on them directly, since no functions in R know how to deal with single-precision floats - all arithmetics are on double precision vectors. If you want to load the data in memory but only work on small pieces, then it would work since you could extract the piece, convert to doubles and carry on.


> In the documentation I found a sentence saying its not supported,
> at least not out of the box. But I am quite desperate and would also
> consider working with an alpha version or with extension packages?
> 
> Ideally I would like type promotion to work, i.e. that when using
> the data in math operations they should be promoted to double.
> 

That won't work automatically that way, but you cloud write methods for operators on your new type class and implement it as coercion + call to the regular operators. You may take a hint from the 64-bit int packages and I dimly recall that some of the mem-mapping packages (bigMemory, ff, ..) may also support single-precision storage.

Cheers,
Simon



> Any help is greatly appreciated! All the best,
> 
>    Mario
> 
> 
> 
> -- 
> Mario Emmenlauer BioDataAnalysis             Mobil: +49-(0)151-68108489
> Balanstrasse 43                    mailto: mario.emmenlauer * unibas.ch
> D-81669 M?nchen                          http://www.marioemmenlauer.de/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Wed Aug 27 15:49:32 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 27 Aug 2014 09:49:32 -0400
Subject: [Rd] R, OSX, should creating SVGs request XQuartz
In-Reply-To: <53FDA8B3.5020606@thon.cc>
References: <53FDA8B3.5020606@thon.cc>
Message-ID: <3BF3453B-FF9A-4CC1-9F97-BE8CB09EC663@r-project.org>

On Aug 27, 2014, at 5:45 AM, Jonathon Love <jon at thon.cc> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
> 
> hi,
> 
> on OS X, when you try and use something which depends on X11, and you
> don't have XQuartz installed, you receive an error message, it directs
> you to download XQuartz, and then it euthanizes your process.
> 
> (my guess is that there is a skeleton X11 dylib installed in OS X by
> default, and it is responsible for the error message and the
> euthanasia. once XQuartz is installed, the skeleton dylib is replaced
> with a functioning version)
> 
> in my application, i write SVGs using:
> 
> grDevices::svg( ... )
> 
> this provokes the X11 error message. i was wondering if this is an
> erroneous/unnecessary loading of X11, or if grDevices::svg() does in
> fact rely on X11 functions?
> 

It relies on a library that does: cairo
It doesn't actually call any X11 calls for the SVG backend, but since cairo also supports X11 back-end it has to link against X11. Apple chose to write the stub in such a way that it kicks in when you load X11 even if you don't actually call it.

The only way out would be to compile your own cairographics library and R with disabled X11 support.

Cheers,
Simon



> obviously, if i can avoid making my users install XQuartz if it isn't
> necessary (not to mention avoiding the abrupt euthanizing of my
> program), that would be ideal from my perspective.
> 
> with thanks
> 
> jonathon
> 
> 
> - -- 
> 
> JASP - A Fresh Way to Do Statistics
> http://jasp-stats.org/
> 
> - --
> 
> How happy is he born and taught,
> That serveth not another's will;
> Whose armour is his honest thought,
> And simple truth his utmost skill
> 
> This man is freed from servile bands
> Of hope to rise, or fear to fall:
> Lord of himself, though not of lands,
> And, having nothing, yet hath all.
> 
>  -- Sir Henry Wotton
> 
> 
> 
> 
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
> Comment: GPGTools - https://gpgtools.org
> 
> iQIcBAEBCgAGBQJT/aizAAoJEH277gjmPGDYDH4P/3gRNBLCM81s6psZQRSY9lfe
> jZQ9ZqpjIk68ulyRwl2JxrkHuzCHYbSh6cYRk6N2CBgdxQnfYG0De8dOUHMX6bfh
> 263yROUTcvQ1/jztqNlvhW0MbpnzVtoCkCXvuAzMx9R0CdLzqmUGZUTkdLESPpdE
> 5zOkIRtcO/pMuq92MRl3ucYGsP7T+bXRTLY64ZkFnJT3vpNVPBwcIFYigdoxw9cw
> 8l+PY2iyAn5wyoHbB523GWun5jqgwY1YFnXblftuI5yN5Y1UybOqwfWKnO1367bS
> Bsw8Z4oXidTqblfvchDiyD1V/nfrm6f8BdAdi/sZZYh/jWB2vYNdgdVNGBi/R85O
> inVqZzxZ/KU30sV+HVW+H3d798m9mWwTtOA9hsO+bXYsxwYsVUhwSHaUACxN7bz3
> vXN3C1zq7HvtsOOR+wMpMIrDvTgwx1MKpFUhbA7n8+acqh+nIkNttSS+I6SAA9EO
> gP//lBoFy57a5bU1U2vlmvqtWHfJKeIU3BDSchoLn+WUfTdaccKtfgk898lb+Ciu
> UIKOocWHrE8cIXUdk+7C6GyrVecZa4fe/LAid1NDbDRgK2Bi5vGeYydA+8OGJzlG
> K6m8fpme0mApOopsXrOLURlscY7829/TK9CrM9F+zHD8xm7cs330KHn650aiF0pB
> 2q2TifMU7Kxar1FiY+Uq
> =a93C
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ripley at stats.ox.ac.uk  Wed Aug 27 16:00:27 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 Aug 2014 15:00:27 +0100
Subject: [Rd] working with huge memory: single precision?
In-Reply-To: <1A3BE161-C838-4E3D-A24F-257A19F2D9FC@r-project.org>
References: <53FD90DC.80802@emmenlauer.de>
	<1A3BE161-C838-4E3D-A24F-257A19F2D9FC@r-project.org>
Message-ID: <53FDE47B.8090000@stats.ox.ac.uk>

On 27/08/2014 14:43, Simon Urbanek wrote:
> Mario,
>
> On Aug 27, 2014, at 4:03 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
>
>>
>> Hello,
>>
>> I'm very new to R and don't know much about it yet. I would like
>> to develop R-programs that work with data of sizes of 10^10 - 10^11
>> data points. We have very-high-memory machines with ~256 GB, but it
>> would significantly help if I could store the data points in single
>> precision in RAM instead of double precision. Is that possible?
>>
>
> You can (e.g. in raw vectors), but it may not help much since you can't operate on them directly, since no functions in R know how to deal with single-precision floats - all arithmetics are on double precision vectors. If you want to load the data in memory but only work on small pieces, then it would work since you could extract the piece, convert to doubles and carry on.

We have almost no idea what you want to do with the data, but in my 
experience datasets of a billion cases are best divided into homogeneous 
groups for analysis followed by a meta-analysis.  I've yet to see an 
example where storing the data in an efficient RDBMS and loading 
sections into multiple R sessions did not make a better workflow.  They 
may exist: they are not the norm.

And BTW, 256GB is not really a lot of RAM, and storing as floats would 
only reduce the footprint 0.5x.

>
>> In the documentation I found a sentence saying its not supported,
>> at least not out of the box. But I am quite desperate and would also
>> consider working with an alpha version or with extension packages?
>>
>> Ideally I would like type promotion to work, i.e. that when using
>> the data in math operations they should be promoted to double.
>>
>
> That won't work automatically that way, but you cloud write methods for operators on your new type class and implement it as coercion + call to the regular operators. You may take a hint from the 64-bit int packages and I dimly recall that some of the mem-mapping packages (bigMemory, ff, ..) may also support single-precision storage.
>
> Cheers,
> Simon
>
>
>
>> Any help is greatly appreciated! All the best,
>>
>>     Mario
>>
>>
>>
>> --
>> Mario Emmenlauer BioDataAnalysis             Mobil: +49-(0)151-68108489
>> Balanstrasse 43                    mailto: mario.emmenlauer * unibas.ch
>> D-81669 M?nchen                          http://www.marioemmenlauer.de/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From friendly at yorku.ca  Wed Aug 27 16:07:04 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 27 Aug 2014 10:07:04 -0400
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <53FDDD55.1040807@yorku.ca>
References: <53FD030A.1020709@yorku.ca>	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca>
Message-ID: <53FDE608.40801@yorku.ca>

On 8/27/2014 9:29 AM, Michael Friendly wrote:
>> It works in the sense that  Lahman::Label("yearID")  will
>> work even when Lahman is not in the search path,
>> but   R-devel CMD check   will still give the same NOTE,
>> though you can argue that that note is actally a "false positive".
> So, this would be version 1 of "2)":
>
> Label <- function(var, labels) {
>      stopifnot(require(Lahman, quietly=TRUE))
>      if(missing(labels)) labels <- rbind(battingLabels, pitchingLabels,
> fieldingLabels)
>      wanted <- which(labels[,1]==var)
>      if (length(wanted)) labels[wanted[1],2] else var
> }
>
> And this would be version 2, using data():
>
> Label <- function(var, labels) {
>      stopifnot(require(Lahman, quietly=TRUE))
>      if(missing(labels)) {
>          data(battingLabels); data(pitchingLabels); data(fieldingLabels)
>          labels <- rbind(battingLabels, pitchingLabels, fieldingLabels)
>          }
>      wanted <- which(labels[,1]==var)
>      if (length(wanted)) labels[wanted[1],2] else var
> }
>
>

Just to follow up:  R-devel likes this less than it does my initial 
version.  I still get no visible binding NOTES, and complaint about
using data() in a function:

* checking R code for possible problems ... NOTE
Label: no visible binding for global variable 'battingLabels'
Label: no visible binding for global variable 'pitchingLabels'
Label: no visible binding for global variable 'fieldingLabels'
battingStats: no visible binding for global variable 'Batting'
battingStats: no visible global function definition for 'mutate'
playerInfo: no visible binding for global variable 'Master'
teamInfo: no visible binding for global variable 'Teams'

Found the following calls to data() loading into the global environment:
File 'Lahman/R/Label.R':
   data(battingLabels)
   data(pitchingLabels)
   data(fieldingLabels)
See section 'Good practice' in '?data'.


From pdalgd at gmail.com  Wed Aug 27 16:41:33 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Aug 2014 16:41:33 +0200
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <53FDE608.40801@yorku.ca>
References: <53FD030A.1020709@yorku.ca>	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
Message-ID: <D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>

Using data() in a package with lazyloaded data seems like asking for trouble to me. But you're making me curious (and I'm too lazy[*] to set up for rebuilding the package myself):

Did you actually try putting battingLabels & friends in the namespace? What happened?

A workaround could be to use rbind(Lahman::battingLabels,....) which runs a bit against the grain for me.

I think the right answer _is_ to export the lazy data; the question is how to do it. There's nothing particularly strange about exporting non-functions ("letters" would be an example, save for the special status of package:base). If you attach the package, the lazyloaded data appear in the same environment as the exported function so they are de facto already in the namespace for the purposes of library() and `::`. So I agree, something like exportData() would be useful. (Or some other mechanism. You might want to be able to export data selectively.)

- pd


[*] "Burdened with pressing obligations", if you like.


On 27 Aug 2014, at 16:07 , Michael Friendly <friendly at yorku.ca> wrote:

> On 8/27/2014 9:29 AM, Michael Friendly wrote:
>>> It works in the sense that  Lahman::Label("yearID")  will
>>> work even when Lahman is not in the search path,
>>> but   R-devel CMD check   will still give the same NOTE,
>>> though you can argue that that note is actally a "false positive".
>> So, this would be version 1 of "2)":
>> 
>> Label <- function(var, labels) {
>>     stopifnot(require(Lahman, quietly=TRUE))
>>     if(missing(labels)) labels <- rbind(battingLabels, pitchingLabels,
>> fieldingLabels)
>>     wanted <- which(labels[,1]==var)
>>     if (length(wanted)) labels[wanted[1],2] else var
>> }
>> 
>> And this would be version 2, using data():
>> 
>> Label <- function(var, labels) {
>>     stopifnot(require(Lahman, quietly=TRUE))
>>     if(missing(labels)) {
>>         data(battingLabels); data(pitchingLabels); data(fieldingLabels)
>>         labels <- rbind(battingLabels, pitchingLabels, fieldingLabels)
>>         }
>>     wanted <- which(labels[,1]==var)
>>     if (length(wanted)) labels[wanted[1],2] else var
>> }
>> 
>> 
> 
> Just to follow up:  R-devel likes this less than it does my initial version.  I still get no visible binding NOTES, and complaint about
> using data() in a function:
> 
> * checking R code for possible problems ... NOTE
> Label: no visible binding for global variable 'battingLabels'
> Label: no visible binding for global variable 'pitchingLabels'
> Label: no visible binding for global variable 'fieldingLabels'
> battingStats: no visible binding for global variable 'Batting'
> battingStats: no visible global function definition for 'mutate'
> playerInfo: no visible binding for global variable 'Master'
> teamInfo: no visible binding for global variable 'Teams'
> 
> Found the following calls to data() loading into the global environment:
> File 'Lahman/R/Label.R':
>  data(battingLabels)
>  data(pitchingLabels)
>  data(fieldingLabels)
> See section 'Good practice' in '?data'.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Wed Aug 27 16:48:30 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 27 Aug 2014 09:48:30 -0500
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
Message-ID: <CABdHhvE1NVHibz6rzcRzcdeRZMA2gjCzzEkiE7eENoTSE5=+1Q@mail.gmail.com>

> I think the right answer _is_ to export the lazy data; the question is how to do it. There's nothing particularly strange about exporting non-functions ("letters" would be an example, save for the special status of package:base). If you attach the package, the lazyloaded data appear in the same environment as the exported function so they are de facto already in the namespace for the purposes of library() and `::`. So I agree, something like exportData() would be useful. (Or some other mechanism. You might want to be able to export data selectively.)

I don't think lazyloaded data are in the same environment as exported
functions - getExportedValue() (called by ::) looks first in the
"exports" namespace, then in the "lazydata" namespace:

function (ns, name)
{
    getInternalExportName <- function(name, ns) {
        exports <- getNamespaceInfo(ns, "exports")
        if (exists(name, envir = exports, inherits = FALSE))
            get(get(name, envir = exports, inherits = FALSE),
                envir = ns)
        else {
            ld <- getNamespaceInfo(ns, "lazydata")
            if (exists(name, envir = ld, inherits = FALSE))
                get(name, envir = ld, inherits = FALSE)
            else stop(gettextf("'%s' is not an exported object from
'namespace:%s'",
                name, getNamespaceName(ns)), call. = FALSE, domain = NA)
        }
    }
    ns <- asNamespace(ns)
    if (isBaseNamespace(ns))
        get(name, envir = ns, inherits = FALSE)
    else getInternalExportName(name, ns)
}


(But maybe you just meant the library() and :: behaves as is lazydata
and exports were the same thing)

Hadley

-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Wed Aug 27 16:54:40 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 Aug 2014 15:54:40 +0100
Subject: [Rd] no visible binding for global variable for data sets in a
 package
In-Reply-To: <53FDE608.40801@yorku.ca>
References: <53FD030A.1020709@yorku.ca>	<21501.41940.216907.982935@stat.math.ethz.ch>	<53FDDD55.1040807@yorku.ca>
	<53FDE608.40801@yorku.ca>
Message-ID: <53FDF130.60601@stats.ox.ac.uk>

http://cran.r-project.org/doc/manuals/r-patched/R-exts.html#Suggested-packages 
suggests e.g. Lahman::battingLabels, and that does work for lazy-loaded 
datasets (which is what these appear to be).

We have seen a couple of other instances in which this was needed for 
code within the package.  However, in this case I would have thought 
battingLabels etc were really system data and should be in sysdata.rda. 
  See ?data.

As the reference suggests, putting Lahman on the search path does not 
necessarily work correctly: what if a user (or someone else's package!) 
puts another package on the search path which masks battingLabels? 
Assuming you want the version in the package, you have to say so.  (If 
you do not, supply argument 'labels'.)


On 27/08/2014 15:07, Michael Friendly wrote:
> On 8/27/2014 9:29 AM, Michael Friendly wrote:
>>> It works in the sense that  Lahman::Label("yearID")  will
>>> work even when Lahman is not in the search path,
>>> but   R-devel CMD check   will still give the same NOTE,
>>> though you can argue that that note is actally a "false positive".
>> So, this would be version 1 of "2)":
>>
>> Label <- function(var, labels) {
>>      stopifnot(require(Lahman, quietly=TRUE))
>>      if(missing(labels)) labels <- rbind(battingLabels, pitchingLabels,
>> fieldingLabels)
>>      wanted <- which(labels[,1]==var)
>>      if (length(wanted)) labels[wanted[1],2] else var
>> }
>>
>> And this would be version 2, using data():
>>
>> Label <- function(var, labels) {
>>      stopifnot(require(Lahman, quietly=TRUE))
>>      if(missing(labels)) {
>>          data(battingLabels); data(pitchingLabels); data(fieldingLabels)
>>          labels <- rbind(battingLabels, pitchingLabels, fieldingLabels)
>>          }
>>      wanted <- which(labels[,1]==var)
>>      if (length(wanted)) labels[wanted[1],2] else var
>> }
>>
>>
>
> Just to follow up:  R-devel likes this less than it does my initial
> version.  I still get no visible binding NOTES, and complaint about
> using data() in a function:
>
> * checking R code for possible problems ... NOTE
> Label: no visible binding for global variable 'battingLabels'
> Label: no visible binding for global variable 'pitchingLabels'
> Label: no visible binding for global variable 'fieldingLabels'
> battingStats: no visible binding for global variable 'Batting'
> battingStats: no visible global function definition for 'mutate'
> playerInfo: no visible binding for global variable 'Master'
> teamInfo: no visible binding for global variable 'Teams'
>
> Found the following calls to data() loading into the global environment:
> File 'Lahman/R/Label.R':
>    data(battingLabels)
>    data(pitchingLabels)
>    data(fieldingLabels)
> See section 'Good practice' in '?data'.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From friendly at yorku.ca  Wed Aug 27 19:51:11 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 27 Aug 2014 13:51:11 -0400
Subject: [Rd] no visible binding for global variable for data sets in a
 package
In-Reply-To: <D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
References: <53FD030A.1020709@yorku.ca>	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
Message-ID: <53FE1A8F.3060809@yorku.ca>

On 8/27/2014 10:41 AM, peter dalgaard wrote:
> Using data() in a package with lazyloaded data seems like asking for trouble to me. But you're making me curious (and I'm too lazy[*] to set up for rebuilding the package myself):
>
> Did you actually try putting battingLabels & friends in the namespace? What happened?
Well, I tried this, with NAMESPACE as

# all the rest is data, except we try to export the data sets used 
globally in these functions
export(battingStats,
     playerInfo,teamInfo,
     Label,
     battingLabels, pitchingLabels, fieldingLabels,
     Batting, Master, Teams
     )

R CMD check was even more unhappy, failing immediately, so the attempted 
cure was worse than the original disease.

* checking whether package 'Lahman' can be installed ...Warning: running 
command '"C:/R/R-3.0.3/bin/x64/Rcmd.exe" INSTALL -l 
"C:/eclipse/Lahman2013.Rcheck" --no-html 
"C:\DOCUME~2\WORKSP~1\LAHMAN~1"' had status 1
  ERROR
Installation failed.
See 'C:/eclipse/Lahman2013.Rcheck/00install.out' for details.

00install.out said:

Error in namespaceExport(ns, exports) :
   undefined exports: battingLabels, pitchingLabels, fieldingLabels, 
Batting, Master, Teams
Error: loading failed
Execution halted

My conclusions so far are:

- These are just NOTEs, so I will ignore them for now.  But they will 
probably trigger the CRAN
maintainers to notice them when I resubmit and I will have to plead 
guilty with an explanation.  This makes more useless work for all involved.

- Peter Dalgaard noted the change in R-devel, and nobody so far has 
suggested a working remedy, so a clean solution
seems warranted.  It mentions 'now by default' -- is there a switch for 
this?

The change would seem to be this

       \item \command{R CMD check} now by default checks code usage
       directly on the package namespace without loading and attaching
       the package and its suggests and enhances.

and perhaps the remedies could be stated more clearly?

Alternatively, it isn't common, but it is by no means rare for package 
functions to need to use data sets
in the package, so some mechanism to declare these, perhaps in NAMESPACE 
is needed.
>
> A workaround could be to use rbind(Lahman::battingLabels,....) which runs a bit against the grain for me.
>
> I think the right answer _is_ to export the lazy data; the question is how to do it. There's nothing particularly strange about exporting non-functions ("letters" would be an example, save for the special status of package:base). If you attach the package, the lazyloaded data appear in the same environment as the exported function so they are de facto already in the namespace for the purposes of library() and `::`. So I agree, something like exportData() would be useful. (Or some other mechanism. You might want to be able to export data selectively.)
>
> - pd
>
>
> [*] "Burdened with pressing obligations", if you like.
>
>
> On 27 Aug 2014, at 16:07 , Michael Friendly <friendly at yorku.ca> wrote:
>
>> On 8/27/2014 9:29 AM, Michael Friendly wrote:
>>>> It works in the sense that  Lahman::Label("yearID")  will
>>>> work even when Lahman is not in the search path,
>>>> but   R-devel CMD check   will still give the same NOTE,
>>>> though you can argue that that note is actally a "false positive".
>>> So, this would be version 1 of "2)":
>>>
>>> Label <- function(var, labels) {
>>>      stopifnot(require(Lahman, quietly=TRUE))
>>>      if(missing(labels)) labels <- rbind(battingLabels, pitchingLabels,
>>> fieldingLabels)
>>>      wanted <- which(labels[,1]==var)
>>>      if (length(wanted)) labels[wanted[1],2] else var
>>> }
>>>
>>> And this would be version 2, using data():
>>>
>>> Label <- function(var, labels) {
>>>      stopifnot(require(Lahman, quietly=TRUE))
>>>      if(missing(labels)) {
>>>          data(battingLabels); data(pitchingLabels); data(fieldingLabels)
>>>          labels <- rbind(battingLabels, pitchingLabels, fieldingLabels)
>>>          }
>>>      wanted <- which(labels[,1]==var)
>>>      if (length(wanted)) labels[wanted[1],2] else var
>>> }
>>>
>>>
>> Just to follow up:  R-devel likes this less than it does my initial version.  I still get no visible binding NOTES, and complaint about
>> using data() in a function:
>>
>> * checking R code for possible problems ... NOTE
>> Label: no visible binding for global variable 'battingLabels'
>> Label: no visible binding for global variable 'pitchingLabels'
>> Label: no visible binding for global variable 'fieldingLabels'
>> battingStats: no visible binding for global variable 'Batting'
>> battingStats: no visible global function definition for 'mutate'
>> playerInfo: no visible binding for global variable 'Master'
>> teamInfo: no visible binding for global variable 'Teams'
>>
>> Found the following calls to data() loading into the global environment:
>> File 'Lahman/R/Label.R':
>>   data(battingLabels)
>>   data(pitchingLabels)
>>   data(fieldingLabels)
>> See section 'Good practice' in '?data'.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From h.wickham at gmail.com  Wed Aug 27 20:49:04 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 27 Aug 2014 13:49:04 -0500
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <53FE1A8F.3060809@yorku.ca>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
	<53FE1A8F.3060809@yorku.ca>
Message-ID: <CABdHhvE8geMgcOcXr8YsKqNd1FSWdehG1xE1emeVXos-5RTKzg@mail.gmail.com>

On Wed, Aug 27, 2014 at 12:51 PM, Michael Friendly <friendly at yorku.ca> wrote:
> On 8/27/2014 10:41 AM, peter dalgaard wrote:
>>
>> Using data() in a package with lazyloaded data seems like asking for
>> trouble to me. But you're making me curious (and I'm too lazy[*] to set up
>> for rebuilding the package myself):
>>
>> Did you actually try putting battingLabels & friends in the namespace?
>> What happened?
>
> Well, I tried this, with NAMESPACE as
>
> # all the rest is data, except we try to export the data sets used globally
> in these functions
>
> export(battingStats,
>     playerInfo,teamInfo,
>     Label,
>     battingLabels, pitchingLabels, fieldingLabels,
>     Batting, Master, Teams
>     )
>
> R CMD check was even more unhappy, failing immediately, so the attempted
> cure was worse than the original disease.

If you want to export your datasets, you'll need to put them in R/sysdata.rda.

But I think Brian suggested the right fix: use Lahmann::Batting
instead of Batting. (And leave everything else as is)

Hadley

-- 
http://had.co.nz/


From pdalgd at gmail.com  Wed Aug 27 21:05:28 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Aug 2014 21:05:28 +0200
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <53FE1A8F.3060809@yorku.ca>
References: <53FD030A.1020709@yorku.ca>	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
	<53FE1A8F.3060809@yorku.ca>
Message-ID: <F94B7B13-4417-413F-8B9F-DECC1307908C@gmail.com>


On 27 Aug 2014, at 19:51 , Michael Friendly <friendly at yorku.ca> wrote:

> - Peter Dalgaard noted the change in R-devel, and nobody so far has suggested a working remedy, so a clean solution
> seems warranted. 

Actually, both Peter Dalgaard and Brian Ripley suggested Lahman:battingLabels, and, with the current semantics at least, it does seem to be recommendable to namespace-qualify any such datasets, lest you be a potential victim of variable masking.

(See also my reply to Hadley, once I get it finalized.)

-pd
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Wed Aug 27 21:09:47 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Aug 2014 21:09:47 +0200
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <CABdHhvE1NVHibz6rzcRzcdeRZMA2gjCzzEkiE7eENoTSE5=+1Q@mail.gmail.com>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
	<CABdHhvE1NVHibz6rzcRzcdeRZMA2gjCzzEkiE7eENoTSE5=+1Q@mail.gmail.com>
Message-ID: <56F97895-26A8-4EC3-B8EB-21243A5448FE@gmail.com>


On 27 Aug 2014, at 16:48 , Hadley Wickham <h.wickham at gmail.com> wrote:

>> I think the right answer _is_ to export the lazy data; the question is how to do it. There's nothing particularly strange about exporting non-functions ("letters" would be an example, save for the special status of package:base). If you attach the package, the lazyloaded data appear in the same environment as the exported function so they are de facto already in the namespace for the purposes of library() and `::`. So I agree, something like exportData() would be useful. (Or some other mechanism. You might want to be able to export data selectively.)
> 
> I don't think lazyloaded data are in the same environment as exported
> functions - getExportedValue() (called by ::) looks first in the
> "exports" namespace, then in the "lazydata" namespace:
> 
> function (ns, name)
> {
>    getInternalExportName <- function(name, ns) {
>        exports <- getNamespaceInfo(ns, "exports")
>        if (exists(name, envir = exports, inherits = FALSE))
>            get(get(name, envir = exports, inherits = FALSE),
>                envir = ns)
>        else {
>            ld <- getNamespaceInfo(ns, "lazydata")
>            if (exists(name, envir = ld, inherits = FALSE))
>                get(name, envir = ld, inherits = FALSE)
>            else stop(gettextf("'%s' is not an exported object from
> 'namespace:%s'",
>                name, getNamespaceName(ns)), call. = FALSE, domain = NA)
>        }
>    }
>    ns <- asNamespace(ns)
>    if (isBaseNamespace(ns))
>        get(name, envir = ns, inherits = FALSE)
>    else getInternalExportName(name, ns)
> }
> 
> 
> (But maybe you just meant the library() and :: behaves as is lazydata
> and exports were the same thing)
> 
> Hadley
> 
> -- 
> http://had.co.nz/

I meant that 

a) :: gives results as if the data was in the namespace

b) if you do

> library(MASS)
> ls("package:MASS")
  [1] "abbey"              "accdeaths"          "addterm"           
  [4] "Aids2"              "Animals"            "anorexia"          
  [7] "area"               "as.fractions"       "bacteria"          
 [10] "bandwidth.nrd"      "bcv"                "beav1"             
 ....

data and functions get put together in the same environment (however, this is not the namespace environment, see later).

What puzzles me is why the distinction between lazydata and exports was there to begin with. 

The implication of the current setup is clearly that pkg::foo() cannot access package::dat by referring to `dat` whereas it can do so if invoked as library(pkg); foo(). 

We also have

> get("accdeaths", environment(MASS::addterm))
Error in get("accdeaths", environment(MASS::addterm)) : 
  object 'accdeaths' not found
> library(MASS)
> get("accdeaths", environment(MASS::addterm))
       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov
1973  9007  8106  8928  9137 10017 10826 11317 10744  9713  9938  9161
1974  7750  6981  8038  8422  8714  9512 10120  9823  8743  9129  8710
...

which confused me at first, but it actually just means that "accdeaths" is found on the search path in the latter case. This strikes me as somewhat dangerous: If a package uses one of its own datasets, it can be masked by a later attach() or the global env. 

(I suspect that someone already explained all this a while back, but I just wasn't listening at the time...)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ucfagls at gmail.com  Wed Aug 27 22:20:36 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 27 Aug 2014 14:20:36 -0600
Subject: [Rd] Re R CMD check checking in development version of R
Message-ID: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>

Dear list,

This is related to the change discussed in the thread "no visible binding
for global variables for data sets in a package".

I went to look at the Check results for one of my packages (analogue) on
CRAN: http://cran.r-project.org/web/checks/check_results_analogue.html

Under the r-devel build machines I'm seeing a lot of things like this:

    Stratiplot.default : axis.VarLabs: no visible global function
     definition for ?current.panel.limits?
    Stratiplot.default : axis.VarLabs: no visible global function
     definition for ?panel.axis?
    Stratiplot.default : axis.VarLabs: no visible global function
     definition for ?which.packet?
    Stratiplot.default : axis.VarLabs: no visible global function
     definition for ?axis.default?
    Stratiplot.default: no visible global function definition for ?xyplot?
    Stratiplot.default: no visible binding for global variable
     ?axis.default?
    initCurve: no visible global function definition for ?cca?
    initCurve: no visible global function definition for ?rda?
    oldDistance.default: no visible global function definition for
     ?vegdist?
    panel.Loess: no visible global function definition for
     ?trellis.par.get?
....
    panel.Stratiplot: no visible global function definition for
     ?panel.abline?
    plot3d.prcurve: no visible global function definition for ?rda?
    prcurve: no visible global function definition for ?rda?
    tran.default: no visible global function definition for ?wisconsin?
    tran.default: no visible global function definition for ?decostand?

I realise that I don't importFrom all of those functions in NAMESPACE -
I've missed some so this list is actually very handy. But also I Depend on
packages that provide some of the function complained about.

Is that the cause of these NOTEs? Is the expectation that if I am using a
function from a package, even a package that I have in Depends:, that I
have to explicitly declare these imports in NAMESPACE?

I'm just seeking a bit of clarification on what this new check aims to test
and what is the ideal solution in the view of R Core given this change to R
CMD check.

Thanks in advance

Gavin

-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Wed Aug 27 23:24:37 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 27 Aug 2014 16:24:37 -0500
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
Message-ID: <CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>

> Is that the cause of these NOTEs? Is the expectation that if I am using a
> function from a package, even a package that I have in Depends:, that I
> have to explicitly declare these imports in NAMESPACE?

Yes.

(Otherwise your package won't work if it's only attached and not
loaded. i.e. if someone does analogue::foo() only the imported
functions are available, not the functions in packages you depend on)

(And really you shouldn't have any packages in depends, they should
all be in imports)

Hadley


-- 
http://had.co.nz/


From ucfagls at gmail.com  Thu Aug 28 00:01:53 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 27 Aug 2014 16:01:53 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
Message-ID: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>

On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:

> > Is that the cause of these NOTEs? Is the expectation that if I am using a
> > function from a package, even a package that I have in Depends:, that I
> > have to explicitly declare these imports in NAMESPACE?
>
> Yes.
>
> (Otherwise your package won't work if it's only attached and not
> loaded. i.e. if someone does analogue::foo() only the imported
> functions are available, not the functions in packages you depend on)
>

Cheers Hadley. Thanks for the confirmation, but...

...I don't get this; what is the point of Depends? I thought it was "my
package needs these other packages to work, i.e. be loaded". Hence it is
user error (IMHO ;-) to do `analogue::foo()` without having the
dependencies loaded too.

This check (whilst having found some things I should have imported and
didn't - which is a good thing!) seems to be circumventing the intention of
having something in Depends. Is Depends going to go away?


> (And really you shouldn't have any packages in depends, they should
> all be in imports)


I disagree with *any*; having say vegan loaded when one is using analogue
is a design decision as the latter borrows heavily from and builds upon
vegan. In general I have moved packages that didn't need to be in Depends
into Imports; in the version I am currently doing final tweaks on before it
goes to CRAN I have remove all but vegan from Depends.

Or am I thinking about this in the wrong way?

Thanks again

Gavin


>
> Hadley
>
>
> --
> http://had.co.nz/
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From dtenenba at fhcrc.org  Thu Aug 28 00:09:52 2014
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 27 Aug 2014 15:09:52 -0700 (PDT)
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
Message-ID: <534513610.2281174.1409177392064.JavaMail.root@fhcrc.org>



----- Original Message -----
> From: "Gavin Simpson" <ucfagls at gmail.com>
> To: "Hadley Wickham" <h.wickham at gmail.com>
> Cc: r-devel at r-project.org
> Sent: Wednesday, August 27, 2014 3:01:53 PM
> Subject: Re: [Rd] Re R CMD check checking in development version of R
> 
> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> > > Is that the cause of these NOTEs? Is the expectation that if I am
> > > using a
> > > function from a package, even a package that I have in Depends:,
> > > that I
> > > have to explicitly declare these imports in NAMESPACE?
> >
> > Yes.
> >
> > (Otherwise your package won't work if it's only attached and not
> > loaded. i.e. if someone does analogue::foo() only the imported
> > functions are available, not the functions in packages you depend
> > on)
> >
> 
> Cheers Hadley. Thanks for the confirmation, but...
> 
> ...I don't get this; what is the point of Depends? I thought it was
> "my
> package needs these other packages to work, i.e. be loaded". Hence it
> is
> user error (IMHO ;-) to do `analogue::foo()` without having the
> dependencies loaded too.
> 
> This check (whilst having found some things I should have imported
> and
> didn't - which is a good thing!) seems to be circumventing the
> intention of
> having something in Depends. Is Depends going to go away?
> 
> 
> > (And really you shouldn't have any packages in depends, they should
> > all be in imports)
> 
> 
> I disagree with *any*; having say vegan loaded when one is using
> analogue
> is a design decision as the latter borrows heavily from and builds
> upon
> vegan. In general I have moved packages that didn't need to be in
> Depends
> into Imports; in the version I am currently doing final tweaks on
> before it
> goes to CRAN I have remove all but vegan from Depends.
> 
> Or am I thinking about this in the wrong way?
> 

I've found that if yourpkg (which Depends on theirpkg but does not import it) has yourfunction() which calls some function in theirpkg, and if someone else writes a package which imports yourpkg and calls yourfunction, it will not work. Whereas if yourpkg imported theirpkg (in the NAMESPACE file), it would work. I've had to write to many package maintainers asking them to import things for this reason.

So that in itself is a reason not to use Depends, or at least, to be sure that you import (in your NAMESPACE) whatever's in Depends (in addition to Imports).

Dan


> Thanks again
> 
> Gavin
> 
> 
> >
> > Hadley
> >
> >
> > --
> > http://had.co.nz/
> >
> 
> 
> 
> --
> Gavin Simpson, PhD
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ucfagls at gmail.com  Thu Aug 28 00:19:54 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 27 Aug 2014 16:19:54 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <534513610.2281174.1409177392064.JavaMail.root@fhcrc.org>
References: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<534513610.2281174.1409177392064.JavaMail.root@fhcrc.org>
Message-ID: <CAAHES9x+oDdtE3-Qs5OmDSiFg9213GL7+YHHo4UQjXT6W4jTQQ@mail.gmail.com>

On 27 August 2014 16:09, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:

> ----- Original Message -----
> > From: "Gavin Simpson" <ucfagls at gmail.com>
> > To: "Hadley Wickham" <h.wickham at gmail.com>
> > Cc: r-devel at r-project.org
> > Sent: Wednesday, August 27, 2014 3:01:53 PM
> > Subject: Re: [Rd] Re R CMD check checking in development version of R
> >
> > On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> >
> > > > Is that the cause of these NOTEs? Is the expectation that if I am
> > > > using a
> > > > function from a package, even a package that I have in Depends:,
> > > > that I
> > > > have to explicitly declare these imports in NAMESPACE?
> > >
> > > Yes.
>


> > > (And really you shouldn't have any packages in depends, they should
> > > all be in imports)
> >
> >
> > I disagree with *any*; having say vegan loaded when one is using
> > analogue
> > is a design decision as the latter borrows heavily from and builds
> > upon
> > vegan. In general I have moved packages that didn't need to be in
> > Depends
> > into Imports; in the version I am currently doing final tweaks on
> > before it
> > goes to CRAN I have remove all but vegan from Depends.
> >
> > Or am I thinking about this in the wrong way?
> >
>
> I've found that if yourpkg (which Depends on theirpkg but does not import
> it) has yourfunction() which calls some function in theirpkg, and if
> someone else writes a package which imports yourpkg and calls yourfunction,
> it will not work. Whereas if yourpkg imported theirpkg (in the NAMESPACE
> file), it would work. I've had to write to many package maintainers asking
> them to import things for this reason.
>
> So that in itself is a reason not to use Depends, or at least, to be sure
> that you import (in your NAMESPACE) whatever's in Depends (in addition to
> Imports).
>
> Dan


Dan,

I think we'll just have to differ on this point Dan. Why should I make it
somewhat more complicated for the people I anticipate using my package just
so that I make it easier for developers of other packages to *potentially*
write code using my packages. analogue and vegan have been around for a
long time, since before the required namespaces --- in vegan's case
possibly before there were namespaces in R (or at least before the were in
widespread use), so to change the standard behaviour of loading my package
and getting vegan too is not something I'm going to do lightly. Especially
as there are several papers out there with code written before the
compulsory namespace stuff came to R that assumed vegan was loaded because
thats what `library("analogue")` *did*.

I'm happy to work with developers on issues as they arrive of course. I
just don;t see why their envisioned future needs should trump the needs of
the user now.

If we take your and Hadley's reasoning to the extreme, not a single package
should use Depends in which case what purpose is there for Depends? Until R
Core remove Depends from DESCRIPTION and flag it under `R CMD check`-ing
people, including me, are going to continue using it if that is what they
think is best for their users.

Again, I am happy to be re-educated on this though :-)

Cheers,

G


>
> > Thanks again
> >
> > Gavin
> >
> >
> > >
> > > Hadley
> > >
> > >
> > > --
> > > http://had.co.nz/
> > >
> >
> >
> >
> > --
> > Gavin Simpson, PhD
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Thu Aug 28 00:25:10 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 28 Aug 2014 00:25:10 +0200
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9x+oDdtE3-Qs5OmDSiFg9213GL7+YHHo4UQjXT6W4jTQQ@mail.gmail.com>
References: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>	<534513610.2281174.1409177392064.JavaMail.root@fhcrc.org>
	<CAAHES9x+oDdtE3-Qs5OmDSiFg9213GL7+YHHo4UQjXT6W4jTQQ@mail.gmail.com>
Message-ID: <53FE5AC6.5000209@statistik.tu-dortmund.de>



On 28.08.2014 00:19, Gavin Simpson wrote:
> On 27 August 2014 16:09, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
>
>> ----- Original Message -----
>>> From: "Gavin Simpson" <ucfagls at gmail.com>
>>> To: "Hadley Wickham" <h.wickham at gmail.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Wednesday, August 27, 2014 3:01:53 PM
>>> Subject: Re: [Rd] Re R CMD check checking in development version of R
>>>
>>> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>>>
>>>>> Is that the cause of these NOTEs? Is the expectation that if I am
>>>>> using a
>>>>> function from a package, even a package that I have in Depends:,
>>>>> that I
>>>>> have to explicitly declare these imports in NAMESPACE?
>>>>
>>>> Yes.
>>
>
>
>>>> (And really you shouldn't have any packages in depends, they should
>>>> all be in imports)
>>>
>>>
>>> I disagree with *any*; having say vegan loaded when one is using
>>> analogue
>>> is a design decision as the latter borrows heavily from and builds
>>> upon
>>> vegan. In general I have moved packages that didn't need to be in
>>> Depends
>>> into Imports; in the version I am currently doing final tweaks on
>>> before it
>>> goes to CRAN I have remove all but vegan from Depends.
>>>
>>> Or am I thinking about this in the wrong way?
>>>
>>
>> I've found that if yourpkg (which Depends on theirpkg but does not import
>> it) has yourfunction() which calls some function in theirpkg, and if
>> someone else writes a package which imports yourpkg and calls yourfunction,
>> it will not work. Whereas if yourpkg imported theirpkg (in the NAMESPACE
>> file), it would work. I've had to write to many package maintainers asking
>> them to import things for this reason.
>>
>> So that in itself is a reason not to use Depends, or at least, to be sure
>> that you import (in your NAMESPACE) whatever's in Depends (in addition to
>> Imports).
>>
>> Dan
>
>
> Dan,
>
> I think we'll just have to differ on this point Dan. Why should I make it
> somewhat more complicated for the people I anticipate using my package just
> so that I make it easier for developers of other packages to *potentially*
> write code using my packages. analogue and vegan have been around for a
> long time, since before the required namespaces --- in vegan's case
> possibly before there were namespaces in R (or at least before the were in
> widespread use), so to change the standard behaviour of loading my package
> and getting vegan too is not something I'm going to do lightly. Especially
> as there are several papers out there with code written before the
> compulsory namespace stuff came to R that assumed vegan was loaded because
> thats what `library("analogue")` *did*.
>
> I'm happy to work with developers on issues as they arrive of course. I
> just don;t see why their envisioned future needs should trump the needs of
> the user now.
>
> If we take your and Hadley's reasoning to the extreme, not a single package
> should use Depends in which case what purpose is there for Depends? Until R
> Core remove Depends from DESCRIPTION and flag it under `R CMD check`-ing
> people, including me, are going to continue using it if that is what they
> think is best for their users.
>
> Again, I am happy to be re-educated on this though :-)

If you like, you can fill the search path with lots of packages (and 
make masking of functions more likely), but you shoudl really import 
into your namesoace so that unanticipated order of packages in your 
search path won't break your package.

Best,
Uwe Ligges


From ucfagls at gmail.com  Thu Aug 28 00:34:31 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 27 Aug 2014 16:34:31 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <53FE5AC6.5000209@statistik.tu-dortmund.de>
References: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<534513610.2281174.1409177392064.JavaMail.root@fhcrc.org>
	<CAAHES9x+oDdtE3-Qs5OmDSiFg9213GL7+YHHo4UQjXT6W4jTQQ@mail.gmail.com>
	<53FE5AC6.5000209@statistik.tu-dortmund.de>
Message-ID: <CAAHES9x0iaEcueaZgOJ2LefzXUccu0oO5ZoxE09JT6DW4ANUYA@mail.gmail.com>

On 27 August 2014 16:25, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
<snip />

> Again, I am happy to be re-educated on this though :-)
>>
>
> If you like, you can fill the search path with lots of packages (and make
> masking of functions more likely), but you shoudl really import into your
> namesoace so that unanticipated order of packages in your search path won't
> break your package.
>
> Best,
> Uwe Ligges
>

I do already do that (well, I had missed a few which R-devel CMD check
showed to me). I have a corresponding importFrom(vegan, ....) in my
NAMESPACE even with Depends: vegan in DESCRIPTION.

What I'm pushing back on is the notion that *no* packages should be in
Depends.

Cheers,

G

-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Aug 28 01:24:11 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 27 Aug 2014 18:24:11 -0500
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
Message-ID: <CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>

On Wed, Aug 27, 2014 at 5:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>
> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>> > Is that the cause of these NOTEs? Is the expectation that if I am using
>> > a
>> > function from a package, even a package that I have in Depends:, that I
>> > have to explicitly declare these imports in NAMESPACE?
>>
>> Yes.
>>
>> (Otherwise your package won't work if it's only attached and not
>> loaded. i.e. if someone does analogue::foo() only the imported
>> functions are available, not the functions in packages you depend on)
>
>
> Cheers Hadley. Thanks for the confirmation, but...
>
> ...I don't get this; what is the point of Depends? I thought it was "my
> package needs these other packages to work, i.e. be loaded". Hence it is
> user error (IMHO ;-) to do `analogue::foo()` without having the dependencies
> loaded too.

I'd say: Depends is a historical artefact from ye old days before
package namespaces. Apart from depending on a specific version of R,
you should basically never use depends.  (The one exception is, as
mentioned in R-exts, if you're writing something like latticeExtras
that doesn't make sense unless lattice is already loaded).

> This check (whilst having found some things I should have imported and
> didn't - which is a good thing!) seems to be circumventing the intention of
> having something in Depends. Is Depends going to go away?

I don't think it's going to go away anytime soon, but you should
consider it to be largely deprecated and you should avoid it wherever
possible.

>> (And really you shouldn't have any packages in depends, they should
>> all be in imports)
>
> I disagree with *any*; having say vegan loaded when one is using analogue is
> a design decision as the latter borrows heavily from and builds upon vegan.
> In general I have moved packages that didn't need to be in Depends into
> Imports; in the version I am currently doing final tweaks on before it goes
> to CRAN I have remove all but vegan from Depends.

I think that is a reasonable use case for depends. Here's the exact
text from R-exts: "Field ?Depends? should nowadays be used rarely,
only for packages which are intended to be put on the search path to
make their facilities available to the end user (and not to the
package itself): for example it makes sense that a user of package
latticeExtra would want the functions of package lattice made
available."

Personally I avoid even this use, requiring users of my packages to be
explicit about exactly what packages are on the search path.  You are
of course welcome to your own approach, but I think you'll find it
will become more and more difficult to maintain in time. I recommend
that you bite the bullet now.

Put another way, packages should be extremely conservative about
global side effects (and modifying the search path is such a
side-effect)

Hadley

-- 
http://had.co.nz/


From ucfagls at gmail.com  Thu Aug 28 05:33:12 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Wed, 27 Aug 2014 21:33:12 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
Message-ID: <CAAHES9yXGVs+bzmSs-CEwA2DhGMmOr1cHT2PfkdKzodiP5G=Xw@mail.gmail.com>

On Aug 27, 2014 5:24 PM, "Hadley Wickham"
<snip />
> I'd say: Depends is a historical artefact from ye old days before
> package namespaces. Apart from depending on a specific version of R,
> you should basically never use depends.  (The one exception is, as
> mentioned in R-exts, if you're writing something like latticeExtras
> that doesn't make sense unless lattice is already loaded).

Keeping this nuance in mind when when discussing Depends vs Imports is
important so as to not suggest that there isn't any reason to use Depends
any longer.

I am in full agreement that its use should be limited to exceptional
situations, and have modified my packages accordingly.

Cheers,

G

> > This check (whilst having found some things I should have imported and
> > didn't - which is a good thing!) seems to be circumventing the
intention of
> > having something in Depends. Is Depends going to go away?
>
> I don't think it's going to go away anytime soon, but you should
> consider it to be largely deprecated and you should avoid it wherever
> possible.
>
> >> (And really you shouldn't have any packages in depends, they should
> >> all be in imports)
> >
> > I disagree with *any*; having say vegan loaded when one is using
analogue is
> > a design decision as the latter borrows heavily from and builds upon
vegan.
> > In general I have moved packages that didn't need to be in Depends into
> > Imports; in the version I am currently doing final tweaks on before it
goes
> > to CRAN I have remove all but vegan from Depends.
>
> I think that is a reasonable use case for depends. Here's the exact
> text from R-exts: "Field ?Depends? should nowadays be used rarely,
> only for packages which are intended to be put on the search path to
> make their facilities available to the end user (and not to the
> package itself): for example it makes sense that a user of package
> latticeExtra would want the functions of package lattice made
> available."
>
> Personally I avoid even this use, requiring users of my packages to be
> explicit about exactly what packages are on the search path.  You are
> of course welcome to your own approach, but I think you'll find it
> will become more and more difficult to maintain in time. I recommend
> that you bite the bullet now.
>
> Put another way, packages should be extremely conservative about
> global side effects (and modifying the search path is such a
> side-effect)
>
> Hadley
>
> --
> http://had.co.nz/

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Aug 28 09:56:41 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 28 Aug 2014 08:56:41 +0100
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <2e7cee84622b43e191193825590b6d82@EX-0-HT0.lancs.local>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
	<2e7cee84622b43e191193825590b6d82@EX-0-HT0.lancs.local>
Message-ID: <CANVKczM=5jf08xYfBjXfjS-4D+ny+kcAYmtyMKEf-L35zCe1ew@mail.gmail.com>

And if, like me, you always forget which of Depends and Imports is the
one you are supposed to be using, the mnemonic device is "DEPends is
DEPrecated[1], IMPorts is IMPortant."

Barry

[1] kinda.



On Thu, Aug 28, 2014 at 4:33 AM, Gavin Simpson <ucfagls at gmail.com> wrote:
> On Aug 27, 2014 5:24 PM, "Hadley Wickham"
> <snip />
>> I'd say: Depends is a historical artefact from ye old days before
>> package namespaces. Apart from depending on a specific version of R,
>> you should basically never use depends.  (The one exception is, as
>> mentioned in R-exts, if you're writing something like latticeExtras
>> that doesn't make sense unless lattice is already loaded).
>
> Keeping this nuance in mind when when discussing Depends vs Imports is
> important so as to not suggest that there isn't any reason to use Depends
> any longer.
>
> I am in full agreement that its use should be limited to exceptional
> situations, and have modified my packages accordingly.
>
> Cheers,
>
> G
>
>> > This check (whilst having found some things I should have imported and
>> > didn't - which is a good thing!) seems to be circumventing the
> intention of
>> > having something in Depends. Is Depends going to go away?
>>
>> I don't think it's going to go away anytime soon, but you should
>> consider it to be largely deprecated and you should avoid it wherever
>> possible.
>>
>> >> (And really you shouldn't have any packages in depends, they should
>> >> all be in imports)
>> >
>> > I disagree with *any*; having say vegan loaded when one is using
> analogue is
>> > a design decision as the latter borrows heavily from and builds upon
> vegan.
>> > In general I have moved packages that didn't need to be in Depends into
>> > Imports; in the version I am currently doing final tweaks on before it
> goes
>> > to CRAN I have remove all but vegan from Depends.
>>
>> I think that is a reasonable use case for depends. Here's the exact
>> text from R-exts: "Field ?Depends? should nowadays be used rarely,
>> only for packages which are intended to be put on the search path to
>> make their facilities available to the end user (and not to the
>> package itself): for example it makes sense that a user of package
>> latticeExtra would want the functions of package lattice made
>> available."
>>
>> Personally I avoid even this use, requiring users of my packages to be
>> explicit about exactly what packages are on the search path.  You are
>> of course welcome to your own approach, but I think you'll find it
>> will become more and more difficult to maintain in time. I recommend
>> that you bite the bullet now.
>>
>> Put another way, packages should be extremely conservative about
>> global side effects (and modifying the search path is such a
>> side-effect)
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Aug 28 10:50:44 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 28 Aug 2014 10:50:44 +0200
Subject: [Rd] no visible binding for global variable for data sets in a
	package
In-Reply-To: <56F97895-26A8-4EC3-B8EB-21243A5448FE@gmail.com>
References: <53FD030A.1020709@yorku.ca>
	<21501.41940.216907.982935@stat.math.ethz.ch>
	<53FDDD55.1040807@yorku.ca> <53FDE608.40801@yorku.ca>
	<D13961DB-34D8-4A33-B01E-D8F8BECCB501@gmail.com>
	<CABdHhvE1NVHibz6rzcRzcdeRZMA2gjCzzEkiE7eENoTSE5=+1Q@mail.gmail.com>
	<56F97895-26A8-4EC3-B8EB-21243A5448FE@gmail.com>
Message-ID: <21502.60772.107028.995768@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Wed, 27 Aug 2014 21:09:47 +0200 writes:

    > On 27 Aug 2014, at 16:48 , Hadley Wickham <h.wickham at gmail.com> wrote:

    >>> I think the right answer _is_ to export the lazy data; the question is how to do it. There's nothing particularly strange about exporting non-functions ("letters" would be an example, save for the special status of package:base). If you attach the package, the lazyloaded data appear in the same environment as the exported function so they are de facto already in the namespace for the purposes of library() and `::`. So I agree, something like exportData() would be useful. (Or some other mechanism. You might want to be able to export data selectively.)
    >> 
    >> I don't think lazyloaded data are in the same environment as exported
    >> functions - getExportedValue() (called by ::) looks first in the
    >> "exports" namespace, then in the "lazydata" namespace:
    >> 
    >> function (ns, name)
    >> {
    >> getInternalExportName <- function(name, ns) {
    >> exports <- getNamespaceInfo(ns, "exports")
    >> if (exists(name, envir = exports, inherits = FALSE))
    >> get(get(name, envir = exports, inherits = FALSE),
    >> envir = ns)
    >> else {
    >> ld <- getNamespaceInfo(ns, "lazydata")
    >> if (exists(name, envir = ld, inherits = FALSE))
    >> get(name, envir = ld, inherits = FALSE)
    >> else stop(gettextf("'%s' is not an exported object from
    >> 'namespace:%s'",
    >> name, getNamespaceName(ns)), call. = FALSE, domain = NA)
    >> }
    >> }
    >> ns <- asNamespace(ns)
    >> if (isBaseNamespace(ns))
    >> get(name, envir = ns, inherits = FALSE)
    >> else getInternalExportName(name, ns)
    >> }
    >> 
    >> 
    >> (But maybe you just meant the library() and :: behaves as is lazydata
    >> and exports were the same thing)
    >> 
    >> Hadley
    >> 
    >> -- 
    >> http://had.co.nz/

    > I meant that 

    > a) :: gives results as if the data was in the namespace

    > b) if you do

    >> library(MASS)
    >> ls("package:MASS")
    > [1] "abbey"              "accdeaths"          "addterm"           
    > [4] "Aids2"              "Animals"            "anorexia"          
    > [7] "area"               "as.fractions"       "bacteria"          
    > [10] "bandwidth.nrd"      "bcv"                "beav1"             
    > ....

    > data and functions get put together in the same environment (however, this is not the namespace environment, see later).

    > What puzzles me is why the distinction between lazydata and exports was there to begin with. 

    > The implication of the current setup is clearly that pkg::foo() cannot access package::dat by referring to `dat` whereas it can do so if invoked as library(pkg); foo(). 

    > We also have

    >> get("accdeaths", environment(MASS::addterm))
    > Error in get("accdeaths", environment(MASS::addterm)) : 
    > object 'accdeaths' not found
    >> library(MASS)
    >> get("accdeaths", environment(MASS::addterm))
    > Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov
    > 1973  9007  8106  8928  9137 10017 10826 11317 10744  9713  9938  9161
    > 1974  7750  6981  8038  8422  8714  9512 10120  9823  8743  9129  8710
    > ...

    > which confused me at first, but it actually just means that "accdeaths" is found on the search path in the latter case. This strikes me as somewhat dangerous: If a package uses one of its own datasets, it can be masked by a later attach() or the global env. 

    > (I suspect that someone already explained all this a while back, but I just wasn't listening at the time...)

I did say (as first reply in this thread) that the lazyloaded
datasets where in the package environment, but not
in the package's *namespace* environment -- which is somewhat
exceptional, as otherwise, the namespace envir is typically a superset
of the package envir, and I did mention the solution with
sysdata.rda + NAMESPACE which Brian and Hadley later mentioned, too.
However Michael did not get it well enough (because you
need to read other material), and I do think that is not an
ideal solution for data sets that have help pages, etc; notably
because creating sysdata.rda is not at all part of the package
sources, and hence harder for maintenance and "open source transparency".

The one additional important in the thread was the special
semantic of '::'  which here returns something for
 <pkg>::<obj> which is *not* part of the <pkg>'s namespace,
whereas the use of '::' does suggest to Joe Average to be
working with namespace (as opposed to package) contents.
I agree with your suggestion, Peter, that this looks more
confusing than it should, and ideally, we'd find a better setup.

OTOH, if we additionally allowed something like   exportData(),
we would additionally get data that is both in the package and
namespace environments and other (not exported) data that is
only in the package, so add room for even more confusion.

Martin


From mtmorgan at fhcrc.org  Thu Aug 28 14:29:48 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 28 Aug 2014 05:29:48 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9yXGVs+bzmSs-CEwA2DhGMmOr1cHT2PfkdKzodiP5G=Xw@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>	<CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
	<CAAHES9yXGVs+bzmSs-CEwA2DhGMmOr1cHT2PfkdKzodiP5G=Xw@mail.gmail.com>
Message-ID: <53FF20BC.1060704@fhcrc.org>

On 08/27/2014 08:33 PM, Gavin Simpson wrote:
> On Aug 27, 2014 5:24 PM, "Hadley Wickham"
> <snip />
>> I'd say: Depends is a historical artefact from ye old days before
>> package namespaces. Apart from depending on a specific version of R,
>> you should basically never use depends.  (The one exception is, as
>> mentioned in R-exts, if you're writing something like latticeExtras
>> that doesn't make sense unless lattice is already loaded).
>
> Keeping this nuance in mind when when discussing Depends vs Imports is
> important so as to not suggest that there isn't any reason to use Depends
> any longer.


A common case in Bioconductor is that a package defines a class and methods 
intended for the user; this requires the package to be on the search path (else 
the user wouldn't be able to do anything with the returned object). A class and 
supporting methods can represent significant infrastructure, so that it makes 
sense to separate these in distinct packages. It is not uncommon to find 3-5 or 
more packages in the Depends: field of derived packages for this reason.

Martin

>
> I am in full agreement that its use should be limited to exceptional
> situations, and have modified my packages accordingly.
>
> Cheers,
>
> G
>
>>> This check (whilst having found some things I should have imported and
>>> didn't - which is a good thing!) seems to be circumventing the
> intention of
>>> having something in Depends. Is Depends going to go away?
>>
>> I don't think it's going to go away anytime soon, but you should
>> consider it to be largely deprecated and you should avoid it wherever
>> possible.
>>
>>>> (And really you shouldn't have any packages in depends, they should
>>>> all be in imports)
>>>
>>> I disagree with *any*; having say vegan loaded when one is using
> analogue is
>>> a design decision as the latter borrows heavily from and builds upon
> vegan.
>>> In general I have moved packages that didn't need to be in Depends into
>>> Imports; in the version I am currently doing final tweaks on before it
> goes
>>> to CRAN I have remove all but vegan from Depends.
>>
>> I think that is a reasonable use case for depends. Here's the exact
>> text from R-exts: "Field ?Depends? should nowadays be used rarely,
>> only for packages which are intended to be put on the search path to
>> make their facilities available to the end user (and not to the
>> package itself): for example it makes sense that a user of package
>> latticeExtra would want the functions of package lattice made
>> available."
>>
>> Personally I avoid even this use, requiring users of my packages to be
>> explicit about exactly what packages are on the search path.  You are
>> of course welcome to your own approach, but I think you'll find it
>> will become more and more difficult to maintain in time. I recommend
>> that you bite the bullet now.
>>
>> Put another way, packages should be extremely conservative about
>> global side effects (and modifying the search path is such a
>> side-effect)
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From h.wickham at gmail.com  Thu Aug 28 14:52:21 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 28 Aug 2014 07:52:21 -0500
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <53FF20BC.1060704@fhcrc.org>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
	<CAAHES9yXGVs+bzmSs-CEwA2DhGMmOr1cHT2PfkdKzodiP5G=Xw@mail.gmail.com>
	<53FF20BC.1060704@fhcrc.org>
Message-ID: <CABdHhvEvkLwekWtYxgeFo9fKE8dZHPUzaWV=SOLE9Aox5UNbTA@mail.gmail.com>

>>> I'd say: Depends is a historical artefact from ye old days before
>>> package namespaces. Apart from depending on a specific version of R,
>>> you should basically never use depends.  (The one exception is, as
>>> mentioned in R-exts, if you're writing something like latticeExtras
>>> that doesn't make sense unless lattice is already loaded).
>>
>> Keeping this nuance in mind when when discussing Depends vs Imports is
>> important so as to not suggest that there isn't any reason to use Depends
>> any longer.
>
> A common case in Bioconductor is that a package defines a class and methods
> intended for the user; this requires the package to be on the search path
> (else the user wouldn't be able to do anything with the returned object). A
> class and supporting methods can represent significant infrastructure, so
> that it makes sense to separate these in distinct packages. It is not
> uncommon to find 3-5 or more packages in the Depends: field of derived
> packages for this reason.

For that scenario, is it reasonable to say that every package in
depends must also be in imports?

Hadley

-- 
http://had.co.nz/


From mtmorgan at fhcrc.org  Thu Aug 28 15:05:05 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 28 Aug 2014 06:05:05 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CABdHhvEvkLwekWtYxgeFo9fKE8dZHPUzaWV=SOLE9Aox5UNbTA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<CABdHhvEX3LWudrX-nFiUO1RcgJsYtYhcLOp0FFufHPw8yU1Kag@mail.gmail.com>
	<CAAHES9yXGVs+bzmSs-CEwA2DhGMmOr1cHT2PfkdKzodiP5G=Xw@mail.gmail.com>
	<53FF20BC.1060704@fhcrc.org>
	<CABdHhvEvkLwekWtYxgeFo9fKE8dZHPUzaWV=SOLE9Aox5UNbTA@mail.gmail.com>
Message-ID: <53FF2901.9060409@fhcrc.org>

On 08/28/2014 05:52 AM, Hadley Wickham wrote:
>>>> I'd say: Depends is a historical artefact from ye old days before
>>>> package namespaces. Apart from depending on a specific version of R,
>>>> you should basically never use depends.  (The one exception is, as
>>>> mentioned in R-exts, if you're writing something like latticeExtras
>>>> that doesn't make sense unless lattice is already loaded).
>>>
>>> Keeping this nuance in mind when when discussing Depends vs Imports is
>>> important so as to not suggest that there isn't any reason to use Depends
>>> any longer.
>>
>> A common case in Bioconductor is that a package defines a class and methods
>> intended for the user; this requires the package to be on the search path
>> (else the user wouldn't be able to do anything with the returned object). A
>> class and supporting methods can represent significant infrastructure, so
>> that it makes sense to separate these in distinct packages. It is not
>> uncommon to find 3-5 or more packages in the Depends: field of derived
>> packages for this reason.
>
> For that scenario, is it reasonable to say that every package in
> depends must also be in imports?

Important to pay attention to capitalization here. A package listed in Depends: 
_never_ needs to be listed in Imports:, but will often be import()'ed (in one 
way or another) in the NAMESPACE. Some would argue that listing a package in 
Depends: and Imports: in this case clarifies intent -- provides functionality 
available to the user, and important for the package itself. Others (such as R 
CMD check) view the replication as redundancy.

I think one can imagine scenarios where a package in the Depends: fields does 
not actually have anything import()'ed, e.g., PkgA defines a class, PkgB 
provides some special functionality that returns the class PkgC use PkgB's 
special functionality without ever manipulating the object of PkgA.

Martin Morgan

>
> Hadley
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From therneau at mayo.edu  Thu Aug 28 15:49:29 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 28 Aug 2014 08:49:29 -0500
Subject: [Rd] no visible binding for global variable for data sets in a
	package
Message-ID: <31062c$94enn4@ironport10.mayo.edu>

Here is one rationale for the change, which was useful for my understanding

This arises in the survival package in the survexp function:
     survexp <- function(formula, data, weights, subset, na.action,.... ratetable=survexp.us)

The argument has been changed to survival::survexp.us, soon to be uploaded to CRAN.

Assume that a user has an object named "survexp.us" in their working data, and calls 
survexp without providing a ratetable arguement.  Should they get the package default or 
their own object?  I'd vote for the first, but the current behavior is the latter.  This 
was presented to me as "fixing a bug that has long been present, but we never noticed before."

Now, if the user adds "ratetable=survexp.us" to the call they should get their own 
object.  I've always hated computer systems that ignore explicit direction, assuming they 
know more than me.

Terry Therneau


From simon.urbanek at r-project.org  Thu Aug 28 16:39:37 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 28 Aug 2014 10:39:37 -0400
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
Message-ID: <79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>


On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:

> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
>>> Is that the cause of these NOTEs? Is the expectation that if I am using a
>>> function from a package, even a package that I have in Depends:, that I
>>> have to explicitly declare these imports in NAMESPACE?
>> 
>> Yes.
>> 
>> (Otherwise your package won't work if it's only attached and not
>> loaded. i.e. if someone does analogue::foo() only the imported
>> functions are available, not the functions in packages you depend on)
>> 
> 
> Cheers Hadley. Thanks for the confirmation, but...
> 
> ...I don't get this; what is the point of Depends? I thought it was "my
> package needs these other packages to work, i.e. be loaded". Hence it is
> user error (IMHO ;-) to do `analogue::foo()` without having the
> dependencies loaded too.
> 

No. The point of Depends is that if your package is attached, it also attaches the other packages to make them available for the user. Essentially you're saying "if you want to use my package interactively, you will also want to use those other packages interactively". You still need to use import() to define what exactly is used by your package - as opposed to what you want to be available to the user in case it is attached.

Cheers,
Simon



> This check (whilst having found some things I should have imported and
> didn't - which is a good thing!) seems to be circumventing the intention of
> having something in Depends. Is Depends going to go away?
> 
> 
>> (And really you shouldn't have any packages in depends, they should
>> all be in imports)
> 
> 
> I disagree with *any*; having say vegan loaded when one is using analogue
> is a design decision as the latter borrows heavily from and builds upon
> vegan. In general I have moved packages that didn't need to be in Depends
> into Imports; in the version I am currently doing final tweaks on before it
> goes to CRAN I have remove all but vegan from Depends.
> 
> Or am I thinking about this in the wrong way?
> 
> Thanks again
> 
> Gavin
> 
> 
>> 
>> Hadley
>> 
>> 
>> --
>> http://had.co.nz/
>> 
> 
> 
> 
> -- 
> Gavin Simpson, PhD
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From gunter.berton at gene.com  Thu Aug 28 16:47:22 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 28 Aug 2014 07:47:22 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
Message-ID: <CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>

This is a nice explanation of the Imports/Depends distinction. It
ought to go into the Extensions ref manual imho.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>
>> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>>>> Is that the cause of these NOTEs? Is the expectation that if I am using a
>>>> function from a package, even a package that I have in Depends:, that I
>>>> have to explicitly declare these imports in NAMESPACE?
>>>
>>> Yes.
>>>
>>> (Otherwise your package won't work if it's only attached and not
>>> loaded. i.e. if someone does analogue::foo() only the imported
>>> functions are available, not the functions in packages you depend on)
>>>
>>
>> Cheers Hadley. Thanks for the confirmation, but...
>>
>> ...I don't get this; what is the point of Depends? I thought it was "my
>> package needs these other packages to work, i.e. be loaded". Hence it is
>> user error (IMHO ;-) to do `analogue::foo()` without having the
>> dependencies loaded too.
>>
>
> No. The point of Depends is that if your package is attached, it also attaches the other packages to make them available for the user. Essentially you're saying "if you want to use my package interactively, you will also want to use those other packages interactively". You still need to use import() to define what exactly is used by your package - as opposed to what you want to be available to the user in case it is attached.
>
> Cheers,
> Simon
>
>
>
>> This check (whilst having found some things I should have imported and
>> didn't - which is a good thing!) seems to be circumventing the intention of
>> having something in Depends. Is Depends going to go away?
>>
>>
>>> (And really you shouldn't have any packages in depends, they should
>>> all be in imports)
>>
>>
>> I disagree with *any*; having say vegan loaded when one is using analogue
>> is a design decision as the latter borrows heavily from and builds upon
>> vegan. In general I have moved packages that didn't need to be in Depends
>> into Imports; in the version I am currently doing final tweaks on before it
>> goes to CRAN I have remove all but vegan from Depends.
>>
>> Or am I thinking about this in the wrong way?
>>
>> Thanks again
>>
>> Gavin
>>
>>
>>>
>>> Hadley
>>>
>>>
>>> --
>>> http://had.co.nz/
>>>
>>
>>
>>
>> --
>> Gavin Simpson, PhD
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ravi.varadhan at jhu.edu  Thu Aug 28 17:23:46 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 28 Aug 2014 15:23:46 +0000
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C31247075D@DOM-EB-MAIL1.win.ad.jhu.edu>

Hi,

I second Bert's comment. I would like to go even farther and suggest that it would be really useful if one of the R gurus (like Simon) wrote a relatively non-technical article in the R journal on this topic of "Depends/Imports/Suggested."  Someone like myself would benefit immensely.

Thank you,
Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, August 28, 2014 10:47 AM
To: Simon Urbanek
Cc: r-devel at r-project.org
Subject: Re: [Rd] Re R CMD check checking in development version of R

This is a nice explanation of the Imports/Depends distinction. It ought to go into the Extensions ref manual imho.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
Clifford Stoll




On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>
>> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>>>> Is that the cause of these NOTEs? Is the expectation that if I am 
>>>> using a function from a package, even a package that I have in 
>>>> Depends:, that I have to explicitly declare these imports in NAMESPACE?
>>>
>>> Yes.
>>>
>>> (Otherwise your package won't work if it's only attached and not 
>>> loaded. i.e. if someone does analogue::foo() only the imported 
>>> functions are available, not the functions in packages you depend 
>>> on)
>>>
>>
>> Cheers Hadley. Thanks for the confirmation, but...
>>
>> ...I don't get this; what is the point of Depends? I thought it was 
>> "my package needs these other packages to work, i.e. be loaded". 
>> Hence it is user error (IMHO ;-) to do `analogue::foo()` without 
>> having the dependencies loaded too.
>>
>
> No. The point of Depends is that if your package is attached, it also attaches the other packages to make them available for the user. Essentially you're saying "if you want to use my package interactively, you will also want to use those other packages interactively". You still need to use import() to define what exactly is used by your package - as opposed to what you want to be available to the user in case it is attached.
>
> Cheers,
> Simon
>
>
>
>> This check (whilst having found some things I should have imported 
>> and didn't - which is a good thing!) seems to be circumventing the 
>> intention of having something in Depends. Is Depends going to go away?
>>
>>
>>> (And really you shouldn't have any packages in depends, they should 
>>> all be in imports)
>>
>>
>> I disagree with *any*; having say vegan loaded when one is using 
>> analogue is a design decision as the latter borrows heavily from and 
>> builds upon vegan. In general I have moved packages that didn't need 
>> to be in Depends into Imports; in the version I am currently doing 
>> final tweaks on before it goes to CRAN I have remove all but vegan from Depends.
>>
>> Or am I thinking about this in the wrong way?
>>
>> Thanks again
>>
>> Gavin
>>
>>
>>>
>>> Hadley
>>>
>>>
>>> --
>>> http://had.co.nz/
>>>
>>
>>
>>
>> --
>> Gavin Simpson, PhD
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Thu Aug 28 17:41:38 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 28 Aug 2014 08:41:38 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
Message-ID: <CAFDcVCTu7TvkyzhUwdFD5wcdtfGao4T2M39fSTLE0xuQSoAiFw@mail.gmail.com>

>From a developers point of view, these days a less ambiguous name for
'Depends' would be 'Attaches'.

...or maybe even 'ImportsAndAttaches' with 'ImportsOnly' (for 'Imports').

I think Simon phrased it very well, and as others already pointed out,
having one package attaching additional ones certainly has its values. This
is probably more useful for packages that are used directly by the end user
than for packages that mainly provides infrastructure to other packages.

Henrik
On Aug 28, 2014 7:48 AM, "Bert Gunter" <gunter.berton at gene.com> wrote:

> This is a nice explanation of the Imports/Depends distinction. It
> ought to go into the Extensions ref manual imho.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
> >
> > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
> >
> >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> >>
> >>>> Is that the cause of these NOTEs? Is the expectation that if I am
> using a
> >>>> function from a package, even a package that I have in Depends:, that
> I
> >>>> have to explicitly declare these imports in NAMESPACE?
> >>>
> >>> Yes.
> >>>
> >>> (Otherwise your package won't work if it's only attached and not
> >>> loaded. i.e. if someone does analogue::foo() only the imported
> >>> functions are available, not the functions in packages you depend on)
> >>>
> >>
> >> Cheers Hadley. Thanks for the confirmation, but...
> >>
> >> ...I don't get this; what is the point of Depends? I thought it was "my
> >> package needs these other packages to work, i.e. be loaded". Hence it is
> >> user error (IMHO ;-) to do `analogue::foo()` without having the
> >> dependencies loaded too.
> >>
> >
> > No. The point of Depends is that if your package is attached, it also
> attaches the other packages to make them available for the user.
> Essentially you're saying "if you want to use my package interactively, you
> will also want to use those other packages interactively". You still need
> to use import() to define what exactly is used by your package - as opposed
> to what you want to be available to the user in case it is attached.
> >
> > Cheers,
> > Simon
> >
> >
> >
> >> This check (whilst having found some things I should have imported and
> >> didn't - which is a good thing!) seems to be circumventing the
> intention of
> >> having something in Depends. Is Depends going to go away?
> >>
> >>
> >>> (And really you shouldn't have any packages in depends, they should
> >>> all be in imports)
> >>
> >>
> >> I disagree with *any*; having say vegan loaded when one is using
> analogue
> >> is a design decision as the latter borrows heavily from and builds upon
> >> vegan. In general I have moved packages that didn't need to be in
> Depends
> >> into Imports; in the version I am currently doing final tweaks on
> before it
> >> goes to CRAN I have remove all but vegan from Depends.
> >>
> >> Or am I thinking about this in the wrong way?
> >>
> >> Thanks again
> >>
> >> Gavin
> >>
> >>
> >>>
> >>> Hadley
> >>>
> >>>
> >>> --
> >>> http://had.co.nz/
> >>>
> >>
> >>
> >>
> >> --
> >> Gavin Simpson, PhD
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ucfagls at gmail.com  Thu Aug 28 20:43:27 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Thu, 28 Aug 2014 12:43:27 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
Message-ID: <CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>

I fully agree.

This is how I have come to understand Depends vs Imports and why I
currently will not be removing vegan from Depends for my analogue package.
This is also why I was pushing back against the notion that was voiced
early in this thread that *nothing* should be in Depends.

Cheers

G


On 28 August 2014 08:47, Bert Gunter <bgunter at gene.com> wrote:

> This is a nice explanation of the Imports/Depends distinction. It
> ought to go into the Extensions ref manual imho.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
> >
> > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
> >
> >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> >>
> >>>> Is that the cause of these NOTEs? Is the expectation that if I am
> using a
> >>>> function from a package, even a package that I have in Depends:, that
> I
> >>>> have to explicitly declare these imports in NAMESPACE?
> >>>
> >>> Yes.
> >>>
> >>> (Otherwise your package won't work if it's only attached and not
> >>> loaded. i.e. if someone does analogue::foo() only the imported
> >>> functions are available, not the functions in packages you depend on)
> >>>
> >>
> >> Cheers Hadley. Thanks for the confirmation, but...
> >>
> >> ...I don't get this; what is the point of Depends? I thought it was "my
> >> package needs these other packages to work, i.e. be loaded". Hence it is
> >> user error (IMHO ;-) to do `analogue::foo()` without having the
> >> dependencies loaded too.
> >>
> >
> > No. The point of Depends is that if your package is attached, it also
> attaches the other packages to make them available for the user.
> Essentially you're saying "if you want to use my package interactively, you
> will also want to use those other packages interactively". You still need
> to use import() to define what exactly is used by your package - as opposed
> to what you want to be available to the user in case it is attached.
> >
> > Cheers,
> > Simon
> >
> >
> >
> >> This check (whilst having found some things I should have imported and
> >> didn't - which is a good thing!) seems to be circumventing the
> intention of
> >> having something in Depends. Is Depends going to go away?
> >>
> >>
> >>> (And really you shouldn't have any packages in depends, they should
> >>> all be in imports)
> >>
> >>
> >> I disagree with *any*; having say vegan loaded when one is using
> analogue
> >> is a design decision as the latter borrows heavily from and builds upon
> >> vegan. In general I have moved packages that didn't need to be in
> Depends
> >> into Imports; in the version I am currently doing final tweaks on
> before it
> >> goes to CRAN I have remove all but vegan from Depends.
> >>
> >> Or am I thinking about this in the wrong way?
> >>
> >> Thanks again
> >>
> >> Gavin
> >>
> >>
> >>>
> >>> Hadley
> >>>
> >>>
> >>> --
> >>> http://had.co.nz/
> >>>
> >>
> >>
> >>
> >> --
> >> Gavin Simpson, PhD
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Thu Aug 28 23:14:43 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 28 Aug 2014 14:14:43 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
	<CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
Message-ID: <CADwqtCPgUNyPNw5wQnGnu6wdNJHE6biVL-mH7JibH3OvLiP6jA@mail.gmail.com>

Gavin,

I admit to not knowing the details of your package, but do users commonly
need to use symbols from other package *in calls to functions exported by
your package*? If so, you're in the situation Martin (Morgan) described,
which is one I think everyone agrees Depends is appropriate for.

If the above is not the case, and you're arguing it's simply convenient for
users because it's very common for them to use top level functions from
both in the same analysis, the case for Depends is not as strong. In that
case, the official wisdom, AFAIK, is that Depends is not warranted.

~G


On Thu, Aug 28, 2014 at 11:43 AM, Gavin Simpson <ucfagls at gmail.com> wrote:

> I fully agree.
>
> This is how I have come to understand Depends vs Imports and why I
> currently will not be removing vegan from Depends for my analogue package.
> This is also why I was pushing back against the notion that was voiced
> early in this thread that *nothing* should be in Depends.
>
> Cheers
>
> G
>
>
> On 28 August 2014 08:47, Bert Gunter <bgunter at gene.com> wrote:
>
> > This is a nice explanation of the Imports/Depends distinction. It
> > ought to go into the Extensions ref manual imho.
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
> > <simon.urbanek at r-project.org> wrote:
> > >
> > > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
> > >
> > >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
> > >>
> > >>>> Is that the cause of these NOTEs? Is the expectation that if I am
> > using a
> > >>>> function from a package, even a package that I have in Depends:,
> that
> > I
> > >>>> have to explicitly declare these imports in NAMESPACE?
> > >>>
> > >>> Yes.
> > >>>
> > >>> (Otherwise your package won't work if it's only attached and not
> > >>> loaded. i.e. if someone does analogue::foo() only the imported
> > >>> functions are available, not the functions in packages you depend on)
> > >>>
> > >>
> > >> Cheers Hadley. Thanks for the confirmation, but...
> > >>
> > >> ...I don't get this; what is the point of Depends? I thought it was
> "my
> > >> package needs these other packages to work, i.e. be loaded". Hence it
> is
> > >> user error (IMHO ;-) to do `analogue::foo()` without having the
> > >> dependencies loaded too.
> > >>
> > >
> > > No. The point of Depends is that if your package is attached, it also
> > attaches the other packages to make them available for the user.
> > Essentially you're saying "if you want to use my package interactively,
> you
> > will also want to use those other packages interactively". You still need
> > to use import() to define what exactly is used by your package - as
> opposed
> > to what you want to be available to the user in case it is attached.
> > >
> > > Cheers,
> > > Simon
> > >
> > >
> > >
> > >> This check (whilst having found some things I should have imported and
> > >> didn't - which is a good thing!) seems to be circumventing the
> > intention of
> > >> having something in Depends. Is Depends going to go away?
> > >>
> > >>
> > >>> (And really you shouldn't have any packages in depends, they should
> > >>> all be in imports)
> > >>
> > >>
> > >> I disagree with *any*; having say vegan loaded when one is using
> > analogue
> > >> is a design decision as the latter borrows heavily from and builds
> upon
> > >> vegan. In general I have moved packages that didn't need to be in
> > Depends
> > >> into Imports; in the version I am currently doing final tweaks on
> > before it
> > >> goes to CRAN I have remove all but vegan from Depends.
> > >>
> > >> Or am I thinking about this in the wrong way?
> > >>
> > >> Thanks again
> > >>
> > >> Gavin
> > >>
> > >>
> > >>>
> > >>> Hadley
> > >>>
> > >>>
> > >>> --
> > >>> http://had.co.nz/
> > >>>
> > >>
> > >>
> > >>
> > >> --
> > >> Gavin Simpson, PhD
> > >>
> > >>       [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>
> --
> Gavin Simpson, PhD
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From ucfagls at gmail.com  Thu Aug 28 23:42:28 2014
From: ucfagls at gmail.com (Gavin Simpson)
Date: Thu, 28 Aug 2014 15:42:28 -0600
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CADwqtCPgUNyPNw5wQnGnu6wdNJHE6biVL-mH7JibH3OvLiP6jA@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
	<CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
	<CADwqtCPgUNyPNw5wQnGnu6wdNJHE6biVL-mH7JibH3OvLiP6jA@mail.gmail.com>
Message-ID: <CAAHES9whb7MWNNJBWZ4Bfn-WNk=_40-P5H1nf5qCPVBxq_fbyg@mail.gmail.com>

Gabriel,

That is not my understanding of this at all. I could hide the fact that I
was using vegan under the hood, supplying methods for its generics and by
exporting the generic I imported from vegan, etc. But you are missing the
point that I see users of my package, because I envisioned close
interlinking with the functionality provided by vegan, wanting to use vegan
interactively with many of the objects that functions in analogue create.

I do feel this aversion to Depends is being taken too far by some. Simon's
articulation in this thread of what Depends means (to him) is the closest I
have seen to how I have interpreted things. That's also about as close to
official wisdom that I have seen beyond what is in Writing R Extensions.

Analogue also uses Lattice, but I have moved this to Imports as I don't
expect users to be manipulating the few plot alternatives analogue provides
using this graphics package and if they want to they can load lattice
themselves. So, I fully understand the differences and nuances of Depends
and Imports etc. I just don't agree with those that claim no packages
should be in Depends, or that my use case is somehow wrong or not best
practice.

G


On 28 August 2014 15:14, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> Gavin,
>
> I admit to not knowing the details of your package, but do users commonly
> need to use symbols from other package *in calls to functions exported by
> your package*? If so, you're in the situation Martin (Morgan) described,
> which is one I think everyone agrees Depends is appropriate for.
>
> If the above is not the case, and you're arguing it's simply convenient
> for users because it's very common for them to use top level functions from
> both in the same analysis, the case for Depends is not as strong. In that
> case, the official wisdom, AFAIK, is that Depends is not warranted.
>
> ~G
>
>
> On Thu, Aug 28, 2014 at 11:43 AM, Gavin Simpson <ucfagls at gmail.com> wrote:
>
>> I fully agree.
>>
>> This is how I have come to understand Depends vs Imports and why I
>> currently will not be removing vegan from Depends for my analogue package.
>> This is also why I was pushing back against the notion that was voiced
>> early in this thread that *nothing* should be in Depends.
>>
>> Cheers
>>
>> G
>>
>>
>> On 28 August 2014 08:47, Bert Gunter <bgunter at gene.com> wrote:
>>
>> > This is a nice explanation of the Imports/Depends distinction. It
>> > ought to go into the Extensions ref manual imho.
>> >
>> > Cheers,
>> > Bert
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> > (650) 467-7374
>> >
>> > "Data is not information. Information is not knowledge. And knowledge
>> > is certainly not wisdom."
>> > Clifford Stoll
>> >
>> >
>> >
>> >
>> > On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
>> > <simon.urbanek at r-project.org> wrote:
>> > >
>> > > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>> > >
>> > >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>> > >>
>> > >>>> Is that the cause of these NOTEs? Is the expectation that if I am
>> > using a
>> > >>>> function from a package, even a package that I have in Depends:,
>> that
>> > I
>> > >>>> have to explicitly declare these imports in NAMESPACE?
>> > >>>
>> > >>> Yes.
>> > >>>
>> > >>> (Otherwise your package won't work if it's only attached and not
>> > >>> loaded. i.e. if someone does analogue::foo() only the imported
>> > >>> functions are available, not the functions in packages you depend
>> on)
>> > >>>
>> > >>
>> > >> Cheers Hadley. Thanks for the confirmation, but...
>> > >>
>> > >> ...I don't get this; what is the point of Depends? I thought it was
>> "my
>> > >> package needs these other packages to work, i.e. be loaded". Hence
>> it is
>> > >> user error (IMHO ;-) to do `analogue::foo()` without having the
>> > >> dependencies loaded too.
>> > >>
>> > >
>> > > No. The point of Depends is that if your package is attached, it also
>> > attaches the other packages to make them available for the user.
>> > Essentially you're saying "if you want to use my package interactively,
>> you
>> > will also want to use those other packages interactively". You still
>> need
>> > to use import() to define what exactly is used by your package - as
>> opposed
>> > to what you want to be available to the user in case it is attached.
>> > >
>> > > Cheers,
>> > > Simon
>> > >
>> > >
>> > >
>> > >> This check (whilst having found some things I should have imported
>> and
>> > >> didn't - which is a good thing!) seems to be circumventing the
>> > intention of
>> > >> having something in Depends. Is Depends going to go away?
>> > >>
>> > >>
>> > >>> (And really you shouldn't have any packages in depends, they should
>> > >>> all be in imports)
>> > >>
>> > >>
>> > >> I disagree with *any*; having say vegan loaded when one is using
>> > analogue
>> > >> is a design decision as the latter borrows heavily from and builds
>> upon
>> > >> vegan. In general I have moved packages that didn't need to be in
>> > Depends
>> > >> into Imports; in the version I am currently doing final tweaks on
>> > before it
>> > >> goes to CRAN I have remove all but vegan from Depends.
>> > >>
>> > >> Or am I thinking about this in the wrong way?
>> > >>
>> > >> Thanks again
>> > >>
>> > >> Gavin
>> > >>
>> > >>
>> > >>>
>> > >>> Hadley
>> > >>>
>> > >>>
>> > >>> --
>> > >>> http://had.co.nz/
>> > >>>
>> > >>
>> > >>
>> > >>
>> > >> --
>> > >> Gavin Simpson, PhD
>> > >>
>> > >>       [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-devel at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> > >>
>> > >
>> > > ______________________________________________
>> > > R-devel at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>> --
>> Gavin Simpson, PhD
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Fri Aug 29 00:36:56 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 28 Aug 2014 15:36:56 -0700
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9whb7MWNNJBWZ4Bfn-WNk=_40-P5H1nf5qCPVBxq_fbyg@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
	<CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
	<CADwqtCPgUNyPNw5wQnGnu6wdNJHE6biVL-mH7JibH3OvLiP6jA@mail.gmail.com>
	<CAAHES9whb7MWNNJBWZ4Bfn-WNk=_40-P5H1nf5qCPVBxq_fbyg@mail.gmail.com>
Message-ID: <CADwqtCOM2jenZJ9Y+ZVYdnA+dAYiSzuvcA+N-qf_xmMxPocELQ@mail.gmail.com>

Gavin,

I don't claim to be the arbiter of good package design. The following are
my opinions, along with the reasons I hold them.

If you are also importing vegan, which I think everyone agreed needs to
happen, the only thing putting vegan in Depends does is attach the package.
This is something users can easily do themselves, and which *may* not be
required to use your package (I don't know). As such, using Depends limits
the user's agency/control over their session in return for what I would
argue may (depending on circumstance) be a nominal benefit at best.

Continued inline.

On Thu, Aug 28, 2014 at 2:42 PM, Gavin Simpson <ucfagls at gmail.com> wrote:

> Gabriel,
>
> That is not my understanding of this at all. I could hide the fact that I
> was using vegan under the hood, supplying methods for its generics and by
> exporting the generic I imported from vegan, etc. But you are missing the
> point that I see users of my package, because I envisioned close
> interlinking with the functionality provided by vegan, wanting to use vegan
> interactively with many of the objects that functions in analogue create.
>

Well sure, but if that is the case, they know they want to call functions
in vegan, so I would think that they would expect to load vegan and not
really think twice about having to do so, making your Depends irrelevant.

The other question is, can analogue be used without vegan? If it can,
*forcing* users to have vegan attached it doesn't seem desirable. Depends
gives users less power to avoid or resolve symbol conflicts.

Point in case, there is a logging package called log4r which overrides the
'debug' (madness, I know) symbol, and I once had a package (call it PkgA)
loaded which Depends on log4r it, with good reason, even, since you are
expected to pass a user-created logging object of some kind to the to
PkgA's functions. This meant that the base-R debug function was
*mandatorally* masked. This is very bad for the user (me), and honestly if
the author hadn't agreed to change the Dependency I wouldn't even consider
using the package.

If log4r has been imported, I wouldn't have cared at all, as I would have
been in control of whether the package was attached or not, and when.

I'm sure (hope) that vegan doesn't do anything this egregious, and if not,
your use of Depends isn't The-Most-Horrible-Thing-Ever. I'd argue that it
is undesirable, but relatively mildly so, and others may argue not at all.


>
> I do feel this aversion to Depends is being taken too far by some. Simon's
> articulation in this thread of what Depends means (to him) is the closest I
> have seen to how I have interpreted things. That's also about as close to
> official wisdom that I have seen beyond what is in Writing R Extensions.
>

If the official wisdom from R-core disagrees with me, that is probably a
good reason not to listen to me. I was under the impression that Depends
was not recommended except in cases like the described by Mr. Morgan.

Best,
~G


On 28 August 2014 15:14, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> Gavin,
>
> I admit to not knowing the details of your package, but do users commonly
> need to use symbols from other package *in calls to functions exported by
> your package*? If so, you're in the situation Martin (Morgan) described,
> which is one I think everyone agrees Depends is appropriate for.
>
> If the above is not the case, and you're arguing it's simply convenient
> for users because it's very common for them to use top level functions from
> both in the same analysis, the case for Depends is not as strong. In that
> case, the official wisdom, AFAIK, is that Depends is not warranted.
>
> ~G
>
>
> On Thu, Aug 28, 2014 at 11:43 AM, Gavin Simpson <ucfagls at gmail.com> wrote:
>
>> I fully agree.
>>
>> This is how I have come to understand Depends vs Imports and why I
>> currently will not be removing vegan from Depends for my analogue package.
>> This is also why I was pushing back against the notion that was voiced
>> early in this thread that *nothing* should be in Depends.
>>
>> Cheers
>>
>> G
>>
>>
>> On 28 August 2014 08:47, Bert Gunter <bgunter at gene.com> wrote:
>>
>> > This is a nice explanation of the Imports/Depends distinction. It
>> > ought to go into the Extensions ref manual imho.
>> >
>> > Cheers,
>> > Bert
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> > (650) 467-7374
>> >
>> > "Data is not information. Information is not knowledge. And knowledge
>> > is certainly not wisdom."
>> > Clifford Stoll
>> >
>> >
>> >
>> >
>> > On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
>> > <simon.urbanek at r-project.org> wrote:
>> > >
>> > > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>> > >
>> > >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>> > >>
>> > >>>> Is that the cause of these NOTEs? Is the expectation that if I am
>> > using a
>> > >>>> function from a package, even a package that I have in Depends:,
>> that
>> > I
>> > >>>> have to explicitly declare these imports in NAMESPACE?
>> > >>>
>> > >>> Yes.
>> > >>>
>> > >>> (Otherwise your package won't work if it's only attached and not
>> > >>> loaded. i.e. if someone does analogue::foo() only the imported
>> > >>> functions are available, not the functions in packages you depend
>> on)
>> > >>>
>> > >>
>> > >> Cheers Hadley. Thanks for the confirmation, but...
>> > >>
>> > >> ...I don't get this; what is the point of Depends? I thought it was
>> "my
>> > >> package needs these other packages to work, i.e. be loaded". Hence
>> it is
>> > >> user error (IMHO ;-) to do `analogue::foo()` without having the
>> > >> dependencies loaded too.
>> > >>
>> > >
>> > > No. The point of Depends is that if your package is attached, it also
>> > attaches the other packages to make them available for the user.
>> > Essentially you're saying "if you want to use my package interactively,
>> you
>> > will also want to use those other packages interactively". You still
>> need
>> > to use import() to define what exactly is used by your package - as
>> opposed
>> > to what you want to be available to the user in case it is attached.
>> > >
>> > > Cheers,
>> > > Simon
>> > >
>> > >
>> > >
>> > >> This check (whilst having found some things I should have imported
>> and
>> > >> didn't - which is a good thing!) seems to be circumventing the
>> > intention of
>> > >> having something in Depends. Is Depends going to go away?
>> > >>
>> > >>
>> > >>> (And really you shouldn't have any packages in depends, they should
>> > >>> all be in imports)
>> > >>
>> > >>
>> > >> I disagree with *any*; having say vegan loaded when one is using
>> > analogue
>> > >> is a design decision as the latter borrows heavily from and builds
>> upon
>> > >> vegan. In general I have moved packages that didn't need to be in
>> > Depends
>> > >> into Imports; in the version I am currently doing final tweaks on
>> > before it
>> > >> goes to CRAN I have remove all but vegan from Depends.
>> > >>
>> > >> Or am I thinking about this in the wrong way?
>> > >>
>> > >> Thanks again
>> > >>
>> > >> Gavin
>> > >>
>> > >>
>> > >>>
>> > >>> Hadley
>> > >>>
>> > >>>
>> > >>> --
>> > >>> http://had.co.nz/
>> > >>>
>> > >>
>> > >>
>> > >>
>> > >> --
>> > >> Gavin Simpson, PhD
>> > >>
>> > >>       [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-devel at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> > >>
>> > >
>> > > ______________________________________________
>> > > R-devel at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>> --
>> Gavin Simpson, PhD
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
>



-- 
> Gavin Simpson, PhD
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Fri Aug 29 01:26:32 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Aug 2014 19:26:32 -0400
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>
	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>
	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
	<CACk-te1fEUTzqwEF1EBBtaBTy3QvK13ARr2tOsYjda3Q++_dvA@mail.gmail.com>
	<CAAHES9x2otsMnzqgLymx_b_xqbJPGr7Uv4t5F9Bqs0OPqyJLKg@mail.gmail.com>
Message-ID: <CAP01uRkmpZLmg3ab20OCQzsv1uEDGDq+8bJzYcvHtfihOgdM8w@mail.gmail.com>

Yes, Depends certainly has a role. The ability of one package to
automatically provide all the facilities of another package to the
user is important. There are many situations where the functionality
you want to provide to the user is split among multiple packages.

For example,

1. xts uses zoo and the user ought to be able to use all the
functionality of zoo when they issue a library(zoo) call.  The
alternatives are that the user must tediously issue library(zoo) every
time they issue library(xts) or else that the zoo code be copied or
partially replicated into xts which would be undesirable
maintenance-wise.

2. Another example is sqldf.  The user wants to be able to use fn$ and
other string manipulation functions in gsubfn when using sqldf in
order to perform string substitution on the SQL statement.  Also its
desirable to be able to directly access sqlite which means the user
needs access to RSQLite.

3. At one time one could just issue library(ggplot2) but now that
ggplot2 does not use Depends for scales one annoyingly needs to issue
library(scales) if one wants to specify a scale.   I use ggplot2
enough that I can remember it despite the ongoing annoyance but I
would hate to think that every package with split functionality
suddenly adds such onerous requirements onto all its users.  (I am not
really picking on ggplot2 which is a very nice package - just this one
aspect.)

I am not sure but there might be additional problems if the secondary
package defines an S3 generic that the primary package needs to use if
one does not use Depends.


On Thu, Aug 28, 2014 at 2:43 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
> I fully agree.
>
> This is how I have come to understand Depends vs Imports and why I
> currently will not be removing vegan from Depends for my analogue package.
> This is also why I was pushing back against the notion that was voiced
> early in this thread that *nothing* should be in Depends.
>
> Cheers
>
> G
>
>
> On 28 August 2014 08:47, Bert Gunter <bgunter at gene.com> wrote:
>
>> This is a nice explanation of the Imports/Depends distinction. It
>> ought to go into the Extensions ref manual imho.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Thu, Aug 28, 2014 at 7:39 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>> >
>> > On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com> wrote:
>> >
>> >> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com> wrote:
>> >>
>> >>>> Is that the cause of these NOTEs? Is the expectation that if I am
>> using a
>> >>>> function from a package, even a package that I have in Depends:, that
>> I
>> >>>> have to explicitly declare these imports in NAMESPACE?
>> >>>
>> >>> Yes.
>> >>>
>> >>> (Otherwise your package won't work if it's only attached and not
>> >>> loaded. i.e. if someone does analogue::foo() only the imported
>> >>> functions are available, not the functions in packages you depend on)
>> >>>
>> >>
>> >> Cheers Hadley. Thanks for the confirmation, but...
>> >>
>> >> ...I don't get this; what is the point of Depends? I thought it was "my
>> >> package needs these other packages to work, i.e. be loaded". Hence it is
>> >> user error (IMHO ;-) to do `analogue::foo()` without having the
>> >> dependencies loaded too.
>> >>
>> >
>> > No. The point of Depends is that if your package is attached, it also
>> attaches the other packages to make them available for the user.
>> Essentially you're saying "if you want to use my package interactively, you
>> will also want to use those other packages interactively". You still need
>> to use import() to define what exactly is used by your package - as opposed
>> to what you want to be available to the user in case it is attached.
>> >
>> > Cheers,
>> > Simon
>> >
>> >
>> >
>> >> This check (whilst having found some things I should have imported and
>> >> didn't - which is a good thing!) seems to be circumventing the
>> intention of
>> >> having something in Depends. Is Depends going to go away?
>> >>
>> >>
>> >>> (And really you shouldn't have any packages in depends, they should
>> >>> all be in imports)
>> >>
>> >>
>> >> I disagree with *any*; having say vegan loaded when one is using
>> analogue
>> >> is a design decision as the latter borrows heavily from and builds upon
>> >> vegan. In general I have moved packages that didn't need to be in
>> Depends
>> >> into Imports; in the version I am currently doing final tweaks on
>> before it
>> >> goes to CRAN I have remove all but vegan from Depends.
>> >>
>> >> Or am I thinking about this in the wrong way?
>> >>
>> >> Thanks again
>> >>
>> >> Gavin
>> >>
>> >>
>> >>>
>> >>> Hadley
>> >>>
>> >>>
>> >>> --
>> >>> http://had.co.nz/
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >> Gavin Simpson, PhD
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gavin Simpson, PhD
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pgilbert902 at gmail.com  Fri Aug 29 04:55:04 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 28 Aug 2014 22:55:04 -0400
Subject: [Rd] Re R CMD check checking in development version of R
In-Reply-To: <79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
References: <CAAHES9xbHJLUbzLzS7C2tTaODv=d_JV5ds09ZFdA6Bv+uBSYEA@mail.gmail.com>	<CABdHhvG7ahtFhBOCRU9X2KRR2Z30S1gE_F66m0W=91wpkbvyOA@mail.gmail.com>	<CAAHES9yzPkidSVAW6=BE689mrfo7Bv_MHZ=WzanHwpctGC21Tg@mail.gmail.com>
	<79381712-FCA3-4995-83BC-956270EDABC4@r-project.org>
Message-ID: <53FFEB88.7050607@gmail.com>

(Please correct me if I'm wrong. I thought I mostly understood this, 
finally, but I've made the mistake of thinking I understood something 
too many times before.)

On 08/28/2014 10:39 AM, Simon Urbanek wrote:
>
> On Aug 27, 2014, at 6:01 PM, Gavin Simpson <ucfagls at gmail.com>
> wrote:
>
>> On 27 August 2014 15:24, Hadley Wickham <h.wickham at gmail.com>
>> wrote:
>>
>>>> Is that the cause of these NOTEs? Is the expectation that if I
>>>> am using a function from a package, even a package that I have
>>>> in Depends:, that I have to explicitly declare these imports in
>>>> NAMESPACE?
>>>
>>> Yes.
>>>
>>> (Otherwise your package won't work if it's only attached and not
>>> loaded. i.e. if someone does analogue::foo() only the imported
>>> functions are available, not the functions in packages you depend
>>> on)
>>>
>>
>> Cheers Hadley. Thanks for the confirmation, but...
>>
>> ...I don't get this; what is the point of Depends? I thought it was
>> "my package needs these other packages to work, i.e. be loaded".
>> Hence it is user error (IMHO ;-) to do `analogue::foo()` without
>> having the dependencies loaded too.
>>
>
> No. The point of Depends is that if your package is attached, it also
> attaches the other packages to make them available for the user.
> Essentially you're saying "if you want to use my package
> interactively, you will also want to use those other packages
> interactively".

I agree that "interactively" catches the flavour of what Depends does, 
but technically that is the wrong word. The important point is whether 
the functions in a Depended upon package should be available to the user 
directly without them needing to use library() or require() to make them 
available, in an interactive session or a batch job.

>You still need to use import() to define what exactly
> is used by your package -

Amplifying a bit: By import() in the NAMESPACE, which you need whether 
you have Depends or Imports in the DESCRIPTION file, you ensure that the 
functions in your package use the ones in the package imported and do 
not get clobbered by anything the user might do. The user might redefine 
functions available to the interactive session, or require() another 
package with functions having the same names, and those are the ones his 
interactive direct calls will find, but your package functions will not 
use those.

People are sure to have differences of opinion about the trade-off 
between the annoyance of having to specifically attach packages being 
used, and the clarity this provides. At first I was really annoyed, but 
have eventually decided I do like the clarity.

In my experience it turns out to be surprisingly rare that you need 
packages in Depends, but there are legitimate cases beyond the annoyance 
case mentioned above. I think if you are putting packages in Depends you 
really do want to have a very good understanding of why you are doing 
that. If you use Depends then you are inviting support difficulties. 
Users will contact you about bugs in the package you attach, even though 
your package may not use the broken functions. If they attach the 
package themselves then they are much more likely to understand who they 
should contact. Core seems to have forgotten to take credit for trying 
to make life easier for package developers.

Paul

as opposed to what you want to be available
> to the user in case it is attached.
>
> Cheers, Simon
>
>
>
>> This check (whilst having found some things I should have imported
>> and didn't - which is a good thing!) seems to be circumventing the
>> intention of having something in Depends. Is Depends going to go
>> away?
>>
>>
>>> (And really you shouldn't have any packages in depends, they
>>> should all be in imports)
>>
>>
>> I disagree with *any*; having say vegan loaded when one is using
>> analogue is a design decision as the latter borrows heavily from
>> and builds upon vegan. In general I have moved packages that didn't
>> need to be in Depends into Imports; in the version I am currently
>> doing final tweaks on before it goes to CRAN I have remove all but
>> vegan from Depends.
>>
>> Or am I thinking about this in the wrong way?
>>
>> Thanks again
>>
>> Gavin
>>
>>
>>>
>>> Hadley
>>>
>>>
>>> -- http://had.co.nz/
>>>
>>
>>
>>
>> -- Gavin Simpson, PhD
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Fri Aug 29 17:45:09 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 Aug 2014 17:45:09 +0200
Subject: [Rd] Unfixed bugs in latest R-patched
In-Reply-To: <21417.30777.209017.331344@stat.math.ethz.ch>
References: <20140623152435.GA22211@cs.toronto.edu>
	<21417.30777.209017.331344@stat.math.ethz.ch>
Message-ID: <21504.40965.94098.976528@stat.math.ethz.ch>

Getting back to 2 months old considerations  [more inline]:

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 24 Jun 2014 15:08:09 +0200 writes:

>>>>> Radford Neal <radford at cs.toronto.edu>
>>>>>     on Mon, 23 Jun 2014 11:24:35 -0400 writes:

    >> A new version of pqR is now available at pqR-project.org, which fixes
    >> several bugs that are also present in the latest R Core patch release
    >> (r66002).  A number of bugs found previously during pqR development
    >> are also unfixed in the latest R Core release.  Here is the list of
    >> these bugs that are unfixed in r66002 (including documentation
    >> deficiencies), taken from the pqR bug fix and documentation update
    >> sections of the pqR NEWS file (pqR-project.org/NEWS.txt):

    > Duncan Murdoch has already mentioned that "unfixed bugs" is a
    > strong wording...

    > I'm commenting on one subtopic only:

    > [.........]

    >> o Fixed the following bug (also present in R-2.15.0 and R-3.0.2):
      
    >> x <- t(5)
    >> print (x %*% c(3,4))
    >> print (crossprod(5,c(3,4)))

    >> The call of crossprod produced an error, whereas the
    >> corresponding use of %*% does not.

    >> In pqR-2013-12-29, this bug also affected the expression t(5) %*%
    >> c(3,4), since it is converted to the equivalent of
    >> crossprod(5,c(3,4)).
    > (I'm not getting this last para... but that may be unimportant)

    > [........]

    >> o Fixed the following bug (also present in R-2.15.0 and R-3.0.2):
      
    >> v <- c(1,2)
    >> m <- matrix(c(3,4),1,2)
    >> print(t(m)%*%v)
    >> print(crossprod(m,v))

    >> in which crossprod gave an error rather than produce the answer
    >> for the corresponding use of %*%.

    > Both cases above concern  %*%, crossprod() {and also
    > tcrossprod()}, and always when one at least one operand is a
    > vector... 

    > As S and R's terminology has always been mathematically correct and
    > "knows" that a vector is not a 1-row matrix or 1-column matrix 
    > (which some people call row-vector and column-vector), R has
    > indeed much more freedom to be lenient in how to promote vectors
    > to matrices, and it has always done so tolerantly for some cases
    > of "%*%", but even there is room for discussion, see below.

    > Since about January, I have a corresponding entry in the TODO
    > file of the Matrix package (which I maintain), and I (at least
    > partly) agree with you, that we should *consider* changing the
    > current behavior.  
    > The following is from my corresponding R script :

 > ### NOTA BENE:  vector %*% Matrix  _and_  Matrix %*% vector :
 > ### ---------   -----------------         -----------------
 > ## The k-vector is treated as  (1,k)-matrix *or* (k,1)-matrix
 > ## on both sides  whenever it "helps fit" the matrix dimensions:

    > and one kind of reasoning would go to say that 
    > crossprod() and tcrossprod()  should do the same.   This would
    > even make more cases work than (I think) your proposal.

Yes, more cases, indeed:
I've just (svn rev 66495) committed changes to R-devel (aka "the trunk"),
with the following regression tests:

  ## Radford (R-devel, June 24, 2014); M.Maechler
  m <- matrix(1:2, 1,2); v <- 1:3
  stopifnot(identical(crossprod(2, v), t(2) %*% v),
	    identical(crossprod(m, v), t(m) %*% v),
	    identical(5 %*% v, 5 %*% t(v)),
	    identical(tcrossprod(m, 1:2), m %*% 1:2) )
  ## gave error "non-conformable arguments" in R <= 3.2.0

Note that the first two correspond to your "bugs" and the other two
follow the principle of promoting a vector to that (column or
row) matrix which "makes it work".

I did not label these as bug fixes, but new features, and for
this reason -- and for a longer review period and RFC --
these are *not* planned to be part of the next R release  
(R 3.1.2, no release date planned yet), but only of the next
yearly ".0" release next spring, (probably) version 3.2.0.


Comments are welcome, (particularly praises ;-)

Martin

    > However, one can argue that the current behavior is quite
    > consistent {there is more than one kind of consistency here; in
    > this case it's the consistency of underlying C code IIRC}, and
    > not strictly a bug.
    > It is something which I am grateful you bring up for discussion,
    > and I'm happy to settle here.
    > Note that the Matrix package and many other packages that
    > implement matrix multiplication methods, should then also follow
    > the new semantic, and so this is typically rather for R-devel
    > than R-patched.

    > Note that from your first case example, one could also argue
    > -- at least from my 'NOTA BENE' rule above --
    > that    5 %*% 3:4
    > should work, since  
    > 5 %*% rbind(3:4)
    > does work, but
    > 5 %*% cbind(3:4)
    > does not.  So you see, there are quite a few cases one could
    > discuss, and have reasons pro and contra some of the changes.

    > I will be too busy till the end of 'useR! 2014' and would want
    > quite a bit of further thoughts before making a quick decision,
    > notably about the cases I have in the appended  products.Rout

    > Martin Maechler,
    > (ETH Zurich and R Core team)

    > ---------------
    > ### NOTA BENE:  vector %*% Matrix  _and_  Matrix %*% vector :
    > ### ---------   -----------------         -----------------
    > ## The k-vector is treated as  (1,k)-matrix *or* (k,1)-matrix
    > ## on both sides  whenever it "helps fit" the matrix dimensions:

    > ## --------------- %*% ---------------------------------------------

    > ## --------- v . v -----------------------------
    > ## We *could* consider allowing more even here: could argue
    > ## from the 'NOTA BENE' above that
    >> 5 %*% 3:4        ## should work, since
    >> 5 %*% rbind(3:4) ## does work, but
    >> 5 %*% cbind(3:4) ## does not.

    > ## --------- v . M -----------------------------
    >> 1:3 %*% matrix(1:12, 3,4) ## (1, n)  if n == nrow(.)
    > [,1] [,2] [,3] [,4]
    > [1,]   14   32   50   68
    >> 1:4 %*% matrix(1:12, 3,4)
    > Error in 1:4 %*% matrix(1:12, 3, 4) : non-conformable arguments
    > No suitable frames for recover()
    >> 1:4 %*% matrix(1:5, 1,5)  ##  (n, 1) if nrow(.) == 1
    > [,1] [,2] [,3] [,4] [,5]
    > [1,]    1    2    3    4    5
    > [2,]    2    4    6    8   10
    > [3,]    3    6    9   12   15
    > [4,]    4    8   12   16   20
    > ## --------- M . v -----------------------------
    >> matrix(1:4, 3,4) %*% 1:4  ##  (n, 1) if  n == ncol(.)
    > [,1]
    > [1,]   26
    > [2,]   28
    > [3,]   26
    >> matrix(1:4, 3,4) %*% 1:3
    > Error in matrix(1:4, 3, 4) %*% 1:3 : non-conformable arguments
    > No suitable frames for recover()
    >> matrix(1:3, 3,1) %*% 1:3  ##  (1, n) if  ncol(.) == 1
    > [,1] [,2] [,3]
    > [1,]    1    2    3
    > [2,]    2    4    6
    > [3,]    3    6    9
    >> 

    > ## --------------- crossprod -------------------------------------

    > ## --------- M . v -----------------------------
    >> crossprod(matrix(1:4, 3,4), 1:3)  ## (n, 1) if  n == nrow(.)
    > [,1]
    > [1,]   14
    > [2,]   12
    > [3,]   14
    > [4,]   20
    >> crossprod(matrix(1:4, 3,4), 1:4)
    > Error in crossprod(matrix(1:4, 3, 4), 1:4) : non-conformable arguments
    >> m <- matrix(1:2, 1,2); v <- 1:3
    >> crossprod(m,v)	 ##>>> *could* be nice  and use (1,n) as nrow(.)==1 <<<
    > Error in crossprod(m, v) : non-conformable arguments
    > ##>> after all, crossprod(m,v) "should"== t(m) %*% v  and that does work:
    >> t(m) %*% v
    > [,1] [,2] [,3]
    > [1,]    1    2    3
    > [2,]    2    4    6
    >> 

    > ## --------- v . M -----------------------------
    >> crossprod(1:3, matrix(1:4, 3,4))  ## (1, n)  if  n == nrow(.)
    > [,1] [,2] [,3] [,4]
    > [1,]   14   12   14   20
    >> crossprod(1:4, matrix(1:4, 3,4))
    > Error in crossprod(1:4, matrix(1:4, 3, 4)) : non-conformable arguments
    >> crossprod(1:3, matrix(1:3, 1,3)) ##>>> *could* be nice  and use (n,1) as nrow(.)==1 <<<
    > Error in crossprod(1:3, matrix(1:3, 1, 3)) : non-conformable arguments
    >> crossprod(v,m)
    > Error in crossprod(v, m) : non-conformable arguments
    > ##>> "as"   v %*% m   does work  and v could have been  A[1,] instead of A[1, , drop=TRUE]


    >> ## --------------- tcrossprod -------------------------------------

    > ## --------- M . v -----------------------------
    >> tcrossprod(matrix(1:4, 3,4), 1:3)
    > Error in tcrossprod(matrix(1:4, 3, 4), 1:3) : non-conformable arguments
    >> tcrossprod(matrix(1:4, 3,4), 1:4)
    > Error in tcrossprod(matrix(1:4, 3, 4), 1:4) : non-conformable arguments
    >> tcrossprod(matrix(1:4, 1,4), 1:4)##>>> *could* be nice and use (n,1) as ncol(.) == 1 <<<
    > Error in tcrossprod(matrix(1:4, 1, 4), 1:4) : non-conformable arguments
    > ##>> "as"   m %*% v   does work  and v could have been  A[1,] instead of  A[1, , drop=TRUE]
    >> matrix(1:4, 1,4) %*%  1:4
    > [,1]
    > [1,]   30
    >> tcrossprod(matrix(1:2, 2,1), 1:5)  # v -> c(1, n)     as ncol(.) == 1
    > [,1] [,2] [,3] [,4] [,5]
    > [1,]    1    2    3    4    5
    > [2,]    2    4    6    8   10
    >> 

    > ## --------- v . M -----------------------------
    >> tcrossprod(1:4, matrix(1:4, 3,4)) # v -> c(1, n)     as n == ncol(.)
    > [,1] [,2] [,3]
    > [1,]   26   28   26
    >> tcrossprod(1:3, matrix(1:4, 3,4))
    > Error in tcrossprod(1:3, matrix(1:4, 3, 4)) : non-conformable arguments
    >> tcrossprod(1:3, matrix(1:3, 3,1)) # v -> c(n, 1)     as ncol(.) == 1
    > [,1] [,2] [,3]
    > [1,]    1    2    3
    > [2,]    2    4    6
    > [3,]    3    6    9
    >> 
    > ##--------------------------- vector x vector -----------------

    >> 1:3 %*% 1:3         ## must have same n
    > [,1]
    > [1,]   14

    >> crossprod(1:3, 1:3) ## must have same n
    > [,1]
    > [1,]   14


    >> tcrossprod(1:3, 1:4) ## can have different length
    > [,1] [,2] [,3] [,4]
    > [1,]    1    2    3    4
    > [2,]    2    4    6    8
    > [3,]    3    6    9   12

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bhh at xs4all.nl  Sun Aug 31 15:47:01 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 31 Aug 2014 15:47:01 +0200
Subject: [Rd] Typo in doc/html/about.html
Message-ID: <4929C4E0-EA54-4AC0-89BF-4094410EE213@xs4all.nl>


There is a typo in the file <path-to-R-source>/doc/html/about.html:

In the line with "The two languages are implemented quite differently, but bear enough superficial resemblence that users should be able to switch between the two with relative ease.?

resemblence should be resemblance.

Berend Hasselman

