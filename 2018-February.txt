From murdoch.duncan at gmail.com  Thu Feb  1 00:31:28 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 31 Jan 2018 18:31:28 -0500
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CAOKDuOj01EUf1Phru7CP6k-Cfdh6qjFqDmfcv9i0BGbDfBKzog@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <CAOKDuOj01EUf1Phru7CP6k-Cfdh6qjFqDmfcv9i0BGbDfBKzog@mail.gmail.com>
Message-ID: <b1df4aed-280f-3d06-5571-e649d2104885@gmail.com>

On 31/01/2018 8:59 AM, Mark van der Loo wrote:
> I fully agree with Joris and Hadley on roxygen2.
> 
> 
> Additionally:
> 
> I wrote and published my first package before roxygen (or roxygen2) was 
> available. I found editing .Rd extremely terse (especially when code is 
> updated). For example, the fact that there are no spaces allowed between 
> } and { in \param{}{} has hurt my brain quite a few times, especially 

There's no \param macro in Rd.  You're probably thinking of \item{}{} or 
\section{}{}, or some other two-arg macro.  There aren't very many of 
them, but there are a few.

If it really is \item, then the error message you get would look 
something like this:

Warning: bad markup (extra space?) at foo.Rd:15:16

That's column 16 of line 15.  I'm not sure this guess is right, because 
that message does seem pretty informative.

There are also a couple of 1 or 2 argument macros (\eqn and \deqn), 
where the space would make the parser think you were using the 1 
argument version.  I think that's the same behaviour as LaTeX, which the 
Rd format is loosely based on.


> since R CMD check did not give any useful error messages about it. For 
> me it is a signal that the Rd parser is rather primitive.

Originally the format was defined in a really ad hoc way:  help pages 
were formed not by parsing the Rd file, but by applying a sequence of 
substitutions to it.  I wrote a parser following the usual R policy of 
trying not to break too much existing code.  This wasn't easy because 
the format had grown into something fairly awful, but I wouldn't call it 
primitive.  At the time I was really hoping someone else would propose 
something better, but I don't think that ever happened.

Duncan Murdoch


  On the other
> hand Roxygen2 now usually gives pretty good error messages when I syntax 
> error something.
> 
> Also, the 'parent' of roxygen is Doxygen, which was already widely used 
> (also by me) in the C/C++ community before roxygen was published. I 
> cannot remember anyone ever complaining about C/C++ documentation 
> deteriorating because of Doxygen.
> 
> 
> -Mark
> 
> 
> Op wo 31 jan. 2018 om 14:02 schreef Joris Meys <jorismeys at gmail.com 
> <mailto:jorismeys at gmail.com>>:
> 
>     On Wed, Jan 31, 2018 at 1:41 PM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>
>     wrote:
> 
>      > On 31/01/2018 6:33 AM, Joris Meys wrote:
>      >
>      > 3. given your criticism, I'd like your opinion on where I can
>     improve the
>      >> documentation of
>     https://github.com/CenterForStatistics-UGent/pim. I'm
>      >> currently busy updating the help files for a next release on
>     CRAN, so your
>      >> input is more than welcome.
>      >>
>      >
>      > After this invitation I sent some private comments to Joris.? I
>     would say
>      > his package does a pretty good job of documentation; it isn't the
>     kind of
>      > Roxygen-using package that I was complaining about.? So I will
>     say I have
>      > received an example of a Roxygen-using package that
>      > has good help pages.
>      >
> 
>     Thank you for the nice compliment and the valuable tips.
> 
>     --
>     Joris Meys
>     Statistical consultant
> 
>     Department of Data Analysis and Mathematical Modelling
>     Ghent University
>     Coupure Links 653, B-9000 Gent (Belgium)
>     <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
> 
>     -----------
>     Biowiskundedagen 2017-2018
>     http://www.biowiskundedagen.ugent.be/
> 
>     -------------------------------
>     Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
>      ? ? ? ? [[alternative HTML version deleted]]
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Thu Feb  1 09:14:36 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Feb 2018 09:14:36 +0100
Subject: [Rd] as.list method for by Objects
In-Reply-To: <CAOQ5NyegUu+9sGCuT4HZpP8vqJncPB5TckLXteS2zNSdtE9zTQ@mail.gmail.com>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <02275be4-b015-0860-8733-efb2b6b17996@fredhutch.org>
 <CADwqtCO98pTE6G4xOva3pVEEA0jSMND9zepcR19B-8rZ6mhYRg@mail.gmail.com>
 <f2080a27-71e0-4f52-61cd-2c2a8bb8e8cd@fredhutch.org>
 <CAOQ5Nye8vFGjheY+QW1H5-Am6BN+V_jKGuCe8=_YbeMQyQFGkA@mail.gmail.com>
 <74406925-3fbb-67d6-5afa-2d18f0b00513@fredhutch.org>
 <CAOQ5NyegUu+9sGCuT4HZpP8vqJncPB5TckLXteS2zNSdtE9zTQ@mail.gmail.com>
Message-ID: <23154.52332.796492.172488@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Tue, 30 Jan 2018 15:57:42 -0800 writes:

    > I just meant that the minimal contract for as.list() appears to be that it
    > returns a VECSXP. To the user, we might say that is.list() will always
    > return TRUE.
    
Indeed. I also agree with Herv'e that the user level
documentation should rather mention  is.list(.) |--> TRUE  than
VECSXP, and interestingly for the experts among us,
the  is.list() primitive gives not only TRUE for  VECSXP  but
also of LISTSXP (the good ole' pairlists).

    > I'm not sure we can expect consistency across methods
    > beyond that, nor is it feasible at this point to match the
    > semantics of the methods package. It deals in "class
    > space" while as.list() deals in "typeof() space".

    > Michael

Yes, and that *is* the extra complexity we have in R (inherited
from S, I'd say)  which ideally wasn't there and of course is
not there in much younger languages/systems such as julia.

And --- by the way let me preach, for the "class space" ---
do __never__ use

      if(class(obj) == "<classname>")

in your code (I see this so often, shockingly to me ...) but rather use

      if(inherits(obj, "<classname>"))

instead.

Martin



    > On Tue, Jan 30, 2018 at 3:47 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

    >> On 01/30/2018 02:50 PM, Michael Lawrence wrote:
    >> 
    >>> by() does not always return a list. In Gabe's example, it returns an
    >>> integer, thus it is coerced to a list. as.list() means that it should be a
    >>> VECSXP, not necessarily with "list" in the class attribute.
    >>> 
    >> 
    >> The documentation is not particularly clear about what as.list()
    >> means for list derivatives. IMO clarifications should stick to
    >> simple concepts and formulations like "is.list(x) is TRUE" or
    >> "x is a list or a list derivative" rather than "x is a VECSXP".
    >> Coercion is useful beyond the use case of implementing a .C entry
    >> point and calling as.numeric/as.list/etc... on its arguments.
    >> 
    >> This is why I was hoping that we could maybe discuss the possibility
    >> of making the as.list() contract less vague than just "as.list()
    >> must return a list or a list derivative".
    >> 
    >> Again, I think that 2 things weight quite a lot in that discussion:
    >> 1) as.list() returns an object of class "data.frame" on a
    >> data.frame (strict coercion). If all what as.list() needed to
    >> do was to return a VECSXP, then as.list.default() already does
    >> this on a data.frame so why did someone bother adding an
    >> as.list.data.frame method that does strict coercion?
    >> 2) The S4 coercion system based on as() does strict coercion by
    >> default.
    >> 
    >> H.
    >> 
    >> 
    >>> Michael
    >>> 
    >>> 
    >>> On Tue, Jan 30, 2018 at 2:41 PM, Herv? Pag?s <hpages at fredhutch.org
    >>> <mailto:hpages at fredhutch.org>> wrote:
    >>> 
    >>> Hi Gabe,
    >>> 
    >>> Interestingly the behavior of as.list() on by objects seem to
    >>> depend on the object itself:
    >>> 
    >>> > b1 <- by(1:2, 1:2, identity)
    >>> > class(as.list(b1))
    >>> [1] "list"
    >>> 
    >>> > b2 <- by(warpbreaks[, 1:2], warpbreaks[,"tension"], summary)
    >>> > class(as.list(b2))
    >>> [1] "by"
    >>> 
    >>> This is with R 3.4.3 and R devel (2017-12-11 r73889).
    >>> 
    >>> H.
    >>> 
    >>> On 01/30/2018 02:33 PM, Gabriel Becker wrote:
    >>> 
    >>> Dario,
    >>> 
    >>> What version of R are you using. In my mildly old 3.4.0
    >>> installation and in the version of Revel I have lying around
    >>> (also mildly old...)  I don't see the behavior I think you are
    >>> describing
    >>> 
    >>> > b = by(1:2, 1:2, identity)
    >>> 
    >>> > class(as.list(b))
    >>> 
    >>> [1] "list"
    >>> 
    >>> > sessionInfo()
    >>> 
    >>> R Under development (unstable) (2017-12-19 r73926)
    >>> 
    >>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
    >>> 
    >>> Running under: OS X El Capitan 10.11.6
    >>> 
    >>> 
    >>> Matrix products: default
    >>> 
    >>> BLAS:
    >>> /Users/beckerg4/local/Rdevel/R
    >>> .framework/Versions/3.5/Resources/lib/libRblas.dylib
    >>> 
    >>> LAPACK:
    >>> /Users/beckerg4/local/Rdevel/R
    >>> .framework/Versions/3.5/Resources/lib/libRlapack.dylib
    >>> 
    >>> 
    >>> locale:
    >>> 
    >>> [1]
    >>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    >>> 
    >>> 
    >>> attached base packages:
    >>> 
    >>> [1] stats     graphics  grDevices utils     datasets
    >>> methods   base
    >>> 
    >>> 
    >>> loaded via a namespace (and not attached):
    >>> 
    >>> [1] compiler_3.5.0
    >>> 
    >>> >
    >>> 
    >>> 
    >>> As for by not having a class definition, no S3 class has an
    >>> explicit definition, so this is somewhat par for the course
    >>> here...
    >>> 
    >>> did I misunderstand something?
    >>> 
    >>> 
    >>> ~G
    >>> 
    >>> On Tue, Jan 30, 2018 at 2:24 PM, Herv? Pag?s
    >>> <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
    >>> <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>>
    >>> wrote:
    >>> 
    >>> I agree that it makes sense to expect as.list() to perform
    >>> a "strict coercion" i.e. to return an object of class "list",
    >>> *even* on a list derivative. That's what as( , "list") does
    >>> by default:
    >>> 
    >>> # on a data.frame object
    >>> as(data.frame(), "list")  # object of class "list"
    >>> # (but strangely it drops the
    >>> names)
    >>> 
    >>> # on a by object
    >>> x <- by(warpbreaks[, 1:2], warpbreaks[,"tension"],
    >>> summary)
    >>> as(x, "list")  # object of class "list"
    >>> 
    >>> More generally speaking as() is expected to perform "strict
    >>> coercion" by default, unless called with 'strict=FALSE'.
    >>> 
    >>> That's also what as.list() does on a data.frame:
    >>> 
    >>> as.list(data.frame())  # object of class "list"
    >>> 
    >>> FWIW as.numeric() also performs "strict coercion" on an
    >>> integer
    >>> vector:
    >>> 
    >>> as.numeric(1:3)  # object of class "numeric"
    >>> 
    >>> So an as.list.env method that does the same as as(x, "list")
    >>> would bring a small touch of consistency in an otherwise
    >>> quite inconsistent world of coercion methods(*).
    >>> 
    >>> H.
    >>> 
    >>> (*) as(data.frame(), "list", strict=FALSE) doesn't do what
    >>> you'd
    >>> expect (just one of many examples)
    >>> 
    >>> 
    >>> On 01/29/2018 05:00 PM, Dario Strbenac wrote:
    >>> 
    >>> Good day,
    >>> 
    >>> I'd like to suggest the addition of an as.list method
    >>> for a by
    >>> object that actually returns a list of class "list".
    >>> This would
    >>> make it safer to do type-checking, because is.list also
    >>> returns
    >>> TRUE for a data.frame variable and using class(result)
    >>> == "list"
    >>> is an alternative that only returns TRUE for lists.
    >>> It's also
    >>> confusing initially that
    >>> 
    >>> class(x)
    >>> 
    >>> [1] "by"
    >>> 
    >>> is.list(x)
    >>> 
    >>> [1] TRUE
    >>> 
    >>> since there's no explicit class definition for "by" and no
    >>> mention if it has any superclasses.
    >>> 
    >>> --------------------------------------
    >>> Dario Strbenac
    >>> University of Sydney
    >>> Camperdown NSW 2050
    >>> Australia

    .............

    >>> --         Gabriel Becker, PhD
    >>> Scientist (Bioinformatics)
    >>> Genentech Research
    >>> 

    >> Herv? Pag?s
    >> 
    >> Program in Computational Biology
    >> Division of Public Health Sciences
    >> Fred Hutchinson Cancer Research Center
    >> 1100 Fairview Ave. N, M1-B514
    >> P.O. Box 19024
    >> Seattle, WA 98109-1024
    >> 
    >> E-mail: hpages at fredhutch.org
    >> Phone:  (206) 667-5791
    >> Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Thu Feb  1 10:21:19 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Feb 2018 10:21:19 +0100
Subject: [Rd] as.list method for by Objects
In-Reply-To: <CAOQ5NyeqQCKRKEb6BC8PCV=EojhmjRvqyvkona0hx6mZP8uq0g@mail.gmail.com>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <CAOQ5NyeqQCKRKEb6BC8PCV=EojhmjRvqyvkona0hx6mZP8uq0g@mail.gmail.com>
Message-ID: <23154.56335.356144.896852@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Tue, 30 Jan 2018 10:37:38 -0800 writes:

    > I agree that it would make sense for the object to have c("by", "list") as
    > its class attribute, since the object is known to behave as a list.

Well, but that (list behavior) applies to most non-simple S3
classed objects, say "data.frame", say "lm" to start with real basic ones.

The later part of the discussion, seems more relevant to me.
Adding "list" to the class attribute seems as wrong to me as
e.g. adding "double" to "Date" or "POSIXct" (and many more such cases).

For the present case, we should stay with focusing on  is.list()
being true after as.list() .. the same we would do with
as.numeric() and is.numeric().

Martin

    > However, it would may be too disruptive to make this change at this point.
    > Hard to predict.

    > Michael

    > On Mon, Jan 29, 2018 at 5:00 PM, Dario Strbenac <dstr7320 at uni.sydney.edu.au>
    > wrote:

    >> Good day,
    >> 
    >> I'd like to suggest the addition of an as.list method for a by object that
    >> actually returns a list of class "list". This would make it safer to do
    >> type-checking, because is.list also returns TRUE for a data.frame variable
    >> and using class(result) == "list" is an alternative that only returns TRUE
    >> for lists. It's also confusing initially that
    >> 
    >> > class(x)
    >> [1] "by"
    >> > is.list(x)
    >> [1] TRUE
    >> 
    >> since there's no explicit class definition for "by" and no mention if it
    >> has any superclasses.
    >> 
    >> --------------------------------------
    >> Dario Strbenac
    >> University of Sydney
    >> Camperdown NSW 2050
    >> Australia
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From michal.burda at centrum.cz  Thu Feb  1 09:23:22 2018
From: michal.burda at centrum.cz (Michal Burda)
Date: Thu, 1 Feb 2018 09:23:22 +0100
Subject: [Rd]  Error message: 'Rscript' should not be used without a path
Message-ID: <CAP4zaHOSSFJYoaaLS8_dP=G+ikg7X55E8YAaxR-rYgx_h4Cmew@mail.gmail.com>

Dear R-devel members,

recently, I ran into the following error message (R-devel 2018-01-31):

'Rscript' should not be used without a path -- see par. 1.6 of the manual

I would like to know more about it, why is it required to run Rscript with
a path, and where is that par. 1.6 of the manual.

I get this error message during Travis r-devel build of my package for
generating makefiles. I am developing a makefile generator package, which
contains testthat unit tests that generate and run various makefiles in
/tmp. These makefiles run several "Rscript -e" commands. Everything works
OK on R-stable on Linux as well as on Windows, the only problem is with
R-devel on that Travis cloud builder. Could someone give me more
information about that error? Is there any workaround or do I really need
to obtain somehow the full path of Rscript and put it into the makefiles
(as it may be tricky for such makefile work on linux, macOs and Windows)?

Thanks, in advance.


Michal Burda

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Thu Feb  1 13:22:18 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 1 Feb 2018 13:22:18 +0100
Subject: [Rd] Error message: 'Rscript' should not be used without a path
In-Reply-To: <CAP4zaHOSSFJYoaaLS8_dP=G+ikg7X55E8YAaxR-rYgx_h4Cmew@mail.gmail.com>
References: <CAP4zaHOSSFJYoaaLS8_dP=G+ikg7X55E8YAaxR-rYgx_h4Cmew@mail.gmail.com>
Message-ID: <df6c1ad0-5f8a-2423-c7a5-25f3027f33eb@gmail.com>

Hi Michal,

On 02/01/2018 09:23 AM, Michal Burda wrote:
> Dear R-devel members,
>
> recently, I ran into the following error message (R-devel 2018-01-31):
>
> 'Rscript' should not be used without a path -- see par. 1.6 of the manual
>
> I would like to know more about it, why is it required to run Rscript with
> a path, and where is that par. 1.6 of the manual.
The manual is "Writing R Extensions"
https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Writing-portable-packages

"
Do not invoke R by plain R, Rscript or (on Windows) Rterm in your 
examples, tests, vignettes, makefiles or other scripts. As pointed out 
in several places earlier in this manual, use something like
"$(R_HOME)/bin/Rscript"
"$(R_HOME)/bin$(R_ARCH_BIN)/Rterm"
with appropriate quotes (as, although not recommended, R_HOME can 
contain spaces).
"

This is needed to make sure that one does not run Rscript from a 
different version of R installed in the system. The quotes are important 
and it works on all platforms supported by R.

(for similar questions perhaps R-package-devel is a bit better list)

Best
Tomas

>
> I get this error message during Travis r-devel build of my package for
> generating makefiles. I am developing a makefile generator package, which
> contains testthat unit tests that generate and run various makefiles in
> /tmp. These makefiles run several "Rscript -e" commands. Everything works
> OK on R-stable on Linux as well as on Windows, the only problem is with
> R-devel on that Travis cloud builder. Could someone give me more
> information about that error? Is there any workaround or do I really need
> to obtain somehow the full path of Rscript and put it into the makefiles
> (as it may be tricky for such makefile work on linux, macOs and Windows)?
>
> Thanks, in advance.
>
>
> Michal Burda
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Feb  1 13:29:01 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 1 Feb 2018 07:29:01 -0500
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <89bbc3b2-b173-961d-5cd2-fc83c05600dc@gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CY4PR2001MB10641A6B87B06111469FDBD0BEE40@CY4PR2001MB1064.namprd20.prod.outlook.com>
 <23152.57287.697853.990831@rob.eddelbuettel.com>
 <CAPekMCkWYvdGJ=wXA3bGFs655xsV6RUFCCjFpcpZ4rjmB8u-VQ@mail.gmail.com>
 <a8fbf26f-5a4c-3526-68a5-e062a596313c@gmail.com>
 <CABdHhvGGCpjFa-dPiK6fHLfVzCzZ3PboGSH9c8Jy+daW14vSNg@mail.gmail.com>
 <89bbc3b2-b173-961d-5cd2-fc83c05600dc@gmail.com>
Message-ID: <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>

On 31/01/2018 6:59 AM, Duncan Murdoch wrote:
> On 30/01/2018 11:39 PM, Hadley Wickham wrote:
  [ lots deleted ]
>> Personally, I don't find writing in comments any harder than writing
>> in .Rd files, especially now that you can write in markdown and have
>> it automatically translated to Rd formatting commands.
> 
> I didn't know about the possibility of Markdown.  That's a good thing.
> You didn't say what editor you use, but RStudio is a good guess, and it
> also makes it easier to write in comments.

I've taken a look at the Markdown support, and I think that is 
fantastic.  I'd rather it wasn't inline in the .R file (does it have to 
be?), but I'd say it tips the balance, and I'll certainly experiment 
with using that for new projects.

The only negative I see besides forcing inline docs is pretty minor:  I 
can see that supporting Rd markup within the Markdown text will on rare 
occasions cause lots of confusion (because users won't know why their 
backslashes are doing funny things).  I'd suggest that (at least 
optionally) you should escape anything that looks like Rd markup, so a 
user can put text like \item into the middle of a paragraph and not have 
the Rd parser see it.

Duncan Murdoch


From jorismeys at gmail.com  Thu Feb  1 13:44:24 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 1 Feb 2018 13:44:24 +0100
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CY4PR2001MB10641A6B87B06111469FDBD0BEE40@CY4PR2001MB1064.namprd20.prod.outlook.com>
 <23152.57287.697853.990831@rob.eddelbuettel.com>
 <CAPekMCkWYvdGJ=wXA3bGFs655xsV6RUFCCjFpcpZ4rjmB8u-VQ@mail.gmail.com>
 <a8fbf26f-5a4c-3526-68a5-e062a596313c@gmail.com>
 <CABdHhvGGCpjFa-dPiK6fHLfVzCzZ3PboGSH9c8Jy+daW14vSNg@mail.gmail.com>
 <89bbc3b2-b173-961d-5cd2-fc83c05600dc@gmail.com>
 <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>
Message-ID: <CAO1zAVYnHx_TFcZBvynQ8GRX_fRadpqRipgk-731G-X5BXO29w@mail.gmail.com>

On Thu, Feb 1, 2018 at 1:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 31/01/2018 6:59 AM, Duncan Murdoch wrote:
>
>> On 30/01/2018 11:39 PM, Hadley Wickham wrote:
>>
>  [ lots deleted ]
>
>> Personally, I don't find writing in comments any harder than writing
>>> in .Rd files, especially now that you can write in markdown and have
>>> it automatically translated to Rd formatting commands.
>>>
>>
>> I didn't know about the possibility of Markdown.  That's a good thing.
>> You didn't say what editor you use, but RStudio is a good guess, and it
>> also makes it easier to write in comments.
>>
>
> I've taken a look at the Markdown support, and I think that is fantastic.
> I'd rather it wasn't inline in the .R file (does it have to be?), but I'd
> say it tips the balance, and I'll certainly experiment with using that for
> new projects.
>

You don't have to put the Rmarkdown in the .R file of the function, there
are ways to keep them in separate files. But keeping them in the same file
does make it easier for Rmarkdown to eg generate the correct usage section
and use the correct Rd makeup etc. At least that's my understanding of it.
Hadley will hopefully correct me if I'm wrong.  I haven't checked all the
options and possibilities yet in the latest iterations of the package.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From georgi.boshnakov at manchester.ac.uk  Thu Feb  1 14:17:41 2018
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 1 Feb 2018 13:17:41 +0000
Subject: [Rd] Best practices in developing package: From a single file
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F64BEB0@MBXP01.ds.man.ac.uk>

It is indeed a matter of what the developer is comfortable with and the one-stop solution provided by devtools is difficult to beat. 
This may also vary across projects. I use EMACS/ESS with and without roxygen2. In some cases EMACS/ESS+Org mode provides stunning benefits.

Updating "usage" statements in Rd files was mentioned several times. 
Rdpack::reprompt() does this and more for functions, methods and classes. 


Georgi Boshnakov

------------------------------
Date: Wed, 31 Jan 2018 07:53:18 -0800
From: Michael Lawrence <lawrence.michael at gene.com>
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: "Brian G. Peterson" <brian at braverock.com>, "Suzen, Mehmet"
	<mehmet.suzen at gmail.com>, R-devel <r-devel at r-project.org>
Subject: Re: [Rd] Best practices in developing package: From a single
	file
Message-ID:
	<CAOQ5NyequDcsBczAqOg6XqDeUNx2hXg+4ggHc0Ews0NxgszHSA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

I pretty much agree. I tried using roxygen when it was first released but
couldn't stand putting documentation in comments, especially for complex,
S4-based software. Rd is easy to read and write and lets me focus on the
task of writing documentation (focus is the hardest part of any task for
me). Probably the best feature of roxygen is that it automatically
generates \usage{}, which is otherwise completely redundant with the code.

I think the preceeding systems like doxygen, javadoc, gtk-doc, qtdoc, etc,
found a nice compromise through templating, where the bulk of the details
are written into the template, and just the essentials (usage, arguments,
return value) were embedded in the source file. I think this is even more
important for R, since we're often describing complex algorithms, while
most C/C++/Java software is oriented complex classes containing many
relatively simple methods.

Michael


On Tue, Jan 30, 2018 at 11:53 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/01/2018 11:29 AM, Brian G. Peterson wrote:
>
>> On Tue, 2018-01-30 at 17:00 +0100, Suzen, Mehmet wrote:
>>
>>> Dear R developers,
>>>
>>> I am wondering what are the best practices for developing an R
>>> package. I am aware of Hadley Wickham's best practice
>>> documentation/book (http://r-pkgs.had.co.nz/).  I recall a couple of
>>> years ago there were some tools for generating a package out of a
>>> single file, such as using package.skeleton, but no auto-generated
>>> documentation. Do you know a way to generate documentation and a
>>> package out of single R source file, or from an environment?
>>>
>>
>> Mehmet,
>>
>> This list is for development of the R language itself and closely
>> related tools.  There is a separate list, R-pkg-devel, for development
>> of packages.
>>
>> Since you're here, I'll try to answer your question.
>>
>> package.skeleton can create a package from all the R functions in a
>> specified environment.  So if you load all the functions that you want
>> in your new package into your R environment, then call
>> package.skeleton, you'll have a starting point.
>>
>> At that point, I would probably recommend moving to RStudio, and using
>> RStudio to generate markdown comments for roxygen for all your newly
>> created function files.  Then you could finish off the documentation by
>> writing it in these roxygen skeletons or copying and pasting from
>> comments in your original code files.
>>
>
> I'd agree about moving to RStudio, but I think Roxygen is the wrong
> approach for documentation.  package.skeleton() will have done the boring
> mechanical part of setting up your .Rd files; all you have to do is edit
> some content into them.  (Use prompt() to add a new file if you add a new
> function later, don't run package.skeleton() again.)
>
> This isn't the fashionable point of view, but I think it is easier to get
> good documentation that way than using Roxygen.  (It's easier to get bad
> documentation using Roxygen, but who wants that?)
>
> The reason I think this is that good documentation requires work and
> thought.  You need to think about the markup that will get your point
> across, you need to think about putting together good examples, etc.
> This is *harder* in Roxygen than if you are writing Rd files, because
> Roxygen is a thin front end to produce Rd files from comments in your .R
> files.  To get good stuff in the help page, you need just as much work as
> in writing the .Rd file directly, but then you need to add another layer on
> top to put in in a comment.  Most people don't bother.
>
> I don't know any packages with what I'd consider to be good documentation
> that use Roxygen.  It's just too easy to write minimal documentation that
> passes checks, so Roxygen users don't keep refining it.
>
> (There are plenty of examples of packages that write bad documentation
> directly to .Rd as well.  I just don't know of examples of packages with
> good documentation that use Roxygen.)
>
> Based on my criticism last week of git and Github, I expect to be called a
> grumpy old man for holding this point of view.  I'd actually like to be
> proven wrong.  So to anyone who disagrees with me:  rather than just
> calling me names, how about some examples of Roxygen-using packages that
> have good help pages with good explanations, and good examples in them?
>
> Back to Mehmet's question:  I think Hadley's book is pretty good, and I'd
> recommend most of it, just not the Roxygen part.
>
> Duncan Murdoch
>


From lionel at rstudio.com  Thu Feb  1 14:24:52 2018
From: lionel at rstudio.com (Lionel Henry)
Date: Thu, 1 Feb 2018 05:24:52 -0800
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <FCD9A33C859ACC469587CB09DD5C6C7132024B84@GBLONXMB13.corp.amvescap.net>
 <CAPtbhHzGAT9LKC-kkwWQQBdBsMdsirq=0UeZRGb5Ack5rPPX9w@mail.gmail.com>
 <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
Message-ID: <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>

On 31 janv. 2018, at 09:08, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> it *actively discourages* the bits it doesn't directly support.

It may be discouraging to include Rd syntax in roxygen docs but only
because the LaTeX-like syntax of Rd is burdensome, not because of
roxygen. It is still handy to have inlined Rd as a backup and we do
use it for the cases where we need finer grained control.

I agree with your sentiment that roxygen encourages writing of
documentation for time-constrained users.

I'll add that the major problem of documentation is not fancy
formatting but the content getting out of sync with the codebase.
Having documentation sitting next to the code is the preferred
antidote to doc rot, e.g. docstrings in lisp languages, Julia and
Python, the Linux kernel-doc system, doxygen, javadoc, ...
It is true that R CMD check extensive checks help a lot as well in
this regard though only for things that can be checked automatically.

Best,
Lionel


From lawrence.michael at gene.com  Thu Feb  1 15:12:20 2018
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 1 Feb 2018 06:12:20 -0800
Subject: [Rd] as.list method for by Objects
In-Reply-To: <23154.56335.356144.896852@stat.math.ethz.ch>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <CAOQ5NyeqQCKRKEb6BC8PCV=EojhmjRvqyvkona0hx6mZP8uq0g@mail.gmail.com>
 <23154.56335.356144.896852@stat.math.ethz.ch>
Message-ID: <CAOQ5Nye7Ug_dmzc-75wCQyVarn1=L9Q71mRm5vY97njFpoUYmg@mail.gmail.com>

On Thu, Feb 1, 2018 at 1:21 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Tue, 30 Jan 2018 10:37:38 -0800 writes:
>
>     > I agree that it would make sense for the object to have c("by",
> "list") as
>     > its class attribute, since the object is known to behave as a list.
>
> Well, but that (list behavior) applies to most non-simple S3
> classed objects, say "data.frame", say "lm" to start with real basic ones.
>
> The later part of the discussion, seems more relevant to me.
> Adding "list" to the class attribute seems as wrong to me as
> e.g. adding "double" to "Date" or "POSIXct" (and many more such cases).
>
>
There's a distinction though. Date and POSIXct should not really behave as
double values (an implementation detail), but "by" is expected to behave as
a list (when it is one).

For the present case, we should stay with focusing on  is.list()
> being true after as.list() .. the same we would do with
> as.numeric() and is.numeric().
>
> Martin
>
>     > However, it would may be too disruptive to make this change at this
> point.
>     > Hard to predict.
>
>     > Michael
>
>     > On Mon, Jan 29, 2018 at 5:00 PM, Dario Strbenac <
> dstr7320 at uni.sydney.edu.au>
>     > wrote:
>
>     >> Good day,
>     >>
>     >> I'd like to suggest the addition of an as.list method for a by
> object that
>     >> actually returns a list of class "list". This would make it safer
> to do
>     >> type-checking, because is.list also returns TRUE for a data.frame
> variable
>     >> and using class(result) == "list" is an alternative that only
> returns TRUE
>     >> for lists. It's also confusing initially that
>     >>
>     >> > class(x)
>     >> [1] "by"
>     >> > is.list(x)
>     >> [1] TRUE
>     >>
>     >> since there's no explicit class definition for "by" and no mention
> if it
>     >> has any superclasses.
>     >>
>     >> --------------------------------------
>     >> Dario Strbenac
>     >> University of Sydney
>     >> Camperdown NSW 2050
>     >> Australia
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>     >>
>
>     > [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb  1 15:40:43 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 1 Feb 2018 09:40:43 -0500
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E018F64BEB0@MBXP01.ds.man.ac.uk>
References: <438D2EC9EAFE5946B2D5864670EA468E018F64BEB0@MBXP01.ds.man.ac.uk>
Message-ID: <b9addad5-9411-2bab-8a83-d217ad789658@gmail.com>

On 01/02/2018 8:17 AM, Georgi Boshnakov wrote:
> It is indeed a matter of what the developer is comfortable with and the one-stop solution provided by devtools is difficult to beat.
> This may also vary across projects. I use EMACS/ESS with and without roxygen2. In some cases EMACS/ESS+Org mode provides stunning benefits.
> 
> Updating "usage" statements in Rd files was mentioned several times.
> Rdpack::reprompt() does this and more for functions, methods and classes.

Thanks for pointing that out (and for writing it)!  I had forgotten 
about your package.

Duncan Murdoch


From therneau at mayo.edu  Thu Feb  1 15:51:24 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 01 Feb 2018 08:51:24 -0600
Subject: [Rd] Fwd: Re:  Best practices in developing package:
In-Reply-To: <16a568f8-b467-57b8-04a6-46ecfac7ae63@mayo.edu>
References: <16a568f8-b467-57b8-04a6-46ecfac7ae63@mayo.edu>
Message-ID: <943511$8qar09@ironport10.mayo.edu>

> I'm not going to force anyone to use roxygen2. But I personally find it
> easier to have the function right below the documentation, so that any
> change to the function can immediately be documented as well. You prefer to
> do this by keeping that strictly separated, which is absolutely fine. It's
> just not my prefered workflow. Different animal, different habits I guess.
> 

Lest Duncan be left standing all alone let me say that I am another who really dislikes
the roxygen style.  Joris' comment above is a key one though; the goal is good
documentation and any tool to that end is just a tool.  One driver for my preferences is
that I don't like editing large files, e.g., in the survival package every function is a
separate file.  A second is that I care a lot about documentation so my help files are
fairly long, so much so that the advantage of having the documentation of an argument
"close" to the declaration of said argument is lost.

The closeness argument works best when the documentation for each argument is a terse half
sentence, and in that sense roxygen encourages minimalist documentation.  But the real
issue with poor documentation is the orneriness of the writers: good documentation is hard
work and most don't bother.  For most R packages lines of code > lines of documentation >
lines of test suite, usually by a factor of 10 at each stage.  One of my goals for the
survival package has been to make them more equal with 'lines of documentation' the
largest.  I'm getting closer: currently 17395 lines in the R subdirectory, 8042 + 8841 in
man + vignettes, and 6000 in test.

A challenge for someone who is better at document analysis than me: what is the distribution
of the ratios above, across CRAN packages?  Is my 10:1 impression optimistic?

 ?Terry T.


From lionel at rstudio.com  Thu Feb  1 16:20:18 2018
From: lionel at rstudio.com (Lionel Henry)
Date: Thu, 1 Feb 2018 07:20:18 -0800
Subject: [Rd] Fwd: Re:  Best practices in developing package:
In-Reply-To: <943511$8qar09@ironport10.mayo.edu>
References: <16a568f8-b467-57b8-04a6-46ecfac7ae63@mayo.edu>
 <943511$8qar09@ironport10.mayo.edu>
Message-ID: <B1ABA533-F827-4774-B9EE-DCBF607F9F73@rstudio.com>


> On 1 f?vr. 2018, at 06:51, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
> 
> A second is that I care a lot about documentation so my help files are
> fairly long, so much so that the advantage of having the documentation of an argument
> "close" to the declaration of said argument is lost.

Good point. It suggests editors need folding support for roxygen sections.

Lionel

From murdoch.duncan at gmail.com  Thu Feb  1 16:20:16 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 1 Feb 2018 10:20:16 -0500
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CAO1zAVYnHx_TFcZBvynQ8GRX_fRadpqRipgk-731G-X5BXO29w@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CY4PR2001MB10641A6B87B06111469FDBD0BEE40@CY4PR2001MB1064.namprd20.prod.outlook.com>
 <23152.57287.697853.990831@rob.eddelbuettel.com>
 <CAPekMCkWYvdGJ=wXA3bGFs655xsV6RUFCCjFpcpZ4rjmB8u-VQ@mail.gmail.com>
 <a8fbf26f-5a4c-3526-68a5-e062a596313c@gmail.com>
 <CABdHhvGGCpjFa-dPiK6fHLfVzCzZ3PboGSH9c8Jy+daW14vSNg@mail.gmail.com>
 <89bbc3b2-b173-961d-5cd2-fc83c05600dc@gmail.com>
 <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>
 <CAO1zAVYnHx_TFcZBvynQ8GRX_fRadpqRipgk-731G-X5BXO29w@mail.gmail.com>
Message-ID: <58b63a61-ae71-3fd3-57b7-1424bf1cfdab@gmail.com>

On 01/02/2018 7:44 AM, Joris Meys wrote:
> 
> 
> On Thu, Feb 1, 2018 at 1:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 31/01/2018 6:59 AM, Duncan Murdoch wrote:
> 
>         On 30/01/2018 11:39 PM, Hadley Wickham wrote:
> 
>      ?[ lots deleted ]
> 
>             Personally, I don't find writing in comments any harder than
>             writing
>             in .Rd files, especially now that you can write in markdown
>             and have
>             it automatically translated to Rd formatting commands.
> 
> 
>         I didn't know about the possibility of Markdown.? That's a good
>         thing.
>         You didn't say what editor you use, but RStudio is a good guess,
>         and it
>         also makes it easier to write in comments.
> 
> 
>     I've taken a look at the Markdown support, and I think that is
>     fantastic.? I'd rather it wasn't inline in the .R file (does it have
>     to be?), but I'd say it tips the balance, and I'll certainly
>     experiment with using that for new projects.
> 
> 
> You don't have to put the Rmarkdown in the .R file of the function, 
> there are ways to keep them in separate files. But keeping them in the 
> same file does make it easier for Rmarkdown to eg generate the correct 
> usage section and use the correct Rd makeup etc. At least that's my 
> understanding of it. Hadley will hopefully correct me if I'm wrong.? I 
> haven't checked all the options and possibilities yet in the latest 
> iterations of the package.

I don't see that in the Roxygen2 docs, so hopefully it is possible, and 
someone will point out how it's done.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Thu Feb  1 16:34:04 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Feb 2018 16:34:04 +0100
Subject: [Rd] sum() returns NA on a long *logical* vector when nb of
 TRUE values exceeds 2^31
In-Reply-To: <3d97d7d0-ef1b-90a7-ed1e-16af5461abc0@fredhutch.org>
References: <5931466B.1060407@fredhutch.org>
 <CAFDcVCRt1=-1t8=-x5TLhe3y0T_tpZUkTAH1W-hyMKqFH-eJYg@mail.gmail.com>
 <CAFDcVCQv19O2zBybkRHh6G58AMa0GjQRZcHnD3WEnQACnuM7Uw@mail.gmail.com>
 <23148.23857.970768.727765@stat.math.ethz.ch>
 <3d97d7d0-ef1b-90a7-ed1e-16af5461abc0@fredhutch.org>
Message-ID: <23155.13164.411368.435222@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Tue, 30 Jan 2018 13:30:18 -0800 writes:

    > Hi Martin, Henrik,
    > Thanks for the follow up.

    > @Martin: I vote for 2) without *any* hesitation :-)

    > (and uniformity could be restored at some point in the
    > future by having prod(), rowSums(), colSums(), and others
    > align with the behavior of length() and sum())

As a matter of fact, I had procrastinated and worked at
implementing '2)' already a bit on the weekend and made it work
- more or less.  It needs a bit more work, and I had also been considering
replacing the numbers in the current overflow check

	if (ii++ > 1000) {	 \
	    ii = 0;							\
	    if (s > 9000000000000000L || s < -9000000000000000L) {	\
		if(!updated) updated = TRUE;				\
		*value = NA_INTEGER;					\
		warningcall(call, _("integer overflow - use sum(as.numeric(.))")); \
		return updated;						\
	    }								\
	}								\

i.e. think of tweaking the '1000' and '9000000000000000L', 
but decided to leave these and add comments there about why. For
the moment.
They may look arbitrary, but are not at all: If you multiply
them (which looks correct, if we check the sum 's' only every 1000-th
time ...((still not sure they *are* correct))) you get  9*10^18
which is only slightly smaller than  2^63 - 1 which may be the
maximal "LONG_INT" integer we have.

So, in the end, at least for now, we do not quite go all they way
but overflow a bit earlier,... but do potentially gain a bit of
speed, notably with the ITERATE_BY_REGION(..) macros
(which I did not show above).

Will hopefully become available in R-devel real soon now.

Martin

    > Cheers,
    > H.


    > On 01/27/2018 03:06 AM, Martin Maechler wrote:
    >>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
    >>>>>>> on Thu, 25 Jan 2018 09:30:42 -0800 writes:
    >> 
    >> > Just following up on this old thread since matrixStats 0.53.0 is now
    >> > out, which supports this use case:
    >> 
    >> >> x <- rep(TRUE, times = 2^31)
    >> 
    >> >> y <- sum(x)
    >> >> y
    >> > [1] NA
    >> > Warning message:
    >> > In sum(x) : integer overflow - use sum(as.numeric(.))
    >> 
    >> >> y <- matrixStats::sum2(x, mode = "double")
    >> >> y
    >> > [1] 2147483648
    >> >> str(y)
    >> > num 2.15e+09
    >> 
    >> > No coercion is taking place, so the memory overhead is zero:
    >> 
    >> >> profmem::profmem(y <- matrixStats::sum2(x, mode = "double"))
    >> > Rprofmem memory profiling of:
    >> > y <- matrixStats::sum2(x, mode = "double")
    >> 
    >> > Memory allocations:
    >> > bytes calls
    >> > total     0
    >> 
    >> > /Henrik
    >> 
    >> Thank you, Henrik, for the reminder.
    >> 
    >> Back in June, I had mentioned to Herv? and R-devel that
    >> 'logical' should remain to be treated as 'integer' as in all
    >> arithmetic in (S and) R.     Herv? did mention the isum()
    >> function in the C code which is relevant here .. which does have
    >> a LONG INT counter already -- *but* if we consider that sum()
    >> has '...' i.e. a conceptually arbitrary number of long vector
    >> integer arguments that counter won't suffice even there.
    >> 
    >> Before talking about implementation / patch, I think we should
    >> consider 2 possible goals of a change --- I agree the status quo
    >> is not a real option
    >> 
    >> 1) sum(x) for logical and integer x  would return a double
    >> in any case and overflow should not happen (unless for
    >> the case where the result would be larger the
    >> .Machine$double.max which I think will not be possible
    >> even with "arbitrary" nargs() of sum.
    >> 
    >> 2) sum(x) for logical and integer x  should return an integer in
    >> all cases there is no overflow, including returning
    >> NA_integer_ in case of NAs.
    >> If there would be an overflow it must be detected "in time"
    >> and the result should be double.
    >> 
    >> The big advantage of 2) is that it is back compatible in 99.x %
    >> of use cases, and another advantage that it may be a very small
    >> bit more efficient.  Also, in the case of "counting" (logical),
    >> it is nice to get an integer instead of double when we can --
    >> entirely analogously to the behavior of length() which returns
    >> integer whenever possible.
    >> 
    >> The advantage of 1) is uniformity.
    >> 
    >> We should (at least provisionally) decide between 1) and 2) and then go for that.
    >> It could be that going for 1) may have bad
    >> compatibility-consequences in package space, because indeed we
    >> had documented sum() would be integer for logical and integer arguments.
    >> 
    >> I currently don't really have time to
    >> {work on implementing + dealing with the consequences}
    >> for either ..
    >> 
    >> Martin
    >> 
    >> > On Fri, Jun 2, 2017 at 1:58 PM, Henrik Bengtsson
    >> > <henrik.bengtsson at gmail.com> wrote:
    >> >> I second this feature request (it's understandable that this and
    >> >> possibly other parts of the code was left behind / forgotten after the
    >> >> introduction of long vector).
    >> >>
    >> >> I think mean() avoids full copies, so in the meanwhile, you can work
    >> >> around this limitation using:
    >> >>
    >> >> countTRUE <- function(x, na.rm = FALSE) {
    >> >> nx <- length(x)
    >> >> if (nx < .Machine$integer.max) return(sum(x, na.rm = na.rm))
    >> >> nx * mean(x, na.rm = na.rm)
    >> >> }
    >> >>
    >> >> (not sure if one needs to worry about rounding errors, i.e. where n %% 0 != 0)
    >> >>
    >> >> x <- rep(TRUE, times = .Machine$integer.max+1)
    >> >> object.size(x)
    >> >> ## 8589934632 bytes
    >> >>
    >> >> p <- profmem::profmem( n <- countTRUE(x) )
    >> >> str(n)
    >> >> ## num 2.15e+09
    >> >> print(n == .Machine$integer.max + 1)
    >> >> ## [1] TRUE
    >> >>
    >> >> print(p)
    >> >> ## Rprofmem memory profiling of:
    >> >> ## n <- countTRUE(x)
    >> >> ##
    >> >> ## Memory allocations:
    >> >> ##      bytes calls
    >> >> ## total     0
    >> >>
    >> >>
    >> >> FYI / related: I've just updated matrixStats::sum2() to support
    >> >> logicals (develop branch) and I'll also try to update
    >> >> matrixStats::count() to count beyond .Machine$integer.max.
    >> >>
    >> >> /Henrik
    >> >>
    >> >> On Fri, Jun 2, 2017 at 4:05 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:
    >> >>> Hi,
    >> >>>
    >> >>> I have a long numeric vector 'xx' and I want to use sum() to count
    >> >>> the number of elements that satisfy some criteria like non-zero
    >> >>> values or values lower than a certain threshold etc...
    >> >>>
    >> >>> The problem is: sum() returns an NA (with a warning) if the count
    >> >>> is greater than 2^31. For example:
    >> >>>
    >> >>> > xx <- runif(3e9)
    >> >>> > sum(xx < 0.9)
    >> >>> [1] NA
    >> >>> Warning message:
    >> >>> In sum(xx < 0.9) : integer overflow - use sum(as.numeric(.))
    >> >>>
    >> >>> This already takes a long time and doing sum(as.numeric(.)) would
    >> >>> take even longer and require allocation of 24Gb of memory just to
    >> >>> store an intermediate numeric vector made of 0s and 1s. Plus, having
    >> >>> to do sum(as.numeric(.)) every time I need to count things is not
    >> >>> convenient and is easy to forget.
    >> >>>
    >> >>> It seems that sum() on a logical vector could be modified to return
    >> >>> the count as a double when it cannot be represented as an integer.
    >> >>> Note that length() already does this so that wouldn't create a
    >> >>> precedent. Also and FWIW prod() avoids the problem by always returning
    >> >>> a double, whatever the type of the input is (except on a complex
    >> >>> vector).
    >> >>>
    >> >>> I can provide a patch if this change sounds reasonable.
    >> >>>
    >> >>> Cheers,
    >> >>> H.
    >> >>>
    >> >>> --
    >> >>> Herv? Pag?s
    >> 
    >> 

    > -- 
    > Herv? Pag?s

    > Program in Computational Biology
    > Division of Public Health Sciences
    > Fred Hutchinson Cancer Research Center
    > 1100 Fairview Ave. N, M1-B514
    > P.O. Box 19024
    > Seattle, WA 98109-1024

    > E-mail: hpages at fredhutch.org
    > Phone:  (206) 667-5791
    > Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Thu Feb  1 16:37:05 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Feb 2018 16:37:05 +0100
Subject: [Rd] as.list method for by Objects
In-Reply-To: <CAOQ5Nye7Ug_dmzc-75wCQyVarn1=L9Q71mRm5vY97njFpoUYmg@mail.gmail.com>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <CAOQ5NyeqQCKRKEb6BC8PCV=EojhmjRvqyvkona0hx6mZP8uq0g@mail.gmail.com>
 <23154.56335.356144.896852@stat.math.ethz.ch>
 <CAOQ5Nye7Ug_dmzc-75wCQyVarn1=L9Q71mRm5vY97njFpoUYmg@mail.gmail.com>
Message-ID: <23155.13345.961232.702014@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Thu, 1 Feb 2018 06:12:20 -0800 writes:

    > On Thu, Feb 1, 2018 at 1:21 AM, Martin Maechler <maechler at stat.math.ethz.ch>
    > wrote:

    >> >>>>> Michael Lawrence <lawrence.michael at gene.com>
    >> >>>>>     on Tue, 30 Jan 2018 10:37:38 -0800 writes:
    >> 
    >> > I agree that it would make sense for the object to have c("by",
    >> "list") as
    >> > its class attribute, since the object is known to behave as a list.
    >> 
    >> Well, but that (list behavior) applies to most non-simple S3
    >> classed objects, say "data.frame", say "lm" to start with real basic ones.
    >> 
    >> The later part of the discussion, seems more relevant to me.
    >> Adding "list" to the class attribute seems as wrong to me as
    >> e.g. adding "double" to "Date" or "POSIXct" (and many more such cases).
    >> 
    >> 
    > There's a distinction though. Date and POSIXct should not really behave as
    > double values (an implementation detail), but "by" is expected to behave as
    > a list (when it is one).

yes, you are right....  As I'm "never"(*) using by(), I'm glad
to leave this issue to you.

Martin

---
*) Never .... [James Bond, 1983]

    > For the present case, we should stay with focusing on  is.list()
    >> being true after as.list() .. the same we would do with
    >> as.numeric() and is.numeric().
    >> 
    >> Martin
    >> 
    >> > However, it would may be too disruptive to make this change at this
    >> point.
    >> > Hard to predict.
    >> 
    >> > Michael
    >> 
    >> > On Mon, Jan 29, 2018 at 5:00 PM, Dario Strbenac <
    >> dstr7320 at uni.sydney.edu.au>
    >> > wrote:
    >> 
    >> >> Good day,
    >> >>
    >> >> I'd like to suggest the addition of an as.list method for a by
    >> object that
    >> >> actually returns a list of class "list". This would make it safer
    >> to do
    >> >> type-checking, because is.list also returns TRUE for a data.frame
    >> variable
    >> >> and using class(result) == "list" is an alternative that only
    >> returns TRUE
    >> >> for lists. It's also confusing initially that
    >> >>
    >> >> > class(x)
    >> >> [1] "by"
    >> >> > is.list(x)
    >> >> [1] TRUE
    >> >>
    >> >> since there's no explicit class definition for "by" and no mention
    >> if it
    >> >> has any superclasses.
    >> >>
    >> >> --------------------------------------
    >> >> Dario Strbenac
    >> >> University of Sydney
    >> >> Camperdown NSW 2050
    >> >> Australia
    >> >>
    >> >> ______________________________________________
    >> >> R-devel at r-project.org mailing list
    >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >>
    >> >>
    >> 
    >> > [[alternative HTML version deleted]]
    >> 
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    > [[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Feb  1 16:36:59 2018
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 1 Feb 2018 07:36:59 -0800
Subject: [Rd] Fwd: Re: Best practices in developing package:
In-Reply-To: <B1ABA533-F827-4774-B9EE-DCBF607F9F73@rstudio.com>
References: <16a568f8-b467-57b8-04a6-46ecfac7ae63@mayo.edu>
 <943511$8qar09@ironport10.mayo.edu>
 <B1ABA533-F827-4774-B9EE-DCBF607F9F73@rstudio.com>
Message-ID: <CAOQ5NyefqSqo1LDV7ytfiempmKSGq8kAgvoybqo_Y1Q9zEo58w@mail.gmail.com>

Folding is a simple solution, but there are intrinsic problems, like the
need to embed the documentation in comments. If the user already has to
expand a fold to edit the docs, the IDE could instead just provide a link
or shortcut that jumps to a separate documentation file, written in
whatever language, Rd, markdown, docbook. For example, I could imagine
RStudio showing the rendered documentation in a side pane when the cursor
is on the function name/signature, and the user could somehow switch modes
to edit it. But there would be no need to mix two different languages in
the same file, and thus no ugly escaping, and no documentation obscuring
the code, or vice versa.

On Thu, Feb 1, 2018 at 7:20 AM, Lionel Henry <lionel at rstudio.com> wrote:

>
> > On 1 f?vr. 2018, at 06:51, Therneau, Terry M., Ph.D. <therneau at mayo.edu>
> wrote:
> >
> > A second is that I care a lot about documentation so my help files are
> > fairly long, so much so that the advantage of having the documentation
> of an argument
> > "close" to the declaration of said argument is lost.
>
> Good point. It suggests editors need folding support for roxygen sections.
>
> Lionel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Feb  1 17:12:58 2018
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 1 Feb 2018 08:12:58 -0800
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CY4PR2001MB10641A6B87B06111469FDBD0BEE40@CY4PR2001MB1064.namprd20.prod.outlook.com>
 <23152.57287.697853.990831@rob.eddelbuettel.com>
 <CAPekMCkWYvdGJ=wXA3bGFs655xsV6RUFCCjFpcpZ4rjmB8u-VQ@mail.gmail.com>
 <a8fbf26f-5a4c-3526-68a5-e062a596313c@gmail.com>
 <CABdHhvGGCpjFa-dPiK6fHLfVzCzZ3PboGSH9c8Jy+daW14vSNg@mail.gmail.com>
 <89bbc3b2-b173-961d-5cd2-fc83c05600dc@gmail.com>
 <aacda07a-836c-313d-5cc9-c32a5d178f7f@gmail.com>
Message-ID: <CABdHhvHojfnMfOp9P7bm6zPCXz00M3XxidFMXyzqHUw7yy9oQw@mail.gmail.com>

On Thu, Feb 1, 2018 at 4:29 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 31/01/2018 6:59 AM, Duncan Murdoch wrote:
>>
>> On 30/01/2018 11:39 PM, Hadley Wickham wrote:
>
>  [ lots deleted ]
>>>
>>> Personally, I don't find writing in comments any harder than writing
>>> in .Rd files, especially now that you can write in markdown and have
>>> it automatically translated to Rd formatting commands.
>>
>>
>> I didn't know about the possibility of Markdown.  That's a good thing.
>> You didn't say what editor you use, but RStudio is a good guess, and it
>> also makes it easier to write in comments.
>
>
> I've taken a look at the Markdown support, and I think that is fantastic.
> I'd rather it wasn't inline in the .R file (does it have to be?), but I'd
> say it tips the balance, and I'll certainly experiment with using that for
> new projects.

Please do let me know how it goes - often a fresh set of eyes reveals
problems that an experienced user is blind to.

> The only negative I see besides forcing inline docs is pretty minor:  I can
> see that supporting Rd markup within the Markdown text will on rare
> occasions cause lots of confusion (because users won't know why their
> backslashes are doing funny things).  I'd suggest that (at least optionally)
> you should escape anything that looks like Rd markup, so a user can put text
> like \item into the middle of a paragraph and not have the Rd parser see it.

Yes, that would certainly be nice. It's a little challenging because
we're using the commonmark parser, but it should be possible somehow.

Hadley

-- 
http://hadley.nz


From gmbecker at ucdavis.edu  Thu Feb  1 18:20:53 2018
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 1 Feb 2018 09:20:53 -0800
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <FCD9A33C859ACC469587CB09DD5C6C7132024B84@GBLONXMB13.corp.amvescap.net>
 <CAPtbhHzGAT9LKC-kkwWQQBdBsMdsirq=0UeZRGb5Ack5rPPX9w@mail.gmail.com>
 <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
 <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>
Message-ID: <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>

On Thu, Feb 1, 2018 at 5:24 AM, Lionel Henry <lionel at rstudio.com> wrote:

> On 31 janv. 2018, at 09:08, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>
> > it *actively discourages* the bits it doesn't directly support.
>
> It may be discouraging to include Rd syntax in roxygen docs but only
> because the LaTeX-like syntax of Rd is burdensome, not because of
> roxygen. It is still handy to have inlined Rd as a backup and we do
> use it for the cases where we need finer grained control.
>

I only somewhat agree with this. Part of it is the Rd specifically, I
agree, but part of it is just the fact that it is a different syntax at
all. People who write roxygen documentation tend to think about and write
it in roxygen, I think. Any switch out to another syntax, thus introducing
two syntaxes side-by-side, is discouraged by the very fact that they are
thinking in roxygen comments.

Again, this is a "discouragement", not a disallowing. I know that people
who care deeply about writing absolutely top notch documentation, and who
also use roxygen will do the switch when called for, but the path of least
resistance, i.e. the pattern of behavior that is *encouraged* by roxygen2
is to not do that, and simply write documentation using only the supported
roxygen2 tags. I'm not saying this makes the system bad, per se. As I
pointed out, I use it in many of my packages (and it was my choice to do
so, not because I inherited code from someone who already did), but
pretending it doesn't encourage certain types of behavior doesn't seem like
the right way to go either.


>
> I agree with your sentiment that roxygen encourages writing of
> documentation for time-constrained users.
>

I do think it does that, but that was really only half of what I said, I
said it encourages time constrained users to write middling (i.e. not
great) documentation. Another person pointed out that structurally it
really encourages terseness in the explanations of parameters, which I
think is very true and have heard independently from others when talking
about it as well. This is again not a requirement, but it is a real thing.


>
> I'll add that the major problem of documentation is not fancy
> formatting but the content getting out of sync with the codebase.
> Having documentation sitting next to the code is the preferred
> antidote to doc rot, e.g. docstrings in lisp languages, Julia and
> Python, the Linux kernel-doc system, doxygen, javadoc, ...
>

I mean, it is *an *antidote to doc rot. And sure, one that is used
elsewhere. You could easily imagine one that didn't require it though.
Perhaps doc files associated with objects (including closures) could embed
a hash of the object they document, then you could see which things have
changed since the documentation was updated and look at which documentation
is still ok and which needs updating. That's just off the top of my head,
I'm sure you could make the detection much more sophisticated.

Or perhaps you could imagine two help systems, akin to --help and man for
command line tools, one of which is minimalist showing usage, etc,
generated by roxygen comments, and one of which is much more extensive, and
not tied to (what could be extremely large) comments in the same .R file as
the code.

Best,
~G


> It is true that R CMD check extensive checks help a lot as well in
> this regard though only for things that can be checked automatically.
>
> Best,
> Lionel
>
>


-- 
Gabriel Becker, PhD
Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Thu Feb  1 19:26:23 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 1 Feb 2018 10:26:23 -0800
Subject: [Rd] as.list method for by Objects
In-Reply-To: <23154.52332.796492.172488@stat.math.ethz.ch>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <02275be4-b015-0860-8733-efb2b6b17996@fredhutch.org>
 <CADwqtCO98pTE6G4xOva3pVEEA0jSMND9zepcR19B-8rZ6mhYRg@mail.gmail.com>
 <f2080a27-71e0-4f52-61cd-2c2a8bb8e8cd@fredhutch.org>
 <CAOQ5Nye8vFGjheY+QW1H5-Am6BN+V_jKGuCe8=_YbeMQyQFGkA@mail.gmail.com>
 <74406925-3fbb-67d6-5afa-2d18f0b00513@fredhutch.org>
 <CAOQ5NyegUu+9sGCuT4HZpP8vqJncPB5TckLXteS2zNSdtE9zTQ@mail.gmail.com>
 <23154.52332.796492.172488@stat.math.ethz.ch>
Message-ID: <CAFDcVCRvmKrFMuoEDBVjaKEdEc6=wbHGfJQBSDBakSNRCGc0oA@mail.gmail.com>

On Thu, Feb 1, 2018 at 12:14 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>>     on Tue, 30 Jan 2018 15:57:42 -0800 writes:
>
>     > I just meant that the minimal contract for as.list() appears to be that it
>     > returns a VECSXP. To the user, we might say that is.list() will always
>     > return TRUE.
>
> Indeed. I also agree with Herv'e that the user level
> documentation should rather mention  is.list(.) |--> TRUE  than
> VECSXP, and interestingly for the experts among us,
> the  is.list() primitive gives not only TRUE for  VECSXP  but
> also of LISTSXP (the good ole' pairlists).
>
>     > I'm not sure we can expect consistency across methods
>     > beyond that, nor is it feasible at this point to match the
>     > semantics of the methods package. It deals in "class
>     > space" while as.list() deals in "typeof() space".
>
>     > Michael
>
> Yes, and that *is* the extra complexity we have in R (inherited
> from S, I'd say)  which ideally wasn't there and of course is
> not there in much younger languages/systems such as julia.
>
> And --- by the way let me preach, for the "class space" ---
> do __never__ use
>
>       if(class(obj) == "<classname>")
>
> in your code (I see this so often, shockingly to me ...) but rather use
>
>       if(inherits(obj, "<classname>"))
>
> instead.

Second this one.  But, soon (*) the former will at least give the
correct answer when length(class(obj)) == 1 and produce an error
otherwise.  So, several of these cases will be caught at run-time in a
near future.

(*) When _R_CHECK_LENGTH_1_CONDITION_=true becomes the default
behavior - hopefully by R 3.5.0.

>
> Martin
>
>
>
>     > On Tue, Jan 30, 2018 at 3:47 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>
>     >> On 01/30/2018 02:50 PM, Michael Lawrence wrote:
>     >>
>     >>> by() does not always return a list. In Gabe's example, it returns an
>     >>> integer, thus it is coerced to a list. as.list() means that it should be a
>     >>> VECSXP, not necessarily with "list" in the class attribute.
>     >>>
>     >>
>     >> The documentation is not particularly clear about what as.list()
>     >> means for list derivatives. IMO clarifications should stick to
>     >> simple concepts and formulations like "is.list(x) is TRUE" or
>     >> "x is a list or a list derivative" rather than "x is a VECSXP".
>     >> Coercion is useful beyond the use case of implementing a .C entry
>     >> point and calling as.numeric/as.list/etc... on its arguments.
>     >>
>     >> This is why I was hoping that we could maybe discuss the possibility
>     >> of making the as.list() contract less vague than just "as.list()
>     >> must return a list or a list derivative".
>     >>
>     >> Again, I think that 2 things weight quite a lot in that discussion:
>     >> 1) as.list() returns an object of class "data.frame" on a
>     >> data.frame (strict coercion). If all what as.list() needed to
>     >> do was to return a VECSXP, then as.list.default() already does
>     >> this on a data.frame so why did someone bother adding an
>     >> as.list.data.frame method that does strict coercion?
>     >> 2) The S4 coercion system based on as() does strict coercion by
>     >> default.
>     >>
>     >> H.
>     >>
>     >>
>     >>> Michael
>     >>>
>     >>>
>     >>> On Tue, Jan 30, 2018 at 2:41 PM, Herv? Pag?s <hpages at fredhutch.org
>     >>> <mailto:hpages at fredhutch.org>> wrote:
>     >>>
>     >>> Hi Gabe,
>     >>>
>     >>> Interestingly the behavior of as.list() on by objects seem to
>     >>> depend on the object itself:
>     >>>
>     >>> > b1 <- by(1:2, 1:2, identity)
>     >>> > class(as.list(b1))
>     >>> [1] "list"
>     >>>
>     >>> > b2 <- by(warpbreaks[, 1:2], warpbreaks[,"tension"], summary)
>     >>> > class(as.list(b2))
>     >>> [1] "by"
>     >>>
>     >>> This is with R 3.4.3 and R devel (2017-12-11 r73889).
>     >>>
>     >>> H.
>     >>>
>     >>> On 01/30/2018 02:33 PM, Gabriel Becker wrote:
>     >>>
>     >>> Dario,
>     >>>
>     >>> What version of R are you using. In my mildly old 3.4.0
>     >>> installation and in the version of Revel I have lying around
>     >>> (also mildly old...)  I don't see the behavior I think you are
>     >>> describing
>     >>>
>     >>> > b = by(1:2, 1:2, identity)
>     >>>
>     >>> > class(as.list(b))
>     >>>
>     >>> [1] "list"
>     >>>
>     >>> > sessionInfo()
>     >>>
>     >>> R Under development (unstable) (2017-12-19 r73926)
>     >>>
>     >>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>     >>>
>     >>> Running under: OS X El Capitan 10.11.6
>     >>>
>     >>>
>     >>> Matrix products: default
>     >>>
>     >>> BLAS:
>     >>> /Users/beckerg4/local/Rdevel/R
>     >>> .framework/Versions/3.5/Resources/lib/libRblas.dylib
>     >>>
>     >>> LAPACK:
>     >>> /Users/beckerg4/local/Rdevel/R
>     >>> .framework/Versions/3.5/Resources/lib/libRlapack.dylib
>     >>>
>     >>>
>     >>> locale:
>     >>>
>     >>> [1]
>     >>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>     >>>
>     >>>
>     >>> attached base packages:
>     >>>
>     >>> [1] stats     graphics  grDevices utils     datasets
>     >>> methods   base
>     >>>
>     >>>
>     >>> loaded via a namespace (and not attached):
>     >>>
>     >>> [1] compiler_3.5.0
>     >>>
>     >>> >
>     >>>
>     >>>
>     >>> As for by not having a class definition, no S3 class has an
>     >>> explicit definition, so this is somewhat par for the course
>     >>> here...
>     >>>
>     >>> did I misunderstand something?
>     >>>
>     >>>
>     >>> ~G
>     >>>
>     >>> On Tue, Jan 30, 2018 at 2:24 PM, Herv? Pag?s
>     >>> <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     >>> <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>>
>     >>> wrote:
>     >>>
>     >>> I agree that it makes sense to expect as.list() to perform
>     >>> a "strict coercion" i.e. to return an object of class "list",
>     >>> *even* on a list derivative. That's what as( , "list") does
>     >>> by default:
>     >>>
>     >>> # on a data.frame object
>     >>> as(data.frame(), "list")  # object of class "list"
>     >>> # (but strangely it drops the
>     >>> names)
>     >>>
>     >>> # on a by object
>     >>> x <- by(warpbreaks[, 1:2], warpbreaks[,"tension"],
>     >>> summary)
>     >>> as(x, "list")  # object of class "list"
>     >>>
>     >>> More generally speaking as() is expected to perform "strict
>     >>> coercion" by default, unless called with 'strict=FALSE'.
>     >>>
>     >>> That's also what as.list() does on a data.frame:
>     >>>
>     >>> as.list(data.frame())  # object of class "list"
>     >>>
>     >>> FWIW as.numeric() also performs "strict coercion" on an
>     >>> integer
>     >>> vector:
>     >>>
>     >>> as.numeric(1:3)  # object of class "numeric"
>     >>>
>     >>> So an as.list.env method that does the same as as(x, "list")
>     >>> would bring a small touch of consistency in an otherwise
>     >>> quite inconsistent world of coercion methods(*).
>     >>>
>     >>> H.
>     >>>
>     >>> (*) as(data.frame(), "list", strict=FALSE) doesn't do what
>     >>> you'd
>     >>> expect (just one of many examples)
>     >>>
>     >>>
>     >>> On 01/29/2018 05:00 PM, Dario Strbenac wrote:
>     >>>
>     >>> Good day,
>     >>>
>     >>> I'd like to suggest the addition of an as.list method
>     >>> for a by
>     >>> object that actually returns a list of class "list".
>     >>> This would
>     >>> make it safer to do type-checking, because is.list also
>     >>> returns
>     >>> TRUE for a data.frame variable and using class(result)
>     >>> == "list"
>     >>> is an alternative that only returns TRUE for lists.
>     >>> It's also
>     >>> confusing initially that
>     >>>
>     >>> class(x)
>     >>>
>     >>> [1] "by"
>     >>>
>     >>> is.list(x)
>     >>>
>     >>> [1] TRUE
>     >>>
>     >>> since there's no explicit class definition for "by" and no
>     >>> mention if it has any superclasses.
>     >>>
>     >>> --------------------------------------
>     >>> Dario Strbenac
>     >>> University of Sydney
>     >>> Camperdown NSW 2050
>     >>> Australia
>
>     .............
>
>     >>> --         Gabriel Becker, PhD
>     >>> Scientist (Bioinformatics)
>     >>> Genentech Research
>     >>>
>
>     >> Herv? Pag?s
>     >>
>     >> Program in Computational Biology
>     >> Division of Public Health Sciences
>     >> Fred Hutchinson Cancer Research Center
>     >> 1100 Fairview Ave. N, M1-B514
>     >> P.O. Box 19024
>     >> Seattle, WA 98109-1024
>     >>
>     >> E-mail: hpages at fredhutch.org
>     >> Phone:  (206) 667-5791
>     >> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Feb  2 09:07:44 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Feb 2018 09:07:44 +0100
Subject: [Rd] as.list method for by Objects
In-Reply-To: <CAFDcVCRvmKrFMuoEDBVjaKEdEc6=wbHGfJQBSDBakSNRCGc0oA@mail.gmail.com>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <02275be4-b015-0860-8733-efb2b6b17996@fredhutch.org>
 <CADwqtCO98pTE6G4xOva3pVEEA0jSMND9zepcR19B-8rZ6mhYRg@mail.gmail.com>
 <f2080a27-71e0-4f52-61cd-2c2a8bb8e8cd@fredhutch.org>
 <CAOQ5Nye8vFGjheY+QW1H5-Am6BN+V_jKGuCe8=_YbeMQyQFGkA@mail.gmail.com>
 <74406925-3fbb-67d6-5afa-2d18f0b00513@fredhutch.org>
 <CAOQ5NyegUu+9sGCuT4HZpP8vqJncPB5TckLXteS2zNSdtE9zTQ@mail.gmail.com>
 <23154.52332.796492.172488@stat.math.ethz.ch>
 <CAFDcVCRvmKrFMuoEDBVjaKEdEc6=wbHGfJQBSDBakSNRCGc0oA@mail.gmail.com>
Message-ID: <23156.7248.538523.4058@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Thu, 1 Feb 2018 10:26:23 -0800 writes:

    > On Thu, Feb 1, 2018 at 12:14 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Michael Lawrence <lawrence.michael at gene.com>
    >>>>>>> on Tue, 30 Jan 2018 15:57:42 -0800 writes:
    >> 
    >> > I just meant that the minimal contract for as.list() appears to be that it
    >> > returns a VECSXP. To the user, we might say that is.list() will always
    >> > return TRUE.
    >> 
    >> Indeed. I also agree with Herv'e that the user level
    >> documentation should rather mention  is.list(.) |--> TRUE  than
    >> VECSXP, and interestingly for the experts among us,
    >> the  is.list() primitive gives not only TRUE for  VECSXP  but
    >> also of LISTSXP (the good ole' pairlists).
    >> 
    >> > I'm not sure we can expect consistency across methods
    >> > beyond that, nor is it feasible at this point to match the
    >> > semantics of the methods package. It deals in "class
    >> > space" while as.list() deals in "typeof() space".
    >> 
    >> > Michael
    >> 
    >> Yes, and that *is* the extra complexity we have in R (inherited
    >> from S, I'd say)  which ideally wasn't there and of course is
    >> not there in much younger languages/systems such as julia.
    >> 
    >> And --- by the way let me preach, for the "class space" ---
    >> do __never__ use
    >> 
    >> if(class(obj) == "<classname>")
    >> 
    >> in your code (I see this so often, shockingly to me ...) but rather use
    >> 
    >> if(inherits(obj, "<classname>"))
    >> 
    >> instead.

    > Second this one.  But, soon (*) the former will at least give the
    > correct answer when length(class(obj)) == 1 
    > and produce an error
    > otherwise.

Not quite; I think you you did not get the real danger in using
'class(.) == *':
What you say above would only be true if there were only S3 classes!
Try the following small R snippet

myDate <- setClass("myDate", contains = "Date")
## Object of class "myDate"
## [1] "2018-02-02"
(d <- myDate(Sys.Date()))
class(d) == "Date"  # is FALSE (hence of length 1)
inherits(d, "Date") # is TRUE

    > So, several of these cases will be caught at run-time in a
    > near future.

Maybe.  But all the others are  still wrong, as I show above.
Martin

    > (*) When _R_CHECK_LENGTH_1_CONDITION_=true becomes the default
    > behavior - hopefully by R 3.5.0.

    >> 
    >> Martin


From jorismeys at gmail.com  Fri Feb  2 10:23:36 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 2 Feb 2018 10:23:36 +0100
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <FCD9A33C859ACC469587CB09DD5C6C7132024B84@GBLONXMB13.corp.amvescap.net>
 <CAPtbhHzGAT9LKC-kkwWQQBdBsMdsirq=0UeZRGb5Ack5rPPX9w@mail.gmail.com>
 <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
 <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>
 <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
Message-ID: <CAO1zAVYenMBUoZxvYH7yJTv9oh5xi5=3i-bRAmgM+CoUQmf_Jg@mail.gmail.com>

On Thu, Feb 1, 2018 at 6:20 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

>
> Or perhaps you could imagine two help systems, akin to --help and man for
> command line tools, one of which is minimalist showing usage, etc,
> generated by roxygen comments, and one of which is much more extensive, and
> not tied to (what could be extremely large) comments in the same .R file as
> the code.
>

That sounds like basic help files and a few vignettes. I would argue we
have the tools to do this if necessary. One can even create topics in the
help file system (by using either Rd manually or through roxygen) that
aren't necessarily tied to a function. And each time I come to the same
conclusion: we have multiple tools to do this. We just need package
developers to care enough to do it.

-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb  2 13:17:18 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 2 Feb 2018 07:17:18 -0500
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <FCD9A33C859ACC469587CB09DD5C6C7132024B84@GBLONXMB13.corp.amvescap.net>
 <CAPtbhHzGAT9LKC-kkwWQQBdBsMdsirq=0UeZRGb5Ack5rPPX9w@mail.gmail.com>
 <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
 <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>
 <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
Message-ID: <41bfcd9a-9a86-eec5-cb2d-c8d4cd86fe23@gmail.com>

On 01/02/2018 12:20 PM, Gabriel Becker wrote:
[ lots deleted...]

> Or perhaps you could imagine two help systems, akin to --help and man for
> command line tools, one of which is minimalist showing usage, etc,
> generated by roxygen comments, and one of which is much more extensive, and
> not tied to (what could be extremely large) comments in the same .R file as
> the code.

I think the input method and output form should be orthogonal.  Several 
front ends already implement minimalist help (e.g. RStudio displays the 
usage and description sections from the help page).

I'd rather have the help info coming from a separate file; other people 
apparently prefer to put it in the .R file.  I think both methods should 
be supported.  It makes sense to me to get both types of info from one 
place, but the author should be able to choose where that is.

Duncan Murdoch

P.S.  I've been playing around with Georgi Boshnakov's Rdpack package, 
putting together an RStudio plug-in to make usage updates trivial.  If 
anyone wants to try it out it's on my Github page for now 
(dmurdoch/Rdpack), but once it's usable, Georgi has said he will merge 
it back into his.


From lawrence.michael at gene.com  Thu Feb  1 19:14:04 2018
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 1 Feb 2018 10:14:04 -0800
Subject: [Rd] Best practices in developing package: From a single file
In-Reply-To: <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
References: <CAPtbhHwLXvdCX+1PJvEAyjWtcaVf=k4kL2fgXNhxLqfBhoJg-Q@mail.gmail.com>
 <1517329742.15543.15.camel@braverock.com>
 <aef83954-b118-6f8f-6d4f-d2a9758121cc@gmail.com>
 <CAO1zAVaHnOthsFc9DGbC2+otAhHJ7qRi4hUZrqk67NFwpr6osA@mail.gmail.com>
 <2d6d82a8-0dc3-0fbe-5b25-8c86c74a1aad@gmail.com>
 <CAO1zAVZGG33AUWUQ0Sbjaaqf2FSZ3JNsxzvdNHn9sBcYYDL7LQ@mail.gmail.com>
 <FCD9A33C859ACC469587CB09DD5C6C7132024B84@GBLONXMB13.corp.amvescap.net>
 <CAPtbhHzGAT9LKC-kkwWQQBdBsMdsirq=0UeZRGb5Ack5rPPX9w@mail.gmail.com>
 <CADwqtCO3Z7vp2TNJLBXpdwnqYyzH4vEzSeXieOSSjsyebojnhA@mail.gmail.com>
 <3A690EC2-7022-4C89-B607-2A9E84EA5862@rstudio.com>
 <CADwqtCNrMRY=TJnP7cW59+3z5VTJkVFkSYAf0may1qTk2E0Zpg@mail.gmail.com>
Message-ID: <CAOQ5NyccmP4NgBtycAK4RFmbNAPMMoAGgbXaL4vYQ3hSLj--xw@mail.gmail.com>

On Thu, Feb 1, 2018 at 9:20 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> On Thu, Feb 1, 2018 at 5:24 AM, Lionel Henry <lionel at rstudio.com> wrote:
>
> > On 31 janv. 2018, at 09:08, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> >
> > > it *actively discourages* the bits it doesn't directly support.
> >
> > It may be discouraging to include Rd syntax in roxygen docs but only
> > because the LaTeX-like syntax of Rd is burdensome, not because of
> > roxygen. It is still handy to have inlined Rd as a backup and we do
> > use it for the cases where we need finer grained control.
> >
>
> I only somewhat agree with this. Part of it is the Rd specifically, I
> agree, but part of it is just the fact that it is a different syntax at
> all. People who write roxygen documentation tend to think about and write
> it in roxygen, I think. Any switch out to another syntax, thus introducing
> two syntaxes side-by-side, is discouraged by the very fact that they are
> thinking in roxygen comments.
>
> Again, this is a "discouragement", not a disallowing. I know that people
> who care deeply about writing absolutely top notch documentation, and who
> also use roxygen will do the switch when called for, but the path of least
> resistance, i.e. the pattern of behavior that is *encouraged* by roxygen2
> is to not do that, and simply write documentation using only the supported
> roxygen2 tags. I'm not saying this makes the system bad, per se. As I
> pointed out, I use it in many of my packages (and it was my choice to do
> so, not because I inherited code from someone who already did), but
> pretending it doesn't encourage certain types of behavior doesn't seem like
> the right way to go either.
>
>
> >
> > I agree with your sentiment that roxygen encourages writing of
> > documentation for time-constrained users.
> >
>
> I do think it does that, but that was really only half of what I said, I
> said it encourages time constrained users to write middling (i.e. not
> great) documentation. Another person pointed out that structurally it
> really encourages terseness in the explanations of parameters, which I
> think is very true and have heard independently from others when talking
> about it as well. This is again not a requirement, but it is a real thing.
>
>
> >
> > I'll add that the major problem of documentation is not fancy
> > formatting but the content getting out of sync with the codebase.
> > Having documentation sitting next to the code is the preferred
> > antidote to doc rot, e.g. docstrings in lisp languages, Julia and
> > Python, the Linux kernel-doc system, doxygen, javadoc, ...
> >
>
> I mean, it is *an *antidote to doc rot. And sure, one that is used
> elsewhere. You could easily imagine one that didn't require it though.
> Perhaps doc files associated with objects (including closures) could embed
> a hash of the object they document, then you could see which things have
> changed since the documentation was updated and look at which documentation
> is still ok and which needs updating. That's just off the top of my head,
> I'm sure you could make the detection much more sophisticated.
>
> Or perhaps you could imagine two help systems, akin to --help and man for
> command line tools, one of which is minimalist showing usage, etc,
> generated by roxygen comments, and one of which is much more extensive, and
> not tied to (what could be extremely large) comments in the same .R file as
> the code.
>
>
This is basically what I meant by the template-based approach. Have the
details in the template, and the vitals in the doc comment block. Combine
the two and view the docs in different ways, dynamically.


> Best,
> ~G
>
>
> > It is true that R CMD check extensive checks help a lot as well in
> > this regard though only for things that can be checked automatically.
> >
> > Best,
> > Lionel
> >
> >
>
>
> --
> Gabriel Becker, PhD
> Scientist (Bioinformatics)
> Genentech Research
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeshyb at dtu.dk  Fri Feb  2 15:22:37 2018
From: jeshyb at dtu.dk (Jesper Hybel Pedersen)
Date: Fri, 2 Feb 2018 14:22:37 +0000
Subject: [Rd] R-gui sessions end when executing C-code
Message-ID: <8dd5d3d5b5c34524a1eb42f7e4a4264b@dtu.dk>

Hi

I'm trying to develop some C code to find the fixpoint of a contraction mapping, the code compiles and gives the right results when executed in R.
However R-gui session is frequently terminated. I'm suspecting some access violation error due to the exception code 0xc0000005
In the error report windows 10 gives me.

It is the first time I'm writing any C-code so I'm guessing I have done something really stupid. I have been trying to debug the code for a couple of days now,
But I simply can't figure out what generates the problem. Could it be something particular to my windows set up and security stuff?


I'm in the process of reading Writing R Extensions and Hadley Wickham's Advanced R but might have missed something.

The windows error report:

Faulting application name: Rgui.exe, version: 3.33.6774.0, time stamp: 0x58bd6d26
Faulting module name: R.dll, version: 3.33.6774.0, time stamp: 0x58bd6d0b
Exception code: 0xc0000005
Fault offset: 0x000000000010b273
Faulting process id: 0x1d14
Faulting application start time: 0x01d39aede45c96e9
Faulting application path: C:\Program Files\R\R-3.3.3\bin\x64\Rgui.exe
Faulting module path: C:\Program Files\R\R-3.3.3\bin\x64\R.dll
Report Id: c78d7c52-72c5-40f3-a3cc-927323d2af07
Faulting package full name:
Faulting package-relative application ID:


####### How I call the C-function in R

dyn.load("C://users//jeshyb//desktop//myC//lce_fixpoint_cc.dll")


N = 10
H = 3
v <- rnorm(N*H)
mu <- 0.1
psi <- matrix(c(1,0,0.5,0.5,0,1),nrow=2)
K <- dim(psi)[1]
p <- rep(1/H,N*H)
error <- 1e-10


f<-function(p,v,mu,psi,N,H,K)
                           {
                                                      .Call("lce_fixpoint_cc",p, v,  mu,  psi,  as.integer(N), as.integer(H),  as.integer(K),error)
                           }


for (i in 1:100)
                           {
                                                      v <- rnorm(N*H)
                                                      p <- rep(1/H,N*H)
                                                      a<-f(p,v,mu,psi,N,H,K)
                           }


a<-f(p,v,mu,psi,N,H,K)
plot(a)



######## The C- function



#include <R.h>
#include <Rinternals.h>


SEXP lce_fixpoint_cc(SEXP q, SEXP v, SEXP mu, SEXP psi, SEXP N,SEXP H, SEXP K, SEXP err)
{

                           int n_prot = 0;
                           /* Make ready integer and double constants */
                           PROTECT(N); n_prot++;
                           PROTECT(H); n_prot++;
                           PROTECT(K); n_prot++;
                           int N_c = asInteger(N);
                           int H_c = asInteger(H);
                           int K_c = asInteger(K);

                           double mu_c = asReal(mu);
                           double mu2_c = 1.0 - mu_c;
                           double error_c = asReal(err);
                           double lowest_double = 1e-15;
                           double tmp_c;
                           double denom;
                           double error_temp;
                           double error_i_c;


                           /* Make ready vector froms input */
                           PROTECT(q); n_prot++;
                           PROTECT(v); n_prot++;
                           PROTECT(psi); n_prot++;
                           double *v_c; v_c = REAL(v);
                           double *psi_c; psi_c = REAL(psi);

                           /* Initialize new vectors not given as input */
                           SEXP q_copy = PROTECT(duplicate(q)); n_prot++;
                           double *q_c; q_c = REAL(q_copy);

                           SEXP q_new = PROTECT(allocVector(REALSXP,length(q))); n_prot++;
                           double *q_new_c; q_new_c = REAL(q_new);

                           SEXP eta = PROTECT(allocVector(REALSXP,H_c)); n_prot++;
                           double *eta_c; eta_c = REAL(eta);

                           SEXP exp_eta = PROTECT(allocVector(REALSXP,H_c)); n_prot++;
                           double *exp_eta_c; exp_eta_c = REAL(exp_eta);

                           SEXP psi_ln_psiq = PROTECT(allocVector(REALSXP,H_c)); n_prot++;
                           double *psi_ln_psiq_c; psi_ln_psiq_c = REAL(psi_ln_psiq);

                           int not_converged;
                           int maxIter = 10000;
                           int iter;
                           int start_c;

                           /* loop indeces */
                           int i;
                           int j;
                           int k;

                           /* loop over observational units to find choice probabilities for i=1,...,N */
                           for (i=0;i<N_c;i++)
                           {

                                                      start_c = i * H_c;
                                                      not_converged = 1;
                                                      iter = 0;

                                                      while(iter < maxIter && not_converged)
                                                      {
                                                                                                                                        /* make v_ij + (1-mu)*ln(q_ij) */
                                                                                  for (j=0; j<H_c; j++)
                                                                                  {
                                                                                                             eta_c[start_c + j] = v_c[start_c + j] + mu2_c * log(q_c[start_c + j]);
                                                                                                             psi_ln_psiq_c[j] = 0.0;
                                                                                  }

                                                                                  /* Make psi_ln_psiq_c vector for individual i */
                                                                                  for (k=0;k<K_c;k++)
                                                                                  {
                                                                                                             tmp_c = 0.0;

                                                                                                             /* Calculate row k of psi %*% q */
                                                                                                             for (j=0;j<H_c;j++)
                                                                                                             {
                                                                                                                                        tmp_c += psi_c[k + j*K_c] * q_c[start_c +j];
                                                                                                             }

                                                                                                                                        tmp_c = mu2_c * log(tmp_c);

                                                                                                             for (j=0;j<H_c;j++)
                                                                                                             {
                                                                                                                                        psi_ln_psiq_c[j] += psi_c[k + j*K_c] * tmp_c;
                                                                                                             }
                                                                                  }

                                                                                  denom = 0.0;
                                                                                  for (j=0;j<H_c;j++)
                                                                                  {
                                                                                                             exp_eta_c[start_c + j] = exp( eta_c[start_c + j] - psi_ln_psiq_c[j] ) + lowest_double;
                                                                                                             denom += exp_eta_c[start_c + j];
                                                                                  }

                                                                                  error_i_c = 0.0;
                                                                                  error_temp = 0.0;

                                                                                  /* calculate error and update choice prob */
                                                                                  for (j=0;j<H_c;j++)
                                                                                  {
                                                                                                             q_new_c[start_c + j] = exp_eta_c[start_c + j]/denom;
                                                                                                             error_temp = fabs(q_new_c[start_c + j] - q_c[start_c + j]);
                                                                                                             if (error_temp>error_i_c)
                                                                                                                                        {
                                                                                                                                                                   error_i_c = error_temp;
                                                                                                                                        }
                                                                                                             q_c[start_c + j] = q_new_c[start_c + j];
                                                                                  }

                                                                                  not_converged = error_i_c > error_c;
                                                                                  iter++;
                                                      } /* End while loop for individual i to solve for q_i */


                           } /* End loop over individuals */


                           UNPROTECT(n_prot);
                           return(q_new);
}



Best regards
Jesper Hybel


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Feb  2 21:28:15 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 2 Feb 2018 12:28:15 -0800
Subject: [Rd] R-gui sessions end when executing C-code
In-Reply-To: <8dd5d3d5b5c34524a1eb42f7e4a4264b@dtu.dk>
References: <8dd5d3d5b5c34524a1eb42f7e4a4264b@dtu.dk>
Message-ID: <CAF8bMcYM3sri5d4grNTV_tknYhjuPhfKz4JEwt4RGcVA+EudyA@mail.gmail.com>

   SEXP eta = PROTECT(allocVector(REALSXP,H_c)); n_prot++;
   double *eta_c; eta_c = REAL(eta);
   for (i=0;i<N_c;i++)
   {
      start_c = i * H_c;
      for (j=0; j<H_c; j++)
      {
          eta_c[start_c + j] = ...

It looks you expect to be able to write into the N_c*H_c element
of eta, but you only allocated H_c elements for it.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 2, 2018 at 6:22 AM, Jesper Hybel Pedersen <jeshyb at dtu.dk> wrote:

> Hi
>
> I'm trying to develop some C code to find the fixpoint of a contraction
> mapping, the code compiles and gives the right results when executed in R.
> However R-gui session is frequently terminated. I'm suspecting some access
> violation error due to the exception code 0xc0000005
> In the error report windows 10 gives me.
>
> It is the first time I'm writing any C-code so I'm guessing I have done
> something really stupid. I have been trying to debug the code for a couple
> of days now,
> But I simply can't figure out what generates the problem. Could it be
> something particular to my windows set up and security stuff?
>
>
> I'm in the process of reading Writing R Extensions and Hadley Wickham's
> Advanced R but might have missed something.
>
> The windows error report:
>
> Faulting application name: Rgui.exe, version: 3.33.6774.0, time stamp:
> 0x58bd6d26
> Faulting module name: R.dll, version: 3.33.6774.0, time stamp: 0x58bd6d0b
> Exception code: 0xc0000005
> Fault offset: 0x000000000010b273
> Faulting process id: 0x1d14
> Faulting application start time: 0x01d39aede45c96e9
> Faulting application path: C:\Program Files\R\R-3.3.3\bin\x64\Rgui.exe
> Faulting module path: C:\Program Files\R\R-3.3.3\bin\x64\R.dll
> Report Id: c78d7c52-72c5-40f3-a3cc-927323d2af07
> Faulting package full name:
> Faulting package-relative application ID:
>
>
> ####### How I call the C-function in R
>
> dyn.load("C://users//jeshyb//desktop//myC//lce_fixpoint_cc.dll")
>
>
> N = 10
> H = 3
> v <- rnorm(N*H)
> mu <- 0.1
> psi <- matrix(c(1,0,0.5,0.5,0,1),nrow=2)
> K <- dim(psi)[1]
> p <- rep(1/H,N*H)
> error <- 1e-10
>
>
> f<-function(p,v,mu,psi,N,H,K)
>                            {
>
> .Call("lce_fixpoint_cc",p, v,  mu,  psi,  as.integer(N), as.integer(H),
> as.integer(K),error)
>                            }
>
>
> for (i in 1:100)
>                            {
>                                                       v <- rnorm(N*H)
>                                                       p <- rep(1/H,N*H)
>
> a<-f(p,v,mu,psi,N,H,K)
>                            }
>
>
> a<-f(p,v,mu,psi,N,H,K)
> plot(a)
>
>
>
> ######## The C- function
>
>
>
> #include <R.h>
> #include <Rinternals.h>
>
>
> SEXP lce_fixpoint_cc(SEXP q, SEXP v, SEXP mu, SEXP psi, SEXP N,SEXP H,
> SEXP K, SEXP err)
> {
>
>                            int n_prot = 0;
>                            /* Make ready integer and double constants */
>                            PROTECT(N); n_prot++;
>                            PROTECT(H); n_prot++;
>                            PROTECT(K); n_prot++;
>                            int N_c = asInteger(N);
>                            int H_c = asInteger(H);
>                            int K_c = asInteger(K);
>
>                            double mu_c = asReal(mu);
>                            double mu2_c = 1.0 - mu_c;
>                            double error_c = asReal(err);
>                            double lowest_double = 1e-15;
>                            double tmp_c;
>                            double denom;
>                            double error_temp;
>                            double error_i_c;
>
>
>                            /* Make ready vector froms input */
>                            PROTECT(q); n_prot++;
>                            PROTECT(v); n_prot++;
>                            PROTECT(psi); n_prot++;
>                            double *v_c; v_c = REAL(v);
>                            double *psi_c; psi_c = REAL(psi);
>
>                            /* Initialize new vectors not given as input */
>                            SEXP q_copy = PROTECT(duplicate(q)); n_prot++;
>                            double *q_c; q_c = REAL(q_copy);
>
>                            SEXP q_new = PROTECT(allocVector(REALSXP,length(q)));
> n_prot++;
>                            double *q_new_c; q_new_c = REAL(q_new);
>
>                            SEXP eta = PROTECT(allocVector(REALSXP,H_c));
> n_prot++;
>                            double *eta_c; eta_c = REAL(eta);
>
>                            SEXP exp_eta = PROTECT(allocVector(REALSXP,H_c));
> n_prot++;
>                            double *exp_eta_c; exp_eta_c = REAL(exp_eta);
>
>                            SEXP psi_ln_psiq =
> PROTECT(allocVector(REALSXP,H_c)); n_prot++;
>                            double *psi_ln_psiq_c; psi_ln_psiq_c =
> REAL(psi_ln_psiq);
>
>                            int not_converged;
>                            int maxIter = 10000;
>                            int iter;
>                            int start_c;
>
>                            /* loop indeces */
>                            int i;
>                            int j;
>                            int k;
>
>                            /* loop over observational units to find choice
> probabilities for i=1,...,N */
>                            for (i=0;i<N_c;i++)
>                            {
>
>                                                       start_c = i * H_c;
>                                                       not_converged = 1;
>                                                       iter = 0;
>
>                                                       while(iter < maxIter
> && not_converged)
>                                                       {
>
>                                                               /* make v_ij
> + (1-mu)*ln(q_ij) */
>
>         for (j=0; j<H_c; j++)
>
>         {
>
>                                    eta_c[start_c + j] = v_c[start_c + j] +
> mu2_c * log(q_c[start_c + j]);
>
>                                    psi_ln_psiq_c[j] = 0.0;
>
>         }
>
>
>         /* Make psi_ln_psiq_c vector for individual i */
>
>         for (k=0;k<K_c;k++)
>
>         {
>
>                                    tmp_c = 0.0;
>
>
>                                    /* Calculate row k of psi %*% q */
>
>                                    for (j=0;j<H_c;j++)
>
>                                    {
>
>                                                               tmp_c +=
> psi_c[k + j*K_c] * q_c[start_c +j];
>
>                                    }
>
>
>                                                               tmp_c = mu2_c
> * log(tmp_c);
>
>
>                                    for (j=0;j<H_c;j++)
>
>                                    {
>
>
> psi_ln_psiq_c[j] += psi_c[k + j*K_c] * tmp_c;
>
>                                    }
>
>         }
>
>
>         denom = 0.0;
>
>         for (j=0;j<H_c;j++)
>
>         {
>
>                                    exp_eta_c[start_c + j] = exp(
> eta_c[start_c + j] - psi_ln_psiq_c[j] ) + lowest_double;
>
>                                    denom += exp_eta_c[start_c + j];
>
>         }
>
>
>         error_i_c = 0.0;
>
>         error_temp = 0.0;
>
>
>         /* calculate error and update choice prob */
>
>         for (j=0;j<H_c;j++)
>
>         {
>
>                                    q_new_c[start_c + j] = exp_eta_c[start_c
> + j]/denom;
>
>                                    error_temp = fabs(q_new_c[start_c + j] -
> q_c[start_c + j]);
>
>                                    if (error_temp>error_i_c)
>
>                                                               {
>
>
>              error_i_c = error_temp;
>
>                                                               }
>
>                                    q_c[start_c + j] = q_new_c[start_c + j];
>
>         }
>
>
>         not_converged = error_i_c > error_c;
>
>         iter++;
>                                                       } /* End while loop
> for individual i to solve for q_i */
>
>
>                            } /* End loop over individuals */
>
>
>                            UNPROTECT(n_prot);
>                            return(q_new);
> }
>
>
>
> Best regards
> Jesper Hybel
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jtelleria.rproject at gmail.com  Fri Feb  2 22:17:20 2018
From: jtelleria.rproject at gmail.com (Juan Telleria Ruiz de Aguirre)
Date: Fri, 2 Feb 2018 22:17:20 +0100
Subject: [Rd] Why R should never move to git
In-Reply-To: <CAPtbhHxZ64faxmbeNpWy1U_Ra_72RhsnhbrSCt=jRnZyL47p8g@mail.gmail.com>
References: <786e446c35374edc8d633f1f65619460@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczOTWqKEqud_yDcO0ybPJwDK=2ydY6SDN5zPF+8_7C9qmg@mail.gmail.com>
 <CAPtbhHxZ64faxmbeNpWy1U_Ra_72RhsnhbrSCt=jRnZyL47p8g@mail.gmail.com>
Message-ID: <CAJXDcw3K-hWPi+7=Fv+Q0ywPVPyT9rqycYm=2Qq0qR_Vw4P6RQ@mail.gmail.com>

Yes, indeed Gitlab GUI Core Code is Open Source (Libre / Community
Edition): https://gitlab.com/gitlab-org/gitlab-ce

> But his instructions required command-line git, and my main claim is that Github is not good enough to do the kinds of things I want to do and R Core would need to do.
>
> My other claim is that git is too hard to use.

I'm sure that Git Command Line Recipe Documentation can solve this
issue, Gitlab, in particular, has a wiki in which this kind of issues
could be documented. Also Git cheat-sheets might prove useful. In
addition, any feature request could be done in Gitlab Issue Section
(See above), or if that does not still does not convince, other
options could be considered, such as Bitbucket
(https://bitbucket.org/), etc.

In addition, the Git Repository:
* Could be self-hosted in the University Servers (Just as SVN actually
is nowadays).
* Be accessed either by the Command Line or the Graphical User
Interface (As users prefer).

The main reason motivating the move to the GIT Repository, as said
before, is that it would to allow individual users or companies from
the R Consortium to do pull requests based on issues for improving
base R code.

Indeed, in some years from now I would like to help to improve base R
myself, maybe re-writing some parts of the code in C++, fixing bugs,
or who knows :)

Kind regards,
Juan Telleria


From jtelleria.rproject at gmail.com  Sat Feb  3 00:36:38 2018
From: jtelleria.rproject at gmail.com (Juan Telleria Ruiz de Aguirre)
Date: Sat, 3 Feb 2018 00:36:38 +0100
Subject: [Rd] Why R should never move to git
In-Reply-To: <CAJXDcw3K-hWPi+7=Fv+Q0ywPVPyT9rqycYm=2Qq0qR_Vw4P6RQ@mail.gmail.com>
References: <786e446c35374edc8d633f1f65619460@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczOTWqKEqud_yDcO0ybPJwDK=2ydY6SDN5zPF+8_7C9qmg@mail.gmail.com>
 <CAPtbhHxZ64faxmbeNpWy1U_Ra_72RhsnhbrSCt=jRnZyL47p8g@mail.gmail.com>
 <CAJXDcw3K-hWPi+7=Fv+Q0ywPVPyT9rqycYm=2Qq0qR_Vw4P6RQ@mail.gmail.com>
Message-ID: <CAJXDcw28PUv+6tmTPYaL3pn1igerbyogZc9S5oYE+902bA-39w@mail.gmail.com>

> So I created a branch within my fork, and committed the change there. But Github provides no way to create a pull request that only includes the new stuff!
> Every attempt I made would have included everything from both bug fixes.

I have been doing some tests, and I think that this issue can be
easily addressed with Bitbucket GUI (https://bitbucket.org/product),
which is free for Open Source Projects
(https://www.atlassian.com/software/views/open-source-license-request)
and seems easy to use (So it follows the K.I.S.S. principle).

Just another alternative instead of Gitlab for self-hosting... no worries.

Best,
Juan


From suharto_anggono at yahoo.com  Sat Feb  3 17:07:54 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 3 Feb 2018 16:07:54 +0000 (UTC)
Subject: [Rd] as.list method for by Objects
References: <875408384.2580847.1517674074115.ref@mail.yahoo.com>
Message-ID: <875408384.2580847.1517674074115@mail.yahoo.com>

Maybe behavior of 'as.list' in R is not inherited from S?
- From https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=78 , in "the prototype" (S), 'as.list' on a data frame gave a list, not a data frame as given by the default 'as.list' in R. That led to introduction of 'as.list.data.frame'.
- From https://biostat-lists.wustl.edu/sympa/arc/s-news/1999-07/msg00198.html , with
s <- c("a"=1, "b"=2) ,
as.list(z) doesn't have names in S-PLUS 3.4, different from in R. In S-PLUS 5.1, as.list(z) has names, like in R.

In "Details" section, the documentation, list.Rd, mentions this about 'as.list'.
Attributes may be dropped unless the argument already is a list or expression.? (This is inconsistent with functions such as as.character which always drop attributes, and is for efficiency since lists can be expensive to copy.)

On efficiency issue, shallow copying has been introduced. So, can the behavior of the default method of 'as.list' be reconsidered?

Related: The default mehod of 'as.vector' with mode="list" behaves like the default method of 'as.list'. As a consequence, 'is.vector' with mode="list" on its result may return FALSE. I have raised the issue in https://stat.ethz.ch/pipermail/r-devel/2013-May/066671.html .

------------------------
>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>? ?? on Tue, 30 Jan 2018 15:57:42 -0800 writes:

? ? > I just meant that the minimal contract for as.list() appears to be that it
? ? > returns a VECSXP. To the user, we might say that is.list() will always
? ? > return TRUE.
? ? 
Indeed. I also agree with Herv'e that the user level
documentation should rather mention? is.list(.) |--> TRUE? than
VECSXP, and interestingly for the experts among us,
the? is.list() primitive gives not only TRUE for? VECSXP? but
also of LISTSXP (the good ole' pairlists).

? ? > I'm not sure we can expect consistency across methods
? ? > beyond that, nor is it feasible at this point to match the
? ? > semantics of the methods package. It deals in "class
? ? > space" while as.list() deals in "typeof() space".

? ? > Michael

Yes, and that *is* the extra complexity we have in R (inherited
from S, I'd say)? which ideally wasn't there and of course is
not there in much younger languages/systems such as julia.

And --- by the way let me preach, for the "class space" ---
do __never__ use

? ? ? if(class(obj) == "<classname>")

in your code (I see this so often, shockingly to me ...) but rather use

? ? ? if(inherits(obj, "<classname>"))

instead.

Martin



? ? > On Tue, Jan 30, 2018 at 3:47 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

? ? >> On 01/30/2018 02:50 PM, Michael Lawrence wrote:
? ? >> 
? ? >>> by() does not always return a list. In Gabe's example, it returns an
? ? >>> integer, thus it is coerced to a list. as.list() means that it should be a
? ? >>> VECSXP, not necessarily with "list" in the class attribute.
? ? >>> 
? ? >> 
? ? >> The documentation is not particularly clear about what as.list()
? ? >> means for list derivatives. IMO clarifications should stick to
? ? >> simple concepts and formulations like "is.list(x) is TRUE" or
? ? >> "x is a list or a list derivative" rather than "x is a VECSXP".
? ? >> Coercion is useful beyond the use case of implementing a .C entry
? ? >> point and calling as.numeric/as.list/etc... on its arguments.
? ? >> 
? ? >> This is why I was hoping that we could maybe discuss the possibility
? ? >> of making the as.list() contract less vague than just "as.list()
? ? >> must return a list or a list derivative".
? ? >> 
? ? >> Again, I think that 2 things weight quite a lot in that discussion:
? ? >> 1) as.list() returns an object of class "data.frame" on a
? ? >> data.frame (strict coercion). If all what as.list() needed to
? ? >> do was to return a VECSXP, then as.list.default() already does
? ? >> this on a data.frame so why did someone bother adding an
? ? >> as.list.data.frame method that does strict coercion?
? ? >> 2) The S4 coercion system based on as() does strict coercion by
? ? >> default.
? ? >> 
? ? >> H.
? ? >> 
? ? >> 
? ? >>> Michael
? ? >>> 
? ? >>> 
? ? >>> On Tue, Jan 30, 2018 at 2:41 PM, Herv? Pag?s <hpages at fredhutch.org
? ? >>> <mailto:hpages at fredhutch.org>> wrote:
? ? >>> 
? ? >>> Hi Gabe,
? ? >>> 
? ? >>> Interestingly the behavior of as.list() on by objects seem to
? ? >>> depend on the object itself:
? ? >>> 
? ? >>> > b1 <- by(1:2, 1:2, identity)
? ? >>> > class(as.list(b1))
? ? >>> [1] "list"
? ? >>> 
? ? >>> > b2 <- by(warpbreaks[, 1:2], warpbreaks[,"tension"], summary)
? ? >>> > class(as.list(b2))
? ? >>> [1] "by"
? ? >>> 
? ? >>> This is with R 3.4.3 and R devel (2017-12-11 r73889).
? ? >>> 
? ? >>> H.
? ? >>> 
? ? >>> On 01/30/2018 02:33 PM, Gabriel Becker wrote:
? ? >>> 
? ? >>> Dario,
? ? >>> 
? ? >>> What version of R are you using. In my mildly old 3.4.0
? ? >>> installation and in the version of Revel I have lying around
? ? >>> (also mildly old...)? I don't see the behavior I think you are
? ? >>> describing
? ? >>> 
? ? >>> > b = by(1:2, 1:2, identity)
? ? >>> 
? ? >>> > class(as.list(b))
? ? >>> 
? ? >>> [1] "list"
? ? >>> 
? ? >>> > sessionInfo()
? ? >>> 
? ? >>> R Under development (unstable) (2017-12-19 r73926)
? ? >>> 
? ? >>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
? ? >>> 
? ? >>> Running under: OS X El Capitan 10.11.6
? ? >>> 
? ? >>> 
? ? >>> Matrix products: default
? ? >>> 
? ? >>> BLAS:
? ? >>> /Users/beckerg4/local/Rdevel/R
? ? >>> .framework/Versions/3.5/Resources/lib/libRblas.dylib
? ? >>> 
? ? >>> LAPACK:
? ? >>> /Users/beckerg4/local/Rdevel/R
? ? >>> .framework/Versions/3.5/Resources/lib/libRlapack.dylib
? ? >>> 
? ? >>> 
? ? >>> locale:
? ? >>> 
? ? >>> [1]
? ? >>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
? ? >>> 
? ? >>> 
? ? >>> attached base packages:
? ? >>> 
? ? >>> [1] stats? ?? graphics? grDevices utils? ?? datasets
? ? >>> methods?? base
? ? >>> 
? ? >>> 
? ? >>> loaded via a namespace (and not attached):
? ? >>> 
? ? >>> [1] compiler_3.5.0
? ? >>> 
? ? >>> >
? ? >>> 
? ? >>> 
? ? >>> As for by not having a class definition, no S3 class has an
? ? >>> explicit definition, so this is somewhat par for the course
? ? >>> here...
? ? >>> 
? ? >>> did I misunderstand something?
? ? >>> 
? ? >>> 
? ? >>> ~G
? ? >>> 
? ? >>> On Tue, Jan 30, 2018 at 2:24 PM, Herv? Pag?s
? ? >>> <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
? ? >>> <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>>
? ? >>> wrote:
? ? >>> 
? ? >>> I agree that it makes sense to expect as.list() to perform
? ? >>> a "strict coercion" i.e. to return an object of class "list",
? ? >>> *even* on a list derivative. That's what as( , "list") does
? ? >>> by default:
? ? >>> 
? ? >>> # on a data.frame object
? ? >>> as(data.frame(), "list")? # object of class "list"
? ? >>> # (but strangely it drops the
? ? >>> names)
? ? >>> 
? ? >>> # on a by object
? ? >>> x <- by(warpbreaks[, 1:2], warpbreaks[,"tension"],
? ? >>> summary)
? ? >>> as(x, "list")? # object of class "list"
? ? >>> 
? ? >>> More generally speaking as() is expected to perform "strict
? ? >>> coercion" by default, unless called with 'strict=FALSE'.
? ? >>> 
? ? >>> That's also what as.list() does on a data.frame:
? ? >>> 
? ? >>> as.list(data.frame())? # object of class "list"
? ? >>> 
? ? >>> FWIW as.numeric() also performs "strict coercion" on an
? ? >>> integer
? ? >>> vector:
? ? >>> 
? ? >>> as.numeric(1:3)? # object of class "numeric"
? ? >>> 
? ? >>> So an as.list.env method that does the same as as(x, "list")
? ? >>> would bring a small touch of consistency in an otherwise
? ? >>> quite inconsistent world of coercion methods(*).
? ? >>> 
? ? >>> H.
? ? >>> 
? ? >>> (*) as(data.frame(), "list", strict=FALSE) doesn't do what
? ? >>> you'd
? ? >>> expect (just one of many examples)
? ? >>> 
? ? >>> 
? ? >>> On 01/29/2018 05:00 PM, Dario Strbenac wrote:
? ? >>> 
? ? >>> Good day,
? ? >>> 
? ? >>> I'd like to suggest the addition of an as.list method
? ? >>> for a by
? ? >>> object that actually returns a list of class "list".
? ? >>> This would
? ? >>> make it safer to do type-checking, because is.list also
? ? >>> returns
? ? >>> TRUE for a data.frame variable and using class(result)
? ? >>> == "list"
? ? >>> is an alternative that only returns TRUE for lists.
? ? >>> It's also
? ? >>> confusing initially that
? ? >>> 
? ? >>> class(x)
? ? >>> 
? ? >>> [1] "by"
? ? >>> 
? ? >>> is.list(x)
? ? >>> 
? ? >>> [1] TRUE
? ? >>> 
? ? >>> since there's no explicit class definition for "by" and no
? ? >>> mention if it has any superclasses.
? ? >>> 
? ? >>> --------------------------------------
? ? >>> Dario Strbenac
? ? >>> University of Sydney
? ? >>> Camperdown NSW 2050
? ? >>> Australia

? ? .............

? ? >>> --? ? ? ?? Gabriel Becker, PhD
? ? >>> Scientist (Bioinformatics)
? ? >>> Genentech Research
? ? >>> 

? ? >> Herv? Pag?s
? ? >> 
? ? >> Program in Computational Biology
? ? >> Division of Public Health Sciences
? ? >> Fred Hutchinson Cancer Research Center
? ? >> 1100 Fairview Ave. N, M1-B514
? ? >> P.O. Box 19024
? ? >> Seattle, WA 98109-1024
? ? >> 
? ? >> E-mail: hpages at fredhutch.org
? ? >> Phone:? (206) 667-5791
? ? >> Fax:? ? (206) 667-1319


From winstonchang1 at gmail.com  Sat Feb  3 20:31:47 2018
From: winstonchang1 at gmail.com (Winston Chang)
Date: Sat, 3 Feb 2018 11:31:47 -0800
Subject: [Rd] CRAN indices out of whack (for at least macOS)
In-Reply-To: <23152.57727.522184.800529@rob.eddelbuettel.com>
References: <23152.57727.522184.800529@rob.eddelbuettel.com>
Message-ID: <CAFOpNVHt-4JDDK4ZS3yJPBQWxrGd5KY+fxZNyRgqg8jKzZb33A@mail.gmail.com>

Although it may not have been the cause of this particular index
inconsistency, there are other causes of intermittent index
inconsistencies. They could be avoided if there were a different
directory structure on CRAN servers.

One of the causes of inconsistencies is caching. With
cloud.r-project.org (note that this is not cran.r-project.org), the
there is a CDN in front of the server; the CDN has caching endpoints
around the world, and will serve files to the user from the nearest
endpoint.

The cache timeout for each file is 30 minutes. Suppose a user
downloads file X from some endpoint at 1:00. If the endpoint doesn't
already have X in the cache, then it will fetch the file from the
server, and then send it to the user. The endpoint will consider the
cached file valid until 1:30. If another user requests X at 1:20, the
endpoint will serve up the file from its cache without checking with
the server. If someone requests X at 1:40, the endpoint will check
with the server to see if its cached version is still valid (and
download an updated version if necessary), then it wills end the file
to the user.

Because the caching is on a per-file basis, this can lead to a
situation where the PACKAGES file served by an endpoint is out of sync
with the .tgz package files. Imagine this scenario:

1:00 Someone downloads PACKAGES. It is not yet in the endpoint's
cache, so it fetches it from the server. This version of PACKAGES says
that the current version of PkgA is 1.0.
1:10 The server performs an rsync from the central CRAN mirror. It
gets an updated version of PACKAGES, which says that the current
version of PkgA is 2.0. The rsync also removes the PkgA_1.0.tgz file
and adds PkgA_2.0.tgz.
1:20 Someone else wants to install PkgA, so their R session first
downloads PACKAGES, which points to PkgA_1.0.tgz. Then R tries to
download PkgA_1.0.tgz; it is not in the endpoint's cache, so the
endpoint tries to fetch it from the server, but the file is not
present there so it sends a 404 missing message. The endpoint passes
this to the R session, and the package installation fails.

Anyone else who tries to install PkgA (and hits the same CDN endpoint)
will get the same installation failure, until the cache for PACKAGES
expires at 1:30. However, another person who happens to hit another
endpoint may be able to install PkgA, because each endpoint does its
caching independently.

Something similar even without a CDN, because download.packages()
caches the contents of PACKAGES. However, that can be worked around by
telling download.packages() to not use the cache, or by simply
restarting R.

One reason that package installations fail in these cases is that the
current version of a package is in one directory, and the old
(archived) versions of a package are in another directory. If current
and old versions were in the same directory, then package installation
would not fail.


-Winston



On Tue, Jan 30, 2018 at 1:19 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> I have received three distinct (non-)bug reports where someone claimed a
> recent package of mine was broken ... simply because the macOS binary was not
> there.
>
> Is there something wrong with the cronjob providing the indices? Why is it
> pointing people to binaries that do not exist?
>
> Concretely, file
>
>   https://cloud.r-project.org/bin/macosx/el-capitan/contrib/3.4/PACKAGES
>
> contains
>
>   Package: digest
>   Version: 0.6.15
>   Title: Create Compact Hash Digests of R Objects
>   Depends: R (>= 2.4.1)
>   Suggests: knitr, rmarkdown
>   Built: R 3.4.3; x86_64-apple-darwin15.6.0; 2018-01-29 05:21:06 UTC; unix
>   Archs: digest.so.dSYM
>
> yet the _same directory_ only has:
>
>   digest_0.6.14.tgz     15-Jan-2018 21:36       157K
>
> I presume this is a temporary accident.
>
> We are all spoiled by you all providing such a wonderfully robust and
> well-oiled service---so again big THANKS for that--but today something is out
> of order.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Sat Feb  3 22:25:55 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 3 Feb 2018 13:25:55 -0800
Subject: [Rd] as.list method for by Objects
In-Reply-To: <23156.7248.538523.4058@stat.math.ethz.ch>
References: <SY3PR01MB07474F9CEBBC61FD2A152E58CDE40@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <02275be4-b015-0860-8733-efb2b6b17996@fredhutch.org>
 <CADwqtCO98pTE6G4xOva3pVEEA0jSMND9zepcR19B-8rZ6mhYRg@mail.gmail.com>
 <f2080a27-71e0-4f52-61cd-2c2a8bb8e8cd@fredhutch.org>
 <CAOQ5Nye8vFGjheY+QW1H5-Am6BN+V_jKGuCe8=_YbeMQyQFGkA@mail.gmail.com>
 <74406925-3fbb-67d6-5afa-2d18f0b00513@fredhutch.org>
 <CAOQ5NyegUu+9sGCuT4HZpP8vqJncPB5TckLXteS2zNSdtE9zTQ@mail.gmail.com>
 <23154.52332.796492.172488@stat.math.ethz.ch>
 <CAFDcVCRvmKrFMuoEDBVjaKEdEc6=wbHGfJQBSDBakSNRCGc0oA@mail.gmail.com>
 <23156.7248.538523.4058@stat.math.ethz.ch>
Message-ID: <CAFDcVCSnU0-f5gEz79L3+v9vBMUs9MGuH7T0X_V7gOFx+cC0bA@mail.gmail.com>

On Fri, Feb 2, 2018 at 12:07 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>>     on Thu, 1 Feb 2018 10:26:23 -0800 writes:
>
>     > On Thu, Feb 1, 2018 at 12:14 AM, Martin Maechler
>     > <maechler at stat.math.ethz.ch> wrote:
>     >>>>>>> Michael Lawrence <lawrence.michael at gene.com>
>     >>>>>>> on Tue, 30 Jan 2018 15:57:42 -0800 writes:
>     >>
>     >> > I just meant that the minimal contract for as.list() appears to be that it
>     >> > returns a VECSXP. To the user, we might say that is.list() will always
>     >> > return TRUE.
>     >>
>     >> Indeed. I also agree with Herv'e that the user level
>     >> documentation should rather mention  is.list(.) |--> TRUE  than
>     >> VECSXP, and interestingly for the experts among us,
>     >> the  is.list() primitive gives not only TRUE for  VECSXP  but
>     >> also of LISTSXP (the good ole' pairlists).
>     >>
>     >> > I'm not sure we can expect consistency across methods
>     >> > beyond that, nor is it feasible at this point to match the
>     >> > semantics of the methods package. It deals in "class
>     >> > space" while as.list() deals in "typeof() space".
>     >>
>     >> > Michael
>     >>
>     >> Yes, and that *is* the extra complexity we have in R (inherited
>     >> from S, I'd say)  which ideally wasn't there and of course is
>     >> not there in much younger languages/systems such as julia.
>     >>
>     >> And --- by the way let me preach, for the "class space" ---
>     >> do __never__ use
>     >>
>     >> if(class(obj) == "<classname>")
>     >>
>     >> in your code (I see this so often, shockingly to me ...) but rather use
>     >>
>     >> if(inherits(obj, "<classname>"))
>     >>
>     >> instead.
>
>     > Second this one.  But, soon (*) the former will at least give the
>     > correct answer when length(class(obj)) == 1
>     > and produce an error
>     > otherwise.
>
> Not quite; I think you you did not get the real danger in using
> 'class(.) == *':
> What you say above would only be true if there were only S3 classes!
> Try the following small R snippet
>
> myDate <- setClass("myDate", contains = "Date")
> ## Object of class "myDate"
> ## [1] "2018-02-02"
> (d <- myDate(Sys.Date()))
> class(d) == "Date"  # is FALSE (hence of length 1)
> inherits(d, "Date") # is TRUE
>
>     > So, several of these cases will be caught at run-time in a
>     > near future.
>
> Maybe.  But all the others are  still wrong, as I show above.

Oh my, thanks for clarifying/emphasizing.  I hope I didn't mislead too
many people.  I've been away from S4 for too long - I like to stay in
the cozy S3 world :)

/Henrik

> Martin
>
>     > (*) When _R_CHECK_LENGTH_1_CONDITION_=true becomes the default
>     > behavior - hopefully by R 3.5.0.
>
>     >>
>     >> Martin


From jtelleria.rproject at gmail.com  Sun Feb  4 12:25:14 2018
From: jtelleria.rproject at gmail.com (Juan Telleria Ruiz de Aguirre)
Date: Sun, 4 Feb 2018 12:25:14 +0100
Subject: [Rd] Why R should never move to git
In-Reply-To: <CAJXDcw2FT7M42DHX_shYYSH_xa4nttNtDHcF8gxB96vPhOwhOg@mail.gmail.com>
References: <786e446c35374edc8d633f1f65619460@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczOTWqKEqud_yDcO0ybPJwDK=2ydY6SDN5zPF+8_7C9qmg@mail.gmail.com>
 <CAPtbhHxZ64faxmbeNpWy1U_Ra_72RhsnhbrSCt=jRnZyL47p8g@mail.gmail.com>
 <CAJXDcw3K-hWPi+7=Fv+Q0ywPVPyT9rqycYm=2Qq0qR_Vw4P6RQ@mail.gmail.com>
 <ace664be-cb82-f037-29d8-97d5dda50ecd@gmail.com>
 <CAJXDcw3gh8CdRJ9y=3PZ8923if1pN03Btc9nPiZKDjJY+buNUQ@mail.gmail.com>
 <5ab1dcb2-ec1a-9332-422e-efad663a73b4@gmail.com>
 <CAJXDcw0xmG5=CzOFhSGo0m4uoEN-SjvFbxKDjvtJvUKzqNWX0g@mail.gmail.com>
 <CAJXDcw2+PrP7z8=Ndp7XQH=cCABoV3w3TygdTjSfLz1GPw3aVw@mail.gmail.com>
 <CAJXDcw2FT7M42DHX_shYYSH_xa4nttNtDHcF8gxB96vPhOwhOg@mail.gmail.com>
Message-ID: <CAJXDcw2UQhB13+m6GAq8zQW_cgJ7g5RaE_B=nO9c8kd4Fdxdcw@mail.gmail.com>

I attach the Github Flow for teams and projects with regular deployments:

https://guides.github.com/pdfs/githubflow-online.pdf

https://guides.github.com/introduction/flow/

Tips:
* Always!!!! Do pull requests based on branches (never on the master).
* Keep your Fork Synchronized with the Upstream Repository.


From thierry.onkelinx at inbo.be  Mon Feb  5 11:31:45 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 5 Feb 2018 11:31:45 +0100
Subject: [Rd] CRAN indices out of whack (for at least macOS)
In-Reply-To: <CAFOpNVHt-4JDDK4ZS3yJPBQWxrGd5KY+fxZNyRgqg8jKzZb33A@mail.gmail.com>
References: <23152.57727.522184.800529@rob.eddelbuettel.com>
 <CAFOpNVHt-4JDDK4ZS3yJPBQWxrGd5KY+fxZNyRgqg8jKzZb33A@mail.gmail.com>
Message-ID: <CAJuCY5wepFYe71DjGNLLAw_RLcpA_V-wx4+pGNtqo_t3oVUvXw@mail.gmail.com>

Another benefit of Winston's proposal is that it make it easy to
install specific package versions from source. For the time being I'm
using a construct like
https://github.com/inbo/Rstable/blob/master/cran_install.sh to
generate a Docker image.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-03 20:31 GMT+01:00 Winston Chang <winstonchang1 at gmail.com>:
> Although it may not have been the cause of this particular index
> inconsistency, there are other causes of intermittent index
> inconsistencies. They could be avoided if there were a different
> directory structure on CRAN servers.
>
> One of the causes of inconsistencies is caching. With
> cloud.r-project.org (note that this is not cran.r-project.org), the
> there is a CDN in front of the server; the CDN has caching endpoints
> around the world, and will serve files to the user from the nearest
> endpoint.
>
> The cache timeout for each file is 30 minutes. Suppose a user
> downloads file X from some endpoint at 1:00. If the endpoint doesn't
> already have X in the cache, then it will fetch the file from the
> server, and then send it to the user. The endpoint will consider the
> cached file valid until 1:30. If another user requests X at 1:20, the
> endpoint will serve up the file from its cache without checking with
> the server. If someone requests X at 1:40, the endpoint will check
> with the server to see if its cached version is still valid (and
> download an updated version if necessary), then it wills end the file
> to the user.
>
> Because the caching is on a per-file basis, this can lead to a
> situation where the PACKAGES file served by an endpoint is out of sync
> with the .tgz package files. Imagine this scenario:
>
> 1:00 Someone downloads PACKAGES. It is not yet in the endpoint's
> cache, so it fetches it from the server. This version of PACKAGES says
> that the current version of PkgA is 1.0.
> 1:10 The server performs an rsync from the central CRAN mirror. It
> gets an updated version of PACKAGES, which says that the current
> version of PkgA is 2.0. The rsync also removes the PkgA_1.0.tgz file
> and adds PkgA_2.0.tgz.
> 1:20 Someone else wants to install PkgA, so their R session first
> downloads PACKAGES, which points to PkgA_1.0.tgz. Then R tries to
> download PkgA_1.0.tgz; it is not in the endpoint's cache, so the
> endpoint tries to fetch it from the server, but the file is not
> present there so it sends a 404 missing message. The endpoint passes
> this to the R session, and the package installation fails.
>
> Anyone else who tries to install PkgA (and hits the same CDN endpoint)
> will get the same installation failure, until the cache for PACKAGES
> expires at 1:30. However, another person who happens to hit another
> endpoint may be able to install PkgA, because each endpoint does its
> caching independently.
>
> Something similar even without a CDN, because download.packages()
> caches the contents of PACKAGES. However, that can be worked around by
> telling download.packages() to not use the cache, or by simply
> restarting R.
>
> One reason that package installations fail in these cases is that the
> current version of a package is in one directory, and the old
> (archived) versions of a package are in another directory. If current
> and old versions were in the same directory, then package installation
> would not fail.
>
>
> -Winston
>
>
>
> On Tue, Jan 30, 2018 at 1:19 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>> I have received three distinct (non-)bug reports where someone claimed a
>> recent package of mine was broken ... simply because the macOS binary was not
>> there.
>>
>> Is there something wrong with the cronjob providing the indices? Why is it
>> pointing people to binaries that do not exist?
>>
>> Concretely, file
>>
>>   https://cloud.r-project.org/bin/macosx/el-capitan/contrib/3.4/PACKAGES
>>
>> contains
>>
>>   Package: digest
>>   Version: 0.6.15
>>   Title: Create Compact Hash Digests of R Objects
>>   Depends: R (>= 2.4.1)
>>   Suggests: knitr, rmarkdown
>>   Built: R 3.4.3; x86_64-apple-darwin15.6.0; 2018-01-29 05:21:06 UTC; unix
>>   Archs: digest.so.dSYM
>>
>> yet the _same directory_ only has:
>>
>>   digest_0.6.14.tgz     15-Jan-2018 21:36       157K
>>
>> I presume this is a temporary accident.
>>
>> We are all spoiled by you all providing such a wonderfully robust and
>> well-oiled service---so again big THANKS for that--but today something is out
>> of order.
>>
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Mon Feb  5 13:43:31 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 Feb 2018 13:43:31 +0100
Subject: [Rd] 
 sum() returns NA on a long *logical* vector when nb of TRUE
 values exceeds 2^31
In-Reply-To: <23155.13164.411368.435222@stat.math.ethz.ch>
References: <5931466B.1060407@fredhutch.org>
 <CAFDcVCRt1=-1t8=-x5TLhe3y0T_tpZUkTAH1W-hyMKqFH-eJYg@mail.gmail.com>
 <CAFDcVCQv19O2zBybkRHh6G58AMa0GjQRZcHnD3WEnQACnuM7Uw@mail.gmail.com>
 <23148.23857.970768.727765@stat.math.ethz.ch>
 <3d97d7d0-ef1b-90a7-ed1e-16af5461abc0@fredhutch.org>
 <23155.13164.411368.435222@stat.math.ethz.ch>
Message-ID: <23160.20851.680296.281972@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 1 Feb 2018 16:34:04 +0100 writes:

> >>>>> Herv? Pag?s <hpages at fredhutch.org>
> >>>>>     on Tue, 30 Jan 2018 13:30:18 -0800 writes:
> 
>     > Hi Martin, Henrik,
>     > Thanks for the follow up.
> 
>     > @Martin: I vote for 2) without *any* hesitation :-)
> 
>     > (and uniformity could be restored at some point in the
>     > future by having prod(), rowSums(), colSums(), and others
>     > align with the behavior of length() and sum())
> 
> As a matter of fact, I had procrastinated and worked at
> implementing '2)' already a bit on the weekend and made it work
> - more or less.  It needs a bit more work, and I had also been considering
> replacing the numbers in the current overflow check
> 
> 	if (ii++ > 1000) {	 \
> 	    ii = 0;							\
> 	    if (s > 9000000000000000L || s < -9000000000000000L) {	\
> 		if(!updated) updated = TRUE;				\
> 		*value = NA_INTEGER;					\
> 		warningcall(call, _("integer overflow - use sum(as.numeric(.))")); \
> 		return updated;						\
> 	    }								\
> 	}								\
> 
> i.e. think of tweaking the '1000' and '9000000000000000L', 
> but decided to leave these and add comments there about why. For
> the moment.
> They may look arbitrary, but are not at all: If you multiply
> them (which looks correct, if we check the sum 's' only every 1000-th
> time ...((still not sure they *are* correct))) you get  9*10^18
> which is only slightly smaller than  2^63 - 1 which may be the
> maximal "LONG_INT" integer we have.
> 
> So, in the end, at least for now, we do not quite go all they way
> but overflow a bit earlier,... but do potentially gain a bit of
> speed, notably with the ITERATE_BY_REGION(..) macros
> (which I did not show above).
> 
> Will hopefully become available in R-devel real soon now.
>
> Martin

After finishing that... I challenged myself that one should be able to do
better, namely "no overflow" (because of large/many
integer/logical), and so introduced  irsum()  which uses a double 
precision accumulator for integer/logical  ... but would really
only be used when the 64-bit int accumulator would get close to
overflow.
The resulting code is not really beautiful, and also contains a
a comment     " (a waste, rare; FIXME ?) "
If anybody feels like finding a more elegant version without the
"waste" case, go ahead and be our guest ! 

Testing the code does need access to a platform with enough GB
RAM, say 32 (and I have run the checks only on servers with >
100 GB RAM). This concerns the new checks at the (current) end
of <R-devel_R>/tests/reg-large.R

In R-devel svn rev >= 74208  for a few minutes now.

Martin


From mbanghart at ssc.wisc.edu  Tue Feb  6 22:50:55 2018
From: mbanghart at ssc.wisc.edu (MARK BANGHART)
Date: Tue, 6 Feb 2018 21:50:55 +0000
Subject: [Rd] Warning from Sys.junction when using network drive.
Message-ID: <CY4PR06MB33018142339A5327757C19238BFD0@CY4PR06MB3301.namprd06.prod.outlook.com>

I am running 3.4.3 on a windows server and I ran the code in a new session.


I get a warning when running packrat::init() on a project that is located on a windows network drive.
The warning I get is


Warning message:
cannot set reparse point 'U:/packrat5/packrat/lib-R/base', reason 'Access is denied'


The error is created based inside the function .Internal(mkjunction(fr, link)) which is called from Sys.junction().  I have run Sys.junction inside the RStudio debugger and I checked that the 'U:/packrat5/packrat/lib-R/base'
could be accessed via the windows file explorer before the .Internal(mkjunction(fr, link)) call is made.  Looking at the code for do_mkjunction(), the warning looks to be thrown based on the return status from DeviceIoControl.


I setup a project on the C: drive and tried the same packrat::init() code.

The call to .Internal(mkjunction(fr, link)) did not produce an error.


I would appreciate any help you can provide on this issue.

Thanks,

Mark

	[[alternative HTML version deleted]]


From mikko.korpela at maanmittauslaitos.fi  Wed Feb  7 14:38:26 2018
From: mikko.korpela at maanmittauslaitos.fi (Korpela Mikko (MML))
Date: Wed, 7 Feb 2018 13:38:26 +0000
Subject: [Rd] Possible bug in package installation when R_ICU_LOCALE is set
Message-ID: <f83b26e7f5d148deaa3797635e190505@C119S212VM016.msvyvi.vaha.local>

On a Windows computer (other platforms not tested), installing a
package from source may fail if the environment variable R_ICU_LOCALE
is set, depending on the package and the locale.

For example, after setting R_ICU_LOCALE to "fi_FI",

  install.packages("seriation", type = "source")

(package version 1.2-3) fails with the following error:

** preparing package for lazy loading
Error in set_criterion_method("dist", "AR_events", criterion_ar_events,  :
  could not find function "set_criterion_method"
Error : unable to load R code in package 'seriation'

Package "Epi" (version 2.24) fails similarly:

** preparing package for lazy loading
Error in eval(exprs[i], envir) : object 'Relevel.default' not found
Error : unable to load R code in package 'Epi'

Whether R_ICU_LOCALE is set before R is launched or during the session
doesn't matter: installation of these two example packages fails
either way. If R_ICU_LOCALE is unset, calling

  icuSetCollate(locale = "fi_FI")

is harmless. Browsing through the R manuals, I did not find warnings
against using R_ICU_LOCALE, or any indication why package installation
should fail with the variable being set. About the collation order of R
code files, "Writing R Extensions" says:

> The default is to collate according to the 'C' locale.

I interpret this (and the surrounding text) as a "promise" to package
developers that no matter what the end user does, the developer should
be able to rely on the collation order being 'C' unless the developer
defines another order.

> sessionInfo()
R version 3.4.3 Patched (2018-02-03 r74231)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Finnish_Finland.1252  LC_CTYPE=Finnish_Finland.1252
[3] LC_MONETARY=Finnish_Finland.1252 LC_NUMERIC=C
[5] LC_TIME=Finnish_Finland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 tools_3.4.3

-- 
Mikko Korpela
Chief Expert, Valuations
National Land Survey of Finland
Opastinsilta 12 C, FI-00520 Helsinki, Finland
+358 50?462 6082
www.maanmittauslaitos.fi


From istazahn at gmail.com  Wed Feb  7 16:04:50 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Feb 2018 10:04:50 -0500
Subject: [Rd] 
 Possible bug in package installation when R_ICU_LOCALE is set
In-Reply-To: <f83b26e7f5d148deaa3797635e190505@C119S212VM016.msvyvi.vaha.local>
References: <f83b26e7f5d148deaa3797635e190505@C119S212VM016.msvyvi.vaha.local>
Message-ID: <CA+vqiLGFkMoj7fC2QcOSavg4XXML1Ud5zipMW-ynqPh6VjMBSA@mail.gmail.com>

I can reproduce this on Linux, so it is not Windows-specific.

> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Arch Linux

Matrix products: default
BLAS/LAPACK: /usr/lib/libopenblas_haswellp-r0.2.20.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 rmsfact_0.0.3  tools_3.4.3    cowsay_0.5.0   fortunes_1.5-4


On Wed, Feb 7, 2018 at 8:38 AM, Korpela Mikko (MML)
<mikko.korpela at maanmittauslaitos.fi> wrote:
> On a Windows computer (other platforms not tested), installing a
> package from source may fail if the environment variable R_ICU_LOCALE
> is set, depending on the package and the locale.
>
> For example, after setting R_ICU_LOCALE to "fi_FI",
>
>   install.packages("seriation", type = "source")
>
> (package version 1.2-3) fails with the following error:
>
> ** preparing package for lazy loading
> Error in set_criterion_method("dist", "AR_events", criterion_ar_events,  :
>   could not find function "set_criterion_method"
> Error : unable to load R code in package 'seriation'
>
> Package "Epi" (version 2.24) fails similarly:
>
> ** preparing package for lazy loading
> Error in eval(exprs[i], envir) : object 'Relevel.default' not found
> Error : unable to load R code in package 'Epi'
>
> Whether R_ICU_LOCALE is set before R is launched or during the session
> doesn't matter: installation of these two example packages fails
> either way. If R_ICU_LOCALE is unset, calling
>
>   icuSetCollate(locale = "fi_FI")
>
> is harmless. Browsing through the R manuals, I did not find warnings
> against using R_ICU_LOCALE, or any indication why package installation
> should fail with the variable being set. About the collation order of R
> code files, "Writing R Extensions" says:
>
>> The default is to collate according to the 'C' locale.
>
> I interpret this (and the surrounding text) as a "promise" to package
> developers that no matter what the end user does, the developer should
> be able to rely on the collation order being 'C' unless the developer
> defines another order.
>
>> sessionInfo()
> R version 3.4.3 Patched (2018-02-03 r74231)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Finnish_Finland.1252  LC_CTYPE=Finnish_Finland.1252
> [3] LC_MONETARY=Finnish_Finland.1252 LC_NUMERIC=C
> [5] LC_TIME=Finnish_Finland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3 tools_3.4.3
>
> --
> Mikko Korpela
> Chief Expert, Valuations
> National Land Survey of Finland
> Opastinsilta 12 C, FI-00520 Helsinki, Finland
> +358 50 462 6082
> www.maanmittauslaitos.fi
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mbodin at dim.uchile.cl  Wed Feb  7 16:12:10 2018
From: mbodin at dim.uchile.cl (Martin Bodin)
Date: Wed, 7 Feb 2018 12:12:10 -0300
Subject: [Rd] Possible typo in the C source code of R
Message-ID: <7faca923-dfd9-19f6-7cff-3289bb4f715e@dim.uchile.cl>

Good morning,

I am Martin Bodin, a postdoc at the CMM in Santiago de Chile, and I am
currently in the process of formalising (a part of) the R language into
the Coq proof assistant. This work makes me look frequently at the
source code of R.

I have noticed a strange line in the file src/main/util.c of the trunk
branch:
https://github.com/wch/r-source/blob/e42531eff56ee6582d7dc6a46f242af5447c633e/src/main/util.c#L70

The line 70 ?REAL(x)[0] == REAL(x)[0]? doesn?t make any sense for me:
are we looking for NaN values here? I think that it should be
?REAL(x)[0] == REAL(y)[0]? instead (and the same applies for the next
two lines).

I didn?t searched for any R program that may be affected by this typo,
but I have the feeling that it may lead to unexpected behaviours.

From what I understood, the bug reporting tool for R is closed for
non-members, and I am thus sending this possible bug report in this
list. Please redirect me if I am not reporting in the right place.

Best regards,
Martin Bodin.



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180207/a654ad87/attachment.sig>

From kmbell56 at gmail.com  Wed Feb  7 16:14:32 2018
From: kmbell56 at gmail.com (Kenny Bell)
Date: Wed, 07 Feb 2018 15:14:32 +0000
Subject: [Rd] saveRDS() overwrites file when object is not found
Message-ID: <CAPekMC=7FrMGEzm7G_9r7JRTdQd23UTPjb9q7Vkx0dPoW1LhjQ@mail.gmail.com>

I ran into this behaviour when accidentally running a line of code that I
shouldn't have.

When saving over an rds with an object that's not found, I would have
expected saveRDS to not touch the file.

saveRDS(iris, "test.rds")
file.size("test.rds")
#> [1] 1080
saveRDS(no_object_here, "test.rds")
#> Error in saveRDS(no_object_here, "test.rds"): object 'no_object_here'
not found
file.size("test.rds")
#> [1] 20
file.remove("test.rds")

	[[alternative HTML version deleted]]


From khoran at cs.ucr.edu  Wed Feb  7 16:59:16 2018
From: khoran at cs.ucr.edu (Kevin Horan)
Date: Wed, 7 Feb 2018 07:59:16 -0800
Subject: [Rd] rsvg on mac
Message-ID: <db50bcf7-2e15-f7a5-ad87-7587e8ec6fee@cs.ucr.edu>


The ChemmineR build is failing on the mac due to a new dependency not 
being available, the package "rsvg". Would it be possible to install 
that on the mac build machine? Thanks.

http://bioconductor.org/checkResults/devel/bioc-LATEST/ChemmineR/merida2-install.html


Kevin


From khoran at cs.ucr.edu  Wed Feb  7 17:07:53 2018
From: khoran at cs.ucr.edu (Kevin Horan)
Date: Wed, 7 Feb 2018 08:07:53 -0800
Subject: [Rd] release build of ChemmineR failing
Message-ID: <14f276e8-9253-62d6-5916-a2111a9cdfb4@cs.ucr.edu>


The release version of ChemmineR is failing on windows. It seems to be a 
build script issue though, possibly something on your side. The package 
was building fine a few weeks ago and I have not modified it. Can you 
please have a look? Thanks.

"C:/Users/BIOCBU?1/BBS-3?1.6-B/R/bin/Rscript" -e "library(rmarkdown); library(BiocStyle); rmarkdown::render('ChemmineR.Rmd')"
'C:\Users\BIOCBU?1\BBS-3?1.6-B\R\bin\x64\Rscript.exe" -e "library' is not recognized as an internal or external command,operable program or batch file.

http://bioconductor.org/checkResults/release/bioc-LATEST/ChemmineR/tokay1-buildsrc.html 


Kevin


	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Feb  7 17:24:48 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Feb 2018 11:24:48 -0500
Subject: [Rd] rsvg on mac
In-Reply-To: <db50bcf7-2e15-f7a5-ad87-7587e8ec6fee@cs.ucr.edu>
References: <db50bcf7-2e15-f7a5-ad87-7587e8ec6fee@cs.ucr.edu>
Message-ID: <CA+vqiLFrp6SOQz1_oXYEyLAZ_h1+fTTC1w0E5RHEot=4W11=Zg@mail.gmail.com>

Hi Kevin,

I can't imagine what gave you the idea that r-devel is an appropriate
place to make requests regarding bioconductor build infrastructure. It
is not.

Best,
Ista

On Wed, Feb 7, 2018 at 10:59 AM, Kevin Horan <khoran at cs.ucr.edu> wrote:
>
> The ChemmineR build is failing on the mac due to a new dependency not being
> available, the package "rsvg". Would it be possible to install that on the
> mac build machine? Thanks.
>
> http://bioconductor.org/checkResults/devel/bioc-LATEST/ChemmineR/merida2-install.html
>
>
> Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From istazahn at gmail.com  Wed Feb  7 17:35:06 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Feb 2018 11:35:06 -0500
Subject: [Rd] release build of ChemmineR failing
In-Reply-To: <14f276e8-9253-62d6-5916-a2111a9cdfb4@cs.ucr.edu>
References: <14f276e8-9253-62d6-5916-a2111a9cdfb4@cs.ucr.edu>
Message-ID: <CA+vqiLFRetFZDeA5PWPmFae0aYF1yOP+3EA3zoOTrcdQY-jpFA@mail.gmail.com>

This is not the right place to report Bioconductor issues. Even if it
were you have not provided adequate reproduction steps.

source("https://bioconductor.org/biocLite.R")
biocLite("ChemmineR")
library(ChemmineR)

works fine for me. When you find the correct venue for reporting this
issue I hope you'll more specific about what the problem is.

Best,
Ista

On Wed, Feb 7, 2018 at 11:07 AM, Kevin Horan <khoran at cs.ucr.edu> wrote:
>
> The release version of ChemmineR is failing on windows. It seems to be a
> build script issue though, possibly something on your side. The package
> was building fine a few weeks ago and I have not modified it. Can you
> please have a look? Thanks.
>
> "C:/Users/BIOCBU?1/BBS-3?1.6-B/R/bin/Rscript" -e "library(rmarkdown); library(BiocStyle); rmarkdown::render('ChemmineR.Rmd')"
> 'C:\Users\BIOCBU?1\BBS-3?1.6-B\R\bin\x64\Rscript.exe" -e "library' is not recognized as an internal or external command,operable program or batch file.
>
> http://bioconductor.org/checkResults/release/bioc-LATEST/ChemmineR/tokay1-buildsrc.html
>
>
> Kevin
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Wed Feb  7 23:14:40 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 7 Feb 2018 14:14:40 -0800
Subject: [Rd] Trailing underscores on C function names
Message-ID: <CAF8bMcYvp5LgC7bvcMGvLvs9jagNjS4iyy2itPSoujE852NzCQ@mail.gmail.com>

In the fastmatch package, version 1.1-0, there is a C function called
"ctapply_", with a trailing underscore.  However, the NAMESPACE's call to
useDynLib refers to "ctapply", without the trailing underscore.

% grep ctapply NAMESPACE {R,src}/*
NAMESPACE:useDynLib(fastmatch, C_fmatch = fmatch, C_ctapply = ctapply,
C_coalesce = coalesce, C_append = append, mk_hash, get_table, get_values)
NAMESPACE:export(fmatch, fmatch.hash, ctapply, coalesce, "%fin%")
R/ctapply.R:ctapply <- function(X, INDEX, FUN, ..., MERGE=c)
.External(C_ctapply, parent.frame(), X, INDEX, FUN, MERGE, ...)
src/ctapply.c:SEXP ctapply_(SEXP args) {
src/ctapply.c:     see ctapply(x, y, identity). It should be uncommon,
though


"Writing R Extensions" mentions, section 5.2, footnote 121, that .C and
.Fortran interpret their first argument as the name of the object file
symbol "possibly after some platform-specific translation, e.g. adding
leading or trailing underscores".

Should useDynLib use the underscored name?  The code doesn't seem
"platform-specific".  What are the rules concerning added underscores (or
capitalization?) that  R uses?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From dstr7320 at uni.sydney.edu.au  Thu Feb  8 05:00:13 2018
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Thu, 8 Feb 2018 04:00:13 +0000
Subject: [Rd] sparse.model.matrix Generates Non-Existent Factor Levels if
 Ord.factor Columns Present
Message-ID: <SYAPR01MB2909E2D69C15EAAC96F7C6E5CDF30@SYAPR01MB2909.ausprd01.prod.outlook.com>

Good day,

Sometimes, sparse.model.matrix outputs a dgCMatrix which has column names consisting of factor levels that were not in the original dataset. The first factor appears to be correctly transformed, but the following factors don't. For example:

diamonds <- as.data.frame(ggplot2::diamonds)
> colnames(sparse.model.matrix(~ . -1, diamonds))
 [1] "carat"        "cutFair"      "cutGood"      "cutVery Good" "cutPremium"   "cutIdeal"     "color.L"      "color.Q"      "color.C"      "color^4"      "color^5"     
[12] "color^6"      "clarity.L"    "clarity.Q"    "clarity.C"    "clarity^4"    "clarity^5"    "clarity^6"    "clarity^7"    "depth"        "table"        "price"       
[23] "x"            "y"            "z"

The variables color and clarity don't have factor levels which have been suffixed to them in the transformed matrix. The values in those columns are also wrong. Changing the Ord.factor columns into simply being factors fixes the problem. 

> diamonds[, "cut"] <- factor(as.character(diamonds[, "cut"]))
> diamonds[, "color"] <- factor(as.character(diamonds[, "color"]))
> diamonds[, "clarity"] <- factor(as.character(diamonds[, "clarity"]))

> colnames(sparse.model.matrix(~ . -1, diamonds)) # No more invented factor levels.
 [1] "carat"        "cutFair"      "cutGood"      "cutIdeal"     "cutPremium"   "cutVery Good" "colorE"       "colorF"       "colorG"       "colorH"      
[11] "colorI"       "colorJ"       "clarityIF"    "claritySI1"   "claritySI2"   "clarityVS1"   "clarityVS2"   "clarityVVS1"  "clarityVVS2"  "depth"       
[21] "table"        "price"        "x"            "y"            "z"

Can it be made to work correctly for both plain and ordered factors?

> sessionInfo()
R Under development (unstable) (2018-02-06 r74231)
Platform: i386-w64-mingw32/i386 (32-bit)

other attached packages:
[1] Matrix_1.2-12

loaded via a namespace (and not attached):
 [1] colorspace_1.3-2 scales_0.5.0     compiler_3.5.0   lazyeval_0.2.1  
 [5] plyr_1.8.4       pillar_1.1.0     gtable_0.2.0     tibble_1.4.2    
 [9] Rcpp_0.12.15     ggplot2_2.2.1    grid_3.5.0       rlang_0.1.6     
[13] munsell_0.4.3    lattice_0.20-35

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia


From bbolker at gmail.com  Thu Feb  8 13:51:12 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Feb 2018 07:51:12 -0500
Subject: [Rd] 
 sparse.model.matrix Generates Non-Existent Factor Levels if
 Ord.factor Columns Present
In-Reply-To: <SYAPR01MB2909E2D69C15EAAC96F7C6E5CDF30@SYAPR01MB2909.ausprd01.prod.outlook.com>
References: <SYAPR01MB2909E2D69C15EAAC96F7C6E5CDF30@SYAPR01MB2909.ausprd01.prod.outlook.com>
Message-ID: <8514e60d-e80b-456f-a9fa-150f70a808d7@gmail.com>


  color and clarity are ordered factors, so sparse.model.matrix is
generating orthogonal-polynomial contrasts  (see ?contr.poly).  This is
by design ...  what are you trying to do?  Are you interested in fac2sparse?

On 18-02-07 11:00 PM, Dario Strbenac wrote:
> Good day,
> 
> Sometimes, sparse.model.matrix outputs a dgCMatrix which has column names consisting of factor levels that were not in the original dataset. The first factor appears to be correctly transformed, but the following factors don't. For example:
> 
> diamonds <- as.data.frame(ggplot2::diamonds)
>> colnames(sparse.model.matrix(~ . -1, diamonds))
>  [1] "carat"        "cutFair"      "cutGood"      "cutVery Good" "cutPremium"   "cutIdeal"     "color.L"      "color.Q"      "color.C"      "color^4"      "color^5"     
> [12] "color^6"      "clarity.L"    "clarity.Q"    "clarity.C"    "clarity^4"    "clarity^5"    "clarity^6"    "clarity^7"    "depth"        "table"        "price"       
> [23] "x"            "y"            "z"
> 
> The variables color and clarity don't have factor levels which have been suffixed to them in the transformed matrix. The values in those columns are also wrong. Changing the Ord.factor columns into simply being factors fixes the problem. 
> 
>> diamonds[, "cut"] <- factor(as.character(diamonds[, "cut"]))
>> diamonds[, "color"] <- factor(as.character(diamonds[, "color"]))
>> diamonds[, "clarity"] <- factor(as.character(diamonds[, "clarity"]))
> 
>> colnames(sparse.model.matrix(~ . -1, diamonds)) # No more invented factor levels.
>  [1] "carat"        "cutFair"      "cutGood"      "cutIdeal"     "cutPremium"   "cutVery Good" "colorE"       "colorF"       "colorG"       "colorH"      
> [11] "colorI"       "colorJ"       "clarityIF"    "claritySI1"   "claritySI2"   "clarityVS1"   "clarityVS2"   "clarityVVS1"  "clarityVVS2"  "depth"       
> [21] "table"        "price"        "x"            "y"            "z"
> 
> Can it be made to work correctly for both plain and ordered factors?
> 
>> sessionInfo()
> R Under development (unstable) (2018-02-06 r74231)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> other attached packages:
> [1] Matrix_1.2-12
> 
> loaded via a namespace (and not attached):
>  [1] colorspace_1.3-2 scales_0.5.0     compiler_3.5.0   lazyeval_0.2.1  
>  [5] plyr_1.8.4       pillar_1.1.0     gtable_0.2.0     tibble_1.4.2    
>  [9] Rcpp_0.12.15     ggplot2_2.2.1    grid_3.5.0       rlang_0.1.6     
> [13] munsell_0.4.3    lattice_0.20-35
> 
> --------------------------------------
> Dario Strbenac
> University of Sydney
> Camperdown NSW 2050
> Australia
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tomas.kalibera at gmail.com  Thu Feb  8 15:02:43 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 8 Feb 2018 15:02:43 +0100
Subject: [Rd] Warning from Sys.junction when using network drive.
In-Reply-To: <CY4PR06MB33018142339A5327757C19238BFD0@CY4PR06MB3301.namprd06.prod.outlook.com>
References: <CY4PR06MB33018142339A5327757C19238BFD0@CY4PR06MB3301.namprd06.prod.outlook.com>
Message-ID: <2f07232a-7975-0575-6e46-a3c088492ea4@gmail.com>


Unfortunately, junctions cannot link to a network drive, they only can 
link directories on the same computer (possibly on different local 
volumes). This is a limitation imposed by Windows. I have updated the 
documentation for Sys.junction in R-devel accordingly.

Tomas

On 02/06/2018 10:50 PM, MARK BANGHART wrote:
> I am running 3.4.3 on a windows server and I ran the code in a new session.
>
>
> I get a warning when running packrat::init() on a project that is located on a windows network drive.
> The warning I get is
>
>
> Warning message:
> cannot set reparse point 'U:/packrat5/packrat/lib-R/base', reason 'Access is denied'
>
>
> The error is created based inside the function .Internal(mkjunction(fr, link)) which is called from Sys.junction().  I have run Sys.junction inside the RStudio debugger and I checked that the 'U:/packrat5/packrat/lib-R/base'
> could be accessed via the windows file explorer before the .Internal(mkjunction(fr, link)) call is made.  Looking at the code for do_mkjunction(), the warning looks to be thrown based on the return status from DeviceIoControl.
>
>
> I setup a project on the C: drive and tried the same packrat::init() code.
>
> The call to .Internal(mkjunction(fr, link)) did not produce an error.
>
>
> I would appreciate any help you can provide on this issue.
>
> Thanks,
>
> Mark
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Thu Feb  8 15:18:15 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 8 Feb 2018 15:18:15 +0100
Subject: [Rd] saveRDS() overwrites file when object is not found
In-Reply-To: <CAPekMC=7FrMGEzm7G_9r7JRTdQd23UTPjb9q7Vkx0dPoW1LhjQ@mail.gmail.com>
References: <CAPekMC=7FrMGEzm7G_9r7JRTdQd23UTPjb9q7Vkx0dPoW1LhjQ@mail.gmail.com>
Message-ID: <e5d19adf-49f6-c6d8-ba0d-6fb5efae6890@gmail.com>

Thanks, this has been already reported as bug 17358. Addressed in 
R-devel 74238. R may still create a corrupt file, though, in other 
circumstances (e.g. if it runs out of memory or is interrupted during 
serialization, etc).

Tomas

On 02/07/2018 04:14 PM, Kenny Bell wrote:
> I ran into this behaviour when accidentally running a line of code that I
> shouldn't have.
>
> When saving over an rds with an object that's not found, I would have
> expected saveRDS to not touch the file.
>
> saveRDS(iris, "test.rds")
> file.size("test.rds")
> #> [1] 1080
> saveRDS(no_object_here, "test.rds")
> #> Error in saveRDS(no_object_here, "test.rds"): object 'no_object_here'
> not found
> file.size("test.rds")
> #> [1] 20
> file.remove("test.rds")
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dstr7320 at uni.sydney.edu.au  Fri Feb  9 01:00:11 2018
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 9 Feb 2018 00:00:11 +0000
Subject: [Rd] 
 sparse.model.matrix Generates Non-Existent Factor Levels if
 Ord.factor Columns Present
In-Reply-To: <8514e60d-e80b-456f-a9fa-150f70a808d7@gmail.com>
References: <SYAPR01MB2909E2D69C15EAAC96F7C6E5CDF30@SYAPR01MB2909.ausprd01.prod.outlook.com>,
 <8514e60d-e80b-456f-a9fa-150f70a808d7@gmail.com>
Message-ID: <SYAPR01MB29097AC9E88583C9F37C062CCDF30@SYAPR01MB2909.ausprd01.prod.outlook.com>

Good day,

The intention is to convert the dataset into a format suitable for the random forest classifier implemented by the CRAN package xgboost. The input data is required to be transformed into one-hot format using the sparse.discrim.matrix function, as specified by the package's vignette of URL https://cran.r-project.org/web/packages/xgboost/vignettes/discoverYourData.html I did not know to read the help page for contr.poly after reading the sparse.discrim.matrix help page. Perhaps there could be a helpful mention added to it?

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia

From indrajitsg at gmail.com  Fri Feb  9 03:44:54 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Fri, 9 Feb 2018 08:14:54 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
Message-ID: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>

Hi All,

I am trying to compile R from source on a 64 bit Windows. I have downloaded
and installed all the third party software as per the R - documentation.
The compilation starts fine and after a while it stops with the following
error message:

D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
cannot find -lRgraphapp
collect2.exe: error: ld returned 1 exit status
make[3]: *** [R.dll] Error 1
make[2]: *** [../../bin/x64/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2

The file Rgraphapp.dll is created in the folder *D:\R64\R-3.4.3\bin\x64*
but somehow the process is not able to find it and gives an error. The
purpose for going through this process was to compile R with OpenBlas which
I had compiled earlier with MinGW and had created the file:
*libopenblas_haswell-r0.2.20.a. *

I have attached the MkRules.local and the output log along with this email.
Any would be greatly appreciated.

Regards,
Indrajit

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: output_log.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180209/751569e0/attachment.txt>

From avraham.adler at gmail.com  Fri Feb  9 06:23:51 2018
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 9 Feb 2018 00:23:51 -0500
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
Message-ID: <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>

On Thu, Feb 8, 2018 at 9:44 PM, Indrajit Sen Gupta <indrajitsg at gmail.com> wrote:
> Hi All,
>
> I am trying to compile R from source on a 64 bit Windows.

[snip]

> I had compiled earlier with MinGW and had created the file:
> *libopenblas_haswell-r0.2.20.a. *

Hello, Indrajit.

I don't see your MkRules.local attached. In any event, perhaps try
following the directions here [1]. I've been building R with OpenBLAS
on Windows 64 for years and it almost always works. In the past year
or two, rarely, it will stop with an error. But if you restart the
make process (by just typing "make" again) it finishes with no issues
and passes make check-devel. I have not tried this with R-dev, though.
R 3.4.3 Patched (2018-01-03 r74042) is the most recent I have built
successfully.

Good luck,

Avraham

[1] https://www.avrahamadler.com/r-tips/build-openblas-for-windows-r64/


From indrajitsg at gmail.com  Fri Feb  9 07:28:52 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Fri, 9 Feb 2018 11:58:52 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
Message-ID: <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>

Hi Avraham,

What a coincidence, I have been following this post of yours:
https://www.avrahamadler.com/2013/10/24/an-openblas-based-rblas-for-windows-64-step-by-step/

Looks like this post is slightly older than what you have shared
previously. It is strange that you did not get the attachments. I am
pasting the contents of the MkRules.local here:

-------------------------------------------------------------------

#-*- Makefile -*-

## This is only used when building R itself but it does customize
## etc/*/Makeconf using LOCAL_SOFT, BINPREF[64], IMPLIB and R_ARCH

## Customize by copying to MkRules.local and uncommenting and editing
## some of the definitions there.
##

## =========== configuration macros for building packages ================
# Absolute path to '/usr/local' software collection.  The versions used
# on CRAN can be found at https://www.stats.ox.ac.uk/pub/Rtools/libs.html
# It can be interrogated by 'R CMD config LOCAL_SOFT'
# Use 'make rsync-extsoft' to populate the default directory.
# LOCAL_SOFT = D:/R64/extsoft

## ============== configuration macros for building R ===================

# Path of library directory containing zlib, bzlib, liblzma, pcre,
# libpng, libjpeg, libtiff.
# Use 'make rsync-extsoft' to populate the default directory.
EXT_LIBS = D:/R64/extsoft

# an alternative is to use -gstabs here, if the debugger supports only
stabs.
# G_FLAG = -gdwarf-2

# Set to YES and specify the path if you want to use the ATLAS BLAS.
USE_ATLAS = YES
ATLAS_PATH =D:/home/thread0

# Support for the ACML and Goto BLASes has been withdrawn: see R-admin.html

# Define to use svnversion to set SVN-REVISION (slow, and requires a clean
# checkout with no modifications).
# USE_SVNVERSION = YES

# With the previously recommended gcc 4.6.3 toolchain, set this to 32 or 64
# MULTI = 64
# If the toolchain's bin directory is not in your path, set this to the path
# (including the trailing /, and use / not \).
# TOOL_PATH =
# for other toolchains leave these empty and set the more detailed options
below

# With the recommended gcc 4.9.3 toolchain or another toolchain, set
# BINPREF and BINPREF64 (below) to the respective bin directories.
# Include the trailing /, and use / not \.
# Do this in the more detailed options below
# Set this to 32 or 64
WIN = 64


### BEGIN more detailed options
# Some of the toolchains have prefixes for e.g. ar, gcc.
# This can also be used to give the full path to the compiler,
# including a trailing / .
# BINPREF = c:/Rtools/mingw_32/bin/
# prefix for 64-bit:
BINPREF64 = D:/Rtools/mingw_64/bin/
# Set this to indicate a non-gcc compiler and version
# COMPILED_BY = <determined automatically>

# Others use a -m64 or -m32 option to select architectures
# M_ARCH = -m64
# and for as (--32 or --64)
# AS_ARCH = --64
# and for windres (-F pe-i386 or pe-x86-64)
# RC_ARCH = pe-x86-64
# and for dlltool ("-m i386 --as-flags --32" vs "-m i386:x86-64 --as-flags
--64")
DT_ARCH = -m i386:x86-64 --as-flags --64

# 32- or 64-bit Windows?
WIN = 64

# The gcc 4.9.3 64 bit toolchain is set up for the 'medium code' model and
needs
# to remove the .refptr and .weak entries from the exports list; this is
the default
# when WIN = 64, with blank for WIN = 32:
NM_FILTER = | $(SED) -e '/[.]refptr[.]/d' -e '/[.]weak[.]/d'

# We normally link directly against DLLs,
# but this macro forces the use of import libs
# Has been needed for some versions of MinGW-w64
USE_IMPLIBS = YES

### END more detailed options


# set to use ICU
USE_ICU = YES
# path to parent of ICU headers
ICU_PATH = D:/home/ICU
ICU_LIBS = -lsicuin -lsicuuc -lsicudt -lstdc++

# set to use libcurl
USE_LIBCURL = YES
# path to parent of libcurl headers
CURL_PATH = D:/home/curl
# libs: for 32-bit
# CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
-lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm -lidn
# libs: for 64-bit
CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
-lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm

# For the cairographics devices
# Optionally use a static build of cairographics from
#   https://www.rforge.net/Cairo/files/cairo-current-win.tar.gz
# and set CAIRO_HOME to the parent of the win32/win64 directories
#
# If CAIRO_HOME is not set the devices are not built.
CAIRO_HOME = D:/home/cairo/src

# set this to YES to build static HTML help
BUILD_HTML = YES

# unset this if you are *not* using MiKTeX
MIKTEX = TRUE
# Recent MiKTEX does not provide texi2dvi and needs something like
TEXI2DVI = TEXINDEX=texindex.exe texify

# for texinfo >= 5.1. If the texinfo files are installed at
/packages/texinfo,
# TEXI2ANY = /path/to/perl -I/packages/texinfo /packages/texinfo/texi2any
# if you do not have texinfo (default),
# TEXI2ANY = missing

# additional optimization flags (use -mtune=native for a private build)
EOPTS = -mtune=native

# define to -fopenmp if the toolchain has OpenMP support
# OPENMP = -fopenmp

# define to -pthread if the toolchain has pthreads support
# PTHREAD = -pthread

## ====== configuration macros for building installer ===========

# location where Inno Setup 5.[34].x was installed. Spaces allowed.
ISDIR = D:/home/inno5

# optional location where qpdf was installed (in $(QPDF)/bin). Spaces
allowed.
QPDF = D:/home/qpdf/bin

# home of 32-bit files for combined installer on 64-bit build
# HOME32 =

# Full paths of extra DLLs that need to be shipped
# e.g
# DLLs32 = c:/R/bin/pthreadGC2-w32.dll
# DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
# DLLs32 =
# DLLs64 =


## ====== configuration macros for building MSI installer ===========

# location where WiX 3.x executables were installed. Spaces allowed.
# The MSI uses '/bin': other packagings may not
# WIX3DIR = C:/packages/WiX3.5/bin

# set to 1 for a non-elevated per-user installer
# WIX_PERSONAL = 0

## =============== end of user-customizable parts  ===================

-----------------------------------------------------------------------------------

I will go through your latest post and see what are the differences. I have
used the latest version of R 3.4.3 with the latest version of rtools:
Rtools34.exe.

Not sure why but i have feeling that the culprit might be a setting in the
MkRules.

Regards,
Indrajit

On Fri, Feb 9, 2018 at 10:53 AM, Avraham Adler <avraham.adler at gmail.com>
wrote:

> On Thu, Feb 8, 2018 at 9:44 PM, Indrajit Sen Gupta <indrajitsg at gmail.com>
> wrote:
> > Hi All,
> >
> > I am trying to compile R from source on a 64 bit Windows.
>
> [snip]
>
> > I had compiled earlier with MinGW and had created the file:
> > *libopenblas_haswell-r0.2.20.a. *
>
> Hello, Indrajit.
>
> I don't see your MkRules.local attached. In any event, perhaps try
> following the directions here [1]. I've been building R with OpenBLAS
> on Windows 64 for years and it almost always works. In the past year
> or two, rarely, it will stop with an error. But if you restart the
> make process (by just typing "make" again) it finishes with no issues
> and passes make check-devel. I have not tried this with R-dev, though.
> R 3.4.3 Patched (2018-01-03 r74042) is the most recent I have built
> successfully.
>
> Good luck,
>
> Avraham
>
> [1] https://www.avrahamadler.com/r-tips/build-openblas-for-windows-r64/
>

	[[alternative HTML version deleted]]


From indrajitsg at gmail.com  Fri Feb  9 08:16:31 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Fri, 9 Feb 2018 12:46:31 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
Message-ID: <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>

Hi Avraham,

A quick question - I realized I did not have *Perl* installed. So I
installed *ActiveState Perl* right now. Also I see I need *texinfo* and
*texi2any*. I was able to installed *texinfo* from here:
http://gnuwin32.sourceforge.net/packages/texinfo.htm. But not sure where to
get *texi2any*. Can you guide me in this step?

Regards,
Indrajit

On Fri, Feb 9, 2018 at 11:58 AM, Indrajit Sen Gupta <indrajitsg at gmail.com>
wrote:

> Hi Avraham,
>
> What a coincidence, I have been following this post of yours: https://www.
> avrahamadler.com/2013/10/24/an-openblas-based-rblas-for-
> windows-64-step-by-step/
>
> Looks like this post is slightly older than what you have shared
> previously. It is strange that you did not get the attachments. I am
> pasting the contents of the MkRules.local here:
>
> -------------------------------------------------------------------
>
> #-*- Makefile -*-
>
> ## This is only used when building R itself but it does customize
> ## etc/*/Makeconf using LOCAL_SOFT, BINPREF[64], IMPLIB and R_ARCH
>
> ## Customize by copying to MkRules.local and uncommenting and editing
> ## some of the definitions there.
> ##
>
> ## =========== configuration macros for building packages ================
> # Absolute path to '/usr/local' software collection.  The versions used
> # on CRAN can be found at https://www.stats.ox.ac.uk/pub/Rtools/libs.html
> # It can be interrogated by 'R CMD config LOCAL_SOFT'
> # Use 'make rsync-extsoft' to populate the default directory.
> # LOCAL_SOFT = D:/R64/extsoft
>
> ## ============== configuration macros for building R ===================
>
> # Path of library directory containing zlib, bzlib, liblzma, pcre,
> # libpng, libjpeg, libtiff.
> # Use 'make rsync-extsoft' to populate the default directory.
> EXT_LIBS = D:/R64/extsoft
>
> # an alternative is to use -gstabs here, if the debugger supports only
> stabs.
> # G_FLAG = -gdwarf-2
>
> # Set to YES and specify the path if you want to use the ATLAS BLAS.
> USE_ATLAS = YES
> ATLAS_PATH =D:/home/thread0
>
> # Support for the ACML and Goto BLASes has been withdrawn: see R-admin.html
>
> # Define to use svnversion to set SVN-REVISION (slow, and requires a clean
> # checkout with no modifications).
> # USE_SVNVERSION = YES
>
> # With the previously recommended gcc 4.6.3 toolchain, set this to 32 or 64
> # MULTI = 64
> # If the toolchain's bin directory is not in your path, set this to the
> path
> # (including the trailing /, and use / not \).
> # TOOL_PATH =
> # for other toolchains leave these empty and set the more detailed options
> below
>
> # With the recommended gcc 4.9.3 toolchain or another toolchain, set
> # BINPREF and BINPREF64 (below) to the respective bin directories.
> # Include the trailing /, and use / not \.
> # Do this in the more detailed options below
> # Set this to 32 or 64
> WIN = 64
>
>
> ### BEGIN more detailed options
> # Some of the toolchains have prefixes for e.g. ar, gcc.
> # This can also be used to give the full path to the compiler,
> # including a trailing / .
> # BINPREF = c:/Rtools/mingw_32/bin/
> # prefix for 64-bit:
> BINPREF64 = D:/Rtools/mingw_64/bin/
> # Set this to indicate a non-gcc compiler and version
> # COMPILED_BY = <determined automatically>
>
> # Others use a -m64 or -m32 option to select architectures
> # M_ARCH = -m64
> # and for as (--32 or --64)
> # AS_ARCH = --64
> # and for windres (-F pe-i386 or pe-x86-64)
> # RC_ARCH = pe-x86-64
> # and for dlltool ("-m i386 --as-flags --32" vs "-m i386:x86-64 --as-flags
> --64")
> DT_ARCH = -m i386:x86-64 --as-flags --64
>
> # 32- or 64-bit Windows?
> WIN = 64
>
> # The gcc 4.9.3 64 bit toolchain is set up for the 'medium code' model and
> needs
> # to remove the .refptr and .weak entries from the exports list; this is
> the default
> # when WIN = 64, with blank for WIN = 32:
> NM_FILTER = | $(SED) -e '/[.]refptr[.]/d' -e '/[.]weak[.]/d'
>
> # We normally link directly against DLLs,
> # but this macro forces the use of import libs
> # Has been needed for some versions of MinGW-w64
> USE_IMPLIBS = YES
>
> ### END more detailed options
>
>
> # set to use ICU
> USE_ICU = YES
> # path to parent of ICU headers
> ICU_PATH = D:/home/ICU
> ICU_LIBS = -lsicuin -lsicuuc -lsicudt -lstdc++
>
> # set to use libcurl
> USE_LIBCURL = YES
> # path to parent of libcurl headers
> CURL_PATH = D:/home/curl
> # libs: for 32-bit
> # CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm -lidn
> # libs: for 64-bit
> CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm
>
> # For the cairographics devices
> # Optionally use a static build of cairographics from
> #   https://www.rforge.net/Cairo/files/cairo-current-win.tar.gz
> # and set CAIRO_HOME to the parent of the win32/win64 directories
> #
> # If CAIRO_HOME is not set the devices are not built.
> CAIRO_HOME = D:/home/cairo/src
>
> # set this to YES to build static HTML help
> BUILD_HTML = YES
>
> # unset this if you are *not* using MiKTeX
> MIKTEX = TRUE
> # Recent MiKTEX does not provide texi2dvi and needs something like
> TEXI2DVI = TEXINDEX=texindex.exe texify
>
> # for texinfo >= 5.1. If the texinfo files are installed at
> /packages/texinfo,
> # TEXI2ANY = /path/to/perl -I/packages/texinfo /packages/texinfo/texi2any
> # if you do not have texinfo (default),
> # TEXI2ANY = missing
>
> # additional optimization flags (use -mtune=native for a private build)
> EOPTS = -mtune=native
>
> # define to -fopenmp if the toolchain has OpenMP support
> # OPENMP = -fopenmp
>
> # define to -pthread if the toolchain has pthreads support
> # PTHREAD = -pthread
>
> ## ====== configuration macros for building installer ===========
>
> # location where Inno Setup 5.[34].x was installed. Spaces allowed.
> ISDIR = D:/home/inno5
>
> # optional location where qpdf was installed (in $(QPDF)/bin). Spaces
> allowed.
> QPDF = D:/home/qpdf/bin
>
> # home of 32-bit files for combined installer on 64-bit build
> # HOME32 =
>
> # Full paths of extra DLLs that need to be shipped
> # e.g
> # DLLs32 = c:/R/bin/pthreadGC2-w32.dll
> # DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
> # DLLs32 =
> # DLLs64 =
>
>
> ## ====== configuration macros for building MSI installer ===========
>
> # location where WiX 3.x executables were installed. Spaces allowed.
> # The MSI uses '/bin': other packagings may not
> # WIX3DIR = C:/packages/WiX3.5/bin
>
> # set to 1 for a non-elevated per-user installer
> # WIX_PERSONAL = 0
>
> ## =============== end of user-customizable parts  ===================
>
> ------------------------------------------------------------
> -----------------------
>
> I will go through your latest post and see what are the differences. I
> have used the latest version of R 3.4.3 with the latest version of rtools:
> Rtools34.exe.
>
> Not sure why but i have feeling that the culprit might be a setting in the
> MkRules.
>
> Regards,
> Indrajit
>
> On Fri, Feb 9, 2018 at 10:53 AM, Avraham Adler <avraham.adler at gmail.com>
> wrote:
>
>> On Thu, Feb 8, 2018 at 9:44 PM, Indrajit Sen Gupta <indrajitsg at gmail.com>
>> wrote:
>> > Hi All,
>> >
>> > I am trying to compile R from source on a 64 bit Windows.
>>
>> [snip]
>>
>> > I had compiled earlier with MinGW and had created the file:
>> > *libopenblas_haswell-r0.2.20.a. *
>>
>> Hello, Indrajit.
>>
>> I don't see your MkRules.local attached. In any event, perhaps try
>> following the directions here [1]. I've been building R with OpenBLAS
>> on Windows 64 for years and it almost always works. In the past year
>> or two, rarely, it will stop with an error. But if you restart the
>> make process (by just typing "make" again) it finishes with no issues
>> and passes make check-devel. I have not tried this with R-dev, though.
>> R 3.4.3 Patched (2018-01-03 r74042) is the most recent I have built
>> successfully.
>>
>> Good luck,
>>
>> Avraham
>>
>> [1] https://www.avrahamadler.com/r-tips/build-openblas-for-windows-r64/
>>
>
>

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Fri Feb  9 09:34:43 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 9 Feb 2018 09:34:43 +0100
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
Message-ID: <ac52d5ab-f8ae-1447-1e5e-c06b972cd54b@gmail.com>

Please note that building R on Windows is documented in "R Installation 
and Administration", including links to external software. Particularly 
there is a link to texinfo which is part of Rtools. The documentation is 
maintained and it is a sufficient source of information for building R 
on Windows.

https://cran.r-project.org/doc/manuals/r-release/R-admin.html
https://cran.r-project.org/bin/windows/base/rw-FAQ.html

Tomas

On 02/09/2018 08:16 AM, Indrajit Sen Gupta wrote:
> Hi Avraham,
>
> A quick question - I realized I did not have *Perl* installed. So I
> installed *ActiveState Perl* right now. Also I see I need *texinfo* and
> *texi2any*. I was able to installed *texinfo* from here:
> http://gnuwin32.sourceforge.net/packages/texinfo.htm. But not sure where to
> get *texi2any*. Can you guide me in this step?
>
> Regards,
> Indrajit
>
> On Fri, Feb 9, 2018 at 11:58 AM, Indrajit Sen Gupta <indrajitsg at gmail.com>
> wrote:
>
>> Hi Avraham,
>>
>> What a coincidence, I have been following this post of yours: https://www.
>> avrahamadler.com/2013/10/24/an-openblas-based-rblas-for-
>> windows-64-step-by-step/
>>
>> Looks like this post is slightly older than what you have shared
>> previously. It is strange that you did not get the attachments. I am
>> pasting the contents of the MkRules.local here:
>>
>> -------------------------------------------------------------------
>>
>> #-*- Makefile -*-
>>
>> ## This is only used when building R itself but it does customize
>> ## etc/*/Makeconf using LOCAL_SOFT, BINPREF[64], IMPLIB and R_ARCH
>>
>> ## Customize by copying to MkRules.local and uncommenting and editing
>> ## some of the definitions there.
>> ##
>>
>> ## =========== configuration macros for building packages ================
>> # Absolute path to '/usr/local' software collection.  The versions used
>> # on CRAN can be found at https://www.stats.ox.ac.uk/pub/Rtools/libs.html
>> # It can be interrogated by 'R CMD config LOCAL_SOFT'
>> # Use 'make rsync-extsoft' to populate the default directory.
>> # LOCAL_SOFT = D:/R64/extsoft
>>
>> ## ============== configuration macros for building R ===================
>>
>> # Path of library directory containing zlib, bzlib, liblzma, pcre,
>> # libpng, libjpeg, libtiff.
>> # Use 'make rsync-extsoft' to populate the default directory.
>> EXT_LIBS = D:/R64/extsoft
>>
>> # an alternative is to use -gstabs here, if the debugger supports only
>> stabs.
>> # G_FLAG = -gdwarf-2
>>
>> # Set to YES and specify the path if you want to use the ATLAS BLAS.
>> USE_ATLAS = YES
>> ATLAS_PATH =D:/home/thread0
>>
>> # Support for the ACML and Goto BLASes has been withdrawn: see R-admin.html
>>
>> # Define to use svnversion to set SVN-REVISION (slow, and requires a clean
>> # checkout with no modifications).
>> # USE_SVNVERSION = YES
>>
>> # With the previously recommended gcc 4.6.3 toolchain, set this to 32 or 64
>> # MULTI = 64
>> # If the toolchain's bin directory is not in your path, set this to the
>> path
>> # (including the trailing /, and use / not \).
>> # TOOL_PATH =
>> # for other toolchains leave these empty and set the more detailed options
>> below
>>
>> # With the recommended gcc 4.9.3 toolchain or another toolchain, set
>> # BINPREF and BINPREF64 (below) to the respective bin directories.
>> # Include the trailing /, and use / not \.
>> # Do this in the more detailed options below
>> # Set this to 32 or 64
>> WIN = 64
>>
>>
>> ### BEGIN more detailed options
>> # Some of the toolchains have prefixes for e.g. ar, gcc.
>> # This can also be used to give the full path to the compiler,
>> # including a trailing / .
>> # BINPREF = c:/Rtools/mingw_32/bin/
>> # prefix for 64-bit:
>> BINPREF64 = D:/Rtools/mingw_64/bin/
>> # Set this to indicate a non-gcc compiler and version
>> # COMPILED_BY = <determined automatically>
>>
>> # Others use a -m64 or -m32 option to select architectures
>> # M_ARCH = -m64
>> # and for as (--32 or --64)
>> # AS_ARCH = --64
>> # and for windres (-F pe-i386 or pe-x86-64)
>> # RC_ARCH = pe-x86-64
>> # and for dlltool ("-m i386 --as-flags --32" vs "-m i386:x86-64 --as-flags
>> --64")
>> DT_ARCH = -m i386:x86-64 --as-flags --64
>>
>> # 32- or 64-bit Windows?
>> WIN = 64
>>
>> # The gcc 4.9.3 64 bit toolchain is set up for the 'medium code' model and
>> needs
>> # to remove the .refptr and .weak entries from the exports list; this is
>> the default
>> # when WIN = 64, with blank for WIN = 32:
>> NM_FILTER = | $(SED) -e '/[.]refptr[.]/d' -e '/[.]weak[.]/d'
>>
>> # We normally link directly against DLLs,
>> # but this macro forces the use of import libs
>> # Has been needed for some versions of MinGW-w64
>> USE_IMPLIBS = YES
>>
>> ### END more detailed options
>>
>>
>> # set to use ICU
>> USE_ICU = YES
>> # path to parent of ICU headers
>> ICU_PATH = D:/home/ICU
>> ICU_LIBS = -lsicuin -lsicuuc -lsicudt -lstdc++
>>
>> # set to use libcurl
>> USE_LIBCURL = YES
>> # path to parent of libcurl headers
>> CURL_PATH = D:/home/curl
>> # libs: for 32-bit
>> # CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
>> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm -lidn
>> # libs: for 64-bit
>> CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
>> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm
>>
>> # For the cairographics devices
>> # Optionally use a static build of cairographics from
>> #   https://www.rforge.net/Cairo/files/cairo-current-win.tar.gz
>> # and set CAIRO_HOME to the parent of the win32/win64 directories
>> #
>> # If CAIRO_HOME is not set the devices are not built.
>> CAIRO_HOME = D:/home/cairo/src
>>
>> # set this to YES to build static HTML help
>> BUILD_HTML = YES
>>
>> # unset this if you are *not* using MiKTeX
>> MIKTEX = TRUE
>> # Recent MiKTEX does not provide texi2dvi and needs something like
>> TEXI2DVI = TEXINDEX=texindex.exe texify
>>
>> # for texinfo >= 5.1. If the texinfo files are installed at
>> /packages/texinfo,
>> # TEXI2ANY = /path/to/perl -I/packages/texinfo /packages/texinfo/texi2any
>> # if you do not have texinfo (default),
>> # TEXI2ANY = missing
>>
>> # additional optimization flags (use -mtune=native for a private build)
>> EOPTS = -mtune=native
>>
>> # define to -fopenmp if the toolchain has OpenMP support
>> # OPENMP = -fopenmp
>>
>> # define to -pthread if the toolchain has pthreads support
>> # PTHREAD = -pthread
>>
>> ## ====== configuration macros for building installer ===========
>>
>> # location where Inno Setup 5.[34].x was installed. Spaces allowed.
>> ISDIR = D:/home/inno5
>>
>> # optional location where qpdf was installed (in $(QPDF)/bin). Spaces
>> allowed.
>> QPDF = D:/home/qpdf/bin
>>
>> # home of 32-bit files for combined installer on 64-bit build
>> # HOME32 =
>>
>> # Full paths of extra DLLs that need to be shipped
>> # e.g
>> # DLLs32 = c:/R/bin/pthreadGC2-w32.dll
>> # DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
>> # DLLs32 =
>> # DLLs64 =
>>
>>
>> ## ====== configuration macros for building MSI installer ===========
>>
>> # location where WiX 3.x executables were installed. Spaces allowed.
>> # The MSI uses '/bin': other packagings may not
>> # WIX3DIR = C:/packages/WiX3.5/bin
>>
>> # set to 1 for a non-elevated per-user installer
>> # WIX_PERSONAL = 0
>>
>> ## =============== end of user-customizable parts  ===================
>>
>> ------------------------------------------------------------
>> -----------------------
>>
>> I will go through your latest post and see what are the differences. I
>> have used the latest version of R 3.4.3 with the latest version of rtools:
>> Rtools34.exe.
>>
>> Not sure why but i have feeling that the culprit might be a setting in the
>> MkRules.
>>
>> Regards,
>> Indrajit
>>
>> On Fri, Feb 9, 2018 at 10:53 AM, Avraham Adler <avraham.adler at gmail.com>
>> wrote:
>>
>>> On Thu, Feb 8, 2018 at 9:44 PM, Indrajit Sen Gupta <indrajitsg at gmail.com>
>>> wrote:
>>>> Hi All,
>>>>
>>>> I am trying to compile R from source on a 64 bit Windows.
>>> [snip]
>>>
>>>> I had compiled earlier with MinGW and had created the file:
>>>> *libopenblas_haswell-r0.2.20.a. *
>>> Hello, Indrajit.
>>>
>>> I don't see your MkRules.local attached. In any event, perhaps try
>>> following the directions here [1]. I've been building R with OpenBLAS
>>> on Windows 64 for years and it almost always works. In the past year
>>> or two, rarely, it will stop with an error. But if you restart the
>>> make process (by just typing "make" again) it finishes with no issues
>>> and passes make check-devel. I have not tried this with R-dev, though.
>>> R 3.4.3 Patched (2018-01-03 r74042) is the most recent I have built
>>> successfully.
>>>
>>> Good luck,
>>>
>>> Avraham
>>>
>>> [1] https://www.avrahamadler.com/r-tips/build-openblas-for-windows-r64/
>>>
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From indrajitsg at gmail.com  Fri Feb  9 12:16:26 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Fri, 9 Feb 2018 16:46:26 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <ac52d5ab-f8ae-1447-1e5e-c06b972cd54b@gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <ac52d5ab-f8ae-1447-1e5e-c06b972cd54b@gmail.com>
Message-ID: <CAB-BrmcJbR-b8372wC06=5U7nLWo_DJ+=Mii0BLEafx6PFacng@mail.gmail.com>

Thanks, I will take a look. But right now, the process has not reached
texinfo stage yet. The error is happening before that. Here is log from the
latest output. There is line which caught my eye:

D:\Rtools\mingw_64\bin\dlltool.exe: Syntax error in def file Rgraphapp.def:1

I am wondering if this has caused some error in the end. The full log
output is as follows:

--------------------------------------------------------------------------------------------

make --no-print-directory -C front-ends Rpwd
make -C ../../include -f Makefile.win version
make Rpwd.exe
gcc -std=gnu99 -m64 -I../../include -DR_ARCH='"x64"'  -O3 -Wall -pedantic
 -c rpwd.c -o rpwd.o
windres -F pe-x86-64 -DWN64  -i rcico.rc -o rcico.o
gcc -std=gnu99 -m64 -s  -o Rpwd.exe rpwd.o rcico.o
cp front-ends/Rpwd.exe Rpwd.exe
-------- Building ../../../library/base/R/Rprofile from
../../library/profile/Common.R
../../library/profile/Rprofile.windows--------
mkdir -p ../../../library/base/R
cp -p html/rwin.html ../../../doc/html/index.html
cp -p ./etc/Makeconf ./etc/Rcmd_environ ./etc/Rconsole ./etc/Rdevga
./etc/Rprofile.site ./etc/rgb.txt ../../../etc
rm -f ../../../etc/Makeconf
mkdir -p ../../../etc//x64
sed -e 's/WIN = 32/WIN = 64/' \
  -e "s/-O3/-O2/" \
  -e "s/@EOPTS@/-mtune=native -pipe/" \
  -e "s|BINPREF =|BINPREF ?= |" \
  -e "s|COMPILED_BY =|COMPILED_BY = gcc-4.9.3|" \
  -e "s|IMPDIR = bin|IMPDIR = lib|" \
  -e "s|LOCAL_SOFT =|LOCAL_SOFT = |" \
  -e "s|R_ARCH =|R_ARCH = /x64|" \
  -e "s|DT_ARCH =|DT_ARCH = -m i386:x86-64 --as-flags --64|" \
  -e "s|RC_ARCH =|RC_ARCH = -F pe-x86-64|" \
  -e "s|M_ARCH =|M_ARCH = -m64|" \
  -e "s|@SYMPAT@|'s/^.* [BCDRT] / /p'|" \
  -e "s|(TCL_HOME)/bin|(TCL_HOME)/bin64|" \
  -e "s|@OPENMP@|-fopenmp|" \
  -e "s|@PTHREAD@|-pthread|" \
  -e "s at NM_FILTER =@NM_FILTER = | sed -e '/[.]refptr[.]/d' -e
'/[.]weak[.]/d'@" \
  etc/Makeconf > ../../../etc/x64/Makeconf
sed -e "s+ at BINDIR@+bin/x64+" Makeconf > ../../../Makeconf
cp -p ../CHANGES0 ../CHANGES1 ../CHANGES2 ../../../doc
make[5]: Nothing to be done for `svnonly'.
installing C headers
dlltool --as as -m i386:x86-64 --as-flags --64 -k  --dllname Riconv.dll \
  --input-def unicode/iconv.def --output-lib libRiconv.dll.a
make[6]: Nothing to be done for `svnonly'.
installing C headers
make --no-print-directory -C ../extra/intl CFLAGS='-O3 -Wall -pedantic
-mtune=native -pipe' -f Makefile.win
sed -e 's,@''HAVE_POSIX_PRINTF''@,1,g' \
    -e 's,@''HAVE_ASPRINTF''@,0,g' \
    -e 's,@''HAVE_SNPRINTF''@,1,g' \
    -e 's,@''HAVE_WPRINTF''@,0,g' \
  < libgnuintl.h.in > libgnuintl.h
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c bindtextdom.c -o bindtextdom.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c dcgettext.c -o dcgettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c dgettext.c -o dgettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c gettext.c -o gettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c finddomain.c -o finddomain.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c loadmsgcat.c -o loadmsgcat.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c textdomain.c -o textdomain.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c l10nflist.c -o l10nflist.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c explodename.c -o explodename.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include
-DLOCALEDIR=\"\" -O3 -Wall -pedantic -mtune=native -pipe   -c dcigettext.c
-o dcigettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c dcngettext.c -o dcngettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c dngettext.c -o dngettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c ngettext.c -o ngettext.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c plural.c -o plural.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c plural-exp.c -o plural-exp.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c langprefs.c -o langprefs.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c localcharset.c -o localcharset.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c localename.c -o localename.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c printf.c -o printf.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c osdep.c -o osdep.o
gcc -std=gnu99 -m64 -DIN_LIBINTL -DHAVE_CONFIG_H -I. -I../../include  -O3
-Wall -pedantic -mtune=native -pipe   -c hash-string.c -o hash-string.o
ar crs libintl.a bindtextdom.o dcgettext.o dgettext.o gettext.o
finddomain.o loadmsgcat.o textdomain.o l10nflist.o explodename.o
dcigettext.o dcngettext.o dngettext.o ngettext.o plural.o plural-exp.o
langprefs.o localcharset.o localename.o printf.o osdep.o hash-string.o
cp libgnuintl.h libintl.h
make --no-print-directory -C ../appl CFLAGS='-O3 -Wall -pedantic
-mtune=native -pipe' FFLAGS='-O3 -mtune=native -pipe' -f Makefile.win
making integrate.d from integrate.c
making interv.d from interv.c
making maxcol.d from maxcol.c
making optim.d from optim.c
making pretty.d from pretty.c
making uncmin.d from uncmin.c
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c integrate.c -o integrate.o
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c interv.c -o interv.o
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c maxcol.c -o maxcol.o
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c optim.c -o optim.o
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c pretty.c -o pretty.o
gcc -std=gnu99 -m64 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall
-pedantic -mtune=native -pipe   -c uncmin.c -o uncmin.o
gfortran -m64 -O3 -mtune=native -pipe  -c dchdc.f -o dchdc.o
gfortran -m64 -O3 -mtune=native -pipe  -c dpbfa.f -o dpbfa.o
gfortran -m64 -O3 -mtune=native -pipe  -c dpbsl.f -o dpbsl.o
gfortran -m64 -O3 -mtune=native -pipe  -c dpoco.f -o dpoco.o
gfortran -m64 -O3 -mtune=native -pipe  -c dpodi.f -o dpodi.o
gfortran -m64 -O3 -mtune=native -pipe  -c dpofa.f -o dpofa.o
gfortran -m64 -O3 -mtune=native -pipe  -c dposl.f -o dposl.o
gfortran -m64 -O3 -mtune=native -pipe  -c dqrdc.f -o dqrdc.o
gfortran -m64 -O3 -mtune=native -pipe  -c dqrdc2.f -o dqrdc2.o
gfortran -m64 -O3 -mtune=native -pipe  -c dqrls.f -o dqrls.o
gfortran -m64 -O3 -mtune=native -pipe  -c dqrsl.f -o dqrsl.o
gfortran -m64 -O3 -mtune=native -pipe  -c dqrutl.f -o dqrutl.o
gfortran -m64 -O3 -mtune=native -pipe  -c dsvdc.f -o dsvdc.o
gfortran -m64 -O3 -mtune=native -pipe  -c dtrco.f -o dtrco.o
gfortran -m64 -O3 -mtune=native -pipe  -c dtrsl.f -o dtrsl.o
ar crs libappl.a integrate.o interv.o maxcol.o optim.o pretty.o uncmin.o
dchdc.o dpbfa.o dpbsl.o dpoco.o dpodi.o dpofa.o dposl.o dqrdc.o dqrdc2.o
dqrls.o dqrsl.o dqrutl.o dsvdc.o dtrco.o dtrsl.o
make --no-print-directory -C ../nmath CFLAGS='-O3 -Wall -pedantic
-mtune=native -pipe' FFLAGS='-O3 -mtune=native -pipe' -f Makefile.win
making mlutils.d from mlutils.c
making d1mach.d from d1mach.c
making i1mach.d from i1mach.c
making fmax2.d from fmax2.c
making fmin2.d from fmin2.c
making fprec.d from fprec.c
making fround.d from fround.c
making ftrunc.d from ftrunc.c
making sign.d from sign.c
making fsign.d from fsign.c
making imax2.d from imax2.c
making imin2.d from imin2.c
making chebyshev.d from chebyshev.c
making log1p.d from log1p.c
making expm1.d from expm1.c
making lgammacor.d from lgammacor.c
making gammalims.d from gammalims.c
making stirlerr.d from stirlerr.c
making bd0.d from bd0.c
making gamma.d from gamma.c
making lgamma.d from lgamma.c
making gamma_cody.d from gamma_cody.c
making beta.d from beta.c
making lbeta.d from lbeta.c
making polygamma.d from polygamma.c
making cospi.d from cospi.c
making bessel_i.d from bessel_i.c
making bessel_j.d from bessel_j.c
making bessel_k.d from bessel_k.c
making bessel_y.d from bessel_y.c
making choose.d from choose.c
making snorm.d from snorm.c
making sexp.d from sexp.c
making dgamma.d from dgamma.c
making pgamma.d from pgamma.c
making qgamma.d from qgamma.c
making rgamma.d from rgamma.c
making dbeta.d from dbeta.c
making pbeta.d from pbeta.c
making qbeta.d from qbeta.c
making rbeta.d from rbeta.c
making dunif.d from dunif.c
making punif.d from punif.c
making qunif.d from qunif.c
making runif.d from runif.c
making dnorm.d from dnorm.c
making pnorm.d from pnorm.c
making qnorm.d from qnorm.c
making rnorm.d from rnorm.c
making dlnorm.d from dlnorm.c
making plnorm.d from plnorm.c
making qlnorm.d from qlnorm.c
making rlnorm.d from rlnorm.c
making df.d from df.c
making pf.d from pf.c
making qf.d from qf.c
making rf.d from rf.c
making dnf.d from dnf.c
making dt.d from dt.c
making pt.d from pt.c
making qt.d from qt.c
making rt.d from rt.c
making dnt.d from dnt.c
making dchisq.d from dchisq.c
making pchisq.d from pchisq.c
making qchisq.d from qchisq.c
making rchisq.d from rchisq.c
making rnchisq.d from rnchisq.c
making dbinom.d from dbinom.c
making pbinom.d from pbinom.c
making qbinom.d from qbinom.c
making rbinom.d from rbinom.c
making rmultinom.d from rmultinom.c
making dcauchy.d from dcauchy.c
making pcauchy.d from pcauchy.c
making qcauchy.d from qcauchy.c
making rcauchy.d from rcauchy.c
making dexp.d from dexp.c
making pexp.d from pexp.c
making qexp.d from qexp.c
making rexp.d from rexp.c
making dgeom.d from dgeom.c
making pgeom.d from pgeom.c
making qgeom.d from qgeom.c
making rgeom.d from rgeom.c
making dhyper.d from dhyper.c
making phyper.d from phyper.c
making qhyper.d from qhyper.c
making rhyper.d from rhyper.c
making dnbinom.d from dnbinom.c
making pnbinom.d from pnbinom.c
making qnbinom.d from qnbinom.c
making rnbinom.d from rnbinom.c
making dpois.d from dpois.c
making ppois.d from ppois.c
making qpois.d from qpois.c
making rpois.d from rpois.c
making dweibull.d from dweibull.c
making pweibull.d from pweibull.c
making qweibull.d from qweibull.c
making rweibull.d from rweibull.c
making dlogis.d from dlogis.c
making plogis.d from plogis.c
making qlogis.d from qlogis.c
making rlogis.d from rlogis.c
making dnchisq.d from dnchisq.c
making pnchisq.d from pnchisq.c
making qnchisq.d from qnchisq.c
making dnbeta.d from dnbeta.c
making pnbeta.d from pnbeta.c
making qnbeta.d from qnbeta.c
making pnf.d from pnf.c
making pnt.d from pnt.c
making qnf.d from qnf.c
making qnt.d from qnt.c
making ptukey.d from ptukey.c
making qtukey.d from qtukey.c
making toms708.d from toms708.c
making wilcox.d from wilcox.c
making signrank.d from signrank.c
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c mlutils.c -o mlutils.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c d1mach.c -o d1mach.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c i1mach.c -o i1mach.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c fmax2.c -o fmax2.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c fmin2.c -o fmin2.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c fprec.c -o fprec.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c fround.c -o fround.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c ftrunc.c -o ftrunc.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c sign.c -o sign.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c fsign.c -o fsign.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c imax2.c -o imax2.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c imin2.c -o imin2.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c chebyshev.c -o chebyshev.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c log1p.c -o log1p.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c expm1.c -o expm1.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c lgammacor.c -o lgammacor.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c gammalims.c -o gammalims.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c stirlerr.c -o stirlerr.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c bd0.c -o bd0.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c gamma.c -o gamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c lgamma.c -o lgamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c gamma_cody.c -o gamma_cody.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c beta.c -o beta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c lbeta.c -o lbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c polygamma.c -o polygamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c cospi.c -o cospi.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c bessel_i.c -o bessel_i.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c bessel_j.c -o bessel_j.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c bessel_k.c -o bessel_k.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c bessel_y.c -o bessel_y.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c choose.c -o choose.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c snorm.c -o snorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c sexp.c -o sexp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dgamma.c -o dgamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pgamma.c -o pgamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qgamma.c -o qgamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rgamma.c -o rgamma.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dbeta.c -o dbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pbeta.c -o pbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qbeta.c -o qbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rbeta.c -o rbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dunif.c -o dunif.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c punif.c -o punif.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qunif.c -o qunif.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c runif.c -o runif.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnorm.c -o dnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnorm.c -o pnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnorm.c -o qnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rnorm.c -o rnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dlnorm.c -o dlnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c plnorm.c -o plnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qlnorm.c -o qlnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rlnorm.c -o rlnorm.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c df.c -o df.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pf.c -o pf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qf.c -o qf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rf.c -o rf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnf.c -o dnf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dt.c -o dt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pt.c -o pt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qt.c -o qt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rt.c -o rt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnt.c -o dnt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dchisq.c -o dchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pchisq.c -o pchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qchisq.c -o qchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rchisq.c -o rchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rnchisq.c -o rnchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dbinom.c -o dbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pbinom.c -o pbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qbinom.c -o qbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rbinom.c -o rbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rmultinom.c -o rmultinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dcauchy.c -o dcauchy.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pcauchy.c -o pcauchy.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qcauchy.c -o qcauchy.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rcauchy.c -o rcauchy.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dexp.c -o dexp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pexp.c -o pexp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qexp.c -o qexp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rexp.c -o rexp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dgeom.c -o dgeom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pgeom.c -o pgeom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qgeom.c -o qgeom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rgeom.c -o rgeom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dhyper.c -o dhyper.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c phyper.c -o phyper.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qhyper.c -o qhyper.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rhyper.c -o rhyper.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnbinom.c -o dnbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnbinom.c -o pnbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnbinom.c -o qnbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rnbinom.c -o rnbinom.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dpois.c -o dpois.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c ppois.c -o ppois.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qpois.c -o qpois.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rpois.c -o rpois.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dweibull.c -o dweibull.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pweibull.c -o pweibull.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qweibull.c -o qweibull.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rweibull.c -o rweibull.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dlogis.c -o dlogis.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c plogis.c -o plogis.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qlogis.c -o qlogis.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c rlogis.c -o rlogis.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnchisq.c -o dnchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnchisq.c -o pnchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnchisq.c -o qnchisq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c dnbeta.c -o dnbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnbeta.c -o pnbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnbeta.c -o qnbeta.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnf.c -o pnf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c pnt.c -o pnt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnf.c -o qnf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qnt.c -o qnt.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c ptukey.c -o ptukey.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c qtukey.c -o qtukey.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c toms708.c -o toms708.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c wilcox.c -o wilcox.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3
-Wall -pedantic -mtune=native -pipe   -c signrank.c -o signrank.o
ar crs libnmath.a mlutils.o d1mach.o i1mach.o fmax2.o fmin2.o fprec.o
fround.o ftrunc.o sign.o fsign.o imax2.o imin2.o chebyshev.o log1p.o
expm1.o lgammacor.o gammalims.o stirlerr.o bd0.o gamma.o lgamma.o
gamma_cody.o beta.o lbeta.o polygamma.o cospi.o bessel_i.o bessel_j.o
bessel_k.o bessel_y.o choose.o snorm.o sexp.o dgamma.o pgamma.o qgamma.o
rgamma.o dbeta.o pbeta.o qbeta.o rbeta.o dunif.o punif.o qunif.o runif.o
dnorm.o pnorm.o qnorm.o rnorm.o dlnorm.o plnorm.o qlnorm.o rlnorm.o df.o
pf.o qf.o rf.o dnf.o dt.o pt.o qt.o rt.o dnt.o dchisq.o pchisq.o qchisq.o
rchisq.o rnchisq.o dbinom.o pbinom.o qbinom.o rbinom.o rmultinom.o
dcauchy.o pcauchy.o qcauchy.o rcauchy.o dexp.o pexp.o qexp.o rexp.o dgeom.o
pgeom.o qgeom.o rgeom.o dhyper.o phyper.o qhyper.o rhyper.o dnbinom.o
pnbinom.o qnbinom.o rnbinom.o dpois.o ppois.o qpois.o rpois.o dweibull.o
pweibull.o qweibull.o rweibull.o dlogis.o plogis.o qlogis.o rlogis.o
dnchisq.o pnchisq.o qnchisq.o dnbeta.o pnbeta.o qnbeta.o pnf.o pnt.o qnf.o
qnt.o ptukey.o qtukey.o toms708.o wilcox.o signrank.o
make --no-print-directory -C ../main CFLAGS='-O3 -Wall -pedantic
-mtune=native -pipe' FFLAGS='-O3 -mtune=native -pipe' malloc-DEFS='' -f
Makefile.win
making CommandLineArgs.d from CommandLineArgs.c
making Rdynload.d from Rdynload.c
making Renviron.d from Renviron.c
making RNG.d from RNG.c
making agrep.d from agrep.c
making apply.d from apply.c
making arithmetic.d from arithmetic.c
making array.d from array.c
making attrib.d from attrib.c
making bind.d from bind.c
making builtin.d from builtin.c
making character.d from character.c
making coerce.d from coerce.c
making colors.d from colors.c
making complex.d from complex.c
making connections.d from connections.c
making context.d from context.c
making cum.d from cum.c
making dcf.d from dcf.c
making datetime.d from datetime.c
making debug.d from debug.c
making deparse.d from deparse.c
making devices.d from devices.c
making dotcode.d from dotcode.c
making dounzip.d from dounzip.c
making dstruct.d from dstruct.c
making duplicate.d from duplicate.c
making edit.d from edit.c
making engine.d from engine.c
making envir.d from envir.c
making errors.d from errors.c
making eval.d from eval.c
making format.d from format.c
making gevents.d from gevents.c
making gram.d from gram.c
making gram-ex.d from gram-ex.c
making graphics.d from graphics.c
making grep.d from grep.c
making identical.d from identical.c
making inlined.d from inlined.c
making inspect.d from inspect.c
making internet.d from internet.c
making iosupport.d from iosupport.c
making lapack.d from lapack.c
making list.d from list.c
making localecharset.d from localecharset.c
making logic.d from logic.c
making main.d from main.c
making mapply.d from mapply.c
making match.d from match.c
making memory.d from memory.c
making mkdtemp.d from mkdtemp.c
making names.d from names.c
making objects.d from objects.c
making options.d from options.c
making paste.d from paste.c
making platform.d from platform.c
making plot.d from plot.c
making plot3d.d from plot3d.c
making plotmath.d from plotmath.c
making print.d from print.c
making printarray.d from printarray.c
making printvector.d from printvector.c
making printutils.d from printutils.c
making qsort.d from qsort.c
making radixsort.d from radixsort.c
making random.d from random.c
making raw.d from raw.c
making registration.d from registration.c
making relop.d from relop.c
making rlocale.d from rlocale.c
making saveload.d from saveload.c
making scan.d from scan.c
making seq.d from seq.c
making serialize.d from serialize.c
making sort.d from sort.c
making source.d from source.c
making split.d from split.c
making sprintf.d from sprintf.c
making startup.d from startup.c
making subassign.d from subassign.c
making subscript.d from subscript.c
making subset.d from subset.c
making summary.d from summary.c
making sysutils.d from sysutils.c
making times.d from times.c
making unique.d from unique.c
making util.d from util.c
making version.d from version.c
making g_alab_her.d from g_alab_her.c
making g_cntrlify.d from g_cntrlify.c
making g_fontdb.d from g_fontdb.c
making g_her_glyph.d from g_her_glyph.c
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c
CommandLineArgs.c -o CommandLineArgs.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c Rdynload.c
-o Rdynload.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c Renviron.c
-o Renviron.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../nmath -O3 -Wall -pedantic -mtune=native -pipe   -c
RNG.c -o RNG.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../extra -O3 -Wall -pedantic -mtune=native -pipe   -c
agrep.c -o agrep.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c apply.c -o
apply.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c arithmetic.c
-o arithmetic.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c array.c -o
array.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c attrib.c -o
attrib.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c bind.c -o
bind.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../gnuwin32 -O3 -Wall -pedantic -mtune=native -pipe   -c
builtin.c -o builtin.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c character.c
-o character.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c coerce.c -o
coerce.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c colors.c -o
colors.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c complex.c -o
complex.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -DLZMA_API_STATIC -I"D:/R64/extsoft"/include
-DHAVE_CURL_CURL_H -DHAVE_LIBCURL -O3 -Wall -pedantic -mtune=native -pipe
 -c connections.c -o connections.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c context.c -o
context.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c cum.c -o
cum.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../extra -O3 -Wall -pedantic -mtune=native -pipe   -c
dcf.c -o dcf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c datetime.c
-o datetime.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c debug.c -o
debug.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe -Wno-format  -c
deparse.c -o deparse.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c devices.c -o
devices.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c dotcode.c -o
dotcode.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -ID:/R64/extsoft/include -O3 -Wall -pedantic -mtune=native
-pipe   -c dounzip.c -o dounzip.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c dstruct.c -o
dstruct.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c duplicate.c
-o duplicate.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../gnuwin32 -O3 -Wall -pedantic -mtune=native -pipe   -c
edit.c -o edit.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c engine.c -o
engine.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c envir.c -o
envir.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c errors.c -o
errors.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c eval.c -o
eval.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c format.c -o
format.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c gevents.c -o
gevents.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c gram.c -o
gram.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c gram-ex.c -o
gram-ex.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c graphics.c
-o graphics.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -DPCRE_STATIC -I../extra -I../gnuwin32
-I"D:/R64/extsoft"/include -O3 -Wall -pedantic -mtune=native -pipe   -c
grep.c -o grep.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c identical.c
-o identical.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c inlined.c -o
inlined.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c inspect.c -o
inspect.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c internet.c
-o internet.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c iosupport.c
-o iosupport.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c lapack.c -o
lapack.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c list.c -o
list.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c
localecharset.c -o localecharset.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c logic.c -o
logic.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c main.c -o
main.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c mapply.c -o
mapply.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c match.c -o
match.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c memory.c -o
memory.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c mkdtemp.c -o
mkdtemp.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c names.c -o
names.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c objects.c -o
objects.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c options.c -o
options.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c paste.c -o
paste.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../gnuwin32 -I../extra -DPLATFORM_PKGTYPE='"win.binary"'
-DPCRE_STATIC -DLZMA_API_STATIC -I"D:/R64/extsoft"/include -DUSE_ICU
-I"D:/home/ICU"/include -DHAVE_CURL_CURL_H -DHAVE_LIBCURL -O3 -Wall
-pedantic -mtune=native -pipe   -c platform.c -o platform.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c plot.c -o
plot.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c plot3d.c -o
plot3d.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c plotmath.c
-o plotmath.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c print.c -o
print.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c printarray.c
-o printarray.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c
printvector.c -o printvector.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../gnuwin32 -O3 -Wall -pedantic -mtune=native -pipe   -c
printutils.c -o printutils.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c qsort.c -o
qsort.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c radixsort.c
-o radixsort.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c random.c -o
random.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c raw.c -o
raw.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c
registration.c -o registration.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c relop.c -o
relop.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c rlocale.c -o
rlocale.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../extra/xdr -O3 -Wall -pedantic -mtune=native -pipe
 -c saveload.c -o saveload.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c scan.c -o
scan.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c seq.c -o
seq.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../extra/xdr -O3 -Wall -pedantic -mtune=native -pipe
 -c serialize.c -o serialize.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c sort.c -o
sort.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c source.c -o
source.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c split.c -o
split.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c sprintf.c -o
sprintf.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c startup.c -o
startup.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c subassign.c
-o subassign.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c subscript.c
-o subscript.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c subset.c -o
subset.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c summary.c -o
summary.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -I../gnuwin32 -O3 -Wall -pedantic -mtune=native -pipe   -c
sysutils.c -o sysutils.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c times.c -o
times.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c unique.c -o
unique.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"' -DLZMA_API_STATIC -I"D:/R64/extsoft"/include -DUSE_ICU
-I"D:/home/ICU"/include -O3 -Wall -pedantic -mtune=native -pipe   -c util.c
-o util.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c version.c -o
version.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c g_alab_her.c
-o g_alab_her.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c g_cntrlify.c
-o g_cntrlify.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c g_fontdb.c
-o g_fontdb.o
gcc -std=gnu99 -m64 -I. -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD
-DR_ARCH='"x64"'  -O3 -Wall -pedantic -mtune=native -pipe   -c
g_her_glyph.c -o g_her_glyph.o
gfortran -m64 -O3 -mtune=native -pipe  -c xxxpr.f -o xxxpr.o
ar crs libmain.a CommandLineArgs.o Rdynload.o Renviron.o RNG.o agrep.o
apply.o arithmetic.o array.o attrib.o bind.o builtin.o character.o coerce.o
colors.o complex.o connections.o context.o cum.o dcf.o datetime.o debug.o
deparse.o devices.o dotcode.o dounzip.o dstruct.o duplicate.o edit.o
engine.o envir.o errors.o eval.o format.o gevents.o gram.o gram-ex.o
graphics.o grep.o identical.o inlined.o inspect.o internet.o iosupport.o
lapack.o list.o localecharset.o logic.o main.o mapply.o match.o memory.o
mkdtemp.o names.o objects.o options.o paste.o platform.o plot.o plot3d.o
plotmath.o print.o printarray.o printvector.o printutils.o qsort.o
radixsort.o random.o raw.o registration.o relop.o rlocale.o saveload.o
scan.o seq.o serialize.o sort.o source.o split.o sprintf.o startup.o
subassign.o subscript.o subset.o summary.o sysutils.o times.o unique.o
util.o version.o g_alab_her.o g_cntrlify.o g_fontdb.o g_her_glyph.o xxxpr.o
make --no-print-directory -C ./getline CFLAGS='-O3 -Wall -pedantic
-mtune=native -pipe'
gcc -std=gnu99 -m64 -DWin32 -I. -I../../include  -O3 -Wall -pedantic
-mtune=native -pipe   -c getline.c -o getline.o
gcc -std=gnu99 -m64 -DWin32 -I. -I../../include  -O3 -Wall -pedantic
-mtune=native -pipe   -c wc_history.c -o wc_history.o
ar crs gl.a getline.o wc_history.o
making arith.d from arith.c
making array.d from array.c
making bitmaps.d from bitmaps.c
making buttons.d from buttons.c
making clipboard.d from clipboard.c
making context.d from context.c
making controls.d from controls.c
making cursors.d from cursors.c
making dialogs.d from dialogs.c
making drawing.d from drawing.c
making drawtext.d from drawtext.c
making events.d from events.c
making fonts.d from fonts.c
making gbuttons.d from gbuttons.c
making gdraw.d from gdraw.c
making gif.d from gif.c
making gimage.d from gimage.c
making gmenus.d from gmenus.c
making image.d from image.c
making init.d from init.c
making menus.d from menus.c
making metafile.d from metafile.c
making objects.d from objects.c
making printer.d from printer.c
making rgb.d from rgb.c
making status.d from status.c
making stdimg.d from stdimg.c
making strings.d from strings.c
making tooltips.d from tooltips.c
making windows.d from windows.c
dlltool --as as -m i386:x86-64 --as-flags --64 -k  --dllname R.dll
--input-def R.def --output-lib libR.dll.a
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c arith.c -o
arith.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c array.c -o
array.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c bitmaps.c -o
bitmaps.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c buttons.c -o
buttons.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c clipboard.c -o
clipboard.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c context.c -o
context.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c controls.c -o
controls.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c cursors.c -o
cursors.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c dialogs.c -o
dialogs.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c drawing.c -o
drawing.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c drawtext.c -o
drawtext.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c events.c -o
events.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c fonts.c -o
fonts.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c gbuttons.c -o
gbuttons.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c gdraw.c -o
gdraw.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c gif.c -o gif.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c gimage.c -o
gimage.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c gmenus.c -o
gmenus.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c image.c -o
image.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c init.c -o
init.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c menus.c -o
menus.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c metafile.c -o
metafile.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c objects.c -o
objects.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c printer.c -o
printer.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c rgb.c -o rgb.o
In file included from ga.h:29:0,
                 from rgb.c:32:
graphapp.h:43:23: note: previous declaration of 'GAbyte' was here
 typedef unsigned char GAbyte;
                       ^
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c status.c -o
status.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c stdimg.c -o
stdimg.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c strings.c -o
strings.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c tooltips.c -o
tooltips.o
gcc -std=gnu99 -m64 -I. -I../../gnuwin32 -I../../include -DGA_DLL_BUILD
-DENABLE_NLS=1  -O3 -Wall -pedantic -mtune=native -pipe   -c windows.c -o
windows.o
windres -F pe-x86-64   -i dllversion.rc -o dllversion.o
gcc -std=gnu99 -m64 -shared -mwindows -o Rgraphapp.dll Rgraphapp.def
arith.o array.o bitmaps.o buttons.o clipboard.o context.o controls.o
cursors.o dialogs.o drawing.o drawtext.o events.o fonts.o gbuttons.o
gdraw.o gif.o gimage.o gmenus.o image.o init.o menus.o metafile.o objects.o
printer.o rgb.o status.o stdimg.o strings.o tooltips.o windows.o
dllversion.o -L. -lR -lcomctl32 -limm32 -lmsimg32
dlltool --as as -m i386:x86-64 --as-flags --64 -k  --dllname Rgraphapp.dll
--input-def Rgraphapp.def --output-lib libRgraphapp.dll.a
D:\Rtools\mingw_64\bin\dlltool.exe: Syntax error in def file Rgraphapp.def:1
gcc -std=gnu99 -m64 -I. -I../../include -DWIN32 -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c xdr.c -o xdr.o
gcc -std=gnu99 -m64 -I. -I../../include -DWIN32 -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c xdr_float.c -o xdr_float.o
gcc -std=gnu99 -m64 -I. -I../../include -DWIN32 -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c xdr_stdio.c -o xdr_stdio.o
gcc -std=gnu99 -m64 -I. -I../../include -DWIN32 -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c xdr_mem.c -o xdr_mem.o
ar crs libxdr.a xdr.o xdr_float.o xdr_stdio.o xdr_mem.o
make -f Makefile.win makeMakedeps
making regcomp.d from regcomp.c
making regerror.d from regerror.c
making regexec.d from regexec.c
making tre-ast.d from tre-ast.c
making tre-compile.d from tre-compile.c
making tre-match-approx.d from tre-match-approx.c
making tre-match-backtrack.d from tre-match-backtrack.c
making tre-match-parallel.d from tre-match-parallel.c
making tre-mem.d from tre-mem.c
making tre-parse.d from tre-parse.c
making tre-stack.d from tre-stack.c
making xmalloc.d from xmalloc.c
make -f Makefile.win libtre.a
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c regcomp.c -o regcomp.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c regerror.c -o regerror.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c regexec.c -o regexec.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-ast.c -o tre-ast.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-compile.c -o tre-compile.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-match-approx.c -o tre-match-approx.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-match-backtrack.c -o
tre-match-backtrack.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-match-parallel.c -o
tre-match-parallel.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-mem.c -o tre-mem.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-parse.c -o tre-parse.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c tre-stack.c -o tre-stack.o
gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=native -pipe   -c xmalloc.c -o xmalloc.o
ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
tre-match-approx.o tre-match-backtrack.o tre-match-parallel.o tre-mem.o
tre-parse.o tre-stack.o xmalloc.o
gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=native -pipe   -c compat.c
-o compat.o
gcc -std=gnu99 -m64  -DTRIO_FEATURE_WIDECHAR=1 -O3 -Wall -pedantic
-mtune=native -pipe   -c trio.c -o trio.o
ar crs libtrio.a compat.o trio.o
making localtime.d from localtime.c
making registryTZ.d from registryTZ.c
making strftime.d from strftime.c
gcc -std=gnu99 -m64 -I../../include -I../../main  -O3 -Wall -pedantic
-mtune=native -pipe   -c localtime.c -o localtime.o
gcc -std=gnu99 -m64 -I../../include -I../../main  -O3 -Wall -pedantic
-mtune=native -pipe   -c registryTZ.c -o registryTZ.o
gcc -std=gnu99 -m64 -I../../include -I../../main  -O3 -Wall -pedantic
-mtune=native -pipe   -c strftime.c -o strftime.o
ar crs libtz.a localtime.o registryTZ.o strftime.o
installing zoneinfo
making win_iconv.d from win_iconv.c
gcc -std=gnu99 -m64 -I../../include  -O3 -Wall -pedantic -mtune=native
-pipe   -c win_iconv.c -o win_iconv.o
gcc -std=gnu99 -m64 -shared   -o Riconv.dll Riconv.def win_iconv.o
making console.d from console.c
making dynload.d from dynload.c
making editor.d from editor.c
making embeddedR.d from embeddedR.c
making extra.d from extra.c
making malloc.d from malloc.c
making opt.d from opt.c
making pager.d from pager.c
making preferences.d from preferences.c
making psignal.d from psignal.c
making rhome.d from rhome.c
making rt_complete.d from rt_complete.c
making rui.d from rui.c
making run.d from run.c
making shext.d from shext.c
making sys-win32.d from sys-win32.c
making system.d from system.c
making dos_wglob.d from dos_wglob.c
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c console.c -o
console.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c dynload.c -o
dynload.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c editor.c -o
editor.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c embeddedR.c -o
embeddedR.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD -I../library/grDevices/src -O3 -Wall -pedantic -mtune=native
-pipe   -c extra.c -o extra.o
In file included from ../extra/graphapp/ga.h:29:0,
                 from extra.c:39:
../extra/graphapp/graphapp.h:43:23: note: previous declaration of 'GAbyte'
was here
 typedef unsigned char GAbyte;
                       ^
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c malloc.c -o
malloc.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c opt.c -o opt.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c pager.c -o
pager.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c preferences.c
-o preferences.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c psignal.c -o
psignal.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c rhome.c -o
rhome.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c rt_complete.c
-o rt_complete.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c rui.c -o rui.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c run.c -o run.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c shext.c -o
shext.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c sys-win32.c -o
sys-win32.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c system.c -o
system.o
gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=native -pipe   -c dos_wglob.c -o
dos_wglob.o
windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o dynload.o
editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o psignal.o
rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o dos_wglob.o
dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
-fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp -lRiconv
-lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
-L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
cannot find -lRgraphapp
collect2.exe: error: ld returned 1 exit status
make[4]: *** [R.dll] Error 1
make[3]: *** [../../bin/x64/R.dll] Error 2
make[2]: *** [rbuild] Error 2
make[1]: *** [all] Error 2
make: *** [distribution] Error 2

D:\R64\R-3.4.3\src\gnuwin32>

--------------------------------------------------------------------------------------------

Regards,
Indrajit

On Fri, Feb 9, 2018 at 2:04 PM, Tomas Kalibera <tomas.kalibera at gmail.com>
wrote:

> Please note that building R on Windows is documented in "R Installation
> and Administration", including links to external software. Particularly
> there is a link to texinfo which is part of Rtools. The documentation is
> maintained and it is a sufficient source of information for building R on
> Windows.
>
> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
> https://cran.r-project.org/bin/windows/base/rw-FAQ.html
>
> Tomas
>
> On 02/09/2018 08:16 AM, Indrajit Sen Gupta wrote:
>
>> Hi Avraham,
>>
>> A quick question - I realized I did not have *Perl* installed. So I
>> installed *ActiveState Perl* right now. Also I see I need *texinfo* and
>> *texi2any*. I was able to installed *texinfo* from here:
>> http://gnuwin32.sourceforge.net/packages/texinfo.htm. But not sure where
>> to
>> get *texi2any*. Can you guide me in this step?
>>
>>
>> Regards,
>> Indrajit
>>
>> On Fri, Feb 9, 2018 at 11:58 AM, Indrajit Sen Gupta <indrajitsg at gmail.com
>> >
>> wrote:
>>
>> Hi Avraham,
>>>
>>> What a coincidence, I have been following this post of yours:
>>> https://www.
>>> avrahamadler.com/2013/10/24/an-openblas-based-rblas-for-
>>> windows-64-step-by-step/
>>>
>>> Looks like this post is slightly older than what you have shared
>>> previously. It is strange that you did not get the attachments. I am
>>> pasting the contents of the MkRules.local here:
>>>
>>> -------------------------------------------------------------------
>>>
>>> #-*- Makefile -*-
>>>
>>> ## This is only used when building R itself but it does customize
>>> ## etc/*/Makeconf using LOCAL_SOFT, BINPREF[64], IMPLIB and R_ARCH
>>>
>>> ## Customize by copying to MkRules.local and uncommenting and editing
>>> ## some of the definitions there.
>>> ##
>>>
>>> ## =========== configuration macros for building packages
>>> ================
>>> # Absolute path to '/usr/local' software collection.  The versions used
>>> # on CRAN can be found at https://www.stats.ox.ac.uk/pub
>>> /Rtools/libs.html
>>> # It can be interrogated by 'R CMD config LOCAL_SOFT'
>>> # Use 'make rsync-extsoft' to populate the default directory.
>>> # LOCAL_SOFT = D:/R64/extsoft
>>>
>>> ## ============== configuration macros for building R ===================
>>>
>>> # Path of library directory containing zlib, bzlib, liblzma, pcre,
>>> # libpng, libjpeg, libtiff.
>>> # Use 'make rsync-extsoft' to populate the default directory.
>>> EXT_LIBS = D:/R64/extsoft
>>>
>>> # an alternative is to use -gstabs here, if the debugger supports only
>>> stabs.
>>> # G_FLAG = -gdwarf-2
>>>
>>> # Set to YES and specify the path if you want to use the ATLAS BLAS.
>>> USE_ATLAS = YES
>>> ATLAS_PATH =D:/home/thread0
>>>
>>> # Support for the ACML and Goto BLASes has been withdrawn: see
>>> R-admin.html
>>>
>>> # Define to use svnversion to set SVN-REVISION (slow, and requires a
>>> clean
>>> # checkout with no modifications).
>>> # USE_SVNVERSION = YES
>>>
>>> # With the previously recommended gcc 4.6.3 toolchain, set this to 32 or
>>> 64
>>> # MULTI = 64
>>> # If the toolchain's bin directory is not in your path, set this to the
>>> path
>>> # (including the trailing /, and use / not \).
>>> # TOOL_PATH =
>>> # for other toolchains leave these empty and set the more detailed
>>> options
>>> below
>>>
>>> # With the recommended gcc 4.9.3 toolchain or another toolchain, set
>>> # BINPREF and BINPREF64 (below) to the respective bin directories.
>>> # Include the trailing /, and use / not \.
>>> # Do this in the more detailed options below
>>> # Set this to 32 or 64
>>> WIN = 64
>>>
>>>
>>> ### BEGIN more detailed options
>>> # Some of the toolchains have prefixes for e.g. ar, gcc.
>>> # This can also be used to give the full path to the compiler,
>>> # including a trailing / .
>>> # BINPREF = c:/Rtools/mingw_32/bin/
>>> # prefix for 64-bit:
>>> BINPREF64 = D:/Rtools/mingw_64/bin/
>>> # Set this to indicate a non-gcc compiler and version
>>> # COMPILED_BY = <determined automatically>
>>>
>>> # Others use a -m64 or -m32 option to select architectures
>>> # M_ARCH = -m64
>>> # and for as (--32 or --64)
>>> # AS_ARCH = --64
>>> # and for windres (-F pe-i386 or pe-x86-64)
>>> # RC_ARCH = pe-x86-64
>>> # and for dlltool ("-m i386 --as-flags --32" vs "-m i386:x86-64
>>> --as-flags
>>> --64")
>>> DT_ARCH = -m i386:x86-64 --as-flags --64
>>>
>>> # 32- or 64-bit Windows?
>>> WIN = 64
>>>
>>> # The gcc 4.9.3 64 bit toolchain is set up for the 'medium code' model
>>> and
>>> needs
>>> # to remove the .refptr and .weak entries from the exports list; this is
>>> the default
>>> # when WIN = 64, with blank for WIN = 32:
>>> NM_FILTER = | $(SED) -e '/[.]refptr[.]/d' -e '/[.]weak[.]/d'
>>>
>>> # We normally link directly against DLLs,
>>> # but this macro forces the use of import libs
>>> # Has been needed for some versions of MinGW-w64
>>> USE_IMPLIBS = YES
>>>
>>> ### END more detailed options
>>>
>>>
>>> # set to use ICU
>>> USE_ICU = YES
>>> # path to parent of ICU headers
>>> ICU_PATH = D:/home/ICU
>>> ICU_LIBS = -lsicuin -lsicuuc -lsicudt -lstdc++
>>>
>>> # set to use libcurl
>>> USE_LIBCURL = YES
>>> # path to parent of libcurl headers
>>> CURL_PATH = D:/home/curl
>>> # libs: for 32-bit
>>> # CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
>>> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm -lidn
>>> # libs: for 64-bit
>>> CURL_LIBS = -lcurl -lrtmp -lssl -lssh2 -lcrypto -lgdi32 -lcrypt32 -lz
>>> -lws2_32 -lgdi32 -lcrypt32 -lwldap32 -lwinmm
>>>
>>> # For the cairographics devices
>>> # Optionally use a static build of cairographics from
>>> #   https://www.rforge.net/Cairo/files/cairo-current-win.tar.gz
>>> # and set CAIRO_HOME to the parent of the win32/win64 directories
>>> #
>>> # If CAIRO_HOME is not set the devices are not built.
>>> CAIRO_HOME = D:/home/cairo/src
>>>
>>> # set this to YES to build static HTML help
>>> BUILD_HTML = YES
>>>
>>> # unset this if you are *not* using MiKTeX
>>> MIKTEX = TRUE
>>> # Recent MiKTEX does not provide texi2dvi and needs something like
>>> TEXI2DVI = TEXINDEX=texindex.exe texify
>>>
>>> # for texinfo >= 5.1. If the texinfo files are installed at
>>> /packages/texinfo,
>>> # TEXI2ANY = /path/to/perl -I/packages/texinfo /packages/texinfo/texi2any
>>> # if you do not have texinfo (default),
>>> # TEXI2ANY = missing
>>>
>>> # additional optimization flags (use -mtune=native for a private build)
>>> EOPTS = -mtune=native
>>>
>>> # define to -fopenmp if the toolchain has OpenMP support
>>> # OPENMP = -fopenmp
>>>
>>> # define to -pthread if the toolchain has pthreads support
>>> # PTHREAD = -pthread
>>>
>>> ## ====== configuration macros for building installer ===========
>>>
>>> # location where Inno Setup 5.[34].x was installed. Spaces allowed.
>>> ISDIR = D:/home/inno5
>>>
>>> # optional location where qpdf was installed (in $(QPDF)/bin). Spaces
>>> allowed.
>>> QPDF = D:/home/qpdf/bin
>>>
>>> # home of 32-bit files for combined installer on 64-bit build
>>> # HOME32 =
>>>
>>> # Full paths of extra DLLs that need to be shipped
>>> # e.g
>>> # DLLs32 = c:/R/bin/pthreadGC2-w32.dll
>>> # DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
>>> # DLLs32 =
>>> # DLLs64 =
>>>
>>>
>>> ## ====== configuration macros for building MSI installer ===========
>>>
>>> # location where WiX 3.x executables were installed. Spaces allowed.
>>> # The MSI uses '/bin': other packagings may not
>>> # WIX3DIR = C:/packages/WiX3.5/bin
>>>
>>> # set to 1 for a non-elevated per-user installer
>>> # WIX_PERSONAL = 0
>>>
>>> ## =============== end of user-customizable parts  ===================
>>>
>>> ------------------------------------------------------------
>>> -----------------------
>>>
>>> I will go through your latest post and see what are the differences. I
>>> have used the latest version of R 3.4.3 with the latest version of
>>> rtools:
>>> Rtools34.exe.
>>>
>>> Not sure why but i have feeling that the culprit might be a setting in
>>> the
>>> MkRules.
>>>
>>> Regards,
>>> Indrajit
>>>
>>> On Fri, Feb 9, 2018 at 10:53 AM, Avraham Adler <avraham.adler at gmail.com>
>>> wrote:
>>>
>>> On Thu, Feb 8, 2018 at 9:44 PM, Indrajit Sen Gupta <indrajitsg at gmail.com
>>>> >
>>>> wrote:
>>>>
>>>>> Hi All,
>>>>>
>>>>> I am trying to compile R from source on a 64 bit Windows.
>>>>>
>>>> [snip]
>>>>
>>>> I had compiled earlier with MinGW and had created the file:
>>>>> *libopenblas_haswell-r0.2.20.a. *
>>>>>
>>>> Hello, Indrajit.
>>>>
>>>> I don't see your MkRules.local attached. In any event, perhaps try
>>>> following the directions here [1]. I've been building R with OpenBLAS
>>>> on Windows 64 for years and it almost always works. In the past year
>>>> or two, rarely, it will stop with an error. But if you restart the
>>>> make process (by just typing "make" again) it finishes with no issues
>>>> and passes make check-devel. I have not tried this with R-dev, though.
>>>> R 3.4.3 Patched (2018-01-03 r74042) is the most recent I have built
>>>> successfully.
>>>>
>>>> Good luck,
>>>>
>>>> Avraham
>>>>
>>>> [1] https://www.avrahamadler.com/r-tips/build-openblas-for-windows-r64/
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Fri Feb  9 14:32:50 2018
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 9 Feb 2018 08:32:50 -0500
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
Message-ID: <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>

On Fri, Feb 9, 2018 at 2:16 AM, Indrajit Sen Gupta <indrajitsg at gmail.com> wrote:
> Hi Avraham,
>
> A quick question - I realized I did not have Perl installed. So I installed
> ActiveState Perl right now. Also I see I need texinfo and texi2any. I was
> able to installed texinfo from here:
> http://gnuwin32.sourceforge.net/packages/texinfo.htm. But not sure where to
> get texi2any. Can you guide me in this step?

It is in the ZIP file "texinfo5.zip" here [1]. Unzip that entire file
into a directory and use that as your texinfo directory. That works
for me.

Avi

[1] http://www.stats.ox.ac.uk/pub/Rtools/


From kmbell56 at gmail.com  Fri Feb  9 15:29:02 2018
From: kmbell56 at gmail.com (Kenny Bell)
Date: Fri, 09 Feb 2018 14:29:02 +0000
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
Message-ID: <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>

You can see how the appveyor build works here:

https://github.com/rwinlib/base

I suggest that you work off the build process in the  rwinlib repository so
you are starting from something that you know works and already
incorporates the set of dependencies you need.

On Fri, Feb 9, 2018, 5:33 AM Avraham Adler <avraham.adler at gmail.com> wrote:

> On Fri, Feb 9, 2018 at 2:16 AM, Indrajit Sen Gupta <indrajitsg at gmail.com>
> wrote:
> > Hi Avraham,
> >
> > A quick question - I realized I did not have Perl installed. So I
> installed
> > ActiveState Perl right now. Also I see I need texinfo and texi2any. I was
> > able to installed texinfo from here:
> > http://gnuwin32.sourceforge.net/packages/texinfo.htm. But not sure
> where to
> > get texi2any. Can you guide me in this step?
>
> It is in the ZIP file "texinfo5.zip" here [1]. Unzip that entire file
> into a directory and use that as your texinfo directory. That works
> for me.
>
> Avi
>
> [1] http://www.stats.ox.ac.uk/pub/Rtools/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Fri Feb  9 17:28:26 2018
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 9 Feb 2018 11:28:26 -0500
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
Message-ID: <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>

On Fri, Feb 9, 2018 at 9:29 AM, Kenny Bell <kmbell56 at gmail.com> wrote:
> I suggest that you work off the build process in the  rwinlib repository so
> you are starting from something that you know works and already incorporates
> the set of dependencies you need.

Hello, Kenny.

For what it's worth I've been successfully building R+OpenBLAS on
Windows64 since 2013, which I believe predates rwinlib on github, but
I may be mistaken. Thus, I don't think I'm incorrect in saying that
the instructions I provide are also "something that you know works" :)
I did make the explicit assumption that people will successfully
follow the instructions at R Installation & Administration. Perhaps
that is too much to ask.

Thanks,

Avi


From suharto_anggono at yahoo.com  Sat Feb 10 09:41:32 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 10 Feb 2018 08:41:32 +0000 (UTC)
Subject: [Rd] Nice names in deparse
References: <1299014423.2278379.1518252092899.ref@mail.yahoo.com>
Message-ID: <1299014423.2278379.1518252092899@mail.yahoo.com>

x <- 0; names(x) <- "recursive"
I am saying more plainly: With 'x' above, deparse(x, control = "all") is wrong in R devel.

--------------------------------------------
On Sat, 16/12/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

 Subject: Nice names in deparse
 To: r-devel at r-project.org
 Date: Saturday, 16 December, 2017, 11:09 PM

 Tags (argument names) in call to 'list'
 becomes names of the result. It is not necessarily so with
 call to 'c'. The default method of 'c' has 'recursive' and
 'use.names' arguments.

 In R devel r73778, with
 x <- 0; names(x) <- "recursive"?
 ,
 dput(x)
 or even
 dput(x, control = "all")
 gives
 c(recursive = 0)
 However, actual result of c(recursive =
 0) is NULL.

 Also with
 x <- 0; names(x) <- "recursive"?
 ,
 dput(x, control = c("keepNA",
 "keepInteger", "showAttributes"))
 in R devel r73778
 gives
 structure(c(0), .Names = "recursive")
 The 'control' is suggested by an
 example for output as in R < 3.5.0. However, the output
 is slightly different from
 dput(x)
 in R 3.3.2:
 structure(0, .Names = "recursive")


 Part of NEWS item related with
 "niceNames" control option:
 as.character(list( c (one = 1))) now
 includes the name, as as.character(list(list(one = 1))) has
 always done.

 Please reconsider.
 As
 as.numeric(list(c(one = 1)))
 gives
 1 ,
 I expect that
 as.character(list(c(one = "1")))
 gives
 "1" .
 It does in R devel r73778.
 Why does
 as.character(list(c(one = 1)))
 give
 "c(one = 1)" ?

 as.numeric(list(c(one = "1")))
 gives
 1 .

 list(list(one = 1))
 is not quite the same.
 as.numeric(list(list(one = 1)))
 gives
 NA .


From fjaeger at ur.rochester.edu  Sat Feb 10 21:11:14 2018
From: fjaeger at ur.rochester.edu (T. Florian Jaeger)
Date: Sat, 10 Feb 2018 15:11:14 -0500
Subject: [Rd] makeCluster hangs
Message-ID: <d5cb6887-2745-8e8a-a510-302ad736dbad@ur.rochester.edu>

Hi all,

I can't get the functionality of the package parallel to work. 
Specifically, makeCluster() hangs when I run it. I first noticed the 
problem when trying to run Rstan with multiple cores and the traced it 
back to the core package parallel. The following results in R hanging 
after the call to makeCluster.

library(parallel)

# Calculate the number of cores
no_cores <- detectCores() - 1

# Initiate cluster
cl <- makeCluster(no_cores)

I'm running MacOS High Sierra 10.13.3 (17D47) on a MacbookPro 2017 
laptop with 4 cores.

platform?????? x86_64-apple-darwin15.6.0
arch?????????? x86_64
os???????????? darwin15.6.0
system???????? x86_64, darwin15.6.0
status
major????????? 3
minor????????? 4.3
year?????????? 2017
month????????? 11
day??????????? 30
svn rev??????? 73796
language?????? R
version.string R version 3.4.3 (2017-11-30)
nickname?????? Kite-Eating Tree

The problem replicates in R --vanilla


I've spent hours googling for solutions but can't find any reports of 
this problem. Any help would be appreciated.


Florian


From henrik.bengtsson at gmail.com  Sat Feb 10 22:39:02 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 10 Feb 2018 13:39:02 -0800
Subject: [Rd] makeCluster hangs
In-Reply-To: <d5cb6887-2745-8e8a-a510-302ad736dbad@ur.rochester.edu>
References: <d5cb6887-2745-8e8a-a510-302ad736dbad@ur.rochester.edu>
Message-ID: <CAFDcVCT3LvyfHa+duqD-sjbrr07cgoZ_Z=HymouOP8neWRGdKQ@mail.gmail.com>

A few quick comments:

* You mention R --vanilla, but make sure to try with
parallel::makeCluster(), so that you don't happen to pick up
snow::makeCluster() if 'snow' is attached and ahead of parallel on the
search() path.

* Try creating a single background worker, i.e. parallel::makeCluster(1L).

* Try with cl <- future::makeClusterPSOCK(1L, verbose = TRUE), which
gives the same thing, but it also show you some details on what it
does internally; that may give some clues where it stalls.

/Henrik

On Sat, Feb 10, 2018 at 12:11 PM, T. Florian Jaeger
<fjaeger at ur.rochester.edu> wrote:
> Hi all,
>
> I can't get the functionality of the package parallel to work. Specifically,
> makeCluster() hangs when I run it. I first noticed the problem when trying
> to run Rstan with multiple cores and the traced it back to the core package
> parallel. The following results in R hanging after the call to makeCluster.
>
> library(parallel)
>
> # Calculate the number of cores
> no_cores <- detectCores() - 1
>
> # Initiate cluster
> cl <- makeCluster(no_cores)
>
> I'm running MacOS High Sierra 10.13.3 (17D47) on a MacbookPro 2017 laptop
> with 4 cores.
>
> platform       x86_64-apple-darwin15.6.0
> arch           x86_64
> os             darwin15.6.0
> system         x86_64, darwin15.6.0
> status
> major          3
> minor          4.3
> year           2017
> month          11
> day            30
> svn rev        73796
> language       R
> version.string R version 3.4.3 (2017-11-30)
> nickname       Kite-Eating Tree
>
> The problem replicates in R --vanilla
>
>
> I've spent hours googling for solutions but can't find any reports of this
> problem. Any help would be appreciated.
>
>
> Florian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ilia-kats at gmx.net  Sun Feb 11 14:15:23 2018
From: ilia-kats at gmx.net (Ilia Kats)
Date: Sun, 11 Feb 2018 14:15:23 +0100
Subject: [Rd] incorrect clipping on cairo devices
Message-ID: <cf6e7902-6095-00b3-2a3f-ff96601045f9@gmx.net>

Hi all,

consider the plot https://ptpb.pw/rTGw.pdf , generated by 
cairo_pdf();plot(1, 1, pch=16, cex=10, xlim=c(1,2), 
ylim=c(1,2));dev.off() . Notice how the circle is outside the bottom 
edge of the box. While this example is somewhat artificial, this 
behavior is very annoying when plotting scatterplots with lots and lots 
of data points and restricting xlim and ylim to show only a subset of 
data. I believe the cause was identified in 
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16299 . I also 
believe that this is the cause of 
https://github.com/tidyverse/ggplot2/issues/670 (correct clipping would 
produce thinner than specified borders on all sides, which could be 
remedied by simply requesting a twice as wide border).

Are there any plans to fix this?

Note that I'm not subscribed to the list, so please CC me in replies.

Cheers, Ilia


From fjaeger at ur.rochester.edu  Sun Feb 11 21:51:57 2018
From: fjaeger at ur.rochester.edu (T. Florian Jaeger)
Date: Sun, 11 Feb 2018 15:51:57 -0500
Subject: [Rd] makeCluster hangs
In-Reply-To: <CAFDcVCT3LvyfHa+duqD-sjbrr07cgoZ_Z=HymouOP8neWRGdKQ@mail.gmail.com>
References: <d5cb6887-2745-8e8a-a510-302ad736dbad@ur.rochester.edu>
 <CAFDcVCT3LvyfHa+duqD-sjbrr07cgoZ_Z=HymouOP8neWRGdKQ@mail.gmail.com>
Message-ID: <18085b5b-f50e-215d-e879-da94cf1ffcb1@ur.rochester.edu>

Dear Henrik,

thank you, for the quick reply. Bizarrely enough, the problem vanished when
I woke the computer from sleep (I had previously replicated the problem
after several restarts of both R and the MacOS).

I will follow-up if I can again replicate the problem.

Florian


On 2/10/18 4:39 PM, Henrik Bengtsson wrote:
> A few quick comments:
>
> * You mention R --vanilla, but make sure to try with
> parallel::makeCluster(), so that you don't happen to pick up
> snow::makeCluster() if 'snow' is attached and ahead of parallel on the
> search() path.
>
> * Try creating a single background worker, i.e. parallel::makeCluster(1L).
>
> * Try with cl <- future::makeClusterPSOCK(1L, verbose = TRUE), which
> gives the same thing, but it also show you some details on what it
> does internally; that may give some clues where it stalls.
>
> /Henrik
>
> On Sat, Feb 10, 2018 at 12:11 PM, T. Florian Jaeger
> <fjaeger at ur.rochester.edu> wrote:
>> Hi all,
>>
>> I can't get the functionality of the package parallel to work. Specifically,
>> makeCluster() hangs when I run it. I first noticed the problem when trying
>> to run Rstan with multiple cores and the traced it back to the core package
>> parallel. The following results in R hanging after the call to makeCluster.
>>
>> library(parallel)
>>
>> # Calculate the number of cores
>> no_cores <- detectCores() - 1
>>
>> # Initiate cluster
>> cl <- makeCluster(no_cores)
>>
>> I'm running MacOS High Sierra 10.13.3 (17D47) on a MacbookPro 2017 laptop
>> with 4 cores.
>>
>> platform       x86_64-apple-darwin15.6.0
>> arch           x86_64
>> os             darwin15.6.0
>> system         x86_64, darwin15.6.0
>> status
>> major          3
>> minor          4.3
>> year           2017
>> month          11
>> day            30
>> svn rev        73796
>> language       R
>> version.string R version 3.4.3 (2017-11-30)
>> nickname       Kite-Eating Tree
>>
>> The problem replicates in R --vanilla
>>
>>
>> I've spent hours googling for solutions but can't find any reports of this
>> problem. Any help would be appreciated.
>>
>>
>> Florian
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIBaQ&c=kbmfwr1Yojg42sGEpaQh5ofMHBeTl9EI2eaqQZhHbOU&r=O6dqVFPEDpdoXY3wkv8u6o0LHKx4WbQ_itn0O87jj5s&m=R7DIWWqYTP2xarhrvKcymtN3XlAQ9vHLFDhPL6FxQ60&s=7F8Lez-XE8iC2JBU4JYsEtF3U0HObhMnCASud5xTgNM&e=
> .
>

-- 
T. Florian Jaeger
Professor of the Brain and Cognitive Sciences,
Computer Science
Alfred P. Sloan Research Fellow
University of Rochester,
Meliora Hall, Box 270268,
Rochester, NY 14627-0268
USA
P: +1 (585) 276 3611
F: +1 (585) 442 9216
E: fjaeger at ur.rochester.edu
B: http://www.hlplab.wordpress.com/
T: https://twitter.com/_hlplab_

To schedule an appointment, please visit 
http://www.bcs.rochester.edu/people/fjaeger/appointments.html

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Mon Feb 12 09:24:06 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 12 Feb 2018 09:24:06 +0100
Subject: [Rd] makeCluster hangs
In-Reply-To: <18085b5b-f50e-215d-e879-da94cf1ffcb1@ur.rochester.edu>
References: <d5cb6887-2745-8e8a-a510-302ad736dbad@ur.rochester.edu>
 <CAFDcVCT3LvyfHa+duqD-sjbrr07cgoZ_Z=HymouOP8neWRGdKQ@mail.gmail.com>
 <18085b5b-f50e-215d-e879-da94cf1ffcb1@ur.rochester.edu>
Message-ID: <e2d43660-78f3-370d-2b36-a0962a4ff790@gmail.com>

Also using R-devel might help - the forking support in parallel has been 
made more robust against race conditions, but the changes are probably 
too substantial to port to 3.4.x. If you find how to cause a race 
condition using parallel/forking in R-devel, a report would be greatly 
appreciated.

Tomas

On 02/11/2018 09:51 PM, T. Florian Jaeger wrote:
> Dear Henrik,
>
> thank you, for the quick reply. Bizarrely enough, the problem vanished when
> I woke the computer from sleep (I had previously replicated the problem
> after several restarts of both R and the MacOS).
>
> I will follow-up if I can again replicate the problem.
>
> Florian
>
>
> On 2/10/18 4:39 PM, Henrik Bengtsson wrote:
>> A few quick comments:
>>
>> * You mention R --vanilla, but make sure to try with
>> parallel::makeCluster(), so that you don't happen to pick up
>> snow::makeCluster() if 'snow' is attached and ahead of parallel on the
>> search() path.
>>
>> * Try creating a single background worker, i.e. parallel::makeCluster(1L).
>>
>> * Try with cl <- future::makeClusterPSOCK(1L, verbose = TRUE), which
>> gives the same thing, but it also show you some details on what it
>> does internally; that may give some clues where it stalls.
>>
>> /Henrik
>>
>> On Sat, Feb 10, 2018 at 12:11 PM, T. Florian Jaeger
>> <fjaeger at ur.rochester.edu> wrote:
>>> Hi all,
>>>
>>> I can't get the functionality of the package parallel to work. Specifically,
>>> makeCluster() hangs when I run it. I first noticed the problem when trying
>>> to run Rstan with multiple cores and the traced it back to the core package
>>> parallel. The following results in R hanging after the call to makeCluster.
>>>
>>> library(parallel)
>>>
>>> # Calculate the number of cores
>>> no_cores <- detectCores() - 1
>>>
>>> # Initiate cluster
>>> cl <- makeCluster(no_cores)
>>>
>>> I'm running MacOS High Sierra 10.13.3 (17D47) on a MacbookPro 2017 laptop
>>> with 4 cores.
>>>
>>> platform       x86_64-apple-darwin15.6.0
>>> arch           x86_64
>>> os             darwin15.6.0
>>> system         x86_64, darwin15.6.0
>>> status
>>> major          3
>>> minor          4.3
>>> year           2017
>>> month          11
>>> day            30
>>> svn rev        73796
>>> language       R
>>> version.string R version 3.4.3 (2017-11-30)
>>> nickname       Kite-Eating Tree
>>>
>>> The problem replicates in R --vanilla
>>>
>>>
>>> I've spent hours googling for solutions but can't find any reports of this
>>> problem. Any help would be appreciated.
>>>
>>>
>>> Florian
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIBaQ&c=kbmfwr1Yojg42sGEpaQh5ofMHBeTl9EI2eaqQZhHbOU&r=O6dqVFPEDpdoXY3wkv8u6o0LHKx4WbQ_itn0O87jj5s&m=R7DIWWqYTP2xarhrvKcymtN3XlAQ9vHLFDhPL6FxQ60&s=7F8Lez-XE8iC2JBU4JYsEtF3U0HObhMnCASud5xTgNM&e=
>> .
>>


From christian.krause at idiv.de  Mon Feb 12 20:08:15 2018
From: christian.krause at idiv.de (Christian Krause)
Date: Mon, 12 Feb 2018 20:08:15 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
Message-ID: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>

Dear R-Devel List,

**TL;DR:** The function **parLapplyLB** of the parallel package has [reportedly][1] (see also attached RRD output) not
been doing its job, i.e. not actually balancing the load. My colleague Dirk Sarpe and I found the cause of the problem
and we also have a patch to fix it (attached). A similar fix has also been provided [here][2].

[1]: https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
[2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792


## The Call Chain

First, we traced the relevant R function calls through the code, beginning with `parLapplyLB`:

1.  **parLapplyLB:** clusterApply.R:177, calls **splitList**, then **clusterApplyLB**
2.  **splitList:** clusterApply.R:157
3.  **clusterApplyLB:** clusterApply.R:87, calls **dynamicClusterApply**
4.  **dynamicClusterApply:** clusterApply.R:39


## splitList

We used both our whiteboard and an R session to manually *run* a few examples. We were using lists of 100 elements and 5
workers. First, lets take a look at **splitList**:

```r
> sapply(parallel:::splitList(1:100, 5), length)
[1] 20 20 20 20 20

> sapply(parallel:::splitList(1:97, 5), length)
[1] 20 19 19 19 20

> sapply(parallel:::splitList(1:97, 20), length)
 [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
```

As we can see in the examples, the work is distributed as equally as possible.


## dynamicClusterApply

**dynamicClusterApply** works this way (simplified):

1.  it first gives a chunk to each worker
2.  once a worker comes back with the result, it is given the next chunk

**This is the important part:** As long as there are **more** chunks than workers, there will be load balancing. If
there are fewer chunks than workers, each worker will get **at most one chunk** and there is **no** load balancing.


## parLapplyLB

This is how **parLapplyLB** splits the input list (with a bit of refactoring, for readability):

```r
parLapplyLB <- function(cl = NULL, X, fun, ...)
{
    cl <- defaultCluster(cl)

    chunks <- splitList(X, length(cl))

    do.call(c,
            clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
            quote = TRUE)
}
```

For our examples, the chunks have these sizes:

```r
> sapply(parallel:::splitList(1:100, 5), length)
[1] 20 20 20 20 20
```

There we have it: 5 chunks. 5 workers. With this work distribution, there can't possibly be any load balancing, because
each worker is given a single chunk and then it stops working because there are no more chunks.

Instead, **parLapplyLB** should look like this (patch is attached):

```r
parLapplyLB <- function(cl = NULL, X, fun, ...)
{
    cl <- defaultCluster(cl)

    chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))

    chunks <- splitList(X, chunkSize)

    do.call(c,
            clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
            quote = TRUE)
}
```

Examples with a cluster of 5 workers:

```r
# length(cl) < length(X)
> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
 [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5

# length(cl) >= length(X)
> sapply(parallel:::splitList(1:4, 4), length)
[1] 1 1 1 1
# one worker idles here, but we can't do better than that
```

With this patch, the number of chunks is larger than the number of workers, if possible at all, and then load balancing
should work.

Best Regards

-- 

Christian Krause

Scientific Computing Administration and Support

------------------------------------------------------------------------------------------------------------------------

Phone: +49 341 97 33144

Email: christian.krause at idiv.de

------------------------------------------------------------------------------------------------------------------------

German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig

Deutscher Platz 5e

04103 Leipzig

Germany

------------------------------------------------------------------------------------------------------------------------

iDiv is a research centre of the DFG ? Deutsche Forschungsgemeinschaft

iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der
Martin-Luther-Universit?t Halle-Wittenberg und der Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation
mit dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte Kooperationspartner sind die folgenden
au?eruniversit?ren Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH - UFZ, das
Max-Planck-Institut f?r Biogeochemie (MPI BGC), das Max-Planck-Institut f?r chemische ?kologie (MPI CE), das
Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das Leibniz-Institut Deutsche Sammlung von Mikroorganismen
und Zellkulturen (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das Leibniz-Institut f?r Pflanzengenetik und
Kulturpflanzenforschung (IPK) und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz (SMNG). USt-IdNr. DE
141510383


-------------- next part --------------
A non-text attachment was scrubbed...
Name: fixes-parLapplyLB.patch
Type: text/x-patch
Size: 676 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180212/927bc7d1/attachment.bin>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: r-parallel-load-balancing.png
Type: image/png
Size: 47263 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180212/927bc7d1/attachment.png>

From jdblischak at gmail.com  Mon Feb 12 21:33:38 2018
From: jdblischak at gmail.com (John Blischak)
Date: Mon, 12 Feb 2018 15:33:38 -0500
Subject: [Rd] Fix minor typo in error message from grDevices
Message-ID: <CACmKiDwHgAwa5GDbsrnWiyizKVAQR1qwnLuGFnm4B5Lhvq3uuw@mail.gmail.com>

Hi,

I fixed a minor typo in an error message from grDevices. Please see
attached for a patch to revision 74246.

Thanks,

John

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180212/ee2c88cd/attachment.ksh>

From peter.langfelder at gmail.com  Tue Feb 13 07:45:00 2018
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 12 Feb 2018 22:45:00 -0800
Subject: [Rd] Setting the path to Rtools for package compilation on Windows
Message-ID: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>

Hi all,

I'm trying to set up the Windows Rtools toolset for building packages
with compiled code. I installed for Windows R-3.4.3 from CRAN and
installed Rtools-3.4 in a custom location M:\R\R-3.4.3 and
M:\R\Rtools-3.4

Following the instructions, in shell, I set
Path=M:\R\Rtools-3.4\bin;M:\R\Rtools-3.4\gcc-4.6.3\bin;M:\R\R-3.4.3\bin;...
(the ... are other paths irrelevant for R/Rtools).

When I run

M:\Work\RLibs>R.exe CMD INSTALL --build WGCNA

I get the following ouput:

In R CMD INSTALL
* installing to library 'M:/R/R-3.4.3/library'
* installing *source* package 'WGCNA' ...
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/g++  -I"M:/R/R-3.4.3/include" -DNDEBUG
-O2 -Wall  -mtune=generic -c bucketApproxSort.cc
-o bucketApproxSort.o
c:/Rtools/mingw_32/bin/g++: not found
make: *** [bucketApproxSort.o] Error 127
Warning: running command 'make -f "Makevars.win" -f
"M:/R/R-3.4.3/etc/i386/Makeconf" -f "M:/R/R-3.4.3/share/make/winshli
b.mk" SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
SHLIB="WGCNA.dll" OBJECTS="bucketApproxSort.o corFun
ctions-common.o corFunctions-unified.o networkFunctions.o pivot.o
quantileC.o"' had status 2
ERROR: compilation failed for package 'WGCNA'
* removing 'M:/R/R-3.4.3/library/WGCNA'
* restoring previous 'M:/R/R-3.4.3/library/WGCNA'


Apparently the install is looking for Rtools in c:\Rtools. I am a
perpetual Windows newbie and would be really thankful for any pointers
as to how to proceed.

Peter


From sorenh at math.aau.dk  Tue Feb 13 08:33:54 2018
From: sorenh at math.aau.dk (=?ISO-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 13 Feb 2018 08:33:54 +0100
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
Message-ID: <1518507234.20503.4.camel@math.aau.dk>

I can confirm the behaviour that you report.?

Usually I put Rtools in c:\programs\Rtools and modify the path
accordingly. Recently (don't recall for how long) I have encountered
the same problems as you have and I have resorted to moving Rtools to
c:\Rtools

I have no idea as how to proceed; perhaps it could be worth trying an
older version of Rtools (though that may cause other problems).

Regards
S?ren


On Mon, 2018-02-12 at 22:45 -0800, Peter Langfelder wrote:
> Hi all,
> 
> I'm trying to set up the Windows Rtools toolset for building packages
> with compiled code. I installed for Windows R-3.4.3 from CRAN and
> installed Rtools-3.4 in a custom location M:\R\R-3.4.3 and
> M:\R\Rtools-3.4
> 
> Following the instructions, in shell, I set
> Path=M:\R\Rtools-3.4\bin;M:\R\Rtools-3.4\gcc-4.6.3\bin;M:\R\R-
> 3.4.3\bin;...
> (the ... are other paths irrelevant for R/Rtools).
> 
> When I run
> 
> M:\Work\RLibs>R.exe CMD INSTALL --build WGCNA
> 
> I get the following ouput:
> 
> In R CMD INSTALL
> * installing to library 'M:/R/R-3.4.3/library'
> * installing *source* package 'WGCNA' ...
> ** libs
> 
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++??-I"M:/R/R-3.4.3/include" -DNDEBUG
> -O2 -Wall??-mtune=generic -c bucketApproxSort.cc
> -o bucketApproxSort.o
> c:/Rtools/mingw_32/bin/g++: not found
> make: *** [bucketApproxSort.o] Error 127
> Warning: running command 'make -f "Makevars.win" -f
> "M:/R/R-3.4.3/etc/i386/Makeconf" -f "M:/R/R-3.4.3/share/make/winshli
> b.mk" SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="WGCNA.dll" OBJECTS="bucketApproxSort.o corFun
> ctions-common.o corFunctions-unified.o networkFunctions.o pivot.o
> quantileC.o"' had status 2
> ERROR: compilation failed for package 'WGCNA'
> * removing 'M:/R/R-3.4.3/library/WGCNA'
> * restoring previous 'M:/R/R-3.4.3/library/WGCNA'
> 
> 
> Apparently the install is looking for Rtools in c:\Rtools. I am a
> perpetual Windows newbie and would be really thankful for any
> pointers
> as to how to proceed.
> 
> Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Tue Feb 13 10:21:22 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 13 Feb 2018 10:21:22 +0100
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <1518507234.20503.4.camel@math.aau.dk>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
 <1518507234.20503.4.camel@math.aau.dk>
Message-ID: <71fe085c-b29e-079f-1397-7a20d2551fe5@gmail.com>

Thanks for the report - this has been already reported as bug 17376, it 
is caused by scripts that build the Windows binaries and by now has been 
fixed in R-patched and R-devel snapshot builds. So as a solution that 
works now I would recommend using R-patched.

Tomas


On 02/13/2018 08:33 AM, S?ren H?jsgaard wrote:
> I can confirm the behaviour that you report.
>
> Usually I put Rtools in c:\programs\Rtools and modify the path
> accordingly. Recently (don't recall for how long) I have encountered
> the same problems as you have and I have resorted to moving Rtools to
> c:\Rtools
>
> I have no idea as how to proceed; perhaps it could be worth trying an
> older version of Rtools (though that may cause other problems).
>
> Regards
> S?ren
>
>
> On Mon, 2018-02-12 at 22:45 -0800, Peter Langfelder wrote:
>> Hi all,
>>
>> I'm trying to set up the Windows Rtools toolset for building packages
>> with compiled code. I installed for Windows R-3.4.3 from CRAN and
>> installed Rtools-3.4 in a custom location M:\R\R-3.4.3 and
>> M:\R\Rtools-3.4
>>
>> Following the instructions, in shell, I set
>> Path=M:\R\Rtools-3.4\bin;M:\R\Rtools-3.4\gcc-4.6.3\bin;M:\R\R-
>> 3.4.3\bin;...
>> (the ... are other paths irrelevant for R/Rtools).
>>
>> When I run
>>
>> M:\Work\RLibs>R.exe CMD INSTALL --build WGCNA
>>
>> I get the following ouput:
>>
>> In R CMD INSTALL
>> * installing to library 'M:/R/R-3.4.3/library'
>> * installing *source* package 'WGCNA' ...
>> ** libs
>>
>> *** arch - i386
>> c:/Rtools/mingw_32/bin/g++??-I"M:/R/R-3.4.3/include" -DNDEBUG
>> -O2 -Wall??-mtune=generic -c bucketApproxSort.cc
>> -o bucketApproxSort.o
>> c:/Rtools/mingw_32/bin/g++: not found
>> make: *** [bucketApproxSort.o] Error 127
>> Warning: running command 'make -f "Makevars.win" -f
>> "M:/R/R-3.4.3/etc/i386/Makeconf" -f "M:/R/R-3.4.3/share/make/winshli
>> b.mk" SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
>> SHLIB="WGCNA.dll" OBJECTS="bucketApproxSort.o corFun
>> ctions-common.o corFunctions-unified.o networkFunctions.o pivot.o
>> quantileC.o"' had status 2
>> ERROR: compilation failed for package 'WGCNA'
>> * removing 'M:/R/R-3.4.3/library/WGCNA'
>> * restoring previous 'M:/R/R-3.4.3/library/WGCNA'
>>
>>
>> Apparently the install is looking for Rtools in c:\Rtools. I am a
>> perpetual Windows newbie and would be really thankful for any
>> pointers
>> as to how to proceed.
>>
>> Peter
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Tue Feb 13 11:20:58 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 13 Feb 2018 11:20:58 +0100
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
Message-ID: <CABFfbXv17xKpr84ifZfbuga9xdQ1rPG5BVBQmjRFk3JcBifYUA@mail.gmail.com>

On Tue, Feb 13, 2018 at 7:45 AM, Peter Langfelder
<peter.langfelder at gmail.com> wrote:
> Hi all,
>
> I'm trying to set up the Windows Rtools toolset for building packages
> with compiled code. I installed for Windows R-3.4.3 from CRAN and
> installed Rtools-3.4 in a custom location M:\R\R-3.4.3 and
> M:\R\Rtools-3.4
>
> Following the instructions, in shell, I set
> Path=M:\R\Rtools-3.4\bin;M:\R\Rtools-3.4\gcc-4.6.3\bin;M:\R\R-3.4.3\bin;...
> (the ... are other paths irrelevant for R/Rtools).

Thanks for your question. Your logs show that 'gcc' is not found. As
of R 3.3 you need to set the path to the compiler using the BINPREF
variable. This is because we ship two separate versions of gcc, one
targeting win32 and one targeting win64. I am not sure what your
rtools installation looks like, but could you try setting this
environment variable:

  BINPREF="M:/R/Rtools-3.4/mingw_$(WIN)/bin/"

I think this will do the job.

On Tue, Feb 13, 2018 at 10:21 AM, Tomas Kalibera
<tomas.kalibera at gmail.com> wrote:
> Thanks for the report - this has been already reported as bug 17376, it is
> caused by scripts that build the Windows binaries and by now has been fixed
> in R-patched and R-devel snapshot builds. So as a solution that works now I
> would recommend using R-patched.

This issue is unrelated, I doubt your advice will solve anything. The
only thing that 17376 does is add c:/rtools/bin to the default path.
But this dir does not exist for this user, so it is ignored by windows
when searching the PATH.


From tomas.kalibera at gmail.com  Tue Feb 13 11:34:50 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 13 Feb 2018 11:34:50 +0100
Subject: [Rd] Fix minor typo in error message from grDevices
In-Reply-To: <CACmKiDwHgAwa5GDbsrnWiyizKVAQR1qwnLuGFnm4B5Lhvq3uuw@mail.gmail.com>
References: <CACmKiDwHgAwa5GDbsrnWiyizKVAQR1qwnLuGFnm4B5Lhvq3uuw@mail.gmail.com>
Message-ID: <ccf9e24a-b16e-c733-6df3-b5f7df2b1b49@gmail.com>

Fixed, thanks,
Tomas

On 02/12/2018 09:33 PM, John Blischak wrote:
> Hi,
>
> I fixed a minor typo in an error message from grDevices. Please see
> attached for a patch to revision 74246.
>
> Thanks,
>
> John
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



	[[alternative HTML version deleted]]


From indrajitsg at gmail.com  Tue Feb 13 12:22:44 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Tue, 13 Feb 2018 16:52:44 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
Message-ID: <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>

Hi Avraham,

I tried with the patched version. The same error message.

gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o dynload.o
editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o psignal.o
rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o dos_wglob.o
dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
-fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp -lRiconv
-lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
-L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
cannot find -lRgraphapp
collect2.exe: error: ld returned 1 exit status
make[4]: *** [R.dll] Error 1
make[3]: *** [../../bin/x64/R.dll] Error 2
make[2]: *** [rbuild] Error 2
make[1]: *** [all] Error 2
make: *** [distribution] Error 2


Would it be possible for you to share your MkRules.local and Makefile.win
files?

Also as per your website, we don't need the line:

*TCL_VERSION = 86 *

in the file *Makeconf *inside *R_HOME/src/gnuwin32/fixed/etc*. Hence I am
commenting it. Also I noticed, just above this line (line 60), the
following line which specifies Rgraphapp:

*GRAPHAPP_LIB = -lRgraphapp*
# TCL_VERSION = 86
# was a reference to Rzlib.dll in R < 3.2.0
ZLIB_LIBS = -lz


This looks like the step which is causing the error. Anything I can try out
at this point?

Regards,
Indrajit


On Fri, Feb 9, 2018 at 9:58 PM, Avraham Adler <avraham.adler at gmail.com>
wrote:

> On Fri, Feb 9, 2018 at 9:29 AM, Kenny Bell <kmbell56 at gmail.com> wrote:
> > I suggest that you work off the build process in the  rwinlib repository
> so
> > you are starting from something that you know works and already
> incorporates
> > the set of dependencies you need.
>
> Hello, Kenny.
>
> For what it's worth I've been successfully building R+OpenBLAS on
> Windows64 since 2013, which I believe predates rwinlib on github, but
> I may be mistaken. Thus, I don't think I'm incorrect in saying that
> the instructions I provide are also "something that you know works" :)
> I did make the explicit assumption that people will successfully
> follow the instructions at R Installation & Administration. Perhaps
> that is too much to ask.
>
> Thanks,
>
> Avi
>

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Tue Feb 13 13:15:16 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 13 Feb 2018 13:15:16 +0100
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
 <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
Message-ID: <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>

On Tue, Feb 13, 2018 at 12:22 PM, Indrajit Sen Gupta
<indrajitsg at gmail.com> wrote:
> Hi Avraham,
>
> I tried with the patched version. The same error message.
>
> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o dynload.o
> editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o psignal.o
> rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o dos_wglob.o
> dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
> getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
> ../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
> -fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp -lRiconv
> -lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
> -L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
> D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
> cannot find -lRgraphapp
> collect2.exe: error: ld returned 1 exit status
> make[4]: *** [R.dll] Error 1
> make[3]: *** [../../bin/x64/R.dll] Error 2
> make[2]: *** [rbuild] Error 2
> make[1]: *** [all] Error 2
> make: *** [distribution] Error 2
>
>
> Would it be possible for you to share your MkRules.local and Makefile.win
> files?


Hi Indrajit

As somebody above already mentioned, the full build script as well as
MkRules.local that we use for the CRAN releases of R for windows are
available from https://github.com/rwinlib/base

As is explained in the repository readme, if you have the required
dependencies (rtools, miktex innosetup, strawberry perl) all you need
to do is run the build-r-devel.bat script from the root of the
repository.

Once you got this to work, you can adapt it to your needs.


From indrajitsg at gmail.com  Tue Feb 13 14:11:51 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Tue, 13 Feb 2018 18:41:51 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
 <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
 <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>
Message-ID: <CAB-BrmeAP_MSPpyhj4NFiwvLu4_Cb=OW_3GtZPa_CxFZUEkAFA@mail.gmail.com>

I was able to compile the R from the github by running build-r-devel.bat!

Now need to see how to compile it with BLAS.

Regard,
Indrajit

On Tue, Feb 13, 2018 at 5:45 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> On Tue, Feb 13, 2018 at 12:22 PM, Indrajit Sen Gupta
> <indrajitsg at gmail.com> wrote:
> > Hi Avraham,
> >
> > I tried with the patched version. The same error message.
> >
> > gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
> dynload.o
> > editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o
> psignal.o
> > rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o
> dos_wglob.o
> > dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
> > getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
> > ../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
> > -fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp
> -lRiconv
> > -lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
> > -L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
> > D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/.
> ./../../../x86_64-w64-mingw32/bin/ld.exe:
> > cannot find -lRgraphapp
> > collect2.exe: error: ld returned 1 exit status
> > make[4]: *** [R.dll] Error 1
> > make[3]: *** [../../bin/x64/R.dll] Error 2
> > make[2]: *** [rbuild] Error 2
> > make[1]: *** [all] Error 2
> > make: *** [distribution] Error 2
> >
> >
> > Would it be possible for you to share your MkRules.local and Makefile.win
> > files?
>
>
> Hi Indrajit
>
> As somebody above already mentioned, the full build script as well as
> MkRules.local that we use for the CRAN releases of R for windows are
> available from https://github.com/rwinlib/base
>
> As is explained in the repository readme, if you have the required
> dependencies (rtools, miktex innosetup, strawberry perl) all you need
> to do is run the build-r-devel.bat script from the root of the
> repository.
>
> Once you got this to work, you can adapt it to your needs.
>

	[[alternative HTML version deleted]]


From indrajitsg at gmail.com  Tue Feb 13 14:18:40 2018
From: indrajitsg at gmail.com (Indrajit Sen Gupta)
Date: Tue, 13 Feb 2018 18:48:40 +0530
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmeAP_MSPpyhj4NFiwvLu4_Cb=OW_3GtZPa_CxFZUEkAFA@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
 <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
 <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>
 <CAB-BrmeAP_MSPpyhj4NFiwvLu4_Cb=OW_3GtZPa_CxFZUEkAFA@mail.gmail.com>
Message-ID: <CAB-BrmfoV1cJvVzKpZCF_6wX_a7wf8r1VuWivUO9joKv2jnknw@mail.gmail.com>

In the file MkRules.local.in, I see the line: USE_ATLAS = NO which I
believe needs to be changed to YES. But how do I specify the BLAS file
*libopenblas_haswell-r0.2.20.a
*and its location?

Regards,
Indrajit

On Tue, Feb 13, 2018 at 6:41 PM, Indrajit Sen Gupta <indrajitsg at gmail.com>
wrote:

> I was able to compile the R from the github by running build-r-devel.bat!
>
> Now need to see how to compile it with BLAS.
>
> Regard,
> Indrajit
>
> On Tue, Feb 13, 2018 at 5:45 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>
>> On Tue, Feb 13, 2018 at 12:22 PM, Indrajit Sen Gupta
>> <indrajitsg at gmail.com> wrote:
>> > Hi Avraham,
>> >
>> > I tried with the patched version. The same error message.
>> >
>> > gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>> dynload.o
>> > editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o
>> psignal.o
>> > rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o
>> dos_wglob.o
>> > dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
>> > getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
>> > ../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
>> > -fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp
>> -lRiconv
>> > -lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
>> > -L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
>> > D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/.
>> ./../../../x86_64-w64-mingw32/bin/ld.exe:
>> > cannot find -lRgraphapp
>> > collect2.exe: error: ld returned 1 exit status
>> > make[4]: *** [R.dll] Error 1
>> > make[3]: *** [../../bin/x64/R.dll] Error 2
>> > make[2]: *** [rbuild] Error 2
>> > make[1]: *** [all] Error 2
>> > make: *** [distribution] Error 2
>> >
>> >
>> > Would it be possible for you to share your MkRules.local and
>> Makefile.win
>> > files?
>>
>>
>> Hi Indrajit
>>
>> As somebody above already mentioned, the full build script as well as
>> MkRules.local that we use for the CRAN releases of R for windows are
>> available from https://github.com/rwinlib/base
>>
>> As is explained in the repository readme, if you have the required
>> dependencies (rtools, miktex innosetup, strawberry perl) all you need
>> to do is run the build-r-devel.bat script from the root of the
>> repository.
>>
>> Once you got this to work, you can adapt it to your needs.
>>
>
>

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Tue Feb 13 14:28:43 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 13 Feb 2018 14:28:43 +0100
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmfoV1cJvVzKpZCF_6wX_a7wf8r1VuWivUO9joKv2jnknw@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
 <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
 <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>
 <CAB-BrmeAP_MSPpyhj4NFiwvLu4_Cb=OW_3GtZPa_CxFZUEkAFA@mail.gmail.com>
 <CAB-BrmfoV1cJvVzKpZCF_6wX_a7wf8r1VuWivUO9joKv2jnknw@mail.gmail.com>
Message-ID: <CABFfbXvxdtp6oQH3AqQp51o3a3QCsnBXhx8FX8=-g7660NMFAg@mail.gmail.com>

On Tue, Feb 13, 2018 at 2:18 PM, Indrajit Sen Gupta
<indrajitsg at gmail.com> wrote:
> In the file MkRules.local.in, I see the line: USE_ATLAS = NO which I believe
> needs to be changed to YES. But how do I specify the BLAS file
> libopenblas_haswell-r0.2.20.a and its location?

I have never done this, but a good starting point is searching the R
source code for how this works:
https://github.com/wch/r-source/search?utf8=?&q=USE_ATLAS

>From the extra/blas/Makefile.win file it looks like you may need to
rename libopenblas_haswell-r0.2.20.a to libatlas.a and point to this
directory via the variable ATLAS_PATH in your MkRules.local.in?


From avraham.adler at gmail.com  Tue Feb 13 14:37:36 2018
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 13 Feb 2018 13:37:36 +0000
Subject: [Rd] R Compilation gets stuck on Windows 64
In-Reply-To: <CAB-BrmfoV1cJvVzKpZCF_6wX_a7wf8r1VuWivUO9joKv2jnknw@mail.gmail.com>
References: <CAB-BrmcdSmj-3e9RY7Pzf-+vLb+4K3=gCEDyoEKNCdVh+rPJWw@mail.gmail.com>
 <CAL6gwnJFr_F+Bb2GDU+YH2_miNfbYwwJ=6FR2BAoZvQ4HeGc0w@mail.gmail.com>
 <CAB-BrmcLin89AQ8W6OZLaqcvvj7UZnvwK-MVCfRCsUBk2yni3A@mail.gmail.com>
 <CAB-BrmfrcW_yNqrhipM+Bk_ffO1=Kv32xFFJU0UxNFjH-GUU4A@mail.gmail.com>
 <CAL6gwn+bzp__o3+Ezb88DzzHKj+Gsx-W5CtXh9rkFO-7oMMmCg@mail.gmail.com>
 <CAPekMCmkwy7UidTF5pzgkOMSjdhtBL0Oc=cohpzzed1ykkJ6Qg@mail.gmail.com>
 <CAL6gwnKZJc0kOA75v_q7XLYgwC+UMjbrNKDEVThR+cMqrzF0Mg@mail.gmail.com>
 <CAB-Brmd64xvwiDZFnfAJdLoRrb7KOkSpy6veJcy0hvUTbz+9mg@mail.gmail.com>
 <CABFfbXv-GoNKsvKqjACZCB1KvqOVrSOacukHni3vFZ7t6a5cBg@mail.gmail.com>
 <CAB-BrmeAP_MSPpyhj4NFiwvLu4_Cb=OW_3GtZPa_CxFZUEkAFA@mail.gmail.com>
 <CAB-BrmfoV1cJvVzKpZCF_6wX_a7wf8r1VuWivUO9joKv2jnknw@mail.gmail.com>
Message-ID: <CAL6gwn+hXXgO8m76n4rLdRghHxAdQE6kuQRtW-c-ta+JrcAjJQ@mail.gmail.com>

Set the location of atlas path in mkrules.local to what you need, then edit
arc/extra/blas/makevars.win to read lopenblas_haswell-r0.2.20 instead of
the two libraries there in the atlas section. I think I described this in
my more recent instructions.

Avi

On Tue, Feb 13, 2018 at 8:18 AM Indrajit Sen Gupta <indrajitsg at gmail.com>
wrote:

> In the file MkRules.local.in, I see the line: USE_ATLAS = NO which I
> believe needs to be changed to YES. But how do I specify the BLAS file *libopenblas_haswell-r0.2.20.a
> *and its location?
>
> Regards,
> Indrajit
>
> On Tue, Feb 13, 2018 at 6:41 PM, Indrajit Sen Gupta <indrajitsg at gmail.com>
> wrote:
>
>> I was able to compile the R from the github by running build-r-devel.bat!
>>
>> Now need to see how to compile it with BLAS.
>>
>> Regard,
>> Indrajit
>>
>> On Tue, Feb 13, 2018 at 5:45 PM, Jeroen Ooms <jeroenooms at gmail.com>
>> wrote:
>>
>>> On Tue, Feb 13, 2018 at 12:22 PM, Indrajit Sen Gupta
>>> <indrajitsg at gmail.com> wrote:
>>> > Hi Avraham,
>>> >
>>> > I tried with the patched version. The same error message.
>>> >
>>> > gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>>> dynload.o
>>> > editor.o embeddedR.o extra.o malloc.o opt.o pager.o preferences.o
>>> psignal.o
>>> > rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o system.o
>>> dos_wglob.o
>>> > dllversion.o ../main/libmain.a ../appl/libappl.a ../nmath/libnmath.a
>>> > getline/gl.a ../extra/xdr/libxdr.a ../extra/intl/libintl.a
>>> > ../extra/trio/libtrio.a ../extra/tzone/libtz.a ../extra/tre/libtre.a
>>> > -fopenmp -L. -lgfortran -lquadmath -lRblas -L../../lib -lRgraphapp
>>> -lRiconv
>>> > -lcomctl32 -lversion -L"D:/R64/extsoft"/lib/x64 -lpcre -lz -lbz2 -llzma
>>> > -L"D:/home/ICU"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++
>>> >
>>> D:/Rtools/mingw_64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.3/../../../../x86_64-w64-mingw32/bin/ld.exe:
>>> > cannot find -lRgraphapp
>>> > collect2.exe: error: ld returned 1 exit status
>>> > make[4]: *** [R.dll] Error 1
>>> > make[3]: *** [../../bin/x64/R.dll] Error 2
>>> > make[2]: *** [rbuild] Error 2
>>> > make[1]: *** [all] Error 2
>>> > make: *** [distribution] Error 2
>>> >
>>> >
>>> > Would it be possible for you to share your MkRules.local and
>>> Makefile.win
>>> > files?
>>>
>>>
>>> Hi Indrajit
>>>
>>> As somebody above already mentioned, the full build script as well as
>>> MkRules.local that we use for the CRAN releases of R for windows are
>>> available from https://github.com/rwinlib/base
>>>
>>> As is explained in the repository readme, if you have the required
>>> dependencies (rtools, miktex innosetup, strawberry perl) all you need
>>> to do is run the build-r-devel.bat script from the root of the
>>> repository.
>>>
>>> Once you got this to work, you can adapt it to your needs.
>>>
>>
>>
> --
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Tue Feb 13 19:58:14 2018
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 13 Feb 2018 10:58:14 -0800
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <CABFfbXv17xKpr84ifZfbuga9xdQ1rPG5BVBQmjRFk3JcBifYUA@mail.gmail.com>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
 <CABFfbXv17xKpr84ifZfbuga9xdQ1rPG5BVBQmjRFk3JcBifYUA@mail.gmail.com>
Message-ID: <CA+hbrhWiHVot0NYEzx39afUdPVWZc-AswQg5wJOAcabd0tcS-A@mail.gmail.com>

On Tue, Feb 13, 2018 at 2:20 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> Thanks for your question. Your logs show that 'gcc' is not found. As
> of R 3.3 you need to set the path to the compiler using the BINPREF
> variable. This is because we ship two separate versions of gcc, one
> targeting win32 and one targeting win64. I am not sure what your
> rtools installation looks like, but could you try setting this
> environment variable:
>
>   BINPREF="M:/R/Rtools-3.4/mingw_$(WIN)/bin/"
>
> I think this will do the job.

Thanks, that indeed did the trick. May I suggest that this hint be
also included in "REMAINING TASKS" section of the file Rtools.txt that
is part of the Rtools distribution?  The R installation manual does
mention BINPREF and BINPREF64 but I missed that part...

Peter


From jeroenooms at gmail.com  Wed Feb 14 13:32:32 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 14 Feb 2018 13:32:32 +0100
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <CA+hbrhWiHVot0NYEzx39afUdPVWZc-AswQg5wJOAcabd0tcS-A@mail.gmail.com>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
 <CABFfbXv17xKpr84ifZfbuga9xdQ1rPG5BVBQmjRFk3JcBifYUA@mail.gmail.com>
 <CA+hbrhWiHVot0NYEzx39afUdPVWZc-AswQg5wJOAcabd0tcS-A@mail.gmail.com>
Message-ID: <CABFfbXupKgXDRE9pqAuCWUMMA78csVc28D6S-ue=8sP-eWpowA@mail.gmail.com>

On Tue, Feb 13, 2018 at 7:58 PM, Peter Langfelder
<peter.langfelder at gmail.com> wrote:
> On Tue, Feb 13, 2018 at 2:20 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>
>> Thanks for your question. Your logs show that 'gcc' is not found. As
>> of R 3.3 you need to set the path to the compiler using the BINPREF
>> variable. This is because we ship two separate versions of gcc, one
>> targeting win32 and one targeting win64. I am not sure what your
>> rtools installation looks like, but could you try setting this
>> environment variable:
>>
>>   BINPREF="M:/R/Rtools-3.4/mingw_$(WIN)/bin/"
>>
>> I think this will do the job.
>
> Thanks, that indeed did the trick. May I suggest that this hint be
> also included in "REMAINING TASKS" section of the file Rtools.txt that
> is part of the Rtools distribution?  The R installation manual does
> mention BINPREF and BINPREF64 but I missed that part...

Glad it worked. Actually BINPREF64 only exists when building R itself.
For the R user there is no BINPREF64. There is only BINPREF which has
to point to a 32bit gcc when R runs in 32bit, and a 64bit compiler
when R runs in 64bit. But if you compile R packages you need both at
the same time. Hence the "$(WIN)" variable in the BINPREF above.

Yes the rtools setup is a bit convoluted, and we're currently
discussing ways to improve this. Thanks for your suggestion.


From ggrothendieck at gmail.com  Thu Feb 15 01:12:26 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 14 Feb 2018 19:12:26 -0500
Subject: [Rd] 
 Setting the path to Rtools for package compilation on Windows
In-Reply-To: <CABFfbXupKgXDRE9pqAuCWUMMA78csVc28D6S-ue=8sP-eWpowA@mail.gmail.com>
References: <CA+hbrhVN1ngZiyVH2q2Z+rOMeLhGZ88eQu4c04unkVDo7zkugw@mail.gmail.com>
 <CABFfbXv17xKpr84ifZfbuga9xdQ1rPG5BVBQmjRFk3JcBifYUA@mail.gmail.com>
 <CA+hbrhWiHVot0NYEzx39afUdPVWZc-AswQg5wJOAcabd0tcS-A@mail.gmail.com>
 <CABFfbXupKgXDRE9pqAuCWUMMA78csVc28D6S-ue=8sP-eWpowA@mail.gmail.com>
Message-ID: <CAP01uRkWCncEB2iFJ+cR_rbhOYSKso1JTC=2DULRewBxWOLCyA@mail.gmail.com>

If there is work going on to improve Rtools

1. one of the most annoying aspects of it is that it does not play nice
with builtin Windows commands.  In particular, it defines a command
called find which works like UNIX find but it masks Windows find
if you add the Rtools folders to your PATH making it quite dangerous
to do so.

2. Another annoyance is that what to put on the PATH can change from
one Rtools version to another and it is not straight forward to
discover that automatically.  One can extract it from the unins000.dat
(and I have done that) but it is not straight forward.

3. Ideally it would be nice if it were as easy to install Rtools as installing
an R package.  In fact, maybe Rtools could be an R package or maybe
it could be part of the R installation process itself.



On Wed, Feb 14, 2018 at 7:32 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> On Tue, Feb 13, 2018 at 7:58 PM, Peter Langfelder
> <peter.langfelder at gmail.com> wrote:
>> On Tue, Feb 13, 2018 at 2:20 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>>
>>> Thanks for your question. Your logs show that 'gcc' is not found. As
>>> of R 3.3 you need to set the path to the compiler using the BINPREF
>>> variable. This is because we ship two separate versions of gcc, one
>>> targeting win32 and one targeting win64. I am not sure what your
>>> rtools installation looks like, but could you try setting this
>>> environment variable:
>>>
>>>   BINPREF="M:/R/Rtools-3.4/mingw_$(WIN)/bin/"
>>>
>>> I think this will do the job.
>>
>> Thanks, that indeed did the trick. May I suggest that this hint be
>> also included in "REMAINING TASKS" section of the file Rtools.txt that
>> is part of the Rtools distribution?  The R installation manual does
>> mention BINPREF and BINPREF64 but I missed that part...
>
> Glad it worked. Actually BINPREF64 only exists when building R itself.
> For the R user there is no BINPREF64. There is only BINPREF which has
> to point to a 32bit gcc when R runs in 32bit, and a 64bit compiler
> when R runs in 64bit. But if you compile R packages you need both at
> the same time. Hence the "$(WIN)" variable in the BINPREF above.
>
> Yes the rtools setup is a bit convoluted, and we're currently
> discussing ways to improve this. Thanks for your suggestion.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From davorj at live.com  Thu Feb 15 08:36:30 2018
From: davorj at live.com (Davor Josipovic)
Date: Thu, 15 Feb 2018 07:36:30 +0000
Subject: [Rd] writeLines argument useBytes = TRUE still making conversions
Message-ID: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>

I think this behavior is inconsistent with the documentation:

  tmp <- '?'
  tmp <- iconv(tmp, to = 'UTF-8')
  print(Encoding(tmp))
  print(charToRaw(tmp))
  tmpfilepath <- tempfile()
  writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)

[1] "UTF-8"
[1] c3 a9

Raw text as hex: c3 83 c2 a9

If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.

Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509


	[[alternative HTML version deleted]]


From dmitrii.pasechnik at maths.ox.ac.uk  Thu Feb 15 15:39:55 2018
From: dmitrii.pasechnik at maths.ox.ac.uk (dmitrii.pasechnik at maths.ox.ac.uk)
Date: Thu, 15 Feb 2018 14:39:55 +0000
Subject: [Rd] missing extern in GraphicsBase.h
Message-ID: <20180215143952.GA28628@hilbert>

Dear all,
in src/include/GraphicsBase.h one has a declaration

int baseRegisterIndex;

the same as in src/main/devices.c

which causes problems on Solaris, see bug #17385, 
and other platforms with "unusual" linkers, see bug #16633.

By right, global variables like baseRegisterIndex are to be
declared just once, and not in a header file, but in a *.c file.
Then, to use them elsewhere in the code, one declares them as
extern in the header. 
(as proposed on #17385)

Otherwise one has an undefined behaviour,
some linkers might silently prepend extern, some not...

May I humbly request attention to this bug
(which is classified as UNCONFIRNMED---and indeed it needs an extra
effort to reproduce the error on, say, Linux --- but it really is an obvious C
bug, which will rear its ugly head sooner or later again)

Thanks,
Dmitrii


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180215/81d3065b/attachment.sig>

From kevinushey at gmail.com  Thu Feb 15 17:19:32 2018
From: kevinushey at gmail.com (Kevin Ushey)
Date: Thu, 15 Feb 2018 08:19:32 -0800
Subject: [Rd] 
 writeLines argument useBytes = TRUE still making conversions
In-Reply-To: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
References: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
Message-ID: <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>

I suspect your UTF-8 string is being stripped of its encoding before
write, and so assumed to be in the system native encoding, and then
re-encoded as UTF-8 when written to the file. You can see something
similar with:

    > tmp <- '?'
    > tmp <- iconv(tmp, to = 'UTF-8')
    > Encoding(tmp) <- "unknown"
    > charToRaw(iconv(tmp, to = "UTF-8"))
    [1] c3 83 c2 a9

It's worth saying that:

    file(..., encoding = "UTF-8")

means "attempt to re-encode strings as UTF-8 when writing to this
file". However, if you already know your text is UTF-8, then you
likely want to avoid opening a connection that might attempt to
re-encode the input. Conversely (assuming I'm understanding the
documentation correctly)

    file(..., encoding = "native.enc")

means "assume that strings are in the native encoding, and hence
translation is unnecessary". Note that it does not mean "attempt to
translate strings to the native encoding".

Also note that writeLines(..., useBytes = FALSE) will explicitly
translate to the current encoding before sending bytes to the
requested connection. In other words, there are two locations where
translation might occur in your example:

   1) In the call to writeLines(),
   2) When characters are passed to the connection.

In your case, it sounds like translation should be suppressed at both steps.

I think this is documented correctly in ?writeLines (and also the
Encoding section of ?file), but the behavior may feel unfamiliar at
first glance.

Kevin

On Wed, Feb 14, 2018 at 11:36 PM, Davor Josipovic <davorj at live.com> wrote:
>
> I think this behavior is inconsistent with the documentation:
>
>   tmp <- '?'
>   tmp <- iconv(tmp, to = 'UTF-8')
>   print(Encoding(tmp))
>   print(charToRaw(tmp))
>   tmpfilepath <- tempfile()
>   writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>
> [1] "UTF-8"
> [1] c3 a9
>
> Raw text as hex: c3 83 c2 a9
>
> If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.
>
> Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From istazahn at gmail.com  Thu Feb 15 18:16:59 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 15 Feb 2018 12:16:59 -0500
Subject: [Rd] 
 writeLines argument useBytes = TRUE still making conversions
In-Reply-To: <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>
References: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
 <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>
Message-ID: <CA+vqiLFT8Tsq5VumuYELs-ZP5u=z7Ggo3FfiUjFR_bkJTBdexw@mail.gmail.com>

On Thu, Feb 15, 2018 at 11:19 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
> I suspect your UTF-8 string is being stripped of its encoding before
> write, and so assumed to be in the system native encoding, and then
> re-encoded as UTF-8 when written to the file. You can see something
> similar with:
>
>     > tmp <- '?'
>     > tmp <- iconv(tmp, to = 'UTF-8')
>     > Encoding(tmp) <- "unknown"
>     > charToRaw(iconv(tmp, to = "UTF-8"))
>     [1] c3 83 c2 a9
>
> It's worth saying that:
>
>     file(..., encoding = "UTF-8")
>
> means "attempt to re-encode strings as UTF-8 when writing to this
> file". However, if you already know your text is UTF-8, then you
> likely want to avoid opening a connection that might attempt to
> re-encode the input. Conversely (assuming I'm understanding the
> documentation correctly)
>
>     file(..., encoding = "native.enc")
>
> means "assume that strings are in the native encoding, and hence
> translation is unnecessary". Note that it does not mean "attempt to
> translate strings to the native encoding".

If all that is true I think ?file needs some attention. I've read it
several times now and I just don't see how it can be interpreted as
you've described it.

Best,
Ista

>
> Also note that writeLines(..., useBytes = FALSE) will explicitly
> translate to the current encoding before sending bytes to the
> requested connection. In other words, there are two locations where
> translation might occur in your example:
>
>    1) In the call to writeLines(),
>    2) When characters are passed to the connection.
>
> In your case, it sounds like translation should be suppressed at both steps.
>
> I think this is documented correctly in ?writeLines (and also the
> Encoding section of ?file), but the behavior may feel unfamiliar at
> first glance.
>
> Kevin
>
> On Wed, Feb 14, 2018 at 11:36 PM, Davor Josipovic <davorj at live.com> wrote:
>>
>> I think this behavior is inconsistent with the documentation:
>>
>>   tmp <- '?'
>>   tmp <- iconv(tmp, to = 'UTF-8')
>>   print(Encoding(tmp))
>>   print(charToRaw(tmp))
>>   tmpfilepath <- tempfile()
>>   writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>>
>> [1] "UTF-8"
>> [1] c3 a9
>>
>> Raw text as hex: c3 83 c2 a9
>>
>> If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.
>>
>> Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From paul at stat.auckland.ac.nz  Thu Feb 15 22:21:32 2018
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 16 Feb 2018 10:21:32 +1300
Subject: [Rd] missing extern in GraphicsBase.h
In-Reply-To: <20180215143952.GA28628@hilbert>
References: <20180215143952.GA28628@hilbert>
Message-ID: <f2391c5b-e3b2-ecc6-b7b6-46d0162f60a4@stat.auckland.ac.nz>

Hi

I have committed the suggested "extern" patch.

Could you please confirm that this fixes the issue on Solaris (and 
anything else you can test) ?

Thanks!

Paul

On 16/02/18 03:39, dmitrii.pasechnik at maths.ox.ac.uk wrote:
> Dear all,
> in src/include/GraphicsBase.h one has a declaration
> 
> int baseRegisterIndex;
> 
> the same as in src/main/devices.c
> 
> which causes problems on Solaris, see bug #17385,
> and other platforms with "unusual" linkers, see bug #16633.
> 
> By right, global variables like baseRegisterIndex are to be
> declared just once, and not in a header file, but in a *.c file.
> Then, to use them elsewhere in the code, one declares them as
> extern in the header.
> (as proposed on #17385)
> 
> Otherwise one has an undefined behaviour,
> some linkers might silently prepend extern, some not...
> 
> May I humbly request attention to this bug
> (which is classified as UNCONFIRNMED---and indeed it needs an extra
> effort to reproduce the error on, say, Linux --- but it really is an obvious C
> bug, which will rear its ugly head sooner or later again)
> 
> Thanks,
> Dmitrii
> 
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From s.ritchie73 at gmail.com  Thu Feb 15 23:08:29 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Fri, 16 Feb 2018 09:08:29 +1100
Subject: [Rd] Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
Message-ID: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>

Hi,

I was unable to find a bug report for this with a cursory search, but would
like clarification if this is intended or unavoidable behaviour:

```{r}
# Create example data.frames
parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
                      sex=c("F", "M", "F", "M"),
                      age=c(41, 43, 36, 51))
children <- data.frame(parent=c("Sarah", "Max", "Qin"),
                       name=c("Oliver", "Sebastian", "Kai-lee"),
                       sex=c("M", "M", "F"),
                       age=c(5,8,7))

# Merge() creates a duplicated "name" column:
merge(parents, children, by.x = "name", by.y = "parent")
```

Output:
```
   name sex.x age.x      name sex.y age.y
1   Max     M    43 Sebastian     M     8
2   Qin     F    36   Kai-lee     F     7
3 Sarah     F    41    Oliver     M     5
Warning message:
In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
  column name ?name? is duplicated in the result
```

Kind Regards,

Scott Ritchie

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri Feb 16 17:03:00 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 16 Feb 2018 16:03:00 +0000
Subject: [Rd] Unnecessary lines in stem.c?
Message-ID: <1A8C1289955EF649A09086A153E267240C3FD9146F@GBTEDVPEXCMB04.corp.lgc-group.com>

A discussion on r-help led me to look at stem.c at
https://github.com/wch/r-source/blob/trunk/src/library/graphics/src/stem.c

Lines 76-77 appear superfluous. They sit inside a condition, and set mu, as follows:
	if (k*(k-4)*(k-8) == 0) mu = 5;
	if ((k-1)*(k-5)*(k-6) == 0) mu = 20;

But mu is set unconditionally to 10 on line 84, and that is followed by conditional assignments (on line 85-6) identical to lines 76-77.

It looks like a couple of lines got left inside a condition that are no longer needed there. If that is correct, is it worth removing the superfluous lines, for future coders' benefit?

S Ellison
 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From tomas.kalibera at gmail.com  Fri Feb 16 17:29:34 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 16 Feb 2018 17:29:34 +0100
Subject: [Rd] 
 [R-win] Bug 17159 - recursive dir.create() fails on windows
 shares due to permissions (MMaechler: Resending to R-windows@R-pr..)
In-Reply-To: <CAO1zAVbrWenNDRjAm+85BbRkad63sZFy3umPtfXb=bxiMHoY2A@mail.gmail.com>
References: <44DC0D86-8E3B-42B8-99DA-71A588AD8616@quintiles.com>
 <CAO1zAVasTKupjQF8mJewAzdyqrJk=vvghMdJqc8uVdS_N5mCZw@mail.gmail.com>
 <DA11F272-BA91-4869-BEC3-D75772FCB312@cbs.dk>
 <C5C54C10-F8ED-4E6A-881A-B13E2E233BD6@quintiles.com>
 <8E8BE323-108F-4791-970A-6512FAD9F117@cbs.dk>
 <CAO1zAVbrWenNDRjAm+85BbRkad63sZFy3umPtfXb=bxiMHoY2A@mail.gmail.com>
Message-ID: <89c355bf-9044-07a5-c5f1-3c2bbc7058da@gmail.com>

Bug 17159 has been fixed (in R-devel), but there may be more issues left 
with UNC paths.
Tomas

On 01/17/2018 01:37 PM, Joris Meys wrote:
> Hi Peter,
>
> I share your experience with trying to help IT departments setting things
> up. The network directory of the students is mapped to a drive, but R still
> uses the unc path instead of the drive when attempting to create that user
> library. Unless I do it manually of course. The only solution I see right
> now is to set the HOME or R_LIBS_USER environment variable in Renviron, but
> that should be done each time a new student logs into the computer. Or is
> there a way to ensure R uses the mapped drive instead of the network unc
> path, either using an R setting or by messing with Windows itself?
>
> Cheers
> Joris
>
>
>
> On Wed, Jan 17, 2018 at 1:21 PM, Peter Dalgaard <pd.mes at cbs.dk> wrote:
>
>> I can easily believe that. It was maily for Joris, that it might not be
>> necessary to reinstall.
>>
>> -pd
>>
>>> On 17 Jan 2018, at 11:55 , Thompson, Pete <Pete.Thompson at iqvia.com>
>> wrote:
>>> That solution works fine for the use case where each user has a network
>> based home directory and needs to run R from there, but doesn?t help with
>> my situation. I need to be able to support arbitrary network based paths in
>> arbitrary numbers ? so mapping drives isn?t an option. I have found a
>> workaround using symbolic links to the network share created within the
>> temporary folder, but would much prefer that R support UNC paths ? it seems
>> a reasonably simple fix.
>>> Cheers
>>> Pete
>>>
>>>
>>> On 17/01/2018, 10:52, "Peter Dalgaard" <pd.mes at cbs.dk> wrote:
>>>
>>>     I usually draw a complete blank if  I try to assist our IT department
>> with such issues (we really need better documentation than the Admin manual
>> for large-system installs by non-experts in R).
>>>     However, it is my impression that there are also options involving
>> environment variables and LFS naming. E.g., map the networked user
>> directory to, say, a P: "drive" and make sure that the environment is set
>> up to reflect this.
>>>     -pd
>>>
>>>> On 16 Jan 2018, at 17:52 , Joris Meys <jorismeys at gmail.com> wrote:
>>>>
>>>> Hi all,
>>>>
>>>> I ran into this exact issue yesterday during the exam of statistical
>>>> computing. Users can install packages in a user library that R tries to
>>>> create automatically on the network drive of the student. But that
>> doesn't
>>>> happen as the unc path is not read correctly, leading to R attempting to
>>>> create a local directory and being told it has no right to do so.
>>>>
>>>> That is an older version of R though (3.3), but I'm wondering whether I
>>>> would ask our IT department to just update R on all these computers to
>> the
>>>> latest version, or if we have to look for another solution.
>>>>
>>>> Cheers
>>>> Joris
>>>>
>>>> On Mon, Jan 8, 2018 at 1:43 PM, Thompson, Pete <Pete.Thompson at iqvia.com
>>>> wrote:
>>>>
>>>>> Hi, I?d like to ask about bug 17159:
>>>>>
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17159
>>>>>
>>>>> I can confirm that I see exactly this bug when using dir.create on
>> paths
>>>>> of UNC form (\\server\share\xxx), with the recursive flag set. I?m
>> seeing
>>>>> this when attempting to use install.packages with such a path (which I
>> know
>>>>> isn?t supported, but would be great if it was!). I can see that a
>> patch has
>>>>> been suggested for the problem and from looking at the source code I
>>>>> believe it?s a correct fix. Is there a possibility of getting this
>> patch
>>>>> included?
>>>>>
>>>>> The existing logic for Windows recursive dir.create (platform.c lines
>>>>> 2209-22203) appears to be:
>>>>> - Skip over any \\share at the start of the directory name
>>>>> - Loop while there are pieces of directory name left (i.e. we haven?t
>> hit
>>>>> the last \ character)
>>>>> = Find the next portion of the directory name (up to the next \
>>>>> character)
>>>>> = Attempt to create the directory (unless it is of the form x: - i.e. a
>>>>> drive name)
>>>>> = Ignore any ?already exists? errors, otherwise throw an error
>>>>>
>>>>> This logic appears flawed in that it skips \\share which isn?t a valid
>>>>> path format (according to https://msdn.microsoft.com/en-
>>>>> us/library/windows/desktop/aa365247(v=vs.85).aspx ). Dredging my
>> memory,
>>>>> it?s possible that \\share was a supported format in very old versions
>> of
>>>>> Windows, but it?s been a long time since the UNC format came in. It?s
>> also
>>>>> possible that \\share is a valid format in some odd environments, but
>> the
>>>>> UNC format is far more widely used.
>>>>>
>>>>> The patch suggested by Evan Cortens is simply to change the skip logic
>> to
>>>>> skip over \\server\share instead of \\share. This will certainly fix
>> the
>>>>> common use case of using UNC paths, but doesn?t attempt to deal with
>> all
>>>>> the more complex options in Microsoft?s documentation. I doubt many
>> users
>>>>> would ask for the complex cases, but the basic UNC format would be of
>> wide
>>>>> applicability.
>>>>>
>>>>> Thanks
>>>>> Pete Thompson
>>>>> Director, Information Technology
>>>>> Head of Spotfire Centre of Excellence
>>>>> IQVIA
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ________________________________________
>>>>> IMPORTANT - PLEASE READ: This electronic message, including its
>>>>> attachments, is CONFIDENTIAL and may contain PROPRIETARY or LEGALLY
>>>>> PRIVILEGED or PROTECTED information and is intended for the authorized
>>>>> recipient of the sender. If you are not the intended recipient, you are
>>>>> hereby notified that any use, disclosure, copying, or distribution of
>> this
>>>>> message or any of the information included in it is unauthorized and
>>>>> strictly prohibited. If you have received this message in error, please
>>>>> immediately notify the sender by reply e-mail and permanently delete
>> this
>>>>> message and its attachments, along with any copies thereof, from all
>>>>> locations received (e.g., computer, mobile device, etc.). Thank you.
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>> --
>>>> Joris Meys
>>>> Statistical consultant
>>>>
>>>> Department of Data Analysis and Mathematical Modelling
>>>> Ghent University
>>>> Coupure Links 653, B-9000 Gent (Belgium)
>>>> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-
>> 9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>>>> -----------
>>>> Biowiskundedagen 2017-2018
>>>> http://www.biowiskundedagen.ugent.be/
>>>>
>>>> -------------------------------
>>>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> _______________________________________________
>>>> R-windows mailing list
>>>> R-windows at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-windows
>>>     --
>>>     Peter Dalgaard, Professor,
>>>     Center for Statistics, Copenhagen Business School
>>>     Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>     Phone: (+45)38153501
>>>     Office: A 4.23
>>>     Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> ________________________________________
>>> IMPORTANT - PLEASE READ: This electronic message, including its
>> attachments, is CONFIDENTIAL and may contain PROPRIETARY or LEGALLY
>> PRIVILEGED or PROTECTED information and is intended for the authorized
>> recipient of the sender. If you are not the intended recipient, you are
>> hereby notified that any use, disclosure, copying, or distribution of this
>> message or any of the information included in it is unauthorized and
>> strictly prohibited. If you have received this message in error, please
>> immediately notify the sender by reply e-mail and permanently delete this
>> message and its attachments, along with any copies thereof, from all
>> locations received (e.g., computer, mobile device, etc.). Thank you.
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>


From frederik at ofb.net  Fri Feb 16 17:53:44 2018
From: frederik at ofb.net (frederik at ofb.net)
Date: Fri, 16 Feb 2018 08:53:44 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
Message-ID: <20180216165344.GB32564@ofb.net>

Hi Scott,

It seems like reasonable behavior to me. What result would you expect?
That the second "name" should be called "name.y"?

The "merge" documentation says:

    If the columns in the data frames not used in merging have any
    common names, these have ?suffixes? (?".x"? and ?".y"? by default)
    appended to try to make the names of the result unique.

Since the first "name" column was used in merging, leaving both
without a suffix seems consistent with the documentation...

Frederick

On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> Hi,
> 
> I was unable to find a bug report for this with a cursory search, but would
> like clarification if this is intended or unavoidable behaviour:
> 
> ```{r}
> # Create example data.frames
> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
>                       sex=c("F", "M", "F", "M"),
>                       age=c(41, 43, 36, 51))
> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
>                        name=c("Oliver", "Sebastian", "Kai-lee"),
>                        sex=c("M", "M", "F"),
>                        age=c(5,8,7))
> 
> # Merge() creates a duplicated "name" column:
> merge(parents, children, by.x = "name", by.y = "parent")
> ```
> 
> Output:
> ```
>    name sex.x age.x      name sex.y age.y
> 1   Max     M    43 Sebastian     M     8
> 2   Qin     F    36   Kai-lee     F     7
> 3 Sarah     F    41    Oliver     M     5
> Warning message:
> In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
>   column name ?name? is duplicated in the result
> ```
> 
> Kind Regards,
> 
> Scott Ritchie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Pete.Thompson at iqvia.com  Fri Feb 16 17:30:21 2018
From: Pete.Thompson at iqvia.com (Thompson, Pete)
Date: Fri, 16 Feb 2018 16:30:21 +0000
Subject: [Rd] 
 [R-win] Bug 17159 - recursive dir.create() fails on windows
 shares due to permissions (MMaechler: Resending to R-windows@R-pr..)
In-Reply-To: <89c355bf-9044-07a5-c5f1-3c2bbc7058da@gmail.com>
References: <44DC0D86-8E3B-42B8-99DA-71A588AD8616@quintiles.com>
 <CAO1zAVasTKupjQF8mJewAzdyqrJk=vvghMdJqc8uVdS_N5mCZw@mail.gmail.com>
 <DA11F272-BA91-4869-BEC3-D75772FCB312@cbs.dk>
 <C5C54C10-F8ED-4E6A-881A-B13E2E233BD6@quintiles.com>
 <8E8BE323-108F-4791-970A-6512FAD9F117@cbs.dk>
 <CAO1zAVbrWenNDRjAm+85BbRkad63sZFy3umPtfXb=bxiMHoY2A@mail.gmail.com>
 <89c355bf-9044-07a5-c5f1-3c2bbc7058da@gmail.com>
Message-ID: <7809A821-B458-4CAB-A246-A6874DA30D28@quintiles.com>

Wonderful ( - thanks!

Cheers
Pete

?On 16/02/2018, 16:29, "Tomas Kalibera" <tomas.kalibera at gmail.com> wrote:

    Bug 17159 has been fixed (in R-devel), but there may be more issues left
    with UNC paths.
    Tomas

    On 01/17/2018 01:37 PM, Joris Meys wrote:
    > Hi Peter,
    >
    > I share your experience with trying to help IT departments setting things
    > up. The network directory of the students is mapped to a drive, but R still
    > uses the unc path instead of the drive when attempting to create that user
    > library. Unless I do it manually of course. The only solution I see right
    > now is to set the HOME or R_LIBS_USER environment variable in Renviron, but
    > that should be done each time a new student logs into the computer. Or is
    > there a way to ensure R uses the mapped drive instead of the network unc
    > path, either using an R setting or by messing with Windows itself?
    >
    > Cheers
    > Joris
    >
    >
    >
    > On Wed, Jan 17, 2018 at 1:21 PM, Peter Dalgaard <pd.mes at cbs.dk> wrote:
    >
    >> I can easily believe that. It was maily for Joris, that it might not be
    >> necessary to reinstall.
    >>
    >> -pd
    >>
    >>> On 17 Jan 2018, at 11:55 , Thompson, Pete <Pete.Thompson at iqvia.com>
    >> wrote:
    >>> That solution works fine for the use case where each user has a network
    >> based home directory and needs to run R from there, but doesn?t help with
    >> my situation. I need to be able to support arbitrary network based paths in
    >> arbitrary numbers ? so mapping drives isn?t an option. I have found a
    >> workaround using symbolic links to the network share created within the
    >> temporary folder, but would much prefer that R support UNC paths ? it seems
    >> a reasonably simple fix.
    >>> Cheers
    >>> Pete
    >>>
    >>>
    >>> On 17/01/2018, 10:52, "Peter Dalgaard" <pd.mes at cbs.dk> wrote:
    >>>
    >>>     I usually draw a complete blank if  I try to assist our IT department
    >> with such issues (we really need better documentation than the Admin manual
    >> for large-system installs by non-experts in R).
    >>>     However, it is my impression that there are also options involving
    >> environment variables and LFS naming. E.g., map the networked user
    >> directory to, say, a P: "drive" and make sure that the environment is set
    >> up to reflect this.
    >>>     -pd
    >>>
    >>>> On 16 Jan 2018, at 17:52 , Joris Meys <jorismeys at gmail.com> wrote:
    >>>>
    >>>> Hi all,
    >>>>
    >>>> I ran into this exact issue yesterday during the exam of statistical
    >>>> computing. Users can install packages in a user library that R tries to
    >>>> create automatically on the network drive of the student. But that
    >> doesn't
    >>>> happen as the unc path is not read correctly, leading to R attempting to
    >>>> create a local directory and being told it has no right to do so.
    >>>>
    >>>> That is an older version of R though (3.3), but I'm wondering whether I
    >>>> would ask our IT department to just update R on all these computers to
    >> the
    >>>> latest version, or if we have to look for another solution.
    >>>>
    >>>> Cheers
    >>>> Joris
    >>>>
    >>>> On Mon, Jan 8, 2018 at 1:43 PM, Thompson, Pete <Pete.Thompson at iqvia.com
    >>>> wrote:
    >>>>
    >>>>> Hi, I?d like to ask about bug 17159:
    >>>>>
    >>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17159
    >>>>>
    >>>>> I can confirm that I see exactly this bug when using dir.create on
    >> paths
    >>>>> of UNC form (\\server\share\xxx), with the recursive flag set. I?m
    >> seeing
    >>>>> this when attempting to use install.packages with such a path (which I
    >> know
    >>>>> isn?t supported, but would be great if it was!). I can see that a
    >> patch has
    >>>>> been suggested for the problem and from looking at the source code I
    >>>>> believe it?s a correct fix. Is there a possibility of getting this
    >> patch
    >>>>> included?
    >>>>>
    >>>>> The existing logic for Windows recursive dir.create (platform.c lines
    >>>>> 2209-22203) appears to be:
    >>>>> - Skip over any \\share at the start of the directory name
    >>>>> - Loop while there are pieces of directory name left (i.e. we haven?t
    >> hit
    >>>>> the last \ character)
    >>>>> = Find the next portion of the directory name (up to the next \
    >>>>> character)
    >>>>> = Attempt to create the directory (unless it is of the form x: - i.e. a
    >>>>> drive name)
    >>>>> = Ignore any ?already exists? errors, otherwise throw an error
    >>>>>
    >>>>> This logic appears flawed in that it skips \\share which isn?t a valid
    >>>>> path format (according to https://msdn.microsoft.com/en-
    >>>>> us/library/windows/desktop/aa365247(v=vs.85).aspx ). Dredging my
    >> memory,
    >>>>> it?s possible that \\share was a supported format in very old versions
    >> of
    >>>>> Windows, but it?s been a long time since the UNC format came in. It?s
    >> also
    >>>>> possible that \\share is a valid format in some odd environments, but
    >> the
    >>>>> UNC format is far more widely used.
    >>>>>
    >>>>> The patch suggested by Evan Cortens is simply to change the skip logic
    >> to
    >>>>> skip over \\server\share instead of \\share. This will certainly fix
    >> the
    >>>>> common use case of using UNC paths, but doesn?t attempt to deal with
    >> all
    >>>>> the more complex options in Microsoft?s documentation. I doubt many
    >> users
    >>>>> would ask for the complex cases, but the basic UNC format would be of
    >> wide
    >>>>> applicability.
    >>>>>
    >>>>> Thanks
    >>>>> Pete Thompson
    >>>>> Director, Information Technology
    >>>>> Head of Spotfire Centre of Excellence
    >>>>> IQVIA
    >>>>>
    >>>>>
    >>>>>
    >>>>>
    >>>>> ________________________________________
    >>>>> IMPORTANT - PLEASE READ: This electronic message, including its
    >>>>> attachments, is CONFIDENTIAL and may contain PROPRIETARY or LEGALLY
    >>>>> PRIVILEGED or PROTECTED information and is intended for the authorized
    >>>>> recipient of the sender. If you are not the intended recipient, you are
    >>>>> hereby notified that any use, disclosure, copying, or distribution of
    >> this
    >>>>> message or any of the information included in it is unauthorized and
    >>>>> strictly prohibited. If you have received this message in error, please
    >>>>> immediately notify the sender by reply e-mail and permanently delete
    >> this
    >>>>> message and its attachments, along with any copies thereof, from all
    >>>>> locations received (e.g., computer, mobile device, etc.). Thank you.
    >>>>> ______________________________________________
    >>>>> R-devel at r-project.org mailing list
    >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>>
    >>>>
    >>>>
    >>>> --
    >>>> Joris Meys
    >>>> Statistical consultant
    >>>>
    >>>> Department of Data Analysis and Mathematical Modelling
    >>>> Ghent University
    >>>> Coupure Links 653, B-9000 Gent (Belgium)
    >>>> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-
    >> 9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
    >>>> -----------
    >>>> Biowiskundedagen 2017-2018
    >>>> http://www.biowiskundedagen.ugent.be/
    >>>>
    >>>> -------------------------------
    >>>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
    >>>>
    >>>> [[alternative HTML version deleted]]
    >>>>
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> _______________________________________________
    >>>> R-windows mailing list
    >>>> R-windows at r-project.org
    >>>> https://stat.ethz.ch/mailman/listinfo/r-windows
    >>>     --
    >>>     Peter Dalgaard, Professor,
    >>>     Center for Statistics, Copenhagen Business School
    >>>     Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    >>>     Phone: (+45)38153501
    >>>     Office: A 4.23
    >>>     Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>>
    >>> ________________________________________
    >>> IMPORTANT - PLEASE READ: This electronic message, including its
    >> attachments, is CONFIDENTIAL and may contain PROPRIETARY or LEGALLY
    >> PRIVILEGED or PROTECTED information and is intended for the authorized
    >> recipient of the sender. If you are not the intended recipient, you are
    >> hereby notified that any use, disclosure, copying, or distribution of this
    >> message or any of the information included in it is unauthorized and
    >> strictly prohibited. If you have received this message in error, please
    >> immediately notify the sender by reply e-mail and permanently delete this
    >> message and its attachments, along with any copies thereof, from all
    >> locations received (e.g., computer, mobile device, etc.). Thank you.
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> --
    >> Peter Dalgaard, Professor,
    >> Center for Statistics, Copenhagen Business School
    >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    >> Phone: (+45)38153501
    >> Office: A 4.23
    >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >





________________________________________
IMPORTANT - PLEASE READ: This electronic message, including its attachments, is CONFIDENTIAL and may contain PROPRIETARY or LEGALLY PRIVILEGED or PROTECTED information and is intended for the authorized recipient of the sender. If you are not the intended recipient, you are hereby notified that any use, disclosure, copying, or distribution of this message or any of the information included in it is unauthorized and strictly prohibited. If you have received this message in error, please immediately notify the sender by reply e-mail and permanently delete this message and its attachments, along with any copies thereof, from all locations received (e.g., computer, mobile device, etc.). Thank you.

From s.ritchie73 at gmail.com  Sat Feb 17 01:15:01 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Sat, 17 Feb 2018 11:15:01 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <20180216165344.GB32564@ofb.net>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
Message-ID: <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>

Hi Frederick,

I would expect that any duplicate names in the resulting data.frame would
have the suffixes appended to them, regardless of whether or not they are
used as the join key. So in my example I would expect "names.x" and
"names.y" to indicate their source data.frame.

While careful reading of the documentation reveals this is not the case, I
would argue the intent of the suffixes functionality should equally be
applied to this type of case.

If you agree this would be useful, I'm happy to write a patch for
merge.data.frame that will add suffixes in this case - I intend to do the
same for merge.data.table in the data.table package where I initially
encountered the edge case.

Best,

Scott

On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:

> Hi Scott,
>
> It seems like reasonable behavior to me. What result would you expect?
> That the second "name" should be called "name.y"?
>
> The "merge" documentation says:
>
>     If the columns in the data frames not used in merging have any
>     common names, these have ?suffixes? (?".x"? and ?".y"? by default)
>     appended to try to make the names of the result unique.
>
> Since the first "name" column was used in merging, leaving both
> without a suffix seems consistent with the documentation...
>
> Frederick
>
> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> > Hi,
> >
> > I was unable to find a bug report for this with a cursory search, but
> would
> > like clarification if this is intended or unavoidable behaviour:
> >
> > ```{r}
> > # Create example data.frames
> > parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> >                       sex=c("F", "M", "F", "M"),
> >                       age=c(41, 43, 36, 51))
> > children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> >                        name=c("Oliver", "Sebastian", "Kai-lee"),
> >                        sex=c("M", "M", "F"),
> >                        age=c(5,8,7))
> >
> > # Merge() creates a duplicated "name" column:
> > merge(parents, children, by.x = "name", by.y = "parent")
> > ```
> >
> > Output:
> > ```
> >    name sex.x age.x      name sex.y age.y
> > 1   Max     M    43 Sebastian     M     8
> > 2   Qin     F    36   Kai-lee     F     7
> > 3 Sarah     F    41    Oliver     M     5
> > Warning message:
> > In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
> >   column name ?name? is duplicated in the result
> > ```
> >
> > Kind Regards,
> >
> > Scott Ritchie
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>

	[[alternative HTML version deleted]]


From s.ritchie73 at gmail.com  Sat Feb 17 06:42:21 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Sat, 17 Feb 2018 16:42:21 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
Message-ID: <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>

The attached patch.diff will make merge.data.frame() append the suffixes to
columns with common names between by.x and names(y).

Best,

Scott Ritchie

On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com> wrote:

> Hi Frederick,
>
> I would expect that any duplicate names in the resulting data.frame would
> have the suffixes appended to them, regardless of whether or not they are
> used as the join key. So in my example I would expect "names.x" and
> "names.y" to indicate their source data.frame.
>
> While careful reading of the documentation reveals this is not the case, I
> would argue the intent of the suffixes functionality should equally be
> applied to this type of case.
>
> If you agree this would be useful, I'm happy to write a patch for
> merge.data.frame that will add suffixes in this case - I intend to do the
> same for merge.data.table in the data.table package where I initially
> encountered the edge case.
>
> Best,
>
> Scott
>
> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
>
>> Hi Scott,
>>
>> It seems like reasonable behavior to me. What result would you expect?
>> That the second "name" should be called "name.y"?
>>
>> The "merge" documentation says:
>>
>>     If the columns in the data frames not used in merging have any
>>     common names, these have ?suffixes? (?".x"? and ?".y"? by default)
>>     appended to try to make the names of the result unique.
>>
>> Since the first "name" column was used in merging, leaving both
>> without a suffix seems consistent with the documentation...
>>
>> Frederick
>>
>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
>> > Hi,
>> >
>> > I was unable to find a bug report for this with a cursory search, but
>> would
>> > like clarification if this is intended or unavoidable behaviour:
>> >
>> > ```{r}
>> > # Create example data.frames
>> > parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
>> >                       sex=c("F", "M", "F", "M"),
>> >                       age=c(41, 43, 36, 51))
>> > children <- data.frame(parent=c("Sarah", "Max", "Qin"),
>> >                        name=c("Oliver", "Sebastian", "Kai-lee"),
>> >                        sex=c("M", "M", "F"),
>> >                        age=c(5,8,7))
>> >
>> > # Merge() creates a duplicated "name" column:
>> > merge(parents, children, by.x = "name", by.y = "parent")
>> > ```
>> >
>> > Output:
>> > ```
>> >    name sex.x age.x      name sex.y age.y
>> > 1   Max     M    43 Sebastian     M     8
>> > 2   Qin     F    36   Kai-lee     F     7
>> > 3 Sarah     F    41    Oliver     M     5
>> > Warning message:
>> > In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
>> >   column name ?name? is duplicated in the result
>> > ```
>> >
>> > Kind Regards,
>> >
>> > Scott Ritchie
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180217/efabe387/attachment.ksh>

From hugh.parsonage at gmail.com  Sat Feb 17 11:10:32 2018
From: hugh.parsonage at gmail.com (Hugh Parsonage)
Date: Sat, 17 Feb 2018 21:10:32 +1100
Subject: [Rd] readLines interaction with gsub different in R-dev
Message-ID: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>

I was told to re-raise this issue with R-dev:

In the documentation of R-dev and R-3.4.3, under ?gsub

> replacement
>    ... For perl = TRUE only, it can also contain "\U" or "\L" to convert the rest of the replacement to upper or lower case and "\E" to end case conversion.

However, the following code runs differently:

tempf <- tempfile()
writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
entry <- readLines(tempf, encoding = "UTF-8")
gsub("(\\w)", "\\U\\1", entry, perl = TRUE)


"AUTHOR: AM?LIE"  # R-3.4.3

"A"                              # R-dev



Best,

Hugh Parsonage.


From edd at debian.org  Sat Feb 17 16:15:19 2018
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 17 Feb 2018 09:15:19 -0600
Subject: [Rd] readLines interaction with gsub different in R-dev
In-Reply-To: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>
References: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>
Message-ID: <23176.18183.140869.415407@rob.eddelbuettel.com>


On 17 February 2018 at 21:10, Hugh Parsonage wrote:
| I was told to re-raise this issue with R-dev:
| 
| In the documentation of R-dev and R-3.4.3, under ?gsub
| 
| > replacement
| >    ... For perl = TRUE only, it can also contain "\U" or "\L" to convert the rest of the replacement to upper or lower case and "\E" to end case conversion.
| 
| However, the following code runs differently:
| 
| tempf <- tempfile()
| writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
| entry <- readLines(tempf, encoding = "UTF-8")
| gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
| 
| 
| "AUTHOR: AM?LIE"  # R-3.4.3
| 
| "A"                              # R-dev

Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the regexp
you use wrong, ie isn't R-devel giving the correct answer?

R> tempf <- tempfile()
R> writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
R> entry <- readLines(tempf, encoding = "UTF-8")
R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
[1] "A"
R> gsub("(\\w+)", "\\U\\1", entry, perl = TRUE)
[1] "AUTHOR"
R> gsub("(.*)", "\\U\\1", entry, perl = TRUE)
[1] "AUTHOR: AM?LIE"
R> 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From hugh.parsonage at gmail.com  Sat Feb 17 16:35:59 2018
From: hugh.parsonage at gmail.com (Hugh Parsonage)
Date: Sun, 18 Feb 2018 02:35:59 +1100
Subject: [Rd] readLines interaction with gsub different in R-dev
In-Reply-To: <23176.18183.140869.415407@rob.eddelbuettel.com>
References: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>
 <23176.18183.140869.415407@rob.eddelbuettel.com>
Message-ID: <CAJmOi+N3HjY_+p7Y0zJbT_8n3STuOrDbFx0JE7qMeDj5JpHDKw@mail.gmail.com>

| Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the regexp
| you use wrong, ie isn't R-devel giving the correct answer?

No, I don't think R-devel is correct (or at least consistent with the
documentation). My interpretation of gsub("(\\w)", "\\U\\1", entry,
perl = TRUE) is "Take every word character and replace it with itself,
converted to uppercase."

Perhaps my example was too minimal. Consider the following:

R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
[1] "A"

R> gsub("(\\w)", "\\1", entry, perl = TRUE)
[1] "author: Am?lie"   # OK, but very different to 'A', despite only
not specifying uppercase

R> gsub("(\\w)", "\\U\\1", "author: Amelie", perl = TRUE)
[1] "AUTHOR: AMELIE"  # OK, but very different to 'A',

R> gsub("^(\\w+?): (\\w)", "\\U\\1\\E: \\2", entry, perl = TRUE)
 "AUTHOR"  # Where did everything after the first group go?

I should note the following example too:
R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE, useBytes = TRUE)
[1] "AUTHOR: AM??LIE"  # latin1 encoding


A call to `readLines` (possibly `scan()` and `read.table` and friends)
is essential.




On 18 February 2018 at 02:15, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 17 February 2018 at 21:10, Hugh Parsonage wrote:
> | I was told to re-raise this issue with R-dev:
> |
> | In the documentation of R-dev and R-3.4.3, under ?gsub
> |
> | > replacement
> | >    ... For perl = TRUE only, it can also contain "\U" or "\L" to convert the rest of the replacement to upper or lower case and "\E" to end case conversion.
> |
> | However, the following code runs differently:
> |
> | tempf <- tempfile()
> | writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
> | entry <- readLines(tempf, encoding = "UTF-8")
> | gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
> |
> |
> | "AUTHOR: AM?LIE"  # R-3.4.3
> |
> | "A"                              # R-dev
>
> Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the regexp
> you use wrong, ie isn't R-devel giving the correct answer?
>
> R> tempf <- tempfile()
> R> writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
> R> entry <- readLines(tempf, encoding = "UTF-8")
> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
> [1] "A"
> R> gsub("(\\w+)", "\\U\\1", entry, perl = TRUE)
> [1] "AUTHOR"
> R> gsub("(.*)", "\\U\\1", entry, perl = TRUE)
> [1] "AUTHOR: AM?LIE"
> R>
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wdunlap at tibco.com  Sat Feb 17 20:24:23 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 17 Feb 2018 11:24:23 -0800
Subject: [Rd] readLines interaction with gsub different in R-dev
In-Reply-To: <CAJmOi+N3HjY_+p7Y0zJbT_8n3STuOrDbFx0JE7qMeDj5JpHDKw@mail.gmail.com>
References: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>
 <23176.18183.140869.415407@rob.eddelbuettel.com>
 <CAJmOi+N3HjY_+p7Y0zJbT_8n3STuOrDbFx0JE7qMeDj5JpHDKw@mail.gmail.com>
Message-ID: <CAF8bMcYdtJGE+K0RiVWTemv=24ENMwV5PBLZq29u9n407b41yA@mail.gmail.com>

I think the problem in R-devel happens when there are non-ASCII characters
in any
of the strings passed to gsub.

txt <- vapply(list(as.raw(c(0x41, 0x6d, 0xc3, 0xa9, 0x6c, 0x69, 0x65)),
as.raw(c(0x41, 0x6d, 0x65, 0x6c, 0x69, 0x61))), rawToChar, "")
txt
#[1] "Am?lie" "Amelia"
Encoding(txt)
#[1] "unknown" "unknown"
gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt)
#[1] "<a" "<a"
gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt[1])
#[1] "<a"
gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt[2])
#[1] "<aM><eL><iA>"

I can change the Encoding to "latin1" or "UTF-8" and get similar results
from gsub.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Feb 17, 2018 at 7:35 AM, Hugh Parsonage <hugh.parsonage at gmail.com>
wrote:

> | Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the
> regexp
> | you use wrong, ie isn't R-devel giving the correct answer?
>
> No, I don't think R-devel is correct (or at least consistent with the
> documentation). My interpretation of gsub("(\\w)", "\\U\\1", entry,
> perl = TRUE) is "Take every word character and replace it with itself,
> converted to uppercase."
>
> Perhaps my example was too minimal. Consider the following:
>
> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
> [1] "A"
>
> R> gsub("(\\w)", "\\1", entry, perl = TRUE)
> [1] "author: Am?lie"   # OK, but very different to 'A', despite only
> not specifying uppercase
>
> R> gsub("(\\w)", "\\U\\1", "author: Amelie", perl = TRUE)
> [1] "AUTHOR: AMELIE"  # OK, but very different to 'A',
>
> R> gsub("^(\\w+?): (\\w)", "\\U\\1\\E: \\2", entry, perl = TRUE)
>  "AUTHOR"  # Where did everything after the first group go?
>
> I should note the following example too:
> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE, useBytes = TRUE)
> [1] "AUTHOR: AM??LIE"  # latin1 encoding
>
>
> A call to `readLines` (possibly `scan()` and `read.table` and friends)
> is essential.
>
>
>
>
> On 18 February 2018 at 02:15, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> > On 17 February 2018 at 21:10, Hugh Parsonage wrote:
> > | I was told to re-raise this issue with R-dev:
> > |
> > | In the documentation of R-dev and R-3.4.3, under ?gsub
> > |
> > | > replacement
> > | >    ... For perl = TRUE only, it can also contain "\U" or "\L" to
> convert the rest of the replacement to upper or lower case and "\E" to end
> case conversion.
> > |
> > | However, the following code runs differently:
> > |
> > | tempf <- tempfile()
> > | writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
> > | entry <- readLines(tempf, encoding = "UTF-8")
> > | gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
> > |
> > |
> > | "AUTHOR: AM?LIE"  # R-3.4.3
> > |
> > | "A"                              # R-dev
> >
> > Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the
> regexp
> > you use wrong, ie isn't R-devel giving the correct answer?
> >
> > R> tempf <- tempfile()
> > R> writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
> > R> entry <- readLines(tempf, encoding = "UTF-8")
> > R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
> > [1] "A"
> > R> gsub("(\\w+)", "\\U\\1", entry, perl = TRUE)
> > [1] "AUTHOR"
> > R> gsub("(.*)", "\\U\\1", entry, perl = TRUE)
> > [1] "AUTHOR: AM?LIE"
> > R>
> >
> > Dirk
> >
> > --
> > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From kevinushey at gmail.com  Sat Feb 17 23:19:50 2018
From: kevinushey at gmail.com (Kevin Ushey)
Date: Sat, 17 Feb 2018 14:19:50 -0800
Subject: [Rd] 
 writeLines argument useBytes = TRUE still making conversions
In-Reply-To: <CA+vqiLFT8Tsq5VumuYELs-ZP5u=z7Ggo3FfiUjFR_bkJTBdexw@mail.gmail.com>
References: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
 <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>
 <CA+vqiLFT8Tsq5VumuYELs-ZP5u=z7Ggo3FfiUjFR_bkJTBdexw@mail.gmail.com>
Message-ID: <CAJXgQP24OpUm20FAxDJeBpjsttVAVk7bv1y1RXt2ii_=8maXrg@mail.gmail.com>

>From my understanding, translation is implied in this line of ?file (from the
Encoding section):

    The encoding of the input/output stream of a connection can be specified
    by name in the same way as it would be given to iconv: see that help page
    for how to find out what encoding names are recognized on your platform.
    Additionally, "" and "native.enc" both mean the ?native? encoding, that is
    the internal encoding of the current locale and hence no translation is
    done.

This is also hinted at in the documentation in ?readLines for its 'encoding'
argument, which has a different semantic meaning from the 'encoding' argument
as used with R connections:

    encoding to be assumed for input strings. It is used to mark character
    strings as known to be in Latin-1 or UTF-8: it is not used to re-encode
    the input. To do the latter, specify the encoding as part of the
    connection con or via options(encoding=): see the examples.

It might be useful to augment the documentation in ?file with something like:

    The 'encoding' argument is used to request the translation of strings when
    writing to a connection.

and, perhaps to further drive home the point about not translating when
encoding = "native.enc":

    Note that R will not attempt translation of strings when encoding is
    either "" or "native.enc" (the default, as per getOption("encoding")).
    This implies that attempting to write, for example, UTF-8 encoded content
    to a connection opened using "native.enc" will retain its original UTF-8
    encoding -- it will not be translated.

It is a bit surprising that 'native.enc' means "do not translate" rather than
"attempt translation to the encoding associated with the current locale", but
those are the semantics and they are not bound to change.

This is the code I used to convince myself of that case:

    conn <- file(tempfile(), encoding = "native.enc", open = "w+")

    before <- iconv('?', to = "UTF-8")
    cat(before, file = conn, sep = "\n")
    after <- readLines(conn)

    charToRaw(before)
    charToRaw(after)

with output:

    > charToRaw(before)
    [1] c3 a9
    > charToRaw(after)
    [1] c3 a9

Best,
Kevin


On Thu, Feb 15, 2018 at 9:16 AM, Ista Zahn <istazahn at gmail.com> wrote:
> On Thu, Feb 15, 2018 at 11:19 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
>> I suspect your UTF-8 string is being stripped of its encoding before
>> write, and so assumed to be in the system native encoding, and then
>> re-encoded as UTF-8 when written to the file. You can see something
>> similar with:
>>
>>     > tmp <- '?'
>>     > tmp <- iconv(tmp, to = 'UTF-8')
>>     > Encoding(tmp) <- "unknown"
>>     > charToRaw(iconv(tmp, to = "UTF-8"))
>>     [1] c3 83 c2 a9
>>
>> It's worth saying that:
>>
>>     file(..., encoding = "UTF-8")
>>
>> means "attempt to re-encode strings as UTF-8 when writing to this
>> file". However, if you already know your text is UTF-8, then you
>> likely want to avoid opening a connection that might attempt to
>> re-encode the input. Conversely (assuming I'm understanding the
>> documentation correctly)
>>
>>     file(..., encoding = "native.enc")
>>
>> means "assume that strings are in the native encoding, and hence
>> translation is unnecessary". Note that it does not mean "attempt to
>> translate strings to the native encoding".
>
> If all that is true I think ?file needs some attention. I've read it
> several times now and I just don't see how it can be interpreted as
> you've described it.
>
> Best,
> Ista
>
>>
>> Also note that writeLines(..., useBytes = FALSE) will explicitly
>> translate to the current encoding before sending bytes to the
>> requested connection. In other words, there are two locations where
>> translation might occur in your example:
>>
>>    1) In the call to writeLines(),
>>    2) When characters are passed to the connection.
>>
>> In your case, it sounds like translation should be suppressed at both steps.
>>
>> I think this is documented correctly in ?writeLines (and also the
>> Encoding section of ?file), but the behavior may feel unfamiliar at
>> first glance.
>>
>> Kevin
>>
>> On Wed, Feb 14, 2018 at 11:36 PM, Davor Josipovic <davorj at live.com> wrote:
>>>
>>> I think this behavior is inconsistent with the documentation:
>>>
>>>   tmp <- '?'
>>>   tmp <- iconv(tmp, to = 'UTF-8')
>>>   print(Encoding(tmp))
>>>   print(charToRaw(tmp))
>>>   tmpfilepath <- tempfile()
>>>   writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>>>
>>> [1] "UTF-8"
>>> [1] c3 a9
>>>
>>> Raw text as hex: c3 83 c2 a9
>>>
>>> If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.
>>>
>>> Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevinushey at gmail.com  Sat Feb 17 23:24:11 2018
From: kevinushey at gmail.com (Kevin Ushey)
Date: Sat, 17 Feb 2018 14:24:11 -0800
Subject: [Rd] 
 writeLines argument useBytes = TRUE still making conversions
In-Reply-To: <CAJXgQP24OpUm20FAxDJeBpjsttVAVk7bv1y1RXt2ii_=8maXrg@mail.gmail.com>
References: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
 <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>
 <CA+vqiLFT8Tsq5VumuYELs-ZP5u=z7Ggo3FfiUjFR_bkJTBdexw@mail.gmail.com>
 <CAJXgQP24OpUm20FAxDJeBpjsttVAVk7bv1y1RXt2ii_=8maXrg@mail.gmail.com>
Message-ID: <CAJXgQP3zDKCjWpODs--kay8=F0Jnp9WLNK6T-zwz__LZ6KEjKg@mail.gmail.com>

Of course, right after writing this e-mail I tested on my Windows
machine and did not see what I expected:

> charToRaw(before)
[1] c3 a9
> charToRaw(after)
[1] e9

so obviously I'm misunderstanding something as well.

Best,
Kevin

On Sat, Feb 17, 2018 at 2:19 PM, Kevin Ushey <kevinushey at gmail.com> wrote:
> From my understanding, translation is implied in this line of ?file (from the
> Encoding section):
>
>     The encoding of the input/output stream of a connection can be specified
>     by name in the same way as it would be given to iconv: see that help page
>     for how to find out what encoding names are recognized on your platform.
>     Additionally, "" and "native.enc" both mean the ?native? encoding, that is
>     the internal encoding of the current locale and hence no translation is
>     done.
>
> This is also hinted at in the documentation in ?readLines for its 'encoding'
> argument, which has a different semantic meaning from the 'encoding' argument
> as used with R connections:
>
>     encoding to be assumed for input strings. It is used to mark character
>     strings as known to be in Latin-1 or UTF-8: it is not used to re-encode
>     the input. To do the latter, specify the encoding as part of the
>     connection con or via options(encoding=): see the examples.
>
> It might be useful to augment the documentation in ?file with something like:
>
>     The 'encoding' argument is used to request the translation of strings when
>     writing to a connection.
>
> and, perhaps to further drive home the point about not translating when
> encoding = "native.enc":
>
>     Note that R will not attempt translation of strings when encoding is
>     either "" or "native.enc" (the default, as per getOption("encoding")).
>     This implies that attempting to write, for example, UTF-8 encoded content
>     to a connection opened using "native.enc" will retain its original UTF-8
>     encoding -- it will not be translated.
>
> It is a bit surprising that 'native.enc' means "do not translate" rather than
> "attempt translation to the encoding associated with the current locale", but
> those are the semantics and they are not bound to change.
>
> This is the code I used to convince myself of that case:
>
>     conn <- file(tempfile(), encoding = "native.enc", open = "w+")
>
>     before <- iconv('?', to = "UTF-8")
>     cat(before, file = conn, sep = "\n")
>     after <- readLines(conn)
>
>     charToRaw(before)
>     charToRaw(after)
>
> with output:
>
>     > charToRaw(before)
>     [1] c3 a9
>     > charToRaw(after)
>     [1] c3 a9
>
> Best,
> Kevin
>
>
> On Thu, Feb 15, 2018 at 9:16 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> On Thu, Feb 15, 2018 at 11:19 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
>>> I suspect your UTF-8 string is being stripped of its encoding before
>>> write, and so assumed to be in the system native encoding, and then
>>> re-encoded as UTF-8 when written to the file. You can see something
>>> similar with:
>>>
>>>     > tmp <- '?'
>>>     > tmp <- iconv(tmp, to = 'UTF-8')
>>>     > Encoding(tmp) <- "unknown"
>>>     > charToRaw(iconv(tmp, to = "UTF-8"))
>>>     [1] c3 83 c2 a9
>>>
>>> It's worth saying that:
>>>
>>>     file(..., encoding = "UTF-8")
>>>
>>> means "attempt to re-encode strings as UTF-8 when writing to this
>>> file". However, if you already know your text is UTF-8, then you
>>> likely want to avoid opening a connection that might attempt to
>>> re-encode the input. Conversely (assuming I'm understanding the
>>> documentation correctly)
>>>
>>>     file(..., encoding = "native.enc")
>>>
>>> means "assume that strings are in the native encoding, and hence
>>> translation is unnecessary". Note that it does not mean "attempt to
>>> translate strings to the native encoding".
>>
>> If all that is true I think ?file needs some attention. I've read it
>> several times now and I just don't see how it can be interpreted as
>> you've described it.
>>
>> Best,
>> Ista
>>
>>>
>>> Also note that writeLines(..., useBytes = FALSE) will explicitly
>>> translate to the current encoding before sending bytes to the
>>> requested connection. In other words, there are two locations where
>>> translation might occur in your example:
>>>
>>>    1) In the call to writeLines(),
>>>    2) When characters are passed to the connection.
>>>
>>> In your case, it sounds like translation should be suppressed at both steps.
>>>
>>> I think this is documented correctly in ?writeLines (and also the
>>> Encoding section of ?file), but the behavior may feel unfamiliar at
>>> first glance.
>>>
>>> Kevin
>>>
>>> On Wed, Feb 14, 2018 at 11:36 PM, Davor Josipovic <davorj at live.com> wrote:
>>>>
>>>> I think this behavior is inconsistent with the documentation:
>>>>
>>>>   tmp <- '?'
>>>>   tmp <- iconv(tmp, to = 'UTF-8')
>>>>   print(Encoding(tmp))
>>>>   print(charToRaw(tmp))
>>>>   tmpfilepath <- tempfile()
>>>>   writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>>>>
>>>> [1] "UTF-8"
>>>> [1] c3 a9
>>>>
>>>> Raw text as hex: c3 83 c2 a9
>>>>
>>>> If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.
>>>>
>>>> Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From frederik at ofb.net  Sun Feb 18 00:36:40 2018
From: frederik at ofb.net (frederik at ofb.net)
Date: Sat, 17 Feb 2018 15:36:40 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
Message-ID: <20180217233640.GG32564@ofb.net>

Hi Scott,

Thanks for the patch. I'm not really involved in R development; it
will be up to someone in the R core team to apply it. I would hazard
to say that even if correct (I haven't checked), it will not be
applied because the change might break existing code. For example it
seems like reasonable code might easily assume that a column with the
same name as "by.x" exists in the output of 'merge'. That's just my
best guess... I don't participate on here often.

Cheers,

Frederick

On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> The attached patch.diff will make merge.data.frame() append the suffixes to
> columns with common names between by.x and names(y).
> 
> Best,
> 
> Scott Ritchie
> 
> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com> wrote:
> 
> > Hi Frederick,
> >
> > I would expect that any duplicate names in the resulting data.frame would
> > have the suffixes appended to them, regardless of whether or not they are
> > used as the join key. So in my example I would expect "names.x" and
> > "names.y" to indicate their source data.frame.
> >
> > While careful reading of the documentation reveals this is not the case, I
> > would argue the intent of the suffixes functionality should equally be
> > applied to this type of case.
> >
> > If you agree this would be useful, I'm happy to write a patch for
> > merge.data.frame that will add suffixes in this case - I intend to do the
> > same for merge.data.table in the data.table package where I initially
> > encountered the edge case.
> >
> > Best,
> >
> > Scott
> >
> > On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> >
> >> Hi Scott,
> >>
> >> It seems like reasonable behavior to me. What result would you expect?
> >> That the second "name" should be called "name.y"?
> >>
> >> The "merge" documentation says:
> >>
> >>     If the columns in the data frames not used in merging have any
> >>     common names, these have ?suffixes? (?".x"? and ?".y"? by default)
> >>     appended to try to make the names of the result unique.
> >>
> >> Since the first "name" column was used in merging, leaving both
> >> without a suffix seems consistent with the documentation...
> >>
> >> Frederick
> >>
> >> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> >> > Hi,
> >> >
> >> > I was unable to find a bug report for this with a cursory search, but
> >> would
> >> > like clarification if this is intended or unavoidable behaviour:
> >> >
> >> > ```{r}
> >> > # Create example data.frames
> >> > parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> >> >                       sex=c("F", "M", "F", "M"),
> >> >                       age=c(41, 43, 36, 51))
> >> > children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> >> >                        name=c("Oliver", "Sebastian", "Kai-lee"),
> >> >                        sex=c("M", "M", "F"),
> >> >                        age=c(5,8,7))
> >> >
> >> > # Merge() creates a duplicated "name" column:
> >> > merge(parents, children, by.x = "name", by.y = "parent")
> >> > ```
> >> >
> >> > Output:
> >> > ```
> >> >    name sex.x age.x      name sex.y age.y
> >> > 1   Max     M    43 Sebastian     M     8
> >> > 2   Qin     F    36   Kai-lee     F     7
> >> > 3 Sarah     F    41    Oliver     M     5
> >> > Warning message:
> >> > In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
> >> >   column name ?name? is duplicated in the result
> >> > ```
> >> >
> >> > Kind Regards,
> >> >
> >> > Scott Ritchie
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >>
> >
> >

> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R	(revision 74264)
> +++ src/library/base/R/merge.R	(working copy)
> @@ -157,6 +157,15 @@
>          }
>  
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to these
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[1L]))
> +            names(x)[match(dupe.keyx, names(x), 0L)] <- paste(dupe.keyx, suffixes[1L], sep="")
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx, suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)


From murdoch.duncan at gmail.com  Sun Feb 18 01:48:58 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 17 Feb 2018 19:48:58 -0500
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <20180217233640.GG32564@ofb.net>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
Message-ID: <ab784c23-f231-330a-c305-50130770e291@gmail.com>

On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> Hi Scott,
> 
> Thanks for the patch. I'm not really involved in R development; it
> will be up to someone in the R core team to apply it. I would hazard
> to say that even if correct (I haven't checked), it will not be
> applied because the change might break existing code. For example it
> seems like reasonable code might easily assume that a column with the
> same name as "by.x" exists in the output of 'merge'. That's just my
> best guess... I don't participate on here often.


I think you're right.  If I were still a member of R Core, I would want 
to test this against all packages on CRAN and Bioconductor, and since 
that test takes a couple of days to run on my laptop, I'd probably never 
get around to it.

There are lots of cases where "I would have done that differently", but 
most of them are far too much trouble to change now that R is more than 
20 years old.  And in many cases it will turn out that the way R does it 
actually does make more sense than the way I would have done it.

Duncan Murdoch

> 
> Cheers,
> 
> Frederick
> 
> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
>> The attached patch.diff will make merge.data.frame() append the suffixes to
>> columns with common names between by.x and names(y).
>>
>> Best,
>>
>> Scott Ritchie
>>
>> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com> wrote:
>>
>>> Hi Frederick,
>>>
>>> I would expect that any duplicate names in the resulting data.frame would
>>> have the suffixes appended to them, regardless of whether or not they are
>>> used as the join key. So in my example I would expect "names.x" and
>>> "names.y" to indicate their source data.frame.
>>>
>>> While careful reading of the documentation reveals this is not the case, I
>>> would argue the intent of the suffixes functionality should equally be
>>> applied to this type of case.
>>>
>>> If you agree this would be useful, I'm happy to write a patch for
>>> merge.data.frame that will add suffixes in this case - I intend to do the
>>> same for merge.data.table in the data.table package where I initially
>>> encountered the edge case.
>>>
>>> Best,
>>>
>>> Scott
>>>
>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
>>>
>>>> Hi Scott,
>>>>
>>>> It seems like reasonable behavior to me. What result would you expect?
>>>> That the second "name" should be called "name.y"?
>>>>
>>>> The "merge" documentation says:
>>>>
>>>>      If the columns in the data frames not used in merging have any
>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by default)
>>>>      appended to try to make the names of the result unique.
>>>>
>>>> Since the first "name" column was used in merging, leaving both
>>>> without a suffix seems consistent with the documentation...
>>>>
>>>> Frederick
>>>>
>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
>>>>> Hi,
>>>>>
>>>>> I was unable to find a bug report for this with a cursory search, but
>>>> would
>>>>> like clarification if this is intended or unavoidable behaviour:
>>>>>
>>>>> ```{r}
>>>>> # Create example data.frames
>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
>>>>>                        sex=c("F", "M", "F", "M"),
>>>>>                        age=c(41, 43, 36, 51))
>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
>>>>>                         name=c("Oliver", "Sebastian", "Kai-lee"),
>>>>>                         sex=c("M", "M", "F"),
>>>>>                         age=c(5,8,7))
>>>>>
>>>>> # Merge() creates a duplicated "name" column:
>>>>> merge(parents, children, by.x = "name", by.y = "parent")
>>>>> ```
>>>>>
>>>>> Output:
>>>>> ```
>>>>>     name sex.x age.x      name sex.y age.y
>>>>> 1   Max     M    43 Sebastian     M     8
>>>>> 2   Qin     F    36   Kai-lee     F     7
>>>>> 3 Sarah     F    41    Oliver     M     5
>>>>> Warning message:
>>>>> In merge.data.frame(parents, children, by.x = "name", by.y = "parent") :
>>>>>    column name ?name? is duplicated in the result
>>>>> ```
>>>>>
>>>>> Kind Regards,
>>>>>
>>>>> Scott Ritchie
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>
>>>
> 
>> Index: src/library/base/R/merge.R
>> ===================================================================
>> --- src/library/base/R/merge.R	(revision 74264)
>> +++ src/library/base/R/merge.R	(working copy)
>> @@ -157,6 +157,15 @@
>>           }
>>   
>>           if(has.common.nms) names(y) <- nm.y
>> +        ## If by.x %in% names(y) then duplicate column names still arise,
>> +        ## apply suffixes to these
>> +        dupe.keyx <- intersect(nm.by, names(y))
>> +        if(length(dupe.keyx)) {
>> +          if(nzchar(suffixes[1L]))
>> +            names(x)[match(dupe.keyx, names(x), 0L)] <- paste(dupe.keyx, suffixes[1L], sep="")
>> +          if(nzchar(suffixes[2L]))
>> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx, suffixes[2L], sep="")
>> +        }
>>           nm <- c(names(x), names(y))
>>           if(any(d <- duplicated(nm)))
>>               if(sum(d) > 1L)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at prodsyse.com  Sun Feb 18 03:48:44 2018
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 17 Feb 2018 20:48:44 -0600
Subject: [Rd] Draft proposal for Searching R Packages
In-Reply-To: <CA+mbi1ctsGUMFVaWC9jqwdwRf6bSZrpGHn8=gEB2HPjMjSkKsw@mail.gmail.com>
References: <9a34c09a-a531-38ba-5e77-d6e3d848064a@prodsyse.com>
 <9617D71649BB1F4FB51D5CA6B6C1FECB704B8B90@CHH-EX2K10-1>
 <20180201190912.GB20849@upenn.edu> <20180201191735.GC20849@upenn.edu>
 <e8dae538-bfdd-c671-2bfc-3296bb785ab9@prodsyse.com>
 <20180201203227.GA22934@upenn.edu>
 <2d7b3b8a-ea9d-df77-b3ff-80e119a3bc92@prodsyse.com>
 <CA+mbi1ctsGUMFVaWC9jqwdwRf6bSZrpGHn8=gEB2HPjMjSkKsw@mail.gmail.com>
Message-ID: <6ecaed5d-79af-c7d0-9176-425f579ab4b5@prodsyse.com>

Hello, All:


 ????? I just posted a "Draft Proposal for improving the ability of R 
users to search R packages" to Wikiversity 
(https://en.wikiversity.org/wiki/Draft_Proposal_for_improving_the_ability_of_R_users_to_search_R_packages). 



 ????? You are all invited to rewrite it in any way you think is more 
likely to produce the most useful result.? Wikimedia invites 
contributors to "be bold but not reckless", writing from a neutral point 
of view citing credible sources.? I do NOT want to do this project:? I 
think the world will be better if it is done, and I think others are 
better equipped to actually do it -- or manage others doing it -- than I am.


 ????? If you read this, you will see that it contains critical gaps.? I 
hope one or more of you will fill these critical gaps or help find 
others who will.


 ????? As indicated there, the next major deadline is April 1.? This 
sounds like lots of time, except that the key thing that is missing in 
this draft proposal is principal investigator(s).? Without PI(s), it 
won't fly.


 ????? Thanks,
 ????? Spencer Graves, PhD
 ????? Founder
 ????? EffectivedDefense.org
 ????? 7300 W. 107th St. # 506
 ????? Overland Park, KS 66212
ph:? 408-655-4567


From s.ritchie73 at gmail.com  Sun Feb 18 03:50:19 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Sun, 18 Feb 2018 13:50:19 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <ab784c23-f231-330a-c305-50130770e291@gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
Message-ID: <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>

Thanks Duncan and Frederick,

I suspected as much - there doesn't appear to be any reason why conflicts
between by.x and names(y) shouldn't and cannot be checked, but I can see
how this might be more trouble than its worth given it potentially may
break downstream packages (i.e. any cases where this occurs but they expect
the name of the key column(s) to remain the same).

Best,

Scott

On 18 February 2018 at 11:48, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
>
>> Hi Scott,
>>
>> Thanks for the patch. I'm not really involved in R development; it
>> will be up to someone in the R core team to apply it. I would hazard
>> to say that even if correct (I haven't checked), it will not be
>> applied because the change might break existing code. For example it
>> seems like reasonable code might easily assume that a column with the
>> same name as "by.x" exists in the output of 'merge'. That's just my
>> best guess... I don't participate on here often.
>>
>
>
> I think you're right.  If I were still a member of R Core, I would want to
> test this against all packages on CRAN and Bioconductor, and since that
> test takes a couple of days to run on my laptop, I'd probably never get
> around to it.
>
> There are lots of cases where "I would have done that differently", but
> most of them are far too much trouble to change now that R is more than 20
> years old.  And in many cases it will turn out that the way R does it
> actually does make more sense than the way I would have done it.
>
> Duncan Murdoch
>
>
>
>> Cheers,
>>
>> Frederick
>>
>> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
>>
>>> The attached patch.diff will make merge.data.frame() append the suffixes
>>> to
>>> columns with common names between by.x and names(y).
>>>
>>> Best,
>>>
>>> Scott Ritchie
>>>
>>> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com>
>>> wrote:
>>>
>>> Hi Frederick,
>>>>
>>>> I would expect that any duplicate names in the resulting data.frame
>>>> would
>>>> have the suffixes appended to them, regardless of whether or not they
>>>> are
>>>> used as the join key. So in my example I would expect "names.x" and
>>>> "names.y" to indicate their source data.frame.
>>>>
>>>> While careful reading of the documentation reveals this is not the
>>>> case, I
>>>> would argue the intent of the suffixes functionality should equally be
>>>> applied to this type of case.
>>>>
>>>> If you agree this would be useful, I'm happy to write a patch for
>>>> merge.data.frame that will add suffixes in this case - I intend to do
>>>> the
>>>> same for merge.data.table in the data.table package where I initially
>>>> encountered the edge case.
>>>>
>>>> Best,
>>>>
>>>> Scott
>>>>
>>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
>>>>
>>>> Hi Scott,
>>>>>
>>>>> It seems like reasonable behavior to me. What result would you expect?
>>>>> That the second "name" should be called "name.y"?
>>>>>
>>>>> The "merge" documentation says:
>>>>>
>>>>>      If the columns in the data frames not used in merging have any
>>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by default)
>>>>>      appended to try to make the names of the result unique.
>>>>>
>>>>> Since the first "name" column was used in merging, leaving both
>>>>> without a suffix seems consistent with the documentation...
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I was unable to find a bug report for this with a cursory search, but
>>>>>>
>>>>> would
>>>>>
>>>>>> like clarification if this is intended or unavoidable behaviour:
>>>>>>
>>>>>> ```{r}
>>>>>> # Create example data.frames
>>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
>>>>>>                        sex=c("F", "M", "F", "M"),
>>>>>>                        age=c(41, 43, 36, 51))
>>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
>>>>>>                         name=c("Oliver", "Sebastian", "Kai-lee"),
>>>>>>                         sex=c("M", "M", "F"),
>>>>>>                         age=c(5,8,7))
>>>>>>
>>>>>> # Merge() creates a duplicated "name" column:
>>>>>> merge(parents, children, by.x = "name", by.y = "parent")
>>>>>> ```
>>>>>>
>>>>>> Output:
>>>>>> ```
>>>>>>     name sex.x age.x      name sex.y age.y
>>>>>> 1   Max     M    43 Sebastian     M     8
>>>>>> 2   Qin     F    36   Kai-lee     F     7
>>>>>> 3 Sarah     F    41    Oliver     M     5
>>>>>> Warning message:
>>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
>>>>>> "parent") :
>>>>>>    column name ?name? is duplicated in the result
>>>>>> ```
>>>>>>
>>>>>> Kind Regards,
>>>>>>
>>>>>> Scott Ritchie
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>
>>>>>
>>>>
>>>>
>> Index: src/library/base/R/merge.R
>>> ===================================================================
>>> --- src/library/base/R/merge.R  (revision 74264)
>>> +++ src/library/base/R/merge.R  (working copy)
>>> @@ -157,6 +157,15 @@
>>>           }
>>>             if(has.common.nms) names(y) <- nm.y
>>> +        ## If by.x %in% names(y) then duplicate column names still
>>> arise,
>>> +        ## apply suffixes to these
>>> +        dupe.keyx <- intersect(nm.by, names(y))
>>> +        if(length(dupe.keyx)) {
>>> +          if(nzchar(suffixes[1L]))
>>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
>>> paste(dupe.keyx, suffixes[1L], sep="")
>>> +          if(nzchar(suffixes[2L]))
>>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
>>> paste(dupe.keyx, suffixes[2L], sep="")
>>> +        }
>>>           nm <- c(names(x), names(y))
>>>           if(any(d <- duplicated(nm)))
>>>               if(sum(d) > 1L)
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Sun Feb 18 19:08:31 2018
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 18 Feb 2018 10:08:31 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
Message-ID: <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>

It seems like there is a way that is backwards compatible-ish in the sense
mentioned and still has the (arguably, but a good argument I think) better
behavior:

if by.x is 'name', (AND by.y is not also 'name'), then x's 'name' column is
called name and y's 'name' column (not used int he merge) is changed to
name.y.

Now of course this would still change output, but it would change it to
something I think would be better, while retaining the 'merge columns
retain their exact names' mechanic as documented.

~G

On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <s.ritchie73 at gmail.com>
wrote:

> Thanks Duncan and Frederick,
>
> I suspected as much - there doesn't appear to be any reason why conflicts
> between by.x and names(y) shouldn't and cannot be checked, but I can see
> how this might be more trouble than its worth given it potentially may
> break downstream packages (i.e. any cases where this occurs but they expect
> the name of the key column(s) to remain the same).
>
> Best,
>
> Scott
>
> On 18 February 2018 at 11:48, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> >
> >> Hi Scott,
> >>
> >> Thanks for the patch. I'm not really involved in R development; it
> >> will be up to someone in the R core team to apply it. I would hazard
> >> to say that even if correct (I haven't checked), it will not be
> >> applied because the change might break existing code. For example it
> >> seems like reasonable code might easily assume that a column with the
> >> same name as "by.x" exists in the output of 'merge'. That's just my
> >> best guess... I don't participate on here often.
> >>
> >
> >
> > I think you're right.  If I were still a member of R Core, I would want
> to
> > test this against all packages on CRAN and Bioconductor, and since that
> > test takes a couple of days to run on my laptop, I'd probably never get
> > around to it.
> >
> > There are lots of cases where "I would have done that differently", but
> > most of them are far too much trouble to change now that R is more than
> 20
> > years old.  And in many cases it will turn out that the way R does it
> > actually does make more sense than the way I would have done it.
> >
> > Duncan Murdoch
> >
> >
> >
> >> Cheers,
> >>
> >> Frederick
> >>
> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> >>
> >>> The attached patch.diff will make merge.data.frame() append the
> suffixes
> >>> to
> >>> columns with common names between by.x and names(y).
> >>>
> >>> Best,
> >>>
> >>> Scott Ritchie
> >>>
> >>> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com>
> >>> wrote:
> >>>
> >>> Hi Frederick,
> >>>>
> >>>> I would expect that any duplicate names in the resulting data.frame
> >>>> would
> >>>> have the suffixes appended to them, regardless of whether or not they
> >>>> are
> >>>> used as the join key. So in my example I would expect "names.x" and
> >>>> "names.y" to indicate their source data.frame.
> >>>>
> >>>> While careful reading of the documentation reveals this is not the
> >>>> case, I
> >>>> would argue the intent of the suffixes functionality should equally be
> >>>> applied to this type of case.
> >>>>
> >>>> If you agree this would be useful, I'm happy to write a patch for
> >>>> merge.data.frame that will add suffixes in this case - I intend to do
> >>>> the
> >>>> same for merge.data.table in the data.table package where I initially
> >>>> encountered the edge case.
> >>>>
> >>>> Best,
> >>>>
> >>>> Scott
> >>>>
> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> >>>>
> >>>> Hi Scott,
> >>>>>
> >>>>> It seems like reasonable behavior to me. What result would you
> expect?
> >>>>> That the second "name" should be called "name.y"?
> >>>>>
> >>>>> The "merge" documentation says:
> >>>>>
> >>>>>      If the columns in the data frames not used in merging have any
> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by
> default)
> >>>>>      appended to try to make the names of the result unique.
> >>>>>
> >>>>> Since the first "name" column was used in merging, leaving both
> >>>>> without a suffix seems consistent with the documentation...
> >>>>>
> >>>>> Frederick
> >>>>>
> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> >>>>>
> >>>>>> Hi,
> >>>>>>
> >>>>>> I was unable to find a bug report for this with a cursory search,
> but
> >>>>>>
> >>>>> would
> >>>>>
> >>>>>> like clarification if this is intended or unavoidable behaviour:
> >>>>>>
> >>>>>> ```{r}
> >>>>>> # Create example data.frames
> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> >>>>>>                        sex=c("F", "M", "F", "M"),
> >>>>>>                        age=c(41, 43, 36, 51))
> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> >>>>>>                         name=c("Oliver", "Sebastian", "Kai-lee"),
> >>>>>>                         sex=c("M", "M", "F"),
> >>>>>>                         age=c(5,8,7))
> >>>>>>
> >>>>>> # Merge() creates a duplicated "name" column:
> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
> >>>>>> ```
> >>>>>>
> >>>>>> Output:
> >>>>>> ```
> >>>>>>     name sex.x age.x      name sex.y age.y
> >>>>>> 1   Max     M    43 Sebastian     M     8
> >>>>>> 2   Qin     F    36   Kai-lee     F     7
> >>>>>> 3 Sarah     F    41    Oliver     M     5
> >>>>>> Warning message:
> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
> >>>>>> "parent") :
> >>>>>>    column name ?name? is duplicated in the result
> >>>>>> ```
> >>>>>>
> >>>>>> Kind Regards,
> >>>>>>
> >>>>>> Scott Ritchie
> >>>>>>
> >>>>>>        [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>
> >>>>>>
> >>>>>
> >>>>
> >>>>
> >> Index: src/library/base/R/merge.R
> >>> ===================================================================
> >>> --- src/library/base/R/merge.R  (revision 74264)
> >>> +++ src/library/base/R/merge.R  (working copy)
> >>> @@ -157,6 +157,15 @@
> >>>           }
> >>>             if(has.common.nms) names(y) <- nm.y
> >>> +        ## If by.x %in% names(y) then duplicate column names still
> >>> arise,
> >>> +        ## apply suffixes to these
> >>> +        dupe.keyx <- intersect(nm.by, names(y))
> >>> +        if(length(dupe.keyx)) {
> >>> +          if(nzchar(suffixes[1L]))
> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> >>> paste(dupe.keyx, suffixes[1L], sep="")
> >>> +          if(nzchar(suffixes[2L]))
> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> >>> paste(dupe.keyx, suffixes[2L], sep="")
> >>> +        }
> >>>           nm <- c(names(x), names(y))
> >>>           if(any(d <- duplicated(nm)))
> >>>               if(sum(d) > 1L)
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From s.ritchie73 at gmail.com  Sun Feb 18 21:19:32 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Mon, 19 Feb 2018 07:19:32 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
Message-ID: <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>

Thanks Gabriel,

I think your suggested approach is 100% backwards compatible

Currently in the case of duplicate column names only the first can be
indexed by its name. This will always be the column appearing in by.x,
meaning the column in y with the same name cannot be accessed. Appending
".y" (suffixes[2L]) to this column means it can now be accessed, while
keeping the current behaviour of making the key columns always accessible
by using the names provided to by.x.

I've attached a new patch that has this behaviour.

Best,

Scott

On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> It seems like there is a way that is backwards compatible-ish in the sense
> mentioned and still has the (arguably, but a good argument I think) better
> behavior:
>
> if by.x is 'name', (AND by.y is not also 'name'), then x's 'name' column
> is called name and y's 'name' column (not used int he merge) is changed to
> name.y.
>
> Now of course this would still change output, but it would change it to
> something I think would be better, while retaining the 'merge columns
> retain their exact names' mechanic as documented.
>
> ~G
>
> On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <s.ritchie73 at gmail.com>
> wrote:
>
>> Thanks Duncan and Frederick,
>>
>> I suspected as much - there doesn't appear to be any reason why conflicts
>> between by.x and names(y) shouldn't and cannot be checked, but I can see
>> how this might be more trouble than its worth given it potentially may
>> break downstream packages (i.e. any cases where this occurs but they
>> expect
>> the name of the key column(s) to remain the same).
>>
>> Best,
>>
>> Scott
>>
>> On 18 February 2018 at 11:48, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
>> >
>> >> Hi Scott,
>> >>
>> >> Thanks for the patch. I'm not really involved in R development; it
>> >> will be up to someone in the R core team to apply it. I would hazard
>> >> to say that even if correct (I haven't checked), it will not be
>> >> applied because the change might break existing code. For example it
>> >> seems like reasonable code might easily assume that a column with the
>> >> same name as "by.x" exists in the output of 'merge'. That's just my
>> >> best guess... I don't participate on here often.
>> >>
>> >
>> >
>> > I think you're right.  If I were still a member of R Core, I would want
>> to
>> > test this against all packages on CRAN and Bioconductor, and since that
>> > test takes a couple of days to run on my laptop, I'd probably never get
>> > around to it.
>> >
>> > There are lots of cases where "I would have done that differently", but
>> > most of them are far too much trouble to change now that R is more than
>> 20
>> > years old.  And in many cases it will turn out that the way R does it
>> > actually does make more sense than the way I would have done it.
>> >
>> > Duncan Murdoch
>> >
>> >
>> >
>> >> Cheers,
>> >>
>> >> Frederick
>> >>
>> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
>> >>
>> >>> The attached patch.diff will make merge.data.frame() append the
>> suffixes
>> >>> to
>> >>> columns with common names between by.x and names(y).
>> >>>
>> >>> Best,
>> >>>
>> >>> Scott Ritchie
>> >>>
>> >>> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com>
>> >>> wrote:
>> >>>
>> >>> Hi Frederick,
>> >>>>
>> >>>> I would expect that any duplicate names in the resulting data.frame
>> >>>> would
>> >>>> have the suffixes appended to them, regardless of whether or not they
>> >>>> are
>> >>>> used as the join key. So in my example I would expect "names.x" and
>> >>>> "names.y" to indicate their source data.frame.
>> >>>>
>> >>>> While careful reading of the documentation reveals this is not the
>> >>>> case, I
>> >>>> would argue the intent of the suffixes functionality should equally
>> be
>> >>>> applied to this type of case.
>> >>>>
>> >>>> If you agree this would be useful, I'm happy to write a patch for
>> >>>> merge.data.frame that will add suffixes in this case - I intend to do
>> >>>> the
>> >>>> same for merge.data.table in the data.table package where I initially
>> >>>> encountered the edge case.
>> >>>>
>> >>>> Best,
>> >>>>
>> >>>> Scott
>> >>>>
>> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
>> >>>>
>> >>>> Hi Scott,
>> >>>>>
>> >>>>> It seems like reasonable behavior to me. What result would you
>> expect?
>> >>>>> That the second "name" should be called "name.y"?
>> >>>>>
>> >>>>> The "merge" documentation says:
>> >>>>>
>> >>>>>      If the columns in the data frames not used in merging have any
>> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by
>> default)
>> >>>>>      appended to try to make the names of the result unique.
>> >>>>>
>> >>>>> Since the first "name" column was used in merging, leaving both
>> >>>>> without a suffix seems consistent with the documentation...
>> >>>>>
>> >>>>> Frederick
>> >>>>>
>> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
>> >>>>>
>> >>>>>> Hi,
>> >>>>>>
>> >>>>>> I was unable to find a bug report for this with a cursory search,
>> but
>> >>>>>>
>> >>>>> would
>> >>>>>
>> >>>>>> like clarification if this is intended or unavoidable behaviour:
>> >>>>>>
>> >>>>>> ```{r}
>> >>>>>> # Create example data.frames
>> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
>> >>>>>>                        sex=c("F", "M", "F", "M"),
>> >>>>>>                        age=c(41, 43, 36, 51))
>> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
>> >>>>>>                         name=c("Oliver", "Sebastian", "Kai-lee"),
>> >>>>>>                         sex=c("M", "M", "F"),
>> >>>>>>                         age=c(5,8,7))
>> >>>>>>
>> >>>>>> # Merge() creates a duplicated "name" column:
>> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
>> >>>>>> ```
>> >>>>>>
>> >>>>>> Output:
>> >>>>>> ```
>> >>>>>>     name sex.x age.x      name sex.y age.y
>> >>>>>> 1   Max     M    43 Sebastian     M     8
>> >>>>>> 2   Qin     F    36   Kai-lee     F     7
>> >>>>>> 3 Sarah     F    41    Oliver     M     5
>> >>>>>> Warning message:
>> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
>> >>>>>> "parent") :
>> >>>>>>    column name ?name? is duplicated in the result
>> >>>>>> ```
>> >>>>>>
>> >>>>>> Kind Regards,
>> >>>>>>
>> >>>>>> Scott Ritchie
>> >>>>>>
>> >>>>>>        [[alternative HTML version deleted]]
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-devel at r-project.org mailing list
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>>>>
>> >>>>>>
>> >>>>>
>> >>>>
>> >>>>
>> >> Index: src/library/base/R/merge.R
>> >>> ===================================================================
>> >>> --- src/library/base/R/merge.R  (revision 74264)
>> >>> +++ src/library/base/R/merge.R  (working copy)
>> >>> @@ -157,6 +157,15 @@
>> >>>           }
>> >>>             if(has.common.nms) names(y) <- nm.y
>> >>> +        ## If by.x %in% names(y) then duplicate column names still
>> >>> arise,
>> >>> +        ## apply suffixes to these
>> >>> +        dupe.keyx <- intersect(nm.by, names(y))
>> >>> +        if(length(dupe.keyx)) {
>> >>> +          if(nzchar(suffixes[1L]))
>> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
>> >>> paste(dupe.keyx, suffixes[1L], sep="")
>> >>> +          if(nzchar(suffixes[2L]))
>> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
>> >>> paste(dupe.keyx, suffixes[2L], sep="")
>> >>> +        }
>> >>>           nm <- c(names(x), names(y))
>> >>>           if(any(d <- duplicated(nm)))
>> >>>               if(sum(d) > 1L)
>> >>>
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker, PhD
> Scientist (Bioinformatics)
> Genentech Research
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180219/6c467cb5/attachment.ksh>

From tomas.kalibera at gmail.com  Mon Feb 19 12:08:35 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 19 Feb 2018 12:08:35 +0100
Subject: [Rd] 
 writeLines argument useBytes = TRUE still making conversions
In-Reply-To: <CAJXgQP3zDKCjWpODs--kay8=F0Jnp9WLNK6T-zwz__LZ6KEjKg@mail.gmail.com>
References: <MWHPR03MB327997228A6D35430EA431FBA7F40@MWHPR03MB3279.namprd03.prod.outlook.com>
 <CAJXgQP1PBMP-ZFC397_iDc6sj5YAPnovR0AgOCpNDimJVcfCZw@mail.gmail.com>
 <CA+vqiLFT8Tsq5VumuYELs-ZP5u=z7Ggo3FfiUjFR_bkJTBdexw@mail.gmail.com>
 <CAJXgQP24OpUm20FAxDJeBpjsttVAVk7bv1y1RXt2ii_=8maXrg@mail.gmail.com>
 <CAJXgQP3zDKCjWpODs--kay8=F0Jnp9WLNK6T-zwz__LZ6KEjKg@mail.gmail.com>
Message-ID: <645efc33-ffd2-0323-6aa5-1fd5626003b3@gmail.com>


I think it is as Kevin described in an earlier response - the garbled 
output is because a UTF-8 encoded string is assumed to be native 
encoding (which happens not to be UTF-8 on the platform where this is 
observed) and converted again to UTF-8.

I think the documentation is consistent with the observed behavior

>    tmp <- '?'
>    tmp <- iconv(tmp, to = 'UTF-8')
>    print(Encoding(tmp))
>    print(charToRaw(tmp))
>    tmpfilepath <- tempfile()
>    writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>
> [1] "UTF-8"
> [1] c3 a9
>
> Raw text as hex: c3 83 c2 a9
useBytes=TRUE in writeLines means that the UTF-8 string will be passed 
byte-by-byte to the connection. encoding="UTF-8" tells the connection to 
convert the bytes to UTF-8 (from native encoding). So the second step is 
converting a string which is assumed to be in native encoding, but in 
fact it is in UTF-8.

The documentation describes "useBytes=TRUE" as for expert use only, it 
can be useful for avoiding unnecessary conversions in some special 
cases, but one has then to make sure that no more conversions are 
attempted (so use "" as encoding of in "file", for instance). The long 
advice short would be to not use useBytes=TRUE with writeLines, but 
depend on the default behavior.

Tomas


On 02/17/2018 11:24 PM, Kevin Ushey wrote:
> Of course, right after writing this e-mail I tested on my Windows
> machine and did not see what I expected:
>
>> charToRaw(before)
> [1] c3 a9
>> charToRaw(after)
> [1] e9
>
> so obviously I'm misunderstanding something as well.
>
> Best,
> Kevin
>
> On Sat, Feb 17, 2018 at 2:19 PM, Kevin Ushey <kevinushey at gmail.com> wrote:
>>  From my understanding, translation is implied in this line of ?file (from the
>> Encoding section):
>>
>>      The encoding of the input/output stream of a connection can be specified
>>      by name in the same way as it would be given to iconv: see that help page
>>      for how to find out what encoding names are recognized on your platform.
>>      Additionally, "" and "native.enc" both mean the ?native? encoding, that is
>>      the internal encoding of the current locale and hence no translation is
>>      done.
>>
>> This is also hinted at in the documentation in ?readLines for its 'encoding'
>> argument, which has a different semantic meaning from the 'encoding' argument
>> as used with R connections:
>>
>>      encoding to be assumed for input strings. It is used to mark character
>>      strings as known to be in Latin-1 or UTF-8: it is not used to re-encode
>>      the input. To do the latter, specify the encoding as part of the
>>      connection con or via options(encoding=): see the examples.
>>
>> It might be useful to augment the documentation in ?file with something like:
>>
>>      The 'encoding' argument is used to request the translation of strings when
>>      writing to a connection.
>>
>> and, perhaps to further drive home the point about not translating when
>> encoding = "native.enc":
>>
>>      Note that R will not attempt translation of strings when encoding is
>>      either "" or "native.enc" (the default, as per getOption("encoding")).
>>      This implies that attempting to write, for example, UTF-8 encoded content
>>      to a connection opened using "native.enc" will retain its original UTF-8
>>      encoding -- it will not be translated.
>>
>> It is a bit surprising that 'native.enc' means "do not translate" rather than
>> "attempt translation to the encoding associated with the current locale", but
>> those are the semantics and they are not bound to change.
>>
>> This is the code I used to convince myself of that case:
>>
>>      conn <- file(tempfile(), encoding = "native.enc", open = "w+")
>>
>>      before <- iconv('?', to = "UTF-8")
>>      cat(before, file = conn, sep = "\n")
>>      after <- readLines(conn)
>>
>>      charToRaw(before)
>>      charToRaw(after)
>>
>> with output:
>>
>>      > charToRaw(before)
>>      [1] c3 a9
>>      > charToRaw(after)
>>      [1] c3 a9
>>
>> Best,
>> Kevin
>>
>>
>> On Thu, Feb 15, 2018 at 9:16 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> On Thu, Feb 15, 2018 at 11:19 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
>>>> I suspect your UTF-8 string is being stripped of its encoding before
>>>> write, and so assumed to be in the system native encoding, and then
>>>> re-encoded as UTF-8 when written to the file. You can see something
>>>> similar with:
>>>>
>>>>      > tmp <- '?'
>>>>      > tmp <- iconv(tmp, to = 'UTF-8')
>>>>      > Encoding(tmp) <- "unknown"
>>>>      > charToRaw(iconv(tmp, to = "UTF-8"))
>>>>      [1] c3 83 c2 a9
>>>>
>>>> It's worth saying that:
>>>>
>>>>      file(..., encoding = "UTF-8")
>>>>
>>>> means "attempt to re-encode strings as UTF-8 when writing to this
>>>> file". However, if you already know your text is UTF-8, then you
>>>> likely want to avoid opening a connection that might attempt to
>>>> re-encode the input. Conversely (assuming I'm understanding the
>>>> documentation correctly)
>>>>
>>>>      file(..., encoding = "native.enc")
>>>>
>>>> means "assume that strings are in the native encoding, and hence
>>>> translation is unnecessary". Note that it does not mean "attempt to
>>>> translate strings to the native encoding".
>>> If all that is true I think ?file needs some attention. I've read it
>>> several times now and I just don't see how it can be interpreted as
>>> you've described it.
>>>
>>> Best,
>>> Ista
>>>
>>>> Also note that writeLines(..., useBytes = FALSE) will explicitly
>>>> translate to the current encoding before sending bytes to the
>>>> requested connection. In other words, there are two locations where
>>>> translation might occur in your example:
>>>>
>>>>     1) In the call to writeLines(),
>>>>     2) When characters are passed to the connection.
>>>>
>>>> In your case, it sounds like translation should be suppressed at both steps.
>>>>
>>>> I think this is documented correctly in ?writeLines (and also the
>>>> Encoding section of ?file), but the behavior may feel unfamiliar at
>>>> first glance.
>>>>
>>>> Kevin
>>>>
>>>> On Wed, Feb 14, 2018 at 11:36 PM, Davor Josipovic <davorj at live.com> wrote:
>>>>> I think this behavior is inconsistent with the documentation:
>>>>>
>>>>>    tmp <- '?'
>>>>>    tmp <- iconv(tmp, to = 'UTF-8')
>>>>>    print(Encoding(tmp))
>>>>>    print(charToRaw(tmp))
>>>>>    tmpfilepath <- tempfile()
>>>>>    writeLines(tmp, con = file(tmpfilepath, encoding = 'UTF-8'), useBytes = TRUE)
>>>>>
>>>>> [1] "UTF-8"
>>>>> [1] c3 a9
>>>>>
>>>>> Raw text as hex: c3 83 c2 a9
>>>>>
>>>>> If I switch to useBytes = FALSE, then the variable is written correctly as  c3 a9.
>>>>>
>>>>> Any thoughts? This behavior is related to this issue: https://github.com/yihui/knitr/issues/1509
>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Mon Feb 19 15:58:30 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 19 Feb 2018 15:58:30 +0100
Subject: [Rd] readLines interaction with gsub different in R-dev
In-Reply-To: <CAF8bMcYdtJGE+K0RiVWTemv=24ENMwV5PBLZq29u9n407b41yA@mail.gmail.com>
References: <CAJmOi+PDrqfwTYPqbHM-aJwx1ret0auvuB=cbUvFW8p6BVAAeQ@mail.gmail.com>
 <23176.18183.140869.415407@rob.eddelbuettel.com>
 <CAJmOi+N3HjY_+p7Y0zJbT_8n3STuOrDbFx0JE7qMeDj5JpHDKw@mail.gmail.com>
 <CAF8bMcYdtJGE+K0RiVWTemv=24ENMwV5PBLZq29u9n407b41yA@mail.gmail.com>
Message-ID: <1f795115-3823-55bf-6eda-86f8cd281669@gmail.com>

Thank you for the report and analysis. Now fixed in R-devel.
Tomas

On 02/17/2018 08:24 PM, William Dunlap via R-devel wrote:
> I think the problem in R-devel happens when there are non-ASCII characters
> in any
> of the strings passed to gsub.
>
> txt <- vapply(list(as.raw(c(0x41, 0x6d, 0xc3, 0xa9, 0x6c, 0x69, 0x65)),
> as.raw(c(0x41, 0x6d, 0x65, 0x6c, 0x69, 0x61))), rawToChar, "")
> txt
> #[1] "Am?lie" "Amelia"
> Encoding(txt)
> #[1] "unknown" "unknown"
> gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt)
> #[1] "<a" "<a"
> gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt[1])
> #[1] "<a"
> gsub(perl=TRUE, "(\\w)(\\w)", "<\\L\\1\\U\\2>", txt[2])
> #[1] "<aM><eL><iA>"
>
> I can change the Encoding to "latin1" or "UTF-8" and get similar results
> from gsub.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, Feb 17, 2018 at 7:35 AM, Hugh Parsonage <hugh.parsonage at gmail.com>
> wrote:
>
>> | Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the
>> regexp
>> | you use wrong, ie isn't R-devel giving the correct answer?
>>
>> No, I don't think R-devel is correct (or at least consistent with the
>> documentation). My interpretation of gsub("(\\w)", "\\U\\1", entry,
>> perl = TRUE) is "Take every word character and replace it with itself,
>> converted to uppercase."
>>
>> Perhaps my example was too minimal. Consider the following:
>>
>> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
>> [1] "A"
>>
>> R> gsub("(\\w)", "\\1", entry, perl = TRUE)
>> [1] "author: Am?lie"   # OK, but very different to 'A', despite only
>> not specifying uppercase
>>
>> R> gsub("(\\w)", "\\U\\1", "author: Amelie", perl = TRUE)
>> [1] "AUTHOR: AMELIE"  # OK, but very different to 'A',
>>
>> R> gsub("^(\\w+?): (\\w)", "\\U\\1\\E: \\2", entry, perl = TRUE)
>>   "AUTHOR"  # Where did everything after the first group go?
>>
>> I should note the following example too:
>> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE, useBytes = TRUE)
>> [1] "AUTHOR: AM??LIE"  # latin1 encoding
>>
>>
>> A call to `readLines` (possibly `scan()` and `read.table` and friends)
>> is essential.
>>
>>
>>
>>
>> On 18 February 2018 at 02:15, Dirk Eddelbuettel <edd at debian.org> wrote:
>>> On 17 February 2018 at 21:10, Hugh Parsonage wrote:
>>> | I was told to re-raise this issue with R-dev:
>>> |
>>> | In the documentation of R-dev and R-3.4.3, under ?gsub
>>> |
>>> | > replacement
>>> | >    ... For perl = TRUE only, it can also contain "\U" or "\L" to
>> convert the rest of the replacement to upper or lower case and "\E" to end
>> case conversion.
>>> |
>>> | However, the following code runs differently:
>>> |
>>> | tempf <- tempfile()
>>> | writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
>>> | entry <- readLines(tempf, encoding = "UTF-8")
>>> | gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
>>> |
>>> |
>>> | "AUTHOR: AM?LIE"  # R-3.4.3
>>> |
>>> | "A"                              # R-dev
>>>
>>> Confirmed for R-devel (current) on Ubuntu 17.10.  But ... isn't the
>> regexp
>>> you use wrong, ie isn't R-devel giving the correct answer?
>>>
>>> R> tempf <- tempfile()
>>> R> writeLines(enc2utf8("author: Am?lie"), con = tempf, useBytes = TRUE)
>>> R> entry <- readLines(tempf, encoding = "UTF-8")
>>> R> gsub("(\\w)", "\\U\\1", entry, perl = TRUE)
>>> [1] "A"
>>> R> gsub("(\\w+)", "\\U\\1", entry, perl = TRUE)
>>> [1] "AUTHOR"
>>> R> gsub("(.*)", "\\U\\1", entry, perl = TRUE)
>>> [1] "AUTHOR: AM?LIE"
>>> R>
>>>
>>> Dirk
>>>
>>> --
>>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From christian.krause at idiv.de  Mon Feb 19 19:21:24 2018
From: christian.krause at idiv.de (Christian Krause)
Date: Mon, 19 Feb 2018 19:21:24 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
Message-ID: <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>

Dear R-Devel List,

I have installed R 3.4.3 with the patch applied on our cluster and ran a *real-world* job of one of our users to confirm that the patch works to my satisfaction. Here are the results.

The original was a series of jobs, all essentially doing the same stuff using bootstrapped data, so for the original there is more data and I show the arithmetic mean with standard deviation. The confirmation with the patched R was only a single instance of that series of jobs.

## Job Efficiency

The job efficiency is defined as (this is what the `qacct-efficiency` tool below does):

```
efficiency = cputime / cores / wallclocktime * 100%
```

In simpler words: how well did the job utilize its CPU cores. It shows the percentage of time the job was actually doing stuff, as opposed to the difference:

```
wasted = 100% - efficiency
```

... which, essentially, tells us how much of the resources were wasted, i.e. CPU cores just idling, without being used by anyone. We care a lot about that because, for our scientific computing cluster, wasted resources is like burning money.

### original

This is the entire series from our job accounting database, filteres the successful jobs, calculates efficiency and then shows the average and standard deviation of the efficiency:

```
$ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
n=945 ? 61.7276 ? 7.78719
```

This is the entire series from our job accounting database, filteres the successful jobs, calculates efficiency and does sort of a histogram-like binning before calculation of mean and standard deviation (to get a more detailed impression of the distribution when standard deviation of the previous command is comparatively high):

```
$ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w 10 | sort -gk1 | column -t
10  -  20  ->  n=3    ?  19.21666666666667   ?  0.9112811494447459
20  -  30  ->  n=6    ?  26.418333333333333  ?  2.665996374091058
30  -  40  ->  n=12   ?  35.11583333333334   ?  2.8575783082671196
40  -  50  ->  n=14   ?  45.35285714285715   ?  2.98623361591005
50  -  60  ->  n=344  ?  57.114593023255814  ?  2.1922005551774415
60  -  70  ->  n=453  ?  64.29536423841049   ?  2.8334788433963856
70  -  80  ->  n=108  ?  72.95592592592598   ?  2.5219474143639276
80  -  90  ->  n=5    ?  81.526              ?  1.2802265424525452
```

I have attached an example graph from our monitoring system of a single instance in my previous mail. There you can see that the load balancing does not actually work, i.e. same as `parLapply`. This reflects in the job efficiency.

### patch applied

This is the single instance I used to confirm that the patch works:

```
$ qacct -j 4562202 | qacct-efficiency
97.36
```

The graph from our monitoring system is attached. As you can see, the load balancing works to a satisfying degree and the efficiency is well above 90% which was what I had hoped for :-)

## Additional Notes

The list used in this jobs `parLapplyLB` is 5812 elements long. With the `splitList`-chunking from the patch, you'll get 208 lists of about 28 elements (208 chunks of size 28). The job ran on 28 CPU cores and had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the function we apply to our list takes about 580 seconds per list element, i.e. about 10 minutes. I suppose, for that runtime, we would get even better load balancing if we would reduce the chunk size even further, maybe even down to 1, thus getting our efficiency even closer to 100%.

Of course, for really short-running functions, a higher chunk size may be more efficient because of the overhead. In our case, the overhead is negligible and that is why the low chunk size works really well. In contrast, for smallish lists with short-running functions, you might not even need load balancing and `parLapply` suffices. It only becomes an issue, when the runtime of the function is high and / or varying.

In our case, the entire runtime of the entire series of jobs was:

```
$ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print sum, "seconds" }'
4.72439e+09 seconds
```

Thats about 150 years on a single core or 7.5 years on a 20 core server! Our user was constantly using about 500 cores, so this took about 110 days. If you compare this to my 97% efficiency example, the jobs could have been finished in 75 days instead ;-)

## Upcoming Patch

If this patch gets applied to the R code base (and I hope it will :-)) my colleague and I will submit another patch that adds the chunk size as an optional parameter to all off the load balancing functions. With that parameter, users of these functions *can* decide for themselves which chunk size they prefer for their code. As mentioned before, the most efficient chunk size depends on the used functions runtime, which is the only thing R does not know and users really should be allowed to specify explicitly. The default of this new optional parameter would be the one we used here and this would make that upcoming patch fully source-compatible.

Best Regards

On 02/12/2018 08:08 PM, Christian Krause wrote:
> Dear R-Devel List,
> 
> **TL;DR:** The function **parLapplyLB** of the parallel package has [reportedly][1] (see also attached RRD output) not
> been doing its job, i.e. not actually balancing the load. My colleague Dirk Sarpe and I found the cause of the problem
> and we also have a patch to fix it (attached). A similar fix has also been provided [here][2].
> 
> [1]: https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
> 
> 
> ## The Call Chain
> 
> First, we traced the relevant R function calls through the code, beginning with `parLapplyLB`:
> 
> 1.  **parLapplyLB:** clusterApply.R:177, calls **splitList**, then **clusterApplyLB**
> 2.  **splitList:** clusterApply.R:157
> 3.  **clusterApplyLB:** clusterApply.R:87, calls **dynamicClusterApply**
> 4.  **dynamicClusterApply:** clusterApply.R:39
> 
> 
> ## splitList
> 
> We used both our whiteboard and an R session to manually *run* a few examples. We were using lists of 100 elements and 5
> workers. First, lets take a look at **splitList**:
> 
> ```r
>> sapply(parallel:::splitList(1:100, 5), length)
> [1] 20 20 20 20 20
> 
>> sapply(parallel:::splitList(1:97, 5), length)
> [1] 20 19 19 19 20
> 
>> sapply(parallel:::splitList(1:97, 20), length)
>  [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
> ```
> 
> As we can see in the examples, the work is distributed as equally as possible.
> 
> 
> ## dynamicClusterApply
> 
> **dynamicClusterApply** works this way (simplified):
> 
> 1.  it first gives a chunk to each worker
> 2.  once a worker comes back with the result, it is given the next chunk
> 
> **This is the important part:** As long as there are **more** chunks than workers, there will be load balancing. If
> there are fewer chunks than workers, each worker will get **at most one chunk** and there is **no** load balancing.
> 
> 
> ## parLapplyLB
> 
> This is how **parLapplyLB** splits the input list (with a bit of refactoring, for readability):
> 
> ```r
> parLapplyLB <- function(cl = NULL, X, fun, ...)
> {
>     cl <- defaultCluster(cl)
> 
>     chunks <- splitList(X, length(cl))
> 
>     do.call(c,
>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>             quote = TRUE)
> }
> ```
> 
> For our examples, the chunks have these sizes:
> 
> ```r
>> sapply(parallel:::splitList(1:100, 5), length)
> [1] 20 20 20 20 20
> ```
> 
> There we have it: 5 chunks. 5 workers. With this work distribution, there can't possibly be any load balancing, because
> each worker is given a single chunk and then it stops working because there are no more chunks.
> 
> Instead, **parLapplyLB** should look like this (patch is attached):
> 
> ```r
> parLapplyLB <- function(cl = NULL, X, fun, ...)
> {
>     cl <- defaultCluster(cl)
> 
>     chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
> 
>     chunks <- splitList(X, chunkSize)
> 
>     do.call(c,
>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>             quote = TRUE)
> }
> ```
> 
> Examples with a cluster of 5 workers:
> 
> ```r
> # length(cl) < length(X)
>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>  [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
> 
> # length(cl) >= length(X)
>> sapply(parallel:::splitList(1:4, 4), length)
> [1] 1 1 1 1
> # one worker idles here, but we can't do better than that
> ```
> 
> With this patch, the number of chunks is larger than the number of workers, if possible at all, and then load balancing
> should work.
> 
> Best Regards
> 
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Christian Krause

Scientific Computing Administration and Support

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Email: christian.krause at idiv.de

Office: BioCity Leipzig 5e, Room 3.201.3

Phone: +49 341 97 33144

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig

Deutscher Platz 5e

04103 Leipzig

Germany

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

iDiv is a research centre of the DFG ? Deutsche Forschungsgemeinschaft

iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der Martin-Luther-Universit?t Halle-Wittenberg und der Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte Kooperationspartner sind die folgenden au?eruniversit?ren Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das Max-Planck-Institut f?r chemische ?kologie (MPI CE), das Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK) und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz (SMNG). USt-IdNr. DE 141510383


-------------- next part --------------
A non-text attachment was scrubbed...
Name: krausec-parLapplyLB-fixed.png
Type: image/png
Size: 42277 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180219/645ca8fb/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180219/645ca8fb/attachment.sig>

From henrik.bengtsson at gmail.com  Mon Feb 19 22:11:04 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 19 Feb 2018 13:11:04 -0800
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
 <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
Message-ID: <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>

Hi, I'm trying to understand the rationale for your proposed amount of
splitting and more precisely why that one is THE one.

If I put labels on your example numbers in one of your previous post:

 nbrOfElements <- 97
 nbrOfWorkers <- 5

With these, there are two extremes in how you can split up the
processing in chunks such that all workers are utilized:

(A) Each worker, called multiple times, processes one element each time:

> nbrOfElements <- 97
> nbrOfWorkers <- 5
> nbrOfChunks <- nbrOfElements
> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
 [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[30] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[59] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[88] 1 1 1 1 1 1 1 1 1 1


(B) Each worker, called once, processes multiple element:

> nbrOfElements <- 97
> nbrOfWorkers <- 5
> nbrOfChunks <- nbrOfWorkers
> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
[1] 20 19 19 19 20

I understand that neither of these two extremes may be the best when
it comes to orchestration overhead and load balancing. Instead, the
best might be somewhere in-between, e.g.

(C) Each worker, called multiple times, processing multiple elements:

> nbrOfElements <- 97
> nbrOfWorkers <- 5
> nbrOfChunks <- nbrOfElements / nbrOfWorkers
> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
 [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5

However, there are multiple alternatives between the two extremes, e.g.

> nbrOfChunks <- scale * nbrOfElements / nbrOfWorkers

So, is there a reason why you argue for scale = 1.0 to be the optimal?

FYI, In future.apply::future_lapply(X, FUN, ...) there is a
'future.scheduling' scale factor(*) argument where default
future.scheduling = 1 corresponds to (B) and future.scheduling = +Inf
to (A).  Using future.scheduling = 4 achieves the amount of
load-balancing you propose in (C).   (*) Different definition from the
above 'scale'. (Disclaimer: I'm the author)

/Henrik

On Mon, Feb 19, 2018 at 10:21 AM, Christian Krause
<christian.krause at idiv.de> wrote:
> Dear R-Devel List,
>
> I have installed R 3.4.3 with the patch applied on our cluster and ran a *real-world* job of one of our users to confirm that the patch works to my satisfaction. Here are the results.
>
> The original was a series of jobs, all essentially doing the same stuff using bootstrapped data, so for the original there is more data and I show the arithmetic mean with standard deviation. The confirmation with the patched R was only a single instance of that series of jobs.
>
> ## Job Efficiency
>
> The job efficiency is defined as (this is what the `qacct-efficiency` tool below does):
>
> ```
> efficiency = cputime / cores / wallclocktime * 100%
> ```
>
> In simpler words: how well did the job utilize its CPU cores. It shows the percentage of time the job was actually doing stuff, as opposed to the difference:
>
> ```
> wasted = 100% - efficiency
> ```
>
> ... which, essentially, tells us how much of the resources were wasted, i.e. CPU cores just idling, without being used by anyone. We care a lot about that because, for our scientific computing cluster, wasted resources is like burning money.
>
> ### original
>
> This is the entire series from our job accounting database, filteres the successful jobs, calculates efficiency and then shows the average and standard deviation of the efficiency:
>
> ```
> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
> n=945 ? 61.7276 ? 7.78719
> ```
>
> This is the entire series from our job accounting database, filteres the successful jobs, calculates efficiency and does sort of a histogram-like binning before calculation of mean and standard deviation (to get a more detailed impression of the distribution when standard deviation of the previous command is comparatively high):
>
> ```
> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w 10 | sort -gk1 | column -t
> 10  -  20  ->  n=3    ?  19.21666666666667   ?  0.9112811494447459
> 20  -  30  ->  n=6    ?  26.418333333333333  ?  2.665996374091058
> 30  -  40  ->  n=12   ?  35.11583333333334   ?  2.8575783082671196
> 40  -  50  ->  n=14   ?  45.35285714285715   ?  2.98623361591005
> 50  -  60  ->  n=344  ?  57.114593023255814  ?  2.1922005551774415
> 60  -  70  ->  n=453  ?  64.29536423841049   ?  2.8334788433963856
> 70  -  80  ->  n=108  ?  72.95592592592598   ?  2.5219474143639276
> 80  -  90  ->  n=5    ?  81.526              ?  1.2802265424525452
> ```
>
> I have attached an example graph from our monitoring system of a single instance in my previous mail. There you can see that the load balancing does not actually work, i.e. same as `parLapply`. This reflects in the job efficiency.
>
> ### patch applied
>
> This is the single instance I used to confirm that the patch works:
>
> ```
> $ qacct -j 4562202 | qacct-efficiency
> 97.36
> ```
>
> The graph from our monitoring system is attached. As you can see, the load balancing works to a satisfying degree and the efficiency is well above 90% which was what I had hoped for :-)
>
> ## Additional Notes
>
> The list used in this jobs `parLapplyLB` is 5812 elements long. With the `splitList`-chunking from the patch, you'll get 208 lists of about 28 elements (208 chunks of size 28). The job ran on 28 CPU cores and had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the function we apply to our list takes about 580 seconds per list element, i.e. about 10 minutes. I suppose, for that runtime, we would get even better load balancing if we would reduce the chunk size even further, maybe even down to 1, thus getting our efficiency even closer to 100%.
>
> Of course, for really short-running functions, a higher chunk size may be more efficient because of the overhead. In our case, the overhead is negligible and that is why the low chunk size works really well. In contrast, for smallish lists with short-running functions, you might not even need load balancing and `parLapply` suffices. It only becomes an issue, when the runtime of the function is high and / or varying.
>
> In our case, the entire runtime of the entire series of jobs was:
>
> ```
> $ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print sum, "seconds" }'
> 4.72439e+09 seconds
> ```
>
> Thats about 150 years on a single core or 7.5 years on a 20 core server! Our user was constantly using about 500 cores, so this took about 110 days. If you compare this to my 97% efficiency example, the jobs could have been finished in 75 days instead ;-)
>
> ## Upcoming Patch
>
> If this patch gets applied to the R code base (and I hope it will :-)) my colleague and I will submit another patch that adds the chunk size as an optional parameter to all off the load balancing functions. With that parameter, users of these functions *can* decide for themselves which chunk size they prefer for their code. As mentioned before, the most efficient chunk size depends on the used functions runtime, which is the only thing R does not know and users really should be allowed to specify explicitly. The default of this new optional parameter would be the one we used here and this would make that upcoming patch fully source-compatible.
>
> Best Regards
>
> On 02/12/2018 08:08 PM, Christian Krause wrote:
>> Dear R-Devel List,
>>
>> **TL;DR:** The function **parLapplyLB** of the parallel package has [reportedly][1] (see also attached RRD output) not
>> been doing its job, i.e. not actually balancing the load. My colleague Dirk Sarpe and I found the cause of the problem
>> and we also have a patch to fix it (attached). A similar fix has also been provided [here][2].
>>
>> [1]: https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
>> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
>>
>>
>> ## The Call Chain
>>
>> First, we traced the relevant R function calls through the code, beginning with `parLapplyLB`:
>>
>> 1.  **parLapplyLB:** clusterApply.R:177, calls **splitList**, then **clusterApplyLB**
>> 2.  **splitList:** clusterApply.R:157
>> 3.  **clusterApplyLB:** clusterApply.R:87, calls **dynamicClusterApply**
>> 4.  **dynamicClusterApply:** clusterApply.R:39
>>
>>
>> ## splitList
>>
>> We used both our whiteboard and an R session to manually *run* a few examples. We were using lists of 100 elements and 5
>> workers. First, lets take a look at **splitList**:
>>
>> ```r
>>> sapply(parallel:::splitList(1:100, 5), length)
>> [1] 20 20 20 20 20
>>
>>> sapply(parallel:::splitList(1:97, 5), length)
>> [1] 20 19 19 19 20
>>
>>> sapply(parallel:::splitList(1:97, 20), length)
>>  [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>> ```
>>
>> As we can see in the examples, the work is distributed as equally as possible.
>>
>>
>> ## dynamicClusterApply
>>
>> **dynamicClusterApply** works this way (simplified):
>>
>> 1.  it first gives a chunk to each worker
>> 2.  once a worker comes back with the result, it is given the next chunk
>>
>> **This is the important part:** As long as there are **more** chunks than workers, there will be load balancing. If
>> there are fewer chunks than workers, each worker will get **at most one chunk** and there is **no** load balancing.
>>
>>
>> ## parLapplyLB
>>
>> This is how **parLapplyLB** splits the input list (with a bit of refactoring, for readability):
>>
>> ```r
>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>> {
>>     cl <- defaultCluster(cl)
>>
>>     chunks <- splitList(X, length(cl))
>>
>>     do.call(c,
>>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>             quote = TRUE)
>> }
>> ```
>>
>> For our examples, the chunks have these sizes:
>>
>> ```r
>>> sapply(parallel:::splitList(1:100, 5), length)
>> [1] 20 20 20 20 20
>> ```
>>
>> There we have it: 5 chunks. 5 workers. With this work distribution, there can't possibly be any load balancing, because
>> each worker is given a single chunk and then it stops working because there are no more chunks.
>>
>> Instead, **parLapplyLB** should look like this (patch is attached):
>>
>> ```r
>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>> {
>>     cl <- defaultCluster(cl)
>>
>>     chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
>>
>>     chunks <- splitList(X, chunkSize)
>>
>>     do.call(c,
>>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>             quote = TRUE)
>> }
>> ```
>>
>> Examples with a cluster of 5 workers:
>>
>> ```r
>> # length(cl) < length(X)
>>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>>  [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
>>
>> # length(cl) >= length(X)
>>> sapply(parallel:::splitList(1:4, 4), length)
>> [1] 1 1 1 1
>> # one worker idles here, but we can't do better than that
>> ```
>>
>> With this patch, the number of chunks is larger than the number of workers, if possible at all, and then load balancing
>> should work.
>>
>> Best Regards
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Christian Krause
>
> Scientific Computing Administration and Support
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> Email: christian.krause at idiv.de
>
> Office: BioCity Leipzig 5e, Room 3.201.3
>
> Phone: +49 341 97 33144
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig
>
> Deutscher Platz 5e
>
> 04103 Leipzig
>
> Germany
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> iDiv is a research centre of the DFG ? Deutsche Forschungsgemeinschaft
>
> iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der Martin-Luther-Universit?t Halle-Wittenberg und der Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte Kooperationspartner sind die folgenden au?eruniversit?ren Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das Max-Planck-Institut f?r chemische ?kologie (MPI CE), das Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK) und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz (SMNG). USt-IdNr. DE 141510383
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From christian.krause at idiv.de  Tue Feb 20 11:45:38 2018
From: christian.krause at idiv.de (Christian Krause)
Date: Tue, 20 Feb 2018 11:45:38 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
 <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
 <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>
Message-ID: <1f1c808a24e9471784537dabde08d477@urzdommbx02.dom.uni-leipzig.de>

Dear Henrik,

The rationale is just that it is within these extremes and that it is really simple to calculate, without making any assumptions and knowing that it won't be perfect.

The extremes A and B you are mentioning are special cases based on assumptions. Case A is based on the assumption that the function has a long runtime or varying runtime, then you are likely to get the best load balancing with really small chunks. Case B is based on the assumption that the function runtime is the same for each list element, i.e. where you don't actually need load balancing, i.e. just use `parLapply` without load balancing.

This new default is **not the best one**. It's just a better one than we had before. There is no best one we can use as default because **we don't know the function runtime and how it varies**. The user needs to decide that because he/she knows the function. As mentioned before, I will write a patch that makes the chunk size an optional argument, so the user can decide because only he/she has all the information to choose the best chunk size, just like you did with the `future.scheduling` parameter.

Best Regards

On February 19, 2018 10:11:04 PM GMT+01:00, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>Hi, I'm trying to understand the rationale for your proposed amount of
>splitting and more precisely why that one is THE one.
>
>If I put labels on your example numbers in one of your previous post:
>
> nbrOfElements <- 97
> nbrOfWorkers <- 5
>
>With these, there are two extremes in how you can split up the
>processing in chunks such that all workers are utilized:
>
>(A) Each worker, called multiple times, processes one element each
>time:
>
>> nbrOfElements <- 97
>> nbrOfWorkers <- 5
>> nbrOfChunks <- nbrOfElements
>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
> [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>[30] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>[59] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>[88] 1 1 1 1 1 1 1 1 1 1
>
>
>(B) Each worker, called once, processes multiple element:
>
>> nbrOfElements <- 97
>> nbrOfWorkers <- 5
>> nbrOfChunks <- nbrOfWorkers
>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>[1] 20 19 19 19 20
>
>I understand that neither of these two extremes may be the best when
>it comes to orchestration overhead and load balancing. Instead, the
>best might be somewhere in-between, e.g.
>
>(C) Each worker, called multiple times, processing multiple elements:
>
>> nbrOfElements <- 97
>> nbrOfWorkers <- 5
>> nbrOfChunks <- nbrOfElements / nbrOfWorkers
>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
> [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>
>However, there are multiple alternatives between the two extremes, e.g.
>
>> nbrOfChunks <- scale * nbrOfElements / nbrOfWorkers
>
>So, is there a reason why you argue for scale = 1.0 to be the optimal?
>
>FYI, In future.apply::future_lapply(X, FUN, ...) there is a
>'future.scheduling' scale factor(*) argument where default
>future.scheduling = 1 corresponds to (B) and future.scheduling = +Inf
>to (A).  Using future.scheduling = 4 achieves the amount of
>load-balancing you propose in (C).   (*) Different definition from the
>above 'scale'. (Disclaimer: I'm the author)
>
>/Henrik
>
>On Mon, Feb 19, 2018 at 10:21 AM, Christian Krause
><christian.krause at idiv.de> wrote:
>> Dear R-Devel List,
>>
>> I have installed R 3.4.3 with the patch applied on our cluster and
>ran a *real-world* job of one of our users to confirm that the patch
>works to my satisfaction. Here are the results.
>>
>> The original was a series of jobs, all essentially doing the same
>stuff using bootstrapped data, so for the original there is more data
>and I show the arithmetic mean with standard deviation. The
>confirmation with the patched R was only a single instance of that
>series of jobs.
>>
>> ## Job Efficiency
>>
>> The job efficiency is defined as (this is what the `qacct-efficiency`
>tool below does):
>>
>> ```
>> efficiency = cputime / cores / wallclocktime * 100%
>> ```
>>
>> In simpler words: how well did the job utilize its CPU cores. It
>shows the percentage of time the job was actually doing stuff, as
>opposed to the difference:
>>
>> ```
>> wasted = 100% - efficiency
>> ```
>>
>> ... which, essentially, tells us how much of the resources were
>wasted, i.e. CPU cores just idling, without being used by anyone. We
>care a lot about that because, for our scientific computing cluster,
>wasted resources is like burning money.
>>
>> ### original
>>
>> This is the entire series from our job accounting database, filteres
>the successful jobs, calculates efficiency and then shows the average
>and standard deviation of the efficiency:
>>
>> ```
>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
>> n=945 ? 61.7276 ? 7.78719
>> ```
>>
>> This is the entire series from our job accounting database, filteres
>the successful jobs, calculates efficiency and does sort of a
>histogram-like binning before calculation of mean and standard
>deviation (to get a more detailed impression of the distribution when
>standard deviation of the previous command is comparatively high):
>>
>> ```
>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w
>10 | sort -gk1 | column -t
>> 10  -  20  ->  n=3    ?  19.21666666666667   ?  0.9112811494447459
>> 20  -  30  ->  n=6    ?  26.418333333333333  ?  2.665996374091058
>> 30  -  40  ->  n=12   ?  35.11583333333334   ?  2.8575783082671196
>> 40  -  50  ->  n=14   ?  45.35285714285715   ?  2.98623361591005
>> 50  -  60  ->  n=344  ?  57.114593023255814  ?  2.1922005551774415
>> 60  -  70  ->  n=453  ?  64.29536423841049   ?  2.8334788433963856
>> 70  -  80  ->  n=108  ?  72.95592592592598   ?  2.5219474143639276
>> 80  -  90  ->  n=5    ?  81.526              ?  1.2802265424525452
>> ```
>>
>> I have attached an example graph from our monitoring system of a
>single instance in my previous mail. There you can see that the load
>balancing does not actually work, i.e. same as `parLapply`. This
>reflects in the job efficiency.
>>
>> ### patch applied
>>
>> This is the single instance I used to confirm that the patch works:
>>
>> ```
>> $ qacct -j 4562202 | qacct-efficiency
>> 97.36
>> ```
>>
>> The graph from our monitoring system is attached. As you can see, the
>load balancing works to a satisfying degree and the efficiency is well
>above 90% which was what I had hoped for :-)
>>
>> ## Additional Notes
>>
>> The list used in this jobs `parLapplyLB` is 5812 elements long. With
>the `splitList`-chunking from the patch, you'll get 208 lists of about
>28 elements (208 chunks of size 28). The job ran on 28 CPU cores and
>had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the
>function we apply to our list takes about 580 seconds per list element,
>i.e. about 10 minutes. I suppose, for that runtime, we would get even
>better load balancing if we would reduce the chunk size even further,
>maybe even down to 1, thus getting our efficiency even closer to 100%.
>>
>> Of course, for really short-running functions, a higher chunk size
>may be more efficient because of the overhead. In our case, the
>overhead is negligible and that is why the low chunk size works really
>well. In contrast, for smallish lists with short-running functions, you
>might not even need load balancing and `parLapply` suffices. It only
>becomes an issue, when the runtime of the function is high and / or
>varying.
>>
>> In our case, the entire runtime of the entire series of jobs was:
>>
>> ```
>> $ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print
>sum, "seconds" }'
>> 4.72439e+09 seconds
>> ```
>>
>> Thats about 150 years on a single core or 7.5 years on a 20 core
>server! Our user was constantly using about 500 cores, so this took
>about 110 days. If you compare this to my 97% efficiency example, the
>jobs could have been finished in 75 days instead ;-)
>>
>> ## Upcoming Patch
>>
>> If this patch gets applied to the R code base (and I hope it will
>:-)) my colleague and I will submit another patch that adds the chunk
>size as an optional parameter to all off the load balancing functions.
>With that parameter, users of these functions *can* decide for
>themselves which chunk size they prefer for their code. As mentioned
>before, the most efficient chunk size depends on the used functions
>runtime, which is the only thing R does not know and users really
>should be allowed to specify explicitly. The default of this new
>optional parameter would be the one we used here and this would make
>that upcoming patch fully source-compatible.
>>
>> Best Regards
>>
>> On 02/12/2018 08:08 PM, Christian Krause wrote:
>>> Dear R-Devel List,
>>>
>>> **TL;DR:** The function **parLapplyLB** of the parallel package has
>[reportedly][1] (see also attached RRD output) not
>>> been doing its job, i.e. not actually balancing the load. My
>colleague Dirk Sarpe and I found the cause of the problem
>>> and we also have a patch to fix it (attached). A similar fix has
>also been provided [here][2].
>>>
>>> [1]:
>https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
>>> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
>>>
>>>
>>> ## The Call Chain
>>>
>>> First, we traced the relevant R function calls through the code,
>beginning with `parLapplyLB`:
>>>
>>> 1.  **parLapplyLB:** clusterApply.R:177, calls **splitList**, then
>**clusterApplyLB**
>>> 2.  **splitList:** clusterApply.R:157
>>> 3.  **clusterApplyLB:** clusterApply.R:87, calls
>**dynamicClusterApply**
>>> 4.  **dynamicClusterApply:** clusterApply.R:39
>>>
>>>
>>> ## splitList
>>>
>>> We used both our whiteboard and an R session to manually *run* a few
>examples. We were using lists of 100 elements and 5
>>> workers. First, lets take a look at **splitList**:
>>>
>>> ```r
>>>> sapply(parallel:::splitList(1:100, 5), length)
>>> [1] 20 20 20 20 20
>>>
>>>> sapply(parallel:::splitList(1:97, 5), length)
>>> [1] 20 19 19 19 20
>>>
>>>> sapply(parallel:::splitList(1:97, 20), length)
>>>  [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>> ```
>>>
>>> As we can see in the examples, the work is distributed as equally as
>possible.
>>>
>>>
>>> ## dynamicClusterApply
>>>
>>> **dynamicClusterApply** works this way (simplified):
>>>
>>> 1.  it first gives a chunk to each worker
>>> 2.  once a worker comes back with the result, it is given the next
>chunk
>>>
>>> **This is the important part:** As long as there are **more** chunks
>than workers, there will be load balancing. If
>>> there are fewer chunks than workers, each worker will get **at most
>one chunk** and there is **no** load balancing.
>>>
>>>
>>> ## parLapplyLB
>>>
>>> This is how **parLapplyLB** splits the input list (with a bit of
>refactoring, for readability):
>>>
>>> ```r
>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>> {
>>>     cl <- defaultCluster(cl)
>>>
>>>     chunks <- splitList(X, length(cl))
>>>
>>>     do.call(c,
>>>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>             quote = TRUE)
>>> }
>>> ```
>>>
>>> For our examples, the chunks have these sizes:
>>>
>>> ```r
>>>> sapply(parallel:::splitList(1:100, 5), length)
>>> [1] 20 20 20 20 20
>>> ```
>>>
>>> There we have it: 5 chunks. 5 workers. With this work distribution,
>there can't possibly be any load balancing, because
>>> each worker is given a single chunk and then it stops working
>because there are no more chunks.
>>>
>>> Instead, **parLapplyLB** should look like this (patch is attached):
>>>
>>> ```r
>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>> {
>>>     cl <- defaultCluster(cl)
>>>
>>>     chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
>>>
>>>     chunks <- splitList(X, chunkSize)
>>>
>>>     do.call(c,
>>>             clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>             quote = TRUE)
>>> }
>>> ```
>>>
>>> Examples with a cluster of 5 workers:
>>>
>>> ```r
>>> # length(cl) < length(X)
>>>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>>>  [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
>>>
>>> # length(cl) >= length(X)
>>>> sapply(parallel:::splitList(1:4, 4), length)
>>> [1] 1 1 1 1
>>> # one worker idles here, but we can't do better than that
>>> ```
>>>
>>> With this patch, the number of chunks is larger than the number of
>workers, if possible at all, and then load balancing
>>> should work.
>>>
>>> Best Regards
>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Christian Krause
>>
>> Scientific Computing Administration and Support
>>
>>
>------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>
>> Email: christian.krause at idiv.de
>>
>> Office: BioCity Leipzig 5e, Room 3.201.3
>>
>> Phone: +49 341 97 33144
>>
>>
>------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>
>> German Centre for Integrative Biodiversity Research (iDiv)
>Halle-Jena-Leipzig
>>
>> Deutscher Platz 5e
>>
>> 04103 Leipzig
>>
>> Germany
>>
>>
>------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>
>> iDiv is a research centre of the DFG ? Deutsche
>Forschungsgemeinschaft
>>
>> iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne
>des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der
>Martin-Luther-Universit?t Halle-Wittenberg und der
>Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit
>dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte
>Kooperationspartner sind die folgenden au?eruniversit?ren
>Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH
>- UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das
>Max-Planck-Institut f?r chemische ?kologie (MPI CE), das
>Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das
>Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen
>(DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das
>Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK)
>und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz
>(SMNG). USt-IdNr. DE 141510383
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

-- 
Sent from my mobile device, please excuse my brevity.


From tomas.kalibera at gmail.com  Tue Feb 20 15:11:34 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 20 Feb 2018 15:11:34 +0100
Subject: [Rd] Unnecessary lines in stem.c?
In-Reply-To: <1A8C1289955EF649A09086A153E267240C3FD9146F@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <1A8C1289955EF649A09086A153E267240C3FD9146F@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <834e5801-e1ff-2bb1-cfcf-4b5da4d6807c@gmail.com>

Thanks! Cleaned up in R-devel,
Tomas

On 02/16/2018 05:03 PM, S Ellison wrote:
> A discussion on r-help led me to look at stem.c at
> https://github.com/wch/r-source/blob/trunk/src/library/graphics/src/stem.c
>
> Lines 76-77 appear superfluous. They sit inside a condition, and set mu, as follows:
> 	if (k*(k-4)*(k-8) == 0) mu = 5;
> 	if ((k-1)*(k-5)*(k-6) == 0) mu = 20;
>
> But mu is set unconditionally to 10 on line 84, and that is followed by conditional assignments (on line 85-6) identical to lines 76-77.
>
> It looks like a couple of lines got left inside a condition that are no longer needed there. If that is correct, is it worth removing the superfluous lines, for future coders' benefit?
>
> S Ellison
>   
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:7}}


From i.ucar86 at gmail.com  Tue Feb 20 19:33:34 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Tue, 20 Feb 2018 19:33:34 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
Message-ID: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>

Hi all,

Not sure if this belongs to R-devel or R-package-devel. Anyways...

Suppose we have objects of class c("foo", "bar"), and there are two S3
methods c.foo, c.bar. In c.foo, I'm trying to modify the dots and
forward the dispatch using NextMethod without any success. This is
what I've tried so far:

c.foo <- function(..., recursive=FALSE) {
  dots <- list(...)
  # inspect and modify dots
  # ...
  do.call(
    function(..., recursive=FALSE) structure(NextMethod("c"), class="foo"),
    c(dots, recursive=recursive)
  )
}

foobar <- 1
class(foobar) <- c("foo", "bar")
c(foobar, foobar)
Error: C stack usage  7970788 is too close to the limit

There's recursion (!). But the funniest thing is that if c.foo is
exported by one package and c.bar is exported by another one, there's
no recursion, but c.bar is never called (!!). Why is the same code
behaving in a different way depending on whether these functions are
defined in the .GlobalEnv or in two attached packages? (BTW,
isS3method() is TRUE, for c.foo and c.bar in both cases).

I'm blocked here. Am I missing something? Is there a way of doing
this? Thanks in advance.

Regards,
I?aki


From frederik at ofb.net  Tue Feb 20 22:23:51 2018
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 20 Feb 2018 13:23:51 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
Message-ID: <20180220212351.GP32564@ofb.net>

Hi Scott,

I think that's a good idea and I tried your patch on my copy of the
repository. But it looks to me like the recent patch is identical to
the previous one, can you confirm this?

Frederick

On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
> Thanks Gabriel,
> 
> I think your suggested approach is 100% backwards compatible
> 
> Currently in the case of duplicate column names only the first can be
> indexed by its name. This will always be the column appearing in by.x,
> meaning the column in y with the same name cannot be accessed. Appending
> ".y" (suffixes[2L]) to this column means it can now be accessed, while
> keeping the current behaviour of making the key columns always accessible
> by using the names provided to by.x.
> 
> I've attached a new patch that has this behaviour.
> 
> Best,
> 
> Scott
> 
> On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> 
> > It seems like there is a way that is backwards compatible-ish in the sense
> > mentioned and still has the (arguably, but a good argument I think) better
> > behavior:
> >
> > if by.x is 'name', (AND by.y is not also 'name'), then x's 'name' column
> > is called name and y's 'name' column (not used int he merge) is changed to
> > name.y.
> >
> > Now of course this would still change output, but it would change it to
> > something I think would be better, while retaining the 'merge columns
> > retain their exact names' mechanic as documented.
> >
> > ~G
> >
> > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <s.ritchie73 at gmail.com>
> > wrote:
> >
> >> Thanks Duncan and Frederick,
> >>
> >> I suspected as much - there doesn't appear to be any reason why conflicts
> >> between by.x and names(y) shouldn't and cannot be checked, but I can see
> >> how this might be more trouble than its worth given it potentially may
> >> break downstream packages (i.e. any cases where this occurs but they
> >> expect
> >> the name of the key column(s) to remain the same).
> >>
> >> Best,
> >>
> >> Scott
> >>
> >> On 18 February 2018 at 11:48, Duncan Murdoch <murdoch.duncan at gmail.com>
> >> wrote:
> >>
> >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> >> >
> >> >> Hi Scott,
> >> >>
> >> >> Thanks for the patch. I'm not really involved in R development; it
> >> >> will be up to someone in the R core team to apply it. I would hazard
> >> >> to say that even if correct (I haven't checked), it will not be
> >> >> applied because the change might break existing code. For example it
> >> >> seems like reasonable code might easily assume that a column with the
> >> >> same name as "by.x" exists in the output of 'merge'. That's just my
> >> >> best guess... I don't participate on here often.
> >> >>
> >> >
> >> >
> >> > I think you're right.  If I were still a member of R Core, I would want
> >> to
> >> > test this against all packages on CRAN and Bioconductor, and since that
> >> > test takes a couple of days to run on my laptop, I'd probably never get
> >> > around to it.
> >> >
> >> > There are lots of cases where "I would have done that differently", but
> >> > most of them are far too much trouble to change now that R is more than
> >> 20
> >> > years old.  And in many cases it will turn out that the way R does it
> >> > actually does make more sense than the way I would have done it.
> >> >
> >> > Duncan Murdoch
> >> >
> >> >
> >> >
> >> >> Cheers,
> >> >>
> >> >> Frederick
> >> >>
> >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> >> >>
> >> >>> The attached patch.diff will make merge.data.frame() append the
> >> suffixes
> >> >>> to
> >> >>> columns with common names between by.x and names(y).
> >> >>>
> >> >>> Best,
> >> >>>
> >> >>> Scott Ritchie
> >> >>>
> >> >>> On 17 February 2018 at 11:15, Scott Ritchie <s.ritchie73 at gmail.com>
> >> >>> wrote:
> >> >>>
> >> >>> Hi Frederick,
> >> >>>>
> >> >>>> I would expect that any duplicate names in the resulting data.frame
> >> >>>> would
> >> >>>> have the suffixes appended to them, regardless of whether or not they
> >> >>>> are
> >> >>>> used as the join key. So in my example I would expect "names.x" and
> >> >>>> "names.y" to indicate their source data.frame.
> >> >>>>
> >> >>>> While careful reading of the documentation reveals this is not the
> >> >>>> case, I
> >> >>>> would argue the intent of the suffixes functionality should equally
> >> be
> >> >>>> applied to this type of case.
> >> >>>>
> >> >>>> If you agree this would be useful, I'm happy to write a patch for
> >> >>>> merge.data.frame that will add suffixes in this case - I intend to do
> >> >>>> the
> >> >>>> same for merge.data.table in the data.table package where I initially
> >> >>>> encountered the edge case.
> >> >>>>
> >> >>>> Best,
> >> >>>>
> >> >>>> Scott
> >> >>>>
> >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> >> >>>>
> >> >>>> Hi Scott,
> >> >>>>>
> >> >>>>> It seems like reasonable behavior to me. What result would you
> >> expect?
> >> >>>>> That the second "name" should be called "name.y"?
> >> >>>>>
> >> >>>>> The "merge" documentation says:
> >> >>>>>
> >> >>>>>      If the columns in the data frames not used in merging have any
> >> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by
> >> default)
> >> >>>>>      appended to try to make the names of the result unique.
> >> >>>>>
> >> >>>>> Since the first "name" column was used in merging, leaving both
> >> >>>>> without a suffix seems consistent with the documentation...
> >> >>>>>
> >> >>>>> Frederick
> >> >>>>>
> >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> >> >>>>>
> >> >>>>>> Hi,
> >> >>>>>>
> >> >>>>>> I was unable to find a bug report for this with a cursory search,
> >> but
> >> >>>>>>
> >> >>>>> would
> >> >>>>>
> >> >>>>>> like clarification if this is intended or unavoidable behaviour:
> >> >>>>>>
> >> >>>>>> ```{r}
> >> >>>>>> # Create example data.frames
> >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> >> >>>>>>                        sex=c("F", "M", "F", "M"),
> >> >>>>>>                        age=c(41, 43, 36, 51))
> >> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> >> >>>>>>                         name=c("Oliver", "Sebastian", "Kai-lee"),
> >> >>>>>>                         sex=c("M", "M", "F"),
> >> >>>>>>                         age=c(5,8,7))
> >> >>>>>>
> >> >>>>>> # Merge() creates a duplicated "name" column:
> >> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
> >> >>>>>> ```
> >> >>>>>>
> >> >>>>>> Output:
> >> >>>>>> ```
> >> >>>>>>     name sex.x age.x      name sex.y age.y
> >> >>>>>> 1   Max     M    43 Sebastian     M     8
> >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
> >> >>>>>> 3 Sarah     F    41    Oliver     M     5
> >> >>>>>> Warning message:
> >> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
> >> >>>>>> "parent") :
> >> >>>>>>    column name ?name? is duplicated in the result
> >> >>>>>> ```
> >> >>>>>>
> >> >>>>>> Kind Regards,
> >> >>>>>>
> >> >>>>>> Scott Ritchie
> >> >>>>>>
> >> >>>>>>        [[alternative HTML version deleted]]
> >> >>>>>>
> >> >>>>>> ______________________________________________
> >> >>>>>> R-devel at r-project.org mailing list
> >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>>>>>
> >> >>>>>>
> >> >>>>>
> >> >>>>
> >> >>>>
> >> >> Index: src/library/base/R/merge.R
> >> >>> ===================================================================
> >> >>> --- src/library/base/R/merge.R  (revision 74264)
> >> >>> +++ src/library/base/R/merge.R  (working copy)
> >> >>> @@ -157,6 +157,15 @@
> >> >>>           }
> >> >>>             if(has.common.nms) names(y) <- nm.y
> >> >>> +        ## If by.x %in% names(y) then duplicate column names still
> >> >>> arise,
> >> >>> +        ## apply suffixes to these
> >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
> >> >>> +        if(length(dupe.keyx)) {
> >> >>> +          if(nzchar(suffixes[1L]))
> >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> >> >>> paste(dupe.keyx, suffixes[1L], sep="")
> >> >>> +          if(nzchar(suffixes[2L]))
> >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> >> >>> paste(dupe.keyx, suffixes[2L], sep="")
> >> >>> +        }
> >> >>>           nm <- c(names(x), names(y))
> >> >>>           if(any(d <- duplicated(nm)))
> >> >>>               if(sum(d) > 1L)
> >> >>>
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >> >>
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
> > --
> > Gabriel Becker, PhD
> > Scientist (Bioinformatics)
> > Genentech Research
> >

> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R	(revision 74264)
> +++ src/library/base/R/merge.R	(working copy)
> @@ -157,6 +157,15 @@
>          }
>  
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to these
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[1L]))
> +            names(x)[match(dupe.keyx, names(x), 0L)] <- paste(dupe.keyx, suffixes[1L], sep="")
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx, suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From s.ritchie73 at gmail.com  Wed Feb 21 00:06:21 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Wed, 21 Feb 2018 10:06:21 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <20180220212351.GP32564@ofb.net>
References: <CAO1VBV2WCJDNgmDdbomwqGVq-aNXnz4puuCNvnSCpJ1WzQOQdQ@mail.gmail.com>
 <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
Message-ID: <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>

Hi Frederick,

It looks like I didn't overwrite the patch.diff file after the last edits.
Here's the correct patch (attached and copied below):

Index: src/library/base/R/merge.R
===================================================================
--- src/library/base/R/merge.R (revision 74280)
+++ src/library/base/R/merge.R (working copy)
@@ -157,6 +157,14 @@
         }

         if(has.common.nms) names(y) <- nm.y
+        ## If by.x %in% names(y) then duplicate column names still arise,
+        ## apply suffixes to just y - this keeps backwards compatibility
+        ## when referring to by.x in the resulting data.frame
+        dupe.keyx <- intersect(nm.by, names(y))
+        if(length(dupe.keyx)) {
+          if(nzchar(suffixes[2L]))
+            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
suffixes[2L], sep="")
+        }
         nm <- c(names(x), names(y))
         if(any(d <- duplicated(nm)))
             if(sum(d) > 1L)

Best,

Scott

On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:

> Hi Scott,
>
> I think that's a good idea and I tried your patch on my copy of the
> repository. But it looks to me like the recent patch is identical to
> the previous one, can you confirm this?
>
> Frederick
>
> On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
> > Thanks Gabriel,
> >
> > I think your suggested approach is 100% backwards compatible
> >
> > Currently in the case of duplicate column names only the first can be
> > indexed by its name. This will always be the column appearing in by.x,
> > meaning the column in y with the same name cannot be accessed. Appending
> > ".y" (suffixes[2L]) to this column means it can now be accessed, while
> > keeping the current behaviour of making the key columns always accessible
> > by using the names provided to by.x.
> >
> > I've attached a new patch that has this behaviour.
> >
> > Best,
> >
> > Scott
> >
> > On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> >
> > > It seems like there is a way that is backwards compatible-ish in the
> sense
> > > mentioned and still has the (arguably, but a good argument I think)
> better
> > > behavior:
> > >
> > > if by.x is 'name', (AND by.y is not also 'name'), then x's 'name'
> column
> > > is called name and y's 'name' column (not used int he merge) is
> changed to
> > > name.y.
> > >
> > > Now of course this would still change output, but it would change it to
> > > something I think would be better, while retaining the 'merge columns
> > > retain their exact names' mechanic as documented.
> > >
> > > ~G
> > >
> > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <s.ritchie73 at gmail.com>
> > > wrote:
> > >
> > >> Thanks Duncan and Frederick,
> > >>
> > >> I suspected as much - there doesn't appear to be any reason why
> conflicts
> > >> between by.x and names(y) shouldn't and cannot be checked, but I can
> see
> > >> how this might be more trouble than its worth given it potentially may
> > >> break downstream packages (i.e. any cases where this occurs but they
> > >> expect
> > >> the name of the key column(s) to remain the same).
> > >>
> > >> Best,
> > >>
> > >> Scott
> > >>
> > >> On 18 February 2018 at 11:48, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> > >> wrote:
> > >>
> > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> > >> >
> > >> >> Hi Scott,
> > >> >>
> > >> >> Thanks for the patch. I'm not really involved in R development; it
> > >> >> will be up to someone in the R core team to apply it. I would
> hazard
> > >> >> to say that even if correct (I haven't checked), it will not be
> > >> >> applied because the change might break existing code. For example
> it
> > >> >> seems like reasonable code might easily assume that a column with
> the
> > >> >> same name as "by.x" exists in the output of 'merge'. That's just my
> > >> >> best guess... I don't participate on here often.
> > >> >>
> > >> >
> > >> >
> > >> > I think you're right.  If I were still a member of R Core, I would
> want
> > >> to
> > >> > test this against all packages on CRAN and Bioconductor, and since
> that
> > >> > test takes a couple of days to run on my laptop, I'd probably never
> get
> > >> > around to it.
> > >> >
> > >> > There are lots of cases where "I would have done that differently",
> but
> > >> > most of them are far too much trouble to change now that R is more
> than
> > >> 20
> > >> > years old.  And in many cases it will turn out that the way R does
> it
> > >> > actually does make more sense than the way I would have done it.
> > >> >
> > >> > Duncan Murdoch
> > >> >
> > >> >
> > >> >
> > >> >> Cheers,
> > >> >>
> > >> >> Frederick
> > >> >>
> > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> > >> >>
> > >> >>> The attached patch.diff will make merge.data.frame() append the
> > >> suffixes
> > >> >>> to
> > >> >>> columns with common names between by.x and names(y).
> > >> >>>
> > >> >>> Best,
> > >> >>>
> > >> >>> Scott Ritchie
> > >> >>>
> > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
> s.ritchie73 at gmail.com>
> > >> >>> wrote:
> > >> >>>
> > >> >>> Hi Frederick,
> > >> >>>>
> > >> >>>> I would expect that any duplicate names in the resulting
> data.frame
> > >> >>>> would
> > >> >>>> have the suffixes appended to them, regardless of whether or not
> they
> > >> >>>> are
> > >> >>>> used as the join key. So in my example I would expect "names.x"
> and
> > >> >>>> "names.y" to indicate their source data.frame.
> > >> >>>>
> > >> >>>> While careful reading of the documentation reveals this is not
> the
> > >> >>>> case, I
> > >> >>>> would argue the intent of the suffixes functionality should
> equally
> > >> be
> > >> >>>> applied to this type of case.
> > >> >>>>
> > >> >>>> If you agree this would be useful, I'm happy to write a patch for
> > >> >>>> merge.data.frame that will add suffixes in this case - I intend
> to do
> > >> >>>> the
> > >> >>>> same for merge.data.table in the data.table package where I
> initially
> > >> >>>> encountered the edge case.
> > >> >>>>
> > >> >>>> Best,
> > >> >>>>
> > >> >>>> Scott
> > >> >>>>
> > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> > >> >>>>
> > >> >>>> Hi Scott,
> > >> >>>>>
> > >> >>>>> It seems like reasonable behavior to me. What result would you
> > >> expect?
> > >> >>>>> That the second "name" should be called "name.y"?
> > >> >>>>>
> > >> >>>>> The "merge" documentation says:
> > >> >>>>>
> > >> >>>>>      If the columns in the data frames not used in merging have
> any
> > >> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by
> > >> default)
> > >> >>>>>      appended to try to make the names of the result unique.
> > >> >>>>>
> > >> >>>>> Since the first "name" column was used in merging, leaving both
> > >> >>>>> without a suffix seems consistent with the documentation...
> > >> >>>>>
> > >> >>>>> Frederick
> > >> >>>>>
> > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> > >> >>>>>
> > >> >>>>>> Hi,
> > >> >>>>>>
> > >> >>>>>> I was unable to find a bug report for this with a cursory
> search,
> > >> but
> > >> >>>>>>
> > >> >>>>> would
> > >> >>>>>
> > >> >>>>>> like clarification if this is intended or unavoidable
> behaviour:
> > >> >>>>>>
> > >> >>>>>> ```{r}
> > >> >>>>>> # Create example data.frames
> > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> > >> >>>>>>                        sex=c("F", "M", "F", "M"),
> > >> >>>>>>                        age=c(41, 43, 36, 51))
> > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> > >> >>>>>>                         name=c("Oliver", "Sebastian",
> "Kai-lee"),
> > >> >>>>>>                         sex=c("M", "M", "F"),
> > >> >>>>>>                         age=c(5,8,7))
> > >> >>>>>>
> > >> >>>>>> # Merge() creates a duplicated "name" column:
> > >> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
> > >> >>>>>> ```
> > >> >>>>>>
> > >> >>>>>> Output:
> > >> >>>>>> ```
> > >> >>>>>>     name sex.x age.x      name sex.y age.y
> > >> >>>>>> 1   Max     M    43 Sebastian     M     8
> > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
> > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
> > >> >>>>>> Warning message:
> > >> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
> > >> >>>>>> "parent") :
> > >> >>>>>>    column name ?name? is duplicated in the result
> > >> >>>>>> ```
> > >> >>>>>>
> > >> >>>>>> Kind Regards,
> > >> >>>>>>
> > >> >>>>>> Scott Ritchie
> > >> >>>>>>
> > >> >>>>>>        [[alternative HTML version deleted]]
> > >> >>>>>>
> > >> >>>>>> ______________________________________________
> > >> >>>>>> R-devel at r-project.org mailing list
> > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >> >>>>>>
> > >> >>>>>>
> > >> >>>>>
> > >> >>>>
> > >> >>>>
> > >> >> Index: src/library/base/R/merge.R
> > >> >>> ============================================================
> =======
> > >> >>> --- src/library/base/R/merge.R  (revision 74264)
> > >> >>> +++ src/library/base/R/merge.R  (working copy)
> > >> >>> @@ -157,6 +157,15 @@
> > >> >>>           }
> > >> >>>             if(has.common.nms) names(y) <- nm.y
> > >> >>> +        ## If by.x %in% names(y) then duplicate column names
> still
> > >> >>> arise,
> > >> >>> +        ## apply suffixes to these
> > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
> > >> >>> +        if(length(dupe.keyx)) {
> > >> >>> +          if(nzchar(suffixes[1L]))
> > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
> > >> >>> +          if(nzchar(suffixes[2L]))
> > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
> > >> >>> +        }
> > >> >>>           nm <- c(names(x), names(y))
> > >> >>>           if(any(d <- duplicated(nm)))
> > >> >>>               if(sum(d) > 1L)
> > >> >>>
> > >> >>
> > >> >> ______________________________________________
> > >> >> R-devel at r-project.org mailing list
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >> >>
> > >> >>
> > >> >
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> > >
> > >
> > >
> > > --
> > > Gabriel Becker, PhD
> > > Scientist (Bioinformatics)
> > > Genentech Research
> > >
>
> > Index: src/library/base/R/merge.R
> > ===================================================================
> > --- src/library/base/R/merge.R        (revision 74264)
> > +++ src/library/base/R/merge.R        (working copy)
> > @@ -157,6 +157,15 @@
> >          }
> >
> >          if(has.common.nms) names(y) <- nm.y
> > +        ## If by.x %in% names(y) then duplicate column names still
> arise,
> > +        ## apply suffixes to these
> > +        dupe.keyx <- intersect(nm.by, names(y))
> > +        if(length(dupe.keyx)) {
> > +          if(nzchar(suffixes[1L]))
> > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> paste(dupe.keyx, suffixes[1L], sep="")
> > +          if(nzchar(suffixes[2L]))
> > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> paste(dupe.keyx, suffixes[2L], sep="")
> > +        }
> >          nm <- c(names(x), names(y))
> >          if(any(d <- duplicated(nm)))
> >              if(sum(d) > 1L)
>
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180221/7e77cbd6/attachment.ksh>

From fifis.himik at gmail.com  Wed Feb 21 00:17:09 2018
From: fifis.himik at gmail.com (=?UTF-8?Q?Andre=C3=AF_V=2E_Kostyrka?=)
Date: Wed, 21 Feb 2018 00:17:09 +0100
Subject: [Rd] Unwanted behaviour of bw.nrd: sometimes,
 zero is returned as a valid bandwidth
Message-ID: <CAHFGd_N0_ga6PuRDTmnV7AyRgrS6tC_xwvz+8x1uHicb4xMXjg@mail.gmail.com>

Dear all,

Sorry if I am posting to the wrong place, but I could not find the link for
registration on the bug tracker, that?s why I am writing here.

I think there is inconsistency between two R functions from the stats
package, bw.nrd0 and bw.nrd.

Consider the following vector:
D <- c(0, 1, 1, 1, 1)

bw.nrd(D) returns zero bandwidth for this object even without a warning.
Considering the fact that in most cases, one divides something by the
bandwidth, it is highly undesirable that these function return zero
bandwidth without a warning.

Contrast bw.nrd0: it has three failsafes. First, if the minimum of SD and
IQR/1.34 is 0, it tries three things: set the base multiplier to SD, or to
|x[1]|, or to 1.

In my opinion, bw.nrd should have either one of these failsafes or a
warning that the vanilla formula equals to zero and that the user should
try another method of bandwidth selection (just like bw.ucv warns if the
minimum occurred at one end). It would be better than suddenly discovering
NaNs or NAs without even knowing the possible cause.


--
Bien cordialement,  |  Yours sincerely,
Andre? V. Kostyrka.
http://kostyrka.ru, http://kostyrka.ru/blog

	[[alternative HTML version deleted]]


From frederik at ofb.net  Wed Feb 21 04:15:46 2018
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 20 Feb 2018 19:15:46 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
References: <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
 <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
Message-ID: <20180221031546.GQ32564@ofb.net>

Hi Scott,

I tried the new patch and can confirm that it has the advertised
behavior on a couple of test cases. I think it makes sense to apply
it, because any existing code which refers to a second duplicate
data.frame column by name is already broken, while if the reference is
by numerical index then changing the column name shouldn't break it.

I don't know if you need to update the documentation as part of your
patch, or if whoever applies it would be happy to do that. Somebody
from R core want to weigh in on this?

I attach a file with the test example from your original email as well
as a second test case I added with two "by" columns.

Thanks,

Frederick

On Wed, Feb 21, 2018 at 10:06:21AM +1100, Scott Ritchie wrote:
> Hi Frederick,
> 
> It looks like I didn't overwrite the patch.diff file after the last edits.
> Here's the correct patch (attached and copied below):
> 
> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R (revision 74280)
> +++ src/library/base/R/merge.R (working copy)
> @@ -157,6 +157,14 @@
>          }
> 
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to just y - this keeps backwards compatibility
> +        ## when referring to by.x in the resulting data.frame
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
> suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)
> 
> Best,
> 
> Scott
> 
> On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:
> 
> > Hi Scott,
> >
> > I think that's a good idea and I tried your patch on my copy of the
> > repository. But it looks to me like the recent patch is identical to
> > the previous one, can you confirm this?
> >
> > Frederick
> >
> > On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
> > > Thanks Gabriel,
> > >
> > > I think your suggested approach is 100% backwards compatible
> > >
> > > Currently in the case of duplicate column names only the first can be
> > > indexed by its name. This will always be the column appearing in by.x,
> > > meaning the column in y with the same name cannot be accessed. Appending
> > > ".y" (suffixes[2L]) to this column means it can now be accessed, while
> > > keeping the current behaviour of making the key columns always accessible
> > > by using the names provided to by.x.
> > >
> > > I've attached a new patch that has this behaviour.
> > >
> > > Best,
> > >
> > > Scott
> > >
> > > On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu>
> > wrote:
> > >
> > > > It seems like there is a way that is backwards compatible-ish in the
> > sense
> > > > mentioned and still has the (arguably, but a good argument I think)
> > better
> > > > behavior:
> > > >
> > > > if by.x is 'name', (AND by.y is not also 'name'), then x's 'name'
> > column
> > > > is called name and y's 'name' column (not used int he merge) is
> > changed to
> > > > name.y.
> > > >
> > > > Now of course this would still change output, but it would change it to
> > > > something I think would be better, while retaining the 'merge columns
> > > > retain their exact names' mechanic as documented.
> > > >
> > > > ~G
> > > >
> > > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <s.ritchie73 at gmail.com>
> > > > wrote:
> > > >
> > > >> Thanks Duncan and Frederick,
> > > >>
> > > >> I suspected as much - there doesn't appear to be any reason why
> > conflicts
> > > >> between by.x and names(y) shouldn't and cannot be checked, but I can
> > see
> > > >> how this might be more trouble than its worth given it potentially may
> > > >> break downstream packages (i.e. any cases where this occurs but they
> > > >> expect
> > > >> the name of the key column(s) to remain the same).
> > > >>
> > > >> Best,
> > > >>
> > > >> Scott
> > > >>
> > > >> On 18 February 2018 at 11:48, Duncan Murdoch <
> > murdoch.duncan at gmail.com>
> > > >> wrote:
> > > >>
> > > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> > > >> >
> > > >> >> Hi Scott,
> > > >> >>
> > > >> >> Thanks for the patch. I'm not really involved in R development; it
> > > >> >> will be up to someone in the R core team to apply it. I would
> > hazard
> > > >> >> to say that even if correct (I haven't checked), it will not be
> > > >> >> applied because the change might break existing code. For example
> > it
> > > >> >> seems like reasonable code might easily assume that a column with
> > the
> > > >> >> same name as "by.x" exists in the output of 'merge'. That's just my
> > > >> >> best guess... I don't participate on here often.
> > > >> >>
> > > >> >
> > > >> >
> > > >> > I think you're right.  If I were still a member of R Core, I would
> > want
> > > >> to
> > > >> > test this against all packages on CRAN and Bioconductor, and since
> > that
> > > >> > test takes a couple of days to run on my laptop, I'd probably never
> > get
> > > >> > around to it.
> > > >> >
> > > >> > There are lots of cases where "I would have done that differently",
> > but
> > > >> > most of them are far too much trouble to change now that R is more
> > than
> > > >> 20
> > > >> > years old.  And in many cases it will turn out that the way R does
> > it
> > > >> > actually does make more sense than the way I would have done it.
> > > >> >
> > > >> > Duncan Murdoch
> > > >> >
> > > >> >
> > > >> >
> > > >> >> Cheers,
> > > >> >>
> > > >> >> Frederick
> > > >> >>
> > > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> > > >> >>
> > > >> >>> The attached patch.diff will make merge.data.frame() append the
> > > >> suffixes
> > > >> >>> to
> > > >> >>> columns with common names between by.x and names(y).
> > > >> >>>
> > > >> >>> Best,
> > > >> >>>
> > > >> >>> Scott Ritchie
> > > >> >>>
> > > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
> > s.ritchie73 at gmail.com>
> > > >> >>> wrote:
> > > >> >>>
> > > >> >>> Hi Frederick,
> > > >> >>>>
> > > >> >>>> I would expect that any duplicate names in the resulting
> > data.frame
> > > >> >>>> would
> > > >> >>>> have the suffixes appended to them, regardless of whether or not
> > they
> > > >> >>>> are
> > > >> >>>> used as the join key. So in my example I would expect "names.x"
> > and
> > > >> >>>> "names.y" to indicate their source data.frame.
> > > >> >>>>
> > > >> >>>> While careful reading of the documentation reveals this is not
> > the
> > > >> >>>> case, I
> > > >> >>>> would argue the intent of the suffixes functionality should
> > equally
> > > >> be
> > > >> >>>> applied to this type of case.
> > > >> >>>>
> > > >> >>>> If you agree this would be useful, I'm happy to write a patch for
> > > >> >>>> merge.data.frame that will add suffixes in this case - I intend
> > to do
> > > >> >>>> the
> > > >> >>>> same for merge.data.table in the data.table package where I
> > initially
> > > >> >>>> encountered the edge case.
> > > >> >>>>
> > > >> >>>> Best,
> > > >> >>>>
> > > >> >>>> Scott
> > > >> >>>>
> > > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> > > >> >>>>
> > > >> >>>> Hi Scott,
> > > >> >>>>>
> > > >> >>>>> It seems like reasonable behavior to me. What result would you
> > > >> expect?
> > > >> >>>>> That the second "name" should be called "name.y"?
> > > >> >>>>>
> > > >> >>>>> The "merge" documentation says:
> > > >> >>>>>
> > > >> >>>>>      If the columns in the data frames not used in merging have
> > any
> > > >> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"? by
> > > >> default)
> > > >> >>>>>      appended to try to make the names of the result unique.
> > > >> >>>>>
> > > >> >>>>> Since the first "name" column was used in merging, leaving both
> > > >> >>>>> without a suffix seems consistent with the documentation...
> > > >> >>>>>
> > > >> >>>>> Frederick
> > > >> >>>>>
> > > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie wrote:
> > > >> >>>>>
> > > >> >>>>>> Hi,
> > > >> >>>>>>
> > > >> >>>>>> I was unable to find a bug report for this with a cursory
> > search,
> > > >> but
> > > >> >>>>>>
> > > >> >>>>> would
> > > >> >>>>>
> > > >> >>>>>> like clarification if this is intended or unavoidable
> > behaviour:
> > > >> >>>>>>
> > > >> >>>>>> ```{r}
> > > >> >>>>>> # Create example data.frames
> > > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> > > >> >>>>>>                        sex=c("F", "M", "F", "M"),
> > > >> >>>>>>                        age=c(41, 43, 36, 51))
> > > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> > > >> >>>>>>                         name=c("Oliver", "Sebastian",
> > "Kai-lee"),
> > > >> >>>>>>                         sex=c("M", "M", "F"),
> > > >> >>>>>>                         age=c(5,8,7))
> > > >> >>>>>>
> > > >> >>>>>> # Merge() creates a duplicated "name" column:
> > > >> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
> > > >> >>>>>> ```
> > > >> >>>>>>
> > > >> >>>>>> Output:
> > > >> >>>>>> ```
> > > >> >>>>>>     name sex.x age.x      name sex.y age.y
> > > >> >>>>>> 1   Max     M    43 Sebastian     M     8
> > > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
> > > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
> > > >> >>>>>> Warning message:
> > > >> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
> > > >> >>>>>> "parent") :
> > > >> >>>>>>    column name ?name? is duplicated in the result
> > > >> >>>>>> ```
> > > >> >>>>>>
> > > >> >>>>>> Kind Regards,
> > > >> >>>>>>
> > > >> >>>>>> Scott Ritchie
> > > >> >>>>>>
> > > >> >>>>>>        [[alternative HTML version deleted]]
> > > >> >>>>>>
> > > >> >>>>>> ______________________________________________
> > > >> >>>>>> R-devel at r-project.org mailing list
> > > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> >>>>>>
> > > >> >>>>>>
> > > >> >>>>>
> > > >> >>>>
> > > >> >>>>
> > > >> >> Index: src/library/base/R/merge.R
> > > >> >>> ============================================================
> > =======
> > > >> >>> --- src/library/base/R/merge.R  (revision 74264)
> > > >> >>> +++ src/library/base/R/merge.R  (working copy)
> > > >> >>> @@ -157,6 +157,15 @@
> > > >> >>>           }
> > > >> >>>             if(has.common.nms) names(y) <- nm.y
> > > >> >>> +        ## If by.x %in% names(y) then duplicate column names
> > still
> > > >> >>> arise,
> > > >> >>> +        ## apply suffixes to these
> > > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
> > > >> >>> +        if(length(dupe.keyx)) {
> > > >> >>> +          if(nzchar(suffixes[1L]))
> > > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> > > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
> > > >> >>> +          if(nzchar(suffixes[2L]))
> > > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> > > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
> > > >> >>> +        }
> > > >> >>>           nm <- c(names(x), names(y))
> > > >> >>>           if(any(d <- duplicated(nm)))
> > > >> >>>               if(sum(d) > 1L)
> > > >> >>>
> > > >> >>
> > > >> >> ______________________________________________
> > > >> >> R-devel at r-project.org mailing list
> > > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> >>
> > > >> >>
> > > >> >
> > > >>
> > > >>         [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-devel at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>
> > > >
> > > >
> > > >
> > > > --
> > > > Gabriel Becker, PhD
> > > > Scientist (Bioinformatics)
> > > > Genentech Research
> > > >
> >
> > > Index: src/library/base/R/merge.R
> > > ===================================================================
> > > --- src/library/base/R/merge.R        (revision 74264)
> > > +++ src/library/base/R/merge.R        (working copy)
> > > @@ -157,6 +157,15 @@
> > >          }
> > >
> > >          if(has.common.nms) names(y) <- nm.y
> > > +        ## If by.x %in% names(y) then duplicate column names still
> > arise,
> > > +        ## apply suffixes to these
> > > +        dupe.keyx <- intersect(nm.by, names(y))
> > > +        if(length(dupe.keyx)) {
> > > +          if(nzchar(suffixes[1L]))
> > > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> > paste(dupe.keyx, suffixes[1L], sep="")
> > > +          if(nzchar(suffixes[2L]))
> > > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> > paste(dupe.keyx, suffixes[2L], sep="")
> > > +        }
> > >          nm <- c(names(x), names(y))
> > >          if(any(d <- duplicated(nm)))
> > >              if(sum(d) > 1L)
> >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >

> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R	(revision 74280)
> +++ src/library/base/R/merge.R	(working copy)
> @@ -157,6 +157,14 @@
>          }
>  
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to just y - this keeps backwards compatibility
> +        ## when referring to by.x in the resulting data.frame
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx, suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ritchie-testcase
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180220/b5b74207/attachment.ksh>

From i.ucar86 at gmail.com  Wed Feb 21 14:16:52 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Wed, 21 Feb 2018 14:16:52 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
Message-ID: <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>

I've set up a repo with a reproducible example of the issue described
in my last email:

https://github.com/Enchufa2/dispatchS3dots

I?aki

2018-02-20 19:33 GMT+01:00 I?aki ?car <i.ucar86 at gmail.com>:
> Hi all,
>
> Not sure if this belongs to R-devel or R-package-devel. Anyways...
>
> Suppose we have objects of class c("foo", "bar"), and there are two S3
> methods c.foo, c.bar. In c.foo, I'm trying to modify the dots and
> forward the dispatch using NextMethod without any success. This is
> what I've tried so far:
>
> c.foo <- function(..., recursive=FALSE) {
>   dots <- list(...)
>   # inspect and modify dots
>   # ...
>   do.call(
>     function(..., recursive=FALSE) structure(NextMethod("c"), class="foo"),
>     c(dots, recursive=recursive)
>   )
> }
>
> foobar <- 1
> class(foobar) <- c("foo", "bar")
> c(foobar, foobar)
> Error: C stack usage  7970788 is too close to the limit
>
> There's recursion (!). But the funniest thing is that if c.foo is
> exported by one package and c.bar is exported by another one, there's
> no recursion, but c.bar is never called (!!). Why is the same code
> behaving in a different way depending on whether these functions are
> defined in the .GlobalEnv or in two attached packages? (BTW,
> isS3method() is TRUE, for c.foo and c.bar in both cases).
>
> I'm blocked here. Am I missing something? Is there a way of doing
> this? Thanks in advance.
>
> Regards,
> I?aki



-- 
I?aki ?car
http://www.enchufa2.es
@Enchufa2


From gmbecker at ucdavis.edu  Wed Feb 21 16:11:44 2018
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 21 Feb 2018 07:11:44 -0800
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CADwqtCPTRPfz8xuAiCQ0ccnDc8rbaSdGjTBCcxM=Ef2MEzvj1w@mail.gmail.com>
References: <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
 <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
 <20180221031546.GQ32564@ofb.net>
 <CADwqtCPTRPfz8xuAiCQ0ccnDc8rbaSdGjTBCcxM=Ef2MEzvj1w@mail.gmail.com>
Message-ID: <CADwqtCP84q+JyYUGQ_DSBz9eAVCwTfoz6jt_r_8xiAT5HVnYGQ@mail.gmail.com>

Hi all,

For the record this approach isnt 100% backwards compatible, because
names(mergeddf) will e incompatibly different. Thatx why i claimed
bakcwards compatable-ish

That said its still worth considering imho because of the reasons stated
(and honestly one particular simple reading of the docs might suggest that
this was thr intended behavior all along). Im not a member of Rcore through
so i cant do said considering myself.

Best,
~G

On Feb 20, 2018 7:15 PM, <frederik at ofb.net> wrote:

Hi Scott,

I tried the new patch and can confirm that it has the advertised
behavior on a couple of test cases. I think it makes sense to apply
it, because any existing code which refers to a second duplicate
data.frame column by name is already broken, while if the reference is
by numerical index then changing the column name shouldn't break it.

I don't know if you need to update the documentation as part of your
patch, or if whoever applies it would be happy to do that. Somebody
from R core want to weigh in on this?

I attach a file with the test example from your original email as well
as a second test case I added with two "by" columns.

Thanks,

Frederick

On Wed, Feb 21, 2018 at 10:06:21AM +1100, Scott Ritchie wrote:
> Hi Frederick,
>
> It looks like I didn't overwrite the patch.diff file after the last edits.
> Here's the correct patch (attached and copied below):
>
> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R (revision 74280)
> +++ src/library/base/R/merge.R (working copy)
> @@ -157,6 +157,14 @@
>          }
>
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to just y - this keeps backwards compatibility
> +        ## when referring to by.x in the resulting data.frame
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
> suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)
>
> Best,
>
> Scott
>
> On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:
>
> > Hi Scott,
> >
> > I think that's a good idea and I tried your patch on my copy of the
> > repository. But it looks to me like the recent patch is identical to
> > the previous one, can you confirm this?
> >
> > Frederick
> >
> > On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
> > > Thanks Gabriel,
> > >
> > > I think your suggested approach is 100% backwards compatible
> > >
> > > Currently in the case of duplicate column names only the first can be
> > > indexed by its name. This will always be the column appearing in by.x,
> > > meaning the column in y with the same name cannot be accessed.
Appending
> > > ".y" (suffixes[2L]) to this column means it can now be accessed, while
> > > keeping the current behaviour of making the key columns always
accessible
> > > by using the names provided to by.x.
> > >
> > > I've attached a new patch that has this behaviour.
> > >
> > > Best,
> > >
> > > Scott
> > >
> > > On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu>
> > wrote:
> > >
> > > > It seems like there is a way that is backwards compatible-ish in the
> > sense
> > > > mentioned and still has the (arguably, but a good argument I think)
> > better
> > > > behavior:
> > > >
> > > > if by.x is 'name', (AND by.y is not also 'name'), then x's 'name'
> > column
> > > > is called name and y's 'name' column (not used int he merge) is
> > changed to
> > > > name.y.
> > > >
> > > > Now of course this would still change output, but it would change
it to
> > > > something I think would be better, while retaining the 'merge
columns
> > > > retain their exact names' mechanic as documented.
> > > >
> > > > ~G
> > > >
> > > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <
s.ritchie73 at gmail.com>
> > > > wrote:
> > > >
> > > >> Thanks Duncan and Frederick,
> > > >>
> > > >> I suspected as much - there doesn't appear to be any reason why
> > conflicts
> > > >> between by.x and names(y) shouldn't and cannot be checked, but I
can
> > see
> > > >> how this might be more trouble than its worth given it potentially
may
> > > >> break downstream packages (i.e. any cases where this occurs but
they
> > > >> expect
> > > >> the name of the key column(s) to remain the same).
> > > >>
> > > >> Best,
> > > >>
> > > >> Scott
> > > >>
> > > >> On 18 February 2018 at 11:48, Duncan Murdoch <
> > murdoch.duncan at gmail.com>
> > > >> wrote:
> > > >>
> > > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
> > > >> >
> > > >> >> Hi Scott,
> > > >> >>
> > > >> >> Thanks for the patch. I'm not really involved in R development;
it
> > > >> >> will be up to someone in the R core team to apply it. I would
> > hazard
> > > >> >> to say that even if correct (I haven't checked), it will not be
> > > >> >> applied because the change might break existing code. For
example
> > it
> > > >> >> seems like reasonable code might easily assume that a column
with
> > the
> > > >> >> same name as "by.x" exists in the output of 'merge'. That's
just my
> > > >> >> best guess... I don't participate on here often.
> > > >> >>
> > > >> >
> > > >> >
> > > >> > I think you're right.  If I were still a member of R Core, I
would
> > want
> > > >> to
> > > >> > test this against all packages on CRAN and Bioconductor, and
since
> > that
> > > >> > test takes a couple of days to run on my laptop, I'd probably
never
> > get
> > > >> > around to it.
> > > >> >
> > > >> > There are lots of cases where "I would have done that
differently",
> > but
> > > >> > most of them are far too much trouble to change now that R is
more
> > than
> > > >> 20
> > > >> > years old.  And in many cases it will turn out that the way R
does
> > it
> > > >> > actually does make more sense than the way I would have done it.
> > > >> >
> > > >> > Duncan Murdoch
> > > >> >
> > > >> >
> > > >> >
> > > >> >> Cheers,
> > > >> >>
> > > >> >> Frederick
> > > >> >>
> > > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
> > > >> >>
> > > >> >>> The attached patch.diff will make merge.data.frame() append the
> > > >> suffixes
> > > >> >>> to
> > > >> >>> columns with common names between by.x and names(y).
> > > >> >>>
> > > >> >>> Best,
> > > >> >>>
> > > >> >>> Scott Ritchie
> > > >> >>>
> > > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
> > s.ritchie73 at gmail.com>
> > > >> >>> wrote:
> > > >> >>>
> > > >> >>> Hi Frederick,
> > > >> >>>>
> > > >> >>>> I would expect that any duplicate names in the resulting
> > data.frame
> > > >> >>>> would
> > > >> >>>> have the suffixes appended to them, regardless of whether or
not
> > they
> > > >> >>>> are
> > > >> >>>> used as the join key. So in my example I would expect
"names.x"
> > and
> > > >> >>>> "names.y" to indicate their source data.frame.
> > > >> >>>>
> > > >> >>>> While careful reading of the documentation reveals this is not
> > the
> > > >> >>>> case, I
> > > >> >>>> would argue the intent of the suffixes functionality should
> > equally
> > > >> be
> > > >> >>>> applied to this type of case.
> > > >> >>>>
> > > >> >>>> If you agree this would be useful, I'm happy to write a patch
for
> > > >> >>>> merge.data.frame that will add suffixes in this case - I
intend
> > to do
> > > >> >>>> the
> > > >> >>>> same for merge.data.table in the data.table package where I
> > initially
> > > >> >>>> encountered the edge case.
> > > >> >>>>
> > > >> >>>> Best,
> > > >> >>>>
> > > >> >>>> Scott
> > > >> >>>>
> > > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
> > > >> >>>>
> > > >> >>>> Hi Scott,
> > > >> >>>>>
> > > >> >>>>> It seems like reasonable behavior to me. What result would
you
> > > >> expect?
> > > >> >>>>> That the second "name" should be called "name.y"?
> > > >> >>>>>
> > > >> >>>>> The "merge" documentation says:
> > > >> >>>>>
> > > >> >>>>>      If the columns in the data frames not used in merging
have
> > any
> > > >> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"?
by
> > > >> default)
> > > >> >>>>>      appended to try to make the names of the result unique.
> > > >> >>>>>
> > > >> >>>>> Since the first "name" column was used in merging, leaving
both
> > > >> >>>>> without a suffix seems consistent with the documentation...
> > > >> >>>>>
> > > >> >>>>> Frederick
> > > >> >>>>>
> > > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie
wrote:
> > > >> >>>>>
> > > >> >>>>>> Hi,
> > > >> >>>>>>
> > > >> >>>>>> I was unable to find a bug report for this with a cursory
> > search,
> > > >> but
> > > >> >>>>>>
> > > >> >>>>> would
> > > >> >>>>>
> > > >> >>>>>> like clarification if this is intended or unavoidable
> > behaviour:
> > > >> >>>>>>
> > > >> >>>>>> ```{r}
> > > >> >>>>>> # Create example data.frames
> > > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
> > > >> >>>>>>                        sex=c("F", "M", "F", "M"),
> > > >> >>>>>>                        age=c(41, 43, 36, 51))
> > > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
> > > >> >>>>>>                         name=c("Oliver", "Sebastian",
> > "Kai-lee"),
> > > >> >>>>>>                         sex=c("M", "M", "F"),
> > > >> >>>>>>                         age=c(5,8,7))
> > > >> >>>>>>
> > > >> >>>>>> # Merge() creates a duplicated "name" column:
> > > >> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
> > > >> >>>>>> ```
> > > >> >>>>>>
> > > >> >>>>>> Output:
> > > >> >>>>>> ```
> > > >> >>>>>>     name sex.x age.x      name sex.y age.y
> > > >> >>>>>> 1   Max     M    43 Sebastian     M     8
> > > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
> > > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
> > > >> >>>>>> Warning message:
> > > >> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
> > > >> >>>>>> "parent") :
> > > >> >>>>>>    column name ?name? is duplicated in the result
> > > >> >>>>>> ```
> > > >> >>>>>>
> > > >> >>>>>> Kind Regards,
> > > >> >>>>>>
> > > >> >>>>>> Scott Ritchie
> > > >> >>>>>>
> > > >> >>>>>>        [[alternative HTML version deleted]]
> > > >> >>>>>>
> > > >> >>>>>> ______________________________________________
> > > >> >>>>>> R-devel at r-project.org mailing list
> > > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> >>>>>>
> > > >> >>>>>>
> > > >> >>>>>
> > > >> >>>>
> > > >> >>>>
> > > >> >> Index: src/library/base/R/merge.R
> > > >> >>> ============================================================
> > =======
> > > >> >>> --- src/library/base/R/merge.R  (revision 74264)
> > > >> >>> +++ src/library/base/R/merge.R  (working copy)
> > > >> >>> @@ -157,6 +157,15 @@
> > > >> >>>           }
> > > >> >>>             if(has.common.nms) names(y) <- nm.y
> > > >> >>> +        ## If by.x %in% names(y) then duplicate column names
> > still
> > > >> >>> arise,
> > > >> >>> +        ## apply suffixes to these
> > > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
> > > >> >>> +        if(length(dupe.keyx)) {
> > > >> >>> +          if(nzchar(suffixes[1L]))
> > > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> > > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
> > > >> >>> +          if(nzchar(suffixes[2L]))
> > > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> > > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
> > > >> >>> +        }
> > > >> >>>           nm <- c(names(x), names(y))
> > > >> >>>           if(any(d <- duplicated(nm)))
> > > >> >>>               if(sum(d) > 1L)
> > > >> >>>
> > > >> >>
> > > >> >> ______________________________________________
> > > >> >> R-devel at r-project.org mailing list
> > > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> >>
> > > >> >>
> > > >> >
> > > >>
> > > >>         [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-devel at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>
> > > >
> > > >
> > > >
> > > > --
> > > > Gabriel Becker, PhD
> > > > Scientist (Bioinformatics)
> > > > Genentech Research
> > > >
> >
> > > Index: src/library/base/R/merge.R
> > > ===================================================================
> > > --- src/library/base/R/merge.R        (revision 74264)
> > > +++ src/library/base/R/merge.R        (working copy)
> > > @@ -157,6 +157,15 @@
> > >          }
> > >
> > >          if(has.common.nms) names(y) <- nm.y
> > > +        ## If by.x %in% names(y) then duplicate column names still
> > arise,
> > > +        ## apply suffixes to these
> > > +        dupe.keyx <- intersect(nm.by, names(y))
> > > +        if(length(dupe.keyx)) {
> > > +          if(nzchar(suffixes[1L]))
> > > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
> > paste(dupe.keyx, suffixes[1L], sep="")
> > > +          if(nzchar(suffixes[2L]))
> > > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> > paste(dupe.keyx, suffixes[2L], sep="")
> > > +        }
> > >          nm <- c(names(x), names(y))
> > >          if(any(d <- duplicated(nm)))
> > >              if(sum(d) > 1L)
> >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >

> Index: src/library/base/R/merge.R
> ===================================================================
> --- src/library/base/R/merge.R        (revision 74280)
> +++ src/library/base/R/merge.R        (working copy)
> @@ -157,6 +157,14 @@
>          }
>
>          if(has.common.nms) names(y) <- nm.y
> +        ## If by.x %in% names(y) then duplicate column names still arise,
> +        ## apply suffixes to just y - this keeps backwards compatibility
> +        ## when referring to by.x in the resulting data.frame
> +        dupe.keyx <- intersect(nm.by, names(y))
> +        if(length(dupe.keyx)) {
> +          if(nzchar(suffixes[2L]))
> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
suffixes[2L], sep="")
> +        }
>          nm <- c(names(x), names(y))
>          if(any(d <- duplicated(nm)))
>              if(sum(d) > 1L)

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Thu Feb 22 10:29:10 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 22 Feb 2018 10:29:10 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
 <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
Message-ID: <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>


The example is invoking NextMethod via an anonymous function, which is 
not allowed (see documentation for NextMethod). Normally one gets a 
runtime error "'NextMethod' called from an anonymous function", but not 
here as the anonymous function is called via do.call. I will fix so that 
there is a runtime error in this case as well, thanks for uncovering 
this problem.

I don't think there is a way to replace (unnamed) arguments in dots for 
NextMethod.

Tomas

On 02/21/2018 02:16 PM, I?aki ?car wrote:
> I've set up a repo with a reproducible example of the issue described
> in my last email:
>
> https://github.com/Enchufa2/dispatchS3dots
>
> I?aki
>
> 2018-02-20 19:33 GMT+01:00 I?aki ?car <i.ucar86 at gmail.com>:
>> Hi all,
>>
>> Not sure if this belongs to R-devel or R-package-devel. Anyways...
>>
>> Suppose we have objects of class c("foo", "bar"), and there are two S3
>> methods c.foo, c.bar. In c.foo, I'm trying to modify the dots and
>> forward the dispatch using NextMethod without any success. This is
>> what I've tried so far:
>>
>> c.foo <- function(..., recursive=FALSE) {
>>    dots <- list(...)
>>    # inspect and modify dots
>>    # ...
>>    do.call(
>>      function(..., recursive=FALSE) structure(NextMethod("c"), class="foo"),
>>      c(dots, recursive=recursive)
>>    )
>> }
>>
>> foobar <- 1
>> class(foobar) <- c("foo", "bar")
>> c(foobar, foobar)
>> Error: C stack usage  7970788 is too close to the limit
>>
>> There's recursion (!). But the funniest thing is that if c.foo is
>> exported by one package and c.bar is exported by another one, there's
>> no recursion, but c.bar is never called (!!). Why is the same code
>> behaving in a different way depending on whether these functions are
>> defined in the .GlobalEnv or in two attached packages? (BTW,
>> isS3method() is TRUE, for c.foo and c.bar in both cases).
>>
>> I'm blocked here. Am I missing something? Is there a way of doing
>> this? Thanks in advance.
>>
>> Regards,
>> I?aki
>
>


From i.ucar86 at gmail.com  Thu Feb 22 12:07:22 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 22 Feb 2018 12:07:22 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
 <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
 <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>
Message-ID: <CALEXWq1=VDs2BQ2CEMJKwrtmZNCG1Scf2EfgGn91xTdH9ibGVA@mail.gmail.com>

2018-02-22 10:29 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>
> The example is invoking NextMethod via an anonymous function, which is not
> allowed (see documentation for NextMethod).

Thanks for your response. I definitely missed that bit.

> Normally one gets a runtime
> error "'NextMethod' called from an anonymous function", but not here as the
> anonymous function is called via do.call. I will fix so that there is a
> runtime error in this case as well, thanks for uncovering this problem.

Then I did well chosing this list! Please also note that you could
take that anonymous function out of the method and name it, and the
behaviour would be the same. So maybe this case should issue an error
too.

> I don't think there is a way to replace (unnamed) arguments in dots for
> NextMethod.

That's a pity. IMHO, it should be some mechanism for that, but dots
are special in inscrutable ways.

Anyway, for anyone insterested, I found a workaround:

https://github.com/Enchufa2/dispatchS3dots#workaround

>
> Tomas
>
>

I?aki


From maechler at stat.math.ethz.ch  Thu Feb 22 12:31:40 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Feb 2018 12:31:40 +0100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CADwqtCP84q+JyYUGQ_DSBz9eAVCwTfoz6jt_r_8xiAT5HVnYGQ@mail.gmail.com>
References: <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
 <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
 <20180221031546.GQ32564@ofb.net>
 <CADwqtCPTRPfz8xuAiCQ0ccnDc8rbaSdGjTBCcxM=Ef2MEzvj1w@mail.gmail.com>
 <CADwqtCP84q+JyYUGQ_DSBz9eAVCwTfoz6jt_r_8xiAT5HVnYGQ@mail.gmail.com>
Message-ID: <23182.43548.14172.267191@stat.math.ethz.ch>

>>>>> Gabriel Becker <gmbecker at ucdavis.edu>
>>>>>     on Wed, 21 Feb 2018 07:11:44 -0800 writes:

    > Hi all,
    > For the record this approach isnt 100% backwards compatible, because
    > names(mergeddf) will e incompatibly different. Thatx why i claimed
    > bakcwards compatable-ish

exactly.

    > That said its still worth considering imho because of the reasons stated
    > (and honestly one particular simple reading of the docs might suggest that
    > this was thr intended behavior all along). Im not a member of Rcore through
    > so i cant do said considering myself.

I agree with Scott, Frederik and you that this changes seems
worth considering.
As Duncan Murdoch has mentioned, this alone may not be
sufficient.

In addition to your proposed patch (which I have simplified, not
using intersection() but working with underlying  match()
directly), it is little work to introduce an extra argument, I'm
calling  'no.dups = TRUE'  which when set to false would mirror
current R's behavior... and documenting it, then also documents the
new behavior (to some extent).

My plan is to commit it soonish ;-)
Martin

    > Best,
    > ~G

    > On Feb 20, 2018 7:15 PM, <frederik at ofb.net> wrote:

    > Hi Scott,

    > I tried the new patch and can confirm that it has the advertised
    > behavior on a couple of test cases. I think it makes sense to apply
    > it, because any existing code which refers to a second duplicate
    > data.frame column by name is already broken, while if the reference is
    > by numerical index then changing the column name shouldn't break it.

    > I don't know if you need to update the documentation as part of your
    > patch, or if whoever applies it would be happy to do that. Somebody
    > from R core want to weigh in on this?

    > I attach a file with the test example from your original email as well
    > as a second test case I added with two "by" columns.

    > Thanks,

    > Frederick

    > On Wed, Feb 21, 2018 at 10:06:21AM +1100, Scott Ritchie wrote:
    >> Hi Frederick,
    >> 
    >> It looks like I didn't overwrite the patch.diff file after the last edits.
    >> Here's the correct patch (attached and copied below):
    >> 
    >> Index: src/library/base/R/merge.R
    >> ===================================================================
    >> --- src/library/base/R/merge.R (revision 74280)
    >> +++ src/library/base/R/merge.R (working copy)
    >> @@ -157,6 +157,14 @@
    >> }
    >> 
    >> if(has.common.nms) names(y) <- nm.y
    >> +        ## If by.x %in% names(y) then duplicate column names still arise,
    >> +        ## apply suffixes to just y - this keeps backwards compatibility
    >> +        ## when referring to by.x in the resulting data.frame
    >> +        dupe.keyx <- intersect(nm.by, names(y))
    >> +        if(length(dupe.keyx)) {
    >> +          if(nzchar(suffixes[2L]))
    >> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
    >> suffixes[2L], sep="")
    >> +        }
    >> nm <- c(names(x), names(y))
    >> if(any(d <- duplicated(nm)))
    >> if(sum(d) > 1L)
    >> 
    >> Best,
    >> 
    >> Scott
    >> 
    >> On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:
    >> 
    >> > Hi Scott,
    >> >
    >> > I think that's a good idea and I tried your patch on my copy of the
    >> > repository. But it looks to me like the recent patch is identical to
    >> > the previous one, can you confirm this?
    >> >
    >> > Frederick
    >> >
    >> > On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
    >> > > Thanks Gabriel,
    >> > >
    >> > > I think your suggested approach is 100% backwards compatible
    >> > >
    >> > > Currently in the case of duplicate column names only the first can be
    >> > > indexed by its name. This will always be the column appearing in by.x,
    >> > > meaning the column in y with the same name cannot be accessed.
    > Appending
    >> > > ".y" (suffixes[2L]) to this column means it can now be accessed, while
    >> > > keeping the current behaviour of making the key columns always
    > accessible
    >> > > by using the names provided to by.x.
    >> > >
    >> > > I've attached a new patch that has this behaviour.
    >> > >
    >> > > Best,
    >> > >
    >> > > Scott
    >> > >
    >> > > On 19 February 2018 at 05:08, Gabriel Becker <gmbecker at ucdavis.edu>
    >> > wrote:
    >> > >
    >> > > > It seems like there is a way that is backwards compatible-ish in the
    >> > sense
    >> > > > mentioned and still has the (arguably, but a good argument I think)
    >> > better
    >> > > > behavior:
    >> > > >
    >> > > > if by.x is 'name', (AND by.y is not also 'name'), then x's 'name'
    >> > column
    >> > > > is called name and y's 'name' column (not used int he merge) is
    >> > changed to
    >> > > > name.y.
    >> > > >
    >> > > > Now of course this would still change output, but it would change
    > it to
    >> > > > something I think would be better, while retaining the 'merge
    > columns
    >> > > > retain their exact names' mechanic as documented.
    >> > > >
    >> > > > ~G
    >> > > >
    >> > > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <
    > s.ritchie73 at gmail.com>
    >> > > > wrote:
    >> > > >
    >> > > >> Thanks Duncan and Frederick,
    >> > > >>
    >> > > >> I suspected as much - there doesn't appear to be any reason why
    >> > conflicts
    >> > > >> between by.x and names(y) shouldn't and cannot be checked, but I
    > can
    >> > see
    >> > > >> how this might be more trouble than its worth given it potentially
    > may
    >> > > >> break downstream packages (i.e. any cases where this occurs but
    > they
    >> > > >> expect
    >> > > >> the name of the key column(s) to remain the same).
    >> > > >>
    >> > > >> Best,
    >> > > >>
    >> > > >> Scott
    >> > > >>
    >> > > >> On 18 February 2018 at 11:48, Duncan Murdoch <
    >> > murdoch.duncan at gmail.com>
    >> > > >> wrote:
    >> > > >>
    >> > > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
    >> > > >> >
    >> > > >> >> Hi Scott,
    >> > > >> >>
    >> > > >> >> Thanks for the patch. I'm not really involved in R development;
    > it
    >> > > >> >> will be up to someone in the R core team to apply it. I would
    >> > hazard
    >> > > >> >> to say that even if correct (I haven't checked), it will not be
    >> > > >> >> applied because the change might break existing code. For
    > example
    >> > it
    >> > > >> >> seems like reasonable code might easily assume that a column
    > with
    >> > the
    >> > > >> >> same name as "by.x" exists in the output of 'merge'. That's
    > just my
    >> > > >> >> best guess... I don't participate on here often.
    >> > > >> >>
    >> > > >> >
    >> > > >> >
    >> > > >> > I think you're right.  If I were still a member of R Core, I
    > would
    >> > want
    >> > > >> to
    >> > > >> > test this against all packages on CRAN and Bioconductor, and
    > since
    >> > that
    >> > > >> > test takes a couple of days to run on my laptop, I'd probably
    > never
    >> > get
    >> > > >> > around to it.
    >> > > >> >
    >> > > >> > There are lots of cases where "I would have done that
    > differently",
    >> > but
    >> > > >> > most of them are far too much trouble to change now that R is
    > more
    >> > than
    >> > > >> 20
    >> > > >> > years old.  And in many cases it will turn out that the way R
    > does
    >> > it
    >> > > >> > actually does make more sense than the way I would have done it.
    >> > > >> >
    >> > > >> > Duncan Murdoch
    >> > > >> >
    >> > > >> >
    >> > > >> >
    >> > > >> >> Cheers,
    >> > > >> >>
    >> > > >> >> Frederick
    >> > > >> >>
    >> > > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie wrote:
    >> > > >> >>
    >> > > >> >>> The attached patch.diff will make merge.data.frame() append the
    >> > > >> suffixes
    >> > > >> >>> to
    >> > > >> >>> columns with common names between by.x and names(y).
    >> > > >> >>>
    >> > > >> >>> Best,
    >> > > >> >>>
    >> > > >> >>> Scott Ritchie
    >> > > >> >>>
    >> > > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
    >> > s.ritchie73 at gmail.com>
    >> > > >> >>> wrote:
    >> > > >> >>>
    >> > > >> >>> Hi Frederick,
    >> > > >> >>>>
    >> > > >> >>>> I would expect that any duplicate names in the resulting
    >> > data.frame
    >> > > >> >>>> would
    >> > > >> >>>> have the suffixes appended to them, regardless of whether or
    > not
    >> > they
    >> > > >> >>>> are
    >> > > >> >>>> used as the join key. So in my example I would expect
    > "names.x"
    >> > and
    >> > > >> >>>> "names.y" to indicate their source data.frame.
    >> > > >> >>>>
    >> > > >> >>>> While careful reading of the documentation reveals this is not
    >> > the
    >> > > >> >>>> case, I
    >> > > >> >>>> would argue the intent of the suffixes functionality should
    >> > equally
    >> > > >> be
    >> > > >> >>>> applied to this type of case.
    >> > > >> >>>>
    >> > > >> >>>> If you agree this would be useful, I'm happy to write a patch
    > for
    >> > > >> >>>> merge.data.frame that will add suffixes in this case - I
    > intend
    >> > to do
    >> > > >> >>>> the
    >> > > >> >>>> same for merge.data.table in the data.table package where I
    >> > initially
    >> > > >> >>>> encountered the edge case.
    >> > > >> >>>>
    >> > > >> >>>> Best,
    >> > > >> >>>>
    >> > > >> >>>> Scott
    >> > > >> >>>>
    >> > > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
    >> > > >> >>>>
    >> > > >> >>>> Hi Scott,
    >> > > >> >>>>>
    >> > > >> >>>>> It seems like reasonable behavior to me. What result would
    > you
    >> > > >> expect?
    >> > > >> >>>>> That the second "name" should be called "name.y"?
    >> > > >> >>>>>
    >> > > >> >>>>> The "merge" documentation says:
    >> > > >> >>>>>
    >> > > >> >>>>>      If the columns in the data frames not used in merging
    > have
    >> > any
    >> > > >> >>>>>      common names, these have ?suffixes? (?".x"? and ?".y"?
    > by
    >> > > >> default)
    >> > > >> >>>>>      appended to try to make the names of the result unique.
    >> > > >> >>>>>
    >> > > >> >>>>> Since the first "name" column was used in merging, leaving
    > both
    >> > > >> >>>>> without a suffix seems consistent with the documentation...
    >> > > >> >>>>>
    >> > > >> >>>>> Frederick
    >> > > >> >>>>>
    >> > > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie
    > wrote:
    >> > > >> >>>>>
    >> > > >> >>>>>> Hi,
    >> > > >> >>>>>>
    >> > > >> >>>>>> I was unable to find a bug report for this with a cursory
    >> > search,
    >> > > >> but
    >> > > >> >>>>>>
    >> > > >> >>>>> would
    >> > > >> >>>>>
    >> > > >> >>>>>> like clarification if this is intended or unavoidable
    >> > behaviour:
    >> > > >> >>>>>>
    >> > > >> >>>>>> ```{r}
    >> > > >> >>>>>> # Create example data.frames
    >> > > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin", "Lex"),
    >> > > >> >>>>>>                        sex=c("F", "M", "F", "M"),
    >> > > >> >>>>>>                        age=c(41, 43, 36, 51))
    >> > > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max", "Qin"),
    >> > > >> >>>>>>                         name=c("Oliver", "Sebastian",
    >> > "Kai-lee"),
    >> > > >> >>>>>>                         sex=c("M", "M", "F"),
    >> > > >> >>>>>>                         age=c(5,8,7))
    >> > > >> >>>>>>
    >> > > >> >>>>>> # Merge() creates a duplicated "name" column:
    >> > > >> >>>>>> merge(parents, children, by.x = "name", by.y = "parent")
    >> > > >> >>>>>> ```
    >> > > >> >>>>>>
    >> > > >> >>>>>> Output:
    >> > > >> >>>>>> ```
    >> > > >> >>>>>>     name sex.x age.x      name sex.y age.y
    >> > > >> >>>>>> 1   Max     M    43 Sebastian     M     8
    >> > > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
    >> > > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
    >> > > >> >>>>>> Warning message:
    >> > > >> >>>>>> In merge.data.frame(parents, children, by.x = "name", by.y =
    >> > > >> >>>>>> "parent") :
    >> > > >> >>>>>>    column name ?name? is duplicated in the result
    >> > > >> >>>>>> ```
    >> > > >> >>>>>>
    >> > > >> >>>>>> Kind Regards,
    >> > > >> >>>>>>
    >> > > >> >>>>>> Scott Ritchie
    >> > > >> >>>>>>
    >> > > >> >>>>>>        [[alternative HTML version deleted]]
    >> > > >> >>>>>>
    >> > > >> >>>>>> ______________________________________________
    >> > > >> >>>>>> R-devel at r-project.org mailing list
    >> > > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> > > >> >>>>>>
    >> > > >> >>>>>>
    >> > > >> >>>>>
    >> > > >> >>>>
    >> > > >> >>>>
    >> > > >> >> Index: src/library/base/R/merge.R
    >> > > >> >>> ============================================================
    >> > =======
    >> > > >> >>> --- src/library/base/R/merge.R  (revision 74264)
    >> > > >> >>> +++ src/library/base/R/merge.R  (working copy)
    >> > > >> >>> @@ -157,6 +157,15 @@
    >> > > >> >>>           }
    >> > > >> >>>             if(has.common.nms) names(y) <- nm.y
    >> > > >> >>> +        ## If by.x %in% names(y) then duplicate column names
    >> > still
    >> > > >> >>> arise,
    >> > > >> >>> +        ## apply suffixes to these
    >> > > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
    >> > > >> >>> +        if(length(dupe.keyx)) {
    >> > > >> >>> +          if(nzchar(suffixes[1L]))
    >> > > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
    >> > > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
    >> > > >> >>> +          if(nzchar(suffixes[2L]))
    >> > > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> > > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
    >> > > >> >>> +        }
    >> > > >> >>>           nm <- c(names(x), names(y))
    >> > > >> >>>           if(any(d <- duplicated(nm)))
    >> > > >> >>>               if(sum(d) > 1L)
    >> > > >> >>>
    >> > > >> >>
    >> > > >> >> ______________________________________________
    >> > > >> >> R-devel at r-project.org mailing list
    >> > > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> > > >> >>
    >> > > >> >>
    >> > > >> >
    >> > > >>
    >> > > >>         [[alternative HTML version deleted]]
    >> > > >>
    >> > > >> ______________________________________________
    >> > > >> R-devel at r-project.org mailing list
    >> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> > > >>
    >> > > >
    >> > > >
    >> > > >
    >> > > > --
    >> > > > Gabriel Becker, PhD
    >> > > > Scientist (Bioinformatics)
    >> > > > Genentech Research
    >> > > >
    >> >
    >> > > Index: src/library/base/R/merge.R
    >> > > ===================================================================
    >> > > --- src/library/base/R/merge.R        (revision 74264)
    >> > > +++ src/library/base/R/merge.R        (working copy)
    >> > > @@ -157,6 +157,15 @@
    >> > >          }
    >> > >
    >> > >          if(has.common.nms) names(y) <- nm.y
    >> > > +        ## If by.x %in% names(y) then duplicate column names still
    >> > arise,
    >> > > +        ## apply suffixes to these
    >> > > +        dupe.keyx <- intersect(nm.by, names(y))
    >> > > +        if(length(dupe.keyx)) {
    >> > > +          if(nzchar(suffixes[1L]))
    >> > > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
    >> > paste(dupe.keyx, suffixes[1L], sep="")
    >> > > +          if(nzchar(suffixes[2L]))
    >> > > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> > paste(dupe.keyx, suffixes[2L], sep="")
    >> > > +        }
    >> > >          nm <- c(names(x), names(y))
    >> > >          if(any(d <- duplicated(nm)))
    >> > >              if(sum(d) > 1L)
    >> >
    >> > > ______________________________________________
    >> > > R-devel at r-project.org mailing list
    >> > > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >
    >> >

    >> Index: src/library/base/R/merge.R
    >> ===================================================================
    >> --- src/library/base/R/merge.R        (revision 74280)
    >> +++ src/library/base/R/merge.R        (working copy)
    >> @@ -157,6 +157,14 @@
    >> }
    >> 
    >> if(has.common.nms) names(y) <- nm.y
    >> +        ## If by.x %in% names(y) then duplicate column names still arise,
    >> +        ## apply suffixes to just y - this keeps backwards compatibility
    >> +        ## when referring to by.x in the resulting data.frame
    >> +        dupe.keyx <- intersect(nm.by, names(y))
    >> +        if(length(dupe.keyx)) {
    >> +          if(nzchar(suffixes[2L]))
    >> +            names(y)[match(dupe.keyx, names(y), 0L)] <- paste(dupe.keyx,
    > suffixes[2L], sep="")
    >> +        }
    >> nm <- c(names(x), names(y))
    >> if(any(d <- duplicated(nm)))
    >> if(sum(d) > 1L)

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Thu Feb 22 12:39:31 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 22 Feb 2018 12:39:31 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <CALEXWq1=VDs2BQ2CEMJKwrtmZNCG1Scf2EfgGn91xTdH9ibGVA@mail.gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
 <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
 <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>
 <CALEXWq1=VDs2BQ2CEMJKwrtmZNCG1Scf2EfgGn91xTdH9ibGVA@mail.gmail.com>
Message-ID: <e65eec07-9e6d-4cbb-5337-bd559b6cde03@gmail.com>

On 02/22/2018 12:07 PM, I?aki ?car wrote:
> 2018-02-22 10:29 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>> The example is invoking NextMethod via an anonymous function, which is not
>> allowed (see documentation for NextMethod).
> Thanks for your response. I definitely missed that bit.
>
>> Normally one gets a runtime
>> error "'NextMethod' called from an anonymous function", but not here as the
>> anonymous function is called via do.call. I will fix so that there is a
>> runtime error in this case as well, thanks for uncovering this problem.
> Then I did well chosing this list! Please also note that you could
> take that anonymous function out of the method and name it, and the
> behaviour would be the same. So maybe this case should issue an error
> too.
I am not sure I understand how, but if you find a way to bypass the new 
check for an anonymous function (I intend to commit tomorrow), I will be 
happy to have a look if you provide a reproducible example.
>> I don't think there is a way to replace (unnamed) arguments in dots for
>> NextMethod.
> That's a pity. IMHO, it should be some mechanism for that, but dots
> are special in inscrutable ways.
>
> Anyway, for anyone insterested, I found a workaround:
>
> https://github.com/Enchufa2/dispatchS3dots#workaround
Even though technically this won't be too hard, I don't think NextMethod 
should be made any more complex than it is now. There should always be a 
way to implement special dispatch scenarios in R and your workaround 
shows it is possible specifically in your scenario.

Tomas

>> Tomas
>>
>>
> I?aki


From i.ucar86 at gmail.com  Thu Feb 22 14:31:53 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 22 Feb 2018 14:31:53 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <e65eec07-9e6d-4cbb-5337-bd559b6cde03@gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
 <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
 <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>
 <CALEXWq1=VDs2BQ2CEMJKwrtmZNCG1Scf2EfgGn91xTdH9ibGVA@mail.gmail.com>
 <e65eec07-9e6d-4cbb-5337-bd559b6cde03@gmail.com>
Message-ID: <CALEXWq2K738k8C3eDJBPdtPpixW3rr+NpssSnx+7dM2VnkOo_Q@mail.gmail.com>

2018-02-22 12:39 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
> On 02/22/2018 12:07 PM, I?aki ?car wrote:
>>
>> 2018-02-22 10:29 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>>>
>>> The example is invoking NextMethod via an anonymous function, which is
>>> not
>>> allowed (see documentation for NextMethod).
>>
>> Thanks for your response. I definitely missed that bit.
>>
>>> Normally one gets a runtime
>>> error "'NextMethod' called from an anonymous function", but not here as
>>> the
>>> anonymous function is called via do.call. I will fix so that there is a
>>> runtime error in this case as well, thanks for uncovering this problem.
>>
>> Then I did well chosing this list! Please also note that you could
>> take that anonymous function out of the method and name it, and the
>> behaviour would be the same. So maybe this case should issue an error
>> too.
>
> I am not sure I understand how, but if you find a way to bypass the new
> check for an anonymous function (I intend to commit tomorrow), I will be
> happy to have a look if you provide a reproducible example.

I meant with a named function inside do.call, instead of an anonymous
one. For example:

c.foo <- function(..., recursive=FALSE) {
  message("calling c.foo...")
  dots <- list(...)
  # inspect and modify dots; for example:
  if (length(dots > 1))
    dots[[2]] <- 2
  do.call(
    c.foo.proxy,
    c(dots, recursive=recursive)
  )
}

c.foo.proxy <- function(..., recursive=FALSE)
structure(NextMethod("c"), class="foo")

Right now, the effect of the code above is the same as with the
anonymous function. Shouldn't it issue a similar error then?

>>>
>>> I don't think there is a way to replace (unnamed) arguments in dots for
>>> NextMethod.
>>
>> That's a pity. IMHO, it should be some mechanism for that, but dots
>> are special in inscrutable ways.
>>
>> Anyway, for anyone insterested, I found a workaround:
>>
>> https://github.com/Enchufa2/dispatchS3dots#workaround
>
> Even though technically this won't be too hard, I don't think NextMethod
> should be made any more complex than it is now. There should always be a way
> to implement special dispatch scenarios in R and your workaround shows it is
> possible specifically in your scenario.

My only concern about this workaround is that it triggers the dispatch
stack again from the beginning of the class hierarchy, which seems not
very elegant nor efficient.

>
> Tomas
>

I?aki


From tomas.kalibera at gmail.com  Thu Feb 22 14:54:40 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 22 Feb 2018 14:54:40 +0100
Subject: [Rd] How to modify dots and dispatch NextMethod
In-Reply-To: <CALEXWq2K738k8C3eDJBPdtPpixW3rr+NpssSnx+7dM2VnkOo_Q@mail.gmail.com>
References: <CALEXWq2tL2qxLee_1MhRQcqmeUXe5BfnxCjZQM5RTkB7ccD7PA@mail.gmail.com>
 <CALEXWq1eSvjMxjsu9D+he3FYrpJhyMv9mhmWzVeyk7g8bbB5EQ@mail.gmail.com>
 <8217f2fc-b660-c8bc-406d-22a1d8c4602a@gmail.com>
 <CALEXWq1=VDs2BQ2CEMJKwrtmZNCG1Scf2EfgGn91xTdH9ibGVA@mail.gmail.com>
 <e65eec07-9e6d-4cbb-5337-bd559b6cde03@gmail.com>
 <CALEXWq2K738k8C3eDJBPdtPpixW3rr+NpssSnx+7dM2VnkOo_Q@mail.gmail.com>
Message-ID: <535b6983-125c-2dcf-359a-764643b72366@gmail.com>

On 02/22/2018 02:31 PM, I?aki ?car wrote:
> 2018-02-22 12:39 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>> On 02/22/2018 12:07 PM, I?aki ?car wrote:
>>> 2018-02-22 10:29 GMT+01:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>>>> The example is invoking NextMethod via an anonymous function, which is
>>>> not
>>>> allowed (see documentation for NextMethod).
>>> Thanks for your response. I definitely missed that bit.
>>>
>>>> Normally one gets a runtime
>>>> error "'NextMethod' called from an anonymous function", but not here as
>>>> the
>>>> anonymous function is called via do.call. I will fix so that there is a
>>>> runtime error in this case as well, thanks for uncovering this problem.
>>> Then I did well chosing this list! Please also note that you could
>>> take that anonymous function out of the method and name it, and the
>>> behaviour would be the same. So maybe this case should issue an error
>>> too.
>> I am not sure I understand how, but if you find a way to bypass the new
>> check for an anonymous function (I intend to commit tomorrow), I will be
>> happy to have a look if you provide a reproducible example.
> I meant with a named function inside do.call, instead of an anonymous
> one. For example:
>
> c.foo <- function(..., recursive=FALSE) {
>    message("calling c.foo...")
>    dots <- list(...)
>    # inspect and modify dots; for example:
>    if (length(dots > 1))
>      dots[[2]] <- 2
>    do.call(
>      c.foo.proxy,
>      c(dots, recursive=recursive)
>    )
> }
>
> c.foo.proxy <- function(..., recursive=FALSE)
> structure(NextMethod("c"), class="foo")
>
> Right now, the effect of the code above is the same as with the
> anonymous function. Shouldn't it issue a similar error then?
Yes, it will also result in runtime error after the change is committed:

calling c.foo...
Error in NextMethod("c") : 'NextMethod' called from an anonymous function
>>>> I don't think there is a way to replace (unnamed) arguments in dots for
>>>> NextMethod.
>>> That's a pity. IMHO, it should be some mechanism for that, but dots
>>> are special in inscrutable ways.
>>>
>>> Anyway, for anyone insterested, I found a workaround:
>>>
>>> https://github.com/Enchufa2/dispatchS3dots#workaround
>> Even though technically this won't be too hard, I don't think NextMethod
>> should be made any more complex than it is now. There should always be a way
>> to implement special dispatch scenarios in R and your workaround shows it is
>> possible specifically in your scenario.
> My only concern about this workaround is that it triggers the dispatch
> stack again from the beginning of the class hierarchy, which seems not
> very elegant nor efficient.
There may be a more elegant way, but that'd be a question for R-help and 
it might be worth giving a broader context for what you want to achieve. 
Also please note that S3 dispatch is done on the first argument, and c() 
gives no special meaning to its first argument, what if e.g. the second 
argument is of class "foo" but the first is not - is S3/NextMethod 
really a good fit here?

Tomas

>
>> Tomas
>>
> I?aki


From s.ritchie73 at gmail.com  Fri Feb 23 02:32:41 2018
From: s.ritchie73 at gmail.com (Scott Ritchie)
Date: Fri, 23 Feb 2018 12:32:41 +1100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <23182.43548.14172.267191@stat.math.ethz.ch>
References: <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
 <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
 <20180221031546.GQ32564@ofb.net>
 <CADwqtCPTRPfz8xuAiCQ0ccnDc8rbaSdGjTBCcxM=Ef2MEzvj1w@mail.gmail.com>
 <CADwqtCP84q+JyYUGQ_DSBz9eAVCwTfoz6jt_r_8xiAT5HVnYGQ@mail.gmail.com>
 <23182.43548.14172.267191@stat.math.ethz.ch>
Message-ID: <CAO1VBV1-DtKPUvWLgPywsQ71aibr__OZ0vWUp3_dbpvisE8+Zw@mail.gmail.com>

Thanks Martin!

Can you clarify the functionality of the 'no.dups' argument so I can change
my patch to `data.table:::merge.data.table` accordingly?

- When `no.dups=TRUE` will the suffix to the by.x column name? Or will it
take the functionality of the second functionality where only the column in
y has the suffix added?
- When `no.dups=FALSE` will the output be the same as it currently (no
suffix added to either column)? Or will add the suffix to the column in y?

Best,

Scott

On 22 February 2018 at 22:31, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Gabriel Becker <gmbecker at ucdavis.edu>
> >>>>>     on Wed, 21 Feb 2018 07:11:44 -0800 writes:
>
>     > Hi all,
>     > For the record this approach isnt 100% backwards compatible, because
>     > names(mergeddf) will e incompatibly different. Thatx why i claimed
>     > bakcwards compatable-ish
>
> exactly.
>
>     > That said its still worth considering imho because of the reasons
> stated
>     > (and honestly one particular simple reading of the docs might
> suggest that
>     > this was thr intended behavior all along). Im not a member of Rcore
> through
>     > so i cant do said considering myself.
>
> I agree with Scott, Frederik and you that this changes seems
> worth considering.
> As Duncan Murdoch has mentioned, this alone may not be
> sufficient.
>
> In addition to your proposed patch (which I have simplified, not
> using intersection() but working with underlying  match()
> directly), it is little work to introduce an extra argument, I'm
> calling  'no.dups = TRUE'  which when set to false would mirror
> current R's behavior... and documenting it, then also documents the
> new behavior (to some extent).
>
> My plan is to commit it soonish ;-)
> Martin
>
>     > Best,
>     > ~G
>
>     > On Feb 20, 2018 7:15 PM, <frederik at ofb.net> wrote:
>
>     > Hi Scott,
>
>     > I tried the new patch and can confirm that it has the advertised
>     > behavior on a couple of test cases. I think it makes sense to apply
>     > it, because any existing code which refers to a second duplicate
>     > data.frame column by name is already broken, while if the reference
> is
>     > by numerical index then changing the column name shouldn't break it.
>
>     > I don't know if you need to update the documentation as part of your
>     > patch, or if whoever applies it would be happy to do that. Somebody
>     > from R core want to weigh in on this?
>
>     > I attach a file with the test example from your original email as
> well
>     > as a second test case I added with two "by" columns.
>
>     > Thanks,
>
>     > Frederick
>
>     > On Wed, Feb 21, 2018 at 10:06:21AM +1100, Scott Ritchie wrote:
>     >> Hi Frederick,
>     >>
>     >> It looks like I didn't overwrite the patch.diff file after the last
> edits.
>     >> Here's the correct patch (attached and copied below):
>     >>
>     >> Index: src/library/base/R/merge.R
>     >> ===================================================================
>     >> --- src/library/base/R/merge.R (revision 74280)
>     >> +++ src/library/base/R/merge.R (working copy)
>     >> @@ -157,6 +157,14 @@
>     >> }
>     >>
>     >> if(has.common.nms) names(y) <- nm.y
>     >> +        ## If by.x %in% names(y) then duplicate column names still
> arise,
>     >> +        ## apply suffixes to just y - this keeps backwards
> compatibility
>     >> +        ## when referring to by.x in the resulting data.frame
>     >> +        dupe.keyx <- intersect(nm.by, names(y))
>     >> +        if(length(dupe.keyx)) {
>     >> +          if(nzchar(suffixes[2L]))
>     >> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> paste(dupe.keyx,
>     >> suffixes[2L], sep="")
>     >> +        }
>     >> nm <- c(names(x), names(y))
>     >> if(any(d <- duplicated(nm)))
>     >> if(sum(d) > 1L)
>     >>
>     >> Best,
>     >>
>     >> Scott
>     >>
>     >> On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:
>     >>
>     >> > Hi Scott,
>     >> >
>     >> > I think that's a good idea and I tried your patch on my copy of
> the
>     >> > repository. But it looks to me like the recent patch is identical
> to
>     >> > the previous one, can you confirm this?
>     >> >
>     >> > Frederick
>     >> >
>     >> > On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
>     >> > > Thanks Gabriel,
>     >> > >
>     >> > > I think your suggested approach is 100% backwards compatible
>     >> > >
>     >> > > Currently in the case of duplicate column names only the first
> can be
>     >> > > indexed by its name. This will always be the column appearing
> in by.x,
>     >> > > meaning the column in y with the same name cannot be accessed.
>     > Appending
>     >> > > ".y" (suffixes[2L]) to this column means it can now be
> accessed, while
>     >> > > keeping the current behaviour of making the key columns always
>     > accessible
>     >> > > by using the names provided to by.x.
>     >> > >
>     >> > > I've attached a new patch that has this behaviour.
>     >> > >
>     >> > > Best,
>     >> > >
>     >> > > Scott
>     >> > >
>     >> > > On 19 February 2018 at 05:08, Gabriel Becker <
> gmbecker at ucdavis.edu>
>     >> > wrote:
>     >> > >
>     >> > > > It seems like there is a way that is backwards compatible-ish
> in the
>     >> > sense
>     >> > > > mentioned and still has the (arguably, but a good argument I
> think)
>     >> > better
>     >> > > > behavior:
>     >> > > >
>     >> > > > if by.x is 'name', (AND by.y is not also 'name'), then x's
> 'name'
>     >> > column
>     >> > > > is called name and y's 'name' column (not used int he merge)
> is
>     >> > changed to
>     >> > > > name.y.
>     >> > > >
>     >> > > > Now of course this would still change output, but it would
> change
>     > it to
>     >> > > > something I think would be better, while retaining the 'merge
>     > columns
>     >> > > > retain their exact names' mechanic as documented.
>     >> > > >
>     >> > > > ~G
>     >> > > >
>     >> > > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <
>     > s.ritchie73 at gmail.com>
>     >> > > > wrote:
>     >> > > >
>     >> > > >> Thanks Duncan and Frederick,
>     >> > > >>
>     >> > > >> I suspected as much - there doesn't appear to be any reason
> why
>     >> > conflicts
>     >> > > >> between by.x and names(y) shouldn't and cannot be checked,
> but I
>     > can
>     >> > see
>     >> > > >> how this might be more trouble than its worth given it
> potentially
>     > may
>     >> > > >> break downstream packages (i.e. any cases where this occurs
> but
>     > they
>     >> > > >> expect
>     >> > > >> the name of the key column(s) to remain the same).
>     >> > > >>
>     >> > > >> Best,
>     >> > > >>
>     >> > > >> Scott
>     >> > > >>
>     >> > > >> On 18 February 2018 at 11:48, Duncan Murdoch <
>     >> > murdoch.duncan at gmail.com>
>     >> > > >> wrote:
>     >> > > >>
>     >> > > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
>     >> > > >> >
>     >> > > >> >> Hi Scott,
>     >> > > >> >>
>     >> > > >> >> Thanks for the patch. I'm not really involved in R
> development;
>     > it
>     >> > > >> >> will be up to someone in the R core team to apply it. I
> would
>     >> > hazard
>     >> > > >> >> to say that even if correct (I haven't checked), it will
> not be
>     >> > > >> >> applied because the change might break existing code. For
>     > example
>     >> > it
>     >> > > >> >> seems like reasonable code might easily assume that a
> column
>     > with
>     >> > the
>     >> > > >> >> same name as "by.x" exists in the output of 'merge'.
> That's
>     > just my
>     >> > > >> >> best guess... I don't participate on here often.
>     >> > > >> >>
>     >> > > >> >
>     >> > > >> >
>     >> > > >> > I think you're right.  If I were still a member of R Core,
> I
>     > would
>     >> > want
>     >> > > >> to
>     >> > > >> > test this against all packages on CRAN and Bioconductor,
> and
>     > since
>     >> > that
>     >> > > >> > test takes a couple of days to run on my laptop, I'd
> probably
>     > never
>     >> > get
>     >> > > >> > around to it.
>     >> > > >> >
>     >> > > >> > There are lots of cases where "I would have done that
>     > differently",
>     >> > but
>     >> > > >> > most of them are far too much trouble to change now that R
> is
>     > more
>     >> > than
>     >> > > >> 20
>     >> > > >> > years old.  And in many cases it will turn out that the
> way R
>     > does
>     >> > it
>     >> > > >> > actually does make more sense than the way I would have
> done it.
>     >> > > >> >
>     >> > > >> > Duncan Murdoch
>     >> > > >> >
>     >> > > >> >
>     >> > > >> >
>     >> > > >> >> Cheers,
>     >> > > >> >>
>     >> > > >> >> Frederick
>     >> > > >> >>
>     >> > > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie
> wrote:
>     >> > > >> >>
>     >> > > >> >>> The attached patch.diff will make merge.data.frame()
> append the
>     >> > > >> suffixes
>     >> > > >> >>> to
>     >> > > >> >>> columns with common names between by.x and names(y).
>     >> > > >> >>>
>     >> > > >> >>> Best,
>     >> > > >> >>>
>     >> > > >> >>> Scott Ritchie
>     >> > > >> >>>
>     >> > > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
>     >> > s.ritchie73 at gmail.com>
>     >> > > >> >>> wrote:
>     >> > > >> >>>
>     >> > > >> >>> Hi Frederick,
>     >> > > >> >>>>
>     >> > > >> >>>> I would expect that any duplicate names in the resulting
>     >> > data.frame
>     >> > > >> >>>> would
>     >> > > >> >>>> have the suffixes appended to them, regardless of
> whether or
>     > not
>     >> > they
>     >> > > >> >>>> are
>     >> > > >> >>>> used as the join key. So in my example I would expect
>     > "names.x"
>     >> > and
>     >> > > >> >>>> "names.y" to indicate their source data.frame.
>     >> > > >> >>>>
>     >> > > >> >>>> While careful reading of the documentation reveals this
> is not
>     >> > the
>     >> > > >> >>>> case, I
>     >> > > >> >>>> would argue the intent of the suffixes functionality
> should
>     >> > equally
>     >> > > >> be
>     >> > > >> >>>> applied to this type of case.
>     >> > > >> >>>>
>     >> > > >> >>>> If you agree this would be useful, I'm happy to write a
> patch
>     > for
>     >> > > >> >>>> merge.data.frame that will add suffixes in this case - I
>     > intend
>     >> > to do
>     >> > > >> >>>> the
>     >> > > >> >>>> same for merge.data.table in the data.table package
> where I
>     >> > initially
>     >> > > >> >>>> encountered the edge case.
>     >> > > >> >>>>
>     >> > > >> >>>> Best,
>     >> > > >> >>>>
>     >> > > >> >>>> Scott
>     >> > > >> >>>>
>     >> > > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
>     >> > > >> >>>>
>     >> > > >> >>>> Hi Scott,
>     >> > > >> >>>>>
>     >> > > >> >>>>> It seems like reasonable behavior to me. What result
> would
>     > you
>     >> > > >> expect?
>     >> > > >> >>>>> That the second "name" should be called "name.y"?
>     >> > > >> >>>>>
>     >> > > >> >>>>> The "merge" documentation says:
>     >> > > >> >>>>>
>     >> > > >> >>>>>      If the columns in the data frames not used in
> merging
>     > have
>     >> > any
>     >> > > >> >>>>>      common names, these have ?suffixes? (?".x"? and
> ?".y"?
>     > by
>     >> > > >> default)
>     >> > > >> >>>>>      appended to try to make the names of the result
> unique.
>     >> > > >> >>>>>
>     >> > > >> >>>>> Since the first "name" column was used in merging,
> leaving
>     > both
>     >> > > >> >>>>> without a suffix seems consistent with the
> documentation...
>     >> > > >> >>>>>
>     >> > > >> >>>>> Frederick
>     >> > > >> >>>>>
>     >> > > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie
>     > wrote:
>     >> > > >> >>>>>
>     >> > > >> >>>>>> Hi,
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> I was unable to find a bug report for this with a
> cursory
>     >> > search,
>     >> > > >> but
>     >> > > >> >>>>>>
>     >> > > >> >>>>> would
>     >> > > >> >>>>>
>     >> > > >> >>>>>> like clarification if this is intended or unavoidable
>     >> > behaviour:
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> ```{r}
>     >> > > >> >>>>>> # Create example data.frames
>     >> > > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin",
> "Lex"),
>     >> > > >> >>>>>>                        sex=c("F", "M", "F", "M"),
>     >> > > >> >>>>>>                        age=c(41, 43, 36, 51))
>     >> > > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max",
> "Qin"),
>     >> > > >> >>>>>>                         name=c("Oliver", "Sebastian",
>     >> > "Kai-lee"),
>     >> > > >> >>>>>>                         sex=c("M", "M", "F"),
>     >> > > >> >>>>>>                         age=c(5,8,7))
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> # Merge() creates a duplicated "name" column:
>     >> > > >> >>>>>> merge(parents, children, by.x = "name", by.y =
> "parent")
>     >> > > >> >>>>>> ```
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> Output:
>     >> > > >> >>>>>> ```
>     >> > > >> >>>>>>     name sex.x age.x      name sex.y age.y
>     >> > > >> >>>>>> 1   Max     M    43 Sebastian     M     8
>     >> > > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
>     >> > > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
>     >> > > >> >>>>>> Warning message:
>     >> > > >> >>>>>> In merge.data.frame(parents, children, by.x = "name",
> by.y =
>     >> > > >> >>>>>> "parent") :
>     >> > > >> >>>>>>    column name ?name? is duplicated in the result
>     >> > > >> >>>>>> ```
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> Kind Regards,
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> Scott Ritchie
>     >> > > >> >>>>>>
>     >> > > >> >>>>>>        [[alternative HTML version deleted]]
>     >> > > >> >>>>>>
>     >> > > >> >>>>>> ______________________________________________
>     >> > > >> >>>>>> R-devel at r-project.org mailing list
>     >> > > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> > > >> >>>>>>
>     >> > > >> >>>>>>
>     >> > > >> >>>>>
>     >> > > >> >>>>
>     >> > > >> >>>>
>     >> > > >> >> Index: src/library/base/R/merge.R
>     >> > > >> >>> ==============================
> ==============================
>     >> > =======
>     >> > > >> >>> --- src/library/base/R/merge.R  (revision 74264)
>     >> > > >> >>> +++ src/library/base/R/merge.R  (working copy)
>     >> > > >> >>> @@ -157,6 +157,15 @@
>     >> > > >> >>>           }
>     >> > > >> >>>             if(has.common.nms) names(y) <- nm.y
>     >> > > >> >>> +        ## If by.x %in% names(y) then duplicate column
> names
>     >> > still
>     >> > > >> >>> arise,
>     >> > > >> >>> +        ## apply suffixes to these
>     >> > > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
>     >> > > >> >>> +        if(length(dupe.keyx)) {
>     >> > > >> >>> +          if(nzchar(suffixes[1L]))
>     >> > > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
>     >> > > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
>     >> > > >> >>> +          if(nzchar(suffixes[2L]))
>     >> > > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
>     >> > > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
>     >> > > >> >>> +        }
>     >> > > >> >>>           nm <- c(names(x), names(y))
>     >> > > >> >>>           if(any(d <- duplicated(nm)))
>     >> > > >> >>>               if(sum(d) > 1L)
>     >> > > >> >>>
>     >> > > >> >>
>     >> > > >> >> ______________________________________________
>     >> > > >> >> R-devel at r-project.org mailing list
>     >> > > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> > > >> >>
>     >> > > >> >>
>     >> > > >> >
>     >> > > >>
>     >> > > >>         [[alternative HTML version deleted]]
>     >> > > >>
>     >> > > >> ______________________________________________
>     >> > > >> R-devel at r-project.org mailing list
>     >> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> > > >>
>     >> > > >
>     >> > > >
>     >> > > >
>     >> > > > --
>     >> > > > Gabriel Becker, PhD
>     >> > > > Scientist (Bioinformatics)
>     >> > > > Genentech Research
>     >> > > >
>     >> >
>     >> > > Index: src/library/base/R/merge.R
>     >> > > ============================================================
> =======
>     >> > > --- src/library/base/R/merge.R        (revision 74264)
>     >> > > +++ src/library/base/R/merge.R        (working copy)
>     >> > > @@ -157,6 +157,15 @@
>     >> > >          }
>     >> > >
>     >> > >          if(has.common.nms) names(y) <- nm.y
>     >> > > +        ## If by.x %in% names(y) then duplicate column names
> still
>     >> > arise,
>     >> > > +        ## apply suffixes to these
>     >> > > +        dupe.keyx <- intersect(nm.by, names(y))
>     >> > > +        if(length(dupe.keyx)) {
>     >> > > +          if(nzchar(suffixes[1L]))
>     >> > > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
>     >> > paste(dupe.keyx, suffixes[1L], sep="")
>     >> > > +          if(nzchar(suffixes[2L]))
>     >> > > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
>     >> > paste(dupe.keyx, suffixes[2L], sep="")
>     >> > > +        }
>     >> > >          nm <- c(names(x), names(y))
>     >> > >          if(any(d <- duplicated(nm)))
>     >> > >              if(sum(d) > 1L)
>     >> >
>     >> > > ______________________________________________
>     >> > > R-devel at r-project.org mailing list
>     >> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> >
>     >> >
>
>     >> Index: src/library/base/R/merge.R
>     >> ===================================================================
>     >> --- src/library/base/R/merge.R        (revision 74280)
>     >> +++ src/library/base/R/merge.R        (working copy)
>     >> @@ -157,6 +157,14 @@
>     >> }
>     >>
>     >> if(has.common.nms) names(y) <- nm.y
>     >> +        ## If by.x %in% names(y) then duplicate column names still
> arise,
>     >> +        ## apply suffixes to just y - this keeps backwards
> compatibility
>     >> +        ## when referring to by.x in the resulting data.frame
>     >> +        dupe.keyx <- intersect(nm.by, names(y))
>     >> +        if(length(dupe.keyx)) {
>     >> +          if(nzchar(suffixes[2L]))
>     >> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
> paste(dupe.keyx,
>     > suffixes[2L], sep="")
>     >> +        }
>     >> nm <- c(names(x), names(y))
>     >> if(any(d <- duplicated(nm)))
>     >> if(sum(d) > 1L)
>
>     > [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From mohit.kumar at ashoka.edu.in  Fri Feb 23 06:01:30 2018
From: mohit.kumar at ashoka.edu.in (Mohit Kumar)
Date: Fri, 23 Feb 2018 10:31:30 +0530
Subject: [Rd] Bug in installing rgdal
Message-ID: <CAEjbkt0ZEFFfhg2aoVUO6_1AduWyGXytc1C9HTqR=wATVhUnxQ@mail.gmail.com>

*@*








*BLAS: /usr/lib/libblas/libblas.so.3.6.0LAPACK:
/usr/lib/lapack/liblapack.so.3.6.0locale: [1] LC_CTYPE=en_IN.UTF-8
LC_NUMERIC=C               LC_TIME=en_IN.UTF-8        [4]
LC_COLLATE=en_IN.UTF-8     LC_MONETARY=en_IN.UTF-8
LC_MESSAGES=en_IN.UTF-8    [7] LC_PAPER=en_IN.UTF-8
LC_NAME=C                  LC_ADDRESS=C              [10]
LC_TELEPHONE=C             LC_MEASUREMENT=en_IN.UTF-8
LC_IDENTIFICATION=C       *

Can someone please guide me further?

Regards,

-- 
Mohit Kumar
Research Engineer in Data Science
Trivedi Center for Political Data
Ashoka University
+91-9703840175

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Feb 23 10:19:48 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Feb 2018 09:19:48 +0000
Subject: [Rd] Bug in installing rgdal
In-Reply-To: <CAEjbkt0ZEFFfhg2aoVUO6_1AduWyGXytc1C9HTqR=wATVhUnxQ@mail.gmail.com>
References: <CAEjbkt0ZEFFfhg2aoVUO6_1AduWyGXytc1C9HTqR=wATVhUnxQ@mail.gmail.com>
Message-ID: <BDBEEBC63E3A2C25.7e8c84ae-f519-4b91-9327-a51f1bb06809@mail.outlook.com>

Wrong list. Try R-sig-geo, if you do, confirm that you read the readme in the source package since you are installing from source, and include relevant information from configure. Almost certainly this tells you that you have not installed the devel rpms or debs for gdal or proj.

Roger Bivand
Norwegian School of Economics
Bergen, Norway



Fra: Mohit Kumar
Sendt: fredag 23. februar, 06.01
Emne: Bug in installing rgdal
Til: r-devel at r-project.org, tkeitt at gmail.com, Roger Bivand


@
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_IN.UTF-8       LC_NUMERIC=C               LC_TIME=en_IN.UTF-8
 [4] LC_COLLATE=en_IN.UTF-8     LC_MONETARY=en_IN.UTF-8    LC_MESSAGES=en_IN.UTF-8
 [7] LC_PAPER=en_IN.UTF-8       LC_NAME=C                  LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_IN.UTF-8 LC_IDENTIFICATION=C


Can someone please guide me further?

Regards,

--
Mohit Kumar
Research Engineer in Data Science
Trivedi Center for Political Data
Ashoka University
+91-9703840175



	[[alternative HTML version deleted]]


From Jon.SKOIEN at ec.europa.eu  Fri Feb 23 10:28:02 2018
From: Jon.SKOIEN at ec.europa.eu (Jon.SKOIEN at ec.europa.eu)
Date: Fri, 23 Feb 2018 09:28:02 +0000
Subject: [Rd] Problem with R_registerRoutines
Message-ID: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>

Dear list,

I am trying to update a package to pass the CRAN-checks. 
But I am struggling with the following note:

File 'psgp/libs/i386/psgp.dll':
  Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
File 'psgp/libs/x64/psgp.dll':
  Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'

It is good practice to register native routines and to disable symbol
search.


I did already run:
tools::package_native_routine_registration_skeleton(".")
This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.

I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem? 

Thanks,
Jon












From jeroenooms at gmail.com  Fri Feb 23 13:36:03 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Fri, 23 Feb 2018 13:36:03 +0100
Subject: [Rd] Problem with R_registerRoutines
In-Reply-To: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>
References: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>
Message-ID: <CABFfbXtOKwVySVXrcg0-Rkgtx9Udm-dm3TRhKLqV2Ou7z5Keew@mail.gmail.com>

On Windows this warning may be a false positive if R cannot find
"objdump.exe" which is required for this check. I think this is
actually a bug in R because it should be looking for "objdump.exe"
inside BINPREF (where gcc is) rather than on the PATH.

Can you check if you get the same warning if you upload the package to
https://win-builder.r-project.org ?






On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
> Dear list,
>
> I am trying to update a package to pass the CRAN-checks.
> But I am struggling with the following note:
>
> File 'psgp/libs/i386/psgp.dll':
>   Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
> File 'psgp/libs/x64/psgp.dll':
>   Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
>
> It is good practice to register native routines and to disable symbol
> search.
>
>
> I did already run:
> tools::package_native_routine_registration_skeleton(".")
> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
>
> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
>
> Thanks,
> Jon
>
>
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Feb 23 15:03:09 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Feb 2018 15:03:09 +0100
Subject: [Rd] 
 Duplicate column names created by base::merge() when by.x has
 the same name as a column in y
In-Reply-To: <CAO1VBV1-DtKPUvWLgPywsQ71aibr__OZ0vWUp3_dbpvisE8+Zw@mail.gmail.com>
References: <20180216165344.GB32564@ofb.net>
 <CAO1VBV3NqJEew4jpAfZrWGuW4WtjtkBbDnjToB4NEgdy8DUCZA@mail.gmail.com>
 <CAO1VBV39-MKzR7OoV+GuY+wCf-etakbpsi=Lchwm80_14rU07g@mail.gmail.com>
 <20180217233640.GG32564@ofb.net>
 <ab784c23-f231-330a-c305-50130770e291@gmail.com>
 <CAO1VBV3VZkwL6XsWuUzNiQq0vGAgcXR1nm-CUdWYiq+XyUa1Dg@mail.gmail.com>
 <CADwqtCPyLv42V1v=Azq0cGyJVWYGpOnKPhoj48mWOBE5=4YQug@mail.gmail.com>
 <CAO1VBV15MqcR47v6bEct=am1GbCeOpso_NDgXB=xf0FBBty7ng@mail.gmail.com>
 <20180220212351.GP32564@ofb.net>
 <CAO1VBV0bfx3bWmCR+Wo5+MrnUN9mo_WKv80EvOD2q0b_3y8Ofw@mail.gmail.com>
 <20180221031546.GQ32564@ofb.net>
 <CADwqtCPTRPfz8xuAiCQ0ccnDc8rbaSdGjTBCcxM=Ef2MEzvj1w@mail.gmail.com>
 <CADwqtCP84q+JyYUGQ_DSBz9eAVCwTfoz6jt_r_8xiAT5HVnYGQ@mail.gmail.com>
 <23182.43548.14172.267191@stat.math.ethz.ch>
 <CAO1VBV1-DtKPUvWLgPywsQ71aibr__OZ0vWUp3_dbpvisE8+Zw@mail.gmail.com>
Message-ID: <23184.7965.916647.842009@stat.math.ethz.ch>

>>>>> Scott Ritchie <s.ritchie73 at gmail.com>
>>>>>     on Fri, 23 Feb 2018 12:32:41 +1100 writes:

    > Thanks Martin!
    > Can you clarify the functionality of the 'no.dups' argument so I can change
    > my patch to `data.table:::merge.data.table` accordingly?

    > - When `no.dups=TRUE` will the suffix to the by.x column name? Or will it
    > take the functionality of the second functionality where only the column in
    > y has the suffix added?
    > - When `no.dups=FALSE` will the output be the same as it currently (no
    > suffix added to either column)? Or will add the suffix to the column in y?

I had started from your patch... and worked from there.
So, there's no need (and use) to provide another one.

I also needed to update the man page, add a regression test, add
an entry to NEWS.Rd ...

Just wait until I commit..
Martin




    > Best,

    > Scott

    > On 22 February 2018 at 22:31, Martin Maechler <maechler at stat.math.ethz.ch>
    > wrote:

    >> >>>>> Gabriel Becker <gmbecker at ucdavis.edu>
    >> >>>>>     on Wed, 21 Feb 2018 07:11:44 -0800 writes:
    >> 
    >> > Hi all,
    >> > For the record this approach isnt 100% backwards compatible, because
    >> > names(mergeddf) will e incompatibly different. Thatx why i claimed
    >> > bakcwards compatable-ish
    >> 
    >> exactly.
    >> 
    >> > That said its still worth considering imho because of the reasons
    >> stated
    >> > (and honestly one particular simple reading of the docs might
    >> suggest that
    >> > this was thr intended behavior all along). Im not a member of Rcore
    >> through
    >> > so i cant do said considering myself.
    >> 
    >> I agree with Scott, Frederik and you that this changes seems
    >> worth considering.
    >> As Duncan Murdoch has mentioned, this alone may not be
    >> sufficient.
    >> 
    >> In addition to your proposed patch (which I have simplified, not
    >> using intersection() but working with underlying  match()
    >> directly), it is little work to introduce an extra argument, I'm
    >> calling  'no.dups = TRUE'  which when set to false would mirror
    >> current R's behavior... and documenting it, then also documents the
    >> new behavior (to some extent).
    >> 
    >> My plan is to commit it soonish ;-)
    >> Martin
    >> 
    >> > Best,
    >> > ~G
    >> 
    >> > On Feb 20, 2018 7:15 PM, <frederik at ofb.net> wrote:
    >> 
    >> > Hi Scott,
    >> 
    >> > I tried the new patch and can confirm that it has the advertised
    >> > behavior on a couple of test cases. I think it makes sense to apply
    >> > it, because any existing code which refers to a second duplicate
    >> > data.frame column by name is already broken, while if the reference
    >> is
    >> > by numerical index then changing the column name shouldn't break it.
    >> 
    >> > I don't know if you need to update the documentation as part of your
    >> > patch, or if whoever applies it would be happy to do that. Somebody
    >> > from R core want to weigh in on this?
    >> 
    >> > I attach a file with the test example from your original email as
    >> well
    >> > as a second test case I added with two "by" columns.
    >> 
    >> > Thanks,
    >> 
    >> > Frederick
    >> 
    >> > On Wed, Feb 21, 2018 at 10:06:21AM +1100, Scott Ritchie wrote:
    >> >> Hi Frederick,
    >> >>
    >> >> It looks like I didn't overwrite the patch.diff file after the last
    >> edits.
    >> >> Here's the correct patch (attached and copied below):
    >> >>
    >> >> Index: src/library/base/R/merge.R
    >> >> ===================================================================
    >> >> --- src/library/base/R/merge.R (revision 74280)
    >> >> +++ src/library/base/R/merge.R (working copy)
    >> >> @@ -157,6 +157,14 @@
    >> >> }
    >> >>
    >> >> if(has.common.nms) names(y) <- nm.y
    >> >> +        ## If by.x %in% names(y) then duplicate column names still
    >> arise,
    >> >> +        ## apply suffixes to just y - this keeps backwards
    >> compatibility
    >> >> +        ## when referring to by.x in the resulting data.frame
    >> >> +        dupe.keyx <- intersect(nm.by, names(y))
    >> >> +        if(length(dupe.keyx)) {
    >> >> +          if(nzchar(suffixes[2L]))
    >> >> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> paste(dupe.keyx,
    >> >> suffixes[2L], sep="")
    >> >> +        }
    >> >> nm <- c(names(x), names(y))
    >> >> if(any(d <- duplicated(nm)))
    >> >> if(sum(d) > 1L)
    >> >>
    >> >> Best,
    >> >>
    >> >> Scott
    >> >>
    >> >> On 21 February 2018 at 08:23, <frederik at ofb.net> wrote:
    >> >>
    >> >> > Hi Scott,
    >> >> >
    >> >> > I think that's a good idea and I tried your patch on my copy of
    >> the
    >> >> > repository. But it looks to me like the recent patch is identical
    >> to
    >> >> > the previous one, can you confirm this?
    >> >> >
    >> >> > Frederick
    >> >> >
    >> >> > On Mon, Feb 19, 2018 at 07:19:32AM +1100, Scott Ritchie wrote:
    >> >> > > Thanks Gabriel,
    >> >> > >
    >> >> > > I think your suggested approach is 100% backwards compatible
    >> >> > >
    >> >> > > Currently in the case of duplicate column names only the first
    >> can be
    >> >> > > indexed by its name. This will always be the column appearing
    >> in by.x,
    >> >> > > meaning the column in y with the same name cannot be accessed.
    >> > Appending
    >> >> > > ".y" (suffixes[2L]) to this column means it can now be
    >> accessed, while
    >> >> > > keeping the current behaviour of making the key columns always
    >> > accessible
    >> >> > > by using the names provided to by.x.
    >> >> > >
    >> >> > > I've attached a new patch that has this behaviour.
    >> >> > >
    >> >> > > Best,
    >> >> > >
    >> >> > > Scott
    >> >> > >
    >> >> > > On 19 February 2018 at 05:08, Gabriel Becker <
    >> gmbecker at ucdavis.edu>
    >> >> > wrote:
    >> >> > >
    >> >> > > > It seems like there is a way that is backwards compatible-ish
    >> in the
    >> >> > sense
    >> >> > > > mentioned and still has the (arguably, but a good argument I
    >> think)
    >> >> > better
    >> >> > > > behavior:
    >> >> > > >
    >> >> > > > if by.x is 'name', (AND by.y is not also 'name'), then x's
    >> 'name'
    >> >> > column
    >> >> > > > is called name and y's 'name' column (not used int he merge)
    >> is
    >> >> > changed to
    >> >> > > > name.y.
    >> >> > > >
    >> >> > > > Now of course this would still change output, but it would
    >> change
    >> > it to
    >> >> > > > something I think would be better, while retaining the 'merge
    >> > columns
    >> >> > > > retain their exact names' mechanic as documented.
    >> >> > > >
    >> >> > > > ~G
    >> >> > > >
    >> >> > > > On Sat, Feb 17, 2018 at 6:50 PM, Scott Ritchie <
    >> > s.ritchie73 at gmail.com>
    >> >> > > > wrote:
    >> >> > > >
    >> >> > > >> Thanks Duncan and Frederick,
    >> >> > > >>
    >> >> > > >> I suspected as much - there doesn't appear to be any reason
    >> why
    >> >> > conflicts
    >> >> > > >> between by.x and names(y) shouldn't and cannot be checked,
    >> but I
    >> > can
    >> >> > see
    >> >> > > >> how this might be more trouble than its worth given it
    >> potentially
    >> > may
    >> >> > > >> break downstream packages (i.e. any cases where this occurs
    >> but
    >> > they
    >> >> > > >> expect
    >> >> > > >> the name of the key column(s) to remain the same).
    >> >> > > >>
    >> >> > > >> Best,
    >> >> > > >>
    >> >> > > >> Scott
    >> >> > > >>
    >> >> > > >> On 18 February 2018 at 11:48, Duncan Murdoch <
    >> >> > murdoch.duncan at gmail.com>
    >> >> > > >> wrote:
    >> >> > > >>
    >> >> > > >> > On 17/02/2018 6:36 PM, frederik at ofb.net wrote:
    >> >> > > >> >
    >> >> > > >> >> Hi Scott,
    >> >> > > >> >>
    >> >> > > >> >> Thanks for the patch. I'm not really involved in R
    >> development;
    >> > it
    >> >> > > >> >> will be up to someone in the R core team to apply it. I
    >> would
    >> >> > hazard
    >> >> > > >> >> to say that even if correct (I haven't checked), it will
    >> not be
    >> >> > > >> >> applied because the change might break existing code. For
    >> > example
    >> >> > it
    >> >> > > >> >> seems like reasonable code might easily assume that a
    >> column
    >> > with
    >> >> > the
    >> >> > > >> >> same name as "by.x" exists in the output of 'merge'.
    >> That's
    >> > just my
    >> >> > > >> >> best guess... I don't participate on here often.
    >> >> > > >> >>
    >> >> > > >> >
    >> >> > > >> >
    >> >> > > >> > I think you're right.  If I were still a member of R Core,
    >> I
    >> > would
    >> >> > want
    >> >> > > >> to
    >> >> > > >> > test this against all packages on CRAN and Bioconductor,
    >> and
    >> > since
    >> >> > that
    >> >> > > >> > test takes a couple of days to run on my laptop, I'd
    >> probably
    >> > never
    >> >> > get
    >> >> > > >> > around to it.
    >> >> > > >> >
    >> >> > > >> > There are lots of cases where "I would have done that
    >> > differently",
    >> >> > but
    >> >> > > >> > most of them are far too much trouble to change now that R
    >> is
    >> > more
    >> >> > than
    >> >> > > >> 20
    >> >> > > >> > years old.  And in many cases it will turn out that the
    >> way R
    >> > does
    >> >> > it
    >> >> > > >> > actually does make more sense than the way I would have
    >> done it.
    >> >> > > >> >
    >> >> > > >> > Duncan Murdoch
    >> >> > > >> >
    >> >> > > >> >
    >> >> > > >> >
    >> >> > > >> >> Cheers,
    >> >> > > >> >>
    >> >> > > >> >> Frederick
    >> >> > > >> >>
    >> >> > > >> >> On Sat, Feb 17, 2018 at 04:42:21PM +1100, Scott Ritchie
    >> wrote:
    >> >> > > >> >>
    >> >> > > >> >>> The attached patch.diff will make merge.data.frame()
    >> append the
    >> >> > > >> suffixes
    >> >> > > >> >>> to
    >> >> > > >> >>> columns with common names between by.x and names(y).
    >> >> > > >> >>>
    >> >> > > >> >>> Best,
    >> >> > > >> >>>
    >> >> > > >> >>> Scott Ritchie
    >> >> > > >> >>>
    >> >> > > >> >>> On 17 February 2018 at 11:15, Scott Ritchie <
    >> >> > s.ritchie73 at gmail.com>
    >> >> > > >> >>> wrote:
    >> >> > > >> >>>
    >> >> > > >> >>> Hi Frederick,
    >> >> > > >> >>>>
    >> >> > > >> >>>> I would expect that any duplicate names in the resulting
    >> >> > data.frame
    >> >> > > >> >>>> would
    >> >> > > >> >>>> have the suffixes appended to them, regardless of
    >> whether or
    >> > not
    >> >> > they
    >> >> > > >> >>>> are
    >> >> > > >> >>>> used as the join key. So in my example I would expect
    >> > "names.x"
    >> >> > and
    >> >> > > >> >>>> "names.y" to indicate their source data.frame.
    >> >> > > >> >>>>
    >> >> > > >> >>>> While careful reading of the documentation reveals this
    >> is not
    >> >> > the
    >> >> > > >> >>>> case, I
    >> >> > > >> >>>> would argue the intent of the suffixes functionality
    >> should
    >> >> > equally
    >> >> > > >> be
    >> >> > > >> >>>> applied to this type of case.
    >> >> > > >> >>>>
    >> >> > > >> >>>> If you agree this would be useful, I'm happy to write a
    >> patch
    >> > for
    >> >> > > >> >>>> merge.data.frame that will add suffixes in this case - I
    >> > intend
    >> >> > to do
    >> >> > > >> >>>> the
    >> >> > > >> >>>> same for merge.data.table in the data.table package
    >> where I
    >> >> > initially
    >> >> > > >> >>>> encountered the edge case.
    >> >> > > >> >>>>
    >> >> > > >> >>>> Best,
    >> >> > > >> >>>>
    >> >> > > >> >>>> Scott
    >> >> > > >> >>>>
    >> >> > > >> >>>> On 17 February 2018 at 03:53, <frederik at ofb.net> wrote:
    >> >> > > >> >>>>
    >> >> > > >> >>>> Hi Scott,
    >> >> > > >> >>>>>
    >> >> > > >> >>>>> It seems like reasonable behavior to me. What result
    >> would
    >> > you
    >> >> > > >> expect?
    >> >> > > >> >>>>> That the second "name" should be called "name.y"?
    >> >> > > >> >>>>>
    >> >> > > >> >>>>> The "merge" documentation says:
    >> >> > > >> >>>>>
    >> >> > > >> >>>>>      If the columns in the data frames not used in
    >> merging
    >> > have
    >> >> > any
    >> >> > > >> >>>>>      common names, these have ?suffixes? (?".x"? and
    >> ?".y"?
    >> > by
    >> >> > > >> default)
    >> >> > > >> >>>>>      appended to try to make the names of the result
    >> unique.
    >> >> > > >> >>>>>
    >> >> > > >> >>>>> Since the first "name" column was used in merging,
    >> leaving
    >> > both
    >> >> > > >> >>>>> without a suffix seems consistent with the
    >> documentation...
    >> >> > > >> >>>>>
    >> >> > > >> >>>>> Frederick
    >> >> > > >> >>>>>
    >> >> > > >> >>>>> On Fri, Feb 16, 2018 at 09:08:29AM +1100, Scott Ritchie
    >> > wrote:
    >> >> > > >> >>>>>
    >> >> > > >> >>>>>> Hi,
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> I was unable to find a bug report for this with a
    >> cursory
    >> >> > search,
    >> >> > > >> but
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>> would
    >> >> > > >> >>>>>
    >> >> > > >> >>>>>> like clarification if this is intended or unavoidable
    >> >> > behaviour:
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> ```{r}
    >> >> > > >> >>>>>> # Create example data.frames
    >> >> > > >> >>>>>> parents <- data.frame(name=c("Sarah", "Max", "Qin",
    >> "Lex"),
    >> >> > > >> >>>>>>                        sex=c("F", "M", "F", "M"),
    >> >> > > >> >>>>>>                        age=c(41, 43, 36, 51))
    >> >> > > >> >>>>>> children <- data.frame(parent=c("Sarah", "Max",
    >> "Qin"),
    >> >> > > >> >>>>>>                         name=c("Oliver", "Sebastian",
    >> >> > "Kai-lee"),
    >> >> > > >> >>>>>>                         sex=c("M", "M", "F"),
    >> >> > > >> >>>>>>                         age=c(5,8,7))
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> # Merge() creates a duplicated "name" column:
    >> >> > > >> >>>>>> merge(parents, children, by.x = "name", by.y =
    >> "parent")
    >> >> > > >> >>>>>> ```
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> Output:
    >> >> > > >> >>>>>> ```
    >> >> > > >> >>>>>>     name sex.x age.x      name sex.y age.y
    >> >> > > >> >>>>>> 1   Max     M    43 Sebastian     M     8
    >> >> > > >> >>>>>> 2   Qin     F    36   Kai-lee     F     7
    >> >> > > >> >>>>>> 3 Sarah     F    41    Oliver     M     5
    >> >> > > >> >>>>>> Warning message:
    >> >> > > >> >>>>>> In merge.data.frame(parents, children, by.x = "name",
    >> by.y =
    >> >> > > >> >>>>>> "parent") :
    >> >> > > >> >>>>>>    column name ?name? is duplicated in the result
    >> >> > > >> >>>>>> ```
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> Kind Regards,
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> Scott Ritchie
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>>        [[alternative HTML version deleted]]
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>> ______________________________________________
    >> >> > > >> >>>>>> R-devel at r-project.org mailing list
    >> >> > > >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>>
    >> >> > > >> >>>>>
    >> >> > > >> >>>>
    >> >> > > >> >>>>
    >> >> > > >> >> Index: src/library/base/R/merge.R
    >> >> > > >> >>> ==============================
    >> ==============================
    >> >> > =======
    >> >> > > >> >>> --- src/library/base/R/merge.R  (revision 74264)
    >> >> > > >> >>> +++ src/library/base/R/merge.R  (working copy)
    >> >> > > >> >>> @@ -157,6 +157,15 @@
    >> >> > > >> >>>           }
    >> >> > > >> >>>             if(has.common.nms) names(y) <- nm.y
    >> >> > > >> >>> +        ## If by.x %in% names(y) then duplicate column
    >> names
    >> >> > still
    >> >> > > >> >>> arise,
    >> >> > > >> >>> +        ## apply suffixes to these
    >> >> > > >> >>> +        dupe.keyx <- intersect(nm.by, names(y))
    >> >> > > >> >>> +        if(length(dupe.keyx)) {
    >> >> > > >> >>> +          if(nzchar(suffixes[1L]))
    >> >> > > >> >>> +            names(x)[match(dupe.keyx, names(x), 0L)] <-
    >> >> > > >> >>> paste(dupe.keyx, suffixes[1L], sep="")
    >> >> > > >> >>> +          if(nzchar(suffixes[2L]))
    >> >> > > >> >>> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> >> > > >> >>> paste(dupe.keyx, suffixes[2L], sep="")
    >> >> > > >> >>> +        }
    >> >> > > >> >>>           nm <- c(names(x), names(y))
    >> >> > > >> >>>           if(any(d <- duplicated(nm)))
    >> >> > > >> >>>               if(sum(d) > 1L)
    >> >> > > >> >>>
    >> >> > > >> >>
    >> >> > > >> >> ______________________________________________
    >> >> > > >> >> R-devel at r-project.org mailing list
    >> >> > > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >> > > >> >>
    >> >> > > >> >>
    >> >> > > >> >
    >> >> > > >>
    >> >> > > >>         [[alternative HTML version deleted]]
    >> >> > > >>
    >> >> > > >> ______________________________________________
    >> >> > > >> R-devel at r-project.org mailing list
    >> >> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >> > > >>
    >> >> > > >
    >> >> > > >
    >> >> > > >
    >> >> > > > --
    >> >> > > > Gabriel Becker, PhD
    >> >> > > > Scientist (Bioinformatics)
    >> >> > > > Genentech Research
    >> >> > > >
    >> >> >
    >> >> > > Index: src/library/base/R/merge.R
    >> >> > > ============================================================
    >> =======
    >> >> > > --- src/library/base/R/merge.R        (revision 74264)
    >> >> > > +++ src/library/base/R/merge.R        (working copy)
    >> >> > > @@ -157,6 +157,15 @@
    >> >> > >          }
    >> >> > >
    >> >> > >          if(has.common.nms) names(y) <- nm.y
    >> >> > > +        ## If by.x %in% names(y) then duplicate column names
    >> still
    >> >> > arise,
    >> >> > > +        ## apply suffixes to these
    >> >> > > +        dupe.keyx <- intersect(nm.by, names(y))
    >> >> > > +        if(length(dupe.keyx)) {
    >> >> > > +          if(nzchar(suffixes[1L]))
    >> >> > > +            names(x)[match(dupe.keyx, names(x), 0L)] <-
    >> >> > paste(dupe.keyx, suffixes[1L], sep="")
    >> >> > > +          if(nzchar(suffixes[2L]))
    >> >> > > +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> >> > paste(dupe.keyx, suffixes[2L], sep="")
    >> >> > > +        }
    >> >> > >          nm <- c(names(x), names(y))
    >> >> > >          if(any(d <- duplicated(nm)))
    >> >> > >              if(sum(d) > 1L)
    >> >> >
    >> >> > > ______________________________________________
    >> >> > > R-devel at r-project.org mailing list
    >> >> > > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >> >
    >> >> >
    >> 
    >> >> Index: src/library/base/R/merge.R
    >> >> ===================================================================
    >> >> --- src/library/base/R/merge.R        (revision 74280)
    >> >> +++ src/library/base/R/merge.R        (working copy)
    >> >> @@ -157,6 +157,14 @@
    >> >> }
    >> >>
    >> >> if(has.common.nms) names(y) <- nm.y
    >> >> +        ## If by.x %in% names(y) then duplicate column names still
    >> arise,
    >> >> +        ## apply suffixes to just y - this keeps backwards
    >> compatibility
    >> >> +        ## when referring to by.x in the resulting data.frame
    >> >> +        dupe.keyx <- intersect(nm.by, names(y))
    >> >> +        if(length(dupe.keyx)) {
    >> >> +          if(nzchar(suffixes[2L]))
    >> >> +            names(y)[match(dupe.keyx, names(y), 0L)] <-
    >> paste(dupe.keyx,
    >> > suffixes[2L], sep="")
    >> >> +        }
    >> >> nm <- c(names(x), names(y))
    >> >> if(any(d <- duplicated(nm)))
    >> >> if(sum(d) > 1L)
    >> 
    >> > [[alternative HTML version deleted]]
    >> 
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > [[alternative HTML version deleted]]


From Jon.SKOIEN at ec.europa.eu  Fri Feb 23 16:43:43 2018
From: Jon.SKOIEN at ec.europa.eu (Jon.SKOIEN at ec.europa.eu)
Date: Fri, 23 Feb 2018 15:43:43 +0000
Subject: [Rd] Problem with R_registerRoutines
In-Reply-To: <CABFfbXtOKwVySVXrcg0-Rkgtx9Udm-dm3TRhKLqV2Ou7z5Keew@mail.gmail.com>
References: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>,
 <CABFfbXtOKwVySVXrcg0-Rkgtx9Udm-dm3TRhKLqV2Ou7z5Keew@mail.gmail.com>
Message-ID: <548D52560D5BDE45AEC4EF876BF2A194012CFCEA@S-DC-ESTB01-J.net1.cec.eu.int>

Thanks a lot for your answer Jeroen!
I should have mentioned that I had actually only checked with the win-builder, as I did not have R-devel installed on my computer.
But based on your answer I installed R-devel locally on a Linux-server (Redhat), and the package could be checked without the NOTE. So you might be right that this is a windows issue. However, another package that I am maintaining does not get any notes from the check on the win-builder (including fortran-code), so there is still something I don't understand here.

Anyway, does this mean that the package might be accepted on CRAN without further changes?

Thanks,
Jon


________________________________________
From: Jeroen Ooms [jeroenooms at gmail.com]
Sent: 23 February 2018 13:36
To: SKOIEN Jon (JRC-ISPRA)
Cc: r-devel
Subject: Re: [Rd] Problem with R_registerRoutines

On Windows this warning may be a false positive if R cannot find
"objdump.exe" which is required for this check. I think this is
actually a bug in R because it should be looking for "objdump.exe"
inside BINPREF (where gcc is) rather than on the PATH.

Can you check if you get the same warning if you upload the package to
https://win-builder.r-project.org ?






On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
> Dear list,
>
> I am trying to update a package to pass the CRAN-checks.
> But I am struggling with the following note:
>
> File 'psgp/libs/i386/psgp.dll':
>   Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
> File 'psgp/libs/x64/psgp.dll':
>   Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
>
> It is good practice to register native routines and to disable symbol
> search.
>
>
> I did already run:
> tools::package_native_routine_registration_skeleton(".")
> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
>
> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
>
> Thanks,
> Jon
>
>
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Feb 23 18:56:41 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Feb 2018 18:56:41 +0100
Subject: [Rd] Problem with R_registerRoutines
In-Reply-To: <548D52560D5BDE45AEC4EF876BF2A194012CFCEA@S-DC-ESTB01-J.net1.cec.eu.int>
References: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>
 <CABFfbXtOKwVySVXrcg0-Rkgtx9Udm-dm3TRhKLqV2Ou7z5Keew@mail.gmail.com>
 <548D52560D5BDE45AEC4EF876BF2A194012CFCEA@S-DC-ESTB01-J.net1.cec.eu.int>
Message-ID: <23184.21977.760711.843739@stat.math.ethz.ch>

>>>>>   <Jon.SKOIEN at ec.europa.eu>
>>>>>     on Fri, 23 Feb 2018 15:43:43 +0000 writes:

    > Thanks a lot for your answer Jeroen!
    > I should have mentioned that I had actually only checked with the win-builder, as I did not have R-devel installed on my computer.
    > But based on your answer I installed R-devel locally on a Linux-server (Redhat), and the package could be checked without the NOTE. So you might be right that this is a windows issue. However, another package that I am maintaining does not get any notes from the check on the win-builder (including fortran-code), so there is still something I don't understand here.

    > Anyway, does this mean that the package might be accepted on CRAN without further changes?

at least not automatically, and not very probably in my gut
feeling... but I may be wrong.

Did you use  R CMD check --as-cran  <your_pkg>
on Linux ?

Martin

    > Thanks,
    > Jon


    > ________________________________________
    > From: Jeroen Ooms [jeroenooms at gmail.com]
    > Sent: 23 February 2018 13:36
    > To: SKOIEN Jon (JRC-ISPRA)
    > Cc: r-devel
    > Subject: Re: [Rd] Problem with R_registerRoutines

    > On Windows this warning may be a false positive if R cannot find
    > "objdump.exe" which is required for this check. I think this is
    > actually a bug in R because it should be looking for "objdump.exe"
    > inside BINPREF (where gcc is) rather than on the PATH.

    > Can you check if you get the same warning if you upload the package to
    > https://win-builder.r-project.org ?






    > On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
    >> Dear list,
    >> 
    >> I am trying to update a package to pass the CRAN-checks.
    >> But I am struggling with the following note:
    >> 
    >> File 'psgp/libs/i386/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >> File 'psgp/libs/x64/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >> 
    >> It is good practice to register native routines and to disable symbol
    >> search.
    >> 
    >> 
    >> I did already run:
    >> tools::package_native_routine_registration_skeleton(".")
    >> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
    >> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
    >> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
    >> 
    >> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
    >> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
    >> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
    >> 
    >> Thanks,
    >> Jon
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Mon Feb 26 15:35:30 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 26 Feb 2018 15:35:30 +0100
Subject: [Rd] Possible typo in the C source code of R
In-Reply-To: <7faca923-dfd9-19f6-7cff-3289bb4f715e@dim.uchile.cl>
References: <7faca923-dfd9-19f6-7cff-3289bb4f715e@dim.uchile.cl>
Message-ID: <2ce84680-f081-7d6f-efed-47829e69ace3@gmail.com>

Thank you, Martin, for spotting this, it is clearly a bug, originally a 
conformance check was intended here and time series were defined using 
integers, so exact comparison would have made sense. Now time series are 
defined using doubles and exact comparison could be too strict with 
rounding errors. Moreover, it is not clear whether a conformance check 
at this low-level is a good thing, so the check has been removed 
completely, keeping the current behavior of R (except NaNs in the 
definition).

Best
Tomas

On 02/07/2018 04:12 PM, Martin Bodin wrote:
> Good morning,
>
> I am Martin Bodin, a postdoc at the CMM in Santiago de Chile, and I am
> currently in the process of formalising (a part of) the R language into
> the Coq proof assistant. This work makes me look frequently at the
> source code of R.
>
> I have noticed a strange line in the file src/main/util.c of the trunk
> branch:
> https://github.com/wch/r-source/blob/e42531eff56ee6582d7dc6a46f242af5447c633e/src/main/util.c#L70
>
> The line 70 ?REAL(x)[0] == REAL(x)[0]? doesn?t make any sense for me:
> are we looking for NaN values here? I think that it should be
> ?REAL(x)[0] == REAL(y)[0]? instead (and the same applies for the next
> two lines).
>
> I didn?t searched for any R program that may be affected by this typo,
> but I have the feeling that it may lead to unexpected behaviours.
>
>  From what I understood, the bug reporting tool for R is closed for
> non-members, and I am thus sending this possible bug report in this
> list. Please redirect me if I am not reporting in the right place.
>
> Best regards,
> Martin Bodin.
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Mon Feb 26 15:47:23 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 26 Feb 2018 14:47:23 +0000
Subject: [Rd] R 3.4.4 scheduled for March 15
Message-ID: <63401A34-70F6-4170-BA99-7D9C57A8C669@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tomas.kalibera at gmail.com  Mon Feb 26 16:01:21 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 26 Feb 2018 16:01:21 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <1f1c808a24e9471784537dabde08d477@urzdommbx02.dom.uni-leipzig.de>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
 <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
 <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>
 <1f1c808a24e9471784537dabde08d477@urzdommbx02.dom.uni-leipzig.de>
Message-ID: <097719f7-da88-7a01-c4ec-3154328d6e58@gmail.com>

Dear Christian and Henrik,

thank you for spotting the problem and suggestions for a fix. We'll 
probably add a chunk.size argument to parLapplyLB and parLapply to 
follow OpenMP terminology, which has already been an inspiration for the 
present code (parLapply already implements static scheduling via 
internal function staticClusterApply, yet with a fixed chunk size; 
parLapplyLB already implements dynamic scheduling via internal function 
dynamicClusterApply, but with a fixed chunk size set to an unlucky value 
so that it behaves like static scheduling). The default chunk size for 
parallelLapplyLB will be set so that there is some dynamism in the 
schedule even by default. I am now testing a patch with these changes.

Best
Tomas


On 02/20/2018 11:45 AM, Christian Krause wrote:
> Dear Henrik,
>
> The rationale is just that it is within these extremes and that it is really simple to calculate, without making any assumptions and knowing that it won't be perfect.
>
> The extremes A and B you are mentioning are special cases based on assumptions. Case A is based on the assumption that the function has a long runtime or varying runtime, then you are likely to get the best load balancing with really small chunks. Case B is based on the assumption that the function runtime is the same for each list element, i.e. where you don't actually need load balancing, i.e. just use `parLapply` without load balancing.
>
> This new default is **not the best one**. It's just a better one than we had before. There is no best one we can use as default because **we don't know the function runtime and how it varies**. The user needs to decide that because he/she knows the function. As mentioned before, I will write a patch that makes the chunk size an optional argument, so the user can decide because only he/she has all the information to choose the best chunk size, just like you did with the `future.scheduling` parameter.
>
> Best Regards
>
> On February 19, 2018 10:11:04 PM GMT+01:00, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>> Hi, I'm trying to understand the rationale for your proposed amount of
>> splitting and more precisely why that one is THE one.
>>
>> If I put labels on your example numbers in one of your previous post:
>>
>> nbrOfElements <- 97
>> nbrOfWorkers <- 5
>>
>> With these, there are two extremes in how you can split up the
>> processing in chunks such that all workers are utilized:
>>
>> (A) Each worker, called multiple times, processes one element each
>> time:
>>
>>> nbrOfElements <- 97
>>> nbrOfWorkers <- 5
>>> nbrOfChunks <- nbrOfElements
>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>> [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> [30] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> [59] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> [88] 1 1 1 1 1 1 1 1 1 1
>>
>>
>> (B) Each worker, called once, processes multiple element:
>>
>>> nbrOfElements <- 97
>>> nbrOfWorkers <- 5
>>> nbrOfChunks <- nbrOfWorkers
>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>> [1] 20 19 19 19 20
>>
>> I understand that neither of these two extremes may be the best when
>> it comes to orchestration overhead and load balancing. Instead, the
>> best might be somewhere in-between, e.g.
>>
>> (C) Each worker, called multiple times, processing multiple elements:
>>
>>> nbrOfElements <- 97
>>> nbrOfWorkers <- 5
>>> nbrOfChunks <- nbrOfElements / nbrOfWorkers
>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>> [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>
>> However, there are multiple alternatives between the two extremes, e.g.
>>
>>> nbrOfChunks <- scale * nbrOfElements / nbrOfWorkers
>> So, is there a reason why you argue for scale = 1.0 to be the optimal?
>>
>> FYI, In future.apply::future_lapply(X, FUN, ...) there is a
>> 'future.scheduling' scale factor(*) argument where default
>> future.scheduling = 1 corresponds to (B) and future.scheduling = +Inf
>> to (A).  Using future.scheduling = 4 achieves the amount of
>> load-balancing you propose in (C).   (*) Different definition from the
>> above 'scale'. (Disclaimer: I'm the author)
>>
>> /Henrik
>>
>> On Mon, Feb 19, 2018 at 10:21 AM, Christian Krause
>> <christian.krause at idiv.de> wrote:
>>> Dear R-Devel List,
>>>
>>> I have installed R 3.4.3 with the patch applied on our cluster and
>> ran a *real-world* job of one of our users to confirm that the patch
>> works to my satisfaction. Here are the results.
>>> The original was a series of jobs, all essentially doing the same
>> stuff using bootstrapped data, so for the original there is more data
>> and I show the arithmetic mean with standard deviation. The
>> confirmation with the patched R was only a single instance of that
>> series of jobs.
>>> ## Job Efficiency
>>>
>>> The job efficiency is defined as (this is what the `qacct-efficiency`
>> tool below does):
>>> ```
>>> efficiency = cputime / cores / wallclocktime * 100%
>>> ```
>>>
>>> In simpler words: how well did the job utilize its CPU cores. It
>> shows the percentage of time the job was actually doing stuff, as
>> opposed to the difference:
>>> ```
>>> wasted = 100% - efficiency
>>> ```
>>>
>>> ... which, essentially, tells us how much of the resources were
>> wasted, i.e. CPU cores just idling, without being used by anyone. We
>> care a lot about that because, for our scientific computing cluster,
>> wasted resources is like burning money.
>>> ### original
>>>
>>> This is the entire series from our job accounting database, filteres
>> the successful jobs, calculates efficiency and then shows the average
>> and standard deviation of the efficiency:
>>> ```
>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
>>> n=945 ? 61.7276 ? 7.78719
>>> ```
>>>
>>> This is the entire series from our job accounting database, filteres
>> the successful jobs, calculates efficiency and does sort of a
>> histogram-like binning before calculation of mean and standard
>> deviation (to get a more detailed impression of the distribution when
>> standard deviation of the previous command is comparatively high):
>>> ```
>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w
>> 10 | sort -gk1 | column -t
>>> 10  -  20  ->  n=3    ?  19.21666666666667   ?  0.9112811494447459
>>> 20  -  30  ->  n=6    ?  26.418333333333333  ?  2.665996374091058
>>> 30  -  40  ->  n=12   ?  35.11583333333334   ?  2.8575783082671196
>>> 40  -  50  ->  n=14   ?  45.35285714285715   ?  2.98623361591005
>>> 50  -  60  ->  n=344  ?  57.114593023255814  ?  2.1922005551774415
>>> 60  -  70  ->  n=453  ?  64.29536423841049   ?  2.8334788433963856
>>> 70  -  80  ->  n=108  ?  72.95592592592598   ?  2.5219474143639276
>>> 80  -  90  ->  n=5    ?  81.526              ?  1.2802265424525452
>>> ```
>>>
>>> I have attached an example graph from our monitoring system of a
>> single instance in my previous mail. There you can see that the load
>> balancing does not actually work, i.e. same as `parLapply`. This
>> reflects in the job efficiency.
>>> ### patch applied
>>>
>>> This is the single instance I used to confirm that the patch works:
>>>
>>> ```
>>> $ qacct -j 4562202 | qacct-efficiency
>>> 97.36
>>> ```
>>>
>>> The graph from our monitoring system is attached. As you can see, the
>> load balancing works to a satisfying degree and the efficiency is well
>> above 90% which was what I had hoped for :-)
>>> ## Additional Notes
>>>
>>> The list used in this jobs `parLapplyLB` is 5812 elements long. With
>> the `splitList`-chunking from the patch, you'll get 208 lists of about
>> 28 elements (208 chunks of size 28). The job ran on 28 CPU cores and
>> had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the
>> function we apply to our list takes about 580 seconds per list element,
>> i.e. about 10 minutes. I suppose, for that runtime, we would get even
>> better load balancing if we would reduce the chunk size even further,
>> maybe even down to 1, thus getting our efficiency even closer to 100%.
>>> Of course, for really short-running functions, a higher chunk size
>> may be more efficient because of the overhead. In our case, the
>> overhead is negligible and that is why the low chunk size works really
>> well. In contrast, for smallish lists with short-running functions, you
>> might not even need load balancing and `parLapply` suffices. It only
>> becomes an issue, when the runtime of the function is high and / or
>> varying.
>>> In our case, the entire runtime of the entire series of jobs was:
>>>
>>> ```
>>> $ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print
>> sum, "seconds" }'
>>> 4.72439e+09 seconds
>>> ```
>>>
>>> Thats about 150 years on a single core or 7.5 years on a 20 core
>> server! Our user was constantly using about 500 cores, so this took
>> about 110 days. If you compare this to my 97% efficiency example, the
>> jobs could have been finished in 75 days instead ;-)
>>> ## Upcoming Patch
>>>
>>> If this patch gets applied to the R code base (and I hope it will
>> :-)) my colleague and I will submit another patch that adds the chunk
>> size as an optional parameter to all off the load balancing functions.
>> With that parameter, users of these functions *can* decide for
>> themselves which chunk size they prefer for their code. As mentioned
>> before, the most efficient chunk size depends on the used functions
>> runtime, which is the only thing R does not know and users really
>> should be allowed to specify explicitly. The default of this new
>> optional parameter would be the one we used here and this would make
>> that upcoming patch fully source-compatible.
>>> Best Regards
>>>
>>> On 02/12/2018 08:08 PM, Christian Krause wrote:
>>>> Dear R-Devel List,
>>>>
>>>> **TL;DR:** The function **parLapplyLB** of the parallel package has
>> [reportedly][1] (see also attached RRD output) not
>>>> been doing its job, i.e. not actually balancing the load. My
>> colleague Dirk Sarpe and I found the cause of the problem
>>>> and we also have a patch to fix it (attached). A similar fix has
>> also been provided [here][2].
>>>> [1]:
>> https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
>>>> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
>>>>
>>>>
>>>> ## The Call Chain
>>>>
>>>> First, we traced the relevant R function calls through the code,
>> beginning with `parLapplyLB`:
>>>> 1.  **parLapplyLB:** clusterApply.R:177, calls **splitList**, then
>> **clusterApplyLB**
>>>> 2.  **splitList:** clusterApply.R:157
>>>> 3.  **clusterApplyLB:** clusterApply.R:87, calls
>> **dynamicClusterApply**
>>>> 4.  **dynamicClusterApply:** clusterApply.R:39
>>>>
>>>>
>>>> ## splitList
>>>>
>>>> We used both our whiteboard and an R session to manually *run* a few
>> examples. We were using lists of 100 elements and 5
>>>> workers. First, lets take a look at **splitList**:
>>>>
>>>> ```r
>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>> [1] 20 20 20 20 20
>>>>
>>>>> sapply(parallel:::splitList(1:97, 5), length)
>>>> [1] 20 19 19 19 20
>>>>
>>>>> sapply(parallel:::splitList(1:97, 20), length)
>>>>   [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>>> ```
>>>>
>>>> As we can see in the examples, the work is distributed as equally as
>> possible.
>>>>
>>>> ## dynamicClusterApply
>>>>
>>>> **dynamicClusterApply** works this way (simplified):
>>>>
>>>> 1.  it first gives a chunk to each worker
>>>> 2.  once a worker comes back with the result, it is given the next
>> chunk
>>>> **This is the important part:** As long as there are **more** chunks
>> than workers, there will be load balancing. If
>>>> there are fewer chunks than workers, each worker will get **at most
>> one chunk** and there is **no** load balancing.
>>>>
>>>> ## parLapplyLB
>>>>
>>>> This is how **parLapplyLB** splits the input list (with a bit of
>> refactoring, for readability):
>>>> ```r
>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>> {
>>>>      cl <- defaultCluster(cl)
>>>>
>>>>      chunks <- splitList(X, length(cl))
>>>>
>>>>      do.call(c,
>>>>              clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>              quote = TRUE)
>>>> }
>>>> ```
>>>>
>>>> For our examples, the chunks have these sizes:
>>>>
>>>> ```r
>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>> [1] 20 20 20 20 20
>>>> ```
>>>>
>>>> There we have it: 5 chunks. 5 workers. With this work distribution,
>> there can't possibly be any load balancing, because
>>>> each worker is given a single chunk and then it stops working
>> because there are no more chunks.
>>>> Instead, **parLapplyLB** should look like this (patch is attached):
>>>>
>>>> ```r
>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>> {
>>>>      cl <- defaultCluster(cl)
>>>>
>>>>      chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
>>>>
>>>>      chunks <- splitList(X, chunkSize)
>>>>
>>>>      do.call(c,
>>>>              clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>              quote = TRUE)
>>>> }
>>>> ```
>>>>
>>>> Examples with a cluster of 5 workers:
>>>>
>>>> ```r
>>>> # length(cl) < length(X)
>>>>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>>>>   [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
>>>>
>>>> # length(cl) >= length(X)
>>>>> sapply(parallel:::splitList(1:4, 4), length)
>>>> [1] 1 1 1 1
>>>> # one worker idles here, but we can't do better than that
>>>> ```
>>>>
>>>> With this patch, the number of chunks is larger than the number of
>> workers, if possible at all, and then load balancing
>>>> should work.
>>>>
>>>> Best Regards
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>> --
>>> Christian Krause
>>>
>>> Scientific Computing Administration and Support
>>>
>>>
>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> Email: christian.krause at idiv.de
>>>
>>> Office: BioCity Leipzig 5e, Room 3.201.3
>>>
>>> Phone: +49 341 97 33144
>>>
>>>
>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> German Centre for Integrative Biodiversity Research (iDiv)
>> Halle-Jena-Leipzig
>>> Deutscher Platz 5e
>>>
>>> 04103 Leipzig
>>>
>>> Germany
>>>
>>>
>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> iDiv is a research centre of the DFG ? Deutsche
>> Forschungsgemeinschaft
>>> iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne
>> des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der
>> Martin-Luther-Universit?t Halle-Wittenberg und der
>> Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit
>> dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte
>> Kooperationspartner sind die folgenden au?eruniversit?ren
>> Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH
>> - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das
>> Max-Planck-Institut f?r chemische ?kologie (MPI CE), das
>> Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das
>> Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen
>> (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das
>> Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK)
>> und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz
>> (SMNG). USt-IdNr. DE 141510383
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>


From paul at stat.auckland.ac.nz  Tue Feb 27 04:01:06 2018
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 27 Feb 2018 16:01:06 +1300
Subject: [Rd] [FORGED] Height not set properly in grDevices::jpeg() with
 type = "cairo"
In-Reply-To: <CAFiqf9wkh7Vjnq7q9x7hqSCqVofegWKyv-ObUcit6gbWGMrsVQ@mail.gmail.com>
References: <CAFiqf9wkh7Vjnq7q9x7hqSCqVofegWKyv-ObUcit6gbWGMrsVQ@mail.gmail.com>
Message-ID: <0c514265-4b39-6c10-680a-3e8afabeeb47@stat.auckland.ac.nz>

Hi

That fix checks out for me so I have committed the change to r-devel.

Thanks for the report!

Paul

On 28/11/17 16:25, Marius wrote:
> Hi,
> I have been having issues producing plots in JPEG format, using type =
> "cairo" to get better anti-aliasing. When trying to set the physical
> size with units = "cm" or units = "mm", the width is set correctly but
> the height is not - it looks like the height is simply treated as
> pixels regardless of the 'units' argument.
> 
> Example:
> 
> 
> x = 1:10
> y = 2 * x
> jpeg("ExamplePlot.jpg",
>       type = "cairo",
>       width = 200,
>       height = 200,
>       units = "mm",
>       res = 96)
> plot(x, y)
> dev.off()
> 
> 
> On my system (Windows 7, running R 3.4.2), this produces a plot that
> is 755 x 200 pixels, and is vertically very squashed.
> 
> Looking at grDevices::jpeg, it looks like the culprit is these lines:
> 
>     g <- .geometry(width, height, units, res)
>      if (match.arg(type) == "cairo") {
>          antialias <- match(match.arg(antialias), aa.cairo)
>          invisible(.External(C_devCairo, filename, 3L, g$width,
>              height, pointsize, bg, res, antialias, quality, if
> (nzchar(family)) family else "sans",
>              300))
>      }
> 
> g$width is used, but "height" is used instead of "g$height". I suspect
> simply using "g$height" here would fix the issue but have not had time
> to test this.
> 
> My R.version:
> 
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          4.2
> year           2017
> month          09
> day            28
> svn rev        73368
> language       R
> version.string R version 3.4.2 (2017-09-28)
> nickname       Short Summer
> 
> Please let me know if any further information is needed.
> 
> Thanks,
> Marius
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From Jon.SKOIEN at ec.europa.eu  Tue Feb 27 08:21:18 2018
From: Jon.SKOIEN at ec.europa.eu (Jon.SKOIEN at ec.europa.eu)
Date: Tue, 27 Feb 2018 07:21:18 +0000
Subject: [Rd] Problem with R_registerRoutines
In-Reply-To: <23184.21977.760711.843739@stat.math.ethz.ch>
References: <548D52560D5BDE45AEC4EF876BF2A194012CF051@S-DC-ESTB01-J.net1.cec.eu.int>
 <CABFfbXtOKwVySVXrcg0-Rkgtx9Udm-dm3TRhKLqV2Ou7z5Keew@mail.gmail.com>
 <548D52560D5BDE45AEC4EF876BF2A194012CFCEA@S-DC-ESTB01-J.net1.cec.eu.int>,
 <23184.21977.760711.843739@stat.math.ethz.ch>
Message-ID: <548D52560D5BDE45AEC4EF876BF2A194012D3FF3@S-DC-ESTB01-J.net1.cec.eu.int>


Martin,

I did not use --as-cran on Linux, when I do, I also see the error there.
So most likely something is wrong and you're right that the package would not be accepted on CRAN, but I'm running out of ideas for how to solve this problem. I have tried to modify the initialization file in lots of different ways, so far nothing helps. 

Jon

________________________________________
From: Martin Maechler [maechler at stat.math.ethz.ch]
Sent: 23 February 2018 18:56
To: SKOIEN Jon (JRC-ISPRA)
Cc: jeroenooms at gmail.com; r-devel at r-project.org
Subject: Re: [Rd] Problem with R_registerRoutines

>>>>>   <Jon.SKOIEN at ec.europa.eu>
>>>>>     on Fri, 23 Feb 2018 15:43:43 +0000 writes:

    > Thanks a lot for your answer Jeroen!
    > I should have mentioned that I had actually only checked with the win-builder, as I did not have R-devel installed on my computer.
    > But based on your answer I installed R-devel locally on a Linux-server (Redhat), and the package could be checked without the NOTE. So you might be right that this is a windows issue. However, another package that I am maintaining does not get any notes from the check on the win-builder (including fortran-code), so there is still something I don't understand here.

    > Anyway, does this mean that the package might be accepted on CRAN without further changes?

at least not automatically, and not very probably in my gut
feeling... but I may be wrong.

Did you use  R CMD check --as-cran  <your_pkg>
on Linux ?

Martin

    > Thanks,
    > Jon


    > ________________________________________
    > From: Jeroen Ooms [jeroenooms at gmail.com]
    > Sent: 23 February 2018 13:36
    > To: SKOIEN Jon (JRC-ISPRA)
    > Cc: r-devel
    > Subject: Re: [Rd] Problem with R_registerRoutines

    > On Windows this warning may be a false positive if R cannot find
    > "objdump.exe" which is required for this check. I think this is
    > actually a bug in R because it should be looking for "objdump.exe"
    > inside BINPREF (where gcc is) rather than on the PATH.

    > Can you check if you get the same warning if you upload the package to
    > https://win-builder.r-project.org ?






    > On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
    >> Dear list,
    >>
    >> I am trying to update a package to pass the CRAN-checks.
    >> But I am struggling with the following note:
    >>
    >> File 'psgp/libs/i386/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >> File 'psgp/libs/x64/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >>
    >> It is good practice to register native routines and to disable symbol
    >> search.
    >>
    >>
    >> I did already run:
    >> tools::package_native_routine_registration_skeleton(".")
    >> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
    >> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
    >> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
    >>
    >> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
    >> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
    >> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
    >>
    >> Thanks,
    >> Jon
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From michaelchirico4 at gmail.com  Tue Feb 27 13:18:34 2018
From: michaelchirico4 at gmail.com (Michael Chirico)
Date: Tue, 27 Feb 2018 20:18:34 +0800
Subject: [Rd] scale.default gives an incorrect error message when
 is.numeric() fails on a sparse row matrix (dgeMatrix)
Message-ID: <CAPRVBcyZwt6bYiqeZ3Lz2ivye2oFfLoUShuobps4k5yKg=JGDg@mail.gmail.com>

I am attempting to use the lars package with a sparse input feature matrix,
but the following fails:

library(Matrix)
library(lars)
data(diabetes)
attach(diabetes)
x = as(as.matrix(as.data.frame(x)), 'dgCMatrix')
lars(x, y, intercept = FALSE)

Error in scale.default(x, FALSE, normx) :
>
>   length of 'scale' must equal the number of columns of 'x'
>
>
More specifically, scale.default fails:

normx = new(
  "dgeMatrix",
  x = c(1.00000000000004, 1, 1.00000000000009,
        1.00000000000001, 1.00000000000001,
        0.999999999999992, 1.00000000000004,
        0.999999999999975, 1.00000000000006,
        1.00000000000006), Dim = c(1L, 10L),
  Dimnames =
    list(NULL, c("x.age", "x.sex", "x.bmi", "x.map", "x.tc",
                 "x.ldl", "x.hdl", "x.tch", "x.ltg", "x.glu")),
  factors = list()
)

scale(x, FALSE, normx)

The problem is that this check fails because is.numeric(normx) is FALSE:

if (is.numeric(scale) && length(scale) == nc)

So, the error message is misleading. In fact length(scale) is the same as
nc.

At a minimum, the error message needs to be repaired; do we also want to
attempt as.numeric(normx) (which I believe would have allowed scale to work
in this case)?

(I'm aware that there's some import issues in lars, as the offending line
to create normx *should* work, as is.numeric(sqrt(drop(rep(1, nrow(x)) %*%
(x^2)))) is TRUE -- it's simply that lars doesn't import the appropriate S4
methods)

Michael Chirico

	[[alternative HTML version deleted]]


From georgi.boshnakov at manchester.ac.uk  Tue Feb 27 14:44:51 2018
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Tue, 27 Feb 2018 13:44:51 +0000
Subject: [Rd] R-devel Digest, Vol 180, Issue 24
In-Reply-To: <mailman.46712.5.1519729202.9541.r-devel@r-project.org>
References: <mailman.46712.5.1519729202.9541.r-devel@r-project.org>
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F64FFFC@MBXP01.ds.man.ac.uk>

I didn't find the development version of your package but the latest version archived on CRAN uses Rcpp, RcppArmadillo.
Since the latest versions of Rcpp and Armadillo support registration, it may be something related to RcppAttributes()
or similar. I think that you don't need to do registration manually. 

I had a similar problem but when I realised the above, I discarded everything generated by Rcpp/RcppArmadillo, 
Installed their latest versions and 
compared my package to freshly generated packages by Rcpp.package.skeleton() and RcppArmadillo.package.skeleton().
(Since I had old-ish version of R and Rdevel, I updated them too. )

I believe that you also need to import something from Rcpp (but not from RcppArmadillo). Try the following line

importFrom(Rcpp, evalCpp)

in NAMESPACE (I believe that it is generated by both, Rcpp.package.skeleton() and RcppArmadillo.package.skeleton()).


The path issue on Windows is a separate one. I typically start a command window from a batch file which sets the paths and environment variables maybe more defensively,  and the above removed the "registration" warning. But using  devtools from a different session still gives it. 


Georgi Boshnakov


------------------------------

Message: 5
Date: Tue, 27 Feb 2018 07:21:18 +0000
From: <Jon.SKOIEN at ec.europa.eu>
To: <maechler at stat.math.ethz.ch>
Cc: <jeroenooms at gmail.com>, <r-devel at r-project.org>
Subject: Re: [Rd] Problem with R_registerRoutines
Message-ID:
	<548D52560D5BDE45AEC4EF876BF2A194012D3FF3 at S-DC-ESTB01-J.net1.cec.eu.int>
	
Content-Type: text/plain; charset="us-ascii"


Martin,

I did not use --as-cran on Linux, when I do, I also see the error there.
So most likely something is wrong and you're right that the package would not be accepted on CRAN, but I'm running out of ideas for how to solve this problem. I have tried to modify the initialization file in lots of different ways, so far nothing helps. 

Jon

________________________________________
From: Martin Maechler [maechler at stat.math.ethz.ch]
Sent: 23 February 2018 18:56
To: SKOIEN Jon (JRC-ISPRA)
Cc: jeroenooms at gmail.com; r-devel at r-project.org
Subject: Re: [Rd] Problem with R_registerRoutines

>>>>>   <Jon.SKOIEN at ec.europa.eu>
>>>>>     on Fri, 23 Feb 2018 15:43:43 +0000 writes:

    > Thanks a lot for your answer Jeroen!
    > I should have mentioned that I had actually only checked with the win-builder, as I did not have R-devel installed on my computer.
    > But based on your answer I installed R-devel locally on a Linux-server (Redhat), and the package could be checked without the NOTE. So you might be right that this is a windows issue. However, another package that I am maintaining does not get any notes from the check on the win-builder (including fortran-code), so there is still something I don't understand here.

    > Anyway, does this mean that the package might be accepted on CRAN without further changes?

at least not automatically, and not very probably in my gut
feeling... but I may be wrong.

Did you use  R CMD check --as-cran  <your_pkg>
on Linux ?

Martin

    > Thanks,
    > Jon


    > ________________________________________
    > From: Jeroen Ooms [jeroenooms at gmail.com]
    > Sent: 23 February 2018 13:36
    > To: SKOIEN Jon (JRC-ISPRA)
    > Cc: r-devel
    > Subject: Re: [Rd] Problem with R_registerRoutines

    > On Windows this warning may be a false positive if R cannot find
    > "objdump.exe" which is required for this check. I think this is
    > actually a bug in R because it should be looking for "objdump.exe"
    > inside BINPREF (where gcc is) rather than on the PATH.

    > Can you check if you get the same warning if you upload the package to
    > https://win-builder.r-project.org ?






    > On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
    >> Dear list,
    >>
    >> I am trying to update a package to pass the CRAN-checks.
    >> But I am struggling with the following note:
    >>
    >> File 'psgp/libs/i386/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >> File 'psgp/libs/x64/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >>
    >> It is good practice to register native routines and to disable symbol
    >> search.
    >>
    >>
    >> I did already run:
    >> tools::package_native_routine_registration_skeleton(".")
    >> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
    >> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
    >> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
    >>
    >> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
    >> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
    >> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
    >>
    >> Thanks,
    >> Jon
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel




------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel


------------------------------

End of R-devel Digest, Vol 180, Issue 24
****************************************

From georgi.boshnakov at manchester.ac.uk  Tue Feb 27 14:54:00 2018
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Tue, 27 Feb 2018 13:54:00 +0000
Subject: [Rd] Problem with R_registerRoutines
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F650019@MBXP01.ds.man.ac.uk>

Sorry, resending with correct subject line.


I didn't find the development version of your package but the latest version archived on CRAN uses Rcpp, RcppArmadillo.
Since the latest versions of Rcpp and Armadillo support registration, it may be something related to RcppAttributes() or similar. I think that you don't need to do registration manually. 

I had a similar problem but when I realised the above, I discarded everything generated by Rcpp/RcppArmadillo, Installed their latest versions and compared my package to freshly generated packages by Rcpp.package.skeleton() and RcppArmadillo.package.skeleton().
(Since I had old-ish version of R and Rdevel, I updated them too. )

I believe that you also need to import something from Rcpp (but not from RcppArmadillo). Try the following line

importFrom(Rcpp, evalCpp)

in NAMESPACE (I believe that it is generated by both, Rcpp.package.skeleton() and RcppArmadillo.package.skeleton()).


The path issue on Windows is a separate one. I typically start a command window from a batch file which sets the paths and environment variables maybe more defensively,  and the above removed the "registration" warning. But using  devtools from a different session still gives it. 


Georgi Boshnakov


------------------------------

Message: 5
Date: Tue, 27 Feb 2018 07:21:18 +0000
From: <Jon.SKOIEN at ec.europa.eu>
To: <maechler at stat.math.ethz.ch>
Cc: <jeroenooms at gmail.com>, <r-devel at r-project.org>
Subject: Re: [Rd] Problem with R_registerRoutines
Message-ID:
	<548D52560D5BDE45AEC4EF876BF2A194012D3FF3 at S-DC-ESTB01-J.net1.cec.eu.int>
	
Content-Type: text/plain; charset="us-ascii"


Martin,

I did not use --as-cran on Linux, when I do, I also see the error there.
So most likely something is wrong and you're right that the package would not be accepted on CRAN, but I'm running out of ideas for how to solve this problem. I have tried to modify the initialization file in lots of different ways, so far nothing helps. 

Jon

________________________________________
From: Martin Maechler [maechler at stat.math.ethz.ch]
Sent: 23 February 2018 18:56
To: SKOIEN Jon (JRC-ISPRA)
Cc: jeroenooms at gmail.com; r-devel at r-project.org
Subject: Re: [Rd] Problem with R_registerRoutines

>>>>>   <Jon.SKOIEN at ec.europa.eu>
>>>>>     on Fri, 23 Feb 2018 15:43:43 +0000 writes:

    > Thanks a lot for your answer Jeroen!
    > I should have mentioned that I had actually only checked with the win-builder, as I did not have R-devel installed on my computer.
    > But based on your answer I installed R-devel locally on a Linux-server (Redhat), and the package could be checked without the NOTE. So you might be right that this is a windows issue. However, another package that I am maintaining does not get any notes from the check on the win-builder (including fortran-code), so there is still something I don't understand here.

    > Anyway, does this mean that the package might be accepted on CRAN without further changes?

at least not automatically, and not very probably in my gut feeling... but I may be wrong.

Did you use  R CMD check --as-cran  <your_pkg> on Linux ?

Martin

    > Thanks,
    > Jon


    > ________________________________________
    > From: Jeroen Ooms [jeroenooms at gmail.com]
    > Sent: 23 February 2018 13:36
    > To: SKOIEN Jon (JRC-ISPRA)
    > Cc: r-devel
    > Subject: Re: [Rd] Problem with R_registerRoutines

    > On Windows this warning may be a false positive if R cannot find
    > "objdump.exe" which is required for this check. I think this is
    > actually a bug in R because it should be looking for "objdump.exe"
    > inside BINPREF (where gcc is) rather than on the PATH.

    > Can you check if you get the same warning if you upload the package to
    > https://win-builder.r-project.org ?






    > On Fri, Feb 23, 2018 at 10:28 AM,  <Jon.SKOIEN at ec.europa.eu> wrote:
    >> Dear list,
    >>
    >> I am trying to update a package to pass the CRAN-checks.
    >> But I am struggling with the following note:
    >>
    >> File 'psgp/libs/i386/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >> File 'psgp/libs/x64/psgp.dll':
    >> Found no calls to: 'R_registerRoutines', 'R_useDynamicSymbols'
    >>
    >> It is good practice to register native routines and to disable symbol
    >> search.
    >>
    >>
    >> I did already run:
    >> tools::package_native_routine_registration_skeleton(".")
    >> This gave me some code, including a function R_init_psgp, which includes calls to the functions above, and also the names of the C++ functions to be called from R.
    >> I first saved this code in registerDynamicSymbol.c and added .registration = TRUE to useDynLib in the NAMESPACE file.
    >> I still get the error above. As I saw that the file has different names in other packages, I have also tried to save it psgp_init.c, and in init.cpp, still with the same error message.
    >>
    >> I have read the relevant part of the R extensions manual, but could not find anything that could help me with this problem.
    >> I have had a look at the similar files in other packages (including one of my own, which works), and the initialization seems fine to me.
    >> There is surely something I have overlooked, is anyone able to give me a hint to where I might look? The code is in C++, not sure if that could have anything to do with the problem?
    >>
    >> Thanks,
    >> Jon
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >>
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel




------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED https://stat.ethz.ch/mailman/listinfo/r-devel


------------------------------

End of R-devel Digest, Vol 180, Issue 24
****************************************

