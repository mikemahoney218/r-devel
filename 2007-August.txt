From bolker at ufl.edu  Wed Aug  1 15:14:03 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 1 Aug 2007 13:14:03 +0000 (UTC)
Subject: [Rd] the amazing prof. ripley ...
Message-ID: <loom.20070801T151214-154@post.gmane.org>

x = readLines("http://developer.r-project.org/R.svnlog.2007")
rx = x[grep("^r",x)]
who = gsub(" ","",sapply(strsplit(rx,"\\|"),"[",2))
twho = table(who)
twho["ripley"]/sum(twho)

  74% of all commits!


From bates at stat.wisc.edu  Wed Aug  1 18:13:44 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 1 Aug 2007 11:13:44 -0500
Subject: [Rd] Compiling R for the Sony Playstation 3?
Message-ID: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>

Has anyone installed Linux on a Sony Playstation 3 and compiled R for it?


From marc_schwartz at comcast.net  Wed Aug  1 18:30:21 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 01 Aug 2007 11:30:21 -0500
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
Message-ID: <1185985821.3636.19.camel@Bellerophon.localdomain>

On Wed, 2007-08-01 at 11:13 -0500, Douglas Bates wrote:
> Has anyone installed Linux on a Sony Playstation 3 and compiled R for it?

Doug,

I don't have any personal experience with both Linux and R on the PS3,
but do know folks who have run Linux successfully on that platform.

Here are some links that you might find helpful to at least cover the
first part:

http://www.playstation.com/ps3-openplatform/manual.html

http://en.wikipedia.org/wiki/Linux_for_PlayStation_3

http://www.engadget.com/2006/11/19/fedora-linux-up-and-running-on-playstation-3-with-video/


There are additional links, as usual, on the Wikipedia page.

Regards,

Marc


From whorfin at pixar.com  Wed Aug  1 20:12:34 2007
From: whorfin at pixar.com (whorfin at pixar.com)
Date: Wed,  1 Aug 2007 20:12:34 +0200 (CEST)
Subject: [Rd] Bug in TAB handling for Win32 Rterm and Rgui (PR#9820)
Message-ID: <20070801181234.1E3A66681A@slim.kubism.ku.dk>

Full_Name: Rick Sayre
Version: 2.5.1
OS: Windows XP Pro
Submission from: (NULL) (138.72.131.190)


I floated this to r-help a few days ago just to see if i was off-base.
Here we go:

Before I start, i want to first extend thanks for the big improvements
in integration of command completion for the windows version.  Really
nice to have now.  But i believe there are some issues.

In getline/getline.c, the "tab" case of the character handling switch
statement in getline() simply "break;"s to the end if tab completion is not 
enabled, thus eating the tab.  Thus, if tab completion is disabled, a tab no
longer serves as a tab; it disappears.

likewise, in console.c, if k == TABKEY, a return is done without adding 
the key to kbuf, thus TAB is always discarded, even if completion is 
disabled.

It seems to me that this is wrong.

This new TAB behavior now makes it impossible for me to copy/paste text
from a text file of R expressions which use TABs.  Copy paste behavior
which worked in 2.4.x for Rterm now does not, since the discarded TABs
mean that keyword separators may disappear, changing the meaning of
pasted text.  Rgui thankfully still works with copy/paste, since the
completion/TAB
processing code is bypassed when activating the "paste" command.  But pressing
the TAB key in Rgui with completion disabled results in the tab being eaten,
so in this sense behavior has changed in an undesireable way from previous
versions.

I'd like to request the ability to have both --- TAB as a working
separator, and the ability to configure the completion key to something
other than TAB.  This way one can both enjoy completion and successfully
copy/paste text containing tabs.

Cheers

	--Rick


From byron.ellis at gmail.com  Thu Aug  2 03:36:47 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Wed, 1 Aug 2007 18:36:47 -0700
Subject: [Rd] Wish/RFC: ReadConsoleEx
Message-ID: <7098abec0708011836l2ad4a809h451f1abe7666f795@mail.gmail.com>

Would there be any interest in a patch to introduce "ReadConsoleEx,"
analogous to the WriteConsoleEx? The idea would be to pass the prompt
type and browser level to applications implementing a user interface
to make it easier to implement features like the OS X GUI's history
feature where continue prompts are appended to the history entry
rather than generating their own entry. If so, would people prefer:

ReadConsoleEx(...,int prompt_type,int browser_level)

or

ReadConsoleEx(...,signed int prompt_type)

where 0 = normal, -1 = continue and > 0 = browser level?

-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From jmacdon at med.umich.edu  Thu Aug  2 16:02:49 2007
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Thu, 02 Aug 2007 10:02:49 -0400
Subject: [Rd] rm error on Windows after R CMD INSTALL
Message-ID: <46B1E409.4020401@med.umich.edu>

  Hi,

I seem to have buggered my windows box in such a way that R CMD INSTALL 
no longer works, and I can't figure out what is wrong (and Google 
doesn't seem to be my friend either...). When installing a package 
(doesn't matter what package), I get the following error.

installing to 'c:/R-2.5.1/library'


---------- Making package hthgu133aprobe ------------
   adding build stamp to DESCRIPTION
   installing R files
   installing data files
rm: failed to get attributes of `/': No such file or directory
make[2]: *** [c:/R-2.5.1/library/hthgu133aprobe/data] Error 1
make[1]: *** [all] Error 2
make: *** [pkg-hthgu133aprobe] Error 2
*** Installation of hthgu133aprobe failed ***

Removing 'c:/R-2.5.1/library/hthgu133aprobe'


I'm using the R tools installed via the Rtools.exe installer, have the 
Path variable set up correctly, and I don't have Cygwin installed.

Any suggestions?

Best,

Jim


-- 
James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


From ripley at stats.ox.ac.uk  Thu Aug  2 18:29:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Aug 2007 17:29:39 +0100 (BST)
Subject: [Rd] Package portability issues
Message-ID: <Pine.LNX.4.64.0708021051470.5770@gannet.stats.ox.ac.uk>

We have some new Solaris boxes (both Sparc and amd64), and as they are not 
yet in production use I borrowed some time on them to run tests over CRAN 
packages, using the Solaris make and Sun Studio compilers.  The results 
were quite depressing.  Sun Studio 12 compilers are also available for 
Linux, and there the problems are worse (for C++ code).


Line endings
============

We checked in R CMD check for CRLF line endings on C/C++/Fortran source 
files.  However, two packages have CR line endings, which apparently gcc 
accepts but no other compiler I can find.  R CMD check now checks for CR 
or CRLF line endings.

Apparently GNU make accepts makefiles with CRLF line endings, but Solaris 
make does not. 28 packages had src/Makevars[.in] or src/Makefile with CRLF 
line endings.  R CMD check now checks for this.


Fortran portability
===================

The GNU compilers have never implemented the exact Fortran standards: g77 
was said to be a 'GNU Fortran' compiler, and gfortran has '--std=legacy'. 
So they are not a good check of portability.

There is a comprehensive checker available at
http://www.dsm.fordham.edu/~ftnchek/ .  This is picky, but does pick up 
the main portability problems I found:

- the use of non-integer variables for array indices
- naming variables with the names of builtin functions.
- calling functions with the wrong argument type.

gfortran -Wall does warn on the first and you will see examples in the 
CRAN check summaries.

Although REAL*8 is non-standard it does not seem to cause any actual 
problems.


Make dialects
=============

R does not require GNU make, and if possible packages should not do so.
If your package does, please follow the example of Matrix and declare

SystemRequirements:   GNU make

in the DESCRIPTION file.  (I found 4 other instances: seems an Urbanek 
speciality.)  I think most people would have access to GNU make, but do 
need to be warned that it is needed.


Compiler flags
==============

Flags such as -Wall and -pedantic have no place in distributed Makevars.
Neither do optimization flags, nor does -Wno-conversion.

(Packages that fail because of this include Cairo, amap, gmp. 
FortranCallsR defines FFLAGS but fortunately that is always 
overridden.)


C++ issues
==========

Most of the packages using C++ failed.  Please resist the temptation to 
write C in C++: writing it in C is much more portable.  (About 40 packages 
could not be installed because of C++ issues even after changing the R 
headers.)


1) One common error message is

    An integer constant expression is required within the array subscript
    operator.

Here is an example:

         double data[(*nrow)+2*env][(*ncol)+2*env];

This affects at least packages

GammaTest MCMCpack MasterBayes clusterSim dprep edci epsi knnFinder pbatR 
rmetasim zicounts


2) Including C header files is fraught with difficulties.  Unfortunately 
that includes the R header files, because they in turn include system C 
headers.

The checking of which features were available was done using the C 
compiler with particular flags, and glibc has a habit of hiding features 
depending on the flags set.  So a C header called from the C++ compiler 
may not declare things that the same header called from the C compiler 
does.  This means that C99 features such as isfinite may not be seen from 
the C++ compiler.  (I have since modified R-devel not to use isfinite in 
packages.)

Another example (from MSBVAR)

"/usr/include/stdbool.h", line 42: Error: #error "Use of<stdbool.h> is 
valid only in a c99 compilation environment.".

In a Linux environment the Sun Studio CC compiler will not compile some 
standard C headers such as stdlib.h and math.h (and really cstdlib and 
cmath should be used).


3) Using features of particular sets of headers, e.g.

"General.h", line 3: Error: Could not open include file<map.h>.
"Scythe_Matrix.h", line 193: Error: __PRETTY_FUNCTION__ is not defined.
"mstructs.cc", line 733: Error: The function "isinf" must have a prototype.
"unf.cpp", line 459: Error: The function "finite" must have a prototype.
"matrix.h", line 142: Error: Could not open include file<stdexcep>.
"gnm.c", line 113: identifier redeclared: single
"data.cpp", line 129: Error: _Ios_Openmode is not a member of std.
"./metasim.h", line 32: Error: Could not open include file<ext/algorithm>.
"gbmentry.cpp", line 703: Error: NAN is not defined.


4) There are several instances on Solaris of things like

"GCDcrt.cpp", line 46: Error: Overloading ambiguity between 
"std::sqrt(double)" and "std::sqrt(long double)".


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From b.rowlingson at lancaster.ac.uk  Fri Aug  3 11:01:21 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 03 Aug 2007 10:01:21 +0100
Subject: [Rd] the amazing prof. ripley ...
In-Reply-To: <loom.20070801T151214-154@post.gmane.org>
References: <loom.20070801T151214-154@post.gmane.org>
Message-ID: <46B2EEE1.90208@lancaster.ac.uk>

Ben Bolker wrote:
> x = readLines("http://developer.r-project.org/R.svnlog.2007")
> rx = x[grep("^r",x)]
> who = gsub(" ","",sapply(strsplit(rx,"\\|"),"[",2))
> twho = table(who)
> twho["ripley"]/sum(twho)
> 
>   74% of all commits!

  And 99% of all 'This is not a bug/You have not read the posting guide' 
messages!

  Which is a good thing.

Barry


From gavin.simpson at ucl.ac.uk  Fri Aug  3 15:28:56 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 03 Aug 2007 14:28:56 +0100
Subject: [Rd] correct Rd markup for \value{}
Message-ID: <1186147736.30885.80.camel@gsimpson.geog.ucl.ac.uk>

Dear DevelopeRs

Several functions in a package of mine have complex returned objects
that are lists within the returned list. I wish to document each of the
components of these sublists.

If I do this within a \value{} section and nest \item within an existing
\item, I get indented R-help sections in the standard help view (eg as
shown by ?foo in Linux), but not in the PDF.

For example:

\item{model}{a list containing the model or non-bootstrapped
    estimates for the training set. With the following components:
      \item{\code{estimated}}{estimated values for \code{"y"}, the
	environment.}
    }
  }

If I add an \itemize (for example:

\item{model}{a list containing the model or non-bootstrapped
    estimates for the training set. With the following components:
    % added \itemize
    \itemize{
      \item{\code{estimated}}{estimated values for \code{"y"}, the
	environment.}
    }
  }

) then these are indented in both the ?foo help and the pdf.

But this has several niggles;:

     1. that the indented \item labels are not left aligned as the top
        level \items are, 
     2. as shown above, I have to manually wrap the labels in \code{ }
        to have them show in typewriter font in the pdf pages (but then
        these appear underlined and wrapped in ' ' in the standard view
        in the terminal), and
     3. that in the standard help viewer in the terminal, I don't get
        the ":" after the sub item labels.

I suspect I'm missing something or trying to do something that is not
possible without the niggles.  I'd appreciate suggestions as to where
I'm going wrong, what documentation I missed or suggestions based on the
experience of others.

Thanks in advance,

G

> version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Patched
major          2
minor          5.1
year           2007
month          07
day            05
svn rev        42131
language       R
version.string R version 2.5.1 Patched (2007-07-05 r42131)

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From bates at stat.wisc.edu  Fri Aug  3 15:52:35 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Aug 2007 08:52:35 -0500
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <1185985821.3636.19.camel@Bellerophon.localdomain>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
Message-ID: <40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>

On 8/1/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
> On Wed, 2007-08-01 at 11:13 -0500, Douglas Bates wrote:
> > Has anyone installed Linux on a Sony Playstation 3 and compiled R for it?

> Doug,
>
> I don't have any personal experience with both Linux and R on the PS3,
> but do know folks who have run Linux successfully on that platform.
>
> Here are some links that you might find helpful to at least cover the
> first part:
>
> http://www.playstation.com/ps3-openplatform/manual.html
>
> http://en.wikipedia.org/wiki/Linux_for_PlayStation_3
>
> http://www.engadget.com/2006/11/19/fedora-linux-up-and-running-on-playstation-3-with-video/
>
>
> There are additional links, as usual, on the Wikipedia page.

I did successfully install Ubuntu 7.04 ("feisty") on a Playstation 3.
Once you have Ubuntu installed you can use the standard package
management tools for Debian/Ubuntu to install the r-base-core,
r-recommended and r-base-dev packages.  Those packages are for R-2.4.1
but I had no trouble installing and checking the most recent versions
of R from the SVN site.

Essentially the Playstation 3 becomes a typical Ubuntu system with all
the tools from Ubuntu.  At present X11 uses the framebuffer device so
the graphics is poor by X11 standards and very poor by gamer's
standards.

Overall it is quite amazing given that the PS3 with a 60GB hard drive
is now being sold in the U.S. for $500 and that includes a Blu-ray DVD
drive and full 1080p HDMI interface.  At $500 it is one of the
cheapest Blu-ray DVD players, which is what I bought it for.  It's
great to be able to run R on my DVD player.


From bates at stat.wisc.edu  Fri Aug  3 16:00:36 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Aug 2007 09:00:36 -0500
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
Message-ID: <40e66e0b0708030700u40bfb766hf2454d48e427b313@mail.gmail.com>

P.S. A site with instructions for installing Ubuntu on the PS3 is
psubuntu.com or google "PS3 Ubuntu" to get the community pages
documentation.

It is a good idea to have an Ethernet connection so that once you
install from the CD you can upgrade the packages.  The kernel on the
installation CD image has a known bug that causes it to flood the
system log with messages about querying the memory card readers.  You
want to replace that kernel with a later version.

The processor is apparently a 3.2 GHz dual-core PowerPC-64.  It
doesn't feel as fast as I expected but that could be because of memory
bandwidth (256 MB of memory plus 256 MB of graphics memory that isn't
used by Linux at present) or disk access.  However, it still runs R
faster than any other DVD player I have ever had.


From elw at stderr.org  Fri Aug  3 16:09:59 2007
From: elw at stderr.org (elw at stderr.org)
Date: Fri, 3 Aug 2007 09:09:59 -0500 (CDT)
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>



I've been working off-and-on for a few months on devising some patches to 
R to make it much happier with a Cell processor;  to be honest I've not 
had much time to work at it lately.

Douglas is right that it is mostly a PPC64 sort of architecture; taking 
real advantage of the hardware is going to require support for a different 
BLAS (that knows how to handle the SPUs...) be patched into R's configure 
scripts.

Beyond that, there may be a few more things that can be done to make R run 
"stupidly fast" on ps3 or IBM Cell blades.

--e


On Fri, 3 Aug 2007, Douglas Bates wrote:

> Date: Fri, 3 Aug 2007 08:52:35 -0500
> From: Douglas Bates <bates at stat.wisc.edu>
> To: marc_schwartz at comcast.net
> Cc: R-devel List <r-devel at r-project.org>
> Subject: Re: [Rd] Compiling R for the Sony Playstation 3?
> 
> On 8/1/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
>> On Wed, 2007-08-01 at 11:13 -0500, Douglas Bates wrote:
>>> Has anyone installed Linux on a Sony Playstation 3 and compiled R for it?
>
>> Doug,
>>
>> I don't have any personal experience with both Linux and R on the PS3,
>> but do know folks who have run Linux successfully on that platform.
>>
>> Here are some links that you might find helpful to at least cover the
>> first part:
>>
>> http://www.playstation.com/ps3-openplatform/manual.html
>>
>> http://en.wikipedia.org/wiki/Linux_for_PlayStation_3
>>
>> http://www.engadget.com/2006/11/19/fedora-linux-up-and-running-on-playstation-3-with-video/
>>
>>
>> There are additional links, as usual, on the Wikipedia page.
>
> I did successfully install Ubuntu 7.04 ("feisty") on a Playstation 3. 
> Once you have Ubuntu installed you can use the standard package 
> management tools for Debian/Ubuntu to install the r-base-core, 
> r-recommended and r-base-dev packages.  Those packages are for R-2.4.1 
> but I had no trouble installing and checking the most recent versions of 
> R from the SVN site.
>
> Essentially the Playstation 3 becomes a typical Ubuntu system with all 
> the tools from Ubuntu.  At present X11 uses the framebuffer device so 
> the graphics is poor by X11 standards and very poor by gamer's 
> standards.
>
> Overall it is quite amazing given that the PS3 with a 60GB hard drive is 
> now being sold in the U.S. for $500 and that includes a Blu-ray DVD 
> drive and full 1080p HDMI interface.  At $500 it is one of the cheapest 
> Blu-ray DVD players, which is what I bought it for.  It's great to be 
> able to run R on my DVD player.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bates at stat.wisc.edu  Fri Aug  3 18:32:55 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Aug 2007 11:32:55 -0500
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <46B34FF4.9090505@bank-banque-canada.ca>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
	<40e66e0b0708030700u40bfb766hf2454d48e427b313@mail.gmail.com>
	<46B34FF4.9090505@bank-banque-canada.ca>
Message-ID: <40e66e0b0708030932i17b4388csd1f6016f79939777@mail.gmail.com>

On 8/3/07, Paul Gilbert <pgilbert at bank-banque-canada.ca> wrote:
> Doug

> Does it still play DVDs?

> (My wife keeps telling me that academics have to do all their serious
> work in the summer.)

The way that you install Linux on a PS3 it becomes a dual-boot
machine.  You have to reboot to the original operating system (called
XBM) to play DVD's at present.

Sony made provision for a second operating system to be installed on
the hard drive.  In the 'out-of-the-box' state there is a selection
under the 'System settings' that allows you to reformat the hard drive
with two partitions.  Unfortunately they only offer two possibilities
- either 10 Gb for XBM, 50 Gb for other or 50 Gb for XBM and 10 Gb for
other.  Reformatting does destroy any saved data but there is
provision for saving and restoring such data from a SD memory card or
a USB device.  Reformatting does not destroy the XBM operating system
(I believe it is stored in flash memory).

After reformatting the hard drive you insert the installation CD,
select "Install other OS"  from the System Settings and sit back and
watch the installation.

Once you install Linux the system boots to a boot loader called kboot.
 If you type boot-game-os at the kboot prompt you end up in XBM and
can play DVD's to your heart's content (I understand that you can also
play video games with it :-)

By the way, you can buy a remote control for the PS3 as a DVD player
but you don't need to have it.  You can use the game controller as a
DVD remote and I actually prefer it to having yet another remote
control with 85 buttons of which I use 2 and can never decide which 2
those are without turning on a light and getting reading glasses out.
The game remote is intended to be operated without looking at it and
all the feedback is on the screen.  It doesn't take long to become
proficient with it.


From b.rowlingson at lancaster.ac.uk  Fri Aug  3 18:55:49 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 03 Aug 2007 17:55:49 +0100
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>	<1185985821.3636.19.camel@Bellerophon.localdomain>	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
	<Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>
Message-ID: <46B35E15.2050506@lancaster.ac.uk>

elw at stderr.org wrote:

> Beyond that, there may be a few more things that can be done to make R run 
> "stupidly fast" on ps3 or IBM Cell blades.
> 

  Wouldn't the right way to go here be to make it use the PS3 graphics 
hardware, in a http://www.gpgpu.org/ kind of way? Or are the Cell 
processors on the PS3 graphics processors too?

  Of course if you are doing this for fun I'd like to see a Nintendo Wii 
port, just so I can play Super Mario Generalised Linear Modelling by 
waving the controller around.

Barry


From mgd at santafe.edu  Fri Aug  3 20:57:09 2007
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Fri, 03 Aug 2007 12:57:09 -0600
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <46B35E15.2050506@lancaster.ac.uk>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>	<1185985821.3636.19.camel@Bellerophon.localdomain>	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>	<Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>
	<46B35E15.2050506@lancaster.ac.uk>
Message-ID: <46B37A85.3050200@santafe.edu>

Hi,
>> Beyond that, there may be a few more things that can be done to make R run 
>> "stupidly fast" on ps3 or IBM Cell blades.
>>
>>     
>
>   Wouldn't the right way to go here be to make it use the PS3 graphics 
> hardware, in a http://www.gpgpu.org/ kind of way? Or are the Cell 
> processors on the PS3 graphics processors too?
>   
The Cell can be thought as a mini cluster on a chip.  It uses messaging 
along the lines of the way one might program a distributed application 
using MPI, or organize a program for remote procedure calls.    However 
the latency is about 5 nanoseconds instead of 5 microseconds (as one 
might hope to get with typical high performance networking fabrics).  
Applications for the Cell are typically multithreaded on the PPU 
controlling synchronous, non-timeshared activity on the SPUs. 

The PS3 primary processor, the Celll PPU, is on the same silicon as the 
coprocessors, the SPUs.  The PPU is basically like what's in a Mac G5.  
The SPUs have less smarts in terms of out of order execution lookahead 
and they have only 256K local store.   Messaging is done using a DMA 
controller, and there are some C routines for that.   Newer versions of 
the GNU toolchain have an overlay manager so that the 256K localstore 
can be automatically managed for the most part. 
The SPUs instruction set is new, but GCC has a cross compiler that works 
fine for it.  

I think a lot of the work to make R take advantage of the Cell would be 
pretty general, e.g. localizing the scope of operations and making 
operations multithreaded...  It's desirable to keep computations on the 
local store as much as possible, but it doesn't seem to be crucial.   
The messaging is extremely fast.   It's almost like worrying about 
processor affinity on a SMP system.   Also, there's more need to profile 
and optimize the operations on the SPUs as they are dumb compared to a 
modern microprocessor (e.g. by explicit prefetching)

One nuisance with the PS3 itself (as opposed to IBM blades) is the 
limited RAM.   There's only 256MB.   It's pretty painful to bootstrap 
GCC, for example.
The RAM itself (Rambus XDR) is several times faster latency-wise than 
DDR2. 

Marcus


From michael at frumin.net  Fri Aug  3 13:06:14 2007
From: michael at frumin.net (mfrumin)
Date: Fri, 3 Aug 2007 04:06:14 -0700 (PDT)
Subject: [Rd] O(?) access time for rownames/colnames/named dimensions
Message-ID: <11981293.post@talk.nabble.com>


Dear princely R developers to whom I owe so much of my daily productivity
level,

I am wondering how indexing by row and column names are implemented.  That
is, when I have a matrix with named rows (or columns) and I then index into
that matrix using the string names (rather than integers), how does R scan
through the list of names in order to figure out which row/column to use? 
My current suspicion is that it's a linear search, but I've been wrong many
times before.

If it is linear, may I ask if the possibility of implementing the
name-to-integer-index lookup in a more efficient way as ever been discussed? 
For example, why not hash the string indexes to quickly map them to integer
indexes?

Of course adding this sort of functionality would make it somewhat more
expensive to add rows/columns anywhere but the end of the matrix, but in
many cases I suspect it would be worth it.  Or perhaps there would be a way
to enable this selectively on each named dimension?

In my use case, I am building an array with named dimensions once, and then
doing lots of reading/updates into that matrix without changing its shape. 
This is proving to be rather costly at the moment and I've taken to using a
hashed environment to do lookups where it really counts, but this is rather
inconvenient.

I'm sure this has been thought about before, but I didn't see anything in
this mailing list.

Thanks,
Michael
-- 
View this message in context: http://www.nabble.com/O%28-%29-access-time-for-rownames-colnames-named-dimensions-tf4211918.html#a11981293
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Fri Aug  3 22:14:45 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Aug 2007 21:14:45 +0100 (BST)
Subject: [Rd] O(?) access time for rownames/colnames/named dimensions
In-Reply-To: <11981293.post@talk.nabble.com>
References: <11981293.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0708032105440.29811@gannet.stats.ox.ac.uk>

On Fri, 3 Aug 2007, mfrumin wrote:

>
> Dear princely R developers to whom I owe so much of my daily productivity
> level,
>
> I am wondering how indexing by row and column names are implemented.  That
> is, when I have a matrix with named rows (or columns) and I then index into
> that matrix using the string names (rather than integers), how does R scan
> through the list of names in order to figure out which row/column to use?
> My current suspicion is that it's a linear search, but I've been wrong many
> times before.
>
> If it is linear, may I ask if the possibility of implementing the
> name-to-integer-index lookup in a more efficient way as ever been discussed?
> For example, why not hash the string indexes to quickly map them to integer
> indexes?

We do, for large enough indices.  From ONEWS

     o	Indexing a vector by a character vector was slow if both the
 	vector and index were long (say 10,000).  Now hashing is used
 	and the time should be linear in the longer of the lengths
 	(but more memory is used).

See src/main/subscript.c (the code is also used for array dimensions).

The hash table is not kept, since repeated lookups are not common (R is a 
vectorized language).

> Of course adding this sort of functionality would make it somewhat more
> expensive to add rows/columns anywhere but the end of the matrix, but in
> many cases I suspect it would be worth it.  Or perhaps there would be a way
> to enable this selectively on each named dimension?
>
> In my use case, I am building an array with named dimensions once, and then
> doing lots of reading/updates into that matrix without changing its shape.
> This is proving to be rather costly at the moment and I've taken to using a
> hashed environment to do lookups where it really counts, but this is rather
> inconvenient.
>
> I'm sure this has been thought about before, but I didn't see anything in
> this mailing list.
>
> Thanks,
> Michael
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From clausen at econ.upenn.edu  Sat Aug  4 07:12:31 2007
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Sat, 4 Aug 2007 01:12:31 -0400
Subject: [Rd] Optimization in R
Message-ID: <20070804051231.GB3016@econ.upenn.edu>

Hi all,

I've been working on improving R's optim() command, which does general purpose
unconstrained optimization.  Obviously, this is important for many statistics
computations, such as maximum likelihood, method of moments, etc.  I have
focused my efforts of the BFGS method, mainly because it best matches my
current projects.

Here's a quick summary of what I've done:
 * implemented my own version of BFGS in R,
	http://www.econ.upenn.edu/~clausen/computing/bfgs.zip
 * written a wrapper for the GNU Scientific Library's optimization function,
multimin(),
	http://www.econ.upenn.edu/~clausen/computing/multimin.zip
 * written some tricky functions to compare implementations,
	http://www.econ.upenn.edu/~clausen/computing/tests.zip

My own implementation has several advantages over optim()'s implementation
(which you can see in the vmmin() function in
	https://svn.r-project.org/R/trunk/src/main/optim.c)
 * the linesearch algorithm (More-Thuente) quickly finds a region of interest
to zoom into.  Moreover, it strikes a much better balance between finding
a point that adequately improves upon the old point, but doesn't waste too
much time finding a much better point.  (Unlike optim(), it uses the standard
Wolfe conditions with weak parameters.)
 * the linesearch algorithm uses interpolation, so it finds an acceptable
point more quickly.
 * implements "box" constraints.
 * easier to understand and modify the code, partly because it's written in R.

Of course, this comes at the (slight?) overhead cost of being written in R.

The test suite above takes the first few functions from the paper

        Mor??, Garbow, and Hillstrom, "Testing Unconstrained
        Optimization Software", ACM Trans Math Softw 7:1 (March 1981)

The test results appear below, where "*" means "computed the right solution",
and "!" means "got stuck".

test                    optim           clausen         gsl
--------------------------------------------------------------
bard                                                    !
beale
brown-scaled
freudenstein-roth
gaussian                                                *
helical-valley          *               *
jennrich-sampson                                        *
meyer                                                   *
powell-scaled                           *
rosenbrock                              *

The table indiciates that all three implementations of BFGS failed to compute
the right answer in most cases.  I suppose this means they are all quite
deficient.  Of course, this doesn't imply that they perform badly on real
statistics problems -- but in my limited experience with my crude econometric
models, they do perform badly.   Indeed, that's why I started investigating in
the first place.

For what it's worth, I think:
 * the optimization algorithms should be written in R -- the overhead is
small compared to the cost of evaluating likelihood functions anyway, and is
easily made up by the better algorithms that are possible.
 * it would be useful to keep a repository of interesting optimization
problems relevant to R users.  Then R developers can evaluate "improvements".

Cheers,
Andrew


From murdoch at stats.uwo.ca  Sat Aug  4 15:25:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Aug 2007 09:25:39 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <20070804051231.GB3016@econ.upenn.edu>
References: <20070804051231.GB3016@econ.upenn.edu>
Message-ID: <46B47E53.2040801@stats.uwo.ca>

On 04/08/2007 1:12 AM, Andrew Clausen wrote:
> Hi all,
> 
> I've been working on improving R's optim() command, which does general purpose
> unconstrained optimization.  Obviously, this is important for many statistics
> computations, such as maximum likelihood, method of moments, etc.  I have
> focused my efforts of the BFGS method, mainly because it best matches my
> current projects.
> 
> Here's a quick summary of what I've done:
>  * implemented my own version of BFGS in R,
> 	http://www.econ.upenn.edu/~clausen/computing/bfgs.zip
>  * written a wrapper for the GNU Scientific Library's optimization function,
> multimin(),
> 	http://www.econ.upenn.edu/~clausen/computing/multimin.zip
>  * written some tricky functions to compare implementations,
> 	http://www.econ.upenn.edu/~clausen/computing/tests.zip
> 
> My own implementation has several advantages over optim()'s implementation
> (which you can see in the vmmin() function in
> 	https://svn.r-project.org/R/trunk/src/main/optim.c)
>  * the linesearch algorithm (More-Thuente) quickly finds a region of interest
> to zoom into.  Moreover, it strikes a much better balance between finding
> a point that adequately improves upon the old point, but doesn't waste too
> much time finding a much better point.  (Unlike optim(), it uses the standard
> Wolfe conditions with weak parameters.)
>  * the linesearch algorithm uses interpolation, so it finds an acceptable
> point more quickly.
>  * implements "box" constraints.
>  * easier to understand and modify the code, partly because it's written in R.
> 
> Of course, this comes at the (slight?) overhead cost of being written in R.
> 
> The test suite above takes the first few functions from the paper
> 
>         Mor?, Garbow, and Hillstrom, "Testing Unconstrained
>         Optimization Software", ACM Trans Math Softw 7:1 (March 1981)
> 
> The test results appear below, where "*" means "computed the right solution",
> and "!" means "got stuck".
> 
> test                    optim           clausen         gsl
> --------------------------------------------------------------
> bard                                                    !
> beale
> brown-scaled
> freudenstein-roth
> gaussian                                                *
> helical-valley          *               *
> jennrich-sampson                                        *
> meyer                                                   *
> powell-scaled                           *
> rosenbrock                              *
> 
> The table indiciates that all three implementations of BFGS failed to compute
> the right answer in most cases.  I suppose this means they are all quite
> deficient.  Of course, this doesn't imply that they perform badly on real
> statistics problems -- but in my limited experience with my crude econometric
> models, they do perform badly.   Indeed, that's why I started investigating in
> the first place.
> 
> For what it's worth, I think:
>  * the optimization algorithms should be written in R -- the overhead is
> small compared to the cost of evaluating likelihood functions anyway, and is
> easily made up by the better algorithms that are possible.
>  * it would be useful to keep a repository of interesting optimization
> problems relevant to R users.  Then R developers can evaluate "improvements".

This is interesting work; thanks for doing it.  Could I make a 
suggestion?  Why not put together a package containing those test 
optimization problems, and offer to include other interesting ones as 
they arise?  You could also include your wrapper for the gsl function 
and your own improvements to optim.

On your first point:  I agree that a prototype implementation in R makes 
sense, but I suspect there exist problems where the overhead would not 
be negligible (e.g. ones where the user has written the objective 
function in C for speed).  So I think you should keep in mind the 
possibility of moving the core of your improvements to C once you are 
happy with them.

Duncan Murdoch

P.S. I dropped the help-gsl mailing list from the distribution, since my 
post is mainly about R.


From clausen at econ.upenn.edu  Sat Aug  4 16:02:20 2007
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Sat, 4 Aug 2007 10:02:20 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B4400D.6000908@pburns.seanet.com>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B4400D.6000908@pburns.seanet.com>
Message-ID: <20070804140220.GB16431@econ.upenn.edu>

Hi Pat,

On Sat, Aug 04, 2007 at 09:59:57AM +0100, Patrick Burns wrote:
> Sounds like a good project.

Thanks :)

> How much extra overhead are you getting from the
> algorithm being in R?

On the Rosenbrock function (which is very quick to evaluate), here are the
system.time() results:

> system.time(bfgs(x0, f, g))
[1] 0.148 0.000 0.149 0.000 0.000
> system.time(optim(x0, f, g, method="BFGS"))
[1] 0.008 0.000 0.008 0.000 0.000

and the function evaluation counts:

> bfgs(x0, f, g)$counts
function gradient 
      95       58 
> optim(x0, f, g, method="BFGS")$counts
function gradient 
     318      100 

So the overhead is clearly much bigger, but still too small to matter for
most (?) applications.

Cheers,
Andrew

PS, my computer is a "Intel(R) Pentium(R) 4 CPU 2.80GHz" with a
1024 KB cache, according to /proc/cpuinfo.


From clausen at econ.upenn.edu  Sat Aug  4 16:30:32 2007
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Sat, 4 Aug 2007 10:30:32 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B47E53.2040801@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
Message-ID: <20070804143032.GC16431@econ.upenn.edu>

Hi Duncan,

On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
> This is interesting work; thanks for doing it.  Could I make a 
> suggestion?  Why not put together a package containing those test 
> optimization problems, and offer to include other interesting ones as 
> they arise?

Good idea.

> You could also include your wrapper for the gsl function 
> and your own improvements to optim.

I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
which seems to be the "right" place for it.  (Its maintainer is currently
enjoying a vacation :)

It would be nice if all of these methods could be accessed with the existing
optim() interface, so that users could easily try different algorithms.
That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
Is there a convenient mechanism for packages registering new methods?

One incompatibility with my BFGS implementation is that it returns the
*inverse* Hessian, which is a natural by-product of the BFGS algorithm.
Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
and discards it!  (Disclaimer: as far as I know, there are no theorems that say
that BFGS's inverse Hessians are any good.  In practice, they seem to be.)

The inverse Hessian is more useful than the Hessian for statistics because it
gives the variance-covariance matrix for maximum likelihood estimators.  When
the Hessian is close to being singular (aka "computationally singular"),
solve() sometimes fails to invert it.

I think this means we should change the optim() interface.  For example, an
extra logical parameter, "inv.hessian" could control whether an inv.hessian
matrix is returned.

> On your first point:  I agree that a prototype implementation in R makes 
> sense, but I suspect there exist problems where the overhead would not 
> be negligible (e.g. ones where the user has written the objective 
> function in C for speed).  So I think you should keep in mind the 
> possibility of moving the core of your improvements to C once you are 
> happy with them.

Fair enough.

Cheers,
Andrew


From nikko at hailmail.net  Sat Aug  4 17:10:29 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sat, 04 Aug 2007 11:10:29 -0400
Subject: [Rd]  Optimization in R
In-Reply-To: <mailman.9.1186221605.6064.r-devel@r-project.org>
References: <mailman.9.1186221605.6064.r-devel@r-project.org>
Message-ID: <1186240229.20246.1203727153@webmail.messagingengine.com>



Hi Andrew,
I have been working quite a bit with optim and friends on automated
nonlinear fitting, mainly for calibration. All of the optimizers
seem to have trouble in the tricky situation of fitting a log-logistic 
model when the upper asymptote is not well defined, and trying to
estimate a variance
parameter. Granted this is not necessarily the optimizer, but a
combination
of objective function, convergence criteria, scaling, ... 
But my point is that for automated fitting where many starting values,
iterations with
pseudo likelihood for the variance function, over multiple curves, the
overhead of
the function written in R vs C can become non-negligible for "simple"
univariate functions. 
So I have to agree with Duncan, that R is very good for prototyping but
C would be preferable.

I can contribute some "hard" problems if you start the package.

Nicholas
> Date: Sat, 4 Aug 2007 01:12:31 -0400
> From: Andrew Clausen <clausen at econ.upenn.edu>
> Subject: [Rd] Optimization in R
> To: r-devel at r-project.org
> Cc: help-gsl at gnu.org
> Message-ID: <20070804051231.GB3016 at econ.upenn.edu>
> Content-Type: text/plain; charset=unknown-8bit
> 
> Hi all,
> 
> I've been working on improving R's optim() command, which does general
> purpose
> unconstrained optimization.  Obviously, this is important for many
> statistics
> computations, such as maximum likelihood, method of moments, etc.  I have
> focused my efforts of the BFGS method, mainly because it best matches my
> current projects.
> 
> Here's a quick summary of what I've done:
>  * implemented my own version of BFGS in R,
> 	http://www.econ.upenn.edu/~clausen/computing/bfgs.zip
>  * written a wrapper for the GNU Scientific Library's optimization
>  function,
> multimin(),
> 	http://www.econ.upenn.edu/~clausen/computing/multimin.zip
>  * written some tricky functions to compare implementations,
> 	http://www.econ.upenn.edu/~clausen/computing/tests.zip
> 
> My own implementation has several advantages over optim()'s
> implementation
> (which you can see in the vmmin() function in
> 	https://svn.r-project.org/R/trunk/src/main/optim.c)
>  * the linesearch algorithm (More-Thuente) quickly finds a region of
>  interest
> to zoom into.  Moreover, it strikes a much better balance between finding
> a point that adequately improves upon the old point, but doesn't waste
> too
> much time finding a much better point.  (Unlike optim(), it uses the
> standard
> Wolfe conditions with weak parameters.)
>  * the linesearch algorithm uses interpolation, so it finds an acceptable
> point more quickly.
>  * implements "box" constraints.
>  * easier to understand and modify the code, partly because it's written
>  in R.
> 
> Of course, this comes at the (slight?) overhead cost of being written in
> R.
> 
> The test suite above takes the first few functions from the paper
> 
>         Mor??, Garbow, and Hillstrom, "Testing Unconstrained
>         Optimization Software", ACM Trans Math Softw 7:1 (March 1981)
> 
> The test results appear below, where "*" means "computed the right
> solution",
> and "!" means "got stuck".
> 
> test                    optim           clausen         gsl
> --------------------------------------------------------------
> bard                                                    !
> beale
> brown-scaled
> freudenstein-roth
> gaussian                                                *
> helical-valley          *               *
> jennrich-sampson                                        *
> meyer                                                   *
> powell-scaled                           *
> rosenbrock                              *
> 
> The table indiciates that all three implementations of BFGS failed to
> compute
> the right answer in most cases.  I suppose this means they are all quite
> deficient.  Of course, this doesn't imply that they perform badly on real
> statistics problems -- but in my limited experience with my crude
> econometric
> models, they do perform badly.   Indeed, that's why I started
> investigating in
> the first place.
> 
> For what it's worth, I think:
>  * the optimization algorithms should be written in R -- the overhead is
> small compared to the cost of evaluating likelihood functions anyway, and
> is
> easily made up by the better algorithms that are possible.
>  * it would be useful to keep a repository of interesting optimization
> problems relevant to R users.  Then R developers can evaluate
> "improvements".
> 
> Cheers,
> Andrew
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-devel at r-project.org mailing list  DIGESTED
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> End of R-devel Digest, Vol 54, Issue 4
> **************************************


From murdoch at stats.uwo.ca  Sat Aug  4 17:57:52 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Aug 2007 11:57:52 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <20070804143032.GC16431@econ.upenn.edu>
References: <20070804051231.GB3016@econ.upenn.edu>	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu>
Message-ID: <46B4A200.10109@stats.uwo.ca>

On 04/08/2007 10:30 AM, Andrew Clausen wrote:
> Hi Duncan,
> 
> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
>> This is interesting work; thanks for doing it.  Could I make a 
>> suggestion?  Why not put together a package containing those test 
>> optimization problems, and offer to include other interesting ones as 
>> they arise?
> 
> Good idea.
> 
>> You could also include your wrapper for the gsl function 
>> and your own improvements to optim.
> 
> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
> which seems to be the "right" place for it.  (Its maintainer is currently
> enjoying a vacation :)
> 
> It would be nice if all of these methods could be accessed with the existing
> optim() interface, so that users could easily try different algorithms.
> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
> Is there a convenient mechanism for packages registering new methods?

No there isn't, but I don't really see it as necessary.  The R optim() 
function is reasonably short, mainly setting up defaults specific to 
each of the supported optimization methods.  The C do_optim() function 
has a bit more code common to the methods, but still only about 50 
lines. You could copy this common part into your own function following 
the same argument and return value conventions and a user would just 
need to change the function name in addition to specifying your method, 
not really that much harder.  (You could call your function optim and 
use it as a wrapper for stats::optim if you wanted to avoid even this, 
but I wouldn't recommend it, since then behaviour would depend on the 
search list ordering.)

There's a small risk that the argument list to optim() will change 
incompatibly sometime in the future, but I think that's unlikely.

> One incompatibility with my BFGS implementation is that it returns the
> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)

If you return more than optim() returns it shouldn't have any serious 
ill effects.

> The inverse Hessian is more useful than the Hessian for statistics because it
> gives the variance-covariance matrix for maximum likelihood estimators.  When
> the Hessian is close to being singular (aka "computationally singular"),
> solve() sometimes fails to invert it.
> 
> I think this means we should change the optim() interface.  For example, an
> extra logical parameter, "inv.hessian" could control whether an inv.hessian
> matrix is returned.

I'd suggest always returning it if it's useful and the calculation is 
reliable and cheap.  Adding "inv.hessian" as a general parameter would 
be troublesome with some of the other methods, where the inverse Hessian 
isn't already calculated, because of the inversion problem you mention 
above.

Duncan Murdoch

> 
>> On your first point:  I agree that a prototype implementation in R makes 
>> sense, but I suspect there exist problems where the overhead would not 
>> be negligible (e.g. ones where the user has written the objective 
>> function in C for speed).  So I think you should keep in mind the 
>> possibility of moving the core of your improvements to C once you are 
>> happy with them.
> 
> Fair enough.
> 
> Cheers,
> Andrew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Aug  4 19:05:15 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Aug 2007 13:05:15 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B4A200.10109@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu> <46B4A200.10109@stats.uwo.ca>
Message-ID: <971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>

I think it would be desirable for optim to have a dispatching mechanism
that allows users to add their own optimization techniques to those
provided without having to modify optim and without having to come
up with a new visible function.  For example, if we call optim as
optim(...whatever..., method = "X") then that might dispatch
optim.X consistent with S3 except here X is explicitly given rather
than being a class.

On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
> > Hi Duncan,
> >
> > On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
> >> This is interesting work; thanks for doing it.  Could I make a
> >> suggestion?  Why not put together a package containing those test
> >> optimization problems, and offer to include other interesting ones as
> >> they arise?
> >
> > Good idea.
> >
> >> You could also include your wrapper for the gsl function
> >> and your own improvements to optim.
> >
> > I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
> > which seems to be the "right" place for it.  (Its maintainer is currently
> > enjoying a vacation :)
> >
> > It would be nice if all of these methods could be accessed with the existing
> > optim() interface, so that users could easily try different algorithms.
> > That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
> > Is there a convenient mechanism for packages registering new methods?
>
> No there isn't, but I don't really see it as necessary.  The R optim()
> function is reasonably short, mainly setting up defaults specific to
> each of the supported optimization methods.  The C do_optim() function
> has a bit more code common to the methods, but still only about 50
> lines. You could copy this common part into your own function following
> the same argument and return value conventions and a user would just
> need to change the function name in addition to specifying your method,
> not really that much harder.  (You could call your function optim and
> use it as a wrapper for stats::optim if you wanted to avoid even this,
> but I wouldn't recommend it, since then behaviour would depend on the
> search list ordering.)
>
> There's a small risk that the argument list to optim() will change
> incompatibly sometime in the future, but I think that's unlikely.
>
> > One incompatibility with my BFGS implementation is that it returns the
> > *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
> > Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
> > and discards it!  (Disclaimer: as far as I know, there are no theorems that say
> > that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
>
> If you return more than optim() returns it shouldn't have any serious
> ill effects.
>
> > The inverse Hessian is more useful than the Hessian for statistics because it
> > gives the variance-covariance matrix for maximum likelihood estimators.  When
> > the Hessian is close to being singular (aka "computationally singular"),
> > solve() sometimes fails to invert it.
> >
> > I think this means we should change the optim() interface.  For example, an
> > extra logical parameter, "inv.hessian" could control whether an inv.hessian
> > matrix is returned.
>
> I'd suggest always returning it if it's useful and the calculation is
> reliable and cheap.  Adding "inv.hessian" as a general parameter would
> be troublesome with some of the other methods, where the inverse Hessian
> isn't already calculated, because of the inversion problem you mention
> above.
>
> Duncan Murdoch
>
> >
> >> On your first point:  I agree that a prototype implementation in R makes
> >> sense, but I suspect there exist problems where the overhead would not
> >> be negligible (e.g. ones where the user has written the objective
> >> function in C for speed).  So I think you should keep in mind the
> >> possibility of moving the core of your improvements to C once you are
> >> happy with them.
> >
> > Fair enough.
> >
> > Cheers,
> > Andrew
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sat Aug  4 20:17:22 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Aug 2007 14:17:22 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
References: <20070804051231.GB3016@econ.upenn.edu>	<46B47E53.2040801@stats.uwo.ca>	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
Message-ID: <46B4C2B2.3030109@stats.uwo.ca>

On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
> I think it would be desirable for optim to have a dispatching mechanism
> that allows users to add their own optimization techniques to those
> provided without having to modify optim and without having to come
> up with a new visible function.  For example, if we call optim as
> optim(...whatever..., method = "X") then that might dispatch
> optim.X consistent with S3 except here X is explicitly given rather
> than being a class.

Why?  This would make sense if optim() had a lot of code common to all 
methods, but it doesn't.

Duncan Murdoch

> 
> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
>>> Hi Duncan,
>>>
>>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
>>>> This is interesting work; thanks for doing it.  Could I make a
>>>> suggestion?  Why not put together a package containing those test
>>>> optimization problems, and offer to include other interesting ones as
>>>> they arise?
>>> Good idea.
>>>
>>>> You could also include your wrapper for the gsl function
>>>> and your own improvements to optim.
>>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
>>> which seems to be the "right" place for it.  (Its maintainer is currently
>>> enjoying a vacation :)
>>>
>>> It would be nice if all of these methods could be accessed with the existing
>>> optim() interface, so that users could easily try different algorithms.
>>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
>>> Is there a convenient mechanism for packages registering new methods?
>> No there isn't, but I don't really see it as necessary.  The R optim()
>> function is reasonably short, mainly setting up defaults specific to
>> each of the supported optimization methods.  The C do_optim() function
>> has a bit more code common to the methods, but still only about 50
>> lines. You could copy this common part into your own function following
>> the same argument and return value conventions and a user would just
>> need to change the function name in addition to specifying your method,
>> not really that much harder.  (You could call your function optim and
>> use it as a wrapper for stats::optim if you wanted to avoid even this,
>> but I wouldn't recommend it, since then behaviour would depend on the
>> search list ordering.)
>>
>> There's a small risk that the argument list to optim() will change
>> incompatibly sometime in the future, but I think that's unlikely.
>>
>>> One incompatibility with my BFGS implementation is that it returns the
>>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
>>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
>>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
>>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
>> If you return more than optim() returns it shouldn't have any serious
>> ill effects.
>>
>>> The inverse Hessian is more useful than the Hessian for statistics because it
>>> gives the variance-covariance matrix for maximum likelihood estimators.  When
>>> the Hessian is close to being singular (aka "computationally singular"),
>>> solve() sometimes fails to invert it.
>>>
>>> I think this means we should change the optim() interface.  For example, an
>>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
>>> matrix is returned.
>> I'd suggest always returning it if it's useful and the calculation is
>> reliable and cheap.  Adding "inv.hessian" as a general parameter would
>> be troublesome with some of the other methods, where the inverse Hessian
>> isn't already calculated, because of the inversion problem you mention
>> above.
>>
>> Duncan Murdoch
>>
>>>> On your first point:  I agree that a prototype implementation in R makes
>>>> sense, but I suspect there exist problems where the overhead would not
>>>> be negligible (e.g. ones where the user has written the objective
>>>> function in C for speed).  So I think you should keep in mind the
>>>> possibility of moving the core of your improvements to C once you are
>>>> happy with them.
>>> Fair enough.
>>>
>>> Cheers,
>>> Andrew
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Aug  4 20:23:00 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Aug 2007 14:23:00 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B4C2B2.3030109@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu> <46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
Message-ID: <971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>

For the same reason that generic functions exist.  They don't have
a lot of common code but it makes easier to use.  Perhaps the argument
is not as strong here since the class tends to be implicit whereas the
method is explicit but it would still be a convenience.

On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
> > I think it would be desirable for optim to have a dispatching mechanism
> > that allows users to add their own optimization techniques to those
> > provided without having to modify optim and without having to come
> > up with a new visible function.  For example, if we call optim as
> > optim(...whatever..., method = "X") then that might dispatch
> > optim.X consistent with S3 except here X is explicitly given rather
> > than being a class.
>
> Why?  This would make sense if optim() had a lot of code common to all
> methods, but it doesn't.
>
> Duncan Murdoch
>
> >
> > On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
> >>> Hi Duncan,
> >>>
> >>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
> >>>> This is interesting work; thanks for doing it.  Could I make a
> >>>> suggestion?  Why not put together a package containing those test
> >>>> optimization problems, and offer to include other interesting ones as
> >>>> they arise?
> >>> Good idea.
> >>>
> >>>> You could also include your wrapper for the gsl function
> >>>> and your own improvements to optim.
> >>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
> >>> which seems to be the "right" place for it.  (Its maintainer is currently
> >>> enjoying a vacation :)
> >>>
> >>> It would be nice if all of these methods could be accessed with the existing
> >>> optim() interface, so that users could easily try different algorithms.
> >>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
> >>> Is there a convenient mechanism for packages registering new methods?
> >> No there isn't, but I don't really see it as necessary.  The R optim()
> >> function is reasonably short, mainly setting up defaults specific to
> >> each of the supported optimization methods.  The C do_optim() function
> >> has a bit more code common to the methods, but still only about 50
> >> lines. You could copy this common part into your own function following
> >> the same argument and return value conventions and a user would just
> >> need to change the function name in addition to specifying your method,
> >> not really that much harder.  (You could call your function optim and
> >> use it as a wrapper for stats::optim if you wanted to avoid even this,
> >> but I wouldn't recommend it, since then behaviour would depend on the
> >> search list ordering.)
> >>
> >> There's a small risk that the argument list to optim() will change
> >> incompatibly sometime in the future, but I think that's unlikely.
> >>
> >>> One incompatibility with my BFGS implementation is that it returns the
> >>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
> >>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
> >>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
> >>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
> >> If you return more than optim() returns it shouldn't have any serious
> >> ill effects.
> >>
> >>> The inverse Hessian is more useful than the Hessian for statistics because it
> >>> gives the variance-covariance matrix for maximum likelihood estimators.  When
> >>> the Hessian is close to being singular (aka "computationally singular"),
> >>> solve() sometimes fails to invert it.
> >>>
> >>> I think this means we should change the optim() interface.  For example, an
> >>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
> >>> matrix is returned.
> >> I'd suggest always returning it if it's useful and the calculation is
> >> reliable and cheap.  Adding "inv.hessian" as a general parameter would
> >> be troublesome with some of the other methods, where the inverse Hessian
> >> isn't already calculated, because of the inversion problem you mention
> >> above.
> >>
> >> Duncan Murdoch
> >>
> >>>> On your first point:  I agree that a prototype implementation in R makes
> >>>> sense, but I suspect there exist problems where the overhead would not
> >>>> be negligible (e.g. ones where the user has written the objective
> >>>> function in C for speed).  So I think you should keep in mind the
> >>>> possibility of moving the core of your improvements to C once you are
> >>>> happy with them.
> >>> Fair enough.
> >>>
> >>> Cheers,
> >>> Andrew
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Sat Aug  4 20:29:01 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Aug 2007 14:29:01 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
References: <20070804051231.GB3016@econ.upenn.edu>	
	<46B47E53.2040801@stats.uwo.ca>	
	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>	
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>	
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
Message-ID: <46B4C56D.8020408@stats.uwo.ca>

On 04/08/2007 2:23 PM, Gabor Grothendieck wrote:
> For the same reason that generic functions exist.  They don't have
> a lot of common code but it makes easier to use.  Perhaps the argument
> is not as strong here since the class tends to be implicit whereas the
> method is explicit but it would still be a convenience.

Can you give other examples where we do this?  The ones I can think of 
(graphics drivers and finalizers) involve a large amount of common 
machinery that it's difficult or impossible for the user to duplicate. 
That's not the case here.

Duncan Murdoch

> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
>>> I think it would be desirable for optim to have a dispatching mechanism
>>> that allows users to add their own optimization techniques to those
>>> provided without having to modify optim and without having to come
>>> up with a new visible function.  For example, if we call optim as
>>> optim(...whatever..., method = "X") then that might dispatch
>>> optim.X consistent with S3 except here X is explicitly given rather
>>> than being a class.
>> Why?  This would make sense if optim() had a lot of code common to all
>> methods, but it doesn't.
>>
>> Duncan Murdoch
>>
>>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
>>>>> Hi Duncan,
>>>>>
>>>>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
>>>>>> This is interesting work; thanks for doing it.  Could I make a
>>>>>> suggestion?  Why not put together a package containing those test
>>>>>> optimization problems, and offer to include other interesting ones as
>>>>>> they arise?
>>>>> Good idea.
>>>>>
>>>>>> You could also include your wrapper for the gsl function
>>>>>> and your own improvements to optim.
>>>>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
>>>>> which seems to be the "right" place for it.  (Its maintainer is currently
>>>>> enjoying a vacation :)
>>>>>
>>>>> It would be nice if all of these methods could be accessed with the existing
>>>>> optim() interface, so that users could easily try different algorithms.
>>>>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
>>>>> Is there a convenient mechanism for packages registering new methods?
>>>> No there isn't, but I don't really see it as necessary.  The R optim()
>>>> function is reasonably short, mainly setting up defaults specific to
>>>> each of the supported optimization methods.  The C do_optim() function
>>>> has a bit more code common to the methods, but still only about 50
>>>> lines. You could copy this common part into your own function following
>>>> the same argument and return value conventions and a user would just
>>>> need to change the function name in addition to specifying your method,
>>>> not really that much harder.  (You could call your function optim and
>>>> use it as a wrapper for stats::optim if you wanted to avoid even this,
>>>> but I wouldn't recommend it, since then behaviour would depend on the
>>>> search list ordering.)
>>>>
>>>> There's a small risk that the argument list to optim() will change
>>>> incompatibly sometime in the future, but I think that's unlikely.
>>>>
>>>>> One incompatibility with my BFGS implementation is that it returns the
>>>>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
>>>>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
>>>>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
>>>>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
>>>> If you return more than optim() returns it shouldn't have any serious
>>>> ill effects.
>>>>
>>>>> The inverse Hessian is more useful than the Hessian for statistics because it
>>>>> gives the variance-covariance matrix for maximum likelihood estimators.  When
>>>>> the Hessian is close to being singular (aka "computationally singular"),
>>>>> solve() sometimes fails to invert it.
>>>>>
>>>>> I think this means we should change the optim() interface.  For example, an
>>>>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
>>>>> matrix is returned.
>>>> I'd suggest always returning it if it's useful and the calculation is
>>>> reliable and cheap.  Adding "inv.hessian" as a general parameter would
>>>> be troublesome with some of the other methods, where the inverse Hessian
>>>> isn't already calculated, because of the inversion problem you mention
>>>> above.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>> On your first point:  I agree that a prototype implementation in R makes
>>>>>> sense, but I suspect there exist problems where the overhead would not
>>>>>> be negligible (e.g. ones where the user has written the objective
>>>>>> function in C for speed).  So I think you should keep in mind the
>>>>>> possibility of moving the core of your improvements to C once you are
>>>>>> happy with them.
>>>>> Fair enough.
>>>>>
>>>>> Cheers,
>>>>> Andrew
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From nikko at hailmail.net  Sat Aug  4 20:44:31 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sat, 04 Aug 2007 14:44:31 -0400
Subject: [Rd]  Optimization in R
Message-ID: <1186253071.20091.1203744495@webmail.messagingengine.com>

Hi,
In my earlier post I eluded to a situation where that would be useful. 
In nlme, there is a choice of optimizers, minpack.lm has
Levenberg-Marquardt,
while nlminb has the port routines. For the same starting values,
different
optimizers will present different solutions, having a common interface
would make fitting with multiple optimizers very attractive. 

Also the inverse Hessian would be useful, for cases where the Hessian is
ill conditioned
a little regularization goes a long way. I believe the package accuracy 
has a nice solution.

Nicholas
 

On 04/08/2007 2:23 PM, Gabor Grothendieck wrote:
> For the same reason that generic functions exist.  They don't have
> a lot of common code but it makes easier to use.  Perhaps the argument
> is not as strong here since the class tends to be implicit whereas the
> method is explicit but it would still be a convenience.

Can you give other examples where we do this?  The ones I can think of 
(graphics drivers and finalizers) involve a large amount of common 
machinery that it's difficult or impossible for the user to duplicate. 
That's not the case here.

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Aug  4 20:53:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Aug 2007 14:53:45 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B4C56D.8020408@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu> <46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
Message-ID: <971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>

The example of generic functions.

On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 04/08/2007 2:23 PM, Gabor Grothendieck wrote:
> > For the same reason that generic functions exist.  They don't have
> > a lot of common code but it makes easier to use.  Perhaps the argument
> > is not as strong here since the class tends to be implicit whereas the
> > method is explicit but it would still be a convenience.
>
> Can you give other examples where we do this?  The ones I can think of
> (graphics drivers and finalizers) involve a large amount of common
> machinery that it's difficult or impossible for the user to duplicate.
> That's not the case here.
>
> Duncan Murdoch
>
> > On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
> >>> I think it would be desirable for optim to have a dispatching mechanism
> >>> that allows users to add their own optimization techniques to those
> >>> provided without having to modify optim and without having to come
> >>> up with a new visible function.  For example, if we call optim as
> >>> optim(...whatever..., method = "X") then that might dispatch
> >>> optim.X consistent with S3 except here X is explicitly given rather
> >>> than being a class.
> >> Why?  This would make sense if optim() had a lot of code common to all
> >> methods, but it doesn't.
> >>
> >> Duncan Murdoch
> >>
> >>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
> >>>>> Hi Duncan,
> >>>>>
> >>>>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
> >>>>>> This is interesting work; thanks for doing it.  Could I make a
> >>>>>> suggestion?  Why not put together a package containing those test
> >>>>>> optimization problems, and offer to include other interesting ones as
> >>>>>> they arise?
> >>>>> Good idea.
> >>>>>
> >>>>>> You could also include your wrapper for the gsl function
> >>>>>> and your own improvements to optim.
> >>>>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
> >>>>> which seems to be the "right" place for it.  (Its maintainer is currently
> >>>>> enjoying a vacation :)
> >>>>>
> >>>>> It would be nice if all of these methods could be accessed with the existing
> >>>>> optim() interface, so that users could easily try different algorithms.
> >>>>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
> >>>>> Is there a convenient mechanism for packages registering new methods?
> >>>> No there isn't, but I don't really see it as necessary.  The R optim()
> >>>> function is reasonably short, mainly setting up defaults specific to
> >>>> each of the supported optimization methods.  The C do_optim() function
> >>>> has a bit more code common to the methods, but still only about 50
> >>>> lines. You could copy this common part into your own function following
> >>>> the same argument and return value conventions and a user would just
> >>>> need to change the function name in addition to specifying your method,
> >>>> not really that much harder.  (You could call your function optim and
> >>>> use it as a wrapper for stats::optim if you wanted to avoid even this,
> >>>> but I wouldn't recommend it, since then behaviour would depend on the
> >>>> search list ordering.)
> >>>>
> >>>> There's a small risk that the argument list to optim() will change
> >>>> incompatibly sometime in the future, but I think that's unlikely.
> >>>>
> >>>>> One incompatibility with my BFGS implementation is that it returns the
> >>>>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
> >>>>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
> >>>>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
> >>>>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
> >>>> If you return more than optim() returns it shouldn't have any serious
> >>>> ill effects.
> >>>>
> >>>>> The inverse Hessian is more useful than the Hessian for statistics because it
> >>>>> gives the variance-covariance matrix for maximum likelihood estimators.  When
> >>>>> the Hessian is close to being singular (aka "computationally singular"),
> >>>>> solve() sometimes fails to invert it.
> >>>>>
> >>>>> I think this means we should change the optim() interface.  For example, an
> >>>>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
> >>>>> matrix is returned.
> >>>> I'd suggest always returning it if it's useful and the calculation is
> >>>> reliable and cheap.  Adding "inv.hessian" as a general parameter would
> >>>> be troublesome with some of the other methods, where the inverse Hessian
> >>>> isn't already calculated, because of the inversion problem you mention
> >>>> above.
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>>>> On your first point:  I agree that a prototype implementation in R makes
> >>>>>> sense, but I suspect there exist problems where the overhead would not
> >>>>>> be negligible (e.g. ones where the user has written the objective
> >>>>>> function in C for speed).  So I think you should keep in mind the
> >>>>>> possibility of moving the core of your improvements to C once you are
> >>>>>> happy with them.
> >>>>> Fair enough.
> >>>>>
> >>>>> Cheers,
> >>>>> Andrew
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>
>


From murdoch at stats.uwo.ca  Sat Aug  4 21:13:17 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Aug 2007 15:13:17 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
References: <20070804051231.GB3016@econ.upenn.edu>	<46B47E53.2040801@stats.uwo.ca>	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>	<46B4C2B2.3030109@stats.uwo.ca>	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
Message-ID: <46B4CFCD.2000202@stats.uwo.ca>

On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
> The example of generic functions.

Show me an example where we have a list of ways to do a calculation 
passed as an argument (analogous to the method argument of optim), where 
the user is allowed to add his own function to the list.

Duncan Murdoch
> 
> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 04/08/2007 2:23 PM, Gabor Grothendieck wrote:
>>> For the same reason that generic functions exist.  They don't have
>>> a lot of common code but it makes easier to use.  Perhaps the argument
>>> is not as strong here since the class tends to be implicit whereas the
>>> method is explicit but it would still be a convenience.
>> Can you give other examples where we do this?  The ones I can think of
>> (graphics drivers and finalizers) involve a large amount of common
>> machinery that it's difficult or impossible for the user to duplicate.
>> That's not the case here.
>>
>> Duncan Murdoch
>>
>>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>> On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
>>>>> I think it would be desirable for optim to have a dispatching mechanism
>>>>> that allows users to add their own optimization techniques to those
>>>>> provided without having to modify optim and without having to come
>>>>> up with a new visible function.  For example, if we call optim as
>>>>> optim(...whatever..., method = "X") then that might dispatch
>>>>> optim.X consistent with S3 except here X is explicitly given rather
>>>>> than being a class.
>>>> Why?  This would make sense if optim() had a lot of code common to all
>>>> methods, but it doesn't.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
>>>>>>> Hi Duncan,
>>>>>>>
>>>>>>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
>>>>>>>> This is interesting work; thanks for doing it.  Could I make a
>>>>>>>> suggestion?  Why not put together a package containing those test
>>>>>>>> optimization problems, and offer to include other interesting ones as
>>>>>>>> they arise?
>>>>>>> Good idea.
>>>>>>>
>>>>>>>> You could also include your wrapper for the gsl function
>>>>>>>> and your own improvements to optim.
>>>>>>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
>>>>>>> which seems to be the "right" place for it.  (Its maintainer is currently
>>>>>>> enjoying a vacation :)
>>>>>>>
>>>>>>> It would be nice if all of these methods could be accessed with the existing
>>>>>>> optim() interface, so that users could easily try different algorithms.
>>>>>>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
>>>>>>> Is there a convenient mechanism for packages registering new methods?
>>>>>> No there isn't, but I don't really see it as necessary.  The R optim()
>>>>>> function is reasonably short, mainly setting up defaults specific to
>>>>>> each of the supported optimization methods.  The C do_optim() function
>>>>>> has a bit more code common to the methods, but still only about 50
>>>>>> lines. You could copy this common part into your own function following
>>>>>> the same argument and return value conventions and a user would just
>>>>>> need to change the function name in addition to specifying your method,
>>>>>> not really that much harder.  (You could call your function optim and
>>>>>> use it as a wrapper for stats::optim if you wanted to avoid even this,
>>>>>> but I wouldn't recommend it, since then behaviour would depend on the
>>>>>> search list ordering.)
>>>>>>
>>>>>> There's a small risk that the argument list to optim() will change
>>>>>> incompatibly sometime in the future, but I think that's unlikely.
>>>>>>
>>>>>>> One incompatibility with my BFGS implementation is that it returns the
>>>>>>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
>>>>>>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
>>>>>>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
>>>>>>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
>>>>>> If you return more than optim() returns it shouldn't have any serious
>>>>>> ill effects.
>>>>>>
>>>>>>> The inverse Hessian is more useful than the Hessian for statistics because it
>>>>>>> gives the variance-covariance matrix for maximum likelihood estimators.  When
>>>>>>> the Hessian is close to being singular (aka "computationally singular"),
>>>>>>> solve() sometimes fails to invert it.
>>>>>>>
>>>>>>> I think this means we should change the optim() interface.  For example, an
>>>>>>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
>>>>>>> matrix is returned.
>>>>>> I'd suggest always returning it if it's useful and the calculation is
>>>>>> reliable and cheap.  Adding "inv.hessian" as a general parameter would
>>>>>> be troublesome with some of the other methods, where the inverse Hessian
>>>>>> isn't already calculated, because of the inversion problem you mention
>>>>>> above.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>>>> On your first point:  I agree that a prototype implementation in R makes
>>>>>>>> sense, but I suspect there exist problems where the overhead would not
>>>>>>>> be negligible (e.g. ones where the user has written the objective
>>>>>>>> function in C for speed).  So I think you should keep in mind the
>>>>>>>> possibility of moving the core of your improvements to C once you are
>>>>>>>> happy with them.
>>>>>>> Fair enough.
>>>>>>>
>>>>>>> Cheers,
>>>>>>> Andrew
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Manuel.A.Morales at williams.edu  Sat Aug  4 21:58:33 2007
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Sat, 04 Aug 2007 15:58:33 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B47E53.2040801@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
Message-ID: <1186257513.3966.8.camel@mrubra.localdomain>

Thanks for the functions!

I tried installing the multimin function. To get it to compile, I needed
to change the Makefile to reflect my path and by adding the flags fPIC
in response to the error: "/usr/bin/ld: vector.o: relocation R_X86_64_32
against `a local symbol' can not be used when making a shared object;
recompile with -fPIC"

However, I get the following running test.R:

Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library '/home/mmorales/Desktop/multimin/gsl.so':
  /usr/lib64/libgsl.so.0: undefined symbol: cblas_ctrmv

I'm running R-2.5.1 compiled for x86_64 with a custom built ATLAS.


Manuel

On Sat, 2007-08-04 at 09:25 -0400, Duncan Murdoch wrote:
> On 04/08/2007 1:12 AM, Andrew Clausen wrote:
> > Hi all,
> > 
> > I've been working on improving R's optim() command, which does general purpose
> > unconstrained optimization.  Obviously, this is important for many statistics
> > computations, such as maximum likelihood, method of moments, etc.  I have
> > focused my efforts of the BFGS method, mainly because it best matches my
> > current projects.
> > 
> > Here's a quick summary of what I've done:
> >  * implemented my own version of BFGS in R,
> > 	http://www.econ.upenn.edu/~clausen/computing/bfgs.zip
> >  * written a wrapper for the GNU Scientific Library's optimization function,
> > multimin(),
> > 	http://www.econ.upenn.edu/~clausen/computing/multimin.zip
> >  * written some tricky functions to compare implementations,
> > 	http://www.econ.upenn.edu/~clausen/computing/tests.zip
> > 
> > My own implementation has several advantages over optim()'s implementation
> > (which you can see in the vmmin() function in
> > 	https://svn.r-project.org/R/trunk/src/main/optim.c)
> >  * the linesearch algorithm (More-Thuente) quickly finds a region of interest
> > to zoom into.  Moreover, it strikes a much better balance between finding
> > a point that adequately improves upon the old point, but doesn't waste too
> > much time finding a much better point.  (Unlike optim(), it uses the standard
> > Wolfe conditions with weak parameters.)
> >  * the linesearch algorithm uses interpolation, so it finds an acceptable
> > point more quickly.
> >  * implements "box" constraints.
> >  * easier to understand and modify the code, partly because it's written in R.
> > 
> > Of course, this comes at the (slight?) overhead cost of being written in R.
> > 
> > The test suite above takes the first few functions from the paper
> > 
> >         Mor?, Garbow, and Hillstrom, "Testing Unconstrained
> >         Optimization Software", ACM Trans Math Softw 7:1 (March 1981)
> > 
> > The test results appear below, where "*" means "computed the right solution",
> > and "!" means "got stuck".
> > 
> > test                    optim           clausen         gsl
> > --------------------------------------------------------------
> > bard                                                    !
> > beale
> > brown-scaled
> > freudenstein-roth
> > gaussian                                                *
> > helical-valley          *               *
> > jennrich-sampson                                        *
> > meyer                                                   *
> > powell-scaled                           *
> > rosenbrock                              *
> > 
> > The table indiciates that all three implementations of BFGS failed to compute
> > the right answer in most cases.  I suppose this means they are all quite
> > deficient.  Of course, this doesn't imply that they perform badly on real
> > statistics problems -- but in my limited experience with my crude econometric
> > models, they do perform badly.   Indeed, that's why I started investigating in
> > the first place.
> > 
> > For what it's worth, I think:
> >  * the optimization algorithms should be written in R -- the overhead is
> > small compared to the cost of evaluating likelihood functions anyway, and is
> > easily made up by the better algorithms that are possible.
> >  * it would be useful to keep a repository of interesting optimization
> > problems relevant to R users.  Then R developers can evaluate "improvements".
> 
> This is interesting work; thanks for doing it.  Could I make a 
> suggestion?  Why not put together a package containing those test 
> optimization problems, and offer to include other interesting ones as 
> they arise?  You could also include your wrapper for the gsl function 
> and your own improvements to optim.
> 
> On your first point:  I agree that a prototype implementation in R makes 
> sense, but I suspect there exist problems where the overhead would not 
> be negligible (e.g. ones where the user has written the objective 
> function in C for speed).  So I think you should keep in mind the 
> possibility of moving the core of your improvements to C once you are 
> happy with them.
> 
> Duncan Murdoch
> 
> P.S. I dropped the help-gsl mailing list from the distribution, since my 
> post is mainly about R.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
http://mutualism.williams.edu


From clausen at econ.upenn.edu  Sat Aug  4 22:37:41 2007
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Sat, 4 Aug 2007 16:37:41 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <1186257513.3966.8.camel@mrubra.localdomain>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<1186257513.3966.8.camel@mrubra.localdomain>
Message-ID: <20070804203740.GD16431@econ.upenn.edu>

Hi Manuel,

My multimin() wrapper will be merged into the Rgsl package.  I expect that the
wrapper doesn't do anything special (compared to the rest of Rgsl) to break the
compilation -- you're just having trouble with my very crude and temporary
Makefile.

Does Rgsl work for you?

If it does, you can probably just copy the relevant files into the right spot,
and build Rgsl the normal way.  (i.e. *.[ch] into src/, *.R into R/, and so
on...)

Cheers,
Andrew

On Sat, Aug 04, 2007 at 03:58:33PM -0400, Manuel Morales wrote:
> I tried installing the multimin function. To get it to compile, I needed
> to change the Makefile to reflect my path and by adding the flags fPIC
> in response to the error: "/usr/bin/ld: vector.o: relocation R_X86_64_32
> against `a local symbol' can not be used when making a shared object;
> recompile with -fPIC"
> 
> However, I get the following running test.R:
> 
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library '/home/mmorales/Desktop/multimin/gsl.so':
>   /usr/lib64/libgsl.so.0: undefined symbol: cblas_ctrmv
> 
> I'm running R-2.5.1 compiled for x86_64 with a custom built ATLAS.


From ggrothendieck at gmail.com  Sun Aug  5 00:56:47 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Aug 2007 18:56:47 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <46B4CFCD.2000202@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu> <46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
Message-ID: <971536df0708041556q7faf64ber38bf0da574927adc@mail.gmail.com>

I don't have an example of that but that does not make it less
desirable.  If one wants to use method 1, 2 or 3 then one can
use optim with a method= but if one wants to use methods 4
or 5 then one must use an entirely different function.  Surely
it would be better to be consistent from the user's viewpoint
and allow all of them to work consistently through the same
interface.

On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
> > The example of generic functions.
>
> Show me an example where we have a list of ways to do a calculation
> passed as an argument (analogous to the method argument of optim), where
> the user is allowed to add his own function to the list.
>
> Duncan Murdoch
> >
> > On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 04/08/2007 2:23 PM, Gabor Grothendieck wrote:
> >>> For the same reason that generic functions exist.  They don't have
> >>> a lot of common code but it makes easier to use.  Perhaps the argument
> >>> is not as strong here since the class tends to be implicit whereas the
> >>> method is explicit but it would still be a convenience.
> >> Can you give other examples where we do this?  The ones I can think of
> >> (graphics drivers and finalizers) involve a large amount of common
> >> machinery that it's difficult or impossible for the user to duplicate.
> >> That's not the case here.
> >>
> >> Duncan Murdoch
> >>
> >>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>> On 04/08/2007 1:05 PM, Gabor Grothendieck wrote:
> >>>>> I think it would be desirable for optim to have a dispatching mechanism
> >>>>> that allows users to add their own optimization techniques to those
> >>>>> provided without having to modify optim and without having to come
> >>>>> up with a new visible function.  For example, if we call optim as
> >>>>> optim(...whatever..., method = "X") then that might dispatch
> >>>>> optim.X consistent with S3 except here X is explicitly given rather
> >>>>> than being a class.
> >>>> Why?  This would make sense if optim() had a lot of code common to all
> >>>> methods, but it doesn't.
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>>>> On 04/08/2007 10:30 AM, Andrew Clausen wrote:
> >>>>>>> Hi Duncan,
> >>>>>>>
> >>>>>>> On Sat, Aug 04, 2007 at 09:25:39AM -0400, Duncan Murdoch wrote:
> >>>>>>>> This is interesting work; thanks for doing it.  Could I make a
> >>>>>>>> suggestion?  Why not put together a package containing those test
> >>>>>>>> optimization problems, and offer to include other interesting ones as
> >>>>>>>> they arise?
> >>>>>>> Good idea.
> >>>>>>>
> >>>>>>>> You could also include your wrapper for the gsl function
> >>>>>>>> and your own improvements to optim.
> >>>>>>> I have submitted my gsl multimin() wrapper for inclusion into the Rgsl package,
> >>>>>>> which seems to be the "right" place for it.  (Its maintainer is currently
> >>>>>>> enjoying a vacation :)
> >>>>>>>
> >>>>>>> It would be nice if all of these methods could be accessed with the existing
> >>>>>>> optim() interface, so that users could easily try different algorithms.
> >>>>>>> That is, users could specify method="BFGS" or "BFGS-R" or "BFGS-GSL", etc.
> >>>>>>> Is there a convenient mechanism for packages registering new methods?
> >>>>>> No there isn't, but I don't really see it as necessary.  The R optim()
> >>>>>> function is reasonably short, mainly setting up defaults specific to
> >>>>>> each of the supported optimization methods.  The C do_optim() function
> >>>>>> has a bit more code common to the methods, but still only about 50
> >>>>>> lines. You could copy this common part into your own function following
> >>>>>> the same argument and return value conventions and a user would just
> >>>>>> need to change the function name in addition to specifying your method,
> >>>>>> not really that much harder.  (You could call your function optim and
> >>>>>> use it as a wrapper for stats::optim if you wanted to avoid even this,
> >>>>>> but I wouldn't recommend it, since then behaviour would depend on the
> >>>>>> search list ordering.)
> >>>>>>
> >>>>>> There's a small risk that the argument list to optim() will change
> >>>>>> incompatibly sometime in the future, but I think that's unlikely.
> >>>>>>
> >>>>>>> One incompatibility with my BFGS implementation is that it returns the
> >>>>>>> *inverse* Hessian, which is a natural by-product of the BFGS algorithm.
> >>>>>>> Indeed, R's existing BFGS implementation also calculates the inverse Hessian,
> >>>>>>> and discards it!  (Disclaimer: as far as I know, there are no theorems that say
> >>>>>>> that BFGS's inverse Hessians are any good.  In practice, they seem to be.)
> >>>>>> If you return more than optim() returns it shouldn't have any serious
> >>>>>> ill effects.
> >>>>>>
> >>>>>>> The inverse Hessian is more useful than the Hessian for statistics because it
> >>>>>>> gives the variance-covariance matrix for maximum likelihood estimators.  When
> >>>>>>> the Hessian is close to being singular (aka "computationally singular"),
> >>>>>>> solve() sometimes fails to invert it.
> >>>>>>>
> >>>>>>> I think this means we should change the optim() interface.  For example, an
> >>>>>>> extra logical parameter, "inv.hessian" could control whether an inv.hessian
> >>>>>>> matrix is returned.
> >>>>>> I'd suggest always returning it if it's useful and the calculation is
> >>>>>> reliable and cheap.  Adding "inv.hessian" as a general parameter would
> >>>>>> be troublesome with some of the other methods, where the inverse Hessian
> >>>>>> isn't already calculated, because of the inversion problem you mention
> >>>>>> above.
> >>>>>>
> >>>>>> Duncan Murdoch
> >>>>>>
> >>>>>>>> On your first point:  I agree that a prototype implementation in R makes
> >>>>>>>> sense, but I suspect there exist problems where the overhead would not
> >>>>>>>> be negligible (e.g. ones where the user has written the objective
> >>>>>>>> function in C for speed).  So I think you should keep in mind the
> >>>>>>>> possibility of moving the core of your improvements to C once you are
> >>>>>>>> happy with them.
> >>>>>>> Fair enough.
> >>>>>>>
> >>>>>>> Cheers,
> >>>>>>> Andrew
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-devel at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Manuel.A.Morales at williams.edu  Sun Aug  5 03:13:57 2007
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Sat, 04 Aug 2007 21:13:57 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <20070804203740.GD16431@econ.upenn.edu>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<1186257513.3966.8.camel@mrubra.localdomain>
	<20070804203740.GD16431@econ.upenn.edu>
Message-ID: <1186276437.3966.13.camel@mrubra.localdomain>

On Sat, 2007-08-04 at 16:37 -0400, Andrew Clausen wrote:
> Hi Manuel,
> 
> My multimin() wrapper will be merged into the Rgsl package.  I expect that the
> wrapper doesn't do anything special (compared to the rest of Rgsl) to break the
> compilation -- you're just having trouble with my very crude and temporary
> Makefile.
> 
> Does Rgsl work for you?

I did see a package rgsl on google but I assume you mean the package gsl
- gsl does work for me.

> If it does, you can probably just copy the relevant files into the right spot,
> and build Rgsl the normal way.  (i.e. *.[ch] into src/, *.R into R/, and so
> on...)

I get the same error message (embedded in the log file
'gsl.Rcheck/00install.out'). I'll just wait for the updated package to
be released ...

Thanks again!

> Cheers,
> Andrew
> 
> On Sat, Aug 04, 2007 at 03:58:33PM -0400, Manuel Morales wrote:
> > I tried installing the multimin function. To get it to compile, I needed
> > to change the Makefile to reflect my path and by adding the flags fPIC
> > in response to the error: "/usr/bin/ld: vector.o: relocation R_X86_64_32
> > against `a local symbol' can not be used when making a shared object;
> > recompile with -fPIC"
> > 
> > However, I get the following running test.R:
> > 
> > Error in dyn.load(x, as.logical(local), as.logical(now)) : 
> >         unable to load shared library '/home/mmorales/Desktop/multimin/gsl.so':
> >   /usr/lib64/libgsl.so.0: undefined symbol: cblas_ctrmv
> > 
> > I'm running R-2.5.1 compiled for x86_64 with a custom built ATLAS.
-- 
http://mutualism.williams.edu

From christophe.pouzat at univ-paris5.fr  Sun Aug  5 12:57:30 2007
From: christophe.pouzat at univ-paris5.fr (Christophe Pouzat)
Date: Sun, 5 Aug 2007 12:57:30 +0200
Subject: [Rd] Optimization in R
Message-ID: <79ff51fb0708050357p14d9b6c5m58f597b85fa28862@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070805/aae0cff5/attachment.pl 

From tobias.verbeke at telenet.be  Sun Aug  5 13:36:17 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Sun, 05 Aug 2007 13:36:17 +0200
Subject: [Rd] trivial typos R-admin
Message-ID: <46B5B631.50006@telenet.be>


Please find below a patch against

https://svn.r-project.org/R/trunk/doc/manual/R-admin.texi

for two trivial typos.


1337c1337
< vanilla @R{} installation).  This location cna be overridden by
---
 > vanilla @R{} installation).  This location can be overridden by
1343c1343
< site libraries are always include by @samp{.libPaths()}.
---
 > site libraries are always included by @samp{.libPaths()}.


Kind regards,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From tobias.verbeke at telenet.be  Sun Aug  5 14:11:44 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Sun, 05 Aug 2007 14:11:44 +0200
Subject: [Rd] trivial typo R-lang
Message-ID: <46B5BE80.2050503@telenet.be>

Please find below a patch for a trivial
typo in R-lang:


384c384
< Symbol have mode @code{"name"}, storage mode @code{"symbol"}, and type
---
 > Symbols have mode @code{"name"}, storage mode @code{"symbol"}, and type


Kind regards,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From murdoch at stats.uwo.ca  Sun Aug  5 14:11:49 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 05 Aug 2007 08:11:49 -0400
Subject: [Rd] trivial typos R-admin
In-Reply-To: <46B5B631.50006@telenet.be>
References: <46B5B631.50006@telenet.be>
Message-ID: <46B5BE85.1010908@stats.uwo.ca>

On 05/08/2007 7:36 AM, Tobias Verbeke wrote:
> Please find below a patch against
> 
> https://svn.r-project.org/R/trunk/doc/manual/R-admin.texi
> 
> for two trivial typos.
> 
> 
> 1337c1337
> < vanilla @R{} installation).  This location cna be overridden by
> ---
>  > vanilla @R{} installation).  This location can be overridden by
> 1343c1343
> < site libraries are always include by @samp{.libPaths()}.
> ---
>  > site libraries are always included by @samp{.libPaths()}.


Thanks, now fixed in R-devel.


From murdoch at stats.uwo.ca  Sun Aug  5 14:48:35 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 05 Aug 2007 08:48:35 -0400
Subject: [Rd] trivial typo R-lang
In-Reply-To: <46B5BE80.2050503@telenet.be>
References: <46B5BE80.2050503@telenet.be>
Message-ID: <46B5C723.1040205@stats.uwo.ca>

On 05/08/2007 8:11 AM, Tobias Verbeke wrote:
> Please find below a patch for a trivial
> typo in R-lang:
> 
> 
> 384c384
> < Symbol have mode @code{"name"}, storage mode @code{"symbol"}, and type
> ---
>  > Symbols have mode @code{"name"}, storage mode @code{"symbol"}, and type

Fixed, thanks.

Duncan Murdoch


From elw at stderr.org  Mon Aug  6 01:19:30 2007
From: elw at stderr.org (elw at stderr.org)
Date: Sun, 5 Aug 2007 18:19:30 -0500 (CDT)
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <46B35E15.2050506@lancaster.ac.uk>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
	<Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>
	<46B35E15.2050506@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.64.0708051814200.29521@illuminati.stderr.org>



>> Beyond that, there may be a few more things that can be done to make R 
>> run "stupidly fast" on ps3 or IBM Cell blades.

> Wouldn't the right way to go here be to make it use the PS3 graphics 
> hardware, in a http://www.gpgpu.org/ kind of way? Or are the Cell 
> processors on the PS3 graphics processors too?


The accelerated-graphics bits in the ps3 are not exposed to the linux 
kernel, due to NDA/licensing/SuperSekritTypeStuff at Sony.

But, yes, post-reverse engineering, that would be nice.  :-)

My understanding is that Sony expects to be able to make games for the PS3 
hardware for the next decade or so.  This seems fairly reasonable, given 
that they only stopped making games for the PS**ONE** two or three years 
ago.  I still occasionally see them in stores, even.


> Of course if you are doing this for fun I'd like to see a Nintendo Wii 
> port, just so I can play Super Mario Generalised Linear Modelling by 
> waving the controller around.


There is a python script available to make the wiimotes act as a standard 
X11 mouse device (on linux, via /dev/input/mice);  I hear that this works 
just fine.  The link to instructions is here:

http://www.wiili.org/index.php/WMD

I bought a Wiimote and a Nunchuck (which has a couple extra buttons, 
trigger, a 'hat'-style analog joystick, and a few more accelerometers) a 
couple months ago with the intent of eventually doing some experimenting 
with them.  No time available, yet.

[What I want is to be able to fly through large social network graphs in 
R... rendered in OpenGL.  Is that too much to ask?  :-)]

--e


From elw at stderr.org  Mon Aug  6 01:23:06 2007
From: elw at stderr.org (elw at stderr.org)
Date: Sun, 5 Aug 2007 18:23:06 -0500 (CDT)
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <Pine.LNX.4.64.0708051814200.29521@illuminati.stderr.org>
References: <40e66e0b0708010913o587880c9p7076462d4ea87359@mail.gmail.com>
	<1185985821.3636.19.camel@Bellerophon.localdomain>
	<40e66e0b0708030652i7f9e2923m326695818948e899@mail.gmail.com>
	<Pine.LNX.4.64.0708030906330.30413@illuminati.stderr.org>
	<46B35E15.2050506@lancaster.ac.uk>
	<Pine.LNX.4.64.0708051814200.29521@illuminati.stderr.org>
Message-ID: <Pine.LNX.4.64.0708051821590.29651@illuminati.stderr.org>


> I bought a Wiimote and a Nunchuck (which has a couple extra buttons, 
> trigger, a 'hat'-style analog joystick, and a few more accelerometers) a 
> couple months ago with the intent of eventually doing some experimenting 
> with them.  No time available, yet.

(for folks who don't already know this - the wiimotes are bluetooth 
devices.  there are also bits available to use them as mice with windows 
or a macintosh....)

--e


From savicky at cs.cas.cz  Mon Aug  6 08:04:51 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 6 Aug 2007 08:04:51 +0200
Subject: [Rd] Optimization in R
In-Reply-To: <971536df0708041556q7faf64ber38bf0da574927adc@mail.gmail.com>
References: <46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
	<971536df0708041556q7faf64ber38bf0da574927adc@mail.gmail.com>
Message-ID: <20070806060451.GA8447@cs.cas.cz>

I would like to add a remark and a question.

Remark.

There is a part of R, which allows the user to select
among several methods for the same task and also to add
his own C code: random number generation. However, the interface
for optimization is more complex. In my opinion, looking
for a unified interface for this is desirable, but it is
a research problem, not a suggestion for an immediate
code modification.

Question.

Is there a way how to optimize a function written in C
using optim? This would be very useful, if the optimization
needs a lot of iterations. This may be done by defining 
an R function, which does nothing more than calling .C with
appropriate parameters,
but this looses efficiency. A more efficient solution
could be adding a specified entry point (or several, if derivatives
are also available), similar as in the user defined random number
generator. Then, a parameter of optim could control, whether
the function to be optimized is fn or the C entry point.

Petr Savicky.

> I don't have an example of that but that does not make it less
> desirable.  If one wants to use method 1, 2 or 3 then one can
> use optim with a method= but if one wants to use methods 4
> or 5 then one must use an entirely different function.  Surely
> it would be better to be consistent from the user's viewpoint
> and allow all of them to work consistently through the same
> interface.
> 
> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
> > > The example of generic functions.
> >
> > Show me an example where we have a list of ways to do a calculation
> > passed as an argument (analogous to the method argument of optim), where
> > the user is allowed to add his own function to the list.
> >
> > Duncan Murdoch
> > >


From savicky at cs.cas.cz  Mon Aug  6 08:48:19 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 6 Aug 2007 08:48:19 +0200
Subject: [Rd] Optimization in R
Message-ID: <20070806064819.GB8447@cs.cas.cz>

I am sorry for omitting a citation in my previous post.
The complete message is as follows (my text unchanged). PS

I would like to add a remark and a question.

Remark.

There is a part of R, which allows the user to select
among several methods for the same task and also to add
his own C code: random number generation. However, the interface
for optimization is more complex. In my opinion, looking
for a unified interface for this is desirable, but it is
a research problem, not a suggestion for an immediate
code modification.

Question.

Is there a way how to optimize a function written in C
using optim? This would be very useful, if the optimization
needs a lot of iterations. This may be done by defining 
an R function, which does nothing more than calling .C with
appropriate parameters,
but this looses efficiency. A more efficient solution
could be adding a specified entry point (or several, if derivatives
are also available), similar as in the user defined random number
generator. Then, a parameter of optim could control, whether
the function to be optimized is fn or the C entry point.

Petr Savicky.

On Sat, Aug 04, 2007 at 06:56:47PM -0400, Gabor Grothendieck wrote:
> I don't have an example of that but that does not make it less
> desirable.  If one wants to use method 1, 2 or 3 then one can
> use optim with a method= but if one wants to use methods 4
> or 5 then one must use an entirely different function.  Surely
> it would be better to be consistent from the user's viewpoint
> and allow all of them to work consistently through the same
> interface.
> 
> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
> > > The example of generic functions.
> >
> > Show me an example where we have a list of ways to do a calculation
> > passed as an argument (analogous to the method argument of optim), where
> > the user is allowed to add his own function to the list.
> >
> > Duncan Murdoch
> > >


From tobias.verbeke at telenet.be  Mon Aug  6 13:09:28 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Mon, 06 Aug 2007 11:09:28 +0000
Subject: [Rd] Makefile for embedding OpenBUGS in R package
Message-ID: <W98105532758441186398568@nocme1bl6.telenet-ops.be>

   Dear list, 

   I'm trying to embed OpenBUGS in an R package for use of it
   on 64-bit Linux. In order to get the CLI working one has to
   compile C code contained in $OpenBUGS/Manuals/CBugs.html
   (copied to say CBugs.c) using
 
   gcc -m32 -o bugs CBugs.c -ldl

   I put the OpenBUGS distribution in the ./inst subdirectory of
   the package root. Where should I now put the CBugs.c and how
   should the Makefile look like in order to be able to call
   $PKG_ROOT/OpenBUGS/bugs afterwards ?

   Naively putting the following Makefile in ./src does not work

   -%--------
   bugs: ../inst/OpenBUGS/CBugs.c
        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
   -%-------

   The objective is to use something along the following 

   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
   system(paste(execfile, "< somescript.script > somefile.out"))

   This system call to the CLI is currently the only (non-WINE) 
   way of using OpenBUGS on Linux in batch mode.    


   Many thanks in advance,
   Tobias

--

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From ripley at stats.ox.ac.uk  Mon Aug  6 15:46:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Aug 2007 14:46:34 +0100 (BST)
Subject: [Rd] Makefile for embedding OpenBUGS in R package
In-Reply-To: <W98105532758441186398568@nocme1bl6.telenet-ops.be>
References: <W98105532758441186398568@nocme1bl6.telenet-ops.be>
Message-ID: <Pine.LNX.4.64.0708061349560.23627@gannet.stats.ox.ac.uk>

On Mon, 6 Aug 2007, Tobias Verbeke wrote:

>   Dear list,
>
>   I'm trying to embed OpenBUGS in an R package for use of it
>   on 64-bit Linux. In order to get the CLI working one has to
>   compile C code contained in $OpenBUGS/Manuals/CBugs.html

same as

http://mathstat.helsinki.fi/openbugs/data/Docu/CBugs.html

I presume.

>   (copied to say CBugs.c) using
>
>   gcc -m32 -o bugs CBugs.c -ldl
>
>   I put the OpenBUGS distribution in the ./inst subdirectory of
>   the package root. Where should I now put the CBugs.c and how

Why do you want to install CBugs.c?

>   should the Makefile look like in order to be able to call
>   $PKG_ROOT/OpenBUGS/bugs afterwards ?
>
>   Naively putting the following Makefile in ./src does not work

What does 'does not work' mean?  It's hard to know whether this is just 
not doing what you wanted, or something else is wrong.

>   -%--------
>   bugs: ../inst/OpenBUGS/CBugs.c
>        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
>   -%-------
>
>   The objective is to use something along the following
>
>   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
>   system(paste(execfile, "< somescript.script > somefile.out"))
>
>   This system call to the CLI is currently the only (non-WINE)
>   way of using OpenBUGS on Linux in batch mode.

I think you need to make ../inst/OpenBUGS/bugs, not src/bugs.  So 
something like

all: ../inst/OpenBUGS/bugs

../inst/OpenBUGS/bugs: ../inst/OpenBUGS/CBugs.c
 	gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl

However, -m32 builds a 32-bit executable on 64-bit linux.  Is that what you 
wanted?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Mon Aug  6 16:16:11 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 6 Aug 2007 07:16:11 -0700 (PDT)
Subject: [Rd] Optimization in R
In-Reply-To: <20070806060451.GA8447@cs.cas.cz>
References: <46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
	<971536df0708041556q7faf64ber38bf0da574927adc@mail.gmail.com>
	<20070806060451.GA8447@cs.cas.cz>
Message-ID: <Pine.LNX.4.64.0708060714040.28453@homer24.u.washington.edu>

On Mon, 6 Aug 2007, Petr Savicky wrote:

> Question.
>
> Is there a way how to optimize a function written in C
> using optim?

The algorithms used by optim are all accessible from C. The manual 
"Writing R Extensions" has a section on "The R API", including the 
optimization routines.

 	-thomas


From tobias.verbeke at telenet.be  Mon Aug  6 16:30:41 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Mon, 06 Aug 2007 14:30:41 +0000
Subject: [Rd] Makefile for embedding OpenBUGS in R package
Message-ID: <W906017980119021186410641@nocme1bl6.telenet-ops.be>

>----- Oorspronkelijk bericht -----
>Van: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Verzonden: maandag, augustus 6, 2007 03:46 PM
>Aan: 'Tobias Verbeke'
>CC: r-devel at r-project.org
>Onderwerp: Re: [Rd] Makefile for embedding OpenBUGS in R package
>
>On Mon, 6 Aug 2007, Tobias Verbeke wrote:
>
>>   Dear list,
>>
>>   I'm trying to embed OpenBUGS in an R package for use of it
>>   on 64-bit Linux. In order to get the CLI working one has to
>>   compile C code contained in $OpenBUGS/Manuals/CBugs.html
>
>same as
>
>http://mathstat.helsinki.fi/openbugs/data/Docu/CBugs.html
>
>I presume.

Actually, these files appear to differ. The file I referred to
was the file ./Manuals/CBugs.html contained in the current OpenBUGS 
release:

http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip

>>   (copied to say CBugs.c) using
>>
>>   gcc -m32 -o bugs CBugs.c -ldl
>>
>>   I put the OpenBUGS distribution in the ./inst subdirectory of
>>   the package root. Where should I now put the CBugs.c and how
>
>Why do you want to install CBugs.c?

The CBugs.c file itself is indeed not needed in the built package. 

>
>>   should the Makefile look like in order to be able to call
>>   $PKG_ROOT/OpenBUGS/bugs afterwards ?
>>
>>   Naively putting the following Makefile in ./src does not work
>
>What does 'does not work' mean?  It's hard to know whether this is just 
>not doing what you wanted, or something else is wrong.

Apologies. This is the error message when putting the Makefile
in ./src and launching the package checker:

$ R.250 CMD check CGHmix
DISPLAY=localhost:10.0
* checking for working latex ... OK
* using log directory '/home/tverbek1/pkg/CGHmix.Rcheck'
* using R version 2.5.0 (2007-04-23)
* checking for file 'CGHmix/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'CGHmix' version '0.1-2'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'CGHmix' can be installed ... ERROR
Installation failed.
See '/home/tverbek1/pkg/CGHmix.Rcheck/00install.out' for details.

The file 00install.out contains:

* Installing *source* package 'CGHmix' ...
** libs
** arch -
gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
cp: cannot stat `*.so': No such file or directory
ERROR: compilation failed for package 'CGHmix'
** Removing '/home/tverbek1/pkg/CGHmix.Rcheck/CGHmix'

>
>>   -%--------
>>   bugs: ../inst/OpenBUGS/CBugs.c
>>        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
>>   -%-------
>>
>>   The objective is to use something along the following
>>
>>   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
>>   system(paste(execfile, "< somescript.script > somefile.out"))
>>
>>   This system call to the CLI is currently the only (non-WINE)
>>   way of using OpenBUGS on Linux in batch mode.
>
>I think you need to make ../inst/OpenBUGS/bugs, not src/bugs.  So 
>something like
>
>all: ../inst/OpenBUGS/bugs
>
>../inst/OpenBUGS/bugs: ../inst/OpenBUGS/CBugs.c
> 	gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl

Thank you. 

>However, -m32 builds a 32-bit executable on 64-bit linux.  Is that what you 
>wanted?

Yes. The shared object (brugs.so) comes with the OpenBUGS distribution 
and currently can only be cross-compiled by the main OpenBUGS developer 
(Andrew Thomas) who knows all secrets of the Windows only BlackBox 
(nomen omen) Component Pascal compiler. 

$ file brugs.so
brugs.so: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), stripped

Many thanks for your ever instructive answer.

Tobias

P.S. Contents of CBugs.c from OpenBUGS distribution (3.0.1)

/* GNU General Public Licence
   
   This small C program loads the brugs.so ELF shared library and calls the CLI function.
   Save it as a .c file and then compile it on Linux using gcc -o bugs CBugs.c -ldl

*/

#include <dlfcn.h>
#include <stdio.h>
#include <string.h>

int main (int argc, char **argv)
{
  void * handle;
  void (*cli)(void);

  handle = dlopen("./brugs.so", RTLD_LAZY);
  if (!handle)
    return 1;

  * (void **) (&cli) = dlsym(handle, "CLI");
  (*cli)();
  dlclose(handle);

  return 0;
   
}



>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>


From ligges at statistik.uni-dortmund.de  Mon Aug  6 18:40:00 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 06 Aug 2007 18:40:00 +0200
Subject: [Rd] Makefile for embedding OpenBUGS in R package
In-Reply-To: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
Message-ID: <46B74EE0.2030502@statistik.uni-dortmund.de>

As the BRugs maintainer, as far as I can tell, the most recent OpenBUGS 
brugs.so is not compatible with (at least) my system and I do not have 
the compilers to try it myself. Hence we still only ship BRugs for 
Windows, but if anybody else has ideas how to get the BRugs.so compiled 
(or just running without "traps", I'd be happy to hear about it.

Uwe Ligges








Tobias Verbeke wrote:
>> ----- Oorspronkelijk bericht -----
>> Van: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> Verzonden: maandag, augustus 6, 2007 03:46 PM
>> Aan: 'Tobias Verbeke'
>> CC: r-devel at r-project.org
>> Onderwerp: Re: [Rd] Makefile for embedding OpenBUGS in R package
>>
>> On Mon, 6 Aug 2007, Tobias Verbeke wrote:
>>
>>>   Dear list,
>>>
>>>   I'm trying to embed OpenBUGS in an R package for use of it
>>>   on 64-bit Linux. In order to get the CLI working one has to
>>>   compile C code contained in $OpenBUGS/Manuals/CBugs.html
>> same as
>>
>> http://mathstat.helsinki.fi/openbugs/data/Docu/CBugs.html
>>
>> I presume.
> 
> Actually, these files appear to differ. The file I referred to
> was the file ./Manuals/CBugs.html contained in the current OpenBUGS 
> release:
> 
> http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip
> 
>>>   (copied to say CBugs.c) using
>>>
>>>   gcc -m32 -o bugs CBugs.c -ldl
>>>
>>>   I put the OpenBUGS distribution in the ./inst subdirectory of
>>>   the package root. Where should I now put the CBugs.c and how
>> Why do you want to install CBugs.c?
> 
> The CBugs.c file itself is indeed not needed in the built package. 
> 
>>>   should the Makefile look like in order to be able to call
>>>   $PKG_ROOT/OpenBUGS/bugs afterwards ?
>>>
>>>   Naively putting the following Makefile in ./src does not work
>> What does 'does not work' mean?  It's hard to know whether this is just 
>> not doing what you wanted, or something else is wrong.
> 
> Apologies. This is the error message when putting the Makefile
> in ./src and launching the package checker:
> 
> $ R.250 CMD check CGHmix
> DISPLAY=localhost:10.0
> * checking for working latex ... OK
> * using log directory '/home/tverbek1/pkg/CGHmix.Rcheck'
> * using R version 2.5.0 (2007-04-23)
> * checking for file 'CGHmix/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'CGHmix' version '0.1-2'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'CGHmix' can be installed ... ERROR
> Installation failed.
> See '/home/tverbek1/pkg/CGHmix.Rcheck/00install.out' for details.
> 
> The file 00install.out contains:
> 
> * Installing *source* package 'CGHmix' ...
> ** libs
> ** arch -
> gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
> cp: cannot stat `*.so': No such file or directory
> ERROR: compilation failed for package 'CGHmix'
> ** Removing '/home/tverbek1/pkg/CGHmix.Rcheck/CGHmix'
> 
>>>   -%--------
>>>   bugs: ../inst/OpenBUGS/CBugs.c
>>>        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
>>>   -%-------
>>>
>>>   The objective is to use something along the following
>>>
>>>   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
>>>   system(paste(execfile, "< somescript.script > somefile.out"))
>>>
>>>   This system call to the CLI is currently the only (non-WINE)
>>>   way of using OpenBUGS on Linux in batch mode.
>> I think you need to make ../inst/OpenBUGS/bugs, not src/bugs.  So 
>> something like
>>
>> all: ../inst/OpenBUGS/bugs
>>
>> ../inst/OpenBUGS/bugs: ../inst/OpenBUGS/CBugs.c
>> 	gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
> 
> Thank you. 
> 
>> However, -m32 builds a 32-bit executable on 64-bit linux.  Is that what you 
>> wanted?
> 
> Yes. The shared object (brugs.so) comes with the OpenBUGS distribution 
> and currently can only be cross-compiled by the main OpenBUGS developer 
> (Andrew Thomas) who knows all secrets of the Windows only BlackBox 
> (nomen omen) Component Pascal compiler. 
> 
> $ file brugs.so
> brugs.so: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), stripped
> 
> Many thanks for your ever instructive answer.
> 
> Tobias
> 
> P.S. Contents of CBugs.c from OpenBUGS distribution (3.0.1)
> 
> /* GNU General Public Licence
>    
>    This small C program loads the brugs.so ELF shared library and calls the CLI function.
>    Save it as a .c file and then compile it on Linux using gcc -o bugs CBugs.c -ldl
> 
> */
> 
> #include <dlfcn.h>
> #include <stdio.h>
> #include <string.h>
> 
> int main (int argc, char **argv)
> {
>   void * handle;
>   void (*cli)(void);
> 
>   handle = dlopen("./brugs.so", RTLD_LAZY);
>   if (!handle)
>     return 1;
> 
>   * (void **) (&cli) = dlsym(handle, "CLI");
>   (*cli)();
>   dlclose(handle);
> 
>   return 0;
>    
> }
> 
> 
> 
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bolker at zoo.ufl.edu  Mon Aug  6 18:43:11 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 06 Aug 2007 12:43:11 -0400
Subject: [Rd] fortune() candidate?
Message-ID: <46B74F9F.5030603@zoo.ufl.edu>


R will always be arcane to those who do not make a serious effort
to learn it. It is ***not*** meant to be intuitive and easy for casual users
to just plunge into.

  -- Bert Gunter, R-help, 06/08/2007


From Greg.Snow at intermountainmail.org  Mon Aug  6 19:06:38 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Mon, 6 Aug 2007 11:06:38 -0600
Subject: [Rd] Compiling R for the Sony Playstation 3?
In-Reply-To: <46B35E15.2050506@lancaster.ac.uk>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBB2EF27@LP-EXCHVS07.CO.IHC.COM>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Barry Rowlingson
> Sent: Friday, August 03, 2007 10:56 AM
> To: elw at stderr.org
> Cc: marc_schwartz at comcast.net; Douglas Bates; R-devel List
> Subject: Re: [Rd] Compiling R for the Sony Playstation 3?

[snip]

>   Of course if you are doing this for fun I'd like to see a 
> Nintendo Wii port, just so I can play Super Mario Generalised 
> Linear Modelling by waving the controller around.

This would put a whole new perspective on the survival package :-)

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111


From savicky at cs.cas.cz  Mon Aug  6 20:47:53 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 6 Aug 2007 20:47:53 +0200
Subject: [Rd] Optimization in R
In-Reply-To: <Pine.LNX.4.64.0708060714040.28453@homer24.u.washington.edu>
References: <46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
	<971536df0708041556q7faf64ber38bf0da574927adc@mail.gmail.com>
	<20070806060451.GA8447@cs.cas.cz>
	<Pine.LNX.4.64.0708060714040.28453@homer24.u.washington.edu>
Message-ID: <20070806184753.GA8759@cs.cas.cz>

Thank you for your response. This is a good idea. Although I use
my own packages, some of them using other R API's, I missed
the optimization ones. Thanks again.

Petr Savicky.

On Mon, Aug 06, 2007 at 07:16:11AM -0700, Thomas Lumley wrote:
> On Mon, 6 Aug 2007, Petr Savicky wrote:
> 
> >Question.
> >
> >Is there a way how to optimize a function written in C
> >using optim?
> 
> The algorithms used by optim are all accessible from C. The manual 
> "Writing R Extensions" has a section on "The R API", including the 
> optimization routines.
> 
> 	-thomas
>


From tobias.verbeke at telenet.be  Mon Aug  6 21:15:17 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Mon, 06 Aug 2007 21:15:17 +0200
Subject: [Rd] Makefile for embedding OpenBUGS in R package
In-Reply-To: <46B74EE0.2030502@statistik.uni-dortmund.de>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<46B74EE0.2030502@statistik.uni-dortmund.de>
Message-ID: <46B77345.10003@telenet.be>

Hi Uwe,

> As the BRugs maintainer, as far as I can tell, the most recent OpenBUGS 
> brugs.so is not compatible with (at least) my system and I do not have 
> the compilers to try it myself. Hence we still only ship BRugs for 
> Windows, but if anybody else has ideas how to get the BRugs.so compiled 
> (or just running without "traps", I'd be happy to hear about it.

My strategy is to produce the data, model and inits file in
a BRugs manner and then produce a script along the lines of

modelCheck('Ratsmodel.txt')
modelData('Ratsdata.txt')
modelCompile()
modelInits('Ratsinits.txt')
modelUpdate(1000)
statsSet('alpha')
statsSet('beta')
modelUpdate(2000)
samplesStats('*')
modelQuit()

which is fed to bugs (compiled as described below) like

./bugs < rats.script > rats.out

Afterwards I use some simple R utilities to
clean up rats.out and read it in as
as dataframe for further processing.

There are however two (painfully learned and
undocumented) things to keep in mind when
producing these files:

(1) such a script (as well as all other BUGS files)
should use CR LF line endings

(2) There may be absolutely no character (no newline!)
after the final modelQuit() [otherwise you can end
up (like me) with 47 GB of error messages being joyfully
output to rats.out... which is when I had a phone call
from a local sysasmin]

The only missing piece to embed current OpenBUGS in an
R package for automating analyses on Linux is being able
to compile CBugs.c (see below) when building the R package.

I hope this is useful to someone.

Kind regards,
Tobias

> Tobias Verbeke wrote:
>>> ----- Oorspronkelijk bericht -----
>>> Van: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>>> Verzonden: maandag, augustus 6, 2007 03:46 PM
>>> Aan: 'Tobias Verbeke'
>>> CC: r-devel at r-project.org
>>> Onderwerp: Re: [Rd] Makefile for embedding OpenBUGS in R package
>>>
>>> On Mon, 6 Aug 2007, Tobias Verbeke wrote:
>>>
>>>>   Dear list,
>>>>
>>>>   I'm trying to embed OpenBUGS in an R package for use of it
>>>>   on 64-bit Linux. In order to get the CLI working one has to
>>>>   compile C code contained in $OpenBUGS/Manuals/CBugs.html
>>> same as
>>>
>>> http://mathstat.helsinki.fi/openbugs/data/Docu/CBugs.html
>>>
>>> I presume.
>>
>> Actually, these files appear to differ. The file I referred to
>> was the file ./Manuals/CBugs.html contained in the current OpenBUGS 
>> release:
>>
>> http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip
>>
>>>>   (copied to say CBugs.c) using
>>>>
>>>>   gcc -m32 -o bugs CBugs.c -ldl
>>>>
>>>>   I put the OpenBUGS distribution in the ./inst subdirectory of
>>>>   the package root. Where should I now put the CBugs.c and how
>>> Why do you want to install CBugs.c?
>>
>> The CBugs.c file itself is indeed not needed in the built package.
>>>>   should the Makefile look like in order to be able to call
>>>>   $PKG_ROOT/OpenBUGS/bugs afterwards ?
>>>>
>>>>   Naively putting the following Makefile in ./src does not work
>>> What does 'does not work' mean?  It's hard to know whether this is 
>>> just not doing what you wanted, or something else is wrong.
>>
>> Apologies. This is the error message when putting the Makefile
>> in ./src and launching the package checker:
>>
>> $ R.250 CMD check CGHmix
>> DISPLAY=localhost:10.0
>> * checking for working latex ... OK
>> * using log directory '/home/tverbek1/pkg/CGHmix.Rcheck'
>> * using R version 2.5.0 (2007-04-23)
>> * checking for file 'CGHmix/DESCRIPTION' ... OK
>> * checking extension type ... Package
>> * this is package 'CGHmix' version '0.1-2'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'CGHmix' can be installed ... ERROR
>> Installation failed.
>> See '/home/tverbek1/pkg/CGHmix.Rcheck/00install.out' for details.
>>
>> The file 00install.out contains:
>>
>> * Installing *source* package 'CGHmix' ...
>> ** libs
>> ** arch -
>> gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
>> cp: cannot stat `*.so': No such file or directory
>> ERROR: compilation failed for package 'CGHmix'
>> ** Removing '/home/tverbek1/pkg/CGHmix.Rcheck/CGHmix'
>>
>>>>   -%--------
>>>>   bugs: ../inst/OpenBUGS/CBugs.c
>>>>        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
>>>>   -%-------
>>>>
>>>>   The objective is to use something along the following
>>>>
>>>>   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
>>>>   system(paste(execfile, "< somescript.script > somefile.out"))
>>>>
>>>>   This system call to the CLI is currently the only (non-WINE)
>>>>   way of using OpenBUGS on Linux in batch mode.
>>> I think you need to make ../inst/OpenBUGS/bugs, not src/bugs.  So 
>>> something like
>>>
>>> all: ../inst/OpenBUGS/bugs
>>>
>>> ../inst/OpenBUGS/bugs: ../inst/OpenBUGS/CBugs.c
>>>     gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
>>
>> Thank you.
>>> However, -m32 builds a 32-bit executable on 64-bit linux.  Is that 
>>> what you wanted?
>>
>> Yes. The shared object (brugs.so) comes with the OpenBUGS distribution 
>> and currently can only be cross-compiled by the main OpenBUGS 
>> developer (Andrew Thomas) who knows all secrets of the Windows only 
>> BlackBox (nomen omen) Component Pascal compiler.
>> $ file brugs.so
>> brugs.so: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), 
>> stripped
>>
>> Many thanks for your ever instructive answer.
>>
>> Tobias
>>
>> P.S. Contents of CBugs.c from OpenBUGS distribution (3.0.1)
>>
>> /* GNU General Public Licence
>>       This small C program loads the brugs.so ELF shared library and 
>> calls the CLI function.
>>    Save it as a .c file and then compile it on Linux using gcc -o bugs 
>> CBugs.c -ldl
>>
>> */
>>
>> #include <dlfcn.h>
>> #include <stdio.h>
>> #include <string.h>
>>
>> int main (int argc, char **argv)
>> {
>>   void * handle;
>>   void (*cli)(void);
>>
>>   handle = dlopen("./brugs.so", RTLD_LAZY);
>>   if (!handle)
>>     return 1;
>>
>>   * (void **) (&cli) = dlsym(handle, "CLI");
>>   (*cli)();
>>   dlclose(handle);
>>
>>   return 0;
>>    }
>>
>>
>>
>>>
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Mon Aug  6 21:37:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Aug 2007 20:37:14 +0100 (BST)
Subject: [Rd] Makefile for embedding OpenBUGS in R package
In-Reply-To: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
Message-ID: <Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>

On Mon, 6 Aug 2007, Tobias Verbeke wrote:

>> ----- Oorspronkelijk bericht -----
>> Van: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> Verzonden: maandag, augustus 6, 2007 03:46 PM
>> Aan: 'Tobias Verbeke'
>> CC: r-devel at r-project.org
>> Onderwerp: Re: [Rd] Makefile for embedding OpenBUGS in R package
>>
>> On Mon, 6 Aug 2007, Tobias Verbeke wrote:
>>
>>>   Dear list,
>>>
>>>   I'm trying to embed OpenBUGS in an R package for use of it
>>>   on 64-bit Linux. In order to get the CLI working one has to
>>>   compile C code contained in $OpenBUGS/Manuals/CBugs.html
>>
>> same as
>>
>> http://mathstat.helsinki.fi/openbugs/data/Docu/CBugs.html
>>
>> I presume.
>
> Actually, these files appear to differ. The file I referred to
> was the file ./Manuals/CBugs.html contained in the current OpenBUGS
> release:
>
> http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip

I am baffled by that C file: why not just link an even simpler stub 
against brugs.so rather than play around with dlopen?


>>>   (copied to say CBugs.c) using
>>>
>>>   gcc -m32 -o bugs CBugs.c -ldl
>>>
>>>   I put the OpenBUGS distribution in the ./inst subdirectory of
>>>   the package root. Where should I now put the CBugs.c and how
>>
>> Why do you want to install CBugs.c?
>
> The CBugs.c file itself is indeed not needed in the built package.
>
>>
>>>   should the Makefile look like in order to be able to call
>>>   $PKG_ROOT/OpenBUGS/bugs afterwards ?
>>>
>>>   Naively putting the following Makefile in ./src does not work
>>
>> What does 'does not work' mean?  It's hard to know whether this is just
>> not doing what you wanted, or something else is wrong.
>
> Apologies. This is the error message when putting the Makefile
> in ./src and launching the package checker:
>
> $ R.250 CMD check CGHmix
> DISPLAY=localhost:10.0
> * checking for working latex ... OK
> * using log directory '/home/tverbek1/pkg/CGHmix.Rcheck'
> * using R version 2.5.0 (2007-04-23)
> * checking for file 'CGHmix/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'CGHmix' version '0.1-2'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'CGHmix' can be installed ... ERROR
> Installation failed.
> See '/home/tverbek1/pkg/CGHmix.Rcheck/00install.out' for details.
>
> The file 00install.out contains:
>
> * Installing *source* package 'CGHmix' ...
> ** libs
> ** arch -
> gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
> cp: cannot stat `*.so': No such file or directory
> ERROR: compilation failed for package 'CGHmix'

Ah, so you need to circumvent the installation mechanism as you do not 
have a DLL in your package.  See package Rserve for a workaround.

[rest not needed for the reply.]

> ** Removing '/home/tverbek1/pkg/CGHmix.Rcheck/CGHmix'
>
>>
>>>   -%--------
>>>   bugs: ../inst/OpenBUGS/CBugs.c
>>>        gcc -m32 -o bugs ../inst/OpenBUGS/CBugs.c -ldl
>>>   -%-------
>>>
>>>   The objective is to use something along the following
>>>
>>>   execfile <- system.file("OpenBUGS", "bugs", package = mypkg)
>>>   system(paste(execfile, "< somescript.script > somefile.out"))
>>>
>>>   This system call to the CLI is currently the only (non-WINE)
>>>   way of using OpenBUGS on Linux in batch mode.
>>
>> I think you need to make ../inst/OpenBUGS/bugs, not src/bugs.  So
>> something like
>>
>> all: ../inst/OpenBUGS/bugs
>>
>> ../inst/OpenBUGS/bugs: ../inst/OpenBUGS/CBugs.c
>> 	gcc -m32 -o ../inst/OpenBUGS/bugs ../inst/OpenBUGS/CBugs.c -ldl
>
> Thank you.
>
>> However, -m32 builds a 32-bit executable on 64-bit linux.  Is that what you
>> wanted?
>
> Yes. The shared object (brugs.so) comes with the OpenBUGS distribution
> and currently can only be cross-compiled by the main OpenBUGS developer
> (Andrew Thomas) who knows all secrets of the Windows only BlackBox
> (nomen omen) Component Pascal compiler.
>
> $ file brugs.so
> brugs.so: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), stripped
>
> Many thanks for your ever instructive answer.
>
> Tobias
>
> P.S. Contents of CBugs.c from OpenBUGS distribution (3.0.1)
>
> /* GNU General Public Licence
>
>   This small C program loads the brugs.so ELF shared library and calls the CLI function.
>   Save it as a .c file and then compile it on Linux using gcc -o bugs CBugs.c -ldl
>
> */
>
> #include <dlfcn.h>
> #include <stdio.h>
> #include <string.h>
>
> int main (int argc, char **argv)
> {
>  void * handle;
>  void (*cli)(void);
>
>  handle = dlopen("./brugs.so", RTLD_LAZY);
>  if (!handle)
>    return 1;
>
>  * (void **) (&cli) = dlsym(handle, "CLI");
>  (*cli)();
>  dlclose(handle);
>
>  return 0;
>
> }

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maustin at amgen.com  Mon Aug  6 23:16:33 2007
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 6 Aug 2007 14:16:33 -0700 
Subject: [Rd] Inconsistency in current release version
Message-ID: <E7D5AB4811D20B489622AABA9C53859115CF96C6@teal-exch.amgen.com>

At http://cran.at.r-project.org/ it reads that


"The latest release (2007-04-24): R-2.5.0.tar.gz (read what's new in the
latest version)."

I'm assuming this should be referencing 2.5.1?

--Matt

Matt Austin
Statistician
Amgen, Inc


From hin-tak.leung at cimr.cam.ac.uk  Tue Aug  7 02:10:36 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 07 Aug 2007 01:10:36 +0100
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R package
In-Reply-To: <Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
Message-ID: <46B7B87C.1070808@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Mon, 6 Aug 2007, Tobias Verbeke wrote:
<snipped>
>>> I presume.
>> Actually, these files appear to differ. The file I referred to
>> was the file ./Manuals/CBugs.html contained in the current OpenBUGS
>> release:
>>
>> http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip
> 
> I am baffled by that C file: why not just link an even simpler stub 
> against brugs.so rather than play around with dlopen?
> 
> 
<snipped>

[I am not familiar with openbugs nor its licensing terms, but seeing as 
it is distributed as part-binary-only...]

I agree there is little technical reasons for dlopen() vs a simpler
stub, but there is occasionally licensing/legal reasons for doing so - 
GPL-licensed code dlopen()'ing proprietary-licensed binary-only DLL/so
is allowed, but a 'more intimate' linking of GPL-code with more 
restrictive code is sometimes troublesome in its licensing status.

(for private/internal use, there is no reason for going the dlopen() 
routine...) Just an idea...

Hin-Tak


From murdoch at stats.uwo.ca  Tue Aug  7 02:21:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 06 Aug 2007 20:21:27 -0400
Subject: [Rd] Inconsistency in current release version
In-Reply-To: <E7D5AB4811D20B489622AABA9C53859115CF96C6@teal-exch.amgen.com>
References: <E7D5AB4811D20B489622AABA9C53859115CF96C6@teal-exch.amgen.com>
Message-ID: <46B7BB07.3050307@stats.uwo.ca>

On 06/08/2007 5:16 PM, Austin, Matt wrote:
> At http://cran.at.r-project.org/ it reads that
> 
> 
> "The latest release (2007-04-24): R-2.5.0.tar.gz (read what's new in the
> latest version)."
> 
> I'm assuming this should be referencing 2.5.1?

I don't think you're seeing the latest.  I see

The latest release (2007-06-28): R-2.5.1.tar.gz (

Duncan Murdoch


From clausen at econ.upenn.edu  Tue Aug  7 02:25:32 2007
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Mon, 6 Aug 2007 20:25:32 -0400
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <46B7B87C.1070808@cimr.cam.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
	<46B7B87C.1070808@cimr.cam.ac.uk>
Message-ID: <20070807002532.GI16431@econ.upenn.edu>

Hi Hin-Tak,

On Tue, Aug 07, 2007 at 01:10:36AM +0100, Hin-Tak Leung wrote:
> GPL-licensed code dlopen()'ing proprietary-licensed binary-only DLL/so
> is allowed

Do you have any evidence?  (eg: something written on www.fsf.org?)

As far as I know, the normal grounds for allowing GPL code to link with
proprietary code is the text

"However, as a special exception, the source code distributed need not include
anything that is normally distributed (in either source or binary form) with
the major components (compiler, kernel, and so on) of the operating system on
which the executable runs, unless that component itself accompanies the
executable."

Cheers,
Andrew


From hin-tak.leung at cimr.cam.ac.uk  Tue Aug  7 03:04:11 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 07 Aug 2007 02:04:11 +0100
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <20070807002532.GI16431@econ.upenn.edu>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
	<46B7B87C.1070808@cimr.cam.ac.uk>
	<20070807002532.GI16431@econ.upenn.edu>
Message-ID: <46B7C50B.7070609@cimr.cam.ac.uk>

Andrew Clausen wrote:
> Hi Hin-Tak,
> 
> On Tue, Aug 07, 2007 at 01:10:36AM +0100, Hin-Tak Leung wrote:
>> GPL-licensed code dlopen()'ing proprietary-licensed binary-only DLL/so
>> is allowed
> 
> Do you have any evidence?  (eg: something written on www.fsf.org?)
> 
> As far as I know, the normal grounds for allowing GPL code to link with
> proprietary code is the text
> 
> "However, as a special exception, the source code distributed need not include
> anything that is normally distributed (in either source or binary form) with
> the major components (compiler, kernel, and so on) of the operating system on
> which the executable runs, unless that component itself accompanies the
> executable."

I don't - but openbugs (if you assume it to be the 'major' component)
is certainly not part of the OSes on which the resulting executable
runs.

Consider a few well-known applications in the x86 linux world
for loading binary-only windows DLLs - e.g. ndiswrapper, mplayer.
They distribute the different licensed components separately, or ask the
users to get it elsewhere.

*Re-distribution* (not usage of) of components bundling together
having different re-distributing licensing terms is a sticky matter.

Hin-Tak
P.S. I don't know if the original poster has any intention of
distributing his package for others to use; but having parts of his 
package distributed binary-only and also under a different and
more restrictive license term can be sticky.


From h.wickham at gmail.com  Tue Aug  7 04:55:38 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 6 Aug 2007 21:55:38 -0500
Subject: [Rd] Optimization in R
In-Reply-To: <46B4CFCD.2000202@stats.uwo.ca>
References: <20070804051231.GB3016@econ.upenn.edu>
	<46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu> <46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
Message-ID: <f8e6ff050708061955q4b0cba9fmda8b0df99f3c0173@mail.gmail.com>

On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
> > The example of generic functions.
>
> Show me an example where we have a list of ways to do a calculation
> passed as an argument (analogous to the method argument of optim), where
> the user is allowed to add his own function to the list.

Bin width selection in hist?  Family functions for glm?  Those come
quickly to my mind, but I'm sure there are others.

Hadley


From ripley at stats.ox.ac.uk  Tue Aug  7 05:02:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Aug 2007 04:02:37 +0100 (BST)
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <46B7B87C.1070808@cimr.cam.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
	<46B7B87C.1070808@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>

OpenBUGS is distributed under GPL2, so this seems not to apply.
It is distributed as source and as binaries: the difficulty is that it is 
written in Object Pascal for which a compiler is not readily available.

On Tue, 7 Aug 2007, Hin-Tak Leung wrote:

> Prof Brian Ripley wrote:
>> On Mon, 6 Aug 2007, Tobias Verbeke wrote:
> <snipped>
>>>> I presume.
>>> Actually, these files appear to differ. The file I referred to
>>> was the file ./Manuals/CBugs.html contained in the current OpenBUGS
>>> release:
>>> 
>>> http://mathstat.helsinki.fi/openbugs/OpenBUGS.zip
>> 
>> I am baffled by that C file: why not just link an even simpler stub against 
>> brugs.so rather than play around with dlopen?
>> 
>> 
> <snipped>
>
> [I am not familiar with openbugs nor its licensing terms, but seeing as it is 
> distributed as part-binary-only...]
>
> I agree there is little technical reasons for dlopen() vs a simpler
> stub, but there is occasionally licensing/legal reasons for doing so - 
> GPL-licensed code dlopen()'ing proprietary-licensed binary-only DLL/so
> is allowed, but a 'more intimate' linking of GPL-code with more restrictive 
> code is sometimes troublesome in its licensing status.

But the C code is also under GPL2: see the comment on the web page I 
mentioned.

Doing what Tobias is proposing (communicating with another program via 
files) is generally accepted as allowed under different licencing 
agreements.  The whole brugs executable would be under GPL2.


> (for private/internal use, there is no reason for going the dlopen() 
> routine...) Just an idea...
>
> Hin-Tak
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From christophe.pouzat at univ-paris5.fr  Tue Aug  7 11:54:48 2007
From: christophe.pouzat at univ-paris5.fr (Christophe Pouzat)
Date: Tue, 7 Aug 2007 11:54:48 +0200
Subject: [Rd] Automatic implementation of "trivial" constraints in
	optimization
Message-ID: <79ff51fb0708070254u5a23b962s7a8c03d6d8cfe871@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070807/ef07c2f1/attachment.pl 

From murdoch at stats.uwo.ca  Tue Aug  7 12:33:47 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Aug 2007 06:33:47 -0400
Subject: [Rd] Optimization in R
In-Reply-To: <20070807031813.GA1530@ms.unimelb.edu.au>
References: <46B47E53.2040801@stats.uwo.ca>
	<20070804143032.GC16431@econ.upenn.edu>
	<46B4A200.10109@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
	<f8e6ff050708061955q4b0cba9fmda8b0df99f3c0173@mail.gmail.com>
	<20070807031813.GA1530@ms.unimelb.edu.au>
Message-ID: <46B84A8B.1070601@stats.uwo.ca>

Those are small parts of the calculation, not the whole thing.  The 
original point was that optim() is a very thin wrapper around the code 
to do the optimization.  I just don't see a need to make it more 
complicated so it can be used to wrap other methods.  Authors of new 
optimization methods can just create new functions, following the 
pattern set by optim(), and it will be easier for almost everyone.

Duncan Murdoch

On 06/08/2007 11:18 PM, Andrew Robinson wrote:
>  ... Variance and correlation model classes in nlme.
> 
> Cheers
> 
> Andrew
> 
> On Mon, Aug 06, 2007 at 09:55:38PM -0500, hadley wickham wrote:
>> On 8/4/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>> On 04/08/2007 2:53 PM, Gabor Grothendieck wrote:
>>>> The example of generic functions.
>>> Show me an example where we have a list of ways to do a calculation
>>> passed as an argument (analogous to the method argument of optim), where
>>> the user is allowed to add his own function to the list.
>> Bin width selection in hist?  Family functions for glm?  Those come
>> quickly to my mind, but I'm sure there are others.
>>
>> Hadley
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Tue Aug  7 14:34:07 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 7 Aug 2007 07:34:07 -0500
Subject: [Rd] Optimization in R
In-Reply-To: <46B84A8B.1070601@stats.uwo.ca>
References: <46B47E53.2040801@stats.uwo.ca>
	<971536df0708041005h55c2488by76709cf4fb989690@mail.gmail.com>
	<46B4C2B2.3030109@stats.uwo.ca>
	<971536df0708041123n5d59b1ebw18618d6340b76300@mail.gmail.com>
	<46B4C56D.8020408@stats.uwo.ca>
	<971536df0708041153o174d73f5vd2c28f483a6bf6b6@mail.gmail.com>
	<46B4CFCD.2000202@stats.uwo.ca>
	<f8e6ff050708061955q4b0cba9fmda8b0df99f3c0173@mail.gmail.com>
	<20070807031813.GA1530@ms.unimelb.edu.au>
	<46B84A8B.1070601@stats.uwo.ca>
Message-ID: <f8e6ff050708070534v5aa973b5rd8bc46bf4d4ab334@mail.gmail.com>

On 8/7/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> Those are small parts of the calculation, not the whole thing.  The
> original point was that optim() is a very thin wrapper around the code
> to do the optimization.  I just don't see a need to make it more
> complicated so it can be used to wrap other methods.  Authors of new
> optimization methods can just create new functions, following the
> pattern set by optim(), and it will be easier for almost everyone.

Another alternative would be to describe a common interface to
optimisation functions (like the modelling functions).  Otherwise it
becomes a hassle to switch in and out different functions because they
each have slightly different interfaces (eg. clustering and
classification algorithms).

Hadley


From hin-tak.leung at cimr.cam.ac.uk  Tue Aug  7 22:31:41 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 07 Aug 2007 21:31:41 +0100
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>
	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>
	<46B7B87C.1070808@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>
Message-ID: <46B8D6AD.9040707@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> OpenBUGS is distributed under GPL2, so this seems not to apply.
> It is distributed as source and as binaries: the difficulty is that it 
> is written in Object Pascal for which a compiler is not readily available.

Argh, I just thought of a proper technical reason, and I think I have 
spotted a possible bug in the original poster's code! Some choose to do
dlopen() when the DLL/so is in a non-standard/non-system location, as an
alternative to setting LD_LIBRARY_PATH explicitly or other link-loader
magics.

The line:
    handle = dlopen("./brugs.so", RTLD_LAZY);

Seems to suggest this, However, the problem with this code, is that
the current directory  (./) may not be where the user thinks it is.
I think the user meant to prepend $R_HOME/library/<package>/inst/ 
somehow to "brugs.so", and dlopen'ing 
"$R_HOME/library/<package>/inst/brugs.so" instead.

Hin-Tak

<snipped>


From hpages at fhcrc.org  Tue Aug  7 23:06:56 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Tue, 07 Aug 2007 14:06:56 -0700
Subject: [Rd] Embedded nuls in strings
Message-ID: <46B8DEF0.3030602@fhcrc.org>

Hi,

?rawToChar
     'rawToChar' converts raw bytes either to a single character string
     or a character vector of single bytes.  (Note that a single
     character string could contain embedded nuls.)

Allowing embedded nuls in a string might be an interesting experiment but it
seems to cause some troubles to most of the string manipulation functions.

A string with an embedded 0:

  raw0 <- as.raw(c(65:68, 0 , 70))
  string0 <- rawToChar(raw0)

> string0
[1] "ABCD\0F"

nchar() should return 6:
> nchar(string0)
[1] 4

In addition this embedded nul seems to break almost all string manipulation/searching
functions:
  grep("F", string0)
  strsplit(string0, split=NULL, fixed=TRUE)[[1]]
  tolower(string0)
  chartr("F", "x", string0)
  substr(string0, 6, 6)
  ...
  etc...

Not very surprisingly, they all seem to treat string0 as if it was "ABCD"!

Cheers,
H.


From smckinney at bccrc.ca  Tue Aug  7 23:27:19 2007
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 7 Aug 2007 14:27:19 -0700
Subject: [Rd] Embedded nuls in strings
References: <46B8DEF0.3030602@fhcrc.org>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB03289FA0@crcmail1.BCCRC.CA>

I get similar results on an Apple Mac G5
running OS X, though nchar() works.

>   raw0 <- as.raw(c(65:68, 0 , 70))
>   string0 <- rawToChar(raw0)
> raw0
[1] 41 42 43 44 00 46
> string0
[1] "ABCD\0F"

> nchar(string0)
[1] 6

> grep("F", string0)
integer(0)
>   strsplit(string0, split=NULL, fixed=TRUE)[[1]]
[1] "A" "B" "C" "D"
>   tolower(string0)
[1] "abcd"
>   chartr("F", "x", string0)
[1] "ABCD"
>   substr(string0, 6, 6)
[1] ""
> 
> sessionInfo()
R version 2.5.1 (2007-06-27) 
powerpc-apple-darwin8.9.1 

locale:
en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
> 



Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C. 
V5Z 1L3
Canada




-----Original Message-----
From: r-devel-bounces at r-project.org on behalf of Herve Pages
Sent: Tue 8/7/2007 2:06 PM
To: r-devel at r-project.org
Subject: [Rd] Embedded nuls in strings
 
Hi,

?rawToChar
     'rawToChar' converts raw bytes either to a single character string
     or a character vector of single bytes.  (Note that a single
     character string could contain embedded nuls.)

Allowing embedded nuls in a string might be an interesting experiment but it
seems to cause some troubles to most of the string manipulation functions.

A string with an embedded 0:

  raw0 <- as.raw(c(65:68, 0 , 70))
  string0 <- rawToChar(raw0)

> string0
[1] "ABCD\0F"

nchar() should return 6:
> nchar(string0)
[1] 4

In addition this embedded nul seems to break almost all string manipulation/searching
functions:
  grep("F", string0)
  strsplit(string0, split=NULL, fixed=TRUE)[[1]]
  tolower(string0)
  chartr("F", "x", string0)
  substr(string0, 6, 6)
  ...
  etc...

Not very surprisingly, they all seem to treat string0 as if it was "ABCD"!

Cheers,
H.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue Aug  7 23:49:02 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Aug 2007 17:49:02 -0400
Subject: [Rd] Embedded nuls in strings
In-Reply-To: <46B8DEF0.3030602@fhcrc.org>
References: <46B8DEF0.3030602@fhcrc.org>
Message-ID: <46B8E8CE.1060509@stats.uwo.ca>

On 07/08/2007 5:06 PM, Herve Pages wrote:
> Hi,
> 
> ?rawToChar
>      'rawToChar' converts raw bytes either to a single character string
>      or a character vector of single bytes.  (Note that a single
>      character string could contain embedded nuls.)
> 
> Allowing embedded nuls in a string might be an interesting experiment but it
> seems to cause some troubles to most of the string manipulation functions.
> 
> A string with an embedded 0:
> 
>   raw0 <- as.raw(c(65:68, 0 , 70))
>   string0 <- rawToChar(raw0)
> 
>> string0
> [1] "ABCD\0F"
> 
> nchar() should return 6:
>> nchar(string0)
> [1] 4

You don't state your R version.  The default type of counting in nchar() 
has recently changed from "bytes" (where 6 is correct) to "chars" (where 
4 is correct).

Duncan Murdoch


From hpages at fhcrc.org  Wed Aug  8 00:29:16 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Tue, 07 Aug 2007 15:29:16 -0700
Subject: [Rd] Embedded nuls in strings
In-Reply-To: <46B8E8CE.1060509@stats.uwo.ca>
References: <46B8DEF0.3030602@fhcrc.org> <46B8E8CE.1060509@stats.uwo.ca>
Message-ID: <46B8F23C.3010300@fhcrc.org>

Duncan Murdoch wrote:
> On 07/08/2007 5:06 PM, Herve Pages wrote:
>> Hi,
>>
>> ?rawToChar
>>      'rawToChar' converts raw bytes either to a single character string
>>      or a character vector of single bytes.  (Note that a single
>>      character string could contain embedded nuls.)
>>
>> Allowing embedded nuls in a string might be an interesting experiment
>> but it
>> seems to cause some troubles to most of the string manipulation
>> functions.
>>
>> A string with an embedded 0:
>>
>>   raw0 <- as.raw(c(65:68, 0 , 70))
>>   string0 <- rawToChar(raw0)
>>
>>> string0
>> [1] "ABCD\0F"
>>
>> nchar() should return 6:
>>> nchar(string0)
>> [1] 4
> 
> You don't state your R version.  The default type of counting in nchar()
> has recently changed from "bytes" (where 6 is correct) to "chars" (where
> 4 is correct).


Oops, sorry:

> sessionInfo()
R version 2.6.0 Under development (unstable) (2007-07-02 r42107)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] rcompgen_0.1-15


And indeed:
  raw0 <- as.raw(c(65:68, 0 , 70))
  string0 <- rawToChar(raw0)

> nchar(string0, type="chars")
[1] 4
> nchar(string0, type="bytes")
[1] 6


In addition to the string functions already mentioned before, it's worth noting that
'paste' doesn't seem to be "embedded nul aware" neither:

> paste(string0, "G", sep="")
[1] "ABCDG"

Same for serialization:

> save(string0, file="string0.rda")
> load("string0.rda")
> string0
[1] "ABCD"

One comment about the nchar man page:
  'chars' The number of human-readable characters.

"human-readable" seems to be used for "everything but a nul" here which can be confusing.
For example one would generally think of ascii codes 1 to 31 as non "human-readable" but
nchar() seems to disagree:

> string1 <- rawToChar(as.raw(1:31))
> string1
[1]
"\001\002\003\004\005\006\a\b\t\n\v\f\r\016\017\020\021\022\023\024\025\026\027\030\031\032\033\034\035\036\037"
> nchar(string1, type="chars")
[1] 31


Cheers,
H.


> 
> Duncan Murdoch
>


From murdoch at stats.uwo.ca  Wed Aug  8 02:10:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Aug 2007 20:10:27 -0400
Subject: [Rd] Embedded nuls in strings
In-Reply-To: <46B8F23C.3010300@fhcrc.org>
References: <46B8DEF0.3030602@fhcrc.org> <46B8E8CE.1060509@stats.uwo.ca>
	<46B8F23C.3010300@fhcrc.org>
Message-ID: <46B909F3.1010603@stats.uwo.ca>

On 07/08/2007 6:29 PM, Herve Pages wrote:
> Duncan Murdoch wrote:
>> On 07/08/2007 5:06 PM, Herve Pages wrote:
>>> Hi,
>>>
>>> ?rawToChar
>>>      'rawToChar' converts raw bytes either to a single character string
>>>      or a character vector of single bytes.  (Note that a single
>>>      character string could contain embedded nuls.)
>>>
>>> Allowing embedded nuls in a string might be an interesting experiment
>>> but it
>>> seems to cause some troubles to most of the string manipulation
>>> functions.
>>>
>>> A string with an embedded 0:
>>>
>>>   raw0 <- as.raw(c(65:68, 0 , 70))
>>>   string0 <- rawToChar(raw0)
>>>
>>>> string0
>>> [1] "ABCD\0F"
>>>
>>> nchar() should return 6:
>>>> nchar(string0)
>>> [1] 4
>> You don't state your R version.  The default type of counting in nchar()
>> has recently changed from "bytes" (where 6 is correct) to "chars" (where
>> 4 is correct).
> 
> 
> Oops, sorry:
> 
>> sessionInfo()
> R version 2.6.0 Under development (unstable) (2007-07-02 r42107)
> x86_64-unknown-linux-gnu
> 
> locale:
> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] rcompgen_0.1-15
> 
> 
> And indeed:
>   raw0 <- as.raw(c(65:68, 0 , 70))
>   string0 <- rawToChar(raw0)
> 
>> nchar(string0, type="chars")
> [1] 4
>> nchar(string0, type="bytes")
> [1] 6
> 
> 
> In addition to the string functions already mentioned before, it's worth noting that
> 'paste' doesn't seem to be "embedded nul aware" neither:
> 
>> paste(string0, "G", sep="")
> [1] "ABCDG"
> 
> Same for serialization:
> 
>> save(string0, file="string0.rda")
>> load("string0.rda")
>> string0
> [1] "ABCD"

Of these, I'd say the serialization is the only case where it would be 
reasonable to fix the behaviour.  R depends on C run-time functions for 
most of the string operations, and they'll stop at a null.  So if this 
isn't documented behaviour, it should be, but it's not reasonable to 
rewrite the C run-time string functions just to handle such weird 
objects.  Functions like "grep" require thousands of lines of code, not 
written by us, and in my opinion maintaining changes to it is not 
something the R project should take on.

As to serialization:  there's a comment in the source that embedded 
nulls are handled by it, and that's true up to R-patched, but not in 
R-devel.  Looks like someone has introduced a bug.

Duncan Murdoch
> 
> One comment about the nchar man page:
>   'chars' The number of human-readable characters.
> 
> "human-readable" seems to be used for "everything but a nul" here which can be confusing.
> For example one would generally think of ascii codes 1 to 31 as non "human-readable" but
> nchar() seems to disagree:
> 
>> string1 <- rawToChar(as.raw(1:31))
>> string1
> [1]
> "\001\002\003\004\005\006\a\b\t\n\v\f\r\016\017\020\021\022\023\024\025\026\027\030\031\032\033\034\035\036\037"
>> nchar(string1, type="chars")
> [1] 31

No, "human-readable" also has other meanings in multi-byte encodings. 
If an e-acute is encoded in two bytes in your locale, it still only 
counts as one human-readable character.


From hpages at fhcrc.org  Wed Aug  8 03:13:20 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Tue, 07 Aug 2007 18:13:20 -0700
Subject: [Rd] Embedded nuls in strings
In-Reply-To: <46B909F3.1010603@stats.uwo.ca>
References: <46B8DEF0.3030602@fhcrc.org> <46B8E8CE.1060509@stats.uwo.ca>
	<46B8F23C.3010300@fhcrc.org> <46B909F3.1010603@stats.uwo.ca>
Message-ID: <46B918B0.5090602@fhcrc.org>

Duncan Murdoch wrote:
> On 07/08/2007 6:29 PM, Herve Pages wrote:
[...]
>> Same for serialization:
>>
>>> save(string0, file="string0.rda")
>>> load("string0.rda")
>>> string0
>> [1] "ABCD"
> 
> Of these, I'd say the serialization is the only case where it would be
> reasonable to fix the behaviour.  R depends on C run-time functions for
> most of the string operations, and they'll stop at a null.  So if this
> isn't documented behaviour, it should be, but it's not reasonable to
> rewrite the C run-time string functions just to handle such weird
> objects.  Functions like "grep" require thousands of lines of code, not
> written by us, and in my opinion maintaining changes to it is not
> something the R project should take on.

I was not (of course) suggesting to fix all the string manipulation functions.
I'm just wondering why R would try to support embedded nuls in the first
place given that they can only be a source of troubles.

What about this:

  > string0
  [1] "ABCD\0F"
  > string0 == "ABCD"
  [1] TRUE

string0 is obviously different from "ABCD"!

Maybe it's easier to change the semantic of rawToChar() so it doesn't return
a string with embedded nuls. More generally speaking, base functions should
always return "clean" strings.

> 
> As to serialization:  there's a comment in the source that embedded
> nulls are handled by it, and that's true up to R-patched, but not in
> R-devel.  Looks like someone has introduced a bug.
> 
> Duncan Murdoch
>>
>> One comment about the nchar man page:
>>   'chars' The number of human-readable characters.
>>
>> "human-readable" seems to be used for "everything but a nul" here
>> which can be confusing.
>> For example one would generally think of ascii codes 1 to 31 as non
>> "human-readable" but
>> nchar() seems to disagree:
>>
>>> string1 <- rawToChar(as.raw(1:31))
>>> string1
>> [1]
>> "\001\002\003\004\005\006\a\b\t\n\v\f\r\016\017\020\021\022\023\024\025\026\027\030\031\032\033\034\035\036\037"
>>
>>> nchar(string1, type="chars")
>> [1] 31
> 
> No, "human-readable" also has other meanings in multi-byte encodings. If
> an e-acute is encoded in two bytes in your locale, it still only counts
> as one human-readable character.
>


From murdoch at stats.uwo.ca  Wed Aug  8 03:30:11 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Aug 2007 21:30:11 -0400
Subject: [Rd] Embedded nuls in strings
In-Reply-To: <46B918B0.5090602@fhcrc.org>
References: <46B8DEF0.3030602@fhcrc.org> <46B8E8CE.1060509@stats.uwo.ca>
	<46B8F23C.3010300@fhcrc.org> <46B909F3.1010603@stats.uwo.ca>
	<46B918B0.5090602@fhcrc.org>
Message-ID: <46B91CA3.2020506@stats.uwo.ca>

On 07/08/2007 9:13 PM, Herve Pages wrote:
> Duncan Murdoch wrote:
>> On 07/08/2007 6:29 PM, Herve Pages wrote:
> [...]
>>> Same for serialization:
>>>
>>>> save(string0, file="string0.rda")
>>>> load("string0.rda")
>>>> string0
>>> [1] "ABCD"
>> Of these, I'd say the serialization is the only case where it would be
>> reasonable to fix the behaviour.  R depends on C run-time functions for
>> most of the string operations, and they'll stop at a null.  So if this
>> isn't documented behaviour, it should be, but it's not reasonable to
>> rewrite the C run-time string functions just to handle such weird
>> objects.  Functions like "grep" require thousands of lines of code, not
>> written by us, and in my opinion maintaining changes to it is not
>> something the R project should take on.
> 
> I was not (of course) suggesting to fix all the string manipulation functions.
> I'm just wondering why R would try to support embedded nuls in the first
> place given that they can only be a source of troubles.

I think this predates raw vectors, so this would have been the only way 
to handle strings with embedded nulls.  C has problems with those, but 
not all other languages do.

> 
> What about this:
> 
>   > string0
>   [1] "ABCD\0F"
>   > string0 == "ABCD"
>   [1] TRUE
> 
> string0 is obviously different from "ABCD"!

This is documented behaviour, from ?Comparison:

"When comparisons are made between character strings, parts of the
      strings after embedded 'nul' characters are ignored.  (This is
      necessary as the position of 'nul' in the collation sequence is
      undefined, and we want one of '<', '==' and '>' to be true for any
      comparison.)"

But notice

 > identical(string0, "ABCD")
[1] FALSE

This is documented as

      "Comparison of character strings allows for embedded 'nul'
      characters."

Duncan Murdoch

> 
> Maybe it's easier to change the semantic of rawToChar() so it doesn't return
> a string with embedded nuls. More generally speaking, base functions should
> always return "clean" strings.
> 
>> As to serialization:  there's a comment in the source that embedded
>> nulls are handled by it, and that's true up to R-patched, but not in
>> R-devel.  Looks like someone has introduced a bug.
>>
>> Duncan Murdoch
>>> One comment about the nchar man page:
>>>   'chars' The number of human-readable characters.
>>>
>>> "human-readable" seems to be used for "everything but a nul" here
>>> which can be confusing.
>>> For example one would generally think of ascii codes 1 to 31 as non
>>> "human-readable" but
>>> nchar() seems to disagree:
>>>
>>>> string1 <- rawToChar(as.raw(1:31))
>>>> string1
>>> [1]
>>> "\001\002\003\004\005\006\a\b\t\n\v\f\r\016\017\020\021\022\023\024\025\026\027\030\031\032\033\034\035\036\037"
>>>
>>>> nchar(string1, type="chars")
>>> [1] 31
>> No, "human-readable" also has other meanings in multi-byte encodings. If
>> an e-acute is encoded in two bytes in your locale, it still only counts
>> as one human-readable character.
>>


From savicky at cs.cas.cz  Wed Aug  8 08:54:00 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 8 Aug 2007 08:54:00 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070727071006.GA31738@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
	<316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>
	<20070713203735.GA18016@cs.cas.cz>
	<20070725070320.GA20948@cs.cas.cz>
	<20070727071006.GA31738@cs.cas.cz>
Message-ID: <20070808065400.GA5991@cs.cas.cz>

Thanks to Martin Maechler for his comments, advice and for pointing
out the speed problem. Thanks also to Ben Bolker for tests of speed,
which confirm that for small arrays, a slow down by a factor of about
1.2 - 1.5 may occur. Now, I would like to present a new version of sweep,
which is simpler and has an option to avoid the test. This is expected
to be used in scripts, where the programmer is quite sure that the
usage is correct and speed is required. The new version differs from
the previous one in the following:

1. The option check.margin has a different meaning. It defaults to TRUE
   and it determines whether the test is performed or not.

2. Since check.margin has the meaning above, it cannot be used
   to select, which test should be performed. This depends on the
   type of STATS. The suggested sweep function contains two tests:
   - a vector test by Heather Turner, which is used, if STATS 
     has no dim attribute and, hence, is a vector (STATS should
     not be anything else than a vector or an array)
   - an array test used if STATS has dim attribute.
   The vector test allows some kinds of recycling, while the array test
   does not. Hence, in the most common case, where x is a matrix
   and STATS is a vector, if the user likes to be warned if the length
   of the vector is not exactly the right one, the following call is
   suggested: sweep(x,MARGIN,as.array(STATS)). Otherwise, a warning
   will be generated only if length(STATS) does not divide the specified
   dimension of x, which is nrow(x) (MARGIN=1) or ncol(x) (MARGIN=2).

3. If STATS is an array, then the test is more restrictive than in
   the previous version. It is now required that after deleting
   dimensions with one level, the remaining dimensions coincide.
   The previous version allowed additionally the cases, when dim(STATS)
   is a prefix of dim(x)[MARGIN], for example, if dim(STATS) = k1 and
   dim(x)[MARGIN] = c(k1,k2).

The code of the tests in the suggested sweep is based on the previous suggestions
 https://stat.ethz.ch/pipermail/r-help/2005-June/073989.html by Robin Hankin
 https://stat.ethz.ch/pipermail/r-help/2005-June/074001.html by Heather Turner
 https://stat.ethz.ch/pipermail/r-devel/2007-June/046217.html by Ben Bolker
with some further modifications.

The modification of sweep.Rd was prepared by Ben Bolker and me.

I would like to encourage everybody who likes to express his opinion
on the patch to do it now. In my opinion, the suggestion of the
new code stabilized in the sense that I will not modify it unless
there is a negative feedback.

A patch against R-devel_2007-08-06 is attached. It contains tabs. If they
are corrupted by email transfer, use the link
  http://www.cs.cas.cz/~savicky/R-devel/patch-sweep
which is an identical copy.

Petr Savicky.

================================================================================================
--- R-devel_2007-08-06/src/library/base/R/sweep.R	2007-07-27 17:51:13.000000000 +0200
+++ R-devel_2007-08-06-sweep/src/library/base/R/sweep.R	2007-08-07 10:30:12.383672960 +0200
@@ -14,10 +14,29 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/
 
-sweep <- function(x, MARGIN, STATS, FUN = "-", ...)
+sweep <- function(x, MARGIN, STATS, FUN = "-", check.margin=TRUE, ...)
 {
     FUN <- match.fun(FUN)
     dims <- dim(x)
+	if (check.margin) {
+		dimmargin <- dims[MARGIN]
+		dimstats <- dim(STATS)
+		lstats <- length(STATS)
+		if (lstats > prod(dimmargin)) {
+			warning("length of STATS greater than the extent of dim(x)[MARGIN]")
+		} else if (is.null(dimstats)) { # STATS is a vector
+			cumDim <- c(1, cumprod(dimmargin))
+			upper <- min(cumDim[cumDim >= lstats])
+			lower <- max(cumDim[cumDim <= lstats])
+			if (upper %% lstats != 0 || lstats %% lower != 0)
+				warning("STATS does not recycle exactly across MARGIN")
+		} else {
+			dimmargin <- dimmargin[dimmargin > 1]
+			dimstats <- dimstats[dimstats > 1]
+			if (length(dimstats) != length(dimmargin) || any(dimstats != dimmargin))
+				warning("length(STATS) or dim(STATS) do not match dim(x)[MARGIN]")
+		}
+	}
     perm <- c(MARGIN, (1:length(dims))[ - MARGIN])
     FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
 }
--- R-devel_2007-08-06/src/library/base/man/sweep.Rd	2007-07-27 17:51:35.000000000 +0200
+++ R-devel_2007-08-06-sweep/src/library/base/man/sweep.Rd	2007-08-07 10:29:45.517757200 +0200
@@ -11,7 +11,7 @@
   statistic.
 }
 \usage{
-sweep(x, MARGIN, STATS, FUN="-", \dots)
+sweep(x, MARGIN, STATS, FUN="-", check.margin=TRUE, \dots)
 }
 \arguments{
   \item{x}{an array.}
@@ -22,8 +22,18 @@
     case of binary operators such as \code{"/"} etc., the function name
     must backquoted or quoted. (\code{FUN} is found by a call to
     \code{\link{match.fun}}.)}
+  \item{check.margin}{logical. If \code{TRUE} (the default), warn if the
+    length or dimensions of \code{STATS} do
+    not match the specified dimensions of \code{x}.}
   \item{\dots}{optional arguments to \code{FUN}.}
 }
+\details{
+  The consistency check among \code{STATS}, \code{MARGIN} and \code{x}
+  is stricter if \code{STATS} is an array than if it is a vector.
+  In the vector case, some kinds of recycling are allowed without a
+  warning. Use \code{sweep(x,MARGIN,as.array(STATS))} if \code{STATS}
+  is a vector and you want to be warned if any recycling occurs.
+}
 \value{
   An array with the same shape as \code{x}, but with the summary
   statistics swept out.


From ligges at statistik.uni-dortmund.de  Wed Aug  8 09:21:10 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 08 Aug 2007 09:21:10 +0200
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in
	R	package
In-Reply-To: <46B8D6AD.9040707@cimr.cam.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>
	<46B8D6AD.9040707@cimr.cam.ac.uk>
Message-ID: <46B96EE6.2090606@statistik.uni-dortmund.de>



Hin-Tak Leung wrote:
> Prof Brian Ripley wrote:
>> OpenBUGS is distributed under GPL2, so this seems not to apply.
>> It is distributed as source and as binaries: the difficulty is that it 
>> is written in Object Pascal for which a compiler is not readily available.
> 
> Argh, I just thought of a proper technical reason, and I think I have 
> spotted a possible bug in the original poster's code! Some choose to do
> dlopen() when the DLL/so is in a non-standard/non-system location, as an
> alternative to setting LD_LIBRARY_PATH explicitly or other link-loader
> magics.
> 
> The line:
>     handle = dlopen("./brugs.so", RTLD_LAZY);
> 
> Seems to suggest this, However, the problem with this code, is that
> the current directory  (./) may not be where the user thinks it is.
> I think the user meant to prepend $R_HOME/library/<package>/inst/ 
> somehow to "brugs.so", and dlopen'ing 
> "$R_HOME/library/<package>/inst/brugs.so" instead.

No, it's fine if the executable is started in the same directory, and 
that can be assured by the calling R code. Otherwise it will only work 
if you have the package in the main library of R.
Anyway, it is still highly preferable to just load the Bugs lib into R, 
if we only could compile the stuff...

Uwe




> Hin-Tak
> 
> <snipped>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Aug  8 09:25:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Aug 2007 08:25:10 +0100 (BST)
Subject: [Rd] Use of __FUNCTION__ and__PRETTY_FUNCTION__ is not portable
Message-ID: <Pine.LNX.4.64.0708080742240.15798@gannet.stats.ox.ac.uk>

These are C/C++ extensions found in several packages[1].  They are 
non-standard: the C99 standard has __func__ which should be used in C in 
place of either.  If you really want back compatibilty, try something like

#if __STDC_VERSION__ < 199901L
# if __GNUC__ >= 2
#  define __func__ __FUNCTION__
# else
#  define __func__ "<unknown>"
# endif
#endif

I don't know a portable equivalent in C++, but I do know that some non-GNU 
C++ compilers do not support these, so they should be conditionalized on
__GNUC__  (or tested for by configure).  For example, SunPro C++ supports 
__func__ as a (non-default) extension:

http://docs.sun.com/app/docs/doc/819-5267/6n7c46dpc?a=view

so probably configure should be used to test what is available.


[1] GOSim MCMCpack MasterBayes RGtk2 rcom smoothSurv

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Mike.Lawrence at DAL.CA  Wed Aug  8 15:52:59 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Wed, 08 Aug 2007 10:52:59 -0300
Subject: [Rd] SWF animation method
Message-ID: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>

Hi all,

Just thought I'd share something I discovered last night. I was  
interested in creating animations consisting of a series of plots and  
after finding very little in the usual sources regarding animation in  
R directly, and disliking the imagemagick method described here 
(http://tolstoy.newcastle.edu.au/R/help/05/10/13297.html), I  
discovered that if one exports the plots to a multipage pdf, it is  
relatively trivial to then use the pdf2swf command in SWFTools  
(http://www.swftools.org/download.html; mac install instructions  
here: http://9mmedia.com/blog/?p=7).

pdf2swf seems to generate swf animations with a slow frame rate, but  
you can increase the framerate using 'swfcombine -r 30 --dummy  
myslow.swf -o myfast.swf', where the value passed to -r is the  
framerate.

Unfortunately, this method seems to have limitations with regards to  
the number of plots it can convert. For example, on my system (17"  
macbook pro, 2.33GHz, 2GB ram, OSX 10.4.10, R 2.5.1) the maximum  
number of single point plots I can do is about 5400 (i.e. for(i in  
1:5400) plot(runif(1),ylim=c(0,1)) ). Complexity of the plots might  
matter as well, but I only have rather convoluted examples of this.  
Also, pdf2swf throws up a lot of errors ('ERROR   Internal error:  
drawChar.render!=beginString.render'), the origin of which I know  
not, that might be slowing things down.

Now, if only someone could wrap this process into a single R command  
(I'm a little too newb to do this myself I think).

Mike

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From rasmussen.bryan at gmail.com  Wed Aug  8 16:12:22 2007
From: rasmussen.bryan at gmail.com (bryan rasmussen)
Date: Wed, 8 Aug 2007 16:12:22 +0200
Subject: [Rd] SWF animation method
In-Reply-To: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>
References: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>
Message-ID: <3bb44c6e0708080712qfd8c387t3e78e8dfd442f5eb@mail.gmail.com>

I suppose what is really wanted is a way to associate a the parts of a
graph with a timeline a la gapminder.

Cheers,
Bryan Rasmussen

On 8/8/07, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi all,
>
> Just thought I'd share something I discovered last night. I was
> interested in creating animations consisting of a series of plots and
> after finding very little in the usual sources regarding animation in
> R directly, and disliking the imagemagick method described here
> (http://tolstoy.newcastle.edu.au/R/help/05/10/13297.html), I
> discovered that if one exports the plots to a multipage pdf, it is
> relatively trivial to then use the pdf2swf command in SWFTools
> (http://www.swftools.org/download.html; mac install instructions
> here: http://9mmedia.com/blog/?p=7).
>
> pdf2swf seems to generate swf animations with a slow frame rate, but
> you can increase the framerate using 'swfcombine -r 30 --dummy
> myslow.swf -o myfast.swf', where the value passed to -r is the
> framerate.
>
> Unfortunately, this method seems to have limitations with regards to
> the number of plots it can convert. For example, on my system (17"
> macbook pro, 2.33GHz, 2GB ram, OSX 10.4.10, R 2.5.1) the maximum
> number of single point plots I can do is about 5400 (i.e. for(i in
> 1:5400) plot(runif(1),ylim=c(0,1)) ). Complexity of the plots might
> matter as well, but I only have rather convoluted examples of this.
> Also, pdf2swf throws up a lot of errors ('ERROR   Internal error:
> drawChar.render!=beginString.render'), the origin of which I know
> not, that might be slowing things down.
>
> Now, if only someone could wrap this process into a single R command
> (I'm a little too newb to do this myself I think).
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://memetic.ca
>
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
>         - Piet Hein
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ted.harding at nessie.mcc.ac.uk  Wed Aug  8 16:25:48 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 08 Aug 2007 15:25:48 +0100 (BST)
Subject: [Rd] SWF animation method
In-Reply-To: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>
Message-ID: <XFMail.070808152548.ted.harding@nessie.mcc.ac.uk>

On 08-Aug-07 13:52:59, Mike Lawrence wrote:
> Hi all,
> 
> Just thought I'd share something I discovered last night. I was  
> interested in creating animations consisting of a series of plots and  
> after finding very little in the usual sources regarding animation in  
> R directly, and disliking the imagemagick method described here 
> (http://tolstoy.newcastle.edu.au/R/help/05/10/13297.html), I  
> discovered that if one exports the plots to a multipage pdf, it is  
> relatively trivial to then use the pdf2swf command in SWFTools  
> (http://www.swftools.org/download.html; mac install instructions  
> here: http://9mmedia.com/blog/?p=7).

Thanks so much for sharing your discovery, Mike! Out of the blue!
(Unexpected bonus for being on the R list).

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Aug-07                                       Time: 15:25:44
------------------------------ XFMail ------------------------------


From rfrancois at mango-solutions.com  Wed Aug  8 17:11:16 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Wed, 08 Aug 2007 16:11:16 +0100
Subject: [Rd] SWF animation method
In-Reply-To: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>
References: <FCD0D064-313C-4695-A706-4C4DCCFB06A8@DAL.CA>
Message-ID: <46B9DD14.3020908@mango-solutions.com>

Hello Mike,

You might want to give "mencoder" a try. It usually comes with mplayer. 
I did play with it a while ago and was fairly happy with the results.
Basically, the idea was to create many jpg files somewhere, which is not 
too hard using the %03d substitution described in ?jpeg.
The rest is described here: 
http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-enc-images.html

Cheers,

Romain

PS: You might find some links in this (not really maintained) webpage: 
http://addictedtor.free.fr/movies/

Mike Lawrence wrote:
> Hi all,
>
> Just thought I'd share something I discovered last night. I was 
> interested in creating animations consisting of a series of plots and 
> after finding very little in the usual sources regarding animation in 
> R directly, and disliking the imagemagick method described 
> here(http://tolstoy.newcastle.edu.au/R/help/05/10/13297.html), I 
> discovered that if one exports the plots to a multipage pdf, it is 
> relatively trivial to then use the pdf2swf command in SWFTools 
> (http://www.swftools.org/download.html; mac install instructions here: 
> http://9mmedia.com/blog/?p=7).
>
> pdf2swf seems to generate swf animations with a slow frame rate, but 
> you can increase the framerate using 'swfcombine -r 30 --dummy 
> myslow.swf -o myfast.swf', where the value passed to -r is the framerate.
>
> Unfortunately, this method seems to have limitations with regards to 
> the number of plots it can convert. For example, on my system (17" 
> macbook pro, 2.33GHz, 2GB ram, OSX 10.4.10, R 2.5.1) the maximum 
> number of single point plots I can do is about 5400 (i.e. for(i in 
> 1:5400) plot(runif(1),ylim=c(0,1)) ). Complexity of the plots might 
> matter as well, but I only have rather convoluted examples of this. 
> Also, pdf2swf throws up a lot of errors ('ERROR   Internal error: 
> drawChar.render!=beginString.render'), the origin of which I know not, 
> that might be slowing things down.
>
> Now, if only someone could wrap this process into a single R command 
> (I'm a little too newb to do this myself I think).
>
> Mike
>
> -- 
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://memetic.ca
>
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
>     - Piet Hein
>
>
>


-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From Max.Kuhn at pfizer.com  Wed Aug  8 17:20:10 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Wed, 8 Aug 2007 11:20:10 -0400
Subject: [Rd] SWF animation method
In-Reply-To: <46B9DD14.3020908@mango-solutions.com>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3092865BF@groamrexm03.amer.pfizer.com>

Also,

I've used ImageMagick's convert utility to make animated gifs. Generate
a series of files (I used png) and then

convert -delay 50 -page +0+0 im01.png -page +0+0 im01.png -page +0+0
im01.png -loop 0 mov.gif
 
Max

> -----Original Message-----
> From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
> Sent: Wednesday, August 08, 2007 11:11 AM
> To: Mike Lawrence
> Cc: r-devel at r-project.org; John Christie
> Subject: Re: [Rd] SWF animation method
> 
> Hello Mike,
> 
> You might want to give "mencoder" a try. It usually comes with
mplayer. 
> I did play with it a while ago and was fairly happy with the results.
> Basically, the idea was to create many jpg files somewhere, which is
not 
> too hard using the %03d substitution described in ?jpeg.
> The rest is described here: 
> http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-enc-images.html
> 
> Cheers,
> 
> Romain
> 
> PS: You might find some links in this (not really maintained) webpage:

> http://addictedtor.free.fr/movies/

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From Mike.Lawrence at dal.ca  Wed Aug  8 18:36:58 2007
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 8 Aug 2007 13:36:58 -0300
Subject: [Rd] SWF animation method
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3092865BF@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3092865BF@groamrexm03.amer.pfizer.com>
Message-ID: <6BAE393D-66DB-4692-9FC2-95E368BCD391@dal.ca>

Thanks to Max & Romain for noting alternative methods.

As mentioned in my original post, I've tried the png->imagemagick- 
 >gif solution and was displeased with quality of the results (using  
default quality values at least).

Additionally, I disliked the idea (shared with the menconder method)  
that part of the process involved the creation of a large number of  
intermediary files which would then have to be deleted at some point.  
I know 'rm *.png' is as easy as 'rm mypdf.pdf', but the difference in  
forgetting to do this, from the perspective of gui file browsing at  
least, is significant.

Mike

On 8-Aug-07, at 12:20 PM, Kuhn, Max wrote:

> Also,
>
> I've used ImageMagick's convert utility to make animated gifs.  
> Generate
> a series of files (I used png) and then
>
> convert -delay 50 -page +0+0 im01.png -page +0+0 im01.png -page +0+0
> im01.png -loop 0 mov.gif
>
> Max
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
>> Sent: Wednesday, August 08, 2007 11:11 AM
>> To: Mike Lawrence
>> Cc: r-devel at r-project.org; John Christie
>> Subject: Re: [Rd] SWF animation method
>>
>> Hello Mike,
>>
>> You might want to give "mencoder" a try. It usually comes with
> mplayer.
>> I did play with it a while ago and was fairly happy with the results.
>> Basically, the idea was to create many jpg files somewhere, which is
> not
>> too hard using the %03d substitution described in ?jpeg.
>> The rest is described here:
>> http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-enc-images.html
>>
>> Cheers,
>>
>> Romain
>>
>> PS: You might find some links in this (not really maintained)  
>> webpage:
>
>> http://addictedtor.free.fr/movies/
>
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and  
> may be privileged.  It is intended for the addressee(s) only.   
> Access to this E-mail by anyone else is unauthorized.  If you are  
> not an addressee, any disclosure or copying of the contents of this  
> E-mail or any action taken (or not taken) in reliance on it is  
> unauthorized and may be unlawful.  If you are not an addressee,  
> please inform the sender immediately.

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From tobias.verbeke at telenet.be  Wed Aug  8 21:24:19 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Wed, 08 Aug 2007 21:24:19 +0200
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS
	in	R	package
In-Reply-To: <46B96EE6.2090606@statistik.uni-dortmund.de>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>
	<46B96EE6.2090606@statistik.uni-dortmund.de>
Message-ID: <46BA1863.6030609@telenet.be>

Thank you very much for your input.

In the meantime I was -- thanks to
the pointer to the Rserve Makefile
by Professor Ripley -- able to have
a Makefile that built the package
correctly:

SFILE = ../inst/OpenBUGS/linbugs.c
XFILE = ../inst/OpenBUGS/linbugs
SOFILE = ../src/linbugs.so

all: $(XFILE) copyop

$(XFILE): $(SFILE)
	gcc -m32 -o $(XFILE) $(SFILE) -ldl

copyop:	$(XFILE)
# Only *.so get copied. Therefore we need to fake the bin files as 
".so"s to get
# copied. Not a nice hack, but it works... (Comment from Rserve)
	cp $(XFILE) $(SOFILE)
clean:
	rm -f *.so *~ $(XFILE)
.PHONY: copyop clean

(Note that I changed the naming of the C source and compiled
file following a complaint by the package checker that observed
that the OpenBUGS distribution has a directory Bugs which on
case-insensitive systems could be confused with bugs, the previous
name of the executable)

Uwe Ligges wrote:
> Hin-Tak Leung wrote:
>> Prof Brian Ripley wrote:
>>> OpenBUGS is distributed under GPL2, so this seems not to apply.
>>> It is distributed as source and as binaries: the difficulty is that it 
>>> is written in Object Pascal for which a compiler is not readily available.
>> Argh, I just thought of a proper technical reason, and I think I have 
>> spotted a possible bug in the original poster's code! Some choose to do
>> dlopen() when the DLL/so is in a non-standard/non-system location, as an
>> alternative to setting LD_LIBRARY_PATH explicitly or other link-loader
>> magics.
>>
>> The line:
>>     handle = dlopen("./brugs.so", RTLD_LAZY);
>>
>> Seems to suggest this, However, the problem with this code, is that
>> the current directory  (./) may not be where the user thinks it is.
>> I think the user meant to prepend $R_HOME/library/<package>/inst/ 
>> somehow to "brugs.so", and dlopen'ing 
>> "$R_HOME/library/<package>/inst/brugs.so" instead.

This should be "$R_HOME/library/<package>/OpenBUGS/brugs.so"

(without the inst level that is taken out when installing the package)

> No, it's fine if the executable is started in the same directory, and 
> that can be assured by the calling R code. Otherwise it will only work 
> if you have the package in the main library of R.
> Anyway, it is still highly preferable to just load the Bugs lib into R, 
> if we only could compile the stuff...

Actually, I think Hin-Tak is right about the absolute path. Even when 
the R code will call the executable that resides in that directory, R 
will call it from any directory and that (current) directory will be 
resolved (at least that is what I observe experimentally).

When such an absolute path is coded in, everything runs fine -- we now 
can run a BUGS script from within R under GNU/Linux !

It would however be nice to solve the remaining problem of the
absolute path in the dlopen() call, i.e. being able to fill in
`dynamically' the library path to which the package is actually installed.

Is there a way to have the library path to which a package is installed 
available during package installation and then to do some 
text-processing to fill in this path dynamically into the C file i.e.
as argument of dlopen() before compiling it?

Thanks again,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From hin-tak.leung at cimr.cam.ac.uk  Wed Aug  8 22:58:13 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 08 Aug 2007 21:58:13 +0100
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS
	in	R	package
In-Reply-To: <46BA1863.6030609@telenet.be>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>
	<46B96EE6.2090606@statistik.uni-dortmund.de>
	<46BA1863.6030609@telenet.be>
Message-ID: <46BA2E65.7080301@cimr.cam.ac.uk>

Tobias Verbeke wrote:
<snipped>
> Actually, I think Hin-Tak is right about the absolute path. Even when 
> the R code will call the executable that resides in that directory, R 
> will call it from any directory and that (current) directory will be 
> resolved (at least that is what I observe experimentally).
> 
> When such an absolute path is coded in, everything runs fine -- we now 
> can run a BUGS script from within R under GNU/Linux !
> 
> It would however be nice to solve the remaining problem of the
> absolute path in the dlopen() call, i.e. being able to fill in
> `dynamically' the library path to which the package is actually installed.
> 
> Is there a way to have the library path to which a package is installed 
> available during package installation and then to do some 
> text-processing to fill in this path dynamically into the C file i.e.
> as argument of dlopen() before compiling it?
<snipped>

I don't know if there is a neater way of doing this, but one somewhat 
clunky way is to process the result of .libPath() , append each of its 
elements by <package>/inst/OpenBUGS/bugs.so and test if the file exists,
(.libPath() should be quite a small character vector so it should be too
slow to test every one), then pass the result as an explicit
argument to the main bugs binary before everything else it takes.

I think there is a more clever way of telling where the current package
is installed/located but it escapes me at the moment. Perhaps the source 
code of data() (just typying 'data' without the () at the comment prompt 
will display the source), can shed some lights on this, since data() 
does something quite similiar.

Good luck, and it is an interesting discussion so far.

Hin-Tak


From Manuel.A.Morales at williams.edu  Thu Aug  9 15:34:27 2007
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Thu, 09 Aug 2007 09:34:27 -0400
Subject: [Rd] Feature request: wrapper to gsl multiroot
Message-ID: <1186666467.5977.8.camel@mrubra.localdomain>

A question that often comes up in the listserv is how to solve a system
of nonlinear equations. Recently, a new wrapper function that interfaces
with the gsl library multimin was added to the gsl package as an
alternative to optim(). Unfortunately, I can't code in C, so this is a
shameless request for anyone that might be interested in writing a
similar wrapper for the multiroot gsl library :-)

Manuel

-- 
http://mutualism.williams.edu


From agalecki at umich.edu  Tue Aug  7 21:44:24 2007
From: agalecki at umich.edu (agalecki at umich.edu)
Date: Tue,  7 Aug 2007 21:44:24 +0200 (CEST)
Subject: [Rd] Bug in coef<-.varIdent method (nlme package) (PR#9831)
Message-ID: <20070807194424.F283466839@slim.kubism.ku.dk>

This is a multi-part message in MIME format.
--------------040502080208060001050807
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

Hello,

1. It appears that "coef<-.varIdent" method does not work properly in 
some instances.
Execution error:

Error in `coef<-.varIdent`(`*tmp*`, value = c(11, 12)) :
        Cannot change the length of the varIdent parameter after 
initialization


occurs when  "coef<-.varIdent" is applied to an initialized object of 
class varIdent  with some of the coefficients  being _fixed_.
Attached files: 'varIdentOrthoEmail.txt'  and 'varIdentOrthoEmail.Rout' 
illustrate the problem.

2. The code for  "coef<-.varIdentX" method in  
'varIdentmethodsRevised.txt' file  illustrates how to fix this problem.

3. Specifically, to fix the problem the line

       if (length(value) != nGroups  - 1)  

   in  the "coef<-.varIdent" method should be replaced
   with the following two lines :

        nFixed  <- sum(as.numeric(attr(object,"whichFix")))  # inserted 
new line
        if (length(value) != nGroups - nFixed - 1) {               # 
modified original line

4. Note: Although I am using lme "3.1-80", the  related problem PR#9765 
is fixed manually by over-writing varIdent function.

Thank you

Andrzej Galecki



--------------040502080208060001050807
Content-Type: text/plain;
 name="varIdentXOrthoEmail.txt"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="varIdentXOrthoEmail.txt"



ls() 
require(nlme)
sessionInfo()


## New class varIdentX and methods defined.
### coef<-.varIdentX illustrates how to fix a bug in coef<-.varIdent
# Note: PR#9765 fixed in varIdent() and varIdentX() 
source("C:/temp/varIdentmethodsRevised.txt")
ls()



#### Chunk 1: Everything is OK here
# value= and fixed= arguments
# variance component at age=12 is fixed

val <- c("10"=1.10,"14"=1.14)
vf <- varIdent(value=val, form=~1|age, fixed=c("12"=1.12))
vfi <- Initialize(vf,Orthodont)
str(vfi)
coef(vfi)
coef(vfi, unconstrained = FALSE, allCoef = TRUE)  
vfiCopy <- vfi        # copy of an initialized object

#### Chunk 2: Bug in coef<-.varIdent illustrated

length(vfiCopy)             # length is 2
coef(vfiCopy) <- c(11,12)   # Execution error
# Error in `coef<-.varIdent`(`*tmp*`, value = c(11, 12)) : 
#        Cannot change the length of the varIdent parameter after initialization

#### Chunk 3: Consequently the same execution error in gls

gls.error  <- gls(distance ~ age, 
                weights  = vfi,
                data=Orthodont)

#Error in `coef<-.varIdent`(`*tmp*`, value = c(0.095310179804325, 0.131028262406404 : 
#         Cannot change the length of the varIdent parameter after initialization


### Chunk 1A: 
  
val <- c("10"=1.10,"14"=1.14)
vf <- varIdentX(value=val, form=~1|age, fixed=c("12"=1.12))
vfi <- Initialize(vf,Orthodont)
str(vfi)              # Note: class varIdentX
coef(vfi)
coef(vfi, unconstrained = FALSE, allCoef = TRUE)  
vfiCopy <- vfi        # copy of an initialized object

#### Chunk 2A: Bug in coef<-.varIdent  *** corrected ***

length(vfiCopy)             # length is 2
coef(vfiCopy) <- c(11,12)   # NO Execution error

#### Chunk 3A: No execution error in gls

gls.noerror  <- gls(distance ~ age, 
                weights  = vfi,
                data=Orthodont)



--------------040502080208060001050807
Content-Type: text/plain;
 name="varIdentXOrthoEmail.Rout"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="varIdentXOrthoEmail.Rout"

> ls() 
character(0)
> require(nlme)
Loading required package: nlme
[1] TRUE
> sessionInfo()
R version 2.5.0 (2007-04-23) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"     

other attached packages:
    nlme 
"3.1-80" 
> 
> 
> ## New class varIdentX and methods defined.
> ### coef<-.varIdentX illustrates how to fix a bug in coef<-.varIdent
> # Note: PR#9765 fixed in varIdent() and varIdentX() 
> source("C:/temp/varIdentmethodsRevised.txt")
> ls()
[1] "coef.varIdentX"       "coef<-.varIdentX"     "Initialize.varIdentX"
[4] "varIdent"             "varIdentX"           
> 
> 
> 
> #### Chunk 1: Everything is OK here
> # value= and fixed= arguments
> # variance component at age=12 is fixed
> 
> val <- c("10"=1.10,"14"=1.14)
> vf <- varIdent(value=val, form=~1|age, fixed=c("12"=1.12))
> vfi <- Initialize(vf,Orthodont)
> str(vfi)
Classes 'varIdent', 'varFunc'  atomic [1:2] 0.0953 0.1310
  ..- attr(*, "groupNames")= chr [1:4] "8" "10" "14" "12"
  ..- attr(*, "fixed")= Named num 0.113
  .. ..- attr(*, "names")= chr "12"
  ..- attr(*, "formula")=Class 'formula' length 2 ~1 | age
  .. .. ..- attr(*, ".Environment")=<R_GlobalEnv> 
  ..- attr(*, "groups")= chr [1:108] "8" "10" "12" "14" ...
  ..- attr(*, "whichFix")= logi [1:3] FALSE FALSE  TRUE
  ..- attr(*, "weights")= Named num [1:108] 1.000 0.909 0.893 0.877 1.000 ...
  .. ..- attr(*, "names")= chr [1:108] "8" "10" "12" "14" ...
  ..- attr(*, "logLik")= num -9.17
> coef(vfi)
[1] 0.09531018 0.13102826
> coef(vfi, unconstrained = FALSE, allCoef = TRUE)  
   8   10   14   12 
1.00 1.10 1.14 1.12 
> vfiCopy <- vfi        # copy of an initialized object
> 
> #### Chunk 2: Bug in coef<-.varIdent illustrated
> 
> length(vfiCopy)             # length is 2
[1] 2
> coef(vfiCopy) <- c(11,12)   # Execution error
Error in `coef<-.varIdent`(`*tmp*`, value = c(11, 12)) : 
        Cannot change the length of the varIdent parameter after initialization
> # Error in `coef<-.varIdent`(`*tmp*`, value = c(11, 12)) : 
> #        Cannot change the length of the varIdent parameter after initialization
> 
> #### Chunk 3: Consequently the same execution error in gls
> 
> gls.error  <- gls(distance ~ age, 
+                 weights  = vfi,
+                 data=Orthodont)
Error in `coef<-.varIdent`(`*tmp*`, value = c(0.095310179804325, 0.131028262406404 : 
        Cannot change the length of the varIdent parameter after initialization
> 
> #Error in `coef<-.varIdent`(`*tmp*`, value = c(0.095310179804325, 0.131028262406404 : 
> #         Cannot change the length of the varIdent parameter after initialization
> 
> 
> ### Chunk 1A: 
>   
> val <- c("10"=1.10,"14"=1.14)
> vf <- varIdentX(value=val, form=~1|age, fixed=c("12"=1.12))
> vfi <- Initialize(vf,Orthodont)
> str(vfi)              # Note: class varIdentX
Classes 'varIdentX', 'varFunc'  atomic [1:2] 0.0953 0.1310
  ..- attr(*, "groupNames")= chr [1:4] "8" "10" "14" "12"
  ..- attr(*, "fixed")= Named num 0.113
  .. ..- attr(*, "names")= chr "12"
  ..- attr(*, "formula")=Class 'formula' length 2 ~1 | age
  .. .. ..- attr(*, ".Environment")=<R_GlobalEnv> 
  ..- attr(*, "groups")= chr [1:108] "8" "10" "12" "14" ...
  ..- attr(*, "whichFix")= logi [1:3] FALSE FALSE  TRUE
  ..- attr(*, "weights")= Named num [1:108] 1.000 0.909 0.893 0.877 1.000 ...
  .. ..- attr(*, "names")= chr [1:108] "8" "10" "12" "14" ...
  ..- attr(*, "logLik")= num -9.17
> coef(vfi)
[1] 0.09531018 0.13102826
> coef(vfi, unconstrained = FALSE, allCoef = TRUE)  
   8   10   14   12 
1.00 1.10 1.14 1.12 
> vfiCopy <- vfi        # copy of an initialized object
> 
> #### Chunk 2A: Bug in coef<-.varIdent  *** corrected ***
> 
> length(vfiCopy)             # length is 2
[1] 2
> coef(vfiCopy) <- c(11,12)   # NO Execution error
> 
> #### Chunk 3A: No execution error in gls
> 
> gls.noerror  <- gls(distance ~ age, 
+                 weights  = vfi,
+                 data=Orthodont)
> 
> 
> 

--------------040502080208060001050807
Content-Type: text/plain;
 name="varIdentmethodsRevised.txt"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="varIdentmethodsRevised.txt"

# source("C:/RBookX/QTools/RcodeFix/varIdentmethodsRevised.txt")
# After testing replace varIdentX -> varIdent
# corrections in varIdent


# Note: PR#9765 fixed
# Revised varIdent Function  with PR#9765 fixed


# === List of functions: ===
# 1. varIdent PR#9765 fixed
# 2. varIdentX PR#9765 fixed
# 3. coef<-.varIdentX  with corrections
# 4. Initialize.varIdentX  same as  Initialize.varIdent  
# 5. coef.varIdentX same as coef.varIdentX 

varIdent <-
function (value = numeric(0), form = ~1, fixed = NULL) 
{
    if (is.null(getGroupsFormula(form))) {
        value <- numeric(0)
        attr(value, "fixed") <- NULL
    }
    else {
        if ((lv <- length(value)) > 0) {
            if (is.null(grpNames <- names(value)) && (lv > 1)) {
                stop("Initial values must have group names in varIdent")
            }
            value <- unlist(value)
            if (any(value <= 0)) {
                stop("Initial values for \"varIdent\" must be > 0.")
            }
            value <- log(value)
        }
        else grpNames <- NULL
        attr(value, "groupNames") <- grpNames
        if (!is.null(fixed)) {       # !!! This line changed
            fix <- attr(value, "fixed") <- log(unlist(fixed))
            if (is.null(fixNames <- names(fix))) {
                stop("Fixed parameters must have names in varIdent")
            }
            if (!is.null(attr(value, "groupNames"))) {
                attr(value, "groupNames") <- c(attr(value, "groupNames"), 
                  fixNames)
            }
        }
    }
    attr(value, "formula") <- asOneSidedFormula(form)
    class(value) <- c("varIdent", "varFunc")
    value
}
# End of revised varIdent function


varIdentX <- function (value = numeric(0), form = ~1, fixed = NULL) 
{
    if (is.null(getGroupsFormula(form))) {
        value <- numeric(0)
        attr(value, "fixed") <- NULL
    }
    else {
        if ((lv <- length(value)) > 0) {
            if (is.null(grpNames <- names(value)) && (lv > 1)) {
                stop("Initial values must have group names in varIdent")
            }
            value <- unlist(value)
            if (any(value <= 0)) {
                stop("Initial values for \"varIdent\" must be > 0.")
            }
            value <- log(value)
        }
        else grpNames <- NULL
        attr(value, "groupNames") <- grpNames
        if (!is.null(fixed)) {       # !!! This line changed
            fix <- attr(value, "fixed") <- log(unlist(fixed))
            if (is.null(fixNames <- names(fix))) {
                stop("Fixed parameters must have names in varIdent")
            }
            if (!is.null(attr(value, "groupNames"))) {
                attr(value, "groupNames") <- c(attr(value, "groupNames"), 
                  fixNames)
            }
        }
    }
    attr(value, "formula") <- asOneSidedFormula(form)
    class(value) <- c("varIdentX", "varFunc")
    value
}


"coef<-.varIdentX" <- function (object, ..., value) 
{
    if (!(is.null(grps <- getGroups(object)) || all(attr(object, 
        "whichFix")))) {
        value <- as.numeric(value)
        nGroups <- length(attr(object, "groupNames"))
        nFixed  <- sum(as.numeric(attr(object,"whichFix")))  # inserted line
        if (length(value) != nGroups - nFixed - 1) {# subtracted nFixed
            stop(paste("Cannot change the length of the varIdent", 
                "parameter after initialization"))
        }
        object[] <- value
        natPar <- coef(object, FALSE, allCoef = TRUE)
        attr(object, "logLik") <- sum(log(attr(object, "weights") <- 1/natPar[grps]))
    }
    object
}




### the same as varIdent

Initialize.varIdentX <- function (object, data, ...) 
{
    if (!is.null(form <- formula(object)) && !is.null(grpForm <- getGroupsFormula(form))) {
        if (length(coef(object)) > 0) {
            return(object)
        }
        strat <- attr(object, "groups") <- as.character(getGroups(data, 
            form, level = length(splitFormula(grpForm, sep = "*")), 
            sep = "*"))
        if (length((uStrat <- unique(strat))) == 1) {
            return(Initialize(varIdent(), data))
        }
        if (!is.null(fix <- attr(object, "fixed"))) {
            fixNames <- names(fix)
            if (any(is.na(match(fixNames, uStrat)))) {
                stop(paste("Fixed parameters names in varIdent", 
                  "must be a subset of groups names"))
            }
            uStratVar <- uStrat[is.na(match(uStrat, fixNames))]
            uStrat <- c(uStratVar, fixNames)
        }
        else {
            uStratVar <- uStrat
        }
        if ((nStratVar <- length(uStratVar)) == 0) {
            stop("Cannot fix variances in all groups")
        }
        if (nStratVar > 1) {
            if (length(object) <= 1) {
                oldAttr <- attributes(object)
                if (length(object) > 0) {
                  object <- rep(as.vector(object), nStratVar - 
                    1)
                }
                else {
                  object <- rep(0, nStratVar - 1)
                }
                attributes(object) <- oldAttr
                attr(object, "groupNames") <- uStrat
            }
            else {
                if (length(as.vector(object)) != (len <- (nStratVar - 
                  1))) {
                  stop(paste("Initial value for \"varIdent\" should be of length", 
                    len))
                }
                if (!is.null(stN <- attr(object, "groupNames"))) {
                  missStrat <- uStrat[is.na(match(uStrat, stN))]
                  if (length(missStrat) != 1) {
                    stop(paste("Names of starting value for \"varIdent\" object", 
                      "must contain all but one of the stratum levels"))
                  }
                  stN <- c(missStrat, stN)
                  if ((length(stN) != length(uStrat)) || any(sort(stN) != 
                    sort(uStrat))) {
                    stop("Nonexistent groups names for initial values in varIdent")
                  }
                  attr(object, "groupNames") <- stN
                }
                else {
                  attr(object, "groupNames") <- uStrat
                }
            }
        }
        else {
            oldAttr <- attributes(object)
            object <- numeric(0)
            attributes(object) <- oldAttr
            attr(object, "groupNames") <- uStrat
        }
        attr(object, "whichFix") <- !is.na(match(attr(object, 
            "groupNames")[-1], names(fix)))
        if (all(attr(object, "whichFix"))) {
            if (all(attr(object, "fixed") == 0)) {
                return(Initialize(varIdent(), data))
            }
            else {
                oldAttr <- attributes(object)
                object <- numeric(0)
                attributes(object) <- oldAttr
            }
        }
        attr(object, "logLik") <- sum(log(attr(object, "weights") <- 1/coef(object, 
            FALSE, allCoef = TRUE)[strat]))
        object
    }
    else {
        attr(object, "whichFix") <- TRUE
        NextMethod()
    }
}




coef.varIdentX <- function (object, unconstrained = TRUE, allCoef = FALSE, ...) 
{
    if (!is.null(getGroupsFormula(object)) && !is.null(wPar <- attr(object, 
        "whichFix"))) {
        if (unconstrained && !allCoef) {
            return(as.vector(object))
        }
        val <- double(length(wPar))
        if (any(wPar)) {
            val[wPar] <- attr(object, "fixed")
        }
        if (any(!wPar)) {
            val[!wPar] <- as.vector(object)
        }
        if (!unconstrained) {
            val <- c(1, exp(val))
            names(val) <- attr(object, "groupNames")
            if (!allCoef) {
                val <- val[c(FALSE, !attr(object, "whichFix"))]
            }
        }
        val
    }
    else {
        numeric(0)
    }
}

--------------040502080208060001050807--


From peterwickham at mac.com  Thu Aug  9 21:14:38 2007
From: peterwickham at mac.com (peterwickham at mac.com)
Date: Thu,  9 Aug 2007 21:14:38 +0200 (CEST)
Subject: [Rd] errors in loading packages (PR#9839)
Message-ID: <20070809191438.74F8A66857@slim.kubism.ku.dk>

Full_Name: Peter Wickham
Version: 2.4.1
OS: Mac 10.4.10
Submission from: (NULL) (209.59.87.136)


Attempted to load "gdata" and "gregmisc" packages after using installing via
Package Installer in R. Both load attempts resulted in the following message:
"Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :  there is no package
called 'gtools'". There is no mention of failure in the Mac OSX check summary
for packages. Another package "waveslim" installed and loaded properly (apart
from the R topic "AR1").
I might also mention that I am still using R 2.4.1 tather than R 2.5.1 as I
received warning messages in red
 R[244] and R[451] "tossing reply message sequence 1 on" when downloading the
latest version of R.


From kjbeath at kagi.com  Fri Aug 10 07:02:37 2007
From: kjbeath at kagi.com (Ken Beath)
Date: Fri, 10 Aug 2007 15:02:37 +1000
Subject: [Rd] errors in loading packages (PR#9839)
In-Reply-To: <20070809191438.74F8A66857@slim.kubism.ku.dk>
References: <20070809191438.74F8A66857@slim.kubism.ku.dk>
Message-ID: <1F5197BC-C97F-401D-B98F-5F5CF869D27E@kagi.com>

On 10/08/2007, at 5:14 AM, peterwickham at mac.com wrote:

> Full_Name: Peter Wickham
> Version: 2.4.1
> OS: Mac 10.4.10
> Submission from: (NULL) (209.59.87.136)
>
>
> Attempted to load "gdata" and "gregmisc" packages after using  
> installing via
> Package Installer in R. Both load attempts resulted in the  
> following message:
> "Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :  there  
> is no package
> called 'gtools'". There is no mention of failure in the Mac OSX  
> check summary
> for packages. Another package "waveslim" installed and loaded  
> properly (apart
> from the R topic "AR1").

Either use the installer to download gtools etc or check the Install  
Dependencies box and they will all be automatically downloaded.

> I might also mention that I am still using R 2.4.1 tather than R  
> 2.5.1 as I
> received warning messages in red
>  R[244] and R[451] "tossing reply message sequence 1 on" when  
> downloading the
> latest version of R.
>
>

This isn't a problem, it still works, there might be a development  
version where it is fixed. For Mac related problems there is a  
special list at https://stat.ethz.ch/mailman/listinfo/r-sig-mac Check  
the archives for discussion of this problem.

Ken


From gregory.warnes at mac.com  Fri Aug 10 17:25:16 2007
From: gregory.warnes at mac.com (Gregory Warnes)
Date: Fri, 10 Aug 2007 11:25:16 -0400
Subject: [Rd] errors in loading packages (PR#9839)
In-Reply-To: <1F5197BC-C97F-401D-B98F-5F5CF869D27E@kagi.com>
References: <20070809191438.74F8A66857@slim.kubism.ku.dk>
	<1F5197BC-C97F-401D-B98F-5F5CF869D27E@kagi.com>
Message-ID: <CD36F979-449F-4AEE-9FAC-EDEB4A1E98B2@mac.com>


Another way of answering the question:  The gmodels and gregmisc  
package both depend on the gtools package.  Either install that  
first, or tell R to install all dependencies.  From the command line:

	install.packages(..., depends=TRUE)

or the equivalent checkbox in the UI.

-G

On Aug 10, 2007, at 1:02AM , Ken Beath wrote:

> On 10/08/2007, at 5:14 AM, peterwickham at mac.com wrote:
>
>> Full_Name: Peter Wickham
>> Version: 2.4.1
>> OS: Mac 10.4.10
>> Submission from: (NULL) (209.59.87.136)
>>
>>
>> Attempted to load "gdata" and "gregmisc" packages after using
>> installing via
>> Package Installer in R. Both load attempts resulted in the
>> following message:
>> "Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :  there
>> is no package
>> called 'gtools'". There is no mention of failure in the Mac OSX
>> check summary
>> for packages. Another package "waveslim" installed and loaded
>> properly (apart
>> from the R topic "AR1").
>
> Either use the installer to download gtools etc or check the Install
> Dependencies box and they will all be automatically downloaded.
>
>> I might also mention that I am still using R 2.4.1 tather than R
>> 2.5.1 as I
>> received warning messages in red
>>  R[244] and R[451] "tossing reply message sequence 1 on" when
>> downloading the
>> latest version of R.
>>
>>
>
> This isn't a problem, it still works, there might be a development
> version where it is fixed. For Mac related problems there is a
> special list at https://stat.ethz.ch/mailman/listinfo/r-sig-mac Check
> the archives for discussion of this problem.
>
> Ken
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jonathan.zhou at utoronto.ca  Fri Aug 10 18:52:27 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Fri, 10 Aug 2007 09:52:27 -0700 (PDT)
Subject: [Rd] Manipulating R objects in C++
In-Reply-To: <12095059.post@talk.nabble.com>
References: <12095059.post@talk.nabble.com>
Message-ID: <12095136.post@talk.nabble.com>


Nevermind about the boolean object, after thinking about it for 2 seconds, I
figured it out.  Just going to translate the boolean to an integer object
with 1 representing true and 0=false and send that to C :P.  
-- 
View this message in context: http://www.nabble.com/Manipulating-R-objects-in-C%2B%2B-tf4249882.html#a12095136
Sent from the R devel mailing list archive at Nabble.com.


From jonathan.zhou at utoronto.ca  Fri Aug 10 19:35:52 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Fri, 10 Aug 2007 10:35:52 -0700 (PDT)
Subject: [Rd] Convert multiple C strings into an R character vector
Message-ID: <12095059.post@talk.nabble.com>


I was hoping someone could tell me how to convert multiple C character
strings into an R character vector.  

Thanks, 
Jon
-- 
View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12095059
Sent from the R devel mailing list archive at Nabble.com.


From sfalcon at fhcrc.org  Fri Aug 10 19:58:31 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 10 Aug 2007 10:58:31 -0700
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <12095059.post@talk.nabble.com> (Jonathan Zhou's message of "Fri\,
	10 Aug 2007 10\:35\:52 -0700 \(PDT\)")
References: <12095059.post@talk.nabble.com>
Message-ID: <m2fy2rclvc.fsf@fhcrc.org>

Jonathan Zhou <jonathan.zhou at utoronto.ca> writes:

> I was hoping someone could tell me how to convert multiple C character
> strings into an R character vector.  

Here's a quick untested sketch:


    char **yourStrings;
    int numStrings = /* the length of yourStrings */;
    int i;
    SEXP cvect;
    
    PROTECT(cvect = allocVector(STRSXP, numStrings));
    for (i = 0; i < numStrings; i++) {
        SET_STRING_ELT(cvect, i, mkChar(yourStrings[i]));
    }
    UNPROTECT(cvect);
    return cvect;


+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From jonathan.zhou at utoronto.ca  Fri Aug 10 22:46:52 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Fri, 10 Aug 2007 13:46:52 -0700 (PDT)
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <m2fy2rclvc.fsf@fhcrc.org>
References: <12095059.post@talk.nabble.com> <m2fy2rclvc.fsf@fhcrc.org>
Message-ID: <12098792.post@talk.nabble.com>


Thanks Seth I got the code to work.  I've actually got a followup question.   

The strings were created from reading a file where an R object was placed in
using "dput", meaning the strings hold R objects in character string format. 
My original intention for doing this was so that the character vector that
is passed back to the R code could be parsed back into the original R
object.  Is this possible without bypassing through a temporary file? I'm
not aware of a function or set of functions to do so.

I know the above seems a little twisted in object conversion but I needed to
do this as the original R object was created on a remote host and I'm trying
to transfer the object from the remote host to the local host.  

Best Regards, 
Jon
-- 
View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12098792
Sent from the R devel mailing list archive at Nabble.com.


From btyner at gmail.com  Fri Aug 10 22:47:19 2007
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 10 Aug 2007 16:47:19 -0400
Subject: [Rd] suggestion with ambiguous object component replacement
Message-ID: <5f88b2c50708101347p3ae6d7ebt67d43ffaf41e4b8@mail.gmail.com>

?"[<-" says

"When replacing (that is using indexing on the lhs of an assignment)
NA does not select any element to be replaced. As there is ambiguity
as to whether an element of the rhs should be used or not, this is
only allowed if the rhs value is of length one (so the two
interpretations would have the same outcome)."

This is quite reasonable to me; for example,

letters[NA] <- "z"

does not throw an error but

letters[NA] <- c("z","z")

does. However I wonder why assignments like

letters[c(2,2)] <- c("b1","b2")

are allowed, since at least to me it is not clear at all that "b2" is
the intended replacement. I would think that at the very least this
should throw a warning. I apologize if this has already been
discussed.

Thanks
Ben


From ligges at statistik.uni-dortmund.de  Fri Aug 10 22:47:57 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 10 Aug 2007 22:47:57 +0200
Subject: [Rd] errors in loading packages (PR#9839)
In-Reply-To: <CD36F979-449F-4AEE-9FAC-EDEB4A1E98B2@mac.com>
References: <20070809191438.74F8A66857@slim.kubism.ku.dk>	<1F5197BC-C97F-401D-B98F-5F5CF869D27E@kagi.com>
	<CD36F979-449F-4AEE-9FAC-EDEB4A1E98B2@mac.com>
Message-ID: <46BCCEFD.4050302@statistik.uni-dortmund.de>



Gregory Warnes wrote:
> Another way of answering the question:  The gmodels and gregmisc  
> package both depend on the gtools package.  Either install that  
> first, or tell R to install all dependencies.  From the command line:
> 
> 	install.packages(..., depends=TRUE)

... and dependencies are installed automatically in recent version of R, 
so one reason more for a quick update!

Uwe Ligges


> or the equivalent checkbox in the UI.
> 
> -G
> 
> On Aug 10, 2007, at 1:02AM , Ken Beath wrote:
> 
>> On 10/08/2007, at 5:14 AM, peterwickham at mac.com wrote:
>>
>>> Full_Name: Peter Wickham
>>> Version: 2.4.1
>>> OS: Mac 10.4.10
>>> Submission from: (NULL) (209.59.87.136)
>>>
>>>
>>> Attempted to load "gdata" and "gregmisc" packages after using
>>> installing via
>>> Package Installer in R. Both load attempts resulted in the
>>> following message:
>>> "Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :  there
>>> is no package
>>> called 'gtools'". There is no mention of failure in the Mac OSX
>>> check summary
>>> for packages. Another package "waveslim" installed and loaded
>>> properly (apart
>>> from the R topic "AR1").
>> Either use the installer to download gtools etc or check the Install
>> Dependencies box and they will all be automatically downloaded.
>>
>>> I might also mention that I am still using R 2.4.1 tather than R
>>> 2.5.1 as I
>>> received warning messages in red
>>>  R[244] and R[451] "tossing reply message sequence 1 on" when
>>> downloading the
>>> latest version of R.
>>>
>>>
>> This isn't a problem, it still works, there might be a development
>> version where it is fixed. For Mac related problems there is a
>> special list at https://stat.ethz.ch/mailman/listinfo/r-sig-mac Check
>> the archives for discussion of this problem.
>>
>> Ken
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jonathan.zhou at utoronto.ca  Fri Aug 10 22:49:36 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Fri, 10 Aug 2007 13:49:36 -0700 (PDT)
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <m2fy2rclvc.fsf@fhcrc.org>
References: <12095059.post@talk.nabble.com> <m2fy2rclvc.fsf@fhcrc.org>
Message-ID: <12098792.post@talk.nabble.com>


Thanks Seth I got the code to work.  I've actually got a followup question.   

The strings were created from reading a file where an R object was placed in
using "dput", meaning the strings hold R objects in character string format. 
My original intention for doing this was so that the character vector that
is passed back to the R code could be parsed back into the original R
object.  Is this possible?  Currently I'm doing this through writing the
character string to a temporary file with "write" and then reading it back
into an object using "dget", but I was hoping there was another method as
efficiency is key and I will be needing to do this many many times.  

I know the above seems a little twisted in object conversion but I needed to
do this as the original R object was created on a remote host and I'm trying
to transfer the object from the remote host to the local host.  I'm hoping
to not need to do this through bypassing a temporary

Best Regards, 
Jon
-- 
View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12098792
Sent from the R devel mailing list archive at Nabble.com.


From byron.ellis at gmail.com  Fri Aug 10 23:02:23 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Fri, 10 Aug 2007 14:02:23 -0700
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <12098792.post@talk.nabble.com>
References: <12095059.post@talk.nabble.com> <m2fy2rclvc.fsf@fhcrc.org>
	<12098792.post@talk.nabble.com>
Message-ID: <7098abec0708101402x1d41d765l1d227482df1a5bd9@mail.gmail.com>

R_Serialize and R_Unserialize let you marshal objects across the wire.
The actual protocol implementation is up to you, but everything you
need is there without having to resort to a temporary file or, at the
very least, reparsing a set of strings.

On 8/10/07, Jonathan Zhou <jonathan.zhou at utoronto.ca> wrote:
>
> Thanks Seth I got the code to work.  I've actually got a followup question.
>
> The strings were created from reading a file where an R object was placed in
> using "dput", meaning the strings hold R objects in character string format.
> My original intention for doing this was so that the character vector that
> is passed back to the R code could be parsed back into the original R
> object.  Is this possible without bypassing through a temporary file? I'm
> not aware of a function or set of functions to do so.
>
> I know the above seems a little twisted in object conversion but I needed to
> do this as the original R object was created on a remote host and I'm trying
> to transfer the object from the remote host to the local host.
>
> Best Regards,
> Jon
> --
> View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12098792
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From jonathan.zhou at utoronto.ca  Fri Aug 10 23:33:54 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Fri, 10 Aug 2007 14:33:54 -0700 (PDT)
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <7098abec0708101402x1d41d765l1d227482df1a5bd9@mail.gmail.com>
References: <12095059.post@talk.nabble.com> <m2fy2rclvc.fsf@fhcrc.org>
	<12098792.post@talk.nabble.com>
	<7098abec0708101402x1d41d765l1d227482df1a5bd9@mail.gmail.com>
Message-ID: <12099265.post@talk.nabble.com>


Hey,

I'm actually passing the R objects between hosts through a middleware
software called Symphony.  I'm not sure if R_Serialize/Unserialize will be
of use to me.  On that note, after searching through the R manuals and using
"RSiteSearch", I wasn't able to find any documentation regarding
R_Serialize, where can I find information about this function?

-Jon
-- 
View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12099265
Sent from the R devel mailing list archive at Nabble.com.


From byron.ellis at gmail.com  Sat Aug 11 00:03:17 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Fri, 10 Aug 2007 15:03:17 -0700
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <12099265.post@talk.nabble.com>
References: <12095059.post@talk.nabble.com> <m2fy2rclvc.fsf@fhcrc.org>
	<12098792.post@talk.nabble.com>
	<7098abec0708101402x1d41d765l1d227482df1a5bd9@mail.gmail.com>
	<12099265.post@talk.nabble.com>
Message-ID: <7098abec0708101503w1dd24ddj83974cf461b0de8@mail.gmail.com>

No idea, but if you can get a BLOB through it then you should be fine.
http://www.stat.uiowa.edu/~luke/R/serialize/serialize.html is your
best bet for documentation. I'm not sure what its "Official API"
status might be (nor do I care).

On 8/10/07, Jonathan Zhou <jonathan.zhou at utoronto.ca> wrote:
>
> Hey,
>
> I'm actually passing the R objects between hosts through a middleware
> software called Symphony.  I'm not sure if R_Serialize/Unserialize will be
> of use to me.  On that note, after searching through the R manuals and using
> "RSiteSearch", I wasn't able to find any documentation regarding
> R_Serialize, where can I find information about this function?
>
> -Jon
> --
> View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12099265
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From zivan.karaman at gmail.com  Fri Aug 10 18:09:17 2007
From: zivan.karaman at gmail.com (zivan.karaman at gmail.com)
Date: Fri, 10 Aug 2007 18:09:17 +0200 (CEST)
Subject: [Rd] available.packages (PR#9841)
Message-ID: <20070810160917.4FB8666804@slim.kubism.ku.dk>

Full_Name: Zivan Karaman
Version: 2.5.1
OS: Windows XP SP2
Submission from: (NULL) (195.6.68.214)


I think that I have encountered a bug in the function "available.packages" when
using a local repository (file://
) on Windows.

Version information:
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.1                         
year           2007                        
month          06                          
day            27                          
svn rev        42083                       
language       R                           
version.string R version 2.5.1 (2007-06-27)

I have made a copy of the CRAN "/bin/windows/contrib/2.5" directory in the
"D:/CRAN" folder on my machine.

When I issue the command:

available.packages(contrib.url("file://D:/CRAN"))

I get the follwoing message:
Error in gzfile(file, "r") : unable to open connection
In addition: Warning message:
cannot open compressed file ':/CRAN/bin/windows/contrib/2.5/PACKAGES' in:
gzfile(file, "r")

Looking at the source code, I've spotted the following lines which seem to cause
trouble:

            if (.Platform$OS.type == "windows") {
                if (length(grep("[A-Za-z]:", tmpf))) 
                  tmpf <- substring(tmpf, 2)
            }
Deleting them, the function works OK.


From hin-tak.leung at cimr.cam.ac.uk  Sat Aug 11 04:38:43 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Sat, 11 Aug 2007 03:38:43 +0100
Subject: [Rd] Convert multiple C strings into an R character vector
In-Reply-To: <7098abec0708101503w1dd24ddj83974cf461b0de8@mail.gmail.com>
References: <12095059.post@talk.nabble.com>
	<m2fy2rclvc.fsf@fhcrc.org>	<12098792.post@talk.nabble.com>	<7098abec0708101402x1d41d765l1d227482df1a5bd9@mail.gmail.com>	<12099265.post@talk.nabble.com>
	<7098abec0708101503w1dd24ddj83974cf461b0de8@mail.gmail.com>
Message-ID: <46BD2133.2060601@cimr.cam.ac.uk>

R_serialize is the C API counter-part of the serialize() in R.
Reading ?serialize in R would probably do . It would also
help if one understands connections (?connection) - the C API equivalent
is R_connection or R_conn - 'May the source be with you', to
paraphrase Yoda. (the serialization code is in a file called 
serial<something>.c in the source bundle, as I recall).

Byron Ellis wrote:
> No idea, but if you can get a BLOB through it then you should be fine.
> http://www.stat.uiowa.edu/~luke/R/serialize/serialize.html is your
> best bet for documentation. I'm not sure what its "Official API"
> status might be (nor do I care).
> 
> On 8/10/07, Jonathan Zhou <jonathan.zhou at utoronto.ca> wrote:
>> Hey,
>>
>> I'm actually passing the R objects between hosts through a middleware
>> software called Symphony.  I'm not sure if R_Serialize/Unserialize will be
>> of use to me.  On that note, after searching through the R manuals and using
>> "RSiteSearch", I wasn't able to find any documentation regarding
>> R_Serialize, where can I find information about this function?
>>
>> -Jon
>> --
>> View this message in context: http://www.nabble.com/Convert-multiple-C-strings-into-an-R-character-vector-tf4249882.html#a12099265
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From hb at stat.berkeley.edu  Mon Aug 13 19:45:38 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 13 Aug 2007 10:45:38 -0700
Subject: [Rd] hasNA() / anyNA()?
Message-ID: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>

Hi,

is there a hasNA() / an anyNA() function in R?  Of course,

hasNA <- function(x) {
  any(is.na(x));
}

would do, but that would scan all elements in 'x' and then do the
test.  I'm looking for a more efficient implementation that returns
TRUE at the first NA, e.g.

hasNA <- function(x) {
  for (kk in seq(along=x)) {
    if (is.na(x[kk]))
      return(TRUE);
  }
  FALSE;
}

Cheers

Henrik


From michael at cassin.name  Mon Aug 13 20:18:24 2007
From: michael at cassin.name (Michael Cassin)
Date: Mon, 13 Aug 2007 19:18:24 +0100
Subject: [Rd] hasNA() / anyNA()?
In-Reply-To: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>
References: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>
Message-ID: <b02e8b330708131118g2efc7431k1318c43a87e1f467@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070813/39a7081a/attachment.pl 

From russell-lenth at uiowa.edu  Mon Aug 13 20:27:31 2007
From: russell-lenth at uiowa.edu (russell-lenth at uiowa.edu)
Date: Mon, 13 Aug 2007 20:27:31 +0200 (CEST)
Subject: [Rd] Non-administrator can't install packages (PR#9848)
Message-ID: <20070813182731.2AF4A66826@slim.kubism.ku.dk>

Full_Name: Russ Lenth
Version: 1.5.1
OS: Windows XP Pro
Submission from: (NULL) (128.255.132.36)


I run a Windows system on which I do not have administrator rights.  I am unable
to install R packages, even in a location that I have access to.  I get a
message that it can't write to the specified directory.  I know I WAS able to do
this last April (version 1.4.1??) on the same system -- I have several installed
packages to show for it.  

Some R session excerpts are below.  I have tried the same things on my laptop,
with no problems; thus, I think this bug is related to my not having
Administrator rights.  

By the way, in each call to install.packages(), I get an offer to create a new
library directory, even though I have specified one explicitly in the "lib"
argument.  That seems like a bug too.

My current workaround is to just download and unzip the file to that directory,
with R not running.  That seems to work, but I'm not sure everything gets set up
properly that way.


===== Attempt to install a package to my usual location on a network drive:
R> .libPaths()
[1] "h:/pkg/R/library"               "C:/PROGRA~1/R/R-25~1.1/library"

R> install.packages( "odfWeave", lib="h:/pkg/R/library")
Warning in install.packages("d:/downloads/odfWeave_0.5.9.zip", lib =
"h:/pkg/R/library") : 
         'lib = "h:/pkg/R/library"' is not writable
Error in install.packages("d:/downloads/odfWeave_0.5.9.zip", lib =
"h:/pkg/R/library") : 
        unable to install packages


===== Attempt to install to a local drive:
R> install.packages( "odfWeave", lib="d:")
Warning in install.packages("d:/downloads/odfWeave_0.5.9.zip", lib = "d:") : 
         'lib = "d:"' is not writable
Error in install.packages("d:/downloads/odfWeave_0.5.9.zip", lib = "d:") : 
        unable to install packages


===== Yet, I can write to that location:
R> sink("h:/pkg/R/library/junk.txt")
R> ls()
R> sink()
R> system("cat h:/pkg/R/library/junk.txt")
  [1] "align"              "align.default"      "align.lm"          
  [4] "align.old"          "align.very.old"     "augment"           
.....           
R> system("rm h:/pkg/R/library/junk.txt")
R>


From zemlys at gmail.com  Mon Aug 13 10:04:20 2007
From: zemlys at gmail.com (zemlys at gmail.com)
Date: Mon, 13 Aug 2007 10:04:20 +0200 (CEST)
Subject: [Rd] Mistake in ISOLatin7.enc file (PR#9845)
Message-ID: <20070813080420.5CE596686A@slim.kubism.ku.dk>

Full_Name: Vaidotas Zemlys
Version: 2.5.1
OS: Ubuntu 7.04
Submission from: (NULL) (213.197.173.50)


Hi,

There is a mistake in ISOLatin7.enc file which is shipped with grDevices
package. Instead of Umacron and umacron there are Ucirmcumflex and ucirmcumflex.


There is no U cirmcumflex in ISO Latin 7 encoding, as can be seen in 
http://en.wikipedia.org/wiki/ISO/IEC_8859-13

and I also can report this as native Lithuanian speaker, since ISO Latin 7
encoding is used for Lithuanian and Latvian languages.

Steps to reproduce

1. In R issue commands :

postscript(file="test.ps",encoding="ISOLatin7")
plot(rnorm(100),main="&#362;&#363;")
dev.off()

When viewing postcript file instead of &#362;&#363; you will see ??.

Changing [uU]circumflex to [uU]macron in file ISOLatin7.enc fixes the problem.


From m.pacey at lancaster.ac.uk  Mon Aug 13 16:28:31 2007
From: m.pacey at lancaster.ac.uk (m.pacey at lancaster.ac.uk)
Date: Mon, 13 Aug 2007 16:28:31 +0200 (CEST)
Subject: [Rd] Change in grep functionality causes Rd_db to fail silently
	(PR#9846)
Message-ID: <20070813142831.B5E4966826@slim.kubism.ku.dk>

Full_Name: Mike Pacey
Version: 2.5.1
OS: SUSE SE Linux 9.3
Submission from: (NULL) (194.80.32.10)



Versions 2.5.0 and 2.5.1 currently fail "make check" on my system due to a
silent failure in the call to Rd_db("base"):

-----
> ### Name: Rdutils
> ### Title: Rd Utilities
> ### Aliases: Rd_db Rd_parse
> ### Keywords: utilities documentation
> 
> ### ** Examples
> 
> ## Build the Rd db for the (installed) base package.
> db <- Rd_db("base")
> ## Run Rd_parse on all entries in the Rd db.
> db <- lapply(db, function(txt) Rd_parse(text = txt))
> ## Extract the metadata.
> meta <- lapply(db, "[[", "meta")
> 
> ## Keyword metadata per Rd file.
> keywords <- lapply(meta, "[[", "keywords")
> ## Tabulate the keyword entries.
> kw_table <- sort(table(unlist(keywords)))
Error in as.vector(x, mode) : invalid argument 'mode'
Execution halted
----

Tracing through the call to Rd_db, a call is made to list_files_with_exts(). The
functionality of the relevant section of that function in 2.4.0 is replicated
here:

> dir
[1] "/usr/local/packages/R-2.4.0-acml/lib64/R/library/base/man"
> files <- list.files(dir)
> files
[1] "base.Rd.gz"
> patt
[1] "\\.(Rd|rd|Rd.gz|rd.gz)$"
> grep(patt, files, value = TRUE)
[1] "base.Rd.gz"


In 2.5.1, the behaviour of grep() seems to have changed:

> dir
[1] "/usr/local/packages/src/R-2.5.1/library/base/man"
> files <- list.files(dir)
> files
[1] "base.Rd.gz"
> patt
[1] "\\.(Rd|rd|Rd.gz|rd.gz)$"
> grep(patt, files, value = TRUE)
character(0)

The result is that the call to Rd_db fails to find the relevant documentation
for the base package.


From Kurt.Hornik at wu-wien.ac.at  Mon Aug 13 21:27:09 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon, 13 Aug 2007 21:27:09 +0200
Subject: [Rd] hasNA() / anyNA()?
In-Reply-To: <b02e8b330708131118g2efc7431k1318c43a87e1f467@mail.gmail.com>
References: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>
	<b02e8b330708131118g2efc7431k1318c43a87e1f467@mail.gmail.com>
Message-ID: <18112.45197.316066.610157@mithrandir.hornik.net>

>>>>> Michael Cassin writes:

> I don't know of one.

> Ideally, instead of a specifc function anyNA() function, any() could
> be perhaps be extended to any(x, FUN) where FUN returns a logical for
> an element of x, and implemented to find the 1st instance as you
> suggest.

Patterned after Common Lisp's position(), ideally we would have formals
(x, FUN, right = FALSE) where the last argument controls whether the
search proceeds from left to right or right to left.

This would certainly be very nice to have, and make it trivial to
provide an efficient variant of Common Lisp's find() (which finds the
first element from the left or right for which the predicate gives
true).

-k

> Mike

> On 8/13/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>> 
>> Hi,
>> 
>> is there a hasNA() / an anyNA() function in R?  Of course,
>> 
>> hasNA <- function(x) {
>> any(is.na(x));
>> }
>> 
>> would do, but that would scan all elements in 'x' and then do the
>> test.  I'm looking for a more efficient implementation that returns
>> TRUE at the first NA, e.g.
>> 
>> hasNA <- function(x) {
>> for (kk in seq(along=x)) {
>> if (is.na(x[kk]))
>> return(TRUE);
>> }
>> FALSE;
>> }
>> 
>> Cheers
>> 
>> Henrik
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Mon Aug 13 22:20:12 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 13 Aug 2007 13:20:12 -0700
Subject: [Rd] Compilation error with R-devel_2007-08-12.tar.gz snapshot
Message-ID: <46C0BCFC.6010107@fhcrc.org>

Hi,

I get a compilation error with last available R devel
snapshot (R-devel_2007-08-12.tar.gz, r42483):


==================== CONFIGURE ====================

hpages at wilson1:~/R-2.6.broken> ~/src/R-2.6.r42483/configure
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
[...]
R is now configured for x86_64-unknown-linux-gnu

  Source directory:          /home/hpages/src/R-2.6.r42483
  Installation directory:    /usr/local

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       gfortran  -g -O2

  C++ compiler:              g++  -g -O2
  Fortran 90/95 compiler:    gfortran -g -O2
  Obj-C compiler:            gcc -g -O2

  Interfaces supported:      X11, tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           shared BLAS, R profiling, Java

  Recommended packages:      yes


====================== MAKE =======================

hpages at wilson1:~/R-2.6.broken> make
[...]
make[1]: Entering directory `/home/hpages/R-2.6.broken/src/library/Recommended'
make[2]: Entering directory `/home/hpages/R-2.6.broken/src/library/Recommended'
make[2]: *** No rule to make target `VR.ts', needed by `stamp-recommended'.  Stop.
make[2]: Leaving directory `/home/hpages/R-2.6.broken/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory `/home/hpages/R-2.6.broken/src/library/Recommended'
make: *** [stamp-recommended] Error 2


I have no problems with older tarballs e.g. tarball from 2007-08-06 (r42439)
compiles fine.

Cheers,
H.


From bolker at zoo.ufl.edu  Mon Aug 13 23:49:51 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 13 Aug 2007 17:49:51 -0400
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers bug
 in stats4::mle]
Message-ID: <46C0D1FF.3020005@zoo.ufl.edu>


  I sent this in first on 30 July. Now that UseR! is over I'm trying again
(slightly extended version from last time).

 With R 2.5.1 or R 2.6.0 (2007-08-04 r42421)

 "L-BFGS-B" behaves differently from all of the
other optim() methods, which return the value of the function
when they are given a trivial function (i.e., one with no
variable arguments) to optimize.  This is not
a bug in L-BFGS-B (more like a response to
an undefined condition), but it leads to a bug in stats4::mle --
a spurious error saying that a better fit
has been found during profiling if one tries to profile
a 1-parameter model that was originally fitted with "L-BFGS-B".

  One possible fix is to check for length(start)==0 and 
return a dummy optim() result in that case (see patch included below).
The patch below fixes the basic problem, although I haven't
tested extensively to see what its other implications are.

Or one could change L-BFGS-B to behave the same as the other methods.

  If I don't hear anything in a few days would it be appropriate
to submit this as a bug report?

cheers
 Ben Bolker

---------------------
library(stats4)

## using example from ?mle
x <- 0:10
y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
ll <- function(ymax=15, xhalf=6)
-sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))

## fix one parameter to get 1D profile
fit2 <- mle(ll, fixed=list(xhalf=6))
profile(fit2)

## same again with method="L-BFGS-B"
fit3 <- mle(ll, fixed=list(xhalf=6),method="L-BFGS-B")
profile(fit3)   ## BUG

ll0 <- function(zzz) {
ymax <- 15
xhalf <- 6
-sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}

## try mle() with all-fixed parameters with various methods ...
methods = eval(formals(optim)$method)
sapply(methods,
     function(m) {
       -logLik(mle(ll, start=list(ymax=15,xhalf=6),
                   fixed=list(ymax=15,xhalf=6),method=m))
     })
##   Nelder-Mead          BFGS            CG      L-BFGS-B          SANN
##  3.389441e+01  3.389441e+01  3.389441e+01 5.048277e-270  3.389441e+01



*** mle.R       2007-07-27 11:50:38.000000000 -0400
--- src/library/stats4/R/mle.R  2007-08-13 17:47:11.000000000 -0400
***************
*** 56,62 ****
          l[n] <- fixed
          do.call("minuslogl", l)
      }
!     oout <- optim(start, f, method=method, hessian=TRUE, ...)
      coef <- oout$par
      vcov <- if(length(coef)) solve(oout$hessian) else matrix(numeric(0),0,0)
      min <-  oout$value
--- 56,66 ----
          l[n] <- fixed
          do.call("minuslogl", l)
      }
!     if (length(start)==0) {
!        oout <- list(par=numeric(0),value=f(start))
!     } else {
!       oout <- optim(start, f, method=method, hessian=TRUE, ...)
!     }
      coef <- oout$par
      vcov <- if(length(coef)) solve(oout$hessian) else matrix(numeric(0),0,0)
      min <-  oout$value


From hpages at fhcrc.org  Tue Aug 14 08:23:48 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 13 Aug 2007 23:23:48 -0700
Subject: [Rd] Compilation error with R-devel_2007-08-12.tar.gz snapshot
In-Reply-To: <46C0BCFC.6010107@fhcrc.org>
References: <46C0BCFC.6010107@fhcrc.org>
Message-ID: <46C14A74.4020909@fhcrc.org>

Problem gone with new snapshot (2007-08-13, r42496). Thanks!

H.

Herve Pages wrote:
> Hi,
> 
> I get a compilation error with last available R devel
> snapshot (R-devel_2007-08-12.tar.gz, r42483):
> 
> 
> ==================== CONFIGURE ====================
> 
> hpages at wilson1:~/R-2.6.broken> ~/src/R-2.6.r42483/configure
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> [...]
> R is now configured for x86_64-unknown-linux-gnu
> 
>   Source directory:          /home/hpages/src/R-2.6.r42483
>   Installation directory:    /usr/local
> 
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
> 
>   C++ compiler:              g++  -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:            gcc -g -O2
> 
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline
>   Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>   Options enabled:           shared BLAS, R profiling, Java
> 
>   Recommended packages:      yes
> 
> 
> ====================== MAKE =======================
> 
> hpages at wilson1:~/R-2.6.broken> make
> [...]
> make[1]: Entering directory `/home/hpages/R-2.6.broken/src/library/Recommended'
> make[2]: Entering directory `/home/hpages/R-2.6.broken/src/library/Recommended'
> make[2]: *** No rule to make target `VR.ts', needed by `stamp-recommended'.  Stop.
> make[2]: Leaving directory `/home/hpages/R-2.6.broken/src/library/Recommended'
> make[1]: *** [recommended-packages] Error 2
> make[1]: Leaving directory `/home/hpages/R-2.6.broken/src/library/Recommended'
> make: *** [stamp-recommended] Error 2
> 
> 
> I have no problems with older tarballs e.g. tarball from 2007-08-06 (r42439)
> compiles fine.
> 
> Cheers,
> H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Aug 14 08:52:28 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Aug 2007 07:52:28 +0100 (BST)
Subject: [Rd] Change of compiler for Windows build of R
Message-ID: <Pine.LNX.4.64.0708140719200.31255@gannet.stats.ox.ac.uk>

The MinGW people have finally released a couple of builds of gcc 4.2.1 
(and finally moved the build of 3.4.5 to release status after 19 months as 
'candidate').

We intend to use gcc 4.2.1 for the binary distribution of R 2.6.0, and 
builds of R-devel are being made with it from now on.  The R-admin manual 
now contains details of the pieces you need, and in due course there will 
be an updated Rtools.exe containing this version.  I've successfully built 
cross-compilers although am unlikely to distribute one for a while.

gcc 4.2.1 is a better check of standards conformance, and you may see 
warnings in packages not present with gcc 3.4.5.  All the CRAN packages 
have been checked, and this showed up some issues with packages which 
deviated markedly from the documented procedures. E.g.

- the C++ compiler is $(CXX), not g++, and $(CXX) is defined in MkRules.

- there is a quirk with dlltool both on Vista and with gcc 4.2.1 on XP
   that needs '--as' included amongst the flags.  The rule in MkRules
   works: several user-written rules do not.

So far we have seen no issues with mixing code compiled with gcc 3.4.5 and 
4.2.1.  There would almost certainly be issues with third-party C++ 
libraries, and might be some with Fortran libraries that use complex 
numbers.

The advantages of using this port include:

- Vista compatibility out of the box.

- ongoing support.  The main MinGW developer is really targetting gcc
   4.3.0, and these compilers are interim releases with patches backported
   from the gcc trunk.

- More complete C99 features: for example C99 inlining will be supported
   in gcc 4.3.0 (and has already been tested using snapshots).

- integrated F9x support.  F9x is supported 'out of the box', and can now
   consider using F9x code in R.

- OMP and threading support.


R 2.5.1 will not build out of the box with these compilers, but R-patched 
will (for suitable settings in MkRules).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From russell-lenth at uiowa.edu  Mon Aug 13 21:15:57 2007
From: russell-lenth at uiowa.edu (russell-lenth at uiowa.edu)
Date: Mon, 13 Aug 2007 21:15:57 +0200 (CEST)
Subject: [Rd] PR#9848
Message-ID: <20070813191557.69E646682C@slim.kubism.ku.dk>

Oops -- I meant R version 2.5.1, not 1.5.1.  My apologies.
-- 
Russell V. Lenth, Professor
Department of Statistics
   & Actuarial Science            (319)335-0814    FAX (319)335-3017
The University of Iowa           russell-lenth at uiowa.edu
Iowa City, IA 52242  USA         http://www.stat.uiowa.edu/~rlenth/


From tobias.verbeke at businessdecision.com  Tue Aug 14 08:15:17 2007
From: tobias.verbeke at businessdecision.com (Tobias Verbeke)
Date: Tue, 14 Aug 2007 08:15:17 +0200
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <46BA2E65.7080301@cimr.cam.ac.uk>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>
	<46B96EE6.2090606@statistik.uni-dortmund.de>
	<46BA1863.6030609@telenet.be> <46BA2E65.7080301@cimr.cam.ac.uk>
Message-ID: <46C14875.5020008@businessdecision.com>

Hin-Tak Leung wrote:

> Tobias Verbeke wrote:
> <snipped>
>> Actually, I think Hin-Tak is right about the absolute path. Even when 
>> the R code will call the executable that resides in that directory, R 
>> will call it from any directory and that (current) directory will be 
>> resolved (at least that is what I observe experimentally).
>>
>> When such an absolute path is coded in, everything runs fine -- we now 
>> can run a BUGS script from within R under GNU/Linux !
>>
>> It would however be nice to solve the remaining problem of the
>> absolute path in the dlopen() call, i.e. being able to fill in
>> `dynamically' the library path to which the package is actually 
>> installed.
>>
>> Is there a way to have the library path to which a package is 
>> installed available during package installation and then to do some 
>> text-processing to fill in this path dynamically into the C file i.e.
>> as argument of dlopen() before compiling it?
> <snipped>
> 
> I don't know if there is a neater way of doing this, but one somewhat 
> clunky way is to process the result of .libPath() , append each of its 
> elements by <package>/inst/OpenBUGS/bugs.so and test if the file exists,
> (.libPath() should be quite a small character vector so it should be too
> slow to test every one), then pass the result as an explicit
> argument to the main bugs binary before everything else it takes.
> 
> I think there is a more clever way of telling where the current package
> is installed/located but it escapes me at the moment. Perhaps the source 
> code of data() (just typying 'data' without the () at the comment prompt 
> will display the source), can shed some lights on this, since data() 
> does something quite similiar.

Thank you, Hin-Tak, for pointing me in the right direction.
Please find below the final C code I use to get OpenBUGS
running.

#include <stdlib.h>
#include <stdio.h>
#include <dlfcn.h>

int main (int argc, char *argv[])
{
   void * handle;
   void (*cli)(void);
   char * error;
   char * sopath;

   sopath = argv[1]; /* path of brugs.so */

   handle = dlopen(sopath, RTLD_LAZY);
   if (!handle) {
     fprintf (stderr, "%s\n", dlerror());
     exit(1);
   }

   * (void **) (&cli) = dlsym(handle, "CLI");
   if ((error = dlerror()) != NULL)  {
     fprintf (stderr, "%s\n", error);
     exit(1);
   }

   (*cli)();

   dlclose(handle);
   return 0;
}

At the R level, the use of system.file seemed to me to be
the most generally applicable. The relevant lines from the
calling R code are:

   ## construct system command
   exe <- if (iswin) "bugs.exe" else "linbugs"
   sofile <- "brugs.so"
   OpenBUGSpath <- system.file("OpenBUGS", package = "CGHmix")
   pathexe <- file.path(OpenBUGSpath, exe)
   pathso <- file.path(OpenBUGSpath, sofile)
   cmd <- if (iswin){
            paste(pathexe, "<", scriptfile, ">", resultsfile, sep = " ")
          } else {
            paste(pathexe,  pathso, "<", scriptfile, ">", resultsfile, 
sep = " ")
          }
   system(cmd)

The resulting package now allows for using an embedded OpenBUGS
on GNU/Linux without relying on WINE. Thanks to all for their helpful 
comments.

Kind regards,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From ripley at stats.ox.ac.uk  Tue Aug 14 11:17:00 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 14 Aug 2007 11:17:00 +0200 (CEST)
Subject: [Rd] PR#9848
Message-ID: <20070814091700.4493C6686E@slim.kubism.ku.dk>

The behaviour you quote is the documented behaviour in R 2.5.1.
Please do RTFM, especially ?install.packages:

      'install.packages' can be used to install new packages/bundles. It
      takes a vector of names and a destination library, downloads the
      packages from the repositories and installs them.  (If the library
      is omitted it defaults to the first directory in '.libPaths()',
      with a warning if there is more than one.)  If 'lib' is omitted or
      is of length one and is not a (group) writeable directory, the
      code offers to create a personal library tree (the first element
      of 'Sys.getenv("R_LIBS_USER")') and install there. Detection of a
      writeable directory is problematic on Windows: see the Warning
      section.

Now, it is entirely possible that Windows is mis-reporting on the 
permissions available, but that would not be a bug in R and one that is 
warned about (twice) on the help page.

That you can write a specific file there is not the issue, as the help 
page explains in detail.  You need to be able to write specfic types of 
files there, and a recent WinXP patch stops you being able to do that on 
networked drives.

On Mon, 13 Aug 2007, russell-lenth at uiowa.edu wrote:

> Oops -- I meant R version 2.5.1, not 1.5.1.  My apologies.

So you did mean 1.4.1?  Two separate major version errors suggest that you 
really are insufficiently unaware of what you are using.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From btyner at gmail.com  Tue Aug 14 13:48:25 2007
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 14 Aug 2007 07:48:25 -0400
Subject: [Rd] hasNA() / anyNA()?
Message-ID: <5f88b2c50708140448n659f6ab7gf3bc22205006112b@mail.gmail.com>

Why not

hasNA <- function(x) !is.na(match(NA, x))

-Ben


From marc_schwartz at comcast.net  Tue Aug 14 15:03:51 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 14 Aug 2007 08:03:51 -0500
Subject: [Rd] hasNA() / anyNA()?
In-Reply-To: <5f88b2c50708140448n659f6ab7gf3bc22205006112b@mail.gmail.com>
References: <5f88b2c50708140448n659f6ab7gf3bc22205006112b@mail.gmail.com>
Message-ID: <1187096631.3470.11.camel@Bellerophon.localdomain>

On Tue, 2007-08-14 at 07:48 -0400, Benjamin Tyner wrote:
> Why not
> 
> hasNA <- function(x) !is.na(match(NA, x))
> 
> -Ben

It does not save anything:

Vec1 <- c(NA, rep(1, 10000000))

Vec2 <- c(rep(1, 10000000), NA)


> system.time(!is.na(match(NA, Vec1)))
   user  system elapsed 
  1.053   0.217   1.404 

> system.time(!is.na(match(NA, Vec2)))
   user  system elapsed 
  1.049   0.242   1.360 

Note, there is no difference in execution time between the two. Review
the source code for match() in unique.c and you will see why.


Now try:

> system.time(any(is.na(Vec1)))
   user  system elapsed 
  0.242   0.079   0.358 

> system.time(any(is.na(Vec2)))
   user  system elapsed 
  0.255   0.067   0.321 


Still essentially no time difference, but notably faster than using
match(). To get much faster, you would likely need to code a new
function in C, patterned after Kurt's reply.

HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Tue Aug 14 15:21:13 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Aug 2007 14:21:13 +0100 (BST)
Subject: [Rd] hasNA() / anyNA()?
In-Reply-To: <5f88b2c50708140448n659f6ab7gf3bc22205006112b@mail.gmail.com>
References: <5f88b2c50708140448n659f6ab7gf3bc22205006112b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708141416060.31152@gannet.stats.ox.ac.uk>

On Tue, 14 Aug 2007, Benjamin Tyner wrote:

> Why not
>
> hasNA <- function(x) !is.na(match(NA, x))

It hashes the whole table (here x) and so is both slower and uses more 
memory than is.na(x).

I am not clear what is meant by 'efficiency' here, or why it is needed (we 
have not been told).  But writing a C-level function to do this would have 
taken less time that this discussion has already taken ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From timh at insightful.com  Tue Aug 14 18:08:41 2007
From: timh at insightful.com (Tim Hesterberg)
Date: Tue, 14 Aug 2007 09:08:41 -0700
Subject: [Rd] hasNA() / anyNA()?
In-Reply-To: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>
	(hb@stat.berkeley.edu)
References: <59d7961d0708131045x7feeeab5i4edf107350fbefdb@mail.gmail.com>
Message-ID: <uy7gejdyu.fsf@insightful.com>

S-PLUS has an anyMissing() function, for which the default is:

anyMissing.default <-
function(x){
	(length(which.na(x)) > 0)
}

This is more efficient than any(is.na(x)) in the usual case that there
are few or no missing values.  There are methods for vectors that drop
to C code, and methods for data frames and other classes.

The code below seems to presume a list, and would be very slow for vectors.

For reasons of consistency between S-PLUS and R, I would ask that an R
function be called anyMissing rather than hasNA or anyNA.

Tim Hesterberg

>is there a hasNA() / an anyNA() function in R?  Of course,
>
>hasNA <- function(x) {
>  any(is.na(x));
>}
>
>would do, but that would scan all elements in 'x' and then do the
>test.  I'm looking for a more efficient implementation that returns
>TRUE at the first NA, e.g.
>
>hasNA <- function(x) {
>  for (kk in seq(along=x)) {
>    if (is.na(x[kk]))
>      return(TRUE);
>  }
>  FALSE;
>}
>
>Cheers
>
>Henrik


From savicky at cs.cas.cz  Tue Aug 14 20:26:35 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 14 Aug 2007 20:26:35 +0200
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers
	bug in stats4::mle]
In-Reply-To: <46C0D1FF.3020005@zoo.ufl.edu>
References: <46C0D1FF.3020005@zoo.ufl.edu>
Message-ID: <20070814182635.GB29808@cs.cas.cz>

On Mon, Aug 13, 2007 at 05:49:51PM -0400, Ben Bolker wrote:
[snip]
> an undefined condition), but it leads to a bug in stats4::mle --
> a spurious error saying that a better fit
> has been found during profiling if one tries to profile
> a 1-parameter model that was originally fitted with "L-BFGS-B".
[snip]

Could you also include a script, which reproduces the problem? Just
to see under which conditions the problem occurs and how it
looks like exactly.

Petr Savicky.


From bolker at ufl.edu  Tue Aug 14 20:36:54 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 14 Aug 2007 18:36:54 +0000 (UTC)
Subject: [Rd]
	=?utf-8?q?=5BFwd=3A_behavior_of_L-BFGS-B_with_trivial_functi?=
	=?utf-8?q?on_triggers=09bug_in_stats4=3A=3Amle=5D?=
References: <46C0D1FF.3020005@zoo.ufl.edu> <20070814182635.GB29808@cs.cas.cz>
Message-ID: <loom.20070814T203613-433@post.gmane.org>

Petr Savicky <savicky <at> cs.cas.cz> writes:


> Could you also include a script, which reproduces the problem? Just
> to see under which conditions the problem occurs and how it
> looks like exactly.
> 
> Petr Savicky.
> 

  The original post has such a script, just under the dashed line
and above the diff/patch.  Sorry if I wasn't clear about that.

  cheers
    Ben Bolker


From bolker at ufl.edu  Tue Aug 14 20:47:09 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 14 Aug 2007 18:47:09 +0000 (UTC)
Subject: [Rd]
	=?utf-8?q?Sligthly_OT_Re=3A_Makefile_for_embedding_OpenBUGS_?=
	=?utf-8?q?in_R=09package?=
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>
	<46B96EE6.2090606@statistik.uni-dortmund.de>
	<46BA1863.6030609@telenet.be> <46BA2E65.7080301@cimr.cam.ac.uk>
	<46C14875.5020008@businessdecision.com>
Message-ID: <loom.20070814T203929-398@post.gmane.org>

Tobias Verbeke <tobias.verbeke <at> businessdecision.com> writes:

> The resulting package now allows for using an embedded OpenBUGS
> on GNU/Linux without relying on WINE. Thanks to all for their helpful 
> comments.

  woo-hoo!  this is great!  Any chance that this will propagate
to the R2WinBUGS package at some point ... ??? 

  Ben Bolker


From p.dalgaard at biostat.ku.dk  Tue Aug 14 21:14:33 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 14 Aug 2007 21:14:33 +0200
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers
 bug in stats4::mle]
In-Reply-To: <loom.20070814T203613-433@post.gmane.org>
References: <46C0D1FF.3020005@zoo.ufl.edu> <20070814182635.GB29808@cs.cas.cz>
	<loom.20070814T203613-433@post.gmane.org>
Message-ID: <46C1FF19.7000003@biostat.ku.dk>

Ben Bolker wrote:
> Petr Savicky <savicky <at> cs.cas.cz> writes:
>
>
>   
>> Could you also include a script, which reproduces the problem? Just
>> to see under which conditions the problem occurs and how it
>> looks like exactly.
>>
>> Petr Savicky.
>>
>>     
>
>   The original post has such a script, just under the dashed line
> and above the diff/patch.  Sorry if I wasn't clear about that.
>
>   
Patch inserted in r-devel now.


From tobias.verbeke at telenet.be  Tue Aug 14 21:58:07 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Tue, 14 Aug 2007 21:58:07 +0200
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <loom.20070814T203929-398@post.gmane.org>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>	<46B96EE6.2090606@statistik.uni-dortmund.de>	<46BA1863.6030609@telenet.be>
	<46BA2E65.7080301@cimr.cam.ac.uk>	<46C14875.5020008@businessdecision.com>
	<loom.20070814T203929-398@post.gmane.org>
Message-ID: <46C2094F.5000102@telenet.be>

Hi Ben,

> Tobias Verbeke <tobias.verbeke <at> businessdecision.com> writes:
> 
>> The resulting package now allows for using an embedded OpenBUGS
>> on GNU/Linux without relying on WINE. Thanks to all for their helpful 
>> comments.
> 
>   woo-hoo!  this is great!  Any chance that this will propagate
> to the R2WinBUGS package at some point ... ??? 

A quick look at R2WinBUGS reveals that this package does not
embed the OpenBUGS distribution within the package. This is
not needed per se, but will then imply that the user has to
compile the C file that accesses the brugs.so shared library
(or a variant as the path to the bugs executable is an argument
to the bugs function in R2WinBUGS). When I worked on this (for
a specific application a client had in mind), I deliberately
chose to avoid any administration in addition to ordinary R
package installation.

The BRugs package, on the contrary, embeds a (previous) version
of OpenBUGS and could use what we found out in this thread, but
then the interface of BRugs is more designed for interactive use
of BUGS which currently still is possible only on Windows. It
might be an idea to modify the BRugsFit function (BRugs' meta function) 
to run a script file in one go when it runs on GNU/Linux. This
modification is needed as the current BRugsfit uses the "interactive"
commands modelCheck(), modelCompile() etc. in separate steps.

If the maintainer (in cc) would think this is a good idea, the
following things should then be assured within the BRugs package
in addition of changing BRugsFit function for it to work under
Linux:

(1) all of the BUGS files (data, model, inits and script files)
	should have CR LF line endings

(2) the script file produced should end on modelQuit() without
	any additional character (no newline)

Alternatively, it could be put into (yet another) R <-> BUGS
package, but this would duplicate a lot of the BRugs code.

Kind regards,
Tobias

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From ligges at statistik.uni-dortmund.de  Wed Aug 15 10:37:19 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 15 Aug 2007 10:37:19 +0200
Subject: [Rd] Sligthly OT Re: Makefile for embedding OpenBUGS in R
	package
In-Reply-To: <46C2094F.5000102@telenet.be>
References: <W906017980119021186410641@nocme1bl6.telenet-ops.be>	<Pine.LNX.4.64.0708062029410.27542@gannet.stats.ox.ac.uk>	<46B7B87C.1070808@cimr.cam.ac.uk>	<Pine.LNX.4.64.0708070340290.31210@gannet.stats.ox.ac.uk>	<46B8D6AD.9040707@cimr.cam.ac.uk>	<46B96EE6.2090606@statistik.uni-dortmund.de>	<46BA1863.6030609@telenet.be>
	<46BA2E65.7080301@cimr.cam.ac.uk>	<46C14875.5020008@businessdecision.com>
	<loom.20070814T203929-398@post.gmane.org>
	<46C2094F.5000102@telenet.be>
Message-ID: <46C2BB3F.5010103@statistik.uni-dortmund.de>



Tobias Verbeke wrote:
> Hi Ben,
> 
>> Tobias Verbeke <tobias.verbeke <at> businessdecision.com> writes:
>>
>>> The resulting package now allows for using an embedded OpenBUGS
>>> on GNU/Linux without relying on WINE. Thanks to all for their helpful 
>>> comments.
>>
>>   woo-hoo!  this is great!  Any chance that this will propagate
>> to the R2WinBUGS package at some point ... ??? 
> 
> A quick look at R2WinBUGS reveals that this package does not
> embed the OpenBUGS distribution within the package. This is
> not needed per se, but will then imply that the user has to
> compile the C file that accesses the brugs.so shared library
> (or a variant as the path to the bugs executable is an argument
> to the bugs function in R2WinBUGS). When I worked on this (for
> a specific application a client had in mind), I deliberately
> chose to avoid any administration in addition to ordinary R
> package installation.
> 
> The BRugs package, on the contrary, embeds a (previous) version
> of OpenBUGS and could use what we found out in this thread, but
> then the interface of BRugs is more designed for interactive use
> of BUGS which currently still is possible only on Windows. It
> might be an idea to modify the BRugsFit function (BRugs' meta function) 
> to run a script file in one go when it runs on GNU/Linux. This
> modification is needed as the current BRugsfit uses the "interactive"
> commands modelCheck(), modelCompile() etc. in separate steps.
> 
> If the maintainer (in cc) would think this is a good idea, the
> following things should then be assured within the BRugs package
> in addition of changing BRugsFit function for it to work under
> Linux:
> 
> (1) all of the BUGS files (data, model, inits and script files)
>     should have CR LF line endings
> 
> (2) the script file produced should end on modelQuit() without
>     any additional character (no newline)
> 
> Alternatively, it could be put into (yet another) R <-> BUGS
> package, but this would duplicate a lot of the BRugs code.


I'm fine with it, but I'd prefer to have such wrappers in R2WinBUGS 
(which already includes all those ugly wrappers).
BRugs was intended to have a more or less clean interface and I'd like 
to see a working .so that would be available at some point for running 
under Linux. So if anybody has the knowledge and tools to help Andrew 
Thomas, please do.

Additions to R2WinBUGS and BRugs are welcome. Please send patches 
against the sources on sourceforge 
(http://sourceforge.net/projects/bugs-r), since considerable changes 
have been made in the current developer version: e.g. integration of 
OpenBUGS 3.0.1 (thanks to Insightful), ports to S-PLUS (thanks to 
Insightful). Please make sure any changes will not break behaviour under 
S-PLUS.

Thanks you very much for contributing to BRugs!


Best,
Uwe



> Kind regards,
> Tobias
>


From murdoch at stats.uwo.ca  Wed Aug 15 16:53:11 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 15 Aug 2007 10:53:11 -0400
Subject: [Rd] Change of compiler for Windows build of R
In-Reply-To: <Pine.LNX.4.64.0708140719200.31255@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0708140719200.31255@gannet.stats.ox.ac.uk>
Message-ID: <46C31357.5010209@stats.uwo.ca>

On 8/14/2007 2:52 AM, Prof Brian Ripley wrote:
> The MinGW people have finally released a couple of builds of gcc 4.2.1 
> (and finally moved the build of 3.4.5 to release status after 19 months as 
> 'candidate').
> 
> We intend to use gcc 4.2.1 for the binary distribution of R 2.6.0, and 
> builds of R-devel are being made with it from now on.  The R-admin manual 
> now contains details of the pieces you need, and in due course there will 
> be an updated Rtools.exe containing this version.  I've successfully built 
> cross-compilers although am unlikely to distribute one for a while.

Rtools.exe has now been updated on www.murdoch-sutherland.com/Rtools. 
Please let me know of any problems.

It currently includes both gcc 4.2.1 and 3.4.5; I expect to drop 3.4.5 
sometime after the release of R 2.6.0.  It also includes Vanilla Perl, 
so finally Rtools.exe is all you need to build packages on Windows. 
(You probably want to get the Microsoft help compiler and some LaTeX, 
but these are not strictly necessary.)

Duncan Murdoch

> 
> gcc 4.2.1 is a better check of standards conformance, and you may see 
> warnings in packages not present with gcc 3.4.5.  All the CRAN packages 
> have been checked, and this showed up some issues with packages which 
> deviated markedly from the documented procedures. E.g.
> 
> - the C++ compiler is $(CXX), not g++, and $(CXX) is defined in MkRules.
> 
> - there is a quirk with dlltool both on Vista and with gcc 4.2.1 on XP
>    that needs '--as' included amongst the flags.  The rule in MkRules
>    works: several user-written rules do not.
> 
> So far we have seen no issues with mixing code compiled with gcc 3.4.5 and 
> 4.2.1.  There would almost certainly be issues with third-party C++ 
> libraries, and might be some with Fortran libraries that use complex 
> numbers.
> 
> The advantages of using this port include:
> 
> - Vista compatibility out of the box.
> 
> - ongoing support.  The main MinGW developer is really targetting gcc
>    4.3.0, and these compilers are interim releases with patches backported
>    from the gcc trunk.
> 
> - More complete C99 features: for example C99 inlining will be supported
>    in gcc 4.3.0 (and has already been tested using snapshots).
> 
> - integrated F9x support.  F9x is supported 'out of the box', and can now
>    consider using F9x code in R.
> 
> - OMP and threading support.
> 
> 
> R 2.5.1 will not build out of the box with these compilers, but R-patched 
> will (for suitable settings in MkRules).
>


From hb at stat.berkeley.edu  Wed Aug 15 17:42:34 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 15 Aug 2007 08:42:34 -0700
Subject: [Rd] Change of compiler for Windows build of R
In-Reply-To: <46C31357.5010209@stats.uwo.ca>
References: <Pine.LNX.4.64.0708140719200.31255@gannet.stats.ox.ac.uk>
	<46C31357.5010209@stats.uwo.ca>
Message-ID: <59d7961d0708150842h6b457f93i783a5497e0f34395@mail.gmail.com>

Thanks to both of you! /Henrik

On 8/15/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 8/14/2007 2:52 AM, Prof Brian Ripley wrote:
> > The MinGW people have finally released a couple of builds of gcc 4.2.1
> > (and finally moved the build of 3.4.5 to release status after 19 months as
> > 'candidate').
> >
> > We intend to use gcc 4.2.1 for the binary distribution of R 2.6.0, and
> > builds of R-devel are being made with it from now on.  The R-admin manual
> > now contains details of the pieces you need, and in due course there will
> > be an updated Rtools.exe containing this version.  I've successfully built
> > cross-compilers although am unlikely to distribute one for a while.
>
> Rtools.exe has now been updated on www.murdoch-sutherland.com/Rtools.
> Please let me know of any problems.
>
> It currently includes both gcc 4.2.1 and 3.4.5; I expect to drop 3.4.5
> sometime after the release of R 2.6.0.  It also includes Vanilla Perl,
> so finally Rtools.exe is all you need to build packages on Windows.
> (You probably want to get the Microsoft help compiler and some LaTeX,
> but these are not strictly necessary.)
>
> Duncan Murdoch
>
> >
> > gcc 4.2.1 is a better check of standards conformance, and you may see
> > warnings in packages not present with gcc 3.4.5.  All the CRAN packages
> > have been checked, and this showed up some issues with packages which
> > deviated markedly from the documented procedures. E.g.
> >
> > - the C++ compiler is $(CXX), not g++, and $(CXX) is defined in MkRules.
> >
> > - there is a quirk with dlltool both on Vista and with gcc 4.2.1 on XP
> >    that needs '--as' included amongst the flags.  The rule in MkRules
> >    works: several user-written rules do not.
> >
> > So far we have seen no issues with mixing code compiled with gcc 3.4.5 and
> > 4.2.1.  There would almost certainly be issues with third-party C++
> > libraries, and might be some with Fortran libraries that use complex
> > numbers.
> >
> > The advantages of using this port include:
> >
> > - Vista compatibility out of the box.
> >
> > - ongoing support.  The main MinGW developer is really targetting gcc
> >    4.3.0, and these compilers are interim releases with patches backported
> >    from the gcc trunk.
> >
> > - More complete C99 features: for example C99 inlining will be supported
> >    in gcc 4.3.0 (and has already been tested using snapshots).
> >
> > - integrated F9x support.  F9x is supported 'out of the box', and can now
> >    consider using F9x code in R.
> >
> > - OMP and threading support.
> >
> >
> > R 2.5.1 will not build out of the box with these compilers, but R-patched
> > will (for suitable settings in MkRules).
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Wed Aug 15 18:09:13 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 15 Aug 2007 18:09:13 +0200
Subject: [Rd] Change of compiler for Windows build of R
In-Reply-To: <59d7961d0708150842h6b457f93i783a5497e0f34395@mail.gmail.com>
References: <Pine.LNX.4.64.0708140719200.31255@gannet.stats.ox.ac.uk>	<46C31357.5010209@stats.uwo.ca>
	<59d7961d0708150842h6b457f93i783a5497e0f34395@mail.gmail.com>
Message-ID: <46C32529.5050100@biostat.ku.dk>

Henrik Bengtsson wrote:
> Thanks to both of you! /Henrik
>
> On 8/15/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>   
>> On 8/14/2007 2:52 AM, Prof Brian Ripley wrote:
>>     
>>> The MinGW people have finally released a couple of builds of gcc 4.2.1
>>>       
Seconded. In particular, can we have a big round of applause for this bit:
>>  It also includes Vanilla Perl,
>> so finally Rtools.exe is all you need to build packages on Windows.
>>     
Yay! People doing statistical computing classes rejoice! Getting the 
tools lined up properly has been a major stumbling block.

>> (You probably want to get the Microsoft help compiler and some LaTeX,
>> but these are not strictly necessary.)
>>     
(Can't win'em all. So Sweave still requires some work.)


From ripley at stats.ox.ac.uk  Wed Aug 15 20:32:59 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Aug 2007 19:32:59 +0100 (BST)
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers
 bug in stats4::mle]
In-Reply-To: <46C1FF19.7000003@biostat.ku.dk>
References: <46C0D1FF.3020005@zoo.ufl.edu> <20070814182635.GB29808@cs.cas.cz>
	<loom.20070814T203613-433@post.gmane.org>
	<46C1FF19.7000003@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0708151932240.31744@gannet.stats.ox.ac.uk>

On Tue, 14 Aug 2007, Peter Dalgaard wrote:

> Ben Bolker wrote:
>> Petr Savicky <savicky <at> cs.cas.cz> writes:
>>
>>
>>
>>> Could you also include a script, which reproduces the problem? Just
>>> to see under which conditions the problem occurs and how it
>>> looks like exactly.
>>>
>>> Petr Savicky.
>>>
>>>
>>
>>   The original post has such a script, just under the dashed line
>> and above the diff/patch.  Sorry if I wasn't clear about that.
>>
>>
> Patch inserted in r-devel now.

And all optim() methods now work on zero-length 'par'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Wed Aug 15 20:58:56 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 15 Aug 2007 14:58:56 -0400
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers
 bug in stats4::mle]
In-Reply-To: <Pine.LNX.4.64.0708151932240.31744@gannet.stats.ox.ac.uk>
References: <46C0D1FF.3020005@zoo.ufl.edu> <20070814182635.GB29808@cs.cas.cz>
	<loom.20070814T203613-433@post.gmane.org>
	<46C1FF19.7000003@biostat.ku.dk>
	<Pine.LNX.4.64.0708151932240.31744@gannet.stats.ox.ac.uk>
Message-ID: <46C34CF0.2090402@zoo.ufl.edu>

Prof Brian Ripley wrote:
> On Tue, 14 Aug 2007, Peter Dalgaard wrote:
>
>> Ben Bolker wrote:
>>> Petr Savicky <savicky <at> cs.cas.cz> writes:
>>>
>>>
>>>
>>>> Could you also include a script, which reproduces the problem? Just
>>>> to see under which conditions the problem occurs and how it
>>>> looks like exactly.
>>>>
>>>> Petr Savicky.
>>>>
>>>>
>>>
>>>   The original post has such a script, just under the dashed line
>>> and above the diff/patch.  Sorry if I wasn't clear about that.
>>>
>>>
>> Patch inserted in r-devel now.
>
> And all optim() methods now work on zero-length 'par'.
>
  So my patch would now seem to be unnecessary -- keep it for 
belt-and-suspenders purposes,
or remove it to minimize code complexity?

  thanks very much!

   Ben Bolker


From p.dalgaard at biostat.ku.dk  Wed Aug 15 21:40:02 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 15 Aug 2007 21:40:02 +0200
Subject: [Rd] [Fwd: behavior of L-BFGS-B with trivial function triggers
 bug in stats4::mle]
In-Reply-To: <46C34CF0.2090402@zoo.ufl.edu>
References: <46C0D1FF.3020005@zoo.ufl.edu>
	<20070814182635.GB29808@cs.cas.cz>	<loom.20070814T203613-433@post.gmane.org>	<46C1FF19.7000003@biostat.ku.dk>	<Pine.LNX.4.64.0708151932240.31744@gannet.stats.ox.ac.uk>
	<46C34CF0.2090402@zoo.ufl.edu>
Message-ID: <46C35692.9060002@biostat.ku.dk>

Ben Bolker wrote:
> Prof Brian Ripley wrote:
>   
>> On Tue, 14 Aug 2007, Peter Dalgaard wrote:
>>
>>     
>>> Ben Bolker wrote:
>>>       
>>>> Petr Savicky <savicky <at> cs.cas.cz> writes:
>>>>
>>>>
>>>>
>>>>         
>>>>> Could you also include a script, which reproduces the problem? Just
>>>>> to see under which conditions the problem occurs and how it
>>>>> looks like exactly.
>>>>>
>>>>> Petr Savicky.
>>>>>
>>>>>
>>>>>           
>>>>   The original post has such a script, just under the dashed line
>>>> and above the diff/patch.  Sorry if I wasn't clear about that.
>>>>
>>>>
>>>>         
>>> Patch inserted in r-devel now.
>>>       
>> And all optim() methods now work on zero-length 'par'.
>>
>>     
>   So my patch would now seem to be unnecessary -- keep it for 
> belt-and-suspenders purposes,
> or remove it to minimize code complexity?
>
>   
Isn't broken, do not fix. We can always call it an optimization, 
avoiding unnecessary calls to optim ;-) ....


From zhenhuan at stat.osu.edu  Thu Aug 16 00:41:16 2007
From: zhenhuan at stat.osu.edu (Zhenhuan Cui)
Date: Wed, 15 Aug 2007 18:41:16 -0400 (EDT)
Subject: [Rd] package dependencies
Message-ID: <Pine.LNX.4.64.0708151840410.5798@mordor.stat.ohio-state.edu>

I created an add-on R package. In this package, there is a line 
"require(pckgname)", because I need to call some functions in pckgname. My 
package is successfully built and can be successful installed. But R CMD 
check can not be executed. The error message is:

* checking package dependencies ... ERROR
Packages required but not available:
pckgname

Actually, before running R CMD check, I run the command "set 
R_LIBS=/home/myname/MyRLibrary". It is the directory where pckgname is 
installed.

What else should I do so that I can pass R CMD check?

Best wishes,
Zhenhuan


From sfalcon at fhcrc.org  Thu Aug 16 01:59:01 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 15 Aug 2007 16:59:01 -0700
Subject: [Rd] package dependencies
In-Reply-To: <Pine.LNX.4.64.0708151840410.5798@mordor.stat.ohio-state.edu>
	(Zhenhuan Cui's message of "Wed\,
	15 Aug 2007 18\:41\:16 -0400 \(EDT\)")
References: <Pine.LNX.4.64.0708151840410.5798@mordor.stat.ohio-state.edu>
Message-ID: <m21we48i4a.fsf@fhcrc.org>

Zhenhuan Cui <zhenhuan at stat.osu.edu> writes:

> I created an add-on R package. In this package, there is a line 
> "require(pckgname)", because I need to call some functions in pckgname. My 
> package is successfully built and can be successful installed. But R CMD 
> check can not be executed. The error message is:

Instead of require(pkgname), simply list pkgname in the Depends field
of your package's DESCRIPTION file.  See the Writing R Extensions
manual for details.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From eairoldi at Princeton.EDU  Thu Aug 16 02:55:46 2007
From: eairoldi at Princeton.EDU (Edo Airoldi)
Date: Wed, 15 Aug 2007 20:55:46 -0400
Subject: [Rd] R 2.5.1.
Message-ID: <2C3A8BD1-2AE0-4E2C-903E-51CF94074CAC@Princeton.EDU>

installed from the binary image (http://cran.r-project.org/bin/ 
macosx/) on an intel mac 10.4.10 throws three warnings:

-----------------
R version 2.5.1 (2007-06-27)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

2007-08-15 20:52:09.248 R[711] tossing reply message sequence 1 on  
thread 0x15b5e250
2007-08-15 20:52:09.414 R[711] tossing reply message sequence 2 on  
thread 0x15b5e250
2007-08-15 20:52:09.454 R[711] tossing reply message sequence 3 on  
thread 0x15b5e250
 >
------------------

however nothing obvious seems to go wrong.

edo airoldi


From kjbeath at kagi.com  Thu Aug 16 03:27:41 2007
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 16 Aug 2007 11:27:41 +1000
Subject: [Rd] R 2.5.1.
In-Reply-To: <2C3A8BD1-2AE0-4E2C-903E-51CF94074CAC@Princeton.EDU>
References: <2C3A8BD1-2AE0-4E2C-903E-51CF94074CAC@Princeton.EDU>
Message-ID: <275BB5D6-48D0-446D-B50F-5CA5DBD43D49@kagi.com>

On 16/08/2007, at 10:55 AM, Edo Airoldi wrote:

> installed from the binary image (http://cran.r-project.org/bin/
> macosx/) on an intel mac 10.4.10 throws three warnings:
>
> -----------------
> R version 2.5.1 (2007-06-27)
> Copyright (C) 2007 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> 2007-08-15 20:52:09.248 R[711] tossing reply message sequence 1 on
> thread 0x15b5e250
> 2007-08-15 20:52:09.414 R[711] tossing reply message sequence 2 on
> thread 0x15b5e250
> 2007-08-15 20:52:09.454 R[711] tossing reply message sequence 3 on
> thread 0x15b5e250
>>
> ------------------
>
> however nothing obvious seems to go wrong.
>

This isn't a problem, R still works fine.

There is a special mailing list for Mac related problems at https:// 
stat.ethz.ch/mailman/listinfo/r-sig-mac

Ken


From byron.ellis at gmail.com  Thu Aug 16 07:32:01 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Wed, 15 Aug 2007 22:32:01 -0700
Subject: [Rd] methods and try() [R-devel]
Message-ID: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>

Hi all, I'm having a problem with some sort of interaction with try()
and methods, I think.

The setup is as follows, I have an S4 class that holds an environment
and I would like to evaluate the right hand side of a function inside
that environment. No problem there.

However, if the formula involves a symbol that doesn't exist, which
may or may not happen, it fails as it should and reports and error
"blah blah does not exist." As it should.

When I wrap that same call in a try() statement, the error becomes "no
function to return from, jumping to top level," bypassing the try
statement and generally wreaking havoc. Any clues what might be
causing this?

-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From maechler at stat.math.ethz.ch  Thu Aug 16 09:03:33 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Aug 2007 09:03:33 +0200
Subject: [Rd] package dependencies
In-Reply-To: <m21we48i4a.fsf@fhcrc.org>
References: <Pine.LNX.4.64.0708151840410.5798@mordor.stat.ohio-state.edu>
	<m21we48i4a.fsf@fhcrc.org>
Message-ID: <18115.63173.648636.836215@stat.math.ethz.ch>

>>>>> "SF" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>     on Wed, 15 Aug 2007 16:59:01 -0700 writes:

   SF> Zhenhuan Cui <zhenhuan at stat.osu.edu> writes:

     >> I created an add-on R package. In this package, there is
     >> a line "require(pckgname)", because I need to call some
     >> functions in pckgname. My package is successfully built
     >> and can be successful installed. But R CMD check can not
     >> be executed. The error message is:

     .............

   SF> Instead of require(pkgname), simply list pkgname in the
   SF> Depends field of your package's DESCRIPTION file.  See
   SF> the Writing R Extensions manual for details.

But he still must make sure that "R CMD check" has  'pkgname'
in its R_LIBS :

   >> Actually, before running R CMD check, I run the command "set 
   >> R_LIBS=/home/myname/MyRLibrary". It is the directory where pckgname is 
   >> installed.

   >> What else should I do so that I can pass R CMD check?

Instead of 'set R_LIBS=....'  {which seems to indicate you use a csh-alike}
use
	setenv R_LIBS=.............
	R CMD check ....

or --- typically better, since the R_LIBS setting remains "local" ---

       env R_LIBS=...........  R CMD check <mypkg

       (all in one line)
Martin


From michael at cassin.name  Thu Aug 16 10:44:15 2007
From: michael at cassin.name (Michael Cassin)
Date: Thu, 16 Aug 2007 09:44:15 +0100
Subject: [Rd] Advice on parsing / overriding function calls
Message-ID: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070816/f47c10b4/attachment.pl 

From luke at stat.uiowa.edu  Thu Aug 16 14:47:44 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 16 Aug 2007 07:47:44 -0500 (CDT)
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>

On Wed, 15 Aug 2007, Byron Ellis wrote:

> Hi all, I'm having a problem with some sort of interaction with try()
> and methods, I think.
>
> The setup is as follows, I have an S4 class that holds an environment
> and I would like to evaluate the right hand side of a function inside
> that environment. No problem there.
>
> However, if the formula involves a symbol that doesn't exist, which
> may or may not happen, it fails as it should and reports and error
> "blah blah does not exist." As it should.
>
> When I wrap that same call in a try() statement, the error becomes "no
> function to return from, jumping to top level," bypassing the try
> statement and generally wreaking havoc. Any clues what might be
> causing this?

Yes.  There is no context on the stack that corresponds to the
environment to which a jump is to be made.  Why that is the case is
impossible to tell without a simple reproducible example.

Best,

luke


-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From h.wickham at gmail.com  Thu Aug 16 14:50:42 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 16 Aug 2007 07:50:42 -0500
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
Message-ID: <f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>

What are you trying to defend against?  A serious attacker could still
use rm/assign/get/eval/... to circumvent your replaced functions.  I
think it would be very difficult (if not impossible) to prevent this
from happening), especially if the user can load packages.

Hadley

On 8/16/07, Michael Cassin <michael at cassin.name> wrote:
> Hi,
>
> I am trying to tighten file I/O security on a process that passes a
> user-supplied script to R CMD Batch.  Broadly speaking, I'd like to restrict
> I/O to a designated path on the file system. Right now, I'm trying to
> address this in the R environment by forcing the script to use modified
> versions of scan, read.table, sys.load.image, etc.
>
> I can run a replace string on the user-supplied script so that, for example,
> "scan(" is replaced by "safe.scan("
>
> e.g.
>
> > SafePath <- function(file)
> {fp<-strsplit(file,"/");paste("safepath",fp[[1]][length(fp[[1]])],sep="/")}
> > SafePath("/etc/passwd")
> [1] "safepath/passwd"
>
> >  Safe.scan <- function(file, ...) scan(SafePath(file),...)
> > Safe.scan("/etc/passwd",what="",sep="\n")
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'safepath/passwd', reason 'No such file or directory'
>
> I'd appreciate any critique of this approach.  Is there something more
> effective or elegant?
>
> Regards,
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
http://had.co.nz/


From michael at cassin.name  Thu Aug 16 15:23:24 2007
From: michael at cassin.name (Michael Cassin)
Date: Thu, 16 Aug 2007 14:23:24 +0100
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
Message-ID: <b02e8b330708160623s369196fbtf436d56ed6185d4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070816/d300b4d2/attachment.pl 

From hin-tak.leung at cimr.cam.ac.uk  Thu Aug 16 15:23:31 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 16 Aug 2007 14:23:31 +0100
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
Message-ID: <46C44FD3.3040502@cimr.cam.ac.uk>

Well, I think there are some serious use e.g. offering a web server
for script uploaded then downloading the Rout result back...

The issue is more about whether he wants to limit *all* file system 
access or just limiting to certain areas. For the former,
I would set up a chroot jail and run R from within; for the latter,
I would probably do something with LD_LIBRARY_PRELOAD to override
all the file system accessing functions in libc directly, really.
That would fix the problem with system(rm) and some such, I think,
because if your entire R process and any sub-process R launches has no 
access to the genuine libc fwrite/fread/etc functions you cannot do
any demage, right?
Both are tricky and take time to do (the chroot jail a bit easier, 
actually...), but quite do-able.

It depends on (1) how paranoid you are, (2) how much trouble you want to 
have for yourself to achieve those restrictions...

hadley wickham wrote:
> What are you trying to defend against?  A serious attacker could still
> use rm/assign/get/eval/... to circumvent your replaced functions.  I
> think it would be very difficult (if not impossible) to prevent this
> from happening), especially if the user can load packages.
> 
> Hadley
> 
> On 8/16/07, Michael Cassin <michael at cassin.name> wrote:
>> Hi,
>>
>> I am trying to tighten file I/O security on a process that passes a
>> user-supplied script to R CMD Batch.  Broadly speaking, I'd like to restrict
>> I/O to a designated path on the file system. Right now, I'm trying to
>> address this in the R environment by forcing the script to use modified
>> versions of scan, read.table, sys.load.image, etc.
>>
>> I can run a replace string on the user-supplied script so that, for example,
>> "scan(" is replaced by "safe.scan("
>>
>> e.g.
>>
>>> SafePath <- function(file)
>> {fp<-strsplit(file,"/");paste("safepath",fp[[1]][length(fp[[1]])],sep="/")}
>>> SafePath("/etc/passwd")
>> [1] "safepath/passwd"
>>
>>>  Safe.scan <- function(file, ...) scan(SafePath(file),...)
>>> Safe.scan("/etc/passwd",what="",sep="\n")
>> Error in file(file, "r") : unable to open connection
>> In addition: Warning message:
>> cannot open file 'safepath/passwd', reason 'No such file or directory'
>>
>> I'd appreciate any critique of this approach.  Is there something more
>> effective or elegant?
>>
>> Regards,
>> Mike
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From guillaume.proteowiki at free.fr  Thu Aug 16 14:08:53 2007
From: guillaume.proteowiki at free.fr (Guillaume B.)
Date: Thu, 16 Aug 2007 05:08:53 -0700 (PDT)
Subject: [Rd] call R function in c++ program
Message-ID: <12180033.post@talk.nabble.com>


Hi all
I don't know if my message are correct in this forums.
I create a program in c++ who use statistical function. I want to execute
this function in R (in particular for use packages ade4, lattice,
bioconductor...)

Until now, my program work for simple function ("plot", "rnorm"...) but I
can't use library

My class are :

// in constructor
     int argc = 1;
     char *argv[] = {"wxR"};
     Rf_initEmbeddedR(argc, argv);
     rho = R_GlobalEnv;

// in destructor
     Rf_endEmbeddedR(0);

// for translate std::vector to SEXP VECTOR
// std_vector are defined as "vector<double>" and iterator as
"vector<double>::iterator"
     PROTECT( vector_SEXP = allocVector(REALSXP, std_vector.size()) );
     int i = 0;
     for(std_iterator s_it=std_vector.begin(); s_it!=std_vector.end();
s_it++)
     {
         REAL(vector_SEXP)[i] = (double) *s_it;
         i++;
     }
     UNPROTECT(1);

// for create a variable in R environement
     defineVar(install("variable_name"), variable_value_SEXP, rho);

// for execute "complex" function (with parser)
     PROTECT( e1 = mkString("plot(variable_name, type=\"l\")") );
     PROTECT( e2 = R_ParseVector(e1, 1, &status, R_NilValue) );
     R_tryEval(VECTOR_ELT(e2,0), rho, &hadError);
     UNPROTECT(2);

// for execute "simple" function (without parser)
     PROTECT( e1 = lang3(install(":"), ScalarInteger(1), ScalarInteger(4))
);
     PROTECT( e2 = lang4(install("matrix"), e1, ScalarInteger(4),
ScalarInteger(1)) );
     PROTECT( e3 = lang2(install("layout"), e2) );
     eval(e3,R_GlobalEnv);
     UNPROTECT(3);

// for call library (using parser)
     PROTECT( e1 = mkString("library(ade4, logical.return=TRUE);
     PROTECT( e2 = R_ParseVector(e1, 1, &status, R_NilValue) );
     e3 = R_tryEval(VECTOR_ELT(e2,0), rho, &hadError);
     UNPROTECT(2);
     if(LOGICAL(e3)[0])
          // succes
     else
          // echec

Until this point, all my function succes !

When I try to call function in ade4 library, I have error 1 :
     PROTECT( e1 = mkString("a<-dudi.pca(b,scannf=FALSE, nf=2)") 
     PROTECT( e2 = R_ParseVector(e1, 1, &status, R_NilValue) );
     R_tryEval(VECTOR_ELT(e2,0), rho, &hadError);
     UNPROTECT(2);

You know where come from the problem ?

Bonus question 1 :
I can't call directely the function plot(x, type="l") without parser.
if I try somthing like this, it's doesn't work :
     PROTECT( e2 = lang4(install("type"), mkChar("l")) );
     PROTECT( e3 = lang3(install("plot"), e1, e2) );
     eval(e3,R_GlobalEnv);
     UNPROTECT(3);
How can I resolve this ?

Bonus question 2 :
When I call some "plot" function, my program crash. And I don't khow why


Thanks for yours suggests
-- 
View this message in context: http://www.nabble.com/call-R-function-in-c%2B%2B-program-tf4279222.html#a12180033
Sent from the R devel mailing list archive at Nabble.com.


From elw at stderr.org  Thu Aug 16 17:33:46 2007
From: elw at stderr.org (elw at stderr.org)
Date: Thu, 16 Aug 2007 10:33:46 -0500 (CDT)
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <46C44FD3.3040502@cimr.cam.ac.uk>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
	<46C44FD3.3040502@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0708161025200.10273@illuminati.stderr.org>


> The issue is more about whether he wants to limit *all* file system
> access or just limiting to certain areas. For the former,
> I would set up a chroot jail and run R from within; for the latter,
> I would probably do something with LD_LIBRARY_PRELOAD to override
> all the file system accessing functions in libc directly, really.
> That would fix the problem with system(rm) and some such, I think,
> because if your entire R process and any sub-process R launches has no
> access to the genuine libc fwrite/fread/etc functions you cannot do
> any demage, right?
> Both are tricky and take time to do (the chroot jail a bit easier,
> actually...), but quite do-able.


a sneaky trick:

for each compute session, automate setting up a zone ("solaris 
containers") on a solaris 10+ box.  if you have a 
preinstalled/preconfigured zone template, snapshotted with zfs, you can 
roll out a new compute zone in literally seconds.  you can quota it, limit 
the amount of CPU it gets, etc.  really not very difficult at all to set 
up.  sun's tools are *great* for this nowadays.

this is substantially safer than chroot() or LD_PRELOAD tricks, and lets 
you do this stuff without having to invent the wheel.

it also reduces overhead to the point where you really *can* set up a 
naked compute (well, with R in it...) environment for every compute 
session getting instantiated.  in way, way, way less time than it takes 
for the computations to actually run.

if someone does system(rm) in a container... who cares?  they just trashed 
their own session, and nothing else.  just blow the trashed ones away 
periodically.

--e


From simon.urbanek at r-project.org  Thu Aug 16 17:59:56 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 16 Aug 2007 11:59:56 -0400
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <46C44FD3.3040502@cimr.cam.ac.uk>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
	<46C44FD3.3040502@cimr.cam.ac.uk>
Message-ID: <6100AC6F-81EA-47E1-920B-BE915E22939E@r-project.org>

Thinking along these lines, we actually have a mechanism for  
replacing the system call (it's used by the Mac GUI to allow root  
calls) and one could think of expanding this to all critical  
operations. Clearly, there are issues (speed for example), but it  
would be nice to have a 'fortified' version of R that allows turing  
on restrictions. I don't think it's easy, but given the rising demand  
(at least in my perception), it would be interesting to see how far  
we can get.

Re filtering strings in commands - I don't think this will work,  
because you can compute on the language, so you can construct  
arbitrary calls without using the names in verbatim, so it is  
possible to circumvent such filters fairly easily.

Cheers,
Simon

On Aug 16, 2007, at 9:23 AM, Hin-Tak Leung wrote:

> Well, I think there are some serious use e.g. offering a web server
> for script uploaded then downloading the Rout result back...
>
> The issue is more about whether he wants to limit *all* file system
> access or just limiting to certain areas. For the former,
> I would set up a chroot jail and run R from within; for the latter,
> I would probably do something with LD_LIBRARY_PRELOAD to override
> all the file system accessing functions in libc directly, really.
> That would fix the problem with system(rm) and some such, I think,
> because if your entire R process and any sub-process R launches has no
> access to the genuine libc fwrite/fread/etc functions you cannot do
> any demage, right?
> Both are tricky and take time to do (the chroot jail a bit easier,
> actually...), but quite do-able.
>
> It depends on (1) how paranoid you are, (2) how much trouble you  
> want to
> have for yourself to achieve those restrictions...
>
> hadley wickham wrote:
>> What are you trying to defend against?  A serious attacker could  
>> still
>> use rm/assign/get/eval/... to circumvent your replaced functions.  I
>> think it would be very difficult (if not impossible) to prevent this
>> from happening), especially if the user can load packages.
>>
>> Hadley
>>
>> On 8/16/07, Michael Cassin <michael at cassin.name> wrote:
>>> Hi,
>>>
>>> I am trying to tighten file I/O security on a process that passes a
>>> user-supplied script to R CMD Batch.  Broadly speaking, I'd like  
>>> to restrict
>>> I/O to a designated path on the file system. Right now, I'm  
>>> trying to
>>> address this in the R environment by forcing the script to use  
>>> modified
>>> versions of scan, read.table, sys.load.image, etc.
>>>
>>> I can run a replace string on the user-supplied script so that,  
>>> for example,
>>> "scan(" is replaced by "safe.scan("
>>>
>>> e.g.
>>>
>>>> SafePath <- function(file)
>>> {fp<-strsplit(file,"/");paste("safepath",fp[[1]][length(fp 
>>> [[1]])],sep="/")}
>>>> SafePath("/etc/passwd")
>>> [1] "safepath/passwd"
>>>
>>>>  Safe.scan <- function(file, ...) scan(SafePath(file),...)
>>>> Safe.scan("/etc/passwd",what="",sep="\n")
>>> Error in file(file, "r") : unable to open connection
>>> In addition: Warning message:
>>> cannot open file 'safepath/passwd', reason 'No such file or  
>>> directory'
>>>
>>> I'd appreciate any critique of this approach.  Is there something  
>>> more
>>> effective or elegant?
>>>
>>> Regards,
>>> Mike
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Thu Aug 16 18:27:27 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Aug 2007 17:27:27 +0100 (BST)
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <6100AC6F-81EA-47E1-920B-BE915E22939E@r-project.org>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
	<46C44FD3.3040502@cimr.cam.ac.uk>
	<6100AC6F-81EA-47E1-920B-BE915E22939E@r-project.org>
Message-ID: <Pine.LNX.4.64.0708161714000.31515@gannet.stats.ox.ac.uk>

On Thu, 16 Aug 2007, Simon Urbanek wrote:

> Thinking along these lines, we actually have a mechanism for
> replacing the system call (it's used by the Mac GUI to allow root
> calls) and one could think of expanding this to all critical
> operations. Clearly, there are issues (speed for example), but it
> would be nice to have a 'fortified' version of R that allows turing
> on restrictions. I don't think it's easy, but given the rising demand
> (at least in my perception), it would be interesting to see how far
> we can get.
>
> Re filtering strings in commands - I don't think this will work,
> because you can compute on the language, so you can construct
> arbitrary calls without using the names in verbatim, so it is
> possible to circumvent such filters fairly easily.

Exactly.  All I would need is access to a file() connection, and I could 
easily do that in such a way that 'file' never appeared in the script.
And I've thought of half a dozen backdoors that have not been mentioned in 
this thread.

I am not sure there is really much point in trying to fortify R, when 
that's the OS's job and it may well be better to run R in a suitable 
sandbox.  Certainly I think that is the solution for web services.

One area where it may be necessary is embedded applications.  Certainly if 
R is embedded into the same process (which is how R as an shlib or DLL is 
usually used) then you may want the main application to have privileges 
you do not give to the embedded R.  But using a separate process (e.g. via 
Rserve) may be more secure.

>
> Cheers,
> Simon
>
> On Aug 16, 2007, at 9:23 AM, Hin-Tak Leung wrote:
>
>> Well, I think there are some serious use e.g. offering a web server
>> for script uploaded then downloading the Rout result back...
>>
>> The issue is more about whether he wants to limit *all* file system
>> access or just limiting to certain areas. For the former,
>> I would set up a chroot jail and run R from within; for the latter,
>> I would probably do something with LD_LIBRARY_PRELOAD to override
>> all the file system accessing functions in libc directly, really.
>> That would fix the problem with system(rm) and some such, I think,
>> because if your entire R process and any sub-process R launches has no
>> access to the genuine libc fwrite/fread/etc functions you cannot do
>> any demage, right?
>> Both are tricky and take time to do (the chroot jail a bit easier,
>> actually...), but quite do-able.
>>
>> It depends on (1) how paranoid you are, (2) how much trouble you
>> want to
>> have for yourself to achieve those restrictions...
>>
>> hadley wickham wrote:
>>> What are you trying to defend against?  A serious attacker could
>>> still
>>> use rm/assign/get/eval/... to circumvent your replaced functions.  I
>>> think it would be very difficult (if not impossible) to prevent this
>>> from happening), especially if the user can load packages.
>>>
>>> Hadley
>>>
>>> On 8/16/07, Michael Cassin <michael at cassin.name> wrote:
>>>> Hi,
>>>>
>>>> I am trying to tighten file I/O security on a process that passes a
>>>> user-supplied script to R CMD Batch.  Broadly speaking, I'd like
>>>> to restrict
>>>> I/O to a designated path on the file system. Right now, I'm
>>>> trying to
>>>> address this in the R environment by forcing the script to use
>>>> modified
>>>> versions of scan, read.table, sys.load.image, etc.
>>>>
>>>> I can run a replace string on the user-supplied script so that,
>>>> for example,
>>>> "scan(" is replaced by "safe.scan("
>>>>
>>>> e.g.
>>>>
>>>>> SafePath <- function(file)
>>>> {fp<-strsplit(file,"/");paste("safepath",fp[[1]][length(fp
>>>> [[1]])],sep="/")}
>>>>> SafePath("/etc/passwd")
>>>> [1] "safepath/passwd"
>>>>
>>>>>  Safe.scan <- function(file, ...) scan(SafePath(file),...)
>>>>> Safe.scan("/etc/passwd",what="",sep="\n")
>>>> Error in file(file, "r") : unable to open connection
>>>> In addition: Warning message:
>>>> cannot open file 'safepath/passwd', reason 'No such file or
>>>> directory'
>>>>
>>>> I'd appreciate any critique of this approach.  Is there something
>>>> more
>>>> effective or elegant?
>>>>
>>>> Regards,
>>>> Mike

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From byron.ellis at gmail.com  Thu Aug 16 21:53:38 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Thu, 16 Aug 2007 12:53:38 -0700
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>
	<Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>
Message-ID: <7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com>

On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
> On Wed, 15 Aug 2007, Byron Ellis wrote:
>
> > Hi all, I'm having a problem with some sort of interaction with try()
> > and methods, I think.
> >
> > The setup is as follows, I have an S4 class that holds an environment
> > and I would like to evaluate the right hand side of a function inside
> > that environment. No problem there.
> >
> > However, if the formula involves a symbol that doesn't exist, which
> > may or may not happen, it fails as it should and reports and error
> > "blah blah does not exist." As it should.
> >
> > When I wrap that same call in a try() statement, the error becomes "no
> > function to return from, jumping to top level," bypassing the try
> > statement and generally wreaking havoc. Any clues what might be
> > causing this?
>
> Yes.  There is no context on the stack that corresponds to the
> environment to which a jump is to be made.  Why that is the case is
> impossible to tell without a simple reproducible example.

I have a sinking feeling that generating a good reduction will also
find my bug. :-) I was mostly wondering if there had been a recent
change in the try() machinery. In any case, I'll keep hunting for the
problem.

>
> Best,
>
> luke
>
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From michael at cassin.name  Thu Aug 16 22:04:21 2007
From: michael at cassin.name (Michael Cassin)
Date: Thu, 16 Aug 2007 21:04:21 +0100
Subject: [Rd] Advice on parsing / overriding function calls
In-Reply-To: <Pine.LNX.4.64.0708161714000.31515@gannet.stats.ox.ac.uk>
References: <b02e8b330708160144idf261f4xf0944feb36cbbed3@mail.gmail.com>
	<f8e6ff050708160550t1e7ad0a7he0479efcdc3a575@mail.gmail.com>
	<46C44FD3.3040502@cimr.cam.ac.uk>
	<6100AC6F-81EA-47E1-920B-BE915E22939E@r-project.org>
	<Pine.LNX.4.64.0708161714000.31515@gannet.stats.ox.ac.uk>
Message-ID: <b02e8b330708161304g3fe1815biafeed37dcbc96289@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070816/c5f34112/attachment.pl 

From luke at stat.uiowa.edu  Thu Aug 16 22:26:38 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 16 Aug 2007 15:26:38 -0500 (CDT)
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com> 
	<Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>
	<7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708161525100.2836@itasca2.wildberry.org>

On Thu, 16 Aug 2007, Byron Ellis wrote:

> On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
>> On Wed, 15 Aug 2007, Byron Ellis wrote:
>>
>>> Hi all, I'm having a problem with some sort of interaction with try()
>>> and methods, I think.
>>>
>>> The setup is as follows, I have an S4 class that holds an environment
>>> and I would like to evaluate the right hand side of a function inside
>>> that environment. No problem there.
>>>
>>> However, if the formula involves a symbol that doesn't exist, which
>>> may or may not happen, it fails as it should and reports and error
>>> "blah blah does not exist." As it should.
>>>
>>> When I wrap that same call in a try() statement, the error becomes "no
>>> function to return from, jumping to top level," bypassing the try
>>> statement and generally wreaking havoc. Any clues what might be
>>> causing this?
>>
>> Yes.  There is no context on the stack that corresponds to the
>> environment to which a jump is to be made.  Why that is the case is
>> impossible to tell without a simple reproducible example.
>
> I have a sinking feeling that generating a good reduction will also
> find my bug. :-) I was mostly wondering if there had been a recent
> change in the try() machinery. In any case, I'll keep hunting for the
> problem.

There sae, at 2.5.0 I believe.  At that point try was reimplemented in
terms of tryCatch.  That may have uncovered a bug in our code or
yours, but without a reproducible example it's hard to say more.

Best,

luke


>
>>
>> Best,
>>
>> luke
>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From byron.ellis at gmail.com  Thu Aug 16 22:34:55 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Thu, 16 Aug 2007 13:34:55 -0700
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <Pine.LNX.4.64.0708161525100.2836@itasca2.wildberry.org>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>
	<Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>
	<7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com>
	<Pine.LNX.4.64.0708161525100.2836@itasca2.wildberry.org>
Message-ID: <7098abec0708161334q269d41b0ob4d2398d6660c1b3@mail.gmail.com>

On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
>
> There sae, at 2.5.0 I believe.  At that point try was reimplemented in
> terms of tryCatch.  That may have uncovered a bug in our code or
> yours, but without a reproducible example it's hard to say more.

An indeed, I believe I've got one. Turns out it didn't solve my
problem though. So, imagine we have a method (with a new generic).
Say,

setGeneric("glue",function(a,b) standardGeneric("glue"))
setMethod("glue",signature("character","character"),function(a,b) {
	paste(a,b,sep="")
})

Trying the code:

> glue("A","B")
[1] "AB"
> glue("A",B)
Error: object "B" not found
Error in glue("A", B) :
  error in evaluating the argument 'b' in selecting a method for function 'glue'

Good. Works as expected (there's no B in the environment). However,
I'd expect try to work...

>  try(glue("A",B))
Error: no function to return from, jumping to top level
Error in glue("A", B) :
  error in evaluating the argument 'b' in selecting a method for function 'glue'

with silent=TRUE the "jumping to top level" is not caught and causes
scripts to bail out.

Hopefully that helps?


>
> Best,
>
> luke
>
>
> >
> >>
> >> Best,
> >>
> >> luke
> >>
> >>
> >> --
> >> Luke Tierney
> >> Chair, Statistics and Actuarial Science
> >> Ralph E. Wareham Professor of Mathematical Sciences
> >> University of Iowa                  Phone:             319-335-3386
> >> Department of Statistics and        Fax:               319-335-3017
> >>     Actuarial Science
> >> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> >> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> >>
> >
> >
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From luke at stat.uiowa.edu  Fri Aug 17 00:30:27 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 16 Aug 2007 17:30:27 -0500 (CDT)
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <7098abec0708161334q269d41b0ob4d2398d6660c1b3@mail.gmail.com>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com> 
	<Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org> 
	<7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com> 
	<Pine.LNX.4.64.0708161525100.2836@itasca2.wildberry.org>
	<7098abec0708161334q269d41b0ob4d2398d6660c1b3@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708161654000.2836@itasca2.wildberry.org>

I think I understand the issue.  The methods code uses R_tryCatch
internally in a few places, hoping I think for a C level variant of
tryCatch.  It isn't meant to be used that way.  It is intended only
for use in embedded contexts where there is no proper top level, or
possibly in contexts where conceptually the evaluation is happening in
a seperate thread of execution.  In particular R_tryEval establishes
it's own top level (and that is the top level that is being jumped
to):

> { try(glue("A",B)); 2}
Error: no function to return from, jumping to top level
Error in glue("A", B) :
   error in evaluating the argument 'b' in selecting a method for function 'glue'
[1] 2
>

Because of the "internal" top level established by R_tryEval there is
no way to jump from inside the eval to an outer context, which is what
needs to happen for try() to work here.

It looks like the intent in methods_list_dispatch.c in all but one
case is to catch the error and report something a bit more meaningful;
in the one other case, in R_nextMethodCall, there is also a cleanup
action that occurs before resignaling the error.

To fix this will I think require designing a C level tryCatch.  That
will take a bit of time to get right.  Not sure if it will get done by
2.6.0.  There may be a quick temporary fix but I'm not seeing one at
this point.

Arguably R_tryEval in its present form should also ensure that the
handler stacks are empty in the call (not an issue for the intended
embedded usage).  Need to think about that a bit as well.

Best,

luke

On Thu, 16 Aug 2007, Byron Ellis wrote:

> On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
>>
>> There sae, at 2.5.0 I believe.  At that point try was reimplemented in
>> terms of tryCatch.  That may have uncovered a bug in our code or
>> yours, but without a reproducible example it's hard to say more.
>
> An indeed, I believe I've got one. Turns out it didn't solve my
> problem though. So, imagine we have a method (with a new generic).
> Say,
>
> setGeneric("glue",function(a,b) standardGeneric("glue"))
> setMethod("glue",signature("character","character"),function(a,b) {
> 	paste(a,b,sep="")
> })
>
> Trying the code:
>
>> glue("A","B")
> [1] "AB"
>> glue("A",B)
> Error: object "B" not found
> Error in glue("A", B) :
>  error in evaluating the argument 'b' in selecting a method for function 'glue'
>
> Good. Works as expected (there's no B in the environment). However,
> I'd expect try to work...
>
>>  try(glue("A",B))
> Error: no function to return from, jumping to top level
> Error in glue("A", B) :
>  error in evaluating the argument 'b' in selecting a method for function 'glue'
>
> with silent=TRUE the "jumping to top level" is not caught and causes
> scripts to bail out.
>
> Hopefully that helps?
>
>
>>
>> Best,
>>
>> luke
>>
>>
>>>
>>>>
>>>> Best,
>>>>
>>>> luke
>>>>
>>>>
>>>> --
>>>> Luke Tierney
>>>> Chair, Statistics and Actuarial Science
>>>> Ralph E. Wareham Professor of Mathematical Sciences
>>>> University of Iowa                  Phone:             319-335-3386
>>>> Department of Statistics and        Fax:               319-335-3017
>>>>     Actuarial Science
>>>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>>>
>>>
>>>
>>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From byron.ellis at gmail.com  Fri Aug 17 01:10:14 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Thu, 16 Aug 2007 16:10:14 -0700
Subject: [Rd] methods and try() [R-devel]
In-Reply-To: <Pine.LNX.4.64.0708161654000.2836@itasca2.wildberry.org>
References: <7098abec0708152232s6d9fbb2ewb76cfa2cd4d7b1b2@mail.gmail.com>
	<Pine.LNX.4.64.0708160742020.2550@itasca2.wildberry.org>
	<7098abec0708161253l4b437f37l380c529d1fd4c558@mail.gmail.com>
	<Pine.LNX.4.64.0708161525100.2836@itasca2.wildberry.org>
	<7098abec0708161334q269d41b0ob4d2398d6660c1b3@mail.gmail.com>
	<Pine.LNX.4.64.0708161654000.2836@itasca2.wildberry.org>
Message-ID: <7098abec0708161610l75e9616dg3054afd1c8ae9c4a@mail.gmail.com>

On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
> I think I understand the issue.  The methods code uses R_tryCatch
> internally in a few places, hoping I think for a C level variant of
> tryCatch.  It isn't meant to be used that way.  It is intended only
> for use in embedded contexts where there is no proper top level, or
> possibly in contexts where conceptually the evaluation is happening in
> a seperate thread of execution.  In particular R_tryEval establishes
> it's own top level (and that is the top level that is being jumped
> to):
>
> > { try(glue("A",B)); 2}
> Error: no function to return from, jumping to top level
> Error in glue("A", B) :
>    error in evaluating the argument 'b' in selecting a method for function 'glue'
> [1] 2
> >
>
> Because of the "internal" top level established by R_tryEval there is
> no way to jump from inside the eval to an outer context, which is what
> needs to happen for try() to work here.
>
> It looks like the intent in methods_list_dispatch.c in all but one
> case is to catch the error and report something a bit more meaningful;
> in the one other case, in R_nextMethodCall, there is also a cleanup
> action that occurs before resignaling the error.

Yes, there seems to be some new (and much appreciated) error reporting
that goes on in recent versions of R-devel that gives a stack trace of
method calls instead of telling us that ".local" has failed, which was
less useful.

>
> To fix this will I think require designing a C level tryCatch.  That
> will take a bit of time to get right.  Not sure if it will get done by
> 2.6.0.  There may be a quick temporary fix but I'm not seeing one at
> this point.
>
> Arguably R_tryEval in its present form should also ensure that the
> handler stacks are empty in the call (not an issue for the intended
> embedded usage).  Need to think about that a bit as well.

Ah, that's unfortunate. I guess I will have to back out that feature
for the time being.

>
> Best,
>
> luke
>
> On Thu, 16 Aug 2007, Byron Ellis wrote:
>
> > On 8/16/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
> >>
> >> There sae, at 2.5.0 I believe.  At that point try was reimplemented in
> >> terms of tryCatch.  That may have uncovered a bug in our code or
> >> yours, but without a reproducible example it's hard to say more.
> >
> > An indeed, I believe I've got one. Turns out it didn't solve my
> > problem though. So, imagine we have a method (with a new generic).
> > Say,
> >
> > setGeneric("glue",function(a,b) standardGeneric("glue"))
> > setMethod("glue",signature("character","character"),function(a,b) {
> >       paste(a,b,sep="")
> > })
> >
> > Trying the code:
> >
> >> glue("A","B")
> > [1] "AB"
> >> glue("A",B)
> > Error: object "B" not found
> > Error in glue("A", B) :
> >  error in evaluating the argument 'b' in selecting a method for function 'glue'
> >
> > Good. Works as expected (there's no B in the environment). However,
> > I'd expect try to work...
> >
> >>  try(glue("A",B))
> > Error: no function to return from, jumping to top level
> > Error in glue("A", B) :
> >  error in evaluating the argument 'b' in selecting a method for function 'glue'
> >
> > with silent=TRUE the "jumping to top level" is not caught and causes
> > scripts to bail out.
> >
> > Hopefully that helps?
> >
> >
> >>
> >> Best,
> >>
> >> luke
> >>
> >>
> >>>
> >>>>
> >>>> Best,
> >>>>
> >>>> luke
> >>>>
> >>>>
> >>>> --
> >>>> Luke Tierney
> >>>> Chair, Statistics and Actuarial Science
> >>>> Ralph E. Wareham Professor of Mathematical Sciences
> >>>> University of Iowa                  Phone:             319-335-3386
> >>>> Department of Statistics and        Fax:               319-335-3017
> >>>>     Actuarial Science
> >>>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> >>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> >>>>
> >>>
> >>>
> >>>
> >>
> >> --
> >> Luke Tierney
> >> Chair, Statistics and Actuarial Science
> >> Ralph E. Wareham Professor of Mathematical Sciences
> >> University of Iowa                  Phone:             319-335-3386
> >> Department of Statistics and        Fax:               319-335-3017
> >>     Actuarial Science
> >> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> >> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> >>
> >
> >
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From ggrothendieck at gmail.com  Fri Aug 17 16:53:59 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Aug 2007 10:53:59 -0400
Subject: [Rd] expand.grid fails on zero dims
Message-ID: <971536df0708170753n402385cbva2b59c5df59b53a6@mail.gmail.com>

expand.grid fails if any of the arguments are zero length:

> expand.grid(1:2, 1, seq_len(0))
Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
        invalid number of copies in rep.int()

I think it would be desirable if it output a data frame with zero rows.


From fparlamis at mac.com  Fri Aug 17 09:13:33 2007
From: fparlamis at mac.com (Franklin Parlamis)
Date: Fri, 17 Aug 2007 00:13:33 -0700
Subject: [Rd] Hedge Fund Job Opening
Message-ID: <24360A70-0114-1000-8B9A-2032CE42DC3B-Webmail-10010@mac.com>

Hi all.  

I've been lurking and posting on this list for a few years now.  Prior to that, I managed the US Convertible Arbitrage portfolio for Amaranth Advisors.  I recently agreed to manage a similar portfolio for a different hedge fund and am looking for someone to join me, essentially as the principal quant for a new San Francisco office.  I've been very impressed with the posters on this list and am hopeful that some of you will consider submitting your resume for the position.

The job announcement follows.

Franklin Parlamis

(My apologies for posting in both sig-finance and devel -- finance experience is not mandatory)

***

Statistician/Programmer Sought for San Francisco Hedge Fund Office.

Pine River Capital Management (with assets under management in excess of USD 750 million and offices in Minneapolis, London and Hong Kong) is seeking a Statistician/Programmer for its new San Francisco office.

You will be responsible for designing and programming modeling tools used in convertible and capital structure arbitrage.  You will also be responsible for analyzing market data to identify trade opportunities as well as promising hedging strategies.  You will work in a small office environment, on the trading desk and directly with the portfolio manager.

Ideally you will have a PhD in Statistics or a closely related discipline and significant experience with a statistical programming language such as S.  Other pluses include a background in Bayesian inference and experience with object-oriented programming.

In addition to base compensation, a performance bonus is anticipated to be paid out of book trading profits.

Candidates should please email their resumes to franklin.parlamis at pinerivercapital.com


From gunter.berton at gene.com  Fri Aug 17 20:03:44 2007
From: gunter.berton at gene.com (gunter.berton at gene.com)
Date: Fri, 17 Aug 2007 20:03:44 +0200 (CEST)
Subject: [Rd] match.arg bug or documentation error (PR#9859)
Message-ID: <20070817180344.D62D766884@slim.kubism.ku.dk>


There is either a bug or undocumented feature (afaics) in match.arg that
requires the length of  the arg argument to be no longer than the length of
the choices argument even when several.ok is TRUE. Here is a reproducible
example:

first:

> sessionInfo()
R version 2.5.0 Patched (2007-04-26 r41320) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grid"      "grDevices" "tcltk"     "utils"
"methods"   "base"     


## Now the example:

> x<- letters[1:3]
> y <- c('aa','bb')
> match.arg(x,y) ## error because several.ok = FALSE, but note warning
message.
Error in match.arg(x, y) : 'arg' should be one of aa, bb
In addition: Warning message:
longer object length
        is not a multiple of shorter object length in: arg == choices 

## So set several.ok=TRUE ... but there is still an error
> match.arg(x,y, several.ok = TRUE) 
Error in match.arg(x, y, several.ok = TRUE) : 
        'arg' should be one of aa, bb

## However, if x is of length 2, all is OK.
> x <- letters[1:2]
> match.arg(x,y, several.ok = TRUE) 
[1] "aa" "bb"


Bert Gunter
Genentech Nonclinical Statistics


From mcintosh at research.telcordia.com  Sat Aug 18 00:17:16 2007
From: mcintosh at research.telcordia.com (Allen McIntosh)
Date: Fri, 17 Aug 2007 18:17:16 -0400
Subject: [Rd] Overriding S4 methods in an installed package
Message-ID: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>

Is it possible to override S4 methods in an installed package?
The naive

library("pkg")
setMethod("foo", signature(obj = "bar"),
        function(obj , x, y) { new definition }
	, where="package:pkg")


results in the error

Error in setMethod("foo", signature(obj = "bar"), function(obj,  :
        the environment "pkg" is locked; cannot assign methods for function "foo"

(This is from R 2.5.1 on Fedora Core 5, if that matters)

Background:  A colleague claims to have found an error in a package.
He and I would prefer to do some experimentation before contacting
the authors.  Subclassing is the "correct" way to do this, and I
expect we will eventually subclass for other reasons, but I was
wondering if an override was possible and easier.


From sfalcon at fhcrc.org  Sat Aug 18 19:41:05 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 18 Aug 2007 10:41:05 -0700
Subject: [Rd] Overriding S4 methods in an installed package
In-Reply-To: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>
	(Allen McIntosh's message of "Fri\, 17 Aug 2007 18\:17\:16 -0400")
References: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>
Message-ID: <m28x88u4em.fsf@fhcrc.org>

Allen McIntosh <mcintosh at research.telcordia.com> writes:

> Is it possible to override S4 methods in an installed package?
> The naive
>
> library("pkg")
> setMethod("foo", signature(obj = "bar"),
>         function(obj , x, y) { new definition }
> 	, where="package:pkg")
>
>
> results in the error
>
> Error in setMethod("foo", signature(obj = "bar"), function(obj,  :
>         the environment "pkg" is locked; cannot assign methods for function "foo"
>
> (This is from R 2.5.1 on Fedora Core 5, if that matters)
>
> Background:  A colleague claims to have found an error in a package.
> He and I would prefer to do some experimentation before contacting
> the authors.  Subclassing is the "correct" way to do this, and I
> expect we will eventually subclass for other reasons, but I was
> wondering if an override was possible and easier.

If foo is a generic that you are calling directly, then you can
probably define it in the global environment (omit the where arg) and
test it that way.

OTOH, if foo is used by pkg internally, then it will be much easier to
simply edit the source for pkg, reinstall and test.  If you find and
fix a bug, most package maintainers will be quite happy to integrate
your fix.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From sfalcon at fhcrc.org  Sat Aug 18 21:21:00 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 18 Aug 2007 12:21:00 -0700
Subject: [Rd] [R] Suspected memory leak with R v.2.5.x and large
	matrices with dimnames set
In-Reply-To: <46C6968F.1010803@cs.nyu.edu> (Peter Waltman's message of "Sat\,
	18 Aug 2007 02\:49\:51 -0400")
References: <46C6968F.1010803@cs.nyu.edu>
Message-ID: <m24piwtzs3.fsf@fhcrc.org>

Hi Peter,

Peter Waltman <waltman at cs.nyu.edu> writes:
>    Admittedly,  this  may  not be the most sophisticated memory profiling
>    performed,  but  when using unix's top command, I'm noticing a notable
>    memory leak when using R with a large matrix that has dimnames
>    set.

I'm not sure I understand what you are reporting.  One thing to keep
in mind is that how memory released by R is handled is OS dependent
and one will often observe that after R frees some memory, the OS does
not report that amount as now free.

Is what you are observing preventing you from getting things done, or
just a concern that there is a leak that needs fixing?  It is worth
noting that the internal handling of character vectors has changed in
R-devel and so IMO testing there would make sense before persuing this
further, I suspect your results will be different.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From mcintosh at research.telcordia.com  Sat Aug 18 21:53:07 2007
From: mcintosh at research.telcordia.com (Allen McIntosh)
Date: Sat, 18 Aug 2007 15:53:07 -0400
Subject: [Rd] Overriding S4 methods in an installed package
In-Reply-To: <m28x88u4em.fsf@fhcrc.org>
References: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>
	<m28x88u4em.fsf@fhcrc.org>
Message-ID: <46C74E23.10408@research.telcordia.com>

Seth Falcon wrote:
> Allen McIntosh <mcintosh at research.telcordia.com> writes:
>> Is it possible to override S4 methods in an installed package?
>> The naive
>> library("pkg")
>> setMethod("foo", signature(obj = "bar"),
>>         function(obj , x, y) { new definition }
>> 	, where="package:pkg")
>> results in the error
>> Error in setMethod("foo", signature(obj = "bar"), function(obj,  :
>>         the environment "pkg" is locked; cannot assign methods for function "foo"
> 
> If foo is a generic that you are calling directly, then you can
> probably define it in the global environment (omit the where arg) and
> test it that way.
> 
> OTOH, if foo is used by pkg internally, then it will be much easier to
> simply edit the source for pkg, reinstall and test.  If you find and
> fix a bug, most package maintainers will be quite happy to integrate
> your fix.

Thanks for the suggestion.  Unfortunately, foo() uses internal 
functions.  When foo() is defined in the global environment, these are 
not visible.

I was hoping to avoid recompiling and installing under Windows.  Looks 
like I may not have a choice.


From murdoch at stats.uwo.ca  Sat Aug 18 22:02:58 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Aug 2007 16:02:58 -0400
Subject: [Rd] Overriding S4 methods in an installed package
In-Reply-To: <46C74E23.10408@research.telcordia.com>
References: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>	<m28x88u4em.fsf@fhcrc.org>
	<46C74E23.10408@research.telcordia.com>
Message-ID: <46C75072.3050101@stats.uwo.ca>

Allen McIntosh wrote:
> Seth Falcon wrote:
>   
>> Allen McIntosh <mcintosh at research.telcordia.com> writes:
>>     
>>> Is it possible to override S4 methods in an installed package?
>>> The naive
>>> library("pkg")
>>> setMethod("foo", signature(obj = "bar"),
>>>         function(obj , x, y) { new definition }
>>> 	, where="package:pkg")
>>> results in the error
>>> Error in setMethod("foo", signature(obj = "bar"), function(obj,  :
>>>         the environment "pkg" is locked; cannot assign methods for function "foo"
>>>       
>> If foo is a generic that you are calling directly, then you can
>> probably define it in the global environment (omit the where arg) and
>> test it that way.
>>
>> OTOH, if foo is used by pkg internally, then it will be much easier to
>> simply edit the source for pkg, reinstall and test.  If you find and
>> fix a bug, most package maintainers will be quite happy to integrate
>> your fix.
>>     
>
> Thanks for the suggestion.  Unfortunately, foo() uses internal 
> functions.  When foo() is defined in the global environment, these are 
> not visible.
>   
I think you can set the environment of your method to see the package 
internals.  Those internals won't see your method, though.

To do this, you'd do something like

newfoo <- function(obj , x, y) { new definition }
environment(newfoo) <- environment(foo) # or some other function from 
the package

setMethod("foo", signature(obj = "bar"),
        newfoo)


> I was hoping to avoid recompiling and installing under Windows.  Looks 
> like I may not have a choice.
>   
This is getting easier:  we're down to a single install, as long as you 
don't need all possible formats of man pages.

Duncan Murdoch
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From luke at stat.uiowa.edu  Sun Aug 19 00:00:08 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sat, 18 Aug 2007 17:00:08 -0500 (CDT)
Subject: [Rd] [R] Suspected memory leak with R v.2.5.x and large
 matrices with dimnames set
In-Reply-To: <46C7610A.1030609@cs.nyu.edu>
References: <46C6968F.1010803@cs.nyu.edu> <m24piwtzs3.fsf@fhcrc.org>
	<46C7610A.1030609@cs.nyu.edu>
Message-ID: <Pine.OSX.4.61.0708181644590.5027@luke-tierneys-computer-3.local>

Seth's analysis is correct.  R does return what it can to the malloc
system by calling free.  When and how much memory malloc releases back
to the OS varies with OS and malloc system and also depends on the
sizes of allocations. R curently allocates its memory for small
objects in pages of about 2K.  On Mac OS X if that is increased to
about 16K then much more is returned to the OS. On Linux (Fedora 7 on
i386 at least) the amount would have to be pushed up to around 2M to
make a difference. Increasing page size reduces R's ability to release
pages, so an increase to that level would probably not be a good idea.

Whether or not malloc releases memory back to the OS shouldn't make
much difference to a single R process; it might come into play if you
are trying to run multiple memory-intensive pocesses on the same
machine, though even that may vary among OS/malloc systems.

The changes Seth mentiones are not likely to help in this case. They
are primarily intended to improve performance when there are many
non-unique character vectors; there is additional overhead for many
unique vectors, which we will try to reduce over time.

Best,

luke

On Sat, 18 Aug 2007, Peter Waltman wrote:

> Hi Seth -
>
> Thanks for the follow up.  I'll definitely check out the devel version
> at some point since while I've come up with a workaround, this is
> causing problems for me as it uses up so much memory on some systems
> that R starts throwing malloc errors and has to be killed from the
> command line.  The machine I'm thinking of in particular is a MacOS
> machine with 8 gigs of memory.
>
> Also, having the row and column names set to alphanumeric names causes
> the processing to slow down significantly - as much as by a power of 10
> (or more).
>
> As for you speculation that the memory released by R may not be
> recognized as being free'd by the OS, as a further test, I re-ran my
> code snippet three consecutive times w/in the same R interpreter
> window.  In theory, if there were a memory leak, after the first run
> (resulting in a memory stamp of 2 gig), the subsequent runs would
> further increase R's memory stamp, i.e. up to 4 after the second, and 6
> for the 3rd.
>
> This didn't happen, and R's stamp remained at 2 gig, so I can only
> assume that you're correct and I was wrong about a leak.
>
> Still, it's quite the memory hog when using dimnames, so I'll have to
> avoid those for now and will try the devel version you mentioned.
>
> Thanks and have a good weekend,
>
> Peter
>
> Seth Falcon wrote:
>> Hi Peter,
>>
>> Peter Waltman <waltman at cs.nyu.edu> writes:
>>
>>>    Admittedly,  this  may  not be the most sophisticated memory profiling
>>>    performed,  but  when using unix's top command, I'm noticing a notable
>>>    memory leak when using R with a large matrix that has dimnames
>>>    set.
>>>
>>
>> I'm not sure I understand what you are reporting.  One thing to keep
>> in mind is that how memory released by R is handled is OS dependent
>> and one will often observe that after R frees some memory, the OS does
>> not report that amount as now free.
>>
>> Is what you are observing preventing you from getting things done, or
>> just a concern that there is a leak that needs fixing?  It is worth
>> noting that the internal handling of character vectors has changed in
>> R-devel and so IMO testing there would make sense before persuing this
>> further, I suspect your results will be different.
>>
>> + seth
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From mcintosh at research.telcordia.com  Sun Aug 19 03:12:32 2007
From: mcintosh at research.telcordia.com (Allen McIntosh)
Date: Sat, 18 Aug 2007 21:12:32 -0400
Subject: [Rd] Overriding S4 methods in an installed package
In-Reply-To: <46C75072.3050101@stats.uwo.ca>
References: <200708172217.l7HMHG6a025509@mcintosh.research.telcordia.com>	<m28x88u4em.fsf@fhcrc.org>
	<46C74E23.10408@research.telcordia.com>
	<46C75072.3050101@stats.uwo.ca>
Message-ID: <46C79900.6000402@research.telcordia.com>

Duncan Murdoch wrote:
> I think you can set the environment of your method to see the package 
> internals.  Those internals won't see your method, though.
> 
> To do this, you'd do something like
> 
> newfoo <- function(obj , x, y) { new definition }
> environment(newfoo) <- environment(foo) # or some other function from 
> the package
> 
> setMethod("foo", signature(obj = "bar"),
>        newfoo)

That did it.  Thank you.


From ripley at stats.ox.ac.uk  Sun Aug 19 18:08:13 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sun, 19 Aug 2007 18:08:13 +0200 (CEST)
Subject: [Rd] available.packages (PR#9841)
Message-ID: <20070819160813.A8FC56688D@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-75857366-1187539630=:10054
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 8BIT

The documented specification is file:///d:/CRAN (as specified by RFC1738), 
so this is working correctly.

The CHANGES file for 2.2.0 says:

     o   file:// URLs are now interpreted by download.file(),
         download.packages() and url() in the same way as Mozilla-based
         browsers.  That is, the expected form is

                 file:///d:/path/to/file

         with *three* slashes.

The point is that this is file:// + host + / + path/to/file, and host is 
missing.  That some versions of IE did not follow the standard is part of 
the confusion here.

Note that ?available.packages does say

      If a repository is
      local, i.e., the URL starts with '"file:"', then the packages are
      not downloaded but used directly.  (Both '"file:"' and
      '"file:///"' are allowed as prefixes to a file path, the latter
      for an absolute file path.)

but 'file:' does not work with drives on Windows.  That seems clearly to 
rule out your usage.


On Fri, 10 Aug 2007, zivan.karaman at gmail.com wrote:

> Full_Name: Zivan Karaman
> Version: 2.5.1
> OS: Windows XP SP2
> Submission from: (NULL) (195.6.68.214)
>
>
> I think that I have encountered a bug in the function "available.packages" when
> using a local repository (file://
) on Windows.
>
> Version information:
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.1
> year           2007
> month          06
> day            27
> svn rev        42083
> language       R
> version.string R version 2.5.1 (2007-06-27)
>
> I have made a copy of the CRAN "/bin/windows/contrib/2.5" directory in the
> "D:/CRAN" folder on my machine.
>
> When I issue the command:
>
> available.packages(contrib.url("file://D:/CRAN"))
>
> I get the follwoing message:
> Error in gzfile(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open compressed file ':/CRAN/bin/windows/contrib/2.5/PACKAGES' in:
> gzfile(file, "r")
>
> Looking at the source code, I've spotted the following lines which seem to cause
> trouble:
>
>            if (.Platform$OS.type == "windows") {
>                if (length(grep("[A-Za-z]:", tmpf)))
>                  tmpf <- substring(tmpf, 2)
>            }
> Deleting them, the function works OK.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-75857366-1187539630=:10054--


From h.wickham at gmail.com  Sun Aug 19 20:00:33 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 19 Aug 2007 13:00:33 -0500
Subject: [Rd] Installing dependent packages
Message-ID: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>

Hi all,

When installing ggplot2 on with install.packages("ggplot2", dep = T),
the colorspace dependency doesn't get installed (see below for
transcript from R session).  The relevant lines from my description
file are:

Depends: R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, MASS,
RColorBrewer, colorspace
Suggests: quantreg, Hmisc, mapproj, maps

Have I done something wrong? Or is this a bug in the installation of
dependent packages?

Thanks,

Hadley


> install.packages("ggplot2", dep = T)
also installing the dependencies 'XML', 'RBGL', 'graph', 'chron',
'acepack', 'proto', 'Hmisc'

trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/XML_1.9-0.tgz'
Content type 'application/x-gzip' length 1108754 bytes
opened URL
==================================================
downloaded 1082Kb

trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/RBGL_1.12.0.tgz
'
Content type 'application/x-gzip' length 4577430 bytes
opened URL
==================================================
downloaded 4470Kb

trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/graph_1.14.2.tgz'
Content type 'application/x-gzip' length 494951 bytes
opened URL
==================================================
downloaded 483Kb

trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/chron_2.3-14.tgz'
Content type 'application/x-gzip' length 72595 bytes
opened URL
==================================================
downloaded 70Kb

trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/acepack_1.3-2.2.tgz
'
Content type 'application/x-gzip' length 67871 bytes
opened URL
==================================================
downloaded 66Kb

trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/proto_0.3-7.tgz'
Content type 'application/x-gzip' length 958493 bytes
opened URL
==================================================
downloaded 936Kb

trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/Hmisc_3.4-2.tgz'
Content type 'application/x-gzip' length 1475177 bytes
opened URL
==================================================
downloaded 1440Kb

trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/ggplot2_0.5.4.tgz
'
Content type 'application/x-gzip' length 1928720 bytes
opened URL
==================================================
downloaded 1883Kb


The downloaded packages are in
    /tmp/RtmpWRuZcd/downloaded_packages
Warning message:
dependency 'Rgraphviz' is not available
> library(ggplot2)
Loading required package: proto
Loading required package: splines
Loading required package: MASS
Loading required package: colorspace
Error: package 'colorspace' could not be loaded
In addition: Warning message:
there is no package called 'colorspace' in: library(pkg,
character.only = TRUE, logical = TRUE, lib.loc = lib.loc)



-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Sun Aug 19 20:35:43 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Aug 2007 19:35:43 +0100 (BST)
Subject: [Rd] Installing dependent packages
In-Reply-To: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>
References: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708191930170.15538@gannet.stats.ox.ac.uk>

On Sun, 19 Aug 2007, hadley wickham wrote:

> Hi all,
>
> When installing ggplot2 on with install.packages("ggplot2", dep = T),
> the colorspace dependency doesn't get installed (see below for
> transcript from R session).  The relevant lines from my description
> file are:
>
> Depends: R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, MASS,
> RColorBrewer, colorspace
> Suggests: quantreg, Hmisc, mapproj, maps
>
> Have I done something wrong? Or is this a bug in the installation of
> dependent packages?

You need to start continuation lines with whitespace, but possibly your 
mailer wrapped this. (For readability I would wrap it in the DESCRIPTION 
file.)

I tried in a vanilla session on Linux and colorspace was installed.  Was 
this a vanilla session?  Does it work with type="source"?

It would be helpful if you could debug this as probably no one else can: 
the code has been in use for a long time without any reported problems.

>
> Thanks,
>
> Hadley
>
>
>> install.packages("ggplot2", dep = T)
> also installing the dependencies 'XML', 'RBGL', 'graph', 'chron',
> 'acepack', 'proto', 'Hmisc'
>
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/XML_1.9-0.tgz'
> Content type 'application/x-gzip' length 1108754 bytes
> opened URL
> ==================================================
> downloaded 1082Kb
>
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/RBGL_1.12.0.tgz
> '
> Content type 'application/x-gzip' length 4577430 bytes
> opened URL
> ==================================================
> downloaded 4470Kb
>
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/graph_1.14.2.tgz'
> Content type 'application/x-gzip' length 494951 bytes
> opened URL
> ==================================================
> downloaded 483Kb
>
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/chron_2.3-14.tgz'
> Content type 'application/x-gzip' length 72595 bytes
> opened URL
> ==================================================
> downloaded 70Kb
>
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/acepack_1.3-2.2.tgz
> '
> Content type 'application/x-gzip' length 67871 bytes
> opened URL
> ==================================================
> downloaded 66Kb
>
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/proto_0.3-7.tgz'
> Content type 'application/x-gzip' length 958493 bytes
> opened URL
> ==================================================
> downloaded 936Kb
>
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/Hmisc_3.4-2.tgz'
> Content type 'application/x-gzip' length 1475177 bytes
> opened URL
> ==================================================
> downloaded 1440Kb
>
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/ggplot2_0.5.4.tgz
> '
> Content type 'application/x-gzip' length 1928720 bytes
> opened URL
> ==================================================
> downloaded 1883Kb
>
>
> The downloaded packages are in
>    /tmp/RtmpWRuZcd/downloaded_packages
> Warning message:
> dependency 'Rgraphviz' is not available
>> library(ggplot2)
> Loading required package: proto
> Loading required package: splines
> Loading required package: MASS
> Loading required package: colorspace
> Error: package 'colorspace' could not be loaded
> In addition: Warning message:
> there is no package called 'colorspace' in: library(pkg,
> character.only = TRUE, logical = TRUE, lib.loc = lib.loc)
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sun Aug 19 20:37:46 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 19 Aug 2007 14:37:46 -0400
Subject: [Rd] Installing dependent packages
In-Reply-To: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>
References: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>
Message-ID: <46C88DFA.7010100@stats.uwo.ca>

On 19/08/2007 2:00 PM, hadley wickham wrote:
> Hi all,
> 
> When installing ggplot2 on with install.packages("ggplot2", dep = T),
> the colorspace dependency doesn't get installed (see below for
> transcript from R session).  The relevant lines from my description
> file are:
> 
> Depends: R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, MASS,
> RColorBrewer, colorspace
> Suggests: quantreg, Hmisc, mapproj, maps
> 
> Have I done something wrong? Or is this a bug in the installation of
> dependent packages?

I see the same problem in MacOSX, but not in Windows.  If I try it with 
none of the dependencies installed, only reshape and proto are added but 
there's a warning about grid, splines and MASS, so I'd guess this is a 
bug related to the fact that RColorBrewer and colorspace are on the 
second line, and there's another bug related to the fact that the others 
are recommended packages.

Duncan Murdoch

> 
> Thanks,
> 
> Hadley
> 
> 
>> install.packages("ggplot2", dep = T)
> also installing the dependencies 'XML', 'RBGL', 'graph', 'chron',
> 'acepack', 'proto', 'Hmisc'
> 
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/XML_1.9-0.tgz'
> Content type 'application/x-gzip' length 1108754 bytes
> opened URL
> ==================================================
> downloaded 1082Kb
> 
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/RBGL_1.12.0.tgz
> '
> Content type 'application/x-gzip' length 4577430 bytes
> opened URL
> ==================================================
> downloaded 4470Kb
> 
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/graph_1.14.2.tgz'
> Content type 'application/x-gzip' length 494951 bytes
> opened URL
> ==================================================
> downloaded 483Kb
> 
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/chron_2.3-14.tgz'
> Content type 'application/x-gzip' length 72595 bytes
> opened URL
> ==================================================
> downloaded 70Kb
> 
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/acepack_1.3-2.2.tgz
> '
> Content type 'application/x-gzip' length 67871 bytes
> opened URL
> ==================================================
> downloaded 66Kb
> 
> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/proto_0.3-7.tgz'
> Content type 'application/x-gzip' length 958493 bytes
> opened URL
> ==================================================
> downloaded 936Kb
> 
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/Hmisc_3.4-2.tgz'
> Content type 'application/x-gzip' length 1475177 bytes
> opened URL
> ==================================================
> downloaded 1440Kb
> 
> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/ggplot2_0.5.4.tgz
> '
> Content type 'application/x-gzip' length 1928720 bytes
> opened URL
> ==================================================
> downloaded 1883Kb
> 
> 
> The downloaded packages are in
>     /tmp/RtmpWRuZcd/downloaded_packages
> Warning message:
> dependency 'Rgraphviz' is not available
>> library(ggplot2)
> Loading required package: proto
> Loading required package: splines
> Loading required package: MASS
> Loading required package: colorspace
> Error: package 'colorspace' could not be loaded
> In addition: Warning message:
> there is no package called 'colorspace' in: library(pkg,
> character.only = TRUE, logical = TRUE, lib.loc = lib.loc)
> 
> 
>


From murdoch at stats.uwo.ca  Sun Aug 19 23:31:10 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 19 Aug 2007 17:31:10 -0400
Subject: [Rd] Installing dependent packages
In-Reply-To: <Pine.LNX.4.64.0708191930170.15538@gannet.stats.ox.ac.uk>
References: <f8e6ff050708191100k35d61913ka2dee3dba58da76d@mail.gmail.com>
	<Pine.LNX.4.64.0708191930170.15538@gannet.stats.ox.ac.uk>
Message-ID: <46C8B69E.8060809@stats.uwo.ca>

On 19/08/2007 2:35 PM, Prof Brian Ripley wrote:
> On Sun, 19 Aug 2007, hadley wickham wrote:
> 
>> Hi all,
>>
>> When installing ggplot2 on with install.packages("ggplot2", dep = T),
>> the colorspace dependency doesn't get installed (see below for
>> transcript from R session).  The relevant lines from my description
>> file are:
>>
>> Depends: R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, MASS,
>> RColorBrewer, colorspace
>> Suggests: quantreg, Hmisc, mapproj, maps
>>
>> Have I done something wrong? Or is this a bug in the installation of
>> dependent packages?
> 
> You need to start continuation lines with whitespace, but possibly your 
> mailer wrapped this. (For readability I would wrap it in the DESCRIPTION 
> file.)
> 
> I tried in a vanilla session on Linux and colorspace was installed.  Was 
> this a vanilla session?  Does it work with type="source"?
> 
> It would be helpful if you could debug this as probably no one else can: 
> the code has been in use for a long time without any reported problems.

It seems to be a problem with CRAN:

 > 
available.packages("http://cran.r-project.org/bin/macosx/universal/contrib/2.5")["ggplot2","Depends"]
[1] "R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, MASS,"
 > 
available.packages("http://cran.r-project.org/bin/windows/contrib/2.5")["ggplot2","Depends"]
[1] "R (>= 2.4), grid, reshape (>= 0.8.0), proto, splines, 
MASS,\nRColorBrewer, colorspace"

Duncan Murdoch
> 
>> Thanks,
>>
>> Hadley
>>
>>
>>> install.packages("ggplot2", dep = T)
>> also installing the dependencies 'XML', 'RBGL', 'graph', 'chron',
>> 'acepack', 'proto', 'Hmisc'
>>
>> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/XML_1.9-0.tgz'
>> Content type 'application/x-gzip' length 1108754 bytes
>> opened URL
>> ==================================================
>> downloaded 1082Kb
>>
>> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/RBGL_1.12.0.tgz
>> '
>> Content type 'application/x-gzip' length 4577430 bytes
>> opened URL
>> ==================================================
>> downloaded 4470Kb
>>
>> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/graph_1.14.2.tgz'
>> Content type 'application/x-gzip' length 494951 bytes
>> opened URL
>> ==================================================
>> downloaded 483Kb
>>
>> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/chron_2.3-14.tgz'
>> Content type 'application/x-gzip' length 72595 bytes
>> opened URL
>> ==================================================
>> downloaded 70Kb
>>
>> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/acepack_1.3-2.2.tgz
>> '
>> Content type 'application/x-gzip' length 67871 bytes
>> opened URL
>> ==================================================
>> downloaded 66Kb
>>
>> trying URL ' http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/proto_0.3-7.tgz'
>> Content type 'application/x-gzip' length 958493 bytes
>> opened URL
>> ==================================================
>> downloaded 936Kb
>>
>> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/Hmisc_3.4-2.tgz'
>> Content type 'application/x-gzip' length 1475177 bytes
>> opened URL
>> ==================================================
>> downloaded 1440Kb
>>
>> trying URL 'http://cran.uk.r-project.org/bin/macosx/universal/contrib/2.5/ggplot2_0.5.4.tgz
>> '
>> Content type 'application/x-gzip' length 1928720 bytes
>> opened URL
>> ==================================================
>> downloaded 1883Kb
>>
>>
>> The downloaded packages are in
>>    /tmp/RtmpWRuZcd/downloaded_packages
>> Warning message:
>> dependency 'Rgraphviz' is not available
>>> library(ggplot2)
>> Loading required package: proto
>> Loading required package: splines
>> Loading required package: MASS
>> Loading required package: colorspace
>> Error: package 'colorspace' could not be loaded
>> In addition: Warning message:
>> there is no package called 'colorspace' in: library(pkg,
>> character.only = TRUE, logical = TRUE, lib.loc = lib.loc)
>>
>>
>>
>>
>


From waltman at cs.nyu.edu  Sat Aug 18 23:13:46 2007
From: waltman at cs.nyu.edu (Peter Waltman)
Date: Sat, 18 Aug 2007 17:13:46 -0400
Subject: [Rd] [R] Suspected memory leak with R v.2.5.x and large
 matrices with dimnames set
In-Reply-To: <m24piwtzs3.fsf@fhcrc.org>
References: <46C6968F.1010803@cs.nyu.edu> <m24piwtzs3.fsf@fhcrc.org>
Message-ID: <46C7610A.1030609@cs.nyu.edu>

Hi Seth -

Thanks for the follow up.  I'll definitely check out the devel version 
at some point since while I've come up with a workaround, this is 
causing problems for me as it uses up so much memory on some systems 
that R starts throwing malloc errors and has to be killed from the 
command line.  The machine I'm thinking of in particular is a MacOS 
machine with 8 gigs of memory.

Also, having the row and column names set to alphanumeric names causes 
the processing to slow down significantly - as much as by a power of 10 
(or more).

As for you speculation that the memory released by R may not be 
recognized as being free'd by the OS, as a further test, I re-ran my 
code snippet three consecutive times w/in the same R interpreter 
window.  In theory, if there were a memory leak, after the first run 
(resulting in a memory stamp of 2 gig), the subsequent runs would 
further increase R's memory stamp, i.e. up to 4 after the second, and 6 
for the 3rd.

This didn't happen, and R's stamp remained at 2 gig, so I can only 
assume that you're correct and I was wrong about a leak. 

Still, it's quite the memory hog when using dimnames, so I'll have to 
avoid those for now and will try the devel version you mentioned.

Thanks and have a good weekend,

Peter

Seth Falcon wrote:
> Hi Peter,
>
> Peter Waltman <waltman at cs.nyu.edu> writes:
>   
>>    Admittedly,  this  may  not be the most sophisticated memory profiling
>>    performed,  but  when using unix's top command, I'm noticing a notable
>>    memory leak when using R with a large matrix that has dimnames
>>    set.
>>     
>
> I'm not sure I understand what you are reporting.  One thing to keep
> in mind is that how memory released by R is handled is OS dependent
> and one will often observe that after R frees some memory, the OS does
> not report that amount as now free.
>
> Is what you are observing preventing you from getting things done, or
> just a concern that there is a leak that needs fixing?  It is worth
> noting that the internal handling of character vectors has changed in
> R-devel and so IMO testing there would make sense before persuing this
> further, I suspect your results will be different.
>
> + seth
>
>


From towil at var.fgov.be  Mon Aug 20 11:19:10 2007
From: towil at var.fgov.be (towil at var.fgov.be)
Date: Mon, 20 Aug 2007 11:19:10 +0200 (CEST)
Subject: [Rd] Assertion failure in -[RDeviceView lockFocus] (PR#9867)
Message-ID: <20070820091910.C596B5D5DD@slim.kubism.ku.dk>

Full_Name: tom willems
Version: Version: R 2.5.1 (42083) R.app R 2.5.1 GUI 1.20 (4535)/i386
OS: os x
Submission from: (NULL) (193.190.114.253)


bug report

I am not very familiar with system bug's, so forgive me if i write a wrong
report.
what happend was that R stopped working while ploting a logistic regression
model.
i noticed that it does not know the comand win.graph(), perhapes it has
something to do with that?

here is sthe system message

>plot(c(0,3), c(0,1),type="n", main= titel3,xlab = "Log x", ylab =
"Probability")
2007-08-14 23:14:12.621 R[144] *** Assertion failure in -[RDeviceView
lockFocus], AppKit.subproj/NSView.m:3248
2007-08-14 23:14:12.621 R[144] *** REngine.runREPL: caught ObjC exception in the
main loop!
*** Please report the following error on r-sig-mac at r-project.org along with the
full description of how to reproduce it:
*** reason: lockFocus sent to a view whose window is deferred and does not yet
have a corresponding platform window
*** name: NSInternalInconsistencyException, info: (null)
*** Version: R 2.5.1 (42083) R.app R 2.5.1 GUI 1.20 (4535)/i386
Consider saving your work soon in case this problem leads to a full crash.


From joehl at web.de  Mon Aug 20 15:44:20 2007
From: joehl at web.de (joehl at web.de)
Date: Mon, 20 Aug 2007 15:44:20 +0200 (CEST)
Subject: [Rd] system() fails with fc.exe (PR#9868)
Message-ID: <20070820134420.D824566890@slim.kubism.ku.dk>

Full_Name: Jens Oehlschl?gel
Version:  2.5.1
OS: Windows
Submission from: (NULL) (62.159.183.42)


Even when specifying the full path, the output of fc is not sent to R (neither
shown nor returned). For example

> system('c:\\WINDOWS\\system32\\fc.exe /?',intern=TRUE)
character(0)

When I do the same from python 2.3, I get

>>> import os
>>> os.system("c:\\WINDOWS\\system32\\fc /?")
Compares two files or sets of files and displays the differences between
them

FC [/A] [/C] [/L] [/LBn] [/N] [/OFF[LINE]] [/T] [/U] [/W] [/nnnn]
   [drive1:][path1]filename1 [drive2:][path2]filename2
FC /B [drive1:][path1]filename1 [drive2:][path2]filename2

  /A         Displays only first and last lines for each set of differences.
  /B         Performs a binary comparison.
  /C         Disregards the case of letters.
  /L         Compares files as ASCII text.
  /LBn       Sets the maximum consecutive mismatches to the specified
             number of lines.
  /N         Displays the line numbers on an ASCII comparison.
  /OFF[LINE] Do not skip files with offline attribute set.
  /T         Does not expand tabs to spaces.
  /U         Compare files as UNICODE text files.
  /W         Compresses white space (tabs and spaces) for comparison.
  /nnnn      Specifies the number of consecutive lines that must match
             after a mismatch.
  [drive1:][path1]filename1
             Specifies the first file or set of files to compare.
  [drive2:][path2]filename2
             Specifies the second file or set of files to compare.

-1


> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.1                         
year           2007                        
month          06                          
day            27                          
svn rev        42083                       
language       R                           
version.string R version 2.5.1 (2007-06-27)


From ripley at stats.ox.ac.uk  Mon Aug 20 22:18:37 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 20 Aug 2007 22:18:37 +0200 (CEST)
Subject: [Rd] system() fails with fc.exe (PR#9868)
Message-ID: <20070820201837.C761C6688F@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1509585398-1187640973=:22199
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 8BIT

Try rterm, where this works (and presumably python is also a command-line 
application).


On Mon, 20 Aug 2007, joehl at web.de wrote:

> Full_Name: Jens Oehlschl?gel
> Version:  2.5.1
> OS: Windows
> Submission from: (NULL) (62.159.183.42)
>
>
> Even when specifying the full path, the output of fc is not sent to R (neither
> shown nor returned). For example
>
>> system('c:\\WINDOWS\\system32\\fc.exe /?',intern=TRUE)
> character(0)
>
> When I do the same from python 2.3, I get
>
>>>> import os
>>>> os.system("c:\\WINDOWS\\system32\\fc /?")
> Compares two files or sets of files and displays the differences between
> them
>
> FC [/A] [/C] [/L] [/LBn] [/N] [/OFF[LINE]] [/T] [/U] [/W] [/nnnn]
>   [drive1:][path1]filename1 [drive2:][path2]filename2
> FC /B [drive1:][path1]filename1 [drive2:][path2]filename2
>
>  /A         Displays only first and last lines for each set of differences.
>  /B         Performs a binary comparison.
>  /C         Disregards the case of letters.
>  /L         Compares files as ASCII text.
>  /LBn       Sets the maximum consecutive mismatches to the specified
>             number of lines.
>  /N         Displays the line numbers on an ASCII comparison.
>  /OFF[LINE] Do not skip files with offline attribute set.
>  /T         Does not expand tabs to spaces.
>  /U         Compare files as UNICODE text files.
>  /W         Compresses white space (tabs and spaces) for comparison.
>  /nnnn      Specifies the number of consecutive lines that must match
>             after a mismatch.
>  [drive1:][path1]filename1
>             Specifies the first file or set of files to compare.
>  [drive2:][path2]filename2
>             Specifies the second file or set of files to compare.
>
> -1
>
>
>> version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.1
> year           2007
> month          06
> day            27
> svn rev        42083
> language       R
> version.string R version 2.5.1 (2007-06-27)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1509585398-1187640973=:22199--


From stvjc at channing.harvard.edu  Tue Aug 21 05:49:22 2007
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Mon, 20 Aug 2007 23:49:22 -0400 (EDT)
Subject: [Rd] aesthetics of do.call
Message-ID: <Pine.GSO.4.58.0708202348040.26109@capecod.bwh.harvard.edu>



library(MASS)
G1 = glm(sp~CW, data=crabs, fam=binomial)
G2 = do.call("glm", list(sp~CW, family=binomial, data=crabs))

G1$call is very nice to look at
G2$call is very voluminous

if we revise do.call to

function (what, args, quote = FALSE, envir = parent.frame())
{
    if (!is.list(args))
        stop("second argument must be a list")
    if (quote) {
        enquote <- function(x) as.call(list(as.name("quote"),
            x))
        args <- lapply(args, enquote)
    }
    ans = .Internal(do.call(what, args, envir))
    ans$call = match.call()
    ans
}

G1 and G2 look a lot more alike

> version
               _
platform       powerpc-apple-darwin8.9.0
arch           powerpc
os             darwin8.9.0
system         powerpc, darwin8.9.0
status         Under development (unstable)
major          2
minor          6.0
year           2007
month          06
day            05
svn rev        41826
language       R
version.string R version 2.6.0 Under development (unstable) (2007-06-05 r41826)


---
Vince Carey, PhD
Assoc. Prof Med (Biostatistics)
Harvard Medical School
Channing Laboratory - ph 6175252265 fa 6177311541
181 Longwood Ave Boston MA 02115 USA
stvjc at channing.harvard.edu


From Robert.Denham at nrw.qld.gov.au  Tue Aug 21 06:30:21 2007
From: Robert.Denham at nrw.qld.gov.au (Denham Robert)
Date: Tue, 21 Aug 2007 14:30:21 +1000
Subject: [Rd] compiling R under cygwin
Message-ID: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>

For various reasons, it suits our workplace to have a cygwin version of
R.  I am pretty sure that cygwin is still not a supported environment
for R, but we have managed to compile R-2.5.1 under cygwin without too
many dramas.  Our procedure is described below.  We still have a few
problems compiling libraries without manually changing files from .so to
.dll, but it seems ok.
 
I was wondering whether this information is likely to be useful to
others, and if we should spend any time looking in to ways in which the
configure/build/install code could be modified to allow a standard
install.
 
Notes on building R under cygwin:
 
export FFLAGS=-O3
export CFLAGS=-O3
export CXXFLAGS=-O3
export OBJCFLAGS=-O3
export FCFLAGS=-O3
export LDFLAGS='-lblas -lg2c -lintl'
 
export R_OSTYPE=unix
 
./configure --prefix=/opt/freeware/R/R-2.5.1 \
--with-tcl-config=/usr/lib/tclConfig.sh \
--with-tk-config=/usr/lib/tkConfig.sh \
--with-blas=-lblas \
--with-lapack=-llapack \
--enable-R-shlib
 
comment out Win32 in src/include/config.h and set Unix to 1, change .so
to .dll. change .so to .dll and in Makeconf.
in src/extra/xdr/rpc/types.h comment out defn of malloc.
 
Change .so to .dll in Makefile's
 
edit Makeconf and set R_OSTYPE to unix
 
make -j2
 
when blas doesn't link, re-run command with -lblas -lg2c on end and
change output to .dll
 
edit Rstrptime.c and change wcstod to atof.
 
in modules:
when X11 and internet falls over add -lintl to link line. add -lg2c and
-lblas to lapack
 
comment out library/base/R/library.R lines 47-51 to avoid arch check
which seems to go wrong!
 
make -j2
make install
 
edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl -lg2c
-lblas' to the end of ALL_LIBS
so the module building works. Change .so to .dll also
(can't see how to to this for the build tho...)
 

Our cygwin info is:
             sysname              release              version 
     "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22" 


 
 
Robert Denham
Environmental Statistician
Remote Sensing Centre
Telephone 07 3896 9899 
www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/> 
 
Department of Natural Resources & Water
QScape Building, 80 Meiers Road, Indooroopilly Qld 4068

************************************************************************
The information in this email together with any attachments is
intended only for the person or entity to which it is addressed
and may contain confidential and/or privileged material.
Any form of review, disclosure, modification, distribution
and/or publication of this email message is prohibited, unless
as a necessary part of Departmental business.
If you have received this message in error, you are asked to
inform the sender as quickly as possible and delete this message
and any copies of this message from your computer and/or your
computer system network.


From deepayan.sarkar at gmail.com  Tue Aug 21 07:20:33 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Mon, 20 Aug 2007 22:20:33 -0700
Subject: [Rd] aesthetics of do.call
In-Reply-To: <Pine.GSO.4.58.0708202348040.26109@capecod.bwh.harvard.edu>
References: <Pine.GSO.4.58.0708202348040.26109@capecod.bwh.harvard.edu>
Message-ID: <eb555e660708202220k2cce4d05y416998945d7659da@mail.gmail.com>

On 8/20/07, Vincent Carey 525-2265 <stvjc at channing.harvard.edu> wrote:
>
>
> library(MASS)
> G1 = glm(sp~CW, data=crabs, fam=binomial)
> G2 = do.call("glm", list(sp~CW, family=binomial, data=crabs))
>
> G1$call is very nice to look at
> G2$call is very voluminous
>
> if we revise do.call to
>
> function (what, args, quote = FALSE, envir = parent.frame())
> {
>     if (!is.list(args))
>         stop("second argument must be a list")
>     if (quote) {
>         enquote <- function(x) as.call(list(as.name("quote"),
>             x))
>         args <- lapply(args, enquote)
>     }
>     ans = .Internal(do.call(what, args, envir))
>     ans$call = match.call()
>     ans
> }
>
> G1 and G2 look a lot more alike

But then you get things like

> do.call(c, list(1, 2, 3))
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

$call
do.call2(what = c, args = list(1, 2, 3))

Warning message:
In ans$call = match.call() : Coercing LHS to a list

which is probably not what you want to happen.

-Deepayan


From murdoch at stats.uwo.ca  Tue Aug 21 12:52:56 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Aug 2007 06:52:56 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>
Message-ID: <46CAC408.4080105@stats.uwo.ca>

Denham Robert wrote:
> For various reasons, it suits our workplace to have a cygwin version of
> R.  I am pretty sure that cygwin is still not a supported environment
> for R, but we have managed to compile R-2.5.1 under cygwin without too
> many dramas.  Our procedure is described below.  We still have a few
> problems compiling libraries without manually changing files from .so to
> .dll, but it seems ok.
>   
I would expect other subtle problems as well, because Cygwin is not a 
normal Unix.  I don't know whether any of these differences matter to R, 
but some things to look out for are:

 - you can't unlink a file while it is open
 - filenames are not case sensitive
 - file permissions have strange defaults (everything is executable)
 - I think the executable format still needs to be Windows format
 - There's no such thing as a ptty
 - You'll probably need X11 for graphics, and will lose support for 
Windows metafile output (wmf)
>  
> I was wondering whether this information is likely to be useful to
> others, and if we should spend any time looking in to ways in which the
> configure/build/install code could be modified to allow a standard
> install.
>   
What is the advantage of building this?  I don't think we want to 
support platforms just for the sake of supporting more platforms, but if 
there's a real need for it, that would be different.

Duncan Murdoch
>  
> Notes on building R under cygwin:
>  
> export FFLAGS=-O3
> export CFLAGS=-O3
> export CXXFLAGS=-O3
> export OBJCFLAGS=-O3
> export FCFLAGS=-O3
> export LDFLAGS='-lblas -lg2c -lintl'
>  
> export R_OSTYPE=unix
>  
> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
> --with-tcl-config=/usr/lib/tclConfig.sh \
> --with-tk-config=/usr/lib/tkConfig.sh \
> --with-blas=-lblas \
> --with-lapack=-llapack \
> --enable-R-shlib
>  
> comment out Win32 in src/include/config.h and set Unix to 1, change .so
> to .dll. change .so to .dll and in Makeconf.
> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>  
> Change .so to .dll in Makefile's
>  
> edit Makeconf and set R_OSTYPE to unix
>  
> make -j2
>  
> when blas doesn't link, re-run command with -lblas -lg2c on end and
> change output to .dll
>  
> edit Rstrptime.c and change wcstod to atof.
>  
> in modules:
> when X11 and internet falls over add -lintl to link line. add -lg2c and
> -lblas to lapack
>  
> comment out library/base/R/library.R lines 47-51 to avoid arch check
> which seems to go wrong!
>  
> make -j2
> make install
>  
> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl -lg2c
> -lblas' to the end of ALL_LIBS
> so the module building works. Change .so to .dll also
> (can't see how to to this for the build tho...)
>  
>
> Our cygwin info is:
>              sysname              release              version 
>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22" 
>
>
>  
>  
> Robert Denham
> Environmental Statistician
> Remote Sensing Centre
> Telephone 07 3896 9899 
> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/> 
>  
> Department of Natural Resources & Water
> QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
>
> ************************************************************************
> The information in this email together with any attachments is
> intended only for the person or entity to which it is addressed
> and may contain confidential and/or privileged material.
> Any form of review, disclosure, modification, distribution
> and/or publication of this email message is prohibited, unless
> as a necessary part of Departmental business.
> If you have received this message in error, you are asked to
> inform the sender as quickly as possible and delete this message
> and any copies of this message from your computer and/or your
> computer system network.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Aug 21 13:52:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Aug 2007 12:52:46 +0100 (BST)
Subject: [Rd] compiling R under cygwin
In-Reply-To: <46CAC408.4080105@stats.uwo.ca>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>
	<46CAC408.4080105@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>

Yes,

> What is the advantage of building this?

was my question too.  If you want a Unix-like version of R on PC hardware 
running Windows why not run a Unix-like OS under a virtual machine?

Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as 
intended will solve most of the problems.  I would use --disable-nls 
--disable-mbcs as you don't need them (and in particular you don't benefit 
from MBCS support on Windows unless you are in a CJK locale).

Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any 
changes would be made only to R-devel.  It there is a convincing case to 
tailor a build for Cygwin there we can probably do so rather easily, but 
the need for ongoing support would be a worry.

(If platforms are not used and in particular not tested in the alpha/beta 
testing phases then the ability to build on them crumbles away.  We seems 
to be down to regular testers on Linux, Windows, MacOS X, Solaris and 
FreeBSD, with some help on AIX after a patch with none.)

On Tue, 21 Aug 2007, Duncan Murdoch wrote:

> Denham Robert wrote:
>> For various reasons,

I think it is only courteous to mention some good reasons if you want to 
take up people's time.

>> it suits our workplace to have a cygwin version of
>> R.  I am pretty sure that cygwin is still not a supported environment
>> for R, but we have managed to compile R-2.5.1 under cygwin without too
>> many dramas.  Our procedure is described below.  We still have a few
>> problems compiling libraries without manually changing files from .so to
>> .dll, but it seems ok.
>>
> I would expect other subtle problems as well, because Cygwin is not a
> normal Unix.  I don't know whether any of these differences matter to R,
> but some things to look out for are:
>
> - you can't unlink a file while it is open
> - filenames are not case sensitive
> - file permissions have strange defaults (everything is executable)
> - I think the executable format still needs to be Windows format
> - There's no such thing as a ptty
> - You'll probably need X11 for graphics, and will lose support for
> Windows metafile output (wmf)
>>
>> I was wondering whether this information is likely to be useful to
>> others, and if we should spend any time looking in to ways in which the
>> configure/build/install code could be modified to allow a standard
>> install.
>>
> What is the advantage of building this?  I don't think we want to
> support platforms just for the sake of supporting more platforms, but if
> there's a real need for it, that would be different.
>
> Duncan Murdoch
>>
>> Notes on building R under cygwin:
>>
>> export FFLAGS=-O3
>> export CFLAGS=-O3
>> export CXXFLAGS=-O3
>> export OBJCFLAGS=-O3
>> export FCFLAGS=-O3
>> export LDFLAGS='-lblas -lg2c -lintl'
>>
>> export R_OSTYPE=unix
>>
>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
>> --with-tcl-config=/usr/lib/tclConfig.sh \
>> --with-tk-config=/usr/lib/tkConfig.sh \
>> --with-blas=-lblas \
>> --with-lapack=-llapack \
>> --enable-R-shlib
>>
>> comment out Win32 in src/include/config.h and set Unix to 1, change .so
>> to .dll. change .so to .dll and in Makeconf.
>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>>
>> Change .so to .dll in Makefile's
>>
>> edit Makeconf and set R_OSTYPE to unix
>>
>> make -j2
>>
>> when blas doesn't link, re-run command with -lblas -lg2c on end and
>> change output to .dll
>>
>> edit Rstrptime.c and change wcstod to atof.
>>
>> in modules:
>> when X11 and internet falls over add -lintl to link line. add -lg2c and
>> -lblas to lapack
>>
>> comment out library/base/R/library.R lines 47-51 to avoid arch check
>> which seems to go wrong!
>>
>> make -j2
>> make install
>>
>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl -lg2c
>> -lblas' to the end of ALL_LIBS
>> so the module building works. Change .so to .dll also
>> (can't see how to to this for the build tho...)
>>
>>
>> Our cygwin info is:
>>              sysname              release              version
>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
>>
>>
>>
>>
>> Robert Denham
>> Environmental Statistician
>> Remote Sensing Centre
>> Telephone 07 3896 9899
>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
>>
>> Department of Natural Resources & Water
>> QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
>>
>> ************************************************************************
>> The information in this email together with any attachments is
>> intended only for the person or entity to which it is addressed
>> and may contain confidential and/or privileged material.
>> Any form of review, disclosure, modification, distribution
>> and/or publication of this email message is prohibited, unless
>> as a necessary part of Departmental business.
>> If you have received this message in error, you are asked to
>> inform the sender as quickly as possible and delete this message
>> and any copies of this message from your computer and/or your
>> computer system network.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From znmeb at cesmail.net  Tue Aug 21 16:57:18 2007
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Tue, 21 Aug 2007 07:57:18 -0700
Subject: [Rd] compiling R under cygwin
In-Reply-To: <Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>	<46CAC408.4080105@stats.uwo.ca>
	<Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
Message-ID: <46CAFD4E.7040900@cesmail.net>

Prof Brian Ripley wrote:
> Yes,
> 
>> What is the advantage of building this?
> 
> was my question too.  If you want a Unix-like version of R on PC hardware 
> running Windows why not run a Unix-like OS under a virtual machine?
> 
> Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as 
> intended will solve most of the problems.  I would use --disable-nls 
> --disable-mbcs as you don't need them (and in particular you don't benefit 
> from MBCS support on Windows unless you are in a CJK locale).
> 
> Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any 
> changes would be made only to R-devel.  It there is a convincing case to 
> tailor a build for Cygwin there we can probably do so rather easily, but 
> the need for ongoing support would be a worry.
> 
> (If platforms are not used and in particular not tested in the alpha/beta 
> testing phases then the ability to build on them crumbles away.  We seems 
> to be down to regular testers on Linux, Windows, MacOS X, Solaris and 
> FreeBSD, with some help on AIX after a patch with none.)

I too have a workplace where Windows is the "official" IT-supported OS,
and in some cases open-source tools do not have a native Windows port,
thus needing Cygwin, or as you suggest, an embedded VMware Linux
workstation. I run Cygwin and a Gentoo Linux VMware guest on my Windows
machine. Having said that:

1. I consider the Windows version of R to have a *superior* user
interface to the Linux version. The only place where it falls down in my
opinion is the semi-difficult nature of building contributed packages
that require C or C++ or Fortran compilation.

2. I know of few other open source communities that prefer a Cygwin
version to a native Windows version if the native version exists. Most
of them go further -- for example, the Ruby Windows people flat-out
deprecate the Cygwin Ruby port, even though it is slightly faster than
the native one and even though some C-language extensions won't build
except on the Cygwin version!

In short, Cygwin is a crutch IMHO, and an embedded Linux VMware guest
isn't much better. I'm hoping to phase Cygwin out by the end of the
year. I think if you need Linux, you should run Linux. That's going to
require some patience and extreme people skills when you deal with your
IT department, but it can be done. But on Windows boxes, you're much
better off using only tools built for and tested on native Windows.


From murdoch at stats.uwo.ca  Tue Aug 21 17:51:57 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Aug 2007 11:51:57 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <46CAFD4E.7040900@cesmail.net>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>	<46CAC408.4080105@stats.uwo.ca>	<Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
	<46CAFD4E.7040900@cesmail.net>
Message-ID: <46CB0A1D.3050602@stats.uwo.ca>

On 8/21/2007 10:57 AM, M. Edward (Ed) Borasky wrote:
> Prof Brian Ripley wrote:
>> Yes,
>> 
>>> What is the advantage of building this?
>> 
>> was my question too.  If you want a Unix-like version of R on PC hardware 
>> running Windows why not run a Unix-like OS under a virtual machine?
>> 
>> Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as 
>> intended will solve most of the problems.  I would use --disable-nls 
>> --disable-mbcs as you don't need them (and in particular you don't benefit 
>> from MBCS support on Windows unless you are in a CJK locale).
>> 
>> Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any 
>> changes would be made only to R-devel.  It there is a convincing case to 
>> tailor a build for Cygwin there we can probably do so rather easily, but 
>> the need for ongoing support would be a worry.
>> 
>> (If platforms are not used and in particular not tested in the alpha/beta 
>> testing phases then the ability to build on them crumbles away.  We seems 
>> to be down to regular testers on Linux, Windows, MacOS X, Solaris and 
>> FreeBSD, with some help on AIX after a patch with none.)
> 
> I too have a workplace where Windows is the "official" IT-supported OS,
> and in some cases open-source tools do not have a native Windows port,
> thus needing Cygwin, or as you suggest, an embedded VMware Linux
> workstation. I run Cygwin and a Gentoo Linux VMware guest on my Windows
> machine. Having said that:
> 
> 1. I consider the Windows version of R to have a *superior* user
> interface to the Linux version. The only place where it falls down in my
> opinion is the semi-difficult nature of building contributed packages
> that require C or C++ or Fortran compilation.

And note that this is getting easier:  we're down to a single "Rtools" 
download and install.
> 
> 2. I know of few other open source communities that prefer a Cygwin
> version to a native Windows version if the native version exists. Most
> of them go further -- for example, the Ruby Windows people flat-out
> deprecate the Cygwin Ruby port, even though it is slightly faster than
> the native one and even though some C-language extensions won't build
> except on the Cygwin version!
> 
> In short, Cygwin is a crutch IMHO, and an embedded Linux VMware guest
> isn't much better. I'm hoping to phase Cygwin out by the end of the
> year. I think if you need Linux, you should run Linux. That's going to
> require some patience and extreme people skills when you deal with your
> IT department, but it can be done. But on Windows boxes, you're much
> better off using only tools built for and tested on native Windows.

I still use Cygwin, because I like the bash shell.  But I don't build 
anything for Cygwin, I build native executables.  (There are other 
versions of bash available on Windows, but I prefer the devil I know.)

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Aug 21 17:52:41 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 21 Aug 2007 11:52:41 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <46CAFD4E.7040900@cesmail.net>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>
	<46CAC408.4080105@stats.uwo.ca>
	<Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
	<46CAFD4E.7040900@cesmail.net>
Message-ID: <971536df0708210852v65307687pb1a17dede2699212@mail.gmail.com>

On 8/21/07, M. Edward (Ed) Borasky <znmeb at cesmail.net> wrote:
> Prof Brian Ripley wrote:
> > Yes,
> >
> >> What is the advantage of building this?
> >
> > was my question too.  If you want a Unix-like version of R on PC hardware
> > running Windows why not run a Unix-like OS under a virtual machine?
> >
> > Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as
> > intended will solve most of the problems.  I would use --disable-nls
> > --disable-mbcs as you don't need them (and in particular you don't benefit
> > from MBCS support on Windows unless you are in a CJK locale).
> >
> > Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any
> > changes would be made only to R-devel.  It there is a convincing case to
> > tailor a build for Cygwin there we can probably do so rather easily, but
> > the need for ongoing support would be a worry.
> >
> > (If platforms are not used and in particular not tested in the alpha/beta
> > testing phases then the ability to build on them crumbles away.  We seems
> > to be down to regular testers on Linux, Windows, MacOS X, Solaris and
> > FreeBSD, with some help on AIX after a patch with none.)
>
> I too have a workplace where Windows is the "official" IT-supported OS,
> and in some cases open-source tools do not have a native Windows port,
> thus needing Cygwin, or as you suggest, an embedded VMware Linux
> workstation. I run Cygwin and a Gentoo Linux VMware guest on my Windows
> machine. Having said that:
>
> 1. I consider the Windows version of R to have a *superior* user
> interface to the Linux version. The only place where it falls down in my
> opinion is the semi-difficult nature of building contributed packages
> that require C or C++ or Fortran compilation.
>
> 2. I know of few other open source communities that prefer a Cygwin
> version to a native Windows version if the native version exists. Most
> of them go further -- for example, the Ruby Windows people flat-out
> deprecate the Cygwin Ruby port, even though it is slightly faster than
> the native one and even though some C-language extensions won't build
> except on the Cygwin version!
>
> In short, Cygwin is a crutch IMHO, and an embedded Linux VMware guest
> isn't much better. I'm hoping to phase Cygwin out by the end of the
> year. I think if you need Linux, you should run Linux. That's going to
> require some patience and extreme people skills when you deal with your
> IT department, but it can be done. But on Windows boxes, you're much
> better off using only tools built for and tested on native Windows.

Besides Cygwin and VMware there is also the coLinux kernel which is
a native Linux kernel that runs on Windows.  I have run R with the AndLinux
distro based on Ubuntu/coLinux/Xming on top of Windows with some success.
It has the advantage that it runs much faster than virtual machine solutions
(such as VMware) and it does not require special versions of R -- you can just
use the normal Ubuntu version of R.  AndLinux is being developed (they are
still working on the installer) but its basically usable already and they claim
there are already 30,000 users.

On the downside you have to start it up after starting up Windows and that
takes some time and the installer is not finished so you have to use batch
files to start it.   There may be some other problems associated with its
immaturity as well.  See:
http://www.andlinux.org/


From bolker at zoo.ufl.edu  Tue Aug 21 19:29:33 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 21 Aug 2007 13:29:33 -0400
Subject: [Rd] buglet (?) in de.restore()
Message-ID: <46CB20FD.6070405@zoo.ufl.edu>


   If one calls data.entry() with a matrix:

A = matrix(0,2,2)
data.entry(A)

 everything works fine except that it triggers a warning:

Warning message:
the condition has length > 1 and only the first element will be used in:
   if (dim(x) == dim(args[[i]])) rn <- dimnames(args[[i]])[[1]] else rn 
<- NULL

This is triggered by the following lines in de.restore() [in 
src/library/utils/R/de.R]:
>   if( dim(x) == dim(args[[i]]) )
>                 rn <- dimnames(args[[i]])[[1]]
>             else rn <- NULL
   It would seem to make sense to replace the condition with

if (nrow(x) == nrow(args[[i]]))

   (de.restore() is only called if an element of the list passed to 
data.entry
has more than one column)

  On a side note, I'm curious why

> > A = matrix(0,2,2)
> > is.vector(A)
> [1] FALSE
> > is(A,"vector")
> [1] TRUE
  ...

------------------
sessionInfo()
R version 2.5.1 (2007-06-27)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" 
[7] "base"


From ripley at stats.ox.ac.uk  Tue Aug 21 23:12:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Aug 2007 22:12:18 +0100 (BST)
Subject: [Rd] compiling R under cygwin
In-Reply-To: <Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>
	<46CAC408.4080105@stats.uwo.ca>
	<Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0708212202540.20215@gannet.stats.ox.ac.uk>

On Tue, 21 Aug 2007, Prof Brian Ripley wrote:

> Yes,
>
>> What is the advantage of building this?
>
> was my question too.  If you want a Unix-like version of R on PC hardware
> running Windows why not run a Unix-like OS under a virtual machine?
>
> Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as
> intended will solve most of the problems.  I would use --disable-nls
> --disable-mbcs as you don't need them (and in particular you don't benefit
> from MBCS support on Windows unless you are in a CJK locale).
>
> Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any
> changes would be made only to R-devel.  It there is a convincing case to
> tailor a build for Cygwin there we can probably do so rather easily, but
> the need for ongoing support would be a worry.

It was very easy: R-devel now builds out of the box on Cygwin.  I didn't 
have to do most of the things mentioned here: almost all the pieces needed 
were already available inside configure and just needed to be switched on. 
The exercise was useful in that it found a couple of long-standing minor 
errors in the build process.  The resulting executable hung on the fifo() 
test (seemingly an oft-reported Cygwin issue), but otherwise passed 'make 
check'.

I still don't see why one would prefer this to Rterm.exe.

> (I
f platforms are not used and in particular not tested in the alpha/beta
> testing phases then the ability to build on them crumbles away.  We seems
> to be down to regular testers on Linux, Windows, MacOS X, Solaris and
> FreeBSD, with some help on AIX after a patch with none.)
>
> On Tue, 21 Aug 2007, Duncan Murdoch wrote:
>
>> Denham Robert wrote:
>>> For various reasons,
>
> I think it is only courteous to mention some good reasons if you want to
> take up people's time.
>
>>> it suits our workplace to have a cygwin version of
>>> R.  I am pretty sure that cygwin is still not a supported environment
>>> for R, but we have managed to compile R-2.5.1 under cygwin without too
>>> many dramas.  Our procedure is described below.  We still have a few
>>> problems compiling libraries without manually changing files from .so to
>>> .dll, but it seems ok.
>>>
>> I would expect other subtle problems as well, because Cygwin is not a
>> normal Unix.  I don't know whether any of these differences matter to R,
>> but some things to look out for are:
>>
>> - you can't unlink a file while it is open
>> - filenames are not case sensitive
>> - file permissions have strange defaults (everything is executable)
>> - I think the executable format still needs to be Windows format
>> - There's no such thing as a ptty
>> - You'll probably need X11 for graphics, and will lose support for
>> Windows metafile output (wmf)
>>>
>>> I was wondering whether this information is likely to be useful to
>>> others, and if we should spend any time looking in to ways in which the
>>> configure/build/install code could be modified to allow a standard
>>> install.
>>>
>> What is the advantage of building this?  I don't think we want to
>> support platforms just for the sake of supporting more platforms, but if
>> there's a real need for it, that would be different.
>>
>> Duncan Murdoch
>>>
>>> Notes on building R under cygwin:
>>>
>>> export FFLAGS=-O3
>>> export CFLAGS=-O3
>>> export CXXFLAGS=-O3
>>> export OBJCFLAGS=-O3
>>> export FCFLAGS=-O3
>>> export LDFLAGS='-lblas -lg2c -lintl'
>>>
>>> export R_OSTYPE=unix
>>>
>>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
>>> --with-tcl-config=/usr/lib/tclConfig.sh \
>>> --with-tk-config=/usr/lib/tkConfig.sh \
>>> --with-blas=-lblas \
>>> --with-lapack=-llapack \
>>> --enable-R-shlib
>>>
>>> comment out Win32 in src/include/config.h and set Unix to 1, change .so
>>> to .dll. change .so to .dll and in Makeconf.
>>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>>>
>>> Change .so to .dll in Makefile's
>>>
>>> edit Makeconf and set R_OSTYPE to unix
>>>
>>> make -j2
>>>
>>> when blas doesn't link, re-run command with -lblas -lg2c on end and
>>> change output to .dll
>>>
>>> edit Rstrptime.c and change wcstod to atof.
>>>
>>> in modules:
>>> when X11 and internet falls over add -lintl to link line. add -lg2c and
>>> -lblas to lapack
>>>
>>> comment out library/base/R/library.R lines 47-51 to avoid arch check
>>> which seems to go wrong!
>>>
>>> make -j2
>>> make install
>>>
>>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl -lg2c
>>> -lblas' to the end of ALL_LIBS
>>> so the module building works. Change .so to .dll also
>>> (can't see how to to this for the build tho...)
>>>
>>>
>>> Our cygwin info is:
>>>              sysname              release              version
>>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
>>>
>>>
>>>
>>>
>>> Robert Denham
>>> Environmental Statistician
>>> Remote Sensing Centre
>>> Telephone 07 3896 9899
>>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
>>>
>>> Department of Natural Resources & Water
>>> QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
>>>
>>> ************************************************************************
>>> The information in this email together with any attachments is
>>> intended only for the person or entity to which it is addressed
>>> and may contain confidential and/or privileged material.
>>> Any form of review, disclosure, modification, distribution
>>> and/or publication of this email message is prohibited, unless
>>> as a necessary part of Departmental business.
>>> If you have received this message in error, you are asked to
>>> inform the sender as quickly as possible and delete this message
>>> and any copies of this message from your computer and/or your
>>> computer system network.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From zivan.karaman at gmail.com  Tue Aug 21 17:08:26 2007
From: zivan.karaman at gmail.com (zivan.karaman at gmail.com)
Date: Tue, 21 Aug 2007 17:08:26 +0200 (CEST)
Subject: [Rd] available.packages (PR#9841)
Message-ID: <20070821150826.356A966896@slim.kubism.ku.dk>

------=_Part_60506_18925213.1187708869863
Content-Type: text/plain; charset=WINDOWS-1252
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Thank you very much for your explanation, it woks correctly indeed.




On 8/19/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
> The documented specification is file:///d:/CRAN (as specified by RFC1738)=
,
> so this is working correctly.
>
> The CHANGES file for 2.2.0 says:
>
>     o   file:// URLs are now interpreted by download.file(),
>         download.packages() and url() in the same way as Mozilla-based
>         browsers.  That is, the expected form is
>
>                 file:///d:/path/to/file
>
>         with *three* slashes.
>
> The point is that this is file:// + host + / + path/to/file, and host is
> missing.  That some versions of IE did not follow the standard is part of
> the confusion here.
>
> Note that ?available.packages does say
>
>      If a repository is
>      local, i.e., the URL starts with '"file:"', then the packages are
>      not downloaded but used directly.  (Both '"file:"' and
>      '"file:///"' are allowed as prefixes to a file path, the latter
>      for an absolute file path.)
>
> but 'file:' does not work with drives on Windows.  That seems clearly to
> rule out your usage.
>
>
> On Fri, 10 Aug 2007, zivan.karaman at gmail.com wrote:
>
> > Full_Name: Zivan Karaman
> > Version: 2.5.1
> > OS: Windows XP SP2
> > Submission from: (NULL) (195.6.68.214)
> >
> >
> > I think that I have encountered a bug in the function "
> available.packages" when
> > using a local repository (file://=85) on Windows.
> >
> > Version information:
> > platform       i386-pc-mingw32
> > arch           i386
> > os             mingw32
> > system         i386, mingw32
> > status
> > major          2
> > minor          5.1
> > year           2007
> > month          06
> > day            27
> > svn rev        42083
> > language       R
> > version.string R version 2.5.1 (2007-06-27)
> >
> > I have made a copy of the CRAN "/bin/windows/contrib/2.5" directory in
> the
> > "D:/CRAN" folder on my machine.
> >
> > When I issue the command:
> >
> > available.packages(contrib.url("file://D:/CRAN"))
> >
> > I get the follwoing message:
> > Error in gzfile(file, "r") : unable to open connection
> > In addition: Warning message:
> > cannot open compressed file ':/CRAN/bin/windows/contrib/2.5/PACKAGES'
> in:
> > gzfile(file, "r")
> >
> > Looking at the source code, I've spotted the following lines which seem
> to cause
> > trouble:
> >
> >            if (.Platform$OS.type =3D=3D "windows") {
> >                if (length(grep("[A-Za-z]:", tmpf)))
> >                  tmpf <- substring(tmpf, 2)
> >            }
> > Deleting them, the function works OK.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

------=_Part_60506_18925213.1187708869863
Content-Type: text/html; charset=WINDOWS-1252
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

<p class=3D"MsoNormal" style=3D"MARGIN: 0cm 0cm 0pt"><span lang=3D"EN-GB" s=
tyle=3D"mso-ansi-language: EN-GB"><font size=3D"2"><font face=3D"Verdana">T=
hank you very much for your explanation, it woks correctly indeed.</font></=
font></span>
</p>
<p class=3D"MsoNormal" style=3D"MARGIN: 0cm 0cm 0pt"><span lang=3D"EN-GB" s=
tyle=3D"mso-ansi-language: EN-GB"><font size=3D"2"><font face=3D"Verdana">&=
nbsp;</font></font></span></p><br><br>
<div><span class=3D"gmail_quote">On 8/19/07, <b class=3D"gmail_sendername">=
Prof Brian Ripley</b> &lt;<a href=3D"mailto:ripley at stats.ox.ac.uk">ripley at s=
tats.ox.ac.uk</a>&gt; wrote:</span>
<blockquote class=3D"gmail_quote" style=3D"PADDING-LEFT: 1ex; MARGIN: 0px 0=
px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">The documented specification is =
file:///d:/CRAN (as specified by RFC1738),<br>so this is working correctly.
<br><br>The CHANGES file for 2.2.0 says:<br><br>&nbsp;&nbsp;&nbsp;&nbsp;o&n=
bsp;&nbsp; file:// URLs are now interpreted by download.file(),<br>&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;download.packages() and url() in th=
e same way as Mozilla-based<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;browsers.&nbsp;&nbsp;That is, the expected form is
<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file:///d:/path/to/file<br><br>&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with *three* slashes.<br><br>The point is =
that this is file:// + host + / + path/to/file, and host is<br>missing.&nbs=
p;&nbsp;That some versions of IE did not follow the standard is part of
<br>the confusion here.<br><br>Note that ?available.packages does say<br><b=
r>&nbsp;&nbsp;&nbsp;&nbsp; If a repository is<br>&nbsp;&nbsp;&nbsp;&nbsp; l=
ocal, i.e., the URL starts with &#39;&quot;file:&quot;&#39;, then the packa=
ges are<br>&nbsp;&nbsp;&nbsp;&nbsp; not downloaded but used directly.&nbsp;=
&nbsp;(Both &#39;&quot;file:&quot;&#39; and
<br>&nbsp;&nbsp;&nbsp;&nbsp; &#39;&quot;file:///&quot;&#39; are allowed as =
prefixes to a file path, the latter<br>&nbsp;&nbsp;&nbsp;&nbsp; for an abso=
lute file path.)<br><br>but &#39;file:&#39; does not work with drives on Wi=
ndows.&nbsp;&nbsp;That seems clearly to<br>rule out your usage.
<br><br><br>On Fri, 10 Aug 2007, <a href=3D"mailto:zivan.karaman at gmail.com"=
>zivan.karaman at gmail.com</a> wrote:<br><br>&gt; Full_Name: Zivan Karaman<br=
>&gt; Version: 2.5.1<br>&gt; OS: Windows XP SP2<br>&gt; Submission from: (N=
ULL) (
<a href=3D"http://195.6.68.214">195.6.68.214</a>)<br>&gt;<br>&gt;<br>&gt; I=
 think that I have encountered a bug in the function &quot;available.packag=
es&quot; when<br>&gt; using a local repository (file://=85) on Windows.<br>
&gt;<br>&gt; Version information:<br>&gt; platform&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp; i386-pc-mingw32<br>&gt; arch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp; i386<br>&gt; os&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mingw32<br>&gt; system&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i386, mingw32<br>&gt; status<br>&gt; maj=
or&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2<br>&gt; min=
or&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
5.1<br>&gt; year&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
; 2007<br>&gt; month&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;06<br>&gt; day&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;27<br>&gt; svn rev&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;42083<br>&gt; language&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; R<br>&gt;=
 version.string R version 2.5.1 (2007-06-27)<br>&gt;<br>&gt; I have made a =
copy of the CRAN &quot;/bin/windows/contrib/2.5&quot; directory in the
<br>&gt; &quot;D:/CRAN&quot; folder on my machine.<br>&gt;<br>&gt; When I i=
ssue the command:<br>&gt;<br>&gt; available.packages(contrib.url(&quot;file=
://D:/CRAN&quot;))<br>&gt;<br>&gt; I get the follwoing message:<br>&gt; Err=
or in gzfile(file, &quot;r&quot;) : unable to open connection
<br>&gt; In addition: Warning message:<br>&gt; cannot open compressed file =
&#39;:/CRAN/bin/windows/contrib/2.5/PACKAGES&#39; in:<br>&gt; gzfile(file, =
&quot;r&quot;)<br>&gt;<br>&gt; Looking at the source code, I&#39;ve spotted=
 the following lines which seem to cause
<br>&gt; trouble:<br>&gt;<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (.Platform$OS.type =3D=3D &quot;windows&qu=
ot;) {<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (length(grep(&quot;[A-Za-z]:&quot;, t=
mpf)))<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tmpf &lt;- substring(tmpf, 2=
)<br>
&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;}<br>&gt; Deleting them, the function works OK.<br>&gt;<br>&gt; __________=
____________________________________<br>&gt; <a href=3D"mailto:R-devel at r-pr=
oject.org">R-devel at r-project.org</a> mailing list<br>&gt;=20
<a href=3D"https://stat.ethz.ch/mailman/listinfo/r-devel">https://stat.ethz=
.ch/mailman/listinfo/r-devel</a><br>&gt;<br><br>--<br>Brian D. Ripley,&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=3D"mailto:ripley at stats.ox.ac.uk">ripley=
@stats.ox.ac.uk
</a><br>Professor of Applied Statistics,&nbsp;&nbsp;<a href=3D"http://www.s=
tats.ox.ac.uk/~ripley/">http://www.stats.ox.ac.uk/~ripley/</a><br>Universit=
y of Oxford,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp; Tel:&nbsp;&nbsp;+44 1865 272861 (self)<br>1 South Parks Road,&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +44 1865 272866 (PA)
<br>Oxford OX1 3TG, UK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fax:&nbsp;&nbsp;+44 1865 272595<=
/blockquote></div><br>

------=_Part_60506_18925213.1187708869863--


From znmeb at cesmail.net  Wed Aug 22 03:23:06 2007
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Tue, 21 Aug 2007 18:23:06 -0700
Subject: [Rd] compiling R under cygwin
In-Reply-To: <971536df0708210852v65307687pb1a17dede2699212@mail.gmail.com>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5C37@INDMAIL.lands.resnet.qg>	<46CAC408.4080105@stats.uwo.ca>	<Pine.LNX.4.64.0708211222490.21169@gannet.stats.ox.ac.uk>	<46CAFD4E.7040900@cesmail.net>
	<971536df0708210852v65307687pb1a17dede2699212@mail.gmail.com>
Message-ID: <46CB8FFA.8090508@cesmail.net>

Gabor Grothendieck wrote:

> Besides Cygwin and VMware there is also the coLinux kernel which is
> a native Linux kernel that runs on Windows.  I have run R with the AndLinux
> distro based on Ubuntu/coLinux/Xming on top of Windows with some success.
> It has the advantage that it runs much faster than virtual machine solutions
> (such as VMware) and it does not require special versions of R -- you can just
> use the normal Ubuntu version of R.  AndLinux is being developed (they are
> still working on the installer) but its basically usable already and they claim
> there are already 30,000 users.
> 
> On the downside you have to start it up after starting up Windows and that
> takes some time and the installer is not finished so you have to use batch
> files to start it.   There may be some other problems associated with its
> immaturity as well.  See:
> http://www.andlinux.org/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
CoLinux is a non-starter in many corporate shops -- it violates lots of
security policies by hacking into the Windows environment. It's also
quite immature. It may be the greatest thing since sliced bread, but if
the corporate police won't let you use it, it's not worth much.


From Heather.Turner at warwick.ac.uk  Wed Aug 22 11:20:21 2007
From: Heather.Turner at warwick.ac.uk (Turner, Heather)
Date: Wed, 22 Aug 2007 10:20:21 +0100
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070808065400.GA5991@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu><loom.20070709T175233-590@post.gmane.org><469557AC.2010607@acm.org>
	<20070712081616.GA7100@cs.cas.cz><316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk><20070713203735.GA18016@cs.cas.cz><20070725070320.GA20948@cs.cas.cz><20070727071006.GA31738@cs.cas.cz>
	<20070808065400.GA5991@cs.cas.cz>
Message-ID: <1072002710EB6047A212400EEB65F00676D9DC@ELDER.ads.warwick.ac.uk>

Petr Savicky kindly brought this thread to my attention as I'm afraid it
had passed me by. As one of the contributors to the earlier discussion
on adding warnings to sweep I would like to give my support to Petr's
proposed patch.

For the record I should say that Petr was right to point out that the
use of MARGIN in my examples did not make sense
https://stat.ethz.ch/pipermail/r-devel/2007-July/046487.html
so I have no quibble with that.

I think it is sensible too, to use the dim attribute of STATS as the
basis of the test, when the dim attribute is present. This provides a
way to control the strength of the test in the case of sweeping out a
vector, as Petr describes in his message below. I think that the
proposed patch successfully brings together the different views on what
should be tested, which was the stumbling block last time around
https://stat.ethz.ch/pipermail/r-help/2005-June/074037.html

Even if people set check.margin = FALSE for reasons of speed, this in
itself should be a useful check, since they will need to be confident
that the test is unnecessary.

Heather

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Petr Savicky
Sent: 08 August 2007 07:54
To: r-devel at r-project.org
Subject: Re: [Rd] sweep sanity checking?

Thanks to Martin Maechler for his comments, advice and for pointing
out the speed problem. Thanks also to Ben Bolker for tests of speed,
which confirm that for small arrays, a slow down by a factor of about
1.2 - 1.5 may occur. Now, I would like to present a new version of
sweep,
which is simpler and has an option to avoid the test. This is expected
to be used in scripts, where the programmer is quite sure that the
usage is correct and speed is required. The new version differs from
the previous one in the following:

1. The option check.margin has a different meaning. It defaults to TRUE
   and it determines whether the test is performed or not.

2. Since check.margin has the meaning above, it cannot be used
   to select, which test should be performed. This depends on the
   type of STATS. The suggested sweep function contains two tests:
   - a vector test by Heather Turner, which is used, if STATS 
     has no dim attribute and, hence, is a vector (STATS should
     not be anything else than a vector or an array)
   - an array test used if STATS has dim attribute.
   The vector test allows some kinds of recycling, while the array test
   does not. Hence, in the most common case, where x is a matrix
   and STATS is a vector, if the user likes to be warned if the length
   of the vector is not exactly the right one, the following call is
   suggested: sweep(x,MARGIN,as.array(STATS)). Otherwise, a warning
   will be generated only if length(STATS) does not divide the specified
   dimension of x, which is nrow(x) (MARGIN=1) or ncol(x) (MARGIN=2).

3. If STATS is an array, then the test is more restrictive than in
   the previous version. It is now required that after deleting
   dimensions with one level, the remaining dimensions coincide.
   The previous version allowed additionally the cases, when dim(STATS)
   is a prefix of dim(x)[MARGIN], for example, if dim(STATS) = k1 and
   dim(x)[MARGIN] = c(k1,k2).

The code of the tests in the suggested sweep is based on the previous
suggestions
 https://stat.ethz.ch/pipermail/r-help/2005-June/073989.html by Robin
Hankin
 https://stat.ethz.ch/pipermail/r-help/2005-June/074001.html by Heather
Turner
 https://stat.ethz.ch/pipermail/r-devel/2007-June/046217.html by Ben
Bolker
with some further modifications.

The modification of sweep.Rd was prepared by Ben Bolker and me.

I would like to encourage everybody who likes to express his opinion
on the patch to do it now. In my opinion, the suggestion of the
new code stabilized in the sense that I will not modify it unless
there is a negative feedback.

A patch against R-devel_2007-08-06 is attached. It contains tabs. If
they
are corrupted by email transfer, use the link
  http://www.cs.cas.cz/~savicky/R-devel/patch-sweep
which is an identical copy.

Petr Savicky.

========================================================================
========================
--- R-devel_2007-08-06/src/library/base/R/sweep.R	2007-07-27
17:51:13.000000000 +0200
+++ R-devel_2007-08-06-sweep/src/library/base/R/sweep.R	2007-08-07
10:30:12.383672960 +0200
@@ -14,10 +14,29 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/
 
-sweep <- function(x, MARGIN, STATS, FUN = "-", ...)
+sweep <- function(x, MARGIN, STATS, FUN = "-", check.margin=TRUE, ...)
 {
     FUN <- match.fun(FUN)
     dims <- dim(x)
+	if (check.margin) {
+		dimmargin <- dims[MARGIN]
+		dimstats <- dim(STATS)
+		lstats <- length(STATS)
+		if (lstats > prod(dimmargin)) {
+			warning("length of STATS greater than the extent
of dim(x)[MARGIN]")
+		} else if (is.null(dimstats)) { # STATS is a vector
+			cumDim <- c(1, cumprod(dimmargin))
+			upper <- min(cumDim[cumDim >= lstats])
+			lower <- max(cumDim[cumDim <= lstats])
+			if (upper %% lstats != 0 || lstats %% lower !=
0)
+				warning("STATS does not recycle exactly
across MARGIN")
+		} else {
+			dimmargin <- dimmargin[dimmargin > 1]
+			dimstats <- dimstats[dimstats > 1]
+			if (length(dimstats) != length(dimmargin) ||
any(dimstats != dimmargin))
+				warning("length(STATS) or dim(STATS) do
not match dim(x)[MARGIN]")
+		}
+	}
     perm <- c(MARGIN, (1:length(dims))[ - MARGIN])
     FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
 }
--- R-devel_2007-08-06/src/library/base/man/sweep.Rd	2007-07-27
17:51:35.000000000 +0200
+++ R-devel_2007-08-06-sweep/src/library/base/man/sweep.Rd
2007-08-07 10:29:45.517757200 +0200
@@ -11,7 +11,7 @@
   statistic.
 }
 \usage{
-sweep(x, MARGIN, STATS, FUN="-", \dots)
+sweep(x, MARGIN, STATS, FUN="-", check.margin=TRUE, \dots)
 }
 \arguments{
   \item{x}{an array.}
@@ -22,8 +22,18 @@
     case of binary operators such as \code{"/"} etc., the function name
     must backquoted or quoted. (\code{FUN} is found by a call to
     \code{\link{match.fun}}.)}
+  \item{check.margin}{logical. If \code{TRUE} (the default), warn if
the
+    length or dimensions of \code{STATS} do
+    not match the specified dimensions of \code{x}.}
   \item{\dots}{optional arguments to \code{FUN}.}
 }
+\details{
+  The consistency check among \code{STATS}, \code{MARGIN} and \code{x}
+  is stricter if \code{STATS} is an array than if it is a vector.
+  In the vector case, some kinds of recycling are allowed without a
+  warning. Use \code{sweep(x,MARGIN,as.array(STATS))} if \code{STATS}
+  is a vector and you want to be warned if any recycling occurs.
+}
 \value{
   An array with the same shape as \code{x}, but with the summary
   statistics swept out.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed Aug 22 17:50:43 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Aug 2007 17:50:43 +0200
Subject: [Rd] paste() with NAs ..  change worth persuing?
Message-ID: <18124.23379.575814.316093@stat.math.ethz.ch>


Consider this example code

 c1 <- letters[1:7]; c2 <- LETTERS[1:7]
 c1[2] <- c2[3:4] <- NA
 rbind(c1,c2)

  ##   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
  ## c1 "a"  NA   "c"  "d"  "e"  "f"  "g" 
  ## c2 "A"  "B"  NA   NA   "E"  "F"  "G" 

  paste(c1,c2)

  ## -> [1] "a A"  "NA B" "c NA" "d NA" "e E"  "f F"  "g G" 

where a more logical result would have entries 2:4 equal to
      NA 
i.e.,  as.character(NA)
aka    NA_character_

Is this worth persuing, or does anyone see why not?

Regards,
Martin


From murdoch at stats.uwo.ca  Wed Aug 22 19:16:44 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Aug 2007 13:16:44 -0400
Subject: [Rd] paste() with NAs ..  change worth persuing?
In-Reply-To: <18124.23379.575814.316093@stat.math.ethz.ch>
References: <18124.23379.575814.316093@stat.math.ethz.ch>
Message-ID: <46CC6F7C.2010600@stats.uwo.ca>

On 8/22/2007 11:50 AM, Martin Maechler wrote:
> Consider this example code
> 
>  c1 <- letters[1:7]; c2 <- LETTERS[1:7]
>  c1[2] <- c2[3:4] <- NA
>  rbind(c1,c2)
> 
>   ##   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>   ## c1 "a"  NA   "c"  "d"  "e"  "f"  "g" 
>   ## c2 "A"  "B"  NA   NA   "E"  "F"  "G" 
> 
>   paste(c1,c2)
> 
>   ## -> [1] "a A"  "NA B" "c NA" "d NA" "e E"  "f F"  "g G" 
> 
> where a more logical result would have entries 2:4 equal to
>       NA 
> i.e.,  as.character(NA)
> aka    NA_character_
> 
> Is this worth persuing, or does anyone see why not?

A fairly common use of paste is to put together reports for human 
consumption.  Currently we have

 > p <- as.character(NA)
 > paste("the value of p is", p)
[1] "the value of p is NA"

which looks reasonable. Would this become

 > p <- as.character(NA)
 > paste("the value of p is", p)
[1] NA

under your proposal?  (In a quick search I was unable to find a real 
example where this would happen, but it would worry me...)

Duncan Murdoch


From Robert.Denham at nrw.qld.gov.au  Thu Aug 23 03:30:20 2007
From: Robert.Denham at nrw.qld.gov.au (Denham Robert)
Date: Thu, 23 Aug 2007 11:30:20 +1000
Subject: [Rd] compiling R under cygwin
Message-ID: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>

>> For various reasons,
>I think it is only courteous to mention some good reasons if you want
to take up people's time.

Some of the reasons we would like a cygwin version aren't necessarily
good reasons.  We have been using cygwin for sometime, mostly to deal
with scripting in a combined windows/unix environment.  We have a setup
which allows windows users to run many scripts in the same way as unix
users.  These scripts are often python or shell scripts.  We have R
installed on the unix machines, and the system administrators would like
to be able to have R on windows in the same environment.  This set up
also means that the administrator can fairly easily maintain the version
of software used on all user's machines.  Probably this could all be
managed and still use the native windows version of R, but the
administrator is familiar with cygwin and they could manage this
software in the same way they manage other packages. 

We would like to be able to use linux machines on pc's but unfortunately
we have restrictions imposed on us that prevent this.  This restriction
also goes as far as the use of virtual machines.  My personal preference
would be to run linux on my work pc, and use a virtual machine to run
windows software, such as ArcGIS and Imagine, that are not available for
linux.  This does not seem to be an option for us.

One thing I was interested in was knowing if there are others who also
would like a cygwin version.  From the replies to my post, and from a
search of the mailing list archive, I think that there is little demand
for this.  We would, however, be prepared to help in some way for the
few people who are interested.   



Robert Denham
Environmental Statistician
Remote Sensing Centre
Telephone 07 3896 9899 
www.nrw.qld.gov.au
 
Department of Natural Resources & Water
QScape Building, 80 Meiers Road, Indooroopilly Qld 4068

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Tuesday, 21 August 2007 9:53 PM
To: Duncan Murdoch
Cc: Denham Robert; r-devel at r-project.org
Subject: Re: [Rd] compiling R under cygwin

Yes,

> What is the advantage of building this?

was my question too.  If you want a Unix-like version of R on PC
hardware running Windows why not run a Unix-like OS under a virtual
machine?

Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as
intended will solve most of the problems.  I would use --disable-nls
--disable-mbcs as you don't need them (and in particular you don't
benefit from MBCS support on Windows unless you are in a CJK locale).

Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any
changes would be made only to R-devel.  It there is a convincing case to
tailor a build for Cygwin there we can probably do so rather easily, but
the need for ongoing support would be a worry.

(If platforms are not used and in particular not tested in the
alpha/beta testing phases then the ability to build on them crumbles
away.  We seems to be down to regular testers on Linux, Windows, MacOS
X, Solaris and FreeBSD, with some help on AIX after a patch with none.)

On Tue, 21 Aug 2007, Duncan Murdoch wrote:

> Denham Robert wrote:
>> For various reasons,

I think it is only courteous to mention some good reasons if you want to
take up people's time.

>> it suits our workplace to have a cygwin version of R.  I am pretty 
>> sure that cygwin is still not a supported environment for R, but we 
>> have managed to compile R-2.5.1 under cygwin without too many dramas.

>> Our procedure is described below.  We still have a few problems 
>> compiling libraries without manually changing files from .so to .dll,

>> but it seems ok.
>>
> I would expect other subtle problems as well, because Cygwin is not a 
> normal Unix.  I don't know whether any of these differences matter to 
> R, but some things to look out for are:
>
> - you can't unlink a file while it is open
> - filenames are not case sensitive
> - file permissions have strange defaults (everything is executable)
> - I think the executable format still needs to be Windows format
> - There's no such thing as a ptty
> - You'll probably need X11 for graphics, and will lose support for 
> Windows metafile output (wmf)
>>
>> I was wondering whether this information is likely to be useful to 
>> others, and if we should spend any time looking in to ways in which 
>> the configure/build/install code could be modified to allow a 
>> standard install.
>>
> What is the advantage of building this?  I don't think we want to 
> support platforms just for the sake of supporting more platforms, but 
> if there's a real need for it, that would be different.
>
> Duncan Murdoch
>>
>> Notes on building R under cygwin:
>>
>> export FFLAGS=-O3
>> export CFLAGS=-O3
>> export CXXFLAGS=-O3
>> export OBJCFLAGS=-O3
>> export FCFLAGS=-O3
>> export LDFLAGS='-lblas -lg2c -lintl'
>>
>> export R_OSTYPE=unix
>>
>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \ 
>> --with-tcl-config=/usr/lib/tclConfig.sh \ 
>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \ 
>> --with-lapack=-llapack \ --enable-R-shlib
>>
>> comment out Win32 in src/include/config.h and set Unix to 1, change 
>> .so to .dll. change .so to .dll and in Makeconf.
>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>>
>> Change .so to .dll in Makefile's
>>
>> edit Makeconf and set R_OSTYPE to unix
>>
>> make -j2
>>
>> when blas doesn't link, re-run command with -lblas -lg2c on end and 
>> change output to .dll
>>
>> edit Rstrptime.c and change wcstod to atof.
>>
>> in modules:
>> when X11 and internet falls over add -lintl to link line. add -lg2c 
>> and -lblas to lapack
>>
>> comment out library/base/R/library.R lines 47-51 to avoid arch check 
>> which seems to go wrong!
>>
>> make -j2
>> make install
>>
>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl 
>> -lg2c -lblas' to the end of ALL_LIBS so the module building works. 
>> Change .so to .dll also (can't see how to to this for the build 
>> tho...)
>>
>>
>> Our cygwin info is:
>>              sysname              release              version
>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
>>
>>
>>
>>
>> Robert Denham
>> Environmental Statistician
>> Remote Sensing Centre
>> Telephone 07 3896 9899
>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
>>
>> Department of Natural Resources & Water QScape Building, 80 Meiers 
>> Road, Indooroopilly Qld 4068
>>
>> *********************************************************************
>> *** The information in this email together with any attachments is 
>> intended only for the person or entity to which it is addressed and 
>> may contain confidential and/or privileged material.
>> Any form of review, disclosure, modification, distribution and/or 
>> publication of this email message is prohibited, unless as a 
>> necessary part of Departmental business.
>> If you have received this message in error, you are asked to inform 
>> the sender as quickly as possible and delete this message and any 
>> copies of this message from your computer and/or your computer system

>> network.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Aug 23 08:53:31 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Aug 2007 07:53:31 +0100 (BST)
Subject: [Rd] compiling R under cygwin
In-Reply-To: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
Message-ID: <Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>

On Thu, 23 Aug 2007, Denham Robert wrote:

>>> For various reasons,
>> I think it is only courteous to mention some good reasons if you want
> to take up people's time.
>
> Some of the reasons we would like a cygwin version aren't necessarily
> good reasons.  We have been using cygwin for sometime, mostly to deal
> with scripting in a combined windows/unix environment.  We have a setup
> which allows windows users to run many scripts in the same way as unix
> users.  These scripts are often python or shell scripts.  We have R
> installed on the unix machines, and the system administrators would like
> to be able to have R on windows in the same environment.  This set up
> also means that the administrator can fairly easily maintain the version
> of software used on all user's machines.  Probably this could all be
> managed and still use the native windows version of R, but the
> administrator is familiar with cygwin and they could manage this
> software in the same way they manage other packages.

Yes, it could almost certainly be done with Rterm.exe.

The issue I came across was the so-called 'posix file paths' that Cygwin 
uses.  Most (but not all) Windows programs accept file paths with / as the 
path separator, and most (but not all, e.g. tar) Cygwin programs accept 
paths of the forn c:/path/to/file.  So provided you use that as your
format, interworking with Unix and Unix-like shells work fine.  It used to 
be the case that if you had just one drive C: then Cygwin programs 
produced paths of the form /path/to/file that also worked on Windows.  Now 
they produce /cygdrive/c/path/to/file that works nowhere else.

In general this is a minor nuisance, but I needed to be able to 
cross-build R in an environment where I only have Cygwin-based 
cross-compilers, and there the path issues bit me: I needed a version of R 
that accepted and returned Cygwin-style paths.  So I made the configure 
changes necessary to build R under Cygwin, and had it running in 20 mins.

> We would like to be able to use linux machines on pc's but unfortunately
> we have restrictions imposed on us that prevent this.  This restriction
> also goes as far as the use of virtual machines.  My personal preference
> would be to run linux on my work pc, and use a virtual machine to run
> windows software, such as ArcGIS and Imagine, that are not available for
> linux.  This does not seem to be an option for us.
>
> One thing I was interested in was knowing if there are others who also
> would like a cygwin version.  From the replies to my post, and from a
> search of the mailing list archive, I think that there is little demand
> for this.  We would, however, be prepared to help in some way for the
> few people who are interested.

As I said earlier, it builds out of the box in R-devel (with suitable 
options documented in the R-admin manual).  No guarantees that it will 
continue to do so unless tested in the alpha/beta phase though.  As no 
other platform we use nowadays requires that shared objects/dynamic 
libraries have all imports satisfied at build time, this is liable to get 
broken.

But I would encourage people to use Rterm.exe if it can be made to do what 
you need.


>
>
>
> Robert Denham
> Environmental Statistician
> Remote Sensing Centre
> Telephone 07 3896 9899
> www.nrw.qld.gov.au
>
> Department of Natural Resources & Water
> QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Tuesday, 21 August 2007 9:53 PM
> To: Duncan Murdoch
> Cc: Denham Robert; r-devel at r-project.org
> Subject: Re: [Rd] compiling R under cygwin
>
> Yes,
>
>> What is the advantage of building this?
>
> was my question too.  If you want a Unix-like version of R on PC
> hardware running Windows why not run a Unix-like OS under a virtual
> machine?
>
> Quite a lot of the details are wrong: using FLIBS, BLAS_LIBS and LIBS as
> intended will solve most of the problems.  I would use --disable-nls
> --disable-mbcs as you don't need them (and in particular you don't
> benefit from MBCS support on Windows unless you are in a CJK locale).
>
> Note that 2.5.1 is released and there is unlikely to be a 2.5.2, so any
> changes would be made only to R-devel.  It there is a convincing case to
> tailor a build for Cygwin there we can probably do so rather easily, but
> the need for ongoing support would be a worry.
>
> (If platforms are not used and in particular not tested in the
> alpha/beta testing phases then the ability to build on them crumbles
> away.  We seems to be down to regular testers on Linux, Windows, MacOS
> X, Solaris and FreeBSD, with some help on AIX after a patch with none.)
>
> On Tue, 21 Aug 2007, Duncan Murdoch wrote:
>
>> Denham Robert wrote:
>>> For various reasons,
>
> I think it is only courteous to mention some good reasons if you want to
> take up people's time.
>
>>> it suits our workplace to have a cygwin version of R.  I am pretty
>>> sure that cygwin is still not a supported environment for R, but we
>>> have managed to compile R-2.5.1 under cygwin without too many dramas.
>
>>> Our procedure is described below.  We still have a few problems
>>> compiling libraries without manually changing files from .so to .dll,
>
>>> but it seems ok.
>>>
>> I would expect other subtle problems as well, because Cygwin is not a
>> normal Unix.  I don't know whether any of these differences matter to
>> R, but some things to look out for are:
>>
>> - you can't unlink a file while it is open
>> - filenames are not case sensitive
>> - file permissions have strange defaults (everything is executable)
>> - I think the executable format still needs to be Windows format
>> - There's no such thing as a ptty
>> - You'll probably need X11 for graphics, and will lose support for
>> Windows metafile output (wmf)
>>>
>>> I was wondering whether this information is likely to be useful to
>>> others, and if we should spend any time looking in to ways in which
>>> the configure/build/install code could be modified to allow a
>>> standard install.
>>>
>> What is the advantage of building this?  I don't think we want to
>> support platforms just for the sake of supporting more platforms, but
>> if there's a real need for it, that would be different.
>>
>> Duncan Murdoch
>>>
>>> Notes on building R under cygwin:
>>>
>>> export FFLAGS=-O3
>>> export CFLAGS=-O3
>>> export CXXFLAGS=-O3
>>> export OBJCFLAGS=-O3
>>> export FCFLAGS=-O3
>>> export LDFLAGS='-lblas -lg2c -lintl'
>>>
>>> export R_OSTYPE=unix
>>>
>>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
>>> --with-tcl-config=/usr/lib/tclConfig.sh \
>>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \
>>> --with-lapack=-llapack \ --enable-R-shlib
>>>
>>> comment out Win32 in src/include/config.h and set Unix to 1, change
>>> .so to .dll. change .so to .dll and in Makeconf.
>>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>>>
>>> Change .so to .dll in Makefile's
>>>
>>> edit Makeconf and set R_OSTYPE to unix
>>>
>>> make -j2
>>>
>>> when blas doesn't link, re-run command with -lblas -lg2c on end and
>>> change output to .dll
>>>
>>> edit Rstrptime.c and change wcstod to atof.
>>>
>>> in modules:
>>> when X11 and internet falls over add -lintl to link line. add -lg2c
>>> and -lblas to lapack
>>>
>>> comment out library/base/R/library.R lines 47-51 to avoid arch check
>>> which seems to go wrong!
>>>
>>> make -j2
>>> make install
>>>
>>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl
>>> -lg2c -lblas' to the end of ALL_LIBS so the module building works.
>>> Change .so to .dll also (can't see how to to this for the build
>>> tho...)
>>>
>>>
>>> Our cygwin info is:
>>>              sysname              release              version
>>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
>>>
>>>
>>>
>>>
>>> Robert Denham
>>> Environmental Statistician
>>> Remote Sensing Centre
>>> Telephone 07 3896 9899
>>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
>>>
>>> Department of Natural Resources & Water QScape Building, 80 Meiers
>>> Road, Indooroopilly Qld 4068
>>>
>>> *********************************************************************
>>> *** The information in this email together with any attachments is
>>> intended only for the person or entity to which it is addressed and
>>> may contain confidential and/or privileged material.
>>> Any form of review, disclosure, modification, distribution and/or
>>> publication of this email message is prohibited, unless as a
>>> necessary part of Departmental business.
>>> If you have received this message in error, you are asked to inform
>>> the sender as quickly as possible and delete this message and any
>>> copies of this message from your computer and/or your computer system
>
>>> network.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From oehl_list at gmx.de  Thu Aug 23 12:30:30 2007
From: oehl_list at gmx.de (=?iso-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Thu, 23 Aug 2007 12:30:30 +0200
Subject: [Rd] indexing and regression testing
Message-ID: <20070823103030.131790@gmx.net>

Dear all,

It was a pleasure to meet you at Iowa State University. Two days ago I submitted two experimental packages to CRAN (hope it  will be there soon):

rindex: quick indexing of large objects (currently only character, see ?index)
regtest: some first support for automated regression testing (heavily used in \dontshow{} section of ?index)

With rindex you can for example

i <- index(rownames(someDataFrame))
# then this 
someDataFrame[match(fewRowNames, i),]
# is much faster than that
someDataFrame[match(fewRowNames, rownames(someDataFrame)),]
# which still is much faster than
someDataFrame[fewRowNames, ]
# the latter being surprisingly slow as it can be worked around by match (even without indexing)

I'd appreciate any comments, especially on the "Open Questions" secion in ?index, in order to
1) extend to all atomic types and be UTF8-safe
2) extend to packages R.huge and/or ff
3) optimally integrate with sort(OK), order(no generic yet) and match(no generic and dispatch rather needed on second argument)

Both packages were developed under 2.5.1 and I plan to publish them under a GPL2-QA, a GPL2 clone that obliges users to participate in some kind of regression testing (to be defined).

Best regards


Jens Oehlschl?gel



P.S. 

> # some timings using timefactor(regtest)
> library(rindex)
> 
> Vec1 <- c(NA, paste('a', 1:1000000, sep=""))
> Vec2 <- c(paste('a', 1:1000000, sep=""), NA)
> iVec1 <- index(Vec1, verbose=TRUE)
     user.self sys.self elapsed
sort      7.85     0.01    7.86
tree      0.00     0.00    0.00
> iVec2 <- index(Vec2, verbose=TRUE)
finalized tree
     user.self sys.self elapsed
sort      7.78        0    7.79
tree      0.00        0    0.00
> 
> timefactor(any(Vec1=="a999"), any(iVec1=="a999"), 10, 100)
finalized tree
            nom  denom   factor
user.self 0.041 0.0036 11.38889
sys.self  0.000 0.0000      NaN
elapsed   0.041 0.0036 11.38889
> timefactor(any(Vec2=="a999"), any(iVec2=="a999"), 10, 100)
            nom  denom   factor
user.self 0.040 0.0036 11.11111
sys.self  0.000 0.0000      NaN
elapsed   0.041 0.0036 11.38889
> 
> timefactor(length(match("a999", Vec1)), length(match("a999", iVec1)), 10, 1000)
            nom   denom   factor
user.self 0.125 0.00017 735.2941
sys.self  0.000 0.00000      NaN
elapsed   0.125 0.00018 694.4444
> timefactor(length(match("a999", Vec2)), length(match("a999", iVec2)), 10, 1000)
            nom   denom   factor
user.self 0.123 0.00015 820.0000
sys.self  0.003 0.00000      Inf
elapsed   0.127 0.00015 846.6667
> 
> timefactor(length(match(c("a9","a99","a999","a9999"), Vec1)), length(match(c("a9","a99","a999","a9999"), iVec1)), 10, 1000)
            nom   denom   factor
user.self 0.126 0.00022 572.7273
sys.self  0.000 0.00000      NaN
elapsed   0.127 0.00022 577.2727
> timefactor(length(match(c("a9","a99","a999","a9999"), Vec2)), length(match(c("a9","a99","a999","a9999"), iVec2)), 10, 1000)
            nom   denom   factor
user.self 0.125 0.00022 568.1818
sys.self  0.002 0.00000      Inf
elapsed   0.126 0.00022 572.7273
> 
> # and not too bad with respect to the recent hasNA() / anyNA() thread (once the index has been built)
> timefactor(any(is.na(Vec1)), any(is.na(iVec1)), 50, 50)
             nom denom   factor
user.self 0.0040 0.003 1.333333
sys.self  0.0004 0.000      Inf
elapsed   0.0044 0.003 1.466667
> timefactor(any(is.na(Vec2)), any(is.na(iVec2)), 50, 50)
             nom  denom   factor
user.self 0.0040 0.0036 1.111111
sys.self  0.0008 0.0000      Inf
elapsed   0.0046 0.0034 1.352941
> 
> # especially if using a better function for this
> timefactor(any(is.na(Vec1)), length(match(NA, iVec1)), 50, 1000)
             nom   denom   factor
user.self 0.0044 0.00013 33.84615
sys.self  0.0002 0.00000      Inf
elapsed   0.0046 0.00013 35.38462
> timefactor(any(is.na(Vec2)), length(match(NA, iVec2)), 50, 1000)
             nom   denom   factor
user.self 0.0044 0.00014 31.42857
sys.self  0.0000 0.00000      NaN
elapsed   0.0042 0.00014 30.00000
> 
> # or ask directly :-)
> timefactor(any(is.na(Vec1)), iVec1$nNA, 50, 10000)
             nom denom   factor
user.self 0.0044 9e-06 488.8889
sys.self  0.0000 0e+00      NaN
elapsed   0.0044 9e-06 488.8889
> timefactor(any(is.na(Vec2)), iVec2$nNA, 50, 10000)
             nom denom   factor
user.self 0.0046 1e-05 460.0000
sys.self  0.0000 0e+00      NaN
elapsed   0.0046 9e-06 511.1111
> 
> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.1                         
year           2007                        
month          06                          
day            27                          
svn rev        42083                       
language       R                           
version.string R version 2.5.1 (2007-06-27)






# some timings using timefactor(regtest)
library(rindex)

Vec1 <- c(NA, paste('a', 1:1000000, sep=""))
Vec2 <- c(paste('a', 1:1000000, sep=""), NA)
iVec1 <- index(Vec1, verbose=TRUE)
iVec2 <- index(Vec2, verbose=TRUE)

timefactor(any(Vec1=="a999"), any(iVec1=="a999"), 10, 100)
timefactor(any(Vec2=="a999"), any(iVec2=="a999"), 10, 100)

timefactor(length(match("a999", Vec1)), length(match("a999", iVec1)), 10, 1000)
timefactor(length(match("a999", Vec2)), length(match("a999", iVec2)), 10, 1000)

timefactor(length(match(c("a9","a99","a999","a9999"), Vec1)), length(match(c("a9","a99","a999","a9999"), iVec1)), 10, 1000)
timefactor(length(match(c("a9","a99","a999","a9999"), Vec2)), length(match(c("a9","a99","a999","a9999"), iVec2)), 10, 1000)

# and not too bad with respect to the recent hasNA() / anyNA() thread (once the index has been built)
timefactor(any(is.na(Vec1)), any(is.na(iVec1)), 50, 50)
timefactor(any(is.na(Vec2)), any(is.na(iVec2)), 50, 50)

# especially if using a better function for this
timefactor(any(is.na(Vec1)), length(match(NA, iVec1)), 50, 1000)
timefactor(any(is.na(Vec2)), length(match(NA, iVec2)), 50, 1000)

# or ask directly :-)
timefactor(any(is.na(Vec1)), iVec1$nNA, 50, 10000)
timefactor(any(is.na(Vec2)), iVec2$nNA, 50, 10000)

version

--


From h.y.wong at leeds.ac.uk  Wed Aug 22 14:48:17 2007
From: h.y.wong at leeds.ac.uk (h.y.wong at leeds.ac.uk)
Date: Wed, 22 Aug 2007 14:48:17 +0200 (CEST)
Subject: [Rd] nls fails with large numbers of variables (PR#9873)
Message-ID: <20070822124817.719D25D5FB@slim.kubism.ku.dk>

Full_Name: Yan Wong
Version: 2.5.1
OS: Mac OS X 10.4
Submission from: (NULL) (129.11.77.198)


If nls is called with a large number of variables & parameters (>200), then it
fails because of the default setting of max.names = 200 in the all.vars
function. I guess that nls should either give a meaningful warning ("you can
only have 200 names in an nls formula"), or should not have such a restriction.
If this restriction is kept, for my purposes it would be useful to have a way of
setting max.names in the nls call.

I encountered this in a real dataset, but  an example 

> #nls fails on 100 vars+ 100 params
> d<-data.frame(matrix(runif(100*1000), 1000, 100))
> y <- rowSums(d)+rnorm(1000)
> params <- paste("c", colnames(d), sep=".")
> st <- rep(1,100); names(st) <- params
> nls(as.formula(paste("y ~", paste(params, "*", colnames(d), collapse=" + "))),
data=d, start=st)
Error in eval(expr, envir, enclos) : object "X100" not found


> #works with 50 vars+ 50 params
> d<-data.frame(matrix(runif(100*1000), 1000, 50))
> y <- rowSums(d)+rnorm(1000)
> params <- paste("c", colnames(d), sep=".")
> st <- rep(1,50); names(st) <- params
> nls(as.formula(paste("y ~", paste(params, "*", colnames(d), collapse=" + "))),
data=d, start=st)
Nonlinear regression model
  model:  y ~ c.X1 * X1 + c.X2 * X2 + c.X3 * X3 + c.X4 * X4 + c.X5 * X5 +     
c.X6 * X6 + c.X7 * X7 + c.X8 * X8 + c.X9 * X9 + c.X10 * X10 +      c.X11 * X11 +
c.X12 * X12 + c.X13 * X13 + c.X14 * X14 + c.X15 *      X15 + c.X16 * X16 + c.X17
* X17 + c.X18 * X18 + c.X19 * X19 +      c.X20 * X20 + c.X21 * X21 + c.X22 * X22
+ c.X23 * X23 + c.X24 *      X24 + c.X25 * X25 + c.X26 * X26 + c.X27 * X27 +
c.X28 * X28 +      c.X29 * X29 + c.X30 * X30 + c.X31 * X31 + c.X32 * X32 + c.X33
*      X33 + c.X34 * X34 + c.X35 * X35 + c.X36 * X36 + c.X37 * X37 +      c.X38
* X38 + c.X39 * X39 + c.X40 * X40 + c.X41 * X41 + c.X42 *      X42 + c.X43 * X43
+ c.X44 * X44 + c.X45 * X45 + c.X46 * X46 +      c.X47 * X47 + c.X48 * X48 +
c.X49 * X49 + c.X50 * X50 
   data:  d 
  c.X1   c.X2   c.X3   c.X4   c.X5   c.X6   c.X7   c.X8   c.X9  c.X10  c.X11 
c.X12  c.X13  c.X14  c.X15  c.X16  c.X17  c.X18  c.X19  c.X20  c.X21  c.X22 
c.X23 
0.9400 0.9750 0.9614 1.1029 0.9663 1.1426 1.1534 1.0353 1.0560 0.8258 0.9527
1.1092 0.4769 0.8955 1.0689 0.7415 1.0656 1.0657 1.0430 1.1034 0.9392 1.1177
1.0712 
 c.X24  c.X25  c.X26  c.X27  c.X28  c.X29  c.X30  c.X31  c.X32  c.X33  c.X34 
c.X35  c.X36  c.X37  c.X38  c.X39  c.X40  c.X41  c.X42  c.X43  c.X44  c.X45 
c.X46 
0.8883 0.9722 1.1377 1.1142 0.9033 1.1225 0.7447 1.2757 0.8746 1.1901 1.1669
1.0322 0.9043 1.0546 1.0222 0.9641 1.0834 0.9977 1.0723 0.9720 1.0978 0.9222
0.8162 
 c.X47  c.X48  c.X49  c.X50 
0.8824 1.0690 1.0078 0.9063 
 residual sum-of-squares: 959.4

Number of iterations to convergence: 1 
Achieved convergence tolerance: 1.215e-07


From jari.oksanen at oulu.fi  Wed Aug 22 19:53:39 2007
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 22 Aug 2007 20:53:39 +0300
Subject: [Rd] paste() with NAs ..  change worth persuing?
In-Reply-To: <46CC6F7C.2010600@stats.uwo.ca>
References: <18124.23379.575814.316093@stat.math.ethz.ch>
	<46CC6F7C.2010600@stats.uwo.ca>
Message-ID: <2d3b61b809045fef4ca309796b8ac642@oulu.fi>


On 22 Aug 2007, at 20:16, Duncan Murdoch wrote:

> On 8/22/2007 11:50 AM, Martin Maechler wrote:
>> Consider this example code
>>
>>  c1 <- letters[1:7]; c2 <- LETTERS[1:7]
>>  c1[2] <- c2[3:4] <- NA
>>  rbind(c1,c2)
>>
>>   ##   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>>   ## c1 "a"  NA   "c"  "d"  "e"  "f"  "g"
>>   ## c2 "A"  "B"  NA   NA   "E"  "F"  "G"
>>
>>   paste(c1,c2)
>>
>>   ## -> [1] "a A"  "NA B" "c NA" "d NA" "e E"  "f F"  "g G"
>>
>> where a more logical result would have entries 2:4 equal to
>>       NA
>> i.e.,  as.character(NA)
>> aka    NA_character_
>>
>> Is this worth persuing, or does anyone see why not?
>
> A fairly common use of paste is to put together reports for human
> consumption.  Currently we have
>
>> p <- as.character(NA)
>> paste("the value of p is", p)
> [1] "the value of p is NA"
>
> which looks reasonable. Would this become
>
>> p <- as.character(NA)
>> paste("the value of p is", p)
> [1] NA
>
> under your proposal?  (In a quick search I was unable to find a real
> example where this would happen, but it would worry me...)

At least stop() seems to include such a case:

  message <- paste(args, collapse = "")

and we may expect there are NAs sometimes in stop().

cheers, jazza
--
Jari Oksanen, Oulu, Finland


From savicky at cs.cas.cz  Thu Aug 23 15:49:32 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 23 Aug 2007 15:49:32 +0200
Subject: [Rd] paste() with NAs ..  change worth persuing?
In-Reply-To: <2d3b61b809045fef4ca309796b8ac642@oulu.fi>
References: <18124.23379.575814.316093@stat.math.ethz.ch>
	<46CC6F7C.2010600@stats.uwo.ca>
	<2d3b61b809045fef4ca309796b8ac642@oulu.fi>
Message-ID: <20070823134932.GA28021@cs.cas.cz>

On Wed, Aug 22, 2007 at 08:53:39PM +0300, Jari Oksanen wrote:
> 
> On 22 Aug 2007, at 20:16, Duncan Murdoch wrote:
> > A fairly common use of paste is to put together reports for human
> > consumption.  Currently we have
> >
> >> p <- as.character(NA)
> >> paste("the value of p is", p)
> > [1] "the value of p is NA"
> >
> > which looks reasonable. Would this become
> >
> >> p <- as.character(NA)
> >> paste("the value of p is", p)
> > [1] NA
> >
> > under your proposal?  (In a quick search I was unable to find a real
> > example where this would happen, but it would worry me...)
> 
> At least stop() seems to include such a case:
> 
>   message <- paste(args, collapse = "")
> 
> and we may expect there are NAs sometimes in stop().

The examples show, that changing the behavior of paste in general
may not be appropriate. On the other hand, if we concatenate
character vectors, which are part of data, then is.na(paste(...,NA,...))
makes sense. Character vectors in data are usually represented
by factors. On the other hand, factors are not typical in cases,
where paste is used to produce a readable message. Hence, it
could be possible to have is.na(u[i]) for those i, for which
some of the vectors v1, ..., vn in
  u <- paste(v1,....,vn)
is a factor and has NA at i-th position.

Petr Savicky.


From ripley at stats.ox.ac.uk  Thu Aug 23 19:57:42 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 23 Aug 2007 19:57:42 +0200 (CEST)
Subject: [Rd] nls fails with large numbers of variables (PR#9873)
Message-ID: <20070823175742.B708D2070A@slim.kubism.ku.dk>

This is fixed in the current R-devel.

On Wed, 22 Aug 2007, h.y.wong at leeds.ac.uk wrote:

> Full_Name: Yan Wong
> Version: 2.5.1
> OS: Mac OS X 10.4
> Submission from: (NULL) (129.11.77.198)
>
>
> If nls is called with a large number of variables & parameters (>200), then it
> fails because of the default setting of max.names = 200 in the all.vars
> function. I guess that nls should either give a meaningful warning ("you can
> only have 200 names in an nls formula"), or should not have such a restriction.
> If this restriction is kept, for my purposes it would be useful to have a way of
> setting max.names in the nls call.
>
> I encountered this in a real dataset, but  an example
>
>> #nls fails on 100 vars+ 100 params
>> d<-data.frame(matrix(runif(100*1000), 1000, 100))
>> y <- rowSums(d)+rnorm(1000)
>> params <- paste("c", colnames(d), sep=".")
>> st <- rep(1,100); names(st) <- params
>> nls(as.formula(paste("y ~", paste(params, "*", colnames(d), collapse=" + "))),
> data=d, start=st)
> Error in eval(expr, envir, enclos) : object "X100" not found
>
>
>> #works with 50 vars+ 50 params
>> d<-data.frame(matrix(runif(100*1000), 1000, 50))
>> y <- rowSums(d)+rnorm(1000)
>> params <- paste("c", colnames(d), sep=".")
>> st <- rep(1,50); names(st) <- params
>> nls(as.formula(paste("y ~", paste(params, "*", colnames(d), collapse=" + "))),
> data=d, start=st)
> Nonlinear regression model
>  model:  y ~ c.X1 * X1 + c.X2 * X2 + c.X3 * X3 + c.X4 * X4 + c.X5 * X5 +
> c.X6 * X6 + c.X7 * X7 + c.X8 * X8 + c.X9 * X9 + c.X10 * X10 +      c.X11 * X11 +
> c.X12 * X12 + c.X13 * X13 + c.X14 * X14 + c.X15 *      X15 + c.X16 * X16 + c.X17
> * X17 + c.X18 * X18 + c.X19 * X19 +      c.X20 * X20 + c.X21 * X21 + c.X22 * X22
> + c.X23 * X23 + c.X24 *      X24 + c.X25 * X25 + c.X26 * X26 + c.X27 * X27 +
> c.X28 * X28 +      c.X29 * X29 + c.X30 * X30 + c.X31 * X31 + c.X32 * X32 + c.X33
> *      X33 + c.X34 * X34 + c.X35 * X35 + c.X36 * X36 + c.X37 * X37 +      c.X38
> * X38 + c.X39 * X39 + c.X40 * X40 + c.X41 * X41 + c.X42 *      X42 + c.X43 * X43
> + c.X44 * X44 + c.X45 * X45 + c.X46 * X46 +      c.X47 * X47 + c.X48 * X48 +
> c.X49 * X49 + c.X50 * X50
>   data:  d
>  c.X1   c.X2   c.X3   c.X4   c.X5   c.X6   c.X7   c.X8   c.X9  c.X10  c.X11
> c.X12  c.X13  c.X14  c.X15  c.X16  c.X17  c.X18  c.X19  c.X20  c.X21  c.X22
> c.X23
> 0.9400 0.9750 0.9614 1.1029 0.9663 1.1426 1.1534 1.0353 1.0560 0.8258 0.9527
> 1.1092 0.4769 0.8955 1.0689 0.7415 1.0656 1.0657 1.0430 1.1034 0.9392 1.1177
> 1.0712
> c.X24  c.X25  c.X26  c.X27  c.X28  c.X29  c.X30  c.X31  c.X32  c.X33  c.X34
> c.X35  c.X36  c.X37  c.X38  c.X39  c.X40  c.X41  c.X42  c.X43  c.X44  c.X45
> c.X46
> 0.8883 0.9722 1.1377 1.1142 0.9033 1.1225 0.7447 1.2757 0.8746 1.1901 1.1669
> 1.0322 0.9043 1.0546 1.0222 0.9641 1.0834 0.9977 1.0723 0.9720 1.0978 0.9222
> 0.8162
> c.X47  c.X48  c.X49  c.X50
> 0.8824 1.0690 1.0078 0.9063
> residual sum-of-squares: 959.4
>
> Number of iterations to convergence: 1
> Achieved convergence tolerance: 1.215e-07
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ldimitro at wfubmc.edu  Thu Aug 23 21:33:28 2007
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Thu, 23 Aug 2007 15:33:28 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>

 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> Sent: Thursday, August 23, 2007 2:54 AM
> To: Denham Robert
> Cc: r-devel at r-project.org; Duncan Murdoch
> Subject: Re: [Rd] compiling R under cygwin
> 
> On Thu, 23 Aug 2007, Denham Robert wrote:
> 
> >>> For various reasons,
> >> I think it is only courteous to mention some good reasons 
> if you want
> > to take up people's time.
> >
> > Some of the reasons we would like a cygwin version aren't 
> necessarily 
> > good reasons.  We have been using cygwin for sometime, 
> mostly to deal 
> > with scripting in a combined windows/unix environment.  We have a 
> > setup which allows windows users to run many scripts in the 
> same way 
> > as unix users.  These scripts are often python or shell 
> scripts.  We 
> > have R installed on the unix machines, and the system 
> administrators 
> > would like to be able to have R on windows in the same 
> environment.  
> > This set up also means that the administrator can fairly easily 
> > maintain the version of software used on all user's machines.  
> > Probably this could all be managed and still use the native windows 
> > version of R, but the administrator is familiar with cygwin 
> and they 
> > could manage this software in the same way they manage 
> other packages.
> 
> Yes, it could almost certainly be done with Rterm.exe.
> 
> The issue I came across was the so-called 'posix file paths' 
> that Cygwin uses.  Most (but not all) Windows programs accept 
> file paths with / as the path separator, and most (but not 
> all, e.g. tar) Cygwin programs accept paths of the forn 
> c:/path/to/file.  So provided you use that as your format, 
> interworking with Unix and Unix-like shells work fine.  It 
> used to be the case that if you had just one drive C: then 
> Cygwin programs produced paths of the form /path/to/file that 
> also worked on Windows.  Now they produce 
> /cygdrive/c/path/to/file that works nowhere else.

I'm not sure what you mean by "produce" above but one can easily setup
(by mount option) cygwin to use "/" instead of "/cygdrive/" so that your
example above will become "/c/path/to/file". That's if you insist on
using drive letters. Otherwise w/ proper mounting (in cygwin) one can
have "usual" *nix dir tree.

Regards,
Latchezar

PS. I really like the idea of having (the same) bare terminal/command
window interface to R anywhere as well as anything else (like admin
tasks above) to be the same. So please put my vote (if you care) to have
R Windows installation look the same as *nix (up to the point when you
start R from Start button to have terminal version started instead of
Rgui as it is now) and keep GUI candies separately for whoever
wants/needs them. Sorry if that's been already done and I did not know
about it.

> 
> In general this is a minor nuisance, but I needed to be able 
> to cross-build R in an environment where I only have 
> Cygwin-based cross-compilers, and there the path issues bit 
> me: I needed a version of R that accepted and returned 
> Cygwin-style paths.  So I made the configure changes 
> necessary to build R under Cygwin, and had it running in 20 mins.
> 
> > We would like to be able to use linux machines on pc's but 
> > unfortunately we have restrictions imposed on us that 
> prevent this.  
> > This restriction also goes as far as the use of virtual 
> machines.  My 
> > personal preference would be to run linux on my work pc, and use a 
> > virtual machine to run windows software, such as ArcGIS and 
> Imagine, 
> > that are not available for linux.  This does not seem to be 
> an option for us.
> >
> > One thing I was interested in was knowing if there are 
> others who also 
> > would like a cygwin version.  From the replies to my post, 
> and from a 
> > search of the mailing list archive, I think that there is little 
> > demand for this.  We would, however, be prepared to help in 
> some way 
> > for the few people who are interested.
> 
> As I said earlier, it builds out of the box in R-devel (with 
> suitable options documented in the R-admin manual).  No 
> guarantees that it will continue to do so unless tested in 
> the alpha/beta phase though.  As no other platform we use 
> nowadays requires that shared objects/dynamic libraries have 
> all imports satisfied at build time, this is liable to get broken.
> 
> But I would encourage people to use Rterm.exe if it can be 
> made to do what you need.
> 
> 
> >
> >
> >
> > Robert Denham
> > Environmental Statistician
> > Remote Sensing Centre
> > Telephone 07 3896 9899
> > www.nrw.qld.gov.au
> >
> > Department of Natural Resources & Water
> > QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
> >
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: Tuesday, 21 August 2007 9:53 PM
> > To: Duncan Murdoch
> > Cc: Denham Robert; r-devel at r-project.org
> > Subject: Re: [Rd] compiling R under cygwin
> >
> > Yes,
> >
> >> What is the advantage of building this?
> >
> > was my question too.  If you want a Unix-like version of R on PC
> > hardware running Windows why not run a Unix-like OS under a virtual
> > machine?
> >
> > Quite a lot of the details are wrong: using FLIBS, 
> BLAS_LIBS and LIBS as
> > intended will solve most of the problems.  I would use --disable-nls
> > --disable-mbcs as you don't need them (and in particular you don't
> > benefit from MBCS support on Windows unless you are in a 
> CJK locale).
> >
> > Note that 2.5.1 is released and there is unlikely to be a 
> 2.5.2, so any
> > changes would be made only to R-devel.  It there is a 
> convincing case to
> > tailor a build for Cygwin there we can probably do so 
> rather easily, but
> > the need for ongoing support would be a worry.
> >
> > (If platforms are not used and in particular not tested in the
> > alpha/beta testing phases then the ability to build on them crumbles
> > away.  We seems to be down to regular testers on Linux, 
> Windows, MacOS
> > X, Solaris and FreeBSD, with some help on AIX after a patch 
> with none.)
> >
> > On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> >
> >> Denham Robert wrote:
> >>> For various reasons,
> >
> > I think it is only courteous to mention some good reasons 
> if you want to
> > take up people's time.
> >
> >>> it suits our workplace to have a cygwin version of R.  I am pretty
> >>> sure that cygwin is still not a supported environment for 
> R, but we
> >>> have managed to compile R-2.5.1 under cygwin without too 
> many dramas.
> >
> >>> Our procedure is described below.  We still have a few problems
> >>> compiling libraries without manually changing files from 
> .so to .dll,
> >
> >>> but it seems ok.
> >>>
> >> I would expect other subtle problems as well, because 
> Cygwin is not a
> >> normal Unix.  I don't know whether any of these 
> differences matter to
> >> R, but some things to look out for are:
> >>
> >> - you can't unlink a file while it is open
> >> - filenames are not case sensitive
> >> - file permissions have strange defaults (everything is executable)
> >> - I think the executable format still needs to be Windows format
> >> - There's no such thing as a ptty
> >> - You'll probably need X11 for graphics, and will lose support for
> >> Windows metafile output (wmf)
> >>>
> >>> I was wondering whether this information is likely to be useful to
> >>> others, and if we should spend any time looking in to 
> ways in which
> >>> the configure/build/install code could be modified to allow a
> >>> standard install.
> >>>
> >> What is the advantage of building this?  I don't think we want to
> >> support platforms just for the sake of supporting more 
> platforms, but
> >> if there's a real need for it, that would be different.
> >>
> >> Duncan Murdoch
> >>>
> >>> Notes on building R under cygwin:
> >>>
> >>> export FFLAGS=-O3
> >>> export CFLAGS=-O3
> >>> export CXXFLAGS=-O3
> >>> export OBJCFLAGS=-O3
> >>> export FCFLAGS=-O3
> >>> export LDFLAGS='-lblas -lg2c -lintl'
> >>>
> >>> export R_OSTYPE=unix
> >>>
> >>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
> >>> --with-tcl-config=/usr/lib/tclConfig.sh \
> >>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \
> >>> --with-lapack=-llapack \ --enable-R-shlib
> >>>
> >>> comment out Win32 in src/include/config.h and set Unix to 
> 1, change
> >>> .so to .dll. change .so to .dll and in Makeconf.
> >>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> >>>
> >>> Change .so to .dll in Makefile's
> >>>
> >>> edit Makeconf and set R_OSTYPE to unix
> >>>
> >>> make -j2
> >>>
> >>> when blas doesn't link, re-run command with -lblas -lg2c 
> on end and
> >>> change output to .dll
> >>>
> >>> edit Rstrptime.c and change wcstod to atof.
> >>>
> >>> in modules:
> >>> when X11 and internet falls over add -lintl to link line. 
> add -lg2c
> >>> and -lblas to lapack
> >>>
> >>> comment out library/base/R/library.R lines 47-51 to avoid 
> arch check
> >>> which seems to go wrong!
> >>>
> >>> make -j2
> >>> make install
> >>>
> >>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl
> >>> -lg2c -lblas' to the end of ALL_LIBS so the module building works.
> >>> Change .so to .dll also (can't see how to to this for the build
> >>> tho...)
> >>>
> >>>
> >>> Our cygwin info is:
> >>>              sysname              release              version
> >>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
> >>>
> >>>
> >>>
> >>>
> >>> Robert Denham
> >>> Environmental Statistician
> >>> Remote Sensing Centre
> >>> Telephone 07 3896 9899
> >>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> >>>
> >>> Department of Natural Resources & Water QScape Building, 80 Meiers
> >>> Road, Indooroopilly Qld 4068
> >>>
> >>> 
> *********************************************************************
> >>> *** The information in this email together with any attachments is
> >>> intended only for the person or entity to which it is 
> addressed and
> >>> may contain confidential and/or privileged material.
> >>> Any form of review, disclosure, modification, distribution and/or
> >>> publication of this email message is prohibited, unless as a
> >>> necessary part of Departmental business.
> >>> If you have received this message in error, you are asked 
> to inform
> >>> the sender as quickly as possible and delete this message and any
> >>> copies of this message from your computer and/or your 
> computer system
> >
> >>> network.
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Thu Aug 23 22:01:02 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Aug 2007 16:01:02 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
Message-ID: <971536df0708231301wd72e7d1p37c4e0d02b9c3d4b@mail.gmail.com>

Having it be the same under cygwin as it is for other UNIX systems would
be ok but for the native Windows port R should behave like other
Windows applications, not like UNIX applications.

On 8/23/07, Latchezar (Lucho) Dimitrov <ldimitro at wfubmc.edu> wrote:
>
>
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> > Sent: Thursday, August 23, 2007 2:54 AM
> > To: Denham Robert
> > Cc: r-devel at r-project.org; Duncan Murdoch
> > Subject: Re: [Rd] compiling R under cygwin
> >
> > On Thu, 23 Aug 2007, Denham Robert wrote:
> >
> > >>> For various reasons,
> > >> I think it is only courteous to mention some good reasons
> > if you want
> > > to take up people's time.
> > >
> > > Some of the reasons we would like a cygwin version aren't
> > necessarily
> > > good reasons.  We have been using cygwin for sometime,
> > mostly to deal
> > > with scripting in a combined windows/unix environment.  We have a
> > > setup which allows windows users to run many scripts in the
> > same way
> > > as unix users.  These scripts are often python or shell
> > scripts.  We
> > > have R installed on the unix machines, and the system
> > administrators
> > > would like to be able to have R on windows in the same
> > environment.
> > > This set up also means that the administrator can fairly easily
> > > maintain the version of software used on all user's machines.
> > > Probably this could all be managed and still use the native windows
> > > version of R, but the administrator is familiar with cygwin
> > and they
> > > could manage this software in the same way they manage
> > other packages.
> >
> > Yes, it could almost certainly be done with Rterm.exe.
> >
> > The issue I came across was the so-called 'posix file paths'
> > that Cygwin uses.  Most (but not all) Windows programs accept
> > file paths with / as the path separator, and most (but not
> > all, e.g. tar) Cygwin programs accept paths of the forn
> > c:/path/to/file.  So provided you use that as your format,
> > interworking with Unix and Unix-like shells work fine.  It
> > used to be the case that if you had just one drive C: then
> > Cygwin programs produced paths of the form /path/to/file that
> > also worked on Windows.  Now they produce
> > /cygdrive/c/path/to/file that works nowhere else.
>
> I'm not sure what you mean by "produce" above but one can easily setup
> (by mount option) cygwin to use "/" instead of "/cygdrive/" so that your
> example above will become "/c/path/to/file". That's if you insist on
> using drive letters. Otherwise w/ proper mounting (in cygwin) one can
> have "usual" *nix dir tree.
>
> Regards,
> Latchezar
>
> PS. I really like the idea of having (the same) bare terminal/command
> window interface to R anywhere as well as anything else (like admin
> tasks above) to be the same. So please put my vote (if you care) to have
> R Windows installation look the same as *nix (up to the point when you
> start R from Start button to have terminal version started instead of
> Rgui as it is now) and keep GUI candies separately for whoever
> wants/needs them. Sorry if that's been already done and I did not know
> about it.
>
> >
> > In general this is a minor nuisance, but I needed to be able
> > to cross-build R in an environment where I only have
> > Cygwin-based cross-compilers, and there the path issues bit
> > me: I needed a version of R that accepted and returned
> > Cygwin-style paths.  So I made the configure changes
> > necessary to build R under Cygwin, and had it running in 20 mins.
> >
> > > We would like to be able to use linux machines on pc's but
> > > unfortunately we have restrictions imposed on us that
> > prevent this.
> > > This restriction also goes as far as the use of virtual
> > machines.  My
> > > personal preference would be to run linux on my work pc, and use a
> > > virtual machine to run windows software, such as ArcGIS and
> > Imagine,
> > > that are not available for linux.  This does not seem to be
> > an option for us.
> > >
> > > One thing I was interested in was knowing if there are
> > others who also
> > > would like a cygwin version.  From the replies to my post,
> > and from a
> > > search of the mailing list archive, I think that there is little
> > > demand for this.  We would, however, be prepared to help in
> > some way
> > > for the few people who are interested.
> >
> > As I said earlier, it builds out of the box in R-devel (with
> > suitable options documented in the R-admin manual).  No
> > guarantees that it will continue to do so unless tested in
> > the alpha/beta phase though.  As no other platform we use
> > nowadays requires that shared objects/dynamic libraries have
> > all imports satisfied at build time, this is liable to get broken.
> >
> > But I would encourage people to use Rterm.exe if it can be
> > made to do what you need.
> >
> >
> > >
> > >
> > >
> > > Robert Denham
> > > Environmental Statistician
> > > Remote Sensing Centre
> > > Telephone 07 3896 9899
> > > www.nrw.qld.gov.au
> > >
> > > Department of Natural Resources & Water
> > > QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
> > >
> > > -----Original Message-----
> > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > Sent: Tuesday, 21 August 2007 9:53 PM
> > > To: Duncan Murdoch
> > > Cc: Denham Robert; r-devel at r-project.org
> > > Subject: Re: [Rd] compiling R under cygwin
> > >
> > > Yes,
> > >
> > >> What is the advantage of building this?
> > >
> > > was my question too.  If you want a Unix-like version of R on PC
> > > hardware running Windows why not run a Unix-like OS under a virtual
> > > machine?
> > >
> > > Quite a lot of the details are wrong: using FLIBS,
> > BLAS_LIBS and LIBS as
> > > intended will solve most of the problems.  I would use --disable-nls
> > > --disable-mbcs as you don't need them (and in particular you don't
> > > benefit from MBCS support on Windows unless you are in a
> > CJK locale).
> > >
> > > Note that 2.5.1 is released and there is unlikely to be a
> > 2.5.2, so any
> > > changes would be made only to R-devel.  It there is a
> > convincing case to
> > > tailor a build for Cygwin there we can probably do so
> > rather easily, but
> > > the need for ongoing support would be a worry.
> > >
> > > (If platforms are not used and in particular not tested in the
> > > alpha/beta testing phases then the ability to build on them crumbles
> > > away.  We seems to be down to regular testers on Linux,
> > Windows, MacOS
> > > X, Solaris and FreeBSD, with some help on AIX after a patch
> > with none.)
> > >
> > > On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> > >
> > >> Denham Robert wrote:
> > >>> For various reasons,
> > >
> > > I think it is only courteous to mention some good reasons
> > if you want to
> > > take up people's time.
> > >
> > >>> it suits our workplace to have a cygwin version of R.  I am pretty
> > >>> sure that cygwin is still not a supported environment for
> > R, but we
> > >>> have managed to compile R-2.5.1 under cygwin without too
> > many dramas.
> > >
> > >>> Our procedure is described below.  We still have a few problems
> > >>> compiling libraries without manually changing files from
> > .so to .dll,
> > >
> > >>> but it seems ok.
> > >>>
> > >> I would expect other subtle problems as well, because
> > Cygwin is not a
> > >> normal Unix.  I don't know whether any of these
> > differences matter to
> > >> R, but some things to look out for are:
> > >>
> > >> - you can't unlink a file while it is open
> > >> - filenames are not case sensitive
> > >> - file permissions have strange defaults (everything is executable)
> > >> - I think the executable format still needs to be Windows format
> > >> - There's no such thing as a ptty
> > >> - You'll probably need X11 for graphics, and will lose support for
> > >> Windows metafile output (wmf)
> > >>>
> > >>> I was wondering whether this information is likely to be useful to
> > >>> others, and if we should spend any time looking in to
> > ways in which
> > >>> the configure/build/install code could be modified to allow a
> > >>> standard install.
> > >>>
> > >> What is the advantage of building this?  I don't think we want to
> > >> support platforms just for the sake of supporting more
> > platforms, but
> > >> if there's a real need for it, that would be different.
> > >>
> > >> Duncan Murdoch
> > >>>
> > >>> Notes on building R under cygwin:
> > >>>
> > >>> export FFLAGS=-O3
> > >>> export CFLAGS=-O3
> > >>> export CXXFLAGS=-O3
> > >>> export OBJCFLAGS=-O3
> > >>> export FCFLAGS=-O3
> > >>> export LDFLAGS='-lblas -lg2c -lintl'
> > >>>
> > >>> export R_OSTYPE=unix
> > >>>
> > >>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
> > >>> --with-tcl-config=/usr/lib/tclConfig.sh \
> > >>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \
> > >>> --with-lapack=-llapack \ --enable-R-shlib
> > >>>
> > >>> comment out Win32 in src/include/config.h and set Unix to
> > 1, change
> > >>> .so to .dll. change .so to .dll and in Makeconf.
> > >>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> > >>>
> > >>> Change .so to .dll in Makefile's
> > >>>
> > >>> edit Makeconf and set R_OSTYPE to unix
> > >>>
> > >>> make -j2
> > >>>
> > >>> when blas doesn't link, re-run command with -lblas -lg2c
> > on end and
> > >>> change output to .dll
> > >>>
> > >>> edit Rstrptime.c and change wcstod to atof.
> > >>>
> > >>> in modules:
> > >>> when X11 and internet falls over add -lintl to link line.
> > add -lg2c
> > >>> and -lblas to lapack
> > >>>
> > >>> comment out library/base/R/library.R lines 47-51 to avoid
> > arch check
> > >>> which seems to go wrong!
> > >>>
> > >>> make -j2
> > >>> make install
> > >>>
> > >>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl
> > >>> -lg2c -lblas' to the end of ALL_LIBS so the module building works.
> > >>> Change .so to .dll also (can't see how to to this for the build
> > >>> tho...)
> > >>>
> > >>>
> > >>> Our cygwin info is:
> > >>>              sysname              release              version
> > >>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
> > >>>
> > >>>
> > >>>
> > >>>
> > >>> Robert Denham
> > >>> Environmental Statistician
> > >>> Remote Sensing Centre
> > >>> Telephone 07 3896 9899
> > >>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> > >>>
> > >>> Department of Natural Resources & Water QScape Building, 80 Meiers
> > >>> Road, Indooroopilly Qld 4068
> > >>>
> > >>>
> > *********************************************************************
> > >>> *** The information in this email together with any attachments is
> > >>> intended only for the person or entity to which it is
> > addressed and
> > >>> may contain confidential and/or privileged material.
> > >>> Any form of review, disclosure, modification, distribution and/or
> > >>> publication of this email message is prohibited, unless as a
> > >>> necessary part of Departmental business.
> > >>> If you have received this message in error, you are asked
> > to inform
> > >>> the sender as quickly as possible and delete this message and any
> > >>> copies of this message from your computer and/or your
> > computer system
> > >
> > >>> network.
> > >>>
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> > >
> > >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ldimitro at wfubmc.edu  Thu Aug 23 22:42:57 2007
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Thu, 23 Aug 2007 16:42:57 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <971536df0708231301wd72e7d1p37c4e0d02b9c3d4b@mail.gmail.com>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<971536df0708231301wd72e7d1p37c4e0d02b9c3d4b@mail.gmail.com>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A7@EXCHVS1.medctr.ad.wfubmc.edu>

Depending on what you mean by "native". Anyway, I'd rather have it
uniform to use and easy to maintain across the platforms then keeping
the face of the host os. In any case what I'd suggested is to have the
uniform setup everywhere and "os" specific somewhere in case anybody
needs it. How is that bad? I can tell you it would be a very big issue
to make a "native Windows" user of R to find setwd() on *nix platform.
BTW, R preferred usage is CLI, isn't it. CLI is fully maintained on
Windows too. 

Please also note I did not mention cygwin or something and did not
express any attitude to the port/implementation.

Finally I just wanted to have my vote put there (apparently not where
your vote is) not to argue.

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
> Sent: Thursday, August 23, 2007 4:01 PM
> To: Latchezar (Lucho) Dimitrov
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] compiling R under cygwin
> 
> Having it be the same under cygwin as it is for other UNIX 
> systems would be ok but for the native Windows port R should 
> behave like other Windows applications, not like UNIX applications.
> 
> On 8/23/07, Latchezar (Lucho) Dimitrov <ldimitro at wfubmc.edu> wrote:
> >
> >
> > > -----Original Message-----
> > > From: r-devel-bounces at r-project.org
> > > [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian 
> > > Ripley
> > > Sent: Thursday, August 23, 2007 2:54 AM
> > > To: Denham Robert
> > > Cc: r-devel at r-project.org; Duncan Murdoch
> > > Subject: Re: [Rd] compiling R under cygwin
> > >
> > > On Thu, 23 Aug 2007, Denham Robert wrote:
> > >
> > > >>> For various reasons,
> > > >> I think it is only courteous to mention some good reasons
> > > if you want
> > > > to take up people's time.
> > > >
> > > > Some of the reasons we would like a cygwin version aren't
> > > necessarily
> > > > good reasons.  We have been using cygwin for sometime,
> > > mostly to deal
> > > > with scripting in a combined windows/unix environment.  
> We have a 
> > > > setup which allows windows users to run many scripts in the
> > > same way
> > > > as unix users.  These scripts are often python or shell
> > > scripts.  We
> > > > have R installed on the unix machines, and the system
> > > administrators
> > > > would like to be able to have R on windows in the same
> > > environment.
> > > > This set up also means that the administrator can fairly easily 
> > > > maintain the version of software used on all user's machines.
> > > > Probably this could all be managed and still use the native 
> > > > windows version of R, but the administrator is familiar with 
> > > > cygwin
> > > and they
> > > > could manage this software in the same way they manage
> > > other packages.
> > >
> > > Yes, it could almost certainly be done with Rterm.exe.
> > >
> > > The issue I came across was the so-called 'posix file paths'
> > > that Cygwin uses.  Most (but not all) Windows programs 
> accept file 
> > > paths with / as the path separator, and most (but not 
> all, e.g. tar) 
> > > Cygwin programs accept paths of the forn c:/path/to/file.  So 
> > > provided you use that as your format, interworking with Unix and 
> > > Unix-like shells work fine.  It used to be the case that 
> if you had 
> > > just one drive C: then Cygwin programs produced paths of the form 
> > > /path/to/file that also worked on Windows.  Now they produce 
> > > /cygdrive/c/path/to/file that works nowhere else.
> >
> > I'm not sure what you mean by "produce" above but one can 
> easily setup 
> > (by mount option) cygwin to use "/" instead of "/cygdrive/" so that 
> > your example above will become "/c/path/to/file". That's if 
> you insist 
> > on using drive letters. Otherwise w/ proper mounting (in 
> cygwin) one 
> > can have "usual" *nix dir tree.
> >
> > Regards,
> > Latchezar
> >
> > PS. I really like the idea of having (the same) bare 
> terminal/command 
> > window interface to R anywhere as well as anything else (like admin 
> > tasks above) to be the same. So please put my vote (if you care) to 
> > have R Windows installation look the same as *nix (up to the point 
> > when you start R from Start button to have terminal version started 
> > instead of Rgui as it is now) and keep GUI candies separately for 
> > whoever wants/needs them. Sorry if that's been already done 
> and I did 
> > not know about it.
> >
> > >
> > > In general this is a minor nuisance, but I needed to be able to 
> > > cross-build R in an environment where I only have Cygwin-based 
> > > cross-compilers, and there the path issues bit
> > > me: I needed a version of R that accepted and returned 
> Cygwin-style 
> > > paths.  So I made the configure changes necessary to 
> build R under 
> > > Cygwin, and had it running in 20 mins.
> > >
> > > > We would like to be able to use linux machines on pc's but 
> > > > unfortunately we have restrictions imposed on us that
> > > prevent this.
> > > > This restriction also goes as far as the use of virtual
> > > machines.  My
> > > > personal preference would be to run linux on my work 
> pc, and use a 
> > > > virtual machine to run windows software, such as ArcGIS and
> > > Imagine,
> > > > that are not available for linux.  This does not seem to be
> > > an option for us.
> > > >
> > > > One thing I was interested in was knowing if there are
> > > others who also
> > > > would like a cygwin version.  From the replies to my post,
> > > and from a
> > > > search of the mailing list archive, I think that there 
> is little 
> > > > demand for this.  We would, however, be prepared to help in
> > > some way
> > > > for the few people who are interested.
> > >
> > > As I said earlier, it builds out of the box in R-devel (with 
> > > suitable options documented in the R-admin manual).  No 
> guarantees 
> > > that it will continue to do so unless tested in the 
> alpha/beta phase 
> > > though.  As no other platform we use nowadays requires 
> that shared 
> > > objects/dynamic libraries have all imports satisfied at 
> build time, 
> > > this is liable to get broken.
> > >
> > > But I would encourage people to use Rterm.exe if it can 
> be made to 
> > > do what you need.
> > >
> > >
> > > >
> > > >
> > > >
> > > > Robert Denham
> > > > Environmental Statistician
> > > > Remote Sensing Centre
> > > > Telephone 07 3896 9899
> > > > www.nrw.qld.gov.au
> > > >
> > > > Department of Natural Resources & Water QScape 
> Building, 80 Meiers 
> > > > Road, Indooroopilly Qld 4068
> > > >
> > > > -----Original Message-----
> > > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > > Sent: Tuesday, 21 August 2007 9:53 PM
> > > > To: Duncan Murdoch
> > > > Cc: Denham Robert; r-devel at r-project.org
> > > > Subject: Re: [Rd] compiling R under cygwin
> > > >
> > > > Yes,
> > > >
> > > >> What is the advantage of building this?
> > > >
> > > > was my question too.  If you want a Unix-like version 
> of R on PC 
> > > > hardware running Windows why not run a Unix-like OS under a 
> > > > virtual machine?
> > > >
> > > > Quite a lot of the details are wrong: using FLIBS,
> > > BLAS_LIBS and LIBS as
> > > > intended will solve most of the problems.  I would use 
> > > > --disable-nls --disable-mbcs as you don't need them (and in 
> > > > particular you don't benefit from MBCS support on 
> Windows unless 
> > > > you are in a
> > > CJK locale).
> > > >
> > > > Note that 2.5.1 is released and there is unlikely to be a
> > > 2.5.2, so any
> > > > changes would be made only to R-devel.  It there is a
> > > convincing case to
> > > > tailor a build for Cygwin there we can probably do so
> > > rather easily, but
> > > > the need for ongoing support would be a worry.
> > > >
> > > > (If platforms are not used and in particular not tested in the 
> > > > alpha/beta testing phases then the ability to build on them 
> > > > crumbles away.  We seems to be down to regular testers on Linux,
> > > Windows, MacOS
> > > > X, Solaris and FreeBSD, with some help on AIX after a patch
> > > with none.)
> > > >
> > > > On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> > > >
> > > >> Denham Robert wrote:
> > > >>> For various reasons,
> > > >
> > > > I think it is only courteous to mention some good reasons
> > > if you want to
> > > > take up people's time.
> > > >
> > > >>> it suits our workplace to have a cygwin version of R.  I am 
> > > >>> pretty sure that cygwin is still not a supported 
> environment for
> > > R, but we
> > > >>> have managed to compile R-2.5.1 under cygwin without too
> > > many dramas.
> > > >
> > > >>> Our procedure is described below.  We still have a 
> few problems 
> > > >>> compiling libraries without manually changing files from
> > > .so to .dll,
> > > >
> > > >>> but it seems ok.
> > > >>>
> > > >> I would expect other subtle problems as well, because
> > > Cygwin is not a
> > > >> normal Unix.  I don't know whether any of these
> > > differences matter to
> > > >> R, but some things to look out for are:
> > > >>
> > > >> - you can't unlink a file while it is open
> > > >> - filenames are not case sensitive
> > > >> - file permissions have strange defaults (everything is 
> > > >> executable)
> > > >> - I think the executable format still needs to be 
> Windows format
> > > >> - There's no such thing as a ptty
> > > >> - You'll probably need X11 for graphics, and will lose support 
> > > >> for Windows metafile output (wmf)
> > > >>>
> > > >>> I was wondering whether this information is likely to 
> be useful 
> > > >>> to others, and if we should spend any time looking in to
> > > ways in which
> > > >>> the configure/build/install code could be modified to allow a 
> > > >>> standard install.
> > > >>>
> > > >> What is the advantage of building this?  I don't think 
> we want to 
> > > >> support platforms just for the sake of supporting more
> > > platforms, but
> > > >> if there's a real need for it, that would be different.
> > > >>
> > > >> Duncan Murdoch
> > > >>>
> > > >>> Notes on building R under cygwin:
> > > >>>
> > > >>> export FFLAGS=-O3
> > > >>> export CFLAGS=-O3
> > > >>> export CXXFLAGS=-O3
> > > >>> export OBJCFLAGS=-O3
> > > >>> export FCFLAGS=-O3
> > > >>> export LDFLAGS='-lblas -lg2c -lintl'
> > > >>>
> > > >>> export R_OSTYPE=unix
> > > >>>
> > > >>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \ 
> > > >>> --with-tcl-config=/usr/lib/tclConfig.sh \ 
> > > >>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \ 
> > > >>> --with-lapack=-llapack \ --enable-R-shlib
> > > >>>
> > > >>> comment out Win32 in src/include/config.h and set Unix to
> > > 1, change
> > > >>> .so to .dll. change .so to .dll and in Makeconf.
> > > >>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> > > >>>
> > > >>> Change .so to .dll in Makefile's
> > > >>>
> > > >>> edit Makeconf and set R_OSTYPE to unix
> > > >>>
> > > >>> make -j2
> > > >>>
> > > >>> when blas doesn't link, re-run command with -lblas -lg2c
> > > on end and
> > > >>> change output to .dll
> > > >>>
> > > >>> edit Rstrptime.c and change wcstod to atof.
> > > >>>
> > > >>> in modules:
> > > >>> when X11 and internet falls over add -lintl to link line.
> > > add -lg2c
> > > >>> and -lblas to lapack
> > > >>>
> > > >>> comment out library/base/R/library.R lines 47-51 to avoid
> > > arch check
> > > >>> which seems to go wrong!
> > > >>>
> > > >>> make -j2
> > > >>> make install
> > > >>>
> > > >>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and 
> add '-lintl 
> > > >>> -lg2c -lblas' to the end of ALL_LIBS so the module 
> building works.
> > > >>> Change .so to .dll also (can't see how to to this for 
> the build
> > > >>> tho...)
> > > >>>
> > > >>>
> > > >>> Our cygwin info is:
> > > >>>              sysname              release              version
> > > >>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
> > > >>>
> > > >>>
> > > >>>
> > > >>>
> > > >>> Robert Denham
> > > >>> Environmental Statistician
> > > >>> Remote Sensing Centre
> > > >>> Telephone 07 3896 9899
> > > >>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> > > >>>
> > > >>> Department of Natural Resources & Water QScape Building, 80 
> > > >>> Meiers Road, Indooroopilly Qld 4068
> > > >>>
> > > >>>
> > > 
> ********************************************************************
> > > *
> > > >>> *** The information in this email together with any 
> attachments 
> > > >>> is intended only for the person or entity to which it is
> > > addressed and
> > > >>> may contain confidential and/or privileged material.
> > > >>> Any form of review, disclosure, modification, distribution 
> > > >>> and/or publication of this email message is 
> prohibited, unless 
> > > >>> as a necessary part of Departmental business.
> > > >>> If you have received this message in error, you are asked
> > > to inform
> > > >>> the sender as quickly as possible and delete this message and 
> > > >>> any copies of this message from your computer and/or your
> > > computer system
> > > >
> > > >>> network.
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-devel at r-project.org mailing list 
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>>
> > > >>
> > > >> ______________________________________________
> > > >> R-devel at r-project.org mailing list 
> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>
> > > >
> > > >
> > >
> > > --
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From ggrothendieck at gmail.com  Thu Aug 23 23:02:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Aug 2007 17:02:29 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A7@EXCHVS1.medctr.ad.wfubmc.edu>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<971536df0708231301wd72e7d1p37c4e0d02b9c3d4b@mail.gmail.com>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A7@EXCHVS1.medctr.ad.wfubmc.edu>
Message-ID: <971536df0708231402m28771b1dud98aec69db21c4cd@mail.gmail.com>

Many people, probably about half, of R users are Windows users either
primarily or only and most would expect all their programs on their Windows
machine to work in the same consistent way as all other Windows programs
following a certain Windows look and feel and way of operating.

Software which follows a UNIX look and feel and way of operating is hard
or jarring to use when all the other software on your system follows the
Windows way.  There is a special Windows version of R that is distinct
for a good reason.

If a cygwin version of R were to exist for UNIX people who want to use
R on Windows who basically want to use UNIX on top of Windows
that would be ok but that is not Windows.  Rather, cygwin is primarily a
UNIX system that happens to sit on Windows.  The normal Windows
version of R that most people use is and should be Windows centric.

Regarding your question, native means the ordinary R version on Windows
as opposed to a special cygwin version that might exist in the future.

On 8/23/07, Latchezar (Lucho) Dimitrov <ldimitro at wfubmc.edu> wrote:
> Depending on what you mean by "native". Anyway, I'd rather have it
> uniform to use and easy to maintain across the platforms then keeping
> the face of the host os. In any case what I'd suggested is to have the
> uniform setup everywhere and "os" specific somewhere in case anybody
> needs it. How is that bad? I can tell you it would be a very big issue
> to make a "native Windows" user of R to find setwd() on *nix platform.
> BTW, R preferred usage is CLI, isn't it. CLI is fully maintained on
> Windows too.
>
> Please also note I did not mention cygwin or something and did not
> express any attitude to the port/implementation.
>
> Finally I just wanted to have my vote put there (apparently not where
> your vote is) not to argue.
>
> > -----Original Message-----
> > From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> > Sent: Thursday, August 23, 2007 4:01 PM
> > To: Latchezar (Lucho) Dimitrov
> > Cc: r-devel at r-project.org
> > Subject: Re: [Rd] compiling R under cygwin
> >
> > Having it be the same under cygwin as it is for other UNIX
> > systems would be ok but for the native Windows port R should
> > behave like other Windows applications, not like UNIX applications.
> >
> > On 8/23/07, Latchezar (Lucho) Dimitrov <ldimitro at wfubmc.edu> wrote:
> > >
> > >
> > > > -----Original Message-----
> > > > From: r-devel-bounces at r-project.org
> > > > [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian
> > > > Ripley
> > > > Sent: Thursday, August 23, 2007 2:54 AM
> > > > To: Denham Robert
> > > > Cc: r-devel at r-project.org; Duncan Murdoch
> > > > Subject: Re: [Rd] compiling R under cygwin
> > > >
> > > > On Thu, 23 Aug 2007, Denham Robert wrote:
> > > >
> > > > >>> For various reasons,
> > > > >> I think it is only courteous to mention some good reasons
> > > > if you want
> > > > > to take up people's time.
> > > > >
> > > > > Some of the reasons we would like a cygwin version aren't
> > > > necessarily
> > > > > good reasons.  We have been using cygwin for sometime,
> > > > mostly to deal
> > > > > with scripting in a combined windows/unix environment.
> > We have a
> > > > > setup which allows windows users to run many scripts in the
> > > > same way
> > > > > as unix users.  These scripts are often python or shell
> > > > scripts.  We
> > > > > have R installed on the unix machines, and the system
> > > > administrators
> > > > > would like to be able to have R on windows in the same
> > > > environment.
> > > > > This set up also means that the administrator can fairly easily
> > > > > maintain the version of software used on all user's machines.
> > > > > Probably this could all be managed and still use the native
> > > > > windows version of R, but the administrator is familiar with
> > > > > cygwin
> > > > and they
> > > > > could manage this software in the same way they manage
> > > > other packages.
> > > >
> > > > Yes, it could almost certainly be done with Rterm.exe.
> > > >
> > > > The issue I came across was the so-called 'posix file paths'
> > > > that Cygwin uses.  Most (but not all) Windows programs
> > accept file
> > > > paths with / as the path separator, and most (but not
> > all, e.g. tar)
> > > > Cygwin programs accept paths of the forn c:/path/to/file.  So
> > > > provided you use that as your format, interworking with Unix and
> > > > Unix-like shells work fine.  It used to be the case that
> > if you had
> > > > just one drive C: then Cygwin programs produced paths of the form
> > > > /path/to/file that also worked on Windows.  Now they produce
> > > > /cygdrive/c/path/to/file that works nowhere else.
> > >
> > > I'm not sure what you mean by "produce" above but one can
> > easily setup
> > > (by mount option) cygwin to use "/" instead of "/cygdrive/" so that
> > > your example above will become "/c/path/to/file". That's if
> > you insist
> > > on using drive letters. Otherwise w/ proper mounting (in
> > cygwin) one
> > > can have "usual" *nix dir tree.
> > >
> > > Regards,
> > > Latchezar
> > >
> > > PS. I really like the idea of having (the same) bare
> > terminal/command
> > > window interface to R anywhere as well as anything else (like admin
> > > tasks above) to be the same. So please put my vote (if you care) to
> > > have R Windows installation look the same as *nix (up to the point
> > > when you start R from Start button to have terminal version started
> > > instead of Rgui as it is now) and keep GUI candies separately for
> > > whoever wants/needs them. Sorry if that's been already done
> > and I did
> > > not know about it.
> > >
> > > >
> > > > In general this is a minor nuisance, but I needed to be able to
> > > > cross-build R in an environment where I only have Cygwin-based
> > > > cross-compilers, and there the path issues bit
> > > > me: I needed a version of R that accepted and returned
> > Cygwin-style
> > > > paths.  So I made the configure changes necessary to
> > build R under
> > > > Cygwin, and had it running in 20 mins.
> > > >
> > > > > We would like to be able to use linux machines on pc's but
> > > > > unfortunately we have restrictions imposed on us that
> > > > prevent this.
> > > > > This restriction also goes as far as the use of virtual
> > > > machines.  My
> > > > > personal preference would be to run linux on my work
> > pc, and use a
> > > > > virtual machine to run windows software, such as ArcGIS and
> > > > Imagine,
> > > > > that are not available for linux.  This does not seem to be
> > > > an option for us.
> > > > >
> > > > > One thing I was interested in was knowing if there are
> > > > others who also
> > > > > would like a cygwin version.  From the replies to my post,
> > > > and from a
> > > > > search of the mailing list archive, I think that there
> > is little
> > > > > demand for this.  We would, however, be prepared to help in
> > > > some way
> > > > > for the few people who are interested.
> > > >
> > > > As I said earlier, it builds out of the box in R-devel (with
> > > > suitable options documented in the R-admin manual).  No
> > guarantees
> > > > that it will continue to do so unless tested in the
> > alpha/beta phase
> > > > though.  As no other platform we use nowadays requires
> > that shared
> > > > objects/dynamic libraries have all imports satisfied at
> > build time,
> > > > this is liable to get broken.
> > > >
> > > > But I would encourage people to use Rterm.exe if it can
> > be made to
> > > > do what you need.
> > > >
> > > >
> > > > >
> > > > >
> > > > >
> > > > > Robert Denham
> > > > > Environmental Statistician
> > > > > Remote Sensing Centre
> > > > > Telephone 07 3896 9899
> > > > > www.nrw.qld.gov.au
> > > > >
> > > > > Department of Natural Resources & Water QScape
> > Building, 80 Meiers
> > > > > Road, Indooroopilly Qld 4068
> > > > >
> > > > > -----Original Message-----
> > > > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > > > Sent: Tuesday, 21 August 2007 9:53 PM
> > > > > To: Duncan Murdoch
> > > > > Cc: Denham Robert; r-devel at r-project.org
> > > > > Subject: Re: [Rd] compiling R under cygwin
> > > > >
> > > > > Yes,
> > > > >
> > > > >> What is the advantage of building this?
> > > > >
> > > > > was my question too.  If you want a Unix-like version
> > of R on PC
> > > > > hardware running Windows why not run a Unix-like OS under a
> > > > > virtual machine?
> > > > >
> > > > > Quite a lot of the details are wrong: using FLIBS,
> > > > BLAS_LIBS and LIBS as
> > > > > intended will solve most of the problems.  I would use
> > > > > --disable-nls --disable-mbcs as you don't need them (and in
> > > > > particular you don't benefit from MBCS support on
> > Windows unless
> > > > > you are in a
> > > > CJK locale).
> > > > >
> > > > > Note that 2.5.1 is released and there is unlikely to be a
> > > > 2.5.2, so any
> > > > > changes would be made only to R-devel.  It there is a
> > > > convincing case to
> > > > > tailor a build for Cygwin there we can probably do so
> > > > rather easily, but
> > > > > the need for ongoing support would be a worry.
> > > > >
> > > > > (If platforms are not used and in particular not tested in the
> > > > > alpha/beta testing phases then the ability to build on them
> > > > > crumbles away.  We seems to be down to regular testers on Linux,
> > > > Windows, MacOS
> > > > > X, Solaris and FreeBSD, with some help on AIX after a patch
> > > > with none.)
> > > > >
> > > > > On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> > > > >
> > > > >> Denham Robert wrote:
> > > > >>> For various reasons,
> > > > >
> > > > > I think it is only courteous to mention some good reasons
> > > > if you want to
> > > > > take up people's time.
> > > > >
> > > > >>> it suits our workplace to have a cygwin version of R.  I am
> > > > >>> pretty sure that cygwin is still not a supported
> > environment for
> > > > R, but we
> > > > >>> have managed to compile R-2.5.1 under cygwin without too
> > > > many dramas.
> > > > >
> > > > >>> Our procedure is described below.  We still have a
> > few problems
> > > > >>> compiling libraries without manually changing files from
> > > > .so to .dll,
> > > > >
> > > > >>> but it seems ok.
> > > > >>>
> > > > >> I would expect other subtle problems as well, because
> > > > Cygwin is not a
> > > > >> normal Unix.  I don't know whether any of these
> > > > differences matter to
> > > > >> R, but some things to look out for are:
> > > > >>
> > > > >> - you can't unlink a file while it is open
> > > > >> - filenames are not case sensitive
> > > > >> - file permissions have strange defaults (everything is
> > > > >> executable)
> > > > >> - I think the executable format still needs to be
> > Windows format
> > > > >> - There's no such thing as a ptty
> > > > >> - You'll probably need X11 for graphics, and will lose support
> > > > >> for Windows metafile output (wmf)
> > > > >>>
> > > > >>> I was wondering whether this information is likely to
> > be useful
> > > > >>> to others, and if we should spend any time looking in to
> > > > ways in which
> > > > >>> the configure/build/install code could be modified to allow a
> > > > >>> standard install.
> > > > >>>
> > > > >> What is the advantage of building this?  I don't think
> > we want to
> > > > >> support platforms just for the sake of supporting more
> > > > platforms, but
> > > > >> if there's a real need for it, that would be different.
> > > > >>
> > > > >> Duncan Murdoch
> > > > >>>
> > > > >>> Notes on building R under cygwin:
> > > > >>>
> > > > >>> export FFLAGS=-O3
> > > > >>> export CFLAGS=-O3
> > > > >>> export CXXFLAGS=-O3
> > > > >>> export OBJCFLAGS=-O3
> > > > >>> export FCFLAGS=-O3
> > > > >>> export LDFLAGS='-lblas -lg2c -lintl'
> > > > >>>
> > > > >>> export R_OSTYPE=unix
> > > > >>>
> > > > >>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
> > > > >>> --with-tcl-config=/usr/lib/tclConfig.sh \
> > > > >>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \
> > > > >>> --with-lapack=-llapack \ --enable-R-shlib
> > > > >>>
> > > > >>> comment out Win32 in src/include/config.h and set Unix to
> > > > 1, change
> > > > >>> .so to .dll. change .so to .dll and in Makeconf.
> > > > >>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> > > > >>>
> > > > >>> Change .so to .dll in Makefile's
> > > > >>>
> > > > >>> edit Makeconf and set R_OSTYPE to unix
> > > > >>>
> > > > >>> make -j2
> > > > >>>
> > > > >>> when blas doesn't link, re-run command with -lblas -lg2c
> > > > on end and
> > > > >>> change output to .dll
> > > > >>>
> > > > >>> edit Rstrptime.c and change wcstod to atof.
> > > > >>>
> > > > >>> in modules:
> > > > >>> when X11 and internet falls over add -lintl to link line.
> > > > add -lg2c
> > > > >>> and -lblas to lapack
> > > > >>>
> > > > >>> comment out library/base/R/library.R lines 47-51 to avoid
> > > > arch check
> > > > >>> which seems to go wrong!
> > > > >>>
> > > > >>> make -j2
> > > > >>> make install
> > > > >>>
> > > > >>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and
> > add '-lintl
> > > > >>> -lg2c -lblas' to the end of ALL_LIBS so the module
> > building works.
> > > > >>> Change .so to .dll also (can't see how to to this for
> > the build
> > > > >>> tho...)
> > > > >>>
> > > > >>>
> > > > >>> Our cygwin info is:
> > > > >>>              sysname              release              version
> > > > >>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
> > > > >>>
> > > > >>>
> > > > >>>
> > > > >>>
> > > > >>> Robert Denham
> > > > >>> Environmental Statistician
> > > > >>> Remote Sensing Centre
> > > > >>> Telephone 07 3896 9899
> > > > >>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> > > > >>>
> > > > >>> Department of Natural Resources & Water QScape Building, 80
> > > > >>> Meiers Road, Indooroopilly Qld 4068
> > > > >>>
> > > > >>>
> > > >
> > ********************************************************************
> > > > *
> > > > >>> *** The information in this email together with any
> > attachments
> > > > >>> is intended only for the person or entity to which it is
> > > > addressed and
> > > > >>> may contain confidential and/or privileged material.
> > > > >>> Any form of review, disclosure, modification, distribution
> > > > >>> and/or publication of this email message is
> > prohibited, unless
> > > > >>> as a necessary part of Departmental business.
> > > > >>> If you have received this message in error, you are asked
> > > > to inform
> > > > >>> the sender as quickly as possible and delete this message and
> > > > >>> any copies of this message from your computer and/or your
> > > > computer system
> > > > >
> > > > >>> network.
> > > > >>>
> > > > >>> ______________________________________________
> > > > >>> R-devel at r-project.org mailing list
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > >>>
> > > > >>
> > > > >> ______________________________________________
> > > > >> R-devel at r-project.org mailing list
> > > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > >>
> > > > >
> > > > >
> > > >
> > > > --
> > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > Professor of Applied Statistics,
> > http://www.stats.ox.ac.uk/~ripley/
> > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>


From ldimitro at wfubmc.edu  Fri Aug 24 00:05:26 2007
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Thu, 23 Aug 2007 18:05:26 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <971536df0708231402m28771b1dud98aec69db21c4cd@mail.gmail.com>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<971536df0708231301wd72e7d1p37c4e0d02b9c3d4b@mail.gmail.com>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A7@EXCHVS1.medctr.ad.wfubmc.edu>
	<971536df0708231402m28771b1dud98aec69db21c4cd@mail.gmail.com>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A8@EXCHVS1.medctr.ad.wfubmc.edu>

Sorry but you pushed me where I did not want to go. Anyway this will be
my _last e-mail on this subj_.

1. I did not mention anything about cygwin.

2. Although I mentioned several times *nix if you had read a little bit
more carefully their spirit you would probably have grasped I actually
talked about CLI as in R spirit/recommended/preferred usage (and
maintenance/administration).

3. CLI is full fledged Windows look and feel while Rgui is a mish-mash,
cf. my prev example with setwd(). Again I don't mind having it at all as
any other R candies (I do not consider candies to be unhealthy :-)).

4. For those half or whatever users you mentioned I suggested keeping
their favorite look and feel but _not as the main stream implementation
replacement_.

5. AFAIK 64-bit R on your favorite Windows is far far away (even Windows
is not close enough although it's getting there) and I'd like to see
those above (and enjoy watching them) when Windows is not enough, e.g.,
microarray analysis/BioConductor.

7. Have you really read my e-mails, I mean from the beginning to the
end?

8. Sorry if this sounds harsh but your persistence on having Rgui as
mainstream Windows R asked for it.

9. Please consider all my e-mail on the subj. as an expression and/or
explanation of my wish to have my vote put for CLI mainstream R anywhere
as opposed to anything else. I did not aim convincing you neither do I
like your attempts to convert me.

Best regards,
Latchezar

 
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
> Sent: Thursday, August 23, 2007 5:02 PM
> To: Latchezar (Lucho) Dimitrov
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] compiling R under cygwin
> 
> Many people, probably about half, of R users are Windows 
> users either primarily or only and most would expect all 
> their programs on their Windows machine to work in the same 
> consistent way as all other Windows programs following a 
> certain Windows look and feel and way of operating.
> 
> Software which follows a UNIX look and feel and way of 
> operating is hard or jarring to use when all the other 
> software on your system follows the Windows way.  There is a 
> special Windows version of R that is distinct for a good reason.
> 
> If a cygwin version of R were to exist for UNIX people who 
> want to use R on Windows who basically want to use UNIX on 
> top of Windows that would be ok but that is not Windows.  
> Rather, cygwin is primarily a UNIX system that happens to sit 
> on Windows.  The normal Windows version of R that most people 
> use is and should be Windows centric.
> 
> Regarding your question, native means the ordinary R version 
> on Windows as opposed to a special cygwin version that might 
> exist in the future.
> 
> On 8/23/07, Latchezar (Lucho) Dimitrov <ldimitro at wfubmc.edu> wrote:
> > Depending on what you mean by "native". Anyway, I'd rather have it 
> > uniform to use and easy to maintain across the platforms 
> then keeping 
> > the face of the host os. In any case what I'd suggested is 
> to have the 
> > uniform setup everywhere and "os" specific somewhere in 
> case anybody 
> > needs it. How is that bad? I can tell you it would be a 
> very big issue 
> > to make a "native Windows" user of R to find setwd() on 
> *nix platform.
> > BTW, R preferred usage is CLI, isn't it. CLI is fully maintained on 
> > Windows too.
> >
> > Please also note I did not mention cygwin or something and did not 
> > express any attitude to the port/implementation.
> >
> > Finally I just wanted to have my vote put there (apparently 
> not where 
> > your vote is) not to argue.
> >
> > > -----Original Message-----
> > > From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> > > Sent: Thursday, August 23, 2007 4:01 PM
> > > To: Latchezar (Lucho) Dimitrov
> > > Cc: r-devel at r-project.org
> > > Subject: Re: [Rd] compiling R under cygwin
> > >
> > > Having it be the same under cygwin as it is for other 
> UNIX systems 
> > > would be ok but for the native Windows port R should behave like 
> > > other Windows applications, not like UNIX applications.
> > >
> > > On 8/23/07, Latchezar (Lucho) Dimitrov 
> <ldimitro at wfubmc.edu> wrote:
> > > >
> > > >
> > > > > -----Original Message-----
> > > > > From: r-devel-bounces at r-project.org 
> > > > > [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Prof Brian 
> > > > > Ripley
> > > > > Sent: Thursday, August 23, 2007 2:54 AM
> > > > > To: Denham Robert
> > > > > Cc: r-devel at r-project.org; Duncan Murdoch
> > > > > Subject: Re: [Rd] compiling R under cygwin
> > > > >
> > > > > On Thu, 23 Aug 2007, Denham Robert wrote:
> > > > >
> > > > > >>> For various reasons,
> > > > > >> I think it is only courteous to mention some good reasons
> > > > > if you want
> > > > > > to take up people's time.
> > > > > >
> > > > > > Some of the reasons we would like a cygwin version aren't
> > > > > necessarily
> > > > > > good reasons.  We have been using cygwin for sometime,
> > > > > mostly to deal
> > > > > > with scripting in a combined windows/unix environment.
> > > We have a
> > > > > > setup which allows windows users to run many scripts in the
> > > > > same way
> > > > > > as unix users.  These scripts are often python or shell
> > > > > scripts.  We
> > > > > > have R installed on the unix machines, and the system
> > > > > administrators
> > > > > > would like to be able to have R on windows in the same
> > > > > environment.
> > > > > > This set up also means that the administrator can fairly 
> > > > > > easily maintain the version of software used on all 
> user's machines.
> > > > > > Probably this could all be managed and still use the native 
> > > > > > windows version of R, but the administrator is 
> familiar with 
> > > > > > cygwin
> > > > > and they
> > > > > > could manage this software in the same way they manage
> > > > > other packages.
> > > > >
> > > > > Yes, it could almost certainly be done with Rterm.exe.
> > > > >
> > > > > The issue I came across was the so-called 'posix file paths'
> > > > > that Cygwin uses.  Most (but not all) Windows programs
> > > accept file
> > > > > paths with / as the path separator, and most (but not
> > > all, e.g. tar)
> > > > > Cygwin programs accept paths of the forn c:/path/to/file.  So 
> > > > > provided you use that as your format, interworking 
> with Unix and 
> > > > > Unix-like shells work fine.  It used to be the case that
> > > if you had
> > > > > just one drive C: then Cygwin programs produced paths of the 
> > > > > form /path/to/file that also worked on Windows.  Now they 
> > > > > produce /cygdrive/c/path/to/file that works nowhere else.
> > > >
> > > > I'm not sure what you mean by "produce" above but one can
> > > easily setup
> > > > (by mount option) cygwin to use "/" instead of "/cygdrive/" so 
> > > > that your example above will become "/c/path/to/file". That's if
> > > you insist
> > > > on using drive letters. Otherwise w/ proper mounting (in
> > > cygwin) one
> > > > can have "usual" *nix dir tree.
> > > >
> > > > Regards,
> > > > Latchezar
> > > >
> > > > PS. I really like the idea of having (the same) bare
> > > terminal/command
> > > > window interface to R anywhere as well as anything else (like 
> > > > admin tasks above) to be the same. So please put my 
> vote (if you 
> > > > care) to have R Windows installation look the same as 
> *nix (up to 
> > > > the point when you start R from Start button to have terminal 
> > > > version started instead of Rgui as it is now) and keep 
> GUI candies 
> > > > separately for whoever wants/needs them. Sorry if that's been 
> > > > already done
> > > and I did
> > > > not know about it.
> > > >
> > > > >
> > > > > In general this is a minor nuisance, but I needed to 
> be able to 
> > > > > cross-build R in an environment where I only have 
> Cygwin-based 
> > > > > cross-compilers, and there the path issues bit
> > > > > me: I needed a version of R that accepted and returned
> > > Cygwin-style
> > > > > paths.  So I made the configure changes necessary to
> > > build R under
> > > > > Cygwin, and had it running in 20 mins.
> > > > >
> > > > > > We would like to be able to use linux machines on pc's but 
> > > > > > unfortunately we have restrictions imposed on us that
> > > > > prevent this.
> > > > > > This restriction also goes as far as the use of virtual
> > > > > machines.  My
> > > > > > personal preference would be to run linux on my work
> > > pc, and use a
> > > > > > virtual machine to run windows software, such as ArcGIS and
> > > > > Imagine,
> > > > > > that are not available for linux.  This does not seem to be
> > > > > an option for us.
> > > > > >
> > > > > > One thing I was interested in was knowing if there are
> > > > > others who also
> > > > > > would like a cygwin version.  From the replies to my post,
> > > > > and from a
> > > > > > search of the mailing list archive, I think that there
> > > is little
> > > > > > demand for this.  We would, however, be prepared to help in
> > > > > some way
> > > > > > for the few people who are interested.
> > > > >
> > > > > As I said earlier, it builds out of the box in R-devel (with 
> > > > > suitable options documented in the R-admin manual).  No
> > > guarantees
> > > > > that it will continue to do so unless tested in the
> > > alpha/beta phase
> > > > > though.  As no other platform we use nowadays requires
> > > that shared
> > > > > objects/dynamic libraries have all imports satisfied at
> > > build time,
> > > > > this is liable to get broken.
> > > > >
> > > > > But I would encourage people to use Rterm.exe if it can
> > > be made to
> > > > > do what you need.
> > > > >
> > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > Robert Denham
> > > > > > Environmental Statistician
> > > > > > Remote Sensing Centre
> > > > > > Telephone 07 3896 9899
> > > > > > www.nrw.qld.gov.au
> > > > > >
> > > > > > Department of Natural Resources & Water QScape
> > > Building, 80 Meiers
> > > > > > Road, Indooroopilly Qld 4068
> > > > > >
> > > > > > -----Original Message-----
> > > > > > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > > > > > Sent: Tuesday, 21 August 2007 9:53 PM
> > > > > > To: Duncan Murdoch
> > > > > > Cc: Denham Robert; r-devel at r-project.org
> > > > > > Subject: Re: [Rd] compiling R under cygwin
> > > > > >
> > > > > > Yes,
> > > > > >
> > > > > >> What is the advantage of building this?
> > > > > >
> > > > > > was my question too.  If you want a Unix-like version
> > > of R on PC
> > > > > > hardware running Windows why not run a Unix-like OS under a 
> > > > > > virtual machine?
> > > > > >
> > > > > > Quite a lot of the details are wrong: using FLIBS,
> > > > > BLAS_LIBS and LIBS as
> > > > > > intended will solve most of the problems.  I would use 
> > > > > > --disable-nls --disable-mbcs as you don't need them (and in 
> > > > > > particular you don't benefit from MBCS support on
> > > Windows unless
> > > > > > you are in a
> > > > > CJK locale).
> > > > > >
> > > > > > Note that 2.5.1 is released and there is unlikely to be a
> > > > > 2.5.2, so any
> > > > > > changes would be made only to R-devel.  It there is a
> > > > > convincing case to
> > > > > > tailor a build for Cygwin there we can probably do so
> > > > > rather easily, but
> > > > > > the need for ongoing support would be a worry.
> > > > > >
> > > > > > (If platforms are not used and in particular not 
> tested in the 
> > > > > > alpha/beta testing phases then the ability to build on them 
> > > > > > crumbles away.  We seems to be down to regular testers on 
> > > > > > Linux,
> > > > > Windows, MacOS
> > > > > > X, Solaris and FreeBSD, with some help on AIX after a patch
> > > > > with none.)
> > > > > >
> > > > > > On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> > > > > >
> > > > > >> Denham Robert wrote:
> > > > > >>> For various reasons,
> > > > > >
> > > > > > I think it is only courteous to mention some good reasons
> > > > > if you want to
> > > > > > take up people's time.
> > > > > >
> > > > > >>> it suits our workplace to have a cygwin version 
> of R.  I am 
> > > > > >>> pretty sure that cygwin is still not a supported
> > > environment for
> > > > > R, but we
> > > > > >>> have managed to compile R-2.5.1 under cygwin without too
> > > > > many dramas.
> > > > > >
> > > > > >>> Our procedure is described below.  We still have a
> > > few problems
> > > > > >>> compiling libraries without manually changing files from
> > > > > .so to .dll,
> > > > > >
> > > > > >>> but it seems ok.
> > > > > >>>
> > > > > >> I would expect other subtle problems as well, because
> > > > > Cygwin is not a
> > > > > >> normal Unix.  I don't know whether any of these
> > > > > differences matter to
> > > > > >> R, but some things to look out for are:
> > > > > >>
> > > > > >> - you can't unlink a file while it is open
> > > > > >> - filenames are not case sensitive
> > > > > >> - file permissions have strange defaults (everything is
> > > > > >> executable)
> > > > > >> - I think the executable format still needs to be
> > > Windows format
> > > > > >> - There's no such thing as a ptty
> > > > > >> - You'll probably need X11 for graphics, and will lose 
> > > > > >> support for Windows metafile output (wmf)
> > > > > >>>
> > > > > >>> I was wondering whether this information is likely to
> > > be useful
> > > > > >>> to others, and if we should spend any time looking in to
> > > > > ways in which
> > > > > >>> the configure/build/install code could be 
> modified to allow 
> > > > > >>> a standard install.
> > > > > >>>
> > > > > >> What is the advantage of building this?  I don't think
> > > we want to
> > > > > >> support platforms just for the sake of supporting more
> > > > > platforms, but
> > > > > >> if there's a real need for it, that would be different.
> > > > > >>
> > > > > >> Duncan Murdoch
> > > > > >>>
> > > > > >>> Notes on building R under cygwin:
> > > > > >>>
> > > > > >>> export FFLAGS=-O3
> > > > > >>> export CFLAGS=-O3
> > > > > >>> export CXXFLAGS=-O3
> > > > > >>> export OBJCFLAGS=-O3
> > > > > >>> export FCFLAGS=-O3
> > > > > >>> export LDFLAGS='-lblas -lg2c -lintl'
> > > > > >>>
> > > > > >>> export R_OSTYPE=unix
> > > > > >>>
> > > > > >>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \ 
> > > > > >>> --with-tcl-config=/usr/lib/tclConfig.sh \ 
> > > > > >>> --with-tk-config=/usr/lib/tkConfig.sh \ 
> --with-blas=-lblas \ 
> > > > > >>> --with-lapack=-llapack \ --enable-R-shlib
> > > > > >>>
> > > > > >>> comment out Win32 in src/include/config.h and set Unix to
> > > > > 1, change
> > > > > >>> .so to .dll. change .so to .dll and in Makeconf.
> > > > > >>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> > > > > >>>
> > > > > >>> Change .so to .dll in Makefile's
> > > > > >>>
> > > > > >>> edit Makeconf and set R_OSTYPE to unix
> > > > > >>>
> > > > > >>> make -j2
> > > > > >>>
> > > > > >>> when blas doesn't link, re-run command with -lblas -lg2c
> > > > > on end and
> > > > > >>> change output to .dll
> > > > > >>>
> > > > > >>> edit Rstrptime.c and change wcstod to atof.
> > > > > >>>
> > > > > >>> in modules:
> > > > > >>> when X11 and internet falls over add -lintl to link line.
> > > > > add -lg2c
> > > > > >>> and -lblas to lapack
> > > > > >>>
> > > > > >>> comment out library/base/R/library.R lines 47-51 to avoid
> > > > > arch check
> > > > > >>> which seems to go wrong!
> > > > > >>>
> > > > > >>> make -j2
> > > > > >>> make install
> > > > > >>>
> > > > > >>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and
> > > add '-lintl
> > > > > >>> -lg2c -lblas' to the end of ALL_LIBS so the module
> > > building works.
> > > > > >>> Change .so to .dll also (can't see how to to this for
> > > the build
> > > > > >>> tho...)
> > > > > >>>
> > > > > >>>
> > > > > >>> Our cygwin info is:
> > > > > >>>              sysname              release         
>      version
> > > > > >>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  
> "20060527 19:21:22"
> > > > > >>>
> > > > > >>>
> > > > > >>>
> > > > > >>>
> > > > > >>> Robert Denham
> > > > > >>> Environmental Statistician
> > > > > >>> Remote Sensing Centre
> > > > > >>> Telephone 07 3896 9899
> > > > > >>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> > > > > >>>
> > > > > >>> Department of Natural Resources & Water QScape 
> Building, 80 
> > > > > >>> Meiers Road, Indooroopilly Qld 4068
> > > > > >>>
> > > > > >>>
> > > > >
> > > 
> ********************************************************************
> > > > > *
> > > > > >>> *** The information in this email together with any
> > > attachments
> > > > > >>> is intended only for the person or entity to which it is
> > > > > addressed and
> > > > > >>> may contain confidential and/or privileged material.
> > > > > >>> Any form of review, disclosure, modification, 
> distribution 
> > > > > >>> and/or publication of this email message is
> > > prohibited, unless
> > > > > >>> as a necessary part of Departmental business.
> > > > > >>> If you have received this message in error, you are asked
> > > > > to inform
> > > > > >>> the sender as quickly as possible and delete this message 
> > > > > >>> and any copies of this message from your computer and/or 
> > > > > >>> your
> > > > > computer system
> > > > > >
> > > > > >>> network.
> > > > > >>>
> > > > > >>> ______________________________________________
> > > > > >>> R-devel at r-project.org mailing list 
> > > > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > >>>
> > > > > >>
> > > > > >> ______________________________________________
> > > > > >> R-devel at r-project.org mailing list 
> > > > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > >>
> > > > > >
> > > > > >
> > > > >
> > > > > --
> > > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > > Professor of Applied Statistics,
> > > http://www.stats.ox.ac.uk/~ripley/
> > > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > > >
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list 
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > >
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list 
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > >
> >
>


From murdoch at stats.uwo.ca  Fri Aug 24 03:15:05 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Aug 2007 21:15:05 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
Message-ID: <46CE3119.4060909@stats.uwo.ca>

On 23/08/2007 3:33 PM, Latchezar (Lucho) Dimitrov wrote:
>  
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org 
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
>> Sent: Thursday, August 23, 2007 2:54 AM
>> To: Denham Robert
>> Cc: r-devel at r-project.org; Duncan Murdoch
>> Subject: Re: [Rd] compiling R under cygwin
>>
>> On Thu, 23 Aug 2007, Denham Robert wrote:
>>
>>>>> For various reasons,
>>>> I think it is only courteous to mention some good reasons 
>> if you want
>>> to take up people's time.
>>>
>>> Some of the reasons we would like a cygwin version aren't 
>> necessarily 
>>> good reasons.  We have been using cygwin for sometime, 
>> mostly to deal 
>>> with scripting in a combined windows/unix environment.  We have a 
>>> setup which allows windows users to run many scripts in the 
>> same way 
>>> as unix users.  These scripts are often python or shell 
>> scripts.  We 
>>> have R installed on the unix machines, and the system 
>> administrators 
>>> would like to be able to have R on windows in the same 
>> environment.  
>>> This set up also means that the administrator can fairly easily 
>>> maintain the version of software used on all user's machines.  
>>> Probably this could all be managed and still use the native windows 
>>> version of R, but the administrator is familiar with cygwin 
>> and they 
>>> could manage this software in the same way they manage 
>> other packages.
>>
>> Yes, it could almost certainly be done with Rterm.exe.
>>
>> The issue I came across was the so-called 'posix file paths' 
>> that Cygwin uses.  Most (but not all) Windows programs accept 
>> file paths with / as the path separator, and most (but not 
>> all, e.g. tar) Cygwin programs accept paths of the forn 
>> c:/path/to/file.  So provided you use that as your format, 
>> interworking with Unix and Unix-like shells work fine.  It 
>> used to be the case that if you had just one drive C: then 
>> Cygwin programs produced paths of the form /path/to/file that 
>> also worked on Windows.  Now they produce 
>> /cygdrive/c/path/to/file that works nowhere else.
> 
> I'm not sure what you mean by "produce" above but one can easily setup
> (by mount option) cygwin to use "/" instead of "/cygdrive/" so that your
> example above will become "/c/path/to/file". That's if you insist on
> using drive letters. Otherwise w/ proper mounting (in cygwin) one can
> have "usual" *nix dir tree.

The issue is compatibility with other Windows programs.  /path/to/file 
works in lots of Windows programs, and is interpreted relative to the 
current drive.  In the common situation where the user only has one 
partition which is mounted as C:, it works (as long as they didn't 
switch to a CD or USB drive).

/c/path/to/file wouldn't work anywhere but in Cygwin or similar.

Duncan Murdoch

> 
> Regards,
> Latchezar
> 
> PS. I really like the idea of having (the same) bare terminal/command
> window interface to R anywhere as well as anything else (like admin
> tasks above) to be the same. So please put my vote (if you care) to have
> R Windows installation look the same as *nix (up to the point when you
> start R from Start button to have terminal version started instead of
> Rgui as it is now) and keep GUI candies separately for whoever
> wants/needs them. Sorry if that's been already done and I did not know
> about it.
> 
>> In general this is a minor nuisance, but I needed to be able 
>> to cross-build R in an environment where I only have 
>> Cygwin-based cross-compilers, and there the path issues bit 
>> me: I needed a version of R that accepted and returned 
>> Cygwin-style paths.  So I made the configure changes 
>> necessary to build R under Cygwin, and had it running in 20 mins.
>>
>>> We would like to be able to use linux machines on pc's but 
>>> unfortunately we have restrictions imposed on us that 
>> prevent this.  
>>> This restriction also goes as far as the use of virtual 
>> machines.  My 
>>> personal preference would be to run linux on my work pc, and use a 
>>> virtual machine to run windows software, such as ArcGIS and 
>> Imagine, 
>>> that are not available for linux.  This does not seem to be 
>> an option for us.
>>> One thing I was interested in was knowing if there are 
>> others who also 
>>> would like a cygwin version.  From the replies to my post, 
>> and from a 
>>> search of the mailing list archive, I think that there is little 
>>> demand for this.  We would, however, be prepared to help in 
>> some way 
>>> for the few people who are interested.
>> As I said earlier, it builds out of the box in R-devel (with 
>> suitable options documented in the R-admin manual).  No 
>> guarantees that it will continue to do so unless tested in 
>> the alpha/beta phase though.  As no other platform we use 
>> nowadays requires that shared objects/dynamic libraries have 
>> all imports satisfied at build time, this is liable to get broken.
>>
>> But I would encourage people to use Rterm.exe if it can be 
>> made to do what you need.
>>
>>
>>>
>>>
>>> Robert Denham
>>> Environmental Statistician
>>> Remote Sensing Centre
>>> Telephone 07 3896 9899
>>> www.nrw.qld.gov.au
>>>
>>> Department of Natural Resources & Water
>>> QScape Building, 80 Meiers Road, Indooroopilly Qld 4068
>>>
>>> -----Original Message-----
>>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>>> Sent: Tuesday, 21 August 2007 9:53 PM
>>> To: Duncan Murdoch
>>> Cc: Denham Robert; r-devel at r-project.org
>>> Subject: Re: [Rd] compiling R under cygwin
>>>
>>> Yes,
>>>
>>>> What is the advantage of building this?
>>> was my question too.  If you want a Unix-like version of R on PC
>>> hardware running Windows why not run a Unix-like OS under a virtual
>>> machine?
>>>
>>> Quite a lot of the details are wrong: using FLIBS, 
>> BLAS_LIBS and LIBS as
>>> intended will solve most of the problems.  I would use --disable-nls
>>> --disable-mbcs as you don't need them (and in particular you don't
>>> benefit from MBCS support on Windows unless you are in a 
>> CJK locale).
>>> Note that 2.5.1 is released and there is unlikely to be a 
>> 2.5.2, so any
>>> changes would be made only to R-devel.  It there is a 
>> convincing case to
>>> tailor a build for Cygwin there we can probably do so 
>> rather easily, but
>>> the need for ongoing support would be a worry.
>>>
>>> (If platforms are not used and in particular not tested in the
>>> alpha/beta testing phases then the ability to build on them crumbles
>>> away.  We seems to be down to regular testers on Linux, 
>> Windows, MacOS
>>> X, Solaris and FreeBSD, with some help on AIX after a patch 
>> with none.)
>>> On Tue, 21 Aug 2007, Duncan Murdoch wrote:
>>>
>>>> Denham Robert wrote:
>>>>> For various reasons,
>>> I think it is only courteous to mention some good reasons 
>> if you want to
>>> take up people's time.
>>>
>>>>> it suits our workplace to have a cygwin version of R.  I am pretty
>>>>> sure that cygwin is still not a supported environment for 
>> R, but we
>>>>> have managed to compile R-2.5.1 under cygwin without too 
>> many dramas.
>>>>> Our procedure is described below.  We still have a few problems
>>>>> compiling libraries without manually changing files from 
>> .so to .dll,
>>>>> but it seems ok.
>>>>>
>>>> I would expect other subtle problems as well, because 
>> Cygwin is not a
>>>> normal Unix.  I don't know whether any of these 
>> differences matter to
>>>> R, but some things to look out for are:
>>>>
>>>> - you can't unlink a file while it is open
>>>> - filenames are not case sensitive
>>>> - file permissions have strange defaults (everything is executable)
>>>> - I think the executable format still needs to be Windows format
>>>> - There's no such thing as a ptty
>>>> - You'll probably need X11 for graphics, and will lose support for
>>>> Windows metafile output (wmf)
>>>>> I was wondering whether this information is likely to be useful to
>>>>> others, and if we should spend any time looking in to 
>> ways in which
>>>>> the configure/build/install code could be modified to allow a
>>>>> standard install.
>>>>>
>>>> What is the advantage of building this?  I don't think we want to
>>>> support platforms just for the sake of supporting more 
>> platforms, but
>>>> if there's a real need for it, that would be different.
>>>>
>>>> Duncan Murdoch
>>>>> Notes on building R under cygwin:
>>>>>
>>>>> export FFLAGS=-O3
>>>>> export CFLAGS=-O3
>>>>> export CXXFLAGS=-O3
>>>>> export OBJCFLAGS=-O3
>>>>> export FCFLAGS=-O3
>>>>> export LDFLAGS='-lblas -lg2c -lintl'
>>>>>
>>>>> export R_OSTYPE=unix
>>>>>
>>>>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \
>>>>> --with-tcl-config=/usr/lib/tclConfig.sh \
>>>>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \
>>>>> --with-lapack=-llapack \ --enable-R-shlib
>>>>>
>>>>> comment out Win32 in src/include/config.h and set Unix to 
>> 1, change
>>>>> .so to .dll. change .so to .dll and in Makeconf.
>>>>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
>>>>>
>>>>> Change .so to .dll in Makefile's
>>>>>
>>>>> edit Makeconf and set R_OSTYPE to unix
>>>>>
>>>>> make -j2
>>>>>
>>>>> when blas doesn't link, re-run command with -lblas -lg2c 
>> on end and
>>>>> change output to .dll
>>>>>
>>>>> edit Rstrptime.c and change wcstod to atof.
>>>>>
>>>>> in modules:
>>>>> when X11 and internet falls over add -lintl to link line. 
>> add -lg2c
>>>>> and -lblas to lapack
>>>>>
>>>>> comment out library/base/R/library.R lines 47-51 to avoid 
>> arch check
>>>>> which seems to go wrong!
>>>>>
>>>>> make -j2
>>>>> make install
>>>>>
>>>>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and add '-lintl
>>>>> -lg2c -lblas' to the end of ALL_LIBS so the module building works.
>>>>> Change .so to .dll also (can't see how to to this for the build
>>>>> tho...)
>>>>>
>>>>>
>>>>> Our cygwin info is:
>>>>>              sysname              release              version
>>>>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Robert Denham
>>>>> Environmental Statistician
>>>>> Remote Sensing Centre
>>>>> Telephone 07 3896 9899
>>>>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
>>>>>
>>>>> Department of Natural Resources & Water QScape Building, 80 Meiers
>>>>> Road, Indooroopilly Qld 4068
>>>>>
>>>>>
>> *********************************************************************
>>>>> *** The information in this email together with any attachments is
>>>>> intended only for the person or entity to which it is 
>> addressed and
>>>>> may contain confidential and/or privileged material.
>>>>> Any form of review, disclosure, modification, distribution and/or
>>>>> publication of this email message is prohibited, unless as a
>>>>> necessary part of Departmental business.
>>>>> If you have received this message in error, you are asked 
>> to inform
>>>>> the sender as quickly as possible and delete this message and any
>>>>> copies of this message from your computer and/or your 
>> computer system
>>>>> network.
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ldimitro at wfubmc.edu  Fri Aug 24 04:10:23 2007
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Thu, 23 Aug 2007 22:10:23 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <46CE3119.4060909@stats.uwo.ca>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<46CE3119.4060909@stats.uwo.ca>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF87A9@EXCHVS1.medctr.ad.wfubmc.edu>

 

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
> Sent: Thursday, August 23, 2007 9:15 PM
> To: Latchezar (Lucho) Dimitrov
> Cc: Prof Brian Ripley; Denham Robert; r-devel at r-project.org
> Subject: Re: [Rd] compiling R under cygwin
> 
> On 23/08/2007 3:33 PM, Latchezar (Lucho) Dimitrov wrote:
> >  
> > 
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
> >> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof 
> Brian Ripley
> >> Sent: Thursday, August 23, 2007 2:54 AM
> >> To: Denham Robert
> >> Cc: r-devel at r-project.org; Duncan Murdoch
> >> Subject: Re: [Rd] compiling R under cygwin
> >>
> >> On Thu, 23 Aug 2007, Denham Robert wrote:
> >>
> >>>>> For various reasons,
> >>>> I think it is only courteous to mention some good reasons
> >> if you want
> >>> to take up people's time.
> >>>
> >>> Some of the reasons we would like a cygwin version aren't
> >> necessarily
> >>> good reasons.  We have been using cygwin for sometime,
> >> mostly to deal
> >>> with scripting in a combined windows/unix environment.  We have a 
> >>> setup which allows windows users to run many scripts in the
> >> same way
> >>> as unix users.  These scripts are often python or shell
> >> scripts.  We
> >>> have R installed on the unix machines, and the system
> >> administrators
> >>> would like to be able to have R on windows in the same
> >> environment.  
> >>> This set up also means that the administrator can fairly easily 
> >>> maintain the version of software used on all user's machines.
> >>> Probably this could all be managed and still use the 
> native windows 
> >>> version of R, but the administrator is familiar with cygwin
> >> and they
> >>> could manage this software in the same way they manage
> >> other packages.
> >>
> >> Yes, it could almost certainly be done with Rterm.exe.
> >>
> >> The issue I came across was the so-called 'posix file paths' 
> >> that Cygwin uses.  Most (but not all) Windows programs accept file 
> >> paths with / as the path separator, and most (but not all, 
> e.g. tar) 
> >> Cygwin programs accept paths of the forn c:/path/to/file.  So 
> >> provided you use that as your format, interworking with Unix and 
> >> Unix-like shells work fine.  It used to be the case that 
> if you had 
> >> just one drive C: then Cygwin programs produced paths of the form 
> >> /path/to/file that also worked on Windows.  Now they produce 
> >> /cygdrive/c/path/to/file that works nowhere else.
> > 
> > I'm not sure what you mean by "produce" above but one can 
> easily setup 
> > (by mount option) cygwin to use "/" instead of "/cygdrive/" so that 
> > your example above will become "/c/path/to/file". That's if 
> you insist 
> > on using drive letters. Otherwise w/ proper mounting (in 
> cygwin) one 
> > can have "usual" *nix dir tree.
> 
> The issue is compatibility with other Windows programs.  
> /path/to/file works in lots of Windows programs, and is 
> interpreted relative to the current drive.  In the common 
> situation where the user only has one partition which is 
> mounted as C:, it works (as long as they didn't switch to a 
> CD or USB drive).

As I said _if_ you insist on using c (which btw is absolutely not
necessary)

Please see the output of 'ls' and 'dir' bellow:

C:\Documents and Settings\Latchezar M Dimitrov>dir "u:\home\Latchezar M
Dimitrov\cygwin"
 Volume in drive U is Users':
 Volume Serial Number is 7FC9-20D1

 Directory of u:\home\Latchezar M Dimitrov\cygwin

07/30/2007  07:00 PM    <DIR>          .
07/30/2007  07:00 PM    <DIR>          ..
07/31/2005  07:39 PM             7,664 .alias
07/29/2005  10:29 AM             7,664 .alias~
07/22/2005  11:24 AM    <DIR>          .autosave
02/13/2007  04:46 PM             2,791 .bashrc
01/27/2007  08:47 PM             2,631 .bashrc~
08/20/2007  11:55 AM            25,966 .bash_history
01/27/2007  08:48 PM               959 .bash_profile
05/28/2005  06:18 PM               959 .bash_profile~
10/27/2003  09:09 PM               569 .emacs
05/28/2005  06:18 PM               608 .inputrc
11/03/2004  07:17 PM               135 .saves-2440-TheComputer
09/13/2005  01:40 PM    <DIR>          .semanticdb
07/22/2005  11:24 AM    <DIR>          .ssh
02/09/2002  11:43 PM             1,003 .Xdefaults
02/22/2006  01:33 AM    <DIR>          .xemacs

$ls /home/Latchezar\ M\ Dimitrov/cygwin/
total 962
-rwxrwxrwx   1 Latchezar M Dimitrov None   1003 Feb  9  2002 .Xdefaults*
-rwxrwxrwx   1 Latchezar M Dimitrov None   7664 Jul 31  2005 .alias*
-rwxrwxrwx   1 Latchezar M Dimitrov None   7664 Jul 29  2005 .alias~*
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Jul 22  2005 .autosave/
-rwxrwxrwx   1 Latchezar M Dimitrov None  25966 Aug 20 11:55
.bash_history*
-rwxrwxrwx   1 Latchezar M Dimitrov None    959 Jan 27  2007
.bash_profile*
-rwxrwxrwx   1 Latchezar M Dimitrov None    959 May 28  2005
.bash_profile~*
-rwxrwxrwx   1 Latchezar M Dimitrov None   2791 Feb 13  2007 .bashrc*
-rwxrwxrwx   1 Latchezar M Dimitrov None   2631 Jan 27  2007 .bashrc~*
-rwxrwxrwx   1 Latchezar M Dimitrov None    569 Oct 27  2003 .emacs*
-rwxrwxrwx   1 Latchezar M Dimitrov None    608 May 28  2005 .inputrc*
-rwxrwxrwx   1 Latchezar M Dimitrov None    135 Nov  3  2004
.saves-2440-TheComputer*
drwxr-xr-x+  2 Latchezar M Dimitrov None      0 Sep 13  2005
.semanticdb/
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Jul 22  2005 .ssh/
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Feb 22  2006 .xemacs/

$ls ~
total 962
-rwxrwxrwx   1 Latchezar M Dimitrov None   1003 Feb  9  2002 .Xdefaults*
-rwxrwxrwx   1 Latchezar M Dimitrov None   7664 Jul 31  2005 .alias*
-rwxrwxrwx   1 Latchezar M Dimitrov None   7664 Jul 29  2005 .alias~*
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Jul 22  2005 .autosave/
-rwxrwxrwx   1 Latchezar M Dimitrov None  25966 Aug 20 11:55
.bash_history*
-rwxrwxrwx   1 Latchezar M Dimitrov None    959 Jan 27  2007
.bash_profile*
-rwxrwxrwx   1 Latchezar M Dimitrov None    959 May 28  2005
.bash_profile~*
-rwxrwxrwx   1 Latchezar M Dimitrov None   2791 Feb 13  2007 .bashrc*
-rwxrwxrwx   1 Latchezar M Dimitrov None   2631 Jan 27  2007 .bashrc~*
-rwxrwxrwx   1 Latchezar M Dimitrov None    569 Oct 27  2003 .emacs*
-rwxrwxrwx   1 Latchezar M Dimitrov None    608 May 28  2005 .inputrc*
-rwxrwxrwx   1 Latchezar M Dimitrov None    135 Nov  3  2004
.saves-2440-TheComputer*
drwxr-xr-x+  2 Latchezar M Dimitrov None      0 Sep 13  2005
.semanticdb/
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Jul 22  2005 .ssh/
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Feb 22  2006 .xemacs/
-rw-r--r--   1 Latchezar M Dimitrov None 114993 Jul  4 22:21
2NonSelf.txt.columns
drwxrwxrwx+  2 Latchezar M Dimitrov None      0 Jul 22  2005 Copy of
.xemacs/
drwxrwxrwx+  3 Latchezar M Dimitrov None      0 Jul 22  2005 LaTeX/

No '/u/'. Convincing? No?

Again, this is not apologetics to cygwin. Just counter-argument. E
pluribus unum as we say (or at least inscribe) here :-)

Latchezar

> 
> /c/path/to/file wouldn't work anywhere but in Cygwin or similar.
> 
> Duncan Murdoch
> 
> > 
> > Regards,
> > Latchezar
> > 
> > PS. I really like the idea of having (the same) bare 
> terminal/command 
> > window interface to R anywhere as well as anything else (like admin 
> > tasks above) to be the same. So please put my vote (if you care) to 
> > have R Windows installation look the same as *nix (up to the point 
> > when you start R from Start button to have terminal version started 
> > instead of Rgui as it is now) and keep GUI candies separately for 
> > whoever wants/needs them. Sorry if that's been already done 
> and I did 
> > not know about it.
> > 
> >> In general this is a minor nuisance, but I needed to be able to 
> >> cross-build R in an environment where I only have Cygwin-based 
> >> cross-compilers, and there the path issues bit
> >> me: I needed a version of R that accepted and returned 
> Cygwin-style 
> >> paths.  So I made the configure changes necessary to build R under 
> >> Cygwin, and had it running in 20 mins.
> >>
> >>> We would like to be able to use linux machines on pc's but 
> >>> unfortunately we have restrictions imposed on us that
> >> prevent this.  
> >>> This restriction also goes as far as the use of virtual
> >> machines.  My
> >>> personal preference would be to run linux on my work pc, 
> and use a 
> >>> virtual machine to run windows software, such as ArcGIS and
> >> Imagine,
> >>> that are not available for linux.  This does not seem to be
> >> an option for us.
> >>> One thing I was interested in was knowing if there are
> >> others who also
> >>> would like a cygwin version.  From the replies to my post,
> >> and from a
> >>> search of the mailing list archive, I think that there is little 
> >>> demand for this.  We would, however, be prepared to help in
> >> some way
> >>> for the few people who are interested.
> >> As I said earlier, it builds out of the box in R-devel 
> (with suitable 
> >> options documented in the R-admin manual).  No guarantees that it 
> >> will continue to do so unless tested in the alpha/beta 
> phase though.  
> >> As no other platform we use nowadays requires that shared 
> >> objects/dynamic libraries have all imports satisfied at 
> build time, 
> >> this is liable to get broken.
> >>
> >> But I would encourage people to use Rterm.exe if it can be 
> made to do 
> >> what you need.
> >>
> >>
> >>>
> >>>
> >>> Robert Denham
> >>> Environmental Statistician
> >>> Remote Sensing Centre
> >>> Telephone 07 3896 9899
> >>> www.nrw.qld.gov.au
> >>>
> >>> Department of Natural Resources & Water QScape Building, 
> 80 Meiers 
> >>> Road, Indooroopilly Qld 4068
> >>>
> >>> -----Original Message-----
> >>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> >>> Sent: Tuesday, 21 August 2007 9:53 PM
> >>> To: Duncan Murdoch
> >>> Cc: Denham Robert; r-devel at r-project.org
> >>> Subject: Re: [Rd] compiling R under cygwin
> >>>
> >>> Yes,
> >>>
> >>>> What is the advantage of building this?
> >>> was my question too.  If you want a Unix-like version of R on PC 
> >>> hardware running Windows why not run a Unix-like OS under 
> a virtual 
> >>> machine?
> >>>
> >>> Quite a lot of the details are wrong: using FLIBS,
> >> BLAS_LIBS and LIBS as
> >>> intended will solve most of the problems.  I would use 
> --disable-nls 
> >>> --disable-mbcs as you don't need them (and in particular 
> you don't 
> >>> benefit from MBCS support on Windows unless you are in a
> >> CJK locale).
> >>> Note that 2.5.1 is released and there is unlikely to be a
> >> 2.5.2, so any
> >>> changes would be made only to R-devel.  It there is a
> >> convincing case to
> >>> tailor a build for Cygwin there we can probably do so
> >> rather easily, but
> >>> the need for ongoing support would be a worry.
> >>>
> >>> (If platforms are not used and in particular not tested in the 
> >>> alpha/beta testing phases then the ability to build on 
> them crumbles 
> >>> away.  We seems to be down to regular testers on Linux,
> >> Windows, MacOS
> >>> X, Solaris and FreeBSD, with some help on AIX after a patch
> >> with none.)
> >>> On Tue, 21 Aug 2007, Duncan Murdoch wrote:
> >>>
> >>>> Denham Robert wrote:
> >>>>> For various reasons,
> >>> I think it is only courteous to mention some good reasons
> >> if you want to
> >>> take up people's time.
> >>>
> >>>>> it suits our workplace to have a cygwin version of R.  
> I am pretty 
> >>>>> sure that cygwin is still not a supported environment for
> >> R, but we
> >>>>> have managed to compile R-2.5.1 under cygwin without too
> >> many dramas.
> >>>>> Our procedure is described below.  We still have a few problems 
> >>>>> compiling libraries without manually changing files from
> >> .so to .dll,
> >>>>> but it seems ok.
> >>>>>
> >>>> I would expect other subtle problems as well, because
> >> Cygwin is not a
> >>>> normal Unix.  I don't know whether any of these
> >> differences matter to
> >>>> R, but some things to look out for are:
> >>>>
> >>>> - you can't unlink a file while it is open
> >>>> - filenames are not case sensitive
> >>>> - file permissions have strange defaults (everything is 
> executable)
> >>>> - I think the executable format still needs to be Windows format
> >>>> - There's no such thing as a ptty
> >>>> - You'll probably need X11 for graphics, and will lose 
> support for 
> >>>> Windows metafile output (wmf)
> >>>>> I was wondering whether this information is likely to 
> be useful to 
> >>>>> others, and if we should spend any time looking in to
> >> ways in which
> >>>>> the configure/build/install code could be modified to allow a 
> >>>>> standard install.
> >>>>>
> >>>> What is the advantage of building this?  I don't think 
> we want to 
> >>>> support platforms just for the sake of supporting more
> >> platforms, but
> >>>> if there's a real need for it, that would be different.
> >>>>
> >>>> Duncan Murdoch
> >>>>> Notes on building R under cygwin:
> >>>>>
> >>>>> export FFLAGS=-O3
> >>>>> export CFLAGS=-O3
> >>>>> export CXXFLAGS=-O3
> >>>>> export OBJCFLAGS=-O3
> >>>>> export FCFLAGS=-O3
> >>>>> export LDFLAGS='-lblas -lg2c -lintl'
> >>>>>
> >>>>> export R_OSTYPE=unix
> >>>>>
> >>>>> ./configure --prefix=/opt/freeware/R/R-2.5.1 \ 
> >>>>> --with-tcl-config=/usr/lib/tclConfig.sh \ 
> >>>>> --with-tk-config=/usr/lib/tkConfig.sh \ --with-blas=-lblas \ 
> >>>>> --with-lapack=-llapack \ --enable-R-shlib
> >>>>>
> >>>>> comment out Win32 in src/include/config.h and set Unix to
> >> 1, change
> >>>>> .so to .dll. change .so to .dll and in Makeconf.
> >>>>> in src/extra/xdr/rpc/types.h comment out defn of malloc.
> >>>>>
> >>>>> Change .so to .dll in Makefile's
> >>>>>
> >>>>> edit Makeconf and set R_OSTYPE to unix
> >>>>>
> >>>>> make -j2
> >>>>>
> >>>>> when blas doesn't link, re-run command with -lblas -lg2c
> >> on end and
> >>>>> change output to .dll
> >>>>>
> >>>>> edit Rstrptime.c and change wcstod to atof.
> >>>>>
> >>>>> in modules:
> >>>>> when X11 and internet falls over add -lintl to link line. 
> >> add -lg2c
> >>>>> and -lblas to lapack
> >>>>>
> >>>>> comment out library/base/R/library.R lines 47-51 to avoid
> >> arch check
> >>>>> which seems to go wrong!
> >>>>>
> >>>>> make -j2
> >>>>> make install
> >>>>>
> >>>>> edit  /opt/freeware/R/R-2.5.1/lib/R/etc/Makeconf and 
> add '-lintl 
> >>>>> -lg2c -lblas' to the end of ALL_LIBS so the module 
> building works.
> >>>>> Change .so to .dll also (can't see how to to this for the build
> >>>>> tho...)
> >>>>>
> >>>>>
> >>>>> Our cygwin info is:
> >>>>>              sysname              release              version
> >>>>>      "CYGWIN_NT-5.1" "1.5.20s(0.155/4/2)"  "20060527 19:21:22"
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> Robert Denham
> >>>>> Environmental Statistician
> >>>>> Remote Sensing Centre
> >>>>> Telephone 07 3896 9899
> >>>>> www.nrw.qld.gov.au <http://www.nrw.qld.gov.au/>
> >>>>>
> >>>>> Department of Natural Resources & Water QScape 
> Building, 80 Meiers 
> >>>>> Road, Indooroopilly Qld 4068
> >>>>>
> >>>>>
> >> 
> *********************************************************************
> >>>>> *** The information in this email together with any 
> attachments is 
> >>>>> intended only for the person or entity to which it is
> >> addressed and
> >>>>> may contain confidential and/or privileged material.
> >>>>> Any form of review, disclosure, modification, 
> distribution and/or 
> >>>>> publication of this email message is prohibited, unless as a 
> >>>>> necessary part of Departmental business.
> >>>>> If you have received this message in error, you are asked
> >> to inform
> >>>>> the sender as quickly as possible and delete this 
> message and any 
> >>>>> copies of this message from your computer and/or your
> >> computer system
> >>>>> network.
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list 
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >> -- 
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Fri Aug 24 07:59:49 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Aug 2007 06:59:49 +0100 (BST)
Subject: [Rd] compiling R under cygwin
In-Reply-To: <46CE3119.4060909@stats.uwo.ca>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<46CE3119.4060909@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0708240526280.30984@gannet.stats.ox.ac.uk>

On Thu, 23 Aug 2007, Duncan Murdoch wrote:

> The issue is compatibility with other Windows programs.  /path/to/file works 
> in lots of Windows programs, and is interpreted relative to the current 
> drive.  In the common situation where the user only has one partition which 
> is mounted as C:, it works (as long as they didn't switch to a CD or USB 
> drive).

In particular, it does not work on my system where I need to run under two 
OSes, Vista64 on C: and WinXP on D:, with common development on E: .

I had originally intended to work entirely on E: and mount E:/ as /, which 
is what you need to get Cygwin to return /path/to/file for working files 
on E: . But Cygwin does not handle permissions on a Vista NTFS file system 
well enough.

Latchezar (Lucho) Dimitrov wrote

> 5. AFAIK 64-bit R on your favorite Windows is far far away (even Windows
> is not close enough although it's getting there) and I'd like to see
> those above (and enjoy watching them) when Windows is not enough, e.g.,
> microarray analysis/BioConductor.

That's just not true.  There have been reports of 64-bit R ports to 
Windows and many people are running 64-bit Windows on servers and some on 
desktops (including me).  A MinGW-based 64-bit R for Windows is under 
active development (which is why I have Vista64 installed).  This is even 
covered in the rw-FAQ (Q8.1, and yes that is a file with numbered TOC).

What seems 'far, far away' is something like Cygwin for 64-bit Windows.
(I saw on a Cygwin list that RedHat wanted $$$$$ to do it, for too many 
$$$$$ for the potential customers.)  The 32-bit version is said to work 
under the WOW 32-bit emulation layer but many of us find it flaky.

Personally I use Linux (the main OS on the machine I mention above) and 
Solaris: however many R users (quite possibly the substantial majority of 
all R users even excluding student usage) want a native Windows version.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Aug 24 09:22:02 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Aug 2007 09:22:02 +0200
Subject: [Rd] paste() with NAs ..  change worth persuing?
In-Reply-To: <20070823134932.GA28021@cs.cas.cz>
References: <18124.23379.575814.316093@stat.math.ethz.ch>
	<46CC6F7C.2010600@stats.uwo.ca>
	<2d3b61b809045fef4ca309796b8ac642@oulu.fi>
	<20070823134932.GA28021@cs.cas.cz>
Message-ID: <18126.34586.547146.841235@stat.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Thu, 23 Aug 2007 15:49:32 +0200 writes:

    PS> On Wed, Aug 22, 2007 at 08:53:39PM +0300, Jari Oksanen wrote:
    >> 
    >> On 22 Aug 2007, at 20:16, Duncan Murdoch wrote:
    >> > A fairly common use of paste is to put together reports for human
    >> > consumption.  Currently we have
    >> >
    >> >> p <- as.character(NA)
    >> >> paste("the value of p is", p)
    >> > [1] "the value of p is NA"
    >> >
    >> > which looks reasonable. Would this become
    >> >
    >> >> p <- as.character(NA)
    >> >> paste("the value of p is", p)
    >> > [1] NA
    >> >
    >> > under your proposal?  (In a quick search I was unable to find a real
    >> > example where this would happen, but it would worry me...)
    >> 
    >> At least stop() seems to include such a case:
    >> 
    >> message <- paste(args, collapse = "")
    >> 
    >> and we may expect there are NAs sometimes in stop().

    PS> The examples show, that changing the behavior of paste in general
    PS> may not be appropriate. On the other hand, if we concatenate
    PS> character vectors, which are part of data, then is.na(paste(...,NA,...))
    PS> makes sense. Character vectors in data are usually represented
    PS> by factors. On the other hand, factors are not typical in cases,
    PS> where paste is used to produce a readable message. Hence, it
    PS> could be possible to have is.na(u[i]) for those i, for which
    PS> some of the vectors v1, ..., vn in
    PS> u <- paste(v1,....,vn)
    PS> is a factor and has NA at i-th position.

You are right.  But I don't think any longer that it is sensible
to make paste() complicated like that.

Also note that currently, the first step in  paste 
is to  "as.character(.)" all of its arguments,
--- and it's help page does say so too ---
such that
later, you can't distinguish anymore between
    "original character NA"
and "original numeric/factor NA".

Thanks to all the respondents,
I've now been convinced that the answer to my original question
is  "no"  {i.e. it's not worth persuing to change paste() here ..}.

I will add a note to paste()'s help page mentioning the
somewhat undesired behavior for the case one is really just
thinking of character string manipulations.

Martin


From Yongchao.Ge at mssm.edu  Thu Aug 23 20:36:08 2007
From: Yongchao.Ge at mssm.edu (Yongchao Ge)
Date: Thu, 23 Aug 2007 14:36:08 -0400 (EDT)
Subject: [Rd] .Call and to reclaim the memory by allocVector
Message-ID: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>

Hi,

I am not sure if this is a bug and I apologize if it is something I 
didn't read carefully in the R extension manual. My initial search on the 
R help and R devel list archive didn't find useful information.

I am using .Call (as written in the R extension manual) for the C code 
and have found that the .Call didn't release the memory claimed by 
allocVector. Even after applying gc() function and removing the R object 
created by the .Call function, the memory was still not reclaimed back to 
the operating system.

Here is an example. It was modified from the convolve2 example from the R 
extension manual. Now I am computing the crossproduct of a and b, which 
returns a vector of size length(a)*length(b).

The C code is at the end of this message with the modification commented.
The R code is here
----------------------------
dyn.load("crossprod2.so")
cp <- function(a, b) .Call("crossprod2", a, b)
gctorture()
a<-1:10000
b<-1:1000
gc() #i

c<-cp(a,b)
rm(c)
gc() #ii
--------------

When I run the above code in a fresh start R (version 2.5.0)
the gc() inforamation is below. I report the last column ("max 
used (Mb)" ) here, which agrees the linux command "ps aux". Apparently 
even after I removing the object "c", we still have un-reclaimed 70M bytes 
of memory, which is approximately the memory size for the object "c".

If I run the command "c<-cp(a,b)" for three or four times and then remove the 
object "c" and apply gc() function, the unclaimed memory can reach 150M 
bytes. I tried gc(reset=TRUE), and it doesn't seem to make difference.

Can someone suggest what caused this problem and what the solution will 
be?  When you reply the email, please cc to me as I am not on the help 
list.

Thanks,

Yongchao

------------------------------------------------
> dyn.load("crossprod2.so")
> cp <- function(a, b) .Call("crossprod2", a, b)
> gctorture()
> a<-1:10000
> b<-1:1000


> gc() #i
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 173527  4.7     467875 12.5   350000  9.4
Vcells 108850  0.9     786432  6.0   398019  3.1
>
> c<-cp(a,b)
> rm(c)
> gc() #ii
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 233998  6.3     467875 12.5   350000  9.4
Vcells 108866  0.9   12089861 92.3 10119856 77.3
>
-----------------------------------------------






--------------------------------------------
#include "R.h"
#include "Rinternals.h"
#include "Rdefines.h"
SEXP crossprod2(SEXP a, SEXP b);
//modified from convolve2 in the R extension
//R CMD SHLIB crossprod2.c

#include <R.h>
#include <Rinternals.h>
SEXP crossprod2(SEXP a, SEXP b)
{
      R_len_t i, j, na, nb, nab;
      double *xa, *xb, *xab;
      SEXP ab;

      PROTECT(a = coerceVector(a, REALSXP));
      PROTECT(b = coerceVector(b, REALSXP));
      na = length(a); nb = length(b);

      //nab = na + nb - 1;
      nab=na*nb;// we are doing the cross product
      PROTECT(ab = allocVector(REALSXP, nab));
      xa = REAL(a); xb = REAL(b);
      xab = REAL(ab);
      for(i = 0; i < nab; i++) xab[i] = 0.0;
      for(i = 0; i < na; i++)
 	  for(j = 0; j < nb; j++) //xab[i + j] += xa[i] * xb[j];
 	       xab[i*nb + j] += xa[i] * xb[j];//we are computing crossproduct
      UNPROTECT(3);
      return(ab);
}


From prokaj at cs.elte.hu  Thu Aug 23 17:27:11 2007
From: prokaj at cs.elte.hu (prokaj at cs.elte.hu)
Date: Thu, 23 Aug 2007 17:27:11 +0200 (CEST)
Subject: [Rd] missing --vanilla option in INSTALL (PR#9877)
Message-ID: <20070823152711.5B88F206FA@slim.kubism.ku.dk>

Full_Name: Vilmos Prokaj
Version: 2.5.1
OS: windows
Submission from: (NULL) (81.183.3.216)


I'm not sure that this is really a bug, if not I do not understand why should it
be in this way.

Most of the scripts used to build and install new packages calls the R program
with the 
--slave --vanilla command line options. In the INSTALL script however we can
find the following lines


if($opt_library){
    # remove quotes around the library path
    $opt_library =~ s/^['"]//; $opt_library =~ s/['"]$//; #'"
    chdir($opt_library) ||
	die "Error: cannot change to library directory \$opt_library'\n";
    $library = cwd();
    $library = Win32::GetShortPathName($library) if $library =~ / /;
    my $R_LIBS = $ENV{'R_LIBS'};
    $ENV{'R_LIBS'} = join(";", $library, $R_LIBS);
    chdir($startdir);
} else {
    my @out = R_runR("cat('\n~~~', .libPaths()[1], '\n', sep = '')",
"--slave");
    foreach $f (@out) {
	if($f =~ /^~~~/) {
	    $library = $f;
	    $library =~ s/^~~~//;
	}
    }
    $library = Win32::GetShortPathName($library) if $library =~ / /;
    print "installing to '$library'\n";
}

I think that in the R_runR function there should be also a --vanilla option,
otherwise the process might be slow depending on the content of  .Rprofile
file.

The linenumber of the critical point is 132.

Sincerely yours 
  Vilmos Prokaj


From Ian.Cook at amd.com  Thu Aug 23 22:21:04 2007
From: Ian.Cook at amd.com (Cook, Ian)
Date: Thu, 23 Aug 2007 13:21:04 -0700
Subject: [Rd] RData File Specification?
Message-ID: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>

Hi,

I am developing a tool for converting a large data frame stored in an uncompressed binary (XDR) RData file to a delimited text file.  The data frame is too large to load() and extract rows from on a typical PC.  I'm looking to parse through the file and extract individual entries without loading the whole thing into memory.

In terms of some C source functions, instead of doing RestoreToEnv(R_Unserialize(connection)) which is essentially what load() does, I'm looking to get the documentation I would need to build a function "SaveToCSV()" so that I could do SaveToCSV(R_Unserialize(connection)).

Where can I get documentation on the RData file format?  Does a spec document exist?

See details below.

Thanks,
Ian

Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com

-------------------------

Additional details:

I've browsed through the relevant source code (saveload.c, serialize.c) for ideas.

Here's a demo of the problem I'm looking to solve:

# create a sample data frame
ds <- data.frame(row1=c(1,2,3),row2=c('a','b','c'))
# save into an uncompressed binary R dataset
save(ds,file="ds.rdata",compress=FALSE)
rm(ds)

# Then load() can be simulated like this:

# create and open a file connection
con <- file("ds.rdata",open="rb")
# read the first 5 characters
readChar(con,5)
# unserialize the remainder and restore to the environment
ds <- unserialize(con,NULL)[["ds"]]
close(con)

But this takes up too much memory if the data set is too big.  I can read in the file character-by-character, i.e. using readChar(), but it's obvious that the file format is not trivial.  readChar(con,10000) for this demo yields:

RDX2\nX\n\0\0\0\002\0\002\004\001\0\002\003\0\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\002ds\0\0\003\023\0\0\0\002\0\0\0\016\0\0\0\003??\0\0\0\0\0\0@\0\0\0\0\0\0\0@\b\0\0\0\0\0\0\0\0\003\r\0\0\0\003\0\0\0\001\0\0\0\002\0\0\0\003\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\006levels\0\0\0\020\0\0\0\003\0\0\0\t\0\0\0\001a\0\0\0\t\0\0\0\001b\0\0\0\t\0\0\0\001c\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005class\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\006factor\0\0\0?\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005names\0\0\0\020\0\0\0\002\0\0\0\t\0\0\0\004row1\0\0\0\t\0\0\0\004row2\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\trow.names\0\0\0\r\0\0\0\002?\0\0\0\0\0\0\003\0\0\004\002\0\0\003?\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\ndata.frame\0\0\0?\0\0\0?

This would be parse-able if I had a file spec.  Thanks.

Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com


From ripley at stats.ox.ac.uk  Fri Aug 24 11:41:31 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri, 24 Aug 2007 11:41:31 +0200 (CEST)
Subject: [Rd] missing --vanilla option in INSTALL (PR#9877)
Message-ID: <20070824094131.D29D948B93@slim.kubism.ku.dk>

This is as documented, and intentional.  From ?INSTALL

      If used as 'R CMD INSTALL pkgs' without explicitly specifying
      'lib', packages are installed into the library tree rooted at the
      first directory in the library path which would be used by R run
      in the current environment.

and to do that needs .Rprofile and .Renviron to be processed.

As the R FAQ says:

   If you aren't familiar with the command, or don't know for certain how
   the command is supposed to work, then it might actually be working right.
   Rather than jumping to conclusions, show the problem to someone who
   knows for certain.


On Thu, 23 Aug 2007, prokaj at cs.elte.hu wrote:

> Full_Name: Vilmos Prokaj
> Version: 2.5.1
> OS: windows
> Submission from: (NULL) (81.183.3.216)
>
>
> I'm not sure that this is really a bug, if not I do not understand why 
> should it be in this way.
>
> Most of the scripts used to build and install new packages calls the R 
> program with the --slave --vanilla command line options.

I think you have shown far too little respect for the understanding of the 
R developers.

> In the INSTALL script however we can find the following lines
>
>
> if($opt_library){
>    # remove quotes around the library path
>    $opt_library =~ s/^['"]//; $opt_library =~ s/['"]$//; #'"
>    chdir($opt_library) ||
> 	die "Error: cannot change to library directory \$opt_library'\n";
>    $library = cwd();
>    $library = Win32::GetShortPathName($library) if $library =~ / /;
>    my $R_LIBS = $ENV{'R_LIBS'};
>    $ENV{'R_LIBS'} = join(";", $library, $R_LIBS);
>    chdir($startdir);
> } else {
>    my @out = R_runR("cat('\n~~~', .libPaths()[1], '\n', sep = '')",
> "--slave");
>    foreach $f (@out) {
> 	if($f =~ /^~~~/) {
> 	    $library = $f;
> 	    $library =~ s/^~~~//;
> 	}
>    }
>    $library = Win32::GetShortPathName($library) if $library =~ / /;
>    print "installing to '$library'\n";
> }
>
> I think that in the R_runR function there should be also a --vanilla option,
> otherwise the process might be slow depending on the content of  .Rprofile
> file.
>
> The linenumber of the critical point is 132.
>
> Sincerely yours
>  Vilmos Prokaj
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Aug 24 13:18:23 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Aug 2007 12:18:23 +0100 (BST)
Subject: [Rd] .Call and to reclaim the memory by allocVector
In-Reply-To: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>
References: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>
Message-ID: <Pine.LNX.4.64.0708241204240.20766@gannet.stats.ox.ac.uk>

Please do not post to multiple lists! I've removed R-help.

You have not told us your OS ('linux', perhaps but what CPU), nor how you 
know 'the memory was still not reclaimed back to the operating system'. 
But that is how many OSes work: their malloc maintains a pool of memory 
pages, and free() does not return the memory to the OS kernel, just to the 
process' pool.  It depends on what you meant by 'the operating system'.

Why does this bother you?  150Mb of virtual memory is nothing these days.


On Thu, 23 Aug 2007, Yongchao Ge wrote:

> Hi,
>
> I am not sure if this is a bug and I apologize if it is something I
> didn't read carefully in the R extension manual. My initial search on the
> R help and R devel list archive didn't find useful information.

Exactly this topic was thrashed to death under the misleading title of 
'Suspected memory leak' earlier this month in a thread that started on 
R-help and moved to R-devel. See e.g.

https://stat.ethz.ch/pipermail/r-devel/2007-August/046669.html

from the author of the R memory allocator.


> I am using .Call (as written in the R extension manual) for the C code
> and have found that the .Call didn't release the memory claimed by
> allocVector. Even after applying gc() function and removing the R object
> created by the .Call function, the memory was still not reclaimed back to
> the operating system.
>
> Here is an example. It was modified from the convolve2 example from the R
> extension manual. Now I am computing the crossproduct of a and b, which
> returns a vector of size length(a)*length(b).
>
> The C code is at the end of this message with the modification commented.
> The R code is here
> ----------------------------
> dyn.load("crossprod2.so")
> cp <- function(a, b) .Call("crossprod2", a, b)
> gctorture()
> a<-1:10000
> b<-1:1000
> gc() #i
>
> c<-cp(a,b)
> rm(c)
> gc() #ii
> --------------
>
> When I run the above code in a fresh start R (version 2.5.0)
> the gc() inforamation is below. I report the last column ("max
> used (Mb)" ) here, which agrees the linux command "ps aux". Apparently
> even after I removing the object "c", we still have un-reclaimed 70M bytes
> of memory, which is approximately the memory size for the object "c".
>
> If I run the command "c<-cp(a,b)" for three or four times and then remove the
> object "c" and apply gc() function, the unclaimed memory can reach 150M
> bytes. I tried gc(reset=TRUE), and it doesn't seem to make difference.
>
> Can someone suggest what caused this problem and what the solution will
> be?  When you reply the email, please cc to me as I am not on the help
> list.
>
> Thanks,
>
> Yongchao
>
> ------------------------------------------------
>> dyn.load("crossprod2.so")
>> cp <- function(a, b) .Call("crossprod2", a, b)
>> gctorture()
>> a<-1:10000
>> b<-1:1000
>
>
>> gc() #i
>          used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 173527  4.7     467875 12.5   350000  9.4
> Vcells 108850  0.9     786432  6.0   398019  3.1
>>
>> c<-cp(a,b)
>> rm(c)
>> gc() #ii
>          used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 233998  6.3     467875 12.5   350000  9.4
> Vcells 108866  0.9   12089861 92.3 10119856 77.3
>>
> -----------------------------------------------
>
>
>
>
>
>
> --------------------------------------------
> #include "R.h"
> #include "Rinternals.h"
> #include "Rdefines.h"
> SEXP crossprod2(SEXP a, SEXP b);
> //modified from convolve2 in the R extension
> //R CMD SHLIB crossprod2.c
>
> #include <R.h>
> #include <Rinternals.h>
> SEXP crossprod2(SEXP a, SEXP b)
> {
>      R_len_t i, j, na, nb, nab;
>      double *xa, *xb, *xab;
>      SEXP ab;
>
>      PROTECT(a = coerceVector(a, REALSXP));
>      PROTECT(b = coerceVector(b, REALSXP));
>      na = length(a); nb = length(b);
>
>      //nab = na + nb - 1;
>      nab=na*nb;// we are doing the cross product
>      PROTECT(ab = allocVector(REALSXP, nab));
>      xa = REAL(a); xb = REAL(b);
>      xab = REAL(ab);
>      for(i = 0; i < nab; i++) xab[i] = 0.0;
>      for(i = 0; i < na; i++)
> 	  for(j = 0; j < nb; j++) //xab[i + j] += xa[i] * xb[j];
> 	       xab[i*nb + j] += xa[i] * xb[j];//we are computing crossproduct
>      UNPROTECT(3);
>      return(ab);
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paul at stat.auckland.ac.nz  Fri Aug 24 10:45:55 2007
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 24 Aug 2007 10:45:55 +0200
Subject: [Rd] RData File Specification?
In-Reply-To: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
Message-ID: <46CE9AC3.7020703@stat.auckland.ac.nz>

Hi


Cook, Ian wrote:
> Hi,
> 
> I am developing a tool for converting a large data frame stored in an
> uncompressed binary (XDR) RData file to a delimited text file.  The
> data frame is too large to load() and extract rows from on a typical
> PC.  I'm looking to parse through the file and extract individual
> entries without loading the whole thing into memory.
> 
> In terms of some C source functions, instead of doing
> RestoreToEnv(R_Unserialize(connection)) which is essentially what
> load() does, I'm looking to get the documentation I would need to
> build a function "SaveToCSV()" so that I could do
> SaveToCSV(R_Unserialize(connection)).
> 
> Where can I get documentation on the RData file format?  Does a spec
> document exist?
> 
> See details below.
> 
> Thanks, Ian
> 
> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
> 
> -------------------------
> 
> Additional details:
> 
> I've browsed through the relevant source code (saveload.c,
> serialize.c) for ideas.
> 
> Here's a demo of the problem I'm looking to solve:
> 
> # create a sample data frame ds <-
> data.frame(row1=c(1,2,3),row2=c('a','b','c')) # save into an
> uncompressed binary R dataset save(ds,file="ds.rdata",compress=FALSE)
>  rm(ds)
> 
> # Then load() can be simulated like this:
> 
> # create and open a file connection con <- file("ds.rdata",open="rb")
>  # read the first 5 characters readChar(con,5) # unserialize the
> remainder and restore to the environment ds <-
> unserialize(con,NULL)[["ds"]] close(con)
> 
> But this takes up too much memory if the data set is too big.  I can
> read in the file character-by-character, i.e. using readChar(), but
> it's obvious that the file format is not trivial.
> readChar(con,10000) for this demo yields:
> 
> RDX2\nX\n\0\0\0\002\0\002\004\001\0\002\003\0\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\002ds\0\0\003\023\0\0\0\002\0\0\0\016\0\0\0\003??\0\0\0\0\0\0@\0\0\0\0\0\0\0@\b\0\0\0\0\0\0\0\0\003\r\0\0\0\003\0\0\0\001\0\0\0\002\0\0\0\003\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\006levels\0\0\0\020\0\0\0\003\0\0\0\t\0\0\0\001a\0\0\0\t\0\0\0\001b\0\0\0\t\0\0\0\001c\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005class\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\006factor\0\0\0?\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005names\0\0\0\020\0\0\0\002\0\0\0\t\0\0\0\004row1\0\0\0\t\0\0\0\004row2\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\trow.names\0\0\0\r\0\0\0\002?\0\0\0\0\0\0\003\0\0\004\002\0\0\003?\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\ndata.frame\0\0\0?\0\0\0?
> 
> 
> This would be parse-able if I had a file spec.  Thanks.


See the "R Internals" manual
http://cran.r-project.org/doc/manuals/R-ints.html

You might also find page 5 of R News 7/1 useful for exploring the format
http://cran.r-project.org/doc/Rnews/Rnews_2007-1.pdf

Paul


> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
> 
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ldimitro at wfubmc.edu  Fri Aug 24 17:21:47 2007
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Fri, 24 Aug 2007 11:21:47 -0400
Subject: [Rd] compiling R under cygwin
In-Reply-To: <Pine.LNX.4.64.0708240526280.30984@gannet.stats.ox.ac.uk>
References: <66CE7F4ACF0C74439F9F6E0A5682930202FF5CA7@INDMAIL.lands.resnet.qg>
	<Pine.LNX.4.64.0708230724220.15873@gannet.stats.ox.ac.uk>
	<F160BE32A2E5E04497668BBDFE83FEDF11CF87A5@EXCHVS1.medctr.ad.wfubmc.edu>
	<46CE3119.4060909@stats.uwo.ca>
	<Pine.LNX.4.64.0708240526280.30984@gannet.stats.ox.ac.uk>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF87AB@EXCHVS1.medctr.ad.wfubmc.edu>

 

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Friday, August 24, 2007 2:00 AM
> To: Duncan Murdoch
> Cc: Latchezar (Lucho) Dimitrov; r-devel at r-project.org
> Subject: Re: [Rd] compiling R under cygwin
> 
> On Thu, 23 Aug 2007, Duncan Murdoch wrote:
> 
> > The issue is compatibility with other Windows programs.  
> /path/to/file 
> > works in lots of Windows programs, and is interpreted 
> relative to the 
> > current drive.  In the common situation where the user only has one 
> > partition which is mounted as C:, it works (as long as they didn't 
> > switch to a CD or USB drive).
> 
> In particular, it does not work on my system where I need to 
> run under two OSes, Vista64 on C: and WinXP on D:, with 
> common development on E: .
> 
> I had originally intended to work entirely on E: and mount 
> E:/ as /, which is what you need to get Cygwin to return 
> /path/to/file for working files on E: .

There are many other options. Please check my e-mail with dir and ls
output.

> But Cygwin does not 
> handle permissions on a Vista NTFS file system well enough.

Would you please elaborate on this?

This one (as many others) I may consider Vista issues as well.

Again, I'm not pro or con cygwin. I actually do not want R on it.

> 
> Latchezar (Lucho) Dimitrov wrote
> 
> > 5. AFAIK 64-bit R on your favorite Windows is far far away (even 
> > Windows is not close enough although it's getting there) 
> and I'd like 
> > to see those above (and enjoy watching them) when Windows is not 
> > enough, e.g., microarray analysis/BioConductor.
> 
> That's just not true.  There have been reports of 64-bit R 
> ports to Windows and many people are running 64-bit Windows 
> on servers and some on desktops (including me).  A 
> MinGW-based 64-bit R for Windows is under active development 
> (which is why I have Vista64 installed

I suffer it too :-) and wholeheartedly sympathize you.

).

Thanks for the good news. Although it might be a little bit late - it
was not there when I badly needed it now that I have Solaris 10 OS x64 R
I barely would use it. Sorry. Please no bad feelings.

>  This is even 
> covered in the rw-FAQ (Q8.1, and yes that is a file with 
> numbered TOC).

OK, I take my words back - it's not "far far" it's only "far away" (or
even only "away" if this makes you happier :-). Meaning not _only R
itself but Windows as well_, i.e., the platform plus R. I admit my
initial statement was not that clear, sorry. As you can see here no
blames on R (core :-).

> 
> What seems 'far, far away' is something like Cygwin for 
> 64-bit Windows.

I agree but would use stronger expression here close to "never". And
this is one reason to try minGW (AFAIK they are close to have 64-bit of
it)

> (I saw on a Cygwin list that RedHat wanted $$$$$ to do it, 
> for too many $$$$$ for the potential customers.)  The 32-bit 
> version is said to work under the WOW 32-bit emulation layer 
> but many of us find it flaky.
> 
> Personally I use Linux (the main OS on the machine I mention 
> above) and
> Solaris: however many R users (quite possibly the substantial 
> majority of all R users even excluding student usage) want a 
> native Windows version.

I personally use whatever is most appropriate and hate it to be any
flavor of Windows but ... Again, how is Rgui more "native Windows
version" then plain native Windows CLI version? Are you using/confusing
"native"s two possible meanings here? One being minGW meaning of
"native" and the other as in "native Windows user" :-)))

Latchezar

> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From cooch17 at verizon.net  Fri Aug 24 18:24:41 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 24 Aug 2007 12:24:41 -0400
Subject: [Rd] config error during 2.5.1 compile
Message-ID: <46CF0649.20602@verizon.net>

Have been running 2.5.1 on my multi-pro Opteron box running Fedora Core 
5 with no problems. Had compiled previously with no problems. However, 
for a variety of reasons (mostly due to ACML upgrade), I tried a 
recompile using the following sequence of commands (note I'm compiling 
in ACML support for blas):

LD_LIBRARY_PATH=/opt/acml3.6.1/gfortran64/lib
export LD_LIBRARY_PATH
./configure --with-lapack   
--with-blas="-L/opt/acml3.6.0/gfortran64/lib  -lacml"


This is exactly the same steps I took successfully many times before, 
but now, when I run the config, it terminates with the following error 
message:

config.status: error: cannot find input file: doc/manual/Makefile.in


Now, this puzzles me since doc/manual/Makefile.in is most definitely 
there, but the configure script isn't finding it, for some reason.

Is this a tarball bug? I grabbed another from a different mirror, but 
ended up with the same error.

Oh, and I can say with authority the problem isn't with ACML - I get the 
error even if I point everything at the older (3.6.0) ACML libs. So, the 
problem seems to originate in the configure script.

Can anyone confirm, or 'fix' (workaround?)

Ta in advance...


From cooch17 at verizon.net  Fri Aug 24 18:37:41 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 24 Aug 2007 12:37:41 -0400
Subject: [Rd] config error during 2.5.1 compile
In-Reply-To: <46CF0649.20602@verizon.net>
References: <46CF0649.20602@verizon.net>
Message-ID: <46CF0955.3090500@verizon.net>

For what its worth, I get the same error even if I do a naked 'config' 
(no lapack, no blas, no reference to ACML).
>
> config.status: error: cannot find input file: doc/manual/Makefile.in
>
>   


So, I think its a tarball issue.


From cooch17 at verizon.net  Fri Aug 24 18:44:15 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 24 Aug 2007 12:44:15 -0400
Subject: [Rd] config error during 2.5.1 compile
In-Reply-To: <46CF0649.20602@verizon.net>
References: <46CF0649.20602@verizon.net>
Message-ID: <46CF0ADF.9000402@verizon.net>

Solved - finally (after 4-5 different mirrors) found a tarball that 
didn't give the report configure error.

Strange...


From hin-tak.leung at cimr.cam.ac.uk  Fri Aug 24 20:06:52 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 24 Aug 2007 19:06:52 +0100
Subject: [Rd] RData File Specification?
In-Reply-To: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
Message-ID: <46CF1E3C.8000408@cimr.cam.ac.uk>

I was going to write 'Use the source, Luke', but it seems that you have 
alreday found the relevant source files. I wrote a Python baed Rdata 
writer and a reader sometimes ago just using that info and I am not
away of any file spec, so I know those two files are sufficient. For 
what you want to do, I think you'll have to write some fairly 
substantial code to process the Rdata as just XDR stream (as my python 
scripts do, using the python built-in xdrlib),
because as far as I know the API you are after is not exposed - you'll
have to - and you can - cut and paste a substantial part of saveload.c
and serialize.c for that matter, of course.

I think my python-based Rdata reader would do most of what you want
(it was written for mostly diagnostic purposes as I was 'hand-crafting'
R objects in C and saving them as Rdata then read it tell me what's 
wrong with them, if any) except it dumps a sort of general human 
readable ascii text format rather than csv...

My sugegstion would be to use a lanaguage you are comfortable with which 
comes with an xdr library, and just do it by hand...

Cook, Ian wrote:
> Hi,
> 
> I am developing a tool for converting a large data frame stored in an uncompressed binary (XDR) RData file to a delimited text file.  The data frame is too large to load() and extract rows from on a typical PC.  I'm looking to parse through the file and extract individual entries without loading the whole thing into memory.
> 
> In terms of some C source functions, instead of doing RestoreToEnv(R_Unserialize(connection)) which is essentially what load() does, I'm looking to get the documentation I would need to build a function "SaveToCSV()" so that I could do SaveToCSV(R_Unserialize(connection)).
> 
> Where can I get documentation on the RData file format?  Does a spec document exist?
> 
> See details below.
> 
> Thanks,
> Ian
> 
> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
> 
> -------------------------
> 
> Additional details:
> 
> I've browsed through the relevant source code (saveload.c, serialize.c) for ideas.
> 
> Here's a demo of the problem I'm looking to solve:
> 
> # create a sample data frame
> ds <- data.frame(row1=c(1,2,3),row2=c('a','b','c'))
> # save into an uncompressed binary R dataset
> save(ds,file="ds.rdata",compress=FALSE)
> rm(ds)
> 
> # Then load() can be simulated like this:
> 
> # create and open a file connection
> con <- file("ds.rdata",open="rb")
> # read the first 5 characters
> readChar(con,5)
> # unserialize the remainder and restore to the environment
> ds <- unserialize(con,NULL)[["ds"]]
> close(con)
> 
> But this takes up too much memory if the data set is too big.  I can read in the file character-by-character, i.e. using readChar(), but it's obvious that the file format is not trivial.  readChar(con,10000) for this demo yields:
> 
> RDX2\nX\n\0\0\0\002\0\002\004\001\0\002\003\0\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\002ds\0\0\003\023\0\0\0\002\0\0\0\016\0\0\0\003??\0\0\0\0\0\0@\0\0\0\0\0\0\0@\b\0\0\0\0\0\0\0\0\003\r\0\0\0\003\0\0\0\001\0\0\0\002\0\0\0\003\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\006levels\0\0\0\020\0\0\0\003\0\0\0\t\0\0\0\001a\0\0\0\t\0\0\0\001b\0\0\0\t\0\0\0\001c\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005class\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\006factor\0\0\0?\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\005names\0\0\0\020\0\0\0\002\0\0\0\t\0\0\0\004row1\0\0\0\t\0\0\0\004row2\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0\trow.names\0\0\0\r\0\0\0\002?\0\0\0\0\0\0\003\0\0\004\002\0\0\003?\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\ndata.frame\0\0\0?\0\0\0?
> 
> This would be parse-able if I had a file spec.  Thanks.
> 
> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at stat.berkeley.edu  Fri Aug 24 21:07:50 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 24 Aug 2007 12:07:50 -0700
Subject: [Rd] Suggestion: Making attach() and detach() generic
Message-ID: <59d7961d0708241207j5f66a6abkca2626455df810c9@mail.gmail.com>

Hi,

I would like to suggest to make base::attach() and base::detach()
generic, in order to attach/detach fields of other containers
("databases") than the currently supported ones.

According to help on attach(), one could dispatch on (first) argument 'what'):

    what: "database".  This may currently be a 'data.frame' or a 'list'
          or a R data file created with 'save' or 'NULL' or an
          environment.  See also Details.

So, in S3 terms, something like:

attach():
 attach.data.frame()
 attach.list()
 attach.environment()
 attach.character()
 attach.default()

detach() could be extended in a similar way.

The first step to make attach()/detach() generic would to justed
rename the current attach() to attach.default() and ditto for
detach().  [I haven't investigated all the side effects of doing this;
there could be problems with substitute():s etc.]

Comments?  I would be happy to do the mods, if wanted.

Cheers

Henrik


From Ian.Cook at amd.com  Sat Aug 25 00:36:40 2007
From: Ian.Cook at amd.com (Cook, Ian)
Date: Fri, 24 Aug 2007 15:36:40 -0700
Subject: [Rd] RData File Specification?
In-Reply-To: <46CF1E3C.8000408@cimr.cam.ac.uk>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
	<46CF1E3C.8000408@cimr.cam.ac.uk>
Message-ID: <A312DAB4DB8DC34D86C006C5D8199D466BBB22@ssvlexmb2.amd.com>

It looks like there's a Perl XDR library, but I haven't tested it.
http://search.cpan.org/src/GORD/XDR-0.03/

This might be easy to do all within R if more of the source functions in
serialize.c (ReadItem, MakeReadRefTable, etc.) were callable using
.Internal (i.e. if they were in the R_FunTab table in names.c).

Thanks for your help.

Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com


-----Original Message-----
From: Hin-Tak Leung [mailto:hin-tak.leung at cimr.cam.ac.uk] 
Sent: Friday, August 24, 2007 11:07 AM
To: Cook, Ian
Cc: r-devel at r-project.org
Subject: Re: [Rd] RData File Specification?

I was going to write 'Use the source, Luke', but it seems that you have 
alreday found the relevant source files. I wrote a Python baed Rdata 
writer and a reader sometimes ago just using that info and I am not
away of any file spec, so I know those two files are sufficient. For 
what you want to do, I think you'll have to write some fairly 
substantial code to process the Rdata as just XDR stream (as my python 
scripts do, using the python built-in xdrlib),
because as far as I know the API you are after is not exposed - you'll
have to - and you can - cut and paste a substantial part of saveload.c
and serialize.c for that matter, of course.

I think my python-based Rdata reader would do most of what you want
(it was written for mostly diagnostic purposes as I was 'hand-crafting'
R objects in C and saving them as Rdata then read it tell me what's 
wrong with them, if any) except it dumps a sort of general human 
readable ascii text format rather than csv...

My sugegstion would be to use a lanaguage you are comfortable with which

comes with an xdr library, and just do it by hand...

Cook, Ian wrote:
> Hi,
> 
> I am developing a tool for converting a large data frame stored in an
uncompressed binary (XDR) RData file to a delimited text file.  The data
frame is too large to load() and extract rows from on a typical PC.  I'm
looking to parse through the file and extract individual entries without
loading the whole thing into memory.
> 
> In terms of some C source functions, instead of doing
RestoreToEnv(R_Unserialize(connection)) which is essentially what load()
does, I'm looking to get the documentation I would need to build a
function "SaveToCSV()" so that I could do
SaveToCSV(R_Unserialize(connection)).
> 
> Where can I get documentation on the RData file format?  Does a spec
document exist?
> 
> See details below.
> 
> Thanks,
> Ian
> 
> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com


From simon.urbanek at r-project.org  Sat Aug 25 04:01:12 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Aug 2007 22:01:12 -0400
Subject: [Rd] RData File Specification?
In-Reply-To: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
Message-ID: <76447F9C-A6A8-4BDA-81DB-44EC316A1C5A@r-project.org>

Ian,

On Aug 23, 2007, at 4:21 PM, Cook, Ian wrote:

> I am developing a tool for converting a large data frame stored in  
> an uncompressed binary (XDR) RData file to a delimited text file.   
> The data frame is too large to load() and extract rows from on a  
> typical PC.  I'm looking to parse through the file and extract  
> individual entries without loading the whole thing into memory.
>
> In terms of some C source functions, instead of doing RestoreToEnv 
> (R_Unserialize(connection)) which is essentially what load() does,  
> I'm looking to get the documentation I would need to build a  
> function "SaveToCSV()" so that I could do SaveToCSV(R_Unserialize 
> (connection)).
>
> Where can I get documentation on the RData file format?  Does a  
> spec document exist?
>

I don't think so - basically the sources are all the documentation  
I'm aware of. It's a bit messy, because R supports so many old formats.

However, if you want a stand-alone program that handles  
(uncompressed) XDR2 only, then I may have saved you a bit of work. I  
have a utility (based on the R sources) that allows you to scan  
through XDR2 files and to extract individual objects into a separate  
XDR2 file (this happens to be quite useful when you have a workspace  
that doesn't load into R and yet you want to save some pieces of it).  
Have a look at
http://urbanek.info/rdcopy.c

(you can either run it as "./rdcopy foo" to list the objects or "./ 
rdcopy foo -v" to show the full structure (all SEXPs with their  
offsets) or "./rdcopy foo bar 19" to copy SEXP at offset 19 from foo  
into a separate XDR2 file bar (use offset from the first call to copy  
entire objects).

It's not prefect, but servers its purpose (it resolves references by  
copying them instead of re-indexing, but it doesn't detect loops).  
Maybe it helps, even though the task you describe is still far from  
trivial.

Cheers,
Simon


From simon.urbanek at r-project.org  Sat Aug 25 04:07:18 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Aug 2007 22:07:18 -0400
Subject: [Rd] RData File Specification?
In-Reply-To: <46CF1E3C.8000408@cimr.cam.ac.uk>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
	<46CF1E3C.8000408@cimr.cam.ac.uk>
Message-ID: <0E49B2DD-8E31-4924-8A76-C21EE601626B@r-project.org>


On Aug 24, 2007, at 2:06 PM, Hin-Tak Leung wrote:

> I was going to write 'Use the source, Luke', but it seems that you  
> have
> alreday found the relevant source files. I wrote a Python baed Rdata
> writer and a reader sometimes ago just using that info and I am not
> away of any file spec, so I know those two files are sufficient. For
> what you want to do, I think you'll have to write some fairly
> substantial code to process the Rdata as just XDR stream (as my python
> scripts do, using the python built-in xdrlib),


Unfortunately the format is not true XDR (it is not padded properly -  
CHARs (incl. symbols etc.) and raw vectors violate the padding  
rules), so you have to fall back to low-level access for some parts.  
It effect, the only part of XDR used is the storage of int and double  
(which is quite trivial), so IMHO any language (even without XDR)  
will do ...

Cheers,
Simon


> because as far as I know the API you are after is not exposed - you'll
> have to - and you can - cut and paste a substantial part of saveload.c
> and serialize.c for that matter, of course.
>
> I think my python-based Rdata reader would do most of what you want
> (it was written for mostly diagnostic purposes as I was 'hand- 
> crafting'
> R objects in C and saving them as Rdata then read it tell me what's
> wrong with them, if any) except it dumps a sort of general human
> readable ascii text format rather than csv...
>
> My sugegstion would be to use a lanaguage you are comfortable with  
> which
> comes with an xdr library, and just do it by hand...
>
> Cook, Ian wrote:
>> Hi,
>>
>> I am developing a tool for converting a large data frame stored in  
>> an uncompressed binary (XDR) RData file to a delimited text file.   
>> The data frame is too large to load() and extract rows from on a  
>> typical PC.  I'm looking to parse through the file and extract  
>> individual entries without loading the whole thing into memory.
>>
>> In terms of some C source functions, instead of doing RestoreToEnv 
>> (R_Unserialize(connection)) which is essentially what load() does,  
>> I'm looking to get the documentation I would need to build a  
>> function "SaveToCSV()" so that I could do SaveToCSV(R_Unserialize 
>> (connection)).
>>
>> Where can I get documentation on the RData file format?  Does a  
>> spec document exist?
>>
>> See details below.
>>
>> Thanks,
>> Ian
>>
>> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
>>
>> -------------------------
>>
>> Additional details:
>>
>> I've browsed through the relevant source code (saveload.c,  
>> serialize.c) for ideas.
>>
>> Here's a demo of the problem I'm looking to solve:
>>
>> # create a sample data frame
>> ds <- data.frame(row1=c(1,2,3),row2=c('a','b','c'))
>> # save into an uncompressed binary R dataset
>> save(ds,file="ds.rdata",compress=FALSE)
>> rm(ds)
>>
>> # Then load() can be simulated like this:
>>
>> # create and open a file connection
>> con <- file("ds.rdata",open="rb")
>> # read the first 5 characters
>> readChar(con,5)
>> # unserialize the remainder and restore to the environment
>> ds <- unserialize(con,NULL)[["ds"]]
>> close(con)
>>
>> But this takes up too much memory if the data set is too big.  I  
>> can read in the file character-by-character, i.e. using readChar 
>> (), but it's obvious that the file format is not trivial.  readChar 
>> (con,10000) for this demo yields:
>>
>> RDX2\nX\n\0\0\0\002\0\002\004\001\0\002\003\0\0\0\004\002\0\0\0\001 
>> \0\0\020\t\0\0\0\002ds\0\0\003\023\0\0\0\002\0\0\0\016\0\0\0\003?? 
>> \0\0\0\0\0\0@\0\0\0\0\0\0\0@\b\0\0\0\0\0\0\0\0\003\r\0\0\0\003\0\0 
>> \0\001\0\0\0\002\0\0\0\003\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0 
>> \006levels\0\0\0\020\0\0\0\003\0\0\0\t\0\0\0\001a\0\0\0\t\0\0\0 
>> \001b\0\0\0\t\0\0\0\001c\0\0\004\002\0\0\0\001\0\0\020\t\0\0\0 
>> \005class\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\006factor\0\0\0?\0\0 
>> \004\002\0\0\0\001\0\0\020\t\0\0\0\005names\0\0\0\020\0\0\0\002\0\0 
>> \0\t\0\0\0\004row1\0\0\0\t\0\0\0\004row2\0\0\004\002\0\0\0\001\0\0 
>> \020\t\0\0\0\trow.names\0\0\0\r\0\0\0\002?\0\0\0\0\0\0\003\0\0\004 
>> \002\0\0\003?\0\0\0\020\0\0\0\001\0\0\0\t\0\0\0\ndata.frame\0\0\0? 
>> \0\0\0?
>>
>> This would be parse-able if I had a file spec.  Thanks.
>>
>> Ian Cook | Advanced Micro Devices, Inc. | ian.cook at amd.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Yongchao.Ge at mssm.edu  Fri Aug 24 15:43:54 2007
From: Yongchao.Ge at mssm.edu (Yongchao Ge)
Date: Fri, 24 Aug 2007 09:43:54 -0400 (EDT)
Subject: [Rd] .Call and to reclaim the memory by allocVector
In-Reply-To: <Pine.LNX.4.64.0708241204240.20766@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>
	<Pine.LNX.4.64.0708241204240.20766@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0708240836001.22543@ge.anbg.mssm.edu>

Dear Prof. Ripley

I am using 32bit Ubuntu 7.04 on Dual Core Intel Xeon Processor 5140. I do 
not think that it is the OS's problem in recognizing the memory released by 
free(), as the Calloc() and Free() pair works perfectly well in my 
C program. I'm assuming that the free() in your post does not mean
the standard C library function, but the Free() in the R extension, as 
recommended to release the memory back to the OS by the R extension 
manual.

It was not the 150MB that bothers me. I used the toy example to 
isolate the problem. My actual program needs to allocate around 660M bytes 
(maybe more, depending on the actual dataset) for a return from .Call. 
This return object is stored in R and will be used by many other 
functions, which also uses .Call to wrap the C code. I found that my 
program reaches the memory limit (3G) very quickly even though at most 
1.8G bytes of data should be in the memory in the C and R codes combined 
(potentially two copies of the same R object and a copy in the C 
program). The memory problem in .Call means that my program 
can run once or twice, and it fails the third time. I need to run the 
same program more than twice.

Why am I storing a large dataset in the R? My program consist of two 
parts. The first part is to get the intermediate results, the computation 
of which takes a lot of time. The second part contains many 
different functions to manipulate the the intermediate 
results.

My current solution is to save intermediate result in a temporary file, 
but my final goal is to to save it as an R object. The "memory leak" in 
.Call stops me from doing this and I'd like to know if I can have a clean 
solution for the R package I am writing.

Yongchao

On Fri, 24 Aug 2007, Prof Brian Ripley wrote:

> Please do not post to multiple lists! I've removed R-help.
>
> You have not told us your OS ('linux', perhaps but what CPU), nor how you 
> know 'the memory was still not reclaimed back to the operating system'. But 
> that is how many OSes work: their malloc maintains a pool of memory pages, 
> and free() does not return the memory to the OS kernel, just to the process' 
> pool.  It depends on what you meant by 'the operating system'.
>
> Why does this bother you?  150Mb of virtual memory is nothing these days.
>
>
> On Thu, 23 Aug 2007, Yongchao Ge wrote:
>
>> Hi,
>> 
>> I am not sure if this is a bug and I apologize if it is something I
>> didn't read carefully in the R extension manual. My initial search on the
>> R help and R devel list archive didn't find useful information.
>
> Exactly this topic was thrashed to death under the misleading title of 
> 'Suspected memory leak' earlier this month in a thread that started on R-help 
> and moved to R-devel. See e.g.
>
> https://stat.ethz.ch/pipermail/r-devel/2007-August/046669.html
>
> from the author of the R memory allocator.
>
>
>> I am using .Call (as written in the R extension manual) for the C code
>> and have found that the .Call didn't release the memory claimed by
>> allocVector. Even after applying gc() function and removing the R object
>> created by the .Call function, the memory was still not reclaimed back to
>> the operating system.
>> 
>> Here is an example. It was modified from the convolve2 example from the R
>> extension manual. Now I am computing the crossproduct of a and b, which
>> returns a vector of size length(a)*length(b).
>> 
>> The C code is at the end of this message with the modification commented.
>> The R code is here
>> ----------------------------
>> dyn.load("crossprod2.so")
>> cp <- function(a, b) .Call("crossprod2", a, b)
>> gctorture()
>> a<-1:10000
>> b<-1:1000
>> gc() #i
>> 
>> c<-cp(a,b)
>> rm(c)
>> gc() #ii
>> --------------
>> 
>> When I run the above code in a fresh start R (version 2.5.0)
>> the gc() inforamation is below. I report the last column ("max
>> used (Mb)" ) here, which agrees the linux command "ps aux". Apparently
>> even after I removing the object "c", we still have un-reclaimed 70M bytes
>> of memory, which is approximately the memory size for the object "c".
>> 
>> If I run the command "c<-cp(a,b)" for three or four times and then remove 
>> the
>> object "c" and apply gc() function, the unclaimed memory can reach 150M
>> bytes. I tried gc(reset=TRUE), and it doesn't seem to make difference.
>> 
>> Can someone suggest what caused this problem and what the solution will
>> be?  When you reply the email, please cc to me as I am not on the help
>> list.
>> 
>> Thanks,
>> 
>> Yongchao
>> 
>> ------------------------------------------------
>>> dyn.load("crossprod2.so")
>>> cp <- function(a, b) .Call("crossprod2", a, b)
>>> gctorture()
>>> a<-1:10000
>>> b<-1:1000
>> 
>> 
>>> gc() #i
>>          used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 173527  4.7     467875 12.5   350000  9.4
>> Vcells 108850  0.9     786432  6.0   398019  3.1
>>> 
>>> c<-cp(a,b)
>>> rm(c)
>>> gc() #ii
>>          used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 233998  6.3     467875 12.5   350000  9.4
>> Vcells 108866  0.9   12089861 92.3 10119856 77.3
>>> 
>> -----------------------------------------------
>> 
>> 
>> 
>> 
>> 
>> 
>> --------------------------------------------
>> #include "R.h"
>> #include "Rinternals.h"
>> #include "Rdefines.h"
>> SEXP crossprod2(SEXP a, SEXP b);
>> //modified from convolve2 in the R extension
>> //R CMD SHLIB crossprod2.c
>> 
>> #include <R.h>
>> #include <Rinternals.h>
>> SEXP crossprod2(SEXP a, SEXP b)
>> {
>>      R_len_t i, j, na, nb, nab;
>>      double *xa, *xb, *xab;
>>      SEXP ab;
>>
>>      PROTECT(a = coerceVector(a, REALSXP));
>>      PROTECT(b = coerceVector(b, REALSXP));
>>      na = length(a); nb = length(b);
>>
>>      //nab = na + nb - 1;
>>      nab=na*nb;// we are doing the cross product
>>      PROTECT(ab = allocVector(REALSXP, nab));
>>      xa = REAL(a); xb = REAL(b);
>>      xab = REAL(ab);
>>      for(i = 0; i < nab; i++) xab[i] = 0.0;
>>      for(i = 0; i < na; i++)
>> 	  for(j = 0; j < nb; j++) //xab[i + j] += xa[i] * xb[j];
>> 	       xab[i*nb + j] += xa[i] * xb[j];//we are computing crossproduct
>>      UNPROTECT(3);
>>      return(ab);
>> }
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Yongchao Ge                                  Yongchao.Ge at mssm.edu
Mount Sinai School of Medicine               office: 212-241-3536
Department of Neurology
One Gustave L. Levy Place, Box 1137     New York, NY, 10029, USA
web url: www.mssm.edu/faculty/yongchao-ge
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


From sfalcon at fhcrc.org  Sat Aug 25 17:16:54 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 25 Aug 2007 08:16:54 -0700
Subject: [Rd] .Call and to reclaim the memory by allocVector
In-Reply-To: <Pine.LNX.4.64.0708240836001.22543@ge.anbg.mssm.edu> (Yongchao
	Ge's message of "Fri\, 24 Aug 2007 09\:43\:54 -0400 \(EDT\)")
References: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>
	<Pine.LNX.4.64.0708241204240.20766@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0708240836001.22543@ge.anbg.mssm.edu>
Message-ID: <m2hcmnd4pl.fsf@ziti.fhcrc.org>

Hi Yongchao,

Yongchao Ge <Yongchao.Ge at mssm.edu> writes:
> Why am I storing a large dataset in the R? My program consist of two 
> parts. The first part is to get the intermediate results, the computation 
> of which takes a lot of time. The second part contains many 
> different functions to manipulate the the intermediate 
> results.
>
> My current solution is to save intermediate result in a temporary file, 
> but my final goal is to to save it as an R object. The "memory leak" in 
> .Call stops me from doing this and I'd like to know if I can have a clean 
> solution for the R package I am writing.

There are many examples of packages that use .Call to create large
objects.  I don't think there is a "memory leak".

One thing that may be catching you up is that because of R's
pass-by-value semantics, you may be ending up with multiple copies of
the object on the R side during some of your operations.  I would
recommend recompiling with --enable-memory-profiling and using
tracemem() to see if you can identify places where copies of your
large object are occurring.  You can also take a look at
Rprof(memory.profile=TRUE).

+ seth


-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From hin-tak.leung at cimr.cam.ac.uk  Mon Aug 27 01:53:11 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 27 Aug 2007 00:53:11 +0100
Subject: [Rd] RData File Specification?
In-Reply-To: <0E49B2DD-8E31-4924-8A76-C21EE601626B@r-project.org>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
	<46CF1E3C.8000408@cimr.cam.ac.uk>
	<0E49B2DD-8E31-4924-8A76-C21EE601626B@r-project.org>
Message-ID: <46D21267.8080907@cimr.cam.ac.uk>

Simon Urbanek wrote:
> 
> On Aug 24, 2007, at 2:06 PM, Hin-Tak Leung wrote:
> 
>> I was going to write 'Use the source, Luke', but it seems that you have
>> alreday found the relevant source files. I wrote a Python baed Rdata
>> writer and a reader sometimes ago just using that info and I am not
>> away of any file spec, so I know those two files are sufficient. For
>> what you want to do, I think you'll have to write some fairly
>> substantial code to process the Rdata as just XDR stream (as my python
>> scripts do, using the python built-in xdrlib),
> 
> 
> Unfortunately the format is not true XDR (it is not padded properly - 
> CHARs (incl. symbols etc.) and raw vectors violate the padding rules), 
> so you have to fall back to low-level access for some parts. It effect, 
> the only part of XDR used is the storage of int and double (which is 
> quite trivial), so IMHO any language (even without XDR) will do ...
> 
> Cheers,
> Simon

Yes, I found out about the char not-padding-to-multple-of-4-byte part 
the "hard" way. Still, the python xdrlib library saved me a bit of 
hassle abstracting away from endian issues - since I work mostly on
small endian machines and xdr-based data being bigendian -, even though
I had to "backtrack" my file pointers in the cases of padding
char/raw's...

Anyway, "the source is your guide"...

<snipped>


From ripley at stats.ox.ac.uk  Mon Aug 27 09:13:27 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Aug 2007 08:13:27 +0100 (BST)
Subject: [Rd] RData File Specification?
In-Reply-To: <0E49B2DD-8E31-4924-8A76-C21EE601626B@r-project.org>
References: <A312DAB4DB8DC34D86C006C5D8199D466BBB1C@ssvlexmb2.amd.com>
	<46CF1E3C.8000408@cimr.cam.ac.uk>
	<0E49B2DD-8E31-4924-8A76-C21EE601626B@r-project.org>
Message-ID: <Pine.LNX.4.64.0708270801390.20787@gannet.stats.ox.ac.uk>

On Fri, 24 Aug 2007, Simon Urbanek wrote:

>
> On Aug 24, 2007, at 2:06 PM, Hin-Tak Leung wrote:
>
>> I was going to write 'Use the source, Luke', but it seems that you
>> have
>> alreday found the relevant source files. I wrote a Python baed Rdata
>> writer and a reader sometimes ago just using that info and I am not
>> away of any file spec, so I know those two files are sufficient. For
>> what you want to do, I think you'll have to write some fairly
>> substantial code to process the Rdata as just XDR stream (as my python
>> scripts do, using the python built-in xdrlib),
>
>
> Unfortunately the format is not true XDR (it is not padded properly -
> CHARs (incl. symbols etc.) and raw vectors violate the padding
> rules), so you have to fall back to low-level access for some parts.
> It effect, the only part of XDR used is the storage of int and double
> (which is quite trivial), so IMHO any language (even without XDR)
> will do ...

I don't think XDR for doubles is 'quite trivial': it is if your native 
format is the conventional IEC60559 representation (when all you have to 
worry about is byte order), but not in general.  (Some of us remember 
interworking with Vaxen, for example.)

Note that the format is not actually claimed to be XDR: ?save says

      All R platforms use the XDR representation of binary objects in
      binary save-d files, and these are portable across all R
      platforms.

That was probably written before RAWSXPs, but it is not claiming that 
character strings are written in XDR.  (RFC 1832 seems to expect ASCII 
character strings, so XDR string format would be a pain to use.)

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Thomas.Petzoldt at tu-dresden.de  Mon Aug 27 14:40:57 2007
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Mon, 27 Aug 2007 14:40:57 +0200
Subject: [Rd] silent option in nested calls to try()
Message-ID: <46D2C659.90208@tu-dresden.de>

Hello,

is it *really intentional* that the "silent" option of try() does only 
apply to the outer call in nested try constructs? I would assume that a 
silent try() should suppress all error messages regardless where they 
occur, even if they are already handled with other try()'s.

The error message itself should be (and is in both cases) reported by 
the return value of try().

Thanks in advance

Thomas


## Old behavior (tested with R-2.4.1):
 >  try(try(exp(NULL)), silent=TRUE)
 >


## Current behavior (R-2.6.0 unstable, build 42641, WinXP):
 >  try(try(exp(NULL)), silent=TRUE)
Error in exp(NULL) : Non-numeric argument to mathematical function
 >



-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie
01062 Dresden
GERMANY

http://tu-dresden.de/Members/thomas.petzoldt


From luke at stat.uiowa.edu  Mon Aug 27 15:15:22 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 27 Aug 2007 08:15:22 -0500 (CDT)
Subject: [Rd] silent option in nested calls to try()
In-Reply-To: <46D2C659.90208@tu-dresden.de>
References: <46D2C659.90208@tu-dresden.de>
Message-ID: <Pine.LNX.4.64.0708270815060.2819@itasca.stat.uiowa.edu>

Yes.  If you want finer control use tryCatch.

Best,

luke

On Mon, 27 Aug 2007, Thomas Petzoldt wrote:

> Hello,
>
> is it *really intentional* that the "silent" option of try() does only
> apply to the outer call in nested try constructs? I would assume that a
> silent try() should suppress all error messages regardless where they
> occur, even if they are already handled with other try()'s.
>
> The error message itself should be (and is in both cases) reported by
> the return value of try().
>
> Thanks in advance
>
> Thomas
>
>
> ## Old behavior (tested with R-2.4.1):
> >  try(try(exp(NULL)), silent=TRUE)
> >
>
>
> ## Current behavior (R-2.6.0 unstable, build 42641, WinXP):
> >  try(try(exp(NULL)), silent=TRUE)
> Error in exp(NULL) : Non-numeric argument to mathematical function
> >
>
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From Thomas.Petzoldt at tu-dresden.de  Mon Aug 27 16:20:59 2007
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Mon, 27 Aug 2007 16:20:59 +0200
Subject: [Rd] silent option in nested calls to try()
In-Reply-To: <Pine.LNX.4.64.0708270815060.2819@itasca.stat.uiowa.edu>
References: <46D2C659.90208@tu-dresden.de>
	<Pine.LNX.4.64.0708270815060.2819@itasca.stat.uiowa.edu>
Message-ID: <46D2DDCB.6060008@tu-dresden.de>

Dear Luke,

thank you very much for your immediate answer. The problem I see is, 
however, that while one can rewrite ones outer code using tryCatch, one 
may not have control over the use of try in a given inner function.

Thomas



Luke Tierney wrote:
> Yes.  If you want finer control use tryCatch.
> 
> Best,
> 
> luke
> 
> On Mon, 27 Aug 2007, Thomas Petzoldt wrote:
> 
>> Hello,
>>
>> is it *really intentional* that the "silent" option of try() does only
>> apply to the outer call in nested try constructs? I would assume that a
>> silent try() should suppress all error messages regardless where they
>> occur, even if they are already handled with other try()'s.
>>
>> The error message itself should be (and is in both cases) reported by
>> the return value of try().
>>
>> Thanks in advance
>>
>> Thomas
>>
>>
>> ## Old behavior (tested with R-2.4.1):
>> >  try(try(exp(NULL)), silent=TRUE)
>> >
>>
>>
>> ## Current behavior (R-2.6.0 unstable, build 42641, WinXP):
>> >  try(try(exp(NULL)), silent=TRUE)
>> Error in exp(NULL) : Non-numeric argument to mathematical function
>> >
>>
>>
>>
>>
>


From jbrzusto at fastmail.fm  Mon Aug 27 16:33:48 2007
From: jbrzusto at fastmail.fm (jbrzusto at fastmail.fm)
Date: Mon, 27 Aug 2007 16:33:48 +0200 (CEST)
Subject: [Rd] fix for broken largefile seek() on 32-bit linux (PR#9883)
Message-ID: <20070827143348.0302E668E6@slim.kubism.ku.dk>

Full_Name: John Brzustowski
Version: R-devel-trunk, R-2.4.0
OS: linux
Submission from: (NULL) (206.248.132.197)


DESCRIPTION

seek() on files larger than 2 gigabytes fails for large values of "where" on
i386 linux 2.6.13 (and presumably other 32-bit unix-like platforms).

e.g.:

> f<-file("3gigabytefile.dat", "rb")
> seek(f, 3e9, "start", "r")
[1] 0  ## correct
> seek(f, NA, "start", "r")
[1] 0  ## should be 3e+09

DIAGNOSIS

Typo: the compile-time tests for large file support use "HAVE_SEEKO" instead of
"HAVE_FSEEKO", and so fail.  

The same typo appears in one of the extra/zlib files, so I'm fixing
it in the patch below, but I haven't tested whether that actually
produces a bug.

PATCH
Index: src/extra/zlib/gzio.c
===================================================================
--- src/extra/zlib/gzio.c	(revision 42664)
+++ src/extra/zlib/gzio.c	(working copy)
@@ -25,7 +25,7 @@
 #include "zutil.h"
 
 /* R ADDITION */
-#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
+#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
 #define f_seek fseeko
 #define f_tell ftello
 #else
Index: src/include/Rconnections.h
===================================================================
--- src/include/Rconnections.h	(revision 42664)
+++ src/include/Rconnections.h	(working copy)
@@ -63,7 +63,7 @@
 
 typedef struct fileconn {
     FILE *fp;
-#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
+#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
     off_t rpos, wpos;
 #else
 #ifdef Win32
Index: src/main/connections.c
===================================================================
--- src/main/connections.c	(revision 42664)
+++ src/main/connections.c	(working copy)
@@ -446,7 +446,7 @@
 
 /* ------------------- file connections --------------------- */
 
-#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
+#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
 #define f_seek fseeko
 #define f_tell ftello
 #else
@@ -570,7 +570,7 @@
 {
     Rfileconn this = con->private;
     FILE *fp = this->fp;
-#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
+#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
     off_t pos;
 #else
 #ifdef Win32


From luke at stat.uiowa.edu  Mon Aug 27 16:42:36 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Mon, 27 Aug 2007 09:42:36 -0500 (CDT)
Subject: [Rd] silent option in nested calls to try()
In-Reply-To: <46D2DDCB.6060008@tu-dresden.de>
References: <46D2C659.90208@tu-dresden.de>
	<Pine.LNX.4.64.0708270815060.2819@itasca.stat.uiowa.edu>
	<46D2DDCB.6060008@tu-dresden.de>
Message-ID: <Pine.LNX.4.64.0708270934400.4484@nokomis.stat.uiowa.edu>

Your best option is to contact the author of the software and ask them
to use silent = TRUE or try to play some games with output capture.

try() is an old interface that has been reimplemented on top of
tryCatch.  It could be modified to, for example, use message(), which
would then allow messages to be suppressed with suppressMessages, but
this leaves the issue of warnings (see the try() code).  Coming up
with something that behaves sensibly would require a considerable
design effort.  I don't see the effort as warranted at this point.

The choice of silent=TRUE as the default is I believe unfortunate but
it has been so for many years.  Again I don't see the effort in
changing this as warranted at this point.

Best,

luke

On Mon, 27 Aug 2007, Thomas Petzoldt wrote:

> Dear Luke,
>
> thank you very much for your immediate answer. The problem I see is, however, 
> that while one can rewrite ones outer code using tryCatch, one may not have 
> control over the use of try in a given inner function.
>
> Thomas
>
>
>
> Luke Tierney wrote:
>> Yes.  If you want finer control use tryCatch.
>> 
>> Best,
>> 
>> luke
>> 
>> On Mon, 27 Aug 2007, Thomas Petzoldt wrote:
>> 
>>> Hello,
>>> 
>>> is it *really intentional* that the "silent" option of try() does only
>>> apply to the outer call in nested try constructs? I would assume that a
>>> silent try() should suppress all error messages regardless where they
>>> occur, even if they are already handled with other try()'s.
>>> 
>>> The error message itself should be (and is in both cases) reported by
>>> the return value of try().
>>> 
>>> Thanks in advance
>>> 
>>> Thomas
>>> 
>>> 
>>> ## Old behavior (tested with R-2.4.1):
>>> >  try(try(exp(NULL)), silent=TRUE)
>>> >
>>> 
>>> 
>>> ## Current behavior (R-2.6.0 unstable, build 42641, WinXP):
>>> >  try(try(exp(NULL)), silent=TRUE)
>>> Error in exp(NULL) : Non-numeric argument to mathematical function
>>> >
>>> 
>>> 
>>> 
>>> 
>> 
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From hb at stat.berkeley.edu  Mon Aug 27 20:22:48 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 27 Aug 2007 11:22:48 -0700
Subject: [Rd] Suggestion: Add simpleExit condition
Message-ID: <59d7961d0708271122w846163eoad70e941780495bd@mail.gmail.com>

Hi,

I would like to bring up and old suggestion
[http://tolstoy.newcastle.edu.au/R/devel/06/03/4512.html] of adding an
exit condition, so that for instance it is possible to silently exit
from scripts and Rd examples similar to return() for functions, e.g.

\examples{
require("foo") || exit("Example will not run without the 'foo' package.")
...
}

I know this can be solved by a simple if {require("foo")} { }
statement, but the above is to avoid such nested code, especially in
example code, cf. return() and break.

Here are the details to get this working:

1. Define a new condition class similar to simpleWarning() and simpleError():

simpleExit <- function(...) {
  cond <- simpleCondition(...)
  class(cond) <- c("simpleExit", class(cond))   cond
}

2. Setup a method to generate such a condition similar to warning() and stop():

exit <- function(...) {
  invisible(signalCondition(simpleExit(...))) }
}

3. That is the basic framework. We can then use tryCatch() to catch
and return upon a simpleExit as follows:

evalWithExit <- function(...) {
  tryCatch(..., simpleExit=function(cond) cond) }
}

Then it is matter of flavor if one wants to update source() with an
argument 'allowExits=FALSE' or have a standalone function:

sourceWithExit <- function(...) {
  evalWithExit(source(...))
}

5. The code example() needs to be updated accordingly, i.e. replacing
source() with sourceWithExit().

6. src/scripts/check.in needs to updated so that the examples are
sourced detecting simpleExit:s.

Steps 1-4 can be added without side effects.  It is Step 5 & 6 that
needs extra care.  I am happy to contribute the above if it would be
accepted.

Best,

Henrik

PS. As I queried on in my follow up of the March 2006 thread, if there
is a way to signal user-interrupts programatically, all of the above
is not necessary. DS.


From Andy.Bunn at wwu.edu  Mon Aug 27 22:19:12 2007
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 27 Aug 2007 13:19:12 -0700
Subject: [Rd] [OT] How many useRs?
Message-ID: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070827/6e038322/attachment.pl 

From cberry at tajo.ucsd.edu  Tue Aug 28 00:44:23 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Mon, 27 Aug 2007 15:44:23 -0700
Subject: [Rd] [OT] How many useRs?
In-Reply-To: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>
References: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>
Message-ID: <Pine.LNX.4.64.0708271543590.19709@tajo.ucsd.edu>



Ahem!

 	RSiteSearch("user base")


On Mon, 27 Aug 2007, Andy Bunn wrote:

> I figured the devel list would have people on it who might know the
> answer to this....
>
>
>
> Is there a reliable (for some definition of reliable) estimate of how
> many people use R or have downloaded it? Say an order of magnitude
> estimate? I would like to mention this in the introduction to a paper
> I'm writing where I encourage R's use.
>
>
>
> Thanks for any help.
>
>
>
> -Andy
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From Andy.Bunn at wwu.edu  Tue Aug 28 00:49:38 2007
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 27 Aug 2007 15:49:38 -0700
Subject: [Rd] [OT] How many useRs?
In-Reply-To: <Pine.LNX.4.64.0708271543590.19709@tajo.ucsd.edu>
References: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>
	<Pine.LNX.4.64.0708271543590.19709@tajo.ucsd.edu>
Message-ID: <B786254B2435F94E808B17CEC2A432F708725F9C@EVS1.univ.dir.wwu.edu>

I've seen that thread. Given the way R use has increased over the last
three and a half years I thought it not unlikely that somebody might
have taken a stab at this again.

-----Original Message-----
From: Charles C. Berry [mailto:cberry at tajo.ucsd.edu] 
Sent: Monday, August 27, 2007 3:44 PM
To: Andy Bunn
Cc: r-devel at r-project.org
Subject: Re: [Rd] [OT] How many useRs?



Ahem!

 	RSiteSearch("user base")


On Mon, 27 Aug 2007, Andy Bunn wrote:

> I figured the devel list would have people on it who might know the
> answer to this....
>
>
>
> Is there a reliable (for some definition of reliable) estimate of how
> many people use R or have downloaded it? Say an order of magnitude
> estimate? I would like to mention this in the introduction to a paper
> I'm writing where I encourage R's use.
>
>
>
> Thanks for any help.
>
>
>
> -Andy
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego
92093-0901


From edd at debian.org  Tue Aug 28 01:52:10 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 27 Aug 2007 18:52:10 -0500
Subject: [Rd] [OT] How many useRs?
In-Reply-To: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>
References: <B786254B2435F94E808B17CEC2A432F708725E05@EVS1.univ.dir.wwu.edu>
Message-ID: <18131.25514.995691.969613@ron.nulle.part>


On 27 August 2007 at 13:19, Andy Bunn wrote:
| Is there a reliable (for some definition of reliable) estimate of how
| many people use R or have downloaded it? Say an order of magnitude
| estimate? I would like to mention this in the introduction to a paper
| I'm writing where I encourage R's use.

With a salt mine rather than a mere grain of salt, you could consider the
'popularity contest' results from Debian and Ubuntu.  Briefly, it's an
'opt-in' service that submits the list of installed packages, anonymoysly, to
an aggregation address.   

Using Ubuntu's large install base, we get from http://popcon.ubuntu.com that
eg the GNU bc package in their 'main/math' section is installed (and
reported) 174452 times (based on http://popcon.ubuntu.com/main/math/by_inst).
As this is a mandatory package, we can use this as the baseline.  On the
other hand r-base-core (from the optional universe/math section) is installed
2638 times (see http://popcon.ubuntu.com/universe/math/by_inst).
So you get 2638 / 174452 or around 1.5%.  You now need to figure the various
self-selection biases and correct for those...

As a check, for Debian (with popcon.debian.org as the base URL), we get 1686
/ 54221 or around 3.1% (using file http://popcon.debian.org/main/math/by_inst).  
So even this crude measure has a large amount of variability.  So I still
invoke fortune(43).  

But if you insist, you could use Microsoft's recent 'one billion PCs'
estimate (news.bbc.co.uk/1/hi/sci/tech/2077986.stm), apply the percentages we
laboriously derive above and call it 15 to 31 million....

Dirk

-- 
Three out of two people have difficulties with fractions.


From gregor.gorjanc at bfro.uni-lj.si  Tue Aug 28 10:12:58 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 28 Aug 2007 10:12:58 +0200
Subject: [Rd] Typo in regex help page
Message-ID: <46D3D90A.2090104@bfro.uni-lj.si>

Hi!

I believe there is a typo in

R/src/library/base/man/regex.Rd

The 52nd line looks like:

The metacharacters are in EREs are ...
                    ^^^^^^^^^^^

Gregor


From ripley at stats.ox.ac.uk  Tue Aug 28 11:34:23 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 28 Aug 2007 11:34:23 +0200 (CEST)
Subject: [Rd] fix for broken largefile seek() on 32-bit linux (PR#9883)
Message-ID: <20070828093423.B5C3E668EC@slim.kubism.ku.dk>

I've applied the patch, but I no longer have a 32-bit Linux system. Could 
you please verify it has applied correctly (SVN rev 42672 on trunk, 42673 
on R-patched).  A quick check on 32-bit Solaris suggested it worked as 
expected.

On Mon, 27 Aug 2007, jbrzusto at fastmail.fm wrote:

> Full_Name: John Brzustowski
> Version: R-devel-trunk, R-2.4.0
> OS: linux
> Submission from: (NULL) (206.248.132.197)
>
>
> DESCRIPTION
>
> seek() on files larger than 2 gigabytes fails for large values of "where" on
> i386 linux 2.6.13 (and presumably other 32-bit unix-like platforms).
>
> e.g.:
>
>> f<-file("3gigabytefile.dat", "rb")
>> seek(f, 3e9, "start", "r")
> [1] 0  ## correct
>> seek(f, NA, "start", "r")
> [1] 0  ## should be 3e+09
>
> DIAGNOSIS
>
> Typo: the compile-time tests for large file support use "HAVE_SEEKO" instead of
> "HAVE_FSEEKO", and so fail.
>
> The same typo appears in one of the extra/zlib files, so I'm fixing
> it in the patch below, but I haven't tested whether that actually
> produces a bug.
>
> PATCH
> Index: src/extra/zlib/gzio.c
> ===================================================================
> --- src/extra/zlib/gzio.c	(revision 42664)
> +++ src/extra/zlib/gzio.c	(working copy)
> @@ -25,7 +25,7 @@
> #include "zutil.h"
>
> /* R ADDITION */
> -#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
> +#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
> #define f_seek fseeko
> #define f_tell ftello
> #else
> Index: src/include/Rconnections.h
> ===================================================================
> --- src/include/Rconnections.h	(revision 42664)
> +++ src/include/Rconnections.h	(working copy)
> @@ -63,7 +63,7 @@
>
> typedef struct fileconn {
>     FILE *fp;
> -#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
> +#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
>     off_t rpos, wpos;
> #else
> #ifdef Win32
> Index: src/main/connections.c
> ===================================================================
> --- src/main/connections.c	(revision 42664)
> +++ src/main/connections.c	(working copy)
> @@ -446,7 +446,7 @@
>
> /* ------------------- file connections --------------------- */
>
> -#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
> +#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
> #define f_seek fseeko
> #define f_tell ftello
> #else
> @@ -570,7 +570,7 @@
> {
>     Rfileconn this = con->private;
>     FILE *fp = this->fp;
> -#if defined(HAVE_OFF_T) && defined(HAVE_SEEKO)
> +#if defined(HAVE_OFF_T) && defined(HAVE_FSEEKO)
>     off_t pos;
> #else
> #ifdef Win32
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m.crawley at imperial.ac.uk  Tue Aug 28 16:44:25 2007
From: m.crawley at imperial.ac.uk (m.crawley at imperial.ac.uk)
Date: Tue, 28 Aug 2007 16:44:25 +0200 (CEST)
Subject: [Rd] subcripts on data frames (PR#9885)
Message-ID: <20070828144425.383BA668EE@slim.kubism.ku.dk>

I'm not sure if this is a bug, or if I'm doing something wrong.
=20
=46rom the worms dataframe, which is at in a file called worms.txt at
=20
http://www.imperial.ac.uk/bio/research/crawley/therbook
<http://www.imperial.ac.uk/bio/research/mjcraw/therbook/index.htm>=20

=20
the idea is to extract a subset of the rows, sorted in declining order
of worm density, with only the maximum worm density from each vegetation
type:
=20

worms<-read.table("c:\\temp\\worms.txt",header=3DT)
attach(worms)
names(worms)

[1] "Field.Name"   "Area"         "Slope"        "Vegetation"
"Soil.pH"=20=20=20=20=20
[6] "Damp"         "Worm.density"

=20
Usinng "not duplicated" I get two rows for Meadow and none for Scrub
=20
worms[rev(order(Worm.density)),] [!duplicated(Vegetation),]

       Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7
2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
4     Rush.Meadow  2.4     5     Meadow     4.9  TRUE            5

and here is the correct set of rows, but in the wrong order, using
unique
=20
worms[rev(order(Worm.density)),] [unique(Vegetation),]

       Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
11    Garden.Wood  2.9    10      Scrub     5.2 FALSE            8
2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7

=20
Best wishes,
=20
Mick
=20
Prof  M.J. Crawley  FRS
=20
Imperial College London
Silwood Park
Ascot
Berks
SL5 7PY
UK
=20
Phone (0) 207 5942 216
Fax     (0) 207 5942 339
=20

	[[alternative HTML version deleted]]


From tplate at acm.org  Tue Aug 28 17:44:26 2007
From: tplate at acm.org (Tony Plate)
Date: Tue, 28 Aug 2007 09:44:26 -0600
Subject: [Rd] subcripts on data frames (PR#9885)
In-Reply-To: <20070828144425.383BA668EE@slim.kubism.ku.dk>
References: <20070828144425.383BA668EE@slim.kubism.ku.dk>
Message-ID: <46D442DA.8060500@acm.org>

The line

worms[rev(order(Worm.density)),] [!duplicated(Vegetation),]

looks suspect to me -- it looks like you are first creating an sorted 
version of the dataframe 'worms', and then subsetting it based on values 
of 'Vegetation' in the original order.  When reordering dataframes I 
would avoid 'attaching' them and I would break the expression into two 
separate expressions, so to be sure the subsetting is referring to the 
appropriate values:

 > worms <- 
read.table("http://www.bio.ic.ac.uk/research/mjcraw/therbook/data/worms.txt", 
header=T)
 > worms2 <- worms[rev(order(worms$Worm.density)), ]
 > worms2[!duplicated(worms2$Vegetation), ]
       Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
11    Garden.Wood  2.9    10      Scrub     5.2 FALSE            8
10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7
2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
 >

Here's a one-liner involving 'with' and 'subset':
 > subset(worms[rev(order(worms$Worm.density)), ], !duplicated(Vegetation))
       Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
11    Garden.Wood  2.9    10      Scrub     5.2 FALSE            8
10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7
2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
 >

-- Tony Plate

m.crawley at imperial.ac.uk wrote:
> I'm not sure if this is a bug, or if I'm doing something wrong.
> =20
> =46rom the worms dataframe, which is at in a file called worms.txt at
> =20
> http://www.imperial.ac.uk/bio/research/crawley/therbook
> <http://www.imperial.ac.uk/bio/research/mjcraw/therbook/index.htm>=20
>
> =20
> the idea is to extract a subset of the rows, sorted in declining order
> of worm density, with only the maximum worm density from each vegetation
> type:
> =20
>
> worms<-read.table("c:\\temp\\worms.txt",header=3DT)
> attach(worms)
> names(worms)
>
> [1] "Field.Name"   "Area"         "Slope"        "Vegetation"
> "Soil.pH"=20=20=20=20=20
> [6] "Damp"         "Worm.density"
>
> =20
> Usinng "not duplicated" I get two rows for Meadow and none for Scrub
> =20
> worms[rev(order(Worm.density)),] [!duplicated(Vegetation),]
>
>        Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
> 9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
> 16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
> 10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7
> 2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
> 4     Rush.Meadow  2.4     5     Meadow     4.9  TRUE            5
>
> and here is the correct set of rows, but in the wrong order, using
> unique
> =20
> worms[rev(order(Worm.density)),] [unique(Vegetation),]
>
>        Field.Name Area Slope Vegetation Soil.pH  Damp Worm.density
> 16   Water.Meadow  3.9     0     Meadow     4.9  TRUE            8
> 9     The.Orchard  1.9     0    Orchard     5.7 FALSE            9
> 11    Garden.Wood  2.9    10      Scrub     5.2 FALSE            8
> 2  Silwood.Bottom  5.1     2     Arable     5.2 FALSE            7
> 10  Rookery.Slope  1.5     4  Grassland     5.0  TRUE            7
>
> =20
> Best wishes,
> =20
> Mick
> =20
> Prof  M.J. Crawley  FRS
> =20
> Imperial College London
> Silwood Park
> Ascot
> Berks
> SL5 7PY
> UK
> =20
> Phone (0) 207 5942 216
> Fax     (0) 207 5942 339
> =20
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at stat.berkeley.edu  Tue Aug 28 22:24:48 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 28 Aug 2007 13:24:48 -0700
Subject: [Rd] R CMD check: Error in function (env) : could not find function
	"finalize"
Message-ID: <59d7961d0708281324q11f966d2y724c0bdb0a98e036@mail.gmail.com>

Hi,

does someone else get this error message:

Error in function (env)  : could not find function "finalize"?

I get an error when running examples in R CMD check (v2.6.0; session
info below):

> ### * invertMap
>
> flush(stderr()); flush(stdout())
> ### Name: invertMap
> ### Title: Inverts a read or a write map
> ### Aliases: invertMap
> ### Keywords: file IO internal
>
> ### ** Examples
>
> # .... [TRUNCATED]
> nbrOfCells <- 2600000
> readMap <- sample(nbrOfCells)
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"

The error occurs in R CMD check but also when start a fresh R session
and run, in this case, affxparser.Rcheck/affxparser-Ex.R.  It always
occur on the same line.

When I debug(sample), all values passed to the internal function looks
fine.  I've replaced it with runif() and vector("double", nbrOfCells)
and manged to get the error there too.  So, it seems like there are
some memory issues.  I've called gc() just before without success.
There are a lot of other example code processed before this one and
many of them rely on native code, so it could be a memory leak or
something.  However, before troubleshooting more, I wanted to hear if
someone else got the same problem.  Searching google, gives me one hit
in a recent Bioconductor build/check.  From Google cache
http://tinyurl.com/25hkld

> ## Perform svdImpute using the 3 largest components
> result <- pca(metaboliteData, method="svdImpute", nPcs=3, center = TRUE)
Error in function (env)  : could not find function "finalize"
...

Now, the error is not there.

Any ideas?

/Henrik

> sessionInfo()
R version 2.6.0 Under development (unstable) (2007-08-23 r42614)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MON
ETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252


attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] affxparser_1.9.5

loaded via a namespace (and not attached):
[1] AffymetrixDataTestFiles_0.1.0


From sfalcon at fhcrc.org  Wed Aug 29 06:48:10 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 28 Aug 2007 21:48:10 -0700
Subject: [Rd] R CMD check: Error in function (env) : could not find
	function "finalize"
In-Reply-To: <59d7961d0708281324q11f966d2y724c0bdb0a98e036@mail.gmail.com>
	(Henrik Bengtsson's message of "Tue\,
	28 Aug 2007 13\:24\:48 -0700")
References: <59d7961d0708281324q11f966d2y724c0bdb0a98e036@mail.gmail.com>
Message-ID: <m2lkbv0wvp.fsf@ziti.fhcrc.org>

Hi Henrik,

"Henrik Bengtsson" <hb at stat.berkeley.edu> writes:

> Hi,
>
> does someone else get this error message:
>
> Error in function (env)  : could not find function "finalize"?
>
> I get an error when running examples in R CMD check (v2.6.0; session
> info below):
[snip]
> The error occurs in R CMD check but also when start a fresh R session
> and run, in this case, affxparser.Rcheck/affxparser-Ex.R.  It always
> occur on the same line.

So does options(error=recover) help in determining where the error is
coming from?

If you can narrow it down, gctorture may help or running the examples
under valgrind.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From Yongchao.Ge at mssm.edu  Tue Aug 28 19:02:16 2007
From: Yongchao.Ge at mssm.edu (Yongchao Ge)
Date: Tue, 28 Aug 2007 13:02:16 -0400 (EDT)
Subject: [Rd] .Call and to reclaim the memory by allocVector
In-Reply-To: <m2hcmnd4pl.fsf@ziti.fhcrc.org>
References: <Pine.LNX.4.64.0708231337200.15511@ge.anbg.mssm.edu>
	<Pine.LNX.4.64.0708241204240.20766@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0708240836001.22543@ge.anbg.mssm.edu>
	<m2hcmnd4pl.fsf@ziti.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0708281101010.29194@ge.anbg.mssm.edu>

Hi Seth,

Thank you for the suggestion. Because of using .Call (which does not copy 
the value) for both parts of my program, there is no extra copy shown by 
tracemem(). Anyway, the information shown by gc() is very misleading as 
stated by Prof. Ripley, especially after creating and removing a 
couple of large R datasets and applying the function gc() a couple of times.

As shown by "ps aux", there is no "memory leak" from .Call. It's a big 
relief to me. Mysteriously, my program works now for storing the 
intermediate results as a 660M R object. I can run the same function  as 
often as I want. The maximum space taken by the program has never 
exceeded 1.8G as I expected. The disappearance of taking too much memory 
from .Call may be due to a recompile of my C code or a restart of the 
linux or a fresh mind after the weekend.

Thank you and Prof. Ripley for the suggestions. It helps me to stay 
focused.


Yongchao




On Sat, 25 Aug 2007, Seth Falcon wrote:

> Hi Yongchao,
>
> Yongchao Ge <Yongchao.Ge at mssm.edu> writes:
>> Why am I storing a large dataset in the R? My program consist of two
>> parts. The first part is to get the intermediate results, the computation
>> of which takes a lot of time. The second part contains many
>> different functions to manipulate the the intermediate
>> results.
>>
>> My current solution is to save intermediate result in a temporary file,
>> but my final goal is to to save it as an R object. The "memory leak" in
>> .Call stops me from doing this and I'd like to know if I can have a clean
>> solution for the R package I am writing.
>
> There are many examples of packages that use .Call to create large
> objects.  I don't think there is a "memory leak".
>
> One thing that may be catching you up is that because of R's
> pass-by-value semantics, you may be ending up with multiple copies of
> the object on the R side during some of your operations.  I would
> recommend recompiling with --enable-memory-profiling and using
> tracemem() to see if you can identify places where copies of your
> large object are occurring.  You can also take a look at
> Rprof(memory.profile=TRUE).
>
> + seth
>
>
> -- 
> Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
> BioC: http://bioconductor.org/
> Blog: http://userprimary.net/user/


From savicky at cs.cas.cz  Wed Aug 29 15:53:27 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 29 Aug 2007 15:53:27 +0200
Subject: [Rd] NA and NaN in function identical
Message-ID: <20070829135327.GF7082@cs.cas.cz>

The help page for function identical says:
     'identical' sees 'NaN' as different from 'as.double(NA)', but all
     'NaN's are equal (and all 'NA' of the same type are equal).
However, we have
  x <- NaN
  y <- as.double(NA)
  x # [1] NaN
  y # [1] NA
  identical(x,y) # [1] TRUE

In my opinion, NaN and as.double(NA) should be distinguished as the 
help page suggests.

Tested under R version 2.5.1 Patched (2007-08-19 r42638) on Linux (CPU Xeon).

Petr Savicky.


From ripley at stats.ox.ac.uk  Wed Aug 29 17:53:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Aug 2007 16:53:05 +0100 (BST)
Subject: [Rd] NA and NaN in function identical
In-Reply-To: <20070829135327.GF7082@cs.cas.cz>
References: <20070829135327.GF7082@cs.cas.cz>
Message-ID: <Pine.LNX.4.64.0708291646130.1607@gannet.stats.ox.ac.uk>

On Wed, 29 Aug 2007, Petr Savicky wrote:

> The help page for function identical says:
>     'identical' sees 'NaN' as different from 'as.double(NA)', but all
>     'NaN's are equal (and all 'NA' of the same type are equal).
> However, we have
>  x <- NaN
>  y <- as.double(NA)
>  x # [1] NaN
>  y # [1] NA
>  identical(x,y) # [1] TRUE
>
> In my opinion, NaN and as.double(NA) should be distinguished as the
> help page suggests.

And sometimes they are:

> identical(y,x)
[1] FALSE

so it is a bug.  A quicker version:

identical(NaN, NA_real_) == identical(NA_real_, NaN)

was false, fixed now, thanks for spotting it.

>
> Tested under R version 2.5.1 Patched (2007-08-19 r42638) on Linux (CPU Xeon).
>
> Petr Savicky.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Wed Aug 29 20:56:27 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 29 Aug 2007 11:56:27 -0700
Subject: [Rd] R CMD check: Error in function (env) : could not find
	function "finalize"
In-Reply-To: <m2lkbv0wvp.fsf@ziti.fhcrc.org>
References: <59d7961d0708281324q11f966d2y724c0bdb0a98e036@mail.gmail.com>
	<m2lkbv0wvp.fsf@ziti.fhcrc.org>
Message-ID: <59d7961d0708291156tb7cdd20mc919f72325d3cc4d@mail.gmail.com>

Hi, thanks Seth and others (I've got some offline replies); all
feedback has been useful indeed.

The short story is that as the author of R.oo I am actually the bad
guy here (but not for long since I'm soon committing a fix for R.oo).

REPRODUCIBLE EXAMPLE #1:
% R --vanilla
> library(R.oo)
R.oo v1.2.8 (2006-06-09) successfully loaded. See ?R.oo for help.
> detach("package:R.oo")
> gc()
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
Error in function (env)  : could not find function "finalize"
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 142543  3.9     350000  9.4   350000  9.4
Vcells  82660  0.7     786432  6.0   478255  3.7

REPRODUCIBLE EXAMPLE #2:
Here is another example without R.oo illustrating what is going on.
% R --vanilla
> e <- new.env()
> e$foo <- "foo"
> e$foo <- 1
> e <- new.env()
> e$foo <- 1
> reg.finalizer(e, function(env) { print(ls.str(envir=env)) })
> detach("package:utils")
> rm(e)
> gc()
Error in print(ls.str(envir = env)) : could not find function "ls.str"
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 158213  4.3     350000  9.4   350000  9.4
Vcells  86800  0.7     786432  6.0   478255  3.7


WHY ONLY WHEN RUNNING R CMD CHECK?
So, the problem I had was with 'affxparser' examples failing in R CMD
check, but not when I tested them manually.  Same thing was happening
with the 'pcaMethods' package.  The common denominator was that both
'affxparser' and 'pcaMethods' had R.oo dependent package in
DESCRIPTION/Suggests; 'affxparser' used Suggests: R.utils (which
depends on R.oo), and 'pcaMethods' used Suggests: aroma.light (which
in turn *suggests* R.utils).  To the best of my understanding, when R
CMD check runs examples, it will load *all* suggested packages, and
when done, detach them.  When the garbage collector later runs and
cleans out objects, the generic function finalize() in R.oo called by
the registered finalize hook is not around anymore.  FYI, if you move
the R.oo-dependent package from Suggests: to Depends:, there is no
longer a problem because then the package is never detached.  It all
makes sense.


CONCLUSION:
When registering finalizers for object using reg.finalizer() there is
always the risk of the finalizer code to be broken because a dependent
package has been detached.


SOLUTION:
At least make the finalizer hook function robust against these things.
 For instance, check if required packages are loaded etc, or just add
a tryCatch() statement.  However, since finalizers are typically used
to deallocate resources, much more effort has to be taken to make sure
that is still work, which is not easy.  For instance, one could make
sure to require() the necessary packages in the finalizer, but that
has side effects and it is not necessarily sufficient, e.g. you might
only load a generic function, but the method for a specific subclass
might be in a package out of your control.  Same problem goes with
explicit namespace calls to generic functions, e.g. R.oo::finalize().
If you have more clever suggestions, please let me know.


SOME MORE DETAILS ON R.OO:
This is what R.oo looks like now:

Object <- function (core = NA) {
  this <- core
  attr(this, ".env") <- new.env()
  class(this) <- "Object"
  attr(this, "...instanciationTime") <- Sys.time()
  reg.finalizer(attr(this, ".env"), function(env) finalize(this))
  this
}

finalize.Object <- function(this, ...) {}

finalize <- function(...) UseMethod("finalize")

As you see, when detaching R.oo, finalize() is no longer around.

Lesson learned!

Cheers

Henrik

On 8/28/07, Seth Falcon <sfalcon at fhcrc.org> wrote:
> Hi Henrik,
>
> "Henrik Bengtsson" <hb at stat.berkeley.edu> writes:
>
> > Hi,
> >
> > does someone else get this error message:
> >
> > Error in function (env)  : could not find function "finalize"?
> >
> > I get an error when running examples in R CMD check (v2.6.0; session
> > info below):
> [snip]
> > The error occurs in R CMD check but also when start a fresh R session
> > and run, in this case, affxparser.Rcheck/affxparser-Ex.R.  It always
> > occur on the same line.
>
> So does options(error=recover) help in determining where the error is
> coming from?
>
> If you can narrow it down, gctorture may help or running the examples
> under valgrind.
>
> + seth
>
> --
> Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
> BioC: http://bioconductor.org/
> Blog: http://userprimary.net/user/
>


From milbo at sonic.net  Wed Aug 29 22:18:39 2007
From: milbo at sonic.net (Stephen Milborrow)
Date: Wed, 29 Aug 2007 13:18:39 -0700
Subject: [Rd] Modifying R_CheckStack for a speed increase
Message-ID: <000f01c7ea79$d55b95c0$6401a8c0@DDV3JY61>

Greetings R developers,

R will run a little faster when executing "pure R" code if the function
R_CheckStack() is modified.

With the modification, the following code for example runs 15% faster
(compared to a virgin R-2.5.1 on my Windows XP machine):

      N = 1e7
      foo <- function(x)
      {
           for (i in 1:N)
                x <- x + 1
          x
      }
      foo(0)

The crux of the modification is to change the following line in 
R_CheckStack()

      if(R_CStackLimit != -1 && usage > 0.95 * R_CStackLimit) {...

to

      if(usage > R_CStackLen) { ...

Details and modified sources can be found at
ftp://ftp.sonic.net/pub/users/milbo.

Regards,
Stephen

http://milbo.users.sonic.net


From byron.ellis at gmail.com  Wed Aug 29 22:58:35 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Wed, 29 Aug 2007 13:58:35 -0700
Subject: [Rd] Modifying R_CheckStack for a speed increase
In-Reply-To: <000f01c7ea79$d55b95c0$6401a8c0@DDV3JY61>
References: <000f01c7ea79$d55b95c0$6401a8c0@DDV3JY61>
Message-ID: <7098abec0708291358h7819feb2gda534291ff7d098d@mail.gmail.com>

Alternatively, if you actually wanted to keep the 0.95 you could use

usage > R_CStackLimit - (R_CStackLimit >> 4)

and probably get close enough to 0.95 as it makes no difference or go
with 5 and get something more like 97%. At any rate, you'd avoid
floating point.

On 8/29/07, Stephen Milborrow <milbo at sonic.net> wrote:
> Greetings R developers,
>
> R will run a little faster when executing "pure R" code if the function
> R_CheckStack() is modified.
>
> With the modification, the following code for example runs 15% faster
> (compared to a virgin R-2.5.1 on my Windows XP machine):
>
>       N = 1e7
>       foo <- function(x)
>       {
>            for (i in 1:N)
>                 x <- x + 1
>           x
>       }
>       foo(0)
>
> The crux of the modification is to change the following line in
> R_CheckStack()
>
>       if(R_CStackLimit != -1 && usage > 0.95 * R_CStackLimit) {...
>
> to
>
>       if(usage > R_CStackLen) { ...
>
> Details and modified sources can be found at
> ftp://ftp.sonic.net/pub/users/milbo.
>
> Regards,
> Stephen
>
> http://milbo.users.sonic.net
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From ripley at stats.ox.ac.uk  Wed Aug 29 23:33:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Aug 2007 22:33:54 +0100 (BST)
Subject: [Rd] R CMD check: Error in function (env) : could not find
 function "finalize"
In-Reply-To: <59d7961d0708291156tb7cdd20mc919f72325d3cc4d@mail.gmail.com>
References: <59d7961d0708281324q11f966d2y724c0bdb0a98e036@mail.gmail.com>
	<m2lkbv0wvp.fsf@ziti.fhcrc.org>
	<59d7961d0708291156tb7cdd20mc919f72325d3cc4d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0708292200380.13321@gannet.stats.ox.ac.uk>

> To the best of my understanding, when R
> CMD check runs examples, it will load *all* suggested packages, and
> when done, detach them.  When the garbage collector later runs and

Not so.  R CMD check just runs the examples in a normal session after 
loading the package being tested.  Examples may themselves attach/load 
suggested packages (and if they are suggested it is likely that either 
examples or vignettes will do so).  After each group of examples 
(\examples from a single help file) any packages which have been attached 
in the course of that group are detached.

Looking at pcaMethods, function robustSvd require()s aroma.light, so this 
will happen in example(robustSvd).

I think a package that sets finalizers probably ought to ensure that they 
are run in its .Last.lib or similar hook.  There is no guarantee that they 
will be detached in a particular order, though.  (R CMD check does detach 
them in an ordering determined from the search path, but users may do 
something different.)  If namespaces are involved, similar considerations 
apply to unloading namespaces (although there are some guarantees on order 
since you cannot unload a namespace which is imported from).  Beyond that, 
you may be able to ensure by setting the environment for the 
finalizer function that what it needs will still be present at 
finalization.


On Wed, 29 Aug 2007, Henrik Bengtsson wrote:

> Hi, thanks Seth and others (I've got some offline replies); all
> feedback has been useful indeed.
>
> The short story is that as the author of R.oo I am actually the bad
> guy here (but not for long since I'm soon committing a fix for R.oo).
>
> REPRODUCIBLE EXAMPLE #1:
> % R --vanilla
>> library(R.oo)
> R.oo v1.2.8 (2006-06-09) successfully loaded. See ?R.oo for help.
>> detach("package:R.oo")
>> gc()
> Error in function (env)  : could not find function "finalize"
> Error in function (env)  : could not find function "finalize"
> Error in function (env)  : could not find function "finalize"
> Error in function (env)  : could not find function "finalize"
> Error in function (env)  : could not find function "finalize"
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 142543  3.9     350000  9.4   350000  9.4
> Vcells  82660  0.7     786432  6.0   478255  3.7
>
> REPRODUCIBLE EXAMPLE #2:
> Here is another example without R.oo illustrating what is going on.
> % R --vanilla
>> e <- new.env()
>> e$foo <- "foo"
>> e$foo <- 1
>> e <- new.env()
>> e$foo <- 1
>> reg.finalizer(e, function(env) { print(ls.str(envir=env)) })
>> detach("package:utils")
>> rm(e)
>> gc()
> Error in print(ls.str(envir = env)) : could not find function "ls.str"
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 158213  4.3     350000  9.4   350000  9.4
> Vcells  86800  0.7     786432  6.0   478255  3.7
>
>
> WHY ONLY WHEN RUNNING R CMD CHECK?
> So, the problem I had was with 'affxparser' examples failing in R CMD
> check, but not when I tested them manually.  Same thing was happening
> with the 'pcaMethods' package.  The common denominator was that both
> 'affxparser' and 'pcaMethods' had R.oo dependent package in
> DESCRIPTION/Suggests; 'affxparser' used Suggests: R.utils (which
> depends on R.oo), and 'pcaMethods' used Suggests: aroma.light (which
> in turn *suggests* R.utils).  To the best of my understanding, when R
> CMD check runs examples, it will load *all* suggested packages, and
> when done, detach them.  When the garbage collector later runs and
> cleans out objects, the generic function finalize() in R.oo called by
> the registered finalize hook is not around anymore.  FYI, if you move
> the R.oo-dependent package from Suggests: to Depends:, there is no
> longer a problem because then the package is never detached.  It all
> makes sense.
>
>
> CONCLUSION:
> When registering finalizers for object using reg.finalizer() there is
> always the risk of the finalizer code to be broken because a dependent
> package has been detached.
>
>
> SOLUTION:
> At least make the finalizer hook function robust against these things.
> For instance, check if required packages are loaded etc, or just add
> a tryCatch() statement.  However, since finalizers are typically used
> to deallocate resources, much more effort has to be taken to make sure
> that is still work, which is not easy.  For instance, one could make
> sure to require() the necessary packages in the finalizer, but that
> has side effects and it is not necessarily sufficient, e.g. you might
> only load a generic function, but the method for a specific subclass
> might be in a package out of your control.  Same problem goes with
> explicit namespace calls to generic functions, e.g. R.oo::finalize().
> If you have more clever suggestions, please let me know.
>
>
> SOME MORE DETAILS ON R.OO:
> This is what R.oo looks like now:
>
> Object <- function (core = NA) {
>  this <- core
>  attr(this, ".env") <- new.env()
>  class(this) <- "Object"
>  attr(this, "...instanciationTime") <- Sys.time()
>  reg.finalizer(attr(this, ".env"), function(env) finalize(this))
>  this
> }
>
> finalize.Object <- function(this, ...) {}
>
> finalize <- function(...) UseMethod("finalize")
>
> As you see, when detaching R.oo, finalize() is no longer around.
>
> Lesson learned!
>
> Cheers
>
> Henrik
>
> On 8/28/07, Seth Falcon <sfalcon at fhcrc.org> wrote:
>> Hi Henrik,
>>
>> "Henrik Bengtsson" <hb at stat.berkeley.edu> writes:
>>
>>> Hi,
>>>
>>> does someone else get this error message:
>>>
>>> Error in function (env)  : could not find function "finalize"?
>>>
>>> I get an error when running examples in R CMD check (v2.6.0; session
>>> info below):
>> [snip]
>>> The error occurs in R CMD check but also when start a fresh R session
>>> and run, in this case, affxparser.Rcheck/affxparser-Ex.R.  It always
>>> occur on the same line.
>>
>> So does options(error=recover) help in determining where the error is
>> coming from?
>>
>> If you can narrow it down, gctorture may help or running the examples
>> under valgrind.
>>
>> + seth
>>
>> --
>> Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
>> BioC: http://bioconductor.org/
>> Blog: http://userprimary.net/user/
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Thu Aug 30 00:11:17 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 29 Aug 2007 15:11:17 -0700
Subject: [Rd] R CMD check recursive copy of tests/
Message-ID: <59d7961d0708291511r36a130d9vdd5c1f32b277e670@mail.gmail.com>

>From NEWS of R v2.6.0 devel:

 o	R CMD check now does a recursive copy on the 'tests' directory.

However, R CMD check does not run *.R scripts in such subdirectories
(as I thought/hoped for), only those directly under tests/, This may
or may not be intentional.  If true, maybe the above should be
clarified as:

 o	R CMD check now does a recursive copy on the 'tests' directory for
the purpose of provided data files for input.  Test scripts still has
to be directly under tests/ to be run.

Just a comment

Henrik


From maechler at stat.math.ethz.ch  Thu Aug 30 12:04:40 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 Aug 2007 12:04:40 +0200
Subject: [Rd] R CMD check recursive copy of tests/
In-Reply-To: <59d7961d0708291511r36a130d9vdd5c1f32b277e670@mail.gmail.com>
References: <59d7961d0708291511r36a130d9vdd5c1f32b277e670@mail.gmail.com>
Message-ID: <200708301004.l7UA4eHv016956@lynne.ethz.ch>

>>>>> "HenrikB" == Henrik Bengtsson <hb at stat.berkeley.edu>
>>>>>     on Wed, 29 Aug 2007 15:11:17 -0700 writes:

    >> From NEWS of R v2.6.0 devel:
    HenrikB>  o R CMD check now does a recursive copy on the
    HenrikB> 'tests' directory.

    HenrikB> However, R CMD check does not run *.R scripts in
    HenrikB> such subdirectories (as I thought/hoped for), 

 a pretty bold hope ;-)

    HenrikB> only those directly under tests/, This may or may not be
    HenrikB> intentional.  

intentional I'd say: I did not implement it, but it seems much
more logical to keep the previous rule: All *.R files in
./tests/ are run <period>
Subdirectories can be useful for organization, notably storing
test data.  I don't think it's a good idea to use so very many test files
that you need subdirectories, unless maybe you are thinking
about unit tests; and then, see below.


    HenrikB> If true, maybe the above should be clarified as:

    HenrikB>  o R CMD check now does a recursive copy on the
    HenrikB> 'tests' directory for the purpose of provided data
    HenrikB> files for input.  Test scripts still has to be
    HenrikB> directly under tests/ to be run.

    HenrikB> Just a comment

Thanks for the comment.

Many other people have complained that 'NEWS' is too verbose
already, and hence too much to be read by an average useR, even programmeR.
The point about 'NEWS' is to mention things that are *changed*.
Now since the behavior did *not* change, we definitely should
not make NEWS longer just to say that.

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
 
A note about ./tests/ , directories, etc :

At the useR!2007 meeting three weeks ago, there was an
interesting discussion --- I think after the "Regulated
Environments / R Certification" session {{and those interested
there should look at http://www.r-project.org/certification.html}} ---
on the broader topic of 'R validation' and testing etc,
where one of my short contributions was to acknowledge that
"yes, it would be great if people wrote much more
 regression/unit test code, and I would welcome if these were
 collected, and put into daily testing state etc etc"

*Contrary* to the <pkg>/tests/  concept,
one thing I think we (R developers at large) should consider and
often favor, is the idea that you want to run the tests also at
run time and not just install time
{{and part of that is also desirable for "base R"}}

About a week agao, I have re-organized the
RUnit-based unit regression tests for two Rmetrics R packages to
achieve the following goals :

1) tests should be auto-run via 'R CMD check <pkg>'
2) tests should be easily re-runnable by a user who only
   got the *binary* package {e.g. a typical Windows user}
3) tests should also be easily runnable by the package developer 
   without need to run the full R CMD check.

where "1)" and "2)" where really primary goals.

I've basically started from what is written (I think mainly by
Tony Plate and Gregor Gorjanc) in the R Wiki section
   http://wiki.r-project.org/rwiki/doku.php?id=developers:runit
and Gregor Gojanc's example in CRAN package  'gdata'

but then really also found I needed to change things a bit to
make '2)' more convenient.

The basic idea is:

 ./tests/doRunit.R   is a setup file  {which will not be installed}

 ./inst/unitTests/   contains all the meat {and *is* installed}
with
 ./inst/unitTests/runTests.R   calls all the other unit tests
 ./inst/unitTests/runit*.R  

where the idea is the user of the *installed* package
can easily run the tests again,
hereby **validating** her installation of the package:

E.g., for the not-yet released version of fCalendar,

> source(system.file("unitTests/runTests.R", package = "fCalendar"))

 RUnit 0.4.17 loaded.
Now have RUnit Test Suite 'testSuite' for package 'fCalendar' :

......

Consider doing
	  tests <- runTestSuite(testSuite)

and later
	  printTextProtocol(tests)

-- -- -- -- --

The development version is available via subversion (svn) or also simple
web tools from  https://svn.r-project.org/Rmetrics/trunk/fCalendar/

Martin Maechler, ETH Zurich


From osklyar at ebi.ac.uk  Thu Aug 30 13:10:36 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 30 Aug 2007 12:10:36 +0100
Subject: [Rd] suggesting \alias* for Rd files (in particular for S4
	method	documentation)
Message-ID: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk>

Hi,

I do not know if everybody finds index pages of the html-formatted R
help useful, but I know I am at least not the only one who uses them
extensively to get the overview of functions and methods in a package
(even for my own package). Problems arise, however, if a lot of S4
methods need to be documented blowing out the index with (generally
irrelevant) entries like:

write.image,Image,missing-method
write.image,Image,character-method

instead of a simple "write.image". I also do not believe anyone really
does something like "help(write.image,Image,missing-method)" on the
command line, thus these structures are more for internal linking than
for users.

Therefore, I would suggest to introduce a modification of the \alias
keyword, that would do all the same as the standard \alias keyword, yet
it would *hide* that particular entry from the index. Reasonable
construction could be something like \alias*{} yielding

\alias{write.image}
\alias*{write.image,Image,missing-method}
\alias*{write.image,Image,character-method}

Alternatively:

\alias{write.image}
\alias[hide]{write.image,Image,missing-method}
\alias[hide]{write.image,Image,character-method}

Any comments?

For me, the current way around is to avoid usage sections with \S4method
all together, substituting them with pairs of

\section{Usage}{\preformatted{
}}
\section{Arguments}{
}

and putting all aliases marked above with * into internals, which is
definitely not the best way of going around documentation and
code/documentation mismatches.

Best regards,
Oleg

-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466


From mtmorgan at fhcrc.org  Thu Aug 30 14:54:16 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 30 Aug 2007 05:54:16 -0700
Subject: [Rd] suggesting \alias* for Rd files (in particular for S4
 method	documentation)
In-Reply-To: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk> (Oleg
	Sklyar's message of "Thu, 30 Aug 2007 12:10:36 +0100")
References: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk>
Message-ID: <6phwsvduqrr.fsf@gopher4.fhcrc.org>

Hi Oleg --

On the usefulness of write.image,Image,character-method, in the end I
really want documentation on specific methods. Maybe the issue is one
of presentation?

write.image
    Image,character-method
    Image,missing-method

or, in a little more dynamic world, a '+' in front of write.image to
expand the methods list.

alias* is a little strange, because it implies you're writing
documentation, but then hiding easy access to it! This is not a strong
argument against introducing alias*, since no one is forced to use it.

It also suggests that your documentation is organized by generic,
which might also be a bit unusual -- I typically have an object (e.g.,
an Image) and wonder what can be done to it (e.g., write it to
disk). This suggests associating method documentation with object
documentation. Multiple dispatch might sometimes make this difficult
(though rarely in practice?). Separately documenting the generic is
also important.

Martin

Oleg Sklyar <osklyar at ebi.ac.uk> writes:

> Hi,
>
> I do not know if everybody finds index pages of the html-formatted R
> help useful, but I know I am at least not the only one who uses them
> extensively to get the overview of functions and methods in a package
> (even for my own package). Problems arise, however, if a lot of S4
> methods need to be documented blowing out the index with (generally
> irrelevant) entries like:
>
> write.image,Image,missing-method
> write.image,Image,character-method
>
> instead of a simple "write.image". I also do not believe anyone really
> does something like "help(write.image,Image,missing-method)" on the
> command line, thus these structures are more for internal linking than
> for users.
>
> Therefore, I would suggest to introduce a modification of the \alias
> keyword, that would do all the same as the standard \alias keyword, yet
> it would *hide* that particular entry from the index. Reasonable
> construction could be something like \alias*{} yielding
>
> \alias{write.image}
> \alias*{write.image,Image,missing-method}
> \alias*{write.image,Image,character-method}
>
> Alternatively:
>
> \alias{write.image}
> \alias[hide]{write.image,Image,missing-method}
> \alias[hide]{write.image,Image,character-method}
>
> Any comments?
>
> For me, the current way around is to avoid usage sections with \S4method
> all together, substituting them with pairs of
>
> \section{Usage}{\preformatted{
> }}
> \section{Arguments}{
> }
>
> and putting all aliases marked above with * into internals, which is
> definitely not the best way of going around documentation and
> code/documentation mismatches.
>
> Best regards,
> Oleg
>
> -- 
> Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From jmacdon at med.umich.edu  Thu Aug 30 16:06:35 2007
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Thu, 30 Aug 2007 10:06:35 -0400
Subject: [Rd] suggesting \alias* for Rd files (in particular for S4
 method documentation)
In-Reply-To: <6phwsvduqrr.fsf@gopher4.fhcrc.org>
References: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk>
	<6phwsvduqrr.fsf@gopher4.fhcrc.org>
Message-ID: <46D6CEEB.6040702@med.umich.edu>

I think Oleg makes a good point here, and I don't see how his suggestion 
would hide any documentation.

As an example, start R and then open the HTML help page, and go to the 
Category package. If you click on any one of

annotation,GOHyperGParams-method
categoryName,GOHyperGParams-method
conditional,GOHyperGParams-method
conditional<-,GOHyperGParams-method
GOHyperGParams-class
ontology,GOHyperGParams-method
ontology<-,GOHyperGParams-method
show,GOHyperGParams-method

You will be sent to the same help page, which contains the documentation 
for all those specific methods. The question here is do we really this 
many-to-one relationship in the HTML pages?

In general (Oleg notwithstanding), I think the HTML pages are used 
primarily by new users to R, and having such an overload on the index 
page for this package is IMO a disservice to these people. Having just 
one link, GOHyperGParams-class, or possibly an additional 
GOHyperGParams-methods would be much cleaner.

There already exists a mechanism for keeping internal methods from 
showing up in the HTML indices: adding \keyword{internal} to the end of 
the .Rd file. However, this hides all the \alias{} (and \name{}) 
entries, so won't do what Oleg wants unless you have two separate .Rd 
files, one containing the \alias{} names you want to show, and the other 
with the 'internal' keyword.

Best,

Jim



Martin Morgan wrote:
> Hi Oleg --
> 
> On the usefulness of write.image,Image,character-method, in the end I
> really want documentation on specific methods. Maybe the issue is one
> of presentation?
> 
> write.image
>     Image,character-method
>     Image,missing-method
> 
> or, in a little more dynamic world, a '+' in front of write.image to
> expand the methods list.
> 
> alias* is a little strange, because it implies you're writing
> documentation, but then hiding easy access to it! This is not a strong
> argument against introducing alias*, since no one is forced to use it.
> 
> It also suggests that your documentation is organized by generic,
> which might also be a bit unusual -- I typically have an object (e.g.,
> an Image) and wonder what can be done to it (e.g., write it to
> disk). This suggests associating method documentation with object
> documentation. Multiple dispatch might sometimes make this difficult
> (though rarely in practice?). Separately documenting the generic is
> also important.
> 
> Martin
> 
> Oleg Sklyar <osklyar at ebi.ac.uk> writes:
> 
>> Hi,
>>
>> I do not know if everybody finds index pages of the html-formatted R
>> help useful, but I know I am at least not the only one who uses them
>> extensively to get the overview of functions and methods in a package
>> (even for my own package). Problems arise, however, if a lot of S4
>> methods need to be documented blowing out the index with (generally
>> irrelevant) entries like:
>>
>> write.image,Image,missing-method
>> write.image,Image,character-method
>>
>> instead of a simple "write.image". I also do not believe anyone really
>> does something like "help(write.image,Image,missing-method)" on the
>> command line, thus these structures are more for internal linking than
>> for users.
>>
>> Therefore, I would suggest to introduce a modification of the \alias
>> keyword, that would do all the same as the standard \alias keyword, yet
>> it would *hide* that particular entry from the index. Reasonable
>> construction could be something like \alias*{} yielding
>>
>> \alias{write.image}
>> \alias*{write.image,Image,missing-method}
>> \alias*{write.image,Image,character-method}
>>
>> Alternatively:
>>
>> \alias{write.image}
>> \alias[hide]{write.image,Image,missing-method}
>> \alias[hide]{write.image,Image,character-method}
>>
>> Any comments?
>>
>> For me, the current way around is to avoid usage sections with \S4method
>> all together, substituting them with pairs of
>>
>> \section{Usage}{\preformatted{
>> }}
>> \section{Arguments}{
>> }
>>
>> and putting all aliases marked above with * into internals, which is
>> definitely not the best way of going around documentation and
>> code/documentation mismatches.
>>
>> Best regards,
>> Oleg
>>
>> -- 
>> Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


From hb at stat.berkeley.edu  Thu Aug 30 16:31:02 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 30 Aug 2007 07:31:02 -0700
Subject: [Rd] R CMD check recursive copy of tests/
In-Reply-To: <200708301004.l7UA4eHv016956@lynne.ethz.ch>
References: <59d7961d0708291511r36a130d9vdd5c1f32b277e670@mail.gmail.com>
	<200708301004.l7UA4eHv016956@lynne.ethz.ch>
Message-ID: <59d7961d0708300731x15a363b3w34db4fb4d3ac0310@mail.gmail.com>

Hi.

On 8/30/07, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >>>>> "HenrikB" == Henrik Bengtsson <hb at stat.berkeley.edu>
> >>>>>     on Wed, 29 Aug 2007 15:11:17 -0700 writes:
>
>     >> From NEWS of R v2.6.0 devel:
>     HenrikB>  o R CMD check now does a recursive copy on the
>     HenrikB> 'tests' directory.
>
>     HenrikB> However, R CMD check does not run *.R scripts in
>     HenrikB> such subdirectories (as I thought/hoped for),
>
>  a pretty bold hope ;-)
>
>     HenrikB> only those directly under tests/, This may or may not be
>     HenrikB> intentional.
>
> intentional I'd say: I did not implement it, but it seems much
> more logical to keep the previous rule: All *.R files in
> ./tests/ are run <period>
> Subdirectories can be useful for organization, notably storing
> test data.  I don't think it's a good idea to use so very many test files
> that you need subdirectories, unless maybe you are thinking
> about unit tests; and then, see below.

Examples of subdirectories (some overlapping) are:

units/ - tests of minimal code modules
integration/ - tests of integrating the above units
system/ - "real-world" scenarios/use cases

requirements/ - every requirement should have at least on test.
bugs/ - every bug fix should come with a new test.
regression/ - every update should have a regression test to validate
backward compatibility etc.

robustness/ - Testing the robustness of estimators against outliers as
well as extreme parameter settings.
validation/ - validation of numeric results compared with alternative
implementations or summaries.

benchmarking/ - actually more measuring time, but can involve
validation that a method is faster than an alternative.
crossplatform/ - validate correctness across platforms.
torture/ - pushing the limits.


>
>
>     HenrikB> If true, maybe the above should be clarified as:
>
>     HenrikB>  o R CMD check now does a recursive copy on the
>     HenrikB> 'tests' directory for the purpose of provided data
>     HenrikB> files for input.  Test scripts still has to be
>     HenrikB> directly under tests/ to be run.
>
>     HenrikB> Just a comment
>
> Thanks for the comment.
>
> Many other people have complained that 'NEWS' is too verbose
> already, and hence too much to be read by an average useR, even programmeR.
> The point about 'NEWS' is to mention things that are *changed*.
> Now since the behavior did *not* change, we definitely should
> not make NEWS longer just to say that.
>
>  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
>
> A note about ./tests/ , directories, etc :
>
> At the useR!2007 meeting three weeks ago, there was an
> interesting discussion --- I think after the "Regulated
> Environments / R Certification" session {{and those interested
> there should look at http://www.r-project.org/certification.html}} ---

I ran in to that last week; I think that is a great and important
initiative.  Now I hear that people use R for development and then
reimplement in SAS to please FDA.

> on the broader topic of 'R validation' and testing etc,
> where one of my short contributions was to acknowledge that
> "yes, it would be great if people wrote much more
>  regression/unit test code, and I would welcome if these were
>  collected, and put into daily testing state etc etc"
>
> *Contrary* to the <pkg>/tests/  concept,
> one thing I think we (R developers at large) should consider and
> often favor, is the idea that you want to run the tests also at
> run time and not just install time
> {{and part of that is also desirable for "base R"}}
>
> About a week agao, I have re-organized the
> RUnit-based unit regression tests for two Rmetrics R packages to
> achieve the following goals :
>
> 1) tests should be auto-run via 'R CMD check <pkg>'
> 2) tests should be easily re-runnable by a user who only
>    got the *binary* package {e.g. a typical Windows user}
> 3) tests should also be easily runnable by the package developer
>    without need to run the full R CMD check.
>
> where "1)" and "2)" where really primary goals.
>
> I've basically started from what is written (I think mainly by
> Tony Plate and Gregor Gorjanc) in the R Wiki section
>    http://wiki.r-project.org/rwiki/doku.php?id=developers:runit
> and Gregor Gojanc's example in CRAN package  'gdata'
>
> but then really also found I needed to change things a bit to
> make '2)' more convenient.
>
> The basic idea is:
>
>  ./tests/doRunit.R   is a setup file  {which will not be installed}
>
>  ./inst/unitTests/   contains all the meat {and *is* installed}
> with
>  ./inst/unitTests/runTests.R   calls all the other unit tests
>  ./inst/unitTests/runit*.R
>
> where the idea is the user of the *installed* package
> can easily run the tests again,
> hereby **validating** her installation of the package:
>
> E.g., for the not-yet released version of fCalendar,
>
> > source(system.file("unitTests/runTests.R", package = "fCalendar"))
>
>  RUnit 0.4.17 loaded.
> Now have RUnit Test Suite 'testSuite' for package 'fCalendar' :
>
> ......
>
> Consider doing
>           tests <- runTestSuite(testSuite)
>
> and later
>           printTextProtocol(tests)

I think these are all great ideas/suggests/implementation.  As
important as design and implementation, testing (and bug reporting)
deserves a higher status.

It often the case that it is not feasible to have all tests ran by R
CMD check.  For instance, I have system tests that take literally
hours or even days to run.  I also know that because of their
integrated build/check system, Bioconductor have a rule of thumb that
it shouldn't take more than 5 minutes for R CMD check to finish
[http://wiki.fhcrc.org/bioc/Package_Guidelines#time-requirements].
Then having test cases installed allows you to still include such
tests and run them at other times (run time).

I would like to add that it can also be useful to have the option tp
ask an end-user that reports bugs/problems to run some standard tests
(that might not have been ran by R CMD check).

Cheers

Henrik

>
> -- -- -- -- --
>
> The development version is available via subversion (svn) or also simple
> web tools from  https://svn.r-project.org/Rmetrics/trunk/fCalendar/
>
> Martin Maechler, ETH Zurich
>


From osklyar at ebi.ac.uk  Thu Aug 30 16:34:16 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 30 Aug 2007 15:34:16 +0100
Subject: [Rd] suggesting \alias* for Rd files (in particular for
	S4	method documentation)
In-Reply-To: <46D6CEEB.6040702@med.umich.edu>
References: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk>
	<6phwsvduqrr.fsf@gopher4.fhcrc.org>  <46D6CEEB.6040702@med.umich.edu>
Message-ID: <1188484456.6071.116.camel@maitai.windows.ebi.ac.uk>

Maybe I need to add a comment.

The idea is not to avoid providing documentation for specific methods,
rather to be able to selectively hide things in the index keeping the
index sane. On the developer discretion, as generally I think the
developer should decide what the user can see and how.

It would still bring up the help page on typing the help command e.g.
help(write.image,Image,missing-method) and it would still allow the
corresponding referencing. Moreover it would allow to specifically show
those method definitions, which *are* important rather than all that
exist.

There are not so many cases where the generic is often reused with
different classes across different packages and in those cases it is
truly reasonable to have a comprehensive help listing the signatures in
the index as well. But take the above "write.image" -- I doubt there is
another implementation of this generic anywhere in the R world and my
current documentation would have *one* page for all -- the generic and
all the methods, so why to have 3 visible links in the index that do not
really give more information than the page itself (where all use cases
are listed).

I however agree that the indented structure as Martin suggested would be
a big step forward already.

James: moving things to internals does not work as if you provide
\S4method clause you *must* provide a corresponding alias, otherwise you
get a check warning and for example on Bioconductor you will have
problems with BioC maintainers, and it is good so ;-)

Best,
Oleg

On Thu, 2007-08-30 at 10:06 -0400, James W. MacDonald wrote:
> I think Oleg makes a good point here, and I don't see how his suggestion 
> would hide any documentation.
> 
> As an example, start R and then open the HTML help page, and go to the 
> Category package. If you click on any one of
> 
> annotation,GOHyperGParams-method
> categoryName,GOHyperGParams-method
> conditional,GOHyperGParams-method
> conditional<-,GOHyperGParams-method
> GOHyperGParams-class
> ontology,GOHyperGParams-method
> ontology<-,GOHyperGParams-method
> show,GOHyperGParams-method
> 
> You will be sent to the same help page, which contains the documentation 
> for all those specific methods. The question here is do we really this 
> many-to-one relationship in the HTML pages?
> 
> In general (Oleg notwithstanding), I think the HTML pages are used 
> primarily by new users to R, and having such an overload on the index 
> page for this package is IMO a disservice to these people. Having just 
> one link, GOHyperGParams-class, or possibly an additional 
> GOHyperGParams-methods would be much cleaner.
> 
> There already exists a mechanism for keeping internal methods from 
> showing up in the HTML indices: adding \keyword{internal} to the end of 
> the .Rd file. However, this hides all the \alias{} (and \name{}) 
> entries, so won't do what Oleg wants unless you have two separate .Rd 
> files, one containing the \alias{} names you want to show, and the other 
> with the 'internal' keyword.
> 
> Best,
> 
> Jim
> 
> 
> 
> Martin Morgan wrote:
> > Hi Oleg --
> > 
> > On the usefulness of write.image,Image,character-method, in the end I
> > really want documentation on specific methods. Maybe the issue is one
> > of presentation?
> > 
> > write.image
> >     Image,character-method
> >     Image,missing-method
> > 
> > or, in a little more dynamic world, a '+' in front of write.image to
> > expand the methods list.
> > 
> > alias* is a little strange, because it implies you're writing
> > documentation, but then hiding easy access to it! This is not a strong
> > argument against introducing alias*, since no one is forced to use it.
> > 
> > It also suggests that your documentation is organized by generic,
> > which might also be a bit unusual -- I typically have an object (e.g.,
> > an Image) and wonder what can be done to it (e.g., write it to
> > disk). This suggests associating method documentation with object
> > documentation. Multiple dispatch might sometimes make this difficult
> > (though rarely in practice?). Separately documenting the generic is
> > also important.
> > 
> > Martin
> > 
> > Oleg Sklyar <osklyar at ebi.ac.uk> writes:
> > 
> >> Hi,
> >>
> >> I do not know if everybody finds index pages of the html-formatted R
> >> help useful, but I know I am at least not the only one who uses them
> >> extensively to get the overview of functions and methods in a package
> >> (even for my own package). Problems arise, however, if a lot of S4
> >> methods need to be documented blowing out the index with (generally
> >> irrelevant) entries like:
> >>
> >> write.image,Image,missing-method
> >> write.image,Image,character-method
> >>
> >> instead of a simple "write.image". I also do not believe anyone really
> >> does something like "help(write.image,Image,missing-method)" on the
> >> command line, thus these structures are more for internal linking than
> >> for users.
> >>
> >> Therefore, I would suggest to introduce a modification of the \alias
> >> keyword, that would do all the same as the standard \alias keyword, yet
> >> it would *hide* that particular entry from the index. Reasonable
> >> construction could be something like \alias*{} yielding
> >>
> >> \alias{write.image}
> >> \alias*{write.image,Image,missing-method}
> >> \alias*{write.image,Image,character-method}
> >>
> >> Alternatively:
> >>
> >> \alias{write.image}
> >> \alias[hide]{write.image,Image,missing-method}
> >> \alias[hide]{write.image,Image,character-method}
> >>
> >> Any comments?
> >>
> >> For me, the current way around is to avoid usage sections with \S4method
> >> all together, substituting them with pairs of
> >>
> >> \section{Usage}{\preformatted{
> >> }}
> >> \section{Arguments}{
> >> }
> >>
> >> and putting all aliases marked above with * into internals, which is
> >> definitely not the best way of going around documentation and
> >> code/documentation mismatches.
> >>
> >> Best regards,
> >> Oleg
> >>
> >> -- 
> >> Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466


From hb at stat.berkeley.edu  Thu Aug 30 16:47:19 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 30 Aug 2007 07:47:19 -0700
Subject: [Rd] suggesting \alias* for Rd files (in particular for S4
	method documentation)
In-Reply-To: <46D6CEEB.6040702@med.umich.edu>
References: <1188472236.6071.92.camel@maitai.windows.ebi.ac.uk>
	<6phwsvduqrr.fsf@gopher4.fhcrc.org> <46D6CEEB.6040702@med.umich.edu>
Message-ID: <59d7961d0708300747m475eee17n5b688c0a1c263ff8@mail.gmail.com>

On 8/30/07, James W. MacDonald <jmacdon at med.umich.edu> wrote:
> I think Oleg makes a good point here, and I don't see how his suggestion
> would hide any documentation.
>
> As an example, start R and then open the HTML help page, and go to the
> Category package. If you click on any one of
>
> annotation,GOHyperGParams-method
> categoryName,GOHyperGParams-method
> conditional,GOHyperGParams-method
> conditional<-,GOHyperGParams-method
> GOHyperGParams-class
> ontology,GOHyperGParams-method
> ontology<-,GOHyperGParams-method
> show,GOHyperGParams-method
>
> You will be sent to the same help page, which contains the documentation
> for all those specific methods. The question here is do we really this
> many-to-one relationship in the HTML pages?
>
> In general (Oleg notwithstanding), I think the HTML pages are used
> primarily by new users to R, and having such an overload on the index
> page for this package is IMO a disservice to these people. Having just
> one link, GOHyperGParams-class, or possibly an additional
> GOHyperGParams-methods would be much cleaner.

You're approaching dangerous lands here ;)  Should methods be listed
under a class or a generic function.  Personally I think that is an
academic question, and often I do find it the former to be more
useful, because that is indeed how many packages are designed, i.e. we
do have an Image class or a GOHyperGParams with many methods coupled
to it.  In addition to "standalone" functions, there might be a few
functions with a wider purpose that operates across classes.  These
deserves there own item in the ToC/index too (I design my help index
to be a table of contents).

Some examples of help pages organized like this:

R.matlab:
http://rss.acs.unt.edu/Rdoc/library/R.matlab/html/00Index.html
R.oo:
http://rss.acs.unt.edu/Rdoc/library/R.oo/html/00Index.html

>
> There already exists a mechanism for keeping internal methods from
> showing up in the HTML indices: adding \keyword{internal} to the end of
> the .Rd file. However, this hides all the \alias{} (and \name{})
> entries, so won't do what Oleg wants unless you have two separate .Rd
> files, one containing the \alias{} names you want to show, and the other
> with the 'internal' keywor

You can get a long way cleaning up help indices using
\keyword{internal}, and I believe there are quite a few developers
that are not aware of its existence.

Cheers

Henrik

>
> Best,
>
> Jim
>
>
>
> Martin Morgan wrote:
> > Hi Oleg --
> >
> > On the usefulness of write.image,Image,character-method, in the end I
> > really want documentation on specific methods. Maybe the issue is one
> > of presentation?
> >
> > write.image
> >     Image,character-method
> >     Image,missing-method
> >
> > or, in a little more dynamic world, a '+' in front of write.image to
> > expand the methods list.
> >
> > alias* is a little strange, because it implies you're writing
> > documentation, but then hiding easy access to it! This is not a strong
> > argument against introducing alias*, since no one is forced to use it.
> >
> > It also suggests that your documentation is organized by generic,
> > which might also be a bit unusual -- I typically have an object (e.g.,
> > an Image) and wonder what can be done to it (e.g., write it to
> > disk). This suggests associating method documentation with object
> > documentation. Multiple dispatch might sometimes make this difficult
> > (though rarely in practice?). Separately documenting the generic is
> > also important.
> >
> > Martin
> >
> > Oleg Sklyar <osklyar at ebi.ac.uk> writes:
> >
> >> Hi,
> >>
> >> I do not know if everybody finds index pages of the html-formatted R
> >> help useful, but I know I am at least not the only one who uses them
> >> extensively to get the overview of functions and methods in a package
> >> (even for my own package). Problems arise, however, if a lot of S4
> >> methods need to be documented blowing out the index with (generally
> >> irrelevant) entries like:
> >>
> >> write.image,Image,missing-method
> >> write.image,Image,character-method
> >>
> >> instead of a simple "write.image". I also do not believe anyone really
> >> does something like "help(write.image,Image,missing-method)" on the
> >> command line, thus these structures are more for internal linking than
> >> for users.
> >>
> >> Therefore, I would suggest to introduce a modification of the \alias
> >> keyword, that would do all the same as the standard \alias keyword, yet
> >> it would *hide* that particular entry from the index. Reasonable
> >> construction could be something like \alias*{} yielding
> >>
> >> \alias{write.image}
> >> \alias*{write.image,Image,missing-method}
> >> \alias*{write.image,Image,character-method}
> >>
> >> Alternatively:
> >>
> >> \alias{write.image}
> >> \alias[hide]{write.image,Image,missing-method}
> >> \alias[hide]{write.image,Image,character-method}
> >>
> >> Any comments?
> >>
> >> For me, the current way around is to avoid usage sections with \S4method
> >> all together, substituting them with pairs of
> >>
> >> \section{Usage}{\preformatted{
> >> }}
> >> \section{Arguments}{
> >> }
> >>
> >> and putting all aliases marked above with * into internals, which is
> >> definitely not the best way of going around documentation and
> >> code/documentation mismatches.
> >>
> >> Best regards,
> >> Oleg
> >>
> >> --
> >> Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-464466
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> James W. MacDonald, M.S.
> Biostatistician
> Affymetrix and cDNA Microarray Core
> University of Michigan Cancer Center
> 1500 E. Medical Center Drive
> 7410 CCGC
> Ann Arbor MI 48109
> 734-647-5623
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Thu Aug 30 21:47:43 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 30 Aug 2007 21:47:43 +0200
Subject: [Rd] R 2.5.1 scheduled for October 3
Message-ID: <46D71EDF.8070605@biostat.ku.dk>

This is to announce that we plan to release R version 2.6.0 on Wednesday
October 3, 2007. The following information is mainly for developers,
package maintainers and repository maintainers.

The planned procedure is

Sep  5: "Grand Feature" Freeze  2.6.0 alpha
Sep 19: Feature Freeze          2.6.0 beta
Sep 26: Code Freeze             2.6.0 RC
Oct  3: Release                 2.6.0

GFF: No major restructuring past this point
FF:  Feature set complete, only bugfixing from now on
CF:  Only critical bugfixes and platform build issues

Maintainers of recommended packages should notice that as they become
part of the final R tarball, we expect them to follow a similar freeze
pattern (and beware of potential CRAN delays, so please do not cut it
too close to the deadlines).

Notice that the main structural discontinuities occurs at GFF:

The SVN repository is affected as follows
    The trunk version is set to "2.7.0 Under development (unstable)".
    A new branch, R-2-7-branch is created.

This also implies new version numbers for "r-devel" and
"r-release-branch", in the sense of

http://developer.r-project.org/SVNtips.html 

Also, "r-release-branch" needs to have its tag updated.

Repository maintainers may need to revise directory structures
accordingly.

"R 2.5.1 Patched" will be closed to further development at GFF (as all
the release branches, it can be reopened if the need arises, we just
don't anticipate such a need.)

The source alpha/beta/RC tarballs will be made available daily
(barring build troubles) by a cron job running at 4AM CET, and the
tarballs can be picked up at

http://cran.r-project.org/src/base-prerelease/

a little later.

The various freeze points are marked by changes to the VERSION file
this is also done automatically by a cron job which runs just after
midnight on the relevant days.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pinard at iro.umontreal.ca  Fri Aug 31 04:48:35 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Thu, 30 Aug 2007 22:48:35 -0400
Subject: [Rd] comment() and ls() / ls.str()
Message-ID: <20070831024835.GA20222@alcyon.progiciels-bpi.ca>

Hi, people.

After I revisited some older .RData files this evening, I came to 
consider that comment() might not be such a bad idea, after all! :-)

However, if I randomly visit such older files, it is unlikely that 
I remember which objects got a comment attribute and which do not.

It would be nice if ls.str() was automatically showing comments for the
objects it lists (with maybe some parameter to turn this capability 
off).  On the same vein, the more compact ls() output might use some 
device to at least inform the user that a comment is available.

I have no satisfying suggestion to offer about what would be the best 
way for ls() to yield this information.  (For example, suffixing listed 
names with an hash or asterisk would defeat functions using the produced 
list.)  Maybe someone else might have a good, clever, usable idea?

Fine enough, str() will show me the full comment.  However, users having 
to explicitly call str on all objects, or make (easy) equivalent stunts, 
is not fully in the spirit of a comment, which is to volunteer itself...

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From doc.evans at gmail.com  Fri Aug 31 16:32:06 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Fri, 31 Aug 2007 08:32:06 -0600
Subject: [Rd] Plans for multithreading?
Message-ID: <46D82666.5070506@gmail.com>

I was surprised, given the vector-ish nature of R, to see that
(according to my CPU meters) there doesn't seem to be any obvious
multithreading in R.

Are there any plans to change this?


From sfalcon at fhcrc.org  Fri Aug 31 17:02:17 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 31 Aug 2007 08:02:17 -0700
Subject: [Rd] R CMD check recursive copy of tests/
In-Reply-To: <59d7961d0708300731x15a363b3w34db4fb4d3ac0310@mail.gmail.com>
	(Henrik Bengtsson's message of "Thu\,
	30 Aug 2007 07\:31\:02 -0700")
References: <59d7961d0708291511r36a130d9vdd5c1f32b277e670@mail.gmail.com>
	<200708301004.l7UA4eHv016956@lynne.ethz.ch>
	<59d7961d0708300731x15a363b3w34db4fb4d3ac0310@mail.gmail.com>
Message-ID: <m2myw7rbly.fsf@fhcrc.org>

"Henrik Bengtsson" <hb at stat.berkeley.edu> writes:
>> intentional I'd say: I did not implement it, but it seems much
>> more logical to keep the previous rule: All *.R files in
>> ./tests/ are run <period>
>> Subdirectories can be useful for organization, notably storing
>> test data.  I don't think it's a good idea to use so very many test files
>> that you need subdirectories, unless maybe you are thinking
>> about unit tests; and then, see below.
>
> Examples of subdirectories (some overlapping) are:
>
> units/ - tests of minimal code modules
> integration/ - tests of integrating the above units
> system/ - "real-world" scenarios/use cases
>
> requirements/ - every requirement should have at least on test.
> bugs/ - every bug fix should come with a new test.
> regression/ - every update should have a regression test to validate
> backward compatibility etc.
>
> robustness/ - Testing the robustness of estimators against outliers as
> well as extreme parameter settings.
> validation/ - validation of numeric results compared with alternative
> implementations or summaries.
>
> benchmarking/ - actually more measuring time, but can involve
> validation that a method is faster than an alternative.
> crossplatform/ - validate correctness across platforms.
> torture/ - pushing the limits.

Those all seem like reasonable examples, but the fact that R CMD check
doesn't recurse really isn't a problem.  You can have a driver script
at the top-level that runs as many of the tests in subdirs as you
want.  And this is really a good thing since as you mentioned later in
your response, some tests take a long time to run and probably are
best not automatically run during R CMD check.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From ripley at stats.ox.ac.uk  Fri Aug 31 17:48:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 31 Aug 2007 16:48:39 +0100 (BST)
Subject: [Rd] Plans for multithreading?
In-Reply-To: <46D82666.5070506@gmail.com>
References: <46D82666.5070506@gmail.com>
Message-ID: <Pine.LNX.4.64.0708311555200.5182@gannet.stats.ox.ac.uk>

On Fri, 31 Aug 2007, D. R. Evans wrote:

> I was surprised, given the vector-ish nature of R, to see that
> (according to my CPU meters) there doesn't seem to be any obvious
> multithreading in R.
>
> Are there any plans to change this?

Yes, and some multithreading is done with some external BLAS, which is 
probably where there is the most obvious scope for benefit.

The problem is that unless the vectors are long the costs of using 
multiple threads can exceed the gain in using multiple CPUs: we have seen 
dramatic slowdowns using reputable multithreaded BLAS.

Other parts of R are under active consideration for using multiple 
threads: for example now Open MP is fairly widely available (in gcc >= 
4.2.0 and some earlier RedHat backports) this may be easier to do in a 
portable way.

I think you probably did not mean the ability to run multiple R 
interpreters in separate threads -- that has been discussed for many years 
(e.g. at DSC 2001).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Fri Aug 31 18:30:43 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 31 Aug 2007 09:30:43 -0700
Subject: [Rd] locales and readLines
Message-ID: <6phfy1zll8s.fsf@gopher4.fhcrc.org>

R-developers,

I'm looking for some 'best practices', or perhaps an upstream solution
(I have a deja vu about this, so sorry if it's already been asked).
Problems occur when a file is encoded as latin1, but the user has a
UTF-8 locale (or I guess more generally when the input locale does not
match R's).  Here are two examples from the Bioconductor help list:

https://stat.ethz.ch/pipermail/bioconductor/2007-August/018947.html

(the relevant command is library(GEOquery); gse <- getGEO('GSE94'))

https://stat.ethz.ch/pipermail/bioconductor/2007-July/018204.html

I think solutions are:

* Specify the encoding in readLines.

* Convert the input using iconv.

* Tell the user to set their locale to match the input file (!)

Unfortunately, these (1 & 2, anyway) place extra burden on the package
author, to become educated about locales, the encoding conventions of
the files they read, and to know how R deals with encodings.

Are there other / better solutions? Any chance for some (additional)
'smarts' when reading files?

Martin
-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From hb at stat.berkeley.edu  Fri Aug 31 21:45:34 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 31 Aug 2007 12:45:34 -0700
Subject: [Rd] Consistency of serialize(): please enlighten me
Message-ID: <59d7961d0708311245v5f03dd4djca143eb4d5c29180@mail.gmail.com>

Hi,

I am puzzled with serialize().  It comes down generating identical
hash codes for (apparently) identical objects using digest::digest(),
which in turn relies on serialize().  Here is an example illustration
the issue:

ser <- function(object, ...) {
  list(
    names = names(object),
    namesRaw = charToRaw(names(object)),
    ser = serialize(names(object), connection=NULL, ascii=FALSE)
  )
} # ser()

# Object to be serialized
key <- key0 <- list(abc="Hello");

# Store results
d <- list();

# 1. As is
d[[1]] <- ser(key);

# 2. Set names and redo (hardwired: identical to what's already there)
names(key) <- "abc";
d[[2]] <- ser(key);

# 3. Set names and redo (generic: char->raw->char)
key <- key0;
names(key) <- sapply(names(key), FUN=function(name) rawToChar(charToRaw(name)));
d[[3]] <- ser(key);

# All names are identical
for (kk in 2:length(d))
  stopifnot(identical(d[[1]]$names, d[[kk]]$names));

# All raw names are identical
for (kk in 2:length(d))
  stopifnot(identical(d[[1]]$namesRaw, d[[kk]]$namesRaw));

# But, the serialized names differ.
print(identical(d[[1]]$ser, d[[2]]$ser));
print(identical(d[[1]]$ser, d[[3]]$ser));
print(identical(d[[2]]$ser, d[[3]]$ser));

So, it seems like there is some extra information in the names
attribute that is part of the serialization.  Is it possible to show
they differ at the R level?  What is that extra information?
Promises...?

Please enlighten me.

Henrik


From hb at stat.berkeley.edu  Fri Aug 31 21:49:13 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 31 Aug 2007 12:49:13 -0700
Subject: [Rd] Consistency of serialize(): please enlighten me
In-Reply-To: <59d7961d0708311245v5f03dd4djca143eb4d5c29180@mail.gmail.com>
References: <59d7961d0708311245v5f03dd4djca143eb4d5c29180@mail.gmail.com>
Message-ID: <59d7961d0708311249p798300e3i97c12620c93b82d2@mail.gmail.com>

Forgot...

On 8/31/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Hi,
>
> I am puzzled with serialize().  It comes down generating identical
> hash codes for (apparently) identical objects using digest::digest(),
> which in turn relies on serialize().  Here is an example illustration
> the issue:
>
> ser <- function(object, ...) {
>   list(
>     names = names(object),
>     namesRaw = charToRaw(names(object)),
>     ser = serialize(names(object), connection=NULL, ascii=FALSE)
>   )
> } # ser()
>
> # Object to be serialized
> key <- key0 <- list(abc="Hello");
>
> # Store results
> d <- list();
>
> # 1. As is
> d[[1]] <- ser(key);
>
> # 2. Set names and redo (hardwired: identical to what's already there)
> names(key) <- "abc";
> d[[2]] <- ser(key);
>
> # 3. Set names and redo (generic: char->raw->char)
> key <- key0;
> names(key) <- sapply(names(key), FUN=function(name) rawToChar(charToRaw(name)));
> d[[3]] <- ser(key);
>
> # All names are identical
> for (kk in 2:length(d))
>   stopifnot(identical(d[[1]]$names, d[[kk]]$names));
>
> # All raw names are identical
> for (kk in 2:length(d))
>   stopifnot(identical(d[[1]]$namesRaw, d[[kk]]$namesRaw));
>
> # But, the serialized names differ.
> print(identical(d[[1]]$ser, d[[2]]$ser));
> print(identical(d[[1]]$ser, d[[3]]$ser));
> print(identical(d[[2]]$ser, d[[3]]$ser));

With R version 2.6.0 Under development (unstable) (2007-08-23 r42614) I get:
[1] TRUE
[1] FALSE
[1] FALSE

and with R version 2.5.1 Patched (2007-07-19 r42284):
[1] FALSE
[1] FALSE
[1] TRUE

>
> So, it seems like there is some extra information in the names
> attribute that is part of the serialization.  Is it possible to show
> they differ at the R level?  What is that extra information?
> Promises...?
>
> Please enlighten me.
>
> Henrik
>


From apjaworski at mmm.com  Fri Aug 31 22:31:28 2007
From: apjaworski at mmm.com (apjaworski at mmm.com)
Date: Fri, 31 Aug 2007 15:31:28 -0500
Subject: [Rd] compiling R-devel
Message-ID: <OFA047BAD6.FC254B4C-ON86257348.006D5302-86257348.0070BEB8@mmm.com>


Hello.

I am in a habit of compiling daily snapshots of R-devel and R-patched on my
Windows XP workstation.  I have cygwin environment with up-to-date RTools
and MiKTeX.  I run cygwin and MiKTeX upadaters pretty often (every couple
of days) so both of them are reasonably current.

Recently I noticed a small annoyance when compiling R-dvel.  It started
happening right after I updated to the new version of RTools (containing
MinGW 4.2.1-sjlj compilers).  Everything else stayed the same with possible
exception of MiKTeX update.

I usually just type "make distribution" to compile everything.  The
compilation itself goes smoothly.  Then the PDF version of the reference
manual is created.  Then I see this:

...
Output written on refman.pdf (1563 pages, 7869936 bytes).
Transcript written on refman.log.
creating doc/manual/version.texi
texi2dvi --pdf --texinfo="@set UseExternalXrefs " R-FAQ.texi
This is pdfTeX, Version 3.141592-1.40.4 (MiKTeX 2.6)
entering extended mode
! I can't find file `\tmp\t2d6036\xtr\R-FAQ.texi'.
<*> /tmp/t2d6036/xtr/R-FAQ.texi

Please type another input file name:

Now the file  /tmp/t2d6036/xtr/R-FAQ.texi exists at this point is not empty
and has usual protection codes.  I tried different versions of back and
front slashes, double backslashes, etc., but to no avail.  I was getting
the same message - the file cannot be found.  The only thing that works is
the plain file name.  That is, if I just type (or copy and paste) the
string R-FAQ.texi everything works fine.  This happens three times for
every manual (except the refman).  After that the compilation ends
normally, the windows installer is created and, when I run the installer, I
get everything working correctly including PDFs of the manuals.

It looks to me like the /tmp/t2d6036/xtr/ part of the name gets already
pre-pended to whatever name the make process provides so it expects just
the file name.  Alternatively, something changed in my MiKTeX setup due to
updates.  However, the refman compiles properly and I can also compile
other LaTeX with no apparent problems.

Thanks in advance,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


From p.dalgaard at biostat.ku.dk  Fri Aug 31 22:49:31 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 31 Aug 2007 22:49:31 +0200
Subject: [Rd]  ****R 2.6.0**** scheduled for October 3
In-Reply-To: <46D71EDF.8070605@biostat.ku.dk>
References: <46D71EDF.8070605@biostat.ku.dk>
Message-ID: <46D87EDB.7010809@biostat.ku.dk>

D'oh! There's always one more item to update....

Peter Dalgaard wrote:
> This is to announce that we plan to release R version 2.6.0 on Wednesday
> October 3, 2007. The following information is mainly for developers,
> package maintainers and repository maintainers.
>
> The planned procedure is
>
> Sep  5: "Grand Feature" Freeze  2.6.0 alpha
> Sep 19: Feature Freeze          2.6.0 beta
> Sep 26: Code Freeze             2.6.0 RC
> Oct  3: Release                 2.6.0
>
> GFF: No major restructuring past this point
> FF:  Feature set complete, only bugfixing from now on
> CF:  Only critical bugfixes and platform build issues
>
> Maintainers of recommended packages should notice that as they become
> part of the final R tarball, we expect them to follow a similar freeze
> pattern (and beware of potential CRAN delays, so please do not cut it
> too close to the deadlines).
>
> Notice that the main structural discontinuities occurs at GFF:
>
> The SVN repository is affected as follows
>     The trunk version is set to "2.7.0 Under development (unstable)".
>     A new branch, R-2-7-branch is created.
>
> This also implies new version numbers for "r-devel" and
> "r-release-branch", in the sense of
>
> http://developer.r-project.org/SVNtips.html 
>
> Also, "r-release-branch" needs to have its tag updated.
>
> Repository maintainers may need to revise directory structures
> accordingly.
>
> "R 2.5.1 Patched" will be closed to further development at GFF (as all
> the release branches, it can be reopened if the need arises, we just
> don't anticipate such a need.)
>
> The source alpha/beta/RC tarballs will be made available daily
> (barring build troubles) by a cron job running at 4AM CET, and the
> tarballs can be picked up at
>
> http://cran.r-project.org/src/base-prerelease/
>
> a little later.
>
> The various freeze points are marked by changes to the VERSION file
> this is also done automatically by a cron job which runs just after
> midnight on the relevant days.
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


