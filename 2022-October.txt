From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Sat Oct  1 18:00:07 2022
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Sat, 1 Oct 2022 16:00:07 +0000
Subject: [Rd] Linking to Intel's MKL on Windows
In-Reply-To: <CAP1vfdtozPWjKkvL9tqKZPKA1y+B44d2tc+yO6n4tYCUpJQOug@mail.gmail.com>
References: <CAP1vfdtozPWjKkvL9tqKZPKA1y+B44d2tc+yO6n4tYCUpJQOug@mail.gmail.com>
Message-ID: <acfeb141204c48ebb18d8c6737f1d1a9@UM-MAIL3214.unimaas.nl>

Hi Christine,

MKL is a closed-source commercial product (yes, one can get it for free, but it is not libre/open-source software).

Best,
Wolfgang

>-----Original Message-----
>From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Christine
>Stawitz - NOAA Federal via R-devel
>Sent: Friday, 30 September, 2022 18:46
>To: r-devel at r-project.org
>Subject: [Rd] Linking to Intel's MKL on Windows
>
>Hi,
>
>Recently I became aware that Microsoft R Open provides accelerated matrix
>algebra computations through Intel's Math Kernel Libraries. However, the
>version of R shipped with the Microsoft R Open is too out of date to be
>able to use concurrently with other dependencies while developing our
>package. This thread suggests a way to get the updated matrix libraries
>with a more recent version of R, however it is unlikely to be approved by
>our IT admin since those of us in government agencies aren't typically
>given admin privileges: Linking Intel's Math Kernel Library (MKL) to R on
>Windows - Stack Overflow
><https://stackoverflow.com/questions/38090206/linking-intels-math-kernel-library-
>mkl-to-r-on-windows>
>
>Is there a reason why CRAN doesn't provide a version of R with the updated
>libraries such that developers don't have to recompile R or copy .dlls
>around as described above? It would help those of us running software with
>slow-running matrix calculations in R.
>
>Thanks,
>Christine
>
>--
>Christine C. Stawitz, PhD. (pronouns: she/her)
>
>National Stock Assessment Program Modeling Team
>
>NOAA Fisheries Office of Science and Technology |  U.S. Department of
>Commerce
>
>Mobile: 206-617-2060
>
>www.fisheries.noaa.gov



From bbo|ker @end|ng |rom gm@||@com  Sat Oct  1 18:48:39 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 1 Oct 2022 12:48:39 -0400
Subject: [Rd] Linking to Intel's MKL on Windows
In-Reply-To: <acfeb141204c48ebb18d8c6737f1d1a9@UM-MAIL3214.unimaas.nl>
References: <CAP1vfdtozPWjKkvL9tqKZPKA1y+B44d2tc+yO6n4tYCUpJQOug@mail.gmail.com>
 <acfeb141204c48ebb18d8c6737f1d1a9@UM-MAIL3214.unimaas.nl>
Message-ID: <13d28348-762f-c15a-4ece-980498e7e990@gmail.com>

    Maybe you can find out more about Microsoft's development/release 
process for MRO and why they're still on 4.0.2 (from June 2020)?  I 
followed the "user forum" link on their web page, but it appears to be a 
generic Windows forum ...

https://social.msdn.microsoft.com/Forums/en-US/home?forum%20=ropen

    I might tweet at @revodavid (David Smith) to see if there's any more 
information available about the MRO release schedule ...

   good luck,
    Ben Bolker




On 2022-10-01 12:00 p.m., Viechtbauer, Wolfgang (NP) wrote:
> Hi Christine,
> 
> MKL is a closed-source commercial product (yes, one can get it for free, but it is not libre/open-source software).
> 
> Best,
> Wolfgang
> 
>> -----Original Message-----
>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Christine
>> Stawitz - NOAA Federal via R-devel
>> Sent: Friday, 30 September, 2022 18:46
>> To: r-devel at r-project.org
>> Subject: [Rd] Linking to Intel's MKL on Windows
>>
>> Hi,
>>
>> Recently I became aware that Microsoft R Open provides accelerated matrix
>> algebra computations through Intel's Math Kernel Libraries. However, the
>> version of R shipped with the Microsoft R Open is too out of date to be
>> able to use concurrently with other dependencies while developing our
>> package. This thread suggests a way to get the updated matrix libraries
>> with a more recent version of R, however it is unlikely to be approved by
>> our IT admin since those of us in government agencies aren't typically
>> given admin privileges: Linking Intel's Math Kernel Library (MKL) to R on
>> Windows - Stack Overflow
>> <https://stackoverflow.com/questions/38090206/linking-intels-math-kernel-library-
>> mkl-to-r-on-windows>
>>
>> Is there a reason why CRAN doesn't provide a version of R with the updated
>> libraries such that developers don't have to recompile R or copy .dlls
>> around as described above? It would help those of us running software with
>> slow-running matrix calculations in R.
>>
>> Thanks,
>> Christine
>>
>> --
>> Christine C. Stawitz, PhD. (pronouns: she/her)
>>
>> National Stock Assessment Program Modeling Team
>>
>> NOAA Fisheries Office of Science and Technology |  U.S. Department of
>> Commerce
>>
>> Mobile: 206-617-2060
>>
>> www.fisheries.noaa.gov
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.



From @vr@h@m@@d|er @end|ng |rom gm@||@com  Sun Oct  2 01:52:39 2022
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Sat, 1 Oct 2022 19:52:39 -0400
Subject: [Rd] Linking to Intel's MKL on Windows
In-Reply-To: <13d28348-762f-c15a-4ece-980498e7e990@gmail.com>
References: <13d28348-762f-c15a-4ece-980498e7e990@gmail.com>
Message-ID: <DE8330EC-333A-4F4A-8333-035E1B9ECCA3@gmail.com>

Also, you can build Rblas against OpenBLAS even on Windows which will go far in speeding up matrix calculations. 

Thanks,

Avi

Sent from my iPhone

> On Oct 1, 2022, at 12:49 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> ?   Maybe you can find out more about Microsoft's development/release process for MRO and why they're still on 4.0.2 (from June 2020)?  I followed the "user forum" link on their web page, but it appears to be a generic Windows forum ...
> 
> https://social.msdn.microsoft.com/Forums/en-US/home?forum%20=ropen
> 
>   I might tweet at @revodavid (David Smith) to see if there's any more information available about the MRO release schedule ...
> 
>  good luck,
>   Ben Bolker
> 
> 
> 
> 
>> On 2022-10-01 12:00 p.m., Viechtbauer, Wolfgang (NP) wrote:
>> Hi Christine,
>> MKL is a closed-source commercial product (yes, one can get it for free, but it is not libre/open-source software).
>> Best,
>> Wolfgang
>>> -----Original Message-----
>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Christine
>>> Stawitz - NOAA Federal via R-devel
>>> Sent: Friday, 30 September, 2022 18:46
>>> To: r-devel at r-project.org
>>> Subject: [Rd] Linking to Intel's MKL on Windows
>>> 
>>> Hi,
>>> 
>>> Recently I became aware that Microsoft R Open provides accelerated matrix
>>> algebra computations through Intel's Math Kernel Libraries. However, the
>>> version of R shipped with the Microsoft R Open is too out of date to be
>>> able to use concurrently with other dependencies while developing our
>>> package. This thread suggests a way to get the updated matrix libraries
>>> with a more recent version of R, however it is unlikely to be approved by
>>> our IT admin since those of us in government agencies aren't typically
>>> given admin privileges: Linking Intel's Math Kernel Library (MKL) to R on
>>> Windows - Stack Overflow
>>> <https://stackoverflow.com/questions/38090206/linking-intels-math-kernel-library-
>>> mkl-to-r-on-windows>
>>> 
>>> Is there a reason why CRAN doesn't provide a version of R with the updated
>>> libraries such that developers don't have to recompile R or copy .dlls
>>> around as described above? It would help those of us running software with
>>> slow-running matrix calculations in R.
>>> 
>>> Thanks,
>>> Christine
>>> 
>>> --
>>> Christine C. Stawitz, PhD. (pronouns: she/her)
>>> 
>>> National Stock Assessment Program Modeling Team
>>> 
>>> NOAA Fisheries Office of Science and Technology |  U.S. Department of
>>> Commerce
>>> 
>>> Mobile: 206-617-2060
>>> 
>>> www.fisheries.noaa.gov
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
> > E-mail is sent at my convenience; I don't expect replies outside of working hours.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sun Oct  2 10:42:50 2022
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sun, 2 Oct 2022 08:42:50 +0000 (UTC)
Subject: [Rd] as.character.POSIXt in R devel
References: <1454067819.3486826.1664700170912.ref@mail.yahoo.com>
Message-ID: <1454067819.3486826.1664700170912@mail.yahoo.com>

With?r82904,?'as.character.POSIXt'?in?R?devel?is?changed.?The?NEWS?item:
as.character(<POSIXt>)?now?behaves?more?in?line?with?the
???methods?for?atomic?vectors?such?as?numbers,?and?is?no?longer
???influenced?by?options().

Part?of?the?code:

???????s?<-?trunc(x$sec)
????????fs?<-?x$sec?-?s
????????r1?<-?sprintf("%d-%02d-%02d",?1900?+?x$year,?x$mon+1L,?x$mday)
??????if(any(n0?<-?time?!=?0))?#?add?time?if?not?0
????????????r1[n0]?<-?paste(r1[n0],
????????????????????????sprintf("%02d:%02d:%02d%s",?x$hour[n0],?x$min[n0],?s[n0],
????????????????????????????????substr(as.character(fs[n0]),?2L,?32L)))


*?Wrong:
The?result?is?wrong?when?as.character(fs[n0])?has?scientific?notation.
Example?(modified?from?https://bugs.r-project.org/show_bug.cgi?id=9819):
op?<-?options(scipen?=?0,?OutDec?=?".")?#?(default?setting)
x?<-?as.POSIXlt("2007-07-27?16:11:03.000002")
as.character(x)
#?"2007-07-27?16:11:03.99999999983547e-06"
as.character(x$sec?-?trunc(x$sec))
#?"1.99999999983547e-06"
options(op)

'as.character.POSIXt'?could?temporarily?set?option?'scipen'?large?enough?to?prevent?scientific?notation?in?as.character(fs[n0])?.


*?Too?much?precision:
In?some?cases?with?fractional?seconds?with?seconds?close?to?60,?the?result?has?many?decimal?places?while?there?is?an?accurate?representation?with?less?decimal?places.?It?is?actually?OK,?just?unpleasant.
Example?(modified?from?https://bugs.r-project.org/show_bug.cgi?id=14693):
op?<-?options(scipen?=?0,?OutDec?=?".")?#?(default?setting)
x?<-?as.POSIXlt("2011-10-01?12:34:56.3")
x$sec?==?56.3?#?TRUE
print(x$sec,?17)
#?[1]?56.299999999999997
as.character(x)
#?"2011-10-01?12:34:56.299999999999997"
format(x,?"%Y-%m-%d?%H:%M:%OS1")?#?short?and?accurate
#?"2011-10-01?12:34:56.3"
ct?<-?as.POSIXct(x,?tz?=?"UTC")
identical(ct,
as.POSIXct("2011-10-01?12:34:56.3",?tz?=?"UTC"))
#?TRUE
print(as.numeric(ct),?17)
#?[1]?1317472496.3
lct?<-?as.POSIXlt(ct)
lct$sec?==?56.3?#?FALSE
print(lct$sec,?17)
#?[1]?56.299999952316284
as.character(ct)
#?"2011-10-01?12:34:56.299999952316284"
options(op)

The?"POSIXct"?case?is?a?little?different?because?some?precision?is?already?lost?after?converted?to?"POSIXct".

In?'as.character.POSIXt',?using?'as.character'?on?the?seconds?(not?separating?the?fractional?part)?might?be?good?enough,?but?a?leading?zero?must?be?added?as?necessary.


*?Different?from?'format':

-?With?fractional?seconds,?the?result?is?influenced?by?option?'OutDec'.

-?From?"Printing?years"?in??strptime:?"For?years?0?to?999?most?OSes?pad?with?zeros?or?spaces?to?4?characters,?and?Linux?outputs?just?the?number."
Because?(1900?+?x$year)?is?formatted?with?%d?in?'as.character.POSIXt',?years?0?to?999?is?output?without?padding.?It?is?different?from?'format'?in?OSes?other?than?Linux.


*?Behavior?with?"improper"?"POSIXlt"?object:

-?"POSIXlt"?object?with?out-of-bounds?components?is?not?normalized.
Example?(modified?from?regr.tests-1d.R):
op?<-?options(scipen?=?0)?#?(default?setting)
x?<-?structure(
list(sec?=?10000,?min?=?59L,?hour?=?18L,
mday?=?6L,?mon?=?11L,?year?=?116L,
wday?=?2L,?yday?=?340L,
isdst?=?0L,?zone?=?"CET",?gmtoff?=?3600L),
class?=?c("POSIXlt",?"POSIXt"),?tzone?=?"CET")
as.character(x)
#?"2016-12-06?18:59:10000"
format(x)
#?"2016-12-06?21:45:40"
options(op)

-?With?"POSIXlt"?object?where?sec,?min,?hour,?mday,?mon,?and?year?components?are?not?all?of?the?same?length,?recycling?is?not?handled.
Example?(modified?from?regr.tests-1d.R):
op?<-?options(scipen?=?0)?#?(default?setting)
x?<-?structure(
list(sec?=?c(1,??2),?min?=?59L,?hour?=?18L,
mday?=?6L,?mon?=?11L,?year?=?116L,
wday?=?2L,?yday?=?340L,
isdst?=?0L,?zone?=?"CET",?gmtoff?=?3600L),
class?=?c("POSIXlt",?"POSIXt"),?tzone?=?"CET")
as.character(x)
#?c("2016-12-06?18:59:01",?"NA?NA:NA:02")
format(x)
#?c("2016-12-06?18:59:01",?"2016-12-06?18:59:02")
options(op)



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Oct  3 14:46:08 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Oct 2022 14:46:08 +0200
Subject: [Rd] as.character.POSIXt in R devel
In-Reply-To: <1454067819.3486826.1664700170912@mail.yahoo.com>
References: <1454067819.3486826.1664700170912.ref@mail.yahoo.com>
 <1454067819.3486826.1664700170912@mail.yahoo.com>
Message-ID: <25402.55696.329918.913605@stat.math.ethz.ch>


>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Sun, 2 Oct 2022 08:42:50 +0000 (UTC) writes:

    > With r82904, 'as.character.POSIXt' in R devel is changed. The NEWS item:

    >   as.character(<POSIXt>) now behaves more in line with the
    >   methods for atomic vectors such as numbers, and is no longer
    >   influenced by options().

    > Part of the code:
    > 
    >   s <- trunc(x$sec)
    >   fs <- x$sec - s
    >   r1 <- sprintf("%d-%02d-%02d", 1900 + x$year, x$mon+1L, x$mday)
    >   if(any(n0 <- time != 0)) # add time if not 0
    >     r1[n0] <- paste(r1[n0],
    >                  sprintf("%02d:%02d:%02d%s", x$hour[n0], x$min[n0], s[n0],
    >                         substr(as.character(fs[n0]), 2L, 32L)))


    > * Wrong:

    > The result is wrong when as.character(fs[n0]) has scientific notation.

yes, you are right.  This is a lapsus I will fix.

    > Example (modified from https://bugs.r-project.org/show_bug.cgi?id=9819):
    > op <- options(scipen = 0, OutDec = ".") # (default setting)
    > x <- as.POSIXlt("2007-07-27 16:11:03.000002")
    > as.character(x)
    > # "2007-07-27 16:11:03.99999999983547e-06"
    > as.character(x$sec - trunc(x$sec))
    > # "1.99999999983547e-06"
    > options(op)

    > 'as.character.POSIXt' could temporarily set option 'scipen' large enough to prevent scientific notation in as.character(fs[n0]) .

Yes, something like that.


    > * Too much precision:

    > In some cases with fractional seconds with seconds close to 60, the result has many decimal places while there is an accurate representation with less decimal places. It is actually OK, just unpleasant.

I agree that is unpleasant.
To someone else I had written that we also may need to improve
the number of decimals shown here.
The design has been that it should be "full precision"
as it is for  as.character(<numbers>)

Now, we know that POSIXct cannot be very precise (in its
fractional seconds) but that is very different for POSIXlt where
fractional seconds may have 14 digits after the decimal point.

Ideally we could *store* with the POSIXlt object if it was
produced from a POSIXct one, and hence have only around 6 valid digits
(after the dec.) or not.  As we cannot currently store/save that
info, we kept using "full" precision which may be much more than
is sensible.

    > Example (modified from https://bugs.r-project.org/show_bug.cgi?id=14693):
    > op <- options(scipen = 0, OutDec = ".") # (default setting)
    > x <- as.POSIXlt("2011-10-01 12:34:56.3")
    > x$sec == 56.3 # TRUE

[which may be typical, but may also be platform dependent]

    > print(x$sec, 17)
    > # [1] 56.299999999999997
    > as.character(x)
    > # "2011-10-01 12:34:56.299999999999997"
    > format(x, "%Y-%m-%d %H:%M:%OS1") # short and accurate
    > # "2011-10-01 12:34:56.3"
    > ct <- as.POSIXct(x, tz = "UTC")
    > identical(ct,
    > as.POSIXct("2011-10-01 12:34:56.3", tz = "UTC"))
    > # TRUE
    > print(as.numeric(ct), 17)
    > # [1] 1317472496.3
    > lct <- as.POSIXlt(ct)
    > lct$sec == 56.3 # FALSE
    > print(lct$sec, 17)
    > # [1] 56.299999952316284
    > as.character(ct)
    > # "2011-10-01 12:34:56.299999952316284"
    > options(op)

    > The "POSIXct" case is a little different because some precision is already lost after converted to "POSIXct".

yes, indeed.

    > In 'as.character.POSIXt', using 'as.character' on the seconds (not separating the fractional part) might be good enough, but a leading zero must be added as necessary.

I think you are right: that may definitely better...

    > * Different from 'format':

    > - With fractional seconds, the result is influenced by option 'OutDec'.

Thank you.  I was not aware of that.
The reason "of course" being that  as.character(<numeric>)  is
*also* depending on option  OutDec.

I would say that is clearly wrong...  and I think we should
strongl consider to change that:

'OutDec' should influence print()ing and format()ing  but should
*not* influence  as.character()  at least not for basic R types/objects.


    > - From "Printing years" in ?strptime: "For years 0 to 999 most OSes pad with zeros or spaces to 4 characters, and Linux outputs just the number."
    > Because (1900 + x$year) is formatted with %d in 'as.character.POSIXt', years 0 to 999 is output without padding. It is different from 'format' in OSes other than Linux.

Good point.  This should be  amended.



    > * Behavior with "improper" "POSIXlt" object:

    > - "POSIXlt" object with out-of-bounds components is not normalized.

    > Example (modified from regr.tests-1d.R):
    > op <- options(scipen = 0) # (default setting)
    > x <- structure(
    > list(sec = 10000, min = 59L, hour = 18L,
    > mday = 6L, mon = 11L, year = 116L,
    > wday = 2L, yday = 340L,
    > isdst = 0L, zone = "CET", gmtoff = 3600L),
    > class = c("POSIXlt", "POSIXt"), tzone = "CET")
    > as.character(x)
    > # "2016-12-06 18:59:10000"
    > format(x)
    > # "2016-12-06 21:45:40"
    > options(op)


Yes, we knew that  and were not too happy about it, but also not
too unhappy:
After all,		    help(DateTimeClasses)
clearly explains how
POSIXlt objects should look like :

-------------------------------------------------------------------
  Class ?"POSIXlt"? is a named list of vectors representing

     ?sec? 0-61: seconds.
     ?min? 0-59: minutes.
     ?hour? 0-23: hours.
     ?mday? 1-31: day of the month
     ?mon? 0-11: months after the first of the year.
     ?year? years since 1900.
     ?wday? 0-6 day of the week, starting on Sunday.
     ?yday? 0-365: day of the year (365 only in leap years).

     ?isdst? Daylight Saving Time ... ... ...
     ................................
     ................................

-------------------------------------------------------------------

We have been aware that as.character() assumes the above specification,
even though other R functions, notably format() which uses
internal (C level; either system (OS) or R's own) strptime() do
arithmetic (modulo 60, then modulo 24, then modulo month length)
to compute the date "used".

Allowing such  "un-normalized" / out-of-bound  POSIXlt objects
in R has not been documented AFAICS, and has the consequence
that two different POSIXlt objects may correspond to the exact
same time. 

This may be something worth discussing.
In some sense we are discussing how the "POSIXlt" class is defined
(even though an S3 class is never formally defined).



    > - With "POSIXlt" object where sec, min, hour, mday, mon,
    > and year components are not all of the same length, recycling is not handled.

Good point.  I tend to agree that this should be improved *and* also
documented: AFAIK, it is also not at all documented  (or is it ??)
that the POSIXlt components should be thought to be recycling.

If we decide we want that, 
once this is documented (and all methods/functions tested with
such POSIXlt) it could also be used to use considerably smaller size
POSIXlt objects, e.g, when all parts are in the same year, or
when all seconds are 0, or ...

    > Example (modified from regr.tests-1d.R):
    > op <- options(scipen = 0) # (default setting)
    > x <- structure(
    > list(sec = c(1,  2), min = 59L, hour = 18L,
    > mday = 6L, mon = 11L, year = 116L,
    > wday = 2L, yday = 340L,
    > isdst = 0L, zone = "CET", gmtoff = 3600L),
    > class = c("POSIXlt", "POSIXt"), tzone = "CET")
    > as.character(x)
    > # c("2016-12-06 18:59:01", "NA NA:NA:02")
    > format(x)
    > # c("2016-12-06 18:59:01", "2016-12-06 18:59:02")
    > options(op)


Thank you for your careful analysis and feedback
on this future R behavior !

Best regards,
Martin



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Oct  3 18:58:48 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Oct 2022 18:58:48 +0200
Subject: [Rd] as.character.POSIXt in R devel
In-Reply-To: <25402.55696.329918.913605@stat.math.ethz.ch>
References: <1454067819.3486826.1664700170912.ref@mail.yahoo.com>
 <1454067819.3486826.1664700170912@mail.yahoo.com>
 <25402.55696.329918.913605@stat.math.ethz.ch>
Message-ID: <25403.5320.335656.447541@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Mon, 3 Oct 2022 14:46:08 +0200 writes:

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Sun, 2 Oct 2022 08:42:50 +0000 (UTC) writes:

    >> With r82904, 'as.character.POSIXt' in R devel is changed. The NEWS item:

    >> as.character(<POSIXt>) now behaves more in line with the
    >> methods for atomic vectors such as numbers, and is no longer
    >> influenced by options().

 [..............]

    >> * Wrong:

    >> The result is wrong when as.character(fs[n0]) has scientific notation.

    > yes, you are right.  This is a lapsus I will fix.

    >> Example (modified from https://bugs.r-project.org/show_bug.cgi?id=9819):
    >> op <- options(scipen = 0, OutDec = ".") # (default setting)
    >> x <- as.POSIXlt("2007-07-27 16:11:03.000002")
    >> as.character(x)
    >> # "2007-07-27 16:11:03.99999999983547e-06"
    >> as.character(x$sec - trunc(x$sec))
    >> # "1.99999999983547e-06"
    >> options(op)

    >> 'as.character.POSIXt' could temporarily set option 'scipen' large enough to prevent scientific notation in as.character(fs[n0]) .

    > Yes, something like that.

I have committed a version now of datetime.R,  svn rev 83010 ,
which does no longer depend on  'OutDec' (but gets such argument)
and which has a new 'digits' argument which defaults
to 14 for POSIXlt and
to  6 for POSIXct  .. but the user can choose a different value.

Also, it now uses the equivalent of  as.character(round(x$sec, digits))
(in case the seconds need to be shown)  which also solves the
following  "too much precision"  problem.

    >> * Too much precision:

    >> In some cases with fractional seconds with seconds close to 60, the result has many decimal places while there is an accurate representation with less decimal places. It is actually OK, just unpleasant.

    > I agree that is unpleasant.
    > To someone else I had written that we also may need to improve
    > the number of decimals shown here.
    > The design has been that it should be "full precision"
    > as it is for  as.character(<numbers>)

    > Now, we know that POSIXct cannot be very precise (in its
    > fractional seconds) but that is very different for POSIXlt where
    > fractional seconds may have 14 digits after the decimal point.

    > Ideally we could *store* with the POSIXlt object if it was
    > produced from a POSIXct one, and hence have only around 6 valid digits
    > (after the dec.) or not.  As we cannot currently store/save that
    > info, we kept using "full" precision which may be much more than
    > is sensible.

    >> Example (modified from https://bugs.r-project.org/show_bug.cgi?id=14693):
    >> op <- options(scipen = 0, OutDec = ".") # (default setting)
    >> x <- as.POSIXlt("2011-10-01 12:34:56.3")
    >> x$sec == 56.3 # TRUE

    > [which may be typical, but may also be platform dependent]

    >> print(x$sec, 17)
    >> # [1] 56.299999999999997
    >> as.character(x)
    >> # "2011-10-01 12:34:56.299999999999997"
    >> format(x, "%Y-%m-%d %H:%M:%OS1") # short and accurate
    >> # "2011-10-01 12:34:56.3"
    >> ct <- as.POSIXct(x, tz = "UTC")
    >> identical(ct,
    >> as.POSIXct("2011-10-01 12:34:56.3", tz = "UTC"))
    >> # TRUE
    >> print(as.numeric(ct), 17)
    >> # [1] 1317472496.3
    >> lct <- as.POSIXlt(ct)
    >> lct$sec == 56.3 # FALSE
    >> print(lct$sec, 17)
    >> # [1] 56.299999952316284
    >> as.character(ct)
    >> # "2011-10-01 12:34:56.299999952316284"
    >> options(op)

    >> The "POSIXct" case is a little different because some precision is already lost after converted to "POSIXct".

    > yes, indeed.

    >> In 'as.character.POSIXt', using 'as.character' on the seconds (not separating the fractional part) might be good enough, but a leading zero must be added as necessary.

    > I think you are right: that may definitely better...

indeed; part of my commit.

    >> * Different from 'format':

    >> - With fractional seconds, the result is influenced by option 'OutDec'.

this has been solved, too.
For the "freaks" allowing an explicit  'OutDec = *' argument
but *not* with default depending on options()!


    > Thank you.  I was not aware of that.
    > The reason "of course" being that  as.character(<numeric>)  is
    > *also* depending on option  OutDec.

    > I would say that is clearly wrong...  and I think we should
    > strongl consider to change that:

    > 'OutDec' should influence print()ing and format()ing  but should
    > *not* influence  as.character()  at least not for basic R types/objects.


    >> - From "Printing years" in ?strptime: "For years 0 to 999 most OSes pad with zeros or spaces to 4 characters, and Linux outputs just the number."
    >> Because (1900 + x$year) is formatted with %d in 'as.character.POSIXt', years 0 to 999 is output without padding. It is different from 'format' in OSes other than Linux.

    > Good point.  This should be  amended.

Not yet.  Actually, I'm no longer sure this needs any action.
I find it somewhat natural that

> (CharleMagne.crowned <- as.POSIXlt(ISOdate(774,7,10)))
[1] "774-07-10 12:00:00 GMT"
> as.character(CharleMagne.crowned)
[1] "774-07-10 12:00:00"



    >> * Behavior with "improper" "POSIXlt" object:

    >> - "POSIXlt" object with out-of-bounds components is not normalized.

    >> Example (modified from regr.tests-1d.R):
    >> op <- options(scipen = 0) # (default setting)
    >> x <- structure(
    >> list(sec = 10000, min = 59L, hour = 18L,
    >> mday = 6L, mon = 11L, year = 116L,
    >> wday = 2L, yday = 340L,
    >> isdst = 0L, zone = "CET", gmtoff = 3600L),
    >> class = c("POSIXlt", "POSIXt"), tzone = "CET")
    >> as.character(x)
    >> # "2016-12-06 18:59:10000"
    >> format(x)
    >> # "2016-12-06 21:45:40"
    >> options(op)


    > Yes, we knew that  and were not too happy about it, but also not
    > too unhappy:
    > After all,		    help(DateTimeClasses)
    > clearly explains how
    > POSIXlt objects should look like :

    > -------------------------------------------------------------------
    > Class ?"POSIXlt"? is a named list of vectors representing

    > ?sec? 0-61: seconds.
    > ?min? 0-59: minutes.
    > ?hour? 0-23: hours.
    > ?mday? 1-31: day of the month
    > ?mon? 0-11: months after the first of the year.
    > ?year? years since 1900.
    > ?wday? 0-6 day of the week, starting on Sunday.
    > ?yday? 0-365: day of the year (365 only in leap years).

    > ?isdst? Daylight Saving Time ... ... ...
    > ................................
    > ................................

    > -------------------------------------------------------------------

    > We have been aware that as.character() assumes the above specification,
    > even though other R functions, notably format() which uses
    > internal (C level; either system (OS) or R's own) strptime() do
    > arithmetic (modulo 60, then modulo 24, then modulo month length)
    > to compute the date "used".

    > Allowing such  "un-normalized" / out-of-bound  POSIXlt objects
    > in R has not been documented AFAICS, and has the consequence
    > that two different POSIXlt objects may correspond to the exact
    > same time. 

    > This may be something worth discussing.
    > In some sense we are discussing how the "POSIXlt" class is defined
    > (even though an S3 class is never formally defined).

(nothing changed here)


    >> - With "POSIXlt" object where sec, min, hour, mday, mon,
    >> and year components are not all of the same length, recycling is not handled.

This is still the case... (see below).

    > Good point.  I tend to agree that this should be improved *and* also
    > documented: AFAIK, it is also not at all documented  (or is it ??)
    > that the POSIXlt components should be thought to be recycling.

    > If we decide we want that, 
    > once this is documented (and all methods/functions tested with
    > such POSIXlt) it could also be used to use considerably smaller size
    > POSIXlt objects, e.g, when all parts are in the same year, or
    > when all seconds are 0, or ...

    >> Example (modified from regr.tests-1d.R):
    >> op <- options(scipen = 0) # (default setting)
    >> x <- structure(
    >> list(sec = c(1,  2), min = 59L, hour = 18L,
    >> mday = 6L, mon = 11L, year = 116L,
    >> wday = 2L, yday = 340L,
    >> isdst = 0L, zone = "CET", gmtoff = 3600L),
    >> class = c("POSIXlt", "POSIXt"), tzone = "CET")
    >> as.character(x)
    >> # c("2016-12-06 18:59:01", "NA NA:NA:02")
    >> format(x)
    >> # c("2016-12-06 18:59:01", "2016-12-06 18:59:02")
    >> options(op)

Note that currently such {needing recycling} - cases are
*also* not handled by the simple  (and important!)  length.POSIXlt()
method, either:  It currently only looks at the '.$sec'
component !

So this case does need discussion two.
I think it's unfortunate that *some* *.POSIXt methods do such
recycling, e.g. format.POSIXt,
but others do not {and the documentation does not even mention recycling}.

As mentioned, I am *pro* going in that direction;
so I would change

  length.POSIXlt <- function(x) length(unclass(x)[[1L]])

       (which only uses x$sec !)

to

  length.POSIXlt <- function(x) max(lengths(unclass(x), use.names=FALSE))

not allowing 0-length recycling; 0-lengths components
should really be illegal in an otherwise non-0-length POSIXlt x


Martin



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Mon Oct  3 22:20:50 2022
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 4 Oct 2022 09:20:50 +1300
Subject: [Rd] Question about grid.group compositing operators in cairo
In-Reply-To: <197c7a88-fb1c-49e1-7fc9-c1605abfef95@stat.auckland.ac.nz>
References: <0eaac5fb-b749-1470-c2a7-9f2f8215ace9@posteo.net>
 <c3debb04-04b8-90e8-2315-392105cd9db6@stat.auckland.ac.nz>
 <f581c979-44f0-3dc3-2c6f-015c2651b19c@stat.auckland.ac.nz>
 <6d240042-2017-a760-28d7-bf96d773fd90@posteo.net>
 <3e245b89-9c4f-dcbc-b310-5d3a25687af2@stat.auckland.ac.nz>
 <159821f0-0fc6-9054-c6bc-185102114e68@posteo.net>
 <c92574d5-f064-39c1-5fb4-05242607f19a@stat.auckland.ac.nz>
 <197c7a88-fb1c-49e1-7fc9-c1605abfef95@stat.auckland.ac.nz>
Message-ID: <543be111-1ed2-24ad-51ca-4849a67a49eb@stat.auckland.ac.nz>


Interim update:  I have spoken with Thomas Lin Pedersen (cc'ed), the 
author/maintainer of 'ragg' and 'svglite', who is working on adding 
group support for those graphics devices and he has voted in support of 
the current Cairo implementation, so the needle has shifted towards 
Cairo at this stage.

I still want to do more tests on other devices to gather more evidence.

Paul

p.s.  Attached (if it makes it through the filters) is a manual 
modification of your original dsvg() example that has been changed so 
that it produces the Cairo result.  This is probably not exactly how you 
would want to implement the dsvg() solution, but it is at least a proof 
of concept that the Cairo result can be produced in SVG.

On 30/09/22 10:49, Paul Murrell wrote:
> Hi
> 
> Some more thoughts ...
> 
> <1>
> I said before that currently, dev->group() does this ...
> 
> [OVER] shape shape shape OP shape shape shape
> 
> ... and one option would be an implicit group on 'src' and 'dst' like 
> this ...
> 
> ([OVER] shape shape shape) OP ([OVER] shape shape shape)
> 
> ... but another approach could be just an implicit group on each shape, 
> like this ...
> 
> [OVER] ([OVER] shape) ([OVER] shape) OP ([OVER] shape) ([OVER] shape)
> 
> That may be a better representation of what you are already doing with 
> dsvg() ?? It may also better reflect what naturally occurs in some 
> graphics systems.
> 
> <2>
> Changing the Cairo implementation to work like that would I think 
> produce the same result as your dsvg() for ...
> 
> grid.group(src, "in", dst)
> 
> ... and it would make what constitutes more than one shape much less 
> surprising ...
> 
> gList(rectGrob(), rectGrob())? ## multiple shapes (obviously)
> rectGrob(width=1:2/2)????????? ## multiple shapes (less obvious)
> rectGrob(gp=gpar(col=, fill=)) ## NOT multiple shapes (no surprise)
> 
> ... and it should not break any pre-existing non-group behaviour.
> 
> <3>
> One casualty from this third option would be that the following would no 
> longer solve the overlapping fill and stroke problem ...
> 
> grid.group(overlapRect, "source")
> 
> ... although the fact that that currently works is really a bit 
> surprising AND that result could still be achieved by explicitly drawing 
> separate shapes ...
> 
> grid.group(rectGrob(gp=gpar(col=rgb(1,0,0,.5), lwd=20, fill=NA)),
>  ?????????? "source",
>  ?????????? rectGrob(gp=gpar(col=NA, fill="green")))
> 
> <4>
> I need to try some of this out and also check in with some other people 
> who I think are working on implementing groups on different graphics 
> devices.
> 
> <5>
> In summary, don't go changing dsvg() too much just yet!
> 
> Paul
> 
> On 29/09/2022 1:30 pm, Paul Murrell wrote:
>> Hi
>>
>> Would it work to explicitly record a filled-and-stroked shape as two 
>> separate elements (one only filled and one only stroked) ?
>>
>> Then it should only be as hard to apply the active operator on both of 
>> those elements as it is to apply the active operator to more than one 
>> shape (?)
>>
>> Paul
>>
>> On 29/09/22 10:17, Panagiotis Skintzos wrote:
>>> Thank you for the very thorough explanation Paul.
>>>
>>> To answer your question on 11: The dsvg device, simply defines svg
>>> elements with their attributes (rect with fill & stroke in my examples).
>>> It does not do any internal image processing like cairo.
>>>
>>> My concern is how to proceed with the implementation in dsvg.
>>>
>>> If I leave it as it is now, they're will be cases where it will give
>>> different results from cairo (and perhaps other devices that will
>>> implement group compositing in similar way).
>>>
>>> On the other hand It would be quite challenging in practice to simulate
>>> the cairo implementation and apply first the fill and then the stroke
>>> with the active operator, on the element itself.
>>>
>>> Any suggestions? :-)
>>>
>>> Panagiotis
>>>
>>>
>>> On 28/9/22 02:56, Paul Murrell wrote:
>>> ?> Hi
>>> ?>
>>> ?> Thanks for the code (and for the previous attachments).
>>> ?>
>>> ?> Some thoughts so far (HTML version with images attached) ...
>>> ?>
>>> ?> <1>
>>> ?> As you have pointed out, the Cairo device draws a stroked-and-filled
>>> ?> shape with two separate drawing operations: the path is filled and
>>> ?> then the path is stroked.? I do not believe that there is any
>>> ?> alternative in Cairo graphics (apart from filling and stroking as an
>>> ?> isolated group and then drawing the group, which we will come back 
>>> to).
>>> ?>
>>> ?> <2>
>>> ?> This fill-then-stroke approach is easy to demonstrate just with a 
>>> thick
>>> ?> semitransparent border ...
>>> ?>
>>> ?> library(grid)
>>> ?> overlapRect <- rectGrob(width=.5, height=.5,
>>> ?> ??????????????????????? gp=gpar(fill="green", lwd=20,
>>> ?> ??????????????????????????????? col=rgb(1,0,0,.5)))
>>> ?> grid.newpage()
>>> ?> grid.draw(overlapRect)
>>> ?>
>>> ?> <3>
>>> ?> This fill-then-stroke approach is what happens on many (most?)
>>> ?> graphics devices, including, for example, the core windows() device,
>>> ?> the core quartz() device, the 'ragg' devices, and 'ggiraph'.? The
>>> ?> latter is true because this is actually the defined behaviour for 
>>> SVG ...
>>> ?>
>>> ?> https://www.w3.org/TR/SVG2/render.html#Elements 
>>> <https://www.w3.org/TR/SVG2/render.html#Elements>
>>> ?> https://www.w3.org/TR/SVG2/render.html#PaintingShapesAndText 
>>> <https://www.w3.org/TR/SVG2/render.html#PaintingShapesAndText>
>>> ?>
>>> ?> <4>
>>> ?> There are exceptions to the fill-then-stroke approach, including the
>>> ?> core pdf() device, but I think they are in the minority.? The PDF
>>> ?> language supports a "B" operator that only fills within the border 
>>> (no
>>> ?> overlap between fill and border).? Demonstrating this is complicated
>>> ?> by the fact that not all PDF viewers support this correctly (e.g.,
>>> ?> evince and Firefox do not;? ghostscript and chrome do)!
>>> ?>
>>> ?> <5>
>>> ?> Forcing all R graphics devices to change the rendering of
>>> ?> filled-and-stroked shapes to match the PDF definition instead of
>>> ?> fill-then-stroke is unlikely to happen because it would impact a lot
>>> ?> of graphics devices, it would break existing behaviour, it may be
>>> ?> difficult/impossible for some devices, and it is not clear that it is
>>> ?> the best approach anyway.
>>> ?>
>>> ?> <6>
>>> ?> Finally getting back to your example, the fill-then-stroke approach
>>> ?> produces some interesting results when applying compositing operators
>>> ?> because the fill is drawn using the compositing operator to 
>>> combine it
>>> ?> with previous drawing and then the stroke is drawn using the
>>> ?> compositing operator to combine it with *the result of combining the
>>> ?> fill with previous drawing*. The result makes sense in terms of how
>>> ?> the rendering works, but it probably fails the "principle of least
>>> ?> surprise".
>>> ?>
>>> ?> srcRect <- rectGrob(2/3, 1/3, width=.6, height=.6,
>>> ?> ??????????????????? gp=gpar(lwd = 5, fill=rgb(0, 0, 0.9, 0.4)))
>>> ?> dstRect <- rectGrob(1/3, 2/3, width=.6, height=.6,
>>> ?> ??????????????????? gp=gpar(lwd = 5, fill=rgb(0.7, 0, 0, 0.8)))
>>> ?> grid.newpage()
>>> ?> grid.group(srcRect, "in", dstRect)
>>> ?>
>>> ?> <7>
>>> ?> This issue is not entirely unanticipated because it can arise
>>> ?> slightly-less-unintentionally if we combine a 'src' and/or 'dst' that
>>> ?> draw more than one shape, like this ...
>>> ?>
>>> ?> src <- circleGrob(3:4/5, r=.2, gp=gpar(col=NA, fill=2))
>>> ?> dst <- circleGrob(1:2/5, r=.2, gp=gpar(col=NA, fill=3))
>>> ?> grid.newpage()
>>> ?> grid.group(src, "xor", dst)
>>> ?>
>>> ?> This was discussed in the Section "Compositing and blend modes" in 
>>> the
>>> ?> original technical report about groups and compositing ...
>>> ?>
>>> ?> 
>>> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/groups/groups.html#userdetails 
>>> <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/groups/groups.html#userdetails> 
>>>
>>> ?>
>>> ?>
>>> ?> <8>
>>> ?> A solution to the problem of drawing more than one shape (above) 
>>> is to
>>> ?> take explicit control of how shapes are combined, *using explicit
>>> ?> groups* ...
>>> ?>
>>> ?> grid.newpage()
>>> ?> grid.group(groupGrob(src), "xor", dst)
>>> ?>
>>> ?> <9>
>>> ?> Explicit groups can be used to solve the problem of overlapping fill
>>> ?> and stroke (here we specify that the rectangle border should be
>>> ?> combined with the rectangle fill using the "source" operator) ...
>>> ?>
>>> ?> grid.newpage()
>>> ?> grid.group(overlapRect, "source")
>>> ?>
>>> ?> <10>
>>> ?> Explicit groups can also be used to get the result that we might have
>>> ?> originally expected for the "in" operator example (here we isolate 
>>> the
>>> ?> 'src' rectangle so that the border and the fill are combined together
>>> ?> [using the default "over" operator] and then combined with the other
>>> ?> rectangle using the "in" operator) ...
>>> ?>
>>> ?> grid.newpage()
>>> ?> grid.group(groupGrob(srcRect), "in", dstRect)
>>> ?>
>>> ?> <11>
>>> ?> A possible change would be to force an implicit group (with op=OVER)
>>> ?> on the 'src' and 'dst' in dev->group().? I believe this is 
>>> effectively
>>> ?> what you are doing with your dsvg() device (?).
>>> ?>
>>> ?> Currently, dev->group() does this ...
>>> ?>
>>> ?> [OVER] shape shape shape OP shape shape shape
>>> ?>
>>> ?> ... and an implicit group on 'src' and 'dst' would do this ...
>>> ?>
>>> ?> ([OVER] shape shape shape) OP ([OVER] shape shape shape)
>>> ?>
>>> ?> An implicit (OVER) group would make it easier to combine multiple
>>> ?> shapes with OVER (though only slightly) ...
>>> ?>
>>> ?> grid.group(src, OP, dst)
>>> ?>
>>> ?> ... instead of ...
>>> ?>
>>> ?> grid.group(groupGrob(src), OP, dst)
>>> ?>
>>> ?> On the other hand, an implicit (OVER) group would make it harder to
>>> ?> combine multiple shapes with an operator other than OVER (by quite a
>>> ?> lot?) ...
>>> ?>
>>> ?> grid.group(groupGrob(shape, OP, groupGrob(shape, OP, shape)), OP, 
>>> dst)
>>> ?>
>>> ?> ... instead of ...
>>> ?>
>>> ?> grid.group(src, OP, dst)
>>> ?>
>>> ?> The complicating factor is that what constitutes more than one shape
>>> ?> (or drawing operation) can be unexpected ...
>>> ?>
>>> ?> gList(rectGrob(), rectGrob())? ## obvious
>>> ?> rectGrob(width=1:2/2)????????? ## less obvious
>>> ?> rectGrob(gp=gpar(col=, fill=)) ## a bit of a surprise
>>> ?>
>>> ?> <12>
>>> ?> In summary, while there is some temptation to add an implicit group
>>> ?> around 'src' and 'dst' in a group, there are also reasons not to.
>>> ?>
>>> ?> Happy to hear further arguments on this.
>>> ?>
>>> ?> Paul
>>> ?>
>>> ?> On 28/09/2022 8:04 am, Panagiotis Skintzos wrote:
>>> ?>> Here is the code again in text:
>>> ?>>
>>> ?>>
>>> ?>> src <- rectGrob(2/3, 1/3, width=.6, height=.6, gp=gpar(lwd = 5,
>>> ?>> fill=rgb(0, 0, 0.9, 0.4)))
>>> ?>> dst <- rectGrob(1/3, 2/3, width=.6, height=.6, gp=gpar(lwd = 5,
>>> ?>> fill=rgb(0.7, 0, 0, 0.8)))
>>> ?>>
>>> ?>> svg("cairo.in.svg", width = 5, height = 5)
>>> ?>> grid.group(src, "in", dst)
>>> ?>> dev.off()
>>> ?>>
>>> ?>>
>>> ?>>
>>> ?>> On 27/9/22 04:44, Paul Murrell wrote:
>>> ?>> ?>
>>> ?>> ?> Could you also please send me the SVG code that your device is
>>> ?>> ?> generating for your example.? Thanks!
>>> ?>> ?>
>>> ?>> ?> Paul
>>> ?>> ?>
>>> ?>> ?> On 27/09/22 08:50, Paul Murrell wrote:
>>> ?>> ?>> Hi
>>> ?>> ?>>
>>> ?>> ?>> Thanks for the report.? It certainly sounds like I have done
>>> ?>> ?>> something stupid :)? For my debugging and testing could you 
>>> please
>>> ?>> ?>> share the R code from your tests ?? Thanks!
>>> ?>> ?>>
>>> ?>> ?>> Paul
>>> ?>> ?>>
>>> ?>> ?>> On 26/09/22 10:27, Panagiotis Skintzos wrote:
>>> ?>> ?>>> Hello,
>>> ?>> ?>>>
>>> ?>> ?>>> I'm trying to update ggiraph package in graphic engine v15
>>> ?>> ?>>> (currently we support up to v14).
>>> ?>> ?>>>
>>> ?>> ?>>> I've implemented the group operators and when I compare the 
>>> outputs
>>> ?>> ?>>> of ggiraph::dsvg with the outputs of svg/png, I noticed some 
>>> weird
>>> ?>> ?>>> results.
>>> ?>> ?>>>
>>> ?>> ?>>> Specifically, some operators in cairo (in, out, dest.in, 
>>> dest.atop)
>>> ?>> ?>>> give strange output, when any source element in the group has a
>>> ?>> ?>>> stroke color defined.
>>> ?>> ?>>>
>>> ?>> ?>>> I attach three example images, where two stroked rectangles are
>>> ?>> used
>>> ?>> ?>>> as source (right) and destination (left).
>>> ?>> ?>>>
>>> ?>> ?>>> cairo.over.png shows the result of the over operator in cairo
>>> ?>> ?>>>
>>> ?>> ?>>> cairo.in.png shows the result of the in operator in cairo
>>> ?>> ?>>>
>>> ?>> ?>>> dsvg.in.png shows the result of the in operator in dsvg
>>> ?>> ?>>>
>>> ?>> ?>>>
>>> ?>> ?>>> You can see the difference between cairo.in.png and 
>>> dsvg.in.png. I
>>> ?>> ?>>> found out why I get different results:
>>> ?>> ?>>>
>>> ?>> ?>>> In dsvg implementation there is one drawing operation: Draw the
>>> ?>> ?>>> source element, as whole (fill and stroke) over the destination
>>> ?>> ?>>> element (using feComposite filter)
>>> ?>> ?>>>
>>> ?>> ?>>> In cairo implementation though there are two operations: 
>>> Apply the
>>> ?>> ?>>> fill on source and draw over the destination and then apply the
>>> ?>> ?>>> stroke and draw over the result of the previous operation.
>>> ?>> ?>>>
>>> ?>> ?>>> I'm not sure if this is intentional or not. Shouldn't the 
>>> source
>>> ?>> ?>>> element being drawn first as whole (fill and stroke with over
>>> ?>> ?>>> operator) and then apply the group operator and draw it over 
>>> the
>>> ?>> ?>>> destination? It would seem more logical that way.
>>> ?>> ?>>>
>>> ?>> ?>>>
>>> ?>> ?>>> Thanks,
>>> ?>> ?>>>
>>> ?>> ?>>> Panagiotis
>>> ?>> ?>>>
>>> ?>> ?>>>
>>> ?>> ?>>> ______________________________________________
>>> ?>> ?>>> R-devel at r-project.org mailing list
>>> ?>> ?>>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>>> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
>>>
>>> ?>> <https://stat.ethz.ch/mailman/listinfo/r-devel 
>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>> 
>>>
>>> ?>> ?>>
>>> ?>> ?>
>>> ?>
>>
> 

-- 
Dr Paul Murrell
Te Kura Tatauranga | Department of Statistics
Waipapa Taumata Rau | The University of Auckland
Private Bag 92019, Auckland 1142, New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
www.stat.auckland.ac.nz/~paul/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: dsvg.in-mod-4.svg
Type: image/svg+xml
Size: 2034 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20221004/f2475af8/attachment-0002.svg>

From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Oct  5 21:55:55 2022
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 5 Oct 2022 12:55:55 -0700
Subject: [Rd] 
 [External] Time to drop globalenv() from searches in package code?
In-Reply-To: <aea3c2f-5d61-b73-2ced-724fb8e94da@uiowa.edu>
References: <0bc42d07-d897-2807-0da2-eab959d35a2a@gmail.com>
 <bec8c037-aa79-14f3-bf78-239528dac757@uiowa.edu>
 <25381.36777.795591.36433@hornik.net>
 <aea3c2f-5d61-b73-2ced-724fb8e94da@uiowa.edu>
Message-ID: <CAFDcVCS=euEjcCruXwrQ4UW6xpPYpOPteBt80SMNX5WD49u2ug@mail.gmail.com>

Excluding the global environment, and all its parent environments from
the search path that a package sees would be great news, because it
would makes things more robust and probably detect a few more bugs out
there.  In addition to the use case that Duncan mentions, it would
also remove the ambiguity that comes from searching attached packages
for global/free variables.

Speaking of the latter, isn't it time to escalate the following to a WARNING?

* checking R code for possible problems ... NOTE
my_fcn: no visible global function definition for ?var?
Undefined global functions or variables:
  var
Consider adding
  importFrom("stats", "var")
to your NAMESPACE file.

There are several package on Bioconductor with such mistakes, and I
can imagine there are still some old CRAN package too that haven't
gone from "recent" CRAN incoming checks. The problem here is that the
intended `var` can be overridden in the global environment, in a
third-party attached package, or in any other environment on the
search() path.

Regarding:

> if (require("foo"))
>    bar(...)
>
> with bar exported from foo. I don't know if that is already warned
> about.  Moving away from this is arguably good in principle but also
> probably fairly disruptive.

This should be coved by 'R CMD check', also without --as-cran; if we use:

hello <- function() {
  msg <- "Hello world!"
  if (require("tools")) msg <- toTitleCase(msg)
  message(msg)
}

we get:

* checking dependencies in R code ... NOTE
'library' or 'require' call to ?tools? in package code.
  Please use :: or requireNamespace() instead.
  See section 'Suggested packages' in the 'Writing R Extensions' manual.?
...
* checking R code for possible problems ... NOTE
hello: no visible global function definition for ?toTitleCase?
Undefined global functions or variables:
  toTitleCase

This should be enough for a package developer to figure out that the
function should be implemented as:

hello <- function() {
  msg <- "Hello world!"
  if (requireNamespace("tools")) msg <- tools::toTitleCase(msg)
  message(msg)
}

which passes 'R CMD check' with all OK.


BTW, is there a reason why one cannot import from the 'base' package?
If we add, say, importFrom(base, mean) to a package's NAMESPACE file,
the package builds fine, but fails to install;

$ R --vanilla CMD INSTALL teeny_0.1.0.tar.gz
* installing to library ?/home/hb/R/x86_64-pc-linux-gnu-library/4.2-CBI-gcc9?
* installing *source* package ?teeny? ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
Error in asNamespace(ns, base.OK = FALSE) :
  operation not allowed on base namespace
Calls: <Anonymous> ... namespaceImportFrom -> importIntoEnv ->
getNamespaceInfo -> asNamespace
Execution halted
ERROR: lazy loading failed for package ?teeny?

Is this by design (e.g. more flexibility in maintaining the base-R
packages), or due to a technical limitation (e.g. the 'base' package
is not fully loaded at this point)?

/Henrik

On Sat, Sep 17, 2022 at 1:24 PM <luke-tierney at uiowa.edu> wrote:
>
> On Sat, 17 Sep 2022, Kurt Hornik wrote:
>
> >>>>>> luke-tierney  writes:
> >
> >> On Thu, 15 Sep 2022, Duncan Murdoch wrote:
> >>> The author of this Stackoverflow question
> >>> https://stackoverflow.com/q/73722496/2554330 got confused because a typo in
> >>> his code didn't trigger an error in normal circumstances, but it did when he
> >>> ran his code in pkgdown.
> >>>
> >>> The typo was to use "x" in a test, when the local variable was named ".x".
> >>> There was no "x" defined locally or in the package or its imports, so the
> >>> search got all the way to the global environment and found one.  (The very
> >>> confusing part for this user was that it found the right variable.)
> >>>
> >>> This author had suppressed the "R CMD check" check for use of global
> >>> variables.  Obviously he shouldn't have done that, but he's working with
> >>> tidyverse NSE, and that causes so many false positives that it is somewhat
> >>> understandable he would suppress one too many.
> >>>
> >>> The pkgdown simulation of code in examples doesn't do perfect mimicry of
> >>> running it at top level; the fake global environment never makes it onto the
> >>> search list.  Some might call this a bug, but I'd call it the right search
> >>> strategy.
> >>>
> >>> My suggestion is that the search for variables in package code should never
> >>> get to globalenv().  The chain of environments should stop after handling the
> >>> imports.  (Probably base package functions should also be implicitly
> >>> imported, but nothing else.)
> >>>
> >
> >> This was considered and discussed when I added namespaces. Basically
> >> it would mean making the parent of the base namespace environment be
> >> the empty environment instead of the global environment. As a design
> >> this is cleaner, and it would be a one-line change in eval.c.  But
> >> there were technical reasons this was not a viable option at the time,
> >> also a few political reasons. The technical reasons mostly had to do
> >> with S3 dispatch.
> >
> >> Changes over the years, mostly from work Kurt has done, to S3 dispatch
> >> for methods defined and registered in packages might make this more
> >> viable in principle, but there would still be a lot of existing code
> >> that would stop working. For example, 'make check' with the one-line
> >> change fails in a base example that defines an S3 method. It might be
> >> possible to fiddle with the dispatch to keep most of that code
> >> working, but I suspect that would be a lot of work. Seeing what it
> >> would take to get 'make check' to succeed would be a first step if
> >> anyone wants to take a crack at it.
> >
> > Luke,
> >
> > Can you please share the one-line change so that I can take a closer
> > look?
>
> Index: src/main/envir.c
> ===================================================================
> --- src/main/envir.c    (revision 82861)
> +++ src/main/envir.c    (working copy)
> @@ -683,7 +683,7 @@
>       R_GlobalCachePreserve = CONS(R_GlobalCache, R_NilValue);
>       R_PreserveObject(R_GlobalCachePreserve);
>   #endif
> -    R_BaseNamespace = NewEnvironment(R_NilValue, R_NilValue, R_GlobalEnv);
> +    R_BaseNamespace = NewEnvironment(R_NilValue, R_NilValue, R_EmptyEnv);
>       R_PreserveObject(R_BaseNamespace);
>       SET_SYMVALUE(install(".BaseNamespaceEnv"), R_BaseNamespace);
>       R_BaseNamespaceName = ScalarString(mkChar("base"));
>
> -----
>
> For S3 the dispatch will have to be changed to explicitly search
> .GlobalEnv and parents after the namespace if we don't want to break
> too much.
>
> Another idiom that will be broken is
>
> if (require("foo"))
>     bar(...)
>
> with bar exported from foo. I don't know if that is already warned
> about.  Moving away from this is arguably good in principle but also
> probably fairly disruptive. We might need to add some cleaner
> use-if-available mechanism, or maybe just adjust some checking code.
>
> Best,
>
> luke
>
> >
> > Best
> > -k
> >
> >>> I suspect this change would reveal errors in lots of packages, but the number
> >>> of legitimate uses of the current search strategy has got to be pretty small
> >>> nowadays, since we've been getting warnings for years about implicit imports
> >>> from other standard packages.
> >
> >> Your definition of 'legitimate' is probably quite similar to mine, but
> >> there is likely to be a small but vocal minority with very different
> >> views :-).
> >
> >> Best,
> >
> >> luke
> >
> >>> Duncan Murdoch
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >
> >> --
> >> Luke Tierney
> >> Ralph E. Wareham Professor of Mathematical Sciences
> >> University of Iowa                  Phone:             319-335-3386
> >> Department of Statistics and        Fax:               319-335-3017
> >>     Actuarial Science
> >> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> >> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> >
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



From d@v|@ @end|ng |rom r@tud|o@com  Wed Oct  5 23:04:11 2022
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Wed, 5 Oct 2022 17:04:11 -0400
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
Message-ID: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>

Hi all,

I think I have discovered a bug in the conversion from POSIXlt to Date that
has been introduced in r-devel.

It affects lubridate, but surprisingly didn't cause test failures there.
Instead it caused test failures in users of lubridate, like slider, arrow,
and admiral (see https://github.com/tidyverse/lubridate/issues/1069), and
at least in slider I have been asked by CRAN to correct this issue before
2022-10-16.

In r-devel we get the following:

```
data <- list(
  sec = 0,
  min = 0L,
  hour = 0L,
  mday = 31L,
  mon = c(0L, NA, 2L),
  year = 113L,
  wday = 4L,
  yday = 30L,
  isdst = 0L
)

x <- .POSIXlt(xx = data, tz = "UTC")
x
#> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"

# Looks right
as.POSIXct(x)
#> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"

# Weird, where is the `NA`?
as.Date(x)
#> [1] "2013-01-31" "1970-01-01" "2013-03-31"
```

The POSIXlt object is length 3, but is only partially filled out. The other
elements are all recycled to length 3 upon conversion to POSIXct or Date.
But when converting to Date, we lose the `NA` value. I think the
`as.Date()` conversion seems inconsistent with the `as.POSIXct()`
conversion.

It looks like this comes up because the conversion to Date now defaults to
using `sec` if any of the date-like fields are `NA_INTEGER`, but this means
the `NA` in the `mon` field is ignored.
https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/main/datetime.c#L1293-L1295

Thanks all,
Davis Vaughan

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct  6 10:15:29 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 6 Oct 2022 10:15:29 +0200
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
Message-ID: <25406.36513.13316.676488@stat.math.ethz.ch>

>>>>> Davis Vaughan 
>>>>>     on Wed, 5 Oct 2022 17:04:11 -0400 writes:

    > Hi all,

    > I think I have discovered a bug in the conversion from POSIXlt to Date that
    > has been introduced in r-devel.

    > It affects lubridate, but surprisingly didn't cause test failures there.
    > Instead it caused test failures in users of lubridate, like slider, arrow,
    > and admiral (see https://github.com/tidyverse/lubridate/issues/1069), and
    > at least in slider I have been asked by CRAN to correct this issue before
    > 2022-10-16.

    > In r-devel we get the following:

    > ```
    > data <- list(
    > sec = 0,
    > min = 0L,
    > hour = 0L,
    > mday = 31L,
    > mon = c(0L, NA, 2L),
    > year = 113L,
    > wday = 4L,
    > yday = 30L,
    > isdst = 0L
    > )

    > x <- .POSIXlt(xx = data, tz = "UTC")
    > x
    > #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"

    > # Looks right
    > as.POSIXct(x)
    > #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"



    > # Weird, where is the `NA`?
    > as.Date(x)
    > #> [1] "2013-01-31" "1970-01-01" "2013-03-31"
    > ```

I agree that the above is wrong, i.e., a bug in current  R-devel.

    > The POSIXlt object is length 3, but is only partially filled out. 

    > The other elements are all recycled to length 3 upon
    > conversion to POSIXct or Date. 

    > But when converting to Date, we lose the `NA` value. I think the
    > `as.Date()` conversion seems inconsistent with the `as.POSIXct()`
    > conversion.

Yes.  There was another very much relatd conversation here on R-devel,
initiated by Suharto Anggono just a few days ago.

This subject, i.e., "partially filled out" POSIXlt objects, was
one of the topics, too.

See my reply there, notably at the end:

  https://stat.ethz.ch/pipermail/r-devel/2022-October/082072.html
    
I do mention that "recycling" of partially filled POSIXlt
objects has only partially been implemented in R more generally
and was actually asking for comments and further discussion.


    > It looks like this comes up because the conversion to Date now defaults to
    > using `sec` if any of the date-like fields are `NA_INTEGER`,

yes, because only that allows to also deal with +/- Inf  etc,
as was recently added as new feature, see the NEWS of R 4.2.0

    ? Not strictly fixing a bug, format()ing and print()ing of
      non-finite Date and POSIXt values NaN and +/-Inf no longer show
      as NA but the respective string, e.g., Inf, for consistency with
      numeric vector's behaviour, fulfilling the wish of PR#18308.

i.e., see also R's bugzilla
      https://bugs.r-project.org/show_bug.cgi?id=18308

which actually *also* mentioned an NA problem in Date/Time objects.



    >  but this means  the `NA` in the `mon` field is ignored.

which I agree is bogous and we'll fix.

Still, I did not get any feedback on asking about documentation
etc on  POSIXlt objects ... and I *had* mentioned I agreed that
the current partial implementation of  "partially filled" i.e. recycling of
POSIXlt components should probably be made part of the
"definition" of POSIXlt.

Have I overlooked an existing definition / contract about these?

Martin

--
Martin M?chler
ETH Zurich   and  R Core team


From berw|n@tur|@ch @end|ng |rom gm@||@com  Thu Oct  6 10:41:46 2022
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Thu, 6 Oct 2022 16:41:46 +0800
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <25406.36513.13316.676488@stat.math.ethz.ch>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
Message-ID: <20221006164146.39f9b8e4@ECM-DTC-716.uniwa.uwa.edu.au>

G'day all,

On Thu, 6 Oct 2022 10:15:29 +0200
Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> >>>>> Davis Vaughan 
> >>>>>     on Wed, 5 Oct 2022 17:04:11 -0400 writes:  

>     > # Weird, where is the `NA`?
>     > as.Date(x)  
>     > #> [1] "2013-01-31" "1970-01-01" "2013-03-31"  
>     > ```  
> 
> I agree that the above is wrong, i.e., a bug in current  R-devel.

I have no intention of hijacking this thread, but I wonder whether this
is a good opportunity to mention that the 32 bit build of R-devel falls
over on my machine since 25 September.  It fails one of the regression
tests in reg-tests-1d.R.  The final lines of reg-tests-1d.Rout.fail
are:

> tools::Rd2txt(rd, out <- textConnection(NULL, "w"), fragment = TRUE)
> stopifnot(any(as.character(rd) != "\n"),
+           identical(textConnectionValue(out)[2L], "LaTeX"));
close(out)
> ## empty output in R <= 4.2.x
> 
> 
> ## as.POSIXlt(<very large Date>)  gave integer overflow
> stopifnot(as.POSIXlt(.Date(2^31 + 10))$year == 5879680L)
Error: as.POSIXlt(.Date(2^31 + 10))$year == 5879680L is not TRUE
Execution halted


I should have reported this earlier, but somehow did not find the time
to do so.  So I thought I mention it here. :)

Cheers,

	Berwin


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Thu Oct  6 12:20:38 2022
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Thu, 6 Oct 2022 10:20:38 +0000 (UTC)
Subject: [Rd] as.character.POSIXt in R devel
In-Reply-To: <25403.5320.335656.447541@stat.math.ethz.ch>
References: <1454067819.3486826.1664700170912.ref@mail.yahoo.com>
 <1454067819.3486826.1664700170912@mail.yahoo.com>
 <25402.55696.329918.913605@stat.math.ethz.ch>
 <25403.5320.335656.447541@stat.math.ethz.ch>
Message-ID: <1498226502.5494920.1665051638960@mail.yahoo.com>

In?'as.character.POSIXt'?in?R?devel?after?r83010:
????????????if(getOption("OutDec")?!=?OutDec)?{?op?<-?options(OutDec?=?OutDec);?on.exit(op)?}

on.exit(op)
does?nothing.?It?should?be
on.exit(options(op))


Is?it?OK?to?output?the?seconds?using?scientific?notation?
Example?(modified?from?https://bugs.r-project.org/show_bug.cgi?id=9819):
op?<-?options(scipen?=?0)?#?(default?setting)
as.character(as.POSIXlt("2007-07-27?16:11:00.000002"))
#?"2007-07-27?16:11:02e-06"
options(op)


Example (modified from https://bugs.r-project.org/show_bug.cgi?id=14579):
op?<-?options(scipen?=?0)?#?(default?setting)
ct <- as.POSIXct(1302811200 - 2e-07,
origin = as.POSIXct("1970-01-01 00:00:00", tz="UTC"), tz = "UTC")
as.character(ct) # outputs "60" for seconds
# "2011-04-14 19:59:60"
options(op)


(CharleMagne.crowned?<-?as.POSIXlt(ISOdate(774,7,10)))
as.character(CharleMagne.crowned)

As?I?mentioned,?they?are?different?on?OSes?_other?than_?Linux.

In?R?on?Windows:
>?(CharleMagne.crowned?<-?as.POSIXlt(ISOdate(774,7,10)))
[1]?"0774-07-10?12:00:00?GMT"


-----------------------
On?Monday,?3?October?2022,?11:58:53?pm?GMT+7,?Martin?Maechler?<maechler at stat.math.ethz.ch>?wrote:


>>>>>?Martin?Maechler
>>>>>????on?Mon,?3?Oct?2022?14:46:08?+0200?writes:

>>>>>?Suharto?Anggono?Suharto?Anggono?via?R-devel
>>>>>????on?Sun,?2?Oct?2022?08:42:50?+0000?(UTC)?writes:

????>>?With?r82904,?'as.character.POSIXt'?in?R?devel?is?changed.?The?NEWS?item:

????>>?as.character(<POSIXt>)?now?behaves?more?in?line?with?the
????>>?methods?for?atomic?vectors?such?as?numbers,?and?is?no?longer
????>>?influenced?by?options().

[..............]

????>>?*?Wrong:

????>>?The?result?is?wrong?when?as.character(fs[n0])?has?scientific?notation.

????>?yes,?you?are?right.??This?is?a?lapsus?I?will?fix.

????>>?Example?(modified?from?https://bugs.r-project.org/show_bug.cgi?id=9819):
????>>?op?<-?options(scipen?=?0,?OutDec?=?".")?#?(default?setting)
????>>?x?<-?as.POSIXlt("2007-07-27?16:11:03.000002")
????>>?as.character(x)
????>>?#?"2007-07-27?16:11:03.99999999983547e-06"
????>>?as.character(x$sec?-?trunc(x$sec))
????>>?#?"1.99999999983547e-06"
????>>?options(op)

????>>?'as.character.POSIXt'?could?temporarily?set?option?'scipen'?large?enough?to?prevent?scientific?notation?in?as.character(fs[n0])?.

????>?Yes,?something?like?that.

I?have?committed?a?version?now?of?datetime.R,??svn?rev?83010?,
which?does?no?longer?depend?on??'OutDec'?(but?gets?such?argument)
and?which?has?a?new?'digits'?argument?which?defaults
to?14?for?POSIXlt?and
to??6?for?POSIXct??..?but?the?user?can?choose?a?different?value.

Also,?it?now?uses?the?equivalent?of??as.character(round(x$sec,?digits))
(in?case?the?seconds?need?to?be?shown)??which?also?solves?the
following??"too?much?precision"??problem.

????>>?*?Too?much?precision:

????>>?In?some?cases?with?fractional?seconds?with?seconds?close?to?60,?the?result?has?many?decimal?places?while?there?is?an?accurate?representation?with?less?decimal?places.?It?is?actually?OK,?just?unpleasant.

????>?I?agree?that?is?unpleasant.
????>?To?someone?else?I?had?written?that?we?also?may?need?to?improve
????>?the?number?of?decimals?shown?here.
????>?The?design?has?been?that?it?should?be?"full?precision"
????>?as?it?is?for??as.character(<numbers>)

????>?Now,?we?know?that?POSIXct?cannot?be?very?precise?(in?its
????>?fractional?seconds)?but?that?is?very?different?for?POSIXlt?where
????>?fractional?seconds?may?have?14?digits?after?the?decimal?point.

????>?Ideally?we?could?*store*?with?the?POSIXlt?object?if?it?was
????>?produced?from?a?POSIXct?one,?and?hence?have?only?around?6?valid?digits
????>?(after?the?dec.)?or?not.??As?we?cannot?currently?store/save?that
????>?info,?we?kept?using?"full"?precision?which?may?be?much?more?than
????>?is?sensible.

????>>?Example?(modified?from?https://bugs.r-project.org/show_bug.cgi?id=14693):
????>>?op?<-?options(scipen?=?0,?OutDec?=?".")?#?(default?setting)
????>>?x?<-?as.POSIXlt("2011-10-01?12:34:56.3")
????>>?x$sec?==?56.3?#?TRUE

????>?[which?may?be?typical,?but?may?also?be?platform?dependent]

????>>?print(x$sec,?17)
????>>?#?[1]?56.299999999999997
????>>?as.character(x)
????>>?#?"2011-10-01?12:34:56.299999999999997"
????>>?format(x,?"%Y-%m-%d?%H:%M:%OS1")?#?short?and?accurate
????>>?#?"2011-10-01?12:34:56.3"
????>>?ct?<-?as.POSIXct(x,?tz?=?"UTC")
????>>?identical(ct,
????>>?as.POSIXct("2011-10-01?12:34:56.3",?tz?=?"UTC"))
????>>?#?TRUE
????>>?print(as.numeric(ct),?17)
????>>?#?[1]?1317472496.3
????>>?lct?<-?as.POSIXlt(ct)
????>>?lct$sec?==?56.3?#?FALSE
????>>?print(lct$sec,?17)
????>>?#?[1]?56.299999952316284
????>>?as.character(ct)
????>>?#?"2011-10-01?12:34:56.299999952316284"
????>>?options(op)

????>>?The?"POSIXct"?case?is?a?little?different?because?some?precision?is?already?lost?after?converted?to?"POSIXct".

????>?yes,?indeed.

????>>?In?'as.character.POSIXt',?using?'as.character'?on?the?seconds?(not?separating?the?fractional?part)?might?be?good?enough,?but?a?leading?zero?must?be?added?as?necessary.

????>?I?think?you?are?right:?that?may?definitely?better...

indeed;?part?of?my?commit.

????>>?*?Different?from?'format':

????>>?-?With?fractional?seconds,?the?result?is?influenced?by?option?'OutDec'.

this?has?been?solved,?too.
For?the?"freaks"?allowing?an?explicit??'OutDec?=?*'?argument
but?*not*?with?default?depending?on?options()!


????>?Thank?you.??I?was?not?aware?of?that.
????>?The?reason?"of?course"?being?that??as.character(<numeric>)??is
????>?*also*?depending?on?option??OutDec.

????>?I?would?say?that?is?clearly?wrong...??and?I?think?we?should
????>?strongl?consider?to?change?that:

????>?'OutDec'?should?influence?print()ing?and?format()ing??but?should
????>?*not*?influence??as.character()??at?least?not?for?basic?R?types/objects.


????>>?-?From?"Printing?years"?in??strptime:?"For?years?0?to?999?most?OSes?pad?with?zeros?or?spaces?to?4?characters,?and?Linux?outputs?just?the?number."
????>>?Because?(1900?+?x$year)?is?formatted?with?%d?in?'as.character.POSIXt',?years?0?to?999?is?output?without?padding.?It?is?different?from?'format'?in?OSes?other?than?Linux.

????>?Good?point.??This?should?be??amended.

Not?yet.??Actually,?I'm?no?longer?sure?this?needs?any?action.
I?find?it?somewhat?natural?that

>?(CharleMagne.crowned?<-?as.POSIXlt(ISOdate(774,7,10)))
[1]?"774-07-10?12:00:00?GMT"
>?as.character(CharleMagne.crowned)
[1]?"774-07-10?12:00:00"


[snip]


From r|p|ey @end|ng |rom @t@t@@ox@@c@uk  Thu Oct  6 14:38:38 2022
From: r|p|ey @end|ng |rom @t@t@@ox@@c@uk (Prof Brian Ripley)
Date: Thu, 6 Oct 2022 13:38:38 +0100
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <20221006164146.39f9b8e4@ECM-DTC-716.uniwa.uwa.edu.au>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
 <20221006164146.39f9b8e4@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <df276af2-5024-05dd-1ccb-96ffbf6e980b@stats.ox.ac.uk>

On 06/10/2022 09:41, Berwin A Turlach wrote:
> G'day all,
> 
> On Thu, 6 Oct 2022 10:15:29 +0200
> Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>>> Davis Vaughan
>>>>>>>      on Wed, 5 Oct 2022 17:04:11 -0400 writes:
> 
>>      > # Weird, where is the `NA`?
>>      > as.Date(x)
>>      > #> [1] "2013-01-31" "1970-01-01" "2013-03-31"
>>      > ```
>>
>> I agree that the above is wrong, i.e., a bug in current  R-devel.
> 
> I have no intention of hijacking this thread, but I wonder whether this
> is a good opportunity to mention that the 32 bit build of R-devel falls
> over on my machine since 25 September.  It fails one of the regression
> tests in reg-tests-1d.R.  The final lines of reg-tests-1d.Rout.fail
> are:
> 
>> tools::Rd2txt(rd, out <- textConnection(NULL, "w"), fragment = TRUE)
>> stopifnot(any(as.character(rd) != "\n"),
> +           identical(textConnectionValue(out)[2L], "LaTeX"));
> close(out)
>> ## empty output in R <= 4.2.x

Yes, known for a few days on the R-core list. I am in the middle of an 
OS upgrade on that machine and won't have time to do more than report 
until that (and all the re-building and re-checking) is complete.

>> ## as.POSIXlt(<very large Date>)  gave integer overflow
>> stopifnot(as.POSIXlt(.Date(2^31 + 10))$year == 5879680L)
> Error: as.POSIXlt(.Date(2^31 + 10))$year == 5879680L is not TRUE
> Execution halted
> 
> 
> I should have reported this earlier, but somehow did not find the time
> to do so.  So I thought I mention it here. :)
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From d@v|@ @end|ng |rom r@tud|o@com  Thu Oct  6 15:33:27 2022
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Thu, 6 Oct 2022 09:33:27 -0400
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
Message-ID: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>

Hi all,

I have found another POSIXlt bug while I've been fiddling around with it.
This one only appears on specific OSes, because it has to do with the fact
that the `gmtoff` field is optional, and isn't always used on all OSes. It
also doesn't seem to be specific to r-devel, I think it has been there
awhile.

Here is the bug:

```
x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

# Oh no!
x[1] <- NA
#> Error in x[[n]][i] <- value[[n]] : replacement has length zero
```

If you look at the objects, you can see that `x` has a `gmtoff` field, but
`NA` (when converted to POSIXlt, which is what `[<-.POSIXlt` does) does not:

```
unclass(x)
#> $sec
#> [1] 0
#>
#> $min
#> [1] 0
#>
#> $hour
#> [1] 0
#>
#> $mday
#> [1] 31
#>
#> $mon
#> [1] 0
#>
#> $year
#> [1] 113
#>
#> $wday
#> [1] 4
#>
#> $yday
#> [1] 30
#>
#> $isdst
#> [1] 0
#>
#> $zone
#> [1] "CST"
#>
#> $gmtoff
#> [1] -21600
#>
#> attr(,"tzone")
#> [1] "America/Chicago" "CST"             "CDT"

unclass(as.POSIXlt(NA))
#> $sec
#> [1] NA
#>
#> $min
#> [1] NA
#>
#> $hour
#> [1] NA
#>
#> $mday
#> [1] NA
#>
#> $mon
#> [1] NA
#>
#> $year
#> [1] NA
#>
#> $wday
#> [1] NA
#>
#> $yday
#> [1] NA
#>
#> $isdst
#> [1] -1
#>
#> attr(,"tzone")
#> [1] "UTC"
```

The problem seems to be that `[<-.POSIXlt` assumes that if the field was
there in `x` then it must also be there in `value`:
https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/library/base/R/datetime.R#L1303-L1304

But this isn't the case for the `NA` value that was converted to POSIXlt.

I can't reproduce this on my personal Mac, but it affects the Linux, Mac,
and Windows machines we use for the lubridate CI checks through GitHub
Actions.

Thanks,
Davis

	[[alternative HTML version deleted]]


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Fri Oct  7 11:35:22 2022
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Fri, 7 Oct 2022 09:35:22 +0000 (UTC)
Subject: [Rd] as.character.POSIXt in R devel
In-Reply-To: <25403.5320.335656.447541@stat.math.ethz.ch>
References: <1454067819.3486826.1664700170912.ref@mail.yahoo.com>
 <1454067819.3486826.1664700170912@mail.yahoo.com>
 <25402.55696.329918.913605@stat.math.ethz.ch>
 <25403.5320.335656.447541@stat.math.ethz.ch>
Message-ID: <1924407454.6024655.1665135322197@mail.yahoo.com>

 Yes, no documentation.
"POSIXlt" object with out-of-bounds components or whose components are not all of the same length may be produced internally by 'seq.POSIXt'.
Initially, 'r1' is a "POSIXlt" object whose all components have length 1.
Component 'year', 'mon', or 'mday' of 'r1' is then modified. It may have more than one elements. For 'mon' or 'mday', some may be out-of-bounds.


----------------------------
On Monday, 3 October 2022, 11:58:53 pm GMT+7, Martin Maechler <maechler at stat.math.ethz.ch> wrote:


>>>>> Martin Maechler
>>>>>? ? on Mon, 3 Oct 2022 14:46:08 +0200 writes:

>>>>> Suharto Anggono Suharto Anggono via R-devel
>>>>>? ? on Sun, 2 Oct 2022 08:42:50 +0000 (UTC) writes:

? ? >> With r82904, 'as.character.POSIXt' in R devel is changed. The NEWS item:

? ? >> as.character(<POSIXt>) now behaves more in line with the
? ? >> methods for atomic vectors such as numbers, and is no longer
? ? >> influenced by options().

[..............]

[snip]


? ? >> * Behavior with "improper" "POSIXlt" object:

? ? >> - "POSIXlt" object with out-of-bounds components is not normalized.

? ? >> Example (modified from regr.tests-1d.R):
? ? >> op <- options(scipen = 0) # (default setting)
? ? >> x <- structure(
? ? >> list(sec = 10000, min = 59L, hour = 18L,
? ? >> mday = 6L, mon = 11L, year = 116L,
? ? >> wday = 2L, yday = 340L,
? ? >> isdst = 0L, zone = "CET", gmtoff = 3600L),
? ? >> class = c("POSIXlt", "POSIXt"), tzone = "CET")
? ? >> as.character(x)
? ? >> # "2016-12-06 18:59:10000"
? ? >> format(x)
? ? >> # "2016-12-06 21:45:40"
? ? >> options(op)


? ? > Yes, we knew that? and were not too happy about it, but also not
? ? > too unhappy:
? ? > After all,??? ??? ? ? help(DateTimeClasses)
? ? > clearly explains how
? ? > POSIXlt objects should look like :

? ? > -------------------------------------------------------------------
? ? > Class ?"POSIXlt"? is a named list of vectors representing

? ? > ?sec? 0-61: seconds.
? ? > ?min? 0-59: minutes.
? ? > ?hour? 0-23: hours.
? ? > ?mday? 1-31: day of the month
? ? > ?mon? 0-11: months after the first of the year.
? ? > ?year? years since 1900.
? ? > ?wday? 0-6 day of the week, starting on Sunday.
? ? > ?yday? 0-365: day of the year (365 only in leap years).

? ? > ?isdst? Daylight Saving Time ... ... ...
? ? > ................................
? ? > ................................

? ? > -------------------------------------------------------------------

? ? > We have been aware that as.character() assumes the above specification,
? ? > even though other R functions, notably format() which uses
? ? > internal (C level; either system (OS) or R's own) strptime() do
? ? > arithmetic (modulo 60, then modulo 24, then modulo month length)
? ? > to compute the date "used".

? ? > Allowing such? "un-normalized" / out-of-bound? POSIXlt objects
? ? > in R has not been documented AFAICS, and has the consequence
? ? > that two different POSIXlt objects may correspond to the exact
? ? > same time.

? ? > This may be something worth discussing.
? ? > In some sense we are discussing how the "POSIXlt" class is defined
? ? > (even though an S3 class is never formally defined).

(nothing changed here)


? ? >> - With "POSIXlt" object where sec, min, hour, mday, mon,
? ? >> and year components are not all of the same length, recycling is not handled.

This is still the case... (see below).

? ? > Good point.? I tend to agree that this should be improved *and* also
? ? > documented: AFAIK, it is also not at all documented? (or is it ??)
? ? > that the POSIXlt components should be thought to be recycling.

? ? > If we decide we want that,
? ? > once this is documented (and all methods/functions tested with
? ? > such POSIXlt) it could also be used to use considerably smaller size
? ? > POSIXlt objects, e.g, when all parts are in the same year, or
? ? > when all seconds are 0, or ...

? ? >> Example (modified from regr.tests-1d.R):
? ? >> op <- options(scipen = 0) # (default setting)
? ? >> x <- structure(
? ? >> list(sec = c(1,? 2), min = 59L, hour = 18L,
? ? >> mday = 6L, mon = 11L, year = 116L,
? ? >> wday = 2L, yday = 340L,
? ? >> isdst = 0L, zone = "CET", gmtoff = 3600L),
? ? >> class = c("POSIXlt", "POSIXt"), tzone = "CET")
? ? >> as.character(x)
? ? >> # c("2016-12-06 18:59:01", "NA NA:NA:02")
? ? >> format(x)
? ? >> # c("2016-12-06 18:59:01", "2016-12-06 18:59:02")
? ? >> options(op)

Note that currently such {needing recycling} - cases are
*also* not handled by the simple? (and important!)? length.POSIXlt()
method, either:? It currently only looks at the '.$sec'
component !

So this case does need discussion two.
I think it's unfortunate that *some* *.POSIXt methods do such
recycling, e.g. format.POSIXt,
but others do not {and the documentation does not even mention recycling}.

As mentioned, I am *pro* going in that direction;
so I would change

? length.POSIXlt <- function(x) length(unclass(x)[[1L]])

? ? ? (which only uses x$sec !)

to

? length.POSIXlt <- function(x) max(lengths(unclass(x), use.names=FALSE))

not allowing 0-length recycling; 0-lengths components
should really be illegal in an otherwise non-0-length POSIXlt x



Martin  
	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Oct  7 14:52:01 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 7 Oct 2022 14:52:01 +0200
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <25406.36513.13316.676488@stat.math.ethz.ch>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
Message-ID: <25408.8433.260821.451226@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Thu, 6 Oct 2022 10:15:29 +0200 writes:

>>>>> Davis Vaughan 
>>>>>     on Wed, 5 Oct 2022 17:04:11 -0400 writes:

    >> Hi all,

    >> I think I have discovered a bug in the conversion from POSIXlt to Date that
    >> has been introduced in r-devel.

    >> It affects lubridate, but surprisingly didn't cause test failures there.
    >> Instead it caused test failures in users of lubridate, like slider, arrow,
    >> and admiral (see https://github.com/tidyverse/lubridate/issues/1069), and
    >> at least in slider I have been asked by CRAN to correct this issue before
    >> 2022-10-16.

    >> In r-devel we get the following:

    >> ```
    >> data <- list(
    >> sec = 0,
    >> min = 0L,
    >> hour = 0L,
    >> mday = 31L,
    >> mon = c(0L, NA, 2L),
    >> year = 113L,
    >> wday = 4L,
    >> yday = 30L,
    >> isdst = 0L
    >> )

    >> x <- .POSIXlt(xx = data, tz = "UTC")
    >> x
    >> #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"

    >> # Looks right
    >> as.POSIXct(x)
    >> #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"



    >> # Weird, where is the `NA`?
    >> as.Date(x)
    >> #> [1] "2013-01-31" "1970-01-01" "2013-03-31"
    >> ```

    > I agree that the above is wrong, i.e., a bug in current  R-devel.

    >> The POSIXlt object is length 3, but is only partially filled out. 

    >> The other elements are all recycled to length 3 upon
    >> conversion to POSIXct or Date. 

    >> But when converting to Date, we lose the `NA` value. I think the
    >> `as.Date()` conversion seems inconsistent with the `as.POSIXct()`
    >> conversion.

    > Yes.  There was another very much relatd conversation here on R-devel,
    > initiated by Suharto Anggono just a few days ago.

    > This subject, i.e., "partially filled out" POSIXlt objects, was
    > one of the topics, too.

    > See my reply there, notably at the end:

    > https://stat.ethz.ch/pipermail/r-devel/2022-October/082072.html
    
    > I do mention that "recycling" of partially filled POSIXlt
    > objects has only partially been implemented in R more generally
    > and was actually asking for comments and further discussion.


    >> It looks like this comes up because the conversion to Date now defaults to
    >> using `sec` if any of the date-like fields are `NA_INTEGER`,

    > yes, because only that allows to also deal with +/- Inf  etc,
    > as was recently added as new feature, see the NEWS of R 4.2.0

    > ? Not strictly fixing a bug, format()ing and print()ing of
    > non-finite Date and POSIXt values NaN and +/-Inf no longer show
    > as NA but the respective string, e.g., Inf, for consistency with
    > numeric vector's behaviour, fulfilling the wish of PR#18308.

    > i.e., see also R's bugzilla
    > https://bugs.r-project.org/show_bug.cgi?id=18308

    > which actually *also* mentioned an NA problem in Date/Time objects.


    >> but this means  the `NA` in the `mon` field is ignored.

    > which I agree is bogous and we'll fix.

    > Still, I did not get any feedback on asking about documentation
    > etc on  POSIXlt objects ... and I *had* mentioned I agreed that
    > the current partial implementation of  "partially filled" i.e. recycling of
    > POSIXlt components should probably be made part of the
    > "definition" of POSIXlt.

    > Have I overlooked an existing definition / contract about these?

    > Martin

I'm still waiting for comments.

Note that  "partially filled" POSIXlt do not work correctly in
any version of R.  I mentioned that even length(.) may easily
fail; but there is much more.

While I can relatively easily fix Davis' case above,
the following example behaves wrongly in current and previous
released versions of R and in R-devel:

dlt <- .POSIXlt(list(sec = c(-999, 10000 + c(1:10,-Inf, NA)) + pi,
                                        # "out of range", non-finite, fractions
                     min = 45L, hour = c(21L, 3L, NA, 4L),
                     mday = 6L, mon  = c(11L, NA, 3L),
                     year = 116L, wday = 2L, yday = 340L, isdst = 1L))


Of course that's constructed to be particularly unpleasant.
You can try some of the following "checks" in your version(s) of
R to see that some of the things are misbehaving with it in all (*)
versions of R.
--
*) so I claim boldly


dct <- as.POSIXct(dlt)
(n <- length(dct))
dD  <- as.Date(dlt)
dDc <- as.Date(dct)
dltN <- as.POSIXlt(dct) # "normalized POSIXlt" (with *lost* accuracy):
data.frame(unclass(dltN))
.POSIXltNormalize <- function(x) {
    stopifnot(is.numeric(s <- x$sec))
    x <- as.POSIXlt(as.POSIXct(x)) # and restore the precise seconds :
    ifin <- is.finite(s) & is.finite(x$sec) # (maybe recycling already)
    x$sec[ifin] <- s[ifin] %% 60
    x
}
dlt2 <- .POSIXltNormalize(dlt) # normalized POSIXlt - with accuracy kept
all.equal(dlt2$sec, dltN$sec, tolerance = 0) # .. small (2e-9) difference
stopifnot(all.equal(dlt2, dltN),
          identical(as.POSIXct(dlt2), as.POSIXct(dltN)))
## First show (in a way it also works for older R), then check :
oldR <- getRversion() < "4.2.2"
print(width = 101,
data.frame(dlt, dltN, asCT = dct, asDateCT = dDc,
           asDate = if(oldR) rep_len(dD,  n) else dD ,
           na = is.na(dlt),
           fin = if(oldR) rep_len(NA, n) else is.finite(dlt))
)




--
Martin M?chler
ETH Zurich   and  R Core team


From d@v|@ @end|ng |rom r@tud|o@com  Fri Oct  7 17:00:23 2022
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Fri, 7 Oct 2022 11:00:23 -0400
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <25408.8433.260821.451226@stat.math.ethz.ch>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
 <25408.8433.260821.451226@stat.math.ethz.ch>
Message-ID: <CABzLhzynMazG7dVfr+GC_3F=QDEJK+zx4AX_tz-2CdbJdYvv=w@mail.gmail.com>

Martin,

FWIW, I scoured the docs using GitHub's new code search preview but can't
seem to find any reference to the fact that POSIXlt fields are internally
recycled (even though lubridate seems to have been relying on this for
quite some time).

-Davis

On Fri, Oct 7, 2022 at 8:52 AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Martin Maechler
> >>>>>     on Thu, 6 Oct 2022 10:15:29 +0200 writes:
>
> >>>>> Davis Vaughan
> >>>>>     on Wed, 5 Oct 2022 17:04:11 -0400 writes:
>
>     >> Hi all,
>
>     >> I think I have discovered a bug in the conversion from POSIXlt to
> Date that
>     >> has been introduced in r-devel.
>
>     >> It affects lubridate, but surprisingly didn't cause test failures
> there.
>     >> Instead it caused test failures in users of lubridate, like slider,
> arrow,
>     >> and admiral (see https://github.com/tidyverse/lubridate/issues/1069),
> and
>     >> at least in slider I have been asked by CRAN to correct this issue
> before
>     >> 2022-10-16.
>
>     >> In r-devel we get the following:
>
>     >> ```
>     >> data <- list(
>     >> sec = 0,
>     >> min = 0L,
>     >> hour = 0L,
>     >> mday = 31L,
>     >> mon = c(0L, NA, 2L),
>     >> year = 113L,
>     >> wday = 4L,
>     >> yday = 30L,
>     >> isdst = 0L
>     >> )
>
>     >> x <- .POSIXlt(xx = data, tz = "UTC")
>     >> x
>     >> #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"
>
>     >> # Looks right
>     >> as.POSIXct(x)
>     >> #> [1] "2013-01-31 UTC" NA               "2013-03-31 UTC"
>
>
>
>     >> # Weird, where is the `NA`?
>     >> as.Date(x)
>     >> #> [1] "2013-01-31" "1970-01-01" "2013-03-31"
>     >> ```
>
>     > I agree that the above is wrong, i.e., a bug in current  R-devel.
>
>     >> The POSIXlt object is length 3, but is only partially filled out.
>
>     >> The other elements are all recycled to length 3 upon
>     >> conversion to POSIXct or Date.
>
>     >> But when converting to Date, we lose the `NA` value. I think the
>     >> `as.Date()` conversion seems inconsistent with the `as.POSIXct()`
>     >> conversion.
>
>     > Yes.  There was another very much relatd conversation here on
> R-devel,
>     > initiated by Suharto Anggono just a few days ago.
>
>     > This subject, i.e., "partially filled out" POSIXlt objects, was
>     > one of the topics, too.
>
>     > See my reply there, notably at the end:
>
>     > https://stat.ethz.ch/pipermail/r-devel/2022-October/082072.html
>
>     > I do mention that "recycling" of partially filled POSIXlt
>     > objects has only partially been implemented in R more generally
>     > and was actually asking for comments and further discussion.
>
>
>     >> It looks like this comes up because the conversion to Date now
> defaults to
>     >> using `sec` if any of the date-like fields are `NA_INTEGER`,
>
>     > yes, because only that allows to also deal with +/- Inf  etc,
>     > as was recently added as new feature, see the NEWS of R 4.2.0
>
>     > ? Not strictly fixing a bug, format()ing and print()ing of
>     > non-finite Date and POSIXt values NaN and +/-Inf no longer show
>     > as NA but the respective string, e.g., Inf, for consistency with
>     > numeric vector's behaviour, fulfilling the wish of PR#18308.
>
>     > i.e., see also R's bugzilla
>     > https://bugs.r-project.org/show_bug.cgi?id=18308
>
>     > which actually *also* mentioned an NA problem in Date/Time objects.
>
>
>     >> but this means  the `NA` in the `mon` field is ignored.
>
>     > which I agree is bogous and we'll fix.
>
>     > Still, I did not get any feedback on asking about documentation
>     > etc on  POSIXlt objects ... and I *had* mentioned I agreed that
>     > the current partial implementation of  "partially filled" i.e.
> recycling of
>     > POSIXlt components should probably be made part of the
>     > "definition" of POSIXlt.
>
>     > Have I overlooked an existing definition / contract about these?
>
>     > Martin
>
> I'm still waiting for comments.
>
> Note that  "partially filled" POSIXlt do not work correctly in
> any version of R.  I mentioned that even length(.) may easily
> fail; but there is much more.
>
> While I can relatively easily fix Davis' case above,
> the following example behaves wrongly in current and previous
> released versions of R and in R-devel:
>
> dlt <- .POSIXlt(list(sec = c(-999, 10000 + c(1:10,-Inf, NA)) + pi,
>                                         # "out of range", non-finite,
> fractions
>                      min = 45L, hour = c(21L, 3L, NA, 4L),
>                      mday = 6L, mon  = c(11L, NA, 3L),
>                      year = 116L, wday = 2L, yday = 340L, isdst = 1L))
>
>
> Of course that's constructed to be particularly unpleasant.
> You can try some of the following "checks" in your version(s) of
> R to see that some of the things are misbehaving with it in all (*)
> versions of R.
> --
> *) so I claim boldly
>
>
> dct <- as.POSIXct(dlt)
> (n <- length(dct))
> dD  <- as.Date(dlt)
> dDc <- as.Date(dct)
> dltN <- as.POSIXlt(dct) # "normalized POSIXlt" (with *lost* accuracy):
> data.frame(unclass(dltN))
> .POSIXltNormalize <- function(x) {
>     stopifnot(is.numeric(s <- x$sec))
>     x <- as.POSIXlt(as.POSIXct(x)) # and restore the precise seconds :
>     ifin <- is.finite(s) & is.finite(x$sec) # (maybe recycling already)
>     x$sec[ifin] <- s[ifin] %% 60
>     x
> }
> dlt2 <- .POSIXltNormalize(dlt) # normalized POSIXlt - with accuracy kept
> all.equal(dlt2$sec, dltN$sec, tolerance = 0) # .. small (2e-9) difference
> stopifnot(all.equal(dlt2, dltN),
>           identical(as.POSIXct(dlt2), as.POSIXct(dltN)))
> ## First show (in a way it also works for older R), then check :
> oldR <- getRversion() < "4.2.2"
> print(width = 101,
> data.frame(dlt, dltN, asCT = dct, asDateCT = dDc,
>            asDate = if(oldR) rep_len(dD,  n) else dD ,
>            na = is.na(dlt),
>            fin = if(oldR) rep_len(NA, n) else is.finite(dlt))
> )
>
>
>
>
> --
> Martin M?chler
> ETH Zurich   and  R Core team
>

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sun Oct  9 20:25:44 2022
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sun, 9 Oct 2022 11:25:44 -0700
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
Message-ID: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>

Rscript fails to launch if the standard input (stdin) is closed, e.g.

$ Rscript --vanilla -e 42 0<&-
Fatal error: creating temporary file for '-e' failed

This appear to only happen with `-e EXPR`, e.g. it works when doing:

$ echo "42" > script.R
$ Rscript --vanilla script.R 0<&-
[1] 42

and:

$ R --vanilla 0<&-
R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)
...
>


TROUBLESHOOTING:

$ strace Rscript --vanilla -e 42 0<&-
execve("/home/hb/shared/software/CBI/R-4.2.1-gcc9/bin/Rscript",
["Rscript", "--vanilla", "-e", "42"], 0x7fff9f476418 /* 147 vars */) =
0
brk(NULL)                               = 0x5625ca9e6000
arch_prctl(0x3001 /* ARCH_??? */, 0x7fff23b4d260) = -1 EINVAL (Invalid argument)
...
fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
write(1, "Fatal error: creating temporary "..., 53Fatal error:
creating temporary file for '-e' failed
) = 53
exit_group(2)                           = ?
+++ exited with 2 +++

which points to src/unix/system.c:

ifd = mkstemp(ifile);
if (ifd > 0)
    ifp = fdopen(ifd, "w+");
if(!ifp) R_Suicide(_("creating temporary file for '-e' failed"));


One rationale for having closed standard files (including stdin) is to
avoid leaking file descriptors, cf.
https://wiki.sei.cmu.edu/confluence/display/c/FIO22-C.+Close+files+before+spawning+processes
and https://danwalsh.livejournal.com/53603.html.  The background for
reporting on this was that `system()` fails to work in processx
spawned processes, which closes the standard files by default in
processx (<= 3.7.0).

Best,

Henrik


From pd@|gd @end|ng |rom gm@||@com  Mon Oct 10 11:07:18 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 10 Oct 2022 11:07:18 +0200
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
Message-ID: <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>

He! 

Yes, that looks like a blunder.

mkstemp() returns -1 on failure, not 0, so the test on ifd (and I suppose also the one on ifp) is wrong. And of course, once you close file descriptor 0, mkstemp() chooses the 1st available fd, i.e. 0, for its return value.

-pd

> On 9 Oct 2022, at 20:25 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> Rscript fails to launch if the standard input (stdin) is closed, e.g.
> 
> $ Rscript --vanilla -e 42 0<&-
> Fatal error: creating temporary file for '-e' failed
> 
> This appear to only happen with `-e EXPR`, e.g. it works when doing:
> 
> $ echo "42" > script.R
> $ Rscript --vanilla script.R 0<&-
> [1] 42
> 
> and:
> 
> $ R --vanilla 0<&-
> R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
> Copyright (C) 2022 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> ...
>> 
> 
> 
> TROUBLESHOOTING:
> 
> $ strace Rscript --vanilla -e 42 0<&-
> execve("/home/hb/shared/software/CBI/R-4.2.1-gcc9/bin/Rscript",
> ["Rscript", "--vanilla", "-e", "42"], 0x7fff9f476418 /* 147 vars */) =
> 0
> brk(NULL)                               = 0x5625ca9e6000
> arch_prctl(0x3001 /* ARCH_??? */, 0x7fff23b4d260) = -1 EINVAL (Invalid argument)
> ...
> fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
> write(1, "Fatal error: creating temporary "..., 53Fatal error:
> creating temporary file for '-e' failed
> ) = 53
> exit_group(2)                           = ?
> +++ exited with 2 +++
> 
> which points to src/unix/system.c:
> 
> ifd = mkstemp(ifile);
> if (ifd > 0)
>    ifp = fdopen(ifd, "w+");
> if(!ifp) R_Suicide(_("creating temporary file for '-e' failed"));
> 
> 
> One rationale for having closed standard files (including stdin) is to
> avoid leaking file descriptors, cf.
> https://wiki.sei.cmu.edu/confluence/display/c/FIO22-C.+Close+files+before+spawning+processes
> and https://danwalsh.livejournal.com/53603.html.  The background for
> reporting on this was that `system()` fails to work in processx
> spawned processes, which closes the standard files by default in
> processx (<= 3.7.0).
> 
> Best,
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Mon Oct 10 14:54:48 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 10 Oct 2022 14:54:48 +0200
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
 <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
Message-ID: <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>

It seems to work simply to do  "if (ifd >= 0)..." (the ifp test is fine since ifp is FILE* and initialized to NULL). Will commit (to r-devel for now).

-pd

> On 10 Oct 2022, at 11:07 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> He! 
> 
> Yes, that looks like a blunder.
> 
> mkstemp() returns -1 on failure, not 0, so the test on ifd (and I suppose also the one on ifp) is wrong. And of course, once you close file descriptor 0, mkstemp() chooses the 1st available fd, i.e. 0, for its return value.
> 
> -pd
> 
>> On 9 Oct 2022, at 20:25 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>> 
>> Rscript fails to launch if the standard input (stdin) is closed, e.g.
>> 
>> $ Rscript --vanilla -e 42 0<&-
>> Fatal error: creating temporary file for '-e' failed
>> 
>> This appear to only happen with `-e EXPR`, e.g. it works when doing:
>> 
>> $ echo "42" > script.R
>> $ Rscript --vanilla script.R 0<&-
>> [1] 42
>> 
>> and:
>> 
>> $ R --vanilla 0<&-
>> R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
>> Copyright (C) 2022 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> ...
>>> 
>> 
>> 
>> TROUBLESHOOTING:
>> 
>> $ strace Rscript --vanilla -e 42 0<&-
>> execve("/home/hb/shared/software/CBI/R-4.2.1-gcc9/bin/Rscript",
>> ["Rscript", "--vanilla", "-e", "42"], 0x7fff9f476418 /* 147 vars */) =
>> 0
>> brk(NULL)                               = 0x5625ca9e6000
>> arch_prctl(0x3001 /* ARCH_??? */, 0x7fff23b4d260) = -1 EINVAL (Invalid argument)
>> ...
>> fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
>> write(1, "Fatal error: creating temporary "..., 53Fatal error:
>> creating temporary file for '-e' failed
>> ) = 53
>> exit_group(2)                           = ?
>> +++ exited with 2 +++
>> 
>> which points to src/unix/system.c:
>> 
>> ifd = mkstemp(ifile);
>> if (ifd > 0)
>>   ifp = fdopen(ifd, "w+");
>> if(!ifp) R_Suicide(_("creating temporary file for '-e' failed"));
>> 
>> 
>> One rationale for having closed standard files (including stdin) is to
>> avoid leaking file descriptors, cf.
>> https://wiki.sei.cmu.edu/confluence/display/c/FIO22-C.+Close+files+before+spawning+processes
>> and https://danwalsh.livejournal.com/53603.html.  The background for
>> reporting on this was that `system()` fails to work in processx
>> spawned processes, which closes the standard files by default in
>> processx (<= 3.7.0).
>> 
>> Best,
>> 
>> Henrik
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ||oruppr @end|ng |rom gm@||@com  Mon Oct 10 16:00:59 2022
From: ||oruppr @end|ng |rom gm@||@com (Florian Rupprecht)
Date: Mon, 10 Oct 2022 16:00:59 +0200
Subject: [Rd] Pre-allocating serialization memory buffers
Message-ID: <CAHTZEhDuRURhz384S=RKwT+tH_0WfW512R3MxUxL4wP4oVxkhQ@mail.gmail.com>

Hi all,

While investigating the performance of different hashing algorithms of the
"digest" package, I found that serialization to memory buffers via
serialize(obj, connection=NULL) was suspiciously slow for large objects.

After looking into the R source I found that the memory buffer grows
approx. n -> 2(n+1) but are not pre-allocated in any way. I then created a
minimal demo package (https://github.com/nx10/serialize_prealloc) with
different modified versions of the serialization mechanisms that let me
trace memory allocations and pre-allocate the buffer using
object.size(obj).

Benchmarking this shows that there is no apparent performance decrease for
small or deeply nested objects and approx. logarithmic gains with bigger
objects (more than 3 times faster on my machine with ~1GB large objects).
Benchmarks are included in the README of the demo package.

I have not done any tests with other kinds of streams such as file
connections, as I am not sure we can make assumptions about the
implementation of streams that are created elsewhere.

I would be happy to provide a patch for review if this is something you
consider worth investigating, but I would need some pointers on how you
would want this to be implemented, as object.size lives in the utils
library and serialize is in src\main\. (E.g. copy a non-error version of
objectsize to main\)

Best,
Florian

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Oct 10 18:34:32 2022
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 10 Oct 2022 09:34:32 -0700
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
 <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
 <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>
Message-ID: <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>

Thank you Peter for the quick fix.  Will this make it into R-patched
to become R 4.2.2 soon?

I can confirm that the fix resolved also the original problem report
involving launching a parallel PSOCK cluster from within a 'processx'
background process
(https://stackoverflow.com/questions/73962109/why-are-the-workers-failing-to-connect-when-calling-makepsockcluster-from-an-e/73991833#73991833
and https://github.com/r-lib/callr/issues/236)


/Henrik

On Mon, Oct 10, 2022 at 5:54 AM peter dalgaard <pdalgd at gmail.com> wrote:
>
> It seems to work simply to do  "if (ifd >= 0)..." (the ifp test is fine since ifp is FILE* and initialized to NULL). Will commit (to r-devel for now).
>
> -pd
>
> > On 10 Oct 2022, at 11:07 , peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > He!
> >
> > Yes, that looks like a blunder.
> >
> > mkstemp() returns -1 on failure, not 0, so the test on ifd (and I suppose also the one on ifp) is wrong. And of course, once you close file descriptor 0, mkstemp() chooses the 1st available fd, i.e. 0, for its return value.
> >
> > -pd
> >
> >> On 9 Oct 2022, at 20:25 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> >>
> >> Rscript fails to launch if the standard input (stdin) is closed, e.g.
> >>
> >> $ Rscript --vanilla -e 42 0<&-
> >> Fatal error: creating temporary file for '-e' failed
> >>
> >> This appear to only happen with `-e EXPR`, e.g. it works when doing:
> >>
> >> $ echo "42" > script.R
> >> $ Rscript --vanilla script.R 0<&-
> >> [1] 42
> >>
> >> and:
> >>
> >> $ R --vanilla 0<&-
> >> R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
> >> Copyright (C) 2022 The R Foundation for Statistical Computing
> >> Platform: x86_64-pc-linux-gnu (64-bit)
> >> ...
> >>>
> >>
> >>
> >> TROUBLESHOOTING:
> >>
> >> $ strace Rscript --vanilla -e 42 0<&-
> >> execve("/home/hb/shared/software/CBI/R-4.2.1-gcc9/bin/Rscript",
> >> ["Rscript", "--vanilla", "-e", "42"], 0x7fff9f476418 /* 147 vars */) =
> >> 0
> >> brk(NULL)                               = 0x5625ca9e6000
> >> arch_prctl(0x3001 /* ARCH_??? */, 0x7fff23b4d260) = -1 EINVAL (Invalid argument)
> >> ...
> >> fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
> >> write(1, "Fatal error: creating temporary "..., 53Fatal error:
> >> creating temporary file for '-e' failed
> >> ) = 53
> >> exit_group(2)                           = ?
> >> +++ exited with 2 +++
> >>
> >> which points to src/unix/system.c:
> >>
> >> ifd = mkstemp(ifile);
> >> if (ifd > 0)
> >>   ifp = fdopen(ifd, "w+");
> >> if(!ifp) R_Suicide(_("creating temporary file for '-e' failed"));
> >>
> >>
> >> One rationale for having closed standard files (including stdin) is to
> >> avoid leaking file descriptors, cf.
> >> https://wiki.sei.cmu.edu/confluence/display/c/FIO22-C.+Close+files+before+spawning+processes
> >> and https://danwalsh.livejournal.com/53603.html.  The background for
> >> reporting on this was that `system()` fails to work in processx
> >> spawned processes, which closes the standard files by default in
> >> processx (<= 3.7.0).
> >>
> >> Best,
> >>
> >> Henrik
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 11 10:28:48 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 11 Oct 2022 10:28:48 +0200
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <CABzLhzynMazG7dVfr+GC_3F=QDEJK+zx4AX_tz-2CdbJdYvv=w@mail.gmail.com>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
 <25408.8433.260821.451226@stat.math.ethz.ch>
 <CABzLhzynMazG7dVfr+GC_3F=QDEJK+zx4AX_tz-2CdbJdYvv=w@mail.gmail.com>
Message-ID: <25413.10560.448520.766218@stat.math.ethz.ch>

>>>>> Davis Vaughan 
>>>>>     on Fri, 7 Oct 2022 11:00:23 -0400 writes:

    > Martin,
    > FWIW, I scoured the docs using GitHub's new code search preview but can't
    > seem to find any reference to the fact that POSIXlt fields are internally
    > recycled (even though lubridate seems to have been relying on this for
    > quite some time).

Thank you, Davis, for searching  and confirming that this has
never been documented.  And so,  in that sense there's no bug,
because only non-documented behaviour has changed.

Still, with svn rev 83062  I have finally committed a version of
the C code underlying  as.Date.POSIXlt()  which (I think/hope)
does deal correctly with such partially filled POSIXlt objects
(it does with your relatively benign example and with the more
 nasty one I had mentioned).

BTW,  at least length() has been working correctly for
these, for a bit less than a day now, too,  since svn rev 83056  .

These are still only some of several steps to correctly support
such objects.
Notably the `[` and  `[<-` methods will need a substantial
update, too (as you have noticed for the latter in your other
R-devel post on Oct 6, Subject "Bug with `[<-.POSIXlt` on specific OSes").

Note that I'd be quite grateful for well documented platform
dependent behavior.  In addition to a typical sessionInfo() this
would also need to report the current setting of a  "TZ" environment variable,
where I have noticed [on Linux, Fedora 36] that there may be
different behavior between TZ entirely undefined and a TZ="" setting
(which I intuitively assumed would work equivalently).


Best,
Martin


    > -Davis

    > On Fri, Oct 7, 2022 at 8:52 AM Martin Maechler <maechler at stat.math.ethz.ch>
    > wrote:

    >> >>>>> Martin Maechler
    >> >>>>>     on Thu, 6 Oct 2022 10:15:29 +0200 writes:
    >> 
    >> >>>>> Davis Vaughan
    >> >>>>>     on Wed, 5 Oct 2022 17:04:11 -0400 writes:
    >> 
    >> >> Hi all,
    >> 
    >> >> I think I have discovered a bug in the conversion from POSIXlt to
    >> Date that has been introduced in r-devel.
    >> 
    >> >> It affects lubridate, but surprisingly didn't cause test failures
    >> there.

   [..................]


From pd@|gd @end|ng |rom gm@||@com  Tue Oct 11 10:53:46 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 11 Oct 2022 10:53:46 +0200
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
 <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
 <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>
 <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>
Message-ID: <A6D03905-1731-456C-8FB5-F4AA9D7F5F88@gmail.com>

There's still 2 weeks till code freeze for 4.2.2, and porting the fix would be trivial. As long as there is no risk that someone will get the bright idea of changing a critical package to depend on R >= 4.2.2...

- pd

> On 10 Oct 2022, at 18:34 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> Thank you Peter for the quick fix.  Will this make it into R-patched
> to become R 4.2.2 soon?
> 
> I can confirm that the fix resolved also the original problem report
> involving launching a parallel PSOCK cluster from within a 'processx'
> background process
> (https://stackoverflow.com/questions/73962109/why-are-the-workers-failing-to-connect-when-calling-makepsockcluster-from-an-e/73991833#73991833
> and https://github.com/r-lib/callr/issues/236)
> 
> 
> /Henrik
> 
> On Mon, Oct 10, 2022 at 5:54 AM peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> It seems to work simply to do  "if (ifd >= 0)..." (the ifp test is fine since ifp is FILE* and initialized to NULL). Will commit (to r-devel for now).
>> 
>> -pd
>> 
>>> On 10 Oct 2022, at 11:07 , peter dalgaard <pdalgd at gmail.com> wrote:
>>> 
>>> He!
>>> 
>>> Yes, that looks like a blunder.
>>> 
>>> mkstemp() returns -1 on failure, not 0, so the test on ifd (and I suppose also the one on ifp) is wrong. And of course, once you close file descriptor 0, mkstemp() chooses the 1st available fd, i.e. 0, for its return value.
>>> 
>>> -pd
>>> 
>>>> On 9 Oct 2022, at 20:25 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>> 
>>>> Rscript fails to launch if the standard input (stdin) is closed, e.g.
>>>> 
>>>> $ Rscript --vanilla -e 42 0<&-
>>>> Fatal error: creating temporary file for '-e' failed
>>>> 
>>>> This appear to only happen with `-e EXPR`, e.g. it works when doing:
>>>> 
>>>> $ echo "42" > script.R
>>>> $ Rscript --vanilla script.R 0<&-
>>>> [1] 42
>>>> 
>>>> and:
>>>> 
>>>> $ R --vanilla 0<&-
>>>> R version 4.2.1 (2022-06-23) -- "Funny-Looking Kid"
>>>> Copyright (C) 2022 The R Foundation for Statistical Computing
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> ...
>>>>> 
>>>> 
>>>> 
>>>> TROUBLESHOOTING:
>>>> 
>>>> $ strace Rscript --vanilla -e 42 0<&-
>>>> execve("/home/hb/shared/software/CBI/R-4.2.1-gcc9/bin/Rscript",
>>>> ["Rscript", "--vanilla", "-e", "42"], 0x7fff9f476418 /* 147 vars */) =
>>>> 0
>>>> brk(NULL)                               = 0x5625ca9e6000
>>>> arch_prctl(0x3001 /* ARCH_??? */, 0x7fff23b4d260) = -1 EINVAL (Invalid argument)
>>>> ...
>>>> fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
>>>> write(1, "Fatal error: creating temporary "..., 53Fatal error:
>>>> creating temporary file for '-e' failed
>>>> ) = 53
>>>> exit_group(2)                           = ?
>>>> +++ exited with 2 +++
>>>> 
>>>> which points to src/unix/system.c:
>>>> 
>>>> ifd = mkstemp(ifile);
>>>> if (ifd > 0)
>>>>  ifp = fdopen(ifd, "w+");
>>>> if(!ifp) R_Suicide(_("creating temporary file for '-e' failed"));
>>>> 
>>>> 
>>>> One rationale for having closed standard files (including stdin) is to
>>>> avoid leaking file descriptors, cf.
>>>> https://wiki.sei.cmu.edu/confluence/display/c/FIO22-C.+Close+files+before+spawning+processes
>>>> and https://danwalsh.livejournal.com/53603.html.  The background for
>>>> reporting on this was that `system()` fails to work in processx
>>>> spawned processes, which closes the standard files by default in
>>>> processx (<= 3.7.0).
>>>> 
>>>> Best,
>>>> 
>>>> Henrik
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From d@v|@ @end|ng |rom r@tud|o@com  Tue Oct 11 15:47:47 2022
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Tue, 11 Oct 2022 09:47:47 -0400
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>
References: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>
Message-ID: <CABzLhzxNNce6eEOnnv0fSpLRiZ70FC3-YadS2PeWOFSJfN6Zaw@mail.gmail.com>

I've got a bit more information about this one. It seems like it (only? not
sure) appears when `TZ = "UTC"`, which is why I didn't see it before on my
Mac, which defaults to `TZ = ""`. I think this is at least explainable by
the fact that those "optional" fields aren't technically needed when the
time zone is UTC.

I can reproduce this now on my personal Mac:

```

x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

Sys.setenv(TZ = "")

x[1] <- NA

x

#> [1] NA


x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

Sys.setenv(TZ = "America/New_York")

x[1] <- NA

x

#> [1] NA


x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

Sys.setenv(TZ = "UTC")

x[1] <- NA
#> Error in x[[n]][i] <- value[[n]] : replacement has length zero

x

#> [1] "2013-01-31 CST"
```

Here are `sessionInfo()` and `Sys.getenv("TZ")` outputs for 3 GitHub
Actions platforms where the bug exists (note they all set `TZ = "UTC"`!):

Linux:

```

> sessionInfo()

R version 4.2.1 (2022-06-23)

Platform: x86_64-pc-linux-gnu (64-bit)

Running under: Ubuntu 18.04.6 LTS


Matrix products: default

BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3

LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so


locale:

 [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8

 [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8

 [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C

[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.2.1


> Sys.getenv("TZ")

[1] "UTC"
```

Mac:

```

> sessionInfo()

R version 4.2.1 (2022-06-23)

Platform: x86_64-apple-darwin17.0 (64-bit)

Running under: macOS Big Sur ... 10.16


Matrix products: default

BLAS:
/Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

LAPACK:
/Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


locale:

[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.2.1


> Sys.getenv("TZ")

[1] "UTC"
```

Windows:
This is the best I can get you, sorry (remote worker issues), but note that
it does also say `tz UTC` like the others.

```
version R version 4.2.1 (2022-06-23 ucrt)
os Windows Server x64 (build 20348)
system x86_64, mingw32
ui RTerm
language (EN)
collate English_United States.utf8
ctype English_United States.utf8
tz UTC
date 2022-10-11
```

And here is my Mac where the bug doesn't show up by default because `TZ =
""`:

```

> sessionInfo()

R version 4.2.1 (2022-06-23)

Platform: x86_64-apple-darwin17.0 (64-bit)

Running under: macOS Big Sur ... 10.16


Matrix products: default

BLAS:
/Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

LAPACK:
/Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


locale:

[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.2.1


> Sys.getenv("TZ")

[1] ""


> Sys.timezone()

[1] "America/New_York"
```

-Davis


On Thu, Oct 6, 2022 at 9:33 AM Davis Vaughan <davis at rstudio.com> wrote:

> Hi all,
>
> I have found another POSIXlt bug while I've been fiddling around with it.
> This one only appears on specific OSes, because it has to do with the fact
> that the `gmtoff` field is optional, and isn't always used on all OSes. It
> also doesn't seem to be specific to r-devel, I think it has been there
> awhile.
>
> Here is the bug:
>
> ```
> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
>
> # Oh no!
> x[1] <- NA
> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero
> ```
>
> If you look at the objects, you can see that `x` has a `gmtoff` field, but
> `NA` (when converted to POSIXlt, which is what `[<-.POSIXlt` does) does not:
>
> ```
> unclass(x)
> #> $sec
> #> [1] 0
> #>
> #> $min
> #> [1] 0
> #>
> #> $hour
> #> [1] 0
> #>
> #> $mday
> #> [1] 31
> #>
> #> $mon
> #> [1] 0
> #>
> #> $year
> #> [1] 113
> #>
> #> $wday
> #> [1] 4
> #>
> #> $yday
> #> [1] 30
> #>
> #> $isdst
> #> [1] 0
> #>
> #> $zone
> #> [1] "CST"
> #>
> #> $gmtoff
> #> [1] -21600
> #>
> #> attr(,"tzone")
> #> [1] "America/Chicago" "CST"             "CDT"
>
> unclass(as.POSIXlt(NA))
> #> $sec
> #> [1] NA
> #>
> #> $min
> #> [1] NA
> #>
> #> $hour
> #> [1] NA
> #>
> #> $mday
> #> [1] NA
> #>
> #> $mon
> #> [1] NA
> #>
> #> $year
> #> [1] NA
> #>
> #> $wday
> #> [1] NA
> #>
> #> $yday
> #> [1] NA
> #>
> #> $isdst
> #> [1] -1
> #>
> #> attr(,"tzone")
> #> [1] "UTC"
> ```
>
> The problem seems to be that `[<-.POSIXlt` assumes that if the field was
> there in `x` then it must also be there in `value`:
>
> https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/library/base/R/datetime.R#L1303-L1304
>
> But this isn't the case for the `NA` value that was converted to POSIXlt.
>
> I can't reproduce this on my personal Mac, but it affects the Linux, Mac,
> and Windows machines we use for the lubridate CI checks through GitHub
> Actions.
>
> Thanks,
> Davis
>

	[[alternative HTML version deleted]]


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Tue Oct 11 16:44:13 2022
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Tue, 11 Oct 2022 16:44:13 +0200
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <CABzLhzxNNce6eEOnnv0fSpLRiZ70FC3-YadS2PeWOFSJfN6Zaw@mail.gmail.com>
References: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>
 <CABzLhzxNNce6eEOnnv0fSpLRiZ70FC3-YadS2PeWOFSJfN6Zaw@mail.gmail.com>
Message-ID: <25413.33085.344041.49718@hornik.net>

>>>>> Davis Vaughan writes:

> I've got a bit more information about this one. It seems like it
> (only? not sure) appears when `TZ = "UTC"`, which is why I didn't see
> it before on my Mac, which defaults to `TZ = ""`. I think this is at
> least explainable by the fact that those "optional" fields aren't
> technically needed when the time zone is UTC.

Exactly.  Debugging `[<-.POSIlt` with

x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
Sys.setenv(TZ = "UTC")
x[1] <- NA

shows we get into

    value <- unclass(as.POSIXlt(value))
    if (ici) {
        for (n in names(x)) names(x[[n]]) <- nms
    }
    for (n in names(x)) x[[n]][i] <- value[[n]]

where

Browse[2]> names(value)
[1] "sec"   "min"   "hour"  "mday"  "mon"   "year"  "wday"  "yday"  "isdst"
Browse[2]> names(x)
 [1] "sec"    "min"    "hour"   "mday"   "mon"    "year"   "wday"   "yday"  
 [9] "isdst"  "zone"   "gmtoff"

Without having looked at the code, the docs say

     ?zone? (Optional.) The abbreviation for the time zone in force at
          that time: ?""? if unknown (but ?""? might also be used for
          UTC).

     ?gmtoff? (Optional.) The offset in seconds from GMT: positive
          values are East of the meridian.  Usually ?NA? if unknown,
          but ?0? could mean unknown.

so perhaps we should fill with the values for the unknown case?

-k

> I can reproduce this now on my personal Mac:

> ```

> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

> Sys.setenv(TZ = "")

> x[1] <- NA

> x

> #> [1] NA


> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

> Sys.setenv(TZ = "America/New_York")

> x[1] <- NA

> x

> #> [1] NA


> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

> Sys.setenv(TZ = "UTC")

> x[1] <- NA
> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero

> x

> #> [1] "2013-01-31 CST"
> ```

> Here are `sessionInfo()` and `Sys.getenv("TZ")` outputs for 3 GitHub
> Actions platforms where the bug exists (note they all set `TZ = "UTC"`!):

> Linux:

> ```

>> sessionInfo()

> R version 4.2.1 (2022-06-23)

> Platform: x86_64-pc-linux-gnu (64-bit)

> Running under: Ubuntu 18.04.6 LTS


> Matrix products: default

> BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3

> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so


> locale:

>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8

>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8

>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C

> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C


> attached base packages:

> [1] stats     graphics  grDevices utils     datasets  methods   base


> loaded via a namespace (and not attached):

> [1] compiler_4.2.1


>> Sys.getenv("TZ")

> [1] "UTC"
> ```

> Mac:

> ```

>> sessionInfo()

> R version 4.2.1 (2022-06-23)

> Platform: x86_64-apple-darwin17.0 (64-bit)

> Running under: macOS Big Sur ... 10.16


> Matrix products: default

> BLAS:
> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


> locale:

> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


> attached base packages:

> [1] stats     graphics  grDevices utils     datasets  methods   base


> loaded via a namespace (and not attached):

> [1] compiler_4.2.1


>> Sys.getenv("TZ")

> [1] "UTC"
> ```

> Windows:
> This is the best I can get you, sorry (remote worker issues), but note that
> it does also say `tz UTC` like the others.

> ```
> version R version 4.2.1 (2022-06-23 ucrt)
> os Windows Server x64 (build 20348)
> system x86_64, mingw32
> ui RTerm
> language (EN)
> collate English_United States.utf8
> ctype English_United States.utf8
> tz UTC
> date 2022-10-11
> ```

> And here is my Mac where the bug doesn't show up by default because `TZ =
> ""`:

> ```

>> sessionInfo()

> R version 4.2.1 (2022-06-23)

> Platform: x86_64-apple-darwin17.0 (64-bit)

> Running under: macOS Big Sur ... 10.16


> Matrix products: default

> BLAS:
> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


> locale:

> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


> attached base packages:

> [1] stats     graphics  grDevices utils     datasets  methods   base


> loaded via a namespace (and not attached):

> [1] compiler_4.2.1


>> Sys.getenv("TZ")

> [1] ""


>> Sys.timezone()

> [1] "America/New_York"
> ```

> -Davis


> On Thu, Oct 6, 2022 at 9:33 AM Davis Vaughan <davis at rstudio.com> wrote:

>> Hi all,
>> 
>> I have found another POSIXlt bug while I've been fiddling around with it.
>> This one only appears on specific OSes, because it has to do with the fact
>> that the `gmtoff` field is optional, and isn't always used on all OSes. It
>> also doesn't seem to be specific to r-devel, I think it has been there
>> awhile.
>> 
>> Here is the bug:
>> 
>> ```
>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
>> 
>> # Oh no!
>> x[1] <- NA
>> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero
>> ```
>> 
>> If you look at the objects, you can see that `x` has a `gmtoff` field, but
>> `NA` (when converted to POSIXlt, which is what `[<-.POSIXlt` does) does not:
>> 
>> ```
>> unclass(x)
>> #> $sec
>> #> [1] 0
>> #>
>> #> $min
>> #> [1] 0
>> #>
>> #> $hour
>> #> [1] 0
>> #>
>> #> $mday
>> #> [1] 31
>> #>
>> #> $mon
>> #> [1] 0
>> #>
>> #> $year
>> #> [1] 113
>> #>
>> #> $wday
>> #> [1] 4
>> #>
>> #> $yday
>> #> [1] 30
>> #>
>> #> $isdst
>> #> [1] 0
>> #>
>> #> $zone
>> #> [1] "CST"
>> #>
>> #> $gmtoff
>> #> [1] -21600
>> #>
>> #> attr(,"tzone")
>> #> [1] "America/Chicago" "CST"             "CDT"
>> 
>> unclass(as.POSIXlt(NA))
>> #> $sec
>> #> [1] NA
>> #>
>> #> $min
>> #> [1] NA
>> #>
>> #> $hour
>> #> [1] NA
>> #>
>> #> $mday
>> #> [1] NA
>> #>
>> #> $mon
>> #> [1] NA
>> #>
>> #> $year
>> #> [1] NA
>> #>
>> #> $wday
>> #> [1] NA
>> #>
>> #> $yday
>> #> [1] NA
>> #>
>> #> $isdst
>> #> [1] -1
>> #>
>> #> attr(,"tzone")
>> #> [1] "UTC"
>> ```
>> 
>> The problem seems to be that `[<-.POSIXlt` assumes that if the field was
>> there in `x` then it must also be there in `value`:
>> 
>> https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/library/base/R/datetime.R#L1303-L1304
>> 
>> But this isn't the case for the `NA` value that was converted to POSIXlt.
>> 
>> I can't reproduce this on my personal Mac, but it affects the Linux, Mac,
>> and Windows machines we use for the lubridate CI checks through GitHub
>> Actions.
>> 
>> Thanks,
>> Davis
>> 

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Oct 12 10:17:28 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 12 Oct 2022 10:17:28 +0200
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <25413.33085.344041.49718@hornik.net>
References: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>
 <CABzLhzxNNce6eEOnnv0fSpLRiZ70FC3-YadS2PeWOFSJfN6Zaw@mail.gmail.com>
 <25413.33085.344041.49718@hornik.net>
Message-ID: <25414.30744.139721.871865@stat.math.ethz.ch>

>>>>> Kurt Hornik 
>>>>>     on Tue, 11 Oct 2022 16:44:13 +0200 writes:

>>>>> Davis Vaughan writes:
    >> I've got a bit more information about this one. It seems like it
    >> (only? not sure) appears when `TZ = "UTC"`, which is why I didn't see
    >> it before on my Mac, which defaults to `TZ = ""`. I think this is at
    >> least explainable by the fact that those "optional" fields aren't
    >> technically needed when the time zone is UTC.

    > Exactly.  Debugging `[<-.POSIlt` with

    > x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
    > Sys.setenv(TZ = "UTC")
    > x[1] <- NA

    > shows we get into

    > value <- unclass(as.POSIXlt(value))
    > if (ici) {
    > for (n in names(x)) names(x[[n]]) <- nms
    > }
    > for (n in names(x)) x[[n]][i] <- value[[n]]

    > where

    > Browse[2]> names(value)
    > [1] "sec"   "min"   "hour"  "mday"  "mon"   "year"  "wday"  "yday"  "isdst"
    > Browse[2]> names(x)
    > [1] "sec"    "min"    "hour"   "mday"   "mon"    "year"   "wday"   "yday"  
    > [9] "isdst"  "zone"   "gmtoff"

    > Without having looked at the code, the docs say

    > ?zone? (Optional.) The abbreviation for the time zone in force at
    > that time: ?""? if unknown (but ?""? might also be used for
    > UTC).

    > ?gmtoff? (Optional.) The offset in seconds from GMT: positive
    > values are East of the meridian.  Usually ?NA? if unknown,
    > but ?0? could mean unknown.

    > so perhaps we should fill with the values for the unknown case?

    > -k

Well,

I think you both know  I'm in the midst of dealing with these
issues, to fix both

[.POSIXlt  and
[<-.POSIXlt

Yes, one needs a way to not only "fill" the partially filled
entries but also to *normalize* out-of-range values
(say negative seconds, minutes > 60, etc)

All this is available in our C code, but not on the R level,
so yesterday, I wrote a C function to be called via .Internal(.)
from a new R that provides this.

Provisionally called

   balancePOXIXlt()

because it both balances the 9 to 11 list-components of POSIXlt
and it also puts all numbers of (sec, min, hour, mday, mon)
into a correct range (and also computes correctl wday and yday numbers).
but I'm happy for proposals of better names.
I had contemplated  validatePOSIXlt() as alternative, but then
dismissed that as in some sense we now do agree that
"imbalanced" POSIXlt's are not really invalid ..

.. and yes, to Davis:  Even though I've spent so many hours with
POSIXlt, POSIXct and Date during the last week, I'm still
surprised more often than I like by the effects of timezone
settings there.

Martin


    >> I can reproduce this now on my personal Mac:

    >> ```

    >> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >> Sys.setenv(TZ = "")

    >> x[1] <- NA

    >> x

    >> #> [1] NA


    >> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >> Sys.setenv(TZ = "America/New_York")

    >> x[1] <- NA

    >> x

    >> #> [1] NA


    >> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >> Sys.setenv(TZ = "UTC")

    >> x[1] <- NA
    >> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero

    >> x

    >> #> [1] "2013-01-31 CST"
    >> ```

    >> Here are `sessionInfo()` and `Sys.getenv("TZ")` outputs for 3 GitHub
    >> Actions platforms where the bug exists (note they all set `TZ = "UTC"`!):

    >> Linux:

    >> ```

    >>> sessionInfo()

    >> R version 4.2.1 (2022-06-23)

    >> Platform: x86_64-pc-linux-gnu (64-bit)

    >> Running under: Ubuntu 18.04.6 LTS


    >> Matrix products: default

    >> BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3

    >> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so


    >> locale:

    >> [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8

    >> [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8

    >> [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C

    >> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C


    >> attached base packages:

    >> [1] stats     graphics  grDevices utils     datasets  methods   base


    >> loaded via a namespace (and not attached):

    >> [1] compiler_4.2.1


    >>> Sys.getenv("TZ")

    >> [1] "UTC"
    >> ```

    >> Mac:

    >> ```

    >>> sessionInfo()

    >> R version 4.2.1 (2022-06-23)

    >> Platform: x86_64-apple-darwin17.0 (64-bit)

    >> Running under: macOS Big Sur ... 10.16


    >> Matrix products: default

    >> BLAS:
    >> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

    >> LAPACK:
    >> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


    >> locale:

    >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


    >> attached base packages:

    >> [1] stats     graphics  grDevices utils     datasets  methods   base


    >> loaded via a namespace (and not attached):

    >> [1] compiler_4.2.1


    >>> Sys.getenv("TZ")

    >> [1] "UTC"
    >> ```

    >> Windows:
    >> This is the best I can get you, sorry (remote worker issues), but note that
    >> it does also say `tz UTC` like the others.

    >> ```
    >> version R version 4.2.1 (2022-06-23 ucrt)
    >> os Windows Server x64 (build 20348)
    >> system x86_64, mingw32
    >> ui RTerm
    >> language (EN)
    >> collate English_United States.utf8
    >> ctype English_United States.utf8
    >> tz UTC
    >> date 2022-10-11
    >> ```

    >> And here is my Mac where the bug doesn't show up by default because `TZ =
    >> ""`:

    >> ```

    >>> sessionInfo()

    >> R version 4.2.1 (2022-06-23)

    >> Platform: x86_64-apple-darwin17.0 (64-bit)

    >> Running under: macOS Big Sur ... 10.16


    >> Matrix products: default

    >> BLAS:
    >> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

    >> LAPACK:
    >> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


    >> locale:

    >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


    >> attached base packages:

    >> [1] stats     graphics  grDevices utils     datasets  methods   base


    >> loaded via a namespace (and not attached):

    >> [1] compiler_4.2.1


    >>> Sys.getenv("TZ")

    >> [1] ""


    >>> Sys.timezone()

    >> [1] "America/New_York"
    >> ```

    >> -Davis


    >> On Thu, Oct 6, 2022 at 9:33 AM Davis Vaughan <davis at rstudio.com> wrote:

    >>> Hi all,
    >>> 
    >>> I have found another POSIXlt bug while I've been fiddling around with it.
    >>> This one only appears on specific OSes, because it has to do with the fact
    >>> that the `gmtoff` field is optional, and isn't always used on all OSes. It
    >>> also doesn't seem to be specific to r-devel, I think it has been there
    >>> awhile.
    >>> 
    >>> Here is the bug:
    >>> 
    >>> ```
    >>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
    >>> 
    >>> # Oh no!
    >>> x[1] <- NA
    >>> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero
    >>> ```
    >>> 
    >>> If you look at the objects, you can see that `x` has a `gmtoff` field, but
    >>> `NA` (when converted to POSIXlt, which is what `[<-.POSIXlt` does) does not:
    >>> 
    >>> ```
    >>> unclass(x)
    >>> #> $sec
    >>> #> [1] 0
    >>> #>
    >>> #> $min
    >>> #> [1] 0
    >>> #>
    >>> #> $hour
    >>> #> [1] 0
    >>> #>
    >>> #> $mday
    >>> #> [1] 31
    >>> #>
    >>> #> $mon
    >>> #> [1] 0
    >>> #>
    >>> #> $year
    >>> #> [1] 113
    >>> #>
    >>> #> $wday
    >>> #> [1] 4
    >>> #>
    >>> #> $yday
    >>> #> [1] 30
    >>> #>
    >>> #> $isdst
    >>> #> [1] 0
    >>> #>
    >>> #> $zone
    >>> #> [1] "CST"
    >>> #>
    >>> #> $gmtoff
    >>> #> [1] -21600
    >>> #>
    >>> #> attr(,"tzone")
    >>> #> [1] "America/Chicago" "CST"             "CDT"
    >>> 
    >>> unclass(as.POSIXlt(NA))
    >>> #> $sec
    >>> #> [1] NA
    >>> #>
    >>> #> $min
    >>> #> [1] NA
    >>> #>
    >>> #> $hour
    >>> #> [1] NA
    >>> #>
    >>> #> $mday
    >>> #> [1] NA
    >>> #>
    >>> #> $mon
    >>> #> [1] NA
    >>> #>
    >>> #> $year
    >>> #> [1] NA
    >>> #>
    >>> #> $wday
    >>> #> [1] NA
    >>> #>
    >>> #> $yday
    >>> #> [1] NA
    >>> #>
    >>> #> $isdst
    >>> #> [1] -1
    >>> #>
    >>> #> attr(,"tzone")
    >>> #> [1] "UTC"
    >>> ```
    >>> 
    >>> The problem seems to be that `[<-.POSIXlt` assumes that if the field was
    >>> there in `x` then it must also be there in `value`:
    >>> 
    >>> https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/library/base/R/datetime.R#L1303-L1304
    >>> 
    >>> But this isn't the case for the `NA` value that was converted to POSIXlt.
    >>> 
    >>> I can't reproduce this on my personal Mac, but it affects the Linux, Mac,
    >>> and Windows machines we use for the lubridate CI checks through GitHub
    >>> Actions.
    >>> 
    >>> Thanks,
    >>> Davis
    >>>


From r|p|ey @end|ng |rom @t@t@@ox@@c@uk  Wed Oct 12 12:46:19 2022
From: r|p|ey @end|ng |rom @t@t@@ox@@c@uk (Prof Brian Ripley)
Date: Wed, 12 Oct 2022 11:46:19 +0100
Subject: [Rd] A potential POSIXlt->Date bug introduced in r-devel
In-Reply-To: <df276af2-5024-05dd-1ccb-96ffbf6e980b@stats.ox.ac.uk>
References: <CABzLhzzsnRCwM3LPM-z2T8YFO3bBcD7=iE3Hxx9rLdEUeAkk3g@mail.gmail.com>
 <25406.36513.13316.676488@stat.math.ethz.ch>
 <20221006164146.39f9b8e4@ECM-DTC-716.uniwa.uwa.edu.au>
 <df276af2-5024-05dd-1ccb-96ffbf6e980b@stats.ox.ac.uk>
Message-ID: <192501c4-46a4-ab4e-d908-8bde2eceda7b@stats.ox.ac.uk>

Confirmed on Fedora 36 which has a 32-bit time_t for an i686 compile.  I 
was a bit surprised that has not been changed, but gather Linux distros 
are preferring to drop ix86 than fix it.

There is a simple workaround, to configure R with 
--with-internal-tzcode, which always uses a 64-bit time_t.  Given that 
2038 is not that far away, avoiding 32-bit time_t is generally a very 
good idea (not just for people working with dates in 5881580!).

That test should not really be run on platforms with 32-bit time_t, but 
that is not currently known at R level.

On 06/10/2022 13:38, Prof Brian Ripley wrote:
> On 06/10/2022 09:41, Berwin A Turlach wrote:
>> G'day all,
>>
>> On Thu, 6 Oct 2022 10:15:29 +0200
>> Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>
>>>>>>>> Davis Vaughan
>>>>>>>> ???? on Wed, 5 Oct 2022 17:04:11 -0400 writes:
>>
>>> ???? > # Weird, where is the `NA`?
>>> ???? > as.Date(x)
>>> ???? > #> [1] "2013-01-31" "1970-01-01" "2013-03-31"
>>> ???? > ```
>>>
>>> I agree that the above is wrong, i.e., a bug in current? R-devel.
>>
>> I have no intention of hijacking this thread, but I wonder whether this
>> is a good opportunity to mention that the 32 bit build of R-devel falls
>> over on my machine since 25 September.? It fails one of the regression
>> tests in reg-tests-1d.R.? The final lines of reg-tests-1d.Rout.fail
>> are:
>>
>>> tools::Rd2txt(rd, out <- textConnection(NULL, "w"), fragment = TRUE)
>>> stopifnot(any(as.character(rd) != "\n"),
>> +?????????? identical(textConnectionValue(out)[2L], "LaTeX"));
>> close(out)
>>> ## empty output in R <= 4.2.x
> 
> Yes, known for a few days on the R-core list. I am in the middle of an 
> OS upgrade on that machine and won't have time to do more than report 
> until that (and all the re-building and re-checking) is complete.
> 
>>> ## as.POSIXlt(<very large Date>)? gave integer overflow
>>> stopifnot(as.POSIXlt(.Date(2^31 + 10))$year == 5879680L)
>> Error: as.POSIXlt(.Date(2^31 + 10))$year == 5879680L is not TRUE
>> Execution halted
>>
>>
>> I should have reported this earlier, but somehow did not find the time
>> to do so.? So I thought I mention it here. :)
>>
>> Cheers,
>>
>> ????Berwin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Oct 12 12:47:50 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 12 Oct 2022 12:47:50 +0200
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <25414.30744.139721.871865@stat.math.ethz.ch>
References: <CABzLhzy0eTEAnb36raY5h_P=4+Dnm9uX0k0DB557zntD2qMLxg@mail.gmail.com>
 <CABzLhzxNNce6eEOnnv0fSpLRiZ70FC3-YadS2PeWOFSJfN6Zaw@mail.gmail.com>
 <25413.33085.344041.49718@hornik.net>
 <25414.30744.139721.871865@stat.math.ethz.ch>
Message-ID: <25414.39766.204230.129162@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Wed, 12 Oct 2022 10:17:28 +0200 writes:

>>>>> Kurt Hornik 
>>>>>     on Tue, 11 Oct 2022 16:44:13 +0200 writes:

>>>>> Davis Vaughan writes:
    >>> I've got a bit more information about this one. It seems like it
    >>> (only? not sure) appears when `TZ = "UTC"`, which is why I didn't see
    >>> it before on my Mac, which defaults to `TZ = ""`. I think this is at
    >>> least explainable by the fact that those "optional" fields aren't
    >>> technically needed when the time zone is UTC.

    >> Exactly.  Debugging `[<-.POSIlt` with

    >> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
    >> Sys.setenv(TZ = "UTC")
    >> x[1] <- NA

    >> shows we get into

    >> value <- unclass(as.POSIXlt(value))
    >> if (ici) {
    >> for (n in names(x)) names(x[[n]]) <- nms
    >> }
    >> for (n in names(x)) x[[n]][i] <- value[[n]]

    >> where

    >> Browse[2]> names(value)
    >> [1] "sec"   "min"   "hour"  "mday"  "mon"   "year"  "wday"  "yday"  "isdst"
    >> Browse[2]> names(x)
    >> [1] "sec"    "min"    "hour"   "mday"   "mon"    "year"   "wday"   "yday"  
    >> [9] "isdst"  "zone"   "gmtoff"

    >> Without having looked at the code, the docs say

    >> ?zone? (Optional.) The abbreviation for the time zone in force at
    >> that time: ?""? if unknown (but ?""? might also be used for
    >> UTC).

    >> ?gmtoff? (Optional.) The offset in seconds from GMT: positive
    >> values are East of the meridian.  Usually ?NA? if unknown,
    >> but ?0? could mean unknown.

    >> so perhaps we should fill with the values for the unknown case?

    >> -k

    > Well,

    > I think you both know  I'm in the midst of dealing with these
    > issues, to fix both

    > [.POSIXlt  and
    > [<-.POSIXlt

    > Yes, one needs a way to not only "fill" the partially filled
    > entries but also to *normalize* out-of-range values
    > (say negative seconds, minutes > 60, etc)

    > All this is available in our C code, but not on the R level,
    > so yesterday, I wrote a C function to be called via .Internal(.)
    > from a new R that provides this.

    > Provisionally called

    > balancePOSIXlt()

    > because it both balances the 9 to 11 list-components of POSIXlt
    > and it also puts all numbers of (sec, min, hour, mday, mon)
    > into a correct range (and also computes correctl wday and yday numbers).
    > but I'm happy for proposals of better names.
    > I had contemplated  validatePOSIXlt() as alternative, but then
    > dismissed that as in some sense we now do agree that
    > "imbalanced" POSIXlt's are not really invalid ..

    > .. and yes, to Davis:  Even though I've spent so many hours with
    > POSIXlt, POSIXct and Date during the last week, I'm still
    > surprised more often than I like by the effects of timezone
    > settings there.

    > Martin

I have committed the new R and C code now, defining  balancePOSIXlt(),
to get feedback from the community.

I've extended the documentation in  help(DateTimeClasses),
and notably factored out the description
of  POSIXlt  mentioning the  "ragged" and "out-of-range" cases.

This needs more testing and experiments, and I have not
announced it  NEWS  yet.

Planned next is to use it in  [.POSIXlt and [<-.POSIXlt
so they will work correctly.

But please share your thoughts, propositions, ...

Martin


    >>> I can reproduce this now on my personal Mac:

    >>> ```

    >>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >>> Sys.setenv(TZ = "")

    >>> x[1] <- NA

    >>> x

    >>> #> [1] NA


    >>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >>> Sys.setenv(TZ = "America/New_York")

    >>> x[1] <- NA

    >>> x

    >>> #> [1] NA


    >>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))

    >>> Sys.setenv(TZ = "UTC")

    >>> x[1] <- NA
    >>> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero

    >>> x

    >>> #> [1] "2013-01-31 CST"
    >>> ```

    >>> Here are `sessionInfo()` and `Sys.getenv("TZ")` outputs for 3 GitHub
    >>> Actions platforms where the bug exists (note they all set `TZ = "UTC"`!):

    >>> Linux:

    >>> ```

    >>>> sessionInfo()

    >>> R version 4.2.1 (2022-06-23)

    >>> Platform: x86_64-pc-linux-gnu (64-bit)

    >>> Running under: Ubuntu 18.04.6 LTS


    >>> Matrix products: default

    >>> BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3

    >>> LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so


    >>> locale:

    >>> [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8

    >>> [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8

    >>> [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C

    >>> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C


    >>> attached base packages:

    >>> [1] stats     graphics  grDevices utils     datasets  methods   base


    >>> loaded via a namespace (and not attached):

    >>> [1] compiler_4.2.1


    >>>> Sys.getenv("TZ")

    >>> [1] "UTC"
    >>> ```

    >>> Mac:

    >>> ```

    >>>> sessionInfo()

    >>> R version 4.2.1 (2022-06-23)

    >>> Platform: x86_64-apple-darwin17.0 (64-bit)

    >>> Running under: macOS Big Sur ... 10.16


    >>> Matrix products: default

    >>> BLAS:
    >>> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

    >>> LAPACK:
    >>> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


    >>> locale:

    >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


    >>> attached base packages:

    >>> [1] stats     graphics  grDevices utils     datasets  methods   base


    >>> loaded via a namespace (and not attached):

    >>> [1] compiler_4.2.1


    >>>> Sys.getenv("TZ")

    >>> [1] "UTC"
    >>> ```

    >>> Windows:
    >>> This is the best I can get you, sorry (remote worker issues), but note that
    >>> it does also say `tz UTC` like the others.

    >>> ```
    >>> version R version 4.2.1 (2022-06-23 ucrt)
    >>> os Windows Server x64 (build 20348)
    >>> system x86_64, mingw32
    >>> ui RTerm
    >>> language (EN)
    >>> collate English_United States.utf8
    >>> ctype English_United States.utf8
    >>> tz UTC
    >>> date 2022-10-11
    >>> ```

    >>> And here is my Mac where the bug doesn't show up by default because `TZ =
    >>> ""`:

    >>> ```

    >>>> sessionInfo()

    >>> R version 4.2.1 (2022-06-23)

    >>> Platform: x86_64-apple-darwin17.0 (64-bit)

    >>> Running under: macOS Big Sur ... 10.16


    >>> Matrix products: default

    >>> BLAS:
    >>> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib

    >>> LAPACK:
    >>> /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib


    >>> locale:

    >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8


    >>> attached base packages:

    >>> [1] stats     graphics  grDevices utils     datasets  methods   base


    >>> loaded via a namespace (and not attached):

    >>> [1] compiler_4.2.1


    >>>> Sys.getenv("TZ")

    >>> [1] ""


    >>>> Sys.timezone()

    >>> [1] "America/New_York"
    >>> ```

    >>> -Davis


    >>> On Thu, Oct 6, 2022 at 9:33 AM Davis Vaughan <davis at rstudio.com> wrote:

    >>>> Hi all,
    >>>> 
    >>>> I have found another POSIXlt bug while I've been fiddling around with it.
    >>>> This one only appears on specific OSes, because it has to do with the fact
    >>>> that the `gmtoff` field is optional, and isn't always used on all OSes. It
    >>>> also doesn't seem to be specific to r-devel, I think it has been there
    >>>> awhile.
    >>>> 
    >>>> Here is the bug:
    >>>> 
    >>>> ```
    >>>> x <- as.POSIXlt(as.POSIXct("2013-01-31", tz = "America/Chicago"))
    >>>> 
    >>>> # Oh no!
    >>>> x[1] <- NA
    >>>> #> Error in x[[n]][i] <- value[[n]] : replacement has length zero
    >>>> ```
    >>>> 
    >>>> If you look at the objects, you can see that `x` has a `gmtoff` field, but
    >>>> `NA` (when converted to POSIXlt, which is what `[<-.POSIXlt` does) does not:
    >>>> 
    >>>> ```
    >>>> unclass(x)
    >>>> #> $sec
    >>>> #> [1] 0
    >>>> #>
    >>>> #> $min
    >>>> #> [1] 0
    >>>> #>
    >>>> #> $hour
    >>>> #> [1] 0
    >>>> #>
    >>>> #> $mday
    >>>> #> [1] 31
    >>>> #>
    >>>> #> $mon
    >>>> #> [1] 0
    >>>> #>
    >>>> #> $year
    >>>> #> [1] 113
    >>>> #>
    >>>> #> $wday
    >>>> #> [1] 4
    >>>> #>
    >>>> #> $yday
    >>>> #> [1] 30
    >>>> #>
    >>>> #> $isdst
    >>>> #> [1] 0
    >>>> #>
    >>>> #> $zone
    >>>> #> [1] "CST"
    >>>> #>
    >>>> #> $gmtoff
    >>>> #> [1] -21600
    >>>> #>
    >>>> #> attr(,"tzone")
    >>>> #> [1] "America/Chicago" "CST"             "CDT"
    >>>> 
    >>>> unclass(as.POSIXlt(NA))
    >>>> #> $sec
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $min
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $hour
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $mday
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $mon
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $year
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $wday
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $yday
    >>>> #> [1] NA
    >>>> #>
    >>>> #> $isdst
    >>>> #> [1] -1
    >>>> #>
    >>>> #> attr(,"tzone")
    >>>> #> [1] "UTC"
    >>>> ```
    >>>> 
    >>>> The problem seems to be that `[<-.POSIXlt` assumes that if the field was
    >>>> there in `x` then it must also be there in `value`:
    >>>> 
    >>>> https://github.com/wch/r-source/blob/e10a971dee6a0ab851279c183cc21954d66b3be4/src/library/base/R/datetime.R#L1303-L1304
    >>>> 
    >>>> But this isn't the case for the `NA` value that was converted to POSIXlt.
    >>>> 
    >>>> I can't reproduce this on my personal Mac, but it affects the Linux, Mac,
    >>>> and Windows machines we use for the lubridate CI checks through GitHub
    >>>> Actions.
    >>>> 
    >>>> Thanks,
    >>>> Davis
    >>>> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Oct 12 23:27:57 2022
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Thu, 13 Oct 2022 10:27:57 +1300
Subject: [Rd] Question about grid.group compositing operators in cairo
In-Reply-To: <543be111-1ed2-24ad-51ca-4849a67a49eb@stat.auckland.ac.nz>
References: <0eaac5fb-b749-1470-c2a7-9f2f8215ace9@posteo.net>
 <c3debb04-04b8-90e8-2315-392105cd9db6@stat.auckland.ac.nz>
 <f581c979-44f0-3dc3-2c6f-015c2651b19c@stat.auckland.ac.nz>
 <6d240042-2017-a760-28d7-bf96d773fd90@posteo.net>
 <3e245b89-9c4f-dcbc-b310-5d3a25687af2@stat.auckland.ac.nz>
 <159821f0-0fc6-9054-c6bc-185102114e68@posteo.net>
 <c92574d5-f064-39c1-5fb4-05242607f19a@stat.auckland.ac.nz>
 <197c7a88-fb1c-49e1-7fc9-c1605abfef95@stat.auckland.ac.nz>
 <543be111-1ed2-24ad-51ca-4849a67a49eb@stat.auckland.ac.nz>
Message-ID: <2d7a8915-797f-4036-a489-21c1cd5be158@stat.auckland.ac.nz>

Hi

This issue has expanded to include the behaviour of compositing 
operators in R graphics more generally.

For the record, the discussion is continuing here ...

https://github.com/pmur002/rgraphics-compositing

Paul

On 4/10/22 09:20, Paul Murrell wrote:
> 
> Interim update:? I have spoken with Thomas Lin Pedersen (cc'ed), the 
> author/maintainer of 'ragg' and 'svglite', who is working on adding 
> group support for those graphics devices and he has voted in support of 
> the current Cairo implementation, so the needle has shifted towards 
> Cairo at this stage.
> 
> I still want to do more tests on other devices to gather more evidence.
> 
> Paul
> 
> p.s.? Attached (if it makes it through the filters) is a manual 
> modification of your original dsvg() example that has been changed so 
> that it produces the Cairo result.? This is probably not exactly how you 
> would want to implement the dsvg() solution, but it is at least a proof 
> of concept that the Cairo result can be produced in SVG.
> 
> On 30/09/22 10:49, Paul Murrell wrote:
>> Hi
>>
>> Some more thoughts ...
>>
>> <1>
>> I said before that currently, dev->group() does this ...
>>
>> [OVER] shape shape shape OP shape shape shape
>>
>> ... and one option would be an implicit group on 'src' and 'dst' like 
>> this ...
>>
>> ([OVER] shape shape shape) OP ([OVER] shape shape shape)
>>
>> ... but another approach could be just an implicit group on each 
>> shape, like this ...
>>
>> [OVER] ([OVER] shape) ([OVER] shape) OP ([OVER] shape) ([OVER] shape)
>>
>> That may be a better representation of what you are already doing with 
>> dsvg() ?? It may also better reflect what naturally occurs in some 
>> graphics systems.
>>
>> <2>
>> Changing the Cairo implementation to work like that would I think 
>> produce the same result as your dsvg() for ...
>>
>> grid.group(src, "in", dst)
>>
>> ... and it would make what constitutes more than one shape much less 
>> surprising ...
>>
>> gList(rectGrob(), rectGrob())? ## multiple shapes (obviously)
>> rectGrob(width=1:2/2)????????? ## multiple shapes (less obvious)
>> rectGrob(gp=gpar(col=, fill=)) ## NOT multiple shapes (no surprise)
>>
>> ... and it should not break any pre-existing non-group behaviour.
>>
>> <3>
>> One casualty from this third option would be that the following would 
>> no longer solve the overlapping fill and stroke problem ...
>>
>> grid.group(overlapRect, "source")
>>
>> ... although the fact that that currently works is really a bit 
>> surprising AND that result could still be achieved by explicitly 
>> drawing separate shapes ...
>>
>> grid.group(rectGrob(gp=gpar(col=rgb(1,0,0,.5), lwd=20, fill=NA)),
>> ??????????? "source",
>> ??????????? rectGrob(gp=gpar(col=NA, fill="green")))
>>
>> <4>
>> I need to try some of this out and also check in with some other 
>> people who I think are working on implementing groups on different 
>> graphics devices.
>>
>> <5>
>> In summary, don't go changing dsvg() too much just yet!
>>
>> Paul
>>
>> On 29/09/2022 1:30 pm, Paul Murrell wrote:
>>> Hi
>>>
>>> Would it work to explicitly record a filled-and-stroked shape as two 
>>> separate elements (one only filled and one only stroked) ?
>>>
>>> Then it should only be as hard to apply the active operator on both 
>>> of those elements as it is to apply the active operator to more than 
>>> one shape (?)
>>>
>>> Paul
>>>
>>> On 29/09/22 10:17, Panagiotis Skintzos wrote:
>>>> Thank you for the very thorough explanation Paul.
>>>>
>>>> To answer your question on 11: The dsvg device, simply defines svg
>>>> elements with their attributes (rect with fill & stroke in my 
>>>> examples).
>>>> It does not do any internal image processing like cairo.
>>>>
>>>> My concern is how to proceed with the implementation in dsvg.
>>>>
>>>> If I leave it as it is now, they're will be cases where it will give
>>>> different results from cairo (and perhaps other devices that will
>>>> implement group compositing in similar way).
>>>>
>>>> On the other hand It would be quite challenging in practice to simulate
>>>> the cairo implementation and apply first the fill and then the stroke
>>>> with the active operator, on the element itself.
>>>>
>>>> Any suggestions? :-)
>>>>
>>>> Panagiotis
>>>>
>>>>
>>>> On 28/9/22 02:56, Paul Murrell wrote:
>>>> ?> Hi
>>>> ?>
>>>> ?> Thanks for the code (and for the previous attachments).
>>>> ?>
>>>> ?> Some thoughts so far (HTML version with images attached) ...
>>>> ?>
>>>> ?> <1>
>>>> ?> As you have pointed out, the Cairo device draws a stroked-and-filled
>>>> ?> shape with two separate drawing operations: the path is filled and
>>>> ?> then the path is stroked.? I do not believe that there is any
>>>> ?> alternative in Cairo graphics (apart from filling and stroking as an
>>>> ?> isolated group and then drawing the group, which we will come 
>>>> back to).
>>>> ?>
>>>> ?> <2>
>>>> ?> This fill-then-stroke approach is easy to demonstrate just with a 
>>>> thick
>>>> ?> semitransparent border ...
>>>> ?>
>>>> ?> library(grid)
>>>> ?> overlapRect <- rectGrob(width=.5, height=.5,
>>>> ?> ??????????????????????? gp=gpar(fill="green", lwd=20,
>>>> ?> ??????????????????????????????? col=rgb(1,0,0,.5)))
>>>> ?> grid.newpage()
>>>> ?> grid.draw(overlapRect)
>>>> ?>
>>>> ?> <3>
>>>> ?> This fill-then-stroke approach is what happens on many (most?)
>>>> ?> graphics devices, including, for example, the core windows() device,
>>>> ?> the core quartz() device, the 'ragg' devices, and 'ggiraph'.? The
>>>> ?> latter is true because this is actually the defined behaviour for 
>>>> SVG ...
>>>> ?>
>>>> ?> https://www.w3.org/TR/SVG2/render.html#Elements 
>>>> <https://www.w3.org/TR/SVG2/render.html#Elements>
>>>> ?> https://www.w3.org/TR/SVG2/render.html#PaintingShapesAndText 
>>>> <https://www.w3.org/TR/SVG2/render.html#PaintingShapesAndText>
>>>> ?>
>>>> ?> <4>
>>>> ?> There are exceptions to the fill-then-stroke approach, including the
>>>> ?> core pdf() device, but I think they are in the minority.? The PDF
>>>> ?> language supports a "B" operator that only fills within the 
>>>> border (no
>>>> ?> overlap between fill and border).? Demonstrating this is complicated
>>>> ?> by the fact that not all PDF viewers support this correctly (e.g.,
>>>> ?> evince and Firefox do not;? ghostscript and chrome do)!
>>>> ?>
>>>> ?> <5>
>>>> ?> Forcing all R graphics devices to change the rendering of
>>>> ?> filled-and-stroked shapes to match the PDF definition instead of
>>>> ?> fill-then-stroke is unlikely to happen because it would impact a lot
>>>> ?> of graphics devices, it would break existing behaviour, it may be
>>>> ?> difficult/impossible for some devices, and it is not clear that 
>>>> it is
>>>> ?> the best approach anyway.
>>>> ?>
>>>> ?> <6>
>>>> ?> Finally getting back to your example, the fill-then-stroke approach
>>>> ?> produces some interesting results when applying compositing 
>>>> operators
>>>> ?> because the fill is drawn using the compositing operator to 
>>>> combine it
>>>> ?> with previous drawing and then the stroke is drawn using the
>>>> ?> compositing operator to combine it with *the result of combining the
>>>> ?> fill with previous drawing*. The result makes sense in terms of how
>>>> ?> the rendering works, but it probably fails the "principle of least
>>>> ?> surprise".
>>>> ?>
>>>> ?> srcRect <- rectGrob(2/3, 1/3, width=.6, height=.6,
>>>> ?> ??????????????????? gp=gpar(lwd = 5, fill=rgb(0, 0, 0.9, 0.4)))
>>>> ?> dstRect <- rectGrob(1/3, 2/3, width=.6, height=.6,
>>>> ?> ??????????????????? gp=gpar(lwd = 5, fill=rgb(0.7, 0, 0, 0.8)))
>>>> ?> grid.newpage()
>>>> ?> grid.group(srcRect, "in", dstRect)
>>>> ?>
>>>> ?> <7>
>>>> ?> This issue is not entirely unanticipated because it can arise
>>>> ?> slightly-less-unintentionally if we combine a 'src' and/or 'dst' 
>>>> that
>>>> ?> draw more than one shape, like this ...
>>>> ?>
>>>> ?> src <- circleGrob(3:4/5, r=.2, gp=gpar(col=NA, fill=2))
>>>> ?> dst <- circleGrob(1:2/5, r=.2, gp=gpar(col=NA, fill=3))
>>>> ?> grid.newpage()
>>>> ?> grid.group(src, "xor", dst)
>>>> ?>
>>>> ?> This was discussed in the Section "Compositing and blend modes" 
>>>> in the
>>>> ?> original technical report about groups and compositing ...
>>>> ?>
>>>> ?> 
>>>> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/groups/groups.html#userdetails <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/groups/groups.html#userdetails>
>>>> ?>
>>>> ?>
>>>> ?> <8>
>>>> ?> A solution to the problem of drawing more than one shape (above) 
>>>> is to
>>>> ?> take explicit control of how shapes are combined, *using explicit
>>>> ?> groups* ...
>>>> ?>
>>>> ?> grid.newpage()
>>>> ?> grid.group(groupGrob(src), "xor", dst)
>>>> ?>
>>>> ?> <9>
>>>> ?> Explicit groups can be used to solve the problem of overlapping fill
>>>> ?> and stroke (here we specify that the rectangle border should be
>>>> ?> combined with the rectangle fill using the "source" operator) ...
>>>> ?>
>>>> ?> grid.newpage()
>>>> ?> grid.group(overlapRect, "source")
>>>> ?>
>>>> ?> <10>
>>>> ?> Explicit groups can also be used to get the result that we might 
>>>> have
>>>> ?> originally expected for the "in" operator example (here we 
>>>> isolate the
>>>> ?> 'src' rectangle so that the border and the fill are combined 
>>>> together
>>>> ?> [using the default "over" operator] and then combined with the other
>>>> ?> rectangle using the "in" operator) ...
>>>> ?>
>>>> ?> grid.newpage()
>>>> ?> grid.group(groupGrob(srcRect), "in", dstRect)
>>>> ?>
>>>> ?> <11>
>>>> ?> A possible change would be to force an implicit group (with op=OVER)
>>>> ?> on the 'src' and 'dst' in dev->group().? I believe this is 
>>>> effectively
>>>> ?> what you are doing with your dsvg() device (?).
>>>> ?>
>>>> ?> Currently, dev->group() does this ...
>>>> ?>
>>>> ?> [OVER] shape shape shape OP shape shape shape
>>>> ?>
>>>> ?> ... and an implicit group on 'src' and 'dst' would do this ...
>>>> ?>
>>>> ?> ([OVER] shape shape shape) OP ([OVER] shape shape shape)
>>>> ?>
>>>> ?> An implicit (OVER) group would make it easier to combine multiple
>>>> ?> shapes with OVER (though only slightly) ...
>>>> ?>
>>>> ?> grid.group(src, OP, dst)
>>>> ?>
>>>> ?> ... instead of ...
>>>> ?>
>>>> ?> grid.group(groupGrob(src), OP, dst)
>>>> ?>
>>>> ?> On the other hand, an implicit (OVER) group would make it harder to
>>>> ?> combine multiple shapes with an operator other than OVER (by quite a
>>>> ?> lot?) ...
>>>> ?>
>>>> ?> grid.group(groupGrob(shape, OP, groupGrob(shape, OP, shape)), OP, 
>>>> dst)
>>>> ?>
>>>> ?> ... instead of ...
>>>> ?>
>>>> ?> grid.group(src, OP, dst)
>>>> ?>
>>>> ?> The complicating factor is that what constitutes more than one shape
>>>> ?> (or drawing operation) can be unexpected ...
>>>> ?>
>>>> ?> gList(rectGrob(), rectGrob())? ## obvious
>>>> ?> rectGrob(width=1:2/2)????????? ## less obvious
>>>> ?> rectGrob(gp=gpar(col=, fill=)) ## a bit of a surprise
>>>> ?>
>>>> ?> <12>
>>>> ?> In summary, while there is some temptation to add an implicit group
>>>> ?> around 'src' and 'dst' in a group, there are also reasons not to.
>>>> ?>
>>>> ?> Happy to hear further arguments on this.
>>>> ?>
>>>> ?> Paul
>>>> ?>
>>>> ?> On 28/09/2022 8:04 am, Panagiotis Skintzos wrote:
>>>> ?>> Here is the code again in text:
>>>> ?>>
>>>> ?>>
>>>> ?>> src <- rectGrob(2/3, 1/3, width=.6, height=.6, gp=gpar(lwd = 5,
>>>> ?>> fill=rgb(0, 0, 0.9, 0.4)))
>>>> ?>> dst <- rectGrob(1/3, 2/3, width=.6, height=.6, gp=gpar(lwd = 5,
>>>> ?>> fill=rgb(0.7, 0, 0, 0.8)))
>>>> ?>>
>>>> ?>> svg("cairo.in.svg", width = 5, height = 5)
>>>> ?>> grid.group(src, "in", dst)
>>>> ?>> dev.off()
>>>> ?>>
>>>> ?>>
>>>> ?>>
>>>> ?>> On 27/9/22 04:44, Paul Murrell wrote:
>>>> ?>> ?>
>>>> ?>> ?> Could you also please send me the SVG code that your device is
>>>> ?>> ?> generating for your example.? Thanks!
>>>> ?>> ?>
>>>> ?>> ?> Paul
>>>> ?>> ?>
>>>> ?>> ?> On 27/09/22 08:50, Paul Murrell wrote:
>>>> ?>> ?>> Hi
>>>> ?>> ?>>
>>>> ?>> ?>> Thanks for the report.? It certainly sounds like I have done
>>>> ?>> ?>> something stupid :)? For my debugging and testing could you 
>>>> please
>>>> ?>> ?>> share the R code from your tests ?? Thanks!
>>>> ?>> ?>>
>>>> ?>> ?>> Paul
>>>> ?>> ?>>
>>>> ?>> ?>> On 26/09/22 10:27, Panagiotis Skintzos wrote:
>>>> ?>> ?>>> Hello,
>>>> ?>> ?>>>
>>>> ?>> ?>>> I'm trying to update ggiraph package in graphic engine v15
>>>> ?>> ?>>> (currently we support up to v14).
>>>> ?>> ?>>>
>>>> ?>> ?>>> I've implemented the group operators and when I compare the 
>>>> outputs
>>>> ?>> ?>>> of ggiraph::dsvg with the outputs of svg/png, I noticed 
>>>> some weird
>>>> ?>> ?>>> results.
>>>> ?>> ?>>>
>>>> ?>> ?>>> Specifically, some operators in cairo (in, out, dest.in, 
>>>> dest.atop)
>>>> ?>> ?>>> give strange output, when any source element in the group 
>>>> has a
>>>> ?>> ?>>> stroke color defined.
>>>> ?>> ?>>>
>>>> ?>> ?>>> I attach three example images, where two stroked rectangles 
>>>> are
>>>> ?>> used
>>>> ?>> ?>>> as source (right) and destination (left).
>>>> ?>> ?>>>
>>>> ?>> ?>>> cairo.over.png shows the result of the over operator in cairo
>>>> ?>> ?>>>
>>>> ?>> ?>>> cairo.in.png shows the result of the in operator in cairo
>>>> ?>> ?>>>
>>>> ?>> ?>>> dsvg.in.png shows the result of the in operator in dsvg
>>>> ?>> ?>>>
>>>> ?>> ?>>>
>>>> ?>> ?>>> You can see the difference between cairo.in.png and 
>>>> dsvg.in.png. I
>>>> ?>> ?>>> found out why I get different results:
>>>> ?>> ?>>>
>>>> ?>> ?>>> In dsvg implementation there is one drawing operation: Draw 
>>>> the
>>>> ?>> ?>>> source element, as whole (fill and stroke) over the 
>>>> destination
>>>> ?>> ?>>> element (using feComposite filter)
>>>> ?>> ?>>>
>>>> ?>> ?>>> In cairo implementation though there are two operations: 
>>>> Apply the
>>>> ?>> ?>>> fill on source and draw over the destination and then apply 
>>>> the
>>>> ?>> ?>>> stroke and draw over the result of the previous operation.
>>>> ?>> ?>>>
>>>> ?>> ?>>> I'm not sure if this is intentional or not. Shouldn't the 
>>>> source
>>>> ?>> ?>>> element being drawn first as whole (fill and stroke with over
>>>> ?>> ?>>> operator) and then apply the group operator and draw it 
>>>> over the
>>>> ?>> ?>>> destination? It would seem more logical that way.
>>>> ?>> ?>>>
>>>> ?>> ?>>>
>>>> ?>> ?>>> Thanks,
>>>> ?>> ?>>>
>>>> ?>> ?>>> Panagiotis
>>>> ?>> ?>>>
>>>> ?>> ?>>>
>>>> ?>> ?>>> ______________________________________________
>>>> ?>> ?>>> R-devel at r-project.org mailing list
>>>> ?>> ?>>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>> ?>> <https://stat.ethz.ch/mailman/listinfo/r-devel 
>>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>>>> ?>> ?>>
>>>> ?>> ?>
>>>> ?>
>>>
>>
> 

-- 
Dr Paul Murrell
Te Kura Tatauranga | Department of Statistics
Waipapa Taumata Rau | The University of Auckland
Private Bag 92019, Auckland 1142, New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
www.stat.auckland.ac.nz/~paul/


From j@goreck| @end|ng |rom w|t@edu@p|  Thu Oct 13 23:59:01 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Thu, 13 Oct 2022 22:59:01 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
Message-ID: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>

Dear R devs,

I would like to raise a request for a simple helper function.
Utility function to extract package dependencies from DESCRIPTION file.

I do think that tools package is better place, for such a fundamental
functionality, than community packages.

tools pkg seems perfect fit (having already great function write_PACKAGES).

Functionality I am asking for is already in R svn repository since 2016, in
a branch tools4pkgs. Function is called 'packages.dcf'.
Another one 'repos.dcf' would be a good functional complementary to it.

Those two simple helper functions really makes it easier for organizations
to glue together usage of their own R packages repos and CRAN repo in a
smooth way. That could possibly help to offload CRAN from new submissions.

gh mirror link for easy preview:
https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419

Regards
Jan Gorecki

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Fri Oct 14 03:16:00 2022
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Thu, 13 Oct 2022 20:16:00 -0500
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
 <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
 <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>
 <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>
Message-ID: <25416.47184.786799.960415@rob.eddelbuettel.com>


On 10 October 2022 at 09:34, Henrik Bengtsson wrote:
| Thank you Peter for the quick fix.  Will this make it into R-patched
| to become R 4.2.2 soon?

I checked when you posted this and didn't reply -- but this is also not an
issue for littler so if you need alternative there is one

  $ Rscript --vanilla -e 42 0<&- 
  Fatal error: creating temporary file for '-e' failed
  $
  $ r -p -e 42 0<&-      # -p to force print
  [1] 42
  $ 

Dirk

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From pd@|gd @end|ng |rom gm@||@com  Fri Oct 14 15:07:35 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 14 Oct 2022 15:07:35 +0200
Subject: [Rd] Rscript -e EXPR fails to launch if stdin is closed
In-Reply-To: <A6D03905-1731-456C-8FB5-F4AA9D7F5F88@gmail.com>
References: <CAFDcVCTVBQknxZYbDx9T0d045M9G8M4xdYpr0RA5Qq_+OyxpUw@mail.gmail.com>
 <CE13E09D-A0D5-42E7-949B-32BF375351FE@gmail.com>
 <1219AA40-4A8E-4B77-B141-12154DD5095C@gmail.com>
 <CAFDcVCRrBq1A53ggJNozxR1fNz3SYTocgkzsCBs2Y9vwC51LpA@mail.gmail.com>
 <A6D03905-1731-456C-8FB5-F4AA9D7F5F88@gmail.com>
Message-ID: <F32CC8DE-612D-4DB7-96C9-7261254F0F68@gmail.com>

Done... -pd

> On 11 Oct 2022, at 10:53 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> There's still 2 weeks till code freeze for 4.2.2, and porting the fix would be trivial. As long as there is no risk that someone will get the bright idea of changing a critical package to depend on R >= 4.2.2...
> 
> - pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From net|kj@ @end|ng |rom gm@||@com  Fri Oct 14 16:14:01 2022
From: net|kj@ @end|ng |rom gm@||@com (=?UTF-8?Q?Jan_Net=C3=ADk?=)
Date: Fri, 14 Oct 2022 16:14:01 +0200
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
Message-ID: <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>

Hello Jan,

I have seen many packages that implemented dependencies "extraction" on
their own for internal purposes and today I was doing exactly that for
mine. It's not a big deal using read.dcf on DESCRIPTION. It was sufficient
for me, but I had to take care of some \n chars (the overall returned value
has some rough edges, in my opinion). However, the function from the branch
seems to not care about version requirements, which are crucial for me.
Maybe that is something to reconsider before merging.

Best,
Jan

p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl> napsal:

> Dear R devs,
>
> I would like to raise a request for a simple helper function.
> Utility function to extract package dependencies from DESCRIPTION file.
>
> I do think that tools package is better place, for such a fundamental
> functionality, than community packages.
>
> tools pkg seems perfect fit (having already great function write_PACKAGES).
>
> Functionality I am asking for is already in R svn repository since 2016, in
> a branch tools4pkgs. Function is called 'packages.dcf'.
> Another one 'repos.dcf' would be a good functional complementary to it.
>
> Those two simple helper functions really makes it easier for organizations
> to glue together usage of their own R packages repos and CRAN repo in a
> smooth way. That could possibly help to offload CRAN from new submissions.
>
> gh mirror link for easy preview:
>
> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>
> Regards
> Jan Gorecki
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Fri Oct 14 18:21:14 2022
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Fri, 14 Oct 2022 16:21:14 +0000 (UTC)
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
References: <962239794.1944131.1665764474121.ref@mail.yahoo.com>
Message-ID: <962239794.1944131.1665764474121@mail.yahoo.com>

I?think?'[.POSIXlt'?and?'[<-.POSIXlt'?don't?need?to?normalize?out-of-range?values.?I?think?they?just?make?same?length?for?all?components,?to?ensure?correct?extraction?or?replacement?for?arbitrary?index.

I?have?a?thought?of?adding?an?optional?argument?for?'as.POSIXlt'?applied?to?"POSIXlt"?object.?Possible?name:
normalize
adjust
fixup

To?allow?recycling?only?without?changing?content,?instead?of?TRUE?or?FALSE,?maybe?choice,?like
fixup?=?c("none",?"balance",?"normalize")
,?where?"normalize"?implies?"balance",?or
adjust?=?c("none",?"length",?"content",?"value")
,?where?"content"?and?"value"?are?synonymous.

By?the?way,?Inf?in?'sec'?component?is?out-of-range!


For?'gmtoff',?NA?or?0?should?be?put?for?unknown.?A?known?'gmtoff'?may?be?[ositive,?negative,?or?zero.?The?documentation?says
?gmtoff? (Optional.) The offset in seconds from GMT: positive
values are East of the meridian.  Usually ?NA? if unknown,
but ?0? could mean unknown.


dlt?<-?.POSIXlt(list(sec?=?c(-999,?10000?+?c(1:10,-Inf,?NA))?+?pi,
????????????????????????????????????????#?"out?of?range",?non-finite,?fractions
?????????????????????min?=?45L,?hour?=?c(21L,?3L,?NA,?4L),
?????????????????????mday?=?6L,?mon??=?c(11L,?NA,?3L),
?????????????????????year?=?116L,?wday?=?2L,?yday?=?340L,?isdst?=?1L))

as.POSIXct(dlt)[1]?is?NA?on?Linux?with?timezone?without?DST.?For?example,?after
Sys.setenv(TZ?=?"EST")


----------------
>>>>>?Martin?Maechler
>>>>>?????on?Wed,?12?Oct?2022?10:17:28?+0200?writes:

>>>>>?Kurt?Hornik
>>>>>?????on?Tue,?11?Oct?2022?16:44:13?+0200?writes:

>>>>>?Davis?Vaughan?writes:
????>>>?I've?got?a?bit?more?information?about?this?one.?It?seems?like?it
????>>>?(only??not?sure)?appears?when?`TZ?=?"UTC"`,?which?is?why?I?didn't?see
????>>>?it?before?on?my?Mac,?which?defaults?to?`TZ?=?""`.?I?think?this?is?at
????>>>?least?explainable?by?the?fact?that?those?"optional"?fields?aren't
????>>>?technically?needed?when?the?time?zone?is?UTC.

????>>?Exactly.??Debugging?`[<-.POSIlt`?with

????>>?x?<-?as.POSIXlt(as.POSIXct("2013-01-31",?tz?=?"America/Chicago"))
????>>?Sys.setenv(TZ?=?"UTC")
????>>?x[1]?<-?NA

????>>?shows?we?get?into

????>>?value?<-?unclass(as.POSIXlt(value))
????>>?if?(ici)?{
????>>?for?(n?in?names(x))?names(x[[n]])?<-?nms
????>>?}
????>>?for?(n?in?names(x))?x[[n]][i]?<-?value[[n]]

????>>?where

????>>?Browse[2]>?names(value)
????>>?[1]?"sec"???"min"???"hour"??"mday"??"mon"???"year"??"wday"??"yday"??"isdst"
????>>?Browse[2]>?names(x)
????>>?[1]?"sec"????"min"????"hour"???"mday"???"mon"????"year"???"wday"???"yday"
????>>?[9]?"isdst"??"zone"???"gmtoff"

????>>?Without?having?looked?at?the?code,?the?docs?say

????>>??zone??(Optional.)?The?abbreviation?for?the?time?zone?in?force?at
????>>?that?time:??""??if?unknown?(but??""??might?also?be?used?for
????>>?UTC).

????>>??gmtoff??(Optional.)?The?offset?in?seconds?from?GMT:?positive
????>>?values?are?East?of?the?meridian.??Usually??NA??if?unknown,
????>>?but??0??could?mean?unknown.

????>>?so?perhaps?we?should?fill?with?the?values?for?the?unknown?case?

????>>?-k

????>?Well,

????>?I?think?you?both?know??I'm?in?the?midst?of?dealing?with?these
????>?issues,?to?fix?both

????>?[.POSIXlt??and
????>?[<-.POSIXlt

????>?Yes,?one?needs?a?way?to?not?only?"fill"?the?partially?filled
????>?entries?but?also?to?*normalize*?out-of-range?values
????>?(say?negative?seconds,?minutes?>?60,?etc)

????>?All?this?is?available?in?our?C?code,?but?not?on?the?R?level,
????>?so?yesterday,?I?wrote?a?C?function?to?be?called?via?.Internal(.)
????>?from?a?new?R?that?provides?this.

????>?Provisionally?called

????>?balancePOSIXlt()

????>?because?it?both?balances?the?9?to?11?list-components?of?POSIXlt
????>?and?it?also?puts?all?numbers?of?(sec,?min,?hour,?mday,?mon)
????>?into?a?correct?range?(and?also?computes?correctl?wday?and?yday?numbers).
????>?but?I'm?happy?for?proposals?of?better?names.
????>?I?had?contemplated??validatePOSIXlt()?as?alternative,?but?then
????>?dismissed?that?as?in?some?sense?we?now?do?agree?that
????>?"imbalanced"?POSIXlt's?are?not?really?invalid?..

????>?..?and?yes,?to?Davis:??Even?though?I've?spent?so?many?hours?with
????>?POSIXlt,?POSIXct?and?Date?during?the?last?week,?I'm?still
????>?surprised?more?often?than?I?like?by?the?effects?of?timezone
????>?settings?there.

????>?Martin

I?have?committed?the?new?R?and?C?code?now,?defining??balancePOSIXlt(),
to?get?feedback?from?the?community.

I've?extended?the?documentation?in??help(DateTimeClasses),
and?notably?factored?out?the?description
of??POSIXlt??mentioning?the??"ragged"?and?"out-of-range"?cases.

This?needs?more?testing?and?experiments,?and?I?have?not
announced?it??NEWS??yet.

Planned?next?is?to?use?it?in??[.POSIXlt?and?[<-.POSIXlt
so?they?will?work?correctly.

But?please?share?your?thoughts,?propositions,?...

Martin


[snip]


From j@goreck| @end|ng |rom w|t@edu@p|  Fri Oct 14 23:32:50 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Fri, 14 Oct 2022 22:32:50 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
Message-ID: <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>

Hello Jan,

Thanks for confirming about many packages reinventing this missing
functionality.
packages.dcf was not meant handle versions. It just extracts names of
dependencies... Yes, such a simple thing, yet missing in base R.

Versions of packages can be controlled when setting up R pkgs repo. This is
how I used to handle it. Making a CRAN subset mirror of fixed version pkgs.
BTW. function for that is also included in mentioned branch. I am just not
proposing it, to increase the chance of having at least this simple,
missing, functionality merged.

Best
Jan

On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:

> Hello Jan,
>
> I have seen many packages that implemented dependencies "extraction" on
> their own for internal purposes and today I was doing exactly that for
> mine. It's not a big deal using read.dcf on DESCRIPTION. It was sufficient
> for me, but I had to take care of some \n chars (the overall returned value
> has some rough edges, in my opinion). However, the function from the branch
> seems to not care about version requirements, which are crucial for me.
> Maybe that is something to reconsider before merging.
>
> Best,
> Jan
>
> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
> napsal:
>
>> Dear R devs,
>>
>> I would like to raise a request for a simple helper function.
>> Utility function to extract package dependencies from DESCRIPTION file.
>>
>> I do think that tools package is better place, for such a fundamental
>> functionality, than community packages.
>>
>> tools pkg seems perfect fit (having already great function
>> write_PACKAGES).
>>
>> Functionality I am asking for is already in R svn repository since 2016,
>> in
>> a branch tools4pkgs. Function is called 'packages.dcf'.
>> Another one 'repos.dcf' would be a good functional complementary to it.
>>
>> Those two simple helper functions really makes it easier for organizations
>> to glue together usage of their own R packages repos and CRAN repo in a
>> smooth way. That could possibly help to offload CRAN from new submissions.
>>
>> gh mirror link for easy preview:
>>
>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>>
>> Regards
>> Jan Gorecki
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Sat Oct 15 00:34:18 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 14 Oct 2022 15:34:18 -0700
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
Message-ID: <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>

Hi Jan and Jan,

Can you explain a little more what exactly you want the non-recursive,
non-version aware dependencies from an individual package for?

Either way package_dependencies will do this for you* with a little
"aggressive convincing". It wants output from available.packages, but who
really cares what it wants? It's a function and we are people :)

> library(tools)
> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> package_dependencies("rtables", db, which = intersect(c("Depends",
"Suggests", "Imports", "LinkingTo"), colnames(db)))
$rtables
 [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
 [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
[11] "flextable"  "officer"    "stats"      "htmltools"  "grid"


The only gotcha that I see immediately is that "LinkingTo" isn't always
there (whereas it is with real output from available.packages). If you know
your package doesn't have that (or that it does) at call time , this
becomes a one-liner:

package_dependencies("rtables", db =
read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
c("Depends", "Suggests", "Imports"))
$rtables
 [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
 [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
[11] "flextable"  "officer"    "stats"      "htmltools"  "grid"

You can also trick it a slightly different way by giving it what it
actually wants

> tdir <- tempdir()
> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
"PACKAGES"))
[1] TRUE
> avl <- available.packages(paste0("file://", tdir))
> library(tools)
> package_dependencies("rtables", avl)
$rtables
[1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
[6] "grid"

> package_dependencies("rtables", avl, which = "all")
$rtables
 [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
 [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
[11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"

So the only real benefits I see that we'd be picking up here is automatic
filtering by priority, and automatic extraction of the package name from
the DESCRIPTION file. I'm not sure either of those warrant a new exported
function that R-core has to maintain forever.

Best,
~G

* I haven't tested this across all OSes, but I dont' know of any reason it
wouldn't work generally.

On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:

> Hello Jan,
>
> Thanks for confirming about many packages reinventing this missing
> functionality.
> packages.dcf was not meant handle versions. It just extracts names of
> dependencies... Yes, such a simple thing, yet missing in base R.
>
> Versions of packages can be controlled when setting up R pkgs repo. This is
> how I used to handle it. Making a CRAN subset mirror of fixed version pkgs.
> BTW. function for that is also included in mentioned branch. I am just not
> proposing it, to increase the chance of having at least this simple,
> missing, functionality merged.
>
> Best
> Jan
>
> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>
> > Hello Jan,
> >
> > I have seen many packages that implemented dependencies "extraction" on
> > their own for internal purposes and today I was doing exactly that for
> > mine. It's not a big deal using read.dcf on DESCRIPTION. It was
> sufficient
> > for me, but I had to take care of some \n chars (the overall returned
> value
> > has some rough edges, in my opinion). However, the function from the
> branch
> > seems to not care about version requirements, which are crucial for me.
> > Maybe that is something to reconsider before merging.
> >
> > Best,
> > Jan
> >
> > p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
> > napsal:
> >
> >> Dear R devs,
> >>
> >> I would like to raise a request for a simple helper function.
> >> Utility function to extract package dependencies from DESCRIPTION file.
> >>
> >> I do think that tools package is better place, for such a fundamental
> >> functionality, than community packages.
> >>
> >> tools pkg seems perfect fit (having already great function
> >> write_PACKAGES).
> >>
> >> Functionality I am asking for is already in R svn repository since 2016,
> >> in
> >> a branch tools4pkgs. Function is called 'packages.dcf'.
> >> Another one 'repos.dcf' would be a good functional complementary to it.
> >>
> >> Those two simple helper functions really makes it easier for
> organizations
> >> to glue together usage of their own R packages repos and CRAN repo in a
> >> smooth way. That could possibly help to offload CRAN from new
> submissions.
> >>
> >> gh mirror link for easy preview:
> >>
> >>
> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
> >>
> >> Regards
> >> Jan Gorecki
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From j@goreck| @end|ng |rom w|t@edu@p|  Sat Oct 15 08:14:36 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Sat, 15 Oct 2022 07:14:36 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
Message-ID: <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>

Hi Gabriel,

It's very nice usage you provided here. Maybe instead of adding new
function we could extend packages_depenedncies then? To accept file path to
dsc file.

What about repos.dcf? Maybe additional repositories could be an attribute
attached to returned character vector.

The use case is to, for a given package sources, obtain its dependencies,
so one can use that for installing them/mirroring CRAN subset, or whatever.
The later is especially important for a production environment where one
wants to have fixed version of packages, and mirroring relevant subset of
CRAN is the most simple, and IMO reliable, way to manage such environment.

Regards
Jan

On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:

> Hi Jan and Jan,
>
> Can you explain a little more what exactly you want the non-recursive,
> non-version aware dependencies from an individual package for?
>
> Either way package_dependencies will do this for you* with a little
> "aggressive convincing". It wants output from available.packages, but who
> really cares what it wants? It's a function and we are people :)
>
> > library(tools)
> > db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> > package_dependencies("rtables", db, which = intersect(c("Depends",
> "Suggests", "Imports", "LinkingTo"), colnames(db)))
> $rtables
>  [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>  [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>
>
> The only gotcha that I see immediately is that "LinkingTo" isn't always
> there (whereas it is with real output from available.packages). If you
> know your package doesn't have that (or that it does) at call time , this
> becomes a one-liner:
>
> package_dependencies("rtables", db =
> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
> c("Depends", "Suggests", "Imports"))
> $rtables
>  [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>  [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>
> You can also trick it a slightly different way by giving it what it
> actually wants
>
> > tdir <- tempdir()
> > file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
> "PACKAGES"))
> [1] TRUE
> > avl <- available.packages(paste0("file://", tdir))
> > library(tools)
> > package_dependencies("rtables", avl)
> $rtables
> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> [6] "grid"
>
> > package_dependencies("rtables", avl, which = "all")
> $rtables
>  [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>  [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>
> So the only real benefits I see that we'd be picking up here is automatic
> filtering by priority, and automatic extraction of the package name from
> the DESCRIPTION file. I'm not sure either of those warrant a new exported
> function that R-core has to maintain forever.
>
> Best,
> ~G
>
> * I haven't tested this across all OSes, but I dont' know of any reason it
> wouldn't work generally.
>
> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>
>> Hello Jan,
>>
>> Thanks for confirming about many packages reinventing this missing
>> functionality.
>> packages.dcf was not meant handle versions. It just extracts names of
>> dependencies... Yes, such a simple thing, yet missing in base R.
>>
>> Versions of packages can be controlled when setting up R pkgs repo. This
>> is
>> how I used to handle it. Making a CRAN subset mirror of fixed version
>> pkgs.
>> BTW. function for that is also included in mentioned branch. I am just not
>> proposing it, to increase the chance of having at least this simple,
>> missing, functionality merged.
>>
>> Best
>> Jan
>>
>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>>
>> > Hello Jan,
>> >
>> > I have seen many packages that implemented dependencies "extraction" on
>> > their own for internal purposes and today I was doing exactly that for
>> > mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>> sufficient
>> > for me, but I had to take care of some \n chars (the overall returned
>> value
>> > has some rough edges, in my opinion). However, the function from the
>> branch
>> > seems to not care about version requirements, which are crucial for me.
>> > Maybe that is something to reconsider before merging.
>> >
>> > Best,
>> > Jan
>> >
>> > p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>> > napsal:
>> >
>> >> Dear R devs,
>> >>
>> >> I would like to raise a request for a simple helper function.
>> >> Utility function to extract package dependencies from DESCRIPTION file.
>> >>
>> >> I do think that tools package is better place, for such a fundamental
>> >> functionality, than community packages.
>> >>
>> >> tools pkg seems perfect fit (having already great function
>> >> write_PACKAGES).
>> >>
>> >> Functionality I am asking for is already in R svn repository since
>> 2016,
>> >> in
>> >> a branch tools4pkgs. Function is called 'packages.dcf'.
>> >> Another one 'repos.dcf' would be a good functional complementary to it.
>> >>
>> >> Those two simple helper functions really makes it easier for
>> organizations
>> >> to glue together usage of their own R packages repos and CRAN repo in a
>> >> smooth way. That could possibly help to offload CRAN from new
>> submissions.
>> >>
>> >> gh mirror link for easy preview:
>> >>
>> >>
>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>> >>
>> >> Regards
>> >> Jan Gorecki
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Sat Oct 15 09:29:55 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Sat, 15 Oct 2022 00:29:55 -0700
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
Message-ID: <CAD4oTHHqZjJCtqSAChW1QJzuZuVm-eNo+gBMm-dcR24yQBfn2A@mail.gmail.com>

On Fri, Oct 14, 2022 at 11:14 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:

> Hi Gabriel,
>
> It's very nice usage you provided here. Maybe instead of adding new
> function we could extend packages_depenedncies then? To accept file path to
> dsc file.
>
> What about repos.dcf? Maybe additional repositories could be an attribute
> attached to returned character vector.
>
> The use case is to, for a given package sources, obtain its dependencies,
> so one can use that for installing them/mirroring CRAN subset, or whatever.
> The later is especially important for a production environment where one
> wants to have fixed version of packages, and mirroring relevant subset of
> CRAN is the most simple, and IMO reliable, way to manage such environment.
>

Right. Thats why I asked though, because this only makes sense to do
recursively (i.e. collectively). Packages cannot meaningfully be treated in
isolation in R. If you capture/mirror the non-recursive dependencies only,
your package won't be (re-)installable.

What you actually want is either a frozen slice of CRAN, or a description
of either your full package library, or the full recursive subset of it
relevant to a particular package. (switchr was designed to do both of these
things easily, as an aside). Neither of which is achievable by looking at
an individual DESCRIPTION file.

Here's another fun trick if you don't want to just use switchr and let it
take care of it for you:

> .libPaths()
[1] "/Users/gabrielbecker/Rlib/syswide-4.1.2"
[2] "/Library/Frameworks/R.framework/Versions/4.1/Resources/library"
> write_PACKAGES(.libPaths()[1], unpacked = TRUE, validate = FALSE)
> avl <- available.packages(paste0("file://", .libPaths()[1]))
> head(avl)
              Package         Version  Priority
abind         "abind"         "1.4-5"  NA
AnnotationDbi "AnnotationDbi" "1.56.2" NA
askpass       "askpass"       "1.1"    NA
assertthat    "assertthat"    "0.2.1"  NA
backports     "backports"     "1.4.1"  NA
base64enc     "base64enc"     "0.1-3"  NA
              Depends

abind         "R (>= 1.5.0)"

AnnotationDbi "R (>= 2.7.0), methods, utils, stats4, BiocGenerics
(>=\n0.29.2), Biobase (>= 1.17.0), IRanges"
askpass       NA

assertthat    NA

backports     "R (>= 3.0.0)"

base64enc     "R (>= 2.9.0)"

              Imports
 LinkingTo
abind         "methods, utils"                                       NA

AnnotationDbi "DBI, RSQLite, S4Vectors (>= 0.9.25), stats, KEGGREST" NA

askpass       "sys (>= 2.1)"                                         NA

assertthat    "tools"                                                NA

backports     NA                                                     NA

base64enc     NA                                                     NA

              Suggests


abind         NA


AnnotationDbi "hgu95av2.db, GO.db, org.Sc.sgd.db, org.At.tair.db,
RUnit,\nTxDb.Hsapiens.UCSC.hg19.knownGene, org.Hs.eg.db,
reactome.db,\nAnnotationForge, graph, EnsDb.Hsapiens.v75, BiocStyle, knitr"
askpass       "testthat"


assertthat    "testthat, covr"


backports     NA


base64enc     NA


              Enhances License              License_is_FOSS
abind         NA       "LGPL (>= 2)"        NA
AnnotationDbi NA       "Artistic-2.0"       NA
askpass       NA       "MIT + file LICENSE" NA
assertthat    NA       "GPL-3"              NA
backports     NA       "GPL-2 | GPL-3"      NA
base64enc     "png"    "GPL-2 | GPL-3"      NA
              License_restricts_use OS_type Archs               MD5sum
abind         NA                    NA      NA                  NA
AnnotationDbi NA                    NA      NA                  NA
askpass       NA                    NA      "askpass.so.dSYM"   NA
assertthat    NA                    NA      NA                  NA
backports     NA                    NA      "backports.so.dSYM" NA
base64enc     NA                    NA      "base64enc.so.dSYM" NA
              NeedsCompilation File
abind         "no"             NA
AnnotationDbi "no"             NA
askpass       "yes"            NA
assertthat    "no"             NA
backports     "yes"            NA
base64enc     "yes"            NA
              Repository
abind         "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
AnnotationDbi "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
askpass       "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
assertthat    "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
backports     "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
base64enc     "file:///Users/gabrielbecker/Rlib/syswide-4.1.2"
> package_dependencies("rtables", avl, recursive = TRUE)
$rtables
 [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
 [6] "grid"       "utils"      "digest"     "grDevices"  "base64enc"
[11] "rlang"      "fastmap"

> package_dependencies("rtables", avl, which = "all", recursive = TRUE)
$rtables
  [1] "methods"
  [2] "magrittr"
  [3] "formatters"
  [4] "stats"
  [5] "htmltools"
  [6] "grid"
  [7] "dplyr"
  [8] "tibble"

 <snip>
[653] "rjson"
[654] "rsolr"
[655] "rlecuyer"
[656] "filelock"

Now you should probably move the PACKAGES file somewhere else and not leave
it in your package library, but I trust this illustrated my point. Most of
the exported machinery is based on available.packages output, but that's
not really a meaningful blocker for this type of work. We can get
available.packages output if we need to. Remember the PACKAGES file is just
a bunch of DESCRIPTION files slightly trimmed and then appended one after
the other.

 This also shows why recursive and which=all don't really go together. In
my opinion (and thus switchr's) the correct thing to do is do all for the
package in question and then only hard dependencies of those packages
recursively. That will let you build the package's vignettes (if you care
about such things), but won't pull in hundreds or thousands of reverse deps.

Best,
~G



> Regards
> Jan
>
> On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
>
>> Hi Jan and Jan,
>>
>> Can you explain a little more what exactly you want the non-recursive,
>> non-version aware dependencies from an individual package for?
>>
>> Either way package_dependencies will do this for you* with a little
>> "aggressive convincing". It wants output from available.packages, but who
>> really cares what it wants? It's a function and we are people :)
>>
>> > library(tools)
>> > db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
>> > package_dependencies("rtables", db, which = intersect(c("Depends",
>> "Suggests", "Imports", "LinkingTo"), colnames(db)))
>> $rtables
>>  [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>>  [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>>
>>
>> The only gotcha that I see immediately is that "LinkingTo" isn't always
>> there (whereas it is with real output from available.packages). If you
>> know your package doesn't have that (or that it does) at call time , this
>> becomes a one-liner:
>>
>> package_dependencies("rtables", db =
>> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
>> c("Depends", "Suggests", "Imports"))
>> $rtables
>>  [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>>  [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>>
>> You can also trick it a slightly different way by giving it what it
>> actually wants
>>
>> > tdir <- tempdir()
>> > file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION",
>> file.path(tdir, "PACKAGES"))
>> [1] TRUE
>> > avl <- available.packages(paste0("file://", tdir))
>> > library(tools)
>> > package_dependencies("rtables", avl)
>> $rtables
>> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> [6] "grid"
>>
>> > package_dependencies("rtables", avl, which = "all")
>> $rtables
>>  [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>>  [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
>> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>>
>> So the only real benefits I see that we'd be picking up here is automatic
>> filtering by priority, and automatic extraction of the package name from
>> the DESCRIPTION file. I'm not sure either of those warrant a new exported
>> function that R-core has to maintain forever.
>>
>> Best,
>> ~G
>>
>> * I haven't tested this across all OSes, but I dont' know of any reason
>> it wouldn't work generally.
>>
>> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>>
>>> Hello Jan,
>>>
>>> Thanks for confirming about many packages reinventing this missing
>>> functionality.
>>> packages.dcf was not meant handle versions. It just extracts names of
>>> dependencies... Yes, such a simple thing, yet missing in base R.
>>>
>>> Versions of packages can be controlled when setting up R pkgs repo. This
>>> is
>>> how I used to handle it. Making a CRAN subset mirror of fixed version
>>> pkgs.
>>> BTW. function for that is also included in mentioned branch. I am just
>>> not
>>> proposing it, to increase the chance of having at least this simple,
>>> missing, functionality merged.
>>>
>>> Best
>>> Jan
>>>
>>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>>>
>>> > Hello Jan,
>>> >
>>> > I have seen many packages that implemented dependencies "extraction" on
>>> > their own for internal purposes and today I was doing exactly that for
>>> > mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>>> sufficient
>>> > for me, but I had to take care of some \n chars (the overall returned
>>> value
>>> > has some rough edges, in my opinion). However, the function from the
>>> branch
>>> > seems to not care about version requirements, which are crucial for me.
>>> > Maybe that is something to reconsider before merging.
>>> >
>>> > Best,
>>> > Jan
>>> >
>>> > p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>>> > napsal:
>>> >
>>> >> Dear R devs,
>>> >>
>>> >> I would like to raise a request for a simple helper function.
>>> >> Utility function to extract package dependencies from DESCRIPTION
>>> file.
>>> >>
>>> >> I do think that tools package is better place, for such a fundamental
>>> >> functionality, than community packages.
>>> >>
>>> >> tools pkg seems perfect fit (having already great function
>>> >> write_PACKAGES).
>>> >>
>>> >> Functionality I am asking for is already in R svn repository since
>>> 2016,
>>> >> in
>>> >> a branch tools4pkgs. Function is called 'packages.dcf'.
>>> >> Another one 'repos.dcf' would be a good functional complementary to
>>> it.
>>> >>
>>> >> Those two simple helper functions really makes it easier for
>>> organizations
>>> >> to glue together usage of their own R packages repos and CRAN repo in
>>> a
>>> >> smooth way. That could possibly help to offload CRAN from new
>>> submissions.
>>> >>
>>> >> gh mirror link for easy preview:
>>> >>
>>> >>
>>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>>> >>
>>> >> Regards
>>> >> Jan Gorecki
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-devel at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Sun Oct 16 02:31:03 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Sun, 16 Oct 2022 13:31:03 +1300
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
Message-ID: <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>


Jan,

I think using a single DCF as input is not very practical and would not be useful in the context you describe (creating self contained repos) since they typically concern a list of packages, but essentially splitting out the part of install.packages() which determines which files will be pulled from where would be very useful as it would be trivial to use it to create repository (what we always do in corporate environments) instead of installing the packages. I suspect that install packages is already too complex so instead of adding a flag to install.packages one could move that functionality into a separate function - we all do that constantly for the sites we manage, so it would be certainly something worthwhile.

Cheers,
Simon


> On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> 
> Hi Gabriel,
> 
> It's very nice usage you provided here. Maybe instead of adding new
> function we could extend packages_depenedncies then? To accept file path to
> dsc file.
> 
> What about repos.dcf? Maybe additional repositories could be an attribute
> attached to returned character vector.
> 
> The use case is to, for a given package sources, obtain its dependencies,
> so one can use that for installing them/mirroring CRAN subset, or whatever.
> The later is especially important for a production environment where one
> wants to have fixed version of packages, and mirroring relevant subset of
> CRAN is the most simple, and IMO reliable, way to manage such environment.
> 
> Regards
> Jan
> 
> On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
> 
>> Hi Jan and Jan,
>> 
>> Can you explain a little more what exactly you want the non-recursive,
>> non-version aware dependencies from an individual package for?
>> 
>> Either way package_dependencies will do this for you* with a little
>> "aggressive convincing". It wants output from available.packages, but who
>> really cares what it wants? It's a function and we are people :)
>> 
>>> library(tools)
>>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
>>> package_dependencies("rtables", db, which = intersect(c("Depends",
>> "Suggests", "Imports", "LinkingTo"), colnames(db)))
>> $rtables
>> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> 
>> 
>> The only gotcha that I see immediately is that "LinkingTo" isn't always
>> there (whereas it is with real output from available.packages). If you
>> know your package doesn't have that (or that it does) at call time , this
>> becomes a one-liner:
>> 
>> package_dependencies("rtables", db =
>> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
>> c("Depends", "Suggests", "Imports"))
>> $rtables
>> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> 
>> You can also trick it a slightly different way by giving it what it
>> actually wants
>> 
>>> tdir <- tempdir()
>>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
>> "PACKAGES"))
>> [1] TRUE
>>> avl <- available.packages(paste0("file://", tdir))
>>> library(tools)
>>> package_dependencies("rtables", avl)
>> $rtables
>> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> [6] "grid"
>> 
>>> package_dependencies("rtables", avl, which = "all")
>> $rtables
>> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
>> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>> 
>> So the only real benefits I see that we'd be picking up here is automatic
>> filtering by priority, and automatic extraction of the package name from
>> the DESCRIPTION file. I'm not sure either of those warrant a new exported
>> function that R-core has to maintain forever.
>> 
>> Best,
>> ~G
>> 
>> * I haven't tested this across all OSes, but I dont' know of any reason it
>> wouldn't work generally.
>> 
>> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> 
>>> Hello Jan,
>>> 
>>> Thanks for confirming about many packages reinventing this missing
>>> functionality.
>>> packages.dcf was not meant handle versions. It just extracts names of
>>> dependencies... Yes, such a simple thing, yet missing in base R.
>>> 
>>> Versions of packages can be controlled when setting up R pkgs repo. This
>>> is
>>> how I used to handle it. Making a CRAN subset mirror of fixed version
>>> pkgs.
>>> BTW. function for that is also included in mentioned branch. I am just not
>>> proposing it, to increase the chance of having at least this simple,
>>> missing, functionality merged.
>>> 
>>> Best
>>> Jan
>>> 
>>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>>> 
>>>> Hello Jan,
>>>> 
>>>> I have seen many packages that implemented dependencies "extraction" on
>>>> their own for internal purposes and today I was doing exactly that for
>>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>>> sufficient
>>>> for me, but I had to take care of some \n chars (the overall returned
>>> value
>>>> has some rough edges, in my opinion). However, the function from the
>>> branch
>>>> seems to not care about version requirements, which are crucial for me.
>>>> Maybe that is something to reconsider before merging.
>>>> 
>>>> Best,
>>>> Jan
>>>> 
>>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>>>> napsal:
>>>> 
>>>>> Dear R devs,
>>>>> 
>>>>> I would like to raise a request for a simple helper function.
>>>>> Utility function to extract package dependencies from DESCRIPTION file.
>>>>> 
>>>>> I do think that tools package is better place, for such a fundamental
>>>>> functionality, than community packages.
>>>>> 
>>>>> tools pkg seems perfect fit (having already great function
>>>>> write_PACKAGES).
>>>>> 
>>>>> Functionality I am asking for is already in R svn repository since
>>> 2016,
>>>>> in
>>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
>>>>> Another one 'repos.dcf' would be a good functional complementary to it.
>>>>> 
>>>>> Those two simple helper functions really makes it easier for
>>> organizations
>>>>> to glue together usage of their own R packages repos and CRAN repo in a
>>>>> smooth way. That could possibly help to offload CRAN from new
>>> submissions.
>>>>> 
>>>>> gh mirror link for easy preview:
>>>>> 
>>>>> 
>>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>>>>> 
>>>>> Regards
>>>>> Jan Gorecki
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From j@goreck| @end|ng |rom w|t@edu@p|  Mon Oct 17 09:39:09 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Mon, 17 Oct 2022 08:39:09 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
Message-ID: <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>

Gabriel and Simon

I completely agree with what you are saying.
The thing is that obtaining recursive deps, all/most whatever, is already
well supported in core R. What is missing is just this single functionality
I am requesting.

If you will look into the branch you can see there is mirror.packages
function meant to mirror a slice of CRAN. It is doing exactly what you
described: package_dependencies; to obtain recursive deps, then download
all, etc.
I would love to have this function provided by core R as well, but we need
to start somewhere.

There are other use cases as well.
For example CI, where one wants to install all/most dependencies and then
run R CMD check. Then we don't worry about recursive deps are they will be
resolved automatically.
I don't think it's reasonable to force users to use 3rd party packages to
handle such a common and simple use case. Otherwise one has to hard code
deps in CI script. Not robust at all.

packages.dcf and repos.dcf makes all that way easier, and are solid base
for building customized orchestration like mirroring slice of CRAN.

Best regards
Jan

On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Jan,
>
> I think using a single DCF as input is not very practical and would not be
> useful in the context you describe (creating self contained repos) since
> they typically concern a list of packages, but essentially splitting out
> the part of install.packages() which determines which files will be pulled
> from where would be very useful as it would be trivial to use it to create
> repository (what we always do in corporate environments) instead of
> installing the packages. I suspect that install packages is already too
> complex so instead of adding a flag to install.packages one could move that
> functionality into a separate function - we all do that constantly for the
> sites we manage, so it would be certainly something worthwhile.
>
> Cheers,
> Simon
>
>
> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >
> > Hi Gabriel,
> >
> > It's very nice usage you provided here. Maybe instead of adding new
> > function we could extend packages_depenedncies then? To accept file path
> to
> > dsc file.
> >
> > What about repos.dcf? Maybe additional repositories could be an attribute
> > attached to returned character vector.
> >
> > The use case is to, for a given package sources, obtain its dependencies,
> > so one can use that for installing them/mirroring CRAN subset, or
> whatever.
> > The later is especially important for a production environment where one
> > wants to have fixed version of packages, and mirroring relevant subset of
> > CRAN is the most simple, and IMO reliable, way to manage such
> environment.
> >
> > Regards
> > Jan
> >
> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com>
> wrote:
> >
> >> Hi Jan and Jan,
> >>
> >> Can you explain a little more what exactly you want the non-recursive,
> >> non-version aware dependencies from an individual package for?
> >>
> >> Either way package_dependencies will do this for you* with a little
> >> "aggressive convincing". It wants output from available.packages, but
> who
> >> really cares what it wants? It's a function and we are people :)
> >>
> >>> library(tools)
> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
> >> $rtables
> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >>
> >>
> >> The only gotcha that I see immediately is that "LinkingTo" isn't always
> >> there (whereas it is with real output from available.packages). If you
> >> know your package doesn't have that (or that it does) at call time ,
> this
> >> becomes a one-liner:
> >>
> >> package_dependencies("rtables", db =
> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
> >> c("Depends", "Suggests", "Imports"))
> >> $rtables
> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >>
> >> You can also trick it a slightly different way by giving it what it
> >> actually wants
> >>
> >>> tdir <- tempdir()
> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION",
> file.path(tdir,
> >> "PACKAGES"))
> >> [1] TRUE
> >>> avl <- available.packages(paste0("file://", tdir))
> >>> library(tools)
> >>> package_dependencies("rtables", avl)
> >> $rtables
> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> [6] "grid"
> >>
> >>> package_dependencies("rtables", avl, which = "all")
> >> $rtables
> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
> >>
> >> So the only real benefits I see that we'd be picking up here is
> automatic
> >> filtering by priority, and automatic extraction of the package name from
> >> the DESCRIPTION file. I'm not sure either of those warrant a new
> exported
> >> function that R-core has to maintain forever.
> >>
> >> Best,
> >> ~G
> >>
> >> * I haven't tested this across all OSes, but I dont' know of any reason
> it
> >> wouldn't work generally.
> >>
> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >>
> >>> Hello Jan,
> >>>
> >>> Thanks for confirming about many packages reinventing this missing
> >>> functionality.
> >>> packages.dcf was not meant handle versions. It just extracts names of
> >>> dependencies... Yes, such a simple thing, yet missing in base R.
> >>>
> >>> Versions of packages can be controlled when setting up R pkgs repo.
> This
> >>> is
> >>> how I used to handle it. Making a CRAN subset mirror of fixed version
> >>> pkgs.
> >>> BTW. function for that is also included in mentioned branch. I am just
> not
> >>> proposing it, to increase the chance of having at least this simple,
> >>> missing, functionality merged.
> >>>
> >>> Best
> >>> Jan
> >>>
> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
> >>>
> >>>> Hello Jan,
> >>>>
> >>>> I have seen many packages that implemented dependencies "extraction"
> on
> >>>> their own for internal purposes and today I was doing exactly that for
> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
> >>> sufficient
> >>>> for me, but I had to take care of some \n chars (the overall returned
> >>> value
> >>>> has some rough edges, in my opinion). However, the function from the
> >>> branch
> >>>> seems to not care about version requirements, which are crucial for
> me.
> >>>> Maybe that is something to reconsider before merging.
> >>>>
> >>>> Best,
> >>>> Jan
> >>>>
> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
> >>>> napsal:
> >>>>
> >>>>> Dear R devs,
> >>>>>
> >>>>> I would like to raise a request for a simple helper function.
> >>>>> Utility function to extract package dependencies from DESCRIPTION
> file.
> >>>>>
> >>>>> I do think that tools package is better place, for such a fundamental
> >>>>> functionality, than community packages.
> >>>>>
> >>>>> tools pkg seems perfect fit (having already great function
> >>>>> write_PACKAGES).
> >>>>>
> >>>>> Functionality I am asking for is already in R svn repository since
> >>> 2016,
> >>>>> in
> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
> >>>>> Another one 'repos.dcf' would be a good functional complementary to
> it.
> >>>>>
> >>>>> Those two simple helper functions really makes it easier for
> >>> organizations
> >>>>> to glue together usage of their own R packages repos and CRAN repo
> in a
> >>>>> smooth way. That could possibly help to offload CRAN from new
> >>> submissions.
> >>>>>
> >>>>> gh mirror link for easy preview:
> >>>>>
> >>>>>
> >>>
> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
> >>>>>
> >>>>> Regards
> >>>>> Jan Gorecki
> >>>>>
> >>>>>        [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From c@@rd|@g@bor @end|ng |rom gm@||@com  Sun Oct 16 19:35:07 2022
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 16 Oct 2022 19:35:07 +0200
Subject: [Rd] Installation failure in non-UTF-8 MBCS locale
Message-ID: <CABtg=KkqmJ9JhLw0goeFB5eXsr0hMjgJzAi4cz2VU23Zrwht0A@mail.gmail.com>

I am sorry, part of the output is garbled, as the email's encoding is
different, but the error is hopefully still clear.

This is Ubuntu 20.04, yesterday's R devel or R release, in the zh_CN locale.

The zh_CN.UTF-8 locale is fine, and it is a much better option, so I
am not sure if this is considered to be a bug.

> install.packages("evaluate")
?????????????'/root/R/x86_64-pc-linux-gnu-library/4.3'
(???'lib'???????)
???URL??https://packagemanager.rstudio.com/all/__linux__/focal/latest/src/contrib/evaluate_0.17.tar.gz'
Content type 'binary/octet-stream' length 25984 bytes (25 KB)
==================================================
downloaded 25 KB

* installing *source* package 'evaluate' ...
** ?????'evaluate'????????????MD5?????
** using staged installation
Warning in parse(con, encoding = "UTF-8") :
  argument encoding="UTF-8" is ignored in MBCS locales
Error : invalid multibyte character in parser (<input>:11:32)
ERROR: installing package DESCRIPTION failed for package 'evaluate'
* removing '/root/R/x86_64-pc-linux-gnu-library/4.3/evaluate'

????????????
'/tmp/Rtmp3O0zlO/downloaded_packages'??
Warning message:
In install.packages("evaluate") : ?????????'evaluate'?????????????0

R-release produces the same error.

Dockerfile to reproduce this:

FROM ubuntu:20.04
RUN apt-get -y update && apt-get -y install curl locales
RUN curl -Ls https://github.com/r-lib/rig/releases/download/latest/rig-linux-latest.tar.gz
| tar xz -C /usr/local
RUN rig add devel
RUN rig add release
RUN locale-gen zh_CN
RUN uname -a
RUN R -q -e 'sessionInfo()'
RUN LC_ALL=zh_CN R -q -e 'install.packages("evaluate")'

G.


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Oct 17 11:23:41 2022
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 17 Oct 2022 11:23:41 +0200
Subject: [Rd] Installation failure in non-UTF-8 MBCS locale
In-Reply-To: <CABtg=KkqmJ9JhLw0goeFB5eXsr0hMjgJzAi4cz2VU23Zrwht0A@mail.gmail.com>
References: <CABtg=KkqmJ9JhLw0goeFB5eXsr0hMjgJzAi4cz2VU23Zrwht0A@mail.gmail.com>
Message-ID: <132c7cf1-e81b-fb15-af2b-1d2d542dd076@gmail.com>


On 10/16/22 19:35, G?bor Cs?rdi wrote:
> I am sorry, part of the output is garbled, as the email's encoding is
> different, but the error is hopefully still clear.
>
> This is Ubuntu 20.04, yesterday's R devel or R release, in the zh_CN locale.
>
> The zh_CN.UTF-8 locale is fine, and it is a much better option, so I
> am not sure if this is considered to be a bug.

Right, one should use UTF-8 (on all platforms) as the locale encoding.

For historical reasons, one can still parse UTF-8 when R is running e.g. 
in Latin 1 locale. This is still supported as older Windows systems 
don't use UTF-8 as the native encoding, yet.

When R runs in a non-UTF-8 multi-byte locale, it cannot parse UTF-8 R 
input files. This is due to how the parser works and supporting that 
would require a major rewrite which would not be worth the effort 
(instead effort has been spent on supporting UTF-8 as the native 
encoding on Windows).

Best
Tomas

>
>> install.packages("evaluate")
> ?????????????'/root/R/x86_64-pc-linux-gnu-library/4.3'
> (???'lib'???????)
> ???URL??https://packagemanager.rstudio.com/all/__linux__/focal/latest/src/contrib/evaluate_0.17.tar.gz'
> Content type 'binary/octet-stream' length 25984 bytes (25 KB)
> ==================================================
> downloaded 25 KB
>
> * installing *source* package 'evaluate' ...
> ** ?????'evaluate'????????????MD5?????
> ** using staged installation
> Warning in parse(con, encoding = "UTF-8") :
>    argument encoding="UTF-8" is ignored in MBCS locales
> Error : invalid multibyte character in parser (<input>:11:32)
> ERROR: installing package DESCRIPTION failed for package 'evaluate'
> * removing '/root/R/x86_64-pc-linux-gnu-library/4.3/evaluate'
>
> ????????????
> '/tmp/Rtmp3O0zlO/downloaded_packages'??
> Warning message:
> In install.packages("evaluate") : ?????????'evaluate'?????????????0
>
> R-release produces the same error.
>
> Dockerfile to reproduce this:
>
> FROM ubuntu:20.04
> RUN apt-get -y update && apt-get -y install curl locales
> RUN curl -Ls https://github.com/r-lib/rig/releases/download/latest/rig-linux-latest.tar.gz
> | tar xz -C /usr/local
> RUN rig add devel
> RUN rig add release
> RUN locale-gen zh_CN
> RUN uname -a
> RUN R -q -e 'sessionInfo()'
> RUN LC_ALL=zh_CN R -q -e 'install.packages("evaluate")'
>
> G.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 18 10:56:25 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 18 Oct 2022 10:56:25 +0200
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <962239794.1944131.1665764474121@mail.yahoo.com>
References: <962239794.1944131.1665764474121.ref@mail.yahoo.com>
 <962239794.1944131.1665764474121@mail.yahoo.com>
Message-ID: <20221018085625.CBFB82C1607@lynne.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Fri, 14 Oct 2022 16:21:14 +0000 (UTC) writes:

    > I think '[.POSIXlt' and '[<-.POSIXlt' don't need to
    > normalize out-of-range values. I think they just make same
    > length for all components, to ensure correct extraction or
    > replacement for arbitrary index.

Yes, you are right; this is definitely correct...
and would be more efficient.

At the moment, we were mostly focused on *correct* behaviour in
the case of "ragged" and/or out-of-range  POSIXlt objects.


    > I have a thought of adding an optional argument for 'as.POSIXlt' applied to "POSIXlt" object. Possible name:
    > normalize adjust fixup

    > To allow recycling only without changing content, instead of TRUE or FALSE, maybe choice, like
    > fixup = c("none", "balance", "normalize")
    > , where "normalize" implies "balance", or
    > adjust = c("none", "length", "content", "value")
    > , where "content" and "value" are synonymous.

Such an optional argument for as.POSIXlt() would be a
possibility and could replace the new and for now still somewhat
experimental  balancePOSIXlt().

+: One advantage of (one of the above proposals)
   would be that it does not take up a new function name.

-: OTOH, it may be overdoing the semantics

     as.POSIXlt(<POSIXlt>, <some> = <other>)

  and it may be harder to understand by non-sophisticated R users,
  because as.POSIXlt() is a generic with several methods, and
  these extra arguments would probably only apply to the
  as.POSIXlt.default() method and there *only* for the case where
  the argument inherits from "POSIXlt" .. and all that being
  somewhat subtle to see for Joe Average UseR

I agree that it will make sense to get an R-level version,
either using new arguments in  as.POSIXlt() or (still my preference)
in balancePOSIXlt() to allow to "only fill all components".

HOWEVER note that the "filling" (by recycling) and no extra
checking will often lead to internally inconsistent lt objects.
Eg. Daylight saving time  (isdst = 1 or not) can only be known
when the day (and hour) is known and that can be shifted by out-of-range
sec/min/hour .. ((and of course for 1 hour per year, a time hour=2 will
                  *need* specification of isdst in order to know which of
		  the 2:<min>:<sec>  is meant))
also  $wday and $yday  (who are described as read-only) also can
only be checked after validation or "in-ranging" of the
sec/min/hour/mday/mon components so their simple recycling will typically
be incorrect.

That's why I had opted to *mainly* do full "balancing" (in my
sense), i.e., simultaneous both filling and "in-ranging".



    > By the way, Inf in 'sec' component is out-of-range!

Yes, the non-finite "values" {+/-Inf, NaN, NA}  are all "special", and we had decided
to allow them for compatibility with classes "Date" and "POSIXct".

BTW,  a few days ago, I have updated the
help("DateTimeClasses")  page  in R-devel  to document a bit
more, notably that "ragged" and out-of-range POSIXlt  may exist...
see (the always +- current R-devel Help pages at)
https://stat.ethz.ch/R-manual/R-devel/library/base/html/DateTimeClasses.html


    > For 'gmtoff', NA or 0 should be put for unknown. A known 'gmtoff' may be [ositive, negative, or zero. The documentation says
    > ?gmtoff? (Optional.) The offset in seconds from GMT:
    > positive values are East of the meridian.  Usually ?NA? if
    > unknown, but ?0? could mean unknown.


    > dlt <- .POSIXlt(list(sec = c(-999, 10000 + c(1:10,-Inf, NA)) + pi,
    >                                         # "out of range", non-finite, fractions
    >                      min = 45L, hour = c(21L, 3L, NA, 4L),
    >                      mday = 6L, mon  = c(11L, NA, 3L),
    >                      year = 116L, wday = 2L, yday = 340L, isdst = 1L))

    > as.POSIXct(dlt)[1] is NA on Linux with timezone without DST. For example, after
    > Sys.setenv(TZ = "EST")

Hmm... I needed time to look at the above. Indeed, one gets NA (and has in
previous versions of R) in such a case.

After applying  balancePOSIXlt(), one no longer gets NA.
Are you proposing that we should do that (or possibly simple recycling)
in as.POSIXct.POSIXlt() ?

Martin

    > ----------------
    >>>>>>  Martin Maechler
    >>>>>>      on Wed, 12 Oct 2022 10:17:28 +0200 writes:

    >>>>>>  Kurt Hornik
    >>>>>>      on Tue, 11 Oct 2022 16:44:13 +0200 writes:

    >>>>>>  Davis Vaughan writes:

 [.............]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Oct 22 14:12:47 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 22 Oct 2022 14:12:47 +0200
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <20221018085625.CBFB82C1607@lynne.math.ethz.ch>
References: <962239794.1944131.1665764474121.ref@mail.yahoo.com>
 <962239794.1944131.1665764474121@mail.yahoo.com>
 <20221018085625.CBFB82C1607@lynne.math.ethz.ch>
Message-ID: <25427.56895.726279.318336@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Tue, 18 Oct 2022 10:56:25 +0200 writes:

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Fri, 14 Oct 2022 16:21:14 +0000 (UTC) writes:

    >> I think '[.POSIXlt' and '[<-.POSIXlt' don't need to
    >> normalize out-of-range values. I think they just make
    >> same length for all components, to ensure correct
    >> extraction or replacement for arbitrary index.

    > Yes, you are right; this is definitely correct...  and
    > would be more efficient.

    > At the moment, we were mostly focused on *correct*
    > behaviour in the case of "ragged" and/or out-of-range
    > POSIXlt objects.


    >> I have a thought of adding an optional argument for
    >> 'as.POSIXlt' applied to "POSIXlt" object. Possible name:
    >> normalize adjust fixup

    >> To allow recycling only without changing content, instead
    >> of TRUE or FALSE, maybe choice, like fixup = c("none",
    >> "balance", "normalize") , where "normalize" implies
    >> "balance", or adjust = c("none", "length", "content",
    >> "value") , where "content" and "value" are synonymous.

    > Such an optional argument for as.POSIXlt() would be a
    > possibility and could replace the new and for now still
    > somewhat experimental balancePOSIXlt().

    > +: One advantage of (one of the above proposals) would
    > be that it does not take up a new function name.

    > -: OTOH, it may be overdoing the semantics

    >      as.POSIXlt(<POSIXlt>, <some> = <other>)

    >   and it may be harder to understand by
    > non-sophisticated R users, because as.POSIXlt() is a
    > generic with several methods, and these extra arguments
    > would probably only apply to the as.POSIXlt.default()
    > method and there *only* for the case where the argument
    > inherits from "POSIXlt" .. and all that being somewhat
    > subtle to see for Joe Average UseR

    > I agree that it will make sense to get an R-level
    > version, either using new arguments in as.POSIXlt() or
    > (still my preference) in balancePOSIXlt() to allow to
    > "only fill all components".

    > HOWEVER note that the "filling" (by recycling) and no
    > extra checking will often lead to internally
    > inconsistent lt objects.  Eg. Daylight saving time
    > (isdst = 1 or not) can only be known when the day (and
    > hour) is known and that can be shifted by out-of-range
    > sec/min/hour .. ((and of course for 1 hour per year, a
    > time hour=2 will *need* specification of isdst in order
    > to know which of the 2:<min>:<sec> is meant)) also $wday
    > and $yday (who are described as read-only) also can only
    > be checked after validation or "in-ranging" of the
    > sec/min/hour/mday/mon components so their simple
    > recycling will typically be incorrect.

    > That's why I had opted to *mainly* do full "balancing"
    > (in my sense), i.e., simultaneous both filling and
    > "in-ranging".

A few hours ago [R-devel svn rev 83156; 2022-10-22 10:18:38 +0200]
I have committed an enhanced version of balancePOSIXlt()  which
now has an optional 'fill.only = F/T' rgument.
When TRUE (not by default), it will only do the "filling", i.e.,
recyclying of less-than-full-length components, without any
"in-ranging" nor musch further validity checking.

Currently, almost all POSIXlt methods using balancePOSIXlt(),
notably 
		[.POSIXlt    and    [<-.POSIXlt

use  balancePOSIXlt(x, fill.only=TRUE ..)
and hence are almost as fast as previously (when they did no
balancing and gave sometimes wrong results or errored in case of
partially filled POSIXlt).



    >> By the way, Inf in 'sec' component is out-of-range!

    > Yes, the non-finite "values" {+/-Inf, NaN, NA} are all
    > "special", and we had decided to allow them for
    > compatibility with classes "Date" and "POSIXct".

    > BTW, a few days ago, I have updated the
    > help("DateTimeClasses") page in R-devel to document a
    > bit more, notably that "ragged" and out-of-range POSIXlt
    > may exist...  see (the always +- current R-devel Help
    > pages at)
    > https://stat.ethz.ch/R-manual/R-devel/library/base/html/DateTimeClasses.html


    >> For 'gmtoff', NA or 0 should be put for unknown. A known
    >> 'gmtoff' may be [ositive, negative, or zero. The
    >> documentation says ?gmtoff? (Optional.) The offset in
    >> seconds from GMT: positive values are East of the
    >> meridian.  Usually ?NA? if unknown, but ?0? could mean
    >> unknown.


    >> dlt <- .POSIXlt(list(sec = c(-999, 10000 + c(1:10,-Inf,
    >> NA)) + pi, # "out of range", non-finite, fractions min =
    >> 45L, hour = c(21L, 3L, NA, 4L), mday = 6L, mon = c(11L,
    >> NA, 3L), year = 116L, wday = 2L, yday = 340L, isdst =
    >> 1L))

    >> as.POSIXct(dlt)[1] is NA on Linux with timezone without
    >> DST. For example, after Sys.setenv(TZ = "EST")

    > Hmm... I needed time to look at the above. Indeed, one
    > gets NA (and has in previous versions of R) in such a
    > case.

    > After applying balancePOSIXlt(), one no longer gets NA.
    > Are you proposing that we should do that (or possibly
    > simple recycling) in as.POSIXct.POSIXlt() ?

I am still waiting for comments (also by others) or other
remarks or answers on this question/topic..

Martin


From ch@r||e@g@o @end|ng |rom @h|kokuchuo@net  Sat Oct 22 01:52:09 2022
From: ch@r||e@g@o @end|ng |rom @h|kokuchuo@net (Charlie Gao)
Date: Sat, 22 Oct 2022 00:52:09 +0100
Subject: [Rd] R_GetCurrentEnv() not working as intended
Message-ID: <51be8f23-d595-eb4d-9e0c-1b3f49b23a59@shikokuchuo.net>

Dear all,

I am attempting to use `R_GetCurrentEnv()` to return the current 
environment within C code, but it seems to always return the global 
environment.

Specifically, I would like to use it as an argument to R_NewEnv() so it 
is created with the correct enclosing environment. I also have functions 
in the environment that reference symbols in the closure and I would 
also like to use `R_GetCurrentEnv()` as an argument to `SET_CLOENV()`.

My workaround at the moment is to pass `environment()` as one of the 
arguments to the `.Call()`. For the actual code I am referring to:

https://github.com/shikokuchuo/nanonext/blob/main/src/aio.c#L516-L535

where I am currently passing `environment()` as 'clo' whereas ideally I 
would be able to use `R_GetCurrentEnv()` instead.

There is an open Bugzilla report from 2020 that says `R_GetCurrentEnv()` 
only returns the base namespace from within a `.Call()`, however I see 
that the proposed patch has already been adopted in the R source.

It seems that the function was introduced (fairly) recently in R 3.6, 
presumably for such uses. I would like to know if this is not the case 
or else confirmation that this is an outstanding bug.

Thanks,

Charlie


From j@goreck| @end|ng |rom w|t@edu@p|  Fri Oct 28 21:18:17 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Fri, 28 Oct 2022 20:18:17 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
Message-ID: <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>

Gabriel,

I am trying to design generic solution that could be applied to
arbitrary package. Therefore I went with the latter solution you
proposed.
If we wouldn't have to exclude base packages, then its a 3 liner

file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
db<-available.packages(paste0("file://", tdir));
utils::install.packages(tools::package_dependencies("pkgname", db,
which="most")[[1L]])

As you noticed, we still have to filter out base packages. Otherwise
it won't be a robust utility that can be used in CI. Therefore we have
to add a call to tools:::.get_standard_package_names() which is an
internal function (as of now). Not only complicating the call but also
putting the functionality outside of safe use.

Considering above, don't you agree that the following one liner could
nicely address the problem? The problem that hundreds/thousands of
packages are now addressing in their CI scripts by using a third party
packages.

utils::install.packages(packages.dcf("DESCRIPTION", which="most"))

It is hard to me to understand why R members don't consider this basic
functionality to be part of base R. Possibly they just don't need it
themselves. Yet isn't this sufficient that hundreds/thousands of
packages does need this functionality?

Best regards,
Jan

On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>
> Gabriel and Simon
>
> I completely agree with what you are saying.
> The thing is that obtaining recursive deps, all/most whatever, is already well supported in core R. What is missing is just this single functionality I am requesting.
>
> If you will look into the branch you can see there is mirror.packages function meant to mirror a slice of CRAN. It is doing exactly what you described: package_dependencies; to obtain recursive deps, then download all, etc.
> I would love to have this function provided by core R as well, but we need to start somewhere.
>
> There are other use cases as well.
> For example CI, where one wants to install all/most dependencies and then run R CMD check. Then we don't worry about recursive deps are they will be resolved automatically.
> I don't think it's reasonable to force users to use 3rd party packages to handle such a common and simple use case. Otherwise one has to hard code deps in CI script. Not robust at all.
>
> packages.dcf and repos.dcf makes all that way easier, and are solid base for building customized orchestration like mirroring slice of CRAN.
>
> Best regards
> Jan
>
> On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>
>> Jan,
>>
>> I think using a single DCF as input is not very practical and would not be useful in the context you describe (creating self contained repos) since they typically concern a list of packages, but essentially splitting out the part of install.packages() which determines which files will be pulled from where would be very useful as it would be trivial to use it to create repository (what we always do in corporate environments) instead of installing the packages. I suspect that install packages is already too complex so instead of adding a flag to install.packages one could move that functionality into a separate function - we all do that constantly for the sites we manage, so it would be certainly something worthwhile.
>>
>> Cheers,
>> Simon
>>
>>
>> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >
>> > Hi Gabriel,
>> >
>> > It's very nice usage you provided here. Maybe instead of adding new
>> > function we could extend packages_depenedncies then? To accept file path to
>> > dsc file.
>> >
>> > What about repos.dcf? Maybe additional repositories could be an attribute
>> > attached to returned character vector.
>> >
>> > The use case is to, for a given package sources, obtain its dependencies,
>> > so one can use that for installing them/mirroring CRAN subset, or whatever.
>> > The later is especially important for a production environment where one
>> > wants to have fixed version of packages, and mirroring relevant subset of
>> > CRAN is the most simple, and IMO reliable, way to manage such environment.
>> >
>> > Regards
>> > Jan
>> >
>> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
>> >
>> >> Hi Jan and Jan,
>> >>
>> >> Can you explain a little more what exactly you want the non-recursive,
>> >> non-version aware dependencies from an individual package for?
>> >>
>> >> Either way package_dependencies will do this for you* with a little
>> >> "aggressive convincing". It wants output from available.packages, but who
>> >> really cares what it wants? It's a function and we are people :)
>> >>
>> >>> library(tools)
>> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
>> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
>> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
>> >> $rtables
>> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >>
>> >>
>> >> The only gotcha that I see immediately is that "LinkingTo" isn't always
>> >> there (whereas it is with real output from available.packages). If you
>> >> know your package doesn't have that (or that it does) at call time , this
>> >> becomes a one-liner:
>> >>
>> >> package_dependencies("rtables", db =
>> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
>> >> c("Depends", "Suggests", "Imports"))
>> >> $rtables
>> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >>
>> >> You can also trick it a slightly different way by giving it what it
>> >> actually wants
>> >>
>> >>> tdir <- tempdir()
>> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
>> >> "PACKAGES"))
>> >> [1] TRUE
>> >>> avl <- available.packages(paste0("file://", tdir))
>> >>> library(tools)
>> >>> package_dependencies("rtables", avl)
>> >> $rtables
>> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> [6] "grid"
>> >>
>> >>> package_dependencies("rtables", avl, which = "all")
>> >> $rtables
>> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
>> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>> >>
>> >> So the only real benefits I see that we'd be picking up here is automatic
>> >> filtering by priority, and automatic extraction of the package name from
>> >> the DESCRIPTION file. I'm not sure either of those warrant a new exported
>> >> function that R-core has to maintain forever.
>> >>
>> >> Best,
>> >> ~G
>> >>
>> >> * I haven't tested this across all OSes, but I dont' know of any reason it
>> >> wouldn't work generally.
>> >>
>> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >>
>> >>> Hello Jan,
>> >>>
>> >>> Thanks for confirming about many packages reinventing this missing
>> >>> functionality.
>> >>> packages.dcf was not meant handle versions. It just extracts names of
>> >>> dependencies... Yes, such a simple thing, yet missing in base R.
>> >>>
>> >>> Versions of packages can be controlled when setting up R pkgs repo. This
>> >>> is
>> >>> how I used to handle it. Making a CRAN subset mirror of fixed version
>> >>> pkgs.
>> >>> BTW. function for that is also included in mentioned branch. I am just not
>> >>> proposing it, to increase the chance of having at least this simple,
>> >>> missing, functionality merged.
>> >>>
>> >>> Best
>> >>> Jan
>> >>>
>> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>> >>>
>> >>>> Hello Jan,
>> >>>>
>> >>>> I have seen many packages that implemented dependencies "extraction" on
>> >>>> their own for internal purposes and today I was doing exactly that for
>> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>> >>> sufficient
>> >>>> for me, but I had to take care of some \n chars (the overall returned
>> >>> value
>> >>>> has some rough edges, in my opinion). However, the function from the
>> >>> branch
>> >>>> seems to not care about version requirements, which are crucial for me.
>> >>>> Maybe that is something to reconsider before merging.
>> >>>>
>> >>>> Best,
>> >>>> Jan
>> >>>>
>> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>> >>>> napsal:
>> >>>>
>> >>>>> Dear R devs,
>> >>>>>
>> >>>>> I would like to raise a request for a simple helper function.
>> >>>>> Utility function to extract package dependencies from DESCRIPTION file.
>> >>>>>
>> >>>>> I do think that tools package is better place, for such a fundamental
>> >>>>> functionality, than community packages.
>> >>>>>
>> >>>>> tools pkg seems perfect fit (having already great function
>> >>>>> write_PACKAGES).
>> >>>>>
>> >>>>> Functionality I am asking for is already in R svn repository since
>> >>> 2016,
>> >>>>> in
>> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
>> >>>>> Another one 'repos.dcf' would be a good functional complementary to it.
>> >>>>>
>> >>>>> Those two simple helper functions really makes it easier for
>> >>> organizations
>> >>>>> to glue together usage of their own R packages repos and CRAN repo in a
>> >>>>> smooth way. That could possibly help to offload CRAN from new
>> >>> submissions.
>> >>>>>
>> >>>>> gh mirror link for easy preview:
>> >>>>>
>> >>>>>
>> >>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>> >>>>>
>> >>>>> Regards
>> >>>>> Jan Gorecki
>> >>>>>
>> >>>>>        [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-devel at r-project.org mailing list
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>>>
>> >>>>
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>


From g@bembecker @end|ng |rom gm@||@com  Fri Oct 28 21:42:02 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 28 Oct 2022 12:42:02 -0700
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
 <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
Message-ID: <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>

Hi Jan,

The reason, I suspect without speaking for R-core, is that by design you
should not be specifying package dependencies as additional packages to
install. install.packages already does this for you, as it did in the
construct of a repository code that I provided previously in the thread.
You should be *only* doing

install.packages(<pkg in question>, repos = *)

Then everything happens automatically via extremely well tested very mature
code.

I (still) don't understand why you'd need to pass install.packages the
vector of dependencies yourself, as that is counter to install.packages'
core design.

Does that make sense?

Best,
~G

On Fri, Oct 28, 2022 at 12:18 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:

> Gabriel,
>
> I am trying to design generic solution that could be applied to
> arbitrary package. Therefore I went with the latter solution you
> proposed.
> If we wouldn't have to exclude base packages, then its a 3 liner
>
> file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
> db<-available.packages(paste0("file://", tdir));
> utils::install.packages(tools::package_dependencies("pkgname", db,
> which="most")[[1L]])
>
> As you noticed, we still have to filter out base packages. Otherwise
> it won't be a robust utility that can be used in CI. Therefore we have
> to add a call to tools:::.get_standard_package_names() which is an
> internal function (as of now). Not only complicating the call but also
> putting the functionality outside of safe use.
>
> Considering above, don't you agree that the following one liner could
> nicely address the problem? The problem that hundreds/thousands of
> packages are now addressing in their CI scripts by using a third party
> packages.
>
> utils::install.packages(packages.dcf("DESCRIPTION", which="most"))
>
> It is hard to me to understand why R members don't consider this basic
> functionality to be part of base R. Possibly they just don't need it
> themselves. Yet isn't this sufficient that hundreds/thousands of
> packages does need this functionality?
>
> Best regards,
> Jan
>
> On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >
> > Gabriel and Simon
> >
> > I completely agree with what you are saying.
> > The thing is that obtaining recursive deps, all/most whatever, is
> already well supported in core R. What is missing is just this single
> functionality I am requesting.
> >
> > If you will look into the branch you can see there is mirror.packages
> function meant to mirror a slice of CRAN. It is doing exactly what you
> described: package_dependencies; to obtain recursive deps, then download
> all, etc.
> > I would love to have this function provided by core R as well, but we
> need to start somewhere.
> >
> > There are other use cases as well.
> > For example CI, where one wants to install all/most dependencies and
> then run R CMD check. Then we don't worry about recursive deps are they
> will be resolved automatically.
> > I don't think it's reasonable to force users to use 3rd party packages
> to handle such a common and simple use case. Otherwise one has to hard code
> deps in CI script. Not robust at all.
> >
> > packages.dcf and repos.dcf makes all that way easier, and are solid base
> for building customized orchestration like mirroring slice of CRAN.
> >
> > Best regards
> > Jan
> >
> > On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> >>
> >> Jan,
> >>
> >> I think using a single DCF as input is not very practical and would not
> be useful in the context you describe (creating self contained repos) since
> they typically concern a list of packages, but essentially splitting out
> the part of install.packages() which determines which files will be pulled
> from where would be very useful as it would be trivial to use it to create
> repository (what we always do in corporate environments) instead of
> installing the packages. I suspect that install packages is already too
> complex so instead of adding a flag to install.packages one could move that
> functionality into a separate function - we all do that constantly for the
> sites we manage, so it would be certainly something worthwhile.
> >>
> >> Cheers,
> >> Simon
> >>
> >>
> >> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >> >
> >> > Hi Gabriel,
> >> >
> >> > It's very nice usage you provided here. Maybe instead of adding new
> >> > function we could extend packages_depenedncies then? To accept file
> path to
> >> > dsc file.
> >> >
> >> > What about repos.dcf? Maybe additional repositories could be an
> attribute
> >> > attached to returned character vector.
> >> >
> >> > The use case is to, for a given package sources, obtain its
> dependencies,
> >> > so one can use that for installing them/mirroring CRAN subset, or
> whatever.
> >> > The later is especially important for a production environment where
> one
> >> > wants to have fixed version of packages, and mirroring relevant
> subset of
> >> > CRAN is the most simple, and IMO reliable, way to manage such
> environment.
> >> >
> >> > Regards
> >> > Jan
> >> >
> >> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com>
> wrote:
> >> >
> >> >> Hi Jan and Jan,
> >> >>
> >> >> Can you explain a little more what exactly you want the
> non-recursive,
> >> >> non-version aware dependencies from an individual package for?
> >> >>
> >> >> Either way package_dependencies will do this for you* with a little
> >> >> "aggressive convincing". It wants output from available.packages,
> but who
> >> >> really cares what it wants? It's a function and we are people :)
> >> >>
> >> >>> library(tools)
> >> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> >> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
> >> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
> >> >> $rtables
> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >>
> >> >>
> >> >> The only gotcha that I see immediately is that "LinkingTo" isn't
> always
> >> >> there (whereas it is with real output from available.packages). If
> you
> >> >> know your package doesn't have that (or that it does) at call time ,
> this
> >> >> becomes a one-liner:
> >> >>
> >> >> package_dependencies("rtables", db =
> >> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
> >> >> c("Depends", "Suggests", "Imports"))
> >> >> $rtables
> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >>
> >> >> You can also trick it a slightly different way by giving it what it
> >> >> actually wants
> >> >>
> >> >>> tdir <- tempdir()
> >> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION",
> file.path(tdir,
> >> >> "PACKAGES"))
> >> >> [1] TRUE
> >> >>> avl <- available.packages(paste0("file://", tdir))
> >> >>> library(tools)
> >> >>> package_dependencies("rtables", avl)
> >> >> $rtables
> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> >> [6] "grid"
> >> >>
> >> >>> package_dependencies("rtables", avl, which = "all")
> >> >> $rtables
> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
> >> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
> >> >>
> >> >> So the only real benefits I see that we'd be picking up here is
> automatic
> >> >> filtering by priority, and automatic extraction of the package name
> from
> >> >> the DESCRIPTION file. I'm not sure either of those warrant a new
> exported
> >> >> function that R-core has to maintain forever.
> >> >>
> >> >> Best,
> >> >> ~G
> >> >>
> >> >> * I haven't tested this across all OSes, but I dont' know of any
> reason it
> >> >> wouldn't work generally.
> >> >>
> >> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >> >>
> >> >>> Hello Jan,
> >> >>>
> >> >>> Thanks for confirming about many packages reinventing this missing
> >> >>> functionality.
> >> >>> packages.dcf was not meant handle versions. It just extracts names
> of
> >> >>> dependencies... Yes, such a simple thing, yet missing in base R.
> >> >>>
> >> >>> Versions of packages can be controlled when setting up R pkgs repo.
> This
> >> >>> is
> >> >>> how I used to handle it. Making a CRAN subset mirror of fixed
> version
> >> >>> pkgs.
> >> >>> BTW. function for that is also included in mentioned branch. I am
> just not
> >> >>> proposing it, to increase the chance of having at least this simple,
> >> >>> missing, functionality merged.
> >> >>>
> >> >>> Best
> >> >>> Jan
> >> >>>
> >> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
> >> >>>
> >> >>>> Hello Jan,
> >> >>>>
> >> >>>> I have seen many packages that implemented dependencies
> "extraction" on
> >> >>>> their own for internal purposes and today I was doing exactly that
> for
> >> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
> >> >>> sufficient
> >> >>>> for me, but I had to take care of some \n chars (the overall
> returned
> >> >>> value
> >> >>>> has some rough edges, in my opinion). However, the function from
> the
> >> >>> branch
> >> >>>> seems to not care about version requirements, which are crucial
> for me.
> >> >>>> Maybe that is something to reconsider before merging.
> >> >>>>
> >> >>>> Best,
> >> >>>> Jan
> >> >>>>
> >> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <
> j.gorecki at wit.edu.pl>
> >> >>>> napsal:
> >> >>>>
> >> >>>>> Dear R devs,
> >> >>>>>
> >> >>>>> I would like to raise a request for a simple helper function.
> >> >>>>> Utility function to extract package dependencies from DESCRIPTION
> file.
> >> >>>>>
> >> >>>>> I do think that tools package is better place, for such a
> fundamental
> >> >>>>> functionality, than community packages.
> >> >>>>>
> >> >>>>> tools pkg seems perfect fit (having already great function
> >> >>>>> write_PACKAGES).
> >> >>>>>
> >> >>>>> Functionality I am asking for is already in R svn repository since
> >> >>> 2016,
> >> >>>>> in
> >> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
> >> >>>>> Another one 'repos.dcf' would be a good functional complementary
> to it.
> >> >>>>>
> >> >>>>> Those two simple helper functions really makes it easier for
> >> >>> organizations
> >> >>>>> to glue together usage of their own R packages repos and CRAN
> repo in a
> >> >>>>> smooth way. That could possibly help to offload CRAN from new
> >> >>> submissions.
> >> >>>>>
> >> >>>>> gh mirror link for easy preview:
> >> >>>>>
> >> >>>>>
> >> >>>
> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
> >> >>>>>
> >> >>>>> Regards
> >> >>>>> Jan Gorecki
> >> >>>>>
> >> >>>>>        [[alternative HTML version deleted]]
> >> >>>>>
> >> >>>>> ______________________________________________
> >> >>>>> R-devel at r-project.org mailing list
> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>>>>
> >> >>>>
> >> >>>
> >> >>>        [[alternative HTML version deleted]]
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-devel at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>>
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >>
>

	[[alternative HTML version deleted]]


From @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch  Fri Oct 28 19:41:28 2022
From: @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch (Sebastian Martin Krantz)
Date: Fri, 28 Oct 2022 19:41:28 +0200
Subject: [Rd] pmin() and pmax() should process a single list of vectors,
 rather than returning it
Message-ID: <CAOsNuxDKdtoSN3FxG9MPa1eGquFCjOtfH9y4FMi9SefPcLpvXA@mail.gmail.com>

Dear R Core,

The {kit} package has a nice set of parallel statistical functions
complimenting base R's pmin() and pmax(): psum(), pprod(), pmean(), etc..
These can be called on a set of vectors like pmin() and pmax() e.g.
with(mtcars,  psum(mpg, carb, wt)) or on a single list of vectors e.g.
psum(mtcars). In contrast, pmin() and pmax() only allow the former. Calling
pmax(mtcars) oddly returns mtcars as is, without giving any error or
warning. I think this behavior should be changed to come in line with the
kit versions.

kit::psum is defined as:
psum <- function(..., na.rm=FALSE) .Call(CpsumR,  na.rm, if (...length() ==
1L && is.list(..1)) ..1 else list(...))

The first line of pmin() and pmax() is elts <- list(...). I propose
changing that first line to:
elts <- if (...length() == 1L && is.list(..1)) unclass(..1) else list(...).

This will provide convenient functionality (do.call(pmax, mtcars) is
inconvenient), and guard against the (odd) behavior of simply returning a
list passed to these functions.

Best regards,

Sebastian Krantz

	[[alternative HTML version deleted]]


From d|pter|x@w@ng @end|ng |rom gm@||@com  Fri Oct 28 22:05:14 2022
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Fri, 28 Oct 2022 16:05:14 -0400
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
Message-ID: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>

Hi,

I was wondering if it is a good idea to delay the evaluation of expression within invisible(), just like data()/delayedAssign()?

The idea is a function might return an invisible object. This object might not be used by the users if the function returns are not assigned nor passed to another function call. For example,

f <- function() {
  # do something eagerly

  return(invisible({
    # calculate message that might take long/extra memory, but only useful if printed out
  }))
}

If `f()` is not immediately assigned to a variable, then there is no reason to evaluate invisible(?).

This idea is somewhere between `delayedAssign` and eager evaluation. Maybe we could call it delayedInvisible()?

Best,
- Zhengjia


From j@goreck| @end|ng |rom w|t@edu@p|  Fri Oct 28 22:56:54 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Fri, 28 Oct 2022 21:56:54 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
 <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
 <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>
Message-ID: <CAOO9MKWQNoGdbRPXmVtJUR-H9hxrJDTU-8J_C5iCKucgzTJoSQ@mail.gmail.com>

Gabriel,

It is the most basic CI use case. One wants to install only
dependencies only of the package, and run R CMD check on the package.

Unless you say that installing the package and then running R CMD
check on that package is considered good practice. Then yes,
functionality I am asking about is not needed. Somehow I never thought
that this could be considered a good practice just by the fact that
installation of the package could already impact environment in which
check is taking place.

Best,
Jan

On Fri, Oct 28, 2022 at 8:42 PM Gabriel Becker <gabembecker at gmail.com> wrote:
>
> Hi Jan,
>
> The reason, I suspect without speaking for R-core, is that by design you should not be specifying package dependencies as additional packages to install. install.packages already does this for you, as it did in the construct of a repository code that I provided previously in the thread. You should be *only* doing
>
> install.packages(<pkg in question>, repos = *)
>
> Then everything happens automatically via extremely well tested very mature code.
>
> I (still) don't understand why you'd need to pass install.packages the vector of dependencies yourself, as that is counter to install.packages' core design.
>
> Does that make sense?
>
> Best,
> ~G
>
> On Fri, Oct 28, 2022 at 12:18 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>>
>> Gabriel,
>>
>> I am trying to design generic solution that could be applied to
>> arbitrary package. Therefore I went with the latter solution you
>> proposed.
>> If we wouldn't have to exclude base packages, then its a 3 liner
>>
>> file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
>> db<-available.packages(paste0("file://", tdir));
>> utils::install.packages(tools::package_dependencies("pkgname", db,
>> which="most")[[1L]])
>>
>> As you noticed, we still have to filter out base packages. Otherwise
>> it won't be a robust utility that can be used in CI. Therefore we have
>> to add a call to tools:::.get_standard_package_names() which is an
>> internal function (as of now). Not only complicating the call but also
>> putting the functionality outside of safe use.
>>
>> Considering above, don't you agree that the following one liner could
>> nicely address the problem? The problem that hundreds/thousands of
>> packages are now addressing in their CI scripts by using a third party
>> packages.
>>
>> utils::install.packages(packages.dcf("DESCRIPTION", which="most"))
>>
>> It is hard to me to understand why R members don't consider this basic
>> functionality to be part of base R. Possibly they just don't need it
>> themselves. Yet isn't this sufficient that hundreds/thousands of
>> packages does need this functionality?
>>
>> Best regards,
>> Jan
>>
>> On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >
>> > Gabriel and Simon
>> >
>> > I completely agree with what you are saying.
>> > The thing is that obtaining recursive deps, all/most whatever, is already well supported in core R. What is missing is just this single functionality I am requesting.
>> >
>> > If you will look into the branch you can see there is mirror.packages function meant to mirror a slice of CRAN. It is doing exactly what you described: package_dependencies; to obtain recursive deps, then download all, etc.
>> > I would love to have this function provided by core R as well, but we need to start somewhere.
>> >
>> > There are other use cases as well.
>> > For example CI, where one wants to install all/most dependencies and then run R CMD check. Then we don't worry about recursive deps are they will be resolved automatically.
>> > I don't think it's reasonable to force users to use 3rd party packages to handle such a common and simple use case. Otherwise one has to hard code deps in CI script. Not robust at all.
>> >
>> > packages.dcf and repos.dcf makes all that way easier, and are solid base for building customized orchestration like mirroring slice of CRAN.
>> >
>> > Best regards
>> > Jan
>> >
>> > On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> >>
>> >> Jan,
>> >>
>> >> I think using a single DCF as input is not very practical and would not be useful in the context you describe (creating self contained repos) since they typically concern a list of packages, but essentially splitting out the part of install.packages() which determines which files will be pulled from where would be very useful as it would be trivial to use it to create repository (what we always do in corporate environments) instead of installing the packages. I suspect that install packages is already too complex so instead of adding a flag to install.packages one could move that functionality into a separate function - we all do that constantly for the sites we manage, so it would be certainly something worthwhile.
>> >>
>> >> Cheers,
>> >> Simon
>> >>
>> >>
>> >> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >> >
>> >> > Hi Gabriel,
>> >> >
>> >> > It's very nice usage you provided here. Maybe instead of adding new
>> >> > function we could extend packages_depenedncies then? To accept file path to
>> >> > dsc file.
>> >> >
>> >> > What about repos.dcf? Maybe additional repositories could be an attribute
>> >> > attached to returned character vector.
>> >> >
>> >> > The use case is to, for a given package sources, obtain its dependencies,
>> >> > so one can use that for installing them/mirroring CRAN subset, or whatever.
>> >> > The later is especially important for a production environment where one
>> >> > wants to have fixed version of packages, and mirroring relevant subset of
>> >> > CRAN is the most simple, and IMO reliable, way to manage such environment.
>> >> >
>> >> > Regards
>> >> > Jan
>> >> >
>> >> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
>> >> >
>> >> >> Hi Jan and Jan,
>> >> >>
>> >> >> Can you explain a little more what exactly you want the non-recursive,
>> >> >> non-version aware dependencies from an individual package for?
>> >> >>
>> >> >> Either way package_dependencies will do this for you* with a little
>> >> >> "aggressive convincing". It wants output from available.packages, but who
>> >> >> really cares what it wants? It's a function and we are people :)
>> >> >>
>> >> >>> library(tools)
>> >> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
>> >> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
>> >> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
>> >> >> $rtables
>> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >> >>
>> >> >>
>> >> >> The only gotcha that I see immediately is that "LinkingTo" isn't always
>> >> >> there (whereas it is with real output from available.packages). If you
>> >> >> know your package doesn't have that (or that it does) at call time , this
>> >> >> becomes a one-liner:
>> >> >>
>> >> >> package_dependencies("rtables", db =
>> >> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
>> >> >> c("Depends", "Suggests", "Imports"))
>> >> >> $rtables
>> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >> >>
>> >> >> You can also trick it a slightly different way by giving it what it
>> >> >> actually wants
>> >> >>
>> >> >>> tdir <- tempdir()
>> >> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
>> >> >> "PACKAGES"))
>> >> >> [1] TRUE
>> >> >>> avl <- available.packages(paste0("file://", tdir))
>> >> >>> library(tools)
>> >> >>> package_dependencies("rtables", avl)
>> >> >> $rtables
>> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> >> [6] "grid"
>> >> >>
>> >> >>> package_dependencies("rtables", avl, which = "all")
>> >> >> $rtables
>> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
>> >> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>> >> >>
>> >> >> So the only real benefits I see that we'd be picking up here is automatic
>> >> >> filtering by priority, and automatic extraction of the package name from
>> >> >> the DESCRIPTION file. I'm not sure either of those warrant a new exported
>> >> >> function that R-core has to maintain forever.
>> >> >>
>> >> >> Best,
>> >> >> ~G
>> >> >>
>> >> >> * I haven't tested this across all OSes, but I dont' know of any reason it
>> >> >> wouldn't work generally.
>> >> >>
>> >> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >> >>
>> >> >>> Hello Jan,
>> >> >>>
>> >> >>> Thanks for confirming about many packages reinventing this missing
>> >> >>> functionality.
>> >> >>> packages.dcf was not meant handle versions. It just extracts names of
>> >> >>> dependencies... Yes, such a simple thing, yet missing in base R.
>> >> >>>
>> >> >>> Versions of packages can be controlled when setting up R pkgs repo. This
>> >> >>> is
>> >> >>> how I used to handle it. Making a CRAN subset mirror of fixed version
>> >> >>> pkgs.
>> >> >>> BTW. function for that is also included in mentioned branch. I am just not
>> >> >>> proposing it, to increase the chance of having at least this simple,
>> >> >>> missing, functionality merged.
>> >> >>>
>> >> >>> Best
>> >> >>> Jan
>> >> >>>
>> >> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>> >> >>>
>> >> >>>> Hello Jan,
>> >> >>>>
>> >> >>>> I have seen many packages that implemented dependencies "extraction" on
>> >> >>>> their own for internal purposes and today I was doing exactly that for
>> >> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>> >> >>> sufficient
>> >> >>>> for me, but I had to take care of some \n chars (the overall returned
>> >> >>> value
>> >> >>>> has some rough edges, in my opinion). However, the function from the
>> >> >>> branch
>> >> >>>> seems to not care about version requirements, which are crucial for me.
>> >> >>>> Maybe that is something to reconsider before merging.
>> >> >>>>
>> >> >>>> Best,
>> >> >>>> Jan
>> >> >>>>
>> >> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>> >> >>>> napsal:
>> >> >>>>
>> >> >>>>> Dear R devs,
>> >> >>>>>
>> >> >>>>> I would like to raise a request for a simple helper function.
>> >> >>>>> Utility function to extract package dependencies from DESCRIPTION file.
>> >> >>>>>
>> >> >>>>> I do think that tools package is better place, for such a fundamental
>> >> >>>>> functionality, than community packages.
>> >> >>>>>
>> >> >>>>> tools pkg seems perfect fit (having already great function
>> >> >>>>> write_PACKAGES).
>> >> >>>>>
>> >> >>>>> Functionality I am asking for is already in R svn repository since
>> >> >>> 2016,
>> >> >>>>> in
>> >> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
>> >> >>>>> Another one 'repos.dcf' would be a good functional complementary to it.
>> >> >>>>>
>> >> >>>>> Those two simple helper functions really makes it easier for
>> >> >>> organizations
>> >> >>>>> to glue together usage of their own R packages repos and CRAN repo in a
>> >> >>>>> smooth way. That could possibly help to offload CRAN from new
>> >> >>> submissions.
>> >> >>>>>
>> >> >>>>> gh mirror link for easy preview:
>> >> >>>>>
>> >> >>>>>
>> >> >>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>> >> >>>>>
>> >> >>>>> Regards
>> >> >>>>> Jan Gorecki
>> >> >>>>>
>> >> >>>>>        [[alternative HTML version deleted]]
>> >> >>>>>
>> >> >>>>> ______________________________________________
>> >> >>>>> R-devel at r-project.org mailing list
>> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>>>>
>> >> >>>>
>> >> >>>
>> >> >>>        [[alternative HTML version deleted]]
>> >> >>>
>> >> >>> ______________________________________________
>> >> >>> R-devel at r-project.org mailing list
>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>>
>> >> >>
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-devel at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >
>> >>


From g@bembecker @end|ng |rom gm@||@com  Fri Oct 28 23:10:51 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 28 Oct 2022 14:10:51 -0700
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
Message-ID: <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>

Hi Dipterix,


On Fri, Oct 28, 2022 at 1:10 PM Dipterix Wang <dipterix.wang at gmail.com>
wrote:

> Hi,
>
> I was wondering if it is a good idea to delay the evaluation of expression
> within invisible(), just like data()/delayedAssign()?
>
> The idea is a function might return an invisible object. This object might
> not be used by the users if the function returns are not assigned nor
> passed to another function call. For example,
>
> f <- function() {
>   # do something eagerly
>
>   return(invisible({
>     # calculate message that might take long/extra memory, but only useful
> if printed out
>   }))
> }
>
> If `f()` is not immediately assigned to a variable, then there is no
> reason to evaluate invisible(?).
>

This is not quite true. The value, even when invisible, is captured by
.Last.value, and

> f <- function() invisible(5)

> f()

> .Last.value

[1] 5


Now that doesn't actually preclude what you're suggesting (just have to
wait for .Last.value to be populated by something else), but it does
complicate it to the extent that I'm not sure the benefit we'd get would be
worth it.

Also, in the case you're describing, you'd be pushing the computational
cost into printing, which, imo, is not where it should live. Printing a
values generally speaking, should just print things, imo.

That said, if you really wanted to do this, you could approach the behavior
you want, I believe (but again, I think this is a bad idea) by returning a
custom class that wraps formula (or, I imagine, tidyverse style quosures)
that reach back into the call frame you return them from, and evaluating
them only on demand.

Best,
~G


> This idea is somewhere between `delayedAssign` and eager evaluation. Maybe
> we could call it delayedInvisible()?
>
> Best,
> - Zhengjia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Oct 28 23:24:15 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 28 Oct 2022 14:24:15 -0700
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
 <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
Message-ID: <CAHqSRuToToYjQoHLy5ZEOGZiAXKU2XY0v=VsLJd36K-mTiGx7A@mail.gmail.com>

You can play with the idea by returning an environment that contains
delayed assignments.  E.g.,

> f <- function(x) {
+    delayedAssign("eval_date", { cat("Evaluating 'date'\n"); date()})
+    delayedAssign("sum_x", { cat("Evaluating 'sum_x'\n"); sum(x)})
+    environment()
+ }
> fx <- f(1:10)
> date()
[1] "Fri Oct 28 14:22:12 2022"
> Sys.sleep(2)
> fx$eval_date
Evaluating 'date'
[1] "Fri Oct 28 14:22:24 2022"
> Sys.sleep(2)
> fx$eval_date
[1] "Fri Oct 28 14:22:24 2022"
> fx$sum_x
Evaluating 'sum_x'
[1] 55
> fx$sum_x
[1] 55

-Bill

On Fri, Oct 28, 2022 at 2:11 PM Gabriel Becker <gabembecker at gmail.com>
wrote:

> Hi Dipterix,
>
>
> On Fri, Oct 28, 2022 at 1:10 PM Dipterix Wang <dipterix.wang at gmail.com>
> wrote:
>
> > Hi,
> >
> > I was wondering if it is a good idea to delay the evaluation of
> expression
> > within invisible(), just like data()/delayedAssign()?
> >
> > The idea is a function might return an invisible object. This object
> might
> > not be used by the users if the function returns are not assigned nor
> > passed to another function call. For example,
> >
> > f <- function() {
> >   # do something eagerly
> >
> >   return(invisible({
> >     # calculate message that might take long/extra memory, but only
> useful
> > if printed out
> >   }))
> > }
> >
> > If `f()` is not immediately assigned to a variable, then there is no
> > reason to evaluate invisible(?).
> >
>
> This is not quite true. The value, even when invisible, is captured by
> .Last.value, and
>
> > f <- function() invisible(5)
>
> > f()
>
> > .Last.value
>
> [1] 5
>
>
> Now that doesn't actually preclude what you're suggesting (just have to
> wait for .Last.value to be populated by something else), but it does
> complicate it to the extent that I'm not sure the benefit we'd get would be
> worth it.
>
> Also, in the case you're describing, you'd be pushing the computational
> cost into printing, which, imo, is not where it should live. Printing a
> values generally speaking, should just print things, imo.
>
> That said, if you really wanted to do this, you could approach the behavior
> you want, I believe (but again, I think this is a bad idea) by returning a
> custom class that wraps formula (or, I imagine, tidyverse style quosures)
> that reach back into the call frame you return them from, and evaluating
> them only on demand.
>
> Best,
> ~G
>
>
> > This idea is somewhere between `delayedAssign` and eager evaluation.
> Maybe
> > we could call it delayedInvisible()?
> >
> > Best,
> > - Zhengjia
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Fri Oct 28 23:42:34 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 28 Oct 2022 14:42:34 -0700
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKWQNoGdbRPXmVtJUR-H9hxrJDTU-8J_C5iCKucgzTJoSQ@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
 <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
 <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>
 <CAOO9MKWQNoGdbRPXmVtJUR-H9hxrJDTU-8J_C5iCKucgzTJoSQ@mail.gmail.com>
Message-ID: <CAD4oTHERXkoCY2GfYSTbxqF8kK28d-LZMcjDr2biwEaMktU-7Q@mail.gmail.com>

Hi Jan,


On Fri, Oct 28, 2022 at 1:57 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:

> Gabriel,
>
> It is the most basic CI use case. One wants to install only
> dependencies only of the package, and run R CMD check on the package.


Really what you're looking for though, is to install all the dependencies
which aren't present right? Excluding base packages is just a particular
way to do that under certain assumptions about the CI environment.

So


needed_pkgs <- setdiff(package_dependencies(...),
installed.packages()[,"Package"])
install.packages(needed_pkgs, repos = fancyrepos)


will do what you want without installing the package itself, if that is
important. This will filter out base and recommended packages (which will
be already installed in your CI container, since R is).


Now this does not take into account versioned dependencies, so it's not
actually fully correct (whereas installing the package is), but it gets you
where you're trying to go. And in a clean CI container without cached
package installation for the deps, its equivalent.


Also, as an aside, if you need to get the base packages, you can do

installed.packages(priority="base")[,"Package"]

       base    compiler    datasets    graphics   grDevices        grid

     "base"  "compiler"  "datasets"  "graphics" "grDevices"      "grid"

    methods    parallel     splines       stats      stats4       tcltk

  "methods"  "parallel"   "splines"     "stats"    "stats4"     "tcltk"

      tools       utils

    "tools"     "utils"

(to get base and recommended packages use 'high' instead of 'base')

No need to be reaching down into unexported functions. So if you *really*
only want to exclude base functions (which likely will give you some
protection from versioned dep issues), you can change the code above to

needed_pkgs <- setdiff(package_dependencies(...),
installed.packages(priority = "high")[,"Package"])
install.packages(needed_pkgs, repos = fancyrepos)

Best,
~G


> On Fri, Oct 28, 2022 at 8:42 PM Gabriel Becker <gabembecker at gmail.com>
> wrote:
> >
> > Hi Jan,
> >
> > The reason, I suspect without speaking for R-core, is that by design you
> should not be specifying package dependencies as additional packages to
> install. install.packages already does this for you, as it did in the
> construct of a repository code that I provided previously in the thread.
> You should be *only* doing
> >
> > install.packages(<pkg in question>, repos = *)
> >
> > Then everything happens automatically via extremely well tested very
> mature code.
> >
> > I (still) don't understand why you'd need to pass install.packages the
> vector of dependencies yourself, as that is counter to install.packages'
> core design.
> >
> > Does that make sense?
> >
> > Best,
> > ~G
> >
> > On Fri, Oct 28, 2022 at 12:18 PM Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >>
> >> Gabriel,
> >>
> >> I am trying to design generic solution that could be applied to
> >> arbitrary package. Therefore I went with the latter solution you
> >> proposed.
> >> If we wouldn't have to exclude base packages, then its a 3 liner
> >>
> >> file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
> >> db<-available.packages(paste0("file://", tdir));
> >> utils::install.packages(tools::package_dependencies("pkgname", db,
> >> which="most")[[1L]])
> >>
> >> As you noticed, we still have to filter out base packages. Otherwise
> >> it won't be a robust utility that can be used in CI. Therefore we have
> >> to add a call to tools:::.get_standard_package_names() which is an
> >> internal function (as of now). Not only complicating the call but also
> >> putting the functionality outside of safe use.
> >>
> >> Considering above, don't you agree that the following one liner could
> >> nicely address the problem? The problem that hundreds/thousands of
> >> packages are now addressing in their CI scripts by using a third party
> >> packages.
> >>
> >> utils::install.packages(packages.dcf("DESCRIPTION", which="most"))
> >>
> >> It is hard to me to understand why R members don't consider this basic
> >> functionality to be part of base R. Possibly they just don't need it
> >> themselves. Yet isn't this sufficient that hundreds/thousands of
> >> packages does need this functionality?
> >>
> >> Best regards,
> >> Jan
> >>
> >> On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >> >
> >> > Gabriel and Simon
> >> >
> >> > I completely agree with what you are saying.
> >> > The thing is that obtaining recursive deps, all/most whatever, is
> already well supported in core R. What is missing is just this single
> functionality I am requesting.
> >> >
> >> > If you will look into the branch you can see there is mirror.packages
> function meant to mirror a slice of CRAN. It is doing exactly what you
> described: package_dependencies; to obtain recursive deps, then download
> all, etc.
> >> > I would love to have this function provided by core R as well, but we
> need to start somewhere.
> >> >
> >> > There are other use cases as well.
> >> > For example CI, where one wants to install all/most dependencies and
> then run R CMD check. Then we don't worry about recursive deps are they
> will be resolved automatically.
> >> > I don't think it's reasonable to force users to use 3rd party
> packages to handle such a common and simple use case. Otherwise one has to
> hard code deps in CI script. Not robust at all.
> >> >
> >> > packages.dcf and repos.dcf makes all that way easier, and are solid
> base for building customized orchestration like mirroring slice of CRAN.
> >> >
> >> > Best regards
> >> > Jan
> >> >
> >> > On Sun, Oct 16, 2022, 01:31 Simon Urbanek <
> simon.urbanek at r-project.org> wrote:
> >> >>
> >> >> Jan,
> >> >>
> >> >> I think using a single DCF as input is not very practical and would
> not be useful in the context you describe (creating self contained repos)
> since they typically concern a list of packages, but essentially splitting
> out the part of install.packages() which determines which files will be
> pulled from where would be very useful as it would be trivial to use it to
> create repository (what we always do in corporate environments) instead of
> installing the packages. I suspect that install packages is already too
> complex so instead of adding a flag to install.packages one could move that
> functionality into a separate function - we all do that constantly for the
> sites we manage, so it would be certainly something worthwhile.
> >> >>
> >> >> Cheers,
> >> >> Simon
> >> >>
> >> >>
> >> >> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >> >> >
> >> >> > Hi Gabriel,
> >> >> >
> >> >> > It's very nice usage you provided here. Maybe instead of adding new
> >> >> > function we could extend packages_depenedncies then? To accept
> file path to
> >> >> > dsc file.
> >> >> >
> >> >> > What about repos.dcf? Maybe additional repositories could be an
> attribute
> >> >> > attached to returned character vector.
> >> >> >
> >> >> > The use case is to, for a given package sources, obtain its
> dependencies,
> >> >> > so one can use that for installing them/mirroring CRAN subset, or
> whatever.
> >> >> > The later is especially important for a production environment
> where one
> >> >> > wants to have fixed version of packages, and mirroring relevant
> subset of
> >> >> > CRAN is the most simple, and IMO reliable, way to manage such
> environment.
> >> >> >
> >> >> > Regards
> >> >> > Jan
> >> >> >
> >> >> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com>
> wrote:
> >> >> >
> >> >> >> Hi Jan and Jan,
> >> >> >>
> >> >> >> Can you explain a little more what exactly you want the
> non-recursive,
> >> >> >> non-version aware dependencies from an individual package for?
> >> >> >>
> >> >> >> Either way package_dependencies will do this for you* with a
> little
> >> >> >> "aggressive convincing". It wants output from available.packages,
> but who
> >> >> >> really cares what it wants? It's a function and we are people :)
> >> >> >>
> >> >> >>> library(tools)
> >> >> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> >> >> >>> package_dependencies("rtables", db, which =
> intersect(c("Depends",
> >> >> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
> >> >> >> $rtables
> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"
> "rmarkdown"
> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >> >>
> >> >> >>
> >> >> >> The only gotcha that I see immediately is that "LinkingTo" isn't
> always
> >> >> >> there (whereas it is with real output from available.packages).
> If you
> >> >> >> know your package doesn't have that (or that it does) at call
> time , this
> >> >> >> becomes a one-liner:
> >> >> >>
> >> >> >> package_dependencies("rtables", db =
> >> >> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
> >> >> >> c("Depends", "Suggests", "Imports"))
> >> >> >> $rtables
> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"
> "rmarkdown"
> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >> >>
> >> >> >> You can also trick it a slightly different way by giving it what
> it
> >> >> >> actually wants
> >> >> >>
> >> >> >>> tdir <- tempdir()
> >> >> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION",
> file.path(tdir,
> >> >> >> "PACKAGES"))
> >> >> >> [1] TRUE
> >> >> >>> avl <- available.packages(paste0("file://", tdir))
> >> >> >>> library(tools)
> >> >> >>> package_dependencies("rtables", avl)
> >> >> >> $rtables
> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"
> "htmltools"
> >> >> >> [6] "grid"
> >> >> >>
> >> >> >>> package_dependencies("rtables", avl, which = "all")
> >> >> >> $rtables
> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"
> "htmltools"
> >> >> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
> >> >> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
> >> >> >>
> >> >> >> So the only real benefits I see that we'd be picking up here is
> automatic
> >> >> >> filtering by priority, and automatic extraction of the package
> name from
> >> >> >> the DESCRIPTION file. I'm not sure either of those warrant a new
> exported
> >> >> >> function that R-core has to maintain forever.
> >> >> >>
> >> >> >> Best,
> >> >> >> ~G
> >> >> >>
> >> >> >> * I haven't tested this across all OSes, but I dont' know of any
> reason it
> >> >> >> wouldn't work generally.
> >> >> >>
> >> >> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl>
> wrote:
> >> >> >>
> >> >> >>> Hello Jan,
> >> >> >>>
> >> >> >>> Thanks for confirming about many packages reinventing this
> missing
> >> >> >>> functionality.
> >> >> >>> packages.dcf was not meant handle versions. It just extracts
> names of
> >> >> >>> dependencies... Yes, such a simple thing, yet missing in base R.
> >> >> >>>
> >> >> >>> Versions of packages can be controlled when setting up R pkgs
> repo. This
> >> >> >>> is
> >> >> >>> how I used to handle it. Making a CRAN subset mirror of fixed
> version
> >> >> >>> pkgs.
> >> >> >>> BTW. function for that is also included in mentioned branch. I
> am just not
> >> >> >>> proposing it, to increase the chance of having at least this
> simple,
> >> >> >>> missing, functionality merged.
> >> >> >>>
> >> >> >>> Best
> >> >> >>> Jan
> >> >> >>>
> >> >> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
> >> >> >>>
> >> >> >>>> Hello Jan,
> >> >> >>>>
> >> >> >>>> I have seen many packages that implemented dependencies
> "extraction" on
> >> >> >>>> their own for internal purposes and today I was doing exactly
> that for
> >> >> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
> >> >> >>> sufficient
> >> >> >>>> for me, but I had to take care of some \n chars (the overall
> returned
> >> >> >>> value
> >> >> >>>> has some rough edges, in my opinion). However, the function
> from the
> >> >> >>> branch
> >> >> >>>> seems to not care about version requirements, which are crucial
> for me.
> >> >> >>>> Maybe that is something to reconsider before merging.
> >> >> >>>>
> >> >> >>>> Best,
> >> >> >>>> Jan
> >> >> >>>>
> >> >> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <
> j.gorecki at wit.edu.pl>
> >> >> >>>> napsal:
> >> >> >>>>
> >> >> >>>>> Dear R devs,
> >> >> >>>>>
> >> >> >>>>> I would like to raise a request for a simple helper function.
> >> >> >>>>> Utility function to extract package dependencies from
> DESCRIPTION file.
> >> >> >>>>>
> >> >> >>>>> I do think that tools package is better place, for such a
> fundamental
> >> >> >>>>> functionality, than community packages.
> >> >> >>>>>
> >> >> >>>>> tools pkg seems perfect fit (having already great function
> >> >> >>>>> write_PACKAGES).
> >> >> >>>>>
> >> >> >>>>> Functionality I am asking for is already in R svn repository
> since
> >> >> >>> 2016,
> >> >> >>>>> in
> >> >> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
> >> >> >>>>> Another one 'repos.dcf' would be a good functional
> complementary to it.
> >> >> >>>>>
> >> >> >>>>> Those two simple helper functions really makes it easier for
> >> >> >>> organizations
> >> >> >>>>> to glue together usage of their own R packages repos and CRAN
> repo in a
> >> >> >>>>> smooth way. That could possibly help to offload CRAN from new
> >> >> >>> submissions.
> >> >> >>>>>
> >> >> >>>>> gh mirror link for easy preview:
> >> >> >>>>>
> >> >> >>>>>
> >> >> >>>
> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
> >> >> >>>>>
> >> >> >>>>> Regards
> >> >> >>>>> Jan Gorecki
> >> >> >>>>>
> >> >> >>>>>        [[alternative HTML version deleted]]
> >> >> >>>>>
> >> >> >>>>> ______________________________________________
> >> >> >>>>> R-devel at r-project.org mailing list
> >> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >>>>>
> >> >> >>>>
> >> >> >>>
> >> >> >>>        [[alternative HTML version deleted]]
> >> >> >>>
> >> >> >>> ______________________________________________
> >> >> >>> R-devel at r-project.org mailing list
> >> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >>>
> >> >> >>
> >> >> >
> >> >> >       [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-devel at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >
> >> >>
>

	[[alternative HTML version deleted]]


From d|pter|x@w@ng @end|ng |rom gm@||@com  Sat Oct 29 04:41:30 2022
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Fri, 28 Oct 2022 22:41:30 -0400
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
 <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
Message-ID: <EA4BFBB7-F037-4C41-917D-089997FEC255@gmail.com>


> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
> 
> > f <- function() invisible(5)
> > f()
> > .Last.value
> [1] 5


I understand .Last.value will capture the function returns, but that only happens in the top-level... I guess?

In the followings code, I think .Last.value does not capture the results of f, h, k, l

g <- function() {
  f(); h(); k(); l()
  return()
}
g()


Maybe I caused confusion by mentioning `invisible` function. I guess it should be a new function (let?s call it `delayed`). The function does not have to be limited to ?printing?. For example, a digest key


a <- function(key, value) {
  map$set(key, value)

  return(delayed({
    digest(value)
  }))
}

Or an async evaluation of which the saved result might not be needed if not assigned (detached), or the result will be ?joined? to the main process

a <- function(path) {
  # async 
  f <- future::future({
    # calculate, and then write to path
    saveRDS(?, path)
  })
  
  return(delayed({
    resolve(f) # wait till f to finish

    readRDS(path)
  }))
}

Although I could use wrappers such as formula, quosure, or environment to achieve similar results, there are two major differences

1. There is an extra call to get the lazy-evaluated results (if I do want to resolve it)
2. The returned objects have to contain sort of ?environment? component in it. It can?t just be simple objects like vectors, matrices, lists, ? (also you can't immediately garbage collect the enclosing environment)

>From the implementation perspective, the `delayed` object is ready to be garbage collected if not assigned immediately.

Best,
- D

> 
> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
> 
> > f <- function() invisible(5)
> > f()
> > .Last.value
> [1] 5
> 
> Now that doesn't actually preclude what you're suggesting (just have to wait for .Last.value to be populated by something else), but it does complicate it to the extent that I'm not sure the benefit we'd get would be worth it.
> 
> Also, in the case you're describing, you'd be pushing the computational cost into printing, which, imo, is not where it should live. Printing a values generally speaking, should just print things, imo.
> 
> That said, if you really wanted to do this, you could approach the behavior you want, I believe (but again, I think this is a bad idea) by returning a custom class that wraps formula (or, I imagine, tidyverse style quosures) that reach back into the call frame you return them from, and evaluating them only on demand.
> 
> Best,
> ~G 
> 
> 
> This idea is somewhere between `delayedAssign` and eager evaluation. Maybe we could call it delayedInvisible()?
> 
> Best,
> - Zhengjia
> 
> ______________________________________________
> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel <https://stat.ethz.ch/mailman/listinfo/r-devel>


	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sat Oct 29 17:54:48 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sat, 29 Oct 2022 08:54:48 -0700
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <EA4BFBB7-F037-4C41-917D-089997FEC255@gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
 <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
 <EA4BFBB7-F037-4C41-917D-089997FEC255@gmail.com>
Message-ID: <CAHqSRuR8NUq7gr+vhw5xm=9gi974B9mkAz9t=7zayAZ-bBnPwg@mail.gmail.com>

>  the `delayed` object is ready to be garbage collected if not assigned
immediately.
I am not sure what is meant here.  Any object (at the R code level) is
ready to be garbage collected if not given a name or is not part of an
object with a name.  Do you mean a 'delayed' component of a list
should be considered
garbage if not 'immediately' extracted from a list?   Could you show a few
usage cases?

-Bill

On Fri, Oct 28, 2022 at 7:41 PM Dipterix Wang <dipterix.wang at gmail.com>
wrote:

>
> This is not quite true. The value, even when invisible, is captured by
> .Last.value, and
>
> > f <- function() invisible(5)
> > f()
> > .Last.value
> [1] 5
>
>
> I understand .Last.value will capture the function returns, but that only
> happens in the top-level... I guess?
>
> In the followings code, I think .Last.value does not capture the results
> of f, h, k, l
>
> g <- function() {
>   f(); h(); k(); l()
>   return()
> }
> g()
>
>
> Maybe I caused confusion by mentioning `invisible` function. I guess it
> should be a new function (let?s call it `delayed`). The function does not
> have to be limited to ?printing?. For example, a digest key
>
>
> a <- function(key, value) {
>   map$set(key, value)
>
>   return(*delayed*({
>     digest(value)
>   }))
> }
>
> Or an async evaluation of which the saved result might not be needed if
> not assigned (detached), or the result will be ?joined? to the main process
>
> a <- function(path) {
>   # async
>   f <- future::future({
>     # calculate, and then write to path
>     saveRDS(?, path)
>   })
>
>   return(*delayed*({
>     resolve(f) # wait till f to finish
>
>     readRDS(path)
>   }))
> }
>
> Although I could use wrappers such as formula, quosure, or environment to
> achieve similar results, there are two major differences
>
> 1. There is an extra call to get the lazy-evaluated results (if I do want
> to resolve it)
> 2. The returned objects have to contain sort of ?environment? component in
> it. It can?t just be simple objects like vectors, matrices, lists, ?
> (also you can't immediately garbage collect the enclosing environment)
>
> From the implementation perspective, the `delayed` object is ready to be
> garbage collected if not assigned immediately.
>
> Best,
> - D
>
>
> This is not quite true. The value, even when invisible, is captured by
> .Last.value, and
>
> > f <- function() invisible(5)
> > f()
> > .Last.value
> [1] 5
>
> Now that doesn't actually preclude what you're suggesting (just have to
> wait for .Last.value to be populated by something else), but it does
> complicate it to the extent that I'm not sure the benefit we'd get would be
> worth it.
>
> Also, in the case you're describing, you'd be pushing the computational
> cost into printing, which, imo, is not where it should live. Printing a
> values generally speaking, should just print things, imo.
>
> That said, if you really wanted to do this, you could approach the
> behavior you want, I believe (but again, I think this is a bad idea) by
> returning a custom class that wraps formula (or, I imagine, tidyverse style
> quosures) that reach back into the call frame you return them from, and
> evaluating them only on demand.
>
> Best,
> ~G
>
>
>> This idea is somewhere between `delayedAssign` and eager evaluation.
>> Maybe we could call it delayedInvisible()?
>>
>> Best,
>> - Zhengjia
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From j@goreck| @end|ng |rom w|t@edu@p|  Sat Oct 29 18:26:42 2022
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Sat, 29 Oct 2022 17:26:42 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAD4oTHERXkoCY2GfYSTbxqF8kK28d-LZMcjDr2biwEaMktU-7Q@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
 <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
 <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>
 <CAOO9MKWQNoGdbRPXmVtJUR-H9hxrJDTU-8J_C5iCKucgzTJoSQ@mail.gmail.com>
 <CAD4oTHERXkoCY2GfYSTbxqF8kK28d-LZMcjDr2biwEaMktU-7Q@mail.gmail.com>
Message-ID: <CAOO9MKVxEwe6Vxy_SMDaw5Wy-x2c-qUqqz3B5Y2wa3485Q_Ejg@mail.gmail.com>

Thank you Gabriel,

Just for future readers. Below is a base R way to address this common
problem, as instructed by you (+stopifnot to suppress print).

Rscript -e 'stopifnot(file.copy("DESCRIPTION",
file.path(tdir<-tempdir(), "PACKAGES")));
db<-available.packages(paste0("file://", tdir));
install.packages(setdiff(tools::package_dependencies(read.dcf("DESCRIPTION",
fields="Package")[[1L]], db, which="most")[[1L]],
installed.packages(priority="high")[,"Package"]))'

3 liner, 310 chars long command, far from ideal, but does work.

Best,
Jan


On Fri, Oct 28, 2022 at 10:42 PM Gabriel Becker <gabembecker at gmail.com> wrote:
>
> Hi Jan,
>
>
> On Fri, Oct 28, 2022 at 1:57 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>>
>> Gabriel,
>>
>> It is the most basic CI use case. One wants to install only
>> dependencies only of the package, and run R CMD check on the package.
>
>
> Really what you're looking for though, is to install all the dependencies which aren't present right? Excluding base packages is just a particular way to do that under certain assumptions about the CI environment.
>
> So
>
>
> needed_pkgs <- setdiff(package_dependencies(...), installed.packages()[,"Package"])
> install.packages(needed_pkgs, repos = fancyrepos)
>
>
> will do what you want without installing the package itself, if that is important. This will filter out base and recommended packages (which will be already installed in your CI container, since R is).
>
>
> Now this does not take into account versioned dependencies, so it's not actually fully correct (whereas installing the package is), but it gets you where you're trying to go. And in a clean CI container without cached package installation for the deps, its equivalent.
>
>
> Also, as an aside, if you need to get the base packages, you can do
>
> installed.packages(priority="base")[,"Package"]
>
>        base    compiler    datasets    graphics   grDevices        grid
>
>      "base"  "compiler"  "datasets"  "graphics" "grDevices"      "grid"
>
>     methods    parallel     splines       stats      stats4       tcltk
>
>   "methods"  "parallel"   "splines"     "stats"    "stats4"     "tcltk"
>
>       tools       utils
>
>     "tools"     "utils"
>
>
> (to get base and recommended packages use 'high' instead of 'base')
>
> No need to be reaching down into unexported functions. So if you *really* only want to exclude base functions (which likely will give you some protection from versioned dep issues), you can change the code above to
>
> needed_pkgs <- setdiff(package_dependencies(...), installed.packages(priority = "high")[,"Package"])
> install.packages(needed_pkgs, repos = fancyrepos)
>
> Best,
> ~G
>
>>
>> On Fri, Oct 28, 2022 at 8:42 PM Gabriel Becker <gabembecker at gmail.com> wrote:
>> >
>> > Hi Jan,
>> >
>> > The reason, I suspect without speaking for R-core, is that by design you should not be specifying package dependencies as additional packages to install. install.packages already does this for you, as it did in the construct of a repository code that I provided previously in the thread. You should be *only* doing
>> >
>> > install.packages(<pkg in question>, repos = *)
>> >
>> > Then everything happens automatically via extremely well tested very mature code.
>> >
>> > I (still) don't understand why you'd need to pass install.packages the vector of dependencies yourself, as that is counter to install.packages' core design.
>> >
>> > Does that make sense?
>> >
>> > Best,
>> > ~G
>> >
>> > On Fri, Oct 28, 2022 at 12:18 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >>
>> >> Gabriel,
>> >>
>> >> I am trying to design generic solution that could be applied to
>> >> arbitrary package. Therefore I went with the latter solution you
>> >> proposed.
>> >> If we wouldn't have to exclude base packages, then its a 3 liner
>> >>
>> >> file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
>> >> db<-available.packages(paste0("file://", tdir));
>> >> utils::install.packages(tools::package_dependencies("pkgname", db,
>> >> which="most")[[1L]])
>> >>
>> >> As you noticed, we still have to filter out base packages. Otherwise
>> >> it won't be a robust utility that can be used in CI. Therefore we have
>> >> to add a call to tools:::.get_standard_package_names() which is an
>> >> internal function (as of now). Not only complicating the call but also
>> >> putting the functionality outside of safe use.
>> >>
>> >> Considering above, don't you agree that the following one liner could
>> >> nicely address the problem? The problem that hundreds/thousands of
>> >> packages are now addressing in their CI scripts by using a third party
>> >> packages.
>> >>
>> >> utils::install.packages(packages.dcf("DESCRIPTION", which="most"))
>> >>
>> >> It is hard to me to understand why R members don't consider this basic
>> >> functionality to be part of base R. Possibly they just don't need it
>> >> themselves. Yet isn't this sufficient that hundreds/thousands of
>> >> packages does need this functionality?
>> >>
>> >> Best regards,
>> >> Jan
>> >>
>> >> On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >> >
>> >> > Gabriel and Simon
>> >> >
>> >> > I completely agree with what you are saying.
>> >> > The thing is that obtaining recursive deps, all/most whatever, is already well supported in core R. What is missing is just this single functionality I am requesting.
>> >> >
>> >> > If you will look into the branch you can see there is mirror.packages function meant to mirror a slice of CRAN. It is doing exactly what you described: package_dependencies; to obtain recursive deps, then download all, etc.
>> >> > I would love to have this function provided by core R as well, but we need to start somewhere.
>> >> >
>> >> > There are other use cases as well.
>> >> > For example CI, where one wants to install all/most dependencies and then run R CMD check. Then we don't worry about recursive deps are they will be resolved automatically.
>> >> > I don't think it's reasonable to force users to use 3rd party packages to handle such a common and simple use case. Otherwise one has to hard code deps in CI script. Not robust at all.
>> >> >
>> >> > packages.dcf and repos.dcf makes all that way easier, and are solid base for building customized orchestration like mirroring slice of CRAN.
>> >> >
>> >> > Best regards
>> >> > Jan
>> >> >
>> >> > On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> >> >>
>> >> >> Jan,
>> >> >>
>> >> >> I think using a single DCF as input is not very practical and would not be useful in the context you describe (creating self contained repos) since they typically concern a list of packages, but essentially splitting out the part of install.packages() which determines which files will be pulled from where would be very useful as it would be trivial to use it to create repository (what we always do in corporate environments) instead of installing the packages. I suspect that install packages is already too complex so instead of adding a flag to install.packages one could move that functionality into a separate function - we all do that constantly for the sites we manage, so it would be certainly something worthwhile.
>> >> >>
>> >> >> Cheers,
>> >> >> Simon
>> >> >>
>> >> >>
>> >> >> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >> >> >
>> >> >> > Hi Gabriel,
>> >> >> >
>> >> >> > It's very nice usage you provided here. Maybe instead of adding new
>> >> >> > function we could extend packages_depenedncies then? To accept file path to
>> >> >> > dsc file.
>> >> >> >
>> >> >> > What about repos.dcf? Maybe additional repositories could be an attribute
>> >> >> > attached to returned character vector.
>> >> >> >
>> >> >> > The use case is to, for a given package sources, obtain its dependencies,
>> >> >> > so one can use that for installing them/mirroring CRAN subset, or whatever.
>> >> >> > The later is especially important for a production environment where one
>> >> >> > wants to have fixed version of packages, and mirroring relevant subset of
>> >> >> > CRAN is the most simple, and IMO reliable, way to manage such environment.
>> >> >> >
>> >> >> > Regards
>> >> >> > Jan
>> >> >> >
>> >> >> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
>> >> >> >
>> >> >> >> Hi Jan and Jan,
>> >> >> >>
>> >> >> >> Can you explain a little more what exactly you want the non-recursive,
>> >> >> >> non-version aware dependencies from an individual package for?
>> >> >> >>
>> >> >> >> Either way package_dependencies will do this for you* with a little
>> >> >> >> "aggressive convincing". It wants output from available.packages, but who
>> >> >> >> really cares what it wants? It's a function and we are people :)
>> >> >> >>
>> >> >> >>> library(tools)
>> >> >> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
>> >> >> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
>> >> >> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
>> >> >> >> $rtables
>> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >> >> >>
>> >> >> >>
>> >> >> >> The only gotcha that I see immediately is that "LinkingTo" isn't always
>> >> >> >> there (whereas it is with real output from available.packages). If you
>> >> >> >> know your package doesn't have that (or that it does) at call time , this
>> >> >> >> becomes a one-liner:
>> >> >> >>
>> >> >> >> package_dependencies("rtables", db =
>> >> >> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
>> >> >> >> c("Depends", "Suggests", "Imports"))
>> >> >> >> $rtables
>> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
>> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
>> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
>> >> >> >>
>> >> >> >> You can also trick it a slightly different way by giving it what it
>> >> >> >> actually wants
>> >> >> >>
>> >> >> >>> tdir <- tempdir()
>> >> >> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
>> >> >> >> "PACKAGES"))
>> >> >> >> [1] TRUE
>> >> >> >>> avl <- available.packages(paste0("file://", tdir))
>> >> >> >>> library(tools)
>> >> >> >>> package_dependencies("rtables", avl)
>> >> >> >> $rtables
>> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> >> >> [6] "grid"
>> >> >> >>
>> >> >> >>> package_dependencies("rtables", avl, which = "all")
>> >> >> >> $rtables
>> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
>> >> >> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
>> >> >> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
>> >> >> >>
>> >> >> >> So the only real benefits I see that we'd be picking up here is automatic
>> >> >> >> filtering by priority, and automatic extraction of the package name from
>> >> >> >> the DESCRIPTION file. I'm not sure either of those warrant a new exported
>> >> >> >> function that R-core has to maintain forever.
>> >> >> >>
>> >> >> >> Best,
>> >> >> >> ~G
>> >> >> >>
>> >> >> >> * I haven't tested this across all OSes, but I dont' know of any reason it
>> >> >> >> wouldn't work generally.
>> >> >> >>
>> >> >> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>> >> >> >>
>> >> >> >>> Hello Jan,
>> >> >> >>>
>> >> >> >>> Thanks for confirming about many packages reinventing this missing
>> >> >> >>> functionality.
>> >> >> >>> packages.dcf was not meant handle versions. It just extracts names of
>> >> >> >>> dependencies... Yes, such a simple thing, yet missing in base R.
>> >> >> >>>
>> >> >> >>> Versions of packages can be controlled when setting up R pkgs repo. This
>> >> >> >>> is
>> >> >> >>> how I used to handle it. Making a CRAN subset mirror of fixed version
>> >> >> >>> pkgs.
>> >> >> >>> BTW. function for that is also included in mentioned branch. I am just not
>> >> >> >>> proposing it, to increase the chance of having at least this simple,
>> >> >> >>> missing, functionality merged.
>> >> >> >>>
>> >> >> >>> Best
>> >> >> >>> Jan
>> >> >> >>>
>> >> >> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
>> >> >> >>>
>> >> >> >>>> Hello Jan,
>> >> >> >>>>
>> >> >> >>>> I have seen many packages that implemented dependencies "extraction" on
>> >> >> >>>> their own for internal purposes and today I was doing exactly that for
>> >> >> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
>> >> >> >>> sufficient
>> >> >> >>>> for me, but I had to take care of some \n chars (the overall returned
>> >> >> >>> value
>> >> >> >>>> has some rough edges, in my opinion). However, the function from the
>> >> >> >>> branch
>> >> >> >>>> seems to not care about version requirements, which are crucial for me.
>> >> >> >>>> Maybe that is something to reconsider before merging.
>> >> >> >>>>
>> >> >> >>>> Best,
>> >> >> >>>> Jan
>> >> >> >>>>
>> >> >> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
>> >> >> >>>> napsal:
>> >> >> >>>>
>> >> >> >>>>> Dear R devs,
>> >> >> >>>>>
>> >> >> >>>>> I would like to raise a request for a simple helper function.
>> >> >> >>>>> Utility function to extract package dependencies from DESCRIPTION file.
>> >> >> >>>>>
>> >> >> >>>>> I do think that tools package is better place, for such a fundamental
>> >> >> >>>>> functionality, than community packages.
>> >> >> >>>>>
>> >> >> >>>>> tools pkg seems perfect fit (having already great function
>> >> >> >>>>> write_PACKAGES).
>> >> >> >>>>>
>> >> >> >>>>> Functionality I am asking for is already in R svn repository since
>> >> >> >>> 2016,
>> >> >> >>>>> in
>> >> >> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
>> >> >> >>>>> Another one 'repos.dcf' would be a good functional complementary to it.
>> >> >> >>>>>
>> >> >> >>>>> Those two simple helper functions really makes it easier for
>> >> >> >>> organizations
>> >> >> >>>>> to glue together usage of their own R packages repos and CRAN repo in a
>> >> >> >>>>> smooth way. That could possibly help to offload CRAN from new
>> >> >> >>> submissions.
>> >> >> >>>>>
>> >> >> >>>>> gh mirror link for easy preview:
>> >> >> >>>>>
>> >> >> >>>>>
>> >> >> >>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
>> >> >> >>>>>
>> >> >> >>>>> Regards
>> >> >> >>>>> Jan Gorecki
>> >> >> >>>>>
>> >> >> >>>>>        [[alternative HTML version deleted]]
>> >> >> >>>>>
>> >> >> >>>>> ______________________________________________
>> >> >> >>>>> R-devel at r-project.org mailing list
>> >> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >>>>>
>> >> >> >>>>
>> >> >> >>>
>> >> >> >>>        [[alternative HTML version deleted]]
>> >> >> >>>
>> >> >> >>> ______________________________________________
>> >> >> >>> R-devel at r-project.org mailing list
>> >> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >>>
>> >> >> >>
>> >> >> >
>> >> >> >       [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-devel at r-project.org mailing list
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >
>> >> >>


From d|pter|x@w@ng @end|ng |rom gm@||@com  Sun Oct 30 00:57:50 2022
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Sat, 29 Oct 2022 18:57:50 -0400
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <CAHqSRuR8NUq7gr+vhw5xm=9gi974B9mkAz9t=7zayAZ-bBnPwg@mail.gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
 <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
 <EA4BFBB7-F037-4C41-917D-089997FEC255@gmail.com>
 <CAHqSRuR8NUq7gr+vhw5xm=9gi974B9mkAz9t=7zayAZ-bBnPwg@mail.gmail.com>
Message-ID: <A6A1C84C-0467-4FC3-9F14-764156C5FDF1@gmail.com>

Sorry I think I intended to say that 

1. the expressions within `delayed` don?t have to be executed if not assigned, and 
2. the enclosing runtime environment that is potentially referenced by the objects within delayed() can be released immediately either the returned values are referenced or not (compared to the environment() approach). 

For a toy example,

a <- function() {
  v <- rnorm(1e8)
  return(delayed({
    list(m = mean(v), plot_data = 1:3)
  }))
}
m1 <- a()

can immediately release the function runtime environment either the results of `a()` is assigned to an object (`mean(v)` is evaluated) or not (delayed is not evaluated, and gc?ed), hence the object `v` is freed from the memory.

Compared to the `delayedAssign+environment()` approach

b <- function(){
  v <- rnorm(1e8)
  delayedAssign(?m?, mean(v))
  plot_data <- 1:3
  return(environment())
}
m2 <- b()

`v` will be kept in memory until the returned environment itself gets deleted (rm(m2)). The situation might get tricky if the result of  ?b()? is further used and returned in nested pipes? (might keep parent frame, parent parent frames?)

- D

> On Oct 29, 2022, at 11:54 AM, Bill Dunlap <williamwdunlap at gmail.com> wrote:
> 
> >  the `delayed` object is ready to be garbage collected if not assigned immediately.
> I am not sure what is meant here.  Any object (at the R code level) is ready to be garbage collected if not given a name or is not part of an object with a name.  Do you mean a 'delayed' component of a list should be considered garbage if not 'immediately' extracted from a list?   Could you show a few usage cases?
> 
> -Bill
> 
> On Fri, Oct 28, 2022 at 7:41 PM Dipterix Wang <dipterix.wang at gmail.com <mailto:dipterix.wang at gmail.com>> wrote:
> 
>> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
>> 
>> > f <- function() invisible(5)
>> > f()
>> > .Last.value
>> [1] 5
> 
> 
> I understand .Last.value will capture the function returns, but that only happens in the top-level... I guess?
> 
> In the followings code, I think .Last.value does not capture the results of f, h, k, l
> 
> g <- function() {
>   f(); h(); k(); l()
>   return()
> }
> g()
> 
> 
> Maybe I caused confusion by mentioning `invisible` function. I guess it should be a new function (let?s call it `delayed`). The function does not have to be limited to ?printing?. For example, a digest key
> 
> 
> a <- function(key, value) {
>   map$set(key, value)
> 
>   return(delayed({
>     digest(value)
>   }))
> }
> 
> Or an async evaluation of which the saved result might not be needed if not assigned (detached), or the result will be ?joined? to the main process
> 
> a <- function(path) {
>   # async 
>   f <- future::future({
>     # calculate, and then write to path
>     saveRDS(?, path)
>   })
>   
>   return(delayed({
>     resolve(f) # wait till f to finish
> 
>     readRDS(path)
>   }))
> }
> 
> Although I could use wrappers such as formula, quosure, or environment to achieve similar results, there are two major differences
> 
> 1. There is an extra call to get the lazy-evaluated results (if I do want to resolve it)
> 2. The returned objects have to contain sort of ?environment? component in it. It can?t just be simple objects like vectors, matrices, lists, ? (also you can't immediately garbage collect the enclosing environment)
> 
> From the implementation perspective, the `delayed` object is ready to be garbage collected if not assigned immediately.
> 
> Best,
> - D
> 
>> 
>> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
>> 
>> > f <- function() invisible(5)
>> > f()
>> > .Last.value
>> [1] 5
>> 
>> Now that doesn't actually preclude what you're suggesting (just have to wait for .Last.value to be populated by something else), but it does complicate it to the extent that I'm not sure the benefit we'd get would be worth it.
>> 
>> Also, in the case you're describing, you'd be pushing the computational cost into printing, which, imo, is not where it should live. Printing a values generally speaking, should just print things, imo.
>> 
>> That said, if you really wanted to do this, you could approach the behavior you want, I believe (but again, I think this is a bad idea) by returning a custom class that wraps formula (or, I imagine, tidyverse style quosures) that reach back into the call frame you return them from, and evaluating them only on demand.
>> 
>> Best,
>> ~G 
>> 
>> 
>> This idea is somewhere between `delayedAssign` and eager evaluation. Maybe we could call it delayedInvisible()?
>> 
>> Best,
>> - Zhengjia
>> 
>> ______________________________________________
>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel <https://stat.ethz.ch/mailman/listinfo/r-devel>
> 


	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Sun Oct 30 08:43:04 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Sun, 30 Oct 2022 20:43:04 +1300
Subject: [Rd] Lazy-evaluate elements wrapped with invisible
In-Reply-To: <A6A1C84C-0467-4FC3-9F14-764156C5FDF1@gmail.com>
References: <0E096EB5-CEFD-4AA3-BB04-8A2891A370CC@gmail.com>
 <CAD4oTHGue80OoVyx4NSm2SLDkjNfH0NKWhR5-0ThjHe83n5y3A@mail.gmail.com>
 <EA4BFBB7-F037-4C41-917D-089997FEC255@gmail.com>
 <CAHqSRuR8NUq7gr+vhw5xm=9gi974B9mkAz9t=7zayAZ-bBnPwg@mail.gmail.com>
 <A6A1C84C-0467-4FC3-9F14-764156C5FDF1@gmail.com>
Message-ID: <D6853636-A4C0-40D1-B977-464CF1F9F522@R-project.org>

Dipterix,

I think delayedAssign() example you posted does what you want - if you don't assign the environment, it will be garbage-collected. If you fetch the value, it will be evaluated. However, I think what you meant is to have the result in one specific delayed symbol so:

a <- function() {
 v <- rnorm(1e8)
 local(delayedAssign('x', {
   list(m = mean(v), plot_data = 1:3)
 }))
}
m1 <- a()$x

If you don't assign it, everything will be garbage-collected. If you assign it, it is evaluated and you can garbage-collect the object you needed for its creation.

The only difference is that you need to refer to the value if you decide to assign it, so you never really want to use the environment itself.


With your delayed() wish you are really asking for a "naked" promise without the assignment part, but that is not allowed in R, because promises are only forced as part of symbol evaluation. If you do that (have delayed() return a promise), you will get this:

a <- function() {
 v <- rnorm(1e8)
 return(delayed({
   cat("computing...\n");
   list(m = mean(v), plot_data = 1:3)
 }))
}

> m1 <- a()
> m1
computing...
$m
[1] 0.03834447

$plot_data
[1] 1 2 3

> m2 <- { a(); a(); a() }
> m2
computing...
$m
[1] 0.05177236

$plot_data
[1] 1 2 3


But you cannot use the actual value without assigning it:

> a()$m
Error in a()$m : object of type 'promise' is not subsettable

because R will not try to evaluate a promise anywhere but in symbol evaluation.

Cheers,
Simon



> On Oct 30, 2022, at 11:57 AM, Dipterix Wang <dipterix.wang at gmail.com> wrote:
> 
> Sorry I think I intended to say that 
> 
> 1. the expressions within `delayed` don?t have to be executed if not assigned, and 
> 2. the enclosing runtime environment that is potentially referenced by the objects within delayed() can be released immediately either the returned values are referenced or not (compared to the environment() approach). 
> 
> For a toy example,
> 
> a <- function() {
>  v <- rnorm(1e8)
>  return(delayed({
>    list(m = mean(v), plot_data = 1:3)
>  }))
> }
> m1 <- a()
> 
> can immediately release the function runtime environment either the results of `a()` is assigned to an object (`mean(v)` is evaluated) or not (delayed is not evaluated, and gc?ed), hence the object `v` is freed from the memory.
> 
> Compared to the `delayedAssign+environment()` approach
> 
> b <- function(){
>  v <- rnorm(1e8)
>  delayedAssign(?m?, mean(v))
>  plot_data <- 1:3
>  return(environment())
> }
> m2 <- b()
> 
> `v` will be kept in memory until the returned environment itself gets deleted (rm(m2)). The situation might get tricky if the result of  ?b()? is further used and returned in nested pipes? (might keep parent frame, parent parent frames?)
> 
> - D
> 
>> On Oct 29, 2022, at 11:54 AM, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>> 
>>> the `delayed` object is ready to be garbage collected if not assigned immediately.
>> I am not sure what is meant here.  Any object (at the R code level) is ready to be garbage collected if not given a name or is not part of an object with a name.  Do you mean a 'delayed' component of a list should be considered garbage if not 'immediately' extracted from a list?   Could you show a few usage cases?
>> 
>> -Bill
>> 
>> On Fri, Oct 28, 2022 at 7:41 PM Dipterix Wang <dipterix.wang at gmail.com <mailto:dipterix.wang at gmail.com>> wrote:
>> 
>>> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
>>> 
>>>> f <- function() invisible(5)
>>>> f()
>>>> .Last.value
>>> [1] 5
>> 
>> 
>> I understand .Last.value will capture the function returns, but that only happens in the top-level... I guess?
>> 
>> In the followings code, I think .Last.value does not capture the results of f, h, k, l
>> 
>> g <- function() {
>>  f(); h(); k(); l()
>>  return()
>> }
>> g()
>> 
>> 
>> Maybe I caused confusion by mentioning `invisible` function. I guess it should be a new function (let?s call it `delayed`). The function does not have to be limited to ?printing?. For example, a digest key
>> 
>> 
>> a <- function(key, value) {
>>  map$set(key, value)
>> 
>>  return(delayed({
>>    digest(value)
>>  }))
>> }
>> 
>> Or an async evaluation of which the saved result might not be needed if not assigned (detached), or the result will be ?joined? to the main process
>> 
>> a <- function(path) {
>>  # async 
>>  f <- future::future({
>>    # calculate, and then write to path
>>    saveRDS(?, path)
>>  })
>> 
>>  return(delayed({
>>    resolve(f) # wait till f to finish
>> 
>>    readRDS(path)
>>  }))
>> }
>> 
>> Although I could use wrappers such as formula, quosure, or environment to achieve similar results, there are two major differences
>> 
>> 1. There is an extra call to get the lazy-evaluated results (if I do want to resolve it)
>> 2. The returned objects have to contain sort of ?environment? component in it. It can?t just be simple objects like vectors, matrices, lists, ? (also you can't immediately garbage collect the enclosing environment)
>> 
>> From the implementation perspective, the `delayed` object is ready to be garbage collected if not assigned immediately.
>> 
>> Best,
>> - D
>> 
>>> 
>>> This is not quite true. The value, even when invisible, is captured by .Last.value, and 
>>> 
>>>> f <- function() invisible(5)
>>>> f()
>>>> .Last.value
>>> [1] 5
>>> 
>>> Now that doesn't actually preclude what you're suggesting (just have to wait for .Last.value to be populated by something else), but it does complicate it to the extent that I'm not sure the benefit we'd get would be worth it.
>>> 
>>> Also, in the case you're describing, you'd be pushing the computational cost into printing, which, imo, is not where it should live. Printing a values generally speaking, should just print things, imo.
>>> 
>>> That said, if you really wanted to do this, you could approach the behavior you want, I believe (but again, I think this is a bad idea) by returning a custom class that wraps formula (or, I imagine, tidyverse style quosures) that reach back into the call frame you return them from, and evaluating them only on demand.
>>> 
>>> Best,
>>> ~G 
>>> 
>>> 
>>> This idea is somewhere between `delayedAssign` and eager evaluation. Maybe we could call it delayedInvisible()?
>>> 
>>> Best,
>>> - Zhengjia
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel <https://stat.ethz.ch/mailman/listinfo/r-devel>
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sun Oct 30 11:51:54 2022
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sun, 30 Oct 2022 10:51:54 +0000 (UTC)
Subject: [Rd] Bug with `[<-.POSIXlt` on specific OSes
In-Reply-To: <25427.56895.726279.318336@stat.math.ethz.ch>
References: <962239794.1944131.1665764474121.ref@mail.yahoo.com>
 <962239794.1944131.1665764474121@mail.yahoo.com>
 <20221018085625.CBFB82C1607@lynne.math.ethz.ch>
 <25427.56895.726279.318336@stat.math.ethz.ch>
Message-ID: <1981430134.2013676.1667127114617@mail.yahoo.com>

I?just?pointed?out?that,?in?https://stat.ethz.ch/pipermail/r-devel/2022-October/082082.html?("A?potential?POSIXlt->Date?bug?introduced?in?r-devel"),
dlt?<-?.POSIXlt(list(sec?=?c(-999,?10000?+?c(1:10,-Inf,?NA))?+?pi,
????????????????????????????????????????#?"out?of?range",?non-finite,?fractions
?????????????????????min?=?45L,?hour?=?c(21L,?3L,?NA,?4L),
?????????????????????mday?=?6L,?mon??=?c(11L,?NA,?3L),
?????????????????????year?=?116L,?wday?=?2L,?yday?=?340L,?isdst?=?1L))
doesn't?work?generally?as?an?example.

When?as.POSIXct(dlt)[1]?is?NA,?it?is?unexpected?to?me?that?as.POSIXct(balancePOSIXlt(dlt))[1]?is?not?NA.

It?happens?because,?unlike?'dlt',?'isdst'?is?0?in?balancePOSIXlt(dlt).?It?is?because?'isGMT'?is?TRUE?in?'do_balancePOSIXlt'?in?datetime.c,?as?the?number?of?components?of?'dlt'?is?9.


If?content?is?changed,?possible?output?of?'balancePOSIXlt'?that?I?expect:

Option?1:?companion?of?'as.POSIXct.POSIXlt'?applied?to?the?same?input,?as?with?function?'mktime'?in?C
-?The?input?"POSIXlt"?object?is?like?the?initial?struct?tm?whose?pointer?is?presented?to?'mktime'.
-?The?result?of?'as.POSIXct.POSIXlt'?is?like?the?return?value?of?'mktime'.
-?The?result?of?'balancePOSIXlt'?is?like?the?final?struct?tm?after?'mktime'?is?applied.

Option?2:?corresponding?with?'format.POSIXlt'?applied?to?the?same?input
'format.POSIXlt'?doesn't?fix?'wday'?or?'yday'.

format(dlt,?"%Y-%m-%d?%w?%j")[c(6,?9)]
#?c("2016-04-06?2?341",?"2016-04-07?2?341")


Side?issues?on?'format.POSIXlt':

-?%OSn?uses?unnormalized?'sec',?unlike?%S.
format(dlt,?"%S?%OS3")[1]??#?"24?-995.858"

-
format(dlt,?"%A")[12]??#?"-Inf"
It?is?rather?strange?to?me?to?get?"-Inf"?from?format?%A.?I?expect?to?get?weekday?name.?NA?is?acceptable.
Function?'weekdays'?use?it.


The?reported?issue?remains.

x?<-?as.POSIXlt(as.POSIXct("2013-01-31",?tz?=?"America/Chicago"))
Sys.setenv(TZ?=?"UTC")
x[1]?<-?NA
#?Error?in?x[[n]][i]?<-?value[[n]]?:?replacement?has?length?zero




---------------------------
On?Saturday,?22?October?2022,?07:12:51?pm?GMT+7,?Martin?Maechler?<maechler at stat.math.ethz.ch>?wrote:


>>>>>?Martin?Maechler
>>>>>????on?Tue,?18?Oct?2022?10:56:25?+0200?writes:

>>>>>?Suharto?Anggono?Suharto?Anggono?via?R-devel
>>>>>????on?Fri,?14?Oct?2022?16:21:14?+0000?(UTC)?writes:

????>>?I?think?'[.POSIXlt'?and?'[<-.POSIXlt'?don't?need?to
????>>?normalize?out-of-range?values.?I?think?they?just?make
????>>?same?length?for?all?components,?to?ensure?correct
????>>?extraction?or?replacement?for?arbitrary?index.

????>?Yes,?you?are?right;?this?is?definitely?correct...??and
????>?would?be?more?efficient.

????>?At?the?moment,?we?were?mostly?focused?on?*correct*
????>?behaviour?in?the?case?of?"ragged"?and/or?out-of-range
????>?POSIXlt?objects.


????>>?I?have?a?thought?of?adding?an?optional?argument?for
????>>?'as.POSIXlt'?applied?to?"POSIXlt"?object.?Possible?name:
????>>?normalize?adjust?fixup

????>>?To?allow?recycling?only?without?changing?content,?instead
????>>?of?TRUE?or?FALSE,?maybe?choice,?like?fixup?=?c("none",
????>>?"balance",?"normalize")?,?where?"normalize"?implies
????>>?"balance",?or?adjust?=?c("none",?"length",?"content",
????>>?"value")?,?where?"content"?and?"value"?are?synonymous.

????>?Such?an?optional?argument?for?as.POSIXlt()?would?be?a
????>?possibility?and?could?replace?the?new?and?for?now?still
????>?somewhat?experimental?balancePOSIXlt().

????>?+:?One?advantage?of?(one?of?the?above?proposals)?would
????>?be?that?it?does?not?take?up?a?new?function?name.

????>?-:?OTOH,?it?may?be?overdoing?the?semantics

????>??????as.POSIXlt(<POSIXlt>,?<some>?=?<other>)

????>??and?it?may?be?harder?to?understand?by
????>?non-sophisticated?R?users,?because?as.POSIXlt()?is?a
????>?generic?with?several?methods,?and?these?extra?arguments
????>?would?probably?only?apply?to?the?as.POSIXlt.default()
????>?method?and?there?*only*?for?the?case?where?the?argument
????>?inherits?from?"POSIXlt"?..?and?all?that?being?somewhat
????>?subtle?to?see?for?Joe?Average?UseR

????>?I?agree?that?it?will?make?sense?to?get?an?R-level
????>?version,?either?using?new?arguments?in?as.POSIXlt()?or
????>?(still?my?preference)?in?balancePOSIXlt()?to?allow?to
????>?"only?fill?all?components".

????>?HOWEVER?note?that?the?"filling"?(by?recycling)?and?no
????>?extra?checking?will?often?lead?to?internally
????>?inconsistent?lt?objects.??Eg.?Daylight?saving?time
????>?(isdst?=?1?or?not)?can?only?be?known?when?the?day?(and
????>?hour)?is?known?and?that?can?be?shifted?by?out-of-range
????>?sec/min/hour?..?((and?of?course?for?1?hour?per?year,?a
????>?time?hour=2?will?*need*?specification?of?isdst?in?order
????>?to?know?which?of?the?2:<min>:<sec>?is?meant))?also?$wday
????>?and?$yday?(who?are?described?as?read-only)?also?can?only
????>?be?checked?after?validation?or?"in-ranging"?of?the
????>?sec/min/hour/mday/mon?components?so?their?simple
????>?recycling?will?typically?be?incorrect.

????>?That's?why?I?had?opted?to?*mainly*?do?full?"balancing"
????>?(in?my?sense),?i.e.,?simultaneous?both?filling?and
????>?"in-ranging".

A?few?hours?ago?[R-devel?svn?rev?83156;?2022-10-22?10:18:38?+0200]
I?have?committed?an?enhanced?version?of?balancePOSIXlt()??which
now?has?an?optional?'fill.only?=?F/T'?rgument.
When?TRUE?(not?by?default),?it?will?only?do?the?"filling",?i.e.,
recyclying?of?less-than-full-length?components,?without?any
"in-ranging"?nor?musch?further?validity?checking.

Currently,?almost?all?POSIXlt?methods?using?balancePOSIXlt(),
notably
????????[.POSIXlt????and????[<-.POSIXlt

use??balancePOSIXlt(x,?fill.only=TRUE?..)
and?hence?are?almost?as?fast?as?previously?(when?they?did?no
balancing?and?gave?sometimes?wrong?results?or?errored?in?case?of
partially?filled?POSIXlt).



????>>?By?the?way,?Inf?in?'sec'?component?is?out-of-range!

????>?Yes,?the?non-finite?"values"?{+/-Inf,?NaN,?NA}?are?all
????>?"special",?and?we?had?decided?to?allow?them?for
????>?compatibility?with?classes?"Date"?and?"POSIXct".

????>?BTW,?a?few?days?ago,?I?have?updated?the
????>?help("DateTimeClasses")?page?in?R-devel?to?document?a
????>?bit?more,?notably?that?"ragged"?and?out-of-range?POSIXlt
????>?may?exist...??see?(the?always?+-?current?R-devel?Help
????>?pages?at)
????>?https://stat.ethz.ch/R-manual/R-devel/library/base/html/DateTimeClasses.html


????>>?For?'gmtoff',?NA?or?0?should?be?put?for?unknown.?A?known
????>>?'gmtoff'?may?be?[ositive,?negative,?or?zero.?The
????>>?documentation?says??gmtoff??(Optional.)?The?offset?in
????>>?seconds?from?GMT:?positive?values?are?East?of?the
????>>?meridian.??Usually??NA??if?unknown,?but??0??could?mean
????>>?unknown.


????>>?dlt?<-?.POSIXlt(list(sec?=?c(-999,?10000?+?c(1:10,-Inf,
????>>?NA))?+?pi,?#?"out?of?range",?non-finite,?fractions?min?=
????>>?45L,?hour?=?c(21L,?3L,?NA,?4L),?mday?=?6L,?mon?=?c(11L,
????>>?NA,?3L),?year?=?116L,?wday?=?2L,?yday?=?340L,?isdst?=
????>>?1L))

????>>?as.POSIXct(dlt)[1]?is?NA?on?Linux?with?timezone?without
????>>?DST.?For?example,?after?Sys.setenv(TZ?=?"EST")

????>?Hmm...?I?needed?time?to?look?at?the?above.?Indeed,?one
????>?gets?NA?(and?has?in?previous?versions?of?R)?in?such?a
????>?case.

????>?After?applying?balancePOSIXlt(),?one?no?longer?gets?NA.
????>?Are?you?proposing?that?we?should?do?that?(or?possibly
????>?simple?recycling)?in?as.POSIXct.POSIXlt()??

I?am?still?waiting?for?comments?(also?by?others)?or?other
remarks?or?answers?on?this?question/topic..


Martin


From pd@me@ @end|ng |rom cb@@dk  Mon Oct 31 10:29:07 2022
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Mon, 31 Oct 2022 09:29:07 +0000
Subject: [Rd] R 4.2.2 is released
Message-ID: <68F6A8B5-A842-447C-A1DA-D9C8F6B5B176@cbs.dk>

The build system rolled up R-4.2.2.tar.gz (codename "Innocent and Trusting") this morning.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.2.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 320967884b547734d6279dedbc739dd4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 1ff069b3d34234bb6df71298380da3a8
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = df3c0a29151cfbc40e6a07a5ad398de1
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = b38d94569700664205a76a7de836ba83
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = b154500667b5ebb480f1086dd817f017
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 45b6d2e88a6ecb5b24fa33a781351cd5
MD5 (VERSION-INFO.dcf) = 7c5057ff5958b2312a88556487fae295
MD5 (R-4/R-4.2.2.tar.gz) = b154500667b5ebb480f1086dd817f017

60a0d150e6fc1f424be76ad7b645d236b56e747692a4679f81ce6536c550e949  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
d8cfbd44efe3311bc2d4a71a0850c50aebc18a21affac951898a3b6b45dfe777  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
f9700348b098129906da3489ce7299f86ded993aac2a8861349b1935652f8f6d  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
cde079b6beab7d700d3d4ecda494e2681ad3b7f8fab13b68be090f949393ec62  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
0ff62b42ec51afa5713caee7c4fde7a0c45940ba39bef8c5c9487fef0c953df5  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
8319c5415de58ee10d4bc058d79c370fd8e6b2ad09e25d7a1e04b74ca5f380a6  THANKS
4bf8efc154e3f48800a9ddd1dd5bf333d3cf4f7e943876372699dab76e693318  VERSION-INFO.dcf
0ff62b42ec51afa5713caee7c4fde7a0c45940ba39bef8c5c9487fef0c953df5  R-4/R-4.2.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.2.2:

  NEW FEATURES:

    * tools::Rdiff(useDiff = TRUE) checks for the presence of an
      external diff command and switches to useDiff = FALSE if none is
      found.  This allows R CMD Rdiff to always work.

    * On Windows, environment variable R_LIBCURL_SSL_REVOKE_BEST_EFFORT
      can be used to switch to only 'best-effort' SSL certificate
      revocation checks with the default "libcurl" download method.
      This reduces security, but may be needed for downloads to work
      with MITM proxies (PR#18379).

    * (macOS) The run-time check for libraries from XQuartz for X11 and
      Tcl/Tk no longer uses otool from the Apple Developer Tools
      (PR#18400).

    * The LaTeX style for producing the PDF manuals, Rd.sty, now loads
      the standard amsmath, amsfonts and amssymb packages for greater
      coverage of math commands in the Rd \eqn and \deqn macros.  The
      \mathscr LaTeX command is also provided (via the mathrsfs
      package, if available, or the amsfonts bundle otherwise),
      fulfilling the wish of PR#18398.

    * (Windows) The default format of readClipboard() and
      writeClipboard() has been changed to 13 (CF_UNICODETEXT).

  INSTALLATION on a UNIX-ALIKE:

    * The PDF manuals (if built) can be compacted by the new target
      make compact-pdf (at the top level or in directory doc/manual).

    * There is now configure support for LLVM clang 15 on Linux, which
      defaults to position-independent (PIE) executables whereas
      gfortran does not.

    * Many small changes to ease compilation (and suppress warnings)
      with LLVM clang 15.

  BUG FIXES:

    * Rscript -e would fail if stdin were closed (Reported by Henrik
      Bengtsson.)

    * qt(*, log.p=TRUE) in outer tails no longer produces NaN in its
      final steps, thus fixing PR#18360.

    * tools::Rd2latex() now escapes hashes and ampersands when writing
      URLs, fixing LaTeX errors with such URLs in \tabular.

    * When isGeneric(f, fdef=*) is used with mismatching names, the
      warning is better understandable; reported (with fix) in PR#18370
      by Gabe Becker.

    * poly(x, n) now works again (and is now documented) when x is a
      "Date" or "POSIXct" object, or of another class while fulfilling
      mode(x) == "numeric".  This also enables poly(x, *, raw=TRUE) for
      such variables.  Reported by Michael Chirico to R-devel.

    * write.table(), write.csv() and write.csv2() restore their
      numerical precision (internal equivalent of digits = 15) after an
      interrupt (PR#18384).

    * One can now read also byte FF from a clipboard connection
      (PR#18385).

    * source("") and source(character()) now give more helpful error
      messages.

    * R CMD check --as-cran set _R_CHECK_TIMINGS_ too late to have the
      intended effect.

    * as.POSIXlt(x) now also works with very large dates x, fixing
      PR#18401 reported by Hannes M"uhleisen.

    * Files can now be extracted even from very large zip archives
      (PR#18390, thanks to Martin Jakt).

    * Non-finite objects of class "POSIXlt" are now correctly coerced
      to classes "Date" and "POSIXct"; following up on the extension to
      format() them correctly.

    * Added methods for is.finite(), is.infinite() and is.nan() for
      "POSIXlt" date-time objects.

  BUG FIXES on Windows:

    * Non-ASCII characters are now properly displayed on Windows in
      windows created using GraphApp via e.g. winDialogString thanks to
      a workaround for an at least surprising Windows behavior with
      UTF-8 as the system encoding (PR#18382).

    * Find and replace operations work again in the script editor in
      Rgui on Windows.

    * Computation of window size based on requested client size in
      GraphApp when running in a multi-byte locale on Windows has been
      fixed (regression in R 4.2.0 for users of systems where R 4.1
      used a single-byte locale).  Rgui again respects the number of
      console rows and columns given in Rconsole file.

    * Rterm support for Alt+xxx sequences has been fixed to produce the
      corresponding character (only) once. This fixes pasting text with
      tilde on Italian keyboard (PR#18391).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


