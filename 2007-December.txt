From stgries at gmail.com  Sat Dec  1 01:40:35 2007
From: stgries at gmail.com (stgries at gmail.com)
Date: Sat,  1 Dec 2007 01:40:35 +0100 (CET)
Subject: [Rd] NAs produced by integer overflow (PR#10482)
Message-ID: <20071201004035.88521282EF48@mail.pubhealth.ku.dk>

Full_Name: Stefan Th. Gries
Version: R version 2.6.1 (2007-11-26)
OS: Windows XP Home SP2
Submission from: (NULL) (68.6.47.105)


Hi

A simple computation results in integer overflow:

These are the relevant vectors:

> sum(cur.obs)
[1] 110231

> colfreq
      other        past     perfect     present progressive 
      14845        1222        4776      101347        2863 

> sum(colfreq)
[1] 125053

Now ...

# this works ...
> sum(cur.obs)*(colfreq/sum(colfreq)) # note: brackets around the division
      other        past     perfect     present progressive 
  13085.485    1077.162    4209.921   89334.771    2523.661 

# and this doesn't ...
> sum(cur.obs)*colfreq/sum(colfreq) # note: no brackets around the division
      other        past     perfect     present progressive 
  13085.485    1077.162    4209.921                2523.661 
Warning message:
In sum(cur.obs) * colfreq : NAs produced by integer overflow



I saw this was reported for R 2.3.0 and 2.6.0 before, but I don't know whether
it ever got dealt with. Here's my version information:

# -------------------------------------
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          6.1                         
year           2007                        
month          11                          
day            26                          
svn rev        43537                       
language       R                           
version.string R version 2.6.1 (2007-11-26)
# -------------------------------------

STG


From kate at few.vu.nl  Sat Dec  1 14:11:14 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Sat, 1 Dec 2007 14:11:14 +0100 (CET)
Subject: [Rd] Puzzling message: "no man files in this package"
In-Reply-To: <68735E80D5EB7C4F8477BF00C450D38E02F25507@mailc.lumcnet.prod.intern>
References: <68735E80D5EB7C4F8477BF00C450D38E02F25507@mailc.lumcnet.prod.intern>
Message-ID: <Pine.GSO.4.56.0712011404170.28061@laurel.few.vu.nl>

Dear Jelle,

Could you put the package somewhere public?  This would make it easier to
diagnose the problem.

On Fri, 30 Nov 2007 J.J.Goeman at lumc.nl wrote:

>  Dear R developers,
>
> When building/checking my package (in R 2.6.1 under windows) I run into
> some messages that I do not completely understand and that do not give
> me precise enough leads to pinpoint where the error in my package is. I
> would be very grateful for any suggestions. Did anyone else encounter
> the same problem before?
>
> When building or installing the package, I get the message (no error or
> warning, just a message) "no man files in this package", instead of the
> usual "installing man source files". This puzzles me greatly, as I have
> a "man" subdirectory with several .Rd files, all of which seem to be
> properly handled later on in the install/build process, when the
> "Building/Updating help files" step seems to go fine for all Rd files.
> Both install and build run to conclusion without reporting formal errors
> or warnings.
>
> Next, Rcmd check gives me a lot of nice OK's (even: * checking Rd files
> ... OK), and then
>
> * checking Rd cross-references ... WARNING
> Error in Rd_db(package, lib.loc = lib.loc) :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd objects
> Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db
> Execution halted
>
> Again puzzling! I get the impression that the error message is not meant
> for me (I'm not the one who is supposed to put Rd objects into
> M:/R/packages/penalized.Rcheck/penalized, am I?), but that the error
> somehow prevents me from seeing the real warning.
>
> The same warning with error is repeated several times at "checking for
> code/documentation mismatches" and at "checking Rd \usage sections".
>
> It's obvious that there is something wrong in my .Rd files. But I can't
> find any mistakes by just looking through them, and the error messages
> don't mean much to me. Did I overlook something obvious?
>
> The complete install and build output is given below.
>
> Thanks in advance,
>
> Jelle
>
>
>
>
> ************************
> *** Rcmd install:
> ************************
>
> installing R.css in M:/R/packages/penalized.Rcheck
>
>
> ---------- Making package penalized ------------
>   adding build stamp to DESCRIPTION
>   installing NAMESPACE file and metadata
>   installing R files
>   installing inst files
>   installing data files
>   preparing package penalized for lazy loading
> Loading required package: survival
> Loading required package: splines
> Creating a new generic function for "coefficients" in "penalized"
> Creating a new generic function for "residuals" in "penalized"
> Creating a new generic function for "fitted.values" in "penalized"
> Creating a new generic function for "weights" in "penalized"
> Creating a new generic function for "plot" in "penalized"
> Creating a new generic function for "as.matrix" in "penalized"
> Creating a new generic function for "time" in "penalized"
> Creating a new generic function for "as.list" in "penalized"
>   no man files in this package
>   installing indices
>   not zipping data
>   installing help
>  >>> Building/Updating help pages for package 'penalized'
>      Formats: text html latex example chm
>   breslow                           text    html    latex
>   contrasts                         text    html    latex   example
>   cvl                               text    html    latex   example
>   nki70                             text    html    latex
>   penalized                         text    html    latex   example
>   penfit                            text    html    latex
>   plotpath                          text    html    latex   example
>   adding MD5 sums
>
> * DONE (penalized)
>
>
> ************************
> *** Rcmd check:
> ************************
>
> * using log directory 'M:/R/packages/penalized.Rcheck'
> * using R version 2.6.1 (2007-11-26)
> * checking for file 'penalized/DESCRIPTION' ... OK
> * this is package 'penalized' version '0.9-17'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'penalized' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies
> ... OK
> * checking whether the name space can be loaded with stated dependencies
> ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd cross-references ... WARNING
> Error in Rd_db(package, lib.loc = lib.loc) :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd objects
> Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db
> Execution halted
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... WARNING
> Error in tools::codoc(package = "penalized") :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd sources
> Execution halted
> Error in tools::codocData(package = "penalized") :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd sources
> Execution halted
> Error in tools::codocClasses(package = "penalized") :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd sources
> Execution halted
> * checking Rd \usage sections ... WARNING
> Error in tools::checkDocFiles(package = "penalized") :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd sources
> Execution halted
> Functions with \usage entries need to have the appropriate \alias
> entries,
> and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> Error in tools::checkDocStyle(package = "penalized") :
>   directory 'M:/R/packages/penalized.Rcheck/penalized' does not contain
> Rd sources
> Execution halted
> The \usage entries for S3 methods should use the \method markup and not
> their full name.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking data for non-ASCII characters ... OK
> * creating penalized-Ex.R ... OK
> * checking examples ... OK
> * checking package vignettes in 'inst/doc' ... OK
> * creating penalized-manual.tex ... OK
> * checking penalized-manual.tex ... OK
>
>
>
>
>
> www.msbi.nl/goeman
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Sat Dec  1 14:43:31 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 01 Dec 2007 14:43:31 +0100
Subject: [Rd] NAs produced by integer overflow (PR#10482)
In-Reply-To: <20071201004035.88521282EF48@mail.pubhealth.ku.dk>
References: <20071201004035.88521282EF48@mail.pubhealth.ku.dk>
Message-ID: <47516503.8030600@biostat.ku.dk>

stgries at gmail.com wrote:
> Full_Name: Stefan Th. Gries
> Version: R version 2.6.1 (2007-11-26)
> OS: Windows XP Home SP2
> Submission from: (NULL) (68.6.47.105)
>
>
> Hi
>
> A simple computation results in integer overflow:
>
> These are the relevant vectors:
>
>   
>> sum(cur.obs)
>>     
> [1] 110231
>
>   
>> colfreq
>>     
>       other        past     perfect     present progressive 
>       14845        1222        4776      101347        2863 
>
>   
>> sum(colfreq)
>>     
> [1] 125053
>
> Now ...
>
> # this works ...
>   
>> sum(cur.obs)*(colfreq/sum(colfreq)) # note: brackets around the division
>>     
>       other        past     perfect     present progressive 
>   13085.485    1077.162    4209.921   89334.771    2523.661 
>
> # and this doesn't ...
>   
>> sum(cur.obs)*colfreq/sum(colfreq) # note: no brackets around the division
>>     
>       other        past     perfect     present progressive 
>   13085.485    1077.162    4209.921                2523.661 
> Warning message:
> In sum(cur.obs) * colfreq : NAs produced by integer overflow
>
>
>
> I saw this was reported for R 2.3.0 and 2.6.0 before, but I don't know whether
> it ever got dealt with. 
Well, it is what happens when you multiply two large integers. How would 
you expect it to be "dealt with"? If we are to have a rule that the 
product of two integers is an integer, there's no alternative. 
Alternatively, the result could be automatically coerced to double and 
would then unpredictably be either integer or double.
> Here's my version information:
>
> # -------------------------------------
> platform       i386-pc-mingw32             
> arch           i386                        
> os             mingw32                     
> system         i386, mingw32               
> status                                     
> major          2                           
> minor          6.1                         
> year           2007                        
> month          11                          
> day            26                          
> svn rev        43537                       
> language       R                           
> version.string R version 2.6.1 (2007-11-26)
> # -------------------------------------
>
> STG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Sat Dec  1 14:45:31 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sat,  1 Dec 2007 14:45:31 +0100 (CET)
Subject: [Rd] dataframe does not expand as.Dates objects (PR#10481)
Message-ID: <20071201134531.5E4C5282EF48@mail.pubhealth.ku.dk>

>From the help for data.frame() (sic):

      Objects passed to 'data.frame' should have the same number of
      rows, but atomic vectors, factors and character vectors protected
      by 'I' will be recycled a whole number of times if necessary.

so this is the documented behaviour.

Perhaps you meant this for the wishlist, but you did not follow the 
instructions in the FAQ for sending it there.  Nor is there any case made 
for why this would be desirable (and second-guessing the user's intentions 
often is not).

I'll place it on the wishlist, but personally think it would be 
undesirable to add such an inconsistency to the language.

On Fri, 30 Nov 2007, adrian_d at eskimo.com wrote:

> Full_Name: Adrian Dragulescu
> Version: 2.6.0
> OS: Windows
> Submission from: (NULL) (216.99.178.65)
>
>
>>   data.frame(x=1:10, y="A")  # expands fine
>    x y
> 1   1 A
> 2   2 A
> 3   3 A
> 4   4 A
> 5   5 A
> 6   6 A
> 7   7 A
> 8   8 A
> 9   9 A
> 10 10 A
>>
>>   data.frame(x=1:10, z=as.Date("2007-01-01"))  # get an error
> Error in data.frame(x = 1:10, z = as.Date("2007-01-01")) :
>  arguments imply differing number of rows: 10, 1
>>
>
> I always have to write a "rep" for date objects.  It is not the end of the world
> but it would be nice if dates would behave like characters or numbers.
>
> Thank you.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Dec  1 14:55:15 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sat,  1 Dec 2007 14:55:15 +0100 (CET)
Subject: [Rd] NAs produced by integer overflow (PR#10482)
Message-ID: <20071201135516.008E2282EF48@mail.pubhealth.ku.dk>

What is the bug here?  You haven't told us what you think it is, and

> 110231L * 101347L
[1] NA
Warning message:
In 110231L * 101347L : NAs produced by integer overflow

is both intentional and documented: see ?Arithmetic.

Please do give a reproducible example (as we ask): yours is not as we 
have to guess the types of the objects (I can get similar results if I 
guess "integer", but not quite the same).

cur.obs <- 110231L
colfreq <- as.integer(c(14845,1222,4776,101347,2863))
names(colfreq) <- c("other","past","perfect","present","progressive")
sum(cur.obs)*(colfreq/sum(colfreq))
       other        past     perfect     present progressive
   13085.485    1077.162    4209.921   89334.771    2523.661
sum(cur.obs)*colfreq/sum(colfreq)
       other        past     perfect     present progressive
   13085.485    1077.162    4209.921          NA    2523.661
Warning message:
In sum(cur.obs) * colfreq : NAs produced by integer overflow

Note the fourth entry.


On Sat, 1 Dec 2007, stgries at gmail.com wrote:

> Full_Name: Stefan Th. Gries
> Version: R version 2.6.1 (2007-11-26)
> OS: Windows XP Home SP2
> Submission from: (NULL) (68.6.47.105)
>
>
> Hi
>
> A simple computation results in integer overflow:
>
> These are the relevant vectors:
>
>> sum(cur.obs)
> [1] 110231
>
>> colfreq
>      other        past     perfect     present progressive
>      14845        1222        4776      101347        2863
>
>> sum(colfreq)
> [1] 125053
>
> Now ...
>
> # this works ...
>> sum(cur.obs)*(colfreq/sum(colfreq)) # note: brackets around the division
>      other        past     perfect     present progressive
>  13085.485    1077.162    4209.921   89334.771    2523.661
>
> # and this doesn't ...
>> sum(cur.obs)*colfreq/sum(colfreq) # note: no brackets around the division
>      other        past     perfect     present progressive
>  13085.485    1077.162    4209.921                2523.661
> Warning message:
> In sum(cur.obs) * colfreq : NAs produced by integer overflow
>
>
>
> I saw this was reported for R 2.3.0 and 2.6.0 before, but I don't know whether
> it ever got dealt with. Here's my version information:

Please don't be vague: you need to give URLs for claims that something is 
'reported'.


> # -------------------------------------
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          6.1
> year           2007
> month          11
> day            26
> svn rev        43537
> language       R
> version.string R version 2.6.1 (2007-11-26)
> # -------------------------------------
>
> STG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kate at few.vu.nl  Sat Dec  1 18:18:21 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Sat, 1 Dec 2007 18:18:21 +0100 (CET)
Subject: [Rd] Puzzling message: "no man files in this package"
In-Reply-To: <68735E80D5EB7C4F8477BF00C450D38E02F25515@mailc.lumcnet.prod.intern>
References: <68735E80D5EB7C4F8477BF00C450D38E02F25507@mailc.lumcnet.prod.intern>
	<Pine.GSO.4.56.0712011404170.28061@laurel.few.vu.nl>
	<68735E80D5EB7C4F8477BF00C450D38E02F25515@mailc.lumcnet.prod.intern>
Message-ID: <Pine.GSO.4.56.0712011806520.812@laurel.few.vu.nl>

strange - but at least the strangeness resolved itself.  If the problem
was with your code as opposed to your build environment, I guess you'll
soon here from a CRAN maintainer about it (and by the way: CRAN incoming
does not allow read permission for others, so if you upload there it's
not really publicly available yet).

On Sat, 1 Dec 2007 J.J.Goeman at lumc.nl wrote:

>  Dear Katherine,
>
> To complicate things: whereas I was able to reproduce the problem many
> times yesterday, also after restarting my computer several times and
> with R 2.5.1, R 2.6.0 and R 2.6.1, the package builds and checks
> _completely without errors or warnings_ and installs without the strange
> message today. And I did not change _a single thing_ to the package in
> between. It's a bit of a bewildering experience :-{ but at least it
> solves my immediate problem :-).
>
> I've uploaded the package to CRAN incoming (penalized_0.9-17.tar.gz),
> should you still want to have a look.
>
> My apologies for bothering you with a semi-reproducible (?!) problem.
>
> Jelle
>
>
> > -----Original Message-----
> > From: Katharine Mullen [mailto:kate at few.vu.nl]
> > Sent: zaterdag 1 december 2007 14:11
> > To: Goeman, J.J. (MSTAT)
> > Cc: r-devel at r-project.org
> > Subject: Re: [Rd] Puzzling message: "no man files in this package"
> >
> > Dear Jelle,
> >
> > Could you put the package somewhere public?  This would make
> > it easier to diagnose the problem.
> >
> > On Fri, 30 Nov 2007 J.J.Goeman at lumc.nl wrote:
> >
> > >  Dear R developers,
> > >
> > > When building/checking my package (in R 2.6.1 under windows) I run
> > > into some messages that I do not completely understand and
> > that do not
> > > give me precise enough leads to pinpoint where the error in
> > my package
> > > is. I would be very grateful for any suggestions. Did anyone else
> > > encounter the same problem before?
> > >
> > > When building or installing the package, I get the message
> > (no error
> > > or warning, just a message) "no man files in this package",
> > instead of
> > > the usual "installing man source files". This puzzles me
> > greatly, as I
> > > have a "man" subdirectory with several .Rd files, all of
> > which seem to
> > > be properly handled later on in the install/build process, when the
> > > "Building/Updating help files" step seems to go fine for
> > all Rd files.
> > > Both install and build run to conclusion without reporting formal
> > > errors or warnings.
> > >
> > > Next, Rcmd check gives me a lot of nice OK's (even: * checking Rd
> > > files ... OK), and then
> > >
> > > * checking Rd cross-references ... WARNING Error in Rd_db(package,
> > > lib.loc = lib.loc) :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd objects
> > > Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db Execution halted
> > >
> > > Again puzzling! I get the impression that the error message is not
> > > meant for me (I'm not the one who is supposed to put Rd
> > objects into
> > > M:/R/packages/penalized.Rcheck/penalized, am I?), but that
> > the error
> > > somehow prevents me from seeing the real warning.
> > >
> > > The same warning with error is repeated several times at
> > "checking for
> > > code/documentation mismatches" and at "checking Rd \usage sections".
> > >
> > > It's obvious that there is something wrong in my .Rd files. But I
> > > can't find any mistakes by just looking through them, and the error
> > > messages don't mean much to me. Did I overlook something obvious?
> > >
> > > The complete install and build output is given below.
> > >
> > > Thanks in advance,
> > >
> > > Jelle
> > >
> > >
> > >
> > >
> > > ************************
> > > *** Rcmd install:
> > > ************************
> > >
> > > installing R.css in M:/R/packages/penalized.Rcheck
> > >
> > >
> > > ---------- Making package penalized ------------
> > >   adding build stamp to DESCRIPTION
> > >   installing NAMESPACE file and metadata
> > >   installing R files
> > >   installing inst files
> > >   installing data files
> > >   preparing package penalized for lazy loading Loading required
> > > package: survival Loading required package: splines Creating a new
> > > generic function for "coefficients" in "penalized"
> > > Creating a new generic function for "residuals" in "penalized"
> > > Creating a new generic function for "fitted.values" in "penalized"
> > > Creating a new generic function for "weights" in "penalized"
> > > Creating a new generic function for "plot" in "penalized"
> > > Creating a new generic function for "as.matrix" in "penalized"
> > > Creating a new generic function for "time" in "penalized"
> > > Creating a new generic function for "as.list" in "penalized"
> > >   no man files in this package
> > >   installing indices
> > >   not zipping data
> > >   installing help
> > >  >>> Building/Updating help pages for package 'penalized'
> > >      Formats: text html latex example chm
> > >   breslow                           text    html    latex
> > >   contrasts                         text    html    latex   example
> > >   cvl                               text    html    latex   example
> > >   nki70                             text    html    latex
> > >   penalized                         text    html    latex   example
> > >   penfit                            text    html    latex
> > >   plotpath                          text    html    latex   example
> > >   adding MD5 sums
> > >
> > > * DONE (penalized)
> > >
> > >
> > > ************************
> > > *** Rcmd check:
> > > ************************
> > >
> > > * using log directory 'M:/R/packages/penalized.Rcheck'
> > > * using R version 2.6.1 (2007-11-26)
> > > * checking for file 'penalized/DESCRIPTION' ... OK
> > > * this is package 'penalized' version '0.9-17'
> > > * checking package name space information ... OK
> > > * checking package dependencies ... OK
> > > * checking if this is a source package ... OK
> > > * checking whether package 'penalized' can be installed ... OK
> > > * checking package directory ... OK
> > > * checking for portable file names ... OK
> > > * checking DESCRIPTION meta-information ... OK
> > > * checking top-level files ... OK
> > > * checking index information ... OK
> > > * checking package subdirectories ... OK
> > > * checking R files for non-ASCII characters ... OK
> > > * checking R files for syntax errors ... OK
> > > * checking whether the package can be loaded ... OK
> > > * checking whether the package can be loaded with stated
> > dependencies
> > > ... OK
> > > * checking whether the name space can be loaded with stated
> > > dependencies ... OK
> > > * checking for unstated dependencies in R code ... OK
> > > * checking S3 generic/method consistency ... OK
> > > * checking replacement functions ... OK
> > > * checking foreign function calls ... OK
> > > * checking R code for possible problems ... OK
> > > * checking Rd files ... OK
> > > * checking Rd cross-references ... WARNING Error in Rd_db(package,
> > > lib.loc = lib.loc) :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd objects
> > > Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db Execution halted
> > > * checking for missing documentation entries ... OK
> > > * checking for code/documentation mismatches ... WARNING Error in
> > > tools::codoc(package = "penalized") :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd sources Execution halted Error in
> > tools::codocData(package
> > > = "penalized") :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd sources Execution halted Error in
> > > tools::codocClasses(package = "penalized") :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd sources Execution halted
> > > * checking Rd \usage sections ... WARNING Error in
> > > tools::checkDocFiles(package = "penalized") :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd sources Execution halted Functions with \usage
> > entries need
> > > to have the appropriate \alias entries, and all their arguments
> > > documented.
> > > The \usage entries must correspond to syntactically valid R code.
> > > See the chapter 'Writing R documentation files' in manual
> > 'Writing R
> > > Extensions'.
> > > Error in tools::checkDocStyle(package = "penalized") :
> > >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not
> > > contain Rd sources Execution halted The \usage entries for
> > S3 methods
> > > should use the \method markup and not their full name.
> > > See the chapter 'Writing R documentation files' in manual
> > 'Writing R
> > > Extensions'.
> > > * checking data for non-ASCII characters ... OK
> > > * creating penalized-Ex.R ... OK
> > > * checking examples ... OK
> > > * checking package vignettes in 'inst/doc' ... OK
> > > * creating penalized-manual.tex ... OK
> > > * checking penalized-manual.tex ... OK
> > >
> > >
> > >
> > >
> > >
> > > www.msbi.nl/goeman
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>


From murdoch at stats.uwo.ca  Sat Dec  1 21:56:25 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 01 Dec 2007 15:56:25 -0500
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <fisd7m$85f$1@ger.gmane.org>
References: <fis1g7$65a$1@ger.gmane.org>	<loom.20071201T171543-701@post.gmane.org>
	<fisd7m$85f$1@ger.gmane.org>
Message-ID: <4751CA79.6060507@stats.uwo.ca>

I've moved this response to R-devel, because my contribution is more 
along those lines.  Michael, if this doesn't interest you, please let us 
know.

On 01/12/2007 2:38 PM, Michael Hoffman wrote:
> Dieter Menne wrote:
>> Michael Hoffman <b3i4old02 <at> sneakemail.com> writes:
>>
>>> I would like to be able to do something like this:
>>>
>>>    <<echo=F,fig=T,width=mywidth>>=
>>>    ...
>>>    @
>>>
>>> with mywidth set in a previous code chunk. Is there a way to do this in 
>>> Sweave?
>>>
>> Not in the <<>>, but you could set a hook for fig:
>>
>>
>> >From Sweave docs:
>>
>> If option "SweaveHooks" is defined as list(fig = foo), and foo is a function,
>> then it would be executed before the code in each figure chunk. This is
>> especially useful to set defaults for the graphical parameters in a series of
>> figure chunks.
> 
> Thanks. I guess what I really want to do is switch between one of two 
> settings. Only one value can be in the defaults, and I would like some 
> way of setting the other value. This might not be easily possible, but I 
> thought I would ask.

My understanding is that Michael wants to have the Sweave options in a 
chunk depend on a calculation happening in the underlying R session. 
This is hard to do with hooks, because they are run after the options 
have already been processed.

(His example of changing the width actually does have an ugly solution. 
  In the hook, close the graphics device and reopen it with the options 
you really want.  To find some of the parameters (e.g. the filename), 
you'll need to use parent.frame() to look at the locals of the Rweave 
driver.  Yuck.)

It would be much nicer if a hook could be called after the options have 
been parsed, but before they have been processed, and the hook was 
allowed to modify the options.  For example, something like

options(SweaveHooks = list(
   massageOptions = function(options) {
     options$width = mywidth
     return(options)
   }
))

Comments?

Duncan Murdoch


From mxkuhn at gmail.com  Sun Dec  2 01:45:17 2007
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sat, 1 Dec 2007 19:45:17 -0500
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <4751CA79.6060507@stats.uwo.ca>
References: <fis1g7$65a$1@ger.gmane.org>
	<loom.20071201T171543-701@post.gmane.org> <fisd7m$85f$1@ger.gmane.org>
	<4751CA79.6060507@stats.uwo.ca>
Message-ID: <6731304c0712011645i1c6f2684l15579e3ede521b95@mail.gmail.com>

On Dec 1, 2007 3:56 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> My understanding is that Michael wants to have the Sweave options in a
> chunk depend on a calculation happening in the underlying R session.
> This is hard to do with hooks, because they are run after the options
> have already been processed.

This may not be of practical help, but odfWeave allows you to do this
(assuming that I understand the question).

One clean way to do this in Sweave would be to change how
the device is called. In odfWeave, if <<fig=TRUE>>=. a new device
is opened and the image specifications are retreived from
global variables. See odfWeave:::RweaveOdfRuncode,
setimageDefs and adjustImageSize in the odfWeave package.

I'd love to see this type of change in Sweave, but it would be a
big departure form the current code base.

-- 

Max


From b3i4old02 at sneakemail.com  Sun Dec  2 02:45:53 2007
From: b3i4old02 at sneakemail.com (Michael Hoffman)
Date: Sun, 02 Dec 2007 01:45:53 +0000
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <4751CA79.6060507@stats.uwo.ca>
References: <fis1g7$65a$1@ger.gmane.org>	<loom.20071201T171543-701@post.gmane.org>	<fisd7m$85f$1@ger.gmane.org>
	<4751CA79.6060507@stats.uwo.ca>
Message-ID: <fit2oq$ujf$1@ger.gmane.org>

Duncan Murdoch wrote:

> On 01/12/2007 2:38 PM, Michael Hoffman wrote:
>> Dieter Menne wrote:
>>> Michael Hoffman <b3i4old02 <at> sneakemail.com> writes:
>>>
>>>> I would like to be able to do something like this:
>>>>
>>>>    <<echo=F,fig=T,width=mywidth>>=
>>>>    ...
>>>>    @
>>>>
>>>> with mywidth set in a previous code chunk. Is there a way to do this in 
>>>> Sweave?
>>>>
>>> Not in the <<>>, but you could set a hook for fig:
>>>
>>>
>>> >From Sweave docs:
>>>
>>> If option "SweaveHooks" is defined as list(fig = foo), and foo is a function,
>>> then it would be executed before the code in each figure chunk. This is
>>> especially useful to set defaults for the graphical parameters in a series of
>>> figure chunks.
>> Thanks. I guess what I really want to do is switch between one of two 
>> settings. Only one value can be in the defaults, and I would like some 
>> way of setting the other value. This might not be easily possible, but I 
>> thought I would ask.
> 
> My understanding is that Michael wants to have the Sweave options in a 
> chunk depend on a calculation happening in the underlying R session. 

That would be really nice and allow some things I hadn't even imagined 
would be possible.

But really I just would like the ability to set a variable statically 
and reuse it. Using a macro system like m4 would work, although I 
dislike the idea of adding yet another macro system to my poor document.


From murdoch at stats.uwo.ca  Sun Dec  2 12:42:13 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 02 Dec 2007 06:42:13 -0500
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <fit2oq$ujf$1@ger.gmane.org>
References: <fis1g7$65a$1@ger.gmane.org>	<loom.20071201T171543-701@post.gmane.org>	<fisd7m$85f$1@ger.gmane.org>	<4751CA79.6060507@stats.uwo.ca>
	<fit2oq$ujf$1@ger.gmane.org>
Message-ID: <47529A15.3000100@stats.uwo.ca>

Michael Hoffman wrote:
> Duncan Murdoch wrote:
>
>   
>> On 01/12/2007 2:38 PM, Michael Hoffman wrote:
>>     
>>> Dieter Menne wrote:
>>>       
>>>> Michael Hoffman <b3i4old02 <at> sneakemail.com> writes:
>>>>
>>>>         
>>>>> I would like to be able to do something like this:
>>>>>
>>>>>    <<echo=F,fig=T,width=mywidth>>=
>>>>>    ...
>>>>>    @
>>>>>
>>>>> with mywidth set in a previous code chunk. Is there a way to do this in 
>>>>> Sweave?
>>>>>
>>>>>           
>>>> Not in the <<>>, but you could set a hook for fig:
>>>>
>>>>
>>>> >From Sweave docs:
>>>>
>>>> If option "SweaveHooks" is defined as list(fig = foo), and foo is a function,
>>>> then it would be executed before the code in each figure chunk. This is
>>>> especially useful to set defaults for the graphical parameters in a series of
>>>> figure chunks.
>>>>         
>>> Thanks. I guess what I really want to do is switch between one of two 
>>> settings. Only one value can be in the defaults, and I would like some 
>>> way of setting the other value. This might not be easily possible, but I 
>>> thought I would ask.
>>>       
>> My understanding is that Michael wants to have the Sweave options in a 
>> chunk depend on a calculation happening in the underlying R session. 
>>     
>
> That would be really nice and allow some things I hadn't even imagined 
> would be possible.
>
> But really I just would like the ability to set a variable statically 
> and reuse it. Using a macro system like m4 would work, although I 
> dislike the idea of adding yet another macro system to my poor document.
>   
I put together a clunky way to handle that for a presentation last week; 
it may be enough for you.

I leave the Sweave options at their defaults, but I have code chunks 
that affect the appearance, and I run those without echoing to switch 
between a couple of formats.  For example, I have some pages that 
display one figure, and others that display two.  I use these 
definitions at the beginning:

\SweaveOpts{height=5,width=10}
\setkeys{Gin}{width=\textwidth}

<<double, echo=FALSE, eval=FALSE>>=
options(SweaveHooks=list( fig=function() par(mfrow=c(1,2)) ))
@

<<single, echo=FALSE>>=
options(SweaveHooks=list( fig=function() par(mar=c(5,13,4,11)+0.1)) )
@

Then a plot would look something like this:

<<echo=FALSE>>=
<<double>>
set.seed(130)
@
<<fig=TRUE>>=
x <- rt(1000, 3)
qqnorm(x); qqplot(rnorm(1000), x)
@

The "single" versus "double" settings are persistent, and since most 
plots were single, I'd probably follow this with

<<echo=FALSE>>=
<<single>>
@

This sets up very large margins on single plots, so they are 
approximately centered within the fixed width display.

One other thing that would have helped with this approach would be a way 
to include another file:  then I wouldn't have to repeat those 
definitions in every Rnw of the project.

Duncan Murdoch


From huber at ebi.ac.uk  Sun Dec  2 18:38:06 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Sun, 02 Dec 2007 17:38:06 +0000
Subject: [Rd] sd(NA)
Message-ID: <4752ED7E.1010700@ebi.ac.uk>

Dear Prof. Ripley

I noted a change in the behaviour of "cov", which is very reasonable:

## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
 >  cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
Error in cov(as.numeric(NA), as.numeric(NA), use = "complete.obs") :
   no complete element pairs

whereas earlier behavior was, for example:
## R version 2.6.0 Patched (2007-10-23 r43258)
 > cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
[1] NA


I wanted to ask whether the effect this has on "sd" is desired:

## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
 > sd(NA, na.rm=TRUE)
Error in var(x, na.rm = na.rm) : no complete element pairs

## R version 2.6.0 Patched (2007-10-23 r43258)
 >  sd(NA, na.rm=TRUE)
[1] NA



Best wishes
   Wolfgang Huber

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


From ripley at stats.ox.ac.uk  Sun Dec  2 19:27:57 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Dec 2007 18:27:57 +0000 (GMT)
Subject: [Rd] sd(NA)
In-Reply-To: <4752ED7E.1010700@ebi.ac.uk>
References: <4752ED7E.1010700@ebi.ac.uk>
Message-ID: <Pine.LNX.4.64.0712021817560.22480@gannet.stats.ox.ac.uk>

On Sun, 2 Dec 2007, Wolfgang Huber wrote:

> Dear Prof. Ripley
>
> I noted a change in the behaviour of "cov", which is very reasonable:
>
> ## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
> >  cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
> Error in cov(as.numeric(NA), as.numeric(NA), use = "complete.obs") :
>   no complete element pairs
>
> whereas earlier behavior was, for example:
> ## R version 2.6.0 Patched (2007-10-23 r43258)
> > cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
> [1] NA
>
>
> I wanted to ask whether the effect this has on "sd" is desired:
>
> ## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
> > sd(NA, na.rm=TRUE)
> Error in var(x, na.rm = na.rm) : no complete element pairs
>
> ## R version 2.6.0 Patched (2007-10-23 r43258)
> >  sd(NA, na.rm=TRUE)
> [1] NA

That is a bug fix: see the NEWS entry.  The previous behaviour of

> sd(numeric(0))
Error in var(x, na.rm = na.rm) : 'x' is empty
> sd(NA_real_, na.rm=TRUE)
[1] NA

was not as documented:

      This function computes the standard deviation of the values in
      'x'. If 'na.rm' is 'TRUE' then missing values are removed before
      computation proceeds.

so somehow an empty vector had a sd() if computed one way, and not if 
computed another.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From b3i4old02 at sneakemail.com  Sun Dec  2 20:41:04 2007
From: b3i4old02 at sneakemail.com (Michael Hoffman)
Date: Sun, 02 Dec 2007 19:41:04 +0000
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <47529A15.3000100@stats.uwo.ca>
References: <fis1g7$65a$1@ger.gmane.org>	<loom.20071201T171543-701@post.gmane.org>	<fisd7m$85f$1@ger.gmane.org>	<4751CA79.6060507@stats.uwo.ca>	<fit2oq$ujf$1@ger.gmane.org>
	<47529A15.3000100@stats.uwo.ca>
Message-ID: <fiv1or$qfs$1@ger.gmane.org>

Duncan Murdoch wrote:

> I put together a clunky way to handle that for a presentation last week; 
> it may be enough for you.
> 
> I leave the Sweave options at their defaults, but I have code chunks 
> that affect the appearance, and I run those without echoing to switch 
> between a couple of formats.  For example, I have some pages that 
> display one figure, and others that display two.

That is a decent way of doing what I am suggesting. Probably too 
complicated to be worth it if I am just changing one variable.

> One other thing that would have helped with this approach would be a way 
> to include another file:  then I wouldn't have to repeat those 
> definitions in every Rnw of the project.

Yet another candidate for (yet another) pre-processing step. :)

Of course, you could load the complicated bits in another file with 
source(). You'd still have to redefine <<single>> and <<double>> 
everywhere, but at least you would be able to change the option settings 
easily. Like this:

<<echo=F>>
source("init.R")
@

<<single, echo=F, eval=F>>=
setup.single() # loaded from init.R
@


From J.J.Goeman at lumc.nl  Sat Dec  1 17:32:04 2007
From: J.J.Goeman at lumc.nl (J.J.Goeman at lumc.nl)
Date: Sat, 1 Dec 2007 17:32:04 +0100
Subject: [Rd] Puzzling message: "no man files in this package"
In-Reply-To: <Pine.GSO.4.56.0712011404170.28061@laurel.few.vu.nl>
References: <68735E80D5EB7C4F8477BF00C450D38E02F25507@mailc.lumcnet.prod.intern>
	<Pine.GSO.4.56.0712011404170.28061@laurel.few.vu.nl>
Message-ID: <68735E80D5EB7C4F8477BF00C450D38E02F25515@mailc.lumcnet.prod.intern>

 Dear Katherine,

To complicate things: whereas I was able to reproduce the problem many
times yesterday, also after restarting my computer several times and
with R 2.5.1, R 2.6.0 and R 2.6.1, the package builds and checks
_completely without errors or warnings_ and installs without the strange
message today. And I did not change _a single thing_ to the package in
between. It's a bit of a bewildering experience :-{ but at least it
solves my immediate problem :-).

I've uploaded the package to CRAN incoming (penalized_0.9-17.tar.gz),
should you still want to have a look.

My apologies for bothering you with a semi-reproducible (?!) problem.

Jelle
 

> -----Original Message-----
> From: Katharine Mullen [mailto:kate at few.vu.nl] 
> Sent: zaterdag 1 december 2007 14:11
> To: Goeman, J.J. (MSTAT)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Puzzling message: "no man files in this package"
> 
> Dear Jelle,
> 
> Could you put the package somewhere public?  This would make 
> it easier to diagnose the problem.
> 
> On Fri, 30 Nov 2007 J.J.Goeman at lumc.nl wrote:
> 
> >  Dear R developers,
> >
> > When building/checking my package (in R 2.6.1 under windows) I run 
> > into some messages that I do not completely understand and 
> that do not 
> > give me precise enough leads to pinpoint where the error in 
> my package 
> > is. I would be very grateful for any suggestions. Did anyone else 
> > encounter the same problem before?
> >
> > When building or installing the package, I get the message 
> (no error 
> > or warning, just a message) "no man files in this package", 
> instead of 
> > the usual "installing man source files". This puzzles me 
> greatly, as I 
> > have a "man" subdirectory with several .Rd files, all of 
> which seem to 
> > be properly handled later on in the install/build process, when the 
> > "Building/Updating help files" step seems to go fine for 
> all Rd files.
> > Both install and build run to conclusion without reporting formal 
> > errors or warnings.
> >
> > Next, Rcmd check gives me a lot of nice OK's (even: * checking Rd 
> > files ... OK), and then
> >
> > * checking Rd cross-references ... WARNING Error in Rd_db(package, 
> > lib.loc = lib.loc) :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd objects
> > Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db Execution halted
> >
> > Again puzzling! I get the impression that the error message is not 
> > meant for me (I'm not the one who is supposed to put Rd 
> objects into 
> > M:/R/packages/penalized.Rcheck/penalized, am I?), but that 
> the error 
> > somehow prevents me from seeing the real warning.
> >
> > The same warning with error is repeated several times at 
> "checking for 
> > code/documentation mismatches" and at "checking Rd \usage sections".
> >
> > It's obvious that there is something wrong in my .Rd files. But I 
> > can't find any mistakes by just looking through them, and the error 
> > messages don't mean much to me. Did I overlook something obvious?
> >
> > The complete install and build output is given below.
> >
> > Thanks in advance,
> >
> > Jelle
> >
> >
> >
> >
> > ************************
> > *** Rcmd install:
> > ************************
> >
> > installing R.css in M:/R/packages/penalized.Rcheck
> >
> >
> > ---------- Making package penalized ------------
> >   adding build stamp to DESCRIPTION
> >   installing NAMESPACE file and metadata
> >   installing R files
> >   installing inst files
> >   installing data files
> >   preparing package penalized for lazy loading Loading required 
> > package: survival Loading required package: splines Creating a new 
> > generic function for "coefficients" in "penalized"
> > Creating a new generic function for "residuals" in "penalized"
> > Creating a new generic function for "fitted.values" in "penalized"
> > Creating a new generic function for "weights" in "penalized"
> > Creating a new generic function for "plot" in "penalized"
> > Creating a new generic function for "as.matrix" in "penalized"
> > Creating a new generic function for "time" in "penalized"
> > Creating a new generic function for "as.list" in "penalized"
> >   no man files in this package
> >   installing indices
> >   not zipping data
> >   installing help
> >  >>> Building/Updating help pages for package 'penalized'
> >      Formats: text html latex example chm
> >   breslow                           text    html    latex
> >   contrasts                         text    html    latex   example
> >   cvl                               text    html    latex   example
> >   nki70                             text    html    latex
> >   penalized                         text    html    latex   example
> >   penfit                            text    html    latex
> >   plotpath                          text    html    latex   example
> >   adding MD5 sums
> >
> > * DONE (penalized)
> >
> >
> > ************************
> > *** Rcmd check:
> > ************************
> >
> > * using log directory 'M:/R/packages/penalized.Rcheck'
> > * using R version 2.6.1 (2007-11-26)
> > * checking for file 'penalized/DESCRIPTION' ... OK
> > * this is package 'penalized' version '0.9-17'
> > * checking package name space information ... OK
> > * checking package dependencies ... OK
> > * checking if this is a source package ... OK
> > * checking whether package 'penalized' can be installed ... OK
> > * checking package directory ... OK
> > * checking for portable file names ... OK
> > * checking DESCRIPTION meta-information ... OK
> > * checking top-level files ... OK
> > * checking index information ... OK
> > * checking package subdirectories ... OK
> > * checking R files for non-ASCII characters ... OK
> > * checking R files for syntax errors ... OK
> > * checking whether the package can be loaded ... OK
> > * checking whether the package can be loaded with stated 
> dependencies 
> > ... OK
> > * checking whether the name space can be loaded with stated 
> > dependencies ... OK
> > * checking for unstated dependencies in R code ... OK
> > * checking S3 generic/method consistency ... OK
> > * checking replacement functions ... OK
> > * checking foreign function calls ... OK
> > * checking R code for possible problems ... OK
> > * checking Rd files ... OK
> > * checking Rd cross-references ... WARNING Error in Rd_db(package, 
> > lib.loc = lib.loc) :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd objects
> > Calls: <Anonymous> -> .build_Rd_xref_db -> Rd_db Execution halted
> > * checking for missing documentation entries ... OK
> > * checking for code/documentation mismatches ... WARNING Error in 
> > tools::codoc(package = "penalized") :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd sources Execution halted Error in 
> tools::codocData(package 
> > = "penalized") :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd sources Execution halted Error in 
> > tools::codocClasses(package = "penalized") :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd sources Execution halted
> > * checking Rd \usage sections ... WARNING Error in 
> > tools::checkDocFiles(package = "penalized") :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd sources Execution halted Functions with \usage 
> entries need 
> > to have the appropriate \alias entries, and all their arguments 
> > documented.
> > The \usage entries must correspond to syntactically valid R code.
> > See the chapter 'Writing R documentation files' in manual 
> 'Writing R 
> > Extensions'.
> > Error in tools::checkDocStyle(package = "penalized") :
> >   directory 'M:/R/packages/penalized.Rcheck/penalized' does not 
> > contain Rd sources Execution halted The \usage entries for 
> S3 methods 
> > should use the \method markup and not their full name.
> > See the chapter 'Writing R documentation files' in manual 
> 'Writing R 
> > Extensions'.
> > * checking data for non-ASCII characters ... OK
> > * creating penalized-Ex.R ... OK
> > * checking examples ... OK
> > * checking package vignettes in 'inst/doc' ... OK
> > * creating penalized-manual.tex ... OK
> > * checking penalized-manual.tex ... OK
> >
> >
> >
> >
> >
> > www.msbi.nl/goeman
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 


From friedrich.leisch at stat.uni-muenchen.de  Mon Dec  3 10:18:56 2007
From: friedrich.leisch at stat.uni-muenchen.de (friedrich.leisch at stat.uni-muenchen.de)
Date: Mon, 3 Dec 2007 10:18:56 +0100
Subject: [Rd] [R] Sweave: Variables in code chunk headers
In-Reply-To: <fiv1or$qfs$1@ger.gmane.org>
References: <fis1g7$65a$1@ger.gmane.org>
	<loom.20071201T171543-701@post.gmane.org>
	<fisd7m$85f$1@ger.gmane.org> <4751CA79.6060507@stats.uwo.ca>
	<fit2oq$ujf$1@ger.gmane.org> <47529A15.3000100@stats.uwo.ca>
	<fiv1or$qfs$1@ger.gmane.org>
Message-ID: <18259.51712.43960.315718@lxh5.stat.uni-muenchen.de>

>>>>> On Sun, 02 Dec 2007 19:41:04 +0000,
>>>>> Michael Hoffman (MH) wrote:

  > Duncan Murdoch wrote:
  >> I put together a clunky way to handle that for a presentation last week; 
  >> it may be enough for you.
  >> 
  >> I leave the Sweave options at their defaults, but I have code chunks 
  >> that affect the appearance, and I run those without echoing to switch 
  >> between a couple of formats.  For example, I have some pages that 
  >> display one figure, and others that display two.

  > That is a decent way of doing what I am suggesting. Probably too 
  > complicated to be worth it if I am just changing one variable.

  >> One other thing that would have helped with this approach would be a way 
  >> to include another file:  then I wouldn't have to repeat those 
  >> definitions in every Rnw of the project.

  > Yet another candidate for (yet another) pre-processing step. :)

  > Of course, you could load the complicated bits in another file with 
  > source(). You'd still have to redefine <<single>> and <<double>> 
  > everywhere, but at least you would be able to change the option settings 
  > easily. Like this:

  > <<echo=F>>
  > source("init.R")
  > @

  > <<single, echo=F, eval=F>>=
  > setup.single() # loaded from init.R
  > @

Why do threads on Sweave always seem to happen when I am offline? ;-)

Sorry to join in late, but my excuse is rather good: A plane over
Siberia isn't exactly email-territory yet (at least in economy
class): I was in transit from Munich to Tokio for most of the last 20
hours.

I do have untested code which evaluates options rather than statically
processing them, but I don't want to commit that in my current state
of mind (and I know that it needs another round of testing). I'm also
not sure how good my internet connectivity will be for the rest of the
week -> next week at the latest. Perhaps I can also include Max'
suggestion of default settings via options() & styles a la odfWeave.

Best,
Fritz


From pburns at pburns.seanet.com  Mon Dec  3 11:40:20 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 03 Dec 2007 10:40:20 +0000
Subject: [Rd] sd(NA)
In-Reply-To: <Pine.LNX.4.64.0712021817560.22480@gannet.stats.ox.ac.uk>
References: <4752ED7E.1010700@ebi.ac.uk>
	<Pine.LNX.4.64.0712021817560.22480@gannet.stats.ox.ac.uk>
Message-ID: <4753DD14.4000903@pburns.seanet.com>

I like the 2.6.x behaviour better.  Consider:

x <- array(1:30), c(10,3))
x[,1] <- NA
x[-1,2] <- NA
x[1,3] <- NA

sd(x, na.rm=TRUE)

# 2.7.0
Error in var(x, na.rm = na.rm) : no complete element pairs

# 2.6.x
[1]       NA       NA 2.738613

The reason to put 'na.rm=TRUE' into the call is to avoid
getting an error due to missing values. (And, yes, in finance
it is entirely possible to have a matrix with all NAs in a
column.)

I think the way out is to allow there to be a conceptual
difference between computing a value with no data, and
computing a value on all NAs after removing NAs.  The
first is clearly impossible.  The second has some actual
value, but we don't have enough information to have an
estimate of the value.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Prof Brian Ripley wrote:

>On Sun, 2 Dec 2007, Wolfgang Huber wrote:
>
>  
>
>>Dear Prof. Ripley
>>
>>I noted a change in the behaviour of "cov", which is very reasonable:
>>
>>## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
>>    
>>
>>> cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
>>>      
>>>
>>Error in cov(as.numeric(NA), as.numeric(NA), use = "complete.obs") :
>>  no complete element pairs
>>
>>whereas earlier behavior was, for example:
>>## R version 2.6.0 Patched (2007-10-23 r43258)
>>    
>>
>>>cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
>>>      
>>>
>>[1] NA
>>
>>
>>I wanted to ask whether the effect this has on "sd" is desired:
>>
>>## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
>>    
>>
>>>sd(NA, na.rm=TRUE)
>>>      
>>>
>>Error in var(x, na.rm = na.rm) : no complete element pairs
>>
>>## R version 2.6.0 Patched (2007-10-23 r43258)
>>    
>>
>>> sd(NA, na.rm=TRUE)
>>>      
>>>
>>[1] NA
>>    
>>
>
>That is a bug fix: see the NEWS entry.  The previous behaviour of
>
>  
>
>>sd(numeric(0))
>>    
>>
>Error in var(x, na.rm = na.rm) : 'x' is empty
>  
>
>>sd(NA_real_, na.rm=TRUE)
>>    
>>
>[1] NA
>
>was not as documented:
>
>      This function computes the standard deviation of the values in
>      'x'. If 'na.rm' is 'TRUE' then missing values are removed before
>      computation proceeds.
>
>so somehow an empty vector had a sd() if computed one way, and not if 
>computed another.
>
>  
>


From I.J.Wilson at ncl.ac.uk  Mon Dec  3 15:45:21 2007
From: I.J.Wilson at ncl.ac.uk (I.J.Wilson at ncl.ac.uk)
Date: Mon,  3 Dec 2007 15:45:21 +0100 (CET)
Subject: [Rd] interaction with C++ code (PR#10487)
Message-ID: <20071203144521.35ADA2834158@mail.pubhealth.ku.dk>

Full_Name: Ian Wilson
Version: 2.6.1 
OS: linux 
Submission from: (NULL) (128.240.229.7)


The problem is new to R2.6.?.  The code works as expected in R-2.5.0.  I get the
problem with two different operating systems - an older redhat and new ubuntu
and with both g++4.1 and g++3.4.

I have a problem with character data that is passed back from C++ code.  A small
example is the following C++ code and R functions.

#include <sstream>
extern "C" {
  void extracttxt( char **txt, int *nchars) {
      std::ostringstream oss;      
      oss << "abcdefghij";
      const char *ltxt=oss.str().c_str();
      for (int j=0;j<*nchars;j++) *txt[j]=static_cast<char>(ltxt[j]);
    }
}

# begin R code
dyn.load("test.so")

"testtxt" <-  function() {
  nchars <- 80
  txt <- .C("extracttxt"
            ,character(nchars)
            ,as.integer(nchars))[[1]]

 txt
}
a=testtxt()
a[1:10]

# typically the results are something like
 [1] "a"                   "b\033\xba\bfaul\030" "cz#\b"              
 [4] "d"                   "e"                   "f"                  
 [7] "g"                   "h"                   "i"                  
[10] "j"  

or 
 [1] "az#\b"            "b"                "c"                "d"              

 [5] "e"                "f"                "g"                "h"              

 [9] "i"                "j1\xba\brese\030"


From simon.urbanek at r-project.org  Mon Dec  3 16:38:11 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Dec 2007 10:38:11 -0500
Subject: [Rd] interaction with C++ code (PR#10487)
In-Reply-To: <20071203144521.35ADA2834158@mail.pubhealth.ku.dk>
References: <20071203144521.35ADA2834158@mail.pubhealth.ku.dk>
Message-ID: <85C86045-D36E-4B23-828A-13889B270A59@r-project.org>

This is a bug, but not in R, it's in your program:

On Dec 3, 2007, at 9:45 AM, I.J.Wilson at ncl.ac.uk wrote:

> Full_Name: Ian Wilson
> Version: 2.6.1
> OS: linux
> Submission from: (NULL) (128.240.229.7)
>
>
> The problem is new to R2.6.?.  The code works as expected in R-2.5.0.

it still does in 2.6.x - but it depends on what you expect. You fail  
to terminate the strings, so you get trailing garbage - it just may  
have happened that by chance the trailing memory was zero in 2.5.


> I get the
> problem with two different operating systems - an older redhat and  
> new ubuntu
> and with both g++4.1 and g++3.4.
>
> I have a problem with character data that is passed back from C++  
> code.  A small
> example is the following C++ code and R functions.
>
> #include <sstream>
> extern "C" {
>  void extracttxt( char **txt, int *nchars) {
>      std::ostringstream oss;
>      oss << "abcdefghij";
>      const char *ltxt=oss.str().c_str();
>      for (int j=0;j<*nchars;j++) *txt[j]=static_cast<char>(ltxt[j]);

As said above, you fail to terminate the string, you want to add  
something like:
        txt[j][1]=0;
here.

Cheers,
Simon

>
>    }
> }
>
> # begin R code
> dyn.load("test.so")
>
> "testtxt" <-  function() {
>  nchars <- 80
>  txt <- .C("extracttxt"
>            ,character(nchars)
>            ,as.integer(nchars))[[1]]
>
> txt
> }
> a=testtxt()
> a[1:10]
>
> # typically the results are something like
> [1] "a"                   "b\033\xba\bfaul\030" "cz#\b"
> [4] "d"                   "e"                   "f"
> [7] "g"                   "h"                   "i"
> [10] "j"
>
> or
> [1] "az#\b"            "b"                "c"                "d"
>
> [5] "e"                "f"                "g"                "h"
>
> [9] "i"                "j1\xba\brese\030"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Mon Dec  3 16:42:24 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Dec 2007 10:42:24 -0500
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>
	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>
	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>
	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
Message-ID: <B6E7CF97-44C4-4220-9D3C-A581D46897AB@r-project.org>


On Nov 30, 2007, at 11:22 AM, Saleem Bhatti wrote:

> Simon;
>
> On 30 Nov 2007, at 15:38, Simon Urbanek wrote:
>
>> Window -> Installer Log
>> You can then use Save ... to save it in a file.
>
> OK - file is attached.
>

Thanks. Your system is broken - you have an infinite softlink loop in / 
usr/local or /usr/local/lib
Can you send me the output of
ls -ld /usr/local
ls -l /usr/local
ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/
ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/local

(in Terminal), please?

Cheers,
Simon


>> Well, yes, but you said "automated install" - so how were you  
>> running an "automated" install? For me automated install is run  
>> via /usr/sbin/installer utility and that doesn't have any UI, so I  
>> was wondering what are you using exactly?
>
> My apologies for the confusion.
>
> Cheers,
> --/Saleem
>
>
>
> <R-2.6.1-Installer_Log 30-Nov-2007.txt>
>
>


From ripley at stats.ox.ac.uk  Mon Dec  3 17:15:13 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon,  3 Dec 2007 17:15:13 +0100 (CET)
Subject: [Rd] interaction with C++ code (PR#10487)
Message-ID: <20071203161514.02AB32834158@mail.pubhealth.ku.dk>

On Mon, 3 Dec 2007, Simon Urbanek wrote:

> This is a bug, but not in R, it's in your program:
>
> On Dec 3, 2007, at 9:45 AM, I.J.Wilson at ncl.ac.uk wrote:
>
>> Full_Name: Ian Wilson
>> Version: 2.6.1
>> OS: linux
>> Submission from: (NULL) (128.240.229.7)
>>
>>
>> The problem is new to R2.6.?.  The code works as expected in R-2.5.0.
>
> it still does in 2.6.x - but it depends on what you expect. You fail
> to terminate the strings, so you get trailing garbage - it just may
> have happened that by chance the trailing memory was zero in 2.5.

And there is another bug.  What is passed in is 80 zero-length strings, so 
in principle you cannot extend those strings (as only one byte is 
allocated for each).  It happens that R_alloc currently allocates 8 bytes 
(because it rounds up to a multiple of 8) and so the example worked, but 
you cannot rely on such implementation details.

The only valid change to an element of a character vector via the .C 
interface is to replace it by a 'char *' of the same length or shorter.
.Call is needed for almost all real applications that alter character 
vectors.



>
>
>> I get the
>> problem with two different operating systems - an older redhat and
>> new ubuntu
>> and with both g++4.1 and g++3.4.
>>
>> I have a problem with character data that is passed back from C++
>> code.  A small
>> example is the following C++ code and R functions.
>>
>> #include <sstream>
>> extern "C" {
>>  void extracttxt( char **txt, int *nchars) {
>>      std::ostringstream oss;
>>      oss << "abcdefghij";
>>      const char *ltxt=oss.str().c_str();
>>      for (int j=0;j<*nchars;j++) *txt[j]=static_cast<char>(ltxt[j]);
>
> As said above, you fail to terminate the string, you want to add
> something like:
>        txt[j][1]=0;
> here.
>
> Cheers,
> Simon
>
>>
>>    }
>> }
>>
>> # begin R code
>> dyn.load("test.so")
>>
>> "testtxt" <-  function() {
>>  nchars <- 80
>>  txt <- .C("extracttxt"
>>            ,character(nchars)
>>            ,as.integer(nchars))[[1]]
>>
>> txt
>> }
>> a=testtxt()
>> a[1:10]
>>
>> # typically the results are something like
>> [1] "a"                   "b\033\xba\bfaul\030" "cz#\b"
>> [4] "d"                   "e"                   "f"
>> [7] "g"                   "h"                   "i"
>> [10] "j"
>>
>> or
>> [1] "az#\b"            "b"                "c"                "d"
>>
>> [5] "e"                "f"                "g"                "h"
>>
>> [9] "i"                "j1\xba\brese\030"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Mon Dec  3 22:45:55 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 03 Dec 2007 21:45:55 +0000
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
Message-ID: <47547913.8080602@cimr.cam.ac.uk>

Out of interest, why (the hell!) would the R installer trying to
temper with gcc's files? It looks like it is either trying to rename
or delete them.

R needs gfortran's runtime library, and tries to detect for its 
presence, that's fair enough... modifying, no. Is the failure
because the R installer try to put in some of gcc/xcode, which the
user already has, or something like that?

HTL

Saleem Bhatti wrote:
> Simon;
> 
> On 30 Nov 2007, at 15:38, Simon Urbanek wrote:
> 
>> Window -> Installer Log
>> You can then use Save ... to save it in a file.
> 
> OK - file is attached.
> 
>> Well, yes, but you said "automated install" - so how were you running 
>> an "automated" install? For me automated install is run via 
>> /usr/sbin/installer utility and that doesn't have any UI, so I was 
>> wondering what are you using exactly?
> 
> My apologies for the confusion.
> 
> Cheers,
> --/Saleem
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> 
> 
> 
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From khansen at stat.Berkeley.EDU  Mon Dec  3 23:32:53 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 3 Dec 2007 14:32:53 -0800
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <47547913.8080602@cimr.cam.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
Message-ID: <11D5B817-1554-42C5-BF37-C9419DD96EF9@stat.berkeley.edu>

gfortran is not part of Apple's Xcode which only contains GCC. The R- 
installer contains gfortran for use with the Apple supplied GCC.

Kasper

On Dec 3, 2007, at 1:45 PM, Hin-Tak Leung wrote:

> Out of interest, why (the hell!) would the R installer trying to
> temper with gcc's files? It looks like it is either trying to rename
> or delete them.
>
> R needs gfortran's runtime library, and tries to detect for its
> presence, that's fair enough... modifying, no. Is the failure
> because the R installer try to put in some of gcc/xcode, which the
> user already has, or something like that?
>
> HTL
>
> Saleem Bhatti wrote:
>> Simon;
>>
>> On 30 Nov 2007, at 15:38, Simon Urbanek wrote:
>>
>>> Window -> Installer Log
>>> You can then use Save ... to save it in a file.
>>
>> OK - file is attached.
>>
>>> Well, yes, but you said "automated install" - so how were you  
>>> running
>>> an "automated" install? For me automated install is run via
>>> /usr/sbin/installer utility and that doesn't have any UI, so I was
>>> wondering what are you using exactly?
>>
>> My apologies for the confusion.
>>
>> Cheers,
>> --/Saleem
>>
>>
>>
>>
>> --------------------------------------------------------------------- 
>> ---
>>
>>
>>
>>
>>
>>
>>
>>
>> --------------------------------------------------------------------- 
>> ---
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Mon Dec  3 23:43:46 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Dec 2007 17:43:46 -0500
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <47547913.8080602@cimr.cam.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
Message-ID: <073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>


On Dec 3, 2007, at 4:45 PM, Hin-Tak Leung wrote:

> Out of interest, why (the hell!) would the R installer trying to  
> temper with gcc's files? It looks like it is either trying to rename  
> or delete them.
>

Because it *is* the gcc files? (Note the "/local" in the paths.) Full  
R comes with GNU Fortran 4.2.1, because Apple doesn't offer any  
Fortran compiler and most other Fortran compiler binaries for Mac OS X  
out on the web are not really working well. It installs in /usr/local.


> R needs gfortran's runtime library, and tries to detect for its  
> presence, that's fair enough...

It doesn't need it, or rather, it ships its own copy inside the R  
framework. If you install just R, it won't touch anything outside the  
R.framework / R.app.


> modifying, no. Is the failure because the R installer try to put in  
> some of gcc/xcode, which the user already has, or something like that?
>

No. The failure is due to a strange symlink in /usr/local/lib that  
points to itself. I suspect that this has something to do with an  
upgrade from Tiger to Leopard or Xcode 3 installation and that Apple  
actually creates that infinite symlink. Given that there is "/usr/loca/ 
lib 1" lingering around, I'd bet that

sudo rm /usr/local/lib
sudo mv '/usr/local/lib 1' /usr/local/lib

will fix the problem.

I'm not quite sure what to do with this - I don't really want out  
installer to start attempting to fix broken OS X. If we start doing  
so, we may as well replace entire the X11 on Leopard ;).

Cheers,
Simon

>
> Saleem Bhatti wrote:
>> Simon;
>> On 30 Nov 2007, at 15:38, Simon Urbanek wrote:
>>> Window -> Installer Log
>>> You can then use Save ... to save it in a file.
>> OK - file is attached.
>>> Well, yes, but you said "automated install" - so how were you  
>>> running an "automated" install? For me automated install is run  
>>> via /usr/sbin/installer utility and that doesn't have any UI, so I  
>>> was wondering what are you using exactly?
>> My apologies for the confusion.
>> Cheers,
>> --/Saleem
>> ------------------------------------------------------------------------
>> ------------------------------------------------------------------------
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From saleem at cs.st-andrews.ac.uk  Mon Dec  3 21:52:03 2007
From: saleem at cs.st-andrews.ac.uk (Saleem Bhatti)
Date: Mon, 3 Dec 2007 20:52:03 +0000
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <B6E7CF97-44C4-4220-9D3C-A581D46897AB@r-project.org>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>
	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>
	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>
	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<B6E7CF97-44C4-4220-9D3C-A581D46897AB@r-project.org>
Message-ID: <2A433024-730A-47AA-993B-1FB23724022D@cs.st-andrews.ac.uk>

Simon;

See below.

Cheers,
--/Saleem

On 3 Dec 2007, at 15:42, Simon Urbanek wrote:

>
> On Nov 30, 2007, at 11:22 AM, Saleem Bhatti wrote:
>
>> Simon;
>>
>> On 30 Nov 2007, at 15:38, Simon Urbanek wrote:
>>
>>> Window -> Installer Log
>>> You can then use Save ... to save it in a file.
>>
>> OK - file is attached.
>>
>
> Thanks. Your system is broken - you have an infinite softlink loop  
> in /usr/local or /usr/local/lib
> Can you send me the output of
> ls -ld /usr/local

saleem at logie:~ 501$ ls -ld /usr/local
drwxr-xr-x  14 saleem  saleem  476 26 Oct 19:48 /usr/local
saleem at logie:~ 502$

>
> ls -l /usr/local

saleem at logie:~ 502$ ls -l /usr/local
total 8
drwxr-xr-x    3 root    wheel    102 17 Oct 19:05 OpenSourceLicenses
drwxr-xr-x    3 root    wheel    102 17 Oct 19:05 OpenSourceVersions
drwxr-xr-x  108 saleem  saleem  3672 30 Nov 16:19 bin
drwxr-xr-x   19 root    wheel    646  4 Nov 20:27 include
drwxr-xr-x    6 root    wheel    204 30 Nov 16:19 info
lrwxr-xr-x    1 root    saleem    14 26 Oct 19:48 lib -> /usr/local/lib
drwxr-xr-x   88 saleem  saleem  2992  4 Oct 10:40 lib 1
drwxr-xr-x    4 saleem  saleem   136  4 Oct 10:40 libexec
drwxr-xr-x    7 root    wheel    238 20 Oct 11:04 man
drwxr-xr-x    3 root    saleem   102  4 Jul 10:23 sbin
drwxr-xr-x   13 saleem  saleem   442 29 Jun 08:12 share
drwxr-xr-x    4 root    wheel    136 29 Jun 08:14 texlive
saleem at logie:~ 503$

>
> ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/

saleem at logie:~ 503$ ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/
total 8
drwxr-xr-x    4 root  wheel   136 17 Mar  2007 X11R6
drwxr-xr-x   10 root  wheel   340 17 Mar  2007 bin
drwxr-xr-x  234 root  wheel  7956 26 Oct 19:48 include
drwxr-xr-x  228 root  wheel  7752 26 Oct 19:48 lib
drwxr-xr-x    4 root  wheel   136 17 Mar  2007 libexec
lrwxr-xr-x    1 root  wheel    10  4 Oct 10:40 local -> /usr/local
saleem at logie:~ 504$


>
> ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/local

saleem at logie:~ 504$ ls -l /Developer/SDKs/MacOSX10.4u.sdk/usr/local
lrwxr-xr-x  1 root  wheel  10  4 Oct 10:40 /Developer/SDKs/ 
MacOSX10.4u.sdk/usr/local -> /usr/local
saleem at logie:~ 505$

>
>
> (in Terminal), please?
>
> Cheers,
> Simon
>
>
>>> Well, yes, but you said "automated install" - so how were you  
>>> running an "automated" install? For me automated install is run  
>>> via /usr/sbin/installer utility and that doesn't have any UI, so I  
>>> was wondering what are you using exactly?
>>
>> My apologies for the confusion.
>>
>> Cheers,
>> --/Saleem
>>
>>
>>
>> <R-2.6.1-Installer_Log 30-Nov-2007.txt>
>>
>>
>


From tplate at acm.org  Tue Dec  4 02:39:34 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 03 Dec 2007 18:39:34 -0700
Subject: [Rd] sd(NA)
In-Reply-To: <4753DD14.4000903@pburns.seanet.com>
References: <4752ED7E.1010700@ebi.ac.uk>	<Pine.LNX.4.64.0712021817560.22480@gannet.stats.ox.ac.uk>
	<4753DD14.4000903@pburns.seanet.com>
Message-ID: <4754AFD6.5000202@acm.org>

I also prefer the old behavior.  The old behavior of sd (return NA 
rather than stop with an error) is nicer when one is working with any 
kind of resampling technique.  If there are some NA's in the data, then 
one can happily "debug" with a small or medium number of samples, and 
only when running a full resample will one get a sample containing all 
NA's, which triggers the error and aborts the whole computation (and of 
course the times this caused the loss of several hours of computation by 
happening close to the end are most easily remembered.)

In R-devel (2.7.0), the following behavior occurs with various 
summary/statistics functions when given a vector of all NA (& na.rm=T):

sd, var: stop with error
mean, mad, median, IQR, quantile, fivenum: return NA
min, max, range: warn & return NA

Is the "stop with error" behavior really that useful with sd() & var() 
that these functions should differ in their behavior from mean(), mad(), 
etc?

Personally, I'd find it most convenient if all these functions just 
returned NA values (without warning) when unable to compute a value.

-- Tony Plate

[resent because http://www.orbitrbl.com/ is blocking emails from one of 
my ISPs]

Patrick Burns wrote:
> I like the 2.6.x behaviour better.  Consider:
>
> x <- array(1:30), c(10,3))
> x[,1] <- NA
> x[-1,2] <- NA
> x[1,3] <- NA
>
> sd(x, na.rm=TRUE)
>
> # 2.7.0
> Error in var(x, na.rm = na.rm) : no complete element pairs
>
> # 2.6.x
> [1]       NA       NA 2.738613
>
> The reason to put 'na.rm=TRUE' into the call is to avoid
> getting an error due to missing values. (And, yes, in finance
> it is entirely possible to have a matrix with all NAs in a
> column.)
>
> I think the way out is to allow there to be a conceptual
> difference between computing a value with no data, and
> computing a value on all NAs after removing NAs.  The
> first is clearly impossible.  The second has some actual
> value, but we don't have enough information to have an
> estimate of the value.
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Prof Brian Ripley wrote:
>
>   
>> On Sun, 2 Dec 2007, Wolfgang Huber wrote:
>>
>>  
>>
>>     
>>> Dear Prof. Ripley
>>>
>>> I noted a change in the behaviour of "cov", which is very reasonable:
>>>
>>> ## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
>>>    
>>>
>>>       
>>>> cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
>>>>      
>>>>
>>>>         
>>> Error in cov(as.numeric(NA), as.numeric(NA), use = "complete.obs") :
>>>  no complete element pairs
>>>
>>> whereas earlier behavior was, for example:
>>> ## R version 2.6.0 Patched (2007-10-23 r43258)
>>>    
>>>
>>>       
>>>> cov(as.numeric(NA), as.numeric(NA), use="complete.obs")
>>>>      
>>>>
>>>>         
>>> [1] NA
>>>
>>>
>>> I wanted to ask whether the effect this has on "sd" is desired:
>>>
>>> ## R version 2.7.0 Under development (unstable) (2007-11-30 r43565)
>>>    
>>>
>>>       
>>>> sd(NA, na.rm=TRUE)
>>>>      
>>>>
>>>>         
>>> Error in var(x, na.rm = na.rm) : no complete element pairs
>>>
>>> ## R version 2.6.0 Patched (2007-10-23 r43258)
>>>    
>>>
>>>       
>>>> sd(NA, na.rm=TRUE)
>>>>      
>>>>
>>>>         
>>> [1] NA
>>>    
>>>
>>>       
>> That is a bug fix: see the NEWS entry.  The previous behaviour of
>>
>>  
>>
>>     
>>> sd(numeric(0))
>>>    
>>>
>>>       
>> Error in var(x, na.rm = na.rm) : 'x' is empty
>>  
>>
>>     
>>> sd(NA_real_, na.rm=TRUE)
>>>    
>>>
>>>       
>> [1] NA
>>
>> was not as documented:
>>
>>      This function computes the standard deviation of the values in
>>      'x'. If 'na.rm' is 'TRUE' then missing values are removed before
>>      computation proceeds.
>>
>> so somehow an empty vector had a sd() if computed one way, and not if 
>> computed another.
>>
>>  
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From rihle at gwdg.de  Tue Dec  4 13:10:12 2007
From: rihle at gwdg.de (rihle at gwdg.de)
Date: Tue,  4 Dec 2007 13:10:12 +0100 (CET)
Subject: [Rd] seq() does not create proper numbers (PR#10489)
Message-ID: <20071204121012.9F5632834155@mail.pubhealth.ku.dk>

Full_Name: Rico Ihle
Version: 2.6.1
OS: Windows XP Professional Version 2002 Pentium(R) 4 CPU 3.2 GHz
Submission from: (NULL) (134.76.183.24)


# Bug in seq() function:
x <- seq(-2,2,by=0.01)
which(x==0.05)# How that??
# although:
x# 0.05 seems to be at position 206 of x!!:
x[206]
# Why is this not equal to 0.05?

# Reason:
x2 <- as.character(x);x2
x2[206]# Ooooh... It's really not equal to 0.05!! How that? (compare lines 5 and
6!)

# Remedy:
x3 <- round(as.numeric(x),2)
which(x3==0.05)

# The (necessary) rounding is apparently and unfortunately NOT included in the
seq() function!!!
# But it should be!!!
# Because if one doesn't know about the demonstrated "nice" feature of the seq()
function
# (and it is not visible in lines 5 or 6!!!)
# one gets mad that x[206] is not equal to 0.05 although x[206] is printed as
0.05!!!

# Similarly:
y <-  seq(-0.5,.5,by=0.01)
which(y == 0.05)# None? How that? Result should be 56!!
y[56]

# but:
y2 <-as.character(y)
y2[56]
which(y2 == 0.05)

# or rounding alternatively:
which(round(y,2) == 0.05)


From murdoch at stats.uwo.ca  Tue Dec  4 16:20:48 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 04 Dec 2007 10:20:48 -0500
Subject: [Rd] seq() does not create proper numbers (PR#10489)
In-Reply-To: <20071204121012.9F5632834155@mail.pubhealth.ku.dk>
References: <20071204121012.9F5632834155@mail.pubhealth.ku.dk>
Message-ID: <47557050.6000603@stats.uwo.ca>

On 12/4/2007 7:10 AM, rihle at gwdg.de wrote:
> Full_Name: Rico Ihle
> Version: 2.6.1
> OS: Windows XP Professional Version 2002 Pentium(R) 4 CPU 3.2 GHz
> Submission from: (NULL) (134.76.183.24)

This is not a bug.  See FAQ 7.31, "Why doesn't R think these numbers are 
equal?"

> 
> 
> # Bug in seq() function:
> x <- seq(-2,2,by=0.01)

You've specified that the step size should be some number that's close 
to 0.01, but not exactly 0.01, since R doesn't know how to represent that.

> which(x==0.05)# How that??
> # although:
> x# 0.05 seems to be at position 206 of x!!:
> x[206]
> # Why is this not equal to 0.05?
> 
> # Reason:
> x2 <- as.character(x);x2
> x2[206]# Ooooh... It's really not equal to 0.05!! How that? (compare lines 5 and
> 6!)
> 
> # Remedy:
> x3 <- round(as.numeric(x),2)
> which(x3==0.05)
> 
> # The (necessary) rounding is apparently and unfortunately NOT included in the
> seq() function!!!
> # But it should be!!!

Why should it?  You didn't specify a round number as the step size.

Duncan Murdoch

> # Because if one doesn't know about the demonstrated "nice" feature of the seq()
> function
> # (and it is not visible in lines 5 or 6!!!)
> # one gets mad that x[206] is not equal to 0.05 although x[206] is printed as
> 0.05!!!
> 
> # Similarly:
> y <-  seq(-0.5,.5,by=0.01)
> which(y == 0.05)# None? How that? Result should be 56!!
> y[56]
> 
> # but:
> y2 <-as.character(y)
> y2[56]
> which(y2 == 0.05)
> 
> # or rounding alternatively:
> which(round(y,2) == 0.05)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at stat.berkeley.edu  Tue Dec  4 19:47:16 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 4 Dec 2007 10:47:16 -0800
Subject: [Rd] seq() does not create proper numbers (PR#10489)
In-Reply-To: <47557050.6000603@stats.uwo.ca>
References: <20071204121012.9F5632834155@mail.pubhealth.ku.dk>
	<47557050.6000603@stats.uwo.ca>
Message-ID: <59d7961d0712041047s2dcc38ebu60c81e570005c02c@mail.gmail.com>

On 04/12/2007, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/4/2007 7:10 AM, rihle at gwdg.de wrote:
> > Full_Name: Rico Ihle
> > Version: 2.6.1
> > OS: Windows XP Professional Version 2002 Pentium(R) 4 CPU 3.2 GHz
> > Submission from: (NULL) (134.76.183.24)
>
> This is not a bug.  See FAQ 7.31, "Why doesn't R think these numbers are
> equal?"
>
> >
> >
> > # Bug in seq() function:
> > x <- seq(-2,2,by=0.01)
>
> You've specified that the step size should be some number that's close
> to 0.01, but not exactly 0.01, since R doesn't know how to represent that.

Here is another example adding to the clarification (confusion?):

n <- 1e30;
print(n*(1/n) < 1);
## [1] TRUE

And another one:

c <- 100;
from <- -2;
to <- 2;
x <- seq(from=from, to=to, by=1/c);
y <- seq(from=from*c, to=to*c, by=1)/c;
print(identical(x,y));
## [1] FALSE
print(all.equal(x,y));
## [1] TRUE

Yet another example of problems with representation of certain values:

by <- 1/c;
z <- seq(from=from/by, to=to/by, by=1)*by;
print(identical(x,z));
## [1] FALSE
print(identical(y,z));  # <<< NOTE
## [1] FALSE
print(all.equal(x,z));
## [1] TRUE
print(all.equal(y,z));
## [1] TRUE

I guess the question is whether you prefer the 'x' or the 'y'
sequence.  Actually, if the representation of 'by=1/c' is, say,
strictly smaller than 1/c, for some simple tests it looks like the
deviation of d[k]=y[k]-x[k] increases as k grows.  Here is a plot
illustrating this:

c <- 10;
to <- 1e6;
x <- seq(from=0, to=to, by=1/c);
y <- seq(from=0, to=to*c, by=1)/c;
d <- y-x;
n <- length(d);

# Plot (t,d), where t is uniform on the logaritmic scale,
# because otherwise there are too many data points.
t <- seq(from=0, to=log10(n), length.out=1e3);
t <- unique(as.integer(10^t));
plot(t, d[t]);

/Henrik

>
> > which(x==0.05)# How that??
> > # although:
> > x# 0.05 seems to be at position 206 of x!!:
> > x[206]
> > # Why is this not equal to 0.05?
> >
> > # Reason:
> > x2 <- as.character(x);x2
> > x2[206]# Ooooh... It's really not equal to 0.05!! How that? (compare lines 5 and
> > 6!)
> >
> > # Remedy:
> > x3 <- round(as.numeric(x),2)
> > which(x3==0.05)
> >
> > # The (necessary) rounding is apparently and unfortunately NOT included in the
> > seq() function!!!
> > # But it should be!!!
>
> Why should it?  You didn't specify a round number as the step size.
>
> Duncan Murdoch
>
> > # Because if one doesn't know about the demonstrated "nice" feature of the seq()
> > function
> > # (and it is not visible in lines 5 or 6!!!)
> > # one gets mad that x[206] is not equal to 0.05 although x[206] is printed as
> > 0.05!!!
> >
> > # Similarly:
> > y <-  seq(-0.5,.5,by=0.01)
> > which(y == 0.05)# None? How that? Result should be 56!!
> > y[56]
> >
> > # but:
> > y2 <-as.character(y)
> > y2[56]
> > which(y2 == 0.05)
> >
> > # or rounding alternatively:
> > which(round(y,2) == 0.05)
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From antonio.fabio at gmail.com  Tue Dec  4 20:10:31 2007
From: antonio.fabio at gmail.com (antonio.fabio at gmail.com)
Date: Tue,  4 Dec 2007 20:10:31 +0100 (CET)
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
Message-ID: <20071204191031.B38082834156@mail.pubhealth.ku.dk>

Full_Name: Antonio, Fabio Di Narzo
Version: 2.6.1
OS: linux
Submission from: (NULL) (213.140.16.187)


In 'outer' man page, there is no mention of the Vectorize function.
Moreover, I think it isn't underlined enough that the FUN argument to 'outer'
must be a vectorized function (doc speaks about a function which has to 'operate
elementwise').

A cross-reference from outer to Vectorize (which already has 'outer' usage
examples) would be great.

> R.version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status
major          2
minor          6.1
year           2007
month          11
day            26
svn rev        43537
language       R
version.string R version 2.6.1 (2007-11-26)


From antonio.fabio at gmail.com  Tue Dec  4 20:25:21 2007
From: antonio.fabio at gmail.com (antonio.fabio at gmail.com)
Date: Tue,  4 Dec 2007 20:25:21 +0100 (CET)
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
Message-ID: <20071204192521.9E3F22834156@mail.pubhealth.ku.dk>

------=_Part_13308_28087893.1196796187581
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Here a possible patch. What do you think about it?

2007/12/4, antonio.fabio at gmail.com <antonio.fabio at gmail.com>:
> Full_Name: Antonio, Fabio Di Narzo
> Version: 2.6.1
> OS: linux
> Submission from: (NULL) (213.140.16.187)
>
>
> In 'outer' man page, there is no mention of the Vectorize function.
> Moreover, I think it isn't underlined enough that the FUN argument to 'outer'
> must be a vectorized function (doc speaks about a function which has to 'operate
> elementwise').
>
> A cross-reference from outer to Vectorize (which already has 'outer' usage
> examples) would be great.
>
> > R.version
>                _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status
> major          2
> minor          6.1
> year           2007
> month          11
> day            26
> svn rev        43537
> language       R
> version.string R version 2.6.1 (2007-11-26)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy

------=_Part_13308_28087893.1196796187581
Content-Type: application/octet-stream; name=patch
Content-Transfer-Encoding: base64
X-Attachment-Id: f_f9stff63
Content-Disposition: attachment; filename=patch

ZGlmZiAtLWdpdCBhL3NyYy9saWJyYXJ5L2Jhc2UvbWFuL291dGVyLlJkIGIvc3JjL2xpYnJhcnkv
YmFzZS9tYW4vb3V0ZXIuUmQKaW5kZXggOWYzMmI3OC4uNzVlOGM4NyAxMDA2NDQKLS0tIGEvc3Jj
L2xpYnJhcnkvYmFzZS9tYW4vb3V0ZXIuUmQKKysrIGIvc3JjL2xpYnJhcnkvYmFzZS9tYW4vb3V0
ZXIuUmQKQEAgLTI2LDggKzI2LDggQEAgWCBcJW9cJSBZCiAgIFxpdGVte1xkb3RzfXtvcHRpb25h
bCBhcmd1bWVudHMgdG8gYmUgcGFzc2VkIHRvIFxjb2Rle0ZVTn0ufQogfQogXGRldGFpbHN7Ci0g
IFxjb2Rle0ZVTn0gbXVzdCBiZSBhIGZ1bmN0aW9uIChvciB0aGUgbmFtZSBvZiBpdCkgd2hpY2gg
ZXhwZWN0cyBhdAotICBsZWFzdCB0d28gYXJndW1lbnRzIGFuZCB3aGljaCBvcGVyYXRlcyBlbGVt
ZW50d2lzZS4KKyAgXGNvZGV7RlVOfSBtdXN0IGJlIGEgdmVjdG9yaXplZCBmdW5jdGlvbiAob3Ig
dGhlIG5hbWUgb2YgaXQpIHdoaWNoIGV4cGVjdHMgYXQKKyAgbGVhc3QgdHdvIGFyZ3VtZW50cy4K
IAogICBcY29kZXtYfSBhbmQgXGNvZGV7WX0gbXVzdCBiZSBzdWl0YWJsZSBhcmd1bWVudHMgZm9y
IFxjb2Rle0ZVTn0uICBFYWNoCiAgIHdpbGwgYmUgZXh0ZW5kZWQgYnkgXGNvZGV7XGxpbmt7cmVw
fX0gdG8gbGVuZ3RoIHRoZSBwcm9kdWN0cyBvZiB0aGUKQEAgLTU0LDcgKzU0LDggQEAgWCBcJW9c
JSBZCiBcc2VlYWxzb3sKICAgXGNvZGV7XGxpbmt7XCUqXCV9fSBmb3IgdXN1YWwgKFxlbXBoe2lu
bmVyfSkgbWF0cml4IHZlY3RvcgogICBtdWx0aXBsaWNhdGlvbjsKLSAgXGNvZGV7XGxpbmt7a3Jv
bmVja2VyfX0gd2hpY2ggaXMgYmFzZWQgb24gXGNvZGV7b3V0ZXJ9LgorICBcY29kZXtcbGlua3tr
cm9uZWNrZXJ9fSB3aGljaCBpcyBiYXNlZCBvbiBcY29kZXtvdXRlcn07CisgIFxjb2Rle1xsaW5r
e1ZlY3Rvcml6ZX19IGZvciB2ZWN0b3JpemluZyBhIG5vbi12ZWN0b3JpemVkIGZ1bmN0aW9uLgog
fQogXGV4YW1wbGVzewogeCA8LSAxOjk7IG5hbWVzKHgpIDwtIHgK
------=_Part_13308_28087893.1196796187581--


From p.murrell at auckland.ac.nz  Tue Dec  4 20:53:10 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 05 Dec 2007 08:53:10 +1300
Subject: [Rd] [R] color palette from red to blue passing white (shifted
 from R-help)
In-Reply-To: <18261.5726.555747.583528@stat.math.ethz.ch>
References: <644e1f320712031752k27ac3b14l9b5a4e6e075b799e@mail.gmail.com>	<Pine.LNX.4.44.0712040504230.6948-100000@disco.wu-wien.ac.at>
	<18261.5726.555747.583528@stat.math.ethz.ch>
Message-ID: <4755B026.6020406@stat.auckland.ac.nz>

Hi

Achim and I have been looking at tidying up the colorspace package (see
http://r-forge.r-project.org/projects/colorspace/) to fix a few
inaccuracies, PLUS the possibility of declaring R's internal color space
to be sRGB.

I have started an RFC on the r-developer site
(http://developer.r-project.org/sRGB-RFC.html) to discuss some possible
changes to the core engine and add-on packages.

One of the issues will be consolidating some of the double-ups (e.g.,
hcl() in base and the counterpart in package 'colorspace';  I did not
even know about convertColor()!).

Ideally, we would have only one copy of the conversions between the
various colorspaces (probably C code, then the various R-level front
ends can all just run off the same internal code).

A lot of these conversions exist now in 'colorspace', but as Thomas
pointed out, the S4-ness of 'colorspace' is a problem for making these
conversions part of base R.

Paul


Martin Maechler wrote:
>>>>>> "AZ" == Achim Zeileis <Achim.Zeileis at wu-wien.ac.at>
>>>>>>     on Tue, 4 Dec 2007 05:08:51 +0100 (CET) writes:
> 
>     AZ> On Mon, 3 Dec 2007, jim holtman wrote:
> 
>     >> see if this is what you need:
>     >> 
>     >> require(lattice) x <- matrix(1:100,10)
>     >> levelplot(x,col.regions=colorRampPalette(c('dark
>     >> red','white','dark blue')))
> 
>     AZ> Instead of colorRampPalette(), you could also use
>     AZ> diverge_hcl() in package "vcd" to get a
>     AZ> perceptually-based version, e.g.,
> 
>     AZ>   levelplot(x, col.regions = diverg_hcl(16))
> 
> Hmm,  I would have recommended
> 
>   colorRampPalette(c('dark red','white','dark blue'), 
>                    space = "Lab")
> 
> where the 'space = "Lab"' part also makes sure that a
> "perceptually-based" space rather than RGB is used.
> 
> I think the functions colorRamp() and (even more)
> colorRampPalette()  are very nice, part of "standard R" and 
> still not known and used enough.
> Note that they are based on 'convertColor()' and other color
> space functionality in R all of which deserve more usage 
> in my oppinion and also in my own code ! ;-) 
> 
> Package 'vcd' (and others) use package 'colorspace', 
> and I have wondered in the past if these color space computations
> should not be merged into to standard R (package 'grDevices').
> But that's really a topic for another thread, on R-devel, not R-help..
> 
> Martin Maechler, ETH Zurich
> 
> 
>     >> On Dec 3, 2007 5:41 PM, Linda Smith
>     >> <lsmithingm at gmail.com> wrote: > Hi All,
>     >> >
>     >> > I am looking for a color palette like this: >
>     >> http://www.ncl.ucar.edu/Applications/Images/h_long_5_lg.png
>     >> >
>     >> > I think I found out how some time ago (something like
>     >> Colors[1:n]), but when > I now wanna use it, I could not
>     >> remember how I did it.
>     >> >
>     >> > Does anyone know which package I could use?
>     >> >
>     >> > Many thanks!
>     >> >
>     >> > Linda
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hin-tak.leung at cimr.cam.ac.uk  Wed Dec  5 03:11:11 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 05 Dec 2007 02:11:11 +0000
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
Message-ID: <475608BF.3000607@cimr.cam.ac.uk>

Simon Urbanek wrote:
<snipped>
> Because it *is* the gcc files? (Note the "/local" in the paths.) Full R 
> comes with GNU Fortran 4.2.1, because Apple doesn't offer any Fortran 
> compiler and most other Fortran compiler binaries for Mac OS X out on 
> the web are not really working well. It installs in /usr/local.
<snipped>

This is what I don't understand or agree on. The R windows installer 
does *not* try to install any of mingw gcc or Rtools. Okay, you cannot 
install source packages on windows without mingw gcc or Rtools, but 
that's a caveate.

If I were an Apple user (which I am not), there is a chance that I might 
have my own gcc/gfortran in /usr/local and I surely do not want R to 
temper with them. If you need runtime libgfortran support, you should
just bundle gfortran.so and gcc.so if necesary (there are static
alternatives), and put those in R's area.

(recently, I took enough trouble of bootstrapping gfortran 4.2.x
for cross-compiling - see mingw-devel mailing list archive - because 
mingw don't distribute that as binary. I have win32 R under wine, but I 
really would *not* appreciate if win32 R tries to do anything 
substantially more than just put itself in a directory...).

<snipped>
> No. The failure is due to a strange symlink in /usr/local/lib that 
> points to itself. I suspect that this has something to do with an 
> upgrade from Tiger to Leopard or Xcode 3 installation and that Apple 
> actually creates that infinite symlink. Given that there is 
> "/usr/loca/lib 1" lingering around, I'd bet that
> 
> sudo rm /usr/local/lib
> sudo mv '/usr/local/lib 1' /usr/local/lib
> 
> will fix the problem.

<snipped>

Yeah, that apple box is *so* broken.:-).

HTL


From maechler at stat.math.ethz.ch  Wed Dec  5 09:02:37 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 Dec 2007 09:02:37 +0100
Subject: [Rd] [R] color palette from red to blue passing white (shifted
	from R-help)
In-Reply-To: <4755B026.6020406@stat.auckland.ac.nz>
References: <644e1f320712031752k27ac3b14l9b5a4e6e075b799e@mail.gmail.com>
	<Pine.LNX.4.44.0712040504230.6948-100000@disco.wu-wien.ac.at>
	<18261.5726.555747.583528@stat.math.ethz.ch>
	<4755B026.6020406@stat.auckland.ac.nz>
Message-ID: <18262.23325.226710.391865@stat.math.ethz.ch>

>>>>> "Paul" == Paul Murrell <p.murrell at auckland.ac.nz>
>>>>>     on Wed, 05 Dec 2007 08:53:10 +1300 writes:

    Paul> Hi
    Paul> Achim and I have been looking at tidying up the colorspace package (see
    Paul> http://r-forge.r-project.org/projects/colorspace/) to fix a few
    Paul> inaccuracies, PLUS the possibility of declaring R's internal color space
    Paul> to be sRGB.

    Paul> I have started an RFC on the r-developer site
    Paul> (http://developer.r-project.org/sRGB-RFC.html) to discuss some possible
    Paul> changes to the core engine and add-on packages.

    Paul> One of the issues will be consolidating some of the double-ups (e.g.,
    Paul> hcl() in base and the counterpart in package 'colorspace';  I did not
    Paul> even know about convertColor()!).

    Paul> Ideally, we would have only one copy of the conversions between the
    Paul> various colorspaces (probably C code, then the various R-level front
    Paul> ends can all just run off the same internal code).

    Paul> A lot of these conversions exist now in 'colorspace', but as Thomas
    Paul> pointed out, the S4-ness of 'colorspace' is a problem for making these
    Paul> conversions part of base R.

Hmm, I think we are currently only required to keep 'base' not
dependent on 'methods'.
Why should 'grDevices' or new "standard R" package not be
dependent on 'methods' ?
Many of us would like to see S4 been used much more widely.

Martin


From Achim.Zeileis at wu-wien.ac.at  Wed Dec  5 12:29:53 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 5 Dec 2007 12:29:53 +0100 (CET)
Subject: [Rd] [R] color palette from red to blue passing white (shifted
 from R-help)
In-Reply-To: <4755B026.6020406@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0712051216130.4278-100000@disco.wu-wien.ac.at>

Just a few small additions to what Paul already wrote:

> Achim and I have been looking at tidying up the colorspace package (see
> http://r-forge.r-project.org/projects/colorspace/) to fix a few
> inaccuracies, PLUS the possibility of declaring R's internal color space
> to be sRGB.

Also, we moved the color palettes out of "vcd" into "colorspace" so that
this is all in one place. That version is not on CRAN yet...but on
R-Forge.

> >     AZ>   levelplot(x, col.regions = diverg_hcl(16))
> >
> > Hmm,  I would have recommended
> >
> >   colorRampPalette(c('dark red','white','dark blue'),
> >                    space = "Lab")
> >
> > where the 'space = "Lab"' part also makes sure that a
> > "perceptually-based" space rather than RGB is used.

But that does not help you if your starting points are not balanced. "dark
red" and "dark blue" do not correspond to the same luminance coordinate
in HCL (or also LUV/LAB) space. As both use 139 in RGB, look at

  R> dark <- RGB(c(139/255, 0, 0), c(0, 139/255, 0), c(0, 0, 139/255))
  R> as(dark, "polarLUV")
              L         C         H
  [1,] 40.56124 136.40188  12.17395
  [2,] 68.73912 106.38239 127.72353
  [3,] 23.45176  94.89138 265.87278
       ^^^^^^^^

There are certainly diverging palettes in use with more serious problems,
but why not simply use the canned solution in "vcd" which avoids this
problem?

BTW: Some background information about the stuff we did for "vcd" is
available in
  http://epub.wu-wien.ac.at/dyn/openURL?id=oai:epub.wu-wien.ac.at:epub-wu-01_c87

And, Ken, apologies for using bad terminology again...:-)

grx,
Z


From maechler at stat.math.ethz.ch  Wed Dec  5 15:35:16 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed,  5 Dec 2007 15:35:16 +0100 (CET)
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
Message-ID: <20071205143516.C21592834612@mail.pubhealth.ku.dk>

>>>>> antonio fabio <antonio.fabio at gmail.com>
>>>>>     on Tue,  4 Dec 2007 20:25:21 +0100 (CET) writes:

    > ------=_Part_13308_28087893.1196796187581
    > Content-Type: text/plain; charset=ISO-8859-1
    > Content-Transfer-Encoding: 7bit
    > Content-Disposition: inline

    > Here a possible patch. What do you think about it?

attachments don't make it through R-bugs -> R-devel correctly.

Please use cut & paste instead.

Martin Maechler, ETH Zurich

    > 2007/12/4, antonio.fabio at gmail.com <antonio.fabio at gmail.com>:
    >> Full_Name: Antonio, Fabio Di Narzo
    >> Version: 2.6.1
    >> OS: linux
    >> Submission from: (NULL) (213.140.16.187)
    >> 
    >> 
    >> In 'outer' man page, there is no mention of the Vectorize function.
    >> Moreover, I think it isn't underlined enough that the FUN argument to 'outer'
    >> must be a vectorized function (doc speaks about a function which has to 'operate
    >> elementwise').
    >> 
    >> A cross-reference from outer to Vectorize (which already has 'outer' usage
    >> examples) would be great.
    >> 
    >> > R.version
    >> _
    >> platform       i686-pc-linux-gnu
    >> arch           i686
    >> os             linux-gnu
    >> system         i686, linux-gnu
    >> status
    >> major          2
    >> minor          6.1
    >> year           2007
    >> month          11
    >> day            26
    >> svn rev        43537
    >> language       R
    >> version.string R version 2.6.1 (2007-11-26)
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 


    > -- 
    > Antonio, Fabio Di Narzo
    > Ph.D. student at
    > Department of Statistical Sciences
    > University of Bologna, Italy

    > ------=_Part_13308_28087893.1196796187581
    > Content-Type: application/octet-stream; name=patch
    > Content-Transfer-Encoding: base64
    > X-Attachment-Id: f_f9stff63
    > Content-Disposition: attachment; filename=patch

    > ZGlmZiAtLWdpdCBhL3NyYy9saWJyYXJ5L2Jhc2UvbWFuL291dGVyLlJkIGIvc3JjL2xpYnJhcnkv
    > YmFzZS9tYW4vb3V0ZXIuUmQKaW5kZXggOWYzMmI3OC4uNzVlOGM4NyAxMDA2NDQKLS0tIGEvc3Jj
    > L2xpYnJhcnkvYmFzZS9tYW4vb3V0ZXIuUmQKKysrIGIvc3JjL2xpYnJhcnkvYmFzZS9tYW4vb3V0
    > ZXIuUmQKQEAgLTI2LDggKzI2LDggQEAgWCBcJW9cJSBZCiAgIFxpdGVte1xkb3RzfXtvcHRpb25h
    > bCBhcmd1bWVudHMgdG8gYmUgcGFzc2VkIHRvIFxjb2Rle0ZVTn0ufQogfQogXGRldGFpbHN7Ci0g
    > IFxjb2Rle0ZVTn0gbXVzdCBiZSBhIGZ1bmN0aW9uIChvciB0aGUgbmFtZSBvZiBpdCkgd2hpY2gg
    > ZXhwZWN0cyBhdAotICBsZWFzdCB0d28gYXJndW1lbnRzIGFuZCB3aGljaCBvcGVyYXRlcyBlbGVt
    > ZW50d2lzZS4KKyAgXGNvZGV7RlVOfSBtdXN0IGJlIGEgdmVjdG9yaXplZCBmdW5jdGlvbiAob3Ig
    > dGhlIG5hbWUgb2YgaXQpIHdoaWNoIGV4cGVjdHMgYXQKKyAgbGVhc3QgdHdvIGFyZ3VtZW50cy4K
    > IAogICBcY29kZXtYfSBhbmQgXGNvZGV7WX0gbXVzdCBiZSBzdWl0YWJsZSBhcmd1bWVudHMgZm9y
    > IFxjb2Rle0ZVTn0uICBFYWNoCiAgIHdpbGwgYmUgZXh0ZW5kZWQgYnkgXGNvZGV7XGxpbmt7cmVw
    > fX0gdG8gbGVuZ3RoIHRoZSBwcm9kdWN0cyBvZiB0aGUKQEAgLTU0LDcgKzU0LDggQEAgWCBcJW9c
    > JSBZCiBcc2VlYWxzb3sKICAgXGNvZGV7XGxpbmt7XCUqXCV9fSBmb3IgdXN1YWwgKFxlbXBoe2lu
    > bmVyfSkgbWF0cml4IHZlY3RvcgogICBtdWx0aXBsaWNhdGlvbjsKLSAgXGNvZGV7XGxpbmt7a3Jv
    > bmVja2VyfX0gd2hpY2ggaXMgYmFzZWQgb24gXGNvZGV7b3V0ZXJ9LgorICBcY29kZXtcbGlua3tr
    > cm9uZWNrZXJ9fSB3aGljaCBpcyBiYXNlZCBvbiBcY29kZXtvdXRlcn07CisgIFxjb2Rle1xsaW5r
    > e1ZlY3Rvcml6ZX19IGZvciB2ZWN0b3JpemluZyBhIG5vbi12ZWN0b3JpemVkIGZ1bmN0aW9uLgog
    > fQogXGV4YW1wbGVzewogeCA8LSAxOjk7IG5hbWVzKHgpIDwtIHgK
    > ------=_Part_13308_28087893.1196796187581--

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From Dan.Kelley at dal.ca  Wed Dec  5 13:18:11 2007
From: Dan.Kelley at dal.ca (dankelley)
Date: Wed, 5 Dec 2007 04:18:11 -0800 (PST)
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>
	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>
	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>
	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
Message-ID: <14170397.post@talk.nabble.com>


Simon, quoted below, is correct about the /usr/local/lib infinite-reference
being a problem.  In case it's of any use to other OSX users, my guess is
that macPorts caused that error.  I infer that based on the time at which
the symlink was created, which was at the time when I was trying to install
MacPorts.  (That install failed.  I cannot pin down the time too well
because it took several hours of compilation to fail.)

I am putting a link to a posting I made on this issue below, in case its
thread expands to provide good hints for other R/Leopard users.  (Simon's
suggestion about moving "lib 1" to "lib" worked for me.)

http://www.nabble.com/problem-installing-2.6.1-on-OSX-Leopard-%28after-failed-MacPorts-install%29-tf4933141.html#a14119813



Simon Urbanek wrote:
> 
> 
> 
> No. The failure is due to a strange symlink in /usr/local/lib that  
> points to itself. I suspect that this has something to do with an  
> upgrade from Tiger to Leopard or Xcode 3 installation and that Apple  
> actually creates that infinite symlink. Given that there is "/usr/loca/ 
> lib 1" lingering around, I'd bet that
> 
> sudo rm /usr/local/lib
> sudo mv '/usr/local/lib 1' /usr/local/lib
> 
> will fix the problem.
> 
> 

-- 
View this message in context: http://www.nabble.com/R-install-problem-on-MacOS-10.5.1-%28PR-10476%29-tf4897418.html#a14170397
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Dec  5 15:56:45 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 5 Dec 2007 09:56:45 -0500
Subject: [Rd] R install problem on MacOS 10.5.1 (PR#10476)
In-Reply-To: <14170397.post@talk.nabble.com>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>
	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>
	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>
	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
	<14170397.post@talk.nabble.com>
Message-ID: <834416F1-40CB-4088-BF9B-239C1DAA1597@r-project.org>

Dan,

I have just encountered this issue on my iMac at home yesterday which  
I have upgraded from Tiger to Leopard, so I'm pretty sure that this is  
caused either by the upgrade or by Xcode 3 installation (I did both at  
once, so I didn't check the status immediately after upgrade). I  
didn't install MacPorts, so I'm pretty sure that Apple it creating  
this mess. And yes, moving "lib 1" to lib fixes it.

Cheers,
Simon


On Dec 5, 2007, at 7:18 AM, dankelley wrote:

>
> Simon, quoted below, is correct about the /usr/local/lib infinite- 
> reference being a problem.  In case it's of any use to other OSX  
> users, my guess is that macPorts caused that error.  I infer that  
> based on the time at which the symlink was created, which was at the  
> time when I was trying to install MacPorts.  (That install failed.   
> I cannot pin down the time too well because it took several hours of  
> compilation to fail.)
>
> I am putting a link to a posting I made on this issue below, in case  
> its thread expands to provide good hints for other R/Leopard users.   
> (Simon's suggestion about moving "lib 1" to "lib" worked for me.)
>
> http://www.nabble.com/problem-installing-2.6.1-on-OSX-Leopard-%28after-failed-MacPorts-install%29-tf4933141.html#a14119813
>
>
>
> Simon Urbanek wrote:
>>
>>
>>
>> No. The failure is due to a strange symlink in /usr/local/lib that
>> points to itself. I suspect that this has something to do with an
>> upgrade from Tiger to Leopard or Xcode 3 installation and that Apple
>> actually creates that infinite symlink. Given that there is "/usr/ 
>> loca/
>> lib 1" lingering around, I'd bet that
>>
>> sudo rm /usr/local/lib
>> sudo mv '/usr/local/lib 1' /usr/local/lib
>>
>> will fix the problem.
>>
>>
>
> -- 
> View this message in context: http://www.nabble.com/R-install-problem-on-MacOS-10.5.1-%28PR-10476%29-tf4897418.html#a14170397
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From P.Dalgaard at biostat.ku.dk  Wed Dec  5 16:24:42 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Dec 2007 16:24:42 +0100
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
In-Reply-To: <20071205143516.C21592834612@mail.pubhealth.ku.dk>
References: <20071205143516.C21592834612@mail.pubhealth.ku.dk>
Message-ID: <4756C2BA.9090404@biostat.ku.dk>

maechler at stat.math.ethz.ch wrote:
>>>>>> antonio fabio <antonio.fabio at gmail.com>
>>>>>>     on Tue,  4 Dec 2007 20:25:21 +0100 (CET) writes:
>>>>>>             
>
>     > ------=_Part_13308_28087893.1196796187581
>     > Content-Type: text/plain; charset=ISO-8859-1
>     > Content-Transfer-Encoding: 7bit
>     > Content-Disposition: inline
>
>     > Here a possible patch. What do you think about it?
>
> attachments don't make it through R-bugs -> R-devel correctly.
>
> Please use cut & paste instead.
>   
base64 -di is not THAT hard. I'll apply it to R-devel

diff --git a/src/library/base/man/outer.Rd b/src/library/base/man/outer.Rd
index 9f32b78..75e8c87 100644
--- a/src/library/base/man/outer.Rd
+++ b/src/library/base/man/outer.Rd
@@ -26,8 +26,8 @@ X \%o\% Y
   \item{\dots}{optional arguments to be passed to \code{FUN}.}
 }
 \details{
-  \code{FUN} must be a function (or the name of it) which expects at
-  least two arguments and which operates elementwise.
+  \code{FUN} must be a vectorized function (or the name of it) which
expects at
+  least two arguments.

   \code{X} and \code{Y} must be suitable arguments for \code{FUN}.  Each
   will be extended by \code{\link{rep}} to length the products of the
@@ -54,7 +54,8 @@ X \%o\% Y
 \seealso{
   \code{\link{\%*\%}} for usual (\emph{inner}) matrix vector
   multiplication;
-  \code{\link{kronecker}} which is based on \code{outer}.
+  \code{\link{kronecker}} which is based on \code{outer};
+  \code{\link{Vectorize}} for vectorizing a non-vectorized function.
 }
 \examples{
 x <- 1:9; names(x) <- x


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Wed Dec  5 16:41:10 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Dec 2007 16:41:10 +0100
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
In-Reply-To: <4756C2BA.9090404@biostat.ku.dk>
References: <20071205143516.C21592834612@mail.pubhealth.ku.dk>
	<4756C2BA.9090404@biostat.ku.dk>
Message-ID: <4756C696.6060603@biostat.ku.dk>

Peter Dalgaard wrote:
> maechler at stat.math.ethz.ch wrote:
>   
>>>>>>> antonio fabio <antonio.fabio at gmail.com>
>>>>>>>     on Tue,  4 Dec 2007 20:25:21 +0100 (CET) writes:
>>>>>>>             
>>>>>>>               
>>     > ------=_Part_13308_28087893.1196796187581
>>     > Content-Type: text/plain; charset=ISO-8859-1
>>     > Content-Transfer-Encoding: 7bit
>>     > Content-Disposition: inline
>>
>>     > Here a possible patch. What do you think about it?
>>
>> attachments don't make it through R-bugs -> R-devel correctly.
>>
>> Please use cut & paste instead.
>>   
>>     
> base64 -di is not THAT hard. I'll apply it to R-devel
>   
(The patch, not base64, or course...).

Done. Actually, I ended up polishing a bit more:

--- src/library/base/man/outer.Rd       (revision 43598)
+++ src/library/base/man/outer.Rd       (working copy)
@@ -26,13 +26,15 @@
   \item{\dots}{optional arguments to be passed to \code{FUN}.}
 }
 \details{
-  \code{FUN} must be a function (or the name of it) which expects at
-  least two arguments and which operates elementwise.
-
   \code{X} and \code{Y} must be suitable arguments for \code{FUN}.  Each
   will be extended by \code{\link{rep}} to length the products of the
   lengths of \code{X} and \code{Y} before \code{FUN} is called.

+  \code{FUN} is called with these two extended vectors as
+  arguments. Therefore, it must be a vectorized function (or the
+  name of one), expecting at
+  least two arguments.
+
   Where they exist, the [dim]names of \code{X} and \code{Y} will be
   copied to the answer, and a dimension assigned which is the
   concatenation of the dimensions of \code{X} and \code{Y} (or lengths
@@ -54,7 +56,8 @@
 \seealso{
   \code{\link{\%*\%}} for usual (\emph{inner}) matrix vector
   multiplication;
-  \code{\link{kronecker}} which is based on \code{outer}.
+  \code{\link{kronecker}} which is based on \code{outer};
+  \code{\link{Vectorize}} for vectorizing a non-vectorized function.
 }
 \examples{
 x <- 1:9; names(x) <- x

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From antonio.fabio at gmail.com  Wed Dec  5 18:45:28 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Wed, 5 Dec 2007 18:45:28 +0100
Subject: [Rd] Wishlist: mention Vectorize in 'outer' man page (PR#10490)
In-Reply-To: <4756C696.6060603@biostat.ku.dk>
References: <20071205143516.C21592834612@mail.pubhealth.ku.dk>
	<4756C2BA.9090404@biostat.ku.dk> <4756C696.6060603@biostat.ku.dk>
Message-ID: <b0808fdc0712050945t65d56bceuced856ad22845e93@mail.gmail.com>

Wow.
Now it seems much more explicit and clear than before. Thanks!

2007/12/5, Peter Dalgaard <P.Dalgaard at biostat.ku.dk>:
> Peter Dalgaard wrote:
> > maechler at stat.math.ethz.ch wrote:
> >
> >>>>>>> antonio fabio <antonio.fabio at gmail.com>
> >>>>>>>     on Tue,  4 Dec 2007 20:25:21 +0100 (CET) writes:
> >>>>>>>
> >>>>>>>
> >>     > ------=_Part_13308_28087893.1196796187581
> >>     > Content-Type: text/plain; charset=ISO-8859-1
> >>     > Content-Transfer-Encoding: 7bit
> >>     > Content-Disposition: inline
> >>
> >>     > Here a possible patch. What do you think about it?
> >>
> >> attachments don't make it through R-bugs -> R-devel correctly.
> >>
> >> Please use cut & paste instead.
> >>
> >>
> > base64 -di is not THAT hard. I'll apply it to R-devel
> >
> (The patch, not base64, or course...).
>
> Done. Actually, I ended up polishing a bit more:
>
> --- src/library/base/man/outer.Rd       (revision 43598)
> +++ src/library/base/man/outer.Rd       (working copy)
> @@ -26,13 +26,15 @@
>    \item{\dots}{optional arguments to be passed to \code{FUN}.}
>  }
>  \details{
> -  \code{FUN} must be a function (or the name of it) which expects at
> -  least two arguments and which operates elementwise.
> -
>    \code{X} and \code{Y} must be suitable arguments for \code{FUN}.  Each
>    will be extended by \code{\link{rep}} to length the products of the
>    lengths of \code{X} and \code{Y} before \code{FUN} is called.
>
> +  \code{FUN} is called with these two extended vectors as
> +  arguments. Therefore, it must be a vectorized function (or the
> +  name of one), expecting at
> +  least two arguments.
> +
>    Where they exist, the [dim]names of \code{X} and \code{Y} will be
>    copied to the answer, and a dimension assigned which is the
>    concatenation of the dimensions of \code{X} and \code{Y} (or lengths
> @@ -54,7 +56,8 @@
>  \seealso{
>    \code{\link{\%*\%}} for usual (\emph{inner}) matrix vector
>    multiplication;
> -  \code{\link{kronecker}} which is based on \code{outer}.
> +  \code{\link{kronecker}} which is based on \code{outer};
> +  \code{\link{Vectorize}} for vectorizing a non-vectorized function.
>  }
>  \examples{
>  x <- 1:9; names(x) <- x
>
> --
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From maechler at stat.math.ethz.ch  Wed Dec  5 18:55:15 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed,  5 Dec 2007 18:55:15 +0100 (CET)
Subject: [Rd] Trivial formatting typo in summary(lm()) (PR#10480)
Message-ID: <20071205175515.4390D2834619@mail.pubhealth.ku.dk>

I'm about to commit a fix to this  "age old" typo,
using "R-squared" in both cases as Jeff suggests,
unless some R-corer tells me I should not.

Yes, indeed, two *.Rout.save files need to be replaced too,
but I don't think that this --- and the fact that the output in many
books will eventually be "wrong" by a difference of 
      ' "r" - "R" '
would be good enough reason to keep this inconsistency.

Ok?
Martin


>>>>> "JR" == Jeffrey Racine <racinej at mcmaster.ca>
>>>>>     on Fri, 30 Nov 2007 19:40:12 +0100 (CET) writes:

    JR> Full_Name: Jeffrey Racine
    JR> Version: 2.6.1 and previous...
    JR> OS: FreeBSD
    JR> Submission from: (NULL) (130.113.139.86)


    JR> Hi.

    JR> I almost feel bad reporting this, but here goes.

    JR> The summary() for lm() (and possibly others?) uses a capitalized `S' in Multiple
    JR> R-Squared but a lowercase `s' in Adjusted R-squared. For instance,

    JR> Residual standard error: 0.5608 on 202 degrees of freedom
    JR> Multiple R-Squared: 0.2308,     Adjusted R-squared: 0.2232 
    JR> F-statistic:  30.3 on 2 and 202 DF,  p-value: 3.103e-12 

    JR> Perhaps they both ought to be lowercase? Again, truly trivial but perhaps it
    JR> adds to the overall polish...

    JR> -- Jeff


From P.Dalgaard at biostat.ku.dk  Wed Dec  5 19:08:51 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Dec 2007 19:08:51 +0100
Subject: [Rd] Trivial formatting typo in summary(lm()) (PR#10480)
In-Reply-To: <20071205175515.4390D2834619@mail.pubhealth.ku.dk>
References: <20071205175515.4390D2834619@mail.pubhealth.ku.dk>
Message-ID: <4756E933.4060306@biostat.ku.dk>

maechler at stat.math.ethz.ch wrote:
> I'm about to commit a fix to this  "age old" typo,
> using "R-squared" in both cases as Jeff suggests,
> unless some R-corer tells me I should not.
>
> Yes, indeed, two *.Rout.save files need to be replaced too,
> but I don't think that this --- and the fact that the output in many
> books will eventually be "wrong" by a difference of 
>       ' "r" - "R" '
> would be good enough reason to keep this inconsistency.
>
> Ok?
>   
I think so. (At least one of the books is in the process of being
updated anyway...)

The thing NOT to do (or at least be very careful with) is to mess with
things that are actually NAMES of something (like the "Sum of Sq" in
some anova() output), because someone might be using them for indexing.

> Martin
>
>
>   
>>>>>> "JR" == Jeffrey Racine <racinej at mcmaster.ca>
>>>>>>     on Fri, 30 Nov 2007 19:40:12 +0100 (CET) writes:
>>>>>>             
>
>     JR> Full_Name: Jeffrey Racine
>     JR> Version: 2.6.1 and previous...
>     JR> OS: FreeBSD
>     JR> Submission from: (NULL) (130.113.139.86)
>
>
>     JR> Hi.
>
>     JR> I almost feel bad reporting this, but here goes.
>
>     JR> The summary() for lm() (and possibly others?) uses a capitalized `S' in Multiple
>     JR> R-Squared but a lowercase `s' in Adjusted R-squared. For instance,
>
>     JR> Residual standard error: 0.5608 on 202 degrees of freedom
>     JR> Multiple R-Squared: 0.2308,     Adjusted R-squared: 0.2232 
>     JR> F-statistic:  30.3 on 2 and 202 DF,  p-value: 3.103e-12 
>
>     JR> Perhaps they both ought to be lowercase? Again, truly trivial but perhaps it
>     JR> adds to the overall polish...
>
>     JR> -- Jeff
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.murrell at auckland.ac.nz  Wed Dec  5 20:23:05 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 06 Dec 2007 08:23:05 +1300
Subject: [Rd] [R] color palette from red to blue passing white (shifted
 from R-help)
In-Reply-To: <18262.23325.226710.391865@stat.math.ethz.ch>
References: <644e1f320712031752k27ac3b14l9b5a4e6e075b799e@mail.gmail.com>	<Pine.LNX.4.44.0712040504230.6948-100000@disco.wu-wien.ac.at>	<18261.5726.555747.583528@stat.math.ethz.ch>	<4755B026.6020406@stat.auckland.ac.nz>
	<18262.23325.226710.391865@stat.math.ethz.ch>
Message-ID: <4756FA99.8010505@stat.auckland.ac.nz>

Hi


Martin Maechler wrote:
>>>>>> "Paul" == Paul Murrell <p.murrell at auckland.ac.nz>
>>>>>>     on Wed, 05 Dec 2007 08:53:10 +1300 writes:
> 
>     Paul> Hi
>     Paul> Achim and I have been looking at tidying up the colorspace package (see
>     Paul> http://r-forge.r-project.org/projects/colorspace/) to fix a few
>     Paul> inaccuracies, PLUS the possibility of declaring R's internal color space
>     Paul> to be sRGB.
> 
>     Paul> I have started an RFC on the r-developer site
>     Paul> (http://developer.r-project.org/sRGB-RFC.html) to discuss some possible
>     Paul> changes to the core engine and add-on packages.
> 
>     Paul> One of the issues will be consolidating some of the double-ups (e.g.,
>     Paul> hcl() in base and the counterpart in package 'colorspace';  I did not
>     Paul> even know about convertColor()!).
> 
>     Paul> Ideally, we would have only one copy of the conversions between the
>     Paul> various colorspaces (probably C code, then the various R-level front
>     Paul> ends can all just run off the same internal code).
> 
>     Paul> A lot of these conversions exist now in 'colorspace', but as Thomas
>     Paul> pointed out, the S4-ness of 'colorspace' is a problem for making these
>     Paul> conversions part of base R.
> 
> Hmm, I think we are currently only required to keep 'base' not
> dependent on 'methods'.
> Why should 'grDevices' or new "standard R" package not be
> dependent on 'methods' ?
> Many of us would like to see S4 been used much more widely.


Great.  I will keep working on the RFC to see if I can propose a way to
reconcile all of the color-conversion and palette-selection code based
on a single sRGB representation in the R core and only one set of
conversion functions.

Paul


> Martin

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From a.robotham at bris.ac.uk  Wed Dec  5 17:10:09 2007
From: a.robotham at bris.ac.uk (a.robotham at bris.ac.uk)
Date: Wed,  5 Dec 2007 17:10:09 +0100 (CET)
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
Message-ID: <20071205161009.737972834620@mail.pubhealth.ku.dk>

Hello,
I've recently discovered a persistent issue with rpanel when running
R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
apparent error, and the interactive panels appear to work as expected,
however upon closing the panels rpanel has created I get catastrophic
errors and R crashes completely. For the most part R manages to crash
with dignity and work can be saved, but sometimes it will crash
straight out. Below is an example of an entire work session (only base
packages loaded) with the crash at the end typical of those
encountered:

> library(tcltk)
Loading Tcl/Tk interface ... done
> library(rpanel)
Package `rpanel', version 1.0-4
type help(rpanel) for summary information
> density.draw <- function(panel) {
+   plot(density(panel$x, bw = panel$h))
+   panel
+ }
> panel <- rp.control(x = rnorm(50))
> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)

 *** caught bus error ***
address 0x0, cause 'non-existent physical address'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace

All packages that are required are up to date, and I can find no
evidence of similar issues from searching the mailing lists. Any
suggestions would be appreciated.

Aaron


From Christian.Lajaunie at ensmp.fr  Wed Dec  5 18:40:23 2007
From: Christian.Lajaunie at ensmp.fr (Christian.Lajaunie at ensmp.fr)
Date: Wed,  5 Dec 2007 18:40:23 +0100 (CET)
Subject: [Rd] confint for coefficients from lm model (PR#10496)
Message-ID: <20071205174023.1D3B92834158@mail.pubhealth.ku.dk>

Full_Name: Christian Lajaunie
Version: 2.5.1
OS: Fedora  fc6
Submission from: (NULL) (193.251.63.39)


confint() does not use the appropriate variance term when the design
matrix contains a zero column (which of course should not happen). 
Example:

A 10x2 matrix with trivial column 1:

> junk <- data.frame(x=rep(0,10), u=factor(sample(c("Y", "N"), 10, replace=T)))

The response:
> ans <- as.integer(junk$u) + rnorm(10)
and the model:
> junk.model <- lm(ans ~ junk$x + junk$u)

3 coefficients:

> coefficients(junk.model)
(Intercept)      junk$x     junk$uY 
  0.6808802          NA   1.5912192

and a 2x2 variance (X^tX)^-1:
 
> vcov(junk.model)
            (Intercept)     junk$uY
(Intercept)  0.09905378 -0.09905378
junk$uY     -0.09905378  0.19810756

result in no confidence interval for the third term:

> confint(junk.model)
                  2.5 %   97.5 %
(Intercept) -0.04488412 1.406644
junk$x               NA       NA
junk$uY              NA       NA

confint() seems to be looking for diag(vcov(junk.model))[3]
instead of diag(vcov(junk.model))[2]


From p.dalgaard at biostat.ku.dk  Wed Dec  5 22:12:31 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Dec 2007 22:12:31 +0100
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
In-Reply-To: <20071205161009.737972834620@mail.pubhealth.ku.dk>
References: <20071205161009.737972834620@mail.pubhealth.ku.dk>
Message-ID: <4757143F.9060902@biostat.ku.dk>

a.robotham at bris.ac.uk wrote:
> Hello,
> I've recently discovered a persistent issue with rpanel when running
> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
> apparent error, and the interactive panels appear to work as expected,
> however upon closing the panels rpanel has created I get catastrophic
> errors and R crashes completely. For the most part R manages to crash
> with dignity and work can be saved, but sometimes it will crash
> straight out. Below is an example of an entire work session (only base
> packages loaded) with the crash at the end typical of those
> encountered:
>
>   
>> library(tcltk)
>>     
> Loading Tcl/Tk interface ... done
>   
>> library(rpanel)
>>     
> Package `rpanel', version 1.0-4
> type help(rpanel) for summary information
>   
>> density.draw <- function(panel) {
>>     
> +   plot(density(panel$x, bw = panel$h))
> +   panel
> + }
>   
>> panel <- rp.control(x = rnorm(50))
>> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)
>>     
>
>  *** caught bus error ***
> address 0x0, cause 'non-existent physical address'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
> All packages that are required are up to date, and I can find no
> evidence of similar issues from searching the mailing lists. Any
> suggestions would be appreciated.
>
>   
Can you run this under gdb? A breakpoint in the error handler and a 
backtrace could be valuable.

> Aaron
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Wed Dec  5 22:32:27 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Dec 2007 22:32:27 +0100
Subject: [Rd] confint for coefficients from lm model (PR#10496)
In-Reply-To: <20071205174023.1D3B92834158@mail.pubhealth.ku.dk>
References: <20071205174023.1D3B92834158@mail.pubhealth.ku.dk>
Message-ID: <475718EB.2000507@biostat.ku.dk>

Christian.Lajaunie at ensmp.fr wrote:
> Full_Name: Christian Lajaunie
> Version: 2.5.1
> OS: Fedora  fc6
> Submission from: (NULL) (193.251.63.39)
>
>
> confint() does not use the appropriate variance term when the design
> matrix contains a zero column (which of course should not happen). 
> Example:
>
> A 10x2 matrix with trivial column 1:
>
>   
>> junk <- data.frame(x=rep(0,10), u=factor(sample(c("Y", "N"), 10, replace=T)))
>>     
>
> The response:
>   
>> ans <- as.integer(junk$u) + rnorm(10)
>>     
> and the model:
>   
>> junk.model <- lm(ans ~ junk$x + junk$u)
>>     
>
> 3 coefficients:
>
>   
>> coefficients(junk.model)
>>     
> (Intercept)      junk$x     junk$uY 
>   0.6808802          NA   1.5912192
>
> and a 2x2 variance (X^tX)^-1:
>  
>   
>> vcov(junk.model)
>>     
>             (Intercept)     junk$uY
> (Intercept)  0.09905378 -0.09905378
> junk$uY     -0.09905378  0.19810756
>
> result in no confidence interval for the third term:
>
>   
>> confint(junk.model)
>>     
>                   2.5 %   97.5 %
> (Intercept) -0.04488412 1.406644
> junk$x               NA       NA
> junk$uY              NA       NA
>
> confint() seems to be looking for diag(vcov(junk.model))[3]
> instead of diag(vcov(junk.model))[2]
>   
(You should upgrade, but this is the same in 2.6.1)

Yes. And confint.glm and confint.default are bad too.  The glm method 
must be a different issue, but the other two share the vcov issue.

I'm a bit unsure what is the right fix, though.  Is vcov really 
returning the wrong thing? Should we rather have

 > vcov(junk.model)
           [,1] [,2]       [,3]
[1,]  0.5525259   NA -0.5525259
[2,]         NA   NA         NA
[3,] -0.5525259   NA  0.6906574

which is not massively hard to achieve.

Alternatively we could just skip the aliased coefficients. For GLMs we 
definitely do not want to profile them...
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Wed Dec  5 22:40:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Dec 2007 21:40:54 +0000 (GMT)
Subject: [Rd] confint for coefficients from lm model (PR#10496)
In-Reply-To: <475718EB.2000507@biostat.ku.dk>
References: <20071205174023.1D3B92834158@mail.pubhealth.ku.dk>
	<475718EB.2000507@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0712052138010.17391@gannet.stats.ox.ac.uk>

Yes, vcov is doing the right thing, and it does return dimnames.  (Note 
what the help page says about what parameters.)

If you do this via names not numbers it works out.  I have the .lm and 
.default cases working, but need more time to look into others.


On Wed, 5 Dec 2007, Peter Dalgaard wrote:

> Christian.Lajaunie at ensmp.fr wrote:
>> Full_Name: Christian Lajaunie
>> Version: 2.5.1
>> OS: Fedora  fc6
>> Submission from: (NULL) (193.251.63.39)
>>
>>
>> confint() does not use the appropriate variance term when the design
>> matrix contains a zero column (which of course should not happen).
>> Example:
>>
>> A 10x2 matrix with trivial column 1:
>>
>>
>>> junk <- data.frame(x=rep(0,10), u=factor(sample(c("Y", "N"), 10, replace=T)))
>>>
>>
>> The response:
>>
>>> ans <- as.integer(junk$u) + rnorm(10)
>>>
>> and the model:
>>
>>> junk.model <- lm(ans ~ junk$x + junk$u)
>>>
>>
>> 3 coefficients:
>>
>>
>>> coefficients(junk.model)
>>>
>> (Intercept)      junk$x     junk$uY
>>   0.6808802          NA   1.5912192
>>
>> and a 2x2 variance (X^tX)^-1:
>>
>>
>>> vcov(junk.model)
>>>
>>             (Intercept)     junk$uY
>> (Intercept)  0.09905378 -0.09905378
>> junk$uY     -0.09905378  0.19810756
>>
>> result in no confidence interval for the third term:
>>
>>
>>> confint(junk.model)
>>>
>>                   2.5 %   97.5 %
>> (Intercept) -0.04488412 1.406644
>> junk$x               NA       NA
>> junk$uY              NA       NA
>>
>> confint() seems to be looking for diag(vcov(junk.model))[3]
>> instead of diag(vcov(junk.model))[2]
>>
> (You should upgrade, but this is the same in 2.6.1)
>
> Yes. And confint.glm and confint.default are bad too.  The glm method
> must be a different issue, but the other two share the vcov issue.
>
> I'm a bit unsure what is the right fix, though.  Is vcov really
> returning the wrong thing? Should we rather have
>
> > vcov(junk.model)
>           [,1] [,2]       [,3]
> [1,]  0.5525259   NA -0.5525259
> [2,]         NA   NA         NA
> [3,] -0.5525259   NA  0.6906574
>
> which is not massively hard to achieve.
>
> Alternatively we could just skip the aliased coefficients. For GLMs we
> definitely do not want to profile them...
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Dec  6 09:04:42 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2007 08:04:42 +0000 (GMT)
Subject: [Rd] Defaults for postscript()
Message-ID: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>

The defaults for postscript()

paper = "default"
onefile = TRUE
horizontal = TRUE

(it seems) date from the days when people used to used this to send plots 
directly to a postscript printer via print.it=TRUE.  I haven't done that 
for years, and it seems that our current generation of students don't even 
know the concept.  It seems 'horizontal = TRUE' is particularly difficult 
to grasp.

Given that I suspect almost all uses of postscript() are to produce plots 
to be viewed on-screen or incorporated into another document, a more 
appropriate set of defaults would be

width = 7, height = 7
paper = "special"
onefile = FALSE
horizontal = FALSE

which would have the advantage of using the same default aspect ratio for 
plots as all (?) other R graphics devices.

Does anyone see a reason not to change the defaults?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deepayan.sarkar at gmail.com  Thu Dec  6 09:32:00 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 6 Dec 2007 00:32:00 -0800
Subject: [Rd] Defaults for postscript()
In-Reply-To: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
Message-ID: <eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>

On 12/6/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> The defaults for postscript()
>
> paper = "default"
> onefile = TRUE
> horizontal = TRUE
>
> (it seems) date from the days when people used to used this to send plots
> directly to a postscript printer via print.it=TRUE.  I haven't done that
> for years, and it seems that our current generation of students don't even
> know the concept.  It seems 'horizontal = TRUE' is particularly difficult
> to grasp.
>
> Given that I suspect almost all uses of postscript() are to produce plots
> to be viewed on-screen or incorporated into another document, a more
> appropriate set of defaults would be
>
> width = 7, height = 7
> paper = "special"
> onefile = FALSE
> horizontal = FALSE
>
> which would have the advantage of using the same default aspect ratio for
> plots as all (?) other R graphics devices.
>
> Does anyone see a reason not to change the defaults?

I'm not so sure about the 'onefile' change. Scripts with multiple
plots run in batch mode will end up with multiple files; I prefer the
current behaviour. I also have test scripts in packages that go


postscript("something.ps")
<many examples>
dev.off()


Unless I change all these to have onefile=TRUE, I'll end up only with
the last plot available after the tests are run.

-Deepayan


From nikko at hailmail.net  Thu Dec  6 13:21:22 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 06 Dec 2007 07:21:22 -0500
Subject: [Rd] [R] color palette from red to blue passing white (shifted
 from R-help)
Message-ID: <1196943682.4913.1225132255@webmail.messagingengine.com>

Hi,
The move to sRGB is nice, is there any interest in adding an interface
to lcms, http://www.littlecms.com,
to allow gamut matching? I can think of a lot of instances where I would
like to render a
figure as it would appear on my printer. This is probably best done as a
separate package though,
at least at first.

Nicholas


Martin Maechler wrote:
>>>>>> "Paul" == Paul Murrell <p.murrell at auckland.ac.nz>
>>>>>>     on Wed, 05 Dec 2007 08:53:10 +1300 writes:
> 
>     Paul> Hi
>     Paul> Achim and I have been looking at tidying up the colorspace package (see
>     Paul> http://r-forge.r-project.org/projects/colorspace/) to fix a few
>     Paul> inaccuracies, PLUS the possibility of declaring R's internal color space
>     Paul> to be sRGB.
> 
>     Paul> I have started an RFC on the r-developer site
>     Paul> (http://developer.r-project.org/sRGB-RFC.html) to discuss some possible
>     Paul> changes to the core engine and add-on packages.
> 
>     Paul> One of the issues will be consolidating some of the double-ups (e.g.,
>     Paul> hcl() in base and the counterpart in package 'colorspace';  I did not
>     Paul> even know about convertColor()!).
> 
>     Paul> Ideally, we would have only one copy of the conversions between the
>     Paul> various colorspaces (probably C code, then the various R-level front
>     Paul> ends can all just run off the same internal code).
> 
>     Paul> A lot of these conversions exist now in 'colorspace', but as Thomas
>     Paul> pointed out, the S4-ness of 'colorspace' is a problem for making these
>     Paul> conversions part of base R.
> 
> Hmm, I think we are currently only required to keep 'base' not
> dependent on 'methods'.
> Why should 'grDevices' or new "standard R" package not be
> dependent on 'methods' ?
> Many of us would like to see S4 been used much more widely.


Great.  I will keep working on the RFC to see if I can propose a way to
reconcile all of the color-conversion and palette-selection code based
on a single sRGB representation in the R core and only one set of
conversion functions.

Paul


> Martin


From serge.de.gosson.de.varennes at forsakringskassan.se  Thu Dec  6 13:34:58 2007
From: serge.de.gosson.de.varennes at forsakringskassan.se (de Gosson de Varennes Serge (4100))
Date: Thu, 6 Dec 2007 13:34:58 +0100
Subject: [Rd] Solve.QP
Message-ID: <D0B620C63B10AC41BF1DBD4184C9C50003442529@S00MAIL003.ads.sfa.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071206/23e0d460/attachment.pl 

From murdoch at stats.uwo.ca  Thu Dec  6 14:35:07 2007
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Thu,  6 Dec 2007 14:35:07 +0100 (CET)
Subject: [Rd] trace() problems (PR#10498)
Message-ID: <20071206133507.BA0ED283416A@mail.pubhealth.ku.dk>

trace() seems to be broken in 2.6.1 and R-devel:

Try the example from the ?debug man page:

 > library(methods)
 > trace("plot", browser, exit=browser, signature = c("track",
+       "missing"))
Error in getFunction(what, where = whereF) : no function "plot" found

Okay, it's just an example that doesn't work.  Let's try a simpler one, 
the first example from the ?trace man page:

 > trace(sum)
 > hist(stats::rnorm(100)) # shows about 3-4 calls to sum()
 > untrace(sum)

No trace!  In a clean session without the first error, things are fine:

 > trace(sum)
 > hist(stats::rnorm(100)) # shows about 3-4 calls to sum()
trace: sum(2^(opts - 2))
trace: sum(2^(opts - 2))
trace: sum(2^(opts - 2))
trace: sum(counts)
trace: sum(2^(opts - 2))
 > untrace(sum)

Duncan Murdoch


From berwin at maths.uwa.edu.au  Thu Dec  6 16:49:39 2007
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 6 Dec 2007 23:49:39 +0800
Subject: [Rd] Solve.QP
In-Reply-To: <D0B620C63B10AC41BF1DBD4184C9C50003442529@S00MAIL003.ads.sfa.se>
References: <D0B620C63B10AC41BF1DBD4184C9C50003442529@S00MAIL003.ads.sfa.se>
Message-ID: <20071206234939.5ea4a222@absentia>

G'day Serge,

On Thu, 6 Dec 2007 13:34:58 +0100
"de Gosson de Varennes Serge (4100)"
<serge.de.gosson.de.varennes at forsakringskassan.se> wrote:

> I have a major problem (major for me that is) with solve.QP and I'm
> new at this. You see, to solve my quadratic program I need to have
> the lagrange multipliers after each iteration. Solve.QP gives me the
> solution, the unconstrained solution aswell as the optimal value.
> Does anybody have an idea for how I could extract the multipliers?

You could calculate them.  For the quadratic program 

min  1/2 x'Dx - d'x   such that A'x >= b

the KKT conditions are:

( D -A) (x) = (d)
( A' 0) (l) = (b)

plus the complementary conditions.  solve.QP tells you the solution x*
and which constraints are active.  If A* is the submatrix of A that
contains only those columns of A that correspond to active constraints
at the solution, then the first line in the above set of equations
imply that the corresponding Lagrange multiplier l* fulfill the
equations:

D x* - A* l* = d  -->  l* = (A*' A*)^{-1} A*'(D x* - d)

all other Lagrange multiplier would be zero.  

Thus, using the example from the help page and expanding it, the
following code should calculate the Lagrange multipliers:

Dmat       <- matrix(0,3,3)
diag(Dmat) <- 1
dvec       <- c(0,5,0)
Amat       <- matrix(c(-4,-3,0,2,1,0,0,-2,1),3,3)
bvec       <- c(-8,2,0)
res <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
xst <- res$solution
tmp <- Dmat %*% xst -dvec
Ast <- Amat[,res$iact]
ll <- solve(crossprod(Ast,Ast), crossprod(Ast, tmp))
## a small check
cbind(tmp, Ast %*% ll)
lagr <- rep(0, ncol(Amat))
lagrange[res$iact] <- ll
lagrange
[1] 0.0000000 0.2380952 2.0952381


Alternatively, somewhere down in the FORTRAN code the Lagrange
multipliers are actually calculated.  About 4 years ago somebody asked
me about this and he could locate where they are calculated.  He
modified the FORTRAN code and the R code such that the Lagrange
multipliers would be returned too.  Curiously, he sent the modified
code to me and not to the package maintainer, but I had no time at that
moment to check his modification, so I never passed anything on to the
package maintainer either.  But if you are interested in modifying the
FORTRAN and R code and recompile the package yourself, I can see if I
can find that code.

I still think that this package should be worked over by someone with a
better understanding of the kind of fudges that do not come back to
bite and of finite precision arithmetic than the original author's
appreciation of such issues when the code was written. ;-))  Given
Bill's recent comments on r-help, I wonder whether this package is one
of those on his list of downright dangerous packages.  LOL.

Hope this helps.

Cheers,

	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
Dept of Statistics and Applied Probability        +65 6516 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From marc_schwartz at comcast.net  Thu Dec  6 17:22:06 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 06 Dec 2007 10:22:06 -0600
Subject: [Rd] Defaults for postscript()
In-Reply-To: <eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
	<eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
Message-ID: <1196958126.2955.19.camel@Bellerophon.localdomain>


On Thu, 2007-12-06 at 00:32 -0800, Deepayan Sarkar wrote:
> On 12/6/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > The defaults for postscript()
> >
> > paper = "default"
> > onefile = TRUE
> > horizontal = TRUE
> >
> > (it seems) date from the days when people used to used this to send plots
> > directly to a postscript printer via print.it=TRUE.  I haven't done that
> > for years, and it seems that our current generation of students don't even
> > know the concept.  It seems 'horizontal = TRUE' is particularly difficult
> > to grasp.
> >
> > Given that I suspect almost all uses of postscript() are to produce plots
> > to be viewed on-screen or incorporated into another document, a more
> > appropriate set of defaults would be
> >
> > width = 7, height = 7
> > paper = "special"
> > onefile = FALSE
> > horizontal = FALSE
> >
> > which would have the advantage of using the same default aspect ratio for
> > plots as all (?) other R graphics devices.
> >
> > Does anyone see a reason not to change the defaults?
> 
> I'm not so sure about the 'onefile' change. Scripts with multiple
> plots run in batch mode will end up with multiple files; I prefer the
> current behaviour. I also have test scripts in packages that go
> 
> 
> postscript("something.ps")
> <many examples>
> dev.off()
> 
> 
> Unless I change all these to have onefile=TRUE, I'll end up only with
> the last plot available after the tests are run.
> 
> -Deepayan

In a vacuum, I would agree that changing the default values makes sense
given the preponderance of the use for postscript() for creating EPS
files for use in LaTeX and other documents (eg. Office/OO.org). It might
also serve to reduce the frequency of questions on the lists on this
subject.

That being said, I understand Deepayan's concern.

I don't have a sense of how many others would be affected by such a
change.

Pending any other comments on the matter, an incremental approach might
include an initial near term restructuring of the help file for
postscript(), whereby the following content in the Details section:


The postscript produced for a single R plot is EPS (Encapsulated
PostScript) compatible, and can be included into other documents, e.g.,
into LaTeX, using \includegraphics{<filename>}. For use in this way you
will probably want to set horizontal = FALSE, onefile = FALSE, paper =
"special". Note that the bounding box is for the device region: if you
find the white space around the plot region excessive, reduce the
margins of the figure region via par(mar=).


is moved to a new Notes section, which could precede the Details
section, given the likely nature of such use. This change could be done
now for R-patched and R-devel.

A separate second comment could be added to the Notes section,
indicating that the defaults will change to those above in version
2.8.0. The longer time frame would give affected package maintainers a
heads up of the pending change and more lead time for implementation of
any changes.

HTH,

Marc


From lee.falin at gmail.com  Thu Dec  6 17:58:13 2007
From: lee.falin at gmail.com (Lee Falin)
Date: Thu, 6 Dec 2007 11:58:13 -0500
Subject: [Rd] R-Cocoa Bridge
Message-ID: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>

I had seen old posts on the list (circa 2002) regarding a Cocoa-R  
bridge that was under development, but I can't find anything recent  
about it. Does anyone know if this is available somewhere? If not,  
does anyone have any experience/pointers calling R functions from Cocoa?

Thanks for your time,
Lee Falin


From elw at stderr.org  Thu Dec  6 18:30:21 2007
From: elw at stderr.org (elw at stderr.org)
Date: Thu, 6 Dec 2007 11:30:21 -0600 (CST)
Subject: [Rd] R-Cocoa Bridge
In-Reply-To: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
References: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
Message-ID: <Pine.LNX.4.64.0712061129300.20158@illuminati.stderr.org>



> I had seen old posts on the list (circa 2002) regarding a Cocoa-R bridge 
> that was under development, but I can't find anything recent about it. 
> Does anyone know if this is available somewhere? If not, does anyone 
> have any experience/pointers calling R functions from Cocoa?

The R builds on OSX build an R.Framework; you can probably bootstrap off 
of that without too much trouble.  [I haven't done much with it; wish I 
had time.]

--elijah


From simon.urbanek at r-project.org  Thu Dec  6 18:32:51 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 6 Dec 2007 12:32:51 -0500
Subject: [Rd] R-Cocoa Bridge
In-Reply-To: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
References: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
Message-ID: <1E59E75E-7220-4DD8-9975-8CFAEC7DE56E@r-project.org>


On Dec 6, 2007, at 11:58 AM, Lee Falin wrote:

> I had seen old posts on the list (circa 2002) regarding a Cocoa-R    
> bridge that was under development, but I can't find anything recent  
> about it. Does anyone know if this is available somewhere? If not,  
> does anyone have any experience/pointers calling R functions from  
> Cocoa?
>

R/Cocoa bridge is what the R for Mac OS X GUI is built upon (just grab  
the sources and look at REngine). However, it's not perfect (its main  
purpose was to support the GUI - it may need some de-coupling - see  
also the "stand-alone-REngine" branch) and there is an ongoing project  
to get write a more general bridge as part of the Mac GUI 2.x  
initiative. There are also other alternatives, but I'm not sure how  
public or currently maintained they are these days.

Cheers,
Simon


From jmc at r-project.org  Thu Dec  6 18:38:16 2007
From: jmc at r-project.org (John Chambers)
Date: Thu, 06 Dec 2007 09:38:16 -0800
Subject: [Rd] trace() problems (PR#10498)
In-Reply-To: <20071206133507.BA0ED283416A@mail.pubhealth.ku.dk>
References: <20071206133507.BA0ED283416A@mail.pubhealth.ku.dk>
Message-ID: <47583388.5010207@r-project.org>

The problem is at least as old as 2.5.1.  Looks like a line disappeared 
from trace(), something like:
    on.exit(tracingState(tState))

As a result, if an error occurs in the call to trace(), the tracing 
state is left FALSE.  The workaround is to turn it on explicitly:

    tracingState(TRUE)

after which normal behavior should resume.

murdoch at stats.uwo.ca wrote:
> trace() seems to be broken in 2.6.1 and R-devel:
>
> Try the example from the ?debug man page:
>
>  > library(methods)
>  > trace("plot", browser, exit=browser, signature = c("track",
> +       "missing"))
> Error in getFunction(what, where = whereF) : no function "plot" found
>
> Okay, it's just an example that doesn't work.  Let's try a simpler one, 
> the first example from the ?trace man page:
>
>  > trace(sum)
>  > hist(stats::rnorm(100)) # shows about 3-4 calls to sum()
>  > untrace(sum)
>
> No trace!  In a clean session without the first error, things are fine:
>
>  > trace(sum)
>  > hist(stats::rnorm(100)) # shows about 3-4 calls to sum()
> trace: sum(2^(opts - 2))
> trace: sum(2^(opts - 2))
> trace: sum(2^(opts - 2))
> trace: sum(counts)
> trace: sum(2^(opts - 2))
>  > untrace(sum)
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From spencer.graves at pdf.com  Thu Dec  6 18:38:22 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 06 Dec 2007 09:38:22 -0800
Subject: [Rd] suggested modification to the 'mle' documentation?
Message-ID: <4758338E.3080802@pdf.com>

Hello: 

      I wish to again express my appreciation to all who have 
contributed to making R what it is today. 

      At this moment, I'm particularly grateful for whoever modified the 
'mle' code so data no longer need be passed via global variables.  I 
remember struggling with this a couple of years ago, and I only today 
discovered that it is no longer the case. 

      I'd like to suggest that the 'mle' help file be modified to 
advertise this fact, e.g., by adding one of the two examples appearing 
below. 

      Best Wishes,
      Spencer Graves
################################
x <- 0:10
y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
#  Pass data via function arguments rather than global variables
ll.5 <- function(ymax=15, xhalf=6, x., y.)
         -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))
(fit.5 <- mle(ll.5, start=list(ymax=15, xhalf=6),
              fixed=list(x.=x, y.=y)))

ll3 <- function(lymax=log(15), lxhalf=log(6), x., y.)
  -sum(stats::dpois(y.,
         lambda=exp(lymax)/(1+x./exp(lxhalf)), log=TRUE))
(fit3 <- mle(ll3, start=list(lymax=0, lxhalf=0),
             fixed=list(x.=x, y.=y)))


From simon.urbanek at r-project.org  Thu Dec  6 18:42:03 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 6 Dec 2007 12:42:03 -0500
Subject: [Rd] R-Cocoa Bridge
In-Reply-To: <Pine.LNX.4.64.0712061129300.20158@illuminati.stderr.org>
References: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
	<Pine.LNX.4.64.0712061129300.20158@illuminati.stderr.org>
Message-ID: <6D1632FE-9965-4705-9B34-175BE0E33A36@r-project.org>

On Dec 6, 2007, at 12:30 PM, elw at stderr.org wrote:

>> I had seen old posts on the list (circa 2002) regarding a Cocoa-R  
>> bridge that was under development, but I can't find anything recent  
>> about it. Does anyone know if this is available somewhere? If not,  
>> does anyone have any experience/pointers calling R functions from  
>> Cocoa?
>
> The R builds on OSX build an R.Framework; you can probably bootstrap  
> off of that without too much trouble.  [I haven't done much with it;  
> wish I had time.]
>

Unfortunately the R/ObjC bridge is not part of the framework yet.  
We're working on it, but we need some more cleanup of the old code.  
The current plan is to have it ready for R 2.7.0 (but you never  
know ...).

Cheers,
Simon


From p.murrell at auckland.ac.nz  Thu Dec  6 19:30:47 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 07 Dec 2007 07:30:47 +1300
Subject: [Rd] Defaults for postscript()
In-Reply-To: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
Message-ID: <47583FD7.4000705@stat.auckland.ac.nz>

Hi


Prof Brian Ripley wrote:
> The defaults for postscript()
> 
> paper = "default"
> onefile = TRUE
> horizontal = TRUE
> 
> (it seems) date from the days when people used to used this to send plots 
> directly to a postscript printer via print.it=TRUE.  I haven't done that 
> for years, and it seems that our current generation of students don't even 
> know the concept.  It seems 'horizontal = TRUE' is particularly difficult 
> to grasp.
> 
> Given that I suspect almost all uses of postscript() are to produce plots 
> to be viewed on-screen or incorporated into another document, a more 
> appropriate set of defaults would be
> 
> width = 7, height = 7


Wouldn't that be better as width = 6, height = 6 to match pdf() ?

Paul


> paper = "special"
> onefile = FALSE
> horizontal = FALSE
> 
> which would have the advantage of using the same default aspect ratio for 
> plots as all (?) other R graphics devices.
> 
> Does anyone see a reason not to change the defaults?
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From p.murrell at auckland.ac.nz  Thu Dec  6 19:41:06 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 07 Dec 2007 07:41:06 +1300
Subject: [Rd] [R] color palette from red to blue passing white (shifted
 from R-help)
In-Reply-To: <1196943682.4913.1225132255@webmail.messagingengine.com>
References: <1196943682.4913.1225132255@webmail.messagingengine.com>
Message-ID: <47584242.30005@stat.auckland.ac.nz>

Hi


Nicholas Lewin-Koh wrote:
> Hi,
> The move to sRGB is nice, is there any interest in adding an interface
> to lcms, http://www.littlecms.com,
> to allow gamut matching? I can think of a lot of instances where I would
> like to render a
> figure as it would appear on my printer. This is probably best done as a
> separate package though,
> at least at first.


I saw a mention of this when I began looking at Krita the other day
(because I had heard that it had good colour support).  Screen-to-print
would be a great thing to support.

Paul


> Nicholas
> 
> 
> Martin Maechler wrote:
>>>>>>> "Paul" == Paul Murrell <p.murrell at auckland.ac.nz>
>>>>>>>     on Wed, 05 Dec 2007 08:53:10 +1300 writes:
>>     Paul> Hi
>>     Paul> Achim and I have been looking at tidying up the colorspace package (see
>>     Paul> http://r-forge.r-project.org/projects/colorspace/) to fix a few
>>     Paul> inaccuracies, PLUS the possibility of declaring R's internal color space
>>     Paul> to be sRGB.
>>
>>     Paul> I have started an RFC on the r-developer site
>>     Paul> (http://developer.r-project.org/sRGB-RFC.html) to discuss some possible
>>     Paul> changes to the core engine and add-on packages.
>>
>>     Paul> One of the issues will be consolidating some of the double-ups (e.g.,
>>     Paul> hcl() in base and the counterpart in package 'colorspace';  I did not
>>     Paul> even know about convertColor()!).
>>
>>     Paul> Ideally, we would have only one copy of the conversions between the
>>     Paul> various colorspaces (probably C code, then the various R-level front
>>     Paul> ends can all just run off the same internal code).
>>
>>     Paul> A lot of these conversions exist now in 'colorspace', but as Thomas
>>     Paul> pointed out, the S4-ness of 'colorspace' is a problem for making these
>>     Paul> conversions part of base R.
>>
>> Hmm, I think we are currently only required to keep 'base' not
>> dependent on 'methods'.
>> Why should 'grDevices' or new "standard R" package not be
>> dependent on 'methods' ?
>> Many of us would like to see S4 been used much more widely.
> 
> 
> Great.  I will keep working on the RFC to see if I can propose a way to
> reconcile all of the color-conversion and palette-selection code based
> on a single sRGB representation in the R core and only one set of
> conversion functions.
> 
> Paul
> 
> 
>> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From a.robotham at bristol.ac.uk  Thu Dec  6 15:26:43 2007
From: a.robotham at bristol.ac.uk (Aaron Robotham)
Date: Thu, 6 Dec 2007 14:26:43 +0000
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
In-Reply-To: <4757143F.9060902@biostat.ku.dk>
References: <20071205161009.737972834620@mail.pubhealth.ku.dk>
	<4757143F.9060902@biostat.ku.dk>
Message-ID: <debf56250712060626u540deea0w32f0b919b3cbfa95@mail.gmail.com>

I know of gdb but I'm not certain how to use it with Mac OS X's R.app,
do you just do something like "gdb open R.app" in the terminal?.

Interestingly I don't get this crash when I launch the X11 version of
R through the terminal, so this would suggest the bug in question is
to do with the actual Rgui in R.app. Hopefully this information might
help to narrow down the problem. Any advice for using gdb on R.app
would be appreciated, I couldn't find much in the way of guidance when
searching online.

thanks

Aaron

On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> a.robotham at bris.ac.uk wrote:
> > Hello,
> > I've recently discovered a persistent issue with rpanel when running
> > R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
> > apparent error, and the interactive panels appear to work as expected,
> > however upon closing the panels rpanel has created I get catastrophic
> > errors and R crashes completely. For the most part R manages to crash
> > with dignity and work can be saved, but sometimes it will crash
> > straight out. Below is an example of an entire work session (only base
> > packages loaded) with the crash at the end typical of those
> > encountered:
> >
> >
> >> library(tcltk)
> >>
> > Loading Tcl/Tk interface ... done
> >
> >> library(rpanel)
> >>
> > Package `rpanel', version 1.0-4
> > type help(rpanel) for summary information
> >
> >> density.draw <- function(panel) {
> >>
> > +   plot(density(panel$x, bw = panel$h))
> > +   panel
> > + }
> >
> >> panel <- rp.control(x = rnorm(50))
> >> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)
> >>
> >
> >  *** caught bus error ***
> > address 0x0, cause 'non-existent physical address'
> >
> > Possible actions:
> > 1: abort (with core dump, if enabled)
> > 2: normal R exit
> > 3: exit R without saving workspace
> > 4: exit R saving workspace
> >
> > All packages that are required are up to date, and I can find no
> > evidence of similar issues from searching the mailing lists. Any
> > suggestions would be appreciated.
> >
> >
> Can you run this under gdb? A breakpoint in the error handler and a
> backtrace could be valuable.
>
> > Aaron
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
> --
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>
>


From cyrix333 at gmx.net  Thu Dec  6 10:40:27 2007
From: cyrix333 at gmx.net (cyrix333 at gmx.net)
Date: Thu,  6 Dec 2007 10:40:27 +0100 (CET)
Subject: [Rd] RGtk2  + tcltk combination problem (PR#10497)
Message-ID: <20071206094027.BCD47283416A@mail.pubhealth.ku.dk>

Full_Name: Hans Dieter
Version: 2.6.1
OS: windows
Submission from: (NULL) (217.93.91.19)


Hi all,
first I used a TCL/TK GUI, after my work I cloed it and opend an RGTK2 GUI.
Now I have the problem, the RGTK2 GUI will not refresh correctly and basic
user-commands ( close windows ) dosen't work.

Greetings
Dieter


From lawremi at iastate.edu  Thu Dec  6 21:12:02 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Thu, 6 Dec 2007 14:12:02 -0600
Subject: [Rd] RGtk2 + tcltk combination problem (PR#10497)
In-Reply-To: <20071206094027.BCD47283416A@mail.pubhealth.ku.dk>
References: <20071206094027.BCD47283416A@mail.pubhealth.ku.dk>
Message-ID: <509e0620712061212x513d203cy4734cf03d4a5c944@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071206/f84432b6/attachment.pl 

From simon.urbanek at r-project.org  Thu Dec  6 22:25:34 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 6 Dec 2007 16:25:34 -0500
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
In-Reply-To: <debf56250712060626u540deea0w32f0b919b3cbfa95@mail.gmail.com>
References: <20071205161009.737972834620@mail.pubhealth.ku.dk>
	<4757143F.9060902@biostat.ku.dk>
	<debf56250712060626u540deea0w32f0b919b3cbfa95@mail.gmail.com>
Message-ID: <1497CFD2-F77D-45D6-A68B-AAFD7CB27CBB@r-project.org>


On Dec 6, 2007, at 9:26 AM, Aaron Robotham wrote:

> I know of gdb but I'm not certain how to use it with Mac OS X's  
> R.app, do you just do something like "gdb open R.app" in the  
> terminal?.
>

You can attach it once it's running - just type "attach R" in gdb  
while R is runningm then "c", then let it crash and then "bt".

FWIW: I cannot reproduce the problem and I have tried 3 different  
machines... (you didn't even tell us what machine type this is ...).

Cheers,
Simon


> Interestingly I don't get this crash when I launch the X11 version of
> R through the terminal, so this would suggest the bug in question is
> to do with the actual Rgui in R.app. Hopefully this information might
> help to narrow down the problem. Any advice for using gdb on R.app
> would be appreciated, I couldn't find much in the way of guidance when
> searching online.
>
> thanks
>
> Aaron
>
> On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> a.robotham at bris.ac.uk wrote:
>>> Hello,
>>> I've recently discovered a persistent issue with rpanel when running
>>> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
>>> apparent error, and the interactive panels appear to work as  
>>> expected,
>>> however upon closing the panels rpanel has created I get  
>>> catastrophic
>>> errors and R crashes completely. For the most part R manages to  
>>> crash
>>> with dignity and work can be saved, but sometimes it will crash
>>> straight out. Below is an example of an entire work session (only  
>>> base
>>> packages loaded) with the crash at the end typical of those
>>> encountered:
>>>
>>>
>>>> library(tcltk)
>>>>
>>> Loading Tcl/Tk interface ... done
>>>
>>>> library(rpanel)
>>>>
>>> Package `rpanel', version 1.0-4
>>> type help(rpanel) for summary information
>>>
>>>> density.draw <- function(panel) {
>>>>
>>> +   plot(density(panel$x, bw = panel$h))
>>> +   panel
>>> + }
>>>
>>>> panel <- rp.control(x = rnorm(50))
>>>> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)
>>>>
>>>
>>> *** caught bus error ***
>>> address 0x0, cause 'non-existent physical address'
>>>
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>>
>>> All packages that are required are up to date, and I can find no
>>> evidence of similar issues from searching the mailing lists. Any
>>> suggestions would be appreciated.
>>>
>>>
>> Can you run this under gdb? A breakpoint in the error handler and a
>> backtrace could be valuable.
>>
>>> Aaron
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>> --
>>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
>> 35327907
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Thu Dec  6 22:30:12 2007
From: simon.urbanek at r-project.org (simon.urbanek at r-project.org)
Date: Thu,  6 Dec 2007 22:30:12 +0100 (CET)
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
Message-ID: <20071206213012.34ECA2834611@mail.pubhealth.ku.dk>


On Dec 6, 2007, at 9:26 AM, Aaron Robotham wrote:

> I know of gdb but I'm not certain how to use it with Mac OS X's =20
> R.app, do you just do something like "gdb open R.app" in the =20
> terminal?.
>

You can attach it once it's running - just type "attach R" in gdb =20
while R is runningm then "c", then let it crash and then "bt".

FWIW: I cannot reproduce the problem and I have tried 3 different =20
machines... (you didn't even tell us what machine type this is ...).

Cheers,
Simon


> Interestingly I don't get this crash when I launch the X11 version of
> R through the terminal, so this would suggest the bug in question is
> to do with the actual Rgui in R.app. Hopefully this information might
> help to narrow down the problem. Any advice for using gdb on R.app
> would be appreciated, I couldn't find much in the way of guidance when
> searching online.
>
> thanks
>
> Aaron
>
> On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> a.robotham at bris.ac.uk wrote:
>>> Hello,
>>> I've recently discovered a persistent issue with rpanel when running
>>> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
>>> apparent error, and the interactive panels appear to work as =20
>>> expected,
>>> however upon closing the panels rpanel has created I get =20
>>> catastrophic
>>> errors and R crashes completely. For the most part R manages to =20
>>> crash
>>> with dignity and work can be saved, but sometimes it will crash
>>> straight out. Below is an example of an entire work session (only =20=

>>> base
>>> packages loaded) with the crash at the end typical of those
>>> encountered:
>>>
>>>
>>>> library(tcltk)
>>>>
>>> Loading Tcl/Tk interface ... done
>>>
>>>> library(rpanel)
>>>>
>>> Package `rpanel', version 1.0-4
>>> type help(rpanel) for summary information
>>>
>>>> density.draw <- function(panel) {
>>>>
>>> +   plot(density(panel$x, bw =3D panel$h))
>>> +   panel
>>> + }
>>>
>>>> panel <- rp.control(x =3D rnorm(50))
>>>> rp.slider(panel, h, 0.5, 5, log =3D TRUE, action =3D density.draw)
>>>>
>>>
>>> *** caught bus error ***
>>> address 0x0, cause 'non-existent physical address'
>>>
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>>
>>> All packages that are required are up to date, and I can find no
>>> evidence of similar issues from searching the mailing lists. Any
>>> suggestions would be appreciated.
>>>
>>>
>> Can you run this under gdb? A breakpoint in the error handler and a
>> backtrace could be valuable.
>>
>>> Aaron
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>> --
>>   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) =20=

>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) =20=

>> 35327907
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From mwtoews at sfu.ca  Thu Dec  6 22:50:20 2007
From: mwtoews at sfu.ca (mwtoews at sfu.ca)
Date: Thu,  6 Dec 2007 22:50:20 +0100 (CET)
Subject: [Rd] End of whiskers of boxplots are repeated on PDF device
	(PR#10499)
Message-ID: <20071206215020.230F6283461C@mail.pubhealth.ku.dk>

Full_Name: Michael Toews
Version: 2.61
OS: WinXP SP2
Submission from: (NULL) (142.58.206.114)


Using boxplot on a PDF device with more than one group (or boxes) produces
multiple (and overlain) 1st and 3rd quartile ticks. There are exactly the
multiple of boxplot groups as there are of each 1st and 3rd quartile ticks for
each boxplot (drawn as a horizontal line at the end of each boxplot), which is
(groups^2)x2 tick marks in total drawn for the device region.

For example, a device with 4 boxplots:
dat <- data.frame(f=factor(rep(1:4, 10)), x=rnorm(40))
pdf("test.pdf")
plot(dat)
dev.off()

Since the ticks are overlain, the problem is not apparent when viewed in a PDF
reader, but if one were to open the PDF in either CorelDraw or Adobe
Illustrator[*], it is clear that there are 4 ticks for the 1st and 3rd quartile
marks. This example produces (4^2)x32=64 marks, which is 58 too many. In other
examples that use 86 boxplots, there are (86^2)x2=14792 ticks, of which only
2x86 are needed, the rest are redundant.

[*] I'm not familiar with any OSS capable of editing PDFs, however you can see
the tick marks in the PDF file through any text editor on lines 54-61, 77-84,
100-107, and 123-130. The tick marks alternate from 1st to 3rd each of the four
times, so deleting the bottom 6 lines in each group removes the redundancy.

I have also tested the example using the postscript device, but it seems fine
(the skeleton of the boxplots appear to be compound paths, so are drawn very
differently from a low-level graphics standpoint).


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 6.1
 year = 2007
 month = 11
 day = 26
 svn rev = 43537
 language = R
 version.string = R version 2.6.1 (2007-11-26)

Windows XP (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_Canada.1252;LC_CTYPE=English_Canada.1252;LC_MONETARY=English_Canada.1252;LC_NUMERIC=C;LC_TIME=English_Canada.1252

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices, package:utils,
package:datasets, package:methods, Autoloads, package:base


From ripley at stats.ox.ac.uk  Thu Dec  6 23:07:01 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Dec 2007 22:07:01 +0000 (GMT)
Subject: [Rd] Defaults for postscript()
In-Reply-To: <47583FD7.4000705@stat.auckland.ac.nz>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
	<47583FD7.4000705@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0712061835130.29413@gannet.stats.ox.ac.uk>

On Fri, 7 Dec 2007, Paul Murrell wrote:

> Hi
>
>
> Prof Brian Ripley wrote:
>> The defaults for postscript()
>>
>> paper = "default"
>> onefile = TRUE
>> horizontal = TRUE
>>
>> (it seems) date from the days when people used to used this to send plots
>> directly to a postscript printer via print.it=TRUE.  I haven't done that
>> for years, and it seems that our current generation of students don't even
>> know the concept.  It seems 'horizontal = TRUE' is particularly difficult
>> to grasp.
>>
>> Given that I suspect almost all uses of postscript() are to produce plots
>> to be viewed on-screen or incorporated into another document, a more
>> appropriate set of defaults would be
>>
>> width = 7, height = 7
>
>
> Wouldn't that be better as width = 6, height = 6 to match pdf() ?

Perhaps (but not matching X11 nor windows).  Would anyone notice the 
difference?  One argument against is that I now think the default 
pointsize in pdf() is too large for the default device region.

I would have suggested 8x6 (which is what the MASS scripts use) apart from 
the R preference for square device regions.

Thanks to Deepayan & Marc for other comments: I will have some follow-up 
comments in due course.

>
> Paul
>
>
>> paper = "special"
>> onefile = FALSE
>> horizontal = FALSE
>>
>> which would have the advantage of using the same default aspect ratio for
>> plots as all (?) other R graphics devices.
>>
>> Does anyone see a reason not to change the defaults?
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mwtoews at sfu.ca  Thu Dec  6 23:33:21 2007
From: mwtoews at sfu.ca (Michael Toews)
Date: Thu, 06 Dec 2007 14:33:21 -0800
Subject: [Rd] End of whiskers of boxplots are repeated on PDF
	device	(PR#10499)
Message-ID: <475878B1.6020806@sfu.ca>

As a quick follow up, this problem is apparent in the Postscript device 
too (and possibly other vector devices).

For example:
dat <- data.frame(f=factor(rep(1:4, 10)), x=rnorm(40))
postscript("test.ps")
plot(dat)
dev.off()

In Adobe Illustrator, the compound path needs to be "released" to see 
the extra outer whisker ticks.

In the "test.ps" file, the first occurrence (for the first boxplot) is 
on lines 143-150, and repeats are on lines 151-174.


+mt


From p.dalgaard at biostat.ku.dk  Fri Dec  7 00:01:04 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 07 Dec 2007 00:01:04 +0100
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4758338E.3080802@pdf.com>
References: <4758338E.3080802@pdf.com>
Message-ID: <47587F30.6020701@biostat.ku.dk>

Spencer Graves wrote:
> Hello: 
>
>       I wish to again express my appreciation to all who have 
> contributed to making R what it is today. 
>
>       At this moment, I'm particularly grateful for whoever modified the 
> 'mle' code so data no longer need be passed via global variables.  I 
> remember struggling with this a couple of years ago, and I only today 
> discovered that it is no longer the case. 
>
>       I'd like to suggest that the 'mle' help file be modified to 
> advertise this fact, e.g., by adding one of the two examples appearing 
> below. 
>   

In a word: No!!! That is not the design. A likelihood function is a 
function of its parameters, and the "fixed" argument is for holding some 
parameters fixed (e.g. during profiling).

To include data, just make a closure, e.g.

poissonLike <- function(x., y.){
    function(ymax=15, xhalf=6)
      -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))}
mll <-  poissonLike(x, y)
mle(ll, ....


>       Best Wishes,
>       Spencer Graves
> ################################
> x <- 0:10
> y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
> #  Pass data via function arguments rather than global variables
> ll.5 <- function(ymax=15, xhalf=6, x., y.)
>          -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))
> (fit.5 <- mle(ll.5, start=list(ymax=15, xhalf=6),
>               fixed=list(x.=x, y.=y)))
>
> ll3 <- function(lymax=log(15), lxhalf=log(6), x., y.)
>   -sum(stats::dpois(y.,
>          lambda=exp(lymax)/(1+x./exp(lxhalf)), log=TRUE))
> (fit3 <- mle(ll3, start=list(lymax=0, lxhalf=0),
>              fixed=list(x.=x, y.=y)))
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ggrothendieck at gmail.com  Fri Dec  7 00:12:35 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Dec 2007 18:12:35 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <47587F30.6020701@biostat.ku.dk>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
Message-ID: <971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>

The closure only works if you are defining the inner function yourself.
If you are not then its yet more work to redefine the environment of
the inner function or other workaround.

On Dec 6, 2007 6:01 PM, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Spencer Graves wrote:
> > Hello:
> >
> >       I wish to again express my appreciation to all who have
> > contributed to making R what it is today.
> >
> >       At this moment, I'm particularly grateful for whoever modified the
> > 'mle' code so data no longer need be passed via global variables.  I
> > remember struggling with this a couple of years ago, and I only today
> > discovered that it is no longer the case.
> >
> >       I'd like to suggest that the 'mle' help file be modified to
> > advertise this fact, e.g., by adding one of the two examples appearing
> > below.
> >
>
> In a word: No!!! That is not the design. A likelihood function is a
> function of its parameters, and the "fixed" argument is for holding some
> parameters fixed (e.g. during profiling).
>
> To include data, just make a closure, e.g.
>
> poissonLike <- function(x., y.){
>    function(ymax=15, xhalf=6)
>      -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))}
> mll <-  poissonLike(x, y)
> mle(ll, ....
>
>
> >       Best Wishes,
> >       Spencer Graves
> > ################################
> > x <- 0:10
> > y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
> > #  Pass data via function arguments rather than global variables
> > ll.5 <- function(ymax=15, xhalf=6, x., y.)
> >          -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))
> > (fit.5 <- mle(ll.5, start=list(ymax=15, xhalf=6),
> >               fixed=list(x.=x, y.=y)))
> >
> > ll3 <- function(lymax=log(15), lxhalf=log(6), x., y.)
> >   -sum(stats::dpois(y.,
> >          lambda=exp(lymax)/(1+x./exp(lxhalf)), log=TRUE))
> > (fit3 <- mle(ll3, start=list(lymax=0, lxhalf=0),
> >              fixed=list(x.=x, y.=y)))
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bolker at ufl.edu  Fri Dec  7 04:17:44 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 6 Dec 2007 19:17:44 -0800 (PST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
Message-ID: <14206100.post@talk.nabble.com>




Gabor Grothendieck wrote:
> 
> The closure only works if you are defining the inner function yourself.
> If you are not then its yet more work to redefine the environment of
> the inner function or other workaround.
> 
> On Dec 6, 2007 6:01 PM, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> Spencer Graves wrote:
>> > Hello:
>> >
>> >       I wish to again express my appreciation to all who have
>> > contributed to making R what it is today.
>> >
>> >       At this moment, I'm particularly grateful for whoever modified
>> the
>> > 'mle' code so data no longer need be passed via global variables.  I
>> > remember struggling with this a couple of years ago, and I only today
>> > discovered that it is no longer the case.
>> >
>> >       I'd like to suggest that the 'mle' help file be modified to
>> > advertise this fact, e.g., by adding one of the two examples appearing
>> > below.
>> >
>>
>> In a word: No!!! That is not the design. A likelihood function is a
>> function of its parameters, and the "fixed" argument is for holding some
>> parameters fixed (e.g. during profiling).
>>
>> To include data, just make a closure, e.g.
>>
>> poissonLike <- function(x., y.){
>>    function(ymax=15, xhalf=6)
>>      -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))}
>> mll <-  poissonLike(x, y)
>> mle(ll, ....
>>
>>
>> >       Best Wishes,
>> >       Spencer Graves
>> > ################################
>> > x <- 0:10
>> > y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
>> > #  Pass data via function arguments rather than global variables
>> > ll.5 <- function(ymax=15, xhalf=6, x., y.)
>> >          -sum(stats::dpois(y., lambda=ymax/(1+x./xhalf), log=TRUE))
>> > (fit.5 <- mle(ll.5, start=list(ymax=15, xhalf=6),
>> >               fixed=list(x.=x, y.=y)))
>> >
>> > ll3 <- function(lymax=log(15), lxhalf=log(6), x., y.)
>> >   -sum(stats::dpois(y.,
>> >          lambda=exp(lymax)/(1+x./exp(lxhalf)), log=TRUE))
>> > (fit3 <- mle(ll3, start=list(lymax=0, lxhalf=0),
>> >              fixed=list(x.=x, y.=y)))
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>> --
>>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
>> 35327907
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

  At this point I'd just like to advertise the "bbmle" package
(on CRAN) for those who respectfully disagree, as I do, with Peter over
this issue.  I have added a data= argument to my version
of the function that allows other variables to be passed
to the objective function.  It seems to me that this is perfectly
in line with the way that other modeling functions in R
behave.

  (My version also has a cool formula interface and other
bells and whistles, and I would love to get feedback from other
useRs about it.)

   cheers
    Ben Bolker

-- 
View this message in context: http://www.nabble.com/suggested-modification-to-the-%27mle%27-documentation--tf4957508.html#a14206100
Sent from the R devel mailing list archive at Nabble.com.


From edd at debian.org  Fri Dec  7 04:20:08 2007
From: edd at debian.org (edd at debian.org)
Date: Fri,  7 Dec 2007 04:20:08 +0100 (CET)
Subject: [Rd] Bug#454678: r-base-core: Crash when calling edit.matrix
	with edit.row.names = TRUE when there are no rownames (PR#10500)
Message-ID: <20071207032008.CC49B283416B@mail.pubhealth.ku.dk>


Ben,

Thanks for the bug report. I am off two minds about it as discussed below.
But as it does indeed create a crash / segfault, I am passing this on to the
R bug tracker.  A suggested two-line patch is below; I tested the patch
against a 'vanilla' 2.6.1 source tree.

On 6 December 2007 at 19:32, Ben Goodrich wrote:
| -----BEGIN PGP SIGNED MESSAGE-----
| Hash: SHA1
| 
| Package: r-base-core
| Version: 2.6.1-1
| Severity: important
| 
| Hi Dirk,
| 
| My strong hunch is that this bug should just be forwarded upstream but
| it might have something to do with libc6 on Debian. To reproduce it, do
| 
| args(utils:::edit.matrix)
| mat <- matrix(rnorm(30), nrow = 10, ncol = 3)
| edit(mat, edit.row.names = TRUE) #crash

I can confirm that it crashes 2.6.0 and 2.6.1.  I also spent the last little
while building a (non-stripped) debug version that reveals:

(gdb) where
#0  0xb7b2ef2c in __gconv_transform_utf8_internal () from /lib/i686/cmov/libc.so.6
#1  0xb7b89f75 in mbrtowc () from /lib/i686/cmov/libc.so.6
#2  0xb7db05e3 in Rstrwid (str=0x8052010 "\020!\005\b\002", slen=134595712,
    quote=0) at printutils.c:284
#3  0xb7db0888 in Rstrlen (s=0x8051ff8, quote=0) at printutils.c:377
#4  0xb7d2de24 in Rf_formatString (x=0x873bbb8, n=1, fieldwidth=0xbfd0fc04,
    quote=0) at format.c:62
#5  0xb7db12b5 in Rf_EncodeElement (x=0x873ba10, indx=100, quote=0, dec=46 '.')
    at printutils.c:576
#6  0xb754ae0d in get_col_width (DE=0xbfd100b0, col=1) at dataentry.c:804
#7  0xb754edb4 in initwin (DE=0xbfd100b0, title=0xb755eed9 "R Data Editor")
    at dataentry.c:1986
#8  0xb7549319 in RX11_dataentry (call=0x89b3fe8, op=0x806c970, args=0x8ba40c8,
    rho=0x89b4bd0) at dataentry.c:382
#9  0xb7e52771 in do_dataentry (call=0x89b3fe8, op=0x806c970, args=0x8ba40c8,
    rho=0x89b4bd0) at X11.c:91
#10 0xb7d6045e in do_internal (call=0x89b4020, op=0x8061fa4, args=0x8ba40c8,
    env=0x89b4bd0) at names.c:1120
#11 0xb7d1f352 in Rf_eval (e=0x89b4020, rho=0x89b4bd0) at eval.c:463
#12 0xb7d21d5d in do_set (call=0x89b4074, op=0x8060df0, args=0x89b4058,
    rho=0x89b4bd0) at eval.c:1407
#13 0xb7d1f352 in Rf_eval (e=0x89b4074, rho=0x89b4bd0) at eval.c:463
#14 0xb7d212b4 in do_begin (call=0x89b2798, op=0x8062458, args=0x89b4090,
    rho=0x89b4bd0) at eval.c:1159
#15 0xb7d1f352 in Rf_eval (e=0x89b2798, rho=0x89b4bd0) at eval.c:463
#16 0xb7d1fb67 in Rf_applyClosure (call=0x89b1c9c, op=0x89b1ba0,
    arglist=0x89b1e24, rho=0x89b1d7c, suppliedenv=0x89b1cd4) at eval.c:669
#17 0xb7d60a32 in applyMethod (call=0x89b1c9c, op=0x89b1ba0, args=0x89b1e24,
    rho=0x89b1d7c, newrho=0x89b1cd4) at objects.c:126
#18 0xb7d61223 in Rf_usemethod (generic=0x8069af8 "edit", obj=0x8a87868,
    call=0x89b1e94, args=0x8052110, rho=0x89b1d7c, callrho=0x8073f9c,
    defrho=0x828f2fc, ans=0xbfd10d00) at objects.c:291
#19 0xb7d61776 in do_usemethod (call=0x89b1e94, op=0x80711b8, args=0x89b1e78,
    env=0x89b1d7c) at objects.c:399
#20 0xb7d1f352 in Rf_eval (e=0x89b1e94, rho=0x89b1d7c) at eval.c:463
#21 0xb7d1fb67 in Rf_applyClosure (call=0x89b2230, op=0x89b2150,
    arglist=0x89b1e24, rho=0x8073f9c, suppliedenv=0x8073fb8) at eval.c:669
#22 0xb7d1f601 in Rf_eval (e=0x89b2230, rho=0x8073f9c) at eval.c:507
#23 0xb7d4a879 in Rf_ReplIteration (rho=0x8073f9c, savestack=0, browselevel=0,
    state=0xbfd1116c) at main.c:263
#24 0xb7d4aa61 in R_ReplConsole (rho=0x8073f9c, savestack=0, browselevel=0)
    at main.c:312
#25 0xb7d4bec7 in run_Rmainloop () at main.c:975
#26 0xb7d4beee in Rf_mainloop () at main.c:982
#27 0x08048733 in main (ac=0, av=0x0) at Rmain.c:35
#28 0xb7b27450 in __libc_start_main () from /lib/i686/cmov/libc.so.6
#29 0x08048691 in _start ()
(gdb) up

Now, two comments.  

Firstly, we all prefer if R would not crash.  So this may need some fixing.

Secondly, I think you are rather close to bordering on user error.  As your
snippet shows, you need to invoke args on the non-exported edit.matrix to
learn about the edit.row.names argument. Moreover, you also know full well
from looking at this that this will only be true when there actually are
names set --- and you then proceed to call it when there are none.  Guess
what:  it blows up. 

So we could fix this in a number of places.  Here is one which I tested; R
Core may opt to apply this, or a better version, or to drop the issue:

edd at ron:~/src/debian/R> diff -u R-2.6.1/src/library/utils/R/edit.R{.orig,}
--- R-2.6.1/src/library/utils/R/edit.R.orig     2007-09-04 17:12:32.000000000 -0500
+++ R-2.6.1/src/library/utils/R/edit.R  2007-12-06 21:12:32.000000000 -0600
@@ -166,6 +166,8 @@
     else names(datalist) <- paste("col", 1:ncol(name), sep = "")
     modes <- as.list(rep.int(mode(name), ncol(name)))
     if (edit.row.names) {
+        if (is.null(dn[[1]])) ## true if forced edit.row.names as TRUE on null
+            dn[[1]] <- paste("row", 1:dim(name)[1], sep="")
         datalist <- c(list(row.names = dn[[1]]), datalist)
         modes <- c(list(row.names = "character"), modes)
     }


This results in:
> mat <- matrix(rnorm(30), nrow = 10, ncol = 3); edit(mat, edit.row.names = TRUE)
            col1        col2        col3
row1   0.6185206  0.32911907 -0.12263839
row2   0.4553981 -1.77532265  2.06745757
row3   0.4676557  0.58817426 -0.30507048
row4   1.1898153 -1.24888167  1.02240513
row5  -1.4809138  0.05212133  0.25272844
row6   1.5709981 -1.87496256 -0.05699266
row7   0.3770318 -0.43538598 -1.28299648
row8   1.3900096  0.15139637 -1.01168270
row9  -0.3973376  0.05933193  0.34420058
row10 -1.4248380  0.86637712 -1.25193470
> q()

when the matrix is simply saved from the editor -- ie no segfault.

Hope this helps, and best regards,  Dirk
 

| The only other version of R I can get my hands on at the moment (2.5.1,
| not Debian) does not crash but throws an uninformative error. This crash
| also occurs when calling fix(), which calls edit(). It does not occur if
| the matrix being edited has rownames already. A little gdb output is
| pasted below. -- Thanks, Ben
| 
| R version 2.6.1 (2007-11-26)
| Copyright (C) 2007 The R Foundation for Statistical Computing
| ISBN 3-900051-07-0
| 
| R is free software and comes with ABSOLUTELY NO WARRANTY.
| You are welcome to redistribute it under certain conditions.
| Type 'license()' or 'licence()' for distribution details.
| 
| (no debugging symbols found)
| (no debugging symbols found)
|   Natural language support but running in an English locale
| 
| R is a collaborative project with many contributors.
| Type 'contributors()' for more information and
| 'citation()' on how to cite R or R packages in publications.
| 
| Type 'demo()' for some demos, 'help()' for on-line help, or
| 'help.start()' for an HTML browser interface to help.
| Type 'q()' to quit R.
| 
| (no debugging symbols found)
| (no debugging symbols found)
| > mat <- matrix(rnorm(30), nrow = 10, ncol = 3)
| > edit(mat, edit.row.names = TRUE)
| (no debugging symbols found)
| - ---Type <return> to continue, or q <return> to quit---
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| (no debugging symbols found)
| 
| Program received signal SIGSEGV, Segmentation fault.
| 0xb7b48f2c in __gconv_transform_utf8_internal () from
| /lib/i686/cmov/libc.so.6
| 
| 
| - -- System Information:
| Debian Release: lenny/sid
|   APT prefers unstable
|   APT policy: (500, 'unstable')
| Architecture: i386 (i686)
| 
| Kernel: Linux 2.6.23.9-slh-smp-1 (SMP w/1 CPU core; PREEMPT)
| Locale: LANG=en_US.UTF-8, LC_CTYPE=en_US.UTF-8 (charmap=UTF-8)
| Shell: /bin/sh linked to /bin/bash
| 
| Versions of packages r-base-core depends on:
| ii  libbz2-1.0              1.0.3-7          high-quality block-sorting
| file co
| ii  libc6                   2.7-3            GNU C Library: Shared libraries
| ii  libgcc1                 1:4.2.2-4        GCC support library
| ii  libgfortran2            4.2.2-4          Runtime library for GNU
| Fortran ap
| ii  libice6                 2:1.0.4-1        X11 Inter-Client Exchange
| library
| ii  libjpeg62               6b-14            The Independent JPEG
| Group's JPEG
| ii  libpaper-utils          1.1.23           library for handling paper
| charact
| ii  libpcre3                7.3-2            Perl 5 Compatible Regular
| Expressi
| ii  libpng12-0              1.2.15~beta5-3   PNG library - runtime
| ii  libreadline5            5.2-3            GNU readline and history
| libraries
| ii  libsm6                  2:1.0.3-1+b1     X11 Session Management library
| ii  libx11-6                2:1.0.3-7        X11 client-side library
| ii  libxt6                  1:1.0.5-3        X11 toolkit intrinsics library
| ii  perl                    5.8.8-12         Larry Wall's Practical
| Extraction
| ii  refblas3 [libblas.so.3] 1.2-8            Basic Linear Algebra
| Subroutines 3
| ii  tcl8.4                  8.4.16-4         Tcl (the Tool Command
| Language) v8
| ii  tk8.4                   8.4.16-2         Tk toolkit for Tcl and X11,
| v8.4 -
| ii  unzip                   5.52-10          De-archiver for .zip files
| ii  zip                     2.32-1           Archiver for .zip files
| ii  zlib1g                  1:1.2.3.3.dfsg-7 compression library - runtime
| 
| Versions of packages r-base-core recommends:
| ii  r-base-dev                    2.6.1-1    GNU R installation of
| auxiliary GN
| ii  r-recommended                 2.6.1-1    GNU R collection of
| recommended pa
| 
| - -- no debconf information
| -----BEGIN PGP SIGNATURE-----
| Version: GnuPG v1.4.6 (GNU/Linux)
| 
| iD8DBQFHWJSEzQDSXIcN85kRAo3+AJwJPOkxyJJrmbziYt98lP3tFXsmnQCdHRUg
| sQvIJfAZ6cuGifDdBqKjF7c=
| =+k7N
| -----END PGP SIGNATURE-----
| 
| 

-- 
Three out of two people have difficulties with fractions.


From hb at stat.berkeley.edu  Fri Dec  7 06:08:40 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 6 Dec 2007 21:08:40 -0800
Subject: [Rd] Defaults for postscript()
In-Reply-To: <1196958126.2955.19.camel@Bellerophon.localdomain>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
	<eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
	<1196958126.2955.19.camel@Bellerophon.localdomain>
Message-ID: <59d7961d0712062108k1f2daff4yca96fb6dab8d5a84@mail.gmail.com>

On 06/12/2007, Marc Schwartz <marc_schwartz at comcast.net> wrote:
>
> On Thu, 2007-12-06 at 00:32 -0800, Deepayan Sarkar wrote:
> > On 12/6/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > > The defaults for postscript()
> > >
> > > paper = "default"
> > > onefile = TRUE
> > > horizontal = TRUE
> > >
> > > (it seems) date from the days when people used to used this to send plots
> > > directly to a postscript printer via print.it=TRUE.  I haven't done that
> > > for years, and it seems that our current generation of students don't even
> > > know the concept.  It seems 'horizontal = TRUE' is particularly difficult
> > > to grasp.
> > >
> > > Given that I suspect almost all uses of postscript() are to produce plots
> > > to be viewed on-screen or incorporated into another document, a more
> > > appropriate set of defaults would be
> > >
> > > width = 7, height = 7
> > > paper = "special"
> > > onefile = FALSE
> > > horizontal = FALSE
> > >
> > > which would have the advantage of using the same default aspect ratio for
> > > plots as all (?) other R graphics devices.
> > >
> > > Does anyone see a reason not to change the defaults?
> >
> > I'm not so sure about the 'onefile' change. Scripts with multiple
> > plots run in batch mode will end up with multiple files; I prefer the
> > current behaviour. I also have test scripts in packages that go
> >
> >
> > postscript("something.ps")
> > <many examples>
> > dev.off()
> >
> >
> > Unless I change all these to have onefile=TRUE, I'll end up only with
> > the last plot available after the tests are run.
> >
> > -Deepayan
>
> In a vacuum, I would agree that changing the default values makes sense
> given the preponderance of the use for postscript() for creating EPS
> files for use in LaTeX and other documents (eg. Office/OO.org). It might
> also serve to reduce the frequency of questions on the lists on this
> subject.
>
> That being said, I understand Deepayan's concern.
>
> I don't have a sense of how many others would be affected by such a
> change.
>
> Pending any other comments on the matter, an incremental approach might
> include an initial near term restructuring of the help file for
> postscript(), whereby the following content in the Details section:
>
>
> The postscript produced for a single R plot is EPS (Encapsulated
> PostScript) compatible, and can be included into other documents, e.g.,
> into LaTeX, using \includegraphics{<filename>}. For use in this way you
> will probably want to set horizontal = FALSE, onefile = FALSE, paper =
> "special". Note that the bounding box is for the device region: if you
> find the white space around the plot region excessive, reduce the
> margins of the figure region via par(mar=).

I would like to suggest the following wrapper:

eps <- function(file="Rplot%03d.eps", horizontal=FALSE, paper="special", ...) {
  postscript(file=file, onefile=FALSE, horizontal=horizontal, paper=paper, ...);
}

That separates the use case of creating EPS files and "regular"
postscript files allow each of eps() and postscript() to have their
own default values.

/Henrik

>
>
> is moved to a new Notes section, which could precede the Details
> section, given the likely nature of such use. This change could be done
> now for R-patched and R-devel.
>
> A separate second comment could be added to the Notes section,
> indicating that the defaults will change to those above in version
> 2.8.0. The longer time frame would give affected package maintainers a
> heads up of the pending change and more lead time for implementation of
> any changes.
>
> HTH,
>
> Marc
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From xjqian at gmail.com  Fri Dec  7 06:41:06 2007
From: xjqian at gmail.com (Junqian Gordon Xu)
Date: Thu, 06 Dec 2007 23:41:06 -0600
Subject: [Rd]  Cross Compiling for ARM
In-Reply-To: <59d7961d0712062108k1f2daff4yca96fb6dab8d5a84@mail.gmail.com>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>	<eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>	<1196958126.2955.19.camel@Bellerophon.localdomain>
	<59d7961d0712062108k1f2daff4yca96fb6dab8d5a84@mail.gmail.com>
Message-ID: <4758DCF2.3050308@gmail.com>

I am trying to cross compile R-2.6.0 for ARM. I have my cross compiling 
tool chain set up already.

I've read the cross compiling guide for WIN
# http://cran.r-project.org/doc/contrib/cross-build.pdf
# http://cran.r-project.org/doc/contrib/Makefile-rcb

Following the same approach, I compiled the native R-2.6.0 version 
first. Then passed R=R-2.6.0 to ./configure. After that, I hacked 
makefiles to set R_EXE to the native R binary.

I was able to compile through until R packages in /src/library, where 
the following command was issued

$R_EXE --vanilla --slave -f /src/library/base/makebasedb.R

| Error in eval(expr, envir, enclos) :
| may already be using lazy loading on base
| Calls: local -> eval.parent -> eval -> eval -> eval -> eval
| Execution halted

Seems the error was caused by lazy loading mechanism of the native R 
binary on the host. AFAIK --vanilla should suppress loading any package 
upon startup, however, seems there is no way to get around lazy loading.

My questions are why cross compiling for WIN don't hit this error (maybe 
some special setting I'm not aware of was set in the makefile for WIN). 
Second, how could I get around this lazy loading issue, if my approach 
is not completely off?

Thanks
Gordon


From ripley at stats.ox.ac.uk  Fri Dec  7 09:25:13 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri,  7 Dec 2007 09:25:13 +0100 (CET)
Subject: [Rd] (PR#10500) Bug#454678: r-base-core: Crash when calling
Message-ID: <20071207082513.C7DA6283416B@mail.pubhealth.ku.dk>

I would say this was user error (insisting on editing non-existent 
rownames), although the argument is documented.  You could argue that 
there are implicit rownames, but they would be 1, 2 ... not row1, row2 
....  And rownames(mat) is NULL.

For an interactive function the best solution seems to be to throw an 
error when the user asks for the impossible.

I'll fix it for 2.7.0: it certainly isn't 'important' as it has gone 
undiscovered for many years, and edit.matrix is itself little used.


BTW, 1:dim(names)[1] is dangerous: it could be 1:0.  That was the 
motivation for seq_len.


On Fri, 7 Dec 2007, edd at debian.org wrote:

>
> Ben,
>
> Thanks for the bug report. I am off two minds about it as discussed below.
> But as it does indeed create a crash / segfault, I am passing this on to the
> R bug tracker.  A suggested two-line patch is below; I tested the patch
> against a 'vanilla' 2.6.1 source tree.
>
> On 6 December 2007 at 19:32, Ben Goodrich wrote:
> | -----BEGIN PGP SIGNED MESSAGE-----
> | Hash: SHA1
> |
> | Package: r-base-core
> | Version: 2.6.1-1
> | Severity: important
> |
> | Hi Dirk,
> |
> | My strong hunch is that this bug should just be forwarded upstream but
> | it might have something to do with libc6 on Debian. To reproduce it, do
> |
> | args(utils:::edit.matrix)
> | mat <- matrix(rnorm(30), nrow = 10, ncol = 3)
> | edit(mat, edit.row.names = TRUE) #crash
>
> I can confirm that it crashes 2.6.0 and 2.6.1.  I also spent the last little
> while building a (non-stripped) debug version that reveals:
>
> (gdb) where
> #0  0xb7b2ef2c in __gconv_transform_utf8_internal () from /lib/i686/cmov/libc.so.6
> #1  0xb7b89f75 in mbrtowc () from /lib/i686/cmov/libc.so.6
> #2  0xb7db05e3 in Rstrwid (str=0x8052010 "\020!\005\b\002", slen=134595712,
>    quote=0) at printutils.c:284
> #3  0xb7db0888 in Rstrlen (s=0x8051ff8, quote=0) at printutils.c:377
> #4  0xb7d2de24 in Rf_formatString (x=0x873bbb8, n=1, fieldwidth=0xbfd0fc04,
>    quote=0) at format.c:62
> #5  0xb7db12b5 in Rf_EncodeElement (x=0x873ba10, indx=100, quote=0, dec=46 '.')
>    at printutils.c:576
> #6  0xb754ae0d in get_col_width (DE=0xbfd100b0, col=1) at dataentry.c:804
> #7  0xb754edb4 in initwin (DE=0xbfd100b0, title=0xb755eed9 "R Data Editor")
>    at dataentry.c:1986
> #8  0xb7549319 in RX11_dataentry (call=0x89b3fe8, op=0x806c970, args=0x8ba40c8,
>    rho=0x89b4bd0) at dataentry.c:382
> #9  0xb7e52771 in do_dataentry (call=0x89b3fe8, op=0x806c970, args=0x8ba40c8,
>    rho=0x89b4bd0) at X11.c:91
> #10 0xb7d6045e in do_internal (call=0x89b4020, op=0x8061fa4, args=0x8ba40c8,
>    env=0x89b4bd0) at names.c:1120
> #11 0xb7d1f352 in Rf_eval (e=0x89b4020, rho=0x89b4bd0) at eval.c:463
> #12 0xb7d21d5d in do_set (call=0x89b4074, op=0x8060df0, args=0x89b4058,
>    rho=0x89b4bd0) at eval.c:1407
> #13 0xb7d1f352 in Rf_eval (e=0x89b4074, rho=0x89b4bd0) at eval.c:463
> #14 0xb7d212b4 in do_begin (call=0x89b2798, op=0x8062458, args=0x89b4090,
>    rho=0x89b4bd0) at eval.c:1159
> #15 0xb7d1f352 in Rf_eval (e=0x89b2798, rho=0x89b4bd0) at eval.c:463
> #16 0xb7d1fb67 in Rf_applyClosure (call=0x89b1c9c, op=0x89b1ba0,
>    arglist=0x89b1e24, rho=0x89b1d7c, suppliedenv=0x89b1cd4) at eval.c:669
> #17 0xb7d60a32 in applyMethod (call=0x89b1c9c, op=0x89b1ba0, args=0x89b1e24,
>    rho=0x89b1d7c, newrho=0x89b1cd4) at objects.c:126
> #18 0xb7d61223 in Rf_usemethod (generic=0x8069af8 "edit", obj=0x8a87868,
>    call=0x89b1e94, args=0x8052110, rho=0x89b1d7c, callrho=0x8073f9c,
>    defrho=0x828f2fc, ans=0xbfd10d00) at objects.c:291
> #19 0xb7d61776 in do_usemethod (call=0x89b1e94, op=0x80711b8, args=0x89b1e78,
>    env=0x89b1d7c) at objects.c:399
> #20 0xb7d1f352 in Rf_eval (e=0x89b1e94, rho=0x89b1d7c) at eval.c:463
> #21 0xb7d1fb67 in Rf_applyClosure (call=0x89b2230, op=0x89b2150,
>    arglist=0x89b1e24, rho=0x8073f9c, suppliedenv=0x8073fb8) at eval.c:669
> #22 0xb7d1f601 in Rf_eval (e=0x89b2230, rho=0x8073f9c) at eval.c:507
> #23 0xb7d4a879 in Rf_ReplIteration (rho=0x8073f9c, savestack=0, browselevel=0,
>    state=0xbfd1116c) at main.c:263
> #24 0xb7d4aa61 in R_ReplConsole (rho=0x8073f9c, savestack=0, browselevel=0)
>    at main.c:312
> #25 0xb7d4bec7 in run_Rmainloop () at main.c:975
> #26 0xb7d4beee in Rf_mainloop () at main.c:982
> #27 0x08048733 in main (ac=0, av=0x0) at Rmain.c:35
> #28 0xb7b27450 in __libc_start_main () from /lib/i686/cmov/libc.so.6
> #29 0x08048691 in _start ()
> (gdb) up
>
> Now, two comments.
>
> Firstly, we all prefer if R would not crash.  So this may need some fixing.
>
> Secondly, I think you are rather close to bordering on user error.  As your
> snippet shows, you need to invoke args on the non-exported edit.matrix to
> learn about the edit.row.names argument. Moreover, you also know full well
> from looking at this that this will only be true when there actually are
> names set --- and you then proceed to call it when there are none.  Guess
> what:  it blows up.
>
> So we could fix this in a number of places.  Here is one which I tested; R
> Core may opt to apply this, or a better version, or to drop the issue:
>
> edd at ron:~/src/debian/R> diff -u R-2.6.1/src/library/utils/R/edit.R{.orig,}
> --- R-2.6.1/src/library/utils/R/edit.R.orig     2007-09-04 17:12:32.000000000 -0500
> +++ R-2.6.1/src/library/utils/R/edit.R  2007-12-06 21:12:32.000000000 -0600
> @@ -166,6 +166,8 @@
>     else names(datalist) <- paste("col", 1:ncol(name), sep = "")
>     modes <- as.list(rep.int(mode(name), ncol(name)))
>     if (edit.row.names) {
> +        if (is.null(dn[[1]])) ## true if forced edit.row.names as TRUE on null
> +            dn[[1]] <- paste("row", 1:dim(name)[1], sep="")
>         datalist <- c(list(row.names = dn[[1]]), datalist)
>         modes <- c(list(row.names = "character"), modes)
>     }
>
>
> This results in:
>> mat <- matrix(rnorm(30), nrow = 10, ncol = 3); edit(mat, edit.row.names = TRUE)
>            col1        col2        col3
> row1   0.6185206  0.32911907 -0.12263839
> row2   0.4553981 -1.77532265  2.06745757
> row3   0.4676557  0.58817426 -0.30507048
> row4   1.1898153 -1.24888167  1.02240513
> row5  -1.4809138  0.05212133  0.25272844
> row6   1.5709981 -1.87496256 -0.05699266
> row7   0.3770318 -0.43538598 -1.28299648
> row8   1.3900096  0.15139637 -1.01168270
> row9  -0.3973376  0.05933193  0.34420058
> row10 -1.4248380  0.86637712 -1.25193470
>> q()
>
> when the matrix is simply saved from the editor -- ie no segfault.
>
> Hope this helps, and best regards,  Dirk
>
>
> | The only other version of R I can get my hands on at the moment (2.5.1,
> | not Debian) does not crash but throws an uninformative error. This crash
> | also occurs when calling fix(), which calls edit(). It does not occur if
> | the matrix being edited has rownames already. A little gdb output is
> | pasted below. -- Thanks, Ben
> |
> | R version 2.6.1 (2007-11-26)
> | Copyright (C) 2007 The R Foundation for Statistical Computing
> | ISBN 3-900051-07-0
> |
> | R is free software and comes with ABSOLUTELY NO WARRANTY.
> | You are welcome to redistribute it under certain conditions.
> | Type 'license()' or 'licence()' for distribution details.
> |
> | (no debugging symbols found)
> | (no debugging symbols found)
> |   Natural language support but running in an English locale
> |
> | R is a collaborative project with many contributors.
> | Type 'contributors()' for more information and
> | 'citation()' on how to cite R or R packages in publications.
> |
> | Type 'demo()' for some demos, 'help()' for on-line help, or
> | 'help.start()' for an HTML browser interface to help.
> | Type 'q()' to quit R.
> |
> | (no debugging symbols found)
> | (no debugging symbols found)
> | > mat <- matrix(rnorm(30), nrow = 10, ncol = 3)
> | > edit(mat, edit.row.names = TRUE)
> | (no debugging symbols found)
> | - ---Type <return> to continue, or q <return> to quit---
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> | (no debugging symbols found)
> |
> | Program received signal SIGSEGV, Segmentation fault.
> | 0xb7b48f2c in __gconv_transform_utf8_internal () from
> | /lib/i686/cmov/libc.so.6
> |
> |
> | - -- System Information:
> | Debian Release: lenny/sid
> |   APT prefers unstable
> |   APT policy: (500, 'unstable')
> | Architecture: i386 (i686)
> |
> | Kernel: Linux 2.6.23.9-slh-smp-1 (SMP w/1 CPU core; PREEMPT)
> | Locale: LANG=en_US.UTF-8, LC_CTYPE=en_US.UTF-8 (charmap=UTF-8)
> | Shell: /bin/sh linked to /bin/bash
> |
> | Versions of packages r-base-core depends on:
> | ii  libbz2-1.0              1.0.3-7          high-quality block-sorting
> | file co
> | ii  libc6                   2.7-3            GNU C Library: Shared libraries
> | ii  libgcc1                 1:4.2.2-4        GCC support library
> | ii  libgfortran2            4.2.2-4          Runtime library for GNU
> | Fortran ap
> | ii  libice6                 2:1.0.4-1        X11 Inter-Client Exchange
> | library
> | ii  libjpeg62               6b-14            The Independent JPEG
> | Group's JPEG
> | ii  libpaper-utils          1.1.23           library for handling paper
> | charact
> | ii  libpcre3                7.3-2            Perl 5 Compatible Regular
> | Expressi
> | ii  libpng12-0              1.2.15~beta5-3   PNG library - runtime
> | ii  libreadline5            5.2-3            GNU readline and history
> | libraries
> | ii  libsm6                  2:1.0.3-1+b1     X11 Session Management library
> | ii  libx11-6                2:1.0.3-7        X11 client-side library
> | ii  libxt6                  1:1.0.5-3        X11 toolkit intrinsics library
> | ii  perl                    5.8.8-12         Larry Wall's Practical
> | Extraction
> | ii  refblas3 [libblas.so.3] 1.2-8            Basic Linear Algebra
> | Subroutines 3
> | ii  tcl8.4                  8.4.16-4         Tcl (the Tool Command
> | Language) v8
> | ii  tk8.4                   8.4.16-2         Tk toolkit for Tcl and X11,
> | v8.4 -
> | ii  unzip                   5.52-10          De-archiver for .zip files
> | ii  zip                     2.32-1           Archiver for .zip files
> | ii  zlib1g                  1:1.2.3.3.dfsg-7 compression library - runtime
> |
> | Versions of packages r-base-core recommends:
> | ii  r-base-dev                    2.6.1-1    GNU R installation of
> | auxiliary GN
> | ii  r-recommended                 2.6.1-1    GNU R collection of
> | recommended pa
> |
> | - -- no debconf information
> | -----BEGIN PGP SIGNATURE-----
> | Version: GnuPG v1.4.6 (GNU/Linux)
> |
> | iD8DBQFHWJSEzQDSXIcN85kRAo3+AJwJPOkxyJJrmbziYt98lP3tFXsmnQCdHRUg
> | sQvIJfAZ6cuGifDdBqKjF7c=
> | =+k7N
> | -----END PGP SIGNATURE-----
> |
> |
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Fri Dec  7 14:10:22 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 07 Dec 2007 14:10:22 +0100
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <14206100.post@talk.nabble.com>
References: <4758338E.3080802@pdf.com>
	<47587F30.6020701@biostat.ku.dk>	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com>
Message-ID: <4759463E.3010904@biostat.ku.dk>

Ben Bolker wrote:
>   At this point I'd just like to advertise the "bbmle" package
> (on CRAN) for those who respectfully disagree, as I do, with Peter over
> this issue.  I have added a data= argument to my version
> of the function that allows other variables to be passed
> to the objective function.  It seems to me that this is perfectly
> in line with the way that other modeling functions in R
> behave.
>   
This is at least cleaner than abusing the "fixed" argument. As you know,
I have reservations, one of which is that it is not a given that I want
it to behave just like other modeling functions, e.g. a likelihood
function might refer to more than one data set, and/or data that are not
structured in the traditional data frame format. The design needs more
thought than just adding arguments.

I still prefer a design based a plain likelihood function. Then we can
discuss how to construct such a function so that  the data are
incorporated in a flexible way.  There are many ways to do this, I've
shown one, here's another:

> f <- function(lambda) -sum(dpois(x, lambda, log=T))
> d <- data.frame(x=rpois(10000, 12.34))
> environment(f)<-evalq(environment(),d)
> mle(f, start=list(lambda=10))

Call:
mle(minuslogl = f, start = list(lambda = 10))

Coefficients:
 lambda
12.3402

It is not at all an unlikely design to have mle() as a generic function
which works on many kinds of objects, the default method being
function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
function returning (tada!) the negative log likelihood function.
>   (My version also has a cool formula interface and other
> bells and whistles, and I would love to get feedback from other
> useRs about it.)
>
>    cheers
>     Ben Bolker
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From a.robotham at bristol.ac.uk  Fri Dec  7 10:54:18 2007
From: a.robotham at bristol.ac.uk (Aaron Robotham)
Date: Fri, 7 Dec 2007 09:54:18 +0000
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
In-Reply-To: <1497CFD2-F77D-45D6-A68B-AAFD7CB27CBB@r-project.org>
References: <20071205161009.737972834620@mail.pubhealth.ku.dk>
	<4757143F.9060902@biostat.ku.dk>
	<debf56250712060626u540deea0w32f0b919b3cbfa95@mail.gmail.com>
	<1497CFD2-F77D-45D6-A68B-AAFD7CB27CBB@r-project.org>
Message-ID: <debf56250712070154wad6bf93n6d4c3e9d03d4fb@mail.gmail.com>

The machine in question is a black MacBook, a pretty standard setup
with the rest of the details as listed in my first post (R 2.6.1 OSX
10.4.11). I'll give the back trace a try and let you know the result.

On 06/12/2007, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Dec 6, 2007, at 9:26 AM, Aaron Robotham wrote:
>
> > I know of gdb but I'm not certain how to use it with Mac OS X's
> > R.app, do you just do something like "gdb open R.app" in the
> > terminal?.
> >
>
> You can attach it once it's running - just type "attach R" in gdb
> while R is runningm then "c", then let it crash and then "bt".
>
> FWIW: I cannot reproduce the problem and I have tried 3 different
> machines... (you didn't even tell us what machine type this is ...).
>
> Cheers,
> Simon
>
>
> > Interestingly I don't get this crash when I launch the X11 version of
> > R through the terminal, so this would suggest the bug in question is
> > to do with the actual Rgui in R.app. Hopefully this information might
> > help to narrow down the problem. Any advice for using gdb on R.app
> > would be appreciated, I couldn't find much in the way of guidance when
> > searching online.
> >
> > thanks
> >
> > Aaron
> >
> > On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> >> a.robotham at bris.ac.uk wrote:
> >>> Hello,
> >>> I've recently discovered a persistent issue with rpanel when running
> >>> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
> >>> apparent error, and the interactive panels appear to work as
> >>> expected,
> >>> however upon closing the panels rpanel has created I get
> >>> catastrophic
> >>> errors and R crashes completely. For the most part R manages to
> >>> crash
> >>> with dignity and work can be saved, but sometimes it will crash
> >>> straight out. Below is an example of an entire work session (only
> >>> base
> >>> packages loaded) with the crash at the end typical of those
> >>> encountered:
> >>>
> >>>
> >>>> library(tcltk)
> >>>>
> >>> Loading Tcl/Tk interface ... done
> >>>
> >>>> library(rpanel)
> >>>>
> >>> Package `rpanel', version 1.0-4
> >>> type help(rpanel) for summary information
> >>>
> >>>> density.draw <- function(panel) {
> >>>>
> >>> +   plot(density(panel$x, bw = panel$h))
> >>> +   panel
> >>> + }
> >>>
> >>>> panel <- rp.control(x = rnorm(50))
> >>>> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)
> >>>>
> >>>
> >>> *** caught bus error ***
> >>> address 0x0, cause 'non-existent physical address'
> >>>
> >>> Possible actions:
> >>> 1: abort (with core dump, if enabled)
> >>> 2: normal R exit
> >>> 3: exit R without saving workspace
> >>> 4: exit R saving workspace
> >>>
> >>> All packages that are required are up to date, and I can find no
> >>> evidence of similar issues from searching the mailing lists. Any
> >>> suggestions would be appreciated.
> >>>
> >>>
> >> Can you run this under gdb? A breakpoint in the error handler and a
> >> backtrace could be valuable.
> >>
> >>> Aaron
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >>
> >> --
> >>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> >> 35327918
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> >> 35327907
> >>
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
>
>


From ggrothendieck at gmail.com  Fri Dec  7 14:32:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Dec 2007 08:32:26 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4759463E.3010904@biostat.ku.dk>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
Message-ID: <971536df0712070532hb528e80oa04a60534a3e615b@mail.gmail.com>

On Dec 7, 2007 8:10 AM, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
> Ben Bolker wrote:
> >   At this point I'd just like to advertise the "bbmle" package
> > (on CRAN) for those who respectfully disagree, as I do, with Peter over
> > this issue.  I have added a data= argument to my version
> > of the function that allows other variables to be passed
> > to the objective function.  It seems to me that this is perfectly
> > in line with the way that other modeling functions in R
> > behave.
> >
> This is at least cleaner than abusing the "fixed" argument. As you know,
> I have reservations, one of which is that it is not a given that I want
> it to behave just like other modeling functions, e.g. a likelihood
> function might refer to more than one data set, and/or data that are not
> structured in the traditional data frame format. The design needs more
> thought than just adding arguments.
>
> I still prefer a design based a plain likelihood function. Then we can
> discuss how to construct such a function so that  the data are
> incorporated in a flexible way.  There are many ways to do this, I've
> shown one, here's another:
>
> > f <- function(lambda) -sum(dpois(x, lambda, log=T))
> > d <- data.frame(x=rpois(10000, 12.34))
> > environment(f)<-evalq(environment(),d)
> > mle(f, start=list(lambda=10))
>
> Call:
> mle(minuslogl = f, start = list(lambda = 10))
>
> Coefficients:
>  lambda
> 12.3402
>

The explicit environment manipulation is what I was referring to but
we can simplify it using proto.  Create a proto object to hold
f and x then pass the f in the proto object (rather than the
original f) to mle.  That works because proto automatically resets
the environment of f when its added to avoiding the evalq.

> set.seed(1)
> library(proto)
> f <- function(lambda) -sum(dpois(x, lambda, log=TRUE))
> p <- proto(f = f, x = rpois(100, 12.34))
> mle(p[["f"]], start = list(lambda = 10))

Call:
mle(minuslogl = p[["f"]], start = list(lambda = 10))

Coefficients:
  lambda
12.46000

> It is not at all an unlikely design to have mle() as a generic function
> which works on many kinds of objects, the default method being
> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
> function returning (tada!) the negative log likelihood function.
> >   (My version also has a cool formula interface and other
> > bells and whistles, and I would love to get feedback from other
> > useRs about it.)
> >
> >    cheers
> >     Ben Bolker
> >
> >
>
>
> --
>
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Fri Dec  7 14:43:06 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Dec 2007 08:43:06 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4759463E.3010904@biostat.ku.dk>
References: <4758338E.3080802@pdf.com>	<47587F30.6020701@biostat.ku.dk>	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>	<14206100.post@talk.nabble.com>
	<4759463E.3010904@biostat.ku.dk>
Message-ID: <47594DEA.8080100@stats.uwo.ca>

On 12/7/2007 8:10 AM, Peter Dalgaard wrote:
> Ben Bolker wrote:
>>   At this point I'd just like to advertise the "bbmle" package
>> (on CRAN) for those who respectfully disagree, as I do, with Peter over
>> this issue.  I have added a data= argument to my version
>> of the function that allows other variables to be passed
>> to the objective function.  It seems to me that this is perfectly
>> in line with the way that other modeling functions in R
>> behave.
>>   
> This is at least cleaner than abusing the "fixed" argument. As you know,
> I have reservations, one of which is that it is not a given that I want
> it to behave just like other modeling functions, e.g. a likelihood
> function might refer to more than one data set, and/or data that are not
> structured in the traditional data frame format. The design needs more
> thought than just adding arguments.

We should allow more general things to be passed as data arguments in 
cases where it makes sense.  For example a list with names or an 
environment would be a reasonable way to pass data that doesn't fit into 
a data frame.

> I still prefer a design based a plain likelihood function. Then we can
> discuss how to construct such a function so that  the data are
> incorporated in a flexible way.  There are many ways to do this, I've
> shown one, here's another:
> 
>> f <- function(lambda) -sum(dpois(x, lambda, log=T))
>> d <- data.frame(x=rpois(10000, 12.34))
>> environment(f)<-evalq(environment(),d)

We really need to expand as.environment, so that it can convert data 
frames into environments.  You should be able to say:

environment(f) <- as.environment(d)

and get the same result as

environment(f)<-evalq(environment(),d)

But I'd prefer to avoid the necessity for users to manipulate the 
environment of a function.  I think the pattern

model( f, data=d )

being implemented internally as

environment(f) <- as.environment(d, parent = environment(f))

is very nice and general.  It makes things like cross-validation, 
bootstrapping, etc. conceptually cleaner:  keep the same 
formula/function f, but manipulate the data and see what happens.
It does have problems when d is an environment that already has a 
parent, but I think a reasonable meaning in that case would be to copy 
its contents into a new environment with the new parent set.

Duncan Murdoch


>> mle(f, start=list(lambda=10))
> 
> Call:
> mle(minuslogl = f, start = list(lambda = 10))
> 
> Coefficients:
>  lambda
> 12.3402
> 
> It is not at all an unlikely design to have mle() as a generic function
> which works on many kinds of objects, the default method being
> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
> function returning (tada!) the negative log likelihood function.
>>   (My version also has a cool formula interface and other
>> bells and whistles, and I would love to get feedback from other
>> useRs about it.)
>>
>>    cheers
>>     Ben Bolker
>>
>>   
> 
>


From ggrothendieck at gmail.com  Fri Dec  7 15:16:30 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Dec 2007 09:16:30 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <47594DEA.8080100@stats.uwo.ca>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
Message-ID: <971536df0712070616q1f3f4311m44f2bfe641273249@mail.gmail.com>

On Dec 7, 2007 8:43 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/7/2007 8:10 AM, Peter Dalgaard wrote:
> > Ben Bolker wrote:
> >>   At this point I'd just like to advertise the "bbmle" package
> >> (on CRAN) for those who respectfully disagree, as I do, with Peter over
> >> this issue.  I have added a data= argument to my version
> >> of the function that allows other variables to be passed
> >> to the objective function.  It seems to me that this is perfectly
> >> in line with the way that other modeling functions in R
> >> behave.
> >>
> > This is at least cleaner than abusing the "fixed" argument. As you know,
> > I have reservations, one of which is that it is not a given that I want
> > it to behave just like other modeling functions, e.g. a likelihood
> > function might refer to more than one data set, and/or data that are not
> > structured in the traditional data frame format. The design needs more
> > thought than just adding arguments.
>
> We should allow more general things to be passed as data arguments in
> cases where it makes sense.  For example a list with names or an
> environment would be a reasonable way to pass data that doesn't fit into
> a data frame.
>
> > I still prefer a design based a plain likelihood function. Then we can
> > discuss how to construct such a function so that  the data are
> > incorporated in a flexible way.  There are many ways to do this, I've
> > shown one, here's another:
> >
> >> f <- function(lambda) -sum(dpois(x, lambda, log=T))
> >> d <- data.frame(x=rpois(10000, 12.34))
> >> environment(f)<-evalq(environment(),d)
>
> We really need to expand as.environment, so that it can convert data
> frames into environments.  You should be able to say:
>
> environment(f) <- as.environment(d)
>
> and get the same result as
>
> environment(f)<-evalq(environment(),d)
>
> But I'd prefer to avoid the necessity for users to manipulate the
> environment of a function.  I think the pattern
>
> model( f, data=d )
>
> being implemented internally as
>
> environment(f) <- as.environment(d, parent = environment(f))
>
> is very nice and general.  It makes things like cross-validation,
> bootstrapping, etc. conceptually cleaner:  keep the same
> formula/function f, but manipulate the data and see what happens.
> It does have problems when d is an environment that already has a
> parent, but I think a reasonable meaning in that case would be to copy
> its contents into a new environment with the new parent set.
>
> Duncan Murdoch

Something close to that is already possible in proto and its cleaner in proto
since the explicit environment manipulation is unnecessary as it occurs
implicitly:

1. In terms of data frame d from Peter Dalgaard's post the code
below is similar to my last post but it replaces the explicit
manipulation of f's environemnt with the creation of proto object
p on line ###.  That line converts d to an anonymous proto object
containing the components of d, in this case just x, and then
creates a child object p which can access x via delegation/inheritance.

library(proto)
set.seed(1)
f <- function(lambda) -sum(dpois(x, lambda, log=T))
d <- data.frame(x=rpois(100, 12.34))
p <- proto(as.proto(as.list(d)), f = f) ###
mle(p[["f"]], start=list(lambda=10))

2. Or the ### line could be replaced with the following line
which places f and the components of d, in this case just x,
directly into p:

p <- proto(f = f, envir = as.proto(as.list(d)))

again avoiding the explicit reset of environment(f) and the evalq.

>
>
> >> mle(f, start=list(lambda=10))
> >
> > Call:
> > mle(minuslogl = f, start = list(lambda = 10))
> >
> > Coefficients:
> >  lambda
> > 12.3402
> >
> > It is not at all an unlikely design to have mle() as a generic function
> > which works on many kinds of objects, the default method being
> > function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
> > function returning (tada!) the negative log likelihood function.
> >>   (My version also has a cool formula interface and other
> >> bells and whistles, and I would love to get feedback from other
> >> useRs about it.)
> >>
> >>    cheers
> >>     Ben Bolker
> >>
> >>
> >
> >
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Dec  7 15:40:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Dec 2007 14:40:44 +0000 (GMT)
Subject: [Rd] [R] R CMD Build feature searches or requests
In-Reply-To: <fj8dbj$950$1@ger.gmane.org>
References: <fj8dbj$950$1@ger.gmane.org>
Message-ID: <Pine.LNX.4.64.0712060926540.19049@gannet.stats.ox.ac.uk>

This is clearly an R-devel topic, so I've moved it there.
Please re-read the descriptions of the lists in the posting guide.

On Thu, 6 Dec 2007,Johannes Graumann wrote:

> Hello,
>
> I'm missing two features in "R CMD build":
> 1) Easy building of Windows/zip packaged package version alongside the
> *nix-style *.tar.gz.
> Right now I'm doing a scripted version of
>        R CMD build <PACKAGE>
>        R CMD INSTALL <PACKAGE>
>        mkdir tmp
>        cp -r /usr/local/lib/R/site-library/<PACKAGE> tmp/<PACKAGE>
>        cd tmp
>        zip -r <PACKAGE>_<EXTRACTEDVERSION>.zip <PACKAGE>
>        mv *.zip ..
>        cd ..
>        rm -rf tmp
> I was wondering whether it wouldn't be helpfull to others maintaining
> packages not requiring genuine cross-compilation (only containing R code)
> to deal with this via an option to "R CMD build". Something
> like '-zip-package' might do it ...

But you needed to install first, which 'build' does not do by default. 
This seems a rare need that you can script for yourself.

> 2) My scripted solution right now also automatically increments version
> numbers and adjusts dates in <PACKAGE>/man/<PACKAGE>-package.Rd and
> <PACKAGE>/DESCRIPTION, ensuring progressing and continuous package naming.
> Would be nice to have an "R CMD build"-option to take care of that too ...

R CMD build adds a date when the packaging was done, but that need not be 
the date of the package.  For my packages the date is that of the last 
change, but the final packaging for distribution can be much later, at a 
time related to R release dates.  In particular, the version of the 
DESCRIPTION file in the svn archive is the master, not that distributed.

Incrementing version numbers automatically is nigh impossible: some people 
omit -0 for example, so what is the next version after 1.7?  1.8? 1.8-1? 
1.8.1?

> Please let me know what you think or where to find the functionality in case
> I overlooked it.

If you find that enough people support your wish for 1 (and so far I have 
seen no response at all), you could contribute a patch for review and 
possible inclusion in a future version of R.  But not, please, to R-help.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.hankin at noc.soton.ac.uk  Fri Dec  7 16:27:56 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 7 Dec 2007 15:27:56 +0000
Subject: [Rd] Friday question: negative zero
In-Reply-To: <46D8B4A6.4040800@stats.uwo.ca>
References: <46D8B4A6.4040800@stats.uwo.ca>
Message-ID: <53CE0E0C-C4C6-4A9E-93DE-4CD5D6112A95@noc.soton.ac.uk>

Hello everyone



On 1 Sep 2007, at 01:39, Duncan Murdoch wrote:

> The IEEE floating point standard allows for negative zero, but it's  
> hard
> to know that you have one in R.  One reliable test is to take the
> reciprocal.  For example,
>
>> y <- 0
>> 1/y
> [1] Inf
>> y <- -y
>> 1/y
> [1] -Inf
>
> The other day I came across one in complex numbers, and it took me a
> while to figure out that negative zero was what was happening:
>
>> x <- complex(real = -1)
>> x
> [1] -1+0i
>> 1/x
> [1] -1+0i
>> x^(1/3)
> [1] 0.5+0.8660254i
>> (1/x)^(1/3)
> [1] 0.5-0.8660254i
>
> (The imaginary part of 1/x is negative zero.)
>
> As a Friday question:  are there other ways to create and detect
> negative zero in R?
>
> And another somewhat more serious question:  is the behaviour of
> negative zero consistent across platforms?  (The calculations above  
> were
> done in Windows in R-devel.)
>



I have been pondering branch cuts and branch points
for some functions which I am implementing.

In this area, it is very important to know whether one has
+0 or -0.

Take the log() function, where it is sometimes
very important to know whether one is just above the
imaginary axis or just below it:



(i).  Small y

 > y <- 1e-100
 > log(-1 +  1i*y)
[1] 0+3.141593i
 > y <- -y
 > log(-1 +  1i*y)
[1] 0-3.141593i


(ii)  Zero y.


 > y <- 0
 > log(-1 +  1i*y)
[1] 0+3.141593i
 > y <- -y
 > log(-1 +  1i*y)
[1] 0+3.141593i
 >


[ie small imaginary jumps have  a discontinuity, infinitesimal jumps  
don't].

This behaviour is undesirable (IMO): one would like log (-1+0i) to be  
different from log(-1-0i).

Tony Plate's example shows that
even though  y<- 0 ;  identical(y, -y) is TRUE,  one has identical(1/ 
y, 1/(-y)) is FALSE,
  so the sign is not discarded.

My complex function does have a branch cut that follows a portion of  
the negative real axis
but the other cuts follow absurdly complicated implicit equations.

At this point
one needs the IEEE requirement that x=x == +0  [ie not -0] for any  
real x; one then finds that
(s-t) and -(t-s) are numerically equal but not necessarily  
indistinguishable.

One of my earlier questions involved branch cuts for the inverse trig  
functions but
(IIRC) the patch I supplied only tested for the imaginary part being  
 >0; would it be
possible to include information about signed zero in these or other  
functions?






> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Robin Hankin
Uncertainty Analyst and Neutral Theorist,
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From bolker at ufl.edu  Fri Dec  7 16:29:45 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 07 Dec 2007 10:29:45 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <971536df0712070616q1f3f4311m44f2bfe641273249@mail.gmail.com>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>	
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>	
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>	
	<47594DEA.8080100@stats.uwo.ca>
	<971536df0712070616q1f3f4311m44f2bfe641273249@mail.gmail.com>
Message-ID: <475966E9.1080507@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Gabor Grothendieck wrote:
> On Dec 7, 2007 8:43 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 12/7/2007 8:10 AM, Peter Dalgaard wrote:

>>>>
>>> This is at least cleaner than abusing the "fixed" argument. 

   Agreed.

>>> As you know,
>>> I have reservations, one of which is that it is not a given that I want
>>> it to behave just like other modeling functions, e.g. a likelihood
>>> function might refer to more than one data set, and/or data that are not
>>> structured in the traditional data frame format. The design needs more
>>> thought than just adding arguments.

  Fair enough.

>> We should allow more general things to be passed as data arguments in
>> cases where it makes sense.  For example a list with names or an
>> environment would be a reasonable way to pass data that doesn't fit into
>> a data frame.

  Well, my current design specifies a named list: I *think* (but am not
sure) it works gracefully with a data frame as well.  Hadn't thought of
environments -- I'm aiming this more at a lower-level user to whom that
wouldn't occur.  (But I hope it would be possible to design a system
that would be usable by intermediate users and still useful for experts.)

>>> I still prefer a design based a plain likelihood function. Then we can
>>> discuss how to construct such a function so that  the data are
>>> incorporated in a flexible way.  

   My version still allows a plain likelihood function (I agree that
there will always be situations that are too complicated to encapsulate
as a formula).

>>> There are many ways to do this, I've
>>> shown one, here's another:
>>>
>>>> f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>>> d <- data.frame(x=rpois(10000, 12.34))
>>>> environment(f)<-evalq(environment(),d)
>> We really need to expand as.environment, so that it can convert data
>> frames into environments.  You should be able to say:
>>
>> environment(f) <- as.environment(d)
>>
>> and get the same result as
>>
>> environment(f)<-evalq(environment(),d)
>>
>> But I'd prefer to avoid the necessity for users to manipulate the
>> environment of a function.  

    HEAR, HEAR.

I think the pattern
>>
>> model( f, data=d )
>>
>> being implemented internally as
>>
>> environment(f) <- as.environment(d, parent = environment(f))
>>
>> is very nice and general.  It makes things like cross-validation,
>> bootstrapping, etc. conceptually cleaner:  keep the same
>> formula/function f, but manipulate the data and see what happens.
>> It does have problems when d is an environment that already has a
>> parent, but I think a reasonable meaning in that case would be to copy
>> its contents into a new environment with the new parent set.
>>

  OK.

>> Duncan Murdoch
> 
> Something close to that is already possible in proto and its cleaner in proto
> since the explicit environment manipulation is unnecessary as it occurs
> implicitly:
> 
> 1. In terms of data frame d from Peter Dalgaard's post the code
> below is similar to my last post but it replaces the explicit
> manipulation of f's environemnt with the creation of proto object
> p on line ###.  That line converts d to an anonymous proto object
> containing the components of d, in this case just x, and then
> creates a child object p which can access x via delegation/inheritance.
> 
> library(proto)
> set.seed(1)
> f <- function(lambda) -sum(dpois(x, lambda, log=T))
> d <- data.frame(x=rpois(100, 12.34))
> p <- proto(as.proto(as.list(d)), f = f) ###
> mle(p[["f"]], start=list(lambda=10))
> 
> 2. Or the ### line could be replaced with the following line
> which places f and the components of d, in this case just x,
> directly into p:
> 
> p <- proto(f = f, envir = as.proto(as.list(d)))
> 
> again avoiding the explicit reset of environment(f) and the evalq.
> 
>>
>>>> mle(f, start=list(lambda=10))
>>> Call:
>>> mle(minuslogl = f, start = list(lambda = 10))
>>>
>>> Coefficients:
>>>  lambda
>>> 12.3402
>>>

 *** I still feel very strongly that end users shouldn't have
to deal with closures, environments, protos, etc. --  I want
mle to LOOK LIKE a standard modeling function if at all possible,
even if it can be used more creatively and flexibly by
those who know how. ***

>>> It is not at all an unlikely design to have mle() as a generic function
>>> which works on many kinds of objects, the default method being
>>> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
>>> function returning (tada!) the negative log likelihood function.

   Agreed.  This would work for formulas, too.

  Have any of you guys looked at bbmle?  The evaluation stuff is
quite ugly, since I was groping around in the dark.  I would love
to clean it up in a way that made everyone happy (?) with it and
possibly allowed it to be merged back into mle.

   Ben

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHWWbpc5UpGjwzenMRApxZAJwLYuW+9beykCO1fJvBO4ICZxbEJwCfXgYR
F0nNR+/+/xy11xav9uDZSBE=
=bgiY
-----END PGP SIGNATURE-----


From simon.urbanek at r-project.org  Fri Dec  7 16:32:07 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 7 Dec 2007 10:32:07 -0500
Subject: [Rd] R installer
In-Reply-To: <475608BF.3000607@cimr.cam.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
	<475608BF.3000607@cimr.cam.ac.uk>
Message-ID: <B4953A4B-5867-47D2-9AAF-A53BE9E76995@r-project.org>


On Dec 4, 2007, at 9:11 PM, Hin-Tak Leung wrote:

> Simon Urbanek wrote:
> <snipped>
>> Because it *is* the gcc files? (Note the "/local" in the paths.)  
>> Full R comes with GNU Fortran 4.2.1, because Apple doesn't offer  
>> any Fortran compiler and most other Fortran compiler binaries for  
>> Mac OS X out on the web are not really working well. It installs  
>> in /usr/local.
> <snipped>
>
> This is what I don't understand or agree on. The R windows installer  
> does *not* try to install any of mingw gcc or Rtools. Okay, you  
> cannot install source packages on windows without mingw gcc or  
> Rtools, but that's a caveate.
>
> If I were an Apple user (which I am not), there is a chance that I  
> might have my own gcc/gfortran in /usr/local and I surely do not  
> want R to temper with them. If you need runtime libgfortran support,  
> you should just bundle gfortran.so and gcc.so if necesary (there are  
> static alternatives), and put those in R's area.
>

That's exactly what we do. Apparently you didn't bother to read my e- 
mail (the part you "snipped") or to look at the installer. Please do  
your homework before posting wild (and false) speculations.

Cheers,
Simon



> (recently, I took enough trouble of bootstrapping gfortran 4.2.x
> for cross-compiling - see mingw-devel mailing list archive - because  
> mingw don't distribute that as binary. I have win32 R under wine,  
> but I really would *not* appreciate if win32 R tries to do anything  
> substantially more than just put itself in a directory...).
>
> <snipped>
>> No. The failure is due to a strange symlink in /usr/local/lib that  
>> points to itself. I suspect that this has something to do with an  
>> upgrade from Tiger to Leopard or Xcode 3 installation and that  
>> Apple actually creates that infinite symlink. Given that there is "/ 
>> usr/loca/lib 1" lingering around, I'd bet that
>> sudo rm /usr/local/lib
>> sudo mv '/usr/local/lib 1' /usr/local/lib
>> will fix the problem.
>
> <snipped>
>
> Yeah, that apple box is *so* broken.:-).
>
> HTL
>
>


From b.rowlingson at lancaster.ac.uk  Fri Dec  7 17:07:12 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Dec 2007 16:07:12 +0000
Subject: [Rd] Building packages
Message-ID: <47596FB0.7090904@lancaster.ac.uk>

I've started a new package and I'm trying to work out the best way to do 
it. I'm managing my package source directory with SVN, but "R CMD build" 
likes to dump things in the inst/doc directory when making vignette PDF 
files. I don't want to keep these in SVN (they aren't strictly 
'source'), so it set me thinking.

One of the other projects I work with has an out-of-source build system. 
You make a 'build' directory, run a config system (cmake-based) and then 
'make' does everything in the build directory without touching the 
source tree. Very nice and neat. How much work would it take to have 
something similar for building R packages? At present I've just got some 
svn:ignore settings to stop SVN bothering me.

  I also hit the problem of vignettes needing the package to be 
installed before being able to build them, but not being able to install 
the package because the vignettes wouldn't build without the package 
already being installed. The fix is to build with --no-vignettes, then 
install the package, then build with the vignettes enabled. Seems 
kludgy, plus it means that vignettes are always built with the currently 
installed package and not the currently-being-installed package. So I 
install and do a second pass to get it all right again.

  Or am I doing it wrong?

  Once I get smooth running of R package development and SVN I might 
write it up for R-newsletter - there's a couple of other tricks I've had 
to employ...

Barry


From ggrothendieck at gmail.com  Fri Dec  7 17:12:14 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Dec 2007 11:12:14 -0500
Subject: [Rd] Building packages
In-Reply-To: <47596FB0.7090904@lancaster.ac.uk>
References: <47596FB0.7090904@lancaster.ac.uk>
Message-ID: <971536df0712070812w69023d27k984d7eb86aa2039@mail.gmail.com>

An svn checkout directory can contain a mix of files that
are mirrored in the svn and not mirrored.  In particular, if you
add a new file into your checkout directory it will not automatically
go into the repository on your next commit unless you specifically
place that file under svn control so junk files remain local.

You can exclude files from R CMD build using the .Rbuildignore file.
See the Writing Extensions manual.

On Dec 7, 2007 11:07 AM, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> I've started a new package and I'm trying to work out the best way to do
> it. I'm managing my package source directory with SVN, but "R CMD build"
> likes to dump things in the inst/doc directory when making vignette PDF
> files. I don't want to keep these in SVN (they aren't strictly
> 'source'), so it set me thinking.
>
> One of the other projects I work with has an out-of-source build system.
> You make a 'build' directory, run a config system (cmake-based) and then
> 'make' does everything in the build directory without touching the
> source tree. Very nice and neat. How much work would it take to have
> something similar for building R packages? At present I've just got some
> svn:ignore settings to stop SVN bothering me.
>
>  I also hit the problem of vignettes needing the package to be
> installed before being able to build them, but not being able to install
> the package because the vignettes wouldn't build without the package
> already being installed. The fix is to build with --no-vignettes, then
> install the package, then build with the vignettes enabled. Seems
> kludgy, plus it means that vignettes are always built with the currently
> installed package and not the currently-being-installed package. So I
> install and do a second pass to get it all right again.
>
>  Or am I doing it wrong?
>
>  Once I get smooth running of R package development and SVN I might
> write it up for R-newsletter - there's a couple of other tricks I've had
> to employ...
>
> Barry
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From b.rowlingson at lancaster.ac.uk  Fri Dec  7 17:29:25 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Dec 2007 16:29:25 +0000
Subject: [Rd] Building packages
In-Reply-To: <971536df0712070812w69023d27k984d7eb86aa2039@mail.gmail.com>
References: <47596FB0.7090904@lancaster.ac.uk>
	<971536df0712070812w69023d27k984d7eb86aa2039@mail.gmail.com>
Message-ID: <475974E5.3010708@lancaster.ac.uk>

Gabor Grothendieck wrote:
> An svn checkout directory can contain a mix of files that
> are mirrored in the svn and not mirrored.  In particular, if you
> add a new file into your checkout directory it will not automatically
> go into the repository on your next commit unless you specifically
> place that file under svn control so junk files remain local.

  True, but 'svn status' will keep annoying you with:

? inst/doc/foo.eps

  until you tell it to ignore it ["svn propedit svn:ignore ." and then 
enter some expressions].

Barry


From osklyar at ebi.ac.uk  Fri Dec  7 17:21:54 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Fri, 07 Dec 2007 16:21:54 +0000
Subject: [Rd] Building packages
In-Reply-To: <47596FB0.7090904@lancaster.ac.uk>
References: <47596FB0.7090904@lancaster.ac.uk>
Message-ID: <1197044514.30169.9.camel@maitai.windows.ebi.ac.uk>

These files in the SVN tree does not harm the things that are checked
in. However it is indeed reasonable to keep the rubbish out, so:

> I've started a new package and I'm trying to work out the best way to do 
> it. I'm managing my package source directory with SVN, but "R CMD build" 
> likes to dump things in the inst/doc directory when making vignette PDF 
> files. I don't want to keep these in SVN (they aren't strictly 
> 'source'), so it set me thinking.
Solution 1: copy the package SVN dir elsewhere and build/install from
there
Solution 2: a better one, make a 2-liner shell script that runs solution
1 (what I do)

This will also prevent gcc from populating your svn src directory
with .o, .so, .d, .dll files.

> One of the other projects I work with has an out-of-source build system. 
> You make a 'build' directory, run a config system (cmake-based) and then 
> 'make' does everything in the build directory without touching the 
> source tree. Very nice and neat. How much work would it take to have 
> something similar for building R packages? At present I've just got some 
> svn:ignore settings to stop SVN bothering me.
R does understand 'configure' which is more reasonable then to require
cmake to be installed. Think of multiplatform builds etc.

>   I also hit the problem of vignettes needing the package to be 
> installed before being able to build them, but not being able to install 
> the package because the vignettes wouldn't build without the package 
> already being installed. The fix is to build with --no-vignettes, then 
> install the package, then build with the vignettes enabled. Seems 
> kludgy, plus it means that vignettes are always built with the currently 
> installed package and not the currently-being-installed package. So I 
> install and do a second pass to get it all right again.
If I am not mistaken R CMD build builds the package temporarily and uses
that build to build the vignette, so where is the problem? All my
vignettes build fine on both Linux and Windows and on Windows you
actually see that running R CMD build --binary builds the source code
two times - exactly for the above purposes.

> 
>   Or am I doing it wrong?
> 
>   Once I get smooth running of R package development and SVN I might 
> write it up for R-newsletter - there's a couple of other tricks I've had 
> to employ...
What exactly?

> 
> Barry
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466


From goodrich at fas.harvard.edu  Fri Dec  7 17:30:14 2007
From: goodrich at fas.harvard.edu (goodrich at fas.harvard.edu)
Date: Fri,  7 Dec 2007 17:30:14 +0100 (CET)
Subject: [Rd] (PR#10500) Bug#454678: followup
Message-ID: <20071207163014.F28722834629@mail.pubhealth.ku.dk>

[I was overlooked on the CC. Hopefully this message does not create a
new bug report.]

> Prof Brian Ripley wrote:
> I would say this was user error (insisting on editing non-existent
> rownames), although the argument is documented.  You could argue that
> there are implicit rownames, but they would be 1, 2 ... not row1, row2
> ....  And rownames(mat) is NULL.
>
> For an interactive function the best solution seems to be to throw an
> error when the user asks for the impossible.
>
> I'll fix it for 2.7.0: it certainly isn't 'important' as it has gone
> undiscovered for many years, and edit.matrix is itself little used.
>
>
> BTW, 1:dim(names)[1] is dangerous: it could be 1:0.  That was the
> motivation for seq_len.

I would agree that it is a rare user error, but my original mistake was
a little more benign than the one that is depicted in the bug report. I
just forgot to call rownames()<- before calling edit(); that could have
happened to anyone. Perhaps one reason why this issue has not been
reported before is that in 2.5.1 at least, it produces an error message
rather than crashing (which I noted in the original bug report to Debian
but that was a little hard to see by the time it got forwarded to
R-bugs). In some ways, I think throwing an error in 2.7.0 would be
better than the behavior of edit.data.frame() in this case, which is to
add row names of 1, 2, ... . -- Thanks, Ben


From b.rowlingson at lancaster.ac.uk  Fri Dec  7 17:43:54 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Dec 2007 16:43:54 +0000
Subject: [Rd] Building packages
In-Reply-To: <1197044514.30169.9.camel@maitai.windows.ebi.ac.uk>
References: <47596FB0.7090904@lancaster.ac.uk>
	<1197044514.30169.9.camel@maitai.windows.ebi.ac.uk>
Message-ID: <4759784A.2000908@lancaster.ac.uk>

Oleg Sklyar wrote:

> If I am not mistaken R CMD build builds the package temporarily and uses
> that build to build the vignette, so where is the problem? All my
> vignettes build fine on both Linux and Windows and on Windows you
> actually see that running R CMD build --binary builds the source code
> two times - exactly for the above purposes.

  Ah ha. I'm building as a user and so I've been installing into a 
private library: ~/Rlibs. Hence my vignette has had 
library(foo,lib="~/Rlibs"). I was unaware that it would get the 
currently-being-built package in a library of its own! Thanks!

  www.doingitwrong.com

Barry


From elw at stderr.org  Fri Dec  7 18:16:27 2007
From: elw at stderr.org (elw at stderr.org)
Date: Fri, 7 Dec 2007 11:16:27 -0600 (CST)
Subject: [Rd] R-Cocoa Bridge
In-Reply-To: <6D1632FE-9965-4705-9B34-175BE0E33A36@r-project.org>
References: <AAF9A5F8-70C4-4B24-AE14-D0A57E2C9EFF@gmail.com>
	<Pine.LNX.4.64.0712061129300.20158@illuminati.stderr.org>
	<6D1632FE-9965-4705-9B34-175BE0E33A36@r-project.org>
Message-ID: <Pine.LNX.4.64.0712071115591.7196@illuminati.stderr.org>


>>> I had seen old posts on the list (circa 2002) regarding a Cocoa-R 
>>> bridge that was under development, but I can't find anything recent 
>>> about it. Does anyone know if this is available somewhere? If not, 
>>> does anyone have any experience/pointers calling R functions from 
>>> Cocoa?
>> 
>> The R builds on OSX build an R.Framework; you can probably bootstrap 
>> off of that without too much trouble.  [I haven't done much with it; 
>> wish I had time.]
>
> Unfortunately the R/ObjC bridge is not part of the framework yet. We're 
> working on it, but we need some more cleanup of the old code. The 
> current plan is to have it ready for R 2.7.0 (but you never know ...).


Good to know - looking forward to it.

Thanks, Simon!

--elijah


From edd at debian.org  Fri Dec  7 18:32:01 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 7 Dec 2007 11:32:01 -0600
Subject: [Rd] (PR#10500) Bug#454678: followup
In-Reply-To: <20071207163014.F28722834629@mail.pubhealth.ku.dk>
References: <20071207163014.F28722834629@mail.pubhealth.ku.dk>
Message-ID: <18265.33681.103126.321035@ron.nulle.part>


On 7 December 2007 at 17:30, goodrich at fas.harvard.edu wrote:
| [I was overlooked on the CC. Hopefully this message does not create a
| new bug report.]

[ That was my bad, but I did sent you a forwarded copy a few hours ago when I
noticed this. ]
 
| > Prof Brian Ripley wrote:
| > I would say this was user error (insisting on editing non-existent
| > rownames), although the argument is documented.  You could argue that
| > there are implicit rownames, but they would be 1, 2 ... not row1, row2
| > ....  And rownames(mat) is NULL.
| >
| > For an interactive function the best solution seems to be to throw an
| > error when the user asks for the impossible.
| >
| > I'll fix it for 2.7.0: it certainly isn't 'important' as it has gone
| > undiscovered for many years, and edit.matrix is itself little used.
| >
| >
| > BTW, 1:dim(names)[1] is dangerous: it could be 1:0.  That was the
| > motivation for seq_len.
| 
| I would agree that it is a rare user error, but my original mistake was
| a little more benign than the one that is depicted in the bug report. I
| just forgot to call rownames()<- before calling edit(); that could have
| happened to anyone. Perhaps one reason why this issue has not been
| reported before is that in 2.5.1 at least, it produces an error message
| rather than crashing (which I noted in the original bug report to Debian
| but that was a little hard to see by the time it got forwarded to
| R-bugs). In some ways, I think throwing an error in 2.7.0 would be
| better than the behavior of edit.data.frame() in this case, which is to
| add row names of 1, 2, ... . -- Thanks, Ben

Having first provided a (rough) patch, and havuing had some more time to
ponder the issue, I have decided to call it a non-bug as far as Debian is
concerned (and you even commented that it belonged more into R's BTS). This
message closes the bug report there.

I am also with Brian on the issue at large -- it is a user error as you do
have to force the TRUE state leading to the segfault.

Anyway, a sufficient amount of time has now been spent with the upshot that
it will behave better in the corner case once 2.7.0 is out.  Sounds good to
me.

Thanks to Brian Ripley for the follow-up on R Core's behalf, and thanks to
Ben to report the, err, 'issue'.

Cheers, Dirk

-- 
Three out of two people have difficulties with fractions.


From h.wickham at gmail.com  Fri Dec  7 18:36:42 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 7 Dec 2007 11:36:42 -0600
Subject: [Rd] Building packages
In-Reply-To: <475974E5.3010708@lancaster.ac.uk>
References: <47596FB0.7090904@lancaster.ac.uk>
	<971536df0712070812w69023d27k984d7eb86aa2039@mail.gmail.com>
	<475974E5.3010708@lancaster.ac.uk>
Message-ID: <f8e6ff050712070936k273a455fhd934762761671010@mail.gmail.com>

On 12/7/07, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> Gabor Grothendieck wrote:
> > An svn checkout directory can contain a mix of files that
> > are mirrored in the svn and not mirrored.  In particular, if you
> > add a new file into your checkout directory it will not automatically
> > go into the repository on your next commit unless you specifically
> > place that file under svn control so junk files remain local.
>
>   True, but 'svn status' will keep annoying you with:
>
> ? inst/doc/foo.eps
>
>   until you tell it to ignore it ["svn propedit svn:ignore ." and then
> enter some expressions].

Yes, but that's completely normal svn operation - you ignore the non
source files so that they don't interfere with your view of the source
files.  You particularly need this when working with latex.

I have

alias svnignore='svn pe svn:ignore'

in my .profile to save a little typing.

Hadley
-- 
http://had.co.nz/


From luke at stat.uiowa.edu  Fri Dec  7 20:38:34 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 7 Dec 2007 13:38:34 -0600 (CST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <971536df0712070532hb528e80oa04a60534a3e615b@mail.gmail.com>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<971536df0712070532hb528e80oa04a60534a3e615b@mail.gmail.com>
Message-ID: <Pine.OSX.4.64.0712071301310.753@luke-tierneys-computer-3.local>

On Fri, 7 Dec 2007, Gabor Grothendieck wrote:

> On Dec 7, 2007 8:10 AM, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
>> Ben Bolker wrote:
>>>   At this point I'd just like to advertise the "bbmle" package
>>> (on CRAN) for those who respectfully disagree, as I do, with Peter over
>>> this issue.  I have added a data= argument to my version
>>> of the function that allows other variables to be passed
>>> to the objective function.  It seems to me that this is perfectly
>>> in line with the way that other modeling functions in R
>>> behave.
>>>
>> This is at least cleaner than abusing the "fixed" argument. As you know,
>> I have reservations, one of which is that it is not a given that I want
>> it to behave just like other modeling functions, e.g. a likelihood
>> function might refer to more than one data set, and/or data that are not
>> structured in the traditional data frame format. The design needs more
>> thought than just adding arguments.
>>
>> I still prefer a design based a plain likelihood function. Then we can
>> discuss how to construct such a function so that  the data are
>> incorporated in a flexible way.  There are many ways to do this, I've
>> shown one, here's another:
>>
>>> f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>> d <- data.frame(x=rpois(10000, 12.34))
>>> environment(f)<-evalq(environment(),d)
>>> mle(f, start=list(lambda=10))
>>
>> Call:
>> mle(minuslogl = f, start = list(lambda = 10))
>>
>> Coefficients:
>>  lambda
>> 12.3402
>>
>
> The explicit environment manipulation is what I was referring to but

I make extensive use of lexical scoping in my programming and I NEVER
use explicit environment manipulaiton--for me that is unreadable, and it
is not amenable to checking using things like codetools.  In the
example above all that is needed is to define x directly, e.g.

     > f <- function(lambda) -sum(dpois(x, lambda, log=T))
     > x <- rpois(10000, 12.34)
     > mle(f, start=list(lambda=10))

     Call:
     mle(minuslogl = f, start = list(lambda = 10))

     Coefficients:
     lambda
     12.337

It isn't necessary to go through the data frame or environment
munging.  If you want to be able to work with likelihoods for several
data sets at once then you can either use diferent names for the
variables, like

     x1 <- rpois(10000, 12.34)
     f1 <- function(lambda) -sum(dpois(x1, lambda, log=T))
     x2 <- rpois(10000, 12.34)
     f2 <- function(lambda) -sum(dpois(x2, lambda, log=T))

If you are concerned that x, x1, x2 might have been redefined if you
come back to f1, f2 later (not an issue with typical useage inside a
function but can be an issue at top level) then you can create a
closure that cpatures the particular data set you are using.  The
clean way to do this is with a function that creates the negative log
likelihood, e.g.

     makePoisonNegLogLikelihood <- function(x)
 	function(lambda) -sum(dpois(x, lambda, log=T))

Then you can do

     f <- makePoisonNegLogLikelihood(rpois(10000, 12.34))
     mle(f, start=list(lambda=10))

which I find much cleaner and easier to understand than environment
munging.  Once you are defining a likelihood constructor you can think
about things like making it a bit more efficient by calculating
sufficient statistics once, for example

     makePoisonNegLogLikelihood <- function(x) {
         sumX <- sum(x)
         n <- length(x)
 	function(lambda) -dpois(sumX, n * lambda, log=T)
     }

Best,

luke

> we can simplify it using proto.  Create a proto object to hold
> f and x then pass the f in the proto object (rather than the
> original f) to mle.  That works because proto automatically resets
> the environment of f when its added to avoiding the evalq.
>
>> set.seed(1)
>> library(proto)
>> f <- function(lambda) -sum(dpois(x, lambda, log=TRUE))
>> p <- proto(f = f, x = rpois(100, 12.34))
>> mle(p[["f"]], start = list(lambda = 10))
>
> Call:
> mle(minuslogl = p[["f"]], start = list(lambda = 10))
>
> Coefficients:
>  lambda
> 12.46000
>
>> It is not at all an unlikely design to have mle() as a generic function
>> which works on many kinds of objects, the default method being
>> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
>> function returning (tada!) the negative log likelihood function.
>>>   (My version also has a cool formula interface and other
>>> bells and whistles, and I would love to get feedback from other
>>> useRs about it.)
>>>
>>>    cheers
>>>     Ben Bolker
>>>
>>>
>>
>>
>> --
>>
>>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From luke at stat.uiowa.edu  Fri Dec  7 21:24:36 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 7 Dec 2007 14:24:36 -0600 (CST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <47594DEA.8080100@stats.uwo.ca>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
Message-ID: <Pine.OSX.4.64.0712071345280.753@luke-tierneys-computer-3.local>

On Fri, 7 Dec 2007, Duncan Murdoch wrote:

> On 12/7/2007 8:10 AM, Peter Dalgaard wrote:
>> Ben Bolker wrote:
>>>   At this point I'd just like to advertise the "bbmle" package
>>> (on CRAN) for those who respectfully disagree, as I do, with Peter over
>>> this issue.  I have added a data= argument to my version
>>> of the function that allows other variables to be passed
>>> to the objective function.  It seems to me that this is perfectly
>>> in line with the way that other modeling functions in R
>>> behave.
>>>
>> This is at least cleaner than abusing the "fixed" argument. As you know,
>> I have reservations, one of which is that it is not a given that I want
>> it to behave just like other modeling functions, e.g. a likelihood
>> function might refer to more than one data set, and/or data that are not
>> structured in the traditional data frame format. The design needs more
>> thought than just adding arguments.
>
> We should allow more general things to be passed as data arguments in
> cases where it makes sense.  For example a list with names or an
> environment would be a reasonable way to pass data that doesn't fit into
> a data frame.
>
>> I still prefer a design based a plain likelihood function. Then we can
>> discuss how to construct such a function so that  the data are
>> incorporated in a flexible way.  There are many ways to do this, I've
>> shown one, here's another:
>>
>>> f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>> d <- data.frame(x=rpois(10000, 12.34))
>>> environment(f)<-evalq(environment(),d)
>
> We really need to expand as.environment, so that it can convert data
> frames into environments.  You should be able to say:
>
> environment(f) <- as.environment(d)
>
> and get the same result as
>
> environment(f)<-evalq(environment(),d)
>
> But I'd prefer to avoid the necessity for users to manipulate the
> environment of a function.  I think the pattern
>
> model( f, data=d )
>
> being implemented internally as
>
> environment(f) <- as.environment(d, parent = environment(f))
>
> is very nice and general.  It makes things like cross-validation,
> bootstrapping, etc. conceptually cleaner:  keep the same
> formula/function f, but manipulate the data and see what happens.
> It does have problems when d is an environment that already has a
> parent, but I think a reasonable meaning in that case would be to copy
> its contents into a new environment with the new parent set.
>
> Duncan Murdoch
>
>
>>> mle(f, start=list(lambda=10))
>>
>> Call:
>> mle(minuslogl = f, start = list(lambda = 10))
>>
>> Coefficients:
>>  lambda
>> 12.3402
>>
>> It is not at all an unlikely design to have mle() as a generic function
>> which works on many kinds of objects, the default method being
>> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
>> function returning (tada!) the negative log likelihood function.
>>>   (My version also has a cool formula interface and other
>>> bells and whistles, and I would love to get feedback from other
>>> useRs about it.)
>>>
>>>    cheers
>>>     Ben Bolker
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From brownjtb at gmail.com  Fri Dec  7 18:45:09 2007
From: brownjtb at gmail.com (brownjtb at gmail.com)
Date: Fri,  7 Dec 2007 18:45:09 +0100 (CET)
Subject: [Rd] regression tests for unlink and wildcards fail - Solaris 10
	SPARC / Sun Studio 12 (PR#10501)
Message-ID: <20071207174509.8FD6B283461C@mail.pubhealth.ku.dk>

Full_Name: Jim Brown
Version: 2.6.0 / 2.6.1
OS: Solaris 10 (SPARC)
Submission from: (NULL) (35.8.15.102)


I have been able to successfully compile version 2.5.1 using the Sun Studio 12
compilers on Sun Solaris 10 (SPARC).  All tests using "make check" pass with a
status of OK.   However, the following section of "reg-tests-1.R" fails when I
attempt to test after a build of either 2.6.0 or 2.6.1:

  ## regression tests for unlink and wildcards
  owd <- setwd(tempdir())
  f <- c("ftest1", "ftest2", "ftestmore", "ftest&more")
  file.create(f)
  stopifnot(file.exists(f))
  unlink("ftest?")
  stopifnot(file.exists(f) == c(FALSE, FALSE, TRUE, TRUE))
  unlink("ftest*", recursive = TRUE)
  stopifnot(!file.exists(f))

  stopifnot(unlink("no_such_file") == 0) # not an error

  dd <- c("dir1", "dir2", "dirs", "moredirs")
  for(d in dd) dir.create(d)
  dir(".")
  file.create(file.path(dd, "somefile"))
  dir(".", recursive=TRUE)
  stopifnot(unlink("dir?") == 1) # not an error
  unlink("dir?", recursive = TRUE)
  stopifnot(file.exists(dd) == c(FALSE, FALSE, FALSE, TRUE))
  unlink("*dir*", recursive = TRUE)
  stopifnot(!file.exists(dd))

  # Windows needs short path names for leading spaces
  dir.create(" test")
  dir(".", recursive=TRUE)
  unlink(" test", recursive = TRUE)
  stopifnot(!file.exists(" test"))
  setwd(owd)


If I comment out the above section of the tests, the rest of the test pass. 
However, running as it is intended, the "reg-tests-1.R" test does fail.  Here is
the output that is generated from "make check":

running code in 'reg-tests-1.R' ...*** Error code 1
The following command caused the error:
LC_ALL=C SRCDIR=. R_DEFAULT_PACKAGES= ../bin/R --vanilla < reg-tests-1.R >
reg-tests-1.Rout 2>&1 || (mv reg-tests-1.Rout reg-tests-1.Rout.fail && exit 1)
make: Fatal error: Command failed for target `reg-tests-1.Rout'
Current working directory /apps/local/src/R-2.6.0/tests
*** Error code 1
The following command caused the error:
make reg-tests-1.Rout reg-tests-2.Rout reg-IO.Rout reg-IO2.Rout  reg-plot.Rout
reg-S4.Rout  RVAL_IF_DIFF=1
make: Fatal error: Command failed for target `test-Reg'
Current working directory /apps/local/src/R-2.6.0/tests
*** Error code 1
The following command caused the error:
for name in Examples Specific Reg Internet; do \
  make test-${name} || exit 1; \
done
make: Fatal error: Command failed for target `test-all-basics'
Current working directory /apps/local/src/R-2.6.0/tests
*** Error code 1
The following command caused the error:
(cd tests && make check)
make: Fatal error: Command failed for target `check'



And here are the final entries in the "reg-tests-1.Rout.fail" file:

> ## regression tests for unlink and wildcards
> owd <- setwd(tempdir())
> f <- c("ftest1", "ftest2", "ftestmore", "ftest&more")
> file.create(f)
[1] TRUE TRUE TRUE TRUE
> stopifnot(file.exists(f))
> unlink("ftest?")
> stopifnot(file.exists(f) == c(FALSE, FALSE, TRUE, TRUE))
> unlink("ftest*", recursive = TRUE)
> stopifnot(!file.exists(f))
> 
> stopifnot(unlink("no_such_file") == 0) # not an error
> 
> dd <- c("dir1", "dir2", "dirs", "moredirs")
> for(d in dd) dir.create(d)
> dir(".")
[1] "41c6167e"     "dir1"         "dir2"         "dirs"         "file21ed4192"
[6] "file281327c9" "moredirs"    
> file.create(file.path(dd, "somefile"))
[1] TRUE TRUE TRUE TRUE
> dir(".", recursive=TRUE)
[1] "41c6167e"          "dir1/somefile"     "dir2/somefile"    
[4] "dirs/somefile"     "file21ed4192"      "file281327c9"     
[7] "moredirs/somefile"
> stopifnot(unlink("dir?") == 1) # not an error
Error: unlink("dir?") == 1 is not TRUE
Execution halted
rm: Cannot remove any directory in the path of the current working directory
/tmp/RtmpBLKy4b



Is this safe to ignore?   The empty directory that it is complaining about
(/tmp/RtmpBLKy4b) can not be removed using "rm -r", but can be removed using the
UNIX "unlink" command.


Again, version 2.5.1 builds and checks just fine, but the above tests fail when
I attempt to build/check either 2.6.0 or 2.6.1.


In case it is any help, here are the configure options that I set for all three
builds:

  ./configure --prefix=/usr/local/R
  --with-blas=sunperf
  --with-lapack
  --with-tcl-config=/usr/local/lib/tclConfig.sh
  --with-tk-config=/usr/local/lib/tkConfig.sh
  R_PAPERSIZE=letter
  CC=/opt/SUNWspro/bin/cc
  CFLAGS="-mt -ftrap=%none -xarch=sparcvis"
  LDFLAGS="-L/usr/local/lib -R/usr/local/lib"
  CXX=/opt/SUNWspro/bin/CC
  CXXFLAGS="-mt -ftrap=%none -xarch=sparcvis"
  F77=/opt/SUNWspro/bin/f95
  F95=/opt/SUNWspro/bin/f95
  FFLAGS="-mt -ftrap=%none -xarch=sparcvis" 
  FC=/opt/SUNWspro/bin/f95
  FCFLAGS="-mt -ftrap=%none -xarch=sparcvis"
  CPICFLAGS=-xcode=pic32
  CPPFLAGS="-I/usr/local/include"
  SHLIB_CXXLDFLAGS="-G -lCstd"



For now, I think I will continue to use version 2.5.1 as I am able build/test
that version and I know it works.  However, I would like to upgrade at some
point and just thought I would make you aware of the failed test on the Sun
Solaris 10 (SPARC) platform using the latest Sun Studio 12 set of compilers.


Thanks.



Jim


From a.robotham at bristol.ac.uk  Fri Dec  7 15:35:11 2007
From: a.robotham at bristol.ac.uk (a.robotham at bristol.ac.uk)
Date: Fri,  7 Dec 2007 15:35:11 +0100 (CET)
Subject: [Rd] os x crash using rpanel and tcltk (PR#10495)
Message-ID: <20071207143511.2132D2834620@mail.pubhealth.ku.dk>

Here's the back trace i get after it crashes:

Program received signal SIGTRAP, Trace/breakpoint trap.
0x90a61b09 in _objc_error ()
(gdb) bt
#0  0x90a61b09 in _objc_error ()
#1  0x90a61b40 in __objc_error ()
#2  0x90a601a0 in _freedHandler ()
#3  0x93442c64 in -[NSDocument close] ()
#4  0x00015f0b in -[RQuartz close] ()
#5  0x00016c93 in RQuartz_Close ()
#6  0x0039b6dc in removeDevice ()
#7  0x00015f3f in -[RQuartz windowShouldClose:] ()
#8  0x934429b2 in -[NSWindow _document:shouldClose:contextInfo:] ()
#9  0x93442437 in -[NSWindow __close] ()
#10 0x93382dbc in -[NSApplication sendAction:to:from:] ()
#11 0x93382d15 in -[NSControl sendAction:to:] ()
#12 0x93384ec1 in -[NSCell _sendActionFrom:] ()
#13 0x933976a1 in -[NSCell trackMouse:inRect:ofView:untilMouseUp:] ()
#14 0x933b5289 in -[NSButtonCell trackMouse:inRect:ofView:untilMouseUp:] ()
#15 0x933b4b39 in -[NSControl mouseDown:] ()
#16 0x934422f8 in -[_NSThemeWidget mouseDown:] ()
#17 0x933723e3 in -[NSWindow sendEvent:] ()
#18 0x93364384 in -[NSApplication sendEvent:] ()
#19 0x00005151 in -[RController handleReadConsole:] ()
#20 0x0000c641 in Re_ReadConsole ()
#21 0x00015c76 in run_REngineRmainloop ()
#22 0x0000ec4a in -[REngine runREPL] ()
#23 0x0000226d in main ()

Is this what is wanted?

Thanks for the gdb advice btw. I'm not sure if it's important, but
before it crashed I got lots of warnings similar to the following in
gdb when I attached the tcltk package:

warning: Could not find object file
"/Builds/Rdev-web/QA/Simon/R-build/tiger-ppc/R-2.6-branch/src/extra/blas/bl=
as00.o"
- no debug information available for
"../../../../../R-2.6-branch/src/extra/blas/blas00.c".

Is there an issue with a previous version of R on my machine causing proble=
ms?

Thanks for the help.

Aaron

On 07/12/2007, Aaron Robotham <a.robotham at bristol.ac.uk> wrote:
> The machine in question is a black MacBook, a pretty standard setup
> with the rest of the details as listed in my first post (R 2.6.1 OSX
> 10.4.11). I'll give the back trace a try and let you know the result.
>
> On 06/12/2007, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >
> > On Dec 6, 2007, at 9:26 AM, Aaron Robotham wrote:
> >
> > > I know of gdb but I'm not certain how to use it with Mac OS X's
> > > R.app, do you just do something like "gdb open R.app" in the
> > > terminal?.
> > >
> >
> > You can attach it once it's running - just type "attach R" in gdb
> > while R is runningm then "c", then let it crash and then "bt".
> >
> > FWIW: I cannot reproduce the problem and I have tried 3 different
> > machines... (you didn't even tell us what machine type this is ...).
> >
> > Cheers,
> > Simon
> >
> >
> > > Interestingly I don't get this crash when I launch the X11 version of
> > > R through the terminal, so this would suggest the bug in question is
> > > to do with the actual Rgui in R.app. Hopefully this information might
> > > help to narrow down the problem. Any advice for using gdb on R.app
> > > would be appreciated, I couldn't find much in the way of guidance whe=
n
> > > searching online.
> > >
> > > thanks
> > >
> > > Aaron
> > >
> > > On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > >> a.robotham at bris.ac.uk wrote:
> > >>> Hello,
> > >>> I've recently discovered a persistent issue with rpanel when runnin=
g
> > >>> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without an=
y
> > >>> apparent error, and the interactive panels appear to work as
> > >>> expected,
> > >>> however upon closing the panels rpanel has created I get
> > >>> catastrophic
> > >>> errors and R crashes completely. For the most part R manages to
> > >>> crash
> > >>> with dignity and work can be saved, but sometimes it will crash
> > >>> straight out. Below is an example of an entire work session (only
> > >>> base
> > >>> packages loaded) with the crash at the end typical of those
> > >>> encountered:
> > >>>
> > >>>
> > >>>> library(tcltk)
> > >>>>
> > >>> Loading Tcl/Tk interface ... done
> > >>>
> > >>>> library(rpanel)
> > >>>>
> > >>> Package `rpanel', version 1.0-4
> > >>> type help(rpanel) for summary information
> > >>>
> > >>>> density.draw <- function(panel) {
> > >>>>
> > >>> +   plot(density(panel$x, bw =3D panel$h))
> > >>> +   panel
> > >>> + }
> > >>>
> > >>>> panel <- rp.control(x =3D rnorm(50))
> > >>>> rp.slider(panel, h, 0.5, 5, log =3D TRUE, action =3D density.draw)
> > >>>>
> > >>>
> > >>> *** caught bus error ***
> > >>> address 0x0, cause 'non-existent physical address'
> > >>>
> > >>> Possible actions:
> > >>> 1: abort (with core dump, if enabled)
> > >>> 2: normal R exit
> > >>> 3: exit R without saving workspace
> > >>> 4: exit R saving workspace
> > >>>
> > >>> All packages that are required are up to date, and I can find no
> > >>> evidence of similar issues from searching the mailing lists. Any
> > >>> suggestions would be appreciated.
> > >>>
> > >>>
> > >> Can you run this under gdb? A breakpoint in the error handler and a
> > >> backtrace could be valuable.
> > >>
> > >>> Aaron
> > >>>
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>
> > >>
> > >>
> > >> --
> > >>   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.=
B
> > >>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > >> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> > >> 35327918
> > >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> > >> 35327907
> > >>
> > >>
> > >>
> > >>
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> >
> >
> >
>


From luke at stat.uiowa.edu  Fri Dec  7 21:46:37 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 7 Dec 2007 14:46:37 -0600 (CST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <47594DEA.8080100@stats.uwo.ca>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
Message-ID: <Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>

On Fri, 7 Dec 2007, Duncan Murdoch wrote:

> On 12/7/2007 8:10 AM, Peter Dalgaard wrote:
>> Ben Bolker wrote:
>>>   At this point I'd just like to advertise the "bbmle" package
>>> (on CRAN) for those who respectfully disagree, as I do, with Peter over
>>> this issue.  I have added a data= argument to my version
>>> of the function that allows other variables to be passed
>>> to the objective function.  It seems to me that this is perfectly
>>> in line with the way that other modeling functions in R
>>> behave.
>>>
>> This is at least cleaner than abusing the "fixed" argument. As you know,
>> I have reservations, one of which is that it is not a given that I want
>> it to behave just like other modeling functions, e.g. a likelihood
>> function might refer to more than one data set, and/or data that are not
>> structured in the traditional data frame format. The design needs more
>> thought than just adding arguments.
>
> We should allow more general things to be passed as data arguments in
> cases where it makes sense.  For example a list with names or an
> environment would be a reasonable way to pass data that doesn't fit into
> a data frame.
>
>> I still prefer a design based a plain likelihood function. Then we can
>> discuss how to construct such a function so that  the data are
>> incorporated in a flexible way.  There are many ways to do this, I've
>> shown one, here's another:
>>
>>> f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>> d <- data.frame(x=rpois(10000, 12.34))
>>> environment(f)<-evalq(environment(),d)
>
> We really need to expand as.environment, so that it can convert data
> frames into environments.  You should be able to say:
>
> environment(f) <- as.environment(d)
>
> and get the same result as
>
> environment(f)<-evalq(environment(),d)
>
> But I'd prefer to avoid the necessity for users to manipulate the
> environment of a function.  I think the pattern
>
> model( f, data=d )

For working at the general likelihood I think is is better to
encourage the approach of definign likelihood constructor functions.
The problem with using f, data is that you need to mathc the names
used in f and in data, so either you have to explicitly write out f
with the names you have in data or you have to modify data to use the
names f likes -- in the running example think

     f <- function(lambda) -sum(dpois(x, lambda, log=T))
     d <- data.frame(y=rpois(10000, 12.34))

somebody has to connext up the x in f with the y in d. With a negative
log likelihood constructor defines, for example, as

     makePoisonNegLogLikelihood <- function(x)
         function(lambda) -sum(dpois(x, lambda, log=T))

this happens naturally with

     makePoisonNegLogLikelihood(d$y)

>
> being implemented internally as
>
> environment(f) <- as.environment(d, parent = environment(f))
>
> is very nice and general.  It makes things like cross-validation,
> bootstrapping, etc. conceptually cleaner:  keep the same
> formula/function f, but manipulate the data and see what happens.
> It does have problems when d is an environment that already has a
> parent, but I think a reasonable meaning in that case would be to copy
> its contents into a new environment with the new parent set.

Both (simple) bootstrapping and (simple leave-one-out) crossvalidation
require a data structure with a notion of cases, which is much more
restrictive than the conext in which mle can be used.  A more ngeneric
aproach to bootstrapping that might fit closer to the level of
generality of mle might be parameterized in terms of a negative log
likelihood constructor, a starting value constructor, and a resampling
function, with a single iteration implemented soemthing like

     mleboot1 <- function(nllmaker, start, esample)  {
 	newdata <- resample()
 	newstart <- do.call(start, newdata)
 	nllfun <- do.call(nllmaker, newdata)
 	mle(fnllfun, start = newstart)
     }

This would leave decisions on the resampling method and data structure
up to the user. Somehing similar could be done with K-fold CV.

luke



>
> Duncan Murdoch
>
>
>>> mle(f, start=list(lambda=10))
>>
>> Call:
>> mle(minuslogl = f, start = list(lambda = 10))
>>
>> Coefficients:
>>  lambda
>> 12.3402
>>
>> It is not at all an unlikely design to have mle() as a generic function
>> which works on many kinds of objects, the default method being
>> function(object,...) mle(minuslogl(obj)) and minuslogl is an extractor
>> function returning (tada!) the negative log likelihood function.
>>>   (My version also has a cool formula interface and other
>>> bells and whistles, and I would love to get feedback from other
>>> useRs about it.)
>>>
>>>    cheers
>>>     Ben Bolker
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From bolker at ufl.edu  Fri Dec  7 23:09:57 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 07 Dec 2007 17:09:57 -0500
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
	<Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
Message-ID: <4759C4B5.7030803@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Luke Tierney wrote:
> On Fri, 7 Dec 2007, Duncan Murdoch wrote:
> 
>
> 
> For working at the general likelihood I think is is better to
> encourage the approach of definign likelihood constructor functions.
> The problem with using f, data is that you need to mathc the names
> used in f and in data, so either you have to explicitly write out f
> with the names you have in data or you have to modify data to use the
> names f likes -- in the running example think
> 
>     f <- function(lambda) -sum(dpois(x, lambda, log=T))
>     d <- data.frame(y=rpois(10000, 12.34))
> 
> somebody has to connext up the x in f with the y in d. With a negative
> log likelihood constructor defines, for example, as
> 
>     makePoisonNegLogLikelihood <- function(x)
>         function(lambda) -sum(dpois(x, lambda, log=T))
> 
> this happens naturally with
> 
>     makePoisonNegLogLikelihood(d$y)
> 
> 

  I hate to sound like a jerk, but I do hope that in the end we come
up with a solution that will still be accessible to people who don't
quite have the concept of writing functions to produce functions.  I
feel it is "natural" for people who have multiple data sets to have the
variables named similarly in different data sets.  All of the
constructor stuff is still accessible to anyone who wants to use the
function that way ... is there any way to do a cheesy default
constructor that is just equivalent to taking the likelihood function
and arranging for it to be evaluated in an environment containing
the data?  That way if "nllmaker" below were just a formula
or a log-likelihood function it could still work ...

  [snip]
> Both (simple) bootstrapping and (simple leave-one-out) crossvalidation
> require a data structure with a notion of cases, which is much more
> restrictive than the conext in which mle can be used.  A more ngeneric
> aproach to bootstrapping that might fit closer to the level of
> generality of mle might be parameterized in terms of a negative log
> likelihood constructor, a starting value constructor, and a resampling
> function, with a single iteration implemented soemthing like
> 
>     mleboot1 <- function(nllmaker, start, esample)  {
>     newdata <- resample()
>     newstart <- do.call(start, newdata)
>     nllfun <- do.call(nllmaker, newdata)
>     mle(fnllfun, start = newstart)
>     }
> 
> This would leave decisions on the resampling method and data structure
> up to the user. Somehing similar could be done with K-fold CV.
> 
> luke
> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHWcS1c5UpGjwzenMRAig2AJ9iTzhI1p8tBb7Q15jgT4nA+Zds+gCgggc2
sI2que28Hl1M5cVGa+anEL0=
=hCiS
-----END PGP SIGNATURE-----


From antonio.fabio at gmail.com  Fri Dec  7 23:46:36 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 7 Dec 2007 23:46:36 +0100
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4759C4B5.7030803@ufl.edu>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
	<Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
	<4759C4B5.7030803@ufl.edu>
Message-ID: <b0808fdc0712071446y2224dab0nafb1d6627800f5b0@mail.gmail.com>

2007/12/7, Ben Bolker <bolker at ufl.edu>:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Luke Tierney wrote:
> > On Fri, 7 Dec 2007, Duncan Murdoch wrote:
> >
> >
> >
> > For working at the general likelihood I think is is better to
> > encourage the approach of definign likelihood constructor functions.
> > The problem with using f, data is that you need to mathc the names
> > used in f and in data, so either you have to explicitly write out f
> > with the names you have in data or you have to modify data to use the
> > names f likes -- in the running example think
> >
> >     f <- function(lambda) -sum(dpois(x, lambda, log=T))
> >     d <- data.frame(y=rpois(10000, 12.34))
> >
> > somebody has to connext up the x in f with the y in d. With a negative
> > log likelihood constructor defines, for example, as
> >
> >     makePoisonNegLogLikelihood <- function(x)
> >         function(lambda) -sum(dpois(x, lambda, log=T))
> >
> > this happens naturally with
> >
> >     makePoisonNegLogLikelihood(d$y)
> >
> >
>
>   I hate to sound like a jerk, but I do hope that in the end we come
> up with a solution that will still be accessible to people who don't
> quite have the concept of writing functions to produce functions.  I
> feel it is "natural" for people who have multiple data sets to have the
> variables named similarly in different data sets.  All of the
> constructor stuff is still accessible to anyone who wants to use the
> function that way ... is there any way to do a cheesy default
> constructor that is just equivalent to taking the likelihood function
> and arranging for it to be evaluated in an environment containing
> the data?  That way if "nllmaker" below were just a formula
> or a log-likelihood function it could still work ...

I don't really agree with this.
I found really natural writing functions which builds other functions,
for handling
in a clean way the data-dependency problem, much more than
manipilating function environments.
As a useR, I think that if I'm able to write a likelihood function myself:

data <- whatever
negloglik <- function(theta)
  a + very * complicated / function - of %% theta %*% and %o% data

to be used in mle, I'm also good at abstracting it a bit this way:

nllmaker <- function(data)
  function(theta)
    a + very * complicated / function - of %% theta %*% and %o% data

negloglik <- nllmaker(whatever),

don't you think? I use this kind of tricks routinely for simulations.
In general, I think it should be more emphatized functional style in R coding.
In fact, I like a lot the recent introduction of some higher order
functions in the base package (Reduce, Filter, Map).

Bests,
Antonio, Fabio.
>
>   [snip]
> > Both (simple) bootstrapping and (simple leave-one-out) crossvalidation
> > require a data structure with a notion of cases, which is much more
> > restrictive than the conext in which mle can be used.  A more ngeneric
> > aproach to bootstrapping that might fit closer to the level of
> > generality of mle might be parameterized in terms of a negative log
> > likelihood constructor, a starting value constructor, and a resampling
> > function, with a single iteration implemented soemthing like
> >
> >     mleboot1 <- function(nllmaker, start, esample)  {
> >     newdata <- resample()
> >     newstart <- do.call(start, newdata)
> >     nllfun <- do.call(nllmaker, newdata)
> >     mle(fnllfun, start = newstart)
> >     }
> >
> > This would leave decisions on the resampling method and data structure
> > up to the user. Somehing similar could be done with K-fold CV.
> >
> > luke
> >
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iD8DBQFHWcS1c5UpGjwzenMRAig2AJ9iTzhI1p8tBb7Q15jgT4nA+Zds+gCgggc2
> sI2que28Hl1M5cVGa+anEL0=
> =hCiS
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From p.dalgaard at biostat.ku.dk  Sat Dec  8 01:56:23 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 08 Dec 2007 01:56:23 +0100
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
	<Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
Message-ID: <4759EBB7.5040608@biostat.ku.dk>

Luke Tierney wrote:

 [misc snippage]
>>
>> But I'd prefer to avoid the necessity for users to manipulate the
>> environment of a function.  I think the pattern
>>
>> model( f, data=d )
>
> For working at the general likelihood I think is is better to
> encourage the approach of definign likelihood constructor functions.
> The problem with using f, data is that you need to mathc the names
> used in f and in data, so either you have to explicitly write out f
> with the names you have in data or you have to modify data to use the
> names f likes -- in the running example think
>
>     f <- function(lambda) -sum(dpois(x, lambda, log=T))
>     d <- data.frame(y=rpois(10000, 12.34))
>
> somebody has to connext up the x in f with the y in d. 
[more snippage]

That's not really worse than having to match the names in a model 
formula to the names of the data frame in lm(), is it?

The thing that I'm looking for in these matters is a structure which 
allows us to operate on likelihood functions in a rational way, e.g. 
reparametrize them, join multiple likelihoods with some parameters in 
common, or integrate them. The join operation is illustrative: You can 
easily do 

negljoint <- function(alpha, beta, gamma, delta)
    negl1(alpha, beta, gamma) + negl2(beta, gamma, delta)

and with a bit of diligence, this could be the result of Join(negl1, 
negl2). But if the convention is that likelihods have their their data 
as an argument, you also need to also automatically define a data 
argument fot negljoint, (presumably a list of two) and organize that the 
calls to negl1 and negl2 contains the appropriate subdata. It is the 
sort of thing that might be doable, but you'd rather do without.

-pd

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jayemerson at gmail.com  Sat Dec  8 22:12:41 2007
From: jayemerson at gmail.com (Jay Emerson)
Date: Sat, 8 Dec 2007 16:12:41 -0500
Subject: [Rd] NAMESPACE choices for exporting S4 methods
Message-ID: <d4588dec0712081312u7c7c3393ibaa90c5f5cba16d9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071208/b701f3ed/attachment.pl 

From ripley at stats.ox.ac.uk  Sat Dec  8 23:16:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 8 Dec 2007 22:16:20 +0000 (GMT)
Subject: [Rd] NAMESPACE choices for exporting S4 methods
In-Reply-To: <d4588dec0712081312u7c7c3393ibaa90c5f5cba16d9@mail.gmail.com>
References: <d4588dec0712081312u7c7c3393ibaa90c5f5cba16d9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712082149540.3635@gannet.stats.ox.ac.uk>

On Sat, 8 Dec 2007, Jay Emerson wrote:

> We are building a package, and want to create S4 methods for both head and
> mean for our own BigMatrix class.  Following the recommendation in "Writing
> R Extensions" we use exportMethods instead of export in NAMESPACE (this is
> described as being "clearer").  This works for head, but not for mean.
> Obviously we importFrom(utils, head), but don't need  to do this for mean,
> which is imported automatically from base.

And what is the error message?

> If we export(mean) rather than exportMethods(mean), it works as intended.
> A similar problem arises for a new generic function and an associated
> method, colmean, where the use of exportMethods(colmean) fails, but
> export(colmean) succeeds.
>
> We can build and use the package by using export instead of exportMethods,
> but we suspect that we're missing something that might be important to
> understand.
>
> Any hints or links to something we missed would be appreciated.

I know there are problems if you define a generic and no methods in a 
package (that is what stats4 does for AIC), but it doesn't sound as if 
that is what you are doing.  (Since the introduction of implicit generics 
- which may well apply to your mean() - it is possible to define a generic 
in a package without any methods stored there, not even a default method.)

I saw nothing in your description that is different from several other 
pacakges.  Without either the error messages or an example, we are reduced 
to guessing.  Can you make a minimal version available to us to look at?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at stat.uiowa.edu  Sun Dec  9 00:15:09 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sat, 8 Dec 2007 17:15:09 -0600 (CST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4759C4B5.7030803@ufl.edu>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
	<Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
	<4759C4B5.7030803@ufl.edu>
Message-ID: <Pine.OSX.4.64.0712081710150.1558@luke-tierneys-computer-3.local>

On Fri, 7 Dec 2007, Ben Bolker wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Luke Tierney wrote:
>> On Fri, 7 Dec 2007, Duncan Murdoch wrote:
>>
>>
>>
>> For working at the general likelihood I think is is better to
>> encourage the approach of definign likelihood constructor functions.
>> The problem with using f, data is that you need to mathc the names
>> used in f and in data, so either you have to explicitly write out f
>> with the names you have in data or you have to modify data to use the
>> names f likes -- in the running example think
>>
>>     f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>     d <- data.frame(y=rpois(10000, 12.34))
>>
>> somebody has to connext up the x in f with the y in d. With a negative
>> log likelihood constructor defines, for example, as
>>
>>     makePoisonNegLogLikelihood <- function(x)
>>         function(lambda) -sum(dpois(x, lambda, log=T))
>>
>> this happens naturally with
>>
>>     makePoisonNegLogLikelihood(d$y)
>>
>>
>
>  I hate to sound like a jerk, but I do hope that in the end we come
> up with a solution that will still be accessible to people who don't
> quite have the concept of writing functions to produce functions.

Any programming language has some idioms and conventions that are
worth lerning if you are going to make most effective use of the
language.  R is no exception.  One can use R as interactive C but the
results aren't likely to be too satisfactory.  Three ideas worth
learning in R (not an exclusive list) are how to use vectorized
arithmetic, how to use the apply family of functions, and how to take
advantage of lexical scope.  None of hese is hard to learn, and basic
lexical scope may be the easiest of the three, and the small
investment will pay off.

Best,

luke

> I
> feel it is "natural" for people who have multiple data sets to have the
> variables named similarly in different data sets.  All of the
> constructor stuff is still accessible to anyone who wants to use the
> function that way ... is there any way to do a cheesy default
> constructor that is just equivalent to taking the likelihood function
> and arranging for it to be evaluated in an environment containing
> the data?  That way if "nllmaker" below were just a formula
> or a log-likelihood function it could still work ...
>
>  [snip]
>> Both (simple) bootstrapping and (simple leave-one-out) crossvalidation
>> require a data structure with a notion of cases, which is much more
>> restrictive than the conext in which mle can be used.  A more ngeneric
>> aproach to bootstrapping that might fit closer to the level of
>> generality of mle might be parameterized in terms of a negative log
>> likelihood constructor, a starting value constructor, and a resampling
>> function, with a single iteration implemented soemthing like
>>
>>     mleboot1 <- function(nllmaker, start, esample)  {
>>     newdata <- resample()
>>     newstart <- do.call(start, newdata)
>>     nllfun <- do.call(nllmaker, newdata)
>>     mle(fnllfun, start = newstart)
>>     }
>>
>> This would leave decisions on the resampling method and data structure
>> up to the user. Somehing similar could be done with K-fold CV.
>>
>> luke
>>
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iD8DBQFHWcS1c5UpGjwzenMRAig2AJ9iTzhI1p8tBb7Q15jgT4nA+Zds+gCgggc2
> sI2que28Hl1M5cVGa+anEL0=
> =hCiS
> -----END PGP SIGNATURE-----
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Sun Dec  9 00:38:48 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sat, 8 Dec 2007 17:38:48 -0600 (CST)
Subject: [Rd] suggested modification to the 'mle' documentation?
In-Reply-To: <4759EBB7.5040608@biostat.ku.dk>
References: <4758338E.3080802@pdf.com> <47587F30.6020701@biostat.ku.dk>
	<971536df0712061512k47f89415v5146c61b346239b8@mail.gmail.com>
	<14206100.post@talk.nabble.com> <4759463E.3010904@biostat.ku.dk>
	<47594DEA.8080100@stats.uwo.ca>
	<Pine.OSX.4.64.0712071446100.910@luke-tierneys-computer-3.local>
	<4759EBB7.5040608@biostat.ku.dk>
Message-ID: <Pine.OSX.4.64.0712081717530.1558@luke-tierneys-computer-3.local>

On Sat, 8 Dec 2007, Peter Dalgaard wrote:

> Luke Tierney wrote:
>
> [misc snippage]
>>> 
>>> But I'd prefer to avoid the necessity for users to manipulate the
>>> environment of a function.  I think the pattern
>>> 
>>> model( f, data=d )
>> 
>> For working at the general likelihood I think is is better to
>> encourage the approach of definign likelihood constructor functions.
>> The problem with using f, data is that you need to mathc the names
>> used in f and in data, so either you have to explicitly write out f
>> with the names you have in data or you have to modify data to use the
>> names f likes -- in the running example think
>>
>>     f <- function(lambda) -sum(dpois(x, lambda, log=T))
>>     d <- data.frame(y=rpois(10000, 12.34))
>> 
>> somebody has to connext up the x in f with the y in d. 
> [more snippage]
>
> That's not really worse than having to match the names in a model formula to 
> the names of the data frame in lm(), is it?

Yes and no.

If the likelihood is simple engough to include in line, is in

     d <- data.frame(y=rpois(100,12.34))
     mle(function(lambda) -sum(dpois(d$y, lambda, log = TRUE)),
         start = list(lambda=10))

or neaarly in line, eg in a with or local construct, like

     with(d, {
         f <- function(lambda) -sum(dpois(y, lambda, log = TRUE))
         mle(f, start = list(lambda=10))
     })

or

     local({
         y <- d$y
         f <- function(lambda) -sum(dpois(y, lambda, log = TRUE))
         mle(f, start = list(lambda=10))
     })

then I think it is essentially the same.  But if the function is
complex enough that you will want to define and debug it separately
then you will probably want to be able to reuse your code directly,
not with copy-paste-edit.  At that point things are different.

In a sense this difference also exists with model formulas as well. We
usually write formular in line, rather than something like

     f <- y ~ x
     lm(f)

With simple formulalas that is reasonable. But it would be nice to be
able to abstract out common patterns of more complex fomulas for
simple reuse. A simple-minded example might be to be able to define a
splitPlot formula operator so one can write

     yield ~ splitPlot(whole = fertilizer, sub = variety)

This sort of thing would become more useful in more complicated
multi-level models.  I could be wrong but I don't think BUGS has the
ability to abstract out submodel patterns in this way.  Don't know if
any of the other multi-level modeling systems provide this.  Might be
worth looking into; it's not unrelated to the issues you raise below.

luke

>
> The thing that I'm looking for in these matters is a structure which allows 
> us to operate on likelihood functions in a rational way, e.g. reparametrize 
> them, join multiple likelihoods with some parameters in common, or integrate 
> them. The join operation is illustrative: You can easily do 
> negljoint <- function(alpha, beta, gamma, delta)
>   negl1(alpha, beta, gamma) + negl2(beta, gamma, delta)
>
> and with a bit of diligence, this could be the result of Join(negl1, negl2). 
> But if the convention is that likelihods have their their data as an 
> argument, you also need to also automatically define a data argument fot 
> negljoint, (presumably a list of two) and organize that the calls to negl1 
> and negl2 contains the appropriate subdata. It is the sort of thing that 
> might be doable, but you'd rather do without.
>
> -pd
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jayemerson at gmail.com  Sun Dec  9 02:59:54 2007
From: jayemerson at gmail.com (Jay Emerson)
Date: Sat, 8 Dec 2007 20:59:54 -0500
Subject: [Rd] NAMESPACE choices for exporting S4 methods
In-Reply-To: <d4588dec0712081312u7c7c3393ibaa90c5f5cba16d9@mail.gmail.com>
References: <d4588dec0712081312u7c7c3393ibaa90c5f5cba16d9@mail.gmail.com>
Message-ID: <d4588dec0712081759p6b4407cdp1b47587cc416359f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071208/a586d526/attachment.pl 

From bolker at ufl.edu  Sun Dec  9 05:12:06 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 08 Dec 2007 23:12:06 -0500
Subject: [Rd] buglet in curve?
Message-ID: <475B6B16.6040909@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  Symptoms: curve with log x axis gets the wrong
x limits (in 2.6.1, I believe introduced in this version).

 Credit goes to Mike McCoy for detecting the problem.

  Demonstration:

x = 1:5
plot(x,5*exp(-x),xlim=c(0.1,1000),log="x")
xvec = 10^seq(-1,3,length=100)
lines(xvec,5*exp(-xvec))
curve(5*exp(-x),add=TRUE,col=2,lwd=3)


   I believe the problem arises from this fix:

    o	curve() with unspecified 'from', 'to' and 'xlim' now reuses the
	previous x limits, and not slightly larger ones.

 and I believe the solution is to replace this ...

   if (is.null(xlim))
        delayedAssign("lims", {
            pu <- par("usr")[1:2]
            ll <- if (par("xlog"))
                10^pu
            else pu
            if (par("xaxs") == "r")
                extendrange(ll, f = -1/27)
            else ll
        })


 with this ...

   if (is.null(xlim))
        delayedAssign("lims", {
            pu <- par("usr")[1:2]
             if (par("xaxs") == "r")
                pu <- extendrange(pu, f = -1/27)
            ll <- if (par("xlog"))
                10^pu
            else pu
            ll
        })

  i.e., extend pu, not ll ...

  cheers
    Ben Bolker







-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHW2sWc5UpGjwzenMRApDiAJ9VNtfvdFBbFQvF6Nt5BrgkvcsunACfZFeg
eHBtIBAxrRvj1LpRkT6wdgo=
=ZFiA
-----END PGP SIGNATURE-----


From bolker at ufl.edu  Sun Dec  9 06:47:57 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 09 Dec 2007 00:47:57 -0500
Subject: [Rd] writing S4 documentation
Message-ID: <475B818D.2030709@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  I am getting horribly snarled trying to write S4 documentation.
What is the best existing reference?  I've been looking at
help("Documentation",package="methods") (which is where R-exts
points to).  Does http://bioinf.wehi.edu.au/limma/Rdocs.html exist
anywhere, any more?

  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHW4GNc5UpGjwzenMRAhVbAJoCtN0kyUmiSVSwW3cjQYQmgQd0qACdGigo
LMMGnNdlodrCETGuIWunTd4=
=JFws
-----END PGP SIGNATURE-----


From jfox at mcmaster.ca  Sun Dec  9 15:02:06 2007
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 9 Dec 2007 09:02:06 -0500
Subject: [Rd] Using Fortran 95 in an R package?
Message-ID: <6buhm2$4vpm9n@toip7.srvr.bell.ca>

Dear R-devel list members,

What's the best current advice about writing Fortran code for use in R
packages? The Writing R Extensions manual still says that the .Fortran
interface is primarily intended for FORTRAN 77 code. In particular, are
there portability issues if I use Fortran 95 in a package? For example, I
see that Rtools for Windows now include the gfortran compiler.

(I know that this question has come up before, but not, as far as I can see,
in the last year.)

Thanks,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox


From ripley at stats.ox.ac.uk  Sun Dec  9 19:04:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 9 Dec 2007 18:04:44 +0000 (GMT)
Subject: [Rd] Using Fortran 95 in an R package?
In-Reply-To: <6buhm2$4vpm9n@toip7.srvr.bell.ca>
References: <6buhm2$4vpm9n@toip7.srvr.bell.ca>
Message-ID: <Pine.LNX.4.64.0712091753320.30262@gannet.stats.ox.ac.uk>

On Sun, 9 Dec 2007, John Fox wrote:

> Dear R-devel list members,
>
> What's the best current advice about writing Fortran code for use in R
> packages? The Writing R Extensions manual still says that the .Fortran
> interface is primarily intended for FORTRAN 77 code. In particular, are
> there portability issues if I use Fortran 95 in a package? For example, I
> see that Rtools for Windows now include the gfortran compiler.

Yes, there are still portability issues.  We do still see quite a few 
people using gcc3/g77 (especially on older Linux and commercial Unices) 
and there are further issues if you make use of subprogram names 
containing underlines.  We don't distribute a cross-building solution for 
Windows using gfortran (although one can be built, it will not be mature
until gcc 4.3.x is out).

However, I would not let that deter you: just use .f95 extensions on the 
Fortran 95 files and avoid underlines.  For Windows users you are 
effectively requiring R >= 2.6.0.

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Sun Dec  9 20:38:53 2007
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 9 Dec 2007 14:38:53 -0500
Subject: [Rd] Using Fortran 95 in an R package?
In-Reply-To: <Pine.LNX.4.64.0712091753320.30262@gannet.stats.ox.ac.uk>
Message-ID: <6bplrs$5g1tjp@toip5.srvr.bell.ca>

Dear Brian,

Thank you for this.

John

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> Sent: Sunday, December 09, 2007 1:05 PM
> To: John Fox
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Using Fortran 95 in an R package?
> 
> On Sun, 9 Dec 2007, John Fox wrote:
> 
> > Dear R-devel list members,
> >
> > What's the best current advice about writing Fortran code 
> for use in R 
> > packages? The Writing R Extensions manual still says that 
> the .Fortran 
> > interface is primarily intended for FORTRAN 77 code. In particular, 
> > are there portability issues if I use Fortran 95 in a package? For 
> > example, I see that Rtools for Windows now include the 
> gfortran compiler.
> 
> Yes, there are still portability issues.  We do still see 
> quite a few people using gcc3/g77 (especially on older Linux 
> and commercial Unices) and there are further issues if you 
> make use of subprogram names containing underlines.  We don't 
> distribute a cross-building solution for Windows using 
> gfortran (although one can be built, it will not be mature 
> until gcc 4.3.x is out).
> 
> However, I would not let that deter you: just use .f95 
> extensions on the Fortran 95 files and avoid underlines.  For 
> Windows users you are effectively requiring R >= 2.6.0.
> 
> Brian
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From david at unusualsolutionsthatwork.com  Sun Dec  9 22:41:46 2007
From: david at unusualsolutionsthatwork.com (David C. Norris)
Date: Sun, 09 Dec 2007 13:41:46 -0800
Subject: [Rd] List comprehensions for R
Message-ID: <475C611A.8000302@unusualsolutionsthatwork.com>

Below is code that introduces a list comprehension syntax into R, 
allowing expressions like:

 > .[ sin(x) ~ x <- (0:11)/11 ]
 [1] 0.00000000 0.09078392 0.18081808 0.26935891 0.35567516 0.43905397
 [7] 0.51880673 0.59427479 0.66483486 0.72990422 0.78894546 0.84147098
 > .[ .[x*y ~ x <- 0:3] ~ y <- 0:4]
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    1    2    3    4
[3,]    0    2    4    6    8
[4,]    0    3    6    9   12
 > .[ .[x+y ~ x <- 0:y] ~ y <- 0:4]
[[1]]
[1] 0

[[2]]
[1] 1 2

[[3]]
[1] 2 3 4

[[4]]
[1] 3 4 5 6

[[5]]
[1] 4 5 6 7 8

 > .[ x*y ~ {x <- 1:4; y<-1:x} ]
 [1]  1  2  4  3  6  9  4  8 12 16

These constructions are supported by the following code.

Regards,
David

##
## Define syntax for list/vector/array comprehensions
##

. <<- structure(NA, class="comprehension")

comprehend <- function(expr, vars, seqs, comprehension=list()){
  if(length(vars)==0) # base case
    comprehension[[length(comprehension)+1]] <- eval(expr)
  else
    for(elt in eval(seqs[[1]])){
      assign(vars[1], elt, inherits=TRUE)
      comprehension <- comprehend(expr, vars[-1], seqs[-1], comprehension)
    }
  comprehension
}

## Support general syntax like .[{exprs} ~ {generators}]
"[.comprehension" <- function(x, f){
  f <- substitute(f)
  ## To allow omission of braces around a lone comprehension generator,
  ## as in 'expr ~ var <- seq' we make allowances for two shapes of f:
  ##
  ## (1)    (`<-` (`~` expr
  ##                   var)
  ##              seq)
  ## and
  ##
  ## (2)    (`~` expr
  ##             (`{` (`<-` var1 seq1)
  ##                  (`<-` var2 seq2)
  ##                      ...
  ##                  (`<-` varN <- seqN)))
  ##
  ## In the former case, we set gens <- list(var <- seq), unifying the
  ## treatment of both shapes under the latter, more general one.
  syntax.error <- "Comprehension expects 'expr ~ {x1 <- seq1; ... ; xN 
<- seqN}'."
  if(!is.call(f) || (f[[1]]!='<-' && f[[1]]!='~'))
    stop(syntax.error)
  if(is(f,'<-')){ # (1)
    lhs <- f[[2]]
    if(!is.call(lhs) || lhs[[1]] != '~')
      stop(syntax.error)
    expr <- lhs[[2]]
    var <- as.character(lhs[[3]])
    seq <- f[[3]]
    gens <- list(call('<-', var, seq))
  } else { # (2)
    expr <- f[[2]]
    gens <- as.list(f[[3]])[-1]
    if(any(lapply(gens, class) != '<-'))
      stop(syntax.error)
  }
  ## Fill list comprehension .LC
  vars <- as.character(lapply(gens, function(g) g[[2]]))
  seqs <- lapply(gens, function(g) g[[3]])
  .LC <- comprehend(expr, vars, seqs)
  ## Provided the result is rectangular, convert it to a vector or array
  ## TODO: Extend to handle .LC structures more than 2-deep.
  if(!length(.LC))
    return(.LC)
  dim1 <- dim(.LC[[1]])
  if(is.null(dim1)){
    lengths <- sapply(.LC, length)
    if(all(lengths == lengths[1])){ # rectangular
      .LC <- unlist(.LC)
      if(lengths[1] > 1) # matrix
        dim(.LC) <- c(lengths[1], length(lengths))
    } else { # ragged
      # leave .LC as a list
    }
  } else { # elements of .LC have dimension
    dim <- c(dim1, length(.LC))
    .LC <- unlist(.LC)
    dim(.LC) <- dim
  }
  .LC
}


From ggrothendieck at gmail.com  Sun Dec  9 23:26:44 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 9 Dec 2007 17:26:44 -0500
Subject: [Rd] List comprehensions for R
In-Reply-To: <475C611A.8000302@unusualsolutionsthatwork.com>
References: <475C611A.8000302@unusualsolutionsthatwork.com>
Message-ID: <971536df0712091426i51e9161brbf3fff9550d57645@mail.gmail.com>

That seems quite nice.

Note that there has been some related code posted.  See:
http://tolstoy.newcastle.edu.au/R/help/03b/6406.html
which discusses some R idioms for list comprehensions.

Also the gsubfn package has some functionality in this direction.  We
preface any function with fn$ to allow functions in its arguments
to be specified as formulas.  Its more R-ish than your code and
applies to more than just list comprehensions while your code is
more faithful to list comprehensions.

> library(gsubfn)
> fn$sapply(0:11/11, ~ sin(x))
 [1] 0.00000000 0.09078392 0.18081808 0.26935891 0.35567516 0.43905397
 [7] 0.51880673 0.59427479 0.66483486 0.72990422 0.78894546 0.84147098
> fn$sapply(0:4, y ~ fn$sapply(0:3, x ~ x*y))
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    1    2    3    4
[3,]    0    2    4    6    8
[4,]    0    3    6    9   12
> fn$sapply(0:4, y ~ fn$sapply(0:y, x ~ x*y))
[[1]]
[1] 0

[[2]]
[1] 0 1

[[3]]
[1] 0 2 4

[[4]]
[1] 0 3 6 9

[[5]]
[1]  0  4  8 12 16

> unlist(fn$sapply(1:4, y ~ fn$sapply(1:y, x ~ x*y)))
 [1]  1  2  4  3  6  9  4  8 12 16


On Dec 9, 2007 4:41 PM, David C. Norris
<david at unusualsolutionsthatwork.com> wrote:
> Below is code that introduces a list comprehension syntax into R,
> allowing expressions like:
>
>  > .[ sin(x) ~ x <- (0:11)/11 ]
>  [1] 0.00000000 0.09078392 0.18081808 0.26935891 0.35567516 0.43905397
>  [7] 0.51880673 0.59427479 0.66483486 0.72990422 0.78894546 0.84147098
>  > .[ .[x*y ~ x <- 0:3] ~ y <- 0:4]
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    0    0    0    0    0
> [2,]    0    1    2    3    4
> [3,]    0    2    4    6    8
> [4,]    0    3    6    9   12
>  > .[ .[x+y ~ x <- 0:y] ~ y <- 0:4]
> [[1]]
> [1] 0
>
> [[2]]
> [1] 1 2
>
> [[3]]
> [1] 2 3 4
>
> [[4]]
> [1] 3 4 5 6
>
> [[5]]
> [1] 4 5 6 7 8
>
>  > .[ x*y ~ {x <- 1:4; y<-1:x} ]
>  [1]  1  2  4  3  6  9  4  8 12 16
>
> These constructions are supported by the following code.
>
> Regards,
> David
>
> ##
> ## Define syntax for list/vector/array comprehensions
> ##
>
> . <<- structure(NA, class="comprehension")
>
> comprehend <- function(expr, vars, seqs, comprehension=list()){
>  if(length(vars)==0) # base case
>    comprehension[[length(comprehension)+1]] <- eval(expr)
>  else
>    for(elt in eval(seqs[[1]])){
>      assign(vars[1], elt, inherits=TRUE)
>      comprehension <- comprehend(expr, vars[-1], seqs[-1], comprehension)
>    }
>  comprehension
> }
>
> ## Support general syntax like .[{exprs} ~ {generators}]
> "[.comprehension" <- function(x, f){
>  f <- substitute(f)
>  ## To allow omission of braces around a lone comprehension generator,
>  ## as in 'expr ~ var <- seq' we make allowances for two shapes of f:
>  ##
>  ## (1)    (`<-` (`~` expr
>  ##                   var)
>  ##              seq)
>  ## and
>  ##
>  ## (2)    (`~` expr
>  ##             (`{` (`<-` var1 seq1)
>  ##                  (`<-` var2 seq2)
>  ##                      ...
>  ##                  (`<-` varN <- seqN)))
>  ##
>  ## In the former case, we set gens <- list(var <- seq), unifying the
>  ## treatment of both shapes under the latter, more general one.
>  syntax.error <- "Comprehension expects 'expr ~ {x1 <- seq1; ... ; xN
> <- seqN}'."
>  if(!is.call(f) || (f[[1]]!='<-' && f[[1]]!='~'))
>    stop(syntax.error)
>  if(is(f,'<-')){ # (1)
>    lhs <- f[[2]]
>    if(!is.call(lhs) || lhs[[1]] != '~')
>      stop(syntax.error)
>    expr <- lhs[[2]]
>    var <- as.character(lhs[[3]])
>    seq <- f[[3]]
>    gens <- list(call('<-', var, seq))
>  } else { # (2)
>    expr <- f[[2]]
>    gens <- as.list(f[[3]])[-1]
>    if(any(lapply(gens, class) != '<-'))
>      stop(syntax.error)
>  }
>  ## Fill list comprehension .LC
>  vars <- as.character(lapply(gens, function(g) g[[2]]))
>  seqs <- lapply(gens, function(g) g[[3]])
>  .LC <- comprehend(expr, vars, seqs)
>  ## Provided the result is rectangular, convert it to a vector or array
>  ## TODO: Extend to handle .LC structures more than 2-deep.
>  if(!length(.LC))
>    return(.LC)
>  dim1 <- dim(.LC[[1]])
>  if(is.null(dim1)){
>    lengths <- sapply(.LC, length)
>    if(all(lengths == lengths[1])){ # rectangular
>      .LC <- unlist(.LC)
>      if(lengths[1] > 1) # matrix
>        dim(.LC) <- c(lengths[1], length(lengths))
>    } else { # ragged
>      # leave .LC as a list
>    }
>  } else { # elements of .LC have dimension
>    dim <- c(dim1, length(.LC))
>    .LC <- unlist(.LC)
>    dim(.LC) <- dim
>  }
>  .LC
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Mon Dec 10 09:32:10 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Dec 2007 09:32:10 +0100
Subject: [Rd] buglet in curve?
In-Reply-To: <475B6B16.6040909@ufl.edu>
References: <475B6B16.6040909@ufl.edu>
Message-ID: <18268.63882.268683.604687@stat.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Sat, 08 Dec 2007 23:12:06 -0500 writes:

    BB> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1


    BB>   Symptoms: curve with log x axis gets the wrong x
    BB> limits (in 2.6.1, I believe introduced in this version).

    BB>  Credit goes to Mike McCoy for detecting the problem.

    BB>   Demonstration:

    BB> x = 1:5 plot(x,5*exp(-x),xlim=c(0.1,1000),log="x") xvec
    BB> = 10^seq(-1,3,length=100) lines(xvec,5*exp(-xvec))
    BB> curve(5*exp(-x),add=TRUE,col=2,lwd=3)


    BB>    I believe the problem arises from this fix:

    BB>     o curve() with unspecified 'from', 'to' and 'xlim'
    BB> now reuses the previous x limits, and not slightly
    BB> larger ones.

    BB>  and I believe the solution is to replace this ...

   [    .....   ]

Thank you, Ben  (and Mike).
That's indeed a new buglet, and you are even right about
when it happened.
Mea culpa.

    BB>   cheers Ben Bolker

 {aaaah, it feels good to get a message from you without the
  appended Nabble spam :-)}

Regards,
Martin


From babel at centrum.sk  Sun Dec  9 22:45:23 2007
From: babel at centrum.sk (babel at centrum.sk)
Date: Sun,  9 Dec 2007 22:45:23 +0100 (CET)
Subject: [Rd] Package tseries Garch (PR#10504)
Message-ID: <20071209214523.D5D3B282EFF7@mail.pubhealth.ku.dk>

Full_Name: Jan Troger
Version: R version 2.6.0 (2007-10-03)
OS: Windows
Submission from: (NULL) (158.193.95.57)


Version of tseries is : 0.10-12 
The example(garch) doesnt work
This >>:
n <- 1100
a <- c(0.1, 0.5, 0.2) # ARCH(2) coefficients
e <- rnorm(n)
x <- double(n)
x[1:2] <- rnorm(2, sd = sqrt(a[1]/(1.0-a[2]-a[3])))
for(i in 3:n) # Generate ARCH(2) process
{
x[i] <- e[i]*sqrt(a[1]+a[2]*x[i-1]^2+a[3]*x[i-2]^2)
}
x <- ts(x[101:1100])
x.arch <- garch(x, order = c(0,2)) # Fit ARCH(2)
summary(x.arch) # Diagnostic tests
plot(x.arch)

<<

I have the same problem as it was mentioned in message id=2302, but the result
is a little bit different. The last 2 rows are :

garch> x.arch <- garch(x, order = c(0,2))  # Fit ARCH(2) 

 ***** ESTIMATION WITH ANALYTICAL GRADIENT ***** 

and I have wait 20 minutes and nothing happened.Only the processor was busy on
100%
I try to change data length, also add itmax=10 , but still with the same
result.

Thanks in advance


From ripley at stats.ox.ac.uk  Mon Dec 10 11:50:27 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 10 Dec 2007 11:50:27 +0100 (CET)
Subject: [Rd] Package tseries Garch (PR#10504)
Message-ID: <20071210105027.5F2F8282EFF6@mail.pubhealth.ku.dk>

This is a known problem with a contributed package, so please contact the 
maintainer.  It is not a bug in R, so not appropriate to R-bugs.

The example works in Rterm: the problem is the use of Fortran I/O, which 
has never been supported for consoles and nowadays hangs in Rgui.  This 
has been discussed several times before on the lists, and 
RSiteSearch("tseries hangs") would have found e.g.

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/113444.html


On Sun, 9 Dec 2007, babel at centrum.sk wrote:

> Full_Name: Jan Troger
> Version: R version 2.6.0 (2007-10-03)
> OS: Windows
> Submission from: (NULL) (158.193.95.57)
>
>
> Version of tseries is : 0.10-12
> The example(garch) doesnt work
> This >>:
> n <- 1100
> a <- c(0.1, 0.5, 0.2) # ARCH(2) coefficients
> e <- rnorm(n)
> x <- double(n)
> x[1:2] <- rnorm(2, sd = sqrt(a[1]/(1.0-a[2]-a[3])))
> for(i in 3:n) # Generate ARCH(2) process
> {
> x[i] <- e[i]*sqrt(a[1]+a[2]*x[i-1]^2+a[3]*x[i-2]^2)
> }
> x <- ts(x[101:1100])
> x.arch <- garch(x, order = c(0,2)) # Fit ARCH(2)
> summary(x.arch) # Diagnostic tests
> plot(x.arch)
>
> <<
>
> I have the same problem as it was mentioned in message id=2302, but the result
> is a little bit different. The last 2 rows are :
>
> garch> x.arch <- garch(x, order = c(0,2))  # Fit ARCH(2)
>
> ***** ESTIMATION WITH ANALYTICAL GRADIENT *****
>
> and I have wait 20 minutes and nothing happened.Only the processor was busy on
> 100%
> I try to change data length, also add itmax=10 , but still with the same
> result.
>
> Thanks in advance
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Mon Dec 10 16:05:09 2007
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Mon, 10 Dec 2007 16:05:09 +0100 (CET)
Subject: [Rd] bug in by.data.frame, R-2.6.1 (PR#10506)
Message-ID: <20071210150509.3FAD42832EC5@mail.pubhealth.ku.dk>

by() fails for 1-column matrices and dataframes:

X <- data.frame(a=1:10)
g <- gl(2,5)
by(X, g, colMeans)


Suggested fix:

--- by-old.R    2007-12-10 15:26:22.501086600 +0100
+++ by.R        2007-12-10 15:25:58.390477200 +0100
@@ -26,7 +26,7 @@
          IND[[1]] <- INDICES
          names(IND) <- deparse(substitute(INDICES))[1]
      } else IND <- INDICES
-    FUNx <- function(x) FUN(data[x,], ...)
+    FUNx <- function(x) FUN(data[x, , drop=FALSE], ...)
      nd <- nrow(data)
      ans <- eval(substitute(tapply(1:nd, IND, FUNx)), data)
      attr(ans, "call") <- match.call()



                _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          6.1
year           2007
month          11
day            26
svn rev        43537
language       R
version.string R version 2.6.1 (2007-11-26)


Uwe Ligges


From kmiddel at gmail.com  Mon Dec 10 19:55:10 2007
From: kmiddel at gmail.com (thalarctos)
Date: Mon, 10 Dec 2007 10:55:10 -0800 (PST)
Subject: [Rd]  problem using "by" with custom function?
Message-ID: <14259137.post@talk.nabble.com>


Hi,
I'm relatively new to R and R development, so please forgive me for any
obvious errors.  

What I am trying to do is use the command dpik within the package KernSmooth
to estimate bandwidth parameters for GPS telemetry data.  I have been able
to get this to work on a case by case basis without any problem, but would
like to extend this so that I can batch process many different animals for
pre-determined time periods (months of the year).  I have written a function
that first standardises the data based on the X and Y values, then uses dpik
to calculate the bandwidth for each variable.  The result is the average of
the X and Y estimates.  I then use the command "by" to run the function on a
dataframe which has X and Y in columns 5 and 6, and a grouping variable
"animonth" to individualise the data by animal and month.  when I run the by
command on a small data table (only a few different levels of animonth) it
works perfectly.  

The problem is when I try to run it on all the data (or more than a few
levels) at once.  I get the error posted below.  However, if I run a simple
embedded function like summary within by, there is no error.  Can anyone
provide me with some assistance in interpreting this error?  Any suggestions
on alternative commands to use would be appreciated as well, as I'm not
commited to using by, it was just the one that seemed to work.

Data table example:
    uniqid  animal month animonth       x        y
1   11748   W079    12  W079_12 1494206 12134126
2   11749   W079    12  W079_12 1494123 12134051
3   11750   W079    12  W079_12 1493639 12133705
4   11751   W079    12  W079_12 1493353 12135892
5   11752   W079    12  W079_12 1495157 12137797
6   11753   W079    12  W079_12 1498039 12132112
7   11754   W079    12  W079_12 1497991 12131842
8   11755   W079    12  W079_12 1497918 12131631
9   11756   W079    12  W079_12 1498019 12131638
10  11757   W079    12  W079_12 1498017 12131633

Function for calculating bandwidth:
> kern.est
function(data) {
x.var <- (data$x / sd(data$x)); y.var <- (data$y / sd(data$y))
dpik.x <- dpik(x.var, gridsize = round((max(data$x) - min(data$x))/100))
dpik.y <- dpik(y.var, gridsize = round((max(data$y) - min(data$y))/100))
bw.avg <- ((dpik.x + dpik.y)/2)


by command used:
junk3 <- by(w079.all[,5:6], w079.all$animonth, kern.est)

output from small files (only a few levels of animonth):
w079.all$animonth: W079_1
[1] 0.2117635
----------------------------------------------------------------------------------------------------------------- 
w079.all$animonth: W079_12
[1] 0.2837849

Error on larger files:
Error in rep(0, P - 2 * L - 1) : invalid 'times' argument

-- 
View this message in context: http://www.nabble.com/problem-using-%22by%22-with-custom-function--tp14259137p14259137.html
Sent from the R devel mailing list archive at Nabble.com.


From kmiddel at gmail.com  Mon Dec 10 19:57:23 2007
From: kmiddel at gmail.com (thalarctos)
Date: Mon, 10 Dec 2007 10:57:23 -0800 (PST)
Subject: [Rd]  problem using "by" with custom function?
Message-ID: <14259137.post@talk.nabble.com>


Hi,
I'm relatively new to R and R development, so please forgive me for any
obvious errors.  

What I am trying to do is use the command dpik within the package KernSmooth
to estimate bandwidth parameters for GPS telemetry data.  I have been able
to get this to work on a case by case basis without any problem, but would
like to extend this so that I can batch process many different animals for
pre-determined time periods (months of the year).  I have written a function
that first standardises the data based on the X and Y values, then uses dpik
to calculate the bandwidth for each variable.  The result is the average of
the X and Y estimates.  I then use the command "by" to run the function on a
dataframe which has X and Y in columns 5 and 6, and a grouping variable
"animonth" to individualise the data by animal and month.  when I run the by
command on a small data table (only a few different levels of animonth) it
works perfectly.  

The problem is when I try to run it on all the data (or more than a few
levels) at once.  I get the error posted below.  However, if I run a simple
embedded function like summary within by, there is no error.  Can anyone
provide me with some assistance in interpreting this error?  Any suggestions
on alternative commands to use would be appreciated as well, as I'm not
commited to using by, it was just the one that seemed to work.

Data table example:
    uniqid  animal month animonth       x        y
1   11748   W079    12  W079_12 1494206 12134126
2   11749   W079    12  W079_12 1494123 12134051
3   11750   W079    12  W079_12 1493639 12133705
4   11751   W079    12  W079_12 1493353 12135892
5   11752   W079    12  W079_12 1495157 12137797
6   11753   W079    12  W079_12 1498039 12132112
7   11754   W079    12  W079_12 1497991 12131842
8   11755   W079    12  W079_12 1497918 12131631
9   11756   W079    12  W079_12 1498019 12131638
10  11757   W079    12  W079_12 1498017 12131633

Function for calculating bandwidth:
> kern.est
function(data) {
x.var <- (data$x / sd(data$x)); y.var <- (data$y / sd(data$y))
dpik.x <- dpik(x.var, gridsize = round((max(data$x) - min(data$x))/100))
dpik.y <- dpik(y.var, gridsize = round((max(data$y) - min(data$y))/100))
bw.avg <- ((dpik.x + dpik.y)/2)


by command used:
junk3 <- by(w079.all[,5:6], w079.all$animonth, kern.est)

output from small files (only a few levels of animonth):
w079.all$animonth: W079_1
[1] 0.2117635
----------------------------------------------------------------------------------------------------------------- 
w079.all$animonth: W079_12
[1] 0.2837849

Error on larger files:
Error in rep(0, P - 2 * L - 1) : invalid 'times' argument


Thank in advance for all any help,
Kevin
-- 
View this message in context: http://www.nabble.com/problem-using-%22by%22-with-custom-function--tp14259137p14259137.html
Sent from the R devel mailing list archive at Nabble.com.


From a.robotham at bristol.ac.uk  Mon Dec 10 10:33:24 2007
From: a.robotham at bristol.ac.uk (Aaron Robotham)
Date: Mon, 10 Dec 2007 09:33:24 +0000
Subject: [Rd]  os x crash using rpanel and tcltk (PR#10495)
In-Reply-To: <debf56250712070630i53382f2lc300d47fda5517a7@mail.gmail.com>
References: <20071205161009.737972834620@mail.pubhealth.ku.dk>
	<4757143F.9060902@biostat.ku.dk>
	<debf56250712060626u540deea0w32f0b919b3cbfa95@mail.gmail.com>
	<1497CFD2-F77D-45D6-A68B-AAFD7CB27CBB@r-project.org>
	<debf56250712070154wad6bf93n6d4c3e9d03d4fb@mail.gmail.com>
	<debf56250712070630i53382f2lc300d47fda5517a7@mail.gmail.com>
Message-ID: <debf56250712100133w2eb2833cw1eedd314484f26a6@mail.gmail.com>

---------- Forwarded message ----------
From: Aaron Robotham <a.robotham at bristol.ac.uk>
Date: 7 Dec 2007 14:30
Subject: Re: [Rd] os x crash using rpanel and tcltk (PR#10495)
To: Simon Urbanek <simon.urbanek at r-project.org>
Cc: Peter Dalgaard <p.dalgaard at biostat.ku.dk>, R-bugs at biostat.ku.dk,
r-devel at stat.math.ethz.ch


Here's the back trace i get after it crashes:

Program received signal SIGTRAP, Trace/breakpoint trap.
0x90a61b09 in _objc_error ()
(gdb) bt
#0  0x90a61b09 in _objc_error ()
#1  0x90a61b40 in __objc_error ()
#2  0x90a601a0 in _freedHandler ()
#3  0x93442c64 in -[NSDocument close] ()
#4  0x00015f0b in -[RQuartz close] ()
#5  0x00016c93 in RQuartz_Close ()
#6  0x0039b6dc in removeDevice ()
#7  0x00015f3f in -[RQuartz windowShouldClose:] ()
#8  0x934429b2 in -[NSWindow _document:shouldClose:contextInfo:] ()
#9  0x93442437 in -[NSWindow __close] ()
#10 0x93382dbc in -[NSApplication sendAction:to:from:] ()
#11 0x93382d15 in -[NSControl sendAction:to:] ()
#12 0x93384ec1 in -[NSCell _sendActionFrom:] ()
#13 0x933976a1 in -[NSCell trackMouse:inRect:ofView:untilMouseUp:] ()
#14 0x933b5289 in -[NSButtonCell trackMouse:inRect:ofView:untilMouseUp:] ()
#15 0x933b4b39 in -[NSControl mouseDown:] ()
#16 0x934422f8 in -[_NSThemeWidget mouseDown:] ()
#17 0x933723e3 in -[NSWindow sendEvent:] ()
#18 0x93364384 in -[NSApplication sendEvent:] ()
#19 0x00005151 in -[RController handleReadConsole:] ()
#20 0x0000c641 in Re_ReadConsole ()
#21 0x00015c76 in run_REngineRmainloop ()
#22 0x0000ec4a in -[REngine runREPL] ()
#23 0x0000226d in main ()

Is this what is wanted?

Thanks for the gdb advice btw. I'm not sure if it's important, but
before it crashed I got lots of warnings similar to the following in
gdb when I attached the tcltk package:

warning: Could not find object file
"/Builds/Rdev-web/QA/Simon/R-build/tiger-ppc/R-2.6-branch/src/extra/blas/blas00.o"
- no debug information available for
"../../../../../R-2.6-branch/src/extra/blas/blas00.c".

Is there an issue with a previous version of R on my machine causing problems?

Thanks for the help.

Aaron

On 07/12/2007, Aaron Robotham <a.robotham at bristol.ac.uk> wrote:
> The machine in question is a black MacBook, a pretty standard setup
> with the rest of the details as listed in my first post (R 2.6.1 OSX
> 10.4.11). I'll give the back trace a try and let you know the result.
>
> On 06/12/2007, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >
> > On Dec 6, 2007, at 9:26 AM, Aaron Robotham wrote:
> >
> > > I know of gdb but I'm not certain how to use it with Mac OS X's
> > > R.app, do you just do something like "gdb open R.app" in the
> > > terminal?.
> > >
> >
> > You can attach it once it's running - just type "attach R" in gdb
> > while R is runningm then "c", then let it crash and then "bt".
> >
> > FWIW: I cannot reproduce the problem and I have tried 3 different
> > machines... (you didn't even tell us what machine type this is ...).
> >
> > Cheers,
> > Simon
> >
> >
> > > Interestingly I don't get this crash when I launch the X11 version of
> > > R through the terminal, so this would suggest the bug in question is
> > > to do with the actual Rgui in R.app. Hopefully this information might
> > > help to narrow down the problem. Any advice for using gdb on R.app
> > > would be appreciated, I couldn't find much in the way of guidance when
> > > searching online.
> > >
> > > thanks
> > >
> > > Aaron
> > >
> > > On 05/12/2007, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > >> a.robotham at bris.ac.uk wrote:
> > >>> Hello,
> > >>> I've recently discovered a persistent issue with rpanel when running
> > >>> R.app (2.6.1) on Mac OS X 10.4.11. tcltk and rpanel load without any
> > >>> apparent error, and the interactive panels appear to work as
> > >>> expected,
> > >>> however upon closing the panels rpanel has created I get
> > >>> catastrophic
> > >>> errors and R crashes completely. For the most part R manages to
> > >>> crash
> > >>> with dignity and work can be saved, but sometimes it will crash
> > >>> straight out. Below is an example of an entire work session (only
> > >>> base
> > >>> packages loaded) with the crash at the end typical of those
> > >>> encountered:
> > >>>
> > >>>
> > >>>> library(tcltk)
> > >>>>
> > >>> Loading Tcl/Tk interface ... done
> > >>>
> > >>>> library(rpanel)
> > >>>>
> > >>> Package `rpanel', version 1.0-4
> > >>> type help(rpanel) for summary information
> > >>>
> > >>>> density.draw <- function(panel) {
> > >>>>
> > >>> +   plot(density(panel$x, bw = panel$h))
> > >>> +   panel
> > >>> + }
> > >>>
> > >>>> panel <- rp.control(x = rnorm(50))
> > >>>> rp.slider(panel, h, 0.5, 5, log = TRUE, action = density.draw)
> > >>>>
> > >>>
> > >>> *** caught bus error ***
> > >>> address 0x0, cause 'non-existent physical address'
> > >>>
> > >>> Possible actions:
> > >>> 1: abort (with core dump, if enabled)
> > >>> 2: normal R exit
> > >>> 3: exit R without saving workspace
> > >>> 4: exit R saving workspace
> > >>>
> > >>> All packages that are required are up to date, and I can find no
> > >>> evidence of similar issues from searching the mailing lists. Any
> > >>> suggestions would be appreciated.
> > >>>
> > >>>
> > >> Can you run this under gdb? A breakpoint in the error handler and a
> > >> backtrace could be valuable.
> > >>
> > >>> Aaron
> > >>>
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>
> > >>
> > >>
> > >> --
> > >>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> > >>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > >> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> > >> 35327918
> > >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> > >> 35327907
> > >>
> > >>
> > >>
> > >>
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> >
> >
> >
>


From gkerns at ysu.edu  Mon Dec 10 16:53:44 2007
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Mon, 10 Dec 2007 10:53:44 -0500
Subject: [Rd] setdiff for data frames
Message-ID: <a695148b0712100753m3a6e14c8r33fd77d2ce2179bc@mail.gmail.com>

Hello,

I have been interested in setdiff() for data frames that operates
row-wise.  I looked in the documentation, mailing lists, etc., and
didn't find exactly the right thing.  Given data frames A, B with the
same columns, the goal is to extract the rows that are in A, but not
in B.  Of course, one can usually do setdiff(rownames(A), rownames(B))
but that is cheating.  :-)

I played around a little bit and came up with

setdiff.data.frame = function(A, B){
     g <-  function( y, B){
                 any( apply(B, 1, FUN = function(x)
identical(all.equal(x, y), TRUE) ) ) }
     unique( A[ !apply(A, 1, FUN = function(t) g(t, B) ), ] )
}

I am sure that somebody can do this a better/faster way... any ideas?
Any chance we could get a data.frame method for set.diff in future R
versions? (The notion of "set" is somewhat ambiguous with respect to
rows, columns, and entries in the data frame case.)


Jay


P.S. You can see what I'm looking for with

A <- expand.grid( 1:3, 1:3 )
B <- A[ 2:5, ]
setdiff.data.frame(A,B)





***************************************************
G. Jay Kerns, Ph.D.
Assistant Professor / Statistics Coordinator
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/


From cberry at tajo.ucsd.edu  Tue Dec 11 02:58:57 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Mon, 10 Dec 2007 17:58:57 -0800
Subject: [Rd] setdiff for data frames
In-Reply-To: <a695148b0712100753m3a6e14c8r33fd77d2ce2179bc@mail.gmail.com>
References: <a695148b0712100753m3a6e14c8r33fd77d2ce2179bc@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712101754350.30566@tajo.ucsd.edu>

On Mon, 10 Dec 2007, G. Jay Kerns wrote:

> Hello,
>
> I have been interested in setdiff() for data frames that operates
> row-wise.  I looked in the documentation, mailing lists, etc., and
> didn't find exactly the right thing.  Given data frames A, B with the
> same columns, the goal is to extract the rows that are in A, but not
> in B.  Of course, one can usually do setdiff(rownames(A), rownames(B))
> but that is cheating.  :-)
>
> I played around a little bit and came up with
>
> setdiff.data.frame = function(A, B){
>     g <-  function( y, B){
>                 any( apply(B, 1, FUN = function(x)
> identical(all.equal(x, y), TRUE) ) ) }
>     unique( A[ !apply(A, 1, FUN = function(t) g(t, B) ), ] )
> }
>
> I am sure that somebody can do this a better/faster way... any ideas?

setdiff.data.frame <-
    function(A,B) A[ !duplicated( rbind(B,A) )[ -seq_len(nrow(B))] , ]

This ignores rownames(A) which may not be what is wanted in every case.

HTH,

Chuck

> Any chance we could get a data.frame method for set.diff in future R
> versions? (The notion of "set" is somewhat ambiguous with respect to
> rows, columns, and entries in the data frame case.)
>
>
> Jay
>
>
> P.S. You can see what I'm looking for with
>
> A <- expand.grid( 1:3, 1:3 )
> B <- A[ 2:5, ]
> setdiff.data.frame(A,B)
>
>
>
>
>
> ***************************************************
> G. Jay Kerns, Ph.D.
> Assistant Professor / Statistics Coordinator
> Department of Mathematics & Statistics
> Youngstown State University
> Youngstown, OH 44555-0002 USA
> Office: 1035 Cushwa Hall
> Phone: (330) 941-3310 Office (voice mail)
> -3302 Department
> -3170 FAX
> E-mail: gkerns at ysu.edu
> http://www.cc.ysu.edu/~gjkerns/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From ripley at stats.ox.ac.uk  Tue Dec 11 08:36:49 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2007 07:36:49 +0000 (GMT)
Subject: [Rd] setdiff for data frames
In-Reply-To: <Pine.LNX.4.64.0712101754350.30566@tajo.ucsd.edu>
References: <a695148b0712100753m3a6e14c8r33fd77d2ce2179bc@mail.gmail.com>
	<Pine.LNX.4.64.0712101754350.30566@tajo.ucsd.edu>
Message-ID: <Pine.LNX.4.64.0712110728400.9400@gannet.stats.ox.ac.uk>

On Mon, 10 Dec 2007, Charles C. Berry wrote:

> On Mon, 10 Dec 2007, G. Jay Kerns wrote:
>
>> Hello,
>>
>> I have been interested in setdiff() for data frames that operates
>> row-wise.  I looked in the documentation, mailing lists, etc., and
>> didn't find exactly the right thing.  Given data frames A, B with the
>> same columns, the goal is to extract the rows that are in A, but not
>> in B.  Of course, one can usually do setdiff(rownames(A), rownames(B))
>> but that is cheating.  :-)
>>
>> I played around a little bit and came up with
>>
>> setdiff.data.frame = function(A, B){
>>     g <-  function( y, B){
>>                 any( apply(B, 1, FUN = function(x)
>> identical(all.equal(x, y), TRUE) ) ) }
>>     unique( A[ !apply(A, 1, FUN = function(t) g(t, B) ), ] )
>> }
>>
>> I am sure that somebody can do this a better/faster way... any ideas?
>
> setdiff.data.frame <-
>    function(A,B) A[ !duplicated( rbind(B,A) )[ -seq_len(nrow(B))] , ]
>
> This ignores rownames(A) which may not be what is wanted in every case.

I was about to suggest using the approach taken by duplicated.data.frame, 
(which is to 'hash' the rows to a character vector) then call setdiff.
E.g.

a <- do.call("paste", c(A, sep = "\r"))
b <- do.call("paste", c(B, sep = "\r"))
A[match(setdiff(a, b),a), ]

Note that apply() is intended for matrices (not data frames) and the 
version given can do a horrendous amount of coercion, whereas the above 
does it only once.

>
> HTH,
>
> Chuck
>
>> Any chance we could get a data.frame method for set.diff in future R
>> versions? (The notion of "set" is somewhat ambiguous with respect to
>> rows, columns, and entries in the data frame case.)

No chance: if you have not found it in the archives, it is too rare a 
request.

>> Jay
>>
>> P.S. You can see what I'm looking for with
>>
>> A <- expand.grid( 1:3, 1:3 )
>> B <- A[ 2:5, ]
>> setdiff.data.frame(A,B)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Mon Dec 10 23:02:22 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 10 Dec 2007 17:02:22 -0500
Subject: [Rd] another S4 question ...
Message-ID: <475DB76E.5060503@zoo.ufl.edu>


  The default generic method for "show" has arguments
show(object) -- (no "...")   -- which precludes any kind
of arguments like "digits", etc.

  Is it impossible, or a horrible idea, to override the
generic definition?  (The "arm" package has defined a
new generic, "display", which does a similar thing but
has an intermediate level of detail (between "print/show"
and "summary")

  Ben Bolker


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 252 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20071210/65b52cac/attachment.bin 

From gkerns at ysu.edu  Tue Dec 11 03:16:14 2007
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Mon, 10 Dec 2007 21:16:14 -0500
Subject: [Rd] setdiff for data frames
In-Reply-To: <Pine.LNX.4.64.0712101754350.30566@tajo.ucsd.edu>
References: <a695148b0712100753m3a6e14c8r33fd77d2ce2179bc@mail.gmail.com>
	<Pine.LNX.4.64.0712101754350.30566@tajo.ucsd.edu>
Message-ID: <a695148b0712101816jf128d09m543a9f63da8eded9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071210/4b27a6bd/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Dec 11 11:30:12 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2007 10:30:12 +0000 (GMT)
Subject: [Rd] Defaults for postscript()
In-Reply-To: <eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
	<eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712101212001.13534@gannet.stats.ox.ac.uk>

I think everyone who commented has overlooked that the defaults for these 
postscript() arguments are set by ps.options(), so in fact we are talking 
about the defaults for the defaults.  Unfortunately, the documentation on 
this was full of errors, including not pointing out that some of the 
ps.options() settings apply to xfig() and pdf() (and some do not).
In fact, although you can set the default for 'onefile' via ps.options(), 
that setting is never used AFAICS.

This means that it was never completely safe to rely on the defaults in 
test scripts in packages, since a site could change these defaults 
(although hopefully it would have been done in a file skipped by 
--vanilla).

Given that (most of) the defaults are customizable, it does seem to me to 
be much more important to have defaults that are appropriate to the naive 
user and not the expert one.  When I first drafted this, I thought one 
could switch between the old and proposed defaults via a call to 
ps.options(), but despite documenting 'onefile' as an argument, it is 
never actually used.

I had a further follow-up suggestion, which is to change the default 
device in non-interactive use from postscript() to pdf().  I believe that 
PDF viewers are more widely available than PS viewers these days (almost 
every Windows box ships with AcroRead, and Mac OS has native PDF viewers). 
There used to be an argument over the non-availability of Free PDF viewers 
and the limited range of platforms supported by AcroRead, but the 
availability of several viewers based on xpdf seem to satisfy that 
argument at least as well as the availability of ghostscript and 
front-ends do for PS (and GSView, the Windows front-end, is shareware-like 
- I keep forgetting that, as Oxford has a site licence).

I remain convinced that producing rotated PS plots of a size (and aspect 
ratio) that depends on the locale (since the default papersize does) is no 
longer a reasonable default.

That leaves onefile=TRUE.  Even if we don't move the non-interactive 
default device to pdf, it could be postscript(onefile=TRUE).  However, it 
ought to be possible to implement onefile=NA, which would write an EPS 
file if only one plot was produced and a multi-page PS file otherwise.
That would seem to me to be a good compromise.

Comment to Marc Schwartz: we can't force a Notes sections above Details, 
as the ordering of sections is dictated by Rdconv.  I had already done 
some re-structuring of the page, moving printing to a new section.

A further comment: I wonder if we really want this complexity of using 
ps.options() to set default defaults: I am inclined to remove it for xfig 
and pdf.  (Given that it was not documented, it is unlikely anyone is
knowingly used it.)


On Thu, 6 Dec 2007, Deepayan Sarkar wrote:

> On 12/6/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> The defaults for postscript()
>>
>> paper = "default"
>> onefile = TRUE
>> horizontal = TRUE
>>
>> (it seems) date from the days when people used to used this to send plots
>> directly to a postscript printer via print.it=TRUE.  I haven't done that
>> for years, and it seems that our current generation of students don't even
>> know the concept.  It seems 'horizontal = TRUE' is particularly difficult
>> to grasp.
>>
>> Given that I suspect almost all uses of postscript() are to produce plots
>> to be viewed on-screen or incorporated into another document, a more
>> appropriate set of defaults would be
>>
>> width = 7, height = 7
>> paper = "special"
>> onefile = FALSE
>> horizontal = FALSE
>>
>> which would have the advantage of using the same default aspect ratio for
>> plots as all (?) other R graphics devices.
>>
>> Does anyone see a reason not to change the defaults?
>
> I'm not so sure about the 'onefile' change. Scripts with multiple
> plots run in batch mode will end up with multiple files; I prefer the
> current behaviour. I also have test scripts in packages that go
>
>
> postscript("something.ps")
> <many examples>
> dev.off()
>
>
> Unless I change all these to have onefile=TRUE, I'll end up only with
> the last plot available after the tests are run.
>
> -Deepayan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bjarni at Update.UU.SE  Tue Dec 11 15:43:07 2007
From: bjarni at Update.UU.SE (Bjarni Juliusson)
Date: Tue, 11 Dec 2007 15:43:07 +0100
Subject: [Rd] Interactiveness
Message-ID: <475EA1FB.8010002@Update.UU.SE>

Hi list!

I'm developing R integration for a project called Bioclipse at Uppsala 
University. The current implementation works by simply forking an R and 
sending it text (with some substitutions on it) down a pipe, getting the 
printed output back up another pipe. This of course works fine, except 
it runs into one problem: R finds a pipe on its stdin and decides to be 
"non-interactive", which means that as soon as the user makes a typo and 
causes an error, R exits.

I checked the source, and it's a couple of isatty()'s in the two files 
named system.c that are doing it. They are of course intended to be a 
feature, but in this case it causes us trouble. Would it be possible to 
get a command line switch to control this behaviour? I'm not sure pseudo 
terminals can be used portably, or can they? Are those few lines with 
the isatty's, which set R_Interactive to FALSE, the only places that 
need to be patched (besides adding the switch somewhere)? Should I send 
in a complete patch or is a request for functionality sufficient?

Lots of questions there, grateful for any answers! :-)


Bjarni
-- 

                        INFORMATION WANTS TO BE FREE


From Kurt.Hornik at wu-wien.ac.at  Tue Dec 11 16:20:22 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt.Hornik at wu-wien.ac.at)
Date: Tue, 11 Dec 2007 16:20:22 +0100 (CET)
Subject: [Rd] [Kurt.Hornik@wu-wien.ac.at: Re: range( <dates>,
	na.rm = TRUE )] (PR#10508)
Message-ID: <20071211152022.342B0282EFF8@mail.pubhealth.ku.dk>

------- Start of forwarded message -------
Date: Tue, 13 Nov 2007 21:44:57 +0100
To: Steve Mongin <sjm at ccbr.umn.edu>
Cc: cran at r-project.org
Subject: Re: range( <dates>, na.rm = TRUE )
In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
Reply-To: Kurt.Hornik at wu-wien.ac.at
From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0.34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken.wu-wien.ac.at
X-Virus-Status: Clean

>>>>> Steve Mongin writes:

> Dear CRAN:
> I am running 'R' on Linux as follows:

>> version
>                _                           
>   platform       i686-redhat-linux-gnu       
>   arch           i686                        
>   os             linux-gnu                   
>   system         i686, linux-gnu             
>   status                                     
>   major          2                           
>   minor          6.0                         
>   year           2007                        
>   month          10                          
>   day            03                          
>   svn rev        43063                       
>   language       R                           
>   version.string R version 2.6.0 (2007-10-03)


> I have a question about the behavior of "range()" with missing dates.

> With the previous version (2.4?) , the command:

>> range( as.Date( c( "2007-11-06", NA ) ), na.rm = TRUE )

> yielded:

>> [1] "2007-11-06" "2007-11-06"

> Now I get:

>> [1] NA NA

> Is this a bug?

> Yes, I see in the "What's New" page:

>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>    summ, prod, range) are now primitive."

> Is the "primitive" characteristic supposed to behave as above with
> missing dates?

> Thanks for any help that you can provide.

This is really a question for r-devel or r-bugs, I think, but not for
the CRAN maintainers.

I would think it is a bug.  Perhaps simply file a bug report?

Best
- -k
------- End of forwarded message -------


From ripley at stats.ox.ac.uk  Tue Dec 11 16:27:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2007 15:27:54 +0000 (GMT)
Subject: [Rd] Interactiveness
In-Reply-To: <475EA1FB.8010002@Update.UU.SE>
References: <475EA1FB.8010002@Update.UU.SE>
Message-ID: <Pine.LNX.4.64.0712111454180.7824@auk.stats>

On Tue, 11 Dec 2007, Bjarni Juliusson wrote:

> Hi list!
>
> I'm developing R integration for a project called Bioclipse at Uppsala
> University. The current implementation works by simply forking an R and
> sending it text (with some substitutions on it) down a pipe, getting the
> printed output back up another pipe. This of course works fine, except
> it runs into one problem: R finds a pipe on its stdin and decides to be
> "non-interactive", which means that as soon as the user makes a typo and
> causes an error, R exits.

Actually, not so.  The default error handler for non-interactive use is to 
do that, but you can change it.

> I checked the source, and it's a couple of isatty()'s in the two files
> named system.c that are doing it. They are of course intended to be a
> feature, but in this case it causes us trouble. Would it be possible to
> get a command line switch to control this behaviour? I'm not sure pseudo
> terminals can be used portably, or can they?

They can, and are e.g. by ESS (except on Windows, where there is already a 
switch).  I think you need to look a bit more carefully at what other 
projects do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Tue Dec 11 16:53:21 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 11 Dec 2007 16:53:21 +0100
Subject: [Rd] [Kurt.Hornik@wu-wien.ac.at: Re: range( <dates>,
 na.rm = TRUE )] (PR#10508)
In-Reply-To: <20071211152022.342B0282EFF8@mail.pubhealth.ku.dk>
References: <20071211152022.342B0282EFF8@mail.pubhealth.ku.dk>
Message-ID: <475EB271.90202@biostat.ku.dk>

Kurt.Hornik at wu-wien.ac.at wrote:
> ------- Start of forwarded message -------
> Date: Tue, 13 Nov 2007 21:44:57 +0100
> To: Steve Mongin <sjm at ccbr.umn.edu>
> Cc: cran at r-project.org
> Subject: Re: range( <dates>, na.rm = TRUE )
> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
> Reply-To: Kurt.Hornik at wu-wien.ac.at
> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0.34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken.wu-wien.ac.at
> X-Virus-Status: Clean
>
>   
>>>>>> Steve Mongin writes:
>>>>>>             
>
>   
>> Dear CRAN:
>> I am running 'R' on Linux as follows:
>>     
>
>   
>>> version
>>>       
>>                _                           
>>   platform       i686-redhat-linux-gnu       
>>   arch           i686                        
>>   os             linux-gnu                   
>>   system         i686, linux-gnu             
>>   status                                     
>>   major          2                           
>>   minor          6.0                         
>>   year           2007                        
>>   month          10                          
>>   day            03                          
>>   svn rev        43063                       
>>   language       R                           
>>   version.string R version 2.6.0 (2007-10-03)
>>     
>
>
>   
>> I have a question about the behavior of "range()" with missing dates.
>>     
>
>   
>> With the previous version (2.4?) , the command:
>>     
>
>   
>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm = TRUE )
>>>       
>
>   
>> yielded:
>>     
>
>   
>>> [1] "2007-11-06" "2007-11-06"
>>>       
>
>   
>> Now I get:
>>     
>
>   
>>> [1] NA NA
>>>       
>
>   
>> Is this a bug?
>>     
>
>   
>> Yes, I see in the "What's New" page:
>>     
>
>   
>>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>>    summ, prod, range) are now primitive."
>>     
>
>   
>> Is the "primitive" characteristic supposed to behave as above with
>> missing dates?
>>     
>
>   
>> Thanks for any help that you can provide.
>>     
>
> This is really a question for r-devel or r-bugs, I think, but not for
> the CRAN maintainers.
>
> I would think it is a bug.  Perhaps simply file a bug report?
>
>   
Again? ;-)

The bug is here:

> range.default
function (..., na.rm = FALSE, finite = FALSE)
{
    x <- c(..., recursive = TRUE)
    if (is.numeric(x)) {
        if (finite)
            x <- x[is.finite(x)]
        else if (na.rm)
            x <- x[!is.na(x)]
    }
    c(min(x), max(x))
}
<environment: namespace:base>

Objects of class Date are not considered numeric, so we end up taking
min and max without removing NA.

One solution could be

if (is.numeric(x) || inherits(x, "Date") ){....}


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Tue Dec 11 16:55:04 2007
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Tue, 11 Dec 2007 16:55:04 +0100 (CET)
Subject: [Rd] [Kurt.Hornik@wu-wien.ac.at: Re: range( <dates>,
	na.rm = (PR#10509)
Message-ID: <20071211155504.B326C283460C@mail.pubhealth.ku.dk>

Kurt.Hornik at wu-wien.ac.at wrote:
> ------- Start of forwarded message -------
> Date: Tue, 13 Nov 2007 21:44:57 +0100
> To: Steve Mongin <sjm at ccbr.umn.edu>
> Cc: cran at r-project.org
> Subject: Re: range( <dates>, na.rm =3D TRUE )
> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
> Reply-To: Kurt.Hornik at wu-wien.ac.at
> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0.=
34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken.=
wu-wien.ac.at
> X-Virus-Status: Clean
>
>  =20
>>>>>> Steve Mongin writes:
>>>>>>            =20
>
>  =20
>> Dear CRAN:
>> I am running 'R' on Linux as follows:
>>    =20
>
>  =20
>>> version
>>>      =20
>>                _                          =20
>>   platform       i686-redhat-linux-gnu      =20
>>   arch           i686                       =20
>>   os             linux-gnu                  =20
>>   system         i686, linux-gnu            =20
>>   status                                    =20
>>   major          2                          =20
>>   minor          6.0                        =20
>>   year           2007                       =20
>>   month          10                         =20
>>   day            03                         =20
>>   svn rev        43063                      =20
>>   language       R                          =20
>>   version.string R version 2.6.0 (2007-10-03)
>>    =20
>
>
>  =20
>> I have a question about the behavior of "range()" with missing dates.
>>    =20
>
>  =20
>> With the previous version (2.4?) , the command:
>>    =20
>
>  =20
>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm =3D TRUE )
>>>      =20
>
>  =20
>> yielded:
>>    =20
>
>  =20
>>> [1] "2007-11-06" "2007-11-06"
>>>      =20
>
>  =20
>> Now I get:
>>    =20
>
>  =20
>>> [1] NA NA
>>>      =20
>
>  =20
>> Is this a bug?
>>    =20
>
>  =20
>> Yes, I see in the "What's New" page:
>>    =20
>
>  =20
>>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>>    summ, prod, range) are now primitive."
>>    =20
>
>  =20
>> Is the "primitive" characteristic supposed to behave as above with
>> missing dates?
>>    =20
>
>  =20
>> Thanks for any help that you can provide.
>>    =20
>
> This is really a question for r-devel or r-bugs, I think, but not for
> the CRAN maintainers.
>
> I would think it is a bug.  Perhaps simply file a bug report?
>
>  =20
Again? ;-)

The bug is here:

> range.default
function (..., na.rm =3D FALSE, finite =3D FALSE)
{
    x <- c(..., recursive =3D TRUE)
    if (is.numeric(x)) {
        if (finite)
            x <- x[is.finite(x)]
        else if (na.rm)
            x <- x[!is.na(x)]
    }
    c(min(x), max(x))
}
<environment: namespace:base>

Objects of class Date are not considered numeric, so we end up taking
min and max without removing NA.

One solution could be

if (is.numeric(x) || inherits(x, "Date") ){....}


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907


From bjarni at Update.UU.SE  Tue Dec 11 16:57:44 2007
From: bjarni at Update.UU.SE (Bjarni Juliusson)
Date: Tue, 11 Dec 2007 16:57:44 +0100
Subject: [Rd] Interactiveness
In-Reply-To: <Pine.LNX.4.64.0712111454180.7824@auk.stats>
References: <475EA1FB.8010002@Update.UU.SE>
	<Pine.LNX.4.64.0712111454180.7824@auk.stats>
Message-ID: <475EB378.7030101@Update.UU.SE>

Prof Brian Ripley wrote:
> On Tue, 11 Dec 2007, Bjarni Juliusson wrote:
>> I'm developing R integration for a project called Bioclipse at Uppsala
>> University. The current implementation works by simply forking an R and
>> sending it text (with some substitutions on it) down a pipe, getting the
>> printed output back up another pipe. This of course works fine, except
>> it runs into one problem: R finds a pipe on its stdin and decides to be
>> "non-interactive", which means that as soon as the user makes a typo and
>> causes an error, R exits.
> 
> Actually, not so.  The default error handler for non-interactive use is 
> to do that, but you can change it.

Could you perhaps just point me in the right direction here? I really 
have no idea how to do this.

Also, what exactly does non-interactive mode imply, besides this default 
error handling behaviour?

>> I checked the source, and it's a couple of isatty()'s in the two files
>> named system.c that are doing it. They are of course intended to be a
>> feature, but in this case it causes us trouble. Would it be possible to
>> get a command line switch to control this behaviour? I'm not sure pseudo
>> terminals can be used portably, or can they?
> 
> They can, and are e.g. by ESS (except on Windows, where there is already 
> a switch).  I think you need to look a bit more carefully at what other 
> projects do.

It needs to be portable to Windows. I'll look into this possibility next.

Didn't mean to ask before I had done my homework. Thanks for your help!


Bjarni
-- 

                        INFORMATION WANTS TO BE FREE


From P.Dalgaard at biostat.ku.dk  Tue Dec 11 17:01:06 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 11 Dec 2007 17:01:06 +0100
Subject: [Rd] range( <dates>, na.rm = TRUE ) (PR#10508)
In-Reply-To: <475EB271.90202@biostat.ku.dk>
References: <20071211152022.342B0282EFF8@mail.pubhealth.ku.dk>
	<475EB271.90202@biostat.ku.dk>
Message-ID: <475EB442.7060009@biostat.ku.dk>

(Drats! Jitterbug is playing tricks with the PR# again. Attempting to
refile so that we can kill PR#10509)

Peter Dalgaard wrote:
> Kurt.Hornik at wu-wien.ac.at wrote:
>   
>> ------- Start of forwarded message -------
>> Date: Tue, 13 Nov 2007 21:44:57 +0100
>> To: Steve Mongin <sjm at ccbr.umn.edu>
>> Cc: cran at r-project.org
>> Subject: Re: range( <dates>, na.rm = TRUE )
>> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
>> Reply-To: Kurt.Hornik at wu-wien.ac.at
>> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
>> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0.34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
>> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken.wu-wien.ac.at
>> X-Virus-Status: Clean
>>
>>   
>>     
>>>>>>> Steve Mongin writes:
>>>>>>>             
>>>>>>>               
>>   
>>     
>>> Dear CRAN:
>>> I am running 'R' on Linux as follows:
>>>     
>>>       
>>   
>>     
>>>> version
>>>>       
>>>>         
>>>                _                           
>>>   platform       i686-redhat-linux-gnu       
>>>   arch           i686                        
>>>   os             linux-gnu                   
>>>   system         i686, linux-gnu             
>>>   status                                     
>>>   major          2                           
>>>   minor          6.0                         
>>>   year           2007                        
>>>   month          10                          
>>>   day            03                          
>>>   svn rev        43063                       
>>>   language       R                           
>>>   version.string R version 2.6.0 (2007-10-03)
>>>     
>>>       
>>   
>>     
>>> I have a question about the behavior of "range()" with missing dates.
>>>     
>>>       
>>   
>>     
>>> With the previous version (2.4?) , the command:
>>>     
>>>       
>>   
>>     
>>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm = TRUE )
>>>>       
>>>>         
>>   
>>     
>>> yielded:
>>>     
>>>       
>>   
>>     
>>>> [1] "2007-11-06" "2007-11-06"
>>>>       
>>>>         
>>   
>>     
>>> Now I get:
>>>     
>>>       
>>   
>>     
>>>> [1] NA NA
>>>>       
>>>>         
>>   
>>     
>>> Is this a bug?
>>>     
>>>       
>>   
>>     
>>> Yes, I see in the "What's New" page:
>>>     
>>>       
>>   
>>     
>>>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>>>    summ, prod, range) are now primitive."
>>>     
>>>       
>>   
>>     
>>> Is the "primitive" characteristic supposed to behave as above with
>>> missing dates?
>>>     
>>>       
>>   
>>     
>>> Thanks for any help that you can provide.
>>>     
>>>       
>> This is really a question for r-devel or r-bugs, I think, but not for
>> the CRAN maintainers.
>>
>> I would think it is a bug.  Perhaps simply file a bug report?
>>
>>   
>>     
> Again? ;-)
>
> The bug is here:
>
>   
>> range.default
>>     
> function (..., na.rm = FALSE, finite = FALSE)
> {
>     x <- c(..., recursive = TRUE)
>     if (is.numeric(x)) {
>         if (finite)
>             x <- x[is.finite(x)]
>         else if (na.rm)
>             x <- x[!is.na(x)]
>     }
>     c(min(x), max(x))
> }
> <environment: namespace:base>
>
> Objects of class Date are not considered numeric, so we end up taking
> min and max without removing NA.
>
> One solution could be
>
> if (is.numeric(x) || inherits(x, "Date") ){....}
>
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Tue Dec 11 17:05:14 2007
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Tue, 11 Dec 2007 17:05:14 +0100 (CET)
Subject: [Rd] range( <dates>, na.rm = TRUE ) (PR#10508)
Message-ID: <20071211160514.4CDBB283460C@mail.pubhealth.ku.dk>

(Drats! Jitterbug is playing tricks with the PR# again. Attempting to
refile so that we can kill PR#10509)

Peter Dalgaard wrote:
> Kurt.Hornik at wu-wien.ac.at wrote:
>  =20
>> ------- Start of forwarded message -------
>> Date: Tue, 13 Nov 2007 21:44:57 +0100
>> To: Steve Mongin <sjm at ccbr.umn.edu>
>> Cc: cran at r-project.org
>> Subject: Re: range( <dates>, na.rm =3D TRUE )
>> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
>> Reply-To: Kurt.Hornik at wu-wien.ac.at
>> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
>> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0=
=2E34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
>> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken=
=2Ewu-wien.ac.at
>> X-Virus-Status: Clean
>>
>>  =20
>>    =20
>>>>>>> Steve Mongin writes:
>>>>>>>            =20
>>>>>>>              =20
>>  =20
>>    =20
>>> Dear CRAN:
>>> I am running 'R' on Linux as follows:
>>>    =20
>>>      =20
>>  =20
>>    =20
>>>> version
>>>>      =20
>>>>        =20
>>>                _                          =20
>>>   platform       i686-redhat-linux-gnu      =20
>>>   arch           i686                       =20
>>>   os             linux-gnu                  =20
>>>   system         i686, linux-gnu            =20
>>>   status                                    =20
>>>   major          2                          =20
>>>   minor          6.0                        =20
>>>   year           2007                       =20
>>>   month          10                         =20
>>>   day            03                         =20
>>>   svn rev        43063                      =20
>>>   language       R                          =20
>>>   version.string R version 2.6.0 (2007-10-03)
>>>    =20
>>>      =20
>>  =20
>>    =20
>>> I have a question about the behavior of "range()" with missing dates.=

>>>    =20
>>>      =20
>>  =20
>>    =20
>>> With the previous version (2.4?) , the command:
>>>    =20
>>>      =20
>>  =20
>>    =20
>>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm =3D TRUE )
>>>>      =20
>>>>        =20
>>  =20
>>    =20
>>> yielded:
>>>    =20
>>>      =20
>>  =20
>>    =20
>>>> [1] "2007-11-06" "2007-11-06"
>>>>      =20
>>>>        =20
>>  =20
>>    =20
>>> Now I get:
>>>    =20
>>>      =20
>>  =20
>>    =20
>>>> [1] NA NA
>>>>      =20
>>>>        =20
>>  =20
>>    =20
>>> Is this a bug?
>>>    =20
>>>      =20
>>  =20
>>    =20
>>> Yes, I see in the "What's New" page:
>>>    =20
>>>      =20
>>  =20
>>    =20
>>>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>>>    summ, prod, range) are now primitive."
>>>    =20
>>>      =20
>>  =20
>>    =20
>>> Is the "primitive" characteristic supposed to behave as above with
>>> missing dates?
>>>    =20
>>>      =20
>>  =20
>>    =20
>>> Thanks for any help that you can provide.
>>>    =20
>>>      =20
>> This is really a question for r-devel or r-bugs, I think, but not for
>> the CRAN maintainers.
>>
>> I would think it is a bug.  Perhaps simply file a bug report?
>>
>>  =20
>>    =20
> Again? ;-)
>
> The bug is here:
>
>  =20
>> range.default
>>    =20
> function (..., na.rm =3D FALSE, finite =3D FALSE)
> {
>     x <- c(..., recursive =3D TRUE)
>     if (is.numeric(x)) {
>         if (finite)
>             x <- x[is.finite(x)]
>         else if (na.rm)
>             x <- x[!is.na(x)]
>     }
>     c(min(x), max(x))
> }
> <environment: namespace:base>
>
> Objects of class Date are not considered numeric, so we end up taking
> min and max without removing NA.
>
> One solution could be
>
> if (is.numeric(x) || inherits(x, "Date") ){....}
>
>
>  =20


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907


From ripley at stats.ox.ac.uk  Tue Dec 11 17:20:15 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 11 Dec 2007 17:20:15 +0100 (CET)
Subject: [Rd] range( <dates>, na.rm = TRUE ) (PR#10508)
Message-ID: <20071211162015.9874E282EFF8@mail.pubhealth.ku.dk>

I don't think that is the right fix.  All methods for min/max should now 
support na.rm=TRUE (but not finite=TRUE), so range.default should just 
call min and max with that argument.

I'd need to verify those 'should's first ....

Brian

On Tue, 11 Dec 2007, Peter Dalgaard wrote:

> (Drats! Jitterbug is playing tricks with the PR# again. Attempting to
> refile so that we can kill PR#10509)
>
> Peter Dalgaard wrote:
>> Kurt.Hornik at wu-wien.ac.at wrote:
>>
>>> ------- Start of forwarded message -------
>>> Date: Tue, 13 Nov 2007 21:44:57 +0100
>>> To: Steve Mongin <sjm at ccbr.umn.edu>
>>> Cc: cran at r-project.org
>>> Subject: Re: range( <dates>, na.rm = TRUE )
>>> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
>>> Reply-To: Kurt.Hornik at wu-wien.ac.at
>>> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
>>> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE: 7.6.0.34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
>>> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on pocken.wu-wien.ac.at
>>> X-Virus-Status: Clean
>>>
>>>
>>>
>>>>>>>> Steve Mongin writes:
>>>>>>>>
>>>>>>>>
>>>
>>>
>>>> Dear CRAN:
>>>> I am running 'R' on Linux as follows:
>>>>
>>>>
>>>
>>>
>>>>> version
>>>>>
>>>>>
>>>>                _
>>>>   platform       i686-redhat-linux-gnu
>>>>   arch           i686
>>>>   os             linux-gnu
>>>>   system         i686, linux-gnu
>>>>   status
>>>>   major          2
>>>>   minor          6.0
>>>>   year           2007
>>>>   month          10
>>>>   day            03
>>>>   svn rev        43063
>>>>   language       R
>>>>   version.string R version 2.6.0 (2007-10-03)
>>>>
>>>>
>>>
>>>
>>>> I have a question about the behavior of "range()" with missing dates.
>>>>
>>>>
>>>
>>>
>>>> With the previous version (2.4?) , the command:
>>>>
>>>>
>>>
>>>
>>>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm = TRUE )
>>>>>
>>>>>
>>>
>>>
>>>> yielded:
>>>>
>>>>
>>>
>>>
>>>>> [1] "2007-11-06" "2007-11-06"
>>>>>
>>>>>
>>>
>>>
>>>> Now I get:
>>>>
>>>>
>>>
>>>
>>>>> [1] NA NA
>>>>>
>>>>>
>>>
>>>
>>>> Is this a bug?
>>>>
>>>>
>>>
>>>
>>>> Yes, I see in the "What's New" page:
>>>>
>>>>
>>>
>>>
>>>>   "The Math2 and Summary groups (round, signif, all, any, max, min,
>>>>    summ, prod, range) are now primitive."
>>>>
>>>>
>>>
>>>
>>>> Is the "primitive" characteristic supposed to behave as above with
>>>> missing dates?
>>>>
>>>>
>>>
>>>
>>>> Thanks for any help that you can provide.
>>>>
>>>>
>>> This is really a question for r-devel or r-bugs, I think, but not for
>>> the CRAN maintainers.
>>>
>>> I would think it is a bug.  Perhaps simply file a bug report?
>>>
>>>
>>>
>> Again? ;-)
>>
>> The bug is here:
>>
>>
>>> range.default
>>>
>> function (..., na.rm = FALSE, finite = FALSE)
>> {
>>     x <- c(..., recursive = TRUE)
>>     if (is.numeric(x)) {
>>         if (finite)
>>             x <- x[is.finite(x)]
>>         else if (na.rm)
>>             x <- x[!is.na(x)]
>>     }
>>     c(min(x), max(x))
>> }
>> <environment: namespace:base>
>>
>> Objects of class Date are not considered numeric, so we end up taking
>> min and max without removing NA.
>>
>> One solution could be
>>
>> if (is.numeric(x) || inherits(x, "Date") ){....}
>>
>>
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Tue Dec 11 17:40:11 2007
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Tue, 11 Dec 2007 17:40:11 +0100 (CET)
Subject: [Rd] range( <dates>, na.rm = TRUE ) (PR#10508)
Message-ID: <20071211164011.33AE6282EFF8@mail.pubhealth.ku.dk>

Prof Brian Ripley wrote:
> I don't think that is the right fix.  All methods for min/max should
> now support na.rm=3DTRUE (but not finite=3DTRUE), so range.default shou=
ld
> just call min and max with that argument.
>
> I'd need to verify those 'should's first ....
>
OK, that why I didn't touch the sources....

    -p

> Brian
>
> On Tue, 11 Dec 2007, Peter Dalgaard wrote:
>
>> (Drats! Jitterbug is playing tricks with the PR# again. Attempting to
>> refile so that we can kill PR#10509)
>>
>> Peter Dalgaard wrote:
>>> Kurt.Hornik at wu-wien.ac.at wrote:
>>>
>>>> ------- Start of forwarded message -------
>>>> Date: Tue, 13 Nov 2007 21:44:57 +0100
>>>> To: Steve Mongin <sjm at ccbr.umn.edu>
>>>> Cc: cran at r-project.org
>>>> Subject: Re: range( <dates>, na.rm =3D TRUE )
>>>> In-Reply-To: <200711062044.OAA14064 at minnow.ccbr.umn.edu>
>>>> Reply-To: Kurt.Hornik at wu-wien.ac.at
>>>> From: Kurt Hornik <Kurt.Hornik at wu-wien.ac.at>
>>>> X-AntiVirus: checked by AntiVir MailGate (version: 2.1.3-2; AVE:
>>>> 7.6.0.34; VDF: 7.0.0.210; host: fsme.wu-wien.ac.at)
>>>> X-Virus-Scanned: ClamAV 0.90.3/4768/Tue Nov 13 18:25:08 2007 on
>>>> pocken.wu-wien.ac.at
>>>> X-Virus-Status: Clean
>>>>
>>>>
>>>>
>>>>>>>>> Steve Mongin writes:
>>>>>>>>>
>>>>>>>>>
>>>>
>>>>
>>>>> Dear CRAN:
>>>>> I am running 'R' on Linux as follows:
>>>>>
>>>>>
>>>>
>>>>
>>>>>> version
>>>>>>
>>>>>>
>>>>>                _
>>>>>   platform       i686-redhat-linux-gnu
>>>>>   arch           i686
>>>>>   os             linux-gnu
>>>>>   system         i686, linux-gnu
>>>>>   status
>>>>>   major          2
>>>>>   minor          6.0
>>>>>   year           2007
>>>>>   month          10
>>>>>   day            03
>>>>>   svn rev        43063
>>>>>   language       R
>>>>>   version.string R version 2.6.0 (2007-10-03)
>>>>>
>>>>>
>>>>
>>>>
>>>>> I have a question about the behavior of "range()" with missing date=
s.
>>>>>
>>>>>
>>>>
>>>>
>>>>> With the previous version (2.4?) , the command:
>>>>>
>>>>>
>>>>
>>>>
>>>>>> range( as.Date( c( "2007-11-06", NA ) ), na.rm =3D TRUE )
>>>>>>
>>>>>>
>>>>
>>>>
>>>>> yielded:
>>>>>
>>>>>
>>>>
>>>>
>>>>>> [1] "2007-11-06" "2007-11-06"
>>>>>>
>>>>>>
>>>>
>>>>
>>>>> Now I get:
>>>>>
>>>>>
>>>>
>>>>
>>>>>> [1] NA NA
>>>>>>
>>>>>>
>>>>
>>>>
>>>>> Is this a bug?
>>>>>
>>>>>
>>>>
>>>>
>>>>> Yes, I see in the "What's New" page:
>>>>>
>>>>>
>>>>
>>>>
>>>>>   "The Math2 and Summary groups (round, signif, all, any, max, min,=

>>>>>    summ, prod, range) are now primitive."
>>>>>
>>>>>
>>>>
>>>>
>>>>> Is the "primitive" characteristic supposed to behave as above with
>>>>> missing dates?
>>>>>
>>>>>
>>>>
>>>>
>>>>> Thanks for any help that you can provide.
>>>>>
>>>>>
>>>> This is really a question for r-devel or r-bugs, I think, but not fo=
r
>>>> the CRAN maintainers.
>>>>
>>>> I would think it is a bug.  Perhaps simply file a bug report?
>>>>
>>>>
>>>>
>>> Again? ;-)
>>>
>>> The bug is here:
>>>
>>>
>>>> range.default
>>>>
>>> function (..., na.rm =3D FALSE, finite =3D FALSE)
>>> {
>>>     x <- c(..., recursive =3D TRUE)
>>>     if (is.numeric(x)) {
>>>         if (finite)
>>>             x <- x[is.finite(x)]
>>>         else if (na.rm)
>>>             x <- x[!is.na(x)]
>>>     }
>>>     c(min(x), max(x))
>>> }
>>> <environment: namespace:base>
>>>
>>> Objects of class Date are not considered numeric, so we end up taking=

>>> min and max without removing NA.
>>>
>>> One solution could be
>>>
>>> if (is.numeric(x) || inherits(x, "Date") ){....}
>>>
>>>
>>>
>>
>>
>>
>


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327=
918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327=
907


From mtmorgan at fhcrc.org  Tue Dec 11 17:59:58 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 11 Dec 2007 08:59:58 -0800
Subject: [Rd] another S4 question ...
In-Reply-To: <475DB76E.5060503@zoo.ufl.edu> (Ben Bolker's message of "Mon,
	10 Dec 2007 17:02:22 -0500")
References: <475DB76E.5060503@zoo.ufl.edu>
Message-ID: <6ph63z5tbe9.fsf@gopher4.fhcrc.org>

Ben --

My vote would be against overriding the generic for show. If for some
reason your version proves inadequate, you force the user to
(conditional on loading your package) disambiguate 'show' to get the
methods package behavior.

?show says in part

     Formal methods for 'show' will usually be invoked for automatic
     printing (see the details).

and it's difficult to provide ... with automatic printing. On the
other hand, the naive user is probably expecting to be able to print()
your object (much as they are expecting to use 'as' rather than
'coerce'). ?show goes on to say

     The 'methods' package overrides the base definition of
     'print.default' to arrange for automatic printing to honor methods
     for the function 'show'.  This does not quite manage to override
     old-style printing methods, since the automatic printing in the
     evaluator will look first for the old-style method.

and the following might be a different solution

> setClass("A", representation=representation(x="numeric"))
[1] "A"
> print.A <- function(x, ...) cat("an A\n")
> print(new("A"))
an A

Another solution might be

> rm(print.A)
> setMethod("print", "A", function(x, ...) cat("another A\n"))
Creating a new generic function for "print" in ".GlobalEnv"
[1] "print"
> print(new("A"))
another A

This creates a 'print' generic with an identical signature to 'print',
which might be marginally better than creating another generic (for
'show') with a different signature. I think I'd still go with the
S3-style print, even though it mixes object systems, because it seems
to have the least potential to interfere with other packages.

Martin


Ben Bolker <bolker at zoo.ufl.edu> writes:

>   The default generic method for "show" has arguments
> show(object) -- (no "...")   -- which precludes any kind
> of arguments like "digits", etc.
>
>   Is it impossible, or a horrible idea, to override the
> generic definition?  (The "arm" package has defined a
> new generic, "display", which does a similar thing but
> has an intermediate level of detail (between "print/show"
> and "summary")
>
>   Ben Bolker
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From bolker at zoo.ufl.edu  Tue Dec 11 18:07:08 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 11 Dec 2007 12:07:08 -0500
Subject: [Rd] another S4 question ...
In-Reply-To: <6ph63z5tbe9.fsf@gopher4.fhcrc.org>
References: <475DB76E.5060503@zoo.ufl.edu> <6ph63z5tbe9.fsf@gopher4.fhcrc.org>
Message-ID: <475EC3BC.4020400@zoo.ufl.edu>

  Agreed.  It turns out a similar hack is done in the lme4
package for printMer ...

Martin Morgan wrote:
> Ben --
> 
> My vote would be against overriding the generic for show. If for some
> reason your version proves inadequate, you force the user to
> (conditional on loading your package) disambiguate 'show' to get the
> methods package behavior.
> 
> ?show says in part
> 
>      Formal methods for 'show' will usually be invoked for automatic
>      printing (see the details).
> 
> and it's difficult to provide ... with automatic printing. On the
> other hand, the naive user is probably expecting to be able to print()
> your object (much as they are expecting to use 'as' rather than
> 'coerce'). ?show goes on to say
> 
>      The 'methods' package overrides the base definition of
>      'print.default' to arrange for automatic printing to honor methods
>      for the function 'show'.  This does not quite manage to override
>      old-style printing methods, since the automatic printing in the
>      evaluator will look first for the old-style method.
> 
> and the following might be a different solution
> 
>> setClass("A", representation=representation(x="numeric"))
> [1] "A"
>> print.A <- function(x, ...) cat("an A\n")
>> print(new("A"))
> an A
> 
> Another solution might be
> 
>> rm(print.A)
>> setMethod("print", "A", function(x, ...) cat("another A\n"))
> Creating a new generic function for "print" in ".GlobalEnv"
> [1] "print"
>> print(new("A"))
> another A
> 
> This creates a 'print' generic with an identical signature to 'print',
> which might be marginally better than creating another generic (for
> 'show') with a different signature. I think I'd still go with the
> S3-style print, even though it mixes object systems, because it seems
> to have the least potential to interfere with other packages.
> 
> Martin
> 
> 
> Ben Bolker <bolker at zoo.ufl.edu> writes:
> 
>>   The default generic method for "show" has arguments
>> show(object) -- (no "...")   -- which precludes any kind
>> of arguments like "digits", etc.
>>
>>   Is it impossible, or a horrible idea, to override the
>> generic definition?  (The "arm" package has defined a
>> new generic, "display", which does a similar thing but
>> has an intermediate level of detail (between "print/show"
>> and "summary")
>>
>>   Ben Bolker
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 252 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20071211/f3a5cb42/attachment.bin 

From ripley at stats.ox.ac.uk  Tue Dec 11 18:11:06 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 11 Dec 2007 17:11:06 +0000 (GMT)
Subject: [Rd] another S4 question ...
In-Reply-To: <475DB76E.5060503@zoo.ufl.edu>
References: <475DB76E.5060503@zoo.ufl.edu>
Message-ID: <Pine.LNX.4.64.0712110842150.10434@gannet.stats.ox.ac.uk>

Here is my current understanding: this area has changed a bit recently.

S4 generics of the same name in different packages are regarded as 
different.  If you define a generic show() in your package, it will not 
have any of the methods defined on methods::show, and likely mask the 
latter. So users will be asking 'where have all my show() methods gone?'.

Then there are the perennial scoping problems.  If both your package and 
methods have generics for show(), which is found depends on where you are 
looking from: you cannot in general 'override' an existing function in 
R's scoping system.  For example, any function in another package that 
imports 'methods' will find methods:::show and not your version.

This is a generic problem: e.g. both packages stats4 and lme4 have 
generics for BIC, and you will get the methods for one or the other 
depending on which is found first in the current scope.

On Mon, 10 Dec 2007, Ben Bolker wrote:

>  The default generic method for "show" has arguments
> show(object) -- (no "...")   -- which precludes any kind
> of arguments like "digits", etc.

You can define methods on print(), if you want those arguments.

>  Is it impossible, or a horrible idea, to override the
> generic definition?  (The "arm" package has defined a
> new generic, "display", which does a similar thing but
> has an intermediate level of detail (between "print/show"
> and "summary")
>
>  Ben Bolker
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tplate at acm.org  Tue Dec 11 19:18:48 2007
From: tplate at acm.org (Tony Plate)
Date: Tue, 11 Dec 2007 11:18:48 -0700
Subject: [Rd] Interactiveness
In-Reply-To: <475EB378.7030101@Update.UU.SE>
References: <475EA1FB.8010002@Update.UU.SE>	<Pine.LNX.4.64.0712111454180.7824@auk.stats>
	<475EB378.7030101@Update.UU.SE>
Message-ID: <475ED488.4080805@acm.org>

Bjarni Juliusson wrote:
> Prof Brian Ripley wrote:
>   
>> On Tue, 11 Dec 2007, Bjarni Juliusson wrote:
>>     
>>> I'm developing R integration for a project called Bioclipse at Uppsala
>>> University. The current implementation works by simply forking an R and
>>> sending it text (with some substitutions on it) down a pipe, getting the
>>> printed output back up another pipe. This of course works fine, except
>>> it runs into one problem: R finds a pipe on its stdin and decides to be
>>> "non-interactive", which means that as soon as the user makes a typo and
>>> causes an error, R exits.
>>>       
>> Actually, not so.  The default error handler for non-interactive use is 
>> to do that, but you can change it.
>>     
>
> Could you perhaps just point me in the right direction here? I really 
> have no idea how to do this.
>   
Specify a non-NULL error handler by doing something like this:
 > options(error=dump.frames)
See ?options (look for "error") and ?stop for more details.

-- Tony Plate

> Also, what exactly does non-interactive mode imply, besides this default 
> error handling behaviour?
>
>   
>>> I checked the source, and it's a couple of isatty()'s in the two files
>>> named system.c that are doing it. They are of course intended to be a
>>> feature, but in this case it causes us trouble. Would it be possible to
>>> get a command line switch to control this behaviour? I'm not sure pseudo
>>> terminals can be used portably, or can they?
>>>       
>> They can, and are e.g. by ESS (except on Windows, where there is already 
>> a switch).  I think you need to look a bit more carefully at what other 
>> projects do.
>>     
>
> It needs to be portable to Windows. I'll look into this possibility next.
>
> Didn't mean to ask before I had done my homework. Thanks for your help!
>
>
> Bjarni
>


From marc_schwartz at comcast.net  Tue Dec 11 21:08:37 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 11 Dec 2007 14:08:37 -0600
Subject: [Rd] Defaults for postscript()
In-Reply-To: <Pine.LNX.4.64.0712101212001.13534@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
	<eb555e660712060032v46ce904clf1e454394b59e943@mail.gmail.com>
	<Pine.LNX.4.64.0712101212001.13534@gannet.stats.ox.ac.uk>
Message-ID: <1197403717.5253.73.camel@Bellerophon.localdomain>


On Tue, 2007-12-11 at 10:30 +0000, Prof Brian Ripley wrote:
> I think everyone who commented has overlooked that the defaults for these 
> postscript() arguments are set by ps.options(), so in fact we are talking 
> about the defaults for the defaults.  Unfortunately, the documentation on 
> this was full of errors, including not pointing out that some of the 
> ps.options() settings apply to xfig() and pdf() (and some do not).
> In fact, although you can set the default for 'onefile' via ps.options(), 
> that setting is never used AFAICS.

That actually sounds familiar. I think that I ran into that a few years
ago when I was writing some reports and attempted to use that option.

Yep, checking my svn files, I found the following comment:

# Set ps.options() for most, though postscript() will override the
# onefile = FALSE.
ps.options(horizontal = FALSE, paper = "special", 
           width = 9.5, height = 7.5)
...

Apparently, for whatever reason, I did not pursue it further...seems
contrary to my usual dive in with both arms and feet paradigm... :-)

> This means that it was never completely safe to rely on the defaults in 
> test scripts in packages, since a site could change these defaults 
> (although hopefully it would have been done in a file skipped by 
> --vanilla).
> 
> Given that (most of) the defaults are customizable, it does seem to me to 
> be much more important to have defaults that are appropriate to the naive 
> user and not the expert one.  When I first drafted this, I thought one 
> could switch between the old and proposed defaults via a call to 
> ps.options(), but despite documenting 'onefile' as an argument, it is 
> never actually used.

I do agree here that given the catalyst for considering these changes,
it seems appropriate to focus on ease of use, which in this case, would
need not come at the expense of flexibility.

Within that context, I do rather fancy Henrik's suggestion of an eps()
wrapper to postscript:

  https://stat.ethz.ch/pipermail/r-devel/2007-December/047658.html

though I might be tempted to further constrain the function prototype
to:

  eps <- function(file = "Rplot%03d.eps", height = 6, width = 6, ...) {
     postscript(file = file, onefile = FALSE, horizontal = FALSE,
                height = height, width = width, paper = "special", ...)
  }

given the most common use of eps files. That still leaves the native
postscript() function available for additional customization as
required, including using ps.options().

> I had a further follow-up suggestion, which is to change the default 
> device in non-interactive use from postscript() to pdf().  I believe that 
> PDF viewers are more widely available than PS viewers these days (almost 
> every Windows box ships with AcroRead, and Mac OS has native PDF viewers). 
> There used to be an argument over the non-availability of Free PDF viewers 
> and the limited range of platforms supported by AcroRead, but the 
> availability of several viewers based on xpdf seem to satisfy that 
> argument at least as well as the availability of ghostscript and 
> front-ends do for PS (and GSView, the Windows front-end, is shareware-like 
> - I keep forgetting that, as Oxford has a site licence).

This seems reasonable for all of the reasons referenced. Even for LaTeX
use, unless one is using PS specific packages (eg. pstricks, which I
tend to use for diagrams, etc.), using pdflatex seems more common for
new users.

> I remain convinced that producing rotated PS plots of a size (and aspect 
> ratio) that depends on the locale (since the default papersize does) is no 
> longer a reasonable default.
> 
> That leaves onefile=TRUE.  Even if we don't move the non-interactive 
> default device to pdf, it could be postscript(onefile=TRUE).  However, it 
> ought to be possible to implement onefile=NA, which would write an EPS 
> file if only one plot was produced and a multi-page PS file otherwise.
> That would seem to me to be a good compromise.

My initial reaction is that this approach would seem to make things more
difficult from a maintenance/documentation standpoint, but perhaps I am
missing something.

> Comment to Marc Schwartz: we can't force a Notes sections above Details, 
> as the ordering of sections is dictated by Rdconv.  I had already done 
> some re-structuring of the page, moving printing to a new section.

I noted that in svn. Thanks.

> A further comment: I wonder if we really want this complexity of using 
> ps.options() to set default defaults: I am inclined to remove it for xfig 
> and pdf.  (Given that it was not documented, it is unlikely anyone is
> knowingly used it.)

Again, seems reasonable. I would tend to favor parsimony here.

Thanks!

Marc

<snip>


From gregory.warnes at mac.com  Tue Dec 11 23:47:15 2007
From: gregory.warnes at mac.com (Gregory Warnes)
Date: Tue, 11 Dec 2007 17:47:15 -0500
Subject: [Rd] Interactiveness
In-Reply-To: <475ED488.4080805@acm.org>
References: <475EA1FB.8010002@Update.UU.SE>	<Pine.LNX.4.64.0712111454180.7824@auk.stats><475EB378.7030101@Update.UU.SE>
	<475ED488.4080805@acm.org>
Message-ID: <20921CBE-9E8C-4EB1-AB2B-DBB3E6E96507@mac.com>


You might also find many of the tools provided in the 'session'  
package helpful for interacting with R in this way.

'session' package description:

Utility functions for interacting with R processes from external  
programs. This package includes functions to save and restore session  
information (including loaded packages, and attached data objects),  
as well as functions to evaluate strings containing R commands and  
return the printed results or an execution transcript.

-Greg


On Dec 11, 2007, at 1:18PM , Tony Plate wrote:

> Bjarni Juliusson wrote:
>> Prof Brian Ripley wrote:
>>
>>> On Tue, 11 Dec 2007, Bjarni Juliusson wrote:
>>>
>>>> I'm developing R integration for a project called Bioclipse at  
>>>> Uppsala
>>>> University. The current implementation works by simply forking  
>>>> an R and
>>>> sending it text (with some substitutions on it) down a pipe,  
>>>> getting the
>>>> printed output back up another pipe. This of course works fine,  
>>>> except
>>>> it runs into one problem: R finds a pipe on its stdin and  
>>>> decides to be
>>>> "non-interactive", which means that as soon as the user makes a  
>>>> typo and
>>>> causes an error, R exits.
>>>>
>>> Actually, not so.  The default error handler for non-interactive  
>>> use is
>>> to do that, but you can change it.
>>>
>>
>> Could you perhaps just point me in the right direction here? I really
>> have no idea how to do this.
>>
> Specify a non-NULL error handler by doing something like this:
>> options(error=dump.frames)
> See ?options (look for "error") and ?stop for more details.
>
> -- Tony Plate
>
>> Also, what exactly does non-interactive mode imply, besides this  
>> default
>> error handling behaviour?
>>
>>
>>>> I checked the source, and it's a couple of isatty()'s in the two  
>>>> files
>>>> named system.c that are doing it. They are of course intended to  
>>>> be a
>>>> feature, but in this case it causes us trouble. Would it be  
>>>> possible to
>>>> get a command line switch to control this behaviour? I'm not  
>>>> sure pseudo
>>>> terminals can be used portably, or can they?
>>>>
>>> They can, and are e.g. by ESS (except on Windows, where there is  
>>> already
>>> a switch).  I think you need to look a bit more carefully at what  
>>> other
>>> projects do.
>>>
>>
>> It needs to be portable to Windows. I'll look into this  
>> possibility next.
>>
>> Didn't mean to ask before I had done my homework. Thanks for your  
>> help!
>>
>>
>> Bjarni
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edward.m at psu.ac.th  Wed Dec 12 03:15:08 2007
From: edward.m at psu.ac.th (edward.m at psu.ac.th)
Date: Wed, 12 Dec 2007 03:15:08 +0100 (CET)
Subject: [Rd] Adding a survival object to a data frame (PR#10510)
Message-ID: <20071212021508.D18A92834155@mail.pubhealth.ku.dk>

Full_Name: Edward McNeil
Version: 2.6.1
OS: Windows
Submission from: (NULL) (203.170.234.5)


I want to show students how the survival object looks like in R.
Reproducible example:

library(MASS)
data(Aids2)
attach(Aids2)
status <- status=="D"
stime <- death-diag
surv <- Surv(stime, status)
D <- data.frame(stime, status, surv)
head(D,20)
   stime status x..i..
1    176   TRUE   176 
2     67   TRUE    67 
3    432   TRUE   432 
4     77   TRUE    77 
5    275   TRUE   275 
6    373   TRUE   373 
7    389   TRUE   389 
8   1027   TRUE  1027 
9    492   TRUE   492 
10   434   TRUE   434 
11    16   TRUE    16 
12   308   TRUE   308 
13    92   TRUE    92 
14   265   TRUE   265 
15  1052  FALSE  1052+
16   132   TRUE   132 
17   527   TRUE   527 
18   581  FALSE   581+
19   511  FALSE   511+
20   151   TRUE   151 

detach(Aids2)

The 'surv' column is strangely labelled 'x..i..'.


From abhishek at james.hut.fi  Wed Dec 12 10:55:34 2007
From: abhishek at james.hut.fi (Abhishek Tripathi)
Date: Wed, 12 Dec 2007 11:55:34 +0200 (EET)
Subject: [Rd] R CMD check error, Readitem unknown type 203
Message-ID: <Pine.LNX.4.64.0712121148390.32134@itl-pc16.hut.fi>


Hi,

Apologies if it has already been posted. I searched the archives and 
couldn't find the answer to my problem.

I am building a R package and while checking it with R CMD check, I get 
the following error,

  * checking whether package 'drCCA' can be installed ... ERROR
  Installation failed.

00install.out shows following message,

  ** building package indices ...
  Error in load(zfile, envir = envir) : ReadItem: unknown type 203
  Execution halted
  ERROR: installing package indices failed


Does somebody has any idea what it means?? 
Thanks a lot.

Regards,
Abhishek Tripathi
Researcher
Department of Computer Science
University of Helsinki


From simecek at gmail.com  Tue Dec 11 12:20:25 2007
From: simecek at gmail.com (simecek at gmail.com)
Date: Tue, 11 Dec 2007 12:20:25 +0100 (CET)
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
Message-ID: <20071211112025.811162834156@mail.pubhealth.ku.dk>

Full_Name: Petr Simecek
Version: 2.5.1, 2.6.1
OS: Windows XP
Submission from: (NULL) (195.113.231.2)


Several times I have experienced that a length of a POSIXt vector has not been
computed right.

Example:

tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 
12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 
13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", 
"min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
), class = c("POSIXt", "POSIXlt"))

print(tv)
# print 11 time points (right)

length(tv)
# returns 9 (wrong)

I have tried that on several computers with/without switching to English
locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help pages but I
cannot imagine how that could be OK.


From P.Dalgaard at biostat.ku.dk  Wed Dec 12 15:39:53 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 12 Dec 2007 15:39:53 +0100
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <20071211112025.811162834156@mail.pubhealth.ku.dk>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
Message-ID: <475FF2B9.7030109@biostat.ku.dk>

simecek at gmail.com wrote:
> Full_Name: Petr Simecek
> Version: 2.5.1, 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.113.231.2)
>
>
> Several times I have experienced that a length of a POSIXt vector has not been
> computed right.
>
> Example:
>
> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 
> 12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 
> 13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", 
> "min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
> ), class = c("POSIXt", "POSIXlt"))
>
> print(tv)
> # print 11 time points (right)
>
> length(tv)
> # returns 9 (wrong)
>
> I have tried that on several computers with/without switching to English
> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help pages but I
> cannot imagine how that could be OK.
>
>   
Given the way you define it, you should be able to imagine it!

It's a list of length 9:  sec, min, hour,..., isdst.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Wed Dec 12 15:43:02 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Dec 2007 09:43:02 -0500
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <20071211112025.811162834156@mail.pubhealth.ku.dk>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
Message-ID: <475FF376.8080806@stats.uwo.ca>

On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
> Full_Name: Petr Simecek
> Version: 2.5.1, 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.113.231.2)
> 
> 
> Several times I have experienced that a length of a POSIXt vector has not been
> computed right.
> 
> Example:
> 
> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 
> 12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 
> 13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", 
> "min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
> ), class = c("POSIXt", "POSIXlt"))
> 
> print(tv)
> # print 11 time points (right)
> 
> length(tv)
> # returns 9 (wrong)

tv is a list of length 9.  The answer is right, your expectation is wrong.
> 
> I have tried that on several computers with/without switching to English
> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help pages but I
> cannot imagine how that could be OK.

See this in ?POSIXt:

Class '"POSIXlt"' is a named list of vectors...

You could define your own length measurement as

length.POSIXlt <- function(x) length(x$sec)

and you'll get the answer you expect, but be aware that length.XXX 
methods are quite rare, and you may surprise some of your users.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Wed Dec 12 15:45:21 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 12 Dec 2007 15:45:21 +0100 (CET)
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
Message-ID: <20071212144521.5DCBC2834620@mail.pubhealth.ku.dk>

It is right: it is a list of length 9.  You even constructed it as such a 
list!

On Tue, 11 Dec 2007, simecek at gmail.com wrote:

> Full_Name: Petr Simecek
> Version: 2.5.1, 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.113.231.2)
>
>
> Several times I have experienced that a length of a POSIXt vector has not been
> computed right.
>
> Example:
>
> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L,
> 12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L,
> 13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L,
> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L,
> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec",
> "min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
> ), class = c("POSIXt", "POSIXlt"))
>
> print(tv)
> # print 11 time points (right)
>
> length(tv)
> # returns 9 (wrong)
>
> I have tried that on several computers with/without switching to English 
> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help 
> pages but I cannot imagine how that could be OK.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Wed Dec 12 15:45:08 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Dec 2007 09:45:08 -0500
Subject: [Rd] R CMD check error, Readitem unknown type 203
In-Reply-To: <Pine.LNX.4.64.0712121148390.32134@itl-pc16.hut.fi>
References: <Pine.LNX.4.64.0712121148390.32134@itl-pc16.hut.fi>
Message-ID: <475FF3F4.5020107@stats.uwo.ca>

On 12/12/2007 4:55 AM, Abhishek Tripathi wrote:
> Hi,
> 
> Apologies if it has already been posted. I searched the archives and 
> couldn't find the answer to my problem.
> 
> I am building a R package and while checking it with R CMD check, I get 
> the following error,
> 
>   * checking whether package 'drCCA' can be installed ... ERROR
>   Installation failed.
> 
> 00install.out shows following message,
> 
>   ** building package indices ...
>   Error in load(zfile, envir = envir) : ReadItem: unknown type 203
>   Execution halted
>   ERROR: installing package indices failed
> 
> 
> Does somebody has any idea what it means?? 

I would guess you are trying to build it in an obsolete version of R. 
It probably contains binary data created in a newer version.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Wed Dec 12 15:50:19 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 12 Dec 2007 15:50:19 +0100 (CET)
Subject: [Rd] Adding a survival object to a data frame (PR#10510)
Message-ID: <20071212145020.098072834620@mail.pubhealth.ku.dk>

Your example is not reproducible without 'library(survival)'.
When I include that, I get

> head(D,20)
    stime status  surv
1    176   TRUE  176
...

Objects of class "Surv" are from the contributed package survival, and you 
need that attached to deal with them properly.


On Wed, 12 Dec 2007, edward.m at psu.ac.th wrote:

> Full_Name: Edward McNeil
> Version: 2.6.1
> OS: Windows
> Submission from: (NULL) (203.170.234.5)
>
>
> I want to show students how the survival object looks like in R.
> Reproducible example:
>
> library(MASS)
> data(Aids2)
> attach(Aids2)
> status <- status=="D"
> stime <- death-diag
> surv <- Surv(stime, status)
> D <- data.frame(stime, status, surv)
> head(D,20)
>   stime status x..i..
> 1    176   TRUE   176
> 2     67   TRUE    67
> 3    432   TRUE   432
> 4     77   TRUE    77
> 5    275   TRUE   275
> 6    373   TRUE   373
> 7    389   TRUE   389
> 8   1027   TRUE  1027
> 9    492   TRUE   492
> 10   434   TRUE   434
> 11    16   TRUE    16
> 12   308   TRUE   308
> 13    92   TRUE    92
> 14   265   TRUE   265
> 15  1052  FALSE  1052+
> 16   132   TRUE   132
> 17   527   TRUE   527
> 18   581  FALSE   581+
> 19   511  FALSE   511+
> 20   151   TRUE   151
>
> detach(Aids2)
>
> The 'surv' column is strangely labelled 'x..i..'.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Dec 12 15:43:02 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Dec 2007 14:43:02 +0000 (GMT)
Subject: [Rd] R CMD check error, Readitem unknown type 203
In-Reply-To: <Pine.LNX.4.64.0712121148390.32134@itl-pc16.hut.fi>
References: <Pine.LNX.4.64.0712121148390.32134@itl-pc16.hut.fi>
Message-ID: <Pine.LNX.4.64.0712121441200.8441@gannet.stats.ox.ac.uk>

On Wed, 12 Dec 2007, Abhishek Tripathi wrote:

>
> Hi,
>
> Apologies if it has already been posted. I searched the archives and
> couldn't find the answer to my problem.
>
> I am building a R package and while checking it with R CMD check, I get
> the following error,
>
>  * checking whether package 'drCCA' can be installed ... ERROR
>  Installation failed.
>
> 00install.out shows following message,
>
>  ** building package indices ...
>  Error in load(zfile, envir = envir) : ReadItem: unknown type 203
>  Execution halted
>  ERROR: installing package indices failed
>
>
> Does somebody has any idea what it means??

It means your package is corrupt, most likely something in the data files.

> Thanks a lot.
>
> Regards,
> Abhishek Tripathi
> Researcher
> Department of Computer Science
> University of Helsinki
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Wed Dec 12 16:23:15 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 12 Dec 2007 16:23:15 +0100
Subject: [Rd] Adding a survival object to a data frame (PR#10510)
In-Reply-To: <20071212145020.098072834620@mail.pubhealth.ku.dk>
References: <20071212145020.098072834620@mail.pubhealth.ku.dk>
Message-ID: <475FFCE3.70500@biostat.ku.dk>

ripley at stats.ox.ac.uk wrote:
> Your example is not reproducible without 'library(survival)'.
> When I include that, I get
>
>   
>> head(D,20)
>>     
>     stime status  surv
> 1    176   TRUE  176
> ...
>
> Objects of class "Surv" are from the contributed package survival, and you 
> need that attached to deal with them properly.
>
>
>   
... but even if you detach it, you do not get the symptoms shown:

> head(D,5)
   stime status surv.time surv.status
1    176   TRUE       176           1
2     67   TRUE        67           1
3    432   TRUE       432           1
4     77   TRUE        77           1
5    275   TRUE       275           1


> On Wed, 12 Dec 2007, edward.m at psu.ac.th wrote:
>
>   
>> Full_Name: Edward McNeil
>> Version: 2.6.1
>> OS: Windows
>> Submission from: (NULL) (203.170.234.5)
>>
>>
>> I want to show students how the survival object looks like in R.
>> Reproducible example:
>>
>> library(MASS)
>> data(Aids2)
>> attach(Aids2)
>> status <- status=="D"
>> stime <- death-diag
>> surv <- Surv(stime, status)
>> D <- data.frame(stime, status, surv)
>> head(D,20)
>>   stime status x..i..
>> 1    176   TRUE   176
>> 2     67   TRUE    67
>> 3    432   TRUE   432
>> 4     77   TRUE    77
>> 5    275   TRUE   275
>> 6    373   TRUE   373
>> 7    389   TRUE   389
>> 8   1027   TRUE  1027
>> 9    492   TRUE   492
>> 10   434   TRUE   434
>> 11    16   TRUE    16
>> 12   308   TRUE   308
>> 13    92   TRUE    92
>> 14   265   TRUE   265
>> 15  1052  FALSE  1052+
>> 16   132   TRUE   132
>> 17   527   TRUE   527
>> 18   581  FALSE   581+
>> 19   511  FALSE   511+
>> 20   151   TRUE   151
>>
>> detach(Aids2)
>>
>> The 'surv' column is strangely labelled 'x..i..'.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>     
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From veleinon at mail.student.oulu.fi  Wed Dec 12 17:07:34 2007
From: veleinon at mail.student.oulu.fi (Veikko Leinonen)
Date: Wed, 12 Dec 2007 18:07:34 +0200
Subject: [Rd] APARCH
Message-ID: <1197475654.47600746b635f@webmail.oulu.fi>


Hi, 

Could somebody say if it is possible to compute APARCH-models with garchFit
commands. 

I have earlier used aaa (garchOxFit) and now I try to use bbb (look below) 

aaa <-
garchOxFit(formula.mean=~arma(1,0),formula.var=~aparch(1,1),series=nyk,cond.dist=c('gaussian'))


bbb <- garchFit(formula=~arma(1,0)+aparch(1,1),data=nyk) 

aaa works well, but I need other characteristics of garchFit and, therefore it
would be important to know what's wrong with my bbb command (the value of delta
is fixed to 2 and I get totally different coefficients than with aaa). 

How should I write bbb to get similar answer than with aaa? 

Thanks a lot,

Veikko


From bolker at ufl.edu  Thu Dec 13 06:04:41 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 13 Dec 2007 00:04:41 -0500
Subject: [Rd] S4 class extending data.frame?
Message-ID: <4760BD69.2020807@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I would like to build an S4 class that extends
a data frame, but includes several more slots.

Here's an example using integer as the base
class instead:

setClass("c1",representation(comment="character"),contains="integer")
z1 = new("c1",55,comment="hello")
z1
z1+10
z1[1]
z1 at comment

 -- in other words, it behaves exactly as an integer
for access and operations but happens to have another slot.

 If I do this with a data frame instead, it doesn't seem to work
at all.

setClass("c2",representation(comment="character"),contains="data.frame")
d = data.frame(1:3,2:4)
z2 = new("c2",d,comment="goodbye")
z2  ## data all gone!!
z2[,1]  ## Error ... object is not subsettable
z2 at comment  ## still there

  I can achieve approximately the same effect by
adding attributes, but I was hoping for the structure
of S4 classes ...

  Programming with Data and the R Language Definition
contain 2 references each to data frames, and neither of
them has allowed me to figure out this behavior.

 (While I'm at it: it would be wonderful to have
a "rich data frame" that could include as a column
any object that had an appropriate length and
[ method ... has anyone done anything in this direction?
?data.frame says the allowable types are
 "(numeric, logical, factor and character and so on)",
 but I'm having trouble sorting out what the limitations
are ...)

  hoping for enlightenment (it would be lovely to be
shown how to make this work, but a definitive statement
that it is impossible would be useful too).

  cheers
    Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFHYL1pc5UpGjwzenMRAqErAJ9jj1KgVVSGIf+DtK7Km/+JBaDu2QCaAkl/
eMi+WCEWK6FPpVMpUbo+RBQ=
=huvz
-----END PGP SIGNATURE-----


From osklyar at ebi.ac.uk  Thu Dec 13 11:41:42 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 13 Dec 2007 10:41:42 +0000
Subject: [Rd] S4 class extending data.frame?
In-Reply-To: <4760BD69.2020807@ufl.edu>
References: <4760BD69.2020807@ufl.edu>
Message-ID: <1197542502.7435.4.camel@maitai.windows.ebi.ac.uk>

I had the same problem. Generally data.frame's behave like lists, but
while you can extend list, there are problems extending a data.frame
class. This comes down to the internal representation of the object I
guess. Vectors, including list, contain their information in a (hidden)
slot .Data (see the example below). data.frame's do not seem to follow
this convention.

Any idea how to go around?

The following example is exactly the same as Ben's for a data.frame, but
using a list. It works fine and one can see that the list structure is
stored in .Data

* ~: R
R version 2.6.1 (2007-11-26) 
> setClass("c3",representation(comment="character"),contains="list")
[1] "c3"
> l = list(1:3,2:4)
> z3 = new("c3",l,comment="hello")
> z3
An object of class ?c3?
[[1]]
[1] 1 2 3

[[2]]
[1] 2 3 4

Slot "comment":
[1] "hello"

> z3 at .Data
[[1]]
[1] 1 2 3

[[2]]
[1] 2 3 4

Regards,
Oleg

On Thu, 2007-12-13 at 00:04 -0500, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> I would like to build an S4 class that extends
> a data frame, but includes several more slots.
> 
> Here's an example using integer as the base
> class instead:
> 
> setClass("c1",representation(comment="character"),contains="integer")
> z1 = new("c1",55,comment="hello")
> z1
> z1+10
> z1[1]
> z1 at comment
> 
>  -- in other words, it behaves exactly as an integer
> for access and operations but happens to have another slot.
> 
>  If I do this with a data frame instead, it doesn't seem to work
> at all.
> 
> setClass("c2",representation(comment="character"),contains="data.frame")
> d = data.frame(1:3,2:4)
> z2 = new("c2",d,comment="goodbye")
> z2  ## data all gone!!
> z2[,1]  ## Error ... object is not subsettable
> z2 at comment  ## still there
> 
>   I can achieve approximately the same effect by
> adding attributes, but I was hoping for the structure
> of S4 classes ...
> 
>   Programming with Data and the R Language Definition
> contain 2 references each to data frames, and neither of
> them has allowed me to figure out this behavior.
> 
>  (While I'm at it: it would be wonderful to have
> a "rich data frame" that could include as a column
> any object that had an appropriate length and
> [ method ... has anyone done anything in this direction?
> ?data.frame says the allowable types are
>  "(numeric, logical, factor and character and so on)",
>  but I'm having trouble sorting out what the limitations
> are ...)
> 
>   hoping for enlightenment (it would be lovely to be
> shown how to make this work, but a definitive statement
> that it is impossible would be useful too).
> 
>   cheers
>     Ben Bolker
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFHYL1pc5UpGjwzenMRAqErAJ9jj1KgVVSGIf+DtK7Km/+JBaDu2QCaAkl/
> eMi+WCEWK6FPpVMpUbo+RBQ=
> =huvz
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466


From ripley at stats.ox.ac.uk  Thu Dec 13 12:09:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Dec 2007 11:09:46 +0000 (GMT)
Subject: [Rd] Adding a survival object to a data frame (PR#10510)
In-Reply-To: <475FFCE3.70500@biostat.ku.dk>
References: <20071212145020.098072834620@mail.pubhealth.ku.dk>
	<475FFCE3.70500@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0712131107540.7645@gannet.stats.ox.ac.uk>

Apparently this was Surv from package Design.
So the bug is in contributed package Design, and nothing to do with 
R-bugs.

On Wed, 12 Dec 2007, Peter Dalgaard wrote:

> ripley at stats.ox.ac.uk wrote:
>> Your example is not reproducible without 'library(survival)'.
>> When I include that, I get
>>
>>
>>> head(D,20)
>>>
>>     stime status  surv
>> 1    176   TRUE  176
>> ...
>>
>> Objects of class "Surv" are from the contributed package survival, and you
>> need that attached to deal with them properly.
>>
>>
>>
> ... but even if you detach it, you do not get the symptoms shown:
>
>> head(D,5)
>   stime status surv.time surv.status
> 1    176   TRUE       176           1
> 2     67   TRUE        67           1
> 3    432   TRUE       432           1
> 4     77   TRUE        77           1
> 5    275   TRUE       275           1
>
>
>> On Wed, 12 Dec 2007, edward.m at psu.ac.th wrote:
>>
>>
>>> Full_Name: Edward McNeil
>>> Version: 2.6.1
>>> OS: Windows
>>> Submission from: (NULL) (203.170.234.5)
>>>
>>>
>>> I want to show students how the survival object looks like in R.
>>> Reproducible example:
>>>
>>> library(MASS)
>>> data(Aids2)
>>> attach(Aids2)
>>> status <- status=="D"
>>> stime <- death-diag
>>> surv <- Surv(stime, status)
>>> D <- data.frame(stime, status, surv)
>>> head(D,20)
>>>   stime status x..i..
>>> 1    176   TRUE   176
>>> 2     67   TRUE    67
>>> 3    432   TRUE   432
>>> 4     77   TRUE    77
>>> 5    275   TRUE   275
>>> 6    373   TRUE   373
>>> 7    389   TRUE   389
>>> 8   1027   TRUE  1027
>>> 9    492   TRUE   492
>>> 10   434   TRUE   434
>>> 11    16   TRUE    16
>>> 12   308   TRUE   308
>>> 13    92   TRUE    92
>>> 14   265   TRUE   265
>>> 15  1052  FALSE  1052+
>>> 16   132   TRUE   132
>>> 17   527   TRUE   527
>>> 18   581  FALSE   581+
>>> 19   511  FALSE   511+
>>> 20   151   TRUE   151
>>>
>>> detach(Aids2)
>>>
>>> The 'surv' column is strangely labelled 'x..i..'.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Thu Dec 13 16:01:35 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 13 Dec 2007 07:01:35 -0800
Subject: [Rd] S4 class extending data.frame?
In-Reply-To: <1197542502.7435.4.camel@maitai.windows.ebi.ac.uk> (Oleg
	Sklyar's message of "Thu, 13 Dec 2007 10:41:42 +0000")
References: <4760BD69.2020807@ufl.edu>
	<1197542502.7435.4.camel@maitai.windows.ebi.ac.uk>
Message-ID: <6ph7ijir640.fsf@gopher4.fhcrc.org>

Ben, Oleg --

Some solutions, which you've probably already thought of, are (a) move
the data.frame into its own slot, instead of extending it, (b) manage
the data.frame attributes yourself, or (c) reinvent the data.frame
from scratch as a proper S4 class (e.g., extending 'list' with
validity constraints on element length and homogeneity of element
content).

(b) places a lot of dependence on understanding the data.frame
implementation, and is probably too tricky (for me) to get right,(c)
is probably also tricky, and probably caries significant performance
overhead (e.g., object duplication during validity checking).

(a) means that you don't get automatic method inheritance. On the plus
side, you still get the structure. It is trivial to implement methods
like [, [[, etc to dispatch on your object and act on the appropriate
slot. And in some sense you now know what methods i.e., those you've
implemented, are supported on your object.

Oleg, here's my cautionary tale for extending list, where manually
subsetting the .Data slot mixes up the names (callNextMethod would
have done the right thing, but was not appropriate). This was quite a
subtle bug for me, because I hadn't been expecting named lists in my
object; the problem surfaced when sapply used the (incorrectly subset)
names attribute of the list. My solution in this case was to make sure
'names' were removed from lists used to construct objects. As a
consequence I lose a nice little bit of sapply magic.

> setClass('A', 'list')
[1] "A"
> setMethod('[', 'A', function(x, i, j, ..., drop=TRUE) {
+     x at .Data <- x at .Data[i]
+     x
+ })
[1] "["
> names(new('A', list(x=1, y=2))[2])
[1] "x"

Martin

Oleg Sklyar <osklyar at ebi.ac.uk> writes:

> I had the same problem. Generally data.frame's behave like lists, but
> while you can extend list, there are problems extending a data.frame
> class. This comes down to the internal representation of the object I
> guess. Vectors, including list, contain their information in a (hidden)
> slot .Data (see the example below). data.frame's do not seem to follow
> this convention.
>
> Any idea how to go around?
>
> The following example is exactly the same as Ben's for a data.frame, but
> using a list. It works fine and one can see that the list structure is
> stored in .Data
>
> * ~: R
> R version 2.6.1 (2007-11-26) 
>> setClass("c3",representation(comment="character"),contains="list")
> [1] "c3"
>> l = list(1:3,2:4)
>> z3 = new("c3",l,comment="hello")
>> z3
> An object of class ?c3?
> [[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 2 3 4
>
> Slot "comment":
> [1] "hello"
>
>> z3 at .Data
> [[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 2 3 4
>
> Regards,
> Oleg
>
> On Thu, 2007-12-13 at 00:04 -0500, Ben Bolker wrote:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>> 
>> I would like to build an S4 class that extends
>> a data frame, but includes several more slots.
>> 
>> Here's an example using integer as the base
>> class instead:
>> 
>> setClass("c1",representation(comment="character"),contains="integer")
>> z1 = new("c1",55,comment="hello")
>> z1
>> z1+10
>> z1[1]
>> z1 at comment
>> 
>>  -- in other words, it behaves exactly as an integer
>> for access and operations but happens to have another slot.
>> 
>>  If I do this with a data frame instead, it doesn't seem to work
>> at all.
>> 
>> setClass("c2",representation(comment="character"),contains="data.frame")
>> d = data.frame(1:3,2:4)
>> z2 = new("c2",d,comment="goodbye")
>> z2  ## data all gone!!
>> z2[,1]  ## Error ... object is not subsettable
>> z2 at comment  ## still there
>> 
>>   I can achieve approximately the same effect by
>> adding attributes, but I was hoping for the structure
>> of S4 classes ...
>> 
>>   Programming with Data and the R Language Definition
>> contain 2 references each to data frames, and neither of
>> them has allowed me to figure out this behavior.
>> 
>>  (While I'm at it: it would be wonderful to have
>> a "rich data frame" that could include as a column
>> any object that had an appropriate length and
>> [ method ... has anyone done anything in this direction?
>> ?data.frame says the allowable types are
>>  "(numeric, logical, factor and character and so on)",
>>  but I'm having trouble sorting out what the limitations
>> are ...)
>> 
>>   hoping for enlightenment (it would be lovely to be
>> shown how to make this work, but a definitive statement
>> that it is impossible would be useful too).
>> 
>>   cheers
>>     Ben Bolker
>> 
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.6 (GNU/Linux)
>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>> 
>> iD8DBQFHYL1pc5UpGjwzenMRAqErAJ9jj1KgVVSGIf+DtK7Km/+JBaDu2QCaAkl/
>> eMi+WCEWK6FPpVMpUbo+RBQ=
>> =huvz
>> -----END PGP SIGNATURE-----
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> -- 
> Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From osklyar at ebi.ac.uk  Thu Dec 13 16:32:23 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 13 Dec 2007 15:32:23 +0000
Subject: [Rd] S4 class extending data.frame?
In-Reply-To: <6ph7ijir640.fsf@gopher4.fhcrc.org>
References: <4760BD69.2020807@ufl.edu>
	<1197542502.7435.4.camel@maitai.windows.ebi.ac.uk>
	<6ph7ijir640.fsf@gopher4.fhcrc.org>
Message-ID: <1197559943.8994.9.camel@maitai.windows.ebi.ac.uk>

Thanks for your comments. I cannot recall now when I had the situation
that I wanted to inherit from a data.frame, but the fact was that I
could not set the data. So now it just popped up and I thought it was
indeed unfortunate that data.frame structure did not follow the same
principles as other "standard" classes do.

Regarding named lists, modifying .Data directly may play a bad joke
until one clearly thinks about all aspects of the object. I had a
similar situation as well and after that am very careful about such
things (well, I had it in C when creating an object with names
attribute). The thing is: names is and independent attribute, so there
is a potential possibility to set .Data at different length from names
etc when working directly. Thanks for pointing this out anyway.

Regards,
Oleg


On Thu, 2007-12-13 at 07:01 -0800, Martin Morgan wrote:
> Ben, Oleg --
> 
> Some solutions, which you've probably already thought of, are (a) move
> the data.frame into its own slot, instead of extending it, (b) manage
> the data.frame attributes yourself, or (c) reinvent the data.frame
> from scratch as a proper S4 class (e.g., extending 'list' with
> validity constraints on element length and homogeneity of element
> content).
> 
> (b) places a lot of dependence on understanding the data.frame
> implementation, and is probably too tricky (for me) to get right,(c)
> is probably also tricky, and probably caries significant performance
> overhead (e.g., object duplication during validity checking).
> 
> (a) means that you don't get automatic method inheritance. On the plus
> side, you still get the structure. It is trivial to implement methods
> like [, [[, etc to dispatch on your object and act on the appropriate
> slot. And in some sense you now know what methods i.e., those you've
> implemented, are supported on your object.
> 
> Oleg, here's my cautionary tale for extending list, where manually
> subsetting the .Data slot mixes up the names (callNextMethod would
> have done the right thing, but was not appropriate). This was quite a
> subtle bug for me, because I hadn't been expecting named lists in my
> object; the problem surfaced when sapply used the (incorrectly subset)
> names attribute of the list. My solution in this case was to make sure
> 'names' were removed from lists used to construct objects. As a
> consequence I lose a nice little bit of sapply magic.
> 
> > setClass('A', 'list')
> [1] "A"
> > setMethod('[', 'A', function(x, i, j, ..., drop=TRUE) {
> +     x at .Data <- x at .Data[i]
> +     x
> + })
> [1] "["
> > names(new('A', list(x=1, y=2))[2])
> [1] "x"
> 
> Martin
> 
> Oleg Sklyar <osklyar at ebi.ac.uk> writes:
> 
> > I had the same problem. Generally data.frame's behave like lists, but
> > while you can extend list, there are problems extending a data.frame
> > class. This comes down to the internal representation of the object I
> > guess. Vectors, including list, contain their information in a (hidden)
> > slot .Data (see the example below). data.frame's do not seem to follow
> > this convention.
> >
> > Any idea how to go around?
> >
> > The following example is exactly the same as Ben's for a data.frame, but
> > using a list. It works fine and one can see that the list structure is
> > stored in .Data
> >
> > * ~: R
> > R version 2.6.1 (2007-11-26) 
> >> setClass("c3",representation(comment="character"),contains="list")
> > [1] "c3"
> >> l = list(1:3,2:4)
> >> z3 = new("c3",l,comment="hello")
> >> z3
> > An object of class ?c3?
> > [[1]]
> > [1] 1 2 3
> >
> > [[2]]
> > [1] 2 3 4
> >
> > Slot "comment":
> > [1] "hello"
> >
> >> z3 at .Data
> > [[1]]
> > [1] 1 2 3
> >
> > [[2]]
> > [1] 2 3 4
> >
> > Regards,
> > Oleg
> >
> > On Thu, 2007-12-13 at 00:04 -0500, Ben Bolker wrote:
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA1
> >> 
> >> I would like to build an S4 class that extends
> >> a data frame, but includes several more slots.
> >> 
> >> Here's an example using integer as the base
> >> class instead:
> >> 
> >> setClass("c1",representation(comment="character"),contains="integer")
> >> z1 = new("c1",55,comment="hello")
> >> z1
> >> z1+10
> >> z1[1]
> >> z1 at comment
> >> 
> >>  -- in other words, it behaves exactly as an integer
> >> for access and operations but happens to have another slot.
> >> 
> >>  If I do this with a data frame instead, it doesn't seem to work
> >> at all.
> >> 
> >> setClass("c2",representation(comment="character"),contains="data.frame")
> >> d = data.frame(1:3,2:4)
> >> z2 = new("c2",d,comment="goodbye")
> >> z2  ## data all gone!!
> >> z2[,1]  ## Error ... object is not subsettable
> >> z2 at comment  ## still there
> >> 
> >>   I can achieve approximately the same effect by
> >> adding attributes, but I was hoping for the structure
> >> of S4 classes ...
> >> 
> >>   Programming with Data and the R Language Definition
> >> contain 2 references each to data frames, and neither of
> >> them has allowed me to figure out this behavior.
> >> 
> >>  (While I'm at it: it would be wonderful to have
> >> a "rich data frame" that could include as a column
> >> any object that had an appropriate length and
> >> [ method ... has anyone done anything in this direction?
> >> ?data.frame says the allowable types are
> >>  "(numeric, logical, factor and character and so on)",
> >>  but I'm having trouble sorting out what the limitations
> >> are ...)
> >> 
> >>   hoping for enlightenment (it would be lovely to be
> >> shown how to make this work, but a definitive statement
> >> that it is impossible would be useful too).
> >> 
> >>   cheers
> >>     Ben Bolker
> >> 
> >> -----BEGIN PGP SIGNATURE-----
> >> Version: GnuPG v1.4.6 (GNU/Linux)
> >> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> >> 
> >> iD8DBQFHYL1pc5UpGjwzenMRAqErAJ9jj1KgVVSGIf+DtK7Km/+JBaDu2QCaAkl/
> >> eMi+WCEWK6FPpVMpUbo+RBQ=
> >> =huvz
> >> -----END PGP SIGNATURE-----
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > -- 
> > Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
-- 
Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466


From antonio.fabio at gmail.com  Thu Dec 13 19:21:15 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Thu, 13 Dec 2007 19:21:15 +0100
Subject: [Rd] creating lagged variables
Message-ID: <b0808fdc0712131021s59c09978ub64b8cd5741485ea@mail.gmail.com>

Hi all.
I'm looking for robust ways of building lagged variables in a dataset
with multiple individuals.

Consider a dataset with variables like the following:
##
set.seed(123)
d <- data.frame(id = rep(1:2, each=3), time=rep(1:3, 2), value=rnorm(6))
##
>d
  id time       value
1  1    1 -0.56047565
2  1    2 -0.23017749
3  1    3  1.55870831
4  2    1  0.07050839
5  2    2  0.12928774
6  2    3  1.71506499

I want to compute the lagged variable 'value(t-1)', taking subject id
into account.
My current effort produced the following:
##
my_lag <- function(dt, varname, timevarname='time', lag=1) {
	vname <- paste(varname, if(lag>0) '.' else '', lag, sep='')
	timevar <- dt[[timevarname]]
	dt[[vname]] <- dt[[varname]][match(timevar, timevar + lag)]
	dt
}
lag_by <- function(dt, idvarname='id', ...)
  do.call(rbind, by(dt, dt[[idvarname]], my_lag, ...))
##
With the previous data I get:

> lag_by(d, varname='value')
    id time       value     value.1
1.1  1    1 -0.56047565          NA
1.2  1    2 -0.23017749 -0.56047565
1.3  1    3  1.55870831 -0.23017749
2.4  2    1  0.07050839          NA
2.5  2    2  0.12928774  0.07050839
2.6  2    3  1.71506499  0.12928774

So that seems working. However, I was thinking if there is a
smarter/cleaner/more robust way to do the job. For instance, with the
above function I get dataframe rows re-ordering as a side-effect
(anyway this is of no concern in my current analysis)...
Any suggestion?

All the bests,
Fabio.
-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From tplate at acm.org  Thu Dec 13 19:59:48 2007
From: tplate at acm.org (Tony Plate)
Date: Thu, 13 Dec 2007 11:59:48 -0700
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <475FF376.8080806@stats.uwo.ca>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca>
Message-ID: <47618124.7060504@acm.org>

Duncan Murdoch wrote:
> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>> Full_Name: Petr Simecek
>> Version: 2.5.1, 2.6.1
>> OS: Windows XP
>> Submission from: (NULL) (195.113.231.2)
>>
>>
>> Several times I have experienced that a length of a POSIXt vector has not been
>> computed right.
>>
>> Example:
>>
>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 
>> 12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 
>> 13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", 
>> "min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>> ), class = c("POSIXt", "POSIXlt"))
>>
>> print(tv)
>> # print 11 time points (right)
>>
>> length(tv)
>> # returns 9 (wrong)
> 
> tv is a list of length 9.  The answer is right, your expectation is wrong.
>> I have tried that on several computers with/without switching to English
>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help pages but I
>> cannot imagine how that could be OK.
> 
> See this in ?POSIXt:
> 
> Class '"POSIXlt"' is a named list of vectors...
> 
> You could define your own length measurement as
> 
> length.POSIXlt <- function(x) length(x$sec)
> 
> and you'll get the answer you expect, but be aware that length.XXX 
> methods are quite rare, and you may surprise some of your users.
> 

On the other hand, isn't the fact that length() currently always returns 9 
for POSIXlt objects likely to be a surprise to many users of POSIXlt?

The back of "The New S Language" says "Easy-to-use facilities allow you to 
organize, store and retrieve all sorts of data. ... S functions and data 
organization make applications easy to write."

Now, POSIXlt has methods for c() and vector subsetting "[" (and many other 
vector-manipulation methods - see methods(class="POSIXlt")).  Hence, from 
the point of view of intending to supply "easy-to-use facilities ... [for] 
all sorts of data", isn't it a little incongruous that length() is not also 
provided -- as 3 functions (any others?) comprise a core set of 
vector-manipulation functions?

Would it make sense to have an informal prescription (e.g., in R-exts) that 
a class that implements a vector-like object and provides at least of one 
of functions 'c', '[' and 'length' should provide all three?  It would also 
be easy to describe a test-suite that should be included in the 'test' 
directory of a package implementing such a class, that had some tests of 
the basic vector-manipulation functionality, such as:

 > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
 > # class being tested, of length 0, 1, 3, and 10, and they should
 > # contain no duplicate elements
 > length(x0)
[1] 1
 > length(c(x0, x1))
[1] 2
 > length(c(x1,x10))
[1] 11
 > all(x3 == x3[seq(len=length(x3))])
[1] TRUE
 > all(x3 == c(x3[1], x3[2], x3[3]))
[1] TRUE
 > length(c(x3[2], x10[5:7]))
[1] 4
 >

It would also be possible to describe a larger set of vector manipulation 
functions that should be implemented together, including e.g., 'rep', 
'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', head, tail ... (many 
of which are provided for POSIXlt).

Or is there some good reason that length() cannot be provided (while 'c' 
and '[' can) for some vector-like classes such as "POSIXlt"?

-- Tony Plate

> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Thu Dec 13 20:39:00 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Dec 2007 14:39:00 -0500
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <47618124.7060504@acm.org>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca> <47618124.7060504@acm.org>
Message-ID: <47618A54.3060900@stats.uwo.ca>

On 12/13/2007 1:59 PM, Tony Plate wrote:
> Duncan Murdoch wrote:
>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>>> Full_Name: Petr Simecek
>>> Version: 2.5.1, 2.6.1
>>> OS: Windows XP
>>> Submission from: (NULL) (195.113.231.2)
>>>
>>>
>>> Several times I have experienced that a length of a POSIXt vector has not been
>>> computed right.
>>>
>>> Example:
>>>
>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 
>>> 12L), mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 
>>> 13L), mon = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = c(1L, 
>>> 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", 
>>> "min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>>> ), class = c("POSIXt", "POSIXlt"))
>>>
>>> print(tv)
>>> # print 11 time points (right)
>>>
>>> length(tv)
>>> # returns 9 (wrong)
>> 
>> tv is a list of length 9.  The answer is right, your expectation is wrong.
>>> I have tried that on several computers with/without switching to English
>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a help pages but I
>>> cannot imagine how that could be OK.
>> 
>> See this in ?POSIXt:
>> 
>> Class '"POSIXlt"' is a named list of vectors...
>> 
>> You could define your own length measurement as
>> 
>> length.POSIXlt <- function(x) length(x$sec)
>> 
>> and you'll get the answer you expect, but be aware that length.XXX 
>> methods are quite rare, and you may surprise some of your users.
>> 
> 
> On the other hand, isn't the fact that length() currently always returns 9 
> for POSIXlt objects likely to be a surprise to many users of POSIXlt?
> 
> The back of "The New S Language" says "Easy-to-use facilities allow you to 
> organize, store and retrieve all sorts of data. ... S functions and data 
> organization make applications easy to write."
> 
> Now, POSIXlt has methods for c() and vector subsetting "[" (and many other 
> vector-manipulation methods - see methods(class="POSIXlt")).  Hence, from 
> the point of view of intending to supply "easy-to-use facilities ... [for] 
> all sorts of data", isn't it a little incongruous that length() is not also 
> provided -- as 3 functions (any others?) comprise a core set of 
> vector-manipulation functions?
> 
> Would it make sense to have an informal prescription (e.g., in R-exts) that 
> a class that implements a vector-like object and provides at least of one 
> of functions 'c', '[' and 'length' should provide all three?  It would also 
> be easy to describe a test-suite that should be included in the 'test' 
> directory of a package implementing such a class, that had some tests of 
> the basic vector-manipulation functionality, such as:
> 
>  > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
>  > # class being tested, of length 0, 1, 3, and 10, and they should
>  > # contain no duplicate elements
>  > length(x0)
> [1] 1
>  > length(c(x0, x1))
> [1] 2
>  > length(c(x1,x10))
> [1] 11
>  > all(x3 == x3[seq(len=length(x3))])
> [1] TRUE
>  > all(x3 == c(x3[1], x3[2], x3[3]))
> [1] TRUE
>  > length(c(x3[2], x10[5:7]))
> [1] 4
>  >
> 
> It would also be possible to describe a larger set of vector manipulation 
> functions that should be implemented together, including e.g., 'rep', 
> 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', head, tail ... (many 
> of which are provided for POSIXlt).
> 
> Or is there some good reason that length() cannot be provided (while 'c' 
> and '[' can) for some vector-like classes such as "POSIXlt"?

What you say sounds good in general, but the devil is in the details. 
Changing the meaning of length(x) for some objects has fairly widespread 
effects.  Are they all positive?  I don't know.

Adding a prescription like the one you suggest would be good if it's 
easy to implement, but bad if it's already widely violated.  How many 
base or CRAN or Bioconductor packages violate it currently?   Do the 
ones that provide all 3 methods do so in a consistent way, i.e. does 
"length(x)" mean the same thing in all of them?

I agree that the current state is less than perfect, but making it 
better would really be a lot of work.  I suspect there are better ways 
to spend my time, so I'm not going to volunteer to do it.  I'm not even 
going to invite someone else to do it, or offer to review your work if 
you volunteer.  I think this falls into the class of "next time we write 
a language, let's handle this better" problems.

Duncan Murdoch


From ggrothendieck at gmail.com  Thu Dec 13 21:19:20 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 13 Dec 2007 15:19:20 -0500
Subject: [Rd] creating lagged variables
In-Reply-To: <b0808fdc0712131021s59c09978ub64b8cd5741485ea@mail.gmail.com>
References: <b0808fdc0712131021s59c09978ub64b8cd5741485ea@mail.gmail.com>
Message-ID: <971536df0712131219l6a35db65v5ca798da1bd4893a@mail.gmail.com>

The problem is the representation.

If we transform it into a zoo time series, z, with one
series per column and one time point per row then we
can just merge the series with its lag.

> DF <- data.frame(id = c(1, 1, 1, 2, 2, 2), time = c(1, 2,
+ 3, 1, 2, 3), value = c(-0.56047565, -0.23017749, 1.55870831,
+ 0.07050839, 0.12928774, 1.71506499))
>
> library(zoo)
> z <- do.call(merge, by(DF, DF$id, function(x) zoo(x$value, x$time)))
> merge(z, lag(z, -1))
         1.z        2.z 1.lag(z, -1) 2.lag(z, -1)
1 -0.5604756 0.07050839           NA           NA
2 -0.2301775 0.12928774   -0.5604756   0.07050839
3  1.5587083 1.71506499   -0.2301775   0.12928774


On Dec 13, 2007 1:21 PM, Antonio, Fabio Di Narzo
<antonio.fabio at gmail.com> wrote:
> Hi all.
> I'm looking for robust ways of building lagged variables in a dataset
> with multiple individuals.
>
> Consider a dataset with variables like the following:
> ##
> set.seed(123)
> d <- data.frame(id = rep(1:2, each=3), time=rep(1:3, 2), value=rnorm(6))
> ##
> >d
>  id time       value
> 1  1    1 -0.56047565
> 2  1    2 -0.23017749
> 3  1    3  1.55870831
> 4  2    1  0.07050839
> 5  2    2  0.12928774
> 6  2    3  1.71506499
>
> I want to compute the lagged variable 'value(t-1)', taking subject id
> into account.
> My current effort produced the following:
> ##
> my_lag <- function(dt, varname, timevarname='time', lag=1) {
>        vname <- paste(varname, if(lag>0) '.' else '', lag, sep='')
>        timevar <- dt[[timevarname]]
>        dt[[vname]] <- dt[[varname]][match(timevar, timevar + lag)]
>        dt
> }
> lag_by <- function(dt, idvarname='id', ...)
>  do.call(rbind, by(dt, dt[[idvarname]], my_lag, ...))
> ##
> With the previous data I get:
>
> > lag_by(d, varname='value')
>    id time       value     value.1
> 1.1  1    1 -0.56047565          NA
> 1.2  1    2 -0.23017749 -0.56047565
> 1.3  1    3  1.55870831 -0.23017749
> 2.4  2    1  0.07050839          NA
> 2.5  2    2  0.12928774  0.07050839
> 2.6  2    3  1.71506499  0.12928774
>
> So that seems working. However, I was thinking if there is a
> smarter/cleaner/more robust way to do the job. For instance, with the
> above function I get dataframe rows re-ordering as a side-effect
> (anyway this is of no concern in my current analysis)...
> Any suggestion?
>
> All the bests,
> Fabio.
> --
> Antonio, Fabio Di Narzo
> Ph.D. student at
> Department of Statistical Sciences
> University of Bologna, Italy
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mwtoews at sfu.ca  Thu Dec 13 18:00:37 2007
From: mwtoews at sfu.ca (Michael Toews)
Date: Thu, 13 Dec 2007 09:00:37 -0800
Subject: [Rd] End of whiskers of boxplots are repeated on
	PDF	device	(PR#10499)
Message-ID: <47616535.6030809@sfu.ca>

I've identified the problem for this issue, which is simple to fix. 
Please see and apply the attached patch. Thanks.
+mt

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: boxplot_patch.txt
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071213/1e39d176/attachment.txt 

From serge.de.gosson.de.varennes at forsakringskassan.se  Fri Dec 14 09:15:26 2007
From: serge.de.gosson.de.varennes at forsakringskassan.se (de Gosson de Varennes Serge (4100))
Date: Fri, 14 Dec 2007 09:15:26 +0100
Subject: [Rd] Quadratic Programming
Message-ID: <D0B620C63B10AC41BF1DBD4184C9C50003555912@S00MAIL003.ads.sfa.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071214/c470d708/attachment.pl 

From lieven.clement at gmail.com  Fri Dec 14 14:10:25 2007
From: lieven.clement at gmail.com (lieven.clement at gmail.com)
Date: Fri, 14 Dec 2007 14:10:25 +0100 (CET)
Subject: [Rd] Rsquared bug lm() (PR#10516)
Message-ID: <20071214131025.963A8283416B@mail.pubhealth.ku.dk>

Full_Name: lieven clement
Version:  R version 2.4.0 Patched (2006-11-25 r39997)
OS: i486-pc-linux-gnu
Submission from: (NULL) (157.193.193.180)


summary.lm() does not calculate R?? accurately for models without intercepts if
one of the predictor variables is a factor.
In order to avoid one of the factor levels to be considered as a reference class
you can use the -1 option in a formula. When you use this, R?? is not correctly
calculated.

>  x1<-rnorm(100)
> x2<-c(rep(0,25),rep(10,25),rep(20,25),rep(30,25))
> y<-10*x1+x2+rnorm(100,0,4)
> x2<-as.factor(x2)
> lmtest<-lm(y~-1+x1+x2)
> summary(lmtest)$r.sq
[1] 0.9650201
> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
[1] 0.9342672

The R squared by summary is calculated as
> 1-sum(lmtest$res^2)/sum((y)^2)
[1] 0.9650201
apparently because lm.summary assumes the mean of y to be zero.

In case of an intercept model everything seems ok
> lmtest<-lm(y~x1+x2)
> summary(lmtest)$r.sq
[1] 0.9342672
> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
[1] 0.9342672


From Greg.Snow at imail.org  Thu Dec 13 19:15:20 2007
From: Greg.Snow at imail.org (Greg.Snow at imail.org)
Date: Thu, 13 Dec 2007 19:15:20 +0100 (CET)
Subject: [Rd] Minor documentation bug in R-exts (PR#10515)
Message-ID: <20071213181521.443402834155@mail.pubhealth.ku.dk>

This is a minor documentation bug.  In the document:  Writing R
Extensions (R-exts)  section 1.6.5 (Summary -- converting an existing
package) the 3rd bullet is missing the end of the sentence.

Thanks,

--please do not edit the information below--

Version:
 platform =3D i386-pc-mingw32
 arch =3D i386
 os =3D mingw32
 system =3D i386, mingw32
 status =3D=20
 major =3D 2
 minor =3D 6.1
 year =3D 2007
 month =3D 11
 day =3D 26
 svn rev =3D 43537
 language =3D R
 version.string =3D R version 2.6.1 (2007-11-26)

Windows 2000 (build 2195) Service Pack 4.0

Locale:
LC_COLLATE=3DEnglish_United States.1252;LC_CTYPE=3DEnglish_United
States.1252;LC_MONETARY=3DEnglish_United
States.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_United States.1252

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:utils, package:datasets, package:methods, Autoloads,
package:base

--=20
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
=20


From murdoch at stats.uwo.ca  Fri Dec 14 14:32:10 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 14 Dec 2007 08:32:10 -0500
Subject: [Rd] Minor documentation bug in R-exts (PR#10515)
In-Reply-To: <20071213181521.443402834155@mail.pubhealth.ku.dk>
References: <20071213181521.443402834155@mail.pubhealth.ku.dk>
Message-ID: <476285DA.5040201@stats.uwo.ca>

On 12/13/2007 1:15 PM, Greg.Snow at imail.org wrote:
> This is a minor documentation bug.  In the document:  Writing R
> Extensions (R-exts)  section 1.6.5 (Summary -- converting an existing
> package) the 3rd bullet is missing the end of the sentence.

Thanks, I'll fix it.

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri Dec 14 15:18:18 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 14 Dec 2007 09:18:18 -0500
Subject: [Rd] Rsquared bug lm() (PR#10516)
In-Reply-To: <20071214131025.963A8283416B@mail.pubhealth.ku.dk>
References: <20071214131025.963A8283416B@mail.pubhealth.ku.dk>
Message-ID: <476290AA.3000107@stats.uwo.ca>

On 12/14/2007 8:10 AM, lieven.clement at gmail.com wrote:
> Full_Name: lieven clement
> Version:  R version 2.4.0 Patched (2006-11-25 r39997)
> OS: i486-pc-linux-gnu
> Submission from: (NULL) (157.193.193.180)
> 
> 
> summary.lm() does not calculate R?? accurately for models without intercepts if
> one of the predictor variables is a factor.
> In order to avoid one of the factor levels to be considered as a reference class
> you can use the -1 option in a formula. When you use this, R?? is not correctly
> calculated.

This is not a bug.  A model without an intercept should be using y=0 as 
a reference.

Duncan Murdoch

> 
>>  x1<-rnorm(100)
>> x2<-c(rep(0,25),rep(10,25),rep(20,25),rep(30,25))
>> y<-10*x1+x2+rnorm(100,0,4)
>> x2<-as.factor(x2)
>> lmtest<-lm(y~-1+x1+x2)
>> summary(lmtest)$r.sq
> [1] 0.9650201
>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
> [1] 0.9342672
> 
> The R squared by summary is calculated as
>> 1-sum(lmtest$res^2)/sum((y)^2)
> [1] 0.9650201
> apparently because lm.summary assumes the mean of y to be zero.
> 
> In case of an intercept model everything seems ok
>> lmtest<-lm(y~x1+x2)
>> summary(lmtest)$r.sq
> [1] 0.9342672
>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
> [1] 0.9342672
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Dec 14 15:43:07 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Dec 2007 15:43:07 +0100
Subject: [Rd] End of whiskers of boxplots are repeated on PDF device
	(PR#10499)
In-Reply-To: <47616535.6030809@sfu.ca>
References: <47616535.6030809@sfu.ca>
Message-ID: <18274.38523.413081.654014@stat.math.ethz.ch>

>>>>> "MT" == Michael Toews <mwtoews at sfu.ca>
>>>>>     on Thu, 13 Dec 2007 09:00:37 -0800 writes:

    MT> I've identified the problem for this issue, which is
    MT> simple to fix.  Please see and apply the attached
    MT> patch. Thanks.  +mt

Excellent, Michael!

This will be fixed in R-patched and R-devel from tomorrow.
Thank you, and regards!

Martin


From hkawakat at gmail.com  Fri Dec 14 16:23:44 2007
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Fri, 14 Dec 2007 15:23:44 +0000
Subject: [Rd] windows rtools missing gfortran.exe?
Message-ID: <307b90470712140723vfbc8dccka6c89e3c488565bc@mail.gmail.com>

Hi,

I replaced my Rtools today as posted at
http://www.murdoch-sutherland.com/Rtools/Rtools.exe

Trying to build R-devel_2007-12-13.tar.gz without modifying MkRules
gives the gfortran command not found error below. I am wondering if
gfortran.exe is missing from (recent?) Rtools.exe or I am doing
something wrong.

Thanks to hints at Duncan's site, I worked around the error by adding
"GCC4_SUFF=-sjlj" in MkRules (below the == end of user-customizable
parts  == line).

gcc  -std=gnu99 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall -pedantic
 -c zeroin.c -o zeroin.o
gfortran -O3  -c ch2inv.f -o ch2inv.o
make[4]: gfortran: Command not found
make[4]: *** [ch2inv.o] Error 127
make[3]: *** [rlibs] Error 2
make[2]: *** [../../bin/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2

-- 
----------------------------------
Hiroyuki Kawakatsu
Business School
Dublin City University
Dublin 9, Ireland
Tel +353 (0)1 700 7496


From murdoch at stats.uwo.ca  Fri Dec 14 17:40:16 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 14 Dec 2007 11:40:16 -0500
Subject: [Rd] windows rtools missing gfortran.exe?
In-Reply-To: <307b90470712140723vfbc8dccka6c89e3c488565bc@mail.gmail.com>
References: <307b90470712140723vfbc8dccka6c89e3c488565bc@mail.gmail.com>
Message-ID: <4762B1F0.8050900@stats.uwo.ca>

On 12/14/2007 10:23 AM, Hiroyuki Kawakatsu wrote:
> Hi,
> 
> I replaced my Rtools today as posted at
> http://www.murdoch-sutherland.com/Rtools/Rtools.exe
> 
> Trying to build R-devel_2007-12-13.tar.gz without modifying MkRules
> gives the gfortran command not found error below. I am wondering if
> gfortran.exe is missing from (recent?) Rtools.exe or I am doing
> something wrong.
> 
> Thanks to hints at Duncan's site, I worked around the error by adding
> "GCC4_SUFF=-sjlj" in MkRules (below the == end of user-customizable
> parts  == line).
> 
> gcc  -std=gnu99 -I../include -DHAVE_CONFIG_H -DR_DLL_BUILD  -O3 -Wall -pedantic
>  -c zeroin.c -o zeroin.o
> gfortran -O3  -c ch2inv.f -o ch2inv.o
> make[4]: gfortran: Command not found
> make[4]: *** [ch2inv.o] Error 127
> make[3]: *** [rlibs] Error 2
> make[2]: *** [../../bin/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
> 

It's supposed to be in there; I'm just downloading a copy myself to 
verify...  You're right!  Somehow Rtools.exe got linked to Rtools26.exe, 
instead of the new one.  Now fixed.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Fri Dec 14 18:13:03 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Dec 2007 18:13:03 +0100
Subject: [Rd] Do not misuse R-devel {was "Quadratic Programming"}
In-Reply-To: <D0B620C63B10AC41BF1DBD4184C9C50003555912@S00MAIL003.ads.sfa.se>
References: <D0B620C63B10AC41BF1DBD4184C9C50003555912@S00MAIL003.ads.sfa.se>
Message-ID: <18274.47519.474678.439531@stat.math.ethz.ch>

Please use the R-help mailing for such *Questions*.

R-devel has a very different purpose.
Probably you should also read the posting guide,
--> http://www.r-project.org/posting-guide.html

Regards,
Martin Maechler, ETH Zurich

>>>>> "dGdVS" == de Gosson de Varennes Serge (4100) <serge.de.gosson.de.varennes at forsakringskassan.se>
>>>>>     on Fri, 14 Dec 2007 09:15:26 +0100 writes:

    dGdVS> Hi all!  I have a little question concerning
    dGdVS> quadprog. To make it simple I'll start by stating the
    dGdVS> problem:

    dGdVS> I want to minimize

    dGdVS> 		h(d,delta)=0.5d^T B d +nabla(f(x))^T d
    dGdVS> +rho*delta^2

    dGdVS> With respect to d\in R^n and delta \in R. I obviously
    dGdVS> have constraints (depending on both d and delta).

    dGdVS> Solve.QP does give me a good result for d but I
    dGdVS> cannot obtain anything for delta. Simce dim(Dmat)=n
    dGdVS> and sol<-rep(0,n) it isn't particularly surprising.
    dGdVS> To set a diagonal matrix

    dGdVS> 		(B 0 ) Amat= (0 rho )

    dGdVS> Is a crapy idea. Does anyone have an idea?

    dGdVS> Yours,

    dGdVS> Serge

    dGdVS> "Beatus qui prodest quibus potest" - (Lycklig ?r
    dGdVS> den som hj?lper andra)

    dGdVS> Serge de Gosson de Varennes F?rs?kringskassan
    dGdVS> Swedish Social Insurance Agency +46-76 11 40 799
    dGdVS> serge.de.gosson.de.varennes at forsakringskassan.se





    dGdVS> 	[[alternative HTML version deleted]]

    dGdVS> ______________________________________________
    dGdVS> R-devel at r-project.org mailing list
    dGdVS> https://stat.ethz.ch/mailman/listinfo/r-devel


From b.rowlingson at lancaster.ac.uk  Fri Dec 14 19:01:30 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 14 Dec 2007 18:01:30 +0000
Subject: [Rd] Rapid Random Access
Message-ID: <4762C4FA.7010900@lancaster.ac.uk>

  I have some code that can potentially produce a huge number of 
large-ish R data frames, each of a different number of rows. All the 
data frames together will be way too big to keep in R's memory, but 
we'll assume a single one is manageable. It's just when there's a 
million of them that the machine might start to burn up.

  However I might, for example, want to compute some averages over the 
elements in the data frames. Or I might want to sample ten of them at 
random and do some plots. What I need is rapid random access to data 
stored in external files.

  Here's some ideas I've had:

  * Store all the data in an HDF-5 file - problem here is that the 
current HDF package for R reads the whole file in at once.

  * Store the data in some other custom binary format with an index for 
rapid access to the N-th elements. Problems: feels like reinventing HDF, 
cross-platform issues, etc.

  * Store the data in a number of .RData files in a directory. Hence to 
get the N-th element just attach(paste("foo/A-",n,'.RData')) give or 
take a parameter or two.

  * Use a database. Seems a bit heavyweight, but maybe using RSQLite 
could work in order to keep it local.

  What I'm currently doing is keeping it OO enough that I can in theory 
implement all of the above. At the moment I have an implementation that 
does keep them all in R's memory as a list of data frames, which is fine 
for small test cases but things are going to get big shortly. Any other 
ideas or hints are welcome.

thanks

Barry


From sdavis2 at mail.nih.gov  Fri Dec 14 19:08:35 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 14 Dec 2007 13:08:35 -0500
Subject: [Rd] Rapid Random Access
In-Reply-To: <4762C4FA.7010900@lancaster.ac.uk>
References: <4762C4FA.7010900@lancaster.ac.uk>
Message-ID: <264855a00712141008i3ef1a87ao8ca393fe491b23ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071214/9541ccb2/attachment.pl 

From tobias.verbeke at gmail.com  Fri Dec 14 19:26:17 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Fri, 14 Dec 2007 19:26:17 +0100
Subject: [Rd] segfault isoreg with NAs
Message-ID: <4762CAC9.4000506@telenet.be>

Dear list,

As can be seen below, adding a NA to the y values
in a call to isoreg results in a segfault.

ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))

Adding missing values to the x values, on the contrary,
gives an error, but maybe the error message could be
tailored to this particular situation.

y <- c(5, 9, 1:2, 5:8, 3, 8)
x <- c(1:9, NA)
isoreg(x, y)
## error message: Error in if (!isOrd) { : missing value where 
TRUE/FALSE needed

Please find below a (temporary) patch (against Revision 43692)
for both the R source and the help file.

Kind regards,
Tobias

### patch isoreg.R ###

--- isoreg.R	2007-12-14 19:07:47.000000000 +0100
+++ isoreg2.R	2007-12-14 19:11:20.000000000 +0100
@@ -18,6 +18,9 @@
  ##
  isoreg <- function(x, y=NULL)
  {
+    if (any(is.na(x))) stop("x may not contain NA values")
+    if (any(is.na(y))) stop("y may not contain NA values")
+
      xy <- xy.coords(x,y)
      x <- xy$x
      isOrd <- (!is.null(xy$xlab) && xy$xlab == "Index") || !is.unsorted(x)

### patch isoreg.Rd ###

--- isoreg.Rd	2007-12-14 19:08:12.000000000 +0100
+++ isoreg2.Rd	2007-12-14 19:15:00.000000000 +0100
@@ -20,6 +20,7 @@
    \item{x, y}{%in \code{isoreg},
      coordinate vectors of the regression points.  Alternatively a single
      plotting structure can be specified: see \code{\link{xy.coords}}.
+    The coordinate vectors may not contain missing values.
    }
  }
  \details{


### sessionInfo() information segfault ###

> sessionInfo()
R version 2.6.0 (2007-10-03)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.ISO-8859-15;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.ISO-8859-15;LC_MONETARY=en_US.ISO-8859-15\
;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=en_US.ISO-8859-15;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.ISO-885\
9-15;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))

  *** caught segfault ***
address 0x24, cause 'memory not mapped'

Process R segmentation fault (core dumped) at Fri Dec 14 17:48:22 2007


From tplate at acm.org  Fri Dec 14 20:31:01 2007
From: tplate at acm.org (Tony Plate)
Date: Fri, 14 Dec 2007 12:31:01 -0700
Subject: [Rd] Rapid Random Access
In-Reply-To: <4762C4FA.7010900@lancaster.ac.uk>
References: <4762C4FA.7010900@lancaster.ac.uk>
Message-ID: <4762D9F5.2010904@acm.org>

Barry Rowlingson wrote:
>   I have some code that can potentially produce a huge number of 
> large-ish R data frames, each of a different number of rows. All the 
> data frames together will be way too big to keep in R's memory, but 
> we'll assume a single one is manageable. It's just when there's a 
> million of them that the machine might start to burn up.
>   
This is exactly the type of situation that the trackObjs package is 
designed for.  It will automatically (and invisibly) store each object 
in its own .RData file so that objects can be accessed as ordinary R 
objects, but are not kept in memory (actually, there are options to 
control whether or not objects are cached in memory). It also caches 
some characteristics of objects so that a brief summary of objects can 
be provided without having to read each object.  The g.data package and 
the filehash package also do similar things wrt to providing automatic 
access to objects in .RData files (and were part of the inspiration for 
the trackObjs package.)

-- Tony Plate
>   However I might, for example, want to compute some averages over the 
> elements in the data frames. Or I might want to sample ten of them at 
> random and do some plots. What I need is rapid random access to data 
> stored in external files.
>
>   Here's some ideas I've had:
>
>   * Store all the data in an HDF-5 file - problem here is that the 
> current HDF package for R reads the whole file in at once.
>
>   * Store the data in some other custom binary format with an index for 
> rapid access to the N-th elements. Problems: feels like reinventing HDF, 
> cross-platform issues, etc.
>
>   * Store the data in a number of .RData files in a directory. Hence to 
> get the N-th element just attach(paste("foo/A-",n,'.RData')) give or 
> take a parameter or two.
>
>   * Use a database. Seems a bit heavyweight, but maybe using RSQLite 
> could work in order to keep it local.
>
>   What I'm currently doing is keeping it OO enough that I can in theory 
> implement all of the above. At the moment I have an implementation that 
> does keep them all in R's memory as a list of data frames, which is fine 
> for small test cases but things are going to get big shortly. Any other 
> ideas or hints are welcome.
>
> thanks
>
> Barry
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From b.rowlingson at lancaster.ac.uk  Fri Dec 14 20:40:30 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 14 Dec 2007 19:40:30 +0000
Subject: [Rd] Rapid Random Access
In-Reply-To: <4762D9F5.2010904@acm.org>
References: <4762C4FA.7010900@lancaster.ac.uk> <4762D9F5.2010904@acm.org>
Message-ID: <4762DC2E.9010308@lancaster.ac.uk>

Tony Plate wrote:

> This is exactly the type of situation that the trackObjs package is 
> designed for. 

  Ooh, I'm having deja-vu - yes I think I saw this package a while back 
and wondered what magic it did. I shall go play with it later.

Thanks

Barry


From tplate at acm.org  Fri Dec 14 21:58:30 2007
From: tplate at acm.org (Tony Plate)
Date: Fri, 14 Dec 2007 13:58:30 -0700
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <47618A54.3060900@stats.uwo.ca>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca> <47618124.7060504@acm.org>
	<47618A54.3060900@stats.uwo.ca>
Message-ID: <4762EE76.9070401@acm.org>

Duncan Murdoch wrote:
> On 12/13/2007 1:59 PM, Tony Plate wrote:
>> Duncan Murdoch wrote:
>>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>>>> Full_Name: Petr Simecek
>>>> Version: 2.5.1, 2.6.1
>>>> OS: Windows XP
>>>> Submission from: (NULL) (195.113.231.2)
>>>>
>>>>
>>>> Several times I have experienced that a length of a POSIXt vector 
>>>> has not been
>>>> computed right.
>>>>
>>>> Example:
>>>>
>>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 12L), 
>>>> mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 13L), mon 
>>>> = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
>>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = 
>>>> c(1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
>>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
>>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", "min", 
>>>> "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>>>> ), class = c("POSIXt", "POSIXlt"))
>>>>
>>>> print(tv)
>>>> # print 11 time points (right)
>>>>
>>>> length(tv)
>>>> # returns 9 (wrong)
>>>
>>> tv is a list of length 9.  The answer is right, your expectation is 
>>> wrong.
>>>> I have tried that on several computers with/without switching to 
>>>> English
>>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a 
>>>> help pages but I
>>>> cannot imagine how that could be OK.
>>>
>>> See this in ?POSIXt:
>>>
>>> Class '"POSIXlt"' is a named list of vectors...
>>>
>>> You could define your own length measurement as
>>>
>>> length.POSIXlt <- function(x) length(x$sec)
>>>
>>> and you'll get the answer you expect, but be aware that length.XXX 
>>> methods are quite rare, and you may surprise some of your users.
>>>
>>
>> On the other hand, isn't the fact that length() currently always 
>> returns 9 for POSIXlt objects likely to be a surprise to many users 
>> of POSIXlt?
>>
>> The back of "The New S Language" says "Easy-to-use facilities allow 
>> you to organize, store and retrieve all sorts of data. ... S 
>> functions and data organization make applications easy to write."
>>
>> Now, POSIXlt has methods for c() and vector subsetting "[" (and many 
>> other vector-manipulation methods - see methods(class="POSIXlt")).  
>> Hence, from the point of view of intending to supply "easy-to-use 
>> facilities ... [for] all sorts of data", isn't it a little 
>> incongruous that length() is not also provided -- as 3 functions (any 
>> others?) comprise a core set of vector-manipulation functions?
>>
>> Would it make sense to have an informal prescription (e.g., in 
>> R-exts) that a class that implements a vector-like object and 
>> provides at least of one of functions 'c', '[' and 'length' should 
>> provide all three?  It would also be easy to describe a test-suite 
>> that should be included in the 'test' directory of a package 
>> implementing such a class, that had some tests of the basic 
>> vector-manipulation functionality, such as:
>>
>>  > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
>>  > # class being tested, of length 0, 1, 3, and 10, and they should
>>  > # contain no duplicate elements
>>  > length(x0)
>> [1] 1
>>  > length(c(x0, x1))
>> [1] 2
>>  > length(c(x1,x10))
>> [1] 11
>>  > all(x3 == x3[seq(len=length(x3))])
>> [1] TRUE
>>  > all(x3 == c(x3[1], x3[2], x3[3]))
>> [1] TRUE
>>  > length(c(x3[2], x10[5:7]))
>> [1] 4
>>  >
>>
>> It would also be possible to describe a larger set of vector 
>> manipulation functions that should be implemented together, including 
>> e.g., 'rep', 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', 
>> head, tail ... (many of which are provided for POSIXlt).
>>
>> Or is there some good reason that length() cannot be provided (while 
>> 'c' and '[' can) for some vector-like classes such as "POSIXlt"?
>
> What you say sounds good in general, but the devil is in the details. 
> Changing the meaning of length(x) for some objects has fairly 
> widespread effects.  Are they all positive?  I don't know.
>
> Adding a prescription like the one you suggest would be good if it's 
> easy to implement, but bad if it's already widely violated.  How many 
> base or CRAN or Bioconductor packages violate it currently?   Do the 
> ones that provide all 3 methods do so in a consistent way, i.e. does 
> "length(x)" mean the same thing in all of them?
I'm not sure doing something like this would be so bad even if it is 
already widely violated.  R has evolved significantly over time, and 
many rough edges have been cleaned up, sometimes in ways that were not 
backward compatible.  This is a great thing & my thanks go to the people 
working on R.

If some base or CRAN or Bioconductor packages currently don't implement 
vector operations consistently, wouldn't it be good to know that?  
Wouldn't it be useful to have an automatic way of determining whether a 
particular vector-like class is consistent with generally agreed set of 
principles for how basic vector operations should work -- things like 
length(x)+length(y)==length(c(x,y))?  This could help developers check, 
document & improve their code, and it could help users understand how to 
use a class, and to evaluate the software quality of a class 
implementation and whether or not it provides the functionality they need.
> I agree that the current state is less than perfect, but making it 
> better would really be a lot of work.  I suspect there are better ways 
> to spend my time, so I'm not going to volunteer to do it.  I'm not 
> even going to invite someone else to do it, or offer to review your 
> work if you volunteer.  I think this falls into the class of "next 
> time we write a language, let's handle this better" problems.
Thanks very much for the thoughtful (and honest) feedback!  I suspect 
that the current state could be improved with just a little work, and 
without forcing anyone to do any work they don't want to do.  I'll think 
about this more and try to come back with a better & more concrete 
suggestion.

-- Tony Plate
>
> Duncan Murdoch
>


From ivo at iugrina.com  Fri Dec 14 23:03:37 2007
From: ivo at iugrina.com (Ivo Ugrina)
Date: Fri, 14 Dec 2007 23:03:37 +0100
Subject: [Rd] Improvement of SignRank functions
Message-ID: <4762FDB9.1060603@iugrina.com>

I took some time and liberty and tried to improve
existing implementation of SignRank functions
in R. (dsignrank, ...)

As I have seen they've been based on csignrank.
So I modified csignrank and, I believe,
improved calculation time and memory efficiency.

The idea is basically the same. I use the same recursion
as original author used with one slight modification.
I am generating Wilcoxon SignRank density from the
beginning (for n=2,3,...) with the help of recursion formula.

What is changed?
There is no need for SINGRANK_MAX in src/nmath/nmath.h anymore.
Only functions:
static void w_free()
void signrank_free()
static void w_init_maybe(int n)
static double csignrank(int k, int n)
in src/nmath/signrank.c have been altered.
There was no change to dsignrank, psignrank, ...

I've tried to make as little changes as possible.
So, to compile with new functions only src/nmath/signrank.c
needs to be changed with the one given in attachment.

I hope it really is an improvement.

With respect,
-- 
Ivo Ugrina
ICQ: 47508335 | www.iugrina.com
-------------------------------
baza matematickih pojmova
http://baza.iugrina.com
---------------------------
anime, manga, Japan fanzin
http://yoshi.iugrina.com
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: signrank.c
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071214/ab3480ad/attachment.c 

From tlumley at u.washington.edu  Sat Dec 15 00:24:35 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 14 Dec 2007 15:24:35 -0800 (PST)
Subject: [Rd] Rsquared bug lm() (PR#10516)
In-Reply-To: <20071214131025.963A8283416B@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0712141524350.7000@hymn12.u.washington.edu>


This is deliberate and as documented in ?summary.lm. It is not a bug.

     -thomas

On Fri, 14 Dec 2007 lieven.clement at gmail.com wrote:

> Full_Name: lieven clement
> Version:  R version 2.4.0 Patched (2006-11-25 r39997)
> OS: i486-pc-linux-gnu
> Submission from: (NULL) (157.193.193.180)
>
>
> summary.lm() does not calculate R?? accurately for models without intercepts if
> one of the predictor variables is a factor.
> In order to avoid one of the factor levels to be considered as a reference class
> you can use the -1 option in a formula. When you use this, R?? is not correctly
> calculated.
>
>>  x1<-rnorm(100)
>> x2<-c(rep(0,25),rep(10,25),rep(20,25),rep(30,25))
>> y<-10*x1+x2+rnorm(100,0,4)
>> x2<-as.factor(x2)
>> lmtest<-lm(y~-1+x1+x2)
>> summary(lmtest)$r.sq
> [1] 0.9650201
>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
> [1] 0.9342672
>
> The R squared by summary is calculated as
>> 1-sum(lmtest$res^2)/sum((y)^2)
> [1] 0.9650201
> apparently because lm.summary assumes the mean of y to be zero.
>
> In case of an intercept model everything seems ok
>> lmtest<-lm(y~x1+x2)
>> summary(lmtest)$r.sq
> [1] 0.9342672
>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
> [1] 0.9342672
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From maechler at stat.math.ethz.ch  Sat Dec 15 12:29:34 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 15 Dec 2007 12:29:34 +0100
Subject: [Rd] Improvement of SignRank functions
In-Reply-To: <4762FDB9.1060603@iugrina.com>
References: <4762FDB9.1060603@iugrina.com>
Message-ID: <18275.47774.724113.430936@ada-stat.math.ethz.ch>

Hi Ivo,

>>>>> "IU" == Ivo Ugrina <ivo at iugrina.com>
>>>>>     on Fri, 14 Dec 2007 23:03:37 +0100 writes:

    IU> I took some time and liberty and tried to improve
    IU> existing implementation of SignRank functions
    IU> in R. (dsignrank, ...)

    IU> As I have seen they've been based on csignrank.
    IU> So I modified csignrank and, I believe,
    IU> improved calculation time and memory efficiency.

do you have evidence for your belief?
i.e. a set of  system.time(.) calls where you see the
difference?

    IU> The idea is basically the same. I use the same recursion
    IU> as original author 

 (Kurt Hornik)

    IU> used with one slight modification.
    IU> I am generating Wilcoxon SignRank density from the
    IU> beginning (for n=2,3,...) with the help of recursion formula.

    IU> What is changed?
    IU> There is no need for SINGRANK_MAX in src/nmath/nmath.h anymore.

    IU> Only functions:
    IU> static void w_free()
    IU> void signrank_free()
    IU> static void w_init_maybe(int n)
    IU> static double csignrank(int k, int n)
    IU> in src/nmath/signrank.c have been altered.
    IU> There was no change to dsignrank, psignrank, ...

    IU> I've tried to make as little changes as possible.

    IU> So, to compile with new functions only src/nmath/signrank.c
    IU> needs to be changed with the one given in attachment.

    IU> I hope it really is an improvement.

Me too :-)     {Waiting for your test results}

The code does look slightly simpler, I agree.

BTW: If you had a smart idea to *not* use a static 'w' and still
     be memory efficient,
     that could lead to make that code "thread-safe", but I am
     not at all sure this is possible without using
     "thread-library C code".

Martin


From ivo at iugrina.com  Sat Dec 15 14:13:10 2007
From: ivo at iugrina.com (Ivo Ugrina)
Date: Sat, 15 Dec 2007 14:13:10 +0100
Subject: [Rd] Improvement of SignRank functions
In-Reply-To: <18275.47774.724113.430936@ada-stat.math.ethz.ch>
References: <4762FDB9.1060603@iugrina.com>
	<18275.47774.724113.430936@ada-stat.math.ethz.ch>
Message-ID: <4763D2E6.90301@iugrina.com>

Martin Maechler wrote:
> do you have evidence for your belief?
> i.e. a set of  system.time(.) calls where you see the
> difference?


system.time(dsignrank(17511, 400))
    user  system elapsed
   1.010   0.120   1.145
system.time(dsignrank((0:17511), 400))
    user  system elapsed
    1.25    0.13    1.40
system.time(dsignrank((0:17511), 500))
    user  system elapsed
   2.040   0.220   2.296
system.time(psignrank((0:17511), 600))
    user  system elapsed
  20.670   0.580  21.403
system.time(qsignrank(0.56, 300))
    user  system elapsed
   0.700   0.050   0.753
======================================
system.time(dsignrank(17511, 400))
    user  system elapsed
   0.070   0.000   0.078
system.time(dsignrank((0:17511), 400))
    user  system elapsed
   0.100   0.000   0.104
system.time(dsignrank((0:17511), 500))
    user  system elapsed
   0.160   0.000   0.164
system.time(psignrank((0:17511), 600))
    user  system elapsed
  16.330   0.370  16.729
system.time(qsignrank(0.56, 300))
    user  system elapsed
   0.020   0.010   0.029



system.time(dsignrank((0:20000), 600))
    user  system elapsed
   3.470   0.280   3.745
RAM: ~130MB
======================================
system.time(dsignrank((0:20000), 600))
    user  system elapsed
   0.250   0.010   0.26
RAM: ~1MB



> BTW: If you had a smart idea to *not* use a static 'w' and still
>      be memory efficient,
>      that could lead to make that code "thread-safe", but I am
>      not at all sure this is possible without using
>      "thread-library C code".

I'll look into it.


With respect,
-- 
Ivo Ugrina
ICQ: 47508335 | www.iugrina.com
-------------------------------
baza matematickih pojmova
http://baza.iugrina.com
---------------------------
anime, manga, Japan fanzin
http://yoshi.iugrina.com


From maechler at stat.math.ethz.ch  Sat Dec 15 19:44:59 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 15 Dec 2007 19:44:59 +0100
Subject: [Rd] Improvement of SignRank functions
In-Reply-To: <4763D2E6.90301@iugrina.com>
References: <4762FDB9.1060603@iugrina.com>
	<18275.47774.724113.430936@ada-stat.math.ethz.ch>
	<4763D2E6.90301@iugrina.com>
Message-ID: <18276.8363.639290.462401@ada-stat.math.ethz.ch>

Hi Ivo,

>>>>> "IU" == Ivo Ugrina <ivo at iugrina.com>
>>>>>     on Sat, 15 Dec 2007 14:13:10 +0100 writes:

    IU> Martin Maechler wrote:
    >> do you have evidence for your belief?
    >> i.e. a set of  system.time(.) calls where you see the
    >> difference?

    IU> system.time(dsignrank(17511, 400))
    IU> user  system elapsed
    IU> 1.010   0.120   1.145
    IU> system.time(dsignrank((0:17511), 400))
    IU> user  system elapsed
    IU> 1.25    0.13    1.40
    IU> system.time(dsignrank((0:17511), 500))
    IU> user  system elapsed
    IU> 2.040   0.220   2.296
    IU> system.time(psignrank((0:17511), 600))
    IU> user  system elapsed
    IU> 20.670   0.580  21.403
    IU> system.time(qsignrank(0.56, 300))
    IU> user  system elapsed
    IU> 0.700   0.050   0.753
    IU> ======================================
    IU> system.time(dsignrank(17511, 400))
    IU> user  system elapsed
    IU> 0.070   0.000   0.078
    IU> system.time(dsignrank((0:17511), 400))
    IU> user  system elapsed
    IU> 0.100   0.000   0.104
    IU> system.time(dsignrank((0:17511), 500))
    IU> user  system elapsed
    IU> 0.160   0.000   0.164
    IU> system.time(psignrank((0:17511), 600))
    IU> user  system elapsed
    IU> 16.330   0.370  16.729
    IU> system.time(qsignrank(0.56, 300))
    IU> user  system elapsed
    IU> 0.020   0.010   0.029



    IU> system.time(dsignrank((0:20000), 600))
    IU> user  system elapsed
    IU> 3.470   0.280   3.745
    IU> RAM: ~130MB
    IU> ======================================
    IU> system.time(dsignrank((0:20000), 600))
    IU> user  system elapsed
    IU> 0.250   0.010   0.26
    IU> RAM: ~1MB

that's quite convincing; thank you!
and I can verify part of it on my computer.

I think I'd just commit your signrank.c
(with a few cosmetic changes) to the sources, right?

*Not* using a static with all the previously computed counts
is probably not possible without a (CPU time) efficiency loss;
and to make this thread-safe one could use a "thread-global"
array, but how to do that would really depend on the threading
system used, and that's not at all given.

Thank you for your contribution!
Martin



    >> BTW: If you had a smart idea to *not* use a static 'w' and still
    >> be memory efficient,
    >> that could lead to make that code "thread-safe", but I am
    >> not at all sure this is possible without using
    >> "thread-library C code".

    IU> I'll look into it.


    IU> With respect,
    IU> -- 
    IU> Ivo Ugrina
    IU> ICQ: 47508335 | www.iugrina.com
    IU> -------------------------------
    IU> baza matematickih pojmova
    IU> http://baza.iugrina.com
    IU> ---------------------------
    IU> anime, manga, Japan fanzin
    IU> http://yoshi.iugrina.com


From bolker at ufl.edu  Sat Dec 15 22:39:44 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 15 Dec 2007 13:39:44 -0800 (PST)
Subject: [Rd] S4 class extending data.frame?
In-Reply-To: <6ph7ijir640.fsf@gopher4.fhcrc.org>
References: <4760BD69.2020807@ufl.edu>
	<1197542502.7435.4.camel@maitai.windows.ebi.ac.uk>
	<6ph7ijir640.fsf@gopher4.fhcrc.org>
Message-ID: <14355388.post@talk.nabble.com>



  Thanks, Martin.  In the short term (a) seems best.  In the long
run we may try (c), because there are other things that data.frame
doesn't do that we want it to do (i.e., allow arbitrary objects with
[ methods, print methods, and the same length to be bound together,
rather than being restricted to atomic vectors + Date/factor).

  cheers
    Ben




Martin Morgan wrote:
> 
> Ben, Oleg --
> 
> Some solutions, which you've probably already thought of, are (a) move
> the data.frame into its own slot, instead of extending it, (b) manage
> the data.frame attributes yourself, or (c) reinvent the data.frame
> from scratch as a proper S4 class (e.g., extending 'list' with
> validity constraints on element length and homogeneity of element
> content).
> 
> (b) places a lot of dependence on understanding the data.frame
> implementation, and is probably too tricky (for me) to get right,(c)
> is probably also tricky, and probably caries significant performance
> overhead (e.g., object duplication during validity checking).
> 
> (a) means that you don't get automatic method inheritance. On the plus
> side, you still get the structure. It is trivial to implement methods
> like [, [[, etc to dispatch on your object and act on the appropriate
> slot. And in some sense you now know what methods i.e., those you've
> implemented, are supported on your object.
> 
> Oleg, here's my cautionary tale for extending list, where manually
> subsetting the .Data slot mixes up the names (callNextMethod would
> have done the right thing, but was not appropriate). This was quite a
> subtle bug for me, because I hadn't been expecting named lists in my
> object; the problem surfaced when sapply used the (incorrectly subset)
> names attribute of the list. My solution in this case was to make sure
> 'names' were removed from lists used to construct objects. As a
> consequence I lose a nice little bit of sapply magic.
> 
>> setClass('A', 'list')
> [1] "A"
>> setMethod('[', 'A', function(x, i, j, ..., drop=TRUE) {
> +     x at .Data <- x at .Data[i]
> +     x
> + })
> [1] "["
>> names(new('A', list(x=1, y=2))[2])
> [1] "x"
> 
> Martin
> 
> Oleg Sklyar <osklyar at ebi.ac.uk> writes:
> 
>> I had the same problem. Generally data.frame's behave like lists, but
>> while you can extend list, there are problems extending a data.frame
>> class. This comes down to the internal representation of the object I
>> guess. Vectors, including list, contain their information in a (hidden)
>> slot .Data (see the example below). data.frame's do not seem to follow
>> this convention.
>>
>> Any idea how to go around?
>>
>> The following example is exactly the same as Ben's for a data.frame, but
>> using a list. It works fine and one can see that the list structure is
>> stored in .Data
>>
>> * ~: R
>> R version 2.6.1 (2007-11-26) 
>>> setClass("c3",representation(comment="character"),contains="list")
>> [1] "c3"
>>> l = list(1:3,2:4)
>>> z3 = new("c3",l,comment="hello")
>>> z3
>> An object of class ?c3?
>> [[1]]
>> [1] 1 2 3
>>
>> [[2]]
>> [1] 2 3 4
>>
>> Slot "comment":
>> [1] "hello"
>>
>>> z3 at .Data
>> [[1]]
>> [1] 1 2 3
>>
>> [[2]]
>> [1] 2 3 4
>>
>> Regards,
>> Oleg
>>
>> On Thu, 2007-12-13 at 00:04 -0500, Ben Bolker wrote:
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>> 
>>> I would like to build an S4 class that extends
>>> a data frame, but includes several more slots.
>>> 
>>> Here's an example using integer as the base
>>> class instead:
>>> 
>>> setClass("c1",representation(comment="character"),contains="integer")
>>> z1 = new("c1",55,comment="hello")
>>> z1
>>> z1+10
>>> z1[1]
>>> z1 at comment
>>> 
>>>  -- in other words, it behaves exactly as an integer
>>> for access and operations but happens to have another slot.
>>> 
>>>  If I do this with a data frame instead, it doesn't seem to work
>>> at all.
>>> 
>>> setClass("c2",representation(comment="character"),contains="data.frame")
>>> d = data.frame(1:3,2:4)
>>> z2 = new("c2",d,comment="goodbye")
>>> z2  ## data all gone!!
>>> z2[,1]  ## Error ... object is not subsettable
>>> z2 at comment  ## still there
>>> 
>>>   I can achieve approximately the same effect by
>>> adding attributes, but I was hoping for the structure
>>> of S4 classes ...
>>> 
>>>   Programming with Data and the R Language Definition
>>> contain 2 references each to data frames, and neither of
>>> them has allowed me to figure out this behavior.
>>> 
>>>  (While I'm at it: it would be wonderful to have
>>> a "rich data frame" that could include as a column
>>> any object that had an appropriate length and
>>> [ method ... has anyone done anything in this direction?
>>> ?data.frame says the allowable types are
>>>  "(numeric, logical, factor and character and so on)",
>>>  but I'm having trouble sorting out what the limitations
>>> are ...)
>>> 
>>>   hoping for enlightenment (it would be lovely to be
>>> shown how to make this work, but a definitive statement
>>> that it is impossible would be useful too).
>>> 
>>>   cheers
>>>     Ben Bolker
>>> 
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v1.4.6 (GNU/Linux)
>>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>>> 
>>> iD8DBQFHYL1pc5UpGjwzenMRAqErAJ9jj1KgVVSGIf+DtK7Km/+JBaDu2QCaAkl/
>>> eMi+WCEWK6FPpVMpUbo+RBQ=
>>> =huvz
>>> -----END PGP SIGNATURE-----
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> -- 
>> Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Martin Morgan
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
> 
> Location: Arnold Building M2 B169
> Phone: (206) 667-2793
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/S4-class-extending-data.frame--tp14310126p14355388.html
Sent from the R devel mailing list archive at Nabble.com.


From ivo at iugrina.com  Sat Dec 15 22:59:02 2007
From: ivo at iugrina.com (Ivo Ugrina)
Date: Sat, 15 Dec 2007 22:59:02 +0100
Subject: [Rd] Improvement of SignRank functions
In-Reply-To: <18276.8363.639290.462401@ada-stat.math.ethz.ch>
References: <4762FDB9.1060603@iugrina.com>	<18275.47774.724113.430936@ada-stat.math.ethz.ch>	<4763D2E6.90301@iugrina.com>
	<18276.8363.639290.462401@ada-stat.math.ethz.ch>
Message-ID: <47644E26.8080308@iugrina.com>

Hi Martin,

Martin Maechler wrote:
> that's quite convincing; thank you!
> and I can verify part of it on my computer.
:D

> I think I'd just commit your signrank.c
> (with a few cosmetic changes) to the sources, right?
Right!

There is no need for SIGNRANK_MAX in src/nmath/nmath.h anymore.

> Thank you for your contribution!
You're welcome.

With respect,
-- 
Ivo Ugrina
ICQ: 47508335 | www.iugrina.com
-------------------------------
baza matematickih pojmova
http://baza.iugrina.com
---------------------------
anime, manga, Japan fanzin
http://yoshi.iugrina.com


From david at unusualsolutionsthatwork.com  Sat Dec 15 23:15:03 2007
From: david at unusualsolutionsthatwork.com (David C. Norris)
Date: Sat, 15 Dec 2007 14:15:03 -0800
Subject: [Rd] List comprehensions for R
In-Reply-To: <971536df0712091426i51e9161brbf3fff9550d57645@mail.gmail.com>
References: <475C611A.8000302@unusualsolutionsthatwork.com>
	<971536df0712091426i51e9161brbf3fff9550d57645@mail.gmail.com>
Message-ID: <476451E7.7060901@unusualsolutionsthatwork.com>

Gabor,

Thank you for drawing this previous work to my attention.  I've attached 
below code that extends the list comprehension to include logical 
'guard' expressions, as in

 > leap.years <- .[ x ~ x <- 1900:2100 | (x %% 400 == 0 || x %% 100 != 0 
&& x %% 4 == 0) ]
 > leap.years
 [1] 1904 1908 1912 1916 1920 1924 1928 1932 1936 1940 1944 1948 1952 
1956 1960
[16] 1964 1968 1972 1976 1980 1984 1988 1992 1996 2000 2004 2008 2012 
2016 2020
[31] 2024 2028 2032 2036 2040 2044 2048 2052 2056 2060 2064 2068 2072 
2076 2080
[46] 2084 2088 2092 2096
 >

I wonder, would many (most?) R users be "mathematically-trained 
statisticians first, and programmers second", and therefore find a 
mathematical notation like the list comprehension more natural than less 
declarative programming constructs?  I would be genuinely interested in 
your (and others') thoughts on that question, based on your knowledge of 
the R user community.

Regards,
David

Gabor Grothendieck wrote:
> That seems quite nice.
>
> Note that there has been some related code posted.  See:
> http://tolstoy.newcastle.edu.au/R/help/03b/6406.html
> which discusses some R idioms for list comprehensions.
>
> Also the gsubfn package has some functionality in this direction.  We
> preface any function with fn$ to allow functions in its arguments
> to be specified as formulas.  Its more R-ish than your code and
> applies to more than just list comprehensions while your code is
> more faithful to list comprehensions.
>
>
>>
## Updated to include logical guards in list comprehensions

##
## Define syntax for list/vector/array comprehensions
##

. <<- structure(NA, class="comprehension")

comprehend <- function(expr, vars, seqs, guard, comprehension=list()){
  if(length(vars)==0){  # base case of recursion
    if(eval(guard)) comprehension[[length(comprehension)+1]] <- eval(expr)
  } else {
    for(elt in eval(seqs[[1]])){
      assign(vars[1], elt, inherits=TRUE)
      comprehension <- comprehend(expr, vars[-1], seqs[-1], guard, 
comprehension)
    }
  }
  comprehension
}

## List comprehensions specified by close approximation to set-builder 
notation:
##
##   { x+y | 0<x<9, 0<y<x, x*y<30 } ---> .[ x+y ~ {x<-0:9; y<-0:x} | 
x*y<30 ]
##
"[.comprehension" <- function(x, f){
  f <- substitute(f)
  ## First, we pluck out the optional guard, if it is present:
  if(is.call(f) && is.call(f[[3]]) && f[[3]][[1]]=='|'){
    guard <- f[[3]][[3]]
    f[[3]] <- f[[3]][[2]]
  } else {
    guard <- TRUE
  }
  ## To allow omission of braces around a lone comprehension generator,
  ## as in 'expr ~ var <- seq' we make allowances for two shapes of f:
  ##
  ## (1)    (`<-` (`~` expr
  ##                   var)
  ##              seq)
  ## and
  ##
  ## (2)    (`~` expr
  ##             (`{` (`<-` var1 seq1)
  ##                  (`<-` var2 seq2)
  ##                      ...
  ##                  (`<-` varN <- seqN)))
  ##
  ## In the former case, we set gens <- list(var <- seq), unifying the
  ## treatment of both shapes under the latter, more general one.
  syntax.error <- "Comprehension expects 'expr ~ {x1 <- seq1; ... ; xN 
<- seqN}'."
  if(!is.call(f) || (f[[1]]!='<-' && f[[1]]!='~'))
    stop(syntax.error)
  if(is(f,'<-')){ # (1)
    lhs <- f[[2]]
    if(!is.call(lhs) || lhs[[1]] != '~')
      stop(syntax.error)
    expr <- lhs[[2]]
    var <- as.character(lhs[[3]])
    seq <- f[[3]]
    gens <- list(call('<-', var, seq))
  } else { # (2)
    expr <- f[[2]]
    gens <- as.list(f[[3]])[-1]
    if(any(lapply(gens, class) != '<-'))
      stop(syntax.error)
  }
  ## Fill list comprehension .LC
  vars <- as.character(lapply(gens, function(g) g[[2]]))
  seqs <- lapply(gens, function(g) g[[3]])
  .LC <- comprehend(expr, vars, seqs, guard)
  ## Provided the result is rectangular, convert it to a vector or array
  ## TODO: Extend to handle .LC structures more than 2-deep.
  ## TODO: Avoid rectangularizing nested comprehensions along guarded 
dimensions?
  if(!length(.LC))
    return(.LC)
  dim1 <- dim(.LC[[1]])
  if(is.null(dim1)){
    lengths <- sapply(.LC, length)
    if(all(lengths == lengths[1])){ # rectangular
      .LC <- unlist(.LC)
      if(lengths[1] > 1) # matrix
        dim(.LC) <- c(lengths[1], length(lengths))
    } else { # ragged
      # leave .LC as a list
    }
  } else { # elements of .LC have dimension
    dim <- c(dim1, length(.LC))
    .LC <- unlist(.LC)
    dim(.LC) <- dim
  }
  .LC
}


From maechler at stat.math.ethz.ch  Sat Dec 15 23:17:49 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 15 Dec 2007 23:17:49 +0100
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <4762EE76.9070401@acm.org>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca> <47618124.7060504@acm.org>
	<47618A54.3060900@stats.uwo.ca> <4762EE76.9070401@acm.org>
Message-ID: <18276.21133.818619.889393@ada-stat.math.ethz.ch>

>>>>> "TP" == Tony Plate <tplate at acm.org>
>>>>>     on Fri, 14 Dec 2007 13:58:30 -0700 writes:

    TP> Duncan Murdoch wrote:
    >> On 12/13/2007 1:59 PM, Tony Plate wrote:
    >>> Duncan Murdoch wrote:
    >>>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
    >>>>> Full_Name: Petr Simecek
    >>>>> Version: 2.5.1, 2.6.1
    >>>>> OS: Windows XP
    >>>>> Submission from: (NULL) (195.113.231.2)
    >>>>> 
    >>>>> 
    >>>>> Several times I have experienced that a length of a POSIXt vector 
    >>>>> has not been
    >>>>> computed right.
    >>>>> 
    >>>>> Example:
    >>>>> 
    >>>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
    >>>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
    >>>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 12L), 
    >>>>> mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 13L), mon 
    >>>>> = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
    >>>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = 
    >>>>> c(1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
    >>>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
    >>>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", "min", 
    >>>>> "hour", "mday", "mon", "year", "wday", "yday", "isdst"
    >>>>> ), class = c("POSIXt", "POSIXlt"))
    >>>>> 
    >>>>> print(tv)
    >>>>> # print 11 time points (right)
    >>>>> 
    >>>>> length(tv)
    >>>>> # returns 9 (wrong)
    >>>> 
    >>>> tv is a list of length 9.  The answer is right, your expectation is 
    >>>> wrong.
    >>>>> I have tried that on several computers with/without switching to 
    >>>>> English
    >>>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a 
    >>>>> help pages but I
    >>>>> cannot imagine how that could be OK.
    >>>> 
    >>>> See this in ?POSIXt:
    >>>> 
    >>>> Class '"POSIXlt"' is a named list of vectors...
    >>>> 
    >>>> You could define your own length measurement as
    >>>> 
    >>>> length.POSIXlt <- function(x) length(x$sec)
    >>>> 
    >>>> and you'll get the answer you expect, but be aware that length.XXX 
    >>>> methods are quite rare, and you may surprise some of your users.
    >>>> 
    >>> 
    >>> On the other hand, isn't the fact that length() currently always 
    >>> returns 9 for POSIXlt objects likely to be a surprise to many users 
    >>> of POSIXlt?
    >>> 
    >>> The back of "The New S Language" says "Easy-to-use facilities allow 
    >>> you to organize, store and retrieve all sorts of data. ... S 
    >>> functions and data organization make applications easy to write."
    >>> 
    >>> Now, POSIXlt has methods for c() and vector subsetting "[" (and many 
    >>> other vector-manipulation methods - see methods(class="POSIXlt")).  
    >>> Hence, from the point of view of intending to supply "easy-to-use 
    >>> facilities ... [for] all sorts of data", isn't it a little 
    >>> incongruous that length() is not also provided -- as 3 functions (any 
    >>> others?) comprise a core set of vector-manipulation functions?
    >>> 
    >>> Would it make sense to have an informal prescription (e.g., in 
    >>> R-exts) that a class that implements a vector-like object and 
    >>> provides at least of one of functions 'c', '[' and 'length' should 
    >>> provide all three?  It would also be easy to describe a test-suite 
    >>> that should be included in the 'test' directory of a package 
    >>> implementing such a class, that had some tests of the basic 
    >>> vector-manipulation functionality, such as:
    >>> 
    >>> > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
    >>> > # class being tested, of length 0, 1, 3, and 10, and they should
    >>> > # contain no duplicate elements
    >>> > length(x0)
    >>> [1] 1
    >>> > length(c(x0, x1))
    >>> [1] 2
    >>> > length(c(x1,x10))
    >>> [1] 11
    >>> > all(x3 == x3[seq(len=length(x3))])
    >>> [1] TRUE
    >>> > all(x3 == c(x3[1], x3[2], x3[3]))
    >>> [1] TRUE
    >>> > length(c(x3[2], x10[5:7]))
    >>> [1] 4
    >>> >
    >>> 
    >>> It would also be possible to describe a larger set of vector 
    >>> manipulation functions that should be implemented together, including 
    >>> e.g., 'rep', 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', 
    >>> head, tail ... (many of which are provided for POSIXlt).
    >>> 
    >>> Or is there some good reason that length() cannot be provided (while 
    >>> 'c' and '[' can) for some vector-like classes such as "POSIXlt"?
    >> 
    >> What you say sounds good in general, but the devil is in the details. 
    >> Changing the meaning of length(x) for some objects has fairly 
    >> widespread effects.  Are they all positive?  I don't know.
    >> 
    >> Adding a prescription like the one you suggest would be good if it's 
    >> easy to implement, but bad if it's already widely violated.  How many 
    >> base or CRAN or Bioconductor packages violate it currently?   Do the 
    >> ones that provide all 3 methods do so in a consistent way, i.e. does 
    >> "length(x)" mean the same thing in all of them?
    TP> I'm not sure doing something like this would be so bad even if it is 
    TP> already widely violated.  R has evolved significantly over time, and 
    TP> many rough edges have been cleaned up, sometimes in ways that were not 
    TP> backward compatible.  This is a great thing & my thanks go to the people 
    TP> working on R.

    TP> If some base or CRAN or Bioconductor packages currently don't implement 
    TP> vector operations consistently, wouldn't it be good to know that?  
    TP> Wouldn't it be useful to have an automatic way of determining whether a 
    TP> particular vector-like class is consistent with generally agreed set of 
    TP> principles for how basic vector operations should work -- things like 
    TP> length(x)+length(y)==length(c(x,y))?  This could help developers check, 
    TP> document & improve their code, and it could help users understand how to 
    TP> use a class, and to evaluate the software quality of a class 
    TP> implementation and whether or not it provides the functionality they need.
    >> I agree that the current state is less than perfect, but making it 
    >> better would really be a lot of work.  I suspect there are better ways 
    >> to spend my time, so I'm not going to volunteer to do it.  I'm not 
    >> even going to invite someone else to do it, or offer to review your 
    >> work if you volunteer.  I think this falls into the class of "next 
    >> time we write a language, let's handle this better" problems.

    TP> Thanks very much for the thoughtful (and honest) feedback!  I suspect 
    TP> that the current state could be improved with just a little work, and 
    TP> without forcing anyone to do any work they don't want to do.  I'll think 
    TP> about this more and try to come back with a better & more concrete 
    TP> suggestion.

Good. From "the outside" (i.e. superficial gut feeling :-)
I've sympathized with your suggestion, Tony, quite a bit.
Further, my own taste would probably also have lead me to define
length.POSIXlt differently ..
OTOH, I agree with Duncan that it may be too late to change it
and even more to enforce the consistency rules you propose.
If with a small bit of code (and some patience) we could check
all of CRAN and hopefully bioconductor packages and find only a
very few where it was violated, the whole endeavor may be worth it
... for the sake of making  R more consistent, easier to teach, etc..

Unfortunately I don't remember now what happened many months ago
when I indeed did experiment with having something like

  length.POSIXlt <- function(x) length(x$sec)

Martin Maechler


From ggrothendieck at gmail.com  Sun Dec 16 01:20:07 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Dec 2007 19:20:07 -0500
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <18276.21133.818619.889393@ada-stat.math.ethz.ch>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca> <47618124.7060504@acm.org>
	<47618A54.3060900@stats.uwo.ca> <4762EE76.9070401@acm.org>
	<18276.21133.818619.889393@ada-stat.math.ethz.ch>
Message-ID: <971536df0712151620t182ab193hc1d4263eb6709427@mail.gmail.com>

If it were simply deprecated and then changed then
everyone using it would get a warning during the period
of deprecation so it would
not be so bad.  Given that its current behavior is
not very useful I suspect its not widely used anyways.
| haven't followed the whole discussion so sorry if these
points have already been made.

On Dec 15, 2007 5:17 PM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >>>>> "TP" == Tony Plate <tplate at acm.org>
> >>>>>     on Fri, 14 Dec 2007 13:58:30 -0700 writes:
>
>
>    TP> Duncan Murdoch wrote:
>    >> On 12/13/2007 1:59 PM, Tony Plate wrote:
>    >>> Duncan Murdoch wrote:
>    >>>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>    >>>>> Full_Name: Petr Simecek
>    >>>>> Version: 2.5.1, 2.6.1
>    >>>>> OS: Windows XP
>    >>>>> Submission from: (NULL) (195.113.231.2)
>    >>>>>
>    >>>>>
>    >>>>> Several times I have experienced that a length of a POSIXt vector
>    >>>>> has not been
>    >>>>> computed right.
>    >>>>>
>    >>>>> Example:
>    >>>>>
>    >>>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>    >>>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>    >>>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 12L),
>    >>>>> mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 13L), mon
>    >>>>> = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L,
>    >>>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday =
>    >>>>> c(1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L,
>    >>>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L,
>    >>>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", "min",
>    >>>>> "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>    >>>>> ), class = c("POSIXt", "POSIXlt"))
>    >>>>>
>    >>>>> print(tv)
>    >>>>> # print 11 time points (right)
>    >>>>>
>    >>>>> length(tv)
>    >>>>> # returns 9 (wrong)
>    >>>>
>    >>>> tv is a list of length 9.  The answer is right, your expectation is
>    >>>> wrong.
>    >>>>> I have tried that on several computers with/without switching to
>    >>>>> English
>    >>>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a
>    >>>>> help pages but I
>    >>>>> cannot imagine how that could be OK.
>    >>>>
>    >>>> See this in ?POSIXt:
>    >>>>
>    >>>> Class '"POSIXlt"' is a named list of vectors...
>    >>>>
>    >>>> You could define your own length measurement as
>    >>>>
>    >>>> length.POSIXlt <- function(x) length(x$sec)
>    >>>>
>    >>>> and you'll get the answer you expect, but be aware that length.XXX
>    >>>> methods are quite rare, and you may surprise some of your users.
>    >>>>
>    >>>
>    >>> On the other hand, isn't the fact that length() currently always
>    >>> returns 9 for POSIXlt objects likely to be a surprise to many users
>    >>> of POSIXlt?
>    >>>
>    >>> The back of "The New S Language" says "Easy-to-use facilities allow
>    >>> you to organize, store and retrieve all sorts of data. ... S
>    >>> functions and data organization make applications easy to write."
>    >>>
>    >>> Now, POSIXlt has methods for c() and vector subsetting "[" (and many
>    >>> other vector-manipulation methods - see methods(class="POSIXlt")).
>    >>> Hence, from the point of view of intending to supply "easy-to-use
>    >>> facilities ... [for] all sorts of data", isn't it a little
>    >>> incongruous that length() is not also provided -- as 3 functions (any
>    >>> others?) comprise a core set of vector-manipulation functions?
>    >>>
>    >>> Would it make sense to have an informal prescription (e.g., in
>    >>> R-exts) that a class that implements a vector-like object and
>    >>> provides at least of one of functions 'c', '[' and 'length' should
>    >>> provide all three?  It would also be easy to describe a test-suite
>    >>> that should be included in the 'test' directory of a package
>    >>> implementing such a class, that had some tests of the basic
>    >>> vector-manipulation functionality, such as:
>    >>>
>    >>> > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
>    >>> > # class being tested, of length 0, 1, 3, and 10, and they should
>    >>> > # contain no duplicate elements
>    >>> > length(x0)
>    >>> [1] 1
>    >>> > length(c(x0, x1))
>    >>> [1] 2
>    >>> > length(c(x1,x10))
>    >>> [1] 11
>    >>> > all(x3 == x3[seq(len=length(x3))])
>    >>> [1] TRUE
>    >>> > all(x3 == c(x3[1], x3[2], x3[3]))
>    >>> [1] TRUE
>    >>> > length(c(x3[2], x10[5:7]))
>    >>> [1] 4
>    >>> >
>    >>>
>    >>> It would also be possible to describe a larger set of vector
>    >>> manipulation functions that should be implemented together, including
>    >>> e.g., 'rep', 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na',
>    >>> head, tail ... (many of which are provided for POSIXlt).
>    >>>
>    >>> Or is there some good reason that length() cannot be provided (while
>    >>> 'c' and '[' can) for some vector-like classes such as "POSIXlt"?
>    >>
>    >> What you say sounds good in general, but the devil is in the details.
>    >> Changing the meaning of length(x) for some objects has fairly
>    >> widespread effects.  Are they all positive?  I don't know.
>    >>
>    >> Adding a prescription like the one you suggest would be good if it's
>    >> easy to implement, but bad if it's already widely violated.  How many
>    >> base or CRAN or Bioconductor packages violate it currently?   Do the
>    >> ones that provide all 3 methods do so in a consistent way, i.e. does
>    >> "length(x)" mean the same thing in all of them?
>    TP> I'm not sure doing something like this would be so bad even if it is
>    TP> already widely violated.  R has evolved significantly over time, and
>    TP> many rough edges have been cleaned up, sometimes in ways that were not
>    TP> backward compatible.  This is a great thing & my thanks go to the people
>    TP> working on R.
>
>    TP> If some base or CRAN or Bioconductor packages currently don't implement
>    TP> vector operations consistently, wouldn't it be good to know that?
>    TP> Wouldn't it be useful to have an automatic way of determining whether a
>    TP> particular vector-like class is consistent with generally agreed set of
>    TP> principles for how basic vector operations should work -- things like
>    TP> length(x)+length(y)==length(c(x,y))?  This could help developers check,
>    TP> document & improve their code, and it could help users understand how to
>    TP> use a class, and to evaluate the software quality of a class
>    TP> implementation and whether or not it provides the functionality they need.
>    >> I agree that the current state is less than perfect, but making it
>    >> better would really be a lot of work.  I suspect there are better ways
>    >> to spend my time, so I'm not going to volunteer to do it.  I'm not
>    >> even going to invite someone else to do it, or offer to review your
>    >> work if you volunteer.  I think this falls into the class of "next
>    >> time we write a language, let's handle this better" problems.
>
>    TP> Thanks very much for the thoughtful (and honest) feedback!  I suspect
>    TP> that the current state could be improved with just a little work, and
>    TP> without forcing anyone to do any work they don't want to do.  I'll think
>    TP> about this more and try to come back with a better & more concrete
>    TP> suggestion.
>
> Good. From "the outside" (i.e. superficial gut feeling :-)
> I've sympathized with your suggestion, Tony, quite a bit.
> Further, my own taste would probably also have lead me to define
> length.POSIXlt differently ..
> OTOH, I agree with Duncan that it may be too late to change it
> and even more to enforce the consistency rules you propose.
> If with a small bit of code (and some patience) we could check
> all of CRAN and hopefully bioconductor packages and find only a
> very few where it was violated, the whole endeavor may be worth it
> ... for the sake of making  R more consistent, easier to teach, etc..
>
> Unfortunately I don't remember now what happened many months ago
> when I indeed did experiment with having something like
>
>  length.POSIXlt <- function(x) length(x$sec)
>
> Martin Maechler
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From antonio.fabio at gmail.com  Sun Dec 16 12:50:37 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Sun, 16 Dec 2007 12:50:37 +0100
Subject: [Rd] mistake in Italian translation
Message-ID: <b0808fdc0712160350r5db03f2bn76d610506e9d4417@mail.gmail.com>

Hi all.
I'm not sure I should send this here, but the link to the Italian
Traslation Team is dead here:
http://developer.r-project.org/TranslationTeams.html

I've found an annoying mistake in the italian traslation of a base
error message:
##
> d <- data.frame(a=1)
> d$a <- 1:2
Errore in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
  dati sostitutivi con %righe, i dati ne hanno 1
##

This is a little cryptic message for the final user, if compared with this:
##
> Sys.setlocale('LC_MESSAGES','C')
[1] "C"
> d$a <- 1:2
Error in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
  replacement has 2 rows, data has 1
##

Find attached the proposed patch against revision 43697.

Bests,
Antonio.

-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy
-------------- next part --------------
A non-text attachment was scrubbed...
Name: R-it.po.patch
Type: text/x-patch
Size: 530 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20071216/7a940ee9/attachment.bin 

From allan.pe at windowslive.com  Sun Dec 16 15:14:35 2007
From: allan.pe at windowslive.com (Allan Pe)
Date: Sun, 16 Dec 2007 16:14:35 +0200
Subject: [Rd] APARCH?
In-Reply-To: <1197475654.47600746b635f@webmail.oulu.fi>
References: <1197475654.47600746b635f@webmail.oulu.fi>
Message-ID: <BLU127-W10FA20FB20041DDD1560E189610@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071216/9a04f9f8/attachment.pl 

From murdoch at stats.uwo.ca  Sun Dec 16 15:41:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 16 Dec 2007 09:41:27 -0500
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <18276.21133.818619.889393@ada-stat.math.ethz.ch>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>	<475FF376.8080806@stats.uwo.ca>	<47618124.7060504@acm.org>	<47618A54.3060900@stats.uwo.ca>	<4762EE76.9070401@acm.org>
	<18276.21133.818619.889393@ada-stat.math.ethz.ch>
Message-ID: <47653917.9090905@stats.uwo.ca>

On 15/12/2007 5:17 PM, Martin Maechler wrote:
>>>>>> "TP" == Tony Plate <tplate at acm.org>
>>>>>>     on Fri, 14 Dec 2007 13:58:30 -0700 writes:
> 
>     TP> Duncan Murdoch wrote:
>     >> On 12/13/2007 1:59 PM, Tony Plate wrote:
>     >>> Duncan Murdoch wrote:
>     >>>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>     >>>>> Full_Name: Petr Simecek
>     >>>>> Version: 2.5.1, 2.6.1
>     >>>>> OS: Windows XP
>     >>>>> Submission from: (NULL) (195.113.231.2)
>     >>>>> 
>     >>>>> 
>     >>>>> Several times I have experienced that a length of a POSIXt vector 
>     >>>>> has not been
>     >>>>> computed right.
>     >>>>> 
>     >>>>> Example:
>     >>>>> 
>     >>>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>     >>>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>     >>>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 12L), 
>     >>>>> mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 13L), mon 
>     >>>>> = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
>     >>>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = 
>     >>>>> c(1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
>     >>>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
>     >>>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", "min", 
>     >>>>> "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>     >>>>> ), class = c("POSIXt", "POSIXlt"))
>     >>>>> 
>     >>>>> print(tv)
>     >>>>> # print 11 time points (right)
>     >>>>> 
>     >>>>> length(tv)
>     >>>>> # returns 9 (wrong)
>     >>>> 
>     >>>> tv is a list of length 9.  The answer is right, your expectation is 
>     >>>> wrong.
>     >>>>> I have tried that on several computers with/without switching to 
>     >>>>> English
>     >>>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a 
>     >>>>> help pages but I
>     >>>>> cannot imagine how that could be OK.
>     >>>> 
>     >>>> See this in ?POSIXt:
>     >>>> 
>     >>>> Class '"POSIXlt"' is a named list of vectors...
>     >>>> 
>     >>>> You could define your own length measurement as
>     >>>> 
>     >>>> length.POSIXlt <- function(x) length(x$sec)
>     >>>> 
>     >>>> and you'll get the answer you expect, but be aware that length.XXX 
>     >>>> methods are quite rare, and you may surprise some of your users.
>     >>>> 
>     >>> 
>     >>> On the other hand, isn't the fact that length() currently always 
>     >>> returns 9 for POSIXlt objects likely to be a surprise to many users 
>     >>> of POSIXlt?
>     >>> 
>     >>> The back of "The New S Language" says "Easy-to-use facilities allow 
>     >>> you to organize, store and retrieve all sorts of data. ... S 
>     >>> functions and data organization make applications easy to write."
>     >>> 
>     >>> Now, POSIXlt has methods for c() and vector subsetting "[" (and many 
>     >>> other vector-manipulation methods - see methods(class="POSIXlt")).  
>     >>> Hence, from the point of view of intending to supply "easy-to-use 
>     >>> facilities ... [for] all sorts of data", isn't it a little 
>     >>> incongruous that length() is not also provided -- as 3 functions (any 
>     >>> others?) comprise a core set of vector-manipulation functions?
>     >>> 
>     >>> Would it make sense to have an informal prescription (e.g., in 
>     >>> R-exts) that a class that implements a vector-like object and 
>     >>> provides at least of one of functions 'c', '[' and 'length' should 
>     >>> provide all three?  It would also be easy to describe a test-suite 
>     >>> that should be included in the 'test' directory of a package 
>     >>> implementing such a class, that had some tests of the basic 
>     >>> vector-manipulation functionality, such as:
>     >>> 
>     >>> > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
>     >>> > # class being tested, of length 0, 1, 3, and 10, and they should
>     >>> > # contain no duplicate elements
>     >>> > length(x0)
>     >>> [1] 1
>     >>> > length(c(x0, x1))
>     >>> [1] 2
>     >>> > length(c(x1,x10))
>     >>> [1] 11
>     >>> > all(x3 == x3[seq(len=length(x3))])
>     >>> [1] TRUE
>     >>> > all(x3 == c(x3[1], x3[2], x3[3]))
>     >>> [1] TRUE
>     >>> > length(c(x3[2], x10[5:7]))
>     >>> [1] 4
>     >>> >
>     >>> 
>     >>> It would also be possible to describe a larger set of vector 
>     >>> manipulation functions that should be implemented together, including 
>     >>> e.g., 'rep', 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', 
>     >>> head, tail ... (many of which are provided for POSIXlt).
>     >>> 
>     >>> Or is there some good reason that length() cannot be provided (while 
>     >>> 'c' and '[' can) for some vector-like classes such as "POSIXlt"?
>     >> 
>     >> What you say sounds good in general, but the devil is in the details. 
>     >> Changing the meaning of length(x) for some objects has fairly 
>     >> widespread effects.  Are they all positive?  I don't know.
>     >> 
>     >> Adding a prescription like the one you suggest would be good if it's 
>     >> easy to implement, but bad if it's already widely violated.  How many 
>     >> base or CRAN or Bioconductor packages violate it currently?   Do the 
>     >> ones that provide all 3 methods do so in a consistent way, i.e. does 
>     >> "length(x)" mean the same thing in all of them?
>     TP> I'm not sure doing something like this would be so bad even if it is 
>     TP> already widely violated.  R has evolved significantly over time, and 
>     TP> many rough edges have been cleaned up, sometimes in ways that were not 
>     TP> backward compatible.  This is a great thing & my thanks go to the people 
>     TP> working on R.
> 
>     TP> If some base or CRAN or Bioconductor packages currently don't implement 
>     TP> vector operations consistently, wouldn't it be good to know that?  
>     TP> Wouldn't it be useful to have an automatic way of determining whether a 
>     TP> particular vector-like class is consistent with generally agreed set of 
>     TP> principles for how basic vector operations should work -- things like 
>     TP> length(x)+length(y)==length(c(x,y))?  This could help developers check, 
>     TP> document & improve their code, and it could help users understand how to 
>     TP> use a class, and to evaluate the software quality of a class 
>     TP> implementation and whether or not it provides the functionality they need.
>     >> I agree that the current state is less than perfect, but making it 
>     >> better would really be a lot of work.  I suspect there are better ways 
>     >> to spend my time, so I'm not going to volunteer to do it.  I'm not 
>     >> even going to invite someone else to do it, or offer to review your 
>     >> work if you volunteer.  I think this falls into the class of "next 
>     >> time we write a language, let's handle this better" problems.
> 
>     TP> Thanks very much for the thoughtful (and honest) feedback!  I suspect 
>     TP> that the current state could be improved with just a little work, and 
>     TP> without forcing anyone to do any work they don't want to do.  I'll think 
>     TP> about this more and try to come back with a better & more concrete 
>     TP> suggestion.
> 
> Good. From "the outside" (i.e. superficial gut feeling :-)
> I've sympathized with your suggestion, Tony, quite a bit.
> Further, my own taste would probably also have lead me to define
> length.POSIXlt differently ..
> OTOH, I agree with Duncan that it may be too late to change it
> and even more to enforce the consistency rules you propose.
> If with a small bit of code (and some patience) we could check
> all of CRAN and hopefully bioconductor packages and find only a
> very few where it was violated, the whole endeavor may be worth it
> ... for the sake of making  R more consistent, easier to teach, etc..
> 
> Unfortunately I don't remember now what happened many months ago
> when I indeed did experiment with having something like
> 
>   length.POSIXlt <- function(x) length(x$sec)
> 
> Martin Maechler

One reason I don't want to work on this is because the appropriate 
action depends on what "length(x)" is intended to mean.  Currently for 
POSIXlt objects, it gives the physical length of the underlying basic 
type (the list).  This is the same behaviour as we have for matrices, 
data frames and every other object without a specific length method, so 
it's not outrageous.

The proposed change is to have it return the logical length of the 
object, which also seems quite reasonable.  I don't think matrices and 
data frames have a "logical length", so there would be no contradiction 
in those examples.  The thing that worries me is that there are probably 
objects in packages where both logical length and physical length make 
sense but are different.  I don't have any expectation that length(x) on 
those currently is consistent in which type of value it returns.

If we were to decide that "length(x)" *always* meant logical length, 
then we would have a problem:  matrices and data frames don't have a 
logical length, so we shouldn't be getting an answer there.  Changing 
length(x) for those is not acceptable.

On the other hand, if we decide that "length(x)" *always* means physical 
length, we don't need to do anything to the POSIXlt or matrices or data 
frames, but there may well be other kinds of objects out there that 
violate this rule.

We could leave the meaning of length(x) ambiguous.  If you want to know 
what it does for a POSIXlt object, you need to read the documentation or 
look at the source code.  As a policy, this isn't particularly 
appealing, but I could probably live with it if someone else did the 
research and showed that current usage is ambiguous.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sun Dec 16 19:01:12 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Dec 2007 18:01:12 +0000 (GMT)
Subject: [Rd] mistake in Italian translation
In-Reply-To: <b0808fdc0712160350r5db03f2bn76d610506e9d4417@mail.gmail.com>
References: <b0808fdc0712160350r5db03f2bn76d610506e9d4417@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712161758030.26141@gannet.stats.ox.ac.uk>

I think we no longer have an active Italian translation team.  I'll make 
the change you suggest.

On Sun, 16 Dec 2007, Antonio, Fabio Di Narzo wrote:

> Hi all.
> I'm not sure I should send this here, but the link to the Italian
> Traslation Team is dead here:
> http://developer.r-project.org/TranslationTeams.html
>
> I've found an annoying mistake in the italian traslation of a base
> error message:
> ##
>> d <- data.frame(a=1)
>> d$a <- 1:2
> Errore in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
>  dati sostitutivi con %righe, i dati ne hanno 1
> ##
>
> This is a little cryptic message for the final user, if compared with this:
> ##
>> Sys.setlocale('LC_MESSAGES','C')
> [1] "C"
>> d$a <- 1:2
> Error in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
>  replacement has 2 rows, data has 1
> ##
>
> Find attached the proposed patch against revision 43697.
>
> Bests,
> Antonio.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stefano.iacus at unimi.it  Mon Dec 17 01:13:47 2007
From: stefano.iacus at unimi.it (stefano iacus)
Date: Mon, 17 Dec 2007 09:13:47 +0900
Subject: [Rd] mistake in Italian translation
In-Reply-To: <Pine.LNX.4.64.0712161758030.26141@gannet.stats.ox.ac.uk>
References: <b0808fdc0712160350r5db03f2bn76d610506e9d4417@mail.gmail.com>
	<Pine.LNX.4.64.0712161758030.26141@gannet.stats.ox.ac.uk>
Message-ID: <A973E44A-3EB7-47DE-A70D-D445BD04BE35@unimi.it>

I'll try to revise the translations for 2.7.0
And Antonio is right, that link is broken. Will fix.
stefano
On 17/dic/07, at 03:01, Prof Brian Ripley wrote:

> I think we no longer have an active Italian translation team.  I'll  
> make
> the change you suggest.
>
> On Sun, 16 Dec 2007, Antonio, Fabio Di Narzo wrote:
>
>> Hi all.
>> I'm not sure I should send this here, but the link to the Italian
>> Traslation Team is dead here:
>> http://developer.r-project.org/TranslationTeams.html
>>
>> I've found an annoying mistake in the italian traslation of a base
>> error message:
>> ##
>>> d <- data.frame(a=1)
>>> d$a <- 1:2
>> Errore in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
>>  dati sostitutivi con %righe, i dati ne hanno 1
>> ##
>>
>> This is a little cryptic message for the final user, if compared  
>> with this:
>> ##
>>> Sys.setlocale('LC_MESSAGES','C')
>> [1] "C"
>>> d$a <- 1:2
>> Error in `$<-.data.frame`(`*tmp*`, "a", value = 1:2) :
>>  replacement has 2 rows, data has 1
>> ##
>>
>> Find attached the proposed patch against revision 43697.
>>
>> Bests,
>> Antonio.
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tplate at acm.org  Mon Dec 17 07:53:36 2007
From: tplate at acm.org (Tony Plate)
Date: Sun, 16 Dec 2007 23:53:36 -0700
Subject: [Rd] guidelines for consistency of vector functions
Message-ID: <47661CF0.5060008@acm.org>

Moving on from the discussion of the fact that length(x)==9 for any 
POSIXlt object x (which seems diabolically confusing, given that 'c' and 
'[' are defined for POSIXlt and have the vector-like behavior one would 
expect), what about having some guidelines for coding and documentation 
of vector-like classes?

(1) a vector-like class should implement functions in groups:
    level 1: 'c', '[', 'length'
    level 2: 'x[i] <- value', 'rep', 'unique', 'duplicated'
    level 3: 'head', 'tail', 'sort'
    NA group: 'is.na' 'x[i] <- NA' 'is.na(x) <- TRUE'
    character coercion: 'as.character', 'as.<CLASS>.character'
    names group: 'names()' 'names()<-'

[should '==', 'all.equal' be included anywhere]

If any member of a group is implemented, then it is considered good 
style to implement the others.

(2) conformance or deviation from this guideline should be documented on 
the help page for the class.

These could go in a section of R-ext, and a function that automatically 
checks conformance could also be supplied as part of R.  A rough version 
of such a function is attached.

This would have the following benefits:

(1) developers would have guidelines and tools to help them write 
classes that behave in a way that users expect

(2) users would know better what to expect, both in general, and in 
specific cases where developers followed the documentation guidelines.

(3) observance of the guidelines would be an indicator of software 
quality (no evidence of any attention to the guidelines would be a sign 
that the code was more of an experiment than a piece of software that 
was carefully engineered for widespread use.)

All of the above is a rough draft that could be discussed further (e.g., 
should '[.<-' go in level 1 or level 2?) if there was any interest in 
pursuing this suggestion.

Comments?

-- Tony Plate

PS:

Here's a few examples of running an automatic vector-functionality 
tester on some vector-like classes in R ("basic"="level 1", 
"extra"="level 2", and "bonus"="level 3" functions) (this might be hard 
to read if line wrapping happens -- I've attached text files):

 > source("testVectorFunctionality.R")
 > library(chron)
 > if (exists("length.POSIXlt")) remove(list="length.POSIXlt")
 >
 > ### 'character' passes the functionality tests
 > res <- testVectorFunctionality(CLASS="character", verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >
 > ### 'numeric' passes the functionality tests
 > res <- testVectorFunctionality(CLASS="numeric", verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >
 > ### 'integer' passes the functionality tests
 > res <- testVectorFunctionality(CLASS="integer", verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >
 > ### 'Date' passes the functionality tests
 > res <- testVectorFunctionality(from.numeric=function(i) 
as.Date("2001/01/01") + i, verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >
 > ### chron 'times' passes the basic, but not the extra functionality tests
 > res <- testVectorFunctionality(from.numeric=function(i) 
chron(times=i), verbose=FALSE)
Failed 0 of 17 basic tests, 12 of 17 extra tests, and 0 of 0 bonus tests
 > res <- testVectorFunctionality(from.numeric=function(i) 
chron(times=i), verbose=TRUE)
Testing basic vector functionality for class 'times'
Testing extra vector functionality for class 'times'
   Failed consistency check: unique(xa) == xa
   Failed consistency check: unique(xb) == xb
   Failed consistency check: unique(x0) == x0
   Failed consistency check: unique(x1) == x1
   Failed consistency check: unique(xA) == xA[!duplicated(xA)]
   Failed consistency check: rep(x1, 3) == c(x1, x1, x1)
   Failed consistency check: rep(xa, 3) == c(xa, xa, xa)
   Failed consistency check: rep(xb, 2) == c(xb, xb)
   Failed consistency check: rep(x1, 0) == x1[0]
   Failed consistency check: rep(xa, each = 3) == xa[rep(seq(len = 
xa.len), each = 3)]
   Failed consistency check: rep(xb, each = 2) == xb[rep(seq(len = 
xb.len), each = 2)]
   Failed consistency check: rep(xa, length.out = xa.len + 1) == c(xa, 
xa[1])
In 17 basic consistency tests on 'times', had the following outcomes: ok:17
   'ok' tests (17) involved: '[':4, c:9, length:9
In 17 extra consistency tests on 'times', had the following outcomes: 
failure:12, ok:5
   'failure' tests (12) involved: duplicated:1, rep:7, unique:5
   'ok' tests (5) involved: duplicated:5
Did not perform any bonus consistency tests on 'times'
 >
 > ### chron 'dates' does not pass the basic functionality tests
 > res <- testVectorFunctionality(from.numeric=function(i) chron(i), 
verbose=FALSE)
Failed 6 of 17 basic tests, 0 of 0 extra tests, and 0 of 0 bonus tests
 > res <- testVectorFunctionality(from.numeric=function(i) chron(i), 
verbose=TRUE)
Testing basic vector functionality for class ['dates', 'times']
   Failed consistency check: c(x1) == x1
   Failed consistency check: c(x1, x0) == x1
   Failed consistency check: c(x0, x1) == x1
   Failed consistency check: c(xa) == xa
   Failed consistency check: c(xa, x0) == xa
   Failed consistency check: c(x0, xa) == xa
In 17 basic consistency tests on ['dates', 'times'], had the following 
outcomes: failure:6, ok:11
   'failure' tests (6) involved: c:6
   'ok' tests (11) involved: '[':4, c:3, length:9
Did not perform any extra consistency tests on ['dates', 'times']
Did not perform any bonus consistency tests on ['dates', 'times']
 > # The reason for the failure with c() is that it removes names on the 
origin in chron 'dates'
 > eval(quote(all.equal(c(x1), x1)), res$bindings)
[1] "Attributes: < Component 3: names for current but not for target >"
 > attr(eval(quote(x1), res$bindings), "origin")
month   day  year
     1     1  1970
 > attr(eval(quote(c(x1)), res$bindings), "origin")
[1]    1    1 1970
 >
 > ### POSIXct passes the functionality tests
 > res <- testVectorFunctionality(from.numeric=function(i) 
as.POSIXct("2001/01/01") + 24*3600*i, verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >
 > ### POSIXlt fails the basic functionality tests because length() for 
POSIXlt always returns 9
 > res <- testVectorFunctionality(from.numeric=function(i) 
as.POSIXlt(as.POSIXlt("2001/01/01") + 24*3600*i), verbose=FALSE)
Failed 9 of 17 basic tests, 0 of 0 extra tests, and 0 of 0 bonus tests
 > res <- testVectorFunctionality(from.numeric=function(i) 
as.POSIXlt(as.POSIXlt("2001/01/01") + 24*3600*i), verbose=TRUE)
Testing basic vector functionality for class ['POSIXt', 'POSIXlt']
   Failed consistency check: length(x1) == 1L
   Failed consistency check: length(x0) == 0L
   Failed consistency check: length(xa) == xa.len
   Failed consistency check: length(xb) == xb.len
   Failed consistency check: length(c(x1, xa)) == xa.len + x1.len
   Failed consistency check: length(c(x0, xa)) == xa.len
   Failed consistency check: length(c(xa, xb)) == xa.len + xb.len
   Failed consistency check: xa[-length(xa)] == xa[seq(len = xa.len - 1)]
   Failed consistency check: length(xa[0]) == 0L
In 17 basic consistency tests on ['POSIXt', 'POSIXlt'], had the 
following outcomes: failure:9, ok:8
   'failure' tests (9) involved: '[':2, c:3, length:9
   'ok' tests (8) involved: '[':2, c:6
Did not perform any extra consistency tests on ['POSIXt', 'POSIXlt']
Did not perform any bonus consistency tests on ['POSIXt', 'POSIXlt']
 >
 > ### define length() for POSIXlt and now POSIXlt passes the 
functionality tests
 > length.POSIXlt <- function(x) length(x$sec)
 > res <- testVectorFunctionality(from.numeric=function(i) 
as.POSIXlt(as.POSIXlt("2001/01/01") + 24*3600*i), verbose=FALSE)
Passed all 17 basic tests, 17 extra tests, and 5 bonus tests
 >

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: TestRuns.txt
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071216/fd6d51fc/attachment.txt 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: testVectorFunctionality.R
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071216/fd6d51fc/attachment.pl 

From tplate at acm.org  Mon Dec 17 07:53:40 2007
From: tplate at acm.org (Tony Plate)
Date: Sun, 16 Dec 2007 23:53:40 -0700
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <47653917.9090905@stats.uwo.ca>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>	<475FF376.8080806@stats.uwo.ca>	<47618124.7060504@acm.org>	<47618A54.3060900@stats.uwo.ca>	<4762EE76.9070401@acm.org>	<18276.21133.818619.889393@ada-stat.math.ethz.ch>
	<47653917.9090905@stats.uwo.ca>
Message-ID: <47661CF4.1040303@acm.org>

Duncan Murdoch wrote:
> On 15/12/2007 5:17 PM, Martin Maechler wrote:
>>>>>>> "TP" == Tony Plate <tplate at acm.org>
>>>>>>>     on Fri, 14 Dec 2007 13:58:30 -0700 writes:
>>     TP> Duncan Murdoch wrote:
>>     >> On 12/13/2007 1:59 PM, Tony Plate wrote:
>>     >>> Duncan Murdoch wrote:
>>     >>>> On 12/11/2007 6:20 AM, simecek at gmail.com wrote:
>>     >>>>> Full_Name: Petr Simecek
>>     >>>>> Version: 2.5.1, 2.6.1
>>     >>>>> OS: Windows XP
>>     >>>>> Submission from: (NULL) (195.113.231.2)
>>     >>>>> 
>>     >>>>> 
>>     >>>>> Several times I have experienced that a length of a POSIXt vector 
>>     >>>>> has not been
>>     >>>>> computed right.
>>     >>>>> 
>>     >>>>> Example:
>>     >>>>> 
>>     >>>>> tv<-structure(list(sec = c(50, 0, 55, 12, 2, 0, 37, NA, 17, 3, 31
>>     >>>>> ), min = c(1L, 10L, 11L, 15L, 16L, 18L, 18L, NA, 20L, 22L, 22L
>>     >>>>> ), hour = c(12L, 12L, 12L, 12L, 12L, 12L, 12L, NA, 12L, 12L, 12L), 
>>     >>>>> mday = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, NA, 13L, 13L, 13L), mon 
>>     >>>>> = c(5L, 5L, 5L, 5L, 5L, 5L, 5L, NA, 5L, 5L, 5L), year = c(105L, 
>>     >>>>> 105L, 105L, 105L, 105L, 105L, 105L, NA, 105L, 105L, 105L), wday = 
>>     >>>>> c(1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L), yday = c(163L, 163L, 
>>     >>>>> 163L, 163L, 163L, 163L, 163L, NA, 163L, 163L, 163L), isdst = c(1L, 
>>     >>>>> 1L, 1L, 1L, 1L, 1L, 1L, -1L, 1L, 1L, 1L)), .Names = c("sec", "min", 
>>     >>>>> "hour", "mday", "mon", "year", "wday", "yday", "isdst"
>>     >>>>> ), class = c("POSIXt", "POSIXlt"))
>>     >>>>> 
>>     >>>>> print(tv)
>>     >>>>> # print 11 time points (right)
>>     >>>>> 
>>     >>>>> length(tv)
>>     >>>>> # returns 9 (wrong)
>>     >>>> 
>>     >>>> tv is a list of length 9.  The answer is right, your expectation is 
>>     >>>> wrong.
>>     >>>>> I have tried that on several computers with/without switching to 
>>     >>>>> English
>>     >>>>> locales, i.e. Sys.setlocale("LC_TIME", "en"). I have searched a 
>>     >>>>> help pages but I
>>     >>>>> cannot imagine how that could be OK.
>>     >>>> 
>>     >>>> See this in ?POSIXt:
>>     >>>> 
>>     >>>> Class '"POSIXlt"' is a named list of vectors...
>>     >>>> 
>>     >>>> You could define your own length measurement as
>>     >>>> 
>>     >>>> length.POSIXlt <- function(x) length(x$sec)
>>     >>>> 
>>     >>>> and you'll get the answer you expect, but be aware that length.XXX 
>>     >>>> methods are quite rare, and you may surprise some of your users.
>>     >>>> 
>>     >>> 
>>     >>> On the other hand, isn't the fact that length() currently always 
>>     >>> returns 9 for POSIXlt objects likely to be a surprise to many users 
>>     >>> of POSIXlt?
>>     >>> 
>>     >>> The back of "The New S Language" says "Easy-to-use facilities allow 
>>     >>> you to organize, store and retrieve all sorts of data. ... S 
>>     >>> functions and data organization make applications easy to write."
>>     >>> 
>>     >>> Now, POSIXlt has methods for c() and vector subsetting "[" (and many 
>>     >>> other vector-manipulation methods - see methods(class="POSIXlt")).  
>>     >>> Hence, from the point of view of intending to supply "easy-to-use 
>>     >>> facilities ... [for] all sorts of data", isn't it a little 
>>     >>> incongruous that length() is not also provided -- as 3 functions (any 
>>     >>> others?) comprise a core set of vector-manipulation functions?
>>     >>> 
>>     >>> Would it make sense to have an informal prescription (e.g., in 
>>     >>> R-exts) that a class that implements a vector-like object and 
>>     >>> provides at least of one of functions 'c', '[' and 'length' should 
>>     >>> provide all three?  It would also be easy to describe a test-suite 
>>     >>> that should be included in the 'test' directory of a package 
>>     >>> implementing such a class, that had some tests of the basic 
>>     >>> vector-manipulation functionality, such as:
>>     >>> 
>>     >>> > # at this point, x0, x1, x3, & x10 should exist, as vectors of the
>>     >>> > # class being tested, of length 0, 1, 3, and 10, and they should
>>     >>> > # contain no duplicate elements
>>     >>> > length(x0)
>>     >>> [1] 1
>>     >>> > length(c(x0, x1))
>>     >>> [1] 2
>>     >>> > length(c(x1,x10))
>>     >>> [1] 11
>>     >>> > all(x3 == x3[seq(len=length(x3))])
>>     >>> [1] TRUE
>>     >>> > all(x3 == c(x3[1], x3[2], x3[3]))
>>     >>> [1] TRUE
>>     >>> > length(c(x3[2], x10[5:7]))
>>     >>> [1] 4
>>     >>> >
>>     >>> 
>>     >>> It would also be possible to describe a larger set of vector 
>>     >>> manipulation functions that should be implemented together, including 
>>     >>> e.g., 'rep', 'unique', 'duplicated', '==', 'sort', '[<-', 'is.na', 
>>     >>> head, tail ... (many of which are provided for POSIXlt).
>>     >>> 
>>     >>> Or is there some good reason that length() cannot be provided (while 
>>     >>> 'c' and '[' can) for some vector-like classes such as "POSIXlt"?
>>     >> 
>>     >> What you say sounds good in general, but the devil is in the details. 
>>     >> Changing the meaning of length(x) for some objects has fairly 
>>     >> widespread effects.  Are they all positive?  I don't know.
>>     >> 
>>     >> Adding a prescription like the one you suggest would be good if it's 
>>     >> easy to implement, but bad if it's already widely violated.  How many 
>>     >> base or CRAN or Bioconductor packages violate it currently?   Do the 
>>     >> ones that provide all 3 methods do so in a consistent way, i.e. does 
>>     >> "length(x)" mean the same thing in all of them?
>>     TP> I'm not sure doing something like this would be so bad even if it is 
>>     TP> already widely violated.  R has evolved significantly over time, and 
>>     TP> many rough edges have been cleaned up, sometimes in ways that were not 
>>     TP> backward compatible.  This is a great thing & my thanks go to the people 
>>     TP> working on R.
>>
>>     TP> If some base or CRAN or Bioconductor packages currently don't implement 
>>     TP> vector operations consistently, wouldn't it be good to know that?  
>>     TP> Wouldn't it be useful to have an automatic way of determining whether a 
>>     TP> particular vector-like class is consistent with generally agreed set of 
>>     TP> principles for how basic vector operations should work -- things like 
>>     TP> length(x)+length(y)==length(c(x,y))?  This could help developers check, 
>>     TP> document & improve their code, and it could help users understand how to 
>>     TP> use a class, and to evaluate the software quality of a class 
>>     TP> implementation and whether or not it provides the functionality they need.
>>     >> I agree that the current state is less than perfect, but making it 
>>     >> better would really be a lot of work.  I suspect there are better ways 
>>     >> to spend my time, so I'm not going to volunteer to do it.  I'm not 
>>     >> even going to invite someone else to do it, or offer to review your 
>>     >> work if you volunteer.  I think this falls into the class of "next 
>>     >> time we write a language, let's handle this better" problems.
>>
>>     TP> Thanks very much for the thoughtful (and honest) feedback!  I suspect 
>>     TP> that the current state could be improved with just a little work, and 
>>     TP> without forcing anyone to do any work they don't want to do.  I'll think 
>>     TP> about this more and try to come back with a better & more concrete 
>>     TP> suggestion.
>>
>> Good. From "the outside" (i.e. superficial gut feeling :-)
>> I've sympathized with your suggestion, Tony, quite a bit.
>> Further, my own taste would probably also have lead me to define
>> length.POSIXlt differently ..
>> OTOH, I agree with Duncan that it may be too late to change it
>> and even more to enforce the consistency rules you propose.
>> If with a small bit of code (and some patience) we could check
>> all of CRAN and hopefully bioconductor packages and find only a
>> very few where it was violated, the whole endeavor may be worth it
>> ... for the sake of making  R more consistent, easier to teach, etc..
>>
>> Unfortunately I don't remember now what happened many months ago
>> when I indeed did experiment with having something like
>>
>>   length.POSIXlt <- function(x) length(x$sec)
>>
>> Martin Maechler
> 
> One reason I don't want to work on this is because the appropriate 
> action depends on what "length(x)" is intended to mean.  Currently for 
> POSIXlt objects, it gives the physical length of the underlying basic 
> type (the list).  This is the same behaviour as we have for matrices, 
> data frames and every other object without a specific length method, so 
> it's not outrageous.
> 
> The proposed change is to have it return the logical length of the 
> object, which also seems quite reasonable.  I don't think matrices and 
> data frames have a "logical length", so there would be no contradiction 
> in those examples.  The thing that worries me is that there are probably 
> objects in packages where both logical length and physical length make 
> sense but are different.  I don't have any expectation that length(x) on 
> those currently is consistent in which type of value it returns.
> 
> If we were to decide that "length(x)" *always* meant logical length, 
> then we would have a problem:  matrices and data frames don't have a 
> logical length, so we shouldn't be getting an answer there.  Changing 
> length(x) for those is not acceptable.
> 
> On the other hand, if we decide that "length(x)" *always* means physical 
> length, we don't need to do anything to the POSIXlt or matrices or data 
> frames, but there may well be other kinds of objects out there that 
> violate this rule.
> 
> We could leave the meaning of length(x) ambiguous.  If you want to know 
> what it does for a POSIXlt object, you need to read the documentation or 
> look at the source code.  As a policy, this isn't particularly 
> appealing, but I could probably live with it if someone else did the 
> research and showed that current usage is ambiguous.

Leaving the meaning of length(x) ambiguous seems reasonable to me (as 
are the meanings of 'c' and '[').

I was thinking more in terms of consistency of either supplying all or 
none of the tightly related group of functions 'c', '[', and 'length'. 
It seems diabolically confusing that 'c' and '[' exist for POSIXlt and 
do the expected things in terms of the vector-of-dates interpretation, 
but length does something completely different.  (And this is not 
mentioned in ?POSIXlt).

Coding & documentation guidelines & tools could help R to move towards 
more consistency with regard to this kind of behavior.

-- Tony Plate

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Dan.Kelley at dal.ca  Sun Dec 16 22:38:16 2007
From: Dan.Kelley at dal.ca (dankelley)
Date: Sun, 16 Dec 2007 13:38:16 -0800 (PST)
Subject: [Rd] Defaults for postscript()
In-Reply-To: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0712060752060.17952@gannet.stats.ox.ac.uk>
Message-ID: <14366644.post@talk.nabble.com>


I think you should change anything you want to change, on the assumption that
most users are setting things by themselves, anyway.

Now may be the time to change anything that you (and those kind enough to
reply to your post) would like to see changed.   For an example, I really
like the ratio of font size to default plot size that I see in windows on my
OSX machine, and would love it if pdf (which I use instead of postscript),
produced similar geometry.  I find pdf() produces a sort of "spaced out"
appearance, with large fonts and lots of spacing, and that's great for
giving lectures, but for papers I always set the page width to 10 inches or
more, simply to get a higher ratio of data to labels.
-- 
View this message in context: http://www.nabble.com/Defaults-for-postscript%28%29-tp14188096p14366644.html
Sent from the R devel mailing list archive at Nabble.com.


From lieven.clement at gmail.com  Mon Dec 17 10:14:09 2007
From: lieven.clement at gmail.com (lieven)
Date: Mon, 17 Dec 2007 01:14:09 -0800 (PST)
Subject: [Rd] Rsquared bug lm() (PR#10516)
In-Reply-To: <476290AA.3000107@stats.uwo.ca>
References: <20071214131025.963A8283416B@mail.pubhealth.ku.dk>
	<476290AA.3000107@stats.uwo.ca>
Message-ID: <14370172.post@talk.nabble.com>


Basically, I used the without intercept to get an estimate for each of my
factor levels instead of using a reference class. So I use a kind of hidden
intercept.

I should have noticed that the behavior was documented in ?summary.lm.

Sorry for the inconvenience. 

Lieven



Duncan Murdoch-2 wrote:
> 
> On 12/14/2007 8:10 AM, lieven.clement at gmail.com wrote:
>> Full_Name: lieven clement
>> Version:  R version 2.4.0 Patched (2006-11-25 r39997)
>> OS: i486-pc-linux-gnu
>> Submission from: (NULL) (157.193.193.180)
>> 
>> 
>> summary.lm() does not calculate R?? accurately for models without
>> intercepts if
>> one of the predictor variables is a factor.
>> In order to avoid one of the factor levels to be considered as a
>> reference class
>> you can use the -1 option in a formula. When you use this, R?? is not
>> correctly
>> calculated.
> 
> This is not a bug.  A model without an intercept should be using y=0 as 
> a reference.
> 
> Duncan Murdoch
> 
>> 
>>>  x1<-rnorm(100)
>>> x2<-c(rep(0,25),rep(10,25),rep(20,25),rep(30,25))
>>> y<-10*x1+x2+rnorm(100,0,4)
>>> x2<-as.factor(x2)
>>> lmtest<-lm(y~-1+x1+x2)
>>> summary(lmtest)$r.sq
>> [1] 0.9650201
>>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
>> [1] 0.9342672
>> 
>> The R squared by summary is calculated as
>>> 1-sum(lmtest$res^2)/sum((y)^2)
>> [1] 0.9650201
>> apparently because lm.summary assumes the mean of y to be zero.
>> 
>> In case of an intercept model everything seems ok
>>> lmtest<-lm(y~x1+x2)
>>> summary(lmtest)$r.sq
>> [1] 0.9342672
>>> 1-sum(lmtest$res^2)/sum((y-mean(y))^2)
>> [1] 0.9342672
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Rsquared-bug-lm%28%29-%28PR-10516%29-tp14335791p14370172.html
Sent from the R devel mailing list archive at Nabble.com.


From pburns at pburns.seanet.com  Mon Dec 17 12:00:48 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 17 Dec 2007 11:00:48 +0000
Subject: [Rd] help files for load and related functions
Message-ID: <476656E0.1000307@pburns.seanet.com>

I recently had a discussion with a user about loading
and attaching in R.  I was surprised that the help files
don't  provide a very clear picture.

 From my point of view 'load' and 'attach' are very
similar operations, the difference being that 'attach'
creates a new database on the search list while 'load'
puts all the objects into the global environment.

The help file for 'load' is inexplicit that this is what
happens.  The 'load' and 'attach' help files neither refer
to the other in their See Also.

Furthermore, the 'library' help file talks about "loading"
packages.  I would suggest that it should use "attaching"
as that is the analogous operation.

None of these three help files (nor that of 'save') has a
Side Effects section.  Personally I think that all help files
should have a Side Effects section (to make it clear to
new users what side effects are and that they are not a
good thing for most functions to have).  I can understand
there could be another point of view on that.  However, I
definitely think that there should be a Side Effects section
in the help files of functions whose whole point is a side
effect.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


From murdoch at stats.uwo.ca  Mon Dec 17 15:03:55 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 17 Dec 2007 09:03:55 -0500
Subject: [Rd] help files for load and related functions
In-Reply-To: <476656E0.1000307@pburns.seanet.com>
References: <476656E0.1000307@pburns.seanet.com>
Message-ID: <476681CB.9010900@stats.uwo.ca>

On 12/17/2007 6:00 AM, Patrick Burns wrote:
> I recently had a discussion with a user about loading
> and attaching in R.  I was surprised that the help files
> don't  provide a very clear picture.
> 
>  From my point of view 'load' and 'attach' are very
> similar operations, the difference being that 'attach'
> creates a new database on the search list while 'load'
> puts all the objects into the global environment.
> 
> The help file for 'load' is inexplicit that this is what
> happens.  The 'load' and 'attach' help files neither refer
> to the other in their See Also.
> 
> Furthermore, the 'library' help file talks about "loading"
> packages.  I would suggest that it should use "attaching"
> as that is the analogous operation.
> 
> None of these three help files (nor that of 'save') has a
> Side Effects section.  Personally I think that all help files
> should have a Side Effects section (to make it clear to
> new users what side effects are and that they are not a
> good thing for most functions to have).  I can understand
> there could be another point of view on that.  However, I
> definitely think that there should be a Side Effects section
> in the help files of functions whose whole point is a side
> effect.

I think you make good points.  Care to submit patches?  The source for 
those man pages are in

https://svn.R-project.org/R/trunk/src/library/base/man/attach.Rd

https://svn.R-project.org/R/trunk/src/library/base/man/library.Rd

https://svn.R-project.org/R/trunk/src/library/base/man/load.Rd

https://svn.R-project.org/R/trunk/src/library/base/man/save.Rd

If you send them to me before Thursday or after Jan 2, I'll take a look. 
  (If you send them to me during the Xmas break there's a good chance 
they'll get lost.)

Duncan Murdoch


From osklyar at ebi.ac.uk  Mon Dec 17 15:06:13 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 17 Dec 2007 14:06:13 +0000
Subject: [Rd] help files for load and related functions
In-Reply-To: <476656E0.1000307@pburns.seanet.com>
References: <476656E0.1000307@pburns.seanet.com>
Message-ID: <1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>

Dear Patrick,

?Firstly, and most importantly, I do not think that your post qualified
for Rd! Please use the correct mail list for such things: R-help. I do
not think anybody on Rd wants mailboxes ?clogged with irrelevant
messages.

Back to your question: it is not clear if you are confused, or your
'user' is confused, but all three help pages look pretty clear and
straight forward to me. Moreover,  I do not see any connection between
attach and library, which you find logical:

- load - the general use of this one is to load external data sets, e.g.
load serialised R object(s) (as the example shows). Until you load, you
cannot use the object as it has no relation to the R session and can be
e.g. a file sitting somewhere on a network

- attach - the general use of this one would be to access elements of a
data set directly, without the data set name specifier and the accessor
operator, such as $, thus as the help page states - it is used to add
the data set to the search path (as the example shows). If you look at
the example, you do not have to call attach to be able to use data, data
could have existed there before and what you effectively get with attach
is a more convenient way of dealing with the data

- library - is used to load *and* attach an R package, which is not
exactly the same as a serialised R object(s), but a full set of other
functionality. Attaching packages is just a part of the loading process,
which occurs basically when the package becomes visible to the user.
Same as with load, you cannot use the package until you load it. There
is not a hint of similarity between loading a package and attaching a
data set as I see it. 

Regards,
Oleg

On Mon, 2007-12-17 at 11:00 +0000, Patrick Burns wrote:
> I recently had a discussion with a user about loading
> and attaching in R.  I was surprised that the help files
> don't  provide a very clear picture.
> 
>  From my point of view 'load' and 'attach' are very
> similar operations, the difference being that 'attach'
> creates a new database on the search list while 'load'
> puts all the objects into the global environment.
> 
> The help file for 'load' is inexplicit that this is what
> happens.  The 'load' and 'attach' help files neither refer
> to the other in their See Also.
> 
> Furthermore, the 'library' help file talks about "loading"
> packages.  I would suggest that it should use "attaching"
> as that is the analogous operation.
> 
> None of these three help files (nor that of 'save') has a
> Side Effects section.  Personally I think that all help files
> should have a Side Effects section (to make it clear to
> new users what side effects are and that they are not a
> good thing for most functions to have).  I can understand
> there could be another point of view on that.  However, I
> definitely think that there should be a Side Effects section
> in the help files of functions whose whole point is a side
> effect.
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466


From gavin.simpson at ucl.ac.uk  Mon Dec 17 15:31:20 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 17 Dec 2007 14:31:20 +0000
Subject: [Rd] help files for load and related functions
In-Reply-To: <1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>
References: <476656E0.1000307@pburns.seanet.com>
	<1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>
Message-ID: <1197901880.9683.77.camel@prometheus.geog.ucl.ac.uk>

On Mon, 2007-12-17 at 14:06 +0000, Oleg Sklyar wrote:
> Dear Patrick,
> 
> ?Firstly, and most importantly, I do not think that your post qualified
> for Rd! Please use the correct mail list for such things: R-help. I do
> not think anybody on Rd wants mailboxes ?clogged with irrelevant
> messages.

No. R Devel *is* the correct place for this discussion, as it pertains
to the development of R. Patrick is reporting that he found the current
help for load(), attach() etc lacking explicit statements about what R
actually does when you call them, and how the functions differ in their
side effects, especially from the point of view of a new "user".

The reason for your comment above is perhaps related to the one below my
text; Patrick _isn't_ looking for help, just pointing out an infelicity
in the current documentation as identified by the "user", and, I
suspect, welcoming comment on his suggestions for changes.

G

> 
> Back to your question: it is not clear if you are confused, or your
> 'user' is confused, but all three help pages look pretty clear and
> straight forward to me. Moreover,  I do not see any connection between
> attach and library, which you find logical:
> 
> - load - the general use of this one is to load external data sets, e.g.
> load serialised R object(s) (as the example shows). Until you load, you
> cannot use the object as it has no relation to the R session and can be
> e.g. a file sitting somewhere on a network
> 
> - attach - the general use of this one would be to access elements of a
> data set directly, without the data set name specifier and the accessor
> operator, such as $, thus as the help page states - it is used to add
> the data set to the search path (as the example shows). If you look at
> the example, you do not have to call attach to be able to use data, data
> could have existed there before and what you effectively get with attach
> is a more convenient way of dealing with the data
> 
> - library - is used to load *and* attach an R package, which is not
> exactly the same as a serialised R object(s), but a full set of other
> functionality. Attaching packages is just a part of the loading process,
> which occurs basically when the package becomes visible to the user.
> Same as with load, you cannot use the package until you load it. There
> is not a hint of similarity between loading a package and attaching a
> data set as I see it. 
> 
> Regards,
> Oleg
> 
> On Mon, 2007-12-17 at 11:00 +0000, Patrick Burns wrote:
> > I recently had a discussion with a user about loading
> > and attaching in R.  I was surprised that the help files
> > don't  provide a very clear picture.
> > 
> >  From my point of view 'load' and 'attach' are very
> > similar operations, the difference being that 'attach'
> > creates a new database on the search list while 'load'
> > puts all the objects into the global environment.
> > 
> > The help file for 'load' is inexplicit that this is what
> > happens.  The 'load' and 'attach' help files neither refer
> > to the other in their See Also.
> > 
> > Furthermore, the 'library' help file talks about "loading"
> > packages.  I would suggest that it should use "attaching"
> > as that is the analogous operation.
> > 
> > None of these three help files (nor that of 'save') has a
> > Side Effects section.  Personally I think that all help files
> > should have a Side Effects section (to make it clear to
> > new users what side effects are and that they are not a
> > good thing for most functions to have).  I can understand
> > there could be another point of view on that.  However, I
> > definitely think that there should be a Side Effects section
> > in the help files of functions whose whole point is a side
> > effect.
> > 
> > Patrick Burns
> > patrick at burns-stat.com
> > +44 (0)20 8525 0696
> > http://www.burns-stat.com
> > (home of S Poetry and "A Guide for the Unwilling S User")
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch at stats.uwo.ca  Mon Dec 17 15:36:48 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 17 Dec 2007 09:36:48 -0500
Subject: [Rd] help files for load and related functions
In-Reply-To: <1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>
References: <476656E0.1000307@pburns.seanet.com>
	<1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>
Message-ID: <47668980.5070001@stats.uwo.ca>

On 12/17/2007 9:06 AM, Oleg Sklyar wrote:
> Dear Patrick,
> 
> ?Firstly, and most importantly, I do not think that your post qualified
> for Rd! Please use the correct mail list for such things: R-help. I do
> not think anybody on Rd wants mailboxes ?clogged with irrelevant
> messages.

Since Patrick's message was about changes to the documentation, I think 
it is relevant to this list.

Duncan Murdoch

> Back to your question: it is not clear if you are confused, or your
> 'user' is confused, but all three help pages look pretty clear and
> straight forward to me. Moreover,  I do not see any connection between
> attach and library, which you find logical:
> 
> - load - the general use of this one is to load external data sets, e.g.
> load serialised R object(s) (as the example shows). Until you load, you
> cannot use the object as it has no relation to the R session and can be
> e.g. a file sitting somewhere on a network
> 
> - attach - the general use of this one would be to access elements of a
> data set directly, without the data set name specifier and the accessor
> operator, such as $, thus as the help page states - it is used to add
> the data set to the search path (as the example shows). If you look at
> the example, you do not have to call attach to be able to use data, data
> could have existed there before and what you effectively get with attach
> is a more convenient way of dealing with the data
> 
> - library - is used to load *and* attach an R package, which is not
> exactly the same as a serialised R object(s), but a full set of other
> functionality. Attaching packages is just a part of the loading process,
> which occurs basically when the package becomes visible to the user.
> Same as with load, you cannot use the package until you load it. There
> is not a hint of similarity between loading a package and attaching a
> data set as I see it. 
> 
> Regards,
> Oleg
> 
> On Mon, 2007-12-17 at 11:00 +0000, Patrick Burns wrote:
>> I recently had a discussion with a user about loading
>> and attaching in R.  I was surprised that the help files
>> don't  provide a very clear picture.
>> 
>>  From my point of view 'load' and 'attach' are very
>> similar operations, the difference being that 'attach'
>> creates a new database on the search list while 'load'
>> puts all the objects into the global environment.
>> 
>> The help file for 'load' is inexplicit that this is what
>> happens.  The 'load' and 'attach' help files neither refer
>> to the other in their See Also.
>> 
>> Furthermore, the 'library' help file talks about "loading"
>> packages.  I would suggest that it should use "attaching"
>> as that is the analogous operation.
>> 
>> None of these three help files (nor that of 'save') has a
>> Side Effects section.  Personally I think that all help files
>> should have a Side Effects section (to make it clear to
>> new users what side effects are and that they are not a
>> good thing for most functions to have).  I can understand
>> there could be another point of view on that.  However, I
>> definitely think that there should be a Side Effects section
>> in the help files of functions whose whole point is a side
>> effect.
>> 
>> Patrick Burns
>> patrick at burns-stat.com
>> +44 (0)20 8525 0696
>> http://www.burns-stat.com
>> (home of S Poetry and "A Guide for the Unwilling S User")
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From caroline.keef at jbaconsulting.co.uk  Mon Dec 17 15:00:23 2007
From: caroline.keef at jbaconsulting.co.uk (caroline.keef at jbaconsulting.co.uk)
Date: Mon, 17 Dec 2007 15:00:23 +0100 (CET)
Subject: [Rd] Installation of RGtk2 (PR#10519)
Message-ID: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>

Full_Name: Caroline Keef
Version: 2.6.1
OS: Windows XP
Submission from: (NULL) (195.171.203.131)


I have tried to install the package rggobi which if I'm right requires the
package RGtk2 
If I install RGtk2 using the install.packages (I used the UK (Bristol) mirror, I
haven't tried any other mirror) within R and then use library(RGtk2) I get the
following message box

"This application has failed to start because libtak-1.0-0.dll was not found. 
Re-installing the application may fix this problem."

I click ok and the following is printed to the R console.

Error in dyn.load(file, ...) : 
  unable to load shared library
'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
  LoadLibrary failure:  The specified module could not be found.


[1] "PLEASE RESTART R BEFORE TRYING TO LOAD THE PACKAGE AGAIN"
Error in .C("R_gtkInit", length(args), x = args, PACKAGE = "RGtk2") : 
  C symbol name "R_gtkInit" not in DLL for package "RGtk2"
In addition: Warning message:
In fun(...) :
  Failed to load RGtk2 dynamic library:Error in dyn.load(file, ...) : 
  unable to load shared library
'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
  LoadLibrary failure:  The specified module could not be found.


Error : .onLoad failed in 'loadNamespace' for 'RGtk2'
Error: package/namespace load failed for 'RGtk2'

I've re-started R again and the same happened.  I've also tried downloading the
RGtk2 zip files from the CRAN website and installing from a local zip file
option which gave the same results.  I haven't tried re-installing R to get
around this problem.


From pburns at pburns.seanet.com  Mon Dec 17 15:57:36 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 17 Dec 2007 14:57:36 +0000
Subject: [Rd] help files for load and related functions
In-Reply-To: <476681CB.9010900@stats.uwo.ca>
References: <476656E0.1000307@pburns.seanet.com>
	<476681CB.9010900@stats.uwo.ca>
Message-ID: <47668E60.9070704@pburns.seanet.com>

Patches to the help files sound like a good idea.  However,
it isn't something I'm likely to get to immediately.  I'm
hoping that some other nice person will volunteer.

Pat

Duncan Murdoch wrote:

> On 12/17/2007 6:00 AM, Patrick Burns wrote:
>
>> I recently had a discussion with a user about loading
>> and attaching in R.  I was surprised that the help files
>> don't  provide a very clear picture.
>>
>>  From my point of view 'load' and 'attach' are very
>> similar operations, the difference being that 'attach'
>> creates a new database on the search list while 'load'
>> puts all the objects into the global environment.
>>
>> The help file for 'load' is inexplicit that this is what
>> happens.  The 'load' and 'attach' help files neither refer
>> to the other in their See Also.
>>
>> Furthermore, the 'library' help file talks about "loading"
>> packages.  I would suggest that it should use "attaching"
>> as that is the analogous operation.
>>
>> None of these three help files (nor that of 'save') has a
>> Side Effects section.  Personally I think that all help files
>> should have a Side Effects section (to make it clear to
>> new users what side effects are and that they are not a
>> good thing for most functions to have).  I can understand
>> there could be another point of view on that.  However, I
>> definitely think that there should be a Side Effects section
>> in the help files of functions whose whole point is a side
>> effect.
>
>
> I think you make good points.  Care to submit patches?  The source for 
> those man pages are in
>
> https://svn.R-project.org/R/trunk/src/library/base/man/attach.Rd
>
> https://svn.R-project.org/R/trunk/src/library/base/man/library.Rd
>
> https://svn.R-project.org/R/trunk/src/library/base/man/load.Rd
>
> https://svn.R-project.org/R/trunk/src/library/base/man/save.Rd
>
> If you send them to me before Thursday or after Jan 2, I'll take a 
> look.  (If you send them to me during the Xmas break there's a good 
> chance they'll get lost.)
>
> Duncan Murdoch
>
>


From jhallman at frb.gov  Mon Dec 17 16:13:07 2007
From: jhallman at frb.gov (Jeffrey J. Hallman)
Date: Mon, 17 Dec 2007 10:13:07 -0500
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>
	<475FF376.8080806@stats.uwo.ca> <47618124.7060504@acm.org>
	<47618A54.3060900@stats.uwo.ca> <4762EE76.9070401@acm.org>
	<18276.21133.818619.889393@ada-stat.math.ethz.ch>
	<47653917.9090905@stats.uwo.ca>
Message-ID: <xmrejdlxsl8.fsf@mralx1.rsma.frb.gov>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> One reason I don't want to work on this is because the appropriate 
> action depends on what "length(x)" is intended to mean.  Currently for 
> POSIXlt objects, it gives the physical length of the underlying basic 
> type (the list).  This is the same behaviour as we have for matrices, 
> data frames and every other object without a specific length method, so 
> it's not outrageous.
>
> The proposed change is to have it return the logical length of the 
> object, which also seems quite reasonable.  I don't think matrices and 
> data frames have a "logical length", so there would be no contradiction 
> in those examples.  The thing that worries me is that there are probably 
> objects in packages where both logical length and physical length make 
> sense but are different.  I don't have any expectation that length(x) on 
> those currently is consistent in which type of value it returns.
>
> If we were to decide that "length(x)" *always* meant logical length, 
> then we would have a problem:  matrices and data frames don't have a 
> logical length, so we shouldn't be getting an answer there.  Changing 
> length(x) for those is not acceptable.
>
> On the other hand, if we decide that "length(x)" *always* means physical 
> length, we don't need to do anything to the POSIXlt or matrices or data 
> frames, but there may well be other kinds of objects out there that 
> violate this rule.
>
> We could leave the meaning of length(x) ambiguous.  If you want to know 
> what it does for a POSIXlt object, you need to read the documentation or 
> look at the source code.  As a policy, this isn't particularly 
> appealing, but I could probably live with it if someone else did the 
> research and showed that current usage is ambiguous.

Physical length and logical length are, as you say, two different things.  So
why not two functions?  Keep length() for physical length, as it is now, and
maybe Length() for logical length.  The latter could be defined as

Length <- function(x, ...) UseMethod("Length")

Length.default <- function(x, ...) length(x)

and then add methods for classes that want something else.

-- 
Jeff


From murdoch at stats.uwo.ca  Mon Dec 17 16:21:23 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 17 Dec 2007 10:21:23 -0500
Subject: [Rd] Installation of RGtk2 (PR#10519)
In-Reply-To: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
References: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
Message-ID: <476693F3.2030905@stats.uwo.ca>

This isn't an R bug.  You should send contributed package problems to 
the package maintainer, in this case Michael Lawrence.

You need to install GTK; it's not included as part of the package.  See 
this page for instructions:

http://www.ggobi.org/rgtk2/

It would probably be a good idea for the R package to recognize this 
omission and print more helpful error messages, but setting that up is 
tricky.  Michael, if you want help, please contact me offline.

Duncan Murdoch

On 12/17/2007 9:00 AM, caroline.keef at jbaconsulting.co.uk wrote:
> Full_Name: Caroline Keef
> Version: 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.171.203.131)
> 
> 
> I have tried to install the package rggobi which if I'm right requires the
> package RGtk2 
> If I install RGtk2 using the install.packages (I used the UK (Bristol) mirror, I
> haven't tried any other mirror) within R and then use library(RGtk2) I get the
> following message box
> 
> "This application has failed to start because libtak-1.0-0.dll was not found. 
> Re-installing the application may fix this problem."
> 
> I click ok and the following is printed to the R console.
> 
> Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> [1] "PLEASE RESTART R BEFORE TRYING TO LOAD THE PACKAGE AGAIN"
> Error in .C("R_gtkInit", length(args), x = args, PACKAGE = "RGtk2") : 
>   C symbol name "R_gtkInit" not in DLL for package "RGtk2"
> In addition: Warning message:
> In fun(...) :
>   Failed to load RGtk2 dynamic library:Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error : .onLoad failed in 'loadNamespace' for 'RGtk2'
> Error: package/namespace load failed for 'RGtk2'
> 
> I've re-started R again and the same happened.  I've also tried downloading the
> RGtk2 zip files from the CRAN website and installing from a local zip file
> option which gave the same results.  I haven't tried re-installing R to get
> around this problem.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From osklyar at ebi.ac.uk  Mon Dec 17 16:23:44 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 17 Dec 2007 15:23:44 +0000
Subject: [Rd] Installation of RGtk2 (PR#10519)
In-Reply-To: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
References: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
Message-ID: <1197905024.7815.46.camel@maitai.windows.ebi.ac.uk>

RGtk2 is a packages that is a wrapper for GTK+ GUI toolkit. GTK+ itself
is a large separate software package. I do not know if GTK+ is delivered
within the RGtk2, but I doubt it as the former is quite big (at least
with my own package that uses GTK, users need to install GTK
separately). Now on Windows you can install GTK runtime environment as
any other application by downloading it from here:
http://gladewin32.sf.net and running a Windows-standard installation.
The default installation should be fine. After you have GTK installed,
reinstall the RGtk2 package if it does not work automatically. 

Actually I just checked http://www.ggobi.org/rgtk2/ and it says that
indeed you need to install GTK separately.

Best,
Oleg

On Mon, 2007-12-17 at 15:00 +0100, caroline.keef at jbaconsulting.co.uk
wrote:
> Full_Name: Caroline Keef
> Version: 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.171.203.131)
> 
> 
> I have tried to install the package rggobi which if I'm right requires the
> package RGtk2 
> If I install RGtk2 using the install.packages (I used the UK (Bristol) mirror, I
> haven't tried any other mirror) within R and then use library(RGtk2) I get the
> following message box
> 
> "This application has failed to start because libtak-1.0-0.dll was not found. 
> Re-installing the application may fix this problem."
> 
> I click ok and the following is printed to the R console.
> 
> Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> [1] "PLEASE RESTART R BEFORE TRYING TO LOAD THE PACKAGE AGAIN"
> Error in .C("R_gtkInit", length(args), x = args, PACKAGE = "RGtk2") : 
>   C symbol name "R_gtkInit" not in DLL for package "RGtk2"
> In addition: Warning message:
> In fun(...) :
>   Failed to load RGtk2 dynamic library:Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error : .onLoad failed in 'loadNamespace' for 'RGtk2'
> Error: package/namespace load failed for 'RGtk2'
> 
> I've re-started R again and the same happened.  I've also tried downloading the
> RGtk2 zip files from the CRAN website and installing from a local zip file
> option which gave the same results.  I haven't tried re-installing R to get
> around this problem.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Dr Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +44-1223-494466


From P.Dalgaard at biostat.ku.dk  Mon Dec 17 16:26:25 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 17 Dec 2007 16:26:25 +0100
Subject: [Rd] Installation of RGtk2 (PR#10519)
In-Reply-To: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
References: <20071217140023.5B3152834170@mail.pubhealth.ku.dk>
Message-ID: <47669521.9010000@biostat.ku.dk>

caroline.keef at jbaconsulting.co.uk wrote:
> Full_Name: Caroline Keef
> Version: 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.171.203.131)
>
>
> I have tried to install the package rggobi which if I'm right requires the
> package RGtk2 
> If I install RGtk2 using the install.packages (I used the UK (Bristol) mirror, I
> haven't tried any other mirror) within R and then use library(RGtk2) I get the
> following message box
>
> "This application has failed to start because libtak-1.0-0.dll was not found. 
> Re-installing the application may fix this problem."
>
> I click ok and the following is printed to the R console.
>
> Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> [1] "PLEASE RESTART R BEFORE TRYING TO LOAD THE PACKAGE AGAIN"
> Error in .C("R_gtkInit", length(args), x = args, PACKAGE = "RGtk2") : 
>   C symbol name "R_gtkInit" not in DLL for package "RGtk2"
> In addition: Warning message:
> In fun(...) :
>   Failed to load RGtk2 dynamic library:Error in dyn.load(file, ...) : 
>   unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>   LoadLibrary failure:  The specified module could not be found.
>
>
> Error : .onLoad failed in 'loadNamespace' for 'RGtk2'
> Error: package/namespace load failed for 'RGtk2'
>
> I've re-started R again and the same happened.  I've also tried downloading the
> RGtk2 zip files from the CRAN website and installing from a local zip file
> option which gave the same results.  I haven't tried re-installing R to get
> around this problem.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   
This is a package problem, not an issue in R itself, hence you should
not use the bug report interface.

However, the error indicates reliance on an external library, which you
presumably haven't got, so retrying is not going to help anything. You
probably need to go to http://www.ggobi.org/rgtk2/ and follow the
instructions that start with "If you're on Windows..."

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Mon Dec 17 16:35:18 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 17 Dec 2007 16:35:18 +0100 (CET)
Subject: [Rd] Installation of RGtk2 (PR#10519)
Message-ID: <20071217153518.C5744283416B@mail.pubhealth.ku.dk>

This is not a bug, and not appropriate to R-bugs as it is about a 
contributed package.

>From http://cran.r-project.org/bin/windows/contrib/2.6/ReadMe you will see

   Package RGtk2 requires an installed version of Gtk2 with version
   number >= 2.10.11.

Now, so does GGobi and hence rggobi.  'Installed' includes ensuring they 
are on your path, so if GGobi works I would expect RGtk2 to.


On Mon, 17 Dec 2007, caroline.keef at jbaconsulting.co.uk wrote:

> Full_Name: Caroline Keef
> Version: 2.6.1
> OS: Windows XP
> Submission from: (NULL) (195.171.203.131)
>
>
> I have tried to install the package rggobi which if I'm right requires the
> package RGtk2
> If I install RGtk2 using the install.packages (I used the UK (Bristol) mirror, I
> haven't tried any other mirror) within R and then use library(RGtk2) I get the
> following message box
>
> "This application has failed to start because libtak-1.0-0.dll was not found.
> Re-installing the application may fix this problem."
>
> I click ok and the following is printed to the R console.
>
> Error in dyn.load(file, ...) :
>  unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>  LoadLibrary failure:  The specified module could not be found.
>
>
> [1] "PLEASE RESTART R BEFORE TRYING TO LOAD THE PACKAGE AGAIN"
> Error in .C("R_gtkInit", length(args), x = args, PACKAGE = "RGtk2") :
>  C symbol name "R_gtkInit" not in DLL for package "RGtk2"
> In addition: Warning message:
> In fun(...) :
>  Failed to load RGtk2 dynamic library:Error in dyn.load(file, ...) :
>  unable to load shared library
> 'C:/PROGRA~1/R/R-26~1.1/library/RGtk2/libs/RGtk2.dll':
>  LoadLibrary failure:  The specified module could not be found.
>
>
> Error : .onLoad failed in 'loadNamespace' for 'RGtk2'
> Error: package/namespace load failed for 'RGtk2'
>
> I've re-started R again and the same happened.  I've also tried downloading the
> RGtk2 zip files from the CRAN website and installing from a local zip file
> option which gave the same results.  I haven't tried re-installing R to get
> around this problem.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Mon Dec 17 17:47:53 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 17 Dec 2007 10:47:53 -0600
Subject: [Rd] The XO laptop from the One Laptop Per Child (OLPC) program
Message-ID: <40e66e0b0712170847u35d48813s95bf9f094e66cff@mail.gmail.com>

There was recently a question on the R-help list about the eee pc.  I
had a related question about the XO laptop from OLPC (laptop.org).
Has anyone looked at the development environment sufficiently to
determine if it would be possible to create an executable image for R?
 The laptop itself only supports Python, Javascript, etc. but it is
running a real Linux operating system.


From P.Dalgaard at biostat.ku.dk  Mon Dec 17 18:03:59 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 17 Dec 2007 18:03:59 +0100
Subject: [Rd] The XO laptop from the One Laptop Per Child (OLPC) program
In-Reply-To: <40e66e0b0712170847u35d48813s95bf9f094e66cff@mail.gmail.com>
References: <40e66e0b0712170847u35d48813s95bf9f094e66cff@mail.gmail.com>
Message-ID: <4766ABFF.5040006@biostat.ku.dk>

Douglas Bates wrote:
> There was recently a question on the R-help list about the eee pc.  I
> had a related question about the XO laptop from OLPC (laptop.org).
> Has anyone looked at the development environment sufficiently to
> determine if it would be possible to create an executable image for R?
>  The laptop itself only supports Python, Javascript, etc. but it is
> running a real Linux operating system.
>
>   
It is Fedora based and x86 compatible, so it could be as simple as "yum
install R".
The potential pitfall is if that pulls in so many dependencies that you
overflow the 1GB solid-state disk.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tplate at acm.org  Mon Dec 17 18:34:50 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 17 Dec 2007 10:34:50 -0700
Subject: [Rd] Wrong length of POSIXt vectors (PR#10507)
In-Reply-To: <xmrejdlxsl8.fsf@mralx1.rsma.frb.gov>
References: <20071211112025.811162834156@mail.pubhealth.ku.dk>	<475FF376.8080806@stats.uwo.ca>
	<47618124.7060504@acm.org>	<47618A54.3060900@stats.uwo.ca>
	<4762EE76.9070401@acm.org>	<18276.21133.818619.889393@ada-stat.math.ethz.ch>	<47653917.9090905@stats.uwo.ca>
	<xmrejdlxsl8.fsf@mralx1.rsma.frb.gov>
Message-ID: <4766B33A.5030004@acm.org>

Jeffrey J. Hallman wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>
>   
>> One reason I don't want to work on this is because the appropriate 
>> action depends on what "length(x)" is intended to mean.  Currently for 
>> POSIXlt objects, it gives the physical length of the underlying basic 
>> type (the list).  This is the same behaviour as we have for matrices, 
>> data frames and every other object without a specific length method, so 
>> it's not outrageous.
>>
>> The proposed change is to have it return the logical length of the 
>> object, which also seems quite reasonable.  I don't think matrices and 
>> data frames have a "logical length", so there would be no contradiction 
>> in those examples.  The thing that worries me is that there are probably 
>> objects in packages where both logical length and physical length make 
>> sense but are different.  I don't have any expectation that length(x) on 
>> those currently is consistent in which type of value it returns.
>>
>> If we were to decide that "length(x)" *always* meant logical length, 
>> then we would have a problem:  matrices and data frames don't have a 
>> logical length, so we shouldn't be getting an answer there.  Changing 
>> length(x) for those is not acceptable.
>>
>> On the other hand, if we decide that "length(x)" *always* means physical 
>> length, we don't need to do anything to the POSIXlt or matrices or data 
>> frames, but there may well be other kinds of objects out there that 
>> violate this rule.
>>
>> We could leave the meaning of length(x) ambiguous.  If you want to know 
>> what it does for a POSIXlt object, you need to read the documentation or 
>> look at the source code.  As a policy, this isn't particularly 
>> appealing, but I could probably live with it if someone else did the 
>> research and showed that current usage is ambiguous.
>>     
>
> Physical length and logical length are, as you say, two different things.  So
> why not two functions?  Keep length() for physical length, as it is now, and
> maybe Length() for logical length.  The latter could be defined as
>
> Length <- function(x, ...) UseMethod("Length")
>
> Length.default <- function(x, ...) length(x)
>
> and then add methods for classes that want something else.
>   
A very reasonable suggestion, but I'd also put this in the "next time we 
design a language" category.

The current system in R seems workable to me, if one knows that 
vector-like classes that have a S3 list-based implementation need to 
have methods defined for 'c', 'length', '[', etc, and that if these 
methods aren't defined, then you'll be operating on the underlying list 
structure.  Where these methods are defined, one can get at the 
underlying structure by unclassing first, and that's OK.  However, 
classes that have some of these methods defined but not others seem to 
me to be needlessly confusing -- it's not like there any great benefit 
that length() always returns the length of the underlying list for 
POSIXlt -- if there was a length() method one could get at the 
underlying length using length(unclass(x)).  It just seems like a design 
oversight that makes using such classes unnecessarily difficult and 
error-prone.

Hence my proposal (in a new thread) for coding & documentation 
guidelines that would that would:
(1) suggest consistency is a good thing
(2) suggent compliance or deviation should be documented
(3) define what consistency was (and here it's not so important to get 
absolutely the right set of consistency definitions as it is to get a 
reasonable set that people agree on.)

-- Tony Plate


From edd at debian.org  Mon Dec 17 19:02:48 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Dec 2007 12:02:48 -0600
Subject: [Rd] The XO laptop from the One Laptop Per Child (OLPC) program
In-Reply-To: <4766ABFF.5040006@biostat.ku.dk>
References: <40e66e0b0712170847u35d48813s95bf9f094e66cff@mail.gmail.com>
	<4766ABFF.5040006@biostat.ku.dk>
Message-ID: <18278.47560.23727.568641@ron.nulle.part>


On 17 December 2007 at 18:03, Peter Dalgaard wrote:
| Douglas Bates wrote:
| > There was recently a question on the R-help list about the eee pc.  I
| > had a related question about the XO laptop from OLPC (laptop.org).
| > Has anyone looked at the development environment sufficiently to
| > determine if it would be possible to create an executable image for R?
| >  The laptop itself only supports Python, Javascript, etc. but it is
| > running a real Linux operating system.
| >
| >   
| It is Fedora based and x86 compatible, so it could be as simple as "yum
| install R".
| The potential pitfall is if that pulls in so many dependencies that you
| overflow the 1GB solid-state disk.

AFAIK you can emulate the "sugar" operating system used on the OLPC/XO on
Ubuntu and other Linux variants.  See
	http://wiki.laptop.org/go/Sugar_on_Ubuntu_Linux 
Maybe Doug can get Sugar running on his dvd player?

Dirk

-- 
Three out of two people have difficulties with fractions.


From droberts at montana.edu  Mon Dec 17 22:21:11 2007
From: droberts at montana.edu (Dave Roberts)
Date: Mon, 17 Dec 2007 14:21:11 -0700
Subject: [Rd] Fortran 90 and Windows
Message-ID: <4766E847.4060806@montana.edu>

I have been revising some FORTRAN 77 routines in R packages I have 
previously submitted.  Since R is now using gfortan I experimented with 
some Fortran 90 code (array intrinsics primarily).  So far the code is 
still in F77 fixed format, in files suffixed .f (not .f90), but 
incorporates some F90 constructs.  It has worked fine in linux/R.  I 
tried to follow the thread of previous discussions on this subject, but 
as fast as things are changing, it was somewhat dated, and not too 
definitive.

I don't so my own Windows versions of packages, but rather rely on CRAN 
to do the conversions, and I don't want to send them code that won't 
work on Windows.  Does anybody have extensive experience on what 
elements of F90 can be used in R packages for Windows?  If R CMD SHLIB 
is happy with it, is it likely to work?

Thanks, Dave
-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
David W. Roberts                                     office 406-994-4548
Professor and Head                                      FAX 406-994-3190
Department of Ecology                         email droberts at montana.edu
Montana State University
Bozeman, MT 59717-3460


From P.Dalgaard at biostat.ku.dk  Tue Dec 18 10:17:25 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 18 Dec 2007 10:17:25 +0100
Subject: [Rd] Fortran 90 and Windows
In-Reply-To: <4766E847.4060806@montana.edu>
References: <4766E847.4060806@montana.edu>
Message-ID: <47679025.7040208@biostat.ku.dk>

Dave Roberts wrote:
> I have been revising some FORTRAN 77 routines in R packages I have 
> previously submitted.  Since R is now using gfortan I experimented with 
> some Fortran 90 code (array intrinsics primarily).  So far the code is 
> still in F77 fixed format, in files suffixed .f (not .f90), but 
> incorporates some F90 constructs.  It has worked fine in linux/R.  I 
> tried to follow the thread of previous discussions on this subject, but 
> as fast as things are changing, it was somewhat dated, and not too 
> definitive.
>
> I don't so my own Windows versions of packages, but rather rely on CRAN 
> to do the conversions, and I don't want to send them code that won't 
> work on Windows.  Does anybody have extensive experience on what 
> elements of F90 can be used in R packages for Windows?  If R CMD SHLIB 
> is happy with it, is it likely to work?
>
> Thanks, Dave
>   
The Windows toolkit is also GCC, hence gfortran for new enough R. The
thing to worry about is the "other" category of machines. Either
oldish/specialized Unixes which ship with their own toolchains and
optimized libraries, or commercial compilers like the ones from Intel.
Brian Ripley and/or http://cran.r-project.org/doc/manuals/R-exts.html
can fill you in on the details. See also Brian's reply to John Fox on
December 9 ("I wouldn't let that deter you.").

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue Dec 18 10:37:25 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Dec 2007 09:37:25 +0000 (GMT)
Subject: [Rd] Fortran 90 and Windows
In-Reply-To: <4766E847.4060806@montana.edu>
References: <4766E847.4060806@montana.edu>
Message-ID: <Pine.LNX.4.64.0712180912470.7330@gannet.stats.ox.ac.uk>

On Mon, 17 Dec 2007, Dave Roberts wrote:

> I have been revising some FORTRAN 77 routines in R packages I have
> previously submitted.  Since R is now using gfortan I experimented with
> some Fortran 90 code (array intrinsics primarily).  So far the code is
> still in F77 fixed format, in files suffixed .f (not .f90), but
> incorporates some F90 constructs.  It has worked fine in linux/R.  I
> tried to follow the thread of previous discussions on this subject, but
> as fast as things are changing, it was somewhat dated, and not too
> definitive.

'Writing R Extensions' is both up-to-date and definitive, so please read 
the primary documentation.  In particular, we have strengthened the 
comments about not using Fortran I/O, which can cause severe problems when 
using the GUI version of R under Windows (although we now have a 
workaround).

> I don't so my own Windows versions of packages, but rather rely on CRAN
> to do the conversions, and I don't want to send them code that won't
> work on Windows.  Does anybody have extensive experience on what
> elements of F90 can be used in R packages for Windows?  If R CMD SHLIB
> is happy with it, is it likely to work?

Since Windows' builds nowadays use gcc 4.2.1, if it works on your 
unspecified version of gfortran on Linux it will very likely work on 
Windows.  And you can check that for yourself via 
win-builder.r-project.org.

However, using F9x code suffixed .f is not portable, and there are 
plenty of other systems where it will fail, some of which would accept 
.f90 or .f95 extensions.

See also my reply to John Fox:

https://stat.ethz.ch/pipermail/r-devel/2007-December/047695.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Dec 18 10:42:25 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Dec 2007 10:42:25 +0100
Subject: [Rd] help files for load and related functions
In-Reply-To: <47668980.5070001@stats.uwo.ca>
References: <476656E0.1000307@pburns.seanet.com>
	<1197900373.7815.37.camel@maitai.windows.ebi.ac.uk>
	<47668980.5070001@stats.uwo.ca>
Message-ID: <18279.38401.52281.473018@stat.math.ethz.ch>

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 17 Dec 2007 09:36:48 -0500 writes:

    DM> On 12/17/2007 9:06 AM, Oleg Sklyar wrote:
    >> Dear Patrick,
    >> 
    >> ?Firstly, and most importantly, I do not think that your post qualified
    >> for Rd! Please use the correct mail list for such things: R-help. I do
    >> not think anybody on Rd wants mailboxes ?clogged with irrelevant
    >> messages.

 { Oleg, you may have to be told that Pat Burns has been
   acquainted with the S language for a very long time, maybe
   about as long as you know to read... } 

    DM> Since Patrick's message was about changes to the documentation, I think 
    DM> it is relevant to this list.

yes indeed!
And the technicality of the discussion further down
is another good reason.

    DM> Duncan Murdoch

    >> Back to your question: it is not clear if you are confused, or your
    >> 'user' is confused, but all three help pages look pretty clear and
    >> straight forward to me. Moreover,  I do not see any connection between
    >> attach and library, which you find logical:
    >> 
    >> - load - the general use of this one is to load external data sets, e.g.
    >> load serialised R object(s) (as the example shows). Until you load, you
    >> cannot use the object as it has no relation to the R session and can be
    >> e.g. a file sitting somewhere on a network
    >> 
    >> - attach - the general use of this one would be to access elements of a
    >> data set directly, without the data set name specifier and the accessor
    >> operator, such as $, thus as the help page states - it is used to add
    >> the data set to the search path (as the example shows). If you look at
    >> the example, you do not have to call attach to be able to use data, data
    >> could have existed there before and what you effectively get with attach
    >> is a more convenient way of dealing with the data
    >> 
    >> - library - is used to load *and* attach an R package, which is not
    >> exactly the same as a serialised R object(s), but a full set of other
    >> functionality. Attaching packages is just a part of the loading process,
    >> which occurs basically when the package becomes visible to the user.
    >> Same as with load, you cannot use the package until you load it. There
    >> is not a hint of similarity between loading a package and attaching a
    >> data set as I see it. 

Hmm, I think there is, ..... and there's more :

The function load() is well known for loading R objects into the
global environment; well known, easy to understand.  However, it
can load into any other environment; and environments are the
crucial entities here.
BUT  when talking about loading in the context of R packages *and*
namespaces (!), there are other things:

One important point I think was not mentioned yet, and is probably *the*
reason of potential confusion of useRs and even programmeRs: here

  library(<package>)  does conceptually two things

  1) it *loads* the (exported) objects from the installed package
      (or with lazy-loading just loads "stubs") into a new environment.
  2) it "attaches" the names of those objects to the search() path

where things happen a bit differently for namespaced and other
packages.
For namespaced packages the two steps are really nicely
separable on a user level:  I hope you've known
loadNamespace(), unloadNamespace(), attachNamespace() and the
fact that e.g. cluster::pam() loads cluster's package namespace 
but does not attach cluster to search().

 { If you want to delve and hence to look at the library()
   function, please do so in the sources, e.g.,
      https://svn.r-project.org/R/trunk/src/library/base/R/library.R
   which has many comments that are all gone in the 'library' function object.
 }

I'd say: Because the loading part is the more delicate one than the
attach one, help(library) talks more about loading the package
than attaching..

Regards, Martin

    >> Regards,
    >> Oleg
    >> 
    >> On Mon, 2007-12-17 at 11:00 +0000, Patrick Burns wrote:
    >>> I recently had a discussion with a user about loading
    >>> and attaching in R.  I was surprised that the help files
    >>> don't  provide a very clear picture.
    >>> 
    >>> From my point of view 'load' and 'attach' are very
    >>> similar operations, the difference being that 'attach'
    >>> creates a new database on the search list while 'load'
    >>> puts all the objects into the global environment.
    >>> 
    >>> The help file for 'load' is inexplicit that this is what
    >>> happens.  The 'load' and 'attach' help files neither refer
    >>> to the other in their See Also.
    >>> 
    >>> Furthermore, the 'library' help file talks about "loading"
    >>> packages.  I would suggest that it should use "attaching"
    >>> as that is the analogous operation.
    >>> 
    >>> None of these three help files (nor that of 'save') has a
    >>> Side Effects section.  Personally I think that all help files
    >>> should have a Side Effects section (to make it clear to
    >>> new users what side effects are and that they are not a
    >>> good thing for most functions to have).  I can understand
    >>> there could be another point of view on that.  However, I
    >>> definitely think that there should be a Side Effects section
    >>> in the help files of functions whose whole point is a side
    >>> effect.
    >>> 
    >>> Patrick Burns
    >>> patrick at burns-stat.com
    >>> +44 (0)20 8525 0696
    >>> http://www.burns-stat.com
    >>> (home of S Poetry and "A Guide for the Unwilling S User")
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel

    DM> ______________________________________________
    DM> R-devel at r-project.org mailing list
    DM> https://stat.ethz.ch/mailman/listinfo/r-devel


From r.hankin at noc.soton.ac.uk  Tue Dec 18 12:19:43 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 18 Dec 2007 11:19:43 +0000
Subject: [Rd] branch cuts of log() and sqrt()
Message-ID: <78F50691-10D6-4570-BAD0-18E48E3CEE4F@noc.soton.ac.uk>

Dear developers

Neither Math.Rd nor Log.Rd mention the branch cuts
that appear for complex arguments.  I think it's important
to include such information.

Please find following two context diffs for Log.Rd and Math.Rd.

[The pedants amongst us will observe that
both sqrt() and log() have a branch point at complex
infinity, which is not mentioned in the patch.  Comments
anyone?]



rksh




245-10:~/scratch/R-devel/src/library/base/man% diff -c  Log.Rd  
new_Log.Rd
*** Log.Rd      Fri Jul 27 16:51:42 2007
--- new_Log.Rd  Tue Dec 18 08:57:03 2007
***************
*** 66,71 ****
--- 66,75 ----
     \code{logb} is a wrapper for \code{log} for compatibility with  
S.  If
     (S3 or S4) methods are set for \code{log} they will be dispatched.
     Do not set S4 methods on \code{logb} itself.
+
+   For complex arguments, the branch cut is standard: there is a branch
+   point at zero and a cut along the negative real axis; continuity
+   is from above.
   }
   \section{S4 methods}{
     \code{exp}, \code{expm1}, \code{log}, \code{log10}, \code{log2} and
245-10:~/scratch/R-devel/src/library/base/man%




245-10:~/scratch/R-devel/src/library/base/man% diff -c  Math.Rd  
new_Math.Rd
*** Math.Rd     Fri Jul 27 16:51:44 2007
--- new_Math.Rd Tue Dec 18 09:01:35 2007
***************
*** 22,32 ****
   \details{
     These are generic functions: methods can be defined for them
     individually or via the \code{\link[base:groupGeneric]{Math}}
!   group generic.  For complex arguments (and the default method),  
\code{z},
!   \code{abs(z) == \link{Mod}(z)} and \code{sqrt(z) == z^0.5}.

     \code{abs(x)} returns an \code{\link{integer}} vector when \code 
{x} is
     \code{integer} or \code{\link{logical}}.
   }
   \section{S4 methods}{
     Both are S4 generic and members of the
--- 22,39 ----
   \details{
     These are generic functions: methods can be defined for them
     individually or via the \code{\link[base:groupGeneric]{Math}}
!   group generic.

     \code{abs(x)} returns an \code{\link{integer}} vector when \code 
{x} is
     \code{integer} or \code{\link{logical}}.
+
+   For complex arguments (and the default method), \code{z},
+   \code{abs(z) == \link{Mod}(z)} and \code{sqrt(z) == z^0.5}.
+
+   The branch cut of \code{sqrt()} is standard: there is a branch point
+   at zero and a cut along the negative real axis; continuity is from
+   above.
+
   }
   \section{S4 methods}{
     Both are S4 generic and members of the
245-10:~/scratch/R-devel/src/library/base/man%



--
Robin Hankin
Uncertainty Analyst and Neutral Theorist,
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From Matthias.Kohl at stamats.de  Tue Dec 18 17:06:26 2007
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Tue, 18 Dec 2007 17:06:26 +0100
Subject: [Rd] small bug in panel.cor in example for pairs?
Message-ID: <4767F002.80405@stamats.de>

Dear all,

in the Example section of pairs there is
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
    {
         usr <- par("usr"); on.exit(par(usr))
         par(usr = c(0, 1, 0, 1))
         r <- abs(cor(x, y))
         txt <- format(c(r, 0.123456789), digits=digits)[1]
         txt <- paste(prefix, txt, sep="")
         if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
         text(0.5, 0.5, txt, cex = cex * r)
     }

Shouldn't the last two lines read
         if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
         text(0.5, 0.5, txt, cex = cex.cor * r)
?

Best,
Matthias

--
Dr. Matthias Kohl
Mathematical Statistics
University of Bayreuth


From droberts at montana.edu  Tue Dec 18 17:43:47 2007
From: droberts at montana.edu (Dave Roberts)
Date: Tue, 18 Dec 2007 09:43:47 -0700
Subject: [Rd] Fortran 90 and Windows
In-Reply-To: <Pine.LNX.4.64.0712180912470.7330@gannet.stats.ox.ac.uk>
References: <4766E847.4060806@montana.edu>
	<Pine.LNX.4.64.0712180912470.7330@gannet.stats.ox.ac.uk>
Message-ID: <4767F8C3.30502@montana.edu>

Thank you kindly Professor Ripley, Peter Dalgaard and Jari Oksanen. 
Although I had searched for Fortran 90 in various R locations, I hadn't 
thought to search for Fortran 95, and so hadn't seen Professor Ripley's 
reply to John Fox.  I just joined this list yesterday, and saw the 
December archive just after posting.

As pointed out by Professor Ripley, my approach (Fortran 90 constructs 
in *.f files) relies on the idiosyncrasies of gcc and R CMD SHLIB, and 
is clearly not portable.  However, given that gcc is the engine of R, it 
seems almost worth the gamble.  Fortran 90 array intrinsics are almost 
like compiled S, and very compelling in some circumstances.

I was unaware of win-builder.r-project.org, and will certainly give that 
a shot.  On the other hand, if I hear from very old *nixes that my code 
won't work, I'll probably relent.

Again, thank you all, Dave

Prof Brian Ripley wrote:
> On Mon, 17 Dec 2007, Dave Roberts wrote:
> 
>> I have been revising some FORTRAN 77 routines in R packages I have
>> previously submitted.  Since R is now using gfortan I experimented with
>> some Fortran 90 code (array intrinsics primarily).  So far the code is
>> still in F77 fixed format, in files suffixed .f (not .f90), but
>> incorporates some F90 constructs.  It has worked fine in linux/R.  I
>> tried to follow the thread of previous discussions on this subject, but
>> as fast as things are changing, it was somewhat dated, and not too
>> definitive.
> 
> 'Writing R Extensions' is both up-to-date and definitive, so please read 
> the primary documentation.  In particular, we have strengthened the 
> comments about not using Fortran I/O, which can cause severe problems 
> when using the GUI version of R under Windows (although we now have a 
> workaround).
> 
>> I don't so my own Windows versions of packages, but rather rely on CRAN
>> to do the conversions, and I don't want to send them code that won't
>> work on Windows.  Does anybody have extensive experience on what
>> elements of F90 can be used in R packages for Windows?  If R CMD SHLIB
>> is happy with it, is it likely to work?
> 
> Since Windows' builds nowadays use gcc 4.2.1, if it works on your 
> unspecified version of gfortran on Linux it will very likely work on 
> Windows.  And you can check that for yourself via 
> win-builder.r-project.org.
> 
> However, using F9x code suffixed .f is not portable, and there are 
> plenty of other systems where it will fail, some of which would accept 
> .f90 or .f95 extensions.
> 
> See also my reply to John Fox:
> 
> https://stat.ethz.ch/pipermail/r-devel/2007-December/047695.html
> 


-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
David W. Roberts                                     office 406-994-4548
Professor and Head                                      FAX 406-994-3190
Department of Ecology                         email droberts at montana.edu
Montana State University
Bozeman, MT 59717-3460


From luke at stat.uiowa.edu  Tue Dec 18 19:00:14 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 18 Dec 2007 12:00:14 -0600 (CST)
Subject: [Rd] Improvement of SignRank functions
In-Reply-To: <18276.8363.639290.462401@ada-stat.math.ethz.ch>
References: <4762FDB9.1060603@iugrina.com>
	<18275.47774.724113.430936@ada-stat.math.ethz.ch>
	<4763D2E6.90301@iugrina.com>
	<18276.8363.639290.462401@ada-stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0712181159060.18642@nokomis.stat.uiowa.edu>

On Sat, 15 Dec 2007, Martin Maechler wrote:

> Hi Ivo,
>
>>>>>> "IU" == Ivo Ugrina <ivo at iugrina.com>
>>>>>>     on Sat, 15 Dec 2007 14:13:10 +0100 writes:
>
>    IU> Martin Maechler wrote:
>    >> do you have evidence for your belief?
>    >> i.e. a set of  system.time(.) calls where you see the
>    >> difference?
>
>    IU> system.time(dsignrank(17511, 400))
>    IU> user  system elapsed
>    IU> 1.010   0.120   1.145
>    IU> system.time(dsignrank((0:17511), 400))
>    IU> user  system elapsed
>    IU> 1.25    0.13    1.40
>    IU> system.time(dsignrank((0:17511), 500))
>    IU> user  system elapsed
>    IU> 2.040   0.220   2.296
>    IU> system.time(psignrank((0:17511), 600))
>    IU> user  system elapsed
>    IU> 20.670   0.580  21.403
>    IU> system.time(qsignrank(0.56, 300))
>    IU> user  system elapsed
>    IU> 0.700   0.050   0.753
>    IU> ======================================
>    IU> system.time(dsignrank(17511, 400))
>    IU> user  system elapsed
>    IU> 0.070   0.000   0.078
>    IU> system.time(dsignrank((0:17511), 400))
>    IU> user  system elapsed
>    IU> 0.100   0.000   0.104
>    IU> system.time(dsignrank((0:17511), 500))
>    IU> user  system elapsed
>    IU> 0.160   0.000   0.164
>    IU> system.time(psignrank((0:17511), 600))
>    IU> user  system elapsed
>    IU> 16.330   0.370  16.729
>    IU> system.time(qsignrank(0.56, 300))
>    IU> user  system elapsed
>    IU> 0.020   0.010   0.029
>
>
>
>    IU> system.time(dsignrank((0:20000), 600))
>    IU> user  system elapsed
>    IU> 3.470   0.280   3.745
>    IU> RAM: ~130MB
>    IU> ======================================
>    IU> system.time(dsignrank((0:20000), 600))
>    IU> user  system elapsed
>    IU> 0.250   0.010   0.26
>    IU> RAM: ~1MB
>
> that's quite convincing; thank you!
> and I can verify part of it on my computer.
>
> I think I'd just commit your signrank.c
> (with a few cosmetic changes) to the sources, right?
>
> *Not* using a static with all the previously computed counts
> is probably not possible without a (CPU time) efficiency loss;
> and to make this thread-safe one could use a "thread-global"
> array, but how to do that would really depend on the threading
> system used, and that's not at all given.

I'ts possible to handle this sort of thing with OpenMP, which is I
think the way we want to go, but it does require some care.

luke


>
> Thank you for your contribution!
> Martin
>
>
>
>    >> BTW: If you had a smart idea to *not* use a static 'w' and still
>    >> be memory efficient,
>    >> that could lead to make that code "thread-safe", but I am
>    >> not at all sure this is possible without using
>    >> "thread-library C code".
>
>    IU> I'll look into it.
>
>
>    IU> With respect,
>    IU> --
>    IU> Ivo Ugrina
>    IU> ICQ: 47508335 | www.iugrina.com
>    IU> -------------------------------
>    IU> baza matematickih pojmova
>    IU> http://baza.iugrina.com
>    IU> ---------------------------
>    IU> anime, manga, Japan fanzin
>    IU> http://yoshi.iugrina.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From p.murrell at auckland.ac.nz  Wed Dec 19 01:34:47 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 19 Dec 2007 13:34:47 +1300
Subject: [Rd] interactive graphics devices
Message-ID: <47686727.3040809@stat.auckland.ac.nz>

Hi

For all developers of add-on graphics devices:  please note the
existence of deviceIsInteractive() for adding your device to the list of
devices for which dev.interactive() returns TRUE.  (Available since R
2.6.0;  thanks to Brian Ripley I think)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From byron.ellis at gmail.com  Wed Dec 19 01:46:06 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Tue, 18 Dec 2007 16:46:06 -0800
Subject: [Rd] interactive graphics devices
In-Reply-To: <47686727.3040809@stat.auckland.ac.nz>
References: <47686727.3040809@stat.auckland.ac.nz>
Message-ID: <7098abec0712181646q2a97a3eey3b4fd60a11c607d1@mail.gmail.com>

I probably missed this discussion, but why not just ASK the device if
it is interactive? I can easily imagine a case where a device might be
interactive or not depending on how it was started. In fact, I don't
have to imagine a case since the Quartz device in R-devel can have
exactly this behavior. Something like a Cairo device might also have
this behavior, though I don't know if the current Cairo devices
support it.

On Dec 18, 2007 4:34 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
> For all developers of add-on graphics devices:  please note the
> existence of deviceIsInteractive() for adding your device to the list of
> devices for which dev.interactive() returns TRUE.  (Available since R
> 2.6.0;  thanks to Brian Ripley I think)
>
> Paul
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From deepayan.sarkar at gmail.com  Wed Dec 19 01:56:54 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 18 Dec 2007 16:56:54 -0800
Subject: [Rd] interactive graphics devices
In-Reply-To: <7098abec0712181646q2a97a3eey3b4fd60a11c607d1@mail.gmail.com>
References: <47686727.3040809@stat.auckland.ac.nz>
	<7098abec0712181646q2a97a3eey3b4fd60a11c607d1@mail.gmail.com>
Message-ID: <eb555e660712181656u94dafabub690a5dc6c7b2dc9@mail.gmail.com>

On 12/18/07, Byron Ellis <byron.ellis at gmail.com> wrote:
> I probably missed this discussion, but why not just ASK the device if
> it is interactive?

That's done if the device is open. deviceIsInteractive() takes away
the guessing even when it's not (the use-case is when you type
example(something) without a device open, and R has to decide whether
to set par(ask = TRUE) just by looking at getOption("device")).

> I can easily imagine a case where a device might be
> interactive or not depending on how it was started. In fact, I don't
> have to imagine a case since the Quartz device in R-devel can have
> exactly this behavior. Something like a Cairo device might also have
> this behavior, though I don't know if the current Cairo devices
> support it.

If there's ambiguity, you can choose not to use deviceIsInteractive.
You'll still be OK once the device is open (I don't think there's much
more that can be done).

-Deepayan


> On Dec 18, 2007 4:34 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> > Hi
> >
> > For all developers of add-on graphics devices:  please note the
> > existence of deviceIsInteractive() for adding your device to the list of
> > devices for which dev.interactive() returns TRUE.  (Available since R
> > 2.6.0;  thanks to Brian Ripley I think)
> >
> > Paul
> > --
> > Dr Paul Murrell
> > Department of Statistics
> > The University of Auckland
> > Private Bag 92019
> > Auckland
> > New Zealand
> > 64 9 3737599 x85392
> > paul at stat.auckland.ac.nz
> > http://www.stat.auckland.ac.nz/~paul/
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>
> --
> Byron Ellis (byron.ellis at gmail.com)
> "Oook" -- The Librarian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Wed Dec 19 02:03:40 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 18 Dec 2007 19:03:40 -0600
Subject: [Rd] available.packages() not accurate?
Message-ID: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>

> pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> pkgs["sn", c("Package", "Version")]

But looking at http://cran.r-project.org/src/contrib/ only sn_0.4-2 is
available.  Any ideas?

Thanks,

Hadley

-- 
http://had.co.nz/


From deepayan.sarkar at gmail.com  Wed Dec 19 02:18:14 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 18 Dec 2007 17:18:14 -0800
Subject: [Rd] available.packages() not accurate?
In-Reply-To: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>
References: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>
Message-ID: <eb555e660712181718k29288293g2dc8043f05a2eabf@mail.gmail.com>

On 12/18/07, hadley wickham <h.wickham at gmail.com> wrote:
> > pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> > pkgs["sn", c("Package", "Version")]
>
> But looking at http://cran.r-project.org/src/contrib/ only sn_0.4-2 is
> available.  Any ideas?

I see 0.4-4. Could be a caching problem on your browser.

-Deepayan


From h.wickham at gmail.com  Wed Dec 19 02:31:16 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 18 Dec 2007 19:31:16 -0600
Subject: [Rd] available.packages() not accurate?
In-Reply-To: <eb555e660712181718k29288293g2dc8043f05a2eabf@mail.gmail.com>
References: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>
	<eb555e660712181718k29288293g2dc8043f05a2eabf@mail.gmail.com>
Message-ID: <f8e6ff050712181731h5998da15h4a5593be74af129d@mail.gmail.com>

On 12/18/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 12/18/07, hadley wickham <h.wickham at gmail.com> wrote:
> > > pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> > > pkgs["sn", c("Package", "Version")]
> >
> > But looking at http://cran.r-project.org/src/contrib/ only sn_0.4-2 is
> > available.  Any ideas?
>
> I see 0.4-4. Could be a caching problem on your browser.

Oh sorry - I explained it the wrong way around - available.packages
lists 0.4-2 as the latest version, but 0.4-4 is available from
src/contrib.  The following packages also have a version mismatch
between available.packages and CRAN:

GOSim (1.0.2), GammaTest (2.1), InfNet (0.1), RcppTemplate (5.2),
SNPassoc (1.4-8), StoppingRules (1.1), actuar (0.9-3), ape (2.0-1),
bcp (1.7.2), dtw (0.3-1), edci (1.0-1), gstat (0.9-40), kappalab
(0.4-0), mlegp (1.1), polycor (0.7-3), pwt (6.1-1), rcompletion
(0.1-2), relaimpo (1.2-2), roblm (0.6), seewave (1.4.3), sfsmisc
(0.95-13)

Hadley


-- 
http://had.co.nz/


From deepayan.sarkar at gmail.com  Wed Dec 19 03:00:56 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 18 Dec 2007 18:00:56 -0800
Subject: [Rd] available.packages() not accurate?
In-Reply-To: <f8e6ff050712181731h5998da15h4a5593be74af129d@mail.gmail.com>
References: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>
	<eb555e660712181718k29288293g2dc8043f05a2eabf@mail.gmail.com>
	<f8e6ff050712181731h5998da15h4a5593be74af129d@mail.gmail.com>
Message-ID: <eb555e660712181800y2765a6f5k487cd89044b0340f@mail.gmail.com>

On 12/18/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 12/18/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> > On 12/18/07, hadley wickham <h.wickham at gmail.com> wrote:
> > > > pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> > > > pkgs["sn", c("Package", "Version")]
> > >
> > > But looking at http://cran.r-project.org/src/contrib/ only sn_0.4-2 is
> > > available.  Any ideas?
> >
> > I see 0.4-4. Could be a caching problem on your browser.
>
> Oh sorry - I explained it the wrong way around - available.packages
> lists 0.4-2 as the latest version, but 0.4-4 is available from
> src/contrib.  The following packages also have a version mismatch
> between available.packages and CRAN:
>
> GOSim (1.0.2), GammaTest (2.1), InfNet (0.1), RcppTemplate (5.2),
> SNPassoc (1.4-8), StoppingRules (1.1), actuar (0.9-3), ape (2.0-1),
> bcp (1.7.2), dtw (0.3-1), edci (1.0-1), gstat (0.9-40), kappalab
> (0.4-0), mlegp (1.1), polycor (0.7-3), pwt (6.1-1), rcompletion
> (0.1-2), relaimpo (1.2-2), roblm (0.6), seewave (1.4.3), sfsmisc
> (0.95-13)

I see

> pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> pkgs[c("sn", "GOSim", "GammaTest"), c("Package", "Version")]
      Package Version
sn         sn   0.4-4
GOSim   GOSim   1.1.2
NA       <NA>    <NA>

which match CRAN (which doesn't have GammaTest). So not sure what's going on.

-Deepayan


From h.wickham at gmail.com  Wed Dec 19 03:42:42 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 18 Dec 2007 20:42:42 -0600
Subject: [Rd] available.packages() not accurate?
In-Reply-To: <eb555e660712181800y2765a6f5k487cd89044b0340f@mail.gmail.com>
References: <f8e6ff050712181703s4827b126pff8d93958d7b9706@mail.gmail.com>
	<eb555e660712181718k29288293g2dc8043f05a2eabf@mail.gmail.com>
	<f8e6ff050712181731h5998da15h4a5593be74af129d@mail.gmail.com>
	<eb555e660712181800y2765a6f5k487cd89044b0340f@mail.gmail.com>
Message-ID: <f8e6ff050712181842g3c261350w452149526efefcd8@mail.gmail.com>

> > pkgs <- as.data.frame(available.packages(contrib.url("http://cran.r-project.org")))
> > pkgs[c("sn", "GOSim", "GammaTest"), c("Package", "Version")]
>       Package Version
> sn         sn   0.4-4
> GOSim   GOSim   1.1.2
> NA       <NA>    <NA>
>
> which match CRAN (which doesn't have GammaTest). So not sure what's going on.

I just figured it out:

> contrib.url(contrib.url("http://cran.r-project.org"))
[1] "http://cran.r-project.org/bin/macosx/universal/contrib/2.6/bin/macosx/universal/contrib/2.6"
> contrib.url("http://cran.r-project.org", type="source")
[1] "http://cran.r-project.org/src/contrib"

Oops - thanks for the help.

Hadley


-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Wed Dec 19 06:35:13 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2007 05:35:13 +0000 (GMT)
Subject: [Rd] interactive graphics devices
In-Reply-To: <7098abec0712181646q2a97a3eey3b4fd60a11c607d1@mail.gmail.com>
References: <47686727.3040809@stat.auckland.ac.nz>
	<7098abec0712181646q2a97a3eey3b4fd60a11c607d1@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712190527190.9107@gannet.stats.ox.ac.uk>

On Tue, 18 Dec 2007, Byron Ellis wrote:

> I probably missed this discussion, but why not just ASK the device if
> it is interactive? I can easily imagine a case where a device might be
> interactive or not depending on how it was started. In fact, I don't
> have to imagine a case since the Quartz device in R-devel can have
> exactly this behavior. Something like a Cairo device might also have
> this behavior, though I don't know if the current Cairo devices
> support it.

You cannot ASK a device you have not yet opened: see the 'orNone' 
argument to dev.interactive().  Beyond that, there is nothing in the 
graphics device API to ask an open device.

There are two Cairo devices in two packages and they behave differently: 
that makes it rather difficult to determine the behaviour by name.

> On Dec 18, 2007 4:34 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
>> Hi
>>
>> For all developers of add-on graphics devices:  please note the
>> existence of deviceIsInteractive() for adding your device to the list of
>> devices for which dev.interactive() returns TRUE.  (Available since R
>> 2.6.0;  thanks to Brian Ripley I think)

And Deepayan Sarkar.

>> Paul
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Dec 19 07:20:14 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 19 Dec 2007 07:20:14 +0100 (CET)
Subject: [Rd] bug in by.data.frame, R-2.6.1 (PR#10506)
Message-ID: <20071219062014.69DAF282EF48@mail.pubhealth.ku.dk>

It transpires that package survey relies on the current behaviour (which 
is not new in 2.6.1: R 2.0.0 did it).

The suggested fix is reasonable if 'data' was originally a data frame, but 
the default method promotes vectors to data frames, and the data frame 
method used to drop them back to vectors.

I've backed the fix out of R-patched.

I am not sure if the current undocumented behaviour on vectors is 
100% desirable, but will amend by.default in R-devel to preserve it.

Thomas: I think svymean() needs not to assume that 1-column data frames 
will be dropped.


On Mon, 10 Dec 2007, ligges at statistik.uni-dortmund.de wrote:

> by() fails for 1-column matrices and dataframes:
>
> X <- data.frame(a=1:10)
> g <- gl(2,5)
> by(X, g, colMeans)
>
>
> Suggested fix:
>
> --- by-old.R    2007-12-10 15:26:22.501086600 +0100
> +++ by.R        2007-12-10 15:25:58.390477200 +0100
> @@ -26,7 +26,7 @@
>          IND[[1]] <- INDICES
>          names(IND) <- deparse(substitute(INDICES))[1]
>      } else IND <- INDICES
> -    FUNx <- function(x) FUN(data[x,], ...)
> +    FUNx <- function(x) FUN(data[x, , drop=FALSE], ...)
>      nd <- nrow(data)
>      ans <- eval(substitute(tapply(1:nd, IND, FUNx)), data)
>      attr(ans, "call") <- match.call()
>
>
>
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          6.1
> year           2007
> month          11
> day            26
> svn rev        43537
> language       R
> version.string R version 2.6.1 (2007-11-26)
>
>
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m.zamboni at email.it  Tue Dec 18 16:35:23 2007
From: m.zamboni at email.it (m.zamboni at email.it)
Date: Tue, 18 Dec 2007 16:35:23 +0100 (CET)
Subject: [Rd] bug in r-base (PR#10521)
Message-ID: <20071218153523.47F472834612@mail.pubhealth.ku.dk>

Full_Name: marco zamboni
Version: no R version
OS: ubuntu gusty
Submission from: (NULL) (87.9.174.188)


I have just finish to install gusty ubuntu on my AMD sempron. 
I would like to:
$ sudo apt-get install r-base

but
...
 I seguenti pacchetti hanno dipendenze non soddisfatte:
  r-base: Dipende: r-base-core (>= 2.6.1-1gutsy0) ma 2.5.1-1 sta per essere
installato
          Dipende: r-recommended (= 2.6.1-1gutsy0) ma non sta per essere
installato
E: Pacchetto non integro


thanks
marco zamboni


From vogranovich at jumptrading.com  Tue Dec 18 18:38:20 2007
From: vogranovich at jumptrading.com (Vadim Ogranovich)
Date: Tue, 18 Dec 2007 11:38:20 -0600 (CST)
Subject: [Rd] Rscript thank you
Message-ID: <4045270.10681197999500059.JavaMail.root@jumpmail1.w2k.jumptrading.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071218/d76323d1/attachment.pl 

From vincent.goulet at act.ulaval.ca  Wed Dec 19 16:32:46 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Wed, 19 Dec 2007 10:32:46 -0500
Subject: [Rd] bug in r-base (PR#10521)
In-Reply-To: <20071218153523.47F472834612@mail.pubhealth.ku.dk>
References: <20071218153523.47F472834612@mail.pubhealth.ku.dk>
Message-ID: <B516B72E-2728-4CA1-8202-1D92973094DB@act.ulaval.ca>

[Moved from r-devel]

Le mar. 18 d?c. ? 10:35, m.zamboni at email.it a ?crit :

> Full_Name: marco zamboni
> Version: no R version
> OS: ubuntu gusty
> Submission from: (NULL) (87.9.174.188)
>
>
> I have just finish to install gusty ubuntu on my AMD sempron.
> I would like to:
> $ sudo apt-get install r-base
>
> but
> ...
> I seguenti pacchetti hanno dipendenze non soddisfatte:
>  r-base: Dipende: r-base-core (>= 2.6.1-1gutsy0) ma 2.5.1-1 sta per  
> essere
> installato
>          Dipende: r-recommended (= 2.6.1-1gutsy0) ma non sta per  
> essere
> installato
> E: Pacchetto non integro

First, this is not a bug with R at all; only a difficulty you have  
with installing the r-base package.

Second, this does not belong to r-devel, but to r-sig-debian. Hence  
the discussion is moved to the latter forum.

Now, did you follow the instructions in the Ubuntu README at

	http://cran.r-project.org/bin/linux/ubuntu/

? What is the result of

	apt-cache policy r-base

?

We should be able to help you with this information.

Best,

---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From hin-tak.leung at cimr.cam.ac.uk  Wed Dec 19 18:49:35 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 19 Dec 2007 17:49:35 +0000
Subject: [Rd] R installer
In-Reply-To: <B4953A4B-5867-47D2-9AAF-A53BE9E76995@r-project.org>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
	<475608BF.3000607@cimr.cam.ac.uk>
	<B4953A4B-5867-47D2-9AAF-A53BE9E76995@r-project.org>
Message-ID: <476959AF.2070606@cimr.cam.ac.uk>

Simon Urbanek wrote:
<snipped>
>> If I were an Apple user (which I am not), there is a chance that I 
>> might have my own gcc/gfortran in /usr/local and I surely do not want 
>> R to temper with them. If you need runtime libgfortran support, you 
>> should just bundle gfortran.so and gcc.so if necesary (there are 
>> static alternatives), and put those in R's area.
>>
> 
> That's exactly what we do. Apparently you didn't bother to read my 
> e-mail (the part you "snipped") or to look at the installer. Please do 
> your homework before posting wild (and false) speculations.
<snipped>

Yes and no... I think if you have to bundle gfortran.so and gcc_s.so,
you should put them in 
/Library/Frameworks/R.framework/Versions/Current/Resources/lib ?
Why is /usr/local/* touched at all?

I am actually at this moment sitting in front of a mac (on a public 
university shared computer room) which has gfortran 4.2.0 20070525 
(prerelease) in /usr/local/bin and  gcc_s.* and libgfortran* in
/usr/local/lib and /Library/.../R.../lib are different. (which IMHO is
the right way to do it).

HTL


From simon.urbanek at r-project.org  Wed Dec 19 19:02:11 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 19 Dec 2007 13:02:11 -0500
Subject: [Rd] R installer
In-Reply-To: <476959AF.2070606@cimr.cam.ac.uk>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
	<475608BF.3000607@cimr.cam.ac.uk>
	<B4953A4B-5867-47D2-9AAF-A53BE9E76995@r-project.org>
	<476959AF.2070606@cimr.cam.ac.uk>
Message-ID: <2C80AE55-5926-4B2C-A607-1DDD3B228FFD@r-project.org>


On Dec 19, 2007, at 12:49 PM, Hin-Tak Leung wrote:

> Simon Urbanek wrote:
> <snipped>
>>> If I were an Apple user (which I am not), there is a chance that I  
>>> might have my own gcc/gfortran in /usr/local and I surely do not  
>>> want R to temper with them. If you need runtime libgfortran  
>>> support, you should just bundle gfortran.so and gcc.so if necesary  
>>> (there are static alternatives), and put those in R's area.
>>>
>> That's exactly what we do. Apparently you didn't bother to read my  
>> e-mail (the part you "snipped") or to look at the installer. Please  
>> do your homework before posting wild (and false) speculations.
> <snipped>
>
> Yes and no... I think if you have to bundle gfortran.so and  
> gcc_s.so, you should put them in /Library/Frameworks/R.framework/ 
> Versions/Current/Resources/lib ?

*sigh* - that's what we do (it's libgfortran.dylib by the way) and  
that's what I'm trying to tell you all the time and you keep ignoring  
it ...


> Why is /usr/local/* touched at all?
>

It's not ... at least not for R.


> I am actually at this moment sitting in front of a mac (on a public  
> university shared computer room) which has gfortran 4.2.0 20070525  
> (prerelease) in /usr/local/bin

Quite old one, but well ... ;)


> and  gcc_s.* and libgfortran* in/usr/local/lib and /Library/.../R.../ 
> lib are different. (which IMHO is the right way to do it).
>

And that's what the R installer does - it ships with whatever version  
was used to build R ... That could be more recent that your gfortran  
(if you have one).

Cheers,
Simon


From hin-tak.leung at cimr.cam.ac.uk  Wed Dec 19 20:16:11 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 19 Dec 2007 19:16:11 +0000
Subject: [Rd] R installer
In-Reply-To: <2C80AE55-5926-4B2C-A607-1DDD3B228FFD@r-project.org>
References: <20071128215522.AF9F42834155@mail.pubhealth.ku.dk>	<FA8783E7-C438-4DCC-B5AA-A1F55BE5C3B5@r-project.org>	<DFEB308E-090E-49D0-97D7-72C8994BAA94@cs.st-andrews.ac.uk>	<2D5435B7-0B47-4603-9209-8259252F77B4@r-project.org>
	<31D76F0C-C569-4247-8834-7EB675F15055@cs.st-andrews.ac.uk>
	<47547913.8080602@cimr.cam.ac.uk>
	<073AF4D2-A29D-4C94-88F3-FF9BF8300BC1@r-project.org>
	<475608BF.3000607@cimr.cam.ac.uk>
	<B4953A4B-5867-47D2-9AAF-A53BE9E76995@r-project.org>
	<476959AF.2070606@cimr.cam.ac.uk>
	<2C80AE55-5926-4B2C-A607-1DDD3B228FFD@r-project.org>
Message-ID: <47696DFB.2080800@cimr.cam.ac.uk>

Simon Urbanek wrote:
> 
> On Dec 19, 2007, at 12:49 PM, Hin-Tak Leung wrote:
> 
>> Simon Urbanek wrote:
>> <snipped>
>>>> If I were an Apple user (which I am not), there is a chance that I 
>>>> might have my own gcc/gfortran in /usr/local and I surely do not 
>>>> want R to temper with them. If you need runtime libgfortran support, 
>>>> you should just bundle gfortran.so and gcc.so if necesary (there are 
>>>> static alternatives), and put those in R's area.
>>>>
>>> That's exactly what we do. Apparently you didn't bother to read my 
>>> e-mail (the part you "snipped") or to look at the installer. Please 
>>> do your homework before posting wild (and false) speculations.
>> <snipped>
>>
>> Yes and no... I think if you have to bundle gfortran.so and gcc_s.so, 
>> you should put them in 
>> /Library/Frameworks/R.framework/Versions/Current/Resources/lib ?
> 
> *sigh* - that's what we do (it's libgfortran.dylib by the way) and 
> that's what I'm trying to tell you all the time and you keep ignoring it 
> ...
<snipped>

apologies then... (crawling back to my hole sheepishly...) the installer 
error message was very confusing...

HTL


From mark_komarinski at hms.harvard.edu  Wed Dec 19 21:19:05 2007
From: mark_komarinski at hms.harvard.edu (Mark Komarinski)
Date: Wed, 19 Dec 2007 15:19:05 -0500
Subject: [Rd] Problem compiling R 3.6.1 on POWER 570 system
Message-ID: <47697CB9.5020407@hms.harvard.edu>

I've for a RHEL 4 box on a P570 system.  My end user wants to have a 
64-bit version of R compiled due to the large amount of memory they 
require (this image has 16GB allocated to it).

I can compile R fine in 32-bit mode, but it can't use more than 2.4GB of 
RAM before it falls over and dies.

Compiling in 64-bit mode for POWER systems "should" be as easy as adding 
a CFLAGS="-m64" FFLAGS="-m64" ./configure --without-x .

It's not, and unfortunately I'm at a loss to what the problem is. 
Here's the last few lines of the above configure command:

checking for Fortran 77 libraries of g77...  -L/usr/local/lib64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64 
-L/usr/lib/../lib64 -lfrtbegin -lg2c -lm -lgcc_s_64
checking how to get verbose linking output from gcc -std=gnu99... -v
checking for C libraries of gcc -std=gnu99...  -L/usr/local/lib64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64 
-L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64 
-L/usr/lib/../lib64 -lgcc_s_64
checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... lower case, underscore, 
extra underscore
checking whether g77 appends underscores to external names... yes
checking whether g77 appends extra underscores to external names... yes
checking whether mixed C/Fortran code can be run... configure: WARNING: 
cannot run mixed C/Fortran code
configure: error: Maybe check LDFLAGS for paths to Fortran libraries?

Here's what looks to be the relevant part from config.log:
configure:32383: checking whether mixed C/Fortran code can be run
/usr/bin/ld: skipping incompatible 
/usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for 
-lgcc_s_64
/usr/bin/ld: skipping incompatible 
/usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for 
-lgcc_s_64
/usr/bin/ld: cannot find -lgcc_s_64
collect2: ld returned 1 exit status
configure:32447: WARNING: cannot run mixed C/Fortran code
configure:32449: error: Maybe check LDFLAGS for paths to Fortran libraries?

This implies that configure is compiling the code in 32 bit mode (which 
is why it's skipping libgcc_s_64.o

I guess my questions are: has anyone compiled this for this system?  And 
if so, how did you do it?

-Mark

-- 
Mark Komarinski				mark_komarinski at hms.harvard.edu
Sr. Research Systems Architect		http://ritg.med.harvard.edu
Research IT Group
Harvard Medical School


From ripley at stats.ox.ac.uk  Wed Dec 19 22:17:43 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2007 21:17:43 +0000 (GMT)
Subject: [Rd] Problem compiling R 3.6.1 on POWER 570 system
In-Reply-To: <47697CB9.5020407@hms.harvard.edu>
References: <47697CB9.5020407@hms.harvard.edu>
Message-ID: <Pine.LNX.4.64.0712192110590.10535@gannet.stats.ox.ac.uk>

On Wed, 19 Dec 2007, Mark Komarinski wrote:

> I've for a RHEL 4 box on a P570 system.  My end user wants to have a
> 64-bit version of R compiled due to the large amount of memory they
> require (this image has 16GB allocated to it).
>
> I can compile R fine in 32-bit mode, but it can't use more than 2.4GB of
> RAM before it falls over and dies.
>
> Compiling in 64-bit mode for POWER systems "should" be as easy as adding
> a CFLAGS="-m64" FFLAGS="-m64" ./configure --without-x .

The R-admin manual says to use

CC="gcc -m64"
CXX="gxx -m64"
F77="gfortran -m64"
FC="gfortran -m64"

in several places: can you try following that (with g77 on your old OS, 
and presumably not FC if you don't have an F90 compiler).

> It's not, and unfortunately I'm at a loss to what the problem is.
> Here's the last few lines of the above configure command:
>
> checking for Fortran 77 libraries of g77...  -L/usr/local/lib64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64
> -L/usr/lib/../lib64 -lfrtbegin -lg2c -lm -lgcc_s_64
> checking how to get verbose linking output from gcc -std=gnu99... -v
> checking for C libraries of gcc -std=gnu99...  -L/usr/local/lib64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64
> -L/usr/lib/../lib64 -lgcc_s_64
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... lower case, underscore,
> extra underscore
> checking whether g77 appends underscores to external names... yes
> checking whether g77 appends extra underscores to external names... yes
> checking whether mixed C/Fortran code can be run... configure: WARNING:
> cannot run mixed C/Fortran code
> configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
>
> Here's what looks to be the relevant part from config.log:
> configure:32383: checking whether mixed C/Fortran code can be run
> /usr/bin/ld: skipping incompatible
> /usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for
> -lgcc_s_64
> /usr/bin/ld: skipping incompatible
> /usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for
> -lgcc_s_64
> /usr/bin/ld: cannot find -lgcc_s_64
> collect2: ld returned 1 exit status
> configure:32447: WARNING: cannot run mixed C/Fortran code
> configure:32449: error: Maybe check LDFLAGS for paths to Fortran libraries?
>
> This implies that configure is compiling the code in 32 bit mode (which
> is why it's skipping libgcc_s_64.o
>
> I guess my questions are: has anyone compiled this for this system?  And
> if so, how did you do it?
>
> -Mark
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Dec 19 23:17:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Dec 2007 22:17:47 +0000 (GMT)
Subject: [Rd] Size of graphics device assumed by package examples
Message-ID: <Pine.LNX.4.64.0712190629540.15652@gannet.stats.ox.ac.uk>

R CMD check currently runs the package examples on a landscape postscript 
device with a 12pt font.  This uses A4 or letter paper, and either 
is substantially larger than the canvases of the screen devices.

It seems reasonable to ask that the examples should work on standard 
screen devices.  The X11() and windows() devices default to nominally 7in 
square (although they may be smaller if the screen in use is small, and 
the windows() device allows for scrollbars).  All of these are with a 
(nominally) 12pt font, and that determines the size of the margins.

This suggests we should assume a maximum of 7in square when plotting 
examples.  Unfortunately that is not quite the whole story, as those 
nominal 12pt fonts differ in size and so the X11 device can have slightly 
different margins (larger or smaller) than the postscript() and pdf() 
devices.

Packages SLmisc, ade4 and yaImpute are pushing the limits, as for each an 
example will not plot on a 7x7 postscript or pdf device (nor several 
screen devices).

I suggest you test your examples on a 6in square device to be sure.  It is 
not realistic to expect to plot a 6 by 6 grid of scatterplots with 
individual axes on a screen device: even where the plot succeeds it is 
unreadable.

Also, please *view* the plots produced by R CMD check.  For example that 
for gplots shows a problem with an example (ooplot) setting a layout 
and failing to clear up afterwards.

BTW, at least for me the quartz device (the Mac OS X default) is rather 
different: both the default size and the default font are smaller but the 
net effect is even less space for examples.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mwkimpel at gmail.com  Thu Dec 20 04:38:35 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Wed, 19 Dec 2007 22:38:35 -0500
Subject: [Rd] Problem compiling R 3.6.1 on POWER 570 system
In-Reply-To: <47697CB9.5020407@hms.harvard.edu>
References: <47697CB9.5020407@hms.harvard.edu>
Message-ID: <4769E3BB.20703@gmail.com>

Mark,

My sysadmin has helped me install R on our Power cluster. This is not my 
area of expertise, but I will pass along his directions, which got me up 
and running:

To quote him, "Our machine, BigRed runs SuSE Linux Enterprise Server 9, 
Service Pack 3.  The OS
is 64-bit, but there are 32-bit compatibility libraries, and many
(perhaps most) of the system utilities are 32-bit.  The processors on
the user and compute blades are PowerPC 970MP (dual-core)."

Here is the script I used, your install directories and location of 
x-libraries of course may need to be changed.

Good luck and let the list know what ends up working for you.
Mark Kimpel

cd ~/R_HOME
wget ftp://ftp.stat.math.ethz.ch/Software/R/R-devel.tar.bz2
tar -xjvf R-devel.tar.bz2
cd ~/R_HOME/R-devel
mkdir R-build
cd R-build
LDFLAGS=-m64 FFLAGS="-m64 -mpowerpc64" FCFLAGS="-m64 -mpowerpc64" 
CFLAGS="-m64 -mpowerpc64" ../configure 
--prefix='/N/hd03/mkimpel/BigRed/R_HOME/R-devel/R-build' 
--x-libraries=/usr/X11R6/lib64
make
make install

Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
Indiana University School of Medicine

15032 Hunter Court, Westfield, IN  46074

(317) 490-5129 Work, & Mobile & VoiceMail
(317) 204-4202 Home (no voice mail please)

mwkimpel<at>gmail<dot>com

******************************************************************


Mark Komarinski wrote:
> I've for a RHEL 4 box on a P570 system.  My end user wants to have a 
> 64-bit version of R compiled due to the large amount of memory they 
> require (this image has 16GB allocated to it).
> 
> I can compile R fine in 32-bit mode, but it can't use more than 2.4GB of 
> RAM before it falls over and dies.
> 
> Compiling in 64-bit mode for POWER systems "should" be as easy as adding 
> a CFLAGS="-m64" FFLAGS="-m64" ./configure --without-x .
> 
> It's not, and unfortunately I'm at a loss to what the problem is. 
> Here's the last few lines of the above configure command:
> 
> checking for Fortran 77 libraries of g77...  -L/usr/local/lib64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64 
> -L/usr/lib/../lib64 -lfrtbegin -lg2c -lm -lgcc_s_64
> checking how to get verbose linking output from gcc -std=gnu99... -v
> checking for C libraries of gcc -std=gnu99...  -L/usr/local/lib64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../../../lib64 
> -L/usr/lib/gcc/ppc64-redhat-linux/3.4.6/../../.. -L/lib/../lib64 
> -L/usr/lib/../lib64 -lgcc_s_64
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... lower case, underscore, 
> extra underscore
> checking whether g77 appends underscores to external names... yes
> checking whether g77 appends extra underscores to external names... yes
> checking whether mixed C/Fortran code can be run... configure: WARNING: 
> cannot run mixed C/Fortran code
> configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
> 
> Here's what looks to be the relevant part from config.log:
> configure:32383: checking whether mixed C/Fortran code can be run
> /usr/bin/ld: skipping incompatible 
> /usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for 
> -lgcc_s_64
> /usr/bin/ld: skipping incompatible 
> /usr/lib/gcc/ppc64-redhat-linux/3.4.6/libgcc_s_64.so when searching for 
> -lgcc_s_64
> /usr/bin/ld: cannot find -lgcc_s_64
> collect2: ld returned 1 exit status
> configure:32447: WARNING: cannot run mixed C/Fortran code
> configure:32449: error: Maybe check LDFLAGS for paths to Fortran libraries?
> 
> This implies that configure is compiling the code in 32 bit mode (which 
> is why it's skipping libgcc_s_64.o
> 
> I guess my questions are: has anyone compiled this for this system?  And 
> if so, how did you do it?
> 
> -Mark
>


From tobias.verbeke at telenet.be  Thu Dec 20 08:50:16 2007
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Thu, 20 Dec 2007 08:50:16 +0100
Subject: [Rd] segfault isoreg with NAs
In-Reply-To: <4762CAC9.4000506@telenet.be>
References: <4762CAC9.4000506@telenet.be>
Message-ID: <476A1EB8.1050305@telenet.be>

I was able to reproduce the problem under Windows (R 2.6.1).
When running ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8)),
the following message appears:

"R for Windows GUI front-end has encountered a problem and
needs to close. We are sorry for the inconvenience"

after which R closes.

HTH,
Tobias

 > sessionInfo()
R version 2.6.1 (2007-11-26)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> As can be seen below, adding a NA to the y values
> in a call to isoreg results in a segfault.
> 
> ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))
> 
> Adding missing values to the x values, on the contrary,
> gives an error, but maybe the error message could be
> tailored to this particular situation.
> 
> y <- c(5, 9, 1:2, 5:8, 3, 8)
> x <- c(1:9, NA)
> isoreg(x, y)
> ## error message: Error in if (!isOrd) { : missing value where 
> TRUE/FALSE needed
> 
> Please find below a (temporary) patch (against Revision 43692)
> for both the R source and the help file.
> 
> Kind regards,
> Tobias
> 
> ### patch isoreg.R ###
> 
> --- isoreg.R	2007-12-14 19:07:47.000000000 +0100
> +++ isoreg2.R	2007-12-14 19:11:20.000000000 +0100
> @@ -18,6 +18,9 @@
>   ##
>   isoreg <- function(x, y=NULL)
>   {
> +    if (any(is.na(x))) stop("x may not contain NA values")
> +    if (any(is.na(y))) stop("y may not contain NA values")
> +
>       xy <- xy.coords(x,y)
>       x <- xy$x
>       isOrd <- (!is.null(xy$xlab) && xy$xlab == "Index") || !is.unsorted(x)
> 
> ### patch isoreg.Rd ###
> 
> --- isoreg.Rd	2007-12-14 19:08:12.000000000 +0100
> +++ isoreg2.Rd	2007-12-14 19:15:00.000000000 +0100
> @@ -20,6 +20,7 @@
>     \item{x, y}{%in \code{isoreg},
>       coordinate vectors of the regression points.  Alternatively a single
>       plotting structure can be specified: see \code{\link{xy.coords}}.
> +    The coordinate vectors may not contain missing values.
>     }
>   }
>   \details{
> 
> 
> ### sessionInfo() information segfault ###
> 
>> sessionInfo()
> R version 2.6.0 (2007-10-03)
> i486-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.ISO-8859-15;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.ISO-8859-15;LC_MONETARY=en_US.ISO-8859-15\
> ;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=en_US.ISO-8859-15;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.ISO-885\
> 9-15;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))
> 
>   *** caught segfault ***
> address 0x24, cause 'memory not mapped'
> 
> Process R segmentation fault (core dumped) at Fri Dec 14 17:48:22 2007
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ottorino-luca.pantani at unifi.it  Wed Dec 19 17:54:31 2007
From: ottorino-luca.pantani at unifi.it (Dr. Ottorino-Luca Pantani)
Date: Wed, 19 Dec 2007 17:54:31 +0100
Subject: [Rd] [R-sig-Debian]  bug in r-base (PR#10521)
In-Reply-To: <B516B72E-2728-4CA1-8202-1D92973094DB@act.ulaval.ca>
References: <20071218153523.47F472834612@mail.pubhealth.ku.dk>
	<B516B72E-2728-4CA1-8202-1D92973094DB@act.ulaval.ca>
Message-ID: <47694CC7.3000203@unifi.it>

I had the same problem, but thanks to help of R-help list I solved it.
I'm far from an expert user in Linux, but i solved my problems as follows.

sudo apt-get install build-essential g77
sudo apt-get install refblas3 refblas3-dev
sudo apt-get install r-base-core r-base-dev r-recommended

I really do not know "exactly" what I did with the above commands, but now I can work with R 2.5.1.




Vincent Goulet ha scritto:
> [Moved from r-devel]
>
> Le mar. 18 d?c. ? 10:35, m.zamboni at email.it a ?crit :
>
>   
>> Full_Name: marco zamboni
>> Version: no R version
>> OS: ubuntu gusty
>> Submission from: (NULL) (87.9.174.188)
>>
>>
>> I have just finish to install gusty ubuntu on my AMD sempron.
>> I would like to:
>> $ sudo apt-get install r-base
>>
>> but
>> ...
>> I seguenti pacchetti hanno dipendenze non soddisfatte:
>>  r-base: Dipende: r-base-core (>= 2.6.1-1gutsy0) ma 2.5.1-1 sta per  
>> essere
>> installato
>>          Dipende: r-recommended (= 2.6.1-1gutsy0) ma non sta per  
>> essere
>> installato
>> E: Pacchetto non integro
>>     
>
> First, this is not a bug with R at all; only a difficulty you have  
> with installing the r-base package.
>
> Second, this does not belong to r-devel, but to r-sig-debian. Hence  
> the discussion is moved to the latter forum.
>
> Now, did you follow the instructions in the Ubuntu README at
>
> 	http://cran.r-project.org/bin/linux/ubuntu/
>
> ? What is the result of
>
> 	apt-cache policy r-base
>
> ?
>
> We should be able to help you with this information.
>
> Best,
>
> ---
>    Vincent Goulet, Associate Professor
>    ?cole d'actuariat
>    Universit? Laval, Qu?bec
>    Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca
>
> _______________________________________________
> R-SIG-Debian mailing list
> R-SIG-Debian at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-debian
>
>   

-- 
Ottorino-Luca Pantani, Universit? di Firenze
Dip. Scienza del Suolo e Nutrizione della Pianta
P.zle Cascine 28 50144 Firenze Italia
Tel 39 055 3288 202 (348 lab) Fax 39 055 333 273 
OLPantani at unifi.it  http://www4.unifi.it/dssnp/


From mark_komarinski at hms.harvard.edu  Thu Dec 20 14:39:08 2007
From: mark_komarinski at hms.harvard.edu (Mark Komarinski)
Date: Thu, 20 Dec 2007 08:39:08 -0500
Subject: [Rd] Problem compiling R 2.6.1 on POWER 570 system
In-Reply-To: <47691980.0211.007B.0@mrl.ubc.ca>
References: <47697CB9.5020407@hms.harvard.edu>
	<47691980.0211.007B.0@mrl.ubc.ca>
Message-ID: <476A707C.8050509@hms.harvard.edu>

Cookies all around for the rapid and accurate help!

I wound up using a variation of the below (the non-quoted part is what I 
changed):

On 12/19/2007 04:15 PM, Andrew Ferris wrote:
> Hello Mark,
> 
> Here's the full configure that I used to get 2.4.1 to work on 64bit SLES on a 570:
> 
> ./configure CC="gcc -m64" /
> CXX="gxx -m64" /
CXX="g++ -m64"
> F77="gfortran -m64" /
> FC="gfortran -m64" /
> CFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" /
> FFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" /
> LDFLAGS=-L/usr/lib64 /
> --without-x 

This did indeed create a 64-bit executable.

Alas, I won the battle but may still lose the war.  Red Hat did not 
include many PPC64 versions of their development libraries 
(libxml2-devel for example) that I need to install things like 
AnnBuilder.  It looks like RHEL 5 has these available, so I'll need to 
upgrade this partition and see if I can get this working.

Again, thanks for the help!

-Mark

-- 
Mark Komarinski				mark_komarinski at hms.harvard.edu
Sr. Research Systems Architect		http://ritg.med.harvard.edu
Research IT Group
Harvard Medical School


From tlumley at u.washington.edu  Thu Dec 20 21:20:36 2007
From: tlumley at u.washington.edu (tlumley at u.washington.edu)
Date: Thu, 20 Dec 2007 21:20:36 +0100 (CET)
Subject: [Rd] bug in by.data.frame, R-2.6.1 (PR#10506)
Message-ID: <20071220202036.CCD8F282EFF7@mail.pubhealth.ku.dk>

On Wed, 19 Dec 2007, Prof Brian Ripley wrote:

> It transpires that package survey relies on the current behaviour (which is 
> not new in 2.6.1: R 2.0.0 did it).
>
> The suggested fix is reasonable if 'data' was originally a data frame, but 
> the default method promotes vectors to data frames, and the data frame method 
> used to drop them back to vectors.
>
> I've backed the fix out of R-patched.
>
> I am not sure if the current undocumented behaviour on vectors is 100% 
> desirable, but will amend by.default in R-devel to preserve it.
>
> Thomas: I think svymean() needs not to assume that 1-column data frames will 
> be dropped.

Ok. I think that actually simplifies some things.

  I hope to have some time next week to catch up on a number of package 
issues.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From iago.mosqueira at gmail.com  Thu Dec 20 22:49:22 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Thu, 20 Dec 2007 22:49:22 +0100
Subject: [Rd] SHLIB steps on a Makefile
Message-ID: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>

Hi,

I need to create a Makefile.win for a given package so as to fiddle
slightly with the compilation process. My Makefile works fine in Linux
but I am having trouble creating Makefile.win for MinGW. I first
looked at the commands that Rcmd SHLIB appeared to be running and
copied those onto the Makefile. But one step seems to be missing, the
creation of the _res.rc file needed by windres

	g++-sjlj -I$(RHOME)/include -I../inst/include/ -O2 -Wall -c pkg.cpp -o pkg.o
	windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED"
-I$(RHOME)/include -I../inst/include -i pkg_res.rc -o pkg_res.o
	g++-sjlj -shared -s -o pkg.dll pkg.def pkg.o FL pkg_res.o -L$(RHOME)/bin -lR

This might be fairly obvious, but it is my first attempt at compiling
with MinGW and my search has been fruitless.

What is it that I need to add to replicate what Rcmd SHLIB does?

Many thanks,


Iago Mosqueira


From simon.urbanek at r-project.org  Thu Dec 20 23:11:23 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 20 Dec 2007 17:11:23 -0500
Subject: [Rd] SHLIB steps on a Makefile
In-Reply-To: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
Message-ID: <44D02A38-CAC5-4A74-8D71-2D7EFFB286B7@r-project.org>

Iago,

On Dec 20, 2007, at 4:49 PM, Iago Mosqueira wrote:

> I need to create a Makefile.win for a given package so as to fiddle  
> slightly with the compilation process. My Makefile works fine in  
> Linux but I am having trouble creating Makefile.win for MinGW. I  
> first looked at the commands that Rcmd SHLIB appeared to be running  
> and copied those onto the Makefile. But one step seems to be  
> missing, the creation of the _res.rc file needed by windres
>
> 	g++-sjlj -I$(RHOME)/include -I../inst/include/ -O2 -Wall -c pkg.cpp  
> -o pkg.o
> 	windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED"
> -I$(RHOME)/include -I../inst/include -i pkg_res.rc -o pkg_res.o
> 	g++-sjlj -shared -s -o pkg.dll pkg.def pkg.o FL pkg_res.o -L$ 
> (RHOME)/bin -lR
>
> This might be fairly obvious, but it is my first attempt at  
> compiling with MinGW and my search has been fruitless.
>
> What is it that I need to add to replicate what Rcmd SHLIB does?
>

If that is the only step you're missing then you have probably missed  
the res.rc rule from MakeDll when creating your Makefile:

$(DLLNAME)_res.rc:
         @PERL5LIB=$(RHOME)/share/perl $(PERL) $(RHOME)/src/gnuwin32/ 
makeDllRes.pl $(DLLNAME) > $@

Cheers,
Simon

PS: Given that you can override any rule, it is usually easier to just  
write your modifications in Makevars[.win] when fiddling with the  
compilation than to replicate the whole process.


From ripley at stats.ox.ac.uk  Thu Dec 20 23:23:49 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Dec 2007 22:23:49 +0000 (GMT)
Subject: [Rd] SHLIB steps on a Makefile
In-Reply-To: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>

On Thu, 20 Dec 2007, Iago Mosqueira wrote:

> Hi,
>
> I need to create a Makefile.win for a given package so as to fiddle
> slightly with the compilation process. My Makefile works fine in Linux

That's rather dangerous: we have had lots of trouble with packages for 
which the Makefile works on the maintainer's Linux, but not on other 
people's systems (even Linux ones).

Do you really, really need a Makefile.win?: I would be surprised if you 
did.  Only 9 CRAN packages have a Makefile.win, and two of those are 
dummies and one other we have asked the maintainers to replace by 
Makevars.win as it is not portable.

> but I am having trouble creating Makefile.win for MinGW. I first
> looked at the commands that Rcmd SHLIB appeared to be running and
> copied those onto the Makefile. But one step seems to be missing, the
> creation of the _res.rc file needed by windres
>
> 	g++-sjlj -I$(RHOME)/include -I../inst/include/ -O2 -Wall -c pkg.cpp -o pkg.o
> 	windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED"
> -I$(RHOME)/include -I../inst/include -i pkg_res.rc -o pkg_res.o
> 	g++-sjlj -shared -s -o pkg.dll pkg.def pkg.o FL pkg_res.o -L$(RHOME)/bin -lR
>
> This might be fairly obvious, but it is my first attempt at compiling
> with MinGW and my search has been fruitless.
>
> What is it that I need to add to replicate what Rcmd SHLIB does?

Adding the resources is not essential: they add identification to the 
DLL which can be very useful but are icing on the cake.  So I would not 
try to emulate that step.

But the Makefile in use is src/gnuwin32/MakeDll and that contains

$(DLLNAME)_res.rc:
         @PERL5LIB=$(RHOME)/share/perl $(PERL) $(RHOME)/src/gnuwin32/makeDllRes.pl $(DLLNAME) > $@

$(DLLNAME)_res.o: $(DLLNAME)_res.rc $(RHOME)/include/Rversion.h

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From iago.mosqueira at gmail.com  Thu Dec 20 23:28:31 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Thu, 20 Dec 2007 23:28:31 +0100
Subject: [Rd] SHLIB steps on a Makefile
In-Reply-To: <Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
	<Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
Message-ID: <dba1e14b0712201428n3c55c57fx71de164f3ea50f7@mail.gmail.com>

On Dec 20, 2007 11:23 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Thu, 20 Dec 2007, Iago Mosqueira wrote:
>
> > Hi,
> >
> > I need to create a Makefile.win for a given package so as to fiddle
> > slightly with the compilation process. My Makefile works fine in Linux
>
> That's rather dangerous: we have had lots of trouble with packages for
> which the Makefile works on the maintainer's Linux, but not on other
> people's systems (even Linux ones).
>
> Do you really, really need a Makefile.win?: I would be surprised if you
> did.  Only 9 CRAN packages have a Makefile.win, and two of those are
> dummies and one other we have asked the maintainers to replace by
> Makevars.win as it is not portable.
>
> > but I am having trouble creating Makefile.win for MinGW. I first
> > looked at the commands that Rcmd SHLIB appeared to be running and
> > copied those onto the Makefile. But one step seems to be missing, the
> > creation of the _res.rc file needed by windres
> >
> >       g++-sjlj -I$(RHOME)/include -I../inst/include/ -O2 -Wall -c pkg.cpp -o pkg.o
> >       windres --preprocessor="gcc-sjlj -E -xc -DRC_INVOKED"
> > -I$(RHOME)/include -I../inst/include -i pkg_res.rc -o pkg_res.o
> >       g++-sjlj -shared -s -o pkg.dll pkg.def pkg.o FL pkg_res.o -L$(RHOME)/bin -lR
> >
> > This might be fairly obvious, but it is my first attempt at compiling
> > with MinGW and my search has been fruitless.
> >
> > What is it that I need to add to replicate what Rcmd SHLIB does?
>
> Adding the resources is not essential: they add identification to the
> DLL which can be very useful but are icing on the cake.  So I would not
> try to emulate that step.
>
> But the Makefile in use is src/gnuwin32/MakeDll and that contains
>
> $(DLLNAME)_res.rc:
>          @PERL5LIB=$(RHOME)/share/perl $(PERL) $(RHOME)/src/gnuwin32/makeDllRes.pl $(DLLNAME) > $@
>
> $(DLLNAME)_res.o: $(DLLNAME)_res.rc $(RHOME)/include/Rversion.h
>

Many thanks for the information. I am trying to make a package C code
compile against a DLL already present in another package, so I need to
include its location in the call to gcc.  I'll see what the most
portable system could be and will test widely.

Regards,


Iago Mosqueira


From jombart at biomserv.univ-lyon1.fr  Thu Dec 20 23:30:39 2007
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Thu, 20 Dec 2007 23:30:39 +0100
Subject: [Rd] using example() with S4 documentation
Message-ID: <476AED0F.2000709@biomserv.univ-lyon1.fr>

Hi list,

Developping a plot method for a S4 class 'foo' (signature being x="foo", 
y="missing"), I would like to access the example contained inside the 
\examples{} section of the corresponding Rd file. This file contains the 
aliases: \alias{plot-methods} and \alias{plot,foo,missing}. There is no 
trouble to access the documentation using:
method ? plot("foo")
or
?plot(new("foo"))

Now, is it possible to have example() work as well ? I tried using the 
"package" argument of "example" without success...

Thanks in advance.

Cheers,

Thibaut.
 
-- 
######################################
Thibaut JOMBART
CNRS UMR 5558 - Laboratoire de Biom?trie et Biologie Evolutive
Universite Lyon 1
43 bd du 11 novembre 1918
69622 Villeurbanne Cedex
T?l. : 04.72.43.29.35
Fax : 04.72.43.13.88
jombart at biomserv.univ-lyon1.fr
http://lbbe.univ-lyon1.fr/-Jombart-Thibaut-.html?lang=en
http://pbil.univ-lyon1.fr/software/adegenet/


From markleeds at verizon.net  Thu Dec 20 23:55:19 2007
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Thu, 20 Dec 2007 23:55:19 +0100 (CET)
Subject: [Rd] typo in cbind help page (PR#10523)
Message-ID: <20071220225520.1B6E3282EFF7@mail.pubhealth.ku.dk>

------=_Part_1509_5179695.1198191004146
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit


------=_Part_1509_5179695.1198191004146
Content-Type: application/octet-stream; name=R.bug.report
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename=R.bug.report


# Your mailer is set to "none" (default on Windows),
# hence we cannot send the bug report directly from R.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs at r-project.org
#
######################################################

The bug is that the cbind help should read stringsAsFactors=FALSE
( rather than TRUE ) in the Data Frame Methods section.


--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 6.0
 year = 2007
 month = 10
 day = 03
 svn rev = 43063
 language = R
 version.string = R version 2.6.0 (2007-10-03)

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:datasets, .Marks.env, package:lattice, package:nnet, package:car, package:filehash, package:reshape, package:zoo, package:chron, package:MASS, package:utils, package:stats, package:graphics, package:grDevices, package:methods, Autoloads, package:base

------=_Part_1509_5179695.1198191004146--


From erich.neuwirth at univie.ac.at  Fri Dec 21 09:17:18 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 21 Dec 2007 09:17:18 +0100
Subject: [Rd] Windows version make installer
In-Reply-To: <47697CB9.5020407@hms.harvard.edu>
References: <47697CB9.5020407@hms.harvard.edu>
Message-ID: <476B768E.4040703@univie.ac.at>

I stumbled upon a minor problem when creating a customized installer using

make myR IMAGEDIR=xxxxx

in src/gnuwin32/installer

In IMAGEDIR i have a complete installation with many additional
directories with packages in the directory site-library.
Since the libraries are not in library, help.start, when run,
creates a file "fixedHTMLLinks" in each of the package directories.
These files are included in the installer created with make.
Since the version installed from this installer may live in a different
directories, the fixedHTMLLinks point to incorrect places after such an
install.
So it might make sense that
make myR IMAGEDIR=xxxxx
does not include all these fixedHTMLLinks in the installer.

Erich Neuwirth


From ploua at allstate.com  Fri Dec 21 00:45:56 2007
From: ploua at allstate.com (Louisell, Paul)
Date: Thu, 20 Dec 2007 15:45:56 -0800
Subject: [Rd] 64-bit R build with Studio 12 on Sparc v9
Message-ID: <633AD4C78F3E8F489614A06990F6077B025CCF0B@a0203-xpo0111-s.hodc.ad.allstate.com>

Hi,

I'm working on a server with a sparcv9 chip using SunOS 5.9 Generic May
2002. The compilers are the Sun Studio 12 compilers. I'm trying to build
a 64-bit version of R-2.6.1, and while the configure script runs, the
make does not.

Here are the options I set in config.site:
________________________________________________________________________
_

R_PAPERSIZE=letter
CC="cc -m64"
CFLAGS="-xO5 -xlibmil -xmemalign=8s"
F77="f95 -m64"
FFLAGS="-xO5 -xlibmil -xmemalign=8s"
LDFLAGS="-L/opt/SUNWspro/lib/v9 -L/usr/local/lib"
CXX="CC -m64"
CXXFLAGS="-xO5 -xlibmil -xmemalign=8s"
FC="f95 -m64"
FCFLAGS="-xO5 -xlibmil -xmemalign=8s"
________________________________________________________________________
__

Here's the command invoking configure:
________________________________________________________________________
__

./configure --with-blas --with-lapack --enable-BLAS-shlib
________________________________________________________________________
__

And here are the last several lines of the screen output from running
the configure script:
________________________________________________________________________
__

R is now configured for sparc-sun-solaris2.9

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                cc -m64  -xO5 -xlibmil -xmemalign=8s
  Fortran 77 compiler:       f95 -m64  -xO5 -xlibmil -xmemalign=8s

  C++ compiler:              CC -m64  -xO5 -xlibmil -xmemalign=8s
  Fortran 90/95 compiler:    f95 -m64 -xO5 -xlibmil -xmemalign=8s
  Obj-C compiler:            cc 

  Interfaces supported:      X11
  External libraries:        readline, BLAS(SunPerf)
  Additional capabilities:   iconv, MBCS, NLS
  Options enabled:           shared BLAS, R profiling, Java

  Recommended packages:      yes

configure: WARNING: you cannot build the object documentation system
configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info or HTML versions of the R
manuals
configure: WARNING: you cannot build PDF versions of the R manuals
________________________________________________________________________
____

I'm not concerned about not being able to build the manuals. Here are
the last several lines of the screen output from running make:
________________________________________________________________________
____

making pcre_chartables.d from pcre_chartables.c
"./pcre_internal.h", line 168: Illegal number 4294967295U
*** Error code 2
make: Fatal error: Command failed for target `pcre_chartables.d'
Current working directory
/export/home/ploua/R_HOME/R-2.6.1/src/extra/pcre
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory
/export/home/ploua/R_HOME/R-2.6.1/src/extra/pcre
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /export/home/ploua/R_HOME/R-2.6.1/src/extra
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /export/home/ploua/R_HOME/R-2.6.1/src
*** Error code 1
make: Fatal error: Command failed for target `R'
________________________________________________________________________
____

It seems that the C compiler is having a hard time reading standard C
constants. Some further (hopefully relevant) background:  Here is an
excerpt from the Studio 12 C User's Guide:
________________________________________________________________________
____

If you do not specify -xc99, the compiler defaults to -xc99=all,no_lib.
If you specify -xc99
without any values, the option is set to-xc99=all.
Note - Though the compiler support-level defaults to the language
features of the C99 standard,
the standard headers provided by the Solaris 8 and Solaris 9 operating
systems in /usr/include
do not conform with the 1999 ISO/IEC C standard. If you encounter error
messages, try
specifying -xc99=none to obtain the 1990 ISO/IEC C standard behavior for
these headers.
The 1999 C standard library semantics of routines that appeared in both
the 1990 and 1999 C
standard are not available and therefore cannot be enabled on Solaris 8
and Solaris 9 software.
The compiler issues an error message when you specify -xc99=lib directly
or indirectly on
Solaris 8 or Solaris 9 software.
________________________________________________________________________
____

I've tried adding the option '-xc99=none' to the C flags shown from
config.site above, but I get the same error on running make. When I
specify only '-xc99', I get an error telling me the library is
unavailable on Solaris 9--the User's Guide is telling the truth above. 

I've also tried modifying 'pcre_internal.h' by commenting out the lines
where it's trying to determine the type for 32-bit unsigned integers and
instead hard-coding things with 

typedef unsigned int pcre_uint32;

When I do this, I get the same error but originating in a different
file. I'm not a C programmer so I can't be certain what I've attempted
is reasonable (although I have received some guidance from people who
are C programmers). Is my only option to go through and find all
instances of '4294967295' in source files and hard-code things as I did
above for 'pcre_internal.h'? 

In the R Installation and Admin manual on page 42, it says, "However,
our tests were none too successful: Sparc 64-bit builds crashed." Here
they were referring to Solaris 10. I noticed that Brian Ripley produced
a successful build using Studio 12, but on x86_64 Linux. The references
to Solaris 9 used the Sun Forte 7 compilers. 

My ultimate question: Does anyone know how to successfully build a
64-bit target for R-2.6.1 using Studio 12 on a system with my
architecture? If not using Studio 12, how about Studio 11?

Thanks in advance for any help,



Paul Louisell 
650-833-6254 
ploua at allstate.com 
Associate Predictive Modeler (Statistician) 
Modeling & Data Analytics 
ARPC 


From ripley at stats.ox.ac.uk  Fri Dec 21 10:40:45 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Dec 2007 09:40:45 +0000 (GMT)
Subject: [Rd] Windows version make installer
In-Reply-To: <476B768E.4040703@univie.ac.at>
References: <47697CB9.5020407@hms.harvard.edu> <476B768E.4040703@univie.ac.at>
Message-ID: <Pine.LNX.4.64.0712210929560.27433@auk.stats>

On Fri, 21 Dec 2007, Erich Neuwirth wrote:

> I stumbled upon a minor problem when creating a customized installer using
>
> make myR IMAGEDIR=xxxxx
>
> in src/gnuwin32/installer
>
> In IMAGEDIR i have a complete installation with many additional
> directories with packages in the directory site-library.
> Since the libraries are not in library, help.start, when run,
> creates a file "fixedHTMLLinks" in each of the package directories.
> These files are included in the installer created with make.

> Since the version installed from this installer may live in a different
> directories, the fixedHTMLLinks point to incorrect places after such an
> install.

No problem: they are fixed up at first use of help.start() if incorrect. 
*But* in my dept setup they would be correct so this is the desired 
behaviour.

> So it might make sense that
> make myR IMAGEDIR=xxxxx
> does not include all these fixedHTMLLinks in the installer.

Hmm: *you* gave our script an imagedir containing things you don't want 
there and then expect our script to correct your mistake?  As hinted 
above, others may want these files, so we are not going to second-guess 
the users' intentions.  (There is not much point in building a customized 
installer with packages anywhere other than the main library, since that 
is where the links work best.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Fri Dec 21 16:58:04 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 21 Dec 2007 10:58:04 -0500
Subject: [Rd] request for addition to R-int
Message-ID: <476BE28C.2010203@zoo.ufl.edu>



http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards

 gives detailed advice on how to set the indentation level for
C code to 4, but it took me a bit of poking around in the archives
to find the

(setq ess-indent-level 4)

incantation for getting the R indentation right as well.  It would
have been helpful to have it in the R-ints manual section as well ...

  thanks
    Ben Bolker


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 252 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20071221/851bc573/attachment.bin 

From maechler at stat.math.ethz.ch  Fri Dec 21 17:38:12 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Dec 2007 17:38:12 +0100
Subject: [Rd] small bug in panel.cor in example for pairs?
In-Reply-To: <4767F002.80405@stamats.de>
References: <4767F002.80405@stamats.de>
Message-ID: <18283.60404.245485.606462@stat.math.ethz.ch>

>>>>> "MK" == Matthias Kohl <Matthias.Kohl at stamats.de>
>>>>>     on Tue, 18 Dec 2007 17:06:26 +0100 writes:

    MK> Dear all,
    MK> in the Example section of pairs there is
    MK> panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
    MK> {
    MK> usr <- par("usr"); on.exit(par(usr))
    MK> par(usr = c(0, 1, 0, 1))
    MK> r <- abs(cor(x, y))
    MK> txt <- format(c(r, 0.123456789), digits=digits)[1]
    MK> txt <- paste(prefix, txt, sep="")
    MK> if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
    MK> text(0.5, 0.5, txt, cex = cex * r)
    MK> }

    MK> Shouldn't the last two lines read
    MK> if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    MK> text(0.5, 0.5, txt, cex = cex.cor * r)
    MK> ?

yes, indeed.
A rather inconsequential bug, but you are right; I've fixed 
(for R-devel).

Regards,
Martin

    MK> Best,
    MK> Matthias

    MK> --
    MK> Dr. Matthias Kohl
    MK> Mathematical Statistics
    MK> University of Bayreuth


From maechler at stat.math.ethz.ch  Fri Dec 21 18:03:29 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Dec 2007 18:03:29 +0100
Subject: [Rd] segfault isoreg with NAs
In-Reply-To: <476A1EB8.1050305@telenet.be>
References: <4762CAC9.4000506@telenet.be>
	<476A1EB8.1050305@telenet.be>
Message-ID: <18283.61921.320885.3449@stat.math.ethz.ch>

Hi Tobias,

>>>>> "TobiasV" == Tobias Verbeke <tobias.verbeke at telenet.be>
>>>>>     on Thu, 20 Dec 2007 08:50:16 +0100 writes:

    TobiasV> I was able to reproduce the problem under Windows (R 2.6.1).
    TobiasV> When running ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8)),
    TobiasV> the following message appears:

    TobiasV> "R for Windows GUI front-end has encountered a problem and
    TobiasV> needs to close. We are sorry for the inconvenience"

    TobiasV> after which R closes.

thank you for keeping the topic live.

Just now I've wanted to address this as a "clean up before Christmas"
action.

The next versions of R definitely will no longer seg.fault here.
The question, what exactly one should have happening is another
one.

If you want (since nobody else seems particularly
interested) we can continue to look at this in off-list for a
while.

Best regards,
Martin


    TobiasV> HTH,
    TobiasV> Tobias

    >> sessionInfo()
    TobiasV> R version 2.6.1 (2007-11-26)
    TobiasV> i386-pc-mingw32

    TobiasV> locale:
    TobiasV> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
    TobiasV> States.1252;LC_MONETARY=English_United 
    TobiasV> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

    TobiasV> attached base packages:
    TobiasV> [1] stats     graphics  grDevices utils     datasets  methods   base

    >> As can be seen below, adding a NA to the y values
    >> in a call to isoreg results in a segfault.
    >> 
    >> ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))
    >> 
    >> Adding missing values to the x values, on the contrary,
    >> gives an error, but maybe the error message could be
    >> tailored to this particular situation.
    >> 
    >> y <- c(5, 9, 1:2, 5:8, 3, 8)
    >> x <- c(1:9, NA)
    >> isoreg(x, y)
    >> ## error message: Error in if (!isOrd) { : missing value where 
    >> TRUE/FALSE needed
    >> 
    >> Please find below a (temporary) patch (against Revision 43692)
    >> for both the R source and the help file.
    >> 
    >> Kind regards,
    >> Tobias
    >> 
    >> ### patch isoreg.R ###
    >> 
    >> --- isoreg.R	2007-12-14 19:07:47.000000000 +0100
    >> +++ isoreg2.R	2007-12-14 19:11:20.000000000 +0100
    >> @@ -18,6 +18,9 @@
    >> ##
    >> isoreg <- function(x, y=NULL)
    >> {
    >> +    if (any(is.na(x))) stop("x may not contain NA values")
    >> +    if (any(is.na(y))) stop("y may not contain NA values")
    >> +
    >> xy <- xy.coords(x,y)
    >> x <- xy$x
    >> isOrd <- (!is.null(xy$xlab) && xy$xlab == "Index") || !is.unsorted(x)
    >> 
    >> ### patch isoreg.Rd ###
    >> 
    >> --- isoreg.Rd	2007-12-14 19:08:12.000000000 +0100
    >> +++ isoreg2.Rd	2007-12-14 19:15:00.000000000 +0100
    >> @@ -20,6 +20,7 @@
    >> \item{x, y}{%in \code{isoreg},
    >> coordinate vectors of the regression points.  Alternatively a single
    >> plotting structure can be specified: see \code{\link{xy.coords}}.
    >> +    The coordinate vectors may not contain missing values.
    >> }
    >> }
    >> \details{
    >> 
    >> 
    >> ### sessionInfo() information segfault ###
    >> 
    >>> sessionInfo()
    >> R version 2.6.0 (2007-10-03)
    >> i486-pc-linux-gnu
    >> 
    >> locale:
    >> LC_CTYPE=en_US.ISO-8859-15;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.ISO-8859-15;LC_MONETARY=en_US.ISO-8859-15\
    >> ;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=en_US.ISO-8859-15;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.ISO-885\
    >> 9-15;LC_IDENTIFICATION=C
    >> 
    >> attached base packages:
    >> [1] stats     graphics  grDevices utils     datasets  methods   base
    >>> ir4 <- isoreg(1:10, y4 <- c(5, 9, 1:2, 5:8, NA, 8))
    >> 
    >> *** caught segfault ***
    >> address 0x24, cause 'memory not mapped'
    >> 
    >> Process R segmentation fault (core dumped) at Fri Dec 14 17:48:22 2007
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    TobiasV> ______________________________________________
    TobiasV> R-devel at r-project.org mailing list
    TobiasV> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Dec 21 18:07:28 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 21 Dec 2007 12:07:28 -0500
Subject: [Rd] 64-bit R build with Studio 12 on Sparc v9
In-Reply-To: <633AD4C78F3E8F489614A06990F6077B025CCF0B@a0203-xpo0111-s.hodc.ad.allstate.com>
References: <633AD4C78F3E8F489614A06990F6077B025CCF0B@a0203-xpo0111-s.hodc.ad.allstate.com>
Message-ID: <DAF6B7DA-384F-42AE-A41D-9FB0F1E4C8F9@r-project.org>


On Dec 20, 2007, at 6:45 PM, Louisell, Paul wrote:

> I'm working on a server with a sparcv9 chip using SunOS 5.9 Generic  
> May 2002. The compilers are the Sun Studio 12 compilers. I'm trying  
> to build a 64-bit version of R-2.6.1, and while the configure script  
> runs, the make does not.
>

Paul,

I don't know if that helps, but incidentally I have compiled R  
successfully with spro12  for a v9 machine just yesterday and all you  
need is in the R-admin manual. For completeness these were the (main)  
flags:

'CXX=CC -m64'
'LDFLAGS=-L/opt/SUNWspro/lib/v9'
'CC=cc -xc99 -m64'
'CFLAGS=-O -xlibmieee -xarch=sparcvis'
'F77=f95 -m64' 'FFLAGS=-O4 -xarch=sparcvis'
'CXXFLAGS=-O -m64 -xarch=sparcvis'
'FC=f95 -m64'
'FCFLAGS=-O4 -xarch=sparcvis -libmil'
'SHLIB_CXXLDFLAGS=-G -lCstd'
'SHLIB_LDFLAGS=-shared'
'CPICFLAGS=-Kpic' 'FPICFLAGS=-KPIC' 'CXXPICFLAGS=-Kpic' 'FCPICFLAGS=- 
KPIC'

Cheers,
Simon

PS: My tests so far show that R compiled with gcc 4.2.2 is faster than  
R compiled with the Sun's compilers, so I ended up using gcc instead  
as it's less painful and faster.



> Here are the options I set in config.site:
> ________________________________________________________________________
> _
>
> R_PAPERSIZE=letter
> CC="cc -m64"
> CFLAGS="-xO5 -xlibmil -xmemalign=8s"
> F77="f95 -m64"
> FFLAGS="-xO5 -xlibmil -xmemalign=8s"
> LDFLAGS="-L/opt/SUNWspro/lib/v9 -L/usr/local/lib"
> CXX="CC -m64"
> CXXFLAGS="-xO5 -xlibmil -xmemalign=8s"
> FC="f95 -m64"
> FCFLAGS="-xO5 -xlibmil -xmemalign=8s"
> ________________________________________________________________________
> __
>
> Here's the command invoking configure:
> ________________________________________________________________________
> __
>
> ./configure --with-blas --with-lapack --enable-BLAS-shlib
> ________________________________________________________________________
> __
>
> And here are the last several lines of the screen output from running
> the configure script:
> ________________________________________________________________________
> __
>
> R is now configured for sparc-sun-solaris2.9
>
>  Source directory:          .
>  Installation directory:    /usr/local
>
>  C compiler:                cc -m64  -xO5 -xlibmil -xmemalign=8s
>  Fortran 77 compiler:       f95 -m64  -xO5 -xlibmil -xmemalign=8s
>
>  C++ compiler:              CC -m64  -xO5 -xlibmil -xmemalign=8s
>  Fortran 90/95 compiler:    f95 -m64 -xO5 -xlibmil -xmemalign=8s
>  Obj-C compiler:            cc
>
>  Interfaces supported:      X11
>  External libraries:        readline, BLAS(SunPerf)
>  Additional capabilities:   iconv, MBCS, NLS
>  Options enabled:           shared BLAS, R profiling, Java
>
>  Recommended packages:      yes
>
> configure: WARNING: you cannot build the object documentation system
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info or HTML versions of the R
> manuals
> configure: WARNING: you cannot build PDF versions of the R manuals
> ________________________________________________________________________
> ____
>
> I'm not concerned about not being able to build the manuals. Here are
> the last several lines of the screen output from running make:
> ________________________________________________________________________
> ____
>
> making pcre_chartables.d from pcre_chartables.c
> "./pcre_internal.h", line 168: Illegal number 4294967295U
> *** Error code 2
> make: Fatal error: Command failed for target `pcre_chartables.d'
> Current working directory
> /export/home/ploua/R_HOME/R-2.6.1/src/extra/pcre
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory
> /export/home/ploua/R_HOME/R-2.6.1/src/extra/pcre
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /export/home/ploua/R_HOME/R-2.6.1/src/extra
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> Current working directory /export/home/ploua/R_HOME/R-2.6.1/src
> *** Error code 1
> make: Fatal error: Command failed for target `R'
> ________________________________________________________________________
> ____
>
> It seems that the C compiler is having a hard time reading standard C
> constants. Some further (hopefully relevant) background:  Here is an
> excerpt from the Studio 12 C User's Guide:
> ________________________________________________________________________
> ____
>
> If you do not specify -xc99, the compiler defaults to - 
> xc99=all,no_lib.
> If you specify -xc99
> without any values, the option is set to-xc99=all.
> Note - Though the compiler support-level defaults to the language
> features of the C99 standard,
> the standard headers provided by the Solaris 8 and Solaris 9 operating
> systems in /usr/include
> do not conform with the 1999 ISO/IEC C standard. If you encounter  
> error
> messages, try
> specifying -xc99=none to obtain the 1990 ISO/IEC C standard behavior  
> for
> these headers.
> The 1999 C standard library semantics of routines that appeared in  
> both
> the 1990 and 1999 C
> standard are not available and therefore cannot be enabled on  
> Solaris 8
> and Solaris 9 software.
> The compiler issues an error message when you specify -xc99=lib  
> directly
> or indirectly on
> Solaris 8 or Solaris 9 software.
> ________________________________________________________________________
> ____
>
> I've tried adding the option '-xc99=none' to the C flags shown from
> config.site above, but I get the same error on running make. When I
> specify only '-xc99', I get an error telling me the library is
> unavailable on Solaris 9--the User's Guide is telling the truth above.
>
> I've also tried modifying 'pcre_internal.h' by commenting out the  
> lines
> where it's trying to determine the type for 32-bit unsigned integers  
> and
> instead hard-coding things with
>
> typedef unsigned int pcre_uint32;
>
> When I do this, I get the same error but originating in a different
> file. I'm not a C programmer so I can't be certain what I've attempted
> is reasonable (although I have received some guidance from people who
> are C programmers). Is my only option to go through and find all
> instances of '4294967295' in source files and hard-code things as I  
> did
> above for 'pcre_internal.h'?
>
> In the R Installation and Admin manual on page 42, it says, "However,
> our tests were none too successful: Sparc 64-bit builds crashed." Here
> they were referring to Solaris 10. I noticed that Brian Ripley  
> produced
> a successful build using Studio 12, but on x86_64 Linux. The  
> references
> to Solaris 9 used the Sun Forte 7 compilers.
>
> My ultimate question: Does anyone know how to successfully build a
> 64-bit target for R-2.6.1 using Studio 12 on a system with my
> architecture? If not using Studio 12, how about Studio 11?
>
> Thanks in advance for any help,
>
>
>
> Paul Louisell
> 650-833-6254
> ploua at allstate.com
> Associate Predictive Modeler (Statistician)
> Modeling & Data Analytics
> ARPC
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From alistair.gee at gmail.com  Fri Dec 21 21:17:53 2007
From: alistair.gee at gmail.com (Alistair Gee)
Date: Fri, 21 Dec 2007 12:17:53 -0800
Subject: [Rd] RODBC 1.2.2 patch for queries that return 0 rows
Message-ID: <e63850350712211217j16758b89q76f6e4a0c2288873@mail.gmail.com>

When using RODBC 1.2.2 on R 2.6, I would sometimes get errors with
sqlQuery() whenever the query returned 0 rows. Using gdb, I found
that the SQLExecDirect () call can return SQL_NO_DATA when using
the ODBC 3.x API. The following patch makes RODBC ignore the
SQL_NO_DATA result:

--- RODBC.orig/src/RODBC.c   2007-07-27 00:26:45.000000000 -0700
+++ RODBC/src/RODBC.c        2007-12-21 10:59:05.198998652 -0800
@@ -349,7 +349,9 @@
    res = SQLExecDirect(thisHandle->hStmt,
                       (SQLCHAR *) CHAR(STRING_ELT(query, 0)),
                       SQL_NTS);
-    if( res != SQL_SUCCESS && res != SQL_SUCCESS_WITH_INFO ) {
+    if( res != SQL_SUCCESS && res != SQL_SUCCESS_WITH_INFO
+      /* ODBC 3.x returns SQL_NO_DATA when no rows affected. */
+      && res != SQL_NO_DATA) {
       errlistAppend(thisHandle, _(err_SQLExecDirect));
       geterr(thisHandle);
       (void)SQLFreeHandle(SQL_HANDLE_STMT, thisHandle->hStmt);


From iago.mosqueira at gmail.com  Fri Dec 21 23:39:59 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Fri, 21 Dec 2007 23:39:59 +0100
Subject: [Rd] Small typo in 'Writing R extensions'
In-Reply-To: <Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
	<Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
Message-ID: <476C40BF.6090608@gmail.com>

Hello,

I have just noticed the Table of Contents of 'Writing R extensions' is 
wrongly numbered, as it gives, for example, 5. Debugging, when that is 
section 4, as the acknowledgements section is numbered in the ToC only.

Regards,


Iago


From ripley at stats.ox.ac.uk  Sat Dec 22 09:16:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Dec 2007 08:16:34 +0000 (GMT)
Subject: [Rd] Small typo in 'Writing R extensions'
In-Reply-To: <476C40BF.6090608@gmail.com>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
	<Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
	<476C40BF.6090608@gmail.com>
Message-ID: <Pine.LNX.4.64.0712220809270.19461@gannet.stats.ox.ac.uk>

I presume you mean in HTML?  The PDF versions have the correct numbering.
Compare the two versions on http://cran.r-project.org/manuals.html.

That's not a 'typo' but a makeinfo problem.  There's a similar one in the 
TOC of R-admin.texi where the appendices are numbered not lettered in the 
ToC (but the CRAN copy is missing the ToC).

I've not been able to find a makeinfo workaround.

On Fri, 21 Dec 2007, Iago Mosqueira wrote:

> Hello,
>
> I have just noticed the Table of Contents of 'Writing R extensions' is
> wrongly numbered, as it gives, for example, 5. Debugging, when that is
> section 4, as the acknowledgements section is numbered in the ToC only.
>
> Regards,
>
>
> Iago

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rossibarra at gmail.com  Fri Dec 21 17:45:31 2007
From: rossibarra at gmail.com (rossibarra at gmail.com)
Date: Fri, 21 Dec 2007 17:45:31 +0100 (CET)
Subject: [Rd] substitute() bug? (PR#10525)
Message-ID: <20071221164531.D64372834632@mail.pubhealth.ku.dk>

The first four lines of code below work as normal.  The fifth thorows  
an error: "Error in paste(theta[1], "=", 5) : object "theta" not found"


x=rnorm(1000);
bob=density(x);
topp=5;
plot(bob,xlab="", ylab="",  
main=substitute(paste(theta[1],"=",topp),list(topp=topp)), type="l");
plot(bob$y~bob$x,xlab="", ylab="",  
main=substitute(paste(theta[1],"=",topp),list(topp=topp)), type="l");


Note that theta is not defined anywhere:

ls()
  [1] "bob"      "dline"    "dplot"    "dpt"      "less"     "lesseq"
  [7] "more"     "moreeq"   "peak"     "peakline" "peakplot" "pop"
[13] "topp"     "x"


Version:
  platform = i386-apple-darwin8.10.1
  arch = i386
  os = darwin8.10.1
  system = i386, darwin8.10.1
  status =
  major = 2
  minor = 6.1
  year = 2007
  month = 11
  day = 26
  svn rev = 43537
  language = R
  version.string = R version 2.6.1 (2007-11-26)

Locale:
C

Search Path:
  .GlobalEnv, package:stats, package:graphics, package:grDevices,  
package:utils, package:datasets, package:methods,

____________

Jeffrey Ross-Ibarra
email: rossibarra at gmail.com
web: rossibarra.googlepages.com
Dept. Ecology and Evolutionary Biology
University of California
Irvine, Ca. 92697


From murdoch at stats.uwo.ca  Sat Dec 22 13:58:00 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 22 Dec 2007 07:58:00 -0500
Subject: [Rd] substitute() bug? (PR#10525)
In-Reply-To: <20071221164531.D64372834632@mail.pubhealth.ku.dk>
References: <20071221164531.D64372834632@mail.pubhealth.ku.dk>
Message-ID: <476D09D8.3070403@stats.uwo.ca>

rossibarra at gmail.com wrote:
> The first four lines of code below work as normal.  The fifth thorows  
> an error: "Error in paste(theta[1], "=", 5) : object "theta" not found"
>
>
> x=rnorm(1000);
> bob=density(x);
> topp=5;
> plot(bob,xlab="", ylab="",  
> main=substitute(paste(theta[1],"=",topp),list(topp=topp)), type="l");
> plot(bob$y~bob$x,xlab="", ylab="",  
> main=substitute(paste(theta[1],"=",topp),list(topp=topp)), type="l");
>   
I'm not sure this is a bug, but if it is, it's in 
graphics:::plot.formula, not in substitute.  The problem is that 
substitute returns an unevaluated call, and plot.formula tries to 
evaluate it.  You can avoid the bug by wrapping the substitute call in 
as.expression.

The docs for plotmath say that it requires an expression, but "in most 
cases" language objects will be coerced to one:  it appears this is one 
of the cases where that is not true.

Duncan Murdoch
>
> Note that theta is not defined anywhere:
>
> ls()
>   [1] "bob"      "dline"    "dplot"    "dpt"      "less"     "lesseq"
>   [7] "more"     "moreeq"   "peak"     "peakline" "peakplot" "pop"
> [13] "topp"     "x"
>
>
> Version:
>   platform = i386-apple-darwin8.10.1
>   arch = i386
>   os = darwin8.10.1
>   system = i386, darwin8.10.1
>   status =
>   major = 2
>   minor = 6.1
>   year = 2007
>   month = 11
>   day = 26
>   svn rev = 43537
>   language = R
>   version.string = R version 2.6.1 (2007-11-26)
>
> Locale:
> C
>
> Search Path:
>   .GlobalEnv, package:stats, package:graphics, package:grDevices,  
> package:utils, package:datasets, package:methods,
>
> ____________
>
> Jeffrey Ross-Ibarra
> email: rossibarra at gmail.com
> web: rossibarra.googlepages.com
> Dept. Ecology and Evolutionary Biology
> University of California
> Irvine, Ca. 92697
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bhs2 at mevik.net  Sat Dec 22 18:23:34 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Sat, 22 Dec 2007 18:23:34 +0100
Subject: [Rd] request for addition to R-int
In-Reply-To: <476BE28C.2010203@zoo.ufl.edu> (Ben Bolker's message of "Fri,
	21 Dec 2007 10:58:04 -0500")
References: <476BE28C.2010203@zoo.ufl.edu>
Message-ID: <m0abo28wyx.fsf@bar.nemo-project.org>

Ben Bolker wrote:

> http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards
>
>  gives detailed advice on how to set the indentation level for
> C code to 4, but it took me a bit of poking around in the archives
> to find the
>
> (setq ess-indent-level 4)
>
> incantation for getting the R indentation right as well.

I'm confused.  Doesn't the suggested code 

(add-hook 'ess-mode-hook
               (lambda ()
                 (ess-set-style 'C++)
 ...

implicitly set ess-indent-level to 4?  At least for me, using the
suggested code gives indentation steps of 4 in R code.

-- 
Bj?rn-Helge Mevik


From hin-tak.leung at cimr.cam.ac.uk  Sat Dec 22 20:09:04 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Sat, 22 Dec 2007 19:09:04 +0000
Subject: [Rd] SHLIB steps on a Makefile
In-Reply-To: <dba1e14b0712201428n3c55c57fx71de164f3ea50f7@mail.gmail.com>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>	<Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
	<dba1e14b0712201428n3c55c57fx71de164f3ea50f7@mail.gmail.com>
Message-ID: <476D60D0.2040706@cimr.cam.ac.uk>

Hmm, I don't think you need a whole Makefile - while it is a
bit complicated to set locations, etc, essentially if your C code
needs an extra DLL (well, you'll have to bundle it with your package,
etc because the otherwise link-loader won't find it), it is mostly
just in Makevars.win

PGK_LDGLAGS=-lotherlib

'compiling against a DLL in a another package' is alright, but resolving 
the DLL at runtime won't be trivial (unless you set explicit dependency 
of your package against this other one) ; so you might be better off 
compiling against a static build of the other with yours.

Iago Mosqueira wrote:
<snipped>
> Many thanks for the information. I am trying to make a package C code
> compile against a DLL already present in another package, so I need to
> include its location in the call to gcc.  I'll see what the most
> portable system could be and will test widely.
> 
> Regards,
> 
> 
> Iago Mosqueira
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Dec 22 21:35:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Dec 2007 20:35:54 +0000 (GMT)
Subject: [Rd] SHLIB steps on a Makefile
In-Reply-To: <476D60D0.2040706@cimr.cam.ac.uk>
References: <dba1e14b0712201349t552a9409mb96b1007b3b6a483@mail.gmail.com>
	<Pine.LNX.4.64.0712202206210.11123@gannet.stats.ox.ac.uk>
	<dba1e14b0712201428n3c55c57fx71de164f3ea50f7@mail.gmail.com>
	<476D60D0.2040706@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0712222030420.19707@gannet.stats.ox.ac.uk>

On Sat, 22 Dec 2007, Hin-Tak Leung wrote:

> Hmm, I don't think you need a whole Makefile - while it is a
> bit complicated to set locations, etc, essentially if your C code
> needs an extra DLL (well, you'll have to bundle it with your package,
> etc because the otherwise link-loader won't find it), it is mostly
> just in Makevars.win
>
> PGK_LDGLAGS=-lotherlib
>
> 'compiling against a DLL in a another package' is alright, but resolving
> the DLL at runtime won't be trivial (unless you set explicit dependency
> of your package against this other one) ; so you might be better off
> compiling against a static build of the other with yours.

There is an interface to ensure that happens: details in 'Writing R 
Extensions'.  The 'live' example is lme4 'LinkingTo' on Matrix and stats.


> Iago Mosqueira wrote:
> <snipped>
>> Many thanks for the information. I am trying to make a package C code
>> compile against a DLL already present in another package, so I need to
>> include its location in the call to gcc.  I'll see what the most
>> portable system could be and will test widely.
>>
>> Regards,
>>
>>
>> Iago Mosqueira
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nmcalder at verizon.net  Sun Dec 23 18:44:15 2007
From: nmcalder at verizon.net (Matt Calder)
Date: Sun, 23 Dec 2007 12:44:15 -0500
Subject: [Rd] Problem with dyn.load'ed code
Message-ID: <1198431855.9564.10.camel@calder-linux>

Hi,
    I am having trouble with some code that I am dyn.loading. I am
writing an interface to ARPACK. I compile my interface (dssimp.cc), and
link it against the ARPACK library (libarpack_SUN4.a):

 g++ -shared -static -fPIC dssimp.cc -o dssimp.so -larpack_SUN4 -lg2c -lm 

I can dyn.load the code and it appears OK. However, when I call my
function, the call to the function in the ARPACK library returns an
error. 
	I can print the arguments to my function when I call it from R, so I
can see that I am dyn.load'd, and the arguments are passed correctly. 	
	Moreover, I can load and call the shared object (dssimp.so) using
dlopen and dlsym from a stand alone C++ program. So I can see that the
shared object is OK.
	In summary, I have a shared object that works correctly outside of R,
but when dyn.load'd into R, does not work. Short of calling errors
(which is not the case here) I wonder how that might happen, and how I
might fix it?

	Matt


From cstrato at aon.at  Sun Dec 23 23:36:34 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 23 Dec 2007 23:36:34 +0100
Subject: [Rd] Problem with initialize of S4 classes
Message-ID: <476EE2F2.4010500@aon.at>

Dear all

Below is the code for "scriptPreFilter.R" which gives the following result:
 > source("scriptPreFilter.R")
 > prefltr <- new("PreFilter", mad=c(0.5,0.01))
[1] "------initialize:PreFilter------"
[1] "------initialize:Filter------"
 > str(prefltr)
Formal class 'PreFilter' [package ".GlobalEnv"] with 2 slots
  ..@ mad       :List of 2
  .. ..$ cutoff : num 0.5
  .. ..$ epsilon: num 0.01
  ..@ numfilters: num 1

It seems that everything is ok, the results are as expected.

However, my problem is that copying the identical code to my package 
results in an error:
 > prefltr <- new("PreFilter", mad=c(0.5,0.01))
[1] "------setValidity:Filter------"
Error in validObject(.Object) :
  invalid class "PreFilter" object: invalid object for slot "mad" in 
class "PreFilter": got class "numeric", should be or extend class "list"

The following code avoids the error and gives the result:
 > prefltr <- new("PreFilter", mad=list(0.5,0.01))
[1] "------setValidity:Filter------"
[1] "------setValidity:PreFilter------"
 > str(prefltr)
Formal class 'PreFilter' [package "xps"] with 11 slots
  ..@ mad        :List of 2
  .. ..$ : num 0.5
  .. ..$ : num 0.01
  ..@ numfilters : num 0

This is only partly correct, e.g. numfilters is 0.

Only the following code gives the correct result:
 > prefltr <- new("PreFilter")
 > madFilter(prefltr) <- c(0.5,0.01)
 > str(prefltr)
Formal class 'PreFilter' [package "xps"] with 11 slots
  ..@ mad        :List of 2
  .. ..$ cutoff : num 0.5
  .. ..$ epsilon: num 0.01
  ..@ numfilters : num 1

As you see, the loading "scriptPreFilter.R" calls method initialize but 
not setValidity.
In contrast, loading my package as library calls setValidity but not 
initialize.

My question is:
- Why can the identical code behave differently when put in a package?
- How can I ensure, that initialize gets also called in my package?

 > sessionInfo()
R version 2.6.1 (2007-11-26)
i386-apple-darwin8.10.1

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] xps_0.4.0

loaded via a namespace (and not attached):
[1] rcompgen_0.1-17

Best regards and Merry Christmas
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
e.m.a.i.l:    cstrato at aon.at
_._._._._._._._._._._._._._._._


------- BEGIN: scriptPreFilter.R ---------
setClass("Filter",
   representation(numfilters = "numeric"),
   prototype(numfilters = 0)
)

setClass("PreFilter",
   representation(mad = "list"),
   contains=c("Filter"),
   prototype(mad = list())
)

setGeneric("madFilter",   function(object) standardGeneric("madFilter"))
setGeneric("madFilter<-", function(object, value) 
standardGeneric("madFilter<-"))

"initialize.Filter" <- function(.Object, ...)
{
   print("------initialize:Filter------")
   .Object <- callNextMethod(.Object, ...)
   .Object
}
setMethod("initialize", "Filter", initialize.Filter)

setValidity("Filter",
   function(object) {
      print("------setValidity:Filter------")
      msg <- NULL
      if (is.null(msg)) TRUE else msg
   }
)

"initialize.PreFilter" <- function(.Object, mad = list(), ...)
{
   print("------initialize:PreFilter------")
   .Object at numfilters <- 0
   if (length(mad)) madFilter(.Object) <- unlist(mad)
   .Object <- callNextMethod(.Object, ...)
   .Object
}
setMethod("initialize", "PreFilter", initialize.PreFilter)

setValidity("PreFilter",
   function(object) {
      print("------setValidity:PreFilter------")
      msg <- NULL
      if (is.null(msg)) TRUE else msg
   }
)

setMethod("madFilter", signature(object="PreFilter"),
   function(object) object at mad
)

setReplaceMethod("madFilter", signature(object="PreFilter", 
value="numeric"),
   function(object, value) {
      if (length(value) == 1) {
         value[2] <- 0.01
      } else if (length(value) != 2) {
         stop(paste(sQuote("mad"), "must have <cutoff,epsilon>"))
      }#if

      if (length(object at mad) == 0) {
         object at numfilters <- object at numfilters + 1
      }#if
      object at mad <- list(cutoff  = as.double(value[1]),
                         epsilon = as.double(value[2]))
      return(object)
   }
)
------- END: scriptPreFilter.R ---------


From hin-tak.leung at cimr.cam.ac.uk  Sun Dec 23 23:40:00 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Sun, 23 Dec 2007 22:40:00 +0000
Subject: [Rd] Problem with dyn.load'ed code
In-Reply-To: <1198431855.9564.10.camel@calder-linux>
References: <1198431855.9564.10.camel@calder-linux>
Message-ID: <476EE3C0.9080005@cimr.cam.ac.uk>

You are missing some extern "C" declarations? R needs C linkage style.
Basically a lot of:

extern "C" {

}

around your c++ code.


Matt Calder wrote:
> Hi,
>     I am having trouble with some code that I am dyn.loading. I am
> writing an interface to ARPACK. I compile my interface (dssimp.cc), and
> link it against the ARPACK library (libarpack_SUN4.a):
> 
>  g++ -shared -static -fPIC dssimp.cc -o dssimp.so -larpack_SUN4 -lg2c -lm 
> 
> I can dyn.load the code and it appears OK. However, when I call my
> function, the call to the function in the ARPACK library returns an
> error. 
> 	I can print the arguments to my function when I call it from R, so I
> can see that I am dyn.load'd, and the arguments are passed correctly. 	
> 	Moreover, I can load and call the shared object (dssimp.so) using
> dlopen and dlsym from a stand alone C++ program. So I can see that the
> shared object is OK.
> 	In summary, I have a shared object that works correctly outside of R,
> but when dyn.load'd into R, does not work. Short of calling errors
> (which is not the case here) I wonder how that might happen, and how I
> might fix it?
> 
> 	Matt
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bolker at ufl.edu  Mon Dec 24 00:31:23 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 23 Dec 2007 15:31:23 -0800 (PST)
Subject: [Rd] re quest for addition to R-int
In-Reply-To: <m0abo28wyx.fsf@bar.nemo-project.org>
References: <476BE28C.2010203@zoo.ufl.edu>
	<m0abo28wyx.fsf@bar.nemo-project.org>
Message-ID: <14482966.post@talk.nabble.com>




Bj?rn-Helge Mevik wrote:
> 
> Ben Bolker wrote:
> 
>> http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards
>>
>>  gives detailed advice on how to set the indentation level for
>> C code to 4, but it took me a bit of poking around in the archives
>> to find the
>>
>> (setq ess-indent-level 4)
>>
>> incantation for getting the R indentation right as well.
> 
> I'm confused.  Doesn't the suggested code 
> 
> (add-hook 'ess-mode-hook
>                (lambda ()
>                  (ess-set-style 'C++)
>  ...
> 
> implicitly set ess-indent-level to 4?  At least for me, using the
> suggested code gives indentation steps of 4 in R code.
> 
> -- 
> Bj?rn-Helge Mevik
> 
> ____
> 

  I guess, but since I was using emacs 21 I followed the
instructions to use customization instead -- and I guess
the customization steps don't include this hook ?

  Ben

-- 
View this message in context: http://www.nabble.com/request-for-addition-to-R-int-tp14457818p14482966.html
Sent from the R devel mailing list archive at Nabble.com.


From mtmorgan at fhcrc.org  Mon Dec 24 01:38:56 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 23 Dec 2007 16:38:56 -0800
Subject: [Rd] Problem with initialize of S4 classes
In-Reply-To: <476EE2F2.4010500@aon.at> (cstrato@aon.at's message of "Sun, 23
	Dec 2007 23:36:34 +0100")
References: <476EE2F2.4010500@aon.at>
Message-ID: <6phlk7lapun.fsf@gopher4.fhcrc.org>

Hi Christian --

Does your package have a name space, but not export 'initialize'?
Calling 'new' will then go directly to the default constructors,
generating the error. A different solution would be to define a
constructor in your package

PreFilter <- function(...) {
    new("PreFilter", ...)
}

so that your user would not have to know about the details of calling
new, you could provide helpful arguments to your constructor, and
'pre-processing' of arguments can be done (in the constructor) before
calling 'new' (I find this helpful, to avoid have to be too careful
when constructing initialize methods that deal with both the class and
classes derived from the class).

Martin

cstrato <cstrato at aon.at> writes:

> Dear all
>
> Below is the code for "scriptPreFilter.R" which gives the following result:
>  > source("scriptPreFilter.R")
>  > prefltr <- new("PreFilter", mad=c(0.5,0.01))
> [1] "------initialize:PreFilter------"
> [1] "------initialize:Filter------"
>  > str(prefltr)
> Formal class 'PreFilter' [package ".GlobalEnv"] with 2 slots
>   ..@ mad       :List of 2
>   .. ..$ cutoff : num 0.5
>   .. ..$ epsilon: num 0.01
>   ..@ numfilters: num 1
>
> It seems that everything is ok, the results are as expected.
>
> However, my problem is that copying the identical code to my package 
> results in an error:
>  > prefltr <- new("PreFilter", mad=c(0.5,0.01))
> [1] "------setValidity:Filter------"
> Error in validObject(.Object) :
>   invalid class "PreFilter" object: invalid object for slot "mad" in 
> class "PreFilter": got class "numeric", should be or extend class "list"
>
> The following code avoids the error and gives the result:
>  > prefltr <- new("PreFilter", mad=list(0.5,0.01))
> [1] "------setValidity:Filter------"
> [1] "------setValidity:PreFilter------"
>  > str(prefltr)
> Formal class 'PreFilter' [package "xps"] with 11 slots
>   ..@ mad        :List of 2
>   .. ..$ : num 0.5
>   .. ..$ : num 0.01
>   ..@ numfilters : num 0
>
> This is only partly correct, e.g. numfilters is 0.
>
> Only the following code gives the correct result:
>  > prefltr <- new("PreFilter")
>  > madFilter(prefltr) <- c(0.5,0.01)
>  > str(prefltr)
> Formal class 'PreFilter' [package "xps"] with 11 slots
>   ..@ mad        :List of 2
>   .. ..$ cutoff : num 0.5
>   .. ..$ epsilon: num 0.01
>   ..@ numfilters : num 1
>
> As you see, the loading "scriptPreFilter.R" calls method initialize but 
> not setValidity.
> In contrast, loading my package as library calls setValidity but not 
> initialize.
>
> My question is:
> - Why can the identical code behave differently when put in a package?
> - How can I ensure, that initialize gets also called in my package?
>
>  > sessionInfo()
> R version 2.6.1 (2007-11-26)
> i386-apple-darwin8.10.1
>
> locale:
> C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
>
> other attached packages:
> [1] xps_0.4.0
>
> loaded via a namespace (and not attached):
> [1] rcompgen_0.1-17
>
> Best regards and Merry Christmas
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> e.m.a.i.l:    cstrato at aon.at
> _._._._._._._._._._._._._._._._
>
>
> ------- BEGIN: scriptPreFilter.R ---------
> setClass("Filter",
>    representation(numfilters = "numeric"),
>    prototype(numfilters = 0)
> )
>
> setClass("PreFilter",
>    representation(mad = "list"),
>    contains=c("Filter"),
>    prototype(mad = list())
> )
>
> setGeneric("madFilter",   function(object) standardGeneric("madFilter"))
> setGeneric("madFilter<-", function(object, value) 
> standardGeneric("madFilter<-"))
>
> "initialize.Filter" <- function(.Object, ...)
> {
>    print("------initialize:Filter------")
>    .Object <- callNextMethod(.Object, ...)
>    .Object
> }
> setMethod("initialize", "Filter", initialize.Filter)
>
> setValidity("Filter",
>    function(object) {
>       print("------setValidity:Filter------")
>       msg <- NULL
>       if (is.null(msg)) TRUE else msg
>    }
> )
>
> "initialize.PreFilter" <- function(.Object, mad = list(), ...)
> {
>    print("------initialize:PreFilter------")
>    .Object at numfilters <- 0
>    if (length(mad)) madFilter(.Object) <- unlist(mad)
>    .Object <- callNextMethod(.Object, ...)
>    .Object
> }
> setMethod("initialize", "PreFilter", initialize.PreFilter)
>
> setValidity("PreFilter",
>    function(object) {
>       print("------setValidity:PreFilter------")
>       msg <- NULL
>       if (is.null(msg)) TRUE else msg
>    }
> )
>
> setMethod("madFilter", signature(object="PreFilter"),
>    function(object) object at mad
> )
>
> setReplaceMethod("madFilter", signature(object="PreFilter", 
> value="numeric"),
>    function(object, value) {
>       if (length(value) == 1) {
>          value[2] <- 0.01
>       } else if (length(value) != 2) {
>          stop(paste(sQuote("mad"), "must have <cutoff,epsilon>"))
>       }#if
>
>       if (length(object at mad) == 0) {
>          object at numfilters <- object at numfilters + 1
>       }#if
>       object at mad <- list(cutoff  = as.double(value[1]),
>                          epsilon = as.double(value[2]))
>       return(object)
>    }
> )
> ------- END: scriptPreFilter.R ---------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From rcwright at texas.net  Mon Dec 24 07:00:23 2007
From: rcwright at texas.net (rcwright at texas.net)
Date: Mon, 24 Dec 2007 07:00:23 +0100 (CET)
Subject: [Rd] Errors in demo (PR#10527)
Message-ID: <20071224060023.90263282EFF7@mail.pubhealth.ku.dk>

Full_Name: richard wright
Version: R version 2.6.1 (2007-11-26)
OS: Mac OS X v 10.4.11
Submission from: (NULL) (76.240.79.123)


I downloaded the most recent version of  R for the mac (About: GUI 1.22-devel
(4859) (4859)) and installed it.
After installation, I opened the help file and ran the demo. I am new to R,
although I have over 25 years experience in SAS.

Below is a part of the job I ran. I think I ran the code correctly, but I seem
to be blowing off.
And, I'm not sure it's related, but I also included what I got when I ran
bug.report()

> dummy <- data.frame(x=x, y =x+rnorm(x)*w)
> dummy
    x         y
1   1  1.425904
2   2 -1.083024
3   3 -1.976215
4   4  4.185795
5   5  8.598591
6   6  1.004177
7   7  5.357826
8   8  9.033184
9   9  6.455373
10 10  8.166066
11 11 12.383454
12 12 10.823910
13 13 14.410394
14 14 13.046184
15 15 15.912303
16 16 13.454527
17 17 15.827133
18 18 18.586979
19 19 10.845216
20 20 20.935347
> fm <-lm(y-x,data=dummy)
Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
  invalid formula
In addition: Warning message:
In y - x : longer object length is not a multiple of shorter object length
> ls()
[1] "dummy" "w"     "x"     "y"    
> bug.report()
Error in bug.report() : 'subject' missing
>


From iago.mosqueira at gmail.com  Mon Dec 24 12:16:22 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Mon, 24 Dec 2007 12:16:22 +0100
Subject: [Rd] Errors in demo (PR#10527)
In-Reply-To: <mailman.15.1198494002.12824.r-devel@r-project.org>
References: <mailman.15.1198494002.12824.r-devel@r-project.org>
Message-ID: <476F9506.30204@gmail.com>

 > Date: Mon, 24 Dec 2007 07:00:23 +0100 (CET)
 > From: rcwright at texas.net Subject: [Rd] Errors in demo (PR#10527)
 > To: r-devel at stat.math.ethz.ch

 > R version 2.6.1 (2007-11-26) OS: Mac OS X v 10.4.11
 > Submission from: (NULL) (76.240.79.123)

 > I downloaded the most recent version of R for the mac (About: GUI
 > 1.22-devel (4859) (4859)) and installed it. After installation, I
 > opened the help file and ran the demo. I am new to R, although I have
 > over 25 years experience in SAS. Below is a part of the job I ran. I
 > think I ran the code correctly, but I seem to be blowing off. And, I'm
 > not sure it's related, but I also included what I got when I ran
 > bug.report()
 > > dummy <- data.frame(x=x, y =x+rnorm(x)*w)
 > > dummy
     x         y
1   1  1.425904
2   2 -1.083024
3   3 -1.976215
4   4  4.185795
5   5  8.598591
6   6  1.004177
7   7  5.357826
8   8  9.033184
9   9  6.455373
10 10  8.166066
11 11 12.383454
12 12 10.823910
13 13 14.410394
14 14 13.046184
15 15 15.912303
16 16 13.454527
17 17 15.827133
18 18 18.586979
19 19 10.845216
20 20 20.935347
 > > fm <-lm(y-x,data=dummy)
 > Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"), 
  : invalid formula

 > In addition: Warning message:

 > In y - x : longer object length is not a multiple of shorter object 
length
 > > ls()
[1] "dummy" "w"     "x"     "y"
 > > bug.report()
Error in bug.report() : 'subject' missing


Hi,

The formula should be

fm <-lm(y~x,data=dummy)

instead of the minus sign

What help file are you referring to?


Iago


From iago.mosqueira at gmail.com  Mon Dec 24 12:19:29 2007
From: iago.mosqueira at gmail.com (Iago Mosqueira)
Date: Mon, 24 Dec 2007 12:19:29 +0100
Subject: [Rd] Errors in demo (PR#10527)
In-Reply-To: <mailman.15.1198494002.12824.r-devel@r-project.org>
References: <mailman.15.1198494002.12824.r-devel@r-project.org>
Message-ID: <476F95C1.801@gmail.com>

 > Date: Mon, 24 Dec 2007 07:00:23 +0100 (CET)
 > From: rcwright at texas.net Subject: [Rd] Errors in demo (PR#10527)
 > To: r-devel at stat.math.ethz.ch

 > R version 2.6.1 (2007-11-26) OS: Mac OS X v 10.4.11
 > Submission from: (NULL) (76.240.79.123)

 > I downloaded the most recent version of R for the mac (About: GUI
 > 1.22-devel (4859) (4859)) and installed it. After installation, I
 > opened the help file and ran the demo. I am new to R, although I have
 > over 25 years experience in SAS. Below is a part of the job I ran. I
 > think I ran the code correctly, but I seem to be blowing off. And, I'm
 > not sure it's related, but I also included what I got when I ran
 > bug.report()
 > > dummy <- data.frame(x=x, y =x+rnorm(x)*w)
 > > dummy
     x         y
1   1  1.425904
2   2 -1.083024
3   3 -1.976215
4   4  4.185795
5   5  8.598591
6   6  1.004177
7   7  5.357826
8   8  9.033184
9   9  6.455373
10 10  8.166066
11 11 12.383454
12 12 10.823910
13 13 14.410394
14 14 13.046184
15 15 15.912303
16 16 13.454527
17 17 15.827133
18 18 18.586979
19 19 10.845216
20 20 20.935347
 > > fm <-lm(y-x,data=dummy)
 > Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"), 
  : invalid formula

 > In addition: Warning message:

 > In y - x : longer object length is not a multiple of shorter object 
length
 > > ls()
[1] "dummy" "w"     "x"     "y"
 > > bug.report()
Error in bug.report() : 'subject' missing


Hi,

The formula should be

fm <-lm(y~x,data=dummy)

instead of the minus sign

What help file are you referring to? The example in R-intro you might be 
talking about reads, as expected,

fm <- lm(y ~ x, data=dummy)


Iago


From murdoch at stats.uwo.ca  Mon Dec 24 12:20:28 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Dec 2007 06:20:28 -0500
Subject: [Rd] Errors in demo (PR#10527)
In-Reply-To: <20071224060023.90263282EFF7@mail.pubhealth.ku.dk>
References: <20071224060023.90263282EFF7@mail.pubhealth.ku.dk>
Message-ID: <476F95FC.5080405@stats.uwo.ca>

On 24/12/2007 1:00 AM, rcwright at texas.net wrote:
> Full_Name: richard wright
> Version: R version 2.6.1 (2007-11-26)
> OS: Mac OS X v 10.4.11
> Submission from: (NULL) (76.240.79.123)
> 
> 
> I downloaded the most recent version of  R for the mac (About: GUI 1.22-devel
> (4859) (4859)) and installed it.
> After installation, I opened the help file and ran the demo. I am new to R,
> although I have over 25 years experience in SAS.
> 
> Below is a part of the job I ran. I think I ran the code correctly, but I seem
> to be blowing off.
> And, I'm not sure it's related, but I also included what I got when I ran
> bug.report()
> 
>> dummy <- data.frame(x=x, y =x+rnorm(x)*w)
>> dummy
>     x         y
> 1   1  1.425904
> 2   2 -1.083024
> 3   3 -1.976215
> 4   4  4.185795
> 5   5  8.598591
> 6   6  1.004177
> 7   7  5.357826
> 8   8  9.033184
> 9   9  6.455373
> 10 10  8.166066
> 11 11 12.383454
> 12 12 10.823910
> 13 13 14.410394
> 14 14 13.046184
> 15 15 15.912303
> 16 16 13.454527
> 17 17 15.827133
> 18 18 18.586979
> 19 19 10.845216
> 20 20 20.935347
>> fm <-lm(y-x,data=dummy)
> Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  : 
>   invalid formula

This looks like your error, rather than a bug in R.  The formula should 
be "y ~ x" (y tilde x), not "y - x".

> In addition: Warning message:
> In y - x : longer object length is not a multiple of shorter object length

This warning is also a consequence of the typo, in a roundabout way.  It 
is saying that x and y are different lengths, which is clearly not true 
for the columns of dummy:  but because you just subtracted them, it took 
x and y to be variables in their own right, not columns.  Presumably the 
objects listed below are different lengths.

>> ls()
> [1] "dummy" "w"     "x"     "y"    
>> bug.report()
> Error in bug.report() : 'subject' missing

Please check on R-help or R-devel first, until you're sure something is 
a bug.  It takes a bit of effort to deal with a bug report regardless of 
whether it is real or not.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Dec 24 12:35:14 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 24 Dec 2007 12:35:14 +0100 (CET)
Subject: [Rd] Errors in demo (PR#10527)
Message-ID: <20071224113514.4FBC9282EFF7@mail.pubhealth.ku.dk>

I have no idea what 'demo' this is.  When I open R it says

   Type 'demo()' for some demos, 'help()' for on-line help, or
   'help.start()' for an HTML browser interface to help.

and this is none of those.  At a guess you meant

x <- 1:20
w <- 1 + sqrt(x)/2
dummy <- data.frame(x=x, y= x + rnorm(x)*w)
dummy
fm <- lm(y ~ x, data=dummy)

from the 'sample session' in 'An Introduction to R'.  In which case, this 
is your own typing error (- for ~, and we do put spaces in to make it 
easier to read).

Please do read the R FAQ *before* 'blowing off' a false report.

On Mon, 24 Dec 2007, rcwright at texas.net wrote:

> Full_Name: richard wright
> Version: R version 2.6.1 (2007-11-26)
> OS: Mac OS X v 10.4.11
> Submission from: (NULL) (76.240.79.123)
>
>
> I downloaded the most recent version of  R for the mac (About: GUI 1.22-devel
> (4859) (4859)) and installed it.
> After installation, I opened the help file and ran the demo. I am new to R,
> although I have over 25 years experience in SAS.
>
> Below is a part of the job I ran. I think I ran the code correctly, but I seem
> to be blowing off.
> And, I'm not sure it's related, but I also included what I got when I ran
> bug.report()
>
>> dummy <- data.frame(x=x, y =x+rnorm(x)*w)
>> dummy
>    x         y
> 1   1  1.425904
> 2   2 -1.083024
> 3   3 -1.976215
> 4   4  4.185795
> 5   5  8.598591
> 6   6  1.004177
> 7   7  5.357826
> 8   8  9.033184
> 9   9  6.455373
> 10 10  8.166066
> 11 11 12.383454
> 12 12 10.823910
> 13 13 14.410394
> 14 14 13.046184
> 15 15 15.912303
> 16 16 13.454527
> 17 17 15.827133
> 18 18 18.586979
> 19 19 10.845216
> 20 20 20.935347
>> fm <-lm(y-x,data=dummy)
> Error in switch(mode(x), "NULL" = structure(NULL, class = "formula"),  :
>  invalid formula
> In addition: Warning message:
> In y - x : longer object length is not a multiple of shorter object length
>> ls()
> [1] "dummy" "w"     "x"     "y"
>> bug.report()
> Error in bug.report() : 'subject' missing
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Dec 24 14:09:29 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 24 Dec 2007 14:09:29 +0100
Subject: [Rd] re quest for addition to R-int
In-Reply-To: <14482966.post@talk.nabble.com>
References: <476BE28C.2010203@zoo.ufl.edu>
	<m0abo28wyx.fsf@bar.nemo-project.org>
	<14482966.post@talk.nabble.com>
Message-ID: <18287.44937.608015.137096@ada-stat.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Sun, 23 Dec 2007 15:31:23 -0800 (PST) writes:

    BB> Bj?rn-Helge Mevik wrote:
    >> 
    >> Ben Bolker wrote:
    >> 
    >>> http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards
    >>> 
    >>> gives detailed advice on how to set the indentation level for
    >>> C code to 4, but it took me a bit of poking around in the archives
    >>> to find the
    >>> 
    >>> (setq ess-indent-level 4)
    >>> 
    >>> incantation for getting the R indentation right as well.
    >> 
    >> I'm confused.  Doesn't the suggested code 
    >> 
    >> (add-hook 'ess-mode-hook
    >>  (lambda ()
    >>   (ess-set-style 'C++)
    >> ...
    >> 
    >> implicitly set ess-indent-level to 4?  At least for me, using the
    >> suggested code gives indentation steps of 4 in R code.
    >> 
    >> -- 
    >> Bj?rn-Helge Mevik
    >> 
    >> ____
    >> 

    BB> I guess, but since I was using emacs 21 I followed the
    BB> instructions to use customization instead -- and I guess
    BB> the customization steps don't include this hook ?


I'm confused, too, Ben.

Why exactly are you not willing to use the above (add-hook ...) ?

Is this an "unfortunate" wording of the "Writing R Ext.." manual?

Regards,
Martin


From cstrato at aon.at  Mon Dec 24 14:16:15 2007
From: cstrato at aon.at (cstrato)
Date: Mon, 24 Dec 2007 14:16:15 +0100
Subject: [Rd] Problem with initialize of S4 classes
In-Reply-To: <6phlk7lapun.fsf@gopher4.fhcrc.org>
References: <476EE2F2.4010500@aon.at> <6phlk7lapun.fsf@gopher4.fhcrc.org>
Message-ID: <476FB11F.1020200@aon.at>

Dear Martin

Thank you for your comments!

You are correct, I have a name space but did not export "initialize",
since I thought that a user will never need to use it.

I will also try your suggestion to define a constructor in my package,
this seems to me to be a great idea.

Merry Christmas
Christian

Martin Morgan wrote:
> Hi Christian --
>
> Does your package have a name space, but not export 'initialize'?
> Calling 'new' will then go directly to the default constructors,
> generating the error. A different solution would be to define a
> constructor in your package
>
> PreFilter <- function(...) {
>     new("PreFilter", ...)
> }
>
> so that your user would not have to know about the details of calling
> new, you could provide helpful arguments to your constructor, and
> 'pre-processing' of arguments can be done (in the constructor) before
> calling 'new' (I find this helpful, to avoid have to be too careful
> when constructing initialize methods that deal with both the class and
> classes derived from the class).
>
> Martin
>
> cstrato <cstrato at aon.at> writes:
>
>   
>> Dear all
>>
>> Below is the code for "scriptPreFilter.R" which gives the following result:
>>  > source("scriptPreFilter.R")
>>  > prefltr <- new("PreFilter", mad=c(0.5,0.01))
>> [1] "------initialize:PreFilter------"
>> [1] "------initialize:Filter------"
>>  > str(prefltr)
>> Formal class 'PreFilter' [package ".GlobalEnv"] with 2 slots
>>   ..@ mad       :List of 2
>>   .. ..$ cutoff : num 0.5
>>   .. ..$ epsilon: num 0.01
>>   ..@ numfilters: num 1
>>
>> It seems that everything is ok, the results are as expected.
>>
>> However, my problem is that copying the identical code to my package 
>> results in an error:
>>  > prefltr <- new("PreFilter", mad=c(0.5,0.01))
>> [1] "------setValidity:Filter------"
>> Error in validObject(.Object) :
>>   invalid class "PreFilter" object: invalid object for slot "mad" in 
>> class "PreFilter": got class "numeric", should be or extend class "list"
>>
>> The following code avoids the error and gives the result:
>>  > prefltr <- new("PreFilter", mad=list(0.5,0.01))
>> [1] "------setValidity:Filter------"
>> [1] "------setValidity:PreFilter------"
>>  > str(prefltr)
>> Formal class 'PreFilter' [package "xps"] with 11 slots
>>   ..@ mad        :List of 2
>>   .. ..$ : num 0.5
>>   .. ..$ : num 0.01
>>   ..@ numfilters : num 0
>>
>> This is only partly correct, e.g. numfilters is 0.
>>
>> Only the following code gives the correct result:
>>  > prefltr <- new("PreFilter")
>>  > madFilter(prefltr) <- c(0.5,0.01)
>>  > str(prefltr)
>> Formal class 'PreFilter' [package "xps"] with 11 slots
>>   ..@ mad        :List of 2
>>   .. ..$ cutoff : num 0.5
>>   .. ..$ epsilon: num 0.01
>>   ..@ numfilters : num 1
>>
>> As you see, the loading "scriptPreFilter.R" calls method initialize but 
>> not setValidity.
>> In contrast, loading my package as library calls setValidity but not 
>> initialize.
>>
>> My question is:
>> - Why can the identical code behave differently when put in a package?
>> - How can I ensure, that initialize gets also called in my package?
>>
>>  > sessionInfo()
>> R version 2.6.1 (2007-11-26)
>> i386-apple-darwin8.10.1
>>
>> locale:
>> C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base     
>>
>> other attached packages:
>> [1] xps_0.4.0
>>
>> loaded via a namespace (and not attached):
>> [1] rcompgen_0.1-17
>>
>> Best regards and Merry Christmas
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> e.m.a.i.l:    cstrato at aon.at
>> _._._._._._._._._._._._._._._._
>>


From bolker at ufl.edu  Mon Dec 24 17:38:45 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 24 Dec 2007 16:38:45 +0000 (UTC)
Subject: [Rd] re quest for addition to R-int
References: <476BE28C.2010203@zoo.ufl.edu>
	<m0abo28wyx.fsf@bar.nemo-project.org>
	<14482966.post@talk.nabble.com>
	<18287.44937.608015.137096@ada-stat.math.ethz.ch>
Message-ID: <loom.20071224T155047-209@post.gmane.org>

Martin Maechler <maechler <at> stat.math.ethz.ch> writes:

> 
> >>>>> "BB" == Ben Bolker <bolker <at> ufl.edu>
> >>>>>     on Sun, 23 Dec 2007 15:31:23 -0800 (PST) writes:
> 
>     BB> Bj?rn-Helge Mevik wrote:
>     >> 
>     >> Ben Bolker wrote:
>     >> 
>     >>> http://cran.r-project.org/doc/manuals/R-ints.html#R-coding-standards
>     >>> 
>     >>> gives detailed advice on how to set the indentation level for
>     >>> C code to 4, but it took me a bit of poking around in the archives
>     >>> to find the
>     >>> 
>     >>> (setq ess-indent-level 4)
>     >>> 
>     >>> incantation for getting the R indentation right as well.
>     >> 
>     >> I'm confused.  Doesn't the suggested code 
>     >> 
>     >> (add-hook 'ess-mode-hook
>     >>  (lambda ()
>     >>   (ess-set-style 'C++)
>     >> ...
>     >> 
>     >> implicitly set ess-indent-level to 4?  At least for me, using the
>     >> suggested code gives indentation steps of 4 in R code.
>     >> 
>     >> -- 
>     >> Bj?rn-Helge Mevik
>     >> 
>     >> ____
>     >> 
> 
>     BB> I guess, but since I was using emacs 21 I followed the
>     BB> instructions to use customization instead -- and I guess
>     BB> the customization steps don't include this hook ?
> 
> I'm confused, too, Ben.
> 
> Why exactly are you not willing to use the above (add-hook ...) ?
> 
> Is this an "unfortunate" wording of the "Writing R Ext.." manual?
> 
> Regards,
> Martin

 The current paragraph says:
   
    It is also important that code is written in a way that allows others to
understand it. This
is particularly helpful for fixing problems, and includes using self-descriptive
variable names,
commenting the code, and also formatting it properly. The R Core Team recommends
to use a
basic indentation of 4 for R and C (and most likely also Perl) code, and 2 for
documentation in
Rd format. Emacs users can implement this indentation style by putting the
following in one
of their startup files. (For GNU Emacs 20: for GNU Emacs 21 or later use
customization to set
the c-default-style to "bsd" and c-basic-offset to 4.)

  [followed by emacs code, including the ESS stuff]

  I read the paragraph above and assumed that I could (and
should) use the customization hooks in Emacs 21 rather than
putting the code in my .emacs file by hand.  In fact, I'm
a little confused; the customization recommended appears to
have set the following ...

(custom-set-variables
  ;; custom-set-variables was added by Custom -- don't edit or cut/paste it!
  ;; Your init file should contain only one such instance.
 '(c-basic-offset 4)
 '(c-default-style (quote ((c-mode . "bsd") (java-mode . "java") (other . "gnu")))))

  which takes care of the C mode stuff but doesn't do anything
for ESS or Perl?

 Perhaps change the last sentence to

  (In GNU Emacs 21 or later one can instead use customization to set
the c-default-style to "bsd" and c-basic-offset to 4, although
the ESS and Perl styles still need to be set manually.)

  ?

  Ben


From bolker at ufl.edu  Mon Dec 24 18:56:22 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 24 Dec 2007 12:56:22 -0500
Subject: [Rd] R-ints typos
Message-ID: <476FF2C6.80103@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  "Internationalization" is misspelled (as
"Internationaliation") throughout the R-ints
document ... I ran ispell on the texi document,
diffs for this and a handful of other minor
typos (fron/from, primiitve/primitive, etc.)
are posted at http://www.zoo.ufl.edu/bolker/R-ints_diff.txt ...

   cheers
     Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD4DBQFHb/LGc5UpGjwzenMRAv82AJdSx8PcYXi0dFTo4XatJzZ5WO4HAJ47acGW
bA/phOy/h/BwLS7RK1b62Q==
=YdLf
-----END PGP SIGNATURE-----


From Stephen.Pope at ubs.com  Mon Dec 24 21:42:18 2007
From: Stephen.Pope at ubs.com (Stephen.Pope at ubs.com)
Date: Mon, 24 Dec 2007 13:42:18 -0700
Subject: [Rd] callNextMethod() with builtin group methods fails to create
	proper environment
Message-ID: <AA40204837EA4B409923099DAA9DB2E6A829@nstf0100pex.ubsw.net>

Hi all,

After all these years, I am finally porting some R-2.3.1-based S4 object
code to R-2.6.1, dealing with all the S4 object system changes that came
in R-2.4.0.

I've run across what appears to be some sort of ommission in the
implementation of callNextMethod() when used with primitives having
group generic methods.

In a stock R-2.6.1 patched (happens to be running on AMD64/RHEL 4, but
that shouldn't matter), the following occurs:

R version 2.6.1 Patched (2007-12-03 r43584)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
 ,,,

> options(error=quote(traceback()))
> setClass("Foo", contains="matrix")
[1] "Foo"
> setMethod("Compare", signature(e1="Foo", e2="Foo"), function(e1, e2) {
callNextMethod() })
[1] "Compare"
> f1 = new("Foo")
> f1 == f1
Error in get(fname, envir = envir) : variable ".nextMethod" was not
found
7: get(fname, envir = envir)
6: callGeneric(e1 at .Data, e2 at .Data)
5: .nextMethod(e1 = e1, e2 = e2)
4: .Call("R_nextMethodCall", call, callEnv, PACKAGE = "methods")
3: callNextMethod()
2: f1 == f1
1: f1 == f1

It appears that the issue occurs because the particular set of branches
through the logic of callNextMethod() which result because the next
method, which happens to be:

> selectMethod("Compare", signature("array","array"))
Method Definition:

function (e1, e2)
callGeneric(e1 at .Data, e2 at .Data)
<environment: 0x1582960>

Signatures:
        e1      e2
target  "array" "array"
defined "array" "array"


does not get the various "magic" variables such as .Generic, .Method,
etc. defined in its frame. Thus, callGeneric() fails when, failing to
find ".Generic" then takes the function symbol for the call (which
callNextMethod() has constructed to be ".nextMethod") and attempts to
look it up, which of course also fails, leading to the resulting error
seen above.

The obvious workaround is to avoid callNextMethod() when I know the next
method is one of these primitive group generics, replacing it with the
body of that generic method directly. Straightforward, but unfortunate.

stephen pope
Prediction Company LLC/UBS AG
stephen.pope at ubs.com


-------------- next part --------------
Visit our website at http://www.ubs.com

This message contains confidential information and is intended only 
for the individual named.  If you are not the named addressee you 
should not disseminate, distribute or copy this e-mail.  Please 
notify the sender immediately by e-mail if you have received this 
e-mail by mistake and delete this e-mail from your system.
	
E-mails are not encrypted and cannot be guaranteed to be secure or 
error-free as information could be intercepted, corrupted, lost, 
destroyed, arrive late or incomplete, or contain viruses.  The sender 
therefore does not accept liability for any errors or omissions in the 
contents of this message which arise as a result of e-mail transmission.  
If verification is required please request a hard-copy version.  This 
message is provided for informational purposes and should not be 
construed as a solicitation or offer to buy or sell any securities 
or related financial instruments.

From ggrothendieck at gmail.com  Wed Dec 26 19:09:50 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Dec 2007 13:09:50 -0500
Subject: [Rd] Predictable grid names
Message-ID: <971536df0712261009n70ae1449n70e24040c33f7794@mail.gmail.com>

One thing that makes modifying lattice grid objects difficult is that if
you create the same plot twice you get different grid names for
some grid objects:

1. I wonder if there is some possibility in grid to reset the
names after a grid.newpage(), say, so that one can get predictable
names or some other strategy for getting predictable names.
Sort of like a set.seed() for grid except this has nothing to do with
random numbers.

2. grid.ls() is a great improvement over what previously existed but another
thing that would be nice would be to be able to list out more info with
the grid object so one can more easily identify it.  Sort of like ls -l.
And/or maybe a where clause restricting which objects are listed, e.g. just
list grid objects that are dark green.  I have been using the
following to show the
color values (which displays them if they are in the gp list but not
otherwise) but it would be nice to have something more general and
built in.  Or perhaps something already exists that I am not aware of.

library(lattice)
library(grid)
# show tree with names and col values
recurse <- function(x, indent = "") {
  if (!is.null(x$name)) {
	cat(indent, x$name)
	if (!is.null(x$gp)) cat(" col:", x$gp$col)
	cat("\n")
  }
  for (ch in x$children) Recall(ch, indent = paste(indent, "."))
}
xyplot(Sepal.Length ~ Sepal.Width, iris, group = Species, col = 11:13,
  auto.key = TRUE)
gg <- grid.grab()
recurse(gg)


From ggrothendieck at gmail.com  Wed Dec 26 19:26:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Dec 2007 13:26:17 -0500
Subject: [Rd] seekViewport error
Message-ID: <971536df0712261026w6bdebe49re08ed45e28af8873@mail.gmail.com>

Why does the seekViewport at the bottom give an error?

> xyplot(Sepal.Length ~ Sepal.Width, iris, group = Species, col = 11:13,
+   auto.key = TRUE)
> grid.ls(view = TRUE)
ROOT
  GRID.rect.89
  plot1.toplevel.vp
    plot1.xlab.vp
      plot1.xlab
      1
    plot1.ylab.vp
      plot1.ylab
      1
    plot1.strip.1.1.off.vp
      GRID.segments.90
      1
    plot1.strip.left.1.1.off.vp
      GRID.segments.91
      GRID.text.92
      1
    plot1.panel.1.1.off.vp
      GRID.segments.93
      GRID.text.94
      GRID.segments.95
      1
    plot1.panel.1.1.vp
      GRID.points.96
      GRID.points.97
      GRID.points.98
      1
    plot1.panel.1.1.off.vp
      GRID.rect.99
      1
    plot1.legend.top.vp
      GRID.frame.70
        GRID.VP.18
          GRID.cellGrob.72
            GRID.rect.71
          1
        GRID.VP.19
          GRID.cellGrob.74
            GRID.text.73
          1
        GRID.VP.20
          GRID.cellGrob.76
            GRID.text.75
          1
        GRID.VP.21
          GRID.cellGrob.78
            GRID.text.77
          1
        GRID.VP.22
          GRID.cellGrob.80
            GRID.points.79
          1
        GRID.VP.23
          GRID.cellGrob.82
            GRID.points.81
          1
        GRID.VP.24
          GRID.cellGrob.84
            GRID.points.83
          1
      1
    plot1.
      1
    1
> seekViewport("GRID.VP.24")
Error in downViewport.vpPath(vpPathDirect(name), strict, recording =
recording) :
  Viewport 'GRID.VP.24' was not found

> R.version.string # Vista
[1] "R version 2.6.1 Patched (2007-12-06 r43610)"
> packageDescription("grid")$Version
[1] "2.6.1"
> packageDescription("lattice")$Version
[1] "0.17-2"


From jrecta at gmail.com  Thu Dec 27 08:00:23 2007
From: jrecta at gmail.com (jrecta at gmail.com)
Date: Thu, 27 Dec 2007 08:00:23 +0100 (CET)
Subject: [Rd] x=.94 (PR#10529)
Message-ID: <20071227070024.05CDF2834158@mail.pubhealth.ku.dk>

I am using R Version 2.6.2007-11-23.  I do not know if the problem exists
for other values or versions

I encountered a problem when searching for the number 0.94 and 0.95 in a
vector of values.  I illustrate it below by creating a sequence of values 2
ways and then looking for the value 0.94 (same result for 0.95).  It looks
like the vector generated by seq( ) is a bit off:

> a<-seq(.9,.95,by=.01)
> a
[1] 0.90 0.91 0.92 0.93 0.94 0.95

> b<-c(.90,.91,.92,.93,.94,.95)
> b
[1] 0.90 0.91 0.92 0.93 0.94 0.95

> a==.94
[1] FALSE FALSE FALSE FALSE FALSE FALSE
> b==.94
[1] FALSE FALSE FALSE FALSE  TRUE FALSE

> a-b
[1] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.110223e-16
[6] 1.110223e-16

	[[alternative HTML version deleted]]


From p.dalgaard at biostat.ku.dk  Thu Dec 27 15:11:06 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 27 Dec 2007 15:11:06 +0100
Subject: [Rd] x=.94 (PR#10529)
In-Reply-To: <20071227070024.05CDF2834158@mail.pubhealth.ku.dk>
References: <20071227070024.05CDF2834158@mail.pubhealth.ku.dk>
Message-ID: <4773B27A.8040701@biostat.ku.dk>

jrecta at gmail.com wrote:
> I am using R Version 2.6.2007-11-23.  I do not know if the problem exists
> for other values or versions
>
> I encountered a problem when searching for the number 0.94 and 0.95 in a
> vector of values.  I illustrate it below by creating a sequence of values 2
> ways and then looking for the value 0.94 (same result for 0.95).  It looks
> like the vector generated by seq( ) is a bit off:
>
>   
>> a<-seq(.9,.95,by=.01)
>> a
>>     
> [1] 0.90 0.91 0.92 0.93 0.94 0.95
>
>   
>> b<-c(.90,.91,.92,.93,.94,.95)
>> b
>>     
> [1] 0.90 0.91 0.92 0.93 0.94 0.95
>
>   
>> a==.94
>>     
> [1] FALSE FALSE FALSE FALSE FALSE FALSE
>   
>> b==.94
>>     
> [1] FALSE FALSE FALSE FALSE  TRUE FALSE
>
>   
>> a-b
>>     
> [1] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.110223e-16
> [6] 1.110223e-16
>
> 	[[alternative HTML version deleted]]
>
>   
*Sigh*

FAQ 7.31

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Thu Dec 27 15:14:38 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 27 Dec 2007 15:14:38 +0100
Subject: [Rd] x=.94 (PR#10529)
In-Reply-To: <20071227070024.05CDF2834158@mail.pubhealth.ku.dk>
References: <20071227070024.05CDF2834158@mail.pubhealth.ku.dk>
Message-ID: <4773B34E.409@statistik.uni-dortmund.de>

Please do read the R FAQ:
"Why doesn't R think these numbers are equal?"

and before posting, you should have read the R FAQ:
"What is a bug?"

that points you to the former FAQ!

Uwe Ligges





jrecta at gmail.com wrote:
> I am using R Version 2.6.2007-11-23.  I do not know if the problem exists
> for other values or versions
> 
> I encountered a problem when searching for the number 0.94 and 0.95 in a
> vector of values.  I illustrate it below by creating a sequence of values 2
> ways and then looking for the value 0.94 (same result for 0.95).  It looks
> like the vector generated by seq( ) is a bit off:
> 
>> a<-seq(.9,.95,by=.01)
>> a
> [1] 0.90 0.91 0.92 0.93 0.94 0.95
> 
>> b<-c(.90,.91,.92,.93,.94,.95)
>> b
> [1] 0.90 0.91 0.92 0.93 0.94 0.95
> 
>> a==.94
> [1] FALSE FALSE FALSE FALSE FALSE FALSE
>> b==.94
> [1] FALSE FALSE FALSE FALSE  TRUE FALSE
> 
>> a-b
> [1] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.110223e-16
> [6] 1.110223e-16
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Dec 27 15:49:57 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 Dec 2007 15:49:57 +0100
Subject: [Rd] R-ints typos
In-Reply-To: <476FF2C6.80103@ufl.edu>
References: <476FF2C6.80103@ufl.edu>
Message-ID: <18291.48021.193228.747600@ada-stat.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Mon, 24 Dec 2007 12:56:22 -0500 writes:

    BB> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1


    BB>   "Internationalization" is misspelled (as
    BB> "Internationaliation") throughout the R-ints document
    BB> ... I ran ispell on the texi document, diffs for this
    BB> and a handful of other minor typos (fron/from,
    BB> primiitve/primitive, etc.)  are posted at
    BB> http://www.zoo.ufl.edu/bolker/R-ints_diff.txt ...

Thank  you, Ben, for the Christmas present.
I've applied your patches to R-devel (only; the last R-int.texi
changes were also only done there...).

Regards, Martin Maechler

    BB>    cheers Ben Bolker


From office at matthiaswendel.de  Thu Dec 27 21:11:42 2007
From: office at matthiaswendel.de (Matthias Wendel)
Date: Thu, 27 Dec 2007 21:11:42 +0100
Subject: [Rd] encoding question again
Message-ID: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>

Hi, R Devils,
I'm running the actual R version in JGR (version 1.5-8 ). Sys.getlocale(category = "LC_ALL") yields
[1] "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"

I want to write some HTML-Code enhanced by statistical results and labels encoded in Latin-1, which I pass to a function. Some label shall generate the filename. Although the labels are correctly handled in JGR they are somehow converted when they are written to the file. Also the filename is not constructed as wanted. The function definition is correctly sourced into R. The function is defined like this:

Itemtabelle.head <- function (abt ){
   # n?r z?m T?ST
   zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt", encoding = "UTF-8")
   cat(as.character("<html xmlns:o=\"urn:schemas-microsoft-com:office:office\" xmlns:x=\"urn:schemas-microsoft-com:office:excel\" xmlns=\"http://www.w3.org/TR/REC-html40\">  \n"),
       as.character("   <head>                                                                                                                                                \n"),
		.
		.
		.
       as.character("        <td colspan=5 class=xl28 width=727 style=\'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</td>                                   \n"),
       as.character("       </tr>                                                                                                                                               "), file = zz)
       close(zz)
       unlink(zz)
}
Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function with this argument, yields a filename "Itemtabelle  ??rzte Innere, Gyn??kologie .html" and in the file a line 
         <td colspan=5 class=xl28 width=727 style='width:545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </td>  
is generated.                                 .
I tried to solve this by using iconv, without success.
The problem remains the same in the rgui and rterm - in rterm the resulting filename is "Itemtabelle ?rzte Innere, Gyn?kologie  .html".

Cheers,
Matthias
 


From simon.urbanek at r-project.org  Thu Dec 27 21:39:42 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 27 Dec 2007 15:39:42 -0500
Subject: [Rd] encoding question again
In-Reply-To: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
Message-ID: <A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>

Matthias,

you get exactly what you specified - namely UTF-8. If you want your  
html file to be latin1, then you have to say so:

zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",  
encoding = "latin1")

In addition, you're assuming that `abt' is in the correct encoding to  
be understood by your OS. If it's not, you better convert it into one.  
 From your results it seems as if `abt' is also UTF-8 encoded. Since  
you didn't tell us where you got that from, you should either fix the  
source or use something like iconv(abt,"utf-8","latin1"):

(in UTF-8 locale)
 > abt="n?r"
 > cat(abt,"\n")
n?r
 > charToRaw(abt)
[1] 6e c3 bc 72
 > charToRaw(iconv(abt,"utf-8","latin1"))
[1] 6e fc 72

Cheers,
Simon


On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:

> Hi, R Devils,
> I'm running the actual R version in JGR (version 1.5-8 ).  
> Sys.getlocale(category = "LC_ALL") yields
> [1] "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany. 
> 1252;LC_MONETARY=German_Germany. 
> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>
> I want to write some HTML-Code enhanced by statistical results and  
> labels encoded in Latin-1, which I pass to a function. Some label  
> shall generate the filename. Although the labels are correctly  
> handled in JGR they are somehow converted when they are written to  
> the file. Also the filename is not constructed as wanted. The  
> function definition is correctly sourced into R. The function is  
> defined like this:
>
> Itemtabelle.head <- function (abt ){
>   # n?r z?m T?ST
>   zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",  
> encoding = "UTF-8")
>   cat(as.character("<html xmlns:o=\"urn:schemas-microsoft-com:office:office 
> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\" xmlns=\"http://www.w3.org/TR/REC-html40 
> \">  \n"),
>       as.character("    
> < 
> head 
> > 
>                                                                                                                                                 \n 
> "),
> 		.
> 		.
> 		.
>       as.character("        <td colspan=5 class=xl28 width=727 style= 
> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</ 
> td>                                   \n"),
>       as.character("       </ 
> tr 
> > 
>                                                                                                                                                "), file 
>  = zz)
>       close(zz)
>       unlink(zz)
> }
> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function  
> with this argument, yields a filename "Itemtabelle  ??rzte Innere,  
> Gyn??kologie .html" and in the file a line
>         <td colspan=5 class=xl28 width=727 style='width: 
> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </ 
> td>
> is generated.                                 .
> I tried to solve this by using iconv, without success.
> The problem remains the same in the rgui and rterm - in rterm the  
> resulting filename is "Itemtabelle ?rzte Innere, Gyn?kologie  .html".
>
> Cheers,
> Matthias
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From office at matthiaswendel.de  Thu Dec 27 21:52:40 2007
From: office at matthiaswendel.de (Matthias Wendel)
Date: Thu, 27 Dec 2007 21:52:40 +0100
Subject: [Rd] encoding question again
In-Reply-To: <A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
	<A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
Message-ID: <004301c848ca$6c083510$15b2a8c0@lifebook2>

Hi, simon,
	i followed your advice by adding/changing the lines 
   abt = iconv(abt,"utf-8","latin1")   
   zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt", encoding = "latin1")
but this yielded the same results.
Cheers,
Matthias
-----Urspr?ngliche Nachricht-----
Von: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
Gesendet: Donnerstag, 27. Dezember 2007 21:40
An: Matthias Wendel
Cc: r-devel at r-project.org
Betreff: Re: [Rd] encoding question again

Matthias,

you get exactly what you specified - namely UTF-8. If you want your html file to be latin1, then you have to say so:

zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt", encoding = "latin1")

In addition, you're assuming that `abt' is in the correct encoding to be understood by your OS. If it's not, you better convert it into one.  
 From your results it seems as if `abt' is also UTF-8 encoded. Since you didn't tell us where you got that from, you should either fix the source or use something like iconv(abt,"utf-8","latin1"):

(in UTF-8 locale)
 > abt="n?r"
 > cat(abt,"\n")
n?r
 > charToRaw(abt)
[1] 6e c3 bc 72
 > charToRaw(iconv(abt,"utf-8","latin1"))
[1] 6e fc 72

Cheers,
Simon


On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:

> Hi, R Devils,
> I'm running the actual R version in JGR (version 1.5-8 ).  
> Sys.getlocale(category = "LC_ALL") yields [1] 
> "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.
> 1252;LC_MONETARY=German_Germany. 
> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>
> I want to write some HTML-Code enhanced by statistical results and 
> labels encoded in Latin-1, which I pass to a function. Some label 
> shall generate the filename. Although the labels are correctly handled 
> in JGR they are somehow converted when they are written to the file. 
> Also the filename is not constructed as wanted. The function 
> definition is correctly sourced into R. The function is defined like 
> this:
>
> Itemtabelle.head <- function (abt ){
>   # n?r z?m T?ST
>   zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt", 
> encoding = "UTF-8")
>   cat(as.character("<html 
> xmlns:o=\"urn:schemas-microsoft-com:office:office
> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\" 
> xmlns=\"http://www.w3.org/TR/REC-html40
> \">  \n"),
>       as.character("    
> <
> head
> > 
>                                                                                                                                                 
> \n "),
> 		.
> 		.
> 		.
>       as.character("        <td colspan=5 class=xl28 width=727 style= 
> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</
> td>                                   \n"),
>       as.character("       </ 
> tr
> > 
>                                                                                                                                                
> "), file  = zz)
>       close(zz)
>       unlink(zz)
> }
> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function 
> with this argument, yields a filename "Itemtabelle  ??rzte Innere, 
> Gyn??kologie .html" and in the file a line
>         <td colspan=5 class=xl28 width=727 style='width: 
> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </ 
> td>
> is generated.                                 .
> I tried to solve this by using iconv, without success.
> The problem remains the same in the rgui and rterm - in rterm the 
> resulting filename is "Itemtabelle ?rzte Innere, Gyn?kologie  .html".
>
> Cheers,
> Matthias
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From phgrosjean at sciviews.org  Fri Dec 28 23:02:56 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 28 Dec 2007 23:02:56 +0100
Subject: [Rd] parse() does not complain for not finished strings?
Message-ID: <47757290.5000301@sciviews.org>

Hello,
parse() is supposed to detect incomplete instructions, isn't it?
For instance:

> # Correct code
> msg <- 'log(10)'
> mc <- textConnection(msg)
> parse(mc)
expression(log(10))
> close(mc)

> # Now, an incomplete code
> msg <- 'log('
> mc <- textConnection(msg)
> parse(mc)
Error in parse(mc) : unexpected end of input at
2: log(
> close(mc)

> # Now, another incomplete code (character string not finished)
> msg <- 'text <- "some incomplete string'
> mc <- textConnection(msg)
> parse(mc)
expression(text <- "some incomplete string\n")
> close(mc)

I don't understand why parse() does not complain in this third case, and
why it "finishes" my string and adds a '\n' at its end. Does anybody
could explain me,... or is this a bug?
Many thanks.

Philippe Grosjean


From p.dalgaard at biostat.ku.dk  Sat Dec 29 00:42:14 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 29 Dec 2007 00:42:14 +0100
Subject: [Rd] parse() does not complain for not finished strings?
In-Reply-To: <47757290.5000301@sciviews.org>
References: <47757290.5000301@sciviews.org>
Message-ID: <477589D6.7000807@biostat.ku.dk>

Philippe Grosjean wrote:
> Hello,
> parse() is supposed to detect incomplete instructions, isn't it?
> For instance:
>
>   
>> # Correct code
>> msg <- 'log(10)'
>> mc <- textConnection(msg)
>> parse(mc)
>>     
> expression(log(10))
>   
>> close(mc)
>>     
>
>   
>> # Now, an incomplete code
>> msg <- 'log('
>> mc <- textConnection(msg)
>> parse(mc)
>>     
> Error in parse(mc) : unexpected end of input at
> 2: log(
>   
>> close(mc)
>>     
>
>   
>> # Now, another incomplete code (character string not finished)
>> msg <- 'text <- "some incomplete string'
>> mc <- textConnection(msg)
>> parse(mc)
>>     
> expression(text <- "some incomplete string\n")
>   
>> close(mc)
>>     
>
> I don't understand why parse() does not complain in this third case, and
> why it "finishes" my string and adds a '\n' at its end. Does anybody
> could explain me,... or is this a bug
A buglet at least. It is not parsing per se that does it:

 > parse(text=msg)
Error in parse(text = msg) :
  unexpected end of input in "text <- "some incomplete string"

but it happens whenever you parse from a file or connection e.g.

$ cat > xxx
"incom
$ R
[....]
 > source("xxx")
 > .Last.value
$value
[1] "incom\n"

$visible
[1] TRUE


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From phgrosjean at sciviews.org  Sat Dec 29 12:15:26 2007
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Sat, 29 Dec 2007 12:15:26 +0100 (CET)
Subject: [Rd] capture.output(), truncated last output without \n (PR#10534)
Message-ID: <20071229111526.1015E2834619@mail.pubhealth.ku.dk>

Full_Name: Philippe Grosjean
Version: 2.6.1
OS: MacOS X; Windows XP
Submission from: (NULL) (81.243.237.235)


Last output from capture.output() is truncated if it does not end with a
carriage return:

> capture.output(cat("text\n"))  # Fine
[1] "text"
> capture.output(cat("text"))    # Missing output!
character(0)
> capture.output({cat("text");1+1})  # Only last output is affected
[1] "text[1] 2"

Proposed patch: add a carriage return before exiting capture.output():

capture.output <-
function (..., file = NULL, append = FALSE) {

    
[...]

        for (item in tmp) if (item$visible) 
            print(item$value)
    }
    cat("\n")  ### ADD THIS!
    rval
}

This changes the behavior of capture.output() a little bit, since it adds "" at
the end of regular outputs, but it solves the problem and it allows to detect if
last output line was ended by \n, or not.

Regards,

Philippe Grosjean
               _                           
platform       i386-apple-darwin8.10.1     
arch           i386                        
os             darwin8.10.1                
system         i386, darwin8.10.1          
status                                     
major          2                           
minor          6.1                         
year           2007                        
month          11                          
day            26                          
svn rev        43537                       
language       R


From ripley at stats.ox.ac.uk  Sat Dec 29 13:20:14 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sat, 29 Dec 2007 13:20:14 +0100 (CET)
Subject: [Rd] (PR#10534 capture.output(), truncated last output without
Message-ID: <20071229122014.A78472834619@mail.pubhealth.ku.dk>

This only happens if 'file' is a text connection, and is the expected 
behaviour in that case: you cannot capture an incomplete line to a text 
connection.

There seems no reason to break the documented behaviour in other cases to 
change something that you consider to a bug when file=NULL and the user 
does not produce complete output.  It would be possible to make use of 
isIncomplete() to add a final newline only where needed to complete a 
line.  E.g. use

     if(inherits(file, "textConnection") && isIncomplete(file)) cat("\n")


On Sat, 29 Dec 2007, phgrosjean at sciviews.org wrote:

> Full_Name: Philippe Grosjean
> Version: 2.6.1
> OS: MacOS X; Windows XP
> Submission from: (NULL) (81.243.237.235)
>
>
> Last output from capture.output() is truncated if it does not end with a
> carriage return:
>
>> capture.output(cat("text\n"))  # Fine
> [1] "text"
>> capture.output(cat("text"))    # Missing output!
> character(0)
>> capture.output({cat("text");1+1})  # Only last output is affected
> [1] "text[1] 2"
>
> Proposed patch: add a carriage return before exiting capture.output():
>
> capture.output <-
> function (..., file = NULL, append = FALSE) {
>
>
> [...]
>
>        for (item in tmp) if (item$visible)
>            print(item$value)
>    }
>    cat("\n")  ### ADD THIS!
>    rval
> }
>
> This changes the behavior of capture.output() a little bit, since it adds "" at
> the end of regular outputs, but it solves the problem and it allows to detect if
> last output line was ended by \n, or not.
>
> Regards,
>
> Philippe Grosjean
>               _
> platform       i386-apple-darwin8.10.1
> arch           i386
> os             darwin8.10.1
> system         i386, darwin8.10.1
> status
> major          2
> minor          6.1
> year           2007
> month          11
> day            26
> svn rev        43537
> language       R
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From phgrosjean at sciviews.org  Sat Dec 29 13:44:04 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 29 Dec 2007 13:44:04 +0100
Subject: [Rd] (PR#10534 capture.output(),
 truncated last output without \n
In-Reply-To: <Pine.LNX.4.64.0712291151440.21325@gannet.stats.ox.ac.uk>
References: <20071229111526.1015E2834619@mail.pubhealth.ku.dk>
	<Pine.LNX.4.64.0712291151440.21325@gannet.stats.ox.ac.uk>
Message-ID: <47764114.7090400@sciviews.org>

Thank you, Brian.

Prof Brian Ripley wrote:
> This only happens if 'file' is a text connection, and is the expected 
> behaviour in that case: you cannot capture an incomplete line to a text 
> connection.

Well, in ?textConnection, Details section, one can read:
"Closing the connection will output the final line, complete or not."

> There seems no reason to break the documented behaviour in other cases 
> to change something that you consider to a bug when file=NULL and the 
> user does not produce complete output.  It would be possible to make use 
> of isIncomplete() to add a final newline only where needed to complete a 
> line.  E.g. use
> 
>     if(inherits(file, "textConnection") && isIncomplete(file)) cat("\n")

This is fine, except one cannot detect when the last line was complete 
or not in capture.output(). I suggest adding an attribute complete = 
TRUE/FALSE to the result returned by capture.output(), or any other mean 
to return this information.

Best,

Philippe Grosjean

> 
> On Sat, 29 Dec 2007, phgrosjean at sciviews.org wrote:
> 
>> Full_Name: Philippe Grosjean
>> Version: 2.6.1
>> OS: MacOS X; Windows XP
>> Submission from: (NULL) (81.243.237.235)
>>
>>
>> Last output from capture.output() is truncated if it does not end with a
>> carriage return:
>>
>>> capture.output(cat("text\n"))  # Fine
>> [1] "text"
>>> capture.output(cat("text"))    # Missing output!
>> character(0)
>>> capture.output({cat("text");1+1})  # Only last output is affected
>> [1] "text[1] 2"
>>
>> Proposed patch: add a carriage return before exiting capture.output():
>>
>> capture.output <-
>> function (..., file = NULL, append = FALSE) {
>>
>>
>> [...]
>>
>>        for (item in tmp) if (item$visible)
>>            print(item$value)
>>    }
>>    cat("\n")  ### ADD THIS!
>>    rval
>> }
>>
>> This changes the behavior of capture.output() a little bit, since it 
>> adds "" at
>> the end of regular outputs, but it solves the problem and it allows to 
>> detect if
>> last output line was ended by \n, or not.
>>
>> Regards,
>>
>> Philippe Grosjean
>>               _
>> platform       i386-apple-darwin8.10.1
>> arch           i386
>> os             darwin8.10.1
>> system         i386, darwin8.10.1
>> status
>> major          2
>> minor          6.1
>> year           2007
>> month          11
>> day            26
>> svn rev        43537
>> language       R
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From maechler at stat.math.ethz.ch  Sat Dec 29 14:10:22 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Sat, 29 Dec 2007 14:10:22 +0100 (CET)
Subject: [Rd] (PR#10534 capture.output(), truncated last output without
Message-ID: <20071229131022.D2C57283461C@mail.pubhealth.ku.dk>

>>>>> "BDR" == Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Sat, 29 Dec 2007 13:20:14 +0100 (CET) writes:

    BDR> This only happens if 'file' is a text connection, and
    BDR> is the expected behaviour in that case: you cannot
    BDR> capture an incomplete line to a text connection.

    BDR> There seems no reason to break the documented behaviour
    BDR> in other cases to change something that you consider to
    BDR> a bug when file=NULL and the user does not produce
    BDR> complete output.  It would be possible to make use of
    BDR> isIncomplete() to add a final newline only where needed
    BDR> to complete a line.  E.g. use

    BDR>   if(inherits(file, "textConnection") && isIncomplete(file)) cat("\n")

I think that would be quite a nice improvement.
Martin

    BDR> On Sat, 29 Dec 2007, phgrosjean at sciviews.org wrote:

    >> Full_Name: Philippe Grosjean Version: 2.6.1 OS: MacOS X;
    >> Windows XP Submission from: (NULL) (81.243.237.235)
    >> 
    >> 
    >> Last output from capture.output() is truncated if it does
    >> not end with a carriage return:
    >> 
    >>> capture.output(cat("text\n")) # Fine
    >> [1] "text"
    >>> capture.output(cat("text")) # Missing output!
    >> character(0)
    >>> capture.output({cat("text");1+1}) # Only last output is
    >>> affected
    >> [1] "text[1] 2"
    >> 
    >> Proposed patch: add a carriage return before exiting
    >> capture.output():
    >> 
    >> capture.output <- function (..., file = NULL, append =
    >> FALSE) {
    >> 
    >> 
    >> [...]
    >> 
    >> for (item in tmp) if (item$visible) print(item$value) }
    >> cat("\n") ### ADD THIS!  rval }
    >> 
    >> This changes the behavior of capture.output() a little
    >> bit, since it adds "" at the end of regular outputs, but
    >> it solves the problem and it allows to detect if last
    >> output line was ended by \n, or not.
    >> 
    >> Regards,
    >> 
    >> Philippe Grosjean _ platform i386-apple-darwin8.10.1 arch
    >> i386 os darwin8.10.1 system i386, darwin8.10.1 status
    >> major 2 minor 6.1 year 2007 month 11 day 26 svn rev 43537
    >> language R
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,
    BDR> http://www.stats.ox.ac.uk/~ripley/ University of
    BDR> Oxford, Tel: +44 1865 272861 (self) 1 South Parks Road,
    BDR> +44 1865 272866 (PA) Oxford OX1 3TG, UK Fax: +44 1865
    BDR> 272595

    BDR> ______________________________________________
    BDR> R-devel at r-project.org mailing list
    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Dec 29 14:25:22 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sat, 29 Dec 2007 14:25:22 +0100 (CET)
Subject: [Rd] (PR#10534 capture.output(), truncated last output without
Message-ID: <20071229132522.DA557283461C@mail.pubhealth.ku.dk>

On Sat, 29 Dec 2007, Martin Maechler wrote:

>>>>>> "BDR" == Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Sat, 29 Dec 2007 13:20:14 +0100 (CET) writes:
>
>    BDR> This only happens if 'file' is a text connection, and
>    BDR> is the expected behaviour in that case: you cannot
>    BDR> capture an incomplete line to a text connection.
>
>    BDR> There seems no reason to break the documented behaviour
>    BDR> in other cases to change something that you consider to
>    BDR> a bug when file=NULL and the user does not produce
>    BDR> complete output.  It would be possible to make use of
>    BDR> isIncomplete() to add a final newline only where needed
>    BDR> to complete a line.  E.g. use
>
>    BDR>   if(inherits(file, "textConnection") && isIncomplete(file)) cat("\n")
>
> I think that would be quite a nice improvement.

Yes, I'd like to achieve the effect, but I think there is a better way to 
do it.

The nub of the problem is that close() is done in the on.exit action 
after the return value is set, so the internal logic needs changing.

Brian

> Martin
>
>    BDR> On Sat, 29 Dec 2007, phgrosjean at sciviews.org wrote:
>
>    >> Full_Name: Philippe Grosjean Version: 2.6.1 OS: MacOS X;
>    >> Windows XP Submission from: (NULL) (81.243.237.235)
>    >>
>    >>
>    >> Last output from capture.output() is truncated if it does
>    >> not end with a carriage return:
>    >>
>    >>> capture.output(cat("text\n")) # Fine
>    >> [1] "text"
>    >>> capture.output(cat("text")) # Missing output!
>    >> character(0)
>    >>> capture.output({cat("text");1+1}) # Only last output is
>    >>> affected
>    >> [1] "text[1] 2"
>    >>
>    >> Proposed patch: add a carriage return before exiting
>    >> capture.output():
>    >>
>    >> capture.output <- function (..., file = NULL, append =
>    >> FALSE) {
>    >>
>    >>
>    >> [...]
>    >>
>    >> for (item in tmp) if (item$visible) print(item$value) }
>    >> cat("\n") ### ADD THIS!  rval }
>    >>
>    >> This changes the behavior of capture.output() a little
>    >> bit, since it adds "" at the end of regular outputs, but
>    >> it solves the problem and it allows to detect if last
>    >> output line was ended by \n, or not.
>    >>
>    >> Regards,
>    >>
>    >> Philippe Grosjean _ platform i386-apple-darwin8.10.1 arch
>    >> i386 os darwin8.10.1 system i386, darwin8.10.1 status
>    >> major 2 minor 6.1 year 2007 month 11 day 26 svn rev 43537
>    >> language R
>    >>
>    >> ______________________________________________
>    >> R-devel at r-project.org mailing list
>    >> https://stat.ethz.ch/mailman/listinfo/r-devel
>    >>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Dec 29 14:38:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Dec 2007 13:38:18 +0000 (GMT)
Subject: [Rd] (PR#10534 capture.output(),
 truncated last output without \n
In-Reply-To: <47764114.7090400@sciviews.org>
References: <20071229111526.1015E2834619@mail.pubhealth.ku.dk>
	<Pine.LNX.4.64.0712291151440.21325@gannet.stats.ox.ac.uk>
	<47764114.7090400@sciviews.org>
Message-ID: <Pine.LNX.4.64.0712291311030.23569@gannet.stats.ox.ac.uk>

On Sat, 29 Dec 2007, Philippe Grosjean wrote:

> Thank you, Brian.
>
> Prof Brian Ripley wrote:
>> This only happens if 'file' is a text connection, and is the expected 
>> behaviour in that case: you cannot capture an incomplete line to a text 
>> connection.
>
> Well, in ?textConnection, Details section, one can read:
> "Closing the connection will output the final line, complete or not."

Yes, but 'rval' is returned before the connection is closed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sabine.guesewell at env.ethz.ch  Sat Dec 29 14:55:09 2007
From: sabine.guesewell at env.ethz.ch (sabine.guesewell at env.ethz.ch)
Date: Sat, 29 Dec 2007 14:55:09 +0100 (CET)
Subject: [Rd] Installation of ade4 and ecodist (PR#10535)
Message-ID: <20071229135509.42985283461C@mail.pubhealth.ku.dk>


Dear R Team,

The installation of the packages ade4 and ecodist failed with the 
message that the description file could not be read.

The problem appeared with recent versions of R (2.6.0 or 2.6.1)
- On a Macintosh computer, trying to install packages directly 
through the internet
- On a Windows computer, trying to install packages from ZIP files.

The problem seems to be specific to new compiled version(s) of these 
packages, since:
- I could install these packages in summer 2007 to another Macintosh 
with R Version 2.3.0
- I could install two other packages (car and spdep) on the 
aformentioned Windows computer (doing exactly the same).
- Our IT specialist could download source codes of ade4 and ecodist, 
compile them and install them on the aforementioned Macintosh 
computer (after the installation from binaries had failed).

Thank you for checking what might cause the problem so that I could 
use the packages in teaching.

Yours sincerely,
Sabine Guesewell

-- 

*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
PD Dr. Sabine Guesewell
Institute of Integrative Biology
Department of Environmental Sciences
ETH Zurich, CHN H 68
8092 Zurich
Switzerland

Tel: ++41-44-632 43 07
Fax ++41-44-632 12 15
E-Mail: sabine.guesewell at env.ethz.ch
http://www.plantecology.ethz.ch/people/wissmit


From simon.urbanek at r-project.org  Sat Dec 29 17:11:56 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 29 Dec 2007 11:11:56 -0500
Subject: [Rd] encoding question again
In-Reply-To: <004301c848ca$6c083510$15b2a8c0@lifebook2>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
	<A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
	<004301c848ca$6c083510$15b2a8c0@lifebook2>
Message-ID: <17963695-ACD0-49B2-B8EA-E11C5DF2ECE5@r-project.org>

Hallo Matthias,

On Dec 27, 2007, at 3:52 PM, Matthias Wendel wrote:

> Hi, simon,
> 	i followed your advice by adding/changing the lines
>   abt = iconv(abt,"utf-8","latin1")
>   zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",  
> encoding = "latin1")
> but this yielded the same results.

Ich habe endlich eine Windows-Maschine zum Testen und bei mir wird der  
Dateiname richtig angelegt ...

Dennoch, anscheinend stimmt die locale nicht - denn JGR benutzt immer  
UTF-8,  aber das System liefert CP1252. Deswegen scheint die  
automatische Konvertierung nicht zu funktionieren  
(file(...,encoding..)). Was allerding immer geht, ist die explizite  
Konvertierung:

a=file("foo","wt")
writeLines(iconv(..., "utf-8","latin1"),a)
close(a)

(FWIW: da die empfohlene Kodierung von Webseiten sowieso UTF-8 ist,  
braucht man es eigentlich nicht wirklich ... ;))

charToRaw ist immer eine guter Test, weil UTF-8 fuer Umlaute meist 2- 
bytes bracht und latin1 nur eins.

Viele Gruesse,
Simon


> -----Urspr?ngliche Nachricht-----
> Von: Simon Urbanek [mailto:simon.urbanek at r-project.org]
> Gesendet: Donnerstag, 27. Dezember 2007 21:40
> An: Matthias Wendel
> Cc: r-devel at r-project.org
> Betreff: Re: [Rd] encoding question again
>
> Matthias,
>
> you get exactly what you specified - namely UTF-8. If you want your  
> html file to be latin1, then you have to say so:
>
> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",  
> encoding = "latin1")
>
> In addition, you're assuming that `abt' is in the correct encoding  
> to be understood by your OS. If it's not, you better convert it into  
> one.
> From your results it seems as if `abt' is also UTF-8 encoded. Since  
> you didn't tell us where you got that from, you should either fix  
> the source or use something like iconv(abt,"utf-8","latin1"):
>
> (in UTF-8 locale)
>> abt="n?r"
>> cat(abt,"\n")
> n?r
>> charToRaw(abt)
> [1] 6e c3 bc 72
>> charToRaw(iconv(abt,"utf-8","latin1"))
> [1] 6e fc 72
>
> Cheers,
> Simon
>
>
> On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:
>
>> Hi, R Devils,
>> I'm running the actual R version in JGR (version 1.5-8 ).
>> Sys.getlocale(category = "LC_ALL") yields [1]
>> "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.
>> 1252;LC_MONETARY=German_Germany.
>> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>>
>> I want to write some HTML-Code enhanced by statistical results and
>> labels encoded in Latin-1, which I pass to a function. Some label
>> shall generate the filename. Although the labels are correctly  
>> handled
>> in JGR they are somehow converted when they are written to the file.
>> Also the filename is not constructed as wanted. The function
>> definition is correctly sourced into R. The function is defined like
>> this:
>>
>> Itemtabelle.head <- function (abt ){
>>  # n?r z?m T?ST
>>  zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>> encoding = "UTF-8")
>>  cat(as.character("<html
>> xmlns:o=\"urn:schemas-microsoft-com:office:office
>> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\"
>> xmlns=\"http://www.w3.org/TR/REC-html40
>> \">  \n"),
>>      as.character("
>> <
>> head
>>>
>>
>> \n "),
>> 		.
>> 		.
>> 		.
>>      as.character("        <td colspan=5 class=xl28 width=727 style=
>> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</
>> td>                                   \n"),
>>      as.character("       </
>> tr
>>>
>>
>> "), file  = zz)
>>      close(zz)
>>      unlink(zz)
>> }
>> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function
>> with this argument, yields a filename "Itemtabelle  ??rzte Innere,
>> Gyn??kologie .html" and in the file a line
>>        <td colspan=5 class=xl28 width=727 style='width:
>> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </
>> td>
>> is generated.                                 .
>> I tried to solve this by using iconv, without success.
>> The problem remains the same in the rgui and rterm - in rterm the
>> resulting filename is "Itemtabelle ?rzte Innere, Gyn?kologie  .html".
>>
>> Cheers,
>> Matthias
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>


From simon.urbanek at r-project.org  Sat Dec 29 17:42:53 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 29 Dec 2007 11:42:53 -0500
Subject: [Rd] encoding question again
In-Reply-To: <17963695-ACD0-49B2-B8EA-E11C5DF2ECE5@r-project.org>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
	<A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
	<004301c848ca$6c083510$15b2a8c0@lifebook2>
	<17963695-ACD0-49B2-B8EA-E11C5DF2ECE5@r-project.org>
Message-ID: <3219D6A4-8F66-43E3-A096-69BCF12F2FFD@r-project.org>

Oops, this was supposed to be a private reply ;) - sorry about the  
noise. The essence in English:
JGR uses all strings in UTF-8 encoding, but the system locale reports  
CP1252 which impedes automatic conversions (because R doesn't know  
that everything is UTF-8). Specific conversion via iconv works as  
expected (see the example below).

Cheers,
Simon

On Dec 29, 2007, at 11:11 AM, Simon Urbanek wrote:

> Hallo Matthias,
>
> On Dec 27, 2007, at 3:52 PM, Matthias Wendel wrote:
>
>> Hi, simon,
>> 	i followed your advice by adding/changing the lines
>>  abt = iconv(abt,"utf-8","latin1")
>>  zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>> encoding = "latin1")
>> but this yielded the same results.
>
> Ich habe endlich eine Windows-Maschine zum Testen und bei mir wird der
> Dateiname richtig angelegt ...
>
> Dennoch, anscheinend stimmt die locale nicht - denn JGR benutzt immer
> UTF-8,  aber das System liefert CP1252. Deswegen scheint die
> automatische Konvertierung nicht zu funktionieren
> (file(...,encoding..)). Was allerding immer geht, ist die explizite
> Konvertierung:
>
> a=file("foo","wt")
> writeLines(iconv(..., "utf-8","latin1"),a)
> close(a)
>
> (FWIW: da die empfohlene Kodierung von Webseiten sowieso UTF-8 ist,
> braucht man es eigentlich nicht wirklich ... ;))
>
> charToRaw ist immer eine guter Test, weil UTF-8 fuer Umlaute meist 2-
> bytes bracht und latin1 nur eins.
>
> Viele Gruesse,
> Simon
>
>
>> -----Urspr?ngliche Nachricht-----
>> Von: Simon Urbanek [mailto:simon.urbanek at r-project.org]
>> Gesendet: Donnerstag, 27. Dezember 2007 21:40
>> An: Matthias Wendel
>> Cc: r-devel at r-project.org
>> Betreff: Re: [Rd] encoding question again
>>
>> Matthias,
>>
>> you get exactly what you specified - namely UTF-8. If you want your
>> html file to be latin1, then you have to say so:
>>
>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>> encoding = "latin1")
>>
>> In addition, you're assuming that `abt' is in the correct encoding
>> to be understood by your OS. If it's not, you better convert it into
>> one.
>> From your results it seems as if `abt' is also UTF-8 encoded. Since
>> you didn't tell us where you got that from, you should either fix
>> the source or use something like iconv(abt,"utf-8","latin1"):
>>
>> (in UTF-8 locale)
>>> abt="n?r"
>>> cat(abt,"\n")
>> n?r
>>> charToRaw(abt)
>> [1] 6e c3 bc 72
>>> charToRaw(iconv(abt,"utf-8","latin1"))
>> [1] 6e fc 72
>>
>> Cheers,
>> Simon
>>
>>
>> On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:
>>
>>> Hi, R Devils,
>>> I'm running the actual R version in JGR (version 1.5-8 ).
>>> Sys.getlocale(category = "LC_ALL") yields [1]
>>> "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.
>>> 1252;LC_MONETARY=German_Germany.
>>> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>>>
>>> I want to write some HTML-Code enhanced by statistical results and
>>> labels encoded in Latin-1, which I pass to a function. Some label
>>> shall generate the filename. Although the labels are correctly
>>> handled
>>> in JGR they are somehow converted when they are written to the file.
>>> Also the filename is not constructed as wanted. The function
>>> definition is correctly sourced into R. The function is defined like
>>> this:
>>>
>>> Itemtabelle.head <- function (abt ){
>>> # n?r z?m T?ST
>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>> encoding = "UTF-8")
>>> cat(as.character("<html
>>> xmlns:o=\"urn:schemas-microsoft-com:office:office
>>> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\"
>>> xmlns=\"http://www.w3.org/TR/REC-html40
>>> \">  \n"),
>>>     as.character("
>>> <
>>> head
>>>>
>>>
>>> \n "),
>>> 		.
>>> 		.
>>> 		.
>>>     as.character("        <td colspan=5 class=xl28 width=727 style=
>>> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</
>>> td>                                   \n"),
>>>     as.character("       </
>>> tr
>>>>
>>>
>>> "), file  = zz)
>>>     close(zz)
>>>     unlink(zz)
>>> }
>>> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function
>>> with this argument, yields a filename "Itemtabelle  ??rzte Innere,
>>> Gyn??kologie .html" and in the file a line
>>>       <td colspan=5 class=xl28 width=727 style='width:
>>> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </
>>> td>
>>> is generated.                                 .
>>> I tried to solve this by using iconv, without success.
>>> The problem remains the same in the rgui and rterm - in rterm the
>>> resulting filename is "Itemtabelle ?rzte Innere,  
>>> Gyn?kologie  .html".
>>>
>>> Cheers,
>>> Matthias
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Sat Dec 29 18:28:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Dec 2007 17:28:58 +0000 (GMT)
Subject: [Rd] encoding question again
In-Reply-To: <3219D6A4-8F66-43E3-A096-69BCF12F2FFD@r-project.org>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
	<A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
	<004301c848ca$6c083510$15b2a8c0@lifebook2>
	<17963695-ACD0-49B2-B8EA-E11C5DF2ECE5@r-project.org>
	<3219D6A4-8F66-43E3-A096-69BCF12F2FFD@r-project.org>
Message-ID: <Pine.LNX.4.64.0712291718580.1229@gannet.stats.ox.ac.uk>

On Sat, 29 Dec 2007, Simon Urbanek wrote:

> Oops, this was supposed to be a private reply ;) - sorry about the
> noise. The essence in English:
> JGR uses all strings in UTF-8 encoding, but the system locale reports
> CP1252 which impedes automatic conversions (because R doesn't know
> that everything is UTF-8). Specific conversion via iconv works as
> expected (see the example below).

On Windows there are no UTF-8 locales, but you can probably get the same 
effect by marking the strings via Encoding(), as they will be converted to 
CP1252 (a Latin-1 superset) on output.  A console that is running in a 
non-native encoding needs to convert everything going to and from R. 
We've experimented with running R in UTF-8 on Windows, but then you need 
to convert _everything_ coming in and going out and (and this is the 
killer) so would every package with C-level I/O.  (Tcl/Tk and Perl have 
gone down that route, and to a large extent left their extensions behind.)

>
> Cheers,
> Simon
>
> On Dec 29, 2007, at 11:11 AM, Simon Urbanek wrote:
>
>> Hallo Matthias,
>>
>> On Dec 27, 2007, at 3:52 PM, Matthias Wendel wrote:
>>
>>> Hi, simon,
>>> 	i followed your advice by adding/changing the lines
>>>  abt = iconv(abt,"utf-8","latin1")
>>>  zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>> encoding = "latin1")
>>> but this yielded the same results.
>>
>> Ich habe endlich eine Windows-Maschine zum Testen und bei mir wird der
>> Dateiname richtig angelegt ...
>>
>> Dennoch, anscheinend stimmt die locale nicht - denn JGR benutzt immer
>> UTF-8,  aber das System liefert CP1252. Deswegen scheint die
>> automatische Konvertierung nicht zu funktionieren
>> (file(...,encoding..)). Was allerding immer geht, ist die explizite
>> Konvertierung:
>>
>> a=file("foo","wt")
>> writeLines(iconv(..., "utf-8","latin1"),a)
>> close(a)
>>
>> (FWIW: da die empfohlene Kodierung von Webseiten sowieso UTF-8 ist,
>> braucht man es eigentlich nicht wirklich ... ;))
>>
>> charToRaw ist immer eine guter Test, weil UTF-8 fuer Umlaute meist 2-
>> bytes bracht und latin1 nur eins.
>>
>> Viele Gruesse,
>> Simon
>>
>>
>>> -----Urspr?ngliche Nachricht-----
>>> Von: Simon Urbanek [mailto:simon.urbanek at r-project.org]
>>> Gesendet: Donnerstag, 27. Dezember 2007 21:40
>>> An: Matthias Wendel
>>> Cc: r-devel at r-project.org
>>> Betreff: Re: [Rd] encoding question again
>>>
>>> Matthias,
>>>
>>> you get exactly what you specified - namely UTF-8. If you want your
>>> html file to be latin1, then you have to say so:
>>>
>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>> encoding = "latin1")
>>>
>>> In addition, you're assuming that `abt' is in the correct encoding
>>> to be understood by your OS. If it's not, you better convert it into
>>> one.
>>> From your results it seems as if `abt' is also UTF-8 encoded. Since
>>> you didn't tell us where you got that from, you should either fix
>>> the source or use something like iconv(abt,"utf-8","latin1"):
>>>
>>> (in UTF-8 locale)
>>>> abt="n?r"
>>>> cat(abt,"\n")
>>> n?r
>>>> charToRaw(abt)
>>> [1] 6e c3 bc 72
>>>> charToRaw(iconv(abt,"utf-8","latin1"))
>>> [1] 6e fc 72
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>> On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:
>>>
>>>> Hi, R Devils,
>>>> I'm running the actual R version in JGR (version 1.5-8 ).
>>>> Sys.getlocale(category = "LC_ALL") yields [1]
>>>> "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.
>>>> 1252;LC_MONETARY=German_Germany.
>>>> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>>>>
>>>> I want to write some HTML-Code enhanced by statistical results and
>>>> labels encoded in Latin-1, which I pass to a function. Some label
>>>> shall generate the filename. Although the labels are correctly
>>>> handled
>>>> in JGR they are somehow converted when they are written to the file.
>>>> Also the filename is not constructed as wanted. The function
>>>> definition is correctly sourced into R. The function is defined like
>>>> this:
>>>>
>>>> Itemtabelle.head <- function (abt ){
>>>> # n?r z?m T?ST
>>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>>> encoding = "UTF-8")
>>>> cat(as.character("<html
>>>> xmlns:o=\"urn:schemas-microsoft-com:office:office
>>>> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\"
>>>> xmlns=\"http://www.w3.org/TR/REC-html40
>>>> \">  \n"),
>>>>     as.character("
>>>> <
>>>> head
>>>>>
>>>>
>>>> \n "),
>>>> 		.
>>>> 		.
>>>> 		.
>>>>     as.character("        <td colspan=5 class=xl28 width=727 style=
>>>> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</
>>>> td>                                   \n"),
>>>>     as.character("       </
>>>> tr
>>>>>
>>>>
>>>> "), file  = zz)
>>>>     close(zz)
>>>>     unlink(zz)
>>>> }
>>>> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the function
>>>> with this argument, yields a filename "Itemtabelle  ??rzte Innere,
>>>> Gyn??kologie .html" and in the file a line
>>>>       <td colspan=5 class=xl28 width=727 style='width:
>>>> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn????kologie </
>>>> td>
>>>> is generated.                                 .
>>>> I tried to solve this by using iconv, without success.
>>>> The problem remains the same in the rgui and rterm - in rterm the
>>>> resulting filename is "Itemtabelle ?rzte Innere,
>>>> Gyn?kologie  .html".
>>>>
>>>> Cheers,
>>>> Matthias
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phgrosjean at sciviews.org  Sat Dec 29 23:55:12 2007
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Sat, 29 Dec 2007 23:55:12 +0100 (CET)
Subject: [Rd] Typo in ?options for warning.length (PR#10536)
Message-ID: <20071229225512.3340B2834170@mail.pubhealth.ku.dk>

In ?options, one reads warnings.length, but it should be warning.length.

Version:
  platform = i386-apple-darwin8.10.1
  arch = i386
  os = darwin8.10.1
  system = i386, darwin8.10.1
  status =
  major = 2
  minor = 6.1
  year = 2007
  month = 11
  day = 26
  svn rev = 43537
  language = R
  version.string = R version 2.6.1 (2007-11-26)


From tlumley at u.washington.edu  Sun Dec 30 03:44:22 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sat, 29 Dec 2007 18:44:22 -0800 (PST)
Subject: [Rd] large netCDF files under Windows.
Message-ID: <Pine.LNX.4.43.0712291844220.7069@hymn33.u.washington.edu>


Has anyone successfully used R to access netCDF files larger than 2Gb under Windows?

With the version of the ncdf package that Brian Ripley provides for CRAN extras I get an assertion failure with a 12Gb file, but not a 1Gb subset of it. The same 12Gb file is ok with ncdf on Mac OS X (32bit R) and on Linux(64bit R).


    -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From chcocoysfe at gmail.com  Sun Dec 30 06:23:20 2007
From: chcocoysfe at gmail.com (=?GB2312?B?s8zP/sP3?=)
Date: Sun, 30 Dec 2007 13:23:20 +0800
Subject: [Rd] some questions about startup Rserve
Message-ID: <bf5481070712292123n11bda784k3fbd84e4cdeb4452@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071230/8bb109c9/attachment.pl 

From phgrosjean at sciviews.org  Sun Dec 30 11:14:22 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 30 Dec 2007 11:14:22 +0100
Subject: [Rd] gettext() and messages in 'pkg' domain
Message-ID: <47776F7E.70307@sciviews.org>

Hello,

As I understand it, gettext() is designed to retrieve messages from 
'R-pkg' domains. As such, it cannot retrieve some of the messages in the 
'pkg' domains (those supposed to be accessed by C code only, I know), 
namely, all messages ending with space(s) or \n. This is clearly 
indicated in ?gettext (at least for trailing spaces):

"For 'gettext', leading and trailing whitespace is ignored when looking 
for the translation."

So, my questions:
1) Do I really need to write C code to retrieve all messages from 'pkg' 
domain?

2) Wouldn't it be useful to add an argument to gettext() (like trim = 
TRUE), or alternatively, to propose a Gettext() function in utils 
packages that allows retrieving those messages with trailing space(s) or 
\n in 'pkg' domain from R code?

Best,

Philippe Grosjean


From ripley at stats.ox.ac.uk  Sun Dec 30 11:39:27 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Dec 2007 10:39:27 +0000 (GMT)
Subject: [Rd] gettext() and messages in 'pkg' domain
In-Reply-To: <47776F7E.70307@sciviews.org>
References: <47776F7E.70307@sciviews.org>
Message-ID: <Pine.LNX.4.64.0712301024530.12124@gannet.stats.ox.ac.uk>

On Sun, 30 Dec 2007, Philippe Grosjean wrote:

> Hello,
>
> As I understand it, gettext() is designed to retrieve messages from
> 'R-pkg' domains. As such, it cannot retrieve some of the messages in the
> 'pkg' domains (those supposed to be accessed by C code only, I know),
> namely, all messages ending with space(s) or \n. This is clearly
> indicated in ?gettext (at least for trailing spaces):
>
> "For 'gettext', leading and trailing whitespace is ignored when looking
> for the translation."

(\n _is_ whitespace).

> So, my questions:
> 1) Do I really need to write C code to retrieve all messages from 'pkg'
> domain?

Yes.

> 2) Wouldn't it be useful to add an argument to gettext() (like trim =
> TRUE), or alternatively, to propose a Gettext() function in utils
> packages that allows retrieving those messages with trailing space(s) or
> \n in 'pkg' domain from R code?

Apparently only useful to you: it's certainly not useful for the 
internationalization of R itself, and I don't see why you can't organize 
the package so that the C-level messages don't have leading/trailing 
whitespace *if* you want to mix up domains.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From phgrosjean at sciviews.org  Sun Dec 30 11:48:01 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 30 Dec 2007 11:48:01 +0100
Subject: [Rd] gettext() and messages in 'pkg' domain
In-Reply-To: <Pine.LNX.4.64.0712301024530.12124@gannet.stats.ox.ac.uk>
References: <47776F7E.70307@sciviews.org>
	<Pine.LNX.4.64.0712301024530.12124@gannet.stats.ox.ac.uk>
Message-ID: <47777761.8070205@sciviews.org>

Prof Brian Ripley wrote:
> On Sun, 30 Dec 2007, Philippe Grosjean wrote:
> 
>> Hello,
>>
>> As I understand it, gettext() is designed to retrieve messages from
>> 'R-pkg' domains. As such, it cannot retrieve some of the messages in the
>> 'pkg' domains (those supposed to be accessed by C code only, I know),
>> namely, all messages ending with space(s) or \n. This is clearly
>> indicated in ?gettext (at least for trailing spaces):
>>
>> "For 'gettext', leading and trailing whitespace is ignored when looking
>> for the translation."
> 
> (\n _is_ whitespace).

Yes, soory.

>> So, my questions:
>> 1) Do I really need to write C code to retrieve all messages from 'pkg'
>> domain?
> 
> Yes.
> 
>> 2) Wouldn't it be useful to add an argument to gettext() (like trim =
>> TRUE), or alternatively, to propose a Gettext() function in utils
>> packages that allows retrieving those messages with trailing space(s) or
>> \n in 'pkg' domain from R code?
> 
> Apparently only useful to you: it's certainly not useful for the 
> internationalization of R itself, and I don't see why you can't organize 
> the package so that the C-level messages don't have leading/trailing 
> whitespace *if* you want to mix up domains.

Messages are is someone else's package. So, I have no control on them!


From ripley at stats.ox.ac.uk  Sun Dec 30 13:11:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Dec 2007 12:11:16 +0000 (GMT)
Subject: [Rd] large netCDF files under Windows.
In-Reply-To: <Pine.LNX.4.43.0712291844220.7069@hymn33.u.washington.edu>
References: <Pine.LNX.4.43.0712291844220.7069@hymn33.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0712301205540.14525@gannet.stats.ox.ac.uk>

The netcdf code is rather silly: it uses 64-bit versions of seek etc when 
building a DLL, not on Windows.  I can rebuild it using 64-bit seek, but 
could you please send me (privately) a test case?

On Sat, 29 Dec 2007, Thomas Lumley wrote:

>
> Has anyone successfully used R to access netCDF files larger than 2Gb 
> under Windows?
>
> With the version of the ncdf package that Brian Ripley provides for CRAN 
> extras I get an assertion failure with a 12Gb file, but not a 1Gb subset 
> of it. The same 12Gb file is ok with ncdf on Mac OS X (32bit R) and on 
> Linux(64bit R).
>
>
>    -thomas
>
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Sun Dec 30 20:08:29 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 30 Dec 2007 14:08:29 -0500
Subject: [Rd] encoding question again
In-Reply-To: <Pine.LNX.4.64.0712291718580.1229@gannet.stats.ox.ac.uk>
References: <004201c848c4$b2fbb790$15b2a8c0@lifebook2>
	<A9D3E344-3B44-42C8-97EC-978AE5D2246D@r-project.org>
	<004301c848ca$6c083510$15b2a8c0@lifebook2>
	<17963695-ACD0-49B2-B8EA-E11C5DF2ECE5@r-project.org>
	<3219D6A4-8F66-43E3-A096-69BCF12F2FFD@r-project.org>
	<Pine.LNX.4.64.0712291718580.1229@gannet.stats.ox.ac.uk>
Message-ID: <60C0665B-2074-437C-8833-1A3F092D6C0D@r-project.org>

Brian,

On Dec 29, 2007, at 12:28 PM, Prof Brian Ripley wrote:

> On Sat, 29 Dec 2007, Simon Urbanek wrote:
>
>> Oops, this was supposed to be a private reply ;) - sorry about the
>> noise. The essence in English:
>> JGR uses all strings in UTF-8 encoding, but the system locale reports
>> CP1252 which impedes automatic conversions (because R doesn't know
>> that everything is UTF-8). Specific conversion via iconv works as
>> expected (see the example below).
>
> On Windows there are no UTF-8 locales, but you can probably get the  
> same effect by marking the strings via Encoding(), as they will be  
> converted to CP1252 (a Latin-1 superset) on output.

I was thinking about this before, but I don't have a good solution.  
The problem is that there are many places that may be affected.  
Especially all callbacks assume UTF-8 and since in R they are passed  
as char * they cannot be flagged. It is unfortunate, because JGR  
actually facilitates the use of UTF-8 nicely (e.g. you can create  
Japanese annotated plots regardless of the Windows locale), but it  
cannot pass that ability to R (except silently and sort of  
incorrectly). It is, however, surprising how far you can get despite  
this conflict (basically it works nicely as long as you don't talk to  
the system). Once we force some conversion on callbacks, we lose that  
advantage, so I'm still not sure what's the best solution. One semi- 
fix would be to take care of the latin1 locales and perform all  
conversions there, because they are so limited anyway, that users  
working in latin1 locales don't expect anything fancy to work anyway :).


>  A console that is running in a non-native encoding needs to convert  
> everything going to and from R. We've experimented with running R in  
> UTF-8 on Windows, but then you need to convert _everything_ coming  
> in and going out and (and this is the killer) so would every package  
> with C-level I/O.  (Tcl/Tk and Perl have gone down that route, and  
> to a large extent left their extensions behind.)
>

I agree. On the other hand, ideally there should be very little direct  
I/O in packages and even if it doesn't work in UTF-8, it won't make it  
unusable, just limited.

Most projects adopted UTF-8 or unicode as the native encoding. I think  
we are on the right track (strings flagged with known encoding) and in  
the end we may end up using let's say UTF-8 internally and convert  
only for system calls.
We may also end up supporting a similar concept (string+encoding) on  
the "edges" sooner or later: something like  
WriteConsoleWithEncoding(...) which could flag if possible instead of  
converting. Given that the embedding API needs some more  
consolidation, it may be a good time to tackle this as well. I'm  
hoping to do some cleanup and propose something as a part of the new  
ObjC API for R 2.7 and Mac GUI 2.0, so any input is welcome.

Thanks,
Simon



>>
>> On Dec 29, 2007, at 11:11 AM, Simon Urbanek wrote:
>>
>>> Hallo Matthias,
>>>
>>> On Dec 27, 2007, at 3:52 PM, Matthias Wendel wrote:
>>>
>>>> Hi, simon,
>>>> 	i followed your advice by adding/changing the lines
>>>> abt = iconv(abt,"utf-8","latin1")
>>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>>> encoding = "latin1")
>>>> but this yielded the same results.
>>>
>>> Ich habe endlich eine Windows-Maschine zum Testen und bei mir wird  
>>> der
>>> Dateiname richtig angelegt ...
>>>
>>> Dennoch, anscheinend stimmt die locale nicht - denn JGR benutzt  
>>> immer
>>> UTF-8,  aber das System liefert CP1252. Deswegen scheint die
>>> automatische Konvertierung nicht zu funktionieren
>>> (file(...,encoding..)). Was allerding immer geht, ist die explizite
>>> Konvertierung:
>>>
>>> a=file("foo","wt")
>>> writeLines(iconv(..., "utf-8","latin1"),a)
>>> close(a)
>>>
>>> (FWIW: da die empfohlene Kodierung von Webseiten sowieso UTF-8 ist,
>>> braucht man es eigentlich nicht wirklich ... ;))
>>>
>>> charToRaw ist immer eine guter Test, weil UTF-8 fuer Umlaute meist  
>>> 2-
>>> bytes bracht und latin1 nur eins.
>>>
>>> Viele Gruesse,
>>> Simon
>>>
>>>
>>>> -----Urspr?ngliche Nachricht-----
>>>> Von: Simon Urbanek [mailto:simon.urbanek at r-project.org]
>>>> Gesendet: Donnerstag, 27. Dezember 2007 21:40
>>>> An: Matthias Wendel
>>>> Cc: r-devel at r-project.org
>>>> Betreff: Re: [Rd] encoding question again
>>>>
>>>> Matthias,
>>>>
>>>> you get exactly what you specified - namely UTF-8. If you want your
>>>> html file to be latin1, then you have to say so:
>>>>
>>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>>> encoding = "latin1")
>>>>
>>>> In addition, you're assuming that `abt' is in the correct encoding
>>>> to be understood by your OS. If it's not, you better convert it  
>>>> into
>>>> one.
>>>> From your results it seems as if `abt' is also UTF-8 encoded. Since
>>>> you didn't tell us where you got that from, you should either fix
>>>> the source or use something like iconv(abt,"utf-8","latin1"):
>>>>
>>>> (in UTF-8 locale)
>>>>> abt="n?r"
>>>>> cat(abt,"\n")
>>>> n?r
>>>>> charToRaw(abt)
>>>> [1] 6e c3 bc 72
>>>>> charToRaw(iconv(abt,"utf-8","latin1"))
>>>> [1] 6e fc 72
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>> On Dec 27, 2007, at 3:11 PM, Matthias Wendel wrote:
>>>>
>>>>> Hi, R Devils,
>>>>> I'm running the actual R version in JGR (version 1.5-8 ).
>>>>> Sys.getlocale(category = "LC_ALL") yields [1]
>>>>> "LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.
>>>>> 1252;LC_MONETARY=German_Germany.
>>>>> 1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252"
>>>>>
>>>>> I want to write some HTML-Code enhanced by statistical results and
>>>>> labels encoded in Latin-1, which I pass to a function. Some label
>>>>> shall generate the filename. Although the labels are correctly
>>>>> handled
>>>>> in JGR they are somehow converted when they are written to the  
>>>>> file.
>>>>> Also the filename is not constructed as wanted. The function
>>>>> definition is correctly sourced into R. The function is defined  
>>>>> like
>>>>> this:
>>>>>
>>>>> Itemtabelle.head <- function (abt ){
>>>>> # n?r z?m T?ST
>>>>> zz = file( paste("Itemtabelle/Itemtabelle", abt, ".html"), "wt",
>>>>> encoding = "UTF-8")
>>>>> cat(as.character("<html
>>>>> xmlns:o=\"urn:schemas-microsoft-com:office:office
>>>>> \" xmlns:x=\"urn:schemas-microsoft-com:office:excel\"
>>>>> xmlns=\"http://www.w3.org/TR/REC-html40
>>>>> \">  \n"),
>>>>>    as.character("
>>>>> <
>>>>> head
>>>>>>
>>>>>
>>>>> \n "),
>>>>> 		.
>>>>> 		.
>>>>> 		.
>>>>>    as.character("        <td colspan=5 class=xl28 width=727 style=
>>>>> \'width:545pt\'>Gesundheitsindikatoren:  "), abt, as.character("</
>>>>> td>                                   \n"),
>>>>>    as.character("       </
>>>>> tr
>>>>>>
>>>>>
>>>>> "), file  = zz)
>>>>>    close(zz)
>>>>>    unlink(zz)
>>>>> }
>>>>> Setting abt as " ?rzte Innere, Gyn?kologie" and calling the  
>>>>> function
>>>>> with this argument, yields a filename "Itemtabelle  ??rzte Innere,
>>>>> Gyn??kologie .html" and in the file a line
>>>>>      <td colspan=5 class=xl28 width=727 style='width:
>>>>> 545pt'>Gesundheitsindikatoren:    ????rzte Innere, Gyn??? 
>>>>> ?kologie </
>>>>> td>
>>>>> is generated.                                 .
>>>>> I tried to solve this by using iconv, without success.
>>>>> The problem remains the same in the rgui and rterm - in rterm the
>>>>> resulting filename is "Itemtabelle ?rzte Innere,
>>>>> Gyn?kologie  .html".
>>>>>
>>>>> Cheers,
>>>>> Matthias
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Sun Dec 30 20:19:47 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 30 Dec 2007 14:19:47 -0500
Subject: [Rd] some questions about startup Rserve
In-Reply-To: <bf5481070712292123n11bda784k3fbd84e4cdeb4452@mail.gmail.com>
References: <bf5481070712292123n11bda784k3fbd84e4cdeb4452@mail.gmail.com>
Message-ID: <EA400CF9-6D57-4A2B-8CC4-B0986BC12F46@r-project.org>


On Dec 30, 2007, at 12:23 AM, ??? wrote:

>    I realize the communication between R and Java with Rserve in my
> dissertation, but i can not run the Rserve by double click of  
> Rserve.exe,

Use
library(Rserve)
Rserve()
instead. You need to setup PATH correctly in order to run it manually  
- please read the documentation it is explained there:
http://www.rforge.net/Rserve/doc.html


> and also i can't realize backstage running of Rserve by technique of
> Multi-thread in Java. Can anyone tell me why?

Windows doesn't have fork(), so you cannot have more than one session  
in one Rserve in Windows. Use of a unix computer as a server is highly  
recommended as that allows arbitrarily many connections in parallel  
with almost zero startup overhead. On Windows you can still spawn  
multiple Rserve instances in parallel, but make sure you're not trying  
to connect to the same instance twice.


>    So, before i run the Java, i must run the R manually, then input
> "Rserve()" or "system("Rserve")". This results in the incompactness  
> of my
> software architecture.In order to solve this problem, i have tried  
> many
> method.

Again - just read the documentation - all you need is correctly  
installed R and R.dll on your PATH.


> For example, i tried to input "Rserve()" to the .Rprofile of R, but
> when i run the R, hundreds of processes were started, then my computer
> system was down. would anyone help me to solve this problem?

Cheers,
Simon

PS: Please use stats-rosuda-devel mailing list for questions on  
Rserve, JGR, rJava etc.


From nmcalder at verizon.net  Sun Dec 30 23:25:22 2007
From: nmcalder at verizon.net (Matt Calder)
Date: Sun, 30 Dec 2007 17:25:22 -0500
Subject: [Rd] Problem with dyn.load'ed code
Message-ID: <1199053522.17113.29.camel@calder-linux>

All,
	I am still having trouble dyn.load'ing some code into R. I have
isolated the problem, I wonder if someone could explain what I am
seeing. 
	I think the problem is that a symbol defined in my compiled code
clashes with one already defined in R. The result is that the function
in my code is not called. Here is an example

// lnktst.cc
extern "C" 
{
  void func(double *out1, double *out2);
  void dnrm2_(double *out);
  void dnrm3_(double *out);
}

void func(double *out1, double *out2) 
{
  dnrm2_(out1);
  dnrm3_(out2);
}

void dnrm2_(double *out)
{
  *out = 1234.5;
}

void dnrm3_(double *out)
{
  *out = 6789.0;
}
// End of lnktst.cc

When I compile:

g++ -shared -static -o lnktst.so lnktst.cc

and then in R I call "func"

> dyn.load("lnktst.so")
> .C('func', double(1), double(1))
[[1]]
[1] 0

[[2]]
[1] 6789

So, as you can see, the function "dnrm2_" is not called whereas "dnrm3_"
is, even though both functions are identical in form. Now, I believe
dnrm2_ is a BLAS function, and so it is likely R already has a copy
floating around. However, it surprises me that the "-static" option does
not force the call in my code to "dnrm2_" to be linked to the function
defined in my code. 
	I have been writing C code for Splus for quite a while and don't recall
ever running across this issue. However, I am new to R, so I wonder, am
I missing something obvious?  
	I am running this on Ubuntu Linux, the output of uname -a is:

Linux calder-linux 2.6.22-14-generic #1 SMP Sun Oct 14 23:05:12 GMT 2007 i686 GNU/Linux

Thanks for any help,

	Matt


From simon.urbanek at r-project.org  Mon Dec 31 02:21:41 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 30 Dec 2007 20:21:41 -0500
Subject: [Rd] Problem with dyn.load'ed code
In-Reply-To: <1199053522.17113.29.camel@calder-linux>
References: <1199053522.17113.29.camel@calder-linux>
Message-ID: <5C33CB00-7BE2-4169-8AD6-510BA58977D7@r-project.org>

Matt,

On Dec 30, 2007, at 5:25 PM, Matt Calder wrote:

> 	I am still having trouble dyn.load'ing some code into R. I have  
> isolated the problem, I wonder if someone could explain what I am  
> seeing.
> 	I think the problem is that a symbol defined in my compiled code  
> clashes with one already defined in R.

The result of redefining a symbol is very much system-dependent. For  
example on Mac OS X it has no adverse effects (i.e your symbols are  
always private unless linked against), because it uses a two-level  
namespace, but on Linux (and most other unices) it does as the  
namespace of an executable is shared among all modules (dynamic and  
static).


> The result is that the function in my code is not called. Here is an  
> example
>
> // lnktst.cc
> extern "C"
> {
>  void func(double *out1, double *out2);
>  void dnrm2_(double *out);
>  void dnrm3_(double *out);
> }
>
> void func(double *out1, double *out2)
> {
>  dnrm2_(out1);
>  dnrm3_(out2);
> }
>
> void dnrm2_(double *out)
> {
>  *out = 1234.5;
> }
>
> void dnrm3_(double *out)
> {
>  *out = 6789.0;
> }
> // End of lnktst.cc
>
> When I compile:
>
> g++ -shared -static -o lnktst.so lnktst.cc
>
> and then in R I call "func"
>
>> dyn.load("lnktst.so")
>> .C('func', double(1), double(1))
> [[1]]
> [1] 0
>
> [[2]]
> [1] 6789
>
> So, as you can see, the function "dnrm2_" is not called whereas  
> "dnrm3_" is, even though both functions are identical in form. Now,  
> I believe dnrm2_ is a BLAS function, and so it is likely R already  
> has a copy floating around.

Yes, indeed (it's a BLAS level 1 Fortran function, and usually to be  
found in libRblas.so or the external BLAS implementation).


> However, it surprises me that the "-static" option does
> not force the call in my code to "dnrm2_" to be linked to the function
> defined in my code.

You are confusing the purpose of -static: it only ensures that static  
libraries are used at link time where possible, it doesn't affect your  
code in any way. What you really want is to use
static void dnrm2_(double *out);
in your code instead.

In general, it is a bad idea to use external symbols that clash with  
other libraries (in particular widespread ones such as BLAS),  
especially if your function doesn't perform the same operation. It is  
a good idea to declare all functions that you use internally (i.e.  
that should not be visible to R) as static. However, all this is true  
for C programming in general, not just in conjunction with R.

Cheers,
Simon


> 	I have been writing C code for Splus for quite a while and don't  
> recall
> ever running across this issue. However, I am new to R, so I wonder,  
> am
> I missing something obvious?
> 	I am running this on Ubuntu Linux, the output of uname -a is:
>
> Linux calder-linux 2.6.22-14-generic #1 SMP Sun Oct 14 23:05:12 GMT  
> 2007 i686 GNU/Linux
>
> Thanks for any help,
>
> 	Matt
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From nmcalder at verizon.net  Mon Dec 31 04:43:50 2007
From: nmcalder at verizon.net (Matt Calder)
Date: Sun, 30 Dec 2007 22:43:50 -0500
Subject: [Rd] Problem with dyn.load'ed code
In-Reply-To: <5C33CB00-7BE2-4169-8AD6-510BA58977D7@r-project.org>
References: <1199053522.17113.29.camel@calder-linux>
	<5C33CB00-7BE2-4169-8AD6-510BA58977D7@r-project.org>
Message-ID: <1199072630.17113.54.camel@calder-linux>

Simon,
	Thanks for the reply. Indeed, declaring the function static fixes the
example. Unfortunately, the real problem that gave rise to the example
arises in a large Fortran library that is not under my control (ARPACK).
The author is providing BLAS and LAPACK functionality intentionally.
That may or may not be good practice, but it is a given in this case.
	So, I have a set of Fortran code in which some BLAS functionality is
replicated. I am writing an interface to some of the functions in that
code (not to the BLAS part, that is used internally by ARPACK). I would
like it if that interface did not require alteration of the library
source code or build process (though it is open-source, so if need be I
can change it). 
	I still feel like the linker ought to be able to solve this problem for
me. My impression was that the static keyword passed to the linker
caused it to resolve all references at link time. So something like:

ld -o my_code_and_arpack.o -static my_code.o -larpack

would pull all the references from the two object files (my_code.o and
libarpack.a) and link them as needed, and unresolved references would
cause an error. I guess that impression is wrong, but how does one
accomplish the same thing? 
	Thanks for any help,

	Matt
	

On Sun, 2007-12-30 at 20:21 -0500, Simon Urbanek wrote:
> Matt,
> 
> On Dec 30, 2007, at 5:25 PM, Matt Calder wrote:
> 
> > 	I am still having trouble dyn.load'ing some code into R. I have  
> > isolated the problem, I wonder if someone could explain what I am  
> > seeing.
> > 	I think the problem is that a symbol defined in my compiled code  
> > clashes with one already defined in R.
> 
> The result of redefining a symbol is very much system-dependent. For  
> example on Mac OS X it has no adverse effects (i.e your symbols are  
> always private unless linked against), because it uses a two-level  
> namespace, but on Linux (and most other unices) it does as the  
> namespace of an executable is shared among all modules (dynamic and  
> static).
> 
> 
> > The result is that the function in my code is not called. Here is an  
> > example
> >
> > // lnktst.cc
> > extern "C"
> > {
> >  void func(double *out1, double *out2);
> >  void dnrm2_(double *out);
> >  void dnrm3_(double *out);
> > }
> >
> > void func(double *out1, double *out2)
> > {
> >  dnrm2_(out1);
> >  dnrm3_(out2);
> > }
> >
> > void dnrm2_(double *out)
> > {
> >  *out = 1234.5;
> > }
> >
> > void dnrm3_(double *out)
> > {
> >  *out = 6789.0;
> > }
> > // End of lnktst.cc
> >
> > When I compile:
> >
> > g++ -shared -static -o lnktst.so lnktst.cc
> >
> > and then in R I call "func"
> >
> >> dyn.load("lnktst.so")
> >> .C('func', double(1), double(1))
> > [[1]]
> > [1] 0
> >
> > [[2]]
> > [1] 6789
> >
> > So, as you can see, the function "dnrm2_" is not called whereas  
> > "dnrm3_" is, even though both functions are identical in form. Now,  
> > I believe dnrm2_ is a BLAS function, and so it is likely R already  
> > has a copy floating around.
> 
> Yes, indeed (it's a BLAS level 1 Fortran function, and usually to be  
> found in libRblas.so or the external BLAS implementation).
> 
> 
> > However, it surprises me that the "-static" option does
> > not force the call in my code to "dnrm2_" to be linked to the function
> > defined in my code.
> 
> You are confusing the purpose of -static: it only ensures that static  
> libraries are used at link time where possible, it doesn't affect your  
> code in any way. What you really want is to use
> static void dnrm2_(double *out);
> in your code instead.
> 
> In general, it is a bad idea to use external symbols that clash with  
> other libraries (in particular widespread ones such as BLAS),  
> especially if your function doesn't perform the same operation. It is  
> a good idea to declare all functions that you use internally (i.e.  
> that should not be visible to R) as static. However, all this is true  
> for C programming in general, not just in conjunction with R.
> 
> Cheers,
> Simon
> 
> 
> > 	I have been writing C code for Splus for quite a while and don't  
> > recall
> > ever running across this issue. However, I am new to R, so I wonder,  
> > am
> > I missing something obvious?
> > 	I am running this on Ubuntu Linux, the output of uname -a is:
> >
> > Linux calder-linux 2.6.22-14-generic #1 SMP Sun Oct 14 23:05:12 GMT  
> > 2007 i686 GNU/Linux
> >
> > Thanks for any help,
> >
> > 	Matt
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>


From jeff.a.ryan at gmail.com  Mon Dec 31 06:53:39 2007
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 30 Dec 2007 23:53:39 -0600
Subject: [Rd] as.Date.numeric origin default
Message-ID: <e8e755250712302153ha84354bw53f14a280f22506@mail.gmail.com>

R-devel,

I would like to second Gabor Grothendieck's request from September (
http://www.nabble.com/as.Date.numeric-to12962733.html#a12962733 )
on adding a default value (1970-01-01) to the origin argument of
as.Date.numeric.

I realize there is good reason to allow for origin to be specified,
but I don't see why it must be up to the user at each and every
invocation if most (if not all) users will simply be using 1970-01-01.

My first contact was building quantmod for CRAN - many more hidden
errors occur as I test  on R-devel.  It just seems to me to be an easy
compromise to what will undoubtedly cost many hours of debugging
across all packages/users.

Thank you for your consideration,
Jeff Ryan


From merrick.mccracken at gmail.com  Sun Dec 30 16:55:25 2007
From: merrick.mccracken at gmail.com (merrick.mccracken at gmail.com)
Date: Sun, 30 Dec 2007 16:55:25 +0100 (CET)
Subject: [Rd] Browse option to change working directory (PR#10537)
Message-ID: <20071230155525.58C9F282EFF7@mail.pubhealth.ku.dk>

Full_Name: Merrick McCracken
Version: 2.6.1
OS: Vista Home Premium 32-bit
Submission from: (NULL) (63.239.240.2)


In the R GUI I select File>Change dir... to change the working directory and
select browse and the only folders available to select are those on the Desktop
and none others. I am running in Windows Vista. If I were to select Load
Workspace... or Source R Code... I can browse freely through my hard drive but
with the Browse option in Change dir... I cannot. Thanks.


From ripley at stats.ox.ac.uk  Mon Dec 31 10:00:12 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 31 Dec 2007 10:00:12 +0100 (CET)
Subject: [Rd] Browse option to change working directory (PR#10537)
Message-ID: <20071231090013.097902834620@mail.pubhealth.ku.dk>

This is the same as PR#9959, a known Vista bug.  It is documented under
?choose.dir.

On Sun, 30 Dec 2007, merrick.mccracken at gmail.com wrote:

> Full_Name: Merrick McCracken
> Version: 2.6.1
> OS: Vista Home Premium 32-bit
> Submission from: (NULL) (63.239.240.2)
>
>
> In the R GUI I select File>Change dir... to change the working directory and
> select browse and the only folders available to select are those on the Desktop
> and none others. I am running in Windows Vista. If I were to select Load
> Workspace... or Source R Code... I can browse freely through my hard drive but
> with the Browse option in Change dir... I cannot. Thanks.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sdavis2 at mail.nih.gov  Mon Dec 31 18:58:17 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 31 Dec 2007 12:58:17 -0500
Subject: [Rd] readBin differences on Windows and Linux/mac
Message-ID: <264855a00712310958o42483fa6g27e0111ed6d01b16@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071231/f2070c0d/attachment.pl 

From ligges at statistik.uni-dortmund.de  Mon Dec 31 19:24:48 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 31 Dec 2007 19:24:48 +0100
Subject: [Rd] readBin differences on Windows and Linux/mac
In-Reply-To: <264855a00712310958o42483fa6g27e0111ed6d01b16@mail.gmail.com>
References: <264855a00712310958o42483fa6g27e0111ed6d01b16@mail.gmail.com>
Message-ID: <477933F0.6080205@statistik.uni-dortmund.de>

Can you give a reproducible example, pelase?

Uwe Ligges


Sean Davis wrote:
> I have been trying to use the gunzip function in the R.utils package.  It
> opens a connection to a gzfile, uses readBin to read from that connection,
> and then uses writeBin to write out the raw data to a new file.  This works
> as expected under linux/mac, but under Windows, I get:
> 
> Error in readBin(inn, what= raw(0), size = 1, n=BFR.SIZE)  :
>   negative length vectors are not allowed
> 
> A simple traceback shows the error in readBin.  I wouldn't be surprised if
> this is a programming issue not located in readBin, but I am confused about
> the difference in behaviors on Windows versus mac/linux.  Any insight into
> what I can do to remedy the issue and have a cross-platform gunzip()?
> 
> Thanks,
> Sean
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sdavis2 at mail.nih.gov  Mon Dec 31 20:51:16 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 31 Dec 2007 14:51:16 -0500
Subject: [Rd] readBin differences on Windows and Linux/mac
In-Reply-To: <477933F0.6080205@statistik.uni-dortmund.de>
References: <264855a00712310958o42483fa6g27e0111ed6d01b16@mail.gmail.com>
	<477933F0.6080205@statistik.uni-dortmund.de>
Message-ID: <264855a00712311151w7a43dbeara85e6abb0e6cec22@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20071231/433ee1ad/attachment.pl 

From atp at piskorski.com  Mon Dec 31 21:30:10 2007
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 31 Dec 2007 15:30:10 -0500
Subject: [Rd] Problem with dyn.load'ed code
In-Reply-To: <1199072630.17113.54.camel@calder-linux>
References: <1199072630.17113.54.camel@calder-linux>
Message-ID: <20071231203010.GA72526@piskorski.com>

On Sun, Dec 30, 2007 at 10:43:50PM -0500, Matt Calder wrote:
> Simon,
> 	Thanks for the reply. Indeed, declaring the function static fixes the
> example. Unfortunately, the real problem that gave rise to the example
> arises in a large Fortran library that is not under my control (ARPACK).
> The author is providing BLAS and LAPACK functionality intentionally.
> That may or may not be good practice, but it is a given in this case.

Ok, so R is calling its one "dnrm2_" function, let's call this "A",
while ARPACK defines a second, different "dnrm2_", which we'll call
"B".  You want to call function A from your own C code, while R keeps
calling function A as before without any change or interference.  And
of course, A and B are two C-coded functions with different behaviors
but the exact same name.  You can make that work, it just requires
some tricks.

> 	I still feel like the linker ought to be able to solve this problem for
> me. My impression was that the static keyword passed to the linker

It can, you just need to tell it exactly what you want.  I assume you
are building your own custom C code into a shared library, which you
then load into R.

Thus, one solution is to statically link the ARPACK library into your
own shared library, and then carefully tell the linker which symbols
to export and which to keep private inside your shared library.  As
long as the symbol ARPACK's "B" dnrm2_ function is kept private inside
your own shared library (not exported), R will never see it and will
happily keep using dnrm2_ "A" as before.

That's how I've solved this sort of name collision problem in the
past.  In your "src/Makevars", you may want something like to this:

  PKG_LIBS = -Wl,--version-script=vis.map -Wl,-Bstatic -L/usr/local/lib/ARPACK -lARPACK -Wl,-Bdynamic

You may also need a PG_PKG_LIBS with the same stuff, but I don't
remember why.  The '--version-script=' and related matters were also
disccussed here back in February:

  https://stat.ethz.ch/pipermail/r-devel/2007-February/044531.html

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


