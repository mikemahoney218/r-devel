From Mark.Bravington at csiro.au  Wed Sep  1 00:18:23 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 1 Sep 2010 08:18:23 +1000
Subject: [Rd] RCMD CHECK and non-methods
In-Reply-To: <80CFAA95-BC98-47AE-8A16-9CB753880E7D@r-project.org>
References: <62C82B39B8A85E4B95A18F7F7B852F870576DBBB76@exvic-mbx03.nexus.csiro.au>
	<19574.35318.774118.197785@lynne.math.ethz.ch>,
	<80CFAA95-BC98-47AE-8A16-9CB753880E7D@r-project.org>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F870576DBBB86@exvic-mbx03.nexus.csiro.au>

Thanks for those (very different!) responses. I was about to respond to Martin's question about doco amendments, when I saw Simon's reply. 

Case 1: If Martin completely prevails, then I guess the appropriate amendment to the documentation would be in R-extensions, section 1.3.1 "Checking packages", item 10:

  <<... In addition, it is checked whether methods have all arguments of the corresponding generic,...>>

would become

  <<... In addition, it is checked whether potential methods[1] have all arguments of the corresponding generic,...>>

where [1] refers to a footnote:

  <<"Potential methods" here includes any function whose name starts with a known S3 generic followed by a period, e.g. 'subset.blahblah.blah'. This applies regardless of whether the function is formally registered as an S3 method (see 1.6.2), and even if the function is not intended to be a method at all. It is bad practice to give method-like names to non-methods.>>
  
For absolutely strict super-nanny-level consistency, maybe there ought also to be a change somewhere in the QC/codoc code, to detect "methods" that haven't been registered with 'S3method', and/or have non-generic-style USAGE sections, regardless of whether they happen to have arguments compatible with whatever generic R thinks they belong to. At present, there is a difference in what 'tools::checkDocStyle' and 'tools::checkS3methods' regard as a method. However, enforcing this extra check does strike me as a bit draconian, and would certainly break back-compatibility (in other bits of my code, for a start). You'd have to ask whether it's worth the effort. In my example, I don't think it's worth worrying that anyone is ever going to define an S3 class called 'with.warning' and decide to call 'subset' on it.

Case 2: If Simon completely prevails, then there should be changes in 'tools::checkS3methods' to exempt "documented non-methods". I think the appropriate definition of "documented non-methods" would be functions with a USAGE section that includes the full function name rather than the generic. That's supposed to cover packages with and without NAMESPACEs.

WRTO Simon's comment: I feel the same negative way about camel-case for the same reasons, and would want a much stronger reason to change the naming convention I've been using for 15 years; it's hard enough to remember what name I gave to a function, letAlone how_I_decided to.spell ItThatWeek.

However, I really really hope that S3 *doesn't* get replaced by S4! S3 is very easy to use, and for me it "just works" 99% of the time. Just occasionally it doesn't, but for me at least "the [S4] cure is worse than the [S3] disease". I'll keep an open mind about R5 ;)

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: Simon Urbanek [simon.urbanek at r-project.org]
Sent: 27 August 2010 02:46
To: Martin Maechler
Cc: Bravington, Mark (CMIS, Hobart); r-devel at r-project.org
Subject: Re: [Rd] RCMD CHECK and non-methods

On Aug 26, 2010, at 11:36 AM, Martin Maechler wrote:

>>>>>>  <Mark.Bravington at csiro.au>
>>>>>>    on Wed, 25 Aug 2010 14:06:07 +1000 writes:
>
>> I recently moved a function 'subset.with.warning' into the 'mvbutils' package (a version not yet on CRAN). When I tried RCMD CHECK, I got this warning:
>> * checking S3 generic/method consistency ... WARNING
>> subset:
>> function(x, ...)
>> subset.with.warning:
>> function(x, cond, mess.head, mess.cond, row.info, sub)
>
>> See section 'Generic functions and methods' of the 'Writing R Extensions'
>> manual.
>
>> I know that S3 method arguments need to be compatible with arguments of the generic. However, 'subset.with.warning' is deliberately not a registered S3 method,
>
> I think that's your real trouble ... and then your users' if you
> really insist.
> Short answer:  "Don't do that!"
>
> There have been a few exceptions of "100 years old" R functions
> which validated this rule,
> the most notable probably  t() and t.test(),
> and we (R core) have explicitly listed them in the code base
> as "yes, looks like a method for an S3 generic, but not it ain't!",
> but have basically "forbidden" to commit more such crimes.
> {Also, if you are interested: I think both  t() and t.test()
> pre-dated S3}
>

However, one would hope that S3 will be replaced by S4 (or R5? ;)) eventually so requiring such an arcane rule seems little strong. Personally, I prefer the use of . to that of camelCase [I find it more readable and faster to type] and thus I'm with Mark on this one. IMHO it is perfectly legal and clean to declare a symbol as a function and not an S3 method.

Cheers,
Simon



>
>> and its USAGE section doesn't include a \method{generic}{class} statement. I couldn't see anything in "R Extensions" that says "don't do this", so I'm wondering:
>
> Yes, we should add a such "don't do this" somewhere.
>
> Can you propose a good place to put it in there?
>
>> - should this really be a NOTE not a WARNING (or nothing at all)?
>
> {from the above: definitely a warning, if not "worse"}....
>
> Best regards,
> Martin
>
> Martin Maechler, ETH Zurich
>
>> - if not, shouldn't there be a more explicit statement to the effect that "if R decides it's a method, then it damned well is a method, whether you think it is or not"?
>
>> - and if so, should there also be a check for functions that look like methods but aren't registered and declared as such?
>
>> My preference would be for the first, FWIW. Admittedly, just because I didn't register 'subset.with.warning' as an S3 method, that won't stop 'subset' from trying to use it if it ever encounters an object of class "with.warning". It's a risk that I'm happy to take, though CRAN might not be...
>
>> I made the warning go away by adding a '...' argument to the end of 'subset.with.warning', but that's not pretty.
>
>> Mark Bravington
>> CSIRO
>> Hobart
>> Australia
>
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-06-30 r52418)
>> i386-pc-mingw32
>
>> locale:
>> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252    LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_Australia.1252
>
>> attached base packages:
>> [1] grDevices tools     tcltk     stats     graphics  utils     methods   base
>
>> other attached packages:
>> [1] ad_1.0         chstuff_1.0    handy2_1.2     tweedie_2.0.2  statmod_1.4.1  handy_1.1      debug_1.2.3    mvbutils_2.5.2
>>>
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

From michel at michelboaventura.com  Wed Sep  1 00:45:58 2010
From: michel at michelboaventura.com (Michel Boaventura)
Date: Tue, 31 Aug 2010 19:45:58 -0300
Subject: [Rd] R with multiple processors
In-Reply-To: <alpine.DEB.2.00.1008310723470.2626@luke-inspiron>
References: <4C7BD98A.3070608@michelboaventura.com>
	<alpine.DEB.2.00.1008310723470.2626@luke-inspiron>
Message-ID: <4C7D8626.9080307@michelboaventura.com>

Em 31-08-2010 09:24, luke at stat.uiowa.edu escreveu:
> We are working on extending the approach in pnmath to other functions.
> Hopefully this will make it int othe R distribution in some form
> within the next couple of releases.

That is very nice. Is there a place where I can see how the work is
going, and try to help it out?

Regards


From pdalgd at gmail.com  Wed Sep  1 13:50:00 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 1 Sep 2010 13:50:00 +0200
Subject: [Rd] R and Epi Info
In-Reply-To: <30CCD2C98CF7EC46ABF4CD310179FD6501D6D2F66591@EXCHANGE11.Enterprise.emory.net>
References: <30CCD2C98CF7EC46ABF4CD310179FD6501D6D2F66591@EXCHANGE11.Enterprise.emory.net>
Message-ID: <376C5F17-4C57-4F42-A0D3-A1CC539532E0@gmail.com>


On Aug 31, 2010, at 10:16 PM, Sullivan, Kevin M wrote:

> Hello,
>   I was wondering who to contact to see about somehow interconnecting or integrating the programs R and Epi Info.  

Well, first of all there is a mailing list, R-sig-epi at lists.r-project.org. It is not very active, but I know that at least some of the regulars are familiar with Epi Info and the list includes the authors of several R packages for epidemiology.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From olafm at statistik.tu-dortmund.de  Wed Sep  1 14:06:37 2010
From: olafm at statistik.tu-dortmund.de (Olaf Mersmann)
Date: Wed, 1 Sep 2010 14:06:37 +0200
Subject: [Rd] Speed improvement for Find() and Position()
Message-ID: <1BBEE9E3-BEF1-4997-83C0-5339A7707424@statistik.tu-dortmund.de>

Dear R-developers,

both Find() and Position() (as the documentation mentions) are currently not optimized in any way. I have rewritten both functions in a more efficient manner by replacing the sapply() with a for() loop that terminates early if a match is found. Here is a patch against the current subversion HEAD

  http://www.statistik.tu-dortmund.de/~olafm/temp/fp.patch

and here are some numbers to show that this change is worth while:

% cat fp_bench.R 
set.seed(42)
pred <- function(z) z == 1

for (n in c(10^(2:4))) {
  x <- sample(1:n, 2*n, replace=TRUE)
  
  tf <- system.time(replicate(1000L, Find(pred, x)))
  message(sprintf("Find    : n=%5i user=%6.3f system=%6.3f",
                  2*n, tf[1], tf[2]))

  tp <- system.time(replicate(1000L, Find(pred, x)))
  message(sprintf("Position: n=%5i user=%6.3f system=%6.3f",
                  2*n, tp[1], tp[2]))
}

## Unpatched R:
% Rscript fp_bench.R 
Find    : n=  200 user= 0.491 system= 0.015
Position: n=  200 user= 0.477 system= 0.014
Find    : n= 2000 user= 4.450 system= 0.083
Position: n= 2000 user= 4.507 system= 0.094
Find    : n=20000 user=63.435 system= 1.497
Position: n=20000 user=63.130 system= 1.328

## Patched R:
% ./bin/Rscript fp_bench.R
Find    : n=  200 user= 0.101 system= 0.013
Position: n=  200 user= 0.085 system= 0.003
Find    : n= 2000 user= 0.781 system= 0.002
Position: n= 2000 user= 0.809 system= 0.012
Find    : n=20000 user=20.537 system= 0.394
Position: n=20000 user=20.502 system= 0.404

Cheers,
Olaf Mersmann

From csr21 at cantab.net  Wed Sep  1 15:27:01 2010
From: csr21 at cantab.net (Christophe Rhodes)
Date: Wed, 01 Sep 2010 14:27:01 +0100
Subject: [Rd] introspective capabilities
References: <87iq2ws25s.fsf@cantab.net> <4C7BD5BB.7050501@gmail.com>
Message-ID: <8762ypmw62.fsf@cantab.net>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 27/08/2010 7:52 AM, Christophe Rhodes wrote:
>> Hi,
>>
>> Is there any way, from R code, to perform introspection as to where
>> certain names acquired their values?
>
> There's the "keep.source" option to source() and the optional
> "srcfile" argument to parse() that tell R to keep this information.
> If you haven't changed the default
> getOption("keep.source") from TRUE, then source will default to
> keeping it, and you can find the original location of a function
> definition for function f by looking in attr(body(f), "srcref").  See
> ?srcref for the format; there aren't a lot of user-level utility
> functions for working with this.

Thanks.  This is enough for my immediate purposes: supporting
single-keystroke (M-.) jumping to source locations of functions.

> For packages, the relevant option is "keep.source.pkgs" at the time
> the package is installed.

Thank you.

Is there anything like a cross-referencing database within R?  The
functionality I'm looking for here is to be able to name a function, and
come back with a list of functions (or srcrefs) where that name is
used.  (I realise that this is not in general possible; just the
lexically-apparent cases would be enough).

Cheers,

Christophe


From murdoch.duncan at gmail.com  Wed Sep  1 15:59:22 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 Sep 2010 09:59:22 -0400
Subject: [Rd] introspective capabilities
In-Reply-To: <8762ypmw62.fsf@cantab.net>
References: <87iq2ws25s.fsf@cantab.net> <4C7BD5BB.7050501@gmail.com>
	<8762ypmw62.fsf@cantab.net>
Message-ID: <4C7E5C3A.7070006@gmail.com>

On 01/09/2010 9:27 AM, Christophe Rhodes wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> > On 27/08/2010 7:52 AM, Christophe Rhodes wrote:
> >> Hi,
> >>
> >> Is there any way, from R code, to perform introspection as to where
> >> certain names acquired their values?
> >
> > There's the "keep.source" option to source() and the optional
> > "srcfile" argument to parse() that tell R to keep this information.
> > If you haven't changed the default
> > getOption("keep.source") from TRUE, then source will default to
> > keeping it, and you can find the original location of a function
> > definition for function f by looking in attr(body(f), "srcref").  See
> > ?srcref for the format; there aren't a lot of user-level utility
> > functions for working with this.
>
> Thanks.  This is enough for my immediate purposes: supporting
> single-keystroke (M-.) jumping to source locations of functions.
>
> > For packages, the relevant option is "keep.source.pkgs" at the time
> > the package is installed.
>
> Thank you.
>
> Is there anything like a cross-referencing database within R?  The
> functionality I'm looking for here is to be able to name a function, and
> come back with a list of functions (or srcrefs) where that name is
> used.  (I realise that this is not in general possible; just the
> lexically-apparent cases would be enough).


There is no such database already built, but I imagine the functions in 
the codetools package could construct one. 

Duncan Murdoch


From hadley at rice.edu  Wed Sep  1 17:38:30 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 1 Sep 2010 10:38:30 -0500
Subject: [Rd] S3 method for package listed in suggest/enhance
Message-ID: <AANLkTinP-oDc=EHUvFZi3ShsiYwrMeMhi3xEbxyyEBp9@mail.gmail.com>

Hi all,

The profr package provides a method for displaying its output with
ggplot: ggplot.print.  You don't need this ggplot2 to use profr, so
ggplot2 is listed under enhances in the DESCRIPTION file.

If I have just S3method(ggplot, profr) in my NAMESPACE, then I get:

** testing if installed package can be loaded
Error : object 'ggplot' not found whilst loading namespace 'profr'
ERROR: loading failed

If I have both S3method(ggplot, profr) and importFrom(ggplot2,
ggplot), then I get:

* checking package dependencies ... ERROR
Namespace dependency not required: ggplot2

What's the correct way of exporting an S3 method for a generic in a
suggested package?

Thanks,

Hadley



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From adrian at waddell.ch  Wed Sep  1 18:16:03 2010
From: adrian at waddell.ch (Adrian Waddell)
Date: Wed, 01 Sep 2010 12:16:03 -0400
Subject: [Rd] Installing a Tcl/Tk Extension on OSX
Message-ID: <4C7E7C43.7010602@waddell.ch>

Dear R-Community,

I need the Img tk extension for my R package. It all works on my Ubuntu
machine (libtk-img). However I experience a great deal of trouble when I
try to install the package on OSX 10.5 or 10.6 (in fact I'm not able to
do it).

As I understand it, the ActiveTcl with it's teacup package manager do
not have an effect on the the x11 tcl installation which R accesses.
MacPorts however has the libtk-img package not listed and compiling it
from the source (with configure, make all, make install) does not do the
job either for me (adding the compiled package folder to auto_path).

Now, as I would like some R users to once use my R package (once it's on
CRAN), installing the Img tk extension should to be a fairly easy task
on OSX .

Can anybody tell me how I best tackle this problem in a way, such that
OSX R users (and myself) in future can easily install the Img tk package?

Sincerely,

Adrian Waddell


From kjetilbrinchmannhalvorsen at gmail.com  Thu Sep  2 00:22:12 2010
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Wed, 1 Sep 2010 18:22:12 -0400
Subject: [Rd] Looks like a bug in subsetting of a complicated object
Message-ID: <AANLkTikbbiHFZB9fxHCXfHrnJP_iEYSWX58gOXBEi9LK@mail.gmail.com>

I don't understand what is happening! I have a (large) object sim1, an
matrix list
with dim c(101,101) where each element is an 3*3 matrix. I am
subsetting that with
a matrix coo, of dim c(100,2), of unique indices, but the resulting object
has length 99, not 100 as expected.

Code reproducing the problem follows:


library(RandomFields)

set.seed(123)
sim0 <- GaussRF(x=seq(0, 100, by=1),
                y=seq(0, 100, by=1),
                grid=TRUE, model="spherical",
                param=c(0, 1, 0, 10), trend=NULL, n=9, gridtriple=FALSE)

simmatrices <- function(arr) # arr must be an array of rank 3
                        {
               d <- dim(arr)
               n1 <- d[1]; n2 <- d[2] # we suppose d[3]==9
               res <- vector(length=n1*n2, mode="list")
               dim(res) <- c(n1, n2)
               for (i in 1:n1) for (j in 1:n2) {
                 x1 <- arr[i, j, 1:3];x2 <- arr[i, j, 4:6]
                 x3 <- arr[i, j, 7:9]
                 res[[i, j]] <- x1%o%x1 + x2%o%x2 + x3%o%x3
               }
               res
             }

sim1 <- simmatrices(sim0)

set.seed(234)
x <- sample(seq(0, 100, by=1), 101, replace=TRUE)
y <- sample(seq(0, 100, by=1), 101, replace=TRUE)
coo <- cbind(x=x, y=y)
coo <- unique(coo)

sim1.obs <- sim1[coo]

dim(coo)
length(sim1.obs)


> sessionInfo()
R version 2.11.1 (2010-05-31)
i686-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.18-8      gstat_0.9-69        sp_0.9-66
[4] RandomFields_1.3.41

loaded via a namespace (and not attached):
[1] fortunes_1.3-7 grid_2.11.1    tools_2.11.1
>

Kjetil


From Mark.Bravington at csiro.au  Thu Sep  2 05:01:23 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 2 Sep 2010 13:01:23 +1000
Subject: [Rd] introspective capabilities
In-Reply-To: <8762ypmw62.fsf@cantab.net>
References: <87iq2ws25s.fsf@cantab.net> <4C7BD5BB.7050501@gmail.com>
	<8762ypmw62.fsf@cantab.net>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F87057C9E94C3@exvic-mbx03.nexus.csiro.au>

Hi Christophe

You could also look at the 'foodweb' function in package 'mvbutils'-- and specifically 'callers.of'. It should do just what you want, though you do have to tell it which environments to search through.

bye
Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

Christophe Rhodes wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
> 
>> On 27/08/2010 7:52 AM, Christophe Rhodes wrote:
>>> Hi,
>>> 
>>> Is there any way, from R code, to perform introspection as to where
>>> certain names acquired their values?
>> 
>> There's the "keep.source" option to source() and the optional
>> "srcfile" argument to parse() that tell R to keep this information.
>> If you haven't changed the default
>> getOption("keep.source") from TRUE, then source will default to
>> keeping it, and you can find the original location of a function
>> definition for function f by looking in attr(body(f), "srcref").  See
>> ?srcref for the format; there aren't a lot of user-level utility
>> functions for working with this.
> 
> Thanks.  This is enough for my immediate purposes: supporting
> single-keystroke (M-.) jumping to source locations of functions. 
> 
>> For packages, the relevant option is "keep.source.pkgs" at the time
>> the package is installed.
> 
> Thank you.
> 
> Is there anything like a cross-referencing database within R?  The
> functionality I'm looking for here is to be able to name a function,
> and come back with a list of functions (or srcrefs) where that name
> is used.  (I realise that this is not in general possible; just the
> lexically-apparent cases would be enough).    
> 
> Cheers,
> 
> Christophe
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ehlers at ucalgary.ca  Thu Sep  2 07:22:08 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Wed, 01 Sep 2010 23:22:08 -0600
Subject: [Rd] Looks like a bug in subsetting of a complicated object
In-Reply-To: <AANLkTikbbiHFZB9fxHCXfHrnJP_iEYSWX58gOXBEi9LK@mail.gmail.com>
References: <AANLkTikbbiHFZB9fxHCXfHrnJP_iEYSWX58gOXBEi9LK@mail.gmail.com>
Message-ID: <4C7F3480.2010809@ucalgary.ca>

On 2010-09-01 16:22, Kjetil Halvorsen wrote:
> I don't understand what is happening! I have a (large) object sim1, an
> matrix list
> with dim c(101,101) where each element is an 3*3 matrix. I am
> subsetting that with
> a matrix coo, of dim c(100,2), of unique indices, but the resulting object
> has length 99, not 100 as expected.
>
> Code reproducing the problem follows:
>
>
> library(RandomFields)
>
> set.seed(123)
> sim0<- GaussRF(x=seq(0, 100, by=1),
>                  y=seq(0, 100, by=1),
>                  grid=TRUE, model="spherical",
>                  param=c(0, 1, 0, 10), trend=NULL, n=9, gridtriple=FALSE)
>
> simmatrices<- function(arr) # arr must be an array of rank 3
>                          {
>                 d<- dim(arr)
>                 n1<- d[1]; n2<- d[2] # we suppose d[3]==9
>                 res<- vector(length=n1*n2, mode="list")
>                 dim(res)<- c(n1, n2)
>                 for (i in 1:n1) for (j in 1:n2) {
>                   x1<- arr[i, j, 1:3];x2<- arr[i, j, 4:6]
>                   x3<- arr[i, j, 7:9]
>                   res[[i, j]]<- x1%o%x1 + x2%o%x2 + x3%o%x3
>                 }
>                 res
>               }
>
> sim1<- simmatrices(sim0)
>
> set.seed(234)
> x<- sample(seq(0, 100, by=1), 101, replace=TRUE)
> y<- sample(seq(0, 100, by=1), 101, replace=TRUE)
> coo<- cbind(x=x, y=y)
> coo<- unique(coo)
>
> sim1.obs<- sim1[coo]
>
> dim(coo)
> length(sim1.obs)

One of the values in coo is zero.

   -Peter Ehlers

>
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i686-pc-linux-gnu
>
> locale:
>   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>   [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>   [7] LC_PAPER=en_US.utf8       LC_NAME=C
>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lattice_0.18-8      gstat_0.9-69        sp_0.9-66
> [4] RandomFields_1.3.41
>
> loaded via a namespace (and not attached):
> [1] fortunes_1.3-7 grid_2.11.1    tools_2.11.1
>>
>
> Kjetil
>


From phgrosjean at sciviews.org  Thu Sep  2 11:01:00 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 02 Sep 2010 11:01:00 +0200
Subject: [Rd] Installing a Tcl/Tk Extension on OSX
In-Reply-To: <4C7E7C43.7010602@waddell.ch>
References: <4C7E7C43.7010602@waddell.ch>
Message-ID: <4C7F67CC.6090505@sciviews.org>

This is relatively simple if you can find the packages you need in the 
default Tcl/Tk install on the Mac (/System/Library/Tcl) and if these 
packages are compatibles with the X11 Tcl/Tk used by R. This should be 
fine for packages containing no compiled code. For the others, you 
should check first (but for instance, Img and tsl work for me - Mac OS X 
10.6.4). You can then use these package in R own Tcl environment like this:

 > library(tcltk)
Loading Tcl/Tk interface ... done
 > addTclPath("/System/Library/Tcl")
 > tclRequire("Img")
<Tcl> 1.4

Best,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 01/09/10 18:16, Adrian Waddell wrote:
> Dear R-Community,
>
> I need the Img tk extension for my R package. It all works on my Ubuntu
> machine (libtk-img). However I experience a great deal of trouble when I
> try to install the package on OSX 10.5 or 10.6 (in fact I'm not able to
> do it).
>
> As I understand it, the ActiveTcl with it's teacup package manager do
> not have an effect on the the x11 tcl installation which R accesses.
> MacPorts however has the libtk-img package not listed and compiling it
> from the source (with configure, make all, make install) does not do the
> job either for me (adding the compiled package folder to auto_path).
>
> Now, as I would like some R users to once use my R package (once it's on
> CRAN), installing the Img tk extension should to be a fairly easy task
> on OSX .
>
> Can anybody tell me how I best tackle this problem in a way, such that
> OSX R users (and myself) in future can easily install the Img tk package?
>
> Sincerely,
>
> Adrian Waddell
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From stvjc at channing.harvard.edu  Thu Sep  2 12:27:04 2010
From: stvjc at channing.harvard.edu (Vincent Carey)
Date: Thu, 2 Sep 2010 06:27:04 -0400
Subject: [Rd] CMD check: checking data for non-ASCII characters is very time
	consuming
Message-ID: <AANLkTi=Mk=Z0ikVbTLX5LO+V5bJFuXSmC2y28YGS=66S@mail.gmail.com>

Checking data for non-ASCII characters takes a very long time for
packages with substantial data components.
Could the check be done manually by the developer, and a switch
introduced to optionally skip this during check?


From ehlers at ucalgary.ca  Thu Sep  2 16:45:06 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Thu, 02 Sep 2010 08:45:06 -0600
Subject: [Rd] Assignment of individual values to data frame
 columns:	intentional or unintentional behavior?
In-Reply-To: <4C5AFFA3.7050800@bht-berlin.de>
References: <4C5AE5A9.9060905@bht-berlin.de>	<AANLkTimEyxOM-tevXE1FVDfYScqT-z3dNX9TEc8xez7P@mail.gmail.com>
	<4C5AFFA3.7050800@bht-berlin.de>
Message-ID: <4C7FB872.4050805@ucalgary.ca>

On 2010-08-05 12:14, Ulrike Gr?mping wrote:
> Gabor Grothendieck schrieb:
>> On Thu, Aug 5, 2010 at 12:24 PM, Ulrike Gr?mping
>> <groemping at bht-berlin.de>  wrote:
>>
>>> Dear developeRs,
>>>
>>> I have just discovered a strange feature when assigning some values to
>>> columns of a data frame: The column is matched by partial matching (as
>>> documented), but when assigning a value, a new column with the partial name
>>> is added to the data frame that is identical to the original column except
>>> for the changed value. Is that intentional ? An example:
>>>
>>
>> Note that the lack of partial matching when performing assignment is
>> also documented.
>>
>> See second last paragraph in Details section of ?Extract
>>
> Yes, I see, thanks. I looked at ?"[.data.frame", where this is not
> documented.
>
> However, given the documentation that partial matching is not used on
> the left-hand side, I would have expected even more that the assignment
>
> sw$Fert[1]<- 10
>
> works differently, because I am using it on the left-hand side.
> Probably, extraction ([1]) is done first here, so that the right-hand
> side won. At least, this is very confusing.
>
> Best, Ulrike

This is another example of why it's a good idea to avoid
the '$' notation when fiddling with data frames. Try this:

  sw <- swiss[1:5, 1:4]
  sw[["Fert"]]
  sw[["Fert"]] <- 10

and my preferred version:
  sw[, "Fert"]
  sw[, "Fert"] <- 10

I've never liked partial matching for data frames.

   -Peter Ehlers


From D.Strbenac at garvan.org.au  Fri Sep  3 04:00:14 2010
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Fri,  3 Sep 2010 12:00:14 +1000 (EST)
Subject: [Rd] S4 Method Signatures
Message-ID: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>

Hello,

If the signature of a method defines which generic it implements then I'm confused about why this minimal example I invented won't work :

setGeneric("myFun", function(rs, ...){standardGeneric("myFun")})
setGeneric("myFun", function(cs, ...){standardGeneric("myFun")})

setMethod("myFun", "numeric", function(rs, colour = "Blue")
{
	cat(rs*100, colour)
})

setMethod("myFun", "character", function(cs, colour = "Red")
{
	cat(cs, colour)
})

Thanks for any tips,
                    Dario.

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From ml_a at waddell.ch  Fri Sep  3 04:24:03 2010
From: ml_a at waddell.ch (Adrian Waddell)
Date: Thu, 02 Sep 2010 22:24:03 -0400
Subject: [Rd] Installing a Tcl/Tk Extension on OSX
In-Reply-To: <4C7F67CC.6090505@sciviews.org>
References: <4C7E7C43.7010602@waddell.ch> <4C7F67CC.6090505@sciviews.org>
Message-ID: <4C805C43.7070604@waddell.ch>

Thanks, that works actually out of the box from a fresh OSX 10.6
installation. So no ActiveTcl is needed. This is great!

Greetings,

Adrian


On 09/02/2010 05:01 AM, Philippe Grosjean wrote:
> This is relatively simple if you can find the packages you need in the
> default Tcl/Tk install on the Mac (/System/Library/Tcl) and if these
> packages are compatibles with the X11 Tcl/Tk used by R. This should be
> fine for packages containing no compiled code. For the others, you
> should check first (but for instance, Img and tsl work for me - Mac OS
> X 10.6.4). You can then use these package in R own Tcl environment
> like this:
>
> > library(tcltk)
> Loading Tcl/Tk interface ... done
> > addTclPath("/System/Library/Tcl")
> > tclRequire("Img")
> <Tcl> 1.4
>
> Best,
>
> Philippe
>
> ..............................................<?}))><........
>  ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>  ) ) ) ) )   Mons University, Belgium
> ( ( ( ( (
> ..............................................................
>
> On 01/09/10 18:16, Adrian Waddell wrote:
>> Dear R-Community,
>>
>> I need the Img tk extension for my R package. It all works on my Ubuntu
>> machine (libtk-img). However I experience a great deal of trouble when I
>> try to install the package on OSX 10.5 or 10.6 (in fact I'm not able to
>> do it).
>>
>> As I understand it, the ActiveTcl with it's teacup package manager do
>> not have an effect on the the x11 tcl installation which R accesses.
>> MacPorts however has the libtk-img package not listed and compiling it
>> from the source (with configure, make all, make install) does not do the
>> job either for me (adding the compiled package folder to auto_path).
>>
>> Now, as I would like some R users to once use my R package (once it's on
>> CRAN), installing the Img tk extension should to be a fairly easy task
>> on OSX .
>>
>> Can anybody tell me how I best tackle this problem in a way, such that
>> OSX R users (and myself) in future can easily install the Img tk
>> package?
>>
>> Sincerely,
>>
>> Adrian Waddell
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From D.Strbenac at garvan.org.au  Fri Sep  3 09:30:39 2010
From: D.Strbenac at garvan.org.au (DarioAustralia)
Date: Fri, 3 Sep 2010 00:30:39 -0700 (PDT)
Subject: [Rd] S4 Method Signatures
In-Reply-To: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>
References: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>
Message-ID: <1283499039610-2525216.post@n4.nabble.com>


Ah, nevermind. I realised you could have function(...) as the function
signature in the setGeneric call. 
-- 
View this message in context: http://r.789695.n4.nabble.com/S4-Method-Signatures-tp2525018p2525216.html
Sent from the R devel mailing list archive at Nabble.com.


From maechler at stat.math.ethz.ch  Fri Sep  3 09:34:28 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Sep 2010 09:34:28 +0200
Subject: [Rd] S4 Method Signatures
In-Reply-To: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>
References: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>
Message-ID: <19584.42244.459156.294014@lynne.math.ethz.ch>

>>>>> "DS" == Dario Strbenac <D.Strbenac at garvan.org.au>
>>>>>     on Fri,  3 Sep 2010 12:00:14 +1000 (EST) writes:

    DS> Hello,
    DS> If the signature of a method defines which generic it implements then I'm confused about why this minimal example I invented won't work :

very short answer:

     if(FALSE) {  0 == 1 }

slightly longer:

     if( something_wrong )  {  anything_can_be_put_here }

In other words:

Your assumption is wrong.
There's only one generic and potentially many methods, defined
via signatures, but you have not understood what a signature is.

    DS> setGeneric("myFun", function(rs, ...){standardGeneric("myFun")})
    DS> setGeneric("myFun", function(cs, ...){standardGeneric("myFun")})

    DS> setMethod("myFun", "numeric", function(rs, colour = "Blue")
    DS> {
    DS> cat(rs*100, colour)
    DS> })

    DS> setMethod("myFun", "character", function(cs, colour = "Red")
    DS> {
    DS> cat(cs, colour)
    DS> })

Rather:

setGeneric("myFun", function(x, ...) standardGeneric("myFun"))

setMethod("myFun", "numeric", 
          function(x, colour = "Blue") cat(xs*100, colour))

## etc

where the last is an abbreviated form of 

setMethod("myFun", signature(x = "numeric"), 
          function(x, colour = "Blue") cat(xs*100, colour))

which is abbreviated for

setMethod("myFun", signature = signature(x = "numeric"), 
          function(x, colour = "Blue") cat(xs*100, colour))



I do wonder why the examples on the  ?setMethod   
help page where not sufficient here..

    DS> Thanks for any tips,

you're welcome.
Martin Maechler, ETH Zurich


    DS> --------------------------------------
    DS> Dario Strbenac
    DS> Research Assistant
    DS> Cancer Epigenetics
    DS> Garvan Institute of Medical Research
    DS> Darlinghurst NSW 2010
    DS> Australia

    DS> ______________________________________________
    DS> R-devel at r-project.org mailing list
    DS> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> "DS" == Dario Strbenac <D.Strbenac at garvan.org.au>
>>>>>     on Fri,  3 Sep 2010 12:00:14 +1000 (EST) writes:

    DS> Hello, If the signature of a method defines which
    DS> generic it implements then I'm confused about why this
    DS> minimal example I invented won't work :

    DS> setGeneric("myFun", function(rs,
    DS> ...){standardGeneric("myFun")}) setGeneric("myFun",
    DS> function(cs, ...){standardGeneric("myFun")})

    DS> setMethod("myFun", "numeric", function(rs, colour =
    DS> "Blue") { cat(rs*100, colour) })

    DS> setMethod("myFun", "character", function(cs, colour =
    DS> "Red") { cat(cs, colour) })

    DS> Thanks for any tips, Dario.

    DS> -------------------------------------- Dario Strbenac
    DS> Research Assistant Cancer Epigenetics Garvan Institute
    DS> of Medical Research Darlinghurst NSW 2010 Australia

    DS> ______________________________________________
    DS> R-devel at r-project.org mailing list
    DS> https://stat.ethz.ch/mailman/listinfo/r-devel


From phgrosjean at sciviews.org  Fri Sep  3 10:29:46 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 03 Sep 2010 10:29:46 +0200
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
Message-ID: <4C80B1FA.9060403@sciviews.org>

Hello,

It's several days I try to track this bug, and even cannot cook a 
reproducible example. Yet, it occurs consistently in a long-running task 
after a variable period of time. Here is an example:

... my long-running code [as I said, cannot give something simple
that produces this bug in a reproducible manner]

Error in match(x, table, nomatch = 0L) :
     formal argument "nomatch" matched by multiple actual arguments
 > traceback()
6: match(x, table, nomatch = 0L)
5: "factor" %in% attrib[["class", exact = TRUE]]
4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
3: Sys.time()
2: chemTrigger() at chemostat_1.0-1.R#1132
1: chemRun()

So, the culprid is a call inside `%in%` (from within structure() in 
Sys.time()). But I can run millions times `%in%`, or structure(), or 
Sys.time() on my machine without producing this bug. Arguments at 5: are 
simple character strings. They don't hurt!

Also, I am lost because the message is totally illogical in the context 
where it appears: I can understand this message here:

 > match(1, 2, nomatch = 0L, nomatch = NA)
Error in match(1, 2, nomatch = 0L, nomatch = NA) :
   formal argument "nomatch" matched by multiple actual arguments

or here:

 > test <- function (...) match(1, ..., nomatch = 0L)
 > test(2, nomatch = NA)
Error in match(1, ..., nomatch = 0L) :
   formal argument "nomatch" matched by multiple actual arguments

but in the call "match(x, table, nomatch = 0L)" where x is the character 
string "factor" and table is another character string ("numeric") 
extracted from a list, I don't understand why it produces this error 
message. '.Internal(Sys.time())' uses do_systime c code that returns a 
one-element double... not something that can hurt here?!

Can someone explain me, or give me an example where an argument is NOT 
duplicated in the call (well, as I understand it here) and where one 
gets such an error message? And why?

Many thanks, I am desperate :-(

I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on 
Windows XP SP3 (but it does not matter, since I cannot cook a 
reproducible example).

Philippe

P.S.: seems related to this: 
http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................


From janko.thyson at ku-eichstaett.de  Fri Sep  3 11:44:14 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Fri, 3 Sep 2010 11:44:14 +0200
Subject: [Rd] Stats not loaded? Method for as.ts() results in error
Message-ID: <000301cb4b4c$91965fa0$b4c31ee0$@thyson@ku-eichstaett.de>

Dear list,

 

I've got the following problem:

 

In a package I'm trying to build, there exists a method for the function
"as.ts()". When checking the package, R always throws the error that it
cannot find a function called "as.ts". To me it seems that the package
"stats" (home of "as.ts()") is not loaded during the checking process even
though it's a base package. For testing, I've written a method for "plot()"
to see if it's a general problem with base-functions, but this one passes
just fine.

 

Did anyone of encounter a similar problem or could help me out with a hint?

 

Thank you very much,

Janko

 


From murdoch.duncan at gmail.com  Fri Sep  3 13:42:01 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 Sep 2010 07:42:01 -0400
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <4C80B1FA.9060403@sciviews.org>
References: <4C80B1FA.9060403@sciviews.org>
Message-ID: <4C80DF09.9030805@gmail.com>

Philippe Grosjean wrote:
> Hello,
>
> It's several days I try to track this bug, and even cannot cook a 
> reproducible example. Yet, it occurs consistently in a long-running task 
> after a variable period of time. Here is an example:
>   

I would look closely at the other software that is running in your long 
example.  Does it include C (or other external) code?  Look closely at 
that, it might be writing outside it's own allocated memory.  Also check 
for correct protection of intermediate results, if you're producing 
SEXPs in the external code.  (Running under gctorture might flush out 
the bug more quickly if the latter is the problem.)

If you're only running R code, then this looks like a bug in R, but it 
might still be worth trying gctorture to make it reproducible.  We won't 
be able to fix it if we can't reproduce it.

Duncan Murdoch
> ... my long-running code [as I said, cannot give something simple
> that produces this bug in a reproducible manner]
>
> Error in match(x, table, nomatch = 0L) :
>      formal argument "nomatch" matched by multiple actual arguments
>  > traceback()
> 6: match(x, table, nomatch = 0L)
> 5: "factor" %in% attrib[["class", exact = TRUE]]
> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
> 3: Sys.time()
> 2: chemTrigger() at chemostat_1.0-1.R#1132
> 1: chemRun()
>
> So, the culprid is a call inside `%in%` (from within structure() in 
> Sys.time()). But I can run millions times `%in%`, or structure(), or 
> Sys.time() on my machine without producing this bug. Arguments at 5: are 
> simple character strings. They don't hurt!
>
> Also, I am lost because the message is totally illogical in the context 
> where it appears: I can understand this message here:
>
>  > match(1, 2, nomatch = 0L, nomatch = NA)
> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>    formal argument "nomatch" matched by multiple actual arguments
>
> or here:
>
>  > test <- function (...) match(1, ..., nomatch = 0L)
>  > test(2, nomatch = NA)
> Error in match(1, ..., nomatch = 0L) :
>    formal argument "nomatch" matched by multiple actual arguments
>
> but in the call "match(x, table, nomatch = 0L)" where x is the character 
> string "factor" and table is another character string ("numeric") 
> extracted from a list, I don't understand why it produces this error 
> message. '.Internal(Sys.time())' uses do_systime c code that returns a 
> one-element double... not something that can hurt here?!
>
> Can someone explain me, or give me an example where an argument is NOT 
> duplicated in the call (well, as I understand it here) and where one 
> gets such an error message? And why?
>
> Many thanks, I am desperate :-(
>
> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on 
> Windows XP SP3 (but it does not matter, since I cannot cook a 
> reproducible example).
>
> Philippe
>
> P.S.: seems related to this: 
> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>


From murdoch.duncan at gmail.com  Fri Sep  3 13:45:56 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 Sep 2010 07:45:56 -0400
Subject: [Rd] Stats not loaded? Method for as.ts() results in error
In-Reply-To: <000301cb4b4c$91965fa0$b4c31ee0$@thyson@ku-eichstaett.de>
References: <000301cb4b4c$91965fa0$b4c31ee0$@thyson@ku-eichstaett.de>
Message-ID: <4C80DFF4.4000206@gmail.com>

Janko Thyson wrote:
> Dear list,
>
>  
>
> I've got the following problem:
>
>  
>
> In a package I'm trying to build, there exists a method for the function
> "as.ts()". When checking the package, R always throws the error that it
> cannot find a function called "as.ts". To me it seems that the package
> "stats" (home of "as.ts()") is not loaded during the checking process even
> though it's a base package. For testing, I've written a method for "plot()"
> to see if it's a general problem with base-functions, but this one passes
> just fine.
>   

Are you using a NAMESPACE, and declaring your method as a method?  If 
you don't, R will have to guess what the methods are, and it might be 
getting mixed up because of the unusual name of the generic.

Duncan Murdoch


>  
>
> Did anyone of encounter a similar problem or could help me out with a hint?
>
>  
>
> Thank you very much,
>
> Janko
>
>  
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From phgrosjean at sciviews.org  Fri Sep  3 14:29:54 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 03 Sep 2010 14:29:54 +0200
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <4C80DF09.9030805@gmail.com>
References: <4C80B1FA.9060403@sciviews.org> <4C80DF09.9030805@gmail.com>
Message-ID: <4C80EA42.6060903@sciviews.org>

Thank you, Duncan for your answer.
Indeed, I have also tcltk loaded and running, and the memory allocation 
problem may come from there. I'll investigate using gctorture(). For 
sure, I know that I need a reproducible example for further investigations.
Best,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 03/09/10 13:42, Duncan Murdoch wrote:
> Philippe Grosjean wrote:
>> Hello,
>>
>> It's several days I try to track this bug, and even cannot cook a
>> reproducible example. Yet, it occurs consistently in a long-running
>> task after a variable period of time. Here is an example:
>
> I would look closely at the other software that is running in your long
> example. Does it include C (or other external) code? Look closely at
> that, it might be writing outside it's own allocated memory. Also check
> for correct protection of intermediate results, if you're producing
> SEXPs in the external code. (Running under gctorture might flush out the
> bug more quickly if the latter is the problem.)
>
> If you're only running R code, then this looks like a bug in R, but it
> might still be worth trying gctorture to make it reproducible. We won't
> be able to fix it if we can't reproduce it.
>
> Duncan Murdoch
>> ... my long-running code [as I said, cannot give something simple
>> that produces this bug in a reproducible manner]
>>
>> Error in match(x, table, nomatch = 0L) :
>> formal argument "nomatch" matched by multiple actual arguments
>> > traceback()
>> 6: match(x, table, nomatch = 0L)
>> 5: "factor" %in% attrib[["class", exact = TRUE]]
>> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
>> 3: Sys.time()
>> 2: chemTrigger() at chemostat_1.0-1.R#1132
>> 1: chemRun()
>>
>> So, the culprid is a call inside `%in%` (from within structure() in
>> Sys.time()). But I can run millions times `%in%`, or structure(), or
>> Sys.time() on my machine without producing this bug. Arguments at 5:
>> are simple character strings. They don't hurt!
>>
>> Also, I am lost because the message is totally illogical in the
>> context where it appears: I can understand this message here:
>>
>> > match(1, 2, nomatch = 0L, nomatch = NA)
>> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>> formal argument "nomatch" matched by multiple actual arguments
>>
>> or here:
>>
>> > test <- function (...) match(1, ..., nomatch = 0L)
>> > test(2, nomatch = NA)
>> Error in match(1, ..., nomatch = 0L) :
>> formal argument "nomatch" matched by multiple actual arguments
>>
>> but in the call "match(x, table, nomatch = 0L)" where x is the
>> character string "factor" and table is another character string
>> ("numeric") extracted from a list, I don't understand why it produces
>> this error message. '.Internal(Sys.time())' uses do_systime c code
>> that returns a one-element double... not something that can hurt here?!
>>
>> Can someone explain me, or give me an example where an argument is NOT
>> duplicated in the call (well, as I understand it here) and where one
>> gets such an error message? And why?
>>
>> Many thanks, I am desperate :-(
>>
>> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on
>> Windows XP SP3 (but it does not matter, since I cannot cook a
>> reproducible example).
>>
>> Philippe
>>
>> P.S.: seems related to this:
>> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From daniel.sabanesbove at ifspm.uzh.ch  Fri Sep  3 14:40:52 2010
From: daniel.sabanesbove at ifspm.uzh.ch (=?ISO-8859-15?Q?Daniel_Saban=E9s_Bov=E9?=)
Date: Fri, 03 Sep 2010 14:40:52 +0200
Subject: [Rd] constness in BLAS.h/dger arguments
Message-ID: <4C80ECD4.8020807@ifspm.uzh.ch>

Hi,

I am writing code interfacing R's BLAS functions, and have a problem
with two missing const's in the header of F77_NAME(dger) in
src/include/R_ext/BLAS.h. The current definition is missing the
appropriate consts for the arrays x and y, which are stated in the BLAS
documentation [2] to be "unchanged on exit". This issue was already
mentioned on the list in March 2009 [1], however without any (public)
answer from R-core.

I have tested the attached patch for this issue in the latest R-patched
version and the current release version, and did not encounter any
problem during compilation. Since conversion from double* to const
double* in a function call is not a problem, I do not think that any
external packages could get problems when BLAS.h would be changed in
this way.

It would be great if this change could make it into the next release
version of R.

Thanks in advance,
Daniel


[1] https://stat.ethz.ch/pipermail/r-devel/2009-March/052535.html
[2] http://www.netlib.org/lapack/explore-html/a00044_source.html



-------------- next part --------------
A non-text attachment was scrubbed...
Name: BLAS.h.patch
Type: text/x-patch
Size: 590 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/80b63add/attachment.bin>

From mtmorgan at fhcrc.org  Fri Sep  3 14:53:34 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 03 Sep 2010 05:53:34 -0700
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <4C80DF09.9030805@gmail.com>
References: <4C80B1FA.9060403@sciviews.org> <4C80DF09.9030805@gmail.com>
Message-ID: <4C80EFCE.3070400@fhcrc.org>

On 09/03/2010 04:42 AM, Duncan Murdoch wrote:
> Philippe Grosjean wrote:
>> Hello,
>>
>> It's several days I try to track this bug, and even cannot cook a
>> reproducible example. Yet, it occurs consistently in a long-running
>> task after a variable period of time. Here is an example:
>>   
>
> I would look closely at the other software that is running in your
> long example.  Does it include C (or other external) code?  Look
> closely at that, it might be writing outside it's own allocated
> memory.  Also check for correct protection of intermediate results, if
> you're producing SEXPs in the external code.  (Running under gctorture
> might flush out the bug more quickly if the latter is the problem.)
>
> If you're only running R code, then this looks like a bug in R, but it
> might still be worth trying gctorture to make it reproducible.  We
> won't be able to fix it if we can't reproduce it.
>
> Duncan Murdoch
>> ... my long-running code [as I said, cannot give something simple
>> that produces this bug in a reproducible manner]
>>
>> Error in match(x, table, nomatch = 0L) :
>>      formal argument "nomatch" matched by multiple actual arguments
>>  > traceback()
>> 6: match(x, table, nomatch = 0L)
>> 5: "factor" %in% attrib[["class", exact = TRUE]]
>> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
>> 3: Sys.time()
>> 2: chemTrigger() at chemostat_1.0-1.R#1132
>> 1: chemRun()

I think this is a bug in R that has been fixed in the subversion commit
below, and so should be fixed in R-2.11.1.
What is your sessionInfo(), and does your error occur in the devel
version of R?

Martin

r51232 | falcon | 2010-03-09 13:59:48 -0800 (Tue, 09 Mar 2010) | 14 lines
Changed paths:
   M /trunk/src/main/match.c

Fix bug in matchArgs triggered by gc and finalizers

matchArgs was modifying the general purpose bits of SEXPs making up the
'formals' argument to keep track of ARGUSED.  When gc is triggered
inside matchArgs, finalizer code can end up calling matchArgs on the
same function (hence same formals) resulting in corruption of gp bits.

This patch uses an int array allocated on the stack to keep track of
ARGUSED and avoids modifying the SEXPs in formals.  In place modification
of SEXPs in supplied still occurs via ARGUSED/SET_ARGUSED, but should be
safe as long as no new allocating function calls are added to matchArgs.

A reproducible report of this bug was reported here:
https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000997.html


>>
>> So, the culprid is a call inside `%in%` (from within structure() in
>> Sys.time()). But I can run millions times `%in%`, or structure(), or
>> Sys.time() on my machine without producing this bug. Arguments at 5:
>> are simple character strings. They don't hurt!
>>
>> Also, I am lost because the message is totally illogical in the
>> context where it appears: I can understand this message here:
>>
>>  > match(1, 2, nomatch = 0L, nomatch = NA)
>> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>>    formal argument "nomatch" matched by multiple actual arguments
>>
>> or here:
>>
>>  > test <- function (...) match(1, ..., nomatch = 0L)
>>  > test(2, nomatch = NA)
>> Error in match(1, ..., nomatch = 0L) :
>>    formal argument "nomatch" matched by multiple actual arguments
>>
>> but in the call "match(x, table, nomatch = 0L)" where x is the
>> character string "factor" and table is another character string
>> ("numeric") extracted from a list, I don't understand why it produces
>> this error message. '.Internal(Sys.time())' uses do_systime c code
>> that returns a one-element double... not something that can hurt here?!
>>
>> Can someone explain me, or give me an example where an argument is
>> NOT duplicated in the call (well, as I understand it here) and where
>> one gets such an error message? And why?
>>
>> Many thanks, I am desperate :-(
>>
>> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on
>> Windows XP SP3 (but it does not matter, since I cannot cook a
>> reproducible example).
>>
>> Philippe
>>
>> P.S.: seems related to this:
>> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Fri Sep  3 15:10:03 2010
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 3 Sep 2010 06:10:03 -0700
Subject: [Rd] Feature request: put NewEnvironment and R_NewhashedEnv
	into API
In-Reply-To: <D0B20444-A804-4DB3-B95E-56945FEE804A@fh-koeln.de>
References: <D0B20444-A804-4DB3-B95E-56945FEE804A@fh-koeln.de>
Message-ID: <AANLkTinUgBphrhi_vNYrb-Upvf=KpHo_FruqJnb6w+Fz@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/60b73a8d/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Sep  3 15:56:52 2010
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 3 Sep 2010 08:56:52 -0500
Subject: [Rd] Stats not loaded? Method for as.ts() results in error
In-Reply-To: <9002531500294005716@unknownmsgid>
References: <9002531500294005716@unknownmsgid>
Message-ID: <AANLkTimb6RLr-=VYjUunc8e1M8oKh0n7B6TJHka+=Lxb@mail.gmail.com>

Janko,

You don't mention if you are using S3 or S4.  A small example would
make it easier to identify where your problem is.

Jeff

On Fri, Sep 3, 2010 at 4:44 AM, Janko Thyson
<janko.thyson at ku-eichstaett.de> wrote:
> Dear list,
>
>
>
> I've got the following problem:
>
>
>
> In a package I'm trying to build, there exists a method for the function
> "as.ts()". When checking the package, R always throws the error that it
> cannot find a function called "as.ts". To me it seems that the package
> "stats" (home of "as.ts()") is not loaded during the checking process even
> though it's a base package. For testing, I've written a method for "plot()"
> to see if it's a general problem with base-functions, but this one passes
> just fine.
>
>
>
> Did anyone of encounter a similar problem or could help me out with a hint?
>
>
>
> Thank you very much,
>
> Janko
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
Jeffrey Ryan
jeff.a.ryan at gmail.com


From phgrosjean at sciviews.org  Fri Sep  3 16:01:32 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 03 Sep 2010 16:01:32 +0200
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <4C80EFCE.3070400@fhcrc.org>
References: <4C80B1FA.9060403@sciviews.org> <4C80DF09.9030805@gmail.com>
	<4C80EFCE.3070400@fhcrc.org>
Message-ID: <4C80FFBC.90200@sciviews.org>

Martin,

This looks like a possible explanation. After double-check, it occurs 
with R 2.10.1 and 2.11.0 (not 2.11.1, as I reported in my original 
email). I'll upgrade R and test again. I'll report the results on 
Monday, since my code has to run over the week-end.
Thanks,

PhG

On 03/09/10 14:53, Martin Morgan wrote:
> On 09/03/2010 04:42 AM, Duncan Murdoch wrote:
>> Philippe Grosjean wrote:
>>> Hello,
>>>
>>> It's several days I try to track this bug, and even cannot cook a
>>> reproducible example. Yet, it occurs consistently in a long-running
>>> task after a variable period of time. Here is an example:
>>>
>>
>> I would look closely at the other software that is running in your
>> long example.  Does it include C (or other external) code?  Look
>> closely at that, it might be writing outside it's own allocated
>> memory.  Also check for correct protection of intermediate results, if
>> you're producing SEXPs in the external code.  (Running under gctorture
>> might flush out the bug more quickly if the latter is the problem.)
>>
>> If you're only running R code, then this looks like a bug in R, but it
>> might still be worth trying gctorture to make it reproducible.  We
>> won't be able to fix it if we can't reproduce it.
>>
>> Duncan Murdoch
>>> ... my long-running code [as I said, cannot give something simple
>>> that produces this bug in a reproducible manner]
>>>
>>> Error in match(x, table, nomatch = 0L) :
>>>       formal argument "nomatch" matched by multiple actual arguments
>>>   >  traceback()
>>> 6: match(x, table, nomatch = 0L)
>>> 5: "factor" %in% attrib[["class", exact = TRUE]]
>>> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
>>> 3: Sys.time()
>>> 2: chemTrigger() at chemostat_1.0-1.R#1132
>>> 1: chemRun()
>
> I think this is a bug in R that has been fixed in the subversion commit
> below, and so should be fixed in R-2.11.1.
> What is your sessionInfo(), and does your error occur in the devel
> version of R?
>
> Martin
>
> r51232 | falcon | 2010-03-09 13:59:48 -0800 (Tue, 09 Mar 2010) | 14 lines
> Changed paths:
>     M /trunk/src/main/match.c
>
> Fix bug in matchArgs triggered by gc and finalizers
>
> matchArgs was modifying the general purpose bits of SEXPs making up the
> 'formals' argument to keep track of ARGUSED.  When gc is triggered
> inside matchArgs, finalizer code can end up calling matchArgs on the
> same function (hence same formals) resulting in corruption of gp bits.
>
> This patch uses an int array allocated on the stack to keep track of
> ARGUSED and avoids modifying the SEXPs in formals.  In place modification
> of SEXPs in supplied still occurs via ARGUSED/SET_ARGUSED, but should be
> safe as long as no new allocating function calls are added to matchArgs.
>
> A reproducible report of this bug was reported here:
> https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000997.html
>
>
>>>
>>> So, the culprid is a call inside `%in%` (from within structure() in
>>> Sys.time()). But I can run millions times `%in%`, or structure(), or
>>> Sys.time() on my machine without producing this bug. Arguments at 5:
>>> are simple character strings. They don't hurt!
>>>
>>> Also, I am lost because the message is totally illogical in the
>>> context where it appears: I can understand this message here:
>>>
>>>   >  match(1, 2, nomatch = 0L, nomatch = NA)
>>> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>>>     formal argument "nomatch" matched by multiple actual arguments
>>>
>>> or here:
>>>
>>>   >  test<- function (...) match(1, ..., nomatch = 0L)
>>>   >  test(2, nomatch = NA)
>>> Error in match(1, ..., nomatch = 0L) :
>>>     formal argument "nomatch" matched by multiple actual arguments
>>>
>>> but in the call "match(x, table, nomatch = 0L)" where x is the
>>> character string "factor" and table is another character string
>>> ("numeric") extracted from a list, I don't understand why it produces
>>> this error message. '.Internal(Sys.time())' uses do_systime c code
>>> that returns a one-element double... not something that can hurt here?!
>>>
>>> Can someone explain me, or give me an example where an argument is
>>> NOT duplicated in the call (well, as I understand it here) and where
>>> one gets such an error message? And why?
>>>
>>> Many thanks, I am desperate :-(
>>>
>>> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on
>>> Windows XP SP3 (but it does not matter, since I cannot cook a
>>> reproducible example).
>>>
>>> Philippe
>>>
>>> P.S.: seems related to this:
>>> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From radford at cs.toronto.edu  Fri Sep  3 21:49:34 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Fri, 3 Sep 2010 15:49:34 -0400
Subject: [Rd] Pointer to fourteen patches to speed up R
Message-ID: <20100903194934.GA21681@cs.toronto.edu>

I've continued to work on speeding up R, and now have a collection of
fourteen patches, some of which speed up particular functions, and
some of which reduce general interpretive overhead.  The total speed
improvement from these patches is substantial.  It varies a lot from
one R program to the next, of course, and probably from one machine to
the next, but speedups of 25% can be expected in many programs, and
sometimes much more (though sometimes less as well).

The fourteen patches work for revision r52822 of the development
version of R (I haven't check against any changes in the last few
days), and also for release 2.11.1.  I also wrote a number of timing
test programs.

I tried posting this message with the patches and test programs
attached, but it got held for moderation because it's over 128K.  I'll
leave it uncancelled, since maybe it's good to archive them here, but
in the interim, you can get both the patches and the test programs from 
http://www.cs.toronto.edu/~radford/R-mods.html

I've included below the documentation on what each patch does, which
is also in "doc" in speed-patches.tar.  Note that I fixed a few minor
bugs along the way.

There looks to be scope for more improvements in various parts of the
R interpreter that I didn't get to.  I'll have to put this on hold for
now, however, to spend my time preparing for the coming teaching term.
I'd be happy to hear of any comments on these patches, though,
including information on how much they speed up typical programs, on
various machines.

   Radford Neal

-----------------------------------------------------------------------

These patches to the R source for improving speed were written by
Radford M. Neal, Sept. 2010.

See the README file for how to install them. 

Below, I describe these patches (in alphabetical order), indicate what
improvement they produce, and also mention any potential issues with
using the patch, and bugs that the patches incidently fix.

The timing improvements discussed below are what is obtained by
applying each patch individually, on an Intel system running Ubuntu
Linux with Gcc version 4.2.4.  The total improvement from all patches
is much bigger, though in a few instances a patch can diminish the
effect of another patch, by reducing the magnitude of the
inefficiencies that the other patch eliminates.  Note though, that the
percentage improvement for a given absolute improvement gets bigger as
when other patches reduce overall time.

For r52822, the total time for all tests in the accompanying speed
test suite is 674 seconds.  This is reduced to 487 seconds with all
patches applied, a reduction of 28%.  Particular R programs will, of
course, see widely varying reductions depending on what operations
they mostly do.

patch-dollar

    Speeds up access to lists, pairlists, and environments using the
    $ operator.  The speedup comes mainly from avoiding the overhead of 
    calling DispatchOrEval if there are no complexities, from passing
    on the field to extract as a symbol, or a name, or both, as available,
    and then converting only as necessary, from simplifying and inlining
    the pstrmatch procedure, and from not translating string multiple
    times.  

    Relevant timing test script:  test-dollar.r 

    This test shows about a 40% decrease in the time needed to extract
    elements of lists and environments.

    Changes unrelated to speed improvement:

    A small error-reporting bug is fixed, illustrated by the following
    output with r52822:

    > options(warnPartialMatchDollar=TRUE)
    > pl <- pairlist(abc=1,def=2)
    > pl$ab
    [1] 1
    Warning message:
    In pl$ab : partial match of 'ab' to ''

    Some code is changed at the end of R_subset3_dflt because it seems 
    to be more correct, as discussed in code comments. 
    
patch-evalList

    Speeds up a large number of operations by avoiding allocation of
    an extra CONS cell in the procedures for evaluating argument lists.

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 5%.

patch-fast-base

    Speeds up lookup of symbols defined in the base environment, by
    flagging symbols that have a base environment definition recorded
    in the global cache.  This allows the definition to be retrieved
    quickly without looking in the hash table.  

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 3%.

    Issue:  This patch uses the "spare" bit for the flag.  This bit is
    misnamed, since it is already used elsewhere (for closures).  It is
    possible that one of the "gp" bits should be used instead.  The
    "gp" bits should really be divided up for faster access, and so that
    their present use is apparent in the code.

    In case this use of the "spare" bit proves unwise, the patch code is 
    conditional on FAST_BASE_CACHE_LOOKUP being defined at the start of
    envir.r.

patch-fast-spec

    Speeds up lookup of function symbols that begin with a character
    other than a letter or ".", by allowing fast bypass of non-global
    environments that do not contain (and have never contained) symbols 
    of this sort.  Since it is expected that only functions will be
    given names of this sort, the check is done only in findFun, though
    it could also be done in findVar.

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 8%.    

    Issue:  This patch uses the "spare" bit to flag environments known
    to not have symbols starting with a special character.  See remarks
    on patch-fast-base.

    In case this use of the "spare" bit proves unwise, the patch code is 
    conditional on FAST_SPEC_BYPASS being defined at the start of envir.r.

patch-for

    Speeds up for loops by not allocating new space for the loop
    variable every iteration, unless necessary.  

    Relevant timing test script:  test-for.r

    This test shows a speedup of about 5%.  

    Change unrelated to speed improvement:

    Fixes what I consider to be a bug, in which the loop clobbers a
    global variable, as demonstrated by the following output with r52822:

    > i <- 99
    > f <- function () for (i in 1:3) { print(i); if (i==2) rm(i); }
    > f()
    [1] 1
    [1] 2
    [1] 3
    > print(i)
    [1] 3

patch-matprod

    Speeds up matrix products, including vector dot products.  The
    speed issue here is that the R code checks for any NAs, and 
    does the multiply in the matprod procedure (in array.c) if so,
    since BLAS isn't trusted with NAs.  If this check takes about
    as long as just doing the multiply in matprod, calling a BLAS
    routine makes no sense.  

    Relevant time test script:  test-matprod.r

    With no external BLAS, this patch speeds up long vector-vector 
    products by a factor of about six, matrix-vector products by a
    factor of about three, and some matrix-matrix products by a 
    factor of about two.

    Issue:  The matrix multiply code in matprod using an LDOUBLE
    (long double) variable to accumulate sums, for improved accuracy.  
    On a SPARC system I tested on, operations on long doubles are 
    vastly slower than on doubles, so that the patch produces a 
    large slowdown rather than an improvement.  This is also an issue 
    for the "sum" function, which also uses an LDOUBLE to accumulate
    the sum.  Perhaps an ordinarly double should be used in these
    places, or perhaps the configuration script should define LDOUBLE 
    as double on architectures where long doubles are extraordinarily 
    slow.

    Due to this issue, not defining MATPROD_CAN_BE_DONE_HERE at the
    start of array.c will disable this patch.
    
patch-parens

    Speeds up parentheses by making "(" a special operator whose
    argument is not evaluated, thereby bypassing the overhead of
    evalList.  Also slightly speeds up curly brackets by inlining
    a function that is stylistically better inline anyway.

    Relevant test script:  test-parens.r

    In the parens part of test-parens.r, the speedup is about 9%.

patch-protect

    Speeds up numerous operations by making PROTECT, UNPROTECT, etc.
    be mostly macros in the files in src/main.  This takes effect
    only for files that include Defn.h after defining the symbol
    USE_FAST_PROTECT_MACROS.  With these macros, code of the form
    v = PROTECT(...) must be replaced by PROTECT(v = ...).  

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 9%.

patch-save-alloc

    Speeds up some binary and unary arithmetic operations by, when
    possible, using the space holding one of the operands to hold
    the result, rather than allocating new space.  Though primarily
    a speed improvement, for very long vectors avoiding this allocation 
    could avoid running out of space.

    Relevant test script:  test-complex-expr.r

    On this test, the speedup is about 5% for scalar operands and about
    8% for vector operands.

    Issues:  There are some tricky issues with attributes, but I think
    I got them right.  This patch relies on NAMED being set correctly 
    in the rest of the code.  In case it isn't, the patch can be disabled 
    by not defining AVOID_ALLOC_IF_POSSIBLE at the top of arithmetic.c.

patch-square

    Speeds up a^2 when a is a long vector by not checking for the
    special case of an exponent of 2 over and over again for every 
    vector element.

    Relevant test script:  test-square.r

    The time for squaring a long vector is reduced in this test by a
    factor of more than five.

patch-sum-prod

    Speeds up the "sum" and "prod" functions by not checking for NA
    when na.rm=FALSE, and other detailed code improvements.

    Relevant test script:  test-sum-prod.r

    For sum, the improvement is about a factor of 2.5 when na.rm=FALSE,
    and about 10% when na.rm=TRUE.

    Issue:  See the discussion of patch-matprod regarding LDOUBLE.
    There is no change regarding this issue due to this patch, however.

patch-transpose

    Speeds up the transpose operation (the "t" function) from detailed
    code improvements.

    Relevant test script:  test-transpose.r

    The improvement for 200x60 matrices is about a factor of two.
    There is little or no improvement for long row or column vectors.
    
patch-vec-arith

    Speeds up arithmetic on vectors of the same length, or when on
    vector is of length one.  This is done with detailed code improvements.

    Relevant test script:  test-vec-arith.r

    On long vectors, the +, -, and * operators are sped up by about     
    20% when operands are the same length or one operand is of length one.

    Rather mysteriously, when the operands are not length one or the
    same length, there is about a 20% increase in time required, though
    this may be due to some strange C optimizer peculiarity or some 
    strange cache effect, since the C code for this is the same as before,
    with negligible additional overhead getting to it.  Regardless, this 
    case is much less common than equal lengths or length one.

    There is little change for the / operator, which is much slower than
    +, -, or *.

patch-vec-subset

    Speeds up extraction of subsets of vectors or matrices (eg, v[10:20]
    or M[1:10,101:110]).  This is done with detailed code improvements,
    some increased fast treatment of common cases, and some avoidance of 
    unnecessary duplication.

    Relevant test script:  test-vec-subset.r

    There are lots of tests in this script.  The most dramatic improvement
    is for extracting many rows and columns of a large array, where the 
    improvement is by about a factor of four.  Extracting many rows from
    one column of a matrix is sped up by about 30%.  Extracting a large
    part of a vector is sped up by about 20%.  Several other operations 
    have improvements of 10% or more.

    Changes unrelated to speed improvement:

    Fixes two latent bugs where the code incorrectly refers to NA_LOGICAL
    when NA_INTEGER is appropriate and where LOGICAL and INTEGER types
    are treated as interchangeable.  These cause no problems at the moment,
    but would if representations were changed.

    Issues:  The current code duplicates a vector of indexes when 
    duplication seems unnecessary.  As far as I can see, the only reason
    for this is so that it can remove attributes, which is helpful only
    for string subscripts, given how the routine to handle them returns 
    information via an attribute.  If this is the only reason, as I concluded, 
    the duplication can easily be avoided, so I avoided it.  But perhaps 
    I don't understand something, since there are a fair number of 
    interactions going on with this code.  I also removed a layer of
    procedure call overhead that seemed to be doing nothing.  Probably
    it used to do something, but no longer does, but if instead it is
    preparation for some future use, then removing it would be a mistake.


From janko.thyson at ku-eichstaett.de  Fri Sep  3 21:55:42 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Fri, 3 Sep 2010 21:55:42 +0200
Subject: [Rd] Stats not loaded? Method for as.ts() results in error
In-Reply-To: <AANLkTimb6RLr-=VYjUunc8e1M8oKh0n7B6TJHka+=Lxb@mail.gmail.com>
References: <9002531500294005716@unknownmsgid>
	<AANLkTimb6RLr-=VYjUunc8e1M8oKh0n7B6TJHka+=Lxb@mail.gmail.com>
Message-ID: <001801cb4ba1$fdd2ce60$f9786b20$@thyson@ku-eichstaett.de>

Hi Jeff,

sorry for that! I found the problem in the meanwhile. But since I'm always
grateful to get answers from the list, here's what happened:

I have a method for as.ts()

setMethod(f = "as.ts", signature = "Tsi", definition = function(x, ...) 
{ 
	Function body
})

This is the error I always got while running R CMD check

Error in setMethod(f = "as.ts", signature = "Tsi", definition = function(x,
: 
  no existing definition for function "as.ts"

What I was too stupid to see is the fact that as.ts() isn't a generic in the
first place. Yet, I turned it into one somewhere in my code (which I forgot
;-)) and when I tried to debug my code manually I always misleadingly took
it as an innate generic and wondered why R CMD check always complained about
that fact that it couldn't find it.

Regards,
Janko


> -----Urspr?ngliche Nachricht-----
> Von: Jeff Ryan [mailto:jeff.a.ryan at gmail.com]
> Gesendet: Freitag, 3. September 2010 15:57
> An: Janko Thyson
> Cc: r-devel at r-project. org
> Betreff: Re: [Rd] Stats not loaded? Method for as.ts() results in error
> 
> Janko,
> 
> You don't mention if you are using S3 or S4.  A small example would
> make it easier to identify where your problem is.
> 
> Jeff
> 
> On Fri, Sep 3, 2010 at 4:44 AM, Janko Thyson
> <janko.thyson at ku-eichstaett.de> wrote:
> > Dear list,
> >
> >
> >
> > I've got the following problem:
> >
> >
> >
> > In a package I'm trying to build, there exists a method for the
> function
> > "as.ts()". When checking the package, R always throws the error that
> it
> > cannot find a function called "as.ts". To me it seems that the
> package
> > "stats" (home of "as.ts()") is not loaded during the checking process
> even
> > though it's a base package. For testing, I've written a method for
> "plot()"
> > to see if it's a general problem with base-functions, but this one
> passes
> > just fine.
> >
> >
> >
> > Did anyone of encounter a similar problem or could help me out with a
> hint?
> >
> >
> >
> > Thank you very much,
> >
> > Janko
> >
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> 
> 
> --
> Jeffrey Ryan
> jeff.a.ryan at gmail.com


From chiefmurphy at gmail.com  Sat Sep  4 01:56:03 2010
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Fri, 3 Sep 2010 16:56:03 -0700
Subject: [Rd] Incorrect formatted output after subtracting non-integer
 seconds from POSIXt origin
Message-ID: <AANLkTik_NnTBXUvVCPgxO9b_ExMoYMOa1c7HmBfLLsLt@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/6837d295/attachment.pl>

From simon.urbanek at r-project.org  Sat Sep  4 04:44:46 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 Sep 2010 22:44:46 -0400
Subject: [Rd] Incorrect formatted output after subtracting non-integer
	seconds from POSIXt origin
In-Reply-To: <AANLkTik_NnTBXUvVCPgxO9b_ExMoYMOa1c7HmBfLLsLt@mail.gmail.com>
References: <AANLkTik_NnTBXUvVCPgxO9b_ExMoYMOa1c7HmBfLLsLt@mail.gmail.com>
Message-ID: <360DE74B-85BD-4393-BC30-06D816F9824E@r-project.org>


On Sep 3, 2010, at 7:56 PM, Daniel Murphy wrote:

>> x<-as.POSIXct("1970-1-1", tz="UTC")-.5
>> y<-as.POSIXct("1970-1-1", tz="UTC")+.5
>> x==y
> [1] FALSE  # of course
> but x and y "appear" to be the same when formatted, even with extra
> precision:
>> format(x, format="%Y-%m-%d %H:%M:%OS2")
> [1] "1970-01-01 00:00:00.50"
>> format(y, format="%Y-%m-%d %H:%M:%OS2")
> [1] "1970-01-01 00:00:00.50"
> 
> Formatted output is fine for integral difference points ...
>> x<-as.POSIXct("1970-1-1", tz="UTC")-1
>> y<-as.POSIXct("1970-1-1", tz="UTC")+1
>> format(x, format="%Y-%m-%d %H:%M:%OS2")
> [1] "1969-12-31 23:59:59.00"
>> format(y, format="%Y-%m-%d %H:%M:%OS2")
> [1] "1970-01-01 00:00:01.00"
> 
> ... but seems to be a second "off" for non-integers:
>> format(as.POSIXct("1970-1-1", tz="UTC")-1.5, format="%Y-%m-%d %H:%M:%OS2")
> [1] "1969-12-31 23:59:59.50"   # a second later than expected
>> format(as.POSIXct("1970-1-1", tz="UTC")-86400, format="%Y-%m-%d
> %H:%M:%OS2")
> [1] "1969-12-31 00:00:00.00"   # OK
>> format(as.POSIXct("1970-1-1", tz="UTC")-86400.5, format="%Y-%m-%d
> %H:%M:%OS2")
> [1] "1969-12-31 00:00:00.50"   # why "after" previous time?
> 
> Bug, or user misunderstanding?


If negative POSIX time is supposed to work then it's a bug in as.POSIXlt(). Now fixed in R-devel (and patched).

Cheers,
Simon


before:
> str(unclass(as.POSIXlt(as.POSIXct("1970-1-1", tz="UTC")-0.2)))
List of 9
 $ sec  : num 0.8
 $ min  : int 0
 $ hour : int 0
 $ mday : int 1
 $ mon  : int 0
 $ year : int 70
 $ wday : int 4
 $ yday : int 0
 $ isdst: int 0
 - attr(*, "tzone")= chr "UTC"

R-devel:
> str(unclass(as.POSIXlt(as.POSIXct("1970-1-1", tz="UTC")-0.2)))
List of 9
 $ sec  : num 59.8
 $ min  : int 59
 $ hour : int 23
 $ mday : int 31
 $ mon  : int 11
 $ year : int 69
 $ wday : int 3
 $ yday : int 364
 $ isdst: int 0
 - attr(*, "tzone")= chr "UTC"




> "R version 2.11.1 (2010-05-31)" on Windows
> Thanks.
> Dan Murphy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From chiefmurphy at gmail.com  Sat Sep  4 06:35:26 2010
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Fri, 3 Sep 2010 21:35:26 -0700
Subject: [Rd] Incorrect formatted output after subtracting non-integer
 seconds from POSIXt origin
In-Reply-To: <360DE74B-85BD-4393-BC30-06D816F9824E@r-project.org>
References: <AANLkTik_NnTBXUvVCPgxO9b_ExMoYMOa1c7HmBfLLsLt@mail.gmail.com>
	<360DE74B-85BD-4393-BC30-06D816F9824E@r-project.org>
Message-ID: <AANLkTikH9SimzhBOxKnYVVsUBuq4NuWJwLN+5VifABJi@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/191fc31a/attachment.pl>

From radford at cs.toronto.edu  Fri Sep  3 19:27:19 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Fri, 3 Sep 2010 13:27:19 -0400
Subject: [Rd] Fourteen patches to speed up R
Message-ID: <20100903172719.GA5284@cs.toronto.edu>

I've continued to work on speeding up R, and now have a collection of
fourteen patches, some of which speed up particular functions, and
some of which reduce general interpretive overhead.  The total speed
improvement from these patches is substantial.  It varies a lot from
one R program to the next, of course, and probably from one machine to
the next, but speedups of 25% can be expected in many programs, and
sometimes much more (though sometimes less as well).

The fourteen patches work for revision r52822 of the development
version of R (I haven't check against any changes in the last few
days), and also for release 2.11.1.  These patches, along with
some documentation, are attached as speed-patches.tar.

I also wrote a number of timing test programs, which are attached as
speed-tests.tar.

I've included below the documentation on what each patch does, which
is also in "doc" in speed-patches.tar.  Note that I fixed a few minor
bugs along the way.

There looks to be scope for more improvements in various parts of the
R interpreter that I didn't get to.  I'll have to put this on hold for
now, however, to spend my time preparing for the coming teaching term.
I'd be happy to hear of any comments on these patches, though,
including information on how much they speed up typical programs, on
various machines.

   Radford Neal

-----------------------------------------------------------------------

These patches to the R source for improving speed were written by
Radford M. Neal, Sept. 2010.

See the README file for how to install them. 

Below, I describe these patches (in alphabetical order), indicate what
improvement they produce, and also mention any potential issues with
using the patch, and bugs that the patches incidently fix.

The timing improvements discussed below are what is obtained by
applying each patch individually, on an Intel system running Ubuntu
Linux with Gcc version 4.2.4.  The total improvement from all patches
is much bigger, though in a few instances a patch can diminish the
effect of another patch, by reducing the magnitude of the
inefficiencies that the other patch eliminates.  Note though, that the
percentage improvement for a given absolute improvement gets bigger as
when other patches reduce overall time.

For r52822, the total time for all tests in the accompanying speed
test suite is 674 seconds.  This is reduced to 487 seconds with all
patches applied, a reduction of 28%.  Particular R programs will, of
course, see widely varying reductions depending on what operations
they mostly do.

patch-dollar

    Speeds up access to lists, pairlists, and environments using the
    $ operator.  The speedup comes mainly from avoiding the overhead of 
    calling DispatchOrEval if there are no complexities, from passing
    on the field to extract as a symbol, or a name, or both, as available,
    and then converting only as necessary, from simplifying and inlining
    the pstrmatch procedure, and from not translating string multiple
    times.  

    Relevant timing test script:  test-dollar.r 

    This test shows about a 40% decrease in the time needed to extract
    elements of lists and environments.

    Changes unrelated to speed improvement:

    A small error-reporting bug is fixed, illustrated by the following
    output with r52822:

    > options(warnPartialMatchDollar=TRUE)
    > pl <- pairlist(abc=1,def=2)
    > pl$ab
    [1] 1
    Warning message:
    In pl$ab : partial match of 'ab' to ''

    Some code is changed at the end of R_subset3_dflt because it seems 
    to be more correct, as discussed in code comments. 
    
patch-evalList

    Speeds up a large number of operations by avoiding allocation of
    an extra CONS cell in the procedures for evaluating argument lists.

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 5%.

patch-fast-base

    Speeds up lookup of symbols defined in the base environment, by
    flagging symbols that have a base environment definition recorded
    in the global cache.  This allows the definition to be retrieved
    quickly without looking in the hash table.  

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 3%.

    Issue:  This patch uses the "spare" bit for the flag.  This bit is
    misnamed, since it is already used elsewhere (for closures).  It is
    possible that one of the "gp" bits should be used instead.  The
    "gp" bits should really be divided up for faster access, and so that
    their present use is apparent in the code.

    In case this use of the "spare" bit proves unwise, the patch code is 
    conditional on FAST_BASE_CACHE_LOOKUP being defined at the start of
    envir.r.

patch-fast-spec

    Speeds up lookup of function symbols that begin with a character
    other than a letter or ".", by allowing fast bypass of non-global
    environments that do not contain (and have never contained) symbols 
    of this sort.  Since it is expected that only functions will be
    given names of this sort, the check is done only in findFun, though
    it could also be done in findVar.

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 8%.    

    Issue:  This patch uses the "spare" bit to flag environments known
    to not have symbols starting with a special character.  See remarks
    on patch-fast-base.

    In case this use of the "spare" bit proves unwise, the patch code is 
    conditional on FAST_SPEC_BYPASS being defined at the start of envir.r.

patch-for

    Speeds up for loops by not allocating new space for the loop
    variable every iteration, unless necessary.  

    Relevant timing test script:  test-for.r

    This test shows a speedup of about 5%.  

    Change unrelated to speed improvement:

    Fixes what I consider to be a bug, in which the loop clobbers a
    global variable, as demonstrated by the following output with r52822:

    > i <- 99
    > f <- function () for (i in 1:3) { print(i); if (i==2) rm(i); }
    > f()
    [1] 1
    [1] 2
    [1] 3
    > print(i)
    [1] 3

patch-matprod

    Speeds up matrix products, including vector dot products.  The
    speed issue here is that the R code checks for any NAs, and 
    does the multiply in the matprod procedure (in array.c) if so,
    since BLAS isn't trusted with NAs.  If this check takes about
    as long as just doing the multiply in matprod, calling a BLAS
    routine makes no sense.  

    Relevant time test script:  test-matprod.r

    With no external BLAS, this patch speeds up long vector-vector 
    products by a factor of about six, matrix-vector products by a
    factor of about three, and some matrix-matrix products by a 
    factor of about two.

    Issue:  The matrix multiply code in matprod using an LDOUBLE
    (long double) variable to accumulate sums, for improved accuracy.  
    On a SPARC system I tested on, operations on long doubles are 
    vastly slower than on doubles, so that the patch produces a 
    large slowdown rather than an improvement.  This is also an issue 
    for the "sum" function, which also uses an LDOUBLE to accumulate
    the sum.  Perhaps an ordinarly double should be used in these
    places, or perhaps the configuration script should define LDOUBLE 
    as double on architectures where long doubles are extraordinarily 
    slow.

    Due to this issue, not defining MATPROD_CAN_BE_DONE_HERE at the
    start of array.c will disable this patch.
    
patch-parens

    Speeds up parentheses by making "(" a special operator whose
    argument is not evaluated, thereby bypassing the overhead of
    evalList.  Also slightly speeds up curly brackets by inlining
    a function that is stylistically better inline anyway.

    Relevant test script:  test-parens.r

    In the parens part of test-parens.r, the speedup is about 9%.

patch-protect

    Speeds up numerous operations by making PROTECT, UNPROTECT, etc.
    be mostly macros in the files in src/main.  This takes effect
    only for files that include Defn.h after defining the symbol
    USE_FAST_PROTECT_MACROS.  With these macros, code of the form
    v = PROTECT(...) must be replaced by PROTECT(v = ...).  

    Relevant timing test scripts:  all of them, but will look at test-em.r 

    On test-em.r, the speedup from this patch is about 9%.

patch-save-alloc

    Speeds up some binary and unary arithmetic operations by, when
    possible, using the space holding one of the operands to hold
    the result, rather than allocating new space.  Though primarily
    a speed improvement, for very long vectors avoiding this allocation 
    could avoid running out of space.

    Relevant test script:  test-complex-expr.r

    On this test, the speedup is about 5% for scalar operands and about
    8% for vector operands.

    Issues:  There are some tricky issues with attributes, but I think
    I got them right.  This patch relies on NAMED being set correctly 
    in the rest of the code.  In case it isn't, the patch can be disabled 
    by not defining AVOID_ALLOC_IF_POSSIBLE at the top of arithmetic.c.

patch-square

    Speeds up a^2 when a is a long vector by not checking for the
    special case of an exponent of 2 over and over again for every 
    vector element.

    Relevant test script:  test-square.r

    The time for squaring a long vector is reduced in this test by a
    factor of more than five.

patch-sum-prod

    Speeds up the "sum" and "prod" functions by not checking for NA
    when na.rm=FALSE, and other detailed code improvements.

    Relevant test script:  test-sum-prod.r

    For sum, the improvement is about a factor of 2.5 when na.rm=FALSE,
    and about 10% when na.rm=TRUE.

    Issue:  See the discussion of patch-matprod regarding LDOUBLE.
    There is no change regarding this issue due to this patch, however.

patch-transpose

    Speeds up the transpose operation (the "t" function) from detailed
    code improvements.

    Relevant test script:  test-transpose.r

    The improvement for 200x60 matrices is about a factor of two.
    There is little or no improvement for long row or column vectors.
    
patch-vec-arith

    Speeds up arithmetic on vectors of the same length, or when on
    vector is of length one.  This is done with detailed code improvements.

    Relevant test script:  test-vec-arith.r

    On long vectors, the +, -, and * operators are sped up by about     
    20% when operands are the same length or one operand is of length one.

    Rather mysteriously, when the operands are not length one or the
    same length, there is about a 20% increase in time required, though
    this may be due to some strange C optimizer peculiarity or some 
    strange cache effect, since the C code for this is the same as before,
    with negligible additional overhead getting to it.  Regardless, this 
    case is much less common than equal lengths or length one.

    There is little change for the / operator, which is much slower than
    +, -, or *.

patch-vec-subset

    Speeds up extraction of subsets of vectors or matrices (eg, v[10:20]
    or M[1:10,101:110]).  This is done with detailed code improvements,
    some increased fast treatment of common cases, and some avoidance of 
    unnecessary duplication.

    Relevant test script:  test-vec-subset.r

    There are lots of tests in this script.  The most dramatic improvement
    is for extracting many rows and columns of a large array, where the 
    improvement is by about a factor of four.  Extracting many rows from
    one column of a matrix is sped up by about 30%.  Extracting a large
    part of a vector is sped up by about 20%.  Several other operations 
    have improvements of 10% or more.

    Changes unrelated to speed improvement:

    Fixes two latent bugs where the code incorrectly refers to NA_LOGICAL
    when NA_INTEGER is appropriate and where LOGICAL and INTEGER types
    are treated as interchangeable.  These cause no problems at the moment,
    but would if representations were changed.

    Issues:  The current code duplicates a vector of indexes when 
    duplication seems unnecessary.  As far as I can see, the only reason
    for this is so that it can remove attributes, which is helpful only
    for string subscripts, given how the routine to handle them returns 
    information via an attribute.  If this is the only reason, as I concluded, 
    the duplication can easily be avoided, so I avoided it.  But perhaps 
    I don't understand something, since there are a fair number of 
    interactions going on with this code.  I also removed a layer of
    procedure call overhead that seemed to be doing nothing.  Probably
    it used to do something, but no longer does, but if instead it is
    preparation for some future use, then removing it would be a mistake.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: speed-patches.tar
Type: application/x-tar
Size: 133120 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/f09f134f/attachment.tar>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: speed-tests.tar
Type: application/x-tar
Size: 61440 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100903/f09f134f/attachment-0001.tar>

From renaud.lancelot at gmail.com  Sat Sep  4 14:23:41 2010
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Sat, 4 Sep 2010 14:23:41 +0200
Subject: [Rd] R and Epi Info
In-Reply-To: <30CCD2C98CF7EC46ABF4CD310179FD6501D6D2F66591@EXCHANGE11.Enterprise.emory.net>
References: <30CCD2C98CF7EC46ABF4CD310179FD6501D6D2F66591@EXCHANGE11.Enterprise.emory.net>
Message-ID: <AANLkTi==dBuiVg3bSwWzSY-Ju_JTr=qwsXZ-5gobbmL_@mail.gmail.com>

Dear Kevin,

I often use Epi Info to develop questionnaires and databases with MSc
/ PhD students for the purpose of field surveys. It's straightforward
to send queries in the Epi Info databases (MS Access format) and
retrieve data using packages like RODBC.

All the best,

Renaud

2010/8/31 Sullivan, Kevin M <cdckms at emory.edu>:
> Hello,
> ? I was wondering who to contact to see about somehow interconnecting or integrating the programs R and Epi Info. ?I have been involved in the development of Epi Info which is a software program developed by the Centers for Disease Control and Prevention (CDC) in Atlanta (www.cdc.gov/epiinfo<http://www.cdc.gov/epiinfo>). ?Epi Info allows for creating data entry systems and performs certain epidemiologic and statistical analyses. ?Currently Epi Info is in the public domain and I believe future versions will be open source. ?It might be useful to pull together some of the Epi Info development team members and R team members to discuss how the programs might complement each other. ?Note that I request this from my position at Emory University and this is not an official request from CDC.
> ? Thanks, Kevin
>
> ________________________________
> This e-mail message (including any attachments) is for...{{dropped:24}}


From D.Strbenac at garvan.org.au  Sun Sep  5 06:00:11 2010
From: D.Strbenac at garvan.org.au (DarioAustralia)
Date: Sat, 4 Sep 2010 21:00:11 -0700 (PDT)
Subject: [Rd] S4 Method Signatures
In-Reply-To: <19584.42244.459156.294014@lynne.math.ethz.ch>
References: <20100903120014.BIP57496@gimr.garvan.unsw.edu.au>
	<19584.42244.459156.294014@lynne.math.ethz.ch>
Message-ID: <1283659211635-2527083.post@n4.nabble.com>


Ah yes. I should have checked the details more finely. I come from a
programming background in a different language, and had the thought that
generic functions would work much like function overloading.
-- 
View this message in context: http://r.789695.n4.nabble.com/S4-Method-Signatures-tp2525018p2527083.html
Sent from the R devel mailing list archive at Nabble.com.


From hb at stat.berkeley.edu  Sun Sep  5 06:17:42 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 4 Sep 2010 21:17:42 -0700
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <4C80FFBC.90200@sciviews.org>
References: <4C80B1FA.9060403@sciviews.org> <4C80DF09.9030805@gmail.com>
	<4C80EFCE.3070400@fhcrc.org> <4C80FFBC.90200@sciviews.org>
Message-ID: <AANLkTin35A3XPSpBNRuZXPKgZUW-kVw+UocfVw9CjaZZ@mail.gmail.com>

This looks like a good old friend or maybe its cousin... it's been
discovered, confusing us and also debugged several times before:

http://tolstoy.newcastle.edu.au/R/devel/06/04/4861.html
http://tolstoy.newcastle.edu.au/R/e6/devel/09/06/2081.html

/Henrik

On Fri, Sep 3, 2010 at 7:01 AM, Philippe Grosjean
<phgrosjean at sciviews.org> wrote:
> Martin,
>
> This looks like a possible explanation. After double-check, it occurs with R
> 2.10.1 and 2.11.0 (not 2.11.1, as I reported in my original email). I'll
> upgrade R and test again. I'll report the results on Monday, since my code
> has to run over the week-end.
> Thanks,
>
> PhG
>
> On 03/09/10 14:53, Martin Morgan wrote:
>>
>> On 09/03/2010 04:42 AM, Duncan Murdoch wrote:
>>>
>>> Philippe Grosjean wrote:
>>>>
>>>> Hello,
>>>>
>>>> It's several days I try to track this bug, and even cannot cook a
>>>> reproducible example. Yet, it occurs consistently in a long-running
>>>> task after a variable period of time. Here is an example:
>>>>
>>>
>>> I would look closely at the other software that is running in your
>>> long example. ?Does it include C (or other external) code? ?Look
>>> closely at that, it might be writing outside it's own allocated
>>> memory. ?Also check for correct protection of intermediate results, if
>>> you're producing SEXPs in the external code. ?(Running under gctorture
>>> might flush out the bug more quickly if the latter is the problem.)
>>>
>>> If you're only running R code, then this looks like a bug in R, but it
>>> might still be worth trying gctorture to make it reproducible. ?We
>>> won't be able to fix it if we can't reproduce it.
>>>
>>> Duncan Murdoch
>>>>
>>>> ... my long-running code [as I said, cannot give something simple
>>>> that produces this bug in a reproducible manner]
>>>>
>>>> Error in match(x, table, nomatch = 0L) :
>>>> ? ? ?formal argument "nomatch" matched by multiple actual arguments
>>>> ?> ?traceback()
>>>> 6: match(x, table, nomatch = 0L)
>>>> 5: "factor" %in% attrib[["class", exact = TRUE]]
>>>> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
>>>> 3: Sys.time()
>>>> 2: chemTrigger() at chemostat_1.0-1.R#1132
>>>> 1: chemRun()
>>
>> I think this is a bug in R that has been fixed in the subversion commit
>> below, and so should be fixed in R-2.11.1.
>> What is your sessionInfo(), and does your error occur in the devel
>> version of R?
>>
>> Martin
>>
>> r51232 | falcon | 2010-03-09 13:59:48 -0800 (Tue, 09 Mar 2010) | 14 lines
>> Changed paths:
>> ? ?M /trunk/src/main/match.c
>>
>> Fix bug in matchArgs triggered by gc and finalizers
>>
>> matchArgs was modifying the general purpose bits of SEXPs making up the
>> 'formals' argument to keep track of ARGUSED. ?When gc is triggered
>> inside matchArgs, finalizer code can end up calling matchArgs on the
>> same function (hence same formals) resulting in corruption of gp bits.
>>
>> This patch uses an int array allocated on the stack to keep track of
>> ARGUSED and avoids modifying the SEXPs in formals. ?In place modification
>> of SEXPs in supplied still occurs via ARGUSED/SET_ARGUSED, but should be
>> safe as long as no new allocating function calls are added to matchArgs.
>>
>> A reproducible report of this bug was reported here:
>> https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000997.html
>>
>>
>>>>
>>>> So, the culprid is a call inside `%in%` (from within structure() in
>>>> Sys.time()). But I can run millions times `%in%`, or structure(), or
>>>> Sys.time() on my machine without producing this bug. Arguments at 5:
>>>> are simple character strings. They don't hurt!
>>>>
>>>> Also, I am lost because the message is totally illogical in the
>>>> context where it appears: I can understand this message here:
>>>>
>>>> ?> ?match(1, 2, nomatch = 0L, nomatch = NA)
>>>> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>>>> ? ?formal argument "nomatch" matched by multiple actual arguments
>>>>
>>>> or here:
>>>>
>>>> ?> ?test<- function (...) match(1, ..., nomatch = 0L)
>>>> ?> ?test(2, nomatch = NA)
>>>> Error in match(1, ..., nomatch = 0L) :
>>>> ? ?formal argument "nomatch" matched by multiple actual arguments
>>>>
>>>> but in the call "match(x, table, nomatch = 0L)" where x is the
>>>> character string "factor" and table is another character string
>>>> ("numeric") extracted from a list, I don't understand why it produces
>>>> this error message. '.Internal(Sys.time())' uses do_systime c code
>>>> that returns a one-element double... not something that can hurt here?!
>>>>
>>>> Can someone explain me, or give me an example where an argument is
>>>> NOT duplicated in the call (well, as I understand it here) and where
>>>> one gets such an error message? And why?
>>>>
>>>> Many thanks, I am desperate :-(
>>>>
>>>> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on
>>>> Windows XP SP3 (but it does not matter, since I cannot cook a
>>>> reproducible example).
>>>>
>>>> Philippe
>>>>
>>>> P.S.: seems related to this:
>>>> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From phgrosjean at sciviews.org  Mon Sep  6 17:54:52 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 06 Sep 2010 17:54:52 +0200
Subject: [Rd] Weird erratic error and illogical error message,
 could someone explain this?
In-Reply-To: <AANLkTin35A3XPSpBNRuZXPKgZUW-kVw+UocfVw9CjaZZ@mail.gmail.com>
References: <4C80B1FA.9060403@sciviews.org>
	<4C80DF09.9030805@gmail.com>	<4C80EFCE.3070400@fhcrc.org>
	<4C80FFBC.90200@sciviews.org>
	<AANLkTin35A3XPSpBNRuZXPKgZUW-kVw+UocfVw9CjaZZ@mail.gmail.com>
Message-ID: <4C850ECC.7080808@sciviews.org>

Just to give feedback after running my program during the week-end: the 
bugs has disappeared and everything runs fine now. The only change I did 
was to upgrade to latest patched version of R 1.11.1. It is probable 
that my problem was fixed by:

r51232 | falcon | 2010-03-09 13:59:48 -0800 (Tue, 09 Mar 2010) | 14 lines
Changed paths:
    M /trunk/src/main/match.c

Fix bug in matchArgs triggered by gc and finalizers

matchArgs was modifying the general purpose bits of SEXPs making up the
'formals' argument to keep track of ARGUSED.  When gc is triggered
inside matchArgs, finalizer code can end up calling matchArgs on the
same function (hence same formals) resulting in corruption of gp bits.

This patch uses an int array allocated on the stack to keep track of
ARGUSED and avoids modifying the SEXPs in formals.  In place modification
of SEXPs in supplied still occurs via ARGUSED/SET_ARGUSED, but should be
safe as long as no new allocating function calls are added to matchArgs.

A reproducible report of this bug was reported here:
https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000997.html

Thanks for the help.
Best,

Philippe


On 05/09/10 06:17, Henrik Bengtsson wrote:
> This looks like a good old friend or maybe its cousin... it's been
> discovered, confusing us and also debugged several times before:
>
> http://tolstoy.newcastle.edu.au/R/devel/06/04/4861.html
> http://tolstoy.newcastle.edu.au/R/e6/devel/09/06/2081.html
>
> /Henrik
>
> On Fri, Sep 3, 2010 at 7:01 AM, Philippe Grosjean
> <phgrosjean at sciviews.org>  wrote:
>> Martin,
>>
>> This looks like a possible explanation. After double-check, it occurs with R
>> 2.10.1 and 2.11.0 (not 2.11.1, as I reported in my original email). I'll
>> upgrade R and test again. I'll report the results on Monday, since my code
>> has to run over the week-end.
>> Thanks,
>>
>> PhG
>>
>> On 03/09/10 14:53, Martin Morgan wrote:
>>>
>>> On 09/03/2010 04:42 AM, Duncan Murdoch wrote:
>>>>
>>>> Philippe Grosjean wrote:
>>>>>
>>>>> Hello,
>>>>>
>>>>> It's several days I try to track this bug, and even cannot cook a
>>>>> reproducible example. Yet, it occurs consistently in a long-running
>>>>> task after a variable period of time. Here is an example:
>>>>>
>>>>
>>>> I would look closely at the other software that is running in your
>>>> long example.  Does it include C (or other external) code?  Look
>>>> closely at that, it might be writing outside it's own allocated
>>>> memory.  Also check for correct protection of intermediate results, if
>>>> you're producing SEXPs in the external code.  (Running under gctorture
>>>> might flush out the bug more quickly if the latter is the problem.)
>>>>
>>>> If you're only running R code, then this looks like a bug in R, but it
>>>> might still be worth trying gctorture to make it reproducible.  We
>>>> won't be able to fix it if we can't reproduce it.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>> ... my long-running code [as I said, cannot give something simple
>>>>> that produces this bug in a reproducible manner]
>>>>>
>>>>> Error in match(x, table, nomatch = 0L) :
>>>>>       formal argument "nomatch" matched by multiple actual arguments
>>>>>   >    traceback()
>>>>> 6: match(x, table, nomatch = 0L)
>>>>> 5: "factor" %in% attrib[["class", exact = TRUE]]
>>>>> 4: structure(.Internal(Sys.time()), class = c("POSIXt", "POSIXct"))
>>>>> 3: Sys.time()
>>>>> 2: chemTrigger() at chemostat_1.0-1.R#1132
>>>>> 1: chemRun()
>>>
>>> I think this is a bug in R that has been fixed in the subversion commit
>>> below, and so should be fixed in R-2.11.1.
>>> What is your sessionInfo(), and does your error occur in the devel
>>> version of R?
>>>
>>> Martin
>>>
>>> r51232 | falcon | 2010-03-09 13:59:48 -0800 (Tue, 09 Mar 2010) | 14 lines
>>> Changed paths:
>>>     M /trunk/src/main/match.c
>>>
>>> Fix bug in matchArgs triggered by gc and finalizers
>>>
>>> matchArgs was modifying the general purpose bits of SEXPs making up the
>>> 'formals' argument to keep track of ARGUSED.  When gc is triggered
>>> inside matchArgs, finalizer code can end up calling matchArgs on the
>>> same function (hence same formals) resulting in corruption of gp bits.
>>>
>>> This patch uses an int array allocated on the stack to keep track of
>>> ARGUSED and avoids modifying the SEXPs in formals.  In place modification
>>> of SEXPs in supplied still occurs via ARGUSED/SET_ARGUSED, but should be
>>> safe as long as no new allocating function calls are added to matchArgs.
>>>
>>> A reproducible report of this bug was reported here:
>>> https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000997.html
>>>
>>>
>>>>>
>>>>> So, the culprid is a call inside `%in%` (from within structure() in
>>>>> Sys.time()). But I can run millions times `%in%`, or structure(), or
>>>>> Sys.time() on my machine without producing this bug. Arguments at 5:
>>>>> are simple character strings. They don't hurt!
>>>>>
>>>>> Also, I am lost because the message is totally illogical in the
>>>>> context where it appears: I can understand this message here:
>>>>>
>>>>>   >    match(1, 2, nomatch = 0L, nomatch = NA)
>>>>> Error in match(1, 2, nomatch = 0L, nomatch = NA) :
>>>>>     formal argument "nomatch" matched by multiple actual arguments
>>>>>
>>>>> or here:
>>>>>
>>>>>   >    test<- function (...) match(1, ..., nomatch = 0L)
>>>>>   >    test(2, nomatch = NA)
>>>>> Error in match(1, ..., nomatch = 0L) :
>>>>>     formal argument "nomatch" matched by multiple actual arguments
>>>>>
>>>>> but in the call "match(x, table, nomatch = 0L)" where x is the
>>>>> character string "factor" and table is another character string
>>>>> ("numeric") extracted from a list, I don't understand why it produces
>>>>> this error message. '.Internal(Sys.time())' uses do_systime c code
>>>>> that returns a one-element double... not something that can hurt here?!
>>>>>
>>>>> Can someone explain me, or give me an example where an argument is
>>>>> NOT duplicated in the call (well, as I understand it here) and where
>>>>> one gets such an error message? And why?
>>>>>
>>>>> Many thanks, I am desperate :-(
>>>>>
>>>>> I got this error on R 2.11.1 on Mac OS X 10.6.4, and on R 2.10.1 on
>>>>> Windows XP SP3 (but it does not matter, since I cannot cook a
>>>>> reproducible example).
>>>>>
>>>>> Philippe
>>>>>
>>>>> P.S.: seems related to this:
>>>>> http://finzi.psych.upenn.edu/Rhelp10/2008-June/165101.html
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ligges at statistik.tu-dortmund.de  Mon Sep  6 20:04:38 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 06 Sep 2010 20:04:38 +0200
Subject: [Rd] winbuilder offline / CRAN windows binaries
Message-ID: <4C852D36.6080808@statistik.tu-dortmund.de>

Dear all,

the winbuilder service as well as the build system for new / updated 
CRAN windows binaries will be offline for a day or two. I hope to get it 
online as soon as possible.

Best wishes,
Uwe Ligges


From ligges at statistik.tu-dortmund.de  Mon Sep  6 20:36:20 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 06 Sep 2010 20:36:20 +0200
Subject: [Rd] winbuilder offline / CRAN windows binaries
In-Reply-To: <4C852D36.6080808@statistik.tu-dortmund.de>
References: <4C852D36.6080808@statistik.tu-dortmund.de>
Message-ID: <4C8534A4.1030301@statistik.tu-dortmund.de>



On 06.09.2010 20:04, Uwe Ligges wrote:
> Dear all,
>
> the winbuilder service as well as the build system for new / updated
> CRAN windows binaries will be offline for a day or two. I hope to get it
> online as soon as possible.

.... which could be reduced to 30 minutes. :-)

Uwe


>
> Best wishes,
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From guitarlady86 at hotmail.com  Mon Sep  6 22:10:38 2010
From: guitarlady86 at hotmail.com (Leidy Patricia Garzon)
Date: Mon, 6 Sep 2010 20:10:38 +0000
Subject: [Rd] RJava
Message-ID: <SNT112-W217A47BA9B294045CC64E9CD700@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100906/20c277be/attachment.pl>

From simon.urbanek at r-project.org  Mon Sep  6 23:59:21 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 6 Sep 2010 17:59:21 -0400
Subject: [Rd] RJava
In-Reply-To: <SNT112-W217A47BA9B294045CC64E9CD700@phx.gbl>
References: <SNT112-W217A47BA9B294045CC64E9CD700@phx.gbl>
Message-ID: <DE552547-2CFB-4473-860D-9A86BF969F02@r-project.org>


On Sep 6, 2010, at 4:10 PM, Leidy Patricia Garzon wrote:

> 
> hello 
> 
> I am having the same problem published in https://stat.ethz.ch/pipermail/r-help/2008-July/167191.html but I haven't seen the solution
> 
> Could some body helpme
> 

Well, if you posted to the correct list (stats-rosuda-devel) you would have increased your chance of getting help considerably.

That "problem" is a bug in the Java program -- the constructor it is using does NOT initialize R but is used to hook into an already running R (please consult the docs: http://rforge.net/org/docs/). That program should read:

            Rengine re=new Rengine(args, false, null);
            re.assign("x", "Peter");

Also note that it is discouraged to use the low-level API. It is preferable for new projects to use the high-level org.rosuda.REngine API instead:

	REngine eng = REngine.engineForClass("org.rosuda.REngine.JRI.JRIEngine");  
	eng.assign("x", "Peter")

It is far more flexible and more safe that he direct API. Also it allows you to switch to several back-ends.

Cheers,
Simon


From D.Strbenac at garvan.org.au  Tue Sep  7 07:00:24 2010
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Tue,  7 Sep 2010 15:00:24 +1000 (EST)
Subject: [Rd] Dispatch method on S3 or S4 class
Message-ID: <20100907150024.BIQ94758@gimr.garvan.unsw.edu.au>

Hello,

I've been attempting to make a generic method that dispatches on the first argument, which can be either an S3 or an S4 class. This is as far as I've gotten. Any suggestions about what to try next ?

library(aroma.affymetrix)
library(GenomicRanges)

setGeneric("analyse", function(x, y, ...) standardGeneric("analyse"))

setMethodS3("analyse", "AffymetrixCelSet", function(x, y, z, ...)
{
	x;
	UseMethod("analyse")
}
)

setGeneric("analyse")

setMethod("analyse", "GRangesList", function(x, y, a, b, c)
{
	x;
}
)

Thanks,
       Dario.

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From mtmorgan at fhcrc.org  Tue Sep  7 07:40:47 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 06 Sep 2010 22:40:47 -0700
Subject: [Rd] Sexpr in package.Rd fails
Message-ID: <4C85D05F.4090307@fhcrc.org>

If I

f = function() {}
package.skeleton("PkgA", "f", path="/tmp")

and then edit man/PkgA-pacakge.Rd to read in part

\description{
More about what it does (maybe more than one line)
\Sexpr{1}
}

and then

R CMD build PkgA

I end up with

Saving output to ?/tmp/PkgA/build/PkgA.pdf? ...
Warning in file.create(to[okay]) :
cannot create file '/tmp/PkgA/build/PkgA.pdf', reason 'No such file or
directory'
Done

This is because the 'build' directory does not exist when the pdf is
being written.

Further, if I

\details{
\tabular{ll}{
Package: \tab PkgA \cr
Type: \tab Package\cr
Version: \tab \Sexpr{packageDescription("PkgA")[["Version"]]} \cr
Date: \tab 2010-09-06\cr
License: \tab What license is it under?\cr
LazyLoad: \tab yes\cr
}
}

I see

* installing the package to process help pages
* building the package manual
Hmm ... looks like a package
Converting Rd files to LaTeX Warning in packageDescription("PkgA") : no
package 'PkgA' was found
Error : /tmp/PkgA/man/PkgA-package.Rd:16: subscript out of bounds

The package appears to be installed for processing help pages without
Sexprs, but not with.

This is from a post on the Bioconductor 'devel' list.

https://stat.ethz.ch/pipermail/bioc-devel/2010-September/002296.html

with

> sessionInfo()
R version 2.12.0 Under development (unstable) (2010-09-05 r52874)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8 LC_NAME=C
[9] LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats graphics grDevices utils datasets methods base

Martin


From mtmorgan at fhcrc.org  Tue Sep  7 15:28:30 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 07 Sep 2010 06:28:30 -0700
Subject: [Rd] Dispatch method on S3 or S4 class
In-Reply-To: <20100907150024.BIQ94758@gimr.garvan.unsw.edu.au>
References: <20100907150024.BIQ94758@gimr.garvan.unsw.edu.au>
Message-ID: <4C863DFE.1010506@fhcrc.org>

On 09/06/2010 10:00 PM, Dario Strbenac wrote:
> Hello,
>
> I've been attempting to make a generic method that dispatches on the first argument, which can be either an S3 or an S4 class. This is as far as I've gotten. Any suggestions about what to try next ?
>
> library(aroma.affymetrix)
> library(GenomicRanges)
>
> setGeneric("analyse", function(x, y, ...) standardGeneric("analyse"))
>
> setMethodS3("analyse", "AffymetrixCelSet", function(x, y, z, ...)
> {
> 	x;
> 	UseMethod("analyse")
> }
> )
>
> setGeneric("analyse")
>
> setMethod("analyse", "GRangesList", function(x, y, a, b, c)
> {
> 	x;
> }
> )
I think (no testing on my end) you want

setOldClass("AffymetrixCelSet")

setGeneric("analyse", function(x, y, ...) standardGeneric("analyse"))

setMethod(analyse, "AffymetrixCelSet", function(x, y, z, ...)
{
    cat("AffymetrixCelSet\n")
    x
})

setMethod(analyse, "GRangesList", function(x, y, a, b, c)
{
    cat("GRangesList\n")
    x
})

and then by way of reproducible example

> x = analyse(structure(list(), class="AffymetrixCelSet"))
AffymetrixCelSet
> y = analyse(GRangesList())
GRangesList


Martin
>
> Thanks,
>        Dario.
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at bht-berlin.de  Tue Sep  7 18:23:10 2010
From: groemping at bht-berlin.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Tue, 07 Sep 2010 18:23:10 +0200
Subject: [Rd] as.character on NaN gives "NaN", is that intentional?
Message-ID: <4C8666EE.9030807@bht-berlin.de>

Dear DevelopeRs,

I am surprised about the outcome of the second command:

str(as.character(as.numeric("ee"))) 
str(as.character(log(-1)))

I would have expected a character NA. Is there an intention behind this 
behavior?

Best, Ulrike

-- 
*****************************************************
* Ulrike Groemping                                  *
* BHT Berlin - University of Applied Sciences       *
*****************************************************
* +49 (30) 39404863 (Home Office)                   *
* +49 (30) 4504 5127 (BHT)                          *
*****************************************************
* http://prof.beuth-hochschule.de/groemping         *
* groemping at bht-berlin.de                           *


From kevin.r.coombes at gmail.com  Tue Sep  7 19:03:51 2010
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Tue, 07 Sep 2010 12:03:51 -0500
Subject: [Rd] as.character on NaN gives "NaN", is that intentional?
In-Reply-To: <4C8666EE.9030807@bht-berlin.de>
References: <4C8666EE.9030807@bht-berlin.de>
Message-ID: <4C867077.5030607@gmail.com>

  It seems to me that preserving information about the kind of number 
(or not) present would be useful. I rather like the fact that
    as.numeric(as.character(NaN))
and
    as.numeric(as.character(Inf))
both work as the identity operator on numeric-like objects.  (In this 
context, note that both is.numeric(NaN) and is.numeric(Inf) both return 
TRUE.)  In your example, the character string "ee" does not represent 
any number that I know about (at least in standard R).

     Kevin

On 9/7/2010 11:23 AM, Ulrike Gr?mping wrote:
> Dear DevelopeRs,
>
> I am surprised about the outcome of the second command:
>
> str(as.character(as.numeric("ee"))) str(as.character(log(-1)))
>
> I would have expected a character NA. Is there an intention behind 
> this behavior?
>
> Best, Ulrike
>


From lachmann at eva.mpg.de  Tue Sep  7 20:06:42 2010
From: lachmann at eva.mpg.de (ghostwheel)
Date: Tue, 7 Sep 2010 11:06:42 -0700 (PDT)
Subject: [Rd] Is an R sub-session somehow possible?
Message-ID: <1283882802031-2530174.post@n4.nabble.com>


I wrote the interface between R and TeXmacs. Recently, I added tab
completion. However, there is one slight problem. In order to enable easy
interaction with R, I (I.e. my program) interact with the command-line
interface. This means that the user can invoke demo(), and then R will
interact with the user and ask to press enter.
It also means that the user can enter
a<-c(3,4
and then R will respond with '+'.

The problem is this: the way I implemented tab completion is calling an R
function that creates the completion. But, while in the middle of user
input, I can't call a function.

I guess that ESS for emacs has the same problem. when I enter "a<-c(3,4",
and then on the next line try to do tab completion, ESS replies that 'ESS
process is not ready. Finish your command before trying again'.
Of course while interacting with R on the command line, tab completion does
work.

So, the question is - is there any way to interrupt the current input to R,
call a function, get the return value, and then continue with the input
where it was? To do something similar to what pressing 'tab' in R does
internally? Something like the equivalent of ctrl-Z for a shell?

-- 
View this message in context: http://r.789695.n4.nabble.com/Is-an-R-sub-session-somehow-possible-tp2530174p2530174.html
Sent from the R devel mailing list archive at Nabble.com.


From lachmann at eva.mpg.de  Tue Sep  7 20:21:50 2010
From: lachmann at eva.mpg.de (ghostwheel)
Date: Tue, 7 Sep 2010 11:21:50 -0700 (PDT)
Subject: [Rd] what is the best way for an external interface to interact
 with graphics, libraries
Message-ID: <1283883710896-2530208.post@n4.nabble.com>


Another message about the R to TeXmacs interface.

1. Graphics
The TeXmacs interface allows the user to directly insert graphics into the
session. 

Since I am not very familiar with programming for R, I implemented the
interaction with graphics in a very primitive way. It was two modes of
working: with X11, and without (for example when working remotely through
ssh without forwarding X11).

In both cases the user has to invoke a command, v(), in order to insert the
current graph into the buffer at the current place.

With X11, the way it works is that when v() is invoked I call recordPlot(),
then open a postscript file, then replayPlot(), and then close the
postscript file and insert it into the session.

Without X11, I open a postscript file ahead of time, then when v() is
called, I close it, and insert it into the session, and then open a new
postscript file.

Obviously quite primitive.I think ideally would be if everything was
transparent to the user - the user does a plot, and the plot is inserted
into the buffer right away, and later, updates to the same plot update the
original plot where it is. But to be able to do that I need to be able to
generate the postscript file of the current plot, and be notified somehow
whenever the plot changes.

Is all that possible? Is there a better way to implement this all?

2. Libraries

A remotely related question is this: the interface with TeXmacs generates
menus that depend on the currently loaded libraries. I'd like to be able to
update the menus whenever a new library is loaded. Is there a possibility to
have a function called whenever this happens? Or would it be advisable to
change the global 'library' function?

-- 
View this message in context: http://r.789695.n4.nabble.com/what-is-the-best-way-for-an-external-interface-to-interact-with-graphics-libraries-tp2530208p2530208.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Tue Sep  7 20:23:44 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 7 Sep 2010 14:23:44 -0400
Subject: [Rd] Is an R sub-session somehow possible?
In-Reply-To: <1283882802031-2530174.post@n4.nabble.com>
References: <1283882802031-2530174.post@n4.nabble.com>
Message-ID: <8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>


On Sep 7, 2010, at 2:06 PM, ghostwheel wrote:

> 
> I wrote the interface between R and TeXmacs. Recently, I added tab
> completion. However, there is one slight problem. In order to enable easy
> interaction with R, I (I.e. my program) interact with the command-line
> interface. This means that the user can invoke demo(), and then R will
> interact with the user and ask to press enter.
> It also means that the user can enter
> a<-c(3,4
> and then R will respond with '+'.
> 
> The problem is this: the way I implemented tab completion is calling an R
> function that creates the completion. But, while in the middle of user
> input, I can't call a function.
> 

Why not? After the "+" prompt you're back in ReadConsole so it's safe.

Cheers,
Simon


> I guess that ESS for emacs has the same problem. when I enter "a<-c(3,4",
> and then on the next line try to do tab completion, ESS replies that 'ESS
> process is not ready. Finish your command before trying again'.
> Of course while interacting with R on the command line, tab completion does
> work.
> 
> So, the question is - is there any way to interrupt the current input to R,
> call a function, get the return value, and then continue with the input
> where it was? To do something similar to what pressing 'tab' in R does
> internally? Something like the equivalent of ctrl-Z for a shell?
> 
> -- 
> View this message in context: http://r.789695.n4.nabble.com/Is-an-R-sub-session-somehow-possible-tp2530174p2530174.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Tue Sep  7 20:34:55 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 7 Sep 2010 14:34:55 -0400
Subject: [Rd] what is the best way for an external interface to interact
	with graphics, libraries
In-Reply-To: <1283883710896-2530208.post@n4.nabble.com>
References: <1283883710896-2530208.post@n4.nabble.com>
Message-ID: <B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>


On Sep 7, 2010, at 2:21 PM, ghostwheel wrote:

> 
> Another message about the R to TeXmacs interface.
> 
> 1. Graphics
> The TeXmacs interface allows the user to directly insert graphics into the
> session. 
> 
> Since I am not very familiar with programming for R, I implemented the
> interaction with graphics in a very primitive way. It was two modes of
> working: with X11, and without (for example when working remotely through
> ssh without forwarding X11).
> 
> In both cases the user has to invoke a command, v(), in order to insert the
> current graph into the buffer at the current place.
> 
> With X11, the way it works is that when v() is invoked I call recordPlot(),
> then open a postscript file, then replayPlot(), and then close the
> postscript file and insert it into the session.
> 
> Without X11, I open a postscript file ahead of time, then when v() is
> called, I close it, and insert it into the session, and then open a new
> postscript file.
> 
> Obviously quite primitive.I think ideally would be if everything was
> transparent to the user - the user does a plot, and the plot is inserted
> into the buffer right away, and later, updates to the same plot update the
> original plot where it is. But to be able to do that I need to be able to
> generate the postscript file of the current plot, and be notified somehow
> whenever the plot changes.
> 
> Is all that possible? Is there a better way to implement this all?
> 

I don't know the mechanics of the actual "inserting" in TeXmac but it would be trivial to simply create a copy of the plot as EPS (or whatever is needed) at the time of insertion. See dev.copy2eps() for a function that does exactly that.



> 2. Libraries
> 
> A remotely related question is this: the interface with TeXmacs generates
> menus that depend on the currently loaded libraries.

Libraries are not "loaded" (see .libPath() for handling libraries) - but chances are that you meant packages...


> I'd like to be able to
> update the menus whenever a new library is loaded. Is there a possibility to
> have a function called whenever this happens? Or would it be advisable to
> change the global 'library' function?
> 

I would strongly advise against the latter. A reasonably simple way would be to check the search path - if it changed a package has been loaded. A natural place to do such check would be in a top-level task handler for example.

Cheers,
Simon


From lachmann at eva.mpg.de  Tue Sep  7 20:43:34 2010
From: lachmann at eva.mpg.de (ghostwheel)
Date: Tue, 7 Sep 2010 11:43:34 -0700 (PDT)
Subject: [Rd] Is an R sub-session somehow possible?
In-Reply-To: <8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>
References: <1283882802031-2530174.post@n4.nabble.com>
	<8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>
Message-ID: <1283885014288-2530233.post@n4.nabble.com>



Simon Urbanek wrote:
> 
> 
> On Sep 7, 2010, at 2:06 PM, ghostwheel wrote:
> 
>> a<-c(3,4
>> and then R will respond with '+'.
>> 
>> The problem is this: the way I implemented tab completion is calling an R
>> function that creates the completion. But, while in the middle of user
>> input, I can't call a function.
>> 
> 
> Why not? After the "+" prompt you're back in ReadConsole so it's safe.
> 
> 

I see. ReadConsole() seems quite nice! I should use it.

What about remote sessions? Till now I used ssh, which then opened R. I
guess I could have the user compile and install the program that interfaces
with R on any machine that runs R. Is there another way?

Thanks,
Michael
-- 
View this message in context: http://r.789695.n4.nabble.com/Is-an-R-sub-session-somehow-possible-tp2530174p2530233.html
Sent from the R devel mailing list archive at Nabble.com.


From lachmann at eva.mpg.de  Tue Sep  7 21:07:40 2010
From: lachmann at eva.mpg.de (ghostwheel)
Date: Tue, 7 Sep 2010 12:07:40 -0700 (PDT)
Subject: [Rd] what is the best way for an external interface to interact
 with graphics, libraries
In-Reply-To: <B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>
References: <1283883710896-2530208.post@n4.nabble.com>
	<B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>
Message-ID: <1283886460100-2530256.post@n4.nabble.com>



Simon Urbanek wrote:
> 
> 
> I don't know the mechanics of the actual "inserting" in TeXmac but it
> would be trivial to simply create a copy of the plot as EPS (or whatever
> is needed) at the time of insertion. See dev.copy2eps() for a function
> that does exactly that.
> 
> 

Great. It works much better than my recordPlot() hack. But it seems to only
work for 'screen devices'. I'd like to be able to work remotely without X11.
Is there any equivalent graphics device that would be copyable with
dev.copy2eps?  Is there any way to tell R give me whatever you have till now
in eps? 


-- 
View this message in context: http://r.789695.n4.nabble.com/what-is-the-best-way-for-an-external-interface-to-interact-with-graphics-libraries-tp2530208p2530256.html
Sent from the R devel mailing list archive at Nabble.com.


From groemping at bht-berlin.de  Tue Sep  7 21:18:58 2010
From: groemping at bht-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Tue, 07 Sep 2010 21:18:58 +0200
Subject: [Rd] as.character on NaN gives "NaN", is that intentional?
In-Reply-To: <4C867077.5030607@gmail.com>
References: <4C8666EE.9030807@bht-berlin.de> <4C867077.5030607@gmail.com>
Message-ID: <4C869022.7070800@bht-berlin.de>

Kevin,

I wouldn't mind NaN (although it seems a bit strange, because you 
wouldn't expect a character to be a number), but I find it strange to 
get the character string "NaN". is.na(as.character(NaN)) returns FALSE, 
which is what I dislike.

Best, Ulrike

Kevin R. Coombes schrieb:
>  It seems to me that preserving information about the kind of number 
> (or not) present would be useful. I rather like the fact that
>    as.numeric(as.character(NaN))
> and
>    as.numeric(as.character(Inf))
> both work as the identity operator on numeric-like objects.  (In this 
> context, note that both is.numeric(NaN) and is.numeric(Inf) both 
> return TRUE.)  In your example, the character string "ee" does not 
> represent any number that I know about (at least in standard R).
>
>     Kevin
>
> On 9/7/2010 11:23 AM, Ulrike Gr?mping wrote:
>> Dear DevelopeRs,
>>
>> I am surprised about the outcome of the second command:
>>
>> str(as.character(as.numeric("ee"))) str(as.character(log(-1)))
>>
>> I would have expected a character NA. Is there an intention behind 
>> this behavior?
>>
>> Best, Ulrike
>>


From simon.urbanek at r-project.org  Tue Sep  7 23:23:57 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 7 Sep 2010 17:23:57 -0400
Subject: [Rd] what is the best way for an external interface to interact
	with graphics, libraries
In-Reply-To: <1283886460100-2530256.post@n4.nabble.com>
References: <1283883710896-2530208.post@n4.nabble.com>
	<B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>
	<1283886460100-2530256.post@n4.nabble.com>
Message-ID: <E4390BF3-5D29-49FB-92A3-AF859440FC24@r-project.org>


On Sep 7, 2010, at 3:07 PM, ghostwheel wrote:

> 
> 
> Simon Urbanek wrote:
>> 
>> 
>> I don't know the mechanics of the actual "inserting" in TeXmac but it
>> would be trivial to simply create a copy of the plot as EPS (or whatever
>> is needed) at the time of insertion. See dev.copy2eps() for a function
>> that does exactly that.
>> 
>> 
> 
> Great. It works much better than my recordPlot() hack. But it seems to only
> work for 'screen devices'. I'd like to be able to work remotely without X11.
> Is there any equivalent graphics device that would be copyable with
> dev.copy2eps?  Is there any way to tell R give me whatever you have till now
> in eps? 
> 

No (AFAIR PS devoice does not keep a display list).

However, you can use any other device that uses a display list, e.g. CairoPS from the Cairo package (in fact any of the Cairo devices..).

Cheers,
Simon


From simon.urbanek at r-project.org  Tue Sep  7 23:25:22 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 7 Sep 2010 17:25:22 -0400
Subject: [Rd] Is an R sub-session somehow possible?
In-Reply-To: <1283885014288-2530233.post@n4.nabble.com>
References: <1283882802031-2530174.post@n4.nabble.com>
	<8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>
	<1283885014288-2530233.post@n4.nabble.com>
Message-ID: <DB68F427-6A41-48B5-9C88-6B6B7DB72A2E@r-project.org>


On Sep 7, 2010, at 2:43 PM, ghostwheel wrote:

> 
> 
> Simon Urbanek wrote:
>> 
>> 
>> On Sep 7, 2010, at 2:06 PM, ghostwheel wrote:
>> 
>>> a<-c(3,4
>>> and then R will respond with '+'.
>>> 
>>> The problem is this: the way I implemented tab completion is calling an R
>>> function that creates the completion. But, while in the middle of user
>>> input, I can't call a function.
>>> 
>> 
>> Why not? After the "+" prompt you're back in ReadConsole so it's safe.
>> 
>> 
> 
> I see. ReadConsole() seems quite nice! I should use it.
> 
> What about remote sessions? Till now I used ssh, which then opened R. I
> guess I could have the user compile and install the program that interfaces
> with R on any machine that runs R. Is there another way?
> 

It doesn't really matter where the R is as long as you have some way of getting at the results. You are still leaving us in the dark as of what exactly you do (technically) so there is not much detail we can provide...

Cheers,
Simon


From whuber at embl.de  Wed Sep  8 00:01:23 2010
From: whuber at embl.de (Wolfgang Huber)
Date: Wed, 08 Sep 2010 00:01:23 +0200
Subject: [Rd] as.character on NaN gives "NaN", is that intentional?
In-Reply-To: <4C869022.7070800@bht-berlin.de>
References: <4C8666EE.9030807@bht-berlin.de> <4C867077.5030607@gmail.com>
	<4C869022.7070800@bht-berlin.de>
Message-ID: <4C86B633.90204@embl.de>


Hi Ulrike

any set of three people will probably have five different opinions on 
this, but I can see that this makes sense:

NA - not available, not measured, not recorded
NaN - result of an arithmetic computation that lies outside of the real 
numbers; in that sense, "available".

However, this point of view then opens up the question why 'is.na(NaN)' 
is 'TRUE'.


	Best wishes
	Wolfgang

On 07/09/10 21:18, Ulrike Gr?mping wrote:
> Kevin,
>
> I wouldn't mind NaN (although it seems a bit strange, because you
> wouldn't expect a character to be a number), but I find it strange to
> get the character string "NaN". is.na(as.character(NaN)) returns FALSE,
> which is what I dislike.
>
> Best, Ulrike
>
> Kevin R. Coombes schrieb:
>> It seems to me that preserving information about the kind of number
>> (or not) present would be useful. I rather like the fact that
>> as.numeric(as.character(NaN))
>> and
>> as.numeric(as.character(Inf))
>> both work as the identity operator on numeric-like objects. (In this
>> context, note that both is.numeric(NaN) and is.numeric(Inf) both
>> return TRUE.) In your example, the character string "ee" does not
>> represent any number that I know about (at least in standard R).
>>
>> Kevin
>>
>> On 9/7/2010 11:23 AM, Ulrike Gr?mping wrote:
>>> Dear DevelopeRs,
>>>
>>> I am surprised about the outcome of the second command:
>>>
>>> str(as.character(as.numeric("ee"))) str(as.character(log(-1)))
>>>
>>> I would have expected a character NA. Is there an intention behind
>>> this behavior?
>>>
>>> Best, Ulrike
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 


Wolfgang Huber
EMBL
http://www.embl.de/research/units/genome_biology/huber


From lachmann at eva.mpg.de  Wed Sep  8 00:27:24 2010
From: lachmann at eva.mpg.de (ghostwheel)
Date: Tue, 7 Sep 2010 15:27:24 -0700 (PDT)
Subject: [Rd] Is an R sub-session somehow possible?
In-Reply-To: <DB68F427-6A41-48B5-9C88-6B6B7DB72A2E@r-project.org>
References: <1283882802031-2530174.post@n4.nabble.com>
	<8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>
	<1283885014288-2530233.post@n4.nabble.com>
	<DB68F427-6A41-48B5-9C88-6B6B7DB72A2E@r-project.org>
Message-ID: <1283898444715-2530527.post@n4.nabble.com>



Simon Urbanek wrote:
> 
> 
> 
> It doesn't really matter where the R is as long as you have some way of
> getting at the results. You are still leaving us in the dark as of what
> exactly you do (technically) so there is not much detail we can provide...
> 
> 

Sorry, I'll try to provide more detail:

I am trying to provide a good connection between the TeXmacs editor and R.
(A really nice overview of such connections can be found in
http://www.r-project.org/conferences/useR-2004/abstracts/supplements/Urbanek.pdf
;)
What I do is fake a terminal, and interact with the command line interface
to R (something like what the program 'expect' does). To detect that R is
waiting for input I have to check various properties of the terminal. Not
really pretty.
What happens is that:
1. TeXmacs sends me a string to execute. 
2. I pass it to R, and wait for a prompt.
3. I pass all of R's return, somewhat processed back to TeXmacs. Thus, when 
I want to put a graphics inside TeXmacs' buffer, I have to print something
like 'start postscipt graphics', then the postscript file, then 'end
postscript'.

When the user asks for tab completion, TeXmacs sends me a special message
saying that this string needs to be completed. I call a function in R, and
return the result.

My program is able to interact with a remote R session, i.e. the session
will start on a different machine than the one TeXmacs runs on. Luckily, it
is also possible to detect when R waits for a prompt in a remote session by
doing these ugly terminal hacks.

In some cases the R prompt won't be a prompt for another command, but
instead, R is just waiting for user input, or for completion of the previous
input.

Now, my remaining question is this:
When I run R remotely, by emulating a terminal, and interacting with R in
command line mode, AND
when at the same time R is not waiting for a command, but instead for some
other kind of user interaction, my interface can't send to R a request to
execute the code to complete a certain string.
(I.e. call the function t.tab.complete that I attached below).

If I understand correctly, one solution is to write a replacement input
loop, so that R will call my ReadConsole() from time to time, and while I'm
inside that function, I could call R functions to provide tab completion.

In that case, for remote sessions, I would have to compile on the remote
computer this alternative R input loop, and I would have to have one for
every version of R that a user might want to run on the remote machine (the
machine I am currently working with remotely has 11 versions of R
installed...). I was wondering if there is still a way to avoid that, and
interact with the regular input loop, or maybe it is possible to load an
alternative input loop from a package/library inside an already running
regular R interface?
I would like the user to have to do as little as possible in terms of
installing additional programs on a remote machine.

Thanks,
I'm not sure if this was the type of additional information you meant...
Michael

Here is my tab completion routine, ("\2" and "\5" are the codes for TeXmacs
for a start and a stop of blocks. (basically like brackets) ).
-----
t.tab.comp<-function(s,curs)
  {
    rc.settings(help=F) #This is because of a bug in matchAvailableTopics in
package utils
    rc.settings(file=T)

    utils:::.assignLinebuffer(substr(s,1,curs))
    utils:::.assignEnd(nchar(s))
    utils:::.guessTokenFromLine()
    utils:::.completeToken()
    l=utils:::.retrieveCompletions()
    l=sapply(l,function(x) {
      substr(x, nchar(utils:::.CompletionEnv[["token"]])+1,nchar(x) )
    } )
    i=grep("=$",l)
    if( (length(l[-i]) > 10) & (length(i)>0 ) )
    l=c(l[i])
    s3=utils:::.CompletionEnv[["token"]]
    s3=gsub("\"","\\\\\"",s3)
    deb.l <<- l
    
    cat("\2scheme:(tuple \"",s3,"\"",sep="") ;
    cat(" \"")
    if( length(l) > 0 )
    {
      cat(l,sep="\" \"")
    }
    else
    {
      #cat(s)
      cat("\"\"")
    }
    cat("\"")
    cat(")\5")
    
  ---- 

-- 
View this message in context: http://r.789695.n4.nabble.com/Is-an-R-sub-session-somehow-possible-tp2530174p2530527.html
Sent from the R devel mailing list archive at Nabble.com.


From spluque at gmail.com  Wed Sep  8 01:39:54 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 07 Sep 2010 18:39:54 -0500
Subject: [Rd] How to add a slot to S4 class of an existing package?
In-Reply-To: <495954FE.6070401@ebi.ac.uk> (Wolfgang Huber's message of "Mon,
	29 Dec 2008 22:53:50 +0000")
References: <494FECF9.2020301@aon.at> <495954FE.6070401@ebi.ac.uk>
Message-ID: <878w3df7hx.fsf@kolob.sebmags.homelinux.org>

Hi,

Is there a better approach to adding new slots to an S4 class without
breaking code that accesses older objects of that class than the
Bioconductor reference in the thread below?  Thanks.

Cheers,
Seb



On Mon, 29 Dec 2008 22:53:50 +0000,
Wolfgang Huber <huber at ebi.ac.uk> wrote:

> Dear Christian this post from Martin Morgan on class versioning in
> Bioconductor's Biobase package might be relevant:
> https://stat.ethz.ch/pipermail/bioc-devel/2006-May/000545.html and
> also section 6 of this:
> http://www.bioconductor.org/packages/2.4/bioc/vignettes/Biobase/inst/doc/BiobaseDevelopment.pdf

> 	Best wishes Wolfgang

> ---------------------------------------------------- Wolfgang Huber
> EMBL-EBI http://www.ebi.ac.uk/huber

> cstrato wrote:
>> Dear all,

>> Since my package is based on S4 classes, I would like to know how to
>> add a slot to an existing S4 class without breaking the code of users
>> of my package.

>> Assume the following S4 class: setClass("MyClass",
>> representation(name = "character", type = "character", data =
>> "data.frame" ), prototype(name = "", type = "Default", data =
>> data.frame(matrix(nr=0,nc=0)) ) )#MyClass

>> Assume that a user has created an object: > myclass <- new("MyClass",
>> name="MyName", type="MyType", data=tmp) > str(myclass)


>> Now I would like to add another slot "info" to MyClass:
>> setClass("MyClass", representation(name = "character", type =
>> "character", data = "data.frame", info = "data.frame" ),
>> prototype(name = "", type = "Default", data =
>> data.frame(matrix(nr=0,nc=0)), info = data.frame(matrix(nr=0,nc=0)) )
>> )#MyClass

>> Now when the user loads my package with S4 class MyClass containing a
>> new slot and calls: > str(myclass) Error in FUN(c("name", "type",
>> "data", "info")[[4L]], ...) : no slot of name "info" for this object
>> of class "MyClass"


>> My question is: Is there any possibility or special trick, which
>> would avoid this error message?

>> Are there other possibilities to access an additional data.frame from
>> an existing class?

>> Is there something like an "evolution" of S4 classes, which
>> distinguishes the different implementations of an S4 class, and
>> allows the user to keep the object of an old class?

>> Best regards Christian _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a V.i.e.n.n.a A.u.s.t.r.i.a
>> e.m.a.i.l: cstrato at aon.at _._._._._._._._._._._._._._._._._._

>> ______________________________________________ R-devel at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Seb


From kasperdanielhansen at gmail.com  Wed Sep  8 02:41:14 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 7 Sep 2010 20:41:14 -0400
Subject: [Rd] How to add a slot to S4 class of an existing package?
In-Reply-To: <878w3df7hx.fsf@kolob.sebmags.homelinux.org>
References: <494FECF9.2020301@aon.at> <495954FE.6070401@ebi.ac.uk>
	<878w3df7hx.fsf@kolob.sebmags.homelinux.org>
Message-ID: <AANLkTikJ336mVCnvAD3k-COMffzz_Bc0aJkRAPPyRhni@mail.gmail.com>

Seb

That thread and the resources in Biobase assumes that you have a class
that extends "Versioned".  Doing so will help you in the long run by
providing you with updateObject (at the cost of some complexity).
However, it does not really help you if the existing class does not
extend Versioned.

In general, adding a new slot should not break any existing code, but
you may find users who have old objects lying around that they cannot
use with the new functionality (I assume you are adding slots to
provide new functionality).

Kasper

On Tue, Sep 7, 2010 at 7:39 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,
>
> Is there a better approach to adding new slots to an S4 class without
> breaking code that accesses older objects of that class than the
> Bioconductor reference in the thread below? ?Thanks.
>
> Cheers,
> Seb
>
>
>
> On Mon, 29 Dec 2008 22:53:50 +0000,
> Wolfgang Huber <huber at ebi.ac.uk> wrote:
>
>> Dear Christian this post from Martin Morgan on class versioning in
>> Bioconductor's Biobase package might be relevant:
>> https://stat.ethz.ch/pipermail/bioc-devel/2006-May/000545.html and
>> also section 6 of this:
>> http://www.bioconductor.org/packages/2.4/bioc/vignettes/Biobase/inst/doc/BiobaseDevelopment.pdf
>
>> ? ? ? Best wishes Wolfgang
>
>> ---------------------------------------------------- Wolfgang Huber
>> EMBL-EBI http://www.ebi.ac.uk/huber
>
>> cstrato wrote:
>>> Dear all,
>
>>> Since my package is based on S4 classes, I would like to know how to
>>> add a slot to an existing S4 class without breaking the code of users
>>> of my package.
>
>>> Assume the following S4 class: setClass("MyClass",
>>> representation(name = "character", type = "character", data =
>>> "data.frame" ), prototype(name = "", type = "Default", data =
>>> data.frame(matrix(nr=0,nc=0)) ) )#MyClass
>
>>> Assume that a user has created an object: > myclass <- new("MyClass",
>>> name="MyName", type="MyType", data=tmp) > str(myclass)
>
>
>>> Now I would like to add another slot "info" to MyClass:
>>> setClass("MyClass", representation(name = "character", type =
>>> "character", data = "data.frame", info = "data.frame" ),
>>> prototype(name = "", type = "Default", data =
>>> data.frame(matrix(nr=0,nc=0)), info = data.frame(matrix(nr=0,nc=0)) )
>>> )#MyClass
>
>>> Now when the user loads my package with S4 class MyClass containing a
>>> new slot and calls: > str(myclass) Error in FUN(c("name", "type",
>>> "data", "info")[[4L]], ...) : no slot of name "info" for this object
>>> of class "MyClass"
>
>
>>> My question is: Is there any possibility or special trick, which
>>> would avoid this error message?
>
>>> Are there other possibilities to access an additional data.frame from
>>> an existing class?
>
>>> Is there something like an "evolution" of S4 classes, which
>>> distinguishes the different implementations of an S4 class, and
>>> allows the user to keep the object of an old class?
>
>>> Best regards Christian _._._._._._._._._._._._._._._._._._
>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a V.i.e.n.n.a A.u.s.t.r.i.a
>>> e.m.a.i.l: cstrato at aon.at _._._._._._._._._._._._._._._._._._
>
>>> ______________________________________________ R-devel at r-project.org
>>> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Seb
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.murrell at auckland.ac.nz  Wed Sep  8 03:11:10 2010
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 08 Sep 2010 13:11:10 +1200
Subject: [Rd] what is the best way for an external interface to interact
 with graphics, libraries
In-Reply-To: <E4390BF3-5D29-49FB-92A3-AF859440FC24@r-project.org>
References: <1283883710896-2530208.post@n4.nabble.com>	<B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>	<1283886460100-2530256.post@n4.nabble.com>
	<E4390BF3-5D29-49FB-92A3-AF859440FC24@r-project.org>
Message-ID: <4C86E2AE.8030003@auckland.ac.nz>

Hi

On 8/09/2010 9:23 a.m., Simon Urbanek wrote:
>
> On Sep 7, 2010, at 3:07 PM, ghostwheel wrote:
>
>>
>>
>> Simon Urbanek wrote:
>>>
>>>
>>> I don't know the mechanics of the actual "inserting" in TeXmac but it
>>> would be trivial to simply create a copy of the plot as EPS (or whatever
>>> is needed) at the time of insertion. See dev.copy2eps() for a function
>>> that does exactly that.
>>>
>>>
>>
>> Great. It works much better than my recordPlot() hack. But it seems to only
>> work for 'screen devices'. I'd like to be able to work remotely without X11.
>> Is there any equivalent graphics device that would be copyable with
>> dev.copy2eps?  Is there any way to tell R give me whatever you have till now
>> in eps?
>>
>
> No (AFAIR PS devoice does not keep a display list).

PS device does not keep a display list *by default*.  You should be able 
to turn it on via ...

dev.control("enable")

Paul

> However, you can use any other device that uses a display list, e.g. CairoPS from the Cairo package (in fact any of the Cairo devices..).
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From radford at cs.toronto.edu  Wed Sep  8 04:20:04 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Tue, 7 Sep 2010 22:20:04 -0400
Subject: [Rd] Correction to vec-subset speed patch
Message-ID: <20100908022004.GA28873@cs.toronto.edu>

I found a bug in one of the fourteen speed patches I posted, namely in
patch-vec-subset.  I've fixed this (I now see one does need to
duplicate index vectors sometimes, though one can avoid it most of the
time). I also split this patch in two, since it really has two
different and independent parts.  The patch-vec-subset patch now has
only some straightforward (locally-checkable) speedups for copies.
The new patch-subscript patch has the speedups for creation of index
vectors, which is where the bug was, and which generally have more
global interactions.  I made some other changes in the patch-subscript
part along with fixing the bug.

I've attached the new versions of the patches.  Here is the
documentation for the two revised patches:

patch-vec-subset

    Speeds up extraction of subsets of vectors or matrices (eg, v[10:20]
    or M[1:10,101:110]).  This is done with detailed code improvements.

    Relevant test script:  test-vec-subset.r

    There are lots of tests in this script.  The most dramatic improvement
    is for extracting many rows and columns of a large array, where the 
    improvement is by about a factor of four.  Extracting many rows from
    one column of a matrix is sped up by about 30%. 

    Changes unrelated to speed improvement:

    Fixes two latent bugs where the code incorrectly refers to NA_LOGICAL
    when NA_INTEGER is appropriate and where LOGICAL and INTEGER types
    are treated as interchangeable.  These cause no problems at the moment,
    but would if representations were changed.

patch-subscript

    (Formerly part of patch-vec-subset)  This patch also speeds up
    extraction, and also replacement, of subsets of vectors or
    matrices, but focuses on the creation of the indexes rather than
    the copy operations.  Often avoids a duplication (see below) and
    eliminates a second scan of the subscript vector for zero
    subscripts, folding it into a previous scan at no additional cost.

    Relevant test script:  test-vec-subset.r

    Speeds up some operations with scalar or short vector indexes by
    about 10%.  Speeds up subscripting with a longer vector of
    positive indexes by about 20%.

    Issues:  The current code duplicates a vector of indexes when it
    seems unnecessary.  Duplication is for two reasons:  to handle
    the situation where the index vector is itself being modified in
    a replace operation, and so that any attributes can be removed, which 
    is helpful only for string subscripts, given how the routine to handle 
    them returns information via an attribute.  Duplication for the
    second reasons can easily be avoided, so I avoided it.  The first
    reason for duplication is sometimes valid, but can usually be avoided
    by first only doing it if the subscript is to be used for replacement
    rather than extraction, and second only doing it if the NAMED field
    for the subscript isn't zero.

    I also removed two layers of procedure call overhead (passing seven
    arguments, so not trivial) that seemed to be doing nothing.  Probably 
    it used to do something, but no longer does, but if instead it is 
    preparation for some future use, then removing it might be a mistake.
-------------- next part --------------
Index: src/main/subset.c
===================================================================
--- src/main/subset.c	(revision 52822)
+++ src/main/subset.c	(working copy)
@@ -59,73 +59,77 @@
     if (x == R_NilValue)
 	return x;
 
-    for (i = 0; i < n; i++) {
-	ii = INTEGER(indx)[i];
-	if (ii != NA_INTEGER)
-	    ii--;
-	switch (mode) {
-	case LGLSXP:
-	    if (0 <= ii && ii < nx && ii != NA_LOGICAL)
-		LOGICAL(result)[i] = LOGICAL(x)[ii];
-	    else
-		LOGICAL(result)[i] = NA_INTEGER;
-	    break;
-	case INTSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER)
-		INTEGER(result)[i] = INTEGER(x)[ii];
-	    else
-		INTEGER(result)[i] = NA_INTEGER;
-	    break;
-	case REALSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER)
-		REAL(result)[i] = REAL(x)[ii];
-	    else
-		REAL(result)[i] = NA_REAL;
-	    break;
-	case CPLXSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER) {
-		COMPLEX(result)[i] = COMPLEX(x)[ii];
-	    }
-	    else {
-		COMPLEX(result)[i].r = NA_REAL;
-		COMPLEX(result)[i].i = NA_REAL;
-	    }
-	    break;
-	case STRSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER)
-		SET_STRING_ELT(result, i, STRING_ELT(x, ii));
-	    else
-		SET_STRING_ELT(result, i, NA_STRING);
-	    break;
-	case VECSXP:
-	case EXPRSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER)
-		SET_VECTOR_ELT(result, i, VECTOR_ELT(x, ii));
-	    else
-		SET_VECTOR_ELT(result, i, R_NilValue);
-	    break;
-	case LISTSXP:
+    switch (mode) {
+    case LGLSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                LOGICAL(result)[i] = NA_LOGICAL;
+            else
+                LOGICAL(result)[i] = LOGICAL(x)[ii];
+        break;
+    case INTSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                INTEGER(result)[i] = NA_INTEGER;
+            else
+                INTEGER(result)[i] = INTEGER(x)[ii];
+        break;
+    case REALSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                REAL(result)[i] = NA_REAL;
+            else
+                REAL(result)[i] = REAL(x)[ii];
+        break;
+    case CPLXSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx) {
+                COMPLEX(result)[i].r = NA_REAL;
+                COMPLEX(result)[i].i = NA_REAL; 
+            }
+            else
+                COMPLEX(result)[i] = COMPLEX(x)[ii];
+        break;
+    case STRSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                SET_STRING_ELT(result, i, NA_STRING);
+            else
+                SET_STRING_ELT(result, i, STRING_ELT(x, ii));
+        break;
+    case VECSXP:
+    case EXPRSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                SET_VECTOR_ELT(result, i, R_NilValue);
+            else
+                SET_VECTOR_ELT(result, i, VECTOR_ELT(x, ii));
+        break;
+    case LISTSXP:
 	    /* cannot happen: pairlists are coerced to lists */
-	case LANGSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER) {
-		tmp2 = nthcdr(x, ii);
-		SETCAR(tmp, CAR(tmp2));
-		SET_TAG(tmp, TAG(tmp2));
-	    }
-	    else
-		SETCAR(tmp, R_NilValue);
-	    tmp = CDR(tmp);
-	    break;
-	case RAWSXP:
-	    if (0 <= ii && ii < nx && ii != NA_INTEGER)
-		RAW(result)[i] = RAW(x)[ii];
-	    else
-		RAW(result)[i] = (Rbyte) 0;
-	    break;
-	default:
-	    errorcall(call, R_MSG_ob_nonsub, type2char(mode));
-	}
+    case LANGSXP:
+        for (i = 0; i<n; i++) {
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                SETCAR(tmp, R_NilValue);
+            else {
+                tmp2 = nthcdr(x, ii);
+                SETCAR(tmp, CAR(tmp2));
+                SET_TAG(tmp, TAG(tmp2));
+            }
+            tmp = CDR(tmp);
+        }
+        break;
+    case RAWSXP:
+        for (i = 0; i<n; i++)
+            if ((ii=INTEGER(indx)[i]) == NA_INTEGER || --ii < 0 || ii >= nx)
+                RAW(result)[i] = (Rbyte) 0;
+            else
+                RAW(result)[i] = RAW(x)[ii];
+        break;
+    default:
+        errorcall(call, R_MSG_ob_nonsub, type2char(mode));
     }
+
     return result;
 }
 
@@ -210,12 +214,54 @@
     return result;
 }
 
+/* Used in MatrixSubset to set a whole row or column of a matrix to NAs. */
 
+static void set_row_or_col_to_na (SEXP result, int start, int step, int end,
+                                  SEXP call)
+{
+    int i;
+    switch (TYPEOF(result)) {
+    case LGLSXP:
+        for (i = start; i<end; i += step)
+            LOGICAL(result)[i] = NA_LOGICAL;
+        break;
+    case INTSXP:
+        for (i = start; i<end; i += step)
+            INTEGER(result)[i] = NA_INTEGER;
+        break;
+    case REALSXP:
+        for (i = start; i<end; i += step)
+            REAL(result)[i] = NA_REAL;
+        break;
+    case CPLXSXP:
+        for (i = start; i<end; i += step) {
+            COMPLEX(result)[i].r = NA_REAL;
+            COMPLEX(result)[i].i = NA_REAL;
+        }
+        break;
+    case STRSXP:
+        for (i = start; i<end; i += step)
+            SET_STRING_ELT(result, i, NA_STRING);
+        break;
+    case VECSXP:
+        for (i = start; i<end; i += step)
+            SET_VECTOR_ELT(result, i, R_NilValue);
+        break;
+    case RAWSXP:
+        for (i = start; i<end; i += step)
+            RAW(result)[i] = (Rbyte) 0;
+        break;
+    default:
+        errorcall(call, _("matrix subscripting not handled for this type"));
+    }
+}
+
+
 static SEXP MatrixSubset(SEXP x, SEXP s, SEXP call, int drop)
 {
     SEXP attr, result, sr, sc, dim;
     int nr, nc, nrs, ncs;
-    int i, j, ii, jj, ij, iijj;
+    int i, j, ii, jj, ij, iijj, jjnr;
 
     nr = nrows(x);
     nc = ncols(x);
@@ -234,79 +280,82 @@
     PROTECT(sc);
     result = allocVector(TYPEOF(x), nrs*ncs);
     PROTECT(result);
+
+    /* Set rows of result to NAs where there are NA row indexes.  Also check 
+       for bad row indexes (once here rather than many times in loop). */
+
     for (i = 0; i < nrs; i++) {
-	ii = INTEGER(sr)[i];
-	if (ii != NA_INTEGER) {
-	    if (ii < 1 || ii > nr)
-		errorcall(call, R_MSG_subs_o_b);
-	    ii--;
+        ii = INTEGER(sr)[i];
+        if (ii == NA_INTEGER) 
+            set_row_or_col_to_na (result, i, nrs, i+nrs*ncs, call);
+        else if (ii < 1 || ii > nr)
+            errorcall(call, R_MSG_subs_o_b);
+    }
+
+    /* Loop to handle extraction except for NAs.  Outer loop is over columns so
+       writes are sequential, which is faster for indexing, and probably better
+       for memory speed. */
+
+    for (j = 0, ij = 0; j < ncs; j++) {
+        jj = INTEGER(sc)[j];
+
+        /* If column index is NA, just set column of result to NAs. */
+
+        if (jj == NA_INTEGER) {
+            set_row_or_col_to_na (result, j*nrs, 1, (j+1)*nrs, call);
+            ij += nrs;
+            continue;
+        }
+
+        /* Check for bad column index. */
+
+         if (jj < 1 || jj > nc)
+	     errorcall(call, R_MSG_subs_o_b);
+
+        /* Loops over row indexes, except skips NA row indexes, done above. */
+
+        jjnr = (jj-1) * nr;
+        switch (TYPEOF(x)) {
+	case LGLSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    LOGICAL(result)[ij] = LOGICAL(x)[(ii-1)+jjnr];
+            break;
+	case INTSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    INTEGER(result)[ij] = INTEGER(x)[(ii-1)+jjnr];
+            break;
+	case REALSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    REAL(result)[ij] = REAL(x)[(ii-1)+jjnr];
+            break;
+	case CPLXSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    COMPLEX(result)[ij] = COMPLEX(x)[(ii-1)+jjnr];
+            break;
+	case STRSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    SET_STRING_ELT(result, ij, STRING_ELT(x, (ii-1)+jjnr));
+            break;
+	case VECSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    SET_VECTOR_ELT(result, ij, VECTOR_ELT(x, (ii-1)+jjnr));
+            break;
+	case RAWSXP:
+            for (i = 0; i < nrs; i++, ij++) 
+                if ((ii = INTEGER(sr)[i]) != NA_INTEGER) 
+		    RAW(result)[ij] = RAW(x)[(ii-1)+jjnr];
+	    break;
+	default:
+	    errorcall(call, _("matrix subscripting not handled for this type"));
 	}
-	for (j = 0; j < ncs; j++) {
-	    jj = INTEGER(sc)[j];
-	    if (jj != NA_INTEGER) {
-		if (jj < 1 || jj > nc)
-		    errorcall(call, R_MSG_subs_o_b);
-		jj--;
-	    }
-	    ij = i + j * nrs;
-	    if (ii == NA_INTEGER || jj == NA_INTEGER) {
-		switch (TYPEOF(x)) {
-		case LGLSXP:
-		case INTSXP:
-		    INTEGER(result)[ij] = NA_INTEGER;
-		    break;
-		case REALSXP:
-		    REAL(result)[ij] = NA_REAL;
-		    break;
-		case CPLXSXP:
-		    COMPLEX(result)[ij].r = NA_REAL;
-		    COMPLEX(result)[ij].i = NA_REAL;
-		    break;
-		case STRSXP:
-		    SET_STRING_ELT(result, ij, NA_STRING);
-		    break;
-		case VECSXP:
-		    SET_VECTOR_ELT(result, ij, R_NilValue);
-		    break;
-		case RAWSXP:
-		    RAW(result)[ij] = (Rbyte) 0;
-		    break;
-		default:
-		    errorcall(call, _("matrix subscripting not handled for this type"));
-		    break;
-		}
-	    }
-	    else {
-		iijj = ii + jj * nr;
-		switch (TYPEOF(x)) {
-		case LGLSXP:
-		    LOGICAL(result)[ij] = LOGICAL(x)[iijj];
-		    break;
-		case INTSXP:
-		    INTEGER(result)[ij] = INTEGER(x)[iijj];
-		    break;
-		case REALSXP:
-		    REAL(result)[ij] = REAL(x)[iijj];
-		    break;
-		case CPLXSXP:
-		    COMPLEX(result)[ij] = COMPLEX(x)[iijj];
-		    break;
-		case STRSXP:
-		    SET_STRING_ELT(result, ij, STRING_ELT(x, iijj));
-		    break;
-		case VECSXP:
-		    SET_VECTOR_ELT(result, ij, VECTOR_ELT(x, iijj));
-		    break;
-		case RAWSXP:
-		    RAW(result)[ij] = RAW(x)[iijj];
-		    break;
-		default:
-		    errorcall(call, _("matrix subscripting not handled for this type"));
-		    break;
-		}
-	    }
-	}
     }
+
     if(nrs >= 0 && ncs >= 0) {
 	PROTECT(attr = allocVector(INTSXP, 2));
 	INTEGER(attr)[0] = nrs;
-------------- next part --------------
Index: src/include/Defn.h
===================================================================
--- src/include/Defn.h	(revision 52822)
+++ src/include/Defn.h	(working copy)
@@ -1003,7 +1003,7 @@
 void KillAllDevices(void);
 SEXP levelsgets(SEXP, SEXP);
 void mainloop(void);
-SEXP makeSubscript(SEXP, SEXP, int *, SEXP);
+SEXP makeSubscript(SEXP, SEXP, int *, SEXP, int);
 SEXP markKnown(const char *, SEXP);
 SEXP mat2indsub(SEXP, SEXP, SEXP);
 SEXP matchArg(SEXP, SEXP*);
Index: src/main/subassign.c
===================================================================
--- src/main/subassign.c	(revision 52822)
+++ src/main/subassign.c	(working copy)
@@ -448,7 +448,7 @@
     }
 
     stretch = 1;
-    PROTECT(indx = makeSubscript(x, s, &stretch, R_NilValue));
+    PROTECT(indx = makeSubscript(x, s, &stretch, R_NilValue, 1));
     n = length(indx);
     if(length(y) > 1)
 	for(i = 0; i < n; i++)
@@ -665,11 +665,11 @@
     default:
 	warningcall(call, "sub assignment (*[*] <- *) not done; __bug?__");
     }
-    /* Check for additional named elements. */
+    /* Check for additional named elements, if subscripting with strings. */
     /* Note makeSubscript passes the additional names back as the use.names
        attribute (a vector list) of the generated subscript vector */
-    newnames = getAttrib(indx, R_UseNamesSymbol);
-    if (newnames != R_NilValue) {
+    if (TYPEOF(s)==STRSXP && 
+          (newnames = getAttrib(indx, R_UseNamesSymbol)) != R_NilValue) {
 	SEXP oldnames = getAttrib(x, R_NamesSymbol);
 	if (oldnames != R_NilValue) {
 	    for (i = 0; i < n; i++) {
@@ -1195,7 +1195,7 @@
 	error(_("invalid number of subscripts to list assign"));
 
     PROTECT(sub = GetOneIndex(sub, ind));
-    PROTECT(indx = makeSubscript(x, sub, &stretch, R_NilValue));
+    PROTECT(indx = makeSubscript(x, sub, &stretch, R_NilValue, 1));
     	
     n = length(indx);
     if (n > 1)
@@ -1243,7 +1243,7 @@
     vmax = vmaxget();
     nx = length(x);
     PROTECT(s = GetOneIndex(s, ind));
-    PROTECT(s = makeSubscript(x, s, &stretch, R_NilValue));
+    PROTECT(s = makeSubscript(x, s, &stretch, R_NilValue, 1));
     ns = length(s);
     indx = (int*)R_alloc(nx, sizeof(int));
     for (i = 0; i < nx; i++)
Index: src/main/subscript.c
===================================================================
--- src/main/subscript.c	(revision 52822)
+++ src/main/subscript.c	(working copy)
@@ -27,7 +27,6 @@
 
  *  makeSubscript()   -- for "[" and "[<-" in ./subset.c and ./subassign.c,
  *			 and "[[<-" with a scalar in ./subassign.c
- *  vectorSubscript() -- for makeSubscript()   {currently unused externally}
  *  arraySubscript()  -- for "[i,j,..." and "[<-..." in ./subset.c, ./subassign.c
  */
 
@@ -411,7 +410,7 @@
     return s;
 }
 
-static SEXP positiveSubscript(SEXP s, int ns, int nx)
+static SEXP nonnegativeSubscript(SEXP s, int ns, int nx)
 {
     SEXP indx;
     int i, zct = 0;
@@ -433,34 +432,53 @@
 static SEXP integerSubscript(SEXP s, int ns, int nx, int *stretch, SEXP call)
 {
     int i, ii, min, max, canstretch;
-    Rboolean isna = FALSE;
+    Rboolean isna;
+
     canstretch = *stretch;
     *stretch = 0;
-    min = 0;
-    max = 0;
+
     for (i = 0; i < ns; i++) {
 	ii = INTEGER(s)[i];
-	if (ii != NA_INTEGER) {
-	    if (ii < min)
+	if (ii != NA_INTEGER) 
+            break;
+    }
+
+    if (i==ns) /* all NA, or ns==0 */
+        return s;
+
+    isna = i>0;
+
+    min = ii;
+    max = ii;
+    for (i = i+1; i < ns; i++) {
+	ii = INTEGER(s)[i];
+	if (ii == NA_INTEGER) 
+            isna = TRUE;
+        else {
+	    if (ii > max)  /* checked first since more common than ii < min */
+		max = ii;
+	    else if (ii < min)
 		min = ii;
-	    if (ii > max)
-		max = ii;
-	} else isna = TRUE;
+        }
     }
+
     if (max > nx) {
 	if(canstretch) *stretch = max;
 	else {
 	    ECALL(call, _("subscript out of bounds"));
 	}
     }
-    if (min < 0) {
-	if (max == 0 && !isna) return negativeSubscript(s, ns, nx, call);
+
+    if (min > 0) /* All positive (or NA) */
+        return s;
+    else if (min < 0) {
+	if (max <= 0 && !isna) return negativeSubscript(s, ns, nx, call);
 	else {
 	    ECALL(call, _("only 0's may be mixed with negative subscripts"));
 	}
     }
-    else return positiveSubscript(s, ns, nx);
-    return R_NilValue;
+    else /* min == 0 */
+        return nonnegativeSubscript(s, ns, nx);
 }
 
 typedef SEXP (*StringEltGetter)(SEXP x, int i);
@@ -482,13 +500,14 @@
 
 static SEXP
 stringSubscript(SEXP s, int ns, int nx, SEXP names,
-		StringEltGetter strg, int *stretch, Rboolean in, SEXP call)
+		StringEltGetter strg, int *stretch, SEXP call)
 {
     SEXP indx, indexnames;
     int i, j, nnames, sub, extra;
     int canstretch = *stretch;
     /* product may overflow, so check factors as well. */
-    Rboolean usehashing = in && ( ((ns > 1000 && nx) || (nx > 1000 && ns)) || (ns * nx > 15*nx + ns) );
+    Rboolean usehashing = 
+      (ns > 1000 && nx) || (nx > 1000 && ns) || (ns * nx > 15*nx + ns);
 
     PROTECT(s);
     PROTECT(names);
@@ -520,9 +539,11 @@
 	    if (names != R_NilValue) {
 		for (j = 0; j < nnames; j++) {
 		    SEXP names_j = strg(names, j);
+#if 0 /* Disabled now that the "in" argument is gone; was always TRUE. */
 		    if (!in && TYPEOF(names_j) != CHARSXP) {
 			ECALL(call, _("character vector element does not have type CHARSXP"));
 		    }
+#endif
 		    if (NonNullStringMatch(STRING_ELT(s, i), names_j)) {
 			sub = j + 1;
 			SET_VECTOR_ELT(indexnames, i, R_NilValue);
@@ -577,7 +598,7 @@
 
 static SEXP
 int_arraySubscript(int dim, SEXP s, SEXP dims, AttrGetter dng,
-		   StringEltGetter strg, SEXP x, Rboolean in, SEXP call)
+                   StringEltGetter strg, SEXP x, SEXP call)
 {
     int nd, ns, stretch = 0;
     SEXP dnames, tmp;
@@ -602,7 +623,7 @@
 	    ECALL(call, _("no 'dimnames' attribute for array"));
 	}
 	dnames = VECTOR_ELT(dnames, dim);
-	return stringSubscript(s, ns, nd, dnames, strg, &stretch, in, call);
+	return stringSubscript(s, ns, nd, dnames, strg, &stretch, call);
     case SYMSXP:
 	if (s == R_MissingArg)
 	    return nullSubscript(nd);
@@ -622,61 +643,75 @@
 arraySubscript(int dim, SEXP s, SEXP dims, AttrGetter dng,
 	       StringEltGetter strg, SEXP x)
 {
-    return int_arraySubscript(dim, s, dims, dng, strg, x, TRUE, R_NilValue);
+    return int_arraySubscript(dim, s, dims, dng, strg, x, R_NilValue);
 }
 
-/* Subscript creation.  The first thing we do is check to see */
-/* if there are any user supplied NULL's, these result in */
-/* returning a vector of length 0. */
-/* if stretch is zero on entry then the vector x cannot be
-   "stretched",
-   otherwise, stretch returns the new required length for x
+/* Subscript creation.  
+   x is the object being subscripted; s is the R subscript value.
+   If stretch is zero on entry then the vector x cannot be "stretched",
+   otherwise, stretch returns the new required length for x.
+   The used_to_replace arguement is 1 if the subscript is used to replace 
+   items (hence subscript may need to be duplicated in case it itself 
+   would be modified), and 0 if the subscript is only for extracting items.
 */
 
-SEXP attribute_hidden makeSubscript(SEXP x, SEXP s, int *stretch, SEXP call)
+SEXP attribute_hidden makeSubscript(SEXP x, SEXP s, int *stretch, SEXP call, 
+                                    int used_to_replace)
 {
-    int nx;
-    SEXP ans;
+    int nx, ns;
+    SEXP ans, tmp;
 
-    ans = R_NilValue;
-    if (isVector(x) || isList(x) || isLanguage(x)) {
-	nx = length(x);
-
-	ans = vectorSubscript(nx, s, stretch, getAttrib, (STRING_ELT),
-			      x, call);
-    }
-    else {
+    if (!isVector(x) && !isList(x) && !isLanguage(x)) {
 	ECALL(call, _("subscripting on non-vector"));
+        return R_NilValue;
     }
-    return ans;
 
-}
+    nx = length(x);
+    ns = length(s);
 
-/* nx is the length of the object being subscripted,
-   s is the R subscript value,
-   dng gets a given attrib for x, which is the object we are
-   subsetting,
-*/
+#if 0 /* In r52822, checked for no attributes of s, but only potential */
+      /* problem seems to be an R_UseNamesSymbol attribute, which can  */
+      /* be ignored if the subscripts aren't strings.                  */
+    /* special case for simple indices -- does not duplicate */
+    if (ns == 1 && ATTRIB(s) == R_NilValue) 
+#else
+    /* Handle single positive index (real or integer), not out of bounds.  */
+    /* Note that we don't have to worry about a length one subscript being */
+    /* modified in a replace operation, since even if it is,  we don't use */
+    /* it anymore after the modification.                                  */
+    if (ns == 1) 
+#endif
+        if (TYPEOF(s) == INTSXP) {
+            int i = INTEGER(s)[0];
+            if (0 < i && i <= nx) {
+                *stretch = 0;
+                return s;
+            }
+	} else if (TYPEOF(s) == REALSXP) {
+            int i, warn = 0;
+            i = IntegerFromReal (REAL(s)[0], &warn);
+            if (0 < i && i <= nx) {
+                if (warn) CoercionWarning(warn);
+                *stretch = 0;
+                return ScalarInteger(i);
+            }
+        }
 
-static SEXP
-int_vectorSubscript(int nx, SEXP s, int *stretch, AttrGetter dng,
-		    StringEltGetter strg, SEXP x, Rboolean in, SEXP call)
-{
-    int ns;
-    SEXP ans = R_NilValue, tmp;
-
-    ns = length(s);
-    /* special case for simple indices -- does not duplicate */
-    if (ns == 1 && TYPEOF(s) == INTSXP && ATTRIB(s) == R_NilValue) {
-	int i = INTEGER(s)[0];
-	if (0 < i && i <= nx) {
-	    *stretch = 0;
-	    return s;
-	}
-    }
+#if 0 /* Duplicated in r52822, but seems unnecessary as long as callers ignore
+         any R_UseNamesSymbol attribute when not subscripting with strings,
+         and the subscript will not be modified in a replacement operation
+         that it is supplying the subscripts for. */
     PROTECT(s = duplicate(s));
     SET_ATTRIB(s, R_NilValue);
     SET_OBJECT(s, 0);
+#else
+    /* Duplicate if the subscript might be being used to replace elements of
+       itself. */
+    if (used_to_replace && NAMED(s) > 0) 
+        s = duplicate(s);
+    PROTECT(s);
+#endif
+
     switch (TYPEOF(s)) {
     case NILSXP:
 	*stretch = 0;
@@ -696,9 +731,9 @@
 	break;
     case STRSXP:
     {
-	SEXP names = dng(x, R_NamesSymbol);
+	SEXP names = getAttrib(x, R_NamesSymbol);
 	/* *stretch = 0; */
-	ans = stringSubscript(s, ns, nx, names, strg, stretch, in, call);
+	ans = stringSubscript(s, ns, nx, names, (STRING_ELT), stretch, call);
     }
     break;
     case SYMSXP:
@@ -717,11 +752,3 @@
     UNPROTECT(1);
     return ans;
 }
-
-
-SEXP attribute_hidden
-vectorSubscript(int nx, SEXP s, int *stretch, AttrGetter dng,
-		StringEltGetter strg, SEXP x, SEXP call)
-{
-    return int_vectorSubscript(nx, s, stretch, dng, strg, x, TRUE, call);
-}
Index: src/main/subset.c
===================================================================
--- src/main/subset.c	(revision 52822)
+++ src/main/subset.c	(working copy)
@@ -161,7 +161,7 @@
     /* Convert to a vector of integer subscripts */
     /* in the range 1:length(x). */
 
-    PROTECT(indx = makeSubscript(x, s, &stretch, call));
+    PROTECT(indx = makeSubscript(x, s, &stretch, call, 0));
     n = LENGTH(indx);
 
     /* Allocate the result. */

From phgrosjean at sciviews.org  Wed Sep  8 11:15:30 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 08 Sep 2010 11:15:30 +0200
Subject: [Rd] Is an R sub-session somehow possible?
In-Reply-To: <1283898444715-2530527.post@n4.nabble.com>
References: <1283882802031-2530174.post@n4.nabble.com>	<8E175E90-C40F-4D62-857E-F8C4231862B5@r-project.org>	<1283885014288-2530233.post@n4.nabble.com>	<DB68F427-6A41-48B5-9C88-6B6B7DB72A2E@r-project.org>
	<1283898444715-2530527.post@n4.nabble.com>
Message-ID: <4C875432.8090706@sciviews.org>

Hello,

Di you already look at svSocket (try the version on R-forge that 
corrects a couple of bugs recently -will be soon on CRAN, but only after 
further testing-)? It uses Tcl that already benefits from the modified 
even loop you mention, and it is well-tested since a long time since the 
tcltk package is a recommended R package and is widely used.

With svSocket, you can easily do something like calltip, or completion 
list calculation while R is processing other commands, say at the 
command line, or through other calls to svSocket: it manages multiple 
clients simultaneously (or multiple connections from the same client, 
say, one for evaluation of R code, and another one to get calltip or 
completion list calculation, no matter if R is doing other calculations 
or not). If you want to get inspiration, you can inspect how SciViews-K 
is implemented (http://www.sciviews.org/SciViews-K).
Best,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 08/09/10 00:27, ghostwheel wrote:
>
>
> Simon Urbanek wrote:
>>
>>
>>
>> It doesn't really matter where the R is as long as you have some way of
>> getting at the results. You are still leaving us in the dark as of what
>> exactly you do (technically) so there is not much detail we can provide...
>>
>>
>
> Sorry, I'll try to provide more detail:
>
> I am trying to provide a good connection between the TeXmacs editor and R.
> (A really nice overview of such connections can be found in
> http://www.r-project.org/conferences/useR-2004/abstracts/supplements/Urbanek.pdf
> ;)
> What I do is fake a terminal, and interact with the command line interface
> to R (something like what the program 'expect' does). To detect that R is
> waiting for input I have to check various properties of the terminal. Not
> really pretty.
> What happens is that:
> 1. TeXmacs sends me a string to execute.
> 2. I pass it to R, and wait for a prompt.
> 3. I pass all of R's return, somewhat processed back to TeXmacs. Thus, when
> I want to put a graphics inside TeXmacs' buffer, I have to print something
> like 'start postscipt graphics', then the postscript file, then 'end
> postscript'.
>
> When the user asks for tab completion, TeXmacs sends me a special message
> saying that this string needs to be completed. I call a function in R, and
> return the result.
>
> My program is able to interact with a remote R session, i.e. the session
> will start on a different machine than the one TeXmacs runs on. Luckily, it
> is also possible to detect when R waits for a prompt in a remote session by
> doing these ugly terminal hacks.
>
> In some cases the R prompt won't be a prompt for another command, but
> instead, R is just waiting for user input, or for completion of the previous
> input.
>
> Now, my remaining question is this:
> When I run R remotely, by emulating a terminal, and interacting with R in
> command line mode, AND
> when at the same time R is not waiting for a command, but instead for some
> other kind of user interaction, my interface can't send to R a request to
> execute the code to complete a certain string.
> (I.e. call the function t.tab.complete that I attached below).
>
> If I understand correctly, one solution is to write a replacement input
> loop, so that R will call my ReadConsole() from time to time, and while I'm
> inside that function, I could call R functions to provide tab completion.
>
> In that case, for remote sessions, I would have to compile on the remote
> computer this alternative R input loop, and I would have to have one for
> every version of R that a user might want to run on the remote machine (the
> machine I am currently working with remotely has 11 versions of R
> installed...). I was wondering if there is still a way to avoid that, and
> interact with the regular input loop, or maybe it is possible to load an
> alternative input loop from a package/library inside an already running
> regular R interface?
> I would like the user to have to do as little as possible in terms of
> installing additional programs on a remote machine.
>
> Thanks,
> I'm not sure if this was the type of additional information you meant...
> Michael
>
> Here is my tab completion routine, ("\2" and "\5" are the codes for TeXmacs
> for a start and a stop of blocks. (basically like brackets) ).
> -----
> t.tab.comp<-function(s,curs)
>    {
>      rc.settings(help=F) #This is because of a bug in matchAvailableTopics in
> package utils
>      rc.settings(file=T)
>
>      utils:::.assignLinebuffer(substr(s,1,curs))
>      utils:::.assignEnd(nchar(s))
>      utils:::.guessTokenFromLine()
>      utils:::.completeToken()
>      l=utils:::.retrieveCompletions()
>      l=sapply(l,function(x) {
>        substr(x, nchar(utils:::.CompletionEnv[["token"]])+1,nchar(x) )
>      } )
>      i=grep("=$",l)
>      if( (length(l[-i])>  10)&  (length(i)>0 ) )
>      l=c(l[i])
>      s3=utils:::.CompletionEnv[["token"]]
>      s3=gsub("\"","\\\\\"",s3)
>      deb.l<<- l
>
>      cat("\2scheme:(tuple \"",s3,"\"",sep="") ;
>      cat(" \"")
>      if( length(l)>  0 )
>      {
>        cat(l,sep="\" \"")
>      }
>      else
>      {
>        #cat(s)
>        cat("\"\"")
>      }
>      cat("\"")
>      cat(")\5")
>
>    ----
>


From rafael.laboissiere at inserm.fr  Wed Sep  8 14:52:51 2010
From: rafael.laboissiere at inserm.fr (Rafael Laboissiere)
Date: Wed, 8 Sep 2010 14:52:51 +0200
Subject: [Rd] readline operate-and-get-next
In-Reply-To: <20100814185531.GD4982@pc049-u864.lyon.inserm.fr>
References: <20100807110740.GB13899@pc049-u864.lyon.inserm.fr>
	<20100808185529.GC2603@pc049-u864.lyon.inserm.fr>
	<alpine.LFD.2.00.1008121122340.12173@gannet.stats.ox.ac.uk>
	<20100812182449.GB4587@pc049-u864.lyon.inserm.fr>
	<20100814185531.GD4982@pc049-u864.lyon.inserm.fr>
Message-ID: <20100908125251.GB10793@pc049-u864.lyon.inserm.fr>

Dear Prof Ripley,

* Rafael Laboissiere <rafael.laboissiere at inserm.fr> [2010-08-14 20:55]:

> * Rafael Laboissiere <rafael.laboissiere at inserm.fr> [2010-08-12 20:24]:
> 
> I did not hear from you but I went ahead and prepared a patch according
> to your recommendations, attached below.  I hope that the copyright and
> licensing issues are correctly sorted out now.
> 
> [snip]

Have you had a chance to review the operate-and-get-next patch that I
posted to r-devel last month?

Best regards,

Rafael Laboissi?re


From mjhubisz at cornell.edu  Wed Sep  8 16:11:03 2010
From: mjhubisz at cornell.edu (Melissa Jane Hubisz)
Date: Wed, 8 Sep 2010 10:11:03 -0400
Subject: [Rd] winbuilder warnings and errors
Message-ID: <AANLkTinPKcL+3aJBnJ_RS-5naymeUUSV-HVV-c_OF3wV@mail.gmail.com>

Hello,
I have been developing a package for phylogenetic analysis which I
plan to submit to CRAN soon.  It passes R CMD check with no warnings
on my linux and Mac OS X machines.  I don't have much experience with
Windows and have been using the win-builder service to see how the
package compiles on Windows.  (Thank you for this service, Uwe, it is
a huge time saver for me!)

I have tried win-builder's R-release 32-bit and R-release 64-bit
versions, and both return with different warnings/errors which I don't
understand.  However both do produce binaries which seem to work.  For
the 64-bit, the check goes fine until it gets to the vignettes, and
then I get the message:

* checking package vignettes in 'inst/doc' ... WARNING
*** Weave Errors ***
File d:/RCompile/CRANguest/R64-release/rphast.Rcheck/inst/doc/vignette2.Rnw :
unable to start device PostScript
* checking PDF version of manual ... OK


I'm not sure if I should be concerned about this or not.  I'm more
troubled by the results of the 32-bit check, which produces an error.
The log ends like this:

* checking examples ... OK
* checking tests ... ERROR
Check process probably crashed or hung up for 20 minutes ... killed
Most likely this happened in the example checks (?),
if not, ignore the following last lines of example output:
<< here I snipped a bunch of example output that looks fine>>
>
> ### * <FOOTER>
> ###
> cat("Time elapsed: ", proc.time() - get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  13.23 0.2 13.46 NA NA
> grDevices::dev.off()
null device
          1
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
======== End of example output (where/before crash/hang up occured ?) ========

So here are my questions:
Does anyone have an idea what could cause the error above, or how I
can troubleshoot it?  I do have remote access to a windows machine and
have installed the 32-bit binary, and all the testing code runs
smoothly.  Do I need to resolve these issues in order to submit my
package to CRAN?  I definitely want Windows binaries of my package to
be available.

Thanks for any advice,
Melissa


Melissa  Hubisz
Siepel Lab
Department of Biological Statistics and Computational Biology
Cornell University


From spluque at gmail.com  Wed Sep  8 17:36:55 2010
From: spluque at gmail.com (Seb)
Date: Wed, 08 Sep 2010 10:36:55 -0500
Subject: [Rd] How to add a slot to S4 class of an existing package?
References: <494FECF9.2020301@aon.at> <495954FE.6070401@ebi.ac.uk>
	<878w3df7hx.fsf@kolob.sebmags.homelinux.org>
	<AANLkTikJ336mVCnvAD3k-COMffzz_Bc0aJkRAPPyRhni@mail.gmail.com>
Message-ID: <87occ8dz6w.fsf@kolob.sebmags.homelinux.org>

On Tue, 7 Sep 2010 20:41:14 -0400,
Kasper Daniel Hansen <kasperdanielhansen at gmail.com> wrote:

> Seb That thread and the resources in Biobase assumes that you have a
> class that extends "Versioned".  Doing so will help you in the long
> run by providing you with updateObject (at the cost of some
> complexity).  However, it does not really help you if the existing
> class does not extend Versioned.

Thanks Kasper, indeed the class I'm working with doesn't have anything
to do with Biobase, and having it extend "Versioned" along with the
package dependencies only for this purpose seems overkill in my case.
But perhaps one can implement a similar approach internally in the
package without having to add a new dependency.


> In general, adding a new slot should not break any existing code, but
> you may find users who have old objects lying around that they cannot
> use with the new functionality (I assume you are adding slots to
> provide new functionality).

Yes, the new slot adds new functionality and I also thought that adding
a slot should not affect existing code.  However, an error message
during 'R CMD check' came up to the effect that an object did not have
the new slot.  Unfortunately, I didn't save more details nor
investigated this error any further, but it got me doubting whether
adding the slot would break existing code and access to objects of the
older class.  The object is under data/, although now I'm considering
removing it and creating it in an example, which might be cleaner.


-- 
Seb


From jeffrey.horner at gmail.com  Wed Sep  8 19:21:27 2010
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Wed, 8 Sep 2010 12:21:27 -0500
Subject: [Rd] Development environment for R extentions on Windows
Message-ID: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>

Hi all,

I'm setting up a development environment on Windows as the subject
implies. I've downloaded and installed Rtools211.exe (will upgrade
later when necessary) and I've also downloaded and installed mingw
with the help of mingw-get.exe.

I come from a UNIX development background, so I'm at the bash shell
prompt for just about every step in R extenstion development. Question
is what is an appropriate environment for Windows development. What
shell do you use? Do you use cmd.exe with the PATH variable set up by
Rtools? Do you use the sh.exe that comes with Rtools? I've found the
bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
Do you use something else?

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From murdoch.duncan at gmail.com  Wed Sep  8 19:37:35 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Sep 2010 13:37:35 -0400
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
Message-ID: <4C87C9DF.4030208@gmail.com>

  On 08/09/2010 1:21 PM, Jeffrey Horner wrote:
> Hi all,
>
> I'm setting up a development environment on Windows as the subject
> implies. I've downloaded and installed Rtools211.exe (will upgrade
> later when necessary) and I've also downloaded and installed mingw
> with the help of mingw-get.exe.
>
> I come from a UNIX development background, so I'm at the bash shell
> prompt for just about every step in R extenstion development. Question
> is what is an appropriate environment for Windows development. What
> shell do you use? Do you use cmd.exe with the PATH variable set up by
> Rtools? Do you use the sh.exe that comes with Rtools? I've found the
> bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
> Do you use something else?
>

I've used the bash shell in Cygwin for quite a few years, but I've been 
planning a switch to MSYS sometime.  Cygwin seems to have made some bad 
decisions lately that make it harder and harder to work with.

Duncan Murdoch


From jeffrey.horner at gmail.com  Wed Sep  8 20:01:38 2010
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Wed, 8 Sep 2010 13:01:38 -0500
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <4C87C9DF.4030208@gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
	<4C87C9DF.4030208@gmail.com>
Message-ID: <AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>

On Wed, Sep 8, 2010 at 12:37 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> ?On 08/09/2010 1:21 PM, Jeffrey Horner wrote:
>>
>> Hi all,
>>
>> I'm setting up a development environment on Windows as the subject
>> implies. I've downloaded and installed Rtools211.exe (will upgrade
>> later when necessary) and I've also downloaded and installed mingw
>> with the help of mingw-get.exe.
>>
>> I come from a UNIX development background, so I'm at the bash shell
>> prompt for just about every step in R extenstion development. Question
>> is what is an appropriate environment for Windows development. What
>> shell do you use? Do you use cmd.exe with the PATH variable set up by
>> Rtools? Do you use the sh.exe that comes with Rtools? I've found the
>> bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
>> Do you use something else?
>>
>
> I've used the bash shell in Cygwin for quite a few years, but I've been
> planning a switch to MSYS sometime. ?Cygwin seems to have made some bad
> decisions lately that make it harder and harder to work with.

This is great news! I don't know how I could survive without bash's vi
style editing and command completion...

Here's my PATH variable which sets the Rtools paths first, then MinGW:

hornerj at hornerj-win ~
$ echo $PATH
/c/Rtools/bin:/c/Rtools/perl/bin:/c/Rtools/MinGW/bin:/c/localbin:/mingw/bin:/bin:/usr/bin:/usr/lo
cal/bin:/c/Program Files (x86)/R/R-2.11.1/bin:/c/Program Files
(x86)/CollabNet/Subversion Client:
/c/Windows/system32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.
0/:/c/Program Files (x86)/MiKTeX 2.8/miktex/bin

I'm going to follow the "R Installation ..." manual to compile R on
Windows and learn a bit about the build process. From there, I intend
to "port" some open source libraries that have support for being
compiled with MS VC++ over to MinGW.

Aside from my PATH variable, are there other things about my
development environment I should be aware of?

Jeff


From edd at debian.org  Wed Sep  8 20:27:31 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 8 Sep 2010 13:27:31 -0500
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
	<4C87C9DF.4030208@gmail.com>
	<AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
Message-ID: <19591.54675.282528.393659@max.nulle.part>


On 8 September 2010 at 13:01, Jeffrey Horner wrote:
| This is great news! I don't know how I could survive without bash's vi
| style editing and command completion...
| 
| Here's my PATH variable which sets the Rtools paths first, then MinGW:
| 
| hornerj at hornerj-win ~
| $ echo $PATH
| /c/Rtools/bin:/c/Rtools/perl/bin:/c/Rtools/MinGW/bin:/c/localbin:/mingw/bin:/bin:/usr/bin:/usr/lo
| cal/bin:/c/Program Files (x86)/R/R-2.11.1/bin:/c/Program Files
| (x86)/CollabNet/Subversion Client:
| /c/Windows/system32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.
| 0/:/c/Program Files (x86)/MiKTeX 2.8/miktex/bin
| 
| I'm going to follow the "R Installation ..." manual to compile R on
| Windows and learn a bit about the build process. From there, I intend
| to "port" some open source libraries that have support for being
| compiled with MS VC++ over to MinGW.
| 
| Aside from my PATH variable, are there other things about my
| development environment I should be aware of?

FWIW I always add rxvt (taken from Cygwin's repos) so that I can launch an
'xterm' alike from the usual shortcut by having this as the command in 
Cygwin.bat:

  rxvt -sr -sl 2500 -sb -geometry 90x30 -fg wheat -bg gray10 -tn rxvt \
     -fn 'Lucida Console-14' -e /usr/bin/bash --login -i

The last time I set that up I left myself a note that I got hints from 

  http://blasphemousbits.wordpress.com/2007/02/12/rxvt-solves-many-cygwin-woes/

and

  also see http://www.saltycrane.com/blog/tag/cygwin/

Those links may by now be stale.

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From arnima at hafro.is  Wed Sep  8 20:54:41 2010
From: arnima at hafro.is (Arni Magnusson)
Date: Wed, 8 Sep 2010 18:54:41 +0000 (GMT)
Subject: [Rd] Drop single-dimensional array
In-Reply-To: <FE59E6D8-F3DC-48D8-9706-4DF08147027F@r-project.org>
References: <alpine.LFD.2.00.1009061211090.1206@hafstormur.hafro.is>
	<FE59E6D8-F3DC-48D8-9706-4DF08147027F@r-project.org>
Message-ID: <alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>

Hi Simon, thank you for the concise reply.

Do you mean the reported behavior of drop() is not a bug?

It looks like a borderline bug to me (see below), but I'm not the judge of 
that. If this is the intended behavior and serves an actual purpose, then 
that could be explicitly documented in a \note{} on the help page.

Such a note would slightly reduce the surprise of users running into this 
behavior.

This is related to the oddity that one-dimensional arrays are:

   array(month.abb, dim=c(1,1,12))  # array
   array(month.abb, dim=c(1,12))    # matrix
   array(month.abb, dim=12)         # array

Firstly, one would expect the pattern to be array-matrix-vector. Secondly, 
it's easy to drop() the three-dimensional and two-dimensional objects, but 
drop() does nothing to the one-dimensional array. Instead, it takes an 
unintuitive combination of methods to convert a single-dimensional to a 
vector, while retaining its names. Or I may well be missing something 
obvious.

Best regards,

Arni



On Wed, 8 Sep 2010, Simon Urbanek wrote:

> wrong address - did you mean R-devel?
> Simon
>
>
>
> On Sep 6, 2010, at 8:35 AM, Arni Magnusson wrote:
>
>> Bug or not, I was surprised by this behavior:
>>
>>  x <- tapply(chickwts$weight, chickwts$feed, median)
>>  x  # array ... I'd like to convert to vector with named elements
>>  drop(x)             # what, still an array?
>>  drop(as.matrix(x))  # this works
>>  drop(t(x))          # this works
>>
>> I was expecting drop(x) to return a vector, and I suspect many R users 
>> would too. The title in help(drop), "Drop Redundant Extent 
>> Information", suggests that such a simple array would be converted to a 
>> vector.
>>
>> Reading through the help page, I note that this is perhaps not a clear 
>> bug, but somewhat unclear behavior.
>>
>> The most compact way to break the vector out of its eggshell seems to 
>> be
>>
>>  t(x)[,]
>>
>> but drop(x) would be much easier to read and write. There's nothing 
>> particularly matrix about x, so it's not obvious that the conversion 
>> should involve as.matrix(x).
>>
>> Thanks,
>>
>> Arni
>


From murdoch.duncan at gmail.com  Wed Sep  8 21:57:25 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Sep 2010 15:57:25 -0400
Subject: [Rd] CMD check: checking data for non-ASCII characters is very
 time consuming
In-Reply-To: <AANLkTi=Mk=Z0ikVbTLX5LO+V5bJFuXSmC2y28YGS=66S@mail.gmail.com>
References: <AANLkTi=Mk=Z0ikVbTLX5LO+V5bJFuXSmC2y28YGS=66S@mail.gmail.com>
Message-ID: <4C87EAA5.5030909@gmail.com>

  On 02/09/2010 6:27 AM, Vincent Carey wrote:
> Checking data for non-ASCII characters takes a very long time for
> packages with substantial data components.
> Could the check be done manually by the developer, and a switch
> introduced to optionally skip this during check?
>

I'll add an environment variable to skip this check.  For the full list 
of check configuration variables, see the Tools section of the R 
Internals manual.

Duncan Murdoch


From pgilbert at bank-banque-canada.ca  Wed Sep  8 22:02:12 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 8 Sep 2010 16:02:12 -0400
Subject: [Rd] winbuilder warnings and errors
In-Reply-To: <AANLkTinPKcL+3aJBnJ_RS-5naymeUUSV-HVV-c_OF3wV@mail.gmail.com>
References: <AANLkTinPKcL+3aJBnJ_RS-5naymeUUSV-HVV-c_OF3wV@mail.gmail.com>
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A02D5A49A@EXMAIL2.bocad.bank-banque-canada.ca>

Possibly you are using x11() or postscript() to open a graphics device?
You need to use something generic like dev.new() or nothing (a device
will open automatically). I would check that first, though it does not
really explain the second problem.

Paul

>-----Original Message-----
>From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>project.org] On Behalf Of Melissa Jane Hubisz
>Sent: September 8, 2010 10:11 AM
>To: r-devel at r-project.org
>Subject: [Rd] winbuilder warnings and errors
>
>Hello,
>I have been developing a package for phylogenetic analysis which I
>plan to submit to CRAN soon.  It passes R CMD check with no warnings
>on my linux and Mac OS X machines.  I don't have much experience with
>Windows and have been using the win-builder service to see how the
>package compiles on Windows.  (Thank you for this service, Uwe, it is
>a huge time saver for me!)
>
>I have tried win-builder's R-release 32-bit and R-release 64-bit
>versions, and both return with different warnings/errors which I don't
>understand.  However both do produce binaries which seem to work.  For
>the 64-bit, the check goes fine until it gets to the vignettes, and
>then I get the message:
>
>* checking package vignettes in 'inst/doc' ... WARNING
>*** Weave Errors ***
>File d:/RCompile/CRANguest/R64-
>release/rphast.Rcheck/inst/doc/vignette2.Rnw :
>unable to start device PostScript
>* checking PDF version of manual ... OK
>
>
>I'm not sure if I should be concerned about this or not.  I'm more
>troubled by the results of the 32-bit check, which produces an error.
>The log ends like this:
>
>* checking examples ... OK
>* checking tests ... ERROR
>Check process probably crashed or hung up for 20 minutes ... killed
>Most likely this happened in the example checks (?),
>if not, ignore the following last lines of example output:
><< here I snipped a bunch of example output that looks fine>>
>>
>> ### * <FOOTER>
>> ###
>> cat("Time elapsed: ", proc.time() - get("ptime", pos =
>'CheckExEnv'),"\n")
>Time elapsed:  13.23 0.2 13.46 NA NA
>> grDevices::dev.off()
>null device
>          1
>> ###
>> ### Local variables: ***
>> ### mode: outline-minor ***
>> ### outline-regexp: "\\(> \\)?### [*]+" ***
>> ### End: ***
>> quit('no')
>======== End of example output (where/before crash/hang up occured ?)
>========
>
>So here are my questions:
>Does anyone have an idea what could cause the error above, or how I
>can troubleshoot it?  I do have remote access to a windows machine and
>have installed the 32-bit binary, and all the testing code runs
>smoothly.  Do I need to resolve these issues in order to submit my
>package to CRAN?  I definitely want Windows binaries of my package to
>be available.
>
>Thanks for any advice,
>Melissa
>
>
>Melissa  Hubisz
>Siepel Lab
>Department of Biological Statistics and Computational Biology
>Cornell University
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From p.murrell at auckland.ac.nz  Wed Sep  8 22:42:07 2010
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 09 Sep 2010 08:42:07 +1200
Subject: [Rd] [R] large files produced from image plots?
In-Reply-To: <AANLkTinNQKhxcDvrMa23-FYmfUR_m-u8WDi4_zh2KQ68@mail.gmail.com>
References: <SNT131-w28F3D126917CB8C87B2DAABB720@phx.gbl>	<2277A910-3029-4080-BF1E-BBD4F3C1CC6E@gmail.com>	<SNT131-w112E008F02638748589BD9BB720@phx.gbl>
	<AANLkTinNQKhxcDvrMa23-FYmfUR_m-u8WDi4_zh2KQ68@mail.gmail.com>
Message-ID: <4C87F51F.90207@auckland.ac.nz>

Hi

[shifted this to r-devel]

I can't reproduce this yet on my systems, but I have heard of at least 
one other example of a raster-related crash (on a 64-bit system I think).

Baptiste: I would love to see that broken PDF if you still have it.

Paul

On 9/09/2010 8:00 a.m., baptiste auguie wrote:
> Hi,
>
> I get the same crash with x11() with sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> However it works fine with quartz(). Have you tried other devices?
> pdf() doesn't crash R for me, but the output is incorrect. png() is OK
> but defeats the purpose here.
>
> rasterImage is quite a recent addition, it would probably be
> appreciated to report any such odd behavior to R-devel. Interestingly
> (or not), the x11() test does not crash for me using grid.raster
> instead of rasterImage.
>
> Best,
>
> baptiste
>
>
>
>
>
>
>
> On 8 September 2010 21:47, Stephen T.<obsessively at hotmail.com>  wrote:
>> Hi Baptiste,
>> Thanks for your suggestion. I have to look into this further, but anything I
>> try with rasterImage() gives me this type of error (below is from running
>> the example in the help file). This is with R 2.11.1 on OS X 10.5 -
>>   *** caught bus error ***
>> address 0x24, cause 'non-existent physical address'
>> Traceback:
>>   1: rasterImage(image, 100, 300, 150, 350, interpolate = FALSE)
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> This is not an obvious error, is it?
>> Thanks,
>> Stephen
>>> Subject: Re: [R] large files produced from image plots?
>>> From: baptiste.auguie at googlemail.com
>>> Date: Wed, 8 Sep 2010 19:41:46 +0200
>>> CC: r-help at r-project.org
>>> To: obsessively at hotmail.com
>>>
>>> Hi,
>>>
>>> Have you tried the recent rasterImage() function?
>>>
>>> HTH,
>>>
>>> baptiste
>>>
>>> On Sep 8, 2010, at 7:30 PM, Stephen T. wrote:
>>>
>>>>
>>>> Hi list,
>>>> I wonder if anyone has thoughts on making image plots in R [using
>>>> image() or image.plot(), or filled.contour()]- I've made quite a bit now,
>>>> but they seem quite large in size when exported to pdf file format (even
>>>> after compressing with pdftk or ghostscript, which I regularly do). I know
>>>> that for "images", raster graphics output (png, tiff) may be the way to go,
>>>> but often the ones I make are multi-panel plots with other graphics on them,
>>>> and are usually included in a LaTeX document (PDFLaTeX does accept png) and
>>>> require stretching/shrinking (and/or possibly editing with Adobe
>>>> Illustrator). I have had some luck exporting image plots from Matlab (to
>>>> postscript or pdf) before in the sense that the files seem smaller and less
>>>> pixelated. Is this a difference in the way image() plots are produced, or
>>>> with the way the image is written to the pdf() device (if anyone is familiar
>>>> with other image-exporting programs...)? The other day I had a 13MB dataset,
>>>> and probably plotted 3/4 of it!
>>>> using image() and the compressed pdf output was about 8 MB (it contained
>>>> other stuff but was an addition of a few KB). I tried filled.contour(), as I
>>>> understand that it colors polygons to fill contours instead of coloring
>>>> rectangles at each pixel - and it has saved me before - but this time the
>>>> contours may have been too sharp as as its compressed pdf came out to be 62
>>>> MB... (ouch!). I have not tested this data set with other software programs
>>>> so it may just have been a difficult data set.
>>>> Is there a good solution to this (or is it simply not to use a
>>>> vector-graphics format in these instances), and just for my curiosity, are
>>>> you aware of any things that other software (data analysis) programs do uder
>>>> the hood to make their exported images smaller/smoother?
>>>> Thanks much!
>>>> Stephen
>>>> [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From pdalgd at gmail.com  Wed Sep  8 22:51:40 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 08 Sep 2010 22:51:40 +0200
Subject: [Rd] Drop single-dimensional array
In-Reply-To: <alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>
References: <alpine.LFD.2.00.1009061211090.1206@hafstormur.hafro.is>	<FE59E6D8-F3DC-48D8-9706-4DF08147027F@r-project.org>
	<alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>
Message-ID: <4C87F75C.7090209@gmail.com>

On 09/08/2010 08:54 PM, Arni Magnusson wrote:
> Hi Simon, thank you for the concise reply.
> 
> Do you mean the reported behavior of drop() is not a bug?
> 
> It looks like a borderline bug to me (see below), but I'm not the judge of 
> that. If this is the intended behavior and serves an actual purpose, then 
> that could be explicitly documented in a \note{} on the help page.
> 
> Such a note would slightly reduce the surprise of users running into this 
> behavior.
> 
> This is related to the oddity that one-dimensional arrays are:
> 
>    array(month.abb, dim=c(1,1,12))  # array
>    array(month.abb, dim=c(1,12))    # matrix
>    array(month.abb, dim=12)         # array
> 
> Firstly, one would expect the pattern to be array-matrix-vector. Secondly, 
> it's easy to drop() the three-dimensional and two-dimensional objects, but 
> drop() does nothing to the one-dimensional array. Instead, it takes an 
> unintuitive combination of methods to convert a single-dimensional to a 
> vector, while retaining its names. Or I may well be missing something 
> obvious.

Well, you're missing c(x), but you may still have a point...

1d arrays was something of an afterthought, introduced for the ability
to have named dimnames. Had this been thought of when S was designed,
then maybe vectors and 1d arrays had been the same, but when it
happened, it was not an option to modify the basic vector structures.

drop() is documented to drop extents of length one, of which there are
none in the 1d-array case, and so it is taken as a no-op. A slightly
different design would be to drop in a strict array sense, i.e.
dim=c(1,1,12) would drop to dim=12, not to a vector of length 12, and
THEN if the result is 1d, convert to vector (this could even be made
optional, with some reason).

I don't think it's at the top of anyone's agenda, though. Meanwhile,
c(x) should get you there soon enough.

-pd


> 
> Best regards,
> 
> Arni
> 
> 
> 
> On Wed, 8 Sep 2010, Simon Urbanek wrote:
> 
>> wrong address - did you mean R-devel?
>> Simon
>>
>>
>>
>> On Sep 6, 2010, at 8:35 AM, Arni Magnusson wrote:
>>
>>> Bug or not, I was surprised by this behavior:
>>>
>>>  x <- tapply(chickwts$weight, chickwts$feed, median)
>>>  x  # array ... I'd like to convert to vector with named elements
>>>  drop(x)             # what, still an array?
>>>  drop(as.matrix(x))  # this works
>>>  drop(t(x))          # this works
>>>
>>> I was expecting drop(x) to return a vector, and I suspect many R users 
>>> would too. The title in help(drop), "Drop Redundant Extent 
>>> Information", suggests that such a simple array would be converted to a 
>>> vector.
>>>
>>> Reading through the help page, I note that this is perhaps not a clear 
>>> bug, but somewhat unclear behavior.
>>>
>>> The most compact way to break the vector out of its eggshell seems to 
>>> be
>>>
>>>  t(x)[,]
>>>
>>> but drop(x) would be much easier to read and write. There's nothing 
>>> particularly matrix about x, so it's not obvious that the conversion 
>>> should involve as.matrix(x).
>>>
>>> Thanks,
>>>
>>> Arni
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jeffrey.horner at gmail.com  Wed Sep  8 23:37:10 2010
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Wed, 8 Sep 2010 16:37:10 -0500
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
	<4C87C9DF.4030208@gmail.com>
	<AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
Message-ID: <AANLkTikRwBjviWg2QQn34UccAofbFr4DoAYGtPeGxSME@mail.gmail.com>

On Wed, Sep 8, 2010 at 1:01 PM, Jeffrey Horner <jeffrey.horner at gmail.com> wrote:
> On Wed, Sep 8, 2010 at 12:37 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> ?On 08/09/2010 1:21 PM, Jeffrey Horner wrote:
>>>
>>> Hi all,
>>>
>>> I'm setting up a development environment on Windows as the subject
>>> implies. I've downloaded and installed Rtools211.exe (will upgrade
>>> later when necessary) and I've also downloaded and installed mingw
>>> with the help of mingw-get.exe.
>>>
>>> I come from a UNIX development background, so I'm at the bash shell
>>> prompt for just about every step in R extenstion development. Question
>>> is what is an appropriate environment for Windows development. What
>>> shell do you use? Do you use cmd.exe with the PATH variable set up by
>>> Rtools? Do you use the sh.exe that comes with Rtools? I've found the
>>> bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
>>> Do you use something else?
>>>
>>
>> I've used the bash shell in Cygwin for quite a few years, but I've been
>> planning a switch to MSYS sometime. ?Cygwin seems to have made some bad
>> decisions lately that make it harder and harder to work with.
>
> This is great news! I don't know how I could survive without bash's vi
> style editing and command completion...
>
> Here's my PATH variable which sets the Rtools paths first, then MinGW:
>
> hornerj at hornerj-win ~
> $ echo $PATH
> /c/Rtools/bin:/c/Rtools/perl/bin:/c/Rtools/MinGW/bin:/c/localbin:/mingw/bin:/bin:/usr/bin:/usr/lo
> cal/bin:/c/Program Files (x86)/R/R-2.11.1/bin:/c/Program Files
> (x86)/CollabNet/Subversion Client:
> /c/Windows/system32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.
> 0/:/c/Program Files (x86)/MiKTeX 2.8/miktex/bin
>
> I'm going to follow the "R Installation ..." manual to compile R on
> Windows and learn a bit about the build process. From there, I intend
> to "port" some open source libraries that have support for being
> compiled with MS VC++ over to MinGW.

>From the MinGW bash shell, the R build went quite smoothly. However, I
did run into trouble with temporary files. I got around it by
specifying TMPDIR like so:

$ cd R_HOME/src/gnuwin32
$ TMPDIR=. /c/Rtools/bin/make all

If I didn't set TMPDIR, it would default to /tmp and the failure would
occur within the mkR target of R_HOME/share/make/basepkg.mk. For
reasons beyond me, the shell environment that's entered within the mkR
target has no notion of a root directory. Anyone else seen this?

Jeff

>
> Aside from my PATH variable, are there other things about my
> development environment I should be aware of?
>
> Jeff
>



-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From lawrence.michael at gene.com  Thu Sep  9 00:50:46 2010
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 8 Sep 2010 15:50:46 -0700
Subject: [Rd] what is the best way for an external interface to interact
 with graphics, libraries
In-Reply-To: <B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>
References: <1283883710896-2530208.post@n4.nabble.com>
	<B6FE3EE8-69FD-4E32-90B8-1065F8947026@r-project.org>
Message-ID: <AANLkTinS-tTfAT7vd4wsSjDshAzc-mOzZB3Trb+QKJ94@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100908/a09464ca/attachment.pl>

From murdoch.duncan at gmail.com  Thu Sep  9 01:39:47 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Sep 2010 19:39:47 -0400
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <AANLkTikRwBjviWg2QQn34UccAofbFr4DoAYGtPeGxSME@mail.gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>	<4C87C9DF.4030208@gmail.com>	<AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
	<AANLkTikRwBjviWg2QQn34UccAofbFr4DoAYGtPeGxSME@mail.gmail.com>
Message-ID: <4C881EC3.6040104@gmail.com>

On 08/09/2010 5:37 PM, Jeffrey Horner wrote:
> On Wed, Sep 8, 2010 at 1:01 PM, Jeffrey Horner <jeffrey.horner at gmail.com> wrote:
>> On Wed, Sep 8, 2010 at 12:37 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>  On 08/09/2010 1:21 PM, Jeffrey Horner wrote:
>>>> Hi all,
>>>>
>>>> I'm setting up a development environment on Windows as the subject
>>>> implies. I've downloaded and installed Rtools211.exe (will upgrade
>>>> later when necessary) and I've also downloaded and installed mingw
>>>> with the help of mingw-get.exe.
>>>>
>>>> I come from a UNIX development background, so I'm at the bash shell
>>>> prompt for just about every step in R extenstion development. Question
>>>> is what is an appropriate environment for Windows development. What
>>>> shell do you use? Do you use cmd.exe with the PATH variable set up by
>>>> Rtools? Do you use the sh.exe that comes with Rtools? I've found the
>>>> bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
>>>> Do you use something else?
>>>>
>>> I've used the bash shell in Cygwin for quite a few years, but I've been
>>> planning a switch to MSYS sometime.  Cygwin seems to have made some bad
>>> decisions lately that make it harder and harder to work with.
>> This is great news! I don't know how I could survive without bash's vi
>> style editing and command completion...
>>
>> Here's my PATH variable which sets the Rtools paths first, then MinGW:
>>
>> hornerj at hornerj-win ~
>> $ echo $PATH
>> /c/Rtools/bin:/c/Rtools/perl/bin:/c/Rtools/MinGW/bin:/c/localbin:/mingw/bin:/bin:/usr/bin:/usr/lo
>> cal/bin:/c/Program Files (x86)/R/R-2.11.1/bin:/c/Program Files
>> (x86)/CollabNet/Subversion Client:
>> /c/Windows/system32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.
>> 0/:/c/Program Files (x86)/MiKTeX 2.8/miktex/bin
>>
>> I'm going to follow the "R Installation ..." manual to compile R on
>> Windows and learn a bit about the build process. From there, I intend
>> to "port" some open source libraries that have support for being
>> compiled with MS VC++ over to MinGW.
> 
> From the MinGW bash shell, the R build went quite smoothly. However, I
> did run into trouble with temporary files. I got around it by
> specifying TMPDIR like so:
> 
> $ cd R_HOME/src/gnuwin32
> $ TMPDIR=. /c/Rtools/bin/make all

I don't know if anything would go wrong, but I'd avoid putting your temp 
dir into the source tree.  On my home machine I normally set R_USER to a 
Windows-style path (with backslashes), and that seems to work.  On my 
work machine I think I set TMPDIR explicitly, but I forget what value I 
used.

> 
> If I didn't set TMPDIR, it would default to /tmp and the failure would
> occur within the mkR target of R_HOME/share/make/basepkg.mk. For
> reasons beyond me, the shell environment that's entered within the mkR
> target has no notion of a root directory. Anyone else seen this?

I'm not sure you're using the write make procedure.  Are you running 
make from within src/gnuwin32, so you get the Makefile there?  It 
shouldn't try to use /tmp (but things might have changed recently).

Duncan Murdoch

> 
> Jeff
> 
>> Aside from my PATH variable, are there other things about my
>> development environment I should be aware of?
>>
>> Jeff
>>
> 
> 
>


From spencer.graves at structuremonitoring.com  Thu Sep  9 02:29:45 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 08 Sep 2010 17:29:45 -0700
Subject: [Rd] Wiki entries on "package development process" and "software
	repository"
Message-ID: <4C882A79.4040200@structuremonitoring.com>

        I hereby invite anyone to make or suggest improvements to the 
Wikipedia entries on "package development process" and "software 
repository".


       Parts of these entries were created by Sundar Dorai-Raj and me:  
We believe that the procedures of the R community in these areas provide 
positive examples that could be profitably considered for people writing 
and sharing work in other languages.  I'm scheduled to speak about this 
next Tuesday to the San Francisco Bay Area chapter of the Association 
for Computing Machinery (ACM;  http://www.sfbayacm.org/?p=1962), but my 
interest in this extend beyond next Tuesday.  I may later send a note to 
the "Communications of the ACM" referencing these entries and inviting 
further input.


       Your help with this would be greatly appreciated, because I don't 
know enough to talk authoritatively about "package development process" 
and "software repository" for languages other than R.  If you know other 
people who might contribute perspectives for other languages, please 
feel free to forward this request to them.


       If you are a Wikipedian, feel free to change the entries 
directly.  Otherwise, I'd be pleased to hear your comments, suggested 
improvements, etc., via email.


       Thanks,
       Spencer Graves


From baptiste.auguie at googlemail.com  Thu Sep  9 08:48:39 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Thu, 9 Sep 2010 08:48:39 +0200
Subject: [Rd] [R] large files produced from image plots?
In-Reply-To: <4C87F51F.90207@auckland.ac.nz>
References: <SNT131-w28F3D126917CB8C87B2DAABB720@phx.gbl>
	<2277A910-3029-4080-BF1E-BBD4F3C1CC6E@gmail.com>
	<SNT131-w112E008F02638748589BD9BB720@phx.gbl>
	<AANLkTinNQKhxcDvrMa23-FYmfUR_m-u8WDi4_zh2KQ68@mail.gmail.com>
	<4C87F51F.90207@auckland.ac.nz>
Message-ID: <AANLkTinvY2Y4Cyg-SC42mq7gg9Ehe86hqqc4wbuDuNbd@mail.gmail.com>

Hi,

Oops, I probably spoke too quickly about the pdf() output. I attach
the quartz() result, the pdf() result, and a screenshot of what I saw
using the built-in Preview program of MacOS... Here the pdf appeared
to be wrong, with a strange interpolation going on. I opened the same
file in Acrobat and it's fine, so I guess it's a bug in the pdf
viewer, as is often the case with pdf artifacts.

My code:


pdf("test-raster.pdf")
image <- as.raster(matrix(0:1, ncol=5, nrow=3)); plot.new()
rasterImage(image, 0, 0, 1, 1, interpolate=FALSE)
dev.off()

Best,

baptiste


On 8 September 2010 22:42, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
> [shifted this to r-devel]
>
> I can't reproduce this yet on my systems, but I have heard of at least one
> other example of a raster-related crash (on a 64-bit system I think).
>
> Baptiste: I would love to see that broken PDF if you still have it.
>
> Paul
>
> On 9/09/2010 8:00 a.m., baptiste auguie wrote:
>>
>> Hi,
>>
>> I get the same crash with x11() with sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-apple-darwin9.8.0
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] grid ? ? ?stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>> [8] base
>>
>> However it works fine with quartz(). Have you tried other devices?
>> pdf() doesn't crash R for me, but the output is incorrect. png() is OK
>> but defeats the purpose here.
>>
>> rasterImage is quite a recent addition, it would probably be
>> appreciated to report any such odd behavior to R-devel. Interestingly
>> (or not), the x11() test does not crash for me using grid.raster
>> instead of rasterImage.
>>
>> Best,
>>
>> baptiste
>>
>>
>>
>>
>>
>>
>>
>> On 8 September 2010 21:47, Stephen T.<obsessively at hotmail.com> ?wrote:
>>>
>>> Hi Baptiste,
>>> Thanks for your suggestion. I have to look into this further, but
>>> anything I
>>> try with rasterImage() gives me this type of error (below is from running
>>> the example in the help file). This is with R 2.11.1 on OS X 10.5 -
>>> ?*** caught bus error ***
>>> address 0x24, cause 'non-existent physical address'
>>> Traceback:
>>> ?1: rasterImage(image, 100, 300, 150, 350, interpolate = FALSE)
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> This is not an obvious error, is it?
>>> Thanks,
>>> Stephen
>>>>
>>>> Subject: Re: [R] large files produced from image plots?
>>>> From: baptiste.auguie at googlemail.com
>>>> Date: Wed, 8 Sep 2010 19:41:46 +0200
>>>> CC: r-help at r-project.org
>>>> To: obsessively at hotmail.com
>>>>
>>>> Hi,
>>>>
>>>> Have you tried the recent rasterImage() function?
>>>>
>>>> HTH,
>>>>
>>>> baptiste
>>>>
>>>> On Sep 8, 2010, at 7:30 PM, Stephen T. wrote:
>>>>
>>>>>
>>>>> Hi list,
>>>>> I wonder if anyone has thoughts on making image plots in R [using
>>>>> image() or image.plot(), or filled.contour()]- I've made quite a bit
>>>>> now,
>>>>> but they seem quite large in size when exported to pdf file format
>>>>> (even
>>>>> after compressing with pdftk or ghostscript, which I regularly do). I
>>>>> know
>>>>> that for "images", raster graphics output (png, tiff) may be the way to
>>>>> go,
>>>>> but often the ones I make are multi-panel plots with other graphics on
>>>>> them,
>>>>> and are usually included in a LaTeX document (PDFLaTeX does accept png)
>>>>> and
>>>>> require stretching/shrinking (and/or possibly editing with Adobe
>>>>> Illustrator). I have had some luck exporting image plots from Matlab
>>>>> (to
>>>>> postscript or pdf) before in the sense that the files seem smaller and
>>>>> less
>>>>> pixelated. Is this a difference in the way image() plots are produced,
>>>>> or
>>>>> with the way the image is written to the pdf() device (if anyone is
>>>>> familiar
>>>>> with other image-exporting programs...)? The other day I had a 13MB
>>>>> dataset,
>>>>> and probably plotted 3/4 of it!
>>>>> using image() and the compressed pdf output was about 8 MB (it
>>>>> contained
>>>>> other stuff but was an addition of a few KB). I tried filled.contour(),
>>>>> as I
>>>>> understand that it colors polygons to fill contours instead of coloring
>>>>> rectangles at each pixel - and it has saved me before - but this time
>>>>> the
>>>>> contours may have been too sharp as as its compressed pdf came out to
>>>>> be 62
>>>>> MB... (ouch!). I have not tested this data set with other software
>>>>> programs
>>>>> so it may just have been a difficult data set.
>>>>> Is there a good solution to this (or is it simply not to use a
>>>>> vector-graphics format in these instances), and just for my curiosity,
>>>>> are
>>>>> you aware of any things that other software (data analysis) programs do
>>>>> uder
>>>>> the hood to make their exported images smaller/smoother?
>>>>> Thanks much!
>>>>> Stephen
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pdf-raster.pdf
Type: application/pdf
Size: 2266 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100909/a631a286/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: quartz-raster.pdf
Type: application/pdf
Size: 5544 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100909/a631a286/attachment-0001.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: screenshot-pdf-Preview.png
Type: image/png
Size: 72584 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100909/a631a286/attachment.png>

From b.rowlingson at lancaster.ac.uk  Thu Sep  9 11:57:46 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 9 Sep 2010 10:57:46 +0100
Subject: [Rd] An ls error which is not an error...
Message-ID: <AANLkTinh9C-+sWLs8Fv9vKmiWP+9O99M7w2gKcGhD4g3@mail.gmail.com>

If I try ls with an unquoted version of something in my search list, I
get an error message but the ls completes successfully. For example:

 > attach("x.RData")
 > ls(file:x.RData)
 Error in try(name) : object 'x.RData' not found
 [1] "x"

which seems to be because ls first does: nameValue <- try(name) which
raises the error, and then goes on to do some
substitute(deparse(magic)) to get the name and carries on as if I'd
done ls("file:x.RData")

Documentation says (with my enumeration):

    The ?name? argument can specify the environment from which object
     names are taken in one of several forms:

    1. as an integer (the position in the ?search? list);
    2. as the character string name of an element in the search list;
    3.  or as an explicit ?environment?

Either ls(file:x.RData) is none of these in which case there should be
an error and exit, or it's (2), in which case the error is misleading.
I think try(name,silent=TRUE) might be a better option?

Barry


From murdoch.duncan at gmail.com  Thu Sep  9 12:43:47 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 09 Sep 2010 06:43:47 -0400
Subject: [Rd] An ls error which is not an error...
In-Reply-To: <AANLkTinh9C-+sWLs8Fv9vKmiWP+9O99M7w2gKcGhD4g3@mail.gmail.com>
References: <AANLkTinh9C-+sWLs8Fv9vKmiWP+9O99M7w2gKcGhD4g3@mail.gmail.com>
Message-ID: <4C88BA63.1090601@gmail.com>

On 09/09/2010 5:57 AM, Barry Rowlingson wrote:
> If I try ls with an unquoted version of something in my search list, I
> get an error message but the ls completes successfully. For example:
> 
>  > attach("x.RData")
>  > ls(file:x.RData)
>  Error in try(name) : object 'x.RData' not found
>  [1] "x"
> 
> which seems to be because ls first does: nameValue <- try(name) which
> raises the error, and then goes on to do some
> substitute(deparse(magic)) to get the name and carries on as if I'd
> done ls("file:x.RData")
> 
> Documentation says (with my enumeration):
> 
>     The ?name? argument can specify the environment from which object
>      names are taken in one of several forms:
> 
>     1. as an integer (the position in the ?search? list);
>     2. as the character string name of an element in the search list;
>     3.  or as an explicit ?environment?
> 
> Either ls(file:x.RData) is none of these in which case there should be
> an error and exit, or it's (2), in which case the error is misleading.
> I think try(name,silent=TRUE) might be a better option?

This is old code, so I don't think converting it to an error is a good 
idea.  I don't like the idea of silently eating the error:  it might 
have been a typo, that just coincidentally looks like the name of 
something on the search list.  So I will try to change the error to an 
informative warning.

Duncan Murdoch


From wdunlap at tibco.com  Thu Sep  9 16:54:36 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Sep 2010 07:54:36 -0700
Subject: [Rd] Drop single-dimensional array
In-Reply-To: <alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>
References: <alpine.LFD.2.00.1009061211090.1206@hafstormur.hafro.is><FE59E6D8-F3DC-48D8-9706-4DF08147027F@r-project.org>
	<alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700036E81FE@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Arni Magnusson
> Sent: Wednesday, September 08, 2010 11:55 AM
> To: r-devel at r-project.org
> Cc: Simon Urbanek
> Subject: [Rd] Drop single-dimensional array
> 
> Hi Simon, thank you for the concise reply.
> 
> Do you mean the reported behavior of drop() is not a bug?
> 
> It looks like a borderline bug to me (see below), but I'm not 
> the judge of 
> that. If this is the intended behavior and serves an actual 
> purpose, then 
> that could be explicitly documented in a \note{} on the help page.
> 
> Such a note would slightly reduce the surprise of users 
> running into this 
> behavior.
> 
> This is related to the oddity that one-dimensional arrays are:
> 
>    array(month.abb, dim=c(1,1,12))  # array
>    array(month.abb, dim=c(1,12))    # matrix
>    array(month.abb, dim=12)         # array
> 
> Firstly, one would expect the pattern to be 
> array-matrix-vector. 

I would expect the array() constructor function to return
something of class array.  (I guess matrix is acceptable
because it inherits from array).

One dimensional arrays and vectors act very similarly
when used in R code.  E.g., names(array1d) gives you
the same thing as dimnames(array1d)[[1]].  Accessing
them from C code probably shows more differences.
Are there features beyond drop's behavior that are
causing you to be concerned about differences between
the 2 types?

drop(x) and x[..., drop=TRUE] have always bugged me
because you couldn't control which dimensions got
dropped.  E.g., if you have a n by 2 by 3 array
and want to get the 3rd n by 2 slice of it as a matrix
you can do
   array[,,3,drop=TRUE]
except when n==1.  It would be nice to be able to say
"drop the 3rd dimension, throwing an error if that
dimension is not 1".

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> Secondly, 
> it's easy to drop() the three-dimensional and two-dimensional 
> objects, but 
> drop() does nothing to the one-dimensional array. Instead, it 
> takes an 
> unintuitive combination of methods to convert a 
> single-dimensional to a 
> vector, while retaining its names. Or I may well be missing something 
> obvious.
> 
> Best regards,
> 
> Arni
> 
> 
> 
> On Wed, 8 Sep 2010, Simon Urbanek wrote:
> 
> > wrong address - did you mean R-devel?
> > Simon
> >
> >
> >
> > On Sep 6, 2010, at 8:35 AM, Arni Magnusson wrote:
> >
> >> Bug or not, I was surprised by this behavior:
> >>
> >>  x <- tapply(chickwts$weight, chickwts$feed, median)
> >>  x  # array ... I'd like to convert to vector with named elements
> >>  drop(x)             # what, still an array?
> >>  drop(as.matrix(x))  # this works
> >>  drop(t(x))          # this works
> >>
> >> I was expecting drop(x) to return a vector, and I suspect 
> many R users 
> >> would too. The title in help(drop), "Drop Redundant Extent 
> >> Information", suggests that such a simple array would be 
> converted to a 
> >> vector.
> >>
> >> Reading through the help page, I note that this is perhaps 
> not a clear 
> >> bug, but somewhat unclear behavior.
> >>
> >> The most compact way to break the vector out of its 
> eggshell seems to 
> >> be
> >>
> >>  t(x)[,]
> >>
> >> but drop(x) would be much easier to read and write. 
> There's nothing 
> >> particularly matrix about x, so it's not obvious that the 
> conversion 
> >> should involve as.matrix(x).
> >>
> >> Thanks,
> >>
> >> Arni
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From obsessively at hotmail.com  Thu Sep  9 19:52:19 2010
From: obsessively at hotmail.com (Stephen T.)
Date: Thu, 9 Sep 2010 10:52:19 -0700
Subject: [Rd] [R] large files produced from image plots?
In-Reply-To: <4C87F51F.90207@auckland.ac.nz>
References: <SNT131-w28F3D126917CB8C87B2DAABB720@phx.gbl>
	<2277A910-3029-4080-BF1E-BBD4F3C1CC6E@gmail.com>
	<SNT131-w112E008F02638748589BD9BB720@phx.gbl>
	<AANLkTinNQKhxcDvrMa23-FYmfUR_m-u8WDi4_zh2KQ68@mail.gmail.com>,
	<4C87F51F.90207@auckland.ac.nz>
Message-ID: <SNT131-w15C105ABF3CEFC317EF39ABB730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100909/52d40af5/attachment.pl>

From tplate at acm.org  Fri Sep 10 02:18:00 2010
From: tplate at acm.org (Tony Plate)
Date: Thu, 09 Sep 2010 20:18:00 -0400
Subject: [Rd] Drop single-dimensional array
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700036E81FE@NA-PA-VBE03.na.tibco.com>
References: <alpine.LFD.2.00.1009061211090.1206@hafstormur.hafro.is><FE59E6D8-F3DC-48D8-9706-4DF08147027F@r-project.org>	<alpine.LFD.2.00.1009081814420.16402@hafstormur.hafro.is>
	<77EB52C6DD32BA4D87471DCD70C8D700036E81FE@NA-PA-VBE03.na.tibco.com>
Message-ID: <4C897938.9000605@acm.org>

  On 9/9/2010 10:54 AM, William Dunlap wrote:
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Arni Magnusson
>> Sent: Wednesday, September 08, 2010 11:55 AM
>> To: r-devel at r-project.org
>> Cc: Simon Urbanek
>> Subject: [Rd] Drop single-dimensional array
>>
>> Hi Simon, thank you for the concise reply.
>>
>> Do you mean the reported behavior of drop() is not a bug?
>>
>> It looks like a borderline bug to me (see below), but I'm not
>> the judge of
>> that. If this is the intended behavior and serves an actual
>> purpose, then
>> that could be explicitly documented in a \note{} on the help page.
>>
>> Such a note would slightly reduce the surprise of users
>> running into this
>> behavior.
>>
>> This is related to the oddity that one-dimensional arrays are:
>>
>>     array(month.abb, dim=c(1,1,12))  # array
>>     array(month.abb, dim=c(1,12))    # matrix
>>     array(month.abb, dim=12)         # array
>>
>> Firstly, one would expect the pattern to be
>> array-matrix-vector.
> I would expect the array() constructor function to return
> something of class array.  (I guess matrix is acceptable
> because it inherits from array).
>
> One dimensional arrays and vectors act very similarly
> when used in R code.  E.g., names(array1d) gives you
> the same thing as dimnames(array1d)[[1]].  Accessing
> them from C code probably shows more differences.
> Are there features beyond drop's behavior that are
> causing you to be concerned about differences between
> the 2 types?
>
> drop(x) and x[..., drop=TRUE] have always bugged me
> because you couldn't control which dimensions got
> dropped.  E.g., if you have a n by 2 by 3 array
> and want to get the 3rd n by 2 slice of it as a matrix
> you can do
>     array[,,3,drop=TRUE]
> except when n==1.  It would be nice to be able to say
> "drop the 3rd dimension, throwing an error if that
> dimension is not 1".
That always bugged me too.  The 'abind' package has an 'adrop()' function with this behavior, and I was just working on an enhancement of it that would make it able to convert 1-d arrays to named vectors when this thread started.

-- Tony Plate

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com


From renaud at mancala.cbio.uct.ac.za  Fri Sep 10 12:46:30 2010
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 10 Sep 2010 12:46:30 +0200
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
Message-ID: <4C8A0C86.8030307@cbio.uct.ac.za>

Hi,

suppose you have two versions of the same algorithm: one in pure R, the 
other one in C/C++ called via .Call().
Assuming there is no bug in the implementations (i.e. they both do the 
same thing), is there any well known reason why the C/C++ implementation 
could return numerical results non identical to the one obtained from 
the pure R code? (e.g. could it be rounding errors? please explain.)
Has anybody had a similar experience?

By not identical, I mean very small differences (< 2.4 e-14), but enough 
to have identical() returning FALSE. Maybe I should not bother, but I 
want to be sure where the differences come from, at least by mere curiosity.

Briefly the R code perform multiple matrix product; the C code is an 
optimization of those specific products via custom for loops, where 
entries are not computed in the same order, etc... which improves both 
memory usage and speed. The result is theoretically the same.

Thank you,
Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mail disclaimer published on our website at http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from +27 21 650 4500. This e-mail is intended only for the person(s) to whom it is addressed. If the e-mail has reached you in error, please notify the author. If you are not the intended recipient of the e-mail you may not use, disclose, copy, redirect or print the content. If this e-mail is not related to the business of UCT it is sent by the sender in the sender's individual capacity.

###


From murdoch.duncan at gmail.com  Fri Sep 10 13:00:25 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Sep 2010 07:00:25 -0400
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A0C86.8030307@cbio.uct.ac.za>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
Message-ID: <4C8A0FC9.9060400@gmail.com>

On 10/09/2010 6:46 AM, Renaud Gaujoux wrote:
> Hi,
> 
> suppose you have two versions of the same algorithm: one in pure R, the 
> other one in C/C++ called via .Call().
> Assuming there is no bug in the implementations (i.e. they both do the 
> same thing), is there any well known reason why the C/C++ implementation 
> could return numerical results non identical to the one obtained from 
> the pure R code? (e.g. could it be rounding errors? please explain.)
> Has anybody had a similar experience?

R often uses extended reals (80 bit floating point values on Intel 
chips) for intermediate values.  C compilers may or may not do that.
> 
> By not identical, I mean very small differences (< 2.4 e-14), but enough 
> to have identical() returning FALSE. Maybe I should not bother, but I 
> want to be sure where the differences come from, at least by mere curiosity.
> 
> Briefly the R code perform multiple matrix product; the C code is an 
> optimization of those specific products via custom for loops, where 
> entries are not computed in the same order, etc... which improves both 
> memory usage and speed. The result is theoretically the same.

Changing the order of operations will often affect rounding.  For 
example, suppose epsilon is the smallest number such that 1 + epsilon is 
not equal to 1.  Then 1 + (epsilon/2) + (epsilon/2) will evaluate to 
either 1 or 1 + epsilon, depending on the order of computing the additions.

Duncan Murdoch

> 
> Thank you,
> Renaud
>


From renaud at mancala.cbio.uct.ac.za  Fri Sep 10 13:07:34 2010
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 10 Sep 2010 13:07:34 +0200
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A0FC9.9060400@gmail.com>
References: <4C8A0C86.8030307@cbio.uct.ac.za> <4C8A0FC9.9060400@gmail.com>
Message-ID: <4C8A1176.9060906@cbio.uct.ac.za>

Thank you Duncan for your reply.

Currently I am using 'double' for the computations.
What type should I use for extended real in my intermediate computations?
The result will still be 'double' anyway right?



On 10/09/2010 13:00, Duncan Murdoch wrote:
> On 10/09/2010 6:46 AM, Renaud Gaujoux wrote:
>> Hi,
>>
>> suppose you have two versions of the same algorithm: one in pure R, 
>> the other one in C/C++ called via .Call().
>> Assuming there is no bug in the implementations (i.e. they both do 
>> the same thing), is there any well known reason why the C/C++ 
>> implementation could return numerical results non identical to the 
>> one obtained from the pure R code? (e.g. could it be rounding errors? 
>> please explain.)
>> Has anybody had a similar experience?
>
> R often uses extended reals (80 bit floating point values on Intel 
> chips) for intermediate values.  C compilers may or may not do that.
>>
>> By not identical, I mean very small differences (< 2.4 e-14), but 
>> enough to have identical() returning FALSE. Maybe I should not 
>> bother, but I want to be sure where the differences come from, at 
>> least by mere curiosity.
>>
>> Briefly the R code perform multiple matrix product; the C code is an 
>> optimization of those specific products via custom for loops, where 
>> entries are not computed in the same order, etc... which improves 
>> both memory usage and speed. The result is theoretically the same.
>
> Changing the order of operations will often affect rounding.  For 
> example, suppose epsilon is the smallest number such that 1 + epsilon 
> is not equal to 1.  Then 1 + (epsilon/2) + (epsilon/2) will evaluate 
> to either 1 or 1 + epsilon, depending on the order of computing the 
> additions.
>
> Duncan Murdoch
>
>>
>> Thank you,
>> Renaud
>>
>

 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mail disclaimer published on our website at http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from +27 21 650 4500. This e-mail is intended only for the person(s) to whom it is addressed. If the e-mail has reached you in error, please notify the author. If you are not the intended recipient of the e-mail you may not use, disclose, copy, redirect or print the content. If this e-mail is not related to the business of UCT it is sent by the sender in the sender's individual capacity.

###


From murdoch.duncan at gmail.com  Fri Sep 10 13:18:44 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Sep 2010 07:18:44 -0400
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A1176.9060906@cbio.uct.ac.za>
References: <4C8A0C86.8030307@cbio.uct.ac.za> <4C8A0FC9.9060400@gmail.com>
	<4C8A1176.9060906@cbio.uct.ac.za>
Message-ID: <4C8A1414.2010909@gmail.com>

On 10/09/2010 7:07 AM, Renaud Gaujoux wrote:
> Thank you Duncan for your reply.
> 
> Currently I am using 'double' for the computations.
> What type should I use for extended real in my intermediate computations?

I think it depends on compiler details.  On some compilers "long double" 
will get it, but I don't think there's a standard type that works on all 
compilers.  (In fact, the 80 bit type on Intel chips isn't necessarily 
supported on other hardware.)  R defines LDOUBLE in its header files and 
it is probably best to use that if you want to duplicate R results.

> The result will still be 'double' anyway right?

Yes, you do need to return type double.

Duncan Murdoch

> 
> 
> 
> On 10/09/2010 13:00, Duncan Murdoch wrote:
>> On 10/09/2010 6:46 AM, Renaud Gaujoux wrote:
>>> Hi,
>>>
>>> suppose you have two versions of the same algorithm: one in pure R, 
>>> the other one in C/C++ called via .Call().
>>> Assuming there is no bug in the implementations (i.e. they both do 
>>> the same thing), is there any well known reason why the C/C++ 
>>> implementation could return numerical results non identical to the 
>>> one obtained from the pure R code? (e.g. could it be rounding errors? 
>>> please explain.)
>>> Has anybody had a similar experience?
>> R often uses extended reals (80 bit floating point values on Intel 
>> chips) for intermediate values.  C compilers may or may not do that.
>>> By not identical, I mean very small differences (< 2.4 e-14), but 
>>> enough to have identical() returning FALSE. Maybe I should not 
>>> bother, but I want to be sure where the differences come from, at 
>>> least by mere curiosity.
>>>
>>> Briefly the R code perform multiple matrix product; the C code is an 
>>> optimization of those specific products via custom for loops, where 
>>> entries are not computed in the same order, etc... which improves 
>>> both memory usage and speed. The result is theoretically the same.
>> Changing the order of operations will often affect rounding.  For 
>> example, suppose epsilon is the smallest number such that 1 + epsilon 
>> is not equal to 1.  Then 1 + (epsilon/2) + (epsilon/2) will evaluate 
>> to either 1 or 1 + epsilon, depending on the order of computing the 
>> additions.
>>
>> Duncan Murdoch
>>
>>> Thank you,
>>> Renaud
>>>
> 
>  
> 
> ###
> UNIVERSITY OF CAPE TOWN 
> 
> This e-mail is subject to the UCT ICT policies and e-mail disclaimer published on our website at http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from +27 21 650 4500. This e-mail is intended only for the person(s) to whom it is addressed. If the e-mail has reached you in error, please notify the author. If you are not the intended recipient of the e-mail you may not use, disclose, copy, redirect or print the content. If this e-mail is not related to the business of UCT it is sent by the sender in the sender's individual capacity.
> 
> ###
>  
>


From b.rowlingson at lancaster.ac.uk  Fri Sep 10 13:24:28 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Sep 2010 12:24:28 +0100
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A0C86.8030307@cbio.uct.ac.za>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
Message-ID: <AANLkTimYPVA+VEF+DvU9hYDcNNcnoEqk00=gVimQA4S=@mail.gmail.com>

On Fri, Sep 10, 2010 at 11:46 AM, Renaud Gaujoux
<renaud at mancala.cbio.uct.ac.za> wrote:
> Hi,
>
> suppose you have two versions of the same algorithm: one in pure R, the
> other one in C/C++ called via .Call().
> Assuming there is no bug in the implementations (i.e. they both do the same
> thing), is there any well known reason why the C/C++ implementation could
> return numerical results non identical to the one obtained from the pure R
> code? (e.g. could it be rounding errors? please explain.)
> Has anybody had a similar experience?
>
> By not identical, I mean very small differences (< 2.4 e-14), but enough to
> have identical() returning FALSE. Maybe I should not bother, but I want to
> be sure where the differences come from, at least by mere curiosity.
>
> Briefly the R code perform multiple matrix product; the C code is an
> optimization of those specific products via custom for loops, where entries
> are not computed in the same order, etc... which improves both memory usage
> and speed. The result is theoretically the same.

 I've had almost exactly this situation recently with an algorithm I
first implemented in R and then in C. Guess what the problem was? Yes,
a bug in the C code.

 At first I thought everything was okay because the returned values
were close-ish, and I thought 'oh, rounding error', but I wasn't happy
about that. So I dug a bit deeper. This is worth doing even if you are
sure there no bugs in the C code (remember: there's always one more
bug).

 First, construct a minimal dataset so you can demonstrate the problem
with a manageable size of matrix. I went down to 7 data points. Then
get the C to print out its inputs. Identical, and as expected? Good.

 Now debug intermediate calculations, printing or saving from C and
checking they are the same as the intermediate calculations from R. If
possible, try returning intermediate calculations in C and checking
identical() with R intermediates.

 Eventually you will find out where the first diverge - and this is
the important bit. It's no use just knowing the final answers come out
different, it's likely your answer has a sensitive dependence on
initial conditions. You need to track down when the first bits are
different.

 Or it could be rounding error...

Barry


From renaud at mancala.cbio.uct.ac.za  Fri Sep 10 13:43:28 2010
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 10 Sep 2010 13:43:28 +0200
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <AANLkTimYPVA+VEF+DvU9hYDcNNcnoEqk00=gVimQA4S=@mail.gmail.com>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
	<AANLkTimYPVA+VEF+DvU9hYDcNNcnoEqk00=gVimQA4S=@mail.gmail.com>
Message-ID: <4C8A19E0.9070203@cbio.uct.ac.za>

Ok.

I quickly tried using LDOUBLE wherever I could, but it did not changed 
the results. I might try harder...
I agree with you Barry, and I will re-double re-check my code.

Thank you both for your help.
Bests,
Renaud

On 10/09/2010 13:24, Barry Rowlingson wrote:
> On Fri, Sep 10, 2010 at 11:46 AM, Renaud Gaujoux
> <renaud at mancala.cbio.uct.ac.za>  wrote:
>    
>> Hi,
>>
>> suppose you have two versions of the same algorithm: one in pure R, the
>> other one in C/C++ called via .Call().
>> Assuming there is no bug in the implementations (i.e. they both do the same
>> thing), is there any well known reason why the C/C++ implementation could
>> return numerical results non identical to the one obtained from the pure R
>> code? (e.g. could it be rounding errors? please explain.)
>> Has anybody had a similar experience?
>>
>> By not identical, I mean very small differences (<  2.4 e-14), but enough to
>> have identical() returning FALSE. Maybe I should not bother, but I want to
>> be sure where the differences come from, at least by mere curiosity.
>>
>> Briefly the R code perform multiple matrix product; the C code is an
>> optimization of those specific products via custom for loops, where entries
>> are not computed in the same order, etc... which improves both memory usage
>> and speed. The result is theoretically the same.
>>      
>   I've had almost exactly this situation recently with an algorithm I
> first implemented in R and then in C. Guess what the problem was? Yes,
> a bug in the C code.
>
>   At first I thought everything was okay because the returned values
> were close-ish, and I thought 'oh, rounding error', but I wasn't happy
> about that. So I dug a bit deeper. This is worth doing even if you are
> sure there no bugs in the C code (remember: there's always one more
> bug).
>
>   First, construct a minimal dataset so you can demonstrate the problem
> with a manageable size of matrix. I went down to 7 data points. Then
> get the C to print out its inputs. Identical, and as expected? Good.
>
>   Now debug intermediate calculations, printing or saving from C and
> checking they are the same as the intermediate calculations from R. If
> possible, try returning intermediate calculations in C and checking
> identical() with R intermediates.
>
>   Eventually you will find out where the first diverge - and this is
> the important bit. It's no use just knowing the final answers come out
> different, it's likely your answer has a sensitive dependence on
> initial conditions. You need to track down when the first bits are
> different.
>
>   Or it could be rounding error...
>
> Barry
>    

 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mail disclaimer published on our website at http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from +27 21 650 4500. This e-mail is intended only for the person(s) to whom it is addressed. If the e-mail has reached you in error, please notify the author. If you are not the intended recipient of the e-mail you may not use, disclose, copy, redirect or print the content. If this e-mail is not related to the business of UCT it is sent by the sender in the sender's individual capacity.

###


From pgilbert at bank-banque-canada.ca  Fri Sep 10 16:07:32 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 10 Sep 2010 10:07:32 -0400
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A0C86.8030307@cbio.uct.ac.za>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A02D5AAF7@EXMAIL2.bocad.bank-banque-canada.ca>

With fortran I have always managed to be able to get identical results
on the same computer with the same OS. You will have trouble if you
switch OS or hardware, or try the same hardware and OS with different
math libraries. All the real calculations need to be double, even
intermediate variables. Also, I've had trouble with arrays not being
initialized to double 0.0. If you initialize to single 0.0 the
straggling bits can cause differences. You also need to be careful about
conversion from integer to real, to do double conversion. I'm not sure
about C, but I would guess there are some of the same problems.

Paul

>-----Original Message-----
>From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>project.org] On Behalf Of Renaud Gaujoux
>Sent: September 10, 2010 6:47 AM
>To: r-devel at r-project.org
>Subject: [Rd] Non identical numerical results from R code vs C/C++
code?
>
>Hi,
>
>suppose you have two versions of the same algorithm: one in pure R, the
>other one in C/C++ called via .Call().
>Assuming there is no bug in the implementations (i.e. they both do the
>same thing), is there any well known reason why the C/C++
implementation
>could return numerical results non identical to the one obtained from
>the pure R code? (e.g. could it be rounding errors? please explain.)
>Has anybody had a similar experience?
>
>By not identical, I mean very small differences (< 2.4 e-14), but
enough
>to have identical() returning FALSE. Maybe I should not bother, but I
>want to be sure where the differences come from, at least by mere
>curiosity.
>
>Briefly the R code perform multiple matrix product; the C code is an
>optimization of those specific products via custom for loops, where
>entries are not computed in the same order, etc... which improves both
>memory usage and speed. The result is theoretically the same.
>
>Thank you,
>Renaud
>
>--
>Renaud Gaujoux
>Computational Biology - University of Cape Town
>South Africa
>
>
>
>
>###
>UNIVERSITY OF CAPE TOWN
>
>This e-mail is subject to the UCT ICT policies and e-mail disclaimer
>published on our website at
>http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from
>+27 21 650 4500. This e-mail is intended only for the person(s) to whom
>it is addressed. If the e-mail has reached you in error, please notify
>the author. If you are not the intended recipient of the e-mail you may
>not use, disclose, copy, redirect or print the content. If this e-mail
>is not related to the business of UCT it is sent by the sender in the
>sender's individual capacity.
>
>###
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From jeffrey.horner at gmail.com  Fri Sep 10 16:42:47 2010
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Fri, 10 Sep 2010 09:42:47 -0500
Subject: [Rd] Development environment for R extentions on Windows
In-Reply-To: <4C881EC3.6040104@gmail.com>
References: <AANLkTikqVZAqzUxnVMjZt-0xh9dcx4prJBO404EdQ5Gt@mail.gmail.com>
	<4C87C9DF.4030208@gmail.com>
	<AANLkTikQWCeQXnRyQ_MYGvrCb6xS48y-zhZD6v+VEd-Z@mail.gmail.com>
	<AANLkTikRwBjviWg2QQn34UccAofbFr4DoAYGtPeGxSME@mail.gmail.com>
	<4C881EC3.6040104@gmail.com>
Message-ID: <AANLkTimy5r-76270BFho9N6i1qZzKRLtOP3mNKRwx=dm@mail.gmail.com>

On Wed, Sep 8, 2010 at 6:39 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/09/2010 5:37 PM, Jeffrey Horner wrote:
>>
>> On Wed, Sep 8, 2010 at 1:01 PM, Jeffrey Horner <jeffrey.horner at gmail.com>
>> wrote:
>>>
>>> On Wed, Sep 8, 2010 at 12:37 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> ?On 08/09/2010 1:21 PM, Jeffrey Horner wrote:
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I'm setting up a development environment on Windows as the subject
>>>>> implies. I've downloaded and installed Rtools211.exe (will upgrade
>>>>> later when necessary) and I've also downloaded and installed mingw
>>>>> with the help of mingw-get.exe.
>>>>>
>>>>> I come from a UNIX development background, so I'm at the bash shell
>>>>> prompt for just about every step in R extenstion development. Question
>>>>> is what is an appropriate environment for Windows development. What
>>>>> shell do you use? Do you use cmd.exe with the PATH variable set up by
>>>>> Rtools? Do you use the sh.exe that comes with Rtools? I've found the
>>>>> bash shell from MinGW to be a pretty close equivalent to bash on UNIX.
>>>>> Do you use something else?
>>>>>
>>>> I've used the bash shell in Cygwin for quite a few years, but I've been
>>>> planning a switch to MSYS sometime. ?Cygwin seems to have made some bad
>>>> decisions lately that make it harder and harder to work with.
>>>
>>> This is great news! I don't know how I could survive without bash's vi
>>> style editing and command completion...
>>>
>>> Here's my PATH variable which sets the Rtools paths first, then MinGW:
>>>
>>> hornerj at hornerj-win ~
>>> $ echo $PATH
>>>
>>> /c/Rtools/bin:/c/Rtools/perl/bin:/c/Rtools/MinGW/bin:/c/localbin:/mingw/bin:/bin:/usr/bin:/usr/lo
>>> cal/bin:/c/Program Files (x86)/R/R-2.11.1/bin:/c/Program Files
>>> (x86)/CollabNet/Subversion Client:
>>>
>>> /c/Windows/system32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.
>>> 0/:/c/Program Files (x86)/MiKTeX 2.8/miktex/bin
>>>
>>> I'm going to follow the "R Installation ..." manual to compile R on
>>> Windows and learn a bit about the build process. From there, I intend
>>> to "port" some open source libraries that have support for being
>>> compiled with MS VC++ over to MinGW.
>>
>> From the MinGW bash shell, the R build went quite smoothly. However, I
>> did run into trouble with temporary files. I got around it by
>> specifying TMPDIR like so:
>>
>> $ cd R_HOME/src/gnuwin32
>> $ TMPDIR=. /c/Rtools/bin/make all
>
> I don't know if anything would go wrong, but I'd avoid putting your temp dir
> into the source tree. ?On my home machine I normally set R_USER to a
> Windows-style path (with backslashes), and that seems to work. ?On my work
> machine I think I set TMPDIR explicitly, but I forget what value I used.
>
>>
>> If I didn't set TMPDIR, it would default to /tmp and the failure would
>> occur within the mkR target of R_HOME/share/make/basepkg.mk. For
>> reasons beyond me, the shell environment that's entered within the mkR
>> target has no notion of a root directory. Anyone else seen this?
>
> I'm not sure you're using the write make procedure. ?Are you running make
> from within src/gnuwin32, so you get the Makefile there? ?It shouldn't try
> to use /tmp (but things might have changed recently).

I was (see above), and I think I've found the culprit.
R_HOME/share/make/basepkg.mk is utilized by both the UNIX and Windows
build, and its target mkR will expand the shell variable f to a
suitable path under /tmp if TMPDIR is not set. Rtools' shell (forked
by make) has no notion of a root file system at /, so /tmp is never
found. The solution is to, of course, always set TMPDIR to a suitable
directory before invoking make. Surprisingly, setting TMPDIR=/tmp
actually works since make expands it to the user's temporary folder.
On my windows laptop, that's:

/cygdrive/c/Users/hornerj/AppData/Local/Temp

Jeff

>
> Duncan Murdoch
>
>>
>> Jeff
>>
>>> Aside from my PATH variable, are there other things about my
>>> development environment I should be aware of?
>>>
>>> Jeff
>>>
>>
>>
>>
>
>



-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From renaud at mancala.cbio.uct.ac.za  Fri Sep 10 16:55:29 2010
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 10 Sep 2010 16:55:29 +0200
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <D611103AA7EE3B4DAE7F7D49C72B291A02D5AAF7@EXMAIL2.bocad.bank-banque-canada.ca>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
	<D611103AA7EE3B4DAE7F7D49C72B291A02D5AAF7@EXMAIL2.bocad.bank-banque-canada.ca>
Message-ID: <4C8A46E1.1020203@cbio.uct.ac.za>

Thanks Paul for the hints.
After some tests, reducing portion of my code, I found that simply doing 
a naive computation of 'crossprod' in C does NOT give exactly the same 
results as calling the Fortran underlying routine (dsyrk) as used in the 
R source code.
I will try the double 0.0 to see if it makes a difference.

What do you mean by

"You also need to be careful about
conversion from integer to real, to do double conversion."


?
Where are the trap in this type of conversion?
Thanks.

Renaud

On 10/09/2010 16:07, Paul Gilbert wrote:
> With fortran I have always managed to be able to get identical results
> on the same computer with the same OS. You will have trouble if you
> switch OS or hardware, or try the same hardware and OS with different
> math libraries. All the real calculations need to be double, even
> intermediate variables. Also, I've had trouble with arrays not being
> initialized to double 0.0. If you initialize to single 0.0 the
> straggling bits can cause differences. You also need to be careful about
> conversion from integer to real, to do double conversion. I'm not sure
> about C, but I would guess there are some of the same problems.
>
> Paul
>
>    
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Renaud Gaujoux
>> Sent: September 10, 2010 6:47 AM
>> To: r-devel at r-project.org
>> Subject: [Rd] Non identical numerical results from R code vs C/C++
>>      
> code?
>    
>> Hi,
>>
>> suppose you have two versions of the same algorithm: one in pure R, the
>> other one in C/C++ called via .Call().
>> Assuming there is no bug in the implementations (i.e. they both do the
>> same thing), is there any well known reason why the C/C++
>>      
> implementation
>    
>> could return numerical results non identical to the one obtained from
>> the pure R code? (e.g. could it be rounding errors? please explain.)
>> Has anybody had a similar experience?
>>
>> By not identical, I mean very small differences (<  2.4 e-14), but
>>      
> enough
>    
>> to have identical() returning FALSE. Maybe I should not bother, but I
>> want to be sure where the differences come from, at least by mere
>> curiosity.
>>
>> Briefly the R code perform multiple matrix product; the C code is an
>> optimization of those specific products via custom for loops, where
>> entries are not computed in the same order, etc... which improves both
>> memory usage and speed. The result is theoretically the same.
>>
>> Thank you,
>> Renaud
>>
>> --
>> Renaud Gaujoux
>> Computational Biology - University of Cape Town
>> South Africa
>>
>>
>>
>>
>> ###
>> UNIVERSITY OF CAPE TOWN
>>
>> This e-mail is subject to the UCT ICT policies and e-mail disclaimer
>> published on our website at
>> http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from
>> +27 21 650 4500. This e-mail is intended only for the person(s) to whom
>> it is addressed. If the e-mail has reached you in error, please notify
>> the author. If you are not the intended recipient of the e-mail you may
>> not use, disclose, copy, redirect or print the content. If this e-mail
>> is not related to the business of UCT it is sent by the sender in the
>> sender's individual capacity.
>>
>> ###
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>      
> ====================================================================================
>
> La version fran?aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential ...{{dropped:27}}


From r.ted.byers at gmail.com  Fri Sep 10 17:18:30 2010
From: r.ted.byers at gmail.com (Ted Byers)
Date: Fri, 10 Sep 2010 11:18:30 -0400
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <D611103AA7EE3B4DAE7F7D49C72B291A02D5AAF7@EXMAIL2.bocad.bank-banque-canada.ca>
References: <4C8A0C86.8030307@cbio.uct.ac.za>
	<D611103AA7EE3B4DAE7F7D49C72B291A02D5AAF7@EXMAIL2.bocad.bank-banque-canada.ca>
Message-ID: <AANLkTikyN1nFYuiRLBEYQGKF431ephz7FNE9WbEXne_L@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100910/b1e8b749/attachment.pl>

From marc_schwartz at me.com  Fri Sep 10 17:21:31 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 10 Sep 2010 10:21:31 -0500
Subject: [Rd] A couple of typos in ?pairwise.t.test
Message-ID: <010F038F-DCD8-4943-98BB-81E4667519B1@me.com>

Hi all,

After my reply on R-Help to the relevant thread, I noted what appear to be a couple of typos in the Details section of ?pairwise.t.test. Note text with '**'.

Current text:

The **pool.SD** switch calculates a common SD for all groups and **used** that for all comparisons (this can be useful if some groups are small). This method does not actually call t.test, so extra arguments are ignored. Pooling does not generalize to paired tests so **pool.SD** and paired cannot both be TRUE.


Proposed new text:

The **pool.sd** switch calculates a common SD for all groups and **uses** that for all comparisons (this can be useful if some groups are small). This method does not actually call t.test, so extra arguments are ignored. Pooling does not generalize to paired tests so **pool.sd** and paired cannot both be TRUE.


If that is acceptable, a text file with a patch against the main svn trunk version of pairwise.t.test.Rd is attached.

Regards,

Marc Schwartz


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100910/6b48cf8e/attachment.txt>
-------------- next part --------------



From pdalgd at gmail.com  Fri Sep 10 17:27:28 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 10 Sep 2010 17:27:28 +0200
Subject: [Rd] A couple of typos in ?pairwise.t.test
In-Reply-To: <010F038F-DCD8-4943-98BB-81E4667519B1@me.com>
References: <010F038F-DCD8-4943-98BB-81E4667519B1@me.com>
Message-ID: <984B47AC-0D30-4DEF-92B9-2814DBBC55E7@gmail.com>


On Sep 10, 2010, at 17:21 , Marc Schwartz wrote:

> Hi all,
> 
> After my reply on R-Help to the relevant thread, I noted what appear to be a couple of typos in the Details section of ?pairwise.t.test. Note text with '**'.
> 
> Current text:
> 
> The **pool.SD** switch calculates a common SD for all groups and **used** that for all comparisons (this can be useful if some groups are small). This method does not actually call t.test, so extra arguments are ignored. Pooling does not generalize to paired tests so **pool.SD** and paired cannot both be TRUE.
> 
> 
> Proposed new text:
> 
> The **pool.sd** switch calculates a common SD for all groups and **uses** that for all comparisons (this can be useful if some groups are small). This method does not actually call t.test, so extra arguments are ignored. Pooling does not generalize to paired tests so **pool.sd** and paired cannot both be TRUE.
> 
> 
> If that is acceptable, a text file with a patch against the main svn trunk version of pairwise.t.test.Rd is attached.

Consider it done... Thanks.
-pd

> 
> Regards,
> 
> Marc Schwartz
> 
> 
> <patch.txt>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tlumley at u.washington.edu  Fri Sep 10 18:38:25 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 10 Sep 2010 09:38:25 -0700 (PDT)
Subject: [Rd] Non identical numerical results from R code vs C/C++ code?
In-Reply-To: <4C8A1414.2010909@gmail.com>
Message-ID: <alpine.LRH.2.01.1009100938250.21558@hymn34.u.washington.edu>

On Fri, 10 Sep 2010, Duncan Murdoch wrote:

> On 10/09/2010 7:07 AM, Renaud Gaujoux wrote:
>> Thank you Duncan for your reply.
>> 
>> Currently I am using 'double' for the computations.
>> What type should I use for extended real in my intermediate computations?
>
> I think it depends on compiler details.  On some compilers "long double" will 
> get it, but I don't think there's a standard type that works on all 
> compilers.  (In fact, the 80 bit type on Intel chips isn't necessarily 
> supported on other hardware.)  R defines LDOUBLE in its header files and it 
> is probably best to use that if you want to duplicate R results.

As a little more detail, 'long double' is in the C99 standard and seems to be fairly widely implemented, so code using it is likely to compile.   The Standard, as usual, doesn't define exactly what type it is, and permits it to be a synonym for 'double', so you may not get any extra precision.

On Intel chips it is likely to be the 80-bit type, but the Sparc architecture doesn't have any larger hardware type.  Radford Neal has recently reported much slower results on Solaris with long double, consistent with Wikipedia's statement that long double is sometimes a software-implemented 128-bit type on these systems.


>> The result will still be 'double' anyway right?
>
> Yes, you do need to return type double.
>
> Duncan Murdoch
>
>> 
>> 
>> 
>> On 10/09/2010 13:00, Duncan Murdoch wrote:
>>> On 10/09/2010 6:46 AM, Renaud Gaujoux wrote:
>>>> Hi,
>>>> 
>>>> suppose you have two versions of the same algorithm: one in pure R, the 
>>>> other one in C/C++ called via .Call().
>>>> Assuming there is no bug in the implementations (i.e. they both do the 
>>>> same thing), is there any well known reason why the C/C++ implementation 
>>>> could return numerical results non identical to the one obtained from the 
>>>> pure R code? (e.g. could it be rounding errors? please explain.)
>>>> Has anybody had a similar experience?
>>> R often uses extended reals (80 bit floating point values on Intel chips) 
>>> for intermediate values.  C compilers may or may not do that.
>>>> By not identical, I mean very small differences (< 2.4 e-14), but enough 
>>>> to have identical() returning FALSE. Maybe I should not bother, but I 
>>>> want to be sure where the differences come from, at least by mere 
>>>> curiosity.
>>>> 
>>>> Briefly the R code perform multiple matrix product; the C code is an 
>>>> optimization of those specific products via custom for loops, where 
>>>> entries are not computed in the same order, etc... which improves both 
>>>> memory usage and speed. The result is theoretically the same.
>>> Changing the order of operations will often affect rounding.  For example, 
>>> suppose epsilon is the smallest number such that 1 + epsilon is not equal 
>>> to 1.  Then 1 + (epsilon/2) + (epsilon/2) will evaluate to either 1 or 1 + 
>>> epsilon, depending on the order of computing the additions.
>>> 
>>> Duncan Murdoch
>>> 
>>>> Thank you,
>>>> Renaud
>>>> 
>> 
>>  
>> ###
>> UNIVERSITY OF CAPE TOWN 
>> This e-mail is subject to the UCT ICT policies and e-mail disclaimer 
>> published on our website at 
>> http://www.uct.ac.za/about/policies/emaildisclaimer/ or obtainable from +27 
>> 21 650 4500. This e-mail is intended only for the person(s) to whom it is 
>> addressed. If the e-mail has reached you in error, please notify the 
>> author. If you are not the intended recipient of the e-mail you may not 
>> use, disclose, copy, redirect or print the content. If this e-mail is not 
>> related to the business of UCT it is sent by the sender in the sender's 
>> individual capacity.
>> 
>> ###
>>  
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley
Professor of Biostatistics
University of Washington, Seattle


From daniel.cegielka at gmail.com  Fri Sep 10 19:27:00 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Fri, 10 Sep 2010 19:27:00 +0200
Subject: [Rd] [xts,
	quantmod] segfault probelm when I work with memcpy function
Message-ID: <AANLkTi=ex+XJ-Vxrnqhv4t1tjE6kfYdwtSwTEpGDyrpY@mail.gmail.com>

Hi,

I work with SEXP C code and with xts and quantmod packages. I try to
touch how xts internal works.

So we have R session and:

> ls()
character(0)
> getSymbols('AAPL')     # quantmod package
[1] "AAPL"
> ls()
[1] "AAPL"
> str(AAPL)
An ?xts? object from 2007-01-03 to 2010-09-09 containing:
  Data: num [1:929, 1:6] 86.3 84 85.8 86 86.5 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:6] "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" ...
  Indexed by objects of class: [Date] TZ:
  xts Attributes:
List of 2
 $ src    : chr "yahoo"
 $ updated: POSIXct[1:1], format: "2010-09-10 18:42:10"
> tail(AAPL,5)
           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
2010-09-02    251.26    252.17   248.57     252.17    14811900        252.17
2010-09-03    255.09    258.78   254.50     258.77    18580100        258.77
2010-09-07    256.64    259.53   256.25     257.81    12234200        257.81
2010-09-08    259.78    264.39   259.10     262.92    18777000        262.92
2010-09-09    265.04    266.52   262.92     263.07    15642700        263.07
>
> q()
Save workspace image? [y/n/c]: y
[danice at entropy ~]$


It's looks, that xts data in mamory looks like this (Open=o,High=h,Low=l etc):

ooooo(...)ohhhhh(...)hlllll(...)lccccc(...)cvvvvv(...)vaaaaa(...)a

So if I want to read Open price I need to read this array (from C
code) from x[0] to x[nrow(x)-1] where x is the pointer do AAPL.


I have to test functions - one based on memcpy and second based on for loop:


#include <R.h>
#include <Rinternals.h>

SEXP open(SEXP x) {
        int nr=nrows(x);
        SEXP r;
        PROTECT(r=allocVector(REALSXP,nr));

        memcpy(&REAL(r)[0],&REAL(x)[0],nr*sizeof(double));

        UNPROTECT(1);
        return(r);
}


SEXP open2(SEXP x) {
        int P=0;
        if (TYPEOF(x) != REALSXP) { PROTECT(x = coerceVector(x,REALSXP)); P++; }
        double *d_x = REAL(x);
        int nr = nrows(x);

        SEXP s;
        PROTECT(s = allocVector(REALSXP,nr));
        P++;
        double *d_s = REAL(s);

        int i;
        for (i=0;i<nr;i++) d_s[i] = d_x[i];

        UNPROTECT(P);
        return(s);
}

We starts R session again and:


> # we have AAPL data in memory
>
> ls()
[1] "AAPL"
> tail(AAPL)
           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
2010-09-02    251.26    252.17   248.57     252.17    14811900        252.17
2010-09-03    255.09    258.78   254.50     258.77    18580100        258.77
2010-09-07    256.64    259.53   256.25     257.81    12234200        257.81
2010-09-08    259.78    264.39   259.10     262.92    18777000        262.92
2010-09-09    265.04    266.52   262.92     263.07    15642700        263.07
>
> # now we call do open2 function
>
> .Call('open2',AAPL)
  [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
84.86  86.23  84.12

(...)

>
> # and now call to open based on memcpy
>
> .Call('open',AAPL)
  [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
84.86  86.23  84.12

(...)



AND HERE IS MY PROBLEM:

We download new data:

> getSymbols('IBM')
[1] "IBM"
>
> ####    WE DOWNLOAD NEW DATA
>
> getSymbols('IBM')
[1] "IBM"
>
> # and try open2 function (based on for loop)
>
> .Call('open2',AAPL)
  [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
97.56  92.10  88.63  89.14

(...)

>
> # now we try open function based on memcpy
> # ... and we will have a segfault
>
> .Call('open',AAPL)

 *** caught segfault ***
address 0x2, cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 3


I have this problem only if I download new data...

Do someone know how can I solve this memcpy problem? memcpy should be
much faster in this kind of area... and I want to write some C based
extensions for xts package.

Best regards,
daniel


From brian at braverock.com  Fri Sep 10 20:32:03 2010
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 10 Sep 2010 13:32:03 -0500
Subject: [Rd] [xts,
 quantmod] segfault probelm when I work with memcpy function
In-Reply-To: <AANLkTi=ex+XJ-Vxrnqhv4t1tjE6kfYdwtSwTEpGDyrpY@mail.gmail.com>
References: <AANLkTi=ex+XJ-Vxrnqhv4t1tjE6kfYdwtSwTEpGDyrpY@mail.gmail.com>
Message-ID: <4C8A79A3.1030803@braverock.com>

Daniel,

I haven't tried your example, but I wonder why you aren't using C 
accessor methods defined by xts itself or at least derived from the 
significant amounts of C code in xts.

For example, your test code seems to bear a close resemblance in 
principle to coredata.c, but you don't appear to have used or derived 
from that code.

I understand that your 'real' problem is likely different from your 
contrived example, but it still seems that you should leverage the C 
code already in xts where possible.

Regards,

    - Brian

On 09/10/2010 12:27 PM, Daniel Cegie?ka wrote:
> Hi,
>
> I work with SEXP C code and with xts and quantmod packages. I try to
> touch how xts internal works.
>
> So we have R session and:
>
>> ls()
> character(0)
>> getSymbols('AAPL')     # quantmod package
> [1] "AAPL"
>> ls()
> [1] "AAPL"
>> str(AAPL)
> An ?xts? object from 2007-01-03 to 2010-09-09 containing:
>    Data: num [1:929, 1:6] 86.3 84 85.8 86 86.5 ...
>   - attr(*, "dimnames")=List of 2
>    ..$ : NULL
>    ..$ : chr [1:6] "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" ...
>    Indexed by objects of class: [Date] TZ:
>    xts Attributes:
> List of 2
>   $ src    : chr "yahoo"
>   $ updated: POSIXct[1:1], format: "2010-09-10 18:42:10"
>> tail(AAPL,5)
>             AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
> 2010-09-02    251.26    252.17   248.57     252.17    14811900        252.17
> 2010-09-03    255.09    258.78   254.50     258.77    18580100        258.77
> 2010-09-07    256.64    259.53   256.25     257.81    12234200        257.81
> 2010-09-08    259.78    264.39   259.10     262.92    18777000        262.92
> 2010-09-09    265.04    266.52   262.92     263.07    15642700        263.07
>>
>> q()
> Save workspace image? [y/n/c]: y
> [danice at entropy ~]$
>
>
> It's looks, that xts data in mamory looks like this (Open=o,High=h,Low=l etc):
>
> ooooo(...)ohhhhh(...)hlllll(...)lccccc(...)cvvvvv(...)vaaaaa(...)a
>
> So if I want to read Open price I need to read this array (from C
> code) from x[0] to x[nrow(x)-1] where x is the pointer do AAPL.
>
>
> I have to test functions - one based on memcpy and second based on for loop:
>
>
> #include<R.h>
> #include<Rinternals.h>
>
> SEXP open(SEXP x) {
>          int nr=nrows(x);
>          SEXP r;
>          PROTECT(r=allocVector(REALSXP,nr));
>
>          memcpy(&REAL(r)[0],&REAL(x)[0],nr*sizeof(double));
>
>          UNPROTECT(1);
>          return(r);
> }
>
>
> SEXP open2(SEXP x) {
>          int P=0;
>          if (TYPEOF(x) != REALSXP) { PROTECT(x = coerceVector(x,REALSXP)); P++; }
>          double *d_x = REAL(x);
>          int nr = nrows(x);
>
>          SEXP s;
>          PROTECT(s = allocVector(REALSXP,nr));
>          P++;
>          double *d_s = REAL(s);
>
>          int i;
>          for (i=0;i<nr;i++) d_s[i] = d_x[i];
>
>          UNPROTECT(P);
>          return(s);
> }
>
> We starts R session again and:
>
>
>> # we have AAPL data in memory
>>
>> ls()
> [1] "AAPL"
>> tail(AAPL)
>             AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted
> 2010-09-02    251.26    252.17   248.57     252.17    14811900        252.17
> 2010-09-03    255.09    258.78   254.50     258.77    18580100        258.77
> 2010-09-07    256.64    259.53   256.25     257.81    12234200        257.81
> 2010-09-08    259.78    264.39   259.10     262.92    18777000        262.92
> 2010-09-09    265.04    266.52   262.92     263.07    15642700        263.07
>>
>> # now we call do open2 function
>>
>> .Call('open2',AAPL)
>    [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
> 97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
> 84.86  86.23  84.12
>
> (...)
>
>>
>> # and now call to open based on memcpy
>>
>> .Call('open',AAPL)
>    [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
> 97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
> 84.86  86.23  84.12
>
> (...)
>
>
>
> AND HERE IS MY PROBLEM:
>
> We download new data:
>
>> getSymbols('IBM')
> [1] "IBM"
>>
>> ####    WE DOWNLOAD NEW DATA
>>
>> getSymbols('IBM')
> [1] "IBM"
>>
>> # and try open2 function (based on for loop)
>>
>> .Call('open2',AAPL)
>    [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
> 97.56  92.10  88.63  89.14
>
> (...)
>
>>
>> # now we try open function based on memcpy
>> # ... and we will have a segfault
>>
>> .Call('open',AAPL)
>
>   *** caught segfault ***
> address 0x2, cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 3
>
>
> I have this problem only if I download new data...
>
> Do someone know how can I solve this memcpy problem? memcpy should be
> much faster in this kind of area... and I want to write some C based
> extensions for xts package.
>
> Best regards,
> daniel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From daniel.cegielka at gmail.com  Fri Sep 10 21:11:18 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Fri, 10 Sep 2010 21:11:18 +0200
Subject: [Rd] [xts,
	quantmod] segfault probelm when I work with memcpy function
In-Reply-To: <4C8A79A3.1030803@braverock.com>
References: <AANLkTi=ex+XJ-Vxrnqhv4t1tjE6kfYdwtSwTEpGDyrpY@mail.gmail.com>
	<4C8A79A3.1030803@braverock.com>
Message-ID: <AANLkTimacK5TzcHPgJLm0Ygt2t5RU4TjFErmRgiYsQ+k@mail.gmail.com>

W dniu 10 wrze?nia 2010 20:32 u?ytkownik Brian G. Peterson
<brian at braverock.com> napisa?:
> Daniel,
>
> I haven't tried your example, but I wonder why you aren't using C accessor
> methods defined by xts itself or at least derived from the significant
> amounts of C code in xts.
>
> For example, your test code seems to bear a close resemblance in principle
> to coredata.c, but you don't appear to have used or derived from that code.

I want to have a better expertise with SEXP and R and I hope in the
future I want to help to develop some R financial packages (xts, TTR
and blotter). So this is my main motivation.

>
> I understand that your 'real' problem is likely different from your
> contrived example, but it still seems that you should leverage the C code
> already in xts where possible.

I study xts code :) I could write some indicator in C and build xts
object directly from C, so you have only .Call('myind',IBM) and it's
return xts object. On large data and when you need to call this
function with high frequency it's much more faster then
.xts(.Call('myind',Cl(IBM)),getAttrib(IBM,'index')).

regards,
daniel


>
> Regards,
>
>   - Brian
>
> On 09/10/2010 12:27 PM, Daniel Cegie?ka wrote:
>>
>> Hi,
>>
>> I work with SEXP C code and with xts and quantmod packages. I try to
>> touch how xts internal works.
>>
>> So we have R session and:
>>
>>> ls()
>>
>> character(0)
>>>
>>> getSymbols('AAPL')     # quantmod package
>>
>> [1] "AAPL"
>>>
>>> ls()
>>
>> [1] "AAPL"
>>>
>>> str(AAPL)
>>
>> An 'xts' object from 2007-01-03 to 2010-09-09 containing:
>>   Data: num [1:929, 1:6] 86.3 84 85.8 86 86.5 ...
>>  - attr(*, "dimnames")=List of 2
>>   ..$ : NULL
>>   ..$ : chr [1:6] "AAPL.Open" "AAPL.High" "AAPL.Low" "AAPL.Close" ...
>>   Indexed by objects of class: [Date] TZ:
>>   xts Attributes:
>> List of 2
>>  $ src    : chr "yahoo"
>>  $ updated: POSIXct[1:1], format: "2010-09-10 18:42:10"
>>>
>>> tail(AAPL,5)
>>
>>            AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume
>> AAPL.Adjusted
>> 2010-09-02    251.26    252.17   248.57     252.17    14811900
>>  252.17
>> 2010-09-03    255.09    258.78   254.50     258.77    18580100
>>  258.77
>> 2010-09-07    256.64    259.53   256.25     257.81    12234200
>>  257.81
>> 2010-09-08    259.78    264.39   259.10     262.92    18777000
>>  262.92
>> 2010-09-09    265.04    266.52   262.92     263.07    15642700
>>  263.07
>>>
>>> q()
>>
>> Save workspace image? [y/n/c]: y
>> [danice at entropy ~]$
>>
>>
>> It's looks, that xts data in mamory looks like this (Open=o,High=h,Low=l
>> etc):
>>
>> ooooo(...)ohhhhh(...)hlllll(...)lccccc(...)cvvvvv(...)vaaaaa(...)a
>>
>> So if I want to read Open price I need to read this array (from C
>> code) from x[0] to x[nrow(x)-1] where x is the pointer do AAPL.
>>
>>
>> I have to test functions - one based on memcpy and second based on for
>> loop:
>>
>>
>> #include<R.h>
>> #include<Rinternals.h>
>>
>> SEXP open(SEXP x) {
>>         int nr=nrows(x);
>>         SEXP r;
>>         PROTECT(r=allocVector(REALSXP,nr));
>>
>>         memcpy(&REAL(r)[0],&REAL(x)[0],nr*sizeof(double));
>>
>>         UNPROTECT(1);
>>         return(r);
>> }
>>
>>
>> SEXP open2(SEXP x) {
>>         int P=0;
>>         if (TYPEOF(x) != REALSXP) { PROTECT(x = coerceVector(x,REALSXP));
>> P++; }
>>         double *d_x = REAL(x);
>>         int nr = nrows(x);
>>
>>         SEXP s;
>>         PROTECT(s = allocVector(REALSXP,nr));
>>         P++;
>>         double *d_s = REAL(s);
>>
>>         int i;
>>         for (i=0;i<nr;i++) d_s[i] = d_x[i];
>>
>>         UNPROTECT(P);
>>         return(s);
>> }
>>
>> We starts R session again and:
>>
>>
>>> # we have AAPL data in memory
>>>
>>> ls()
>>
>> [1] "AAPL"
>>>
>>> tail(AAPL)
>>
>>            AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume
>> AAPL.Adjusted
>> 2010-09-02    251.26    252.17   248.57     252.17    14811900
>>  252.17
>> 2010-09-03    255.09    258.78   254.50     258.77    18580100
>>  258.77
>> 2010-09-07    256.64    259.53   256.25     257.81    12234200
>>  257.81
>> 2010-09-08    259.78    264.39   259.10     262.92    18777000
>>  262.92
>> 2010-09-09    265.04    266.52   262.92     263.07    15642700
>>  263.07
>>>
>>> # now we call do open2 function
>>>
>>> .Call('open2',AAPL)
>>
>>   [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
>> 97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
>> 84.86  86.23  84.12
>>
>> (...)
>>
>>>
>>> # and now call to open based on memcpy
>>>
>>> .Call('open',AAPL)
>>
>>   [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
>> 97.56  92.10  88.63  89.14  85.73  86.68  87.11  87.11  86.30  86.43
>> 84.86  86.23  84.12
>>
>> (...)
>>
>>
>>
>> AND HERE IS MY PROBLEM:
>>
>> We download new data:
>>
>>> getSymbols('IBM')
>>
>> [1] "IBM"
>>>
>>> ####    WE DOWNLOAD NEW DATA
>>>
>>> getSymbols('IBM')
>>
>> [1] "IBM"
>>>
>>> # and try open2 function (based on for loop)
>>>
>>> .Call('open2',AAPL)
>>
>>   [1]  86.29  84.05  85.77  85.96  86.45  94.75  95.94  94.59  95.68
>> 97.56  92.10  88.63  89.14
>>
>> (...)
>>
>>>
>>> # now we try open function based on memcpy
>>> # ... and we will have a segfault
>>>
>>> .Call('open',AAPL)
>>
>>  *** caught segfault ***
>> address 0x2, cause 'memory not mapped'
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection: 3
>>
>>
>> I have this problem only if I download new data...
>>
>> Do someone know how can I solve this memcpy problem? memcpy should be
>> much faster in this kind of area... and I want to write some C based
>> extensions for xts package.
>>
>> Best regards,
>> daniel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>


From daniel.cegielka at gmail.com  Fri Sep 10 21:32:46 2010
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Fri, 10 Sep 2010 21:32:46 +0200
Subject: [Rd] [xts,
	quantmod] segfault probelm when I work with memcpy function
In-Reply-To: <29C118A2-23AD-45ED-8404-BD7E5B693F10@r-project.org>
References: <AANLkTi=ex+XJ-Vxrnqhv4t1tjE6kfYdwtSwTEpGDyrpY@mail.gmail.com>
	<29C118A2-23AD-45ED-8404-BD7E5B693F10@r-project.org>
Message-ID: <AANLkTi=RLS=wwLb4Bo7K89r8GQ2Ht7t9GuoQRFW0kzJf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100910/20b65edf/attachment.pl>

From pooja.varshneya at gmail.com  Fri Sep 10 23:05:12 2010
From: pooja.varshneya at gmail.com (pooja varshneya)
Date: Fri, 10 Sep 2010 17:05:12 -0400
Subject: [Rd] Windows build
Message-ID: <AANLkTi=_LmP8Ycp6SCrqMSZ9xgTJJMz9njMP6N+AMvGN@mail.gmail.com>

Hi Folks,

I am trying to build R-2.11.1 from source code on Windows 2003. I am
able to build it, but when i run 'make check', it fails as follows:
Does the tests produce a log somewhere that i can use for
troubleshooting the problem ?

-------------------------------------------------------------------------------------------------
C:\R\R-2.11.1\src\gnuwin32>make check

Collecting examples for package 'base'
  Extracting from parsed Rd's ........................................
Running examples in package 'base'

Collecting examples for package 'tools'
  Extracting from parsed Rd's ....
Running examples in package 'tools'

Collecting examples for package 'utils'
  Extracting from parsed Rd's .............
Running examples in package 'utils'
Error: testing 'utils' failed
Execution halted
make[3]: *** [test-Examples-Base] Error 1
make[2]: *** [test-Examples] Error 2
make[1]: *** [test-all-basics] Error 1
make: *** [check] Error 2
------------------------------------------------------------------------------------------------

Thanks,
Pooja


From murdoch.duncan at gmail.com  Sat Sep 11 01:30:04 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Sep 2010 19:30:04 -0400
Subject: [Rd] Windows build
In-Reply-To: <AANLkTi=_LmP8Ycp6SCrqMSZ9xgTJJMz9njMP6N+AMvGN@mail.gmail.com>
References: <AANLkTi=_LmP8Ycp6SCrqMSZ9xgTJJMz9njMP6N+AMvGN@mail.gmail.com>
Message-ID: <4C8ABF7C.5010802@gmail.com>

On 10/09/2010 5:05 PM, pooja varshneya wrote:
> Hi Folks,
> 
> I am trying to build R-2.11.1 from source code on Windows 2003. I am
> able to build it, but when i run 'make check', it fails as follows:
> Does the tests produce a log somewhere that i can use for
> troubleshooting the problem ?
> 
> -------------------------------------------------------------------------------------------------
> C:\R\R-2.11.1\src\gnuwin32>make check
> 
> Collecting examples for package 'base'
>   Extracting from parsed Rd's ........................................
> Running examples in package 'base'
> 
> Collecting examples for package 'tools'
>   Extracting from parsed Rd's ....
> Running examples in package 'tools'
> 
> Collecting examples for package 'utils'
>   Extracting from parsed Rd's .............
> Running examples in package 'utils'
> Error: testing 'utils' failed
> Execution halted
> make[3]: *** [test-Examples-Base] Error 1
> make[2]: *** [test-Examples] Error 2
> make[1]: *** [test-all-basics] Error 1
> make: *** [check] Error 2

Yes, if you look in the R_HOME/tests directory, you'll see a 
subdirectory named Examples; that's where the logs of all the tests of 
examples are saved.  But I can guess at the problem:  you don't have the 
recommended packages installed.  They're needed to run the tests.  In 
Windows you get them by

make rsync-recommended
make recommended

Getting them in other OS's is slightly different, but I forget the 
details.  See the R Installation and Administration manual.

Duncan Murdoch


From hpages at fhcrc.org  Sat Sep 11 06:52:52 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 10 Sep 2010 21:52:52 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile is
	used
Message-ID: <4C8B0B24.8020609@fhcrc.org>

Hi,

I found the following problem with recent R-devel
(2010-08-26 r52817) on Windows (32-bit and 64-bit):
'R CMD build <pkg>' gets stalled during vignette
creation for packages that have a Makefile in <pkg>/inst/doc.

It seems that the problem is that the commands used in the
Makefile for converting .tex to .pdf are not able to locate
the Sweave.sty file anymore (if I drop this file to
<pkg>/inst/doc, then the problem goes away).

I noticed that the location of Sweave.sty shipped with
R has changed recently (moved from ${R_HOME}/share/texmf
to ${R_HOME}/share/texmf/tex/latex/). Could that be related
to the problem?

I don't see that problem on platforms other than Windows or
with R < 2.12

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Sat Sep 11 12:56:04 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 11 Sep 2010 06:56:04 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8B0B24.8020609@fhcrc.org>
References: <4C8B0B24.8020609@fhcrc.org>
Message-ID: <4C8B6044.1030506@gmail.com>

On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
> Hi,
> 
> I found the following problem with recent R-devel
> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
> 'R CMD build <pkg>' gets stalled during vignette
> creation for packages that have a Makefile in <pkg>/inst/doc.
> 
> It seems that the problem is that the commands used in the
> Makefile for converting .tex to .pdf are not able to locate
> the Sweave.sty file anymore (if I drop this file to
> <pkg>/inst/doc, then the problem goes away).

This sounds like a problem that only the package maintainer could 
address.  Presumably it will be temporary:  once they adjust to the new 
organization of the share/texmf directory, things will be fine again.

The reorg is described in this NEWS item:

     * Directory R_HOME/share/texmf now follows the TDS conventions, so
       can be set as a texmf tree ('root directory' in MiKTeX parlance).

Duncan Murdoch

> 
> I noticed that the location of Sweave.sty shipped with
> R has changed recently (moved from ${R_HOME}/share/texmf
> to ${R_HOME}/share/texmf/tex/latex/). Could that be related
> to the problem?
> 
> I don't see that problem on platforms other than Windows or
> with R < 2.12
> 
> Thanks,
> H.
>


From jackman at stanford.edu  Sat Sep 11 18:42:42 2010
From: jackman at stanford.edu (Simon Jackman)
Date: Sat, 11 Sep 2010 09:42:42 -0700
Subject: [Rd] Sweave issue; keep.source=TRUE and cacheSweave incompatible?
Message-ID: <0C2897B3-DDD3-4CD3-81AA-2D586469BC83@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100911/158f5490/attachment.pl>

From hpages at fhcrc.org  Sun Sep 12 06:49:17 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 11 Sep 2010 21:49:17 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8B6044.1030506@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
Message-ID: <4C8C5BCD.4000207@fhcrc.org>

Hi Duncan,

On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>> Hi,
>>
>> I found the following problem with recent R-devel
>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>> 'R CMD build <pkg>' gets stalled during vignett
>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>
>> It seems that the problem is that the commands used in the
>> Makefile for converting .tex to .pdf are not able to locate
>> the Sweave.sty file anymore (if I drop this file to
>> <pkg>/inst/doc, then the problem goes away).
>
> This sounds like a problem that only the package maintainer could
> address. Presumably it will be temporary: once they adjust to the new
> organization of the share/texmf directory, things will be fine again.
>
> The reorg is described in this NEWS item:
>
> * Directory R_HOME/share/texmf now follows the TDS conventions, so
> can be set as a texmf tree ('root directory' in MiKTeX parlance).

Before this reorg, the package maintainer didn't have to care about
where to find things in R_HOME/share/texmf. 'R CMD build' would just
find them by setting the TEXINPUTS envir variable appropriately (and
then commands in the inst/doc/Makefile file would find them too).

This reorg was checked in svn as rev 52256. I see the following
adjustments to TEXINPUTS:

   ** On Unix (src/scripts/Rcmd.in file):

-## Append 'share/texmf' to TeX's input search path.
-if test -z "$TEXINPUTS}"; then
-  TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
+## Append 'share/texmf/...' to TeX's input search path.
+if test -z "${TEXINPUTS}"; then
+  TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
  else
-  TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
+  TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
  fi
  export TEXINPUTS

   ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):

-TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
+TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;

The path seems to have been adjusted correctly. So my question is:
why isn't this working on Windows for packages that use a Makefile?

Thanks,
H.


>
> Duncan Murdoch
>
>>
>> I noticed that the location of Sweave.sty shipped with
>> R has changed recently (moved from ${R_HOME}/share/texmf
>> to ${R_HOME}/share/texmf/tex/latex/). Could that be related
>> to the problem?
>>
>> I don't see that problem on platforms other than Windows or
>> with R < 2.12
>>
>> Thanks,
>> H.
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Sun Sep 12 08:10:19 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 11 Sep 2010 23:10:19 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
Message-ID: <4C8C6ECB.5080705@fhcrc.org>

Hi,

This is a follow up to:

   https://stat.ethz.ch/pipermail/r-devel/2010-July/057921.html

The Bioconductor daily builds have been reporting a lot of strange
things lately on Windows using R-2.12. This started 2 or 3 months
ago and things are not getting better with recent R-2.12.
Here is a sample from today's build results. We use Windows Server
2003 R2 for the 32-bit builds, Windows Server 2008 R2 Enterprise
for the 64-bit builds, and R-2.12 (2010-08-26 r52817) on both machines:


 >>> On 64-bit Windows:

R\bin\R.exe CMD build ACME
--> produces no output at all and returns code 0.


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings affypdnn_1.23.0.tar.gz
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--no-vignettes'
* checking for file 'affypdnn/DESCRIPTION' ... OK
* this is package 'affypdnn' version '1.23.0'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'affypdnn' can be installed ...Warning in 
file(con, "r") :
   cannot open file 
'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck/00install.out': No such 
file or directory
Error in file(con, "r") : cannot open the connection
Execution halted


 >>> On 32-bit Windows:

R\bin\R.exe CMD build ArrayTools
* checking for file 'ArrayTools/DESCRIPTION' ... OK
* preparing 'ArrayTools':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
       -----------------------------------
Warning: unknown option '-l'
* checking for file 
'E:\biocbld\bbs-2.7-bioc\tmpdir\Rtmpg0MxFa\Rinst69801ce4/DESCRIPTION' ... NO
       -----------------------------------
ERROR: Installation failed
Removing installation dir


 >>> On 64-bit Windows:

R\bin\R.exe CMD build baySeq
* checking for file 'baySeq/DESCRIPTION' ... OK
* preparing 'baySeq':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* creating vignettes ... ERROR
Error: ERROR: no packages specified


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings BioSeqClass_1.7.0.tar.gz
Warning: unknown option '--no-vignettes'
Warning: unknown option '--timings'
Converting Rd files to LaTeX ...
   BioSeqClass_1.7.0.tar.gz
Warning in readLines(f) :
   incomplete final line found on 'BioSeqClass_1.7.0.tar.gz'
Warning in parse_Rd("BioSeqClass_1.7.0.tar.gz", encoding = "unknown", 
fragment = FALSE,  :
   BioSeqClass_1.7.0.tar.gz:2: unexpected UNKNOWN '\?'
Warning: BioSeqClass_1.7.0.tar.gz:1: All text must be in a section
Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
Warning: BioSeqClass_1.7.0.tar.gz:3: All text must be in a section
Warning: BioSeqClass_1.7.0.tar.gz:4: All text must be in a section
Error : BioSeqClass_1.7.0.tar.gz: Sections \title, and \name must exist 
and be unique in Rd files


 >>> On 64-bit Windows:

R\bin\R.exe CMD build BufferedMatrix
--> produces no output at all and returns code 0.


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings daMA_1.21.0.tar.gz
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--no-vignettes'
* checking for file 'daMA/DESCRIPTION' ... OK
* this is package 'daMA' version '1.21.0'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'daMA' can be installed ...Warning in 
file(con, "r") :
   cannot open file 
'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck/00install.out': No such file 
or directory
Error in file(con, "r") : cannot open the connection
Execution halted


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings ddCt_1.3.2.tar.gz
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--no-vignettes'
* checking for file 'ddCt/DESCRIPTION' ... OK
* this is package 'ddCt' version '1.3.2'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'ddCt' can be installed ...Warning in 
file(con, "r") :
   cannot open file 
'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck/00install.out': No such file 
or directory
Error in file(con, "r") : cannot open the connection
Execution halted


 >>> On 64-bit Windows:

R\bin\R.exe CMD build GEOmetadb
* checking for file 'GEOmetadb/DESCRIPTION' ... OK
* preparing 'GEOmetadb':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* creating vignettes ... ERROR
Error: ERROR: no packages specified


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings IRanges_1.7.33.tar.gz
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--no-vignettes'
* checking for file 'IRanges/DESCRIPTION' ... OK
* this is package 'IRanges' version '1.7.33'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'IRanges' can be installed ... ERROR
Installation failed.
See 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck/00install.out' for details.

Content of IRanges.Rcheck/00install.out:

* install options '--no-html --no-multiarch'

Warning: unknown option '-l'
Warning: unknown option '--no-html'
Warning: unknown option '--no-multiarch'
Error in .pkg2tex(files, outfile, encoding = encoding, append = append,  :
   this package does not have either a 'latex' or a (source) 'man' directory


 >>> On 32-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings keggorthology_2.1.1.tar.gz
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--no-vignettes'
* checking for file 'keggorthology/DESCRIPTION' ... OK
* this is package 'keggorthology' version '2.1.1'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'keggorthology' can be installed ... ERROR
Installation failed.
See 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck/00install.out' 
for details.

Content of keggorthology.Rcheck/00install.out:

* install options '--no-html --no-multiarch'

Warning: unknown option '--no-html'
* using log directory 'E:/biocbld/bbs-2.7-bioc/meat/KEGGOR?1.Rcheck'
* using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* checking for file 'KEGGOR?1/DESCRIPTION' ... OK
* this is package 'keggorthology' version '2.1.1'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'keggorthology' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... ERROR
Error in library(KEGGOR ? 1) : 'package' must be of length 1
Execution halted

It looks like this package has a loading problem: see the messages for
details.


 >>> On 64-bit Windows:

R\bin\R.exe CMD check --no-vignettes --timings OLIN_1.27.0.tar.gz
Warning: unknown option '--no-vignettes'
Warning: unknown option '--timings'
Converting Rd files to LaTeX ...
   OLIN_1.27.0.tar.gz
Warning in readLines(f) :
   incomplete final line found on 'OLIN_1.27.0.tar.gz'
Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment 
= FALSE,  :
   OLIN_1.27.0.tar.gz:2: unexpected '}'
Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment 
= FALSE,  :
   OLIN_1.27.0.tar.gz:4: unexpected '}'
Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment 
= FALSE,  :
   OLIN_1.27.0.tar.gz:7: unexpected '{'
Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment 
= FALSE,  :
   OLIN_1.27.0.tar.gz:8: unexpected '}'
Warning: OLIN_1.27.0.tar.gz:1: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:3: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:5: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:6: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
Error : OLIN_1.27.0.tar.gz: Sections \title, and \name must exist and be 
unique in Rd files


 >>> and so on...


AFAICT those problems were never seen before (i.e. with R < 2.12).
They show up randomly everyday for a small number of packages
(between 10 and 20 out of 400). The set of victims changes everyday
and any package seems to be a potential victim (I've not been able
to observe any obvious pattern so far).
Does anyone have any idea what could make 'R CMD build' and
'R CMD check' so confused/unreliable on Windows?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pdalgd at gmail.com  Sun Sep 12 10:51:47 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Sun, 12 Sep 2010 10:51:47 +0200
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8C6ECB.5080705@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org>
Message-ID: <4C8C94A3.3080600@gmail.com>

On 09/12/2010 08:10 AM, Herv? Pag?s wrote:
...
> 
> AFAICT those problems were never seen before (i.e. with R < 2.12).
> They show up randomly everyday for a small number of packages
> (between 10 and 20 out of 400). The set of victims changes everyday
> and any package seems to be a potential victim (I've not been able
> to observe any obvious pattern so far).
> Does anyone have any idea what could make 'R CMD build' and
> 'R CMD check' so confused/unreliable on Windows?
> 
> Thanks,
> H.
> 

Antivirus software? I suspect you already ruled that out, but it has
been the culprit for problems with mysteriously disappearing
intermediate files in several cases, so I thought I'd mention it.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hpages at fhcrc.org  Sun Sep 12 12:10:20 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 12 Sep 2010 03:10:20 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8C94A3.3080600@gmail.com>
References: <4C8C6ECB.5080705@fhcrc.org> <4C8C94A3.3080600@gmail.com>
Message-ID: <4C8CA70C.40109@fhcrc.org>

Hi Peter,

On 09/12/2010 01:51 AM, Peter Dalgaard wrote:
> On 09/12/2010 08:10 AM, Herv? Pag?s wrote:
> ...
>>
>> AFAICT those problems were never seen before (i.e. with R<  2.12).
>> They show up randomly everyday for a small number of packages
>> (between 10 and 20 out of 400). The set of victims changes everyday
>> and any package seems to be a potential victim (I've not been able
>> to observe any obvious pattern so far).
>> Does anyone have any idea what could make 'R CMD build' and
>> 'R CMD check' so confused/unreliable on Windows?
>>
>> Thanks,
>> H.
>>
>
> Antivirus software? I suspect you already ruled that out, but it has
> been the culprit for problems with mysteriously disappearing
> intermediate files in several cases, so I thought I'd mention it.
>

Actually I didn't try that yet because we still build BioC release
(using R-2.11.1) on these 2 Windows boxes and we don't see any of
those problems for the release builds. But I will. Could it be that
the fact that 'R CMD build' and 'R CMD check' are R-based in R-2.12
(and not Perl-based anymore) make them more fragile when something
like an antivirus is messing around with the filesystem?

Thanks for the suggestion,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From patrick.giraudoux at univ-fcomte.fr  Sun Sep 12 13:53:05 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 12 Sep 2010 13:53:05 +0200
Subject: [Rd] packages update and error: no package called 'lattice',Error:
 package 'Hmisc could not be loaded; Tinn-R
Message-ID: <4C8CBF21.40608@univ-fcomte.fr>

  Dear all,

Since some months after updating packages via 
update.packages(ask='graphics'), sometimes I loose 'lattice', although 
already installed. At R restart, I get:

Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
   there is no package called 'lattice'
Error: package 'Hmisc' could not be loaded

In this case I must re-install 'lattice' and all comes back to normal 
thenafter

Here, for updating, R is started first (without Tinn-R) but  the script 
here below is in Rprofile.site (Tinn-R is the editor in standard usage).

I long hesitated to send this post before finding out when exactly 
'lattice' is removed during (or before) the update. But eventually, I am 
still messing on that.

Has anybody an idea about what may happen ?

Patrick


#===============================================================
# Tinn-R: necessary packages and functions
# Tinn-R: >= 2.1.1.2
#===============================================================
library(utils)

# check necesary packages
necessary = c('TinnR', 'svSocket')
installed = necessary %in% installed.packages()[, 'Package']
if (length(necessary[!installed]) >=1)
install.packages(necessary[!installed], dep=T)

# set options
options(use.DDE=T)
# uncoment the line below if you want Tinn-R starts
# always R starts
options(IDE='C:/Program Files/Tinn-R/bin/Tinn-R.exe')

# load packages
library(TinnR)
library(svSocket)

# start DDE
trDDEInstall()

.trPaths <- paste(paste(Sys.getenv('APPDATA'), '\\Tinn-R\\tmp\\', sep=''),
c('', 'search.txt', 'objects.txt', 'file.r', 'selection.r', 'block.r', 
'lines.r'), sep='')


From murdoch.duncan at gmail.com  Sun Sep 12 14:07:51 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 12 Sep 2010 08:07:51 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8C5BCD.4000207@fhcrc.org>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org>
Message-ID: <4C8CC297.1050405@gmail.com>

On 12/09/2010 12:49 AM, Herv? Pag?s wrote:
> Hi Duncan,
> 
> On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
>> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> I found the following problem with recent R-devel
>>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>>> 'R CMD build <pkg>' gets stalled during vignett
>>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>>
>>> It seems that the problem is that the commands used in the
>>> Makefile for converting .tex to .pdf are not able to locate
>>> the Sweave.sty file anymore (if I drop this file to
>>> <pkg>/inst/doc, then the problem goes away).
>> This sounds like a problem that only the package maintainer could
>> address. Presumably it will be temporary: once they adjust to the new
>> organization of the share/texmf directory, things will be fine again.
>>
>> The reorg is described in this NEWS item:
>>
>> * Directory R_HOME/share/texmf now follows the TDS conventions, so
>> can be set as a texmf tree ('root directory' in MiKTeX parlance).
> 
> Before this reorg, the package maintainer didn't have to care about
> where to find things in R_HOME/share/texmf. 'R CMD build' would just
> find them by setting the TEXINPUTS envir variable appropriately (and
> then commands in the inst/doc/Makefile file would find them too).
> 
> This reorg was checked in svn as rev 52256. I see the following
> adjustments to TEXINPUTS:
> 
>    ** On Unix (src/scripts/Rcmd.in file):
> 
> -## Append 'share/texmf' to TeX's input search path.
> -if test -z "$TEXINPUTS}"; then
> -  TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
> +## Append 'share/texmf/...' to TeX's input search path.
> +if test -z "${TEXINPUTS}"; then
> +  TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
>   else
> -  TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
> +  TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
>   fi
>   export TEXINPUTS
> 
>    ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):
> 
> -TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
> +TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;
> 
> The path seems to have been adjusted correctly. So my question is:
> why isn't this working on Windows for packages that use a Makefile?

I don't know.  My first assumption would that something in the Makefile 
is wrong, but since you don't give any examples, I can't check.

Duncan Murdoch


From whuber at embl.de  Sun Sep 12 18:04:55 2010
From: whuber at embl.de (Wolfgang Huber)
Date: Sun, 12 Sep 2010 18:04:55 +0200
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8B6044.1030506@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
Message-ID: <4C8CFA27.50406@embl.de>

Hi Duncan

wouldn't it be possible that by default the Sweave.sty in share/texmf is 
found by 'R CMD build' for use by package vignettes without manual 
intervention?

AfaIcs this is also how it worked in the past.

Best wishes
          Wolfgang

On Sep/11/10 12:56 PM, Duncan Murdoch wrote:
> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>> Hi,
>>
>> I found the following problem with recent R-devel
>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>> 'R CMD build <pkg>' gets stalled during vignette
>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>
>> It seems that the problem is that the commands used in the
>> Makefile for converting .tex to .pdf are not able to locate
>> the Sweave.sty file anymore (if I drop this file to
>> <pkg>/inst/doc, then the problem goes away).
>
> This sounds like a problem that only the package maintainer could
> address. Presumably it will be temporary: once they adjust to the new
> organization of the share/texmf directory, things will be fine again.
>
> The reorg is described in this NEWS item:
>
> * Directory R_HOME/share/texmf now follows the TDS conventions, so
> can be set as a texmf tree ('root directory' in MiKTeX parlance).
>
> Duncan Murdoch
>
>>
>> I noticed that the location of Sweave.sty shipped with
>> R has changed recently (moved from ${R_HOME}/share/texmf
>> to ${R_HOME}/share/texmf/tex/latex/). Could that be related
>> to the problem?
>>
>> I don't see that problem on platforms other than Windows or
>> with R < 2.12
>>
>> Thanks,
>> H.
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 


Wolfgang Huber
EMBL
http://www.embl.de/research/units/genome_biology/huber


From pooja.varshneya at gmail.com  Sun Sep 12 18:36:27 2010
From: pooja.varshneya at gmail.com (pooja varshneya)
Date: Sun, 12 Sep 2010 12:36:27 -0400
Subject: [Rd] Windows build
In-Reply-To: <4C8ABF7C.5010802@gmail.com>
References: <AANLkTi=_LmP8Ycp6SCrqMSZ9xgTJJMz9njMP6N+AMvGN@mail.gmail.com>
	<4C8ABF7C.5010802@gmail.com>
Message-ID: <AANLkTincvP5J58hihsBJRE-ND+42gOZ=h+eW5mqAu30a@mail.gmail.com>

Thanks Duncan !!
Running 'make rsync-recommended' solved the problem.

Thanks,
Pooja

On Fri, Sep 10, 2010 at 7:30 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 10/09/2010 5:05 PM, pooja varshneya wrote:
>>
>> Hi Folks,
>>
>> I am trying to build R-2.11.1 from source code on Windows 2003. I am
>> able to build it, but when i run 'make check', it fails as follows:
>> Does the tests produce a log somewhere that i can use for
>> troubleshooting the problem ?
>>
>>
>> -------------------------------------------------------------------------------------------------
>> C:\R\R-2.11.1\src\gnuwin32>make check
>>
>> Collecting examples for package 'base'
>> ?Extracting from parsed Rd's ........................................
>> Running examples in package 'base'
>>
>> Collecting examples for package 'tools'
>> ?Extracting from parsed Rd's ....
>> Running examples in package 'tools'
>>
>> Collecting examples for package 'utils'
>> ?Extracting from parsed Rd's .............
>> Running examples in package 'utils'
>> Error: testing 'utils' failed
>> Execution halted
>> make[3]: *** [test-Examples-Base] Error 1
>> make[2]: *** [test-Examples] Error 2
>> make[1]: *** [test-all-basics] Error 1
>> make: *** [check] Error 2
>
> Yes, if you look in the R_HOME/tests directory, you'll see a subdirectory
> named Examples; that's where the logs of all the tests of examples are
> saved. ?But I can guess at the problem: ?you don't have the recommended
> packages installed. ?They're needed to run the tests. ?In Windows you get
> them by
>
> make rsync-recommended
> make recommended
>
> Getting them in other OS's is slightly different, but I forget the details.
> ?See the R Installation and Administration manual.
>
> Duncan Murdoch
>


From murdoch.duncan at gmail.com  Sun Sep 12 20:45:31 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 12 Sep 2010 14:45:31 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8CFA27.50406@embl.de>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8CFA27.50406@embl.de>
Message-ID: <4C8D1FCB.3000707@gmail.com>

On 12/09/2010 12:04 PM, Wolfgang Huber wrote:
> Hi Duncan
> 
> wouldn't it be possible that by default the Sweave.sty in share/texmf is 
> found by 'R CMD build' for use by package vignettes without manual 
> intervention?

Yes, it does work that way.  What Herv? is talking about are cases where 
people use Makefiles to bypass the normal process.

Duncan Murdoch

> 
> AfaIcs this is also how it worked in the past.
> 
> Best wishes
>           Wolfgang
> 
> On Sep/11/10 12:56 PM, Duncan Murdoch wrote:
>> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> I found the following problem with recent R-devel
>>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>>> 'R CMD build <pkg>' gets stalled during vignette
>>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>>
>>> It seems that the problem is that the commands used in the
>>> Makefile for converting .tex to .pdf are not able to locate
>>> the Sweave.sty file anymore (if I drop this file to
>>> <pkg>/inst/doc, then the problem goes away).
>> This sounds like a problem that only the package maintainer could
>> address. Presumably it will be temporary: once they adjust to the new
>> organization of the share/texmf directory, things will be fine again.
>>
>> The reorg is described in this NEWS item:
>>
>> * Directory R_HOME/share/texmf now follows the TDS conventions, so
>> can be set as a texmf tree ('root directory' in MiKTeX parlance).
>>
>> Duncan Murdoch
>>
>>> I noticed that the location of Sweave.sty shipped with
>>> R has changed recently (moved from ${R_HOME}/share/texmf
>>> to ${R_HOME}/share/texmf/tex/latex/). Could that be related
>>> to the problem?
>>>
>>> I don't see that problem on platforms other than Windows or
>>> with R < 2.12
>>>
>>> Thanks,
>>> H.
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.murrell at auckland.ac.nz  Mon Sep 13 05:38:50 2010
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 13 Sep 2010 15:38:50 +1200
Subject: [Rd] [R] scalable < > delimiters in plotmath
In-Reply-To: <C28E4EB5-346D-48F0-BE9E-33A6AF74D2B3@comcast.net>
References: <AANLkTikJPdOpuDyEXyThi8-SDf1qp4RUD73K2U8mKD=O@mail.gmail.com>	<AANLkTimmFzDvrg5aEkEXXhFoWUf+eOKXk==PB6O5wrpu@mail.gmail.com>	<AANLkTimTbZ-npnPfG7E_CcR+3FUdxxKXnRf8posB-CO8@mail.gmail.com>	<4C8C2642.8090607@ucalgary.ca>	<EEFDD2EF-421E-4A6D-B130-499CF6440C38@comcast.net>	<AANLkTimaZnbJr=zaOxxz=Shon4KOjnxLNmOtUTe+Qyg1@mail.gmail.com>	<D39BC898-BDB2-4781-8E0B-8933B528A389@comcast.net>
	<AANLkTin=V6FdwGWUNpDPstKoD0RMFi_32n2kdUJ1gbcS@mail.gmail.com>
	<4C8D33E7.8000100@auckland.ac.nz>
	<C28E4EB5-346D-48F0-BE9E-33A6AF74D2B3@comcast.net>
Message-ID: <4C8D9CCA.5080208@auckland.ac.nz>

Hi

[shifting to r-devel]

On 13/09/2010 8:43 a.m., David Winsemius wrote:
>
> On Sep 12, 2010, at 4:11 PM, Paul Murrell wrote:
>
>> Hi
>>
>> On 13/09/2010 7:57 a.m., baptiste auguie wrote:
>>> Oh, right I see. I was completely off then. Maybe it's not so easy to
>>> add<>   delimiters after all, I'll have to look at the list of symbol
>>> pieces to see if these can be constructed too.
>>
>> The plotmath stuff assumes a font with an Adobe Symbol encoding.
>> The characters we have to play with are shown at http://www.stat.auckland.ac.nz/~paul/R/CM/AdobeSym.pdf
>> .
>> You can see the components of "growable" delimiters on the bottom
>> two rows.
>
> Hello Paul;
>
> Both Baptiste and I have looked at the plotmath.c code and it appears
> that only a few of those delimiters are supported. We specifically
> have tried to use the angle brackets:
>
>   >  plot(1,1,
> xlab=expression(bgroup(symbol(0xe1),atop(x,y),symbol(0xf1))))
> Error in bgroup(symbol(225), atop(x, y), symbol(241)) :
>     invalid group delimiter
>
> The supported delimiters appear to each be built up from three parts
> that are then assembled within a bounding box and as far as I can
> determine are limited to "|", "||", "[", "{", "(", ")", "}",and "}". I
> needed to download the full source to find a copy, but I'm fairly sure
> a guRu of your standing needs no help finding the code that handles
> the bgroup display inside plotmath.c. I am not at my machine where I
> was looking at it, but the code that I just found in expanded form on
> the Internet bore your name as a copyright holder.
>
> So I guess my feature request would be:
> ---add option for using scalable single character delimiters such as
> Symbol(0xe1) and Symbol(0xe1).

Unfortunately, I don't think this is trivial.  How are these supposed to 
scale?  Just get drawn bigger?  (which is unlikely to produce nice 
results because the lines will get thicker).

> I'm guessing that the reason three-component delimiters were chosen is
> that it was easier to expand the middle section while not expanding
> the ends as much but that's just the guess of someone who is perusing
> without really being able to fully grasp the intricacies of what is
> being done.

That's about right.  This is all modelled on TeX's equation formatting 
algorithms.  The Computer Modern fonts have this kind of extendable 
components for very large delimiters, but for angled brackets it looks 
like the TeX solution is just to offer various "big" versions.  For 
example, try the following TeX document ...

\documentclass{article}
\begin{document}

\[ \left\{
      \begin{array}{ccc}
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       d & e & f \end{array}
      \right\} \]

\[ \left\langle
      \begin{array}{ccc}
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       a & b & c \\
       d & e & f \end{array}
      \right\rangle \]

\end{document}

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hpages at fhcrc.org  Mon Sep 13 06:45:53 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 12 Sep 2010 21:45:53 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8CC297.1050405@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
Message-ID: <4C8DAC81.8080102@fhcrc.org>

Hi Duncan,

On 09/12/2010 05:07 AM, Duncan Murdoch wrote:
> On 12/09/2010 12:49 AM, Herv? Pag?s wrote:
>> Hi Duncan,
>>
>> On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
>>> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>>>> Hi,
>>>>
>>>> I found the following problem with recent R-devel
>>>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>>>> 'R CMD build <pkg>' gets stalled during vignett
>>>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>>>
>>>> It seems that the problem is that the commands used in the
>>>> Makefile for converting .tex to .pdf are not able to locate
>>>> the Sweave.sty file anymore (if I drop this file to
>>>> <pkg>/inst/doc, then the problem goes away).
>>> This sounds like a problem that only the package maintainer could
>>> address. Presumably it will be temporary: once they adjust to the new
>>> organization of the share/texmf directory, things will be fine again.
>>>
>>> The reorg is described in this NEWS item:
>>>
>>> * Directory R_HOME/share/texmf now follows the TDS conventions, so
>>> can be set as a texmf tree ('root directory' in MiKTeX parlance).
>>
>> Before this reorg, the package maintainer didn't have to care about
>> where to find things in R_HOME/share/texmf. 'R CMD build' would just
>> find them by setting the TEXINPUTS envir variable appropriately (and
>> then commands in the inst/doc/Makefile file would find them too).
>>
>> This reorg was checked in svn as rev 52256. I see the following
>> adjustments to TEXINPUTS:
>>
>> ** On Unix (src/scripts/Rcmd.in file):
>>
>> -## Append 'share/texmf' to TeX's input search path.
>> -if test -z "$TEXINPUTS}"; then
>> - TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
>> +## Append 'share/texmf/...' to TeX's input search path.
>> +if test -z "${TEXINPUTS}"; then
>> + TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
>> else
>> - TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
>> + TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
>> fi
>> export TEXINPUTS
>>
>> ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):
>>
>> -TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
>> +TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;
>>
>> The path seems to have been adjusted correctly. So my question is:
>> why isn't this working on Windows for packages that use a Makefile?
>
> I don't know. My first assumption would that something in the Makefile
> is wrong, but since you don't give any examples, I can't check.

There are 8 Bioconductor packages failing to build on Windows
because of this problem. They have a Makefile in inst/doc/ that
calls 'pdflatex' or 'texi2dvi --pdf' on <some_vignette> to convert
<some_vignette>.tex into <some_vignette>.pdf. They don't
have Sweave.sty in inst/doc/ (other packages use the same kind of
Makefile and are building ok because they have a copy of Sweave.sty
in inst/doc/).

For example, here is the content of adSplit/inst/doc/Makefile:

all:	pdf clean

pdf:	tr_2005_02.tex
	epstopdf splitSet.eps
	pdflatex tr_2005_02
	pdflatex tr_2005_02
	pdflatex tr_2005_02

clean:
	rm -f *.aux *.eps *.log *.out *.tex *.toc
	rm -f Rplots.ps splitSet.pdf tr_2005_02-*

The 7 other packages use similar Makefile. As I said before, they
all used to build ok before the R_HOME/share/texmf reorg. They still
build ok on non-Windows machines. Thanks!

H.

>
> Duncan Murdoch


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ligges at statistik.tu-dortmund.de  Mon Sep 13 12:04:37 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 13 Sep 2010 12:04:37 +0200
Subject: [Rd] R forge : svn + ssh without key
In-Reply-To: <4C73CF9A.1030102@free.fr>
References: <mailman.23.1282644008.6357.r-devel@r-project.org>
	<4C73CF9A.1030102@free.fr>
Message-ID: <4C8DF735.3070403@statistik.tu-dortmund.de>

Works for me, I guess you do not have an appropriate ssh connected to 
your svn client.
Perhaps better ask such questions on the R-forge platform?

Best,
Uwe Ligges


On 24.08.2010 15:56, christophe.genolini wrote:
>
> Hi the list,
>
> I am trying to use R forge. I created an account. I put my project on R
> forge. I installed TortoiseSVN on my computer (windows).
>
> Then I did not manage to go through all the key process but I see in the
> R-Forge Manual that there is another option:
> "2. it is sufficient to use password authentication to write to the
> project repository (if you decided to do so please go to step 5)."
> So I try this new (for me) way. I create a folder on my computer. I
> successfully manage to update my local repository. But I do not manage
> to do a commit. Each time, I get the message
>
> Commit fail (details follow):
> authorization failed
>
> Any idea of what goes wrong?
>
> Christophe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon Sep 13 12:34:11 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 13 Sep 2010 06:34:11 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8DAC81.8080102@fhcrc.org>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org>
Message-ID: <4C8DFE23.5040101@gmail.com>

Herv? Pag?s wrote:
> Hi Duncan,
>
> On 09/12/2010 05:07 AM, Duncan Murdoch wrote:
>   
>> On 12/09/2010 12:49 AM, Herv? Pag?s wrote:
>>     
>>> Hi Duncan,
>>>
>>> On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
>>>       
>>>> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>>>>         
>>>>> Hi,
>>>>>
>>>>> I found the following problem with recent R-devel
>>>>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>>>>> 'R CMD build <pkg>' gets stalled during vignett
>>>>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>>>>
>>>>> It seems that the problem is that the commands used in the
>>>>> Makefile for converting .tex to .pdf are not able to locate
>>>>> the Sweave.sty file anymore (if I drop this file to
>>>>> <pkg>/inst/doc, then the problem goes away).
>>>>>           
>>>> This sounds like a problem that only the package maintainer could
>>>> address. Presumably it will be temporary: once they adjust to the new
>>>> organization of the share/texmf directory, things will be fine again.
>>>>
>>>> The reorg is described in this NEWS item:
>>>>
>>>> * Directory R_HOME/share/texmf now follows the TDS conventions, so
>>>> can be set as a texmf tree ('root directory' in MiKTeX parlance).
>>>>         
>>> Before this reorg, the package maintainer didn't have to care about
>>> where to find things in R_HOME/share/texmf. 'R CMD build' would just
>>> find them by setting the TEXINPUTS envir variable appropriately (and
>>> then commands in the inst/doc/Makefile file would find them too).
>>>
>>> This reorg was checked in svn as rev 52256. I see the following
>>> adjustments to TEXINPUTS:
>>>
>>> ** On Unix (src/scripts/Rcmd.in file):
>>>
>>> -## Append 'share/texmf' to TeX's input search path.
>>> -if test -z "$TEXINPUTS}"; then
>>> - TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
>>> +## Append 'share/texmf/...' to TeX's input search path.
>>> +if test -z "${TEXINPUTS}"; then
>>> + TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
>>> else
>>> - TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
>>> + TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
>>> fi
>>> export TEXINPUTS
>>>
>>> ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):
>>>
>>> -TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
>>> +TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;
>>>
>>> The path seems to have been adjusted correctly. So my question is:
>>> why isn't this working on Windows for packages that use a Makefile?
>>>       
>> I don't know. My first assumption would that something in the Makefile
>> is wrong, but since you don't give any examples, I can't check.
>>     
>
> There are 8 Bioconductor packages failing to build on Windows
> because of this problem. They have a Makefile in inst/doc/ that
> calls 'pdflatex' or 'texi2dvi --pdf' on <some_vignette> to convert
> <some_vignette>.tex into <some_vignette>.pdf. They don't
> have Sweave.sty in inst/doc/ (other packages use the same kind of
> Makefile and are building ok because they have a copy of Sweave.sty
> in inst/doc/).
>
> For example, here is the content of adSplit/inst/doc/Makefile:
>
> all:	pdf clean
>
> pdf:	tr_2005_02.tex
> 	epstopdf splitSet.eps
> 	pdflatex tr_2005_02
> 	pdflatex tr_2005_02
> 	pdflatex tr_2005_02
>
> clean:
> 	rm -f *.aux *.eps *.log *.out *.tex *.toc
> 	rm -f Rplots.ps splitSet.pdf tr_2005_02-*
>
> The 7 other packages use similar Makefile. As I said before, they
> all used to build ok before the R_HOME/share/texmf reorg. They still
> build ok on non-Windows machines. Thanks!
>
> H.
>   

On Windows using MikTeX, we put a -I option on the command line to point 
to the input directory.  If you don't want to do that, you can use "R 
CMD texify --pdf" instead of "pdflatex"; it will try to determine the 
appropriate command line based on the platform.

Duncan Murdoch


From dwinsemius at comcast.net  Mon Sep 13 13:56:22 2010
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 13 Sep 2010 07:56:22 -0400
Subject: [Rd] [R] scalable < > delimiters in plotmath
In-Reply-To: <4C8D9CCA.5080208@auckland.ac.nz>
References: <AANLkTikJPdOpuDyEXyThi8-SDf1qp4RUD73K2U8mKD=O@mail.gmail.com>	<AANLkTimmFzDvrg5aEkEXXhFoWUf+eOKXk==PB6O5wrpu@mail.gmail.com>	<AANLkTimTbZ-npnPfG7E_CcR+3FUdxxKXnRf8posB-CO8@mail.gmail.com>	<4C8C2642.8090607@ucalgary.ca>	<EEFDD2EF-421E-4A6D-B130-499CF6440C38@comcast.net>	<AANLkTimaZnbJr=zaOxxz=Shon4KOjnxLNmOtUTe+Qyg1@mail.gmail.com>	<D39BC898-BDB2-4781-8E0B-8933B528A389@comcast.net>
	<AANLkTin=V6FdwGWUNpDPstKoD0RMFi_32n2kdUJ1gbcS@mail.gmail.com>
	<4C8D33E7.8000100@auckland.ac.nz>
	<C28E4EB5-346D-48F0-BE9E-33A6AF74D2B3@comcast.net>
	<4C8D9CCA.5080208@auckland.ac.nz>
Message-ID: <F414CD14-C97C-4E7F-A793-4D20F5C2E167@comcast.net>


On Sep 12, 2010, at 11:38 PM, Paul Murrell wrote:

> Hi
>
> [shifting to r-devel]
>
> On 13/09/2010 8:43 a.m., David Winsemius wrote:
>>
>> On Sep 12, 2010, at 4:11 PM, Paul Murrell wrote:
>>
>>> Hi
>>>
>>> On 13/09/2010 7:57 a.m., baptiste auguie wrote:
>>>> Oh, right I see. I was completely off then. Maybe it's not so  
>>>> easy to
>>>> add<>   delimiters after all, I'll have to look at the list of  
>>>> symbol
>>>> pieces to see if these can be constructed too.
>>>
>>> The plotmath stuff assumes a font with an Adobe Symbol encoding.
>>> The characters we have to play with are shown at http://www.stat.auckland.ac.nz/~paul/R/CM/AdobeSym.pdf
>>> .
>>> You can see the components of "growable" delimiters on the bottom
>>> two rows.
>>
>> Hello Paul;
>>
>> Both Baptiste and I have looked at the plotmath.c code and it appears
>> that only a few of those delimiters are supported. We specifically
>> have tried to use the angle brackets:
>>
>>  >  plot(1,1,
>> xlab=expression(bgroup(symbol(0xe1),atop(x,y),symbol(0xf1))))
>> Error in bgroup(symbol(225), atop(x, y), symbol(241)) :
>>    invalid group delimiter
>>
>> The supported delimiters appear to each be built up from three parts
>> that are then assembled within a bounding box and as far as I can
>> determine are limited to "|", "||", "[", "{", "(", ")", "}",and  
>> "}". I
>> needed to download the full source to find a copy, but I'm fairly  
>> sure
>> a guRu of your standing needs no help finding the code that handles
>> the bgroup display inside plotmath.c. I am not at my machine where I
>> was looking at it, but the code that I just found in expanded form on
>> the Internet bore your name as a copyright holder.
>>
>> So I guess my feature request would be:
>> ---add option for using scalable single character delimiters such as
>> Symbol(0xe1) and Symbol(0xe1).
>
Meant to type e1 and f1.

> Unfortunately, I don't think this is trivial.  How are these  
> supposed to scale?  Just get drawn bigger?  (which is unlikely to  
> produce nice results because the lines will get thicker).

My thought was thought was that these were unlikely to be called into  
play when they were going to be surrounding multiple lines of text so  
would not be expected to scale up as might matrix brackets, but would  
rather be used in situations where they represented either means or   
physical quantities. In statistical mechanics angle-brackets are the  
time averages of quantities like pressure, while in quantum mechanics  
physical quantities are the probabilities resulting from wave/matrix  
equations involving products of bra's, "<(.)|", and kets, "|(.)>",  
representing complex conjugates possibly with a function in between  
"<  | | >". I would think that including the Symbol(0xf1) and  
Symbol(0xe1) simply as "drawn bigger" would be one approach. I would  
think another approach could be to increase the height by a greater  
ratio than the width, say 1.5 to 1. I don't know what complications  
arise in doing so, but would imagine that these would be no worse than  
the scaling problems arising with the Greek Sigma.

a) http://en.wikipedia.org/wiki/Bra-ket_notation

b) Table VIII of"Reviews of Modern Physics Style Guide":
    http://www.rmp.aps.org/files/rmpgui15.pdf

c) http://www.physics.unlv.edu/~bernard/phy721_99/tex_notes/node8.html


>
>> I'm guessing that the reason three-component delimiters were chosen  
>> is
>> that it was easier to expand the middle section while not expanding
>> the ends as much but that's just the guess of someone who is perusing
>> without really being able to fully grasp the intricacies of what is
>> being done.
>
> That's about right.  This is all modelled on TeX's equation  
> formatting algorithms.  The Computer Modern fonts have this kind of  
> extendable components for very large delimiters, but for angled  
> brackets it looks like the TeX solution is just to offer various  
> "big" versions.  For example, try the following TeX document ...
>
> \documentclass{article}
> \begin{document}
>
> \[ \left\{
>     \begin{array}{ccc}
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      d & e & f \end{array}
>     \right\} \]
>
> \[ \left\langle
>     \begin{array}{ccc}
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      a & b & c \\
>      d & e & f \end{array}
>     \right\rangle \]
>
> \end{document}
>

I see the problem with that construction, although as I said above, I  
don't think the angle brackets would be used very much in enclosing 8  
line constructs. Is there no way to scale the \langle and \rangle by a  
factor of three before prefixing and postfixing a grouped array?

(.... and plotmath doesn't really support grouped arrays anyway, does  
it? My other request was going to be for an array construct such as  
above, since it was rather difficult to get good results with arrays  
having a number of rows that is not an even power of two using atop().  
Or is there an array function in plotmath that I missed?)

I had been thinking that "triple height" "<" or ">" ( using  
Symbol(\0xe1 | \0xf1)) could substitute for the three part  
construction of scalable square, flat,  and rounded brackets that I am  
seeing in the plotmath.c code.

-- 
David.

> Paul
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

David Winsemius, MD
West Hartford, CT


From hpages at fhcrc.org  Mon Sep 13 20:38:59 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 13 Sep 2010 11:38:59 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8DFE23.5040101@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org> <4C8DFE23.5040101@gmail.com>
Message-ID: <4C8E6FC3.1010100@fhcrc.org>

On 09/13/2010 03:34 AM, Duncan Murdoch wrote:
> Herv? Pag?s wrote:
>> Hi Duncan,
>>
>> On 09/12/2010 05:07 AM, Duncan Murdoch wrote:
>>> On 12/09/2010 12:49 AM, Herv? Pag?s wrote:
>>>> Hi Duncan,
>>>>
>>>> On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
>>>>> On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I found the following problem with recent R-devel
>>>>>> (2010-08-26 r52817) on Windows (32-bit and 64-bit):
>>>>>> 'R CMD build <pkg>' gets stalled during vignett
>>>>>> creation for packages that have a Makefile in <pkg>/inst/doc.
>>>>>>
>>>>>> It seems that the problem is that the commands used in the
>>>>>> Makefile for converting .tex to .pdf are not able to locate
>>>>>> the Sweave.sty file anymore (if I drop this file to
>>>>>> <pkg>/inst/doc, then the problem goes away).
>>>>> This sounds like a problem that only the package maintainer could
>>>>> address. Presumably it will be temporary: once they adjust to the new
>>>>> organization of the share/texmf directory, things will be fine again.
>>>>>
>>>>> The reorg is described in this NEWS item:
>>>>>
>>>>> * Directory R_HOME/share/texmf now follows the TDS conventions, so
>>>>> can be set as a texmf tree ('root directory' in MiKTeX parlance).
>>>> Before this reorg, the package maintainer didn't have to care about
>>>> where to find things in R_HOME/share/texmf. 'R CMD build' would just
>>>> find them by setting the TEXINPUTS envir variable appropriately (and
>>>> then commands in the inst/doc/Makefile file would find them too).
>>>>
>>>> This reorg was checked in svn as rev 52256. I see the following
>>>> adjustments to TEXINPUTS:
>>>>
>>>> ** On Unix (src/scripts/Rcmd.in file):
>>>>
>>>> -## Append 'share/texmf' to TeX's input search path.
>>>> -if test -z "$TEXINPUTS}"; then
>>>> - TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
>>>> +## Append 'share/texmf/...' to TeX's input search path.
>>>> +if test -z "${TEXINPUTS}"; then
>>>> + TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
>>>> else
>>>> - TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
>>>> + TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
>>>> fi
>>>> export TEXINPUTS
>>>>
>>>> ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):
>>>>
>>>> -TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
>>>> +TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;
>>>>
>>>> The path seems to have been adjusted correctly. So my question is:
>>>> why isn't this working on Windows for packages that use a Makefile?
>>> I don't know. My first assumption would that something in the Makefile
>>> is wrong, but since you don't give any examples, I can't check.
>>
>> There are 8 Bioconductor packages failing to build on Windows
>> because of this problem. They have a Makefile in inst/doc/ that
>> calls 'pdflatex' or 'texi2dvi --pdf' on <some_vignette> to convert
>> <some_vignette>.tex into <some_vignette>.pdf. They don't
>> have Sweave.sty in inst/doc/ (other packages use the same kind of
>> Makefile and are building ok because they have a copy of Sweave.sty
>> in inst/doc/).
>>
>> For example, here is the content of adSplit/inst/doc/Makefile:
>>
>> all: pdf clean
>>
>> pdf: tr_2005_02.tex
>> epstopdf splitSet.eps
>> pdflatex tr_2005_02
>> pdflatex tr_2005_02
>> pdflatex tr_2005_02
>>
>> clean:
>> rm -f *.aux *.eps *.log *.out *.tex *.toc
>> rm -f Rplots.ps splitSet.pdf tr_2005_02-*
>>
>> The 7 other packages use similar Makefile. As I said before, they
>> all used to build ok before the R_HOME/share/texmf reorg. They still
>> build ok on non-Windows machines. Thanks!
>>
>> H.
>
> On Windows using MikTeX, we put a -I option on the command line to point
> to the input directory. If you don't want to do that, you can use "R CMD
> texify --pdf" instead of "pdflatex"; it will try to determine the
> appropriate command line based on the platform.

Yes I can use 'R CMD some_command' instead of just 'some_command' in the
Makefile so 'some_command' sees the TEXINPUTS variable and that solves
the problem. But when I call 'R CMD build', shouldn't 'make' and its
child processes ('pdflatex', 'texify', etc...) already see TEXINPUTS?
Why do I need to call the commands in the Makefile thru R CMD again
in order to see TEXINPUTS?

Thanks for suggesting workarounds but don't you think there is a real
problem?

H.

>
> Duncan Murdoch


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Mon Sep 13 20:47:54 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 13 Sep 2010 14:47:54 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8E6FC3.1010100@fhcrc.org>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org> <4C8DFE23.5040101@gmail.com>
	<4C8E6FC3.1010100@fhcrc.org>
Message-ID: <4C8E71DA.1000202@gmail.com>

  On 13/09/2010 2:38 PM, Herv? Pag?s wrote:
> On 09/13/2010 03:34 AM, Duncan Murdoch wrote:
> >  Herv? Pag?s wrote:
> >>  Hi Duncan,
> >>
> >>  On 09/12/2010 05:07 AM, Duncan Murdoch wrote:
> >>>  On 12/09/2010 12:49 AM, Herv? Pag?s wrote:
> >>>>  Hi Duncan,
> >>>>
> >>>>  On 09/11/2010 03:56 AM, Duncan Murdoch wrote:
> >>>>>  On 11/09/2010 12:52 AM, Herv? Pag?s wrote:
> >>>>>>  Hi,
> >>>>>>
> >>>>>>  I found the following problem with recent R-devel
> >>>>>>  (2010-08-26 r52817) on Windows (32-bit and 64-bit):
> >>>>>>  'R CMD build<pkg>' gets stalled during vignett
> >>>>>>  creation for packages that have a Makefile in<pkg>/inst/doc.
> >>>>>>
> >>>>>>  It seems that the problem is that the commands used in the
> >>>>>>  Makefile for converting .tex to .pdf are not able to locate
> >>>>>>  the Sweave.sty file anymore (if I drop this file to
> >>>>>>  <pkg>/inst/doc, then the problem goes away).
> >>>>>  This sounds like a problem that only the package maintainer could
> >>>>>  address. Presumably it will be temporary: once they adjust to the new
> >>>>>  organization of the share/texmf directory, things will be fine again.
> >>>>>
> >>>>>  The reorg is described in this NEWS item:
> >>>>>
> >>>>>  * Directory R_HOME/share/texmf now follows the TDS conventions, so
> >>>>>  can be set as a texmf tree ('root directory' in MiKTeX parlance).
> >>>>  Before this reorg, the package maintainer didn't have to care about
> >>>>  where to find things in R_HOME/share/texmf. 'R CMD build' would just
> >>>>  find them by setting the TEXINPUTS envir variable appropriately (and
> >>>>  then commands in the inst/doc/Makefile file would find them too).
> >>>>
> >>>>  This reorg was checked in svn as rev 52256. I see the following
> >>>>  adjustments to TEXINPUTS:
> >>>>
> >>>>  ** On Unix (src/scripts/Rcmd.in file):
> >>>>
> >>>>  -## Append 'share/texmf' to TeX's input search path.
> >>>>  -if test -z "$TEXINPUTS}"; then
> >>>>  - TEXINPUTS=".:${R_SHARE_DIR}/texmf:"
> >>>>  +## Append 'share/texmf/...' to TeX's input search path.
> >>>>  +if test -z "${TEXINPUTS}"; then
> >>>>  + TEXINPUTS=".:${R_SHARE_DIR}/texmf/tex/latex:"
> >>>>  else
> >>>>  - TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf:"
> >>>>  + TEXINPUTS=".:${TEXINPUTS}:${R_SHARE_DIR}/texmf/tex/latex:"
> >>>>  fi
> >>>>  export TEXINPUTS
> >>>>
> >>>>  ** On Windows (src/gnuwin32/fixed/etc/Rcmd_environ file):
> >>>>
> >>>>  -TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf;
> >>>>  +TEXINPUTS=.;${TEXINPUTS};${R_SHARE_DIR}/texmf/tex/latex;
> >>>>
> >>>>  The path seems to have been adjusted correctly. So my question is:
> >>>>  why isn't this working on Windows for packages that use a Makefile?
> >>>  I don't know. My first assumption would that something in the Makefile
> >>>  is wrong, but since you don't give any examples, I can't check.
> >>
> >>  There are 8 Bioconductor packages failing to build on Windows
> >>  because of this problem. They have a Makefile in inst/doc/ that
> >>  calls 'pdflatex' or 'texi2dvi --pdf' on<some_vignette>  to convert
> >>  <some_vignette>.tex into<some_vignette>.pdf. They don't
> >>  have Sweave.sty in inst/doc/ (other packages use the same kind of
> >>  Makefile and are building ok because they have a copy of Sweave.sty
> >>  in inst/doc/).
> >>
> >>  For example, here is the content of adSplit/inst/doc/Makefile:
> >>
> >>  all: pdf clean
> >>
> >>  pdf: tr_2005_02.tex
> >>  epstopdf splitSet.eps
> >>  pdflatex tr_2005_02
> >>  pdflatex tr_2005_02
> >>  pdflatex tr_2005_02
> >>
> >>  clean:
> >>  rm -f *.aux *.eps *.log *.out *.tex *.toc
> >>  rm -f Rplots.ps splitSet.pdf tr_2005_02-*
> >>
> >>  The 7 other packages use similar Makefile. As I said before, they
> >>  all used to build ok before the R_HOME/share/texmf reorg. They still
> >>  build ok on non-Windows machines. Thanks!
> >>
> >>  H.
> >
> >  On Windows using MikTeX, we put a -I option on the command line to point
> >  to the input directory. If you don't want to do that, you can use "R CMD
> >  texify --pdf" instead of "pdflatex"; it will try to determine the
> >  appropriate command line based on the platform.
>
> Yes I can use 'R CMD some_command' instead of just 'some_command' in the
> Makefile so 'some_command' sees the TEXINPUTS variable and that solves
> the problem. But when I call 'R CMD build', shouldn't 'make' and its
> child processes ('pdflatex', 'texify', etc...) already see TEXINPUTS?
> Why do I need to call the commands in the Makefile thru R CMD again
> in order to see TEXINPUTS?
>
> Thanks for suggesting workarounds but don't you think there is a real
> problem?
>

As I said, we don't use TEXINPUTS on Windows, we use the command line 
version.  I didn't write the code, so I don't know why there's the 
difference, but I assume there's a reason for it, and presumably the 
reason is that relying on TEXINPUTS doesn't work.

Duncan Murdoch


From cstrato at aon.at  Mon Sep 13 23:07:35 2010
From: cstrato at aon.at (cstrato)
Date: Mon, 13 Sep 2010 23:07:35 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
Message-ID: <4C8E9297.5050806@aon.at>

Dear all,

When running R CMD check on Windows XP to test my package I get the 
following warning message:

"* checking line endings in C/C++/Fortran sources/headers ... WARNING
Found the following sources/headers with CR or CRLF line endings:
   src/xpsDict.h"

The problem is that this file is created by the compiler AUTOMATICALLY 
during the compilation process, and since the file is created by VC++ on 
WinXP, it will always have CRLF line endings.

Thus my question is:
- Is it really necessary to issues this warning message?
- If yes, could it be suppressed on Windows XP, since there it should 
obviously be no problem.

One more issue:
While I have always received this warning on my WinXP installation, for 
some lucky reason the warning did until now not appear on the 
Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liverpool-checksrc.html

However, for some reason on BioC 2.7 running R-2.12.0 this warning does 
appear, see:
http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liverpool-checksrc.html
For this reason I would  appreciate if there would be a possibility to 
suppress this warning message.

Thank you in advance.
Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From edd at debian.org  Mon Sep 13 23:31:24 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 13 Sep 2010 16:31:24 -0500
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8E9297.5050806@aon.at>
References: <4C8E9297.5050806@aon.at>
Message-ID: <19598.38956.372452.32467@max.nulle.part>


On 13 September 2010 at 23:07, cstrato wrote:
| Dear all,
| 
| When running R CMD check on Windows XP to test my package I get the 
| following warning message:
| 
| "* checking line endings in C/C++/Fortran sources/headers ... WARNING
| Found the following sources/headers with CR or CRLF line endings:
|    src/xpsDict.h"
| 
| The problem is that this file is created by the compiler AUTOMATICALLY 
| during the compilation process, and since the file is created by VC++ on 
| WinXP, it will always have CRLF line endings.
| 
| Thus my question is:
| - Is it really necessary to issues this warning message?
| - If yes, could it be suppressed on Windows XP, since there it should 
| obviously be no problem.
| 
| One more issue:
| While I have always received this warning on my WinXP installation, for 
| some lucky reason the warning did until now not appear on the 
| Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
| http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liverpool-checksrc.html
| 
| However, for some reason on BioC 2.7 running R-2.12.0 this warning does 
| appear, see:
| http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liverpool-checksrc.html
| For this reason I would  appreciate if there would be a possibility to 
| suppress this warning message.

I once had the warning to in project and just added another filtering step
using this


## simple 0d 0a -> 0a converter to suppress a warning on Windows

filename <- commandArgs(trailingOnly=TRUE)[1]
if (!file.exists(filename)) q()

con <- file(filename, "rb")
bin <- readBin(con, raw(), 100000)
bin <- bin[ which(bin != "0d") ]
close(con)

Sys.sleep(1)

con <- file(filename, "wb")
writeBin(bin, con)
close(con)


Maybe you can use something like this and have the generated file transformed.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spluque at gmail.com  Tue Sep 14 00:11:41 2010
From: spluque at gmail.com (Seb)
Date: Mon, 13 Sep 2010 17:11:41 -0500
Subject: [Rd] value returned by by()
Message-ID: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>

Hi,

I noticed that by() returns an object of class 'by', regardless of what
its argument 'simplify' is.  ?by says that it always returns a list if
simplify=FALSE, yet by.data.frame shows:

---<--------------------cut here---------------start------------------->---
function (data, INDICES, FUN, ..., simplify = TRUE) 
{
    if (!is.list(INDICES)) {
        IND <- vector("list", 1L)
        IND[[1L]] <- INDICES
        names(IND) <- deparse(substitute(INDICES))[1L]
    }
    else IND <- INDICES
    FUNx <- function(x) FUN(data[x, , drop = FALSE], ...)
    nd <- nrow(data)
    ans <- eval(substitute(tapply(1L:nd, IND, FUNx, simplify = simplify)), 
        data)
    attr(ans, "call") <- match.call()
    class(ans) <- "by"
    ans
}
<environment: namespace:base>
---<--------------------cut here---------------end--------------------->---

One could force a list by wrapping it around an lapply(by.object, "["),
but this is not possible if the object contains S4 objects.  How does
one force a list in those cases?


Cheers,

-- 
Seb


From wdunlap at tibco.com  Tue Sep 14 02:06:04 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Sep 2010 17:06:04 -0700
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8E9297.5050806@aon.at>
References: <4C8E9297.5050806@aon.at>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
> Sent: Monday, September 13, 2010 2:08 PM
> To: r-devel at r-project.org
> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
> 
> Dear all,
> 
> When running R CMD check on Windows XP to test my package I get the 
> following warning message:
> 
> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
> Found the following sources/headers with CR or CRLF line endings:
>    src/xpsDict.h"
> 
> The problem is that this file is created by the compiler 
> AUTOMATICALLY 
> during the compilation process, and since the file is created 
> by VC++ on 
> WinXP, it will always have CRLF line endings.
> 
> Thus my question is:
> - Is it really necessary to issues this warning message?
> - If yes, could it be suppressed on Windows XP, since there it should 
> obviously be no problem.

Older versions of Sun C compilers would refuse to
compile code with Windows-style line endings.  I don't
know if that is still the case.  One reason to run check
is to see if there are any platform-dependencies in
code on CRAN so the warning should not be suppressed.

(The S+ package system tries to avoid the problem by changing
line endings on text files when it compiles the package.
It is not trivial to reliably figure out which files are
meant to be text files.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> 
> One more issue:
> While I have always received this warning on my WinXP 
> installation, for 
> some lucky reason the warning did until now not appear on the 
> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
pool-checksrc.html
> 
> However, for some reason on BioC 2.7 running R-2.12.0 this 
> warning does 
> appear, see:
> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
pool-checksrc.html
> For this reason I would  appreciate if there would be a 
> possibility to 
> suppress this warning message.
> 
> Thank you in advance.
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
> V.i.e.n.n.a           A.u.s.t.r.i.a
> e.m.a.i.l:        cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ligges at statistik.tu-dortmund.de  Tue Sep 14 12:02:04 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2010 12:02:04 +0200
Subject: [Rd] value returned by by()
In-Reply-To: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>
Message-ID: <4C8F481C.8010502@statistik.tu-dortmund.de>

It returns a list with athe class attribut set to "by", just use:

x <- by(.....)
unclass(x)


Uwe Ligges


On 14.09.2010 00:11, Seb wrote:
> Hi,
>
> I noticed that by() returns an object of class 'by', regardless of what
> its argument 'simplify' is.  ?by says that it always returns a list if
> simplify=FALSE, yet by.data.frame shows:
>
> ---<--------------------cut here---------------start------------------->---
> function (data, INDICES, FUN, ..., simplify = TRUE)
> {
>      if (!is.list(INDICES)) {
>          IND<- vector("list", 1L)
>          IND[[1L]]<- INDICES
>          names(IND)<- deparse(substitute(INDICES))[1L]
>      }
>      else IND<- INDICES
>      FUNx<- function(x) FUN(data[x, , drop = FALSE], ...)
>      nd<- nrow(data)
>      ans<- eval(substitute(tapply(1L:nd, IND, FUNx, simplify = simplify)),
>          data)
>      attr(ans, "call")<- match.call()
>      class(ans)<- "by"
>      ans
> }
> <environment: namespace:base>
> ---<--------------------cut here---------------end--------------------->---
>
> One could force a list by wrapping it around an lapply(by.object, "["),
> but this is not possible if the object contains S4 objects.  How does
> one force a list in those cases?
>
>
> Cheers,
>


From karl.forner at gmail.com  Tue Sep 14 11:06:34 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 14 Sep 2010 11:06:34 +0200
Subject: [Rd] Best way to manage configuration for openMP support
Message-ID: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100914/f1435025/attachment.pl>

From edd at debian.org  Tue Sep 14 13:40:52 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Sep 2010 06:40:52 -0500
Subject: [Rd] Best way to manage configuration for openMP support
In-Reply-To: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>
References: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>
Message-ID: <19599.24388.430713.722583@max.nulle.part>


On 14 September 2010 at 11:06, Karl Forner wrote:
| I've written a package that may use OpenMP to speed up computations. OpenMP
| is supported in recent Gcc versions by using the -fopenmp flag.
| The problem is that flag crashed gcc versions that do not support OpenMP.
| So what is the best way for a package to handle this issue. Has someone a
| configure script that deals with this ?

I don't know off-hand of any CRAN packages that do that, but you could look
at Luke Tierney's pnmath package which uses Open MP. It may have a test.

Else, you can query gcc for minimum versions. I have some configure code from
way back when then tested for a minimum version of 3.0 (!!):

# We are using C++
AC_LANG(C++)
AC_REQUIRE_CPP

AC_PROG_CXX
if test "${GXX}" = yes; then
    gxx_version=`${CXX} -v 2>&1 | grep "^.*g.. version" | \\
		       sed -e 's/^.*g.. version *//'`
    case ${gxx_version} in
        1.*|2.*)
	     AC_MSG_WARN([Only g++ version 3.0 or greater can be used with RQuantib.])
	     AC_MSG_ERROR([Please use a different compiler.])   
        ;;
    esac
fi

You could do the same for gcc and strip out major version (4) and minor (0 or
1) and then complain.  With 4.2 you should be fine.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ligges at statistik.tu-dortmund.de  Tue Sep 14 13:49:18 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2010 13:49:18 +0200
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8CA70C.40109@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org> <4C8C94A3.3080600@gmail.com>
	<4C8CA70C.40109@fhcrc.org>
Message-ID: <4C8F613E.8070407@statistik.tu-dortmund.de>



On 12.09.2010 12:10, Herv? Pag?s wrote:
> Hi Peter,
>
> On 09/12/2010 01:51 AM, Peter Dalgaard wrote:
>> On 09/12/2010 08:10 AM, Herv? Pag?s wrote:
>> ...
>>>
>>> AFAICT those problems were never seen before (i.e. with R< 2.12).
>>> They show up randomly everyday for a small number of packages
>>> (between 10 and 20 out of 400). The set of victims changes everyday
>>> and any package seems to be a potential victim (I've not been able
>>> to observe any obvious pattern so far).
>>> Does anyone have any idea what could make 'R CMD build' and
>>> 'R CMD check' so confused/unreliable on Windows?


Brian had some ideas that the problems are related to the shell that is 
used. Is the problem still apparent in a very recent R-devel from few 
days ago? I am just back from vacations and have not updated yet.
I experienced the same problems and I am just iterating automatically if 
typical problems are apparent from the log files. I hope some if not all 
parts are solved now and will do some new test runs shortly.

Best,
Uwe






>>> Thanks,
>>> H.
>>>
>>
>> Antivirus software? I suspect you already ruled that out, but it has
>> been the culprit for problems with mysteriously disappearing
>> intermediate files in several cases, so I thought I'd mention it.
>>
>
> Actually I didn't try that yet because we still build BioC release
> (using R-2.11.1) on these 2 Windows boxes and we don't see any of
> those problems for the release builds. But I will. Could it be that
> the fact that 'R CMD build' and 'R CMD check' are R-based in R-2.12
> (and not Perl-based anymore) make them more fragile when something
> like an antivirus is messing around with the filesystem?
>
> Thanks for the suggestion,
> H.
>


From bbolker at gmail.com  Tue Sep 14 18:42:30 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Sep 2010 12:42:30 -0400
Subject: [Rd] doc bug in ?residuals.gls
Message-ID: <4C8FA5F6.4070304@gmail.com>


Under the description of the 'type' argument, ?residuals.gls says
'Defaults to ?"pearson"?.'

But residuals.gls starts

residuals.gls <-
function(object, type = c("response", "pearson", "normalized"), ...)
{
type <- match.arg(type)

...

which sure looks to me like it defaults to "response", not "pearson"
(and it behaves that way in tests).

It would seem to make more sense to change the documentation rather than
the code
since anyone who looked at the docs would have been confused already,
whereas someone who had
been happily using the code without looking at the docs would see a
sudden change in the results ...

This is in nlme 3.1-96, from a fresh tools/rsync-recommended. Sending it
to r-devel for comment because r-core is listed as the maintainer.

sincerely
Ben Bolker


From simon.urbanek at r-project.org  Tue Sep 14 19:01:36 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 14 Sep 2010 13:01:36 -0400
Subject: [Rd] Best way to manage configuration for openMP support
In-Reply-To: <19599.24388.430713.722583@max.nulle.part>
References: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>
	<19599.24388.430713.722583@max.nulle.part>
Message-ID: <B295D4D3-C4CA-41D9-AC57-9DD0EC391BE6@r-project.org>

Please do NOT use version checks on compilers and other tools - those are the wrong way to go! You want to use actual functionality check as that is the only reliable way to find out that something works or not*. For example there are issues on certain Linux systems with the gomp library that prevents it from loading into packages so regardless of the compiler version it won't work. Also other compilers also support OMP so checking specific compiler's version will be simply wrong.

In fact autoconf has AC_OPENMP macro that does all the heavy-lifting for you. This is a sample configure.ac that does the job:

# Process this file with autoconf to produce a configure script.
AC_INIT(OpenMPpackage, 0.8, Simon.Urbanek at r-project.org)
AC_CONFIG_SRCDIR([src/test.c])

# find R home and set CC/CFLAGS
: ${R_HOME=`R RHOME`}
if test -z "${R_HOME}"; then
  echo "could not determine R_HOME"
  exit 1
fi
RBIN="${R_HOME}/bin/R"
CC=`"${RBIN}" CMD config CC`;
CFLAGS=`"${RBIN}" CMD config CFLAGS`
LIBS="${PKG_LIBS}"

# Checks for programs.
AC_PROG_CC
# Check for OpenMP
AC_OPENMP

# since some systems have broken OMP libraries
# we also check that the actual package will work
ac_pkg_openmp=no
if test -n "${OPENMP_CFLAGS}"; then
  AC_MSG_CHECKING([whether OpenMP will work in a package])
  AC_LANG_CONFTEST(
  [AC_LANG_PROGRAM([[#include <omp.h>]], [[ return omp_get_num_threads (); ]])])
  PKG_CFLAGS="${OPENMP_CFLAGS}" PKG_LIBS="${OPENMP_CFLAGS}" "$RBIN" CMD SHLIB conftest.c 1>&AS_MESSAGE_LOG_FD 2>&AS_MESSAGE_LOG_FD && "$RBIN" --vanilla -q -e "dyn.load(paste('conftest',.Platform\$dynlib.ext,sep=''))" 1>&AS_MESSAGE_LOG_FD 2>&AS_MESSAGE_LOG_FD && ac_pkg_openmp=yes
  AC_MSG_RESULT([${ac_pkg_openmp}])
fi

# if ${ac_pkg_openmp} = "yes" then we have OMP, otherwise it will be "no"
if test "${ac_pkg_openmp}" = no; then
  OPENMP_CFLAGS=''
  # you could put AC_MSG_ERROR here is OpenMP is required
fi

AC_SUBST(OPENMP_CFLAGS)

AC_CONFIG_FILES([src/Makevars])
AC_OUTPUT

And your Makevars.in will probably look something like:

PKG_CPPFLAGS=@OPENMP_CFLAGS@
PKG_LIBS=@OPENMP_CFLAGS@ @LIBS@

Cheers,
Simon


* - compiler version checks are sometime used directly in the source files as a work-around if autoconf cannot be used. But since autoconf provides an easy way to test functionality you should do that instead if available.

On Sep 14, 2010, at 7:40 AM, Dirk Eddelbuettel wrote:

> 
> On 14 September 2010 at 11:06, Karl Forner wrote:
> | I've written a package that may use OpenMP to speed up computations. OpenMP
> | is supported in recent Gcc versions by using the -fopenmp flag.
> | The problem is that flag crashed gcc versions that do not support OpenMP.
> | So what is the best way for a package to handle this issue. Has someone a
> | configure script that deals with this ?
> 
> I don't know off-hand of any CRAN packages that do that, but you could look
> at Luke Tierney's pnmath package which uses Open MP. It may have a test.
> 
> Else, you can query gcc for minimum versions. I have some configure code from
> way back when then tested for a minimum version of 3.0 (!!):
> 
> # We are using C++
> AC_LANG(C++)
> AC_REQUIRE_CPP
> 
> AC_PROG_CXX
> if test "${GXX}" = yes; then
>    gxx_version=`${CXX} -v 2>&1 | grep "^.*g.. version" | \\
> 		       sed -e 's/^.*g.. version *//'`
>    case ${gxx_version} in
>        1.*|2.*)
> 	     AC_MSG_WARN([Only g++ version 3.0 or greater can be used with RQuantib.])
> 	     AC_MSG_ERROR([Please use a different compiler.])   
>        ;;
>    esac
> fi
> 
> You could do the same for gcc and strip out major version (4) and minor (0 or
> 1) and then complain.  With 4.2 you should be fine.
> 
> Dirk
> 
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Tue Sep 14 19:42:08 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Sep 2010 12:42:08 -0500
Subject: [Rd] Best way to manage configuration for openMP support
In-Reply-To: <B295D4D3-C4CA-41D9-AC57-9DD0EC391BE6@r-project.org>
References: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>
	<19599.24388.430713.722583@max.nulle.part>
	<B295D4D3-C4CA-41D9-AC57-9DD0EC391BE6@r-project.org>
Message-ID: <19599.46064.609453.301965@max.nulle.part>


On 14 September 2010 at 13:01, Simon Urbanek wrote:
| Please do NOT use version checks on compilers and other tools - those are the wrong way to go! You want to use actual functionality check as that is the only reliable way to find out that something works or not*. For example there are issues on certain Linux systems with the gomp library that prevents it from loading into packages so regardless of the compiler version it won't work. Also other compilers also support OMP so checking specific compiler's version will be simply wrong.
| 
| In fact autoconf has AC_OPENMP macro that does all the heavy-lifting for you. This is a sample configure.ac that does the job:

Seconded. This is the proper way. I had meant to add the hint for a
autoconf-wrapped test program but had to dash out earlier.

Thanks for posting a full example, Simon. Much appreciated.

Dirk
 
| # Process this file with autoconf to produce a configure script.
| AC_INIT(OpenMPpackage, 0.8, Simon.Urbanek at r-project.org)
| AC_CONFIG_SRCDIR([src/test.c])
| 
| # find R home and set CC/CFLAGS
| : ${R_HOME=`R RHOME`}
| if test -z "${R_HOME}"; then
|   echo "could not determine R_HOME"
|   exit 1
| fi
| RBIN="${R_HOME}/bin/R"
| CC=`"${RBIN}" CMD config CC`;
| CFLAGS=`"${RBIN}" CMD config CFLAGS`
| LIBS="${PKG_LIBS}"
| 
| # Checks for programs.
| AC_PROG_CC
| # Check for OpenMP
| AC_OPENMP
| 
| # since some systems have broken OMP libraries
| # we also check that the actual package will work
| ac_pkg_openmp=no
| if test -n "${OPENMP_CFLAGS}"; then
|   AC_MSG_CHECKING([whether OpenMP will work in a package])
|   AC_LANG_CONFTEST(
|   [AC_LANG_PROGRAM([[#include <omp.h>]], [[ return omp_get_num_threads (); ]])])
|   PKG_CFLAGS="${OPENMP_CFLAGS}" PKG_LIBS="${OPENMP_CFLAGS}" "$RBIN" CMD SHLIB conftest.c 1>&AS_MESSAGE_LOG_FD 2>&AS_MESSAGE_LOG_FD && "$RBIN" --vanilla -q -e "dyn.load(paste('conftest',.Platform\$dynlib.ext,sep=''))" 1>&AS_MESSAGE_LOG_FD 2>&AS_MESSAGE_LOG_FD && ac_pkg_openmp=yes
|   AC_MSG_RESULT([${ac_pkg_openmp}])
| fi
| 
| # if ${ac_pkg_openmp} = "yes" then we have OMP, otherwise it will be "no"
| if test "${ac_pkg_openmp}" = no; then
|   OPENMP_CFLAGS=''
|   # you could put AC_MSG_ERROR here is OpenMP is required
| fi
| 
| AC_SUBST(OPENMP_CFLAGS)
| 
| AC_CONFIG_FILES([src/Makevars])
| AC_OUTPUT
| 
| And your Makevars.in will probably look something like:
| 
| PKG_CPPFLAGS=@OPENMP_CFLAGS@
| PKG_LIBS=@OPENMP_CFLAGS@ @LIBS@
| 
| Cheers,
| Simon
| 
| 
| * - compiler version checks are sometime used directly in the source files as a work-around if autoconf cannot be used. But since autoconf provides an easy way to test functionality you should do that instead if available.
| 
| On Sep 14, 2010, at 7:40 AM, Dirk Eddelbuettel wrote:
| 
| > 
| > On 14 September 2010 at 11:06, Karl Forner wrote:
| > | I've written a package that may use OpenMP to speed up computations. OpenMP
| > | is supported in recent Gcc versions by using the -fopenmp flag.
| > | The problem is that flag crashed gcc versions that do not support OpenMP.
| > | So what is the best way for a package to handle this issue. Has someone a
| > | configure script that deals with this ?
| > 
| > I don't know off-hand of any CRAN packages that do that, but you could look
| > at Luke Tierney's pnmath package which uses Open MP. It may have a test.
| > 
| > Else, you can query gcc for minimum versions. I have some configure code from
| > way back when then tested for a minimum version of 3.0 (!!):
| > 
| > # We are using C++
| > AC_LANG(C++)
| > AC_REQUIRE_CPP
| > 
| > AC_PROG_CXX
| > if test "${GXX}" = yes; then
| >    gxx_version=`${CXX} -v 2>&1 | grep "^.*g.. version" | \\
| > 		       sed -e 's/^.*g.. version *//'`
| >    case ${gxx_version} in
| >        1.*|2.*)
| > 	     AC_MSG_WARN([Only g++ version 3.0 or greater can be used with RQuantib.])
| > 	     AC_MSG_ERROR([Please use a different compiler.])   
| >        ;;
| >    esac
| > fi
| > 
| > You could do the same for gcc and strip out major version (4) and minor (0 or
| > 1) and then complain.  With 4.2 you should be fine.
| > 
| > Dirk
| > 
| > -- 
| > Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
| > 
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| > 
| > 
| 

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From hpages at fhcrc.org  Tue Sep 14 20:23:44 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 14 Sep 2010 11:23:44 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8F613E.8070407@statistik.tu-dortmund.de>
References: <4C8C6ECB.5080705@fhcrc.org> <4C8C94A3.3080600@gmail.com>
	<4C8CA70C.40109@fhcrc.org>
	<4C8F613E.8070407@statistik.tu-dortmund.de>
Message-ID: <4C8FBDB0.4060106@fhcrc.org>

Hi Uwe,

On 09/14/2010 04:49 AM, Uwe Ligges wrote:
>
>
> On 12.09.2010 12:10, Herv? Pag?s wrote:
>> Hi Peter,
>>
>> On 09/12/2010 01:51 AM, Peter Dalgaard wrote:
>>> On 09/12/2010 08:10 AM, Herv? Pag?s wrote:
>>> ...
>>>>
>>>> AFAICT those problems were never seen before (i.e. with R< 2.12).
>>>> They show up randomly everyday for a small number of packages
>>>> (between 10 and 20 out of 400). The set of victims changes everyday
>>>> and any package seems to be a potential victim (I've not been able
>>>> to observe any obvious pattern so far).
>>>> Does anyone have any idea what could make 'R CMD build' and
>>>> 'R CMD check' so confused/unreliable on Windows?
>
>
> Brian had some ideas that the problems are related to the shell that is
> used. Is the problem still apparent in a very recent R-devel from few
> days ago? I am just back from vacations and have not updated yet.
> I experienced the same problems and I am just iterating automatically if
> typical problems are apparent from the log files. I hope some if not all
> parts are solved now and will do some new test runs shortly.

Sounds good. I just upgraded to R-2.12 (2010-09-13 r52905) on our 32-bit
Windows machine and I'll report here tomorrow after the next build run
has completed. I can already see that this new R solves the issue I
reported here:

   https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html

Thanks!
H.


>
> Best,
> Uwe
>
>
>
>
>
>
>>>> Thanks,
>>>> H.
>>>>
>>>
>>> Antivirus software? I suspect you already ruled that out, but it has
>>> been the culprit for problems with mysteriously disappearing
>>> intermediate files in several cases, so I thought I'd mention it.
>>>
>>
>> Actually I didn't try that yet because we still build BioC release
>> (using R-2.11.1) on these 2 Windows boxes and we don't see any of
>> those problems for the release builds. But I will. Could it be that
>> the fact that 'R CMD build' and 'R CMD check' are R-based in R-2.12
>> (and not Perl-based anymore) make them more fragile when something
>> like an antivirus is messing around with the filesystem?
>>
>> Thanks for the suggestion,
>> H.
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cstrato at aon.at  Tue Sep 14 20:26:46 2010
From: cstrato at aon.at (cstrato)
Date: Tue, 14 Sep 2010 20:26:46 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <19598.38956.372452.32467@max.nulle.part>
References: <4C8E9297.5050806@aon.at> <19598.38956.372452.32467@max.nulle.part>
Message-ID: <4C8FBE66.7060805@aon.at>

Dear Dirk,

Thank you for this suggestion, however I have no idea where this code 
could be used.

As I have said, this file is created automatically during the 
compilation by the compiler, and I have no idea at which point "R CMD 
check" does check for CRLF line endings, and how to interfere with this 
step. Do you have any ideas?

Best regards
Christian


On 9/13/10 11:31 PM, Dirk Eddelbuettel wrote:
>
> On 13 September 2010 at 23:07, cstrato wrote:
> | Dear all,
> |
> | When running R CMD check on Windows XP to test my package I get the
> | following warning message:
> |
> | "* checking line endings in C/C++/Fortran sources/headers ... WARNING
> | Found the following sources/headers with CR or CRLF line endings:
> |    src/xpsDict.h"
> |
> | The problem is that this file is created by the compiler AUTOMATICALLY
> | during the compilation process, and since the file is created by VC++ on
> | WinXP, it will always have CRLF line endings.
> |
> | Thus my question is:
> | - Is it really necessary to issues this warning message?
> | - If yes, could it be suppressed on Windows XP, since there it should
> | obviously be no problem.
> |
> | One more issue:
> | While I have always received this warning on my WinXP installation, for
> | some lucky reason the warning did until now not appear on the
> | Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
> | http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liverpool-checksrc.html
> |
> | However, for some reason on BioC 2.7 running R-2.12.0 this warning does
> | appear, see:
> | http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liverpool-checksrc.html
> | For this reason I would  appreciate if there would be a possibility to
> | suppress this warning message.
>
> I once had the warning to in project and just added another filtering step
> using this
>
>
> ## simple 0d 0a ->  0a converter to suppress a warning on Windows
>
> filename<- commandArgs(trailingOnly=TRUE)[1]
> if (!file.exists(filename)) q()
>
> con<- file(filename, "rb")
> bin<- readBin(con, raw(), 100000)
> bin<- bin[ which(bin != "0d") ]
> close(con)
>
> Sys.sleep(1)
>
> con<- file(filename, "wb")
> writeBin(bin, con)
> close(con)
>
>
> Maybe you can use something like this and have the generated file transformed.
>
> Dirk
>


From cstrato at aon.at  Tue Sep 14 20:27:34 2010
From: cstrato at aon.at (cstrato)
Date: Tue, 14 Sep 2010 20:27:34 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>
References: <4C8E9297.5050806@aon.at>
	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>
Message-ID: <4C8FBE96.6080604@aon.at>

Dear Bill,

It would be great if this warning message could at least be suppressed 
on Windows.

Best regards
Christian


On 9/14/10 2:06 AM, William Dunlap wrote:
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>> Sent: Monday, September 13, 2010 2:08 PM
>> To: r-devel at r-project.org
>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>
>> Dear all,
>>
>> When running R CMD check on Windows XP to test my package I get the
>> following warning message:
>>
>> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
>> Found the following sources/headers with CR or CRLF line endings:
>>     src/xpsDict.h"
>>
>> The problem is that this file is created by the compiler
>> AUTOMATICALLY
>> during the compilation process, and since the file is created
>> by VC++ on
>> WinXP, it will always have CRLF line endings.
>>
>> Thus my question is:
>> - Is it really necessary to issues this warning message?
>> - If yes, could it be suppressed on Windows XP, since there it should
>> obviously be no problem.
>
> Older versions of Sun C compilers would refuse to
> compile code with Windows-style line endings.  I don't
> know if that is still the case.  One reason to run check
> is to see if there are any platform-dependencies in
> code on CRAN so the warning should not be suppressed.
>
> (The S+ package system tries to avoid the problem by changing
> line endings on text files when it compiles the package.
> It is not trivial to reliably figure out which files are
> meant to be text files.)
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>>
>> One more issue:
>> While I have always received this warning on my WinXP
>> installation, for
>> some lucky reason the warning did until now not appear on the
>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
> pool-checksrc.html
>>
>> However, for some reason on BioC 2.7 running R-2.12.0 this
>> warning does
>> appear, see:
>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
> pool-checksrc.html
>> For this reason I would  appreciate if there would be a
>> possibility to
>> suppress this warning message.
>>
>> Thank you in advance.
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>> V.i.e.n.n.a           A.u.s.t.r.i.a
>> e.m.a.i.l:        cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From hpages at fhcrc.org  Tue Sep 14 20:46:20 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 14 Sep 2010 11:46:20 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8E71DA.1000202@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org> <4C8DFE23.5040101@gmail.com>
	<4C8E6FC3.1010100@fhcrc.org> <4C8E71DA.1000202@gmail.com>
Message-ID: <4C8FC2FC.6030200@fhcrc.org>

Duncan,

On 09/13/2010 11:47 AM, Duncan Murdoch wrote:
> On 13/09/2010 2:38 PM, Herv? Pag?s wrote:
[...]
>> Thanks for suggesting workarounds but don't you think there is a real
>> problem?
>>
>
> As I said, we don't use TEXINPUTS on Windows, we use the command line
> version. I didn't write the code, so I don't know why there's the
> difference, but I assume there's a reason for it, and presumably the
> reason is that relying on TEXINPUTS doesn't work.

This is fixed in current R-devel.

Cheers,
H.


From murdoch.duncan at gmail.com  Tue Sep 14 20:48:22 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Sep 2010 14:48:22 -0400
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8FC2FC.6030200@fhcrc.org>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org> <4C8DFE23.5040101@gmail.com>
	<4C8E6FC3.1010100@fhcrc.org> <4C8E71DA.1000202@gmail.com>
	<4C8FC2FC.6030200@fhcrc.org>
Message-ID: <4C8FC376.7060404@gmail.com>

  On 14/09/2010 2:46 PM, Herv? Pag?s wrote:
> Duncan,
>
> On 09/13/2010 11:47 AM, Duncan Murdoch wrote:
> >  On 13/09/2010 2:38 PM, Herv? Pag?s wrote:
> [...]
> >>  Thanks for suggesting workarounds but don't you think there is a real
> >>  problem?
> >>
> >
> >  As I said, we don't use TEXINPUTS on Windows, we use the command line
> >  version. I didn't write the code, so I don't know why there's the
> >  difference, but I assume there's a reason for it, and presumably the
> >  reason is that relying on TEXINPUTS doesn't work.
>
> This is fixed in current R-devel.
>

That explains my confusion.

Duncan Murdoch


From spluque at gmail.com  Tue Sep 14 20:50:43 2010
From: spluque at gmail.com (Seb)
Date: Tue, 14 Sep 2010 13:50:43 -0500
Subject: [Rd] value returned by by()
In-Reply-To: <4C8F481C.8010502@statistik.tu-dortmund.de> (Uwe Ligges's message
	of "Tue, 14 Sep 2010 12:02:04 +0200")
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>
	<4C8F481C.8010502@statistik.tu-dortmund.de>
Message-ID: <877hiob1mk.fsf@kolob.sebmags.homelinux.org>

On Tue, 14 Sep 2010 12:02:04 +0200,
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> It returns a list with athe class attribut set to "by", just use: x <-
> by(.....)  unclass(x)

Thanks Uwe, however, that still returns an array when using the
data.frame method for by():

R> class(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))))
[1] "array"

It seems as if the only way to really ensure a list:

R> class(lapply(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))), function(x) x))
[1] "list"

but it seems like a waste to call another function just to do this.


-- 
Seb


From simon.urbanek at r-project.org  Tue Sep 14 21:59:09 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 14 Sep 2010 15:59:09 -0400
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FBE96.6080604@aon.at>
References: <4C8E9297.5050806@aon.at>
	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>
	<4C8FBE96.6080604@aon.at>
Message-ID: <69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>


On Sep 14, 2010, at 2:27 PM, cstrato wrote:

> Dear Bill,
> 
> It would be great if this warning message could at least be suppressed on Windows.
> 

I think you're missing the point - you should be fixing that file instead - it doesn't matter whether you're on Windows or not. If the file is created automatically then it has no business being in the package. Otherwise you should simply post-process it (e.g., as Dirk suggested) after it has been generated but before you create the package - that is the common practice with generated files that need to be part of the distribution.

Cheers,
Simon


> 
> On 9/14/10 2:06 AM, William Dunlap wrote:
>> 
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>>> Sent: Monday, September 13, 2010 2:08 PM
>>> To: r-devel at r-project.org
>>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>> 
>>> Dear all,
>>> 
>>> When running R CMD check on Windows XP to test my package I get the
>>> following warning message:
>>> 
>>> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
>>> Found the following sources/headers with CR or CRLF line endings:
>>>    src/xpsDict.h"
>>> 
>>> The problem is that this file is created by the compiler
>>> AUTOMATICALLY
>>> during the compilation process, and since the file is created
>>> by VC++ on
>>> WinXP, it will always have CRLF line endings.
>>> 
>>> Thus my question is:
>>> - Is it really necessary to issues this warning message?
>>> - If yes, could it be suppressed on Windows XP, since there it should
>>> obviously be no problem.
>> 
>> Older versions of Sun C compilers would refuse to
>> compile code with Windows-style line endings.  I don't
>> know if that is still the case.  One reason to run check
>> is to see if there are any platform-dependencies in
>> code on CRAN so the warning should not be suppressed.
>> 
>> (The S+ package system tries to avoid the problem by changing
>> line endings on text files when it compiles the package.
>> It is not trivial to reliably figure out which files are
>> meant to be text files.)
>> 
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>> 
>>> 
>>> One more issue:
>>> While I have always received this warning on my WinXP
>>> installation, for
>>> some lucky reason the warning did until now not appear on the
>>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
>> pool-checksrc.html
>>> 
>>> However, for some reason on BioC 2.7 running R-2.12.0 this
>>> warning does
>>> appear, see:
>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
>> pool-checksrc.html
>>> For this reason I would  appreciate if there would be a
>>> possibility to
>>> suppress this warning message.
>>> 
>>> Thank you in advance.
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._._._
>>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a           A.u.s.t.r.i.a
>>> e.m.a.i.l:        cstrato at aon.at
>>> _._._._._._._._._._._._._._._._._._
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From cstrato at aon.at  Tue Sep 14 23:12:07 2010
From: cstrato at aon.at (cstrato)
Date: Tue, 14 Sep 2010 23:12:07 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
References: <4C8E9297.5050806@aon.at>
	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>
	<4C8FBE96.6080604@aon.at>
	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
Message-ID: <4C8FE527.6060308@aon.at>

Dear Simon,

Thank you for this clarification/suggestion, however I am confused. What 
do you mean with "If the file is created automatically then it has no 
business being in the package."?

If you download the source code of my package from:
http://bioconductor.org/packages/2.7/bioc/html/xps.html
you will see that this file is not in the package.

However, I could indeed add the corrected files xpsDict.h and 
xpsDict.cxx to the source code of my package. There is only one problem. 
Currently the source code "xps_1.9.6.tar.gz" has a total size of 4MB. 
Adding the corrected files will add another 4MB to the source code.

Best regards
Christian


On 9/14/10 9:59 PM, Simon Urbanek wrote:
>
> On Sep 14, 2010, at 2:27 PM, cstrato wrote:
>
>> Dear Bill,
>>
>> It would be great if this warning message could at least be suppressed on Windows.
>>
>
> I think you're missing the point - you should be fixing that file instead - it doesn't matter whether you're on Windows or not. If the file is created automatically then it has no business being in the package. Otherwise you should simply post-process it (e.g., as Dirk suggested) after it has been generated but before you create the package - that is the common practice with generated files that need to be part of the distribution.
>
> Cheers,
> Simon
>
>
>>
>> On 9/14/10 2:06 AM, William Dunlap wrote:
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>>>> Sent: Monday, September 13, 2010 2:08 PM
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>>>
>>>> Dear all,
>>>>
>>>> When running R CMD check on Windows XP to test my package I get the
>>>> following warning message:
>>>>
>>>> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
>>>> Found the following sources/headers with CR or CRLF line endings:
>>>>     src/xpsDict.h"
>>>>
>>>> The problem is that this file is created by the compiler
>>>> AUTOMATICALLY
>>>> during the compilation process, and since the file is created
>>>> by VC++ on
>>>> WinXP, it will always have CRLF line endings.
>>>>
>>>> Thus my question is:
>>>> - Is it really necessary to issues this warning message?
>>>> - If yes, could it be suppressed on Windows XP, since there it should
>>>> obviously be no problem.
>>>
>>> Older versions of Sun C compilers would refuse to
>>> compile code with Windows-style line endings.  I don't
>>> know if that is still the case.  One reason to run check
>>> is to see if there are any platform-dependencies in
>>> code on CRAN so the warning should not be suppressed.
>>>
>>> (The S+ package system tries to avoid the problem by changing
>>> line endings on text files when it compiles the package.
>>> It is not trivial to reliably figure out which files are
>>> meant to be text files.)
>>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>>
>>>> One more issue:
>>>> While I have always received this warning on my WinXP
>>>> installation, for
>>>> some lucky reason the warning did until now not appear on the
>>>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>>>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
>>> pool-checksrc.html
>>>>
>>>> However, for some reason on BioC 2.7 running R-2.12.0 this
>>>> warning does
>>>> appear, see:
>>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
>>> pool-checksrc.html
>>>> For this reason I would  appreciate if there would be a
>>>> possibility to
>>>> suppress this warning message.
>>>>
>>>> Thank you in advance.
>>>> Best regards
>>>> Christian
>>>> _._._._._._._._._._._._._._._._._._
>>>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>>>> V.i.e.n.n.a           A.u.s.t.r.i.a
>>>> e.m.a.i.l:        cstrato at aon.at
>>>> _._._._._._._._._._._._._._._._._._
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From hpages at fhcrc.org  Tue Sep 14 23:32:30 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 14 Sep 2010 14:32:30 -0700
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FE527.6060308@aon.at>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
	<4C8FE527.6060308@aon.at>
Message-ID: <4C8FE9EE.60604@fhcrc.org>

Hi Christian,

On 09/14/2010 02:12 PM, cstrato wrote:
> Dear Simon,
>
> Thank you for this clarification/suggestion, however I am confused. What
> do you mean with "If the file is created automatically then it has no
> business being in the package."?

He means it shouldn't be in the source tarball. We run 'R CMD check'
on source trees or source tarballs. Source tarballs are platform
independent. If I understand correctly when you run 'R CMD build'
on your source tree, you use some trick to generate this src/xpsDict.h
file on Windows and this file ends up in the source tarball.
But the source tarball created on Linux won't have this file.
That doesn't sound like a good thing to me to have the content
of the source tarball depending on the machine you've run
'R CMD build'. In other words, you should try to generate this
src/xpsDict.h file at installation time but it shouldn't end up
in the source tarball.
My 2 cents...

Cheers,
H.

>
> If you download the source code of my package from:
> http://bioconductor.org/packages/2.7/bioc/html/xps.html
> you will see that this file is not in the package.
>
> However, I could indeed add the corrected files xpsDict.h and
> xpsDict.cxx to the source code of my package. There is only one problem.
> Currently the source code "xps_1.9.6.tar.gz" has a total size of 4MB.
> Adding the corrected files will add another 4MB to the source code.
>
> Best regards
> Christian
>
>
> On 9/14/10 9:59 PM, Simon Urbanek wrote:
>>
>> On Sep 14, 2010, at 2:27 PM, cstrato wrote:
>>
>>> Dear Bill,
>>>
>>> It would be great if this warning message could at least be
>>> suppressed on Windows.
>>>
>>
>> I think you're missing the point - you should be fixing that file
>> instead - it doesn't matter whether you're on Windows or not. If the
>> file is created automatically then it has no business being in the
>> package. Otherwise you should simply post-process it (e.g., as Dirk
>> suggested) after it has been generated but before you create the
>> package - that is the common practice with generated files that need
>> to be part of the distribution.
>>
>> Cheers,
>> Simon
>>
>>
>>>
>>> On 9/14/10 2:06 AM, William Dunlap wrote:
>>>>
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org
>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>>>>> Sent: Monday, September 13, 2010 2:08 PM
>>>>> To: r-devel at r-project.org
>>>>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>>>>
>>>>> Dear all,
>>>>>
>>>>> When running R CMD check on Windows XP to test my package I get the
>>>>> following warning message:
>>>>>
>>>>> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
>>>>> Found the following sources/headers with CR or CRLF line endings:
>>>>> src/xpsDict.h"
>>>>>
>>>>> The problem is that this file is created by the compiler
>>>>> AUTOMATICALLY
>>>>> during the compilation process, and since the file is created
>>>>> by VC++ on
>>>>> WinXP, it will always have CRLF line endings.
>>>>>
>>>>> Thus my question is:
>>>>> - Is it really necessary to issues this warning message?
>>>>> - If yes, could it be suppressed on Windows XP, since there it should
>>>>> obviously be no problem.
>>>>
>>>> Older versions of Sun C compilers would refuse to
>>>> compile code with Windows-style line endings. I don't
>>>> know if that is still the case. One reason to run check
>>>> is to see if there are any platform-dependencies in
>>>> code on CRAN so the warning should not be suppressed.
>>>>
>>>> (The S+ package system tries to avoid the problem by changing
>>>> line endings on text files when it compiles the package.
>>>> It is not trivial to reliably figure out which files are
>>>> meant to be text files.)
>>>>
>>>> Bill Dunlap
>>>> Spotfire, TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>>
>>>>> One more issue:
>>>>> While I have always received this warning on my WinXP
>>>>> installation, for
>>>>> some lucky reason the warning did until now not appear on the
>>>>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>>>>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
>>>> pool-checksrc.html
>>>>>
>>>>> However, for some reason on BioC 2.7 running R-2.12.0 this
>>>>> warning does
>>>>> appear, see:
>>>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
>>>> pool-checksrc.html
>>>>> For this reason I would appreciate if there would be a
>>>>> possibility to
>>>>> suppress this warning message.
>>>>>
>>>>> Thank you in advance.
>>>>> Best regards
>>>>> Christian
>>>>> _._._._._._._._._._._._._._._._._._
>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>> e.m.a.i.l: cstrato at aon.at
>>>>> _._._._._._._._._._._._._._._._._._
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cstrato at aon.at  Tue Sep 14 23:58:51 2010
From: cstrato at aon.at (cstrato)
Date: Tue, 14 Sep 2010 23:58:51 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FE9EE.60604@fhcrc.org>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
	<4C8FE527.6060308@aon.at> <4C8FE9EE.60604@fhcrc.org>
Message-ID: <4C8FF01B.6060208@aon.at>

Dear Herve,

Thank you for your reply, however maybe I was not quite clear.

The files xpsDict.h and xpsDict.cxx are automatically created by the 
ROOT framework during compilation on every architecture. This means they 
are created on Linux and Mac with LF line endings, but on Windows with 
CRLF line endings. However, they are created only if they do not already 
exist, and thus are not in the source tarball.

For testing purposes I have just added both files with LF line endings 
to the source tarball and compiled it on Windows w/o problems. 
Furthermore, the  size of "xps_1.9.6.tar.gz" increases only from 4MB to 
4.3MB. Thus in principle I could upload both files to SVN for BioC 2.7, 
and this should eliminate the warning message. What is your opinion?

Best regards
Christian


On 9/14/10 11:32 PM, Herv? Pag?s wrote:
> Hi Christian,
>
> On 09/14/2010 02:12 PM, cstrato wrote:
>> Dear Simon,
>>
>> Thank you for this clarification/suggestion, however I am confused. What
>> do you mean with "If the file is created automatically then it has no
>> business being in the package."?
>
> He means it shouldn't be in the source tarball. We run 'R CMD check'
> on source trees or source tarballs. Source tarballs are platform
> independent. If I understand correctly when you run 'R CMD build'
> on your source tree, you use some trick to generate this src/xpsDict.h
> file on Windows and this file ends up in the source tarball.
> But the source tarball created on Linux won't have this file.
> That doesn't sound like a good thing to me to have the content
> of the source tarball depending on the machine you've run
> 'R CMD build'. In other words, you should try to generate this
> src/xpsDict.h file at installation time but it shouldn't end up
> in the source tarball.
> My 2 cents...
>
> Cheers,
> H.
>
>>
>> If you download the source code of my package from:
>> http://bioconductor.org/packages/2.7/bioc/html/xps.html
>> you will see that this file is not in the package.
>>
>> However, I could indeed add the corrected files xpsDict.h and
>> xpsDict.cxx to the source code of my package. There is only one problem.
>> Currently the source code "xps_1.9.6.tar.gz" has a total size of 4MB.
>> Adding the corrected files will add another 4MB to the source code.
>>
>> Best regards
>> Christian
>>
>>
>> On 9/14/10 9:59 PM, Simon Urbanek wrote:
>>>
>>> On Sep 14, 2010, at 2:27 PM, cstrato wrote:
>>>
>>>> Dear Bill,
>>>>
>>>> It would be great if this warning message could at least be
>>>> suppressed on Windows.
>>>>
>>>
>>> I think you're missing the point - you should be fixing that file
>>> instead - it doesn't matter whether you're on Windows or not. If the
>>> file is created automatically then it has no business being in the
>>> package. Otherwise you should simply post-process it (e.g., as Dirk
>>> suggested) after it has been generated but before you create the
>>> package - that is the common practice with generated files that need
>>> to be part of the distribution.
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>>
>>>> On 9/14/10 2:06 AM, William Dunlap wrote:
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: r-devel-bounces at r-project.org
>>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>>>>>> Sent: Monday, September 13, 2010 2:08 PM
>>>>>> To: r-devel at r-project.org
>>>>>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> When running R CMD check on Windows XP to test my package I get the
>>>>>> following warning message:
>>>>>>
>>>>>> "* checking line endings in C/C++/Fortran sources/headers ... WARNING
>>>>>> Found the following sources/headers with CR or CRLF line endings:
>>>>>> src/xpsDict.h"
>>>>>>
>>>>>> The problem is that this file is created by the compiler
>>>>>> AUTOMATICALLY
>>>>>> during the compilation process, and since the file is created
>>>>>> by VC++ on
>>>>>> WinXP, it will always have CRLF line endings.
>>>>>>
>>>>>> Thus my question is:
>>>>>> - Is it really necessary to issues this warning message?
>>>>>> - If yes, could it be suppressed on Windows XP, since there it should
>>>>>> obviously be no problem.
>>>>>
>>>>> Older versions of Sun C compilers would refuse to
>>>>> compile code with Windows-style line endings. I don't
>>>>> know if that is still the case. One reason to run check
>>>>> is to see if there are any platform-dependencies in
>>>>> code on CRAN so the warning should not be suppressed.
>>>>>
>>>>> (The S+ package system tries to avoid the problem by changing
>>>>> line endings on text files when it compiles the package.
>>>>> It is not trivial to reliably figure out which files are
>>>>> meant to be text files.)
>>>>>
>>>>> Bill Dunlap
>>>>> Spotfire, TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>>
>>>>>> One more issue:
>>>>>> While I have always received this warning on my WinXP
>>>>>> installation, for
>>>>>> some lucky reason the warning did until now not appear on the
>>>>>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>>>>>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
>>>>> pool-checksrc.html
>>>>>>
>>>>>> However, for some reason on BioC 2.7 running R-2.12.0 this
>>>>>> warning does
>>>>>> appear, see:
>>>>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
>>>>> pool-checksrc.html
>>>>>> For this reason I would appreciate if there would be a
>>>>>> possibility to
>>>>>> suppress this warning message.
>>>>>>
>>>>>> Thank you in advance.
>>>>>> Best regards
>>>>>> Christian
>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hpages at fhcrc.org  Wed Sep 15 00:08:40 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 14 Sep 2010 15:08:40 -0700
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FF01B.6060208@aon.at>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
	<4C8FE527.6060308@aon.at> <4C8FE9EE.60604@fhcrc.org>
	<4C8FF01B.6060208@aon.at>
Message-ID: <4C8FF268.9010500@fhcrc.org>

On 09/14/2010 02:58 PM, cstrato wrote:
> Dear Herve,
>
> Thank you for your reply, however maybe I was not quite clear.
>
> The files xpsDict.h and xpsDict.cxx are automatically created by the
> ROOT framework during compilation on every architecture.

on every architecture... ok
But if they are created during compilation, why do they need to be
included in the source tarball? They are just temporary files right?
Or I'm missing something...

> This means they
> are created on Linux and Mac with LF line endings, but on Windows with
> CRLF line endings. However, they are created only if they do not already
> exist, and thus are not in the source tarball.

I guess you mean they are not part of the source *tree*.

>
> For testing purposes I have just added both files with LF line endings
> to the source tarball and compiled it on Windows w/o problems.
> Furthermore, the size of "xps_1.9.6.tar.gz" increases only from 4MB to
> 4.3MB. Thus in principle I could upload both files to SVN for BioC 2.7,
> and this should eliminate the warning message. What is your opinion?

I still don't understand why you want to have them in the source
tarball.

H.

>
> Best regards
> Christian
>
>
> On 9/14/10 11:32 PM, Herv? Pag?s wrote:
>> Hi Christian,
>>
>> On 09/14/2010 02:12 PM, cstrato wrote:
>>> Dear Simon,
>>>
>>> Thank you for this clarification/suggestion, however I am confused. What
>>> do you mean with "If the file is created automatically then it has no
>>> business being in the package."?
>>
>> He means it shouldn't be in the source tarball. We run 'R CMD check'
>> on source trees or source tarballs. Source tarballs are platform
>> independent. If I understand correctly when you run 'R CMD build'
>> on your source tree, you use some trick to generate this src/xpsDict.h
>> file on Windows and this file ends up in the source tarball.
>> But the source tarball created on Linux won't have this file.
>> That doesn't sound like a good thing to me to have the content
>> of the source tarball depending on the machine you've run
>> 'R CMD build'. In other words, you should try to generate this
>> src/xpsDict.h file at installation time but it shouldn't end up
>> in the source tarball.
>> My 2 cents...
>>
>> Cheers,
>> H.
>>
>>>
>>> If you download the source code of my package from:
>>> http://bioconductor.org/packages/2.7/bioc/html/xps.html
>>> you will see that this file is not in the package.
>>>
>>> However, I could indeed add the corrected files xpsDict.h and
>>> xpsDict.cxx to the source code of my package. There is only one problem.
>>> Currently the source code "xps_1.9.6.tar.gz" has a total size of 4MB.
>>> Adding the corrected files will add another 4MB to the source code.
>>>
>>> Best regards
>>> Christian
>>>
>>>
>>> On 9/14/10 9:59 PM, Simon Urbanek wrote:
>>>>
>>>> On Sep 14, 2010, at 2:27 PM, cstrato wrote:
>>>>
>>>>> Dear Bill,
>>>>>
>>>>> It would be great if this warning message could at least be
>>>>> suppressed on Windows.
>>>>>
>>>>
>>>> I think you're missing the point - you should be fixing that file
>>>> instead - it doesn't matter whether you're on Windows or not. If the
>>>> file is created automatically then it has no business being in the
>>>> package. Otherwise you should simply post-process it (e.g., as Dirk
>>>> suggested) after it has been generated but before you create the
>>>> package - that is the common practice with generated files that need
>>>> to be part of the distribution.
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>>>
>>>>> On 9/14/10 2:06 AM, William Dunlap wrote:
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: r-devel-bounces at r-project.org
>>>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of cstrato
>>>>>>> Sent: Monday, September 13, 2010 2:08 PM
>>>>>>> To: r-devel at r-project.org
>>>>>>> Subject: [Rd] Problem with WARNING...headers with CRLF line endings
>>>>>>>
>>>>>>> Dear all,
>>>>>>>
>>>>>>> When running R CMD check on Windows XP to test my package I get the
>>>>>>> following warning message:
>>>>>>>
>>>>>>> "* checking line endings in C/C++/Fortran sources/headers ...
>>>>>>> WARNING
>>>>>>> Found the following sources/headers with CR or CRLF line endings:
>>>>>>> src/xpsDict.h"
>>>>>>>
>>>>>>> The problem is that this file is created by the compiler
>>>>>>> AUTOMATICALLY
>>>>>>> during the compilation process, and since the file is created
>>>>>>> by VC++ on
>>>>>>> WinXP, it will always have CRLF line endings.
>>>>>>>
>>>>>>> Thus my question is:
>>>>>>> - Is it really necessary to issues this warning message?
>>>>>>> - If yes, could it be suppressed on Windows XP, since there it
>>>>>>> should
>>>>>>> obviously be no problem.
>>>>>>
>>>>>> Older versions of Sun C compilers would refuse to
>>>>>> compile code with Windows-style line endings. I don't
>>>>>> know if that is still the case. One reason to run check
>>>>>> is to see if there are any platform-dependencies in
>>>>>> code on CRAN so the warning should not be suppressed.
>>>>>>
>>>>>> (The S+ package system tries to avoid the problem by changing
>>>>>> line endings on text files when it compiles the package.
>>>>>> It is not trivial to reliably figure out which files are
>>>>>> meant to be text files.)
>>>>>>
>>>>>> Bill Dunlap
>>>>>> Spotfire, TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>>>
>>>>>>> One more issue:
>>>>>>> While I have always received this warning on my WinXP
>>>>>>> installation, for
>>>>>>> some lucky reason the warning did until now not appear on the
>>>>>>> Bioconductor Windows server, see BioC 2.6 with R-2.11.1:
>>>>>>> http://bioconductor.org/checkResults/2.6/bioc-LATEST/xps/liver
>>>>>> pool-checksrc.html
>>>>>>>
>>>>>>> However, for some reason on BioC 2.7 running R-2.12.0 this
>>>>>>> warning does
>>>>>>> appear, see:
>>>>>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/xps/liver
>>>>>> pool-checksrc.html
>>>>>>> For this reason I would appreciate if there would be a
>>>>>>> possibility to
>>>>>>> suppress this warning message.
>>>>>>>
>>>>>>> Thank you in advance.
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Wed Sep 15 00:30:39 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Sep 2010 18:30:39 -0400
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FF268.9010500@fhcrc.org>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>
	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>
	<4C8FF268.9010500@fhcrc.org>
Message-ID: <4C8FF78F.5020407@gmail.com>

On 14/09/2010 6:08 PM, Herv? Pag?s wrote:
> On 09/14/2010 02:58 PM, cstrato wrote:
>> Dear Herve,
>>
>> Thank you for your reply, however maybe I was not quite clear.
>>
>> The files xpsDict.h and xpsDict.cxx are automatically created by the
>> ROOT framework during compilation on every architecture.
> 
> on every architecture... ok
> But if they are created during compilation, why do they need to be
> included in the source tarball? They are just temporary files right?
> Or I'm missing something...
> 
>> This means they
>> are created on Linux and Mac with LF line endings, but on Windows with
>> CRLF line endings. However, they are created only if they do not already
>> exist, and thus are not in the source tarball.
> 
> I guess you mean they are not part of the source *tree*.
> 
>> For testing purposes I have just added both files with LF line endings
>> to the source tarball and compiled it on Windows w/o problems.
>> Furthermore, the size of "xps_1.9.6.tar.gz" increases only from 4MB to
>> 4.3MB. Thus in principle I could upload both files to SVN for BioC 2.7,
>> and this should eliminate the warning message. What is your opinion?
> 
> I still don't understand why you want to have them in the source
> tarball.

I think he doesn't want to put them in the source tarball, but because 
of the way R CMD check works, he may have to.

It appears that R CMD check builds those files, and then checks for CRLF 
endings on all files.  If it did the CRLF check first, it wouldn't see 
them and complain.  The problem with this change is that some packages 
might create files with CRLF endings on all platforms, and then check 
*should* complain about them.

My advice would be not to put them in the tarball, and ignore the 
warning.  Or write a Makevars.win that fixes the line endings so that 
check is happy.

Duncan Murdoch


From hpages at fhcrc.org  Wed Sep 15 01:58:01 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 14 Sep 2010 16:58:01 -0700
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C8FF78F.5020407@gmail.com>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>
	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>
	<4C8FF268.9010500@fhcrc.org> <4C8FF78F.5020407@gmail.com>
Message-ID: <4C900C09.2010509@fhcrc.org>

On 09/14/2010 03:30 PM, Duncan Murdoch wrote:
> On 14/09/2010 6:08 PM, Herv? Pag?s wrote:
>> On 09/14/2010 02:58 PM, cstrato wrote:
>>> Dear Herve,
>>>
>>> Thank you for your reply, however maybe I was not quite clear.
>>>
>>> The files xpsDict.h and xpsDict.cxx are automatically created by the
>>> ROOT framework during compilation on every architecture.
>>
>> on every architecture... ok
>> But if they are created during compilation, why do they need to be
>> included in the source tarball? They are just temporary files right?
>> Or I'm missing something...
>>
>>> This means they
>>> are created on Linux and Mac with LF line endings, but on Windows with
>>> CRLF line endings. However, they are created only if they do not already
>>> exist, and thus are not in the source tarball.
>>
>> I guess you mean they are not part of the source *tree*.
>>
>>> For testing purposes I have just added both files with LF line endings
>>> to the source tarball and compiled it on Windows w/o problems.
>>> Furthermore, the size of "xps_1.9.6.tar.gz" increases only from 4MB to
>>> 4.3MB. Thus in principle I could upload both files to SVN for BioC 2.7,
>>> and this should eliminate the warning message. What is your opinion?
>>
>> I still don't understand why you want to have them in the source
>> tarball.
>
> I think he doesn't want to put them in the source tarball, but because
> of the way R CMD check works, he may have to.
>
> It appears that R CMD check builds those files, and then checks for CRLF
> endings on all files. If it did the CRLF check first, it wouldn't see
> them and complain. The problem with this change is that some packages
> might create files with CRLF endings on all platforms, and then check
> *should* complain about them.

I see your point but, on the other hand, and more generally speaking,
you expect 'R CMD check' to check the source files i.e. the files that
belong to the source tarball, and not temporary compilation/installation
products that 'R CMD INSTALL' didn't remove (for whatever reason).

It's weird to get a message like:

   * checking line endings in C/C++/Fortran sources/headers ... WARNING
   Found the following sources/headers with CR or CRLF line endings:
     src/xpsDict.h

if there is no such file in the source tarball.

>
> My advice would be not to put them in the tarball, and ignore the
> warning. Or write a Makevars.win that fixes the line endings so that
> check is happy.

Yes and since he already uses a Makefile, it should be easy to remove
those files at the end of installation so they don't end up in the
tarball anymore. Wouldn't that also be enough to silent 'R CMD check'?
Perhaps package authors should really make sure that src/ gets
cleaned after the installation step of 'R CMD build' (this step is
performed only if the package has vignettes). Then it shouldn't matter
whether 'R CMD check' checks for CRLF endings after or before
installing the package.

Cheers,
H.

>
> Duncan Murdoch


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From btyner at gmail.com  Wed Sep 15 03:23:25 2010
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 14 Sep 2010 21:23:25 -0400
Subject: [Rd] warning or error upon type/storage mode coercion?
Message-ID: <4C90200D.2030208@gmail.com>

Hi,

I'm aware that the language definition states "R objects are often 
coerced to different types during computations". Two questions:

1. Is it possible to configure the R environment so that, for example, 
coercion from (say) numeric to integer will throw a warning or an error? 
I realize that in the base R code alone, there are thousands of calls to 
as.integer() which would trigger such an event, so this would not be a 
very practical configuration...

2. So, assuming the answer to (1) is a resounding "no", does anyone care 
to state an opinion regarding the philosophical or historical rationale 
for why this is the case in R/S, whereas certain other interpreted 
languages offer the option to perform strict type checking? Basically, 
I'm trying to explain to someone from a perl background why the 
(apparent) lack of a "use strict; use warnings;" equivalent is not a 
hindrance to writing bullet-proof R code.

Thanks,
Ben


From hb at stat.berkeley.edu  Wed Sep 15 03:26:31 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 14 Sep 2010 18:26:31 -0700
Subject: [Rd] Suggestion: Add DESCRIPTION 'Date' to R CMD check log header
Message-ID: <AANLkTik7PQ6VJDzMqq0nDp2pph3oyAGnt1fbZRPz1du4@mail.gmail.com>

Hi,

in R CMD check, the version of the package being checked is reported, e.g.

Thu Sep  9 05:02:30 2010: Checking package R.utils (SVN revision 399) ...
* using log directory ?/srv/R/R.check/R-devel/PKGS/R.utils.Rcheck?
* using R version 2.12.0 Under development (unstable) (2010-09-07 r52876)
* using platform: x86_64-unknown-linux-gnu (64-bit)
* using session charset: UTF-8
* checking for file ?R.utils/DESCRIPTION? ... OK
* this is package ?R.utils? version ?1.5.2?
...

I'd like to request/suggest that the 'Date' in the DESCRIPTION file is
also added, e.g.

* this is package ?R.utils? version ?1.5.2? ('2010-09-14')


WHY?
This would be particular useful when you work toward sites like
R-forge and Bioconductor when you may commit your day's work on
package when you update the 'Date' but you do not really want to
update the 'Version' because you're going to put in more work
tomorrow.  With the 'Date' information you'll be able to see what
"version" of your updates have been checked by the servers.  I
understand that this may be an odd process to follow even for devel
branches and you may argue that you should always bump the version
number whenever you do an SVN commit (e.g. '1.5.2.1' for temporary
commits).  Either way, I find it useful to see the date as well.

Thxs

Henrik


From hb at stat.berkeley.edu  Wed Sep 15 06:18:51 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 14 Sep 2010 21:18:51 -0700
Subject: [Rd] warning or error upon type/storage mode coercion?
In-Reply-To: <4C90200D.2030208@gmail.com>
References: <4C90200D.2030208@gmail.com>
Message-ID: <AANLkTinKPpqi7R2n+3x_yzXs36zjSEd_7JaxGif3xZVU@mail.gmail.com>

On Tue, Sep 14, 2010 at 6:23 PM, Benjamin Tyner <btyner at gmail.com> wrote:
> Hi,
>
> I'm aware that the language definition states "R objects are often coerced
> to different types during computations". Two questions:
>
> 1. Is it possible to configure the R environment so that, for example,
> coercion from (say) numeric to integer will throw a warning or an error? I
> realize that in the base R code alone, there are thousands of calls to
> as.integer() which would trigger such an event, so this would not be a very
> practical configuration...
>
> 2. So, assuming the answer to (1) is a resounding "no", does anyone care to
> state an opinion regarding the philosophical or historical rationale for why
> this is the case in R/S, whereas certain other interpreted languages offer
> the option to perform strict type checking? Basically, I'm trying to explain
> to someone from a perl background why the (apparent) lack of a "use strict;
> use warnings;" equivalent is not a hindrance to writing bullet-proof R code.

For what's it's worth: it is only recently (only some R releases ago)
that the language/parser gained the syntax for specifying an integer,
e.g. 2L.  I guess, before this the only option you had to get an
integer was through coercion, e.g. as.integer(2), storage.mode(), but
also tricks such as 2:2.  So in some sense from the parsers point of
view, everything was doubles in the beginning.  (disclaimer: I might
be missing something).

My $.02

/Henrik

PS. OT, but reading help(":") I just learned that a:b is not always
the same as rev(b:a).

>
> Thanks,
> Ben
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From maechler at stat.math.ethz.ch  Wed Sep 15 09:49:13 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 15 Sep 2010 09:49:13 +0200
Subject: [Rd] Suggestion: Add DESCRIPTION 'Date' to R CMD check log
	header
In-Reply-To: <AANLkTik7PQ6VJDzMqq0nDp2pph3oyAGnt1fbZRPz1du4@mail.gmail.com>
References: <AANLkTik7PQ6VJDzMqq0nDp2pph3oyAGnt1fbZRPz1du4@mail.gmail.com>
Message-ID: <19600.31353.292555.862815@lynne.math.ethz.ch>

Hi Henrik

>>>>> "HB" == Henrik Bengtsson <hb at stat.berkeley.edu>
>>>>>     on Tue, 14 Sep 2010 18:26:31 -0700 writes:

    HB> Hi,
    HB> in R CMD check, the version of the package being checked is reported, e.g.

    HB> Thu Sep  9 05:02:30 2010: Checking package R.utils (SVN revision 399) ...
    HB> * using log directory ?/srv/R/R.check/R-devel/PKGS/R.utils.Rcheck?
    HB> * using R version 2.12.0 Under development (unstable) (2010-09-07 r52876)
    HB> * using platform: x86_64-unknown-linux-gnu (64-bit)
    HB> * using session charset: UTF-8
    HB> * checking for file ?R.utils/DESCRIPTION? ... OK
    HB> * this is package ?R.utils? version ?1.5.2?
    HB> ...

    HB> I'd like to request/suggest that the 'Date' in the DESCRIPTION file is
    HB> also added, e.g.

    HB> * this is package ?R.utils? version ?1.5.2? ('2010-09-14')


    HB> WHY?
    HB> This would be particular useful when you work toward sites like
    HB> R-forge and Bioconductor when you may commit your day's work on
    HB> package when you update the 'Date' but you do not really want to
    HB> update the 'Version' because you're going to put in more work
    HB> tomorrow.  With the 'Date' information you'll be able to see what
    HB> "version" of your updates have been checked by the servers.  I
    HB> understand that this may be an odd process to follow even for devel
    HB> branches and you may argue that you should always bump the version
    HB> number whenever you do an SVN commit (e.g. '1.5.2.1' for temporary
    HB> commits).  Either way, I find it useful to see the date as well.

I agree that this is useful.
Of course, for all those cases, where there's no  "Date:",
nothing (i.e. no "()") should be written.

If you (or someone) provide patches against  R-devel
( https://svn.r-project.org/R/trunk/ )
and they pass 'make check-all', I'd add this feature.

Martin


From stefanML at collocations.de  Wed Sep 15 09:54:50 2010
From: stefanML at collocations.de (Stefan Evert)
Date: Wed, 15 Sep 2010 09:54:50 +0200
Subject: [Rd] warning or error upon type/storage mode coercion?
In-Reply-To: <4C90200D.2030208@gmail.com>
References: <4C90200D.2030208@gmail.com>
Message-ID: <57738BDD-C024-4E96-80A5-C3AB9B7EBA64@collocations.de>


On 15 Sep 2010, at 03:23, Benjamin Tyner wrote:

> 2. So, assuming the answer to (1) is a resounding "no", does anyone care to state an opinion regarding the philosophical or historical rationale for why this is the case in R/S, whereas certain other interpreted languages offer the option to perform strict type checking? Basically, I'm trying to explain to someone from a perl background why the (apparent) lack of a "use strict; use warnings;" equivalent is not a hindrance to writing bullet-proof R code.

If they're from a Perl background, you might also want to point out to them that (base) Perl doesn't do _any_ type checking at all, and converts types as needed.  As in ...

$x = "0.0";
if ($x) ... # true
if ($x+0) ... # false

AFAIK, that's one of the main complaints that people have about Perl.  "use strict" will just make sure that all variables have to be declared before they're used, so you can't mess up by mistyping variable names.  Which is something I'd very much like to have in R occasionally ...

Best,
Stefan


From karl.forner at gmail.com  Wed Sep 15 10:15:03 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Wed, 15 Sep 2010 10:15:03 +0200
Subject: [Rd] Fwd:  warning or error upon type/storage mode coercion?
In-Reply-To: <AANLkTimdBCB3gP_gp+1fGNwdgAFj04xGhJykYHS0F3Dh@mail.gmail.com>
References: <4C90200D.2030208@gmail.com>
	<57738BDD-C024-4E96-80A5-C3AB9B7EBA64@collocations.de>
	<AANLkTimdBCB3gP_gp+1fGNwdgAFj04xGhJykYHS0F3Dh@mail.gmail.com>
Message-ID: <AANLkTim0PZQxb49+f0EkZU0hkVZj7HXgTs-mo623TBg=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100915/7283c9a9/attachment.pl>

From ligges at statistik.tu-dortmund.de  Wed Sep 15 10:55:26 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2010 10:55:26 +0200
Subject: [Rd] value returned by by()
In-Reply-To: <877hiob1mk.fsf@kolob.sebmags.homelinux.org>
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>	<4C8F481C.8010502@statistik.tu-dortmund.de>
	<877hiob1mk.fsf@kolob.sebmags.homelinux.org>
Message-ID: <4C9089FE.40704@statistik.tu-dortmund.de>



On 14.09.2010 20:50, Seb wrote:
> On Tue, 14 Sep 2010 12:02:04 +0200,
> Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>
>> It returns a list with athe class attribut set to "by", just use: x<-
>> by(.....)  unclass(x)
>
> Thanks Uwe, however, that still returns an array when using the
> data.frame method for by():
>
> R>  class(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))))
> [1] "array"
>
> It seems as if the only way to really ensure a list:
>
> R>  class(lapply(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))), function(x) x))
> [1] "list"
>
> but it seems like a waste to call another function just to do this.
>
>

Then you could still do

x <- by(.....)
attributes(x) <- NULL

Uwe


From Kurt.Hornik at wu.ac.at  Wed Sep 15 10:55:33 2010
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Wed, 15 Sep 2010 10:55:33 +0200
Subject: [Rd] Suggestion: Add DESCRIPTION 'Date' to R CMD check
	log	header
In-Reply-To: <19600.31353.292555.862815@lynne.math.ethz.ch>
References: <AANLkTik7PQ6VJDzMqq0nDp2pph3oyAGnt1fbZRPz1du4@mail.gmail.com>
	<19600.31353.292555.862815@lynne.math.ethz.ch>
Message-ID: <19600.35333.563429.174054@fangorn.hornik.net>

>>>>> Martin Maechler writes:

> Hi Henrik
>>>>> "HB" == Henrik Bengtsson <hb at stat.berkeley.edu>
>>>>>     on Tue, 14 Sep 2010 18:26:31 -0700 writes:

HB> Hi,
HB> in R CMD check, the version of the package being checked is reported, e.g.

HB> Thu Sep  9 05:02:30 2010: Checking package R.utils (SVN revision 399) ...
HB> * using log directory ?/srv/R/R.check/R-devel/PKGS/R.utils.Rcheck?
HB> * using R version 2.12.0 Under development (unstable) (2010-09-07 r52876)
HB> * using platform: x86_64-unknown-linux-gnu (64-bit)
HB> * using session charset: UTF-8
HB> * checking for file ?R.utils/DESCRIPTION? ... OK
HB> * this is package ?R.utils? version ?1.5.2?
HB> ...

HB> I'd like to request/suggest that the 'Date' in the DESCRIPTION file is
HB> also added, e.g.

HB> * this is package ?R.utils? version ?1.5.2? ('2010-09-14')


HB> WHY?
HB> This would be particular useful when you work toward sites like
HB> R-forge and Bioconductor when you may commit your day's work on
HB> package when you update the 'Date' but you do not really want to
HB> update the 'Version' because you're going to put in more work
HB> tomorrow.  With the 'Date' information you'll be able to see what
HB> "version" of your updates have been checked by the servers.  I
HB> understand that this may be an odd process to follow even for devel
HB> branches and you may argue that you should always bump the version
HB> number whenever you do an SVN commit (e.g. '1.5.2.1' for temporary
HB> commits).  Either way, I find it useful to see the date as well.

> I agree that this is useful.
> Of course, for all those cases, where there's no  "Date:",
> nothing (i.e. no "()") should be written.

> If you (or someone) provide patches against  R-devel
> ( https://svn.r-project.org/R/trunk/ )
> and they pass 'make check-all', I'd add this feature.

But pls not against the Date field by default:

R-Forge packages record their revision in their package metadata.

CRAN packages record Date/Publication in their metadata.

Not sure about BioC ...

-k

From romain.francois at dbmail.com  Wed Sep 15 11:21:47 2010
From: romain.francois at dbmail.com (Romain Francois)
Date: Wed, 15 Sep 2010 11:21:47 +0200
Subject: [Rd] list2env( list() )
Message-ID: <4C90902B.7030803@dbmail.com>

Hello,

list2env generates an error on empty lists.

 > l <- list()
 > list2env( l )
Erreur dans list2env(l) : names(x) must be valid character(length(x)).


This is consistent with the requirement that the list must be a 
__named__ list, so this works:

 > names(l) <- character(0)
 > list2env( l )
<environment: 0x102b8fbc8>


But I was wondering if it would make sense to make a special case of 
zero sized lists, with this:

Index: src/main/envir.c
===================================================================
--- src/main/envir.c	(revision 52910)
+++ src/main/envir.c	(working copy)
@@ -1555,7 +1555,7 @@
      x = CAR(args); args = CDR(args);
      n = LENGTH(x);
      xnms = getAttrib(x, R_NamesSymbol);
-    if (TYPEOF(xnms) != STRSXP || LENGTH(xnms) != n)
+    if (n && (TYPEOF(xnms) != STRSXP || LENGTH(xnms) != n) )
  	error(_("names(x) must be valid character(length(x))."));
      envir = CAR(args);  args = CDR(args);
      if (TYPEOF(envir) == NILSXP) {


Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/cCmbgg : Rcpp 0.8.6
|- http://bit.ly/bzoWrs : Rcpp svn revision 2000
`- http://bit.ly/b8VNE2 : Rcpp at LondonR, oct 5th


From pdalgd at gmail.com  Wed Sep 15 11:29:23 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 15 Sep 2010 11:29:23 +0200
Subject: [Rd] value returned by by()
In-Reply-To: <4C9089FE.40704@statistik.tu-dortmund.de>
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>	<4C8F481C.8010502@statistik.tu-dortmund.de>
	<877hiob1mk.fsf@kolob.sebmags.homelinux.org>
	<4C9089FE.40704@statistik.tu-dortmund.de>
Message-ID: <2EA29852-74F3-4107-A428-3F15C9274D09@gmail.com>


On Sep 15, 2010, at 10:55 , Uwe Ligges wrote:

> 
> 
> On 14.09.2010 20:50, Seb wrote:
>> On Tue, 14 Sep 2010 12:02:04 +0200,
>> Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>> 
>>> It returns a list with athe class attribut set to "by", just use: x<-
>>> by(.....)  unclass(x)
>> 
>> Thanks Uwe, however, that still returns an array when using the
>> data.frame method for by():
>> 
>> R>  class(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))))
>> [1] "array"
>> 
>> It seems as if the only way to really ensure a list:
>> 
>> R>  class(lapply(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))), function(x) x))
>> [1] "list"
>> 
>> but it seems like a waste to call another function just to do this.
>> 
>> 
> 
> Then you could still do
> 
> x <- by(.....)
> attributes(x) <- NULL
> 

Or just use c() instead of unclass(). (The root cause is that even with simplify=FALSE, tapply() will always create an array, in this case a 1d array with dim=3. The _contents_ of the array will be a list, though.)

Notice that in the relevant cases, what you get really _is_ a list, and both walks and quacks like one.  E.g.

> L <- with(warpbreaks, by(warpbreaks[, 1], tension, mean, simplify=FALSE))
> is.list(L)
[1] TRUE
> L$M
[1] 26.38889






-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spluque at gmail.com  Wed Sep 15 15:00:53 2010
From: spluque at gmail.com (Seb)
Date: Wed, 15 Sep 2010 08:00:53 -0500
Subject: [Rd] value returned by by()
In-Reply-To: <2EA29852-74F3-4107-A428-3F15C9274D09@gmail.com> (peter
	dalgaard's message of "Wed, 15 Sep 2010 11:29:23 +0200")
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>
	<4C8F481C.8010502@statistik.tu-dortmund.de>
	<877hiob1mk.fsf@kolob.sebmags.homelinux.org>
	<4C9089FE.40704@statistik.tu-dortmund.de>
	<2EA29852-74F3-4107-A428-3F15C9274D09@gmail.com>
Message-ID: <87fwxbrwje.fsf@kolob.sebmags.homelinux.org>

On Wed, 15 Sep 2010 11:29:23 +0200,
peter dalgaard <pdalgd at gmail.com> wrote:

> On Sep 15, 2010, at 10:55 , Uwe Ligges wrote:

> > 
> > 
> > On 14.09.2010 20:50, Seb wrote:
> >> On Tue, 14 Sep 2010 12:02:04 +0200,
> >> Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
> >> 
> >>> It returns a list with athe class attribut set to "by", just use: x<-
> >>> by(.....)  unclass(x)
> >> 
> >> Thanks Uwe, however, that still returns an array when using the
> >> data.frame method for by():
> >> 
> >> R>  class(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))))
> >> [1] "array"
> >> 
> >> It seems as if the only way to really ensure a list:
> >> 
> >> R>  class(lapply(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))), function(x) x))
> >> [1] "list"
> >> 
> >> but it seems like a waste to call another function just to do this.
> >> 
> >> 
> > 
> > Then you could still do
> > 
> > x <- by(.....)
> > attributes(x) <- NULL
> > 

> Or just use c() instead of unclass(). (The root cause is that even with simplify=FALSE, tapply() will always create an array, in this case a 1d array with dim=3. The _contents_ of the array will be a list, though.)

> Notice that in the relevant cases, what you get really _is_ a list, and both walks and quacks like one.  E.g.

> > L <- with(warpbreaks, by(warpbreaks[, 1], tension, mean, simplify=FALSE))
> > is.list(L)
> [1] TRUE
> > L$M
> [1] 26.38889

But if one tries to include this list dressed in 'by' clothes into an S4
class slot declared as a list, then we have problems.  In that case, I
propose this simple patch to by.Rd, which simply removes the statement
about the result being *always* a list.


Index: by.Rd
===================================================================
--- by.Rd	(revision 52375)
+++ by.Rd	(working copy)
@@ -36,8 +36,6 @@
 }
 \value{
   An object of class \code{"by"}, giving the results for each subset.
-  This is always a list if \code{simplify} is false, otherwise a list or
-  array (see \code{\link{tapply}}).
 }
 \seealso{\code{\link{tapply}}}


Thanks!

-- 
Seb


From ligges at statistik.tu-dortmund.de  Wed Sep 15 15:08:48 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2010 15:08:48 +0200
Subject: [Rd] S3 method for package listed in suggest/enhance
In-Reply-To: <AANLkTinP-oDc=EHUvFZi3ShsiYwrMeMhi3xEbxyyEBp9@mail.gmail.com>
References: <AANLkTinP-oDc=EHUvFZi3ShsiYwrMeMhi3xEbxyyEBp9@mail.gmail.com>
Message-ID: <4C90C560.1090100@statistik.tu-dortmund.de>



On 01.09.2010 17:38, Hadley Wickham wrote:
> Hi all,
>
> The profr package provides a method for displaying its output with
> ggplot: ggplot.print.  You don't need this ggplot2 to use profr, so
> ggplot2 is listed under enhances in the DESCRIPTION file.
>
> If I have just S3method(ggplot, profr) in my NAMESPACE, then I get:
>
> ** testing if installed package can be loaded
> Error : object 'ggplot' not found whilst loading namespace 'profr'
> ERROR: loading failed
>
> If I have both S3method(ggplot, profr) and importFrom(ggplot2,
> ggplot), then I get:
>
> * checking package dependencies ... ERROR
> Namespace dependency not required: ggplot2
>
> What's the correct way of exporting an S3 method for a generic in a
> suggested package?


I think you need to declare it as a Depends, since it has to be 
available for getting the Namespace directives right.

Uwe


> Thanks,
>
> Hadley
>
>
>


From ligges at statistik.tu-dortmund.de  Wed Sep 15 15:15:27 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2010 15:15:27 +0200
Subject: [Rd] value returned by by()
In-Reply-To: <87fwxbrwje.fsf@kolob.sebmags.homelinux.org>
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>	<4C8F481C.8010502@statistik.tu-dortmund.de>	<877hiob1mk.fsf@kolob.sebmags.homelinux.org>	<4C9089FE.40704@statistik.tu-dortmund.de>	<2EA29852-74F3-4107-A428-3F15C9274D09@gmail.com>
	<87fwxbrwje.fsf@kolob.sebmags.homelinux.org>
Message-ID: <4C90C6EF.6030200@statistik.tu-dortmund.de>



On 15.09.2010 15:00, Seb wrote:
> On Wed, 15 Sep 2010 11:29:23 +0200,
> peter dalgaard<pdalgd at gmail.com>  wrote:
>
>> On Sep 15, 2010, at 10:55 , Uwe Ligges wrote:
>
>>>
>>>
>>> On 14.09.2010 20:50, Seb wrote:
>>>> On Tue, 14 Sep 2010 12:02:04 +0200,
>>>> Uwe Ligges<ligges at statistik.tu-dortmund.de>   wrote:
>>>>
>>>>> It returns a list with athe class attribut set to "by", just use: x<-
>>>>> by(.....)  unclass(x)
>>>>
>>>> Thanks Uwe, however, that still returns an array when using the
>>>> data.frame method for by():
>>>>
>>>> R>   class(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))))
>>>> [1] "array"
>>>>
>>>> It seems as if the only way to really ensure a list:
>>>>
>>>> R>   class(lapply(unclass(with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))), function(x) x))
>>>> [1] "list"
>>>>
>>>> but it seems like a waste to call another function just to do this.
>>>>
>>>>
>>>
>>> Then you could still do
>>>
>>> x<- by(.....)
>>> attributes(x)<- NULL
>>>
>
>> Or just use c() instead of unclass(). (The root cause is that even with simplify=FALSE, tapply() will always create an array, in this case a 1d array with dim=3. The _contents_ of the array will be a list, though.)
>
>> Notice that in the relevant cases, what you get really _is_ a list, and both walks and quacks like one.  E.g.
>
>>> L<- with(warpbreaks, by(warpbreaks[, 1], tension, mean, simplify=FALSE))
>>> is.list(L)
>> [1] TRUE
>>> L$M
>> [1] 26.38889
>
> But if one tries to include this list dressed in 'by' clothes into an S4
> class slot declared as a list, then we have problems.  In that case, I
> propose this simple patch to by.Rd, which simply removes the statement
> about the result being *always* a list.
>
>
> Index: by.Rd
> ===================================================================
> --- by.Rd	(revision 52375)
> +++ by.Rd	(working copy)
> @@ -36,8 +36,6 @@
>   }
>   \value{
>     An object of class \code{"by"}, giving the results for each subset.
> -  This is always a list if \code{simplify} is false, otherwise a list or
> -  array (see \code{\link{tapply}}).
>   }
>   \seealso{\code{\link{tapply}}}
>
>
> Thanks!
>

Why? It is still accessible as a list, even with S4 object, at least for 
the cases I tried.

Uwe Ligges


From ligges at statistik.tu-dortmund.de  Wed Sep 15 15:23:01 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2010 15:23:01 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
Message-ID: <4C90C8B5.1020802@statistik.tu-dortmund.de>



On 29.08.2010 22:34, Kyle Matoba wrote:
> All,
>
> I just finished the process of build a package for the first time and found
> it characteristically (for R) very straightforward and well documented.
>
> Whenever I deal with open source software I always endeavor to finish the
> task I have in mind, and upon completing this, I then revisit all of the
> configurations, customizing as necessary to achieve my goals more fully.
>   The ability to achieve some minimal level of functionality without the need
> for much filling in of configuration files, etc., is, I feel, important to
> not scaring off the less technically inclined such as myself.
>
> Based on this heuristic, it is my understanding that a few small suggestions
> could make building a warning-free package as easy as running
> package.skeleton(), then R CMD check, R CMD build:
>
> - Fill in default titles for each of the '*.Rd' files in /man
> - Take out the tildes in the 'examples' section of the '*-package.Rd' main
> documentation file for the package (it seems to confuse the latex compiler)
> - Put the lines '~~ Optionally other standard keywords, one per line, from
> file KEYWORDS in ~~
> ~~ the R documentation directory ~~' into the \references{} section, there
> is presently a warning about all text needing to be in a section.


Dear Kyle,

thanks for the suggestions. Actually, it is intended to generate 
warnings / Errors in R CMD check: We want to force package developers to 
document their packages probably. This way, package maintainers / 
developers have to touch each Rd file and cannot use them as is in order 
to pass the checks.

Best wishes,
uwe




> Thanks, as always, to everyone for their hard work to keep my statistical
> computing free and easy.
>
> Best,
>
> Kyle
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From spluque at gmail.com  Wed Sep 15 15:28:44 2010
From: spluque at gmail.com (Seb)
Date: Wed, 15 Sep 2010 08:28:44 -0500
Subject: [Rd] value returned by by()
In-Reply-To: <4C90C6EF.6030200@statistik.tu-dortmund.de> (Uwe Ligges's message
	of "Wed, 15 Sep 2010 15:15:27 +0200")
References: <87vd69b8f6.fsf@kolob.sebmags.homelinux.org>
	<4C8F481C.8010502@statistik.tu-dortmund.de>
	<877hiob1mk.fsf@kolob.sebmags.homelinux.org>
	<4C9089FE.40704@statistik.tu-dortmund.de>
	<2EA29852-74F3-4107-A428-3F15C9274D09@gmail.com>
	<87fwxbrwje.fsf@kolob.sebmags.homelinux.org>
	<4C90C6EF.6030200@statistik.tu-dortmund.de>
Message-ID: <87aanj6sqb.fsf@kolob.sebmags.homelinux.org>

On Wed, 15 Sep 2010 15:15:27 +0200,
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> Why? It is still accessible as a list, even with S4 object, at least
> for the cases I tried.


R> wL <- with(warpbreaks, by(warpbreaks[, 1:2], tension, summary))
R> setClass("Whatever",
+          representation=representation(A="list"))
[1] "Whatever"
R> new("Whatever", A=wL)
Error in validObject(.Object) : 
  invalid class "Whatever" object: invalid object for slot "A" in class "Whatever": got class "by", should be or extend class "list"


-- 
Seb


From janko.thyson at ku-eichstaett.de  Wed Sep 15 15:29:21 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Wed, 15 Sep 2010 15:29:21 +0200
Subject: [Rd] Roxygen: question regarding 'use.Rd2' and creation of
	DESCRIPTION
Message-ID: <000601cb54da$01a6bf60$04f43e20$@thyson@ku-eichstaett.de>

Dear List,

I ran into the following two problems while using the package 'roxygen':

QUESTION 1
I split the relevant R-Code for my package into the following scripts:
classes.R (S4), functions.R ('standard' functions), generics.R (S4),
methods.R (S4). Function package.skeleton() generates Rd-files for all class
defs, function defs etc. in dir 'pkg/man'. So far, so good. Now, I'd like to
run 'roxygenize()' on dir 'pkg' and face the problem that the argument
'use.Rd2' only works for parts of the Rd-files, no matter how it is
specified. Setting it FALSE works for all non-S4 defs, setting it TRUE works
for all S4-defs ('works' in the sense of ending up with non-empty \title{}
in the Rd-files). However, both types of defs are in 'pkg/man' or 'pkg/R',
respectivley. 

I implemented a workaround in which each of the four scripts is addressed
separately by package.skeleton() and roxygenize(). The resulting Rd-files
are stored in temp dirs (e.g. 'pkg/tmp_classes', 'pgk/tmp_functions' etc.)
and are merged to 'pkg/man' at the very end of the process. But I figured
there must be a better or at least more elegant way to do this. Any hints? 

I should mention that not all of my defs (be it non-S4 or S4) are already
prepended with roxygen-code (related to this post
http://stackoverflow.com/questions/2316356/can-roxygen-ignore-non-user-funct
ions), yet the workaround creates non-empty \title{} for all Rd-files. Is
this also possible by running package.skelleton() and roxygenize() just
once?

QUESTION 2
Even though I followed the roxygen vignette closely and also had a look at
the webvis package as suggested here
http://stackoverflow.com/questions/3086081/how-do-you-write-your-package-doc
umentation, I still cannot reproduce a DESCRIPTION file that reflects the
specifications I made via the part of the roxygen-code that is related to
stating the package title, author etc. The outcome in the Rd file
'<pkg_name>-package.Rd' is fine, but the DESCRIPTION file itself still looks
like the dummy created by package.skelleton. Am I doing something wrong
here?

Thanks very much for any suggestions,
Janko


From andy_liaw at merck.com  Wed Sep 15 17:01:16 2010
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Sep 2010 11:01:16 -0400
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <4C90C8B5.1020802@statistik.tu-dortmund.de>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
	<4C90C8B5.1020802@statistik.tu-dortmund.de>
Message-ID: <B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>

From: Uwe Ligges

> 
> 
> On 29.08.2010 22:34, Kyle Matoba wrote:
> > All,
> >
> > I just finished the process of build a package for the 
> first time and found
> > it characteristically (for R) very straightforward and well 
> documented.
> >
> > Whenever I deal with open source software I always endeavor 
> to finish the
> > task I have in mind, and upon completing this, I then 
> revisit all of the
> > configurations, customizing as necessary to achieve my 
> goals more fully.
> >   The ability to achieve some minimal level of 
> functionality without the need
> > for much filling in of configuration files, etc., is, I 
> feel, important to
> > not scaring off the less technically inclined such as myself.
> >
> > Based on this heuristic, it is my understanding that a few 
> small suggestions
> > could make building a warning-free package as easy as running
> > package.skeleton(), then R CMD check, R CMD build:
> >
> > - Fill in default titles for each of the '*.Rd' files in /man
> > - Take out the tildes in the 'examples' section of the 
> '*-package.Rd' main
> > documentation file for the package (it seems to confuse the 
> latex compiler)
> > - Put the lines '~~ Optionally other standard keywords, one 
> per line, from
> > file KEYWORDS in ~~
> > ~~ the R documentation directory ~~' into the \references{} 
> section, there
> > is presently a warning about all text needing to be in a section.
> 
> 
> Dear Kyle,
> 
> thanks for the suggestions. Actually, it is intended to generate 
> warnings / Errors in R CMD check: We want to force package 
> developers to 
> document their packages probably. This way, package maintainers / 
> developers have to touch each Rd file and cannot use them as 
> is in order 
> to pass the checks.

Or else it may be possible to have some malicious person write a script
that 
automagically generate some large number of bogus packages and submit
them to CRAN...

Andy

 
> Best wishes,
> uwe
> 
> 
> 
> 
> > Thanks, as always, to everyone for their hard work to keep 
> my statistical
> > computing free and easy.
> >
> > Best,
> >
> > Kyle
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From pdalgd at gmail.com  Wed Sep 15 17:14:58 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 15 Sep 2010 17:14:58 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
	<4C90C8B5.1020802@statistik.tu-dortmund.de>
	<B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>
Message-ID: <BA6EDF6E-649F-4DC6-A736-C24786569178@gmail.com>


On Sep 15, 2010, at 17:01 , Liaw, Andy wrote:
> 
> Or else it may be possible to have some malicious person write a script
> that 
> automagically generate some large number of bogus packages and submit
> them to CRAN...
> 
> Andy
> 


Douglas Adams - 
- There is a theory which states that if ever anybody discovers exactly what the Universe is for and why it is here, it will instantly disappear and be replaced by something even more bizarre and inexplicable. There is another theory which states that this has already happened.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kmmatoba at stanford.edu  Wed Sep 15 17:18:13 2010
From: kmmatoba at stanford.edu (Kyle Matoba)
Date: Wed, 15 Sep 2010 08:18:13 -0700
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <4C90C8B5.1020802@statistik.tu-dortmund.de>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
	<4C90C8B5.1020802@statistik.tu-dortmund.de>
Message-ID: <AANLkTikSvWfEbSUnDQ2pzg9LkEn=cCQPBmBu5BfJpwAS@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100915/0b6aeea2/attachment.pl>

From marc_schwartz at me.com  Wed Sep 15 17:23:40 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 15 Sep 2010 10:23:40 -0500
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <BA6EDF6E-649F-4DC6-A736-C24786569178@gmail.com>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
	<4C90C8B5.1020802@statistik.tu-dortmund.de>
	<B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>
	<BA6EDF6E-649F-4DC6-A736-C24786569178@gmail.com>
Message-ID: <75AF845A-F43B-4955-B9DA-AF30F5E6E75A@me.com>

On Sep 15, 2010, at 10:14 AM, peter dalgaard wrote:

> 
> On Sep 15, 2010, at 17:01 , Liaw, Andy wrote:
>> 
>> Or else it may be possible to have some malicious person write a script
>> that 
>> automagically generate some large number of bogus packages and submit
>> them to CRAN...
>> 
>> Andy
>> 
> 
> 
> Douglas Adams - 
> - There is a theory which states that if ever anybody discovers exactly what the Universe is for and why it is here, it will instantly disappear and be replaced by something even more bizarre and inexplicable. There is another theory which states that this has already happened.


BTW, that "other" theory helps to explain some local politicians...  ;-)

Regards,

Marc Schwartz
http://www.wolframalpha.com/input/?i=what+is+the+meaning+of+life%3F


From kmmatoba at stanford.edu  Wed Sep 15 17:19:23 2010
From: kmmatoba at stanford.edu (Kyle Matoba)
Date: Wed, 15 Sep 2010 08:19:23 -0700
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>
References: <AANLkTinefNWVpSSTDuWkCt3Wrgkq=hOZig2ix8Tmv0Pe@mail.gmail.com>
	<4C90C8B5.1020802@statistik.tu-dortmund.de>
	<B10BAA7D28D88B45AF82813C4A6FFA93BAC474@usctmx1157.merck.com>
Message-ID: <AANLkTindXvECbu_hi2MeN4ahJ+x-6hA3p35Djg-s4Ux6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100915/3a7bb7cc/attachment.pl>

From hpages at fhcrc.org  Wed Sep 15 19:18:49 2010
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 15 Sep 2010 10:18:49 -0700
Subject: [Rd] Suggestion: Add DESCRIPTION 'Date' to R CMD
	check	log	header
In-Reply-To: <19600.35333.563429.174054@fangorn.hornik.net>
References: <AANLkTik7PQ6VJDzMqq0nDp2pph3oyAGnt1fbZRPz1du4@mail.gmail.com>	<19600.31353.292555.862815@lynne.math.ethz.ch>
	<19600.35333.563429.174054@fangorn.hornik.net>
Message-ID: <4C90FFF9.4090904@fhcrc.org>

On 09/15/2010 01:55 AM, Kurt Hornik wrote:
>>>>>> Martin Maechler writes:
>
>> Hi Henrik
>>>>>> "HB" == Henrik Bengtsson<hb at stat.berkeley.edu>
>>>>>>      on Tue, 14 Sep 2010 18:26:31 -0700 writes:
>
> HB>  Hi,
> HB>  in R CMD check, the version of the package being checked is reported, e.g.
>
> HB>  Thu Sep  9 05:02:30 2010: Checking package R.utils (SVN revision 399) ...
> HB>  * using log directory ?/srv/R/R.check/R-devel/PKGS/R.utils.Rcheck?
> HB>  * using R version 2.12.0 Under development (unstable) (2010-09-07 r52876)
> HB>  * using platform: x86_64-unknown-linux-gnu (64-bit)
> HB>  * using session charset: UTF-8
> HB>  * checking for file ?R.utils/DESCRIPTION? ... OK
> HB>  * this is package ?R.utils? version ?1.5.2?
> HB>  ...
>
> HB>  I'd like to request/suggest that the 'Date' in the DESCRIPTION file is
> HB>  also added, e.g.
>
> HB>  * this is package ?R.utils? version ?1.5.2? ('2010-09-14')
>
>
> HB>  WHY?
> HB>  This would be particular useful when you work toward sites like
> HB>  R-forge and Bioconductor when you may commit your day's work on
> HB>  package when you update the 'Date' but you do not really want to
> HB>  update the 'Version' because you're going to put in more work
> HB>  tomorrow.  With the 'Date' information you'll be able to see what
> HB>  "version" of your updates have been checked by the servers.  I
> HB>  understand that this may be an odd process to follow even for devel
> HB>  branches and you may argue that you should always bump the version
> HB>  number whenever you do an SVN commit (e.g. '1.5.2.1' for temporary
> HB>  commits).  Either way, I find it useful to see the date as well.
>
>> I agree that this is useful.
>> Of course, for all those cases, where there's no  "Date:",
>> nothing (i.e. no "()") should be written.
>
>> If you (or someone) provide patches against  R-devel
>> ( https://svn.r-project.org/R/trunk/ )
>> and they pass 'make check-all', I'd add this feature.
>
> But pls not against the Date field by default:
>
> R-Forge packages record their revision in their package metadata.
>
> CRAN packages record Date/Publication in their metadata.
>
> Not sure about BioC ...

For BioC packages, I look at the svn revision number displayed
on the build/check report so I know exactly which version of my
package was built/checked:

   http://bioconductor.org/checkResults/2.7/bioc-LATEST/

But I can see Henrik's point to not depend on what a particular
build system does and to have this kind of feature incorporated
in 'R CMD check' itself.

Cheers,
H.

>
> -k
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From karl.forner at gmail.com  Wed Sep 15 19:27:03 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Wed, 15 Sep 2010 19:27:03 +0200
Subject: [Rd] Best way to manage configuration for openMP support
In-Reply-To: <B295D4D3-C4CA-41D9-AC57-9DD0EC391BE6@r-project.org>
References: <AANLkTikdeTG2dEQYfTnh5jDTASnCBiSkis+xKsVUBOpu@mail.gmail.com>
	<19599.24388.430713.722583@max.nulle.part>
	<B295D4D3-C4CA-41D9-AC57-9DD0EC391BE6@r-project.org>
Message-ID: <AANLkTi=JUXHBhYtgQE4m2eko7JtA14QXcRV_rn27Zi-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100915/bc8c9033/attachment.pl>

From cstrato at aon.at  Wed Sep 15 22:39:11 2010
From: cstrato at aon.at (cstrato)
Date: Wed, 15 Sep 2010 22:39:11 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C900C09.2010509@fhcrc.org>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>
	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>
	<4C8FF268.9010500@fhcrc.org> <4C8FF78F.5020407@gmail.com>
	<4C900C09.2010509@fhcrc.org>
Message-ID: <4C912EEF.5050701@aon.at>

Dear Duncan, dear Herve,

Thank you both for your help and suggestions. I think that you are both 
right:

In principle I do not want to put these files in the source tarball (and 
I did not in the past), however because of the way R CMD check works 
this seems to be the only possibility to get rid of the warning message.

I agree that it is weird to get this warning message although these 
files are not in the source tarball.

Since I have a Makefile, as Herve mentions, I can try to remove these 
files in the clean step, which currently is:

clean:
	rm -f $(MYOBJ) *.a *.d *.rc

I will try to change this part but I am not sure if this will solve the 
problem.

Best regards
Christian


On 9/15/10 1:58 AM, Herv? Pag?s wrote:
> On 09/14/2010 03:30 PM, Duncan Murdoch wrote:
>> On 14/09/2010 6:08 PM, Herv? Pag?s wrote:
>>> On 09/14/2010 02:58 PM, cstrato wrote:
>>>> Dear Herve,
>>>>
>>>> Thank you for your reply, however maybe I was not quite clear.
>>>>
>>>> The files xpsDict.h and xpsDict.cxx are automatically created by the
>>>> ROOT framework during compilation on every architecture.
>>>
>>> on every architecture... ok
>>> But if they are created during compilation, why do they need to be
>>> included in the source tarball? They are just temporary files right?
>>> Or I'm missing something...
>>>
>>>> This means they
>>>> are created on Linux and Mac with LF line endings, but on Windows with
>>>> CRLF line endings. However, they are created only if they do not
>>>> already
>>>> exist, and thus are not in the source tarball.
>>>
>>> I guess you mean they are not part of the source *tree*.
>>>
>>>> For testing purposes I have just added both files with LF line endings
>>>> to the source tarball and compiled it on Windows w/o problems.
>>>> Furthermore, the size of "xps_1.9.6.tar.gz" increases only from 4MB to
>>>> 4.3MB. Thus in principle I could upload both files to SVN for BioC 2.7,
>>>> and this should eliminate the warning message. What is your opinion?
>>>
>>> I still don't understand why you want to have them in the source
>>> tarball.
>>
>> I think he doesn't want to put them in the source tarball, but because
>> of the way R CMD check works, he may have to.
>>
>> It appears that R CMD check builds those files, and then checks for CRLF
>> endings on all files. If it did the CRLF check first, it wouldn't see
>> them and complain. The problem with this change is that some packages
>> might create files with CRLF endings on all platforms, and then check
>> *should* complain about them.
>
> I see your point but, on the other hand, and more generally speaking,
> you expect 'R CMD check' to check the source files i.e. the files that
> belong to the source tarball, and not temporary compilation/installation
> products that 'R CMD INSTALL' didn't remove (for whatever reason).
>
> It's weird to get a message like:
>
> * checking line endings in C/C++/Fortran sources/headers ... WARNING
> Found the following sources/headers with CR or CRLF line endings:
> src/xpsDict.h
>
> if there is no such file in the source tarball.
>
>>
>> My advice would be not to put them in the tarball, and ignore the
>> warning. Or write a Makevars.win that fixes the line endings so that
>> check is happy.
>
> Yes and since he already uses a Makefile, it should be easy to remove
> those files at the end of installation so they don't end up in the
> tarball anymore. Wouldn't that also be enough to silent 'R CMD check'?
> Perhaps package authors should really make sure that src/ gets
> cleaned after the installation step of 'R CMD build' (this step is
> performed only if the package has vignettes). Then it shouldn't matter
> whether 'R CMD check' checks for CRLF endings after or before
> installing the package.
>
> Cheers,
> H.
>
>>
>> Duncan Murdoch
>
>


From edd at debian.org  Wed Sep 15 22:51:57 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 15 Sep 2010 15:51:57 -0500
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C912EEF.5050701@aon.at>
References: <4C8E9297.5050806@aon.at>
	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>
	<4C8FBE96.6080604@aon.at>
	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>
	<4C8FE527.6060308@aon.at> <4C8FE9EE.60604@fhcrc.org>
	<4C8FF01B.6060208@aon.at> <4C8FF268.9010500@fhcrc.org>
	<4C8FF78F.5020407@gmail.com> <4C900C09.2010509@fhcrc.org>
	<4C912EEF.5050701@aon.at>
Message-ID: <19601.12781.231933.777847@max.nulle.part>


On 15 September 2010 at 22:39, cstrato wrote:
| Dear Duncan, dear Herve,
| 
| Thank you both for your help and suggestions. I think that you are both 
| right:
| 
| In principle I do not want to put these files in the source tarball (and 
| I did not in the past), however because of the way R CMD check works 
| this seems to be the only possibility to get rid of the warning message.
| 
| I agree that it is weird to get this warning message although these 
| files are not in the source tarball.
| 
| Since I have a Makefile, as Herve mentions, I can try to remove these 

If you have a Makefile, then you have implicit rules as well as explicit
ones.  That is how the file gets created.

Now modify the rules and insert another layer which will do the filtering. As
the saying goes:  "there is no problem that cannot be solved by adding
another layer of indirection".  Instead of requiring the generated file,
require the generated and filtered file.

| files in the clean step, which currently is:
| 
| clean:
| 	rm -f $(MYOBJ) *.a *.d *.rc
| 
| I will try to change this part but I am not sure if this will solve the 
| problem.

I fear that the clean step runs too late.  You want the file filtered at the
compile stage.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From cstrato at aon.at  Wed Sep 15 23:22:57 2010
From: cstrato at aon.at (cstrato)
Date: Wed, 15 Sep 2010 23:22:57 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <19601.12781.231933.777847@max.nulle.part>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>	<4C8FF268.9010500@fhcrc.org>	<4C8FF78F.5020407@gmail.com>	<4C900C09.2010509@fhcrc.org>	<4C912EEF.5050701@aon.at>
	<19601.12781.231933.777847@max.nulle.part>
Message-ID: <4C913931.5050807@aon.at>

Dear Dirk,

Thank you for this suggestion, however since I am not very good in 
creating Makefiles I would appreciate if you could explain how to filter 
at the compile stage.

These are the lines which I think are essential:

xps.dll:  $(MYOBJ)
	$(LINK) /dll /def:xps.def /out:xps.dll fp10.obj $(SOFLAGS) $(LDFLAGS) 
$(GLIBS) *.obj
	
xpsDict.cxx: $(MYHDR) xpsLinkDef.h
	@echo "Generating dictionary $@..."
	@rootcint -f $@ -c $(MYHDR) xpsLinkDef.h
	
xpsDict.obj: xpsDict.cxx xpsDict.h
	$(CL) /I"${ROOTSYS}/include" /FIw32pragma.h /MT /EHsc /Ox /D "MSVC" /D 
"WIN32" /c xpsDict.cxx

clean:
	rm -f $(MYOBJ) *.a *.d *.rc

The line @rootcint creates the xpsLinkDef.h file.

Do I have to add something after the compilation step of xpsDict.obj?

Thank you in advance.
Best regards
Christian


On 9/15/10 10:51 PM, Dirk Eddelbuettel wrote:
>
> On 15 September 2010 at 22:39, cstrato wrote:
> | Dear Duncan, dear Herve,
> |
> | Thank you both for your help and suggestions. I think that you are both
> | right:
> |
> | In principle I do not want to put these files in the source tarball (and
> | I did not in the past), however because of the way R CMD check works
> | this seems to be the only possibility to get rid of the warning message.
> |
> | I agree that it is weird to get this warning message although these
> | files are not in the source tarball.
> |
> | Since I have a Makefile, as Herve mentions, I can try to remove these
>
> If you have a Makefile, then you have implicit rules as well as explicit
> ones.  That is how the file gets created.
>
> Now modify the rules and insert another layer which will do the filtering. As
> the saying goes:  "there is no problem that cannot be solved by adding
> another layer of indirection".  Instead of requiring the generated file,
> require the generated and filtered file.
>
> | files in the clean step, which currently is:
> |
> | clean:
> | 	rm -f $(MYOBJ) *.a *.d *.rc
> |
> | I will try to change this part but I am not sure if this will solve the
> | problem.
>
> I fear that the clean step runs too late.  You want the file filtered at the
> compile stage.
>
> Dirk
>


From hpages at fhcrc.org  Wed Sep 15 23:53:49 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 14:53:49 -0700
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <19601.12781.231933.777847@max.nulle.part>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>	<4C8FF268.9010500@fhcrc.org>	<4C8FF78F.5020407@gmail.com>	<4C900C09.2010509@fhcrc.org>	<4C912EEF.5050701@aon.at>
	<19601.12781.231933.777847@max.nulle.part>
Message-ID: <4C91406D.5000102@fhcrc.org>

On 09/15/2010 01:51 PM, Dirk Eddelbuettel wrote:
>
> On 15 September 2010 at 22:39, cstrato wrote:
> | Dear Duncan, dear Herve,
> |
> | Thank you both for your help and suggestions. I think that you are both
> | right:
> |
> | In principle I do not want to put these files in the source tarball (and
> | I did not in the past), however because of the way R CMD check works
> | this seems to be the only possibility to get rid of the warning message.
> |
> | I agree that it is weird to get this warning message although these
> | files are not in the source tarball.
> |
> | Since I have a Makefile, as Herve mentions, I can try to remove these
>
> If you have a Makefile, then you have implicit rules as well as explicit
> ones.  That is how the file gets created.
>
> Now modify the rules and insert another layer which will do the filtering. As
> the saying goes:  "there is no problem that cannot be solved by adding
> another layer of indirection".  Instead of requiring the generated file,
> require the generated and filtered file.
>
> | files in the clean step, which currently is:
> |
> | clean:
> | 	rm -f $(MYOBJ) *.a *.d *.rc
> |
> | I will try to change this part but I am not sure if this will solve the
> | problem.
>
> I fear that the clean step runs too late.

But shouldn't 'R CMD check' run the clean step (if it runs it at all)
right after the 'R CMD INSTALL' step?

Cheers,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Thu Sep 16 01:16:59 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 16:16:59 -0700
Subject: [Rd] R CMD build cannot create vignettes on Windows if Makefile
 is used
In-Reply-To: <4C8FC376.7060404@gmail.com>
References: <4C8B0B24.8020609@fhcrc.org> <4C8B6044.1030506@gmail.com>
	<4C8C5BCD.4000207@fhcrc.org> <4C8CC297.1050405@gmail.com>
	<4C8DAC81.8080102@fhcrc.org> <4C8DFE23.5040101@gmail.com>
	<4C8E6FC3.1010100@fhcrc.org> <4C8E71DA.1000202@gmail.com>
	<4C8FC2FC.6030200@fhcrc.org> <4C8FC376.7060404@gmail.com>
Message-ID: <4C9153EB.9090807@fhcrc.org>

Oops, sorry for the noise but after looking at today's BioC build/check
results, I realize the problem is still here. At least for some of
the 8 packages that had an 'R CMD build' timeout because of the
Sweave.sty file not being found. I just happened to run 'R CMD build'
by hands yesterday on a package for which the problem is gone so
I went ahead and started to sing victory... not so fast!

I'm gonna post with a new subject and give more details.

H.


On 09/14/2010 11:48 AM, Duncan Murdoch wrote:
> On 14/09/2010 2:46 PM, Herv? Pag?s wrote:
>> Duncan,
>>
>> On 09/13/2010 11:47 AM, Duncan Murdoch wrote:
>> > On 13/09/2010 2:38 PM, Herv? Pag?s wrote:
>> [...]
>> >> Thanks for suggesting workarounds but don't you think there is a real
>> >> problem?
>> >>
>> >
>> > As I said, we don't use TEXINPUTS on Windows, we use the command line
>> > version. I didn't write the code, so I don't know why there's the
>> > difference, but I assume there's a reason for it, and presumably the
>> > reason is that relying on TEXINPUTS doesn't work.
>>
>> This is fixed in current R-devel.
>>
>
> That explains my confusion.
>
> Duncan Murdoch


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Thu Sep 16 01:55:29 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 16:55:29 -0700
Subject: [Rd] running 'make' failed during vignette creation ('R CMD build')
 on Windows
Message-ID: <4C915CF1.9020304@fhcrc.org>

Hi,

This is a follow-up to the problem reported here:

   https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html

After I updated R-2.12 to 2010-09-13 r52905 on the Bioc build system,
some of the packages that have a Makefile in <pkg>/inst/doc still
don't build on Windows. For example, 'R\bin\R.exe CMD build adSplit'
gives:

* checking for file 'adSplit/DESCRIPTION' ... OK
* preparing 'adSplit':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to re-build vignettes
* creating vignettes ... ERROR
Loading required package: Biobase

Welcome to Bioconductor

   Vignettes contain introductory material. To view, type
   'openVignette()'. To cite Bioconductor, see
   'citation("Biobase")' and for packages 'citation(pkgname)'.

Loading required package: DBI
Loading required package: hu6800.db
Loading required package: AnnotationDbi
Loading required package: org.Hs.eg.db
   determining 1000 random DLD-scores with 20 probe sets each (wait for 
10 dots)
   ..........
epstopdf splitSet.eps
pdflatex tr_2005_02
This is pdfTeX, Version 3.1415926-1.40.9 (MiKTeX 2.7)
entering extended mode
(tr_2005_02.tex
LaTeX2e <2009/09/24>
Babel <v3.8l> and hyphenation patterns for english, dumylang, 
nohyphenation, ge
rman, ngerman, french, loaded.
("C:\Program Files\MiKTeX 2.7\tex\latex\base\report.cls"
Document Class: report 2007/10/19 v1.4h Standard LaTeX document class
("C:\Program Files\MiKTeX 2.7\tex\latex\base\size11.clo")) (compdiag.sty
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifpdf.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphicx.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\keyval.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphics.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\trig.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\graphics.cfg")
("C:\Program Files\MiKTeX 2.7\tex\latex\pdftex-def\pdftex.def")))
("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\color.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\color.cfg"))
("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hyperref.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ltxcmds.sty")
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\kvsetkeys.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\infwarerr.sty")
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\etexcmds.sty"))
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdfescape.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdftexcmds.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifluatex.sty")))
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifvtex.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\ifxetex\ifxetex.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\hycolor.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\xcolor-patch.sty"))
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\letltxmacro.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\pd1enc.def")
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\intcalc.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\hyperref.cfg")
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\kvoptions.sty")
Implicit mode ON; LaTeX internals redefined
("C:\Program Files\MiKTeX 2.7\tex\latex\ltxmisc\url.sty")
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bitset.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bigintcalc.sty"))
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\atbegshi.sty"))
* hyperref using driver hpdftex *
("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hpdftex.def"
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\atveryend.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\rerunfilecheck.sty"
("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\uniquecounter.sty")))
("C:\Program Files\MiKTeX 2.7\tex\latex\ntgclass\a4.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.cfg"))
("C:\Program Files\MiKTeX 2.7\tex\latex\tools\theorem.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thp.sty"))
("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thb.sty"))
("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsmath.sty"
For additional information on amsmath, use the `?' option.
("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amstext.sty"
("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsgen.sty"))
("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsbsy.sty")
("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsopn.sty"))

! LaTeX Error: File `Sweave.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name:
! Emergency stop.
<read *>

l.39 \begin
            {document}
!  ==> Fatal error occurred, no output PDF file produced!
Transcript written on tr_2005_02.log.
make: *** [pdf] Error 1
Error in tools::buildVignettes(dir = ".") : running 'make' failed
Execution halted

What's different though with this updated R, it that now I get an
error instead of a timeout. Maybe the code that fires the R subprocess
in charge of running tools::buildVignettes() now does better error
checking/handling, I don't know (it seems to have changed between
the 2 versions of R).

A new mystery is why the tilingArray package now does build on
Windows (it was timing out with the previous version of R).
I already sent the content of adSplit/inst/doc/Makefile
in the previous thread and tilingArray does nothing different:

all: findsegments costMatrix assessNorm segmentation plotAlongChrom clean

findsegments: findsegments.tex
         pdflatex findsegments
         pdflatex findsegments

costMatrix: costMatrix.tex
         pdflatex costMatrix
         pdflatex costMatrix

assessNorm: assessNorm.tex
         cp -p ../scripts/assessNorm.pdf .

segmentation: segmentation.tex
         cp -p ../scripts/segmentation.pdf .

plotAlongChrom: plotAlongChrom.tex
         pdflatex plotAlongChrom
         pdflatex plotAlongChrom
clean:
         rm -f *.out *.bbl *.log *.aux *.blg *.brf *.toc *.tex
         rm -f *.dvi *.ps findsegments-* costMatrix-* plotAlongChrom-* 
Rplots.pdf

Another thing that is really puzzling is that if I cd to
adSplit/inst/doc and run 'R CMD make' then it works.

Any help/comment on this will be highly appreciated.

Thanks,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Thu Sep 16 02:21:53 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 17:21:53 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8FBDB0.4060106@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org>
	<4C8C94A3.3080600@gmail.com>	<4C8CA70C.40109@fhcrc.org>	<4C8F613E.8070407@statistik.tu-dortmund.de>
	<4C8FBDB0.4060106@fhcrc.org>
Message-ID: <4C916321.9050108@fhcrc.org>

On 09/14/2010 11:23 AM, Herv? Pag?s wrote:
> Hi Uwe,
>
> On 09/14/2010 04:49 AM, Uwe Ligges wrote:
...
>> Brian had some ideas that the problems are related to the shell that is
>> used. Is the problem still apparent in a very recent R-devel from few
>> days ago? I am just back from vacations and have not updated yet.
>> I experienced the same problems and I am just iterating automatically if
>> typical problems are apparent from the log files. I hope some if not all
>> parts are solved now and will do some new test runs shortly.
>
> Sounds good. I just upgraded to R-2.12 (2010-09-13 r52905) on our 32-bit
> Windows machine and I'll report here tomorrow after the next build run
> has completed. I can already see that this new R solves the issue I
> reported here:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html

Not true sorry 
(https://stat.ethz.ch/pipermail/r-devel/2010-September/058530.html)

As for the strange R CMD build/check errors on Windows I still see them.
A sample of Today's Victims:

   R\bin\R.exe CMD build AffyCompatible
   * checking for file 'AffyCompatible/DESCRIPTION' ... OK
   * preparing 'AffyCompatible':
   * checking DESCRIPTION meta-information ... OK
   * installing the package to re-build vignettes
   * creating vignettes ... ERROR
   Error: ERROR: no packages specified

   R\bin\R.exe CMD build ArrayTools
   * checking for file 'ArrayTools/DESCRIPTION' ... OK
   * preparing 'ArrayTools':
   * checking DESCRIPTION meta-information ... OK
   * installing the package to re-build vignettes
         -----------------------------------
   Warning: unknown option '-l'
   * checking for file 
'E:\biocbld\bbs-2.7-bioc\tmpdir\Rtmpbtur24\Rinst494950ff/DESCRIPTION' ... NO
         -----------------------------------
   ERROR: Installation failed
   Removing installation dir

   R\bin\R.exe CMD build baySeq
   * checking for file 'baySeq/DESCRIPTION' ... OK
   * preparing 'baySeq':
   * checking DESCRIPTION meta-information ... OK
   * installing the package to re-build vignettes
   * creating vignettes ...Warning in file(con, "r") :
     cannot open file 
'E:\biocbld\bbs-2.7-bioc\tmpdir\RtmpKRrdst\xshell4d4a5c70': Permission 
denied
   Error in file(con, "r") : cannot open the connection
   Execution halted

   R\bin\R.exe CMD build beadarray
   --> produces no output at all and returns code 0.

etc...

Cheers,
H.


>
> Thanks!
> H.
>
>
>>
>> Best,
>> Uwe
>>
>>
>>
>>
>>
>>
>>>>> Thanks,
>>>>> H.
>>>>>
>>>>
>>>> Antivirus software? I suspect you already ruled that out, but it has
>>>> been the culprit for problems with mysteriously disappearing
>>>> intermediate files in several cases, so I thought I'd mention it.
>>>>
>>>
>>> Actually I didn't try that yet because we still build BioC release
>>> (using R-2.11.1) on these 2 Windows boxes and we don't see any of
>>> those problems for the release builds. But I will. Could it be that
>>> the fact that 'R CMD build' and 'R CMD check' are R-based in R-2.12
>>> (and not Perl-based anymore) make them more fragile when something
>>> like an antivirus is messing around with the filesystem?
>>>
>>> Thanks for the suggestion,
>>> H.
>>>
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hb at stat.berkeley.edu  Thu Sep 16 04:14:37 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 15 Sep 2010 19:14:37 -0700
Subject: [Rd] R-forge: Web server down / no space left
Message-ID: <AANLkTindioRYs8Es+X8RA3isOXpuXU8DmdmgG8mk0ewp@mail.gmail.com>

FYI and for the R-forge maintainers information:

Trying to access http://r-forge.r-project.org/ at this very moment gives:

"An error occured in the logger. ERROR: could not extend relation
1663/19060/19983: No space left on device HINT: Check free disk
space."

/Henrik


From D.Strbenac at garvan.org.au  Thu Sep 16 05:00:09 2010
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Thu, 16 Sep 2010 13:00:09 +1000 (EST)
Subject: [Rd] R-forge: Web server down / no space left
In-Reply-To: <AANLkTindioRYs8Es+X8RA3isOXpuXU8DmdmgG8mk0ewp@mail.gmail.com>
References: <AANLkTindioRYs8Es+X8RA3isOXpuXU8DmdmgG8mk0ewp@mail.gmail.com>
Message-ID: <20100916130009.BIV56935@gimr.garvan.unsw.edu.au>

I tried it now and it works. It might have been something momentary.

---- Original message ----
>Date: Wed, 15 Sep 2010 19:14:37 -0700
>From: r-devel-bounces at r-project.org (on behalf of Henrik Bengtsson <hb at stat.berkeley.edu>)
>Subject: [Rd] R-forge: Web server down / no space left  
>To: R-devel <r-devel at r-project.org>
>
>FYI and for the R-forge maintainers information:
>
>Trying to access http://r-forge.r-project.org/ at this very moment gives:
>
>"An error occured in the logger. ERROR: could not extend relation
>1663/19060/19983: No space left on device HINT: Check free disk
>space."
>
>/Henrik
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From hpages at fhcrc.org  Thu Sep 16 06:54:54 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 21:54:54 -0700
Subject: [Rd] Lack of consistent cross-platform behaviour of
	tools:::buildVignettes()
Message-ID: <4C91A31E.4020500@fhcrc.org>

Hi,

On both Unix and Windows there is a mechanism to add variables
to the environment when R is started. I noticed that, on Unix,
this mechanism is not used when R is started normally at the
command line but only when it's started using the 'R CMD' syntax.
One problem with this is some lack of consistent cross-platform
behaviour. For example:

On Linux:

   $ echo $TEXINPUTS

   $ echo "Sys.getenv('TEXINPUTS')" | R --slave
   TEXINPUTS
          ""
But on Windows:

   E:\tmp>echo %TEXINPUTS%
   %TEXINPUTS%
   E:\tmp>echo Sys.getenv("TEXINPUTS") | R\bin\R.exe --slave
                                               TEXINPUTS
   ".;;E:/biocbld/bbs-2.7-bioc/R/share/texmf/tex/latex;"

So on Linux if I cd to the inst/doc folder of a package source tree
that has a Makefile and run

   echo "tools:::buildVignettes('pkgname', '.')" | R --slave

it fails with error:

   ! LaTeX Error: File `Sweave.sty' not found.

while doing the same thing on Windows works.

Is there any reason for not setting the environments variables
that are defined in ${R_HOME}/bin/Rcmd (the shell script wrapper
for all R CMD commands) when R is started normally?

Thanks,
H.

BTW, I found this (on both, Unix and Windows):

   $ echo "Sys.getenv('TEXINPUTS')" | R
   Fatal error: you must specify '--save', '--no-save' or '--vanilla'

What about --slave? Thanks!


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Thu Sep 16 08:33:58 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 15 Sep 2010 23:33:58 -0700
Subject: [Rd] running 'make' failed during vignette creation ('R CMD
 build') on Windows
In-Reply-To: <4C915CF1.9020304@fhcrc.org>
References: <4C915CF1.9020304@fhcrc.org>
Message-ID: <4C91BA56.6040209@fhcrc.org>

I think I found the problem. During the recent transition from
Perl-based to R-based 'R CMD check/build', the rcmdfn() function
in src/gnuwin32/front-ends/rcmdfn.c has been hacked quite a bit.
This function gets called right after the R front-end is started
and its main purpose is to process the user arguments passed to
the front-end and to fire the appropriate subprocess.
This function also calls process_Renviron() for putting the
variables defined in ${R_HOME}/etc/rcmd_environ into the
environment of the front-end process.

Problem: before revision 52153

   this code
             ...
             } else if (strcmp(p, "build") == 0) {
                 snprintf(cmd, CMD_LEN, "perl %s/bin/build.pl", RHome);
             } ...

   was *after* this line

             process_Renviron(env_path);

But starting with rev 52153, it was moved *before* the call to
process_Renviron() (and also modified to handle Rcmd build
internally). The new code looks more complicated:

     ...
     } else if (cmdarg > 0 && argc > cmdarg &&
               strcmp(argv[cmdarg], "build") == 0) {
         /* handle Rcmd build internally */
         snprintf(cmd, CMD_LEN,
                  "%s/%s/Rterm.exe -e tools:::.build_packages() 
R_DEFAULT_PACKAGES= LC_COLLATE=C --no-restore --slave --args ",
                  getRHOME(3), BINDIR);
         for (i = cmdarg + 1; i < argc; i++) {
             strcat(cmd, "nextArg");
             if (strlen(cmd) + strlen(argv[i]) > 9900) {
                 fprintf(stderr, "command line too long\n");
                 return(27);
             }
             strcat(cmd, argv[i]);
         }
         status = system(cmd);
         return(status);
     } else {
     ...

but basically, it still fires a subprocess and then the function
returns. process_Renviron() was not called so the subprocess
doesn't see those environment variables anymore.

Then the same happened to 'R CMD build' (rev 52245), and to many
other 'R CMD things': their corresponding code chunks in rcmdfn()
went moved up one by one to end up before the call to
process_Renviron(). So none of the 'R CMD' subcommands sees
the environment variables that they used to see anymore. Only
a normal 'R' command still gets them.

Cheers,
H.


On 09/15/2010 04:55 PM, Herv? Pag?s wrote:
> Hi,
>
> This is a follow-up to the problem reported here:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html
>
> After I updated R-2.12 to 2010-09-13 r52905 on the Bioc build system,
> some of the packages that have a Makefile in <pkg>/inst/doc still
> don't build on Windows. For example, 'R\bin\R.exe CMD build adSplit'
> gives:
>
> * checking for file 'adSplit/DESCRIPTION' ... OK
> * preparing 'adSplit':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * installing the package to re-build vignettes
> * creating vignettes ... ERROR
> Loading required package: Biobase
>
> Welcome to Bioconductor
>
> Vignettes contain introductory material. To view, type
> 'openVignette()'. To cite Bioconductor, see
> 'citation("Biobase")' and for packages 'citation(pkgname)'.
>
> Loading required package: DBI
> Loading required package: hu6800.db
> Loading required package: AnnotationDbi
> Loading required package: org.Hs.eg.db
> determining 1000 random DLD-scores with 20 probe sets each (wait for 10
> dots)
> ..........
> epstopdf splitSet.eps
> pdflatex tr_2005_02
> This is pdfTeX, Version 3.1415926-1.40.9 (MiKTeX 2.7)
> entering extended mode
> (tr_2005_02.tex
> LaTeX2e <2009/09/24>
> Babel <v3.8l> and hyphenation patterns for english, dumylang,
> nohyphenation, ge
> rman, ngerman, french, loaded.
> ("C:\Program Files\MiKTeX 2.7\tex\latex\base\report.cls"
> Document Class: report 2007/10/19 v1.4h Standard LaTeX document class
> ("C:\Program Files\MiKTeX 2.7\tex\latex\base\size11.clo")) (compdiag.sty
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifpdf.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphicx.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\keyval.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphics.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\trig.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\graphics.cfg")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\pdftex-def\pdftex.def")))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\color.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\color.cfg"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hyperref.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ltxcmds.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\kvsetkeys.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\infwarerr.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\etexcmds.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdfescape.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdftexcmds.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifluatex.sty")))
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifvtex.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ifxetex\ifxetex.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\hycolor.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\xcolor-patch.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\letltxmacro.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\pd1enc.def")
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\intcalc.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\hyperref.cfg")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\kvoptions.sty")
> Implicit mode ON; LaTeX internals redefined
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ltxmisc\url.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bitset.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bigintcalc.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\atbegshi.sty"))
> * hyperref using driver hpdftex *
> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hpdftex.def"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\atveryend.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\rerunfilecheck.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\uniquecounter.sty")))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ntgclass\a4.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.cfg"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\theorem.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thp.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thb.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsmath.sty"
> For additional information on amsmath, use the `?' option.
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amstext.sty"
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsgen.sty"))
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsbsy.sty")
> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsopn.sty"))
>
> ! LaTeX Error: File `Sweave.sty' not found.
>
> Type X to quit or <RETURN> to proceed,
> or enter new name. (Default extension: sty)
>
> Enter file name:
> ! Emergency stop.
> <read *>
>
> l.39 \begin
> {document}
> ! ==> Fatal error occurred, no output PDF file produced!
> Transcript written on tr_2005_02.log.
> make: *** [pdf] Error 1
> Error in tools::buildVignettes(dir = ".") : running 'make' failed
> Execution halted
>
> What's different though with this updated R, it that now I get an
> error instead of a timeout. Maybe the code that fires the R subprocess
> in charge of running tools::buildVignettes() now does better error
> checking/handling, I don't know (it seems to have changed between
> the 2 versions of R).
>
> A new mystery is why the tilingArray package now does build on
> Windows (it was timing out with the previous version of R).
> I already sent the content of adSplit/inst/doc/Makefile
> in the previous thread and tilingArray does nothing different:
>
> all: findsegments costMatrix assessNorm segmentation plotAlongChrom clean
>
> findsegments: findsegments.tex
> pdflatex findsegments
> pdflatex findsegments
>
> costMatrix: costMatrix.tex
> pdflatex costMatrix
> pdflatex costMatrix
>
> assessNorm: assessNorm.tex
> cp -p ../scripts/assessNorm.pdf .
>
> segmentation: segmentation.tex
> cp -p ../scripts/segmentation.pdf .
>
> plotAlongChrom: plotAlongChrom.tex
> pdflatex plotAlongChrom
> pdflatex plotAlongChrom
> clean:
> rm -f *.out *.bbl *.log *.aux *.blg *.brf *.toc *.tex
> rm -f *.dvi *.ps findsegments-* costMatrix-* plotAlongChrom-* Rplots.pdf
>
> Another thing that is really puzzling is that if I cd to
> adSplit/inst/doc and run 'R CMD make' then it works.
>
> Any help/comment on this will be highly appreciated.
>
> Thanks,
> H.
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kmmatoba at stanford.edu  Thu Sep 16 10:14:30 2010
From: kmmatoba at stanford.edu (Kyle Matoba)
Date: Thu, 16 Sep 2010 01:14:30 -0700
Subject: [Rd] improvements to plm fitting
Message-ID: <AANLkTin3jawnxqDqrp+6waiSMfVeuxOENU2X3Vdf40+F@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100916/dcc43b02/attachment.pl>

From Thomas.Petzoldt at tu-dresden.de  Thu Sep 16 11:16:47 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Thu, 16 Sep 2010 11:16:47 +0200
Subject: [Rd] package test failed on Solaris x86 -- help needed for debugging
Message-ID: <4C91E07F.5010403@tu-dresden.de>

Dear R developers,

we have currently a 'mysterious' test problem with one package that 
successfully passed the tests on all platforms, with the only exception 
of Solaris x86 where obviously one of our help examples breaks the CRAN 
test.

As we don't own such a machine I want to ask about a possibility to run 
a few tests on such a system:

r-patched-solaris-x86

An even more recent version of R on the same OS (Solaris 10) and with 
the same compiler (Sun Studio 12u1) would help also.

Any assistance is appreciated


Thomas Petzoldt


-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From lukasz.reclawowicz at gmail.com  Thu Sep 16 13:27:35 2010
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Thu, 16 Sep 2010 13:27:35 +0200
Subject: [Rd] [2.11.1] Cross build for Win: psignal.h No such file or
	directory
Message-ID: <AANLkTi=fM5K00PTbVFPvdY_DSNFVmJhmwcKBwvR+C0Uq@mail.gmail.com>

Hi,

I'm trying to build R with Radford Neal's patches. I did successful
before on Win, but with 2.11.1 version i got some problems. So my next
try was cross build on Linux. (without patches, yet)
I use: ./configure --build i686-pc-linux-gnu --host i686-pc-mingw32 --with-x=no
And get:
configure: WARNING: you cannot build info or HTML versions of the R manuals
		    using cross tools not prefixed with host triplet

In file included from dynload.c:33
../../src/inculde/Defn.h:142:22: error psignal.h: No such file or directory

I know that the file is in /gnuwin32/fixed/h, so something i did
wrong. But no idea what.
-- 
Mi?ego dnia


From vqnguyen at uci.edu  Thu Sep 16 16:06:40 2010
From: vqnguyen at uci.edu (Vinh Nguyen)
Date: Thu, 16 Sep 2010 07:06:40 -0700
Subject: [Rd] advice on writing/maintaining an R package with a version
	control system
Message-ID: <AANLkTimAUEkz8-GXaH5NrOnsDj8RLLHESpror3prhmVx@mail.gmail.com>

Dear all,

As I resume my dissertation work next month, I'd like to actually
start an R package this time around.  I haven't done so because I
update my code very often (still in development phase), so running the
skeleton function, running checks, building, and re-installing the
package onto the system seemed like a long and tedious process.

I would like to hear your experience on how you start an R package
with a version control system.  Currently, I have most of my functions
in an R source file.  I expect to use a skeleton function to generate
the package directory (most likely Rcpp's), and start git as my
version control system (although the advice I'm seeking isn't
git-specific).  Once the version control system is set up, a few
questions:

1.  Do you update your code directly into the multiple R files in
./src, or do you update the main R source file?  I'm assuming the
former since we're using version control.
2.  What is your process for updating and testing your code?  Do you
run checks, build, and re-install the package to test?  Or do you have
some fancy workflow?  Please share.

Thanks for your advice.

Vinh
--
Vinh Nguyen
Department of Statistics
Donald Bren School of ICS
2231 Bren Hall
University of California, Irvine
Irvine, CA 92607
vqnguyen at uci.edu | http://www.ics.uci.edu/~vqnguyen/
Schedule a meeting: http://tungle.me/VinhNguyen


From plummer at iarc.fr  Thu Sep 16 17:05:30 2010
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 16 Sep 2010 17:05:30 +0200
Subject: [Rd] package test failed on Solaris x86 -- help needed for
 debugging
In-Reply-To: <4C91E07F.5010403@tu-dresden.de>
References: <4C91E07F.5010403@tu-dresden.de>
Message-ID: <1284649530.3299.395.camel@braque.iarc.fr>

Dear Thomas,

Is this the deSolve package?

http://www.r-project.org/nosvn/R.check/r-patched-solaris-x86/deSolve-00check.html

I can help you with that. It does pass R CMD check on my OpenSolaris
installation, but I am getting some compiler warnings. I will send you
details.

Martyn

On Thu, 2010-09-16 at 11:16 +0200, Thomas Petzoldt wrote:
> Dear R developers,
> 
> we have currently a 'mysterious' test problem with one package that 
> successfully passed the tests on all platforms, with the only exception 
> of Solaris x86 where obviously one of our help examples breaks the CRAN 
> test.
> 
> As we don't own such a machine I want to ask about a possibility to run 
> a few tests on such a system:
> 
> r-patched-solaris-x86
> 
> An even more recent version of R on the same OS (Solaris 10) and with 
> the same compiler (Sun Studio 12u1) would help also.
> 
> Any assistance is appreciated
> 
> 
> Thomas Petzoldt
> 
> 


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From simon.urbanek at r-project.org  Thu Sep 16 17:15:45 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 16 Sep 2010 11:15:45 -0400
Subject: [Rd] advice on writing/maintaining an R package with a version
	control system
In-Reply-To: <AANLkTimAUEkz8-GXaH5NrOnsDj8RLLHESpror3prhmVx@mail.gmail.com>
References: <AANLkTimAUEkz8-GXaH5NrOnsDj8RLLHESpror3prhmVx@mail.gmail.com>
Message-ID: <76E3C663-7DB3-44DC-AAFF-6388AD29EC32@r-project.org>

On Sep 16, 2010, at 10:06 AM, Vinh Nguyen wrote:

> Dear all,
> 
> As I resume my dissertation work next month, I'd like to actually
> start an R package this time around.  I haven't done so because I
> update my code very often (still in development phase), so running the
> skeleton function, running checks, building, and re-installing the
> package onto the system seemed like a long and tedious process.
> 

I guess it depends on the package, but in general I find it's so fast that it's not worth bothering with the alternatives. It's just one line to build, install a package and run the desired test code. The time to do that is usually in single-digit seconds which I'm happy with.


> I would like to hear your experience on how you start an R package
> with a version control system.  Currently, I have most of my functions
> in an R source file.  I expect to use a skeleton function to generate
> the package directory (most likely Rcpp's), and start git as my
> version control system (although the advice I'm seeking isn't
> git-specific).  Once the version control system is set up, a few
> questions:
> 
> 1.  Do you update your code directly into the multiple R files in
> ./src, or do you update the main R source file?

I suspect you mean ./R not ./src if it's an R source file. Personally, I group functions by topic into files, some others put one function per file - it's all about personal preferences because the installed package won't have any of the files you're using so technically it doesn't matter.


>  I'm assuming the
> former since we're using version control.
> 2.  What is your process for updating and testing your code?  Do you
> run checks, build, and re-install the package to test?  Or do you have
> some fancy workflow?  Please share.
> 

I just run
R CMD build xxx && R CMD INSTALL xxx && R
sometimes also including the test code in the last R call so running it requires pressing only two keys. Once I'm happy that the stuff seems to work I run the checks and then commit. (If I'm confident I commit right away since I use SVN and my RForge does run checks on commit so I don't have to bother doing that - it also checks on a different system which is good in case you forgot to add files to the VCS).

If you have large or complex packages, it may be useful to just change a function at a time in the interactive session -- but that's trivial as you simply send the assignment from your editor. (Some tricks may be needed if namespaces are involved but they are usually simple ways around).

Just my very personal $0.02.

Cheers,
Simon




> Thanks for your advice.
> 
> Vinh
> --
> Vinh Nguyen
> Department of Statistics
> Donald Bren School of ICS
> 2231 Bren Hall
> University of California, Irvine
> Irvine, CA 92607
> vqnguyen at uci.edu | http://www.ics.uci.edu/~vqnguyen/
> Schedule a meeting: http://tungle.me/VinhNguyen
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From Thomas.Petzoldt at tu-dresden.de  Thu Sep 16 17:54:25 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Thu, 16 Sep 2010 17:54:25 +0200
Subject: [Rd] package test failed on Solaris x86 -- help needed for
	debugging
In-Reply-To: <1284649530.3299.395.camel@braque.iarc.fr>
References: <4C91E07F.5010403@tu-dresden.de>
	<1284649530.3299.395.camel@braque.iarc.fr>
Message-ID: <4C923DB1.9030700@tu-dresden.de>

On 16.09.2010 17:05, Martyn Plummer wrote:
> Dear Thomas,
>
> Is this the deSolve package?
>
> http://www.r-project.org/nosvn/R.check/r-patched-solaris-x86/deSolve-00check.html
>
> I can help you with that. It does pass R CMD check on my OpenSolaris
> installation, but I am getting some compiler warnings. I will send you
> details.
>
> Martyn

You are right and there are many reasons what can be wrong, i.e. an 
obsolete comma in the example, the call to colorRampPalette after the 
ode.2D call or any problem with the C code. I wonder why this problem is 
so specific because it runs on all other eleven platforms including 
Solaris / Sparc.

Details about the compiler warnings are welcome.

Thomas


From karl.forner at gmail.com  Thu Sep 16 18:11:18 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Thu, 16 Sep 2010 18:11:18 +0200
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
Message-ID: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100916/57401313/attachment.pl>

From armstrong.whit at gmail.com  Thu Sep 16 20:05:35 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 16 Sep 2010 14:05:35 -0400
Subject: [Rd] advice on writing/maintaining an R package with a version
 control system
In-Reply-To: <76E3C663-7DB3-44DC-AAFF-6388AD29EC32@r-project.org>
References: <AANLkTimAUEkz8-GXaH5NrOnsDj8RLLHESpror3prhmVx@mail.gmail.com>
	<76E3C663-7DB3-44DC-AAFF-6388AD29EC32@r-project.org>
Message-ID: <AANLkTikB65f9x0MR7kJ_ZsGD_ggZg2coZaqpq5xpH-bS@mail.gmail.com>

Since you are using git you may want to consider a submodule for your project.

It is often helpful to build a full library in c++ complete with it's
own unit tests.

You can then package this library inside of your R project as a submodule.

This can speed up the testing phase of the project b/c you don't have
to recompile and install the package every time you need to patch/test
your code.

For examples, see fts: http://github.com/armstrtw/fts.

-Whit


On Thu, Sep 16, 2010 at 11:15 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Sep 16, 2010, at 10:06 AM, Vinh Nguyen wrote:
>
>> Dear all,
>>
>> As I resume my dissertation work next month, I'd like to actually
>> start an R package this time around. ?I haven't done so because I
>> update my code very often (still in development phase), so running the
>> skeleton function, running checks, building, and re-installing the
>> package onto the system seemed like a long and tedious process.
>>
>
> I guess it depends on the package, but in general I find it's so fast that it's not worth bothering with the alternatives. It's just one line to build, install a package and run the desired test code. The time to do that is usually in single-digit seconds which I'm happy with.
>
>
>> I would like to hear your experience on how you start an R package
>> with a version control system. ?Currently, I have most of my functions
>> in an R source file. ?I expect to use a skeleton function to generate
>> the package directory (most likely Rcpp's), and start git as my
>> version control system (although the advice I'm seeking isn't
>> git-specific). ?Once the version control system is set up, a few
>> questions:
>>
>> 1. ?Do you update your code directly into the multiple R files in
>> ./src, or do you update the main R source file?
>
> I suspect you mean ./R not ./src if it's an R source file. Personally, I group functions by topic into files, some others put one function per file - it's all about personal preferences because the installed package won't have any of the files you're using so technically it doesn't matter.
>
>
>> ?I'm assuming the
>> former since we're using version control.
>> 2. ?What is your process for updating and testing your code? ?Do you
>> run checks, build, and re-install the package to test? ?Or do you have
>> some fancy workflow? ?Please share.
>>
>
> I just run
> R CMD build xxx && R CMD INSTALL xxx && R
> sometimes also including the test code in the last R call so running it requires pressing only two keys. Once I'm happy that the stuff seems to work I run the checks and then commit. (If I'm confident I commit right away since I use SVN and my RForge does run checks on commit so I don't have to bother doing that - it also checks on a different system which is good in case you forgot to add files to the VCS).
>
> If you have large or complex packages, it may be useful to just change a function at a time in the interactive session -- but that's trivial as you simply send the assignment from your editor. (Some tricks may be needed if namespaces are involved but they are usually simple ways around).
>
> Just my very personal $0.02.
>
> Cheers,
> Simon
>
>
>
>
>> Thanks for your advice.
>>
>> Vinh
>> --
>> Vinh Nguyen
>> Department of Statistics
>> Donald Bren School of ICS
>> 2231 Bren Hall
>> University of California, Irvine
>> Irvine, CA 92607
>> vqnguyen at uci.edu | http://www.ics.uci.edu/~vqnguyen/
>> Schedule a meeting: http://tungle.me/VinhNguyen
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From janko.thyson at ku-eichstaett.de  Thu Sep 16 20:18:53 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Thu, 16 Sep 2010 20:18:53 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
Message-ID: <005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>

> From: Uwe Ligges <ligges_at_statistik.tu-dortmund.de>
> Date: Wed, 15 Sep 2010 15:23:01 +0200
> On 29.08.2010 22:34, Kyle Matoba wrote:
> > All,
> >
> > I just finished the process of build a package for the first time and
> found
> > it characteristically (for R) very straightforward and well
> documented.
> >
> > Whenever I deal with open source software I always endeavor to finish
> the
> > task I have in mind, and upon completing this, I then revisit all of
> the
> > configurations, customizing as necessary to achieve my goals more
> fully.
> > The ability to achieve some minimal level of functionality without
> the
> need
> > for much filling in of configuration files, etc., is, I feel,
> important to
> 
> > not scaring off the less technically inclined such as myself.
> >
> > Based on this heuristic, it is my understanding that a few small
> suggestions
> > could make building a warning-free package as easy as running
> > package.skeleton(), then R CMD check, R CMD build:
> >
> > - Fill in default titles for each of the '*.Rd' files in /man
> > - Take out the tildes in the 'examples' section of the '*-package.Rd'
> main
> 
> > documentation file for the package (it seems to confuse the latex
> compiler)
> > - Put the lines '~~ Optionally other standard keywords, one per line,
> from
> 
> > file KEYWORDS in ~~
> > ~~ the R documentation directory ~~' into the \references{} section,
> there
> 
> > is presently a warning about all text needing to be in a section.
> Dear Kyle,
> thanks for the suggestions. Actually, it is intended to generate
> warnings /
> Errors in R CMD check: We want to force package developers to document
> their
> packages probably. This way, package maintainers / developers have to
> touch
> each Rd file and cannot use them as is in order to pass the checks.
> Best wishes,
> uwe

Dear Uwe, 
in principle, I totally agree with your point of politely forcing developers
to write well documented packages. However, when you're trying to put
together a package, you (or at least I) never get it completely right on the
first, say, 20 tries ;-) Yet, by running package.skelleton() over and over
to keep track of changes you made during the process, you overwrite all Rd
files each time - including the ones that you might already have put a lot
of effort into. And delaying documentation to the very end of the process is
probably not the best idea either ;-) IMHO the community should favor the
approaches taken by packages such as roxygen or inlinedocs as at least it
provides some sort of direct synchronization between code and documentation.
Maybe one could agree on rejecting code that is missing roxygen or inlinedoc
code, which would ensure that code is documented properly. In fact, isn't
programming all about automating unnecessary manual procedures? I would
count starting from scratch with all help files time and time again to be
one of those unnecessary procedures. This time could better be invested in
increasing the package's functionality.

Best regards, my thanks go out to everyone as well,
Janko

> > Thanks, as always, to everyone for their hard work to keep my
> statistical
> > computing free and easy.
> >
> > Best,
> >
> > Kyle
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel_at_r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Thu Sep 16 20:43:11 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 16 Sep 2010 20:43:11 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
Message-ID: <4C92653F.6090003@statistik.tu-dortmund.de>



On 16.09.2010 20:18, Janko Thyson wrote:
>> From: Uwe Ligges<ligges_at_statistik.tu-dortmund.de>
>> Date: Wed, 15 Sep 2010 15:23:01 +0200
>> On 29.08.2010 22:34, Kyle Matoba wrote:
>>> All,
>>>
>>> I just finished the process of build a package for the first time and
>> found
>>> it characteristically (for R) very straightforward and well
>> documented.
>>>
>>> Whenever I deal with open source software I always endeavor to finish
>> the
>>> task I have in mind, and upon completing this, I then revisit all of
>> the
>>> configurations, customizing as necessary to achieve my goals more
>> fully.
>>> The ability to achieve some minimal level of functionality without
>> the
>> need
>>> for much filling in of configuration files, etc., is, I feel,
>> important to
>>
>>> not scaring off the less technically inclined such as myself.
>>>
>>> Based on this heuristic, it is my understanding that a few small
>> suggestions
>>> could make building a warning-free package as easy as running
>>> package.skeleton(), then R CMD check, R CMD build:
>>>
>>> - Fill in default titles for each of the '*.Rd' files in /man
>>> - Take out the tildes in the 'examples' section of the '*-package.Rd'
>> main
>>
>>> documentation file for the package (it seems to confuse the latex
>> compiler)
>>> - Put the lines '~~ Optionally other standard keywords, one per line,
>> from
>>
>>> file KEYWORDS in ~~
>>> ~~ the R documentation directory ~~' into the \references{} section,
>> there
>>
>>> is presently a warning about all text needing to be in a section.
>> Dear Kyle,
>> thanks for the suggestions. Actually, it is intended to generate
>> warnings /
>> Errors in R CMD check: We want to force package developers to document
>> their
>> packages probably. This way, package maintainers / developers have to
>> touch
>> each Rd file and cannot use them as is in order to pass the checks.
>> Best wishes,
>> uwe
>
> Dear Uwe,
> in principle, I totally agree with your point of politely forcing developers
> to write well documented packages. However, when you're trying to put
> together a package, you (or at least I) never get it completely right on the
> first, say, 20 tries ;-) Yet, by running package.skelleton() over and over
> to keep track of changes you made during the process, you overwrite all Rd
> files each time - including the ones that you might already have put a lot
> of effort into. And delaying documentation to the very end of the process is
> probably not the best idea either ;-) IMHO the community should favor the
> approaches taken by packages such as roxygen or inlinedocs as at least it
> provides some sort of direct synchronization between code and documentation.
> Maybe one could agree on rejecting code that is missing roxygen or inlinedoc
> code, which would ensure that code is documented properly. In fact, isn't
> programming all about automating unnecessary manual procedures? I would
> count starting from scratch with all help files time and time again to be
> one of those unnecessary procedures. This time could better be invested in
> increasing the package's functionality.

- I don't think package.skeleton overwrites files unless you ask for it.

- I think once you got started with your package, it is not required to 
call package skeleton again. I tend to add files manually since I am 
working on the package hierarchy itself using some editor...

- Last time I used package.skeleton is probably more than 2 years ago 
(except for presentations in courses about package creation).

Best,
Uwe





>
> Best regards, my thanks go out to everyone as well,
> Janko
>
>>> Thanks, as always, to everyone for their hard work to keep my
>> statistical
>>> computing free and easy.
>>>
>>> Best,
>>>
>>> Kyle
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel_at_r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Sep 16 20:45:15 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Sep 2010 11:45:15 -0700
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700036E8DAB@NA-PA-VBE03.na.tibco.com>

> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Janko Thyson
> Sent: Thursday, September 16, 2010 11:19 AM
> To: r-devel at r-project. org
> Subject: Re: [Rd] a small suggestion for improving the 
> building of packages
...
> Dear Uwe, 
> in principle, I totally agree with your point of politely 
> forcing developers
> to write well documented packages. However, when you're trying to put
> together a package, you (or at least I) never get it 
> completely right on the
> first, say, 20 tries ;-) Yet, by running package.skelleton() 
> over and over
> to keep track of changes you made during the process, you 
> overwrite all Rd
> files each time - including the ones that you might already 
> have put a lot
> of effort into. 

Running package.skeleton more than once is destructive.
Perhaps it needs an update=TRUE/FALSE sort of option
to let you add functions and Rd templates.

When I start a package I don't use package.skeleton,
mainly because it won't make all the usual directories
that I expect to eventually use: src, data, inst, test
(or it is tests?), etc.  I'd rather that it made all
the usual directories (with the proper spelling) so
I could delete them if they ended up being empty.
Do other package writers use package.skeleton routinely?

I copy a template package directory, edit the template
DESCRIPTION file, copy my code into the appropriate
subdirectories, and run prompt(func, filename="pkg/man/func.Rd")
on each function or dataset.   The last step is a pain:
it would be nice if prompt had a dir= or destdir= argument
so that
   prompt(func, destdir="pkg/man")
would make the file "pkg/man/func.Rd".

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> And delaying documentation to the very end of 
> the process is
> probably not the best idea either ;-) IMHO the community 
> should favor the
> approaches taken by packages such as roxygen or inlinedocs as 
> at least it
> provides some sort of direct synchronization between code and 
> documentation.
> Maybe one could agree on rejecting code that is missing 
> roxygen or inlinedoc
> code, which would ensure that code is documented properly. In 
> fact, isn't
> programming all about automating unnecessary manual 
> procedures? I would
> count starting from scratch with all help files time and time 
> again to be
> one of those unnecessary procedures. This time could better 
> be invested in
> increasing the package's functionality.
> 
> Best regards, my thanks go out to everyone as well,
> Janko
> 
> > > Thanks, as always, to everyone for their hard work to keep my
> > statistical
> > > computing free and easy.
> > >
> > > Best,
> > >
> > > Kyle
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel_at_r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Thu Sep 16 20:55:18 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Sep 2010 14:55:18 -0400
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <4C92653F.6090003@statistik.tu-dortmund.de>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
	<4C92653F.6090003@statistik.tu-dortmund.de>
Message-ID: <4C926816.7060206@gmail.com>

  On 16/09/2010 2:43 PM, Uwe Ligges wrote:
>
> On 16.09.2010 20:18, Janko Thyson wrote:
> >>  From: Uwe Ligges<ligges_at_statistik.tu-dortmund.de>
> >>  Date: Wed, 15 Sep 2010 15:23:01 +0200
> >>  On 29.08.2010 22:34, Kyle Matoba wrote:
> >>>  All,
> >>>
> >>>  I just finished the process of build a package for the first time and
> >>  found
> >>>  it characteristically (for R) very straightforward and well
> >>  documented.
> >>>
> >>>  Whenever I deal with open source software I always endeavor to finish
> >>  the
> >>>  task I have in mind, and upon completing this, I then revisit all of
> >>  the
> >>>  configurations, customizing as necessary to achieve my goals more
> >>  fully.
> >>>  The ability to achieve some minimal level of functionality without
> >>  the
> >>  need
> >>>  for much filling in of configuration files, etc., is, I feel,
> >>  important to
> >>
> >>>  not scaring off the less technically inclined such as myself.
> >>>
> >>>  Based on this heuristic, it is my understanding that a few small
> >>  suggestions
> >>>  could make building a warning-free package as easy as running
> >>>  package.skeleton(), then R CMD check, R CMD build:
> >>>
> >>>  - Fill in default titles for each of the '*.Rd' files in /man
> >>>  - Take out the tildes in the 'examples' section of the '*-package.Rd'
> >>  main
> >>
> >>>  documentation file for the package (it seems to confuse the latex
> >>  compiler)
> >>>  - Put the lines '~~ Optionally other standard keywords, one per line,
> >>  from
> >>
> >>>  file KEYWORDS in ~~
> >>>  ~~ the R documentation directory ~~' into the \references{} section,
> >>  there
> >>
> >>>  is presently a warning about all text needing to be in a section.
> >>  Dear Kyle,
> >>  thanks for the suggestions. Actually, it is intended to generate
> >>  warnings /
> >>  Errors in R CMD check: We want to force package developers to document
> >>  their
> >>  packages probably. This way, package maintainers / developers have to
> >>  touch
> >>  each Rd file and cannot use them as is in order to pass the checks.
> >>  Best wishes,
> >>  uwe
> >
> >  Dear Uwe,
> >  in principle, I totally agree with your point of politely forcing developers
> >  to write well documented packages. However, when you're trying to put
> >  together a package, you (or at least I) never get it completely right on the
> >  first, say, 20 tries ;-) Yet, by running package.skelleton() over and over
> >  to keep track of changes you made during the process, you overwrite all Rd
> >  files each time - including the ones that you might already have put a lot
> >  of effort into. And delaying documentation to the very end of the process is
> >  probably not the best idea either ;-) IMHO the community should favor the
> >  approaches taken by packages such as roxygen or inlinedocs as at least it
> >  provides some sort of direct synchronization between code and documentation.
> >  Maybe one could agree on rejecting code that is missing roxygen or inlinedoc
> >  code, which would ensure that code is documented properly. In fact, isn't
> >  programming all about automating unnecessary manual procedures? I would
> >  count starting from scratch with all help files time and time again to be
> >  one of those unnecessary procedures. This time could better be invested in
> >  increasing the package's functionality.
>
> - I don't think package.skeleton overwrites files unless you ask for it.
>
> - I think once you got started with your package, it is not required to
> call package skeleton again. I tend to add files manually since I am
> working on the package hierarchy itself using some editor...

Hi Uwe.  This message is mostly for Janko and others.

You can add them manually, but I would usually use prompt(), a generic 
function that produces just one .Rd file.

It's really one of the prompt methods that package.skeleton is calling 
to produce the bad man pages.  My own feeling is that package.skeleton 
should produce a package that is installable, but it shouldn't pass "R 
CMD check" unless there's some manual intervention to fill in the details.
I think that is the current state of affairs, but if we're producing 
something that causes "R CMD build" or "R CMD INSTALL" to fail, please 
let us know.

By the way, I don't think the title can be filled in automatically 
unless a user has roxygen style documentation, so we don't.  But doesn't 
the roxygen package do that?

Duncan Murdoch

> - Last time I used package.skeleton is probably more than 2 years ago
> (except for presentations in courses about package creation).
>
> Best,
> Uwe
>
>
>


From janko.thyson at ku-eichstaett.de  Thu Sep 16 21:04:45 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Thu, 16 Sep 2010 21:04:45 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700036E8DAB@NA-PA-VBE03.na.tibco.com>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
	<77EB52C6DD32BA4D87471DCD70C8D700036E8DAB@NA-PA-VBE03.na.tibco.com>
Message-ID: <005c01cb55d2$06f0ab40$14d201c0$@thyson@ku-eichstaett.de>



> -----Urspr?ngliche Nachricht-----
> Von: William Dunlap [mailto:wdunlap at tibco.com]
> Gesendet: Donnerstag, 16. September 2010 20:45
> An: Janko Thyson; r-devel at r-project. org
> Betreff: RE: [Rd] a small suggestion for improving the building of
> packages
> 
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Janko Thyson
> > Sent: Thursday, September 16, 2010 11:19 AM
> > To: r-devel at r-project. org
> > Subject: Re: [Rd] a small suggestion for improving the
> > building of packages
> ...
> > Dear Uwe,
> > in principle, I totally agree with your point of politely
> > forcing developers
> > to write well documented packages. However, when you're trying to put
> > together a package, you (or at least I) never get it
> > completely right on the
> > first, say, 20 tries ;-) Yet, by running package.skelleton()
> > over and over
> > to keep track of changes you made during the process, you
> > overwrite all Rd
> > files each time - including the ones that you might already
> > have put a lot
> > of effort into.
> 
> Running package.skeleton more than once is destructive.
> Perhaps it needs an update=TRUE/FALSE sort of option
> to let you add functions and Rd templates.

Uwe just pointed out that there is the argument 'force' that does that but
since it said 'If FALSE will not overwrite an existing directory' I somehow
didn't consider it to handle the update=TRUE/FALSE case. My bad.

> 
> When I start a package I don't use package.skeleton,
> mainly because it won't make all the usual directories
> that I expect to eventually use: src, data, inst, test
> (or it is tests?), etc.  I'd rather that it made all
> the usual directories (with the proper spelling) so
> I could delete them if they ended up being empty.
> Do other package writers use package.skeleton routinely?

I agree. It would be nice if package.skeleton() would create a
'full-feature' skeleton removing empty directories during R CMD check.

> 
> I copy a template package directory, edit the template
> DESCRIPTION file, copy my code into the appropriate
> subdirectories, and run prompt(func, filename="pkg/man/func.Rd")
> on each function or dataset.   The last step is a pain:
> it would be nice if prompt had a dir= or destdir= argument
> so that
>    prompt(func, destdir="pkg/man")
> would make the file "pkg/man/func.Rd".
> 

Oh, never really considered 'prompt()' before. Thanks for the suggestion!
All the manuals always mention 'package.skeleton()'
But couldn't you realize your destdir feature by just building a wrapper
around 'prompt()' or using it in a sapply/lapply construct?
The last couple of days I played around with Roxygen and together with a
couple of utility-functions I managed to completely automate the whole
process from creating a full-feature skeleton, processing the Rds with
roxygenize() and running the full R CMD suite on the package. That way you
document your code right within the actual script which I think is great.

Best regards,
Janko

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> > And delaying documentation to the very end of
> > the process is
> > probably not the best idea either ;-) IMHO the community
> > should favor the
> > approaches taken by packages such as roxygen or inlinedocs as
> > at least it
> > provides some sort of direct synchronization between code and
> > documentation.
> > Maybe one could agree on rejecting code that is missing
> > roxygen or inlinedoc
> > code, which would ensure that code is documented properly. In
> > fact, isn't
> > programming all about automating unnecessary manual
> > procedures? I would
> > count starting from scratch with all help files time and time
> > again to be
> > one of those unnecessary procedures. This time could better
> > be invested in
> > increasing the package's functionality.
> >
> > Best regards, my thanks go out to everyone as well,
> > Janko
> >
> > > > Thanks, as always, to everyone for their hard work to keep my
> > > statistical
> > > > computing free and easy.
> > > >
> > > > Best,
> > > >
> > > > Kyle
> > > >
> > > > [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-devel_at_r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From janko.thyson at ku-eichstaett.de  Thu Sep 16 21:11:51 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Thu, 16 Sep 2010 21:11:51 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <4C926816.7060206@gmail.com>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
	<4C92653F.6090003@statistik.tu-dortmund.de>
	<4C926816.7060206@gmail.com>
Message-ID: <005d01cb55d3$04b4f6a0$0e1ee3e0$@thyson@ku-eichstaett.de>

> -----Urspr?ngliche Nachricht-----
> Von: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Gesendet: Donnerstag, 16. September 2010 20:55
> An: Uwe Ligges
> Cc: Janko Thyson; r-devel at r-project. org
> Betreff: Re: [Rd] a small suggestion for improving the building of
> packages
> 
>   On 16/09/2010 2:43 PM, Uwe Ligges wrote:
> >
> > On 16.09.2010 20:18, Janko Thyson wrote:
> > >>  From: Uwe Ligges<ligges_at_statistik.tu-dortmund.de>
> > >>  Date: Wed, 15 Sep 2010 15:23:01 +0200
> > >>  On 29.08.2010 22:34, Kyle Matoba wrote:
> > >>>  All,
> > >>>
> > >>>  I just finished the process of build a package for the first
> time and
> > >>  found
> > >>>  it characteristically (for R) very straightforward and well
> > >>  documented.
> > >>>
> > >>>  Whenever I deal with open source software I always endeavor to
> finish
> > >>  the
> > >>>  task I have in mind, and upon completing this, I then revisit
> all of
> > >>  the
> > >>>  configurations, customizing as necessary to achieve my goals
> more
> > >>  fully.
> > >>>  The ability to achieve some minimal level of functionality
> without
> > >>  the
> > >>  need
> > >>>  for much filling in of configuration files, etc., is, I feel,
> > >>  important to
> > >>
> > >>>  not scaring off the less technically inclined such as myself.
> > >>>
> > >>>  Based on this heuristic, it is my understanding that a few small
> > >>  suggestions
> > >>>  could make building a warning-free package as easy as running
> > >>>  package.skeleton(), then R CMD check, R CMD build:
> > >>>
> > >>>  - Fill in default titles for each of the '*.Rd' files in /man
> > >>>  - Take out the tildes in the 'examples' section of the '*-
> package.Rd'
> > >>  main
> > >>
> > >>>  documentation file for the package (it seems to confuse the
> latex
> > >>  compiler)
> > >>>  - Put the lines '~~ Optionally other standard keywords, one per
> line,
> > >>  from
> > >>
> > >>>  file KEYWORDS in ~~
> > >>>  ~~ the R documentation directory ~~' into the \references{}
> section,
> > >>  there
> > >>
> > >>>  is presently a warning about all text needing to be in a
> section.
> > >>  Dear Kyle,
> > >>  thanks for the suggestions. Actually, it is intended to generate
> > >>  warnings /
> > >>  Errors in R CMD check: We want to force package developers to
> document
> > >>  their
> > >>  packages probably. This way, package maintainers / developers
> have to
> > >>  touch
> > >>  each Rd file and cannot use them as is in order to pass the
> checks.
> > >>  Best wishes,
> > >>  uwe
> > >
> > >  Dear Uwe,
> > >  in principle, I totally agree with your point of politely forcing
> developers
> > >  to write well documented packages. However, when you're trying to
> put
> > >  together a package, you (or at least I) never get it completely
> right on the
> > >  first, say, 20 tries ;-) Yet, by running package.skelleton() over
> and over
> > >  to keep track of changes you made during the process, you
> overwrite all Rd
> > >  files each time - including the ones that you might already have
> put a lot
> > >  of effort into. And delaying documentation to the very end of the
> process is
> > >  probably not the best idea either ;-) IMHO the community should
> favor the
> > >  approaches taken by packages such as roxygen or inlinedocs as at
> least it
> > >  provides some sort of direct synchronization between code and
> documentation.
> > >  Maybe one could agree on rejecting code that is missing roxygen or
> inlinedoc
> > >  code, which would ensure that code is documented properly. In
> fact, isn't
> > >  programming all about automating unnecessary manual procedures? I
> would
> > >  count starting from scratch with all help files time and time
> again to be
> > >  one of those unnecessary procedures. This time could better be
> invested in
> > >  increasing the package's functionality.
> >
> > - I don't think package.skeleton overwrites files unless you ask for
> it.
> >
> > - I think once you got started with your package, it is not required
> to
> > call package skeleton again. I tend to add files manually since I am
> > working on the package hierarchy itself using some editor...
> 
> Hi Uwe.  This message is mostly for Janko and others.
> 
> You can add them manually, but I would usually use prompt(), a generic
> function that produces just one .Rd file.
> 
> It's really one of the prompt methods that package.skeleton is calling
> to produce the bad man pages.  My own feeling is that package.skeleton
> should produce a package that is installable, but it shouldn't pass "R
> CMD check" unless there's some manual intervention to fill in the
> details.
> I think that is the current state of affairs, but if we're producing
> something that causes "R CMD build" or "R CMD INSTALL" to fail, please
> let us know.
> 
> By the way, I don't think the title can be filled in automatically
> unless a user has roxygen style documentation, so we don't.  But
> doesn't
> the roxygen package do that?
> 

Yes it does but I ran into the problem of roxygen not being able to process
non-S4 and S4-style code/Rd-files correctly if all the files are in the same
directory, e.g. pkg/man.
I played around with 'use.Rd2' but either way I either ended up with empty
titles or this error message:
http://lists.r-forge.r-project.org/pipermail/roxygen-devel/2009-November/000
096.html.  

> Duncan Murdoch
> 
> > - Last time I used package.skeleton is probably more than 2 years ago
> > (except for presentations in courses about package creation).
> >
> > Best,
> > Uwe
> >
> >
> >


From murdoch.duncan at gmail.com  Thu Sep 16 21:26:57 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Sep 2010 15:26:57 -0400
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700036E8DAB@NA-PA-VBE03.na.tibco.com>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
	<77EB52C6DD32BA4D87471DCD70C8D700036E8DAB@NA-PA-VBE03.na.tibco.com>
Message-ID: <4C926F81.6020300@gmail.com>

  On 16/09/2010 2:45 PM, William Dunlap wrote:
> >  From: r-devel-bounces at r-project.org
> >  [mailto:r-devel-bounces at r-project.org] On Behalf Of Janko Thyson
> >  Sent: Thursday, September 16, 2010 11:19 AM
> >  To: r-devel at r-project. org
> >  Subject: Re: [Rd] a small suggestion for improving the
> >  building of packages
> ...
> >  Dear Uwe,
> >  in principle, I totally agree with your point of politely
> >  forcing developers
> >  to write well documented packages. However, when you're trying to put
> >  together a package, you (or at least I) never get it
> >  completely right on the
> >  first, say, 20 tries ;-) Yet, by running package.skelleton()
> >  over and over
> >  to keep track of changes you made during the process, you
> >  overwrite all Rd
> >  files each time - including the ones that you might already
> >  have put a lot
> >  of effort into.
>
> Running package.skeleton more than once is destructive.
> Perhaps it needs an update=TRUE/FALSE sort of option
> to let you add functions and Rd templates.

Yes, that would be a nice addition.  I think good default behaviour 
would be to only create new files if none of the same name already exist 
(and warn that's what you did), but with an option to completely 
overwrite what was there.

> When I start a package I don't use package.skeleton,
> mainly because it won't make all the usual directories
> that I expect to eventually use: src, data, inst, test
> (or it is tests?), etc.  I'd rather that it made all
> the usual directories (with the proper spelling) so
> I could delete them if they ended up being empty.
> Do other package writers use package.skeleton routinely?

I don't make a lot of new packages, but I do use it for quick little 
ones.  I'm not so sure we should create all the directories:  it's 
mainly aimed at beginners, who might find that intimidating.  Advanced 
users can do what you do.  Perhaps an option (default off) to create 
everything
would be a good compromise.

Duncan Murdoch

> I copy a template package directory, edit the template
> DESCRIPTION file, copy my code into the appropriate
> subdirectories, and run prompt(func, filename="pkg/man/func.Rd")
> on each function or dataset.   The last step is a pain:
> it would be nice if prompt had a dir= or destdir= argument
> so that
>     prompt(func, destdir="pkg/man")
> would make the file "pkg/man/func.Rd".
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> >  And delaying documentation to the very end of
> >  the process is
> >  probably not the best idea either ;-) IMHO the community
> >  should favor the
> >  approaches taken by packages such as roxygen or inlinedocs as
> >  at least it
> >  provides some sort of direct synchronization between code and
> >  documentation.
> >  Maybe one could agree on rejecting code that is missing
> >  roxygen or inlinedoc
> >  code, which would ensure that code is documented properly. In
> >  fact, isn't
> >  programming all about automating unnecessary manual
> >  procedures? I would
> >  count starting from scratch with all help files time and time
> >  again to be
> >  one of those unnecessary procedures. This time could better
> >  be invested in
> >  increasing the package's functionality.
> >
> >  Best regards, my thanks go out to everyone as well,
> >  Janko
> >
> >  >  >  Thanks, as always, to everyone for their hard work to keep my
> >  >  statistical
> >  >  >  computing free and easy.
> >  >  >
> >  >  >  Best,
> >  >  >
> >  >  >  Kyle
> >  >  >
> >  >  >  [[alternative HTML version deleted]]
> >  >  >
> >  >  >  ______________________________________________
> >  >  >  R-devel_at_r-project.org mailing list
> >  >  >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevin.r.coombes at gmail.com  Thu Sep 16 23:17:19 2010
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Thu, 16 Sep 2010 16:17:19 -0500
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
References: <004f01cb55c7$4abf3950$e03dabf0$@thyson@ku-eichstaett.de>
	<005001cb55cb$9e7634a0$db629de0$@thyson@ku-eichstaett.de>
Message-ID: <4C92895F.80405@gmail.com>

  The phrase that caught my attention in your post is the one about 
"running package.skeleton() over and over".  When I'm developing 
packages, I never run it more than once.  And I usually delete a lot of 
the files it produces (since I like to organize my functions in logical 
batches and  not in separate files).  And once I think I have the file 
structure organized, I put everything under version control and run 
future development out that system.

Can you explain why you would need to re-run package.skeleton()? Is 
there some use case that I am missing?

     Kevin

On 9/16/2010 1:18 PM, Janko Thyson wrote:
> Dear Uwe,
> in principle, I totally agree with your point of politely forcing developers
> to write well documented packages. However, when you're trying to put
> together a package, you (or at least I) never get it completely right on the
> first, say, 20 tries ;-) Yet, by running package.skelleton() over and over
> to keep track of changes you made during the process, you overwrite all Rd
> files each time - including the ones that you might already have put a lot
> of effort into. And delaying documentation to the very end of the process is
> probably not the best idea either ;-) IMHO the community should favor the
> approaches taken by packages such as roxygen or inlinedocs as at least it
> provides some sort of direct synchronization between code and documentation.
> Maybe one could agree on rejecting code that is missing roxygen or inlinedoc
> code, which would ensure that code is documented properly. In fact, isn't
> programming all about automating unnecessary manual procedures? I would
> count starting from scratch with all help files time and time again to be
> one of those unnecessary procedures. This time could better be invested in
> increasing the package's functionality.
>
> Best regards, my thanks go out to everyone as well,
> Janko


From kasperdanielhansen at gmail.com  Thu Sep 16 23:48:08 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 16 Sep 2010 17:48:08 -0400
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <4C92895F.80405@gmail.com>
References: <4C92895F.80405@gmail.com>
Message-ID: <AANLkTiniR=KiQCtx41LPK35d4tuvj7oz8KFJi-f2uawK@mail.gmail.com>

I agree with Kevin, I never run package.skeleton more than once.  But
one advantage to running it over and over again is if you change the
names or the ordering of function arguments.  That gets autowritten
and I could see that being convenient if you change those a lot (as
you sometime do in development)

Kasper

On Thu, Sep 16, 2010 at 5:17 PM, Kevin R. Coombes
<kevin.r.coombes at gmail.com> wrote:
> ?The phrase that caught my attention in your post is the one about "running
> package.skeleton() over and over". ?When I'm developing packages, I never
> run it more than once. ?And I usually delete a lot of the files it produces
> (since I like to organize my functions in logical batches and ?not in
> separate files). ?And once I think I have the file structure organized, I
> put everything under version control and run future development out that
> system.
>
> Can you explain why you would need to re-run package.skeleton()? Is there
> some use case that I am missing?
>
> ? ?Kevin
>
> On 9/16/2010 1:18 PM, Janko Thyson wrote:
>>
>> Dear Uwe,
>> in principle, I totally agree with your point of politely forcing
>> developers
>> to write well documented packages. However, when you're trying to put
>> together a package, you (or at least I) never get it completely right on
>> the
>> first, say, 20 tries ;-) Yet, by running package.skelleton() over and over
>> to keep track of changes you made during the process, you overwrite all Rd
>> files each time - including the ones that you might already have put a lot
>> of effort into. And delaying documentation to the very end of the process
>> is
>> probably not the best idea either ;-) IMHO the community should favor the
>> approaches taken by packages such as roxygen or inlinedocs as at least it
>> provides some sort of direct synchronization between code and
>> documentation.
>> Maybe one could agree on rejecting code that is missing roxygen or
>> inlinedoc
>> code, which would ensure that code is documented properly. In fact, isn't
>> programming all about automating unnecessary manual procedures? I would
>> count starting from scratch with all help files time and time again to be
>> one of those unnecessary procedures. This time could better be invested in
>> increasing the package's functionality.
>>
>> Best regards, my thanks go out to everyone as well,
>> Janko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Thu Sep 16 23:53:21 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 16 Sep 2010 14:53:21 -0700
Subject: [Rd] environment variable for tar()/untar()
Message-ID: <4C9291D1.5020007@fhcrc.org>

Hi,

Is there any reason why tar() and untar() don't use the
same environment variable?

Usage:

      tar(tarfile, files = NULL,
          compression = c("none", "gzip", "bzip2", "xz"),
          compression_level = 6, tar = Sys.getenv("tar"))

Usage:

      untar(tarfile, files = NULL, list = FALSE, exdir = ".",
            compressed = NA, extras = NULL, verbose = FALSE,
            tar = Sys.getenv("TAR"))

Thanks!
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From spluque at gmail.com  Fri Sep 17 01:24:02 2010
From: spluque at gmail.com (Seb)
Date: Thu, 16 Sep 2010 18:24:02 -0500
Subject: [Rd] S4 plot generic documentation
Message-ID: <87zkvhqnl9.fsf@kolob.sebmags.homelinux.org>

Hi,

Say we want to supply a generic plot() in a package with a simple class,
like this:

---<--------------------cut here---------------start------------------->---
setClass("track",
         representation=representation(x="numeric", y="numeric"))

if (!isGeneric("plot")) {
    setGeneric("plot",
               function(x, y, ...) standardGeneric("plot"))
}

setMethod("plot", signature(x="track", y="missing"),
          function(x, y, ...) {
              plot(x at x, x at y, ...)
          })
---<--------------------cut here---------------end--------------------->---

To document the new method, I thought argument 'y' shouldn't need to be
documented in the package because it's declared 'missing', and the
following in plot-methods.Rd would be ok:

---<--------------------cut here---------------start------------------->---
\name{plot-methods}
\docType{methods}
\alias{plot-methods}
\alias{plot}
\alias{plot,track,missing-method}
\title{Methods}
\description{A plotting method}
\usage{\S4method{plot}{track,missing}(x, \ldots)}
\arguments{
  \item{x}{track.}
  \item{\ldots}{Arguments passed to \code{\link{plot}}.}
}
\section{Methods}{
  \describe{
    \item{plot}{\code{signature(x="track", y="missing")}: some plot.}
  }
}
\keyword{methods}
---<--------------------cut here---------------end--------------------->---

yet 'R CMD check' issues a warning:

---<--------------------cut here---------------start------------------->---
Codoc mismatches from documentation object 'plot-methods':
\S4method{plot}{track,missing}
  Code: function(x, y, ...)
  Docs: function(x, ...)
  Argument names in code not in docs:
    y
  Mismatches in argument names:
    Position: 2 Code: y Docs: ...
---<--------------------cut here---------------end--------------------->---

So it seems as if I'm asked to document the generic, not the particular
method.  What am I misunderstanding?  Thanks.

Cheers,

-- 
Seb


From Mark.Bravington at csiro.au  Fri Sep 17 01:35:57 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 17 Sep 2010 09:35:57 +1000
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <AANLkTiniR=KiQCtx41LPK35d4tuvj7oz8KFJi-f2uawK@mail.gmail.com>
References: <4C92895F.80405@gmail.com>
	<AANLkTiniR=KiQCtx41LPK35d4tuvj7oz8KFJi-f2uawK@mail.gmail.com>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F8705802B97E2@exvic-mbx03.nexus.csiro.au>

FWIW, the package-building tools in the 'mvbutils' package-- see ?mvbutils.packaging.tools-- are supposed to alleviate much of this (provided of course you are willing to sign up to MY view of the universe...). Building a "legal" package out of existing code from scratch takes me less than 5 minutes, I never have to write a line of Rd or call package.skeleton() or remember the syntax of NAMESPACE files etc, and if I don't want to write any doco myself yet I don't have to.  Plus, 
once I've built the package the first time, I can continue to work on it "live", without needing to unload/rebuild/reinstall all the time. The modus operandi is to work from a "task package folder"-- a level above/before the formal source-package layout-- which is the basis for (i) automatically generating the source package, and (ii) updating the installed package.

WRTO some of the points in the discussion already:  
 
 - Using fixr( myfunc, new.doc=T) is a bit like 'prompt'. It will add "legal" documentation to your function 'myfunc'-- ie it should pass RCMD CHECK. (As per an earlier post, this is "automatically manipulating some text to fill in the minimal documentation necessary to pass checks"). Of course, it still won't be much use to human beings unless you take the trouble to edit it. Having said that, I've come across some packages on CRAN with documentation that is little better...

 - Documentation is in plain-text that is automatically converted to Rd format later. Even if your plain-text is "wrong", it should still emerge as "legal" Rd & help files.

 - It's subsequently up to you to keep the doco in synch with any changes you make to the function itself, but at least the code & documentation for a function live next to each other in the same text file, so you are confronted with the one whenever you change the other.

 - You can work "live" on your package while it's loaded, and all changes/additions to the code and documentation are instantly reflected. [I know I said this already, but it bears repeating :)]

R 2.12 has changed the structure of installed packages (specifically, where DLLs live), and I haven't had time to tweak mvbutils accordingly-- hopefully I will find some time to sort it out before the release of 2.12.

This email may not excite much interest because-- unlike some of the other writers-- I personally found the R package creation process to be rather horrendous; it required me to learn a whole lot of very specific things that inevitably were forgotten by the next time I had to do it. In fact, it was enough to put me off writing documentation or proper packages for a long time. Now that I have an easy-to-use system in place, I've been much better about writing documentation and distributing mini-packages to colleagues.

Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

Kasper Daniel Hansen wrote:
> I agree with Kevin, I never run package.skeleton more than once.  But
> one advantage to running it over and over again is if you change the
> names or the ordering of function arguments.  That gets autowritten
> and I could see that being convenient if you change those a lot (as
> you sometime do in development)    
> 
> Kasper
> 
> On Thu, Sep 16, 2010 at 5:17 PM, Kevin R. Coombes
> <kevin.r.coombes at gmail.com> wrote: 
>> ?The phrase that caught my attention in your post is the one about
>> "running package.skeleton() over and over". ?When I'm developing
>> packages, I never run it more than once. ?And I usually delete a lot
>> of the files it produces (since I like to organize my functions in
>> logical batches and ?not in separate files). ?And once I think I
>> have the file structure organized, I put everything under version
>> control and run future development out that system.
>> 
>> Can you explain why you would need to re-run package.skeleton()? Is
>> there some use case that I am missing?
>> 
>> ? ?Kevin
>> 
>> On 9/16/2010 1:18 PM, Janko Thyson wrote:
>>> 
>>> Dear Uwe,
>>> in principle, I totally agree with your point of politely forcing
>>> developers to write well documented packages. However, when you're
>>> trying to put together a package, you (or at least I) never get it
>>> completely right on the first, say, 20 tries ;-) Yet, by running
>>> package.skelleton() over and over to keep track of changes you made
>>> during the process, you overwrite all Rd files each time - including
>>> the ones that you might already have put a lot of effort into. And
>>> delaying documentation to the very end of the process is probably
>>> not the best idea either ;-) IMHO the community should favor the
>>> approaches taken by packages such as roxygen or inlinedocs as at
>>> least it provides some sort of direct synchronization between code
>>> and documentation. Maybe one could agree on rejecting code that is
>>> missing roxygen or inlinedoc code, which would ensure that code is
>>> documented properly. In fact, isn't programming all about
>>> automating unnecessary manual procedures? I would count starting
>>> from scratch with all help files time and time again to be one of
>>> those unnecessary procedures. This time could better be invested in
>>> increasing the package's functionality. 
>>> 
>>> Best regards, my thanks go out to everyone as well, Janko
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From Thomas.Petzoldt at tu-dresden.de  Fri Sep 17 11:02:30 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 17 Sep 2010 11:02:30 +0200
Subject: [Rd] Summary: package test failed on Solaris x86  ...
In-Reply-To: <1284710502.3299.475.camel@braque.iarc.fr>
References: <4C91E07F.5010403@tu-dresden.de>	
	<1284649530.3299.395.camel@braque.iarc.fr>
	<4C923DB1.9030700@tu-dresden.de>	
	<1284654827.3299.461.camel@braque.iarc.fr>
	<4C924820.1090404@tu-dresden.de>
	<1284710502.3299.475.camel@braque.iarc.fr>
Message-ID: <4C932EA6.5030700@tu-dresden.de>

Dear Martin,

many thanks for your effort. Last night we found the same, thanks to the 
kind assistance from Bill Dunlap. The most important bugs are now 
already fixed, some minor things and an upload of a new version will 
follow soon.

Many thanks for the quick and competent assistance to Bill Dunlap, 
Matthew Doyle and you (Martyn Plummer). I've also setup a new Linux test 
system, so that next time valgrind checks can be performed before 
package upload.

Thank you!

Thomas Petzoldt


From janko.thyson at ku-eichstaett.de  Fri Sep 17 12:03:40 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Fri, 17 Sep 2010 12:03:40 +0200
Subject: [Rd] a small suggestion for improving the building of packages
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F8705802B97E2@exvic-mbx03.nexus.csiro.au>
References: <4C92895F.80405@gmail.com>
	<AANLkTiniR=KiQCtx41LPK35d4tuvj7oz8KFJi-f2uawK@mail.gmail.com>
	<62C82B39B8A85E4B95A18F7F7B852F8705802B97E2@exvic-mbx03.nexus.csiro.au>
Message-ID: <005e01cb564f$9aa179f0$cfe46dd0$@thyson@ku-eichstaett.de>

> -----Urspr?ngliche Nachricht-----
> Von: Mark.Bravington at csiro.au [mailto:Mark.Bravington at csiro.au]
> Gesendet: Freitag, 17. September 2010 01:36
> An: kasperdanielhansen at gmail.com; kevin.r.coombes at gmail.com
> Cc: janko.thyson at ku-eichstaett.de; r-devel at r-project.org
> Betreff: RE: [Rd] a small suggestion for improving the building of
> packages
> 
> FWIW, the package-building tools in the 'mvbutils' package-- see
> ?mvbutils.packaging.tools-- are supposed to alleviate much of this
> (provided of course you are willing to sign up to MY view of the
> universe...). Building a "legal" package out of existing code from
> scratch takes me less than 5 minutes, I never have to write a line of
> Rd or call package.skeleton() or remember the syntax of NAMESPACE files
> etc, and if I don't want to write any doco myself yet I don't have to.
> Plus,
> once I've built the package the first time, I can continue to work on
> it "live", without needing to unload/rebuild/reinstall all the time.
> The modus operandi is to work from a "task package folder"-- a level
> above/before the formal source-package layout-- which is the basis for
> (i) automatically generating the source package, and (ii) updating the
> installed package.

Wow, that sounds cool! I also tried to come up with a framework that puts
the focus on coding functionality and not on tediously manipulating things
in order to end up with an actual package time and time again. Thanks for
mentioning that package!
 
> WRTO some of the points in the discussion already:
> 
>  - Using fixr( myfunc, new.doc=T) is a bit like 'prompt'. It will add
> "legal" documentation to your function 'myfunc'-- ie it should pass
> RCMD CHECK. (As per an earlier post, this is "automatically
> manipulating some text to fill in the minimal documentation necessary
> to pass checks"). Of course, it still won't be much use to human beings
> unless you take the trouble to edit it. Having said that, I've come
> across some packages on CRAN with documentation that is little
> better...
> 
>  - Documentation is in plain-text that is automatically converted to Rd
> format later. Even if your plain-text is "wrong", it should still
> emerge as "legal" Rd & help files.
> 
>  - It's subsequently up to you to keep the doco in synch with any
> changes you make to the function itself, but at least the code &
> documentation for a function live next to each other in the same text
> file, so you are confronted with the one whenever you change the other.
> 
>  - You can work "live" on your package while it's loaded, and all
> changes/additions to the code and documentation are instantly
> reflected. [I know I said this already, but it bears repeating :)]
> 
> R 2.12 has changed the structure of installed packages (specifically,
> where DLLs live), and I haven't had time to tweak mvbutils accordingly-
> - hopefully I will find some time to sort it out before the release of
> 2.12.
> 
> This email may not excite much interest because-- unlike some of the
> other writers-- I personally found the R package creation process to be
> rather horrendous; it required me to learn a whole lot of very specific
> things that inevitably were forgotten by the next time I had to do it.
> In fact, it was enough to put me off writing documentation or proper
> packages for a long time. Now that I have an easy-to-use system in
> place, I've been much better about writing documentation and
> distributing mini-packages to colleagues.

That TOTALLY reflects my experiences so far with building packages. I can
see that this is a piece of cake for experienced developers that already can
visualize the complete layout of their package structure in their mind and
thus don't need to change a lot during the actual development. But for me
it's still a rather incremental and tentative process (I regard facilitating
this to be one of the key advantages of R) that involves changing function
and/or argument names and their order quite often. That's also why I used
package.skeleton() numerous times to reflect the changed structure in the
Rd-files. Thanks a lot for all the hints so far on how to do this
differently. Yet, if we would roughly separate developers into cracks and
beginners, it would really be great to have such an 'easy-to-use system'
(e.g. mvbutils or an upgraded version of package.skeleton()) available for
the beginners, as part of the base distribution.

> Mark
> 
> --
> Mark Bravington
> CSIRO Mathematical & Information Sciences
> Marine Laboratory
> Castray Esplanade
> Hobart 7001
> TAS
> 
> ph (+61) 3 6232 5118
> fax (+61) 3 6232 5012
> mob (+61) 438 315 623
> 
> Kasper Daniel Hansen wrote:
> > I agree with Kevin, I never run package.skeleton more than once.  But
> > one advantage to running it over and over again is if you change the
> > names or the ordering of function arguments.  That gets autowritten
> > and I could see that being convenient if you change those a lot (as
> > you sometime do in development)
> >
> > Kasper
> >
> > On Thu, Sep 16, 2010 at 5:17 PM, Kevin R. Coombes
> > <kevin.r.coombes at gmail.com> wrote:
> >> ?The phrase that caught my attention in your post is the one about
> >> "running package.skeleton() over and over". ?When I'm developing
> >> packages, I never run it more than once. ?And I usually delete a lot
> >> of the files it produces (since I like to organize my functions in
> >> logical batches and ?not in separate files). ?And once I think I
> >> have the file structure organized, I put everything under version
> >> control and run future development out that system.
> >>
> >> Can you explain why you would need to re-run package.skeleton()? Is
> >> there some use case that I am missing?
> >>
> >> ? ?Kevin
> >>
> >> On 9/16/2010 1:18 PM, Janko Thyson wrote:
> >>>
> >>> Dear Uwe,
> >>> in principle, I totally agree with your point of politely forcing
> >>> developers to write well documented packages. However, when you're
> >>> trying to put together a package, you (or at least I) never get it
> >>> completely right on the first, say, 20 tries ;-) Yet, by running
> >>> package.skelleton() over and over to keep track of changes you made
> >>> during the process, you overwrite all Rd files each time -
> including
> >>> the ones that you might already have put a lot of effort into. And
> >>> delaying documentation to the very end of the process is probably
> >>> not the best idea either ;-) IMHO the community should favor the
> >>> approaches taken by packages such as roxygen or inlinedocs as at
> >>> least it provides some sort of direct synchronization between code
> >>> and documentation. Maybe one could agree on rejecting code that is
> >>> missing roxygen or inlinedoc code, which would ensure that code is
> >>> documented properly. In fact, isn't programming all about
> >>> automating unnecessary manual procedures? I would count starting
> >>> from scratch with all help files time and time again to be one of
> >>> those unnecessary procedures. This time could better be invested in
> >>> increasing the package's functionality.
> >>>
> >>> Best regards, my thanks go out to everyone as well, Janko
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From janko.thyson at ku-eichstaett.de  Fri Sep 17 12:16:47 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Fri, 17 Sep 2010 12:16:47 +0200
Subject: [Rd] How to set up an own package repository
Message-ID: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>

Dear List,

 

I'd like to set up a package repository so I can use install.packages() on
it for home-grown packages. I set up an AMPP infrastructure on a windows box
already, but I'm pretty lost with respect to what to do next as I didn't do
any web-programming/admin yet. Could anyone recommend some r-specific
tutorials or has a couple of suggestions for me? I've had a look at the
official R manual, but it just describes the required repository structure,
but not how to implement that. I'd also be willing to dive into SVN and
alikes if you think that's best practice.

 

Thanks for any help whatsoever,

Janko


From wht_crl at yahoo.com  Fri Sep 17 14:25:32 2010
From: wht_crl at yahoo.com (carol white)
Date: Fri, 17 Sep 2010 05:25:32 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
Message-ID: <380180.50108.qm@web62003.mail.re1.yahoo.com>

 Hi,
1-
 How is it possible to use the name of a generic function as
 the name of a function which is not related to the generic
 function? For example, if I define predict.my.function, R
 will relate it to predict function and I'll get the following
 warning when I run R CMD check
 
 * checking S3 generic/method consistency ... WARNING
 predict:
 ? function(object, ...)
 predict.my.function ...
 
2- I get the following warning although I have used "require" of the related library in the function and imports in DESCRIPTION file

no visible global function definition for coxph

3- Although I use the alias of an Rd file of my package in cross references:

\seealso{
See Also as \code{\link{object.name}} 
}
where object.name is the name of an Rd file without Rd, I get the following warning

Missing link(s) in documentation object './man/object.name.Rd':
object.name

 I don't think that I will have use the name of my package.

 
Look forward to your reply,

 Carol







From Thomas.Petzoldt at tu-dresden.de  Fri Sep 17 16:04:24 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 17 Sep 2010 16:04:24 +0200
Subject: [Rd] Matrix install fails because of defunct save in require
Message-ID: <4C937568.6030208@tu-dresden.de>

Dear R-Devel,

I've just tried to compile the fresh R-devel and found that the install 
of package Matrix failed:

---------------------------------------------
** help
*** installing help indices
** building package indices ...
Error in require(Matrix, save = FALSE) :
   unused argument(s) (save = FALSE)
ERROR: installing package indices failed
---------------------------------------------


possible reason: Matrix/data/*.R

News.Rd says:

The \code{save} argument of \code{require()} is defunct.


Thomas Petzoldt


From simon.urbanek at r-project.org  Fri Sep 17 16:07:46 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Sep 2010 10:07:46 -0400
Subject: [Rd] How to set up an own package repository
In-Reply-To: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>
References: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>
Message-ID: <5C3A36EF-2B3C-4380-A668-246DC8DA13EF@r-project.org>


On Sep 17, 2010, at 6:16 AM, Janko Thyson wrote:

> Dear List,
> 
> 
> 
> I'd like to set up a package repository so I can use install.packages() on
> it for home-grown packages. I set up an AMPP infrastructure on a windows box
> already, but I'm pretty lost with respect to what to do next as I didn't do
> any web-programming/admin yet. Could anyone recommend some r-specific
> tutorials or has a couple of suggestions for me? I've had a look at the
> official R manual, but it just describes the required repository structure,
> but not how to implement that. I'd also be willing to dive into SVN and
> alikes if you think that's best practice.
> 

All you need is a web space. There are so many way to get one (many hosting provides, renting a server, accessing your home machine if your ISP allows it ...) that it's impossible to give a generic instruction. Once you get a webspace, it's just a matter of creating the directory structure described in R-admin in that space. Most hosting provides have web tools for that so you create the directories and upload your files.

What you are trying to achieve is that if you have let's say
http://someHosting.com/myAccount
as the root for your web space to support
install.packages("myPackage",,"http://someHosting.com/myAccount")
then you want 
http://someHosting.com/myAccount/src/contrib/PACKAGES
to exist and have the list of the packages (see R-admin) and your package sources in there. Analogously you want to create the binaries (Windows, Mac OS X etc.) in the corresponding bin/.../contrib folders so other users can install it without type='source'.

Of course you can use install.packages("myPackage",,"file:///myRepository") and have the files locally in /myRepository/src/contrib if you're only concerned about your local use.

Cheers,
Simon


From friedrich.leisch at stat.uni-muenchen.de  Fri Sep 17 16:39:04 2010
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Fri, 17 Sep 2010 16:39:04 +0200
Subject: [Rd] How to set up an own package repository
In-Reply-To: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>
References: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>
Message-ID: <19603.32136.712620.819950@angua.stat.uni-muenchen.de>

>>>>> On Fri, 17 Sep 2010 12:16:47 +0200,
>>>>> Janko Thyson (JT) wrote:

  > Dear List,
  > I'd like to set up a package repository so I can use install.packages() on
  > it for home-grown packages. I set up an AMPP infrastructure on a windows box
  > already, but I'm pretty lost with respect to what to do next as I didn't do
  > any web-programming/admin yet. Could anyone recommend some r-specific
  > tutorials or has a couple of suggestions for me? I've had a look at the
  > official R manual, but it just describes the required repository structure,
  > but not how to implement that. I'd also be willing to dive into SVN and
  > alikes if you think that's best practice.

If all machines involved can mount the repository as a network drive
you need no webserver at all, just use a file:/path/to/repository URL
for the repository.

If you want a full featured web frontend you may want to have a look
at the Bioconductor scripts for generating repositories:

http://bioconductor.org/packages/2.7/bioc/html/biocViews.html

and especially

http://bioconductor.org/packages/2.7/bioc/vignettes/biocViews/inst/doc/createReposHtml.pdf

The scripts for CRAN are also in R but very specific for CRANs needs ...

Best,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
-----------------------------------------------------------------------
   Journal Computational Statistics --- http://www.springer.com/180 
          M?nchner R Kurse --- http://www.statistik.lmu.de/R


From bbolker at gmail.com  Fri Sep 17 16:37:11 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Sep 2010 14:37:11 +0000 (UTC)
Subject: [Rd] How to set up an own package repository
References: <28265.5509924099$1284718670@news.gmane.org>
Message-ID: <loom.20100917T153848-35@post.gmane.org>

Janko Thyson <janko.thyson <at> ku-eichstaett.de> writes:

> 
> Dear List,
> 
> I'd like to set up a package repository so I can use install.packages() on
> it for home-grown packages. I set up an AMPP infrastructure on a windows box
> already, but I'm pretty lost with respect to what to do next as I didn't do
> any web-programming/admin yet. Could anyone recommend some r-specific
> tutorials or has a couple of suggestions for me? I've had a look at the
> official R manual, but it just describes the required repository structure,
> but not how to implement that. I'd also be willing to dive into SVN and
> alikes if you think that's best practice.

  It's pretty easy.  For example, I have a directory hierarchy

R/bin/{windows,windows64}
R/src/contrib/

  in each bottom-level directory I have the appropriate zipped
binaries or tar.gz sources, along with a PACKAGES file generated
by the write_PACKAGES function in the tools package.
  
  see section 6.6 of the R-admin manual.


From arijeet.rcc at gmail.com  Fri Sep 17 16:55:04 2010
From: arijeet.rcc at gmail.com (Arijeet Mukherjee)
Date: Fri, 17 Sep 2010 20:25:04 +0530
Subject: [Rd] How to connect R to Mysql?
Message-ID: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100917/b5629b4e/attachment.pl>

From spencer.graves at structuremonitoring.com  Fri Sep 17 17:50:06 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 17 Sep 2010 08:50:06 -0700
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>
Message-ID: <4C938E2E.6020000@structuremonitoring.com>



       I've recently been through that with some success.  I don't 
remember all the details, but I first looked at "help(pac=RMySQL)".   
This told me that the maintainer was Jeffrey Horner.  Google told me he 
was at Vanderbilt.  Eventually I found 
"http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL", which told me that 
I needed to build the package myself so it matches your version of 
MySQL, operating system, etc.  I did that.


       Does the MySQL database already exist?  I created a MySQL 
database and tables using MySQL server 5.1.50-win32.  (Which version of 
MySQL do you have?)


       help('RMySQL-package') includes "A typical usage".  That helped 
me get started, except that I needed to write to that database, not just 
query it.  For this, I think I got something like the following to work:


d <- dbReadTable(con, "WL")
dbWriteTable(con, "WL2", a.data.frame)  ## table from a data.frame
dbWriteTable(con, "test2", "~/data/test2.csv") ## table from a file


       Hope this helps.
       Spencer


On 9/17/2010 7:55 AM, Arijeet Mukherjee wrote:
> I installed the RMySql package in R 2.11.1 64 bit
> Now how can I connect R with MySql?
> I am using a windows 7 64 bit version.
> Please help ASAP.
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From etheber at gmx.de  Fri Sep 17 18:26:30 2010
From: etheber at gmx.de (Thomas Etheber)
Date: Fri, 17 Sep 2010 18:26:30 +0200
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <4C938E2E.6020000@structuremonitoring.com>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>
	<4C938E2E.6020000@structuremonitoring.com>
Message-ID: <4C9396B6.7000007@gmx.de>

I also had problems connecting via RMysql on Windows several weeks ago.
I decided to skip the package and now use RODBC, which runs stable out 
of the box. Perhaps you should have a look at this package.

Hth
Thomas

Am 17.09.2010 17:50, schrieb Spencer Graves:
>
>
>       I've recently been through that with some success.  I don't 
> remember all the details, but I first looked at "help(pac=RMySQL)".   
> This told me that the maintainer was Jeffrey Horner.  Google told me 
> he was at Vanderbilt.  Eventually I found 
> "http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL", which told me 
> that I needed to build the package myself so it matches your version 
> of MySQL, operating system, etc.  I did that.
>
>
>       Does the MySQL database already exist?  I created a MySQL 
> database and tables using MySQL server 5.1.50-win32.  (Which version 
> of MySQL do you have?)
>
>
>       help('RMySQL-package') includes "A typical usage".  That helped 
> me get started, except that I needed to write to that database, not 
> just query it.  For this, I think I got something like the following 
> to work:
>
>
> d <- dbReadTable(con, "WL")
> dbWriteTable(con, "WL2", a.data.frame)  ## table from a data.frame
> dbWriteTable(con, "test2", "~/data/test2.csv") ## table from a file
>
>
>       Hope this helps.
>       Spencer
>
>
> On 9/17/2010 7:55 AM, Arijeet Mukherjee wrote:
>> I installed the RMySql package in R 2.11.1 64 bit
>> Now how can I connect R with MySql?
>> I am using a windows 7 64 bit version.
>> Please help ASAP.
>>
>
>


From janko.thyson at ku-eichstaett.de  Fri Sep 17 18:27:02 2010
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Fri, 17 Sep 2010 18:27:02 +0200
Subject: [Rd] How to set up an own package repository
In-Reply-To: <19603.32136.712620.819950@angua.stat.uni-muenchen.de>
References: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>
	<19603.32136.712620.819950@angua.stat.uni-muenchen.de>
Message-ID: <008701cb5685$29221650$7b6642f0$@thyson@ku-eichstaett.de>

Thank you very much for the advice!

Cheers,
Janko

> -----Urspr?ngliche Nachricht-----
> Von: Friedrich Leisch [mailto:friedrich.leisch at stat.uni-muenchen.de]
> Gesendet: Freitag, 17. September 2010 16:39
> An: Janko Thyson
> Cc: r-devel at r-project. org
> Betreff: Re: [Rd] How to set up an own package repository
> 
> >>>>> On Fri, 17 Sep 2010 12:16:47 +0200,
> >>>>> Janko Thyson (JT) wrote:
> 
>   > Dear List,
>   > I'd like to set up a package repository so I can use
> install.packages() on
>   > it for home-grown packages. I set up an AMPP infrastructure on a
> windows box
>   > already, but I'm pretty lost with respect to what to do next as I
> didn't do
>   > any web-programming/admin yet. Could anyone recommend some r-
> specific
>   > tutorials or has a couple of suggestions for me? I've had a look at
> the
>   > official R manual, but it just describes the required repository
> structure,
>   > but not how to implement that. I'd also be willing to dive into SVN
> and
>   > alikes if you think that's best practice.
> 
> If all machines involved can mount the repository as a network drive
> you need no webserver at all, just use a file:/path/to/repository URL
> for the repository.
> 
> If you want a full featured web frontend you may want to have a look
> at the Bioconductor scripts for generating repositories:
> 
> http://bioconductor.org/packages/2.7/bioc/html/biocViews.html
> 
> and especially
> 
> http://bioconductor.org/packages/2.7/bioc/vignettes/biocViews/inst/doc/
> createReposHtml.pdf
> 
> The scripts for CRAN are also in R but very specific for CRANs needs
> ...
> 
> Best,
> Fritz
> 
> --
> -----------------------------------------------------------------------
> Prof. Dr. Friedrich Leisch
> 
> Institut f?r Statistik                          Tel: (+49 89) 2180 3165
> Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
> Ludwigstra?e 33
> D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
> -----------------------------------------------------------------------
>    Journal Computational Statistics --- http://www.springer.com/180
>           M?nchner R Kurse --- http://www.statistik.lmu.de/R
> 

From spencer.graves at structuremonitoring.com  Fri Sep 17 18:45:38 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 17 Sep 2010 09:45:38 -0700
Subject: [Rd] How to set up an own package repository
In-Reply-To: <008701cb5685$29221650$7b6642f0$@thyson@ku-eichstaett.de>
References: <006001cb5651$6f5d8250$4e1886f0$@thyson@ku-eichstaett.de>	<19603.32136.712620.819950@angua.stat.uni-muenchen.de>
	<008701cb5685$29221650$7b6642f0$@thyson@ku-eichstaett.de>
Message-ID: <4C939B32.9020302@structuremonitoring.com>

  This is also discussed in "Creating R Packages, Using CRAN, R-Forge, 
And Local R Archive Networks And Subversion (SVN) Repositories ? by 
Spencer Graves and Sundar Dorai-Raj, available from CRAN -> contributed 
documentation 
"http://cran.fhcrc.org/doc/contrib/Graves+DoraiRaj-RPackageDevelopment.pdf". 



Hope this helps. Spencer


On 9/17/2010 9:27 AM, Janko Thyson wrote:
> Thank you very much for the advice!
>
> Cheers,
> Janko
>
>> -----Urspr?ngliche Nachricht-----
>> Von: Friedrich Leisch [mailto:friedrich.leisch at stat.uni-muenchen.de]
>> Gesendet: Freitag, 17. September 2010 16:39
>> An: Janko Thyson
>> Cc: r-devel at r-project. org
>> Betreff: Re: [Rd] How to set up an own package repository
>>
>>>>>>> On Fri, 17 Sep 2010 12:16:47 +0200,
>>>>>>> Janko Thyson (JT) wrote:
>>    >  Dear List,
>>    >  I'd like to set up a package repository so I can use
>> install.packages() on
>>    >  it for home-grown packages. I set up an AMPP infrastructure on a
>> windows box
>>    >  already, but I'm pretty lost with respect to what to do next as I
>> didn't do
>>    >  any web-programming/admin yet. Could anyone recommend some r-
>> specific
>>    >  tutorials or has a couple of suggestions for me? I've had a look at
>> the
>>    >  official R manual, but it just describes the required repository
>> structure,
>>    >  but not how to implement that. I'd also be willing to dive into SVN
>> and
>>    >  alikes if you think that's best practice.
>>
>> If all machines involved can mount the repository as a network drive
>> you need no webserver at all, just use a file:/path/to/repository URL
>> for the repository.
>>
>> If you want a full featured web frontend you may want to have a look
>> at the Bioconductor scripts for generating repositories:
>>
>> http://bioconductor.org/packages/2.7/bioc/html/biocViews.html
>>
>> and especially
>>
>> http://bioconductor.org/packages/2.7/bioc/vignettes/biocViews/inst/doc/
>> createReposHtml.pdf
>>
>> The scripts for CRAN are also in R but very specific for CRANs needs
>> ...
>>
>> Best,
>> Fritz
>>
>> --
>> -----------------------------------------------------------------------
>> Prof. Dr. Friedrich Leisch
>>
>> Institut f?r Statistik                          Tel: (+49 89) 2180 3165
>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
>> Ludwigstra?e 33
>> D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
>> -----------------------------------------------------------------------
>>     Journal Computational Statistics --- http://www.springer.com/180
>>            M?nchner R Kurse --- http://www.statistik.lmu.de/R
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From spencer.graves at structuremonitoring.com  Fri Sep 17 18:47:13 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 17 Sep 2010 09:47:13 -0700
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <4C9396B6.7000007@gmx.de>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>	<4C938E2E.6020000@structuremonitoring.com>
	<4C9396B6.7000007@gmx.de>
Message-ID: <4C939B91.9020004@structuremonitoring.com>

  Hi, Thomas:


       You use RODBC to connect to MySQL?


       Thanks, Spencer


On 9/17/2010 9:26 AM, Thomas Etheber wrote:
> I also had problems connecting via RMysql on Windows several weeks ago.
> I decided to skip the package and now use RODBC, which runs stable out 
> of the box. Perhaps you should have a look at this package.
>
> Hth
> Thomas
>
> Am 17.09.2010 17:50, schrieb Spencer Graves:
>>
>>
>>       I've recently been through that with some success.  I don't 
>> remember all the details, but I first looked at "help(pac=RMySQL)".   
>> This told me that the maintainer was Jeffrey Horner.  Google told me 
>> he was at Vanderbilt.  Eventually I found 
>> "http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL", which told me 
>> that I needed to build the package myself so it matches your version 
>> of MySQL, operating system, etc.  I did that.
>>
>>
>>       Does the MySQL database already exist?  I created a MySQL 
>> database and tables using MySQL server 5.1.50-win32.  (Which version 
>> of MySQL do you have?)
>>
>>
>>       help('RMySQL-package') includes "A typical usage".  That helped 
>> me get started, except that I needed to write to that database, not 
>> just query it.  For this, I think I got something like the following 
>> to work:
>>
>>
>> d <- dbReadTable(con, "WL")
>> dbWriteTable(con, "WL2", a.data.frame)  ## table from a data.frame
>> dbWriteTable(con, "test2", "~/data/test2.csv") ## table from a file
>>
>>
>>       Hope this helps.
>>       Spencer
>>
>>
>> On 9/17/2010 7:55 AM, Arijeet Mukherjee wrote:
>>> I installed the RMySql package in R 2.11.1 64 bit
>>> Now how can I connect R with MySql?
>>> I am using a windows 7 64 bit version.
>>> Please help ASAP.
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From ligges at statistik.tu-dortmund.de  Fri Sep 17 19:22:04 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2010 19:22:04 +0200
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <4C937568.6030208@tu-dresden.de>
References: <4C937568.6030208@tu-dresden.de>
Message-ID: <4C93A3BC.3010409@statistik.tu-dortmund.de>



On 17.09.2010 16:04, Thomas Petzoldt wrote:
> Dear R-Devel,
>
> I've just tried to compile the fresh R-devel and found that the install
> of package Matrix failed:
>
> ---------------------------------------------
> ** help
> *** installing help indices
> ** building package indices ...
> Error in require(Matrix, save = FALSE) :
> unused argument(s) (save = FALSE)
> ERROR: installing package indices failed
> ---------------------------------------------


Have you got the Matrix package from the appropriate 2.12/recommended 
repository or installed via

make rsync-recommended
make recommended



In that case it works for me.

Uwe

>
> possible reason: Matrix/data/*.R
>
> News.Rd says:
>
> The \code{save} argument of \code{require()} is defunct.
>
>
> Thomas Petzoldt
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From andy_liaw at merck.com  Fri Sep 17 19:22:00 2010
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 17 Sep 2010 13:22:00 -0400
Subject: [Rd] Is it safe not to coerce matrices with as.double() in .C()?
In-Reply-To: <B10BAA7D28D88B45AF82813C4A6FFA93B32416@usctmx1157.merck.com>
References: <B10BAA7D28D88B45AF82813C4A6FFA93B323DA@usctmx1157.merck.com><B70A8DAE-0879-4E71-9792-359CF433240B@gmail.com><alpine.LFD.2.00.1008271510490.30882@localhost>
	<B10BAA7D28D88B45AF82813C4A6FFA93B32416@usctmx1157.merck.com>
Message-ID: <B10BAA7D28D88B45AF82813C4A6FFA93BAC851@usctmx1157.merck.com>

From: Liaw, Andy
> 
> From: Prof Brian Ripley
> > 
> > On Fri, 27 Aug 2010, peter dalgaard wrote:
> > 
> > >
> > > On Aug 27, 2010, at 2:44 PM, Liaw, Andy wrote:
> > >
> > >> I'd very much appreciate guidance on this.  A user 
> > reported that the
> > >> as.double() coercion used inside the .C() call for a 
> function in my
> > >> package (specifically, randomForest:::predict.randomForest()) is
> > >> taking up significant amount of time when called repeatedly, and
> > >> Removing some of these reduced run time by 30-40% in some cases.
> > >> These arguments are components of the fitted model (thus do not
> > >> change), and are matrices.  Some basic tests show no 
> difference in
> > >> The result when the coercions are removed (other than 
> > faster run time).
> > >> What I like to know is whether this is safe to do, or is 
> > it likely to
> > >> lead
> > >> to trouble in the future?
> > >
> > > In a word: yes. It is safe as long as you are absolutely 
> sure that 
> > > the argument has the right mode. The unsafeness comes in 
> > when people 
> > > might unwittingly use, say, an integer vector where a double was 
> > > expected, causing memory overruns and general mayhem.
> > >
> > > Notice, BTW, that if you switch to .Call or .External, then 
> > you have 
> > > much more scope for handling such details on the C-side. E.g. you 
> > > could coerce only if the object has the wrong mode, avoid 
> > > duplicating things you won't be modifying anyway, etc.
> > 
> > But as as.double is effectively .Call it has the same 
> freedom, and it 
> > does nothing if no coercion is required.  The crunch here is 
> > likely to 
> > be
> > 
> >       ?as.double? attempts to coerce its argument to be of 
> > double type:
> >       like ?as.vector? it strips attributes including names.  
> > (To ensure
> >       that an object is of double type without stripping 
> > attributes, use
> >       ?storage.mode?.)
> > 
> > I suspect the issue is the copying to remove attributes, in 
> which case
> 
> I can certainly believe this.  I've tried replacing 
> as.double() to c(), thinking attributes need to be stripped.  
> That actually increased run time very slightly instead of reducing it.
>  
> > storage.mode(x) <- "double"
> > 
> > should be a null op and so both fast and safe.
> 
> Will follow this advise.  Thanks to both of you for the help!

My apologies for coming back to this so late.  I did some test, and found that

  storage.mode(x) <- "double"

isn't as low on resource as I thought it might be.  Changing the code to this from

  x <- as.double(x)

did not give the expected speed improvement.  Here's a little test:

f1 <- function(x) { as.double(x); NULL }
f2 <- function(x) { storage.mode(x) <- "double"; NULL }
f3 <- function(x) { x <- x; NULL }
set.seed(917)
reps <- 500
x <- matrix(rnorm(1e6L), 1e3L, 1e3L)
system.time(junk <- replicate(reps, f1(x)))
system.time(junk <- replicate(reps, f2(x)))
system.time(junk <- replicate(reps, f3(x)))

On my laptop running R  2.11.1 Patched (2010-06-26 r52410), I get:

R> system.time(junk <- replicate(reps, f1(x)))
   user  system elapsed 
   3.54    2.14    5.74 
R> system.time(junk <- replicate(reps, f2(x)))
   user  system elapsed 
   3.32    2.11    5.92 
R> system.time(junk <- replicate(reps, f3(x)))
   user  system elapsed 
      0       0       0 

Perhaps I need to first check and see if the storage mode is as expected before trying coercion?

Best,
Andy


 
> Best,
> Andy
> 
>  
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
> New Jersey, USA 08889), and/or its affiliates Direct contact 
> information
> for affiliates is available at 
> http://www.merck.com/contact/contacts.html) that may be confidential,
> proprietary copyrighted and/or legally privileged. It is 
> intended solely
> for the use of the individual or entity named on this 
> message. If you are
> not the intended recipient, and have received this message in error,
> please notify us immediately by reply e-mail and then delete it from 
> your system.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates Direct contact information
for affiliates is available at 
http://www.merck.com/contact/contacts.html) that may be confidential,
proprietary copyrighted and/or legally privileged. It is intended solely
for the use of the individual or entity named on this message. If you are
not the intended recipient, and have received this message in error,
please notify us immediately by reply e-mail and then delete it from 
your system.

From ligges at statistik.tu-dortmund.de  Fri Sep 17 19:45:47 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2010 19:45:47 +0200
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <380180.50108.qm@web62003.mail.re1.yahoo.com>
References: <380180.50108.qm@web62003.mail.re1.yahoo.com>
Message-ID: <4C93A94B.2010307@statistik.tu-dortmund.de>



On 17.09.2010 14:25, carol white wrote:
>   Hi,
> 1-
>   How is it possible to use the name of a generic function as
>   the name of a function which is not related to the generic
>   function?

This is not possible, choose a different name or make it a predict() 
methods.

 >  For example, if I define predict.my.function, R
>   will relate it to predict function and I'll get the following
>   warning when I run R CMD check
>
>   * checking S3 generic/method consistency ... WARNING
>   predict:
>     function(object, ...)
>   predict.my.function ...



> 2- I get the following warning although I have used "require" of the related library in the function and imports in DESCRIPTION file
>
> no visible global function definition for coxph


If you do not import it into your namespace but make it available via 
require() instead, you need to declare it as Depends.


> 3- Although I use the alias of an Rd file of my package in cross references:
>
> \seealso{
> See Also as \code{\link{object.name}}
> }
> where object.name is the name of an Rd file without Rd

What is "an Rd file without Rd"?


> , I get the following warning
>
> Missing link(s) in documentation object './man/object.name.Rd':
> object.name

This means you cited the help page itself?

I think you need to tell us the alias(es) you used as well as the 
purpose of this one.


>
>   I don't think that I will have use the name of my package.


Why is this related?

Best wishes,
Uwe Ligges



>
> Look forward to your reply,
>
>   Carol
>
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From berwin at maths.uwa.edu.au  Fri Sep 17 19:54:40 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 18 Sep 2010 01:54:40 +0800
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <4C93A3BC.3010409@statistik.tu-dortmund.de>
References: <4C937568.6030208@tu-dresden.de>
	<4C93A3BC.3010409@statistik.tu-dortmund.de>
Message-ID: <20100918015440.67368ba2@goodenia>

G'day Uwe,

On Fri, 17 Sep 2010 19:22:04 +0200
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 17.09.2010 16:04, Thomas Petzoldt wrote:
> > Dear R-Devel,
> >
> > I've just tried to compile the fresh R-devel and found that the
> > install of package Matrix failed:
> >
> > ---------------------------------------------
> > ** help
> > *** installing help indices
> > ** building package indices ...
> > Error in require(Matrix, save = FALSE) :
> > unused argument(s) (save = FALSE)
> > ERROR: installing package indices failed
> > ---------------------------------------------
> 
> 
> Have you got the Matrix package from the appropriate 2.12/recommended 
> repository or installed via
> 
> make rsync-recommended
> make recommended

Are those the commands that should now be used?  My script is
essentially doing:

	svn up
	tools/rsync-recommended
	make 
	make check FORCE=FORCE

Running the script now, I experience the same problem as Thomas.  But I
note that Thomas did not state exactly what he is compiling.  My 'svn
up' updates the version checked out from:
	https://svn.r-project.org/R/trunk
which I think of as R-devel.   
Now after the svn up the file VERSION in the source directory says:
	2.13.0 Under development (unstable)
The SVN-REVISION file in my build directory says:
	Revision: 52938
	Last Changed Date: 2010-09-17
And I have Matrix_0.999375-44.tar.gz in src/library/Recommended of my
source directory.

As you refer to 2.12/recommended, you and Thomas might talk about
different versions when talking about R-devel.

Cheers,

	Berwin


From ligges at statistik.tu-dortmund.de  Fri Sep 17 19:59:06 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2010 19:59:06 +0200
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <20100918015440.67368ba2@goodenia>
References: <4C937568.6030208@tu-dresden.de>	<4C93A3BC.3010409@statistik.tu-dortmund.de>
	<20100918015440.67368ba2@goodenia>
Message-ID: <4C93AC6A.10008@statistik.tu-dortmund.de>



On 17.09.2010 19:54, Berwin A Turlach wrote:
> G'day Uwe,
>
> On Fri, 17 Sep 2010 19:22:04 +0200
> Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>
>>
>>
>> On 17.09.2010 16:04, Thomas Petzoldt wrote:
>>> Dear R-Devel,
>>>
>>> I've just tried to compile the fresh R-devel and found that the
>>> install of package Matrix failed:
>>>
>>> ---------------------------------------------
>>> ** help
>>> *** installing help indices
>>> ** building package indices ...
>>> Error in require(Matrix, save = FALSE) :
>>> unused argument(s) (save = FALSE)
>>> ERROR: installing package indices failed
>>> ---------------------------------------------
>>
>>
>> Have you got the Matrix package from the appropriate 2.12/recommended
>> repository or installed via
>>
>> make rsync-recommended
>> make recommended
>
> Are those the commands that should now be used?  My script is
> essentially doing:
>
> 	svn up
> 	tools/rsync-recommended
> 	make
> 	make check FORCE=FORCE
>
> Running the script now, I experience the same problem as Thomas.  But I
> note that Thomas did not state exactly what he is compiling.  My 'svn
> up' updates the version checked out from:
> 	https://svn.r-project.org/R/trunk
> which I think of as R-devel.
> Now after the svn up the file VERSION in the source directory says:
> 	2.13.0 Under development (unstable)
> The SVN-REVISION file in my build directory says:
> 	Revision: 52938
> 	Last Changed Date: 2010-09-17
> And I have Matrix_0.999375-44.tar.gz in src/library/Recommended of my
> source directory.
>
> As you refer to 2.12/recommended, you and Thomas might talk about
> different versions when talking about R-devel.


Indeed, I referred to R-prerelease (alpha / to be R-2.12.0 in October) 
rather than R-devel (perhaps to be R-2.13.0 next April or so).

Uwe


> Cheers,
>
> 	Berwin


From Thomas.Petzoldt at tu-dresden.de  Fri Sep 17 19:59:43 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 17 Sep 2010 19:59:43 +0200
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <4C93A3BC.3010409@statistik.tu-dortmund.de>
References: <4C937568.6030208@tu-dresden.de>
	<4C93A3BC.3010409@statistik.tu-dortmund.de>
Message-ID: <4C93AC8F.6010703@tu-dresden.de>

On 17.09.2010 19:22, Uwe Ligges wrote:
>
>
> On 17.09.2010 16:04, Thomas Petzoldt wrote:
>> Dear R-Devel,
>>
>> I've just tried to compile the fresh R-devel and found that the install
>> of package Matrix failed:
>>
>> ---------------------------------------------
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> Error in require(Matrix, save = FALSE) :
>> unused argument(s) (save = FALSE)
>> ERROR: installing package indices failed
>> ---------------------------------------------
>
>
> Have you got the Matrix package from the appropriate 2.12/recommended
> repository or installed via
>
> make rsync-recommended
> make recommended
>
 >
>
> In that case it works for me.
>
> Uwe

Yes, I did it this way, but did you use svn version before 52932 or a 
version equal or newer than 52940?

The svn log shows that in the meantime Brian Ripley added a workaround:

Revision: 52940
Author: ripley
Date: 19:31:48, Freitag, 17. September 2010
Message:
keep dummy require(save=FALSE) for now
----
Modified : /trunk/doc/NEWS.Rd
Modified : /trunk/src/library/base/R/library.R
Modified : /trunk/src/library/base/man/library.Rd


Is solved for now.

Thanks, Thomas P.


From ripley at stats.ox.ac.uk  Fri Sep 17 20:04:00 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Sep 2010 19:04:00 +0100 (BST)
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <20100918015440.67368ba2@goodenia>
References: <4C937568.6030208@tu-dresden.de>
	<4C93A3BC.3010409@statistik.tu-dortmund.de>
	<20100918015440.67368ba2@goodenia>
Message-ID: <alpine.LFD.2.00.1009171901110.1617@gannet.stats.ox.ac.uk>

I'm not sure why end users would be using R-devel rather than R-alpha 
at this point, but I have already changed R-devel to allow Matrix to 
get updated before it fails.

Warning: R-devel tends to be particularly unstable during the period 
when we are in alpha/beta/RC phases.

On Sat, 18 Sep 2010, Berwin A Turlach wrote:

> G'day Uwe,
>
> On Fri, 17 Sep 2010 19:22:04 +0200
> Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
>>
>>
>> On 17.09.2010 16:04, Thomas Petzoldt wrote:
>>> Dear R-Devel,
>>>
>>> I've just tried to compile the fresh R-devel and found that the
>>> install of package Matrix failed:
>>>
>>> ---------------------------------------------
>>> ** help
>>> *** installing help indices
>>> ** building package indices ...
>>> Error in require(Matrix, save = FALSE) :
>>> unused argument(s) (save = FALSE)
>>> ERROR: installing package indices failed
>>> ---------------------------------------------
>>
>>
>> Have you got the Matrix package from the appropriate 2.12/recommended
>> repository or installed via
>>
>> make rsync-recommended
>> make recommended
>
> Are those the commands that should now be used?  My script is
> essentially doing:
>
> 	svn up
> 	tools/rsync-recommended
> 	make
> 	make check FORCE=FORCE
>
> Running the script now, I experience the same problem as Thomas.  But I
> note that Thomas did not state exactly what he is compiling.  My 'svn
> up' updates the version checked out from:
> 	https://svn.r-project.org/R/trunk
> which I think of as R-devel.
> Now after the svn up the file VERSION in the source directory says:
> 	2.13.0 Under development (unstable)
> The SVN-REVISION file in my build directory says:
> 	Revision: 52938
> 	Last Changed Date: 2010-09-17
> And I have Matrix_0.999375-44.tar.gz in src/library/Recommended of my
> source directory.
>
> As you refer to 2.12/recommended, you and Thomas might talk about
> different versions when talking about R-devel.
>
> Cheers,
>
> 	Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.ted.byers at gmail.com  Fri Sep 17 20:04:37 2010
From: r.ted.byers at gmail.com (Ted Byers)
Date: Fri, 17 Sep 2010 14:04:37 -0400
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <4C9396B6.7000007@gmx.de>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>
	<4C938E2E.6020000@structuremonitoring.com>
	<4C9396B6.7000007@gmx.de>
Message-ID: <AANLkTikdVSUjt0KVOjNd+E9Wv02xJE6qBKYA2MMwcOFo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100917/9b8a3e9d/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Sep 17 20:14:55 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Sep 2010 19:14:55 +0100 (BST)
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <4C939B91.9020004@structuremonitoring.com>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>
	<4C938E2E.6020000@structuremonitoring.com>
	<4C9396B6.7000007@gmx.de>
	<4C939B91.9020004@structuremonitoring.com>
Message-ID: <alpine.LFD.2.00.1009171906320.1617@gannet.stats.ox.ac.uk>

On Fri, 17 Sep 2010, Spencer Graves wrote:

> Hi, Thomas:
>
>      You use RODBC to connect to MySQL?

Well, I do, and it is faster and more stable than RMySQL on all my 
platforms.

However, I have no idea why this is thought to be the appropriate 
list.  See R-sig-db !

For Windows, we need to know (see the posting guide) not just the 
version of the OS but also the version of R.  If you are running x64 
Win 7, you might be running 32- or 64-bit Windows.  Whichever, the the 
ODBC driver or MySQL client dll has to be of the same architecture as 
R *and not MySQL nor the OS*.  This is covered in detail in the RODBC 
manual.  For RMySQL it is quite recent that it has worked under x64 
Windows and I am not sure the documentation has yet caught up.

Follow-up to R-sig-db (which requires you to join to post) would be 
appropriate, so I am copying this there for future reference.

>
>
>      Thanks, Spencer
>
>
> On 9/17/2010 9:26 AM, Thomas Etheber wrote:
>> I also had problems connecting via RMysql on Windows several weeks ago.
>> I decided to skip the package and now use RODBC, which runs stable out of 
>> the box. Perhaps you should have a look at this package.
>> 
>> Hth
>> Thomas
>> 
>> Am 17.09.2010 17:50, schrieb Spencer Graves:
>>> 
>>>
>>>       I've recently been through that with some success.  I don't remember 
>>> all the details, but I first looked at "help(pac=RMySQL)".   This told me 
>>> that the maintainer was Jeffrey Horner.  Google told me he was at 
>>> Vanderbilt.  Eventually I found 
>>> "http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL", which told me that I 
>>> needed to build the package myself so it matches your version of MySQL, 
>>> operating system, etc.  I did that.
>>> 
>>>
>>>       Does the MySQL database already exist?  I created a MySQL database 
>>> and tables using MySQL server 5.1.50-win32.  (Which version of MySQL do 
>>> you have?)
>>> 
>>>
>>>       help('RMySQL-package') includes "A typical usage".  That helped me 
>>> get started, except that I needed to write to that database, not just 
>>> query it.  For this, I think I got something like the following to work:
>>> 
>>> 
>>> d <- dbReadTable(con, "WL")
>>> dbWriteTable(con, "WL2", a.data.frame)  ## table from a data.frame
>>> dbWriteTable(con, "test2", "~/data/test2.csv") ## table from a file
>>> 
>>>
>>>       Hope this helps.
>>>       Spencer
>>> 
>>> 
>>> On 9/17/2010 7:55 AM, Arijeet Mukherjee wrote:
>>>> I installed the RMySql package in R 2.11.1 64 bit
>>>> Now how can I connect R with MySql?
>>>> I am using a windows 7 64 bit version.
>>>> Please help ASAP.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wht_crl at yahoo.com  Fri Sep 17 20:15:57 2010
From: wht_crl at yahoo.com (carol white)
Date: Fri, 17 Sep 2010 11:15:57 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <4C93A94B.2010307@statistik.tu-dortmund.de>
Message-ID: <935784.92453.qm@web62004.mail.re1.yahoo.com>

Thank you for your reply.

--- On Fri, 9/17/10, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
> Subject: Re: [Rd] some problems reported in 00check.log
> To: "carol white" <wht_crl at yahoo.com>
> Cc: r-devel at r-project.org
> Date: Friday, September 17, 2010, 10:45 AM
> 

> 
regarding the point 3,
Suppose I have a data set, data.set1 with data.set1.Rd and data.set2 with data.set2.Rd that are related to each other. then, I put in \seealso field

in data.set2.Rd
\seealso{
 See Also as \code{\link{data.set1}}

and in data.set1.Rd
\seealso{
 See Also as \code{\link{data.set2}}

But I get the aforementioned warning that I don't understand why.
> > Missing link(s) in documentation object
> './man/object.name.Rd':
> > object.name

There is another problem. I have installed two packages in another path than the library path of R. how could I load them for R CMD check (where to indicate the path for lib.loc) as I get error message due to require of these two packages in different functions?

> 
> > 3- Although I use the alias of an Rd file of my
> package in cross references:
> >
> > \seealso{
> > See Also as \code{\link{object.name}}
> > }
> > where object.name is the name of an Rd file without
> Rd
> 
> What is "an Rd file without Rd"?
> 
> 
> > , I get the following warning
> >
> > Missing link(s) in documentation object
> './man/object.name.Rd':
> > object.name
> 
> This means you cited the help page itself?
> 
> I think you need to tell us the alias(es) you used as well
> as the 
> purpose of this one.
> 
> 
> >
> >???I don't think that I will have use
> the name of my package.
> 
> 
> Why is this related?
> 
> Best wishes,
> Uwe Ligges
> 
> 
> 
> >
> > Look forward to your reply,
> >
> >???Carol
> >
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 





From Thomas.Petzoldt at tu-dresden.de  Fri Sep 17 20:18:04 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Fri, 17 Sep 2010 20:18:04 +0200
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <alpine.LFD.2.00.1009171901110.1617@gannet.stats.ox.ac.uk>
References: <4C937568.6030208@tu-dresden.de>	<4C93A3BC.3010409@statistik.tu-dortmund.de>	<20100918015440.67368ba2@goodenia>
	<alpine.LFD.2.00.1009171901110.1617@gannet.stats.ox.ac.uk>
Message-ID: <4C93B0DC.8090104@tu-dresden.de>

On 17.09.2010 20:04, Prof Brian Ripley wrote:
> I'm not sure why end users would be using R-devel rather than R-alpha at
> this point, but I have already changed R-devel to allow Matrix to get
> updated before it fails.

Yes I realized the update and successfully recompiled it. Many thanks.

"End users" or package developers want to keep own packages compatible 
with future versions, so maintaining svn syncs is much more efficient 
than downloading snapshoots. In the current case it would have been much 
easier for me, of course, to go back to an older svn release (as I 
sometimes do). However, I felt to be responsible for reporting issues as 
contribution to the open source development process.

O.K., I'll wait a little bit longer in the future and many thanks for 
developing this great software.

ThPe


From ripley at stats.ox.ac.uk  Fri Sep 17 20:27:45 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Sep 2010 19:27:45 +0100 (BST)
Subject: [Rd] Matrix install fails because of defunct save in require
In-Reply-To: <4C93B0DC.8090104@tu-dresden.de>
References: <4C937568.6030208@tu-dresden.de>
	<4C93A3BC.3010409@statistik.tu-dortmund.de>
	<20100918015440.67368ba2@goodenia>
	<alpine.LFD.2.00.1009171901110.1617@gannet.stats.ox.ac.uk>
	<4C93B0DC.8090104@tu-dresden.de>
Message-ID: <alpine.LFD.2.00.1009171920480.1617@gannet.stats.ox.ac.uk>

On Fri, 17 Sep 2010, Thomas Petzoldt wrote:

> On 17.09.2010 20:04, Prof Brian Ripley wrote:
>> I'm not sure why end users would be using R-devel rather than R-alpha at
>> this point, but I have already changed R-devel to allow Matrix to get
>> updated before it fails.
>
> Yes I realized the update and successfully recompiled it. Many thanks.
>
> "End users" or package developers want to keep own packages compatible with 
> future versions, so maintaining svn syncs is much more efficient than 
> downloading snapshoots. In the current case it would have been much easier

But many of us svn sync e.g. R-2-12-branch rather than use snapshots.

> for me, of course, to go back to an older svn release (as I sometimes do). 
> However, I felt to be responsible for reporting issues as contribution to the 
> open source development process.
>
> O.K., I'll wait a little bit longer in the future and many thanks for 
> developing this great software.

I think the advice in the Windows binary download page

'This is a development version of R. It likely contains bugs, so be 
careful if you use it. Please don't report bugs in this version 
through the usual R bug reporting system, please report them on the 
r-devel mailing list---but only if they persist for a few days.'

is spot-on. It takes at least several hours, maybe a couple of days, 
for the package checks to reveal problems with changes in R-devel, 
especially platform-specific ones.


> ThPe
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Fri Sep 17 21:18:13 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Sep 2010 15:18:13 -0400
Subject: [Rd] Is it safe not to coerce matrices with as.double() in .C()?
In-Reply-To: <B10BAA7D28D88B45AF82813C4A6FFA93BAC851@usctmx1157.merck.com>
References: <B10BAA7D28D88B45AF82813C4A6FFA93B323DA@usctmx1157.merck.com><B70A8DAE-0879-4E71-9792-359CF433240B@gmail.com><alpine.LFD.2.00.1008271510490.30882@localhost>
	<B10BAA7D28D88B45AF82813C4A6FFA93B32416@usctmx1157.merck.com>
	<B10BAA7D28D88B45AF82813C4A6FFA93BAC851@usctmx1157.merck.com>
Message-ID: <21F84AB4-2184-4B48-9A15-EFFA00E5958A@r-project.org>


On Sep 17, 2010, at 1:22 PM, Liaw, Andy wrote:

> From: Liaw, Andy
>> 
>> From: Prof Brian Ripley
>>> 
>>> On Fri, 27 Aug 2010, peter dalgaard wrote:
>>> 
>>>> 
>>>> On Aug 27, 2010, at 2:44 PM, Liaw, Andy wrote:
>>>> 
>>>>> I'd very much appreciate guidance on this.  A user 
>>> reported that the
>>>>> as.double() coercion used inside the .C() call for a 
>> function in my
>>>>> package (specifically, randomForest:::predict.randomForest()) is
>>>>> taking up significant amount of time when called repeatedly, and
>>>>> Removing some of these reduced run time by 30-40% in some cases.
>>>>> These arguments are components of the fitted model (thus do not
>>>>> change), and are matrices.  Some basic tests show no 
>> difference in
>>>>> The result when the coercions are removed (other than 
>>> faster run time).
>>>>> What I like to know is whether this is safe to do, or is 
>>> it likely to
>>>>> lead
>>>>> to trouble in the future?
>>>> 
>>>> In a word: yes. It is safe as long as you are absolutely 
>> sure that 
>>>> the argument has the right mode. The unsafeness comes in 
>>> when people 
>>>> might unwittingly use, say, an integer vector where a double was 
>>>> expected, causing memory overruns and general mayhem.
>>>> 
>>>> Notice, BTW, that if you switch to .Call or .External, then 
>>> you have 
>>>> much more scope for handling such details on the C-side. E.g. you 
>>>> could coerce only if the object has the wrong mode, avoid 
>>>> duplicating things you won't be modifying anyway, etc.
>>> 
>>> But as as.double is effectively .Call it has the same 
>> freedom, and it 
>>> does nothing if no coercion is required.  The crunch here is 
>>> likely to 
>>> be
>>> 
>>>      ?as.double? attempts to coerce its argument to be of 
>>> double type:
>>>      like ?as.vector? it strips attributes including names.  
>>> (To ensure
>>>      that an object is of double type without stripping 
>>> attributes, use
>>>      ?storage.mode?.)
>>> 
>>> I suspect the issue is the copying to remove attributes, in 
>> which case
>> 
>> I can certainly believe this.  I've tried replacing 
>> as.double() to c(), thinking attributes need to be stripped.  
>> That actually increased run time very slightly instead of reducing it.
>> 
>>> storage.mode(x) <- "double"
>>> 
>>> should be a null op and so both fast and safe.
>> 
>> Will follow this advise.  Thanks to both of you for the help!
> 
> My apologies for coming back to this so late.  I did some test, and found that
> 
>  storage.mode(x) <- "double"
> 
> isn't as low on resource as I thought it might be.  Changing the code to this from
> 
>  x <- as.double(x)
> 
> did not give the expected speed improvement.  Here's a little test:
> 
> f1 <- function(x) { as.double(x); NULL }
> f2 <- function(x) { storage.mode(x) <- "double"; NULL }
> f3 <- function(x) { x <- x; NULL }
> set.seed(917)
> reps <- 500
> x <- matrix(rnorm(1e6L), 1e3L, 1e3L)
> system.time(junk <- replicate(reps, f1(x)))
> system.time(junk <- replicate(reps, f2(x)))
> system.time(junk <- replicate(reps, f3(x)))
> 
> On my laptop running R  2.11.1 Patched (2010-06-26 r52410), I get:
> 
> R> system.time(junk <- replicate(reps, f1(x)))
>   user  system elapsed 
>   3.54    2.14    5.74 
> R> system.time(junk <- replicate(reps, f2(x)))
>   user  system elapsed 
>   3.32    2.11    5.92 
> R> system.time(junk <- replicate(reps, f3(x)))
>   user  system elapsed 
>      0       0       0 
> 
> Perhaps I need to first check and see if the storage mode is as expected before trying coercion?
> 

Well, the devil is in the details. Although storage.mode<- is a noop itself, the issue is that it does trigger duplication because it is an assignment, not because storage mode would change anything. Technically, x <- x is a special case which is truly a noop whereas any call `foo<-` has to assume modification. So, yes, in your case 
f4 <- function(x) { if (storage.mode(x) != "double") storage.mode(x) <- "double"; NULL }
will have the same speed as f3. If you are going in to .Call then you could as well do that in the C side (with the benefit of being able to strip attributes since you can get them from the original object if you care...).

Cheers,
Simon



> Best,
> Andy
> 
> 
> 
>> Best,
>> Andy
>> 
>> 
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>> 
>> Notice:  This e-mail message, together with any attachments, contains
>> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
>> New Jersey, USA 08889), and/or its affiliates Direct contact 
>> information
>> for affiliates is available at 
>> http://www.merck.com/contact/contacts.html) that may be confidential,
>> proprietary copyrighted and/or legally privileged. It is 
>> intended solely
>> for the use of the individual or entity named on this 
>> message. If you are
>> not the intended recipient, and have received this message in error,
>> please notify us immediately by reply e-mail and then delete it from 
>> your system.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> Notice:  This e-mail message, together with any attach...{{dropped:18}}


From andy_liaw at merck.com  Fri Sep 17 22:16:11 2010
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 17 Sep 2010 16:16:11 -0400
Subject: [Rd] Is it safe not to coerce matrices with as.double() in .C()?
In-Reply-To: <21F84AB4-2184-4B48-9A15-EFFA00E5958A@r-project.org>
References: <B10BAA7D28D88B45AF82813C4A6FFA93B323DA@usctmx1157.merck.com><B70A8DAE-0879-4E71-9792-359CF433240B@gmail.com><alpine.LFD.2.00.1008271510490.30882@localhost>
	<B10BAA7D28D88B45AF82813C4A6FFA93B32416@usctmx1157.merck.com>
	<B10BAA7D28D88B45AF82813C4A6FFA93BAC851@usctmx1157.merck.com>
	<21F84AB4-2184-4B48-9A15-EFFA00E5958A@r-project.org>
Message-ID: <B10BAA7D28D88B45AF82813C4A6FFA93BAC8A5@usctmx1157.merck.com>

 
> From: Simon Urbanek 
> 
> On Sep 17, 2010, at 1:22 PM, Liaw, Andy wrote:
> 
> > From: Liaw, Andy
> >> 
> >> From: Prof Brian Ripley
> >>> 
> >>> On Fri, 27 Aug 2010, peter dalgaard wrote:
> >>> 
> >>>> 
> >>>> On Aug 27, 2010, at 2:44 PM, Liaw, Andy wrote:
> >>>> 
> >>>>> I'd very much appreciate guidance on this.  A user 
> >>> reported that the
> >>>>> as.double() coercion used inside the .C() call for a 
> >> function in my
> >>>>> package (specifically, randomForest:::predict.randomForest()) is
> >>>>> taking up significant amount of time when called repeatedly, and
> >>>>> Removing some of these reduced run time by 30-40% in some cases.
> >>>>> These arguments are components of the fitted model (thus do not
> >>>>> change), and are matrices.  Some basic tests show no 
> >> difference in
> >>>>> The result when the coercions are removed (other than 
> >>> faster run time).
> >>>>> What I like to know is whether this is safe to do, or is 
> >>> it likely to
> >>>>> lead
> >>>>> to trouble in the future?
> >>>> 
> >>>> In a word: yes. It is safe as long as you are absolutely 
> >> sure that 
> >>>> the argument has the right mode. The unsafeness comes in 
> >>> when people 
> >>>> might unwittingly use, say, an integer vector where a double was 
> >>>> expected, causing memory overruns and general mayhem.
> >>>> 
> >>>> Notice, BTW, that if you switch to .Call or .External, then 
> >>> you have 
> >>>> much more scope for handling such details on the C-side. 
> E.g. you 
> >>>> could coerce only if the object has the wrong mode, avoid 
> >>>> duplicating things you won't be modifying anyway, etc.
> >>> 
> >>> But as as.double is effectively .Call it has the same 
> >> freedom, and it 
> >>> does nothing if no coercion is required.  The crunch here is 
> >>> likely to 
> >>> be
> >>> 
> >>>      'as.double' attempts to coerce its argument to be of 
> >>> double type:
> >>>      like 'as.vector' it strips attributes including names.  
> >>> (To ensure
> >>>      that an object is of double type without stripping 
> >>> attributes, use
> >>>      'storage.mode'.)
> >>> 
> >>> I suspect the issue is the copying to remove attributes, in 
> >> which case
> >> 
> >> I can certainly believe this.  I've tried replacing 
> >> as.double() to c(), thinking attributes need to be stripped.  
> >> That actually increased run time very slightly instead of 
> reducing it.
> >> 
> >>> storage.mode(x) <- "double"
> >>> 
> >>> should be a null op and so both fast and safe.
> >> 
> >> Will follow this advise.  Thanks to both of you for the help!
> > 
> > My apologies for coming back to this so late.  I did some 
> test, and found that
> > 
> >  storage.mode(x) <- "double"
> > 
> > isn't as low on resource as I thought it might be.  
> Changing the code to this from
> > 
> >  x <- as.double(x)
> > 
> > did not give the expected speed improvement.  Here's a little test:
> > 
> > f1 <- function(x) { as.double(x); NULL }
> > f2 <- function(x) { storage.mode(x) <- "double"; NULL }
> > f3 <- function(x) { x <- x; NULL }
> > set.seed(917)
> > reps <- 500
> > x <- matrix(rnorm(1e6L), 1e3L, 1e3L)
> > system.time(junk <- replicate(reps, f1(x)))
> > system.time(junk <- replicate(reps, f2(x)))
> > system.time(junk <- replicate(reps, f3(x)))
> > 
> > On my laptop running R  2.11.1 Patched (2010-06-26 r52410), I get:
> > 
> > R> system.time(junk <- replicate(reps, f1(x)))
> >   user  system elapsed 
> >   3.54    2.14    5.74 
> > R> system.time(junk <- replicate(reps, f2(x)))
> >   user  system elapsed 
> >   3.32    2.11    5.92 
> > R> system.time(junk <- replicate(reps, f3(x)))
> >   user  system elapsed 
> >      0       0       0 
> > 
> > Perhaps I need to first check and see if the storage mode 
> is as expected before trying coercion?
> > 
> 
> Well, the devil is in the details. Although storage.mode<- is 
> a noop itself, the issue is that it does trigger duplication 
> because it is an assignment, not because storage mode would 
> change anything. Technically, x <- x is a special case which 
> is truly a noop whereas any call `foo<-` has to assume 
> modification. So, yes, in your case 
> f4 <- function(x) { if (storage.mode(x) != "double") 
> storage.mode(x) <- "double"; NULL }
> will have the same speed as f3. If you are going in to .Call 
> then you could as well do that in the C side (with the 
> benefit of being able to strip attributes since you can get 
> them from the original object if you care...).
> 
> Cheers,
> Simon

Thanks a lot, Simon, for the clarification.  Unfortunately I'm not using
.Call(), but .C() with DUP=FALSE, and it's exactly the duplication that
I'm trying to avoid.  For now I just inserted tests (is.double() and
is.integer()) and only do the coercion if needed, prior to the .C()
call.  That gives the speed up that I was expecting.

To do this more cleanly, I really need to learn .Call()...

Best,
Andy

> 
> > Best,
> > Andy
> > 
> > 
> > 
> >> Best,
> >> Andy
> >> 
> >> 
> >>> -- 
> >>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>> Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> >>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>> 
> >> Notice:  This e-mail message, together with any 
> attachments, contains
> >> information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station,
> >> New Jersey, USA 08889), and/or its affiliates Direct contact 
> >> information
> >> for affiliates is available at 
> >> http://www.merck.com/contact/contacts.html) that may be 
> confidential,
> >> proprietary copyrighted and/or legally privileged. It is 
> >> intended solely
> >> for the use of the individual or entity named on this 
> >> message. If you are
> >> not the intended recipient, and have received this message 
> in error,
> >> please notify us immediately by reply e-mail and then 
> delete it from 
> >> your system.
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> > Notice:  This e-mail message, together with any 
> attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station,
> > New Jersey, USA 08889), and/or its affiliates Direct 
> contact information
> > for affiliates is available at 
> > http://www.merck.com/contact/contacts.html) that may be 
> confidential,
> > proprietary copyrighted and/or legally privileged. It is 
> intended solely
> > for the use of the individual or entity named on this 
> message. If you are
> > not the intended recipient, and have received this message in error,
> > please notify us immediately by reply e-mail and then 
> delete it from 
> > your system.
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From ligges at statistik.tu-dortmund.de  Sat Sep 18 14:43:59 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 18 Sep 2010 14:43:59 +0200
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <935784.92453.qm@web62004.mail.re1.yahoo.com>
References: <935784.92453.qm@web62004.mail.re1.yahoo.com>
Message-ID: <4C94B40F.6040708@statistik.tu-dortmund.de>



On 17.09.2010 20:15, carol white wrote:
> Thank you for your reply.
>
> --- On Fri, 9/17/10, Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>
>> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
>> Subject: Re: [Rd] some problems reported in 00check.log
>> To: "carol white"<wht_crl at yahoo.com>
>> Cc: r-devel at r-project.org
>> Date: Friday, September 17, 2010, 10:45 AM
>>
>
>>
> regarding the point 3,
> Suppose I have a data set, data.set1 with data.set1.Rd and data.set2 with data.set2.Rd that are related to each other. then, I put in \seealso field
>
> in data.set2.Rd
> \seealso{
>   See Also as \code{\link{data.set1}}
>
> and in data.set1.Rd
> \seealso{
>   See Also as \code{\link{data.set2}}
>
> But I get the aforementioned warning that I don't understand why.
>>> Missing link(s) in documentation object
>> './man/object.name.Rd':
>>> object.name


In that case I guess you forgot to specify the aliases appropriately?


> There is another problem. I have installed two packages in another path than the library path of R. how could I load them for R CMD check (where to indicate the path for lib.loc) as I get error message due to require of these two packages in different functions?

For example, specify all relevant libraries in the environment variable 
R_LIBS.

Best,
Uwe Ligges


>
>>
>>> 3- Although I use the alias of an Rd file of my
>> package in cross references:
>>>
>>> \seealso{
>>> See Also as \code{\link{object.name}}
>>> }
>>> where object.name is the name of an Rd file without
>> Rd
>>
>> What is "an Rd file without Rd"?
>>
>>
>>> , I get the following warning
>>>
>>> Missing link(s) in documentation object
>> './man/object.name.Rd':
>>> object.name
>>
>> This means you cited the help page itself?
>>
>> I think you need to tell us the alias(es) you used as well
>> as the
>> purpose of this one.
>>
>>
>>>
>>>     I don't think that I will have use
>> the name of my package.
>>
>>
>> Why is this related?
>>
>> Best wishes,
>> Uwe Ligges
>>
>>
>>
>>>
>>> Look forward to your reply,
>>>
>>>     Carol
>>>
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>


From d.scott at auckland.ac.nz  Sat Sep 18 15:22:04 2010
From: d.scott at auckland.ac.nz (David Scott)
Date: Sun, 19 Sep 2010 01:22:04 +1200
Subject: [Rd] How to connect R to Mysql?
In-Reply-To: <4C939B91.9020004@structuremonitoring.com>
References: <AANLkTi=ca5M_jbzexYE8KXQ0nKCz1xbui4uXgoGBK1N3@mail.gmail.com>	<4C938E2E.6020000@structuremonitoring.com>	<4C9396B6.7000007@gmx.de>
	<4C939B91.9020004@structuremonitoring.com>
Message-ID: <4C94BCFC.3060306@auckland.ac.nz>

On 18/09/2010 4:47 a.m., Spencer Graves wrote:
>    Hi, Thomas:
>
>
>         You use RODBC to connect to MySQL?
>
>
>         Thanks, Spencer
>
>

I also use RODBC to connect to MySQL. That is in part because it is 
useful for other connections as well. I am using it for connecting to 
Microsoft SQL Server in a current project, and it is one of two 
approaches I commonly use to read Excel files (along with xlsReadWrite).

While I am at it, I would like to say thanks to Brian Ripley for his 
work on RODBC.

David Scott




> On 9/17/2010 9:26 AM, Thomas Etheber wrote:
>> I also had problems connecting via RMysql on Windows several weeks ago.
>> I decided to skip the package and now use RODBC, which runs stable out
>> of the box. Perhaps you should have a look at this package.
>>
>> Hth
>> Thomas
>>
>> Am 17.09.2010 17:50, schrieb Spencer Graves:
>>>
>>>
>>>        I've recently been through that with some success.  I don't
>>> remember all the details, but I first looked at "help(pac=RMySQL)".
>>> This told me that the maintainer was Jeffrey Horner.  Google told me
>>> he was at Vanderbilt.  Eventually I found
>>> "http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL", which told me
>>> that I needed to build the package myself so it matches your version
>>> of MySQL, operating system, etc.  I did that.
>>>
>>>
>>>        Does the MySQL database already exist?  I created a MySQL
>>> database and tables using MySQL server 5.1.50-win32.  (Which version
>>> of MySQL do you have?)
>>>
>>>
>>>        help('RMySQL-package') includes "A typical usage".  That helped
>>> me get started, except that I needed to write to that database, not
>>> just query it.  For this, I think I got something like the following
>>> to work:
>>>
>>>
>>> d<- dbReadTable(con, "WL")
>>> dbWriteTable(con, "WL2", a.data.frame)  ## table from a data.frame
>>> dbWriteTable(con, "test2", "~/data/test2.csv") ## table from a file
>>>
>>>
>>>        Hope this helps.
>>>        Spencer
>>>
>>>
>>> On 9/17/2010 7:55 AM, Arijeet Mukherjee wrote:
>>>> I installed the RMySql package in R 2.11.1 64 bit
>>>> Now how can I connect R with MySql?
>>>> I am using a windows 7 64 bit version.
>>>> Please help ASAP.
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From xie at yihui.name  Sun Sep 19 00:17:26 2010
From: xie at yihui.name (Yihui Xie)
Date: Sat, 18 Sep 2010 17:17:26 -0500
Subject: [Rd] Check for updates under Windows (Was: a reliable way to check
 the latest version of R on CRAN?)
Message-ID: <AANLkTimv0p+MARUQ7D94aadWCT0=BYyWtBk6kxQHKTvH@mail.gmail.com>

Dear R developers,

I asked this question in r-help list but have not got a definite
solution yet, and I think it might be more appropriate to ask
developers or CRAN maintainers directly. Many software packages often
have a menu item like "Check for updates" under the "Help" menu, e.g.
Filezilla and Firefox, and I believe it is also necessary for R (at
least for R GUI under Windows). Note all users really have to update
R, but we should make it clearer to them that new versions are
available. Yes, they can go to R homepage to check by themselves, but
my experience tells me it is rarely the case. Therefore, I wish RGui
could gain a new menu to check for updates of R. Thanks very much!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA




---------- Forwarded message ----------
From: Yihui Xie <xie at yihui.name>
Date: Thu, Sep 16, 2010 at 11:29 AM
Subject: a reliable way to check the latest version of R on CRAN?
To: R Help <r-help at r-project.org>


Hi all,

We know old.packages() can check for updates of add-on packages, but
is there a way to check updates of R itself? "go to R homepage" is a
way, of course, but I hope this can be done by R.

I'm not sure about the "reliable" place to check; here is a simple
example to check from one of the CRAN webpages (kind of nasty
approach...):

x = readLines("http://cran.r-project.org/sources.html")
# the version number is in the next line of 'The latest release'
rls = x[grep("latest release", x) + 1L]
newver = gsub("(.*R-|\\.tar\\.gz.*)", "", rls)
oldver = paste(getRversion(), collapse = ".")
# new version available?
compareVersion(newver, oldver) == 1L

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From spinuvit.list at gmail.com  Tue Sep 21 12:55:53 2010
From: spinuvit.list at gmail.com (Vitaly S.)
Date: Tue, 21 Sep 2010 12:55:53 +0200
Subject: [Rd] lapply version with [ subseting  - a suggestion
Message-ID: <87k4mf4b7q.fsf@gmail.com>


Dear R developers,

Reviewing my code, I have realized that about 80% of the time in the lapply I
need to access the names of the objects inside the loop.

In such cases I iterate over indexes or names:
lapply(names(x), ... [i]), 
lapply(seq_along(x),  ... x[[i]] ... names(x)[i] ), or
for(i in seq_along(x)) ...

which is rather inconvenient.

How about an argument to lapply which would specify the [ or [[ subseting to use
in the splitting of the vector?
Or may be a different set of functions lapply1,
sapply1?

I believe this pattern is rather common for other users as well.

Thanks.
VS.


From b.rowlingson at lancaster.ac.uk  Tue Sep 21 13:54:18 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 21 Sep 2010 12:54:18 +0100
Subject: [Rd] Check for updates under Windows (Was: a reliable way to
 check the latest version of R on CRAN?)
In-Reply-To: <AANLkTimv0p+MARUQ7D94aadWCT0=BYyWtBk6kxQHKTvH@mail.gmail.com>
References: <AANLkTimv0p+MARUQ7D94aadWCT0=BYyWtBk6kxQHKTvH@mail.gmail.com>
Message-ID: <AANLkTi=dudzSAO4M7HkZkaQA1nbxW=7yt5WuJC7-FW_Q@mail.gmail.com>

On Sat, Sep 18, 2010 at 11:17 PM, Yihui Xie <xie at yihui.name> wrote:
> Dear R developers,
>
> I asked this question in r-help list but have not got a definite
> solution yet, and I think it might be more appropriate to ask
> developers or CRAN maintainers directly. Many software packages often
> have a menu item like "Check for updates" under the "Help" menu, e.g.
> Filezilla and Firefox, and I believe it is also necessary for R (at
> least for R GUI under Windows). Note all users really have to update
> R, but we should make it clearer to them that new versions are
> available. Yes, they can go to R homepage to check by themselves, but
> my experience tells me it is rarely the case. Therefore, I wish RGui
> could gain a new menu to check for updates of R. Thanks very much!

Something like this:

 winMenuAdd("Updates"); winMenuAddItem("Updates","R
Version","require(gtools);checkRVersion()")

Barry


From lawrence.michael at gene.com  Tue Sep 21 15:42:29 2010
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 21 Sep 2010 06:42:29 -0700
Subject: [Rd] lapply version with [ subseting - a suggestion
In-Reply-To: <87k4mf4b7q.fsf@gmail.com>
References: <87k4mf4b7q.fsf@gmail.com>
Message-ID: <AANLkTi=a1mH=ZiohpOJcqvTuhGP9RKte_SH-nJnKxdSy@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100921/1eff12ee/attachment.pl>

From wwwhsd at gmail.com  Tue Sep 21 15:47:22 2010
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Tue, 21 Sep 2010 10:47:22 -0300
Subject: [Rd] lapply version with [ subseting - a suggestion
In-Reply-To: <87k4mf4b7q.fsf@gmail.com>
References: <87k4mf4b7q.fsf@gmail.com>
Message-ID: <AANLkTi=gVBNZ56zWanLVpjAPSVOjWXNHzXA06Akrzz_4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100921/10af4ffd/attachment.pl>

From karl.forner at gmail.com  Tue Sep 21 16:38:28 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 21 Sep 2010 16:38:28 +0200
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>
Message-ID: <AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100921/67b57746/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 21 17:33:12 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Sep 2010 11:33:12 -0400
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>
	<AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>
Message-ID: <4C98D038.8040507@gmail.com>

  On 21/09/2010 10:38 AM, Karl Forner wrote:
> Hello,
>
> I got no reply on this issue.
> It is not critical and I could think of work-around, but it really looks
> like a bug to me.
> Should I file a bug-report instead of posting in this list ?

I'd probably post instructions for a reproducible example first.  Pick 
some CRAN package, tell us what to do with it to trigger the error, and 
then we can see if it's something special about your package or Roxygen 
or a general problem.

Duncan Murdoch

> Thanks,
>
> Karl
>
> On Thu, Sep 16, 2010 at 6:11 PM, Karl Forner<karl.forner at gmail.com>  wrote:
>
> >  Hello,
> >
> >  I have a package with a namespace. Because I use Roxygen that overwrites
> >  the NAMESPACE file each time it is run, I use a R/zzz.R file with
> >  an .onLoad() and .onUnload() functions to take care of loading and
> >  unloading my shared library.
> >
> >  The problem: if I load my library from a local directory, then the
> >  unloading of the package fails, e.g:
> >
> >  # loads fine
> >  >library(Foo, lib.loc=".Rcheck")
> >
> >  >unloadNamespace("Foo")
> >  Warning message:
> >  .onUnload failed in unloadNamespace() for 'Foo', details:
> >    call: library.dynam.unload("Foo", libpath)
> >    error: shared library 'Foo' was not loaded
> >
> >  # I traced it a little:
> >  >library.dynam.unload("Foo", ".Rcheck/Foo")
> >  Error in library.dynam.unload("Foo", ".Rcheck/Foo") :
> >    shared library 'Foo' was not loaded
> >
> >  # using an absolute path works
> >  >library.dynam.unload("Foo", "/home/toto/.Rcheck/Foo")
> >
> >
> >  So from what I understand, the problem is either that the relative libpath
> >  is sent to the .onUnload() function instead of the absolute one,
> >  or that library.dynam.unload() should be modified to handle the relative
> >  paths.
> >
> >  Am I missing something ? What should I do ?
> >
> >  Thanks,
> >
> >
> >  Karl
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From spinuvit.list at gmail.com  Tue Sep 21 17:41:03 2010
From: spinuvit.list at gmail.com (Vitalie Spinu)
Date: Tue, 21 Sep 2010 17:41:03 +0200
Subject: [Rd] lapply version with [ subseting - a suggestion
In-Reply-To: <AANLkTi=a1mH=ZiohpOJcqvTuhGP9RKte_SH-nJnKxdSy@mail.gmail.com>
References: <87k4mf4b7q.fsf@gmail.com>
	<AANLkTi=a1mH=ZiohpOJcqvTuhGP9RKte_SH-nJnKxdSy@mail.gmail.com>
Message-ID: <AANLkTi=g5U2k-2Wjde7ha8+JTAXPGdFFnETY=7DV2PKP@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100921/3f6f488d/attachment.pl>

From xie at yihui.name  Tue Sep 21 18:49:50 2010
From: xie at yihui.name (Yihui Xie)
Date: Tue, 21 Sep 2010 11:49:50 -0500
Subject: [Rd] Check for updates under Windows (Was: a reliable way to
 check the latest version of R on CRAN?)
In-Reply-To: <AANLkTi=dudzSAO4M7HkZkaQA1nbxW=7yt5WuJC7-FW_Q@mail.gmail.com>
References: <AANLkTimv0p+MARUQ7D94aadWCT0=BYyWtBk6kxQHKTvH@mail.gmail.com>
	<AANLkTi=dudzSAO4M7HkZkaQA1nbxW=7yt5WuJC7-FW_Q@mail.gmail.com>
Message-ID: <AANLkTinyoeQ2+K1QYAF2PimU2+wvTr+Wiwtvse1xGFQc@mail.gmail.com>

Yes, that's more or less what I mean. Thanks!

Maybe this functionality can be added to src/gnuwin32/rui.c

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Tue, Sep 21, 2010 at 6:54 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Sat, Sep 18, 2010 at 11:17 PM, Yihui Xie <xie at yihui.name> wrote:
>> Dear R developers,
>>
>> I asked this question in r-help list but have not got a definite
>> solution yet, and I think it might be more appropriate to ask
>> developers or CRAN maintainers directly. Many software packages often
>> have a menu item like "Check for updates" under the "Help" menu, e.g.
>> Filezilla and Firefox, and I believe it is also necessary for R (at
>> least for R GUI under Windows). Note all users really have to update
>> R, but we should make it clearer to them that new versions are
>> available. Yes, they can go to R homepage to check by themselves, but
>> my experience tells me it is rarely the case. Therefore, I wish RGui
>> could gain a new menu to check for updates of R. Thanks very much!
>
> Something like this:
>
> ?winMenuAdd("Updates"); winMenuAddItem("Updates","R
> Version","require(gtools);checkRVersion()")
>
> Barry
>


From radford at cs.toronto.edu  Tue Sep 21 21:48:38 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Tue, 21 Sep 2010 15:48:38 -0400
Subject: [Rd] Speeding up squaring of vectors
Message-ID: <20100921194838.GA15271@cs.toronto.edu>

I see that some of the speed patches that I posted have been
incorporated into the current development version (eg, my patch-for,
patch-evalList, and patch-vec-arith).

My patch for speeding up x^2 has been addressed in an inadvisable way,
however.  This was a simple addition of four lines of code that speeds
up squaring of real vectors by a factor of about six (for vectors of
length 10000), by just converting x^2 to x*x.  Modifications in the
current development version (r52936 and r52937) attempt to address
this issue in a different way, but they produce a smaller speedup. My
modification is about 2.6 faster than the current development version
(on an Intel/Linux system).  Similarly, in the current development
version, x*x is still about 2.6 times faster than x^2.  Furthermore,
the modification in the current development version slows down
exponentiation by 0.5 (square roots) by about 4%.

I think there's no reason not to just use my patch.  One could also
put in a similar modification to speed up squaring of integer vectors,
but I think that is a much less common operation than squaring of real
vectors, which arises all the time when computing squared residuals,
squared Euclidean distances, etc.


From r.ted.byers at gmail.com  Tue Sep 21 22:11:15 2010
From: r.ted.byers at gmail.com (Ted Byers)
Date: Tue, 21 Sep 2010 16:11:15 -0400
Subject: [Rd] trouble compiling RMySQL (and others) for 64 bit windows.
Message-ID: <AANLkTinDSqVgdtt2qJ634_2QTOADQbbxiiXC-qoFrFj_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100921/358a003b/attachment.pl>

From hb at stat.berkeley.edu  Wed Sep 22 05:04:47 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 21 Sep 2010 20:04:47 -0700
Subject: [Rd] Crash report: regexpr("a{2-}", "")
Message-ID: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>

Each of the following calls crash ("core dumps") R (R --vanilla) on
various versions and OSes:

regexpr("a{2-}", "")
sub("a{2-}", "")
gsub("a{2-}", "")


EXAMPLES:

> sessionInfo()
R version 2.11.1 Patched (2010-09-16 r52949)
Platform: i386-pc-mingw32 (32-bit)
...
> regexpr("a{2-}", "")
Assertion failed: iter->max == -1 || iter->max == 1, file
tre-compile.c, line 1825
This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.

> sessionInfo()
R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
Platform: i386-pc-mingw32/i386 (32-bit)
...
> regexpr("a{2-}", "")
Assertion failed: iter->max == -1 || iter->max == 1, file
tre-compile.c, line 1825
This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.


> sessionInfo()
R version 2.11.0 Patched (2010-05-09 r51960)
x86_64-unknown-linux-gnu
...
> regexpr("a{2-}", "")
R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
iter->max == 1' failed.
Aborted


/Henrik


From dwinsemius at comcast.net  Wed Sep 22 05:43:58 2010
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Sep 2010 23:43:58 -0400
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
Message-ID: <B5067C6B-B806-4632-A58B-9F293CD52D3F@comcast.net>


On Sep 21, 2010, at 11:04 PM, Henrik Bengtsson wrote:

> Each of the following calls crash ("core dumps") R (R --vanilla) on
> various versions and OSes:
>
> regexpr("a{2-}", "")
> sub("a{2-}", "")
> gsub("a{2-}", "")
>
>
> EXAMPLES:
>
>> sessionInfo()
> R version 2.11.1 Patched (2010-09-16 r52949)
> Platform: i386-pc-mingw32 (32-bit)
> ...
>> regexpr("a{2-}", "")
> Assertion failed: iter->max == -1 || iter->max == 1, file
> tre-compile.c, line 1825
> This application has requested the Runtime to terminate it in an  
> unusual way.
> Please contact the application's support team for more information.
>
>> sessionInfo()
> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
> Platform: i386-pc-mingw32/i386 (32-bit)
> ...
>> regexpr("a{2-}", "")
> Assertion failed: iter->max == -1 || iter->max == 1, file
> tre-compile.c, line 1825
> This application has requested the Runtime to terminate it in an  
> unusual way.
> Please contact the application's support team for more information.
>
>
>> sessionInfo()
> R version 2.11.0 Patched (2010-05-09 r51960)
> x86_64-unknown-linux-gnu
> ...
>> regexpr("a{2-}", "")
> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
> iter->max == 1' failed.
> Aborted

Not a problem in reasonably current Mac with 64bit GUI:
 > regexpr("a{2-}", "")
[1] 1
attr(,"match.length")
[1] 0
 > sub("a{2-}", "")
Error in is.character(x) : 'x' is missing
 > gsub("a{2-}", "")
Error in is.character(x) : 'x' is missing

R version 2.11.1 Patched (2010-08-26 r52822)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
[R.app GUI 1.35 (5612) x86_64-apple-darwin9.8.0]

-- 
David.
>
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at stat.berkeley.edu  Wed Sep 22 06:12:19 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 21 Sep 2010 21:12:19 -0700
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <B5067C6B-B806-4632-A58B-9F293CD52D3F@comcast.net>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
	<B5067C6B-B806-4632-A58B-9F293CD52D3F@comcast.net>
Message-ID: <AANLkTik=5K-2yiOrgx7bUp-vta2vx4pEg7b=BdpK2D6U@mail.gmail.com>

David's post made me realize that I got the sub()/gsub() lines wrong.
It should be:

regexpr("a{2-}", "")
sub("a{2-}", "", "")
gsub("a{2-}", "", "")

Either way, the crash is there, at on least Windows and Linux.

/Henrik

On Tue, Sep 21, 2010 at 8:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Sep 21, 2010, at 11:04 PM, Henrik Bengtsson wrote:
>
>> Each of the following calls crash ("core dumps") R (R --vanilla) on
>> various versions and OSes:
>>
>> regexpr("a{2-}", "")
>> sub("a{2-}", "")
>> gsub("a{2-}", "")
>>
>>
>> EXAMPLES:
>>
>>> sessionInfo()
>>
>> R version 2.11.1 Patched (2010-09-16 r52949)
>> Platform: i386-pc-mingw32 (32-bit)
>> ...
>>>
>>> regexpr("a{2-}", "")
>>
>> Assertion failed: iter->max == -1 || iter->max == 1, file
>> tre-compile.c, line 1825
>> This application has requested the Runtime to terminate it in an unusual
>> way.
>> Please contact the application's support team for more information.
>>
>>> sessionInfo()
>>
>> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>> ...
>>>
>>> regexpr("a{2-}", "")
>>
>> Assertion failed: iter->max == -1 || iter->max == 1, file
>> tre-compile.c, line 1825
>> This application has requested the Runtime to terminate it in an unusual
>> way.
>> Please contact the application's support team for more information.
>>
>>
>>> sessionInfo()
>>
>> R version 2.11.0 Patched (2010-05-09 r51960)
>> x86_64-unknown-linux-gnu
>> ...
>>>
>>> regexpr("a{2-}", "")
>>
>> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
>> iter->max == 1' failed.
>> Aborted
>
> Not a problem in reasonably current Mac with 64bit GUI:
>> regexpr("a{2-}", "")
> [1] 1
> attr(,"match.length")
> [1] 0
>> sub("a{2-}", "")
> Error in is.character(x) : 'x' is missing
>> gsub("a{2-}", "")
> Error in is.character(x) : 'x' is missing
>
> R version 2.11.1 Patched (2010-08-26 r52822)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> [R.app GUI 1.35 (5612) x86_64-apple-darwin9.8.0]
>
> --
> David.
>>
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dwinsemius at comcast.net  Wed Sep 22 06:20:23 2010
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 22 Sep 2010 00:20:23 -0400
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <AANLkTik=5K-2yiOrgx7bUp-vta2vx4pEg7b=BdpK2D6U@mail.gmail.com>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
	<B5067C6B-B806-4632-A58B-9F293CD52D3F@comcast.net>
	<AANLkTik=5K-2yiOrgx7bUp-vta2vx4pEg7b=BdpK2D6U@mail.gmail.com>
Message-ID: <DB03C938-7BA3-4464-BF2C-506E33C9549B@comcast.net>


On Sep 22, 2010, at 12:12 AM, Henrik Bengtsson wrote:

> David's post made me realize that I got the sub()/gsub() lines wrong.
> It should be:
>
> regexpr("a{2-}", "")
> sub("a{2-}", "", "")
> gsub("a{2-}", "", "")
>

Still no crash on a Mac. Did you mean to include a third argument to  
regexpr() as you did for sub and gsub?

-- 
David.
> Either way, the crash is there, at on least Windows and Linux.
>
> /Henrik
>
> On Tue, Sep 21, 2010 at 8:43 PM, David Winsemius <dwinsemius at comcast.net 
> > wrote:
>>
>> On Sep 21, 2010, at 11:04 PM, Henrik Bengtsson wrote:
>>
>>> Each of the following calls crash ("core dumps") R (R --vanilla) on
>>> various versions and OSes:
>>>
>>> regexpr("a{2-}", "")
>>> sub("a{2-}", "")
>>> gsub("a{2-}", "")
>>>
>>>
>>> EXAMPLES:
>>>
>>>> sessionInfo()
>>>
>>> R version 2.11.1 Patched (2010-09-16 r52949)
>>> Platform: i386-pc-mingw32 (32-bit)
>>> ...
>>>>
>>>> regexpr("a{2-}", "")
>>>
>>> Assertion failed: iter->max == -1 || iter->max == 1, file
>>> tre-compile.c, line 1825
>>> This application has requested the Runtime to terminate it in an  
>>> unusual
>>> way.
>>> Please contact the application's support team for more information.
>>>
>>>> sessionInfo()
>>>
>>> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>> ...
>>>>
>>>> regexpr("a{2-}", "")
>>>
>>> Assertion failed: iter->max == -1 || iter->max == 1, file
>>> tre-compile.c, line 1825
>>> This application has requested the Runtime to terminate it in an  
>>> unusual
>>> way.
>>> Please contact the application's support team for more information.
>>>
>>>
>>>> sessionInfo()
>>>
>>> R version 2.11.0 Patched (2010-05-09 r51960)
>>> x86_64-unknown-linux-gnu
>>> ...
>>>>
>>>> regexpr("a{2-}", "")
>>>
>>> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1  
>>> ||
>>> iter->max == 1' failed.
>>> Aborted
>>
>> Not a problem in reasonably current Mac with 64bit GUI:
>>> regexpr("a{2-}", "")
>> [1] 1
>> attr(,"match.length")
>> [1] 0
>>> sub("a{2-}", "")
>> Error in is.character(x) : 'x' is missing
>>> gsub("a{2-}", "")
>> Error in is.character(x) : 'x' is missing
>>
>> R version 2.11.1 Patched (2010-08-26 r52822)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> [R.app GUI 1.35 (5612) x86_64-apple-darwin9.8.0]
>>
>> --
>> David.
>>>
>>>
>>> /Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From hb at stat.berkeley.edu  Wed Sep 22 06:52:07 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 21 Sep 2010 21:52:07 -0700
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <DB03C938-7BA3-4464-BF2C-506E33C9549B@comcast.net>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
	<B5067C6B-B806-4632-A58B-9F293CD52D3F@comcast.net>
	<AANLkTik=5K-2yiOrgx7bUp-vta2vx4pEg7b=BdpK2D6U@mail.gmail.com>
	<DB03C938-7BA3-4464-BF2C-506E33C9549B@comcast.net>
Message-ID: <AANLkTik8Bybanwap-8iTcozwNdUr2VDZHizCA6XdRfB+@mail.gmail.com>

On Tue, Sep 21, 2010 at 9:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Sep 22, 2010, at 12:12 AM, Henrik Bengtsson wrote:
>
>> David's post made me realize that I got the sub()/gsub() lines wrong.
>> It should be:
>>
>> regexpr("a{2-}", "")
>> sub("a{2-}", "", "")
>> gsub("a{2-}", "", "")
>>
>
> Still no crash on a Mac. Did you mean to include a third argument to
> regexpr() as you did for sub and gsub?

No, it was only that sub()/gsub() needs at least three arguments while
regexpr() only needs two, and did a simple cut'n'paste when I wrote
the original message.  All three commands probably use the same
underlying regular expression library, so it is likely it is same bug.

It looks like at least on your OS/R version it does not crash.

/Henrik

>
> --
> David.
>>
>> Either way, the crash is there, at on least Windows and Linux.
>>
>> /Henrik
>>
>> On Tue, Sep 21, 2010 at 8:43 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>>
>>> On Sep 21, 2010, at 11:04 PM, Henrik Bengtsson wrote:
>>>
>>>> Each of the following calls crash ("core dumps") R (R --vanilla) on
>>>> various versions and OSes:
>>>>
>>>> regexpr("a{2-}", "")
>>>> sub("a{2-}", "")
>>>> gsub("a{2-}", "")
>>>>
>>>>
>>>> EXAMPLES:
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.11.1 Patched (2010-09-16 r52949)
>>>> Platform: i386-pc-mingw32 (32-bit)
>>>> ...
>>>>>
>>>>> regexpr("a{2-}", "")
>>>>
>>>> Assertion failed: iter->max == -1 || iter->max == 1, file
>>>> tre-compile.c, line 1825
>>>> This application has requested the Runtime to terminate it in an unusual
>>>> way.
>>>> Please contact the application's support team for more information.
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>> ...
>>>>>
>>>>> regexpr("a{2-}", "")
>>>>
>>>> Assertion failed: iter->max == -1 || iter->max == 1, file
>>>> tre-compile.c, line 1825
>>>> This application has requested the Runtime to terminate it in an unusual
>>>> way.
>>>> Please contact the application's support team for more information.
>>>>
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.11.0 Patched (2010-05-09 r51960)
>>>> x86_64-unknown-linux-gnu
>>>> ...
>>>>>
>>>>> regexpr("a{2-}", "")
>>>>
>>>> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
>>>> iter->max == 1' failed.
>>>> Aborted
>>>
>>> Not a problem in reasonably current Mac with 64bit GUI:
>>>>
>>>> regexpr("a{2-}", "")
>>>
>>> [1] 1
>>> attr(,"match.length")
>>> [1] 0
>>>>
>>>> sub("a{2-}", "")
>>>
>>> Error in is.character(x) : 'x' is missing
>>>>
>>>> gsub("a{2-}", "")
>>>
>>> Error in is.character(x) : 'x' is missing
>>>
>>> R version 2.11.1 Patched (2010-08-26 r52822)
>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>> [R.app GUI 1.35 (5612) x86_64-apple-darwin9.8.0]
>>>
>>> --
>>> David.
>>>>
>>>>
>>>> /Henrik
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>
>


From Bill.Venables at csiro.au  Wed Sep 22 07:29:41 2010
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Wed, 22 Sep 2010 15:29:41 +1000
Subject: [Rd] On the median
In-Reply-To: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
Message-ID: <1BDAE2969943D540934EE8B4EF68F95FB27A44F408@EXNSW-MBX03.nexus.csiro.au>

I have recently become aware of some curious behaviour of median() which I think could be usefully corrected.  I am sure this must have come up before, but I'm raising it again.

The phenomenon is best shown by a simple example.

> d <- matrix(runif(4*4), 4, 4)
> d
          [,1]       [,2]       [,3]      [,4]
[1,] 0.1388592 0.08478220 0.02012404 0.7733054
[2,] 0.1718332 0.06370432 0.66167219 0.2521809
[3,] 0.3190116 0.08616569 0.23107320 0.6278422
[4,] 0.9185233 0.29218144 0.99193823 0.6306847
> apply(d, 1, median)
[1] 0.1118207 0.2120070 0.2750424 0.7746040

So far, so good. But what happens when you turn it into a data frame?

> d <- data.frame(d)
> apply(d, 1, median)
[1] 0.1118207 0.2120070 0.2750424 0.7746040

No problem there, yet.  But if you just look at one row:

> median(d[1, ])
[1] 0.0847822 0.1388592

without warning you get a vector of size two as the result, viz the two values which enclose the middle.  I thought this was simply because one row of a data frame is a list, but that can't be the whole story.  e.g.

> median(d[,1])
[1] 0.2454224
> median(as.list(d[,1]))
Error in sort.list(x, partial = half + 0L:1L) : 
  'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?
> 

(Well yes, Brian, I did...)  

The function mean() has a nice property when you call it on a data frame, e.g.

> mean(d)
       X1        X2        X3        X4 
0.3870568 0.1317084 0.4762019 0.5710033 

and just to complicate the issue even further, 

> mean(d[1, ])
        X1         X2         X3         X4 
0.13885916 0.08478220 0.02012404 0.77330535 

On the other hand, median(), whose behaviour should be similar I would suggest, just fails when handed a data frame argument.

> median(d)
[1] NA NA
Warning messages:
1: In mean.default(X[[1L]], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(X[[2L]], ...) :
  argument is not numeric or logical: returning NA
> 
_________________

I suggest that there should be some consistency here, and I suggest that median() be given a data.frame method that would allow it to respond much the same as mean() does.  The way it responds to data frame arguments now is quirky, at best.

Currently median() though generic, has only the default method.

> methods("mean")
[1] mean.data.frame mean.Date       mean.default    mean.difftime   mean.POSIXct   
[6] mean.POSIXlt   

> methods("median")
[1] median.default
> 

Perhaps quantile() should also have a data.frame method for the same reason.  To me it seems curious, too, that quantile has a POSIXt method (in the stats package) whereas median currently does not.  (mean.POSIX*t are in the base package.)

> methods("quantile")
[1] quantile.default quantile.POSIXt*

   Non-visible functions are asterisked
> 

How do people respond to this?

(I see there have been hints of this in the past, see http://tolstoy.newcastle.edu.au/R/e2/help/06/12/7692.html
but I could only find hints.)

Bill Venables
CSIRO/CMIS, Cleveland Labs.
 

From hb at stat.berkeley.edu  Wed Sep 22 08:26:31 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 21 Sep 2010 23:26:31 -0700
Subject: [Rd] OT: Reason/history behind ## notation for comments?
Message-ID: <AANLkTimRgeGVxira9GzJoBfPSyWKYxBcbD1TALXzFYd9@mail.gmail.com>

Off topic, but since I've observe both styles, does anyone know the
history behind/reason for using ## instead of a single # to start
comments in R.  I know some editors do this by default.  Is it because
in C it is easier to distinguish (search/replace/...) comments from C
preprocessor directives such as #include, and that's became a de facto
standard elsewhere?

/Henrik

PS. I don't want to get into a debate on what's the best style.


From laurent.gatto at gmail.com  Wed Sep 22 09:33:20 2010
From: laurent.gatto at gmail.com (Laurent Gatto)
Date: Wed, 22 Sep 2010 08:33:20 +0100
Subject: [Rd] OT: Reason/history behind ## notation for comments?
In-Reply-To: <AANLkTimRgeGVxira9GzJoBfPSyWKYxBcbD1TALXzFYd9@mail.gmail.com>
References: <AANLkTimRgeGVxira9GzJoBfPSyWKYxBcbD1TALXzFYd9@mail.gmail.com>
Message-ID: <AANLkTime_rZcJNCttC01nZbJRfgs-n0rXy_PnuDgcapw@mail.gmail.com>

For what concerns emacs users, the number of '#' has different effects
on the position of the comment. From the ESS manual: 'By default,
comments beginning with ?###? are aligned to the beginning of the
line. Comments beginning with ?##? are aligned to the current level of
indentation for the block containing the comment. Finally, comments
beginning with ?#? are aligned to a column on the right...'. I guess
that ## is the most wanted indentation for comments.

Best wishes,

Laurent

On 22 September 2010 07:26, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Off topic, but since I've observe both styles, does anyone know the
> history behind/reason for using ## instead of a single # to start
> comments in R. ?I know some editors do this by default. ?Is it because
> in C it is easier to distinguish (search/replace/...) comments from C
> preprocessor directives such as #include, and that's became a de facto
> standard elsewhere?
>
> /Henrik
>
> PS. I don't want to get into a debate on what's the best style.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wht_crl at yahoo.com  Wed Sep 22 10:41:00 2010
From: wht_crl at yahoo.com (carol white)
Date: Wed, 22 Sep 2010 01:41:00 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <4C94B40F.6040708@statistik.tu-dortmund.de>
Message-ID: <999809.52421.qm@web62001.mail.re1.yahoo.com>

Thank you very much Uwe. It works now.

I have a question about pdf formating in pdf manual file: 

How to format the long lines which go to the margin? For ex, this happens in Usage field if a function has many arguments. Also, it happens in examples or Arugment sections when the lines are long.

Best,

Carol


From ripley at stats.ox.ac.uk  Wed Sep 22 11:15:57 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Sep 2010 10:15:57 +0100 (BST)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <999809.52421.qm@web62001.mail.re1.yahoo.com>
References: <999809.52421.qm@web62001.mail.re1.yahoo.com>
Message-ID: <alpine.LFD.2.00.1009221010520.8757@gannet.stats.ox.ac.uk>

On Wed, 22 Sep 2010, carol white wrote:

> Thank you very much Uwe. It works now.
>
> I have a question about pdf formating in pdf manual file:
>
> How to format the long lines which go to the margin? For ex, this 
> happens in Usage field if a function has many arguments. Also, it 
> happens in examples or Arugment sections when the lines are long.

Correct the sources by re-formatting over-long lines yourself.  (This 
should only happen in verbatim-like sections, hence unlikely to happen 
in \argument{}.)

One of the things we suggest when checking a package is to read 
through the PDF manual, and this is one of the problems to look out 
for.  (Note that it does depend on the fonts used for the PDF, but the 
default Courier for monospaced text is somewhat wide.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Sep 22 11:41:12 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Sep 2010 10:41:12 +0100 (BST)
Subject: [Rd] doc bug in ?residuals.gls
In-Reply-To: <4C8FA5F6.4070304@gmail.com>
References: <4C8FA5F6.4070304@gmail.com>
Message-ID: <alpine.LFD.2.00.1009221018520.27764@gannet.stats.ox.ac.uk>

On Tue, 14 Sep 2010, Ben Bolker wrote:

>
> Under the description of the 'type' argument, ?residuals.gls says
> 'Defaults to ?"pearson"?.'
>
> But residuals.gls starts
>
> residuals.gls <-
> function(object, type = c("response", "pearson", "normalized"), ...)
> {
> type <- match.arg(type)
>
> ...
>
> which sure looks to me like it defaults to "response", not "pearson"
> (and it behaves that way in tests).
>
> It would seem to make more sense to change the documentation rather than
> the code
> since anyone who looked at the docs would have been confused already,
> whereas someone who had
> been happily using the code without looking at the docs would see a
> sudden change in the results ...
>
> This is in nlme 3.1-96, from a fresh tools/rsync-recommended. Sending it
> to r-devel for comment because r-core is listed as the maintainer.

Whereas bug reports should be sent to the maintainer or (for packages 
maintained by R-core) R-bugs.  The SVN version of nlme has
BugReports: http://bugs.r-project.org
since reports here are easily overlooked.

I've changed the SVN sources, but most likely a new release of nlme 
will be made only when something substantive is changed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wht_crl at yahoo.com  Wed Sep 22 13:48:02 2010
From: wht_crl at yahoo.com (carol white)
Date: Wed, 22 Sep 2010 04:48:02 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <alpine.LFD.2.00.1009221010520.8757@gannet.stats.ox.ac.uk>
Message-ID: <307070.79133.qm@web62007.mail.re1.yahoo.com>

So there is no sort of automatic way like using a markup command for the susceptible fields instead of splitting manually a line on different lines? 

True that this doesn't happen in Arguments field (I confused with Format field). 

Also true that the codes used in Usage, Examples etc are in courrier. Is there any way to reduce the size and not to change the font of character for these fields? 

Best,

Carol

--- On Wed, 9/22/10, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [Rd] some problems reported in 00check.log
> To: "carol white" <wht_crl at yahoo.com>
> Cc: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>, r-devel at r-project.org
> Date: Wednesday, September 22, 2010, 2:15 AM
> On Wed, 22 Sep 2010, carol white
> wrote:
> 
> > Thank you very much Uwe. It works now.
> > 
> > I have a question about pdf formating in pdf manual
> file:
> > 
> > How to format the long lines which go to the margin?
> For ex, this happens in Usage field if a function has many
> arguments. Also, it happens in examples or Arugment sections
> when the lines are long.
> 
> Correct the sources by re-formatting over-long lines
> yourself.? (This should only happen in verbatim-like
> sections, hence unlikely to happen in \argument{}.)
> 
> One of the things we suggest when checking a package is to
> read through the PDF manual, and this is one of the problems
> to look out for.? (Note that it does depend on the
> fonts used for the PDF, but the default Courier for
> monospaced text is somewhat wide.)
> 
> -- Brian D. Ripley,? ? ? ? ?
> ? ? ? ? ripley at stats.ox.ac.uk
> Professor of Applied Statistics,? http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,? ? ? ? ?
> ???Tel:? +44 1865 272861 (self)
> 1 South Parks Road,? ? ? ? ?
> ? ? ? ? ???+44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK? ? ? ? ? ?
> ? ? Fax:? +44 1865 272595
> 


     

From ripley at stats.ox.ac.uk  Wed Sep 22 14:04:05 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Sep 2010 13:04:05 +0100 (BST)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <307070.79133.qm@web62007.mail.re1.yahoo.com>
References: <307070.79133.qm@web62007.mail.re1.yahoo.com>
Message-ID: <alpine.LFD.2.00.1009221255180.29567@gannet.stats.ox.ac.uk>

On Wed, 22 Sep 2010, carol white wrote:

> So there is no sort of automatic way like using a markup command for the susceptible fields instead of splitting manually a line on different lines?

Well, how is the automatic command to know how to do this?  As you 
will see from the autmatic wrapping in e.g. deparse(), we are not able 
to do a very good job.

There has been some talk about doing this automatically as a backstop, 
but I don't know the current state: in any case it does not happen in 
released versions of R.

> True that this doesn't happen in Arguments field (I confused with 
> Format field).
>
> Also true that the codes used in Usage, Examples etc are in 
> courrier. Is there any way to reduce the size and not to change the 
> font of character for these fields?

You can change Rd.sty, which already contains options for using 
other fontsets.

>
> Best,
>
> Carol
>
> --- On Wed, 9/22/10, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>> Subject: Re: [Rd] some problems reported in 00check.log
>> To: "carol white" <wht_crl at yahoo.com>
>> Cc: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>, r-devel at r-project.org
>> Date: Wednesday, September 22, 2010, 2:15 AM
>> On Wed, 22 Sep 2010, carol white
>> wrote:
>>
>>> Thank you very much Uwe. It works now.
>>>
>>> I have a question about pdf formating in pdf manual
>> file:
>>>
>>> How to format the long lines which go to the margin?
>> For ex, this happens in Usage field if a function has many
>> arguments. Also, it happens in examples or Arugment sections
>> when the lines are long.
>>
>> Correct the sources by re-formatting over-long lines
>> yourself.? (This should only happen in verbatim-like
>> sections, hence unlikely to happen in \argument{}.)
>>
>> One of the things we suggest when checking a package is to
>> read through the PDF manual, and this is one of the problems
>> to look out for.? (Note that it does depend on the
>> fonts used for the PDF, but the default Courier for
>> monospaced text is somewhat wide.)
>>
>> -- Brian D. Ripley,? ? ? ? ?
>> ? ? ? ? ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,? http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,? ? ? ? ?
>> ???Tel:? +44 1865 272861 (self)
>> 1 South Parks Road,? ? ? ? ?
>> ? ? ? ? ???+44 1865
>> 272866 (PA)
>> Oxford OX1 3TG, UK? ? ? ? ? ?
>> ? ? Fax:? +44 1865 272595
>>
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From karl.forner at gmail.com  Wed Sep 22 17:22:57 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Wed, 22 Sep 2010 17:22:57 +0200
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <4C98D038.8040507@gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>
	<AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>
	<4C98D038.8040507@gmail.com>
Message-ID: <AANLkTimDqM3pdFH5-Ph9kW=CafapEt7aQB_4YjTC5+9X@mail.gmail.com>

Thanks Duncan for your suggestion.

I could not find any package using dynamic library, namespaces and not the
useDynLib pragma so
I created a minimalistic package to demonstrate the problem.
Please find attached a very small package foo (8.8k)

Steps to reproduce the problem:

* unarchive it ( tar zxvf foo_0.1.tar.gz )
* cd foo
* install it locally ( mkdir local; R CMD INSTALL -l local . )
* R
> library(foo, lib.loc="local/")
>.dynLibs()
# there you should be able to see the foo.so lib, in my case
/x05/people/m160508/workspace/foo/local/foo/libs/foo.so

> unloadNamespace("foo")
.onUnload, libpath= local/fooWarning message:
.onUnload failed in unloadNamespace() for 'foo', details:
  call: library.dynam.unload("foo", libpath)
  error: shared library 'foo' was not loaded

#The libpath that the .onUnload() gets is "local/foo".

#This fails:
>library.dynam.unload("foo", "local/foo")
Error in library.dynam.unload("foo", "local/foo") :
  shared library 'foo' was not loaded

# but if you use the absolute path it works:
>library.dynam.unload("foo", "/x05/people/m160508/workspace/foo/local/foo")

Karl

On Tue, Sep 21, 2010 at 5:33 PM, Duncan Murdoch <murdoch.duncan at gmail.com>wrote:

>  On 21/09/2010 10:38 AM, Karl Forner wrote:
>
>> Hello,
>>
>> I got no reply on this issue.
>> It is not critical and I could think of work-around, but it really looks
>> like a bug to me.
>> Should I file a bug-report instead of posting in this list ?
>>
>
> I'd probably post instructions for a reproducible example first.  Pick some
> CRAN package, tell us what to do with it to trigger the error, and then we
> can see if it's something special about your package or Roxygen or a general
> problem.
>
> Duncan Murdoch
>
>  Thanks,
>>
>> Karl
>>
>> On Thu, Sep 16, 2010 at 6:11 PM, Karl Forner<karl.forner at gmail.com>
>>  wrote:
>>
>> >  Hello,
>> >
>> >  I have a package with a namespace. Because I use Roxygen that
>> overwrites
>> >  the NAMESPACE file each time it is run, I use a R/zzz.R file with
>> >  an .onLoad() and .onUnload() functions to take care of loading and
>> >  unloading my shared library.
>> >
>> >  The problem: if I load my library from a local directory, then the
>> >  unloading of the package fails, e.g:
>> >
>> >  # loads fine
>> >  >library(Foo, lib.loc=".Rcheck")
>> >
>> >  >unloadNamespace("Foo")
>> >  Warning message:
>> >  .onUnload failed in unloadNamespace() for 'Foo', details:
>> >    call: library.dynam.unload("Foo", libpath)
>> >    error: shared library 'Foo' was not loaded
>> >
>> >  # I traced it a little:
>> >  >library.dynam.unload("Foo", ".Rcheck/Foo")
>> >  Error in library.dynam.unload("Foo", ".Rcheck/Foo") :
>> >    shared library 'Foo' was not loaded
>> >
>> >  # using an absolute path works
>> >  >library.dynam.unload("Foo", "/home/toto/.Rcheck/Foo")
>> >
>> >
>> >  So from what I understand, the problem is either that the relative
>> libpath
>> >  is sent to the .onUnload() function instead of the absolute one,
>> >  or that library.dynam.unload() should be modified to handle the
>> relative
>> >  paths.
>> >
>> >  Am I missing something ? What should I do ?
>> >
>> >  Thanks,
>> >
>> >
>> >  Karl
>> >
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: foo_0.1.tar.gz
Type: application/x-gzip
Size: 9010 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100922/4787d39a/attachment.gz>

From murdoch.duncan at gmail.com  Wed Sep 22 17:31:09 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 22 Sep 2010 11:31:09 -0400
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <AANLkTimDqM3pdFH5-Ph9kW=CafapEt7aQB_4YjTC5+9X@mail.gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>	<AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>	<4C98D038.8040507@gmail.com>
	<AANLkTimDqM3pdFH5-Ph9kW=CafapEt7aQB_4YjTC5+9X@mail.gmail.com>
Message-ID: <4C9A213D.7040006@gmail.com>

  On 22/09/2010 11:22 AM, Karl Forner wrote:
> Thanks Duncan for your suggestion.
>
> I could not find any package using dynamic library, namespaces and not the
> useDynLib pragma so
> I created a minimalistic package to demonstrate the problem.
> Please find attached a very small package foo (8.8k)

Your package depends on Rcpp, so I didn't try it in the alpha version of 
2.12.0 (Rcpp isn't available there in a Windows binary at the moment), 
but I did try it in R-patched.  With one minor change to your script 
(the lib.loc needs to be "local", not "local/" on Windows), I can 
reproduce the problem, and it looks like a bug to me.  Thanks for the 
report, I'll put it on the bugs page, and hopefully it will be fixed 
before the 2.12.0 release.

Duncan Murdoch

> Steps to reproduce the problem:
>
> * unarchive it ( tar zxvf foo_0.1.tar.gz )
> * cd foo
> * install it locally ( mkdir local; R CMD INSTALL -l local . )
> * R
> >  library(foo, lib.loc="local/")
> >.dynLibs()
> # there you should be able to see the foo.so lib, in my case
> /x05/people/m160508/workspace/foo/local/foo/libs/foo.so
>
> >  unloadNamespace("foo")
> .onUnload, libpath= local/fooWarning message:
> .onUnload failed in unloadNamespace() for 'foo', details:
>    call: library.dynam.unload("foo", libpath)
>    error: shared library 'foo' was not loaded
>
> #The libpath that the .onUnload() gets is "local/foo".
>
> #This fails:
> >library.dynam.unload("foo", "local/foo")
> Error in library.dynam.unload("foo", "local/foo") :
>    shared library 'foo' was not loaded
>
> # but if you use the absolute path it works:
> >library.dynam.unload("foo", "/x05/people/m160508/workspace/foo/local/foo")
>
> Karl
>
> On Tue, Sep 21, 2010 at 5:33 PM, Duncan Murdoch<murdoch.duncan at gmail.com>wrote:
>
> >   On 21/09/2010 10:38 AM, Karl Forner wrote:
> >
> >>  Hello,
> >>
> >>  I got no reply on this issue.
> >>  It is not critical and I could think of work-around, but it really looks
> >>  like a bug to me.
> >>  Should I file a bug-report instead of posting in this list ?
> >>
> >
> >  I'd probably post instructions for a reproducible example first.  Pick some
> >  CRAN package, tell us what to do with it to trigger the error, and then we
> >  can see if it's something special about your package or Roxygen or a general
> >  problem.
> >
> >  Duncan Murdoch
> >
> >   Thanks,
> >>
> >>  Karl
> >>
> >>  On Thu, Sep 16, 2010 at 6:11 PM, Karl Forner<karl.forner at gmail.com>
> >>   wrote:
> >>
> >>  >   Hello,
> >>  >
> >>  >   I have a package with a namespace. Because I use Roxygen that
> >>  overwrites
> >>  >   the NAMESPACE file each time it is run, I use a R/zzz.R file with
> >>  >   an .onLoad() and .onUnload() functions to take care of loading and
> >>  >   unloading my shared library.
> >>  >
> >>  >   The problem: if I load my library from a local directory, then the
> >>  >   unloading of the package fails, e.g:
> >>  >
> >>  >   # loads fine
> >>  >   >library(Foo, lib.loc=".Rcheck")
> >>  >
> >>  >   >unloadNamespace("Foo")
> >>  >   Warning message:
> >>  >   .onUnload failed in unloadNamespace() for 'Foo', details:
> >>  >     call: library.dynam.unload("Foo", libpath)
> >>  >     error: shared library 'Foo' was not loaded
> >>  >
> >>  >   # I traced it a little:
> >>  >   >library.dynam.unload("Foo", ".Rcheck/Foo")
> >>  >   Error in library.dynam.unload("Foo", ".Rcheck/Foo") :
> >>  >     shared library 'Foo' was not loaded
> >>  >
> >>  >   # using an absolute path works
> >>  >   >library.dynam.unload("Foo", "/home/toto/.Rcheck/Foo")
> >>  >
> >>  >
> >>  >   So from what I understand, the problem is either that the relative
> >>  libpath
> >>  >   is sent to the .onUnload() function instead of the absolute one,
> >>  >   or that library.dynam.unload() should be modified to handle the
> >>  relative
> >>  >   paths.
> >>  >
> >>  >   Am I missing something ? What should I do ?
> >>  >
> >>  >   Thanks,
> >>  >
> >>  >
> >>  >   Karl
> >>  >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
>


From karl.forner at gmail.com  Wed Sep 22 17:34:50 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Wed, 22 Sep 2010 17:34:50 +0200
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <4C9A213D.7040006@gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>
	<AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>
	<4C98D038.8040507@gmail.com>
	<AANLkTimDqM3pdFH5-Ph9kW=CafapEt7aQB_4YjTC5+9X@mail.gmail.com>
	<4C9A213D.7040006@gmail.com>
Message-ID: <AANLkTinLxspM5HyVYGw1B_5mCgmjvh+7Mud_S8OBgj8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100922/597e0ad8/attachment.pl>

From diggsb at ohsu.edu  Wed Sep 22 18:37:39 2010
From: diggsb at ohsu.edu (Brian Diggs)
Date: Wed, 22 Sep 2010 09:37:39 -0700
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
Message-ID: <4C9A30D3.3000102@ohsu.edu>

[Accidentally posted this to r-help instead of r-devel; reposting to put 
it into the correct list and thread. My apologies for the duplication.]

On 9/21/2010 8:04 PM, Henrik Bengtsson wrote:
> Each of the following calls crash ("core dumps") R (R --vanilla) on
> various versions and OSes:
>
> regexpr("a{2-}", "")
> sub("a{2-}", "")
> gsub("a{2-}", "")
>
>
> EXAMPLES:

To add another (windows) example it also crashes the 2.12.0 alpha build:

 > sessionInfo()
R version 2.12.0 alpha (2010-09-20 r52948)
Platform: i386-pc-mingw32/i386 (32-bit)
...
 > regexpr("a{2-}", "")
Assertion failed: iter->max == -1 || iter->max == 1, file tre-compile.c,
line 1825

This application has requested the Runtime to terminate it in an unusual 
way.
Please contact the application's support team for more information.

>> sessionInfo()
> R version 2.11.1 Patched (2010-09-16 r52949)
> Platform: i386-pc-mingw32 (32-bit)
> ...
>> regexpr("a{2-}", "")
> Assertion failed: iter->max == -1 || iter->max == 1, file
> tre-compile.c, line 1825
> This application has requested the Runtime to terminate it in an unusual way.
> Please contact the application's support team for more information.
>
>> sessionInfo()
> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
> Platform: i386-pc-mingw32/i386 (32-bit)
> ...
>> regexpr("a{2-}", "")
> Assertion failed: iter->max == -1 || iter->max == 1, file
> tre-compile.c, line 1825
> This application has requested the Runtime to terminate it in an unusual way.
> Please contact the application's support team for more information.
>
>
>> sessionInfo()
> R version 2.11.0 Patched (2010-05-09 r51960)
> x86_64-unknown-linux-gnu
> ...
>> regexpr("a{2-}", "")
> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
> iter->max == 1' failed.
> Aborted
>
>
> /Henrik
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From romain.francois at dbmail.com  Wed Sep 22 18:53:12 2010
From: romain.francois at dbmail.com (Romain Francois)
Date: Wed, 22 Sep 2010 18:53:12 +0200
Subject: [Rd] Possible bug or annoyance with library.dynam.unload()
In-Reply-To: <4C9A213D.7040006@gmail.com>
References: <AANLkTik-Spu2SEAZjB3kSY1YoWFUhUy3NZ5-g3WRw_i2@mail.gmail.com>	<AANLkTimOnBLjWY9Qro88Pakd7_nTLibkqCkB1e=D7faQ@mail.gmail.com>	<4C98D038.8040507@gmail.com>	<AANLkTimDqM3pdFH5-Ph9kW=CafapEt7aQB_4YjTC5+9X@mail.gmail.com>
	<4C9A213D.7040006@gmail.com>
Message-ID: <4C9A3478.30201@dbmail.com>

Le 22/09/10 17:31, Duncan Murdoch a ?crit :
>
> On 22/09/2010 11:22 AM, Karl Forner wrote:
>> Thanks Duncan for your suggestion.
>>
>> I could not find any package using dynamic library, namespaces and not
>> the
>> useDynLib pragma so
>> I created a minimalistic package to demonstrate the problem.
>> Please find attached a very small package foo (8.8k)
>
> Your package depends on Rcpp, so I didn't try it in the alpha version of
> 2.12.0 (Rcpp isn't available there in a Windows binary at the moment)

(This might be moot given Karl's answer), but:

We are working on having Rcpp to work with R 2.12.0, we have currently a 
few issues to deal with due to the use of a newer compiler for R 2.12.0.

We hope we can make this happen before R 2.12.0 is out next month.

Romain

> but I did try it in R-patched. With one minor change to your script (the
> lib.loc needs to be "local", not "local/" on Windows), I can reproduce
> the problem, and it looks like a bug to me. Thanks for the report, I'll
> put it on the bugs page, and hopefully it will be fixed before the
> 2.12.0 release.
>
> Duncan Murdoch
>
>> Steps to reproduce the problem:
>>
>> * unarchive it ( tar zxvf foo_0.1.tar.gz )
>> * cd foo
>> * install it locally ( mkdir local; R CMD INSTALL -l local . )
>> * R
>> > library(foo, lib.loc="local/")
>> >.dynLibs()
>> # there you should be able to see the foo.so lib, in my case
>> /x05/people/m160508/workspace/foo/local/foo/libs/foo.so
>>
>> > unloadNamespace("foo")
>> .onUnload, libpath= local/fooWarning message:
>> .onUnload failed in unloadNamespace() for 'foo', details:
>> call: library.dynam.unload("foo", libpath)
>> error: shared library 'foo' was not loaded
>>
>> #The libpath that the .onUnload() gets is "local/foo".
>>
>> #This fails:
>> >library.dynam.unload("foo", "local/foo")
>> Error in library.dynam.unload("foo", "local/foo") :
>> shared library 'foo' was not loaded
>>
>> # but if you use the absolute path it works:
>> >library.dynam.unload("foo",
>> "/x05/people/m160508/workspace/foo/local/foo")
>>
>> Karl
>>
>> On Tue, Sep 21, 2010 at 5:33 PM, Duncan
>> Murdoch<murdoch.duncan at gmail.com>wrote:
>>
>> > On 21/09/2010 10:38 AM, Karl Forner wrote:
>> >
>> >> Hello,
>> >>
>> >> I got no reply on this issue.
>> >> It is not critical and I could think of work-around, but it really
>> looks
>> >> like a bug to me.
>> >> Should I file a bug-report instead of posting in this list ?
>> >>
>> >
>> > I'd probably post instructions for a reproducible example first.
>> Pick some
>> > CRAN package, tell us what to do with it to trigger the error, and
>> then we
>> > can see if it's something special about your package or Roxygen or a
>> general
>> > problem.
>> >
>> > Duncan Murdoch
>> >
>> > Thanks,
>> >>
>> >> Karl
>> >>
>> >> On Thu, Sep 16, 2010 at 6:11 PM, Karl Forner<karl.forner at gmail.com>
>> >> wrote:
>> >>
>> >> > Hello,
>> >> >
>> >> > I have a package with a namespace. Because I use Roxygen that
>> >> overwrites
>> >> > the NAMESPACE file each time it is run, I use a R/zzz.R file with
>> >> > an .onLoad() and .onUnload() functions to take care of loading and
>> >> > unloading my shared library.
>> >> >
>> >> > The problem: if I load my library from a local directory, then the
>> >> > unloading of the package fails, e.g:
>> >> >
>> >> > # loads fine
>> >> > >library(Foo, lib.loc=".Rcheck")
>> >> >
>> >> > >unloadNamespace("Foo")
>> >> > Warning message:
>> >> > .onUnload failed in unloadNamespace() for 'Foo', details:
>> >> > call: library.dynam.unload("Foo", libpath)
>> >> > error: shared library 'Foo' was not loaded
>> >> >
>> >> > # I traced it a little:
>> >> > >library.dynam.unload("Foo", ".Rcheck/Foo")
>> >> > Error in library.dynam.unload("Foo", ".Rcheck/Foo") :
>> >> > shared library 'Foo' was not loaded
>> >> >
>> >> > # using an absolute path works
>> >> > >library.dynam.unload("Foo", "/home/toto/.Rcheck/Foo")
>> >> >
>> >> >
>> >> > So from what I understand, the problem is either that the relative
>> >> libpath
>> >> > is sent to the .onUnload() function instead of the absolute one,
>> >> > or that library.dynam.unload() should be modified to handle the
>> >> relative
>> >> > paths.
>> >> >
>> >> > Am I missing something ? What should I do ?
>> >> >
>> >> > Thanks,
>> >> >
>> >> >
>> >> > Karl


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/cCmbgg : Rcpp 0.8.6
|- http://bit.ly/bzoWrs : Rcpp svn revision 2000
`- http://bit.ly/b8VNE2 : Rcpp at LondonR, oct 5th


From d.scott at auckland.ac.nz  Wed Sep 22 22:16:23 2010
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 23 Sep 2010 08:16:23 +1200
Subject: [Rd] Crash report: regexpr("a{2-}", "")
In-Reply-To: <4C9A30D3.3000102@ohsu.edu>
References: <AANLkTinxcpVMmZ6w6vRL74Xa8fSFUcVFV2t6t3sKszAG@mail.gmail.com>
	<4C9A30D3.3000102@ohsu.edu>
Message-ID: <4C9A6417.3090807@auckland.ac.nz>

  It crashes R on my linux:
 > regexpr("a{2-}", "")
R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 || 
iter->max == 1' failed.
Aborted

My setup is:

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-redhat-linux-gnu

locale:
  [1] LC_CTYPE=en_NZ       LC_NUMERIC=C         LC_TIME=en_NZ
  [4] LC_COLLATE=en_NZ     LC_MONETARY=C        LC_MESSAGES=en_NZ
  [7] LC_PAPER=en_NZ       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_NZ LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] djsmisc_1.0-1


David Scott


On 23/09/10 04:37, Brian Diggs wrote:
> [Accidentally posted this to r-help instead of r-devel; reposting to put
> it into the correct list and thread. My apologies for the duplication.]
>
> On 9/21/2010 8:04 PM, Henrik Bengtsson wrote:
>> Each of the following calls crash ("core dumps") R (R --vanilla) on
>> various versions and OSes:
>>
>> regexpr("a{2-}", "")
>> sub("a{2-}", "")
>> gsub("a{2-}", "")
>>
>>
>> EXAMPLES:
> To add another (windows) example it also crashes the 2.12.0 alpha build:
>
>   >  sessionInfo()
> R version 2.12.0 alpha (2010-09-20 r52948)
> Platform: i386-pc-mingw32/i386 (32-bit)
> ...
>   >  regexpr("a{2-}", "")
> Assertion failed: iter->max == -1 || iter->max == 1, file tre-compile.c,
> line 1825
>
> This application has requested the Runtime to terminate it in an unusual
> way.
> Please contact the application's support team for more information.
>
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-09-16 r52949)
>> Platform: i386-pc-mingw32 (32-bit)
>> ...
>>> regexpr("a{2-}", "")
>> Assertion failed: iter->max == -1 || iter->max == 1, file
>> tre-compile.c, line 1825
>> This application has requested the Runtime to terminate it in an unusual way.
>> Please contact the application's support team for more information.
>>
>>> sessionInfo()
>> R version 2.12.0 Under development (unstable) (2010-09-14 r52910)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>> ...
>>> regexpr("a{2-}", "")
>> Assertion failed: iter->max == -1 || iter->max == 1, file
>> tre-compile.c, line 1825
>> This application has requested the Runtime to terminate it in an unusual way.
>> Please contact the application's support team for more information.
>>
>>
>>> sessionInfo()
>> R version 2.11.0 Patched (2010-05-09 r51960)
>> x86_64-unknown-linux-gnu
>> ...
>>> regexpr("a{2-}", "")
>> R: tre-compile.c:1825: tre_ast_to_tnfa: Assertion `iter->max == -1 ||
>> iter->max == 1' failed.
>> Aborted
>>
>>
>> /Henrik
>>
>


-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From luke at stat.uiowa.edu  Thu Sep 23 03:19:02 2010
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Wed, 22 Sep 2010 20:19:02 -0500 (CDT)
Subject: [Rd] Fourteen patches to speed up R
In-Reply-To: <20100903172719.GA5284@cs.toronto.edu>
References: <20100903172719.GA5284@cs.toronto.edu>
Message-ID: <alpine.DEB.2.00.1009222018170.1743@luke-inspiron>

Thanks very much for the patches.  I have spent a couple of days
working through them, and others have looked at some of them as well
and may continue to do so. Here are some notes on the individual
patches describing things I have done or decided not to do and things
others have done that I know about.

patch-transpose

 	Applied by Martin Maechler.


patch-for

 	Applied by Duncan Murdoch; revised by me. Some cosmetic
 	revisions, including going back to PROTECT_WITH_INDEX. Also
 	placed two variables 'n' and 'bgn' back under volatile
 	declarations.  Theoretically this shouldn't be needed, but gcc
 	-O2 -Wclobbered warns about them, so to be safe and eliminate
 	the warnings they are declared volatile as well.

 	The current byte code compiler actually stores the binding
 	cell rather than using setVar or defineVar -- this eliminates
 	the search and does not have the destructive effect of
 	modifying an outer variable if the loop variable is removed,
 	but removing the loop variable will then reference an outer
 	one if available or do other strange things. It doesn't
 	actually make much performance difference (at least in simple
 	examples) -- for that we would probably need to eliminate a
 	number of the function calls involved at the moment.  A better
 	solution for preserving the semantics in the case of user code
 	removing the loop variable might be to disallow removing the
 	loop variable, or to allow removal to be detected easily
 	(e.g. by having rm() put R_UnboundValue in the value cell).


patch-parens

 	Should not be applied.  `(` is conceptually a BUILTIN, i.e. a
 	strict function that evaluates all arguments in order. Making
 	it a SPECIAL is conceptually wrong and confuses issues of code
 	analysis and compilation. It is true that calling of BUILTINs
 	is currently less efficient than calling of SPECIALS because
 	the evaluated arguments for BUILTINs are stored in freshly
 	allocated lists, but it would be better to work towards making
 	that calling mechanism more efficient for all BUILTINs than to
 	confuse internal semantics by converting BUILTINs to SPECIALs.

 	We have currently a few things that are SPECIAL even though
 	they really have BUILTIN semantics, but they are SPECIAL
 	because of issues like needing to support missing arguments,
 	which BUILTINs do not. We should be moving these to BUILTIN
 	status, though perhaps not until BUILTIN calling performance
 	is improved.

 	Whether working on BUILTIN calling performance in the
 	interpreter makes sense depends on where the byte code
 	compiler gets to.  The current compiler is much more efficient
 	about the handling of inlined BUILTINs; the revised one in
 	progress is likely to me much more efficient for all BUILTINs.

 	I would rather not make the proposed change for braces
 	(do_begin) as it makes it harder to find the relevant bits to
 	remove if we want to change this. Source references are very
 	useful, but we should be able to find a way of having them
 	without incurring runtime overhead unless they are actually
 	used. I have added an R_INLINE designation to getSrcref to
 	encourage the compiler to do the inlining. Timing differences
 	for test-parens.r are in the right direction but in the noise
 	level on an Ubuntu laptop:

 			   inline   byte
 		    devel    decl   comp

 	    curly:  10.25   10.13   1.94
 	    parens: 11.21   10.91   1.91

 	The byte comp column is for the current byte code engine and
 	compiler and illustrates that this approach has much more
 	promise.


patch-sum-prod

 	I had looked at this a while back and had an uncommitted
 	change along very similar lines.  I think the reason I didn't
 	commit this change is that I didn't like the code expansion
 	that resulted, and I still don't.  Looking at this again it
 	turns out there is a very simple code change that preserves
 	the code structure and achieves the same improvement in the
 	narm == FALSE case: reverse the test order from

             if (!ISNAN(x[i]) || !narm)  ...

 	to

             if (!narm || !ISNAN(x[i])) ...

         That way the expensive ISNAN test is only done when the result
         might matter. This has been done for real and complex sum and
         prod. It provides the same level of improvement for the narm
         == FALSE case as the patch, and for the narm == TRUE cases the
         differences are in the noise level on my system. This has been
         committed as r52925.

         The specific six timings from test-sum-prod.r on my Ubuntu
         laptop are

 	    R 2.11   devel   patch  switch

 	      3.25   10.27    2.50    2.47
 	     10.69   10.39   10.25    9.99
 	     10.73   10.53   10.37   10.02
 	      3.80   10.77    3.60    3.57
 	     10.57   10.93   10.32   10.89
 	     10.54   11.07   10.45   11.09


patch-evalList

 	This looks fine (standard Lisp idiom) and has been applied as
 	r52930. Needed to add initial values for 'tail' variables to
 	turn off uninitialized variable warnings (r52935). Some
 	timings:

 			    R        R    patch  byte
 			 2.11    devel evalList  comp

 	    test-em     18.49    15.13    14.08  4.34
 	    p1          39.52    30.80    28.72  8.80

 	Again a compilation approach should produce much more
 	substantial gains for code dominated by interpreter overhead.
 	Here p1 is the example

             p1 <- function(x) {
                 for (i in seq_along(x))
                     x[i] <- x[i] + 1
                 x
             }
             x <- rep(1, 1e7)
             system.time(p1(x))


patch-square

 	The analysis provided with this patch needs fleshing out.  It
 	is useful to try to understand where the speed gains come from
 	and to make changes that can help other code as well.

 	The y == 2.0 test is fairly cheap.  The speed gain of the
 	patch comes mostly from avoiding the overhead that comes
 	before the y == 2.0 test, mainly the call into R_pow and two
 	calls to FINITE. r52937 (r52967 for 2.12) moves the test for y
 	== 2.0 to the top of the R_pow function, thus avoiding the
 	FINITE calls; this cuts the per value cost roughly in half on
 	one test platform at least. r52938 (r52968 for 2.12) defines
 	R_POW as an inline function that handles the y == 2.0 case in
 	line and only calls R_pow in the general case. This cuts the
 	time again by roughly a third.

 	On some platforms further improvement comes from avoiding the
 	overhead in mod_iterate for cases where one argument is a
 	scalar or the arguments are of equal length. r52965 (r52970
 	for 2.12) addresses this using the same approach as for
 	addition, etc. from patch-vec-arith; this should be abstracted
 	into a macro and used consistently in a few more cases.
 	Special handling the scalar exponent case only speeds things
 	up by a few percent on my laptop and one other machine and
 	actually slows down on a third platform (presumably a
 	code/optimizer interaction), though it does help some on a
 	fourth platform.  To keep the code simpler I prefer not to
 	make this change now, at least until we have had a chance to
 	look at abstracting the iteration process into a macro.


patch-matprod

 	I don't have particularly strong views on this one and will
 	leave it to others in R-core for now. One note: on my x86_64
 	Ubuntu laptop replacing ISNAN with

 	#undef ISNAN
 	static R_INLINE double ISNAN(double x) { return x != x; }

 	produces a fairly substantial improvement.  Dropping the ISNAN
 	test entirely speeds things up some more, and going to an
 	inline version of matrix multiply helps more for the smaller
 	cases but not much for the larger ones in the test-matprod
 	examples if the inline uses LDOUBLE for accumulation.  It
 	helps in all these cases if the inline uses double.  Here are
 	some timings that might be useful:

                                          R  inline    drop  inline  inline
                 		     devel   ISNAN   ISNAN LDOUBLE  double
 	V-V, length 1000:             8.64    4.71    3.05    1.67    1.36
 	M-V, 5x1000 times 1000x1:     4.95    2.60    1.61    1.80    1.44
 	M-V, 50x1000 times 1000x1:    3.72    1.75    0.91    2.06    1.64
 	M-M, 2x1000 times 1000x3:     5.72    3.60    2.87    1.57    1.16
 	M-M, 5x1000 times 1000x3:     8.99    5.87    4.55    5.13    4.03
 	M-M, 10x1000 times 1000x10:  10.05    7.71    6.75    7.61    5.96
 	M-M, 10x1000 times 1000x11:  10.87    8.40    7.38    8.35    6.51

 	On one of our lab machines, where we are still running 2.10.1
 	but also have MKL BLAS versions available I got

                                          R      MKL      MKL
                                     2.10.1      seq   thread
 	V-V, length 1000:            6.265    5.250    5.255
 	M-V, 5x1000 times 1000x1:    3.197    2.832    2.837
 	M-V, 50x1000 times 1000x1:   2.525    2.260    2.263
 	M-M, 2x1000 times 1000x3:    3.478    2.654    2.648
 	M-M, 5x1000 times 1000x3:    5.598    4.258    4.272
 	M-M, 10x1000 times 1000x10:  6.693    3.749    3.796
 	M-M, 10x1000 times 1000x11:  7.221    3.981    4.042


patch-fast-base
patch-fast-spec

 	I tried the patch-fast-spec patch and did not see consistent
 	performance improvement -- slightly faster on one example,
 	slightly slower on another. So it is not at all clear to me
 	that this provides any real benefit.  The code is certainly
 	made more complex, so I do not think these should be applied.
 	Optimizing access to base functions in general and operators
 	in particular is one of the things a byte code compiler will
 	do, at least at reasonable optimization levels. The current
 	byte code compiler speeds up the EM example by about a factor
 	of three; the revised one I am working on will hopefully do
 	even better.

 		      R    fast    byte
 		  devel    spec    code
 	    em    13.83   12.75    4.28
 	    p1    28.30   29.91    9.04


patch-vec-arith

 	Looks OK.  Applied to trunk as r52946 (r52969 in 2-12-branch).
 	Eventually it may make sense to revisit this and maybe use a
 	macro to abstract out common code and apply it to some other
 	cases as well.


patch-save-alloc

 	This is similar to something I have been experimenting with in
 	the context of byte code compilation. In that setting there is
 	more opportunity for optimization by looking at where the
 	result of a computation is being used and possibly overwriting
 	the target. I'm not sure this is worth doing in the
 	interpreter, and my timings give somewhat mixed results (that
 	also vary for non-obvious reasons with seemingly small code
 	changes). I would prefer to defer committing to this idea in
 	the interpreter until more is learned from the byte code
 	experiments and about exactly where gains, if any, might be
 	coming from.


patch-vec-subset
patch-dollar

 	I would prefer if someone in R-core who is more familiar with
 	the subsetting/dollar code than I am could have a look at
 	these.


patch-protect

 	As I mentioned in my initial reply, I've tried this before on
 	the theory that it should make a difference, but it didn't
 	then and I still doesn't now, at least not relative to the
 	noise level on my machines on the tests I ran.  So I don't
 	think this is worth doing now, but it is worth keeping in mind
 	and trying again as other factors improve.

luke

On Fri, 3 Sep 2010, Radford Neal wrote:

> I've continued to work on speeding up R, and now have a collection of
> fourteen patches, some of which speed up particular functions, and
> some of which reduce general interpretive overhead.  The total speed
> improvement from these patches is substantial.  It varies a lot from
> one R program to the next, of course, and probably from one machine to
> the next, but speedups of 25% can be expected in many programs, and
> sometimes much more (though sometimes less as well).
>
> The fourteen patches work for revision r52822 of the development
> version of R (I haven't check against any changes in the last few
> days), and also for release 2.11.1.  These patches, along with
> some documentation, are attached as speed-patches.tar.
>
> I also wrote a number of timing test programs, which are attached as
> speed-tests.tar.
>
> I've included below the documentation on what each patch does, which
> is also in "doc" in speed-patches.tar.  Note that I fixed a few minor
> bugs along the way.
>
> There looks to be scope for more improvements in various parts of the
> R interpreter that I didn't get to.  I'll have to put this on hold for
> now, however, to spend my time preparing for the coming teaching term.
> I'd be happy to hear of any comments on these patches, though,
> including information on how much they speed up typical programs, on
> various machines.
>
>   Radford Neal
>
> -----------------------------------------------------------------------
>
> These patches to the R source for improving speed were written by
> Radford M. Neal, Sept. 2010.
>
> See the README file for how to install them.
>
> Below, I describe these patches (in alphabetical order), indicate what
> improvement they produce, and also mention any potential issues with
> using the patch, and bugs that the patches incidently fix.
>
> The timing improvements discussed below are what is obtained by
> applying each patch individually, on an Intel system running Ubuntu
> Linux with Gcc version 4.2.4.  The total improvement from all patches
> is much bigger, though in a few instances a patch can diminish the
> effect of another patch, by reducing the magnitude of the
> inefficiencies that the other patch eliminates.  Note though, that the
> percentage improvement for a given absolute improvement gets bigger as
> when other patches reduce overall time.
>
> For r52822, the total time for all tests in the accompanying speed
> test suite is 674 seconds.  This is reduced to 487 seconds with all
> patches applied, a reduction of 28%.  Particular R programs will, of
> course, see widely varying reductions depending on what operations
> they mostly do.
>
> patch-dollar
>
>    Speeds up access to lists, pairlists, and environments using the
>    $ operator.  The speedup comes mainly from avoiding the overhead of
>    calling DispatchOrEval if there are no complexities, from passing
>    on the field to extract as a symbol, or a name, or both, as available,
>    and then converting only as necessary, from simplifying and inlining
>    the pstrmatch procedure, and from not translating string multiple
>    times.
>
>    Relevant timing test script:  test-dollar.r
>
>    This test shows about a 40% decrease in the time needed to extract
>    elements of lists and environments.
>
>    Changes unrelated to speed improvement:
>
>    A small error-reporting bug is fixed, illustrated by the following
>    output with r52822:
>
>    > options(warnPartialMatchDollar=TRUE)
>    > pl <- pairlist(abc=1,def=2)
>    > pl$ab
>    [1] 1
>    Warning message:
>    In pl$ab : partial match of 'ab' to ''
>
>    Some code is changed at the end of R_subset3_dflt because it seems
>    to be more correct, as discussed in code comments.
>
> patch-evalList
>
>    Speeds up a large number of operations by avoiding allocation of
>    an extra CONS cell in the procedures for evaluating argument lists.
>
>    Relevant timing test scripts:  all of them, but will look at test-em.r
>
>    On test-em.r, the speedup from this patch is about 5%.
>
> patch-fast-base
>
>    Speeds up lookup of symbols defined in the base environment, by
>    flagging symbols that have a base environment definition recorded
>    in the global cache.  This allows the definition to be retrieved
>    quickly without looking in the hash table.
>
>    Relevant timing test scripts:  all of them, but will look at test-em.r
>
>    On test-em.r, the speedup from this patch is about 3%.
>
>    Issue:  This patch uses the "spare" bit for the flag.  This bit is
>    misnamed, since it is already used elsewhere (for closures).  It is
>    possible that one of the "gp" bits should be used instead.  The
>    "gp" bits should really be divided up for faster access, and so that
>    their present use is apparent in the code.
>
>    In case this use of the "spare" bit proves unwise, the patch code is
>    conditional on FAST_BASE_CACHE_LOOKUP being defined at the start of
>    envir.r.
>
> patch-fast-spec
>
>    Speeds up lookup of function symbols that begin with a character
>    other than a letter or ".", by allowing fast bypass of non-global
>    environments that do not contain (and have never contained) symbols
>    of this sort.  Since it is expected that only functions will be
>    given names of this sort, the check is done only in findFun, though
>    it could also be done in findVar.
>
>    Relevant timing test scripts:  all of them, but will look at test-em.r
>
>    On test-em.r, the speedup from this patch is about 8%.
>
>    Issue:  This patch uses the "spare" bit to flag environments known
>    to not have symbols starting with a special character.  See remarks
>    on patch-fast-base.
>
>    In case this use of the "spare" bit proves unwise, the patch code is
>    conditional on FAST_SPEC_BYPASS being defined at the start of envir.r.
>
> patch-for
>
>    Speeds up for loops by not allocating new space for the loop
>    variable every iteration, unless necessary.
>
>    Relevant timing test script:  test-for.r
>
>    This test shows a speedup of about 5%.
>
>    Change unrelated to speed improvement:
>
>    Fixes what I consider to be a bug, in which the loop clobbers a
>    global variable, as demonstrated by the following output with r52822:
>
>    > i <- 99
>    > f <- function () for (i in 1:3) { print(i); if (i==2) rm(i); }
>    > f()
>    [1] 1
>    [1] 2
>    [1] 3
>    > print(i)
>    [1] 3
>
> patch-matprod
>
>    Speeds up matrix products, including vector dot products.  The
>    speed issue here is that the R code checks for any NAs, and
>    does the multiply in the matprod procedure (in array.c) if so,
>    since BLAS isn't trusted with NAs.  If this check takes about
>    as long as just doing the multiply in matprod, calling a BLAS
>    routine makes no sense.
>
>    Relevant time test script:  test-matprod.r
>
>    With no external BLAS, this patch speeds up long vector-vector
>    products by a factor of about six, matrix-vector products by a
>    factor of about three, and some matrix-matrix products by a
>    factor of about two.
>
>    Issue:  The matrix multiply code in matprod using an LDOUBLE
>    (long double) variable to accumulate sums, for improved accuracy.
>    On a SPARC system I tested on, operations on long doubles are
>    vastly slower than on doubles, so that the patch produces a
>    large slowdown rather than an improvement.  This is also an issue
>    for the "sum" function, which also uses an LDOUBLE to accumulate
>    the sum.  Perhaps an ordinarly double should be used in these
>    places, or perhaps the configuration script should define LDOUBLE
>    as double on architectures where long doubles are extraordinarily
>    slow.
>
>    Due to this issue, not defining MATPROD_CAN_BE_DONE_HERE at the
>    start of array.c will disable this patch.
>
> patch-parens
>
>    Speeds up parentheses by making "(" a special operator whose
>    argument is not evaluated, thereby bypassing the overhead of
>    evalList.  Also slightly speeds up curly brackets by inlining
>    a function that is stylistically better inline anyway.
>
>    Relevant test script:  test-parens.r
>
>    In the parens part of test-parens.r, the speedup is about 9%.
>
> patch-protect
>
>    Speeds up numerous operations by making PROTECT, UNPROTECT, etc.
>    be mostly macros in the files in src/main.  This takes effect
>    only for files that include Defn.h after defining the symbol
>    USE_FAST_PROTECT_MACROS.  With these macros, code of the form
>    v = PROTECT(...) must be replaced by PROTECT(v = ...).
>
>    Relevant timing test scripts:  all of them, but will look at test-em.r
>
>    On test-em.r, the speedup from this patch is about 9%.
>
> patch-save-alloc
>
>    Speeds up some binary and unary arithmetic operations by, when
>    possible, using the space holding one of the operands to hold
>    the result, rather than allocating new space.  Though primarily
>    a speed improvement, for very long vectors avoiding this allocation
>    could avoid running out of space.
>
>    Relevant test script:  test-complex-expr.r
>
>    On this test, the speedup is about 5% for scalar operands and about
>    8% for vector operands.
>
>    Issues:  There are some tricky issues with attributes, but I think
>    I got them right.  This patch relies on NAMED being set correctly
>    in the rest of the code.  In case it isn't, the patch can be disabled
>    by not defining AVOID_ALLOC_IF_POSSIBLE at the top of arithmetic.c.
>
> patch-square
>
>    Speeds up a^2 when a is a long vector by not checking for the
>    special case of an exponent of 2 over and over again for every
>    vector element.
>
>    Relevant test script:  test-square.r
>
>    The time for squaring a long vector is reduced in this test by a
>    factor of more than five.
>
> patch-sum-prod
>
>    Speeds up the "sum" and "prod" functions by not checking for NA
>    when na.rm=FALSE, and other detailed code improvements.
>
>    Relevant test script:  test-sum-prod.r
>
>    For sum, the improvement is about a factor of 2.5 when na.rm=FALSE,
>    and about 10% when na.rm=TRUE.
>
>    Issue:  See the discussion of patch-matprod regarding LDOUBLE.
>    There is no change regarding this issue due to this patch, however.
>
> patch-transpose
>
>    Speeds up the transpose operation (the "t" function) from detailed
>    code improvements.
>
>    Relevant test script:  test-transpose.r
>
>    The improvement for 200x60 matrices is about a factor of two.
>    There is little or no improvement for long row or column vectors.
>
> patch-vec-arith
>
>    Speeds up arithmetic on vectors of the same length, or when on
>    vector is of length one.  This is done with detailed code improvements.
>
>    Relevant test script:  test-vec-arith.r
>
>    On long vectors, the +, -, and * operators are sped up by about
>    20% when operands are the same length or one operand is of length one.
>
>    Rather mysteriously, when the operands are not length one or the
>    same length, there is about a 20% increase in time required, though
>    this may be due to some strange C optimizer peculiarity or some
>    strange cache effect, since the C code for this is the same as before,
>    with negligible additional overhead getting to it.  Regardless, this
>    case is much less common than equal lengths or length one.
>
>    There is little change for the / operator, which is much slower than
>    +, -, or *.
>
> patch-vec-subset
>
>    Speeds up extraction of subsets of vectors or matrices (eg, v[10:20]
>    or M[1:10,101:110]).  This is done with detailed code improvements,
>    some increased fast treatment of common cases, and some avoidance of
>    unnecessary duplication.
>
>    Relevant test script:  test-vec-subset.r
>
>    There are lots of tests in this script.  The most dramatic improvement
>    is for extracting many rows and columns of a large array, where the
>    improvement is by about a factor of four.  Extracting many rows from
>    one column of a matrix is sped up by about 30%.  Extracting a large
>    part of a vector is sped up by about 20%.  Several other operations
>    have improvements of 10% or more.
>
>    Changes unrelated to speed improvement:
>
>    Fixes two latent bugs where the code incorrectly refers to NA_LOGICAL
>    when NA_INTEGER is appropriate and where LOGICAL and INTEGER types
>    are treated as interchangeable.  These cause no problems at the moment,
>    but would if representations were changed.
>
>    Issues:  The current code duplicates a vector of indexes when
>    duplication seems unnecessary.  As far as I can see, the only reason
>    for this is so that it can remove attributes, which is helpful only
>    for string subscripts, given how the routine to handle them returns
>    information via an attribute.  If this is the only reason, as I concluded,
>    the duplication can easily be avoided, so I avoided it.  But perhaps
>    I don't understand something, since there are a fair number of
>    interactions going on with this code.  I also removed a layer of
>    procedure call overhead that seemed to be doing nothing.  Probably
>    it used to do something, but no longer does, but if instead it is
>    preparation for some future use, then removing it would be a mistake.
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From wht_crl at yahoo.com  Thu Sep 23 09:20:42 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Sep 2010 00:20:42 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <alpine.LFD.2.00.1009221255180.29567@gannet.stats.ox.ac.uk>
Message-ID: <134458.1267.qm@web62005.mail.re1.yahoo.com>

True. A markup command won't be enough to do the job. A function is needed to count the character number (based on the font and size) and if it is greater than the width of the page (based on A4 format or US letter), it will split the line.

Now another question regarding the code in the \examples field: how to keep the same format as the source code because all lines start vertically at the same position? for ex, if I have tab set manually in the source code, it is ignored in the pdf manual file. Do I have to use \tab? How about html help page?

I have noticed that there is one file 00Index.html in html folder. I didn't have any error message when I ran R CMD check and build. But it seems that other html files missing. How to repair?

when I ran R CMD check, the pdf manual file was created in one level up the package folder. I moved it to help folder. How to set options so that  it will be created in the help folder? 

thanks,

--- On Wed, 9/22/10, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [Rd] some problems reported in 00check.log
> To: "carol white" <wht_crl at yahoo.com>
> Cc: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>, r-devel at r-project.org
> Date: Wednesday, September 22, 2010, 5:04 AM
> On Wed, 22 Sep 2010, carol white
> wrote:
> 
> > So there is no sort of automatic way like using a
> markup command for the susceptible fields instead of
> splitting manually a line on different lines?
> 
> Well, how is the automatic command to know how to do
> this?? As you 
> will see from the autmatic wrapping in e.g. deparse(), we
> are not able 
> to do a very good job.
> 
> There has been some talk about doing this automatically as
> a backstop, 
> but I don't know the current state: in any case it does not
> happen in 
> released versions of R.
> 
> > True that this doesn't happen in Arguments field (I
> confused with 
> > Format field).
> >
> > Also true that the codes used in Usage, Examples etc
> are in 
> > courrier. Is there any way to reduce the size and not
> to change the 
> > font of character for these fields?
> 
> You can change Rd.sty, which already contains options for
> using 
> other fontsets.
> 
> >
> > Best,
> >
> > Carol
> >
> > --- On Wed, 9/22/10, Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
> >
> >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >> Subject: Re: [Rd] some problems reported in
> 00check.log
> >> To: "carol white" <wht_crl at yahoo.com>
> >> Cc: "Uwe Ligges" <ligges at statistik.tu-dortmund.de>,
> r-devel at r-project.org
> >> Date: Wednesday, September 22, 2010, 2:15 AM
> >> On Wed, 22 Sep 2010, carol white
> >> wrote:
> >>
> >>> Thank you very much Uwe. It works now.
> >>>
> >>> I have a question about pdf formating in pdf
> manual
> >> file:
> >>>
> >>> How to format the long lines which go to the
> margin?
> >> For ex, this happens in Usage field if a function
> has many
> >> arguments. Also, it happens in examples or
> Arugment sections
> >> when the lines are long.
> >>
> >> Correct the sources by re-formatting over-long
> lines
> >> yourself.? (This should only happen in
> verbatim-like
> >> sections, hence unlikely to happen in
> \argument{}.)
> >>
> >> One of the things we suggest when checking a
> package is to
> >> read through the PDF manual, and this is one of
> the problems
> >> to look out for.? (Note that it does depend on
> the
> >> fonts used for the PDF, but the default Courier
> for
> >> monospaced text is somewhat wide.)
> >>
> >> -- Brian D. Ripley,? ? ? ? ?
> >> ? ? ? ? ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,? http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,? ? ? ? ?
> >> ???Tel:? +44 1865 272861 (self)
> >> 1 South Parks Road,? ? ? ? ?
> >> ? ? ? ? ???+44 1865
> >> 272866 (PA)
> >> Oxford OX1 3TG, UK? ? ? ? ? ?
> >> ? ? Fax:? +44 1865 272595
> >>
> >
> >
> >
> >
> 
> -- 
> Brian D. Ripley,? ? ? ? ? ?
> ? ? ? ripley at stats.ox.ac.uk
> Professor of Applied Statistics,? http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,? ? ? ? ?
> ???Tel:? +44 1865 272861 (self)
> 1 South Parks Road,? ? ? ? ?
> ? ? ? ? ???+44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK? ? ? ? ? ?
> ? ? Fax:? +44 1865 272595





From maechler at stat.math.ethz.ch  Thu Sep 23 13:52:05 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 23 Sep 2010 13:52:05 +0200
Subject: [Rd] OT: Reason/history behind ## notation for comments?
In-Reply-To: <AANLkTime_rZcJNCttC01nZbJRfgs-n0rXy_PnuDgcapw@mail.gmail.com>
References: <AANLkTimRgeGVxira9GzJoBfPSyWKYxBcbD1TALXzFYd9@mail.gmail.com>
	<AANLkTime_rZcJNCttC01nZbJRfgs-n0rXy_PnuDgcapw@mail.gmail.com>
Message-ID: <19611.16229.504704.752935@lynne.math.ethz.ch>

>>>>> "LG" == Laurent Gatto <laurent.gatto at gmail.com>
>>>>>     on Wed, 22 Sep 2010 08:33:20 +0100 writes:

    LG> For what concerns emacs users, the number of '#' has
    LG> different effects on the position of the comment. From
    LG> the ESS manual: 'By default, comments beginning with
    LG> ?###? are aligned to the beginning of the line. Comments
    LG> beginning with ?##? are aligned to the current level of
    LG> indentation for the block containing the
    LG> comment. Finally, comments beginning with ?#? are
    LG> aligned to a column on the right...'. I guess that ## is
    LG> the most wanted indentation for comments.

Yes, that's all correct.
(and Emacs+ESS being used quite a bit by some active R Core
 members, at least "historically")

One thing to add:
As most of you probably know, R was built using ideas and
concepts from Lisp (aka "LISP"), and (Emacs-)Lisp being emacs'
extension language, Emacs has always supported
auto-indenting/filling of comments---which in lisp start with a
";" --- using different indentation rules for ";", ";;", ";;;" ....
So it seems quite apt for R to continue this Lisp convention.
Given the Lisp decent, this tradition is probably quite an old one in
(academic) programming history. 

Martin Maechler,
ETH Zurich (and R Core)


    LG> Best wishes,

    LG> Laurent

    LG> On 22 September 2010 07:26, Henrik Bengtsson
    LG> <hb at stat.berkeley.edu> wrote:
    >> Off topic, but since I've observe both styles, does
    >> anyone know the history behind/reason for using ##
    >> instead of a single # to start comments in R. ?I know
    >> some editors do this by default. ?Is it because in C it
    >> is easier to distinguish (search/replace/...) comments
    >> from C preprocessor directives such as #include, and
    >> that's became a de facto standard elsewhere?
    >> 
    >> /Henrik
    >> 
    >> PS. I don't want to get into a debate on what's the best
    >> style.
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

______________________________________________
    LG> R-devel at r-project.org mailing list
    LG> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Thu Sep 23 13:57:25 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2010 13:57:25 +0200
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <134458.1267.qm@web62005.mail.re1.yahoo.com>
References: <134458.1267.qm@web62005.mail.re1.yahoo.com>
Message-ID: <4C9B40A5.8070101@statistik.tu-dortmund.de>



On 23.09.2010 09:20, carol white wrote:
> True. A markup command won't be enough to do the job. A function is needed to count the character number (based on the font and size) and if it is greater than the width of the page (based on A4 format or US letter), it will split the line.
>
> Now another question regarding the code in the \examples field: how to keep the same format as the source code because all lines start vertically at the same position? for ex, if I have tab set manually in the source code, it is ignored in the pdf manual file. Do I have to use \tab? How about html help page?
 >
> I have noticed that there is one file 00Index.html in html folder. I didn't have any error message when I ran R CMD check and build. But it seems that other html files missing. How to repair?

If this is R > 2.10.0, it is expected. Static html files are not 
generated upon installation any more. Contents is generated dynamically 
upon request now.


> when I ran R CMD check, the pdf manual file was created in one level up the package folder. I moved it to help folder. How to set options so that  it will be created in the help folder?

The pdf manual is not part of a binary package. A user can ask R to 
generate the manual or parts of it. The manual will so be generated by 
CRAN, for example.


Uwe Ligges




>
> thanks,
>
> --- On Wed, 9/22/10, Prof Brian Ripley<ripley at stats.ox.ac.uk>  wrote:
>
>> From: Prof Brian Ripley<ripley at stats.ox.ac.uk>
>> Subject: Re: [Rd] some problems reported in 00check.log
>> To: "carol white"<wht_crl at yahoo.com>
>> Cc: "Uwe Ligges"<ligges at statistik.tu-dortmund.de>, r-devel at r-project.org
>> Date: Wednesday, September 22, 2010, 5:04 AM
>> On Wed, 22 Sep 2010, carol white
>> wrote:
>>
>>> So there is no sort of automatic way like using a
>> markup command for the susceptible fields instead of
>> splitting manually a line on different lines?
>>
>> Well, how is the automatic command to know how to do
>> this?  As you
>> will see from the autmatic wrapping in e.g. deparse(), we
>> are not able
>> to do a very good job.
>>
>> There has been some talk about doing this automatically as
>> a backstop,
>> but I don't know the current state: in any case it does not
>> happen in
>> released versions of R.
>>
>>> True that this doesn't happen in Arguments field (I
>> confused with
>>> Format field).
>>>
>>> Also true that the codes used in Usage, Examples etc
>> are in
>>> courrier. Is there any way to reduce the size and not
>> to change the
>>> font of character for these fields?
>>
>> You can change Rd.sty, which already contains options for
>> using
>> other fontsets.
>>
>>>
>>> Best,
>>>
>>> Carol
>>>
>>> --- On Wed, 9/22/10, Prof Brian Ripley<ripley at stats.ox.ac.uk>
>> wrote:
>>>
>>>> From: Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>> Subject: Re: [Rd] some problems reported in
>> 00check.log
>>>> To: "carol white"<wht_crl at yahoo.com>
>>>> Cc: "Uwe Ligges"<ligges at statistik.tu-dortmund.de>,
>> r-devel at r-project.org
>>>> Date: Wednesday, September 22, 2010, 2:15 AM
>>>> On Wed, 22 Sep 2010, carol white
>>>> wrote:
>>>>
>>>>> Thank you very much Uwe. It works now.
>>>>>
>>>>> I have a question about pdf formating in pdf
>> manual
>>>> file:
>>>>>
>>>>> How to format the long lines which go to the
>> margin?
>>>> For ex, this happens in Usage field if a function
>> has many
>>>> arguments. Also, it happens in examples or
>> Arugment sections
>>>> when the lines are long.
>>>>
>>>> Correct the sources by re-formatting over-long
>> lines
>>>> yourself.  (This should only happen in
>> verbatim-like
>>>> sections, hence unlikely to happen in
>> \argument{}.)
>>>>
>>>> One of the things we suggest when checking a
>> package is to
>>>> read through the PDF manual, and this is one of
>> the problems
>>>> to look out for.  (Note that it does depend on
>> the
>>>> fonts used for the PDF, but the default Courier
>> for
>>>> monospaced text is somewhat wide.)
>>>>
>>>> -- Brian D. Ripley,
>>>>          ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,
>>>>     Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,
>>>>             +44 1865
>>>> 272866 (PA)
>>>> Oxford OX1 3TG, UK
>>>>      Fax:  +44 1865 272595
>>>>
>>>
>>>
>>>
>>>
>>
>> --
>> Brian D. Ripley,
>>        ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,
>>     Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,
>>             +44 1865
>> 272866 (PA)
>> Oxford OX1 3TG, UK
>>      Fax:  +44 1865 272595
>
>
>


From hkawakat at gmail.com  Thu Sep 23 15:05:20 2010
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Thu, 23 Sep 2010 14:05:20 +0100
Subject: [Rd] R CMD Rprof --help suggestion
Message-ID: <AANLkTikY6HvY5M5DKj8grH+5AMtGyy0aBK1vKPeUz=Tb@mail.gmail.com>

Hi,

>From reading ?Rprof, I checked
R CMD Rprof --help
and learned that there are options to specify the min % to print. This
is currently (R-devel r52975) displayed with the --help option as

  --min%total           minimum % to print for 'by total'
  --min%self            minimum % to print for 'by self'

So I tried
R CMD Rprof --min%total 5
and got an error. After looking at the source, I find that I need to do
R CMD Rprof --min%total=5

Can I suggest a change in (R_SOURCE/src/library/tools/R/Rprof.R) the
--help option display for --min%total and --min%self to something like

  --min%total=NUM       set NUM as minimum % to print for 'by total'
  --min%self=NUM        set NUM as minimum % to print for 'by self'

which I think is more in line with e.g. R --help.

PS 1: ?Rprof states that R CMD Rprof is a Perl script but that no
longer seems to be the case. The remark in ?summaryRprof about it
being slower than R CMD Rprof for large files no longer applies?

PS 2: summaryRprof() currently does not appear to support these min %
options. I find them quite useful so I would like to request them to
be added. By looking at how .Rprof() post-processes summaryRprof(), a
quick hack I use is

summaryRprof2 <- function(..., mintotal=-1L, minself=-1L) {
  res <- utils::summaryRprof(...)
  if (mintotal>0) res$by.total <-
res$by.total[res$by.total[,"total.pct"]>=mintotal,]
  if (minself>0) res$by.self <- res$by.self[res$by.self[,"self.pct"]>=minself,]
  return(res)
}

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From harold.petithomme at meteo.fr  Thu Sep 23 16:21:11 2010
From: harold.petithomme at meteo.fr (Harold PETITHOMME)
Date: Thu, 23 Sep 2010 16:21:11 +0200
Subject: [Rd] strange behaviour of callNextMethod in S4 methods
Message-ID: <4C9B6257.8070500@meteo.fr>

Hello,

I experienced a strange behaviour of callNextMethod when used in either 
initialize or any other S4 function method definition.
Help says callNextMethod calls the next inherited method for the current 
function from where it is called with the same actual (non missing) 
arguments. This is OK. The problem appears when some formal arguments 
(in particular, S4 objects) of this function are first used in the 
current method and then must be used in the "next method" too. It 
happens that such an argument is said to be missing in the "next 
method". My guess is that using the argument in the current method makes 
it disappear the next method. Is it a bug or a normal behaviour?

For understanding, let's see this example (with calls to some RNetCDF 
functions):

Define a generic:
setGeneric("ncputVar",def=function(nc,variable,object) 
standardGeneric("ncputVar"))

Define a 1st method for class Source:
setMethod("ncputVar",signature(nc="NetCDF",variable="ANY",object="Source"),
    def=function(nc,variable,object)
{
    att.put.nc(nc,variable,"nom","NC_CHAR",object at nom)
    att.put.nc(nc,variable,"dom","NC_CHAR",object at dom)
    att.put.nc(nc,variable,"loc","NC_CHAR",object at loc)
    att.put.nc(nc,variable,"time","NC_CHAR",object at time)
}
)

Define an inherited method for class OPSource:
setMethod("ncputVar",signature(nc="NetCDF",variable="ANY",object="OPSource"),
    def=function(nc,variable,object)
{
    att.put.nc(nc,variable,"srctype","NC_CHAR","OPSource")
    att.put.nc(nc,variable,"oporig","NC_CHAR",object at oporig)
    callNextMethod()
}
)

A call to ncputVar with an OPSource object causes an error saying object 
is not present.
But if the method definition is changed like this:

setMethod("ncputVar",signature(nc="NetCDF",variable="ANY",object="OPSource"),
    def=function(nc,variable,object)
{
    o = object
    att.put.nc(nc,variable,"srctype","NC_CHAR","OPSource")
    att.put.nc(nc,variable,"oporig","NC_CHAR",object at oporig)
    callNextMethod(nc,variable,o)
}
)

there is no more an error.
Why does my "object" disappear?

Thanks to all.
Harold

-- 
*********************************************************
Harold PETITHOMME
Equipe Donn?es et Outils de Pr?vision (DPREVI/COMPAS/DOP)

M?t?o France - Direction de la Production
42, avenue G. Coriolis.
31057 Toulouse Cedex
France

Tel : (33/0)5.61.07.82.85
Fax : (33/0)5.61.07.86.09
E-mail : harold.petithomme at meteo.fr


From wht_crl at yahoo.com  Thu Sep 23 18:16:14 2010
From: wht_crl at yahoo.com (carol white)
Date: Thu, 23 Sep 2010 09:16:14 -0700 (PDT)
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <4C9B40A5.8070101@statistik.tu-dortmund.de>
Message-ID: <161864.23208.qm@web62006.mail.re1.yahoo.com>

I used the 2.10.0 version

--- On Thu, 9/23/10, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
> Subject: Re: [Rd] some problems reported in 00check.log
> To: "carol white" <wht_crl at yahoo.com>
> Cc: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>, r-devel at r-project.org
> Date: Thursday, September 23, 2010, 4:57 AM

> 
> If this is R > 2.10.0, it is expected. Static html files
> are not 
> generated upon installation any more. Contents is generated
> dynamically 
> upon request now.
>


From ligges at statistik.tu-dortmund.de  Thu Sep 23 18:21:09 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2010 18:21:09 +0200
Subject: [Rd] some problems reported in 00check.log
In-Reply-To: <161864.23208.qm@web62006.mail.re1.yahoo.com>
References: <161864.23208.qm@web62006.mail.re1.yahoo.com>
Message-ID: <4C9B7E75.9040001@statistik.tu-dortmund.de>



On 23.09.2010 18:16, carol white wrote:
> I used the 2.10.0 version

My apologies, I actually meant  R >= 2.10.0
and hence it is not a surprise.

Best,
Uwe Ligges


> --- On Thu, 9/23/10, Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>
>> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
>> Subject: Re: [Rd] some problems reported in 00check.log
>> To: "carol white"<wht_crl at yahoo.com>
>> Cc: "Prof Brian Ripley"<ripley at stats.ox.ac.uk>, r-devel at r-project.org
>> Date: Thursday, September 23, 2010, 4:57 AM
>
>>
>> If this is R>  2.10.0, it is expected. Static html files
>> are not
>> generated upon installation any more. Contents is generated
>> dynamically
>> upon request now.
>>
>
>
>


From b.rowe at baml.com  Fri Sep 24 00:44:06 2010
From: b.rowe at baml.com (Rowe, Brian - Eqty NY)
Date: Thu, 23 Sep 2010 18:44:06 -0400
Subject: [Rd] Behavior of R CMD build and library() w.r.t. setGeneric-like
	functions
Message-ID: <CD52DB5226F62F4EBC1116CD5E9BE898021B14DA@ex2k.bankofamerica.com>

Hello developeRs,

Apologies in advance for a rather long email, but to describe the
problem, I need to step through many details. I have been working on a
new dispatching system (futile.paradigm on CRAN) based on functional
programming concepts that is an alternative to S3 and S4 dispatching. I
use a declarative syntax using guard statements to control the
dispatching between function variants. I also provide post assertions
via an 'ensure' command that programatically behave similar to the
'guard' command. In a sense, these work like setGeneric/setMethod in S4.

As a simple example, I write code like this:
  guard(month.date, isa(Date,date))
  ensure(month.date, as.numeric(result) < 13)
  month.date <- function(date) format(date, '%m')

  guard(month.int, is.numeric(date))
  month.int <- function(date) month(i2date(date))

and call it like this:
  > month(20100913)
  [1] "09"

Behind the scenes, the guard command is using 'assign' to create a
parent function with the name 'month'. This can be done explicitly as
well, although it is typically not necessary. The parent definition
looks like this:
  month <- function(...) UseFunction('month',...)

The package works fine when I'm writing scripts, but all heck breaks
loose when I try to write a package that depends on futile.paradigm.
When I run R CMD check, it doesn't seem that the guard commands are
being executed. A less likely hypothesis is that they are being deleted
by the cleanEx() function.

* checking examples ... ERROR
Running examples in 'pars.core-Ex.R' failed.
The error most likely occurred in:
>   set_date(20100921)
Error: could not find function "set_date"
Execution halted

If I add the explicit function definition for 'month' as shown above, I
get one of my own error messages indicating that no guard statements
were executed.

>   set_date(20100921)
Error in UseFunction("set_date", ...) :
  Function must have guards for functional dispatching
Calls: set_date -> UseFunction
Execution halted

I decided to bypass the check process and just install the built package
to see if it is an issue with check as opposed to the package.
Unfortunately, it seems that when the package is built, the guard
commands get stripped from the package.

> library(futile.paradigm)
Loading required package: futile.options
> debug(guard)
> library(pars.core)
Loading required package: futile.logger 

It's unclear to me why this happens when setClass, setGeneric, etc work
under seemingly similar conditions. Is this because of the export*
declarations in the NAMESPACE? What happens in the R CMD build process
that strips these function calls and their side-effects? Finally, what
do I need to do to make my 'guard' and 'ensure' commands operate
properly in a package context?

Warm Regards,
Brian Rowe

----------------------------------------------------------------------
This message w/attachments (message) is intended solely ...{{dropped:7}}


From b.rowe at baml.com  Fri Sep 24 20:24:59 2010
From: b.rowe at baml.com (Rowe, Brian - Eqty NY)
Date: Fri, 24 Sep 2010 14:24:59 -0400
Subject: [Rd] Behavior of R CMD build and library() w.r.t.
	setGeneric-likefunctions
In-Reply-To: <CD52DB5226F62F4EBC1116CD5E9BE898021B14DA@ex2k.bankofamerica.com>
References: <CD52DB5226F62F4EBC1116CD5E9BE898021B14DA@ex2k.bankofamerica.com>
Message-ID: <CD52DB5226F62F4EBC1116CD5E9BE898022509EC@ex2k.bankofamerica.com>

FYI I resolved this with a combination of explicit variable declarations
and tweaking namespace environment visibility. I'd still like to get a
better understanding of how setGeneric is able to define functions that
are visible without the explicit variable declarations. Any insight into
this is appreciated.

Regards,
Brian

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Rowe, Brian - Eqty
NY
Sent: Thursday, September 23, 2010 6:44 PM
To: r-devel at r-project.org
Subject: [Rd] Behavior of R CMD build and library() w.r.t.
setGeneric-likefunctions

Hello developeRs,

Apologies in advance for a rather long email, but to describe the
problem, I need to step through many details. I have been working on a
new dispatching system (futile.paradigm on CRAN) based on functional
programming concepts that is an alternative to S3 and S4 dispatching. I
use a declarative syntax using guard statements to control the
dispatching between function variants. I also provide post assertions
via an 'ensure' command that programatically behave similar to the
'guard' command. In a sense, these work like setGeneric/setMethod in S4.

As a simple example, I write code like this:
  guard(month.date, isa(Date,date))
  ensure(month.date, as.numeric(result) < 13)
  month.date <- function(date) format(date, '%m')

  guard(month.int, is.numeric(date))
  month.int <- function(date) month(i2date(date))

and call it like this:
  > month(20100913)
  [1] "09"

Behind the scenes, the guard command is using 'assign' to create a
parent function with the name 'month'. This can be done explicitly as
well, although it is typically not necessary. The parent definition
looks like this:
  month <- function(...) UseFunction('month',...)

The package works fine when I'm writing scripts, but all heck breaks
loose when I try to write a package that depends on futile.paradigm.
When I run R CMD check, it doesn't seem that the guard commands are
being executed. A less likely hypothesis is that they are being deleted
by the cleanEx() function.

* checking examples ... ERROR
Running examples in 'pars.core-Ex.R' failed.
The error most likely occurred in:
>   set_date(20100921)
Error: could not find function "set_date"
Execution halted

If I add the explicit function definition for 'month' as shown above, I
get one of my own error messages indicating that no guard statements
were executed.

>   set_date(20100921)
Error in UseFunction("set_date", ...) :
  Function must have guards for functional dispatching
Calls: set_date -> UseFunction
Execution halted

I decided to bypass the check process and just install the built package
to see if it is an issue with check as opposed to the package.
Unfortunately, it seems that when the package is built, the guard
commands get stripped from the package.

> library(futile.paradigm)
Loading required package: futile.options
> debug(guard)
> library(pars.core)
Loading required package: futile.logger 

It's unclear to me why this happens when setClass, setGeneric, etc work
under seemingly similar conditions. Is this because of the export*
declarations in the NAMESPACE? What happens in the R CMD build process
that strips these function calls and their side-effects? Finally, what
do I need to do to make my 'guard' and 'ensure' commands operate
properly in a package context?

Warm Regards,
Brian Rowe

----------------------------------------------------------------------
This message w/attachments (message) is intended solely ...{{dropped:7}}

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

----------------------------------------------------------------------
This message w/attachments (message) is intended solely ...{{dropped:7}}


From radford at cs.toronto.edu  Fri Sep 24 23:06:13 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Fri, 24 Sep 2010 17:06:13 -0400
Subject: [Rd] Fourteen patches to speed up R
In-Reply-To: <alpine.DEB.2.00.1009222018170.1743@luke-inspiron>
References: <20100903172719.GA5284@cs.toronto.edu>
	<alpine.DEB.2.00.1009222018170.1743@luke-inspiron>
Message-ID: <20100924210613.GA28338@cs.toronto.edu>

Luke - Thanks for your comments on the speed patches I submitted.  
I'm glad you like patch-transpose, patch-for, patch-evalList, and
patch-vec-arith.  I'll be interested to hear what you or other people
think about patch-dollar and patch-vec-subset after you've had more
time to consider them.  (Recall I later posted a split of
patch-vecsubset into patch-vec-subset and a new patch-subscript,
fixing in patch-subscript a bug in my original combined patch.)

Regarding patch-square and patch-sum-prod, you make different changes
that address the largest inefficiencies, but I'd like to do some runs
comparing your version with mine to see how big the remaining
differences are.  This is complicated by the fact that your changes to
sum and prod seem to encounter a bug in the C compiler I'm using (gcc
4.2.4 for i486-linux-gnu) at optimization level -O2 (the default for
the R configuration), the effect of which is for sum to deliver the
right answer, but just as slowly as before.  This doesn't happen with
-O3.  I'll investigate this further and report the conclusion.

Similarly, I'll do some more timing tests regarding patch-protect,
patch-fast-base, patch-fast-spec, and patch-save-alloc, and then
comment further on the gains that they produce.

Regarding patch-matprod, the issue of what BLAS routines do with NaN
and NA seems like it's one that needs to be resolved, preferably in a
way that doesn't slow down vector dot products by a factor of six.
However, I don't know what actual problem reports motivated the
current costly check for NAs.  This all interacts with the extreme
slowness on some machines of arithmetic on LDOUBLEs, which also seems
like it needs some resolution.  It's not clear to me what the
expectations regarding accuracy of functions like sum should be.  
One could certainly argue that users would expect the same accuracy 
as adding them up with "+", and no huge slowdown from trying to get
better accuracy.  But maybe there's some history here, or packages
that depend on increased accuracy (though of course there's no
guarantee that a C "long double" will actually be bigger than a
"double".)

Regarding patch-parens, I don't understand your reluctance to
incorporate this two-line code change.  According to my timing tests
(medians of five runs), it speeds up the test-parens.r script by 4.5%.
(Recall this is "for (i in 1:n) d <- (a+1)/(a*(b+c))".)  This is not 
a huge amount, but of course the speedup for the actual parenthesis
operator is greater, since there is other overhead in this test.  It
would be even better to make all BUILTIN operators faster (which my
patch-evalList does), but there are limits to how much is possible.

The fact that "(" is conceptually a BUILTIN rather than a SPECIAL
doesn't seem relevant to me.  "{" is also conceptually a BUILTIN.
Both are "special" from the point of view of the users, few of whom
will even imagine that one could call "(" and "{" as ordinary
functions.  Even if they can imagine this, it makes no difference,
since the patch has no user-visible effects.  If one is worried that
someone reading the code in src/main/eval.c might become confused
about the semantics of parentheses, a two-line comment saying "Parens
are conceptually a BUILTIN but are implemented as a SPECIAL to bypass
the overhead of creating an evaluated argument list" would avoid any
problem.

As an analogy, consider a C compiler generating code for "2*x".  One
could argue that multiplication is conceptually repeated addition, so
converting this to "x+x" is OK, but converting it to "x<<1" would be
wrong.  But I think no one would argue this.  Rather, everyone would
expect the compiler to choose between "x+x" and "x<<1" purely on the
basis of which one is faster.

    Radford


From ronggui.huang at gmail.com  Sat Sep 25 05:59:04 2010
From: ronggui.huang at gmail.com (Wincent)
Date: Sat, 25 Sep 2010 11:59:04 +0800
Subject: [Rd] error with browseURL
Message-ID: <AANLkTikjzWhpQ2nT-EouYKj4Lr2cP0Rto7X+nVijdJLK@mail.gmail.com>

> link="http://search.soufun.com/bbs/search.jsp?fld=all&city=%b9%e3%d6%dd&forum=%bd%f1%c8%d5%c0%f6%c9%e1%28%e2%f9%be%b0%bb%a8%d4%b0%29&sl=post&q=%c4%cf%b9%fa%b0%c2%c1%d6%c6%a5%bf%cb%bb%a8%d4%b0%20%ce%ac%c8%a8&serachtype=all&fw=forum&sort=score&imageField.x=25&imageField.y=8"
> browseURL(link)
Error in shell.exec(url) : file name conversion problem
> sessionInfo()
R version 2.11.1 Patched (2010-08-25 r52804)
Platform: i386-pc-mingw32 (32-bit)

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
[2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

The problem remains in R 2.12.0.

Best

-- 
Wincent Rong-gui HUANG
Doctoral Candidate
Dept of Public and Social Administration
City University of Hong Kong
http://asrr.r-forge.r-project.org/rghuang.html


From hpages at fhcrc.org  Sat Sep 25 09:30:28 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 25 Sep 2010 00:30:28 -0700
Subject: [Rd] Lack of consistent cross-platform behaviour
	of	tools:::buildVignettes()
In-Reply-To: <4C91A31E.4020500@fhcrc.org>
References: <4C91A31E.4020500@fhcrc.org>
Message-ID: <4C9DA514.8070101@fhcrc.org>

Hi,

In current R-alpha (r52991), consistent cross-platform behavior
has been restored, thanks!
That is, on both Unix and Windows, ${R_HOME}/bin/R doesn't add
variables to the environment, but ${R_HOME}/bin/R CMD does.

Is there any reason why ${R_HOME}/bin/R couldn't add those variables
to the environment too (on both platforms of course) so the code
in the examples and vignettes that is run during R CMD check
sees the same environment as if run interactively?

The example I gave below with buildVignettes() is a situation where
it runs fine if run by 'R CMD check' but fails if run interactively.

Thanks!
H.


On 09/15/2010 09:54 PM, Herv? Pag?s wrote:
> Hi,
>
> On both Unix and Windows there is a mechanism to add variables
> to the environment when R is started. I noticed that, on Unix,
> this mechanism is not used when R is started normally at the
> command line but only when it's started using the 'R CMD' syntax.
> One problem with this is some lack of consistent cross-platform
> behaviour. For example:
>
> On Linux:
>
> $ echo $TEXINPUTS
>
> $ echo "Sys.getenv('TEXINPUTS')" | R --slave
> TEXINPUTS
> ""
> But on Windows:
>
> E:\tmp>echo %TEXINPUTS%
> %TEXINPUTS%
> E:\tmp>echo Sys.getenv("TEXINPUTS") | R\bin\R.exe --slave
> TEXINPUTS
> ".;;E:/biocbld/bbs-2.7-bioc/R/share/texmf/tex/latex;"
>
> So on Linux if I cd to the inst/doc folder of a package source tree
> that has a Makefile and run
>
> echo "tools:::buildVignettes('pkgname', '.')" | R --slave
>
> it fails with error:
>
> ! LaTeX Error: File `Sweave.sty' not found.
>
> while doing the same thing on Windows works.
>
> Is there any reason for not setting the environments variables
> that are defined in ${R_HOME}/bin/Rcmd (the shell script wrapper
> for all R CMD commands) when R is started normally?
>
> Thanks,
> H.
>
> BTW, I found this (on both, Unix and Windows):
>
> $ echo "Sys.getenv('TEXINPUTS')" | R
> Fatal error: you must specify '--save', '--no-save' or '--vanilla'
>
> What about --slave? Thanks!
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Sat Sep 25 09:32:17 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 25 Sep 2010 00:32:17 -0700
Subject: [Rd] running 'make' failed during vignette creation ('R CMD
 build') on Windows
In-Reply-To: <4C91BA56.6040209@fhcrc.org>
References: <4C915CF1.9020304@fhcrc.org> <4C91BA56.6040209@fhcrc.org>
Message-ID: <4C9DA581.6090602@fhcrc.org>

This fixed in current R-alpha (r52991) too. Thanks!

H.


On 09/15/2010 11:33 PM, Herv? Pag?s wrote:
> I think I found the problem. During the recent transition from
> Perl-based to R-based 'R CMD check/build', the rcmdfn() function
> in src/gnuwin32/front-ends/rcmdfn.c has been hacked quite a bit.
> This function gets called right after the R front-end is started
> and its main purpose is to process the user arguments passed to
> the front-end and to fire the appropriate subprocess.
> This function also calls process_Renviron() for putting the
> variables defined in ${R_HOME}/etc/rcmd_environ into the
> environment of the front-end process.
>
> Problem: before revision 52153
>
> this code
> ...
> } else if (strcmp(p, "build") == 0) {
> snprintf(cmd, CMD_LEN, "perl %s/bin/build.pl", RHome);
> } ...
>
> was *after* this line
>
> process_Renviron(env_path);
>
> But starting with rev 52153, it was moved *before* the call to
> process_Renviron() (and also modified to handle Rcmd build
> internally). The new code looks more complicated:
>
> ...
> } else if (cmdarg > 0 && argc > cmdarg &&
> strcmp(argv[cmdarg], "build") == 0) {
> /* handle Rcmd build internally */
> snprintf(cmd, CMD_LEN,
> "%s/%s/Rterm.exe -e tools:::.build_packages() R_DEFAULT_PACKAGES=
> LC_COLLATE=C --no-restore --slave --args ",
> getRHOME(3), BINDIR);
> for (i = cmdarg + 1; i < argc; i++) {
> strcat(cmd, "nextArg");
> if (strlen(cmd) + strlen(argv[i]) > 9900) {
> fprintf(stderr, "command line too long\n");
> return(27);
> }
> strcat(cmd, argv[i]);
> }
> status = system(cmd);
> return(status);
> } else {
> ...
>
> but basically, it still fires a subprocess and then the function
> returns. process_Renviron() was not called so the subprocess
> doesn't see those environment variables anymore.
>
> Then the same happened to 'R CMD build' (rev 52245), and to many
> other 'R CMD things': their corresponding code chunks in rcmdfn()
> went moved up one by one to end up before the call to
> process_Renviron(). So none of the 'R CMD' subcommands sees
> the environment variables that they used to see anymore. Only
> a normal 'R' command still gets them.
>
> Cheers,
> H.
>
>
> On 09/15/2010 04:55 PM, Herv? Pag?s wrote:
>> Hi,
>>
>> This is a follow-up to the problem reported here:
>>
>> https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html
>>
>> After I updated R-2.12 to 2010-09-13 r52905 on the Bioc build system,
>> some of the packages that have a Makefile in <pkg>/inst/doc still
>> don't build on Windows. For example, 'R\bin\R.exe CMD build adSplit'
>> gives:
>>
>> * checking for file 'adSplit/DESCRIPTION' ... OK
>> * preparing 'adSplit':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * installing the package to re-build vignettes
>> * creating vignettes ... ERROR
>> Loading required package: Biobase
>>
>> Welcome to Bioconductor
>>
>> Vignettes contain introductory material. To view, type
>> 'openVignette()'. To cite Bioconductor, see
>> 'citation("Biobase")' and for packages 'citation(pkgname)'.
>>
>> Loading required package: DBI
>> Loading required package: hu6800.db
>> Loading required package: AnnotationDbi
>> Loading required package: org.Hs.eg.db
>> determining 1000 random DLD-scores with 20 probe sets each (wait for 10
>> dots)
>> ..........
>> epstopdf splitSet.eps
>> pdflatex tr_2005_02
>> This is pdfTeX, Version 3.1415926-1.40.9 (MiKTeX 2.7)
>> entering extended mode
>> (tr_2005_02.tex
>> LaTeX2e <2009/09/24>
>> Babel <v3.8l> and hyphenation patterns for english, dumylang,
>> nohyphenation, ge
>> rman, ngerman, french, loaded.
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\base\report.cls"
>> Document Class: report 2007/10/19 v1.4h Standard LaTeX document class
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\base\size11.clo")) (compdiag.sty
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifpdf.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphicx.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\keyval.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\graphics.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\trig.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\graphics.cfg")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\pdftex-def\pdftex.def")))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\graphics\color.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\color.cfg"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hyperref.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ltxcmds.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\kvsetkeys.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\infwarerr.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\etexcmds.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdfescape.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\pdftexcmds.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifluatex.sty")))
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\ifvtex.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ifxetex\ifxetex.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\hycolor.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\xcolor-patch.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\letltxmacro.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\pd1enc.def")
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\intcalc.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\00miktex\hyperref.cfg")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\kvoptions.sty")
>> Implicit mode ON; LaTeX internals redefined
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ltxmisc\url.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bitset.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\bigintcalc.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\atbegshi.sty"))
>> * hyperref using driver hpdftex *
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\hyperref\hpdftex.def"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\atveryend.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\oberdiek\rerunfilecheck.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\generic\oberdiek\uniquecounter.sty")))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ntgclass\a4.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\geometry\geometry.cfg"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\theorem.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thp.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\tools\thb.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsmath.sty"
>> For additional information on amsmath, use the `?' option.
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amstext.sty"
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsgen.sty"))
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsbsy.sty")
>> ("C:\Program Files\MiKTeX 2.7\tex\latex\ams\math\amsopn.sty"))
>>
>> ! LaTeX Error: File `Sweave.sty' not found.
>>
>> Type X to quit or <RETURN> to proceed,
>> or enter new name. (Default extension: sty)
>>
>> Enter file name:
>> ! Emergency stop.
>> <read *>
>>
>> l.39 \begin
>> {document}
>> ! ==> Fatal error occurred, no output PDF file produced!
>> Transcript written on tr_2005_02.log.
>> make: *** [pdf] Error 1
>> Error in tools::buildVignettes(dir = ".") : running 'make' failed
>> Execution halted
>>
>> What's different though with this updated R, it that now I get an
>> error instead of a timeout. Maybe the code that fires the R subprocess
>> in charge of running tools::buildVignettes() now does better error
>> checking/handling, I don't know (it seems to have changed between
>> the 2 versions of R).
>>
>> A new mystery is why the tilingArray package now does build on
>> Windows (it was timing out with the previous version of R).
>> I already sent the content of adSplit/inst/doc/Makefile
>> in the previous thread and tilingArray does nothing different:
>>
>> all: findsegments costMatrix assessNorm segmentation plotAlongChrom clean
>>
>> findsegments: findsegments.tex
>> pdflatex findsegments
>> pdflatex findsegments
>>
>> costMatrix: costMatrix.tex
>> pdflatex costMatrix
>> pdflatex costMatrix
>>
>> assessNorm: assessNorm.tex
>> cp -p ../scripts/assessNorm.pdf .
>>
>> segmentation: segmentation.tex
>> cp -p ../scripts/segmentation.pdf .
>>
>> plotAlongChrom: plotAlongChrom.tex
>> pdflatex plotAlongChrom
>> pdflatex plotAlongChrom
>> clean:
>> rm -f *.out *.bbl *.log *.aux *.blg *.brf *.toc *.tex
>> rm -f *.dvi *.ps findsegments-* costMatrix-* plotAlongChrom-* Rplots.pdf
>>
>> Another thing that is really puzzling is that if I cd to
>> adSplit/inst/doc and run 'R CMD make' then it works.
>>
>> Any help/comment on this will be highly appreciated.
>>
>> Thanks,
>> H.
>>
>>
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cstrato at aon.at  Sat Sep 25 15:02:43 2010
From: cstrato at aon.at (cstrato)
Date: Sat, 25 Sep 2010 15:02:43 +0200
Subject: [Rd] Problem with WARNING...headers with CRLF line endings
In-Reply-To: <4C91406D.5000102@fhcrc.org>
References: <4C8E9297.5050806@aon.at>	<77EB52C6DD32BA4D87471DCD70C8D700036E87E6@NA-PA-VBE03.na.tibco.com>	<4C8FBE96.6080604@aon.at>	<69C89B57-A641-44D3-A95D-D95A5AD6B2A6@r-project.org>	<4C8FE527.6060308@aon.at>	<4C8FE9EE.60604@fhcrc.org>	<4C8FF01B.6060208@aon.at>	<4C8FF268.9010500@fhcrc.org>	<4C8FF78F.5020407@gmail.com>	<4C900C09.2010509@fhcrc.org>	<4C912EEF.5050701@aon.at>
	<19601.12781.231933.777847@max.nulle.part>
	<4C91406D.5000102@fhcrc.org>
Message-ID: <4C9DF2F3.6010307@aon.at>

Dear Herve,

I have just tested the modification of Makefile.win:

clean:
	rm -f $(MYOBJ) *.a *.d *.rc xpsLinkDef.h

and it was sufficient to eliminate the warning message.
Thus R CMD check seems indeed to run the clean step.

I have just uploaded the new version to BioC2.7.

Best regards
Christian


On 9/15/10 11:53 PM, Herv? Pag?s wrote:
> On 09/15/2010 01:51 PM, Dirk Eddelbuettel wrote:
>>
>> On 15 September 2010 at 22:39, cstrato wrote:
>> | Dear Duncan, dear Herve,
>> |
>> | Thank you both for your help and suggestions. I think that you are both
>> | right:
>> |
>> | In principle I do not want to put these files in the source tarball
>> (and
>> | I did not in the past), however because of the way R CMD check works
>> | this seems to be the only possibility to get rid of the warning
>> message.
>> |
>> | I agree that it is weird to get this warning message although these
>> | files are not in the source tarball.
>> |
>> | Since I have a Makefile, as Herve mentions, I can try to remove these
>>
>> If you have a Makefile, then you have implicit rules as well as explicit
>> ones. That is how the file gets created.
>>
>> Now modify the rules and insert another layer which will do the
>> filtering. As
>> the saying goes: "there is no problem that cannot be solved by adding
>> another layer of indirection". Instead of requiring the generated file,
>> require the generated and filtered file.
>>
>> | files in the clean step, which currently is:
>> |
>> | clean:
>> | rm -f $(MYOBJ) *.a *.d *.rc
>> |
>> | I will try to change this part but I am not sure if this will solve the
>> | problem.
>>
>> I fear that the clean step runs too late.
>
> But shouldn't 'R CMD check' run the clean step (if it runs it at all)
> right after the 'R CMD INSTALL' step?
>
> Cheers,
> H.
>
>


From spinuvit.list at gmail.com  Sun Sep 26 16:37:50 2010
From: spinuvit.list at gmail.com (Vitally S.)
Date: Sun, 26 Sep 2010 16:37:50 +0200
Subject: [Rd] strange behaviour of callNextMethod in S4 methods
In-Reply-To: <4C9B6257.8070500@meteo.fr> (Harold PETITHOMME's message of "Thu, 
	23 Sep 2010 16:21:11 +0200")
References: <4C9B6257.8070500@meteo.fr>
Message-ID: <cpnk4m8muyp.fsf@gmail.com>

Harold PETITHOMME <harold.petithomme at meteo.fr> writes:

Hi,
>
> there is no more an error.
> Why does my "object" disappear?

I cannot reproduce your problem.

Here is an example identical to yours:

setClass("foo", list(a = "character", b = "numeric"), proto = 100,
         contains = "numeric")
setClass("boo", list(c = "numeric"), contains = "foo")


setGeneric("meth",
           def=function(variable, object, nc) standardGeneric("

setMethod("meth",signature(variable="ANY",object="numeric", nc="foo"),
            def=function(variable,object, nc)
            {
              nc at a <- as.character(variable)
              nc at b <- object+5
              nc
            }
            )

meth( 2432, 22, new("foo"))

setMethod("meth", signature(variable="ANY",object="numeric", nc="boo"),
            def=function(variable, object, nc)
            {
              nc at c <- object+10
              callNextMethod()
            }
            )
meth(4232, 22, new("boo")) ##works ok


Everything works as expected.

Vitaly.

>
> Thanks to all.
> Harold


From elgorgonzola at hotmail.com  Mon Sep 27 16:44:56 2010
From: elgorgonzola at hotmail.com (elgorgonzola)
Date: Mon, 27 Sep 2010 07:44:56 -0700 (PDT)
Subject: [Rd] Incorporate graphic files into R-package
Message-ID: <1285598696018-2715520.post@n4.nabble.com>


Hi,

I am working on a package which will be used to generate reports using
Sweave. The createReport() function should create a folder and Rnw/tex-files
automatically. The reports should, however, also feature the company logo. I
don't want to have to manually copy the image file into the folder each time
a report is created. I don't know if it is possible or not but I would like
to somehow store the graphic-file within the package and have the
createReport() automatically copy it to the appropriate folder. Does anyone
have an idea how this could be achieved?
I'm thinking of something similar to the way data is stored as a RData-file
in the data-path of a package and is accessed via load() once the package is
loaded.

Thanks in advance and hava a great day.

El

-- 
View this message in context: http://r.789695.n4.nabble.com/Incorporate-graphic-files-into-R-package-tp2715520p2715520.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Mon Sep 27 17:31:22 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Sep 2010 11:31:22 -0400
Subject: [Rd] Incorporate graphic files into R-package
In-Reply-To: <1285598696018-2715520.post@n4.nabble.com>
References: <1285598696018-2715520.post@n4.nabble.com>
Message-ID: <4CA0B8CA.1040807@gmail.com>

  On 27/09/2010 10:44 AM, elgorgonzola wrote:
> Hi,
>
> I am working on a package which will be used to generate reports using
> Sweave. The createReport() function should create a folder and Rnw/tex-files
> automatically. The reports should, however, also feature the company logo. I
> don't want to have to manually copy the image file into the folder each time
> a report is created. I don't know if it is possible or not but I would like
> to somehow store the graphic-file within the package and have the
> createReport() automatically copy it to the appropriate folder. Does anyone
> have an idea how this could be achieved?
> I'm thinking of something similar to the way data is stored as a RData-file
> in the data-path of a package and is accessed via load() once the package is
> loaded.
>
> Thanks in advance and hava a great day.

Read about the "inst" directory in Writing R Extensions.  You can put 
your logo there, it will be installed when your package is installed, 
and your Sweave document can find it using system.file("path within 
package", package="yourpackage") to copy to the output directory.

Duncan Murdoch


From hpages at fhcrc.org  Mon Sep 27 19:47:20 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 27 Sep 2010 10:47:20 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C916321.9050108@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org>	<4C8C94A3.3080600@gmail.com>	<4C8CA70C.40109@fhcrc.org>	<4C8F613E.8070407@statistik.tu-dortmund.de>	<4C8FBDB0.4060106@fhcrc.org>
	<4C916321.9050108@fhcrc.org>
Message-ID: <4CA0D8A8.6000505@fhcrc.org>

Hi,

Something I should mention too, and I don't know whether it is
related to the "'R CMD' confusion" issue I described previously,
is that with the migration from Perl-based to R-based 'R CMD build',
we also started to see the following 'R CMD build' error on Windows:

R\bin\R.exe CMD build cosmoGUI
* checking for file 'cosmoGUI/DESCRIPTION' ... OK
* preparing 'cosmoGUI':
* checking DESCRIPTION meta-information ... OK
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/DESCRIPTION: Cannot change 
ownership to uid 0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/man/constraintBuilder.Rd: Cannot 
change ownership to uid 0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/man: Cannot change ownership to 
uid 0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/NAMESPACE: Cannot change 
ownership to uid 0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/R/gui.R: Cannot change ownership 
to uid 0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI/R: Cannot change ownership to uid 
0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: cosmoGUI: Cannot change ownership to uid 
0, gid 401: Invalid argument
/cygdrive/c/RTOOLS?1/bin/tar: Exiting with failure status due to 
previous errors
  ERROR
copying to build directory failed

Like for the "'R CMD' confusion" issue, this error will show up
randomly everyday on our build report for around 10% of the
Bioconductor packages.

This is with 2.12.0 alpha (2010-09-24 r52991) on Windows Server 2003 R2
(32-bit). The tar command used is from current Rtools212.

Cheers,
H.


On 09/15/2010 05:21 PM, Herv? Pag?s wrote:
> On 09/14/2010 11:23 AM, Herv? Pag?s wrote:
>> Hi Uwe,
>>
>> On 09/14/2010 04:49 AM, Uwe Ligges wrote:
> ...
>>> Brian had some ideas that the problems are related to the shell that is
>>> used. Is the problem still apparent in a very recent R-devel from few
>>> days ago? I am just back from vacations and have not updated yet.
>>> I experienced the same problems and I am just iterating automatically if
>>> typical problems are apparent from the log files. I hope some if not all
>>> parts are solved now and will do some new test runs shortly.
>>
>> Sounds good. I just upgraded to R-2.12 (2010-09-13 r52905) on our 32-bit
>> Windows machine and I'll report here tomorrow after the next build run
>> has completed. I can already see that this new R solves the issue I
>> reported here:
>>
>> https://stat.ethz.ch/pipermail/r-devel/2010-September/058460.html
>
> Not true sorry
> (https://stat.ethz.ch/pipermail/r-devel/2010-September/058530.html)
>
> As for the strange R CMD build/check errors on Windows I still see them.
> A sample of Today's Victims:
>
> R\bin\R.exe CMD build AffyCompatible
> * checking for file 'AffyCompatible/DESCRIPTION' ... OK
> * preparing 'AffyCompatible':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ... ERROR
> Error: ERROR: no packages specified
>
> R\bin\R.exe CMD build ArrayTools
> * checking for file 'ArrayTools/DESCRIPTION' ... OK
> * preparing 'ArrayTools':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> -----------------------------------
> Warning: unknown option '-l'
> * checking for file
> 'E:\biocbld\bbs-2.7-bioc\tmpdir\Rtmpbtur24\Rinst494950ff/DESCRIPTION'
> ... NO
> -----------------------------------
> ERROR: Installation failed
> Removing installation dir
>
> R\bin\R.exe CMD build baySeq
> * checking for file 'baySeq/DESCRIPTION' ... OK
> * preparing 'baySeq':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ...Warning in file(con, "r") :
> cannot open file
> 'E:\biocbld\bbs-2.7-bioc\tmpdir\RtmpKRrdst\xshell4d4a5c70': Permission
> denied
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
> R\bin\R.exe CMD build beadarray
> --> produces no output at all and returns code 0.
>
> etc...
>
> Cheers,
> H.
>
>
>>
>> Thanks!
>> H.
>>
>>
>>>
>>> Best,
>>> Uwe
>>>
>>>
>>>
>>>
>>>
>>>
>>>>>> Thanks,
>>>>>> H.
>>>>>>
>>>>>
>>>>> Antivirus software? I suspect you already ruled that out, but it has
>>>>> been the culprit for problems with mysteriously disappearing
>>>>> intermediate files in several cases, so I thought I'd mention it.
>>>>>
>>>>
>>>> Actually I didn't try that yet because we still build BioC release
>>>> (using R-2.11.1) on these 2 Windows boxes and we don't see any of
>>>> those problems for the release builds. But I will. Could it be that
>>>> the fact that 'R CMD build' and 'R CMD check' are R-based in R-2.12
>>>> (and not Perl-based anymore) make them more fragile when something
>>>> like an antivirus is messing around with the filesystem?
>>>>
>>>> Thanks for the suggestion,
>>>> H.
>>>>
>>
>>
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From Mike.Lawrence at dal.ca  Tue Sep 28 02:33:13 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Mon, 27 Sep 2010 21:33:13 -0300
Subject: [Rd] Function works when custom defined but not when part of a
	package
Message-ID: <AANLkTinwXUM9GajqbMEVwChhyqLY7X90uc1NDbZ3zMp1@mail.gmail.com>

Hi folks,

I'm not sure if this is a bug or not so I thought I'd check here
first. I came across it while working on an update to my package where
I try to get AICtab slot from the summary of an lmer object (
summary(my_lmer)@AICtab ). The attached contains a minimal example,
where the code  below will work if you load the f() function by
sourcing the package's R code but will throw an error ("trying to get
slot "AICtab" from an object (class "table") that is not an S4
object") if you load the f() function by installing and loading the
package itself.

library(lme4)
#here is where you would either source('f.R') or library(dummy)

#fit an lmer model (from ?lmer examples)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

#run f()
f(fm1)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dummy_0.0-1.tar.gz
Type: application/x-gzip
Size: 470 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100927/243c4318/attachment.gz>

From ligges at statistik.tu-dortmund.de  Tue Sep 28 11:48:43 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 28 Sep 2010 11:48:43 +0200
Subject: [Rd] Function works when custom defined but not when part of
 a	package
In-Reply-To: <AANLkTinwXUM9GajqbMEVwChhyqLY7X90uc1NDbZ3zMp1@mail.gmail.com>
References: <AANLkTinwXUM9GajqbMEVwChhyqLY7X90uc1NDbZ3zMp1@mail.gmail.com>
Message-ID: <4CA1B9FB.5010004@statistik.tu-dortmund.de>

I guess you forgot to import the relevant S4 functionality into your 
namespace.

Best,
Uwe



On 28.09.2010 02:33, Mike Lawrence wrote:
> Hi folks,
>
> I'm not sure if this is a bug or not so I thought I'd check here
> first. I came across it while working on an update to my package where
> I try to get AICtab slot from the summary of an lmer object (
> summary(my_lmer)@AICtab ). The attached contains a minimal example,
> where the code  below will work if you load the f() function by
> sourcing the package's R code but will throw an error ("trying to get
> slot "AICtab" from an object (class "table") that is not an S4
> object") if you load the f() function by installing and loading the
> package itself.
>
> library(lme4)
> #here is where you would either source('f.R') or library(dummy)
>
> #fit an lmer model (from ?lmer examples)
> fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>
> #run f()
> f(fm1)
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From elgorgonzola at hotmail.com  Tue Sep 28 15:31:17 2010
From: elgorgonzola at hotmail.com (elgorgonzola)
Date: Tue, 28 Sep 2010 06:31:17 -0700 (PDT)
Subject: [Rd] Incorporate graphic files into R-package
In-Reply-To: <4CA0B8CA.1040807@gmail.com>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
Message-ID: <1285680677823-2717204.post@n4.nabble.com>



Duncan Murdoch-2 wrote:
> 
>   On 27/09/2010 10:44 AM, elgorgonzola wrote:
> 
> Read about the "inst" directory in Writing R Extensions.  You can put 
> your logo there, it will be installed when your package is installed, 
> and your Sweave document can find it using system.file("path within 
> package", package="yourpackage") to copy to the output directory.
> 
> Duncan Murdoch
> 
> 

Thanks for the quick reply. I'll try that.

El
-- 
View this message in context: http://r.789695.n4.nabble.com/Incorporate-graphic-files-into-R-package-tp2715520p2717204.html
Sent from the R devel mailing list archive at Nabble.com.


From Mike.Lawrence at dal.ca  Tue Sep 28 17:41:51 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 28 Sep 2010 12:41:51 -0300
Subject: [Rd] Function works when custom defined but not when part of a
	package
In-Reply-To: <4CA1B9FB.5010004@statistik.tu-dortmund.de>
References: <AANLkTinwXUM9GajqbMEVwChhyqLY7X90uc1NDbZ3zMp1@mail.gmail.com>
	<4CA1B9FB.5010004@statistik.tu-dortmund.de>
Message-ID: <AANLkTikaU1YxwuWdLS5ecwiWH+uNsL3+yFuc7Yit+Lnh@mail.gmail.com>

Ah, "forgot" is a bit too generous. Seems I failed to get that far in
the Extensions manual because I never dealt with S4 classes until now.
Thanks for the pointer.

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



2010/9/28 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
> I guess you forgot to import the relevant S4 functionality into your
> namespace.
>
> Best,
> Uwe
>
>
>
> On 28.09.2010 02:33, Mike Lawrence wrote:
>>
>> Hi folks,
>>
>> I'm not sure if this is a bug or not so I thought I'd check here
>> first. I came across it while working on an update to my package where
>> I try to get AICtab slot from the summary of an lmer object (
>> summary(my_lmer)@AICtab ). The attached contains a minimal example,
>> where the code ?below will work if you load the f() function by
>> sourcing the package's R code but will throw an error ("trying to get
>> slot "AICtab" from an object (class "table") that is not an S4
>> object") if you load the f() function by installing and loading the
>> package itself.
>>
>> library(lme4)
>> #here is where you would either source('f.R') or library(dummy)
>>
>> #fit an lmer model (from ?lmer examples)
>> fm1<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>
>> #run f()
>> f(fm1)
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From karl.forner at gmail.com  Tue Sep 28 18:52:37 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 28 Sep 2010 18:52:37 +0200
Subject: [Rd] checking user interrupts in C(++) code
Message-ID: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100928/d8f390b6/attachment.pl>

From tal.galili at gmail.com  Tue Sep 28 20:14:50 2010
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 28 Sep 2010 20:14:50 +0200
Subject: [Rd] Bug report: Disappearing text when using a long "expression"
	in ylab
Message-ID: <AANLkTimA65P1muqxZbnvmqC7+czLnaCFniBu47svm8KJ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100928/75bae3ea/attachment.pl>

From simon.urbanek at r-project.org  Tue Sep 28 20:55:34 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 28 Sep 2010 14:55:34 -0400
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
Message-ID: <C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>

Karl,

On Sep 28, 2010, at 12:52 PM, Karl Forner wrote:

> My problem is that I have an extension in C++ that can be quite time-consuming. I'd like to make it interruptible.
> The problem is that if I use the recommended R_CheckUserInterrupt() method I have no possibility to cleanup (e.g. free the memory).
> 

You do and if you allow interrupts you have to. If you play by the rules, you don't need to do it specifically since R will take care of that. Interrupting an operation is far more complex than just signaling the interrupt - it involves collection of everything that needs to be cleaned on the way and your code is only a small part of it. The reason why interrupt is not allowed in random code is exactly that it's unsafe as many things could break and leak. When you use R_CheckUserInterrupt() you're vouching for your code that it is well written and will behave reasonably in the case of an interrupt.

There are several ways in which you can make your code respond to interrupts properly - which one is suitable depends on your application. Probably the most commonly used for interfacing foreign objects is to create an external pointer with a finalizer - that makes sure the object is released even if you pass it on to R later. For memory allocated within a call you can either use R's transient memory allocation (see Salloc) or use the on.exit handler to cleanup any objects you allocated manually and left over.


> I've seen an old thread about this, but I wonder if there's a new and
> definitive answer.
> 
> I just do not understand why a simple R_CheckUserInterrupt() like method
> returning a boolean could not be used.

Because that won't help since it involves running the event loop (otherwise users would have no way of actually triggering it) which in turn could trigger error handing and thus not return to your function, either. BTW: pretty much any call to R can trigger an error, so R_CheckUserInterrupt() is not the only place that requires you to think about cleanup.

Cheers,
Simon


From Weigand.Stephen at mayo.edu  Tue Sep 28 23:53:06 2010
From: Weigand.Stephen at mayo.edu (Weigand, Stephen D.)
Date: Tue, 28 Sep 2010 16:53:06 -0500
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
Message-ID: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>

I am connecting from a PC to a Linux system running CentOS
release 5.5 (Final) and it is extremely slow to render plots 
to the X11 device. 

This is not R's fault but I wonder if anyone can offer 
guidance so I can help the system administrators address 
the problem.

I can connect to the Linux server using a NoMachine NX client 
for Windows or using X-Win32. I also have access to R running 
on my Windows PC and an older version of R on Solaris which 
I connect to using X-Win32.

Using a test function of:

f <- function(n){
  for(i in 1:n) qqnorm(rnorm(100))
}
system.time(f(20))

I get typical timings of:

Platform Version Client    'type'  user  system elapsed
--------------------------------------------------------
Linux    2.11.0  NX client  cairo  1.012  0.131   7.155 
Linux    2.11.0  NX client  Xlib   0.964  0.127   7.119  

Linux    2.11.0  X-Win32    cairo  1.141  0.211  20.287
Linux    2.11.0  X-Win32    Xlib   1.116  0.207  20.152

Solaris  2.8.1   X-Win32    cairo  0.172  0.020   0.356
Solaris  2.8.1   X-Win32    Xlib   0.173  0.019   0.364

Win32    2.11.1  Native            0.03    0.22    0.25 


The Linux timings are just awful, particularly using 
X-Win32. Cairo vs. Xlib doesn't seem to matter much.

Does anybody have any suggestions on what to look into? 

I can work around the Linux problems by not using the X11 
device and instead writing a plot to a temporary PNG or 
PDF and using Eye of GNOME or Evince but that isn't ideal.
But I would welcome any tips in this regard.

The Linux sessionInfo is:

R version 2.11.0 (2010-04-22) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Thank you,

Stephen

--
Stephen Weigand, Statistician II
Biomedical Statistics and Informatics
(507) 266-1650; fax (507) 284-9542
Mayo Clinic; 200 First St. SW
Rochester, Minn., 55905 USA 


From herrold at owlriver.com  Wed Sep 29 00:19:07 2010
From: herrold at owlriver.com (R P Herrold)
Date: Tue, 28 Sep 2010 18:19:07 -0400 (EDT)
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
In-Reply-To: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
References: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
Message-ID: <alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>

On Tue, 28 Sep 2010, Weigand, Stephen D. wrote:

> I am connecting from a PC to a Linux system running CentOS
> release 5.5 (Final) and it is extremely slow to render plots
> to the X11 device.

> The Linux timings are just awful, particularly using
> X-Win32. Cairo vs. Xlib doesn't seem to matter much.

I have to think it is display rendering load at the displaying 
unit [an X server], or network latencies in getting the detail 
from the producer [an X client] to the displaying unit [an X 
server]

With centos 5 on a local X display [so the X client, and 
the X server do not have to push the content through the X 
fowarding and across the network sockets, but rather can go 
through the lo interface under Linux]:

> f <- function(n){
+   for(i in 1:n) qqnorm(rnorm(100))
+ }
> system.time(f(20))
    user  system elapsed
   0.220   0.028   2.417
>

which is quite sprightly ;)

-------------------

Then when I run it on the same hardware, but through two SSH 
hops, to, and back from a remote unit in the local subnet, 
things fall apart:

[herrold at centos-5 ~]$ ssh xps400
Last login: Tue Sep 28 11:00:05 2010 from centos-5.first.lan
[herrold at xps400 ~]$ ssh centos-5
herrold at centos-5's password:
Last login: Tue Sep 28 09:13:50 2010
[herrold at centos-5 ~]$ R
  ...
> f <- function(n){
+   for(i in 1:n) qqnorm(rnorm(100))
+ }
> system.time(f(20))
    user  system elapsed
   0.352   0.272  29.681
>

-------------------

I build my own R packaging under CentOS and do not have a 
packaging suitable for the architecture of that intermediate 
box -- installing R to a Debian testing box, and running the X 
forwarding connection only one hop, it is again visually 
rebdered MUCH slower.  I get:

> system.time(f(20))
    user  system elapsed
   0.644   0.212  45.089
>

yikes  ;)

I'll get a packaging built under CentOS 5 on that other 
architecture overnight, and supplement this post

-- Russ herrold


From hb at stat.berkeley.edu  Wed Sep 29 00:53:18 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 28 Sep 2010 15:53:18 -0700
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
In-Reply-To: <alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
References: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
	<alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
Message-ID: <AANLkTinVqnp8G3EawF0Th_EtcQr0tgmu_22L9yfwjFQ0@mail.gmail.com>

For whatever it is worth, a long time ago I had this problem when "ssh
-X" connecting to a server and doing simple plots such as plot(1:10).
It was painfully slow and I could see how each data points was
plotted.  After using X11.options(type="Xlib") in R things was back to
normal (fast) again.  I think the default before was
X11.options(type="cairo").

My $0.02

/Henrik

On Tue, Sep 28, 2010 at 3:19 PM, R P Herrold <herrold at owlriver.com> wrote:
> On Tue, 28 Sep 2010, Weigand, Stephen D. wrote:
>
>> I am connecting from a PC to a Linux system running CentOS
>> release 5.5 (Final) and it is extremely slow to render plots
>> to the X11 device.
>
>> The Linux timings are just awful, particularly using
>> X-Win32. Cairo vs. Xlib doesn't seem to matter much.
>
> I have to think it is display rendering load at the displaying unit [an X
> server], or network latencies in getting the detail from the producer [an X
> client] to the displaying unit [an X server]
>
> With centos 5 on a local X display [so the X client, and the X server do not
> have to push the content through the X fowarding and across the network
> sockets, but rather can go through the lo interface under Linux]:
>
>> f <- function(n){
>
> + ? for(i in 1:n) qqnorm(rnorm(100))
> + }
>>
>> system.time(f(20))
>
> ? user ?system elapsed
> ?0.220 ? 0.028 ? 2.417
>>
>
> which is quite sprightly ;)
>
> -------------------
>
> Then when I run it on the same hardware, but through two SSH hops, to, and
> back from a remote unit in the local subnet, things fall apart:
>
> [herrold at centos-5 ~]$ ssh xps400
> Last login: Tue Sep 28 11:00:05 2010 from centos-5.first.lan
> [herrold at xps400 ~]$ ssh centos-5
> herrold at centos-5's password:
> Last login: Tue Sep 28 09:13:50 2010
> [herrold at centos-5 ~]$ R
> ?...
>>
>> f <- function(n){
>
> + ? for(i in 1:n) qqnorm(rnorm(100))
> + }
>>
>> system.time(f(20))
>
> ? user ?system elapsed
> ?0.352 ? 0.272 ?29.681
>>
>
> -------------------
>
> I build my own R packaging under CentOS and do not have a packaging suitable
> for the architecture of that intermediate box -- installing R to a Debian
> testing box, and running the X forwarding connection only one hop, it is
> again visually rebdered MUCH slower. ?I get:
>
>> system.time(f(20))
>
> ? user ?system elapsed
> ?0.644 ? 0.212 ?45.089
>>
>
> yikes ?;)
>
> I'll get a packaging built under CentOS 5 on that other architecture
> overnight, and supplement this post
>
> -- Russ herrold
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Wed Sep 29 01:27:03 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 28 Sep 2010 16:27:03 -0700
Subject: [Rd] small inaccuracy in startup warning message
Message-ID: <4CA279C7.1010408@fhcrc.org>

Hi,

Cosmetic. Starting R with e.g. --max-ppsize=-10 produces the following 
warning:

   WARNING: '-max-ppsize' value is negative: ignored

The name of the option displayed in the warning is incorrect.

Could that be fixed? See src/main/CommandLineArgs.c (there are 3 places
in that file where the name of this option needs to be adjusted).

This is with current R-alpha.

Thanks!
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Wed Sep 29 06:19:14 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 28 Sep 2010 21:19:14 -0700
Subject: [Rd] temp Rscript file collision on Windows
Message-ID: <4CA2BE42.10304@fhcrc.org>

Hi,

The code below (found in src/gnuwin32/system.c) is almost
guaranteed to do the wrong thing if 2 Rterm processes are
started at the same time (or less than 1 second apart, the
resolution of time() being 1 second):

   /* tmpfile() seems not to work on Vista: it tries to write in c:/
   ifp = tmpfile();
   */
   {
       char *tm;
       tm = getenv("TMPDIR");
       if (!isDir(tm)) {
           tm = getenv("TMP");
           if (!isDir(tm)) {
               tm = getenv("TEMP");
               if (!isDir(tm))
                   tm = getenv("R_USER"); /* this one will succeed */
           }
       }
       srand( (unsigned) time(NULL) );
       sprintf(ifile, "%s/Rscript%x%x", tm, rand(), rand());
       ifp = fopen(ifile, "w+b");
       if(!ifp) R_Suicide(_("creation of tmpfile failed -- set TMPDIR 
suitably?"));
   }

Because the seed is set to whatever is returned by time(), it's
very easy to have 2 concurrent Rterm processes end up using the
same temp Rscript file. Note that calling rand() twice doesn't
help: if the 2 processes use the same seed, then the 2 consecutive
calls to rand() will generate the same pairs of numbers for the
2 processes.

An unfortunate consequence of this temp Rscript file collision
could very well be what we observe here:

   https://stat.ethz.ch/pipermail/r-devel/2010-September/058464.html

Could the PID be used instead? Something like this:

   sprintf(ifile, "%s/Rscript%dx%x", tm, getpid(), rand());

will surely be much safer. Furthermore, my understanding is that
a given Rterm process needs to create at most 1 temp Rscript file
so maybe using rand() is not even needed.

Note that Unix is safe because tmpfile() is used there (file
src/unix/system.c).

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From karl.forner at gmail.com  Wed Sep 29 10:31:00 2010
From: karl.forner at gmail.com (Karl Forner)
Date: Wed, 29 Sep 2010 10:31:00 +0200
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
	<C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
Message-ID: <AANLkTim-qxP3zZmmUpkQQc8Ztk4AERhpyokgAua36Lk2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100929/ba4a7be9/attachment.pl>

From csardi at rmki.kfki.hu  Wed Sep 29 11:54:24 2010
From: csardi at rmki.kfki.hu (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Wed, 29 Sep 2010 11:54:24 +0200
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <AANLkTim-qxP3zZmmUpkQQc8Ztk4AERhpyokgAua36Lk2@mail.gmail.com>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
	<C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
	<AANLkTim-qxP3zZmmUpkQQc8Ztk4AERhpyokgAua36Lk2@mail.gmail.com>
Message-ID: <AANLkTi=GSGFzhMPUcLV54xAgzVCbEYWNdKn3OjZF63Es@mail.gmail.com>

Karl,

I think you right, if you are not controlling all memory allocation,
then you cannot do anything.

In the igraph package, I keep a stack that contains all allocated
objects, and also their
destructor. In case of an error, or an interrupt, I go over the stack
and call all destructors.
(I use on.exit to call back again to C and free everything.)  It is
not optimal, but works
well, and it is very nice to be able to interrupt a long computation.

igraph is written in C, I am not sure how difficult it is to make this
work with C++.

If anyone has a better solution, please don't hesitate to enlighten us....

Best Regards,
Gabor

On Wed, Sep 29, 2010 at 10:31 AM, Karl Forner <karl.forner at gmail.com> wrote:
> Hi,
>
> Thanks for your reply,
>
>
> There are several ways in which you can make your code respond to interrupts
>> properly - which one is suitable depends on your application. Probably the
>> most commonly used for interfacing foreign objects is to create an external
>> pointer with a finalizer - that makes sure the object is released even if
>> you pass it on to R later. For memory allocated within a call you can either
>> use R's transient memory allocation (see Salloc) or use the on.exit handler
>> to cleanup any objects you allocated manually and left over.
>>
>
> Using ?R's transient memory allocation is not really an option when you use
> some code, like a library, not developed for R. Moreover what about c++ and
> the new operator ?
>
> One related question: if the code is interrupted, are C++ local objects
> freed ?
> Otherwise it is very very complex to attack all allocated objects, moreover
> it depends on where happens the interruption
>
> Best,
>
> Karl
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabor Csardi <Gabor.Csardi at unil.ch>? ?? UNIL DGM


From kjell.konis at epfl.ch  Wed Sep 29 14:46:42 2010
From: kjell.konis at epfl.ch (Konis Kjell)
Date: Wed, 29 Sep 2010 12:46:42 +0000
Subject: [Rd] location of Rconfig.h when using architecture-dependent subdirs
Message-ID: <C8C901D0.594%kjell.konis@epfl.ch>

Hello,

I just tried configuring R to use architecture-dependent subdirs

  $ r_arch=x86_64 ./configure --prefix=/u/smat/konis/testdir


on a Debain Squeeze box

  $ uname -a
  Linux smapc007 2.6.32-5-686 #1 SMP Sat Sep 18 02:14:45 UTC 2010 i686
GNU/Linux


After building and installing, the Rconfig.h ended up in
.../lib/R/include/x86_64 but R.h still includes it as

  #include <Rconfig.h>

I noticed that the CRAN binary for Mac OS X has the following
.../lib/R/include/Rconfig.h. What step am I missing that causes this file
to be generated?

Thanks,
Kjell


/* This is an automatically generated universal stub for
architecture-dependent headers. */
#ifdef __i386__
#include "i386/Rconfig.h"
#elif defined __ppc__
#include "ppc/Rconfig.h"
#elif defined __ppc64__
#include "ppc64/Rconfig.h"
#elif defined __x86_64__
#include "x86_64/Rconfig.h"
#elif defined __arm__
#include "arm/Rconfig.h"
#else
#error "Unsupported architecture."
#endif


From herrold at owlriver.com  Wed Sep 29 15:40:16 2010
From: herrold at owlriver.com (R P Herrold)
Date: Wed, 29 Sep 2010 09:40:16 -0400 (EDT)
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
In-Reply-To: <alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
References: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
	<alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
Message-ID: <alpine.LRH.1.00.1009290937220.10278@oebafba.bjyevire.pbz>

On Tue, 28 Sep 2010, R P Herrold wrote:

>> I am connecting from a PC to a Linux system running CentOS
>> release 5.5 (Final) and it is extremely slow to render plots
>> to the X11 device.

> f <- function(n){
    for(i in 1:n) qqnorm(rnorm(100))
}
system.time(f(20))

> I'll get a packaging built under CentOS 5 on that other architecture 
> overnight, and supplement this post

done -- same sources and build environment, but a i686 rather 
than a a x86_64 architecture.  Similar hardware at the remove 
unit in the local subnet

It is noticeably sluggish in the rendering compared to local X 
client to X server

> f <- function(n){
+    for(i in 1:n) qqnorm(rnorm(100))
+ }
> system.time(f(20))
    user  system elapsed
   0.953   0.185  36.992

-- Russ herrold


From ripley at stats.ox.ac.uk  Wed Sep 29 16:22:45 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Sep 2010 15:22:45 +0100 (BST)
Subject: [Rd] location of Rconfig.h when using architecture-dependent
 subdirs
In-Reply-To: <C8C901D0.594%kjell.konis@epfl.ch>
References: <C8C901D0.594%kjell.konis@epfl.ch>
Message-ID: <alpine.LFD.2.00.1009291454390.25013@toucan.stats.ox.ac.uk>

On Wed, 29 Sep 2010, Konis Kjell wrote:

> Hello,
>
> I just tried configuring R to use architecture-dependent subdirs
>
>  $ r_arch=x86_64 ./configure --prefix=/u/smat/konis/testdir
>
>
> on a Debain Squeeze box
>
>  $ uname -a
>  Linux smapc007 2.6.32-5-686 #1 SMP Sat Sep 18 02:14:45 UTC 2010 i686
> GNU/Linux
>
>
> After building and installing, the Rconfig.h ended up in
> .../lib/R/include/x86_64 but R.h still includes it as
>
>  #include <Rconfig.h>

That should be OK, though.  etc/Makeconf will include

R_XTRA_CPPFLAGS =  -I$(R_INCLUDE_DIR) -I$(R_INCLUDE_DIR)/x86_64

so Rconfig.h will be found when packages are installed.

> I noticed that the CRAN binary for Mac OS X has the following
> .../lib/R/include/Rconfig.h. What step am I missing that causes this file
> to be generated?

I suspect it is a back-compatibility fix for packages with Makefiles 
that don't use R_XTRA_CPPFLAGS.

I don't have that file on my Mac build (nor my R 2.12.0 Windows 
builds, both of which use subarchitectures) and I've never seen an 
issue.

>
> Thanks,
> Kjell
>
>
> /* This is an automatically generated universal stub for
> architecture-dependent headers. */
> #ifdef __i386__
> #include "i386/Rconfig.h"
> #elif defined __ppc__
> #include "ppc/Rconfig.h"
> #elif defined __ppc64__
> #include "ppc64/Rconfig.h"
> #elif defined __x86_64__
> #include "x86_64/Rconfig.h"
> #elif defined __arm__
> #include "arm/Rconfig.h"
> #else
> #error "Unsupported architecture."
> #endif
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Weigand.Stephen at mayo.edu  Wed Sep 29 16:47:09 2010
From: Weigand.Stephen at mayo.edu (Weigand, Stephen D.)
Date: Wed, 29 Sep 2010 09:47:09 -0500
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
In-Reply-To: <alpine.LRH.1.00.1009290937220.10278@oebafba.bjyevire.pbz>
References: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
	<alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
	<alpine.LRH.1.00.1009290937220.10278@oebafba.bjyevire.pbz>
Message-ID: <0BDC4CE410E68F47BA74903185B3DC7702E5141D@MSGEBE12.mfad.mfroot.org>

Many, many thanks for the effort Russ. I'm not clear on next steps
but think I need to look at CentOS vs. others in terms of X. 

-----Original Message-----
From: R P Herrold [mailto:herrold at owlriver.com] 
Sent: Wednesday, September 29, 2010 8:40 AM

On Tue, 28 Sep 2010, R P Herrold wrote:

>> I am connecting from a PC to a Linux system running CentOS release 
>> 5.5 (Final) and it is extremely slow to render plots to the X11 
>> device.

> f <- function(n){
    for(i in 1:n) qqnorm(rnorm(100))
}
system.time(f(20))

> I'll get a packaging built under CentOS 5 on that other architecture 
> overnight, and supplement this post

done -- same sources and build environment, but a i686 rather than a a
x86_64 architecture.  Similar hardware at the remove unit in the local
subnet

It is noticeably sluggish in the rendering compared to local X client to
X server

> f <- function(n){
+    for(i in 1:n) qqnorm(rnorm(100))
+ }
> system.time(f(20))
    user  system elapsed
   0.953   0.185  36.992

-- Russ herrold


From kjell.konis at epfl.ch  Wed Sep 29 16:53:44 2010
From: kjell.konis at epfl.ch (Konis Kjell)
Date: Wed, 29 Sep 2010 14:53:44 +0000
Subject: [Rd] location of Rconfig.h when using architecture-dependent
 subdirs
In-Reply-To: <alpine.LFD.2.00.1009291454390.25013@toucan.stats.ox.ac.uk>
Message-ID: <C8C91CF0.59B%kjell.konis@epfl.ch>

My problem arose while trying to build Graphviz with a swig binding for R.
The wrapper includes R_ext/RS.h which contains #include <Rconfig.h>, then
uses the pkg-config provided search path taken from libR.pc. Currently
this is

Cflags: -I${rincludedir}

Could this be changed to match R_XTRA_CPPFLAGS?

Kjell



On 29.09.10 16:22, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

>On Wed, 29 Sep 2010, Konis Kjell wrote:
>
>> Hello,
>>
>> I just tried configuring R to use architecture-dependent subdirs
>>
>>  $ r_arch=x86_64 ./configure --prefix=/u/smat/konis/testdir
>>
>>
>> on a Debain Squeeze box
>>
>>  $ uname -a
>>  Linux smapc007 2.6.32-5-686 #1 SMP Sat Sep 18 02:14:45 UTC 2010 i686
>> GNU/Linux
>>
>>
>> After building and installing, the Rconfig.h ended up in
>> .../lib/R/include/x86_64 but R.h still includes it as
>>
>>  #include <Rconfig.h>
>
>That should be OK, though.  etc/Makeconf will include
>
>R_XTRA_CPPFLAGS =  -I$(R_INCLUDE_DIR) -I$(R_INCLUDE_DIR)/x86_64
>
>so Rconfig.h will be found when packages are installed.
>
>> I noticed that the CRAN binary for Mac OS X has the following
>> .../lib/R/include/Rconfig.h. What step am I missing that causes this
>>file
>> to be generated?
>
>I suspect it is a back-compatibility fix for packages with Makefiles
>that don't use R_XTRA_CPPFLAGS.
>
>I don't have that file on my Mac build (nor my R 2.12.0 Windows
>builds, both of which use subarchitectures) and I've never seen an
>issue.
>
>>
>> Thanks,
>> Kjell
>>
>>
>> /* This is an automatically generated universal stub for
>> architecture-dependent headers. */
>> #ifdef __i386__
>> #include "i386/Rconfig.h"
>> #elif defined __ppc__
>> #include "ppc/Rconfig.h"
>> #elif defined __ppc64__
>> #include "ppc64/Rconfig.h"
>> #elif defined __x86_64__
>> #include "x86_64/Rconfig.h"
>> #elif defined __arm__
>> #include "arm/Rconfig.h"
>> #else
>> #error "Unsupported architecture."
>> #endif
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Sep 29 16:59:22 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Sep 2010 15:59:22 +0100 (BST)
Subject: [Rd] location of Rconfig.h when using architecture-dependent
 subdirs
In-Reply-To: <C8C91CF0.59B%kjell.konis@epfl.ch>
References: <C8C91CF0.59B%kjell.konis@epfl.ch>
Message-ID: <alpine.LFD.2.00.1009291556380.25782@toucan.stats.ox.ac.uk>

On Wed, 29 Sep 2010, Konis Kjell wrote:

> My problem arose while trying to build Graphviz with a swig binding for R.
> The wrapper includes R_ext/RS.h which contains #include <Rconfig.h>, then
> uses the pkg-config provided search path taken from libR.pc. Currently
> this is
>
> Cflags: -I${rincludedir}
>
> Could this be changed to match R_XTRA_CPPFLAGS?

Yes.  Not sure we will get to it for 2.12.0, but you can presumably 
edit the file yourself pro tem.

>
> Kjell
>
>
>
> On 29.09.10 16:22, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>
>> On Wed, 29 Sep 2010, Konis Kjell wrote:
>>
>>> Hello,
>>>
>>> I just tried configuring R to use architecture-dependent subdirs
>>>
>>>  $ r_arch=x86_64 ./configure --prefix=/u/smat/konis/testdir
>>>
>>>
>>> on a Debain Squeeze box
>>>
>>>  $ uname -a
>>>  Linux smapc007 2.6.32-5-686 #1 SMP Sat Sep 18 02:14:45 UTC 2010 i686
>>> GNU/Linux
>>>
>>>
>>> After building and installing, the Rconfig.h ended up in
>>> .../lib/R/include/x86_64 but R.h still includes it as
>>>
>>>  #include <Rconfig.h>
>>
>> That should be OK, though.  etc/Makeconf will include
>>
>> R_XTRA_CPPFLAGS =  -I$(R_INCLUDE_DIR) -I$(R_INCLUDE_DIR)/x86_64
>>
>> so Rconfig.h will be found when packages are installed.
>>
>>> I noticed that the CRAN binary for Mac OS X has the following
>>> .../lib/R/include/Rconfig.h. What step am I missing that causes this
>>> file
>>> to be generated?
>>
>> I suspect it is a back-compatibility fix for packages with Makefiles
>> that don't use R_XTRA_CPPFLAGS.
>>
>> I don't have that file on my Mac build (nor my R 2.12.0 Windows
>> builds, both of which use subarchitectures) and I've never seen an
>> issue.
>>
>>>
>>> Thanks,
>>> Kjell
>>>
>>>
>>> /* This is an automatically generated universal stub for
>>> architecture-dependent headers. */
>>> #ifdef __i386__
>>> #include "i386/Rconfig.h"
>>> #elif defined __ppc__
>>> #include "ppc/Rconfig.h"
>>> #elif defined __ppc64__
>>> #include "ppc64/Rconfig.h"
>>> #elif defined __x86_64__
>>> #include "x86_64/Rconfig.h"
>>> #elif defined __arm__
>>> #include "arm/Rconfig.h"
>>> #else
>>> #error "Unsupported architecture."
>>> #endif
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hadley at rice.edu  Wed Sep 29 17:05:53 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 29 Sep 2010 10:05:53 -0500
Subject: [Rd] License of R manuals
Message-ID: <AANLkTimXcXjHjV123wBDi759g-ceDVHZOTgQAT+hVf=+@mail.gmail.com>

Hi all,

Under what license are the R manuals (R language definition etc)
released?  They are not mentioned explicitly in license() and have no
license information in the individual documents.  Does this mean that
they are released under GPL-2?  If so, what does that mean, given that
they aren't software?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From berwin at maths.uwa.edu.au  Wed Sep 29 17:34:08 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Wed, 29 Sep 2010 23:34:08 +0800
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
	<C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
Message-ID: <20100929233408.4c49a389@goodenia>

G'day Simon,

since Karl brought up this topic, I thought I might use it to seek
clarification for something that bothered me for some time.

On Tue, 28 Sep 2010 14:55:34 -0400
Simon Urbanek <simon.urbanek at r-project.org> wrote:

> There are several ways in which you can make your code respond to
> interrupts properly - which one is suitable depends on your
> application. Probably the most commonly used for interfacing foreign
> objects is to create an external pointer with a finalizer - that
> makes sure the object is released even if you pass it on to R later.
> For memory allocated within a call you can either use R's transient
> memory allocation (see Salloc) or use the on.exit handler to cleanup
> any objects you allocated manually and left over.

But what about objects created by allocVector() or NEW_XXXX in C code
that is called via .Call that need to be PROTECT'd?

The "Writing R Extensions" manual states:

	The programmer is solely responsible for housekeeping the calls
	to @code{PROTECT}.  There is a corresponding macro
	@code{UNPROTECT} that takes as argument an @code{int} giving
	the number of objects to unprotect when they are no longer
	needed.  The protection mechanism is stack-based, so
	@code{UNPROTECT(@var{n})} unprotects the last @var{n} objects
	which were protected.  The calls to @code{PROTECT} and
	@code{UNPROTECT} must balance when the user's code returns.
	@R{} will warn about @code{"stack imbalance in .Call"} (or
	@code{.External}) if the housekeeping is wrong.

If a call to R_CheckUserInterrupt() may not return, does that mean that
you should not call this function while you have objects PROTECT'd?

Even more, the section on R_CheckUserInterrupt() states:

	Note that it is possible that the code behind one of the entry
	points defined here if called from your C or FORTRAN code could
	be interruptible or generate an error and so not return to your
	code.

This seems to imply that, if you have objects PROTECT'd in your code,
you shouldn't use any of the R API defined in Chapter 6 of the manual,
except if you know that it doesn't call R_CheckUserInterrupt(), and
there seems to be no documentation on which functions in the API do and
which don't.

I guess my question is, essentially, does the PROTECT mechanism and
R_CheckUserInterrupt() play together nicely?  Can I call the latter
from code that has objects PROTECT'd?  If yes, and the code gets
interrupted, is the worse that happens a warning about a stack
imbalance, or will the R session become "unusable/unstable"?

Thanks in advance for any enlightening comments.

Cheers,

	Berwin


From pd.mes at cbs.dk  Wed Sep 29 17:39:41 2010
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 29 Sep 2010 17:39:41 +0200
Subject: [Rd] License of R manuals
In-Reply-To: <AANLkTimXcXjHjV123wBDi759g-ceDVHZOTgQAT+hVf=+@mail.gmail.com>
References: <AANLkTimXcXjHjV123wBDi759g-ceDVHZOTgQAT+hVf=+@mail.gmail.com>
Message-ID: <FD5A9083-86F3-412A-9B98-CC2BD6C05A4B@cbs.dk>


On Sep 29, 2010, at 17:05 , Hadley Wickham wrote:

> Hi all,
> 
> Under what license are the R manuals (R language definition etc)
> released?  They are not mentioned explicitly in license() and have no
> license information in the individual documents.  Does this mean that
> they are released under GPL-2?  If so, what does that mean, given that
> they aren't software?

Hmm, well... I have always understood it so that: (a) yes, it's GPL-2 (what else could it be) and (b) it means that the restrictions of GPL apply insofar as they make sense, e.g., you can pick it apart and reuse it in other GPL-2 or compatible products, but not take it proprietary. Upon request, distributors should probably be prepared to deliver a machine-readable version of the source code. However, there is no requirement of attribution, as with some of the CC licenses. 

By and large, I think this makes sense for technical documentation files. E.g., the help file for poisson.test has stretches of text copied verbatim from binom.test, and it would be ridiculous if such cross-pollination would require that Peter, the author of poisson.test should put in a statement that some of the text was borrowed from binom.test, by Kurt. (In this particular case, both are (c) R Foundation, but you get the point.)

For more extensive free-standing documents, there might be a point in using a CC/FDL-style license instead. However, these licenses appear to be GPL INcompatible, so some care is required.  Until now, the GPL plus Common Courtesy has worked well enough.

> 
> Hadley
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Wed Sep 29 17:47:37 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 29 Sep 2010 11:47:37 -0400
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <20100929233408.4c49a389@goodenia>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
	<C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
	<20100929233408.4c49a389@goodenia>
Message-ID: <8250F4BC-84B7-4DF1-8D13-EB6A5EA4C240@r-project.org>


On Sep 29, 2010, at 11:34 AM, Berwin A Turlach wrote:

> G'day Simon,
> 
> since Karl brought up this topic, I thought I might use it to seek
> clarification for something that bothered me for some time.
> 
> On Tue, 28 Sep 2010 14:55:34 -0400
> Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> There are several ways in which you can make your code respond to
>> interrupts properly - which one is suitable depends on your
>> application. Probably the most commonly used for interfacing foreign
>> objects is to create an external pointer with a finalizer - that
>> makes sure the object is released even if you pass it on to R later.
>> For memory allocated within a call you can either use R's transient
>> memory allocation (see Salloc) or use the on.exit handler to cleanup
>> any objects you allocated manually and left over.
> 
> But what about objects created by allocVector() or NEW_XXXX in C code
> that is called via .Call that need to be PROTECT'd?
> 

Any R objects are just fine because the protection stack gets unwound during cleanup. The whole point of PROTECT is that it protects the object for the duration of the call. On a clean exit you're responsible for the UNPROTECTing, for error handling exit R is responsible.


> The "Writing R Extensions" manual states:
> 
> 	The programmer is solely responsible for housekeeping the calls
> 	to @code{PROTECT}.  There is a corresponding macro
> 	@code{UNPROTECT} that takes as argument an @code{int} giving
> 	the number of objects to unprotect when they are no longer
> 	needed.  The protection mechanism is stack-based, so
> 	@code{UNPROTECT(@var{n})} unprotects the last @var{n} objects
> 	which were protected.  The calls to @code{PROTECT} and
> 	@code{UNPROTECT} must balance when the user's code returns.
> 	@R{} will warn about @code{"stack imbalance in .Call"} (or
> 	@code{.External}) if the housekeeping is wrong.
> 
> If a call to R_CheckUserInterrupt() may not return, does that mean that
> you should not call this function while you have objects PROTECT'd?
> 
> Even more, the section on R_CheckUserInterrupt() states:
> 
> 	Note that it is possible that the code behind one of the entry
> 	points defined here if called from your C or FORTRAN code could
> 	be interruptible or generate an error and so not return to your
> 	code.
> 
> This seems to imply that, if you have objects PROTECT'd in your code,
> you shouldn't use any of the R API defined in Chapter 6 of the manual,
> except if you know that it doesn't call R_CheckUserInterrupt(), and
> there seems to be no documentation on which functions in the API do and
> which don't.
> 

Nope, R_CheckInterrupt is just like any other R function - it may never return - but if it doesn't it cleans up everything R-related properly. The above R-ext note just tells you that your own stuff will need cleaning. R_CheckInterrupt is not really special in any way - for all practical purposes it behaves just like any other R API call and the same rules apply.

Cheers,
Simon


> I guess my question is, essentially, does the PROTECT mechanism and
> R_CheckUserInterrupt() play together nicely?  Can I call the latter
> from code that has objects PROTECT'd?  If yes, and the code gets
> interrupted, is the worse that happens a warning about a stack
> imbalance, or will the R session become "unusable/unstable"?
> 
> Thanks in advance for any enlightening comments.
> 
> Cheers,
> 
> 	Berwin
> 
> 


From hadley at rice.edu  Wed Sep 29 18:00:20 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 29 Sep 2010 11:00:20 -0500
Subject: [Rd] License of R manuals
In-Reply-To: <FD5A9083-86F3-412A-9B98-CC2BD6C05A4B@cbs.dk>
References: <AANLkTimXcXjHjV123wBDi759g-ceDVHZOTgQAT+hVf=+@mail.gmail.com>
	<FD5A9083-86F3-412A-9B98-CC2BD6C05A4B@cbs.dk>
Message-ID: <AANLkTin0nNUx5coWyvF+Ptnc2UNyEeBv3KC0u_Y3tAw9@mail.gmail.com>

> Hmm, well... I have always understood it so that: (a) yes, it's GPL-2 (what else could it be) and (b) it means that the restrictions of GPL apply insofar as they make sense, e.g., you can pick it apart and reuse it in other GPL-2 or compatible products, but not take it proprietary. Upon request, distributors should probably be prepared to deliver a machine-readable version of the source code. However, there is no requirement of attribution, as with some of the CC licenses.
>
> By and large, I think this makes sense for technical documentation files. E.g., the help file for poisson.test has stretches of text copied verbatim from binom.test, and it would be ridiculous if such cross-pollination would require that Peter, the author of poisson.test should put in a statement that some of the text was borrowed from binom.test, by Kurt. (In this particular case, both are (c) R Foundation, but you get the point.)
>
> For more extensive free-standing documents, there might be a point in using a CC/FDL-style license instead. However, these licenses appear to be GPL INcompatible, so some care is required. ?Until now, the GPL plus Common Courtesy has worked well enough.

Ok - great.  I ask because I've been working on a brief introduction
to S3 that has been adapted from the R language definition -
http://github.com/hadley/devtools/wiki/S3. I've included a note giving
the source and stating that its licensed under GPL-2.  Does that sound
sufficient?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From herrold at owlriver.com  Wed Sep 29 19:07:08 2010
From: herrold at owlriver.com (R P Herrold)
Date: Wed, 29 Sep 2010 13:07:08 -0400 (EDT)
Subject: [Rd] Very slow plot rendering with X11 on CentOS 5.5
In-Reply-To: <0BDC4CE410E68F47BA74903185B3DC7702E5141D@MSGEBE12.mfad.mfroot.org>
References: <0BDC4CE410E68F47BA74903185B3DC7702E5141A@MSGEBE12.mfad.mfroot.org>
	<alpine.LRH.1.00.1009281756020.31459@oebafba.bjyevire.pbz>
	<alpine.LRH.1.00.1009290937220.10278@oebafba.bjyevire.pbz>
	<0BDC4CE410E68F47BA74903185B3DC7702E5141D@MSGEBE12.mfad.mfroot.org>
Message-ID: <alpine.LRH.1.00.1009291304260.13938@oebafba.bjyevire.pbz>

On Wed, 29 Sep 2010, Weigand, Stephen D. wrote:

> Many, many thanks for the effort Russ. I'm not clear on next steps
> but think I need to look at CentOS vs. others in terms of X.

I suspect all X will be similar within an order of magnitude, 
but dunno -- I did not 'tune' the workstation I tested on to 
be a racehorse, and there are ways to do that.  Your local 
admins will (should) know how

I guess with such dramatic speed difference, if R is part of 
your daily analytic toolset, I'd use those time trialling as 
the evidence to be lobbying for a local workstation to work 
in.  out of scope, here of course

-- Russ herrold


From simon.urbanek at r-project.org  Wed Sep 29 19:57:55 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 29 Sep 2010 13:57:55 -0400
Subject: [Rd] checking user interrupts in C(++) code
In-Reply-To: <AANLkTim-qxP3zZmmUpkQQc8Ztk4AERhpyokgAua36Lk2@mail.gmail.com>
References: <AANLkTikfpH46Jb7WF3b1Wv_tMs30vagvx2ZB1dKnu38k@mail.gmail.com>
	<C5CD55A5-2313-4748-8F7F-CFB27136A22F@r-project.org>
	<AANLkTim-qxP3zZmmUpkQQc8Ztk4AERhpyokgAua36Lk2@mail.gmail.com>
Message-ID: <197E5670-F949-4493-8BDC-E2ED219966E0@r-project.org>


On Sep 29, 2010, at 4:31 AM, Karl Forner wrote:

> Hi,
> 
> Thanks for your reply,
> 
> 
> There are several ways in which you can make your code respond to interrupts properly - which one is suitable depends on your application. Probably the most commonly used for interfacing foreign objects is to create an external pointer with a finalizer - that makes sure the object is released even if you pass it on to R later. For memory allocated within a call you can either use R's transient memory allocation (see Salloc) or use the on.exit handler to cleanup any objects you allocated manually and left over.
> 
> Using  R's transient memory allocation is not really an option when you use some code, like a library, not developed for R. Moreover what about c++ and the new operator ? 
> 

It's really up to you - clearly, you can set new to use R's allocation (there is some benefit to that due to the more efficient allocation on some platforms, but in general it should not  be needed). For the case of a library the other two options I mentioned are more useful.


> One related question: if the code is interrupted, are C++ local objects freed ? 

Although this may be compiler-dependent in general the answer is no, because you would have to invoke the C++ clean-up code from on.exit and I'm not aware of a portable way of doing it (but I'm not a C++ expert).


> Otherwise it is very very complex to attack all allocated objects, moreover it depends on where happens the interruption
> 

Yes, but in a well-written C++ code that is usually not a problem because you will have a root object that represents the current operation and thus the cleanup is trivial (you will have a top-level interfacing call anyway). If you have multiple such objects that are hard to track for some reason, you can always use the finalizer approach. As you mentioned yourself the only issue are method-local objects that you cannot move inside of the critical region which you may have to push to the attribute level.

Cheers,
Simon


From hpages at fhcrc.org  Wed Sep 29 23:11:39 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 29 Sep 2010 14:11:39 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4C8C6ECB.5080705@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org>
Message-ID: <4CA3AB8B.9020307@fhcrc.org>

Hi,

I can confirm that most of those "strange R CMD build/check errors"
we observe on Windows are actually a consequence of the "temp
Rscript file collision" I reported yesterday here:

   https://stat.ethz.ch/pipermail/r-devel/2010-September/058648.html

I just applied the following patch to the R we use for the Bioconductor
Windows builds:

Index: src/gnuwin32/system.c
===================================================================
--- src/gnuwin32/system.c	(revision 53067)
+++ src/gnuwin32/system.c	(working copy)
@@ -821,6 +821,8 @@

  #include <sys/stat.h>
  #include <time.h>
+#include <sys/types.h>
+#include <unistd.h>
  static int isDir(char *path)
  {
      struct stat sb;
@@ -1093,7 +1095,7 @@
  		}
  	    }
  	    srand( (unsigned) time(NULL) );
-	    sprintf(ifile, "%s/Rscript%x%x", tm, rand(), rand());
+	    sprintf(ifile, "%s/Rscript%dx%x", tm, getpid(), rand());
  	    ifp = fopen(ifile, "w+b");
  	    if(!ifp) R_Suicide(_("creation of tmpfile failed -- set TMPDIR 
suitably?"));
  	}

and the "strange R CMD build/check errors" are now all gone, except
those of the type:

   R\bin\R.exe CMD build baySeq
   * checking for file 'baySeq/DESCRIPTION' ... OK
   * preparing 'baySeq':
   * checking DESCRIPTION meta-information ... OK
   * installing the package to re-build vignettes
   * creating vignettes ...Warning in file(con, "r") :
     cannot open file 
'E:\biocbld\bbs-2.7-bioc\tmpdir\RtmpL9YTVu\xshell45ae180c': Permission 
denied
   Error in file(con, "r") : cannot open the connection
   Execution halted

I didn't initially report failures of this particular type because I
thought they might be yet another manifestation of the same bug but
apparently they are not (looks like it could be a temp file collision
again, but a different temp file now), so I'm going to report them in
a separate post.

Can the patch above be applied? Thanks!

H.


On 09/11/2010 11:10 PM, Herv? Pag?s wrote:
> Hi,
>
> This is a follow up to:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-July/057921.html
>
> The Bioconductor daily builds have been reporting a lot of strange
> things lately on Windows using R-2.12. This started 2 or 3 months
> ago and things are not getting better with recent R-2.12.
> Here is a sample from today's build results. We use Windows Server
> 2003 R2 for the 32-bit builds, Windows Server 2008 R2 Enterprise
> for the 64-bit builds, and R-2.12 (2010-08-26 r52817) on both machines:
>
>
>  >>> On 64-bit Windows:
>
> R\bin\R.exe CMD build ACME
> --> produces no output at all and returns code 0.
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings affypdnn_1.23.0.tar.gz
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--no-vignettes'
> * checking for file 'affypdnn/DESCRIPTION' ... OK
> * this is package 'affypdnn' version '1.23.0'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'affypdnn' can be installed ...Warning in
> file(con, "r") :
> cannot open file
> 'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck/00install.out': No such
> file or directory
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD build ArrayTools
> * checking for file 'ArrayTools/DESCRIPTION' ... OK
> * preparing 'ArrayTools':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> -----------------------------------
> Warning: unknown option '-l'
> * checking for file
> 'E:\biocbld\bbs-2.7-bioc\tmpdir\Rtmpg0MxFa\Rinst69801ce4/DESCRIPTION'
> ... NO
> -----------------------------------
> ERROR: Installation failed
> Removing installation dir
>
>
>  >>> On 64-bit Windows:
>
> R\bin\R.exe CMD build baySeq
> * checking for file 'baySeq/DESCRIPTION' ... OK
> * preparing 'baySeq':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ... ERROR
> Error: ERROR: no packages specified
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings BioSeqClass_1.7.0.tar.gz
> Warning: unknown option '--no-vignettes'
> Warning: unknown option '--timings'
> Converting Rd files to LaTeX ...
> BioSeqClass_1.7.0.tar.gz
> Warning in readLines(f) :
> incomplete final line found on 'BioSeqClass_1.7.0.tar.gz'
> Warning in parse_Rd("BioSeqClass_1.7.0.tar.gz", encoding = "unknown",
> fragment = FALSE, :
> BioSeqClass_1.7.0.tar.gz:2: unexpected UNKNOWN '\?'
> Warning: BioSeqClass_1.7.0.tar.gz:1: All text must be in a section
> Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
> Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
> Warning: BioSeqClass_1.7.0.tar.gz:3: All text must be in a section
> Warning: BioSeqClass_1.7.0.tar.gz:4: All text must be in a section
> Error : BioSeqClass_1.7.0.tar.gz: Sections \title, and \name must exist
> and be unique in Rd files
>
>
>  >>> On 64-bit Windows:
>
> R\bin\R.exe CMD build BufferedMatrix
> --> produces no output at all and returns code 0.
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings daMA_1.21.0.tar.gz
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--no-vignettes'
> * checking for file 'daMA/DESCRIPTION' ... OK
> * this is package 'daMA' version '1.21.0'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'daMA' can be installed ...Warning in
> file(con, "r") :
> cannot open file
> 'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck/00install.out': No such file
> or directory
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings ddCt_1.3.2.tar.gz
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--no-vignettes'
> * checking for file 'ddCt/DESCRIPTION' ... OK
> * this is package 'ddCt' version '1.3.2'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'ddCt' can be installed ...Warning in
> file(con, "r") :
> cannot open file
> 'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck/00install.out': No such file
> or directory
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
>
>  >>> On 64-bit Windows:
>
> R\bin\R.exe CMD build GEOmetadb
> * checking for file 'GEOmetadb/DESCRIPTION' ... OK
> * preparing 'GEOmetadb':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ... ERROR
> Error: ERROR: no packages specified
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings IRanges_1.7.33.tar.gz
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--no-vignettes'
> * checking for file 'IRanges/DESCRIPTION' ... OK
> * this is package 'IRanges' version '1.7.33'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'IRanges' can be installed ... ERROR
> Installation failed.
> See 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck/00install.out' for
> details.
>
> Content of IRanges.Rcheck/00install.out:
>
> * install options '--no-html --no-multiarch'
>
> Warning: unknown option '-l'
> Warning: unknown option '--no-html'
> Warning: unknown option '--no-multiarch'
> Error in .pkg2tex(files, outfile, encoding = encoding, append = append, :
> this package does not have either a 'latex' or a (source) 'man' directory
>
>
>  >>> On 32-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings keggorthology_2.1.1.tar.gz
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--no-vignettes'
> * checking for file 'keggorthology/DESCRIPTION' ... OK
> * this is package 'keggorthology' version '2.1.1'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'keggorthology' can be installed ... ERROR
> Installation failed.
> See 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck/00install.out'
> for details.
>
> Content of keggorthology.Rcheck/00install.out:
>
> * install options '--no-html --no-multiarch'
>
> Warning: unknown option '--no-html'
> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/KEGGOR?1.Rcheck'
> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'KEGGOR?1/DESCRIPTION' ... OK
> * this is package 'keggorthology' version '2.1.1'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'keggorthology' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... ERROR
> Error in library(KEGGOR ? 1) : 'package' must be of length 1
> Execution halted
>
> It looks like this package has a loading problem: see the messages for
> details.
>
>
>  >>> On 64-bit Windows:
>
> R\bin\R.exe CMD check --no-vignettes --timings OLIN_1.27.0.tar.gz
> Warning: unknown option '--no-vignettes'
> Warning: unknown option '--timings'
> Converting Rd files to LaTeX ...
> OLIN_1.27.0.tar.gz
> Warning in readLines(f) :
> incomplete final line found on 'OLIN_1.27.0.tar.gz'
> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
> = FALSE, :
> OLIN_1.27.0.tar.gz:2: unexpected '}'
> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
> = FALSE, :
> OLIN_1.27.0.tar.gz:4: unexpected '}'
> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
> = FALSE, :
> OLIN_1.27.0.tar.gz:7: unexpected '{'
> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
> = FALSE, :
> OLIN_1.27.0.tar.gz:8: unexpected '}'
> Warning: OLIN_1.27.0.tar.gz:1: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:3: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:5: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:6: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
> Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
> Error : OLIN_1.27.0.tar.gz: Sections \title, and \name must exist and be
> unique in Rd files
>
>
>  >>> and so on...
>
>
> AFAICT those problems were never seen before (i.e. with R < 2.12).
> They show up randomly everyday for a small number of packages
> (between 10 and 20 out of 400). The set of victims changes everyday
> and any package seems to be a potential victim (I've not been able
> to observe any obvious pattern so far).
> Does anyone have any idea what could make 'R CMD build' and
> 'R CMD check' so confused/unreliable on Windows?
>
> Thanks,
> H.
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Wed Sep 29 23:13:03 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 29 Sep 2010 14:13:03 -0700
Subject: [Rd] small inaccuracy in startup warning message
In-Reply-To: <4CA279C7.1010408@fhcrc.org>
References: <4CA279C7.1010408@fhcrc.org>
Message-ID: <4CA3ABDF.5090109@fhcrc.org>

It looks like this has been fixed in current R-alpha. Thanks!  H.

On 09/28/2010 04:27 PM, Herv? Pag?s wrote:
> Hi,
>
> Cosmetic. Starting R with e.g. --max-ppsize=-10 produces the following
> warning:
>
> WARNING: '-max-ppsize' value is negative: ignored
>
> The name of the option displayed in the warning is incorrect.
>
> Could that be fixed? See src/main/CommandLineArgs.c (there are 3 places
> in that file where the name of this option needs to be adjusted).
>
> This is with current R-alpha.
>
> Thanks!
> H.
>


From radford at cs.toronto.edu  Thu Sep 30 05:15:57 2010
From: radford at cs.toronto.edu (Radford Neal)
Date: Wed, 29 Sep 2010 23:15:57 -0400
Subject: [Rd] History of seq and seq.int
Message-ID: <20100930031557.GA2782@cs.toronto.edu>

I wonder what is the history of "seq" and "seq.int"?  

>From "help(seq)", one reads that "'seq.int' is an internal generic
which can be much faster but has a few restrictions".  And indeed,
"seq.int(1,99,by=2)" is over 40 times faster than "seq(1,99,by=2)" in
a quick test I just did.  This is not surprising given that "seq" is
written in R whereas "seq.int" is a primitive written in C.  The only
documented restriction on "seq.int" that I can see is that it won't
produce complex-valued sequences.

It would be nice if the 40-times-faster version could replace the slow
version, if it can be made to do the same thing.  But is there some
reason I don't see that this makes this hard?  Was the C version the
original, and then someone decided that complex number support was
essential, and most easily obtained by translating it to R?  (The R
code and C code are very parallel, so there was certainly a
translation rather a rewrite one way or the other.)  Or was the
original in R, and someone rewrote it in C for speed, but stopped just
short of being able to replace the R version with the C version
because they didn't implement complex-valued sequences?  Or is there
some other feature that's missing from seq.int?

By the way, I've submitted a bug report for seq.int, about it
evaluating all it's arguments twice, but that isn't really related to
the efficiency issue of seq versus seq.int.  It is perhaps related to
some strange code (and comments) in seq.int regarding special
treatment for the along.with argument, which maybe also has some
unusual history that isn't obvious...


From jgarcia at ija.csic.es  Thu Sep 30 13:02:49 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Thu, 30 Sep 2010 13:02:49 +0200 (CEST)
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <4CA0B8CA.1040807@gmail.com>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
Message-ID: <1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>

Hi,

I am working on a package with several hydrological functions which
builds/checks/INSTALLs gracefully for a Linux box. However, for a
Microsoft Windows XP [Versi?n 5.1.2600] I have the error:

C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
C:\home\javier\Documents\hydrology\development\hydrosim

Can't locate R/Dcf.pm in @INC (@INC contains: C
/ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
/usr/lib/per
l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
/usr/lib/perl5/site_perl/5.10 /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
/
usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
/usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
 at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build line
28.

However, the content of the first mentioned folder is:

C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm

Is there a problem with the way windows abbreviates folder names for long
names of names withs spaces? Or the problem is elsewhere?

Please, could you help?

Thanks and best regards,
Javier
---


From murdoch.duncan at gmail.com  Thu Sep 30 15:35:44 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Sep 2010 09:35:44 -0400
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
References: <1285598696018-2715520.post@n4.nabble.com>	<4CA0B8CA.1040807@gmail.com>
	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
Message-ID: <4CA49230.3020703@gmail.com>

jgarcia at ija.csic.es wrote:
> Hi,
>
> I am working on a package with several hydrological functions which
> builds/checks/INSTALLs gracefully for a Linux box. However, for a
> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>
> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
> C:\home\javier\Documents\hydrology\development\hydrosim
>   

Are you really using version 2.9.2?  If so, I think you're on your own.  
The current release is 2.11.1, and our efforts are concentrated on 
testing the alpha/beta of 2.12.0 now.

Duncan Murdoch

> Can't locate R/Dcf.pm in @INC (@INC contains: C
> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
> /usr/lib/per
> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
> /usr/lib/perl5/site_perl/5.10 /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
> /
> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>  at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build line
> 28.
>
> However, the content of the first mentioned folder is:
>
> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm
>
> Is there a problem with the way windows abbreviates folder names for long
> names of names withs spaces? Or the problem is elsewhere?
>
> Please, could you help?
>
> Thanks and best regards,
> Javier
> ---
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Thu Sep 30 15:57:29 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2010 14:57:29 +0100 (BST)
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <4CA49230.3020703@gmail.com>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
	<4CA49230.3020703@gmail.com>
Message-ID: <alpine.LFD.2.00.1009301455520.7398@gannet.stats.ox.ac.uk>

On Thu, 30 Sep 2010, Duncan Murdoch wrote:

> jgarcia at ija.csic.es wrote:
>> Hi,
>> 
>> I am working on a package with several hydrological functions which
>> builds/checks/INSTALLs gracefully for a Linux box. However, for a
>> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>> 
>> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
>> C:\home\javier\Documents\hydrology\development\hydrosim
>> 
>
> Are you really using version 2.9.2?  If so, I think you're on your own.  The 
> current release is 2.11.1, and our efforts are concentrated on testing the 
> alpha/beta of 2.12.0 now.

And I believe he failed to heed the warning not to use a Cygwin build 
of Perl.

Please try R 2.12.0 alpha, which does not need any version of Perl to 
build/install/check a package.

>
> Duncan Murdoch
>
>> Can't locate R/Dcf.pm in @INC (@INC contains: C
>> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
>> /usr/lib/per
>> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
>> /usr/lib/perl5/site_perl/5.10 /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
>> /
>> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
>> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>>  at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
>> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build line
>> 28.
>> 
>> However, the content of the first mentioned folder is:
>> 
>> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
>> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm
>> 
>> Is there a problem with the way windows abbreviates folder names for long
>> names of names withs spaces? Or the problem is elsewhere?
>> 
>> Please, could you help?
>> 
>> Thanks and best regards,
>> Javier
>> ---
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Niels.R.Hansen+lists at math.ku.dk  Thu Sep 30 16:19:45 2010
From: Niels.R.Hansen+lists at math.ku.dk (Niels Richard Hansen)
Date: Thu, 30 Sep 2010 16:19:45 +0200
Subject: [Rd] Assignment to a slot in an S4 object in a list seems to
 violate copy rules?
Message-ID: <4CA49C81.6020704@math.ku.dk>

Dear R-developers

I came across the following issue, which I find strange:

setClass("A", representation(a = "numeric"))
B <- list()
myA <- new("A", a = 1)
B$otherA <- myA
B$otherA at a <- 2
myA at a

Assigning a new value to slot 'a' in the _copy_ of myA stored
in B$otherA changes the original value of myA -- this was
surprising to me, and I believe not supposed to be so. This
"copy-through" only happens once.

B$otherA at a <- 1
myA at a

Other ways to access the list entries (B[["otherB"]] and B[[1]]) seem
to work as expected, and it seems that the issue is related to the fact
that 'otherA' does not already exist in B.

Is there something I have missed? Thanks.

Best, Niels	

sessionInfo()

R version 2.12.0 Under development (unstable) (2010-09-13 r52905)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] da_DK.UTF-8/da_DK.UTF-8/C/C/da_DK.UTF-8/da_DK.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Niels Richard Hansen                     Web:   www.math.ku.dk/~richard	
Associate Professor                      Email: Niels.R.Hansen at math.ku.dk
Department of Mathematical Sciences             nielsrichardhansen at gmail.com
University of Copenhagen                 Skype: nielsrichardhansen.dk	
Universitetsparken 5                     Phone: +45 353 20783 (office)	
2100 Copenhagen ?                               +45 2859 0765 (mobile)
Denmark


From pdalgd at gmail.com  Thu Sep 30 17:15:58 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 30 Sep 2010 17:15:58 +0200
Subject: [Rd] Assignment to a slot in an S4 object in a list seems to
	violate copy rules?
In-Reply-To: <4CA49C81.6020704@math.ku.dk>
References: <4CA49C81.6020704@math.ku.dk>
Message-ID: <05A9E180-7213-436D-9321-351B0F7E8882@gmail.com>


On Sep 30, 2010, at 16:19 , Niels Richard Hansen wrote:

> setClass("A", representation(a = "numeric"))
> B <- list()
> myA <- new("A", a = 1)
> B$otherA <- myA
> B$otherA at a <- 2
> myA at a

R version 2.12.0 Under development (unstable) (2010-09-13 r52905)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

--- not anymore, it seems: ---
> setClass("A", representation(a = "numeric"))
[1] "A"
> B <- list()
> myA <- new("A", a = 1)
> B$otherA <- myA
> B$otherA at a <- 2
> myA at a
[1] 1
> sessionInfo()
R version 2.12.0 alpha (2010-09-29 r53067)
Platform: x86_64-apple-darwin10.4.0 (64-bit)

So somewhere in the last 162 commits, this got caught. Probably r52914, but it looks like it hasn't been recored in NEWS (and it should be as this was apparently a live bug, not an obscure corner case):

r52914 | luke | 2010-09-15 19:06:13 +0200 (Wed, 15 Sep 2010) | 4 lines

Modified applydefine to duplicate if necessary to ensure that the
assignment target in calls to assignment functions via the complex
assignment mechanism always has NAMED == 1.




-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jgarcia at ija.csic.es  Thu Sep 30 18:38:22 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Thu, 30 Sep 2010 18:38:22 +0200 (CEST)
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <4CA49230.3020703@gmail.com>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
	<4CA49230.3020703@gmail.com>
Message-ID: <1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>

Thanks to Duncan Murdoch and Prof. Ripley for the previous answers. I
apologize as I was not updated with the R version. Now with R 2.12.0 alpha
the package builds [Windows XP] but it still fails when checking:

---
C:\home\javier\Documents\hydrology\development>R CMD check hydrosim
* using log directory
'C:/home/javier/Documents/hydrology/development/hydrosim.Rcheck'
* using R version 2.12.0 alpha (2010-09-28 r53056)
* using platform: i386-pc-mingw32 (32-bit)
* using session charset: ISO8859-1
* checking for file 'hydrosim/DESCRIPTION' ... OK
* this is package 'hydrosim' version '1.0-0'
* checking package dependencies ... OK
* checking if this is a source package ... OK
Error in system2("file", "--version", TRUE, TRUE) : '"file"' not found
Execution halted

C:\home\javier\Documents\hydrology\development>file
"file" no se reconoce como un comando interno o externo,
programa o archivo por lotes ejecutable.
---

As you may guess, the above means "'file' is not recognized as an internal
or external command, operable program or batch file".

Could you help with this? Perhaps the string "file" should have been
substituted by a file name elsewhere before? Could the white spaces in
"C:\Archivos de programa\..." be the source of the problem?

Thanks again,

Javier
---

> jgarcia at ija.csic.es wrote:
>> Hi,
>>
>> I am working on a package with several hydrological functions which
>> builds/checks/INSTALLs gracefully for a Linux box. However, for a
>> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>>
>> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
>> C:\home\javier\Documents\hydrology\development\hydrosim
>>
>
> Are you really using version 2.9.2?  If so, I think you're on your own.
> The current release is 2.11.1, and our efforts are concentrated on
> testing the alpha/beta of 2.12.0 now.
>
> Duncan Murdoch
>
>> Can't locate R/Dcf.pm in @INC (@INC contains: C
>> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
>> /usr/lib/per
>> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
>> /usr/lib/perl5/site_perl/5.10
>> /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
>> /
>> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
>> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>>  at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
>> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build
>> line
>> 28.
>>
>> However, the content of the first mentioned folder is:
>>
>> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
>> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm
>>
>> Is there a problem with the way windows abbreviates folder names for
>> long
>> names of names withs spaces? Or the problem is elsewhere?
>>
>> Please, could you help?
>>
>> Thanks and best regards,
>> Javier
>> ---
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


From ligges at statistik.tu-dortmund.de  Thu Sep 30 18:37:46 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2010 18:37:46 +0200
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>
References: <1285598696018-2715520.post@n4.nabble.com>	<4CA0B8CA.1040807@gmail.com>	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>	<4CA49230.3020703@gmail.com>
	<1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>
Message-ID: <4CA4BCDA.8000605@statistik.tu-dortmund.de>

You need a recent version of the Rtools from Duncan Murdoch's web page. 
It includes the file.exe required for checking.

Uwe Ligges

On 30.09.2010 18:38, jgarcia at ija.csic.es wrote:
> Thanks to Duncan Murdoch and Prof. Ripley for the previous answers. I
> apologize as I was not updated with the R version. Now with R 2.12.0 alpha
> the package builds [Windows XP] but it still fails when checking:
>
> ---
> C:\home\javier\Documents\hydrology\development>R CMD check hydrosim
> * using log directory
> 'C:/home/javier/Documents/hydrology/development/hydrosim.Rcheck'
> * using R version 2.12.0 alpha (2010-09-28 r53056)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'hydrosim/DESCRIPTION' ... OK
> * this is package 'hydrosim' version '1.0-0'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> Error in system2("file", "--version", TRUE, TRUE) : '"file"' not found
> Execution halted
>
> C:\home\javier\Documents\hydrology\development>file
> "file" no se reconoce como un comando interno o externo,
> programa o archivo por lotes ejecutable.
> ---
>
> As you may guess, the above means "'file' is not recognized as an internal
> or external command, operable program or batch file".
>
> Could you help with this? Perhaps the string "file" should have been
> substituted by a file name elsewhere before? Could the white spaces in
> "C:\Archivos de programa\..." be the source of the problem?
>
> Thanks again,
>
> Javier
> ---
>
>> jgarcia at ija.csic.es wrote:
>>> Hi,
>>>
>>> I am working on a package with several hydrological functions which
>>> builds/checks/INSTALLs gracefully for a Linux box. However, for a
>>> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>>>
>>> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
>>> C:\home\javier\Documents\hydrology\development\hydrosim
>>>
>>
>> Are you really using version 2.9.2?  If so, I think you're on your own.
>> The current release is 2.11.1, and our efforts are concentrated on
>> testing the alpha/beta of 2.12.0 now.
>>
>> Duncan Murdoch
>>
>>> Can't locate R/Dcf.pm in @INC (@INC contains: C
>>> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
>>> /usr/lib/per
>>> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
>>> /usr/lib/perl5/site_perl/5.10
>>> /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
>>> /
>>> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
>>> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>>>   at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
>>> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build
>>> line
>>> 28.
>>>
>>> However, the content of the first mentioned folder is:
>>>
>>> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
>>> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm
>>>
>>> Is there a problem with the way windows abbreviates folder names for
>>> long
>>> names of names withs spaces? Or the problem is elsewhere?
>>>
>>> Please, could you help?
>>>
>>> Thanks and best regards,
>>> Javier
>>> ---
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at uw.edu  Thu Sep 30 17:39:34 2010
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 30 Sep 2010 08:39:34 -0700
Subject: [Rd] Assignment to a slot in an S4 object in a list seems to
 violate copy rules?
In-Reply-To: <05A9E180-7213-436D-9321-351B0F7E8882@gmail.com>
References: <4CA49C81.6020704@math.ku.dk>
	<05A9E180-7213-436D-9321-351B0F7E8882@gmail.com>
Message-ID: <AANLkTikkvmG4PjVLykmGmcg99dC_m0vXmvWo-FOzUUdz@mail.gmail.com>

On Thu, Sep 30, 2010 at 8:15 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Sep 30, 2010, at 16:19 , Niels Richard Hansen wrote:
>
>> setClass("A", representation(a = "numeric"))
>> B <- list()
>> myA <- new("A", a = 1)
>> B$otherA <- myA
>> B$otherA at a <- 2
>> myA at a
>
> R version 2.12.0 Under development (unstable) (2010-09-13 r52905)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>
> --- not anymore, it seems: ---
>> setClass("A", representation(a = "numeric"))
> [1] "A"
>> B <- list()
>> myA <- new("A", a = 1)
>> B$otherA <- myA
>> B$otherA at a <- 2
>> myA at a
> [1] 1
>> sessionInfo()
> R version 2.12.0 alpha (2010-09-29 r53067)
> Platform: x86_64-apple-darwin10.4.0 (64-bit)
>
> So somewhere in the last 162 commits, this got caught. Probably r52914, but it looks like it hasn't been recored in NEWS (and it should be as this was apparently a live bug, not an obscure corner case):
>
> r52914 | luke | 2010-09-15 19:06:13 +0200 (Wed, 15 Sep 2010) | 4 lines
>
> Modified applydefine to duplicate if necessary to ensure that the
> assignment target in calls to assignment functions via the complex
> assignment mechanism always has NAMED == 1.
>

Yes, that was the one.  It was reported as a bug back then too, and
there was quite a bit of discussion that ended up with Luke's fix.

      -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Washington, Seattle


From ripley at stats.ox.ac.uk  Thu Sep 30 19:11:17 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2010 18:11:17 +0100 (BST)
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
	<4CA49230.3020703@gmail.com>
	<1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>
Message-ID: <alpine.LFD.2.00.1009301809250.27926@gannet.stats.ox.ac.uk>

And 'file' is a program available in Rtools ....

On Thu, 30 Sep 2010, jgarcia at ija.csic.es wrote:

> Thanks to Duncan Murdoch and Prof. Ripley for the previous answers. I
> apologize as I was not updated with the R version. Now with R 2.12.0 alpha
> the package builds [Windows XP] but it still fails when checking:
>
> ---
> C:\home\javier\Documents\hydrology\development>R CMD check hydrosim
> * using log directory
> 'C:/home/javier/Documents/hydrology/development/hydrosim.Rcheck'
> * using R version 2.12.0 alpha (2010-09-28 r53056)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'hydrosim/DESCRIPTION' ... OK
> * this is package 'hydrosim' version '1.0-0'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> Error in system2("file", "--version", TRUE, TRUE) : '"file"' not found
> Execution halted
>
> C:\home\javier\Documents\hydrology\development>file
> "file" no se reconoce como un comando interno o externo,
> programa o archivo por lotes ejecutable.
> ---
>
> As you may guess, the above means "'file' is not recognized as an internal
> or external command, operable program or batch file".
>
> Could you help with this? Perhaps the string "file" should have been
> substituted by a file name elsewhere before? Could the white spaces in
> "C:\Archivos de programa\..." be the source of the problem?
>
> Thanks again,
>
> Javier
> ---
>
>> jgarcia at ija.csic.es wrote:
>>> Hi,
>>>
>>> I am working on a package with several hydrological functions which
>>> builds/checks/INSTALLs gracefully for a Linux box. However, for a
>>> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>>>
>>> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
>>> C:\home\javier\Documents\hydrology\development\hydrosim
>>>
>>
>> Are you really using version 2.9.2?  If so, I think you're on your own.
>> The current release is 2.11.1, and our efforts are concentrated on
>> testing the alpha/beta of 2.12.0 now.
>>
>> Duncan Murdoch
>>
>>> Can't locate R/Dcf.pm in @INC (@INC contains: C
>>> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
>>> /usr/lib/per
>>> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
>>> /usr/lib/perl5/site_perl/5.10
>>> /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
>>> /
>>> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
>>> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>>>  at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
>>> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build
>>> line
>>> 28.
>>>
>>> However, the content of the first mentioned folder is:
>>>
>>> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
>>> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm Vars.pm
>>>
>>> Is there a problem with the way windows abbreviates folder names for
>>> long
>>> names of names withs spaces? Or the problem is elsewhere?
>>>
>>> Please, could you help?
>>>
>>> Thanks and best regards,
>>> Javier
>>> ---
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Sep 30 19:13:16 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2010 18:13:16 +0100 (BST)
Subject: [Rd] Assignment to a slot in an S4 object in a list seems to
 violate copy rules?
In-Reply-To: <AANLkTikkvmG4PjVLykmGmcg99dC_m0vXmvWo-FOzUUdz@mail.gmail.com>
References: <4CA49C81.6020704@math.ku.dk>
	<05A9E180-7213-436D-9321-351B0F7E8882@gmail.com>
	<AANLkTikkvmG4PjVLykmGmcg99dC_m0vXmvWo-FOzUUdz@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1009301811430.27926@gannet.stats.ox.ac.uk>

On Thu, 30 Sep 2010, Thomas Lumley wrote:

> On Thu, Sep 30, 2010 at 8:15 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>> On Sep 30, 2010, at 16:19 , Niels Richard Hansen wrote:
>>
>>> setClass("A", representation(a = "numeric"))
>>> B <- list()
>>> myA <- new("A", a = 1)
>>> B$otherA <- myA
>>> B$otherA at a <- 2
>>> myA at a
>>
>> R version 2.12.0 Under development (unstable) (2010-09-13 r52905)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>
>> --- not anymore, it seems: ---
>>> setClass("A", representation(a = "numeric"))
>> [1] "A"
>>> B <- list()
>>> myA <- new("A", a = 1)
>>> B$otherA <- myA
>>> B$otherA at a <- 2
>>> myA at a
>> [1] 1
>>> sessionInfo()
>> R version 2.12.0 alpha (2010-09-29 r53067)
>> Platform: x86_64-apple-darwin10.4.0 (64-bit)
>>
>> So somewhere in the last 162 commits, this got caught. Probably r52914, but it looks like it hasn't been recored in NEWS (and it should be as this was apparently a live bug, not an obscure corner case):
>>
>> r52914 | luke | 2010-09-15 19:06:13 +0200 (Wed, 15 Sep 2010) | 4 lines
>>
>> Modified applydefine to duplicate if necessary to ensure that the
>> assignment target in calls to assignment functions via the complex
>> assignment mechanism always has NAMED == 1.
>>
>
> Yes, that was the one.  It was reported as a bug back then too, and
> there was quite a bit of discussion that ended up with Luke's fix.

There is also a bug fix to that fix a few days later.

>
>      -thomas
>
> -- 
> Thomas Lumley
> Professor of Biostatistics
> University of Washington, Seattle
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hpages at fhcrc.org  Thu Sep 30 19:45:48 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 30 Sep 2010 10:45:48 -0700
Subject: [Rd] tar problem when using 'R CMD build' on Windows
Message-ID: <4CA4CCCC.6020303@fhcrc.org>

Hi,

Already reported here:

   https://stat.ethz.ch/pipermail/r-devel/2010-September/058636.html

but it doesn't seem to be related (at least not in an obvious way) to
the problems described in that previous thread.

So the problem is that, with recent versions of R 2.12 (i.e.
current R-alpha but I've observed this with R-devel for at
least 2-3 months now), 'R CMD build <somepkg>' on Windows will
fail on a random set of Bioconductor packages because of a tar
problem. For example:

   R/bin/R.exe CMD build OLIN
   * checking for file 'OLIN/DESCRIPTION' ... OK
   * preparing 'OLIN':
   * checking DESCRIPTION meta-information ... OK
   /cygdrive/c/RTOOLS?1/bin/tar: OLIN/data/sw.olin.RData: Cannot change 
ownership to uid 0, gid 401: Invalid argument
   /cygdrive/c/RTOOLS?1/bin/tar: OLIN/data/sw.RData: Cannot change 
ownership to uid 0, gid 401: Invalid argument
   /cygdrive/c/RTOOLS?1/bin/tar: OLIN/data/sw.xy.RData: Cannot change 
ownership to uid 0, gid 401: Invalid argument
   /cygdrive/c/RTOOLS?1/bin/tar: OLIN/data: Cannot change ownership to 
uid 0, gid 401: Invalid argument
   ...
   [many lines like this]
   ...
   /cygdrive/c/RTOOLS?1/bin/tar: OLIN: Cannot change ownership to uid 0, 
gid 401: Invalid argument
   /cygdrive/c/RTOOLS?1/bin/tar: Exiting with failure status due to 
previous errors
    ERROR
   copying to build directory failed

19 Bioconductor packages were victim of that bug during yesterday's 
builds, 22 the day before, etc... this looks completely random and
therefore is hard to reproduce.

The following patch:

Index: src/library/tools/R/build.R
===================================================================
--- src/library/tools/R/build.R	(revision 53069)
+++ src/library/tools/R/build.R	(working copy)
@@ -515,7 +515,7 @@
      ## The tar.exe in Rtools has --force-local by default, but this
      ## enables people to use Cygwin or MSYS tar.
      TAR <- Sys.getenv("TAR", NA)
-    TAR <- if (is.na(TAR)) {if (WINDOWS) "tar --force-local" else "tar"}
+    TAR <- if (is.na(TAR)) {if (WINDOWS) "tar --force-local 
--no-same-owner" else "tar"}
      else shQuote(TAR)
      GZIP <- Sys.getenv("R_GZIPCMD")
      if (!nzchar(GZIP)) GZIP <- "gzip"

seems to address the problem even though I admit it doesn't provide
a lot of insight about what's really going on. But it seems safe.

Could it be applied as a workaround?

If that is not desirable, could the tools:::.build_packages() function
not put quotes around the value of the TAR environment variable (the
code does shQuote(TAR)), at least on Windows, so I can set this
variable to

   tar --no-same-owner


Note that the use of quotes around TAR is inconsistent across
utils::untar(), utils::tar() and tools:::.build_packages() (only
the first doesn't put them) but that's another story.

Thanks!
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Thu Sep 30 19:52:19 2010
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 30 Sep 2010 10:52:19 -0700
Subject: [Rd] More strange R CMD build/check errors on Windows
In-Reply-To: <4CA3AB8B.9020307@fhcrc.org>
References: <4C8C6ECB.5080705@fhcrc.org> <4CA3AB8B.9020307@fhcrc.org>
Message-ID: <4CA4CE53.3000909@fhcrc.org>

This has been addressed in current R-alpha, thanks!  H.

On 09/29/2010 02:11 PM, Herv? Pag?s wrote:
> Hi,
>
> I can confirm that most of those "strange R CMD build/check errors"
> we observe on Windows are actually a consequence of the "temp
> Rscript file collision" I reported yesterday here:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-September/058648.html
>
> I just applied the following patch to the R we use for the Bioconductor
> Windows builds:
>
> Index: src/gnuwin32/system.c
> ===================================================================
> --- src/gnuwin32/system.c (revision 53067)
> +++ src/gnuwin32/system.c (working copy)
> @@ -821,6 +821,8 @@
>
> #include <sys/stat.h>
> #include <time.h>
> +#include <sys/types.h>
> +#include <unistd.h>
> static int isDir(char *path)
> {
> struct stat sb;
> @@ -1093,7 +1095,7 @@
> }
> }
> srand( (unsigned) time(NULL) );
> - sprintf(ifile, "%s/Rscript%x%x", tm, rand(), rand());
> + sprintf(ifile, "%s/Rscript%dx%x", tm, getpid(), rand());
> ifp = fopen(ifile, "w+b");
> if(!ifp) R_Suicide(_("creation of tmpfile failed -- set TMPDIR
> suitably?"));
> }
>
> and the "strange R CMD build/check errors" are now all gone, except
> those of the type:
>
> R\bin\R.exe CMD build baySeq
> * checking for file 'baySeq/DESCRIPTION' ... OK
> * preparing 'baySeq':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * creating vignettes ...Warning in file(con, "r") :
> cannot open file
> 'E:\biocbld\bbs-2.7-bioc\tmpdir\RtmpL9YTVu\xshell45ae180c': Permission
> denied
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
> I didn't initially report failures of this particular type because I
> thought they might be yet another manifestation of the same bug but
> apparently they are not (looks like it could be a temp file collision
> again, but a different temp file now), so I'm going to report them in
> a separate post.
>
> Can the patch above be applied? Thanks!
>
> H.
>
>
> On 09/11/2010 11:10 PM, Herv? Pag?s wrote:
>> Hi,
>>
>> This is a follow up to:
>>
>> https://stat.ethz.ch/pipermail/r-devel/2010-July/057921.html
>>
>> The Bioconductor daily builds have been reporting a lot of strange
>> things lately on Windows using R-2.12. This started 2 or 3 months
>> ago and things are not getting better with recent R-2.12.
>> Here is a sample from today's build results. We use Windows Server
>> 2003 R2 for the 32-bit builds, Windows Server 2008 R2 Enterprise
>> for the 64-bit builds, and R-2.12 (2010-08-26 r52817) on both machines:
>>
>>
>> >>> On 64-bit Windows:
>>
>> R\bin\R.exe CMD build ACME
>> --> produces no output at all and returns code 0.
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings affypdnn_1.23.0.tar.gz
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * using option '--no-vignettes'
>> * checking for file 'affypdnn/DESCRIPTION' ... OK
>> * this is package 'affypdnn' version '1.23.0'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'affypdnn' can be installed ...Warning in
>> file(con, "r") :
>> cannot open file
>> 'E:/biocbld/bbs-2.7-bioc/meat/affypdnn.Rcheck/00install.out': No such
>> file or directory
>> Error in file(con, "r") : cannot open the connection
>> Execution halted
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD build ArrayTools
>> * checking for file 'ArrayTools/DESCRIPTION' ... OK
>> * preparing 'ArrayTools':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to re-build vignettes
>> -----------------------------------
>> Warning: unknown option '-l'
>> * checking for file
>> 'E:\biocbld\bbs-2.7-bioc\tmpdir\Rtmpg0MxFa\Rinst69801ce4/DESCRIPTION'
>> ... NO
>> -----------------------------------
>> ERROR: Installation failed
>> Removing installation dir
>>
>>
>> >>> On 64-bit Windows:
>>
>> R\bin\R.exe CMD build baySeq
>> * checking for file 'baySeq/DESCRIPTION' ... OK
>> * preparing 'baySeq':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to re-build vignettes
>> * creating vignettes ... ERROR
>> Error: ERROR: no packages specified
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings BioSeqClass_1.7.0.tar.gz
>> Warning: unknown option '--no-vignettes'
>> Warning: unknown option '--timings'
>> Converting Rd files to LaTeX ...
>> BioSeqClass_1.7.0.tar.gz
>> Warning in readLines(f) :
>> incomplete final line found on 'BioSeqClass_1.7.0.tar.gz'
>> Warning in parse_Rd("BioSeqClass_1.7.0.tar.gz", encoding = "unknown",
>> fragment = FALSE, :
>> BioSeqClass_1.7.0.tar.gz:2: unexpected UNKNOWN '\?'
>> Warning: BioSeqClass_1.7.0.tar.gz:1: All text must be in a section
>> Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
>> Warning: BioSeqClass_1.7.0.tar.gz:2: All text must be in a section
>> Warning: BioSeqClass_1.7.0.tar.gz:3: All text must be in a section
>> Warning: BioSeqClass_1.7.0.tar.gz:4: All text must be in a section
>> Error : BioSeqClass_1.7.0.tar.gz: Sections \title, and \name must exist
>> and be unique in Rd files
>>
>>
>> >>> On 64-bit Windows:
>>
>> R\bin\R.exe CMD build BufferedMatrix
>> --> produces no output at all and returns code 0.
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings daMA_1.21.0.tar.gz
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * using option '--no-vignettes'
>> * checking for file 'daMA/DESCRIPTION' ... OK
>> * this is package 'daMA' version '1.21.0'
>> * checking package name space information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'daMA' can be installed ...Warning in
>> file(con, "r") :
>> cannot open file
>> 'E:/biocbld/bbs-2.7-bioc/meat/daMA.Rcheck/00install.out': No such file
>> or directory
>> Error in file(con, "r") : cannot open the connection
>> Execution halted
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings ddCt_1.3.2.tar.gz
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * using option '--no-vignettes'
>> * checking for file 'ddCt/DESCRIPTION' ... OK
>> * this is package 'ddCt' version '1.3.2'
>> * checking package name space information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'ddCt' can be installed ...Warning in
>> file(con, "r") :
>> cannot open file
>> 'E:/biocbld/bbs-2.7-bioc/meat/ddCt.Rcheck/00install.out': No such file
>> or directory
>> Error in file(con, "r") : cannot open the connection
>> Execution halted
>>
>>
>> >>> On 64-bit Windows:
>>
>> R\bin\R.exe CMD build GEOmetadb
>> * checking for file 'GEOmetadb/DESCRIPTION' ... OK
>> * preparing 'GEOmetadb':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to re-build vignettes
>> * creating vignettes ... ERROR
>> Error: ERROR: no packages specified
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings IRanges_1.7.33.tar.gz
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * using option '--no-vignettes'
>> * checking for file 'IRanges/DESCRIPTION' ... OK
>> * this is package 'IRanges' version '1.7.33'
>> * checking package name space information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'IRanges' can be installed ... ERROR
>> Installation failed.
>> See 'E:/biocbld/bbs-2.7-bioc/meat/IRanges.Rcheck/00install.out' for
>> details.
>>
>> Content of IRanges.Rcheck/00install.out:
>>
>> * install options '--no-html --no-multiarch'
>>
>> Warning: unknown option '-l'
>> Warning: unknown option '--no-html'
>> Warning: unknown option '--no-multiarch'
>> Error in .pkg2tex(files, outfile, encoding = encoding, append = append, :
>> this package does not have either a 'latex' or a (source) 'man' directory
>>
>>
>> >>> On 32-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings keggorthology_2.1.1.tar.gz
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * using option '--no-vignettes'
>> * checking for file 'keggorthology/DESCRIPTION' ... OK
>> * this is package 'keggorthology' version '2.1.1'
>> * checking package name space information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'keggorthology' can be installed ... ERROR
>> Installation failed.
>> See 'E:/biocbld/bbs-2.7-bioc/meat/keggorthology.Rcheck/00install.out'
>> for details.
>>
>> Content of keggorthology.Rcheck/00install.out:
>>
>> * install options '--no-html --no-multiarch'
>>
>> Warning: unknown option '--no-html'
>> * using log directory 'E:/biocbld/bbs-2.7-bioc/meat/KEGGOR?1.Rcheck'
>> * using R version 2.12.0 Under development (unstable) (2010-08-26 r52817)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'KEGGOR?1/DESCRIPTION' ... OK
>> * this is package 'keggorthology' version '2.1.1'
>> * checking package name space information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'keggorthology' can be installed ... OK
>> * checking package directory ... OK
>> * checking for portable file names ... OK
>> * checking DESCRIPTION meta-information ... OK
>> * checking top-level files ... OK
>> * checking index information ... OK
>> * checking package subdirectories ... OK
>> * checking R files for non-ASCII characters ... OK
>> * checking R files for syntax errors ... OK
>> * checking whether the package can be loaded ... ERROR
>> Error in library(KEGGOR ? 1) : 'package' must be of length 1
>> Execution halted
>>
>> It looks like this package has a loading problem: see the messages for
>> details.
>>
>>
>> >>> On 64-bit Windows:
>>
>> R\bin\R.exe CMD check --no-vignettes --timings OLIN_1.27.0.tar.gz
>> Warning: unknown option '--no-vignettes'
>> Warning: unknown option '--timings'
>> Converting Rd files to LaTeX ...
>> OLIN_1.27.0.tar.gz
>> Warning in readLines(f) :
>> incomplete final line found on 'OLIN_1.27.0.tar.gz'
>> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
>> = FALSE, :
>> OLIN_1.27.0.tar.gz:2: unexpected '}'
>> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
>> = FALSE, :
>> OLIN_1.27.0.tar.gz:4: unexpected '}'
>> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
>> = FALSE, :
>> OLIN_1.27.0.tar.gz:7: unexpected '{'
>> Warning in parse_Rd("OLIN_1.27.0.tar.gz", encoding = "unknown", fragment
>> = FALSE, :
>> OLIN_1.27.0.tar.gz:8: unexpected '}'
>> Warning: OLIN_1.27.0.tar.gz:1: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:2: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:3: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:4: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:5: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:6: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:7: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
>> Warning: OLIN_1.27.0.tar.gz:8: All text must be in a section
>> Error : OLIN_1.27.0.tar.gz: Sections \title, and \name must exist and be
>> unique in Rd files
>>
>>
>> >>> and so on...
>>
>>
>> AFAICT those problems were never seen before (i.e. with R < 2.12).
>> They show up randomly everyday for a small number of packages
>> (between 10 and 20 out of 400). The set of victims changes everyday
>> and any package seems to be a potential victim (I've not been able
>> to observe any obvious pattern so far).
>> Does anyone have any idea what could make 'R CMD build' and
>> 'R CMD check' so confused/unreliable on Windows?
>>
>> Thanks,
>> H.
>>
>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jgarcia at ija.csic.es  Thu Sep 30 20:24:58 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Thu, 30 Sep 2010 20:24:58 +0200 (CEST)
Subject: [Rd] bulding a package for Windows (path problem?)
In-Reply-To: <4CA4BCDA.8000605@statistik.tu-dortmund.de>
References: <1285598696018-2715520.post@n4.nabble.com>
	<4CA0B8CA.1040807@gmail.com>
	<1526.155.54.207.175.1285844569.squirrel@paleo.ija.csic.es>
	<4CA49230.3020703@gmail.com>
	<1126.155.54.207.175.1285864702.squirrel@paleo.ija.csic.es>
	<4CA4BCDA.8000605@statistik.tu-dortmund.de>
Message-ID: <1139.155.54.207.175.1285871098.squirrel@paleo.ija.csic.es>

Thanks, Uwe. It now INSTALLs perfectly with Rtools installed.
Best wishes,
Javier
---
> You need a recent version of the Rtools from Duncan Murdoch's web page.
> It includes the file.exe required for checking.
>
> Uwe Ligges
>
> On 30.09.2010 18:38, jgarcia at ija.csic.es wrote:
>> Thanks to Duncan Murdoch and Prof. Ripley for the previous answers. I
>> apologize as I was not updated with the R version. Now with R 2.12.0
>> alpha
>> the package builds [Windows XP] but it still fails when checking:
>>
>> ---
>> C:\home\javier\Documents\hydrology\development>R CMD check hydrosim
>> * using log directory
>> 'C:/home/javier/Documents/hydrology/development/hydrosim.Rcheck'
>> * using R version 2.12.0 alpha (2010-09-28 r53056)
>> * using platform: i386-pc-mingw32 (32-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'hydrosim/DESCRIPTION' ... OK
>> * this is package 'hydrosim' version '1.0-0'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> Error in system2("file", "--version", TRUE, TRUE) : '"file"' not found
>> Execution halted
>>
>> C:\home\javier\Documents\hydrology\development>file
>> "file" no se reconoce como un comando interno o externo,
>> programa o archivo por lotes ejecutable.
>> ---
>>
>> As you may guess, the above means "'file' is not recognized as an
>> internal
>> or external command, operable program or batch file".
>>
>> Could you help with this? Perhaps the string "file" should have been
>> substituted by a file name elsewhere before? Could the white spaces in
>> "C:\Archivos de programa\..." be the source of the problem?
>>
>> Thanks again,
>>
>> Javier
>> ---
>>
>>> jgarcia at ija.csic.es wrote:
>>>> Hi,
>>>>
>>>> I am working on a package with several hydrological functions which
>>>> builds/checks/INSTALLs gracefully for a Linux box. However, for a
>>>> Microsoft Windows XP [Versi?n 5.1.2600] I have the error:
>>>>
>>>> C:\Archivos de programa\R\R-2.9.2\bin>R CMD build
>>>> C:\home\javier\Documents\hydrology\development\hydrosim
>>>>
>>>
>>> Are you really using version 2.9.2?  If so, I think you're on your own.
>>> The current release is 2.11.1, and our efforts are concentrated on
>>> testing the alpha/beta of 2.12.0 now.
>>>
>>> Duncan Murdoch
>>>
>>>> Can't locate R/Dcf.pm in @INC (@INC contains: C
>>>> /ARCHIV~1/R/R-29~1.2/share/perl; /usr/lib/perl5/5.10/i686-cygwin
>>>> /usr/lib/per
>>>> l5/5.10 /usr/lib/perl5/site_perl/5.10/i686-cygwin
>>>> /usr/lib/perl5/site_perl/5.10
>>>> /usr/lib/perl5/vendor_perl/5.10/i686-cygwin
>>>> /
>>>> usr/lib/perl5/vendor_perl/5.10 /usr/lib/perl5/vendor_perl/5.10
>>>> /usr/lib/perl5/site_perl/5.8 /usr/lib/perl5/vendor_perl/5.8 .)
>>>>   at C:\ARCHIV~1\R\R-29~1.2/bin/build line 28.
>>>> BEGIN failed--compilation aborted at C:\ARCHIV~1\R\R-29~1.2/bin/build
>>>> line
>>>> 28.
>>>>
>>>> However, the content of the first mentioned folder is:
>>>>
>>>> C:\ARCHIV~1\R\R-29~1.2\share\perl\R>ls
>>>> Dcf.pm Logfile.pm Rd.pm Rdconv.pm Rdlist.pm Rdtools.pm Utils.pm
>>>> Vars.pm
>>>>
>>>> Is there a problem with the way windows abbreviates folder names for
>>>> long
>>>> names of names withs spaces? Or the problem is elsewhere?
>>>>
>>>> Please, could you help?
>>>>
>>>> Thanks and best regards,
>>>> Javier
>>>> ---
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


